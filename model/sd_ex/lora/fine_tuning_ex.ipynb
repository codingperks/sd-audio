{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19 12:32:19,537] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87822ed83f464169b722ef8107b923f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5782384a014eb4ad9eea06c1f6c6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789d2d98f3864f90810f1005daca42dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40a78d6f8664576bf83ab1c93d9cc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbeec814ab1473a928b797f8b14154c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" , split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=501x512>,\n",
       " 'prompt': 'a spectrogram of bird song',\n",
       " 'audiofile': './data/Bird vocalization-bird call-bird song/train/-aC8TJIZrtE.wav'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 20:51:38,104] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-31 20:51:40,325] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-31 20:51:42,442] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-31 20:51:42,442] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-31 20:51:42,442] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/31/2023 20:51:42 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'dynamic_thresholding_ratio', 'prediction_type', 'sample_max_value', 'thresholding', 'variance_type', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'dual_cross_attention', 'mid_block_only_cross_attention', 'encoder_hid_dim_type', 'projection_class_embeddings_input_dim', 'time_embedding_act_fn', 'class_embed_type', 'num_class_embeds', 'class_embeddings_concat', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'conv_in_kernel', 'upcast_attention', 'resnet_skip_time_act', 'timestep_post_act', 'time_embedding_type', 'conv_out_kernel', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'use_linear_projection', 'encoder_hid_dim', 'addition_embed_type', 'only_cross_attention', 'time_embedding_dim', 'mid_block_type', 'cross_attention_norm'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|███████████████| 587/587 [00:00<00:00, 663090.88it/s]\n",
      "Resolving data files: 100%|███████████████| 115/115 [00:00<00:00, 226772.43it/s]\n",
      "07/31/2023 20:51:45 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-ed444fe877a4ccc2/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 591.16it/s]\n",
      "07/31/2023 20:51:46 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (1).\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.1964704990386963 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-31 20:51:51,475] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/31/2023 20:51:51 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/31/2023 20:51:51 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-31 20:51:51,510] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-31 20:51:51,510] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-31 20:51:51,510] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-31 20:51:51,516] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-31 20:51:51,516] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-31 20:51:51,516] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-31 20:51:51,516] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-31 20:51:51,516] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-31 20:51:51,516] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-31 20:51:51,516] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07412266731262207 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-31 20:51:51,706] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-31 20:51:51,706] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-31 20:51:51,707] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.98 GB, percent = 57.8%\n",
      "[2023-07-31 20:51:51,811] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-31 20:51:51,811] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-31 20:51:51,811] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.98 GB, percent = 57.8%\n",
      "[2023-07-31 20:51:51,812] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-31 20:51:51,905] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-31 20:51:51,905] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-31 20:51:51,905] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.98 GB, percent = 57.8%\n",
      "[2023-07-31 20:51:51,909] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-31 20:51:51,909] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-31 20:51:51,909] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-31 20:51:51,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7efb715b7a00>\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-31 20:51:51,910] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-31 20:51:51,911] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0001964569091796875 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230731_205152-pd5w6oif\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-water-160\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/pd5w6oif\u001b[0m\n",
      "07/31/2023 20:51:58 - INFO - __main__ - ***** Running training *****\n",
      "07/31/2023 20:51:58 - INFO - __main__ -   Num examples = 293\n",
      "07/31/2023 20:51:58 - INFO - __main__ -   Num Epochs = 2365\n",
      "07/31/2023 20:51:58 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/31/2023 20:51:58 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/31/2023 20:51:58 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/31/2023 20:51:58 - INFO - __main__ -   Total optimization steps = 175000\n",
      "Steps:   0%|                                         | 0/175000 [00:00<?, ?it/s]07/31/2023 20:51:58 - INFO - __main__ - Starting epoch 0\n",
      "07/31/2023 20:52:00 - INFO - __main__ - train loss is 0.27870261669158936\n",
      "[2023-07-31 20:52:00,561] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|      | 1/175000 [00:02<117:08:32,  2.41s/it, lr=0, step_loss=0.279]07/31/2023 20:52:00 - INFO - __main__ - train loss is 0.3429446667432785\n",
      "[2023-07-31 20:52:01,065] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|      | 2/175000 [00:02<62:39:59,  1.29s/it, lr=0, step_loss=0.0642]07/31/2023 20:52:01 - INFO - __main__ - train loss is 0.6919285506010056\n",
      "[2023-07-31 20:52:01,573] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|       | 3/175000 [00:03<45:19:44,  1.07it/s, lr=0, step_loss=0.349]07/31/2023 20:52:01 - INFO - __main__ - train loss is 0.7464648671448231\n",
      "[2023-07-31 20:52:02,067] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|      | 4/175000 [00:03<36:54:25,  1.32it/s, lr=0, step_loss=0.0545]07/31/2023 20:52:02 - INFO - __main__ - train loss is 0.8540541864931583\n",
      "[2023-07-31 20:52:02,565] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|       | 5/175000 [00:04<32:19:23,  1.50it/s, lr=0, step_loss=0.108]07/31/2023 20:52:02 - INFO - __main__ - train loss is 0.9633083827793598\n",
      "[2023-07-31 20:52:03,056] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|       | 6/175000 [00:04<29:27:13,  1.65it/s, lr=0, step_loss=0.109]07/31/2023 20:52:03 - INFO - __main__ - train loss is 1.1016420908272266\n",
      "[2023-07-31 20:52:03,546] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|       | 7/175000 [00:05<27:36:13,  1.76it/s, lr=0, step_loss=0.138]07/31/2023 20:52:03 - INFO - __main__ - train loss is 1.2885785587131977\n",
      "[2023-07-31 20:52:04,036] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|       | 8/175000 [00:05<26:24:33,  1.84it/s, lr=0, step_loss=0.187]07/31/2023 20:52:04 - INFO - __main__ - train loss is 1.2913880706764758\n",
      "Steps:   0%| | 9/175000 [00:06<25:42:05,  1.89it/s, lr=8.33e-9, step_loss=0.002807/31/2023 20:52:04 - INFO - __main__ - train loss is 1.4186987043358386\n",
      "[2023-07-31 20:52:05,040] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%| | 10/175000 [00:06<25:22:39,  1.92it/s, lr=8.33e-9, step_loss=0.12707/31/2023 20:52:05 - INFO - __main__ - train loss is 1.4383815438486636\n",
      "Steps:   0%| | 11/175000 [00:07<26:05:57,  1.86it/s, lr=1.67e-8, step_loss=0.01907/31/2023 20:52:06 - INFO - __main__ - train loss is 1.513358457479626\n",
      "Steps:   0%| | 12/175000 [00:07<25:45:41,  1.89it/s, lr=2.5e-8, step_loss=0.075]07/31/2023 20:52:06 - INFO - __main__ - train loss is 1.516102729132399\n",
      "Steps:   0%| | 13/175000 [00:08<25:30:58,  1.90it/s, lr=3.33e-8, step_loss=0.00207/31/2023 20:52:07 - INFO - __main__ - train loss is 1.569354681065306\n",
      "Steps:   0%| | 14/175000 [00:08<25:12:01,  1.93it/s, lr=4.17e-8, step_loss=0.05307/31/2023 20:52:07 - INFO - __main__ - train loss is 1.6152114474680275\n",
      "Steps:   0%|  | 15/175000 [00:09<24:57:22,  1.95it/s, lr=5e-8, step_loss=0.0459]07/31/2023 20:52:08 - INFO - __main__ - train loss is 1.6460792084690183\n",
      "Steps:   0%| | 16/175000 [00:09<24:49:09,  1.96it/s, lr=5.83e-8, step_loss=0.03007/31/2023 20:52:08 - INFO - __main__ - train loss is 1.8071976860519499\n",
      "[2023-07-31 20:52:08,647] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   0%| | 17/175000 [00:10<24:39:28,  1.97it/s, lr=5.83e-8, step_loss=0.16107/31/2023 20:52:09 - INFO - __main__ - train loss is 2.162030812120065\n",
      "Steps:   0%| | 18/175000 [00:11<24:37:16,  1.97it/s, lr=6.67e-8, step_loss=0.35507/31/2023 20:52:09 - INFO - __main__ - train loss is 2.2028021996375173\n",
      "Steps:   0%| | 19/175000 [00:11<24:24:59,  1.99it/s, lr=7.5e-8, step_loss=0.040807/31/2023 20:52:10 - INFO - __main__ - train loss is 2.243546869372949\n",
      "Steps:   0%| | 20/175000 [00:11<24:27:28,  1.99it/s, lr=8.33e-8, step_loss=0.04007/31/2023 20:52:10 - INFO - __main__ - train loss is 2.2549481519963592\n",
      "Steps:   0%| | 21/175000 [00:12<24:29:25,  1.98it/s, lr=9.17e-8, step_loss=0.01107/31/2023 20:52:11 - INFO - __main__ - train loss is 2.2736826406326145\n",
      "Steps:   0%|  | 22/175000 [00:13<24:27:04,  1.99it/s, lr=1e-7, step_loss=0.0187]07/31/2023 20:52:11 - INFO - __main__ - train loss is 2.296181926270947\n",
      "Steps:   0%| | 23/175000 [00:13<24:32:57,  1.98it/s, lr=1.08e-7, step_loss=0.02207/31/2023 20:52:12 - INFO - __main__ - train loss is 2.453702056547627\n",
      "Steps:   0%| | 24/175000 [00:14<24:33:49,  1.98it/s, lr=1.17e-7, step_loss=0.15807/31/2023 20:52:12 - INFO - __main__ - train loss is 2.477183254202828\n",
      "Steps:   0%| | 25/175000 [00:14<24:34:09,  1.98it/s, lr=1.25e-7, step_loss=0.02307/31/2023 20:52:13 - INFO - __main__ - train loss is 2.51177586033009\n",
      "Steps:   0%| | 26/175000 [00:15<24:31:00,  1.98it/s, lr=1.33e-7, step_loss=0.03407/31/2023 20:52:13 - INFO - __main__ - train loss is 2.5884733961429447\n",
      "Steps:   0%| | 27/175000 [00:15<24:27:32,  1.99it/s, lr=1.42e-7, step_loss=0.07607/31/2023 20:52:14 - INFO - __main__ - train loss is 2.6333895528223366\n",
      "Steps:   0%| | 28/175000 [00:16<24:24:19,  1.99it/s, lr=1.5e-7, step_loss=0.044907/31/2023 20:52:14 - INFO - __main__ - train loss is 2.6366408227477223\n",
      "Steps:   0%| | 29/175000 [00:16<24:26:14,  1.99it/s, lr=1.58e-7, step_loss=0.00307/31/2023 20:52:15 - INFO - __main__ - train loss is 2.6445910923648626\n",
      "Steps:   0%| | 30/175000 [00:17<24:30:24,  1.98it/s, lr=1.67e-7, step_loss=0.00707/31/2023 20:52:15 - INFO - __main__ - train loss is 2.711357369320467\n",
      "Steps:   0%| | 31/175000 [00:17<24:30:08,  1.98it/s, lr=1.75e-7, step_loss=0.06607/31/2023 20:52:16 - INFO - __main__ - train loss is 2.7173140302766114\n",
      "Steps:   0%| | 32/175000 [00:18<24:22:54,  1.99it/s, lr=1.83e-7, step_loss=0.00507/31/2023 20:52:16 - INFO - __main__ - train loss is 2.7192539745010436\n",
      "Steps:   0%| | 33/175000 [00:18<24:19:05,  2.00it/s, lr=1.92e-7, step_loss=0.00107/31/2023 20:52:17 - INFO - __main__ - train loss is 2.7275735302828252\n",
      "Steps:   0%| | 34/175000 [00:19<24:10:32,  2.01it/s, lr=2e-7, step_loss=0.00832]07/31/2023 20:52:17 - INFO - __main__ - train loss is 2.849854619707912\n",
      "Steps:   0%| | 35/175000 [00:19<24:16:26,  2.00it/s, lr=2.08e-7, step_loss=0.12207/31/2023 20:52:18 - INFO - __main__ - train loss is 3.091777206864208\n",
      "Steps:   0%| | 36/175000 [00:20<24:17:20,  2.00it/s, lr=2.17e-7, step_loss=0.24207/31/2023 20:52:18 - INFO - __main__ - train loss is 3.5001815571449697\n",
      "Steps:   0%| | 37/175000 [00:20<24:21:11,  2.00it/s, lr=2.25e-7, step_loss=0.40807/31/2023 20:52:19 - INFO - __main__ - train loss is 3.5165409627370536\n",
      "Steps:   0%| | 38/175000 [00:21<24:26:15,  1.99it/s, lr=2.33e-7, step_loss=0.01607/31/2023 20:52:19 - INFO - __main__ - train loss is 3.661010209005326\n",
      "Steps:   0%| | 39/175000 [00:21<24:23:43,  1.99it/s, lr=2.42e-7, step_loss=0.14407/31/2023 20:52:20 - INFO - __main__ - train loss is 3.7994241598062217\n",
      "Steps:   0%| | 40/175000 [00:22<24:26:04,  1.99it/s, lr=2.5e-7, step_loss=0.138]07/31/2023 20:52:20 - INFO - __main__ - train loss is 3.932891774456948\n",
      "Steps:   0%| | 41/175000 [00:22<24:22:28,  1.99it/s, lr=2.58e-7, step_loss=0.13307/31/2023 20:52:21 - INFO - __main__ - train loss is 3.9362503364682198\n",
      "Steps:   0%| | 42/175000 [00:23<24:25:12,  1.99it/s, lr=2.67e-7, step_loss=0.00307/31/2023 20:52:21 - INFO - __main__ - train loss is 3.966778662055731\n",
      "Steps:   0%| | 43/175000 [00:23<24:23:29,  1.99it/s, lr=2.75e-7, step_loss=0.03007/31/2023 20:52:22 - INFO - __main__ - train loss is 4.032311704009771\n",
      "Steps:   0%| | 44/175000 [00:24<24:28:27,  1.99it/s, lr=2.83e-7, step_loss=0.06507/31/2023 20:52:22 - INFO - __main__ - train loss is 4.037343222647905\n",
      "Steps:   0%| | 45/175000 [00:24<24:28:32,  1.99it/s, lr=2.92e-7, step_loss=0.00507/31/2023 20:52:23 - INFO - __main__ - train loss is 4.177831832319498\n",
      "Steps:   0%|    | 46/175000 [00:25<24:26:45,  1.99it/s, lr=3e-7, step_loss=0.14]07/31/2023 20:52:23 - INFO - __main__ - train loss is 4.282117184251547\n",
      "Steps:   0%| | 47/175000 [00:25<24:30:07,  1.98it/s, lr=3.08e-7, step_loss=0.10407/31/2023 20:52:24 - INFO - __main__ - train loss is 4.359630402177572\n",
      "Steps:   0%| | 48/175000 [00:26<24:21:42,  1.99it/s, lr=3.17e-7, step_loss=0.07707/31/2023 20:52:24 - INFO - __main__ - train loss is 4.4338203854858875\n",
      "Steps:   0%| | 49/175000 [00:26<24:18:13,  2.00it/s, lr=3.25e-7, step_loss=0.07407/31/2023 20:52:25 - INFO - __main__ - train loss is 4.629772175103426\n",
      "Steps:   0%| | 50/175000 [00:27<24:15:50,  2.00it/s, lr=3.33e-7, step_loss=0.19607/31/2023 20:52:25 - INFO - __main__ - train loss is 4.9888872392475605\n",
      "Steps:   0%| | 51/175000 [00:27<24:18:41,  2.00it/s, lr=3.42e-7, step_loss=0.35907/31/2023 20:52:26 - INFO - __main__ - train loss is 4.997464809566736\n",
      "Steps:   0%| | 52/175000 [00:28<24:22:22,  1.99it/s, lr=3.5e-7, step_loss=0.008507/31/2023 20:52:26 - INFO - __main__ - train loss is 5.249951396137476\n",
      "Steps:   0%| | 53/175000 [00:28<24:25:42,  1.99it/s, lr=3.58e-7, step_loss=0.25207/31/2023 20:52:27 - INFO - __main__ - train loss is 5.252689054002985\n",
      "Steps:   0%| | 54/175000 [00:29<24:23:22,  1.99it/s, lr=3.67e-7, step_loss=0.00207/31/2023 20:52:27 - INFO - __main__ - train loss is 5.258578124223277\n",
      "Steps:   0%| | 55/175000 [00:29<24:19:23,  2.00it/s, lr=3.75e-7, step_loss=0.00507/31/2023 20:52:28 - INFO - __main__ - train loss is 5.773763897595927\n",
      "Steps:   0%| | 56/175000 [00:30<24:41:46,  1.97it/s, lr=3.83e-7, step_loss=0.51507/31/2023 20:52:28 - INFO - __main__ - train loss is 5.844297158299014\n",
      "Steps:   0%| | 57/175000 [00:30<24:33:16,  1.98it/s, lr=3.92e-7, step_loss=0.07007/31/2023 20:52:29 - INFO - __main__ - train loss is 5.905073980567977\n",
      "Steps:   0%|  | 58/175000 [00:31<24:33:02,  1.98it/s, lr=4e-7, step_loss=0.0608]07/31/2023 20:52:29 - INFO - __main__ - train loss is 6.630696515319869\n",
      "Steps:   0%| | 59/175000 [00:31<24:28:09,  1.99it/s, lr=4.08e-7, step_loss=0.72607/31/2023 20:52:30 - INFO - __main__ - train loss is 6.634418499423191\n",
      "Steps:   0%| | 60/175000 [00:32<24:22:28,  1.99it/s, lr=4.17e-7, step_loss=0.00307/31/2023 20:52:30 - INFO - __main__ - train loss is 6.917860281420872\n",
      "Steps:   0%| | 61/175000 [00:32<24:15:37,  2.00it/s, lr=4.25e-7, step_loss=0.28307/31/2023 20:52:31 - INFO - __main__ - train loss is 6.928087123436853\n",
      "Steps:   0%| | 62/175000 [00:33<24:16:03,  2.00it/s, lr=4.33e-7, step_loss=0.01007/31/2023 20:52:31 - INFO - __main__ - train loss is 7.2797204337548465\n",
      "Steps:   0%| | 63/175000 [00:33<24:19:52,  2.00it/s, lr=4.42e-7, step_loss=0.35207/31/2023 20:52:32 - INFO - __main__ - train loss is 7.867279180092737\n",
      "Steps:   0%| | 64/175000 [00:34<24:19:55,  2.00it/s, lr=4.5e-7, step_loss=0.588]07/31/2023 20:52:32 - INFO - __main__ - train loss is 7.873369234846905\n",
      "Steps:   0%| | 65/175000 [00:34<24:25:53,  1.99it/s, lr=4.58e-7, step_loss=0.00607/31/2023 20:52:33 - INFO - __main__ - train loss is 8.495495218085125\n",
      "Steps:   0%| | 66/175000 [00:35<24:28:06,  1.99it/s, lr=4.67e-7, step_loss=0.62207/31/2023 20:52:33 - INFO - __main__ - train loss is 8.503494245233014\n",
      "Steps:   0%| | 67/175000 [00:35<24:30:30,  1.98it/s, lr=4.75e-7, step_loss=0.00807/31/2023 20:52:34 - INFO - __main__ - train loss is 8.535133336903527\n",
      "Steps:   0%| | 68/175000 [00:36<24:26:12,  1.99it/s, lr=4.83e-7, step_loss=0.03107/31/2023 20:52:34 - INFO - __main__ - train loss is 8.544432698981836\n",
      "Steps:   0%| | 69/175000 [00:36<24:18:15,  2.00it/s, lr=4.92e-7, step_loss=0.00907/31/2023 20:52:35 - INFO - __main__ - train loss is 8.808787583606318\n",
      "[2023-07-31 20:52:35,264] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:   0%| | 70/175000 [00:37<24:22:11,  1.99it/s, lr=4.92e-7, step_loss=0.26407/31/2023 20:52:35 - INFO - __main__ - train loss is 9.166163443820551\n",
      "Steps:   0%|   | 71/175000 [00:37<24:22:36,  1.99it/s, lr=5e-7, step_loss=0.357]07/31/2023 20:52:36 - INFO - __main__ - train loss is 9.171501115197316\n",
      "Steps:   0%| | 72/175000 [00:38<24:18:58,  2.00it/s, lr=5.08e-7, step_loss=0.00507/31/2023 20:52:36 - INFO - __main__ - train loss is 9.17940357257612\n",
      "Steps:   0%| | 73/175000 [00:38<24:19:12,  2.00it/s, lr=5.17e-7, step_loss=0.00707/31/2023 20:52:37 - INFO - __main__ - train loss is 9.183109575882554\n",
      "Steps:   0%| | 74/175000 [00:39<24:17:51,  2.00it/s, lr=5.25e-7, step_loss=0.00307/31/2023 20:52:37 - INFO - __main__ - train loss is 9.207026032730937\n",
      "Steps:   0%| | 75/175000 [00:39<24:19:03,  2.00it/s, lr=5.33e-7, step_loss=0.02307/31/2023 20:52:38 - INFO - __main__ - train loss is 9.213592891581357\n",
      "Steps:   0%| | 76/175000 [00:40<24:22:55,  1.99it/s, lr=5.42e-7, step_loss=0.00607/31/2023 20:52:38 - INFO - __main__ - train loss is 9.402313803322613\n",
      "Steps:   0%| | 77/175000 [00:40<24:36:15,  1.97it/s, lr=5.5e-7, step_loss=0.189]07/31/2023 20:52:39 - INFO - __main__ - train loss is 9.744063560850918\n",
      "Steps:   0%| | 78/175000 [00:41<24:30:32,  1.98it/s, lr=5.58e-7, step_loss=0.34207/31/2023 20:52:39 - INFO - __main__ - train loss is 9.904941861517727\n",
      "Steps:   0%| | 79/175000 [00:41<24:24:17,  1.99it/s, lr=5.67e-7, step_loss=0.16107/31/2023 20:52:40 - INFO - __main__ - train loss is 9.947820016182959\n",
      "Steps:   0%| | 80/175000 [00:42<24:21:52,  1.99it/s, lr=5.75e-7, step_loss=0.04207/31/2023 20:52:40 - INFO - __main__ - train loss is 10.340215333737433\n",
      "Steps:   0%| | 81/175000 [00:42<24:25:06,  1.99it/s, lr=5.83e-7, step_loss=0.39207/31/2023 20:52:41 - INFO - __main__ - train loss is 10.428726666606963\n",
      "Steps:   0%| | 82/175000 [00:43<24:26:41,  1.99it/s, lr=5.92e-7, step_loss=0.08807/31/2023 20:52:41 - INFO - __main__ - train loss is 10.847637587226927\n",
      "Steps:   0%|   | 83/175000 [00:43<24:33:39,  1.98it/s, lr=6e-7, step_loss=0.419]07/31/2023 20:52:42 - INFO - __main__ - train loss is 10.862568182870746\n",
      "Steps:   0%| | 84/175000 [00:44<24:46:16,  1.96it/s, lr=6.08e-7, step_loss=0.01407/31/2023 20:52:42 - INFO - __main__ - train loss is 11.038489116355777\n",
      "Steps:   0%| | 85/175000 [00:44<24:49:27,  1.96it/s, lr=6.17e-7, step_loss=0.17607/31/2023 20:52:43 - INFO - __main__ - train loss is 11.07288114540279\n",
      "Steps:   0%| | 86/175000 [00:45<24:40:01,  1.97it/s, lr=6.25e-7, step_loss=0.03407/31/2023 20:52:43 - INFO - __main__ - train loss is 11.159240437671542\n",
      "Steps:   0%| | 87/175000 [00:45<24:32:19,  1.98it/s, lr=6.33e-7, step_loss=0.08607/31/2023 20:52:44 - INFO - __main__ - train loss is 11.34049273841083\n",
      "Steps:   0%| | 88/175000 [00:46<24:26:59,  1.99it/s, lr=6.42e-7, step_loss=0.18107/31/2023 20:52:44 - INFO - __main__ - train loss is 11.5232123862952\n",
      "Steps:   0%| | 89/175000 [00:46<24:35:58,  1.98it/s, lr=6.5e-7, step_loss=0.183]07/31/2023 20:52:45 - INFO - __main__ - train loss is 11.548455964773893\n",
      "Steps:   0%| | 90/175000 [00:47<24:36:58,  1.97it/s, lr=6.58e-7, step_loss=0.02507/31/2023 20:52:45 - INFO - __main__ - train loss is 11.71801071986556\n",
      "Steps:   0%| | 91/175000 [00:47<24:31:22,  1.98it/s, lr=6.67e-7, step_loss=0.17]07/31/2023 20:52:46 - INFO - __main__ - train loss is 11.831867601722479\n",
      "Steps:   0%| | 92/175000 [00:48<24:29:49,  1.98it/s, lr=6.75e-7, step_loss=0.11407/31/2023 20:52:46 - INFO - __main__ - train loss is 11.923404101282358\n",
      "Steps:   0%| | 93/175000 [00:48<24:24:24,  1.99it/s, lr=6.83e-7, step_loss=0.09107/31/2023 20:52:47 - INFO - __main__ - train loss is 11.97661218419671\n",
      "Steps:   0%| | 94/175000 [00:49<24:20:47,  2.00it/s, lr=6.92e-7, step_loss=0.05307/31/2023 20:52:47 - INFO - __main__ - train loss is 12.318594548851252\n",
      "Steps:   0%|   | 95/175000 [00:49<24:25:05,  1.99it/s, lr=7e-7, step_loss=0.342]07/31/2023 20:52:48 - INFO - __main__ - train loss is 12.763663414865732\n",
      "Steps:   0%| | 96/175000 [00:50<24:25:56,  1.99it/s, lr=7.08e-7, step_loss=0.44507/31/2023 20:52:48 - INFO - __main__ - train loss is 13.105119708925486\n",
      "Steps:   0%| | 97/175000 [00:50<24:23:19,  1.99it/s, lr=7.17e-7, step_loss=0.34107/31/2023 20:52:49 - INFO - __main__ - train loss is 13.177742321044207\n",
      "Steps:   0%| | 98/175000 [00:51<24:23:52,  1.99it/s, lr=7.25e-7, step_loss=0.07207/31/2023 20:52:49 - INFO - __main__ - train loss is 13.371507603675127\n",
      "Steps:   0%| | 99/175000 [00:51<24:20:34,  2.00it/s, lr=7.33e-7, step_loss=0.19407/31/2023 20:52:50 - INFO - __main__ - train loss is 13.373204664560035\n",
      "Steps:   0%| | 100/175000 [00:52<24:18:36,  2.00it/s, lr=7.42e-7, step_loss=0.0007/31/2023 20:52:50 - INFO - __main__ - train loss is 13.444456414552405\n",
      "Steps:   0%| | 101/175000 [00:52<24:41:26,  1.97it/s, lr=7.5e-7, step_loss=0.07107/31/2023 20:52:51 - INFO - __main__ - train loss is 13.465183501364663\n",
      "Steps:   0%| | 102/175000 [00:53<24:41:53,  1.97it/s, lr=7.58e-7, step_loss=0.0207/31/2023 20:52:51 - INFO - __main__ - train loss is 13.611932684900239\n",
      "Steps:   0%| | 103/175000 [00:53<24:41:13,  1.97it/s, lr=7.67e-7, step_loss=0.1407/31/2023 20:52:52 - INFO - __main__ - train loss is 13.61395178292878\n",
      "Steps:   0%| | 104/175000 [00:54<24:27:26,  1.99it/s, lr=7.75e-7, step_loss=0.0007/31/2023 20:52:52 - INFO - __main__ - train loss is 13.97634945367463\n",
      "Steps:   0%| | 105/175000 [00:54<24:20:09,  2.00it/s, lr=7.83e-7, step_loss=0.3607/31/2023 20:52:53 - INFO - __main__ - train loss is 13.983519716421142\n",
      "Steps:   0%| | 106/175000 [00:55<24:24:51,  1.99it/s, lr=7.92e-7, step_loss=0.0007/31/2023 20:52:53 - INFO - __main__ - train loss is 14.427344156662002\n",
      "Steps:   0%|  | 107/175000 [00:55<24:26:55,  1.99it/s, lr=8e-7, step_loss=0.444]07/31/2023 20:52:54 - INFO - __main__ - train loss is 14.430186346871778\n",
      "Steps:   0%| | 108/175000 [00:56<24:35:59,  1.97it/s, lr=8.08e-7, step_loss=0.0007/31/2023 20:52:54 - INFO - __main__ - train loss is 14.432406526757404\n",
      "Steps:   0%| | 109/175000 [00:56<24:30:55,  1.98it/s, lr=8.17e-7, step_loss=0.0007/31/2023 20:52:55 - INFO - __main__ - train loss is 15.205185633851215\n",
      "Steps:   0%| | 110/175000 [00:57<24:26:16,  1.99it/s, lr=8.25e-7, step_loss=0.7707/31/2023 20:52:55 - INFO - __main__ - train loss is 15.207897804910317\n",
      "Steps:   0%| | 111/175000 [00:57<24:24:18,  1.99it/s, lr=8.33e-7, step_loss=0.0007/31/2023 20:52:56 - INFO - __main__ - train loss is 15.224486893275753\n",
      "Steps:   0%| | 112/175000 [00:58<24:18:43,  2.00it/s, lr=8.42e-7, step_loss=0.0107/31/2023 20:52:56 - INFO - __main__ - train loss is 15.716179942945018\n",
      "Steps:   0%| | 113/175000 [00:58<24:21:15,  1.99it/s, lr=8.5e-7, step_loss=0.49207/31/2023 20:52:57 - INFO - __main__ - train loss is 15.865744536975399\n",
      "Steps:   0%| | 114/175000 [00:59<24:44:49,  1.96it/s, lr=8.58e-7, step_loss=0.1507/31/2023 20:52:57 - INFO - __main__ - train loss is 16.505789941409603\n",
      "Steps:   0%| | 115/175000 [00:59<24:33:43,  1.98it/s, lr=8.67e-7, step_loss=0.6407/31/2023 20:52:58 - INFO - __main__ - train loss is 16.678559398511425\n",
      "Steps:   0%| | 116/175000 [01:00<24:31:22,  1.98it/s, lr=8.75e-7, step_loss=0.1707/31/2023 20:52:58 - INFO - __main__ - train loss is 16.985972380498424\n",
      "Steps:   0%| | 117/175000 [01:00<24:29:28,  1.98it/s, lr=8.83e-7, step_loss=0.3007/31/2023 20:52:59 - INFO - __main__ - train loss is 17.33197948918678\n",
      "Steps:   0%| | 118/175000 [01:01<24:28:57,  1.98it/s, lr=8.92e-7, step_loss=0.3407/31/2023 20:52:59 - INFO - __main__ - train loss is 17.581471478799358\n",
      "Steps:   0%|  | 119/175000 [01:01<24:27:56,  1.99it/s, lr=9e-7, step_loss=0.249]07/31/2023 20:53:00 - INFO - __main__ - train loss is 17.60284186177887\n",
      "Steps:   0%| | 120/175000 [01:02<24:24:24,  1.99it/s, lr=9.08e-7, step_loss=0.0207/31/2023 20:53:00 - INFO - __main__ - train loss is 17.627689462387934\n",
      "Steps:   0%| | 121/175000 [01:02<24:22:32,  1.99it/s, lr=9.17e-7, step_loss=0.0207/31/2023 20:53:01 - INFO - __main__ - train loss is 17.87393380352296\n",
      "Steps:   0%| | 122/175000 [01:03<24:27:07,  1.99it/s, lr=9.25e-7, step_loss=0.2407/31/2023 20:53:01 - INFO - __main__ - train loss is 17.990367096150294\n",
      "Steps:   0%| | 123/175000 [01:03<24:31:43,  1.98it/s, lr=9.33e-7, step_loss=0.1107/31/2023 20:53:02 - INFO - __main__ - train loss is 18.49568311520852\n",
      "Steps:   0%| | 124/175000 [01:04<24:36:44,  1.97it/s, lr=9.42e-7, step_loss=0.5007/31/2023 20:53:02 - INFO - __main__ - train loss is 18.569315042579547\n",
      "Steps:   0%| | 125/175000 [01:04<24:26:41,  1.99it/s, lr=9.5e-7, step_loss=0.07307/31/2023 20:53:03 - INFO - __main__ - train loss is 18.57311576511711\n",
      "Steps:   0%| | 126/175000 [01:05<24:24:50,  1.99it/s, lr=9.58e-7, step_loss=0.0007/31/2023 20:53:03 - INFO - __main__ - train loss is 18.59433328267187\n",
      "Steps:   0%| | 127/175000 [01:05<24:28:13,  1.99it/s, lr=9.67e-7, step_loss=0.0207/31/2023 20:53:04 - INFO - __main__ - train loss is 19.12649582978338\n",
      "Steps:   0%| | 128/175000 [01:06<24:30:33,  1.98it/s, lr=9.75e-7, step_loss=0.5307/31/2023 20:53:04 - INFO - __main__ - train loss is 19.380607715807855\n",
      "Steps:   0%| | 129/175000 [01:06<24:25:23,  1.99it/s, lr=9.83e-7, step_loss=0.2507/31/2023 20:53:05 - INFO - __main__ - train loss is 19.404920394532382\n",
      "Steps:   0%| | 130/175000 [01:07<24:28:31,  1.98it/s, lr=9.92e-7, step_loss=0.0207/31/2023 20:53:05 - INFO - __main__ - train loss is 19.41601308248937\n",
      "Steps:   0%| | 131/175000 [01:07<24:33:56,  1.98it/s, lr=1e-6, step_loss=0.0111]07/31/2023 20:53:06 - INFO - __main__ - train loss is 19.8335787858814\n",
      "Steps:   0%| | 132/175000 [01:08<24:44:18,  1.96it/s, lr=1.01e-6, step_loss=0.4107/31/2023 20:53:06 - INFO - __main__ - train loss is 20.013378193601966\n",
      "Steps:   0%| | 133/175000 [01:08<24:38:52,  1.97it/s, lr=1.02e-6, step_loss=0.1807/31/2023 20:53:07 - INFO - __main__ - train loss is 20.02628807350993\n",
      "Steps:   0%| | 134/175000 [01:09<24:41:05,  1.97it/s, lr=1.03e-6, step_loss=0.0107/31/2023 20:53:07 - INFO - __main__ - train loss is 20.078432831913233\n",
      "Steps:   0%| | 135/175000 [01:09<24:35:58,  1.97it/s, lr=1.03e-6, step_loss=0.0507/31/2023 20:53:08 - INFO - __main__ - train loss is 20.122130911797285\n",
      "Steps:   0%| | 136/175000 [01:10<24:33:44,  1.98it/s, lr=1.04e-6, step_loss=0.0407/31/2023 20:53:08 - INFO - __main__ - train loss is 20.163144633173943\n",
      "Steps:   0%| | 137/175000 [01:10<24:31:01,  1.98it/s, lr=1.05e-6, step_loss=0.0407/31/2023 20:53:09 - INFO - __main__ - train loss is 20.194540411233902\n",
      "Steps:   0%| | 138/175000 [01:11<24:38:17,  1.97it/s, lr=1.06e-6, step_loss=0.0307/31/2023 20:53:09 - INFO - __main__ - train loss is 21.04956492781639\n",
      "Steps:   0%| | 139/175000 [01:11<24:45:15,  1.96it/s, lr=1.07e-6, step_loss=0.8507/31/2023 20:53:10 - INFO - __main__ - train loss is 21.184954404830933\n",
      "Steps:   0%| | 140/175000 [01:12<24:40:47,  1.97it/s, lr=1.07e-6, step_loss=0.1307/31/2023 20:53:10 - INFO - __main__ - train loss is 21.29723509401083\n",
      "Steps:   0%| | 141/175000 [01:12<24:31:13,  1.98it/s, lr=1.08e-6, step_loss=0.1107/31/2023 20:53:11 - INFO - __main__ - train loss is 21.36065149307251\n",
      "Steps:   0%| | 142/175000 [01:13<24:28:27,  1.98it/s, lr=1.09e-6, step_loss=0.0607/31/2023 20:53:11 - INFO - __main__ - train loss is 21.40524259209633\n",
      "Steps:   0%| | 143/175000 [01:13<24:28:20,  1.98it/s, lr=1.1e-6, step_loss=0.04407/31/2023 20:53:12 - INFO - __main__ - train loss is 21.412242180667818\n",
      "Steps:   0%| | 144/175000 [01:14<24:35:40,  1.97it/s, lr=1.11e-6, step_loss=0.0007/31/2023 20:53:13 - INFO - __main__ - train loss is 21.686230308376253\n",
      "Steps:   0%| | 145/175000 [01:14<24:31:13,  1.98it/s, lr=1.12e-6, step_loss=0.2707/31/2023 20:53:13 - INFO - __main__ - train loss is 21.699315091595054\n",
      "Steps:   0%| | 146/175000 [01:15<24:30:09,  1.98it/s, lr=1.13e-6, step_loss=0.0107/31/2023 20:53:14 - INFO - __main__ - train loss is 21.740093117579818\n",
      "Steps:   0%| | 147/175000 [01:15<24:30:54,  1.98it/s, lr=1.13e-6, step_loss=0.0407/31/2023 20:53:14 - INFO - __main__ - train loss is 21.74196355312597\n",
      "Steps:   0%| | 148/175000 [01:16<24:39:17,  1.97it/s, lr=1.14e-6, step_loss=0.0007/31/2023 20:53:15 - INFO - __main__ - train loss is 21.99364380806219\n",
      "Steps:   0%| | 149/175000 [01:16<24:31:14,  1.98it/s, lr=1.15e-6, step_loss=0.2507/31/2023 20:53:15 - INFO - __main__ - train loss is 22.200374680454843\n",
      "Steps:   0%| | 150/175000 [01:17<24:27:44,  1.99it/s, lr=1.16e-6, step_loss=0.2007/31/2023 20:53:16 - INFO - __main__ - train loss is 22.209572822670452\n",
      "Steps:   0%| | 151/175000 [01:17<24:08:26,  2.01it/s, lr=1.17e-6, step_loss=0.0007/31/2023 20:53:16 - INFO - __main__ - train loss is 22.212396084680222\n",
      "Steps:   0%| | 152/175000 [01:18<24:12:14,  2.01it/s, lr=1.17e-6, step_loss=0.0007/31/2023 20:53:17 - INFO - __main__ - train loss is 22.28505086095538\n",
      "Steps:   0%| | 153/175000 [01:18<24:15:52,  2.00it/s, lr=1.18e-6, step_loss=0.0707/31/2023 20:53:17 - INFO - __main__ - train loss is 22.287233949056827\n",
      "Steps:   0%| | 154/175000 [01:19<24:17:05,  2.00it/s, lr=1.19e-6, step_loss=0.0007/31/2023 20:53:18 - INFO - __main__ - train loss is 22.29644161032047\n",
      "Steps:   0%| | 155/175000 [01:19<24:15:47,  2.00it/s, lr=1.2e-6, step_loss=0.00907/31/2023 20:53:18 - INFO - __main__ - train loss is 22.29822239105124\n",
      "Steps:   0%| | 156/175000 [01:20<24:38:44,  1.97it/s, lr=1.21e-6, step_loss=0.0007/31/2023 20:53:19 - INFO - __main__ - train loss is 22.456622688216157\n",
      "Steps:   0%| | 157/175000 [01:21<24:53:15,  1.95it/s, lr=1.22e-6, step_loss=0.1507/31/2023 20:53:19 - INFO - __main__ - train loss is 22.485082926345058\n",
      "Steps:   0%| | 158/175000 [01:21<24:58:18,  1.94it/s, lr=1.23e-6, step_loss=0.0207/31/2023 20:53:20 - INFO - __main__ - train loss is 22.48695525212679\n",
      "Steps:   0%| | 159/175000 [01:22<24:49:39,  1.96it/s, lr=1.23e-6, step_loss=0.0007/31/2023 20:53:20 - INFO - __main__ - train loss is 22.584827852086164\n",
      "Steps:   0%| | 160/175000 [01:22<24:38:40,  1.97it/s, lr=1.24e-6, step_loss=0.0907/31/2023 20:53:21 - INFO - __main__ - train loss is 22.593572218553163\n",
      "Steps:   0%| | 161/175000 [01:23<24:29:01,  1.98it/s, lr=1.25e-6, step_loss=0.0007/31/2023 20:53:21 - INFO - __main__ - train loss is 22.787021447555162\n",
      "Steps:   0%| | 162/175000 [01:23<24:26:42,  1.99it/s, lr=1.26e-6, step_loss=0.1907/31/2023 20:53:22 - INFO - __main__ - train loss is 23.051126946345903\n",
      "Steps:   0%| | 163/175000 [01:24<24:20:24,  2.00it/s, lr=1.27e-6, step_loss=0.2607/31/2023 20:53:22 - INFO - __main__ - train loss is 23.282793824211694\n",
      "Steps:   0%| | 164/175000 [01:24<24:23:12,  1.99it/s, lr=1.28e-6, step_loss=0.2307/31/2023 20:53:23 - INFO - __main__ - train loss is 23.28616358374711\n",
      "Steps:   0%| | 165/175000 [01:25<24:32:49,  1.98it/s, lr=1.28e-6, step_loss=0.0007/31/2023 20:53:23 - INFO - __main__ - train loss is 23.290617443970405\n",
      "Steps:   0%| | 166/175000 [01:25<26:03:38,  1.86it/s, lr=1.29e-6, step_loss=0.0007/31/2023 20:53:24 - INFO - __main__ - train loss is 23.305387705913745\n",
      "Steps:   0%| | 167/175000 [01:26<25:35:35,  1.90it/s, lr=1.3e-6, step_loss=0.01407/31/2023 20:53:24 - INFO - __main__ - train loss is 23.500843108049594\n",
      "Steps:   0%| | 168/175000 [01:26<25:20:57,  1.92it/s, lr=1.31e-6, step_loss=0.1907/31/2023 20:53:25 - INFO - __main__ - train loss is 23.93845665489789\n",
      "Steps:   0%| | 169/175000 [01:27<25:08:12,  1.93it/s, lr=1.32e-6, step_loss=0.4307/31/2023 20:53:25 - INFO - __main__ - train loss is 24.128981098881923\n",
      "Steps:   0%| | 170/175000 [01:27<24:52:38,  1.95it/s, lr=1.33e-6, step_loss=0.1907/31/2023 20:53:26 - INFO - __main__ - train loss is 24.254867986193858\n",
      "Steps:   0%| | 171/175000 [01:28<24:45:49,  1.96it/s, lr=1.33e-6, step_loss=0.1207/31/2023 20:53:26 - INFO - __main__ - train loss is 24.594290688983165\n",
      "Steps:   0%| | 172/175000 [01:28<24:38:16,  1.97it/s, lr=1.34e-6, step_loss=0.3307/31/2023 20:53:27 - INFO - __main__ - train loss is 24.69743916427251\n",
      "Steps:   0%| | 173/175000 [01:29<24:30:17,  1.98it/s, lr=1.35e-6, step_loss=0.1007/31/2023 20:53:27 - INFO - __main__ - train loss is 25.10043135320302\n",
      "Steps:   0%| | 174/175000 [01:29<24:30:26,  1.98it/s, lr=1.36e-6, step_loss=0.4007/31/2023 20:53:28 - INFO - __main__ - train loss is 25.297043755999766\n",
      "Steps:   0%| | 175/175000 [01:30<24:39:28,  1.97it/s, lr=1.37e-6, step_loss=0.1907/31/2023 20:53:28 - INFO - __main__ - train loss is 25.433565274230205\n",
      "Steps:   0%| | 176/175000 [01:30<25:04:18,  1.94it/s, lr=1.38e-6, step_loss=0.1307/31/2023 20:53:29 - INFO - __main__ - train loss is 25.653566182008944\n",
      "Steps:   0%| | 177/175000 [01:31<24:55:05,  1.95it/s, lr=1.38e-6, step_loss=0.2207/31/2023 20:53:29 - INFO - __main__ - train loss is 25.797939539304934\n",
      "Steps:   0%| | 178/175000 [01:31<24:48:00,  1.96it/s, lr=1.39e-6, step_loss=0.1407/31/2023 20:53:30 - INFO - __main__ - train loss is 25.813281726441346\n",
      "Steps:   0%| | 179/175000 [01:32<24:45:16,  1.96it/s, lr=1.4e-6, step_loss=0.01507/31/2023 20:53:30 - INFO - __main__ - train loss is 25.81572895788122\n",
      "Steps:   0%| | 180/175000 [01:32<24:43:09,  1.96it/s, lr=1.41e-6, step_loss=0.0007/31/2023 20:53:31 - INFO - __main__ - train loss is 25.817804198595695\n",
      "Steps:   0%| | 181/175000 [01:33<24:41:58,  1.97it/s, lr=1.42e-6, step_loss=0.0007/31/2023 20:53:31 - INFO - __main__ - train loss is 25.833644593018107\n",
      "Steps:   0%| | 182/175000 [01:33<24:36:02,  1.97it/s, lr=1.43e-6, step_loss=0.0107/31/2023 20:53:32 - INFO - __main__ - train loss is 25.92212163831573\n",
      "Steps:   0%| | 183/175000 [01:34<24:24:13,  1.99it/s, lr=1.43e-6, step_loss=0.0807/31/2023 20:53:32 - INFO - __main__ - train loss is 26.141104632872157\n",
      "Steps:   0%| | 184/175000 [01:34<24:18:34,  2.00it/s, lr=1.44e-6, step_loss=0.2107/31/2023 20:53:33 - INFO - __main__ - train loss is 26.157618807512335\n",
      "Steps:   0%| | 185/175000 [01:35<24:17:39,  2.00it/s, lr=1.45e-6, step_loss=0.0107/31/2023 20:53:33 - INFO - __main__ - train loss is 26.329552965122275\n",
      "Steps:   0%| | 186/175000 [01:35<24:11:37,  2.01it/s, lr=1.46e-6, step_loss=0.1707/31/2023 20:53:34 - INFO - __main__ - train loss is 26.78245736833196\n",
      "Steps:   0%| | 187/175000 [01:36<24:28:07,  1.98it/s, lr=1.47e-6, step_loss=0.4507/31/2023 20:53:34 - INFO - __main__ - train loss is 26.787682225811295\n",
      "Steps:   0%| | 188/175000 [01:36<25:38:59,  1.89it/s, lr=1.48e-6, step_loss=0.0007/31/2023 20:53:35 - INFO - __main__ - train loss is 26.84446258645039\n",
      "Steps:   0%| | 189/175000 [01:37<25:14:18,  1.92it/s, lr=1.48e-6, step_loss=0.0507/31/2023 20:53:35 - INFO - __main__ - train loss is 26.932891113567166\n",
      "Steps:   0%| | 190/175000 [01:37<24:57:51,  1.95it/s, lr=1.49e-6, step_loss=0.0807/31/2023 20:53:36 - INFO - __main__ - train loss is 26.964156566071324\n",
      "Steps:   0%| | 191/175000 [01:38<24:43:07,  1.96it/s, lr=1.5e-6, step_loss=0.03107/31/2023 20:53:36 - INFO - __main__ - train loss is 27.00787267636042\n",
      "Steps:   0%| | 192/175000 [01:38<24:36:17,  1.97it/s, lr=1.51e-6, step_loss=0.04^C\n",
      "\u001b[2;36m[20:53:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Received \u001b[1;36m2\u001b[0m death signal, shutting down workers    \u001b]8;id=631891;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=541673;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py#729\u001b\\\u001b[2m729\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Sending process \u001b[1;36m13693\u001b[0m closing signal SIGINT       \u001b]8;id=376581;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=292540;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#698\u001b\\\u001b[2m698\u001b[0m\u001b]8;;\u001b\\\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7efbe2d4c790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1219, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 907, in main\n",
      "    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py\", line 823, in forward\n",
      "    sample = self.mid_block(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py\", line 574, in forward\n",
      "    hidden_states = attn(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/transformer_2d.py\", line 296, in forward\n",
      "    hidden_states = block(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention.py\", line 160, in forward\n",
      "    attn_output = self.attn2(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention_processor.py\", line 320, in forward\n",
      "    return self.processor(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention_processor.py\", line 605, in __call__\n",
      "    hidden_states = attn.to_out[0](hidden_states) + scale * self.to_out_lora(hidden_states)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention_processor.py\", line 529, in forward\n",
      "    up_hidden_states = self.up(down_hidden_states)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1604, in __getattr__\n",
      "    if name in _parameters:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=175000 \\\n",
    "  --learning_rate=1e-04 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --validation_epochs=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=3000 \\\n",
    "  --output_dir=$\"./out/28-07\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of acoustic guitar\" \\\n",
    "  --validation_prompt2=\"A spectrogram of cheering\" \\\n",
    "  --validation_prompt3=\"A spectrogram of dog bark\" \\\n",
    "  --validation_prompt4=\"A spectrogram of snare drum\" \\\n",
    "  --validation_prompt5=\"A spectrogram of train horn\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-27 17:44:25,419] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-27 17:44:28,280] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-27 17:44:31,722] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-27 17:44:31,722] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-27 17:44:31,722] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/27/2023 17:44:31 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'prediction_type', 'thresholding', 'sample_max_value', 'dynamic_thresholding_ratio', 'clip_sample_range', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'conv_out_kernel', 'conv_in_kernel', 'time_cond_proj_dim', 'resnet_skip_time_act', 'resnet_time_scale_shift', 'timestep_post_act', 'encoder_hid_dim_type', 'class_embed_type', 'encoder_hid_dim', 'dual_cross_attention', 'addition_embed_type', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'class_embeddings_concat', 'only_cross_attention', 'mid_block_type', 'mid_block_only_cross_attention', 'time_embedding_act_fn', 'num_class_embeds', 'time_embedding_dim', 'use_linear_projection', 'upcast_attention', 'time_embedding_type', 'cross_attention_norm'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|███████████████| 607/607 [00:00<00:00, 578623.30it/s]\n",
      "Resolving data files: 100%|███████████████| 159/159 [00:00<00:00, 176333.77it/s]\n",
      "07/27/2023 17:44:36 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-6db3f63079a2e832/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 416.62it/s]\n",
      "07/27/2023 17:44:37 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (1).\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.206104278564453 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.001000, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-27 17:44:42,784] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/27/2023 17:44:42 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/27/2023 17:44:42 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-27 17:44:42,818] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-27 17:44:42,819] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-27 17:44:42,819] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-27 17:44:42,824] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-27 17:44:42,824] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-27 17:44:42,824] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-27 17:44:42,824] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-27 17:44:42,824] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-27 17:44:42,825] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-27 17:44:42,825] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07692790031433105 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-27 17:44:43,021] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-27 17:44:43,022] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-27 17:44:43,022] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 5.86 GB, percent = 37.7%\n",
      "[2023-07-27 17:44:43,126] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-27 17:44:43,127] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-27 17:44:43,127] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 5.86 GB, percent = 37.7%\n",
      "[2023-07-27 17:44:43,127] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-27 17:44:43,221] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-27 17:44:43,221] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-27 17:44:43,221] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 5.86 GB, percent = 37.7%\n",
      "[2023-07-27 17:44:43,226] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-27 17:44:43,226] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-27 17:44:43,226] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-27 17:44:43,226] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
      "[2023-07-27 17:44:43,226] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f16d82b9570>\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-27 17:44:43,227] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-27 17:44:43,228] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0001990795135498047 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230727_174444-3s4fa9rp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-dawn-147\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/3s4fa9rp\u001b[0m\n",
      "07/27/2023 17:44:49 - INFO - __main__ - ***** Running training *****\n",
      "07/27/2023 17:44:49 - INFO - __main__ -   Num examples = 303\n",
      "07/27/2023 17:44:49 - INFO - __main__ -   Num Epochs = 198\n",
      "07/27/2023 17:44:49 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/27/2023 17:44:49 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/27/2023 17:44:49 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/27/2023 17:44:49 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]07/27/2023 17:44:49 - INFO - __main__ - Starting epoch 0\n",
      "07/27/2023 17:44:52 - INFO - __main__ - train loss is 0.3201653063297272\n",
      "[2023-07-27 17:44:52,497] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|         | 1/15000 [00:02<11:19:55,  2.72s/it, lr=0, step_loss=0.32]07/27/2023 17:44:52 - INFO - __main__ - train loss is 0.42399103939533234\n",
      "[2023-07-27 17:44:52,994] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|         | 2/15000 [00:03<5:53:02,  1.41s/it, lr=0, step_loss=0.104]07/27/2023 17:44:53 - INFO - __main__ - train loss is 0.819630578160286\n",
      "[2023-07-27 17:44:53,487] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|         | 3/15000 [00:03<4:08:05,  1.01it/s, lr=0, step_loss=0.396]07/27/2023 17:44:53 - INFO - __main__ - train loss is 0.865287896245718\n",
      "[2023-07-27 17:44:53,980] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|        | 4/15000 [00:04<3:18:45,  1.26it/s, lr=0, step_loss=0.0457]07/27/2023 17:44:54 - INFO - __main__ - train loss is 0.9997849725186825\n",
      "[2023-07-27 17:44:54,471] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|         | 5/15000 [00:04<2:51:19,  1.46it/s, lr=0, step_loss=0.134]07/27/2023 17:44:54 - INFO - __main__ - train loss is 1.1258753202855587\n",
      "[2023-07-27 17:44:54,994] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|         | 6/15000 [00:05<2:37:29,  1.59it/s, lr=0, step_loss=0.126]07/27/2023 17:44:55 - INFO - __main__ - train loss is 1.2985133342444897\n",
      "[2023-07-27 17:44:55,485] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|         | 7/15000 [00:05<2:26:06,  1.71it/s, lr=0, step_loss=0.173]07/27/2023 17:44:55 - INFO - __main__ - train loss is 1.5183276943862438\n",
      "[2023-07-27 17:44:55,978] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|          | 8/15000 [00:06<2:18:46,  1.80it/s, lr=0, step_loss=0.22]07/27/2023 17:44:56 - INFO - __main__ - train loss is 1.5220562750473619\n",
      "Steps:   0%| | 9/15000 [00:06<2:14:27,  1.86it/s, lr=1.25e-7, step_loss=0.00373]07/27/2023 17:44:56 - INFO - __main__ - train loss is 1.6581117743626237\n",
      "[2023-07-27 17:44:56,984] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%|  | 10/15000 [00:07<2:11:57,  1.89it/s, lr=1.25e-7, step_loss=0.136]07/27/2023 17:44:57 - INFO - __main__ - train loss is 1.6759554585441947\n",
      "Steps:   0%|  | 11/15000 [00:07<2:09:39,  1.93it/s, lr=2.5e-7, step_loss=0.0178]07/27/2023 17:44:57 - INFO - __main__ - train loss is 1.7711524805054069\n",
      "Steps:   0%| | 12/15000 [00:08<2:08:37,  1.94it/s, lr=3.75e-7, step_loss=0.0952]07/27/2023 17:44:58 - INFO - __main__ - train loss is 1.7744398573413491\n",
      "Steps:   0%|   | 13/15000 [00:08<2:07:48,  1.95it/s, lr=5e-7, step_loss=0.00329]07/27/2023 17:44:58 - INFO - __main__ - train loss is 1.8437373796477914\n",
      "Steps:   0%| | 14/15000 [00:09<2:06:51,  1.97it/s, lr=6.25e-7, step_loss=0.0693]07/27/2023 17:44:59 - INFO - __main__ - train loss is 1.90144366864115\n",
      "Steps:   0%|  | 15/15000 [00:09<2:06:42,  1.97it/s, lr=7.5e-7, step_loss=0.0577]07/27/2023 17:44:59 - INFO - __main__ - train loss is 1.9429183760657907\n",
      "Steps:   0%| | 16/15000 [00:10<2:06:25,  1.98it/s, lr=8.75e-7, step_loss=0.0415]07/27/2023 17:45:00 - INFO - __main__ - train loss is 2.1625865260139108\n",
      "[2023-07-27 17:45:00,498] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   0%|   | 17/15000 [00:10<2:05:46,  1.99it/s, lr=8.75e-7, step_loss=0.22]07/27/2023 17:45:00 - INFO - __main__ - train loss is 2.53856594953686\n",
      "Steps:   0%|     | 18/15000 [00:11<2:05:52,  1.98it/s, lr=1e-6, step_loss=0.376]07/27/2023 17:45:01 - INFO - __main__ - train loss is 2.5722418585792184\n",
      "Steps:   0%| | 19/15000 [00:11<2:05:33,  1.99it/s, lr=1.13e-6, step_loss=0.0337]07/27/2023 17:45:01 - INFO - __main__ - train loss is 2.6066103810444474\n",
      "Steps:   0%| | 20/15000 [00:12<2:05:15,  1.99it/s, lr=1.25e-6, step_loss=0.0344]07/27/2023 17:45:02 - INFO - __main__ - train loss is 2.616840205155313\n",
      "Steps:   0%| | 21/15000 [00:12<2:05:28,  1.99it/s, lr=1.37e-6, step_loss=0.0102]07/27/2023 17:45:02 - INFO - __main__ - train loss is 2.635043597780168\n",
      "Steps:   0%|  | 22/15000 [00:13<2:05:37,  1.99it/s, lr=1.5e-6, step_loss=0.0182]07/27/2023 17:45:03 - INFO - __main__ - train loss is 2.6630769772455096\n",
      "Steps:   0%|  | 23/15000 [00:13<2:06:19,  1.98it/s, lr=1.62e-6, step_loss=0.028]07/27/2023 17:45:03 - INFO - __main__ - train loss is 2.834359715692699\n",
      "Steps:   0%|  | 24/15000 [00:14<2:06:25,  1.97it/s, lr=1.75e-6, step_loss=0.171]07/27/2023 17:45:04 - INFO - __main__ - train loss is 2.858399481512606\n",
      "Steps:   0%|  | 25/15000 [00:14<2:06:09,  1.98it/s, lr=1.88e-6, step_loss=0.024]07/27/2023 17:45:04 - INFO - __main__ - train loss is 2.893649351783097\n",
      "Steps:   0%|    | 26/15000 [00:15<2:05:54,  1.98it/s, lr=2e-6, step_loss=0.0352]07/27/2023 17:45:05 - INFO - __main__ - train loss is 2.97999728936702\n",
      "Steps:   0%| | 27/15000 [00:15<2:05:30,  1.99it/s, lr=2.13e-6, step_loss=0.0863]07/27/2023 17:45:05 - INFO - __main__ - train loss is 3.040041354484856\n",
      "Steps:   0%|   | 28/15000 [00:16<2:05:18,  1.99it/s, lr=2.25e-6, step_loss=0.06]07/27/2023 17:45:06 - INFO - __main__ - train loss is 3.0431236042641103\n",
      "Steps:   0%| | 29/15000 [00:16<2:03:43,  2.02it/s, lr=2.38e-6, step_loss=0.0030807/27/2023 17:45:06 - INFO - __main__ - train loss is 3.0540138888172805\n",
      "Steps:   0%|  | 30/15000 [00:17<2:04:23,  2.01it/s, lr=2.5e-6, step_loss=0.0109]07/27/2023 17:45:07 - INFO - __main__ - train loss is 3.1183381038717926\n",
      "Steps:   0%| | 31/15000 [00:17<2:04:45,  2.00it/s, lr=2.63e-6, step_loss=0.0643]07/27/2023 17:45:07 - INFO - __main__ - train loss is 3.122859111521393\n",
      "Steps:   0%| | 32/15000 [00:18<2:04:52,  2.00it/s, lr=2.75e-6, step_loss=0.0045207/27/2023 17:45:08 - INFO - __main__ - train loss is 3.1250651739537716\n",
      "Steps:   0%| | 33/15000 [00:18<2:04:56,  2.00it/s, lr=2.88e-6, step_loss=0.0022107/27/2023 17:45:08 - INFO - __main__ - train loss is 3.1309228762984276\n",
      "Steps:   0%|   | 34/15000 [00:19<2:04:51,  2.00it/s, lr=3e-6, step_loss=0.00586]07/27/2023 17:45:09 - INFO - __main__ - train loss is 3.2363052368164062\n",
      "Steps:   0%|  | 35/15000 [00:19<2:05:17,  1.99it/s, lr=3.13e-6, step_loss=0.105]07/27/2023 17:45:09 - INFO - __main__ - train loss is 3.6540302336215973\n",
      "Steps:   0%|  | 36/15000 [00:20<2:05:35,  1.99it/s, lr=3.25e-6, step_loss=0.418]07/27/2023 17:45:10 - INFO - __main__ - train loss is 3.9150537252426147\n",
      "Steps:   0%|  | 37/15000 [00:20<2:05:08,  1.99it/s, lr=3.37e-6, step_loss=0.261]07/27/2023 17:45:10 - INFO - __main__ - train loss is 3.9294163612648845\n",
      "Steps:   0%|  | 38/15000 [00:21<2:05:17,  1.99it/s, lr=3.5e-6, step_loss=0.0144]07/27/2023 17:45:11 - INFO - __main__ - train loss is 4.139720338396728\n",
      "Steps:   0%|   | 39/15000 [00:21<2:05:54,  1.98it/s, lr=3.63e-6, step_loss=0.21]07/27/2023 17:45:11 - INFO - __main__ - train loss is 4.318328249268234\n",
      "Steps:   0%|  | 40/15000 [00:22<2:05:50,  1.98it/s, lr=3.75e-6, step_loss=0.179]07/27/2023 17:45:12 - INFO - __main__ - train loss is 4.477274301461875\n",
      "Steps:   0%|  | 41/15000 [00:22<2:05:38,  1.98it/s, lr=3.88e-6, step_loss=0.159]07/27/2023 17:45:12 - INFO - __main__ - train loss is 4.4802563635166734\n",
      "Steps:   0%|   | 42/15000 [00:23<2:05:52,  1.98it/s, lr=4e-6, step_loss=0.00298]07/27/2023 17:45:13 - INFO - __main__ - train loss is 4.505706568947062\n",
      "Steps:   0%| | 43/15000 [00:23<2:05:26,  1.99it/s, lr=4.13e-6, step_loss=0.0255]07/27/2023 17:45:13 - INFO - __main__ - train loss is 4.575711181154475\n",
      "Steps:   0%|   | 44/15000 [00:24<2:06:11,  1.98it/s, lr=4.25e-6, step_loss=0.07]07/27/2023 17:45:14 - INFO - __main__ - train loss is 4.580737394979224\n",
      "Steps:   0%| | 45/15000 [00:24<2:06:17,  1.97it/s, lr=4.38e-6, step_loss=0.0050307/27/2023 17:45:15 - INFO - __main__ - train loss is 4.719977838685736\n",
      "Steps:   0%|   | 46/15000 [00:25<2:06:09,  1.98it/s, lr=4.5e-6, step_loss=0.139]07/27/2023 17:45:15 - INFO - __main__ - train loss is 4.813313020160422\n",
      "Steps:   0%| | 47/15000 [00:25<2:05:43,  1.98it/s, lr=4.62e-6, step_loss=0.0933]07/27/2023 17:45:16 - INFO - __main__ - train loss is 4.9408175626304\n",
      "Steps:   0%|  | 48/15000 [00:26<2:05:46,  1.98it/s, lr=4.75e-6, step_loss=0.128]07/27/2023 17:45:16 - INFO - __main__ - train loss is 5.036134836962447\n",
      "Steps:   0%| | 49/15000 [00:26<2:06:23,  1.97it/s, lr=4.87e-6, step_loss=0.0953]07/27/2023 17:45:17 - INFO - __main__ - train loss is 5.186067400267348\n",
      "Steps:   0%|      | 50/15000 [00:27<2:06:40,  1.97it/s, lr=5e-6, step_loss=0.15]07/27/2023 17:45:17 - INFO - __main__ - train loss is 5.544631896307692\n",
      "Steps:   0%|  | 51/15000 [00:27<2:06:55,  1.96it/s, lr=5.13e-6, step_loss=0.359]07/27/2023 17:45:18 - INFO - __main__ - train loss is 5.552874293876812\n",
      "Steps:   0%| | 52/15000 [00:28<2:06:34,  1.97it/s, lr=5.25e-6, step_loss=0.0082407/27/2023 17:45:18 - INFO - __main__ - train loss is 5.8179988830816\n",
      "Steps:   0%|  | 53/15000 [00:28<2:06:30,  1.97it/s, lr=5.37e-6, step_loss=0.265]07/27/2023 17:45:19 - INFO - __main__ - train loss is 5.82095713284798\n",
      "Steps:   0%| | 54/15000 [00:29<2:06:14,  1.97it/s, lr=5.5e-6, step_loss=0.00296]07/27/2023 17:45:19 - INFO - __main__ - train loss is 5.825512133771554\n",
      "Steps:   0%| | 55/15000 [00:29<2:06:13,  1.97it/s, lr=5.62e-6, step_loss=0.0045607/27/2023 17:45:20 - INFO - __main__ - train loss is 6.295290671521798\n",
      "Steps:   0%|   | 56/15000 [00:30<2:06:03,  1.98it/s, lr=5.75e-6, step_loss=0.47]07/27/2023 17:45:20 - INFO - __main__ - train loss is 6.342649519676343\n",
      "Steps:   0%| | 57/15000 [00:30<2:05:49,  1.98it/s, lr=5.88e-6, step_loss=0.0474]07/27/2023 17:45:21 - INFO - __main__ - train loss is 6.408055514330044\n",
      "Steps:   0%|    | 58/15000 [00:31<2:06:02,  1.98it/s, lr=6e-6, step_loss=0.0654]07/27/2023 17:45:21 - INFO - __main__ - train loss is 7.095594078535214\n",
      "Steps:   0%|  | 59/15000 [00:31<2:05:34,  1.98it/s, lr=6.13e-6, step_loss=0.688]07/27/2023 17:45:22 - INFO - __main__ - train loss is 7.098257569829002\n",
      "Steps:   0%| | 60/15000 [00:32<2:05:04,  1.99it/s, lr=6.25e-6, step_loss=0.0026607/27/2023 17:45:22 - INFO - __main__ - train loss is 7.364266632357612\n",
      "Steps:   0%|  | 61/15000 [00:32<2:04:49,  1.99it/s, lr=6.37e-6, step_loss=0.266]07/27/2023 17:45:23 - INFO - __main__ - train loss is 7.375951413298026\n",
      "Steps:   0%|  | 62/15000 [00:33<2:04:58,  1.99it/s, lr=6.5e-6, step_loss=0.0117]07/27/2023 17:45:23 - INFO - __main__ - train loss is 7.661728207254782\n",
      "Steps:   0%|  | 63/15000 [00:33<2:05:00,  1.99it/s, lr=6.63e-6, step_loss=0.286]07/27/2023 17:45:24 - INFO - __main__ - train loss is 8.248357836389914\n",
      "Steps:   0%|  | 64/15000 [00:34<2:04:49,  1.99it/s, lr=6.75e-6, step_loss=0.587]07/27/2023 17:45:24 - INFO - __main__ - train loss is 8.254675379255787\n",
      "Steps:   0%| | 65/15000 [00:34<2:05:41,  1.98it/s, lr=6.88e-6, step_loss=0.0063207/27/2023 17:45:25 - INFO - __main__ - train loss is 8.959358563879505\n",
      "Steps:   0%|     | 66/15000 [00:35<2:05:24,  1.98it/s, lr=7e-6, step_loss=0.705]07/27/2023 17:45:25 - INFO - __main__ - train loss is 8.968320484505966\n",
      "Steps:   0%| | 67/15000 [00:35<2:05:13,  1.99it/s, lr=7.13e-6, step_loss=0.0089607/27/2023 17:45:26 - INFO - __main__ - train loss is 8.991385977016762\n",
      "Steps:   0%| | 68/15000 [00:36<2:05:05,  1.99it/s, lr=7.25e-6, step_loss=0.0231]07/27/2023 17:45:26 - INFO - __main__ - train loss is 9.002173622371629\n",
      "Steps:   0%| | 69/15000 [00:36<2:05:12,  1.99it/s, lr=7.37e-6, step_loss=0.0108]07/27/2023 17:45:27 - INFO - __main__ - train loss is 9.26747449231334\n",
      "Steps:   0%|   | 70/15000 [00:37<2:04:47,  1.99it/s, lr=7.5e-6, step_loss=0.265]07/27/2023 17:45:27 - INFO - __main__ - train loss is 9.56093477201648\n",
      "Steps:   0%|  | 71/15000 [00:37<2:04:41,  2.00it/s, lr=7.62e-6, step_loss=0.293]07/27/2023 17:45:28 - INFO - __main__ - train loss is 9.568022828781977\n",
      "Steps:   0%| | 72/15000 [00:38<2:04:48,  1.99it/s, lr=7.75e-6, step_loss=0.0070907/27/2023 17:45:28 - INFO - __main__ - train loss is 9.575033069821075\n",
      "Steps:   0%| | 73/15000 [00:38<2:04:56,  1.99it/s, lr=7.87e-6, step_loss=0.0070107/27/2023 17:45:29 - INFO - __main__ - train loss is 9.579621821874753\n",
      "Steps:   0%|   | 74/15000 [00:39<2:05:04,  1.99it/s, lr=8e-6, step_loss=0.00459]07/27/2023 17:45:29 - INFO - __main__ - train loss is 9.614530533785\n",
      "Steps:   0%| | 75/15000 [00:39<2:05:08,  1.99it/s, lr=8.13e-6, step_loss=0.0349]07/27/2023 17:45:30 - INFO - __main__ - train loss is 9.620190488407388\n",
      "Steps:   1%| | 76/15000 [00:40<2:05:12,  1.99it/s, lr=8.25e-6, step_loss=0.0056607/27/2023 17:45:30 - INFO - __main__ - train loss is 9.819719853112474\n",
      "Steps:   1%|    | 77/15000 [00:40<2:05:14,  1.99it/s, lr=8.38e-6, step_loss=0.2]07/27/2023 17:45:31 - INFO - __main__ - train loss is 10.101510407635942\n",
      "Steps:   1%|   | 78/15000 [00:41<2:04:57,  1.99it/s, lr=8.5e-6, step_loss=0.282]07/27/2023 17:45:31 - INFO - __main__ - train loss is 10.316262604901567\n",
      "Steps:   1%|  | 79/15000 [00:41<2:04:55,  1.99it/s, lr=8.63e-6, step_loss=0.215]07/27/2023 17:45:32 - INFO - __main__ - train loss is 10.360920747974887\n",
      "Steps:   1%| | 80/15000 [00:42<2:04:21,  2.00it/s, lr=8.75e-6, step_loss=0.0447]07/27/2023 17:45:32 - INFO - __main__ - train loss is 10.615496060112491\n",
      "Steps:   1%|  | 81/15000 [00:42<2:04:24,  2.00it/s, lr=8.87e-6, step_loss=0.255]07/27/2023 17:45:33 - INFO - __main__ - train loss is 10.706055796006694\n",
      "Steps:   1%|    | 82/15000 [00:43<2:05:43,  1.98it/s, lr=9e-6, step_loss=0.0906]07/27/2023 17:45:33 - INFO - __main__ - train loss is 11.123437499860302\n",
      "Steps:   1%|  | 83/15000 [00:43<2:05:21,  1.98it/s, lr=9.12e-6, step_loss=0.417]07/27/2023 17:45:34 - INFO - __main__ - train loss is 11.134442006470636\n",
      "Steps:   1%|  | 84/15000 [00:44<2:05:11,  1.99it/s, lr=9.25e-6, step_loss=0.011]07/27/2023 17:45:34 - INFO - __main__ - train loss is 11.396622692467645\n",
      "Steps:   1%|  | 85/15000 [00:44<2:05:03,  1.99it/s, lr=9.37e-6, step_loss=0.262]07/27/2023 17:45:35 - INFO - __main__ - train loss is 11.425945264520124\n",
      "Steps:   1%|  | 86/15000 [00:45<2:04:31,  2.00it/s, lr=9.5e-6, step_loss=0.0293]07/27/2023 17:45:35 - INFO - __main__ - train loss is 11.496433777036145\n",
      "Steps:   1%| | 87/15000 [00:45<2:04:24,  2.00it/s, lr=9.63e-6, step_loss=0.0705]07/27/2023 17:45:36 - INFO - __main__ - train loss is 11.66012699645944\n",
      "[2023-07-27 17:45:36,232] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:   1%|  | 88/15000 [00:46<2:04:02,  2.00it/s, lr=9.63e-6, step_loss=0.164]07/27/2023 17:45:36 - INFO - __main__ - train loss is 11.830717724980786\n",
      "Steps:   1%|  | 89/15000 [00:46<2:03:55,  2.01it/s, lr=9.75e-6, step_loss=0.171]07/27/2023 17:45:37 - INFO - __main__ - train loss is 11.851855074288324\n",
      "Steps:   1%| | 90/15000 [00:47<2:04:42,  1.99it/s, lr=9.87e-6, step_loss=0.0211]07/27/2023 17:45:37 - INFO - __main__ - train loss is 12.033542012097314\n",
      "Steps:   1%|     | 91/15000 [00:47<2:04:29,  2.00it/s, lr=1e-5, step_loss=0.182]07/27/2023 17:45:38 - INFO - __main__ - train loss is 12.174963121535257\n",
      "Steps:   1%|  | 92/15000 [00:48<2:04:27,  2.00it/s, lr=1.01e-5, step_loss=0.141]07/27/2023 17:45:38 - INFO - __main__ - train loss is 12.24214040231891\n",
      "Steps:   1%| | 93/15000 [00:48<2:04:32,  1.99it/s, lr=1.03e-5, step_loss=0.0672]07/27/2023 17:45:39 - INFO - __main__ - train loss is 12.31708507728763\n",
      "Steps:   1%| | 94/15000 [00:49<2:04:41,  1.99it/s, lr=1.04e-5, step_loss=0.0749]07/27/2023 17:45:39 - INFO - __main__ - train loss is 12.744983633281663\n",
      "Steps:   1%|  | 95/15000 [00:49<2:04:50,  1.99it/s, lr=1.05e-5, step_loss=0.428]07/27/2023 17:45:40 - INFO - __main__ - train loss is 13.245948751689866\n",
      "Steps:   1%|  | 96/15000 [00:50<2:05:21,  1.98it/s, lr=1.06e-5, step_loss=0.501]07/27/2023 17:45:40 - INFO - __main__ - train loss is 13.612667163135484\n",
      "Steps:   1%|  | 97/15000 [00:50<2:05:12,  1.98it/s, lr=1.07e-5, step_loss=0.367]07/27/2023 17:45:41 - INFO - __main__ - train loss is 13.708542880835012\n",
      "Steps:   1%| | 98/15000 [00:51<2:05:44,  1.98it/s, lr=1.09e-5, step_loss=0.0959]07/27/2023 17:45:41 - INFO - __main__ - train loss is 13.92413812619634\n",
      "Steps:   1%|   | 99/15000 [00:51<2:05:31,  1.98it/s, lr=1.1e-5, step_loss=0.216]07/27/2023 17:45:42 - INFO - __main__ - train loss is 13.92566001880914\n",
      "Steps:   1%| | 100/15000 [00:52<2:06:06,  1.97it/s, lr=1.11e-5, step_loss=0.001507/27/2023 17:45:42 - INFO - __main__ - train loss is 13.986631681211293\n",
      "Steps:   1%| | 101/15000 [00:53<2:05:53,  1.97it/s, lr=1.12e-5, step_loss=0.061]07/27/2023 17:45:43 - INFO - __main__ - train loss is 14.018077311106026\n",
      "Steps:   1%| | 102/15000 [00:53<2:05:44,  1.97it/s, lr=1.14e-5, step_loss=0.031407/27/2023 17:45:43 - INFO - __main__ - train loss is 14.182287839241326\n",
      "Steps:   1%| | 103/15000 [00:54<2:05:31,  1.98it/s, lr=1.15e-5, step_loss=0.164]07/27/2023 17:45:44 - INFO - __main__ - train loss is 14.184632233576849\n",
      "Steps:   1%| | 104/15000 [00:54<2:04:59,  1.99it/s, lr=1.16e-5, step_loss=0.002307/27/2023 17:45:44 - INFO - __main__ - train loss is 14.58381640096195\n",
      "Steps:   1%| | 105/15000 [00:55<2:04:57,  1.99it/s, lr=1.18e-5, step_loss=0.399]07/27/2023 17:45:45 - INFO - __main__ - train loss is 14.590936401626095\n",
      "Steps:   1%| | 106/15000 [00:55<2:05:30,  1.98it/s, lr=1.19e-5, step_loss=0.007107/27/2023 17:45:45 - INFO - __main__ - train loss is 15.029929438373074\n",
      "Steps:   1%|  | 107/15000 [00:56<2:05:24,  1.98it/s, lr=1.2e-5, step_loss=0.439]07/27/2023 17:45:46 - INFO - __main__ - train loss is 15.032977105118334\n",
      "Steps:   1%| | 108/15000 [00:56<2:05:33,  1.98it/s, lr=1.21e-5, step_loss=0.003007/27/2023 17:45:46 - INFO - __main__ - train loss is 15.035232219612226\n",
      "Steps:   1%| | 109/15000 [00:57<2:05:33,  1.98it/s, lr=1.23e-5, step_loss=0.002207/27/2023 17:45:47 - INFO - __main__ - train loss is 15.833018038189039\n",
      "Steps:   1%| | 110/15000 [00:57<2:05:16,  1.98it/s, lr=1.24e-5, step_loss=0.798]07/27/2023 17:45:47 - INFO - __main__ - train loss is 15.835889376699924\n",
      "Steps:   1%| | 111/15000 [00:58<2:05:21,  1.98it/s, lr=1.25e-5, step_loss=0.002807/27/2023 17:45:48 - INFO - __main__ - train loss is 15.852061688899994\n",
      "Steps:   1%| | 112/15000 [00:58<2:05:40,  1.97it/s, lr=1.26e-5, step_loss=0.016207/27/2023 17:45:48 - INFO - __main__ - train loss is 16.390778720378876\n",
      "Steps:   1%| | 113/15000 [00:59<2:06:36,  1.96it/s, lr=1.27e-5, step_loss=0.539]07/27/2023 17:45:49 - INFO - __main__ - train loss is 16.57990153133869\n",
      "Steps:   1%| | 114/15000 [00:59<2:06:34,  1.96it/s, lr=1.29e-5, step_loss=0.189]07/27/2023 17:45:49 - INFO - __main__ - train loss is 17.209923520684242\n",
      "Steps:   1%|   | 115/15000 [01:00<2:06:44,  1.96it/s, lr=1.3e-5, step_loss=0.63]07/27/2023 17:45:50 - INFO - __main__ - train loss is 17.35661579668522\n",
      "Steps:   1%| | 116/15000 [01:00<2:06:06,  1.97it/s, lr=1.31e-5, step_loss=0.147]07/27/2023 17:45:50 - INFO - __main__ - train loss is 17.68082620203495\n",
      "Steps:   1%| | 117/15000 [01:01<2:05:37,  1.97it/s, lr=1.33e-5, step_loss=0.324]07/27/2023 17:45:51 - INFO - __main__ - train loss is 17.977518543601036\n",
      "Steps:   1%| | 118/15000 [01:01<2:05:12,  1.98it/s, lr=1.34e-5, step_loss=0.297]07/27/2023 17:45:51 - INFO - __main__ - train loss is 18.171145901083946\n",
      "Steps:   1%| | 119/15000 [01:02<2:04:39,  1.99it/s, lr=1.35e-5, step_loss=0.194]07/27/2023 17:45:52 - INFO - __main__ - train loss is 18.201083410531282\n",
      "Steps:   1%| | 120/15000 [01:02<2:04:45,  1.99it/s, lr=1.36e-5, step_loss=0.029907/27/2023 17:45:52 - INFO - __main__ - train loss is 18.229823483154178\n",
      "Steps:   1%| | 121/15000 [01:03<2:05:14,  1.98it/s, lr=1.38e-5, step_loss=0.028707/27/2023 17:45:53 - INFO - __main__ - train loss is 18.573136223480105\n",
      "Steps:   1%| | 122/15000 [01:03<2:05:29,  1.98it/s, lr=1.39e-5, step_loss=0.343]07/27/2023 17:45:53 - INFO - __main__ - train loss is 18.6923152115196\n",
      "Steps:   1%|  | 123/15000 [01:04<2:05:27,  1.98it/s, lr=1.4e-5, step_loss=0.119]07/27/2023 17:45:54 - INFO - __main__ - train loss is 19.280472030863166\n",
      "Steps:   1%| | 124/15000 [01:04<2:05:09,  1.98it/s, lr=1.41e-5, step_loss=0.588]07/27/2023 17:45:54 - INFO - __main__ - train loss is 19.369737459346652\n",
      "Steps:   1%| | 125/15000 [01:05<2:05:18,  1.98it/s, lr=1.43e-5, step_loss=0.089307/27/2023 17:45:55 - INFO - __main__ - train loss is 19.37401487585157\n",
      "Steps:   1%| | 126/15000 [01:05<2:05:03,  1.98it/s, lr=1.44e-5, step_loss=0.004207/27/2023 17:45:55 - INFO - __main__ - train loss is 19.39396587293595\n",
      "Steps:   1%|  | 127/15000 [01:06<2:04:38,  1.99it/s, lr=1.45e-5, step_loss=0.02]07/27/2023 17:45:56 - INFO - __main__ - train loss is 19.985932919196784\n",
      "Steps:   1%| | 128/15000 [01:06<2:04:33,  1.99it/s, lr=1.46e-5, step_loss=0.592]07/27/2023 17:45:56 - INFO - __main__ - train loss is 20.25866541545838\n",
      "Steps:   1%| | 129/15000 [01:07<2:04:55,  1.98it/s, lr=1.47e-5, step_loss=0.273]07/27/2023 17:45:57 - INFO - __main__ - train loss is 20.2868007523939\n",
      "Steps:   1%| | 130/15000 [01:07<2:05:03,  1.98it/s, lr=1.49e-5, step_loss=0.028107/27/2023 17:45:57 - INFO - __main__ - train loss is 20.298064389266074\n",
      "Steps:   1%| | 131/15000 [01:08<2:05:04,  1.98it/s, lr=1.5e-5, step_loss=0.0113]07/27/2023 17:45:58 - INFO - __main__ - train loss is 20.66004262212664\n",
      "Steps:   1%| | 132/15000 [01:08<2:04:53,  1.98it/s, lr=1.51e-5, step_loss=0.362]07/27/2023 17:45:58 - INFO - __main__ - train loss is 20.86047422233969\n",
      "Steps:   1%|   | 133/15000 [01:09<2:04:52,  1.98it/s, lr=1.52e-5, step_loss=0.2]07/27/2023 17:45:59 - INFO - __main__ - train loss is 20.870913648046553\n",
      "Steps:   1%| | 134/15000 [01:09<2:04:44,  1.99it/s, lr=1.54e-5, step_loss=0.010407/27/2023 17:45:59 - INFO - __main__ - train loss is 20.927649156190455\n",
      "Steps:   1%| | 135/15000 [01:10<2:04:42,  1.99it/s, lr=1.55e-5, step_loss=0.056707/27/2023 17:46:00 - INFO - __main__ - train loss is 20.971278683282435\n",
      "Steps:   1%| | 136/15000 [01:10<2:04:43,  1.99it/s, lr=1.56e-5, step_loss=0.043607/27/2023 17:46:00 - INFO - __main__ - train loss is 21.012961314059794\n",
      "Steps:   1%| | 137/15000 [01:11<2:04:44,  1.99it/s, lr=1.57e-5, step_loss=0.041707/27/2023 17:46:01 - INFO - __main__ - train loss is 21.046476387418807\n",
      "Steps:   1%| | 138/15000 [01:11<2:04:27,  1.99it/s, lr=1.59e-5, step_loss=0.033507/27/2023 17:46:01 - INFO - __main__ - train loss is 21.888456844724715\n",
      "Steps:   1%|  | 139/15000 [01:12<2:04:20,  1.99it/s, lr=1.6e-5, step_loss=0.842]07/27/2023 17:46:02 - INFO - __main__ - train loss is 22.04244310501963\n",
      "Steps:   1%| | 140/15000 [01:12<2:04:27,  1.99it/s, lr=1.61e-5, step_loss=0.154]07/27/2023 17:46:02 - INFO - __main__ - train loss is 22.158367195166647\n",
      "Steps:   1%| | 141/15000 [01:13<2:05:04,  1.98it/s, lr=1.63e-5, step_loss=0.116]07/27/2023 17:46:03 - INFO - __main__ - train loss is 22.185299639590085\n",
      "Steps:   1%| | 142/15000 [01:13<2:03:15,  2.01it/s, lr=1.64e-5, step_loss=0.026907/27/2023 17:46:03 - INFO - __main__ - train loss is 22.234440964646637\n",
      "Steps:   1%| | 143/15000 [01:14<2:03:47,  2.00it/s, lr=1.65e-5, step_loss=0.049107/27/2023 17:46:04 - INFO - __main__ - train loss is 22.239412304013968\n",
      "Steps:   1%| | 144/15000 [01:14<2:03:40,  2.00it/s, lr=1.66e-5, step_loss=0.004907/27/2023 17:46:04 - INFO - __main__ - train loss is 22.563267078250647\n",
      "Steps:   1%| | 145/15000 [01:15<2:04:31,  1.99it/s, lr=1.68e-5, step_loss=0.324]07/27/2023 17:46:05 - INFO - __main__ - train loss is 22.577166739851236\n",
      "Steps:   1%| | 146/15000 [01:15<2:05:49,  1.97it/s, lr=1.69e-5, step_loss=0.013907/27/2023 17:46:05 - INFO - __main__ - train loss is 22.661891136318445\n",
      "Steps:   1%| | 147/15000 [01:16<2:06:04,  1.96it/s, lr=1.7e-5, step_loss=0.0847]07/27/2023 17:46:06 - INFO - __main__ - train loss is 22.66347695188597\n",
      "Steps:   1%| | 148/15000 [01:16<2:06:23,  1.96it/s, lr=1.71e-5, step_loss=0.001507/27/2023 17:46:06 - INFO - __main__ - train loss is 22.957905777264386\n",
      "Steps:   1%| | 149/15000 [01:17<2:06:04,  1.96it/s, lr=1.73e-5, step_loss=0.294]07/27/2023 17:46:07 - INFO - __main__ - train loss is 23.15709049301222\n",
      "Steps:   1%| | 150/15000 [01:17<2:06:21,  1.96it/s, lr=1.74e-5, step_loss=0.199]07/27/2023 17:46:07 - INFO - __main__ - train loss is 23.177092450205237\n",
      "Steps:   1%|  | 151/15000 [01:18<2:05:45,  1.97it/s, lr=1.75e-5, step_loss=0.02]07/27/2023 17:46:08 - INFO - __main__ - train loss is 23.180701220873743\n",
      "Steps:   1%| | 152/15000 [01:18<2:05:36,  1.97it/s, lr=1.76e-5, step_loss=0.003607/27/2023 17:46:08 - INFO - __main__ - train loss is 23.289262200240046\n",
      "Steps:   1%| | 153/15000 [01:19<2:05:10,  1.98it/s, lr=1.77e-5, step_loss=0.109]07/27/2023 17:46:09 - INFO - __main__ - train loss is 23.2923203734681\n",
      "Steps:   1%| | 154/15000 [01:19<2:05:16,  1.98it/s, lr=1.79e-5, step_loss=0.003007/27/2023 17:46:10 - INFO - __main__ - train loss is 23.30471838451922\n",
      "Steps:   1%| | 155/15000 [01:20<2:08:55,  1.92it/s, lr=1.8e-5, step_loss=0.0124]07/27/2023 17:46:10 - INFO - __main__ - train loss is 23.306340957293287\n",
      "Steps:   1%| | 156/15000 [01:20<2:09:44,  1.91it/s, lr=1.81e-5, step_loss=0.001607/27/2023 17:46:11 - INFO - __main__ - train loss is 23.50247740210034\n",
      "Steps:   1%| | 157/15000 [01:21<2:09:15,  1.91it/s, lr=1.82e-5, step_loss=0.196]07/27/2023 17:46:11 - INFO - __main__ - train loss is 23.532479645917192\n",
      "Steps:   1%|  | 158/15000 [01:21<2:07:50,  1.93it/s, lr=1.84e-5, step_loss=0.03]07/27/2023 17:46:12 - INFO - __main__ - train loss is 23.534498849185184\n",
      "Steps:   1%| | 159/15000 [01:22<2:07:03,  1.95it/s, lr=1.85e-5, step_loss=0.002007/27/2023 17:46:12 - INFO - __main__ - train loss is 23.608500973554328\n",
      "Steps:   1%| | 160/15000 [01:22<2:06:04,  1.96it/s, lr=1.86e-5, step_loss=0.074]07/27/2023 17:46:13 - INFO - __main__ - train loss is 23.618614747421816\n",
      "Steps:   1%| | 161/15000 [01:23<2:05:21,  1.97it/s, lr=1.87e-5, step_loss=0.010107/27/2023 17:46:13 - INFO - __main__ - train loss is 23.786506726639345\n",
      "Steps:   1%| | 162/15000 [01:23<2:04:48,  1.98it/s, lr=1.89e-5, step_loss=0.168]07/27/2023 17:46:14 - INFO - __main__ - train loss is 24.0370950542856\n",
      "Steps:   1%|  | 163/15000 [01:24<2:04:34,  1.99it/s, lr=1.9e-5, step_loss=0.251]07/27/2023 17:46:14 - INFO - __main__ - train loss is 24.283990665571764\n",
      "Steps:   1%| | 164/15000 [01:24<2:04:38,  1.98it/s, lr=1.91e-5, step_loss=0.247]07/27/2023 17:46:15 - INFO - __main__ - train loss is 24.28746672393754\n",
      "Steps:   1%| | 165/15000 [01:25<2:08:50,  1.92it/s, lr=1.93e-5, step_loss=0.003407/27/2023 17:46:15 - INFO - __main__ - train loss is 24.29260431556031\n",
      "Steps:   1%| | 166/15000 [01:25<2:07:50,  1.93it/s, lr=1.94e-5, step_loss=0.005107/27/2023 17:46:16 - INFO - __main__ - train loss is 24.308503206353635\n",
      "Steps:   1%| | 167/15000 [01:26<2:06:49,  1.95it/s, lr=1.95e-5, step_loss=0.015907/27/2023 17:46:16 - INFO - __main__ - train loss is 24.499482985120267\n",
      "Steps:   1%| | 168/15000 [01:26<2:05:58,  1.96it/s, lr=1.96e-5, step_loss=0.191]07/27/2023 17:46:17 - INFO - __main__ - train loss is 24.895484145265073\n",
      "Steps:   1%| | 169/15000 [01:27<2:05:24,  1.97it/s, lr=1.97e-5, step_loss=0.396]07/27/2023 17:46:17 - INFO - __main__ - train loss is 25.09542730031535\n",
      "Steps:   1%|   | 170/15000 [01:27<2:05:28,  1.97it/s, lr=1.99e-5, step_loss=0.2]07/27/2023 17:46:18 - INFO - __main__ - train loss is 25.228901545982808\n",
      "Steps:   1%|    | 171/15000 [01:28<2:05:11,  1.97it/s, lr=2e-5, step_loss=0.133]07/27/2023 17:46:18 - INFO - __main__ - train loss is 25.49545494792983\n",
      "Steps:   1%| | 172/15000 [01:29<2:05:03,  1.98it/s, lr=2.01e-5, step_loss=0.267]07/27/2023 17:46:19 - INFO - __main__ - train loss is 25.651286478620023\n",
      "Steps:   1%| | 173/15000 [01:29<2:05:02,  1.98it/s, lr=2.03e-5, step_loss=0.156]07/27/2023 17:46:19 - INFO - __main__ - train loss is 25.966585035901517\n",
      "Steps:   1%| | 174/15000 [01:30<2:05:34,  1.97it/s, lr=2.04e-5, step_loss=0.315]07/27/2023 17:46:20 - INFO - __main__ - train loss is 26.16343953786418\n",
      "Steps:   1%| | 175/15000 [01:30<2:07:17,  1.94it/s, lr=2.05e-5, step_loss=0.197]07/27/2023 17:46:20 - INFO - __main__ - train loss is 26.35185034153983\n",
      "Steps:   1%| | 176/15000 [01:31<2:07:25,  1.94it/s, lr=2.06e-5, step_loss=0.188]07/27/2023 17:46:21 - INFO - __main__ - train loss is 26.57244450924918\n",
      "Steps:   1%| | 177/15000 [01:31<2:06:37,  1.95it/s, lr=2.08e-5, step_loss=0.221]07/27/2023 17:46:21 - INFO - __main__ - train loss is 26.723023142199963\n",
      "Steps:   1%| | 178/15000 [01:32<2:06:01,  1.96it/s, lr=2.09e-5, step_loss=0.151]07/27/2023 17:46:22 - INFO - __main__ - train loss is 26.73835773440078\n",
      "Steps:   1%| | 179/15000 [01:32<2:05:28,  1.97it/s, lr=2.1e-5, step_loss=0.0153]07/27/2023 17:46:22 - INFO - __main__ - train loss is 26.740371628431603\n",
      "Steps:   1%| | 180/15000 [01:33<2:05:03,  1.98it/s, lr=2.11e-5, step_loss=0.002007/27/2023 17:46:23 - INFO - __main__ - train loss is 26.74267305713147\n",
      "Steps:   1%| | 181/15000 [01:33<2:04:55,  1.98it/s, lr=2.13e-5, step_loss=0.002307/27/2023 17:46:23 - INFO - __main__ - train loss is 26.75927774515003\n",
      "Steps:   1%| | 182/15000 [01:34<2:04:45,  1.98it/s, lr=2.14e-5, step_loss=0.016607/27/2023 17:46:24 - INFO - __main__ - train loss is 26.82670450117439\n",
      "Steps:   1%| | 183/15000 [01:34<2:04:27,  1.98it/s, lr=2.15e-5, step_loss=0.067407/27/2023 17:46:24 - INFO - __main__ - train loss is 27.084343194030225\n",
      "Steps:   1%| | 184/15000 [01:35<2:05:39,  1.97it/s, lr=2.16e-5, step_loss=0.258]07/27/2023 17:46:25 - INFO - __main__ - train loss is 27.100025366060436\n",
      "Steps:   1%| | 185/15000 [01:35<2:06:25,  1.95it/s, lr=2.18e-5, step_loss=0.015707/27/2023 17:46:25 - INFO - __main__ - train loss is 27.262310246936977\n",
      "Steps:   1%| | 186/15000 [01:36<2:06:44,  1.95it/s, lr=2.19e-5, step_loss=0.162]07/27/2023 17:46:26 - INFO - __main__ - train loss is 27.63084066938609\n",
      "Steps:   1%|  | 187/15000 [01:36<2:06:29,  1.95it/s, lr=2.2e-5, step_loss=0.369]07/27/2023 17:46:26 - INFO - __main__ - train loss is 27.635034289211035\n",
      "Steps:   1%| | 188/15000 [01:37<2:06:14,  1.96it/s, lr=2.21e-5, step_loss=0.004107/27/2023 17:46:27 - INFO - __main__ - train loss is 27.690975811332464\n",
      "Steps:   1%| | 189/15000 [01:37<2:06:23,  1.95it/s, lr=2.22e-5, step_loss=0.055907/27/2023 17:46:27 - INFO - __main__ - train loss is 27.78460330143571\n",
      "Steps:   1%| | 190/15000 [01:38<2:05:43,  1.96it/s, lr=2.24e-5, step_loss=0.093607/27/2023 17:46:28 - INFO - __main__ - train loss is 27.825327917933464\n",
      "Steps:   1%| | 191/15000 [01:38<2:05:24,  1.97it/s, lr=2.25e-5, step_loss=0.040707/27/2023 17:46:28 - INFO - __main__ - train loss is 27.858086310327053\n",
      "Steps:   1%| | 192/15000 [01:39<2:04:56,  1.98it/s, lr=2.26e-5, step_loss=0.032807/27/2023 17:46:29 - INFO - __main__ - train loss is 28.09154588729143\n",
      "Steps:   1%| | 193/15000 [01:39<2:04:45,  1.98it/s, lr=2.28e-5, step_loss=0.233]07/27/2023 17:46:29 - INFO - __main__ - train loss is 28.112178169190884\n",
      "Steps:   1%| | 194/15000 [01:40<2:04:34,  1.98it/s, lr=2.29e-5, step_loss=0.020607/27/2023 17:46:30 - INFO - __main__ - train loss is 28.13066628947854\n",
      "Steps:   1%| | 195/15000 [01:40<2:04:23,  1.98it/s, lr=2.3e-5, step_loss=0.0185]07/27/2023 17:46:30 - INFO - __main__ - train loss is 28.427226100116968\n",
      "Steps:   1%| | 196/15000 [01:41<2:05:09,  1.97it/s, lr=2.31e-5, step_loss=0.297]07/27/2023 17:46:31 - INFO - __main__ - train loss is 28.4635506644845\n",
      "Steps:   1%| | 197/15000 [01:41<2:05:30,  1.97it/s, lr=2.32e-5, step_loss=0.036307/27/2023 17:46:31 - INFO - __main__ - train loss is 28.54812351614237\n",
      "Steps:   1%| | 198/15000 [01:42<2:05:36,  1.96it/s, lr=2.34e-5, step_loss=0.084607/27/2023 17:46:32 - INFO - __main__ - train loss is 28.599113076925278\n",
      "Steps:   1%| | 199/15000 [01:42<2:06:16,  1.95it/s, lr=2.35e-5, step_loss=0.051]07/27/2023 17:46:32 - INFO - __main__ - train loss is 28.905957609415054\n",
      "Steps:   1%| | 200/15000 [01:43<2:05:37,  1.96it/s, lr=2.36e-5, step_loss=0.307]07/27/2023 17:46:33 - INFO - __main__ - train loss is 29.08172255754471\n",
      "Steps:   1%| | 201/15000 [01:43<2:05:17,  1.97it/s, lr=2.38e-5, step_loss=0.176]07/27/2023 17:46:33 - INFO - __main__ - train loss is 29.110783271491528\n",
      "Steps:   1%| | 202/15000 [01:44<2:05:25,  1.97it/s, lr=2.39e-5, step_loss=0.029107/27/2023 17:46:34 - INFO - __main__ - train loss is 29.251318730413914\n",
      "Steps:   1%|  | 203/15000 [01:44<2:06:07,  1.96it/s, lr=2.4e-5, step_loss=0.141]07/27/2023 17:46:34 - INFO - __main__ - train loss is 29.578461326658726\n",
      "Steps:   1%| | 204/15000 [01:45<2:05:50,  1.96it/s, lr=2.41e-5, step_loss=0.327]07/27/2023 17:46:35 - INFO - __main__ - train loss is 30.280652798712254\n",
      "Steps:   1%| | 205/15000 [01:45<2:05:57,  1.96it/s, lr=2.42e-5, step_loss=0.702]07/27/2023 17:46:36 - INFO - __main__ - train loss is 30.481429733335972\n",
      "Steps:   1%| | 206/15000 [01:46<2:06:17,  1.95it/s, lr=2.44e-5, step_loss=0.201]07/27/2023 17:46:36 - INFO - __main__ - train loss is 30.490126429125667\n",
      "Steps:   1%| | 207/15000 [01:46<2:05:40,  1.96it/s, lr=2.45e-5, step_loss=0.008707/27/2023 17:46:37 - INFO - __main__ - train loss is 30.614989718422294\n",
      "Steps:   1%| | 208/15000 [01:47<2:06:56,  1.94it/s, lr=2.46e-5, step_loss=0.125]07/27/2023 17:46:37 - INFO - __main__ - train loss is 30.787346055731177\n",
      "Steps:   1%| | 209/15000 [01:47<2:07:24,  1.93it/s, lr=2.48e-5, step_loss=0.172]07/27/2023 17:46:38 - INFO - __main__ - train loss is 30.862637093290687\n",
      "Steps:   1%| | 210/15000 [01:48<2:06:53,  1.94it/s, lr=2.49e-5, step_loss=0.075307/27/2023 17:46:38 - INFO - __main__ - train loss is 30.865795105230063\n",
      "Steps:   1%| | 211/15000 [01:48<2:07:00,  1.94it/s, lr=2.5e-5, step_loss=0.0031607/27/2023 17:46:39 - INFO - __main__ - train loss is 31.619160800706595\n",
      "Steps:   1%| | 212/15000 [01:49<2:06:49,  1.94it/s, lr=2.51e-5, step_loss=0.753]07/27/2023 17:46:39 - INFO - __main__ - train loss is 31.995190292131156\n",
      "Steps:   1%| | 213/15000 [01:49<2:05:57,  1.96it/s, lr=2.53e-5, step_loss=0.376]07/27/2023 17:46:40 - INFO - __main__ - train loss is 31.997094641206786\n",
      "Steps:   1%| | 214/15000 [01:50<2:05:13,  1.97it/s, lr=2.54e-5, step_loss=0.001907/27/2023 17:46:40 - INFO - __main__ - train loss is 32.048305387375876\n",
      "Steps:   1%| | 215/15000 [01:50<2:04:54,  1.97it/s, lr=2.55e-5, step_loss=0.051207/27/2023 17:46:41 - INFO - __main__ - train loss is 32.16483561205678\n",
      "Steps:   1%| | 216/15000 [01:51<2:04:23,  1.98it/s, lr=2.56e-5, step_loss=0.117]07/27/2023 17:46:41 - INFO - __main__ - train loss is 32.274119580863044\n",
      "Steps:   1%| | 217/15000 [01:51<2:04:40,  1.98it/s, lr=2.57e-5, step_loss=0.109]07/27/2023 17:46:42 - INFO - __main__ - train loss is 32.327791849849746\n",
      "Steps:   1%| | 218/15000 [01:52<2:05:03,  1.97it/s, lr=2.59e-5, step_loss=0.053707/27/2023 17:46:42 - INFO - __main__ - train loss is 32.41507280874066\n",
      "Steps:   1%| | 219/15000 [01:52<2:05:04,  1.97it/s, lr=2.6e-5, step_loss=0.0873]07/27/2023 17:46:43 - INFO - __main__ - train loss is 32.42850451800041\n",
      "Steps:   1%| | 220/15000 [01:53<2:08:03,  1.92it/s, lr=2.61e-5, step_loss=0.013407/27/2023 17:46:43 - INFO - __main__ - train loss is 32.49707548948936\n",
      "Steps:   1%| | 221/15000 [01:54<2:07:16,  1.94it/s, lr=2.63e-5, step_loss=0.068607/27/2023 17:46:44 - INFO - __main__ - train loss is 32.89663471910171\n",
      "Steps:   1%|   | 222/15000 [01:54<2:06:08,  1.95it/s, lr=2.64e-5, step_loss=0.4]07/27/2023 17:46:44 - INFO - __main__ - train loss is 32.89869976625778\n",
      "Steps:   1%| | 223/15000 [01:55<2:05:50,  1.96it/s, lr=2.65e-5, step_loss=0.002007/27/2023 17:46:45 - INFO - __main__ - train loss is 33.01812774525024\n",
      "Steps:   1%| | 224/15000 [01:55<2:05:39,  1.96it/s, lr=2.66e-5, step_loss=0.119]07/27/2023 17:46:45 - INFO - __main__ - train loss is 33.10799582884647\n",
      "Steps:   2%| | 225/15000 [01:56<2:05:20,  1.96it/s, lr=2.67e-5, step_loss=0.089907/27/2023 17:46:46 - INFO - __main__ - train loss is 33.13504887954332\n",
      "Steps:   2%| | 226/15000 [01:56<2:05:51,  1.96it/s, lr=2.69e-5, step_loss=0.027107/27/2023 17:46:46 - INFO - __main__ - train loss is 33.13681042660028\n",
      "Steps:   2%| | 227/15000 [01:57<2:05:04,  1.97it/s, lr=2.7e-5, step_loss=0.0017607/27/2023 17:46:47 - INFO - __main__ - train loss is 33.46179742086679\n",
      "Steps:   2%| | 228/15000 [01:57<2:04:39,  1.98it/s, lr=2.71e-5, step_loss=0.325]07/27/2023 17:46:47 - INFO - __main__ - train loss is 33.46351315884385\n",
      "Steps:   2%| | 229/15000 [01:58<2:04:31,  1.98it/s, lr=2.73e-5, step_loss=0.001707/27/2023 17:46:48 - INFO - __main__ - train loss is 34.03261777071748\n",
      "Steps:   2%| | 230/15000 [01:58<2:04:21,  1.98it/s, lr=2.74e-5, step_loss=0.569]07/27/2023 17:46:48 - INFO - __main__ - train loss is 34.38630189804826\n",
      "Steps:   2%| | 231/15000 [01:59<2:04:13,  1.98it/s, lr=2.75e-5, step_loss=0.354]07/27/2023 17:46:49 - INFO - __main__ - train loss is 34.60052119998727\n",
      "Steps:   2%| | 232/15000 [01:59<2:03:50,  1.99it/s, lr=2.76e-5, step_loss=0.214]07/27/2023 17:46:49 - INFO - __main__ - train loss is 34.64913152961526\n",
      "Steps:   2%| | 233/15000 [02:00<2:04:38,  1.97it/s, lr=2.78e-5, step_loss=0.048607/27/2023 17:46:50 - INFO - __main__ - train loss is 34.65216066536959\n",
      "Steps:   2%| | 234/15000 [02:00<2:09:57,  1.89it/s, lr=2.79e-5, step_loss=0.003007/27/2023 17:46:50 - INFO - __main__ - train loss is 34.962015470839106\n",
      "Steps:   2%|   | 235/15000 [02:01<2:10:11,  1.89it/s, lr=2.8e-5, step_loss=0.31]07/27/2023 17:46:51 - INFO - __main__ - train loss is 34.97662954160478\n",
      "Steps:   2%| | 236/15000 [02:01<2:08:25,  1.92it/s, lr=2.81e-5, step_loss=0.014607/27/2023 17:46:51 - INFO - __main__ - train loss is 34.98946509452071\n",
      "Steps:   2%| | 237/15000 [02:02<2:07:46,  1.93it/s, lr=2.83e-5, step_loss=0.012807/27/2023 17:46:52 - INFO - __main__ - train loss is 35.093590862466954\n",
      "Steps:   2%| | 238/15000 [02:02<2:06:32,  1.94it/s, lr=2.84e-5, step_loss=0.104]07/27/2023 17:46:52 - INFO - __main__ - train loss is 35.099696451216005\n",
      "Steps:   2%| | 239/15000 [02:03<2:05:48,  1.96it/s, lr=2.85e-5, step_loss=0.006107/27/2023 17:46:53 - INFO - __main__ - train loss is 35.397495204000734\n",
      "Steps:   2%| | 240/15000 [02:03<2:04:55,  1.97it/s, lr=2.86e-5, step_loss=0.298]07/27/2023 17:46:53 - INFO - __main__ - train loss is 35.54579138138797\n",
      "Steps:   2%| | 241/15000 [02:04<2:04:59,  1.97it/s, lr=2.88e-5, step_loss=0.148]07/27/2023 17:46:54 - INFO - __main__ - train loss is 35.85072671750095\n",
      "Steps:   2%| | 242/15000 [02:04<2:04:36,  1.97it/s, lr=2.89e-5, step_loss=0.305]07/27/2023 17:46:54 - INFO - __main__ - train loss is 35.87495103792753\n",
      "Steps:   2%| | 243/15000 [02:05<2:04:16,  1.98it/s, lr=2.9e-5, step_loss=0.0242]07/27/2023 17:46:55 - INFO - __main__ - train loss is 35.884446316747926\n",
      "Steps:   2%| | 244/15000 [02:05<2:04:28,  1.98it/s, lr=2.91e-5, step_loss=0.009507/27/2023 17:46:55 - INFO - __main__ - train loss is 35.891151997609995\n",
      "Steps:   2%| | 245/15000 [02:06<2:04:16,  1.98it/s, lr=2.93e-5, step_loss=0.006707/27/2023 17:46:56 - INFO - __main__ - train loss is 35.901704435586\n",
      "Steps:   2%| | 246/15000 [02:06<2:04:04,  1.98it/s, lr=2.94e-5, step_loss=0.010607/27/2023 17:46:56 - INFO - __main__ - train loss is 35.99445857608225\n",
      "Steps:   2%| | 247/15000 [02:07<2:07:53,  1.92it/s, lr=2.95e-5, step_loss=0.092807/27/2023 17:46:57 - INFO - __main__ - train loss is 36.325722237466834\n",
      "Steps:   2%| | 248/15000 [02:07<2:07:20,  1.93it/s, lr=2.96e-5, step_loss=0.331]07/27/2023 17:46:58 - INFO - __main__ - train loss is 36.538386454223655\n",
      "Steps:   2%| | 249/15000 [02:08<2:06:21,  1.95it/s, lr=2.97e-5, step_loss=0.213]07/27/2023 17:46:58 - INFO - __main__ - train loss is 37.17539857828524\n",
      "Steps:   2%| | 250/15000 [02:08<2:05:49,  1.95it/s, lr=2.99e-5, step_loss=0.637]07/27/2023 17:46:59 - INFO - __main__ - train loss is 37.582088997005485\n",
      "Steps:   2%|    | 251/15000 [02:09<2:05:18,  1.96it/s, lr=3e-5, step_loss=0.407]07/27/2023 17:46:59 - INFO - __main__ - train loss is 37.6587690388551\n",
      "Steps:   2%| | 252/15000 [02:09<2:04:39,  1.97it/s, lr=3.01e-5, step_loss=0.076707/27/2023 17:47:00 - INFO - __main__ - train loss is 37.69065649562981\n",
      "Steps:   2%| | 253/15000 [02:10<2:04:40,  1.97it/s, lr=3.03e-5, step_loss=0.031907/27/2023 17:47:00 - INFO - __main__ - train loss is 37.93111540132668\n",
      "Steps:   2%|  | 254/15000 [02:10<2:04:47,  1.97it/s, lr=3.04e-5, step_loss=0.24]07/27/2023 17:47:01 - INFO - __main__ - train loss is 37.97607623541262\n",
      "Steps:   2%| | 255/15000 [02:11<2:04:08,  1.98it/s, lr=3.05e-5, step_loss=0.045]07/27/2023 17:47:01 - INFO - __main__ - train loss is 38.877501895069145\n",
      "Steps:   2%| | 256/15000 [02:11<2:04:44,  1.97it/s, lr=3.06e-5, step_loss=0.901]07/27/2023 17:47:02 - INFO - __main__ - train loss is 39.1863023241749\n",
      "Steps:   2%| | 257/15000 [02:12<2:04:29,  1.97it/s, lr=3.08e-5, step_loss=0.309]07/27/2023 17:47:02 - INFO - __main__ - train loss is 39.2116773215821\n",
      "Steps:   2%| | 258/15000 [02:12<2:04:40,  1.97it/s, lr=3.09e-5, step_loss=0.025407/27/2023 17:47:03 - INFO - __main__ - train loss is 39.38028226175811\n",
      "Steps:   2%|  | 259/15000 [02:13<2:05:30,  1.96it/s, lr=3.1e-5, step_loss=0.169]07/27/2023 17:47:03 - INFO - __main__ - train loss is 39.500931949703954\n",
      "Steps:   2%| | 260/15000 [02:13<2:04:58,  1.97it/s, lr=3.11e-5, step_loss=0.121]07/27/2023 17:47:04 - INFO - __main__ - train loss is 39.67693972715642\n",
      "Steps:   2%| | 261/15000 [02:14<2:04:32,  1.97it/s, lr=3.13e-5, step_loss=0.176]07/27/2023 17:47:04 - INFO - __main__ - train loss is 39.69213193224277\n",
      "Steps:   2%| | 262/15000 [02:14<2:04:25,  1.97it/s, lr=3.14e-5, step_loss=0.015207/27/2023 17:47:05 - INFO - __main__ - train loss is 40.162111874087714\n",
      "Steps:   2%|  | 263/15000 [02:15<2:08:25,  1.91it/s, lr=3.15e-5, step_loss=0.47]07/27/2023 17:47:05 - INFO - __main__ - train loss is 40.30013428197708\n",
      "Steps:   2%| | 264/15000 [02:16<2:09:59,  1.89it/s, lr=3.16e-5, step_loss=0.138]07/27/2023 17:47:06 - INFO - __main__ - train loss is 40.301885221968405\n",
      "Steps:   2%| | 265/15000 [02:16<2:08:28,  1.91it/s, lr=3.17e-5, step_loss=0.001707/27/2023 17:47:06 - INFO - __main__ - train loss is 40.30718297359999\n",
      "Steps:   2%| | 266/15000 [02:17<2:07:14,  1.93it/s, lr=3.19e-5, step_loss=0.005307/27/2023 17:47:07 - INFO - __main__ - train loss is 40.396621099091135\n",
      "Steps:   2%| | 267/15000 [02:17<2:06:08,  1.95it/s, lr=3.2e-5, step_loss=0.0894]07/27/2023 17:47:07 - INFO - __main__ - train loss is 40.406459113932215\n",
      "Steps:   2%| | 268/15000 [02:18<2:04:57,  1.96it/s, lr=3.21e-5, step_loss=0.009807/27/2023 17:47:08 - INFO - __main__ - train loss is 40.45011342165526\n",
      "Steps:   2%| | 269/15000 [02:18<2:03:44,  1.98it/s, lr=3.23e-5, step_loss=0.043707/27/2023 17:47:08 - INFO - __main__ - train loss is 40.482492445386015\n",
      "Steps:   2%| | 270/15000 [02:19<2:03:32,  1.99it/s, lr=3.24e-5, step_loss=0.032407/27/2023 17:47:09 - INFO - __main__ - train loss is 40.497664295486175\n",
      "Steps:   2%| | 271/15000 [02:19<2:03:13,  1.99it/s, lr=3.25e-5, step_loss=0.015207/27/2023 17:47:09 - INFO - __main__ - train loss is 40.57658031617757\n",
      "Steps:   2%| | 272/15000 [02:20<2:03:01,  2.00it/s, lr=3.26e-5, step_loss=0.078907/27/2023 17:47:10 - INFO - __main__ - train loss is 40.60646074300166\n",
      "Steps:   2%| | 273/15000 [02:20<2:03:03,  1.99it/s, lr=3.28e-5, step_loss=0.029907/27/2023 17:47:10 - INFO - __main__ - train loss is 40.611272334936075\n",
      "Steps:   2%| | 274/15000 [02:21<2:03:08,  1.99it/s, lr=3.29e-5, step_loss=0.004807/27/2023 17:47:11 - INFO - __main__ - train loss is 40.62634268950205\n",
      "Steps:   2%| | 275/15000 [02:21<2:02:58,  2.00it/s, lr=3.3e-5, step_loss=0.0151]07/27/2023 17:47:11 - INFO - __main__ - train loss is 40.66832189809065\n",
      "Steps:   2%| | 276/15000 [02:22<2:02:54,  2.00it/s, lr=3.31e-5, step_loss=0.042]07/27/2023 17:47:12 - INFO - __main__ - train loss is 40.67942067596596\n",
      "Steps:   2%| | 277/15000 [02:22<2:02:50,  2.00it/s, lr=3.33e-5, step_loss=0.011107/27/2023 17:47:12 - INFO - __main__ - train loss is 40.764838930103\n",
      "Steps:   2%| | 278/15000 [02:23<2:03:49,  1.98it/s, lr=3.34e-5, step_loss=0.085407/27/2023 17:47:13 - INFO - __main__ - train loss is 40.851747590932064\n",
      "Steps:   2%| | 279/15000 [02:23<2:14:12,  1.83it/s, lr=3.35e-5, step_loss=0.086907/27/2023 17:47:13 - INFO - __main__ - train loss is 40.85830968420487\n",
      "Steps:   2%| | 280/15000 [02:24<2:14:09,  1.83it/s, lr=3.36e-5, step_loss=0.006507/27/2023 17:47:14 - INFO - __main__ - train loss is 40.916042769211344\n",
      "Steps:   2%| | 281/15000 [02:24<2:11:35,  1.86it/s, lr=3.38e-5, step_loss=0.057707/27/2023 17:47:14 - INFO - __main__ - train loss is 41.39464282419067\n",
      "Steps:   2%| | 282/15000 [02:25<2:09:54,  1.89it/s, lr=3.39e-5, step_loss=0.479]07/27/2023 17:47:15 - INFO - __main__ - train loss is 41.432163311052136\n",
      "Steps:   2%| | 283/15000 [02:25<2:08:52,  1.90it/s, lr=3.4e-5, step_loss=0.0375]07/27/2023 17:47:15 - INFO - __main__ - train loss is 41.903043044614606\n",
      "Steps:   2%| | 284/15000 [02:26<2:07:31,  1.92it/s, lr=3.41e-5, step_loss=0.471]07/27/2023 17:47:16 - INFO - __main__ - train loss is 42.1547070274828\n",
      "Steps:   2%| | 285/15000 [02:26<2:06:19,  1.94it/s, lr=3.43e-5, step_loss=0.252]07/27/2023 17:47:16 - INFO - __main__ - train loss is 42.28027231793385\n",
      "Steps:   2%| | 286/15000 [02:27<2:05:43,  1.95it/s, lr=3.44e-5, step_loss=0.126]07/27/2023 17:47:17 - INFO - __main__ - train loss is 42.69109393458348\n",
      "Steps:   2%| | 287/15000 [02:27<2:05:31,  1.95it/s, lr=3.45e-5, step_loss=0.411]07/27/2023 17:47:18 - INFO - __main__ - train loss is 43.01111914019566\n",
      "Steps:   2%|  | 288/15000 [02:28<2:05:24,  1.96it/s, lr=3.46e-5, step_loss=0.32]07/27/2023 17:47:18 - INFO - __main__ - train loss is 43.05870858381968\n",
      "Steps:   2%| | 289/15000 [02:28<2:05:20,  1.96it/s, lr=3.48e-5, step_loss=0.047607/27/2023 17:47:19 - INFO - __main__ - train loss is 43.16052396397572\n",
      "Steps:   2%| | 290/15000 [02:29<2:04:49,  1.96it/s, lr=3.49e-5, step_loss=0.102]07/27/2023 17:47:19 - INFO - __main__ - train loss is 43.24865522782784\n",
      "Steps:   2%| | 291/15000 [02:29<2:04:45,  1.96it/s, lr=3.5e-5, step_loss=0.0881]07/27/2023 17:47:20 - INFO - __main__ - train loss is 43.26454387407284\n",
      "Steps:   2%| | 292/15000 [02:30<2:04:48,  1.96it/s, lr=3.51e-5, step_loss=0.015907/27/2023 17:47:20 - INFO - __main__ - train loss is 43.461374057340436\n",
      "Steps:   2%| | 293/15000 [02:30<2:04:44,  1.97it/s, lr=3.52e-5, step_loss=0.197]07/27/2023 17:47:21 - INFO - __main__ - train loss is 43.48871457751375\n",
      "Steps:   2%| | 294/15000 [02:31<2:06:24,  1.94it/s, lr=3.54e-5, step_loss=0.027307/27/2023 17:47:21 - INFO - __main__ - train loss is 43.51846014696639\n",
      "Steps:   2%| | 295/15000 [02:31<2:07:42,  1.92it/s, lr=3.55e-5, step_loss=0.029707/27/2023 17:47:22 - INFO - __main__ - train loss is 43.55772034439724\n",
      "Steps:   2%| | 296/15000 [02:32<2:07:39,  1.92it/s, lr=3.56e-5, step_loss=0.039307/27/2023 17:47:22 - INFO - __main__ - train loss is 43.58983521151822\n",
      "Steps:   2%| | 297/15000 [02:32<2:07:28,  1.92it/s, lr=3.57e-5, step_loss=0.032107/27/2023 17:47:23 - INFO - __main__ - train loss is 43.7438348083524\n",
      "Steps:   2%| | 298/15000 [02:33<2:05:12,  1.96it/s, lr=3.59e-5, step_loss=0.154]07/27/2023 17:47:23 - INFO - __main__ - train loss is 43.757474738988094\n",
      "Steps:   2%| | 299/15000 [02:33<2:04:54,  1.96it/s, lr=3.6e-5, step_loss=0.0136]07/27/2023 17:47:24 - INFO - __main__ - train loss is 44.463770586880855\n",
      "Steps:   2%| | 300/15000 [02:34<2:04:34,  1.97it/s, lr=3.61e-5, step_loss=0.706]07/27/2023 17:47:24 - INFO - __main__ - train loss is 44.47881254728418\n",
      "Steps:   2%| | 301/15000 [02:34<2:04:12,  1.97it/s, lr=3.63e-5, step_loss=0.015]07/27/2023 17:47:25 - INFO - __main__ - train loss is 44.70812367077451\n",
      "Steps:   2%| | 302/15000 [02:35<2:04:12,  1.97it/s, lr=3.64e-5, step_loss=0.229]07/27/2023 17:47:25 - INFO - __main__ - train loss is 44.76915657694917\n",
      "Steps:   2%| | 303/15000 [02:36<2:14:41,  1.82it/s, lr=3.65e-5, step_loss=0.061]07/27/2023 17:47:26 - INFO - __main__ - Per validation step average loss is 0.029672153294086456\n",
      "07/27/2023 17:47:26 - INFO - __main__ - Cumulative validation average loss is 0.029672153294086456\n",
      "07/27/2023 17:47:27 - INFO - __main__ - Per validation step average loss is 0.002520943759009242\n",
      "07/27/2023 17:47:27 - INFO - __main__ - Cumulative validation average loss is 0.0321930970530957\n",
      "07/27/2023 17:47:27 - INFO - __main__ - Per validation step average loss is 0.05595870316028595\n",
      "07/27/2023 17:47:27 - INFO - __main__ - Cumulative validation average loss is 0.08815180021338165\n",
      "07/27/2023 17:47:27 - INFO - __main__ - Per validation step average loss is 0.21619576215744019\n",
      "07/27/2023 17:47:27 - INFO - __main__ - Cumulative validation average loss is 0.30434756237082183\n",
      "07/27/2023 17:47:28 - INFO - __main__ - Per validation step average loss is 0.00468013621866703\n",
      "07/27/2023 17:47:28 - INFO - __main__ - Cumulative validation average loss is 0.30902769858948886\n",
      "07/27/2023 17:47:28 - INFO - __main__ - Per validation step average loss is 0.1761435717344284\n",
      "07/27/2023 17:47:28 - INFO - __main__ - Cumulative validation average loss is 0.48517127032391727\n",
      "07/27/2023 17:47:29 - INFO - __main__ - Per validation step average loss is 0.11391019076108932\n",
      "07/27/2023 17:47:29 - INFO - __main__ - Cumulative validation average loss is 0.5990814610850066\n",
      "07/27/2023 17:47:29 - INFO - __main__ - Per validation step average loss is 0.09969544410705566\n",
      "07/27/2023 17:47:29 - INFO - __main__ - Cumulative validation average loss is 0.6987769051920623\n",
      "07/27/2023 17:47:30 - INFO - __main__ - Per validation step average loss is 0.040995873510837555\n",
      "07/27/2023 17:47:30 - INFO - __main__ - Cumulative validation average loss is 0.7397727787028998\n",
      "07/27/2023 17:47:30 - INFO - __main__ - Per validation step average loss is 0.4826067090034485\n",
      "07/27/2023 17:47:30 - INFO - __main__ - Cumulative validation average loss is 1.2223794877063483\n",
      "07/27/2023 17:47:30 - INFO - __main__ - Per validation step average loss is 0.035652823746204376\n",
      "07/27/2023 17:47:30 - INFO - __main__ - Cumulative validation average loss is 1.2580323114525527\n",
      "07/27/2023 17:47:31 - INFO - __main__ - Per validation step average loss is 0.14651238918304443\n",
      "07/27/2023 17:47:31 - INFO - __main__ - Cumulative validation average loss is 1.404544700635597\n",
      "07/27/2023 17:47:31 - INFO - __main__ - Per validation step average loss is 0.006124676205217838\n",
      "07/27/2023 17:47:31 - INFO - __main__ - Cumulative validation average loss is 1.410669376840815\n",
      "07/27/2023 17:47:32 - INFO - __main__ - Per validation step average loss is 0.0022684773430228233\n",
      "07/27/2023 17:47:32 - INFO - __main__ - Cumulative validation average loss is 1.4129378541838378\n",
      "07/27/2023 17:47:32 - INFO - __main__ - Per validation step average loss is 0.3063076138496399\n",
      "07/27/2023 17:47:32 - INFO - __main__ - Cumulative validation average loss is 1.7192454680334777\n",
      "07/27/2023 17:47:32 - INFO - __main__ - Per validation step average loss is 0.00926936138421297\n",
      "07/27/2023 17:47:32 - INFO - __main__ - Cumulative validation average loss is 1.7285148294176906\n",
      "07/27/2023 17:47:33 - INFO - __main__ - Per validation step average loss is 0.6860553026199341\n",
      "07/27/2023 17:47:33 - INFO - __main__ - Cumulative validation average loss is 2.4145701320376247\n",
      "07/27/2023 17:47:33 - INFO - __main__ - Per validation step average loss is 0.01267037820070982\n",
      "07/27/2023 17:47:33 - INFO - __main__ - Cumulative validation average loss is 2.4272405102383345\n",
      "07/27/2023 17:47:34 - INFO - __main__ - Per validation step average loss is 0.13957077264785767\n",
      "07/27/2023 17:47:34 - INFO - __main__ - Cumulative validation average loss is 2.566811282886192\n",
      "07/27/2023 17:47:34 - INFO - __main__ - Per validation step average loss is 0.09120315313339233\n",
      "07/27/2023 17:47:34 - INFO - __main__ - Cumulative validation average loss is 2.6580144360195845\n",
      "07/27/2023 17:47:34 - INFO - __main__ - Per validation step average loss is 0.2636258006095886\n",
      "07/27/2023 17:47:34 - INFO - __main__ - Cumulative validation average loss is 2.921640236629173\n",
      "07/27/2023 17:47:35 - INFO - __main__ - Per validation step average loss is 0.062251243740320206\n",
      "07/27/2023 17:47:35 - INFO - __main__ - Cumulative validation average loss is 2.9838914803694934\n",
      "07/27/2023 17:47:35 - INFO - __main__ - Per validation step average loss is 0.16773563623428345\n",
      "07/27/2023 17:47:35 - INFO - __main__ - Cumulative validation average loss is 3.151627116603777\n",
      "07/27/2023 17:47:36 - INFO - __main__ - Per validation step average loss is 0.1146012395620346\n",
      "07/27/2023 17:47:36 - INFO - __main__ - Cumulative validation average loss is 3.2662283561658114\n",
      "07/27/2023 17:47:36 - INFO - __main__ - Per validation step average loss is 0.037714727222919464\n",
      "07/27/2023 17:47:36 - INFO - __main__ - Cumulative validation average loss is 3.303943083388731\n",
      "07/27/2023 17:47:37 - INFO - __main__ - Per validation step average loss is 0.005385574884712696\n",
      "07/27/2023 17:47:37 - INFO - __main__ - Cumulative validation average loss is 3.3093286582734436\n",
      "07/27/2023 17:47:37 - INFO - __main__ - Per validation step average loss is 0.008218862116336823\n",
      "07/27/2023 17:47:37 - INFO - __main__ - Cumulative validation average loss is 3.3175475203897804\n",
      "07/27/2023 17:47:37 - INFO - __main__ - Per validation step average loss is 0.0010891490383073688\n",
      "07/27/2023 17:47:37 - INFO - __main__ - Cumulative validation average loss is 3.3186366694280878\n",
      "07/27/2023 17:47:38 - INFO - __main__ - Per validation step average loss is 0.008494876325130463\n",
      "07/27/2023 17:47:38 - INFO - __main__ - Cumulative validation average loss is 3.3271315457532182\n",
      "07/27/2023 17:47:38 - INFO - __main__ - Per validation step average loss is 0.017973609268665314\n",
      "07/27/2023 17:47:38 - INFO - __main__ - Cumulative validation average loss is 3.3451051550218835\n",
      "07/27/2023 17:47:39 - INFO - __main__ - Per validation step average loss is 0.23275741934776306\n",
      "07/27/2023 17:47:39 - INFO - __main__ - Cumulative validation average loss is 3.5778625743696466\n",
      "07/27/2023 17:47:39 - INFO - __main__ - Per validation step average loss is 0.003589679254218936\n",
      "07/27/2023 17:47:39 - INFO - __main__ - Cumulative validation average loss is 3.5814522536238655\n",
      "07/27/2023 17:47:39 - INFO - __main__ - Per validation step average loss is 0.0024100574664771557\n",
      "07/27/2023 17:47:39 - INFO - __main__ - Cumulative validation average loss is 3.5838623110903427\n",
      "07/27/2023 17:47:40 - INFO - __main__ - Per validation step average loss is 0.18063369393348694\n",
      "07/27/2023 17:47:40 - INFO - __main__ - Cumulative validation average loss is 3.7644960050238296\n",
      "07/27/2023 17:47:40 - INFO - __main__ - Per validation step average loss is 0.2571491599082947\n",
      "07/27/2023 17:47:40 - INFO - __main__ - Cumulative validation average loss is 4.021645164932124\n",
      "07/27/2023 17:47:41 - INFO - __main__ - Per validation step average loss is 0.321384072303772\n",
      "07/27/2023 17:47:41 - INFO - __main__ - Cumulative validation average loss is 4.343029237235896\n",
      "07/27/2023 17:47:41 - INFO - __main__ - Per validation step average loss is 0.016760148108005524\n",
      "07/27/2023 17:47:41 - INFO - __main__ - Cumulative validation average loss is 4.359789385343902\n",
      "07/27/2023 17:47:41 - INFO - __main__ - Per validation step average loss is 0.0215742364525795\n",
      "07/27/2023 17:47:41 - INFO - __main__ - Cumulative validation average loss is 4.381363621796481\n",
      "07/27/2023 17:47:42 - INFO - __main__ - Per validation step average loss is 0.19667068123817444\n",
      "07/27/2023 17:47:42 - INFO - __main__ - Cumulative validation average loss is 4.578034303034656\n",
      "07/27/2023 17:47:42 - INFO - __main__ - Per validation step average loss is 0.1840815246105194\n",
      "07/27/2023 17:47:42 - INFO - __main__ - Cumulative validation average loss is 4.762115827645175\n",
      "07/27/2023 17:47:43 - INFO - __main__ - Per validation step average loss is 0.01777970790863037\n",
      "07/27/2023 17:47:43 - INFO - __main__ - Cumulative validation average loss is 4.7798955355538055\n",
      "07/27/2023 17:47:43 - INFO - __main__ - Per validation step average loss is 0.6674236059188843\n",
      "07/27/2023 17:47:43 - INFO - __main__ - Cumulative validation average loss is 5.44731914147269\n",
      "07/27/2023 17:47:43 - INFO - __main__ - Per validation step average loss is 0.02442927658557892\n",
      "07/27/2023 17:47:43 - INFO - __main__ - Cumulative validation average loss is 5.471748418058269\n",
      "07/27/2023 17:47:44 - INFO - __main__ - Per validation step average loss is 0.1851007640361786\n",
      "07/27/2023 17:47:44 - INFO - __main__ - Cumulative validation average loss is 5.656849182094447\n",
      "07/27/2023 17:47:44 - INFO - __main__ - Per validation step average loss is 0.44181352853775024\n",
      "07/27/2023 17:47:44 - INFO - __main__ - Cumulative validation average loss is 6.098662710632198\n",
      "07/27/2023 17:47:45 - INFO - __main__ - Per validation step average loss is 0.001665901392698288\n",
      "07/27/2023 17:47:45 - INFO - __main__ - Cumulative validation average loss is 6.100328612024896\n",
      "07/27/2023 17:47:45 - INFO - __main__ - Per validation step average loss is 0.0622033029794693\n",
      "07/27/2023 17:47:45 - INFO - __main__ - Cumulative validation average loss is 6.162531915004365\n",
      "07/27/2023 17:47:45 - INFO - __main__ - Per validation step average loss is 0.23048318922519684\n",
      "07/27/2023 17:47:45 - INFO - __main__ - Cumulative validation average loss is 6.393015104229562\n",
      "07/27/2023 17:47:46 - INFO - __main__ - Per validation step average loss is 0.03319327160716057\n",
      "07/27/2023 17:47:46 - INFO - __main__ - Cumulative validation average loss is 6.4262083758367226\n",
      "07/27/2023 17:47:46 - INFO - __main__ - Per validation step average loss is 0.009896508418023586\n",
      "07/27/2023 17:47:46 - INFO - __main__ - Cumulative validation average loss is 6.436104884254746\n",
      "07/27/2023 17:47:47 - INFO - __main__ - Per validation step average loss is 0.004948969930410385\n",
      "07/27/2023 17:47:47 - INFO - __main__ - Cumulative validation average loss is 6.4410538541851565\n",
      "07/27/2023 17:47:47 - INFO - __main__ - Per validation step average loss is 0.004692845046520233\n",
      "07/27/2023 17:47:47 - INFO - __main__ - Cumulative validation average loss is 6.445746699231677\n",
      "07/27/2023 17:47:48 - INFO - __main__ - Per validation step average loss is 0.05535021424293518\n",
      "07/27/2023 17:47:48 - INFO - __main__ - Cumulative validation average loss is 6.501096913474612\n",
      "07/27/2023 17:47:48 - INFO - __main__ - Per validation step average loss is 0.1934349238872528\n",
      "07/27/2023 17:47:48 - INFO - __main__ - Cumulative validation average loss is 6.694531837361865\n",
      "07/27/2023 17:47:48 - INFO - __main__ - Per validation step average loss is 0.027314424514770508\n",
      "07/27/2023 17:47:48 - INFO - __main__ - Cumulative validation average loss is 6.721846261876635\n",
      "07/27/2023 17:47:49 - INFO - __main__ - Per validation step average loss is 0.00493185268715024\n",
      "07/27/2023 17:47:49 - INFO - __main__ - Cumulative validation average loss is 6.7267781145637855\n",
      "07/27/2023 17:47:49 - INFO - __main__ - Per validation step average loss is 0.0016854512505233288\n",
      "07/27/2023 17:47:49 - INFO - __main__ - Cumulative validation average loss is 6.728463565814309\n",
      "07/27/2023 17:47:50 - INFO - __main__ - Per validation step average loss is 0.01780140958726406\n",
      "07/27/2023 17:47:50 - INFO - __main__ - Cumulative validation average loss is 6.746264975401573\n",
      "07/27/2023 17:47:50 - INFO - __main__ - Per validation step average loss is 0.11646702140569687\n",
      "07/27/2023 17:47:50 - INFO - __main__ - Cumulative validation average loss is 6.86273199680727\n",
      "07/27/2023 17:47:50 - INFO - __main__ - Per validation step average loss is 0.19626128673553467\n",
      "07/27/2023 17:47:50 - INFO - __main__ - Cumulative validation average loss is 7.058993283542804\n",
      "07/27/2023 17:47:51 - INFO - __main__ - Per validation step average loss is 0.10465401411056519\n",
      "07/27/2023 17:47:51 - INFO - __main__ - Cumulative validation average loss is 7.16364729765337\n",
      "07/27/2023 17:47:51 - INFO - __main__ - Per validation step average loss is 0.044034719467163086\n",
      "07/27/2023 17:47:51 - INFO - __main__ - Cumulative validation average loss is 7.207682017120533\n",
      "07/27/2023 17:47:52 - INFO - __main__ - Per validation step average loss is 0.1888558566570282\n",
      "07/27/2023 17:47:52 - INFO - __main__ - Cumulative validation average loss is 7.396537873777561\n",
      "07/27/2023 17:47:52 - INFO - __main__ - Per validation step average loss is 0.030805431306362152\n",
      "07/27/2023 17:47:52 - INFO - __main__ - Cumulative validation average loss is 7.427343305083923\n",
      "07/27/2023 17:47:52 - INFO - __main__ - Per validation step average loss is 0.13879403471946716\n",
      "07/27/2023 17:47:52 - INFO - __main__ - Cumulative validation average loss is 7.56613733980339\n",
      "07/27/2023 17:47:53 - INFO - __main__ - Per validation step average loss is 0.01161575224250555\n",
      "07/27/2023 17:47:53 - INFO - __main__ - Cumulative validation average loss is 7.577753092045896\n",
      "07/27/2023 17:47:53 - INFO - __main__ - Per validation step average loss is 0.006059193052351475\n",
      "07/27/2023 17:47:53 - INFO - __main__ - Cumulative validation average loss is 7.583812285098247\n",
      "07/27/2023 17:47:54 - INFO - __main__ - Per validation step average loss is 0.021579958498477936\n",
      "07/27/2023 17:47:54 - INFO - __main__ - Cumulative validation average loss is 7.605392243596725\n",
      "07/27/2023 17:47:54 - INFO - __main__ - Per validation step average loss is 0.09353412687778473\n",
      "07/27/2023 17:47:54 - INFO - __main__ - Cumulative validation average loss is 7.69892637047451\n",
      "07/27/2023 17:47:55 - INFO - __main__ - Per validation step average loss is 0.007591790519654751\n",
      "07/27/2023 17:47:55 - INFO - __main__ - Cumulative validation average loss is 7.706518160994165\n",
      "07/27/2023 17:47:55 - INFO - __main__ - Per validation step average loss is 0.2647552490234375\n",
      "07/27/2023 17:47:55 - INFO - __main__ - Cumulative validation average loss is 7.971273410017602\n",
      "07/27/2023 17:47:55 - INFO - __main__ - Per validation step average loss is 0.250465452671051\n",
      "07/27/2023 17:47:55 - INFO - __main__ - Cumulative validation average loss is 8.221738862688653\n",
      "07/27/2023 17:47:56 - INFO - __main__ - Per validation step average loss is 0.1920977681875229\n",
      "07/27/2023 17:47:56 - INFO - __main__ - Cumulative validation average loss is 8.413836630876176\n",
      "07/27/2023 17:47:56 - INFO - __main__ - Per validation step average loss is 0.25128793716430664\n",
      "07/27/2023 17:47:56 - INFO - __main__ - Cumulative validation average loss is 8.665124568040483\n",
      "07/27/2023 17:47:57 - INFO - __main__ - Per validation step average loss is 0.04500603675842285\n",
      "07/27/2023 17:47:57 - INFO - __main__ - Cumulative validation average loss is 8.710130604798906\n",
      "07/27/2023 17:47:57 - INFO - __main__ - Per validation step average loss is 0.3897286057472229\n",
      "07/27/2023 17:47:57 - INFO - __main__ - Cumulative validation average loss is 9.099859210546128\n",
      "07/27/2023 17:47:57 - INFO - __main__ - Per validation step average loss is 0.06769103556871414\n",
      "07/27/2023 17:47:57 - INFO - __main__ - Cumulative validation average loss is 9.167550246114843\n",
      "07/27/2023 17:47:58 - INFO - __main__ - Per validation step average loss is 0.016084274277091026\n",
      "07/27/2023 17:47:58 - INFO - __main__ - Cumulative validation average loss is 9.183634520391934\n",
      "07/27/2023 17:47:58 - INFO - __main__ - Per validation step average loss is 0.31308305263519287\n",
      "07/27/2023 17:47:58 - INFO - __main__ - Cumulative validation average loss is 9.496717573027126\n",
      "07/27/2023 17:47:58 - INFO - __main__ - Average validation loss for Epoch 0 is 0.12021161484844464\n",
      "07/27/2023 17:47:58 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 17:48:55 - INFO - __main__ - Starting epoch 1\n",
      "07/27/2023 17:48:56 - INFO - __main__ - train loss is 0.021799232810735703\n",
      "Steps:   2%| | 304/15000 [04:06<112:36:20, 27.58s/it, lr=3.66e-5, step_loss=0.0207/27/2023 17:48:56 - INFO - __main__ - train loss is 0.040630877017974854\n",
      "Steps:   2%| | 305/15000 [04:06<79:03:25, 19.37s/it, lr=3.67e-5, step_loss=0.01807/27/2023 17:48:56 - INFO - __main__ - train loss is 0.048337697982788086\n",
      "Steps:   2%| | 306/15000 [04:07<55:33:47, 13.61s/it, lr=3.69e-5, step_loss=0.00707/27/2023 17:48:57 - INFO - __main__ - train loss is 0.052657813765108585\n",
      "Steps:   2%| | 307/15000 [04:07<39:07:27,  9.59s/it, lr=3.7e-5, step_loss=0.004307/27/2023 17:48:57 - INFO - __main__ - train loss is 0.0686309291049838\n",
      "Steps:   2%| | 308/15000 [04:07<27:36:57,  6.77s/it, lr=3.71e-5, step_loss=0.01607/27/2023 17:48:57 - INFO - __main__ - train loss is 0.22025355231016874\n",
      "Steps:   2%| | 309/15000 [04:07<19:33:42,  4.79s/it, lr=3.72e-5, step_loss=0.15207/27/2023 17:48:57 - INFO - __main__ - train loss is 0.22481897752732038\n",
      "Steps:   2%| | 310/15000 [04:07<13:55:47,  3.41s/it, lr=3.74e-5, step_loss=0.00407/27/2023 17:48:57 - INFO - __main__ - train loss is 0.2937300903722644\n",
      "Steps:   2%| | 311/15000 [04:08<9:58:14,  2.44s/it, lr=3.75e-5, step_loss=0.068907/27/2023 17:48:57 - INFO - __main__ - train loss is 0.6209156019613147\n",
      "Steps:   2%| | 312/15000 [04:08<7:11:50,  1.76s/it, lr=3.76e-5, step_loss=0.327]07/27/2023 17:48:58 - INFO - __main__ - train loss is 0.7302471427246928\n",
      "Steps:   2%| | 313/15000 [04:08<5:15:33,  1.29s/it, lr=3.78e-5, step_loss=0.109]07/27/2023 17:48:58 - INFO - __main__ - train loss is 0.972879352979362\n",
      "Steps:   2%| | 314/15000 [04:08<3:53:57,  1.05it/s, lr=3.79e-5, step_loss=0.243]07/27/2023 17:48:58 - INFO - __main__ - train loss is 1.0571407629176974\n",
      "Steps:   2%| | 315/15000 [04:08<2:57:14,  1.38it/s, lr=3.8e-5, step_loss=0.0843]07/27/2023 17:48:58 - INFO - __main__ - train loss is 1.5245942426845431\n",
      "Steps:   2%| | 316/15000 [04:09<2:17:22,  1.78it/s, lr=3.81e-5, step_loss=0.467]07/27/2023 17:48:58 - INFO - __main__ - train loss is 2.1183720184490085\n",
      "Steps:   2%| | 317/15000 [04:09<1:53:11,  2.16it/s, lr=3.83e-5, step_loss=0.594]07/27/2023 17:48:59 - INFO - __main__ - train loss is 2.152981194667518\n",
      "Steps:   2%| | 318/15000 [04:09<1:35:35,  2.56it/s, lr=3.84e-5, step_loss=0.034607/27/2023 17:48:59 - INFO - __main__ - train loss is 2.155033702496439\n",
      "Steps:   2%| | 319/15000 [04:09<1:22:09,  2.98it/s, lr=3.85e-5, step_loss=0.002007/27/2023 17:48:59 - INFO - __main__ - train loss is 2.2019765698350966\n",
      "Steps:   2%| | 320/15000 [04:09<1:11:00,  3.45it/s, lr=3.86e-5, step_loss=0.046907/27/2023 17:48:59 - INFO - __main__ - train loss is 2.2356937103904784\n",
      "Steps:   2%| | 321/15000 [04:10<1:02:50,  3.89it/s, lr=3.87e-5, step_loss=0.033707/27/2023 17:48:59 - INFO - __main__ - train loss is 2.6330869370140135\n",
      "Steps:   2%|   | 322/15000 [04:10<57:06,  4.28it/s, lr=3.89e-5, step_loss=0.397]07/27/2023 17:49:00 - INFO - __main__ - train loss is 2.847120436374098\n",
      "Steps:   2%|    | 323/15000 [04:10<53:39,  4.56it/s, lr=3.9e-5, step_loss=0.214]07/27/2023 17:49:00 - INFO - __main__ - train loss is 2.8708839775063097\n",
      "Steps:   2%|  | 324/15000 [04:10<51:22,  4.76it/s, lr=3.91e-5, step_loss=0.0238]07/27/2023 17:49:00 - INFO - __main__ - train loss is 2.957302412483841\n",
      "Steps:   2%|  | 325/15000 [04:10<49:11,  4.97it/s, lr=3.92e-5, step_loss=0.0864]07/27/2023 17:49:00 - INFO - __main__ - train loss is 2.980547717306763\n",
      "Steps:   2%|  | 326/15000 [04:10<47:35,  5.14it/s, lr=3.94e-5, step_loss=0.0232]07/27/2023 17:49:00 - INFO - __main__ - train loss is 3.1465851576067507\n",
      "Steps:   2%|   | 327/15000 [04:11<46:26,  5.27it/s, lr=3.95e-5, step_loss=0.166]07/27/2023 17:49:01 - INFO - __main__ - train loss is 3.773624709341675\n",
      "Steps:   2%|   | 328/15000 [04:11<45:38,  5.36it/s, lr=3.96e-5, step_loss=0.627]07/27/2023 17:49:01 - INFO - __main__ - train loss is 3.7823382155038416\n",
      "Steps:   2%| | 329/15000 [04:11<45:04,  5.42it/s, lr=3.98e-5, step_loss=0.00871]07/27/2023 17:49:01 - INFO - __main__ - train loss is 4.07006378332153\n",
      "Steps:   2%|   | 330/15000 [04:11<44:41,  5.47it/s, lr=3.99e-5, step_loss=0.288]07/27/2023 17:49:01 - INFO - __main__ - train loss is 4.099068182054907\n",
      "Steps:   2%|▏     | 331/15000 [04:11<44:25,  5.50it/s, lr=4e-5, step_loss=0.029]07/27/2023 17:49:01 - INFO - __main__ - train loss is 4.104094495531172\n",
      "Steps:   2%| | 332/15000 [04:12<44:36,  5.48it/s, lr=4.01e-5, step_loss=0.00503]07/27/2023 17:49:01 - INFO - __main__ - train loss is 4.621513595338911\n",
      "Steps:   2%|   | 333/15000 [04:12<44:56,  5.44it/s, lr=4.03e-5, step_loss=0.517]07/27/2023 17:49:02 - INFO - __main__ - train loss is 5.126103033777326\n",
      "Steps:   2%|   | 334/15000 [04:12<45:00,  5.43it/s, lr=4.04e-5, step_loss=0.505]07/27/2023 17:49:02 - INFO - __main__ - train loss is 5.334785541053861\n",
      "Steps:   2%|   | 335/15000 [04:12<44:37,  5.48it/s, lr=4.05e-5, step_loss=0.209]07/27/2023 17:49:02 - INFO - __main__ - train loss is 5.361930155660957\n",
      "Steps:   2%|  | 336/15000 [04:12<44:23,  5.51it/s, lr=4.06e-5, step_loss=0.0271]07/27/2023 17:49:02 - INFO - __main__ - train loss is 5.571794444229454\n",
      "Steps:   2%|    | 337/15000 [04:12<44:13,  5.53it/s, lr=4.08e-5, step_loss=0.21]07/27/2023 17:49:02 - INFO - __main__ - train loss is 5.678800979163498\n",
      "Steps:   2%|   | 338/15000 [04:13<44:05,  5.54it/s, lr=4.09e-5, step_loss=0.107]07/27/2023 17:49:02 - INFO - __main__ - train loss is 5.789529570844024\n",
      "Steps:   2%|    | 339/15000 [04:13<43:58,  5.56it/s, lr=4.1e-5, step_loss=0.111]07/27/2023 17:49:03 - INFO - __main__ - train loss is 6.041576334740967\n",
      "Steps:   2%|   | 340/15000 [04:13<43:59,  5.55it/s, lr=4.11e-5, step_loss=0.252]07/27/2023 17:49:03 - INFO - __main__ - train loss is 6.081339036580175\n",
      "Steps:   2%|  | 341/15000 [04:13<43:52,  5.57it/s, lr=4.12e-5, step_loss=0.0398]07/27/2023 17:49:03 - INFO - __main__ - train loss is 6.40981969749555\n",
      "Steps:   2%|   | 342/15000 [04:13<43:48,  5.58it/s, lr=4.14e-5, step_loss=0.328]07/27/2023 17:49:03 - INFO - __main__ - train loss is 6.586843257304281\n",
      "Steps:   2%|   | 343/15000 [04:14<43:47,  5.58it/s, lr=4.15e-5, step_loss=0.177]07/27/2023 17:49:03 - INFO - __main__ - train loss is 7.01336253201589\n",
      "Steps:   2%|   | 344/15000 [04:14<43:46,  5.58it/s, lr=4.16e-5, step_loss=0.427]07/27/2023 17:49:04 - INFO - __main__ - train loss is 7.190631633158773\n",
      "Steps:   2%|   | 345/15000 [04:14<43:45,  5.58it/s, lr=4.18e-5, step_loss=0.177]07/27/2023 17:49:04 - INFO - __main__ - train loss is 7.195136239286512\n",
      "Steps:   2%|  | 346/15000 [04:14<43:47,  5.58it/s, lr=4.19e-5, step_loss=0.0045]07/27/2023 17:49:04 - INFO - __main__ - train loss is 7.536445756908506\n",
      "Steps:   2%|    | 347/15000 [04:14<43:56,  5.56it/s, lr=4.2e-5, step_loss=0.341]07/27/2023 17:49:04 - INFO - __main__ - train loss is 7.549369299318641\n",
      "Steps:   2%|  | 348/15000 [04:14<43:52,  5.57it/s, lr=4.21e-5, step_loss=0.0129]07/27/2023 17:49:04 - INFO - __main__ - train loss is 7.705985346343368\n",
      "Steps:   2%|   | 349/15000 [04:15<43:46,  5.58it/s, lr=4.23e-5, step_loss=0.157]07/27/2023 17:49:04 - INFO - __main__ - train loss is 7.713154383003712\n",
      "Steps:   2%| | 350/15000 [04:15<43:44,  5.58it/s, lr=4.24e-5, step_loss=0.00717]07/27/2023 17:49:05 - INFO - __main__ - train loss is 7.8061548396945\n",
      "Steps:   2%|   | 351/15000 [04:15<43:42,  5.59it/s, lr=4.25e-5, step_loss=0.093]07/27/2023 17:49:05 - INFO - __main__ - train loss is 7.846580281853676\n",
      "Steps:   2%|  | 352/15000 [04:15<43:41,  5.59it/s, lr=4.26e-5, step_loss=0.0404]07/27/2023 17:49:05 - INFO - __main__ - train loss is 7.894378539174795\n",
      "Steps:   2%|  | 353/15000 [04:15<43:42,  5.59it/s, lr=4.28e-5, step_loss=0.0478]07/27/2023 17:49:05 - INFO - __main__ - train loss is 8.224473144859076\n",
      "Steps:   2%|    | 354/15000 [04:15<43:42,  5.59it/s, lr=4.29e-5, step_loss=0.33]07/27/2023 17:49:05 - INFO - __main__ - train loss is 8.22624523891136\n",
      "Steps:   2%|  | 355/15000 [04:16<43:40,  5.59it/s, lr=4.3e-5, step_loss=0.00177]07/27/2023 17:49:06 - INFO - __main__ - train loss is 8.287242412101477\n",
      "Steps:   2%|   | 356/15000 [04:16<43:38,  5.59it/s, lr=4.31e-5, step_loss=0.061]07/27/2023 17:49:06 - INFO - __main__ - train loss is 8.728312551509589\n",
      "Steps:   2%|   | 357/15000 [04:16<43:56,  5.55it/s, lr=4.33e-5, step_loss=0.441]07/27/2023 17:49:06 - INFO - __main__ - train loss is 9.128330051433295\n",
      "Steps:   2%|     | 358/15000 [04:16<43:54,  5.56it/s, lr=4.34e-5, step_loss=0.4]07/27/2023 17:49:06 - INFO - __main__ - train loss is 9.171911134850234\n",
      "Steps:   2%|  | 359/15000 [04:16<43:53,  5.56it/s, lr=4.35e-5, step_loss=0.0436]07/27/2023 17:49:06 - INFO - __main__ - train loss is 9.421760871540755\n",
      "Steps:   2%|    | 360/15000 [04:17<43:52,  5.56it/s, lr=4.36e-5, step_loss=0.25]07/27/2023 17:49:06 - INFO - __main__ - train loss is 9.68452589167282\n",
      "Steps:   2%|   | 361/15000 [04:17<43:48,  5.57it/s, lr=4.37e-5, step_loss=0.263]07/27/2023 17:49:07 - INFO - __main__ - train loss is 9.938480957876891\n",
      "Steps:   2%|   | 362/15000 [04:17<43:44,  5.58it/s, lr=4.39e-5, step_loss=0.254]07/27/2023 17:49:07 - INFO - __main__ - train loss is 9.949982540216297\n",
      "Steps:   2%|   | 363/15000 [04:17<43:41,  5.58it/s, lr=4.4e-5, step_loss=0.0115]07/27/2023 17:49:07 - INFO - __main__ - train loss is 10.037849904503673\n",
      "Steps:   2%|  | 364/15000 [04:17<43:54,  5.56it/s, lr=4.41e-5, step_loss=0.0879]07/27/2023 17:49:07 - INFO - __main__ - train loss is 10.080953204538673\n",
      "Steps:   2%|  | 365/15000 [04:17<44:07,  5.53it/s, lr=4.42e-5, step_loss=0.0431]07/27/2023 17:49:07 - INFO - __main__ - train loss is 10.112784249242395\n",
      "Steps:   2%|  | 366/15000 [04:18<44:11,  5.52it/s, lr=4.44e-5, step_loss=0.0318]07/27/2023 17:49:08 - INFO - __main__ - train loss is 10.251189661677927\n",
      "Steps:   2%|   | 367/15000 [04:18<44:01,  5.54it/s, lr=4.45e-5, step_loss=0.138]07/27/2023 17:49:08 - INFO - __main__ - train loss is 10.549873722251505\n",
      "Steps:   2%|   | 368/15000 [04:18<44:00,  5.54it/s, lr=4.46e-5, step_loss=0.299]07/27/2023 17:49:08 - INFO - __main__ - train loss is 10.554980858694762\n",
      "Steps:   2%| | 369/15000 [04:18<44:16,  5.51it/s, lr=4.47e-5, step_loss=0.00511]07/27/2023 17:49:08 - INFO - __main__ - train loss is 10.96229140413925\n",
      "Steps:   2%|   | 370/15000 [04:18<44:16,  5.51it/s, lr=4.49e-5, step_loss=0.407]07/27/2023 17:49:08 - INFO - __main__ - train loss is 11.0044030318968\n",
      "Steps:   2%|   | 371/15000 [04:19<44:04,  5.53it/s, lr=4.5e-5, step_loss=0.0421]07/27/2023 17:49:08 - INFO - __main__ - train loss is 11.274558163713664\n",
      "Steps:   2%|    | 372/15000 [04:19<44:13,  5.51it/s, lr=4.51e-5, step_loss=0.27]07/27/2023 17:49:09 - INFO - __main__ - train loss is 11.278941889759153\n",
      "Steps:   2%| | 373/15000 [04:19<44:24,  5.49it/s, lr=4.53e-5, step_loss=0.00438]07/27/2023 17:49:09 - INFO - __main__ - train loss is 11.869552393909544\n",
      "Steps:   2%|   | 374/15000 [04:19<44:10,  5.52it/s, lr=4.54e-5, step_loss=0.591]07/27/2023 17:49:09 - INFO - __main__ - train loss is 11.905217205639929\n",
      "Steps:   2%|  | 375/15000 [04:19<44:01,  5.54it/s, lr=4.55e-5, step_loss=0.0357]07/27/2023 17:49:09 - INFO - __main__ - train loss is 11.917030918877572\n",
      "Steps:   3%|  | 376/15000 [04:19<44:21,  5.50it/s, lr=4.56e-5, step_loss=0.0118]07/27/2023 17:49:09 - INFO - __main__ - train loss is 12.03801679937169\n",
      "Steps:   3%|   | 377/15000 [04:20<44:15,  5.51it/s, lr=4.58e-5, step_loss=0.121]07/27/2023 17:49:10 - INFO - __main__ - train loss is 12.343340042512864\n",
      "Steps:   3%|   | 378/15000 [04:20<44:07,  5.52it/s, lr=4.59e-5, step_loss=0.305]07/27/2023 17:49:10 - INFO - __main__ - train loss is 12.35567659465596\n",
      "Steps:   3%|   | 379/15000 [04:20<44:22,  5.49it/s, lr=4.6e-5, step_loss=0.0123]07/27/2023 17:49:10 - INFO - __main__ - train loss is 12.358639240032062\n",
      "Steps:   3%| | 380/15000 [04:20<44:15,  5.50it/s, lr=4.61e-5, step_loss=0.00296]07/27/2023 17:49:10 - INFO - __main__ - train loss is 12.436555661028251\n",
      "Steps:   3%|  | 381/15000 [04:20<44:04,  5.53it/s, lr=4.62e-5, step_loss=0.0779]07/27/2023 17:49:10 - INFO - __main__ - train loss is 12.550352327292785\n",
      "Steps:   3%|   | 382/15000 [04:21<44:26,  5.48it/s, lr=4.64e-5, step_loss=0.114]07/27/2023 17:49:10 - INFO - __main__ - train loss is 12.561398960417137\n",
      "Steps:   3%|   | 383/15000 [04:21<44:47,  5.44it/s, lr=4.65e-5, step_loss=0.011]07/27/2023 17:49:11 - INFO - __main__ - train loss is 12.565131879877299\n",
      "Steps:   3%| | 384/15000 [04:21<44:32,  5.47it/s, lr=4.66e-5, step_loss=0.00373]07/27/2023 17:49:11 - INFO - __main__ - train loss is 12.606056693475693\n",
      "Steps:   3%|  | 385/15000 [04:21<44:15,  5.50it/s, lr=4.67e-5, step_loss=0.0409]07/27/2023 17:49:11 - INFO - __main__ - train loss is 12.726404781918973\n",
      "Steps:   3%|    | 386/15000 [04:21<44:03,  5.53it/s, lr=4.69e-5, step_loss=0.12]07/27/2023 17:49:11 - INFO - __main__ - train loss is 12.811979110818356\n",
      "Steps:   3%|   | 387/15000 [04:21<43:55,  5.55it/s, lr=4.7e-5, step_loss=0.0856]07/27/2023 17:49:11 - INFO - __main__ - train loss is 12.995975773315877\n",
      "Steps:   3%|   | 388/15000 [04:22<43:50,  5.56it/s, lr=4.71e-5, step_loss=0.184]07/27/2023 17:49:12 - INFO - __main__ - train loss is 13.123758580069989\n",
      "Steps:   3%|   | 389/15000 [04:22<43:44,  5.57it/s, lr=4.73e-5, step_loss=0.128]07/27/2023 17:49:12 - INFO - __main__ - train loss is 13.159386064391583\n",
      "Steps:   3%|  | 390/15000 [04:22<43:41,  5.57it/s, lr=4.74e-5, step_loss=0.0356]07/27/2023 17:49:12 - INFO - __main__ - train loss is 13.169359375257045\n",
      "Steps:   3%| | 391/15000 [04:22<43:38,  5.58it/s, lr=4.75e-5, step_loss=0.00997]07/27/2023 17:49:12 - INFO - __main__ - train loss is 13.275365073699504\n",
      "Steps:   3%|   | 392/15000 [04:22<43:34,  5.59it/s, lr=4.76e-5, step_loss=0.106]07/27/2023 17:49:12 - INFO - __main__ - train loss is 13.301626004744321\n",
      "Steps:   3%|  | 393/15000 [04:23<43:34,  5.59it/s, lr=4.78e-5, step_loss=0.0263]07/27/2023 17:49:12 - INFO - __main__ - train loss is 13.315139658283442\n",
      "Steps:   3%|  | 394/15000 [04:23<43:35,  5.58it/s, lr=4.79e-5, step_loss=0.0135]07/27/2023 17:49:13 - INFO - __main__ - train loss is 13.376056618522853\n",
      "Steps:   3%|   | 395/15000 [04:23<43:49,  5.55it/s, lr=4.8e-5, step_loss=0.0609]07/27/2023 17:49:13 - INFO - __main__ - train loss is 13.4704824606888\n",
      "Steps:   3%|  | 396/15000 [04:23<43:44,  5.57it/s, lr=4.81e-5, step_loss=0.0944]07/27/2023 17:49:13 - INFO - __main__ - train loss is 13.579984493087977\n",
      "Steps:   3%|    | 397/15000 [04:23<43:41,  5.57it/s, lr=4.83e-5, step_loss=0.11]07/27/2023 17:49:13 - INFO - __main__ - train loss is 13.689087472390383\n",
      "Steps:   3%|   | 398/15000 [04:23<43:37,  5.58it/s, lr=4.84e-5, step_loss=0.109]07/27/2023 17:49:13 - INFO - __main__ - train loss is 13.756427652668208\n",
      "Steps:   3%|  | 399/15000 [04:24<43:37,  5.58it/s, lr=4.85e-5, step_loss=0.0673]07/27/2023 17:49:13 - INFO - __main__ - train loss is 13.84378085238859\n",
      "Steps:   3%|  | 400/15000 [04:24<43:34,  5.58it/s, lr=4.86e-5, step_loss=0.0874]07/27/2023 17:49:14 - INFO - __main__ - train loss is 13.850359827745706\n",
      "Steps:   3%| | 401/15000 [04:24<43:34,  5.58it/s, lr=4.88e-5, step_loss=0.00658]07/27/2023 17:49:14 - INFO - __main__ - train loss is 13.929106355179101\n",
      "Steps:   3%|  | 402/15000 [04:24<43:34,  5.58it/s, lr=4.89e-5, step_loss=0.0787]07/27/2023 17:49:14 - INFO - __main__ - train loss is 14.244064063299447\n",
      "Steps:   3%|    | 403/15000 [04:24<43:32,  5.59it/s, lr=4.9e-5, step_loss=0.315]07/27/2023 17:49:14 - INFO - __main__ - train loss is 14.318758488167077\n",
      "Steps:   3%|  | 404/15000 [04:25<43:31,  5.59it/s, lr=4.91e-5, step_loss=0.0747]07/27/2023 17:49:14 - INFO - __main__ - train loss is 14.417174146045\n",
      "Steps:   3%|  | 405/15000 [04:25<43:32,  5.59it/s, lr=4.93e-5, step_loss=0.0984]07/27/2023 17:49:15 - INFO - __main__ - train loss is 14.494232699740678\n",
      "Steps:   3%|  | 406/15000 [04:25<43:32,  5.59it/s, lr=4.94e-5, step_loss=0.0771]07/27/2023 17:49:15 - INFO - __main__ - train loss is 14.570156977046281\n",
      "Steps:   3%|  | 407/15000 [04:25<43:35,  5.58it/s, lr=4.95e-5, step_loss=0.0759]07/27/2023 17:49:15 - INFO - __main__ - train loss is 14.582946890499443\n",
      "Steps:   3%|  | 408/15000 [04:25<43:32,  5.59it/s, lr=4.96e-5, step_loss=0.0128]07/27/2023 17:49:15 - INFO - __main__ - train loss is 14.698468708898872\n",
      "Steps:   3%|   | 409/15000 [04:25<43:30,  5.59it/s, lr=4.98e-5, step_loss=0.116]07/27/2023 17:49:15 - INFO - __main__ - train loss is 14.736568988766521\n",
      "Steps:   3%|  | 410/15000 [04:26<43:29,  5.59it/s, lr=4.99e-5, step_loss=0.0381]07/27/2023 17:49:15 - INFO - __main__ - train loss is 14.740265819011256\n",
      "Steps:   3%|▏    | 411/15000 [04:26<43:30,  5.59it/s, lr=5e-5, step_loss=0.0037]07/27/2023 17:49:16 - INFO - __main__ - train loss is 14.776478218613192\n",
      "Steps:   3%|  | 412/15000 [04:26<43:32,  5.58it/s, lr=5.01e-5, step_loss=0.0362]07/27/2023 17:49:16 - INFO - __main__ - train loss is 14.785242478130385\n",
      "Steps:   3%| | 413/15000 [04:26<43:32,  5.58it/s, lr=5.03e-5, step_loss=0.00876]07/27/2023 17:49:16 - INFO - __main__ - train loss is 14.91940292227082\n",
      "Steps:   3%|   | 414/15000 [04:26<43:33,  5.58it/s, lr=5.04e-5, step_loss=0.134]07/27/2023 17:49:16 - INFO - __main__ - train loss is 14.932133967755362\n",
      "Steps:   3%|  | 415/15000 [04:26<43:30,  5.59it/s, lr=5.05e-5, step_loss=0.0127]07/27/2023 17:49:16 - INFO - __main__ - train loss is 14.936339458217844\n",
      "Steps:   3%| | 416/15000 [04:27<43:29,  5.59it/s, lr=5.06e-5, step_loss=0.00421]07/27/2023 17:49:17 - INFO - __main__ - train loss is 14.962554583093151\n",
      "Steps:   3%|  | 417/15000 [04:27<43:29,  5.59it/s, lr=5.08e-5, step_loss=0.0262]07/27/2023 17:49:17 - INFO - __main__ - train loss is 15.019956500967965\n",
      "Steps:   3%|  | 418/15000 [04:27<43:30,  5.59it/s, lr=5.09e-5, step_loss=0.0574]07/27/2023 17:49:17 - INFO - __main__ - train loss is 15.113617228111252\n",
      "Steps:   3%|   | 419/15000 [04:27<43:33,  5.58it/s, lr=5.1e-5, step_loss=0.0937]07/27/2023 17:49:17 - INFO - __main__ - train loss is 15.196532817324623\n",
      "Steps:   3%|  | 420/15000 [04:27<43:57,  5.53it/s, lr=5.11e-5, step_loss=0.0829]07/27/2023 17:49:17 - INFO - __main__ - train loss is 15.538684399565682\n",
      "Steps:   3%|   | 421/15000 [04:28<43:48,  5.55it/s, lr=5.12e-5, step_loss=0.342]07/27/2023 17:49:17 - INFO - __main__ - train loss is 15.544124035863206\n",
      "Steps:   3%| | 422/15000 [04:28<43:42,  5.56it/s, lr=5.14e-5, step_loss=0.00544]07/27/2023 17:49:18 - INFO - __main__ - train loss is 15.586863985983655\n",
      "Steps:   3%|  | 423/15000 [04:28<43:41,  5.56it/s, lr=5.15e-5, step_loss=0.0427]07/27/2023 17:49:18 - INFO - __main__ - train loss is 15.589197807013988\n",
      "Steps:   3%| | 424/15000 [04:28<43:37,  5.57it/s, lr=5.16e-5, step_loss=0.00233]07/27/2023 17:49:18 - INFO - __main__ - train loss is 15.683672413229942\n",
      "Steps:   3%|  | 425/15000 [04:28<43:34,  5.57it/s, lr=5.17e-5, step_loss=0.0945]07/27/2023 17:49:18 - INFO - __main__ - train loss is 15.713761571794748\n",
      "Steps:   3%|  | 426/15000 [04:28<43:31,  5.58it/s, lr=5.19e-5, step_loss=0.0301]07/27/2023 17:49:18 - INFO - __main__ - train loss is 15.814264360815287\n",
      "Steps:   3%|    | 427/15000 [04:29<43:29,  5.58it/s, lr=5.2e-5, step_loss=0.101]07/27/2023 17:49:18 - INFO - __main__ - train loss is 16.335055772215128\n",
      "Steps:   3%|   | 428/15000 [04:29<43:29,  5.58it/s, lr=5.21e-5, step_loss=0.521]07/27/2023 17:49:19 - INFO - __main__ - train loss is 16.397537294775248\n",
      "Steps:   3%|  | 429/15000 [04:29<43:28,  5.59it/s, lr=5.22e-5, step_loss=0.0625]07/27/2023 17:49:19 - INFO - __main__ - train loss is 16.424910929054022\n",
      "Steps:   3%|  | 430/15000 [04:29<43:31,  5.58it/s, lr=5.24e-5, step_loss=0.0274]07/27/2023 17:49:19 - INFO - __main__ - train loss is 16.679371770471334\n",
      "Steps:   3%|   | 431/15000 [04:29<43:29,  5.58it/s, lr=5.25e-5, step_loss=0.254]07/27/2023 17:49:19 - INFO - __main__ - train loss is 16.69246538821608\n",
      "Steps:   3%|  | 432/15000 [04:30<43:28,  5.58it/s, lr=5.26e-5, step_loss=0.0131]07/27/2023 17:49:19 - INFO - __main__ - train loss is 16.69992169784382\n",
      "Steps:   3%| | 433/15000 [04:30<43:27,  5.59it/s, lr=5.28e-5, step_loss=0.00746]07/27/2023 17:49:20 - INFO - __main__ - train loss is 17.219710618723184\n",
      "Steps:   3%|    | 434/15000 [04:30<43:28,  5.58it/s, lr=5.29e-5, step_loss=0.52]07/27/2023 17:49:20 - INFO - __main__ - train loss is 17.224636625964195\n",
      "Steps:   3%|  | 435/15000 [04:30<43:28,  5.58it/s, lr=5.3e-5, step_loss=0.00493]07/27/2023 17:49:20 - INFO - __main__ - train loss is 17.444816899020225\n",
      "Steps:   3%|    | 436/15000 [04:30<43:28,  5.58it/s, lr=5.31e-5, step_loss=0.22]07/27/2023 17:49:20 - INFO - __main__ - train loss is 17.447468630736694\n",
      "Steps:   3%| | 437/15000 [04:30<43:27,  5.59it/s, lr=5.33e-5, step_loss=0.00265]07/27/2023 17:49:20 - INFO - __main__ - train loss is 17.576868898933753\n",
      "Steps:   3%|   | 438/15000 [04:31<43:29,  5.58it/s, lr=5.34e-5, step_loss=0.129]07/27/2023 17:49:20 - INFO - __main__ - train loss is 17.607305915793404\n",
      "Steps:   3%|  | 439/15000 [04:31<43:28,  5.58it/s, lr=5.35e-5, step_loss=0.0304]07/27/2023 17:49:21 - INFO - __main__ - train loss is 17.613668313948438\n",
      "Steps:   3%| | 440/15000 [04:31<43:27,  5.58it/s, lr=5.36e-5, step_loss=0.00636]07/27/2023 17:49:21 - INFO - __main__ - train loss is 17.758370390860364\n",
      "Steps:   3%|   | 441/15000 [04:31<43:30,  5.58it/s, lr=5.37e-5, step_loss=0.145]07/27/2023 17:49:21 - INFO - __main__ - train loss is 18.236192337004468\n",
      "Steps:   3%|   | 442/15000 [04:31<43:30,  5.58it/s, lr=5.39e-5, step_loss=0.478]07/27/2023 17:49:21 - INFO - __main__ - train loss is 18.24722407083027\n",
      "Steps:   3%|    | 443/15000 [04:31<43:28,  5.58it/s, lr=5.4e-5, step_loss=0.011]07/27/2023 17:49:21 - INFO - __main__ - train loss is 18.248542097746395\n",
      "Steps:   3%| | 444/15000 [04:32<43:27,  5.58it/s, lr=5.41e-5, step_loss=0.00132]07/27/2023 17:49:22 - INFO - __main__ - train loss is 18.283249792992137\n",
      "Steps:   3%|  | 445/15000 [04:32<43:26,  5.58it/s, lr=5.43e-5, step_loss=0.0347]07/27/2023 17:49:22 - INFO - __main__ - train loss is 18.35214277857449\n",
      "Steps:   3%|  | 446/15000 [04:32<43:26,  5.58it/s, lr=5.44e-5, step_loss=0.0689]07/27/2023 17:49:22 - INFO - __main__ - train loss is 18.412782472907566\n",
      "Steps:   3%|  | 447/15000 [04:32<43:25,  5.59it/s, lr=5.45e-5, step_loss=0.0606]07/27/2023 17:49:22 - INFO - __main__ - train loss is 18.612560910522006\n",
      "Steps:   3%|▏    | 448/15000 [04:32<43:24,  5.59it/s, lr=5.46e-5, step_loss=0.2]07/27/2023 17:49:22 - INFO - __main__ - train loss is 18.662760136066936\n",
      "Steps:   3%|  | 449/15000 [04:33<43:26,  5.58it/s, lr=5.48e-5, step_loss=0.0502]07/27/2023 17:49:22 - INFO - __main__ - train loss is 18.9889113282552\n",
      "Steps:   3%|   | 450/15000 [04:33<43:23,  5.59it/s, lr=5.49e-5, step_loss=0.326]07/27/2023 17:49:23 - INFO - __main__ - train loss is 19.138437909423374\n",
      "Steps:   3%|▏    | 451/15000 [04:33<43:23,  5.59it/s, lr=5.5e-5, step_loss=0.15]07/27/2023 17:49:23 - INFO - __main__ - train loss is 19.181634088396095\n",
      "Steps:   3%|  | 452/15000 [04:33<43:22,  5.59it/s, lr=5.51e-5, step_loss=0.0432]07/27/2023 17:49:23 - INFO - __main__ - train loss is 19.190080943866633\n",
      "Steps:   3%| | 453/15000 [04:33<43:23,  5.59it/s, lr=5.53e-5, step_loss=0.00845]07/27/2023 17:49:23 - INFO - __main__ - train loss is 19.22181080596056\n",
      "Steps:   3%|  | 454/15000 [04:33<43:25,  5.58it/s, lr=5.54e-5, step_loss=0.0317]07/27/2023 17:49:23 - INFO - __main__ - train loss is 19.596898752613924\n",
      "Steps:   3%|   | 455/15000 [04:34<43:23,  5.59it/s, lr=5.55e-5, step_loss=0.375]07/27/2023 17:49:24 - INFO - __main__ - train loss is 19.598382859141566\n",
      "Steps:   3%| | 456/15000 [04:34<43:23,  5.59it/s, lr=5.56e-5, step_loss=0.00148]07/27/2023 17:49:24 - INFO - __main__ - train loss is 19.603999862098135\n",
      "Steps:   3%| | 457/15000 [04:34<43:23,  5.59it/s, lr=5.57e-5, step_loss=0.00562]07/27/2023 17:49:24 - INFO - __main__ - train loss is 19.637109094881453\n",
      "Steps:   3%|  | 458/15000 [04:34<43:21,  5.59it/s, lr=5.59e-5, step_loss=0.0331]07/27/2023 17:49:24 - INFO - __main__ - train loss is 20.23373108508531\n",
      "Steps:   3%|    | 459/15000 [04:34<43:24,  5.58it/s, lr=5.6e-5, step_loss=0.597]07/27/2023 17:49:24 - INFO - __main__ - train loss is 20.492228412651457\n",
      "Steps:   3%|   | 460/15000 [04:35<43:22,  5.59it/s, lr=5.61e-5, step_loss=0.258]07/27/2023 17:49:24 - INFO - __main__ - train loss is 21.002496624016203\n",
      "Steps:   3%|    | 461/15000 [04:35<43:29,  5.57it/s, lr=5.63e-5, step_loss=0.51]07/27/2023 17:49:25 - INFO - __main__ - train loss is 21.008616386563517\n",
      "Steps:   3%| | 462/15000 [04:35<43:32,  5.56it/s, lr=5.64e-5, step_loss=0.00612]07/27/2023 17:49:25 - INFO - __main__ - train loss is 21.025991757051088\n",
      "Steps:   3%|  | 463/15000 [04:35<43:29,  5.57it/s, lr=5.65e-5, step_loss=0.0174]07/27/2023 17:49:25 - INFO - __main__ - train loss is 21.04028218856547\n",
      "Steps:   3%|  | 464/15000 [04:35<43:25,  5.58it/s, lr=5.66e-5, step_loss=0.0143]07/27/2023 17:49:25 - INFO - __main__ - train loss is 21.33888527622912\n",
      "Steps:   3%|   | 465/15000 [04:35<43:23,  5.58it/s, lr=5.68e-5, step_loss=0.299]07/27/2023 17:49:25 - INFO - __main__ - train loss is 21.489352120668627\n",
      "Steps:   3%|    | 466/15000 [04:36<43:23,  5.58it/s, lr=5.69e-5, step_loss=0.15]07/27/2023 17:49:25 - INFO - __main__ - train loss is 21.491523898788728\n",
      "Steps:   3%|  | 467/15000 [04:36<43:22,  5.58it/s, lr=5.7e-5, step_loss=0.00217]07/27/2023 17:49:26 - INFO - __main__ - train loss is 22.13539478892926\n",
      "Steps:   3%|   | 468/15000 [04:36<43:24,  5.58it/s, lr=5.71e-5, step_loss=0.644]07/27/2023 17:49:26 - INFO - __main__ - train loss is 22.151515740551986\n",
      "Steps:   3%|  | 469/15000 [04:36<43:23,  5.58it/s, lr=5.73e-5, step_loss=0.0161]07/27/2023 17:49:26 - INFO - __main__ - train loss is 22.152803616249003\n",
      "Steps:   3%| | 470/15000 [04:36<43:20,  5.59it/s, lr=5.74e-5, step_loss=0.00129]07/27/2023 17:49:26 - INFO - __main__ - train loss is 22.65664680453483\n",
      "Steps:   3%|   | 471/15000 [04:37<43:19,  5.59it/s, lr=5.75e-5, step_loss=0.504]07/27/2023 17:49:26 - INFO - __main__ - train loss is 22.666448661708273\n",
      "Steps:   3%|  | 472/15000 [04:37<43:17,  5.59it/s, lr=5.76e-5, step_loss=0.0098]07/27/2023 17:49:27 - INFO - __main__ - train loss is 22.868947231792845\n",
      "Steps:   3%|   | 473/15000 [04:37<43:16,  5.59it/s, lr=5.78e-5, step_loss=0.202]07/27/2023 17:49:27 - INFO - __main__ - train loss is 23.003979080938734\n",
      "Steps:   3%|   | 474/15000 [04:37<43:16,  5.59it/s, lr=5.79e-5, step_loss=0.135]07/27/2023 17:49:27 - INFO - __main__ - train loss is 23.138271400355734\n",
      "Steps:   3%|▏   | 475/15000 [04:37<43:20,  5.59it/s, lr=5.8e-5, step_loss=0.134]07/27/2023 17:49:27 - INFO - __main__ - train loss is 23.342698016786017\n",
      "Steps:   3%|   | 476/15000 [04:37<43:19,  5.59it/s, lr=5.81e-5, step_loss=0.204]07/27/2023 17:49:27 - INFO - __main__ - train loss is 23.40061766805593\n",
      "Steps:   3%|  | 477/15000 [04:38<43:18,  5.59it/s, lr=5.83e-5, step_loss=0.0579]07/27/2023 17:49:27 - INFO - __main__ - train loss is 23.632932612323202\n",
      "Steps:   3%|   | 478/15000 [04:38<43:17,  5.59it/s, lr=5.84e-5, step_loss=0.232]07/27/2023 17:49:28 - INFO - __main__ - train loss is 23.678864674293436\n",
      "Steps:   3%|  | 479/15000 [04:38<43:17,  5.59it/s, lr=5.85e-5, step_loss=0.0459]07/27/2023 17:49:28 - INFO - __main__ - train loss is 23.760776357376017\n",
      "Steps:   3%|  | 480/15000 [04:38<43:17,  5.59it/s, lr=5.86e-5, step_loss=0.0819]07/27/2023 17:49:28 - INFO - __main__ - train loss is 23.766875434783287\n",
      "Steps:   3%|  | 481/15000 [04:38<43:17,  5.59it/s, lr=5.87e-5, step_loss=0.0061]07/27/2023 17:49:28 - INFO - __main__ - train loss is 23.77040071191732\n",
      "Steps:   3%| | 482/15000 [04:38<43:17,  5.59it/s, lr=5.89e-5, step_loss=0.00353]07/27/2023 17:49:28 - INFO - __main__ - train loss is 23.899027743958868\n",
      "Steps:   3%|▏   | 483/15000 [04:39<43:23,  5.58it/s, lr=5.9e-5, step_loss=0.129]07/27/2023 17:49:29 - INFO - __main__ - train loss is 23.927981260814704\n",
      "Steps:   3%|   | 484/15000 [04:39<43:19,  5.58it/s, lr=5.91e-5, step_loss=0.029]07/27/2023 17:49:29 - INFO - __main__ - train loss is 23.994258571066894\n",
      "Steps:   3%|  | 485/15000 [04:39<43:31,  5.56it/s, lr=5.92e-5, step_loss=0.0663]07/27/2023 17:49:29 - INFO - __main__ - train loss is 24.176710370578803\n",
      "Steps:   3%|   | 486/15000 [04:39<43:36,  5.55it/s, lr=5.94e-5, step_loss=0.182]07/27/2023 17:49:29 - INFO - __main__ - train loss is 24.281173858442344\n",
      "Steps:   3%|   | 487/15000 [04:39<43:42,  5.53it/s, lr=5.95e-5, step_loss=0.104]07/27/2023 17:49:29 - INFO - __main__ - train loss is 24.362102727987804\n",
      "Steps:   3%|  | 488/15000 [04:40<43:43,  5.53it/s, lr=5.96e-5, step_loss=0.0809]07/27/2023 17:49:29 - INFO - __main__ - train loss is 24.66007045994047\n",
      "Steps:   3%|   | 489/15000 [04:40<43:44,  5.53it/s, lr=5.97e-5, step_loss=0.298]07/27/2023 17:49:30 - INFO - __main__ - train loss is 24.677248563268222\n",
      "Steps:   3%|  | 490/15000 [04:40<43:45,  5.53it/s, lr=5.99e-5, step_loss=0.0172]07/27/2023 17:49:30 - INFO - __main__ - train loss is 24.909390609362163\n",
      "Steps:   3%|▏     | 491/15000 [04:40<44:07,  5.48it/s, lr=6e-5, step_loss=0.232]07/27/2023 17:49:30 - INFO - __main__ - train loss is 25.061582874157466\n",
      "Steps:   3%|   | 492/15000 [04:40<44:02,  5.49it/s, lr=6.01e-5, step_loss=0.152]07/27/2023 17:49:30 - INFO - __main__ - train loss is 25.07681751961354\n",
      "Steps:   3%|  | 493/15000 [04:40<43:59,  5.50it/s, lr=6.03e-5, step_loss=0.0152]07/27/2023 17:49:30 - INFO - __main__ - train loss is 25.08355680818204\n",
      "Steps:   3%| | 494/15000 [04:41<43:59,  5.50it/s, lr=6.04e-5, step_loss=0.00674]07/27/2023 17:49:31 - INFO - __main__ - train loss is 25.117319658049382\n",
      "Steps:   3%|  | 495/15000 [04:41<43:55,  5.50it/s, lr=6.05e-5, step_loss=0.0338]07/27/2023 17:49:31 - INFO - __main__ - train loss is 25.222523167380132\n",
      "Steps:   3%|   | 496/15000 [04:41<43:55,  5.50it/s, lr=6.06e-5, step_loss=0.105]07/27/2023 17:49:31 - INFO - __main__ - train loss is 25.22535234701354\n",
      "Steps:   3%| | 497/15000 [04:41<43:54,  5.51it/s, lr=6.07e-5, step_loss=0.00283]07/27/2023 17:49:31 - INFO - __main__ - train loss is 25.235189040307887\n",
      "Steps:   3%| | 498/15000 [04:41<43:55,  5.50it/s, lr=6.09e-5, step_loss=0.00984]07/27/2023 17:49:31 - INFO - __main__ - train loss is 25.23936140735168\n",
      "Steps:   3%|  | 499/15000 [04:42<43:54,  5.50it/s, lr=6.1e-5, step_loss=0.00417]07/27/2023 17:49:31 - INFO - __main__ - train loss is 25.241035116487183\n",
      "Steps:   3%|  | 500/15000 [04:42<44:17,  5.46it/s, lr=6.1e-5, step_loss=0.00417]07/27/2023 17:49:32 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-500\n",
      "07/27/2023 17:49:32 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 17:49:32,028] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "[2023-07-27 17:49:32,035] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 17:49:32,035] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 17:49:32,044] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 17:49:32,044] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 17:49:32,052] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 17:49:32,053] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 17:49:32,053] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 17:49:32 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-500/pytorch_model\n",
      "07/27/2023 17:49:32 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-500/scheduler.bin\n",
      "07/27/2023 17:49:32 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-500/random_states_0.pkl\n",
      "07/27/2023 17:49:32 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-500\n",
      "Steps:   3%| | 500/15000 [04:42<44:17,  5.46it/s, lr=6.11e-5, step_loss=0.00167]07/27/2023 17:49:32 - INFO - __main__ - train loss is 25.441981507115997\n",
      "Steps:   3%|   | 501/15000 [04:42<46:03,  5.25it/s, lr=6.12e-5, step_loss=0.201]07/27/2023 17:49:32 - INFO - __main__ - train loss is 25.858878923230805\n",
      "Steps:   3%|   | 502/15000 [04:42<45:13,  5.34it/s, lr=6.14e-5, step_loss=0.417]07/27/2023 17:49:32 - INFO - __main__ - train loss is 25.943891165428795\n",
      "Steps:   3%|   | 503/15000 [04:42<45:13,  5.34it/s, lr=6.15e-5, step_loss=0.085]07/27/2023 17:49:32 - INFO - __main__ - train loss is 25.970411726855673\n",
      "Steps:   3%|  | 504/15000 [04:43<44:47,  5.39it/s, lr=6.16e-5, step_loss=0.0265]07/27/2023 17:49:32 - INFO - __main__ - train loss is 25.97670389257837\n",
      "Steps:   3%| | 505/15000 [04:43<44:30,  5.43it/s, lr=6.17e-5, step_loss=0.00629]07/27/2023 17:49:33 - INFO - __main__ - train loss is 26.157304207910784\n",
      "Steps:   3%|   | 506/15000 [04:43<44:17,  5.45it/s, lr=6.19e-5, step_loss=0.181]07/27/2023 17:49:33 - INFO - __main__ - train loss is 26.393260489334352\n",
      "Steps:   3%|▏   | 507/15000 [04:43<44:09,  5.47it/s, lr=6.2e-5, step_loss=0.236]07/27/2023 17:49:33 - INFO - __main__ - train loss is 26.44290137209464\n",
      "Steps:   3%|  | 508/15000 [04:43<44:26,  5.43it/s, lr=6.21e-5, step_loss=0.0496]07/27/2023 17:49:33 - INFO - __main__ - train loss is 26.60126516141463\n",
      "Steps:   3%|   | 509/15000 [04:43<44:02,  5.48it/s, lr=6.22e-5, step_loss=0.158]07/27/2023 17:49:33 - INFO - __main__ - train loss is 26.60681046231184\n",
      "Steps:   3%| | 510/15000 [04:44<43:47,  5.51it/s, lr=6.24e-5, step_loss=0.00555]07/27/2023 17:49:33 - INFO - __main__ - train loss is 26.75102977140341\n",
      "Steps:   3%|   | 511/15000 [04:44<43:35,  5.54it/s, lr=6.25e-5, step_loss=0.144]07/27/2023 17:49:34 - INFO - __main__ - train loss is 27.156793397502042\n",
      "Steps:   3%|   | 512/15000 [04:44<43:28,  5.55it/s, lr=6.26e-5, step_loss=0.406]07/27/2023 17:49:34 - INFO - __main__ - train loss is 27.158331675105728\n",
      "Steps:   3%| | 513/15000 [04:44<43:24,  5.56it/s, lr=6.28e-5, step_loss=0.00154]07/27/2023 17:49:34 - INFO - __main__ - train loss is 27.174516433500685\n",
      "Steps:   3%|  | 514/15000 [04:44<43:21,  5.57it/s, lr=6.29e-5, step_loss=0.0162]07/27/2023 17:49:34 - INFO - __main__ - train loss is 27.190482312464155\n",
      "Steps:   3%|▏   | 515/15000 [04:44<43:17,  5.58it/s, lr=6.3e-5, step_loss=0.016]07/27/2023 17:49:34 - INFO - __main__ - train loss is 27.404196614050306\n",
      "Steps:   3%|   | 516/15000 [04:45<43:15,  5.58it/s, lr=6.31e-5, step_loss=0.214]07/27/2023 17:49:35 - INFO - __main__ - train loss is 27.411066684522666\n",
      "Steps:   3%| | 517/15000 [04:45<43:13,  5.58it/s, lr=6.33e-5, step_loss=0.00687]07/27/2023 17:49:35 - INFO - __main__ - train loss is 27.48683244327549\n",
      "Steps:   3%|  | 518/15000 [04:45<43:26,  5.56it/s, lr=6.34e-5, step_loss=0.0758]07/27/2023 17:49:35 - INFO - __main__ - train loss is 27.49241466645617\n",
      "Steps:   3%| | 519/15000 [04:45<43:20,  5.57it/s, lr=6.35e-5, step_loss=0.00558]07/27/2023 17:49:35 - INFO - __main__ - train loss is 27.582196598988958\n",
      "Steps:   3%|  | 520/15000 [04:45<43:16,  5.58it/s, lr=6.36e-5, step_loss=0.0898]07/27/2023 17:49:35 - INFO - __main__ - train loss is 28.189643031102605\n",
      "Steps:   3%|   | 521/15000 [04:46<43:14,  5.58it/s, lr=6.38e-5, step_loss=0.607]07/27/2023 17:49:35 - INFO - __main__ - train loss is 28.333177959662862\n",
      "Steps:   3%|   | 522/15000 [04:46<43:12,  5.58it/s, lr=6.39e-5, step_loss=0.144]07/27/2023 17:49:36 - INFO - __main__ - train loss is 28.527370995027013\n",
      "Steps:   3%|▏   | 523/15000 [04:46<43:12,  5.58it/s, lr=6.4e-5, step_loss=0.194]07/27/2023 17:49:36 - INFO - __main__ - train loss is 28.530037646065466\n",
      "Steps:   3%| | 524/15000 [04:46<43:11,  5.59it/s, lr=6.41e-5, step_loss=0.00267]07/27/2023 17:49:36 - INFO - __main__ - train loss is 28.585518707404844\n",
      "Steps:   4%|  | 525/15000 [04:46<43:12,  5.58it/s, lr=6.43e-5, step_loss=0.0555]07/27/2023 17:49:36 - INFO - __main__ - train loss is 28.596401254530065\n",
      "Steps:   4%|  | 526/15000 [04:46<43:10,  5.59it/s, lr=6.44e-5, step_loss=0.0109]07/27/2023 17:49:36 - INFO - __main__ - train loss is 28.599833168671466\n",
      "Steps:   4%| | 527/15000 [04:47<43:09,  5.59it/s, lr=6.45e-5, step_loss=0.00343]07/27/2023 17:49:37 - INFO - __main__ - train loss is 29.097847439930774\n",
      "Steps:   4%|   | 528/15000 [04:47<43:09,  5.59it/s, lr=6.46e-5, step_loss=0.498]07/27/2023 17:49:37 - INFO - __main__ - train loss is 29.212657683179714\n",
      "Steps:   4%|   | 529/15000 [04:47<43:08,  5.59it/s, lr=6.48e-5, step_loss=0.115]07/27/2023 17:49:37 - INFO - __main__ - train loss is 29.793720596120693\n",
      "Steps:   4%|   | 530/15000 [04:47<43:07,  5.59it/s, lr=6.49e-5, step_loss=0.581]07/27/2023 17:49:37 - INFO - __main__ - train loss is 29.848710522637703\n",
      "Steps:   4%|▏   | 531/15000 [04:47<43:07,  5.59it/s, lr=6.5e-5, step_loss=0.055]07/27/2023 17:49:37 - INFO - __main__ - train loss is 29.893980332301\n",
      "Steps:   4%|  | 532/15000 [04:48<43:07,  5.59it/s, lr=6.51e-5, step_loss=0.0453]07/27/2023 17:49:37 - INFO - __main__ - train loss is 29.90856768435333\n",
      "Steps:   4%|  | 533/15000 [04:48<43:08,  5.59it/s, lr=6.53e-5, step_loss=0.0146]07/27/2023 17:49:38 - INFO - __main__ - train loss is 29.91741415357683\n",
      "Steps:   4%| | 534/15000 [04:48<43:08,  5.59it/s, lr=6.54e-5, step_loss=0.00885]07/27/2023 17:49:38 - INFO - __main__ - train loss is 29.91960635560099\n",
      "Steps:   4%| | 535/15000 [04:48<43:08,  5.59it/s, lr=6.55e-5, step_loss=0.00219]07/27/2023 17:49:38 - INFO - __main__ - train loss is 29.98946803587023\n",
      "Steps:   4%|  | 536/15000 [04:48<43:07,  5.59it/s, lr=6.56e-5, step_loss=0.0699]07/27/2023 17:49:38 - INFO - __main__ - train loss is 30.044383851462044\n",
      "Steps:   4%|  | 537/15000 [04:48<43:06,  5.59it/s, lr=6.57e-5, step_loss=0.0549]07/27/2023 17:49:38 - INFO - __main__ - train loss is 30.047484028269537\n",
      "Steps:   4%|  | 538/15000 [04:49<43:12,  5.58it/s, lr=6.59e-5, step_loss=0.0031]07/27/2023 17:49:38 - INFO - __main__ - train loss is 30.053426312399097\n",
      "Steps:   4%|  | 539/15000 [04:49<43:34,  5.53it/s, lr=6.6e-5, step_loss=0.00594]07/27/2023 17:49:39 - INFO - __main__ - train loss is 30.119315700721927\n",
      "Steps:   4%|  | 540/15000 [04:49<43:44,  5.51it/s, lr=6.61e-5, step_loss=0.0659]07/27/2023 17:49:39 - INFO - __main__ - train loss is 30.12402427068446\n",
      "Steps:   4%| | 541/15000 [04:49<43:41,  5.51it/s, lr=6.63e-5, step_loss=0.00471]07/27/2023 17:49:39 - INFO - __main__ - train loss is 30.12898865400348\n",
      "Steps:   4%| | 542/15000 [04:49<43:32,  5.53it/s, lr=6.64e-5, step_loss=0.00496]07/27/2023 17:49:39 - INFO - __main__ - train loss is 30.457713515148498\n",
      "Steps:   4%|   | 543/15000 [04:50<43:25,  5.55it/s, lr=6.65e-5, step_loss=0.329]07/27/2023 17:49:39 - INFO - __main__ - train loss is 30.98748609481845\n",
      "Steps:   4%|▏   | 544/15000 [04:50<43:18,  5.56it/s, lr=6.66e-5, step_loss=0.53]07/27/2023 17:49:40 - INFO - __main__ - train loss is 30.98952467564959\n",
      "Steps:   4%| | 545/15000 [04:50<43:24,  5.55it/s, lr=6.68e-5, step_loss=0.00204]07/27/2023 17:49:40 - INFO - __main__ - train loss is 31.02373345021624\n",
      "Steps:   4%|  | 546/15000 [04:50<43:27,  5.54it/s, lr=6.69e-5, step_loss=0.0342]07/27/2023 17:49:40 - INFO - __main__ - train loss is 31.038104280945845\n",
      "Steps:   4%|   | 547/15000 [04:50<43:31,  5.53it/s, lr=6.7e-5, step_loss=0.0144]07/27/2023 17:49:40 - INFO - __main__ - train loss is 31.111795283970423\n",
      "Steps:   4%|  | 548/15000 [04:50<43:38,  5.52it/s, lr=6.71e-5, step_loss=0.0737]07/27/2023 17:49:40 - INFO - __main__ - train loss is 31.234540976700373\n",
      "Steps:   4%|   | 549/15000 [04:51<43:38,  5.52it/s, lr=6.73e-5, step_loss=0.123]07/27/2023 17:49:40 - INFO - __main__ - train loss is 31.484329052385874\n",
      "Steps:   4%|▏   | 550/15000 [04:51<43:38,  5.52it/s, lr=6.74e-5, step_loss=0.25]07/27/2023 17:49:41 - INFO - __main__ - train loss is 31.707696981844492\n",
      "Steps:   4%|   | 551/15000 [04:51<43:38,  5.52it/s, lr=6.75e-5, step_loss=0.223]07/27/2023 17:49:41 - INFO - __main__ - train loss is 32.03942704957444\n",
      "Steps:   4%|   | 552/15000 [04:51<43:38,  5.52it/s, lr=6.76e-5, step_loss=0.332]07/27/2023 17:49:41 - INFO - __main__ - train loss is 32.15766812127549\n",
      "Steps:   4%|   | 553/15000 [04:51<43:39,  5.52it/s, lr=6.78e-5, step_loss=0.118]07/27/2023 17:49:41 - INFO - __main__ - train loss is 32.22585008305032\n",
      "Steps:   4%|  | 554/15000 [04:52<43:39,  5.52it/s, lr=6.79e-5, step_loss=0.0682]07/27/2023 17:49:41 - INFO - __main__ - train loss is 32.26655290287454\n",
      "Steps:   4%|   | 555/15000 [04:52<43:41,  5.51it/s, lr=6.8e-5, step_loss=0.0407]07/27/2023 17:49:42 - INFO - __main__ - train loss is 32.28279522259254\n",
      "Steps:   4%|  | 556/15000 [04:52<43:29,  5.53it/s, lr=6.81e-5, step_loss=0.0162]07/27/2023 17:49:42 - INFO - __main__ - train loss is 32.9327248056652\n",
      "Steps:   4%|▏   | 557/15000 [04:52<43:29,  5.53it/s, lr=6.83e-5, step_loss=0.65]07/27/2023 17:49:42 - INFO - __main__ - train loss is 32.93444534158334\n",
      "Steps:   4%| | 558/15000 [04:52<43:22,  5.55it/s, lr=6.84e-5, step_loss=0.00172]07/27/2023 17:49:42 - INFO - __main__ - train loss is 32.97169122612104\n",
      "Steps:   4%|  | 559/15000 [04:52<43:16,  5.56it/s, lr=6.85e-5, step_loss=0.0372]07/27/2023 17:49:42 - INFO - __main__ - train loss is 33.001896341796964\n",
      "Steps:   4%|  | 560/15000 [04:53<43:10,  5.57it/s, lr=6.86e-5, step_loss=0.0302]07/27/2023 17:49:42 - INFO - __main__ - train loss is 33.00341013795696\n",
      "Steps:   4%| | 561/15000 [04:53<43:07,  5.58it/s, lr=6.88e-5, step_loss=0.00151]07/27/2023 17:49:43 - INFO - __main__ - train loss is 33.28831288940273\n",
      "Steps:   4%|   | 562/15000 [04:53<43:05,  5.58it/s, lr=6.89e-5, step_loss=0.285]07/27/2023 17:49:43 - INFO - __main__ - train loss is 33.38639913476072\n",
      "Steps:   4%|   | 563/15000 [04:53<43:04,  5.59it/s, lr=6.9e-5, step_loss=0.0981]07/27/2023 17:49:43 - INFO - __main__ - train loss is 33.398431341862306\n",
      "Steps:   4%|   | 564/15000 [04:53<43:02,  5.59it/s, lr=6.91e-5, step_loss=0.012]07/27/2023 17:49:43 - INFO - __main__ - train loss is 33.470935847377405\n",
      "Steps:   4%|  | 565/15000 [04:53<43:03,  5.59it/s, lr=6.93e-5, step_loss=0.0725]07/27/2023 17:49:43 - INFO - __main__ - train loss is 33.52218836522661\n",
      "Steps:   4%|  | 566/15000 [04:54<43:02,  5.59it/s, lr=6.94e-5, step_loss=0.0513]07/27/2023 17:49:44 - INFO - __main__ - train loss is 33.55792285106145\n",
      "Steps:   4%|  | 567/15000 [04:54<43:04,  5.58it/s, lr=6.95e-5, step_loss=0.0357]07/27/2023 17:49:44 - INFO - __main__ - train loss is 33.70482550165616\n",
      "Steps:   4%|   | 568/15000 [04:54<43:04,  5.59it/s, lr=6.96e-5, step_loss=0.147]07/27/2023 17:49:44 - INFO - __main__ - train loss is 33.70785317919217\n",
      "Steps:   4%| | 569/15000 [04:54<43:12,  5.57it/s, lr=6.98e-5, step_loss=0.00303]07/27/2023 17:49:44 - INFO - __main__ - train loss is 33.743473414098844\n",
      "Steps:   4%|  | 570/15000 [04:54<43:09,  5.57it/s, lr=6.99e-5, step_loss=0.0356]07/27/2023 17:49:44 - INFO - __main__ - train loss is 33.86944315186702\n",
      "Steps:   4%|▏     | 571/15000 [04:55<43:07,  5.58it/s, lr=7e-5, step_loss=0.126]07/27/2023 17:49:44 - INFO - __main__ - train loss is 33.872621193761006\n",
      "Steps:   4%| | 572/15000 [04:55<43:05,  5.58it/s, lr=7.01e-5, step_loss=0.00318]07/27/2023 17:49:45 - INFO - __main__ - train loss is 33.943127885693684\n",
      "Steps:   4%|  | 573/15000 [04:55<43:03,  5.58it/s, lr=7.03e-5, step_loss=0.0705]07/27/2023 17:49:45 - INFO - __main__ - train loss is 34.28889496647753\n",
      "Steps:   4%|   | 574/15000 [04:55<43:48,  5.49it/s, lr=7.04e-5, step_loss=0.346]07/27/2023 17:49:45 - INFO - __main__ - train loss is 34.33258805447258\n",
      "Steps:   4%|  | 575/15000 [04:55<43:48,  5.49it/s, lr=7.05e-5, step_loss=0.0437]07/27/2023 17:49:45 - INFO - __main__ - train loss is 34.35229418077506\n",
      "Steps:   4%|  | 576/15000 [04:55<43:33,  5.52it/s, lr=7.06e-5, step_loss=0.0197]07/27/2023 17:49:45 - INFO - __main__ - train loss is 34.35714150243439\n",
      "Steps:   4%| | 577/15000 [04:56<43:23,  5.54it/s, lr=7.07e-5, step_loss=0.00485]07/27/2023 17:49:46 - INFO - __main__ - train loss is 34.500587560469285\n",
      "Steps:   4%|   | 578/15000 [04:56<43:16,  5.55it/s, lr=7.09e-5, step_loss=0.143]07/27/2023 17:49:46 - INFO - __main__ - train loss is 34.51336325262673\n",
      "Steps:   4%|   | 579/15000 [04:56<43:11,  5.57it/s, lr=7.1e-5, step_loss=0.0128]07/27/2023 17:49:46 - INFO - __main__ - train loss is 34.569541855948046\n",
      "Steps:   4%|  | 580/15000 [04:56<43:07,  5.57it/s, lr=7.11e-5, step_loss=0.0562]07/27/2023 17:49:46 - INFO - __main__ - train loss is 34.64963386883028\n",
      "Steps:   4%|  | 581/15000 [04:56<43:04,  5.58it/s, lr=7.12e-5, step_loss=0.0801]07/27/2023 17:49:46 - INFO - __main__ - train loss is 34.65258159884252\n",
      "Steps:   4%| | 582/15000 [04:57<43:02,  5.58it/s, lr=7.14e-5, step_loss=0.00295]07/27/2023 17:49:46 - INFO - __main__ - train loss is 34.66110502486117\n",
      "Steps:   4%| | 583/15000 [04:57<43:02,  5.58it/s, lr=7.15e-5, step_loss=0.00852]07/27/2023 17:49:47 - INFO - __main__ - train loss is 34.66314626694657\n",
      "Steps:   4%| | 584/15000 [04:57<43:02,  5.58it/s, lr=7.16e-5, step_loss=0.00204]07/27/2023 17:49:47 - INFO - __main__ - train loss is 34.89222679496743\n",
      "Steps:   4%|   | 585/15000 [04:57<43:02,  5.58it/s, lr=7.17e-5, step_loss=0.229]07/27/2023 17:49:47 - INFO - __main__ - train loss is 34.89366984204389\n",
      "Steps:   4%| | 586/15000 [04:57<43:08,  5.57it/s, lr=7.19e-5, step_loss=0.00144]07/27/2023 17:49:47 - INFO - __main__ - train loss is 34.94869072572328\n",
      "Steps:   4%|▏   | 587/15000 [04:57<43:08,  5.57it/s, lr=7.2e-5, step_loss=0.055]07/27/2023 17:49:47 - INFO - __main__ - train loss is 35.07012473628856\n",
      "Steps:   4%|   | 588/15000 [04:58<43:25,  5.53it/s, lr=7.21e-5, step_loss=0.121]07/27/2023 17:49:47 - INFO - __main__ - train loss is 35.07462527253665\n",
      "Steps:   4%|  | 589/15000 [04:58<43:16,  5.55it/s, lr=7.22e-5, step_loss=0.0045]07/27/2023 17:49:48 - INFO - __main__ - train loss is 35.44234396913089\n",
      "Steps:   4%|   | 590/15000 [04:58<43:10,  5.56it/s, lr=7.24e-5, step_loss=0.368]07/27/2023 17:49:48 - INFO - __main__ - train loss is 35.47280180663802\n",
      "Steps:   4%|  | 591/15000 [04:58<43:05,  5.57it/s, lr=7.25e-5, step_loss=0.0305]07/27/2023 17:49:48 - INFO - __main__ - train loss is 35.616354452678934\n",
      "Steps:   4%|   | 592/15000 [04:58<43:00,  5.58it/s, lr=7.26e-5, step_loss=0.144]07/27/2023 17:49:48 - INFO - __main__ - train loss is 35.636912198970094\n",
      "Steps:   4%|  | 593/15000 [04:59<42:56,  5.59it/s, lr=7.27e-5, step_loss=0.0206]07/27/2023 17:49:48 - INFO - __main__ - train loss is 35.83194391638972\n",
      "Steps:   4%|   | 594/15000 [04:59<42:55,  5.59it/s, lr=7.29e-5, step_loss=0.195]07/27/2023 17:49:49 - INFO - __main__ - train loss is 35.86367599875666\n",
      "Steps:   4%|   | 595/15000 [04:59<42:59,  5.58it/s, lr=7.3e-5, step_loss=0.0317]07/27/2023 17:49:49 - INFO - __main__ - train loss is 36.53066067607142\n",
      "Steps:   4%|   | 596/15000 [04:59<42:58,  5.59it/s, lr=7.31e-5, step_loss=0.667]07/27/2023 17:49:49 - INFO - __main__ - train loss is 36.927103804657236\n",
      "Steps:   4%|   | 597/15000 [04:59<42:57,  5.59it/s, lr=7.32e-5, step_loss=0.396]07/27/2023 17:49:49 - INFO - __main__ - train loss is 37.01261458010413\n",
      "Steps:   4%|  | 598/15000 [04:59<42:54,  5.59it/s, lr=7.34e-5, step_loss=0.0855]07/27/2023 17:49:49 - INFO - __main__ - train loss is 37.30411038012244\n",
      "Steps:   4%|   | 599/15000 [05:00<42:52,  5.60it/s, lr=7.35e-5, step_loss=0.291]07/27/2023 17:49:49 - INFO - __main__ - train loss is 37.30607634736225\n",
      "Steps:   4%| | 600/15000 [05:00<42:50,  5.60it/s, lr=7.36e-5, step_loss=0.00197]07/27/2023 17:49:50 - INFO - __main__ - train loss is 37.30979790259153\n",
      "Steps:   4%| | 601/15000 [05:00<42:49,  5.60it/s, lr=7.38e-5, step_loss=0.00372]07/27/2023 17:49:50 - INFO - __main__ - train loss is 37.57195838261396\n",
      "Steps:   4%|   | 602/15000 [05:00<42:50,  5.60it/s, lr=7.39e-5, step_loss=0.262]07/27/2023 17:49:50 - INFO - __main__ - train loss is 37.599141483195126\n",
      "Steps:   4%|   | 603/15000 [05:00<42:51,  5.60it/s, lr=7.4e-5, step_loss=0.0272]07/27/2023 17:49:50 - INFO - __main__ - train loss is 37.67810164857656\n",
      "Steps:   4%|   | 604/15000 [05:00<42:57,  5.59it/s, lr=7.41e-5, step_loss=0.079]07/27/2023 17:49:50 - INFO - __main__ - train loss is 37.900598739273846\n",
      "Steps:   4%|   | 605/15000 [05:01<42:56,  5.59it/s, lr=7.43e-5, step_loss=0.222]07/27/2023 17:49:51 - INFO - __main__ - train loss is 37.979832832701504\n",
      "Steps:   4%| | 606/15000 [05:01<1:00:21,  3.97it/s, lr=7.44e-5, step_loss=0.079207/27/2023 17:49:52 - INFO - __main__ - Per validation step average loss is 0.037453874945640564\n",
      "07/27/2023 17:49:52 - INFO - __main__ - Cumulative validation average loss is 0.037453874945640564\n",
      "07/27/2023 17:49:52 - INFO - __main__ - Per validation step average loss is 0.2893016040325165\n",
      "07/27/2023 17:49:52 - INFO - __main__ - Cumulative validation average loss is 0.32675547897815704\n",
      "07/27/2023 17:49:53 - INFO - __main__ - Per validation step average loss is 0.07005508244037628\n",
      "07/27/2023 17:49:53 - INFO - __main__ - Cumulative validation average loss is 0.3968105614185333\n",
      "07/27/2023 17:49:53 - INFO - __main__ - Per validation step average loss is 0.0066430941224098206\n",
      "07/27/2023 17:49:53 - INFO - __main__ - Cumulative validation average loss is 0.40345365554094315\n",
      "07/27/2023 17:49:53 - INFO - __main__ - Per validation step average loss is 0.11397989839315414\n",
      "07/27/2023 17:49:53 - INFO - __main__ - Cumulative validation average loss is 0.5174335539340973\n",
      "07/27/2023 17:49:54 - INFO - __main__ - Per validation step average loss is 0.004671294242143631\n",
      "07/27/2023 17:49:54 - INFO - __main__ - Cumulative validation average loss is 0.5221048481762409\n",
      "07/27/2023 17:49:54 - INFO - __main__ - Per validation step average loss is 0.02212967351078987\n",
      "07/27/2023 17:49:54 - INFO - __main__ - Cumulative validation average loss is 0.5442345216870308\n",
      "07/27/2023 17:49:55 - INFO - __main__ - Per validation step average loss is 0.10197329521179199\n",
      "07/27/2023 17:49:55 - INFO - __main__ - Cumulative validation average loss is 0.6462078168988228\n",
      "07/27/2023 17:49:55 - INFO - __main__ - Per validation step average loss is 0.15982483327388763\n",
      "07/27/2023 17:49:55 - INFO - __main__ - Cumulative validation average loss is 0.8060326501727104\n",
      "07/27/2023 17:49:55 - INFO - __main__ - Per validation step average loss is 0.05204208195209503\n",
      "07/27/2023 17:49:55 - INFO - __main__ - Cumulative validation average loss is 0.8580747321248055\n",
      "07/27/2023 17:49:56 - INFO - __main__ - Per validation step average loss is 0.25399482250213623\n",
      "07/27/2023 17:49:56 - INFO - __main__ - Cumulative validation average loss is 1.1120695546269417\n",
      "07/27/2023 17:49:56 - INFO - __main__ - Per validation step average loss is 0.012493906542658806\n",
      "07/27/2023 17:49:56 - INFO - __main__ - Cumulative validation average loss is 1.1245634611696005\n",
      "07/27/2023 17:49:57 - INFO - __main__ - Per validation step average loss is 0.011202804744243622\n",
      "07/27/2023 17:49:57 - INFO - __main__ - Cumulative validation average loss is 1.135766265913844\n",
      "07/27/2023 17:49:57 - INFO - __main__ - Per validation step average loss is 0.004492724314332008\n",
      "07/27/2023 17:49:57 - INFO - __main__ - Cumulative validation average loss is 1.1402589902281761\n",
      "07/27/2023 17:49:57 - INFO - __main__ - Per validation step average loss is 0.07865925133228302\n",
      "07/27/2023 17:49:57 - INFO - __main__ - Cumulative validation average loss is 1.2189182415604591\n",
      "07/27/2023 17:49:58 - INFO - __main__ - Per validation step average loss is 0.28915947675704956\n",
      "07/27/2023 17:49:58 - INFO - __main__ - Cumulative validation average loss is 1.5080777183175087\n",
      "07/27/2023 17:49:58 - INFO - __main__ - Per validation step average loss is 0.17439383268356323\n",
      "07/27/2023 17:49:58 - INFO - __main__ - Cumulative validation average loss is 1.682471551001072\n",
      "07/27/2023 17:49:59 - INFO - __main__ - Per validation step average loss is 0.004513384774327278\n",
      "07/27/2023 17:49:59 - INFO - __main__ - Cumulative validation average loss is 1.6869849357753992\n",
      "07/27/2023 17:49:59 - INFO - __main__ - Per validation step average loss is 0.3624623715877533\n",
      "07/27/2023 17:49:59 - INFO - __main__ - Cumulative validation average loss is 2.0494473073631525\n",
      "07/27/2023 17:50:00 - INFO - __main__ - Per validation step average loss is 0.0028018634766340256\n",
      "07/27/2023 17:50:00 - INFO - __main__ - Cumulative validation average loss is 2.0522491708397865\n",
      "07/27/2023 17:50:00 - INFO - __main__ - Per validation step average loss is 0.0014798043994233012\n",
      "07/27/2023 17:50:00 - INFO - __main__ - Cumulative validation average loss is 2.05372897523921\n",
      "07/27/2023 17:50:00 - INFO - __main__ - Per validation step average loss is 0.030732400715351105\n",
      "07/27/2023 17:50:00 - INFO - __main__ - Cumulative validation average loss is 2.084461375954561\n",
      "07/27/2023 17:50:01 - INFO - __main__ - Per validation step average loss is 0.007530301343649626\n",
      "07/27/2023 17:50:01 - INFO - __main__ - Cumulative validation average loss is 2.0919916772982106\n",
      "07/27/2023 17:50:01 - INFO - __main__ - Per validation step average loss is 0.004986096639186144\n",
      "07/27/2023 17:50:01 - INFO - __main__ - Cumulative validation average loss is 2.0969777739373967\n",
      "07/27/2023 17:50:02 - INFO - __main__ - Per validation step average loss is 0.04463276267051697\n",
      "07/27/2023 17:50:02 - INFO - __main__ - Cumulative validation average loss is 2.1416105366079137\n",
      "07/27/2023 17:50:02 - INFO - __main__ - Per validation step average loss is 0.20835572481155396\n",
      "07/27/2023 17:50:02 - INFO - __main__ - Cumulative validation average loss is 2.3499662614194676\n",
      "07/27/2023 17:50:02 - INFO - __main__ - Per validation step average loss is 0.317291259765625\n",
      "07/27/2023 17:50:02 - INFO - __main__ - Cumulative validation average loss is 2.6672575211850926\n",
      "07/27/2023 17:50:03 - INFO - __main__ - Per validation step average loss is 0.05513814091682434\n",
      "07/27/2023 17:50:03 - INFO - __main__ - Cumulative validation average loss is 2.722395662101917\n",
      "07/27/2023 17:50:03 - INFO - __main__ - Per validation step average loss is 0.46554744243621826\n",
      "07/27/2023 17:50:03 - INFO - __main__ - Cumulative validation average loss is 3.1879431045381352\n",
      "07/27/2023 17:50:04 - INFO - __main__ - Per validation step average loss is 0.02338576316833496\n",
      "07/27/2023 17:50:04 - INFO - __main__ - Cumulative validation average loss is 3.21132886770647\n",
      "07/27/2023 17:50:04 - INFO - __main__ - Per validation step average loss is 0.2117323875427246\n",
      "07/27/2023 17:50:04 - INFO - __main__ - Cumulative validation average loss is 3.423061255249195\n",
      "07/27/2023 17:50:04 - INFO - __main__ - Per validation step average loss is 0.010359210893511772\n",
      "07/27/2023 17:50:04 - INFO - __main__ - Cumulative validation average loss is 3.4334204661427066\n",
      "07/27/2023 17:50:05 - INFO - __main__ - Per validation step average loss is 0.4015549421310425\n",
      "07/27/2023 17:50:05 - INFO - __main__ - Cumulative validation average loss is 3.834975408273749\n",
      "07/27/2023 17:50:05 - INFO - __main__ - Per validation step average loss is 0.09452997148036957\n",
      "07/27/2023 17:50:05 - INFO - __main__ - Cumulative validation average loss is 3.9295053797541186\n",
      "07/27/2023 17:50:06 - INFO - __main__ - Per validation step average loss is 0.2264937162399292\n",
      "07/27/2023 17:50:06 - INFO - __main__ - Cumulative validation average loss is 4.155999095994048\n",
      "07/27/2023 17:50:06 - INFO - __main__ - Per validation step average loss is 0.07595601677894592\n",
      "07/27/2023 17:50:06 - INFO - __main__ - Cumulative validation average loss is 4.231955112772994\n",
      "07/27/2023 17:50:07 - INFO - __main__ - Per validation step average loss is 0.10315212607383728\n",
      "07/27/2023 17:50:07 - INFO - __main__ - Cumulative validation average loss is 4.335107238846831\n",
      "07/27/2023 17:50:07 - INFO - __main__ - Per validation step average loss is 0.4010326862335205\n",
      "07/27/2023 17:50:07 - INFO - __main__ - Cumulative validation average loss is 4.7361399250803515\n",
      "07/27/2023 17:50:07 - INFO - __main__ - Per validation step average loss is 0.005209104157984257\n",
      "07/27/2023 17:50:07 - INFO - __main__ - Cumulative validation average loss is 4.741349029238336\n",
      "07/27/2023 17:50:08 - INFO - __main__ - Per validation step average loss is 0.49866798520088196\n",
      "07/27/2023 17:50:08 - INFO - __main__ - Cumulative validation average loss is 5.240017014439218\n",
      "07/27/2023 17:50:08 - INFO - __main__ - Per validation step average loss is 0.15666532516479492\n",
      "07/27/2023 17:50:08 - INFO - __main__ - Cumulative validation average loss is 5.396682339604013\n",
      "07/27/2023 17:50:09 - INFO - __main__ - Per validation step average loss is 0.0038992080371826887\n",
      "07/27/2023 17:50:09 - INFO - __main__ - Cumulative validation average loss is 5.400581547641195\n",
      "07/27/2023 17:50:09 - INFO - __main__ - Per validation step average loss is 0.045663345605134964\n",
      "07/27/2023 17:50:09 - INFO - __main__ - Cumulative validation average loss is 5.44624489324633\n",
      "07/27/2023 17:50:09 - INFO - __main__ - Per validation step average loss is 0.09849242866039276\n",
      "07/27/2023 17:50:09 - INFO - __main__ - Cumulative validation average loss is 5.544737321906723\n",
      "07/27/2023 17:50:10 - INFO - __main__ - Per validation step average loss is 0.157861590385437\n",
      "07/27/2023 17:50:10 - INFO - __main__ - Cumulative validation average loss is 5.70259891229216\n",
      "07/27/2023 17:50:10 - INFO - __main__ - Per validation step average loss is 0.11229629069566727\n",
      "07/27/2023 17:50:10 - INFO - __main__ - Cumulative validation average loss is 5.814895202987827\n",
      "07/27/2023 17:50:11 - INFO - __main__ - Per validation step average loss is 0.05159452185034752\n",
      "07/27/2023 17:50:11 - INFO - __main__ - Cumulative validation average loss is 5.866489724838175\n",
      "07/27/2023 17:50:11 - INFO - __main__ - Per validation step average loss is 0.018545053899288177\n",
      "07/27/2023 17:50:11 - INFO - __main__ - Cumulative validation average loss is 5.885034778737463\n",
      "07/27/2023 17:50:11 - INFO - __main__ - Per validation step average loss is 0.02710746042430401\n",
      "07/27/2023 17:50:11 - INFO - __main__ - Cumulative validation average loss is 5.912142239161767\n",
      "07/27/2023 17:50:12 - INFO - __main__ - Per validation step average loss is 0.010864085517823696\n",
      "07/27/2023 17:50:12 - INFO - __main__ - Cumulative validation average loss is 5.923006324679591\n",
      "07/27/2023 17:50:12 - INFO - __main__ - Per validation step average loss is 0.5064737796783447\n",
      "07/27/2023 17:50:12 - INFO - __main__ - Cumulative validation average loss is 6.4294801043579355\n",
      "07/27/2023 17:50:13 - INFO - __main__ - Per validation step average loss is 0.04860842227935791\n",
      "07/27/2023 17:50:13 - INFO - __main__ - Cumulative validation average loss is 6.478088526637293\n",
      "07/27/2023 17:50:13 - INFO - __main__ - Per validation step average loss is 0.22351694107055664\n",
      "07/27/2023 17:50:13 - INFO - __main__ - Cumulative validation average loss is 6.70160546770785\n",
      "07/27/2023 17:50:13 - INFO - __main__ - Per validation step average loss is 0.041365355253219604\n",
      "07/27/2023 17:50:13 - INFO - __main__ - Cumulative validation average loss is 6.74297082296107\n",
      "07/27/2023 17:50:14 - INFO - __main__ - Per validation step average loss is 0.0403977707028389\n",
      "07/27/2023 17:50:14 - INFO - __main__ - Cumulative validation average loss is 6.7833685936639085\n",
      "07/27/2023 17:50:14 - INFO - __main__ - Per validation step average loss is 0.04266274720430374\n",
      "07/27/2023 17:50:14 - INFO - __main__ - Cumulative validation average loss is 6.826031340868212\n",
      "07/27/2023 17:50:15 - INFO - __main__ - Per validation step average loss is 0.06465774029493332\n",
      "07/27/2023 17:50:15 - INFO - __main__ - Cumulative validation average loss is 6.890689081163146\n",
      "07/27/2023 17:50:15 - INFO - __main__ - Per validation step average loss is 0.059435099363327026\n",
      "07/27/2023 17:50:15 - INFO - __main__ - Cumulative validation average loss is 6.950124180526473\n",
      "07/27/2023 17:50:16 - INFO - __main__ - Per validation step average loss is 0.33330199122428894\n",
      "07/27/2023 17:50:16 - INFO - __main__ - Cumulative validation average loss is 7.283426171750762\n",
      "07/27/2023 17:50:16 - INFO - __main__ - Per validation step average loss is 0.006932789459824562\n",
      "07/27/2023 17:50:16 - INFO - __main__ - Cumulative validation average loss is 7.290358961210586\n",
      "07/27/2023 17:50:16 - INFO - __main__ - Per validation step average loss is 0.009718768298625946\n",
      "07/27/2023 17:50:16 - INFO - __main__ - Cumulative validation average loss is 7.300077729509212\n",
      "07/27/2023 17:50:17 - INFO - __main__ - Per validation step average loss is 0.1701454222202301\n",
      "07/27/2023 17:50:17 - INFO - __main__ - Cumulative validation average loss is 7.470223151729442\n",
      "07/27/2023 17:50:17 - INFO - __main__ - Per validation step average loss is 0.3395514190196991\n",
      "07/27/2023 17:50:17 - INFO - __main__ - Cumulative validation average loss is 7.809774570749141\n",
      "07/27/2023 17:50:18 - INFO - __main__ - Per validation step average loss is 0.36769843101501465\n",
      "07/27/2023 17:50:18 - INFO - __main__ - Cumulative validation average loss is 8.177473001764156\n",
      "07/27/2023 17:50:18 - INFO - __main__ - Per validation step average loss is 0.005086543969810009\n",
      "07/27/2023 17:50:18 - INFO - __main__ - Cumulative validation average loss is 8.182559545733966\n",
      "07/27/2023 17:50:18 - INFO - __main__ - Per validation step average loss is 0.035643551498651505\n",
      "07/27/2023 17:50:18 - INFO - __main__ - Cumulative validation average loss is 8.218203097232617\n",
      "07/27/2023 17:50:19 - INFO - __main__ - Per validation step average loss is 0.009903824888169765\n",
      "07/27/2023 17:50:19 - INFO - __main__ - Cumulative validation average loss is 8.228106922120787\n",
      "07/27/2023 17:50:19 - INFO - __main__ - Per validation step average loss is 0.019544262439012527\n",
      "07/27/2023 17:50:19 - INFO - __main__ - Cumulative validation average loss is 8.2476511845598\n",
      "07/27/2023 17:50:20 - INFO - __main__ - Per validation step average loss is 0.03417021408677101\n",
      "07/27/2023 17:50:20 - INFO - __main__ - Cumulative validation average loss is 8.28182139864657\n",
      "07/27/2023 17:50:20 - INFO - __main__ - Per validation step average loss is 0.0028407350182533264\n",
      "07/27/2023 17:50:20 - INFO - __main__ - Cumulative validation average loss is 8.284662133664824\n",
      "07/27/2023 17:50:20 - INFO - __main__ - Per validation step average loss is 0.5968170166015625\n",
      "07/27/2023 17:50:20 - INFO - __main__ - Cumulative validation average loss is 8.881479150266387\n",
      "07/27/2023 17:50:21 - INFO - __main__ - Per validation step average loss is 0.38309362530708313\n",
      "07/27/2023 17:50:21 - INFO - __main__ - Cumulative validation average loss is 9.26457277557347\n",
      "07/27/2023 17:50:21 - INFO - __main__ - Per validation step average loss is 0.38966935873031616\n",
      "07/27/2023 17:50:21 - INFO - __main__ - Cumulative validation average loss is 9.654242134303786\n",
      "07/27/2023 17:50:22 - INFO - __main__ - Per validation step average loss is 0.5301278829574585\n",
      "07/27/2023 17:50:22 - INFO - __main__ - Cumulative validation average loss is 10.184370017261244\n",
      "07/27/2023 17:50:22 - INFO - __main__ - Per validation step average loss is 0.15388888120651245\n",
      "07/27/2023 17:50:22 - INFO - __main__ - Cumulative validation average loss is 10.338258898467757\n",
      "07/27/2023 17:50:22 - INFO - __main__ - Per validation step average loss is 0.006242247298359871\n",
      "07/27/2023 17:50:22 - INFO - __main__ - Cumulative validation average loss is 10.344501145766117\n",
      "07/27/2023 17:50:23 - INFO - __main__ - Per validation step average loss is 0.4752536118030548\n",
      "07/27/2023 17:50:23 - INFO - __main__ - Cumulative validation average loss is 10.819754757569171\n",
      "07/27/2023 17:50:23 - INFO - __main__ - Per validation step average loss is 0.16258695721626282\n",
      "07/27/2023 17:50:23 - INFO - __main__ - Cumulative validation average loss is 10.982341714785434\n",
      "07/27/2023 17:50:24 - INFO - __main__ - Per validation step average loss is 0.24810326099395752\n",
      "07/27/2023 17:50:24 - INFO - __main__ - Cumulative validation average loss is 11.230444975779392\n",
      "07/27/2023 17:50:24 - INFO - __main__ - Average validation loss for Epoch 1 is 0.14215753133897965\n",
      "07/27/2023 17:50:24 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 17:51:21 - INFO - __main__ - Starting epoch 2\n",
      "07/27/2023 17:51:21 - INFO - __main__ - train loss is 0.013076575472950935\n",
      "Steps:   4%| | 607/15000 [06:32<109:15:38, 27.33s/it, lr=7.45e-5, step_loss=0.0107/27/2023 17:51:21 - INFO - __main__ - train loss is 0.13722366280853748\n",
      "Steps:   4%| | 608/15000 [06:32<76:41:54, 19.19s/it, lr=7.46e-5, step_loss=0.12407/27/2023 17:51:22 - INFO - __main__ - train loss is 0.22554278559982777\n",
      "Steps:   4%| | 609/15000 [06:32<53:53:58, 13.48s/it, lr=7.48e-5, step_loss=0.08807/27/2023 17:51:22 - INFO - __main__ - train loss is 0.28294156305491924\n",
      "Steps:   4%| | 610/15000 [06:32<37:56:55,  9.49s/it, lr=7.49e-5, step_loss=0.05707/27/2023 17:51:22 - INFO - __main__ - train loss is 0.2861050176434219\n",
      "Steps:   4%| | 611/15000 [06:32<26:47:19,  6.70s/it, lr=7.5e-5, step_loss=0.003107/27/2023 17:51:22 - INFO - __main__ - train loss is 0.2956179711036384\n",
      "Steps:   4%| | 612/15000 [06:33<18:58:37,  4.75s/it, lr=7.51e-5, step_loss=0.00907/27/2023 17:51:22 - INFO - __main__ - train loss is 0.3018006766214967\n",
      "Steps:   4%| | 613/15000 [06:33<13:30:13,  3.38s/it, lr=7.52e-5, step_loss=0.00607/27/2023 17:51:23 - INFO - __main__ - train loss is 0.6375752175226808\n",
      "Steps:   4%| | 614/15000 [06:33<9:39:59,  2.42s/it, lr=7.54e-5, step_loss=0.336]07/27/2023 17:51:23 - INFO - __main__ - train loss is 0.7646258855238557\n",
      "Steps:   4%| | 615/15000 [06:33<6:58:51,  1.75s/it, lr=7.55e-5, step_loss=0.127]07/27/2023 17:51:23 - INFO - __main__ - train loss is 0.7770748371258378\n",
      "Steps:   4%| | 616/15000 [06:33<5:06:04,  1.28s/it, lr=7.56e-5, step_loss=0.012407/27/2023 17:51:23 - INFO - __main__ - train loss is 0.8381058545783162\n",
      "Steps:   4%| | 617/15000 [06:33<3:47:04,  1.06it/s, lr=7.57e-5, step_loss=0.061]07/27/2023 17:51:23 - INFO - __main__ - train loss is 1.0637180330231786\n",
      "Steps:   4%| | 618/15000 [06:34<2:51:49,  1.40it/s, lr=7.59e-5, step_loss=0.226]07/27/2023 17:51:23 - INFO - __main__ - train loss is 1.0762904770672321\n",
      "Steps:   4%| | 619/15000 [06:34<2:13:12,  1.80it/s, lr=7.6e-5, step_loss=0.0126]07/27/2023 17:51:24 - INFO - __main__ - train loss is 1.3176093585789204\n",
      "Steps:   4%| | 620/15000 [06:34<1:46:04,  2.26it/s, lr=7.61e-5, step_loss=0.241]07/27/2023 17:51:24 - INFO - __main__ - train loss is 1.4184356592595577\n",
      "Steps:   4%| | 621/15000 [06:34<1:27:11,  2.75it/s, lr=7.62e-5, step_loss=0.101]07/27/2023 17:51:24 - INFO - __main__ - train loss is 1.5398195497691631\n",
      "Steps:   4%| | 622/15000 [06:34<1:13:54,  3.24it/s, lr=7.64e-5, step_loss=0.121]07/27/2023 17:51:24 - INFO - __main__ - train loss is 1.5587841533124447\n",
      "Steps:   4%| | 623/15000 [06:34<1:04:59,  3.69it/s, lr=7.65e-5, step_loss=0.019]07/27/2023 17:51:24 - INFO - __main__ - train loss is 1.6271457187831402\n",
      "Steps:   4%|  | 624/15000 [06:35<59:10,  4.05it/s, lr=7.66e-5, step_loss=0.0684]07/27/2023 17:51:25 - INFO - __main__ - train loss is 1.764047097414732\n",
      "Steps:   4%|▏  | 625/15000 [06:35<54:57,  4.36it/s, lr=7.67e-5, step_loss=0.137]07/27/2023 17:51:25 - INFO - __main__ - train loss is 1.8458176515996456\n",
      "Steps:   4%|  | 626/15000 [06:35<51:31,  4.65it/s, lr=7.69e-5, step_loss=0.0818]07/27/2023 17:51:25 - INFO - __main__ - train loss is 1.8495373986661434\n",
      "Steps:   4%|  | 627/15000 [06:35<48:56,  4.89it/s, lr=7.7e-5, step_loss=0.00372]07/27/2023 17:51:25 - INFO - __main__ - train loss is 1.9873495511710644\n",
      "Steps:   4%|▏  | 628/15000 [06:35<47:10,  5.08it/s, lr=7.71e-5, step_loss=0.138]07/27/2023 17:51:25 - INFO - __main__ - train loss is 2.6407118253409863\n",
      "Steps:   4%|▏  | 629/15000 [06:36<46:18,  5.17it/s, lr=7.73e-5, step_loss=0.653]07/27/2023 17:51:25 - INFO - __main__ - train loss is 3.0667541436851025\n",
      "Steps:   4%|▏  | 630/15000 [06:36<45:23,  5.28it/s, lr=7.74e-5, step_loss=0.426]07/27/2023 17:51:26 - INFO - __main__ - train loss is 3.096061296761036\n",
      "Steps:   4%|  | 631/15000 [06:36<44:40,  5.36it/s, lr=7.75e-5, step_loss=0.0293]07/27/2023 17:51:26 - INFO - __main__ - train loss is 3.0975683447904885\n",
      "Steps:   4%| | 632/15000 [06:36<44:08,  5.42it/s, lr=7.76e-5, step_loss=0.00151]07/27/2023 17:51:26 - INFO - __main__ - train loss is 3.0991792326094583\n",
      "Steps:   4%| | 633/15000 [06:36<43:46,  5.47it/s, lr=7.78e-5, step_loss=0.00161]07/27/2023 17:51:26 - INFO - __main__ - train loss is 3.8059275989653543\n",
      "Steps:   4%|▏  | 634/15000 [06:36<43:32,  5.50it/s, lr=7.79e-5, step_loss=0.707]07/27/2023 17:51:26 - INFO - __main__ - train loss is 4.362676823628135\n",
      "Steps:   4%|▏   | 635/15000 [06:37<43:20,  5.52it/s, lr=7.8e-5, step_loss=0.557]07/27/2023 17:51:27 - INFO - __main__ - train loss is 4.3704410820500925\n",
      "Steps:   4%| | 636/15000 [06:37<43:12,  5.54it/s, lr=7.81e-5, step_loss=0.00776]07/27/2023 17:51:27 - INFO - __main__ - train loss is 4.674191895057447\n",
      "Steps:   4%|▏  | 637/15000 [06:37<43:06,  5.55it/s, lr=7.83e-5, step_loss=0.304]07/27/2023 17:51:27 - INFO - __main__ - train loss is 4.70607063092757\n",
      "Steps:   4%|  | 638/15000 [06:37<43:28,  5.51it/s, lr=7.84e-5, step_loss=0.0319]07/27/2023 17:51:27 - INFO - __main__ - train loss is 4.720703660626896\n",
      "Steps:   4%|  | 639/15000 [06:37<43:18,  5.53it/s, lr=7.85e-5, step_loss=0.0146]07/27/2023 17:51:27 - INFO - __main__ - train loss is 4.728626725380309\n",
      "Steps:   4%| | 640/15000 [06:38<43:12,  5.54it/s, lr=7.86e-5, step_loss=0.00792]07/27/2023 17:51:27 - INFO - __main__ - train loss is 5.0734473440097645\n",
      "Steps:   4%|▏  | 641/15000 [06:38<43:07,  5.55it/s, lr=7.88e-5, step_loss=0.345]07/27/2023 17:51:28 - INFO - __main__ - train loss is 5.101888074656017\n",
      "Steps:   4%|  | 642/15000 [06:38<43:04,  5.56it/s, lr=7.89e-5, step_loss=0.0284]07/27/2023 17:51:28 - INFO - __main__ - train loss is 5.22777368046809\n",
      "Steps:   4%|▏   | 643/15000 [06:38<43:02,  5.56it/s, lr=7.9e-5, step_loss=0.126]07/27/2023 17:51:28 - INFO - __main__ - train loss is 5.242800764855929\n",
      "Steps:   4%|▏  | 644/15000 [06:38<43:00,  5.56it/s, lr=7.91e-5, step_loss=0.015]07/27/2023 17:51:28 - INFO - __main__ - train loss is 5.52416323882062\n",
      "Steps:   4%|▏  | 645/15000 [06:38<42:59,  5.57it/s, lr=7.93e-5, step_loss=0.281]07/27/2023 17:51:28 - INFO - __main__ - train loss is 5.611346371588297\n",
      "Steps:   4%|  | 646/15000 [06:39<44:10,  5.42it/s, lr=7.94e-5, step_loss=0.0872]07/27/2023 17:51:29 - INFO - __main__ - train loss is 5.708322398480959\n",
      "Steps:   4%|▏  | 647/15000 [06:39<45:50,  5.22it/s, lr=7.95e-5, step_loss=0.097]07/27/2023 17:51:29 - INFO - __main__ - train loss is 5.957880072412081\n",
      "Steps:   4%|▏   | 648/15000 [06:39<46:10,  5.18it/s, lr=7.96e-5, step_loss=0.25]07/27/2023 17:51:29 - INFO - __main__ - train loss is 5.96014636696782\n",
      "Steps:   4%| | 649/15000 [06:39<47:48,  5.00it/s, lr=7.98e-5, step_loss=0.00227]07/27/2023 17:51:29 - INFO - __main__ - train loss is 5.973680175258778\n",
      "Steps:   4%|  | 650/15000 [06:40<48:54,  4.89it/s, lr=7.99e-5, step_loss=0.0135]07/27/2023 17:51:29 - INFO - __main__ - train loss is 6.0214178742608055\n",
      "Steps:   4%|▏    | 651/15000 [06:40<47:05,  5.08it/s, lr=8e-5, step_loss=0.0477]07/27/2023 17:51:30 - INFO - __main__ - train loss is 6.348859894438647\n",
      "Steps:   4%|▏  | 652/15000 [06:40<45:49,  5.22it/s, lr=8.01e-5, step_loss=0.327]07/27/2023 17:51:30 - INFO - __main__ - train loss is 7.022909212275408\n",
      "Steps:   4%|▏  | 653/15000 [06:40<45:04,  5.30it/s, lr=8.02e-5, step_loss=0.674]07/27/2023 17:51:30 - INFO - __main__ - train loss is 7.1806452156743035\n",
      "Steps:   4%|▏  | 654/15000 [06:40<44:38,  5.36it/s, lr=8.04e-5, step_loss=0.158]07/27/2023 17:51:30 - INFO - __main__ - train loss is 7.1831055682851\n",
      "Steps:   4%| | 655/15000 [06:40<44:06,  5.42it/s, lr=8.05e-5, step_loss=0.00246]07/27/2023 17:51:30 - INFO - __main__ - train loss is 7.21841883927118\n",
      "Steps:   4%|  | 656/15000 [06:41<43:43,  5.47it/s, lr=8.06e-5, step_loss=0.0353]07/27/2023 17:51:30 - INFO - __main__ - train loss is 7.276702451403253\n",
      "Steps:   4%|  | 657/15000 [06:41<43:28,  5.50it/s, lr=8.07e-5, step_loss=0.0583]07/27/2023 17:51:31 - INFO - __main__ - train loss is 7.288975492934696\n",
      "Steps:   4%|  | 658/15000 [06:41<43:17,  5.52it/s, lr=8.09e-5, step_loss=0.0123]07/27/2023 17:51:31 - INFO - __main__ - train loss is 7.351609812001698\n",
      "Steps:   4%|▏  | 659/15000 [06:41<43:09,  5.54it/s, lr=8.1e-5, step_loss=0.0626]07/27/2023 17:51:31 - INFO - __main__ - train loss is 7.630737737636082\n",
      "Steps:   4%|▏  | 660/15000 [06:41<43:04,  5.55it/s, lr=8.11e-5, step_loss=0.279]07/27/2023 17:51:31 - INFO - __main__ - train loss is 8.063470319728367\n",
      "Steps:   4%|▏  | 661/15000 [06:41<43:01,  5.55it/s, lr=8.13e-5, step_loss=0.433]07/27/2023 17:51:31 - INFO - __main__ - train loss is 8.394972191075794\n",
      "Steps:   4%|▏  | 662/15000 [06:42<43:03,  5.55it/s, lr=8.14e-5, step_loss=0.332]07/27/2023 17:51:32 - INFO - __main__ - train loss is 8.591563180903904\n",
      "Steps:   4%|▏  | 663/15000 [06:42<43:21,  5.51it/s, lr=8.15e-5, step_loss=0.197]07/27/2023 17:51:32 - INFO - __main__ - train loss is 8.723376364330761\n",
      "Steps:   4%|▏  | 664/15000 [06:42<43:34,  5.48it/s, lr=8.16e-5, step_loss=0.132]07/27/2023 17:51:32 - INFO - __main__ - train loss is 8.727266393485479\n",
      "Steps:   4%| | 665/15000 [06:42<43:41,  5.47it/s, lr=8.18e-5, step_loss=0.00389]07/27/2023 17:51:32 - INFO - __main__ - train loss is 8.728618369903415\n",
      "Steps:   4%| | 666/15000 [06:42<43:27,  5.50it/s, lr=8.19e-5, step_loss=0.00135]07/27/2023 17:51:32 - INFO - __main__ - train loss is 8.764718142803758\n",
      "Steps:   4%|▏  | 667/15000 [06:43<43:17,  5.52it/s, lr=8.2e-5, step_loss=0.0361]07/27/2023 17:51:32 - INFO - __main__ - train loss is 9.350995746906847\n",
      "Steps:   4%|▏  | 668/15000 [06:43<43:10,  5.53it/s, lr=8.21e-5, step_loss=0.586]07/27/2023 17:51:33 - INFO - __main__ - train loss is 9.353291997220367\n",
      "Steps:   4%|  | 669/15000 [06:43<43:05,  5.54it/s, lr=8.23e-5, step_loss=0.0023]07/27/2023 17:51:33 - INFO - __main__ - train loss is 9.43715258082375\n",
      "Steps:   4%|  | 670/15000 [06:43<43:10,  5.53it/s, lr=8.24e-5, step_loss=0.0839]07/27/2023 17:51:33 - INFO - __main__ - train loss is 9.442744628991932\n",
      "Steps:   4%| | 671/15000 [06:43<43:04,  5.54it/s, lr=8.25e-5, step_loss=0.00559]07/27/2023 17:51:33 - INFO - __main__ - train loss is 9.447225056122988\n",
      "Steps:   4%| | 672/15000 [06:43<43:04,  5.54it/s, lr=8.26e-5, step_loss=0.00448]07/27/2023 17:51:33 - INFO - __main__ - train loss is 9.661745063494891\n",
      "Steps:   4%|▏  | 673/15000 [06:44<42:59,  5.55it/s, lr=8.28e-5, step_loss=0.215]07/27/2023 17:51:34 - INFO - __main__ - train loss is 9.789669982623309\n",
      "Steps:   4%|▏  | 674/15000 [06:44<42:57,  5.56it/s, lr=8.29e-5, step_loss=0.128]07/27/2023 17:51:34 - INFO - __main__ - train loss is 9.859804458450526\n",
      "Steps:   4%|▏  | 675/15000 [06:44<43:12,  5.53it/s, lr=8.3e-5, step_loss=0.0701]07/27/2023 17:51:34 - INFO - __main__ - train loss is 9.96611214382574\n",
      "Steps:   5%|▏  | 676/15000 [06:44<43:30,  5.49it/s, lr=8.31e-5, step_loss=0.106]07/27/2023 17:51:34 - INFO - __main__ - train loss is 10.027066230308264\n",
      "Steps:   5%|▏  | 677/15000 [06:44<43:25,  5.50it/s, lr=8.33e-5, step_loss=0.061]07/27/2023 17:51:34 - INFO - __main__ - train loss is 10.068992696236819\n",
      "Steps:   5%|  | 678/15000 [06:45<43:14,  5.52it/s, lr=8.34e-5, step_loss=0.0419]07/27/2023 17:51:34 - INFO - __main__ - train loss is 10.072095765266567\n",
      "Steps:   5%|  | 679/15000 [06:45<43:06,  5.54it/s, lr=8.35e-5, step_loss=0.0031]07/27/2023 17:51:35 - INFO - __main__ - train loss is 10.17240950325504\n",
      "Steps:   5%|▏    | 680/15000 [06:45<42:59,  5.55it/s, lr=8.36e-5, step_loss=0.1]07/27/2023 17:51:35 - INFO - __main__ - train loss is 10.187054534908384\n",
      "Steps:   5%|  | 681/15000 [06:45<42:54,  5.56it/s, lr=8.38e-5, step_loss=0.0146]07/27/2023 17:51:35 - INFO - __main__ - train loss is 10.218717699404806\n",
      "Steps:   5%|  | 682/15000 [06:45<42:52,  5.57it/s, lr=8.39e-5, step_loss=0.0317]07/27/2023 17:51:35 - INFO - __main__ - train loss is 10.266495147254318\n",
      "Steps:   5%|▏  | 683/15000 [06:45<42:51,  5.57it/s, lr=8.4e-5, step_loss=0.0478]07/27/2023 17:51:35 - INFO - __main__ - train loss is 10.400054657366127\n",
      "Steps:   5%|▏  | 684/15000 [06:46<42:52,  5.56it/s, lr=8.41e-5, step_loss=0.134]07/27/2023 17:51:36 - INFO - __main__ - train loss is 10.482383096124977\n",
      "Steps:   5%|  | 685/15000 [06:46<43:00,  5.55it/s, lr=8.43e-5, step_loss=0.0823]07/27/2023 17:51:36 - INFO - __main__ - train loss is 10.48641935409978\n",
      "Steps:   5%| | 686/15000 [06:46<42:57,  5.55it/s, lr=8.44e-5, step_loss=0.00404]07/27/2023 17:51:36 - INFO - __main__ - train loss is 10.515920907724649\n",
      "Steps:   5%|  | 687/15000 [06:46<42:54,  5.56it/s, lr=8.45e-5, step_loss=0.0295]07/27/2023 17:51:36 - INFO - __main__ - train loss is 10.567056544590741\n",
      "Steps:   5%|  | 688/15000 [06:46<42:52,  5.56it/s, lr=8.46e-5, step_loss=0.0511]07/27/2023 17:51:36 - INFO - __main__ - train loss is 10.585916636977345\n",
      "Steps:   5%|  | 689/15000 [06:47<42:51,  5.57it/s, lr=8.48e-5, step_loss=0.0189]07/27/2023 17:51:36 - INFO - __main__ - train loss is 10.646722751203924\n",
      "Steps:   5%|  | 690/15000 [06:47<42:49,  5.57it/s, lr=8.49e-5, step_loss=0.0608]07/27/2023 17:51:37 - INFO - __main__ - train loss is 10.717527049127966\n",
      "Steps:   5%|▏  | 691/15000 [06:47<42:47,  5.57it/s, lr=8.5e-5, step_loss=0.0708]07/27/2023 17:51:37 - INFO - __main__ - train loss is 10.737125965300947\n",
      "Steps:   5%|  | 692/15000 [06:47<42:48,  5.57it/s, lr=8.51e-5, step_loss=0.0196]07/27/2023 17:51:37 - INFO - __main__ - train loss is 10.754729383159429\n",
      "Steps:   5%|  | 693/15000 [06:47<42:54,  5.56it/s, lr=8.53e-5, step_loss=0.0176]07/27/2023 17:51:37 - INFO - __main__ - train loss is 10.81937674479559\n",
      "Steps:   5%|  | 694/15000 [06:47<42:52,  5.56it/s, lr=8.54e-5, step_loss=0.0646]07/27/2023 17:51:37 - INFO - __main__ - train loss is 10.824019980151206\n",
      "Steps:   5%| | 695/15000 [06:48<42:51,  5.56it/s, lr=8.55e-5, step_loss=0.00464]07/27/2023 17:51:37 - INFO - __main__ - train loss is 10.827089238446206\n",
      "Steps:   5%| | 696/15000 [06:48<42:51,  5.56it/s, lr=8.56e-5, step_loss=0.00307]07/27/2023 17:51:38 - INFO - __main__ - train loss is 10.990670803468674\n",
      "Steps:   5%|▏  | 697/15000 [06:48<42:50,  5.56it/s, lr=8.58e-5, step_loss=0.164]07/27/2023 17:51:38 - INFO - __main__ - train loss is 11.007496788632125\n",
      "Steps:   5%|  | 698/15000 [06:48<42:49,  5.57it/s, lr=8.59e-5, step_loss=0.0168]07/27/2023 17:51:38 - INFO - __main__ - train loss is 11.038136582355946\n",
      "Steps:   5%|▏  | 699/15000 [06:48<42:46,  5.57it/s, lr=8.6e-5, step_loss=0.0306]07/27/2023 17:51:38 - INFO - __main__ - train loss is 11.049731753300875\n",
      "Steps:   5%|  | 700/15000 [06:49<43:02,  5.54it/s, lr=8.61e-5, step_loss=0.0116]07/27/2023 17:51:38 - INFO - __main__ - train loss is 11.739632747601718\n",
      "Steps:   5%|▏   | 701/15000 [06:49<42:59,  5.54it/s, lr=8.62e-5, step_loss=0.69]07/27/2023 17:51:39 - INFO - __main__ - train loss is 11.745347844436765\n",
      "Steps:   5%| | 702/15000 [06:49<43:06,  5.53it/s, lr=8.64e-5, step_loss=0.00572]07/27/2023 17:51:39 - INFO - __main__ - train loss is 12.03629724867642\n",
      "Steps:   5%|▏  | 703/15000 [06:49<43:00,  5.54it/s, lr=8.65e-5, step_loss=0.291]07/27/2023 17:51:39 - INFO - __main__ - train loss is 12.681041883304715\n",
      "Steps:   5%|▏  | 704/15000 [06:49<42:54,  5.55it/s, lr=8.66e-5, step_loss=0.645]07/27/2023 17:51:39 - INFO - __main__ - train loss is 12.948260175064206\n",
      "Steps:   5%|▏  | 705/15000 [06:49<42:51,  5.56it/s, lr=8.67e-5, step_loss=0.267]07/27/2023 17:51:39 - INFO - __main__ - train loss is 13.147032232955098\n",
      "Steps:   5%|▏  | 706/15000 [06:50<42:53,  5.56it/s, lr=8.69e-5, step_loss=0.199]07/27/2023 17:51:39 - INFO - __main__ - train loss is 13.171189138665795\n",
      "Steps:   5%|▏  | 707/15000 [06:50<42:50,  5.56it/s, lr=8.7e-5, step_loss=0.0242]07/27/2023 17:51:40 - INFO - __main__ - train loss is 13.563658216968179\n",
      "Steps:   5%|▏  | 708/15000 [06:50<43:02,  5.53it/s, lr=8.71e-5, step_loss=0.392]07/27/2023 17:51:40 - INFO - __main__ - train loss is 13.613487301394343\n",
      "Steps:   5%|  | 709/15000 [06:50<42:55,  5.55it/s, lr=8.72e-5, step_loss=0.0498]07/27/2023 17:51:40 - INFO - __main__ - train loss is 13.737999161705375\n",
      "Steps:   5%|▏  | 710/15000 [06:50<42:51,  5.56it/s, lr=8.74e-5, step_loss=0.125]07/27/2023 17:51:40 - INFO - __main__ - train loss is 14.320260962471366\n",
      "Steps:   5%|▏  | 711/15000 [06:50<42:48,  5.56it/s, lr=8.75e-5, step_loss=0.582]07/27/2023 17:51:40 - INFO - __main__ - train loss is 14.33736508525908\n",
      "Steps:   5%|  | 712/15000 [06:51<42:46,  5.57it/s, lr=8.76e-5, step_loss=0.0171]07/27/2023 17:51:41 - INFO - __main__ - train loss is 14.626978123560548\n",
      "Steps:   5%|▏   | 713/15000 [06:51<42:45,  5.57it/s, lr=8.77e-5, step_loss=0.29]07/27/2023 17:51:41 - INFO - __main__ - train loss is 14.714784311130643\n",
      "Steps:   5%|  | 714/15000 [06:51<42:44,  5.57it/s, lr=8.79e-5, step_loss=0.0878]07/27/2023 17:51:41 - INFO - __main__ - train loss is 14.925645055249333\n",
      "Steps:   5%|▏   | 715/15000 [06:51<43:13,  5.51it/s, lr=8.8e-5, step_loss=0.211]07/27/2023 17:51:41 - INFO - __main__ - train loss is 15.350890459492803\n",
      "Steps:   5%|▏  | 716/15000 [06:51<43:49,  5.43it/s, lr=8.81e-5, step_loss=0.425]07/27/2023 17:51:41 - INFO - __main__ - train loss is 15.387666733935475\n",
      "Steps:   5%|  | 717/15000 [06:52<43:29,  5.47it/s, lr=8.82e-5, step_loss=0.0368]07/27/2023 17:51:41 - INFO - __main__ - train loss is 15.972951920703053\n",
      "Steps:   5%|▏  | 718/15000 [06:52<43:15,  5.50it/s, lr=8.84e-5, step_loss=0.585]07/27/2023 17:51:42 - INFO - __main__ - train loss is 15.988544804044068\n",
      "Steps:   5%|  | 719/15000 [06:52<43:08,  5.52it/s, lr=8.85e-5, step_loss=0.0156]07/27/2023 17:51:42 - INFO - __main__ - train loss is 16.30288462061435\n",
      "Steps:   5%|▏  | 720/15000 [06:52<43:21,  5.49it/s, lr=8.86e-5, step_loss=0.314]07/27/2023 17:51:42 - INFO - __main__ - train loss is 16.43357439059764\n",
      "Steps:   5%|▏  | 721/15000 [06:52<43:37,  5.46it/s, lr=8.88e-5, step_loss=0.131]07/27/2023 17:51:42 - INFO - __main__ - train loss is 16.452467218972743\n",
      "Steps:   5%|  | 722/15000 [06:53<43:55,  5.42it/s, lr=8.89e-5, step_loss=0.0189]07/27/2023 17:51:42 - INFO - __main__ - train loss is 16.47565328795463\n",
      "Steps:   5%|▏  | 723/15000 [06:53<43:49,  5.43it/s, lr=8.9e-5, step_loss=0.0232]07/27/2023 17:51:43 - INFO - __main__ - train loss is 16.53141324687749\n",
      "Steps:   5%|  | 724/15000 [06:53<43:40,  5.45it/s, lr=8.91e-5, step_loss=0.0558]07/27/2023 17:51:43 - INFO - __main__ - train loss is 16.573564906604588\n",
      "Steps:   5%|  | 725/15000 [06:53<43:34,  5.46it/s, lr=8.93e-5, step_loss=0.0422]07/27/2023 17:51:43 - INFO - __main__ - train loss is 16.652685997076333\n",
      "Steps:   5%|  | 726/15000 [06:53<43:44,  5.44it/s, lr=8.94e-5, step_loss=0.0791]07/27/2023 17:51:43 - INFO - __main__ - train loss is 16.92135548312217\n",
      "Steps:   5%|▏  | 727/15000 [06:53<43:26,  5.48it/s, lr=8.95e-5, step_loss=0.269]07/27/2023 17:51:43 - INFO - __main__ - train loss is 16.952164967544377\n",
      "Steps:   5%|  | 728/15000 [06:54<43:14,  5.50it/s, lr=8.96e-5, step_loss=0.0308]07/27/2023 17:51:43 - INFO - __main__ - train loss is 16.979084179736674\n",
      "Steps:   5%|  | 729/15000 [06:54<43:05,  5.52it/s, lr=8.97e-5, step_loss=0.0269]07/27/2023 17:51:44 - INFO - __main__ - train loss is 16.987894001416862\n",
      "Steps:   5%| | 730/15000 [06:54<43:22,  5.48it/s, lr=8.99e-5, step_loss=0.00881]07/27/2023 17:51:44 - INFO - __main__ - train loss is 16.99098991136998\n",
      "Steps:   5%|▏    | 731/15000 [06:54<43:29,  5.47it/s, lr=9e-5, step_loss=0.0031]07/27/2023 17:51:44 - INFO - __main__ - train loss is 17.00277804862708\n",
      "Steps:   5%|  | 732/15000 [06:54<43:30,  5.47it/s, lr=9.01e-5, step_loss=0.0118]07/27/2023 17:51:44 - INFO - __main__ - train loss is 17.01853393483907\n",
      "Steps:   5%|  | 733/15000 [06:55<43:16,  5.50it/s, lr=9.02e-5, step_loss=0.0158]07/27/2023 17:51:44 - INFO - __main__ - train loss is 17.029827998951077\n",
      "Steps:   5%|  | 734/15000 [06:55<43:12,  5.50it/s, lr=9.04e-5, step_loss=0.0113]07/27/2023 17:51:45 - INFO - __main__ - train loss is 17.187932329252362\n",
      "Steps:   5%|▏  | 735/15000 [06:55<43:04,  5.52it/s, lr=9.05e-5, step_loss=0.158]07/27/2023 17:51:45 - INFO - __main__ - train loss is 17.211049219593406\n",
      "Steps:   5%|  | 736/15000 [06:55<42:57,  5.53it/s, lr=9.06e-5, step_loss=0.0231]07/27/2023 17:51:45 - INFO - __main__ - train loss is 17.335215656086802\n",
      "Steps:   5%|▏  | 737/15000 [06:55<43:10,  5.51it/s, lr=9.07e-5, step_loss=0.124]07/27/2023 17:51:45 - INFO - __main__ - train loss is 17.616665510460734\n",
      "Steps:   5%|▏  | 738/15000 [06:55<43:01,  5.52it/s, lr=9.09e-5, step_loss=0.281]07/27/2023 17:51:45 - INFO - __main__ - train loss is 17.77107742242515\n",
      "Steps:   5%|▏   | 739/15000 [06:56<43:10,  5.51it/s, lr=9.1e-5, step_loss=0.154]07/27/2023 17:51:45 - INFO - __main__ - train loss is 17.89895728044212\n",
      "Steps:   5%|▏  | 740/15000 [06:56<43:24,  5.48it/s, lr=9.11e-5, step_loss=0.128]07/27/2023 17:51:46 - INFO - __main__ - train loss is 17.902593097649515\n",
      "Steps:   5%| | 741/15000 [06:56<43:19,  5.48it/s, lr=9.12e-5, step_loss=0.00364]07/27/2023 17:51:46 - INFO - __main__ - train loss is 17.90705357864499\n",
      "Steps:   5%| | 742/15000 [06:56<43:31,  5.46it/s, lr=9.14e-5, step_loss=0.00446]07/27/2023 17:51:46 - INFO - __main__ - train loss is 17.929705563932657\n",
      "Steps:   5%|  | 743/15000 [06:56<43:23,  5.48it/s, lr=9.15e-5, step_loss=0.0227]07/27/2023 17:51:46 - INFO - __main__ - train loss is 18.024151999503374\n",
      "Steps:   5%|  | 744/15000 [06:57<43:13,  5.50it/s, lr=9.16e-5, step_loss=0.0944]07/27/2023 17:51:46 - INFO - __main__ - train loss is 18.09252331778407\n",
      "Steps:   5%|  | 745/15000 [06:57<43:02,  5.52it/s, lr=9.17e-5, step_loss=0.0684]07/27/2023 17:51:47 - INFO - __main__ - train loss is 18.612774770706892\n",
      "Steps:   5%|▏   | 746/15000 [06:57<42:54,  5.54it/s, lr=9.19e-5, step_loss=0.52]07/27/2023 17:51:47 - INFO - __main__ - train loss is 18.631852958351374\n",
      "Steps:   5%|▏  | 747/15000 [06:57<42:50,  5.55it/s, lr=9.2e-5, step_loss=0.0191]07/27/2023 17:51:47 - INFO - __main__ - train loss is 19.094560001045465\n",
      "Steps:   5%|▏  | 748/15000 [06:57<42:46,  5.55it/s, lr=9.21e-5, step_loss=0.463]07/27/2023 17:51:47 - INFO - __main__ - train loss is 19.126816418021917\n",
      "Steps:   5%|  | 749/15000 [06:57<42:43,  5.56it/s, lr=9.23e-5, step_loss=0.0323]07/27/2023 17:51:47 - INFO - __main__ - train loss is 19.242508199065924\n",
      "Steps:   5%|▏  | 750/15000 [06:58<42:40,  5.57it/s, lr=9.24e-5, step_loss=0.116]07/27/2023 17:51:47 - INFO - __main__ - train loss is 19.347325306385756\n",
      "Steps:   5%|▏  | 751/15000 [06:58<43:00,  5.52it/s, lr=9.25e-5, step_loss=0.105]07/27/2023 17:51:48 - INFO - __main__ - train loss is 19.883669178932905\n",
      "Steps:   5%|▏  | 752/15000 [06:58<43:16,  5.49it/s, lr=9.26e-5, step_loss=0.536]07/27/2023 17:51:48 - INFO - __main__ - train loss is 19.907759187743068\n",
      "Steps:   5%|  | 753/15000 [06:58<43:24,  5.47it/s, lr=9.28e-5, step_loss=0.0241]07/27/2023 17:51:48 - INFO - __main__ - train loss is 20.015718368813396\n",
      "Steps:   5%|▏  | 754/15000 [06:58<43:22,  5.47it/s, lr=9.29e-5, step_loss=0.108]07/27/2023 17:51:48 - INFO - __main__ - train loss is 20.060894472524524\n",
      "Steps:   5%|▏  | 755/15000 [06:59<43:21,  5.48it/s, lr=9.3e-5, step_loss=0.0452]07/27/2023 17:51:48 - INFO - __main__ - train loss is 20.067935184109956\n",
      "Steps:   5%| | 756/15000 [06:59<43:08,  5.50it/s, lr=9.31e-5, step_loss=0.00704]07/27/2023 17:51:49 - INFO - __main__ - train loss is 20.109772671479732\n",
      "Steps:   5%|  | 757/15000 [06:59<42:59,  5.52it/s, lr=9.33e-5, step_loss=0.0418]07/27/2023 17:51:49 - INFO - __main__ - train loss is 20.11637256992981\n",
      "Steps:   5%|  | 758/15000 [06:59<43:07,  5.50it/s, lr=9.34e-5, step_loss=0.0066]07/27/2023 17:51:49 - INFO - __main__ - train loss is 20.263807370793074\n",
      "Steps:   5%|▏  | 759/15000 [06:59<42:56,  5.53it/s, lr=9.35e-5, step_loss=0.147]07/27/2023 17:51:49 - INFO - __main__ - train loss is 20.27348517952487\n",
      "Steps:   5%| | 760/15000 [06:59<42:47,  5.55it/s, lr=9.36e-5, step_loss=0.00968]07/27/2023 17:51:49 - INFO - __main__ - train loss is 20.28038532566279\n",
      "Steps:   5%|  | 761/15000 [07:00<42:43,  5.55it/s, lr=9.38e-5, step_loss=0.0069]07/27/2023 17:51:49 - INFO - __main__ - train loss is 20.283565427875146\n",
      "Steps:   5%| | 762/15000 [07:00<42:39,  5.56it/s, lr=9.39e-5, step_loss=0.00318]07/27/2023 17:51:50 - INFO - __main__ - train loss is 20.336252618348226\n",
      "Steps:   5%|▏  | 763/15000 [07:00<42:37,  5.57it/s, lr=9.4e-5, step_loss=0.0527]07/27/2023 17:51:50 - INFO - __main__ - train loss is 20.575461227213964\n",
      "Steps:   5%|▏  | 764/15000 [07:00<42:35,  5.57it/s, lr=9.41e-5, step_loss=0.239]07/27/2023 17:51:50 - INFO - __main__ - train loss is 20.636081654345617\n",
      "Steps:   5%|  | 765/15000 [07:00<42:58,  5.52it/s, lr=9.43e-5, step_loss=0.0606]07/27/2023 17:51:50 - INFO - __main__ - train loss is 20.637784144375473\n",
      "Steps:   5%|  | 766/15000 [07:00<42:50,  5.54it/s, lr=9.44e-5, step_loss=0.0017]07/27/2023 17:51:50 - INFO - __main__ - train loss is 20.68264919379726\n",
      "Steps:   5%|  | 767/15000 [07:01<42:44,  5.55it/s, lr=9.45e-5, step_loss=0.0449]07/27/2023 17:51:51 - INFO - __main__ - train loss is 20.72702886397019\n",
      "Steps:   5%|  | 768/15000 [07:01<42:39,  5.56it/s, lr=9.46e-5, step_loss=0.0444]07/27/2023 17:51:51 - INFO - __main__ - train loss is 20.73287409171462\n",
      "Steps:   5%| | 769/15000 [07:01<42:35,  5.57it/s, lr=9.47e-5, step_loss=0.00585]07/27/2023 17:51:51 - INFO - __main__ - train loss is 20.741396233439445\n",
      "Steps:   5%| | 770/15000 [07:01<42:33,  5.57it/s, lr=9.49e-5, step_loss=0.00852]07/27/2023 17:51:51 - INFO - __main__ - train loss is 20.745519927237183\n",
      "Steps:   5%|  | 771/15000 [07:01<42:52,  5.53it/s, lr=9.5e-5, step_loss=0.00412]07/27/2023 17:51:51 - INFO - __main__ - train loss is 20.756690706592053\n",
      "Steps:   5%|  | 772/15000 [07:02<43:16,  5.48it/s, lr=9.51e-5, step_loss=0.0112]07/27/2023 17:51:51 - INFO - __main__ - train loss is 20.765514394734055\n",
      "Steps:   5%| | 773/15000 [07:02<43:11,  5.49it/s, lr=9.52e-5, step_loss=0.00882]07/27/2023 17:51:52 - INFO - __main__ - train loss is 21.355251035187393\n",
      "Steps:   5%|▏   | 774/15000 [07:02<43:15,  5.48it/s, lr=9.54e-5, step_loss=0.59]07/27/2023 17:51:52 - INFO - __main__ - train loss is 21.400527762714773\n",
      "Steps:   5%|  | 775/15000 [07:02<43:01,  5.51it/s, lr=9.55e-5, step_loss=0.0453]07/27/2023 17:51:52 - INFO - __main__ - train loss is 21.47295986348763\n",
      "Steps:   5%|  | 776/15000 [07:02<42:54,  5.52it/s, lr=9.56e-5, step_loss=0.0724]07/27/2023 17:51:52 - INFO - __main__ - train loss is 21.556248562876135\n",
      "Steps:   5%|  | 777/15000 [07:02<42:49,  5.53it/s, lr=9.58e-5, step_loss=0.0833]07/27/2023 17:51:52 - INFO - __main__ - train loss is 21.573936867062002\n",
      "Steps:   5%|  | 778/15000 [07:03<42:43,  5.55it/s, lr=9.59e-5, step_loss=0.0177]07/27/2023 17:51:53 - INFO - __main__ - train loss is 21.87322964007035\n",
      "Steps:   5%|▏   | 779/15000 [07:03<43:02,  5.51it/s, lr=9.6e-5, step_loss=0.299]07/27/2023 17:51:53 - INFO - __main__ - train loss is 22.307810264173895\n",
      "Steps:   5%|▏  | 780/15000 [07:03<42:54,  5.52it/s, lr=9.61e-5, step_loss=0.435]07/27/2023 17:51:53 - INFO - __main__ - train loss is 22.322558181826025\n",
      "Steps:   5%|  | 781/15000 [07:03<42:48,  5.54it/s, lr=9.63e-5, step_loss=0.0147]07/27/2023 17:51:53 - INFO - __main__ - train loss is 22.337609061505646\n",
      "Steps:   5%|  | 782/15000 [07:03<42:45,  5.54it/s, lr=9.64e-5, step_loss=0.0151]07/27/2023 17:51:53 - INFO - __main__ - train loss is 22.411680647637695\n",
      "Steps:   5%|  | 783/15000 [07:04<42:40,  5.55it/s, lr=9.65e-5, step_loss=0.0741]07/27/2023 17:51:53 - INFO - __main__ - train loss is 22.41419203951955\n",
      "Steps:   5%| | 784/15000 [07:04<42:38,  5.56it/s, lr=9.66e-5, step_loss=0.00251]07/27/2023 17:51:54 - INFO - __main__ - train loss is 22.60730818286538\n",
      "Steps:   5%|▏  | 785/15000 [07:04<42:35,  5.56it/s, lr=9.68e-5, step_loss=0.193]07/27/2023 17:51:54 - INFO - __main__ - train loss is 22.73153380677104\n",
      "Steps:   5%|▏  | 786/15000 [07:04<43:06,  5.50it/s, lr=9.69e-5, step_loss=0.124]07/27/2023 17:51:54 - INFO - __main__ - train loss is 22.76936898007989\n",
      "Steps:   5%|▏  | 787/15000 [07:04<43:02,  5.50it/s, lr=9.7e-5, step_loss=0.0378]07/27/2023 17:51:54 - INFO - __main__ - train loss is 22.856797005981207\n",
      "Steps:   5%|  | 788/15000 [07:04<42:52,  5.52it/s, lr=9.71e-5, step_loss=0.0874]07/27/2023 17:51:54 - INFO - __main__ - train loss is 22.887993410229683\n",
      "Steps:   5%|  | 789/15000 [07:05<42:45,  5.54it/s, lr=9.73e-5, step_loss=0.0312]07/27/2023 17:51:55 - INFO - __main__ - train loss is 22.993736766278744\n",
      "Steps:   5%|▏  | 790/15000 [07:05<42:41,  5.55it/s, lr=9.74e-5, step_loss=0.106]07/27/2023 17:51:55 - INFO - __main__ - train loss is 23.162697352468967\n",
      "Steps:   5%|▏  | 791/15000 [07:05<42:46,  5.54it/s, lr=9.75e-5, step_loss=0.169]07/27/2023 17:51:55 - INFO - __main__ - train loss is 23.33980316668749\n",
      "Steps:   5%|▏  | 792/15000 [07:05<42:41,  5.55it/s, lr=9.76e-5, step_loss=0.177]07/27/2023 17:51:55 - INFO - __main__ - train loss is 23.345762306358665\n",
      "Steps:   5%| | 793/15000 [07:05<42:53,  5.52it/s, lr=9.78e-5, step_loss=0.00596]07/27/2023 17:51:55 - INFO - __main__ - train loss is 24.00589864840731\n",
      "Steps:   5%|▏   | 794/15000 [07:06<42:48,  5.53it/s, lr=9.79e-5, step_loss=0.66]07/27/2023 17:51:55 - INFO - __main__ - train loss is 24.029409108217806\n",
      "Steps:   5%|▏  | 795/15000 [07:06<42:44,  5.54it/s, lr=9.8e-5, step_loss=0.0235]07/27/2023 17:51:56 - INFO - __main__ - train loss is 24.50547462468967\n",
      "Steps:   5%|▏  | 796/15000 [07:06<42:41,  5.54it/s, lr=9.81e-5, step_loss=0.476]07/27/2023 17:51:56 - INFO - __main__ - train loss is 24.51193721499294\n",
      "Steps:   5%| | 797/15000 [07:06<42:37,  5.55it/s, lr=9.83e-5, step_loss=0.00646]07/27/2023 17:51:56 - INFO - __main__ - train loss is 24.853302552364767\n",
      "Steps:   5%|▏  | 798/15000 [07:06<42:34,  5.56it/s, lr=9.84e-5, step_loss=0.341]07/27/2023 17:51:56 - INFO - __main__ - train loss is 25.103064252994955\n",
      "Steps:   5%|▏   | 799/15000 [07:06<42:31,  5.57it/s, lr=9.85e-5, step_loss=0.25]07/27/2023 17:51:56 - INFO - __main__ - train loss is 25.105896536726505\n",
      "Steps:   5%| | 800/15000 [07:07<42:53,  5.52it/s, lr=9.86e-5, step_loss=0.00283]07/27/2023 17:51:57 - INFO - __main__ - train loss is 25.298521254677325\n",
      "Steps:   5%|▏  | 801/15000 [07:07<42:43,  5.54it/s, lr=9.88e-5, step_loss=0.193]07/27/2023 17:51:57 - INFO - __main__ - train loss is 25.409549098927528\n",
      "Steps:   5%|▏  | 802/15000 [07:07<42:37,  5.55it/s, lr=9.89e-5, step_loss=0.111]07/27/2023 17:51:57 - INFO - __main__ - train loss is 25.882526230532676\n",
      "Steps:   5%|▏   | 803/15000 [07:07<42:52,  5.52it/s, lr=9.9e-5, step_loss=0.473]07/27/2023 17:51:57 - INFO - __main__ - train loss is 26.251495849806815\n",
      "Steps:   5%|▏  | 804/15000 [07:07<42:44,  5.53it/s, lr=9.91e-5, step_loss=0.369]07/27/2023 17:51:57 - INFO - __main__ - train loss is 26.25786879705265\n",
      "Steps:   5%| | 805/15000 [07:08<42:39,  5.55it/s, lr=9.93e-5, step_loss=0.00637]07/27/2023 17:51:57 - INFO - __main__ - train loss is 26.286307763773948\n",
      "Steps:   5%|  | 806/15000 [07:08<42:36,  5.55it/s, lr=9.94e-5, step_loss=0.0284]07/27/2023 17:51:58 - INFO - __main__ - train loss is 26.305473033804446\n",
      "Steps:   5%|  | 807/15000 [07:08<43:09,  5.48it/s, lr=9.95e-5, step_loss=0.0192]07/27/2023 17:51:58 - INFO - __main__ - train loss is 26.77576706232503\n",
      "Steps:   5%|▏   | 808/15000 [07:08<43:29,  5.44it/s, lr=9.96e-5, step_loss=0.47]07/27/2023 17:51:58 - INFO - __main__ - train loss is 26.778260005405173\n",
      "Steps:   5%| | 809/15000 [07:08<43:18,  5.46it/s, lr=9.98e-5, step_loss=0.00249]07/27/2023 17:51:58 - INFO - __main__ - train loss is 27.380521608283743\n",
      "Steps:   5%|▏  | 810/15000 [07:08<43:03,  5.49it/s, lr=9.99e-5, step_loss=0.602]07/27/2023 17:51:58 - INFO - __main__ - train loss is 27.520422560861334\n",
      "Steps:   5%|▎    | 811/15000 [07:09<42:52,  5.52it/s, lr=0.0001, step_loss=0.14]07/27/2023 17:51:59 - INFO - __main__ - train loss is 27.561937575927004\n",
      "Steps:   5%|▏  | 812/15000 [07:09<42:44,  5.53it/s, lr=0.0001, step_loss=0.0415]07/27/2023 17:51:59 - INFO - __main__ - train loss is 27.583835063269362\n",
      "Steps:   5%|▏  | 813/15000 [07:09<42:40,  5.54it/s, lr=0.0001, step_loss=0.0219]07/27/2023 17:51:59 - INFO - __main__ - train loss is 27.781688121845946\n",
      "Steps:   5%|▏   | 814/15000 [07:09<42:43,  5.53it/s, lr=0.0001, step_loss=0.198]07/27/2023 17:51:59 - INFO - __main__ - train loss is 28.16101693897508\n",
      "Steps:   5%|  | 815/15000 [07:09<42:38,  5.54it/s, lr=0.000101, step_loss=0.379]07/27/2023 17:51:59 - INFO - __main__ - train loss is 28.164606245001778\n",
      "Steps:   5%| | 816/15000 [07:10<42:36,  5.55it/s, lr=0.000101, step_loss=0.0035907/27/2023 17:51:59 - INFO - __main__ - train loss is 28.77122381492518\n",
      "Steps:   5%|  | 817/15000 [07:10<42:34,  5.55it/s, lr=0.000101, step_loss=0.607]07/27/2023 17:52:00 - INFO - __main__ - train loss is 28.81782822473906\n",
      "Steps:   5%| | 818/15000 [07:10<42:34,  5.55it/s, lr=0.000101, step_loss=0.0466]07/27/2023 17:52:00 - INFO - __main__ - train loss is 28.88417105539702\n",
      "Steps:   5%| | 819/15000 [07:10<42:31,  5.56it/s, lr=0.000101, step_loss=0.0663]07/27/2023 17:52:00 - INFO - __main__ - train loss is 29.75021724565886\n",
      "Steps:   5%|  | 820/15000 [07:10<42:30,  5.56it/s, lr=0.000101, step_loss=0.866]07/27/2023 17:52:00 - INFO - __main__ - train loss is 29.772594336187467\n",
      "Steps:   5%| | 821/15000 [07:10<42:34,  5.55it/s, lr=0.000101, step_loss=0.0224]07/27/2023 17:52:00 - INFO - __main__ - train loss is 30.030738089000806\n",
      "Steps:   5%|  | 822/15000 [07:11<42:31,  5.56it/s, lr=0.000101, step_loss=0.258]07/27/2023 17:52:00 - INFO - __main__ - train loss is 30.10693697980605\n",
      "Steps:   5%| | 823/15000 [07:11<42:28,  5.56it/s, lr=0.000102, step_loss=0.0762]07/27/2023 17:52:01 - INFO - __main__ - train loss is 30.13846705458127\n",
      "Steps:   5%| | 824/15000 [07:11<42:51,  5.51it/s, lr=0.000102, step_loss=0.0315]07/27/2023 17:52:01 - INFO - __main__ - train loss is 30.181480154162273\n",
      "Steps:   6%|  | 825/15000 [07:11<42:51,  5.51it/s, lr=0.000102, step_loss=0.043]07/27/2023 17:52:01 - INFO - __main__ - train loss is 30.218635398661718\n",
      "Steps:   6%| | 826/15000 [07:11<42:45,  5.52it/s, lr=0.000102, step_loss=0.0372]07/27/2023 17:52:01 - INFO - __main__ - train loss is 30.551271337782964\n",
      "Steps:   6%|  | 827/15000 [07:12<42:40,  5.54it/s, lr=0.000102, step_loss=0.333]07/27/2023 17:52:01 - INFO - __main__ - train loss is 30.563765003113076\n",
      "Steps:   6%| | 828/15000 [07:12<42:38,  5.54it/s, lr=0.000102, step_loss=0.0125]07/27/2023 17:52:02 - INFO - __main__ - train loss is 30.798263414530084\n",
      "Steps:   6%|  | 829/15000 [07:12<42:35,  5.54it/s, lr=0.000102, step_loss=0.234]07/27/2023 17:52:02 - INFO - __main__ - train loss is 31.083618505625054\n",
      "Steps:   6%|  | 830/15000 [07:12<42:32,  5.55it/s, lr=0.000102, step_loss=0.285]07/27/2023 17:52:02 - INFO - __main__ - train loss is 31.085881122155115\n",
      "Steps:   6%| | 831/15000 [07:12<42:30,  5.56it/s, lr=0.000102, step_loss=0.0022607/27/2023 17:52:02 - INFO - __main__ - train loss is 31.27281961659901\n",
      "Steps:   6%|  | 832/15000 [07:12<42:30,  5.55it/s, lr=0.000103, step_loss=0.187]07/27/2023 17:52:02 - INFO - __main__ - train loss is 31.277986717177555\n",
      "Steps:   6%| | 833/15000 [07:13<42:28,  5.56it/s, lr=0.000103, step_loss=0.0051707/27/2023 17:52:02 - INFO - __main__ - train loss is 31.454024058533832\n",
      "Steps:   6%|  | 834/15000 [07:13<42:26,  5.56it/s, lr=0.000103, step_loss=0.176]07/27/2023 17:52:03 - INFO - __main__ - train loss is 31.461754711112007\n",
      "Steps:   6%| | 835/15000 [07:13<42:29,  5.55it/s, lr=0.000103, step_loss=0.0077307/27/2023 17:52:03 - INFO - __main__ - train loss is 31.50564087345265\n",
      "Steps:   6%| | 836/15000 [07:13<42:51,  5.51it/s, lr=0.000103, step_loss=0.0439]07/27/2023 17:52:03 - INFO - __main__ - train loss is 31.52186084142886\n",
      "Steps:   6%| | 837/15000 [07:13<42:51,  5.51it/s, lr=0.000103, step_loss=0.0162]07/27/2023 17:52:03 - INFO - __main__ - train loss is 31.53437585453503\n",
      "Steps:   6%| | 838/15000 [07:14<42:43,  5.52it/s, lr=0.000103, step_loss=0.0125]07/27/2023 17:52:03 - INFO - __main__ - train loss is 31.615483888192102\n",
      "Steps:   6%| | 839/15000 [07:14<42:39,  5.53it/s, lr=0.000103, step_loss=0.0811]07/27/2023 17:52:04 - INFO - __main__ - train loss is 31.647483587963507\n",
      "Steps:   6%|  | 840/15000 [07:14<43:00,  5.49it/s, lr=0.000104, step_loss=0.032]07/27/2023 17:52:04 - INFO - __main__ - train loss is 31.64991028769873\n",
      "Steps:   6%| | 841/15000 [07:14<43:16,  5.45it/s, lr=0.000104, step_loss=0.0024307/27/2023 17:52:04 - INFO - __main__ - train loss is 32.03663946851157\n",
      "Steps:   6%|  | 842/15000 [07:14<43:15,  5.45it/s, lr=0.000104, step_loss=0.387]07/27/2023 17:52:04 - INFO - __main__ - train loss is 32.166348384460434\n",
      "Steps:   6%|▏  | 843/15000 [07:14<42:58,  5.49it/s, lr=0.000104, step_loss=0.13]07/27/2023 17:52:04 - INFO - __main__ - train loss is 32.16837046761066\n",
      "Steps:   6%| | 844/15000 [07:15<43:10,  5.46it/s, lr=0.000104, step_loss=0.0020207/27/2023 17:52:04 - INFO - __main__ - train loss is 32.170090688276105\n",
      "Steps:   6%| | 845/15000 [07:15<42:55,  5.50it/s, lr=0.000104, step_loss=0.0017207/27/2023 17:52:05 - INFO - __main__ - train loss is 32.343531383085065\n",
      "Steps:   6%|  | 846/15000 [07:15<42:44,  5.52it/s, lr=0.000104, step_loss=0.173]07/27/2023 17:52:05 - INFO - __main__ - train loss is 32.3458497178508\n",
      "Steps:   6%| | 847/15000 [07:15<42:38,  5.53it/s, lr=0.000104, step_loss=0.0023207/27/2023 17:52:05 - INFO - __main__ - train loss is 32.37304169021081\n",
      "Steps:   6%| | 848/15000 [07:15<42:33,  5.54it/s, lr=0.000105, step_loss=0.0272]07/27/2023 17:52:05 - INFO - __main__ - train loss is 32.37563148105983\n",
      "Steps:   6%| | 849/15000 [07:16<42:44,  5.52it/s, lr=0.000105, step_loss=0.0025907/27/2023 17:52:05 - INFO - __main__ - train loss is 32.379835946136154\n",
      "Steps:   6%| | 850/15000 [07:16<43:01,  5.48it/s, lr=0.000105, step_loss=0.0042]07/27/2023 17:52:06 - INFO - __main__ - train loss is 32.478811887674965\n",
      "Steps:   6%|  | 851/15000 [07:16<43:10,  5.46it/s, lr=0.000105, step_loss=0.099]07/27/2023 17:52:06 - INFO - __main__ - train loss is 32.49303336406592\n",
      "Steps:   6%| | 852/15000 [07:16<42:56,  5.49it/s, lr=0.000105, step_loss=0.0142]07/27/2023 17:52:06 - INFO - __main__ - train loss is 32.81128413940314\n",
      "Steps:   6%|  | 853/15000 [07:16<42:45,  5.51it/s, lr=0.000105, step_loss=0.318]07/27/2023 17:52:06 - INFO - __main__ - train loss is 32.98447917366866\n",
      "Steps:   6%|  | 854/15000 [07:16<42:39,  5.53it/s, lr=0.000105, step_loss=0.173]07/27/2023 17:52:06 - INFO - __main__ - train loss is 32.98988097591791\n",
      "Steps:   6%| | 855/15000 [07:17<42:33,  5.54it/s, lr=0.000106, step_loss=0.0054]07/27/2023 17:52:06 - INFO - __main__ - train loss is 32.99122751771938\n",
      "Steps:   6%| | 856/15000 [07:17<42:33,  5.54it/s, lr=0.000106, step_loss=0.0013507/27/2023 17:52:07 - INFO - __main__ - train loss is 32.99800376908388\n",
      "Steps:   6%| | 857/15000 [07:17<42:27,  5.55it/s, lr=0.000106, step_loss=0.0067807/27/2023 17:52:07 - INFO - __main__ - train loss is 33.10737193690147\n",
      "Steps:   6%|  | 858/15000 [07:17<42:48,  5.51it/s, lr=0.000106, step_loss=0.109]07/27/2023 17:52:07 - INFO - __main__ - train loss is 33.550868521793745\n",
      "Steps:   6%|  | 859/15000 [07:17<42:47,  5.51it/s, lr=0.000106, step_loss=0.443]07/27/2023 17:52:07 - INFO - __main__ - train loss is 33.562836465775035\n",
      "Steps:   6%|  | 860/15000 [07:18<42:37,  5.53it/s, lr=0.000106, step_loss=0.012]07/27/2023 17:52:07 - INFO - __main__ - train loss is 33.58062417560723\n",
      "Steps:   6%| | 861/15000 [07:18<42:30,  5.54it/s, lr=0.000106, step_loss=0.0178]07/27/2023 17:52:08 - INFO - __main__ - train loss is 33.59987496526446\n",
      "Steps:   6%| | 862/15000 [07:18<42:49,  5.50it/s, lr=0.000106, step_loss=0.0193]07/27/2023 17:52:08 - INFO - __main__ - train loss is 33.738564587547444\n",
      "Steps:   6%|  | 863/15000 [07:18<42:42,  5.52it/s, lr=0.000107, step_loss=0.139]07/27/2023 17:52:08 - INFO - __main__ - train loss is 33.74397205223795\n",
      "Steps:   6%| | 864/15000 [07:18<42:35,  5.53it/s, lr=0.000107, step_loss=0.0054107/27/2023 17:52:08 - INFO - __main__ - train loss is 33.77840800618287\n",
      "Steps:   6%| | 865/15000 [07:18<42:51,  5.50it/s, lr=0.000107, step_loss=0.0344]07/27/2023 17:52:08 - INFO - __main__ - train loss is 34.08209566806909\n",
      "Steps:   6%|  | 866/15000 [07:19<43:05,  5.47it/s, lr=0.000107, step_loss=0.304]07/27/2023 17:52:08 - INFO - __main__ - train loss is 34.09836075489875\n",
      "Steps:   6%| | 867/15000 [07:19<43:05,  5.47it/s, lr=0.000107, step_loss=0.0163]07/27/2023 17:52:09 - INFO - __main__ - train loss is 34.10331729229074\n",
      "Steps:   6%| | 868/15000 [07:19<42:49,  5.50it/s, lr=0.000107, step_loss=0.0049607/27/2023 17:52:09 - INFO - __main__ - train loss is 34.10608996625524\n",
      "Steps:   6%| | 869/15000 [07:19<42:52,  5.49it/s, lr=0.000107, step_loss=0.0027707/27/2023 17:52:09 - INFO - __main__ - train loss is 34.312067957478575\n",
      "Steps:   6%|  | 870/15000 [07:19<42:42,  5.52it/s, lr=0.000107, step_loss=0.206]07/27/2023 17:52:09 - INFO - __main__ - train loss is 34.32837484206539\n",
      "Steps:   6%| | 871/15000 [07:19<42:33,  5.53it/s, lr=0.000107, step_loss=0.0163]07/27/2023 17:52:09 - INFO - __main__ - train loss is 34.484036574023776\n",
      "Steps:   6%|  | 872/15000 [07:20<42:28,  5.54it/s, lr=0.000108, step_loss=0.156]07/27/2023 17:52:10 - INFO - __main__ - train loss is 34.62803592707496\n",
      "Steps:   6%|  | 873/15000 [07:20<42:24,  5.55it/s, lr=0.000108, step_loss=0.144]07/27/2023 17:52:10 - INFO - __main__ - train loss is 34.782135391491465\n",
      "Steps:   6%|  | 874/15000 [07:20<42:21,  5.56it/s, lr=0.000108, step_loss=0.154]07/27/2023 17:52:10 - INFO - __main__ - train loss is 35.249981725472026\n",
      "Steps:   6%|  | 875/15000 [07:20<42:41,  5.51it/s, lr=0.000108, step_loss=0.468]07/27/2023 17:52:10 - INFO - __main__ - train loss is 35.251984136761166\n",
      "Steps:   6%|  | 876/15000 [07:20<42:34,  5.53it/s, lr=0.000108, step_loss=0.002]07/27/2023 17:52:10 - INFO - __main__ - train loss is 35.25489919784013\n",
      "Steps:   6%| | 877/15000 [07:21<42:32,  5.53it/s, lr=0.000108, step_loss=0.0029207/27/2023 17:52:10 - INFO - __main__ - train loss is 35.2597235852154\n",
      "Steps:   6%| | 878/15000 [07:21<42:28,  5.54it/s, lr=0.000108, step_loss=0.0048207/27/2023 17:52:11 - INFO - __main__ - train loss is 35.27178349450696\n",
      "Steps:   6%| | 879/15000 [07:21<42:27,  5.54it/s, lr=0.000109, step_loss=0.0121]07/27/2023 17:52:11 - INFO - __main__ - train loss is 35.48178819671739\n",
      "Steps:   6%|▏  | 880/15000 [07:21<42:25,  5.55it/s, lr=0.000109, step_loss=0.21]07/27/2023 17:52:11 - INFO - __main__ - train loss is 35.646235087071545\n",
      "Steps:   6%|  | 881/15000 [07:21<42:49,  5.50it/s, lr=0.000109, step_loss=0.164]07/27/2023 17:52:11 - INFO - __main__ - train loss is 35.68687969550956\n",
      "Steps:   6%| | 882/15000 [07:21<42:45,  5.50it/s, lr=0.000109, step_loss=0.0406]07/27/2023 17:52:11 - INFO - __main__ - train loss is 35.94065401062835\n",
      "Steps:   6%|  | 883/15000 [07:22<42:54,  5.48it/s, lr=0.000109, step_loss=0.254]07/27/2023 17:52:12 - INFO - __main__ - train loss is 35.993578174267896\n",
      "Steps:   6%| | 884/15000 [07:22<42:42,  5.51it/s, lr=0.000109, step_loss=0.0529]07/27/2023 17:52:12 - INFO - __main__ - train loss is 35.994520490057766\n",
      "Steps:   6%| | 885/15000 [07:22<42:31,  5.53it/s, lr=0.000109, step_loss=0.0009407/27/2023 17:52:12 - INFO - __main__ - train loss is 35.99593658489175\n",
      "Steps:   6%| | 886/15000 [07:22<42:27,  5.54it/s, lr=0.000109, step_loss=0.0014207/27/2023 17:52:12 - INFO - __main__ - train loss is 36.02993315202184\n",
      "Steps:   6%|▏  | 887/15000 [07:22<42:22,  5.55it/s, lr=0.00011, step_loss=0.034]07/27/2023 17:52:12 - INFO - __main__ - train loss is 36.60881477338262\n",
      "Steps:   6%|▏  | 888/15000 [07:23<42:44,  5.50it/s, lr=0.00011, step_loss=0.579]07/27/2023 17:52:12 - INFO - __main__ - train loss is 36.63944643479772\n",
      "Steps:   6%|  | 889/15000 [07:23<42:55,  5.48it/s, lr=0.00011, step_loss=0.0306]07/27/2023 17:52:13 - INFO - __main__ - train loss is 36.670955636771396\n",
      "Steps:   6%|  | 890/15000 [07:23<43:00,  5.47it/s, lr=0.00011, step_loss=0.0315]07/27/2023 17:52:13 - INFO - __main__ - train loss is 36.92671630647965\n",
      "Steps:   6%|▏  | 891/15000 [07:23<42:44,  5.50it/s, lr=0.00011, step_loss=0.256]07/27/2023 17:52:13 - INFO - __main__ - train loss is 37.12046290305443\n",
      "Steps:   6%|▏  | 892/15000 [07:23<42:34,  5.52it/s, lr=0.00011, step_loss=0.194]07/27/2023 17:52:13 - INFO - __main__ - train loss is 37.19401276973076\n",
      "Steps:   6%|  | 893/15000 [07:23<42:50,  5.49it/s, lr=0.00011, step_loss=0.0735]07/27/2023 17:52:13 - INFO - __main__ - train loss is 37.19580407149624\n",
      "Steps:   6%| | 894/15000 [07:24<42:43,  5.50it/s, lr=0.00011, step_loss=0.00179]07/27/2023 17:52:14 - INFO - __main__ - train loss is 37.38156328804325\n",
      "Steps:   6%|  | 895/15000 [07:24<42:31,  5.53it/s, lr=0.000111, step_loss=0.186]07/27/2023 17:52:14 - INFO - __main__ - train loss is 37.40399581834208\n",
      "Steps:   6%| | 896/15000 [07:24<42:24,  5.54it/s, lr=0.000111, step_loss=0.0224]07/27/2023 17:52:14 - INFO - __main__ - train loss is 37.55897553905379\n",
      "Steps:   6%|  | 897/15000 [07:24<42:17,  5.56it/s, lr=0.000111, step_loss=0.155]07/27/2023 17:52:14 - INFO - __main__ - train loss is 37.56895499944221\n",
      "Steps:   6%| | 898/15000 [07:24<42:11,  5.57it/s, lr=0.000111, step_loss=0.0099807/27/2023 17:52:14 - INFO - __main__ - train loss is 37.64894900738727\n",
      "Steps:   6%|▏  | 899/15000 [07:25<42:08,  5.58it/s, lr=0.000111, step_loss=0.08]07/27/2023 17:52:14 - INFO - __main__ - train loss is 37.66158340300899\n",
      "Steps:   6%| | 900/15000 [07:25<42:06,  5.58it/s, lr=0.000111, step_loss=0.0126]07/27/2023 17:52:15 - INFO - __main__ - train loss is 38.11114768113475\n",
      "Steps:   6%|▏  | 901/15000 [07:25<42:20,  5.55it/s, lr=0.000111, step_loss=0.45]07/27/2023 17:52:15 - INFO - __main__ - train loss is 38.751381674665026\n",
      "Steps:   6%|▏  | 902/15000 [07:25<42:14,  5.56it/s, lr=0.000111, step_loss=0.64]07/27/2023 17:52:15 - INFO - __main__ - train loss is 38.82525282527786\n",
      "Steps:   6%| | 903/15000 [07:25<42:10,  5.57it/s, lr=0.000111, step_loss=0.0739]07/27/2023 17:52:15 - INFO - __main__ - train loss is 38.82837113097776\n",
      "Steps:   6%| | 904/15000 [07:25<42:46,  5.49it/s, lr=0.000112, step_loss=0.0031207/27/2023 17:52:15 - INFO - __main__ - train loss is 38.85042446583975\n",
      "Steps:   6%| | 905/15000 [07:26<42:37,  5.51it/s, lr=0.000112, step_loss=0.0221]07/27/2023 17:52:16 - INFO - __main__ - train loss is 39.502502140705474\n",
      "Steps:   6%|  | 906/15000 [07:26<42:25,  5.54it/s, lr=0.000112, step_loss=0.652]07/27/2023 17:52:16 - INFO - __main__ - train loss is 39.50513414281886\n",
      "Steps:   6%| | 907/15000 [07:26<42:26,  5.54it/s, lr=0.000112, step_loss=0.0026307/27/2023 17:52:16 - INFO - __main__ - train loss is 39.50778836978134\n",
      "Steps:   6%| | 908/15000 [07:26<42:18,  5.55it/s, lr=0.000112, step_loss=0.0026507/27/2023 17:52:16 - INFO - __main__ - train loss is 39.944241235381924\n",
      "Steps:   6%|  | 909/15000 [07:27<58:48,  3.99it/s, lr=0.000112, step_loss=0.436]07/27/2023 17:52:17 - INFO - __main__ - Per validation step average loss is 0.23286710679531097\n",
      "07/27/2023 17:52:17 - INFO - __main__ - Cumulative validation average loss is 0.23286710679531097\n",
      "07/27/2023 17:52:18 - INFO - __main__ - Per validation step average loss is 0.057177379727363586\n",
      "07/27/2023 17:52:18 - INFO - __main__ - Cumulative validation average loss is 0.29004448652267456\n",
      "07/27/2023 17:52:18 - INFO - __main__ - Per validation step average loss is 0.18343192338943481\n",
      "07/27/2023 17:52:18 - INFO - __main__ - Cumulative validation average loss is 0.4734764099121094\n",
      "07/27/2023 17:52:19 - INFO - __main__ - Per validation step average loss is 0.028397906571626663\n",
      "07/27/2023 17:52:19 - INFO - __main__ - Cumulative validation average loss is 0.501874316483736\n",
      "07/27/2023 17:52:19 - INFO - __main__ - Per validation step average loss is 0.21634040772914886\n",
      "07/27/2023 17:52:19 - INFO - __main__ - Cumulative validation average loss is 0.7182147242128849\n",
      "07/27/2023 17:52:19 - INFO - __main__ - Per validation step average loss is 0.03389454632997513\n",
      "07/27/2023 17:52:19 - INFO - __main__ - Cumulative validation average loss is 0.75210927054286\n",
      "07/27/2023 17:52:20 - INFO - __main__ - Per validation step average loss is 0.0016976433107629418\n",
      "07/27/2023 17:52:20 - INFO - __main__ - Cumulative validation average loss is 0.753806913853623\n",
      "07/27/2023 17:52:20 - INFO - __main__ - Per validation step average loss is 0.3312007188796997\n",
      "07/27/2023 17:52:20 - INFO - __main__ - Cumulative validation average loss is 1.0850076327333227\n",
      "07/27/2023 17:52:21 - INFO - __main__ - Per validation step average loss is 0.27211999893188477\n",
      "07/27/2023 17:52:21 - INFO - __main__ - Cumulative validation average loss is 1.3571276316652074\n",
      "07/27/2023 17:52:21 - INFO - __main__ - Per validation step average loss is 0.38578566908836365\n",
      "07/27/2023 17:52:21 - INFO - __main__ - Cumulative validation average loss is 1.742913300753571\n",
      "07/27/2023 17:52:22 - INFO - __main__ - Per validation step average loss is 0.00587485171854496\n",
      "07/27/2023 17:52:22 - INFO - __main__ - Cumulative validation average loss is 1.748788152472116\n",
      "07/27/2023 17:52:22 - INFO - __main__ - Per validation step average loss is 0.6361377239227295\n",
      "07/27/2023 17:52:22 - INFO - __main__ - Cumulative validation average loss is 2.3849258763948455\n",
      "07/27/2023 17:52:22 - INFO - __main__ - Per validation step average loss is 0.005608660168945789\n",
      "07/27/2023 17:52:22 - INFO - __main__ - Cumulative validation average loss is 2.3905345365637913\n",
      "07/27/2023 17:52:23 - INFO - __main__ - Per validation step average loss is 0.03885631635785103\n",
      "07/27/2023 17:52:23 - INFO - __main__ - Cumulative validation average loss is 2.4293908529216424\n",
      "07/27/2023 17:52:23 - INFO - __main__ - Per validation step average loss is 0.0649944394826889\n",
      "07/27/2023 17:52:23 - INFO - __main__ - Cumulative validation average loss is 2.4943852924043313\n",
      "07/27/2023 17:52:24 - INFO - __main__ - Per validation step average loss is 0.19806787371635437\n",
      "07/27/2023 17:52:24 - INFO - __main__ - Cumulative validation average loss is 2.6924531661206856\n",
      "07/27/2023 17:52:24 - INFO - __main__ - Per validation step average loss is 0.03491687402129173\n",
      "07/27/2023 17:52:24 - INFO - __main__ - Cumulative validation average loss is 2.7273700401419774\n",
      "07/27/2023 17:52:24 - INFO - __main__ - Per validation step average loss is 0.39900481700897217\n",
      "07/27/2023 17:52:24 - INFO - __main__ - Cumulative validation average loss is 3.1263748571509495\n",
      "07/27/2023 17:52:25 - INFO - __main__ - Per validation step average loss is 0.05278194695711136\n",
      "07/27/2023 17:52:25 - INFO - __main__ - Cumulative validation average loss is 3.179156804108061\n",
      "07/27/2023 17:52:25 - INFO - __main__ - Per validation step average loss is 0.3581658601760864\n",
      "07/27/2023 17:52:25 - INFO - __main__ - Cumulative validation average loss is 3.5373226642841473\n",
      "07/27/2023 17:52:26 - INFO - __main__ - Per validation step average loss is 0.2717556655406952\n",
      "07/27/2023 17:52:26 - INFO - __main__ - Cumulative validation average loss is 3.8090783298248425\n",
      "07/27/2023 17:52:26 - INFO - __main__ - Per validation step average loss is 0.010065206326544285\n",
      "07/27/2023 17:52:26 - INFO - __main__ - Cumulative validation average loss is 3.819143536151387\n",
      "07/27/2023 17:52:26 - INFO - __main__ - Per validation step average loss is 0.018355168402194977\n",
      "07/27/2023 17:52:26 - INFO - __main__ - Cumulative validation average loss is 3.8374987045535818\n",
      "07/27/2023 17:52:27 - INFO - __main__ - Per validation step average loss is 0.11207092553377151\n",
      "07/27/2023 17:52:27 - INFO - __main__ - Cumulative validation average loss is 3.9495696300873533\n",
      "07/27/2023 17:52:27 - INFO - __main__ - Per validation step average loss is 0.02760327234864235\n",
      "07/27/2023 17:52:27 - INFO - __main__ - Cumulative validation average loss is 3.9771729024359956\n",
      "07/27/2023 17:52:28 - INFO - __main__ - Per validation step average loss is 0.006752653978765011\n",
      "07/27/2023 17:52:28 - INFO - __main__ - Cumulative validation average loss is 3.9839255564147606\n",
      "07/27/2023 17:52:28 - INFO - __main__ - Per validation step average loss is 0.013774728402495384\n",
      "07/27/2023 17:52:28 - INFO - __main__ - Cumulative validation average loss is 3.997700284817256\n",
      "07/27/2023 17:52:28 - INFO - __main__ - Per validation step average loss is 0.013902257196605206\n",
      "07/27/2023 17:52:28 - INFO - __main__ - Cumulative validation average loss is 4.011602542013861\n",
      "07/27/2023 17:52:29 - INFO - __main__ - Per validation step average loss is 0.2960495352745056\n",
      "07/27/2023 17:52:29 - INFO - __main__ - Cumulative validation average loss is 4.307652077288367\n",
      "07/27/2023 17:52:29 - INFO - __main__ - Per validation step average loss is 0.00625710841268301\n",
      "07/27/2023 17:52:29 - INFO - __main__ - Cumulative validation average loss is 4.31390918570105\n",
      "07/27/2023 17:52:30 - INFO - __main__ - Per validation step average loss is 0.009377947077155113\n",
      "07/27/2023 17:52:30 - INFO - __main__ - Cumulative validation average loss is 4.323287132778205\n",
      "07/27/2023 17:52:30 - INFO - __main__ - Per validation step average loss is 0.0013741333968937397\n",
      "07/27/2023 17:52:30 - INFO - __main__ - Cumulative validation average loss is 4.324661266175099\n",
      "07/27/2023 17:52:30 - INFO - __main__ - Per validation step average loss is 0.06935941427946091\n",
      "07/27/2023 17:52:30 - INFO - __main__ - Cumulative validation average loss is 4.39402068045456\n",
      "07/27/2023 17:52:31 - INFO - __main__ - Per validation step average loss is 0.03223904222249985\n",
      "07/27/2023 17:52:31 - INFO - __main__ - Cumulative validation average loss is 4.4262597226770595\n",
      "07/27/2023 17:52:31 - INFO - __main__ - Per validation step average loss is 0.0038021854124963284\n",
      "07/27/2023 17:52:31 - INFO - __main__ - Cumulative validation average loss is 4.430061908089556\n",
      "07/27/2023 17:52:32 - INFO - __main__ - Per validation step average loss is 0.008360793814063072\n",
      "07/27/2023 17:52:32 - INFO - __main__ - Cumulative validation average loss is 4.438422701903619\n",
      "07/27/2023 17:52:32 - INFO - __main__ - Per validation step average loss is 0.42169347405433655\n",
      "07/27/2023 17:52:32 - INFO - __main__ - Cumulative validation average loss is 4.860116175957955\n",
      "07/27/2023 17:52:33 - INFO - __main__ - Per validation step average loss is 0.0024767224676907063\n",
      "07/27/2023 17:52:33 - INFO - __main__ - Cumulative validation average loss is 4.862592898425646\n",
      "07/27/2023 17:52:33 - INFO - __main__ - Per validation step average loss is 0.15604081749916077\n",
      "07/27/2023 17:52:33 - INFO - __main__ - Cumulative validation average loss is 5.018633715924807\n",
      "07/27/2023 17:52:33 - INFO - __main__ - Per validation step average loss is 0.004882526583969593\n",
      "07/27/2023 17:52:33 - INFO - __main__ - Cumulative validation average loss is 5.0235162425087765\n",
      "07/27/2023 17:52:34 - INFO - __main__ - Per validation step average loss is 0.061310507357120514\n",
      "07/27/2023 17:52:34 - INFO - __main__ - Cumulative validation average loss is 5.084826749865897\n",
      "07/27/2023 17:52:34 - INFO - __main__ - Per validation step average loss is 0.15587474405765533\n",
      "07/27/2023 17:52:34 - INFO - __main__ - Cumulative validation average loss is 5.240701493923552\n",
      "07/27/2023 17:52:35 - INFO - __main__ - Per validation step average loss is 0.0373215451836586\n",
      "07/27/2023 17:52:35 - INFO - __main__ - Cumulative validation average loss is 5.278023039107211\n",
      "07/27/2023 17:52:35 - INFO - __main__ - Per validation step average loss is 0.17648372054100037\n",
      "07/27/2023 17:52:35 - INFO - __main__ - Cumulative validation average loss is 5.454506759648211\n",
      "07/27/2023 17:52:35 - INFO - __main__ - Per validation step average loss is 0.3300488591194153\n",
      "07/27/2023 17:52:35 - INFO - __main__ - Cumulative validation average loss is 5.784555618767627\n",
      "07/27/2023 17:52:36 - INFO - __main__ - Per validation step average loss is 0.049757979810237885\n",
      "07/27/2023 17:52:36 - INFO - __main__ - Cumulative validation average loss is 5.8343135985778645\n",
      "07/27/2023 17:52:36 - INFO - __main__ - Per validation step average loss is 0.029425498098134995\n",
      "07/27/2023 17:52:36 - INFO - __main__ - Cumulative validation average loss is 5.8637390966759995\n",
      "07/27/2023 17:52:37 - INFO - __main__ - Per validation step average loss is 0.11014385521411896\n",
      "07/27/2023 17:52:37 - INFO - __main__ - Cumulative validation average loss is 5.973882951890118\n",
      "07/27/2023 17:52:37 - INFO - __main__ - Per validation step average loss is 0.19254891574382782\n",
      "07/27/2023 17:52:37 - INFO - __main__ - Cumulative validation average loss is 6.166431867633946\n",
      "07/27/2023 17:52:37 - INFO - __main__ - Per validation step average loss is 0.1754455864429474\n",
      "07/27/2023 17:52:37 - INFO - __main__ - Cumulative validation average loss is 6.341877454076894\n",
      "07/27/2023 17:52:38 - INFO - __main__ - Per validation step average loss is 0.16393576562404633\n",
      "07/27/2023 17:52:38 - INFO - __main__ - Cumulative validation average loss is 6.50581321970094\n",
      "07/27/2023 17:52:38 - INFO - __main__ - Per validation step average loss is 0.006152443587779999\n",
      "07/27/2023 17:52:38 - INFO - __main__ - Cumulative validation average loss is 6.51196566328872\n",
      "07/27/2023 17:52:39 - INFO - __main__ - Per validation step average loss is 0.19838665425777435\n",
      "07/27/2023 17:52:39 - INFO - __main__ - Cumulative validation average loss is 6.710352317546494\n",
      "07/27/2023 17:52:39 - INFO - __main__ - Per validation step average loss is 0.04811735451221466\n",
      "07/27/2023 17:52:39 - INFO - __main__ - Cumulative validation average loss is 6.758469672058709\n",
      "07/27/2023 17:52:39 - INFO - __main__ - Per validation step average loss is 0.03556080907583237\n",
      "07/27/2023 17:52:39 - INFO - __main__ - Cumulative validation average loss is 6.794030481134541\n",
      "07/27/2023 17:52:40 - INFO - __main__ - Per validation step average loss is 0.07731883227825165\n",
      "07/27/2023 17:52:40 - INFO - __main__ - Cumulative validation average loss is 6.871349313412793\n",
      "07/27/2023 17:52:40 - INFO - __main__ - Per validation step average loss is 0.06478840857744217\n",
      "07/27/2023 17:52:40 - INFO - __main__ - Cumulative validation average loss is 6.936137721990235\n",
      "07/27/2023 17:52:41 - INFO - __main__ - Per validation step average loss is 0.004434351343661547\n",
      "07/27/2023 17:52:41 - INFO - __main__ - Cumulative validation average loss is 6.940572073333897\n",
      "07/27/2023 17:52:41 - INFO - __main__ - Per validation step average loss is 0.0026956493966281414\n",
      "07/27/2023 17:52:41 - INFO - __main__ - Cumulative validation average loss is 6.943267722730525\n",
      "07/27/2023 17:52:42 - INFO - __main__ - Per validation step average loss is 0.019872399047017097\n",
      "07/27/2023 17:52:42 - INFO - __main__ - Cumulative validation average loss is 6.963140121777542\n",
      "07/27/2023 17:52:42 - INFO - __main__ - Per validation step average loss is 0.12171530723571777\n",
      "07/27/2023 17:52:42 - INFO - __main__ - Cumulative validation average loss is 7.08485542901326\n",
      "07/27/2023 17:52:42 - INFO - __main__ - Per validation step average loss is 0.02277006208896637\n",
      "07/27/2023 17:52:42 - INFO - __main__ - Cumulative validation average loss is 7.107625491102226\n",
      "07/27/2023 17:52:43 - INFO - __main__ - Per validation step average loss is 0.42949551343917847\n",
      "07/27/2023 17:52:43 - INFO - __main__ - Cumulative validation average loss is 7.5371210045414045\n",
      "07/27/2023 17:52:43 - INFO - __main__ - Per validation step average loss is 0.6265366077423096\n",
      "07/27/2023 17:52:43 - INFO - __main__ - Cumulative validation average loss is 8.163657612283714\n",
      "07/27/2023 17:52:44 - INFO - __main__ - Per validation step average loss is 0.009995577856898308\n",
      "07/27/2023 17:52:44 - INFO - __main__ - Cumulative validation average loss is 8.173653190140612\n",
      "07/27/2023 17:52:44 - INFO - __main__ - Per validation step average loss is 0.09251589328050613\n",
      "07/27/2023 17:52:44 - INFO - __main__ - Cumulative validation average loss is 8.266169083421119\n",
      "07/27/2023 17:52:44 - INFO - __main__ - Per validation step average loss is 0.08275988698005676\n",
      "07/27/2023 17:52:44 - INFO - __main__ - Cumulative validation average loss is 8.348928970401175\n",
      "07/27/2023 17:52:45 - INFO - __main__ - Per validation step average loss is 0.731543779373169\n",
      "07/27/2023 17:52:45 - INFO - __main__ - Cumulative validation average loss is 9.080472749774344\n",
      "07/27/2023 17:52:45 - INFO - __main__ - Per validation step average loss is 0.15773418545722961\n",
      "07/27/2023 17:52:45 - INFO - __main__ - Cumulative validation average loss is 9.238206935231574\n",
      "07/27/2023 17:52:46 - INFO - __main__ - Per validation step average loss is 0.003672604449093342\n",
      "07/27/2023 17:52:46 - INFO - __main__ - Cumulative validation average loss is 9.241879539680667\n",
      "07/27/2023 17:52:46 - INFO - __main__ - Per validation step average loss is 0.01633458584547043\n",
      "07/27/2023 17:52:46 - INFO - __main__ - Cumulative validation average loss is 9.258214125526138\n",
      "07/27/2023 17:52:46 - INFO - __main__ - Per validation step average loss is 0.028498485684394836\n",
      "07/27/2023 17:52:46 - INFO - __main__ - Cumulative validation average loss is 9.286712611210532\n",
      "07/27/2023 17:52:47 - INFO - __main__ - Per validation step average loss is 0.009201460517942905\n",
      "07/27/2023 17:52:47 - INFO - __main__ - Cumulative validation average loss is 9.295914071728475\n",
      "07/27/2023 17:52:47 - INFO - __main__ - Per validation step average loss is 0.006653310731053352\n",
      "07/27/2023 17:52:47 - INFO - __main__ - Cumulative validation average loss is 9.302567382459529\n",
      "07/27/2023 17:52:48 - INFO - __main__ - Per validation step average loss is 0.008052065968513489\n",
      "07/27/2023 17:52:48 - INFO - __main__ - Cumulative validation average loss is 9.310619448428042\n",
      "07/27/2023 17:52:48 - INFO - __main__ - Per validation step average loss is 0.03412436693906784\n",
      "07/27/2023 17:52:48 - INFO - __main__ - Cumulative validation average loss is 9.34474381536711\n",
      "07/27/2023 17:52:48 - INFO - __main__ - Per validation step average loss is 0.0032905442640185356\n",
      "07/27/2023 17:52:48 - INFO - __main__ - Cumulative validation average loss is 9.348034359631129\n",
      "07/27/2023 17:52:49 - INFO - __main__ - Per validation step average loss is 0.5006603002548218\n",
      "07/27/2023 17:52:49 - INFO - __main__ - Cumulative validation average loss is 9.84869465988595\n",
      "07/27/2023 17:52:50 - INFO - __main__ - Per validation step average loss is 0.07791247963905334\n",
      "07/27/2023 17:52:50 - INFO - __main__ - Cumulative validation average loss is 9.926607139525004\n",
      "07/27/2023 17:52:50 - INFO - __main__ - Average validation loss for Epoch 2 is 0.12565325493069626\n",
      "07/27/2023 17:52:50 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 17:53:46 - INFO - __main__ - Starting epoch 3\n",
      "07/27/2023 17:53:47 - INFO - __main__ - train loss is 0.004298995714634657\n",
      "Steps:   6%| | 910/15000 [08:57<107:15:44, 27.41s/it, lr=0.000112, step_loss=0.007/27/2023 17:53:47 - INFO - __main__ - train loss is 0.010483750607818365\n",
      "Steps:   6%| | 911/15000 [08:58<75:17:42, 19.24s/it, lr=0.000113, step_loss=0.0007/27/2023 17:53:47 - INFO - __main__ - train loss is 0.02406508242711425\n",
      "Steps:   6%| | 912/15000 [08:58<52:54:48, 13.52s/it, lr=0.000113, step_loss=0.0107/27/2023 17:53:48 - INFO - __main__ - train loss is 0.029703008476644754\n",
      "Steps:   6%| | 913/15000 [08:58<37:15:04,  9.52s/it, lr=0.000113, step_loss=0.0007/27/2023 17:53:48 - INFO - __main__ - train loss is 0.12867567921057343\n",
      "Steps:   6%| | 914/15000 [08:58<26:17:04,  6.72s/it, lr=0.000113, step_loss=0.0907/27/2023 17:53:48 - INFO - __main__ - train loss is 0.1493257344700396\n",
      "Steps:   6%| | 915/15000 [08:58<18:36:41,  4.76s/it, lr=0.000113, step_loss=0.0207/27/2023 17:53:48 - INFO - __main__ - train loss is 0.28199479589238763\n",
      "Steps:   6%| | 916/15000 [08:58<13:14:28,  3.38s/it, lr=0.000113, step_loss=0.1307/27/2023 17:53:48 - INFO - __main__ - train loss is 0.2831649186555296\n",
      "Steps:   6%| | 917/15000 [08:59<9:28:42,  2.42s/it, lr=0.000113, step_loss=0.00107/27/2023 17:53:49 - INFO - __main__ - train loss is 0.3195253948215395\n",
      "Steps:   6%| | 918/15000 [08:59<6:50:41,  1.75s/it, lr=0.000113, step_loss=0.03607/27/2023 17:53:49 - INFO - __main__ - train loss is 0.32126589166000485\n",
      "Steps:   6%| | 919/15000 [08:59<5:00:04,  1.28s/it, lr=0.000114, step_loss=0.00107/27/2023 17:53:49 - INFO - __main__ - train loss is 0.3247317001223564\n",
      "Steps:   6%| | 920/15000 [08:59<3:42:42,  1.05it/s, lr=0.000114, step_loss=0.00307/27/2023 17:53:49 - INFO - __main__ - train loss is 0.412819467484951\n",
      "Steps:   6%| | 921/15000 [08:59<2:48:27,  1.39it/s, lr=0.000114, step_loss=0.08807/27/2023 17:53:49 - INFO - __main__ - train loss is 0.41730931494385004\n",
      "Steps:   6%| | 922/15000 [09:00<2:10:31,  1.80it/s, lr=0.000114, step_loss=0.00407/27/2023 17:53:49 - INFO - __main__ - train loss is 0.6761116096749902\n",
      "Steps:   6%| | 923/15000 [09:00<1:43:56,  2.26it/s, lr=0.000114, step_loss=0.25907/27/2023 17:53:50 - INFO - __main__ - train loss is 0.6835396811366081\n",
      "Steps:   6%| | 924/15000 [09:00<1:25:51,  2.73it/s, lr=0.000114, step_loss=0.00707/27/2023 17:53:50 - INFO - __main__ - train loss is 0.6855344702489674\n",
      "Steps:   6%| | 925/15000 [09:00<1:13:01,  3.21it/s, lr=0.000114, step_loss=0.00107/27/2023 17:53:50 - INFO - __main__ - train loss is 0.7016126071102917\n",
      "Steps:   6%| | 926/15000 [09:00<1:03:40,  3.68it/s, lr=0.000114, step_loss=0.01607/27/2023 17:53:50 - INFO - __main__ - train loss is 0.7654074286110699\n",
      "Steps:   6%| | 927/15000 [09:00<57:12,  4.10it/s, lr=0.000115, step_loss=0.0638]07/27/2023 17:53:50 - INFO - __main__ - train loss is 0.8379635666497052\n",
      "Steps:   6%| | 928/15000 [09:01<52:41,  4.45it/s, lr=0.000115, step_loss=0.0726]07/27/2023 17:53:50 - INFO - __main__ - train loss is 0.839542951900512\n",
      "Steps:   6%| | 929/15000 [09:01<50:57,  4.60it/s, lr=0.000115, step_loss=0.0015807/27/2023 17:53:51 - INFO - __main__ - train loss is 0.8640019823797047\n",
      "Steps:   6%| | 930/15000 [09:01<54:27,  4.31it/s, lr=0.000115, step_loss=0.0245]07/27/2023 17:53:51 - INFO - __main__ - train loss is 1.0414479305036366\n",
      "Steps:   6%|  | 931/15000 [09:01<51:47,  4.53it/s, lr=0.000115, step_loss=0.177]07/27/2023 17:53:51 - INFO - __main__ - train loss is 1.04873103229329\n",
      "Steps:   6%| | 932/15000 [09:01<50:40,  4.63it/s, lr=0.000115, step_loss=0.0072807/27/2023 17:53:51 - INFO - __main__ - train loss is 1.064393989276141\n",
      "Steps:   6%| | 933/15000 [09:02<48:56,  4.79it/s, lr=0.000115, step_loss=0.0157]07/27/2023 17:53:52 - INFO - __main__ - train loss is 1.0686807562597096\n",
      "Steps:   6%| | 934/15000 [09:02<47:18,  4.96it/s, lr=0.000115, step_loss=0.0042907/27/2023 17:53:52 - INFO - __main__ - train loss is 1.553948633838445\n",
      "Steps:   6%|  | 935/15000 [09:02<45:41,  5.13it/s, lr=0.000116, step_loss=0.485]07/27/2023 17:53:52 - INFO - __main__ - train loss is 2.0567643572576344\n",
      "Steps:   6%|  | 936/15000 [09:02<44:52,  5.22it/s, lr=0.000116, step_loss=0.503]07/27/2023 17:53:52 - INFO - __main__ - train loss is 2.1154740345664322\n",
      "Steps:   6%| | 937/15000 [09:02<44:04,  5.32it/s, lr=0.000116, step_loss=0.0587]07/27/2023 17:53:52 - INFO - __main__ - train loss is 2.126499753911048\n",
      "Steps:   6%|▏ | 938/15000 [09:03<43:29,  5.39it/s, lr=0.000116, step_loss=0.011]07/27/2023 17:53:52 - INFO - __main__ - train loss is 2.5526484069414437\n",
      "Steps:   6%|▏ | 939/15000 [09:03<43:07,  5.43it/s, lr=0.000116, step_loss=0.426]07/27/2023 17:53:53 - INFO - __main__ - train loss is 2.783101123291999\n",
      "Steps:   6%|▏  | 940/15000 [09:03<42:55,  5.46it/s, lr=0.000116, step_loss=0.23]07/27/2023 17:53:53 - INFO - __main__ - train loss is 2.7908158875070512\n",
      "Steps:   6%| | 941/15000 [09:03<42:41,  5.49it/s, lr=0.000116, step_loss=0.0077107/27/2023 17:53:53 - INFO - __main__ - train loss is 2.8061059056781232\n",
      "Steps:   6%| | 942/15000 [09:03<42:49,  5.47it/s, lr=0.000116, step_loss=0.0153]07/27/2023 17:53:53 - INFO - __main__ - train loss is 3.0072632073424757\n",
      "Steps:   6%|▏ | 943/15000 [09:03<42:37,  5.50it/s, lr=0.000117, step_loss=0.201]07/27/2023 17:53:53 - INFO - __main__ - train loss is 3.412359321024269\n",
      "Steps:   6%|▏ | 944/15000 [09:04<42:28,  5.52it/s, lr=0.000117, step_loss=0.405]07/27/2023 17:53:54 - INFO - __main__ - train loss is 3.840337151195854\n",
      "Steps:   6%|▏ | 945/15000 [09:04<42:23,  5.53it/s, lr=0.000117, step_loss=0.428]07/27/2023 17:53:54 - INFO - __main__ - train loss is 3.99531247606501\n",
      "Steps:   6%|▏ | 946/15000 [09:04<42:17,  5.54it/s, lr=0.000117, step_loss=0.155]07/27/2023 17:53:54 - INFO - __main__ - train loss is 4.286225432064384\n",
      "Steps:   6%|▏ | 947/15000 [09:04<42:15,  5.54it/s, lr=0.000117, step_loss=0.291]07/27/2023 17:53:54 - INFO - __main__ - train loss is 4.411387616302818\n",
      "Steps:   6%|▏ | 948/15000 [09:04<42:19,  5.53it/s, lr=0.000117, step_loss=0.125]07/27/2023 17:53:54 - INFO - __main__ - train loss is 5.140634828712791\n",
      "Steps:   6%|▏ | 949/15000 [09:05<42:20,  5.53it/s, lr=0.000117, step_loss=0.729]07/27/2023 17:53:54 - INFO - __main__ - train loss is 5.177073204424232\n",
      "Steps:   6%| | 950/15000 [09:05<42:15,  5.54it/s, lr=0.000117, step_loss=0.0364]07/27/2023 17:53:55 - INFO - __main__ - train loss is 5.187412902247161\n",
      "Steps:   6%| | 951/15000 [09:05<42:11,  5.55it/s, lr=0.000117, step_loss=0.0103]07/27/2023 17:53:55 - INFO - __main__ - train loss is 5.373693763744086\n",
      "Steps:   6%|▏ | 952/15000 [09:05<42:33,  5.50it/s, lr=0.000118, step_loss=0.186]07/27/2023 17:53:55 - INFO - __main__ - train loss is 5.466929606627673\n",
      "Steps:   6%| | 953/15000 [09:05<43:04,  5.44it/s, lr=0.000118, step_loss=0.0932]07/27/2023 17:53:55 - INFO - __main__ - train loss is 5.740055433940142\n",
      "Steps:   6%|▏ | 954/15000 [09:05<43:12,  5.42it/s, lr=0.000118, step_loss=0.273]07/27/2023 17:53:55 - INFO - __main__ - train loss is 5.8444883595220745\n",
      "Steps:   6%|▏ | 955/15000 [09:06<43:21,  5.40it/s, lr=0.000118, step_loss=0.104]07/27/2023 17:53:56 - INFO - __main__ - train loss is 5.958445123862475\n",
      "Steps:   6%|▏ | 956/15000 [09:06<43:13,  5.41it/s, lr=0.000118, step_loss=0.114]07/27/2023 17:53:56 - INFO - __main__ - train loss is 6.09972759289667\n",
      "Steps:   6%|▏ | 957/15000 [09:06<42:53,  5.46it/s, lr=0.000118, step_loss=0.141]07/27/2023 17:53:56 - INFO - __main__ - train loss is 6.109396718908101\n",
      "Steps:   6%| | 958/15000 [09:06<42:39,  5.49it/s, lr=0.000118, step_loss=0.0096707/27/2023 17:53:56 - INFO - __main__ - train loss is 6.119481347966939\n",
      "Steps:   6%| | 959/15000 [09:06<42:29,  5.51it/s, lr=0.000118, step_loss=0.0101]07/27/2023 17:53:56 - INFO - __main__ - train loss is 6.213717900682241\n",
      "Steps:   6%| | 960/15000 [09:07<42:22,  5.52it/s, lr=0.000119, step_loss=0.0942]07/27/2023 17:53:56 - INFO - __main__ - train loss is 6.4307646532543\n",
      "Steps:   6%|▏ | 961/15000 [09:07<42:15,  5.54it/s, lr=0.000119, step_loss=0.217]07/27/2023 17:53:57 - INFO - __main__ - train loss is 6.453605251852423\n",
      "Steps:   6%| | 962/15000 [09:07<42:11,  5.54it/s, lr=0.000119, step_loss=0.0228]07/27/2023 17:53:57 - INFO - __main__ - train loss is 6.8508755140937865\n",
      "Steps:   6%|▏ | 963/15000 [09:07<42:08,  5.55it/s, lr=0.000119, step_loss=0.397]07/27/2023 17:53:57 - INFO - __main__ - train loss is 7.3907150202430785\n",
      "Steps:   6%|▏  | 964/15000 [09:07<42:04,  5.56it/s, lr=0.000119, step_loss=0.54]07/27/2023 17:53:57 - INFO - __main__ - train loss is 7.405489126686007\n",
      "Steps:   6%| | 965/15000 [09:07<42:02,  5.56it/s, lr=0.000119, step_loss=0.0148]07/27/2023 17:53:57 - INFO - __main__ - train loss is 7.600589195732027\n",
      "Steps:   6%|▏ | 966/15000 [09:08<42:01,  5.57it/s, lr=0.000119, step_loss=0.195]07/27/2023 17:53:58 - INFO - __main__ - train loss is 7.60301290685311\n",
      "Steps:   6%| | 967/15000 [09:08<41:59,  5.57it/s, lr=0.000119, step_loss=0.0024207/27/2023 17:53:58 - INFO - __main__ - train loss is 7.60436441632919\n",
      "Steps:   6%| | 968/15000 [09:08<42:00,  5.57it/s, lr=0.00012, step_loss=0.00135]07/27/2023 17:53:58 - INFO - __main__ - train loss is 7.717073715059087\n",
      "Steps:   6%|▏  | 969/15000 [09:08<42:18,  5.53it/s, lr=0.00012, step_loss=0.113]07/27/2023 17:53:58 - INFO - __main__ - train loss is 7.733723110286519\n",
      "Steps:   6%|▏ | 970/15000 [09:08<42:28,  5.51it/s, lr=0.00012, step_loss=0.0166]07/27/2023 17:53:58 - INFO - __main__ - train loss is 7.77016011509113\n",
      "Steps:   6%|▏ | 971/15000 [09:09<42:20,  5.52it/s, lr=0.00012, step_loss=0.0364]07/27/2023 17:53:58 - INFO - __main__ - train loss is 7.7918084401171654\n",
      "Steps:   6%|▏ | 972/15000 [09:09<42:15,  5.53it/s, lr=0.00012, step_loss=0.0216]07/27/2023 17:53:59 - INFO - __main__ - train loss is 7.796851712977514\n",
      "Steps:   6%| | 973/15000 [09:09<42:11,  5.54it/s, lr=0.00012, step_loss=0.00504]07/27/2023 17:53:59 - INFO - __main__ - train loss is 7.799383521778509\n",
      "Steps:   6%| | 974/15000 [09:09<42:17,  5.53it/s, lr=0.00012, step_loss=0.00253]07/27/2023 17:53:59 - INFO - __main__ - train loss is 7.9251040674280375\n",
      "Steps:   6%|▏ | 975/15000 [09:09<42:25,  5.51it/s, lr=0.000121, step_loss=0.126]07/27/2023 17:53:59 - INFO - __main__ - train loss is 7.927971909521148\n",
      "Steps:   7%| | 976/15000 [09:09<42:28,  5.50it/s, lr=0.000121, step_loss=0.0028707/27/2023 17:53:59 - INFO - __main__ - train loss is 8.037524710176513\n",
      "Steps:   7%|▏  | 977/15000 [09:10<42:29,  5.50it/s, lr=0.000121, step_loss=0.11]07/27/2023 17:54:00 - INFO - __main__ - train loss is 8.039207799476571\n",
      "Steps:   7%| | 978/15000 [09:10<42:30,  5.50it/s, lr=0.000121, step_loss=0.0016807/27/2023 17:54:00 - INFO - __main__ - train loss is 8.30130897287745\n",
      "Steps:   7%|▏ | 979/15000 [09:10<42:31,  5.49it/s, lr=0.000121, step_loss=0.262]07/27/2023 17:54:00 - INFO - __main__ - train loss is 8.307295662467368\n",
      "Steps:   7%| | 980/15000 [09:10<42:32,  5.49it/s, lr=0.000121, step_loss=0.0059907/27/2023 17:54:00 - INFO - __main__ - train loss is 8.317992967669852\n",
      "Steps:   7%| | 981/15000 [09:10<42:38,  5.48it/s, lr=0.000121, step_loss=0.0107]07/27/2023 17:54:00 - INFO - __main__ - train loss is 8.471383866970427\n",
      "Steps:   7%|▏ | 982/15000 [09:11<42:35,  5.48it/s, lr=0.000121, step_loss=0.153]07/27/2023 17:54:00 - INFO - __main__ - train loss is 8.489435230498202\n",
      "Steps:   7%| | 983/15000 [09:11<42:34,  5.49it/s, lr=0.000121, step_loss=0.0181]07/27/2023 17:54:01 - INFO - __main__ - train loss is 8.51944653794635\n",
      "Steps:   7%|▏  | 984/15000 [09:11<42:34,  5.49it/s, lr=0.000122, step_loss=0.03]07/27/2023 17:54:01 - INFO - __main__ - train loss is 8.598519177292474\n",
      "Steps:   7%| | 985/15000 [09:11<42:33,  5.49it/s, lr=0.000122, step_loss=0.0791]07/27/2023 17:54:01 - INFO - __main__ - train loss is 8.621554647688754\n",
      "Steps:   7%|▏ | 986/15000 [09:11<42:31,  5.49it/s, lr=0.000122, step_loss=0.023]07/27/2023 17:54:01 - INFO - __main__ - train loss is 8.858471055631526\n",
      "Steps:   7%|▏ | 987/15000 [09:11<42:33,  5.49it/s, lr=0.000122, step_loss=0.237]07/27/2023 17:54:01 - INFO - __main__ - train loss is 8.98674665868748\n",
      "Steps:   7%|▏ | 988/15000 [09:12<42:32,  5.49it/s, lr=0.000122, step_loss=0.128]07/27/2023 17:54:02 - INFO - __main__ - train loss is 9.703910579090007\n",
      "Steps:   7%|▏ | 989/15000 [09:12<42:32,  5.49it/s, lr=0.000122, step_loss=0.717]07/27/2023 17:54:02 - INFO - __main__ - train loss is 9.722440288518555\n",
      "Steps:   7%| | 990/15000 [09:12<42:32,  5.49it/s, lr=0.000122, step_loss=0.0185]07/27/2023 17:54:02 - INFO - __main__ - train loss is 9.80151194438804\n",
      "Steps:   7%| | 991/15000 [09:12<42:30,  5.49it/s, lr=0.000122, step_loss=0.0791]07/27/2023 17:54:02 - INFO - __main__ - train loss is 9.853322201524861\n",
      "Steps:   7%| | 992/15000 [09:12<42:41,  5.47it/s, lr=0.000123, step_loss=0.0518]07/27/2023 17:54:02 - INFO - __main__ - train loss is 10.173532777582295\n",
      "Steps:   7%|▏  | 993/15000 [09:13<42:38,  5.48it/s, lr=0.000123, step_loss=0.32]07/27/2023 17:54:02 - INFO - __main__ - train loss is 10.34750587597955\n",
      "Steps:   7%|▏ | 994/15000 [09:13<42:35,  5.48it/s, lr=0.000123, step_loss=0.174]07/27/2023 17:54:03 - INFO - __main__ - train loss is 10.647728272830136\n",
      "Steps:   7%|▎   | 995/15000 [09:13<43:03,  5.42it/s, lr=0.000123, step_loss=0.3]07/27/2023 17:54:03 - INFO - __main__ - train loss is 10.676351294969209\n",
      "Steps:   7%| | 996/15000 [09:13<42:50,  5.45it/s, lr=0.000123, step_loss=0.0286]07/27/2023 17:54:03 - INFO - __main__ - train loss is 10.815922276233323\n",
      "Steps:   7%|▏  | 997/15000 [09:13<43:08,  5.41it/s, lr=0.000123, step_loss=0.14]07/27/2023 17:54:03 - INFO - __main__ - train loss is 10.834115692530759\n",
      "Steps:   7%| | 998/15000 [09:13<42:57,  5.43it/s, lr=0.000123, step_loss=0.0182]07/27/2023 17:54:03 - INFO - __main__ - train loss is 10.842539195087738\n",
      "Steps:   7%| | 999/15000 [09:14<42:48,  5.45it/s, lr=0.000123, step_loss=0.0084207/27/2023 17:54:04 - INFO - __main__ - train loss is 10.847391572897322\n",
      "Steps:   7%| | 1000/15000 [09:14<42:41,  5.47it/s, lr=0.000123, step_loss=0.008407/27/2023 17:54:04 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-1000\n",
      "07/27/2023 17:54:04 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 17:54:04,140] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 17:54:04,144] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 17:54:04,144] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 17:54:04,151] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 17:54:04,151] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 17:54:04,157] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 17:54:04,158] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 17:54:04,158] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 17:54:04 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-1000/pytorch_model\n",
      "07/27/2023 17:54:04 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-1000/scheduler.bin\n",
      "07/27/2023 17:54:04 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-1000/random_states_0.pkl\n",
      "07/27/2023 17:54:04 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-1000\n",
      "Steps:   7%| | 1000/15000 [09:14<42:41,  5.47it/s, lr=0.000124, step_loss=0.004807/27/2023 17:54:04 - INFO - __main__ - train loss is 10.956207377021201\n",
      "Steps:   7%| | 1001/15000 [09:14<44:01,  5.30it/s, lr=0.000124, step_loss=0.109]07/27/2023 17:54:04 - INFO - __main__ - train loss is 11.006958422367461\n",
      "Steps:   7%| | 1002/15000 [09:14<43:38,  5.35it/s, lr=0.000124, step_loss=0.050807/27/2023 17:54:04 - INFO - __main__ - train loss is 11.009226448484696\n",
      "Steps:   7%| | 1003/15000 [09:14<43:17,  5.39it/s, lr=0.000124, step_loss=0.002207/27/2023 17:54:04 - INFO - __main__ - train loss is 11.017037877463736\n",
      "Steps:   7%| | 1004/15000 [09:15<42:50,  5.44it/s, lr=0.000124, step_loss=0.007807/27/2023 17:54:04 - INFO - __main__ - train loss is 11.024651405983604\n",
      "Steps:   7%| | 1005/15000 [09:15<42:32,  5.48it/s, lr=0.000124, step_loss=0.007607/27/2023 17:54:05 - INFO - __main__ - train loss is 11.026184758520685\n",
      "Steps:   7%| | 1006/15000 [09:15<42:21,  5.51it/s, lr=0.000124, step_loss=0.001507/27/2023 17:54:05 - INFO - __main__ - train loss is 11.032614257535897\n",
      "Steps:   7%| | 1007/15000 [09:15<42:36,  5.47it/s, lr=0.000124, step_loss=0.006407/27/2023 17:54:05 - INFO - __main__ - train loss is 11.239416655502282\n",
      "Steps:   7%| | 1008/15000 [09:15<43:10,  5.40it/s, lr=0.000125, step_loss=0.207]07/27/2023 17:54:05 - INFO - __main__ - train loss is 11.698799725971185\n",
      "Steps:   7%| | 1009/15000 [09:16<42:52,  5.44it/s, lr=0.000125, step_loss=0.459]07/27/2023 17:54:05 - INFO - __main__ - train loss is 11.906193491420709\n",
      "Steps:   7%| | 1010/15000 [09:16<42:41,  5.46it/s, lr=0.000125, step_loss=0.207]07/27/2023 17:54:06 - INFO - __main__ - train loss is 11.910882029565983\n",
      "Steps:   7%| | 1011/15000 [09:16<42:29,  5.49it/s, lr=0.000125, step_loss=0.004607/27/2023 17:54:06 - INFO - __main__ - train loss is 11.950325615587644\n",
      "Steps:   7%| | 1012/15000 [09:16<42:19,  5.51it/s, lr=0.000125, step_loss=0.039407/27/2023 17:54:06 - INFO - __main__ - train loss is 12.385258264723234\n",
      "Steps:   7%| | 1013/15000 [09:16<42:39,  5.46it/s, lr=0.000125, step_loss=0.435]07/27/2023 17:54:06 - INFO - __main__ - train loss is 12.390377722564153\n",
      "Steps:   7%| | 1014/15000 [09:16<42:27,  5.49it/s, lr=0.000125, step_loss=0.005107/27/2023 17:54:06 - INFO - __main__ - train loss is 12.392118227784522\n",
      "Steps:   7%| | 1015/15000 [09:17<42:19,  5.51it/s, lr=0.000126, step_loss=0.001707/27/2023 17:54:06 - INFO - __main__ - train loss is 12.762911033933051\n",
      "Steps:   7%| | 1016/15000 [09:17<42:11,  5.52it/s, lr=0.000126, step_loss=0.371]07/27/2023 17:54:07 - INFO - __main__ - train loss is 13.145841878955252\n",
      "Steps:   7%| | 1017/15000 [09:17<42:05,  5.54it/s, lr=0.000126, step_loss=0.383]07/27/2023 17:54:07 - INFO - __main__ - train loss is 13.193548810784705\n",
      "Steps:   7%| | 1018/15000 [09:17<42:01,  5.55it/s, lr=0.000126, step_loss=0.047707/27/2023 17:54:07 - INFO - __main__ - train loss is 13.349680435960181\n",
      "Steps:   7%| | 1019/15000 [09:17<42:11,  5.52it/s, lr=0.000126, step_loss=0.156]07/27/2023 17:54:07 - INFO - __main__ - train loss is 13.354137320653535\n",
      "Steps:   7%| | 1020/15000 [09:18<42:29,  5.48it/s, lr=0.000126, step_loss=0.004407/27/2023 17:54:07 - INFO - __main__ - train loss is 13.385169920162298\n",
      "Steps:   7%| | 1021/15000 [09:18<42:34,  5.47it/s, lr=0.000126, step_loss=0.031]07/27/2023 17:54:08 - INFO - __main__ - train loss is 13.436939444974996\n",
      "Steps:   7%| | 1022/15000 [09:18<42:23,  5.50it/s, lr=0.000126, step_loss=0.051807/27/2023 17:54:08 - INFO - __main__ - train loss is 14.076994386152364\n",
      "Steps:   7%|▏ | 1023/15000 [09:18<42:15,  5.51it/s, lr=0.000127, step_loss=0.64]07/27/2023 17:54:08 - INFO - __main__ - train loss is 14.07863552076742\n",
      "Steps:   7%| | 1024/15000 [09:18<42:30,  5.48it/s, lr=0.000127, step_loss=0.001607/27/2023 17:54:08 - INFO - __main__ - train loss is 14.0898607657291\n",
      "Steps:   7%| | 1025/15000 [09:18<42:28,  5.48it/s, lr=0.000127, step_loss=0.011207/27/2023 17:54:08 - INFO - __main__ - train loss is 14.463518141303211\n",
      "Steps:   7%| | 1026/15000 [09:19<42:19,  5.50it/s, lr=0.000127, step_loss=0.374]07/27/2023 17:54:08 - INFO - __main__ - train loss is 14.497392794582993\n",
      "Steps:   7%| | 1027/15000 [09:19<42:19,  5.50it/s, lr=0.000127, step_loss=0.033907/27/2023 17:54:09 - INFO - __main__ - train loss is 14.514870444778353\n",
      "Steps:   7%| | 1028/15000 [09:19<42:16,  5.51it/s, lr=0.000127, step_loss=0.017507/27/2023 17:54:09 - INFO - __main__ - train loss is 14.677825401071459\n",
      "Steps:   7%| | 1029/15000 [09:19<42:09,  5.52it/s, lr=0.000127, step_loss=0.163]07/27/2023 17:54:09 - INFO - __main__ - train loss is 14.715086916927248\n",
      "Steps:   7%| | 1030/15000 [09:19<42:04,  5.53it/s, lr=0.000127, step_loss=0.037307/27/2023 17:54:09 - INFO - __main__ - train loss is 15.045408884529024\n",
      "Steps:   7%|▏ | 1031/15000 [09:20<41:59,  5.54it/s, lr=0.000128, step_loss=0.33]07/27/2023 17:54:09 - INFO - __main__ - train loss is 15.126248876098543\n",
      "Steps:   7%| | 1032/15000 [09:20<41:55,  5.55it/s, lr=0.000128, step_loss=0.080807/27/2023 17:54:10 - INFO - __main__ - train loss is 15.365444699767977\n",
      "Steps:   7%| | 1033/15000 [09:20<41:53,  5.56it/s, lr=0.000128, step_loss=0.239]07/27/2023 17:54:10 - INFO - __main__ - train loss is 15.3837561593391\n",
      "Steps:   7%| | 1034/15000 [09:20<41:50,  5.56it/s, lr=0.000128, step_loss=0.018307/27/2023 17:54:10 - INFO - __main__ - train loss is 15.92090523103252\n",
      "Steps:   7%| | 1035/15000 [09:20<41:57,  5.55it/s, lr=0.000128, step_loss=0.537]07/27/2023 17:54:10 - INFO - __main__ - train loss is 16.246182201895863\n",
      "Steps:   7%| | 1036/15000 [09:20<41:53,  5.55it/s, lr=0.000128, step_loss=0.325]07/27/2023 17:54:10 - INFO - __main__ - train loss is 16.71993130305782\n",
      "Steps:   7%| | 1037/15000 [09:21<41:51,  5.56it/s, lr=0.000128, step_loss=0.474]07/27/2023 17:54:10 - INFO - __main__ - train loss is 16.769928647670895\n",
      "Steps:   7%|▏ | 1038/15000 [09:21<41:50,  5.56it/s, lr=0.000128, step_loss=0.05]07/27/2023 17:54:11 - INFO - __main__ - train loss is 16.811075358185917\n",
      "Steps:   7%| | 1039/15000 [09:21<41:49,  5.56it/s, lr=0.000129, step_loss=0.041107/27/2023 17:54:11 - INFO - __main__ - train loss is 16.946400134358555\n",
      "Steps:   7%| | 1040/15000 [09:21<41:48,  5.57it/s, lr=0.000129, step_loss=0.135]07/27/2023 17:54:11 - INFO - __main__ - train loss is 17.027228041086346\n",
      "Steps:   7%| | 1041/15000 [09:21<41:51,  5.56it/s, lr=0.000129, step_loss=0.080807/27/2023 17:54:11 - INFO - __main__ - train loss is 17.536357982549816\n",
      "Steps:   7%| | 1042/15000 [09:21<41:48,  5.56it/s, lr=0.000129, step_loss=0.509]07/27/2023 17:54:11 - INFO - __main__ - train loss is 17.537569299456663\n",
      "Steps:   7%| | 1043/15000 [09:22<41:47,  5.57it/s, lr=0.000129, step_loss=0.001207/27/2023 17:54:12 - INFO - __main__ - train loss is 17.585381828364916\n",
      "Steps:   7%| | 1044/15000 [09:22<41:47,  5.57it/s, lr=0.000129, step_loss=0.047807/27/2023 17:54:12 - INFO - __main__ - train loss is 17.601392656681128\n",
      "Steps:   7%| | 1045/15000 [09:22<41:46,  5.57it/s, lr=0.000129, step_loss=0.016]07/27/2023 17:54:12 - INFO - __main__ - train loss is 17.946425765869208\n",
      "Steps:   7%| | 1046/15000 [09:22<41:51,  5.56it/s, lr=0.000129, step_loss=0.345]07/27/2023 17:54:12 - INFO - __main__ - train loss is 18.138914257404394\n",
      "Steps:   7%|▏ | 1047/15000 [09:22<41:50,  5.56it/s, lr=0.00013, step_loss=0.192]07/27/2023 17:54:12 - INFO - __main__ - train loss is 18.156282704439946\n",
      "Steps:   7%| | 1048/15000 [09:23<41:48,  5.56it/s, lr=0.00013, step_loss=0.0174]07/27/2023 17:54:12 - INFO - __main__ - train loss is 18.160092332982458\n",
      "Steps:   7%| | 1049/15000 [09:23<41:51,  5.56it/s, lr=0.00013, step_loss=0.0038107/27/2023 17:54:13 - INFO - __main__ - train loss is 18.161839837790467\n",
      "Steps:   7%| | 1050/15000 [09:23<41:48,  5.56it/s, lr=0.00013, step_loss=0.0017507/27/2023 17:54:13 - INFO - __main__ - train loss is 18.242891247035004\n",
      "Steps:   7%| | 1051/15000 [09:23<41:53,  5.55it/s, lr=0.00013, step_loss=0.0811]07/27/2023 17:54:13 - INFO - __main__ - train loss is 18.311668897629716\n",
      "Steps:   7%| | 1052/15000 [09:23<41:51,  5.55it/s, lr=0.00013, step_loss=0.0688]07/27/2023 17:54:13 - INFO - __main__ - train loss is 18.44505696988199\n",
      "Steps:   7%|▏ | 1053/15000 [09:23<42:10,  5.51it/s, lr=0.00013, step_loss=0.133]07/27/2023 17:54:13 - INFO - __main__ - train loss is 18.483209411264397\n",
      "Steps:   7%| | 1054/15000 [09:24<42:22,  5.48it/s, lr=0.00013, step_loss=0.0382]07/27/2023 17:54:14 - INFO - __main__ - train loss is 18.667367274523713\n",
      "Steps:   7%| | 1055/15000 [09:24<42:33,  5.46it/s, lr=0.000131, step_loss=0.184]07/27/2023 17:54:14 - INFO - __main__ - train loss is 18.754376302124\n",
      "Steps:   7%| | 1056/15000 [09:24<42:23,  5.48it/s, lr=0.000131, step_loss=0.087]07/27/2023 17:54:14 - INFO - __main__ - train loss is 18.944704572320916\n",
      "Steps:   7%|▏ | 1057/15000 [09:24<42:11,  5.51it/s, lr=0.000131, step_loss=0.19]07/27/2023 17:54:14 - INFO - __main__ - train loss is 18.94786745228339\n",
      "Steps:   7%| | 1058/15000 [09:24<42:03,  5.53it/s, lr=0.000131, step_loss=0.003107/27/2023 17:54:14 - INFO - __main__ - train loss is 18.969160950859077\n",
      "Steps:   7%| | 1059/15000 [09:25<41:55,  5.54it/s, lr=0.000131, step_loss=0.021307/27/2023 17:54:14 - INFO - __main__ - train loss is 19.02395971037913\n",
      "Steps:   7%| | 1060/15000 [09:25<41:52,  5.55it/s, lr=0.000131, step_loss=0.054807/27/2023 17:54:15 - INFO - __main__ - train loss is 19.284123315592296\n",
      "Steps:   7%|▏ | 1061/15000 [09:25<41:55,  5.54it/s, lr=0.000131, step_loss=0.26]07/27/2023 17:54:15 - INFO - __main__ - train loss is 19.319436065037735\n",
      "Steps:   7%| | 1062/15000 [09:25<42:14,  5.50it/s, lr=0.000131, step_loss=0.035307/27/2023 17:54:15 - INFO - __main__ - train loss is 19.368019092013128\n",
      "Steps:   7%| | 1063/15000 [09:25<42:13,  5.50it/s, lr=0.000131, step_loss=0.048607/27/2023 17:54:15 - INFO - __main__ - train loss is 19.515948432614096\n",
      "Steps:   7%| | 1064/15000 [09:25<42:02,  5.52it/s, lr=0.000132, step_loss=0.148]07/27/2023 17:54:15 - INFO - __main__ - train loss is 20.151944774319418\n",
      "Steps:   7%| | 1065/15000 [09:26<41:57,  5.54it/s, lr=0.000132, step_loss=0.636]07/27/2023 17:54:16 - INFO - __main__ - train loss is 20.366885366966017\n",
      "Steps:   7%| | 1066/15000 [09:26<42:00,  5.53it/s, lr=0.000132, step_loss=0.215]07/27/2023 17:54:16 - INFO - __main__ - train loss is 20.383649676223285\n",
      "Steps:   7%| | 1067/15000 [09:26<41:54,  5.54it/s, lr=0.000132, step_loss=0.016807/27/2023 17:54:16 - INFO - __main__ - train loss is 20.390067393076606\n",
      "Steps:   7%| | 1068/15000 [09:26<41:50,  5.55it/s, lr=0.000132, step_loss=0.006407/27/2023 17:54:16 - INFO - __main__ - train loss is 20.640654677641578\n",
      "Steps:   7%| | 1069/15000 [09:26<41:47,  5.56it/s, lr=0.000132, step_loss=0.251]07/27/2023 17:54:16 - INFO - __main__ - train loss is 20.686895730090328\n",
      "Steps:   7%| | 1070/15000 [09:27<41:44,  5.56it/s, lr=0.000132, step_loss=0.046207/27/2023 17:54:16 - INFO - __main__ - train loss is 20.7470206116559\n",
      "Steps:   7%| | 1071/15000 [09:27<41:57,  5.53it/s, lr=0.000133, step_loss=0.060107/27/2023 17:54:17 - INFO - __main__ - train loss is 20.811206365120597\n",
      "Steps:   7%| | 1072/15000 [09:27<41:53,  5.54it/s, lr=0.000133, step_loss=0.064207/27/2023 17:54:17 - INFO - __main__ - train loss is 21.13088693667669\n",
      "Steps:   7%|▏ | 1073/15000 [09:27<41:49,  5.55it/s, lr=0.000133, step_loss=0.32]07/27/2023 17:54:17 - INFO - __main__ - train loss is 21.203952478361316\n",
      "Steps:   7%| | 1074/15000 [09:27<41:46,  5.56it/s, lr=0.000133, step_loss=0.073107/27/2023 17:54:17 - INFO - __main__ - train loss is 21.5626123418333\n",
      "Steps:   7%| | 1075/15000 [09:27<41:45,  5.56it/s, lr=0.000133, step_loss=0.359]07/27/2023 17:54:17 - INFO - __main__ - train loss is 21.793401168775745\n",
      "Steps:   7%| | 1076/15000 [09:28<41:49,  5.55it/s, lr=0.000133, step_loss=0.231]07/27/2023 17:54:18 - INFO - __main__ - train loss is 21.79560240067076\n",
      "Steps:   7%| | 1077/15000 [09:28<41:46,  5.56it/s, lr=0.000133, step_loss=0.002207/27/2023 17:54:18 - INFO - __main__ - train loss is 21.828748402069323\n",
      "Steps:   7%| | 1078/15000 [09:28<41:43,  5.56it/s, lr=0.000133, step_loss=0.033107/27/2023 17:54:18 - INFO - __main__ - train loss is 21.83056155743543\n",
      "Steps:   7%| | 1079/15000 [09:28<41:42,  5.56it/s, lr=0.000134, step_loss=0.001807/27/2023 17:54:18 - INFO - __main__ - train loss is 22.109636822366156\n",
      "Steps:   7%| | 1080/15000 [09:28<41:41,  5.57it/s, lr=0.000134, step_loss=0.279]07/27/2023 17:54:18 - INFO - __main__ - train loss is 22.37525177898351\n",
      "Steps:   7%| | 1081/15000 [09:29<41:47,  5.55it/s, lr=0.000134, step_loss=0.266]07/27/2023 17:54:18 - INFO - __main__ - train loss is 22.634483972215094\n",
      "Steps:   7%| | 1082/15000 [09:29<41:45,  5.56it/s, lr=0.000134, step_loss=0.259]07/27/2023 17:54:19 - INFO - __main__ - train loss is 23.223924437188543\n",
      "Steps:   7%| | 1083/15000 [09:29<41:43,  5.56it/s, lr=0.000134, step_loss=0.589]07/27/2023 17:54:19 - INFO - __main__ - train loss is 23.32723881455604\n",
      "Steps:   7%| | 1084/15000 [09:29<41:43,  5.56it/s, lr=0.000134, step_loss=0.103]07/27/2023 17:54:19 - INFO - __main__ - train loss is 23.440563292824663\n",
      "Steps:   7%| | 1085/15000 [09:29<41:42,  5.56it/s, lr=0.000134, step_loss=0.113]07/27/2023 17:54:19 - INFO - __main__ - train loss is 23.58189781161491\n",
      "Steps:   7%| | 1086/15000 [09:29<41:49,  5.54it/s, lr=0.000134, step_loss=0.141]07/27/2023 17:54:19 - INFO - __main__ - train loss is 23.863044814788736\n",
      "Steps:   7%| | 1087/15000 [09:30<41:47,  5.55it/s, lr=0.000135, step_loss=0.281]07/27/2023 17:54:19 - INFO - __main__ - train loss is 23.865717093111016\n",
      "Steps:   7%| | 1088/15000 [09:30<41:45,  5.55it/s, lr=0.000135, step_loss=0.002607/27/2023 17:54:20 - INFO - __main__ - train loss is 23.914511243463494\n",
      "Steps:   7%| | 1089/15000 [09:30<42:08,  5.50it/s, lr=0.000135, step_loss=0.048807/27/2023 17:54:20 - INFO - __main__ - train loss is 24.17346040403936\n",
      "Steps:   7%| | 1090/15000 [09:30<42:10,  5.50it/s, lr=0.000135, step_loss=0.259]07/27/2023 17:54:20 - INFO - __main__ - train loss is 24.651852915645577\n",
      "Steps:   7%| | 1091/15000 [09:30<42:06,  5.51it/s, lr=0.000135, step_loss=0.478]07/27/2023 17:54:20 - INFO - __main__ - train loss is 24.846409002901055\n",
      "Steps:   7%| | 1092/15000 [09:31<42:26,  5.46it/s, lr=0.000135, step_loss=0.195]07/27/2023 17:54:20 - INFO - __main__ - train loss is 24.84829432296101\n",
      "Steps:   7%| | 1093/15000 [09:31<42:20,  5.47it/s, lr=0.000135, step_loss=0.001807/27/2023 17:54:21 - INFO - __main__ - train loss is 25.04779078590218\n",
      "Steps:   7%| | 1094/15000 [09:31<42:09,  5.50it/s, lr=0.000135, step_loss=0.199]07/27/2023 17:54:21 - INFO - __main__ - train loss is 25.787063022726215\n",
      "Steps:   7%| | 1095/15000 [09:31<42:05,  5.51it/s, lr=0.000136, step_loss=0.739]07/27/2023 17:54:21 - INFO - __main__ - train loss is 25.789264437393285\n",
      "Steps:   7%| | 1096/15000 [09:31<42:06,  5.50it/s, lr=0.000136, step_loss=0.002207/27/2023 17:54:21 - INFO - __main__ - train loss is 26.05559932871256\n",
      "Steps:   7%| | 1097/15000 [09:31<41:58,  5.52it/s, lr=0.000136, step_loss=0.266]07/27/2023 17:54:21 - INFO - __main__ - train loss is 26.475583907798864\n",
      "Steps:   7%|▏ | 1098/15000 [09:32<41:50,  5.54it/s, lr=0.000136, step_loss=0.42]07/27/2023 17:54:21 - INFO - __main__ - train loss is 26.79462048097048\n",
      "Steps:   7%| | 1099/15000 [09:32<41:44,  5.55it/s, lr=0.000136, step_loss=0.319]07/27/2023 17:54:22 - INFO - __main__ - train loss is 26.805856811464764\n",
      "Steps:   7%| | 1100/15000 [09:32<41:41,  5.56it/s, lr=0.000136, step_loss=0.011207/27/2023 17:54:22 - INFO - __main__ - train loss is 27.14642046636436\n",
      "Steps:   7%| | 1101/15000 [09:32<41:50,  5.54it/s, lr=0.000136, step_loss=0.341]07/27/2023 17:54:22 - INFO - __main__ - train loss is 27.167651083902456\n",
      "Steps:   7%| | 1102/15000 [09:32<41:45,  5.55it/s, lr=0.000136, step_loss=0.021207/27/2023 17:54:22 - INFO - __main__ - train loss is 27.463231620029546\n",
      "Steps:   7%| | 1103/15000 [09:33<41:43,  5.55it/s, lr=0.000137, step_loss=0.296]07/27/2023 17:54:22 - INFO - __main__ - train loss is 27.574076947406866\n",
      "Steps:   7%| | 1104/15000 [09:33<41:42,  5.55it/s, lr=0.000137, step_loss=0.111]07/27/2023 17:54:23 - INFO - __main__ - train loss is 27.579925744910724\n",
      "Steps:   7%| | 1105/15000 [09:33<41:40,  5.56it/s, lr=0.000137, step_loss=0.005807/27/2023 17:54:23 - INFO - __main__ - train loss is 27.95584818639327\n",
      "Steps:   7%| | 1106/15000 [09:33<41:46,  5.54it/s, lr=0.000137, step_loss=0.376]07/27/2023 17:54:23 - INFO - __main__ - train loss is 27.960133670945652\n",
      "Steps:   7%| | 1107/15000 [09:33<41:43,  5.55it/s, lr=0.000137, step_loss=0.004207/27/2023 17:54:23 - INFO - __main__ - train loss is 28.364979743142612\n",
      "Steps:   7%| | 1108/15000 [09:33<41:40,  5.55it/s, lr=0.000137, step_loss=0.405]07/27/2023 17:54:23 - INFO - __main__ - train loss is 28.386017791111954\n",
      "Steps:   7%| | 1109/15000 [09:34<41:44,  5.55it/s, lr=0.000137, step_loss=0.021]07/27/2023 17:54:23 - INFO - __main__ - train loss is 28.40317338996101\n",
      "Steps:   7%| | 1110/15000 [09:34<41:41,  5.55it/s, lr=0.000137, step_loss=0.017207/27/2023 17:54:24 - INFO - __main__ - train loss is 28.528543117572553\n",
      "Steps:   7%| | 1111/15000 [09:34<41:57,  5.52it/s, lr=0.000138, step_loss=0.125]07/27/2023 17:54:24 - INFO - __main__ - train loss is 28.794898542691953\n",
      "Steps:   7%| | 1112/15000 [09:34<41:51,  5.53it/s, lr=0.000138, step_loss=0.266]07/27/2023 17:54:24 - INFO - __main__ - train loss is 28.82119399786461\n",
      "Steps:   7%| | 1113/15000 [09:34<41:46,  5.54it/s, lr=0.000138, step_loss=0.026307/27/2023 17:54:24 - INFO - __main__ - train loss is 29.129550879006274\n",
      "Steps:   7%| | 1114/15000 [09:34<41:41,  5.55it/s, lr=0.000138, step_loss=0.308]07/27/2023 17:54:24 - INFO - __main__ - train loss is 29.25993353605736\n",
      "Steps:   7%|▏ | 1115/15000 [09:35<41:39,  5.56it/s, lr=0.000138, step_loss=0.13]07/27/2023 17:54:25 - INFO - __main__ - train loss is 29.388274182681926\n",
      "Steps:   7%| | 1116/15000 [09:35<41:52,  5.53it/s, lr=0.000138, step_loss=0.128]07/27/2023 17:54:25 - INFO - __main__ - train loss is 29.392726756283082\n",
      "Steps:   7%| | 1117/15000 [09:35<41:46,  5.54it/s, lr=0.000138, step_loss=0.004407/27/2023 17:54:25 - INFO - __main__ - train loss is 29.687016941257752\n",
      "Steps:   7%| | 1118/15000 [09:35<41:43,  5.54it/s, lr=0.000138, step_loss=0.294]07/27/2023 17:54:25 - INFO - __main__ - train loss is 29.69371539831627\n",
      "Steps:   7%| | 1119/15000 [09:35<41:46,  5.54it/s, lr=0.000139, step_loss=0.006707/27/2023 17:54:25 - INFO - __main__ - train loss is 29.711561926756985\n",
      "Steps:   7%| | 1120/15000 [09:36<41:44,  5.54it/s, lr=0.000139, step_loss=0.017807/27/2023 17:54:25 - INFO - __main__ - train loss is 29.85616637126077\n",
      "Steps:   7%| | 1121/15000 [09:36<42:07,  5.49it/s, lr=0.000139, step_loss=0.145]07/27/2023 17:54:26 - INFO - __main__ - train loss is 29.878613908891566\n",
      "Steps:   7%| | 1122/15000 [09:36<41:58,  5.51it/s, lr=0.000139, step_loss=0.022407/27/2023 17:54:26 - INFO - __main__ - train loss is 30.41192968667019\n",
      "Steps:   7%| | 1123/15000 [09:36<41:51,  5.53it/s, lr=0.000139, step_loss=0.533]07/27/2023 17:54:26 - INFO - __main__ - train loss is 30.415480134193785\n",
      "Steps:   7%| | 1124/15000 [09:36<41:48,  5.53it/s, lr=0.000139, step_loss=0.003507/27/2023 17:54:26 - INFO - __main__ - train loss is 30.614044961635955\n",
      "Steps:   8%| | 1125/15000 [09:36<41:46,  5.53it/s, lr=0.000139, step_loss=0.199]07/27/2023 17:54:26 - INFO - __main__ - train loss is 30.631957837496884\n",
      "Steps:   8%| | 1126/15000 [09:37<42:06,  5.49it/s, lr=0.000139, step_loss=0.017907/27/2023 17:54:27 - INFO - __main__ - train loss is 30.757764660869725\n",
      "Steps:   8%|▏ | 1127/15000 [09:37<41:57,  5.51it/s, lr=0.00014, step_loss=0.126]07/27/2023 17:54:27 - INFO - __main__ - train loss is 31.115580462967046\n",
      "Steps:   8%|▏ | 1128/15000 [09:37<41:49,  5.53it/s, lr=0.00014, step_loss=0.358]07/27/2023 17:54:27 - INFO - __main__ - train loss is 31.16271527961362\n",
      "Steps:   8%| | 1129/15000 [09:37<41:46,  5.53it/s, lr=0.00014, step_loss=0.0471]07/27/2023 17:54:27 - INFO - __main__ - train loss is 31.276926332269795\n",
      "Steps:   8%|▏ | 1130/15000 [09:37<41:43,  5.54it/s, lr=0.00014, step_loss=0.114]07/27/2023 17:54:27 - INFO - __main__ - train loss is 31.360012055491097\n",
      "Steps:   8%| | 1131/15000 [09:38<42:04,  5.49it/s, lr=0.00014, step_loss=0.0831]07/27/2023 17:54:27 - INFO - __main__ - train loss is 31.413602409069426\n",
      "Steps:   8%| | 1132/15000 [09:38<41:55,  5.51it/s, lr=0.00014, step_loss=0.0536]07/27/2023 17:54:28 - INFO - __main__ - train loss is 31.5986851277994\n",
      "Steps:   8%|▏ | 1133/15000 [09:38<41:55,  5.51it/s, lr=0.00014, step_loss=0.185]07/27/2023 17:54:28 - INFO - __main__ - train loss is 31.626499359612353\n",
      "Steps:   8%| | 1134/15000 [09:38<41:49,  5.52it/s, lr=0.00014, step_loss=0.0278]07/27/2023 17:54:28 - INFO - __main__ - train loss is 31.72720896929968\n",
      "Steps:   8%| | 1135/15000 [09:38<41:50,  5.52it/s, lr=0.000141, step_loss=0.101]07/27/2023 17:54:28 - INFO - __main__ - train loss is 31.85497462481726\n",
      "Steps:   8%| | 1136/15000 [09:38<42:10,  5.48it/s, lr=0.000141, step_loss=0.128]07/27/2023 17:54:28 - INFO - __main__ - train loss is 31.922045675222762\n",
      "Steps:   8%| | 1137/15000 [09:39<41:56,  5.51it/s, lr=0.000141, step_loss=0.067107/27/2023 17:54:29 - INFO - __main__ - train loss is 31.970015511964448\n",
      "Steps:   8%| | 1138/15000 [09:39<41:48,  5.53it/s, lr=0.000141, step_loss=0.048]07/27/2023 17:54:29 - INFO - __main__ - train loss is 31.97692327213008\n",
      "Steps:   8%| | 1139/15000 [09:39<41:44,  5.53it/s, lr=0.000141, step_loss=0.006907/27/2023 17:54:29 - INFO - __main__ - train loss is 31.984040382434614\n",
      "Steps:   8%| | 1140/15000 [09:39<41:41,  5.54it/s, lr=0.000141, step_loss=0.007107/27/2023 17:54:29 - INFO - __main__ - train loss is 32.010213851113804\n",
      "Steps:   8%| | 1141/15000 [09:39<42:04,  5.49it/s, lr=0.000141, step_loss=0.026207/27/2023 17:54:29 - INFO - __main__ - train loss is 32.0933766803937\n",
      "Steps:   8%| | 1142/15000 [09:40<41:54,  5.51it/s, lr=0.000141, step_loss=0.083207/27/2023 17:54:29 - INFO - __main__ - train loss is 32.17759366251994\n",
      "Steps:   8%| | 1143/15000 [09:40<41:46,  5.53it/s, lr=0.000141, step_loss=0.084207/27/2023 17:54:30 - INFO - __main__ - train loss is 32.19340295076836\n",
      "Steps:   8%| | 1144/15000 [09:40<41:41,  5.54it/s, lr=0.000142, step_loss=0.015807/27/2023 17:54:30 - INFO - __main__ - train loss is 32.20179911341984\n",
      "Steps:   8%| | 1145/15000 [09:40<41:39,  5.54it/s, lr=0.000142, step_loss=0.008407/27/2023 17:54:30 - INFO - __main__ - train loss is 32.592023272183724\n",
      "Steps:   8%|▏ | 1146/15000 [09:40<41:45,  5.53it/s, lr=0.000142, step_loss=0.39]07/27/2023 17:54:30 - INFO - __main__ - train loss is 32.71975137677509\n",
      "Steps:   8%| | 1147/15000 [09:40<41:39,  5.54it/s, lr=0.000142, step_loss=0.128]07/27/2023 17:54:30 - INFO - __main__ - train loss is 32.73769011173863\n",
      "Steps:   8%| | 1148/15000 [09:41<41:36,  5.55it/s, lr=0.000142, step_loss=0.017907/27/2023 17:54:31 - INFO - __main__ - train loss is 32.8123575655045\n",
      "Steps:   8%| | 1149/15000 [09:41<41:31,  5.56it/s, lr=0.000142, step_loss=0.074707/27/2023 17:54:31 - INFO - __main__ - train loss is 32.87473389331717\n",
      "Steps:   8%| | 1150/15000 [09:41<41:30,  5.56it/s, lr=0.000142, step_loss=0.062407/27/2023 17:54:31 - INFO - __main__ - train loss is 32.877756967325695\n",
      "Steps:   8%| | 1151/15000 [09:41<41:36,  5.55it/s, lr=0.000142, step_loss=0.003007/27/2023 17:54:31 - INFO - __main__ - train loss is 32.9581357530551\n",
      "Steps:   8%| | 1152/15000 [09:41<41:35,  5.55it/s, lr=0.000143, step_loss=0.080407/27/2023 17:54:31 - INFO - __main__ - train loss is 33.743081956286915\n",
      "Steps:   8%| | 1153/15000 [09:42<41:58,  5.50it/s, lr=0.000143, step_loss=0.785]07/27/2023 17:54:31 - INFO - __main__ - train loss is 33.915273993392475\n",
      "Steps:   8%| | 1154/15000 [09:42<41:47,  5.52it/s, lr=0.000143, step_loss=0.172]07/27/2023 17:54:32 - INFO - __main__ - train loss is 33.97301230498124\n",
      "Steps:   8%| | 1155/15000 [09:42<41:42,  5.53it/s, lr=0.000143, step_loss=0.057707/27/2023 17:54:32 - INFO - __main__ - train loss is 34.199616051395424\n",
      "Steps:   8%| | 1156/15000 [09:42<41:56,  5.50it/s, lr=0.000143, step_loss=0.227]07/27/2023 17:54:32 - INFO - __main__ - train loss is 34.23201808251906\n",
      "Steps:   8%| | 1157/15000 [09:42<41:49,  5.52it/s, lr=0.000143, step_loss=0.032407/27/2023 17:54:32 - INFO - __main__ - train loss is 34.24416088697035\n",
      "Steps:   8%| | 1158/15000 [09:42<42:05,  5.48it/s, lr=0.000143, step_loss=0.012107/27/2023 17:54:32 - INFO - __main__ - train loss is 34.30268105503637\n",
      "Steps:   8%| | 1159/15000 [09:43<41:51,  5.51it/s, lr=0.000143, step_loss=0.058507/27/2023 17:54:33 - INFO - __main__ - train loss is 34.368829455343075\n",
      "Steps:   8%| | 1160/15000 [09:43<41:42,  5.53it/s, lr=0.000144, step_loss=0.066107/27/2023 17:54:33 - INFO - __main__ - train loss is 34.38037131924648\n",
      "Steps:   8%| | 1161/15000 [09:43<41:44,  5.53it/s, lr=0.000144, step_loss=0.011507/27/2023 17:54:33 - INFO - __main__ - train loss is 34.5617196430685\n",
      "Steps:   8%| | 1162/15000 [09:43<41:37,  5.54it/s, lr=0.000144, step_loss=0.181]07/27/2023 17:54:33 - INFO - __main__ - train loss is 34.62518343527336\n",
      "Steps:   8%| | 1163/15000 [09:43<41:33,  5.55it/s, lr=0.000144, step_loss=0.063507/27/2023 17:54:33 - INFO - __main__ - train loss is 34.82600626547355\n",
      "Steps:   8%| | 1164/15000 [09:44<41:30,  5.56it/s, lr=0.000144, step_loss=0.201]07/27/2023 17:54:33 - INFO - __main__ - train loss is 34.99495184619445\n",
      "Steps:   8%| | 1165/15000 [09:44<41:27,  5.56it/s, lr=0.000144, step_loss=0.169]07/27/2023 17:54:34 - INFO - __main__ - train loss is 35.121307732653804\n",
      "Steps:   8%| | 1166/15000 [09:44<41:31,  5.55it/s, lr=0.000144, step_loss=0.126]07/27/2023 17:54:34 - INFO - __main__ - train loss is 35.2326181178214\n",
      "Steps:   8%| | 1167/15000 [09:44<41:29,  5.56it/s, lr=0.000144, step_loss=0.111]07/27/2023 17:54:34 - INFO - __main__ - train loss is 35.23585611314047\n",
      "Steps:   8%| | 1168/15000 [09:44<41:26,  5.56it/s, lr=0.000145, step_loss=0.003207/27/2023 17:54:34 - INFO - __main__ - train loss is 35.293975849752314\n",
      "Steps:   8%| | 1169/15000 [09:44<41:25,  5.56it/s, lr=0.000145, step_loss=0.058107/27/2023 17:54:34 - INFO - __main__ - train loss is 35.296240422991104\n",
      "Steps:   8%| | 1170/15000 [09:45<41:26,  5.56it/s, lr=0.000145, step_loss=0.002207/27/2023 17:54:34 - INFO - __main__ - train loss is 35.32106405508239\n",
      "Steps:   8%| | 1171/15000 [09:45<41:34,  5.54it/s, lr=0.000145, step_loss=0.024807/27/2023 17:54:35 - INFO - __main__ - train loss is 35.32469871419016\n",
      "Steps:   8%| | 1172/15000 [09:45<41:30,  5.55it/s, lr=0.000145, step_loss=0.003607/27/2023 17:54:35 - INFO - __main__ - train loss is 35.3822671972448\n",
      "Steps:   8%| | 1173/15000 [09:45<41:29,  5.55it/s, lr=0.000145, step_loss=0.057607/27/2023 17:54:35 - INFO - __main__ - train loss is 35.486349409096874\n",
      "Steps:   8%| | 1174/15000 [09:45<41:26,  5.56it/s, lr=0.000145, step_loss=0.104]07/27/2023 17:54:35 - INFO - __main__ - train loss is 35.855903541320004\n",
      "Steps:   8%|▏ | 1175/15000 [09:46<41:26,  5.56it/s, lr=0.000145, step_loss=0.37]07/27/2023 17:54:35 - INFO - __main__ - train loss is 35.86250901280437\n",
      "Steps:   8%| | 1176/15000 [09:46<41:34,  5.54it/s, lr=0.000146, step_loss=0.006607/27/2023 17:54:36 - INFO - __main__ - train loss is 35.887813551933505\n",
      "Steps:   8%| | 1177/15000 [09:46<41:33,  5.54it/s, lr=0.000146, step_loss=0.025307/27/2023 17:54:36 - INFO - __main__ - train loss is 35.90715453273151\n",
      "Steps:   8%| | 1178/15000 [09:46<41:51,  5.50it/s, lr=0.000146, step_loss=0.019307/27/2023 17:54:36 - INFO - __main__ - train loss is 35.90955499454867\n",
      "Steps:   8%| | 1179/15000 [09:46<41:40,  5.53it/s, lr=0.000146, step_loss=0.002407/27/2023 17:54:36 - INFO - __main__ - train loss is 35.92252010747325\n",
      "Steps:   8%| | 1180/15000 [09:46<41:34,  5.54it/s, lr=0.000146, step_loss=0.013]07/27/2023 17:54:36 - INFO - __main__ - train loss is 36.08019932254683\n",
      "Steps:   8%| | 1181/15000 [09:47<41:38,  5.53it/s, lr=0.000146, step_loss=0.158]07/27/2023 17:54:36 - INFO - __main__ - train loss is 36.37305446609389\n",
      "Steps:   8%| | 1182/15000 [09:47<41:35,  5.54it/s, lr=0.000146, step_loss=0.293]07/27/2023 17:54:37 - INFO - __main__ - train loss is 36.45581563457381\n",
      "Steps:   8%| | 1183/15000 [09:47<41:51,  5.50it/s, lr=0.000146, step_loss=0.082807/27/2023 17:54:37 - INFO - __main__ - train loss is 36.78268235072028\n",
      "Steps:   8%| | 1184/15000 [09:47<41:42,  5.52it/s, lr=0.000147, step_loss=0.327]07/27/2023 17:54:37 - INFO - __main__ - train loss is 36.81293719157111\n",
      "Steps:   8%| | 1185/15000 [09:47<41:36,  5.53it/s, lr=0.000147, step_loss=0.030307/27/2023 17:54:37 - INFO - __main__ - train loss is 36.92461215599906\n",
      "Steps:   8%| | 1186/15000 [09:48<41:41,  5.52it/s, lr=0.000147, step_loss=0.112]07/27/2023 17:54:37 - INFO - __main__ - train loss is 36.92937363300007\n",
      "Steps:   8%| | 1187/15000 [09:48<41:36,  5.53it/s, lr=0.000147, step_loss=0.004707/27/2023 17:54:38 - INFO - __main__ - train loss is 36.99676693591755\n",
      "Steps:   8%| | 1188/15000 [09:48<41:31,  5.54it/s, lr=0.000147, step_loss=0.067407/27/2023 17:54:38 - INFO - __main__ - train loss is 37.033162306877784\n",
      "Steps:   8%| | 1189/15000 [09:48<41:32,  5.54it/s, lr=0.000147, step_loss=0.036407/27/2023 17:54:38 - INFO - __main__ - train loss is 37.13083583477419\n",
      "Steps:   8%| | 1190/15000 [09:48<41:32,  5.54it/s, lr=0.000147, step_loss=0.097707/27/2023 17:54:38 - INFO - __main__ - train loss is 37.14174859027844\n",
      "Steps:   8%| | 1191/15000 [09:48<41:42,  5.52it/s, lr=0.000148, step_loss=0.010907/27/2023 17:54:38 - INFO - __main__ - train loss is 38.032060367870145\n",
      "Steps:   8%|▏ | 1192/15000 [09:49<41:34,  5.54it/s, lr=0.000148, step_loss=0.89]07/27/2023 17:54:38 - INFO - __main__ - train loss is 38.25107990007382\n",
      "Steps:   8%| | 1193/15000 [09:49<41:29,  5.55it/s, lr=0.000148, step_loss=0.219]07/27/2023 17:54:39 - INFO - __main__ - train loss is 38.444933114456944\n",
      "Steps:   8%| | 1194/15000 [09:49<41:26,  5.55it/s, lr=0.000148, step_loss=0.194]07/27/2023 17:54:39 - INFO - __main__ - train loss is 38.862298129010014\n",
      "Steps:   8%| | 1195/15000 [09:49<41:24,  5.56it/s, lr=0.000148, step_loss=0.417]07/27/2023 17:54:39 - INFO - __main__ - train loss is 38.872528291190974\n",
      "Steps:   8%| | 1196/15000 [09:49<41:36,  5.53it/s, lr=0.000148, step_loss=0.010207/27/2023 17:54:39 - INFO - __main__ - train loss is 38.88193362846505\n",
      "Steps:   8%| | 1197/15000 [09:49<41:28,  5.55it/s, lr=0.000148, step_loss=0.009407/27/2023 17:54:39 - INFO - __main__ - train loss is 38.89620377297979\n",
      "Steps:   8%| | 1198/15000 [09:50<41:23,  5.56it/s, lr=0.000148, step_loss=0.014307/27/2023 17:54:40 - INFO - __main__ - train loss is 39.4708405303536\n",
      "Steps:   8%| | 1199/15000 [09:50<41:19,  5.57it/s, lr=0.000149, step_loss=0.575]07/27/2023 17:54:40 - INFO - __main__ - train loss is 39.5058944466291\n",
      "Steps:   8%| | 1200/15000 [09:50<41:18,  5.57it/s, lr=0.000149, step_loss=0.035107/27/2023 17:54:40 - INFO - __main__ - train loss is 39.56586788769346\n",
      "Steps:   8%|▏ | 1201/15000 [09:50<41:40,  5.52it/s, lr=0.000149, step_loss=0.06]07/27/2023 17:54:40 - INFO - __main__ - train loss is 39.58227992232423\n",
      "Steps:   8%| | 1202/15000 [09:50<41:32,  5.54it/s, lr=0.000149, step_loss=0.016407/27/2023 17:54:40 - INFO - __main__ - train loss is 39.58843451354187\n",
      "Steps:   8%| | 1203/15000 [09:51<41:27,  5.55it/s, lr=0.000149, step_loss=0.006107/27/2023 17:54:40 - INFO - __main__ - train loss is 39.67454092565458\n",
      "Steps:   8%| | 1204/15000 [09:51<41:23,  5.56it/s, lr=0.000149, step_loss=0.086107/27/2023 17:54:41 - INFO - __main__ - train loss is 39.713163610431366\n",
      "Steps:   8%| | 1205/15000 [09:51<41:20,  5.56it/s, lr=0.000149, step_loss=0.038607/27/2023 17:54:41 - INFO - __main__ - train loss is 39.73245577130001\n",
      "Steps:   8%| | 1206/15000 [09:51<41:51,  5.49it/s, lr=0.000149, step_loss=0.019307/27/2023 17:54:41 - INFO - __main__ - train loss is 39.75815786223393\n",
      "Steps:   8%| | 1207/15000 [09:51<41:38,  5.52it/s, lr=0.00015, step_loss=0.0257]07/27/2023 17:54:41 - INFO - __main__ - train loss is 39.846289714681916\n",
      "Steps:   8%| | 1208/15000 [09:51<41:36,  5.52it/s, lr=0.00015, step_loss=0.0881]07/27/2023 17:54:41 - INFO - __main__ - train loss is 40.2451648915885\n",
      "Steps:   8%|▏ | 1209/15000 [09:52<41:28,  5.54it/s, lr=0.00015, step_loss=0.399]07/27/2023 17:54:42 - INFO - __main__ - train loss is 40.283899782109074\n",
      "Steps:   8%| | 1210/15000 [09:52<41:21,  5.56it/s, lr=0.00015, step_loss=0.0387]07/27/2023 17:54:42 - INFO - __main__ - train loss is 40.57989805738907\n",
      "Steps:   8%|▏ | 1211/15000 [09:52<41:21,  5.56it/s, lr=0.00015, step_loss=0.296]07/27/2023 17:54:42 - INFO - __main__ - train loss is 40.93893092672806\n",
      "Steps:   8%|▏ | 1212/15000 [09:52<56:40,  4.05it/s, lr=0.00015, step_loss=0.359]07/27/2023 17:54:43 - INFO - __main__ - Per validation step average loss is 0.2136305868625641\n",
      "07/27/2023 17:54:43 - INFO - __main__ - Cumulative validation average loss is 0.2136305868625641\n",
      "07/27/2023 17:54:44 - INFO - __main__ - Per validation step average loss is 0.002992384135723114\n",
      "07/27/2023 17:54:44 - INFO - __main__ - Cumulative validation average loss is 0.2166229709982872\n",
      "07/27/2023 17:54:44 - INFO - __main__ - Per validation step average loss is 0.24461975693702698\n",
      "07/27/2023 17:54:44 - INFO - __main__ - Cumulative validation average loss is 0.4612427279353142\n",
      "07/27/2023 17:54:44 - INFO - __main__ - Per validation step average loss is 0.4062008857727051\n",
      "07/27/2023 17:54:44 - INFO - __main__ - Cumulative validation average loss is 0.8674436137080193\n",
      "07/27/2023 17:54:45 - INFO - __main__ - Per validation step average loss is 0.12155495584011078\n",
      "07/27/2023 17:54:45 - INFO - __main__ - Cumulative validation average loss is 0.98899856954813\n",
      "07/27/2023 17:54:45 - INFO - __main__ - Per validation step average loss is 0.008132202550768852\n",
      "07/27/2023 17:54:45 - INFO - __main__ - Cumulative validation average loss is 0.9971307720988989\n",
      "07/27/2023 17:54:46 - INFO - __main__ - Per validation step average loss is 0.023051299154758453\n",
      "07/27/2023 17:54:46 - INFO - __main__ - Cumulative validation average loss is 1.0201820712536573\n",
      "07/27/2023 17:54:46 - INFO - __main__ - Per validation step average loss is 0.07300683856010437\n",
      "07/27/2023 17:54:46 - INFO - __main__ - Cumulative validation average loss is 1.0931889098137617\n",
      "07/27/2023 17:54:46 - INFO - __main__ - Per validation step average loss is 0.29151761531829834\n",
      "07/27/2023 17:54:46 - INFO - __main__ - Cumulative validation average loss is 1.38470652513206\n",
      "07/27/2023 17:54:47 - INFO - __main__ - Per validation step average loss is 0.026503920555114746\n",
      "07/27/2023 17:54:47 - INFO - __main__ - Cumulative validation average loss is 1.4112104456871748\n",
      "07/27/2023 17:54:47 - INFO - __main__ - Per validation step average loss is 0.002216036431491375\n",
      "07/27/2023 17:54:47 - INFO - __main__ - Cumulative validation average loss is 1.4134264821186662\n",
      "07/27/2023 17:54:48 - INFO - __main__ - Per validation step average loss is 0.08751906454563141\n",
      "07/27/2023 17:54:48 - INFO - __main__ - Cumulative validation average loss is 1.5009455466642976\n",
      "07/27/2023 17:54:48 - INFO - __main__ - Per validation step average loss is 0.004148104228079319\n",
      "07/27/2023 17:54:48 - INFO - __main__ - Cumulative validation average loss is 1.505093650892377\n",
      "07/27/2023 17:54:48 - INFO - __main__ - Per validation step average loss is 0.004223293624818325\n",
      "07/27/2023 17:54:48 - INFO - __main__ - Cumulative validation average loss is 1.5093169445171952\n",
      "07/27/2023 17:54:49 - INFO - __main__ - Per validation step average loss is 0.40548497438430786\n",
      "07/27/2023 17:54:49 - INFO - __main__ - Cumulative validation average loss is 1.914801918901503\n",
      "07/27/2023 17:54:49 - INFO - __main__ - Per validation step average loss is 0.15156851708889008\n",
      "07/27/2023 17:54:49 - INFO - __main__ - Cumulative validation average loss is 2.066370435990393\n",
      "07/27/2023 17:54:50 - INFO - __main__ - Per validation step average loss is 0.01196574978530407\n",
      "07/27/2023 17:54:50 - INFO - __main__ - Cumulative validation average loss is 2.0783361857756972\n",
      "07/27/2023 17:54:50 - INFO - __main__ - Per validation step average loss is 0.014245737344026566\n",
      "07/27/2023 17:54:50 - INFO - __main__ - Cumulative validation average loss is 2.092581923119724\n",
      "07/27/2023 17:54:50 - INFO - __main__ - Per validation step average loss is 0.004031060729175806\n",
      "07/27/2023 17:54:50 - INFO - __main__ - Cumulative validation average loss is 2.0966129838488996\n",
      "07/27/2023 17:54:51 - INFO - __main__ - Per validation step average loss is 0.3317640423774719\n",
      "07/27/2023 17:54:51 - INFO - __main__ - Cumulative validation average loss is 2.4283770262263715\n",
      "07/27/2023 17:54:51 - INFO - __main__ - Per validation step average loss is 0.18838021159172058\n",
      "07/27/2023 17:54:51 - INFO - __main__ - Cumulative validation average loss is 2.616757237818092\n",
      "07/27/2023 17:54:52 - INFO - __main__ - Per validation step average loss is 0.23590317368507385\n",
      "07/27/2023 17:54:52 - INFO - __main__ - Cumulative validation average loss is 2.852660411503166\n",
      "07/27/2023 17:54:52 - INFO - __main__ - Per validation step average loss is 0.04073912650346756\n",
      "07/27/2023 17:54:52 - INFO - __main__ - Cumulative validation average loss is 2.8933995380066335\n",
      "07/27/2023 17:54:53 - INFO - __main__ - Per validation step average loss is 0.048959698528051376\n",
      "07/27/2023 17:54:53 - INFO - __main__ - Cumulative validation average loss is 2.942359236534685\n",
      "07/27/2023 17:54:53 - INFO - __main__ - Per validation step average loss is 0.001284966478124261\n",
      "07/27/2023 17:54:53 - INFO - __main__ - Cumulative validation average loss is 2.943644203012809\n",
      "07/27/2023 17:54:53 - INFO - __main__ - Per validation step average loss is 0.24525663256645203\n",
      "07/27/2023 17:54:53 - INFO - __main__ - Cumulative validation average loss is 3.188900835579261\n",
      "07/27/2023 17:54:54 - INFO - __main__ - Per validation step average loss is 0.05094892531633377\n",
      "07/27/2023 17:54:54 - INFO - __main__ - Cumulative validation average loss is 3.239849760895595\n",
      "07/27/2023 17:54:54 - INFO - __main__ - Per validation step average loss is 0.13106831908226013\n",
      "07/27/2023 17:54:54 - INFO - __main__ - Cumulative validation average loss is 3.370918079977855\n",
      "07/27/2023 17:54:55 - INFO - __main__ - Per validation step average loss is 0.5787737369537354\n",
      "07/27/2023 17:54:55 - INFO - __main__ - Cumulative validation average loss is 3.9496918169315904\n",
      "07/27/2023 17:54:55 - INFO - __main__ - Per validation step average loss is 0.0021631079725921154\n",
      "07/27/2023 17:54:55 - INFO - __main__ - Cumulative validation average loss is 3.9518549249041826\n",
      "07/27/2023 17:54:55 - INFO - __main__ - Per validation step average loss is 0.21025721728801727\n",
      "07/27/2023 17:54:55 - INFO - __main__ - Cumulative validation average loss is 4.1621121421922\n",
      "07/27/2023 17:54:56 - INFO - __main__ - Per validation step average loss is 0.002381999511271715\n",
      "07/27/2023 17:54:56 - INFO - __main__ - Cumulative validation average loss is 4.1644941417034715\n",
      "07/27/2023 17:54:56 - INFO - __main__ - Per validation step average loss is 0.19897820055484772\n",
      "07/27/2023 17:54:56 - INFO - __main__ - Cumulative validation average loss is 4.363472342258319\n",
      "07/27/2023 17:54:57 - INFO - __main__ - Per validation step average loss is 0.1014942079782486\n",
      "07/27/2023 17:54:57 - INFO - __main__ - Cumulative validation average loss is 4.464966550236568\n",
      "07/27/2023 17:54:57 - INFO - __main__ - Per validation step average loss is 0.055111635476350784\n",
      "07/27/2023 17:54:57 - INFO - __main__ - Cumulative validation average loss is 4.520078185712919\n",
      "07/27/2023 17:54:57 - INFO - __main__ - Per validation step average loss is 0.025886904448270798\n",
      "07/27/2023 17:54:57 - INFO - __main__ - Cumulative validation average loss is 4.545965090161189\n",
      "07/27/2023 17:54:58 - INFO - __main__ - Per validation step average loss is 0.20666982233524323\n",
      "07/27/2023 17:54:58 - INFO - __main__ - Cumulative validation average loss is 4.752634912496433\n",
      "07/27/2023 17:54:58 - INFO - __main__ - Per validation step average loss is 0.026871168985962868\n",
      "07/27/2023 17:54:58 - INFO - __main__ - Cumulative validation average loss is 4.7795060814823955\n",
      "07/27/2023 17:54:59 - INFO - __main__ - Per validation step average loss is 0.006415949203073978\n",
      "07/27/2023 17:54:59 - INFO - __main__ - Cumulative validation average loss is 4.7859220306854695\n",
      "07/27/2023 17:54:59 - INFO - __main__ - Per validation step average loss is 0.02849467657506466\n",
      "07/27/2023 17:54:59 - INFO - __main__ - Cumulative validation average loss is 4.814416707260534\n",
      "07/27/2023 17:54:59 - INFO - __main__ - Per validation step average loss is 0.04573728144168854\n",
      "07/27/2023 17:54:59 - INFO - __main__ - Cumulative validation average loss is 4.860153988702223\n",
      "07/27/2023 17:55:00 - INFO - __main__ - Per validation step average loss is 0.004436059854924679\n",
      "07/27/2023 17:55:00 - INFO - __main__ - Cumulative validation average loss is 4.864590048557147\n",
      "07/27/2023 17:55:00 - INFO - __main__ - Per validation step average loss is 0.09001776576042175\n",
      "07/27/2023 17:55:00 - INFO - __main__ - Cumulative validation average loss is 4.954607814317569\n",
      "07/27/2023 17:55:01 - INFO - __main__ - Per validation step average loss is 0.00191795383580029\n",
      "07/27/2023 17:55:01 - INFO - __main__ - Cumulative validation average loss is 4.956525768153369\n",
      "07/27/2023 17:55:01 - INFO - __main__ - Per validation step average loss is 0.006428996566683054\n",
      "07/27/2023 17:55:01 - INFO - __main__ - Cumulative validation average loss is 4.9629547647200525\n",
      "07/27/2023 17:55:01 - INFO - __main__ - Per validation step average loss is 0.2971556484699249\n",
      "07/27/2023 17:55:01 - INFO - __main__ - Cumulative validation average loss is 5.260110413189977\n",
      "07/27/2023 17:55:02 - INFO - __main__ - Per validation step average loss is 0.11805016547441483\n",
      "07/27/2023 17:55:02 - INFO - __main__ - Cumulative validation average loss is 5.378160578664392\n",
      "07/27/2023 17:55:02 - INFO - __main__ - Per validation step average loss is 0.34407731890678406\n",
      "07/27/2023 17:55:02 - INFO - __main__ - Cumulative validation average loss is 5.722237897571176\n",
      "07/27/2023 17:55:03 - INFO - __main__ - Per validation step average loss is 0.07701729238033295\n",
      "07/27/2023 17:55:03 - INFO - __main__ - Cumulative validation average loss is 5.799255189951509\n",
      "07/27/2023 17:55:03 - INFO - __main__ - Per validation step average loss is 0.26484450697898865\n",
      "07/27/2023 17:55:03 - INFO - __main__ - Cumulative validation average loss is 6.064099696930498\n",
      "07/27/2023 17:55:04 - INFO - __main__ - Per validation step average loss is 0.0040049622766673565\n",
      "07/27/2023 17:55:04 - INFO - __main__ - Cumulative validation average loss is 6.068104659207165\n",
      "07/27/2023 17:55:04 - INFO - __main__ - Per validation step average loss is 0.06426271051168442\n",
      "07/27/2023 17:55:04 - INFO - __main__ - Cumulative validation average loss is 6.13236736971885\n",
      "07/27/2023 17:55:04 - INFO - __main__ - Per validation step average loss is 0.02099510096013546\n",
      "07/27/2023 17:55:04 - INFO - __main__ - Cumulative validation average loss is 6.153362470678985\n",
      "07/27/2023 17:55:05 - INFO - __main__ - Per validation step average loss is 0.39261454343795776\n",
      "07/27/2023 17:55:05 - INFO - __main__ - Cumulative validation average loss is 6.545977014116943\n",
      "07/27/2023 17:55:05 - INFO - __main__ - Per validation step average loss is 0.07461583614349365\n",
      "07/27/2023 17:55:05 - INFO - __main__ - Cumulative validation average loss is 6.6205928502604365\n",
      "07/27/2023 17:55:06 - INFO - __main__ - Per validation step average loss is 0.03428002446889877\n",
      "07/27/2023 17:55:06 - INFO - __main__ - Cumulative validation average loss is 6.654872874729335\n",
      "07/27/2023 17:55:06 - INFO - __main__ - Per validation step average loss is 0.002571658231317997\n",
      "07/27/2023 17:55:06 - INFO - __main__ - Cumulative validation average loss is 6.657444532960653\n",
      "07/27/2023 17:55:06 - INFO - __main__ - Per validation step average loss is 0.02751375362277031\n",
      "07/27/2023 17:55:06 - INFO - __main__ - Cumulative validation average loss is 6.684958286583424\n",
      "07/27/2023 17:55:07 - INFO - __main__ - Per validation step average loss is 0.03462083265185356\n",
      "07/27/2023 17:55:07 - INFO - __main__ - Cumulative validation average loss is 6.719579119235277\n",
      "07/27/2023 17:55:07 - INFO - __main__ - Per validation step average loss is 0.14778493344783783\n",
      "07/27/2023 17:55:07 - INFO - __main__ - Cumulative validation average loss is 6.867364052683115\n",
      "07/27/2023 17:55:08 - INFO - __main__ - Per validation step average loss is 0.002435950795188546\n",
      "07/27/2023 17:55:08 - INFO - __main__ - Cumulative validation average loss is 6.8698000034783036\n",
      "07/27/2023 17:55:08 - INFO - __main__ - Per validation step average loss is 0.019203484058380127\n",
      "07/27/2023 17:55:08 - INFO - __main__ - Cumulative validation average loss is 6.889003487536684\n",
      "07/27/2023 17:55:08 - INFO - __main__ - Per validation step average loss is 0.013634486123919487\n",
      "07/27/2023 17:55:08 - INFO - __main__ - Cumulative validation average loss is 6.902637973660603\n",
      "07/27/2023 17:55:09 - INFO - __main__ - Per validation step average loss is 0.019404202699661255\n",
      "07/27/2023 17:55:09 - INFO - __main__ - Cumulative validation average loss is 6.922042176360264\n",
      "07/27/2023 17:55:09 - INFO - __main__ - Per validation step average loss is 0.00485460227355361\n",
      "07/27/2023 17:55:09 - INFO - __main__ - Cumulative validation average loss is 6.926896778633818\n",
      "07/27/2023 17:55:10 - INFO - __main__ - Per validation step average loss is 0.42337334156036377\n",
      "07/27/2023 17:55:10 - INFO - __main__ - Cumulative validation average loss is 7.350270120194182\n",
      "07/27/2023 17:55:10 - INFO - __main__ - Per validation step average loss is 0.0020098118111491203\n",
      "07/27/2023 17:55:10 - INFO - __main__ - Cumulative validation average loss is 7.352279932005331\n",
      "07/27/2023 17:55:11 - INFO - __main__ - Per validation step average loss is 0.29683753848075867\n",
      "07/27/2023 17:55:11 - INFO - __main__ - Cumulative validation average loss is 7.64911747048609\n",
      "07/27/2023 17:55:11 - INFO - __main__ - Per validation step average loss is 0.0048822034150362015\n",
      "07/27/2023 17:55:11 - INFO - __main__ - Cumulative validation average loss is 7.653999673901126\n",
      "07/27/2023 17:55:11 - INFO - __main__ - Per validation step average loss is 0.0048742955550551414\n",
      "07/27/2023 17:55:11 - INFO - __main__ - Cumulative validation average loss is 7.658873969456181\n",
      "07/27/2023 17:55:12 - INFO - __main__ - Per validation step average loss is 0.8472585082054138\n",
      "07/27/2023 17:55:12 - INFO - __main__ - Cumulative validation average loss is 8.506132477661595\n",
      "07/27/2023 17:55:12 - INFO - __main__ - Per validation step average loss is 0.062403444200754166\n",
      "07/27/2023 17:55:12 - INFO - __main__ - Cumulative validation average loss is 8.568535921862349\n",
      "07/27/2023 17:55:13 - INFO - __main__ - Per validation step average loss is 0.04598751664161682\n",
      "07/27/2023 17:55:13 - INFO - __main__ - Cumulative validation average loss is 8.614523438503966\n",
      "07/27/2023 17:55:13 - INFO - __main__ - Per validation step average loss is 0.2145751714706421\n",
      "07/27/2023 17:55:13 - INFO - __main__ - Cumulative validation average loss is 8.829098609974608\n",
      "07/27/2023 17:55:13 - INFO - __main__ - Per validation step average loss is 0.14424540102481842\n",
      "07/27/2023 17:55:13 - INFO - __main__ - Cumulative validation average loss is 8.973344010999426\n",
      "07/27/2023 17:55:14 - INFO - __main__ - Per validation step average loss is 0.02786966785788536\n",
      "07/27/2023 17:55:14 - INFO - __main__ - Cumulative validation average loss is 9.001213678857312\n",
      "07/27/2023 17:55:14 - INFO - __main__ - Per validation step average loss is 0.10598558932542801\n",
      "07/27/2023 17:55:14 - INFO - __main__ - Cumulative validation average loss is 9.10719926818274\n",
      "07/27/2023 17:55:15 - INFO - __main__ - Per validation step average loss is 0.7289313077926636\n",
      "07/27/2023 17:55:15 - INFO - __main__ - Cumulative validation average loss is 9.836130575975403\n",
      "07/27/2023 17:55:15 - INFO - __main__ - Per validation step average loss is 0.24774213135242462\n",
      "07/27/2023 17:55:15 - INFO - __main__ - Cumulative validation average loss is 10.083872707327828\n",
      "07/27/2023 17:55:15 - INFO - __main__ - Average validation loss for Epoch 3 is 0.1276439583206054\n",
      "07/27/2023 17:55:15 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 17:56:12 - INFO - __main__ - Starting epoch 4\n",
      "07/27/2023 17:56:13 - INFO - __main__ - train loss is 0.4888879358768463\n",
      "Steps:   8%| | 1213/15000 [11:23<104:50:11, 27.37s/it, lr=0.00015, step_loss=0.407/27/2023 17:56:13 - INFO - __main__ - train loss is 0.5679092407226562\n",
      "Steps:   8%| | 1214/15000 [11:23<73:35:16, 19.22s/it, lr=0.00015, step_loss=0.0707/27/2023 17:56:13 - INFO - __main__ - train loss is 0.6807781159877777\n",
      "Steps:   8%| | 1215/15000 [11:23<51:42:50, 13.51s/it, lr=0.00015, step_loss=0.1107/27/2023 17:56:13 - INFO - __main__ - train loss is 0.7509997338056564\n",
      "Steps:   8%| | 1216/15000 [11:24<36:24:39,  9.51s/it, lr=0.000151, step_loss=0.007/27/2023 17:56:14 - INFO - __main__ - train loss is 0.753098264336586\n",
      "Steps:   8%| | 1217/15000 [11:24<25:42:08,  6.71s/it, lr=0.000151, step_loss=0.007/27/2023 17:56:14 - INFO - __main__ - train loss is 0.7547272952506319\n",
      "Steps:   8%| | 1218/15000 [11:24<18:16:53,  4.78s/it, lr=0.000151, step_loss=0.007/27/2023 17:56:14 - INFO - __main__ - train loss is 0.8364296915242448\n",
      "Steps:   8%| | 1219/15000 [11:24<13:00:53,  3.40s/it, lr=0.000151, step_loss=0.007/27/2023 17:56:14 - INFO - __main__ - train loss is 0.8431805853033438\n",
      "Steps:   8%| | 1220/15000 [11:24<9:19:17,  2.44s/it, lr=0.000151, step_loss=0.0007/27/2023 17:56:14 - INFO - __main__ - train loss is 1.1976534608984366\n",
      "Steps:   8%| | 1221/15000 [11:25<6:44:36,  1.76s/it, lr=0.000151, step_loss=0.3507/27/2023 17:56:15 - INFO - __main__ - train loss is 1.628281343379058\n",
      "Steps:   8%| | 1222/15000 [11:25<4:55:26,  1.29s/it, lr=0.000151, step_loss=0.4307/27/2023 17:56:15 - INFO - __main__ - train loss is 1.7487913701916113\n",
      "Steps:   8%| | 1223/15000 [11:25<3:39:08,  1.05it/s, lr=0.000151, step_loss=0.1207/27/2023 17:56:15 - INFO - __main__ - train loss is 2.304546270170249\n",
      "Steps:   8%| | 1224/15000 [11:25<2:46:07,  1.38it/s, lr=0.000152, step_loss=0.5507/27/2023 17:56:15 - INFO - __main__ - train loss is 2.373204815783538\n",
      "Steps:   8%| | 1225/15000 [11:25<2:08:35,  1.79it/s, lr=0.000152, step_loss=0.0607/27/2023 17:56:15 - INFO - __main__ - train loss is 2.408151361742057\n",
      "Steps:   8%| | 1226/15000 [11:26<1:42:25,  2.24it/s, lr=0.000152, step_loss=0.0307/27/2023 17:56:15 - INFO - __main__ - train loss is 2.4279753357404843\n",
      "Steps:   8%| | 1227/15000 [11:26<1:24:01,  2.73it/s, lr=0.000152, step_loss=0.0107/27/2023 17:56:16 - INFO - __main__ - train loss is 2.4500696040922776\n",
      "Steps:   8%| | 1228/15000 [11:26<1:11:06,  3.23it/s, lr=0.000152, step_loss=0.0207/27/2023 17:56:16 - INFO - __main__ - train loss is 2.504792617284693\n",
      "Steps:   8%| | 1229/15000 [11:26<1:02:08,  3.69it/s, lr=0.000152, step_loss=0.0507/27/2023 17:56:16 - INFO - __main__ - train loss is 2.5980544701451436\n",
      "Steps:   8%| | 1230/15000 [11:26<55:49,  4.11it/s, lr=0.000152, step_loss=0.093307/27/2023 17:56:16 - INFO - __main__ - train loss is 2.6204027958447114\n",
      "Steps:   8%| | 1231/15000 [11:26<51:25,  4.46it/s, lr=0.000152, step_loss=0.022307/27/2023 17:56:16 - INFO - __main__ - train loss is 2.6507889308268204\n",
      "Steps:   8%| | 1232/15000 [11:27<48:18,  4.75it/s, lr=0.000153, step_loss=0.030407/27/2023 17:56:16 - INFO - __main__ - train loss is 2.653099230141379\n",
      "Steps:   8%| | 1233/15000 [11:27<46:16,  4.96it/s, lr=0.000153, step_loss=0.002307/27/2023 17:56:17 - INFO - __main__ - train loss is 2.6749493876704946\n",
      "Steps:   8%| | 1234/15000 [11:27<44:45,  5.13it/s, lr=0.000153, step_loss=0.021907/27/2023 17:56:17 - INFO - __main__ - train loss is 2.680312931188382\n",
      "Steps:   8%| | 1235/15000 [11:27<43:38,  5.26it/s, lr=0.000153, step_loss=0.005307/27/2023 17:56:17 - INFO - __main__ - train loss is 2.7298483547056094\n",
      "Steps:   8%| | 1236/15000 [11:27<42:51,  5.35it/s, lr=0.000153, step_loss=0.049507/27/2023 17:56:17 - INFO - __main__ - train loss is 2.73336242150981\n",
      "Steps:   8%| | 1237/15000 [11:28<42:19,  5.42it/s, lr=0.000153, step_loss=0.003507/27/2023 17:56:17 - INFO - __main__ - train loss is 2.743418345344253\n",
      "Steps:   8%| | 1238/15000 [11:28<41:58,  5.46it/s, lr=0.000153, step_loss=0.010107/27/2023 17:56:18 - INFO - __main__ - train loss is 2.798447268200107\n",
      "Steps:   8%| | 1239/15000 [11:28<41:44,  5.49it/s, lr=0.000153, step_loss=0.055]07/27/2023 17:56:18 - INFO - __main__ - train loss is 2.898490453255363\n",
      "Steps:   8%|▏  | 1240/15000 [11:28<41:31,  5.52it/s, lr=0.000154, step_loss=0.1]07/27/2023 17:56:18 - INFO - __main__ - train loss is 2.9810658638598397\n",
      "Steps:   8%| | 1241/15000 [11:28<41:24,  5.54it/s, lr=0.000154, step_loss=0.082607/27/2023 17:56:18 - INFO - __main__ - train loss is 3.0029289406957105\n",
      "Steps:   8%| | 1242/15000 [11:28<41:37,  5.51it/s, lr=0.000154, step_loss=0.021907/27/2023 17:56:18 - INFO - __main__ - train loss is 3.0162671544821933\n",
      "Steps:   8%| | 1243/15000 [11:29<41:51,  5.48it/s, lr=0.000154, step_loss=0.013307/27/2023 17:56:18 - INFO - __main__ - train loss is 3.0623170734615996\n",
      "Steps:   8%| | 1244/15000 [11:29<42:20,  5.41it/s, lr=0.000154, step_loss=0.046]07/27/2023 17:56:19 - INFO - __main__ - train loss is 3.2182047666283324\n",
      "Steps:   8%| | 1245/15000 [11:29<42:11,  5.43it/s, lr=0.000154, step_loss=0.156]07/27/2023 17:56:19 - INFO - __main__ - train loss is 3.3572606743546203\n",
      "Steps:   8%| | 1246/15000 [11:29<42:02,  5.45it/s, lr=0.000154, step_loss=0.139]07/27/2023 17:56:19 - INFO - __main__ - train loss is 3.6653682292671874\n",
      "Steps:   8%| | 1247/15000 [11:29<42:18,  5.42it/s, lr=0.000155, step_loss=0.308]07/27/2023 17:56:19 - INFO - __main__ - train loss is 3.6777392962248996\n",
      "Steps:   8%| | 1248/15000 [11:30<41:55,  5.47it/s, lr=0.000155, step_loss=0.012407/27/2023 17:56:19 - INFO - __main__ - train loss is 3.6940837578149512\n",
      "Steps:   8%| | 1249/15000 [11:30<42:03,  5.45it/s, lr=0.000155, step_loss=0.016307/27/2023 17:56:20 - INFO - __main__ - train loss is 4.011638291296549\n",
      "Steps:   8%| | 1250/15000 [11:30<41:55,  5.47it/s, lr=0.000155, step_loss=0.318]07/27/2023 17:56:20 - INFO - __main__ - train loss is 4.281302519259043\n",
      "Steps:   8%|▏ | 1251/15000 [11:30<42:11,  5.43it/s, lr=0.000155, step_loss=0.27]07/27/2023 17:56:20 - INFO - __main__ - train loss is 4.412979640183039\n",
      "Steps:   8%| | 1252/15000 [11:30<41:52,  5.47it/s, lr=0.000155, step_loss=0.132]07/27/2023 17:56:20 - INFO - __main__ - train loss is 4.455706421402283\n",
      "Steps:   8%| | 1253/15000 [11:30<41:38,  5.50it/s, lr=0.000155, step_loss=0.042707/27/2023 17:56:20 - INFO - __main__ - train loss is 4.460300005157478\n",
      "Steps:   8%| | 1254/15000 [11:31<41:29,  5.52it/s, lr=0.000155, step_loss=0.004507/27/2023 17:56:20 - INFO - __main__ - train loss is 4.676246813614853\n",
      "Steps:   8%| | 1255/15000 [11:31<41:21,  5.54it/s, lr=0.000156, step_loss=0.216]07/27/2023 17:56:21 - INFO - __main__ - train loss is 4.972186020691879\n",
      "Steps:   8%| | 1256/15000 [11:31<41:16,  5.55it/s, lr=0.000156, step_loss=0.296]07/27/2023 17:56:21 - INFO - __main__ - train loss is 5.133822626550682\n",
      "Steps:   8%| | 1257/15000 [11:31<41:12,  5.56it/s, lr=0.000156, step_loss=0.162]07/27/2023 17:56:21 - INFO - __main__ - train loss is 5.309713221271522\n",
      "Steps:   8%| | 1258/15000 [11:31<41:11,  5.56it/s, lr=0.000156, step_loss=0.176]07/27/2023 17:56:21 - INFO - __main__ - train loss is 5.34235688589979\n",
      "Steps:   8%| | 1259/15000 [11:32<41:09,  5.56it/s, lr=0.000156, step_loss=0.032607/27/2023 17:56:21 - INFO - __main__ - train loss is 5.349977442645468\n",
      "Steps:   8%| | 1260/15000 [11:32<41:07,  5.57it/s, lr=0.000156, step_loss=0.007607/27/2023 17:56:22 - INFO - __main__ - train loss is 5.355582287185825\n",
      "Steps:   8%| | 1261/15000 [11:32<41:06,  5.57it/s, lr=0.000156, step_loss=0.005607/27/2023 17:56:22 - INFO - __main__ - train loss is 5.429876146488823\n",
      "Steps:   8%| | 1262/15000 [11:32<41:04,  5.57it/s, lr=0.000156, step_loss=0.074307/27/2023 17:56:22 - INFO - __main__ - train loss is 5.528513734810986\n",
      "Steps:   8%| | 1263/15000 [11:32<41:04,  5.57it/s, lr=0.000157, step_loss=0.098607/27/2023 17:56:22 - INFO - __main__ - train loss is 5.61836814659182\n",
      "Steps:   8%| | 1264/15000 [11:32<41:18,  5.54it/s, lr=0.000157, step_loss=0.089907/27/2023 17:56:22 - INFO - __main__ - train loss is 5.620490813744254\n",
      "Steps:   8%| | 1265/15000 [11:33<41:12,  5.55it/s, lr=0.000157, step_loss=0.002107/27/2023 17:56:22 - INFO - __main__ - train loss is 5.913499498856254\n",
      "Steps:   8%| | 1266/15000 [11:33<41:10,  5.56it/s, lr=0.000157, step_loss=0.293]07/27/2023 17:56:23 - INFO - __main__ - train loss is 5.918098030262627\n",
      "Steps:   8%| | 1267/15000 [11:33<41:07,  5.57it/s, lr=0.000157, step_loss=0.004607/27/2023 17:56:23 - INFO - __main__ - train loss is 5.920009445515461\n",
      "Steps:   8%| | 1268/15000 [11:33<41:29,  5.52it/s, lr=0.000157, step_loss=0.001907/27/2023 17:56:23 - INFO - __main__ - train loss is 6.311976444092579\n",
      "Steps:   8%| | 1269/15000 [11:33<41:20,  5.53it/s, lr=0.000157, step_loss=0.392]07/27/2023 17:56:23 - INFO - __main__ - train loss is 6.456532757845707\n",
      "Steps:   8%| | 1270/15000 [11:34<41:13,  5.55it/s, lr=0.000157, step_loss=0.145]07/27/2023 17:56:23 - INFO - __main__ - train loss is 6.482192199793644\n",
      "Steps:   8%| | 1271/15000 [11:34<41:09,  5.56it/s, lr=0.000158, step_loss=0.025707/27/2023 17:56:24 - INFO - __main__ - train loss is 6.759129446116276\n",
      "Steps:   8%| | 1272/15000 [11:34<41:06,  5.57it/s, lr=0.000158, step_loss=0.277]07/27/2023 17:56:24 - INFO - __main__ - train loss is 6.98467449482996\n",
      "Steps:   8%| | 1273/15000 [11:34<41:10,  5.56it/s, lr=0.000158, step_loss=0.226]07/27/2023 17:56:24 - INFO - __main__ - train loss is 7.206415634718724\n",
      "Steps:   8%| | 1274/15000 [11:34<41:06,  5.57it/s, lr=0.000158, step_loss=0.222]07/27/2023 17:56:24 - INFO - __main__ - train loss is 7.209308736142702\n",
      "Steps:   8%| | 1275/15000 [11:34<41:10,  5.56it/s, lr=0.000158, step_loss=0.002807/27/2023 17:56:24 - INFO - __main__ - train loss is 7.244830772397108\n",
      "Steps:   9%| | 1276/15000 [11:35<41:07,  5.56it/s, lr=0.000158, step_loss=0.035507/27/2023 17:56:24 - INFO - __main__ - train loss is 7.248161790543236\n",
      "Steps:   9%| | 1277/15000 [11:35<41:29,  5.51it/s, lr=0.000158, step_loss=0.003307/27/2023 17:56:25 - INFO - __main__ - train loss is 7.249258382827975\n",
      "Steps:   9%| | 1278/15000 [11:35<41:19,  5.53it/s, lr=0.000158, step_loss=0.001107/27/2023 17:56:25 - INFO - __main__ - train loss is 7.280202596099116\n",
      "Steps:   9%| | 1279/15000 [11:35<41:12,  5.55it/s, lr=0.000159, step_loss=0.030907/27/2023 17:56:25 - INFO - __main__ - train loss is 7.504766865284182\n",
      "Steps:   9%| | 1280/15000 [11:35<41:07,  5.56it/s, lr=0.000159, step_loss=0.225]07/27/2023 17:56:25 - INFO - __main__ - train loss is 7.506442082230933\n",
      "Steps:   9%| | 1281/15000 [11:35<41:03,  5.57it/s, lr=0.000159, step_loss=0.001607/27/2023 17:56:25 - INFO - __main__ - train loss is 7.854422551696189\n",
      "Steps:   9%| | 1282/15000 [11:36<41:06,  5.56it/s, lr=0.000159, step_loss=0.348]07/27/2023 17:56:26 - INFO - __main__ - train loss is 8.068307262961753\n",
      "Steps:   9%| | 1283/15000 [11:36<41:02,  5.57it/s, lr=0.000159, step_loss=0.214]07/27/2023 17:56:26 - INFO - __main__ - train loss is 8.070262119290419\n",
      "Steps:   9%| | 1284/15000 [11:36<41:00,  5.57it/s, lr=0.000159, step_loss=0.001907/27/2023 17:56:26 - INFO - __main__ - train loss is 8.07494679291267\n",
      "Steps:   9%| | 1285/15000 [11:36<40:59,  5.58it/s, lr=0.000159, step_loss=0.004607/27/2023 17:56:26 - INFO - __main__ - train loss is 8.100096842390485\n",
      "Steps:   9%| | 1286/15000 [11:36<41:03,  5.57it/s, lr=0.000159, step_loss=0.025207/27/2023 17:56:26 - INFO - __main__ - train loss is 8.109374323976226\n",
      "Steps:   9%| | 1287/15000 [11:37<41:01,  5.57it/s, lr=0.00016, step_loss=0.0092807/27/2023 17:56:26 - INFO - __main__ - train loss is 8.204602124285884\n",
      "Steps:   9%| | 1288/15000 [11:37<41:00,  5.57it/s, lr=0.00016, step_loss=0.0952]07/27/2023 17:56:27 - INFO - __main__ - train loss is 8.414601059746929\n",
      "Steps:   9%|▎  | 1289/15000 [11:37<41:00,  5.57it/s, lr=0.00016, step_loss=0.21]07/27/2023 17:56:27 - INFO - __main__ - train loss is 8.486675890279002\n",
      "Steps:   9%| | 1290/15000 [11:37<41:04,  5.56it/s, lr=0.00016, step_loss=0.0721]07/27/2023 17:56:27 - INFO - __main__ - train loss is 8.517875412595458\n",
      "Steps:   9%| | 1291/15000 [11:37<41:04,  5.56it/s, lr=0.00016, step_loss=0.0312]07/27/2023 17:56:27 - INFO - __main__ - train loss is 8.717643151176162\n",
      "Steps:   9%|▎   | 1292/15000 [11:37<41:03,  5.57it/s, lr=0.00016, step_loss=0.2]07/27/2023 17:56:27 - INFO - __main__ - train loss is 8.719015678623691\n",
      "Steps:   9%| | 1293/15000 [11:38<41:02,  5.57it/s, lr=0.00016, step_loss=0.0013707/27/2023 17:56:28 - INFO - __main__ - train loss is 8.772411240497604\n",
      "Steps:   9%| | 1294/15000 [11:38<41:01,  5.57it/s, lr=0.00016, step_loss=0.0534]07/27/2023 17:56:28 - INFO - __main__ - train loss is 9.07157195941545\n",
      "Steps:   9%|▏ | 1295/15000 [11:38<41:03,  5.56it/s, lr=0.00016, step_loss=0.299]07/27/2023 17:56:28 - INFO - __main__ - train loss is 9.077953945612535\n",
      "Steps:   9%| | 1296/15000 [11:38<41:00,  5.57it/s, lr=0.000161, step_loss=0.006307/27/2023 17:56:28 - INFO - __main__ - train loss is 9.232462923740968\n",
      "Steps:   9%| | 1297/15000 [11:38<40:58,  5.57it/s, lr=0.000161, step_loss=0.155]07/27/2023 17:56:28 - INFO - __main__ - train loss is 9.261580783640966\n",
      "Steps:   9%| | 1298/15000 [11:39<40:58,  5.57it/s, lr=0.000161, step_loss=0.029107/27/2023 17:56:28 - INFO - __main__ - train loss is 9.310168672120199\n",
      "Steps:   9%| | 1299/15000 [11:39<40:58,  5.57it/s, lr=0.000161, step_loss=0.048607/27/2023 17:56:29 - INFO - __main__ - train loss is 9.312344670994207\n",
      "Steps:   9%| | 1300/15000 [11:39<40:57,  5.58it/s, lr=0.000161, step_loss=0.002107/27/2023 17:56:29 - INFO - __main__ - train loss is 9.327984328148887\n",
      "Steps:   9%| | 1301/15000 [11:39<40:56,  5.58it/s, lr=0.000161, step_loss=0.015607/27/2023 17:56:29 - INFO - __main__ - train loss is 9.337639027973637\n",
      "Steps:   9%| | 1302/15000 [11:39<40:54,  5.58it/s, lr=0.000161, step_loss=0.009607/27/2023 17:56:29 - INFO - __main__ - train loss is 9.465850109001622\n",
      "Steps:   9%| | 1303/15000 [11:39<41:01,  5.56it/s, lr=0.000161, step_loss=0.128]07/27/2023 17:56:29 - INFO - __main__ - train loss is 10.106008106609806\n",
      "Steps:   9%|▏ | 1304/15000 [11:40<40:58,  5.57it/s, lr=0.000162, step_loss=0.64]07/27/2023 17:56:29 - INFO - __main__ - train loss is 10.123807031428441\n",
      "Steps:   9%| | 1305/15000 [11:40<41:02,  5.56it/s, lr=0.000162, step_loss=0.017807/27/2023 17:56:30 - INFO - __main__ - train loss is 10.175425708061084\n",
      "Steps:   9%| | 1306/15000 [11:40<40:58,  5.57it/s, lr=0.000162, step_loss=0.051607/27/2023 17:56:30 - INFO - __main__ - train loss is 10.177627004450187\n",
      "Steps:   9%| | 1307/15000 [11:40<41:17,  5.53it/s, lr=0.000162, step_loss=0.002207/27/2023 17:56:30 - INFO - __main__ - train loss is 10.659393526380882\n",
      "Steps:   9%| | 1308/15000 [11:40<41:08,  5.55it/s, lr=0.000162, step_loss=0.482]07/27/2023 17:56:30 - INFO - __main__ - train loss is 10.824222735827789\n",
      "Steps:   9%| | 1309/15000 [11:41<41:03,  5.56it/s, lr=0.000162, step_loss=0.165]07/27/2023 17:56:30 - INFO - __main__ - train loss is 10.873080733930692\n",
      "Steps:   9%| | 1310/15000 [11:41<41:00,  5.56it/s, lr=0.000162, step_loss=0.048907/27/2023 17:56:31 - INFO - __main__ - train loss is 10.877549552125856\n",
      "Steps:   9%| | 1311/15000 [11:41<40:58,  5.57it/s, lr=0.000163, step_loss=0.004407/27/2023 17:56:31 - INFO - __main__ - train loss is 11.058784209890291\n",
      "Steps:   9%| | 1312/15000 [11:41<41:01,  5.56it/s, lr=0.000163, step_loss=0.181]07/27/2023 17:56:31 - INFO - __main__ - train loss is 11.127609953982756\n",
      "Steps:   9%| | 1313/15000 [11:41<40:57,  5.57it/s, lr=0.000163, step_loss=0.068807/27/2023 17:56:31 - INFO - __main__ - train loss is 11.544345781905577\n",
      "Steps:   9%| | 1314/15000 [11:41<41:20,  5.52it/s, lr=0.000163, step_loss=0.417]07/27/2023 17:56:31 - INFO - __main__ - train loss is 11.565517646027729\n",
      "Steps:   9%| | 1315/15000 [11:42<41:12,  5.54it/s, lr=0.000163, step_loss=0.021207/27/2023 17:56:31 - INFO - __main__ - train loss is 12.202155929757282\n",
      "Steps:   9%| | 1316/15000 [11:42<41:05,  5.55it/s, lr=0.000163, step_loss=0.637]07/27/2023 17:56:32 - INFO - __main__ - train loss is 12.24396323855035\n",
      "Steps:   9%| | 1317/15000 [11:42<41:00,  5.56it/s, lr=0.000163, step_loss=0.041807/27/2023 17:56:32 - INFO - __main__ - train loss is 12.248236727202311\n",
      "Steps:   9%| | 1318/15000 [11:42<40:58,  5.57it/s, lr=0.000163, step_loss=0.004207/27/2023 17:56:32 - INFO - __main__ - train loss is 12.250816747080535\n",
      "Steps:   9%| | 1319/15000 [11:42<41:21,  5.51it/s, lr=0.000164, step_loss=0.002507/27/2023 17:56:32 - INFO - __main__ - train loss is 12.355484149884433\n",
      "Steps:   9%| | 1320/15000 [11:43<41:31,  5.49it/s, lr=0.000164, step_loss=0.105]07/27/2023 17:56:32 - INFO - __main__ - train loss is 12.572780482005328\n",
      "Steps:   9%| | 1321/15000 [11:43<41:21,  5.51it/s, lr=0.000164, step_loss=0.217]07/27/2023 17:56:33 - INFO - __main__ - train loss is 12.587780450936407\n",
      "Steps:   9%| | 1322/15000 [11:43<41:10,  5.54it/s, lr=0.000164, step_loss=0.015]07/27/2023 17:56:33 - INFO - __main__ - train loss is 12.655108442064375\n",
      "Steps:   9%| | 1323/15000 [11:43<41:21,  5.51it/s, lr=0.000164, step_loss=0.067307/27/2023 17:56:33 - INFO - __main__ - train loss is 12.868112017866224\n",
      "Steps:   9%| | 1324/15000 [11:43<41:13,  5.53it/s, lr=0.000164, step_loss=0.213]07/27/2023 17:56:33 - INFO - __main__ - train loss is 13.175058712717146\n",
      "Steps:   9%| | 1325/15000 [11:43<41:11,  5.53it/s, lr=0.000164, step_loss=0.307]07/27/2023 17:56:33 - INFO - __main__ - train loss is 13.199788597878069\n",
      "Steps:   9%| | 1326/15000 [11:44<41:24,  5.50it/s, lr=0.000164, step_loss=0.024707/27/2023 17:56:33 - INFO - __main__ - train loss is 13.548808900173753\n",
      "Steps:   9%| | 1327/15000 [11:44<41:15,  5.52it/s, lr=0.000165, step_loss=0.349]07/27/2023 17:56:34 - INFO - __main__ - train loss is 13.555813768412918\n",
      "Steps:   9%| | 1328/15000 [11:44<41:22,  5.51it/s, lr=0.000165, step_loss=0.007]07/27/2023 17:56:34 - INFO - __main__ - train loss is 13.694333681371063\n",
      "Steps:   9%| | 1329/15000 [11:44<41:16,  5.52it/s, lr=0.000165, step_loss=0.139]07/27/2023 17:56:34 - INFO - __main__ - train loss is 14.020932653453201\n",
      "Steps:   9%| | 1330/15000 [11:44<41:13,  5.53it/s, lr=0.000165, step_loss=0.327]07/27/2023 17:56:34 - INFO - __main__ - train loss is 14.54642186453566\n",
      "Steps:   9%| | 1331/15000 [11:44<41:05,  5.54it/s, lr=0.000165, step_loss=0.525]07/27/2023 17:56:34 - INFO - __main__ - train loss is 14.548548461869359\n",
      "Steps:   9%| | 1332/15000 [11:45<41:01,  5.55it/s, lr=0.000165, step_loss=0.002107/27/2023 17:56:35 - INFO - __main__ - train loss is 14.646661194041371\n",
      "Steps:   9%| | 1333/15000 [11:45<41:01,  5.55it/s, lr=0.000165, step_loss=0.098107/27/2023 17:56:35 - INFO - __main__ - train loss is 14.662576792761683\n",
      "Steps:   9%| | 1334/15000 [11:45<41:00,  5.55it/s, lr=0.000165, step_loss=0.015907/27/2023 17:56:35 - INFO - __main__ - train loss is 14.716226099058986\n",
      "Steps:   9%| | 1335/15000 [11:45<41:01,  5.55it/s, lr=0.000166, step_loss=0.053607/27/2023 17:56:35 - INFO - __main__ - train loss is 14.788349313661456\n",
      "Steps:   9%| | 1336/15000 [11:45<40:59,  5.56it/s, lr=0.000166, step_loss=0.072107/27/2023 17:56:35 - INFO - __main__ - train loss is 15.287910534068942\n",
      "Steps:   9%|▎  | 1337/15000 [11:46<41:14,  5.52it/s, lr=0.000166, step_loss=0.5]07/27/2023 17:56:35 - INFO - __main__ - train loss is 15.954495383426547\n",
      "Steps:   9%| | 1338/15000 [11:46<41:05,  5.54it/s, lr=0.000166, step_loss=0.667]07/27/2023 17:56:36 - INFO - __main__ - train loss is 16.05451555363834\n",
      "Steps:   9%|▎  | 1339/15000 [11:46<41:00,  5.55it/s, lr=0.000166, step_loss=0.1]07/27/2023 17:56:36 - INFO - __main__ - train loss is 16.063042269088328\n",
      "Steps:   9%| | 1340/15000 [11:46<40:59,  5.55it/s, lr=0.000166, step_loss=0.008507/27/2023 17:56:36 - INFO - __main__ - train loss is 16.330319569446146\n",
      "Steps:   9%| | 1341/15000 [11:46<41:02,  5.55it/s, lr=0.000166, step_loss=0.267]07/27/2023 17:56:36 - INFO - __main__ - train loss is 16.341130265034735\n",
      "Steps:   9%| | 1342/15000 [11:46<41:20,  5.51it/s, lr=0.000166, step_loss=0.010807/27/2023 17:56:36 - INFO - __main__ - train loss is 16.362143700011075\n",
      "Steps:   9%| | 1343/15000 [11:47<41:19,  5.51it/s, lr=0.000167, step_loss=0.021]07/27/2023 17:56:37 - INFO - __main__ - train loss is 16.511993263848126\n",
      "Steps:   9%|▏ | 1344/15000 [11:47<41:16,  5.51it/s, lr=0.000167, step_loss=0.15]07/27/2023 17:56:37 - INFO - __main__ - train loss is 16.576524396426976\n",
      "Steps:   9%| | 1345/15000 [11:47<41:11,  5.52it/s, lr=0.000167, step_loss=0.064507/27/2023 17:56:37 - INFO - __main__ - train loss is 16.577806387795135\n",
      "Steps:   9%| | 1346/15000 [11:47<41:05,  5.54it/s, lr=0.000167, step_loss=0.001207/27/2023 17:56:37 - INFO - __main__ - train loss is 16.748353992355987\n",
      "Steps:   9%| | 1347/15000 [11:47<40:59,  5.55it/s, lr=0.000167, step_loss=0.171]07/27/2023 17:56:37 - INFO - __main__ - train loss is 16.797524188412353\n",
      "Steps:   9%| | 1348/15000 [11:48<40:55,  5.56it/s, lr=0.000167, step_loss=0.049207/27/2023 17:56:37 - INFO - __main__ - train loss is 16.813314067898318\n",
      "Steps:   9%| | 1349/15000 [11:48<41:26,  5.49it/s, lr=0.000167, step_loss=0.015807/27/2023 17:56:38 - INFO - __main__ - train loss is 17.175519573269412\n",
      "Steps:   9%| | 1350/15000 [11:48<41:14,  5.52it/s, lr=0.000167, step_loss=0.362]07/27/2023 17:56:38 - INFO - __main__ - train loss is 17.17874417384155\n",
      "Steps:   9%| | 1351/15000 [11:48<41:06,  5.53it/s, lr=0.000168, step_loss=0.003207/27/2023 17:56:38 - INFO - __main__ - train loss is 17.240816611098126\n",
      "Steps:   9%| | 1352/15000 [11:48<41:04,  5.54it/s, lr=0.000168, step_loss=0.062107/27/2023 17:56:38 - INFO - __main__ - train loss is 17.246345336781815\n",
      "Steps:   9%| | 1353/15000 [11:48<41:28,  5.48it/s, lr=0.000168, step_loss=0.005507/27/2023 17:56:38 - INFO - __main__ - train loss is 17.249314938904718\n",
      "Steps:   9%| | 1354/15000 [11:49<41:45,  5.45it/s, lr=0.000168, step_loss=0.002907/27/2023 17:56:39 - INFO - __main__ - train loss is 17.519615267636254\n",
      "Steps:   9%|▏ | 1355/15000 [11:49<41:50,  5.44it/s, lr=0.000168, step_loss=0.27]07/27/2023 17:56:39 - INFO - __main__ - train loss is 17.559865043731406\n",
      "Steps:   9%| | 1356/15000 [11:49<41:31,  5.48it/s, lr=0.000168, step_loss=0.040207/27/2023 17:56:39 - INFO - __main__ - train loss is 17.584331781836227\n",
      "Steps:   9%| | 1357/15000 [11:49<41:34,  5.47it/s, lr=0.000168, step_loss=0.024507/27/2023 17:56:39 - INFO - __main__ - train loss is 17.695135691436008\n",
      "Steps:   9%| | 1358/15000 [11:49<41:32,  5.47it/s, lr=0.000168, step_loss=0.111]07/27/2023 17:56:39 - INFO - __main__ - train loss is 17.703119998099282\n",
      "Steps:   9%| | 1359/15000 [11:50<41:18,  5.50it/s, lr=0.000169, step_loss=0.007907/27/2023 17:56:39 - INFO - __main__ - train loss is 17.710295781726018\n",
      "Steps:   9%| | 1360/15000 [11:50<41:13,  5.51it/s, lr=0.000169, step_loss=0.007107/27/2023 17:56:40 - INFO - __main__ - train loss is 17.99780412041582\n",
      "Steps:   9%| | 1361/15000 [11:50<41:04,  5.53it/s, lr=0.000169, step_loss=0.288]07/27/2023 17:56:40 - INFO - __main__ - train loss is 18.001142462249845\n",
      "Steps:   9%| | 1362/15000 [11:50<40:58,  5.55it/s, lr=0.000169, step_loss=0.003307/27/2023 17:56:40 - INFO - __main__ - train loss is 18.129859854932874\n",
      "Steps:   9%| | 1363/15000 [11:50<40:53,  5.56it/s, lr=0.000169, step_loss=0.129]07/27/2023 17:56:40 - INFO - __main__ - train loss is 18.156455331947654\n",
      "Steps:   9%| | 1364/15000 [11:50<41:15,  5.51it/s, lr=0.000169, step_loss=0.026607/27/2023 17:56:40 - INFO - __main__ - train loss is 18.18091050675139\n",
      "Steps:   9%| | 1365/15000 [11:51<41:13,  5.51it/s, lr=0.000169, step_loss=0.024507/27/2023 17:56:41 - INFO - __main__ - train loss is 18.247188189532608\n",
      "Steps:   9%| | 1366/15000 [11:51<41:22,  5.49it/s, lr=0.000169, step_loss=0.066307/27/2023 17:56:41 - INFO - __main__ - train loss is 18.253796807024628\n",
      "Steps:   9%| | 1367/15000 [11:51<41:32,  5.47it/s, lr=0.00017, step_loss=0.0066107/27/2023 17:56:41 - INFO - __main__ - train loss is 18.268482143525034\n",
      "Steps:   9%| | 1368/15000 [11:51<41:50,  5.43it/s, lr=0.00017, step_loss=0.0147]07/27/2023 17:56:41 - INFO - __main__ - train loss is 18.520743066910654\n",
      "Steps:   9%|▏ | 1369/15000 [11:51<41:41,  5.45it/s, lr=0.00017, step_loss=0.252]07/27/2023 17:56:41 - INFO - __main__ - train loss is 18.85014461958781\n",
      "Steps:   9%|▏ | 1370/15000 [11:52<41:49,  5.43it/s, lr=0.00017, step_loss=0.329]07/27/2023 17:56:41 - INFO - __main__ - train loss is 18.85690919170156\n",
      "Steps:   9%| | 1371/15000 [11:52<41:50,  5.43it/s, lr=0.00017, step_loss=0.0067607/27/2023 17:56:42 - INFO - __main__ - train loss is 18.879626052919775\n",
      "Steps:   9%| | 1372/15000 [11:52<41:58,  5.41it/s, lr=0.00017, step_loss=0.0227]07/27/2023 17:56:42 - INFO - __main__ - train loss is 18.928879404906183\n",
      "Steps:   9%| | 1373/15000 [11:52<41:38,  5.46it/s, lr=0.00017, step_loss=0.0493]07/27/2023 17:56:42 - INFO - __main__ - train loss is 18.933838272001594\n",
      "Steps:   9%| | 1374/15000 [11:52<41:21,  5.49it/s, lr=0.00017, step_loss=0.0049607/27/2023 17:56:42 - INFO - __main__ - train loss is 18.936759570147842\n",
      "Steps:   9%| | 1375/15000 [11:52<41:09,  5.52it/s, lr=0.000171, step_loss=0.002907/27/2023 17:56:42 - INFO - __main__ - train loss is 18.938320089364424\n",
      "Steps:   9%| | 1376/15000 [11:53<41:31,  5.47it/s, lr=0.000171, step_loss=0.001507/27/2023 17:56:43 - INFO - __main__ - train loss is 19.548800755525008\n",
      "Steps:   9%|▏ | 1377/15000 [11:53<41:24,  5.48it/s, lr=0.000171, step_loss=0.61]07/27/2023 17:56:43 - INFO - __main__ - train loss is 20.041609842563048\n",
      "Steps:   9%| | 1378/15000 [11:53<41:12,  5.51it/s, lr=0.000171, step_loss=0.493]07/27/2023 17:56:43 - INFO - __main__ - train loss is 20.263535786652938\n",
      "Steps:   9%| | 1379/15000 [11:53<41:03,  5.53it/s, lr=0.000171, step_loss=0.222]07/27/2023 17:56:43 - INFO - __main__ - train loss is 20.769725252175704\n",
      "Steps:   9%| | 1380/15000 [11:53<40:59,  5.54it/s, lr=0.000171, step_loss=0.506]07/27/2023 17:56:43 - INFO - __main__ - train loss is 20.857816208386794\n",
      "Steps:   9%| | 1381/15000 [11:54<40:53,  5.55it/s, lr=0.000171, step_loss=0.088107/27/2023 17:56:43 - INFO - __main__ - train loss is 21.177971739554778\n",
      "Steps:   9%|▏ | 1382/15000 [11:54<40:53,  5.55it/s, lr=0.000171, step_loss=0.32]07/27/2023 17:56:44 - INFO - __main__ - train loss is 21.20330446609296\n",
      "Steps:   9%| | 1383/15000 [11:54<40:52,  5.55it/s, lr=0.000172, step_loss=0.025307/27/2023 17:56:44 - INFO - __main__ - train loss is 21.441078882897273\n",
      "Steps:   9%| | 1384/15000 [11:54<40:55,  5.54it/s, lr=0.000172, step_loss=0.238]07/27/2023 17:56:44 - INFO - __main__ - train loss is 21.584697913611308\n",
      "Steps:   9%| | 1385/15000 [11:54<41:05,  5.52it/s, lr=0.000172, step_loss=0.144]07/27/2023 17:56:44 - INFO - __main__ - train loss is 21.59700362221338\n",
      "Steps:   9%| | 1386/15000 [11:54<41:20,  5.49it/s, lr=0.000172, step_loss=0.012307/27/2023 17:56:44 - INFO - __main__ - train loss is 21.8469591869507\n",
      "Steps:   9%|▏ | 1387/15000 [11:55<41:17,  5.49it/s, lr=0.000172, step_loss=0.25]07/27/2023 17:56:45 - INFO - __main__ - train loss is 22.006599916378036\n",
      "Steps:   9%|▏ | 1388/15000 [11:55<41:20,  5.49it/s, lr=0.000172, step_loss=0.16]07/27/2023 17:56:45 - INFO - __main__ - train loss is 22.008796300040558\n",
      "Steps:   9%| | 1389/15000 [11:55<41:09,  5.51it/s, lr=0.000172, step_loss=0.002207/27/2023 17:56:45 - INFO - __main__ - train loss is 22.06866707955487\n",
      "Steps:   9%| | 1390/15000 [11:55<41:08,  5.51it/s, lr=0.000172, step_loss=0.059907/27/2023 17:56:45 - INFO - __main__ - train loss is 22.30428722058423\n",
      "Steps:   9%| | 1391/15000 [11:55<41:23,  5.48it/s, lr=0.000172, step_loss=0.236]07/27/2023 17:56:45 - INFO - __main__ - train loss is 22.409560310887173\n",
      "Steps:   9%| | 1392/15000 [11:56<41:17,  5.49it/s, lr=0.000173, step_loss=0.105]07/27/2023 17:56:45 - INFO - __main__ - train loss is 22.49034025077708\n",
      "Steps:   9%| | 1393/15000 [11:56<41:07,  5.51it/s, lr=0.000173, step_loss=0.080807/27/2023 17:56:46 - INFO - __main__ - train loss is 22.50174014014192\n",
      "Steps:   9%| | 1394/15000 [11:56<40:59,  5.53it/s, lr=0.000173, step_loss=0.011407/27/2023 17:56:46 - INFO - __main__ - train loss is 22.520511173876002\n",
      "Steps:   9%| | 1395/15000 [11:56<40:52,  5.55it/s, lr=0.000173, step_loss=0.018807/27/2023 17:56:46 - INFO - __main__ - train loss is 23.182713174493983\n",
      "Steps:   9%| | 1396/15000 [11:56<41:12,  5.50it/s, lr=0.000173, step_loss=0.662]07/27/2023 17:56:46 - INFO - __main__ - train loss is 23.302675255807117\n",
      "Steps:   9%|▏ | 1397/15000 [11:56<41:05,  5.52it/s, lr=0.000173, step_loss=0.12]07/27/2023 17:56:46 - INFO - __main__ - train loss is 23.309561014873907\n",
      "Steps:   9%| | 1398/15000 [11:57<40:58,  5.53it/s, lr=0.000173, step_loss=0.006807/27/2023 17:56:47 - INFO - __main__ - train loss is 23.32872301596217\n",
      "Steps:   9%| | 1399/15000 [11:57<40:53,  5.54it/s, lr=0.000173, step_loss=0.019207/27/2023 17:56:47 - INFO - __main__ - train loss is 23.379918093560264\n",
      "Steps:   9%| | 1400/15000 [11:57<41:06,  5.51it/s, lr=0.000174, step_loss=0.051207/27/2023 17:56:47 - INFO - __main__ - train loss is 23.418798385886475\n",
      "Steps:   9%| | 1401/15000 [11:57<40:59,  5.53it/s, lr=0.000174, step_loss=0.038907/27/2023 17:56:47 - INFO - __main__ - train loss is 23.421903324546292\n",
      "Steps:   9%| | 1402/15000 [11:57<40:55,  5.54it/s, lr=0.000174, step_loss=0.003107/27/2023 17:56:47 - INFO - __main__ - train loss is 23.71391172450967\n",
      "Steps:   9%| | 1403/15000 [11:58<40:51,  5.55it/s, lr=0.000174, step_loss=0.292]07/27/2023 17:56:47 - INFO - __main__ - train loss is 23.87477229279466\n",
      "Steps:   9%| | 1404/15000 [11:58<40:55,  5.54it/s, lr=0.000174, step_loss=0.161]07/27/2023 17:56:48 - INFO - __main__ - train loss is 23.994850133778527\n",
      "Steps:   9%|▏ | 1405/15000 [11:58<40:50,  5.55it/s, lr=0.000174, step_loss=0.12]07/27/2023 17:56:48 - INFO - __main__ - train loss is 24.156762515427545\n",
      "Steps:   9%| | 1406/15000 [11:58<40:48,  5.55it/s, lr=0.000174, step_loss=0.162]07/27/2023 17:56:48 - INFO - __main__ - train loss is 24.65775087964721\n",
      "Steps:   9%| | 1407/15000 [11:58<40:45,  5.56it/s, lr=0.000174, step_loss=0.501]07/27/2023 17:56:48 - INFO - __main__ - train loss is 24.681781959952787\n",
      "Steps:   9%| | 1408/15000 [11:58<40:45,  5.56it/s, lr=0.000175, step_loss=0.024]07/27/2023 17:56:48 - INFO - __main__ - train loss is 24.687951743369922\n",
      "Steps:   9%| | 1409/15000 [11:59<40:44,  5.56it/s, lr=0.000175, step_loss=0.006107/27/2023 17:56:49 - INFO - __main__ - train loss is 24.727842148160562\n",
      "Steps:   9%| | 1410/15000 [11:59<40:48,  5.55it/s, lr=0.000175, step_loss=0.039907/27/2023 17:56:49 - INFO - __main__ - train loss is 24.730697242775932\n",
      "Steps:   9%| | 1411/15000 [11:59<40:50,  5.55it/s, lr=0.000175, step_loss=0.002807/27/2023 17:56:49 - INFO - __main__ - train loss is 24.735283042071387\n",
      "Steps:   9%| | 1412/15000 [11:59<41:09,  5.50it/s, lr=0.000175, step_loss=0.004507/27/2023 17:56:49 - INFO - __main__ - train loss is 25.530941928504035\n",
      "Steps:   9%| | 1413/15000 [11:59<41:00,  5.52it/s, lr=0.000175, step_loss=0.796]07/27/2023 17:56:49 - INFO - __main__ - train loss is 25.557225900469348\n",
      "Steps:   9%| | 1414/15000 [12:00<40:56,  5.53it/s, lr=0.000175, step_loss=0.026307/27/2023 17:56:49 - INFO - __main__ - train loss is 25.7113691593986\n",
      "Steps:   9%| | 1415/15000 [12:00<40:50,  5.54it/s, lr=0.000175, step_loss=0.154]07/27/2023 17:56:50 - INFO - __main__ - train loss is 25.88817951339297\n",
      "Steps:   9%| | 1416/15000 [12:00<40:54,  5.53it/s, lr=0.000176, step_loss=0.177]07/27/2023 17:56:50 - INFO - __main__ - train loss is 25.8934214648325\n",
      "Steps:   9%| | 1417/15000 [12:00<40:57,  5.53it/s, lr=0.000176, step_loss=0.005207/27/2023 17:56:50 - INFO - __main__ - train loss is 26.017613002331927\n",
      "Steps:   9%| | 1418/15000 [12:00<40:51,  5.54it/s, lr=0.000176, step_loss=0.124]07/27/2023 17:56:50 - INFO - __main__ - train loss is 26.63771576550789\n",
      "Steps:   9%|▏ | 1419/15000 [12:00<40:48,  5.55it/s, lr=0.000176, step_loss=0.62]07/27/2023 17:56:50 - INFO - __main__ - train loss is 26.824948468478397\n",
      "Steps:   9%| | 1420/15000 [12:01<40:46,  5.55it/s, lr=0.000176, step_loss=0.187]07/27/2023 17:56:50 - INFO - __main__ - train loss is 26.827477348502725\n",
      "Steps:   9%| | 1421/15000 [12:01<40:47,  5.55it/s, lr=0.000176, step_loss=0.002507/27/2023 17:56:51 - INFO - __main__ - train loss is 26.831016284180805\n",
      "Steps:   9%| | 1422/15000 [12:01<40:45,  5.55it/s, lr=0.000176, step_loss=0.003507/27/2023 17:56:51 - INFO - __main__ - train loss is 26.865696881664917\n",
      "Steps:   9%| | 1423/15000 [12:01<40:44,  5.55it/s, lr=0.000176, step_loss=0.034707/27/2023 17:56:51 - INFO - __main__ - train loss is 26.945872728480026\n",
      "Steps:   9%| | 1424/15000 [12:01<40:54,  5.53it/s, lr=0.000177, step_loss=0.080207/27/2023 17:56:51 - INFO - __main__ - train loss is 27.205269788159057\n",
      "Steps:  10%| | 1425/15000 [12:02<40:50,  5.54it/s, lr=0.000177, step_loss=0.259]07/27/2023 17:56:51 - INFO - __main__ - train loss is 27.63555381144397\n",
      "Steps:  10%|▏ | 1426/15000 [12:02<40:46,  5.55it/s, lr=0.000177, step_loss=0.43]07/27/2023 17:56:52 - INFO - __main__ - train loss is 27.806087975157425\n",
      "Steps:  10%| | 1427/15000 [12:02<40:49,  5.54it/s, lr=0.000177, step_loss=0.171]07/27/2023 17:56:52 - INFO - __main__ - train loss is 28.12178805912845\n",
      "Steps:  10%| | 1428/15000 [12:02<41:16,  5.48it/s, lr=0.000177, step_loss=0.316]07/27/2023 17:56:52 - INFO - __main__ - train loss is 28.216289398027584\n",
      "Steps:  10%| | 1429/15000 [12:02<41:28,  5.45it/s, lr=0.000177, step_loss=0.094507/27/2023 17:56:52 - INFO - __main__ - train loss is 28.35257923300378\n",
      "Steps:  10%| | 1430/15000 [12:02<41:14,  5.48it/s, lr=0.000177, step_loss=0.136]07/27/2023 17:56:52 - INFO - __main__ - train loss is 28.41419367934577\n",
      "Steps:  10%| | 1431/15000 [12:03<41:04,  5.51it/s, lr=0.000178, step_loss=0.061607/27/2023 17:56:52 - INFO - __main__ - train loss is 28.819748510373756\n",
      "Steps:  10%| | 1432/15000 [12:03<41:03,  5.51it/s, lr=0.000178, step_loss=0.406]07/27/2023 17:56:53 - INFO - __main__ - train loss is 28.82167443796061\n",
      "Steps:  10%| | 1433/15000 [12:03<40:56,  5.52it/s, lr=0.000178, step_loss=0.001907/27/2023 17:56:53 - INFO - __main__ - train loss is 28.97138995095156\n",
      "Steps:  10%|▏ | 1434/15000 [12:03<40:50,  5.54it/s, lr=0.000178, step_loss=0.15]07/27/2023 17:56:53 - INFO - __main__ - train loss is 29.071779096266255\n",
      "Steps:  10%|▎  | 1435/15000 [12:03<41:09,  5.49it/s, lr=0.000178, step_loss=0.1]07/27/2023 17:56:53 - INFO - __main__ - train loss is 29.191910246154293\n",
      "Steps:  10%|▏ | 1436/15000 [12:04<41:11,  5.49it/s, lr=0.000178, step_loss=0.12]07/27/2023 17:56:53 - INFO - __main__ - train loss is 29.198045085882768\n",
      "Steps:  10%| | 1437/15000 [12:04<41:05,  5.50it/s, lr=0.000178, step_loss=0.006107/27/2023 17:56:54 - INFO - __main__ - train loss is 29.22933315834962\n",
      "Steps:  10%| | 1438/15000 [12:04<40:55,  5.52it/s, lr=0.000178, step_loss=0.031307/27/2023 17:56:54 - INFO - __main__ - train loss is 29.51204254827462\n",
      "Steps:  10%| | 1439/15000 [12:04<40:59,  5.51it/s, lr=0.000179, step_loss=0.283]07/27/2023 17:56:54 - INFO - __main__ - train loss is 30.02300712070428\n",
      "Steps:  10%| | 1440/15000 [12:04<41:07,  5.50it/s, lr=0.000179, step_loss=0.511]07/27/2023 17:56:54 - INFO - __main__ - train loss is 30.43841364583932\n",
      "Steps:  10%| | 1441/15000 [12:04<41:11,  5.49it/s, lr=0.000179, step_loss=0.415]07/27/2023 17:56:54 - INFO - __main__ - train loss is 30.60110669932328\n",
      "Steps:  10%| | 1442/15000 [12:05<41:12,  5.48it/s, lr=0.000179, step_loss=0.163]07/27/2023 17:56:54 - INFO - __main__ - train loss is 30.604711432009935\n",
      "Steps:  10%| | 1443/15000 [12:05<41:24,  5.46it/s, lr=0.000179, step_loss=0.003607/27/2023 17:56:55 - INFO - __main__ - train loss is 30.61973056010902\n",
      "Steps:  10%| | 1444/15000 [12:05<41:09,  5.49it/s, lr=0.000179, step_loss=0.015]07/27/2023 17:56:55 - INFO - __main__ - train loss is 30.623301977757365\n",
      "Steps:  10%| | 1445/15000 [12:05<41:03,  5.50it/s, lr=0.000179, step_loss=0.003507/27/2023 17:56:55 - INFO - __main__ - train loss is 30.62533047585748\n",
      "Steps:  10%| | 1446/15000 [12:05<41:16,  5.47it/s, lr=0.000179, step_loss=0.002007/27/2023 17:56:55 - INFO - __main__ - train loss is 30.76970642595552\n",
      "Steps:  10%| | 1447/15000 [12:06<41:15,  5.47it/s, lr=0.000179, step_loss=0.144]07/27/2023 17:56:55 - INFO - __main__ - train loss is 31.167135474970564\n",
      "Steps:  10%|▏ | 1448/15000 [12:06<41:25,  5.45it/s, lr=0.00018, step_loss=0.397]07/27/2023 17:56:56 - INFO - __main__ - train loss is 31.207882122835144\n",
      "Steps:  10%| | 1449/15000 [12:06<41:40,  5.42it/s, lr=0.00018, step_loss=0.0407]07/27/2023 17:56:56 - INFO - __main__ - train loss is 31.215919429203495\n",
      "Steps:  10%| | 1450/15000 [12:06<41:27,  5.45it/s, lr=0.00018, step_loss=0.0080407/27/2023 17:56:56 - INFO - __main__ - train loss is 31.221317518269643\n",
      "Steps:  10%| | 1451/15000 [12:06<41:40,  5.42it/s, lr=0.00018, step_loss=0.0054]07/27/2023 17:56:56 - INFO - __main__ - train loss is 31.22411863040179\n",
      "Steps:  10%| | 1452/15000 [12:06<41:27,  5.45it/s, lr=0.00018, step_loss=0.0028]07/27/2023 17:56:56 - INFO - __main__ - train loss is 31.3117272881791\n",
      "Steps:  10%| | 1453/15000 [12:07<41:26,  5.45it/s, lr=0.00018, step_loss=0.0876]07/27/2023 17:56:57 - INFO - __main__ - train loss is 31.618578555993736\n",
      "Steps:  10%|▏ | 1454/15000 [12:07<41:31,  5.44it/s, lr=0.00018, step_loss=0.307]07/27/2023 17:56:57 - INFO - __main__ - train loss is 31.623230994679034\n",
      "Steps:  10%| | 1455/15000 [12:07<41:22,  5.46it/s, lr=0.00018, step_loss=0.0046507/27/2023 17:56:57 - INFO - __main__ - train loss is 31.636161315254867\n",
      "Steps:  10%| | 1456/15000 [12:07<41:06,  5.49it/s, lr=0.000181, step_loss=0.012907/27/2023 17:56:57 - INFO - __main__ - train loss is 31.811219069175422\n",
      "Steps:  10%| | 1457/15000 [12:07<40:55,  5.52it/s, lr=0.000181, step_loss=0.175]07/27/2023 17:56:57 - INFO - __main__ - train loss is 31.896156447939575\n",
      "Steps:  10%| | 1458/15000 [12:08<41:03,  5.50it/s, lr=0.000181, step_loss=0.084907/27/2023 17:56:57 - INFO - __main__ - train loss is 32.435327428393066\n",
      "Steps:  10%| | 1459/15000 [12:08<41:22,  5.45it/s, lr=0.000181, step_loss=0.539]07/27/2023 17:56:58 - INFO - __main__ - train loss is 32.43971489276737\n",
      "Steps:  10%| | 1460/15000 [12:08<41:14,  5.47it/s, lr=0.000181, step_loss=0.004307/27/2023 17:56:58 - INFO - __main__ - train loss is 32.47912542428821\n",
      "Steps:  10%| | 1461/15000 [12:08<41:04,  5.49it/s, lr=0.000181, step_loss=0.039407/27/2023 17:56:58 - INFO - __main__ - train loss is 32.491683980450034\n",
      "Steps:  10%| | 1462/15000 [12:08<40:53,  5.52it/s, lr=0.000181, step_loss=0.012607/27/2023 17:56:58 - INFO - __main__ - train loss is 32.79947834275663\n",
      "Steps:  10%| | 1463/15000 [12:08<41:07,  5.49it/s, lr=0.000181, step_loss=0.308]07/27/2023 17:56:58 - INFO - __main__ - train loss is 32.86312443576753\n",
      "Steps:  10%| | 1464/15000 [12:09<40:56,  5.51it/s, lr=0.000182, step_loss=0.063607/27/2023 17:56:59 - INFO - __main__ - train loss is 32.9017119910568\n",
      "Steps:  10%| | 1465/15000 [12:09<40:49,  5.53it/s, lr=0.000182, step_loss=0.038607/27/2023 17:56:59 - INFO - __main__ - train loss is 33.001976964995265\n",
      "Steps:  10%|▎  | 1466/15000 [12:09<40:46,  5.53it/s, lr=0.000182, step_loss=0.1]07/27/2023 17:56:59 - INFO - __main__ - train loss is 33.00793586205691\n",
      "Steps:  10%| | 1467/15000 [12:09<41:04,  5.49it/s, lr=0.000182, step_loss=0.005907/27/2023 17:56:59 - INFO - __main__ - train loss is 33.01937451027334\n",
      "Steps:  10%| | 1468/15000 [12:09<40:52,  5.52it/s, lr=0.000182, step_loss=0.011407/27/2023 17:56:59 - INFO - __main__ - train loss is 33.08484728448093\n",
      "Steps:  10%| | 1469/15000 [12:10<40:43,  5.54it/s, lr=0.000182, step_loss=0.065507/27/2023 17:56:59 - INFO - __main__ - train loss is 33.09342204220593\n",
      "Steps:  10%| | 1470/15000 [12:10<40:37,  5.55it/s, lr=0.000182, step_loss=0.008507/27/2023 17:57:00 - INFO - __main__ - train loss is 33.242693500593305\n",
      "Steps:  10%| | 1471/15000 [12:10<40:43,  5.54it/s, lr=0.000182, step_loss=0.149]07/27/2023 17:57:00 - INFO - __main__ - train loss is 33.245276304893196\n",
      "Steps:  10%| | 1472/15000 [12:10<40:37,  5.55it/s, lr=0.000183, step_loss=0.002507/27/2023 17:57:00 - INFO - __main__ - train loss is 33.52933147829026\n",
      "Steps:  10%| | 1473/15000 [12:10<40:33,  5.56it/s, lr=0.000183, step_loss=0.284]07/27/2023 17:57:00 - INFO - __main__ - train loss is 33.5394987128675\n",
      "Steps:  10%| | 1474/15000 [12:10<40:32,  5.56it/s, lr=0.000183, step_loss=0.010207/27/2023 17:57:00 - INFO - __main__ - train loss is 33.63903022930026\n",
      "Steps:  10%| | 1475/15000 [12:11<40:35,  5.55it/s, lr=0.000183, step_loss=0.099507/27/2023 17:57:00 - INFO - __main__ - train loss is 34.053205978125334\n",
      "Steps:  10%| | 1476/15000 [12:11<40:33,  5.56it/s, lr=0.000183, step_loss=0.414]07/27/2023 17:57:01 - INFO - __main__ - train loss is 34.18645615503192\n",
      "Steps:  10%| | 1477/15000 [12:11<40:30,  5.56it/s, lr=0.000183, step_loss=0.133]07/27/2023 17:57:01 - INFO - __main__ - train loss is 34.198643137700856\n",
      "Steps:  10%| | 1478/15000 [12:11<40:27,  5.57it/s, lr=0.000183, step_loss=0.012207/27/2023 17:57:01 - INFO - __main__ - train loss is 34.208946202881634\n",
      "Steps:  10%| | 1479/15000 [12:11<40:50,  5.52it/s, lr=0.000183, step_loss=0.010307/27/2023 17:57:01 - INFO - __main__ - train loss is 34.45329063106328\n",
      "Steps:  10%| | 1480/15000 [12:12<40:41,  5.54it/s, lr=0.000184, step_loss=0.244]07/27/2023 17:57:01 - INFO - __main__ - train loss is 34.69500856567174\n",
      "Steps:  10%| | 1481/15000 [12:12<40:36,  5.55it/s, lr=0.000184, step_loss=0.242]07/27/2023 17:57:02 - INFO - __main__ - train loss is 34.760692027397454\n",
      "Steps:  10%| | 1482/15000 [12:12<40:33,  5.55it/s, lr=0.000184, step_loss=0.065707/27/2023 17:57:02 - INFO - __main__ - train loss is 34.80664449650794\n",
      "Steps:  10%| | 1483/15000 [12:12<40:46,  5.53it/s, lr=0.000184, step_loss=0.046]07/27/2023 17:57:02 - INFO - __main__ - train loss is 34.94264036137611\n",
      "Steps:  10%| | 1484/15000 [12:12<40:38,  5.54it/s, lr=0.000184, step_loss=0.136]07/27/2023 17:57:02 - INFO - __main__ - train loss is 34.96025288756937\n",
      "Steps:  10%| | 1485/15000 [12:12<40:33,  5.55it/s, lr=0.000184, step_loss=0.017607/27/2023 17:57:02 - INFO - __main__ - train loss is 34.9946968248114\n",
      "Steps:  10%| | 1486/15000 [12:13<40:31,  5.56it/s, lr=0.000184, step_loss=0.034407/27/2023 17:57:02 - INFO - __main__ - train loss is 35.2990038683638\n",
      "Steps:  10%| | 1487/15000 [12:13<40:46,  5.52it/s, lr=0.000185, step_loss=0.304]07/27/2023 17:57:03 - INFO - __main__ - train loss is 35.300733133684844\n",
      "Steps:  10%| | 1488/15000 [12:13<40:38,  5.54it/s, lr=0.000185, step_loss=0.001707/27/2023 17:57:03 - INFO - __main__ - train loss is 35.80355291021988\n",
      "Steps:  10%| | 1489/15000 [12:13<40:56,  5.50it/s, lr=0.000185, step_loss=0.503]07/27/2023 17:57:03 - INFO - __main__ - train loss is 35.808302839286625\n",
      "Steps:  10%| | 1490/15000 [12:13<41:07,  5.47it/s, lr=0.000185, step_loss=0.004707/27/2023 17:57:03 - INFO - __main__ - train loss is 36.14901583362371\n",
      "Steps:  10%| | 1491/15000 [12:14<41:02,  5.49it/s, lr=0.000185, step_loss=0.341]07/27/2023 17:57:03 - INFO - __main__ - train loss is 36.161383788101375\n",
      "Steps:  10%| | 1492/15000 [12:14<40:50,  5.51it/s, lr=0.000185, step_loss=0.012407/27/2023 17:57:04 - INFO - __main__ - train loss is 36.370254467241466\n",
      "Steps:  10%| | 1493/15000 [12:14<40:47,  5.52it/s, lr=0.000185, step_loss=0.209]07/27/2023 17:57:04 - INFO - __main__ - train loss is 36.37409304874018\n",
      "Steps:  10%| | 1494/15000 [12:14<40:41,  5.53it/s, lr=0.000185, step_loss=0.003807/27/2023 17:57:04 - INFO - __main__ - train loss is 36.521267615724355\n",
      "Steps:  10%| | 1495/15000 [12:14<40:56,  5.50it/s, lr=0.000186, step_loss=0.147]07/27/2023 17:57:04 - INFO - __main__ - train loss is 36.53686405392364\n",
      "Steps:  10%| | 1496/15000 [12:14<41:11,  5.46it/s, lr=0.000186, step_loss=0.015607/27/2023 17:57:04 - INFO - __main__ - train loss is 36.57761402102187\n",
      "Steps:  10%| | 1497/15000 [12:15<41:05,  5.48it/s, lr=0.000186, step_loss=0.040707/27/2023 17:57:04 - INFO - __main__ - train loss is 36.74155595572665\n",
      "Steps:  10%| | 1498/15000 [12:15<41:06,  5.47it/s, lr=0.000186, step_loss=0.164]07/27/2023 17:57:05 - INFO - __main__ - train loss is 36.745615439955145\n",
      "Steps:  10%| | 1499/15000 [12:15<41:12,  5.46it/s, lr=0.000186, step_loss=0.004007/27/2023 17:57:05 - INFO - __main__ - train loss is 36.75165019975975\n",
      "Steps:  10%| | 1500/15000 [12:15<41:18,  5.45it/s, lr=0.000186, step_loss=0.004007/27/2023 17:57:05 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-1500\n",
      "07/27/2023 17:57:05 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 17:57:05,435] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 17:57:05,441] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 17:57:05,441] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 17:57:05,449] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 17:57:05,450] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 17:57:05,459] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 17:57:05,459] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 17:57:05,459] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 17:57:05 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-1500/pytorch_model\n",
      "07/27/2023 17:57:05 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-1500/scheduler.bin\n",
      "07/27/2023 17:57:05 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-1500/random_states_0.pkl\n",
      "07/27/2023 17:57:05 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-1500\n",
      "Steps:  10%| | 1500/15000 [12:15<41:18,  5.45it/s, lr=0.000186, step_loss=0.006007/27/2023 17:57:05 - INFO - __main__ - train loss is 36.76369188213721\n",
      "Steps:  10%| | 1501/15000 [12:15<42:52,  5.25it/s, lr=0.000186, step_loss=0.012]07/27/2023 17:57:05 - INFO - __main__ - train loss is 37.229506412986666\n",
      "Steps:  10%| | 1502/15000 [12:16<42:42,  5.27it/s, lr=0.000186, step_loss=0.466]07/27/2023 17:57:05 - INFO - __main__ - train loss is 37.245110420975834\n",
      "Steps:  10%| | 1503/15000 [12:16<42:06,  5.34it/s, lr=0.000187, step_loss=0.015607/27/2023 17:57:06 - INFO - __main__ - train loss is 37.26076953718439\n",
      "Steps:  10%| | 1504/15000 [12:16<41:33,  5.41it/s, lr=0.000187, step_loss=0.015707/27/2023 17:57:06 - INFO - __main__ - train loss is 37.36658209422603\n",
      "Steps:  10%| | 1505/15000 [12:16<41:31,  5.42it/s, lr=0.000187, step_loss=0.106]07/27/2023 17:57:06 - INFO - __main__ - train loss is 37.43978920439258\n",
      "Steps:  10%| | 1506/15000 [12:16<41:14,  5.45it/s, lr=0.000187, step_loss=0.073207/27/2023 17:57:06 - INFO - __main__ - train loss is 38.36911180475727\n",
      "Steps:  10%| | 1507/15000 [12:16<40:55,  5.49it/s, lr=0.000187, step_loss=0.929]07/27/2023 17:57:06 - INFO - __main__ - train loss is 38.3993590218015\n",
      "Steps:  10%| | 1508/15000 [12:17<40:42,  5.52it/s, lr=0.000187, step_loss=0.030207/27/2023 17:57:07 - INFO - __main__ - train loss is 38.42623265692964\n",
      "Steps:  10%| | 1509/15000 [12:17<40:35,  5.54it/s, lr=0.000187, step_loss=0.026907/27/2023 17:57:07 - INFO - __main__ - train loss is 38.66383255133405\n",
      "Steps:  10%| | 1510/15000 [12:17<40:32,  5.55it/s, lr=0.000187, step_loss=0.238]07/27/2023 17:57:07 - INFO - __main__ - train loss is 38.70957053313032\n",
      "Steps:  10%| | 1511/15000 [12:17<40:25,  5.56it/s, lr=0.000188, step_loss=0.045707/27/2023 17:57:07 - INFO - __main__ - train loss is 38.90700594196096\n",
      "Steps:  10%| | 1512/15000 [12:17<40:19,  5.57it/s, lr=0.000188, step_loss=0.197]07/27/2023 17:57:07 - INFO - __main__ - train loss is 39.04172242293134\n",
      "Steps:  10%| | 1513/15000 [12:18<40:16,  5.58it/s, lr=0.000188, step_loss=0.135]07/27/2023 17:57:07 - INFO - __main__ - train loss is 39.05497446144\n",
      "Steps:  10%| | 1514/15000 [12:18<40:17,  5.58it/s, lr=0.000188, step_loss=0.013307/27/2023 17:57:08 - INFO - __main__ - train loss is 39.28522827709094\n",
      "Steps:  10%|▏ | 1515/15000 [12:18<54:46,  4.10it/s, lr=0.000188, step_loss=0.23]07/27/2023 17:57:09 - INFO - __main__ - Per validation step average loss is 0.04737333580851555\n",
      "07/27/2023 17:57:09 - INFO - __main__ - Cumulative validation average loss is 0.04737333580851555\n",
      "07/27/2023 17:57:09 - INFO - __main__ - Per validation step average loss is 0.29654309153556824\n",
      "07/27/2023 17:57:09 - INFO - __main__ - Cumulative validation average loss is 0.3439164273440838\n",
      "07/27/2023 17:57:10 - INFO - __main__ - Per validation step average loss is 0.00964365340769291\n",
      "07/27/2023 17:57:10 - INFO - __main__ - Cumulative validation average loss is 0.3535600807517767\n",
      "07/27/2023 17:57:10 - INFO - __main__ - Per validation step average loss is 0.06396783888339996\n",
      "07/27/2023 17:57:10 - INFO - __main__ - Cumulative validation average loss is 0.41752791963517666\n",
      "07/27/2023 17:57:10 - INFO - __main__ - Per validation step average loss is 0.0973471999168396\n",
      "07/27/2023 17:57:10 - INFO - __main__ - Cumulative validation average loss is 0.5148751195520163\n",
      "07/27/2023 17:57:11 - INFO - __main__ - Per validation step average loss is 0.07762066274881363\n",
      "07/27/2023 17:57:11 - INFO - __main__ - Cumulative validation average loss is 0.5924957823008299\n",
      "07/27/2023 17:57:11 - INFO - __main__ - Per validation step average loss is 0.08896256238222122\n",
      "07/27/2023 17:57:11 - INFO - __main__ - Cumulative validation average loss is 0.6814583446830511\n",
      "07/27/2023 17:57:12 - INFO - __main__ - Per validation step average loss is 0.11812702566385269\n",
      "07/27/2023 17:57:12 - INFO - __main__ - Cumulative validation average loss is 0.7995853703469038\n",
      "07/27/2023 17:57:12 - INFO - __main__ - Per validation step average loss is 0.01058390736579895\n",
      "07/27/2023 17:57:12 - INFO - __main__ - Cumulative validation average loss is 0.8101692777127028\n",
      "07/27/2023 17:57:13 - INFO - __main__ - Per validation step average loss is 0.14281734824180603\n",
      "07/27/2023 17:57:13 - INFO - __main__ - Cumulative validation average loss is 0.9529866259545088\n",
      "07/27/2023 17:57:13 - INFO - __main__ - Per validation step average loss is 0.20847490429878235\n",
      "07/27/2023 17:57:13 - INFO - __main__ - Cumulative validation average loss is 1.1614615302532911\n",
      "07/27/2023 17:57:13 - INFO - __main__ - Per validation step average loss is 0.14663034677505493\n",
      "07/27/2023 17:57:13 - INFO - __main__ - Cumulative validation average loss is 1.308091877028346\n",
      "07/27/2023 17:57:14 - INFO - __main__ - Per validation step average loss is 0.28002431988716125\n",
      "07/27/2023 17:57:14 - INFO - __main__ - Cumulative validation average loss is 1.5881161969155073\n",
      "07/27/2023 17:57:14 - INFO - __main__ - Per validation step average loss is 0.03417513519525528\n",
      "07/27/2023 17:57:14 - INFO - __main__ - Cumulative validation average loss is 1.6222913321107626\n",
      "07/27/2023 17:57:15 - INFO - __main__ - Per validation step average loss is 0.0021039480343461037\n",
      "07/27/2023 17:57:15 - INFO - __main__ - Cumulative validation average loss is 1.6243952801451087\n",
      "07/27/2023 17:57:15 - INFO - __main__ - Per validation step average loss is 0.10920674353837967\n",
      "07/27/2023 17:57:15 - INFO - __main__ - Cumulative validation average loss is 1.7336020236834884\n",
      "07/27/2023 17:57:15 - INFO - __main__ - Per validation step average loss is 0.35708945989608765\n",
      "07/27/2023 17:57:15 - INFO - __main__ - Cumulative validation average loss is 2.090691483579576\n",
      "07/27/2023 17:57:16 - INFO - __main__ - Per validation step average loss is 0.7180279493331909\n",
      "07/27/2023 17:57:16 - INFO - __main__ - Cumulative validation average loss is 2.808719432912767\n",
      "07/27/2023 17:57:16 - INFO - __main__ - Per validation step average loss is 0.3619265556335449\n",
      "07/27/2023 17:57:16 - INFO - __main__ - Cumulative validation average loss is 3.170645988546312\n",
      "07/27/2023 17:57:17 - INFO - __main__ - Per validation step average loss is 0.8150122761726379\n",
      "07/27/2023 17:57:17 - INFO - __main__ - Cumulative validation average loss is 3.98565826471895\n",
      "07/27/2023 17:57:17 - INFO - __main__ - Per validation step average loss is 0.2615862190723419\n",
      "07/27/2023 17:57:17 - INFO - __main__ - Cumulative validation average loss is 4.247244483791292\n",
      "07/27/2023 17:57:17 - INFO - __main__ - Per validation step average loss is 0.013272601179778576\n",
      "07/27/2023 17:57:17 - INFO - __main__ - Cumulative validation average loss is 4.26051708497107\n",
      "07/27/2023 17:57:18 - INFO - __main__ - Per validation step average loss is 0.026650909334421158\n",
      "07/27/2023 17:57:18 - INFO - __main__ - Cumulative validation average loss is 4.2871679943054914\n",
      "07/27/2023 17:57:18 - INFO - __main__ - Per validation step average loss is 0.25733911991119385\n",
      "07/27/2023 17:57:18 - INFO - __main__ - Cumulative validation average loss is 4.544507114216685\n",
      "07/27/2023 17:57:19 - INFO - __main__ - Per validation step average loss is 0.2555694878101349\n",
      "07/27/2023 17:57:19 - INFO - __main__ - Cumulative validation average loss is 4.80007660202682\n",
      "07/27/2023 17:57:19 - INFO - __main__ - Per validation step average loss is 0.36603063344955444\n",
      "07/27/2023 17:57:19 - INFO - __main__ - Cumulative validation average loss is 5.166107235476375\n",
      "07/27/2023 17:57:19 - INFO - __main__ - Per validation step average loss is 0.2713932991027832\n",
      "07/27/2023 17:57:19 - INFO - __main__ - Cumulative validation average loss is 5.437500534579158\n",
      "07/27/2023 17:57:20 - INFO - __main__ - Per validation step average loss is 0.05464984476566315\n",
      "07/27/2023 17:57:20 - INFO - __main__ - Cumulative validation average loss is 5.492150379344821\n",
      "07/27/2023 17:57:20 - INFO - __main__ - Per validation step average loss is 0.002744734287261963\n",
      "07/27/2023 17:57:20 - INFO - __main__ - Cumulative validation average loss is 5.494895113632083\n",
      "07/27/2023 17:57:21 - INFO - __main__ - Per validation step average loss is 0.039862941950559616\n",
      "07/27/2023 17:57:21 - INFO - __main__ - Cumulative validation average loss is 5.5347580555826426\n",
      "07/27/2023 17:57:21 - INFO - __main__ - Per validation step average loss is 0.003247735556215048\n",
      "07/27/2023 17:57:21 - INFO - __main__ - Cumulative validation average loss is 5.538005791138858\n",
      "07/27/2023 17:57:22 - INFO - __main__ - Per validation step average loss is 0.2797406315803528\n",
      "07/27/2023 17:57:22 - INFO - __main__ - Cumulative validation average loss is 5.81774642271921\n",
      "07/27/2023 17:57:22 - INFO - __main__ - Per validation step average loss is 0.05256316810846329\n",
      "07/27/2023 17:57:22 - INFO - __main__ - Cumulative validation average loss is 5.870309590827674\n",
      "07/27/2023 17:57:22 - INFO - __main__ - Per validation step average loss is 0.2500985264778137\n",
      "07/27/2023 17:57:22 - INFO - __main__ - Cumulative validation average loss is 6.120408117305487\n",
      "07/27/2023 17:57:23 - INFO - __main__ - Per validation step average loss is 0.84673011302948\n",
      "07/27/2023 17:57:23 - INFO - __main__ - Cumulative validation average loss is 6.967138230334967\n",
      "07/27/2023 17:57:23 - INFO - __main__ - Per validation step average loss is 0.015894832089543343\n",
      "07/27/2023 17:57:23 - INFO - __main__ - Cumulative validation average loss is 6.983033062424511\n",
      "07/27/2023 17:57:24 - INFO - __main__ - Per validation step average loss is 0.007106403820216656\n",
      "07/27/2023 17:57:24 - INFO - __main__ - Cumulative validation average loss is 6.990139466244727\n",
      "07/27/2023 17:57:24 - INFO - __main__ - Per validation step average loss is 0.005504028871655464\n",
      "07/27/2023 17:57:24 - INFO - __main__ - Cumulative validation average loss is 6.995643495116383\n",
      "07/27/2023 17:57:24 - INFO - __main__ - Per validation step average loss is 0.0015383579302579165\n",
      "07/27/2023 17:57:24 - INFO - __main__ - Cumulative validation average loss is 6.997181853046641\n",
      "07/27/2023 17:57:25 - INFO - __main__ - Per validation step average loss is 0.02298286370933056\n",
      "07/27/2023 17:57:25 - INFO - __main__ - Cumulative validation average loss is 7.020164716755971\n",
      "07/27/2023 17:57:25 - INFO - __main__ - Per validation step average loss is 0.04252040758728981\n",
      "07/27/2023 17:57:25 - INFO - __main__ - Cumulative validation average loss is 7.062685124343261\n",
      "07/27/2023 17:57:26 - INFO - __main__ - Per validation step average loss is 0.03246764838695526\n",
      "07/27/2023 17:57:26 - INFO - __main__ - Cumulative validation average loss is 7.095152772730216\n",
      "07/27/2023 17:57:26 - INFO - __main__ - Per validation step average loss is 0.12104155123233795\n",
      "07/27/2023 17:57:26 - INFO - __main__ - Cumulative validation average loss is 7.216194323962554\n",
      "07/27/2023 17:57:26 - INFO - __main__ - Per validation step average loss is 0.0918775200843811\n",
      "07/27/2023 17:57:26 - INFO - __main__ - Cumulative validation average loss is 7.308071844046935\n",
      "07/27/2023 17:57:27 - INFO - __main__ - Per validation step average loss is 0.02057560347020626\n",
      "07/27/2023 17:57:27 - INFO - __main__ - Cumulative validation average loss is 7.328647447517142\n",
      "07/27/2023 17:57:27 - INFO - __main__ - Per validation step average loss is 0.20441116392612457\n",
      "07/27/2023 17:57:27 - INFO - __main__ - Cumulative validation average loss is 7.533058611443266\n",
      "07/27/2023 17:57:28 - INFO - __main__ - Per validation step average loss is 0.012815983965992928\n",
      "07/27/2023 17:57:28 - INFO - __main__ - Cumulative validation average loss is 7.545874595409259\n",
      "07/27/2023 17:57:28 - INFO - __main__ - Per validation step average loss is 0.9290354251861572\n",
      "07/27/2023 17:57:28 - INFO - __main__ - Cumulative validation average loss is 8.474910020595416\n",
      "07/27/2023 17:57:28 - INFO - __main__ - Per validation step average loss is 0.05880045145750046\n",
      "07/27/2023 17:57:28 - INFO - __main__ - Cumulative validation average loss is 8.533710472052917\n",
      "07/27/2023 17:57:29 - INFO - __main__ - Per validation step average loss is 0.007937334477901459\n",
      "07/27/2023 17:57:29 - INFO - __main__ - Cumulative validation average loss is 8.541647806530818\n",
      "07/27/2023 17:57:29 - INFO - __main__ - Per validation step average loss is 0.08738027513027191\n",
      "07/27/2023 17:57:29 - INFO - __main__ - Cumulative validation average loss is 8.62902808166109\n",
      "07/27/2023 17:57:30 - INFO - __main__ - Per validation step average loss is 0.09686210751533508\n",
      "07/27/2023 17:57:30 - INFO - __main__ - Cumulative validation average loss is 8.725890189176425\n",
      "07/27/2023 17:57:30 - INFO - __main__ - Per validation step average loss is 0.18669812381267548\n",
      "07/27/2023 17:57:30 - INFO - __main__ - Cumulative validation average loss is 8.9125883129891\n",
      "07/27/2023 17:57:30 - INFO - __main__ - Per validation step average loss is 0.03755303472280502\n",
      "07/27/2023 17:57:30 - INFO - __main__ - Cumulative validation average loss is 8.950141347711906\n",
      "07/27/2023 17:57:31 - INFO - __main__ - Per validation step average loss is 0.07886206358671188\n",
      "07/27/2023 17:57:31 - INFO - __main__ - Cumulative validation average loss is 9.029003411298618\n",
      "07/27/2023 17:57:31 - INFO - __main__ - Per validation step average loss is 0.2514856457710266\n",
      "07/27/2023 17:57:31 - INFO - __main__ - Cumulative validation average loss is 9.280489057069644\n",
      "07/27/2023 17:57:32 - INFO - __main__ - Per validation step average loss is 0.07192331552505493\n",
      "07/27/2023 17:57:32 - INFO - __main__ - Cumulative validation average loss is 9.3524123725947\n",
      "07/27/2023 17:57:32 - INFO - __main__ - Per validation step average loss is 0.008944700472056866\n",
      "07/27/2023 17:57:32 - INFO - __main__ - Cumulative validation average loss is 9.361357073066756\n",
      "07/27/2023 17:57:33 - INFO - __main__ - Per validation step average loss is 0.20903268456459045\n",
      "07/27/2023 17:57:33 - INFO - __main__ - Cumulative validation average loss is 9.570389757631347\n",
      "07/27/2023 17:57:33 - INFO - __main__ - Per validation step average loss is 0.02724698930978775\n",
      "07/27/2023 17:57:33 - INFO - __main__ - Cumulative validation average loss is 9.597636746941134\n",
      "07/27/2023 17:57:33 - INFO - __main__ - Per validation step average loss is 0.22252565622329712\n",
      "07/27/2023 17:57:33 - INFO - __main__ - Cumulative validation average loss is 9.820162403164431\n",
      "07/27/2023 17:57:34 - INFO - __main__ - Per validation step average loss is 0.25573843717575073\n",
      "07/27/2023 17:57:34 - INFO - __main__ - Cumulative validation average loss is 10.075900840340182\n",
      "07/27/2023 17:57:34 - INFO - __main__ - Per validation step average loss is 0.012693142518401146\n",
      "07/27/2023 17:57:34 - INFO - __main__ - Cumulative validation average loss is 10.088593982858583\n",
      "07/27/2023 17:57:35 - INFO - __main__ - Per validation step average loss is 0.021011408418416977\n",
      "07/27/2023 17:57:35 - INFO - __main__ - Cumulative validation average loss is 10.109605391277\n",
      "07/27/2023 17:57:35 - INFO - __main__ - Per validation step average loss is 0.38170135021209717\n",
      "07/27/2023 17:57:35 - INFO - __main__ - Cumulative validation average loss is 10.491306741489097\n",
      "07/27/2023 17:57:35 - INFO - __main__ - Per validation step average loss is 0.08613726496696472\n",
      "07/27/2023 17:57:35 - INFO - __main__ - Cumulative validation average loss is 10.577444006456062\n",
      "07/27/2023 17:57:36 - INFO - __main__ - Per validation step average loss is 0.017268169671297073\n",
      "07/27/2023 17:57:36 - INFO - __main__ - Cumulative validation average loss is 10.59471217612736\n",
      "07/27/2023 17:57:36 - INFO - __main__ - Per validation step average loss is 0.006961863022297621\n",
      "07/27/2023 17:57:36 - INFO - __main__ - Cumulative validation average loss is 10.601674039149657\n",
      "07/27/2023 17:57:37 - INFO - __main__ - Per validation step average loss is 0.0276283361017704\n",
      "07/27/2023 17:57:37 - INFO - __main__ - Cumulative validation average loss is 10.629302375251427\n",
      "07/27/2023 17:57:37 - INFO - __main__ - Per validation step average loss is 0.3417068421840668\n",
      "07/27/2023 17:57:37 - INFO - __main__ - Cumulative validation average loss is 10.971009217435494\n",
      "07/27/2023 17:57:37 - INFO - __main__ - Per validation step average loss is 0.00194087706040591\n",
      "07/27/2023 17:57:37 - INFO - __main__ - Cumulative validation average loss is 10.9729500944959\n",
      "07/27/2023 17:57:38 - INFO - __main__ - Per validation step average loss is 0.05181458592414856\n",
      "07/27/2023 17:57:38 - INFO - __main__ - Cumulative validation average loss is 11.024764680420049\n",
      "07/27/2023 17:57:38 - INFO - __main__ - Per validation step average loss is 0.04891738295555115\n",
      "07/27/2023 17:57:38 - INFO - __main__ - Cumulative validation average loss is 11.0736820633756\n",
      "07/27/2023 17:57:39 - INFO - __main__ - Per validation step average loss is 0.05287972465157509\n",
      "07/27/2023 17:57:39 - INFO - __main__ - Cumulative validation average loss is 11.126561788027175\n",
      "07/27/2023 17:57:39 - INFO - __main__ - Per validation step average loss is 0.08751539140939713\n",
      "07/27/2023 17:57:39 - INFO - __main__ - Cumulative validation average loss is 11.214077179436572\n",
      "07/27/2023 17:57:40 - INFO - __main__ - Per validation step average loss is 0.0992104634642601\n",
      "07/27/2023 17:57:40 - INFO - __main__ - Cumulative validation average loss is 11.313287642900832\n",
      "07/27/2023 17:57:40 - INFO - __main__ - Per validation step average loss is 0.15272393822669983\n",
      "07/27/2023 17:57:40 - INFO - __main__ - Cumulative validation average loss is 11.466011581127532\n",
      "07/27/2023 17:57:40 - INFO - __main__ - Per validation step average loss is 0.637173056602478\n",
      "07/27/2023 17:57:40 - INFO - __main__ - Cumulative validation average loss is 12.10318463773001\n",
      "07/27/2023 17:57:41 - INFO - __main__ - Per validation step average loss is 0.0048706079833209515\n",
      "07/27/2023 17:57:41 - INFO - __main__ - Cumulative validation average loss is 12.10805524571333\n",
      "07/27/2023 17:57:41 - INFO - __main__ - Average validation loss for Epoch 4 is 0.1532665220976371\n",
      "07/27/2023 17:57:41 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 17:58:38 - INFO - __main__ - Starting epoch 5\n",
      "07/27/2023 17:58:39 - INFO - __main__ - train loss is 0.06219017505645752\n",
      "Steps:  10%| | 1516/15000 [13:49<102:46:59, 27.44s/it, lr=0.000188, step_loss=0.07/27/2023 17:58:39 - INFO - __main__ - train loss is 0.21418416500091553\n",
      "Steps:  10%| | 1517/15000 [13:49<72:09:35, 19.27s/it, lr=0.000188, step_loss=0.107/27/2023 17:58:39 - INFO - __main__ - train loss is 0.3433420956134796\n",
      "Steps:  10%| | 1518/15000 [13:49<50:43:21, 13.54s/it, lr=0.000188, step_loss=0.107/27/2023 17:58:39 - INFO - __main__ - train loss is 0.7847850620746613\n",
      "Steps:  10%| | 1519/15000 [13:50<35:42:28,  9.54s/it, lr=0.000189, step_loss=0.407/27/2023 17:58:39 - INFO - __main__ - train loss is 0.8285659104585648\n",
      "Steps:  10%| | 1520/15000 [13:50<25:11:46,  6.73s/it, lr=0.000189, step_loss=0.007/27/2023 17:58:40 - INFO - __main__ - train loss is 1.2733686417341232\n",
      "Steps:  10%| | 1521/15000 [13:50<17:50:24,  4.76s/it, lr=0.000189, step_loss=0.407/27/2023 17:58:40 - INFO - __main__ - train loss is 1.430118814110756\n",
      "Steps:  10%| | 1522/15000 [13:50<12:41:37,  3.39s/it, lr=0.000189, step_loss=0.107/27/2023 17:58:40 - INFO - __main__ - train loss is 1.650021731853485\n",
      "Steps:  10%| | 1523/15000 [13:50<9:05:11,  2.43s/it, lr=0.000189, step_loss=0.2207/27/2023 17:58:40 - INFO - __main__ - train loss is 1.8904830515384674\n",
      "Steps:  10%| | 1524/15000 [13:50<6:33:45,  1.75s/it, lr=0.000189, step_loss=0.2407/27/2023 17:58:40 - INFO - __main__ - train loss is 1.9951856136322021\n",
      "Steps:  10%| | 1525/15000 [13:51<4:47:43,  1.28s/it, lr=0.000189, step_loss=0.1007/27/2023 17:58:41 - INFO - __main__ - train loss is 2.05220066010952\n",
      "Steps:  10%| | 1526/15000 [13:51<3:33:31,  1.05it/s, lr=0.000189, step_loss=0.0507/27/2023 17:58:41 - INFO - __main__ - train loss is 2.311415269970894\n",
      "Steps:  10%| | 1527/15000 [13:51<2:41:28,  1.39it/s, lr=0.000189, step_loss=0.2507/27/2023 17:58:41 - INFO - __main__ - train loss is 2.486166015267372\n",
      "Steps:  10%| | 1528/15000 [13:51<2:05:01,  1.80it/s, lr=0.00019, step_loss=0.17507/27/2023 17:58:41 - INFO - __main__ - train loss is 2.638121798634529\n",
      "Steps:  10%| | 1529/15000 [13:51<1:39:32,  2.26it/s, lr=0.00019, step_loss=0.15207/27/2023 17:58:41 - INFO - __main__ - train loss is 2.7664458602666855\n",
      "Steps:  10%| | 1530/15000 [13:52<1:21:47,  2.74it/s, lr=0.00019, step_loss=0.12807/27/2023 17:58:41 - INFO - __main__ - train loss is 3.343439981341362\n",
      "Steps:  10%| | 1531/15000 [13:52<1:09:17,  3.24it/s, lr=0.00019, step_loss=0.57707/27/2023 17:58:42 - INFO - __main__ - train loss is 3.3740614615380764\n",
      "Steps:  10%| | 1532/15000 [13:52<1:00:35,  3.70it/s, lr=0.00019, step_loss=0.03007/27/2023 17:58:42 - INFO - __main__ - train loss is 3.4191770777106285\n",
      "Steps:  10%| | 1533/15000 [13:52<54:30,  4.12it/s, lr=0.00019, step_loss=0.0451]07/27/2023 17:58:42 - INFO - __main__ - train loss is 3.4296607449650764\n",
      "Steps:  10%| | 1534/15000 [13:52<50:21,  4.46it/s, lr=0.00019, step_loss=0.0105]07/27/2023 17:58:42 - INFO - __main__ - train loss is 3.4421103969216347\n",
      "Steps:  10%| | 1535/15000 [13:52<47:19,  4.74it/s, lr=0.00019, step_loss=0.0124]07/27/2023 17:58:42 - INFO - __main__ - train loss is 3.6314953342080116\n",
      "Steps:  10%| | 1536/15000 [13:53<45:15,  4.96it/s, lr=0.000191, step_loss=0.189]07/27/2023 17:58:43 - INFO - __main__ - train loss is 3.7921356931328773\n",
      "Steps:  10%| | 1537/15000 [13:53<43:46,  5.12it/s, lr=0.000191, step_loss=0.161]07/27/2023 17:58:43 - INFO - __main__ - train loss is 3.799929562024772\n",
      "Steps:  10%| | 1538/15000 [13:53<42:47,  5.24it/s, lr=0.000191, step_loss=0.007707/27/2023 17:58:43 - INFO - __main__ - train loss is 4.295574965886772\n",
      "Steps:  10%| | 1539/15000 [13:53<42:02,  5.34it/s, lr=0.000191, step_loss=0.496]07/27/2023 17:58:43 - INFO - __main__ - train loss is 4.393372598104179\n",
      "Steps:  10%| | 1540/15000 [13:53<41:33,  5.40it/s, lr=0.000191, step_loss=0.097807/27/2023 17:58:43 - INFO - __main__ - train loss is 4.745209905318916\n",
      "Steps:  10%| | 1541/15000 [13:54<41:13,  5.44it/s, lr=0.000191, step_loss=0.352]07/27/2023 17:58:43 - INFO - __main__ - train loss is 4.78668976854533\n",
      "Steps:  10%| | 1542/15000 [13:54<41:03,  5.46it/s, lr=0.000191, step_loss=0.041507/27/2023 17:58:44 - INFO - __main__ - train loss is 4.789560114732012\n",
      "Steps:  10%| | 1543/15000 [13:54<40:50,  5.49it/s, lr=0.000192, step_loss=0.002807/27/2023 17:58:44 - INFO - __main__ - train loss is 5.308101689210162\n",
      "Steps:  10%| | 1544/15000 [13:54<41:00,  5.47it/s, lr=0.000192, step_loss=0.519]07/27/2023 17:58:44 - INFO - __main__ - train loss is 5.348030296852812\n",
      "Steps:  10%| | 1545/15000 [13:54<40:50,  5.49it/s, lr=0.000192, step_loss=0.039907/27/2023 17:58:44 - INFO - __main__ - train loss is 5.351636670064181\n",
      "Steps:  10%| | 1546/15000 [13:54<41:12,  5.44it/s, lr=0.000192, step_loss=0.003607/27/2023 17:58:44 - INFO - __main__ - train loss is 5.353284932207316\n",
      "Steps:  10%| | 1547/15000 [13:55<41:18,  5.43it/s, lr=0.000192, step_loss=0.001607/27/2023 17:58:44 - INFO - __main__ - train loss is 5.82113430602476\n",
      "Steps:  10%| | 1548/15000 [13:55<41:00,  5.47it/s, lr=0.000192, step_loss=0.468]07/27/2023 17:58:45 - INFO - __main__ - train loss is 5.871031924616545\n",
      "Steps:  10%| | 1549/15000 [13:55<40:47,  5.50it/s, lr=0.000192, step_loss=0.049907/27/2023 17:58:45 - INFO - __main__ - train loss is 6.162210538517684\n",
      "Steps:  10%| | 1550/15000 [13:55<40:44,  5.50it/s, lr=0.000192, step_loss=0.291]07/27/2023 17:58:45 - INFO - __main__ - train loss is 6.276908114086837\n",
      "Steps:  10%| | 1551/15000 [13:55<40:40,  5.51it/s, lr=0.000193, step_loss=0.115]07/27/2023 17:58:45 - INFO - __main__ - train loss is 6.469315394293517\n",
      "Steps:  10%| | 1552/15000 [13:56<40:52,  5.48it/s, lr=0.000193, step_loss=0.192]07/27/2023 17:58:45 - INFO - __main__ - train loss is 6.472439609467983\n",
      "Steps:  10%| | 1553/15000 [13:56<40:41,  5.51it/s, lr=0.000193, step_loss=0.003107/27/2023 17:58:46 - INFO - __main__ - train loss is 6.63239573687315\n",
      "Steps:  10%|▏ | 1554/15000 [13:56<41:04,  5.46it/s, lr=0.000193, step_loss=0.16]07/27/2023 17:58:46 - INFO - __main__ - train loss is 6.74732319265604\n",
      "Steps:  10%| | 1555/15000 [13:56<41:19,  5.42it/s, lr=0.000193, step_loss=0.115]07/27/2023 17:58:46 - INFO - __main__ - train loss is 6.750354235293344\n",
      "Steps:  10%| | 1556/15000 [13:56<41:01,  5.46it/s, lr=0.000193, step_loss=0.003007/27/2023 17:58:46 - INFO - __main__ - train loss is 6.774942823918536\n",
      "Steps:  10%| | 1557/15000 [13:56<40:48,  5.49it/s, lr=0.000193, step_loss=0.024607/27/2023 17:58:46 - INFO - __main__ - train loss is 6.820661274017766\n",
      "Steps:  10%| | 1558/15000 [13:57<40:38,  5.51it/s, lr=0.000193, step_loss=0.045707/27/2023 17:58:47 - INFO - __main__ - train loss is 6.8221997120417655\n",
      "Steps:  10%| | 1559/15000 [13:57<40:32,  5.52it/s, lr=0.000194, step_loss=0.001507/27/2023 17:58:47 - INFO - __main__ - train loss is 6.854626948479563\n",
      "Steps:  10%| | 1560/15000 [13:57<40:55,  5.47it/s, lr=0.000194, step_loss=0.032407/27/2023 17:58:47 - INFO - __main__ - train loss is 6.8644950543530285\n",
      "Steps:  10%| | 1561/15000 [13:57<40:58,  5.47it/s, lr=0.000194, step_loss=0.009807/27/2023 17:58:47 - INFO - __main__ - train loss is 6.867351334076375\n",
      "Steps:  10%| | 1562/15000 [13:57<40:45,  5.50it/s, lr=0.000194, step_loss=0.002807/27/2023 17:58:47 - INFO - __main__ - train loss is 7.0527880298905075\n",
      "Steps:  10%| | 1563/15000 [13:58<40:53,  5.48it/s, lr=0.000194, step_loss=0.185]07/27/2023 17:58:47 - INFO - __main__ - train loss is 7.230495463591069\n",
      "Steps:  10%| | 1564/15000 [13:58<40:42,  5.50it/s, lr=0.000194, step_loss=0.178]07/27/2023 17:58:48 - INFO - __main__ - train loss is 7.282465289812535\n",
      "Steps:  10%| | 1565/15000 [13:58<40:58,  5.47it/s, lr=0.000194, step_loss=0.052]07/27/2023 17:58:48 - INFO - __main__ - train loss is 7.340056541841477\n",
      "Steps:  10%| | 1566/15000 [13:58<46:08,  4.85it/s, lr=0.000194, step_loss=0.057607/27/2023 17:58:48 - INFO - __main__ - train loss is 7.518039229791611\n",
      "Steps:  10%| | 1567/15000 [13:58<47:58,  4.67it/s, lr=0.000195, step_loss=0.178]07/27/2023 17:58:48 - INFO - __main__ - train loss is 7.599787596147507\n",
      "Steps:  10%| | 1568/15000 [13:59<47:10,  4.75it/s, lr=0.000195, step_loss=0.081707/27/2023 17:58:48 - INFO - __main__ - train loss is 7.642220574896783\n",
      "Steps:  10%| | 1569/15000 [13:59<46:41,  4.79it/s, lr=0.000195, step_loss=0.042407/27/2023 17:58:49 - INFO - __main__ - train loss is 7.678579229395837\n",
      "Steps:  10%| | 1570/15000 [13:59<45:30,  4.92it/s, lr=0.000195, step_loss=0.036407/27/2023 17:58:49 - INFO - __main__ - train loss is 7.80470885662362\n",
      "Steps:  10%| | 1571/15000 [13:59<45:25,  4.93it/s, lr=0.000195, step_loss=0.126]07/27/2023 17:58:49 - INFO - __main__ - train loss is 7.956999752204865\n",
      "Steps:  10%| | 1572/15000 [13:59<43:55,  5.10it/s, lr=0.000195, step_loss=0.152]07/27/2023 17:58:49 - INFO - __main__ - train loss is 8.145090762060136\n",
      "Steps:  10%| | 1573/15000 [14:00<42:51,  5.22it/s, lr=0.000195, step_loss=0.188]07/27/2023 17:58:49 - INFO - __main__ - train loss is 8.181832875590771\n",
      "Steps:  10%| | 1574/15000 [14:00<42:09,  5.31it/s, lr=0.000195, step_loss=0.036707/27/2023 17:58:50 - INFO - __main__ - train loss is 8.18481312924996\n",
      "Steps:  10%| | 1575/15000 [14:00<41:46,  5.36it/s, lr=0.000196, step_loss=0.002907/27/2023 17:58:50 - INFO - __main__ - train loss is 8.231758343521506\n",
      "Steps:  11%| | 1576/15000 [14:00<41:17,  5.42it/s, lr=0.000196, step_loss=0.046907/27/2023 17:58:50 - INFO - __main__ - train loss is 8.243701177183539\n",
      "Steps:  11%| | 1577/15000 [14:00<41:18,  5.42it/s, lr=0.000196, step_loss=0.011907/27/2023 17:58:50 - INFO - __main__ - train loss is 8.279889340046793\n",
      "Steps:  11%| | 1578/15000 [14:00<41:13,  5.43it/s, lr=0.000196, step_loss=0.036207/27/2023 17:58:50 - INFO - __main__ - train loss is 8.429136166814715\n",
      "Steps:  11%| | 1579/15000 [14:01<41:00,  5.45it/s, lr=0.000196, step_loss=0.149]07/27/2023 17:58:51 - INFO - __main__ - train loss is 8.443453299347311\n",
      "Steps:  11%| | 1580/15000 [14:01<40:46,  5.49it/s, lr=0.000196, step_loss=0.014307/27/2023 17:58:51 - INFO - __main__ - train loss is 8.606288182083517\n",
      "Steps:  11%| | 1581/15000 [14:01<40:37,  5.51it/s, lr=0.000196, step_loss=0.163]07/27/2023 17:58:51 - INFO - __main__ - train loss is 8.631888140458614\n",
      "Steps:  11%| | 1582/15000 [14:01<40:35,  5.51it/s, lr=0.000196, step_loss=0.025607/27/2023 17:58:51 - INFO - __main__ - train loss is 8.815814692992717\n",
      "Steps:  11%| | 1583/15000 [14:01<40:34,  5.51it/s, lr=0.000197, step_loss=0.184]07/27/2023 17:58:51 - INFO - __main__ - train loss is 9.010362137574703\n",
      "Steps:  11%| | 1584/15000 [14:02<40:51,  5.47it/s, lr=0.000197, step_loss=0.195]07/27/2023 17:58:51 - INFO - __main__ - train loss is 9.12596480967477\n",
      "Steps:  11%| | 1585/15000 [14:02<40:43,  5.49it/s, lr=0.000197, step_loss=0.116]07/27/2023 17:58:52 - INFO - __main__ - train loss is 9.265083987731487\n",
      "Steps:  11%| | 1586/15000 [14:02<40:39,  5.50it/s, lr=0.000197, step_loss=0.139]07/27/2023 17:58:52 - INFO - __main__ - train loss is 9.3126688641496\n",
      "Steps:  11%| | 1587/15000 [14:02<40:55,  5.46it/s, lr=0.000197, step_loss=0.047607/27/2023 17:58:52 - INFO - __main__ - train loss is 9.53087003948167\n",
      "Steps:  11%| | 1588/15000 [14:02<40:55,  5.46it/s, lr=0.000197, step_loss=0.218]07/27/2023 17:58:52 - INFO - __main__ - train loss is 9.620840792078525\n",
      "Steps:  11%|▏ | 1589/15000 [14:02<40:42,  5.49it/s, lr=0.000197, step_loss=0.09]07/27/2023 17:58:52 - INFO - __main__ - train loss is 9.915687684435397\n",
      "Steps:  11%| | 1590/15000 [14:03<40:56,  5.46it/s, lr=0.000197, step_loss=0.295]07/27/2023 17:58:53 - INFO - __main__ - train loss is 9.974337243009359\n",
      "Steps:  11%| | 1591/15000 [14:03<40:41,  5.49it/s, lr=0.000198, step_loss=0.058607/27/2023 17:58:53 - INFO - __main__ - train loss is 10.082337640691549\n",
      "Steps:  11%| | 1592/15000 [14:03<40:30,  5.52it/s, lr=0.000198, step_loss=0.108]07/27/2023 17:58:53 - INFO - __main__ - train loss is 10.157595523167402\n",
      "Steps:  11%| | 1593/15000 [14:03<40:23,  5.53it/s, lr=0.000198, step_loss=0.075307/27/2023 17:58:53 - INFO - __main__ - train loss is 10.244408756960183\n",
      "Steps:  11%| | 1594/15000 [14:03<40:25,  5.53it/s, lr=0.000198, step_loss=0.086807/27/2023 17:58:53 - INFO - __main__ - train loss is 10.333201230037957\n",
      "Steps:  11%| | 1595/15000 [14:04<40:20,  5.54it/s, lr=0.000198, step_loss=0.088807/27/2023 17:58:53 - INFO - __main__ - train loss is 10.461231738794595\n",
      "Steps:  11%| | 1596/15000 [14:04<40:40,  5.49it/s, lr=0.000198, step_loss=0.128]07/27/2023 17:58:54 - INFO - __main__ - train loss is 10.464440679177642\n",
      "Steps:  11%| | 1597/15000 [14:04<40:38,  5.50it/s, lr=0.000198, step_loss=0.003207/27/2023 17:58:54 - INFO - __main__ - train loss is 10.465741146239452\n",
      "Steps:  11%| | 1598/15000 [14:04<40:53,  5.46it/s, lr=0.000198, step_loss=0.001307/27/2023 17:58:54 - INFO - __main__ - train loss is 10.472878758679144\n",
      "Steps:  11%| | 1599/15000 [14:04<41:16,  5.41it/s, lr=0.000199, step_loss=0.007107/27/2023 17:58:54 - INFO - __main__ - train loss is 11.045309428940527\n",
      "Steps:  11%| | 1600/15000 [14:04<41:05,  5.44it/s, lr=0.000199, step_loss=0.572]07/27/2023 17:58:54 - INFO - __main__ - train loss is 11.159856323967688\n",
      "Steps:  11%| | 1601/15000 [14:05<40:59,  5.45it/s, lr=0.000199, step_loss=0.115]07/27/2023 17:58:55 - INFO - __main__ - train loss is 11.35680145479273\n",
      "Steps:  11%| | 1602/15000 [14:05<41:17,  5.41it/s, lr=0.000199, step_loss=0.197]07/27/2023 17:58:55 - INFO - __main__ - train loss is 11.410934247891419\n",
      "Steps:  11%| | 1603/15000 [14:05<41:26,  5.39it/s, lr=0.000199, step_loss=0.054107/27/2023 17:58:55 - INFO - __main__ - train loss is 11.421846031094901\n",
      "Steps:  11%| | 1604/15000 [14:05<41:12,  5.42it/s, lr=0.000199, step_loss=0.010907/27/2023 17:58:55 - INFO - __main__ - train loss is 11.789719848777167\n",
      "Steps:  11%| | 1605/15000 [14:05<41:02,  5.44it/s, lr=0.000199, step_loss=0.368]07/27/2023 17:58:55 - INFO - __main__ - train loss is 11.810686989570968\n",
      "Steps:  11%| | 1606/15000 [14:06<40:56,  5.45it/s, lr=0.000199, step_loss=0.021]07/27/2023 17:58:55 - INFO - __main__ - train loss is 12.601425870205276\n",
      "Steps:  11%|▎  | 1607/15000 [14:06<40:59,  5.45it/s, lr=0.0002, step_loss=0.791]07/27/2023 17:58:56 - INFO - __main__ - train loss is 13.048614128376357\n",
      "Steps:  11%|▎  | 1608/15000 [14:06<40:58,  5.45it/s, lr=0.0002, step_loss=0.447]07/27/2023 17:58:56 - INFO - __main__ - train loss is 13.050586435361765\n",
      "Steps:  11%| | 1609/15000 [14:06<40:55,  5.45it/s, lr=0.0002, step_loss=0.00197]07/27/2023 17:58:56 - INFO - __main__ - train loss is 13.243281084462069\n",
      "Steps:  11%|▎  | 1610/15000 [14:06<40:55,  5.45it/s, lr=0.0002, step_loss=0.193]07/27/2023 17:58:56 - INFO - __main__ - train loss is 13.326740163727663\n",
      "Steps:  11%|▏ | 1611/15000 [14:07<40:54,  5.46it/s, lr=0.0002, step_loss=0.0835]07/27/2023 17:58:56 - INFO - __main__ - train loss is 13.795741218491457\n",
      "Steps:  11%|▎  | 1612/15000 [14:07<41:12,  5.42it/s, lr=0.0002, step_loss=0.469]07/27/2023 17:58:57 - INFO - __main__ - train loss is 14.234729010029696\n",
      "Steps:  11%|▎  | 1613/15000 [14:07<41:06,  5.43it/s, lr=0.0002, step_loss=0.439]07/27/2023 17:58:57 - INFO - __main__ - train loss is 14.236161204404198\n",
      "Steps:  11%| | 1614/15000 [14:07<40:59,  5.44it/s, lr=0.0002, step_loss=0.00143]07/27/2023 17:58:57 - INFO - __main__ - train loss is 14.244951131171547\n",
      "Steps:  11%| | 1615/15000 [14:07<40:53,  5.46it/s, lr=0.000201, step_loss=0.008707/27/2023 17:58:57 - INFO - __main__ - train loss is 14.326033803052269\n",
      "Steps:  11%| | 1616/15000 [14:07<40:49,  5.46it/s, lr=0.000201, step_loss=0.081107/27/2023 17:58:57 - INFO - __main__ - train loss is 14.426587405032478\n",
      "Steps:  11%| | 1617/15000 [14:08<41:08,  5.42it/s, lr=0.000201, step_loss=0.101]07/27/2023 17:58:57 - INFO - __main__ - train loss is 14.674346404499374\n",
      "Steps:  11%| | 1618/15000 [14:08<40:51,  5.46it/s, lr=0.000201, step_loss=0.248]07/27/2023 17:58:58 - INFO - __main__ - train loss is 14.69588894431945\n",
      "Steps:  11%| | 1619/15000 [14:08<40:37,  5.49it/s, lr=0.000201, step_loss=0.021507/27/2023 17:58:58 - INFO - __main__ - train loss is 14.698746909270994\n",
      "Steps:  11%| | 1620/15000 [14:08<40:53,  5.45it/s, lr=0.000201, step_loss=0.002807/27/2023 17:58:58 - INFO - __main__ - train loss is 14.853747625718825\n",
      "Steps:  11%| | 1621/15000 [14:08<40:49,  5.46it/s, lr=0.000201, step_loss=0.155]07/27/2023 17:58:58 - INFO - __main__ - train loss is 15.196233381400816\n",
      "Steps:  11%| | 1622/15000 [14:09<40:44,  5.47it/s, lr=0.000201, step_loss=0.342]07/27/2023 17:58:58 - INFO - __main__ - train loss is 15.227282957057469\n",
      "Steps:  11%| | 1623/15000 [14:09<40:56,  5.44it/s, lr=0.000202, step_loss=0.031]07/27/2023 17:58:59 - INFO - __main__ - train loss is 15.36438030085992\n",
      "Steps:  11%| | 1624/15000 [14:09<41:02,  5.43it/s, lr=0.000202, step_loss=0.137]07/27/2023 17:58:59 - INFO - __main__ - train loss is 15.645751089672558\n",
      "Steps:  11%| | 1625/15000 [14:09<41:02,  5.43it/s, lr=0.000202, step_loss=0.281]07/27/2023 17:58:59 - INFO - __main__ - train loss is 15.900089175323956\n",
      "Steps:  11%| | 1626/15000 [14:09<40:54,  5.45it/s, lr=0.000202, step_loss=0.254]07/27/2023 17:58:59 - INFO - __main__ - train loss is 15.902629049844109\n",
      "Steps:  11%| | 1627/15000 [14:09<40:52,  5.45it/s, lr=0.000202, step_loss=0.002507/27/2023 17:58:59 - INFO - __main__ - train loss is 16.012449482805096\n",
      "Steps:  11%|▏ | 1628/15000 [14:10<40:48,  5.46it/s, lr=0.000202, step_loss=0.11]07/27/2023 17:58:59 - INFO - __main__ - train loss is 16.015074153547175\n",
      "Steps:  11%| | 1629/15000 [14:10<40:46,  5.47it/s, lr=0.000202, step_loss=0.002607/27/2023 17:59:00 - INFO - __main__ - train loss is 16.05569067329634\n",
      "Steps:  11%| | 1630/15000 [14:10<40:42,  5.47it/s, lr=0.000202, step_loss=0.040607/27/2023 17:59:00 - INFO - __main__ - train loss is 16.177211743895896\n",
      "Steps:  11%| | 1631/15000 [14:10<40:51,  5.45it/s, lr=0.000203, step_loss=0.122]07/27/2023 17:59:00 - INFO - __main__ - train loss is 16.257564981584437\n",
      "Steps:  11%| | 1632/15000 [14:10<40:45,  5.47it/s, lr=0.000203, step_loss=0.080407/27/2023 17:59:00 - INFO - __main__ - train loss is 16.346680139307864\n",
      "Steps:  11%| | 1633/15000 [14:11<40:41,  5.47it/s, lr=0.000203, step_loss=0.089107/27/2023 17:59:00 - INFO - __main__ - train loss is 16.35623728588689\n",
      "Steps:  11%| | 1634/15000 [14:11<40:52,  5.45it/s, lr=0.000203, step_loss=0.009507/27/2023 17:59:01 - INFO - __main__ - train loss is 16.37331700057257\n",
      "Steps:  11%| | 1635/15000 [14:11<40:49,  5.46it/s, lr=0.000203, step_loss=0.017107/27/2023 17:59:01 - INFO - __main__ - train loss is 16.49869458109606\n",
      "Steps:  11%| | 1636/15000 [14:11<40:46,  5.46it/s, lr=0.000203, step_loss=0.125]07/27/2023 17:59:01 - INFO - __main__ - train loss is 16.963738960330375\n",
      "Steps:  11%| | 1637/15000 [14:11<41:07,  5.42it/s, lr=0.000203, step_loss=0.465]07/27/2023 17:59:01 - INFO - __main__ - train loss is 17.094353926484473\n",
      "Steps:  11%| | 1638/15000 [14:11<40:58,  5.44it/s, lr=0.000203, step_loss=0.131]07/27/2023 17:59:01 - INFO - __main__ - train loss is 17.217911985819228\n",
      "Steps:  11%| | 1639/15000 [14:12<41:00,  5.43it/s, lr=0.000203, step_loss=0.124]07/27/2023 17:59:02 - INFO - __main__ - train loss is 17.58082145184744\n",
      "Steps:  11%| | 1640/15000 [14:12<40:42,  5.47it/s, lr=0.000204, step_loss=0.363]07/27/2023 17:59:02 - INFO - __main__ - train loss is 17.593428339925595\n",
      "Steps:  11%| | 1641/15000 [14:12<40:29,  5.50it/s, lr=0.000204, step_loss=0.012607/27/2023 17:59:02 - INFO - __main__ - train loss is 17.59548254206311\n",
      "Steps:  11%| | 1642/15000 [14:12<40:36,  5.48it/s, lr=0.000204, step_loss=0.002007/27/2023 17:59:02 - INFO - __main__ - train loss is 17.606333273346536\n",
      "Steps:  11%| | 1643/15000 [14:12<40:25,  5.51it/s, lr=0.000204, step_loss=0.010907/27/2023 17:59:02 - INFO - __main__ - train loss is 17.654158647055738\n",
      "Steps:  11%| | 1644/15000 [14:13<40:41,  5.47it/s, lr=0.000204, step_loss=0.047807/27/2023 17:59:02 - INFO - __main__ - train loss is 17.691670182044618\n",
      "Steps:  11%| | 1645/15000 [14:13<40:41,  5.47it/s, lr=0.000204, step_loss=0.037507/27/2023 17:59:03 - INFO - __main__ - train loss is 17.699487303267233\n",
      "Steps:  11%| | 1646/15000 [14:13<40:28,  5.50it/s, lr=0.000204, step_loss=0.007807/27/2023 17:59:03 - INFO - __main__ - train loss is 17.7255177058978\n",
      "Steps:  11%| | 1647/15000 [14:13<40:20,  5.52it/s, lr=0.000204, step_loss=0.026]07/27/2023 17:59:03 - INFO - __main__ - train loss is 17.953374371747486\n",
      "Steps:  11%| | 1648/15000 [14:13<40:13,  5.53it/s, lr=0.000205, step_loss=0.228]07/27/2023 17:59:03 - INFO - __main__ - train loss is 17.9575267637847\n",
      "Steps:  11%| | 1649/15000 [14:13<40:14,  5.53it/s, lr=0.000205, step_loss=0.004107/27/2023 17:59:03 - INFO - __main__ - train loss is 18.008941164123826\n",
      "Steps:  11%| | 1650/15000 [14:14<40:07,  5.54it/s, lr=0.000205, step_loss=0.051407/27/2023 17:59:04 - INFO - __main__ - train loss is 18.070897938567214\n",
      "Steps:  11%| | 1651/15000 [14:14<40:05,  5.55it/s, lr=0.000205, step_loss=0.062]07/27/2023 17:59:04 - INFO - __main__ - train loss is 18.592604281264357\n",
      "Steps:  11%| | 1652/15000 [14:14<40:33,  5.49it/s, lr=0.000205, step_loss=0.522]07/27/2023 17:59:04 - INFO - __main__ - train loss is 18.711330341058783\n",
      "Steps:  11%| | 1653/15000 [14:14<40:32,  5.49it/s, lr=0.000205, step_loss=0.119]07/27/2023 17:59:04 - INFO - __main__ - train loss is 18.715399435604922\n",
      "Steps:  11%| | 1654/15000 [14:14<40:23,  5.51it/s, lr=0.000205, step_loss=0.004007/27/2023 17:59:04 - INFO - __main__ - train loss is 19.00578584417235\n",
      "Steps:  11%|▏ | 1655/15000 [14:15<40:35,  5.48it/s, lr=0.000205, step_loss=0.29]07/27/2023 17:59:04 - INFO - __main__ - train loss is 19.0132236283971\n",
      "Steps:  11%| | 1656/15000 [14:15<40:29,  5.49it/s, lr=0.000206, step_loss=0.007407/27/2023 17:59:05 - INFO - __main__ - train loss is 19.075333933229558\n",
      "Steps:  11%| | 1657/15000 [14:15<40:37,  5.47it/s, lr=0.000206, step_loss=0.062107/27/2023 17:59:05 - INFO - __main__ - train loss is 19.077097288449295\n",
      "Steps:  11%| | 1658/15000 [14:15<40:48,  5.45it/s, lr=0.000206, step_loss=0.001707/27/2023 17:59:05 - INFO - __main__ - train loss is 19.103283277829178\n",
      "Steps:  11%| | 1659/15000 [14:15<41:09,  5.40it/s, lr=0.000206, step_loss=0.026207/27/2023 17:59:05 - INFO - __main__ - train loss is 19.15657325007487\n",
      "Steps:  11%| | 1660/15000 [14:15<41:10,  5.40it/s, lr=0.000206, step_loss=0.053307/27/2023 17:59:05 - INFO - __main__ - train loss is 19.65887583710719\n",
      "Steps:  11%| | 1661/15000 [14:16<40:49,  5.45it/s, lr=0.000206, step_loss=0.502]07/27/2023 17:59:06 - INFO - __main__ - train loss is 19.90927775122691\n",
      "Steps:  11%|▏ | 1662/15000 [14:16<40:32,  5.48it/s, lr=0.000206, step_loss=0.25]07/27/2023 17:59:06 - INFO - __main__ - train loss is 19.94395410933066\n",
      "Steps:  11%| | 1663/15000 [14:16<40:30,  5.49it/s, lr=0.000207, step_loss=0.034707/27/2023 17:59:06 - INFO - __main__ - train loss is 20.010115995188244\n",
      "Steps:  11%| | 1664/15000 [14:16<40:18,  5.51it/s, lr=0.000207, step_loss=0.066207/27/2023 17:59:06 - INFO - __main__ - train loss is 20.238620563526638\n",
      "Steps:  11%| | 1665/15000 [14:16<40:11,  5.53it/s, lr=0.000207, step_loss=0.229]07/27/2023 17:59:06 - INFO - __main__ - train loss is 20.33578506775666\n",
      "Steps:  11%| | 1666/15000 [14:17<40:25,  5.50it/s, lr=0.000207, step_loss=0.097207/27/2023 17:59:06 - INFO - __main__ - train loss is 20.3763693041401\n",
      "Steps:  11%| | 1667/15000 [14:17<40:17,  5.52it/s, lr=0.000207, step_loss=0.040607/27/2023 17:59:07 - INFO - __main__ - train loss is 20.392384453793056\n",
      "Steps:  11%| | 1668/15000 [14:17<40:09,  5.53it/s, lr=0.000207, step_loss=0.016]07/27/2023 17:59:07 - INFO - __main__ - train loss is 20.569283886929043\n",
      "Steps:  11%| | 1669/15000 [14:17<40:04,  5.54it/s, lr=0.000207, step_loss=0.177]07/27/2023 17:59:07 - INFO - __main__ - train loss is 20.677305682678707\n",
      "Steps:  11%| | 1670/15000 [14:17<40:11,  5.53it/s, lr=0.000207, step_loss=0.108]07/27/2023 17:59:07 - INFO - __main__ - train loss is 20.717372286249883\n",
      "Steps:  11%| | 1671/15000 [14:17<40:06,  5.54it/s, lr=0.000208, step_loss=0.040107/27/2023 17:59:07 - INFO - __main__ - train loss is 20.71969479357358\n",
      "Steps:  11%| | 1672/15000 [14:18<40:03,  5.55it/s, lr=0.000208, step_loss=0.002307/27/2023 17:59:08 - INFO - __main__ - train loss is 20.732248669839464\n",
      "Steps:  11%| | 1673/15000 [14:18<40:04,  5.54it/s, lr=0.000208, step_loss=0.012607/27/2023 17:59:08 - INFO - __main__ - train loss is 20.736071668216027\n",
      "Steps:  11%| | 1674/15000 [14:18<40:00,  5.55it/s, lr=0.000208, step_loss=0.003807/27/2023 17:59:08 - INFO - __main__ - train loss is 21.486516140052117\n",
      "Steps:  11%|▏ | 1675/15000 [14:18<39:58,  5.56it/s, lr=0.000208, step_loss=0.75]07/27/2023 17:59:08 - INFO - __main__ - train loss is 21.605324007221498\n",
      "Steps:  11%| | 1676/15000 [14:18<40:19,  5.51it/s, lr=0.000208, step_loss=0.119]07/27/2023 17:59:08 - INFO - __main__ - train loss is 21.61276891513262\n",
      "Steps:  11%| | 1677/15000 [14:19<40:12,  5.52it/s, lr=0.000208, step_loss=0.007407/27/2023 17:59:08 - INFO - __main__ - train loss is 21.81306633038912\n",
      "Steps:  11%|▎  | 1678/15000 [14:19<40:06,  5.54it/s, lr=0.000208, step_loss=0.2]07/27/2023 17:59:09 - INFO - __main__ - train loss is 21.903741930262186\n",
      "Steps:  11%| | 1679/15000 [14:19<40:03,  5.54it/s, lr=0.000208, step_loss=0.090707/27/2023 17:59:09 - INFO - __main__ - train loss is 21.909406406455673\n",
      "Steps:  11%| | 1680/15000 [14:19<40:08,  5.53it/s, lr=0.000209, step_loss=0.005607/27/2023 17:59:09 - INFO - __main__ - train loss is 21.91560652910266\n",
      "Steps:  11%| | 1681/15000 [14:19<40:03,  5.54it/s, lr=0.000209, step_loss=0.006207/27/2023 17:59:09 - INFO - __main__ - train loss is 21.919230075902306\n",
      "Steps:  11%| | 1682/15000 [14:19<40:00,  5.55it/s, lr=0.000209, step_loss=0.003607/27/2023 17:59:09 - INFO - __main__ - train loss is 21.92583074362483\n",
      "Steps:  11%| | 1683/15000 [14:20<40:19,  5.50it/s, lr=0.000209, step_loss=0.006607/27/2023 17:59:10 - INFO - __main__ - train loss is 21.928541021305136\n",
      "Steps:  11%| | 1684/15000 [14:20<40:12,  5.52it/s, lr=0.000209, step_loss=0.002707/27/2023 17:59:10 - INFO - __main__ - train loss is 21.986673148232512\n",
      "Steps:  11%| | 1685/15000 [14:20<40:06,  5.53it/s, lr=0.000209, step_loss=0.058107/27/2023 17:59:10 - INFO - __main__ - train loss is 22.068161750095896\n",
      "Steps:  11%| | 1686/15000 [14:20<40:02,  5.54it/s, lr=0.000209, step_loss=0.081507/27/2023 17:59:10 - INFO - __main__ - train loss is 22.22720068122726\n",
      "Steps:  11%| | 1687/15000 [14:20<40:00,  5.55it/s, lr=0.000209, step_loss=0.159]07/27/2023 17:59:10 - INFO - __main__ - train loss is 22.229050013120286\n",
      "Steps:  11%| | 1688/15000 [14:21<39:56,  5.55it/s, lr=0.00021, step_loss=0.0018507/27/2023 17:59:10 - INFO - __main__ - train loss is 22.608391377027147\n",
      "Steps:  11%|▏ | 1689/15000 [14:21<39:54,  5.56it/s, lr=0.00021, step_loss=0.379]07/27/2023 17:59:11 - INFO - __main__ - train loss is 22.830073269899003\n",
      "Steps:  11%|▏ | 1690/15000 [14:21<40:00,  5.55it/s, lr=0.00021, step_loss=0.222]07/27/2023 17:59:11 - INFO - __main__ - train loss is 22.83127132768277\n",
      "Steps:  11%| | 1691/15000 [14:21<39:57,  5.55it/s, lr=0.00021, step_loss=0.0012]07/27/2023 17:59:11 - INFO - __main__ - train loss is 22.94222075457219\n",
      "Steps:  11%|▏ | 1692/15000 [14:21<39:55,  5.56it/s, lr=0.00021, step_loss=0.111]07/27/2023 17:59:11 - INFO - __main__ - train loss is 23.28736270184163\n",
      "Steps:  11%|▏ | 1693/15000 [14:21<39:54,  5.56it/s, lr=0.00021, step_loss=0.345]07/27/2023 17:59:11 - INFO - __main__ - train loss is 23.298449480556883\n",
      "Steps:  11%| | 1694/15000 [14:22<40:05,  5.53it/s, lr=0.00021, step_loss=0.0111]07/27/2023 17:59:11 - INFO - __main__ - train loss is 23.590074682259\n",
      "Steps:  11%|▏ | 1695/15000 [14:22<39:59,  5.54it/s, lr=0.00021, step_loss=0.292]07/27/2023 17:59:12 - INFO - __main__ - train loss is 23.73659911158029\n",
      "Steps:  11%| | 1696/15000 [14:22<39:56,  5.55it/s, lr=0.000211, step_loss=0.147]07/27/2023 17:59:12 - INFO - __main__ - train loss is 23.744420478702523\n",
      "Steps:  11%| | 1697/15000 [14:22<40:09,  5.52it/s, lr=0.000211, step_loss=0.007807/27/2023 17:59:12 - INFO - __main__ - train loss is 24.120322922826745\n",
      "Steps:  11%| | 1698/15000 [14:22<40:02,  5.54it/s, lr=0.000211, step_loss=0.376]07/27/2023 17:59:12 - INFO - __main__ - train loss is 24.17574043071363\n",
      "Steps:  11%| | 1699/15000 [14:23<39:59,  5.54it/s, lr=0.000211, step_loss=0.055407/27/2023 17:59:12 - INFO - __main__ - train loss is 24.187910574139096\n",
      "Steps:  11%| | 1700/15000 [14:23<39:56,  5.55it/s, lr=0.000211, step_loss=0.012207/27/2023 17:59:13 - INFO - __main__ - train loss is 24.209662395180203\n",
      "Steps:  11%| | 1701/15000 [14:23<40:11,  5.51it/s, lr=0.000211, step_loss=0.021807/27/2023 17:59:13 - INFO - __main__ - train loss is 24.40370287245605\n",
      "Steps:  11%| | 1702/15000 [14:23<40:04,  5.53it/s, lr=0.000211, step_loss=0.194]07/27/2023 17:59:13 - INFO - __main__ - train loss is 24.64450837916229\n",
      "Steps:  11%| | 1703/15000 [14:23<39:59,  5.54it/s, lr=0.000211, step_loss=0.241]07/27/2023 17:59:13 - INFO - __main__ - train loss is 24.721409740508534\n",
      "Steps:  11%| | 1704/15000 [14:23<40:03,  5.53it/s, lr=0.000212, step_loss=0.076907/27/2023 17:59:13 - INFO - __main__ - train loss is 24.72426353453193\n",
      "Steps:  11%| | 1705/15000 [14:24<39:58,  5.54it/s, lr=0.000212, step_loss=0.002807/27/2023 17:59:13 - INFO - __main__ - train loss is 24.865711525664665\n",
      "Steps:  11%| | 1706/15000 [14:24<39:55,  5.55it/s, lr=0.000212, step_loss=0.141]07/27/2023 17:59:14 - INFO - __main__ - train loss is 24.91937536804471\n",
      "Steps:  11%| | 1707/15000 [14:24<39:53,  5.55it/s, lr=0.000212, step_loss=0.053707/27/2023 17:59:14 - INFO - __main__ - train loss is 24.9367141952971\n",
      "Steps:  11%| | 1708/15000 [14:24<39:51,  5.56it/s, lr=0.000212, step_loss=0.017307/27/2023 17:59:14 - INFO - __main__ - train loss is 24.994107023463584\n",
      "Steps:  11%| | 1709/15000 [14:24<39:49,  5.56it/s, lr=0.000212, step_loss=0.057407/27/2023 17:59:14 - INFO - __main__ - train loss is 25.013807438896038\n",
      "Steps:  11%| | 1710/15000 [14:24<39:50,  5.56it/s, lr=0.000212, step_loss=0.019707/27/2023 17:59:14 - INFO - __main__ - train loss is 25.019060856313445\n",
      "Steps:  11%| | 1711/15000 [14:25<39:55,  5.55it/s, lr=0.000212, step_loss=0.005207/27/2023 17:59:15 - INFO - __main__ - train loss is 25.064128785044886\n",
      "Steps:  11%| | 1712/15000 [14:25<39:53,  5.55it/s, lr=0.000213, step_loss=0.045107/27/2023 17:59:15 - INFO - __main__ - train loss is 25.0889254497597\n",
      "Steps:  11%| | 1713/15000 [14:25<39:52,  5.55it/s, lr=0.000213, step_loss=0.024807/27/2023 17:59:15 - INFO - __main__ - train loss is 25.096408924204297\n",
      "Steps:  11%| | 1714/15000 [14:25<39:50,  5.56it/s, lr=0.000213, step_loss=0.007407/27/2023 17:59:15 - INFO - __main__ - train loss is 25.098377812770195\n",
      "Steps:  11%| | 1715/15000 [14:25<39:50,  5.56it/s, lr=0.000213, step_loss=0.001907/27/2023 17:59:15 - INFO - __main__ - train loss is 25.107827069354244\n",
      "Steps:  11%| | 1716/15000 [14:26<39:50,  5.56it/s, lr=0.000213, step_loss=0.009407/27/2023 17:59:15 - INFO - __main__ - train loss is 25.111314296838827\n",
      "Steps:  11%| | 1717/15000 [14:26<39:50,  5.56it/s, lr=0.000213, step_loss=0.003407/27/2023 17:59:16 - INFO - __main__ - train loss is 25.13978980493266\n",
      "Steps:  11%| | 1718/15000 [14:26<39:54,  5.55it/s, lr=0.000213, step_loss=0.028507/27/2023 17:59:16 - INFO - __main__ - train loss is 25.2547587902518\n",
      "Steps:  11%| | 1719/15000 [14:26<39:51,  5.55it/s, lr=0.000214, step_loss=0.115]07/27/2023 17:59:16 - INFO - __main__ - train loss is 25.3241481409641\n",
      "Steps:  11%| | 1720/15000 [14:26<39:50,  5.56it/s, lr=0.000214, step_loss=0.069407/27/2023 17:59:16 - INFO - __main__ - train loss is 25.641094289836474\n",
      "Steps:  11%| | 1721/15000 [14:26<40:04,  5.52it/s, lr=0.000214, step_loss=0.317]07/27/2023 17:59:16 - INFO - __main__ - train loss is 25.655841944855638\n",
      "Steps:  11%| | 1722/15000 [14:27<40:04,  5.52it/s, lr=0.000214, step_loss=0.014707/27/2023 17:59:17 - INFO - __main__ - train loss is 25.773507451754995\n",
      "Steps:  11%| | 1723/15000 [14:27<39:59,  5.53it/s, lr=0.000214, step_loss=0.118]07/27/2023 17:59:17 - INFO - __main__ - train loss is 26.13772562716622\n",
      "Steps:  11%| | 1724/15000 [14:27<39:55,  5.54it/s, lr=0.000214, step_loss=0.364]07/27/2023 17:59:17 - INFO - __main__ - train loss is 26.52362397883553\n",
      "Steps:  12%| | 1725/15000 [14:27<40:02,  5.53it/s, lr=0.000214, step_loss=0.386]07/27/2023 17:59:17 - INFO - __main__ - train loss is 26.70489000354428\n",
      "Steps:  12%| | 1726/15000 [14:27<39:54,  5.54it/s, lr=0.000214, step_loss=0.181]07/27/2023 17:59:17 - INFO - __main__ - train loss is 26.72552887548227\n",
      "Steps:  12%| | 1727/15000 [14:28<39:51,  5.55it/s, lr=0.000215, step_loss=0.020607/27/2023 17:59:17 - INFO - __main__ - train loss is 26.87615705479402\n",
      "Steps:  12%| | 1728/15000 [14:28<40:07,  5.51it/s, lr=0.000215, step_loss=0.151]07/27/2023 17:59:18 - INFO - __main__ - train loss is 26.89334791910369\n",
      "Steps:  12%| | 1729/15000 [14:28<40:02,  5.52it/s, lr=0.000215, step_loss=0.017207/27/2023 17:59:18 - INFO - __main__ - train loss is 27.128871172782965\n",
      "Steps:  12%| | 1730/15000 [14:28<39:55,  5.54it/s, lr=0.000215, step_loss=0.236]07/27/2023 17:59:18 - INFO - __main__ - train loss is 27.171342365560122\n",
      "Steps:  12%| | 1731/15000 [14:28<39:52,  5.55it/s, lr=0.000215, step_loss=0.042507/27/2023 17:59:18 - INFO - __main__ - train loss is 27.20766776811797\n",
      "Steps:  12%| | 1732/15000 [14:28<40:01,  5.52it/s, lr=0.000215, step_loss=0.036307/27/2023 17:59:18 - INFO - __main__ - train loss is 27.303041696664877\n",
      "Steps:  12%| | 1733/15000 [14:29<39:55,  5.54it/s, lr=0.000215, step_loss=0.095407/27/2023 17:59:19 - INFO - __main__ - train loss is 27.357565648970194\n",
      "Steps:  12%| | 1734/15000 [14:29<39:50,  5.55it/s, lr=0.000215, step_loss=0.054507/27/2023 17:59:19 - INFO - __main__ - train loss is 27.370704373461194\n",
      "Steps:  12%| | 1735/15000 [14:29<39:56,  5.54it/s, lr=0.000216, step_loss=0.013107/27/2023 17:59:19 - INFO - __main__ - train loss is 27.40535217721481\n",
      "Steps:  12%| | 1736/15000 [14:29<39:52,  5.54it/s, lr=0.000216, step_loss=0.034607/27/2023 17:59:19 - INFO - __main__ - train loss is 27.411680692923255\n",
      "Steps:  12%| | 1737/15000 [14:29<39:52,  5.54it/s, lr=0.000216, step_loss=0.006307/27/2023 17:59:19 - INFO - __main__ - train loss is 27.419145163730718\n",
      "Steps:  12%| | 1738/15000 [14:30<39:48,  5.55it/s, lr=0.000216, step_loss=0.007407/27/2023 17:59:19 - INFO - __main__ - train loss is 27.425028700497933\n",
      "Steps:  12%| | 1739/15000 [14:30<39:46,  5.56it/s, lr=0.000216, step_loss=0.005807/27/2023 17:59:20 - INFO - __main__ - train loss is 27.428895197925158\n",
      "Steps:  12%| | 1740/15000 [14:30<39:42,  5.56it/s, lr=0.000216, step_loss=0.003807/27/2023 17:59:20 - INFO - __main__ - train loss is 27.645600907620974\n",
      "Steps:  12%| | 1741/15000 [14:30<39:50,  5.55it/s, lr=0.000216, step_loss=0.217]07/27/2023 17:59:20 - INFO - __main__ - train loss is 27.649137882632203\n",
      "Steps:  12%| | 1742/15000 [14:30<40:22,  5.47it/s, lr=0.000216, step_loss=0.003507/27/2023 17:59:20 - INFO - __main__ - train loss is 27.65091330104042\n",
      "Steps:  12%| | 1743/15000 [14:30<40:17,  5.48it/s, lr=0.000217, step_loss=0.001707/27/2023 17:59:20 - INFO - __main__ - train loss is 27.70482382841874\n",
      "Steps:  12%| | 1744/15000 [14:31<40:06,  5.51it/s, lr=0.000217, step_loss=0.053907/27/2023 17:59:21 - INFO - __main__ - train loss is 27.71699279092718\n",
      "Steps:  12%| | 1745/15000 [14:31<39:58,  5.53it/s, lr=0.000217, step_loss=0.012207/27/2023 17:59:21 - INFO - __main__ - train loss is 28.219228322734125\n",
      "Steps:  12%| | 1746/15000 [14:31<40:03,  5.51it/s, lr=0.000217, step_loss=0.502]07/27/2023 17:59:21 - INFO - __main__ - train loss is 28.30343654297758\n",
      "Steps:  12%| | 1747/15000 [14:31<39:59,  5.52it/s, lr=0.000217, step_loss=0.084207/27/2023 17:59:21 - INFO - __main__ - train loss is 28.328607323695906\n",
      "Steps:  12%| | 1748/15000 [14:31<39:56,  5.53it/s, lr=0.000217, step_loss=0.025207/27/2023 17:59:21 - INFO - __main__ - train loss is 28.331921673496254\n",
      "Steps:  12%| | 1749/15000 [14:32<40:17,  5.48it/s, lr=0.000217, step_loss=0.003307/27/2023 17:59:21 - INFO - __main__ - train loss is 28.353530629654415\n",
      "Steps:  12%| | 1750/15000 [14:32<40:08,  5.50it/s, lr=0.000217, step_loss=0.021607/27/2023 17:59:22 - INFO - __main__ - train loss is 28.668153508682735\n",
      "Steps:  12%| | 1751/15000 [14:32<40:23,  5.47it/s, lr=0.000218, step_loss=0.315]07/27/2023 17:59:22 - INFO - __main__ - train loss is 28.970904871006496\n",
      "Steps:  12%| | 1752/15000 [14:32<40:09,  5.50it/s, lr=0.000218, step_loss=0.303]07/27/2023 17:59:22 - INFO - __main__ - train loss is 28.98907496884931\n",
      "Steps:  12%| | 1753/15000 [14:32<40:03,  5.51it/s, lr=0.000218, step_loss=0.018207/27/2023 17:59:22 - INFO - __main__ - train loss is 28.99307441257406\n",
      "Steps:  12%| | 1754/15000 [14:32<39:55,  5.53it/s, lr=0.000218, step_loss=0.004]07/27/2023 17:59:22 - INFO - __main__ - train loss is 29.229158814181574\n",
      "Steps:  12%| | 1755/15000 [14:33<39:49,  5.54it/s, lr=0.000218, step_loss=0.236]07/27/2023 17:59:23 - INFO - __main__ - train loss is 29.230636648484506\n",
      "Steps:  12%| | 1756/15000 [14:33<39:51,  5.54it/s, lr=0.000218, step_loss=0.001407/27/2023 17:59:23 - INFO - __main__ - train loss is 29.23553060425911\n",
      "Steps:  12%| | 1757/15000 [14:33<39:59,  5.52it/s, lr=0.000218, step_loss=0.004807/27/2023 17:59:23 - INFO - __main__ - train loss is 29.333424781099893\n",
      "Steps:  12%| | 1758/15000 [14:33<39:51,  5.54it/s, lr=0.000218, step_loss=0.097907/27/2023 17:59:23 - INFO - __main__ - train loss is 29.56613132788334\n",
      "Steps:  12%| | 1759/15000 [14:33<39:47,  5.55it/s, lr=0.000218, step_loss=0.233]07/27/2023 17:59:23 - INFO - __main__ - train loss is 29.774603400961496\n",
      "Steps:  12%| | 1760/15000 [14:34<39:49,  5.54it/s, lr=0.000219, step_loss=0.208]07/27/2023 17:59:23 - INFO - __main__ - train loss is 29.776306343381293\n",
      "Steps:  12%| | 1761/15000 [14:34<39:46,  5.55it/s, lr=0.000219, step_loss=0.001707/27/2023 17:59:24 - INFO - __main__ - train loss is 29.879279193584807\n",
      "Steps:  12%| | 1762/15000 [14:34<39:41,  5.56it/s, lr=0.000219, step_loss=0.103]07/27/2023 17:59:24 - INFO - __main__ - train loss is 30.68105977505911\n",
      "Steps:  12%| | 1763/15000 [14:34<39:49,  5.54it/s, lr=0.000219, step_loss=0.802]07/27/2023 17:59:24 - INFO - __main__ - train loss is 30.697480031405576\n",
      "Steps:  12%| | 1764/15000 [14:34<39:51,  5.53it/s, lr=0.000219, step_loss=0.016407/27/2023 17:59:24 - INFO - __main__ - train loss is 30.700691675418057\n",
      "Steps:  12%| | 1765/15000 [14:34<40:12,  5.49it/s, lr=0.000219, step_loss=0.003207/27/2023 17:59:24 - INFO - __main__ - train loss is 30.703665918088518\n",
      "Steps:  12%| | 1766/15000 [14:35<40:46,  5.41it/s, lr=0.000219, step_loss=0.002907/27/2023 17:59:25 - INFO - __main__ - train loss is 30.86290589568671\n",
      "Steps:  12%| | 1767/15000 [14:35<40:53,  5.39it/s, lr=0.000219, step_loss=0.159]07/27/2023 17:59:25 - INFO - __main__ - train loss is 30.864674238488078\n",
      "Steps:  12%| | 1768/15000 [14:35<40:32,  5.44it/s, lr=0.00022, step_loss=0.0017707/27/2023 17:59:25 - INFO - __main__ - train loss is 30.881930703297257\n",
      "Steps:  12%| | 1769/15000 [14:35<40:16,  5.47it/s, lr=0.00022, step_loss=0.0173]07/27/2023 17:59:25 - INFO - __main__ - train loss is 30.96389319933951\n",
      "Steps:  12%|▏ | 1770/15000 [14:35<40:32,  5.44it/s, lr=0.00022, step_loss=0.082]07/27/2023 17:59:25 - INFO - __main__ - train loss is 31.063982347026467\n",
      "Steps:  12%|▍   | 1771/15000 [14:36<40:39,  5.42it/s, lr=0.00022, step_loss=0.1]07/27/2023 17:59:25 - INFO - __main__ - train loss is 31.157216960564256\n",
      "Steps:  12%| | 1772/15000 [14:36<40:23,  5.46it/s, lr=0.00022, step_loss=0.0932]07/27/2023 17:59:26 - INFO - __main__ - train loss is 31.447056824341416\n",
      "Steps:  12%|▎  | 1773/15000 [14:36<40:14,  5.48it/s, lr=0.00022, step_loss=0.29]07/27/2023 17:59:26 - INFO - __main__ - train loss is 31.716786975041032\n",
      "Steps:  12%|▎  | 1774/15000 [14:36<40:21,  5.46it/s, lr=0.00022, step_loss=0.27]07/27/2023 17:59:26 - INFO - __main__ - train loss is 31.736840119585395\n",
      "Steps:  12%| | 1775/15000 [14:36<40:38,  5.42it/s, lr=0.00022, step_loss=0.0201]07/27/2023 17:59:26 - INFO - __main__ - train loss is 31.786664789542556\n",
      "Steps:  12%| | 1776/15000 [14:36<40:25,  5.45it/s, lr=0.000221, step_loss=0.049807/27/2023 17:59:26 - INFO - __main__ - train loss is 32.00835592113435\n",
      "Steps:  12%| | 1777/15000 [14:37<40:19,  5.47it/s, lr=0.000221, step_loss=0.222]07/27/2023 17:59:27 - INFO - __main__ - train loss is 32.186540907248855\n",
      "Steps:  12%| | 1778/15000 [14:37<40:06,  5.49it/s, lr=0.000221, step_loss=0.178]07/27/2023 17:59:27 - INFO - __main__ - train loss is 32.49436936341226\n",
      "Steps:  12%| | 1779/15000 [14:37<39:58,  5.51it/s, lr=0.000221, step_loss=0.308]07/27/2023 17:59:27 - INFO - __main__ - train loss is 32.61833761446178\n",
      "Steps:  12%| | 1780/15000 [14:37<39:51,  5.53it/s, lr=0.000221, step_loss=0.124]07/27/2023 17:59:27 - INFO - __main__ - train loss is 32.95600546710193\n",
      "Steps:  12%| | 1781/15000 [14:37<39:50,  5.53it/s, lr=0.000221, step_loss=0.338]07/27/2023 17:59:27 - INFO - __main__ - train loss is 33.08702473156154\n",
      "Steps:  12%| | 1782/15000 [14:38<39:46,  5.54it/s, lr=0.000221, step_loss=0.131]07/27/2023 17:59:27 - INFO - __main__ - train loss is 33.091173622291535\n",
      "Steps:  12%| | 1783/15000 [14:38<39:53,  5.52it/s, lr=0.000222, step_loss=0.004107/27/2023 17:59:28 - INFO - __main__ - train loss is 33.09270005649887\n",
      "Steps:  12%| | 1784/15000 [14:38<40:10,  5.48it/s, lr=0.000222, step_loss=0.001507/27/2023 17:59:28 - INFO - __main__ - train loss is 33.09615864674561\n",
      "Steps:  12%| | 1785/15000 [14:38<40:01,  5.50it/s, lr=0.000222, step_loss=0.003407/27/2023 17:59:28 - INFO - __main__ - train loss is 33.23241383652203\n",
      "Steps:  12%| | 1786/15000 [14:38<39:52,  5.52it/s, lr=0.000222, step_loss=0.136]07/27/2023 17:59:28 - INFO - __main__ - train loss is 33.25714246626012\n",
      "Steps:  12%| | 1787/15000 [14:38<39:49,  5.53it/s, lr=0.000222, step_loss=0.024707/27/2023 17:59:28 - INFO - __main__ - train loss is 33.27733372221701\n",
      "Steps:  12%| | 1788/15000 [14:39<39:46,  5.54it/s, lr=0.000222, step_loss=0.020207/27/2023 17:59:29 - INFO - __main__ - train loss is 33.28028368088417\n",
      "Steps:  12%| | 1789/15000 [14:39<39:42,  5.55it/s, lr=0.000222, step_loss=0.002907/27/2023 17:59:29 - INFO - __main__ - train loss is 33.28432462899946\n",
      "Steps:  12%| | 1790/15000 [14:39<39:42,  5.55it/s, lr=0.000222, step_loss=0.004007/27/2023 17:59:29 - INFO - __main__ - train loss is 33.330885184695944\n",
      "Steps:  12%| | 1791/15000 [14:39<40:02,  5.50it/s, lr=0.000223, step_loss=0.046607/27/2023 17:59:29 - INFO - __main__ - train loss is 33.70598710863851\n",
      "Steps:  12%| | 1792/15000 [14:39<39:54,  5.52it/s, lr=0.000223, step_loss=0.375]07/27/2023 17:59:29 - INFO - __main__ - train loss is 33.86224606423639\n",
      "Steps:  12%| | 1793/15000 [14:40<39:57,  5.51it/s, lr=0.000223, step_loss=0.156]07/27/2023 17:59:29 - INFO - __main__ - train loss is 33.90971285640262\n",
      "Steps:  12%| | 1794/15000 [14:40<39:50,  5.53it/s, lr=0.000223, step_loss=0.047507/27/2023 17:59:30 - INFO - __main__ - train loss is 33.9989517533686\n",
      "Steps:  12%| | 1795/15000 [14:40<39:56,  5.51it/s, lr=0.000223, step_loss=0.089207/27/2023 17:59:30 - INFO - __main__ - train loss is 34.11230052052997\n",
      "Steps:  12%| | 1796/15000 [14:40<39:50,  5.52it/s, lr=0.000223, step_loss=0.113]07/27/2023 17:59:30 - INFO - __main__ - train loss is 34.33291386603378\n",
      "Steps:  12%| | 1797/15000 [14:40<39:46,  5.53it/s, lr=0.000223, step_loss=0.221]07/27/2023 17:59:30 - INFO - __main__ - train loss is 34.46855788468383\n",
      "Steps:  12%| | 1798/15000 [14:40<39:50,  5.52it/s, lr=0.000223, step_loss=0.136]07/27/2023 17:59:30 - INFO - __main__ - train loss is 34.473025950370356\n",
      "Steps:  12%| | 1799/15000 [14:41<39:46,  5.53it/s, lr=0.000224, step_loss=0.004407/27/2023 17:59:30 - INFO - __main__ - train loss is 34.80621540802531\n",
      "Steps:  12%| | 1800/15000 [14:41<39:41,  5.54it/s, lr=0.000224, step_loss=0.333]07/27/2023 17:59:31 - INFO - __main__ - train loss is 34.816235412610695\n",
      "Steps:  12%|▏ | 1801/15000 [14:41<39:39,  5.55it/s, lr=0.000224, step_loss=0.01]07/27/2023 17:59:31 - INFO - __main__ - train loss is 35.03956246818416\n",
      "Steps:  12%| | 1802/15000 [14:41<39:37,  5.55it/s, lr=0.000224, step_loss=0.223]07/27/2023 17:59:31 - INFO - __main__ - train loss is 35.27610792662017\n",
      "Steps:  12%| | 1803/15000 [14:41<39:33,  5.56it/s, lr=0.000224, step_loss=0.237]07/27/2023 17:59:31 - INFO - __main__ - train loss is 35.608538527740166\n",
      "Steps:  12%| | 1804/15000 [14:42<39:35,  5.56it/s, lr=0.000224, step_loss=0.332]07/27/2023 17:59:31 - INFO - __main__ - train loss is 35.98408528114669\n",
      "Steps:  12%| | 1805/15000 [14:42<39:42,  5.54it/s, lr=0.000224, step_loss=0.376]07/27/2023 17:59:32 - INFO - __main__ - train loss is 36.228235934628174\n",
      "Steps:  12%| | 1806/15000 [14:42<39:36,  5.55it/s, lr=0.000224, step_loss=0.244]07/27/2023 17:59:32 - INFO - __main__ - train loss is 36.23455219599418\n",
      "Steps:  12%| | 1807/15000 [14:42<39:50,  5.52it/s, lr=0.000225, step_loss=0.006307/27/2023 17:59:32 - INFO - __main__ - train loss is 36.45247726771049\n",
      "Steps:  12%| | 1808/15000 [14:42<40:07,  5.48it/s, lr=0.000225, step_loss=0.218]07/27/2023 17:59:32 - INFO - __main__ - train loss is 36.58027016255073\n",
      "Steps:  12%| | 1809/15000 [14:42<40:28,  5.43it/s, lr=0.000225, step_loss=0.128]07/27/2023 17:59:32 - INFO - __main__ - train loss is 36.652289426652715\n",
      "Steps:  12%| | 1810/15000 [14:43<40:34,  5.42it/s, lr=0.000225, step_loss=0.072]07/27/2023 17:59:33 - INFO - __main__ - train loss is 36.65668009663932\n",
      "Steps:  12%| | 1811/15000 [14:43<40:22,  5.44it/s, lr=0.000225, step_loss=0.004307/27/2023 17:59:33 - INFO - __main__ - train loss is 37.21753035928123\n",
      "Steps:  12%| | 1812/15000 [14:43<40:10,  5.47it/s, lr=0.000225, step_loss=0.561]07/27/2023 17:59:33 - INFO - __main__ - train loss is 37.221769236261025\n",
      "Steps:  12%| | 1813/15000 [14:43<40:05,  5.48it/s, lr=0.000225, step_loss=0.004207/27/2023 17:59:33 - INFO - __main__ - train loss is 37.30994149320759\n",
      "Steps:  12%| | 1814/15000 [14:43<39:52,  5.51it/s, lr=0.000225, step_loss=0.088207/27/2023 17:59:33 - INFO - __main__ - train loss is 37.39763276302256\n",
      "Steps:  12%| | 1815/15000 [14:44<39:52,  5.51it/s, lr=0.000226, step_loss=0.087707/27/2023 17:59:33 - INFO - __main__ - train loss is 37.40618255571462\n",
      "Steps:  12%| | 1816/15000 [14:44<39:43,  5.53it/s, lr=0.000226, step_loss=0.008507/27/2023 17:59:34 - INFO - __main__ - train loss is 37.500488771358505\n",
      "Steps:  12%| | 1817/15000 [14:44<39:37,  5.55it/s, lr=0.000226, step_loss=0.094307/27/2023 17:59:34 - INFO - __main__ - train loss is 37.516828276449814\n",
      "Steps:  12%| | 1818/15000 [14:44<54:18,  4.05it/s, lr=0.000226, step_loss=0.016307/27/2023 17:59:35 - INFO - __main__ - Per validation step average loss is 0.00891464576125145\n",
      "07/27/2023 17:59:35 - INFO - __main__ - Cumulative validation average loss is 0.00891464576125145\n",
      "07/27/2023 17:59:35 - INFO - __main__ - Per validation step average loss is 0.028822071850299835\n",
      "07/27/2023 17:59:35 - INFO - __main__ - Cumulative validation average loss is 0.037736717611551285\n",
      "07/27/2023 17:59:36 - INFO - __main__ - Per validation step average loss is 0.1379636824131012\n",
      "07/27/2023 17:59:36 - INFO - __main__ - Cumulative validation average loss is 0.17570040002465248\n",
      "07/27/2023 17:59:36 - INFO - __main__ - Per validation step average loss is 0.0029882986564189196\n",
      "07/27/2023 17:59:36 - INFO - __main__ - Cumulative validation average loss is 0.1786886986810714\n",
      "07/27/2023 17:59:37 - INFO - __main__ - Per validation step average loss is 0.19065481424331665\n",
      "07/27/2023 17:59:37 - INFO - __main__ - Cumulative validation average loss is 0.36934351292438805\n",
      "07/27/2023 17:59:37 - INFO - __main__ - Per validation step average loss is 0.0018067595083266497\n",
      "07/27/2023 17:59:37 - INFO - __main__ - Cumulative validation average loss is 0.3711502724327147\n",
      "07/27/2023 17:59:37 - INFO - __main__ - Per validation step average loss is 0.007953647524118423\n",
      "07/27/2023 17:59:37 - INFO - __main__ - Cumulative validation average loss is 0.3791039199568331\n",
      "07/27/2023 17:59:38 - INFO - __main__ - Per validation step average loss is 0.017942268401384354\n",
      "07/27/2023 17:59:38 - INFO - __main__ - Cumulative validation average loss is 0.3970461883582175\n",
      "07/27/2023 17:59:38 - INFO - __main__ - Per validation step average loss is 0.6615912914276123\n",
      "07/27/2023 17:59:38 - INFO - __main__ - Cumulative validation average loss is 1.0586374797858298\n",
      "07/27/2023 17:59:39 - INFO - __main__ - Per validation step average loss is 0.32601308822631836\n",
      "07/27/2023 17:59:39 - INFO - __main__ - Cumulative validation average loss is 1.3846505680121481\n",
      "07/27/2023 17:59:39 - INFO - __main__ - Per validation step average loss is 0.19524884223937988\n",
      "07/27/2023 17:59:39 - INFO - __main__ - Cumulative validation average loss is 1.579899410251528\n",
      "07/27/2023 17:59:40 - INFO - __main__ - Per validation step average loss is 0.3273929953575134\n",
      "07/27/2023 17:59:40 - INFO - __main__ - Cumulative validation average loss is 1.9072924056090415\n",
      "07/27/2023 17:59:40 - INFO - __main__ - Per validation step average loss is 0.8402080535888672\n",
      "07/27/2023 17:59:40 - INFO - __main__ - Cumulative validation average loss is 2.7475004591979086\n",
      "07/27/2023 17:59:40 - INFO - __main__ - Per validation step average loss is 0.08208390325307846\n",
      "07/27/2023 17:59:40 - INFO - __main__ - Cumulative validation average loss is 2.829584362450987\n",
      "07/27/2023 17:59:41 - INFO - __main__ - Per validation step average loss is 0.0013162830146029592\n",
      "07/27/2023 17:59:41 - INFO - __main__ - Cumulative validation average loss is 2.83090064546559\n",
      "07/27/2023 17:59:41 - INFO - __main__ - Per validation step average loss is 0.03607309237122536\n",
      "07/27/2023 17:59:41 - INFO - __main__ - Cumulative validation average loss is 2.8669737378368154\n",
      "07/27/2023 17:59:42 - INFO - __main__ - Per validation step average loss is 0.03255091607570648\n",
      "07/27/2023 17:59:42 - INFO - __main__ - Cumulative validation average loss is 2.899524653912522\n",
      "07/27/2023 17:59:42 - INFO - __main__ - Per validation step average loss is 0.36190423369407654\n",
      "07/27/2023 17:59:42 - INFO - __main__ - Cumulative validation average loss is 3.2614288876065984\n",
      "07/27/2023 17:59:42 - INFO - __main__ - Per validation step average loss is 0.007184996269643307\n",
      "07/27/2023 17:59:42 - INFO - __main__ - Cumulative validation average loss is 3.2686138838762417\n",
      "07/27/2023 17:59:43 - INFO - __main__ - Per validation step average loss is 0.284123033285141\n",
      "07/27/2023 17:59:43 - INFO - __main__ - Cumulative validation average loss is 3.5527369171613827\n",
      "07/27/2023 17:59:43 - INFO - __main__ - Per validation step average loss is 0.001677384483627975\n",
      "07/27/2023 17:59:43 - INFO - __main__ - Cumulative validation average loss is 3.5544143016450107\n",
      "07/27/2023 17:59:44 - INFO - __main__ - Per validation step average loss is 0.24734646081924438\n",
      "07/27/2023 17:59:44 - INFO - __main__ - Cumulative validation average loss is 3.801760762464255\n",
      "07/27/2023 17:59:44 - INFO - __main__ - Per validation step average loss is 0.15123343467712402\n",
      "07/27/2023 17:59:44 - INFO - __main__ - Cumulative validation average loss is 3.952994197141379\n",
      "07/27/2023 17:59:44 - INFO - __main__ - Per validation step average loss is 0.15680864453315735\n",
      "07/27/2023 17:59:44 - INFO - __main__ - Cumulative validation average loss is 4.1098028416745365\n",
      "07/27/2023 17:59:45 - INFO - __main__ - Per validation step average loss is 0.07626647502183914\n",
      "07/27/2023 17:59:45 - INFO - __main__ - Cumulative validation average loss is 4.186069316696376\n",
      "07/27/2023 17:59:45 - INFO - __main__ - Per validation step average loss is 0.35180172324180603\n",
      "07/27/2023 17:59:45 - INFO - __main__ - Cumulative validation average loss is 4.537871039938182\n",
      "07/27/2023 17:59:46 - INFO - __main__ - Per validation step average loss is 0.08882258832454681\n",
      "07/27/2023 17:59:46 - INFO - __main__ - Cumulative validation average loss is 4.6266936282627285\n",
      "07/27/2023 17:59:46 - INFO - __main__ - Per validation step average loss is 0.014778059907257557\n",
      "07/27/2023 17:59:46 - INFO - __main__ - Cumulative validation average loss is 4.641471688169986\n",
      "07/27/2023 17:59:46 - INFO - __main__ - Per validation step average loss is 0.06885850429534912\n",
      "07/27/2023 17:59:46 - INFO - __main__ - Cumulative validation average loss is 4.710330192465335\n",
      "07/27/2023 17:59:47 - INFO - __main__ - Per validation step average loss is 0.11821364611387253\n",
      "07/27/2023 17:59:47 - INFO - __main__ - Cumulative validation average loss is 4.828543838579208\n",
      "07/27/2023 17:59:47 - INFO - __main__ - Per validation step average loss is 0.08585833013057709\n",
      "07/27/2023 17:59:47 - INFO - __main__ - Cumulative validation average loss is 4.914402168709785\n",
      "07/27/2023 17:59:48 - INFO - __main__ - Per validation step average loss is 0.0608377531170845\n",
      "07/27/2023 17:59:48 - INFO - __main__ - Cumulative validation average loss is 4.975239921826869\n",
      "07/27/2023 17:59:48 - INFO - __main__ - Per validation step average loss is 0.3265402317047119\n",
      "07/27/2023 17:59:48 - INFO - __main__ - Cumulative validation average loss is 5.301780153531581\n",
      "07/27/2023 17:59:49 - INFO - __main__ - Per validation step average loss is 0.7156676054000854\n",
      "07/27/2023 17:59:49 - INFO - __main__ - Cumulative validation average loss is 6.017447758931667\n",
      "07/27/2023 17:59:49 - INFO - __main__ - Per validation step average loss is 0.02609137073159218\n",
      "07/27/2023 17:59:49 - INFO - __main__ - Cumulative validation average loss is 6.043539129663259\n",
      "07/27/2023 17:59:49 - INFO - __main__ - Per validation step average loss is 0.014666540548205376\n",
      "07/27/2023 17:59:49 - INFO - __main__ - Cumulative validation average loss is 6.058205670211464\n",
      "07/27/2023 17:59:50 - INFO - __main__ - Per validation step average loss is 0.03813733160495758\n",
      "07/27/2023 17:59:50 - INFO - __main__ - Cumulative validation average loss is 6.096343001816422\n",
      "07/27/2023 17:59:50 - INFO - __main__ - Per validation step average loss is 0.01963214948773384\n",
      "07/27/2023 17:59:50 - INFO - __main__ - Cumulative validation average loss is 6.115975151304156\n",
      "07/27/2023 17:59:51 - INFO - __main__ - Per validation step average loss is 0.40598610043525696\n",
      "07/27/2023 17:59:51 - INFO - __main__ - Cumulative validation average loss is 6.5219612517394125\n",
      "07/27/2023 17:59:51 - INFO - __main__ - Per validation step average loss is 0.006900810170918703\n",
      "07/27/2023 17:59:51 - INFO - __main__ - Cumulative validation average loss is 6.528862061910331\n",
      "07/27/2023 17:59:51 - INFO - __main__ - Per validation step average loss is 0.07400591671466827\n",
      "07/27/2023 17:59:51 - INFO - __main__ - Cumulative validation average loss is 6.6028679786249995\n",
      "07/27/2023 17:59:52 - INFO - __main__ - Per validation step average loss is 0.3781381845474243\n",
      "07/27/2023 17:59:52 - INFO - __main__ - Cumulative validation average loss is 6.981006163172424\n",
      "07/27/2023 17:59:52 - INFO - __main__ - Per validation step average loss is 0.4424442946910858\n",
      "07/27/2023 17:59:52 - INFO - __main__ - Cumulative validation average loss is 7.42345045786351\n",
      "07/27/2023 17:59:53 - INFO - __main__ - Per validation step average loss is 0.03882834315299988\n",
      "07/27/2023 17:59:53 - INFO - __main__ - Cumulative validation average loss is 7.4622788010165095\n",
      "07/27/2023 17:59:53 - INFO - __main__ - Per validation step average loss is 0.32051873207092285\n",
      "07/27/2023 17:59:53 - INFO - __main__ - Cumulative validation average loss is 7.782797533087432\n",
      "07/27/2023 17:59:53 - INFO - __main__ - Per validation step average loss is 0.016665492206811905\n",
      "07/27/2023 17:59:53 - INFO - __main__ - Cumulative validation average loss is 7.799463025294244\n",
      "07/27/2023 17:59:54 - INFO - __main__ - Per validation step average loss is 0.019962448626756668\n",
      "07/27/2023 17:59:54 - INFO - __main__ - Cumulative validation average loss is 7.819425473921001\n",
      "07/27/2023 17:59:54 - INFO - __main__ - Per validation step average loss is 0.26671648025512695\n",
      "07/27/2023 17:59:54 - INFO - __main__ - Cumulative validation average loss is 8.086141954176128\n",
      "07/27/2023 17:59:55 - INFO - __main__ - Per validation step average loss is 0.008644357323646545\n",
      "07/27/2023 17:59:55 - INFO - __main__ - Cumulative validation average loss is 8.094786311499774\n",
      "07/27/2023 17:59:55 - INFO - __main__ - Per validation step average loss is 0.030214112251996994\n",
      "07/27/2023 17:59:55 - INFO - __main__ - Cumulative validation average loss is 8.125000423751771\n",
      "07/27/2023 17:59:55 - INFO - __main__ - Per validation step average loss is 0.08771820366382599\n",
      "07/27/2023 17:59:55 - INFO - __main__ - Cumulative validation average loss is 8.212718627415597\n",
      "07/27/2023 17:59:56 - INFO - __main__ - Per validation step average loss is 0.1549261212348938\n",
      "07/27/2023 17:59:56 - INFO - __main__ - Cumulative validation average loss is 8.367644748650491\n",
      "07/27/2023 17:59:56 - INFO - __main__ - Per validation step average loss is 0.018533021211624146\n",
      "07/27/2023 17:59:56 - INFO - __main__ - Cumulative validation average loss is 8.386177769862115\n",
      "07/27/2023 17:59:57 - INFO - __main__ - Per validation step average loss is 0.15184363722801208\n",
      "07/27/2023 17:59:57 - INFO - __main__ - Cumulative validation average loss is 8.538021407090127\n",
      "07/27/2023 17:59:57 - INFO - __main__ - Per validation step average loss is 0.07975354790687561\n",
      "07/27/2023 17:59:57 - INFO - __main__ - Cumulative validation average loss is 8.617774954997003\n",
      "07/27/2023 17:59:58 - INFO - __main__ - Per validation step average loss is 0.15303237736225128\n",
      "07/27/2023 17:59:58 - INFO - __main__ - Cumulative validation average loss is 8.770807332359254\n",
      "07/27/2023 17:59:58 - INFO - __main__ - Per validation step average loss is 0.036949846893548965\n",
      "07/27/2023 17:59:58 - INFO - __main__ - Cumulative validation average loss is 8.807757179252803\n",
      "07/27/2023 17:59:58 - INFO - __main__ - Per validation step average loss is 0.04719436913728714\n",
      "07/27/2023 17:59:58 - INFO - __main__ - Cumulative validation average loss is 8.85495154839009\n",
      "07/27/2023 17:59:59 - INFO - __main__ - Per validation step average loss is 0.019833063706755638\n",
      "07/27/2023 17:59:59 - INFO - __main__ - Cumulative validation average loss is 8.874784612096846\n",
      "07/27/2023 17:59:59 - INFO - __main__ - Per validation step average loss is 0.01012897677719593\n",
      "07/27/2023 17:59:59 - INFO - __main__ - Cumulative validation average loss is 8.884913588874042\n",
      "07/27/2023 18:00:00 - INFO - __main__ - Per validation step average loss is 0.01006774790585041\n",
      "07/27/2023 18:00:00 - INFO - __main__ - Cumulative validation average loss is 8.894981336779892\n",
      "07/27/2023 18:00:00 - INFO - __main__ - Per validation step average loss is 0.30096322298049927\n",
      "07/27/2023 18:00:00 - INFO - __main__ - Cumulative validation average loss is 9.195944559760392\n",
      "07/27/2023 18:00:00 - INFO - __main__ - Per validation step average loss is 0.07987505197525024\n",
      "07/27/2023 18:00:00 - INFO - __main__ - Cumulative validation average loss is 9.275819611735642\n",
      "07/27/2023 18:00:01 - INFO - __main__ - Per validation step average loss is 0.00430968077853322\n",
      "07/27/2023 18:00:01 - INFO - __main__ - Cumulative validation average loss is 9.280129292514175\n",
      "07/27/2023 18:00:01 - INFO - __main__ - Per validation step average loss is 0.023189479485154152\n",
      "07/27/2023 18:00:01 - INFO - __main__ - Cumulative validation average loss is 9.30331877199933\n",
      "07/27/2023 18:00:02 - INFO - __main__ - Per validation step average loss is 0.0030474583618342876\n",
      "07/27/2023 18:00:02 - INFO - __main__ - Cumulative validation average loss is 9.306366230361164\n",
      "07/27/2023 18:00:02 - INFO - __main__ - Per validation step average loss is 0.002692725043743849\n",
      "07/27/2023 18:00:02 - INFO - __main__ - Cumulative validation average loss is 9.309058955404907\n",
      "07/27/2023 18:00:02 - INFO - __main__ - Per validation step average loss is 0.014650458469986916\n",
      "07/27/2023 18:00:02 - INFO - __main__ - Cumulative validation average loss is 9.323709413874894\n",
      "07/27/2023 18:00:03 - INFO - __main__ - Per validation step average loss is 0.09180240333080292\n",
      "07/27/2023 18:00:03 - INFO - __main__ - Cumulative validation average loss is 9.415511817205697\n",
      "07/27/2023 18:00:03 - INFO - __main__ - Per validation step average loss is 0.002038797829300165\n",
      "07/27/2023 18:00:03 - INFO - __main__ - Cumulative validation average loss is 9.417550615034997\n",
      "07/27/2023 18:00:04 - INFO - __main__ - Per validation step average loss is 0.039619170129299164\n",
      "07/27/2023 18:00:04 - INFO - __main__ - Cumulative validation average loss is 9.457169785164297\n",
      "07/27/2023 18:00:04 - INFO - __main__ - Per validation step average loss is 0.05937402695417404\n",
      "07/27/2023 18:00:04 - INFO - __main__ - Cumulative validation average loss is 9.51654381211847\n",
      "07/27/2023 18:00:04 - INFO - __main__ - Per validation step average loss is 0.012973714619874954\n",
      "07/27/2023 18:00:04 - INFO - __main__ - Cumulative validation average loss is 9.529517526738346\n",
      "07/27/2023 18:00:05 - INFO - __main__ - Per validation step average loss is 0.00828494317829609\n",
      "07/27/2023 18:00:05 - INFO - __main__ - Cumulative validation average loss is 9.537802469916642\n",
      "07/27/2023 18:00:05 - INFO - __main__ - Per validation step average loss is 0.03503735363483429\n",
      "07/27/2023 18:00:05 - INFO - __main__ - Cumulative validation average loss is 9.572839823551476\n",
      "07/27/2023 18:00:06 - INFO - __main__ - Per validation step average loss is 0.2834376096725464\n",
      "07/27/2023 18:00:06 - INFO - __main__ - Cumulative validation average loss is 9.856277433224022\n",
      "07/27/2023 18:00:06 - INFO - __main__ - Per validation step average loss is 0.322331964969635\n",
      "07/27/2023 18:00:06 - INFO - __main__ - Cumulative validation average loss is 10.178609398193657\n",
      "07/27/2023 18:00:07 - INFO - __main__ - Per validation step average loss is 0.3107609748840332\n",
      "07/27/2023 18:00:07 - INFO - __main__ - Cumulative validation average loss is 10.48937037307769\n",
      "07/27/2023 18:00:07 - INFO - __main__ - Per validation step average loss is 0.2821078300476074\n",
      "07/27/2023 18:00:07 - INFO - __main__ - Cumulative validation average loss is 10.771478203125298\n",
      "07/27/2023 18:00:07 - INFO - __main__ - Average validation loss for Epoch 5 is 0.13634782535601644\n",
      "07/27/2023 18:00:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:01:04 - INFO - __main__ - Starting epoch 6\n",
      "07/27/2023 18:01:05 - INFO - __main__ - train loss is 0.006082986015826464\n",
      "Steps:  12%| | 1819/15000 [16:15<100:19:17, 27.40s/it, lr=0.000226, step_loss=0.07/27/2023 18:01:05 - INFO - __main__ - train loss is 0.34351757587864995\n",
      "Steps:  12%| | 1820/15000 [16:15<70:26:00, 19.24s/it, lr=0.000226, step_loss=0.307/27/2023 18:01:05 - INFO - __main__ - train loss is 0.736279044765979\n",
      "Steps:  12%| | 1821/15000 [16:15<49:30:10, 13.52s/it, lr=0.000226, step_loss=0.307/27/2023 18:01:05 - INFO - __main__ - train loss is 1.690619979519397\n",
      "Steps:  12%| | 1822/15000 [16:16<34:50:51,  9.52s/it, lr=0.000226, step_loss=0.907/27/2023 18:01:05 - INFO - __main__ - train loss is 2.1093854350037873\n",
      "Steps:  12%| | 1823/15000 [16:16<24:35:16,  6.72s/it, lr=0.000227, step_loss=0.407/27/2023 18:01:06 - INFO - __main__ - train loss is 2.1123768626712263\n",
      "Steps:  12%| | 1824/15000 [16:16<17:24:34,  4.76s/it, lr=0.000227, step_loss=0.007/27/2023 18:01:06 - INFO - __main__ - train loss is 2.131430087145418\n",
      "Steps:  12%| | 1825/15000 [16:16<12:23:15,  3.38s/it, lr=0.000227, step_loss=0.007/27/2023 18:01:06 - INFO - __main__ - train loss is 2.352587667759508\n",
      "Steps:  12%| | 1826/15000 [16:16<8:52:01,  2.42s/it, lr=0.000227, step_loss=0.2207/27/2023 18:01:06 - INFO - __main__ - train loss is 2.573781085666269\n",
      "Steps:  12%| | 1827/15000 [16:17<6:24:04,  1.75s/it, lr=0.000227, step_loss=0.2207/27/2023 18:01:06 - INFO - __main__ - train loss is 2.6796248904429376\n",
      "Steps:  12%| | 1828/15000 [16:17<4:40:35,  1.28s/it, lr=0.000227, step_loss=0.1007/27/2023 18:01:07 - INFO - __main__ - train loss is 3.149081682320684\n",
      "Steps:  12%| | 1829/15000 [16:17<3:28:10,  1.05it/s, lr=0.000227, step_loss=0.4607/27/2023 18:01:07 - INFO - __main__ - train loss is 3.565904592629522\n",
      "Steps:  12%| | 1830/15000 [16:17<2:37:30,  1.39it/s, lr=0.000227, step_loss=0.4107/27/2023 18:01:07 - INFO - __main__ - train loss is 3.5749586005695164\n",
      "Steps:  12%| | 1831/15000 [16:17<2:02:00,  1.80it/s, lr=0.000228, step_loss=0.0007/27/2023 18:01:07 - INFO - __main__ - train loss is 3.6359393377788365\n",
      "Steps:  12%| | 1832/15000 [16:17<1:37:31,  2.25it/s, lr=0.000228, step_loss=0.0607/27/2023 18:01:07 - INFO - __main__ - train loss is 3.6507311877794564\n",
      "Steps:  12%| | 1833/15000 [16:18<1:20:13,  2.74it/s, lr=0.000228, step_loss=0.0107/27/2023 18:01:07 - INFO - __main__ - train loss is 3.781316947657615\n",
      "Steps:  12%| | 1834/15000 [16:18<1:08:15,  3.21it/s, lr=0.000228, step_loss=0.1307/27/2023 18:01:08 - INFO - __main__ - train loss is 4.243754279334098\n",
      "Steps:  12%| | 1835/15000 [16:18<59:32,  3.68it/s, lr=0.000228, step_loss=0.462]07/27/2023 18:01:08 - INFO - __main__ - train loss is 4.245546405436471\n",
      "Steps:  12%| | 1836/15000 [16:18<53:28,  4.10it/s, lr=0.000228, step_loss=0.001707/27/2023 18:01:08 - INFO - __main__ - train loss is 4.252177326241508\n",
      "Steps:  12%| | 1837/15000 [16:18<49:16,  4.45it/s, lr=0.000228, step_loss=0.006607/27/2023 18:01:08 - INFO - __main__ - train loss is 4.649610547581688\n",
      "Steps:  12%| | 1838/15000 [16:18<46:16,  4.74it/s, lr=0.000228, step_loss=0.397]07/27/2023 18:01:08 - INFO - __main__ - train loss is 4.8416950984392315\n",
      "Steps:  12%| | 1839/15000 [16:19<44:09,  4.97it/s, lr=0.000229, step_loss=0.192]07/27/2023 18:01:09 - INFO - __main__ - train loss is 4.9799144400749356\n",
      "Steps:  12%| | 1840/15000 [16:19<42:40,  5.14it/s, lr=0.000229, step_loss=0.138]07/27/2023 18:01:09 - INFO - __main__ - train loss is 4.982344608521089\n",
      "Steps:  12%| | 1841/15000 [16:19<41:38,  5.27it/s, lr=0.000229, step_loss=0.002407/27/2023 18:01:09 - INFO - __main__ - train loss is 5.112398143624887\n",
      "Steps:  12%|▏ | 1842/15000 [16:19<40:53,  5.36it/s, lr=0.000229, step_loss=0.13]07/27/2023 18:01:09 - INFO - __main__ - train loss is 5.19424769631587\n",
      "Steps:  12%| | 1843/15000 [16:19<40:51,  5.37it/s, lr=0.000229, step_loss=0.081807/27/2023 18:01:09 - INFO - __main__ - train loss is 5.198769596172497\n",
      "Steps:  12%| | 1844/15000 [16:20<40:46,  5.38it/s, lr=0.000229, step_loss=0.004507/27/2023 18:01:09 - INFO - __main__ - train loss is 5.2077415061648935\n",
      "Steps:  12%| | 1845/15000 [16:20<40:20,  5.43it/s, lr=0.000229, step_loss=0.008907/27/2023 18:01:10 - INFO - __main__ - train loss is 5.209098529070616\n",
      "Steps:  12%| | 1846/15000 [16:20<40:21,  5.43it/s, lr=0.000229, step_loss=0.001307/27/2023 18:01:10 - INFO - __main__ - train loss is 5.2111531847622246\n",
      "Steps:  12%| | 1847/15000 [16:20<40:24,  5.43it/s, lr=0.00023, step_loss=0.0020507/27/2023 18:01:10 - INFO - __main__ - train loss is 5.21293303091079\n",
      "Steps:  12%| | 1848/15000 [16:20<40:10,  5.46it/s, lr=0.00023, step_loss=0.0017807/27/2023 18:01:10 - INFO - __main__ - train loss is 5.22211027611047\n",
      "Steps:  12%| | 1849/15000 [16:20<40:00,  5.48it/s, lr=0.00023, step_loss=0.0091807/27/2023 18:01:10 - INFO - __main__ - train loss is 5.22437335876748\n",
      "Steps:  12%| | 1850/15000 [16:21<39:47,  5.51it/s, lr=0.00023, step_loss=0.0022607/27/2023 18:01:11 - INFO - __main__ - train loss is 5.288813102524728\n",
      "Steps:  12%| | 1851/15000 [16:21<39:39,  5.53it/s, lr=0.00023, step_loss=0.0644]07/27/2023 18:01:11 - INFO - __main__ - train loss is 5.329256005119532\n",
      "Steps:  12%| | 1852/15000 [16:21<40:09,  5.46it/s, lr=0.00023, step_loss=0.0404]07/27/2023 18:01:11 - INFO - __main__ - train loss is 5.445348239969462\n",
      "Steps:  12%|▏ | 1853/15000 [16:21<48:02,  4.56it/s, lr=0.00023, step_loss=0.116]07/27/2023 18:01:11 - INFO - __main__ - train loss is 5.455314928200096\n",
      "Steps:  12%| | 1854/15000 [16:22<49:14,  4.45it/s, lr=0.00023, step_loss=0.0099707/27/2023 18:01:11 - INFO - __main__ - train loss is 5.457138206111267\n",
      "Steps:  12%| | 1855/15000 [16:22<47:38,  4.60it/s, lr=0.000231, step_loss=0.001807/27/2023 18:01:12 - INFO - __main__ - train loss is 5.461187021108344\n",
      "Steps:  12%| | 1856/15000 [16:22<45:21,  4.83it/s, lr=0.000231, step_loss=0.004007/27/2023 18:01:12 - INFO - __main__ - train loss is 5.584175543161109\n",
      "Steps:  12%| | 1857/15000 [16:22<43:39,  5.02it/s, lr=0.000231, step_loss=0.123]07/27/2023 18:01:12 - INFO - __main__ - train loss is 5.589658795623109\n",
      "Steps:  12%| | 1858/15000 [16:22<42:52,  5.11it/s, lr=0.000231, step_loss=0.005407/27/2023 18:01:12 - INFO - __main__ - train loss is 5.706610611407086\n",
      "Steps:  12%| | 1859/15000 [16:23<42:16,  5.18it/s, lr=0.000231, step_loss=0.117]07/27/2023 18:01:12 - INFO - __main__ - train loss is 5.794822647003457\n",
      "Steps:  12%| | 1860/15000 [16:23<41:24,  5.29it/s, lr=0.000231, step_loss=0.088207/27/2023 18:01:13 - INFO - __main__ - train loss is 5.81199222127907\n",
      "Steps:  12%| | 1861/15000 [16:23<40:45,  5.37it/s, lr=0.000231, step_loss=0.017207/27/2023 18:01:13 - INFO - __main__ - train loss is 5.814293129136786\n",
      "Steps:  12%| | 1862/15000 [16:23<40:16,  5.44it/s, lr=0.000231, step_loss=0.002307/27/2023 18:01:13 - INFO - __main__ - train loss is 6.331561369588599\n",
      "Steps:  12%| | 1863/15000 [16:23<40:17,  5.43it/s, lr=0.000232, step_loss=0.517]07/27/2023 18:01:13 - INFO - __main__ - train loss is 6.384649408748373\n",
      "Steps:  12%| | 1864/15000 [16:23<40:08,  5.45it/s, lr=0.000232, step_loss=0.053107/27/2023 18:01:13 - INFO - __main__ - train loss is 6.392931797308847\n",
      "Steps:  12%| | 1865/15000 [16:24<40:03,  5.47it/s, lr=0.000232, step_loss=0.008207/27/2023 18:01:13 - INFO - __main__ - train loss is 6.472138055367395\n",
      "Steps:  12%| | 1866/15000 [16:24<39:57,  5.48it/s, lr=0.000232, step_loss=0.079207/27/2023 18:01:14 - INFO - __main__ - train loss is 6.474262123228982\n",
      "Steps:  12%| | 1867/15000 [16:24<40:00,  5.47it/s, lr=0.000232, step_loss=0.002107/27/2023 18:01:14 - INFO - __main__ - train loss is 6.8019922722596675\n",
      "Steps:  12%| | 1868/15000 [16:24<39:54,  5.48it/s, lr=0.000232, step_loss=0.328]07/27/2023 18:01:14 - INFO - __main__ - train loss is 6.855443512322381\n",
      "Steps:  12%| | 1869/15000 [16:24<39:50,  5.49it/s, lr=0.000232, step_loss=0.053507/27/2023 18:01:14 - INFO - __main__ - train loss is 6.866095871897414\n",
      "Steps:  12%| | 1870/15000 [16:25<39:48,  5.50it/s, lr=0.000232, step_loss=0.010707/27/2023 18:01:14 - INFO - __main__ - train loss is 6.898945116670802\n",
      "Steps:  12%| | 1871/15000 [16:25<39:46,  5.50it/s, lr=0.000233, step_loss=0.032807/27/2023 18:01:15 - INFO - __main__ - train loss is 6.965162963839248\n",
      "Steps:  12%| | 1872/15000 [16:25<39:50,  5.49it/s, lr=0.000233, step_loss=0.066207/27/2023 18:01:15 - INFO - __main__ - train loss is 7.076594629557803\n",
      "Steps:  12%| | 1873/15000 [16:25<39:51,  5.49it/s, lr=0.000233, step_loss=0.111]07/27/2023 18:01:15 - INFO - __main__ - train loss is 7.2731829669792205\n",
      "Steps:  12%| | 1874/15000 [16:25<39:55,  5.48it/s, lr=0.000233, step_loss=0.197]07/27/2023 18:01:15 - INFO - __main__ - train loss is 7.343628005357459\n",
      "Steps:  12%|▏| 1875/15000 [16:25<39:52,  5.49it/s, lr=0.000233, step_loss=0.070407/27/2023 18:01:15 - INFO - __main__ - train loss is 7.544989303918555\n",
      "Steps:  13%|▏| 1876/15000 [16:26<39:49,  5.49it/s, lr=0.000233, step_loss=0.201]07/27/2023 18:01:15 - INFO - __main__ - train loss is 7.599840053590015\n",
      "Steps:  13%|▏| 1877/15000 [16:26<40:05,  5.45it/s, lr=0.000233, step_loss=0.054907/27/2023 18:01:16 - INFO - __main__ - train loss is 7.651647520484403\n",
      "Steps:  13%|▏| 1878/15000 [16:26<39:58,  5.47it/s, lr=0.000233, step_loss=0.051807/27/2023 18:01:16 - INFO - __main__ - train loss is 8.318143499316648\n",
      "Steps:  13%|▏| 1879/15000 [16:26<39:54,  5.48it/s, lr=0.000234, step_loss=0.666]07/27/2023 18:01:16 - INFO - __main__ - train loss is 8.323682764777914\n",
      "Steps:  13%|▏| 1880/15000 [16:26<40:10,  5.44it/s, lr=0.000234, step_loss=0.005507/27/2023 18:01:16 - INFO - __main__ - train loss is 8.327037146082148\n",
      "Steps:  13%|▏| 1881/15000 [16:27<40:01,  5.46it/s, lr=0.000234, step_loss=0.003307/27/2023 18:01:16 - INFO - __main__ - train loss is 8.414767807116732\n",
      "Steps:  13%|▏| 1882/15000 [16:27<39:55,  5.48it/s, lr=0.000234, step_loss=0.087707/27/2023 18:01:17 - INFO - __main__ - train loss is 8.976657336344942\n",
      "Steps:  13%|▏| 1883/15000 [16:27<40:14,  5.43it/s, lr=0.000234, step_loss=0.562]07/27/2023 18:01:17 - INFO - __main__ - train loss is 9.241673474898562\n",
      "Steps:  13%|▏| 1884/15000 [16:27<40:03,  5.46it/s, lr=0.000234, step_loss=0.265]07/27/2023 18:01:17 - INFO - __main__ - train loss is 9.245851117419079\n",
      "Steps:  13%|▏| 1885/15000 [16:27<39:59,  5.47it/s, lr=0.000234, step_loss=0.004107/27/2023 18:01:17 - INFO - __main__ - train loss is 9.280157911824062\n",
      "Steps:  13%|▏| 1886/15000 [16:27<40:14,  5.43it/s, lr=0.000234, step_loss=0.034307/27/2023 18:01:17 - INFO - __main__ - train loss is 9.37729738210328\n",
      "Steps:  13%|▏| 1887/15000 [16:28<40:27,  5.40it/s, lr=0.000234, step_loss=0.097107/27/2023 18:01:18 - INFO - __main__ - train loss is 9.439157839166\n",
      "Steps:  13%|▏| 1888/15000 [16:28<40:17,  5.42it/s, lr=0.000235, step_loss=0.061907/27/2023 18:01:18 - INFO - __main__ - train loss is 9.60744073544629\n",
      "Steps:  13%|▏| 1889/15000 [16:28<40:19,  5.42it/s, lr=0.000235, step_loss=0.168]07/27/2023 18:01:18 - INFO - __main__ - train loss is 10.521703387843445\n",
      "Steps:  13%|▏| 1890/15000 [16:28<40:01,  5.46it/s, lr=0.000235, step_loss=0.914]07/27/2023 18:01:18 - INFO - __main__ - train loss is 10.57311415229924\n",
      "Steps:  13%|▏| 1891/15000 [16:28<39:46,  5.49it/s, lr=0.000235, step_loss=0.051407/27/2023 18:01:18 - INFO - __main__ - train loss is 10.943330581532791\n",
      "Steps:  13%|▎ | 1892/15000 [16:29<39:35,  5.52it/s, lr=0.000235, step_loss=0.37]07/27/2023 18:01:18 - INFO - __main__ - train loss is 10.966340107144788\n",
      "Steps:  13%|▏| 1893/15000 [16:29<39:27,  5.54it/s, lr=0.000235, step_loss=0.023]07/27/2023 18:01:19 - INFO - __main__ - train loss is 11.083767441334203\n",
      "Steps:  13%|▏| 1894/15000 [16:29<39:21,  5.55it/s, lr=0.000235, step_loss=0.117]07/27/2023 18:01:19 - INFO - __main__ - train loss is 11.17103407275863\n",
      "Steps:  13%|▏| 1895/15000 [16:29<39:17,  5.56it/s, lr=0.000236, step_loss=0.087307/27/2023 18:01:19 - INFO - __main__ - train loss is 11.187713497551158\n",
      "Steps:  13%|▏| 1896/15000 [16:29<39:15,  5.56it/s, lr=0.000236, step_loss=0.016707/27/2023 18:01:19 - INFO - __main__ - train loss is 11.313228585990146\n",
      "Steps:  13%|▏| 1897/15000 [16:29<39:39,  5.51it/s, lr=0.000236, step_loss=0.126]07/27/2023 18:01:19 - INFO - __main__ - train loss is 11.37907808390446\n",
      "Steps:  13%|▏| 1898/15000 [16:30<39:35,  5.51it/s, lr=0.000236, step_loss=0.065807/27/2023 18:01:19 - INFO - __main__ - train loss is 11.384647875325754\n",
      "Steps:  13%|▏| 1899/15000 [16:30<39:27,  5.53it/s, lr=0.000236, step_loss=0.005507/27/2023 18:01:20 - INFO - __main__ - train loss is 11.506073772208765\n",
      "Steps:  13%|▏| 1900/15000 [16:30<39:25,  5.54it/s, lr=0.000236, step_loss=0.121]07/27/2023 18:01:20 - INFO - __main__ - train loss is 11.508682064944878\n",
      "Steps:  13%|▏| 1901/15000 [16:30<39:43,  5.50it/s, lr=0.000236, step_loss=0.002607/27/2023 18:01:20 - INFO - __main__ - train loss is 11.535453863674775\n",
      "Steps:  13%|▏| 1902/15000 [16:30<39:41,  5.50it/s, lr=0.000236, step_loss=0.026807/27/2023 18:01:20 - INFO - __main__ - train loss is 11.552802730584517\n",
      "Steps:  13%|▏| 1903/15000 [16:31<39:37,  5.51it/s, lr=0.000237, step_loss=0.017307/27/2023 18:01:20 - INFO - __main__ - train loss is 11.652358446503058\n",
      "Steps:  13%|▏| 1904/15000 [16:31<39:31,  5.52it/s, lr=0.000237, step_loss=0.099607/27/2023 18:01:21 - INFO - __main__ - train loss is 11.658386730356142\n",
      "Steps:  13%|▏| 1905/15000 [16:31<39:26,  5.53it/s, lr=0.000237, step_loss=0.006007/27/2023 18:01:21 - INFO - __main__ - train loss is 11.677076282678172\n",
      "Steps:  13%|▏| 1906/15000 [16:31<39:48,  5.48it/s, lr=0.000237, step_loss=0.018707/27/2023 18:01:21 - INFO - __main__ - train loss is 11.678342986502685\n",
      "Steps:  13%|▏| 1907/15000 [16:31<39:55,  5.47it/s, lr=0.000237, step_loss=0.001207/27/2023 18:01:21 - INFO - __main__ - train loss is 11.781503427424468\n",
      "Steps:  13%|▏| 1908/15000 [16:31<39:50,  5.48it/s, lr=0.000237, step_loss=0.103]07/27/2023 18:01:21 - INFO - __main__ - train loss is 12.229575622477569\n",
      "Steps:  13%|▏| 1909/15000 [16:32<39:45,  5.49it/s, lr=0.000237, step_loss=0.448]07/27/2023 18:01:21 - INFO - __main__ - train loss is 12.549722958006896\n",
      "Steps:  13%|▎ | 1910/15000 [16:32<39:43,  5.49it/s, lr=0.000237, step_loss=0.32]07/27/2023 18:01:22 - INFO - __main__ - train loss is 12.563574049272574\n",
      "Steps:  13%|▏| 1911/15000 [16:32<39:40,  5.50it/s, lr=0.000237, step_loss=0.013907/27/2023 18:01:22 - INFO - __main__ - train loss is 12.568294694297947\n",
      "Steps:  13%|▏| 1912/15000 [16:32<39:38,  5.50it/s, lr=0.000238, step_loss=0.004707/27/2023 18:01:22 - INFO - __main__ - train loss is 12.57132440584246\n",
      "Steps:  13%|▏| 1913/15000 [16:32<39:37,  5.51it/s, lr=0.000238, step_loss=0.003007/27/2023 18:01:22 - INFO - __main__ - train loss is 12.595283848815598\n",
      "Steps:  13%|▏| 1914/15000 [16:33<39:37,  5.50it/s, lr=0.000238, step_loss=0.024]07/27/2023 18:01:22 - INFO - __main__ - train loss is 12.600324043654837\n",
      "Steps:  13%|▏| 1915/15000 [16:33<39:36,  5.51it/s, lr=0.000238, step_loss=0.005007/27/2023 18:01:23 - INFO - __main__ - train loss is 12.603261348907836\n",
      "Steps:  13%|▏| 1916/15000 [16:33<39:36,  5.51it/s, lr=0.000238, step_loss=0.002907/27/2023 18:01:23 - INFO - __main__ - train loss is 12.807593149249442\n",
      "Steps:  13%|▏| 1917/15000 [16:33<39:38,  5.50it/s, lr=0.000238, step_loss=0.204]07/27/2023 18:01:23 - INFO - __main__ - train loss is 12.885364373330958\n",
      "Steps:  13%|▏| 1918/15000 [16:33<39:42,  5.49it/s, lr=0.000238, step_loss=0.077807/27/2023 18:01:23 - INFO - __main__ - train loss is 12.921160281752236\n",
      "Steps:  13%|▏| 1919/15000 [16:33<39:38,  5.50it/s, lr=0.000238, step_loss=0.035807/27/2023 18:01:23 - INFO - __main__ - train loss is 12.970677961711772\n",
      "Steps:  13%|▏| 1920/15000 [16:34<39:35,  5.51it/s, lr=0.000239, step_loss=0.049507/27/2023 18:01:23 - INFO - __main__ - train loss is 12.986245998297818\n",
      "Steps:  13%|▏| 1921/15000 [16:34<39:33,  5.51it/s, lr=0.000239, step_loss=0.015607/27/2023 18:01:24 - INFO - __main__ - train loss is 13.402901598368771\n",
      "Steps:  13%|▏| 1922/15000 [16:34<39:34,  5.51it/s, lr=0.000239, step_loss=0.417]07/27/2023 18:01:24 - INFO - __main__ - train loss is 13.955311247264035\n",
      "Steps:  13%|▏| 1923/15000 [16:34<39:38,  5.50it/s, lr=0.000239, step_loss=0.552]07/27/2023 18:01:24 - INFO - __main__ - train loss is 13.957924406626262\n",
      "Steps:  13%|▏| 1924/15000 [16:34<39:42,  5.49it/s, lr=0.000239, step_loss=0.002607/27/2023 18:01:24 - INFO - __main__ - train loss is 14.130790974595584\n",
      "Steps:  13%|▏| 1925/15000 [16:35<39:49,  5.47it/s, lr=0.000239, step_loss=0.173]07/27/2023 18:01:24 - INFO - __main__ - train loss is 14.277134921052493\n",
      "Steps:  13%|▏| 1926/15000 [16:35<39:49,  5.47it/s, lr=0.000239, step_loss=0.146]07/27/2023 18:01:25 - INFO - __main__ - train loss is 14.314268689253367\n",
      "Steps:  13%|▏| 1927/15000 [16:35<39:48,  5.47it/s, lr=0.000239, step_loss=0.037107/27/2023 18:01:25 - INFO - __main__ - train loss is 14.317561918054707\n",
      "Steps:  13%|▏| 1928/15000 [16:35<39:49,  5.47it/s, lr=0.00024, step_loss=0.0032907/27/2023 18:01:25 - INFO - __main__ - train loss is 14.326094822143205\n",
      "Steps:  13%|▏| 1929/15000 [16:35<40:03,  5.44it/s, lr=0.00024, step_loss=0.0085307/27/2023 18:01:25 - INFO - __main__ - train loss is 14.648546443437226\n",
      "Steps:  13%|▎ | 1930/15000 [16:35<39:55,  5.46it/s, lr=0.00024, step_loss=0.322]07/27/2023 18:01:25 - INFO - __main__ - train loss is 14.65002419508528\n",
      "Steps:  13%|▏| 1931/15000 [16:36<40:11,  5.42it/s, lr=0.00024, step_loss=0.0014807/27/2023 18:01:26 - INFO - __main__ - train loss is 14.757965114782564\n",
      "Steps:  13%|▎ | 1932/15000 [16:36<39:57,  5.45it/s, lr=0.00024, step_loss=0.108]07/27/2023 18:01:26 - INFO - __main__ - train loss is 14.761887720203958\n",
      "Steps:  13%|▏| 1933/15000 [16:36<39:40,  5.49it/s, lr=0.00024, step_loss=0.0039207/27/2023 18:01:26 - INFO - __main__ - train loss is 14.76899080851581\n",
      "Steps:  13%|▏| 1934/15000 [16:36<39:29,  5.51it/s, lr=0.00024, step_loss=0.0071]07/27/2023 18:01:26 - INFO - __main__ - train loss is 14.79266372078564\n",
      "Steps:  13%|▏| 1935/15000 [16:36<39:32,  5.51it/s, lr=0.00024, step_loss=0.0237]07/27/2023 18:01:26 - INFO - __main__ - train loss is 14.826977392076515\n",
      "Steps:  13%|▏| 1936/15000 [16:37<39:26,  5.52it/s, lr=0.000241, step_loss=0.034307/27/2023 18:01:26 - INFO - __main__ - train loss is 14.856986237107776\n",
      "Steps:  13%|▎ | 1937/15000 [16:37<39:26,  5.52it/s, lr=0.000241, step_loss=0.03]07/27/2023 18:01:27 - INFO - __main__ - train loss is 14.85878772160504\n",
      "Steps:  13%|▏| 1938/15000 [16:37<39:17,  5.54it/s, lr=0.000241, step_loss=0.001807/27/2023 18:01:27 - INFO - __main__ - train loss is 14.94127493223641\n",
      "Steps:  13%|▏| 1939/15000 [16:37<39:10,  5.56it/s, lr=0.000241, step_loss=0.082507/27/2023 18:01:27 - INFO - __main__ - train loss is 14.960285971523263\n",
      "Steps:  13%|▏| 1940/15000 [16:37<39:06,  5.57it/s, lr=0.000241, step_loss=0.019]07/27/2023 18:01:27 - INFO - __main__ - train loss is 14.9625610121293\n",
      "Steps:  13%|▏| 1941/15000 [16:37<39:03,  5.57it/s, lr=0.000241, step_loss=0.002207/27/2023 18:01:27 - INFO - __main__ - train loss is 15.252720714430325\n",
      "Steps:  13%|▎ | 1942/15000 [16:38<39:03,  5.57it/s, lr=0.000241, step_loss=0.29]07/27/2023 18:01:27 - INFO - __main__ - train loss is 15.267317483085208\n",
      "Steps:  13%|▏| 1943/15000 [16:38<39:01,  5.58it/s, lr=0.000241, step_loss=0.014607/27/2023 18:01:28 - INFO - __main__ - train loss is 15.497885564225726\n",
      "Steps:  13%|▏| 1944/15000 [16:38<39:06,  5.56it/s, lr=0.000242, step_loss=0.231]07/27/2023 18:01:28 - INFO - __main__ - train loss is 15.51921727124136\n",
      "Steps:  13%|▏| 1945/15000 [16:38<39:34,  5.50it/s, lr=0.000242, step_loss=0.021307/27/2023 18:01:28 - INFO - __main__ - train loss is 15.557769477250986\n",
      "Steps:  13%|▏| 1946/15000 [16:38<39:23,  5.52it/s, lr=0.000242, step_loss=0.038607/27/2023 18:01:28 - INFO - __main__ - train loss is 15.66854858386796\n",
      "Steps:  13%|▏| 1947/15000 [16:39<39:14,  5.54it/s, lr=0.000242, step_loss=0.111]07/27/2023 18:01:28 - INFO - __main__ - train loss is 15.949276536586694\n",
      "Steps:  13%|▏| 1948/15000 [16:39<39:07,  5.56it/s, lr=0.000242, step_loss=0.281]07/27/2023 18:01:29 - INFO - __main__ - train loss is 16.093030035379343\n",
      "Steps:  13%|▏| 1949/15000 [16:39<39:03,  5.57it/s, lr=0.000242, step_loss=0.144]07/27/2023 18:01:29 - INFO - __main__ - train loss is 16.19906467932742\n",
      "Steps:  13%|▏| 1950/15000 [16:39<39:01,  5.57it/s, lr=0.000242, step_loss=0.106]07/27/2023 18:01:29 - INFO - __main__ - train loss is 16.529514320078306\n",
      "Steps:  13%|▎ | 1951/15000 [16:39<38:59,  5.58it/s, lr=0.000242, step_loss=0.33]07/27/2023 18:01:29 - INFO - __main__ - train loss is 16.70273787516635\n",
      "Steps:  13%|▏| 1952/15000 [16:39<39:27,  5.51it/s, lr=0.000243, step_loss=0.173]07/27/2023 18:01:29 - INFO - __main__ - train loss is 16.963192917290144\n",
      "Steps:  13%|▎ | 1953/15000 [16:40<39:32,  5.50it/s, lr=0.000243, step_loss=0.26]07/27/2023 18:01:29 - INFO - __main__ - train loss is 16.967251734691672\n",
      "Steps:  13%|▏| 1954/15000 [16:40<39:31,  5.50it/s, lr=0.000243, step_loss=0.004007/27/2023 18:01:30 - INFO - __main__ - train loss is 16.981527527677827\n",
      "Steps:  13%|▏| 1955/15000 [16:40<39:31,  5.50it/s, lr=0.000243, step_loss=0.014307/27/2023 18:01:30 - INFO - __main__ - train loss is 17.195522105204873\n",
      "Steps:  13%|▏| 1956/15000 [16:40<39:31,  5.50it/s, lr=0.000243, step_loss=0.214]07/27/2023 18:01:30 - INFO - __main__ - train loss is 17.24767940293532\n",
      "Steps:  13%|▏| 1957/15000 [16:40<39:33,  5.50it/s, lr=0.000243, step_loss=0.052207/27/2023 18:01:30 - INFO - __main__ - train loss is 17.315225889789872\n",
      "Steps:  13%|▏| 1958/15000 [16:41<39:39,  5.48it/s, lr=0.000243, step_loss=0.067507/27/2023 18:01:30 - INFO - __main__ - train loss is 17.35761972318869\n",
      "Steps:  13%|▏| 1959/15000 [16:41<39:50,  5.46it/s, lr=0.000244, step_loss=0.042407/27/2023 18:01:31 - INFO - __main__ - train loss is 17.81545602332335\n",
      "Steps:  13%|▏| 1960/15000 [16:41<39:44,  5.47it/s, lr=0.000244, step_loss=0.458]07/27/2023 18:01:31 - INFO - __main__ - train loss is 17.901283739018254\n",
      "Steps:  13%|▏| 1961/15000 [16:41<39:47,  5.46it/s, lr=0.000244, step_loss=0.085807/27/2023 18:01:31 - INFO - __main__ - train loss is 17.919128605979495\n",
      "Steps:  13%|▏| 1962/15000 [16:41<39:43,  5.47it/s, lr=0.000244, step_loss=0.017807/27/2023 18:01:31 - INFO - __main__ - train loss is 17.95279660250526\n",
      "Steps:  13%|▏| 1963/15000 [16:41<39:45,  5.47it/s, lr=0.000244, step_loss=0.033707/27/2023 18:01:31 - INFO - __main__ - train loss is 18.132241407292895\n",
      "Steps:  13%|▏| 1964/15000 [16:42<39:46,  5.46it/s, lr=0.000244, step_loss=0.179]07/27/2023 18:01:31 - INFO - __main__ - train loss is 18.416219631093554\n",
      "Steps:  13%|▏| 1965/15000 [16:42<39:41,  5.47it/s, lr=0.000244, step_loss=0.284]07/27/2023 18:01:32 - INFO - __main__ - train loss is 18.43064911745023\n",
      "Steps:  13%|▏| 1966/15000 [16:42<39:37,  5.48it/s, lr=0.000244, step_loss=0.014407/27/2023 18:01:32 - INFO - __main__ - train loss is 18.540288069169037\n",
      "Steps:  13%|▎ | 1967/15000 [16:42<39:41,  5.47it/s, lr=0.000244, step_loss=0.11]07/27/2023 18:01:32 - INFO - __main__ - train loss is 18.55772999196779\n",
      "Steps:  13%|▏| 1968/15000 [16:42<40:00,  5.43it/s, lr=0.000245, step_loss=0.017407/27/2023 18:01:32 - INFO - __main__ - train loss is 18.7095341560198\n",
      "Steps:  13%|▏| 1969/15000 [16:43<39:47,  5.46it/s, lr=0.000245, step_loss=0.152]07/27/2023 18:01:32 - INFO - __main__ - train loss is 18.819729032809846\n",
      "Steps:  13%|▎ | 1970/15000 [16:43<39:34,  5.49it/s, lr=0.000245, step_loss=0.11]07/27/2023 18:01:33 - INFO - __main__ - train loss is 18.823168673436157\n",
      "Steps:  13%|▏| 1971/15000 [16:43<39:23,  5.51it/s, lr=0.000245, step_loss=0.003407/27/2023 18:01:33 - INFO - __main__ - train loss is 18.838009840692393\n",
      "Steps:  13%|▏| 1972/15000 [16:43<39:30,  5.49it/s, lr=0.000245, step_loss=0.014807/27/2023 18:01:33 - INFO - __main__ - train loss is 18.867539520259015\n",
      "Steps:  13%|▏| 1973/15000 [16:43<39:21,  5.52it/s, lr=0.000245, step_loss=0.029507/27/2023 18:01:33 - INFO - __main__ - train loss is 18.88284150965046\n",
      "Steps:  13%|▏| 1974/15000 [16:43<39:13,  5.53it/s, lr=0.000245, step_loss=0.015307/27/2023 18:01:33 - INFO - __main__ - train loss is 19.261271995375864\n",
      "Steps:  13%|▏| 1975/15000 [16:44<39:21,  5.51it/s, lr=0.000246, step_loss=0.378]07/27/2023 18:01:33 - INFO - __main__ - train loss is 19.363438126514666\n",
      "Steps:  13%|▏| 1976/15000 [16:44<39:32,  5.49it/s, lr=0.000246, step_loss=0.102]07/27/2023 18:01:34 - INFO - __main__ - train loss is 19.75465807027649\n",
      "Steps:  13%|▏| 1977/15000 [16:44<39:18,  5.52it/s, lr=0.000246, step_loss=0.391]07/27/2023 18:01:34 - INFO - __main__ - train loss is 19.75755754543934\n",
      "Steps:  13%|▏| 1978/15000 [16:44<39:13,  5.53it/s, lr=0.000246, step_loss=0.002907/27/2023 18:01:34 - INFO - __main__ - train loss is 20.682856951490976\n",
      "Steps:  13%|▏| 1979/15000 [16:44<39:33,  5.49it/s, lr=0.000246, step_loss=0.925]07/27/2023 18:01:34 - INFO - __main__ - train loss is 21.222246621386148\n",
      "Steps:  13%|▏| 1980/15000 [16:45<39:52,  5.44it/s, lr=0.000246, step_loss=0.539]07/27/2023 18:01:34 - INFO - __main__ - train loss is 21.517295931116678\n",
      "Steps:  13%|▏| 1981/15000 [16:45<39:50,  5.45it/s, lr=0.000246, step_loss=0.295]07/27/2023 18:01:35 - INFO - __main__ - train loss is 21.52823789289687\n",
      "Steps:  13%|▏| 1982/15000 [16:45<39:37,  5.47it/s, lr=0.000246, step_loss=0.010907/27/2023 18:01:35 - INFO - __main__ - train loss is 21.52949495462235\n",
      "Steps:  13%|▏| 1983/15000 [16:45<39:38,  5.47it/s, lr=0.000247, step_loss=0.001207/27/2023 18:01:35 - INFO - __main__ - train loss is 21.865834666765295\n",
      "Steps:  13%|▏| 1984/15000 [16:45<39:42,  5.46it/s, lr=0.000247, step_loss=0.336]07/27/2023 18:01:35 - INFO - __main__ - train loss is 22.017605407512747\n",
      "Steps:  13%|▏| 1985/15000 [16:45<39:33,  5.48it/s, lr=0.000247, step_loss=0.152]07/27/2023 18:01:35 - INFO - __main__ - train loss is 22.16331560758408\n",
      "Steps:  13%|▏| 1986/15000 [16:46<39:25,  5.50it/s, lr=0.000247, step_loss=0.146]07/27/2023 18:01:35 - INFO - __main__ - train loss is 22.16565680631902\n",
      "Steps:  13%|▏| 1987/15000 [16:46<39:19,  5.52it/s, lr=0.000247, step_loss=0.002307/27/2023 18:01:36 - INFO - __main__ - train loss is 22.195151702850126\n",
      "Steps:  13%|▏| 1988/15000 [16:46<39:11,  5.53it/s, lr=0.000247, step_loss=0.029507/27/2023 18:01:36 - INFO - __main__ - train loss is 22.198416929575615\n",
      "Steps:  13%|▏| 1989/15000 [16:46<39:08,  5.54it/s, lr=0.000247, step_loss=0.003207/27/2023 18:01:36 - INFO - __main__ - train loss is 22.27216169598978\n",
      "Steps:  13%|▏| 1990/15000 [16:46<39:04,  5.55it/s, lr=0.000247, step_loss=0.073707/27/2023 18:01:36 - INFO - __main__ - train loss is 22.350745204719715\n",
      "Steps:  13%|▏| 1991/15000 [16:47<39:20,  5.51it/s, lr=0.000247, step_loss=0.078607/27/2023 18:01:36 - INFO - __main__ - train loss is 22.817128542694263\n",
      "Steps:  13%|▏| 1992/15000 [16:47<39:16,  5.52it/s, lr=0.000248, step_loss=0.466]07/27/2023 18:01:37 - INFO - __main__ - train loss is 23.195840123924427\n",
      "Steps:  13%|▏| 1993/15000 [16:47<39:08,  5.54it/s, lr=0.000248, step_loss=0.379]07/27/2023 18:01:37 - INFO - __main__ - train loss is 23.323548395070247\n",
      "Steps:  13%|▏| 1994/15000 [16:47<39:02,  5.55it/s, lr=0.000248, step_loss=0.128]07/27/2023 18:01:37 - INFO - __main__ - train loss is 23.611036676797085\n",
      "Steps:  13%|▏| 1995/15000 [16:47<39:06,  5.54it/s, lr=0.000248, step_loss=0.287]07/27/2023 18:01:37 - INFO - __main__ - train loss is 23.613472484401427\n",
      "Steps:  13%|▏| 1996/15000 [16:47<39:01,  5.55it/s, lr=0.000248, step_loss=0.002407/27/2023 18:01:37 - INFO - __main__ - train loss is 23.6168532645097\n",
      "Steps:  13%|▏| 1997/15000 [16:48<38:57,  5.56it/s, lr=0.000248, step_loss=0.003307/27/2023 18:01:37 - INFO - __main__ - train loss is 23.62085589149501\n",
      "Steps:  13%|▏| 1998/15000 [16:48<38:52,  5.57it/s, lr=0.000248, step_loss=0.004]07/27/2023 18:01:38 - INFO - __main__ - train loss is 23.645486521883868\n",
      "Steps:  13%|▏| 1999/15000 [16:48<38:50,  5.58it/s, lr=0.000249, step_loss=0.024607/27/2023 18:01:38 - INFO - __main__ - train loss is 23.67008657322731\n",
      "Steps:  13%|▏| 2000/15000 [16:48<38:50,  5.58it/s, lr=0.000249, step_loss=0.024607/27/2023 18:01:38 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-2000\n",
      "07/27/2023 18:01:38 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:01:38,422] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:01:38,426] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:01:38,426] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:01:38,433] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:01:38,433] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:01:38,439] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:01:38,440] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:01:38,440] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:01:38 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-2000/pytorch_model\n",
      "07/27/2023 18:01:38 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-2000/scheduler.bin\n",
      "07/27/2023 18:01:38 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-2000/random_states_0.pkl\n",
      "07/27/2023 18:01:38 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-2000\n",
      "Steps:  13%|▏| 2000/15000 [16:48<38:50,  5.58it/s, lr=0.000249, step_loss=0.024607/27/2023 18:01:38 - INFO - __main__ - train loss is 24.018264423473738\n",
      "Steps:  13%|▏| 2001/15000 [16:48<40:18,  5.37it/s, lr=0.000249, step_loss=0.348]07/27/2023 18:01:38 - INFO - __main__ - train loss is 24.334091495140456\n",
      "Steps:  13%|▏| 2002/15000 [16:49<40:13,  5.39it/s, lr=0.000249, step_loss=0.316]07/27/2023 18:01:38 - INFO - __main__ - train loss is 24.363515316857956\n",
      "Steps:  13%|▏| 2003/15000 [16:49<40:09,  5.39it/s, lr=0.000249, step_loss=0.029407/27/2023 18:01:39 - INFO - __main__ - train loss is 24.591589420451783\n",
      "Steps:  13%|▏| 2004/15000 [16:49<39:45,  5.45it/s, lr=0.000249, step_loss=0.228]07/27/2023 18:01:39 - INFO - __main__ - train loss is 25.236010401858948\n",
      "Steps:  13%|▏| 2005/15000 [16:49<39:27,  5.49it/s, lr=0.000249, step_loss=0.644]07/27/2023 18:01:39 - INFO - __main__ - train loss is 25.524885475053452\n",
      "Steps:  13%|▏| 2006/15000 [16:49<39:15,  5.52it/s, lr=0.000249, step_loss=0.289]07/27/2023 18:01:39 - INFO - __main__ - train loss is 25.536409722990356\n",
      "Steps:  13%|▏| 2007/15000 [16:49<39:07,  5.53it/s, lr=0.000249, step_loss=0.011507/27/2023 18:01:39 - INFO - __main__ - train loss is 25.553220862871967\n",
      "Steps:  13%|▏| 2008/15000 [16:50<39:00,  5.55it/s, lr=0.00025, step_loss=0.0168]07/27/2023 18:01:39 - INFO - __main__ - train loss is 25.57098262978252\n",
      "Steps:  13%|▏| 2009/15000 [16:50<38:55,  5.56it/s, lr=0.00025, step_loss=0.0178]07/27/2023 18:01:40 - INFO - __main__ - train loss is 25.823460782296024\n",
      "Steps:  13%|▎ | 2010/15000 [16:50<38:53,  5.57it/s, lr=0.00025, step_loss=0.252]07/27/2023 18:01:40 - INFO - __main__ - train loss is 25.879924090928398\n",
      "Steps:  13%|▏| 2011/15000 [16:50<39:06,  5.54it/s, lr=0.00025, step_loss=0.0565]07/27/2023 18:01:40 - INFO - __main__ - train loss is 25.941106358892284\n",
      "Steps:  13%|▏| 2012/15000 [16:50<39:00,  5.55it/s, lr=0.00025, step_loss=0.0612]07/27/2023 18:01:40 - INFO - __main__ - train loss is 26.0431121684378\n",
      "Steps:  13%|▎ | 2013/15000 [16:51<38:55,  5.56it/s, lr=0.00025, step_loss=0.102]07/27/2023 18:01:40 - INFO - __main__ - train loss is 26.116536790854298\n",
      "Steps:  13%|▏| 2014/15000 [16:51<38:52,  5.57it/s, lr=0.00025, step_loss=0.0734]07/27/2023 18:01:41 - INFO - __main__ - train loss is 26.12298706115689\n",
      "Steps:  13%|▏| 2015/15000 [16:51<38:50,  5.57it/s, lr=0.000251, step_loss=0.006407/27/2023 18:01:41 - INFO - __main__ - train loss is 26.12889825727325\n",
      "Steps:  13%|▏| 2016/15000 [16:51<38:48,  5.58it/s, lr=0.000251, step_loss=0.005907/27/2023 18:01:41 - INFO - __main__ - train loss is 26.130981885246\n",
      "Steps:  13%|▏| 2017/15000 [16:51<38:49,  5.57it/s, lr=0.000251, step_loss=0.002007/27/2023 18:01:41 - INFO - __main__ - train loss is 26.167150281718932\n",
      "Steps:  13%|▏| 2018/15000 [16:51<38:47,  5.58it/s, lr=0.000251, step_loss=0.036207/27/2023 18:01:41 - INFO - __main__ - train loss is 26.39266493206378\n",
      "Steps:  13%|▏| 2019/15000 [16:52<38:45,  5.58it/s, lr=0.000251, step_loss=0.226]07/27/2023 18:01:41 - INFO - __main__ - train loss is 26.460361093631946\n",
      "Steps:  13%|▏| 2020/15000 [16:52<38:51,  5.57it/s, lr=0.000251, step_loss=0.067707/27/2023 18:01:42 - INFO - __main__ - train loss is 26.58420485293027\n",
      "Steps:  13%|▏| 2021/15000 [16:52<38:48,  5.57it/s, lr=0.000251, step_loss=0.124]07/27/2023 18:01:42 - INFO - __main__ - train loss is 26.705219902447425\n",
      "Steps:  13%|▏| 2022/15000 [16:52<39:12,  5.52it/s, lr=0.000251, step_loss=0.121]07/27/2023 18:01:42 - INFO - __main__ - train loss is 26.709465697291307\n",
      "Steps:  13%|▏| 2023/15000 [16:52<39:45,  5.44it/s, lr=0.000251, step_loss=0.004207/27/2023 18:01:42 - INFO - __main__ - train loss is 26.718175751972012\n",
      "Steps:  13%|▏| 2024/15000 [16:52<39:26,  5.48it/s, lr=0.000252, step_loss=0.008707/27/2023 18:01:42 - INFO - __main__ - train loss is 26.74907597701531\n",
      "Steps:  14%|▏| 2025/15000 [16:53<39:13,  5.51it/s, lr=0.000252, step_loss=0.030907/27/2023 18:01:43 - INFO - __main__ - train loss is 26.930328635382466\n",
      "Steps:  14%|▏| 2026/15000 [16:53<39:04,  5.53it/s, lr=0.000252, step_loss=0.181]07/27/2023 18:01:43 - INFO - __main__ - train loss is 26.997759086894803\n",
      "Steps:  14%|▏| 2027/15000 [16:53<38:57,  5.55it/s, lr=0.000252, step_loss=0.067407/27/2023 18:01:43 - INFO - __main__ - train loss is 26.999068798613735\n",
      "Steps:  14%|▏| 2028/15000 [16:53<39:00,  5.54it/s, lr=0.000252, step_loss=0.001307/27/2023 18:01:43 - INFO - __main__ - train loss is 27.17598068912048\n",
      "Steps:  14%|▏| 2029/15000 [16:53<38:54,  5.56it/s, lr=0.000252, step_loss=0.177]07/27/2023 18:01:43 - INFO - __main__ - train loss is 27.179632083163597\n",
      "Steps:  14%|▏| 2030/15000 [16:54<38:50,  5.57it/s, lr=0.000252, step_loss=0.003607/27/2023 18:01:43 - INFO - __main__ - train loss is 27.188051766366698\n",
      "Steps:  14%|▏| 2031/15000 [16:54<38:48,  5.57it/s, lr=0.000253, step_loss=0.008407/27/2023 18:01:44 - INFO - __main__ - train loss is 27.40508455655072\n",
      "Steps:  14%|▏| 2032/15000 [16:54<38:47,  5.57it/s, lr=0.000253, step_loss=0.217]07/27/2023 18:01:44 - INFO - __main__ - train loss is 27.40849866264034\n",
      "Steps:  14%|▏| 2033/15000 [16:54<38:46,  5.57it/s, lr=0.000253, step_loss=0.003407/27/2023 18:01:44 - INFO - __main__ - train loss is 27.459915253450163\n",
      "Steps:  14%|▏| 2034/15000 [16:54<38:46,  5.57it/s, lr=0.000253, step_loss=0.051407/27/2023 18:01:44 - INFO - __main__ - train loss is 27.53724275820423\n",
      "Steps:  14%|▏| 2035/15000 [16:54<39:09,  5.52it/s, lr=0.000253, step_loss=0.077307/27/2023 18:01:44 - INFO - __main__ - train loss is 27.62571192078758\n",
      "Steps:  14%|▏| 2036/15000 [16:55<39:14,  5.51it/s, lr=0.000253, step_loss=0.088507/27/2023 18:01:45 - INFO - __main__ - train loss is 27.685097406734712\n",
      "Steps:  14%|▏| 2037/15000 [16:55<39:11,  5.51it/s, lr=0.000253, step_loss=0.059407/27/2023 18:01:45 - INFO - __main__ - train loss is 27.71262063004542\n",
      "Steps:  14%|▏| 2038/15000 [16:55<39:02,  5.53it/s, lr=0.000253, step_loss=0.027507/27/2023 18:01:45 - INFO - __main__ - train loss is 27.737804624368437\n",
      "Steps:  14%|▏| 2039/15000 [16:55<38:55,  5.55it/s, lr=0.000253, step_loss=0.025207/27/2023 18:01:45 - INFO - __main__ - train loss is 27.745415281620808\n",
      "Steps:  14%|▏| 2040/15000 [16:55<38:56,  5.55it/s, lr=0.000254, step_loss=0.007607/27/2023 18:01:45 - INFO - __main__ - train loss is 27.758396141347475\n",
      "Steps:  14%|▏| 2041/15000 [16:56<38:52,  5.56it/s, lr=0.000254, step_loss=0.013]07/27/2023 18:01:45 - INFO - __main__ - train loss is 27.94455715280492\n",
      "Steps:  14%|▏| 2042/15000 [16:56<38:48,  5.56it/s, lr=0.000254, step_loss=0.186]07/27/2023 18:01:46 - INFO - __main__ - train loss is 28.113673679647036\n",
      "Steps:  14%|▏| 2043/15000 [16:56<38:51,  5.56it/s, lr=0.000254, step_loss=0.169]07/27/2023 18:01:46 - INFO - __main__ - train loss is 28.173788651940413\n",
      "Steps:  14%|▏| 2044/15000 [16:56<38:49,  5.56it/s, lr=0.000254, step_loss=0.060107/27/2023 18:01:46 - INFO - __main__ - train loss is 28.444030508515425\n",
      "Steps:  14%|▎ | 2045/15000 [16:56<38:49,  5.56it/s, lr=0.000254, step_loss=0.27]07/27/2023 18:01:46 - INFO - __main__ - train loss is 28.475510634598322\n",
      "Steps:  14%|▏| 2046/15000 [16:56<38:46,  5.57it/s, lr=0.000254, step_loss=0.031507/27/2023 18:01:46 - INFO - __main__ - train loss is 28.748447157558985\n",
      "Steps:  14%|▏| 2047/15000 [16:57<38:55,  5.55it/s, lr=0.000255, step_loss=0.273]07/27/2023 18:01:47 - INFO - __main__ - train loss is 29.25039646786172\n",
      "Steps:  14%|▏| 2048/15000 [16:57<38:57,  5.54it/s, lr=0.000255, step_loss=0.502]07/27/2023 18:01:47 - INFO - __main__ - train loss is 29.38212870818097\n",
      "Steps:  14%|▏| 2049/15000 [16:57<39:00,  5.53it/s, lr=0.000255, step_loss=0.132]07/27/2023 18:01:47 - INFO - __main__ - train loss is 29.386915032868274\n",
      "Steps:  14%|▏| 2050/15000 [16:57<38:54,  5.55it/s, lr=0.000255, step_loss=0.004707/27/2023 18:01:47 - INFO - __main__ - train loss is 29.689422254567035\n",
      "Steps:  14%|▏| 2051/15000 [16:57<38:50,  5.56it/s, lr=0.000255, step_loss=0.303]07/27/2023 18:01:47 - INFO - __main__ - train loss is 29.752931405906565\n",
      "Steps:  14%|▏| 2052/15000 [16:58<38:55,  5.54it/s, lr=0.000255, step_loss=0.063507/27/2023 18:01:47 - INFO - __main__ - train loss is 29.792141673271544\n",
      "Steps:  14%|▏| 2053/15000 [16:58<39:24,  5.47it/s, lr=0.000255, step_loss=0.039207/27/2023 18:01:48 - INFO - __main__ - train loss is 29.897664320771582\n",
      "Steps:  14%|▏| 2054/15000 [16:58<39:31,  5.46it/s, lr=0.000255, step_loss=0.106]07/27/2023 18:01:48 - INFO - __main__ - train loss is 29.90207895322237\n",
      "Steps:  14%|▏| 2055/15000 [16:58<39:27,  5.47it/s, lr=0.000256, step_loss=0.004407/27/2023 18:01:48 - INFO - __main__ - train loss is 30.049809154705144\n",
      "Steps:  14%|▏| 2056/15000 [16:58<39:11,  5.50it/s, lr=0.000256, step_loss=0.148]07/27/2023 18:01:48 - INFO - __main__ - train loss is 30.274056103662588\n",
      "Steps:  14%|▏| 2057/15000 [16:58<39:23,  5.48it/s, lr=0.000256, step_loss=0.224]07/27/2023 18:01:48 - INFO - __main__ - train loss is 30.540487912134267\n",
      "Steps:  14%|▏| 2058/15000 [16:59<39:18,  5.49it/s, lr=0.000256, step_loss=0.266]07/27/2023 18:01:49 - INFO - __main__ - train loss is 30.568692979053594\n",
      "Steps:  14%|▏| 2059/15000 [16:59<39:06,  5.51it/s, lr=0.000256, step_loss=0.028207/27/2023 18:01:49 - INFO - __main__ - train loss is 30.618793238536455\n",
      "Steps:  14%|▏| 2060/15000 [16:59<38:58,  5.53it/s, lr=0.000256, step_loss=0.050107/27/2023 18:01:49 - INFO - __main__ - train loss is 31.21115123166237\n",
      "Steps:  14%|▏| 2061/15000 [16:59<39:13,  5.50it/s, lr=0.000256, step_loss=0.592]07/27/2023 18:01:49 - INFO - __main__ - train loss is 31.506675053969957\n",
      "Steps:  14%|▏| 2062/15000 [16:59<39:16,  5.49it/s, lr=0.000256, step_loss=0.296]07/27/2023 18:01:49 - INFO - __main__ - train loss is 31.579431955353357\n",
      "Steps:  14%|▏| 2063/15000 [17:00<39:06,  5.51it/s, lr=0.000257, step_loss=0.072807/27/2023 18:01:49 - INFO - __main__ - train loss is 31.77669325901661\n",
      "Steps:  14%|▏| 2064/15000 [17:00<38:59,  5.53it/s, lr=0.000257, step_loss=0.197]07/27/2023 18:01:50 - INFO - __main__ - train loss is 31.808191907242872\n",
      "Steps:  14%|▏| 2065/15000 [17:00<39:19,  5.48it/s, lr=0.000257, step_loss=0.031507/27/2023 18:01:50 - INFO - __main__ - train loss is 31.847677190438844\n",
      "Steps:  14%|▏| 2066/15000 [17:00<39:48,  5.41it/s, lr=0.000257, step_loss=0.039507/27/2023 18:01:50 - INFO - __main__ - train loss is 31.8837984619895\n",
      "Steps:  14%|▏| 2067/15000 [17:00<40:05,  5.38it/s, lr=0.000257, step_loss=0.036107/27/2023 18:01:50 - INFO - __main__ - train loss is 32.007491577998735\n",
      "Steps:  14%|▏| 2068/15000 [17:00<39:41,  5.43it/s, lr=0.000257, step_loss=0.124]07/27/2023 18:01:50 - INFO - __main__ - train loss is 32.070518676773645\n",
      "Steps:  14%|▏| 2069/15000 [17:01<39:23,  5.47it/s, lr=0.000257, step_loss=0.063]07/27/2023 18:01:51 - INFO - __main__ - train loss is 32.12888879014645\n",
      "Steps:  14%|▏| 2070/15000 [17:01<39:09,  5.50it/s, lr=0.000257, step_loss=0.058407/27/2023 18:01:51 - INFO - __main__ - train loss is 32.16914197488222\n",
      "Steps:  14%|▏| 2071/15000 [17:01<39:04,  5.51it/s, lr=0.000258, step_loss=0.040307/27/2023 18:01:51 - INFO - __main__ - train loss is 32.309400525526144\n",
      "Steps:  14%|▎ | 2072/15000 [17:01<38:56,  5.53it/s, lr=0.000258, step_loss=0.14]07/27/2023 18:01:51 - INFO - __main__ - train loss is 32.31576106662396\n",
      "Steps:  14%|▏| 2073/15000 [17:01<38:50,  5.55it/s, lr=0.000258, step_loss=0.006307/27/2023 18:01:51 - INFO - __main__ - train loss is 32.49909356946591\n",
      "Steps:  14%|▏| 2074/15000 [17:02<38:45,  5.56it/s, lr=0.000258, step_loss=0.183]07/27/2023 18:01:51 - INFO - __main__ - train loss is 32.52717255766038\n",
      "Steps:  14%|▏| 2075/15000 [17:02<38:42,  5.56it/s, lr=0.000258, step_loss=0.028107/27/2023 18:01:52 - INFO - __main__ - train loss is 32.6888962459052\n",
      "Steps:  14%|▏| 2076/15000 [17:02<38:59,  5.52it/s, lr=0.000258, step_loss=0.162]07/27/2023 18:01:52 - INFO - __main__ - train loss is 32.82154849881772\n",
      "Steps:  14%|▏| 2077/15000 [17:02<38:56,  5.53it/s, lr=0.000258, step_loss=0.133]07/27/2023 18:01:52 - INFO - __main__ - train loss is 32.90791846776847\n",
      "Steps:  14%|▏| 2078/15000 [17:02<38:50,  5.54it/s, lr=0.000258, step_loss=0.086407/27/2023 18:01:52 - INFO - __main__ - train loss is 33.030600338825025\n",
      "Steps:  14%|▏| 2079/15000 [17:02<38:46,  5.55it/s, lr=0.000258, step_loss=0.123]07/27/2023 18:01:52 - INFO - __main__ - train loss is 33.03541865537409\n",
      "Steps:  14%|▏| 2080/15000 [17:03<38:43,  5.56it/s, lr=0.000259, step_loss=0.004807/27/2023 18:01:52 - INFO - __main__ - train loss is 33.047034744755365\n",
      "Steps:  14%|▏| 2081/15000 [17:03<38:48,  5.55it/s, lr=0.000259, step_loss=0.011607/27/2023 18:01:53 - INFO - __main__ - train loss is 33.1973341597477\n",
      "Steps:  14%|▎ | 2082/15000 [17:03<38:52,  5.54it/s, lr=0.000259, step_loss=0.15]07/27/2023 18:01:53 - INFO - __main__ - train loss is 33.389426384703256\n",
      "Steps:  14%|▏| 2083/15000 [17:03<38:47,  5.55it/s, lr=0.000259, step_loss=0.192]07/27/2023 18:01:53 - INFO - __main__ - train loss is 33.4382911255816\n",
      "Steps:  14%|▏| 2084/15000 [17:03<38:43,  5.56it/s, lr=0.000259, step_loss=0.048907/27/2023 18:01:53 - INFO - __main__ - train loss is 33.44363118673209\n",
      "Steps:  14%|▏| 2085/15000 [17:04<38:39,  5.57it/s, lr=0.000259, step_loss=0.005307/27/2023 18:01:53 - INFO - __main__ - train loss is 33.48872529680375\n",
      "Steps:  14%|▏| 2086/15000 [17:04<38:37,  5.57it/s, lr=0.000259, step_loss=0.045107/27/2023 18:01:54 - INFO - __main__ - train loss is 33.50681231881026\n",
      "Steps:  14%|▏| 2087/15000 [17:04<38:42,  5.56it/s, lr=0.00026, step_loss=0.0181]07/27/2023 18:01:54 - INFO - __main__ - train loss is 33.595187760540284\n",
      "Steps:  14%|▏| 2088/15000 [17:04<38:39,  5.57it/s, lr=0.00026, step_loss=0.0884]07/27/2023 18:01:54 - INFO - __main__ - train loss is 33.59812876104843\n",
      "Steps:  14%|▏| 2089/15000 [17:04<38:36,  5.57it/s, lr=0.00026, step_loss=0.0029407/27/2023 18:01:54 - INFO - __main__ - train loss is 33.611309072817676\n",
      "Steps:  14%|▏| 2090/15000 [17:04<38:48,  5.55it/s, lr=0.00026, step_loss=0.0132]07/27/2023 18:01:54 - INFO - __main__ - train loss is 33.614585325238295\n",
      "Steps:  14%|▏| 2091/15000 [17:05<38:44,  5.55it/s, lr=0.00026, step_loss=0.0032807/27/2023 18:01:54 - INFO - __main__ - train loss is 33.61648420628626\n",
      "Steps:  14%|▏| 2092/15000 [17:05<38:47,  5.55it/s, lr=0.00026, step_loss=0.0019]07/27/2023 18:01:55 - INFO - __main__ - train loss is 33.748471479979344\n",
      "Steps:  14%|▎ | 2093/15000 [17:05<38:43,  5.56it/s, lr=0.00026, step_loss=0.132]07/27/2023 18:01:55 - INFO - __main__ - train loss is 34.0300231986912\n",
      "Steps:  14%|▎ | 2094/15000 [17:05<38:41,  5.56it/s, lr=0.00026, step_loss=0.282]07/27/2023 18:01:55 - INFO - __main__ - train loss is 34.04863824334461\n",
      "Steps:  14%|▏| 2095/15000 [17:05<38:38,  5.57it/s, lr=0.00026, step_loss=0.0186]07/27/2023 18:01:55 - INFO - __main__ - train loss is 34.21918389585335\n",
      "Steps:  14%|▏| 2096/15000 [17:06<38:35,  5.57it/s, lr=0.000261, step_loss=0.171]07/27/2023 18:01:55 - INFO - __main__ - train loss is 34.5263256469043\n",
      "Steps:  14%|▏| 2097/15000 [17:06<38:34,  5.58it/s, lr=0.000261, step_loss=0.307]07/27/2023 18:01:56 - INFO - __main__ - train loss is 34.68738623347599\n",
      "Steps:  14%|▏| 2098/15000 [17:06<38:34,  5.57it/s, lr=0.000261, step_loss=0.161]07/27/2023 18:01:56 - INFO - __main__ - train loss is 34.76889747765381\n",
      "Steps:  14%|▏| 2099/15000 [17:06<38:32,  5.58it/s, lr=0.000261, step_loss=0.081507/27/2023 18:01:56 - INFO - __main__ - train loss is 34.77780636784155\n",
      "Steps:  14%|▏| 2100/15000 [17:06<38:31,  5.58it/s, lr=0.000261, step_loss=0.008907/27/2023 18:01:56 - INFO - __main__ - train loss is 35.0514406823786\n",
      "Steps:  14%|▏| 2101/15000 [17:06<38:52,  5.53it/s, lr=0.000261, step_loss=0.274]07/27/2023 18:01:56 - INFO - __main__ - train loss is 35.074776936438866\n",
      "Steps:  14%|▏| 2102/15000 [17:07<38:57,  5.52it/s, lr=0.000261, step_loss=0.023307/27/2023 18:01:56 - INFO - __main__ - train loss is 35.651466895011254\n",
      "Steps:  14%|▏| 2103/15000 [17:07<38:59,  5.51it/s, lr=0.000262, step_loss=0.577]07/27/2023 18:01:57 - INFO - __main__ - train loss is 35.699978876975365\n",
      "Steps:  14%|▏| 2104/15000 [17:07<39:01,  5.51it/s, lr=0.000262, step_loss=0.048507/27/2023 18:01:57 - INFO - __main__ - train loss is 35.70182005467359\n",
      "Steps:  14%|▏| 2105/15000 [17:07<38:51,  5.53it/s, lr=0.000262, step_loss=0.001807/27/2023 18:01:57 - INFO - __main__ - train loss is 35.77348614635412\n",
      "Steps:  14%|▏| 2106/15000 [17:07<38:42,  5.55it/s, lr=0.000262, step_loss=0.071707/27/2023 18:01:57 - INFO - __main__ - train loss is 35.93911362590734\n",
      "Steps:  14%|▏| 2107/15000 [17:07<38:36,  5.57it/s, lr=0.000262, step_loss=0.166]07/27/2023 18:01:57 - INFO - __main__ - train loss is 36.04204210045282\n",
      "Steps:  14%|▏| 2108/15000 [17:08<38:32,  5.57it/s, lr=0.000262, step_loss=0.103]07/27/2023 18:01:58 - INFO - __main__ - train loss is 36.05345770868007\n",
      "Steps:  14%|▏| 2109/15000 [17:08<38:41,  5.55it/s, lr=0.000262, step_loss=0.011407/27/2023 18:01:58 - INFO - __main__ - train loss is 36.167811052524485\n",
      "Steps:  14%|▏| 2110/15000 [17:08<38:38,  5.56it/s, lr=0.000262, step_loss=0.114]07/27/2023 18:01:58 - INFO - __main__ - train loss is 36.361785040819086\n",
      "Steps:  14%|▏| 2111/15000 [17:08<38:34,  5.57it/s, lr=0.000263, step_loss=0.194]07/27/2023 18:01:58 - INFO - __main__ - train loss is 36.40932834299747\n",
      "Steps:  14%|▏| 2112/15000 [17:08<38:30,  5.58it/s, lr=0.000263, step_loss=0.047507/27/2023 18:01:58 - INFO - __main__ - train loss is 36.4147480657557\n",
      "Steps:  14%|▏| 2113/15000 [17:09<38:41,  5.55it/s, lr=0.000263, step_loss=0.005407/27/2023 18:01:58 - INFO - __main__ - train loss is 36.419599339482374\n",
      "Steps:  14%|▏| 2114/15000 [17:09<38:36,  5.56it/s, lr=0.000263, step_loss=0.004807/27/2023 18:01:59 - INFO - __main__ - train loss is 36.45531696092803\n",
      "Steps:  14%|▏| 2115/15000 [17:09<38:31,  5.57it/s, lr=0.000263, step_loss=0.035707/27/2023 18:01:59 - INFO - __main__ - train loss is 36.45961980812717\n",
      "Steps:  14%|▏| 2116/15000 [17:09<38:28,  5.58it/s, lr=0.000263, step_loss=0.004307/27/2023 18:01:59 - INFO - __main__ - train loss is 36.525180074502714\n",
      "Steps:  14%|▏| 2117/15000 [17:09<38:24,  5.59it/s, lr=0.000263, step_loss=0.065607/27/2023 18:01:59 - INFO - __main__ - train loss is 36.53146208834369\n",
      "Steps:  14%|▏| 2118/15000 [17:09<38:27,  5.58it/s, lr=0.000263, step_loss=0.006207/27/2023 18:01:59 - INFO - __main__ - train loss is 36.59026697289664\n",
      "Steps:  14%|▏| 2119/15000 [17:10<38:26,  5.58it/s, lr=0.000264, step_loss=0.058807/27/2023 18:02:00 - INFO - __main__ - train loss is 36.633577734348364\n",
      "Steps:  14%|▏| 2120/15000 [17:10<38:26,  5.58it/s, lr=0.000264, step_loss=0.043307/27/2023 18:02:00 - INFO - __main__ - train loss is 36.63481323455926\n",
      "Steps:  14%|▏| 2121/15000 [17:10<52:28,  4.09it/s, lr=0.000264, step_loss=0.001207/27/2023 18:02:01 - INFO - __main__ - Per validation step average loss is 0.1482088416814804\n",
      "07/27/2023 18:02:01 - INFO - __main__ - Cumulative validation average loss is 0.1482088416814804\n",
      "07/27/2023 18:02:01 - INFO - __main__ - Per validation step average loss is 0.04445198178291321\n",
      "07/27/2023 18:02:01 - INFO - __main__ - Cumulative validation average loss is 0.19266082346439362\n",
      "07/27/2023 18:02:02 - INFO - __main__ - Per validation step average loss is 0.0315878763794899\n",
      "07/27/2023 18:02:02 - INFO - __main__ - Cumulative validation average loss is 0.22424869984388351\n",
      "07/27/2023 18:02:02 - INFO - __main__ - Per validation step average loss is 0.09169881790876389\n",
      "07/27/2023 18:02:02 - INFO - __main__ - Cumulative validation average loss is 0.3159475177526474\n",
      "07/27/2023 18:02:03 - INFO - __main__ - Per validation step average loss is 0.20790433883666992\n",
      "07/27/2023 18:02:03 - INFO - __main__ - Cumulative validation average loss is 0.5238518565893173\n",
      "07/27/2023 18:02:03 - INFO - __main__ - Per validation step average loss is 0.2381206899881363\n",
      "07/27/2023 18:02:03 - INFO - __main__ - Cumulative validation average loss is 0.7619725465774536\n",
      "07/27/2023 18:02:03 - INFO - __main__ - Per validation step average loss is 0.0029681692831218243\n",
      "07/27/2023 18:02:03 - INFO - __main__ - Cumulative validation average loss is 0.7649407158605754\n",
      "07/27/2023 18:02:04 - INFO - __main__ - Per validation step average loss is 0.009889086708426476\n",
      "07/27/2023 18:02:04 - INFO - __main__ - Cumulative validation average loss is 0.7748298025690019\n",
      "07/27/2023 18:02:04 - INFO - __main__ - Per validation step average loss is 0.01504519023001194\n",
      "07/27/2023 18:02:04 - INFO - __main__ - Cumulative validation average loss is 0.7898749927990139\n",
      "07/27/2023 18:02:05 - INFO - __main__ - Per validation step average loss is 0.009997386485338211\n",
      "07/27/2023 18:02:05 - INFO - __main__ - Cumulative validation average loss is 0.7998723792843521\n",
      "07/27/2023 18:02:05 - INFO - __main__ - Per validation step average loss is 0.3997914791107178\n",
      "07/27/2023 18:02:05 - INFO - __main__ - Cumulative validation average loss is 1.1996638583950698\n",
      "07/27/2023 18:02:05 - INFO - __main__ - Per validation step average loss is 0.1962311863899231\n",
      "07/27/2023 18:02:05 - INFO - __main__ - Cumulative validation average loss is 1.395895044784993\n",
      "07/27/2023 18:02:06 - INFO - __main__ - Per validation step average loss is 0.4709550738334656\n",
      "07/27/2023 18:02:06 - INFO - __main__ - Cumulative validation average loss is 1.8668501186184585\n",
      "07/27/2023 18:02:06 - INFO - __main__ - Per validation step average loss is 0.010165227577090263\n",
      "07/27/2023 18:02:06 - INFO - __main__ - Cumulative validation average loss is 1.8770153461955488\n",
      "07/27/2023 18:02:07 - INFO - __main__ - Per validation step average loss is 0.030353736132383347\n",
      "07/27/2023 18:02:07 - INFO - __main__ - Cumulative validation average loss is 1.9073690823279321\n",
      "07/27/2023 18:02:07 - INFO - __main__ - Per validation step average loss is 0.11364202946424484\n",
      "07/27/2023 18:02:07 - INFO - __main__ - Cumulative validation average loss is 2.021011111792177\n",
      "07/27/2023 18:02:07 - INFO - __main__ - Per validation step average loss is 0.05594248324632645\n",
      "07/27/2023 18:02:07 - INFO - __main__ - Cumulative validation average loss is 2.0769535950385034\n",
      "07/27/2023 18:02:08 - INFO - __main__ - Per validation step average loss is 0.007641255855560303\n",
      "07/27/2023 18:02:08 - INFO - __main__ - Cumulative validation average loss is 2.0845948508940637\n",
      "07/27/2023 18:02:08 - INFO - __main__ - Per validation step average loss is 0.2740454077720642\n",
      "07/27/2023 18:02:08 - INFO - __main__ - Cumulative validation average loss is 2.358640258666128\n",
      "07/27/2023 18:02:09 - INFO - __main__ - Per validation step average loss is 0.012628188356757164\n",
      "07/27/2023 18:02:09 - INFO - __main__ - Cumulative validation average loss is 2.371268447022885\n",
      "07/27/2023 18:02:09 - INFO - __main__ - Per validation step average loss is 0.09790417551994324\n",
      "07/27/2023 18:02:09 - INFO - __main__ - Cumulative validation average loss is 2.4691726225428283\n",
      "07/27/2023 18:02:10 - INFO - __main__ - Per validation step average loss is 0.13280238211154938\n",
      "07/27/2023 18:02:10 - INFO - __main__ - Cumulative validation average loss is 2.6019750046543777\n",
      "07/27/2023 18:02:10 - INFO - __main__ - Per validation step average loss is 0.16385647654533386\n",
      "07/27/2023 18:02:10 - INFO - __main__ - Cumulative validation average loss is 2.7658314811997116\n",
      "07/27/2023 18:02:10 - INFO - __main__ - Per validation step average loss is 0.14503124356269836\n",
      "07/27/2023 18:02:10 - INFO - __main__ - Cumulative validation average loss is 2.91086272476241\n",
      "07/27/2023 18:02:11 - INFO - __main__ - Per validation step average loss is 0.07193724811077118\n",
      "07/27/2023 18:02:11 - INFO - __main__ - Cumulative validation average loss is 2.982799972873181\n",
      "07/27/2023 18:02:11 - INFO - __main__ - Per validation step average loss is 0.03358189016580582\n",
      "07/27/2023 18:02:11 - INFO - __main__ - Cumulative validation average loss is 3.016381863038987\n",
      "07/27/2023 18:02:12 - INFO - __main__ - Per validation step average loss is 0.034081317484378815\n",
      "07/27/2023 18:02:12 - INFO - __main__ - Cumulative validation average loss is 3.0504631805233657\n",
      "07/27/2023 18:02:12 - INFO - __main__ - Per validation step average loss is 0.1380486786365509\n",
      "07/27/2023 18:02:12 - INFO - __main__ - Cumulative validation average loss is 3.1885118591599166\n",
      "07/27/2023 18:02:12 - INFO - __main__ - Per validation step average loss is 0.26475828886032104\n",
      "07/27/2023 18:02:12 - INFO - __main__ - Cumulative validation average loss is 3.4532701480202377\n",
      "07/27/2023 18:02:13 - INFO - __main__ - Per validation step average loss is 0.03362409397959709\n",
      "07/27/2023 18:02:13 - INFO - __main__ - Cumulative validation average loss is 3.4868942419998348\n",
      "07/27/2023 18:02:13 - INFO - __main__ - Per validation step average loss is 0.15152907371520996\n",
      "07/27/2023 18:02:13 - INFO - __main__ - Cumulative validation average loss is 3.6384233157150447\n",
      "07/27/2023 18:02:14 - INFO - __main__ - Per validation step average loss is 0.016003839671611786\n",
      "07/27/2023 18:02:14 - INFO - __main__ - Cumulative validation average loss is 3.6544271553866565\n",
      "07/27/2023 18:02:14 - INFO - __main__ - Per validation step average loss is 0.04990023002028465\n",
      "07/27/2023 18:02:14 - INFO - __main__ - Cumulative validation average loss is 3.704327385406941\n",
      "07/27/2023 18:02:14 - INFO - __main__ - Per validation step average loss is 0.44589489698410034\n",
      "07/27/2023 18:02:14 - INFO - __main__ - Cumulative validation average loss is 4.1502222823910415\n",
      "07/27/2023 18:02:15 - INFO - __main__ - Per validation step average loss is 0.0078281220048666\n",
      "07/27/2023 18:02:15 - INFO - __main__ - Cumulative validation average loss is 4.158050404395908\n",
      "07/27/2023 18:02:15 - INFO - __main__ - Per validation step average loss is 0.028747521340847015\n",
      "07/27/2023 18:02:15 - INFO - __main__ - Cumulative validation average loss is 4.186797925736755\n",
      "07/27/2023 18:02:16 - INFO - __main__ - Per validation step average loss is 0.014215080067515373\n",
      "07/27/2023 18:02:16 - INFO - __main__ - Cumulative validation average loss is 4.2010130058042705\n",
      "07/27/2023 18:02:16 - INFO - __main__ - Per validation step average loss is 0.0017138852272182703\n",
      "07/27/2023 18:02:16 - INFO - __main__ - Cumulative validation average loss is 4.202726891031489\n",
      "07/27/2023 18:02:17 - INFO - __main__ - Per validation step average loss is 0.006584795191884041\n",
      "07/27/2023 18:02:17 - INFO - __main__ - Cumulative validation average loss is 4.209311686223373\n",
      "07/27/2023 18:02:17 - INFO - __main__ - Per validation step average loss is 0.1462114453315735\n",
      "07/27/2023 18:02:17 - INFO - __main__ - Cumulative validation average loss is 4.355523131554946\n",
      "07/27/2023 18:02:17 - INFO - __main__ - Per validation step average loss is 0.3714296817779541\n",
      "07/27/2023 18:02:17 - INFO - __main__ - Cumulative validation average loss is 4.7269528133329\n",
      "07/27/2023 18:02:18 - INFO - __main__ - Per validation step average loss is 0.1494540572166443\n",
      "07/27/2023 18:02:18 - INFO - __main__ - Cumulative validation average loss is 4.876406870549545\n",
      "07/27/2023 18:02:18 - INFO - __main__ - Per validation step average loss is 0.05963819473981857\n",
      "07/27/2023 18:02:18 - INFO - __main__ - Cumulative validation average loss is 4.936045065289363\n",
      "07/27/2023 18:02:19 - INFO - __main__ - Per validation step average loss is 0.09114013612270355\n",
      "07/27/2023 18:02:19 - INFO - __main__ - Cumulative validation average loss is 5.027185201412067\n",
      "07/27/2023 18:02:19 - INFO - __main__ - Per validation step average loss is 0.02407519519329071\n",
      "07/27/2023 18:02:19 - INFO - __main__ - Cumulative validation average loss is 5.0512603966053575\n",
      "07/27/2023 18:02:19 - INFO - __main__ - Per validation step average loss is 0.39896416664123535\n",
      "07/27/2023 18:02:19 - INFO - __main__ - Cumulative validation average loss is 5.450224563246593\n",
      "07/27/2023 18:02:20 - INFO - __main__ - Per validation step average loss is 0.1844034492969513\n",
      "07/27/2023 18:02:20 - INFO - __main__ - Cumulative validation average loss is 5.634628012543544\n",
      "07/27/2023 18:02:20 - INFO - __main__ - Per validation step average loss is 0.5679762363433838\n",
      "07/27/2023 18:02:20 - INFO - __main__ - Cumulative validation average loss is 6.202604248886928\n",
      "07/27/2023 18:02:21 - INFO - __main__ - Per validation step average loss is 0.13310973346233368\n",
      "07/27/2023 18:02:21 - INFO - __main__ - Cumulative validation average loss is 6.335713982349262\n",
      "07/27/2023 18:02:21 - INFO - __main__ - Per validation step average loss is 0.003981987480074167\n",
      "07/27/2023 18:02:21 - INFO - __main__ - Cumulative validation average loss is 6.339695969829336\n",
      "07/27/2023 18:02:21 - INFO - __main__ - Per validation step average loss is 0.0029032062739133835\n",
      "07/27/2023 18:02:21 - INFO - __main__ - Cumulative validation average loss is 6.342599176103249\n",
      "07/27/2023 18:02:22 - INFO - __main__ - Per validation step average loss is 0.21134480834007263\n",
      "07/27/2023 18:02:22 - INFO - __main__ - Cumulative validation average loss is 6.553943984443322\n",
      "07/27/2023 18:02:22 - INFO - __main__ - Per validation step average loss is 0.03148457780480385\n",
      "07/27/2023 18:02:22 - INFO - __main__ - Cumulative validation average loss is 6.585428562248126\n",
      "07/27/2023 18:02:23 - INFO - __main__ - Per validation step average loss is 0.20717734098434448\n",
      "07/27/2023 18:02:23 - INFO - __main__ - Cumulative validation average loss is 6.79260590323247\n",
      "07/27/2023 18:02:23 - INFO - __main__ - Per validation step average loss is 0.04458431154489517\n",
      "07/27/2023 18:02:23 - INFO - __main__ - Cumulative validation average loss is 6.837190214777365\n",
      "07/27/2023 18:02:24 - INFO - __main__ - Per validation step average loss is 0.0020987289026379585\n",
      "07/27/2023 18:02:24 - INFO - __main__ - Cumulative validation average loss is 6.839288943680003\n",
      "07/27/2023 18:02:24 - INFO - __main__ - Per validation step average loss is 0.10589781403541565\n",
      "07/27/2023 18:02:24 - INFO - __main__ - Cumulative validation average loss is 6.945186757715419\n",
      "07/27/2023 18:02:24 - INFO - __main__ - Per validation step average loss is 0.0067720250226557255\n",
      "07/27/2023 18:02:24 - INFO - __main__ - Cumulative validation average loss is 6.951958782738075\n",
      "07/27/2023 18:02:25 - INFO - __main__ - Per validation step average loss is 0.002113050315529108\n",
      "07/27/2023 18:02:25 - INFO - __main__ - Cumulative validation average loss is 6.954071833053604\n",
      "07/27/2023 18:02:25 - INFO - __main__ - Per validation step average loss is 0.014609142206609249\n",
      "07/27/2023 18:02:25 - INFO - __main__ - Cumulative validation average loss is 6.968680975260213\n",
      "07/27/2023 18:02:26 - INFO - __main__ - Per validation step average loss is 0.003275536000728607\n",
      "07/27/2023 18:02:26 - INFO - __main__ - Cumulative validation average loss is 6.971956511260942\n",
      "07/27/2023 18:02:26 - INFO - __main__ - Per validation step average loss is 0.013758872635662556\n",
      "07/27/2023 18:02:26 - INFO - __main__ - Cumulative validation average loss is 6.985715383896604\n",
      "07/27/2023 18:02:26 - INFO - __main__ - Per validation step average loss is 0.004254827741533518\n",
      "07/27/2023 18:02:26 - INFO - __main__ - Cumulative validation average loss is 6.989970211638138\n",
      "07/27/2023 18:02:27 - INFO - __main__ - Per validation step average loss is 0.013328757137060165\n",
      "07/27/2023 18:02:27 - INFO - __main__ - Cumulative validation average loss is 7.003298968775198\n",
      "07/27/2023 18:02:27 - INFO - __main__ - Per validation step average loss is 0.008625434711575508\n",
      "07/27/2023 18:02:27 - INFO - __main__ - Cumulative validation average loss is 7.011924403486773\n",
      "07/27/2023 18:02:28 - INFO - __main__ - Per validation step average loss is 0.6632676124572754\n",
      "07/27/2023 18:02:28 - INFO - __main__ - Cumulative validation average loss is 7.675192015944049\n",
      "07/27/2023 18:02:28 - INFO - __main__ - Per validation step average loss is 0.020141005516052246\n",
      "07/27/2023 18:02:28 - INFO - __main__ - Cumulative validation average loss is 7.695333021460101\n",
      "07/27/2023 18:02:29 - INFO - __main__ - Per validation step average loss is 0.00655874190852046\n",
      "07/27/2023 18:02:29 - INFO - __main__ - Cumulative validation average loss is 7.7018917633686215\n",
      "07/27/2023 18:02:29 - INFO - __main__ - Per validation step average loss is 0.33749768137931824\n",
      "07/27/2023 18:02:29 - INFO - __main__ - Cumulative validation average loss is 8.03938944474794\n",
      "07/27/2023 18:02:29 - INFO - __main__ - Per validation step average loss is 0.02948717772960663\n",
      "07/27/2023 18:02:29 - INFO - __main__ - Cumulative validation average loss is 8.068876622477546\n",
      "07/27/2023 18:02:30 - INFO - __main__ - Per validation step average loss is 0.03965868055820465\n",
      "07/27/2023 18:02:30 - INFO - __main__ - Cumulative validation average loss is 8.108535303035751\n",
      "07/27/2023 18:02:30 - INFO - __main__ - Per validation step average loss is 0.31457239389419556\n",
      "07/27/2023 18:02:30 - INFO - __main__ - Cumulative validation average loss is 8.423107696929947\n",
      "07/27/2023 18:02:31 - INFO - __main__ - Per validation step average loss is 0.04149803891777992\n",
      "07/27/2023 18:02:31 - INFO - __main__ - Cumulative validation average loss is 8.464605735847726\n",
      "07/27/2023 18:02:31 - INFO - __main__ - Per validation step average loss is 0.3768198490142822\n",
      "07/27/2023 18:02:31 - INFO - __main__ - Cumulative validation average loss is 8.841425584862009\n",
      "07/27/2023 18:02:31 - INFO - __main__ - Per validation step average loss is 0.018475599586963654\n",
      "07/27/2023 18:02:31 - INFO - __main__ - Cumulative validation average loss is 8.859901184448972\n",
      "07/27/2023 18:02:32 - INFO - __main__ - Per validation step average loss is 0.25488364696502686\n",
      "07/27/2023 18:02:32 - INFO - __main__ - Cumulative validation average loss is 9.114784831414\n",
      "07/27/2023 18:02:32 - INFO - __main__ - Per validation step average loss is 0.0291455015540123\n",
      "07/27/2023 18:02:32 - INFO - __main__ - Cumulative validation average loss is 9.143930332968011\n",
      "07/27/2023 18:02:33 - INFO - __main__ - Per validation step average loss is 0.08391894400119781\n",
      "07/27/2023 18:02:33 - INFO - __main__ - Cumulative validation average loss is 9.22784927696921\n",
      "07/27/2023 18:02:33 - INFO - __main__ - Per validation step average loss is 0.017625894397497177\n",
      "07/27/2023 18:02:33 - INFO - __main__ - Cumulative validation average loss is 9.245475171366706\n",
      "07/27/2023 18:02:33 - INFO - __main__ - Average validation loss for Epoch 6 is 0.11703133128312286\n",
      "07/27/2023 18:02:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:03:31 - INFO - __main__ - Starting epoch 7\n",
      "07/27/2023 18:03:31 - INFO - __main__ - train loss is 0.235122948884964\n",
      "Steps:  14%|▏| 2122/15000 [18:42<98:47:51, 27.62s/it, lr=0.000264, step_loss=0.207/27/2023 18:03:32 - INFO - __main__ - train loss is 0.33489739894866943\n",
      "Steps:  14%|▏| 2123/15000 [18:42<69:21:13, 19.39s/it, lr=0.000264, step_loss=0.007/27/2023 18:03:32 - INFO - __main__ - train loss is 0.3652990236878395\n",
      "Steps:  14%|▏| 2124/15000 [18:42<48:44:13, 13.63s/it, lr=0.000264, step_loss=0.007/27/2023 18:03:32 - INFO - __main__ - train loss is 0.4432748332619667\n",
      "Steps:  14%|▏| 2125/15000 [18:42<34:18:36,  9.59s/it, lr=0.000264, step_loss=0.007/27/2023 18:03:32 - INFO - __main__ - train loss is 0.6215608343482018\n",
      "Steps:  14%|▏| 2126/15000 [18:42<24:12:33,  6.77s/it, lr=0.000264, step_loss=0.107/27/2023 18:03:32 - INFO - __main__ - train loss is 0.6701910570263863\n",
      "Steps:  14%|▏| 2127/15000 [18:43<17:08:20,  4.79s/it, lr=0.000265, step_loss=0.007/27/2023 18:03:32 - INFO - __main__ - train loss is 0.733039066195488\n",
      "Steps:  14%|▏| 2128/15000 [18:43<12:11:35,  3.41s/it, lr=0.000265, step_loss=0.007/27/2023 18:03:33 - INFO - __main__ - train loss is 0.7399012083187699\n",
      "Steps:  14%|▏| 2129/15000 [18:43<8:43:58,  2.44s/it, lr=0.000265, step_loss=0.0007/27/2023 18:03:33 - INFO - __main__ - train loss is 0.8904277915135026\n",
      "Steps:  14%|▏| 2130/15000 [18:43<6:18:24,  1.76s/it, lr=0.000265, step_loss=0.1507/27/2023 18:03:33 - INFO - __main__ - train loss is 0.8988313023000956\n",
      "Steps:  14%|▏| 2131/15000 [18:43<4:36:32,  1.29s/it, lr=0.000265, step_loss=0.0007/27/2023 18:03:33 - INFO - __main__ - train loss is 1.52929144538939\n",
      "Steps:  14%|▏| 2132/15000 [18:44<3:25:10,  1.05it/s, lr=0.000265, step_loss=0.6307/27/2023 18:03:33 - INFO - __main__ - train loss is 1.5312713282182813\n",
      "Steps:  14%|▏| 2133/15000 [18:44<2:35:14,  1.38it/s, lr=0.000265, step_loss=0.0007/27/2023 18:03:34 - INFO - __main__ - train loss is 1.8090995149686933\n",
      "Steps:  14%|▏| 2134/15000 [18:44<2:00:17,  1.78it/s, lr=0.000265, step_loss=0.2707/27/2023 18:03:34 - INFO - __main__ - train loss is 1.8224992705509067\n",
      "Steps:  14%|▏| 2135/15000 [18:44<1:35:50,  2.24it/s, lr=0.000266, step_loss=0.0107/27/2023 18:03:34 - INFO - __main__ - train loss is 1.8246740261092782\n",
      "Steps:  14%|▏| 2136/15000 [18:44<1:18:46,  2.72it/s, lr=0.000266, step_loss=0.0007/27/2023 18:03:34 - INFO - __main__ - train loss is 1.82652353704907\n",
      "Steps:  14%|▏| 2137/15000 [18:44<1:06:51,  3.21it/s, lr=0.000266, step_loss=0.0007/27/2023 18:03:34 - INFO - __main__ - train loss is 1.9203484451863915\n",
      "Steps:  14%|▏| 2138/15000 [18:45<58:24,  3.67it/s, lr=0.000266, step_loss=0.093807/27/2023 18:03:34 - INFO - __main__ - train loss is 2.0157701468560845\n",
      "Steps:  14%|▏| 2139/15000 [18:45<52:33,  4.08it/s, lr=0.000266, step_loss=0.095407/27/2023 18:03:35 - INFO - __main__ - train loss is 2.052032927284017\n",
      "Steps:  14%|▏| 2140/15000 [18:45<48:28,  4.42it/s, lr=0.000266, step_loss=0.036307/27/2023 18:03:35 - INFO - __main__ - train loss is 2.291926527628675\n",
      "Steps:  14%|▎ | 2141/15000 [18:45<46:06,  4.65it/s, lr=0.000266, step_loss=0.24]07/27/2023 18:03:35 - INFO - __main__ - train loss is 2.296171813039109\n",
      "Steps:  14%|▏| 2142/15000 [18:45<50:44,  4.22it/s, lr=0.000266, step_loss=0.004207/27/2023 18:03:35 - INFO - __main__ - train loss is 2.345862465677783\n",
      "Steps:  14%|▏| 2143/15000 [18:46<48:54,  4.38it/s, lr=0.000267, step_loss=0.049707/27/2023 18:03:36 - INFO - __main__ - train loss is 2.6684354718308896\n",
      "[2023-07-27 18:03:36,138] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:  14%|▏| 2144/15000 [18:46<46:33,  4.60it/s, lr=0.000267, step_loss=0.323]07/27/2023 18:03:36 - INFO - __main__ - train loss is 2.6708081422839314\n",
      "Steps:  14%|▏| 2145/15000 [18:46<44:07,  4.86it/s, lr=0.000267, step_loss=0.002307/27/2023 18:03:36 - INFO - __main__ - train loss is 2.694388365605846\n",
      "Steps:  14%|▏| 2146/15000 [18:46<42:41,  5.02it/s, lr=0.000267, step_loss=0.023607/27/2023 18:03:36 - INFO - __main__ - train loss is 2.7565049997065216\n",
      "Steps:  14%|▏| 2147/15000 [18:46<41:32,  5.16it/s, lr=0.000267, step_loss=0.062107/27/2023 18:03:36 - INFO - __main__ - train loss is 2.937653141329065\n",
      "Steps:  14%|▏| 2148/15000 [18:47<40:43,  5.26it/s, lr=0.000267, step_loss=0.181]07/27/2023 18:03:36 - INFO - __main__ - train loss is 2.9420373716857284\n",
      "Steps:  14%|▏| 2149/15000 [18:47<40:02,  5.35it/s, lr=0.000267, step_loss=0.004307/27/2023 18:03:37 - INFO - __main__ - train loss is 3.0565756985452026\n",
      "Steps:  14%|▏| 2150/15000 [18:47<39:34,  5.41it/s, lr=0.000267, step_loss=0.115]07/27/2023 18:03:37 - INFO - __main__ - train loss is 3.409105939557776\n",
      "Steps:  14%|▏| 2151/15000 [18:47<39:32,  5.42it/s, lr=0.000267, step_loss=0.353]07/27/2023 18:03:37 - INFO - __main__ - train loss is 3.4256964528467506\n",
      "Steps:  14%|▏| 2152/15000 [18:47<39:11,  5.46it/s, lr=0.000267, step_loss=0.016607/27/2023 18:03:37 - INFO - __main__ - train loss is 3.4295854072552174\n",
      "Steps:  14%|▏| 2153/15000 [18:47<39:15,  5.45it/s, lr=0.000268, step_loss=0.003807/27/2023 18:03:37 - INFO - __main__ - train loss is 3.6425335358362645\n",
      "Steps:  14%|▏| 2154/15000 [18:48<39:03,  5.48it/s, lr=0.000268, step_loss=0.213]07/27/2023 18:03:38 - INFO - __main__ - train loss is 3.671388442395255\n",
      "Steps:  14%|▏| 2155/15000 [18:48<38:56,  5.50it/s, lr=0.000268, step_loss=0.028907/27/2023 18:03:38 - INFO - __main__ - train loss is 3.704233943251893\n",
      "Steps:  14%|▏| 2156/15000 [18:48<38:45,  5.52it/s, lr=0.000268, step_loss=0.032807/27/2023 18:03:38 - INFO - __main__ - train loss is 3.890911965398118\n",
      "Steps:  14%|▏| 2157/15000 [18:48<38:37,  5.54it/s, lr=0.000268, step_loss=0.187]07/27/2023 18:03:38 - INFO - __main__ - train loss is 3.9072424869518727\n",
      "Steps:  14%|▏| 2158/15000 [18:48<38:54,  5.50it/s, lr=0.000268, step_loss=0.016307/27/2023 18:03:38 - INFO - __main__ - train loss is 4.1749270658474416\n",
      "Steps:  14%|▏| 2159/15000 [18:49<38:50,  5.51it/s, lr=0.000268, step_loss=0.268]07/27/2023 18:03:38 - INFO - __main__ - train loss is 4.298993962584063\n",
      "Steps:  14%|▏| 2160/15000 [18:49<38:40,  5.53it/s, lr=0.000269, step_loss=0.124]07/27/2023 18:03:39 - INFO - __main__ - train loss is 4.415976638672873\n",
      "Steps:  14%|▏| 2161/15000 [18:49<38:34,  5.55it/s, lr=0.000269, step_loss=0.117]07/27/2023 18:03:39 - INFO - __main__ - train loss is 4.5118092994671315\n",
      "Steps:  14%|▏| 2162/15000 [18:49<38:49,  5.51it/s, lr=0.000269, step_loss=0.095807/27/2023 18:03:39 - INFO - __main__ - train loss is 5.114055583951995\n",
      "Steps:  14%|▏| 2163/15000 [18:49<38:52,  5.50it/s, lr=0.000269, step_loss=0.602]07/27/2023 18:03:39 - INFO - __main__ - train loss is 5.188173147616908\n",
      "Steps:  14%|▏| 2164/15000 [18:49<39:24,  5.43it/s, lr=0.000269, step_loss=0.074107/27/2023 18:03:39 - INFO - __main__ - train loss is 5.2037200254853815\n",
      "Steps:  14%|▏| 2165/15000 [18:50<39:17,  5.44it/s, lr=0.000269, step_loss=0.015507/27/2023 18:03:40 - INFO - __main__ - train loss is 5.20763403759338\n",
      "Steps:  14%|▏| 2166/15000 [18:50<39:05,  5.47it/s, lr=0.000269, step_loss=0.003907/27/2023 18:03:40 - INFO - __main__ - train loss is 5.316281704464927\n",
      "Steps:  14%|▏| 2167/15000 [18:50<38:51,  5.50it/s, lr=0.000269, step_loss=0.109]07/27/2023 18:03:40 - INFO - __main__ - train loss is 5.432704789796844\n",
      "Steps:  14%|▎ | 2168/15000 [18:50<38:42,  5.53it/s, lr=0.00027, step_loss=0.116]07/27/2023 18:03:40 - INFO - __main__ - train loss is 5.442461752565578\n",
      "Steps:  14%|▏| 2169/15000 [18:50<38:44,  5.52it/s, lr=0.00027, step_loss=0.0097607/27/2023 18:03:40 - INFO - __main__ - train loss is 5.571489938767627\n",
      "Steps:  14%|▎ | 2170/15000 [18:51<38:34,  5.54it/s, lr=0.00027, step_loss=0.129]07/27/2023 18:03:40 - INFO - __main__ - train loss is 5.575454463949427\n",
      "Steps:  14%|▏| 2171/15000 [18:51<38:29,  5.55it/s, lr=0.00027, step_loss=0.0039607/27/2023 18:03:41 - INFO - __main__ - train loss is 5.590122012188658\n",
      "Steps:  14%|▏| 2172/15000 [18:51<38:28,  5.56it/s, lr=0.00027, step_loss=0.0147]07/27/2023 18:03:41 - INFO - __main__ - train loss is 5.59307664190419\n",
      "Steps:  14%|▏| 2173/15000 [18:51<38:25,  5.56it/s, lr=0.00027, step_loss=0.0029507/27/2023 18:03:41 - INFO - __main__ - train loss is 5.870489354478195\n",
      "Steps:  14%|▎ | 2174/15000 [18:51<38:22,  5.57it/s, lr=0.00027, step_loss=0.277]07/27/2023 18:03:41 - INFO - __main__ - train loss is 5.978789757238701\n",
      "Steps:  14%|▎ | 2175/15000 [18:51<38:36,  5.54it/s, lr=0.00027, step_loss=0.108]07/27/2023 18:03:41 - INFO - __main__ - train loss is 6.2817883000243455\n",
      "Steps:  15%|▏| 2176/15000 [18:52<38:31,  5.55it/s, lr=0.000271, step_loss=0.303]07/27/2023 18:03:42 - INFO - __main__ - train loss is 6.531074847327545\n",
      "Steps:  15%|▏| 2177/15000 [18:52<38:26,  5.56it/s, lr=0.000271, step_loss=0.249]07/27/2023 18:03:42 - INFO - __main__ - train loss is 6.768935318337753\n",
      "Steps:  15%|▏| 2178/15000 [18:52<38:42,  5.52it/s, lr=0.000271, step_loss=0.238]07/27/2023 18:03:42 - INFO - __main__ - train loss is 6.7896617979276925\n",
      "Steps:  15%|▏| 2179/15000 [18:52<38:35,  5.54it/s, lr=0.000271, step_loss=0.020707/27/2023 18:03:42 - INFO - __main__ - train loss is 6.860989700304344\n",
      "Steps:  15%|▏| 2180/15000 [18:52<38:30,  5.55it/s, lr=0.000271, step_loss=0.071307/27/2023 18:03:42 - INFO - __main__ - train loss is 7.256800006376579\n",
      "Steps:  15%|▏| 2181/15000 [18:53<38:51,  5.50it/s, lr=0.000271, step_loss=0.396]07/27/2023 18:03:42 - INFO - __main__ - train loss is 7.264628044562414\n",
      "Steps:  15%|▏| 2182/15000 [18:53<38:55,  5.49it/s, lr=0.000271, step_loss=0.007807/27/2023 18:03:43 - INFO - __main__ - train loss is 7.639425776200369\n",
      "Steps:  15%|▏| 2183/15000 [18:53<39:06,  5.46it/s, lr=0.000271, step_loss=0.375]07/27/2023 18:03:43 - INFO - __main__ - train loss is 7.791088319616392\n",
      "Steps:  15%|▏| 2184/15000 [18:53<39:00,  5.48it/s, lr=0.000272, step_loss=0.152]07/27/2023 18:03:43 - INFO - __main__ - train loss is 8.116814649896696\n",
      "Steps:  15%|▏| 2185/15000 [18:53<38:46,  5.51it/s, lr=0.000272, step_loss=0.326]07/27/2023 18:03:43 - INFO - __main__ - train loss is 8.146376277552918\n",
      "Steps:  15%|▏| 2186/15000 [18:53<38:36,  5.53it/s, lr=0.000272, step_loss=0.029607/27/2023 18:03:43 - INFO - __main__ - train loss is 8.273004855262116\n",
      "Steps:  15%|▏| 2187/15000 [18:54<38:29,  5.55it/s, lr=0.000272, step_loss=0.127]07/27/2023 18:03:44 - INFO - __main__ - train loss is 8.293353009270504\n",
      "Steps:  15%|▏| 2188/15000 [18:54<38:24,  5.56it/s, lr=0.000272, step_loss=0.020307/27/2023 18:03:44 - INFO - __main__ - train loss is 8.412259894656017\n",
      "Steps:  15%|▏| 2189/15000 [18:54<38:20,  5.57it/s, lr=0.000272, step_loss=0.119]07/27/2023 18:03:44 - INFO - __main__ - train loss is 8.417111575836316\n",
      "Steps:  15%|▏| 2190/15000 [18:54<38:18,  5.57it/s, lr=0.000272, step_loss=0.004807/27/2023 18:03:44 - INFO - __main__ - train loss is 8.615163401002064\n",
      "Steps:  15%|▏| 2191/15000 [18:54<38:26,  5.55it/s, lr=0.000272, step_loss=0.198]07/27/2023 18:03:44 - INFO - __main__ - train loss is 8.7025177704636\n",
      "Steps:  15%|▏| 2192/15000 [18:55<38:25,  5.56it/s, lr=0.000273, step_loss=0.087407/27/2023 18:03:44 - INFO - __main__ - train loss is 8.704674365697429\n",
      "Steps:  15%|▏| 2193/15000 [18:55<38:22,  5.56it/s, lr=0.000273, step_loss=0.002107/27/2023 18:03:45 - INFO - __main__ - train loss is 8.732241910649464\n",
      "Steps:  15%|▏| 2194/15000 [18:55<38:19,  5.57it/s, lr=0.000273, step_loss=0.027607/27/2023 18:03:45 - INFO - __main__ - train loss is 8.734572134446353\n",
      "Steps:  15%|▏| 2195/15000 [18:55<38:20,  5.57it/s, lr=0.000273, step_loss=0.002307/27/2023 18:03:45 - INFO - __main__ - train loss is 9.276372275780886\n",
      "Steps:  15%|▏| 2196/15000 [18:55<38:30,  5.54it/s, lr=0.000273, step_loss=0.542]07/27/2023 18:03:45 - INFO - __main__ - train loss is 9.28134183306247\n",
      "Steps:  15%|▏| 2197/15000 [18:55<38:29,  5.54it/s, lr=0.000273, step_loss=0.004907/27/2023 18:03:45 - INFO - __main__ - train loss is 9.303206815384328\n",
      "Steps:  15%|▏| 2198/15000 [18:56<38:27,  5.55it/s, lr=0.000273, step_loss=0.021907/27/2023 18:03:45 - INFO - __main__ - train loss is 9.311477777548134\n",
      "Steps:  15%|▏| 2199/15000 [18:56<38:30,  5.54it/s, lr=0.000273, step_loss=0.008207/27/2023 18:03:46 - INFO - __main__ - train loss is 9.568905469961464\n",
      "Steps:  15%|▏| 2200/15000 [18:56<38:41,  5.51it/s, lr=0.000274, step_loss=0.257]07/27/2023 18:03:46 - INFO - __main__ - train loss is 9.613849361427128\n",
      "Steps:  15%|▏| 2201/15000 [18:56<38:52,  5.49it/s, lr=0.000274, step_loss=0.044907/27/2023 18:03:46 - INFO - __main__ - train loss is 9.737468902952969\n",
      "Steps:  15%|▏| 2202/15000 [18:56<38:41,  5.51it/s, lr=0.000274, step_loss=0.124]07/27/2023 18:03:46 - INFO - __main__ - train loss is 9.886755202896893\n",
      "Steps:  15%|▏| 2203/15000 [18:57<38:32,  5.53it/s, lr=0.000274, step_loss=0.149]07/27/2023 18:03:46 - INFO - __main__ - train loss is 10.03129464853555\n",
      "Steps:  15%|▏| 2204/15000 [18:57<38:25,  5.55it/s, lr=0.000274, step_loss=0.145]07/27/2023 18:03:47 - INFO - __main__ - train loss is 10.051076003350317\n",
      "Steps:  15%|▏| 2205/15000 [18:57<38:28,  5.54it/s, lr=0.000274, step_loss=0.019807/27/2023 18:03:47 - INFO - __main__ - train loss is 10.057188535109162\n",
      "Steps:  15%|▏| 2206/15000 [18:57<38:22,  5.56it/s, lr=0.000274, step_loss=0.006107/27/2023 18:03:47 - INFO - __main__ - train loss is 10.14127635397017\n",
      "Steps:  15%|▏| 2207/15000 [18:57<38:20,  5.56it/s, lr=0.000274, step_loss=0.084107/27/2023 18:03:47 - INFO - __main__ - train loss is 10.257917338982224\n",
      "Steps:  15%|▏| 2208/15000 [18:57<38:18,  5.57it/s, lr=0.000275, step_loss=0.117]07/27/2023 18:03:47 - INFO - __main__ - train loss is 10.402190769091249\n",
      "Steps:  15%|▏| 2209/15000 [18:58<38:16,  5.57it/s, lr=0.000275, step_loss=0.144]07/27/2023 18:03:47 - INFO - __main__ - train loss is 10.56104319728911\n",
      "Steps:  15%|▏| 2210/15000 [18:58<38:16,  5.57it/s, lr=0.000275, step_loss=0.159]07/27/2023 18:03:48 - INFO - __main__ - train loss is 10.68255870230496\n",
      "Steps:  15%|▏| 2211/15000 [18:58<38:20,  5.56it/s, lr=0.000275, step_loss=0.122]07/27/2023 18:03:48 - INFO - __main__ - train loss is 10.900390567258\n",
      "Steps:  15%|▏| 2212/15000 [18:58<38:17,  5.57it/s, lr=0.000275, step_loss=0.218]07/27/2023 18:03:48 - INFO - __main__ - train loss is 11.145802380517125\n",
      "Steps:  15%|▏| 2213/15000 [18:58<38:16,  5.57it/s, lr=0.000275, step_loss=0.245]07/27/2023 18:03:48 - INFO - __main__ - train loss is 11.147220317739993\n",
      "Steps:  15%|▏| 2214/15000 [18:59<38:28,  5.54it/s, lr=0.000275, step_loss=0.001407/27/2023 18:03:48 - INFO - __main__ - train loss is 11.360273574013263\n",
      "Steps:  15%|▏| 2215/15000 [18:59<38:22,  5.55it/s, lr=0.000275, step_loss=0.213]07/27/2023 18:03:49 - INFO - __main__ - train loss is 11.506672714371234\n",
      "Steps:  15%|▏| 2216/15000 [18:59<38:19,  5.56it/s, lr=0.000276, step_loss=0.146]07/27/2023 18:03:49 - INFO - __main__ - train loss is 11.886791412252933\n",
      "Steps:  15%|▎ | 2217/15000 [18:59<38:18,  5.56it/s, lr=0.000276, step_loss=0.38]07/27/2023 18:03:49 - INFO - __main__ - train loss is 12.047752414364368\n",
      "Steps:  15%|▏| 2218/15000 [18:59<38:16,  5.57it/s, lr=0.000276, step_loss=0.161]07/27/2023 18:03:49 - INFO - __main__ - train loss is 12.14599457802251\n",
      "Steps:  15%|▏| 2219/15000 [18:59<38:40,  5.51it/s, lr=0.000276, step_loss=0.098207/27/2023 18:03:49 - INFO - __main__ - train loss is 12.216078717727214\n",
      "Steps:  15%|▏| 2220/15000 [19:00<38:32,  5.53it/s, lr=0.000276, step_loss=0.070107/27/2023 18:03:49 - INFO - __main__ - train loss is 12.377414007205516\n",
      "Steps:  15%|▏| 2221/15000 [19:00<38:24,  5.54it/s, lr=0.000276, step_loss=0.161]07/27/2023 18:03:50 - INFO - __main__ - train loss is 13.261551995296031\n",
      "Steps:  15%|▏| 2222/15000 [19:00<38:20,  5.55it/s, lr=0.000276, step_loss=0.884]07/27/2023 18:03:50 - INFO - __main__ - train loss is 13.28704070718959\n",
      "Steps:  15%|▏| 2223/15000 [19:00<38:16,  5.56it/s, lr=0.000276, step_loss=0.025507/27/2023 18:03:50 - INFO - __main__ - train loss is 13.2968262671493\n",
      "Steps:  15%|▏| 2224/15000 [19:00<38:14,  5.57it/s, lr=0.000277, step_loss=0.009707/27/2023 18:03:50 - INFO - __main__ - train loss is 13.321435736026615\n",
      "Steps:  15%|▏| 2225/15000 [19:00<38:15,  5.57it/s, lr=0.000277, step_loss=0.024607/27/2023 18:03:50 - INFO - __main__ - train loss is 13.359037355985492\n",
      "Steps:  15%|▏| 2226/15000 [19:01<38:14,  5.57it/s, lr=0.000277, step_loss=0.037607/27/2023 18:03:51 - INFO - __main__ - train loss is 13.363187307491899\n",
      "Steps:  15%|▏| 2227/15000 [19:01<38:15,  5.57it/s, lr=0.000277, step_loss=0.004107/27/2023 18:03:51 - INFO - __main__ - train loss is 13.48333608545363\n",
      "Steps:  15%|▎ | 2228/15000 [19:01<38:35,  5.52it/s, lr=0.000277, step_loss=0.12]07/27/2023 18:03:51 - INFO - __main__ - train loss is 13.595910111442208\n",
      "Steps:  15%|▏| 2229/15000 [19:01<38:37,  5.51it/s, lr=0.000277, step_loss=0.113]07/27/2023 18:03:51 - INFO - __main__ - train loss is 13.807552168145776\n",
      "Steps:  15%|▏| 2230/15000 [19:01<38:43,  5.50it/s, lr=0.000277, step_loss=0.212]07/27/2023 18:03:51 - INFO - __main__ - train loss is 13.812718805857003\n",
      "Steps:  15%|▏| 2231/15000 [19:02<39:05,  5.44it/s, lr=0.000277, step_loss=0.005107/27/2023 18:03:51 - INFO - __main__ - train loss is 14.481083867140114\n",
      "Steps:  15%|▏| 2232/15000 [19:02<39:15,  5.42it/s, lr=0.000278, step_loss=0.668]07/27/2023 18:03:52 - INFO - __main__ - train loss is 15.284054753370583\n",
      "Steps:  15%|▏| 2233/15000 [19:02<39:05,  5.44it/s, lr=0.000278, step_loss=0.803]07/27/2023 18:03:52 - INFO - __main__ - train loss is 15.286823766771704\n",
      "Steps:  15%|▏| 2234/15000 [19:02<39:05,  5.44it/s, lr=0.000278, step_loss=0.002707/27/2023 18:03:52 - INFO - __main__ - train loss is 15.40958439046517\n",
      "Steps:  15%|▏| 2235/15000 [19:02<38:58,  5.46it/s, lr=0.000278, step_loss=0.123]07/27/2023 18:03:52 - INFO - __main__ - train loss is 15.424147803802043\n",
      "Steps:  15%|▏| 2236/15000 [19:03<38:42,  5.49it/s, lr=0.000278, step_loss=0.014607/27/2023 18:03:52 - INFO - __main__ - train loss is 15.43271662434563\n",
      "Steps:  15%|▏| 2237/15000 [19:03<38:33,  5.52it/s, lr=0.000278, step_loss=0.008507/27/2023 18:03:53 - INFO - __main__ - train loss is 15.44169121189043\n",
      "Steps:  15%|▏| 2238/15000 [19:03<38:26,  5.53it/s, lr=0.000278, step_loss=0.008907/27/2023 18:03:53 - INFO - __main__ - train loss is 15.45035764342174\n",
      "Steps:  15%|▏| 2239/15000 [19:03<38:43,  5.49it/s, lr=0.000278, step_loss=0.008607/27/2023 18:03:53 - INFO - __main__ - train loss is 15.509817918296903\n",
      "Steps:  15%|▏| 2240/15000 [19:03<38:38,  5.50it/s, lr=0.000279, step_loss=0.059507/27/2023 18:03:53 - INFO - __main__ - train loss is 15.824013104196638\n",
      "Steps:  15%|▏| 2241/15000 [19:03<38:27,  5.53it/s, lr=0.000279, step_loss=0.314]07/27/2023 18:03:53 - INFO - __main__ - train loss is 15.897595753427595\n",
      "Steps:  15%|▏| 2242/15000 [19:04<38:19,  5.55it/s, lr=0.000279, step_loss=0.073607/27/2023 18:03:53 - INFO - __main__ - train loss is 15.948791266884655\n",
      "Steps:  15%|▏| 2243/15000 [19:04<38:15,  5.56it/s, lr=0.000279, step_loss=0.051207/27/2023 18:03:54 - INFO - __main__ - train loss is 15.957337345462292\n",
      "Steps:  15%|▏| 2244/15000 [19:04<38:11,  5.57it/s, lr=0.000279, step_loss=0.008507/27/2023 18:03:54 - INFO - __main__ - train loss is 15.964555070269853\n",
      "Steps:  15%|▏| 2245/15000 [19:04<38:09,  5.57it/s, lr=0.000279, step_loss=0.007207/27/2023 18:03:54 - INFO - __main__ - train loss is 15.992225671652704\n",
      "Steps:  15%|▏| 2246/15000 [19:04<38:10,  5.57it/s, lr=0.000279, step_loss=0.027707/27/2023 18:03:54 - INFO - __main__ - train loss is 16.168432200793177\n",
      "Steps:  15%|▏| 2247/15000 [19:04<38:20,  5.54it/s, lr=0.000279, step_loss=0.176]07/27/2023 18:03:54 - INFO - __main__ - train loss is 16.32729154312983\n",
      "Steps:  15%|▎ | 2248/15000 [19:05<38:17,  5.55it/s, lr=0.00028, step_loss=0.159]07/27/2023 18:03:55 - INFO - __main__ - train loss is 16.550735706929117\n",
      "Steps:  15%|▎ | 2249/15000 [19:05<38:17,  5.55it/s, lr=0.00028, step_loss=0.223]07/27/2023 18:03:55 - INFO - __main__ - train loss is 16.558989020530134\n",
      "Steps:  15%|▏| 2250/15000 [19:05<38:14,  5.56it/s, lr=0.00028, step_loss=0.0082507/27/2023 18:03:55 - INFO - __main__ - train loss is 16.563099102582783\n",
      "Steps:  15%|▏| 2251/15000 [19:05<38:13,  5.56it/s, lr=0.00028, step_loss=0.0041107/27/2023 18:03:55 - INFO - __main__ - train loss is 16.58927059872076\n",
      "Steps:  15%|▏| 2252/15000 [19:05<38:18,  5.55it/s, lr=0.00028, step_loss=0.0262]07/27/2023 18:03:55 - INFO - __main__ - train loss is 16.696241445373744\n",
      "Steps:  15%|▎ | 2253/15000 [19:06<38:15,  5.55it/s, lr=0.00028, step_loss=0.107]07/27/2023 18:03:55 - INFO - __main__ - train loss is 16.703340040054172\n",
      "Steps:  15%|▏| 2254/15000 [19:06<38:12,  5.56it/s, lr=0.00028, step_loss=0.0071]07/27/2023 18:03:56 - INFO - __main__ - train loss is 16.70479814358987\n",
      "Steps:  15%|▏| 2255/15000 [19:06<38:39,  5.49it/s, lr=0.00028, step_loss=0.0014607/27/2023 18:03:56 - INFO - __main__ - train loss is 16.72364624054171\n",
      "Steps:  15%|▏| 2256/15000 [19:06<38:57,  5.45it/s, lr=0.000281, step_loss=0.018807/27/2023 18:03:56 - INFO - __main__ - train loss is 16.729051066329703\n",
      "Steps:  15%|▏| 2257/15000 [19:06<38:48,  5.47it/s, lr=0.000281, step_loss=0.005407/27/2023 18:03:56 - INFO - __main__ - train loss is 16.754578931024298\n",
      "Steps:  15%|▏| 2258/15000 [19:06<38:35,  5.50it/s, lr=0.000281, step_loss=0.025507/27/2023 18:03:56 - INFO - __main__ - train loss is 17.004729909589514\n",
      "Steps:  15%|▎ | 2259/15000 [19:07<38:37,  5.50it/s, lr=0.000281, step_loss=0.25]07/27/2023 18:03:57 - INFO - __main__ - train loss is 17.275372786214575\n",
      "Steps:  15%|▏| 2260/15000 [19:07<38:38,  5.49it/s, lr=0.000281, step_loss=0.271]07/27/2023 18:03:57 - INFO - __main__ - train loss is 17.33435850753449\n",
      "Steps:  15%|▏| 2261/15000 [19:07<38:28,  5.52it/s, lr=0.000281, step_loss=0.059]07/27/2023 18:03:57 - INFO - __main__ - train loss is 17.97873323573731\n",
      "Steps:  15%|▏| 2262/15000 [19:07<38:43,  5.48it/s, lr=0.000281, step_loss=0.644]07/27/2023 18:03:57 - INFO - __main__ - train loss is 18.019259253283963\n",
      "Steps:  15%|▏| 2263/15000 [19:07<38:57,  5.45it/s, lr=0.000281, step_loss=0.040507/27/2023 18:03:57 - INFO - __main__ - train loss is 18.03930246992968\n",
      "Steps:  15%|▎ | 2264/15000 [19:08<39:03,  5.43it/s, lr=0.000281, step_loss=0.02]07/27/2023 18:03:57 - INFO - __main__ - train loss is 18.276786194881424\n",
      "Steps:  15%|▏| 2265/15000 [19:08<39:15,  5.41it/s, lr=0.000282, step_loss=0.237]07/27/2023 18:03:58 - INFO - __main__ - train loss is 18.280196053674445\n",
      "Steps:  15%|▏| 2266/15000 [19:08<39:07,  5.42it/s, lr=0.000282, step_loss=0.003407/27/2023 18:03:58 - INFO - __main__ - train loss is 18.33101130812429\n",
      "Steps:  15%|▏| 2267/15000 [19:08<39:12,  5.41it/s, lr=0.000282, step_loss=0.050807/27/2023 18:03:58 - INFO - __main__ - train loss is 18.590633107116446\n",
      "Steps:  15%|▎ | 2268/15000 [19:08<39:06,  5.43it/s, lr=0.000282, step_loss=0.26]07/27/2023 18:03:58 - INFO - __main__ - train loss is 18.68665557890199\n",
      "Steps:  15%|▏| 2269/15000 [19:09<39:09,  5.42it/s, lr=0.000282, step_loss=0.096]07/27/2023 18:03:58 - INFO - __main__ - train loss is 18.787800578167662\n",
      "Steps:  15%|▏| 2270/15000 [19:09<38:56,  5.45it/s, lr=0.000282, step_loss=0.101]07/27/2023 18:03:59 - INFO - __main__ - train loss is 19.062860218575224\n",
      "Steps:  15%|▏| 2271/15000 [19:09<38:42,  5.48it/s, lr=0.000282, step_loss=0.275]07/27/2023 18:03:59 - INFO - __main__ - train loss is 19.198630628874525\n",
      "Steps:  15%|▏| 2272/15000 [19:09<38:44,  5.48it/s, lr=0.000282, step_loss=0.136]07/27/2023 18:03:59 - INFO - __main__ - train loss is 19.28365491121076\n",
      "Steps:  15%|▏| 2273/15000 [19:09<38:30,  5.51it/s, lr=0.000283, step_loss=0.085]07/27/2023 18:03:59 - INFO - __main__ - train loss is 19.590135706355795\n",
      "Steps:  15%|▏| 2274/15000 [19:09<39:00,  5.44it/s, lr=0.000283, step_loss=0.306]07/27/2023 18:03:59 - INFO - __main__ - train loss is 19.59938009805046\n",
      "Steps:  15%|▏| 2275/15000 [19:10<38:42,  5.48it/s, lr=0.000283, step_loss=0.009207/27/2023 18:03:59 - INFO - __main__ - train loss is 19.646358247613534\n",
      "Steps:  15%|▏| 2276/15000 [19:10<38:30,  5.51it/s, lr=0.000283, step_loss=0.047]07/27/2023 18:04:00 - INFO - __main__ - train loss is 19.915052350377664\n",
      "Steps:  15%|▏| 2277/15000 [19:10<38:50,  5.46it/s, lr=0.000283, step_loss=0.269]07/27/2023 18:04:00 - INFO - __main__ - train loss is 20.140479322290048\n",
      "Steps:  15%|▏| 2278/15000 [19:10<38:38,  5.49it/s, lr=0.000283, step_loss=0.225]07/27/2023 18:04:00 - INFO - __main__ - train loss is 20.4937804301735\n",
      "Steps:  15%|▏| 2279/15000 [19:10<38:29,  5.51it/s, lr=0.000283, step_loss=0.353]07/27/2023 18:04:00 - INFO - __main__ - train loss is 20.496024695923552\n",
      "Steps:  15%|▏| 2280/15000 [19:11<38:24,  5.52it/s, lr=0.000284, step_loss=0.002207/27/2023 18:04:00 - INFO - __main__ - train loss is 20.631450889399275\n",
      "Steps:  15%|▏| 2281/15000 [19:11<38:18,  5.53it/s, lr=0.000284, step_loss=0.135]07/27/2023 18:04:01 - INFO - __main__ - train loss is 21.376776931574568\n",
      "Steps:  15%|▏| 2282/15000 [19:11<38:12,  5.55it/s, lr=0.000284, step_loss=0.745]07/27/2023 18:04:01 - INFO - __main__ - train loss is 21.517239240696654\n",
      "Steps:  15%|▎ | 2283/15000 [19:11<38:07,  5.56it/s, lr=0.000284, step_loss=0.14]07/27/2023 18:04:01 - INFO - __main__ - train loss is 21.575159398606047\n",
      "Steps:  15%|▏| 2284/15000 [19:11<38:03,  5.57it/s, lr=0.000284, step_loss=0.057907/27/2023 18:04:01 - INFO - __main__ - train loss is 21.61806214018725\n",
      "Steps:  15%|▏| 2285/15000 [19:11<38:06,  5.56it/s, lr=0.000284, step_loss=0.042907/27/2023 18:04:01 - INFO - __main__ - train loss is 21.693125189980492\n",
      "Steps:  15%|▏| 2286/15000 [19:12<38:17,  5.53it/s, lr=0.000284, step_loss=0.075107/27/2023 18:04:01 - INFO - __main__ - train loss is 21.883258612593636\n",
      "Steps:  15%|▎ | 2287/15000 [19:12<38:11,  5.55it/s, lr=0.000284, step_loss=0.19]07/27/2023 18:04:02 - INFO - __main__ - train loss is 21.885986774694175\n",
      "Steps:  15%|▏| 2288/15000 [19:12<38:12,  5.55it/s, lr=0.000284, step_loss=0.002707/27/2023 18:04:02 - INFO - __main__ - train loss is 21.904941230546683\n",
      "Steps:  15%|▏| 2289/15000 [19:12<38:08,  5.56it/s, lr=0.000285, step_loss=0.019]07/27/2023 18:04:02 - INFO - __main__ - train loss is 22.077618062030524\n",
      "Steps:  15%|▏| 2290/15000 [19:12<38:05,  5.56it/s, lr=0.000285, step_loss=0.173]07/27/2023 18:04:02 - INFO - __main__ - train loss is 22.107153068762273\n",
      "Steps:  15%|▏| 2291/15000 [19:12<38:06,  5.56it/s, lr=0.000285, step_loss=0.029507/27/2023 18:04:02 - INFO - __main__ - train loss is 22.260880331974477\n",
      "Steps:  15%|▏| 2292/15000 [19:13<38:02,  5.57it/s, lr=0.000285, step_loss=0.154]07/27/2023 18:04:03 - INFO - __main__ - train loss is 22.305304318200797\n",
      "Steps:  15%|▏| 2293/15000 [19:13<38:00,  5.57it/s, lr=0.000285, step_loss=0.044407/27/2023 18:04:03 - INFO - __main__ - train loss is 22.34904134972021\n",
      "Steps:  15%|▏| 2294/15000 [19:13<37:58,  5.58it/s, lr=0.000285, step_loss=0.043707/27/2023 18:04:03 - INFO - __main__ - train loss is 22.50619912846014\n",
      "Steps:  15%|▏| 2295/15000 [19:13<37:59,  5.57it/s, lr=0.000285, step_loss=0.157]07/27/2023 18:04:03 - INFO - __main__ - train loss is 22.534288350027055\n",
      "Steps:  15%|▏| 2296/15000 [19:13<37:58,  5.58it/s, lr=0.000286, step_loss=0.028107/27/2023 18:04:03 - INFO - __main__ - train loss is 22.56893965182826\n",
      "Steps:  15%|▏| 2297/15000 [19:14<37:57,  5.58it/s, lr=0.000286, step_loss=0.034707/27/2023 18:04:03 - INFO - __main__ - train loss is 22.597681577783078\n",
      "Steps:  15%|▏| 2298/15000 [19:14<37:55,  5.58it/s, lr=0.000286, step_loss=0.028707/27/2023 18:04:04 - INFO - __main__ - train loss is 22.977214212995023\n",
      "Steps:  15%|▎ | 2299/15000 [19:14<37:55,  5.58it/s, lr=0.000286, step_loss=0.38]07/27/2023 18:04:04 - INFO - __main__ - train loss is 23.191227938514203\n",
      "Steps:  15%|▏| 2300/15000 [19:14<37:54,  5.58it/s, lr=0.000286, step_loss=0.214]07/27/2023 18:04:04 - INFO - __main__ - train loss is 23.19579745689407\n",
      "Steps:  15%|▏| 2301/15000 [19:14<37:54,  5.58it/s, lr=0.000286, step_loss=0.004507/27/2023 18:04:04 - INFO - __main__ - train loss is 23.197552993427962\n",
      "Steps:  15%|▏| 2302/15000 [19:14<38:20,  5.52it/s, lr=0.000286, step_loss=0.001707/27/2023 18:04:04 - INFO - __main__ - train loss is 23.216369371395558\n",
      "Steps:  15%|▏| 2303/15000 [19:15<38:11,  5.54it/s, lr=0.000286, step_loss=0.018807/27/2023 18:04:05 - INFO - __main__ - train loss is 23.219902996905148\n",
      "Steps:  15%|▏| 2304/15000 [19:15<38:04,  5.56it/s, lr=0.000286, step_loss=0.003507/27/2023 18:04:05 - INFO - __main__ - train loss is 23.33150486368686\n",
      "Steps:  15%|▏| 2305/15000 [19:15<38:00,  5.57it/s, lr=0.000287, step_loss=0.112]07/27/2023 18:04:05 - INFO - __main__ - train loss is 23.420222503133118\n",
      "Steps:  15%|▏| 2306/15000 [19:15<37:58,  5.57it/s, lr=0.000287, step_loss=0.088707/27/2023 18:04:05 - INFO - __main__ - train loss is 23.51879740227014\n",
      "Steps:  15%|▏| 2307/15000 [19:15<38:04,  5.55it/s, lr=0.000287, step_loss=0.098607/27/2023 18:04:05 - INFO - __main__ - train loss is 23.76030691433698\n",
      "Steps:  15%|▏| 2308/15000 [19:16<38:02,  5.56it/s, lr=0.000287, step_loss=0.242]07/27/2023 18:04:05 - INFO - __main__ - train loss is 23.937778850086033\n",
      "Steps:  15%|▏| 2309/15000 [19:16<38:01,  5.56it/s, lr=0.000287, step_loss=0.177]07/27/2023 18:04:06 - INFO - __main__ - train loss is 23.997055646963418\n",
      "Steps:  15%|▏| 2310/15000 [19:16<38:02,  5.56it/s, lr=0.000287, step_loss=0.059307/27/2023 18:04:06 - INFO - __main__ - train loss is 24.347051021642983\n",
      "Steps:  15%|▎ | 2311/15000 [19:16<38:00,  5.57it/s, lr=0.000287, step_loss=0.35]07/27/2023 18:04:06 - INFO - __main__ - train loss is 24.453625638969243\n",
      "Steps:  15%|▏| 2312/15000 [19:16<37:57,  5.57it/s, lr=0.000287, step_loss=0.107]07/27/2023 18:04:06 - INFO - __main__ - train loss is 24.548226033337414\n",
      "Steps:  15%|▏| 2313/15000 [19:16<37:56,  5.57it/s, lr=0.000288, step_loss=0.094607/27/2023 18:04:06 - INFO - __main__ - train loss is 24.565412209369242\n",
      "Steps:  15%|▏| 2314/15000 [19:17<38:10,  5.54it/s, lr=0.000288, step_loss=0.017207/27/2023 18:04:06 - INFO - __main__ - train loss is 24.658003077842295\n",
      "Steps:  15%|▏| 2315/15000 [19:17<38:07,  5.55it/s, lr=0.000288, step_loss=0.092607/27/2023 18:04:07 - INFO - __main__ - train loss is 24.66555443033576\n",
      "Steps:  15%|▏| 2316/15000 [19:17<38:06,  5.55it/s, lr=0.000288, step_loss=0.007507/27/2023 18:04:07 - INFO - __main__ - train loss is 24.675133696757257\n",
      "Steps:  15%|▏| 2317/15000 [19:17<38:03,  5.55it/s, lr=0.000288, step_loss=0.009507/27/2023 18:04:07 - INFO - __main__ - train loss is 25.020846745930612\n",
      "Steps:  15%|▏| 2318/15000 [19:17<38:20,  5.51it/s, lr=0.000288, step_loss=0.346]07/27/2023 18:04:07 - INFO - __main__ - train loss is 25.037099371664226\n",
      "Steps:  15%|▏| 2319/15000 [19:18<38:15,  5.52it/s, lr=0.000288, step_loss=0.016307/27/2023 18:04:07 - INFO - __main__ - train loss is 25.221446464769542\n",
      "Steps:  15%|▏| 2320/15000 [19:18<38:12,  5.53it/s, lr=0.000288, step_loss=0.184]07/27/2023 18:04:08 - INFO - __main__ - train loss is 25.437932471744716\n",
      "Steps:  15%|▏| 2321/15000 [19:18<38:19,  5.51it/s, lr=0.000289, step_loss=0.216]07/27/2023 18:04:08 - INFO - __main__ - train loss is 25.441426560282707\n",
      "Steps:  15%|▏| 2322/15000 [19:18<38:29,  5.49it/s, lr=0.000289, step_loss=0.003407/27/2023 18:04:08 - INFO - __main__ - train loss is 25.463699055835605\n",
      "Steps:  15%|▏| 2323/15000 [19:18<38:19,  5.51it/s, lr=0.000289, step_loss=0.022307/27/2023 18:04:08 - INFO - __main__ - train loss is 25.47006047796458\n",
      "Steps:  15%|▏| 2324/15000 [19:18<38:19,  5.51it/s, lr=0.000289, step_loss=0.006307/27/2023 18:04:08 - INFO - __main__ - train loss is 25.48360817786306\n",
      "Steps:  16%|▏| 2325/15000 [19:19<38:14,  5.52it/s, lr=0.000289, step_loss=0.013507/27/2023 18:04:08 - INFO - __main__ - train loss is 25.567599936388433\n",
      "Steps:  16%|▏| 2326/15000 [19:19<38:07,  5.54it/s, lr=0.000289, step_loss=0.084]07/27/2023 18:04:09 - INFO - __main__ - train loss is 25.573990497738123\n",
      "Steps:  16%|▏| 2327/15000 [19:19<38:04,  5.55it/s, lr=0.000289, step_loss=0.006307/27/2023 18:04:09 - INFO - __main__ - train loss is 25.853254709392786\n",
      "Steps:  16%|▏| 2328/15000 [19:19<38:10,  5.53it/s, lr=0.000289, step_loss=0.279]07/27/2023 18:04:09 - INFO - __main__ - train loss is 25.857369909528643\n",
      "Steps:  16%|▏| 2329/15000 [19:19<38:05,  5.54it/s, lr=0.00029, step_loss=0.0041207/27/2023 18:04:09 - INFO - __main__ - train loss is 25.861939463298768\n",
      "Steps:  16%|▏| 2330/15000 [19:20<38:02,  5.55it/s, lr=0.00029, step_loss=0.0045707/27/2023 18:04:09 - INFO - __main__ - train loss is 25.870070374105126\n",
      "Steps:  16%|▏| 2331/15000 [19:20<37:58,  5.56it/s, lr=0.00029, step_loss=0.0081307/27/2023 18:04:10 - INFO - __main__ - train loss is 25.994463159237057\n",
      "Steps:  16%|▎ | 2332/15000 [19:20<37:58,  5.56it/s, lr=0.00029, step_loss=0.124]07/27/2023 18:04:10 - INFO - __main__ - train loss is 26.07041875878349\n",
      "Steps:  16%|▎ | 2333/15000 [19:20<38:03,  5.55it/s, lr=0.00029, step_loss=0.076]07/27/2023 18:04:10 - INFO - __main__ - train loss is 26.07914970861748\n",
      "Steps:  16%|▏| 2334/15000 [19:20<37:59,  5.56it/s, lr=0.00029, step_loss=0.0087307/27/2023 18:04:10 - INFO - __main__ - train loss is 26.08201334485784\n",
      "Steps:  16%|▏| 2335/15000 [19:20<37:58,  5.56it/s, lr=0.00029, step_loss=0.0028607/27/2023 18:04:10 - INFO - __main__ - train loss is 26.09856344619766\n",
      "Steps:  16%|▏| 2336/15000 [19:21<38:02,  5.55it/s, lr=0.00029, step_loss=0.0166]07/27/2023 18:04:10 - INFO - __main__ - train loss is 26.146343542728573\n",
      "Steps:  16%|▏| 2337/15000 [19:21<37:58,  5.56it/s, lr=0.000291, step_loss=0.047807/27/2023 18:04:11 - INFO - __main__ - train loss is 26.64578355709091\n",
      "Steps:  16%|▏| 2338/15000 [19:21<37:56,  5.56it/s, lr=0.000291, step_loss=0.499]07/27/2023 18:04:11 - INFO - __main__ - train loss is 26.94729302683845\n",
      "Steps:  16%|▏| 2339/15000 [19:21<37:57,  5.56it/s, lr=0.000291, step_loss=0.302]07/27/2023 18:04:11 - INFO - __main__ - train loss is 27.036557315383106\n",
      "Steps:  16%|▏| 2340/15000 [19:21<38:12,  5.52it/s, lr=0.000291, step_loss=0.089307/27/2023 18:04:11 - INFO - __main__ - train loss is 27.11078634718433\n",
      "Steps:  16%|▏| 2341/15000 [19:21<38:05,  5.54it/s, lr=0.000291, step_loss=0.074207/27/2023 18:04:11 - INFO - __main__ - train loss is 27.275720848236233\n",
      "Steps:  16%|▏| 2342/15000 [19:22<38:02,  5.54it/s, lr=0.000291, step_loss=0.165]07/27/2023 18:04:12 - INFO - __main__ - train loss is 27.420998795423657\n",
      "Steps:  16%|▏| 2343/15000 [19:22<37:57,  5.56it/s, lr=0.000291, step_loss=0.145]07/27/2023 18:04:12 - INFO - __main__ - train loss is 27.451119751203805\n",
      "Steps:  16%|▏| 2344/15000 [19:22<37:54,  5.56it/s, lr=0.000291, step_loss=0.030107/27/2023 18:04:12 - INFO - __main__ - train loss is 27.457177815493196\n",
      "Steps:  16%|▏| 2345/15000 [19:22<37:55,  5.56it/s, lr=0.000292, step_loss=0.006007/27/2023 18:04:12 - INFO - __main__ - train loss is 27.654130486305803\n",
      "Steps:  16%|▏| 2346/15000 [19:22<37:53,  5.57it/s, lr=0.000292, step_loss=0.197]07/27/2023 18:04:12 - INFO - __main__ - train loss is 27.77109888708219\n",
      "Steps:  16%|▏| 2347/15000 [19:23<37:52,  5.57it/s, lr=0.000292, step_loss=0.117]07/27/2023 18:04:12 - INFO - __main__ - train loss is 28.017047574277967\n",
      "Steps:  16%|▏| 2348/15000 [19:23<37:53,  5.57it/s, lr=0.000292, step_loss=0.246]07/27/2023 18:04:13 - INFO - __main__ - train loss is 28.04153655609116\n",
      "Steps:  16%|▏| 2349/15000 [19:23<37:51,  5.57it/s, lr=0.000292, step_loss=0.024507/27/2023 18:04:13 - INFO - __main__ - train loss is 28.154819705989212\n",
      "Steps:  16%|▏| 2350/15000 [19:23<37:52,  5.57it/s, lr=0.000292, step_loss=0.113]07/27/2023 18:04:13 - INFO - __main__ - train loss is 28.461419024970382\n",
      "Steps:  16%|▏| 2351/15000 [19:23<38:16,  5.51it/s, lr=0.000292, step_loss=0.307]07/27/2023 18:04:13 - INFO - __main__ - train loss is 28.48182383319363\n",
      "Steps:  16%|▏| 2352/15000 [19:23<38:07,  5.53it/s, lr=0.000293, step_loss=0.020407/27/2023 18:04:13 - INFO - __main__ - train loss is 28.540444006677717\n",
      "Steps:  16%|▏| 2353/15000 [19:24<38:00,  5.55it/s, lr=0.000293, step_loss=0.058607/27/2023 18:04:14 - INFO - __main__ - train loss is 28.55346151208505\n",
      "Steps:  16%|▏| 2354/15000 [19:24<37:55,  5.56it/s, lr=0.000293, step_loss=0.013]07/27/2023 18:04:14 - INFO - __main__ - train loss is 28.816507866140455\n",
      "Steps:  16%|▏| 2355/15000 [19:24<37:51,  5.57it/s, lr=0.000293, step_loss=0.263]07/27/2023 18:04:14 - INFO - __main__ - train loss is 29.357650568243116\n",
      "Steps:  16%|▏| 2356/15000 [19:24<37:50,  5.57it/s, lr=0.000293, step_loss=0.541]07/27/2023 18:04:14 - INFO - __main__ - train loss is 29.371275746729225\n",
      "Steps:  16%|▏| 2357/15000 [19:24<37:53,  5.56it/s, lr=0.000293, step_loss=0.013607/27/2023 18:04:14 - INFO - __main__ - train loss is 29.374469271861017\n",
      "Steps:  16%|▏| 2358/15000 [19:25<37:54,  5.56it/s, lr=0.000293, step_loss=0.003107/27/2023 18:04:14 - INFO - __main__ - train loss is 29.48020405229181\n",
      "Steps:  16%|▏| 2359/15000 [19:25<38:14,  5.51it/s, lr=0.000293, step_loss=0.106]07/27/2023 18:04:15 - INFO - __main__ - train loss is 29.799283272586763\n",
      "Steps:  16%|▏| 2360/15000 [19:25<38:14,  5.51it/s, lr=0.000293, step_loss=0.319]07/27/2023 18:04:15 - INFO - __main__ - train loss is 29.90849610324949\n",
      "Steps:  16%|▏| 2361/15000 [19:25<38:28,  5.48it/s, lr=0.000294, step_loss=0.109]07/27/2023 18:04:15 - INFO - __main__ - train loss is 29.910511715337634\n",
      "Steps:  16%|▏| 2362/15000 [19:25<38:22,  5.49it/s, lr=0.000294, step_loss=0.002007/27/2023 18:04:15 - INFO - __main__ - train loss is 30.4734057020396\n",
      "Steps:  16%|▏| 2363/15000 [19:25<38:11,  5.51it/s, lr=0.000294, step_loss=0.563]07/27/2023 18:04:15 - INFO - __main__ - train loss is 30.482525093480945\n",
      "Steps:  16%|▏| 2364/15000 [19:26<38:04,  5.53it/s, lr=0.000294, step_loss=0.009107/27/2023 18:04:16 - INFO - __main__ - train loss is 30.512975929304957\n",
      "Steps:  16%|▏| 2365/15000 [19:26<37:58,  5.54it/s, lr=0.000294, step_loss=0.030507/27/2023 18:04:16 - INFO - __main__ - train loss is 30.701160876080394\n",
      "Steps:  16%|▏| 2366/15000 [19:26<38:05,  5.53it/s, lr=0.000294, step_loss=0.188]07/27/2023 18:04:16 - INFO - __main__ - train loss is 30.794836623594165\n",
      "Steps:  16%|▏| 2367/15000 [19:26<37:58,  5.54it/s, lr=0.000294, step_loss=0.093707/27/2023 18:04:16 - INFO - __main__ - train loss is 30.797123978845775\n",
      "Steps:  16%|▏| 2368/15000 [19:26<37:55,  5.55it/s, lr=0.000295, step_loss=0.002207/27/2023 18:04:16 - INFO - __main__ - train loss is 30.972200254909694\n",
      "Steps:  16%|▏| 2369/15000 [19:27<37:59,  5.54it/s, lr=0.000295, step_loss=0.175]07/27/2023 18:04:16 - INFO - __main__ - train loss is 30.97628165455535\n",
      "Steps:  16%|▏| 2370/15000 [19:27<37:57,  5.55it/s, lr=0.000295, step_loss=0.004007/27/2023 18:04:17 - INFO - __main__ - train loss is 31.35538746090606\n",
      "Steps:  16%|▏| 2371/15000 [19:27<37:55,  5.55it/s, lr=0.000295, step_loss=0.379]07/27/2023 18:04:17 - INFO - __main__ - train loss is 31.612440925557166\n",
      "Steps:  16%|▏| 2372/15000 [19:27<38:06,  5.52it/s, lr=0.000295, step_loss=0.257]07/27/2023 18:04:17 - INFO - __main__ - train loss is 31.68467227788642\n",
      "Steps:  16%|▏| 2373/15000 [19:27<38:00,  5.54it/s, lr=0.000295, step_loss=0.072207/27/2023 18:04:17 - INFO - __main__ - train loss is 31.685976702254266\n",
      "Steps:  16%|▏| 2374/15000 [19:27<37:58,  5.54it/s, lr=0.000295, step_loss=0.001307/27/2023 18:04:17 - INFO - __main__ - train loss is 31.68970849737525\n",
      "Steps:  16%|▏| 2375/15000 [19:28<37:57,  5.54it/s, lr=0.000295, step_loss=0.003707/27/2023 18:04:17 - INFO - __main__ - train loss is 31.784368444234133\n",
      "Steps:  16%|▏| 2376/15000 [19:28<38:14,  5.50it/s, lr=0.000295, step_loss=0.094707/27/2023 18:04:18 - INFO - __main__ - train loss is 31.970359180122614\n",
      "Steps:  16%|▏| 2377/15000 [19:28<38:48,  5.42it/s, lr=0.000296, step_loss=0.186]07/27/2023 18:04:18 - INFO - __main__ - train loss is 32.0313454605639\n",
      "Steps:  16%|▏| 2378/15000 [19:28<38:27,  5.47it/s, lr=0.000296, step_loss=0.061]07/27/2023 18:04:18 - INFO - __main__ - train loss is 32.218242321163416\n",
      "Steps:  16%|▏| 2379/15000 [19:28<38:14,  5.50it/s, lr=0.000296, step_loss=0.187]07/27/2023 18:04:18 - INFO - __main__ - train loss is 32.565153393894434\n",
      "Steps:  16%|▏| 2380/15000 [19:29<38:05,  5.52it/s, lr=0.000296, step_loss=0.347]07/27/2023 18:04:18 - INFO - __main__ - train loss is 32.61781803146005\n",
      "Steps:  16%|▏| 2381/15000 [19:29<38:20,  5.49it/s, lr=0.000296, step_loss=0.052707/27/2023 18:04:19 - INFO - __main__ - train loss is 32.762602273374796\n",
      "Steps:  16%|▏| 2382/15000 [19:29<38:15,  5.50it/s, lr=0.000296, step_loss=0.145]07/27/2023 18:04:19 - INFO - __main__ - train loss is 32.99808806553483\n",
      "Steps:  16%|▏| 2383/15000 [19:29<38:05,  5.52it/s, lr=0.000296, step_loss=0.235]07/27/2023 18:04:19 - INFO - __main__ - train loss is 33.01372584141791\n",
      "Steps:  16%|▏| 2384/15000 [19:29<37:58,  5.54it/s, lr=0.000296, step_loss=0.015607/27/2023 18:04:19 - INFO - __main__ - train loss is 33.09962729550898\n",
      "Steps:  16%|▏| 2385/15000 [19:29<38:01,  5.53it/s, lr=0.000297, step_loss=0.085907/27/2023 18:04:19 - INFO - __main__ - train loss is 33.152250641956925\n",
      "Steps:  16%|▏| 2386/15000 [19:30<37:58,  5.54it/s, lr=0.000297, step_loss=0.052607/27/2023 18:04:19 - INFO - __main__ - train loss is 33.472006971016526\n",
      "Steps:  16%|▎ | 2387/15000 [19:30<37:54,  5.55it/s, lr=0.000297, step_loss=0.32]07/27/2023 18:04:20 - INFO - __main__ - train loss is 33.98883860744536\n",
      "Steps:  16%|▏| 2388/15000 [19:30<37:55,  5.54it/s, lr=0.000297, step_loss=0.517]07/27/2023 18:04:20 - INFO - __main__ - train loss is 34.174343371763825\n",
      "Steps:  16%|▏| 2389/15000 [19:30<37:50,  5.55it/s, lr=0.000297, step_loss=0.186]07/27/2023 18:04:20 - INFO - __main__ - train loss is 34.20196421816945\n",
      "Steps:  16%|▏| 2390/15000 [19:30<37:48,  5.56it/s, lr=0.000297, step_loss=0.027607/27/2023 18:04:20 - INFO - __main__ - train loss is 34.204080063384026\n",
      "Steps:  16%|▏| 2391/15000 [19:31<37:46,  5.56it/s, lr=0.000297, step_loss=0.002107/27/2023 18:04:20 - INFO - __main__ - train loss is 34.49508597282693\n",
      "Steps:  16%|▏| 2392/15000 [19:31<37:44,  5.57it/s, lr=0.000297, step_loss=0.291]07/27/2023 18:04:21 - INFO - __main__ - train loss is 34.533087007235736\n",
      "Steps:  16%|▏| 2393/15000 [19:31<38:05,  5.51it/s, lr=0.000298, step_loss=0.038]07/27/2023 18:04:21 - INFO - __main__ - train loss is 34.534692412940785\n",
      "Steps:  16%|▏| 2394/15000 [19:31<38:09,  5.50it/s, lr=0.000298, step_loss=0.001607/27/2023 18:04:21 - INFO - __main__ - train loss is 35.08939994010143\n",
      "Steps:  16%|▏| 2395/15000 [19:31<38:17,  5.49it/s, lr=0.000298, step_loss=0.555]07/27/2023 18:04:21 - INFO - __main__ - train loss is 35.23479520413093\n",
      "Steps:  16%|▏| 2396/15000 [19:31<38:13,  5.49it/s, lr=0.000298, step_loss=0.145]07/27/2023 18:04:21 - INFO - __main__ - train loss is 35.45861045154743\n",
      "Steps:  16%|▏| 2397/15000 [19:32<38:11,  5.50it/s, lr=0.000298, step_loss=0.224]07/27/2023 18:04:21 - INFO - __main__ - train loss is 36.367897308198735\n",
      "Steps:  16%|▏| 2398/15000 [19:32<38:03,  5.52it/s, lr=0.000298, step_loss=0.909]07/27/2023 18:04:22 - INFO - __main__ - train loss is 36.76007560524158\n",
      "Steps:  16%|▏| 2399/15000 [19:32<38:00,  5.52it/s, lr=0.000298, step_loss=0.392]07/27/2023 18:04:22 - INFO - __main__ - train loss is 36.95524538191967\n",
      "Steps:  16%|▏| 2400/15000 [19:32<38:26,  5.46it/s, lr=0.000298, step_loss=0.195]07/27/2023 18:04:22 - INFO - __main__ - train loss is 37.08108896645717\n",
      "Steps:  16%|▏| 2401/15000 [19:32<38:20,  5.48it/s, lr=0.000299, step_loss=0.126]07/27/2023 18:04:22 - INFO - __main__ - train loss is 37.08322461415082\n",
      "Steps:  16%|▏| 2402/15000 [19:33<38:18,  5.48it/s, lr=0.000299, step_loss=0.002107/27/2023 18:04:22 - INFO - __main__ - train loss is 37.50831886101514\n",
      "Steps:  16%|▏| 2403/15000 [19:33<38:14,  5.49it/s, lr=0.000299, step_loss=0.425]07/27/2023 18:04:23 - INFO - __main__ - train loss is 37.51917432714254\n",
      "Steps:  16%|▏| 2404/15000 [19:33<38:11,  5.50it/s, lr=0.000299, step_loss=0.010907/27/2023 18:04:23 - INFO - __main__ - train loss is 37.62771437037736\n",
      "Steps:  16%|▏| 2405/15000 [19:33<38:12,  5.49it/s, lr=0.000299, step_loss=0.109]07/27/2023 18:04:23 - INFO - __main__ - train loss is 37.71362890023738\n",
      "Steps:  16%|▏| 2406/15000 [19:33<38:10,  5.50it/s, lr=0.000299, step_loss=0.085907/27/2023 18:04:23 - INFO - __main__ - train loss is 37.78439705539495\n",
      "Steps:  16%|▏| 2407/15000 [19:33<38:09,  5.50it/s, lr=0.000299, step_loss=0.070807/27/2023 18:04:23 - INFO - __main__ - train loss is 37.811927751637995\n",
      "Steps:  16%|▎ | 2408/15000 [19:34<37:56,  5.53it/s, lr=0.0003, step_loss=0.0275]07/27/2023 18:04:23 - INFO - __main__ - train loss is 38.18248160276562\n",
      "Steps:  16%|▍  | 2409/15000 [19:34<37:47,  5.55it/s, lr=0.0003, step_loss=0.371]07/27/2023 18:04:24 - INFO - __main__ - train loss is 38.19043167959899\n",
      "Steps:  16%|▏| 2410/15000 [19:34<37:41,  5.57it/s, lr=0.0003, step_loss=0.00795]07/27/2023 18:04:24 - INFO - __main__ - train loss is 38.26162057649344\n",
      "Steps:  16%|▎ | 2411/15000 [19:34<37:37,  5.58it/s, lr=0.0003, step_loss=0.0712]07/27/2023 18:04:24 - INFO - __main__ - train loss is 38.278964589349926\n",
      "Steps:  16%|▎ | 2412/15000 [19:34<37:42,  5.56it/s, lr=0.0003, step_loss=0.0173]07/27/2023 18:04:24 - INFO - __main__ - train loss is 38.2925057252869\n",
      "Steps:  16%|▎ | 2413/15000 [19:35<37:47,  5.55it/s, lr=0.0003, step_loss=0.0135]07/27/2023 18:04:24 - INFO - __main__ - train loss is 38.308079491369426\n",
      "Steps:  16%|▎ | 2414/15000 [19:35<37:42,  5.56it/s, lr=0.0003, step_loss=0.0156]07/27/2023 18:04:25 - INFO - __main__ - train loss is 38.375688086263835\n",
      "Steps:  16%|▎ | 2415/15000 [19:35<37:42,  5.56it/s, lr=0.0003, step_loss=0.0676]07/27/2023 18:04:25 - INFO - __main__ - train loss is 38.472361634485424\n",
      "Steps:  16%|▎ | 2416/15000 [19:35<37:37,  5.57it/s, lr=0.0003, step_loss=0.0967]07/27/2023 18:04:25 - INFO - __main__ - train loss is 38.502640089951456\n",
      "Steps:  16%|▏| 2417/15000 [19:35<37:35,  5.58it/s, lr=0.000301, step_loss=0.030307/27/2023 18:04:25 - INFO - __main__ - train loss is 38.541133045218885\n",
      "Steps:  16%|▏| 2418/15000 [19:35<37:40,  5.57it/s, lr=0.000301, step_loss=0.038507/27/2023 18:04:25 - INFO - __main__ - train loss is 38.69523890223354\n",
      "Steps:  16%|▏| 2419/15000 [19:36<37:36,  5.57it/s, lr=0.000301, step_loss=0.154]07/27/2023 18:04:25 - INFO - __main__ - train loss is 38.81246867682785\n",
      "Steps:  16%|▏| 2420/15000 [19:36<37:33,  5.58it/s, lr=0.000301, step_loss=0.117]07/27/2023 18:04:26 - INFO - __main__ - train loss is 38.82689999695867\n",
      "Steps:  16%|▏| 2421/15000 [19:36<37:32,  5.59it/s, lr=0.000301, step_loss=0.014407/27/2023 18:04:26 - INFO - __main__ - train loss is 38.8300941712223\n",
      "Steps:  16%|▏| 2422/15000 [19:36<37:32,  5.58it/s, lr=0.000301, step_loss=0.003107/27/2023 18:04:26 - INFO - __main__ - train loss is 38.975078088697046\n",
      "Steps:  16%|▏| 2423/15000 [19:36<37:31,  5.59it/s, lr=0.000301, step_loss=0.145]07/27/2023 18:04:26 - INFO - __main__ - train loss is 39.19464933639392\n",
      "Steps:  16%|▎ | 2424/15000 [19:37<53:37,  3.91it/s, lr=0.000302, step_loss=0.22]07/27/2023 18:04:27 - INFO - __main__ - Per validation step average loss is 0.009717971086502075\n",
      "07/27/2023 18:04:27 - INFO - __main__ - Cumulative validation average loss is 0.009717971086502075\n",
      "07/27/2023 18:04:28 - INFO - __main__ - Per validation step average loss is 0.24805137515068054\n",
      "07/27/2023 18:04:28 - INFO - __main__ - Cumulative validation average loss is 0.2577693462371826\n",
      "07/27/2023 18:04:28 - INFO - __main__ - Per validation step average loss is 0.004654284566640854\n",
      "07/27/2023 18:04:28 - INFO - __main__ - Cumulative validation average loss is 0.26242363080382347\n",
      "07/27/2023 18:04:29 - INFO - __main__ - Per validation step average loss is 0.1884271502494812\n",
      "07/27/2023 18:04:29 - INFO - __main__ - Cumulative validation average loss is 0.45085078105330467\n",
      "07/27/2023 18:04:29 - INFO - __main__ - Per validation step average loss is 0.5731214284896851\n",
      "07/27/2023 18:04:29 - INFO - __main__ - Cumulative validation average loss is 1.0239722095429897\n",
      "07/27/2023 18:04:29 - INFO - __main__ - Per validation step average loss is 0.05304273962974548\n",
      "07/27/2023 18:04:29 - INFO - __main__ - Cumulative validation average loss is 1.0770149491727352\n",
      "07/27/2023 18:04:30 - INFO - __main__ - Per validation step average loss is 0.028334077447652817\n",
      "07/27/2023 18:04:30 - INFO - __main__ - Cumulative validation average loss is 1.105349026620388\n",
      "07/27/2023 18:04:30 - INFO - __main__ - Per validation step average loss is 0.06509619951248169\n",
      "07/27/2023 18:04:30 - INFO - __main__ - Cumulative validation average loss is 1.1704452261328697\n",
      "07/27/2023 18:04:31 - INFO - __main__ - Per validation step average loss is 0.20354214310646057\n",
      "07/27/2023 18:04:31 - INFO - __main__ - Cumulative validation average loss is 1.3739873692393303\n",
      "07/27/2023 18:04:31 - INFO - __main__ - Per validation step average loss is 0.09022854268550873\n",
      "07/27/2023 18:04:31 - INFO - __main__ - Cumulative validation average loss is 1.464215911924839\n",
      "07/27/2023 18:04:32 - INFO - __main__ - Per validation step average loss is 0.012691311538219452\n",
      "07/27/2023 18:04:32 - INFO - __main__ - Cumulative validation average loss is 1.4769072234630585\n",
      "07/27/2023 18:04:32 - INFO - __main__ - Per validation step average loss is 0.009364636614918709\n",
      "07/27/2023 18:04:32 - INFO - __main__ - Cumulative validation average loss is 1.4862718600779772\n",
      "07/27/2023 18:04:32 - INFO - __main__ - Per validation step average loss is 0.3506524860858917\n",
      "07/27/2023 18:04:32 - INFO - __main__ - Cumulative validation average loss is 1.836924346163869\n",
      "07/27/2023 18:04:33 - INFO - __main__ - Per validation step average loss is 0.32509809732437134\n",
      "07/27/2023 18:04:33 - INFO - __main__ - Cumulative validation average loss is 2.1620224434882402\n",
      "07/27/2023 18:04:33 - INFO - __main__ - Per validation step average loss is 0.0053877984173595905\n",
      "07/27/2023 18:04:33 - INFO - __main__ - Cumulative validation average loss is 2.1674102419056\n",
      "07/27/2023 18:04:34 - INFO - __main__ - Per validation step average loss is 0.7384531497955322\n",
      "07/27/2023 18:04:34 - INFO - __main__ - Cumulative validation average loss is 2.905863391701132\n",
      "07/27/2023 18:04:34 - INFO - __main__ - Per validation step average loss is 0.019414477050304413\n",
      "07/27/2023 18:04:34 - INFO - __main__ - Cumulative validation average loss is 2.9252778687514365\n",
      "07/27/2023 18:04:34 - INFO - __main__ - Per validation step average loss is 0.011070601642131805\n",
      "07/27/2023 18:04:34 - INFO - __main__ - Cumulative validation average loss is 2.9363484703935683\n",
      "07/27/2023 18:04:35 - INFO - __main__ - Per validation step average loss is 0.0023554698564112186\n",
      "07/27/2023 18:04:35 - INFO - __main__ - Cumulative validation average loss is 2.9387039402499795\n",
      "07/27/2023 18:04:35 - INFO - __main__ - Per validation step average loss is 0.03052227571606636\n",
      "07/27/2023 18:04:35 - INFO - __main__ - Cumulative validation average loss is 2.969226215966046\n",
      "07/27/2023 18:04:36 - INFO - __main__ - Per validation step average loss is 0.005949866957962513\n",
      "07/27/2023 18:04:36 - INFO - __main__ - Cumulative validation average loss is 2.9751760829240084\n",
      "07/27/2023 18:04:36 - INFO - __main__ - Per validation step average loss is 0.029073331505060196\n",
      "07/27/2023 18:04:36 - INFO - __main__ - Cumulative validation average loss is 3.0042494144290686\n",
      "07/27/2023 18:04:36 - INFO - __main__ - Per validation step average loss is 0.0023733004927635193\n",
      "07/27/2023 18:04:36 - INFO - __main__ - Cumulative validation average loss is 3.006622714921832\n",
      "07/27/2023 18:04:37 - INFO - __main__ - Per validation step average loss is 0.012953639030456543\n",
      "07/27/2023 18:04:37 - INFO - __main__ - Cumulative validation average loss is 3.0195763539522886\n",
      "07/27/2023 18:04:37 - INFO - __main__ - Per validation step average loss is 0.005680982954800129\n",
      "07/27/2023 18:04:37 - INFO - __main__ - Cumulative validation average loss is 3.0252573369070888\n",
      "07/27/2023 18:04:38 - INFO - __main__ - Per validation step average loss is 0.01972639001905918\n",
      "07/27/2023 18:04:38 - INFO - __main__ - Cumulative validation average loss is 3.044983726926148\n",
      "07/27/2023 18:04:38 - INFO - __main__ - Per validation step average loss is 0.19673585891723633\n",
      "07/27/2023 18:04:38 - INFO - __main__ - Cumulative validation average loss is 3.2417195858433843\n",
      "07/27/2023 18:04:39 - INFO - __main__ - Per validation step average loss is 0.07748726010322571\n",
      "07/27/2023 18:04:39 - INFO - __main__ - Cumulative validation average loss is 3.31920684594661\n",
      "07/27/2023 18:04:39 - INFO - __main__ - Per validation step average loss is 0.07875975966453552\n",
      "07/27/2023 18:04:39 - INFO - __main__ - Cumulative validation average loss is 3.3979666056111455\n",
      "07/27/2023 18:04:39 - INFO - __main__ - Per validation step average loss is 0.39547285437583923\n",
      "07/27/2023 18:04:39 - INFO - __main__ - Cumulative validation average loss is 3.7934394599869847\n",
      "07/27/2023 18:04:40 - INFO - __main__ - Per validation step average loss is 0.04363062605261803\n",
      "07/27/2023 18:04:40 - INFO - __main__ - Cumulative validation average loss is 3.8370700860396028\n",
      "07/27/2023 18:04:40 - INFO - __main__ - Per validation step average loss is 0.062097273766994476\n",
      "07/27/2023 18:04:40 - INFO - __main__ - Cumulative validation average loss is 3.8991673598065972\n",
      "07/27/2023 18:04:41 - INFO - __main__ - Per validation step average loss is 0.05002366006374359\n",
      "07/27/2023 18:04:41 - INFO - __main__ - Cumulative validation average loss is 3.949191019870341\n",
      "07/27/2023 18:04:41 - INFO - __main__ - Per validation step average loss is 0.27546873688697815\n",
      "07/27/2023 18:04:41 - INFO - __main__ - Cumulative validation average loss is 4.224659756757319\n",
      "07/27/2023 18:04:41 - INFO - __main__ - Per validation step average loss is 0.012147453613579273\n",
      "07/27/2023 18:04:41 - INFO - __main__ - Cumulative validation average loss is 4.236807210370898\n",
      "07/27/2023 18:04:42 - INFO - __main__ - Per validation step average loss is 0.19755813479423523\n",
      "07/27/2023 18:04:42 - INFO - __main__ - Cumulative validation average loss is 4.4343653451651335\n",
      "07/27/2023 18:04:42 - INFO - __main__ - Per validation step average loss is 0.09779289364814758\n",
      "07/27/2023 18:04:42 - INFO - __main__ - Cumulative validation average loss is 4.532158238813281\n",
      "07/27/2023 18:04:43 - INFO - __main__ - Per validation step average loss is 0.005017764400690794\n",
      "07/27/2023 18:04:43 - INFO - __main__ - Cumulative validation average loss is 4.537176003213972\n",
      "07/27/2023 18:04:43 - INFO - __main__ - Per validation step average loss is 0.2735815644264221\n",
      "07/27/2023 18:04:43 - INFO - __main__ - Cumulative validation average loss is 4.810757567640394\n",
      "07/27/2023 18:04:43 - INFO - __main__ - Per validation step average loss is 0.2609749734401703\n",
      "07/27/2023 18:04:43 - INFO - __main__ - Cumulative validation average loss is 5.071732541080564\n",
      "07/27/2023 18:04:44 - INFO - __main__ - Per validation step average loss is 0.019409576430916786\n",
      "07/27/2023 18:04:44 - INFO - __main__ - Cumulative validation average loss is 5.091142117511481\n",
      "07/27/2023 18:04:44 - INFO - __main__ - Per validation step average loss is 0.0017960513941943645\n",
      "07/27/2023 18:04:44 - INFO - __main__ - Cumulative validation average loss is 5.092938168905675\n",
      "07/27/2023 18:04:45 - INFO - __main__ - Per validation step average loss is 0.007339159958064556\n",
      "07/27/2023 18:04:45 - INFO - __main__ - Cumulative validation average loss is 5.10027732886374\n",
      "07/27/2023 18:04:45 - INFO - __main__ - Per validation step average loss is 0.08190493285655975\n",
      "07/27/2023 18:04:45 - INFO - __main__ - Cumulative validation average loss is 5.1821822617203\n",
      "07/27/2023 18:04:45 - INFO - __main__ - Per validation step average loss is 0.05245710909366608\n",
      "07/27/2023 18:04:45 - INFO - __main__ - Cumulative validation average loss is 5.234639370813966\n",
      "07/27/2023 18:04:46 - INFO - __main__ - Per validation step average loss is 0.003045529592782259\n",
      "07/27/2023 18:04:46 - INFO - __main__ - Cumulative validation average loss is 5.237684900406748\n",
      "07/27/2023 18:04:46 - INFO - __main__ - Per validation step average loss is 0.4262077212333679\n",
      "07/27/2023 18:04:46 - INFO - __main__ - Cumulative validation average loss is 5.663892621640116\n",
      "07/27/2023 18:04:47 - INFO - __main__ - Per validation step average loss is 0.1834793984889984\n",
      "07/27/2023 18:04:47 - INFO - __main__ - Cumulative validation average loss is 5.847372020129114\n",
      "07/27/2023 18:04:47 - INFO - __main__ - Per validation step average loss is 0.23531319200992584\n",
      "07/27/2023 18:04:47 - INFO - __main__ - Cumulative validation average loss is 6.08268521213904\n",
      "07/27/2023 18:04:47 - INFO - __main__ - Per validation step average loss is 0.0031484575010836124\n",
      "07/27/2023 18:04:47 - INFO - __main__ - Cumulative validation average loss is 6.085833669640124\n",
      "07/27/2023 18:04:48 - INFO - __main__ - Per validation step average loss is 0.0035963819827884436\n",
      "07/27/2023 18:04:48 - INFO - __main__ - Cumulative validation average loss is 6.089430051622912\n",
      "07/27/2023 18:04:48 - INFO - __main__ - Per validation step average loss is 0.21684250235557556\n",
      "07/27/2023 18:04:48 - INFO - __main__ - Cumulative validation average loss is 6.306272553978488\n",
      "07/27/2023 18:04:49 - INFO - __main__ - Per validation step average loss is 0.3505868911743164\n",
      "07/27/2023 18:04:49 - INFO - __main__ - Cumulative validation average loss is 6.656859445152804\n",
      "07/27/2023 18:04:49 - INFO - __main__ - Per validation step average loss is 0.009021630510687828\n",
      "07/27/2023 18:04:49 - INFO - __main__ - Cumulative validation average loss is 6.665881075663492\n",
      "07/27/2023 18:04:50 - INFO - __main__ - Per validation step average loss is 0.2536749541759491\n",
      "07/27/2023 18:04:50 - INFO - __main__ - Cumulative validation average loss is 6.919556029839441\n",
      "07/27/2023 18:04:50 - INFO - __main__ - Per validation step average loss is 0.14846937358379364\n",
      "07/27/2023 18:04:50 - INFO - __main__ - Cumulative validation average loss is 7.068025403423235\n",
      "07/27/2023 18:04:50 - INFO - __main__ - Per validation step average loss is 0.23172134160995483\n",
      "07/27/2023 18:04:50 - INFO - __main__ - Cumulative validation average loss is 7.29974674503319\n",
      "07/27/2023 18:04:51 - INFO - __main__ - Per validation step average loss is 0.17794282734394073\n",
      "07/27/2023 18:04:51 - INFO - __main__ - Cumulative validation average loss is 7.47768957237713\n",
      "07/27/2023 18:04:51 - INFO - __main__ - Per validation step average loss is 0.14968615770339966\n",
      "07/27/2023 18:04:51 - INFO - __main__ - Cumulative validation average loss is 7.62737573008053\n",
      "07/27/2023 18:04:52 - INFO - __main__ - Per validation step average loss is 0.023621685802936554\n",
      "07/27/2023 18:04:52 - INFO - __main__ - Cumulative validation average loss is 7.650997415883467\n",
      "07/27/2023 18:04:52 - INFO - __main__ - Per validation step average loss is 0.19382622838020325\n",
      "07/27/2023 18:04:52 - INFO - __main__ - Cumulative validation average loss is 7.84482364426367\n",
      "07/27/2023 18:04:52 - INFO - __main__ - Per validation step average loss is 0.08307569473981857\n",
      "07/27/2023 18:04:52 - INFO - __main__ - Cumulative validation average loss is 7.927899339003488\n",
      "07/27/2023 18:04:53 - INFO - __main__ - Per validation step average loss is 0.5908856987953186\n",
      "07/27/2023 18:04:53 - INFO - __main__ - Cumulative validation average loss is 8.518785037798807\n",
      "07/27/2023 18:04:53 - INFO - __main__ - Per validation step average loss is 0.34865623712539673\n",
      "07/27/2023 18:04:53 - INFO - __main__ - Cumulative validation average loss is 8.867441274924204\n",
      "07/27/2023 18:04:54 - INFO - __main__ - Per validation step average loss is 0.004139942117035389\n",
      "07/27/2023 18:04:54 - INFO - __main__ - Cumulative validation average loss is 8.87158121704124\n",
      "07/27/2023 18:04:54 - INFO - __main__ - Per validation step average loss is 0.38608837127685547\n",
      "07/27/2023 18:04:54 - INFO - __main__ - Cumulative validation average loss is 9.257669588318095\n",
      "07/27/2023 18:04:54 - INFO - __main__ - Per validation step average loss is 0.1070428192615509\n",
      "07/27/2023 18:04:54 - INFO - __main__ - Cumulative validation average loss is 9.364712407579646\n",
      "07/27/2023 18:04:55 - INFO - __main__ - Per validation step average loss is 0.011054502800107002\n",
      "07/27/2023 18:04:55 - INFO - __main__ - Cumulative validation average loss is 9.375766910379753\n",
      "07/27/2023 18:04:55 - INFO - __main__ - Per validation step average loss is 0.14504200220108032\n",
      "07/27/2023 18:04:55 - INFO - __main__ - Cumulative validation average loss is 9.520808912580833\n",
      "07/27/2023 18:04:56 - INFO - __main__ - Per validation step average loss is 0.2901795208454132\n",
      "07/27/2023 18:04:56 - INFO - __main__ - Cumulative validation average loss is 9.810988433426246\n",
      "07/27/2023 18:04:56 - INFO - __main__ - Per validation step average loss is 0.03037519007921219\n",
      "07/27/2023 18:04:56 - INFO - __main__ - Cumulative validation average loss is 9.841363623505458\n",
      "07/27/2023 18:04:56 - INFO - __main__ - Per validation step average loss is 0.029040399938821793\n",
      "07/27/2023 18:04:56 - INFO - __main__ - Cumulative validation average loss is 9.87040402344428\n",
      "07/27/2023 18:04:57 - INFO - __main__ - Per validation step average loss is 0.12743337452411652\n",
      "07/27/2023 18:04:57 - INFO - __main__ - Cumulative validation average loss is 9.997837397968397\n",
      "07/27/2023 18:04:57 - INFO - __main__ - Per validation step average loss is 0.006818701047450304\n",
      "07/27/2023 18:04:57 - INFO - __main__ - Cumulative validation average loss is 10.004656099015847\n",
      "07/27/2023 18:04:58 - INFO - __main__ - Per validation step average loss is 0.03764570876955986\n",
      "07/27/2023 18:04:58 - INFO - __main__ - Cumulative validation average loss is 10.042301807785407\n",
      "07/27/2023 18:04:58 - INFO - __main__ - Per validation step average loss is 0.19768108427524567\n",
      "07/27/2023 18:04:58 - INFO - __main__ - Cumulative validation average loss is 10.239982892060652\n",
      "07/27/2023 18:04:59 - INFO - __main__ - Per validation step average loss is 0.4976200759410858\n",
      "07/27/2023 18:04:59 - INFO - __main__ - Cumulative validation average loss is 10.737602968001738\n",
      "07/27/2023 18:04:59 - INFO - __main__ - Per validation step average loss is 0.0030266903340816498\n",
      "07/27/2023 18:04:59 - INFO - __main__ - Cumulative validation average loss is 10.74062965833582\n",
      "07/27/2023 18:05:00 - INFO - __main__ - Per validation step average loss is 0.23429745435714722\n",
      "07/27/2023 18:05:00 - INFO - __main__ - Cumulative validation average loss is 10.974927112692967\n",
      "07/27/2023 18:05:00 - INFO - __main__ - Average validation loss for Epoch 7 is 0.13892312800877174\n",
      "07/27/2023 18:05:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:05:57 - INFO - __main__ - Starting epoch 8\n",
      "07/27/2023 18:05:58 - INFO - __main__ - train loss is 0.10756787657737732\n",
      "Steps:  16%|▏| 2425/15000 [21:08<96:06:40, 27.51s/it, lr=0.000302, step_loss=0.107/27/2023 18:05:58 - INFO - __main__ - train loss is 0.22881264984607697\n",
      "Steps:  16%|▏| 2426/15000 [21:08<67:28:18, 19.32s/it, lr=0.000302, step_loss=0.107/27/2023 18:05:58 - INFO - __main__ - train loss is 0.23204956809058785\n",
      "Steps:  16%|▏| 2427/15000 [21:08<47:25:04, 13.58s/it, lr=0.000302, step_loss=0.007/27/2023 18:05:58 - INFO - __main__ - train loss is 0.5390686825849116\n",
      "Steps:  16%|▏| 2428/15000 [21:08<33:22:40,  9.56s/it, lr=0.000302, step_loss=0.307/27/2023 18:05:58 - INFO - __main__ - train loss is 0.6917726532556117\n",
      "Steps:  16%|▏| 2429/15000 [21:09<23:33:14,  6.75s/it, lr=0.000302, step_loss=0.107/27/2023 18:05:58 - INFO - __main__ - train loss is 0.9058783487416804\n",
      "Steps:  16%|▏| 2430/15000 [21:09<16:40:30,  4.78s/it, lr=0.000302, step_loss=0.207/27/2023 18:05:59 - INFO - __main__ - train loss is 0.927063109818846\n",
      "Steps:  16%|▏| 2431/15000 [21:09<11:51:38,  3.40s/it, lr=0.000302, step_loss=0.007/27/2023 18:05:59 - INFO - __main__ - train loss is 0.9326226538978517\n",
      "Steps:  16%|▏| 2432/15000 [21:09<8:29:21,  2.43s/it, lr=0.000302, step_loss=0.0007/27/2023 18:05:59 - INFO - __main__ - train loss is 0.9498742180876434\n",
      "Steps:  16%|▏| 2433/15000 [21:09<6:07:51,  1.76s/it, lr=0.000303, step_loss=0.0107/27/2023 18:05:59 - INFO - __main__ - train loss is 0.9568326524458826\n",
      "Steps:  16%|▏| 2434/15000 [21:09<4:28:43,  1.28s/it, lr=0.000303, step_loss=0.0007/27/2023 18:05:59 - INFO - __main__ - train loss is 1.0371110043488443\n",
      "Steps:  16%|▏| 2435/15000 [21:10<3:19:19,  1.05it/s, lr=0.000303, step_loss=0.0807/27/2023 18:06:00 - INFO - __main__ - train loss is 1.1147824353538454\n",
      "Steps:  16%|▏| 2436/15000 [21:10<2:30:44,  1.39it/s, lr=0.000303, step_loss=0.0707/27/2023 18:06:00 - INFO - __main__ - train loss is 1.2256139270029962\n",
      "Steps:  16%|▏| 2437/15000 [21:10<1:56:48,  1.79it/s, lr=0.000303, step_loss=0.1107/27/2023 18:06:00 - INFO - __main__ - train loss is 1.6981368116103113\n",
      "Steps:  16%|▏| 2438/15000 [21:10<1:32:57,  2.25it/s, lr=0.000303, step_loss=0.4707/27/2023 18:06:00 - INFO - __main__ - train loss is 1.704934122506529\n",
      "Steps:  16%|▏| 2439/15000 [21:10<1:16:17,  2.74it/s, lr=0.000303, step_loss=0.0007/27/2023 18:06:00 - INFO - __main__ - train loss is 1.7382927709259093\n",
      "Steps:  16%|▏| 2440/15000 [21:11<1:04:35,  3.24it/s, lr=0.000304, step_loss=0.0307/27/2023 18:06:00 - INFO - __main__ - train loss is 1.7444167495705187\n",
      "Steps:  16%|▏| 2441/15000 [21:11<56:23,  3.71it/s, lr=0.000304, step_loss=0.006107/27/2023 18:06:01 - INFO - __main__ - train loss is 1.7485663332045078\n",
      "Steps:  16%|▏| 2442/15000 [21:11<50:41,  4.13it/s, lr=0.000304, step_loss=0.004107/27/2023 18:06:01 - INFO - __main__ - train loss is 1.7572997519746423\n",
      "Steps:  16%|▏| 2443/15000 [21:11<46:42,  4.48it/s, lr=0.000304, step_loss=0.008707/27/2023 18:06:01 - INFO - __main__ - train loss is 2.4635438630357385\n",
      "Steps:  16%|▏| 2444/15000 [21:11<43:58,  4.76it/s, lr=0.000304, step_loss=0.706]07/27/2023 18:06:01 - INFO - __main__ - train loss is 3.3409993359819055\n",
      "Steps:  16%|▏| 2445/15000 [21:11<42:21,  4.94it/s, lr=0.000304, step_loss=0.877]07/27/2023 18:06:01 - INFO - __main__ - train loss is 3.34245282842312\n",
      "Steps:  16%|▏| 2446/15000 [21:12<41:06,  5.09it/s, lr=0.000304, step_loss=0.001407/27/2023 18:06:02 - INFO - __main__ - train loss is 3.409295846358873\n",
      "Steps:  16%|▏| 2447/15000 [21:12<39:58,  5.23it/s, lr=0.000304, step_loss=0.066807/27/2023 18:06:02 - INFO - __main__ - train loss is 3.417186326929368\n",
      "Steps:  16%|▏| 2448/15000 [21:12<39:12,  5.34it/s, lr=0.000304, step_loss=0.007807/27/2023 18:06:02 - INFO - __main__ - train loss is 3.5634286772692576\n",
      "Steps:  16%|▏| 2449/15000 [21:12<38:39,  5.41it/s, lr=0.000305, step_loss=0.146]07/27/2023 18:06:02 - INFO - __main__ - train loss is 3.56546246598009\n",
      "Steps:  16%|▏| 2450/15000 [21:12<38:17,  5.46it/s, lr=0.000305, step_loss=0.002007/27/2023 18:06:02 - INFO - __main__ - train loss is 3.587824971997179\n",
      "Steps:  16%|▏| 2451/15000 [21:13<38:01,  5.50it/s, lr=0.000305, step_loss=0.022407/27/2023 18:06:02 - INFO - __main__ - train loss is 4.031735064112581\n",
      "Steps:  16%|▏| 2452/15000 [21:13<37:52,  5.52it/s, lr=0.000305, step_loss=0.444]07/27/2023 18:06:03 - INFO - __main__ - train loss is 4.270010785781778\n",
      "Steps:  16%|▏| 2453/15000 [21:13<37:44,  5.54it/s, lr=0.000305, step_loss=0.238]07/27/2023 18:06:03 - INFO - __main__ - train loss is 4.274635609821416\n",
      "Steps:  16%|▏| 2454/15000 [21:13<38:00,  5.50it/s, lr=0.000305, step_loss=0.004607/27/2023 18:06:03 - INFO - __main__ - train loss is 4.456936192349531\n",
      "Steps:  16%|▏| 2455/15000 [21:13<38:29,  5.43it/s, lr=0.000305, step_loss=0.182]07/27/2023 18:06:03 - INFO - __main__ - train loss is 4.458795268670656\n",
      "Steps:  16%|▏| 2456/15000 [21:13<38:11,  5.47it/s, lr=0.000305, step_loss=0.001807/27/2023 18:06:03 - INFO - __main__ - train loss is 4.75820209516678\n",
      "Steps:  16%|▏| 2457/15000 [21:14<38:17,  5.46it/s, lr=0.000306, step_loss=0.299]07/27/2023 18:06:04 - INFO - __main__ - train loss is 4.781962071196176\n",
      "Steps:  16%|▏| 2458/15000 [21:14<38:21,  5.45it/s, lr=0.000306, step_loss=0.023807/27/2023 18:06:04 - INFO - __main__ - train loss is 4.785236525698565\n",
      "Steps:  16%|▏| 2459/15000 [21:14<38:04,  5.49it/s, lr=0.000306, step_loss=0.003207/27/2023 18:06:04 - INFO - __main__ - train loss is 4.828225626959465\n",
      "Steps:  16%|▏| 2460/15000 [21:14<38:13,  5.47it/s, lr=0.000306, step_loss=0.043]07/27/2023 18:06:04 - INFO - __main__ - train loss is 5.46505452634301\n",
      "Steps:  16%|▏| 2461/15000 [21:14<38:06,  5.48it/s, lr=0.000306, step_loss=0.637]07/27/2023 18:06:04 - INFO - __main__ - train loss is 5.473194048157893\n",
      "Steps:  16%|▏| 2462/15000 [21:15<37:53,  5.51it/s, lr=0.000306, step_loss=0.008107/27/2023 18:06:04 - INFO - __main__ - train loss is 5.518746883026324\n",
      "Steps:  16%|▏| 2463/15000 [21:15<37:43,  5.54it/s, lr=0.000306, step_loss=0.045607/27/2023 18:06:05 - INFO - __main__ - train loss is 5.522286223829724\n",
      "Steps:  16%|▏| 2464/15000 [21:15<37:38,  5.55it/s, lr=0.000307, step_loss=0.003507/27/2023 18:06:05 - INFO - __main__ - train loss is 5.929076122702099\n",
      "Steps:  16%|▏| 2465/15000 [21:15<37:33,  5.56it/s, lr=0.000307, step_loss=0.407]07/27/2023 18:06:05 - INFO - __main__ - train loss is 5.937702591181733\n",
      "Steps:  16%|▏| 2466/15000 [21:15<37:30,  5.57it/s, lr=0.000307, step_loss=0.008607/27/2023 18:06:05 - INFO - __main__ - train loss is 6.428490335703827\n",
      "Steps:  16%|▏| 2467/15000 [21:15<37:28,  5.57it/s, lr=0.000307, step_loss=0.491]07/27/2023 18:06:05 - INFO - __main__ - train loss is 7.10831778740976\n",
      "Steps:  16%|▎ | 2468/15000 [21:16<37:27,  5.58it/s, lr=0.000307, step_loss=0.68]07/27/2023 18:06:05 - INFO - __main__ - train loss is 7.114157376461662\n",
      "Steps:  16%|▏| 2469/15000 [21:16<37:25,  5.58it/s, lr=0.000307, step_loss=0.005807/27/2023 18:06:06 - INFO - __main__ - train loss is 7.118240759358741\n",
      "Steps:  16%|▏| 2470/15000 [21:16<37:24,  5.58it/s, lr=0.000307, step_loss=0.004007/27/2023 18:06:06 - INFO - __main__ - train loss is 7.119877085206099\n",
      "Steps:  16%|▏| 2471/15000 [21:16<37:25,  5.58it/s, lr=0.000307, step_loss=0.001607/27/2023 18:06:06 - INFO - __main__ - train loss is 7.35442160081584\n",
      "Steps:  16%|▏| 2472/15000 [21:16<37:25,  5.58it/s, lr=0.000307, step_loss=0.235]07/27/2023 18:06:06 - INFO - __main__ - train loss is 7.397852942463942\n",
      "Steps:  16%|▏| 2473/15000 [21:17<37:25,  5.58it/s, lr=0.000308, step_loss=0.043407/27/2023 18:06:06 - INFO - __main__ - train loss is 7.6440542788477615\n",
      "Steps:  16%|▏| 2474/15000 [21:17<37:44,  5.53it/s, lr=0.000308, step_loss=0.246]07/27/2023 18:06:07 - INFO - __main__ - train loss is 7.970584616181441\n",
      "Steps:  16%|▏| 2475/15000 [21:17<37:37,  5.55it/s, lr=0.000308, step_loss=0.327]07/27/2023 18:06:07 - INFO - __main__ - train loss is 7.994391903397627\n",
      "Steps:  17%|▏| 2476/15000 [21:17<37:32,  5.56it/s, lr=0.000308, step_loss=0.023807/27/2023 18:06:07 - INFO - __main__ - train loss is 7.996565569075756\n",
      "Steps:  17%|▏| 2477/15000 [21:17<37:28,  5.57it/s, lr=0.000308, step_loss=0.002107/27/2023 18:06:07 - INFO - __main__ - train loss is 8.009292995440774\n",
      "Steps:  17%|▏| 2478/15000 [21:17<37:27,  5.57it/s, lr=0.000308, step_loss=0.012707/27/2023 18:06:07 - INFO - __main__ - train loss is 8.056112130987458\n",
      "Steps:  17%|▏| 2479/15000 [21:18<37:24,  5.58it/s, lr=0.000308, step_loss=0.046807/27/2023 18:06:07 - INFO - __main__ - train loss is 8.118499969947152\n",
      "Steps:  17%|▏| 2480/15000 [21:18<37:23,  5.58it/s, lr=0.000309, step_loss=0.062407/27/2023 18:06:08 - INFO - __main__ - train loss is 8.272891541826539\n",
      "Steps:  17%|▏| 2481/15000 [21:18<37:21,  5.59it/s, lr=0.000309, step_loss=0.154]07/27/2023 18:06:08 - INFO - __main__ - train loss is 8.284989151987247\n",
      "Steps:  17%|▏| 2482/15000 [21:18<37:19,  5.59it/s, lr=0.000309, step_loss=0.012107/27/2023 18:06:08 - INFO - __main__ - train loss is 8.540092620882206\n",
      "Steps:  17%|▏| 2483/15000 [21:18<37:19,  5.59it/s, lr=0.000309, step_loss=0.255]07/27/2023 18:06:08 - INFO - __main__ - train loss is 8.591109715285711\n",
      "Steps:  17%|▏| 2484/15000 [21:18<37:18,  5.59it/s, lr=0.000309, step_loss=0.051]07/27/2023 18:06:08 - INFO - __main__ - train loss is 8.595756349037401\n",
      "Steps:  17%|▏| 2485/15000 [21:19<37:23,  5.58it/s, lr=0.000309, step_loss=0.004607/27/2023 18:06:09 - INFO - __main__ - train loss is 8.598194924532436\n",
      "Steps:  17%|▏| 2486/15000 [21:19<37:23,  5.58it/s, lr=0.000309, step_loss=0.002407/27/2023 18:06:09 - INFO - __main__ - train loss is 8.599592635291629\n",
      "Steps:  17%|▏| 2487/15000 [21:19<37:22,  5.58it/s, lr=0.000309, step_loss=0.001407/27/2023 18:06:09 - INFO - __main__ - train loss is 8.60833159822505\n",
      "Steps:  17%|▏| 2488/15000 [21:19<37:22,  5.58it/s, lr=0.000309, step_loss=0.008707/27/2023 18:06:09 - INFO - __main__ - train loss is 9.32701531786006\n",
      "Steps:  17%|▎ | 2489/15000 [21:19<37:20,  5.58it/s, lr=0.00031, step_loss=0.719]07/27/2023 18:06:09 - INFO - __main__ - train loss is 9.398660384002142\n",
      "Steps:  17%|▏| 2490/15000 [21:20<37:39,  5.54it/s, lr=0.00031, step_loss=0.0716]07/27/2023 18:06:09 - INFO - __main__ - train loss is 9.432951662573032\n",
      "Steps:  17%|▏| 2491/15000 [21:20<37:39,  5.54it/s, lr=0.00031, step_loss=0.0343]07/27/2023 18:06:10 - INFO - __main__ - train loss is 9.487495250883512\n",
      "Steps:  17%|▏| 2492/15000 [21:20<37:42,  5.53it/s, lr=0.00031, step_loss=0.0545]07/27/2023 18:06:10 - INFO - __main__ - train loss is 9.83766178030055\n",
      "Steps:  17%|▍  | 2493/15000 [21:20<37:45,  5.52it/s, lr=0.00031, step_loss=0.35]07/27/2023 18:06:10 - INFO - __main__ - train loss is 9.995347000542097\n",
      "Steps:  17%|▎ | 2494/15000 [21:20<37:47,  5.52it/s, lr=0.00031, step_loss=0.158]07/27/2023 18:06:10 - INFO - __main__ - train loss is 10.14429003733676\n",
      "Steps:  17%|▎ | 2495/15000 [21:20<37:46,  5.52it/s, lr=0.00031, step_loss=0.149]07/27/2023 18:06:10 - INFO - __main__ - train loss is 10.347905404749326\n",
      "Steps:  17%|▏| 2496/15000 [21:21<37:46,  5.52it/s, lr=0.000311, step_loss=0.204]07/27/2023 18:06:11 - INFO - __main__ - train loss is 10.449504800024442\n",
      "Steps:  17%|▏| 2497/15000 [21:21<37:46,  5.52it/s, lr=0.000311, step_loss=0.102]07/27/2023 18:06:11 - INFO - __main__ - train loss is 10.462354099261574\n",
      "Steps:  17%|▏| 2498/15000 [21:21<37:47,  5.51it/s, lr=0.000311, step_loss=0.012807/27/2023 18:06:11 - INFO - __main__ - train loss is 10.65643922041636\n",
      "Steps:  17%|▏| 2499/15000 [21:21<37:46,  5.51it/s, lr=0.000311, step_loss=0.194]07/27/2023 18:06:11 - INFO - __main__ - train loss is 11.039388453471474\n",
      "Steps:  17%|▏| 2500/15000 [21:21<37:46,  5.51it/s, lr=0.000311, step_loss=0.194]07/27/2023 18:06:11 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-2500\n",
      "07/27/2023 18:06:11 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:06:11,659] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:06:11,663] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:06:11,663] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:06:11,670] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:06:11,670] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:06:11,676] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:06:11,677] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:06:11,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:06:11 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-2500/pytorch_model\n",
      "07/27/2023 18:06:11 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-2500/scheduler.bin\n",
      "07/27/2023 18:06:11 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-2500/random_states_0.pkl\n",
      "07/27/2023 18:06:11 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-2500\n",
      "Steps:  17%|▏| 2500/15000 [21:21<37:46,  5.51it/s, lr=0.000311, step_loss=0.383]07/27/2023 18:06:11 - INFO - __main__ - train loss is 11.445856666075997\n",
      "Steps:  17%|▏| 2501/15000 [21:22<38:57,  5.35it/s, lr=0.000311, step_loss=0.406]07/27/2023 18:06:11 - INFO - __main__ - train loss is 11.756667708861642\n",
      "Steps:  17%|▏| 2502/15000 [21:22<38:36,  5.40it/s, lr=0.000311, step_loss=0.311]07/27/2023 18:06:12 - INFO - __main__ - train loss is 11.795456854510121\n",
      "Steps:  17%|▏| 2503/15000 [21:22<38:21,  5.43it/s, lr=0.000311, step_loss=0.038807/27/2023 18:06:12 - INFO - __main__ - train loss is 11.826759373652749\n",
      "Steps:  17%|▏| 2504/15000 [21:22<38:12,  5.45it/s, lr=0.000311, step_loss=0.031307/27/2023 18:06:12 - INFO - __main__ - train loss is 11.855916378903203\n",
      "Steps:  17%|▏| 2505/15000 [21:22<38:04,  5.47it/s, lr=0.000312, step_loss=0.029207/27/2023 18:06:12 - INFO - __main__ - train loss is 11.867488389718346\n",
      "Steps:  17%|▏| 2506/15000 [21:22<37:59,  5.48it/s, lr=0.000312, step_loss=0.011607/27/2023 18:06:12 - INFO - __main__ - train loss is 11.871821167762391\n",
      "Steps:  17%|▏| 2507/15000 [21:23<37:54,  5.49it/s, lr=0.000312, step_loss=0.004307/27/2023 18:06:13 - INFO - __main__ - train loss is 11.982404160196893\n",
      "Steps:  17%|▏| 2508/15000 [21:23<37:53,  5.49it/s, lr=0.000312, step_loss=0.111]07/27/2023 18:06:13 - INFO - __main__ - train loss is 12.060190300340764\n",
      "Steps:  17%|▏| 2509/15000 [21:23<37:50,  5.50it/s, lr=0.000312, step_loss=0.077807/27/2023 18:06:13 - INFO - __main__ - train loss is 12.080978094483726\n",
      "Steps:  17%|▏| 2510/15000 [21:23<37:49,  5.50it/s, lr=0.000312, step_loss=0.020807/27/2023 18:06:13 - INFO - __main__ - train loss is 12.438940434600227\n",
      "Steps:  17%|▏| 2511/15000 [21:23<37:47,  5.51it/s, lr=0.000312, step_loss=0.358]07/27/2023 18:06:13 - INFO - __main__ - train loss is 12.441196641302668\n",
      "Steps:  17%|▏| 2512/15000 [21:24<37:46,  5.51it/s, lr=0.000313, step_loss=0.002207/27/2023 18:06:13 - INFO - __main__ - train loss is 12.473863063729368\n",
      "Steps:  17%|▏| 2513/15000 [21:24<37:45,  5.51it/s, lr=0.000313, step_loss=0.032707/27/2023 18:06:14 - INFO - __main__ - train loss is 12.481507295160554\n",
      "Steps:  17%|▏| 2514/15000 [21:24<37:47,  5.51it/s, lr=0.000313, step_loss=0.007607/27/2023 18:06:14 - INFO - __main__ - train loss is 12.50169140973594\n",
      "Steps:  17%|▏| 2515/15000 [21:24<37:46,  5.51it/s, lr=0.000313, step_loss=0.020207/27/2023 18:06:14 - INFO - __main__ - train loss is 12.777948060422204\n",
      "Steps:  17%|▏| 2516/15000 [21:24<37:47,  5.51it/s, lr=0.000313, step_loss=0.276]07/27/2023 18:06:14 - INFO - __main__ - train loss is 12.879864969640039\n",
      "Steps:  17%|▏| 2517/15000 [21:24<37:45,  5.51it/s, lr=0.000313, step_loss=0.102]07/27/2023 18:06:14 - INFO - __main__ - train loss is 12.925245334743522\n",
      "Steps:  17%|▏| 2518/15000 [21:25<37:46,  5.51it/s, lr=0.000313, step_loss=0.045407/27/2023 18:06:15 - INFO - __main__ - train loss is 13.196773459552787\n",
      "Steps:  17%|▏| 2519/15000 [21:25<37:44,  5.51it/s, lr=0.000313, step_loss=0.272]07/27/2023 18:06:15 - INFO - __main__ - train loss is 13.203056244994514\n",
      "Steps:  17%|▏| 2520/15000 [21:25<37:44,  5.51it/s, lr=0.000314, step_loss=0.006207/27/2023 18:06:15 - INFO - __main__ - train loss is 13.583003430510871\n",
      "Steps:  17%|▎ | 2521/15000 [21:25<37:44,  5.51it/s, lr=0.000314, step_loss=0.38]07/27/2023 18:06:15 - INFO - __main__ - train loss is 13.59032359009143\n",
      "Steps:  17%|▏| 2522/15000 [21:25<37:44,  5.51it/s, lr=0.000314, step_loss=0.007307/27/2023 18:06:15 - INFO - __main__ - train loss is 13.623502213857137\n",
      "Steps:  17%|▏| 2523/15000 [21:26<37:43,  5.51it/s, lr=0.000314, step_loss=0.033207/27/2023 18:06:15 - INFO - __main__ - train loss is 14.007341970107518\n",
      "Steps:  17%|▏| 2524/15000 [21:26<37:43,  5.51it/s, lr=0.000314, step_loss=0.384]07/27/2023 18:06:16 - INFO - __main__ - train loss is 14.022137064835988\n",
      "Steps:  17%|▏| 2525/15000 [21:26<37:42,  5.51it/s, lr=0.000314, step_loss=0.014807/27/2023 18:06:16 - INFO - __main__ - train loss is 14.027397427125834\n",
      "Steps:  17%|▏| 2526/15000 [21:26<37:43,  5.51it/s, lr=0.000314, step_loss=0.005207/27/2023 18:06:16 - INFO - __main__ - train loss is 14.19440329389181\n",
      "Steps:  17%|▏| 2527/15000 [21:26<37:42,  5.51it/s, lr=0.000314, step_loss=0.167]07/27/2023 18:06:16 - INFO - __main__ - train loss is 14.262990515097044\n",
      "Steps:  17%|▏| 2528/15000 [21:26<37:43,  5.51it/s, lr=0.000315, step_loss=0.068607/27/2023 18:06:16 - INFO - __main__ - train loss is 14.732408504351042\n",
      "Steps:  17%|▏| 2529/15000 [21:27<37:43,  5.51it/s, lr=0.000315, step_loss=0.469]07/27/2023 18:06:17 - INFO - __main__ - train loss is 14.864149223431014\n",
      "Steps:  17%|▏| 2530/15000 [21:27<37:44,  5.51it/s, lr=0.000315, step_loss=0.132]07/27/2023 18:06:17 - INFO - __main__ - train loss is 15.160780321224593\n",
      "Steps:  17%|▏| 2531/15000 [21:27<37:43,  5.51it/s, lr=0.000315, step_loss=0.297]07/27/2023 18:06:17 - INFO - __main__ - train loss is 15.196823518141173\n",
      "Steps:  17%|▏| 2532/15000 [21:27<37:43,  5.51it/s, lr=0.000315, step_loss=0.036]07/27/2023 18:06:17 - INFO - __main__ - train loss is 15.200221580336802\n",
      "Steps:  17%|▏| 2533/15000 [21:27<37:43,  5.51it/s, lr=0.000315, step_loss=0.003407/27/2023 18:06:17 - INFO - __main__ - train loss is 15.254189324448816\n",
      "Steps:  17%|▏| 2534/15000 [21:28<37:43,  5.51it/s, lr=0.000315, step_loss=0.054]07/27/2023 18:06:17 - INFO - __main__ - train loss is 15.610426080296747\n",
      "Steps:  17%|▏| 2535/15000 [21:28<37:42,  5.51it/s, lr=0.000315, step_loss=0.356]07/27/2023 18:06:18 - INFO - __main__ - train loss is 15.623261569882743\n",
      "Steps:  17%|▏| 2536/15000 [21:28<37:42,  5.51it/s, lr=0.000316, step_loss=0.012807/27/2023 18:06:18 - INFO - __main__ - train loss is 15.627589749987237\n",
      "Steps:  17%|▏| 2537/15000 [21:28<37:42,  5.51it/s, lr=0.000316, step_loss=0.004307/27/2023 18:06:18 - INFO - __main__ - train loss is 15.630065773031674\n",
      "Steps:  17%|▏| 2538/15000 [21:28<37:43,  5.51it/s, lr=0.000316, step_loss=0.002407/27/2023 18:06:18 - INFO - __main__ - train loss is 16.088603351614438\n",
      "Steps:  17%|▏| 2539/15000 [21:28<37:44,  5.50it/s, lr=0.000316, step_loss=0.459]07/27/2023 18:06:18 - INFO - __main__ - train loss is 16.411992255947553\n",
      "Steps:  17%|▏| 2540/15000 [21:29<37:35,  5.53it/s, lr=0.000316, step_loss=0.323]07/27/2023 18:06:19 - INFO - __main__ - train loss is 16.595301602385007\n",
      "Steps:  17%|▏| 2541/15000 [21:29<37:27,  5.54it/s, lr=0.000316, step_loss=0.183]07/27/2023 18:06:19 - INFO - __main__ - train loss is 16.910127047798596\n",
      "Steps:  17%|▏| 2542/15000 [21:29<37:23,  5.55it/s, lr=0.000316, step_loss=0.315]07/27/2023 18:06:19 - INFO - __main__ - train loss is 16.93310179223772\n",
      "Steps:  17%|▏| 2543/15000 [21:29<37:18,  5.56it/s, lr=0.000316, step_loss=0.023]07/27/2023 18:06:19 - INFO - __main__ - train loss is 16.935431033489294\n",
      "Steps:  17%|▏| 2544/15000 [21:29<37:15,  5.57it/s, lr=0.000316, step_loss=0.002307/27/2023 18:06:19 - INFO - __main__ - train loss is 17.018297970411368\n",
      "Steps:  17%|▏| 2545/15000 [21:30<37:13,  5.58it/s, lr=0.000317, step_loss=0.082907/27/2023 18:06:19 - INFO - __main__ - train loss is 17.019988813670352\n",
      "Steps:  17%|▏| 2546/15000 [21:30<37:13,  5.58it/s, lr=0.000317, step_loss=0.001607/27/2023 18:06:20 - INFO - __main__ - train loss is 17.109987535746768\n",
      "Steps:  17%|▎ | 2547/15000 [21:30<37:20,  5.56it/s, lr=0.000317, step_loss=0.09]07/27/2023 18:06:20 - INFO - __main__ - train loss is 17.37435577181168\n",
      "Steps:  17%|▏| 2548/15000 [21:30<37:27,  5.54it/s, lr=0.000317, step_loss=0.264]07/27/2023 18:06:20 - INFO - __main__ - train loss is 17.386669296072796\n",
      "Steps:  17%|▏| 2549/15000 [21:30<37:32,  5.53it/s, lr=0.000317, step_loss=0.012307/27/2023 18:06:20 - INFO - __main__ - train loss is 17.546633842634037\n",
      "Steps:  17%|▎ | 2550/15000 [21:30<37:35,  5.52it/s, lr=0.000317, step_loss=0.16]07/27/2023 18:06:20 - INFO - __main__ - train loss is 17.785645219730213\n",
      "Steps:  17%|▏| 2551/15000 [21:31<37:38,  5.51it/s, lr=0.000317, step_loss=0.239]07/27/2023 18:06:21 - INFO - __main__ - train loss is 17.78941245819442\n",
      "Steps:  17%|▏| 2552/15000 [21:31<37:29,  5.53it/s, lr=0.000318, step_loss=0.003707/27/2023 18:06:21 - INFO - __main__ - train loss is 17.846460410160944\n",
      "Steps:  17%|▏| 2553/15000 [21:31<37:21,  5.55it/s, lr=0.000318, step_loss=0.057]07/27/2023 18:06:21 - INFO - __main__ - train loss is 17.903726246906444\n",
      "Steps:  17%|▏| 2554/15000 [21:31<37:17,  5.56it/s, lr=0.000318, step_loss=0.057307/27/2023 18:06:21 - INFO - __main__ - train loss is 17.906969813862815\n",
      "Steps:  17%|▏| 2555/15000 [21:31<37:13,  5.57it/s, lr=0.000318, step_loss=0.003207/27/2023 18:06:21 - INFO - __main__ - train loss is 17.920289654517546\n",
      "Steps:  17%|▏| 2556/15000 [21:32<37:12,  5.57it/s, lr=0.000318, step_loss=0.013307/27/2023 18:06:21 - INFO - __main__ - train loss is 17.939609579974785\n",
      "Steps:  17%|▏| 2557/15000 [21:32<37:10,  5.58it/s, lr=0.000318, step_loss=0.019307/27/2023 18:06:22 - INFO - __main__ - train loss is 18.121260054642335\n",
      "Steps:  17%|▏| 2558/15000 [21:32<37:11,  5.58it/s, lr=0.000318, step_loss=0.182]07/27/2023 18:06:22 - INFO - __main__ - train loss is 18.124866192229092\n",
      "Steps:  17%|▏| 2559/15000 [21:32<37:09,  5.58it/s, lr=0.000318, step_loss=0.003607/27/2023 18:06:22 - INFO - __main__ - train loss is 18.317127470858395\n",
      "Steps:  17%|▏| 2560/15000 [21:32<37:08,  5.58it/s, lr=0.000318, step_loss=0.192]07/27/2023 18:06:22 - INFO - __main__ - train loss is 18.3266262980178\n",
      "Steps:  17%|▏| 2561/15000 [21:32<37:07,  5.58it/s, lr=0.000319, step_loss=0.009507/27/2023 18:06:22 - INFO - __main__ - train loss is 18.33621025364846\n",
      "Steps:  17%|▏| 2562/15000 [21:33<37:07,  5.58it/s, lr=0.000319, step_loss=0.009507/27/2023 18:06:22 - INFO - __main__ - train loss is 18.341537466738373\n",
      "Steps:  17%|▏| 2563/15000 [21:33<37:07,  5.58it/s, lr=0.000319, step_loss=0.005307/27/2023 18:06:23 - INFO - __main__ - train loss is 18.519749543163925\n",
      "Steps:  17%|▏| 2564/15000 [21:33<37:08,  5.58it/s, lr=0.000319, step_loss=0.178]07/27/2023 18:06:23 - INFO - __main__ - train loss is 18.85864274809137\n",
      "Steps:  17%|▏| 2565/15000 [21:33<37:09,  5.58it/s, lr=0.000319, step_loss=0.339]07/27/2023 18:06:23 - INFO - __main__ - train loss is 18.88363665388897\n",
      "Steps:  17%|▏| 2566/15000 [21:33<37:09,  5.58it/s, lr=0.000319, step_loss=0.025]07/27/2023 18:06:23 - INFO - __main__ - train loss is 19.262558669317514\n",
      "Steps:  17%|▏| 2567/15000 [21:34<37:08,  5.58it/s, lr=0.000319, step_loss=0.379]07/27/2023 18:06:23 - INFO - __main__ - train loss is 19.382744171191007\n",
      "Steps:  17%|▌  | 2568/15000 [21:34<37:08,  5.58it/s, lr=0.00032, step_loss=0.12]07/27/2023 18:06:24 - INFO - __main__ - train loss is 19.45838610129431\n",
      "Steps:  17%|▏| 2569/15000 [21:34<37:06,  5.58it/s, lr=0.00032, step_loss=0.0756]07/27/2023 18:06:24 - INFO - __main__ - train loss is 19.46154097514227\n",
      "Steps:  17%|▏| 2570/15000 [21:34<37:06,  5.58it/s, lr=0.00032, step_loss=0.0031507/27/2023 18:06:24 - INFO - __main__ - train loss is 19.58931014733389\n",
      "Steps:  17%|▎ | 2571/15000 [21:34<37:04,  5.59it/s, lr=0.00032, step_loss=0.128]07/27/2023 18:06:24 - INFO - __main__ - train loss is 19.69577332632616\n",
      "Steps:  17%|▎ | 2572/15000 [21:34<37:05,  5.59it/s, lr=0.00032, step_loss=0.106]07/27/2023 18:06:24 - INFO - __main__ - train loss is 19.71546095283702\n",
      "Steps:  17%|▏| 2573/15000 [21:35<37:04,  5.59it/s, lr=0.00032, step_loss=0.0197]07/27/2023 18:06:24 - INFO - __main__ - train loss is 19.9561651465483\n",
      "Steps:  17%|▎ | 2574/15000 [21:35<37:06,  5.58it/s, lr=0.00032, step_loss=0.241]07/27/2023 18:06:25 - INFO - __main__ - train loss is 20.12436827691272\n",
      "Steps:  17%|▎ | 2575/15000 [21:35<37:05,  5.58it/s, lr=0.00032, step_loss=0.168]07/27/2023 18:06:25 - INFO - __main__ - train loss is 20.143519817385823\n",
      "Steps:  17%|▏| 2576/15000 [21:35<37:05,  5.58it/s, lr=0.000321, step_loss=0.019207/27/2023 18:06:25 - INFO - __main__ - train loss is 20.503683208022267\n",
      "Steps:  17%|▎ | 2577/15000 [21:35<37:05,  5.58it/s, lr=0.000321, step_loss=0.36]07/27/2023 18:06:25 - INFO - __main__ - train loss is 20.7292131469585\n",
      "Steps:  17%|▏| 2578/15000 [21:35<37:05,  5.58it/s, lr=0.000321, step_loss=0.226]07/27/2023 18:06:25 - INFO - __main__ - train loss is 20.7540346221067\n",
      "Steps:  17%|▏| 2579/15000 [21:36<37:04,  5.58it/s, lr=0.000321, step_loss=0.024807/27/2023 18:06:26 - INFO - __main__ - train loss is 20.790334346238524\n",
      "Steps:  17%|▏| 2580/15000 [21:36<37:06,  5.58it/s, lr=0.000321, step_loss=0.036307/27/2023 18:06:26 - INFO - __main__ - train loss is 20.924375417176634\n",
      "Steps:  17%|▏| 2581/15000 [21:36<37:05,  5.58it/s, lr=0.000321, step_loss=0.134]07/27/2023 18:06:26 - INFO - __main__ - train loss is 20.969551207963377\n",
      "Steps:  17%|▏| 2582/15000 [21:36<37:05,  5.58it/s, lr=0.000321, step_loss=0.045207/27/2023 18:06:26 - INFO - __main__ - train loss is 21.52843970293179\n",
      "Steps:  17%|▏| 2583/15000 [21:36<37:03,  5.58it/s, lr=0.000321, step_loss=0.559]07/27/2023 18:06:26 - INFO - __main__ - train loss is 21.93885791534558\n",
      "Steps:  17%|▎ | 2584/15000 [21:37<37:03,  5.59it/s, lr=0.000322, step_loss=0.41]07/27/2023 18:06:26 - INFO - __main__ - train loss is 21.9432293609716\n",
      "Steps:  17%|▏| 2585/15000 [21:37<37:01,  5.59it/s, lr=0.000322, step_loss=0.004307/27/2023 18:06:27 - INFO - __main__ - train loss is 21.946128421463072\n",
      "Steps:  17%|▏| 2586/15000 [21:37<37:01,  5.59it/s, lr=0.000322, step_loss=0.002907/27/2023 18:06:27 - INFO - __main__ - train loss is 21.970236376859248\n",
      "Steps:  17%|▏| 2587/15000 [21:37<37:01,  5.59it/s, lr=0.000322, step_loss=0.024107/27/2023 18:06:27 - INFO - __main__ - train loss is 22.19998170528561\n",
      "Steps:  17%|▎ | 2588/15000 [21:37<37:02,  5.59it/s, lr=0.000322, step_loss=0.23]07/27/2023 18:06:27 - INFO - __main__ - train loss is 22.336526290513575\n",
      "Steps:  17%|▏| 2589/15000 [21:37<37:24,  5.53it/s, lr=0.000322, step_loss=0.137]07/27/2023 18:06:27 - INFO - __main__ - train loss is 22.33857247652486\n",
      "Steps:  17%|▏| 2590/15000 [21:38<37:51,  5.46it/s, lr=0.000322, step_loss=0.002007/27/2023 18:06:28 - INFO - __main__ - train loss is 22.342726065777242\n",
      "Steps:  17%|▏| 2591/15000 [21:38<37:47,  5.47it/s, lr=0.000322, step_loss=0.004107/27/2023 18:06:28 - INFO - __main__ - train loss is 22.357068188488483\n",
      "Steps:  17%|▏| 2592/15000 [21:38<37:42,  5.48it/s, lr=0.000323, step_loss=0.014307/27/2023 18:06:28 - INFO - __main__ - train loss is 22.361430435441434\n",
      "Steps:  17%|▏| 2593/15000 [21:38<37:39,  5.49it/s, lr=0.000323, step_loss=0.004307/27/2023 18:06:28 - INFO - __main__ - train loss is 22.36360619124025\n",
      "Steps:  17%|▏| 2594/15000 [21:38<38:01,  5.44it/s, lr=0.000323, step_loss=0.002107/27/2023 18:06:28 - INFO - __main__ - train loss is 22.610340512357652\n",
      "Steps:  17%|▏| 2595/15000 [21:39<38:39,  5.35it/s, lr=0.000323, step_loss=0.247]07/27/2023 18:06:28 - INFO - __main__ - train loss is 22.7622305219993\n",
      "Steps:  17%|▏| 2596/15000 [21:39<39:07,  5.28it/s, lr=0.000323, step_loss=0.152]07/27/2023 18:06:29 - INFO - __main__ - train loss is 23.188002205453813\n",
      "Steps:  17%|▏| 2597/15000 [21:39<39:30,  5.23it/s, lr=0.000323, step_loss=0.426]07/27/2023 18:06:29 - INFO - __main__ - train loss is 23.191727986559272\n",
      "Steps:  17%|▏| 2598/15000 [21:39<39:27,  5.24it/s, lr=0.000323, step_loss=0.003707/27/2023 18:06:29 - INFO - __main__ - train loss is 23.356222977861762\n",
      "Steps:  17%|▏| 2599/15000 [21:39<39:39,  5.21it/s, lr=0.000323, step_loss=0.164]07/27/2023 18:06:29 - INFO - __main__ - train loss is 23.357463066698983\n",
      "Steps:  17%|▏| 2600/15000 [21:40<39:50,  5.19it/s, lr=0.000324, step_loss=0.001207/27/2023 18:06:29 - INFO - __main__ - train loss is 23.36042454582639\n",
      "Steps:  17%|▏| 2601/15000 [21:40<39:56,  5.17it/s, lr=0.000324, step_loss=0.002907/27/2023 18:06:30 - INFO - __main__ - train loss is 23.57477116328664\n",
      "Steps:  17%|▏| 2602/15000 [21:40<39:51,  5.18it/s, lr=0.000324, step_loss=0.214]07/27/2023 18:06:30 - INFO - __main__ - train loss is 23.576936803990975\n",
      "Steps:  17%|▏| 2603/15000 [21:40<39:20,  5.25it/s, lr=0.000324, step_loss=0.002107/27/2023 18:06:30 - INFO - __main__ - train loss is 23.65426402562298\n",
      "Steps:  17%|▏| 2604/15000 [21:40<39:20,  5.25it/s, lr=0.000324, step_loss=0.077307/27/2023 18:06:30 - INFO - __main__ - train loss is 23.669646673137322\n",
      "Steps:  17%|▏| 2605/15000 [21:40<38:46,  5.33it/s, lr=0.000324, step_loss=0.015407/27/2023 18:06:30 - INFO - __main__ - train loss is 23.678978542098776\n",
      "Steps:  17%|▏| 2606/15000 [21:41<38:15,  5.40it/s, lr=0.000324, step_loss=0.009307/27/2023 18:06:31 - INFO - __main__ - train loss is 23.802203187951818\n",
      "Steps:  17%|▏| 2607/15000 [21:41<37:53,  5.45it/s, lr=0.000324, step_loss=0.123]07/27/2023 18:06:31 - INFO - __main__ - train loss is 24.54319758177735\n",
      "Steps:  17%|▏| 2608/15000 [21:41<37:38,  5.49it/s, lr=0.000325, step_loss=0.741]07/27/2023 18:06:31 - INFO - __main__ - train loss is 24.69260017038323\n",
      "Steps:  17%|▏| 2609/15000 [21:41<37:27,  5.51it/s, lr=0.000325, step_loss=0.149]07/27/2023 18:06:31 - INFO - __main__ - train loss is 24.792035969207063\n",
      "Steps:  17%|▏| 2610/15000 [21:41<37:18,  5.53it/s, lr=0.000325, step_loss=0.099407/27/2023 18:06:31 - INFO - __main__ - train loss is 24.7937926184386\n",
      "Steps:  17%|▏| 2611/15000 [21:42<37:31,  5.50it/s, lr=0.000325, step_loss=0.001707/27/2023 18:06:31 - INFO - __main__ - train loss is 24.800565748475492\n",
      "Steps:  17%|▏| 2612/15000 [21:42<37:21,  5.53it/s, lr=0.000325, step_loss=0.006707/27/2023 18:06:32 - INFO - __main__ - train loss is 24.902514814399183\n",
      "Steps:  17%|▏| 2613/15000 [21:42<37:14,  5.54it/s, lr=0.000325, step_loss=0.102]07/27/2023 18:06:32 - INFO - __main__ - train loss is 24.976048110984266\n",
      "Steps:  17%|▏| 2614/15000 [21:42<37:11,  5.55it/s, lr=0.000325, step_loss=0.073507/27/2023 18:06:32 - INFO - __main__ - train loss is 25.208444415591657\n",
      "Steps:  17%|▏| 2615/15000 [21:42<37:07,  5.56it/s, lr=0.000325, step_loss=0.232]07/27/2023 18:06:32 - INFO - __main__ - train loss is 25.21688700374216\n",
      "Steps:  17%|▏| 2616/15000 [21:42<37:05,  5.56it/s, lr=0.000325, step_loss=0.008407/27/2023 18:06:32 - INFO - __main__ - train loss is 25.21971098682843\n",
      "Steps:  17%|▏| 2617/15000 [21:43<37:02,  5.57it/s, lr=0.000326, step_loss=0.002807/27/2023 18:06:33 - INFO - __main__ - train loss is 25.28082040301524\n",
      "Steps:  17%|▏| 2618/15000 [21:43<37:00,  5.58it/s, lr=0.000326, step_loss=0.061107/27/2023 18:06:33 - INFO - __main__ - train loss is 25.32669787458144\n",
      "Steps:  17%|▏| 2619/15000 [21:43<36:58,  5.58it/s, lr=0.000326, step_loss=0.045907/27/2023 18:06:33 - INFO - __main__ - train loss is 25.331785310758278\n",
      "Steps:  17%|▏| 2620/15000 [21:43<36:59,  5.58it/s, lr=0.000326, step_loss=0.005007/27/2023 18:06:33 - INFO - __main__ - train loss is 25.758821834577248\n",
      "Steps:  17%|▏| 2621/15000 [21:43<36:58,  5.58it/s, lr=0.000326, step_loss=0.427]07/27/2023 18:06:33 - INFO - __main__ - train loss is 25.784779605222866\n",
      "Steps:  17%|▏| 2622/15000 [21:44<36:59,  5.58it/s, lr=0.000326, step_loss=0.026]07/27/2023 18:06:33 - INFO - __main__ - train loss is 25.792729259235784\n",
      "Steps:  17%|▏| 2623/15000 [21:44<36:58,  5.58it/s, lr=0.000326, step_loss=0.007907/27/2023 18:06:34 - INFO - __main__ - train loss is 25.948935107095167\n",
      "Steps:  17%|▏| 2624/15000 [21:44<37:03,  5.57it/s, lr=0.000327, step_loss=0.156]07/27/2023 18:06:34 - INFO - __main__ - train loss is 25.993372888071463\n",
      "Steps:  18%|▏| 2625/15000 [21:44<37:00,  5.57it/s, lr=0.000327, step_loss=0.044407/27/2023 18:06:34 - INFO - __main__ - train loss is 26.319257498485968\n",
      "Steps:  18%|▏| 2626/15000 [21:44<36:58,  5.58it/s, lr=0.000327, step_loss=0.326]07/27/2023 18:06:34 - INFO - __main__ - train loss is 26.692328423960134\n",
      "Steps:  18%|▏| 2627/15000 [21:44<36:55,  5.58it/s, lr=0.000327, step_loss=0.373]07/27/2023 18:06:34 - INFO - __main__ - train loss is 26.981934935553\n",
      "Steps:  18%|▎ | 2628/15000 [21:45<37:16,  5.53it/s, lr=0.000327, step_loss=0.29]07/27/2023 18:06:34 - INFO - __main__ - train loss is 27.30372163723223\n",
      "Steps:  18%|▏| 2629/15000 [21:45<37:17,  5.53it/s, lr=0.000327, step_loss=0.322]07/27/2023 18:06:35 - INFO - __main__ - train loss is 27.390615061623976\n",
      "Steps:  18%|▏| 2630/15000 [21:45<37:11,  5.54it/s, lr=0.000327, step_loss=0.086907/27/2023 18:06:35 - INFO - __main__ - train loss is 27.416658864123747\n",
      "Steps:  18%|▏| 2631/15000 [21:45<37:06,  5.56it/s, lr=0.000327, step_loss=0.026]07/27/2023 18:06:35 - INFO - __main__ - train loss is 28.3657452322077\n",
      "Steps:  18%|▏| 2632/15000 [21:45<37:04,  5.56it/s, lr=0.000328, step_loss=0.949]07/27/2023 18:06:35 - INFO - __main__ - train loss is 28.42428968916647\n",
      "Steps:  18%|▏| 2633/15000 [21:46<37:02,  5.56it/s, lr=0.000328, step_loss=0.058507/27/2023 18:06:35 - INFO - __main__ - train loss is 28.444401499582455\n",
      "Steps:  18%|▏| 2634/15000 [21:46<36:59,  5.57it/s, lr=0.000328, step_loss=0.020107/27/2023 18:06:36 - INFO - __main__ - train loss is 28.574079108191654\n",
      "Steps:  18%|▎ | 2635/15000 [21:46<36:57,  5.58it/s, lr=0.000328, step_loss=0.13]07/27/2023 18:06:36 - INFO - __main__ - train loss is 28.646816071821377\n",
      "Steps:  18%|▏| 2636/15000 [21:46<36:58,  5.57it/s, lr=0.000328, step_loss=0.072707/27/2023 18:06:36 - INFO - __main__ - train loss is 28.677678177831694\n",
      "Steps:  18%|▏| 2637/15000 [21:46<37:04,  5.56it/s, lr=0.000328, step_loss=0.030907/27/2023 18:06:36 - INFO - __main__ - train loss is 28.82055441546254\n",
      "Steps:  18%|▏| 2638/15000 [21:46<37:03,  5.56it/s, lr=0.000328, step_loss=0.143]07/27/2023 18:06:36 - INFO - __main__ - train loss is 28.92786333221011\n",
      "Steps:  18%|▏| 2639/15000 [21:47<37:03,  5.56it/s, lr=0.000328, step_loss=0.107]07/27/2023 18:06:36 - INFO - __main__ - train loss is 28.943757752655074\n",
      "Steps:  18%|▏| 2640/15000 [21:47<37:03,  5.56it/s, lr=0.000329, step_loss=0.015907/27/2023 18:06:37 - INFO - __main__ - train loss is 29.153867597458884\n",
      "Steps:  18%|▎ | 2641/15000 [21:47<37:02,  5.56it/s, lr=0.000329, step_loss=0.21]07/27/2023 18:06:37 - INFO - __main__ - train loss is 29.15621927450411\n",
      "Steps:  18%|▏| 2642/15000 [21:47<37:03,  5.56it/s, lr=0.000329, step_loss=0.002307/27/2023 18:06:37 - INFO - __main__ - train loss is 29.16632587532513\n",
      "Steps:  18%|▏| 2643/15000 [21:47<37:02,  5.56it/s, lr=0.000329, step_loss=0.010107/27/2023 18:06:37 - INFO - __main__ - train loss is 29.257037573261186\n",
      "Steps:  18%|▏| 2644/15000 [21:47<37:10,  5.54it/s, lr=0.000329, step_loss=0.090707/27/2023 18:06:37 - INFO - __main__ - train loss is 29.28016263875179\n",
      "Steps:  18%|▏| 2645/15000 [21:48<37:04,  5.56it/s, lr=0.000329, step_loss=0.023107/27/2023 18:06:38 - INFO - __main__ - train loss is 29.286066744243726\n",
      "Steps:  18%|▏| 2646/15000 [21:48<37:00,  5.56it/s, lr=0.000329, step_loss=0.005907/27/2023 18:06:38 - INFO - __main__ - train loss is 29.59157148352824\n",
      "Steps:  18%|▏| 2647/15000 [21:48<36:56,  5.57it/s, lr=0.000329, step_loss=0.306]07/27/2023 18:06:38 - INFO - __main__ - train loss is 29.716892082011327\n",
      "Steps:  18%|▎ | 2648/15000 [21:48<36:55,  5.57it/s, lr=0.00033, step_loss=0.125]07/27/2023 18:06:38 - INFO - __main__ - train loss is 29.718503837822936\n",
      "Steps:  18%|▏| 2649/15000 [21:48<36:54,  5.58it/s, lr=0.00033, step_loss=0.0016107/27/2023 18:06:38 - INFO - __main__ - train loss is 29.83531404042151\n",
      "Steps:  18%|▎ | 2650/15000 [21:49<36:54,  5.58it/s, lr=0.00033, step_loss=0.117]07/27/2023 18:06:38 - INFO - __main__ - train loss is 29.84137785329949\n",
      "Steps:  18%|▏| 2651/15000 [21:49<36:52,  5.58it/s, lr=0.00033, step_loss=0.0060607/27/2023 18:06:39 - INFO - __main__ - train loss is 29.98168331279885\n",
      "Steps:  18%|▌  | 2652/15000 [21:49<36:52,  5.58it/s, lr=0.00033, step_loss=0.14]07/27/2023 18:06:39 - INFO - __main__ - train loss is 30.211384146357886\n",
      "Steps:  18%|▌  | 2653/15000 [21:49<36:53,  5.58it/s, lr=0.00033, step_loss=0.23]07/27/2023 18:06:39 - INFO - __main__ - train loss is 30.299032813753\n",
      "Steps:  18%|▏| 2654/15000 [21:49<36:54,  5.58it/s, lr=0.00033, step_loss=0.0876]07/27/2023 18:06:39 - INFO - __main__ - train loss is 30.40673088177573\n",
      "Steps:  18%|▎ | 2655/15000 [21:49<36:53,  5.58it/s, lr=0.00033, step_loss=0.108]07/27/2023 18:06:39 - INFO - __main__ - train loss is 30.4347087246133\n",
      "Steps:  18%|▏| 2656/15000 [21:50<36:52,  5.58it/s, lr=0.000331, step_loss=0.028]07/27/2023 18:06:40 - INFO - __main__ - train loss is 30.81531832634937\n",
      "Steps:  18%|▏| 2657/15000 [21:50<36:51,  5.58it/s, lr=0.000331, step_loss=0.381]07/27/2023 18:06:40 - INFO - __main__ - train loss is 30.82554165914189\n",
      "Steps:  18%|▏| 2658/15000 [21:50<36:51,  5.58it/s, lr=0.000331, step_loss=0.010207/27/2023 18:06:40 - INFO - __main__ - train loss is 30.972163035417907\n",
      "Steps:  18%|▏| 2659/15000 [21:50<36:50,  5.58it/s, lr=0.000331, step_loss=0.147]07/27/2023 18:06:40 - INFO - __main__ - train loss is 30.994262515450828\n",
      "Steps:  18%|▏| 2660/15000 [21:50<36:51,  5.58it/s, lr=0.000331, step_loss=0.022107/27/2023 18:06:40 - INFO - __main__ - train loss is 31.345847546006553\n",
      "Steps:  18%|▏| 2661/15000 [21:51<36:51,  5.58it/s, lr=0.000331, step_loss=0.352]07/27/2023 18:06:40 - INFO - __main__ - train loss is 31.37577408447396\n",
      "Steps:  18%|▏| 2662/15000 [21:51<36:52,  5.58it/s, lr=0.000331, step_loss=0.029907/27/2023 18:06:41 - INFO - __main__ - train loss is 31.589778988505714\n",
      "Steps:  18%|▏| 2663/15000 [21:51<36:51,  5.58it/s, lr=0.000331, step_loss=0.214]07/27/2023 18:06:41 - INFO - __main__ - train loss is 31.59778249252122\n",
      "Steps:  18%|▏| 2664/15000 [21:51<36:51,  5.58it/s, lr=0.000332, step_loss=0.008]07/27/2023 18:06:41 - INFO - __main__ - train loss is 31.61853978212457\n",
      "Steps:  18%|▏| 2665/15000 [21:51<36:51,  5.58it/s, lr=0.000332, step_loss=0.020807/27/2023 18:06:41 - INFO - __main__ - train loss is 31.619879985344596\n",
      "Steps:  18%|▏| 2666/15000 [21:51<36:50,  5.58it/s, lr=0.000332, step_loss=0.001307/27/2023 18:06:41 - INFO - __main__ - train loss is 31.63121614244301\n",
      "Steps:  18%|▏| 2667/15000 [21:52<36:49,  5.58it/s, lr=0.000332, step_loss=0.011307/27/2023 18:06:41 - INFO - __main__ - train loss is 31.703153926995583\n",
      "Steps:  18%|▏| 2668/15000 [21:52<36:49,  5.58it/s, lr=0.000332, step_loss=0.071907/27/2023 18:06:42 - INFO - __main__ - train loss is 31.792471218970604\n",
      "Steps:  18%|▏| 2669/15000 [21:52<36:49,  5.58it/s, lr=0.000332, step_loss=0.089307/27/2023 18:06:42 - INFO - __main__ - train loss is 32.271487493184395\n",
      "Steps:  18%|▏| 2670/15000 [21:52<36:49,  5.58it/s, lr=0.000332, step_loss=0.479]07/27/2023 18:06:42 - INFO - __main__ - train loss is 32.5364986845525\n",
      "Steps:  18%|▏| 2671/15000 [21:52<36:49,  5.58it/s, lr=0.000332, step_loss=0.265]07/27/2023 18:06:42 - INFO - __main__ - train loss is 32.626509275403805\n",
      "Steps:  18%|▎ | 2672/15000 [21:53<36:49,  5.58it/s, lr=0.000333, step_loss=0.09]07/27/2023 18:06:42 - INFO - __main__ - train loss is 32.63135000516195\n",
      "Steps:  18%|▏| 2673/15000 [21:53<36:48,  5.58it/s, lr=0.000333, step_loss=0.004807/27/2023 18:06:43 - INFO - __main__ - train loss is 32.64236216072459\n",
      "Steps:  18%|▏| 2674/15000 [21:53<36:48,  5.58it/s, lr=0.000333, step_loss=0.011]07/27/2023 18:06:43 - INFO - __main__ - train loss is 32.81104385678191\n",
      "Steps:  18%|▏| 2675/15000 [21:53<36:49,  5.58it/s, lr=0.000333, step_loss=0.169]07/27/2023 18:06:43 - INFO - __main__ - train loss is 32.82257249869872\n",
      "Steps:  18%|▏| 2676/15000 [21:53<36:49,  5.58it/s, lr=0.000333, step_loss=0.011507/27/2023 18:06:43 - INFO - __main__ - train loss is 32.863440665532835\n",
      "Steps:  18%|▏| 2677/15000 [21:53<36:50,  5.58it/s, lr=0.000333, step_loss=0.040907/27/2023 18:06:43 - INFO - __main__ - train loss is 33.4634999363916\n",
      "Steps:  18%|▌  | 2678/15000 [21:54<36:50,  5.57it/s, lr=0.000333, step_loss=0.6]07/27/2023 18:06:43 - INFO - __main__ - train loss is 33.470366395660676\n",
      "Steps:  18%|▏| 2679/15000 [21:54<36:49,  5.58it/s, lr=0.000333, step_loss=0.006807/27/2023 18:06:44 - INFO - __main__ - train loss is 33.64763576502446\n",
      "Steps:  18%|▏| 2680/15000 [21:54<36:49,  5.57it/s, lr=0.000334, step_loss=0.177]07/27/2023 18:06:44 - INFO - __main__ - train loss is 33.65542836592067\n",
      "Steps:  18%|▏| 2681/15000 [21:54<36:50,  5.57it/s, lr=0.000334, step_loss=0.007707/27/2023 18:06:44 - INFO - __main__ - train loss is 33.87932503328193\n",
      "Steps:  18%|▏| 2682/15000 [21:54<36:51,  5.57it/s, lr=0.000334, step_loss=0.224]07/27/2023 18:06:44 - INFO - __main__ - train loss is 34.11876767978538\n",
      "Steps:  18%|▏| 2683/15000 [21:54<36:51,  5.57it/s, lr=0.000334, step_loss=0.239]07/27/2023 18:06:44 - INFO - __main__ - train loss is 34.122798954253085\n",
      "Steps:  18%|▏| 2684/15000 [21:55<36:51,  5.57it/s, lr=0.000334, step_loss=0.004007/27/2023 18:06:45 - INFO - __main__ - train loss is 34.14327341050375\n",
      "Steps:  18%|▏| 2685/15000 [21:55<36:49,  5.57it/s, lr=0.000334, step_loss=0.020507/27/2023 18:06:45 - INFO - __main__ - train loss is 34.15850817889441\n",
      "Steps:  18%|▏| 2686/15000 [21:55<36:49,  5.57it/s, lr=0.000334, step_loss=0.015207/27/2023 18:06:45 - INFO - __main__ - train loss is 34.16090490936767\n",
      "Steps:  18%|▏| 2687/15000 [21:55<36:48,  5.58it/s, lr=0.000334, step_loss=0.002407/27/2023 18:06:45 - INFO - __main__ - train loss is 34.1786285553826\n",
      "Steps:  18%|▏| 2688/15000 [21:55<36:47,  5.58it/s, lr=0.000335, step_loss=0.017707/27/2023 18:06:45 - INFO - __main__ - train loss is 34.57710157975089\n",
      "Steps:  18%|▏| 2689/15000 [21:56<36:45,  5.58it/s, lr=0.000335, step_loss=0.398]07/27/2023 18:06:45 - INFO - __main__ - train loss is 34.942662319983356\n",
      "Steps:  18%|▏| 2690/15000 [21:56<36:44,  5.58it/s, lr=0.000335, step_loss=0.366]07/27/2023 18:06:46 - INFO - __main__ - train loss is 34.988760447944514\n",
      "Steps:  18%|▏| 2691/15000 [21:56<36:43,  5.59it/s, lr=0.000335, step_loss=0.046107/27/2023 18:06:46 - INFO - __main__ - train loss is 35.101649782503955\n",
      "Steps:  18%|▏| 2692/15000 [21:56<37:05,  5.53it/s, lr=0.000335, step_loss=0.113]07/27/2023 18:06:46 - INFO - __main__ - train loss is 35.113496184232645\n",
      "Steps:  18%|▏| 2693/15000 [21:56<37:07,  5.52it/s, lr=0.000335, step_loss=0.011807/27/2023 18:06:46 - INFO - __main__ - train loss is 35.126046636956744\n",
      "Steps:  18%|▏| 2694/15000 [21:56<37:02,  5.54it/s, lr=0.000335, step_loss=0.012607/27/2023 18:06:46 - INFO - __main__ - train loss is 35.198536554235034\n",
      "Steps:  18%|▏| 2695/15000 [21:57<36:57,  5.55it/s, lr=0.000335, step_loss=0.072507/27/2023 18:06:47 - INFO - __main__ - train loss is 35.32408148969989\n",
      "Steps:  18%|▏| 2696/15000 [21:57<37:16,  5.50it/s, lr=0.000336, step_loss=0.126]07/27/2023 18:06:47 - INFO - __main__ - train loss is 35.3686764332233\n",
      "Steps:  18%|▏| 2697/15000 [21:57<37:23,  5.48it/s, lr=0.000336, step_loss=0.044607/27/2023 18:06:47 - INFO - __main__ - train loss is 35.41403003211599\n",
      "Steps:  18%|▏| 2698/15000 [21:57<37:33,  5.46it/s, lr=0.000336, step_loss=0.045407/27/2023 18:06:47 - INFO - __main__ - train loss is 35.61794074054342\n",
      "Steps:  18%|▏| 2699/15000 [21:57<37:26,  5.48it/s, lr=0.000336, step_loss=0.204]07/27/2023 18:06:47 - INFO - __main__ - train loss is 35.65422037418466\n",
      "Steps:  18%|▏| 2700/15000 [21:58<37:14,  5.50it/s, lr=0.000336, step_loss=0.036307/27/2023 18:06:47 - INFO - __main__ - train loss is 36.31589958246332\n",
      "Steps:  18%|▏| 2701/15000 [21:58<37:06,  5.52it/s, lr=0.000336, step_loss=0.662]07/27/2023 18:06:48 - INFO - __main__ - train loss is 36.39968400623184\n",
      "Steps:  18%|▏| 2702/15000 [21:58<37:01,  5.54it/s, lr=0.000336, step_loss=0.083807/27/2023 18:06:48 - INFO - __main__ - train loss is 36.48620084847789\n",
      "Steps:  18%|▏| 2703/15000 [21:58<36:56,  5.55it/s, lr=0.000336, step_loss=0.086507/27/2023 18:06:48 - INFO - __main__ - train loss is 36.8796270879684\n",
      "Steps:  18%|▏| 2704/15000 [21:58<36:54,  5.55it/s, lr=0.000337, step_loss=0.393]07/27/2023 18:06:48 - INFO - __main__ - train loss is 37.10213493730407\n",
      "Steps:  18%|▏| 2705/15000 [21:58<37:08,  5.52it/s, lr=0.000337, step_loss=0.223]07/27/2023 18:06:48 - INFO - __main__ - train loss is 37.107406725990586\n",
      "Steps:  18%|▏| 2706/15000 [21:59<37:21,  5.49it/s, lr=0.000337, step_loss=0.005207/27/2023 18:06:49 - INFO - __main__ - train loss is 37.121322751860134\n",
      "Steps:  18%|▏| 2707/15000 [21:59<37:13,  5.51it/s, lr=0.000337, step_loss=0.013907/27/2023 18:06:49 - INFO - __main__ - train loss is 37.41002675972413\n",
      "Steps:  18%|▏| 2708/15000 [21:59<37:13,  5.50it/s, lr=0.000337, step_loss=0.289]07/27/2023 18:06:49 - INFO - __main__ - train loss is 37.48825390718412\n",
      "Steps:  18%|▏| 2709/15000 [21:59<37:05,  5.52it/s, lr=0.000337, step_loss=0.078207/27/2023 18:06:49 - INFO - __main__ - train loss is 37.517200407455675\n",
      "Steps:  18%|▏| 2710/15000 [21:59<37:23,  5.48it/s, lr=0.000337, step_loss=0.028907/27/2023 18:06:49 - INFO - __main__ - train loss is 37.62380002147984\n",
      "Steps:  18%|▏| 2711/15000 [22:00<37:24,  5.48it/s, lr=0.000337, step_loss=0.107]07/27/2023 18:06:49 - INFO - __main__ - train loss is 37.73640391684603\n",
      "Steps:  18%|▏| 2712/15000 [22:00<37:11,  5.51it/s, lr=0.000338, step_loss=0.113]07/27/2023 18:06:50 - INFO - __main__ - train loss is 37.909344528685324\n",
      "Steps:  18%|▏| 2713/15000 [22:00<37:01,  5.53it/s, lr=0.000338, step_loss=0.173]07/27/2023 18:06:50 - INFO - __main__ - train loss is 37.91132752795238\n",
      "Steps:  18%|▏| 2714/15000 [22:00<37:14,  5.50it/s, lr=0.000338, step_loss=0.001907/27/2023 18:06:50 - INFO - __main__ - train loss is 38.06846906442661\n",
      "Steps:  18%|▏| 2715/15000 [22:00<37:10,  5.51it/s, lr=0.000338, step_loss=0.157]07/27/2023 18:06:50 - INFO - __main__ - train loss is 38.102726722252555\n",
      "Steps:  18%|▏| 2716/15000 [22:00<37:21,  5.48it/s, lr=0.000338, step_loss=0.034307/27/2023 18:06:50 - INFO - __main__ - train loss is 38.11025052063633\n",
      "Steps:  18%|▏| 2717/15000 [22:01<37:15,  5.49it/s, lr=0.000338, step_loss=0.007507/27/2023 18:06:51 - INFO - __main__ - train loss is 38.1232276140945\n",
      "Steps:  18%|▏| 2718/15000 [22:01<37:05,  5.52it/s, lr=0.000338, step_loss=0.013]07/27/2023 18:06:51 - INFO - __main__ - train loss is 38.46219058625866\n",
      "Steps:  18%|▏| 2719/15000 [22:01<37:10,  5.51it/s, lr=0.000338, step_loss=0.339]07/27/2023 18:06:51 - INFO - __main__ - train loss is 38.476055672508664\n",
      "Steps:  18%|▏| 2720/15000 [22:01<37:00,  5.53it/s, lr=0.000339, step_loss=0.013907/27/2023 18:06:51 - INFO - __main__ - train loss is 38.782335212570615\n",
      "Steps:  18%|▏| 2721/15000 [22:01<36:54,  5.54it/s, lr=0.000339, step_loss=0.306]07/27/2023 18:06:51 - INFO - __main__ - train loss is 38.79778743360657\n",
      "Steps:  18%|▏| 2722/15000 [22:02<37:04,  5.52it/s, lr=0.000339, step_loss=0.015507/27/2023 18:06:51 - INFO - __main__ - train loss is 38.95560089324135\n",
      "Steps:  18%|▏| 2723/15000 [22:02<37:15,  5.49it/s, lr=0.000339, step_loss=0.158]07/27/2023 18:06:52 - INFO - __main__ - train loss is 38.96638643939514\n",
      "Steps:  18%|▏| 2724/15000 [22:02<37:11,  5.50it/s, lr=0.000339, step_loss=0.010807/27/2023 18:06:52 - INFO - __main__ - train loss is 39.193906264496036\n",
      "Steps:  18%|▏| 2725/15000 [22:02<37:09,  5.51it/s, lr=0.000339, step_loss=0.228]07/27/2023 18:06:52 - INFO - __main__ - train loss is 39.203386470791884\n",
      "Steps:  18%|▏| 2726/15000 [22:02<37:07,  5.51it/s, lr=0.000339, step_loss=0.009407/27/2023 18:06:52 - INFO - __main__ - train loss is 39.20625874877442\n",
      "Steps:  18%|▏| 2727/15000 [22:03<51:01,  4.01it/s, lr=0.000339, step_loss=0.002807/27/2023 18:06:53 - INFO - __main__ - Per validation step average loss is 0.020879987627267838\n",
      "07/27/2023 18:06:53 - INFO - __main__ - Cumulative validation average loss is 0.020879987627267838\n",
      "07/27/2023 18:06:54 - INFO - __main__ - Per validation step average loss is 0.17859038710594177\n",
      "07/27/2023 18:06:54 - INFO - __main__ - Cumulative validation average loss is 0.1994703747332096\n",
      "07/27/2023 18:06:54 - INFO - __main__ - Per validation step average loss is 0.01872275024652481\n",
      "07/27/2023 18:06:54 - INFO - __main__ - Cumulative validation average loss is 0.21819312497973442\n",
      "07/27/2023 18:06:55 - INFO - __main__ - Per validation step average loss is 0.3726541996002197\n",
      "07/27/2023 18:06:55 - INFO - __main__ - Cumulative validation average loss is 0.5908473245799541\n",
      "07/27/2023 18:06:55 - INFO - __main__ - Per validation step average loss is 0.0865500271320343\n",
      "07/27/2023 18:06:55 - INFO - __main__ - Cumulative validation average loss is 0.6773973517119884\n",
      "07/27/2023 18:06:55 - INFO - __main__ - Per validation step average loss is 0.08982741087675095\n",
      "07/27/2023 18:06:55 - INFO - __main__ - Cumulative validation average loss is 0.7672247625887394\n",
      "07/27/2023 18:06:56 - INFO - __main__ - Per validation step average loss is 0.018665291368961334\n",
      "07/27/2023 18:06:56 - INFO - __main__ - Cumulative validation average loss is 0.7858900539577007\n",
      "07/27/2023 18:06:56 - INFO - __main__ - Per validation step average loss is 0.022414563223719597\n",
      "07/27/2023 18:06:56 - INFO - __main__ - Cumulative validation average loss is 0.8083046171814203\n",
      "07/27/2023 18:06:57 - INFO - __main__ - Per validation step average loss is 0.28621917963027954\n",
      "07/27/2023 18:06:57 - INFO - __main__ - Cumulative validation average loss is 1.0945237968116999\n",
      "07/27/2023 18:06:57 - INFO - __main__ - Per validation step average loss is 0.014766674488782883\n",
      "07/27/2023 18:06:57 - INFO - __main__ - Cumulative validation average loss is 1.1092904713004827\n",
      "07/27/2023 18:06:57 - INFO - __main__ - Per validation step average loss is 0.1715216338634491\n",
      "07/27/2023 18:06:57 - INFO - __main__ - Cumulative validation average loss is 1.2808121051639318\n",
      "07/27/2023 18:06:58 - INFO - __main__ - Per validation step average loss is 0.05050044506788254\n",
      "07/27/2023 18:06:58 - INFO - __main__ - Cumulative validation average loss is 1.3313125502318144\n",
      "07/27/2023 18:06:58 - INFO - __main__ - Per validation step average loss is 0.006906390190124512\n",
      "07/27/2023 18:06:58 - INFO - __main__ - Cumulative validation average loss is 1.338218940421939\n",
      "07/27/2023 18:06:59 - INFO - __main__ - Per validation step average loss is 0.4591815769672394\n",
      "07/27/2023 18:06:59 - INFO - __main__ - Cumulative validation average loss is 1.7974005173891783\n",
      "07/27/2023 18:06:59 - INFO - __main__ - Per validation step average loss is 0.004304436035454273\n",
      "07/27/2023 18:06:59 - INFO - __main__ - Cumulative validation average loss is 1.8017049534246325\n",
      "07/27/2023 18:06:59 - INFO - __main__ - Per validation step average loss is 0.05256816744804382\n",
      "07/27/2023 18:06:59 - INFO - __main__ - Cumulative validation average loss is 1.8542731208726764\n",
      "07/27/2023 18:07:00 - INFO - __main__ - Per validation step average loss is 0.4001975655555725\n",
      "07/27/2023 18:07:00 - INFO - __main__ - Cumulative validation average loss is 2.254470686428249\n",
      "07/27/2023 18:07:00 - INFO - __main__ - Per validation step average loss is 0.2556619644165039\n",
      "07/27/2023 18:07:00 - INFO - __main__ - Cumulative validation average loss is 2.510132650844753\n",
      "07/27/2023 18:07:01 - INFO - __main__ - Per validation step average loss is 0.005775821395218372\n",
      "07/27/2023 18:07:01 - INFO - __main__ - Cumulative validation average loss is 2.515908472239971\n",
      "07/27/2023 18:07:01 - INFO - __main__ - Per validation step average loss is 0.13110686838626862\n",
      "07/27/2023 18:07:01 - INFO - __main__ - Cumulative validation average loss is 2.6470153406262398\n",
      "07/27/2023 18:07:02 - INFO - __main__ - Per validation step average loss is 0.12341858446598053\n",
      "07/27/2023 18:07:02 - INFO - __main__ - Cumulative validation average loss is 2.7704339250922203\n",
      "07/27/2023 18:07:02 - INFO - __main__ - Per validation step average loss is 0.17926296591758728\n",
      "07/27/2023 18:07:02 - INFO - __main__ - Cumulative validation average loss is 2.9496968910098076\n",
      "07/27/2023 18:07:02 - INFO - __main__ - Per validation step average loss is 0.001997337443754077\n",
      "07/27/2023 18:07:02 - INFO - __main__ - Cumulative validation average loss is 2.9516942284535617\n",
      "07/27/2023 18:07:03 - INFO - __main__ - Per validation step average loss is 0.006142820231616497\n",
      "07/27/2023 18:07:03 - INFO - __main__ - Cumulative validation average loss is 2.957837048685178\n",
      "07/27/2023 18:07:03 - INFO - __main__ - Per validation step average loss is 0.003714463207870722\n",
      "07/27/2023 18:07:03 - INFO - __main__ - Cumulative validation average loss is 2.961551511893049\n",
      "07/27/2023 18:07:04 - INFO - __main__ - Per validation step average loss is 0.003432859666645527\n",
      "07/27/2023 18:07:04 - INFO - __main__ - Cumulative validation average loss is 2.9649843715596944\n",
      "07/27/2023 18:07:04 - INFO - __main__ - Per validation step average loss is 0.36545175313949585\n",
      "07/27/2023 18:07:04 - INFO - __main__ - Cumulative validation average loss is 3.3304361246991903\n",
      "07/27/2023 18:07:04 - INFO - __main__ - Per validation step average loss is 0.019206300377845764\n",
      "07/27/2023 18:07:04 - INFO - __main__ - Cumulative validation average loss is 3.349642425077036\n",
      "07/27/2023 18:07:05 - INFO - __main__ - Per validation step average loss is 0.3668549060821533\n",
      "07/27/2023 18:07:05 - INFO - __main__ - Cumulative validation average loss is 3.7164973311591893\n",
      "07/27/2023 18:07:05 - INFO - __main__ - Per validation step average loss is 0.1027066558599472\n",
      "07/27/2023 18:07:05 - INFO - __main__ - Cumulative validation average loss is 3.8192039870191365\n",
      "07/27/2023 18:07:06 - INFO - __main__ - Per validation step average loss is 0.22597277164459229\n",
      "07/27/2023 18:07:06 - INFO - __main__ - Cumulative validation average loss is 4.045176758663729\n",
      "07/27/2023 18:07:06 - INFO - __main__ - Per validation step average loss is 0.11212432384490967\n",
      "07/27/2023 18:07:06 - INFO - __main__ - Cumulative validation average loss is 4.1573010825086385\n",
      "07/27/2023 18:07:06 - INFO - __main__ - Per validation step average loss is 0.2554088830947876\n",
      "07/27/2023 18:07:06 - INFO - __main__ - Cumulative validation average loss is 4.412709965603426\n",
      "07/27/2023 18:07:07 - INFO - __main__ - Per validation step average loss is 0.0069168852642178535\n",
      "07/27/2023 18:07:07 - INFO - __main__ - Cumulative validation average loss is 4.419626850867644\n",
      "07/27/2023 18:07:07 - INFO - __main__ - Per validation step average loss is 0.005326876416802406\n",
      "07/27/2023 18:07:07 - INFO - __main__ - Cumulative validation average loss is 4.424953727284446\n",
      "07/27/2023 18:07:08 - INFO - __main__ - Per validation step average loss is 0.012548539787530899\n",
      "07/27/2023 18:07:08 - INFO - __main__ - Cumulative validation average loss is 4.437502267071977\n",
      "07/27/2023 18:07:08 - INFO - __main__ - Per validation step average loss is 0.04135305434465408\n",
      "07/27/2023 18:07:08 - INFO - __main__ - Cumulative validation average loss is 4.478855321416631\n",
      "07/27/2023 18:07:08 - INFO - __main__ - Per validation step average loss is 0.3683924376964569\n",
      "07/27/2023 18:07:08 - INFO - __main__ - Cumulative validation average loss is 4.847247759113088\n",
      "07/27/2023 18:07:09 - INFO - __main__ - Per validation step average loss is 0.014716513454914093\n",
      "07/27/2023 18:07:09 - INFO - __main__ - Cumulative validation average loss is 4.861964272568002\n",
      "07/27/2023 18:07:09 - INFO - __main__ - Per validation step average loss is 0.6066431999206543\n",
      "07/27/2023 18:07:09 - INFO - __main__ - Cumulative validation average loss is 5.468607472488657\n",
      "07/27/2023 18:07:10 - INFO - __main__ - Per validation step average loss is 0.020350400358438492\n",
      "07/27/2023 18:07:10 - INFO - __main__ - Cumulative validation average loss is 5.488957872847095\n",
      "07/27/2023 18:07:10 - INFO - __main__ - Per validation step average loss is 0.013027891516685486\n",
      "07/27/2023 18:07:10 - INFO - __main__ - Cumulative validation average loss is 5.501985764363781\n",
      "07/27/2023 18:07:10 - INFO - __main__ - Per validation step average loss is 0.007064179051667452\n",
      "07/27/2023 18:07:10 - INFO - __main__ - Cumulative validation average loss is 5.509049943415448\n",
      "07/27/2023 18:07:11 - INFO - __main__ - Per validation step average loss is 0.0011321869678795338\n",
      "07/27/2023 18:07:11 - INFO - __main__ - Cumulative validation average loss is 5.510182130383328\n",
      "07/27/2023 18:07:11 - INFO - __main__ - Per validation step average loss is 0.2549288868904114\n",
      "07/27/2023 18:07:11 - INFO - __main__ - Cumulative validation average loss is 5.765111017273739\n",
      "07/27/2023 18:07:12 - INFO - __main__ - Per validation step average loss is 0.002775713801383972\n",
      "07/27/2023 18:07:12 - INFO - __main__ - Cumulative validation average loss is 5.767886731075123\n",
      "07/27/2023 18:07:12 - INFO - __main__ - Per validation step average loss is 0.031818851828575134\n",
      "07/27/2023 18:07:12 - INFO - __main__ - Cumulative validation average loss is 5.799705582903698\n",
      "07/27/2023 18:07:13 - INFO - __main__ - Per validation step average loss is 0.10331815481185913\n",
      "07/27/2023 18:07:13 - INFO - __main__ - Cumulative validation average loss is 5.903023737715557\n",
      "07/27/2023 18:07:13 - INFO - __main__ - Per validation step average loss is 0.057704344391822815\n",
      "07/27/2023 18:07:13 - INFO - __main__ - Cumulative validation average loss is 5.96072808210738\n",
      "07/27/2023 18:07:13 - INFO - __main__ - Per validation step average loss is 0.00471420306712389\n",
      "07/27/2023 18:07:13 - INFO - __main__ - Cumulative validation average loss is 5.965442285174504\n",
      "07/27/2023 18:07:14 - INFO - __main__ - Per validation step average loss is 0.00997714139521122\n",
      "07/27/2023 18:07:14 - INFO - __main__ - Cumulative validation average loss is 5.975419426569715\n",
      "07/27/2023 18:07:14 - INFO - __main__ - Per validation step average loss is 0.06567607820034027\n",
      "07/27/2023 18:07:14 - INFO - __main__ - Cumulative validation average loss is 6.041095504770055\n",
      "07/27/2023 18:07:15 - INFO - __main__ - Per validation step average loss is 0.029810704290866852\n",
      "07/27/2023 18:07:15 - INFO - __main__ - Cumulative validation average loss is 6.070906209060922\n",
      "07/27/2023 18:07:15 - INFO - __main__ - Per validation step average loss is 0.018548589199781418\n",
      "07/27/2023 18:07:15 - INFO - __main__ - Cumulative validation average loss is 6.089454798260704\n",
      "07/27/2023 18:07:15 - INFO - __main__ - Per validation step average loss is 0.05637245625257492\n",
      "07/27/2023 18:07:15 - INFO - __main__ - Cumulative validation average loss is 6.145827254513279\n",
      "07/27/2023 18:07:16 - INFO - __main__ - Per validation step average loss is 0.02108021453022957\n",
      "07/27/2023 18:07:16 - INFO - __main__ - Cumulative validation average loss is 6.166907469043508\n",
      "07/27/2023 18:07:16 - INFO - __main__ - Per validation step average loss is 0.1283593773841858\n",
      "07/27/2023 18:07:16 - INFO - __main__ - Cumulative validation average loss is 6.295266846427694\n",
      "07/27/2023 18:07:17 - INFO - __main__ - Per validation step average loss is 0.026819393038749695\n",
      "07/27/2023 18:07:17 - INFO - __main__ - Cumulative validation average loss is 6.322086239466444\n",
      "07/27/2023 18:07:17 - INFO - __main__ - Per validation step average loss is 0.1321304440498352\n",
      "07/27/2023 18:07:17 - INFO - __main__ - Cumulative validation average loss is 6.454216683516279\n",
      "07/27/2023 18:07:17 - INFO - __main__ - Per validation step average loss is 0.013216504827141762\n",
      "07/27/2023 18:07:17 - INFO - __main__ - Cumulative validation average loss is 6.467433188343421\n",
      "07/27/2023 18:07:18 - INFO - __main__ - Per validation step average loss is 0.014523369260132313\n",
      "07/27/2023 18:07:18 - INFO - __main__ - Cumulative validation average loss is 6.481956557603553\n",
      "07/27/2023 18:07:18 - INFO - __main__ - Per validation step average loss is 0.14861121773719788\n",
      "07/27/2023 18:07:18 - INFO - __main__ - Cumulative validation average loss is 6.630567775340751\n",
      "07/27/2023 18:07:19 - INFO - __main__ - Per validation step average loss is 0.5941836833953857\n",
      "07/27/2023 18:07:19 - INFO - __main__ - Cumulative validation average loss is 7.2247514587361366\n",
      "07/27/2023 18:07:19 - INFO - __main__ - Per validation step average loss is 0.003320399671792984\n",
      "07/27/2023 18:07:19 - INFO - __main__ - Cumulative validation average loss is 7.2280718584079295\n",
      "07/27/2023 18:07:19 - INFO - __main__ - Per validation step average loss is 0.013178425841033459\n",
      "07/27/2023 18:07:19 - INFO - __main__ - Cumulative validation average loss is 7.241250284248963\n",
      "07/27/2023 18:07:20 - INFO - __main__ - Per validation step average loss is 0.0038779773749411106\n",
      "07/27/2023 18:07:20 - INFO - __main__ - Cumulative validation average loss is 7.245128261623904\n",
      "07/27/2023 18:07:20 - INFO - __main__ - Per validation step average loss is 0.01192985288798809\n",
      "07/27/2023 18:07:20 - INFO - __main__ - Cumulative validation average loss is 7.257058114511892\n",
      "07/27/2023 18:07:21 - INFO - __main__ - Per validation step average loss is 0.24498139321804047\n",
      "07/27/2023 18:07:21 - INFO - __main__ - Cumulative validation average loss is 7.502039507729933\n",
      "07/27/2023 18:07:21 - INFO - __main__ - Per validation step average loss is 0.0020098399836570024\n",
      "07/27/2023 18:07:21 - INFO - __main__ - Cumulative validation average loss is 7.50404934771359\n",
      "07/27/2023 18:07:22 - INFO - __main__ - Per validation step average loss is 0.061431705951690674\n",
      "07/27/2023 18:07:22 - INFO - __main__ - Cumulative validation average loss is 7.56548105366528\n",
      "07/27/2023 18:07:22 - INFO - __main__ - Per validation step average loss is 0.18000468611717224\n",
      "07/27/2023 18:07:22 - INFO - __main__ - Cumulative validation average loss is 7.745485739782453\n",
      "07/27/2023 18:07:22 - INFO - __main__ - Per validation step average loss is 0.15262176096439362\n",
      "07/27/2023 18:07:22 - INFO - __main__ - Cumulative validation average loss is 7.898107500746846\n",
      "07/27/2023 18:07:23 - INFO - __main__ - Per validation step average loss is 0.10231836140155792\n",
      "07/27/2023 18:07:23 - INFO - __main__ - Cumulative validation average loss is 8.000425862148404\n",
      "07/27/2023 18:07:23 - INFO - __main__ - Per validation step average loss is 0.3728522062301636\n",
      "07/27/2023 18:07:23 - INFO - __main__ - Cumulative validation average loss is 8.373278068378568\n",
      "07/27/2023 18:07:24 - INFO - __main__ - Per validation step average loss is 0.0015768806915730238\n",
      "07/27/2023 18:07:24 - INFO - __main__ - Cumulative validation average loss is 8.37485494907014\n",
      "07/27/2023 18:07:24 - INFO - __main__ - Per validation step average loss is 0.19553720951080322\n",
      "07/27/2023 18:07:24 - INFO - __main__ - Cumulative validation average loss is 8.570392158580944\n",
      "07/27/2023 18:07:24 - INFO - __main__ - Per validation step average loss is 0.07086067646741867\n",
      "07/27/2023 18:07:24 - INFO - __main__ - Cumulative validation average loss is 8.641252835048363\n",
      "07/27/2023 18:07:25 - INFO - __main__ - Per validation step average loss is 0.2676714360713959\n",
      "07/27/2023 18:07:25 - INFO - __main__ - Cumulative validation average loss is 8.908924271119758\n",
      "07/27/2023 18:07:25 - INFO - __main__ - Per validation step average loss is 0.008187690749764442\n",
      "07/27/2023 18:07:25 - INFO - __main__ - Cumulative validation average loss is 8.917111961869523\n",
      "07/27/2023 18:07:25 - INFO - __main__ - Average validation loss for Epoch 8 is 0.1128748349603737\n",
      "07/27/2023 18:07:25 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:08:23 - INFO - __main__ - Starting epoch 9\n",
      "07/27/2023 18:08:23 - INFO - __main__ - train loss is 0.12900251150131226\n",
      "Steps:  18%|▏| 2728/15000 [23:34<93:31:23, 27.44s/it, lr=0.00034, step_loss=0.1207/27/2023 18:08:23 - INFO - __main__ - train loss is 0.1304419138468802\n",
      "Steps:  18%|▏| 2729/15000 [23:34<65:38:47, 19.26s/it, lr=0.00034, step_loss=0.0007/27/2023 18:08:24 - INFO - __main__ - train loss is 0.31064035976305604\n",
      "Steps:  18%|▏| 2730/15000 [23:34<46:07:53, 13.53s/it, lr=0.00034, step_loss=0.1807/27/2023 18:08:24 - INFO - __main__ - train loss is 0.3274914943613112\n",
      "Steps:  18%|▏| 2731/15000 [23:34<32:28:27,  9.53s/it, lr=0.00034, step_loss=0.0107/27/2023 18:08:24 - INFO - __main__ - train loss is 0.4586684131063521\n",
      "Steps:  18%|▏| 2732/15000 [23:34<22:54:45,  6.72s/it, lr=0.00034, step_loss=0.1307/27/2023 18:08:24 - INFO - __main__ - train loss is 0.5308715575374663\n",
      "Steps:  18%|▏| 2733/15000 [23:34<16:13:24,  4.76s/it, lr=0.00034, step_loss=0.0707/27/2023 18:08:24 - INFO - __main__ - train loss is 0.5793700725771487\n",
      "Steps:  18%|▏| 2734/15000 [23:35<11:32:15,  3.39s/it, lr=0.00034, step_loss=0.0407/27/2023 18:08:24 - INFO - __main__ - train loss is 1.1347315819002688\n",
      "Steps:  18%|▏| 2735/15000 [23:35<8:15:28,  2.42s/it, lr=0.00034, step_loss=0.55507/27/2023 18:08:25 - INFO - __main__ - train loss is 1.4951354176737368\n",
      "Steps:  18%|▏| 2736/15000 [23:35<5:57:42,  1.75s/it, lr=0.000341, step_loss=0.3607/27/2023 18:08:25 - INFO - __main__ - train loss is 1.859697273466736\n",
      "Steps:  18%|▏| 2737/15000 [23:35<4:21:18,  1.28s/it, lr=0.000341, step_loss=0.3607/27/2023 18:08:25 - INFO - __main__ - train loss is 1.8619615924544632\n",
      "Steps:  18%|▏| 2738/15000 [23:35<3:13:48,  1.05it/s, lr=0.000341, step_loss=0.0007/27/2023 18:08:25 - INFO - __main__ - train loss is 1.9492600751109421\n",
      "Steps:  18%|▏| 2739/15000 [23:36<2:26:34,  1.39it/s, lr=0.000341, step_loss=0.0807/27/2023 18:08:25 - INFO - __main__ - train loss is 1.951750968117267\n",
      "Steps:  18%|▏| 2740/15000 [23:36<1:53:31,  1.80it/s, lr=0.000341, step_loss=0.0007/27/2023 18:08:26 - INFO - __main__ - train loss is 2.0165568781085312\n",
      "Steps:  18%|▏| 2741/15000 [23:36<1:30:25,  2.26it/s, lr=0.000341, step_loss=0.0607/27/2023 18:08:26 - INFO - __main__ - train loss is 2.0242537180893123\n",
      "Steps:  18%|▏| 2742/15000 [23:36<1:14:11,  2.75it/s, lr=0.000341, step_loss=0.0007/27/2023 18:08:26 - INFO - __main__ - train loss is 2.040299620013684\n",
      "Steps:  18%|▏| 2743/15000 [23:36<1:02:53,  3.25it/s, lr=0.000341, step_loss=0.0107/27/2023 18:08:26 - INFO - __main__ - train loss is 2.08390925033018\n",
      "Steps:  18%|▏| 2744/15000 [23:36<54:58,  3.72it/s, lr=0.000342, step_loss=0.043607/27/2023 18:08:26 - INFO - __main__ - train loss is 2.3878310094587505\n",
      "Steps:  18%|▏| 2745/15000 [23:37<49:25,  4.13it/s, lr=0.000342, step_loss=0.304]07/27/2023 18:08:26 - INFO - __main__ - train loss is 2.4094103067182004\n",
      "Steps:  18%|▏| 2746/15000 [23:37<45:31,  4.49it/s, lr=0.000342, step_loss=0.021607/27/2023 18:08:27 - INFO - __main__ - train loss is 2.4845869629643857\n",
      "Steps:  18%|▏| 2747/15000 [23:37<42:49,  4.77it/s, lr=0.000342, step_loss=0.075207/27/2023 18:08:27 - INFO - __main__ - train loss is 2.6023247777484357\n",
      "Steps:  18%|▏| 2748/15000 [23:37<40:55,  4.99it/s, lr=0.000342, step_loss=0.118]07/27/2023 18:08:27 - INFO - __main__ - train loss is 2.6046684943139553\n",
      "Steps:  18%|▏| 2749/15000 [23:37<39:41,  5.15it/s, lr=0.000342, step_loss=0.002307/27/2023 18:08:27 - INFO - __main__ - train loss is 2.903529044240713\n",
      "Steps:  18%|▏| 2750/15000 [23:37<39:33,  5.16it/s, lr=0.000342, step_loss=0.299]07/27/2023 18:08:27 - INFO - __main__ - train loss is 3.097044836729765\n",
      "Steps:  18%|▏| 2751/15000 [23:38<39:34,  5.16it/s, lr=0.000342, step_loss=0.194]07/27/2023 18:08:28 - INFO - __main__ - train loss is 3.0991274686530232\n",
      "Steps:  18%|▏| 2752/15000 [23:38<39:31,  5.16it/s, lr=0.000343, step_loss=0.002007/27/2023 18:08:28 - INFO - __main__ - train loss is 3.1096748868003488\n",
      "Steps:  18%|▏| 2753/15000 [23:38<38:55,  5.24it/s, lr=0.000343, step_loss=0.010507/27/2023 18:08:28 - INFO - __main__ - train loss is 3.233681575395167\n",
      "Steps:  18%|▏| 2754/15000 [23:38<38:11,  5.34it/s, lr=0.000343, step_loss=0.124]07/27/2023 18:08:28 - INFO - __main__ - train loss is 3.918919221498072\n",
      "Steps:  18%|▏| 2755/15000 [23:38<37:40,  5.42it/s, lr=0.000343, step_loss=0.685]07/27/2023 18:08:28 - INFO - __main__ - train loss is 4.017499306239188\n",
      "Steps:  18%|▏| 2756/15000 [23:39<37:18,  5.47it/s, lr=0.000343, step_loss=0.098607/27/2023 18:08:28 - INFO - __main__ - train loss is 4.019837545929477\n",
      "Steps:  18%|▏| 2757/15000 [23:39<37:04,  5.50it/s, lr=0.000343, step_loss=0.002307/27/2023 18:08:29 - INFO - __main__ - train loss is 4.246125059900805\n",
      "Steps:  18%|▏| 2758/15000 [23:39<36:55,  5.53it/s, lr=0.000343, step_loss=0.226]07/27/2023 18:08:29 - INFO - __main__ - train loss is 4.256989061599597\n",
      "Steps:  18%|▏| 2759/15000 [23:39<36:47,  5.55it/s, lr=0.000343, step_loss=0.010907/27/2023 18:08:29 - INFO - __main__ - train loss is 4.6428185102995485\n",
      "Steps:  18%|▏| 2760/15000 [23:39<36:41,  5.56it/s, lr=0.000344, step_loss=0.386]07/27/2023 18:08:29 - INFO - __main__ - train loss is 5.3347857592161745\n",
      "Steps:  18%|▏| 2761/15000 [23:40<36:38,  5.57it/s, lr=0.000344, step_loss=0.692]07/27/2023 18:08:29 - INFO - __main__ - train loss is 5.621500968700275\n",
      "Steps:  18%|▏| 2762/15000 [23:40<36:35,  5.57it/s, lr=0.000344, step_loss=0.287]07/27/2023 18:08:30 - INFO - __main__ - train loss is 5.6273195871617645\n",
      "Steps:  18%|▏| 2763/15000 [23:40<36:37,  5.57it/s, lr=0.000344, step_loss=0.005807/27/2023 18:08:30 - INFO - __main__ - train loss is 5.630141539266333\n",
      "Steps:  18%|▏| 2764/15000 [23:40<36:35,  5.57it/s, lr=0.000344, step_loss=0.002807/27/2023 18:08:30 - INFO - __main__ - train loss is 5.787081939866766\n",
      "Steps:  18%|▏| 2765/15000 [23:40<36:33,  5.58it/s, lr=0.000344, step_loss=0.157]07/27/2023 18:08:30 - INFO - __main__ - train loss is 5.910576393594965\n",
      "Steps:  18%|▏| 2766/15000 [23:40<36:31,  5.58it/s, lr=0.000344, step_loss=0.123]07/27/2023 18:08:30 - INFO - __main__ - train loss is 6.04907608567737\n",
      "Steps:  18%|▏| 2767/15000 [23:41<36:31,  5.58it/s, lr=0.000344, step_loss=0.138]07/27/2023 18:08:30 - INFO - __main__ - train loss is 6.051335809286684\n",
      "Steps:  18%|▏| 2768/15000 [23:41<36:30,  5.58it/s, lr=0.000344, step_loss=0.002207/27/2023 18:08:31 - INFO - __main__ - train loss is 6.217566964682192\n",
      "Steps:  18%|▏| 2769/15000 [23:41<36:29,  5.59it/s, lr=0.000345, step_loss=0.166]07/27/2023 18:08:31 - INFO - __main__ - train loss is 6.277666812296957\n",
      "Steps:  18%|▏| 2770/15000 [23:41<36:29,  5.59it/s, lr=0.000345, step_loss=0.060107/27/2023 18:08:31 - INFO - __main__ - train loss is 6.329134275671095\n",
      "Steps:  18%|▏| 2771/15000 [23:41<36:28,  5.59it/s, lr=0.000345, step_loss=0.051507/27/2023 18:08:31 - INFO - __main__ - train loss is 6.569481705781072\n",
      "Steps:  18%|▎ | 2772/15000 [23:41<36:28,  5.59it/s, lr=0.000345, step_loss=0.24]07/27/2023 18:08:31 - INFO - __main__ - train loss is 7.402189647313207\n",
      "[2023-07-27 18:08:31,923] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  18%|▏| 2773/15000 [23:42<36:12,  5.63it/s, lr=0.000345, step_loss=0.833]07/27/2023 18:08:32 - INFO - __main__ - train loss is 7.485109438654035\n",
      "Steps:  18%|▏| 2774/15000 [23:42<36:16,  5.62it/s, lr=0.000345, step_loss=0.082907/27/2023 18:08:32 - INFO - __main__ - train loss is 7.559851398225874\n",
      "Steps:  18%|▏| 2775/15000 [23:42<36:25,  5.59it/s, lr=0.000345, step_loss=0.074707/27/2023 18:08:32 - INFO - __main__ - train loss is 7.628587221261114\n",
      "Steps:  19%|▏| 2776/15000 [23:42<36:25,  5.59it/s, lr=0.000345, step_loss=0.068707/27/2023 18:08:32 - INFO - __main__ - train loss is 7.630059742950834\n",
      "Steps:  19%|▏| 2777/15000 [23:42<36:24,  5.60it/s, lr=0.000345, step_loss=0.001407/27/2023 18:08:32 - INFO - __main__ - train loss is 7.663512730621733\n",
      "Steps:  19%|▏| 2778/15000 [23:43<36:24,  5.60it/s, lr=0.000346, step_loss=0.033507/27/2023 18:08:32 - INFO - __main__ - train loss is 7.8484809041256085\n",
      "Steps:  19%|▏| 2779/15000 [23:43<36:25,  5.59it/s, lr=0.000346, step_loss=0.185]07/27/2023 18:08:33 - INFO - __main__ - train loss is 7.853805333026685\n",
      "Steps:  19%|▏| 2780/15000 [23:43<36:25,  5.59it/s, lr=0.000346, step_loss=0.005307/27/2023 18:08:33 - INFO - __main__ - train loss is 8.355286031612195\n",
      "Steps:  19%|▏| 2781/15000 [23:43<36:26,  5.59it/s, lr=0.000346, step_loss=0.501]07/27/2023 18:08:33 - INFO - __main__ - train loss is 8.425731874653138\n",
      "Steps:  19%|▏| 2782/15000 [23:43<36:36,  5.56it/s, lr=0.000346, step_loss=0.070407/27/2023 18:08:33 - INFO - __main__ - train loss is 8.465342752286233\n",
      "Steps:  19%|▏| 2783/15000 [23:43<38:54,  5.23it/s, lr=0.000346, step_loss=0.039607/27/2023 18:08:33 - INFO - __main__ - train loss is 8.579997546621598\n",
      "Steps:  19%|▏| 2784/15000 [23:44<44:02,  4.62it/s, lr=0.000346, step_loss=0.115]07/27/2023 18:08:34 - INFO - __main__ - train loss is 9.012495346018113\n",
      "Steps:  19%|▏| 2785/15000 [23:44<42:55,  4.74it/s, lr=0.000346, step_loss=0.432]07/27/2023 18:08:34 - INFO - __main__ - train loss is 9.164666629978456\n",
      "Steps:  19%|▏| 2786/15000 [23:44<41:46,  4.87it/s, lr=0.000347, step_loss=0.152]07/27/2023 18:08:34 - INFO - __main__ - train loss is 9.167269653757103\n",
      "Steps:  19%|▏| 2787/15000 [23:44<40:09,  5.07it/s, lr=0.000347, step_loss=0.002607/27/2023 18:08:34 - INFO - __main__ - train loss is 9.907925731618889\n",
      "Steps:  19%|▏| 2788/15000 [23:45<39:02,  5.21it/s, lr=0.000347, step_loss=0.741]07/27/2023 18:08:34 - INFO - __main__ - train loss is 10.056920907576568\n",
      "Steps:  19%|▏| 2789/15000 [23:45<38:15,  5.32it/s, lr=0.000347, step_loss=0.149]07/27/2023 18:08:35 - INFO - __main__ - train loss is 10.126763044972904\n",
      "Steps:  19%|▏| 2790/15000 [23:45<37:42,  5.40it/s, lr=0.000347, step_loss=0.069807/27/2023 18:08:35 - INFO - __main__ - train loss is 10.147332371328957\n",
      "Steps:  19%|▏| 2791/15000 [23:45<37:19,  5.45it/s, lr=0.000347, step_loss=0.020607/27/2023 18:08:35 - INFO - __main__ - train loss is 10.371878401492722\n",
      "Steps:  19%|▏| 2792/15000 [23:45<37:02,  5.49it/s, lr=0.000347, step_loss=0.225]07/27/2023 18:08:35 - INFO - __main__ - train loss is 10.430083108250983\n",
      "Steps:  19%|▏| 2793/15000 [23:45<36:50,  5.52it/s, lr=0.000347, step_loss=0.058207/27/2023 18:08:35 - INFO - __main__ - train loss is 10.477359620039351\n",
      "Steps:  19%|▏| 2794/15000 [23:46<36:41,  5.55it/s, lr=0.000348, step_loss=0.047307/27/2023 18:08:35 - INFO - __main__ - train loss is 10.491288378019817\n",
      "Steps:  19%|▏| 2795/15000 [23:46<36:35,  5.56it/s, lr=0.000348, step_loss=0.013907/27/2023 18:08:36 - INFO - __main__ - train loss is 10.543672288884409\n",
      "Steps:  19%|▏| 2796/15000 [23:46<36:31,  5.57it/s, lr=0.000348, step_loss=0.052407/27/2023 18:08:36 - INFO - __main__ - train loss is 10.547483637346886\n",
      "Steps:  19%|▏| 2797/15000 [23:46<36:28,  5.58it/s, lr=0.000348, step_loss=0.003807/27/2023 18:08:36 - INFO - __main__ - train loss is 10.72964142204728\n",
      "Steps:  19%|▏| 2798/15000 [23:46<36:25,  5.58it/s, lr=0.000348, step_loss=0.182]07/27/2023 18:08:36 - INFO - __main__ - train loss is 11.011621638550423\n",
      "Steps:  19%|▏| 2799/15000 [23:46<36:26,  5.58it/s, lr=0.000348, step_loss=0.282]07/27/2023 18:08:36 - INFO - __main__ - train loss is 11.032603695406578\n",
      "Steps:  19%|▏| 2800/15000 [23:47<36:25,  5.58it/s, lr=0.000348, step_loss=0.021]07/27/2023 18:08:37 - INFO - __main__ - train loss is 11.034773544990458\n",
      "Steps:  19%|▏| 2801/15000 [23:47<36:24,  5.58it/s, lr=0.000348, step_loss=0.002107/27/2023 18:08:37 - INFO - __main__ - train loss is 11.103102596127428\n",
      "Steps:  19%|▏| 2802/15000 [23:47<36:23,  5.59it/s, lr=0.000349, step_loss=0.068307/27/2023 18:08:37 - INFO - __main__ - train loss is 11.274213777505793\n",
      "Steps:  19%|▏| 2803/15000 [23:47<36:24,  5.58it/s, lr=0.000349, step_loss=0.171]07/27/2023 18:08:37 - INFO - __main__ - train loss is 11.72668744775001\n",
      "Steps:  19%|▏| 2804/15000 [23:47<36:23,  5.59it/s, lr=0.000349, step_loss=0.452]07/27/2023 18:08:37 - INFO - __main__ - train loss is 12.030799464904703\n",
      "Steps:  19%|▏| 2805/15000 [23:48<36:22,  5.59it/s, lr=0.000349, step_loss=0.304]07/27/2023 18:08:37 - INFO - __main__ - train loss is 12.068571792566217\n",
      "Steps:  19%|▏| 2806/15000 [23:48<36:20,  5.59it/s, lr=0.000349, step_loss=0.037807/27/2023 18:08:38 - INFO - __main__ - train loss is 12.429587946855463\n",
      "Steps:  19%|▏| 2807/15000 [23:48<36:20,  5.59it/s, lr=0.000349, step_loss=0.361]07/27/2023 18:08:38 - INFO - __main__ - train loss is 12.441371845663525\n",
      "Steps:  19%|▏| 2808/15000 [23:48<36:21,  5.59it/s, lr=0.000349, step_loss=0.011807/27/2023 18:08:38 - INFO - __main__ - train loss is 12.44565051572863\n",
      "Steps:  19%|▏| 2809/15000 [23:48<36:21,  5.59it/s, lr=0.000349, step_loss=0.004207/27/2023 18:08:38 - INFO - __main__ - train loss is 12.459597216569819\n",
      "Steps:  19%|▏| 2810/15000 [23:48<36:21,  5.59it/s, lr=0.00035, step_loss=0.0139]07/27/2023 18:08:38 - INFO - __main__ - train loss is 12.803547756397165\n",
      "Steps:  19%|▎ | 2811/15000 [23:49<36:25,  5.58it/s, lr=0.00035, step_loss=0.344]07/27/2023 18:08:38 - INFO - __main__ - train loss is 13.69713582249824\n",
      "Steps:  19%|▎ | 2812/15000 [23:49<36:24,  5.58it/s, lr=0.00035, step_loss=0.894]07/27/2023 18:08:39 - INFO - __main__ - train loss is 14.077207879745401\n",
      "Steps:  19%|▌  | 2813/15000 [23:49<36:28,  5.57it/s, lr=0.00035, step_loss=0.38]07/27/2023 18:08:39 - INFO - __main__ - train loss is 14.085376141243614\n",
      "Steps:  19%|▏| 2814/15000 [23:49<36:26,  5.57it/s, lr=0.00035, step_loss=0.0081707/27/2023 18:08:39 - INFO - __main__ - train loss is 14.13581596466247\n",
      "Steps:  19%|▏| 2815/15000 [23:49<36:29,  5.56it/s, lr=0.00035, step_loss=0.0504]07/27/2023 18:08:39 - INFO - __main__ - train loss is 14.262744160019793\n",
      "Steps:  19%|▍ | 2816/15000 [23:50<36:28,  5.57it/s, lr=0.00035, step_loss=0.127]07/27/2023 18:08:39 - INFO - __main__ - train loss is 14.404604451381601\n",
      "Steps:  19%|▏| 2817/15000 [23:50<36:26,  5.57it/s, lr=0.000351, step_loss=0.142]07/27/2023 18:08:40 - INFO - __main__ - train loss is 14.470680134021677\n",
      "Steps:  19%|▏| 2818/15000 [23:50<36:33,  5.55it/s, lr=0.000351, step_loss=0.066107/27/2023 18:08:40 - INFO - __main__ - train loss is 14.560857908450998\n",
      "Steps:  19%|▏| 2819/15000 [23:50<36:30,  5.56it/s, lr=0.000351, step_loss=0.090207/27/2023 18:08:40 - INFO - __main__ - train loss is 14.782154993736185\n",
      "Steps:  19%|▏| 2820/15000 [23:50<36:27,  5.57it/s, lr=0.000351, step_loss=0.221]07/27/2023 18:08:40 - INFO - __main__ - train loss is 15.282056973897852\n",
      "Steps:  19%|▌  | 2821/15000 [23:50<36:45,  5.52it/s, lr=0.000351, step_loss=0.5]07/27/2023 18:08:40 - INFO - __main__ - train loss is 15.448033289634623\n",
      "Steps:  19%|▏| 2822/15000 [23:51<36:49,  5.51it/s, lr=0.000351, step_loss=0.166]07/27/2023 18:08:40 - INFO - __main__ - train loss is 15.502695591771044\n",
      "Steps:  19%|▏| 2823/15000 [23:51<37:00,  5.48it/s, lr=0.000351, step_loss=0.054707/27/2023 18:08:41 - INFO - __main__ - train loss is 15.60567720385734\n",
      "Steps:  19%|▏| 2824/15000 [23:51<36:54,  5.50it/s, lr=0.000351, step_loss=0.103]07/27/2023 18:08:41 - INFO - __main__ - train loss is 15.678727449500002\n",
      "Steps:  19%|▏| 2825/15000 [23:51<36:44,  5.52it/s, lr=0.000351, step_loss=0.073107/27/2023 18:08:41 - INFO - __main__ - train loss is 15.731197150074877\n",
      "Steps:  19%|▏| 2826/15000 [23:51<36:35,  5.54it/s, lr=0.000352, step_loss=0.052507/27/2023 18:08:41 - INFO - __main__ - train loss is 15.772769635193981\n",
      "Steps:  19%|▏| 2827/15000 [23:52<36:30,  5.56it/s, lr=0.000352, step_loss=0.041607/27/2023 18:08:41 - INFO - __main__ - train loss is 15.81838148611132\n",
      "Steps:  19%|▏| 2828/15000 [23:52<36:26,  5.57it/s, lr=0.000352, step_loss=0.045607/27/2023 18:08:42 - INFO - __main__ - train loss is 16.024690372520126\n",
      "Steps:  19%|▏| 2829/15000 [23:52<36:23,  5.57it/s, lr=0.000352, step_loss=0.206]07/27/2023 18:08:42 - INFO - __main__ - train loss is 16.14447461592499\n",
      "Steps:  19%|▍ | 2830/15000 [23:52<36:20,  5.58it/s, lr=0.000352, step_loss=0.12]07/27/2023 18:08:42 - INFO - __main__ - train loss is 16.205277403467335\n",
      "Steps:  19%|▏| 2831/15000 [23:52<36:19,  5.58it/s, lr=0.000352, step_loss=0.060807/27/2023 18:08:42 - INFO - __main__ - train loss is 16.223584433668293\n",
      "Steps:  19%|▏| 2832/15000 [23:52<36:18,  5.58it/s, lr=0.000352, step_loss=0.018307/27/2023 18:08:42 - INFO - __main__ - train loss is 16.268551488989033\n",
      "Steps:  19%|▏| 2833/15000 [23:53<36:18,  5.58it/s, lr=0.000353, step_loss=0.045]07/27/2023 18:08:42 - INFO - __main__ - train loss is 16.399559577577747\n",
      "Steps:  19%|▏| 2834/15000 [23:53<36:18,  5.58it/s, lr=0.000353, step_loss=0.131]07/27/2023 18:08:43 - INFO - __main__ - train loss is 16.422409319900908\n",
      "Steps:  19%|▏| 2835/15000 [23:53<36:18,  5.58it/s, lr=0.000353, step_loss=0.022807/27/2023 18:08:43 - INFO - __main__ - train loss is 16.42677256243769\n",
      "Steps:  19%|▏| 2836/15000 [23:53<36:17,  5.59it/s, lr=0.000353, step_loss=0.004307/27/2023 18:08:43 - INFO - __main__ - train loss is 16.435001354315318\n",
      "Steps:  19%|▏| 2837/15000 [23:53<36:16,  5.59it/s, lr=0.000353, step_loss=0.008207/27/2023 18:08:43 - INFO - __main__ - train loss is 16.46302949974779\n",
      "Steps:  19%|▏| 2838/15000 [23:53<36:32,  5.55it/s, lr=0.000353, step_loss=0.028]07/27/2023 18:08:43 - INFO - __main__ - train loss is 16.755867834785022\n",
      "Steps:  19%|▏| 2839/15000 [23:54<36:28,  5.56it/s, lr=0.000353, step_loss=0.293]07/27/2023 18:08:44 - INFO - __main__ - train loss is 16.781181998201646\n",
      "Steps:  19%|▏| 2840/15000 [23:54<36:25,  5.56it/s, lr=0.000353, step_loss=0.025307/27/2023 18:08:44 - INFO - __main__ - train loss is 16.922000862308778\n",
      "Steps:  19%|▏| 2841/15000 [23:54<36:22,  5.57it/s, lr=0.000353, step_loss=0.141]07/27/2023 18:08:44 - INFO - __main__ - train loss is 16.9692288559163\n",
      "Steps:  19%|▏| 2842/15000 [23:54<36:20,  5.58it/s, lr=0.000354, step_loss=0.047207/27/2023 18:08:44 - INFO - __main__ - train loss is 17.32080098206643\n",
      "Steps:  19%|▏| 2843/15000 [23:54<36:20,  5.57it/s, lr=0.000354, step_loss=0.352]07/27/2023 18:08:44 - INFO - __main__ - train loss is 17.32694302184973\n",
      "Steps:  19%|▏| 2844/15000 [23:55<36:18,  5.58it/s, lr=0.000354, step_loss=0.006107/27/2023 18:08:44 - INFO - __main__ - train loss is 17.340622915537097\n",
      "Steps:  19%|▏| 2845/15000 [23:55<36:17,  5.58it/s, lr=0.000354, step_loss=0.013707/27/2023 18:08:45 - INFO - __main__ - train loss is 17.36095114669297\n",
      "Steps:  19%|▏| 2846/15000 [23:55<36:18,  5.58it/s, lr=0.000354, step_loss=0.020307/27/2023 18:08:45 - INFO - __main__ - train loss is 17.39143799303565\n",
      "Steps:  19%|▏| 2847/15000 [23:55<36:34,  5.54it/s, lr=0.000354, step_loss=0.030507/27/2023 18:08:45 - INFO - __main__ - train loss is 17.623742580995895\n",
      "Steps:  19%|▏| 2848/15000 [23:55<36:28,  5.55it/s, lr=0.000354, step_loss=0.232]07/27/2023 18:08:45 - INFO - __main__ - train loss is 17.655503102228977\n",
      "Steps:  19%|▏| 2849/15000 [23:55<36:23,  5.56it/s, lr=0.000354, step_loss=0.031807/27/2023 18:08:45 - INFO - __main__ - train loss is 17.863525115535595\n",
      "Steps:  19%|▏| 2850/15000 [23:56<36:27,  5.55it/s, lr=0.000355, step_loss=0.208]07/27/2023 18:08:45 - INFO - __main__ - train loss is 18.021929197595455\n",
      "Steps:  19%|▏| 2851/15000 [23:56<36:36,  5.53it/s, lr=0.000355, step_loss=0.158]07/27/2023 18:08:46 - INFO - __main__ - train loss is 18.040052306489088\n",
      "Steps:  19%|▏| 2852/15000 [23:56<36:28,  5.55it/s, lr=0.000355, step_loss=0.018107/27/2023 18:08:46 - INFO - __main__ - train loss is 18.118890073732473\n",
      "Steps:  19%|▏| 2853/15000 [23:56<36:23,  5.56it/s, lr=0.000355, step_loss=0.078807/27/2023 18:08:46 - INFO - __main__ - train loss is 18.143270869390108\n",
      "Steps:  19%|▏| 2854/15000 [23:56<36:20,  5.57it/s, lr=0.000355, step_loss=0.024407/27/2023 18:08:46 - INFO - __main__ - train loss is 18.167271169484593\n",
      "Steps:  19%|▏| 2855/15000 [23:57<36:17,  5.58it/s, lr=0.000355, step_loss=0.024]07/27/2023 18:08:46 - INFO - __main__ - train loss is 18.7911416614661\n",
      "Steps:  19%|▏| 2856/15000 [23:57<36:15,  5.58it/s, lr=0.000355, step_loss=0.624]07/27/2023 18:08:47 - INFO - __main__ - train loss is 18.794522012001835\n",
      "Steps:  19%|▏| 2857/15000 [23:57<36:16,  5.58it/s, lr=0.000355, step_loss=0.003307/27/2023 18:08:47 - INFO - __main__ - train loss is 18.869955206639133\n",
      "Steps:  19%|▏| 2858/15000 [23:57<36:14,  5.58it/s, lr=0.000356, step_loss=0.075407/27/2023 18:08:47 - INFO - __main__ - train loss is 19.11805983853992\n",
      "Steps:  19%|▏| 2859/15000 [23:57<36:14,  5.58it/s, lr=0.000356, step_loss=0.248]07/27/2023 18:08:47 - INFO - __main__ - train loss is 19.46521943283733\n",
      "Steps:  19%|▏| 2860/15000 [23:57<36:15,  5.58it/s, lr=0.000356, step_loss=0.347]07/27/2023 18:08:47 - INFO - __main__ - train loss is 19.622222880250774\n",
      "Steps:  19%|▏| 2861/15000 [23:58<36:13,  5.58it/s, lr=0.000356, step_loss=0.157]07/27/2023 18:08:47 - INFO - __main__ - train loss is 19.89912585390266\n",
      "Steps:  19%|▏| 2862/15000 [23:58<36:11,  5.59it/s, lr=0.000356, step_loss=0.277]07/27/2023 18:08:48 - INFO - __main__ - train loss is 19.905276562436484\n",
      "Steps:  19%|▏| 2863/15000 [23:58<36:11,  5.59it/s, lr=0.000356, step_loss=0.006107/27/2023 18:08:48 - INFO - __main__ - train loss is 19.921532756998204\n",
      "Steps:  19%|▏| 2864/15000 [23:58<36:10,  5.59it/s, lr=0.000356, step_loss=0.016307/27/2023 18:08:48 - INFO - __main__ - train loss is 19.95181275473442\n",
      "Steps:  19%|▏| 2865/15000 [23:58<36:12,  5.59it/s, lr=0.000356, step_loss=0.030307/27/2023 18:08:48 - INFO - __main__ - train loss is 20.223242531879805\n",
      "Steps:  19%|▏| 2866/15000 [23:58<36:11,  5.59it/s, lr=0.000357, step_loss=0.271]07/27/2023 18:08:48 - INFO - __main__ - train loss is 20.257357585593127\n",
      "Steps:  19%|▏| 2867/15000 [23:59<36:11,  5.59it/s, lr=0.000357, step_loss=0.034107/27/2023 18:08:49 - INFO - __main__ - train loss is 20.38314111845102\n",
      "Steps:  19%|▏| 2868/15000 [23:59<36:32,  5.53it/s, lr=0.000357, step_loss=0.126]07/27/2023 18:08:49 - INFO - __main__ - train loss is 20.38568685844075\n",
      "Steps:  19%|▏| 2869/15000 [23:59<36:43,  5.51it/s, lr=0.000357, step_loss=0.002507/27/2023 18:08:49 - INFO - __main__ - train loss is 20.446219823206775\n",
      "Steps:  19%|▏| 2870/15000 [23:59<36:33,  5.53it/s, lr=0.000357, step_loss=0.060507/27/2023 18:08:49 - INFO - __main__ - train loss is 20.981167397345416\n",
      "Steps:  19%|▏| 2871/15000 [23:59<36:29,  5.54it/s, lr=0.000357, step_loss=0.535]07/27/2023 18:08:49 - INFO - __main__ - train loss is 21.013028270448558\n",
      "Steps:  19%|▏| 2872/15000 [24:00<36:23,  5.55it/s, lr=0.000357, step_loss=0.031907/27/2023 18:08:49 - INFO - __main__ - train loss is 21.032134479726665\n",
      "Steps:  19%|▏| 2873/15000 [24:00<36:19,  5.56it/s, lr=0.000358, step_loss=0.019107/27/2023 18:08:50 - INFO - __main__ - train loss is 21.459671742166393\n",
      "Steps:  19%|▏| 2874/15000 [24:00<36:16,  5.57it/s, lr=0.000358, step_loss=0.428]07/27/2023 18:08:50 - INFO - __main__ - train loss is 21.50739534466993\n",
      "Steps:  19%|▏| 2875/15000 [24:00<36:15,  5.57it/s, lr=0.000358, step_loss=0.047707/27/2023 18:08:50 - INFO - __main__ - train loss is 21.51096914813388\n",
      "Steps:  19%|▏| 2876/15000 [24:00<36:13,  5.58it/s, lr=0.000358, step_loss=0.003507/27/2023 18:08:50 - INFO - __main__ - train loss is 21.521469895844348\n",
      "Steps:  19%|▏| 2877/15000 [24:00<36:32,  5.53it/s, lr=0.000358, step_loss=0.010507/27/2023 18:08:50 - INFO - __main__ - train loss is 21.98265803337563\n",
      "Steps:  19%|▏| 2878/15000 [24:01<36:24,  5.55it/s, lr=0.000358, step_loss=0.461]07/27/2023 18:08:51 - INFO - __main__ - train loss is 21.98808211472351\n",
      "Steps:  19%|▏| 2879/15000 [24:01<36:19,  5.56it/s, lr=0.000358, step_loss=0.005407/27/2023 18:08:51 - INFO - __main__ - train loss is 21.995006825891323\n",
      "Steps:  19%|▏| 2880/15000 [24:01<36:22,  5.55it/s, lr=0.000358, step_loss=0.006907/27/2023 18:08:51 - INFO - __main__ - train loss is 22.442478027311154\n",
      "Steps:  19%|▏| 2881/15000 [24:01<36:20,  5.56it/s, lr=0.000358, step_loss=0.447]07/27/2023 18:08:51 - INFO - __main__ - train loss is 22.444652754464187\n",
      "Steps:  19%|▏| 2882/15000 [24:01<36:17,  5.57it/s, lr=0.000359, step_loss=0.002107/27/2023 18:08:51 - INFO - __main__ - train loss is 22.468085359432735\n",
      "Steps:  19%|▏| 2883/15000 [24:02<36:14,  5.57it/s, lr=0.000359, step_loss=0.023407/27/2023 18:08:51 - INFO - __main__ - train loss is 22.47155821567867\n",
      "Steps:  19%|▏| 2884/15000 [24:02<36:12,  5.58it/s, lr=0.000359, step_loss=0.003407/27/2023 18:08:52 - INFO - __main__ - train loss is 22.47486691561062\n",
      "Steps:  19%|▏| 2885/15000 [24:02<36:10,  5.58it/s, lr=0.000359, step_loss=0.003307/27/2023 18:08:52 - INFO - __main__ - train loss is 22.966042388346978\n",
      "Steps:  19%|▏| 2886/15000 [24:02<36:08,  5.59it/s, lr=0.000359, step_loss=0.491]07/27/2023 18:08:52 - INFO - __main__ - train loss is 22.96860963094514\n",
      "Steps:  19%|▏| 2887/15000 [24:02<36:08,  5.59it/s, lr=0.000359, step_loss=0.002507/27/2023 18:08:52 - INFO - __main__ - train loss is 22.970466101774946\n",
      "Steps:  19%|▏| 2888/15000 [24:02<36:07,  5.59it/s, lr=0.000359, step_loss=0.001807/27/2023 18:08:52 - INFO - __main__ - train loss is 23.0421023464296\n",
      "Steps:  19%|▏| 2889/15000 [24:03<36:07,  5.59it/s, lr=0.00036, step_loss=0.0716]07/27/2023 18:08:53 - INFO - __main__ - train loss is 23.068817598978058\n",
      "Steps:  19%|▏| 2890/15000 [24:03<36:07,  5.59it/s, lr=0.00036, step_loss=0.0267]07/27/2023 18:08:53 - INFO - __main__ - train loss is 23.100690638879314\n",
      "Steps:  19%|▏| 2891/15000 [24:03<36:07,  5.59it/s, lr=0.00036, step_loss=0.0319]07/27/2023 18:08:53 - INFO - __main__ - train loss is 23.167495584348217\n",
      "Steps:  19%|▏| 2892/15000 [24:03<36:06,  5.59it/s, lr=0.00036, step_loss=0.0668]07/27/2023 18:08:53 - INFO - __main__ - train loss is 23.634540533879772\n",
      "Steps:  19%|▍ | 2893/15000 [24:03<36:27,  5.54it/s, lr=0.00036, step_loss=0.467]07/27/2023 18:08:53 - INFO - __main__ - train loss is 23.636562070576474\n",
      "Steps:  19%|▏| 2894/15000 [24:04<36:28,  5.53it/s, lr=0.00036, step_loss=0.0020207/27/2023 18:08:53 - INFO - __main__ - train loss is 23.642363264458254\n",
      "Steps:  19%|▏| 2895/15000 [24:04<36:22,  5.55it/s, lr=0.00036, step_loss=0.0058]07/27/2023 18:08:54 - INFO - __main__ - train loss is 23.653644778067246\n",
      "Steps:  19%|▏| 2896/15000 [24:04<36:19,  5.55it/s, lr=0.00036, step_loss=0.0113]07/27/2023 18:08:54 - INFO - __main__ - train loss is 23.66428054519929\n",
      "Steps:  19%|▏| 2897/15000 [24:04<36:15,  5.56it/s, lr=0.00036, step_loss=0.0106]07/27/2023 18:08:54 - INFO - __main__ - train loss is 23.755285781109706\n",
      "Steps:  19%|▏| 2898/15000 [24:04<36:13,  5.57it/s, lr=0.000361, step_loss=0.091]07/27/2023 18:08:54 - INFO - __main__ - train loss is 24.433909218991175\n",
      "Steps:  19%|▏| 2899/15000 [24:04<36:11,  5.57it/s, lr=0.000361, step_loss=0.679]07/27/2023 18:08:54 - INFO - __main__ - train loss is 24.516860325122252\n",
      "Steps:  19%|▏| 2900/15000 [24:05<36:08,  5.58it/s, lr=0.000361, step_loss=0.083]07/27/2023 18:08:54 - INFO - __main__ - train loss is 24.519229630706832\n",
      "Steps:  19%|▏| 2901/15000 [24:05<36:07,  5.58it/s, lr=0.000361, step_loss=0.002307/27/2023 18:08:55 - INFO - __main__ - train loss is 24.608130412874743\n",
      "Steps:  19%|▏| 2902/15000 [24:05<36:05,  5.59it/s, lr=0.000361, step_loss=0.088907/27/2023 18:08:55 - INFO - __main__ - train loss is 25.10514326649718\n",
      "Steps:  19%|▏| 2903/15000 [24:05<36:05,  5.59it/s, lr=0.000361, step_loss=0.497]07/27/2023 18:08:55 - INFO - __main__ - train loss is 25.37200592714362\n",
      "Steps:  19%|▏| 2904/15000 [24:05<36:05,  5.59it/s, lr=0.000361, step_loss=0.267]07/27/2023 18:08:55 - INFO - __main__ - train loss is 25.886778878746554\n",
      "Steps:  19%|▏| 2905/15000 [24:06<36:04,  5.59it/s, lr=0.000362, step_loss=0.515]07/27/2023 18:08:55 - INFO - __main__ - train loss is 25.88943987339735\n",
      "Steps:  19%|▏| 2906/15000 [24:06<36:03,  5.59it/s, lr=0.000362, step_loss=0.002607/27/2023 18:08:56 - INFO - __main__ - train loss is 26.054245479404926\n",
      "Steps:  19%|▏| 2907/15000 [24:06<36:02,  5.59it/s, lr=0.000362, step_loss=0.165]07/27/2023 18:08:56 - INFO - __main__ - train loss is 26.32678235322237\n",
      "Steps:  19%|▏| 2908/15000 [24:06<36:01,  5.59it/s, lr=0.000362, step_loss=0.273]07/27/2023 18:08:56 - INFO - __main__ - train loss is 26.86175585538149\n",
      "Steps:  19%|▏| 2909/15000 [24:06<36:01,  5.59it/s, lr=0.000362, step_loss=0.535]07/27/2023 18:08:56 - INFO - __main__ - train loss is 26.889078725129366\n",
      "Steps:  19%|▏| 2910/15000 [24:06<36:01,  5.59it/s, lr=0.000362, step_loss=0.027307/27/2023 18:08:56 - INFO - __main__ - train loss is 27.043235573917627\n",
      "Steps:  19%|▏| 2911/15000 [24:07<36:02,  5.59it/s, lr=0.000362, step_loss=0.154]07/27/2023 18:08:56 - INFO - __main__ - train loss is 27.181170616298914\n",
      "Steps:  19%|▏| 2912/15000 [24:07<36:01,  5.59it/s, lr=0.000362, step_loss=0.138]07/27/2023 18:08:57 - INFO - __main__ - train loss is 27.816835019737482\n",
      "Steps:  19%|▏| 2913/15000 [24:07<36:01,  5.59it/s, lr=0.000362, step_loss=0.636]07/27/2023 18:08:57 - INFO - __main__ - train loss is 27.819721839157864\n",
      "Steps:  19%|▏| 2914/15000 [24:07<36:22,  5.54it/s, lr=0.000363, step_loss=0.002807/27/2023 18:08:57 - INFO - __main__ - train loss is 27.998045376269147\n",
      "Steps:  19%|▏| 2915/15000 [24:07<36:23,  5.53it/s, lr=0.000363, step_loss=0.178]07/27/2023 18:08:57 - INFO - __main__ - train loss is 27.999643712537363\n",
      "Steps:  19%|▏| 2916/15000 [24:07<36:16,  5.55it/s, lr=0.000363, step_loss=0.001607/27/2023 18:08:57 - INFO - __main__ - train loss is 28.125129877822474\n",
      "Steps:  19%|▏| 2917/15000 [24:08<36:14,  5.56it/s, lr=0.000363, step_loss=0.125]07/27/2023 18:08:58 - INFO - __main__ - train loss is 28.156082964735106\n",
      "Steps:  19%|▏| 2918/15000 [24:08<36:12,  5.56it/s, lr=0.000363, step_loss=0.031]07/27/2023 18:08:58 - INFO - __main__ - train loss is 28.196528814034536\n",
      "Steps:  19%|▏| 2919/15000 [24:08<36:11,  5.56it/s, lr=0.000363, step_loss=0.040407/27/2023 18:08:58 - INFO - __main__ - train loss is 28.365442550973967\n",
      "Steps:  19%|▏| 2920/15000 [24:08<36:09,  5.57it/s, lr=0.000363, step_loss=0.169]07/27/2023 18:08:58 - INFO - __main__ - train loss is 28.73758331616409\n",
      "Steps:  19%|▏| 2921/15000 [24:08<36:09,  5.57it/s, lr=0.000363, step_loss=0.372]07/27/2023 18:08:58 - INFO - __main__ - train loss is 28.905446402030066\n",
      "Steps:  19%|▏| 2922/15000 [24:09<36:07,  5.57it/s, lr=0.000364, step_loss=0.168]07/27/2023 18:08:58 - INFO - __main__ - train loss is 29.045477620558813\n",
      "Steps:  19%|▍ | 2923/15000 [24:09<36:05,  5.58it/s, lr=0.000364, step_loss=0.14]07/27/2023 18:08:59 - INFO - __main__ - train loss is 29.195397458272055\n",
      "Steps:  19%|▍ | 2924/15000 [24:09<36:04,  5.58it/s, lr=0.000364, step_loss=0.15]07/27/2023 18:08:59 - INFO - __main__ - train loss is 29.334797389106825\n",
      "Steps:  20%|▏| 2925/15000 [24:09<36:05,  5.58it/s, lr=0.000364, step_loss=0.139]07/27/2023 18:08:59 - INFO - __main__ - train loss is 29.337561779888347\n",
      "Steps:  20%|▏| 2926/15000 [24:09<36:04,  5.58it/s, lr=0.000364, step_loss=0.002707/27/2023 18:08:59 - INFO - __main__ - train loss is 29.344279870623723\n",
      "Steps:  20%|▏| 2927/15000 [24:09<36:04,  5.58it/s, lr=0.000364, step_loss=0.006707/27/2023 18:08:59 - INFO - __main__ - train loss is 29.381853595608845\n",
      "Steps:  20%|▏| 2928/15000 [24:10<36:04,  5.58it/s, lr=0.000364, step_loss=0.037607/27/2023 18:09:00 - INFO - __main__ - train loss is 29.635681048268452\n",
      "Steps:  20%|▏| 2929/15000 [24:10<36:06,  5.57it/s, lr=0.000365, step_loss=0.254]07/27/2023 18:09:00 - INFO - __main__ - train loss is 29.650536546716467\n",
      "Steps:  20%|▏| 2930/15000 [24:10<36:25,  5.52it/s, lr=0.000365, step_loss=0.014907/27/2023 18:09:00 - INFO - __main__ - train loss is 29.683128448436037\n",
      "Steps:  20%|▏| 2931/15000 [24:10<36:24,  5.52it/s, lr=0.000365, step_loss=0.032607/27/2023 18:09:00 - INFO - __main__ - train loss is 29.698895072797313\n",
      "Steps:  20%|▏| 2932/15000 [24:10<36:17,  5.54it/s, lr=0.000365, step_loss=0.015807/27/2023 18:09:00 - INFO - __main__ - train loss is 29.76898136571981\n",
      "Steps:  20%|▏| 2933/15000 [24:11<36:12,  5.56it/s, lr=0.000365, step_loss=0.070107/27/2023 18:09:00 - INFO - __main__ - train loss is 30.202892808476463\n",
      "Steps:  20%|▏| 2934/15000 [24:11<36:08,  5.56it/s, lr=0.000365, step_loss=0.434]07/27/2023 18:09:01 - INFO - __main__ - train loss is 30.219004003563896\n",
      "Steps:  20%|▏| 2935/15000 [24:11<36:05,  5.57it/s, lr=0.000365, step_loss=0.016107/27/2023 18:09:01 - INFO - __main__ - train loss is 30.533921031514183\n",
      "Steps:  20%|▏| 2936/15000 [24:11<36:05,  5.57it/s, lr=0.000365, step_loss=0.315]07/27/2023 18:09:01 - INFO - __main__ - train loss is 30.74788103834726\n",
      "Steps:  20%|▏| 2937/15000 [24:11<36:03,  5.58it/s, lr=0.000365, step_loss=0.214]07/27/2023 18:09:01 - INFO - __main__ - train loss is 30.86238701478578\n",
      "Steps:  20%|▏| 2938/15000 [24:11<36:01,  5.58it/s, lr=0.000366, step_loss=0.115]07/27/2023 18:09:01 - INFO - __main__ - train loss is 31.026717154541984\n",
      "Steps:  20%|▏| 2939/15000 [24:12<36:01,  5.58it/s, lr=0.000366, step_loss=0.164]07/27/2023 18:09:01 - INFO - __main__ - train loss is 31.029078216291964\n",
      "Steps:  20%|▏| 2940/15000 [24:12<36:01,  5.58it/s, lr=0.000366, step_loss=0.002307/27/2023 18:09:02 - INFO - __main__ - train loss is 31.03024229221046\n",
      "Steps:  20%|▏| 2941/15000 [24:12<36:03,  5.57it/s, lr=0.000366, step_loss=0.001107/27/2023 18:09:02 - INFO - __main__ - train loss is 31.034881270024925\n",
      "Steps:  20%|▏| 2942/15000 [24:12<36:23,  5.52it/s, lr=0.000366, step_loss=0.004607/27/2023 18:09:02 - INFO - __main__ - train loss is 31.132488301489502\n",
      "Steps:  20%|▏| 2943/15000 [24:12<36:20,  5.53it/s, lr=0.000366, step_loss=0.097607/27/2023 18:09:02 - INFO - __main__ - train loss is 31.278649291489273\n",
      "Steps:  20%|▏| 2944/15000 [24:13<36:13,  5.55it/s, lr=0.000366, step_loss=0.146]07/27/2023 18:09:02 - INFO - __main__ - train loss is 31.588166079018265\n",
      "Steps:  20%|▍ | 2945/15000 [24:13<36:29,  5.51it/s, lr=0.000367, step_loss=0.31]07/27/2023 18:09:03 - INFO - __main__ - train loss is 31.604001747909933\n",
      "Steps:  20%|▏| 2946/15000 [24:13<36:20,  5.53it/s, lr=0.000367, step_loss=0.015807/27/2023 18:09:03 - INFO - __main__ - train loss is 31.61819880688563\n",
      "Steps:  20%|▏| 2947/15000 [24:13<36:14,  5.54it/s, lr=0.000367, step_loss=0.014207/27/2023 18:09:03 - INFO - __main__ - train loss is 31.710409889463335\n",
      "Steps:  20%|▏| 2948/15000 [24:13<36:09,  5.56it/s, lr=0.000367, step_loss=0.092207/27/2023 18:09:03 - INFO - __main__ - train loss is 31.714700317010283\n",
      "Steps:  20%|▏| 2949/15000 [24:13<36:07,  5.56it/s, lr=0.000367, step_loss=0.004207/27/2023 18:09:03 - INFO - __main__ - train loss is 31.74442450888455\n",
      "Steps:  20%|▏| 2950/15000 [24:14<36:03,  5.57it/s, lr=0.000367, step_loss=0.029707/27/2023 18:09:03 - INFO - __main__ - train loss is 32.23401038534939\n",
      "Steps:  20%|▍ | 2951/15000 [24:14<36:00,  5.58it/s, lr=0.000367, step_loss=0.49]07/27/2023 18:09:04 - INFO - __main__ - train loss is 32.35243986733258\n",
      "Steps:  20%|▏| 2952/15000 [24:14<35:58,  5.58it/s, lr=0.000367, step_loss=0.118]07/27/2023 18:09:04 - INFO - __main__ - train loss is 32.35480648744851\n",
      "Steps:  20%|▏| 2953/15000 [24:14<35:58,  5.58it/s, lr=0.000367, step_loss=0.002307/27/2023 18:09:04 - INFO - __main__ - train loss is 32.45043334830552\n",
      "Steps:  20%|▏| 2954/15000 [24:14<35:57,  5.58it/s, lr=0.000368, step_loss=0.095607/27/2023 18:09:04 - INFO - __main__ - train loss is 32.45890000741929\n",
      "Steps:  20%|▏| 2955/15000 [24:14<35:56,  5.58it/s, lr=0.000368, step_loss=0.008407/27/2023 18:09:04 - INFO - __main__ - train loss is 32.46032759605441\n",
      "Steps:  20%|▏| 2956/15000 [24:15<35:58,  5.58it/s, lr=0.000368, step_loss=0.001407/27/2023 18:09:05 - INFO - __main__ - train loss is 32.52565787790809\n",
      "Steps:  20%|▏| 2957/15000 [24:15<36:19,  5.52it/s, lr=0.000368, step_loss=0.065307/27/2023 18:09:05 - INFO - __main__ - train loss is 32.70896577893291\n",
      "Steps:  20%|▏| 2958/15000 [24:15<36:16,  5.53it/s, lr=0.000368, step_loss=0.183]07/27/2023 18:09:05 - INFO - __main__ - train loss is 32.72924215963576\n",
      "Steps:  20%|▏| 2959/15000 [24:15<36:11,  5.55it/s, lr=0.000368, step_loss=0.020307/27/2023 18:09:05 - INFO - __main__ - train loss is 32.748062389553525\n",
      "Steps:  20%|▏| 2960/15000 [24:15<36:26,  5.51it/s, lr=0.000368, step_loss=0.018807/27/2023 18:09:05 - INFO - __main__ - train loss is 32.76880744530354\n",
      "Steps:  20%|▏| 2961/15000 [24:16<36:55,  5.43it/s, lr=0.000369, step_loss=0.020707/27/2023 18:09:05 - INFO - __main__ - train loss is 32.78733241802547\n",
      "Steps:  20%|▏| 2962/15000 [24:16<37:15,  5.39it/s, lr=0.000369, step_loss=0.018507/27/2023 18:09:06 - INFO - __main__ - train loss is 32.79248161998112\n",
      "Steps:  20%|▏| 2963/15000 [24:16<37:11,  5.39it/s, lr=0.000369, step_loss=0.005107/27/2023 18:09:06 - INFO - __main__ - train loss is 33.55275138106663\n",
      "Steps:  20%|▍ | 2964/15000 [24:16<36:53,  5.44it/s, lr=0.000369, step_loss=0.76]07/27/2023 18:09:06 - INFO - __main__ - train loss is 33.643885333207436\n",
      "Steps:  20%|▏| 2965/15000 [24:16<36:40,  5.47it/s, lr=0.000369, step_loss=0.091107/27/2023 18:09:06 - INFO - __main__ - train loss is 33.65053399291355\n",
      "Steps:  20%|▏| 2966/15000 [24:17<36:36,  5.48it/s, lr=0.000369, step_loss=0.006607/27/2023 18:09:06 - INFO - __main__ - train loss is 33.844798702863045\n",
      "Steps:  20%|▏| 2967/15000 [24:17<36:37,  5.48it/s, lr=0.000369, step_loss=0.194]07/27/2023 18:09:07 - INFO - __main__ - train loss is 33.87228382390458\n",
      "Steps:  20%|▏| 2968/15000 [24:17<36:41,  5.47it/s, lr=0.000369, step_loss=0.027507/27/2023 18:09:07 - INFO - __main__ - train loss is 33.87500820134301\n",
      "Steps:  20%|▏| 2969/15000 [24:17<36:27,  5.50it/s, lr=0.000369, step_loss=0.002707/27/2023 18:09:07 - INFO - __main__ - train loss is 33.87640134990215\n",
      "Steps:  20%|▏| 2970/15000 [24:17<36:17,  5.52it/s, lr=0.00037, step_loss=0.0013907/27/2023 18:09:07 - INFO - __main__ - train loss is 33.88825173676014\n",
      "Steps:  20%|▏| 2971/15000 [24:17<36:10,  5.54it/s, lr=0.00037, step_loss=0.0119]07/27/2023 18:09:07 - INFO - __main__ - train loss is 33.908311979845166\n",
      "Steps:  20%|▏| 2972/15000 [24:18<36:06,  5.55it/s, lr=0.00037, step_loss=0.0201]07/27/2023 18:09:07 - INFO - __main__ - train loss is 34.31671585328877\n",
      "Steps:  20%|▍ | 2973/15000 [24:18<36:20,  5.52it/s, lr=0.00037, step_loss=0.408]07/27/2023 18:09:08 - INFO - __main__ - train loss is 34.32162141893059\n",
      "Steps:  20%|▏| 2974/15000 [24:18<36:11,  5.54it/s, lr=0.00037, step_loss=0.0049107/27/2023 18:09:08 - INFO - __main__ - train loss is 34.33768617454916\n",
      "Steps:  20%|▏| 2975/15000 [24:18<36:07,  5.55it/s, lr=0.00037, step_loss=0.0161]07/27/2023 18:09:08 - INFO - __main__ - train loss is 34.54863961879164\n",
      "Steps:  20%|▍ | 2976/15000 [24:18<36:04,  5.56it/s, lr=0.00037, step_loss=0.211]07/27/2023 18:09:08 - INFO - __main__ - train loss is 34.563189967535436\n",
      "Steps:  20%|▏| 2977/15000 [24:18<36:03,  5.56it/s, lr=0.000371, step_loss=0.014607/27/2023 18:09:08 - INFO - __main__ - train loss is 34.63470578100532\n",
      "Steps:  20%|▏| 2978/15000 [24:19<36:00,  5.56it/s, lr=0.000371, step_loss=0.071507/27/2023 18:09:09 - INFO - __main__ - train loss is 35.41091477777809\n",
      "Steps:  20%|▏| 2979/15000 [24:19<36:18,  5.52it/s, lr=0.000371, step_loss=0.776]07/27/2023 18:09:09 - INFO - __main__ - train loss is 35.97438263799995\n",
      "Steps:  20%|▏| 2980/15000 [24:19<36:10,  5.54it/s, lr=0.000371, step_loss=0.563]07/27/2023 18:09:09 - INFO - __main__ - train loss is 36.10953628923744\n",
      "Steps:  20%|▏| 2981/15000 [24:19<36:20,  5.51it/s, lr=0.000371, step_loss=0.135]07/27/2023 18:09:09 - INFO - __main__ - train loss is 36.14351013954729\n",
      "Steps:  20%|▏| 2982/15000 [24:19<36:30,  5.49it/s, lr=0.000371, step_loss=0.034]07/27/2023 18:09:09 - INFO - __main__ - train loss is 36.44369331654161\n",
      "Steps:  20%|▌  | 2983/15000 [24:20<36:27,  5.49it/s, lr=0.000371, step_loss=0.3]07/27/2023 18:09:09 - INFO - __main__ - train loss is 36.58546294923872\n",
      "Steps:  20%|▏| 2984/15000 [24:20<36:46,  5.45it/s, lr=0.000371, step_loss=0.142]07/27/2023 18:09:10 - INFO - __main__ - train loss is 36.93554728385061\n",
      "Steps:  20%|▍ | 2985/15000 [24:20<36:36,  5.47it/s, lr=0.000372, step_loss=0.35]07/27/2023 18:09:10 - INFO - __main__ - train loss is 36.9756337357685\n",
      "Steps:  20%|▏| 2986/15000 [24:20<36:22,  5.50it/s, lr=0.000372, step_loss=0.040107/27/2023 18:09:10 - INFO - __main__ - train loss is 37.000154671259224\n",
      "Steps:  20%|▏| 2987/15000 [24:20<36:13,  5.53it/s, lr=0.000372, step_loss=0.024507/27/2023 18:09:10 - INFO - __main__ - train loss is 37.2226074161008\n",
      "Steps:  20%|▏| 2988/15000 [24:20<36:11,  5.53it/s, lr=0.000372, step_loss=0.222]07/27/2023 18:09:10 - INFO - __main__ - train loss is 37.6657691122964\n",
      "Steps:  20%|▏| 2989/15000 [24:21<36:05,  5.55it/s, lr=0.000372, step_loss=0.443]07/27/2023 18:09:11 - INFO - __main__ - train loss is 37.66724292677827\n",
      "Steps:  20%|▏| 2990/15000 [24:21<36:01,  5.56it/s, lr=0.000372, step_loss=0.001407/27/2023 18:09:11 - INFO - __main__ - train loss is 37.69528421317227\n",
      "Steps:  20%|▏| 2991/15000 [24:21<35:58,  5.56it/s, lr=0.000372, step_loss=0.028]07/27/2023 18:09:11 - INFO - __main__ - train loss is 37.721379227237776\n",
      "Steps:  20%|▏| 2992/15000 [24:21<35:56,  5.57it/s, lr=0.000372, step_loss=0.026107/27/2023 18:09:11 - INFO - __main__ - train loss is 37.92743355710991\n",
      "Steps:  20%|▏| 2993/15000 [24:21<35:54,  5.57it/s, lr=0.000373, step_loss=0.206]07/27/2023 18:09:11 - INFO - __main__ - train loss is 37.97512102802284\n",
      "Steps:  20%|▏| 2994/15000 [24:22<35:51,  5.58it/s, lr=0.000373, step_loss=0.047707/27/2023 18:09:11 - INFO - __main__ - train loss is 38.04868209292181\n",
      "Steps:  20%|▏| 2995/15000 [24:22<35:51,  5.58it/s, lr=0.000373, step_loss=0.073607/27/2023 18:09:12 - INFO - __main__ - train loss is 38.37589031388052\n",
      "Steps:  20%|▏| 2996/15000 [24:22<35:50,  5.58it/s, lr=0.000373, step_loss=0.327]07/27/2023 18:09:12 - INFO - __main__ - train loss is 38.40743479062803\n",
      "Steps:  20%|▏| 2997/15000 [24:22<35:50,  5.58it/s, lr=0.000373, step_loss=0.031507/27/2023 18:09:12 - INFO - __main__ - train loss is 38.429750609444454\n",
      "Steps:  20%|▏| 2998/15000 [24:22<35:49,  5.58it/s, lr=0.000373, step_loss=0.022307/27/2023 18:09:12 - INFO - __main__ - train loss is 38.5179311663378\n",
      "Steps:  20%|▏| 2999/15000 [24:22<35:48,  5.59it/s, lr=0.000373, step_loss=0.088207/27/2023 18:09:12 - INFO - __main__ - train loss is 38.61369678680785\n",
      "Steps:  20%|▏| 3000/15000 [24:23<35:47,  5.59it/s, lr=0.000373, step_loss=0.088207/27/2023 18:09:12 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-3000\n",
      "07/27/2023 18:09:12 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:09:12,914] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:09:12,919] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:09:12,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:09:12,925] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:09:12,925] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:09:12,932] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:09:12,932] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:09:12,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:09:12 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-3000/pytorch_model\n",
      "07/27/2023 18:09:12 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-3000/scheduler.bin\n",
      "07/27/2023 18:09:12 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-3000/random_states_0.pkl\n",
      "07/27/2023 18:09:12 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-3000\n",
      "Steps:  20%|▏| 3000/15000 [24:23<35:47,  5.59it/s, lr=0.000373, step_loss=0.095807/27/2023 18:09:13 - INFO - __main__ - train loss is 38.85240078275092\n",
      "Steps:  20%|▏| 3001/15000 [24:23<37:09,  5.38it/s, lr=0.000374, step_loss=0.239]07/27/2023 18:09:13 - INFO - __main__ - train loss is 39.009951072977856\n",
      "Steps:  20%|▏| 3002/15000 [24:23<37:04,  5.39it/s, lr=0.000374, step_loss=0.158]07/27/2023 18:09:13 - INFO - __main__ - train loss is 39.32414211635478\n",
      "Steps:  20%|▏| 3003/15000 [24:23<36:48,  5.43it/s, lr=0.000374, step_loss=0.314]07/27/2023 18:09:13 - INFO - __main__ - train loss is 39.32845133007504\n",
      "Steps:  20%|▏| 3004/15000 [24:23<36:33,  5.47it/s, lr=0.000374, step_loss=0.004307/27/2023 18:09:13 - INFO - __main__ - train loss is 39.367135564098135\n",
      "Steps:  20%|▏| 3005/15000 [24:24<36:19,  5.50it/s, lr=0.000374, step_loss=0.038707/27/2023 18:09:13 - INFO - __main__ - train loss is 39.68657241226174\n",
      "Steps:  20%|▏| 3006/15000 [24:24<36:09,  5.53it/s, lr=0.000374, step_loss=0.319]07/27/2023 18:09:14 - INFO - __main__ - train loss is 39.71746441931464\n",
      "Steps:  20%|▏| 3007/15000 [24:24<36:03,  5.54it/s, lr=0.000374, step_loss=0.030907/27/2023 18:09:14 - INFO - __main__ - train loss is 39.873689549276605\n",
      "Steps:  20%|▏| 3008/15000 [24:24<35:57,  5.56it/s, lr=0.000374, step_loss=0.156]07/27/2023 18:09:14 - INFO - __main__ - train loss is 40.457713620970026\n",
      "Steps:  20%|▏| 3009/15000 [24:24<35:53,  5.57it/s, lr=0.000374, step_loss=0.584]07/27/2023 18:09:14 - INFO - __main__ - train loss is 40.553445326397195\n",
      "Steps:  20%|▏| 3010/15000 [24:24<35:51,  5.57it/s, lr=0.000375, step_loss=0.095707/27/2023 18:09:14 - INFO - __main__ - train loss is 40.56892390199937\n",
      "Steps:  20%|▏| 3011/15000 [24:25<35:49,  5.58it/s, lr=0.000375, step_loss=0.015507/27/2023 18:09:15 - INFO - __main__ - train loss is 40.93938947864808\n",
      "Steps:  20%|▍ | 3012/15000 [24:25<35:47,  5.58it/s, lr=0.000375, step_loss=0.37]07/27/2023 18:09:15 - INFO - __main__ - train loss is 40.951983155915514\n",
      "Steps:  20%|▏| 3013/15000 [24:25<35:46,  5.59it/s, lr=0.000375, step_loss=0.012607/27/2023 18:09:15 - INFO - __main__ - train loss is 40.978753632167354\n",
      "Steps:  20%|▏| 3014/15000 [24:25<35:44,  5.59it/s, lr=0.000375, step_loss=0.026807/27/2023 18:09:15 - INFO - __main__ - train loss is 40.98048850684427\n",
      "Steps:  20%|▏| 3015/15000 [24:25<35:42,  5.59it/s, lr=0.000375, step_loss=0.001707/27/2023 18:09:15 - INFO - __main__ - train loss is 40.99362108646892\n",
      "Steps:  20%|▏| 3016/15000 [24:26<35:40,  5.60it/s, lr=0.000375, step_loss=0.013107/27/2023 18:09:15 - INFO - __main__ - train loss is 41.040351362666115\n",
      "Steps:  20%|▏| 3017/15000 [24:26<35:39,  5.60it/s, lr=0.000376, step_loss=0.046707/27/2023 18:09:16 - INFO - __main__ - train loss is 41.04401049716398\n",
      "Steps:  20%|▏| 3018/15000 [24:26<35:38,  5.60it/s, lr=0.000376, step_loss=0.003607/27/2023 18:09:16 - INFO - __main__ - train loss is 41.1129517625086\n",
      "Steps:  20%|▏| 3019/15000 [24:26<35:38,  5.60it/s, lr=0.000376, step_loss=0.068907/27/2023 18:09:16 - INFO - __main__ - train loss is 41.12085149483755\n",
      "Steps:  20%|▏| 3020/15000 [24:26<35:38,  5.60it/s, lr=0.000376, step_loss=0.007907/27/2023 18:09:16 - INFO - __main__ - train loss is 41.13006429793313\n",
      "Steps:  20%|▏| 3021/15000 [24:26<35:37,  5.60it/s, lr=0.000376, step_loss=0.009207/27/2023 18:09:16 - INFO - __main__ - train loss is 41.13689369568601\n",
      "Steps:  20%|▏| 3022/15000 [24:27<35:37,  5.60it/s, lr=0.000376, step_loss=0.006807/27/2023 18:09:16 - INFO - __main__ - train loss is 41.141582743264735\n",
      "Steps:  20%|▏| 3023/15000 [24:27<35:37,  5.60it/s, lr=0.000376, step_loss=0.004607/27/2023 18:09:17 - INFO - __main__ - train loss is 41.25016881618649\n",
      "Steps:  20%|▏| 3024/15000 [24:27<35:36,  5.61it/s, lr=0.000376, step_loss=0.109]07/27/2023 18:09:17 - INFO - __main__ - train loss is 41.26399981882423\n",
      "Steps:  20%|▏| 3025/15000 [24:27<35:36,  5.60it/s, lr=0.000376, step_loss=0.013807/27/2023 18:09:17 - INFO - __main__ - train loss is 41.628831206820905\n",
      "Steps:  20%|▏| 3026/15000 [24:27<35:36,  5.61it/s, lr=0.000377, step_loss=0.365]07/27/2023 18:09:17 - INFO - __main__ - train loss is 41.63322654366493\n",
      "Steps:  20%|▏| 3027/15000 [24:27<35:36,  5.60it/s, lr=0.000377, step_loss=0.004407/27/2023 18:09:17 - INFO - __main__ - train loss is 41.71636161953211\n",
      "Steps:  20%|▏| 3028/15000 [24:28<35:36,  5.60it/s, lr=0.000377, step_loss=0.083107/27/2023 18:09:18 - INFO - __main__ - train loss is 41.73807103000581\n",
      "Steps:  20%|▏| 3029/15000 [24:28<35:37,  5.60it/s, lr=0.000377, step_loss=0.021707/27/2023 18:09:18 - INFO - __main__ - train loss is 42.0045107062906\n",
      "Steps:  20%|▏| 3030/15000 [24:28<49:00,  4.07it/s, lr=0.000377, step_loss=0.266]07/27/2023 18:09:19 - INFO - __main__ - Per validation step average loss is 0.05143003165721893\n",
      "07/27/2023 18:09:19 - INFO - __main__ - Cumulative validation average loss is 0.05143003165721893\n",
      "07/27/2023 18:09:19 - INFO - __main__ - Per validation step average loss is 0.2246318757534027\n",
      "07/27/2023 18:09:19 - INFO - __main__ - Cumulative validation average loss is 0.27606190741062164\n",
      "07/27/2023 18:09:20 - INFO - __main__ - Per validation step average loss is 0.018944088369607925\n",
      "07/27/2023 18:09:20 - INFO - __main__ - Cumulative validation average loss is 0.29500599578022957\n",
      "07/27/2023 18:09:20 - INFO - __main__ - Per validation step average loss is 0.1121281161904335\n",
      "07/27/2023 18:09:20 - INFO - __main__ - Cumulative validation average loss is 0.40713411197066307\n",
      "07/27/2023 18:09:21 - INFO - __main__ - Per validation step average loss is 0.016944756731390953\n",
      "07/27/2023 18:09:21 - INFO - __main__ - Cumulative validation average loss is 0.424078868702054\n",
      "07/27/2023 18:09:21 - INFO - __main__ - Per validation step average loss is 0.10769055783748627\n",
      "07/27/2023 18:09:21 - INFO - __main__ - Cumulative validation average loss is 0.5317694265395403\n",
      "07/27/2023 18:09:21 - INFO - __main__ - Per validation step average loss is 0.04955979436635971\n",
      "07/27/2023 18:09:21 - INFO - __main__ - Cumulative validation average loss is 0.5813292209059\n",
      "07/27/2023 18:09:22 - INFO - __main__ - Per validation step average loss is 0.190358966588974\n",
      "07/27/2023 18:09:22 - INFO - __main__ - Cumulative validation average loss is 0.771688187494874\n",
      "07/27/2023 18:09:22 - INFO - __main__ - Per validation step average loss is 0.5006381273269653\n",
      "07/27/2023 18:09:22 - INFO - __main__ - Cumulative validation average loss is 1.2723263148218393\n",
      "07/27/2023 18:09:23 - INFO - __main__ - Per validation step average loss is 0.28727445006370544\n",
      "07/27/2023 18:09:23 - INFO - __main__ - Cumulative validation average loss is 1.5596007648855448\n",
      "07/27/2023 18:09:23 - INFO - __main__ - Per validation step average loss is 0.13466596603393555\n",
      "07/27/2023 18:09:23 - INFO - __main__ - Cumulative validation average loss is 1.6942667309194803\n",
      "07/27/2023 18:09:23 - INFO - __main__ - Per validation step average loss is 0.28043925762176514\n",
      "07/27/2023 18:09:23 - INFO - __main__ - Cumulative validation average loss is 1.9747059885412455\n",
      "07/27/2023 18:09:24 - INFO - __main__ - Per validation step average loss is 0.03477758169174194\n",
      "07/27/2023 18:09:24 - INFO - __main__ - Cumulative validation average loss is 2.0094835702329874\n",
      "07/27/2023 18:09:24 - INFO - __main__ - Per validation step average loss is 0.283132404088974\n",
      "07/27/2023 18:09:24 - INFO - __main__ - Cumulative validation average loss is 2.2926159743219614\n",
      "07/27/2023 18:09:25 - INFO - __main__ - Per validation step average loss is 0.0360066294670105\n",
      "07/27/2023 18:09:25 - INFO - __main__ - Cumulative validation average loss is 2.328622603788972\n",
      "07/27/2023 18:09:25 - INFO - __main__ - Per validation step average loss is 0.15782791376113892\n",
      "07/27/2023 18:09:25 - INFO - __main__ - Cumulative validation average loss is 2.486450517550111\n",
      "07/27/2023 18:09:25 - INFO - __main__ - Per validation step average loss is 0.004732058383524418\n",
      "07/27/2023 18:09:25 - INFO - __main__ - Cumulative validation average loss is 2.4911825759336352\n",
      "07/27/2023 18:09:26 - INFO - __main__ - Per validation step average loss is 0.001961087342351675\n",
      "07/27/2023 18:09:26 - INFO - __main__ - Cumulative validation average loss is 2.493143663275987\n",
      "07/27/2023 18:09:26 - INFO - __main__ - Per validation step average loss is 0.2340397834777832\n",
      "07/27/2023 18:09:26 - INFO - __main__ - Cumulative validation average loss is 2.72718344675377\n",
      "07/27/2023 18:09:27 - INFO - __main__ - Per validation step average loss is 0.5056074857711792\n",
      "07/27/2023 18:09:27 - INFO - __main__ - Cumulative validation average loss is 3.2327909325249493\n",
      "07/27/2023 18:09:27 - INFO - __main__ - Per validation step average loss is 0.00932980515062809\n",
      "07/27/2023 18:09:27 - INFO - __main__ - Cumulative validation average loss is 3.2421207376755774\n",
      "07/27/2023 18:09:28 - INFO - __main__ - Per validation step average loss is 0.09447790682315826\n",
      "07/27/2023 18:09:28 - INFO - __main__ - Cumulative validation average loss is 3.3365986444987357\n",
      "07/27/2023 18:09:28 - INFO - __main__ - Per validation step average loss is 0.009021805599331856\n",
      "07/27/2023 18:09:28 - INFO - __main__ - Cumulative validation average loss is 3.3456204500980675\n",
      "07/27/2023 18:09:28 - INFO - __main__ - Per validation step average loss is 0.4060755968093872\n",
      "07/27/2023 18:09:28 - INFO - __main__ - Cumulative validation average loss is 3.7516960469074547\n",
      "07/27/2023 18:09:29 - INFO - __main__ - Per validation step average loss is 0.002573817502707243\n",
      "07/27/2023 18:09:29 - INFO - __main__ - Cumulative validation average loss is 3.754269864410162\n",
      "07/27/2023 18:09:29 - INFO - __main__ - Per validation step average loss is 0.19261693954467773\n",
      "07/27/2023 18:09:29 - INFO - __main__ - Cumulative validation average loss is 3.9468868039548397\n",
      "07/27/2023 18:09:30 - INFO - __main__ - Per validation step average loss is 0.24179290235042572\n",
      "07/27/2023 18:09:30 - INFO - __main__ - Cumulative validation average loss is 4.188679706305265\n",
      "07/27/2023 18:09:30 - INFO - __main__ - Per validation step average loss is 0.1422579288482666\n",
      "07/27/2023 18:09:30 - INFO - __main__ - Cumulative validation average loss is 4.330937635153532\n",
      "07/27/2023 18:09:30 - INFO - __main__ - Per validation step average loss is 0.040236182510852814\n",
      "07/27/2023 18:09:30 - INFO - __main__ - Cumulative validation average loss is 4.371173817664385\n",
      "07/27/2023 18:09:31 - INFO - __main__ - Per validation step average loss is 0.167735293507576\n",
      "07/27/2023 18:09:31 - INFO - __main__ - Cumulative validation average loss is 4.538909111171961\n",
      "07/27/2023 18:09:31 - INFO - __main__ - Per validation step average loss is 0.31552091240882874\n",
      "07/27/2023 18:09:31 - INFO - __main__ - Cumulative validation average loss is 4.85443002358079\n",
      "07/27/2023 18:09:32 - INFO - __main__ - Per validation step average loss is 0.13336512446403503\n",
      "07/27/2023 18:09:32 - INFO - __main__ - Cumulative validation average loss is 4.987795148044825\n",
      "07/27/2023 18:09:32 - INFO - __main__ - Per validation step average loss is 0.0012430606875568628\n",
      "07/27/2023 18:09:32 - INFO - __main__ - Cumulative validation average loss is 4.9890382087323815\n",
      "07/27/2023 18:09:32 - INFO - __main__ - Per validation step average loss is 0.021150998771190643\n",
      "07/27/2023 18:09:32 - INFO - __main__ - Cumulative validation average loss is 5.010189207503572\n",
      "07/27/2023 18:09:33 - INFO - __main__ - Per validation step average loss is 0.10334599018096924\n",
      "07/27/2023 18:09:33 - INFO - __main__ - Cumulative validation average loss is 5.113535197684541\n",
      "07/27/2023 18:09:33 - INFO - __main__ - Per validation step average loss is 0.010686194524168968\n",
      "07/27/2023 18:09:33 - INFO - __main__ - Cumulative validation average loss is 5.12422139220871\n",
      "07/27/2023 18:09:34 - INFO - __main__ - Per validation step average loss is 0.125775545835495\n",
      "07/27/2023 18:09:34 - INFO - __main__ - Cumulative validation average loss is 5.249996938044205\n",
      "07/27/2023 18:09:34 - INFO - __main__ - Per validation step average loss is 0.05184873193502426\n",
      "07/27/2023 18:09:34 - INFO - __main__ - Cumulative validation average loss is 5.30184566997923\n",
      "07/27/2023 18:09:35 - INFO - __main__ - Per validation step average loss is 0.06505247950553894\n",
      "07/27/2023 18:09:35 - INFO - __main__ - Cumulative validation average loss is 5.3668981494847685\n",
      "07/27/2023 18:09:35 - INFO - __main__ - Per validation step average loss is 0.049236297607421875\n",
      "07/27/2023 18:09:35 - INFO - __main__ - Cumulative validation average loss is 5.41613444709219\n",
      "07/27/2023 18:09:35 - INFO - __main__ - Per validation step average loss is 0.3232985734939575\n",
      "07/27/2023 18:09:35 - INFO - __main__ - Cumulative validation average loss is 5.739433020586148\n",
      "07/27/2023 18:09:36 - INFO - __main__ - Per validation step average loss is 0.551293134689331\n",
      "07/27/2023 18:09:36 - INFO - __main__ - Cumulative validation average loss is 6.290726155275479\n",
      "07/27/2023 18:09:36 - INFO - __main__ - Per validation step average loss is 0.03475170582532883\n",
      "07/27/2023 18:09:36 - INFO - __main__ - Cumulative validation average loss is 6.325477861100808\n",
      "07/27/2023 18:09:37 - INFO - __main__ - Per validation step average loss is 0.00329681602306664\n",
      "07/27/2023 18:09:37 - INFO - __main__ - Cumulative validation average loss is 6.328774677123874\n",
      "07/27/2023 18:09:37 - INFO - __main__ - Per validation step average loss is 0.015095395967364311\n",
      "07/27/2023 18:09:37 - INFO - __main__ - Cumulative validation average loss is 6.343870073091239\n",
      "07/27/2023 18:09:37 - INFO - __main__ - Per validation step average loss is 0.0011023584520444274\n",
      "07/27/2023 18:09:37 - INFO - __main__ - Cumulative validation average loss is 6.344972431543283\n",
      "07/27/2023 18:09:38 - INFO - __main__ - Per validation step average loss is 0.31074023246765137\n",
      "07/27/2023 18:09:38 - INFO - __main__ - Cumulative validation average loss is 6.6557126640109345\n",
      "07/27/2023 18:09:38 - INFO - __main__ - Per validation step average loss is 0.39427947998046875\n",
      "07/27/2023 18:09:38 - INFO - __main__ - Cumulative validation average loss is 7.049992143991403\n",
      "07/27/2023 18:09:39 - INFO - __main__ - Per validation step average loss is 0.4615609645843506\n",
      "07/27/2023 18:09:39 - INFO - __main__ - Cumulative validation average loss is 7.511553108575754\n",
      "07/27/2023 18:09:39 - INFO - __main__ - Per validation step average loss is 0.0173720084130764\n",
      "07/27/2023 18:09:39 - INFO - __main__ - Cumulative validation average loss is 7.52892511698883\n",
      "07/27/2023 18:09:39 - INFO - __main__ - Per validation step average loss is 0.5207452774047852\n",
      "07/27/2023 18:09:39 - INFO - __main__ - Cumulative validation average loss is 8.049670394393615\n",
      "07/27/2023 18:09:40 - INFO - __main__ - Per validation step average loss is 0.11633431911468506\n",
      "07/27/2023 18:09:40 - INFO - __main__ - Cumulative validation average loss is 8.1660047135083\n",
      "07/27/2023 18:09:40 - INFO - __main__ - Per validation step average loss is 0.05098846182227135\n",
      "07/27/2023 18:09:40 - INFO - __main__ - Cumulative validation average loss is 8.216993175330572\n",
      "07/27/2023 18:09:41 - INFO - __main__ - Per validation step average loss is 0.06481588631868362\n",
      "07/27/2023 18:09:41 - INFO - __main__ - Cumulative validation average loss is 8.281809061649255\n",
      "07/27/2023 18:09:41 - INFO - __main__ - Per validation step average loss is 0.07863913476467133\n",
      "07/27/2023 18:09:41 - INFO - __main__ - Cumulative validation average loss is 8.360448196413927\n",
      "07/27/2023 18:09:42 - INFO - __main__ - Per validation step average loss is 0.006220370065420866\n",
      "07/27/2023 18:09:42 - INFO - __main__ - Cumulative validation average loss is 8.366668566479348\n",
      "07/27/2023 18:09:42 - INFO - __main__ - Per validation step average loss is 0.06400419771671295\n",
      "07/27/2023 18:09:42 - INFO - __main__ - Cumulative validation average loss is 8.43067276419606\n",
      "07/27/2023 18:09:42 - INFO - __main__ - Per validation step average loss is 0.002295401645824313\n",
      "07/27/2023 18:09:42 - INFO - __main__ - Cumulative validation average loss is 8.432968165841885\n",
      "07/27/2023 18:09:43 - INFO - __main__ - Per validation step average loss is 0.0022613201290369034\n",
      "07/27/2023 18:09:43 - INFO - __main__ - Cumulative validation average loss is 8.435229485970922\n",
      "07/27/2023 18:09:43 - INFO - __main__ - Per validation step average loss is 0.3767887353897095\n",
      "07/27/2023 18:09:43 - INFO - __main__ - Cumulative validation average loss is 8.812018221360631\n",
      "07/27/2023 18:09:44 - INFO - __main__ - Per validation step average loss is 0.2589067220687866\n",
      "07/27/2023 18:09:44 - INFO - __main__ - Cumulative validation average loss is 9.070924943429418\n",
      "07/27/2023 18:09:44 - INFO - __main__ - Per validation step average loss is 0.295535147190094\n",
      "07/27/2023 18:09:44 - INFO - __main__ - Cumulative validation average loss is 9.366460090619512\n",
      "07/27/2023 18:09:44 - INFO - __main__ - Per validation step average loss is 0.03799381107091904\n",
      "07/27/2023 18:09:44 - INFO - __main__ - Cumulative validation average loss is 9.404453901690431\n",
      "07/27/2023 18:09:45 - INFO - __main__ - Per validation step average loss is 0.05986775830388069\n",
      "07/27/2023 18:09:45 - INFO - __main__ - Cumulative validation average loss is 9.464321659994312\n",
      "07/27/2023 18:09:45 - INFO - __main__ - Per validation step average loss is 0.013631300069391727\n",
      "07/27/2023 18:09:45 - INFO - __main__ - Cumulative validation average loss is 9.477952960063703\n",
      "07/27/2023 18:09:46 - INFO - __main__ - Per validation step average loss is 0.3684028387069702\n",
      "07/27/2023 18:09:46 - INFO - __main__ - Cumulative validation average loss is 9.846355798770674\n",
      "07/27/2023 18:09:46 - INFO - __main__ - Per validation step average loss is 0.5932427048683167\n",
      "07/27/2023 18:09:46 - INFO - __main__ - Cumulative validation average loss is 10.43959850363899\n",
      "07/27/2023 18:09:46 - INFO - __main__ - Per validation step average loss is 0.01639978587627411\n",
      "07/27/2023 18:09:46 - INFO - __main__ - Cumulative validation average loss is 10.455998289515264\n",
      "07/27/2023 18:09:47 - INFO - __main__ - Per validation step average loss is 0.2900387942790985\n",
      "07/27/2023 18:09:47 - INFO - __main__ - Cumulative validation average loss is 10.746037083794363\n",
      "07/27/2023 18:09:47 - INFO - __main__ - Per validation step average loss is 0.033979617059230804\n",
      "07/27/2023 18:09:47 - INFO - __main__ - Cumulative validation average loss is 10.780016700853594\n",
      "07/27/2023 18:09:48 - INFO - __main__ - Per validation step average loss is 0.015197455883026123\n",
      "07/27/2023 18:09:48 - INFO - __main__ - Cumulative validation average loss is 10.79521415673662\n",
      "07/27/2023 18:09:48 - INFO - __main__ - Per validation step average loss is 0.011745298281311989\n",
      "07/27/2023 18:09:48 - INFO - __main__ - Cumulative validation average loss is 10.806959455017932\n",
      "07/27/2023 18:09:48 - INFO - __main__ - Per validation step average loss is 0.06746970862150192\n",
      "07/27/2023 18:09:48 - INFO - __main__ - Cumulative validation average loss is 10.874429163639434\n",
      "07/27/2023 18:09:49 - INFO - __main__ - Per validation step average loss is 0.03271020948886871\n",
      "07/27/2023 18:09:49 - INFO - __main__ - Cumulative validation average loss is 10.907139373128302\n",
      "07/27/2023 18:09:49 - INFO - __main__ - Per validation step average loss is 0.05481772869825363\n",
      "07/27/2023 18:09:49 - INFO - __main__ - Cumulative validation average loss is 10.961957101826556\n",
      "07/27/2023 18:09:50 - INFO - __main__ - Per validation step average loss is 0.04039622098207474\n",
      "07/27/2023 18:09:50 - INFO - __main__ - Cumulative validation average loss is 11.00235332280863\n",
      "07/27/2023 18:09:50 - INFO - __main__ - Per validation step average loss is 0.9143730401992798\n",
      "07/27/2023 18:09:50 - INFO - __main__ - Cumulative validation average loss is 11.91672636300791\n",
      "07/27/2023 18:09:51 - INFO - __main__ - Per validation step average loss is 0.40275251865386963\n",
      "07/27/2023 18:09:51 - INFO - __main__ - Cumulative validation average loss is 12.31947888166178\n",
      "07/27/2023 18:09:51 - INFO - __main__ - Per validation step average loss is 0.19481906294822693\n",
      "07/27/2023 18:09:51 - INFO - __main__ - Cumulative validation average loss is 12.514297944610007\n",
      "07/27/2023 18:09:51 - INFO - __main__ - Average validation loss for Epoch 9 is 0.15840883474189882\n",
      "07/27/2023 18:09:51 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:10:48 - INFO - __main__ - Starting epoch 10\n",
      "07/27/2023 18:10:49 - INFO - __main__ - train loss is 0.4521159529685974\n",
      "Steps:  20%|▏| 3031/15000 [26:00<91:40:19, 27.57s/it, lr=0.000377, step_loss=0.407/27/2023 18:10:50 - INFO - __main__ - train loss is 0.47405824810266495\n",
      "Steps:  20%|▏| 3032/15000 [26:00<64:40:04, 19.45s/it, lr=0.000377, step_loss=0.007/27/2023 18:10:50 - INFO - __main__ - train loss is 0.7888591662049294\n",
      "Steps:  20%|▏| 3033/15000 [26:01<45:46:00, 13.77s/it, lr=0.000378, step_loss=0.307/27/2023 18:10:51 - INFO - __main__ - train loss is 1.1005204990506172\n",
      "Steps:  20%|▏| 3034/15000 [26:01<32:31:57,  9.79s/it, lr=0.000378, step_loss=0.307/27/2023 18:10:51 - INFO - __main__ - train loss is 1.1668541803956032\n",
      "Steps:  20%|▏| 3035/15000 [26:02<23:16:22,  7.00s/it, lr=0.000378, step_loss=0.007/27/2023 18:10:52 - INFO - __main__ - train loss is 1.245022177696228\n",
      "Steps:  20%|▏| 3036/15000 [26:02<16:47:30,  5.05s/it, lr=0.000378, step_loss=0.007/27/2023 18:10:52 - INFO - __main__ - train loss is 1.5230609774589539\n",
      "Steps:  20%|▏| 3037/15000 [26:03<12:16:33,  3.69s/it, lr=0.000378, step_loss=0.207/27/2023 18:10:53 - INFO - __main__ - train loss is 1.710439220070839\n",
      "Steps:  20%|▏| 3038/15000 [26:03<9:13:28,  2.78s/it, lr=0.000378, step_loss=0.1807/27/2023 18:10:53 - INFO - __main__ - train loss is 1.885808065533638\n",
      "Steps:  20%|▏| 3039/15000 [26:04<6:58:39,  2.10s/it, lr=0.000378, step_loss=0.1707/27/2023 18:10:54 - INFO - __main__ - train loss is 2.104765012860298\n",
      "Steps:  20%|▏| 3040/15000 [26:04<5:23:19,  1.62s/it, lr=0.000378, step_loss=0.2107/27/2023 18:10:54 - INFO - __main__ - train loss is 2.150974929332733\n",
      "Steps:  20%|▏| 3041/15000 [26:05<4:16:38,  1.29s/it, lr=0.000378, step_loss=0.0407/27/2023 18:10:55 - INFO - __main__ - train loss is 2.197815380990505\n",
      "Steps:  20%|▏| 3042/15000 [26:05<3:29:51,  1.05s/it, lr=0.000379, step_loss=0.0407/27/2023 18:10:55 - INFO - __main__ - train loss is 2.2707734033465385\n",
      "Steps:  20%|▏| 3043/15000 [26:06<2:57:07,  1.13it/s, lr=0.000379, step_loss=0.0707/27/2023 18:10:56 - INFO - __main__ - train loss is 2.276225703768432\n",
      "Steps:  20%|▏| 3044/15000 [26:06<2:34:29,  1.29it/s, lr=0.000379, step_loss=0.0007/27/2023 18:10:57 - INFO - __main__ - train loss is 2.3089343262836337\n",
      "Steps:  20%|▏| 3045/15000 [26:07<2:18:22,  1.44it/s, lr=0.000379, step_loss=0.0307/27/2023 18:10:57 - INFO - __main__ - train loss is 2.4916826440021396\n",
      "Steps:  20%|▏| 3046/15000 [26:07<2:06:55,  1.57it/s, lr=0.000379, step_loss=0.1807/27/2023 18:10:58 - INFO - __main__ - train loss is 2.496358036529273\n",
      "Steps:  20%|▏| 3047/15000 [26:08<1:59:02,  1.67it/s, lr=0.000379, step_loss=0.0007/27/2023 18:10:58 - INFO - __main__ - train loss is 2.5141548509709537\n",
      "Steps:  20%|▏| 3048/15000 [26:08<1:53:47,  1.75it/s, lr=0.000379, step_loss=0.0107/27/2023 18:10:59 - INFO - __main__ - train loss is 2.9130892450921237\n",
      "Steps:  20%|▏| 3049/15000 [26:09<1:50:02,  1.81it/s, lr=0.00038, step_loss=0.39907/27/2023 18:10:59 - INFO - __main__ - train loss is 3.157448738347739\n",
      "Steps:  20%|▏| 3050/15000 [26:09<1:47:18,  1.86it/s, lr=0.00038, step_loss=0.24407/27/2023 18:11:00 - INFO - __main__ - train loss is 4.0817461903207\n",
      "Steps:  20%|▏| 3051/15000 [26:10<1:45:31,  1.89it/s, lr=0.00038, step_loss=0.92407/27/2023 18:11:00 - INFO - __main__ - train loss is 4.083040009951219\n",
      "Steps:  20%|▏| 3052/15000 [26:10<1:44:08,  1.91it/s, lr=0.00038, step_loss=0.00107/27/2023 18:11:01 - INFO - __main__ - train loss is 4.087799099041149\n",
      "Steps:  20%|▏| 3053/15000 [26:11<1:43:18,  1.93it/s, lr=0.00038, step_loss=0.00407/27/2023 18:11:01 - INFO - __main__ - train loss is 4.227619570447132\n",
      "Steps:  20%|▏| 3054/15000 [26:11<1:42:37,  1.94it/s, lr=0.00038, step_loss=0.14]07/27/2023 18:11:02 - INFO - __main__ - train loss is 4.229976881295443\n",
      "Steps:  20%|▏| 3055/15000 [26:12<1:41:54,  1.95it/s, lr=0.00038, step_loss=0.00207/27/2023 18:11:02 - INFO - __main__ - train loss is 4.249796552583575\n",
      "Steps:  20%|▏| 3056/15000 [26:12<1:41:43,  1.96it/s, lr=0.00038, step_loss=0.01907/27/2023 18:11:03 - INFO - __main__ - train loss is 4.694704128429294\n",
      "Steps:  20%|▏| 3057/15000 [26:13<1:41:19,  1.96it/s, lr=0.000381, step_loss=0.4407/27/2023 18:11:03 - INFO - __main__ - train loss is 4.698125218274072\n",
      "Steps:  20%|▏| 3058/15000 [26:13<1:40:42,  1.98it/s, lr=0.000381, step_loss=0.0007/27/2023 18:11:04 - INFO - __main__ - train loss is 4.727227886440232\n",
      "Steps:  20%|▏| 3059/15000 [26:14<1:40:48,  1.97it/s, lr=0.000381, step_loss=0.0207/27/2023 18:11:04 - INFO - __main__ - train loss is 5.1362586815375835\n",
      "Steps:  20%|▏| 3060/15000 [26:14<1:40:38,  1.98it/s, lr=0.000381, step_loss=0.4007/27/2023 18:11:05 - INFO - __main__ - train loss is 5.204917972208932\n",
      "Steps:  20%|▏| 3061/15000 [26:15<1:40:30,  1.98it/s, lr=0.000381, step_loss=0.0607/27/2023 18:11:05 - INFO - __main__ - train loss is 5.206876147305593\n",
      "Steps:  20%|▏| 3062/15000 [26:15<1:40:29,  1.98it/s, lr=0.000381, step_loss=0.0007/27/2023 18:11:06 - INFO - __main__ - train loss is 5.288182753836736\n",
      "Steps:  20%|▏| 3063/15000 [26:16<1:40:27,  1.98it/s, lr=0.000381, step_loss=0.0807/27/2023 18:11:06 - INFO - __main__ - train loss is 5.364517766749486\n",
      "Steps:  20%|▏| 3064/15000 [26:16<1:41:12,  1.97it/s, lr=0.000381, step_loss=0.0707/27/2023 18:11:07 - INFO - __main__ - train loss is 5.527349609648809\n",
      "Steps:  20%|▏| 3065/15000 [26:17<1:48:49,  1.83it/s, lr=0.000382, step_loss=0.1607/27/2023 18:11:07 - INFO - __main__ - train loss is 5.54618939734064\n",
      "Steps:  20%|▏| 3066/15000 [26:18<1:47:49,  1.84it/s, lr=0.000382, step_loss=0.0107/27/2023 18:11:08 - INFO - __main__ - train loss is 5.9024474618490785\n",
      "Steps:  20%|▏| 3067/15000 [26:18<1:46:06,  1.87it/s, lr=0.000382, step_loss=0.3507/27/2023 18:11:08 - INFO - __main__ - train loss is 5.914963193004951\n",
      "Steps:  20%|▏| 3068/15000 [26:19<1:44:24,  1.90it/s, lr=0.000382, step_loss=0.0107/27/2023 18:11:09 - INFO - __main__ - train loss is 5.958365648752078\n",
      "Steps:  20%|▏| 3069/15000 [26:19<1:43:07,  1.93it/s, lr=0.000382, step_loss=0.0407/27/2023 18:11:09 - INFO - __main__ - train loss is 6.075727581745014\n",
      "Steps:  20%|▏| 3070/15000 [26:20<1:42:26,  1.94it/s, lr=0.000382, step_loss=0.1107/27/2023 18:11:10 - INFO - __main__ - train loss is 6.078578512882814\n",
      "Steps:  20%|▏| 3071/15000 [26:20<1:41:34,  1.96it/s, lr=0.000382, step_loss=0.0007/27/2023 18:11:10 - INFO - __main__ - train loss is 6.335283290361986\n",
      "Steps:  20%|▏| 3072/15000 [26:21<1:41:06,  1.97it/s, lr=0.000382, step_loss=0.2507/27/2023 18:11:11 - INFO - __main__ - train loss is 6.357351511484012\n",
      "Steps:  20%|▏| 3073/15000 [26:21<1:41:49,  1.95it/s, lr=0.000383, step_loss=0.0207/27/2023 18:11:11 - INFO - __main__ - train loss is 6.7310951051767915\n",
      "Steps:  20%|▏| 3074/15000 [26:22<1:41:11,  1.96it/s, lr=0.000383, step_loss=0.3707/27/2023 18:11:12 - INFO - __main__ - train loss is 6.776730295037851\n",
      "Steps:  20%|▏| 3075/15000 [26:22<1:40:57,  1.97it/s, lr=0.000383, step_loss=0.0407/27/2023 18:11:12 - INFO - __main__ - train loss is 6.875392671441659\n",
      "Steps:  21%|▏| 3076/15000 [26:23<1:40:36,  1.98it/s, lr=0.000383, step_loss=0.0907/27/2023 18:11:13 - INFO - __main__ - train loss is 6.9443996956106275\n",
      "Steps:  21%|▏| 3077/15000 [26:23<1:40:21,  1.98it/s, lr=0.000383, step_loss=0.0607/27/2023 18:11:13 - INFO - __main__ - train loss is 7.466092210030183\n",
      "Steps:  21%|▏| 3078/15000 [26:24<1:40:18,  1.98it/s, lr=0.000383, step_loss=0.5207/27/2023 18:11:14 - INFO - __main__ - train loss is 7.468250155448914\n",
      "Steps:  21%|▏| 3079/15000 [26:24<1:40:09,  1.98it/s, lr=0.000383, step_loss=0.0007/27/2023 18:11:14 - INFO - __main__ - train loss is 7.87899050116539\n",
      "Steps:  21%|▏| 3080/15000 [26:25<1:40:13,  1.98it/s, lr=0.000383, step_loss=0.4107/27/2023 18:11:15 - INFO - __main__ - train loss is 8.302302688360214\n",
      "Steps:  21%|▏| 3081/15000 [26:25<1:39:58,  1.99it/s, lr=0.000383, step_loss=0.4207/27/2023 18:11:15 - INFO - __main__ - train loss is 8.310949905775487\n",
      "Steps:  21%|▏| 3082/15000 [26:26<1:39:46,  1.99it/s, lr=0.000384, step_loss=0.0007/27/2023 18:11:16 - INFO - __main__ - train loss is 8.678723885677755\n",
      "Steps:  21%|▏| 3083/15000 [26:26<1:39:49,  1.99it/s, lr=0.000384, step_loss=0.3607/27/2023 18:11:16 - INFO - __main__ - train loss is 9.065835698507726\n",
      "Steps:  21%|▏| 3084/15000 [26:27<1:39:32,  2.00it/s, lr=0.000384, step_loss=0.3807/27/2023 18:11:17 - INFO - __main__ - train loss is 9.087138590402901\n",
      "Steps:  21%|▏| 3085/15000 [26:27<1:39:39,  1.99it/s, lr=0.000384, step_loss=0.0207/27/2023 18:11:17 - INFO - __main__ - train loss is 9.088646488729864\n",
      "Steps:  21%|▏| 3086/15000 [26:28<1:39:41,  1.99it/s, lr=0.000384, step_loss=0.0007/27/2023 18:11:18 - INFO - __main__ - train loss is 9.105494181159884\n",
      "Steps:  21%|▏| 3087/15000 [26:28<1:40:20,  1.98it/s, lr=0.000384, step_loss=0.0107/27/2023 18:11:18 - INFO - __main__ - train loss is 9.108317427802831\n",
      "Steps:  21%|▏| 3088/15000 [26:29<1:40:32,  1.97it/s, lr=0.000384, step_loss=0.0007/27/2023 18:11:19 - INFO - __main__ - train loss is 9.468716048169881\n",
      "Steps:  21%|▏| 3089/15000 [26:29<1:40:11,  1.98it/s, lr=0.000385, step_loss=0.3607/27/2023 18:11:19 - INFO - __main__ - train loss is 9.772234641481191\n",
      "Steps:  21%|▏| 3090/15000 [26:30<1:40:03,  1.98it/s, lr=0.000385, step_loss=0.3007/27/2023 18:11:20 - INFO - __main__ - train loss is 10.024171673227102\n",
      "Steps:  21%|▏| 3091/15000 [26:30<1:40:05,  1.98it/s, lr=0.000385, step_loss=0.2507/27/2023 18:11:20 - INFO - __main__ - train loss is 10.105924971867353\n",
      "Steps:  21%|▏| 3092/15000 [26:31<1:41:35,  1.95it/s, lr=0.000385, step_loss=0.0807/27/2023 18:11:21 - INFO - __main__ - train loss is 10.107269724830985\n",
      "Steps:  21%|▏| 3093/15000 [26:31<1:44:52,  1.89it/s, lr=0.000385, step_loss=0.0007/27/2023 18:11:22 - INFO - __main__ - train loss is 10.401406517252326\n",
      "Steps:  21%|▏| 3094/15000 [26:32<1:45:58,  1.87it/s, lr=0.000385, step_loss=0.2907/27/2023 18:11:22 - INFO - __main__ - train loss is 10.566405972465873\n",
      "Steps:  21%|▏| 3095/15000 [26:32<1:44:57,  1.89it/s, lr=0.000385, step_loss=0.1607/27/2023 18:11:23 - INFO - __main__ - train loss is 10.71569605730474\n",
      "Steps:  21%|▏| 3096/15000 [26:33<1:44:14,  1.90it/s, lr=0.000385, step_loss=0.1407/27/2023 18:11:23 - INFO - __main__ - train loss is 10.752179643139243\n",
      "Steps:  21%|▏| 3097/15000 [26:33<1:42:50,  1.93it/s, lr=0.000385, step_loss=0.0307/27/2023 18:11:24 - INFO - __main__ - train loss is 11.025987377390265\n",
      "Steps:  21%|▏| 3098/15000 [26:34<1:42:34,  1.93it/s, lr=0.000386, step_loss=0.2707/27/2023 18:11:24 - INFO - __main__ - train loss is 11.529384126886725\n",
      "Steps:  21%|▏| 3099/15000 [26:34<1:41:47,  1.95it/s, lr=0.000386, step_loss=0.5007/27/2023 18:11:25 - INFO - __main__ - train loss is 11.800657561048865\n",
      "Steps:  21%|▏| 3100/15000 [26:35<1:41:20,  1.96it/s, lr=0.000386, step_loss=0.2707/27/2023 18:11:25 - INFO - __main__ - train loss is 11.837687714025378\n",
      "Steps:  21%|▏| 3101/15000 [26:35<1:41:24,  1.96it/s, lr=0.000386, step_loss=0.0307/27/2023 18:11:26 - INFO - __main__ - train loss is 12.000927640125155\n",
      "Steps:  21%|▏| 3102/15000 [26:36<1:41:01,  1.96it/s, lr=0.000386, step_loss=0.1607/27/2023 18:11:26 - INFO - __main__ - train loss is 12.006343235261738\n",
      "Steps:  21%|▏| 3103/15000 [26:36<1:40:36,  1.97it/s, lr=0.000386, step_loss=0.0007/27/2023 18:11:27 - INFO - __main__ - train loss is 12.025581766851246\n",
      "Steps:  21%|▏| 3104/15000 [26:37<1:40:09,  1.98it/s, lr=0.000386, step_loss=0.0107/27/2023 18:11:27 - INFO - __main__ - train loss is 12.412421782501042\n",
      "Steps:  21%|▏| 3105/15000 [26:37<1:40:17,  1.98it/s, lr=0.000387, step_loss=0.3807/27/2023 18:11:28 - INFO - __main__ - train loss is 12.669641454704106\n",
      "Steps:  21%|▏| 3106/15000 [26:38<1:40:46,  1.97it/s, lr=0.000387, step_loss=0.2507/27/2023 18:11:28 - INFO - __main__ - train loss is 12.955431749112904\n",
      "Steps:  21%|▏| 3107/15000 [26:38<1:41:06,  1.96it/s, lr=0.000387, step_loss=0.2807/27/2023 18:11:29 - INFO - __main__ - train loss is 13.380727996118367\n",
      "Steps:  21%|▏| 3108/15000 [26:39<1:40:35,  1.97it/s, lr=0.000387, step_loss=0.4207/27/2023 18:11:29 - INFO - __main__ - train loss is 13.386463337112218\n",
      "Steps:  21%|▏| 3109/15000 [26:39<1:40:15,  1.98it/s, lr=0.000387, step_loss=0.0007/27/2023 18:11:30 - INFO - __main__ - train loss is 13.418953806627542\n",
      "Steps:  21%|▏| 3110/15000 [26:40<1:40:14,  1.98it/s, lr=0.000387, step_loss=0.0307/27/2023 18:11:30 - INFO - __main__ - train loss is 13.529707707930356\n",
      "Steps:  21%|▏| 3111/15000 [26:41<1:40:40,  1.97it/s, lr=0.000387, step_loss=0.1107/27/2023 18:11:31 - INFO - __main__ - train loss is 13.635563619900495\n",
      "Steps:  21%|▏| 3112/15000 [26:41<1:40:17,  1.98it/s, lr=0.000387, step_loss=0.1007/27/2023 18:11:31 - INFO - __main__ - train loss is 13.638572265626863\n",
      "Steps:  21%|▏| 3113/15000 [26:42<1:40:18,  1.98it/s, lr=0.000388, step_loss=0.0007/27/2023 18:11:32 - INFO - __main__ - train loss is 13.724741091253236\n",
      "Steps:  21%|▏| 3114/15000 [26:42<1:40:15,  1.98it/s, lr=0.000388, step_loss=0.0807/27/2023 18:11:32 - INFO - __main__ - train loss is 13.727388079278171\n",
      "Steps:  21%|▏| 3115/15000 [26:43<1:39:51,  1.98it/s, lr=0.000388, step_loss=0.0007/27/2023 18:11:33 - INFO - __main__ - train loss is 13.740116166882217\n",
      "Steps:  21%|▏| 3116/15000 [26:43<1:39:43,  1.99it/s, lr=0.000388, step_loss=0.0107/27/2023 18:11:33 - INFO - __main__ - train loss is 14.067055809311569\n",
      "Steps:  21%|▏| 3117/15000 [26:44<1:39:31,  1.99it/s, lr=0.000388, step_loss=0.3207/27/2023 18:11:34 - INFO - __main__ - train loss is 14.303938436321914\n",
      "Steps:  21%|▏| 3118/15000 [26:44<1:39:35,  1.99it/s, lr=0.000388, step_loss=0.2307/27/2023 18:11:34 - INFO - __main__ - train loss is 14.316778903827071\n",
      "Steps:  21%|▏| 3119/15000 [26:45<1:39:40,  1.99it/s, lr=0.000388, step_loss=0.0107/27/2023 18:11:35 - INFO - __main__ - train loss is 14.662017052993178\n",
      "Steps:  21%|▏| 3120/15000 [26:45<1:39:42,  1.99it/s, lr=0.000388, step_loss=0.3407/27/2023 18:11:35 - INFO - __main__ - train loss is 14.731072885915637\n",
      "Steps:  21%|▏| 3121/15000 [26:46<1:40:57,  1.96it/s, lr=0.000389, step_loss=0.0607/27/2023 18:11:36 - INFO - __main__ - train loss is 14.7422479018569\n",
      "Steps:  21%|▏| 3122/15000 [26:46<1:43:51,  1.91it/s, lr=0.000389, step_loss=0.0107/27/2023 18:11:36 - INFO - __main__ - train loss is 15.0246045216918\n",
      "Steps:  21%|▏| 3123/15000 [26:47<1:47:32,  1.84it/s, lr=0.000389, step_loss=0.2807/27/2023 18:11:37 - INFO - __main__ - train loss is 15.202707879245281\n",
      "Steps:  21%|▏| 3124/15000 [26:47<1:46:16,  1.86it/s, lr=0.000389, step_loss=0.1707/27/2023 18:11:37 - INFO - __main__ - train loss is 15.213459527119994\n",
      "Steps:  21%|▏| 3125/15000 [26:48<1:44:44,  1.89it/s, lr=0.000389, step_loss=0.0107/27/2023 18:11:38 - INFO - __main__ - train loss is 15.215239497832954\n",
      "Steps:  21%|▏| 3126/15000 [26:48<1:43:58,  1.90it/s, lr=0.000389, step_loss=0.0007/27/2023 18:11:38 - INFO - __main__ - train loss is 15.216505169752054\n",
      "Steps:  21%|▏| 3127/15000 [26:49<1:42:37,  1.93it/s, lr=0.000389, step_loss=0.0007/27/2023 18:11:39 - INFO - __main__ - train loss is 15.29688341903966\n",
      "Steps:  21%|▏| 3128/15000 [26:49<1:41:47,  1.94it/s, lr=0.000389, step_loss=0.0807/27/2023 18:11:39 - INFO - __main__ - train loss is 15.317899662884884\n",
      "Steps:  21%|▏| 3129/15000 [26:50<1:41:46,  1.94it/s, lr=0.00039, step_loss=0.02107/27/2023 18:11:40 - INFO - __main__ - train loss is 15.371577057871036\n",
      "Steps:  21%|▏| 3130/15000 [26:50<1:41:02,  1.96it/s, lr=0.00039, step_loss=0.05307/27/2023 18:11:40 - INFO - __main__ - train loss is 15.381547886761837\n",
      "Steps:  21%|▏| 3131/15000 [26:51<1:40:40,  1.96it/s, lr=0.00039, step_loss=0.00907/27/2023 18:11:41 - INFO - __main__ - train loss is 15.61588310066145\n",
      "Steps:  21%|▏| 3132/15000 [26:51<1:40:20,  1.97it/s, lr=0.00039, step_loss=0.23407/27/2023 18:11:41 - INFO - __main__ - train loss is 15.619091408210807\n",
      "Steps:  21%|▏| 3133/15000 [26:52<1:39:47,  1.98it/s, lr=0.00039, step_loss=0.00307/27/2023 18:11:42 - INFO - __main__ - train loss is 15.62479799229186\n",
      "Steps:  21%|▏| 3134/15000 [26:52<1:39:25,  1.99it/s, lr=0.00039, step_loss=0.00507/27/2023 18:11:42 - INFO - __main__ - train loss is 15.642202786984853\n",
      "Steps:  21%|▏| 3135/15000 [26:53<1:39:31,  1.99it/s, lr=0.00039, step_loss=0.01707/27/2023 18:11:43 - INFO - __main__ - train loss is 15.653233837219886\n",
      "Steps:  21%|▏| 3136/15000 [26:53<1:39:36,  1.99it/s, lr=0.00039, step_loss=0.01107/27/2023 18:11:43 - INFO - __main__ - train loss is 15.857237648102455\n",
      "Steps:  21%|▏| 3137/15000 [26:54<1:39:26,  1.99it/s, lr=0.000391, step_loss=0.2007/27/2023 18:11:44 - INFO - __main__ - train loss is 16.098977159592323\n",
      "Steps:  21%|▏| 3138/15000 [26:54<1:39:09,  1.99it/s, lr=0.000391, step_loss=0.2407/27/2023 18:11:44 - INFO - __main__ - train loss is 16.103872886742465\n",
      "Steps:  21%|▏| 3139/15000 [26:55<1:38:54,  2.00it/s, lr=0.000391, step_loss=0.0007/27/2023 18:11:45 - INFO - __main__ - train loss is 16.56653230532538\n",
      "Steps:  21%|▏| 3140/15000 [26:55<1:39:03,  2.00it/s, lr=0.000391, step_loss=0.4607/27/2023 18:11:45 - INFO - __main__ - train loss is 16.623663007165305\n",
      "Steps:  21%|▏| 3141/15000 [26:56<1:38:55,  2.00it/s, lr=0.000391, step_loss=0.0507/27/2023 18:11:46 - INFO - __main__ - train loss is 17.370539008523338\n",
      "Steps:  21%|▏| 3142/15000 [26:56<1:38:56,  2.00it/s, lr=0.000391, step_loss=0.7407/27/2023 18:11:46 - INFO - __main__ - train loss is 17.612702025915496\n",
      "Steps:  21%|▏| 3143/15000 [26:57<1:39:09,  1.99it/s, lr=0.000391, step_loss=0.2407/27/2023 18:11:47 - INFO - __main__ - train loss is 17.81466190412175\n",
      "Steps:  21%|▏| 3144/15000 [26:57<1:39:33,  1.98it/s, lr=0.000391, step_loss=0.2007/27/2023 18:11:48 - INFO - __main__ - train loss is 17.81852701038588\n",
      "Steps:  21%|▏| 3145/15000 [26:58<1:39:09,  1.99it/s, lr=0.000392, step_loss=0.0007/27/2023 18:11:48 - INFO - __main__ - train loss is 17.8274905300932\n",
      "Steps:  21%|▏| 3146/15000 [26:58<1:39:43,  1.98it/s, lr=0.000392, step_loss=0.0007/27/2023 18:11:49 - INFO - __main__ - train loss is 17.869161709328182\n",
      "Steps:  21%|▏| 3147/15000 [26:59<1:39:27,  1.99it/s, lr=0.000392, step_loss=0.0407/27/2023 18:11:49 - INFO - __main__ - train loss is 18.20000679709483\n",
      "Steps:  21%|▏| 3148/15000 [26:59<1:39:25,  1.99it/s, lr=0.000392, step_loss=0.3307/27/2023 18:11:50 - INFO - __main__ - train loss is 18.243604335119016\n",
      "Steps:  21%|▏| 3149/15000 [27:00<1:39:43,  1.98it/s, lr=0.000392, step_loss=0.0407/27/2023 18:11:50 - INFO - __main__ - train loss is 18.521426024963148\n",
      "Steps:  21%|▏| 3150/15000 [27:00<1:39:27,  1.99it/s, lr=0.000392, step_loss=0.2707/27/2023 18:11:51 - INFO - __main__ - train loss is 18.54331581585575\n",
      "Steps:  21%|▏| 3151/15000 [27:01<1:39:32,  1.98it/s, lr=0.000392, step_loss=0.0207/27/2023 18:11:51 - INFO - __main__ - train loss is 18.70137390785385\n",
      "Steps:  21%|▏| 3152/15000 [27:01<1:40:07,  1.97it/s, lr=0.000392, step_loss=0.1507/27/2023 18:11:52 - INFO - __main__ - train loss is 18.767500485409983\n",
      "Steps:  21%|▏| 3153/15000 [27:02<1:41:25,  1.95it/s, lr=0.000392, step_loss=0.0607/27/2023 18:11:52 - INFO - __main__ - train loss is 19.513844396104105\n",
      "Steps:  21%|▏| 3154/15000 [27:02<1:45:21,  1.87it/s, lr=0.000393, step_loss=0.7407/27/2023 18:11:53 - INFO - __main__ - train loss is 19.530413189087994\n",
      "Steps:  21%|▏| 3155/15000 [27:03<1:47:23,  1.84it/s, lr=0.000393, step_loss=0.0107/27/2023 18:11:53 - INFO - __main__ - train loss is 19.53595884621609\n",
      "Steps:  21%|▏| 3156/15000 [27:04<1:46:03,  1.86it/s, lr=0.000393, step_loss=0.0007/27/2023 18:11:54 - INFO - __main__ - train loss is 19.538439281866886\n",
      "Steps:  21%|▏| 3157/15000 [27:04<1:44:06,  1.90it/s, lr=0.000393, step_loss=0.0007/27/2023 18:11:54 - INFO - __main__ - train loss is 19.567766361520626\n",
      "Steps:  21%|▏| 3158/15000 [27:05<1:42:56,  1.92it/s, lr=0.000393, step_loss=0.0207/27/2023 18:11:55 - INFO - __main__ - train loss is 20.144103341386653\n",
      "Steps:  21%|▏| 3159/15000 [27:05<1:42:28,  1.93it/s, lr=0.000393, step_loss=0.5707/27/2023 18:11:55 - INFO - __main__ - train loss is 20.22611369995866\n",
      "Steps:  21%|▏| 3160/15000 [27:06<1:41:44,  1.94it/s, lr=0.000393, step_loss=0.0807/27/2023 18:11:56 - INFO - __main__ - train loss is 20.244133752421476\n",
      "Steps:  21%|▏| 3161/15000 [27:06<1:41:08,  1.95it/s, lr=0.000394, step_loss=0.0107/27/2023 18:11:56 - INFO - __main__ - train loss is 20.436552595929243\n",
      "Steps:  21%|▏| 3162/15000 [27:07<1:40:44,  1.96it/s, lr=0.000394, step_loss=0.1907/27/2023 18:11:57 - INFO - __main__ - train loss is 20.536108296946622\n",
      "Steps:  21%|▏| 3163/15000 [27:07<1:40:24,  1.96it/s, lr=0.000394, step_loss=0.0907/27/2023 18:11:57 - INFO - __main__ - train loss is 20.88780830486212\n",
      "Steps:  21%|▏| 3164/15000 [27:08<1:40:28,  1.96it/s, lr=0.000394, step_loss=0.3507/27/2023 18:11:58 - INFO - __main__ - train loss is 20.99931592924986\n",
      "Steps:  21%|▏| 3165/15000 [27:08<1:40:21,  1.97it/s, lr=0.000394, step_loss=0.1107/27/2023 18:11:58 - INFO - __main__ - train loss is 21.445465516881086\n",
      "Steps:  21%|▏| 3166/15000 [27:09<1:40:19,  1.97it/s, lr=0.000394, step_loss=0.4407/27/2023 18:11:59 - INFO - __main__ - train loss is 22.222119164303876\n",
      "Steps:  21%|▏| 3167/15000 [27:09<1:40:18,  1.97it/s, lr=0.000394, step_loss=0.7707/27/2023 18:11:59 - INFO - __main__ - train loss is 22.456258725957014\n",
      "Steps:  21%|▏| 3168/15000 [27:10<1:40:21,  1.96it/s, lr=0.000394, step_loss=0.2307/27/2023 18:12:00 - INFO - __main__ - train loss is 23.016857933835126\n",
      "Steps:  21%|▏| 3169/15000 [27:10<1:40:27,  1.96it/s, lr=0.000395, step_loss=0.5607/27/2023 18:12:00 - INFO - __main__ - train loss is 23.033714745775796\n",
      "Steps:  21%|▏| 3170/15000 [27:11<1:40:18,  1.97it/s, lr=0.000395, step_loss=0.0107/27/2023 18:12:01 - INFO - __main__ - train loss is 23.173447702662088\n",
      "Steps:  21%|▏| 3171/15000 [27:11<1:39:54,  1.97it/s, lr=0.000395, step_loss=0.1407/27/2023 18:12:01 - INFO - __main__ - train loss is 23.378397960797884\n",
      "Steps:  21%|▏| 3172/15000 [27:12<1:39:56,  1.97it/s, lr=0.000395, step_loss=0.2007/27/2023 18:12:02 - INFO - __main__ - train loss is 23.57541291846428\n",
      "Steps:  21%|▏| 3173/15000 [27:12<1:40:04,  1.97it/s, lr=0.000395, step_loss=0.1907/27/2023 18:12:02 - INFO - __main__ - train loss is 24.04996364249382\n",
      "Steps:  21%|▏| 3174/15000 [27:13<1:40:08,  1.97it/s, lr=0.000395, step_loss=0.4707/27/2023 18:12:03 - INFO - __main__ - train loss is 24.420918156043626\n",
      "Steps:  21%|▏| 3175/15000 [27:13<1:39:58,  1.97it/s, lr=0.000395, step_loss=0.3707/27/2023 18:12:03 - INFO - __main__ - train loss is 24.423463076003827\n",
      "Steps:  21%|▏| 3176/15000 [27:14<1:39:40,  1.98it/s, lr=0.000395, step_loss=0.0007/27/2023 18:12:04 - INFO - __main__ - train loss is 24.452839187928475\n",
      "Steps:  21%|▏| 3177/15000 [27:14<1:39:47,  1.97it/s, lr=0.000396, step_loss=0.0207/27/2023 18:12:04 - INFO - __main__ - train loss is 24.46778050402645\n",
      "Steps:  21%|▏| 3178/15000 [27:15<1:39:50,  1.97it/s, lr=0.000396, step_loss=0.0107/27/2023 18:12:05 - INFO - __main__ - train loss is 24.508749600150622\n",
      "Steps:  21%|▏| 3179/15000 [27:15<1:39:52,  1.97it/s, lr=0.000396, step_loss=0.0407/27/2023 18:12:05 - INFO - __main__ - train loss is 24.585104625322856\n",
      "Steps:  21%|▏| 3180/15000 [27:16<1:39:38,  1.98it/s, lr=0.000396, step_loss=0.0707/27/2023 18:12:06 - INFO - __main__ - train loss is 24.586693126126193\n",
      "Steps:  21%|▏| 3181/15000 [27:16<1:39:46,  1.97it/s, lr=0.000396, step_loss=0.0007/27/2023 18:12:06 - INFO - __main__ - train loss is 24.610211079358123\n",
      "Steps:  21%|▏| 3182/15000 [27:17<1:39:45,  1.97it/s, lr=0.000396, step_loss=0.0207/27/2023 18:12:07 - INFO - __main__ - train loss is 24.614217291004024\n",
      "Steps:  21%|▏| 3183/15000 [27:17<1:39:40,  1.98it/s, lr=0.000396, step_loss=0.0007/27/2023 18:12:07 - INFO - __main__ - train loss is 25.317183385021053\n",
      "Steps:  21%|▏| 3184/15000 [27:18<1:39:54,  1.97it/s, lr=0.000396, step_loss=0.7007/27/2023 18:12:08 - INFO - __main__ - train loss is 25.473822931176983\n",
      "Steps:  21%|▏| 3185/15000 [27:18<1:39:59,  1.97it/s, lr=0.000397, step_loss=0.1507/27/2023 18:12:08 - INFO - __main__ - train loss is 25.517085297382437\n",
      "Steps:  21%|▏| 3186/15000 [27:19<1:41:44,  1.94it/s, lr=0.000397, step_loss=0.0407/27/2023 18:12:09 - INFO - __main__ - train loss is 25.62339220789727\n",
      "Steps:  21%|▏| 3187/15000 [27:19<1:44:45,  1.88it/s, lr=0.000397, step_loss=0.1007/27/2023 18:12:10 - INFO - __main__ - train loss is 25.758647216833197\n",
      "Steps:  21%|▏| 3188/15000 [27:20<1:44:32,  1.88it/s, lr=0.000397, step_loss=0.1307/27/2023 18:12:10 - INFO - __main__ - train loss is 25.825737810111605\n",
      "Steps:  21%|▏| 3189/15000 [27:20<1:43:10,  1.91it/s, lr=0.000397, step_loss=0.0607/27/2023 18:12:11 - INFO - __main__ - train loss is 25.885194013244472\n",
      "Steps:  21%|▏| 3190/15000 [27:21<1:42:23,  1.92it/s, lr=0.000397, step_loss=0.0507/27/2023 18:12:11 - INFO - __main__ - train loss is 26.227570603019558\n",
      "Steps:  21%|▏| 3191/15000 [27:21<1:41:47,  1.93it/s, lr=0.000397, step_loss=0.3407/27/2023 18:12:12 - INFO - __main__ - train loss is 26.235510330996476\n",
      "Steps:  21%|▏| 3192/15000 [27:22<1:41:18,  1.94it/s, lr=0.000397, step_loss=0.0007/27/2023 18:12:12 - INFO - __main__ - train loss is 26.384523373446427\n",
      "Steps:  21%|▏| 3193/15000 [27:22<1:40:56,  1.95it/s, lr=0.000398, step_loss=0.1407/27/2023 18:12:13 - INFO - __main__ - train loss is 26.92083893378731\n",
      "Steps:  21%|▏| 3194/15000 [27:23<1:40:31,  1.96it/s, lr=0.000398, step_loss=0.5307/27/2023 18:12:13 - INFO - __main__ - train loss is 27.033874277374707\n",
      "Steps:  21%|▏| 3195/15000 [27:23<1:40:09,  1.96it/s, lr=0.000398, step_loss=0.1107/27/2023 18:12:14 - INFO - __main__ - train loss is 27.88602734019514\n",
      "Steps:  21%|▏| 3196/15000 [27:24<1:40:41,  1.95it/s, lr=0.000398, step_loss=0.8507/27/2023 18:12:14 - INFO - __main__ - train loss is 27.93266515096184\n",
      "Steps:  21%|▏| 3197/15000 [27:24<1:40:47,  1.95it/s, lr=0.000398, step_loss=0.0407/27/2023 18:12:15 - INFO - __main__ - train loss is 28.270680766901933\n",
      "Steps:  21%|▏| 3198/15000 [27:25<1:40:30,  1.96it/s, lr=0.000398, step_loss=0.3307/27/2023 18:12:15 - INFO - __main__ - train loss is 28.277477391413413\n",
      "Steps:  21%|▏| 3199/15000 [27:26<1:40:15,  1.96it/s, lr=0.000398, step_loss=0.0007/27/2023 18:12:16 - INFO - __main__ - train loss is 28.33139050041791\n",
      "Steps:  21%|▏| 3200/15000 [27:26<1:40:00,  1.97it/s, lr=0.000398, step_loss=0.0507/27/2023 18:12:16 - INFO - __main__ - train loss is 28.369059242657386\n",
      "Steps:  21%|▏| 3201/15000 [27:27<1:39:43,  1.97it/s, lr=0.000399, step_loss=0.0307/27/2023 18:12:17 - INFO - __main__ - train loss is 28.402391568175517\n",
      "Steps:  21%|▏| 3202/15000 [27:27<1:39:23,  1.98it/s, lr=0.000399, step_loss=0.0307/27/2023 18:12:17 - INFO - __main__ - train loss is 28.63290376996156\n",
      "Steps:  21%|▏| 3203/15000 [27:28<1:39:10,  1.98it/s, lr=0.000399, step_loss=0.2307/27/2023 18:12:18 - INFO - __main__ - train loss is 28.922288492671214\n",
      "Steps:  21%|▏| 3204/15000 [27:28<1:39:15,  1.98it/s, lr=0.000399, step_loss=0.2807/27/2023 18:12:18 - INFO - __main__ - train loss is 29.286051556817256\n",
      "Steps:  21%|▏| 3205/15000 [27:29<1:39:10,  1.98it/s, lr=0.000399, step_loss=0.3607/27/2023 18:12:19 - INFO - __main__ - train loss is 29.36336192523595\n",
      "Steps:  21%|▏| 3206/15000 [27:29<1:39:22,  1.98it/s, lr=0.000399, step_loss=0.0707/27/2023 18:12:19 - INFO - __main__ - train loss is 29.36613805370871\n",
      "Steps:  21%|▏| 3207/15000 [27:30<1:39:16,  1.98it/s, lr=0.000399, step_loss=0.0007/27/2023 18:12:20 - INFO - __main__ - train loss is 29.542329040938057\n",
      "Steps:  21%|▏| 3208/15000 [27:30<1:39:04,  1.98it/s, lr=0.000399, step_loss=0.1707/27/2023 18:12:20 - INFO - __main__ - train loss is 29.583097120397724\n",
      "Steps:  21%|▏| 3209/15000 [27:31<1:39:16,  1.98it/s, lr=0.0004, step_loss=0.040807/27/2023 18:12:21 - INFO - __main__ - train loss is 29.728199263685383\n",
      "Steps:  21%|▏| 3210/15000 [27:31<1:39:26,  1.98it/s, lr=0.0004, step_loss=0.145]07/27/2023 18:12:21 - INFO - __main__ - train loss is 29.730548179359175\n",
      "Steps:  21%|▏| 3211/15000 [27:32<1:39:17,  1.98it/s, lr=0.0004, step_loss=0.002307/27/2023 18:12:22 - INFO - __main__ - train loss is 29.732622818672098\n",
      "Steps:  21%|▏| 3212/15000 [27:32<1:39:05,  1.98it/s, lr=0.0004, step_loss=0.002007/27/2023 18:12:22 - INFO - __main__ - train loss is 29.750574493431486\n",
      "Steps:  21%|▏| 3213/15000 [27:33<1:39:52,  1.97it/s, lr=0.0004, step_loss=0.018]07/27/2023 18:12:23 - INFO - __main__ - train loss is 29.816587293171324\n",
      "Steps:  21%|▏| 3214/15000 [27:33<1:39:16,  1.98it/s, lr=0.0004, step_loss=0.066]07/27/2023 18:12:23 - INFO - __main__ - train loss is 29.821651825797744\n",
      "Steps:  21%|▏| 3215/15000 [27:34<1:39:34,  1.97it/s, lr=0.0004, step_loss=0.005007/27/2023 18:12:24 - INFO - __main__ - train loss is 29.89390529890079\n",
      "Steps:  21%|▏| 3216/15000 [27:34<1:39:36,  1.97it/s, lr=0.0004, step_loss=0.072307/27/2023 18:12:24 - INFO - __main__ - train loss is 29.896274316241033\n",
      "Steps:  21%|▏| 3217/15000 [27:35<1:39:35,  1.97it/s, lr=0.000401, step_loss=0.0007/27/2023 18:12:25 - INFO - __main__ - train loss is 30.169415402342565\n",
      "Steps:  21%|▏| 3218/15000 [27:35<1:39:42,  1.97it/s, lr=0.000401, step_loss=0.2707/27/2023 18:12:25 - INFO - __main__ - train loss is 30.654131996561773\n",
      "Steps:  21%|▏| 3219/15000 [27:36<1:39:34,  1.97it/s, lr=0.000401, step_loss=0.4807/27/2023 18:12:26 - INFO - __main__ - train loss is 30.679350658436306\n",
      "Steps:  21%|▏| 3220/15000 [27:36<1:39:46,  1.97it/s, lr=0.000401, step_loss=0.0207/27/2023 18:12:26 - INFO - __main__ - train loss is 31.1462462983327\n",
      "Steps:  21%|▏| 3221/15000 [27:37<1:41:07,  1.94it/s, lr=0.000401, step_loss=0.4607/27/2023 18:12:27 - INFO - __main__ - train loss is 31.2297426603036\n",
      "Steps:  21%|▏| 3222/15000 [27:37<1:45:21,  1.86it/s, lr=0.000401, step_loss=0.0807/27/2023 18:12:27 - INFO - __main__ - train loss is 31.358416541595943\n",
      "Steps:  21%|▏| 3223/15000 [27:38<1:45:27,  1.86it/s, lr=0.000401, step_loss=0.1207/27/2023 18:12:28 - INFO - __main__ - train loss is 31.362470439751633\n",
      "Steps:  21%|▏| 3224/15000 [27:38<1:44:59,  1.87it/s, lr=0.000401, step_loss=0.0007/27/2023 18:12:29 - INFO - __main__ - train loss is 31.438875130494125\n",
      "Steps:  22%|▏| 3225/15000 [27:39<1:44:44,  1.87it/s, lr=0.000402, step_loss=0.0707/27/2023 18:12:29 - INFO - __main__ - train loss is 31.51483637758065\n",
      "Steps:  22%|▏| 3226/15000 [27:39<1:44:03,  1.89it/s, lr=0.000402, step_loss=0.0707/27/2023 18:12:30 - INFO - __main__ - train loss is 31.649678818066604\n",
      "Steps:  22%|▏| 3227/15000 [27:40<1:43:23,  1.90it/s, lr=0.000402, step_loss=0.1307/27/2023 18:12:30 - INFO - __main__ - train loss is 31.656844978337176\n",
      "Steps:  22%|▏| 3228/15000 [27:40<1:42:36,  1.91it/s, lr=0.000402, step_loss=0.0007/27/2023 18:12:31 - INFO - __main__ - train loss is 32.10423076630104\n",
      "Steps:  22%|▏| 3229/15000 [27:41<1:41:39,  1.93it/s, lr=0.000402, step_loss=0.4407/27/2023 18:12:31 - INFO - __main__ - train loss is 32.15267850935925\n",
      "Steps:  22%|▏| 3230/15000 [27:41<1:40:41,  1.95it/s, lr=0.000402, step_loss=0.0407/27/2023 18:12:32 - INFO - __main__ - train loss is 32.16137869574595\n",
      "Steps:  22%|▏| 3231/15000 [27:42<1:40:05,  1.96it/s, lr=0.000402, step_loss=0.0007/27/2023 18:12:32 - INFO - __main__ - train loss is 32.389942302485\n",
      "Steps:  22%|▏| 3232/15000 [27:42<1:39:45,  1.97it/s, lr=0.000402, step_loss=0.2207/27/2023 18:12:33 - INFO - __main__ - train loss is 32.94552899815608\n",
      "Steps:  22%|▏| 3233/15000 [27:43<1:39:38,  1.97it/s, lr=0.000403, step_loss=0.5507/27/2023 18:12:33 - INFO - __main__ - train loss is 32.99692182906438\n",
      "Steps:  22%|▏| 3234/15000 [27:43<1:40:19,  1.95it/s, lr=0.000403, step_loss=0.0507/27/2023 18:12:34 - INFO - __main__ - train loss is 33.015123627264984\n",
      "Steps:  22%|▏| 3235/15000 [27:44<1:39:53,  1.96it/s, lr=0.000403, step_loss=0.0107/27/2023 18:12:34 - INFO - __main__ - train loss is 33.154152146657\n",
      "Steps:  22%|▏| 3236/15000 [27:44<1:39:39,  1.97it/s, lr=0.000403, step_loss=0.1307/27/2023 18:12:35 - INFO - __main__ - train loss is 33.18673845671583\n",
      "Steps:  22%|▏| 3237/15000 [27:45<1:39:25,  1.97it/s, lr=0.000403, step_loss=0.0307/27/2023 18:12:35 - INFO - __main__ - train loss is 33.61713516258169\n",
      "Steps:  22%|▏| 3238/15000 [27:45<1:39:07,  1.98it/s, lr=0.000403, step_loss=0.4307/27/2023 18:12:36 - INFO - __main__ - train loss is 33.69609182619024\n",
      "Steps:  22%|▏| 3239/15000 [27:46<1:39:35,  1.97it/s, lr=0.000403, step_loss=0.0707/27/2023 18:12:36 - INFO - __main__ - train loss is 33.73457353108097\n",
      "Steps:  22%|▏| 3240/15000 [27:46<1:39:25,  1.97it/s, lr=0.000403, step_loss=0.0307/27/2023 18:12:37 - INFO - __main__ - train loss is 33.751550882239826\n",
      "Steps:  22%|▏| 3241/15000 [27:47<1:39:20,  1.97it/s, lr=0.000404, step_loss=0.0107/27/2023 18:12:37 - INFO - __main__ - train loss is 34.02294567145873\n",
      "Steps:  22%|▏| 3242/15000 [27:47<1:38:58,  1.98it/s, lr=0.000404, step_loss=0.2707/27/2023 18:12:38 - INFO - __main__ - train loss is 34.259657188435085\n",
      "Steps:  22%|▏| 3243/15000 [27:48<1:38:40,  1.99it/s, lr=0.000404, step_loss=0.2307/27/2023 18:12:38 - INFO - __main__ - train loss is 34.26414477464277\n",
      "Steps:  22%|▏| 3244/15000 [27:49<1:39:05,  1.98it/s, lr=0.000404, step_loss=0.0007/27/2023 18:12:39 - INFO - __main__ - train loss is 34.308954466250725\n",
      "Steps:  22%|▏| 3245/15000 [27:49<1:39:18,  1.97it/s, lr=0.000404, step_loss=0.0407/27/2023 18:12:39 - INFO - __main__ - train loss is 34.680465597775765\n",
      "Steps:  22%|▏| 3246/15000 [27:50<1:39:30,  1.97it/s, lr=0.000404, step_loss=0.3707/27/2023 18:12:40 - INFO - __main__ - train loss is 34.68428496515844\n",
      "Steps:  22%|▏| 3247/15000 [27:50<1:39:37,  1.97it/s, lr=0.000404, step_loss=0.0007/27/2023 18:12:40 - INFO - __main__ - train loss is 34.77316198742483\n",
      "Steps:  22%|▏| 3248/15000 [27:51<1:39:25,  1.97it/s, lr=0.000404, step_loss=0.0807/27/2023 18:12:41 - INFO - __main__ - train loss is 34.778861797065474\n",
      "Steps:  22%|▏| 3249/15000 [27:51<1:39:27,  1.97it/s, lr=0.000405, step_loss=0.0007/27/2023 18:12:41 - INFO - __main__ - train loss is 34.85443650058005\n",
      "Steps:  22%|▏| 3250/15000 [27:52<1:39:20,  1.97it/s, lr=0.000405, step_loss=0.0707/27/2023 18:12:42 - INFO - __main__ - train loss is 34.861148637370206\n",
      "Steps:  22%|▏| 3251/15000 [27:52<1:39:12,  1.97it/s, lr=0.000405, step_loss=0.0007/27/2023 18:12:42 - INFO - __main__ - train loss is 35.11757360084448\n",
      "Steps:  22%|▏| 3252/15000 [27:53<1:39:11,  1.97it/s, lr=0.000405, step_loss=0.2507/27/2023 18:12:43 - INFO - __main__ - train loss is 35.125819093198515\n",
      "Steps:  22%|▏| 3253/15000 [27:53<1:39:22,  1.97it/s, lr=0.000405, step_loss=0.0007/27/2023 18:12:43 - INFO - __main__ - train loss is 35.148617024184205\n",
      "Steps:  22%|▏| 3254/15000 [27:54<1:39:31,  1.97it/s, lr=0.000405, step_loss=0.0207/27/2023 18:12:44 - INFO - __main__ - train loss is 35.224013807834126\n",
      "Steps:  22%|▏| 3255/15000 [27:54<1:39:59,  1.96it/s, lr=0.000405, step_loss=0.0707/27/2023 18:12:44 - INFO - __main__ - train loss is 35.226748075918294\n",
      "Steps:  22%|▏| 3256/15000 [27:55<1:39:51,  1.96it/s, lr=0.000405, step_loss=0.0007/27/2023 18:12:45 - INFO - __main__ - train loss is 35.27119048743043\n",
      "Steps:  22%|▏| 3257/15000 [27:55<1:39:53,  1.96it/s, lr=0.000406, step_loss=0.0407/27/2023 18:12:45 - INFO - __main__ - train loss is 35.274481257773004\n",
      "Steps:  22%|▏| 3258/15000 [27:56<1:41:06,  1.94it/s, lr=0.000406, step_loss=0.0007/27/2023 18:12:46 - INFO - __main__ - train loss is 35.48306632635649\n",
      "Steps:  22%|▏| 3259/15000 [27:56<1:49:43,  1.78it/s, lr=0.000406, step_loss=0.2007/27/2023 18:12:47 - INFO - __main__ - train loss is 35.82897863385733\n",
      "Steps:  22%|▏| 3260/15000 [27:57<1:47:38,  1.82it/s, lr=0.000406, step_loss=0.3407/27/2023 18:12:47 - INFO - __main__ - train loss is 35.837133880122565\n",
      "Steps:  22%|▏| 3261/15000 [27:57<1:45:12,  1.86it/s, lr=0.000406, step_loss=0.0007/27/2023 18:12:48 - INFO - __main__ - train loss is 35.8685074740788\n",
      "Steps:  22%|▏| 3262/15000 [27:58<1:43:31,  1.89it/s, lr=0.000406, step_loss=0.0307/27/2023 18:12:48 - INFO - __main__ - train loss is 35.87424532545265\n",
      "Steps:  22%|▏| 3263/15000 [27:58<1:42:06,  1.92it/s, lr=0.000406, step_loss=0.0007/27/2023 18:12:49 - INFO - __main__ - train loss is 36.46779100073036\n",
      "Steps:  22%|▏| 3264/15000 [27:59<1:41:13,  1.93it/s, lr=0.000406, step_loss=0.5907/27/2023 18:12:49 - INFO - __main__ - train loss is 36.661475235945545\n",
      "Steps:  22%|▏| 3265/15000 [27:59<1:40:35,  1.94it/s, lr=0.000406, step_loss=0.1907/27/2023 18:12:50 - INFO - __main__ - train loss is 37.021414393908344\n",
      "Steps:  22%|▏| 3266/15000 [28:00<1:39:56,  1.96it/s, lr=0.000407, step_loss=0.3607/27/2023 18:12:50 - INFO - __main__ - train loss is 37.051713293767534\n",
      "Steps:  22%|▏| 3267/15000 [28:00<1:39:28,  1.97it/s, lr=0.000407, step_loss=0.0307/27/2023 18:12:51 - INFO - __main__ - train loss is 37.25544298288878\n",
      "Steps:  22%|▏| 3268/15000 [28:01<1:39:24,  1.97it/s, lr=0.000407, step_loss=0.2007/27/2023 18:12:51 - INFO - __main__ - train loss is 37.31969261763152\n",
      "Steps:  22%|▏| 3269/15000 [28:01<1:39:25,  1.97it/s, lr=0.000407, step_loss=0.0607/27/2023 18:12:52 - INFO - __main__ - train loss is 37.32133311731741\n",
      "Steps:  22%|▏| 3270/15000 [28:02<1:39:27,  1.97it/s, lr=0.000407, step_loss=0.0007/27/2023 18:12:52 - INFO - __main__ - train loss is 37.39752346975729\n",
      "Steps:  22%|▏| 3271/15000 [28:02<1:39:20,  1.97it/s, lr=0.000407, step_loss=0.0707/27/2023 18:12:53 - INFO - __main__ - train loss is 37.48459783894941\n",
      "Steps:  22%|▏| 3272/15000 [28:03<1:39:16,  1.97it/s, lr=0.000407, step_loss=0.0807/27/2023 18:12:53 - INFO - __main__ - train loss is 37.48666965402663\n",
      "Steps:  22%|▏| 3273/15000 [28:03<1:38:55,  1.98it/s, lr=0.000407, step_loss=0.0007/27/2023 18:12:54 - INFO - __main__ - train loss is 37.67117133177817\n",
      "Steps:  22%|▏| 3274/15000 [28:04<1:39:00,  1.97it/s, lr=0.000408, step_loss=0.1807/27/2023 18:12:54 - INFO - __main__ - train loss is 37.87233414687216\n",
      "Steps:  22%|▏| 3275/15000 [28:04<1:38:26,  1.99it/s, lr=0.000408, step_loss=0.2007/27/2023 18:12:55 - INFO - __main__ - train loss is 37.89494261518121\n",
      "Steps:  22%|▏| 3276/15000 [28:05<1:38:37,  1.98it/s, lr=0.000408, step_loss=0.0207/27/2023 18:12:55 - INFO - __main__ - train loss is 38.03704044595361\n",
      "Steps:  22%|▏| 3277/15000 [28:05<1:38:45,  1.98it/s, lr=0.000408, step_loss=0.1407/27/2023 18:12:56 - INFO - __main__ - train loss is 38.117136653512716\n",
      "Steps:  22%|▏| 3278/15000 [28:06<1:39:00,  1.97it/s, lr=0.000408, step_loss=0.0807/27/2023 18:12:56 - INFO - __main__ - train loss is 38.372094448655844\n",
      "Steps:  22%|▏| 3279/15000 [28:06<1:39:00,  1.97it/s, lr=0.000408, step_loss=0.2507/27/2023 18:12:57 - INFO - __main__ - train loss is 38.425848957151175\n",
      "Steps:  22%|▏| 3280/15000 [28:07<1:38:54,  1.97it/s, lr=0.000408, step_loss=0.0507/27/2023 18:12:57 - INFO - __main__ - train loss is 38.4412269257009\n",
      "Steps:  22%|▏| 3281/15000 [28:07<1:39:01,  1.97it/s, lr=0.000409, step_loss=0.0107/27/2023 18:12:58 - INFO - __main__ - train loss is 38.57676241919398\n",
      "Steps:  22%|▏| 3282/15000 [28:08<1:39:07,  1.97it/s, lr=0.000409, step_loss=0.1307/27/2023 18:12:58 - INFO - __main__ - train loss is 38.60056322440505\n",
      "Steps:  22%|▏| 3283/15000 [28:08<1:38:51,  1.98it/s, lr=0.000409, step_loss=0.0207/27/2023 18:12:59 - INFO - __main__ - train loss is 38.79574402794242\n",
      "Steps:  22%|▏| 3284/15000 [28:09<1:38:58,  1.97it/s, lr=0.000409, step_loss=0.1907/27/2023 18:12:59 - INFO - __main__ - train loss is 38.79745635413565\n",
      "Steps:  22%|▏| 3285/15000 [28:10<1:39:17,  1.97it/s, lr=0.000409, step_loss=0.0007/27/2023 18:13:00 - INFO - __main__ - train loss is 38.80149227497168\n",
      "Steps:  22%|▏| 3286/15000 [28:10<1:39:29,  1.96it/s, lr=0.000409, step_loss=0.0007/27/2023 18:13:00 - INFO - __main__ - train loss is 38.90710254129954\n",
      "Steps:  22%|▏| 3287/15000 [28:11<1:40:09,  1.95it/s, lr=0.000409, step_loss=0.1007/27/2023 18:13:01 - INFO - __main__ - train loss is 38.90943417302333\n",
      "Steps:  22%|▏| 3288/15000 [28:11<1:39:47,  1.96it/s, lr=0.000409, step_loss=0.0007/27/2023 18:13:01 - INFO - __main__ - train loss is 38.91316114878282\n",
      "Steps:  22%|▏| 3289/15000 [28:12<1:39:29,  1.96it/s, lr=0.000409, step_loss=0.0007/27/2023 18:13:02 - INFO - __main__ - train loss is 38.971184541936964\n",
      "Steps:  22%|▏| 3290/15000 [28:12<1:39:05,  1.97it/s, lr=0.00041, step_loss=0.05807/27/2023 18:13:02 - INFO - __main__ - train loss is 38.97413089219481\n",
      "Steps:  22%|▏| 3291/15000 [28:13<1:39:16,  1.97it/s, lr=0.00041, step_loss=0.00207/27/2023 18:13:03 - INFO - __main__ - train loss is 38.99939507525414\n",
      "Steps:  22%|▏| 3292/15000 [28:13<1:39:13,  1.97it/s, lr=0.00041, step_loss=0.02507/27/2023 18:13:03 - INFO - __main__ - train loss is 39.26430374663323\n",
      "Steps:  22%|▏| 3293/15000 [28:14<1:39:15,  1.97it/s, lr=0.00041, step_loss=0.26507/27/2023 18:13:04 - INFO - __main__ - train loss is 39.29339951183647\n",
      "Steps:  22%|▏| 3294/15000 [28:14<1:39:28,  1.96it/s, lr=0.00041, step_loss=0.02907/27/2023 18:13:04 - INFO - __main__ - train loss is 39.74428540375084\n",
      "Steps:  22%|▏| 3295/15000 [28:15<1:39:14,  1.97it/s, lr=0.00041, step_loss=0.45107/27/2023 18:13:05 - INFO - __main__ - train loss is 39.75044933427125\n",
      "Steps:  22%|▏| 3296/15000 [28:15<1:39:15,  1.97it/s, lr=0.00041, step_loss=0.00607/27/2023 18:13:05 - INFO - __main__ - train loss is 39.87539436388761\n",
      "Steps:  22%|▏| 3297/15000 [28:16<1:39:38,  1.96it/s, lr=0.000411, step_loss=0.1207/27/2023 18:13:06 - INFO - __main__ - train loss is 39.87940980680287\n",
      "Steps:  22%|▏| 3298/15000 [28:16<1:43:03,  1.89it/s, lr=0.000411, step_loss=0.0007/27/2023 18:13:06 - INFO - __main__ - train loss is 39.95889357663691\n",
      "Steps:  22%|▏| 3299/15000 [28:17<1:47:44,  1.81it/s, lr=0.000411, step_loss=0.0707/27/2023 18:13:07 - INFO - __main__ - train loss is 40.07470771111548\n",
      "Steps:  22%|▏| 3300/15000 [28:17<1:45:50,  1.84it/s, lr=0.000411, step_loss=0.1107/27/2023 18:13:08 - INFO - __main__ - train loss is 40.1467543784529\n",
      "Steps:  22%|▏| 3301/15000 [28:18<1:44:07,  1.87it/s, lr=0.000411, step_loss=0.0707/27/2023 18:13:08 - INFO - __main__ - train loss is 40.15946557465941\n",
      "Steps:  22%|▏| 3302/15000 [28:18<1:42:33,  1.90it/s, lr=0.000411, step_loss=0.0107/27/2023 18:13:09 - INFO - __main__ - train loss is 40.223656677640975\n",
      "Steps:  22%|▏| 3303/15000 [28:19<1:41:26,  1.92it/s, lr=0.000411, step_loss=0.0607/27/2023 18:13:09 - INFO - __main__ - train loss is 40.35639719013125\n",
      "Steps:  22%|▏| 3304/15000 [28:19<1:40:24,  1.94it/s, lr=0.000411, step_loss=0.1307/27/2023 18:13:10 - INFO - __main__ - train loss is 40.69970590714365\n",
      "Steps:  22%|▏| 3305/15000 [28:20<1:39:45,  1.95it/s, lr=0.000411, step_loss=0.3407/27/2023 18:13:10 - INFO - __main__ - train loss is 40.70396354608238\n",
      "Steps:  22%|▏| 3306/15000 [28:20<1:39:09,  1.97it/s, lr=0.000412, step_loss=0.0007/27/2023 18:13:11 - INFO - __main__ - train loss is 40.70606751181185\n",
      "Steps:  22%|▏| 3307/15000 [28:21<1:39:23,  1.96it/s, lr=0.000412, step_loss=0.0007/27/2023 18:13:11 - INFO - __main__ - train loss is 40.78133940137923\n",
      "Steps:  22%|▏| 3308/15000 [28:21<1:38:46,  1.97it/s, lr=0.000412, step_loss=0.0707/27/2023 18:13:12 - INFO - __main__ - train loss is 41.076562160626054\n",
      "Steps:  22%|▏| 3309/15000 [28:22<1:38:35,  1.98it/s, lr=0.000412, step_loss=0.2907/27/2023 18:13:12 - INFO - __main__ - train loss is 41.079137632856146\n",
      "Steps:  22%|▏| 3310/15000 [28:22<1:37:14,  2.00it/s, lr=0.000412, step_loss=0.0007/27/2023 18:13:13 - INFO - __main__ - train loss is 41.100129740545526\n",
      "Steps:  22%|▏| 3311/15000 [28:23<1:37:12,  2.00it/s, lr=0.000412, step_loss=0.0207/27/2023 18:13:13 - INFO - __main__ - train loss is 41.21715499670245\n",
      "Steps:  22%|▏| 3312/15000 [28:23<1:37:13,  2.00it/s, lr=0.000412, step_loss=0.1107/27/2023 18:13:14 - INFO - __main__ - train loss is 41.52605785639025\n",
      "Steps:  22%|▏| 3313/15000 [28:24<1:37:19,  2.00it/s, lr=0.000412, step_loss=0.3007/27/2023 18:13:14 - INFO - __main__ - train loss is 41.54359036707319\n",
      "Steps:  22%|▏| 3314/15000 [28:24<1:37:25,  2.00it/s, lr=0.000413, step_loss=0.0107/27/2023 18:13:15 - INFO - __main__ - train loss is 41.57237349473871\n",
      "Steps:  22%|▏| 3315/15000 [28:25<1:37:31,  2.00it/s, lr=0.000413, step_loss=0.0207/27/2023 18:13:15 - INFO - __main__ - train loss is 41.701762691373006\n",
      "Steps:  22%|▏| 3316/15000 [28:25<1:37:37,  1.99it/s, lr=0.000413, step_loss=0.1207/27/2023 18:13:16 - INFO - __main__ - train loss is 41.7501599828247\n",
      "Steps:  22%|▏| 3317/15000 [28:26<1:37:56,  1.99it/s, lr=0.000413, step_loss=0.0407/27/2023 18:13:16 - INFO - __main__ - train loss is 41.778896376723424\n",
      "Steps:  22%|▏| 3318/15000 [28:26<1:37:51,  1.99it/s, lr=0.000413, step_loss=0.0207/27/2023 18:13:17 - INFO - __main__ - train loss is 41.78384700906463\n",
      "Steps:  22%|▏| 3319/15000 [28:27<1:37:49,  1.99it/s, lr=0.000413, step_loss=0.0007/27/2023 18:13:17 - INFO - __main__ - train loss is 42.027347018243745\n",
      "Steps:  22%|▏| 3320/15000 [28:27<1:37:40,  1.99it/s, lr=0.000413, step_loss=0.2407/27/2023 18:13:18 - INFO - __main__ - train loss is 42.16777970385738\n",
      "Steps:  22%|▏| 3321/15000 [28:28<1:37:51,  1.99it/s, lr=0.000413, step_loss=0.1407/27/2023 18:13:18 - INFO - __main__ - train loss is 42.72271503997035\n",
      "Steps:  22%|▏| 3322/15000 [28:28<1:37:54,  1.99it/s, lr=0.000414, step_loss=0.5507/27/2023 18:13:19 - INFO - __main__ - train loss is 42.84304178250022\n",
      "Steps:  22%|▏| 3323/15000 [28:29<1:37:55,  1.99it/s, lr=0.000414, step_loss=0.1207/27/2023 18:13:19 - INFO - __main__ - train loss is 43.071993311168626\n",
      "Steps:  22%|▏| 3324/15000 [28:29<1:37:32,  2.00it/s, lr=0.000414, step_loss=0.2207/27/2023 18:13:20 - INFO - __main__ - train loss is 43.211803009035066\n",
      "Steps:  22%|▏| 3325/15000 [28:30<1:37:47,  1.99it/s, lr=0.000414, step_loss=0.1407/27/2023 18:13:20 - INFO - __main__ - train loss is 43.23378891986795\n",
      "Steps:  22%|▏| 3326/15000 [28:30<1:37:32,  1.99it/s, lr=0.000414, step_loss=0.0207/27/2023 18:13:21 - INFO - __main__ - train loss is 43.938162041129544\n",
      "Steps:  22%|▏| 3327/15000 [28:31<1:37:36,  1.99it/s, lr=0.000414, step_loss=0.7007/27/2023 18:13:21 - INFO - __main__ - train loss is 44.34748871368356\n",
      "Steps:  22%|▏| 3328/15000 [28:31<1:37:31,  1.99it/s, lr=0.000414, step_loss=0.4007/27/2023 18:13:22 - INFO - __main__ - train loss is 44.729797763051465\n",
      "Steps:  22%|▏| 3329/15000 [28:32<1:37:37,  1.99it/s, lr=0.000414, step_loss=0.3807/27/2023 18:13:22 - INFO - __main__ - train loss is 44.782107995124534\n",
      "Steps:  22%|▏| 3330/15000 [28:32<1:37:55,  1.99it/s, lr=0.000415, step_loss=0.0507/27/2023 18:13:23 - INFO - __main__ - train loss is 44.784897964214906\n",
      "Steps:  22%|▏| 3331/15000 [28:33<1:37:56,  1.99it/s, lr=0.000415, step_loss=0.0007/27/2023 18:13:23 - INFO - __main__ - train loss is 44.79111539828591\n",
      "Steps:  22%|▏| 3332/15000 [28:33<1:38:00,  1.98it/s, lr=0.000415, step_loss=0.0007/27/2023 18:13:24 - INFO - __main__ - train loss is 44.81228101137094\n",
      "Steps:  22%|▏| 3333/15000 [28:34<1:51:40,  1.74it/s, lr=0.000415, step_loss=0.0207/27/2023 18:13:25 - INFO - __main__ - Per validation step average loss is 0.0018543703481554985\n",
      "07/27/2023 18:13:25 - INFO - __main__ - Cumulative validation average loss is 0.0018543703481554985\n",
      "07/27/2023 18:13:25 - INFO - __main__ - Per validation step average loss is 0.004220114089548588\n",
      "07/27/2023 18:13:25 - INFO - __main__ - Cumulative validation average loss is 0.006074484437704086\n",
      "07/27/2023 18:13:26 - INFO - __main__ - Per validation step average loss is 0.2072795033454895\n",
      "07/27/2023 18:13:26 - INFO - __main__ - Cumulative validation average loss is 0.2133539877831936\n",
      "07/27/2023 18:13:26 - INFO - __main__ - Per validation step average loss is 0.007781150750815868\n",
      "07/27/2023 18:13:26 - INFO - __main__ - Cumulative validation average loss is 0.22113513853400946\n",
      "07/27/2023 18:13:27 - INFO - __main__ - Per validation step average loss is 0.029343273490667343\n",
      "07/27/2023 18:13:27 - INFO - __main__ - Cumulative validation average loss is 0.2504784120246768\n",
      "07/27/2023 18:13:27 - INFO - __main__ - Per validation step average loss is 0.21697622537612915\n",
      "07/27/2023 18:13:27 - INFO - __main__ - Cumulative validation average loss is 0.46745463740080595\n",
      "07/27/2023 18:13:27 - INFO - __main__ - Per validation step average loss is 0.63029545545578\n",
      "07/27/2023 18:13:27 - INFO - __main__ - Cumulative validation average loss is 1.097750092856586\n",
      "07/27/2023 18:13:28 - INFO - __main__ - Per validation step average loss is 0.10244012624025345\n",
      "07/27/2023 18:13:28 - INFO - __main__ - Cumulative validation average loss is 1.2001902190968394\n",
      "07/27/2023 18:13:28 - INFO - __main__ - Per validation step average loss is 0.03149337321519852\n",
      "07/27/2023 18:13:28 - INFO - __main__ - Cumulative validation average loss is 1.231683592312038\n",
      "07/27/2023 18:13:29 - INFO - __main__ - Per validation step average loss is 0.08097219467163086\n",
      "07/27/2023 18:13:29 - INFO - __main__ - Cumulative validation average loss is 1.3126557869836688\n",
      "07/27/2023 18:13:29 - INFO - __main__ - Per validation step average loss is 0.15018299221992493\n",
      "07/27/2023 18:13:29 - INFO - __main__ - Cumulative validation average loss is 1.4628387792035937\n",
      "07/27/2023 18:13:30 - INFO - __main__ - Per validation step average loss is 0.010137585923075676\n",
      "07/27/2023 18:13:30 - INFO - __main__ - Cumulative validation average loss is 1.4729763651266694\n",
      "07/27/2023 18:13:30 - INFO - __main__ - Per validation step average loss is 0.015271867625415325\n",
      "07/27/2023 18:13:30 - INFO - __main__ - Cumulative validation average loss is 1.4882482327520847\n",
      "07/27/2023 18:13:30 - INFO - __main__ - Per validation step average loss is 0.22131776809692383\n",
      "07/27/2023 18:13:30 - INFO - __main__ - Cumulative validation average loss is 1.7095660008490086\n",
      "07/27/2023 18:13:31 - INFO - __main__ - Per validation step average loss is 0.009105056524276733\n",
      "07/27/2023 18:13:31 - INFO - __main__ - Cumulative validation average loss is 1.7186710573732853\n",
      "07/27/2023 18:13:31 - INFO - __main__ - Per validation step average loss is 0.018622100353240967\n",
      "07/27/2023 18:13:31 - INFO - __main__ - Cumulative validation average loss is 1.7372931577265263\n",
      "07/27/2023 18:13:32 - INFO - __main__ - Per validation step average loss is 0.4443023204803467\n",
      "07/27/2023 18:13:32 - INFO - __main__ - Cumulative validation average loss is 2.181595478206873\n",
      "07/27/2023 18:13:32 - INFO - __main__ - Per validation step average loss is 0.4143165946006775\n",
      "07/27/2023 18:13:32 - INFO - __main__ - Cumulative validation average loss is 2.5959120728075504\n",
      "07/27/2023 18:13:32 - INFO - __main__ - Per validation step average loss is 0.005714063532650471\n",
      "07/27/2023 18:13:32 - INFO - __main__ - Cumulative validation average loss is 2.601626136340201\n",
      "07/27/2023 18:13:33 - INFO - __main__ - Per validation step average loss is 0.06705112010240555\n",
      "07/27/2023 18:13:33 - INFO - __main__ - Cumulative validation average loss is 2.6686772564426064\n",
      "07/27/2023 18:13:33 - INFO - __main__ - Per validation step average loss is 0.004959425888955593\n",
      "07/27/2023 18:13:33 - INFO - __main__ - Cumulative validation average loss is 2.673636682331562\n",
      "07/27/2023 18:13:34 - INFO - __main__ - Per validation step average loss is 0.009478786028921604\n",
      "07/27/2023 18:13:34 - INFO - __main__ - Cumulative validation average loss is 2.6831154683604836\n",
      "07/27/2023 18:13:34 - INFO - __main__ - Per validation step average loss is 0.017661139369010925\n",
      "07/27/2023 18:13:34 - INFO - __main__ - Cumulative validation average loss is 2.7007766077294946\n",
      "07/27/2023 18:13:34 - INFO - __main__ - Per validation step average loss is 0.39475157856941223\n",
      "07/27/2023 18:13:34 - INFO - __main__ - Cumulative validation average loss is 3.095528186298907\n",
      "07/27/2023 18:13:35 - INFO - __main__ - Per validation step average loss is 0.4041350781917572\n",
      "07/27/2023 18:13:35 - INFO - __main__ - Cumulative validation average loss is 3.499663264490664\n",
      "07/27/2023 18:13:35 - INFO - __main__ - Per validation step average loss is 0.2187214195728302\n",
      "07/27/2023 18:13:35 - INFO - __main__ - Cumulative validation average loss is 3.718384684063494\n",
      "07/27/2023 18:13:36 - INFO - __main__ - Per validation step average loss is 0.0022154725156724453\n",
      "07/27/2023 18:13:36 - INFO - __main__ - Cumulative validation average loss is 3.7206001565791667\n",
      "07/27/2023 18:13:36 - INFO - __main__ - Per validation step average loss is 0.308788537979126\n",
      "07/27/2023 18:13:36 - INFO - __main__ - Cumulative validation average loss is 4.029388694558293\n",
      "07/27/2023 18:13:36 - INFO - __main__ - Per validation step average loss is 0.15988370776176453\n",
      "07/27/2023 18:13:36 - INFO - __main__ - Cumulative validation average loss is 4.189272402320057\n",
      "07/27/2023 18:13:37 - INFO - __main__ - Per validation step average loss is 0.3180807828903198\n",
      "07/27/2023 18:13:37 - INFO - __main__ - Cumulative validation average loss is 4.507353185210377\n",
      "07/27/2023 18:13:37 - INFO - __main__ - Per validation step average loss is 0.16423118114471436\n",
      "07/27/2023 18:13:37 - INFO - __main__ - Cumulative validation average loss is 4.671584366355091\n",
      "07/27/2023 18:13:38 - INFO - __main__ - Per validation step average loss is 0.009277409873902798\n",
      "07/27/2023 18:13:38 - INFO - __main__ - Cumulative validation average loss is 4.680861776228994\n",
      "07/27/2023 18:13:38 - INFO - __main__ - Per validation step average loss is 0.004608756396919489\n",
      "07/27/2023 18:13:38 - INFO - __main__ - Cumulative validation average loss is 4.685470532625914\n",
      "07/27/2023 18:13:39 - INFO - __main__ - Per validation step average loss is 0.17704296112060547\n",
      "07/27/2023 18:13:39 - INFO - __main__ - Cumulative validation average loss is 4.862513493746519\n",
      "07/27/2023 18:13:39 - INFO - __main__ - Per validation step average loss is 0.0035869223065674305\n",
      "07/27/2023 18:13:39 - INFO - __main__ - Cumulative validation average loss is 4.8661004160530865\n",
      "07/27/2023 18:13:39 - INFO - __main__ - Per validation step average loss is 0.11081485450267792\n",
      "07/27/2023 18:13:39 - INFO - __main__ - Cumulative validation average loss is 4.976915270555764\n",
      "07/27/2023 18:13:40 - INFO - __main__ - Per validation step average loss is 0.0026963374111801386\n",
      "07/27/2023 18:13:40 - INFO - __main__ - Cumulative validation average loss is 4.979611607966945\n",
      "07/27/2023 18:13:40 - INFO - __main__ - Per validation step average loss is 0.02294922061264515\n",
      "07/27/2023 18:13:40 - INFO - __main__ - Cumulative validation average loss is 5.00256082857959\n",
      "07/27/2023 18:13:41 - INFO - __main__ - Per validation step average loss is 0.07382683455944061\n",
      "07/27/2023 18:13:41 - INFO - __main__ - Cumulative validation average loss is 5.07638766313903\n",
      "07/27/2023 18:13:41 - INFO - __main__ - Per validation step average loss is 0.07734557241201401\n",
      "07/27/2023 18:13:41 - INFO - __main__ - Cumulative validation average loss is 5.153733235551044\n",
      "07/27/2023 18:13:41 - INFO - __main__ - Per validation step average loss is 0.022816598415374756\n",
      "07/27/2023 18:13:41 - INFO - __main__ - Cumulative validation average loss is 5.176549833966419\n",
      "07/27/2023 18:13:42 - INFO - __main__ - Per validation step average loss is 0.005261932034045458\n",
      "07/27/2023 18:13:42 - INFO - __main__ - Cumulative validation average loss is 5.181811766000465\n",
      "07/27/2023 18:13:42 - INFO - __main__ - Per validation step average loss is 0.519586443901062\n",
      "07/27/2023 18:13:42 - INFO - __main__ - Cumulative validation average loss is 5.701398209901527\n",
      "07/27/2023 18:13:43 - INFO - __main__ - Per validation step average loss is 0.0461895689368248\n",
      "07/27/2023 18:13:43 - INFO - __main__ - Cumulative validation average loss is 5.747587778838351\n",
      "07/27/2023 18:13:43 - INFO - __main__ - Per validation step average loss is 0.020184945315122604\n",
      "07/27/2023 18:13:43 - INFO - __main__ - Cumulative validation average loss is 5.767772724153474\n",
      "07/27/2023 18:13:43 - INFO - __main__ - Per validation step average loss is 0.02505139634013176\n",
      "07/27/2023 18:13:43 - INFO - __main__ - Cumulative validation average loss is 5.792824120493606\n",
      "07/27/2023 18:13:44 - INFO - __main__ - Per validation step average loss is 0.13650557398796082\n",
      "07/27/2023 18:13:44 - INFO - __main__ - Cumulative validation average loss is 5.9293296944815665\n",
      "07/27/2023 18:13:44 - INFO - __main__ - Per validation step average loss is 0.25717923045158386\n",
      "07/27/2023 18:13:44 - INFO - __main__ - Cumulative validation average loss is 6.18650892493315\n",
      "07/27/2023 18:13:45 - INFO - __main__ - Per validation step average loss is 0.07982192933559418\n",
      "07/27/2023 18:13:45 - INFO - __main__ - Cumulative validation average loss is 6.266330854268745\n",
      "07/27/2023 18:13:45 - INFO - __main__ - Per validation step average loss is 0.013604076579213142\n",
      "07/27/2023 18:13:45 - INFO - __main__ - Cumulative validation average loss is 6.279934930847958\n",
      "07/27/2023 18:13:45 - INFO - __main__ - Per validation step average loss is 0.010271035134792328\n",
      "07/27/2023 18:13:45 - INFO - __main__ - Cumulative validation average loss is 6.29020596598275\n",
      "07/27/2023 18:13:46 - INFO - __main__ - Per validation step average loss is 0.11289852112531662\n",
      "07/27/2023 18:13:46 - INFO - __main__ - Cumulative validation average loss is 6.403104487108067\n",
      "07/27/2023 18:13:46 - INFO - __main__ - Per validation step average loss is 0.002956518903374672\n",
      "07/27/2023 18:13:46 - INFO - __main__ - Cumulative validation average loss is 6.406061006011441\n",
      "07/27/2023 18:13:47 - INFO - __main__ - Per validation step average loss is 0.008703546598553658\n",
      "07/27/2023 18:13:47 - INFO - __main__ - Cumulative validation average loss is 6.414764552609995\n",
      "07/27/2023 18:13:47 - INFO - __main__ - Per validation step average loss is 0.007017134223133326\n",
      "07/27/2023 18:13:47 - INFO - __main__ - Cumulative validation average loss is 6.421781686833128\n",
      "07/27/2023 18:13:48 - INFO - __main__ - Per validation step average loss is 0.002081239828839898\n",
      "07/27/2023 18:13:48 - INFO - __main__ - Cumulative validation average loss is 6.423862926661968\n",
      "07/27/2023 18:13:48 - INFO - __main__ - Per validation step average loss is 0.046071745455265045\n",
      "07/27/2023 18:13:48 - INFO - __main__ - Cumulative validation average loss is 6.469934672117233\n",
      "07/27/2023 18:13:48 - INFO - __main__ - Per validation step average loss is 0.0022149812430143356\n",
      "07/27/2023 18:13:48 - INFO - __main__ - Cumulative validation average loss is 6.472149653360248\n",
      "07/27/2023 18:13:49 - INFO - __main__ - Per validation step average loss is 0.009541762061417103\n",
      "07/27/2023 18:13:49 - INFO - __main__ - Cumulative validation average loss is 6.481691415421665\n",
      "07/27/2023 18:13:49 - INFO - __main__ - Per validation step average loss is 0.028888382017612457\n",
      "07/27/2023 18:13:49 - INFO - __main__ - Cumulative validation average loss is 6.510579797439277\n",
      "07/27/2023 18:13:50 - INFO - __main__ - Per validation step average loss is 0.43710950016975403\n",
      "07/27/2023 18:13:50 - INFO - __main__ - Cumulative validation average loss is 6.947689297609031\n",
      "07/27/2023 18:13:50 - INFO - __main__ - Per validation step average loss is 0.002063408028334379\n",
      "07/27/2023 18:13:50 - INFO - __main__ - Cumulative validation average loss is 6.949752705637366\n",
      "07/27/2023 18:13:50 - INFO - __main__ - Per validation step average loss is 0.11648678034543991\n",
      "07/27/2023 18:13:50 - INFO - __main__ - Cumulative validation average loss is 7.0662394859828055\n",
      "07/27/2023 18:13:51 - INFO - __main__ - Per validation step average loss is 0.00938704889267683\n",
      "07/27/2023 18:13:51 - INFO - __main__ - Cumulative validation average loss is 7.075626534875482\n",
      "07/27/2023 18:13:51 - INFO - __main__ - Per validation step average loss is 0.12387159466743469\n",
      "07/27/2023 18:13:51 - INFO - __main__ - Cumulative validation average loss is 7.199498129542917\n",
      "07/27/2023 18:13:52 - INFO - __main__ - Per validation step average loss is 0.019273895770311356\n",
      "07/27/2023 18:13:52 - INFO - __main__ - Cumulative validation average loss is 7.218772025313228\n",
      "07/27/2023 18:13:52 - INFO - __main__ - Per validation step average loss is 0.002135236281901598\n",
      "07/27/2023 18:13:52 - INFO - __main__ - Cumulative validation average loss is 7.22090726159513\n",
      "07/27/2023 18:13:52 - INFO - __main__ - Per validation step average loss is 0.21491700410842896\n",
      "07/27/2023 18:13:52 - INFO - __main__ - Cumulative validation average loss is 7.435824265703559\n",
      "07/27/2023 18:13:53 - INFO - __main__ - Per validation step average loss is 0.24161668121814728\n",
      "07/27/2023 18:13:53 - INFO - __main__ - Cumulative validation average loss is 7.677440946921706\n",
      "07/27/2023 18:13:53 - INFO - __main__ - Per validation step average loss is 0.012640215456485748\n",
      "07/27/2023 18:13:53 - INFO - __main__ - Cumulative validation average loss is 7.690081162378192\n",
      "07/27/2023 18:13:54 - INFO - __main__ - Per validation step average loss is 0.007223732769489288\n",
      "07/27/2023 18:13:54 - INFO - __main__ - Cumulative validation average loss is 7.697304895147681\n",
      "07/27/2023 18:13:54 - INFO - __main__ - Per validation step average loss is 0.0023670580703765154\n",
      "07/27/2023 18:13:54 - INFO - __main__ - Cumulative validation average loss is 7.699671953218058\n",
      "07/27/2023 18:13:54 - INFO - __main__ - Per validation step average loss is 0.1702384650707245\n",
      "07/27/2023 18:13:54 - INFO - __main__ - Cumulative validation average loss is 7.869910418288782\n",
      "07/27/2023 18:13:55 - INFO - __main__ - Per validation step average loss is 0.3305200934410095\n",
      "07/27/2023 18:13:55 - INFO - __main__ - Cumulative validation average loss is 8.200430511729792\n",
      "07/27/2023 18:13:55 - INFO - __main__ - Per validation step average loss is 0.39296451210975647\n",
      "07/27/2023 18:13:55 - INFO - __main__ - Cumulative validation average loss is 8.593395023839548\n",
      "07/27/2023 18:13:56 - INFO - __main__ - Per validation step average loss is 0.04236939549446106\n",
      "07/27/2023 18:13:56 - INFO - __main__ - Cumulative validation average loss is 8.63576441933401\n",
      "07/27/2023 18:13:56 - INFO - __main__ - Per validation step average loss is 0.2731110453605652\n",
      "07/27/2023 18:13:56 - INFO - __main__ - Cumulative validation average loss is 8.908875464694574\n",
      "07/27/2023 18:13:57 - INFO - __main__ - Per validation step average loss is 0.4784618020057678\n",
      "07/27/2023 18:13:57 - INFO - __main__ - Cumulative validation average loss is 9.387337266700342\n",
      "07/27/2023 18:13:57 - INFO - __main__ - Per validation step average loss is 0.25656330585479736\n",
      "07/27/2023 18:13:57 - INFO - __main__ - Cumulative validation average loss is 9.64390057255514\n",
      "07/27/2023 18:13:57 - INFO - __main__ - Average validation loss for Epoch 10 is 0.1220746907918372\n",
      "07/27/2023 18:13:57 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:14:54 - INFO - __main__ - Starting epoch 11\n",
      "07/27/2023 18:14:55 - INFO - __main__ - train loss is 0.20577815175056458\n",
      "Steps:  22%|▏| 3334/15000 [30:05<89:59:44, 27.77s/it, lr=0.000415, step_loss=0.207/27/2023 18:14:55 - INFO - __main__ - train loss is 0.37703630328178406\n",
      "Steps:  22%|▏| 3335/15000 [30:06<63:09:57, 19.49s/it, lr=0.000415, step_loss=0.107/27/2023 18:14:55 - INFO - __main__ - train loss is 0.39259947557002306\n",
      "Steps:  22%|▏| 3336/15000 [30:06<44:23:08, 13.70s/it, lr=0.000415, step_loss=0.007/27/2023 18:14:56 - INFO - __main__ - train loss is 0.40056008473038673\n",
      "Steps:  22%|▏| 3337/15000 [30:06<31:14:27,  9.64s/it, lr=0.000415, step_loss=0.007/27/2023 18:14:56 - INFO - __main__ - train loss is 0.4027382656931877\n",
      "Steps:  22%|▏| 3338/15000 [30:06<22:02:24,  6.80s/it, lr=0.000416, step_loss=0.007/27/2023 18:14:56 - INFO - __main__ - train loss is 0.40975720388814807\n",
      "Steps:  22%|▏| 3339/15000 [30:06<15:36:10,  4.82s/it, lr=0.000416, step_loss=0.007/27/2023 18:14:56 - INFO - __main__ - train loss is 0.6130832205526531\n",
      "Steps:  22%|▏| 3340/15000 [30:06<11:05:43,  3.43s/it, lr=0.000416, step_loss=0.207/27/2023 18:14:56 - INFO - __main__ - train loss is 0.9137532184831798\n",
      "Steps:  22%|▏| 3341/15000 [30:07<7:56:20,  2.45s/it, lr=0.000416, step_loss=0.3007/27/2023 18:14:57 - INFO - __main__ - train loss is 0.9157824276480824\n",
      "Steps:  22%|▏| 3342/15000 [30:07<5:43:47,  1.77s/it, lr=0.000416, step_loss=0.0007/27/2023 18:14:57 - INFO - __main__ - train loss is 0.9339727556798607\n",
      "Steps:  22%|▏| 3343/15000 [30:07<4:11:01,  1.29s/it, lr=0.000416, step_loss=0.0107/27/2023 18:14:57 - INFO - __main__ - train loss is 1.2086568570230156\n",
      "Steps:  22%|▏| 3344/15000 [30:07<3:06:07,  1.04it/s, lr=0.000416, step_loss=0.2707/27/2023 18:14:57 - INFO - __main__ - train loss is 1.2162934041116387\n",
      "Steps:  22%|▏| 3345/15000 [30:07<2:20:40,  1.38it/s, lr=0.000416, step_loss=0.0007/27/2023 18:14:57 - INFO - __main__ - train loss is 1.657002160558477\n",
      "Steps:  22%|▏| 3346/15000 [30:08<1:48:50,  1.78it/s, lr=0.000417, step_loss=0.4407/27/2023 18:14:57 - INFO - __main__ - train loss is 1.6987160129938275\n",
      "Steps:  22%|▏| 3347/15000 [30:08<1:27:27,  2.22it/s, lr=0.000417, step_loss=0.0407/27/2023 18:14:58 - INFO - __main__ - train loss is 2.3852725906763226\n",
      "Steps:  22%|▏| 3348/15000 [30:08<1:16:27,  2.54it/s, lr=0.000417, step_loss=0.6807/27/2023 18:14:58 - INFO - __main__ - train loss is 2.407181572401896\n",
      "Steps:  22%|▏| 3349/15000 [30:08<1:05:28,  2.97it/s, lr=0.000417, step_loss=0.0207/27/2023 18:14:58 - INFO - __main__ - train loss is 2.552547615254298\n",
      "Steps:  22%|▏| 3350/15000 [30:08<58:17,  3.33it/s, lr=0.000417, step_loss=0.145]07/27/2023 18:14:58 - INFO - __main__ - train loss is 2.577269116649404\n",
      "Steps:  22%|▏| 3351/15000 [30:09<51:20,  3.78it/s, lr=0.000417, step_loss=0.024707/27/2023 18:14:58 - INFO - __main__ - train loss is 2.5792465046979487\n",
      "Steps:  22%|▏| 3352/15000 [30:09<46:23,  4.19it/s, lr=0.000417, step_loss=0.001907/27/2023 18:14:59 - INFO - __main__ - train loss is 2.9283845857717097\n",
      "Steps:  22%|▏| 3353/15000 [30:09<42:56,  4.52it/s, lr=0.000418, step_loss=0.349]07/27/2023 18:14:59 - INFO - __main__ - train loss is 3.454168124590069\n",
      "Steps:  22%|▏| 3354/15000 [30:09<40:32,  4.79it/s, lr=0.000418, step_loss=0.526]07/27/2023 18:14:59 - INFO - __main__ - train loss is 3.7036678777076304\n",
      "Steps:  22%|▏| 3355/15000 [30:09<38:52,  4.99it/s, lr=0.000418, step_loss=0.249]07/27/2023 18:14:59 - INFO - __main__ - train loss is 3.7703753099776804\n",
      "Steps:  22%|▏| 3356/15000 [30:09<37:39,  5.15it/s, lr=0.000418, step_loss=0.066707/27/2023 18:14:59 - INFO - __main__ - train loss is 4.192968843970448\n",
      "Steps:  22%|▏| 3357/15000 [30:10<36:48,  5.27it/s, lr=0.000418, step_loss=0.423]07/27/2023 18:15:00 - INFO - __main__ - train loss is 4.327725781593472\n",
      "Steps:  22%|▏| 3358/15000 [30:10<36:13,  5.36it/s, lr=0.000418, step_loss=0.135]07/27/2023 18:15:00 - INFO - __main__ - train loss is 4.366167558822781\n",
      "Steps:  22%|▏| 3359/15000 [30:10<35:47,  5.42it/s, lr=0.000418, step_loss=0.038407/27/2023 18:15:00 - INFO - __main__ - train loss is 4.4246399574913085\n",
      "Steps:  22%|▏| 3360/15000 [30:10<35:28,  5.47it/s, lr=0.000418, step_loss=0.058507/27/2023 18:15:00 - INFO - __main__ - train loss is 4.444676520768553\n",
      "Steps:  22%|▍ | 3361/15000 [30:10<35:14,  5.50it/s, lr=0.000418, step_loss=0.02]07/27/2023 18:15:00 - INFO - __main__ - train loss is 4.651751460973173\n",
      "Steps:  22%|▏| 3362/15000 [30:11<35:05,  5.53it/s, lr=0.000419, step_loss=0.207]07/27/2023 18:15:00 - INFO - __main__ - train loss is 4.8840189897455275\n",
      "Steps:  22%|▏| 3363/15000 [30:11<35:00,  5.54it/s, lr=0.000419, step_loss=0.232]07/27/2023 18:15:01 - INFO - __main__ - train loss is 4.910103578586131\n",
      "Steps:  22%|▏| 3364/15000 [30:11<34:55,  5.55it/s, lr=0.000419, step_loss=0.026107/27/2023 18:15:01 - INFO - __main__ - train loss is 4.915057091973722\n",
      "Steps:  22%|▏| 3365/15000 [30:11<34:51,  5.56it/s, lr=0.000419, step_loss=0.004907/27/2023 18:15:01 - INFO - __main__ - train loss is 5.215383796952665\n",
      "Steps:  22%|▋  | 3366/15000 [30:11<34:48,  5.57it/s, lr=0.000419, step_loss=0.3]07/27/2023 18:15:01 - INFO - __main__ - train loss is 5.407325594685972\n",
      "Steps:  22%|▏| 3367/15000 [30:11<34:47,  5.57it/s, lr=0.000419, step_loss=0.192]07/27/2023 18:15:01 - INFO - __main__ - train loss is 5.4406355349346995\n",
      "Steps:  22%|▏| 3368/15000 [30:12<34:53,  5.56it/s, lr=0.000419, step_loss=0.033307/27/2023 18:15:02 - INFO - __main__ - train loss is 5.505639138631523\n",
      "Steps:  22%|▍ | 3369/15000 [30:12<34:50,  5.56it/s, lr=0.00042, step_loss=0.065]07/27/2023 18:15:02 - INFO - __main__ - train loss is 5.579283784143627\n",
      "Steps:  22%|▏| 3370/15000 [30:12<34:47,  5.57it/s, lr=0.00042, step_loss=0.0736]07/27/2023 18:15:02 - INFO - __main__ - train loss is 6.266048262827098\n",
      "Steps:  22%|▍ | 3371/15000 [30:12<34:44,  5.58it/s, lr=0.00042, step_loss=0.687]07/27/2023 18:15:02 - INFO - __main__ - train loss is 6.26984752016142\n",
      "Steps:  22%|▏| 3372/15000 [30:12<34:44,  5.58it/s, lr=0.00042, step_loss=0.0038]07/27/2023 18:15:02 - INFO - __main__ - train loss is 6.311549567151815\n",
      "Steps:  22%|▏| 3373/15000 [30:13<34:43,  5.58it/s, lr=0.00042, step_loss=0.0417]07/27/2023 18:15:02 - INFO - __main__ - train loss is 6.980795942712575\n",
      "Steps:  22%|▍ | 3374/15000 [30:13<34:43,  5.58it/s, lr=0.00042, step_loss=0.669]07/27/2023 18:15:03 - INFO - __main__ - train loss is 7.13055530982092\n",
      "Steps:  22%|▋  | 3375/15000 [30:13<34:43,  5.58it/s, lr=0.00042, step_loss=0.15]07/27/2023 18:15:03 - INFO - __main__ - train loss is 7.1341174072586\n",
      "Steps:  23%|▏| 3376/15000 [30:13<34:41,  5.58it/s, lr=0.00042, step_loss=0.0035607/27/2023 18:15:03 - INFO - __main__ - train loss is 7.222395350690931\n",
      "Steps:  23%|▏| 3377/15000 [30:13<34:41,  5.58it/s, lr=0.00042, step_loss=0.0883]07/27/2023 18:15:03 - INFO - __main__ - train loss is 7.5350508890114725\n",
      "Steps:  23%|▏| 3378/15000 [30:13<34:40,  5.59it/s, lr=0.000421, step_loss=0.313]07/27/2023 18:15:03 - INFO - __main__ - train loss is 7.540176552254707\n",
      "Steps:  23%|▏| 3379/15000 [30:14<34:40,  5.59it/s, lr=0.000421, step_loss=0.005107/27/2023 18:15:03 - INFO - __main__ - train loss is 7.619712930638343\n",
      "Steps:  23%|▏| 3380/15000 [30:14<34:39,  5.59it/s, lr=0.000421, step_loss=0.079507/27/2023 18:15:04 - INFO - __main__ - train loss is 7.638944263104349\n",
      "Steps:  23%|▏| 3381/15000 [30:14<34:40,  5.59it/s, lr=0.000421, step_loss=0.019207/27/2023 18:15:04 - INFO - __main__ - train loss is 7.699854927603155\n",
      "Steps:  23%|▏| 3382/15000 [30:14<34:39,  5.59it/s, lr=0.000421, step_loss=0.060907/27/2023 18:15:04 - INFO - __main__ - train loss is 7.713015447836369\n",
      "Steps:  23%|▏| 3383/15000 [30:14<34:40,  5.59it/s, lr=0.000421, step_loss=0.013207/27/2023 18:15:04 - INFO - __main__ - train loss is 7.736521183978766\n",
      "Steps:  23%|▏| 3384/15000 [30:15<34:39,  5.59it/s, lr=0.000421, step_loss=0.023507/27/2023 18:15:04 - INFO - __main__ - train loss is 7.825126900803298\n",
      "Steps:  23%|▏| 3385/15000 [30:15<34:38,  5.59it/s, lr=0.000421, step_loss=0.088607/27/2023 18:15:05 - INFO - __main__ - train loss is 7.831575459334999\n",
      "Steps:  23%|▏| 3386/15000 [30:15<34:38,  5.59it/s, lr=0.000422, step_loss=0.006407/27/2023 18:15:05 - INFO - __main__ - train loss is 8.422740465495735\n",
      "Steps:  23%|▏| 3387/15000 [30:15<34:39,  5.58it/s, lr=0.000422, step_loss=0.591]07/27/2023 18:15:05 - INFO - __main__ - train loss is 8.437147587072104\n",
      "Steps:  23%|▏| 3388/15000 [30:15<34:40,  5.58it/s, lr=0.000422, step_loss=0.014407/27/2023 18:15:05 - INFO - __main__ - train loss is 8.495792854111642\n",
      "Steps:  23%|▏| 3389/15000 [30:15<34:39,  5.58it/s, lr=0.000422, step_loss=0.058607/27/2023 18:15:05 - INFO - __main__ - train loss is 8.730774599593133\n",
      "Steps:  23%|▏| 3390/15000 [30:16<34:40,  5.58it/s, lr=0.000422, step_loss=0.235]07/27/2023 18:15:05 - INFO - __main__ - train loss is 8.828121687751263\n",
      "Steps:  23%|▏| 3391/15000 [30:16<34:40,  5.58it/s, lr=0.000422, step_loss=0.097307/27/2023 18:15:06 - INFO - __main__ - train loss is 8.848546679597348\n",
      "Steps:  23%|▏| 3392/15000 [30:16<34:41,  5.58it/s, lr=0.000422, step_loss=0.020407/27/2023 18:15:06 - INFO - __main__ - train loss is 8.879792300518602\n",
      "Steps:  23%|▏| 3393/15000 [30:16<34:41,  5.58it/s, lr=0.000422, step_loss=0.031207/27/2023 18:15:06 - INFO - __main__ - train loss is 8.989032549317926\n",
      "Steps:  23%|▏| 3394/15000 [30:16<34:39,  5.58it/s, lr=0.000423, step_loss=0.109]07/27/2023 18:15:06 - INFO - __main__ - train loss is 8.99654794903472\n",
      "Steps:  23%|▏| 3395/15000 [30:16<34:39,  5.58it/s, lr=0.000423, step_loss=0.007507/27/2023 18:15:06 - INFO - __main__ - train loss is 9.086040165740997\n",
      "Steps:  23%|▏| 3396/15000 [30:17<34:55,  5.54it/s, lr=0.000423, step_loss=0.089507/27/2023 18:15:07 - INFO - __main__ - train loss is 9.164576117414981\n",
      "Steps:  23%|▏| 3397/15000 [30:17<35:10,  5.50it/s, lr=0.000423, step_loss=0.078507/27/2023 18:15:07 - INFO - __main__ - train loss is 9.16982304258272\n",
      "Steps:  23%|▏| 3398/15000 [30:17<35:07,  5.50it/s, lr=0.000423, step_loss=0.005207/27/2023 18:15:07 - INFO - __main__ - train loss is 9.17422192543745\n",
      "Steps:  23%|▏| 3399/15000 [30:17<34:58,  5.53it/s, lr=0.000423, step_loss=0.004407/27/2023 18:15:07 - INFO - __main__ - train loss is 9.303914584219456\n",
      "Steps:  23%|▍ | 3400/15000 [30:17<34:52,  5.54it/s, lr=0.000423, step_loss=0.13]07/27/2023 18:15:07 - INFO - __main__ - train loss is 9.792509116232395\n",
      "Steps:  23%|▏| 3401/15000 [30:18<34:48,  5.55it/s, lr=0.000423, step_loss=0.489]07/27/2023 18:15:07 - INFO - __main__ - train loss is 9.804186886176467\n",
      "Steps:  23%|▏| 3402/15000 [30:18<34:44,  5.56it/s, lr=0.000424, step_loss=0.011707/27/2023 18:15:08 - INFO - __main__ - train loss is 9.81638286728412\n",
      "Steps:  23%|▏| 3403/15000 [30:18<34:42,  5.57it/s, lr=0.000424, step_loss=0.012207/27/2023 18:15:08 - INFO - __main__ - train loss is 9.826379331760108\n",
      "Steps:  23%|▍ | 3404/15000 [30:18<34:41,  5.57it/s, lr=0.000424, step_loss=0.01]07/27/2023 18:15:08 - INFO - __main__ - train loss is 10.060551690869033\n",
      "Steps:  23%|▏| 3405/15000 [30:18<34:40,  5.57it/s, lr=0.000424, step_loss=0.234]07/27/2023 18:15:08 - INFO - __main__ - train loss is 10.178571867756546\n",
      "Steps:  23%|▏| 3406/15000 [30:18<34:38,  5.58it/s, lr=0.000424, step_loss=0.118]07/27/2023 18:15:08 - INFO - __main__ - train loss is 10.468058216385543\n",
      "Steps:  23%|▏| 3407/15000 [30:19<34:39,  5.58it/s, lr=0.000424, step_loss=0.289]07/27/2023 18:15:09 - INFO - __main__ - train loss is 10.82559900265187\n",
      "Steps:  23%|▏| 3408/15000 [30:19<34:38,  5.58it/s, lr=0.000424, step_loss=0.358]07/27/2023 18:15:09 - INFO - __main__ - train loss is 10.885779182426631\n",
      "Steps:  23%|▏| 3409/15000 [30:19<34:38,  5.58it/s, lr=0.000425, step_loss=0.060207/27/2023 18:15:09 - INFO - __main__ - train loss is 10.898233306594193\n",
      "Steps:  23%|▏| 3410/15000 [30:19<34:37,  5.58it/s, lr=0.000425, step_loss=0.012507/27/2023 18:15:09 - INFO - __main__ - train loss is 10.961951267905533\n",
      "Steps:  23%|▏| 3411/15000 [30:19<34:37,  5.58it/s, lr=0.000425, step_loss=0.063707/27/2023 18:15:09 - INFO - __main__ - train loss is 11.128406521864235\n",
      "Steps:  23%|▏| 3412/15000 [30:20<34:36,  5.58it/s, lr=0.000425, step_loss=0.166]07/27/2023 18:15:09 - INFO - __main__ - train loss is 11.62703984696418\n",
      "Steps:  23%|▏| 3413/15000 [30:20<34:35,  5.58it/s, lr=0.000425, step_loss=0.499]07/27/2023 18:15:10 - INFO - __main__ - train loss is 12.241469201631844\n",
      "Steps:  23%|▏| 3414/15000 [30:20<34:35,  5.58it/s, lr=0.000425, step_loss=0.614]07/27/2023 18:15:10 - INFO - __main__ - train loss is 12.45841094572097\n",
      "Steps:  23%|▏| 3415/15000 [30:20<34:35,  5.58it/s, lr=0.000425, step_loss=0.217]07/27/2023 18:15:10 - INFO - __main__ - train loss is 12.542267111130059\n",
      "Steps:  23%|▏| 3416/15000 [30:20<34:35,  5.58it/s, lr=0.000425, step_loss=0.083907/27/2023 18:15:10 - INFO - __main__ - train loss is 12.803028550930321\n",
      "Steps:  23%|▏| 3417/15000 [30:20<34:35,  5.58it/s, lr=0.000425, step_loss=0.261]07/27/2023 18:15:10 - INFO - __main__ - train loss is 12.992783677764237\n",
      "Steps:  23%|▍ | 3418/15000 [30:21<34:34,  5.58it/s, lr=0.000426, step_loss=0.19]07/27/2023 18:15:10 - INFO - __main__ - train loss is 13.160820555873215\n",
      "Steps:  23%|▏| 3419/15000 [30:21<34:33,  5.59it/s, lr=0.000426, step_loss=0.168]07/27/2023 18:15:11 - INFO - __main__ - train loss is 13.500741702504456\n",
      "Steps:  23%|▍ | 3420/15000 [30:21<34:32,  5.59it/s, lr=0.000426, step_loss=0.34]07/27/2023 18:15:11 - INFO - __main__ - train loss is 13.680121359415352\n",
      "Steps:  23%|▏| 3421/15000 [30:21<34:32,  5.59it/s, lr=0.000426, step_loss=0.179]07/27/2023 18:15:11 - INFO - __main__ - train loss is 14.036105957813561\n",
      "Steps:  23%|▏| 3422/15000 [30:21<34:31,  5.59it/s, lr=0.000426, step_loss=0.356]07/27/2023 18:15:11 - INFO - __main__ - train loss is 14.111076180823147\n",
      "Steps:  23%|▏| 3423/15000 [30:22<34:32,  5.59it/s, lr=0.000426, step_loss=0.075]07/27/2023 18:15:11 - INFO - __main__ - train loss is 14.118743307888508\n",
      "Steps:  23%|▏| 3424/15000 [30:22<34:32,  5.59it/s, lr=0.000426, step_loss=0.007607/27/2023 18:15:12 - INFO - __main__ - train loss is 14.124847133643925\n",
      "Steps:  23%|▏| 3425/15000 [30:22<34:32,  5.59it/s, lr=0.000427, step_loss=0.006107/27/2023 18:15:12 - INFO - __main__ - train loss is 14.210058172233403\n",
      "Steps:  23%|▏| 3426/15000 [30:22<34:31,  5.59it/s, lr=0.000427, step_loss=0.085207/27/2023 18:15:12 - INFO - __main__ - train loss is 14.227818571962416\n",
      "Steps:  23%|▏| 3427/15000 [30:22<34:33,  5.58it/s, lr=0.000427, step_loss=0.017807/27/2023 18:15:12 - INFO - __main__ - train loss is 14.239992056973279\n",
      "Steps:  23%|▏| 3428/15000 [30:22<34:32,  5.58it/s, lr=0.000427, step_loss=0.012207/27/2023 18:15:12 - INFO - __main__ - train loss is 14.26779895927757\n",
      "Steps:  23%|▏| 3429/15000 [30:23<34:32,  5.58it/s, lr=0.000427, step_loss=0.027807/27/2023 18:15:12 - INFO - __main__ - train loss is 14.274060142226517\n",
      "Steps:  23%|▏| 3430/15000 [30:23<34:32,  5.58it/s, lr=0.000427, step_loss=0.006207/27/2023 18:15:13 - INFO - __main__ - train loss is 14.30063755530864\n",
      "Steps:  23%|▏| 3431/15000 [30:23<34:33,  5.58it/s, lr=0.000427, step_loss=0.026607/27/2023 18:15:13 - INFO - __main__ - train loss is 14.378627178259194\n",
      "Steps:  23%|▏| 3432/15000 [30:23<34:34,  5.58it/s, lr=0.000427, step_loss=0.078]07/27/2023 18:15:13 - INFO - __main__ - train loss is 14.404664953239262\n",
      "Steps:  23%|▏| 3433/15000 [30:23<34:42,  5.55it/s, lr=0.000427, step_loss=0.026]07/27/2023 18:15:13 - INFO - __main__ - train loss is 14.446335230953991\n",
      "Steps:  23%|▏| 3434/15000 [30:23<34:59,  5.51it/s, lr=0.000428, step_loss=0.041707/27/2023 18:15:13 - INFO - __main__ - train loss is 14.507115018554032\n",
      "Steps:  23%|▏| 3435/15000 [30:24<34:57,  5.51it/s, lr=0.000428, step_loss=0.060807/27/2023 18:15:14 - INFO - __main__ - train loss is 14.71410393435508\n",
      "Steps:  23%|▏| 3436/15000 [30:24<34:48,  5.54it/s, lr=0.000428, step_loss=0.207]07/27/2023 18:15:14 - INFO - __main__ - train loss is 14.748506830073893\n",
      "Steps:  23%|▏| 3437/15000 [30:24<34:42,  5.55it/s, lr=0.000428, step_loss=0.034407/27/2023 18:15:14 - INFO - __main__ - train loss is 14.802727540023625\n",
      "Steps:  23%|▏| 3438/15000 [30:24<34:39,  5.56it/s, lr=0.000428, step_loss=0.054207/27/2023 18:15:14 - INFO - __main__ - train loss is 14.809655787423253\n",
      "Steps:  23%|▏| 3439/15000 [30:24<34:36,  5.57it/s, lr=0.000428, step_loss=0.006907/27/2023 18:15:14 - INFO - __main__ - train loss is 14.812940143514425\n",
      "Steps:  23%|▏| 3440/15000 [30:25<34:33,  5.57it/s, lr=0.000428, step_loss=0.003207/27/2023 18:15:14 - INFO - __main__ - train loss is 14.851132803130895\n",
      "Steps:  23%|▏| 3441/15000 [30:25<34:33,  5.57it/s, lr=0.000429, step_loss=0.038207/27/2023 18:15:15 - INFO - __main__ - train loss is 14.978505544830114\n",
      "Steps:  23%|▏| 3442/15000 [30:25<34:31,  5.58it/s, lr=0.000429, step_loss=0.127]07/27/2023 18:15:15 - INFO - __main__ - train loss is 15.008097162935883\n",
      "Steps:  23%|▏| 3443/15000 [30:25<34:31,  5.58it/s, lr=0.000429, step_loss=0.029607/27/2023 18:15:15 - INFO - __main__ - train loss is 15.010920115048066\n",
      "Steps:  23%|▏| 3444/15000 [30:25<34:30,  5.58it/s, lr=0.000429, step_loss=0.002807/27/2023 18:15:15 - INFO - __main__ - train loss is 15.01761777116917\n",
      "Steps:  23%|▏| 3445/15000 [30:25<34:30,  5.58it/s, lr=0.000429, step_loss=0.006707/27/2023 18:15:15 - INFO - __main__ - train loss is 15.029960119863972\n",
      "Steps:  23%|▏| 3446/15000 [30:26<34:29,  5.58it/s, lr=0.000429, step_loss=0.012307/27/2023 18:15:15 - INFO - __main__ - train loss is 15.03304503322579\n",
      "Steps:  23%|▏| 3447/15000 [30:26<34:29,  5.58it/s, lr=0.000429, step_loss=0.003007/27/2023 18:15:16 - INFO - __main__ - train loss is 15.037916901754215\n",
      "Steps:  23%|▏| 3448/15000 [30:26<34:29,  5.58it/s, lr=0.000429, step_loss=0.004807/27/2023 18:15:16 - INFO - __main__ - train loss is 15.668384495424107\n",
      "Steps:  23%|▍ | 3449/15000 [30:26<34:29,  5.58it/s, lr=0.000429, step_loss=0.63]07/27/2023 18:15:16 - INFO - __main__ - train loss is 15.687706831144169\n",
      "Steps:  23%|▏| 3450/15000 [30:26<34:28,  5.58it/s, lr=0.00043, step_loss=0.0193]07/27/2023 18:15:16 - INFO - __main__ - train loss is 15.72096114908345\n",
      "Steps:  23%|▏| 3451/15000 [30:27<34:28,  5.58it/s, lr=0.00043, step_loss=0.0333]07/27/2023 18:15:16 - INFO - __main__ - train loss is 15.7480565153528\n",
      "Steps:  23%|▏| 3452/15000 [30:27<34:29,  5.58it/s, lr=0.00043, step_loss=0.0271]07/27/2023 18:15:17 - INFO - __main__ - train loss is 16.15756632317789\n",
      "Steps:  23%|▋  | 3453/15000 [30:27<34:29,  5.58it/s, lr=0.00043, step_loss=0.41]07/27/2023 18:15:17 - INFO - __main__ - train loss is 16.17910201777704\n",
      "Steps:  23%|▏| 3454/15000 [30:27<34:28,  5.58it/s, lr=0.00043, step_loss=0.0215]07/27/2023 18:15:17 - INFO - __main__ - train loss is 16.354778005974367\n",
      "Steps:  23%|▍ | 3455/15000 [30:27<34:27,  5.58it/s, lr=0.00043, step_loss=0.176]07/27/2023 18:15:17 - INFO - __main__ - train loss is 16.383848942117766\n",
      "Steps:  23%|▏| 3456/15000 [30:27<34:27,  5.58it/s, lr=0.00043, step_loss=0.0291]07/27/2023 18:15:17 - INFO - __main__ - train loss is 16.386758057167754\n",
      "Steps:  23%|▏| 3457/15000 [30:28<34:26,  5.59it/s, lr=0.000431, step_loss=0.002907/27/2023 18:15:17 - INFO - __main__ - train loss is 16.39995397790335\n",
      "Steps:  23%|▏| 3458/15000 [30:28<34:26,  5.58it/s, lr=0.000431, step_loss=0.013207/27/2023 18:15:18 - INFO - __main__ - train loss is 16.905682818731293\n",
      "Steps:  23%|▏| 3459/15000 [30:28<34:26,  5.58it/s, lr=0.000431, step_loss=0.506]07/27/2023 18:15:18 - INFO - __main__ - train loss is 16.95506559847854\n",
      "Steps:  23%|▏| 3460/15000 [30:28<34:25,  5.59it/s, lr=0.000431, step_loss=0.049407/27/2023 18:15:18 - INFO - __main__ - train loss is 17.083709155907854\n",
      "Steps:  23%|▏| 3461/15000 [30:28<34:25,  5.59it/s, lr=0.000431, step_loss=0.129]07/27/2023 18:15:18 - INFO - __main__ - train loss is 17.409174209227785\n",
      "Steps:  23%|▏| 3462/15000 [30:28<34:25,  5.59it/s, lr=0.000431, step_loss=0.325]07/27/2023 18:15:18 - INFO - __main__ - train loss is 17.44108640938066\n",
      "Steps:  23%|▏| 3463/15000 [30:29<34:26,  5.58it/s, lr=0.000431, step_loss=0.031907/27/2023 18:15:19 - INFO - __main__ - train loss is 17.45338874286972\n",
      "Steps:  23%|▏| 3464/15000 [30:29<34:25,  5.59it/s, lr=0.000431, step_loss=0.012307/27/2023 18:15:19 - INFO - __main__ - train loss is 17.463527722051367\n",
      "Steps:  23%|▏| 3465/15000 [30:29<34:24,  5.59it/s, lr=0.000432, step_loss=0.010107/27/2023 18:15:19 - INFO - __main__ - train loss is 17.49425715743564\n",
      "Steps:  23%|▏| 3466/15000 [30:29<34:24,  5.59it/s, lr=0.000432, step_loss=0.030707/27/2023 18:15:19 - INFO - __main__ - train loss is 17.784892802825198\n",
      "Steps:  23%|▏| 3467/15000 [30:29<34:47,  5.53it/s, lr=0.000432, step_loss=0.291]07/27/2023 18:15:19 - INFO - __main__ - train loss is 17.786440320778638\n",
      "Steps:  23%|▏| 3468/15000 [30:30<35:21,  5.44it/s, lr=0.000432, step_loss=0.001507/27/2023 18:15:19 - INFO - __main__ - train loss is 17.869637176860124\n",
      "Steps:  23%|▏| 3469/15000 [30:30<35:06,  5.48it/s, lr=0.000432, step_loss=0.083207/27/2023 18:15:20 - INFO - __main__ - train loss is 17.874957758933306\n",
      "Steps:  23%|▏| 3470/15000 [30:30<34:54,  5.51it/s, lr=0.000432, step_loss=0.005307/27/2023 18:15:20 - INFO - __main__ - train loss is 17.876070512342267\n",
      "Steps:  23%|▏| 3471/15000 [30:30<34:49,  5.52it/s, lr=0.000432, step_loss=0.001107/27/2023 18:15:20 - INFO - __main__ - train loss is 18.118245733785443\n",
      "Steps:  23%|▏| 3472/15000 [30:30<34:43,  5.53it/s, lr=0.000432, step_loss=0.242]07/27/2023 18:15:20 - INFO - __main__ - train loss is 18.21853306691628\n",
      "Steps:  23%|▋  | 3473/15000 [30:30<34:37,  5.55it/s, lr=0.000432, step_loss=0.1]07/27/2023 18:15:20 - INFO - __main__ - train loss is 18.625297276186757\n",
      "Steps:  23%|▏| 3474/15000 [30:31<34:34,  5.56it/s, lr=0.000433, step_loss=0.407]07/27/2023 18:15:21 - INFO - __main__ - train loss is 18.65498487080913\n",
      "Steps:  23%|▏| 3475/15000 [30:31<34:31,  5.56it/s, lr=0.000433, step_loss=0.029707/27/2023 18:15:21 - INFO - __main__ - train loss is 18.803754338878207\n",
      "Steps:  23%|▏| 3476/15000 [30:31<34:29,  5.57it/s, lr=0.000433, step_loss=0.149]07/27/2023 18:15:21 - INFO - __main__ - train loss is 19.272593894856982\n",
      "Steps:  23%|▏| 3477/15000 [30:31<34:28,  5.57it/s, lr=0.000433, step_loss=0.469]07/27/2023 18:15:21 - INFO - __main__ - train loss is 19.283175572636537\n",
      "Steps:  23%|▏| 3478/15000 [30:31<34:27,  5.57it/s, lr=0.000433, step_loss=0.010607/27/2023 18:15:21 - INFO - __main__ - train loss is 19.357914797845297\n",
      "Steps:  23%|▏| 3479/15000 [30:32<34:27,  5.57it/s, lr=0.000433, step_loss=0.074707/27/2023 18:15:21 - INFO - __main__ - train loss is 19.38955087575596\n",
      "Steps:  23%|▏| 3480/15000 [30:32<34:26,  5.57it/s, lr=0.000433, step_loss=0.031607/27/2023 18:15:22 - INFO - __main__ - train loss is 19.614653762313537\n",
      "Steps:  23%|▏| 3481/15000 [30:32<34:26,  5.57it/s, lr=0.000434, step_loss=0.225]07/27/2023 18:15:22 - INFO - __main__ - train loss is 19.632997630047612\n",
      "Steps:  23%|▏| 3482/15000 [30:32<34:25,  5.58it/s, lr=0.000434, step_loss=0.018307/27/2023 18:15:22 - INFO - __main__ - train loss is 19.643814542214386\n",
      "Steps:  23%|▏| 3483/15000 [30:32<34:24,  5.58it/s, lr=0.000434, step_loss=0.010807/27/2023 18:15:22 - INFO - __main__ - train loss is 19.950967022101395\n",
      "Steps:  23%|▏| 3484/15000 [30:32<34:24,  5.58it/s, lr=0.000434, step_loss=0.307]07/27/2023 18:15:22 - INFO - __main__ - train loss is 20.09877052239608\n",
      "Steps:  23%|▏| 3485/15000 [30:33<34:24,  5.58it/s, lr=0.000434, step_loss=0.148]07/27/2023 18:15:23 - INFO - __main__ - train loss is 20.22714842192363\n",
      "Steps:  23%|▏| 3486/15000 [30:33<34:27,  5.57it/s, lr=0.000434, step_loss=0.128]07/27/2023 18:15:23 - INFO - __main__ - train loss is 20.421823047916405\n",
      "Steps:  23%|▏| 3487/15000 [30:33<34:30,  5.56it/s, lr=0.000434, step_loss=0.195]07/27/2023 18:15:23 - INFO - __main__ - train loss is 20.770409577409737\n",
      "Steps:  23%|▏| 3488/15000 [30:33<34:27,  5.57it/s, lr=0.000434, step_loss=0.349]07/27/2023 18:15:23 - INFO - __main__ - train loss is 20.771405966370367\n",
      "Steps:  23%|▏| 3489/15000 [30:33<34:25,  5.57it/s, lr=0.000434, step_loss=0.000907/27/2023 18:15:23 - INFO - __main__ - train loss is 20.824317564605735\n",
      "Steps:  23%|▏| 3490/15000 [30:34<34:24,  5.58it/s, lr=0.000435, step_loss=0.052907/27/2023 18:15:23 - INFO - __main__ - train loss is 20.831208312767558\n",
      "Steps:  23%|▏| 3491/15000 [30:34<34:23,  5.58it/s, lr=0.000435, step_loss=0.006807/27/2023 18:15:24 - INFO - __main__ - train loss is 20.83329758036416\n",
      "Steps:  23%|▏| 3492/15000 [30:34<34:23,  5.58it/s, lr=0.000435, step_loss=0.002007/27/2023 18:15:24 - INFO - __main__ - train loss is 21.10372126090806\n",
      "Steps:  23%|▍ | 3493/15000 [30:34<34:23,  5.58it/s, lr=0.000435, step_loss=0.27]07/27/2023 18:15:24 - INFO - __main__ - train loss is 21.10897642641794\n",
      "Steps:  23%|▏| 3494/15000 [30:34<34:22,  5.58it/s, lr=0.000435, step_loss=0.005207/27/2023 18:15:24 - INFO - __main__ - train loss is 21.2656602737261\n",
      "Steps:  23%|▏| 3495/15000 [30:34<34:22,  5.58it/s, lr=0.000435, step_loss=0.157]07/27/2023 18:15:24 - INFO - __main__ - train loss is 21.5021309730364\n",
      "Steps:  23%|▏| 3496/15000 [30:35<34:21,  5.58it/s, lr=0.000435, step_loss=0.236]07/27/2023 18:15:24 - INFO - __main__ - train loss is 21.511347405496053\n",
      "Steps:  23%|▏| 3497/15000 [30:35<34:21,  5.58it/s, lr=0.000436, step_loss=0.009207/27/2023 18:15:25 - INFO - __main__ - train loss is 21.75651187438052\n",
      "Steps:  23%|▏| 3498/15000 [30:35<34:21,  5.58it/s, lr=0.000436, step_loss=0.245]07/27/2023 18:15:25 - INFO - __main__ - train loss is 21.805095240357332\n",
      "Steps:  23%|▏| 3499/15000 [30:35<34:21,  5.58it/s, lr=0.000436, step_loss=0.048607/27/2023 18:15:25 - INFO - __main__ - train loss is 21.906421139719896\n",
      "Steps:  23%|▏| 3500/15000 [30:35<34:21,  5.58it/s, lr=0.000436, step_loss=0.048607/27/2023 18:15:25 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-3500\n",
      "07/27/2023 18:15:25 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:15:25,606] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:15:25,611] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-3500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:15:25,611] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-3500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:15:25,617] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-3500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:15:25,617] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-3500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:15:25,624] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-3500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:15:25,624] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-3500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:15:25,624] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:15:25 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-3500/pytorch_model\n",
      "07/27/2023 18:15:25 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-3500/scheduler.bin\n",
      "07/27/2023 18:15:25 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-3500/random_states_0.pkl\n",
      "07/27/2023 18:15:25 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-3500\n",
      "Steps:  23%|▏| 3500/15000 [30:35<34:21,  5.58it/s, lr=0.000436, step_loss=0.101]07/27/2023 18:15:25 - INFO - __main__ - train loss is 21.910109000396915\n",
      "Steps:  23%|▏| 3501/15000 [30:36<35:28,  5.40it/s, lr=0.000436, step_loss=0.003607/27/2023 18:15:25 - INFO - __main__ - train loss is 22.171299623441882\n",
      "Steps:  23%|▏| 3502/15000 [30:36<35:07,  5.46it/s, lr=0.000436, step_loss=0.261]07/27/2023 18:15:26 - INFO - __main__ - train loss is 22.20673555706162\n",
      "Steps:  23%|▏| 3503/15000 [30:36<34:53,  5.49it/s, lr=0.000436, step_loss=0.035407/27/2023 18:15:26 - INFO - __main__ - train loss is 22.209107953705825\n",
      "Steps:  23%|▏| 3504/15000 [30:36<34:43,  5.52it/s, lr=0.000436, step_loss=0.002307/27/2023 18:15:26 - INFO - __main__ - train loss is 22.416568789281882\n",
      "Steps:  23%|▏| 3505/15000 [30:36<34:37,  5.53it/s, lr=0.000436, step_loss=0.207]07/27/2023 18:15:26 - INFO - __main__ - train loss is 22.657404813566245\n",
      "Steps:  23%|▏| 3506/15000 [30:36<34:33,  5.54it/s, lr=0.000437, step_loss=0.241]07/27/2023 18:15:26 - INFO - __main__ - train loss is 22.70562839473132\n",
      "Steps:  23%|▏| 3507/15000 [30:37<34:29,  5.55it/s, lr=0.000437, step_loss=0.048207/27/2023 18:15:26 - INFO - __main__ - train loss is 22.71724747272674\n",
      "Steps:  23%|▏| 3508/15000 [30:37<34:26,  5.56it/s, lr=0.000437, step_loss=0.011607/27/2023 18:15:27 - INFO - __main__ - train loss is 22.730774765484966\n",
      "Steps:  23%|▏| 3509/15000 [30:37<34:24,  5.57it/s, lr=0.000437, step_loss=0.013507/27/2023 18:15:27 - INFO - __main__ - train loss is 22.847315674298443\n",
      "Steps:  23%|▏| 3510/15000 [30:37<34:23,  5.57it/s, lr=0.000437, step_loss=0.117]07/27/2023 18:15:27 - INFO - __main__ - train loss is 23.015037303441204\n",
      "Steps:  23%|▏| 3511/15000 [30:37<34:23,  5.57it/s, lr=0.000437, step_loss=0.168]07/27/2023 18:15:27 - INFO - __main__ - train loss is 23.151645129197277\n",
      "Steps:  23%|▏| 3512/15000 [30:38<34:45,  5.51it/s, lr=0.000437, step_loss=0.137]07/27/2023 18:15:27 - INFO - __main__ - train loss is 23.25663360732142\n",
      "Steps:  23%|▏| 3513/15000 [30:38<34:58,  5.47it/s, lr=0.000438, step_loss=0.105]07/27/2023 18:15:28 - INFO - __main__ - train loss is 23.515992788248695\n",
      "Steps:  23%|▏| 3514/15000 [30:38<35:08,  5.45it/s, lr=0.000438, step_loss=0.259]07/27/2023 18:15:28 - INFO - __main__ - train loss is 23.73462375777308\n",
      "Steps:  23%|▏| 3515/15000 [30:38<35:05,  5.46it/s, lr=0.000438, step_loss=0.219]07/27/2023 18:15:28 - INFO - __main__ - train loss is 24.22497033851687\n",
      "Steps:  23%|▍ | 3516/15000 [30:38<35:04,  5.46it/s, lr=0.000438, step_loss=0.49]07/27/2023 18:15:28 - INFO - __main__ - train loss is 24.435200957232155\n",
      "Steps:  23%|▍ | 3517/15000 [30:38<35:05,  5.45it/s, lr=0.000438, step_loss=0.21]07/27/2023 18:15:28 - INFO - __main__ - train loss is 24.588237044983543\n",
      "Steps:  23%|▏| 3518/15000 [30:39<35:07,  5.45it/s, lr=0.000438, step_loss=0.153]07/27/2023 18:15:28 - INFO - __main__ - train loss is 24.774597895913757\n",
      "Steps:  23%|▏| 3519/15000 [30:39<35:27,  5.40it/s, lr=0.000438, step_loss=0.186]07/27/2023 18:15:29 - INFO - __main__ - train loss is 25.178729010396637\n",
      "Steps:  23%|▏| 3520/15000 [30:39<36:03,  5.31it/s, lr=0.000438, step_loss=0.404]07/27/2023 18:15:29 - INFO - __main__ - train loss is 25.192565885954536\n",
      "Steps:  23%|▏| 3521/15000 [30:39<36:24,  5.26it/s, lr=0.000439, step_loss=0.013807/27/2023 18:15:29 - INFO - __main__ - train loss is 25.788076487951912\n",
      "Steps:  23%|▏| 3522/15000 [30:39<36:39,  5.22it/s, lr=0.000439, step_loss=0.596]07/27/2023 18:15:29 - INFO - __main__ - train loss is 25.851140064769424\n",
      "Steps:  23%|▏| 3523/15000 [30:40<36:56,  5.18it/s, lr=0.000439, step_loss=0.063107/27/2023 18:15:29 - INFO - __main__ - train loss is 26.04144613223616\n",
      "Steps:  23%|▍ | 3524/15000 [30:40<37:00,  5.17it/s, lr=0.000439, step_loss=0.19]07/27/2023 18:15:30 - INFO - __main__ - train loss is 26.076395274722017\n",
      "Steps:  24%|▏| 3525/15000 [30:40<37:03,  5.16it/s, lr=0.000439, step_loss=0.034907/27/2023 18:15:30 - INFO - __main__ - train loss is 26.078447315259837\n",
      "Steps:  24%|▏| 3526/15000 [30:40<37:11,  5.14it/s, lr=0.000439, step_loss=0.002007/27/2023 18:15:30 - INFO - __main__ - train loss is 26.081118845264427\n",
      "Steps:  24%|▏| 3527/15000 [30:40<37:13,  5.14it/s, lr=0.000439, step_loss=0.002607/27/2023 18:15:30 - INFO - __main__ - train loss is 26.139944084803574\n",
      "Steps:  24%|▏| 3528/15000 [30:41<37:12,  5.14it/s, lr=0.000439, step_loss=0.058807/27/2023 18:15:30 - INFO - __main__ - train loss is 26.70002932182979\n",
      "Steps:  24%|▋  | 3529/15000 [30:41<37:10,  5.14it/s, lr=0.00044, step_loss=0.56]07/27/2023 18:15:31 - INFO - __main__ - train loss is 26.892798312823288\n",
      "Steps:  24%|▍ | 3530/15000 [30:41<36:25,  5.25it/s, lr=0.00044, step_loss=0.193]07/27/2023 18:15:31 - INFO - __main__ - train loss is 27.00194580189418\n",
      "Steps:  24%|▍ | 3531/15000 [30:41<35:47,  5.34it/s, lr=0.00044, step_loss=0.109]07/27/2023 18:15:31 - INFO - __main__ - train loss is 27.006614730576985\n",
      "Steps:  24%|▏| 3532/15000 [30:41<35:19,  5.41it/s, lr=0.00044, step_loss=0.0046707/27/2023 18:15:31 - INFO - __main__ - train loss is 27.154954508761875\n",
      "Steps:  24%|▍ | 3533/15000 [30:41<35:01,  5.46it/s, lr=0.00044, step_loss=0.148]07/27/2023 18:15:31 - INFO - __main__ - train loss is 27.181246061692946\n",
      "Steps:  24%|▏| 3534/15000 [30:42<34:46,  5.49it/s, lr=0.00044, step_loss=0.0263]07/27/2023 18:15:32 - INFO - __main__ - train loss is 27.30189291096758\n",
      "Steps:  24%|▍ | 3535/15000 [30:42<34:38,  5.52it/s, lr=0.00044, step_loss=0.121]07/27/2023 18:15:32 - INFO - __main__ - train loss is 27.308230093563907\n",
      "Steps:  24%|▏| 3536/15000 [30:42<34:30,  5.54it/s, lr=0.00044, step_loss=0.0063407/27/2023 18:15:32 - INFO - __main__ - train loss is 27.310976646724157\n",
      "Steps:  24%|▏| 3537/15000 [30:42<34:26,  5.55it/s, lr=0.000441, step_loss=0.002707/27/2023 18:15:32 - INFO - __main__ - train loss is 27.345671210321598\n",
      "Steps:  24%|▏| 3538/15000 [30:42<34:22,  5.56it/s, lr=0.000441, step_loss=0.034707/27/2023 18:15:32 - INFO - __main__ - train loss is 27.395915929111652\n",
      "Steps:  24%|▏| 3539/15000 [30:43<34:20,  5.56it/s, lr=0.000441, step_loss=0.050207/27/2023 18:15:32 - INFO - __main__ - train loss is 27.482695598038845\n",
      "Steps:  24%|▏| 3540/15000 [30:43<34:17,  5.57it/s, lr=0.000441, step_loss=0.086807/27/2023 18:15:33 - INFO - __main__ - train loss is 27.72275652352255\n",
      "Steps:  24%|▍ | 3541/15000 [30:43<34:17,  5.57it/s, lr=0.000441, step_loss=0.24]07/27/2023 18:15:33 - INFO - __main__ - train loss is 27.74781278136652\n",
      "Steps:  24%|▏| 3542/15000 [30:43<34:16,  5.57it/s, lr=0.000441, step_loss=0.025107/27/2023 18:15:33 - INFO - __main__ - train loss is 28.169836375745945\n",
      "Steps:  24%|▏| 3543/15000 [30:43<34:16,  5.57it/s, lr=0.000441, step_loss=0.422]07/27/2023 18:15:33 - INFO - __main__ - train loss is 28.183647865313105\n",
      "Steps:  24%|▏| 3544/15000 [30:43<34:21,  5.56it/s, lr=0.000441, step_loss=0.013807/27/2023 18:15:33 - INFO - __main__ - train loss is 28.189055696944706\n",
      "Steps:  24%|▏| 3545/15000 [30:44<34:19,  5.56it/s, lr=0.000441, step_loss=0.005407/27/2023 18:15:33 - INFO - __main__ - train loss is 28.197268098476343\n",
      "Steps:  24%|▏| 3546/15000 [30:44<34:16,  5.57it/s, lr=0.000442, step_loss=0.008207/27/2023 18:15:34 - INFO - __main__ - train loss is 28.216304380330257\n",
      "Steps:  24%|▏| 3547/15000 [30:44<34:33,  5.52it/s, lr=0.000442, step_loss=0.019]07/27/2023 18:15:34 - INFO - __main__ - train loss is 28.363075215253048\n",
      "Steps:  24%|▏| 3548/15000 [30:44<34:40,  5.51it/s, lr=0.000442, step_loss=0.147]07/27/2023 18:15:34 - INFO - __main__ - train loss is 28.50532609585207\n",
      "Steps:  24%|▏| 3549/15000 [30:44<34:40,  5.51it/s, lr=0.000442, step_loss=0.142]07/27/2023 18:15:34 - INFO - __main__ - train loss is 29.256843272480182\n",
      "Steps:  24%|▏| 3550/15000 [30:45<34:51,  5.47it/s, lr=0.000442, step_loss=0.752]07/27/2023 18:15:34 - INFO - __main__ - train loss is 29.33391094568651\n",
      "Steps:  24%|▏| 3551/15000 [30:45<34:52,  5.47it/s, lr=0.000442, step_loss=0.077107/27/2023 18:15:35 - INFO - __main__ - train loss is 29.445861328276806\n",
      "Steps:  24%|▏| 3552/15000 [30:45<34:55,  5.46it/s, lr=0.000442, step_loss=0.112]07/27/2023 18:15:35 - INFO - __main__ - train loss is 29.452135697822087\n",
      "Steps:  24%|▏| 3553/15000 [30:45<34:59,  5.45it/s, lr=0.000443, step_loss=0.006207/27/2023 18:15:35 - INFO - __main__ - train loss is 29.454416938009672\n",
      "Steps:  24%|▏| 3554/15000 [30:45<34:46,  5.48it/s, lr=0.000443, step_loss=0.002207/27/2023 18:15:35 - INFO - __main__ - train loss is 29.9426351262955\n",
      "Steps:  24%|▏| 3555/15000 [30:45<34:38,  5.51it/s, lr=0.000443, step_loss=0.488]07/27/2023 18:15:35 - INFO - __main__ - train loss is 29.969464331748895\n",
      "Steps:  24%|▏| 3556/15000 [30:46<34:43,  5.49it/s, lr=0.000443, step_loss=0.026807/27/2023 18:15:36 - INFO - __main__ - train loss is 29.970613256446086\n",
      "Steps:  24%|▏| 3557/15000 [30:46<34:34,  5.52it/s, lr=0.000443, step_loss=0.001107/27/2023 18:15:36 - INFO - __main__ - train loss is 29.975325083709322\n",
      "Steps:  24%|▏| 3558/15000 [30:46<34:27,  5.54it/s, lr=0.000443, step_loss=0.004707/27/2023 18:15:36 - INFO - __main__ - train loss is 30.017873002565466\n",
      "Steps:  24%|▏| 3559/15000 [30:46<34:22,  5.55it/s, lr=0.000443, step_loss=0.042507/27/2023 18:15:36 - INFO - __main__ - train loss is 30.08296149817761\n",
      "Steps:  24%|▏| 3560/15000 [30:46<34:19,  5.56it/s, lr=0.000443, step_loss=0.065107/27/2023 18:15:36 - INFO - __main__ - train loss is 30.08949171740096\n",
      "Steps:  24%|▏| 3561/15000 [30:47<34:19,  5.56it/s, lr=0.000443, step_loss=0.006507/27/2023 18:15:36 - INFO - __main__ - train loss is 30.16916804003995\n",
      "Steps:  24%|▏| 3562/15000 [30:47<34:16,  5.56it/s, lr=0.000444, step_loss=0.079707/27/2023 18:15:37 - INFO - __main__ - train loss is 30.18366657930892\n",
      "Steps:  24%|▏| 3563/15000 [30:47<34:19,  5.55it/s, lr=0.000444, step_loss=0.014507/27/2023 18:15:37 - INFO - __main__ - train loss is 30.56548642355483\n",
      "Steps:  24%|▏| 3564/15000 [30:47<34:15,  5.56it/s, lr=0.000444, step_loss=0.382]07/27/2023 18:15:37 - INFO - __main__ - train loss is 30.571590596227907\n",
      "Steps:  24%|▏| 3565/15000 [30:47<34:14,  5.57it/s, lr=0.000444, step_loss=0.006107/27/2023 18:15:37 - INFO - __main__ - train loss is 31.143474870710634\n",
      "Steps:  24%|▏| 3566/15000 [30:47<34:13,  5.57it/s, lr=0.000444, step_loss=0.572]07/27/2023 18:15:37 - INFO - __main__ - train loss is 31.15365960111376\n",
      "Steps:  24%|▏| 3567/15000 [30:48<34:14,  5.56it/s, lr=0.000444, step_loss=0.010207/27/2023 18:15:37 - INFO - __main__ - train loss is 31.401377309462987\n",
      "Steps:  24%|▏| 3568/15000 [30:48<34:14,  5.56it/s, lr=0.000444, step_loss=0.248]07/27/2023 18:15:38 - INFO - __main__ - train loss is 31.432681057951413\n",
      "Steps:  24%|▏| 3569/15000 [30:48<34:14,  5.56it/s, lr=0.000445, step_loss=0.031307/27/2023 18:15:38 - INFO - __main__ - train loss is 31.54615287145134\n",
      "Steps:  24%|▏| 3570/15000 [30:48<34:13,  5.57it/s, lr=0.000445, step_loss=0.113]07/27/2023 18:15:38 - INFO - __main__ - train loss is 31.687935691676103\n",
      "Steps:  24%|▏| 3571/15000 [30:48<34:14,  5.56it/s, lr=0.000445, step_loss=0.142]07/27/2023 18:15:38 - INFO - __main__ - train loss is 31.802645881078206\n",
      "Steps:  24%|▏| 3572/15000 [30:49<34:12,  5.57it/s, lr=0.000445, step_loss=0.115]07/27/2023 18:15:38 - INFO - __main__ - train loss is 31.88244869222399\n",
      "Steps:  24%|▏| 3573/15000 [30:49<34:12,  5.57it/s, lr=0.000445, step_loss=0.079807/27/2023 18:15:39 - INFO - __main__ - train loss is 31.93398908933159\n",
      "Steps:  24%|▏| 3574/15000 [30:49<34:19,  5.55it/s, lr=0.000445, step_loss=0.051507/27/2023 18:15:39 - INFO - __main__ - train loss is 31.938162973965518\n",
      "Steps:  24%|▏| 3575/15000 [30:49<34:17,  5.55it/s, lr=0.000445, step_loss=0.004107/27/2023 18:15:39 - INFO - __main__ - train loss is 31.958606638829224\n",
      "Steps:  24%|▏| 3576/15000 [30:49<34:15,  5.56it/s, lr=0.000445, step_loss=0.020407/27/2023 18:15:39 - INFO - __main__ - train loss is 31.962105726241134\n",
      "Steps:  24%|▏| 3577/15000 [30:49<34:14,  5.56it/s, lr=0.000446, step_loss=0.003507/27/2023 18:15:39 - INFO - __main__ - train loss is 32.03666271769907\n",
      "Steps:  24%|▏| 3578/15000 [30:50<34:11,  5.57it/s, lr=0.000446, step_loss=0.074607/27/2023 18:15:39 - INFO - __main__ - train loss is 32.40834685170557\n",
      "Steps:  24%|▏| 3579/15000 [30:50<34:13,  5.56it/s, lr=0.000446, step_loss=0.372]07/27/2023 18:15:40 - INFO - __main__ - train loss is 32.47536419832613\n",
      "Steps:  24%|▏| 3580/15000 [30:50<34:10,  5.57it/s, lr=0.000446, step_loss=0.067]07/27/2023 18:15:40 - INFO - __main__ - train loss is 32.49680132546928\n",
      "Steps:  24%|▏| 3581/15000 [30:50<34:10,  5.57it/s, lr=0.000446, step_loss=0.021407/27/2023 18:15:40 - INFO - __main__ - train loss is 32.49909278785344\n",
      "Steps:  24%|▏| 3582/15000 [30:50<34:14,  5.56it/s, lr=0.000446, step_loss=0.002207/27/2023 18:15:40 - INFO - __main__ - train loss is 32.61151698266622\n",
      "Steps:  24%|▏| 3583/15000 [30:50<34:11,  5.57it/s, lr=0.000446, step_loss=0.112]07/27/2023 18:15:40 - INFO - __main__ - train loss is 33.01760849391576\n",
      "Steps:  24%|▏| 3584/15000 [30:51<34:08,  5.57it/s, lr=0.000446, step_loss=0.406]07/27/2023 18:15:41 - INFO - __main__ - train loss is 33.0310810910305\n",
      "Steps:  24%|▏| 3585/15000 [30:51<34:08,  5.57it/s, lr=0.000447, step_loss=0.013507/27/2023 18:15:41 - INFO - __main__ - train loss is 33.323305975063704\n",
      "Steps:  24%|▏| 3586/15000 [30:51<34:08,  5.57it/s, lr=0.000447, step_loss=0.292]07/27/2023 18:15:41 - INFO - __main__ - train loss is 33.68773074017372\n",
      "Steps:  24%|▏| 3587/15000 [30:51<34:23,  5.53it/s, lr=0.000447, step_loss=0.364]07/27/2023 18:15:41 - INFO - __main__ - train loss is 33.77506967203226\n",
      "Steps:  24%|▏| 3588/15000 [30:51<34:18,  5.54it/s, lr=0.000447, step_loss=0.087307/27/2023 18:15:41 - INFO - __main__ - train loss is 33.778043113299645\n",
      "Steps:  24%|▏| 3589/15000 [30:52<34:15,  5.55it/s, lr=0.000447, step_loss=0.002907/27/2023 18:15:41 - INFO - __main__ - train loss is 33.80045827443246\n",
      "Steps:  24%|▏| 3590/15000 [30:52<34:14,  5.55it/s, lr=0.000447, step_loss=0.022407/27/2023 18:15:42 - INFO - __main__ - train loss is 34.31581982190255\n",
      "Steps:  24%|▏| 3591/15000 [30:52<34:12,  5.56it/s, lr=0.000447, step_loss=0.515]07/27/2023 18:15:42 - INFO - __main__ - train loss is 34.32649533788208\n",
      "Steps:  24%|▏| 3592/15000 [30:52<34:09,  5.57it/s, lr=0.000447, step_loss=0.010707/27/2023 18:15:42 - INFO - __main__ - train loss is 34.37386113742832\n",
      "Steps:  24%|▏| 3593/15000 [30:52<34:08,  5.57it/s, lr=0.000448, step_loss=0.047407/27/2023 18:15:42 - INFO - __main__ - train loss is 34.411560196080245\n",
      "Steps:  24%|▏| 3594/15000 [30:52<34:06,  5.57it/s, lr=0.000448, step_loss=0.037707/27/2023 18:15:42 - INFO - __main__ - train loss is 34.43729509378318\n",
      "Steps:  24%|▏| 3595/15000 [30:53<34:06,  5.57it/s, lr=0.000448, step_loss=0.025707/27/2023 18:15:43 - INFO - __main__ - train loss is 34.58405843342189\n",
      "Steps:  24%|▏| 3596/15000 [30:53<34:05,  5.58it/s, lr=0.000448, step_loss=0.147]07/27/2023 18:15:43 - INFO - __main__ - train loss is 34.70674636925105\n",
      "Steps:  24%|▏| 3597/15000 [30:53<34:10,  5.56it/s, lr=0.000448, step_loss=0.123]07/27/2023 18:15:43 - INFO - __main__ - train loss is 34.71029245771933\n",
      "Steps:  24%|▏| 3598/15000 [30:53<34:08,  5.57it/s, lr=0.000448, step_loss=0.003507/27/2023 18:15:43 - INFO - __main__ - train loss is 35.01683419861365\n",
      "Steps:  24%|▏| 3599/15000 [30:53<34:07,  5.57it/s, lr=0.000448, step_loss=0.307]07/27/2023 18:15:43 - INFO - __main__ - train loss is 35.073466266621836\n",
      "Steps:  24%|▏| 3600/15000 [30:54<34:07,  5.57it/s, lr=0.000448, step_loss=0.056607/27/2023 18:15:43 - INFO - __main__ - train loss is 35.07830439519603\n",
      "Steps:  24%|▏| 3601/15000 [30:54<34:07,  5.57it/s, lr=0.000449, step_loss=0.004807/27/2023 18:15:44 - INFO - __main__ - train loss is 35.22082190227229\n",
      "Steps:  24%|▏| 3602/15000 [30:54<34:06,  5.57it/s, lr=0.000449, step_loss=0.143]07/27/2023 18:15:44 - INFO - __main__ - train loss is 35.32670451712329\n",
      "Steps:  24%|▏| 3603/15000 [30:54<34:06,  5.57it/s, lr=0.000449, step_loss=0.106]07/27/2023 18:15:44 - INFO - __main__ - train loss is 35.73513557028491\n",
      "Steps:  24%|▏| 3604/15000 [30:54<34:06,  5.57it/s, lr=0.000449, step_loss=0.408]07/27/2023 18:15:44 - INFO - __main__ - train loss is 35.862288579461165\n",
      "Steps:  24%|▏| 3605/15000 [30:54<34:06,  5.57it/s, lr=0.000449, step_loss=0.127]07/27/2023 18:15:44 - INFO - __main__ - train loss is 36.164558008429594\n",
      "Steps:  24%|▏| 3606/15000 [30:55<34:05,  5.57it/s, lr=0.000449, step_loss=0.302]07/27/2023 18:15:44 - INFO - __main__ - train loss is 36.19492604222614\n",
      "Steps:  24%|▏| 3607/15000 [30:55<34:04,  5.57it/s, lr=0.000449, step_loss=0.030407/27/2023 18:15:45 - INFO - __main__ - train loss is 36.21360590506811\n",
      "Steps:  24%|▏| 3608/15000 [30:55<34:02,  5.58it/s, lr=0.000449, step_loss=0.018707/27/2023 18:15:45 - INFO - __main__ - train loss is 36.2507786025526\n",
      "Steps:  24%|▏| 3609/15000 [30:55<34:01,  5.58it/s, lr=0.00045, step_loss=0.0372]07/27/2023 18:15:45 - INFO - __main__ - train loss is 36.2527786946157\n",
      "Steps:  24%|▍ | 3610/15000 [30:55<34:02,  5.58it/s, lr=0.00045, step_loss=0.002]07/27/2023 18:15:45 - INFO - __main__ - train loss is 36.26001570245717\n",
      "Steps:  24%|▏| 3611/15000 [30:56<34:01,  5.58it/s, lr=0.00045, step_loss=0.0072407/27/2023 18:15:45 - INFO - __main__ - train loss is 36.261910855886526\n",
      "Steps:  24%|▏| 3612/15000 [30:56<34:01,  5.58it/s, lr=0.00045, step_loss=0.0019]07/27/2023 18:15:46 - INFO - __main__ - train loss is 36.38107258838136\n",
      "Steps:  24%|▍ | 3613/15000 [30:56<34:02,  5.57it/s, lr=0.00045, step_loss=0.119]07/27/2023 18:15:46 - INFO - __main__ - train loss is 36.405188560602255\n",
      "Steps:  24%|▏| 3614/15000 [30:56<34:02,  5.57it/s, lr=0.00045, step_loss=0.0241]07/27/2023 18:15:46 - INFO - __main__ - train loss is 36.689783513662405\n",
      "Steps:  24%|▍ | 3615/15000 [30:56<34:02,  5.57it/s, lr=0.00045, step_loss=0.285]07/27/2023 18:15:46 - INFO - __main__ - train loss is 36.69175933639053\n",
      "Steps:  24%|▏| 3616/15000 [30:56<34:01,  5.58it/s, lr=0.00045, step_loss=0.0019807/27/2023 18:15:46 - INFO - __main__ - train loss is 36.73705139348749\n",
      "Steps:  24%|▏| 3617/15000 [30:57<34:00,  5.58it/s, lr=0.00045, step_loss=0.0453]07/27/2023 18:15:46 - INFO - __main__ - train loss is 36.75868146086577\n",
      "Steps:  24%|▏| 3618/15000 [30:57<34:00,  5.58it/s, lr=0.000451, step_loss=0.021607/27/2023 18:15:47 - INFO - __main__ - train loss is 36.83979686314706\n",
      "Steps:  24%|▏| 3619/15000 [30:57<34:00,  5.58it/s, lr=0.000451, step_loss=0.081107/27/2023 18:15:47 - INFO - __main__ - train loss is 36.87484456563834\n",
      "Steps:  24%|▏| 3620/15000 [30:57<33:57,  5.58it/s, lr=0.000451, step_loss=0.035]07/27/2023 18:15:47 - INFO - __main__ - train loss is 36.87672510207631\n",
      "Steps:  24%|▏| 3621/15000 [30:57<33:56,  5.59it/s, lr=0.000451, step_loss=0.001807/27/2023 18:15:47 - INFO - __main__ - train loss is 36.8822964776773\n",
      "Steps:  24%|▏| 3622/15000 [30:57<33:55,  5.59it/s, lr=0.000451, step_loss=0.005507/27/2023 18:15:47 - INFO - __main__ - train loss is 36.9346229035873\n",
      "Steps:  24%|▏| 3623/15000 [30:58<33:54,  5.59it/s, lr=0.000451, step_loss=0.052307/27/2023 18:15:48 - INFO - __main__ - train loss is 37.274492462398484\n",
      "Steps:  24%|▍ | 3624/15000 [30:58<33:53,  5.60it/s, lr=0.000451, step_loss=0.34]07/27/2023 18:15:48 - INFO - __main__ - train loss is 37.277370198396966\n",
      "Steps:  24%|▏| 3625/15000 [30:58<33:53,  5.59it/s, lr=0.000452, step_loss=0.002807/27/2023 18:15:48 - INFO - __main__ - train loss is 37.28275642055087\n",
      "Steps:  24%|▏| 3626/15000 [30:58<33:53,  5.59it/s, lr=0.000452, step_loss=0.005307/27/2023 18:15:48 - INFO - __main__ - train loss is 37.35115365940146\n",
      "Steps:  24%|▏| 3627/15000 [30:58<33:53,  5.59it/s, lr=0.000452, step_loss=0.068407/27/2023 18:15:48 - INFO - __main__ - train loss is 37.46762131410651\n",
      "Steps:  24%|▏| 3628/15000 [30:59<34:47,  5.45it/s, lr=0.000452, step_loss=0.116]07/27/2023 18:15:48 - INFO - __main__ - train loss is 37.65733422595076\n",
      "Steps:  24%|▍ | 3629/15000 [30:59<37:06,  5.11it/s, lr=0.000452, step_loss=0.19]07/27/2023 18:15:49 - INFO - __main__ - train loss is 37.675255874870345\n",
      "Steps:  24%|▏| 3630/15000 [30:59<37:40,  5.03it/s, lr=0.000452, step_loss=0.017907/27/2023 18:15:49 - INFO - __main__ - train loss is 38.13352696108632\n",
      "Steps:  24%|▏| 3631/15000 [30:59<36:43,  5.16it/s, lr=0.000452, step_loss=0.458]07/27/2023 18:15:49 - INFO - __main__ - train loss is 38.37794821965508\n",
      "Steps:  24%|▏| 3632/15000 [30:59<36:01,  5.26it/s, lr=0.000452, step_loss=0.244]07/27/2023 18:15:49 - INFO - __main__ - train loss is 38.41915017622523\n",
      "Steps:  24%|▏| 3633/15000 [31:00<35:32,  5.33it/s, lr=0.000453, step_loss=0.041207/27/2023 18:15:49 - INFO - __main__ - train loss is 39.06735116499476\n",
      "Steps:  24%|▏| 3634/15000 [31:00<35:00,  5.41it/s, lr=0.000453, step_loss=0.648]07/27/2023 18:15:50 - INFO - __main__ - train loss is 39.069080085959285\n",
      "Steps:  24%|▏| 3635/15000 [31:00<34:39,  5.47it/s, lr=0.000453, step_loss=0.001707/27/2023 18:15:50 - INFO - __main__ - train loss is 39.54863536497578\n",
      "Steps:  24%|▍ | 3636/15000 [31:00<48:21,  3.92it/s, lr=0.000453, step_loss=0.48]07/27/2023 18:15:51 - INFO - __main__ - Per validation step average loss is 0.015647951513528824\n",
      "07/27/2023 18:15:51 - INFO - __main__ - Cumulative validation average loss is 0.015647951513528824\n",
      "07/27/2023 18:15:51 - INFO - __main__ - Per validation step average loss is 0.02726738527417183\n",
      "07/27/2023 18:15:51 - INFO - __main__ - Cumulative validation average loss is 0.04291533678770065\n",
      "07/27/2023 18:15:52 - INFO - __main__ - Per validation step average loss is 0.32864341139793396\n",
      "07/27/2023 18:15:52 - INFO - __main__ - Cumulative validation average loss is 0.3715587481856346\n",
      "07/27/2023 18:15:52 - INFO - __main__ - Per validation step average loss is 0.011989379301667213\n",
      "07/27/2023 18:15:52 - INFO - __main__ - Cumulative validation average loss is 0.3835481274873018\n",
      "07/27/2023 18:15:53 - INFO - __main__ - Per validation step average loss is 0.017221558839082718\n",
      "07/27/2023 18:15:53 - INFO - __main__ - Cumulative validation average loss is 0.40076968632638454\n",
      "07/27/2023 18:15:53 - INFO - __main__ - Per validation step average loss is 0.10202325880527496\n",
      "07/27/2023 18:15:53 - INFO - __main__ - Cumulative validation average loss is 0.5027929451316595\n",
      "07/27/2023 18:15:53 - INFO - __main__ - Per validation step average loss is 0.26952046155929565\n",
      "07/27/2023 18:15:53 - INFO - __main__ - Cumulative validation average loss is 0.7723134066909552\n",
      "07/27/2023 18:15:54 - INFO - __main__ - Per validation step average loss is 0.0016741148428991437\n",
      "07/27/2023 18:15:54 - INFO - __main__ - Cumulative validation average loss is 0.7739875215338543\n",
      "07/27/2023 18:15:54 - INFO - __main__ - Per validation step average loss is 0.25198039412498474\n",
      "07/27/2023 18:15:54 - INFO - __main__ - Cumulative validation average loss is 1.025967915658839\n",
      "07/27/2023 18:15:55 - INFO - __main__ - Per validation step average loss is 0.01577099971473217\n",
      "07/27/2023 18:15:55 - INFO - __main__ - Cumulative validation average loss is 1.0417389153735712\n",
      "07/27/2023 18:15:55 - INFO - __main__ - Per validation step average loss is 0.10788551717996597\n",
      "07/27/2023 18:15:55 - INFO - __main__ - Cumulative validation average loss is 1.1496244325535372\n",
      "07/27/2023 18:15:56 - INFO - __main__ - Per validation step average loss is 0.0057096704840660095\n",
      "07/27/2023 18:15:56 - INFO - __main__ - Cumulative validation average loss is 1.1553341030376032\n",
      "07/27/2023 18:15:56 - INFO - __main__ - Per validation step average loss is 0.10042974352836609\n",
      "07/27/2023 18:15:56 - INFO - __main__ - Cumulative validation average loss is 1.2557638465659693\n",
      "07/27/2023 18:15:56 - INFO - __main__ - Per validation step average loss is 0.0326613113284111\n",
      "07/27/2023 18:15:56 - INFO - __main__ - Cumulative validation average loss is 1.2884251578943804\n",
      "07/27/2023 18:15:57 - INFO - __main__ - Per validation step average loss is 0.23257333040237427\n",
      "07/27/2023 18:15:57 - INFO - __main__ - Cumulative validation average loss is 1.5209984882967547\n",
      "07/27/2023 18:15:57 - INFO - __main__ - Per validation step average loss is 0.424493670463562\n",
      "07/27/2023 18:15:57 - INFO - __main__ - Cumulative validation average loss is 1.9454921587603167\n",
      "07/27/2023 18:15:58 - INFO - __main__ - Per validation step average loss is 0.020480811595916748\n",
      "07/27/2023 18:15:58 - INFO - __main__ - Cumulative validation average loss is 1.9659729703562334\n",
      "07/27/2023 18:15:58 - INFO - __main__ - Per validation step average loss is 0.232997328042984\n",
      "07/27/2023 18:15:58 - INFO - __main__ - Cumulative validation average loss is 2.1989702983992174\n",
      "07/27/2023 18:15:58 - INFO - __main__ - Per validation step average loss is 0.01537639182060957\n",
      "07/27/2023 18:15:58 - INFO - __main__ - Cumulative validation average loss is 2.214346690219827\n",
      "07/27/2023 18:15:59 - INFO - __main__ - Per validation step average loss is 0.004856777843087912\n",
      "07/27/2023 18:15:59 - INFO - __main__ - Cumulative validation average loss is 2.219203468062915\n",
      "07/27/2023 18:15:59 - INFO - __main__ - Per validation step average loss is 0.00341087207198143\n",
      "07/27/2023 18:15:59 - INFO - __main__ - Cumulative validation average loss is 2.2226143401348963\n",
      "07/27/2023 18:16:00 - INFO - __main__ - Per validation step average loss is 0.07027655839920044\n",
      "07/27/2023 18:16:00 - INFO - __main__ - Cumulative validation average loss is 2.2928908985340968\n",
      "07/27/2023 18:16:00 - INFO - __main__ - Per validation step average loss is 0.006199297495186329\n",
      "07/27/2023 18:16:00 - INFO - __main__ - Cumulative validation average loss is 2.299090196029283\n",
      "07/27/2023 18:16:00 - INFO - __main__ - Per validation step average loss is 0.5561321377754211\n",
      "07/27/2023 18:16:00 - INFO - __main__ - Cumulative validation average loss is 2.8552223338047042\n",
      "07/27/2023 18:16:01 - INFO - __main__ - Per validation step average loss is 0.8486462235450745\n",
      "07/27/2023 18:16:01 - INFO - __main__ - Cumulative validation average loss is 3.7038685573497787\n",
      "07/27/2023 18:16:01 - INFO - __main__ - Per validation step average loss is 0.09303916245698929\n",
      "07/27/2023 18:16:01 - INFO - __main__ - Cumulative validation average loss is 3.796907719806768\n",
      "07/27/2023 18:16:02 - INFO - __main__ - Per validation step average loss is 0.01506846770644188\n",
      "07/27/2023 18:16:02 - INFO - __main__ - Cumulative validation average loss is 3.81197618751321\n",
      "07/27/2023 18:16:02 - INFO - __main__ - Per validation step average loss is 0.0012341398978605866\n",
      "07/27/2023 18:16:02 - INFO - __main__ - Cumulative validation average loss is 3.8132103274110705\n",
      "07/27/2023 18:16:03 - INFO - __main__ - Per validation step average loss is 0.031419817358255386\n",
      "07/27/2023 18:16:03 - INFO - __main__ - Cumulative validation average loss is 3.844630144769326\n",
      "07/27/2023 18:16:03 - INFO - __main__ - Per validation step average loss is 0.04294067993760109\n",
      "07/27/2023 18:16:03 - INFO - __main__ - Cumulative validation average loss is 3.887570824706927\n",
      "07/27/2023 18:16:03 - INFO - __main__ - Per validation step average loss is 0.11253361403942108\n",
      "07/27/2023 18:16:03 - INFO - __main__ - Cumulative validation average loss is 4.000104438746348\n",
      "07/27/2023 18:16:04 - INFO - __main__ - Per validation step average loss is 0.01760980300605297\n",
      "07/27/2023 18:16:04 - INFO - __main__ - Cumulative validation average loss is 4.017714241752401\n",
      "07/27/2023 18:16:04 - INFO - __main__ - Per validation step average loss is 0.0724342092871666\n",
      "07/27/2023 18:16:04 - INFO - __main__ - Cumulative validation average loss is 4.090148451039568\n",
      "07/27/2023 18:16:05 - INFO - __main__ - Per validation step average loss is 0.2261001169681549\n",
      "07/27/2023 18:16:05 - INFO - __main__ - Cumulative validation average loss is 4.3162485680077225\n",
      "07/27/2023 18:16:05 - INFO - __main__ - Per validation step average loss is 0.18258735537528992\n",
      "07/27/2023 18:16:05 - INFO - __main__ - Cumulative validation average loss is 4.498835923383012\n",
      "07/27/2023 18:16:05 - INFO - __main__ - Per validation step average loss is 0.047673895955085754\n",
      "07/27/2023 18:16:05 - INFO - __main__ - Cumulative validation average loss is 4.546509819338098\n",
      "07/27/2023 18:16:06 - INFO - __main__ - Per validation step average loss is 0.03741852194070816\n",
      "07/27/2023 18:16:06 - INFO - __main__ - Cumulative validation average loss is 4.583928341278806\n",
      "07/27/2023 18:16:06 - INFO - __main__ - Per validation step average loss is 0.6235733032226562\n",
      "07/27/2023 18:16:06 - INFO - __main__ - Cumulative validation average loss is 5.207501644501463\n",
      "07/27/2023 18:16:07 - INFO - __main__ - Per validation step average loss is 0.3205054998397827\n",
      "07/27/2023 18:16:07 - INFO - __main__ - Cumulative validation average loss is 5.528007144341245\n",
      "07/27/2023 18:16:07 - INFO - __main__ - Per validation step average loss is 0.09739126265048981\n",
      "07/27/2023 18:16:07 - INFO - __main__ - Cumulative validation average loss is 5.625398406991735\n",
      "07/27/2023 18:16:07 - INFO - __main__ - Per validation step average loss is 0.6111444234848022\n",
      "07/27/2023 18:16:07 - INFO - __main__ - Cumulative validation average loss is 6.236542830476537\n",
      "07/27/2023 18:16:08 - INFO - __main__ - Per validation step average loss is 0.025278426706790924\n",
      "07/27/2023 18:16:08 - INFO - __main__ - Cumulative validation average loss is 6.261821257183328\n",
      "07/27/2023 18:16:08 - INFO - __main__ - Per validation step average loss is 0.001202442916110158\n",
      "07/27/2023 18:16:08 - INFO - __main__ - Cumulative validation average loss is 6.263023700099438\n",
      "07/27/2023 18:16:09 - INFO - __main__ - Per validation step average loss is 0.005711766891181469\n",
      "07/27/2023 18:16:09 - INFO - __main__ - Cumulative validation average loss is 6.26873546699062\n",
      "07/27/2023 18:16:09 - INFO - __main__ - Per validation step average loss is 0.02632877789437771\n",
      "07/27/2023 18:16:09 - INFO - __main__ - Cumulative validation average loss is 6.295064244884998\n",
      "07/27/2023 18:16:09 - INFO - __main__ - Per validation step average loss is 0.23743411898612976\n",
      "07/27/2023 18:16:09 - INFO - __main__ - Cumulative validation average loss is 6.532498363871127\n",
      "07/27/2023 18:16:10 - INFO - __main__ - Per validation step average loss is 0.6739937663078308\n",
      "07/27/2023 18:16:10 - INFO - __main__ - Cumulative validation average loss is 7.206492130178958\n",
      "07/27/2023 18:16:10 - INFO - __main__ - Per validation step average loss is 0.01656424067914486\n",
      "07/27/2023 18:16:10 - INFO - __main__ - Cumulative validation average loss is 7.223056370858103\n",
      "07/27/2023 18:16:11 - INFO - __main__ - Per validation step average loss is 0.283693790435791\n",
      "07/27/2023 18:16:11 - INFO - __main__ - Cumulative validation average loss is 7.506750161293894\n",
      "07/27/2023 18:16:11 - INFO - __main__ - Per validation step average loss is 0.02002936415374279\n",
      "07/27/2023 18:16:11 - INFO - __main__ - Cumulative validation average loss is 7.526779525447637\n",
      "07/27/2023 18:16:11 - INFO - __main__ - Per validation step average loss is 0.09622544795274734\n",
      "07/27/2023 18:16:11 - INFO - __main__ - Cumulative validation average loss is 7.623004973400384\n",
      "07/27/2023 18:16:12 - INFO - __main__ - Per validation step average loss is 0.6260600686073303\n",
      "07/27/2023 18:16:12 - INFO - __main__ - Cumulative validation average loss is 8.249065042007715\n",
      "07/27/2023 18:16:12 - INFO - __main__ - Per validation step average loss is 0.006118407007306814\n",
      "07/27/2023 18:16:12 - INFO - __main__ - Cumulative validation average loss is 8.255183449015021\n",
      "07/27/2023 18:16:13 - INFO - __main__ - Per validation step average loss is 0.15723639726638794\n",
      "07/27/2023 18:16:13 - INFO - __main__ - Cumulative validation average loss is 8.41241984628141\n",
      "07/27/2023 18:16:13 - INFO - __main__ - Per validation step average loss is 0.0024724081158638\n",
      "07/27/2023 18:16:13 - INFO - __main__ - Cumulative validation average loss is 8.414892254397273\n",
      "07/27/2023 18:16:14 - INFO - __main__ - Per validation step average loss is 0.43847161531448364\n",
      "07/27/2023 18:16:14 - INFO - __main__ - Cumulative validation average loss is 8.853363869711757\n",
      "07/27/2023 18:16:14 - INFO - __main__ - Per validation step average loss is 0.040091030299663544\n",
      "07/27/2023 18:16:14 - INFO - __main__ - Cumulative validation average loss is 8.89345490001142\n",
      "07/27/2023 18:16:14 - INFO - __main__ - Per validation step average loss is 0.172615185379982\n",
      "07/27/2023 18:16:14 - INFO - __main__ - Cumulative validation average loss is 9.066070085391402\n",
      "07/27/2023 18:16:15 - INFO - __main__ - Per validation step average loss is 0.05789656564593315\n",
      "07/27/2023 18:16:15 - INFO - __main__ - Cumulative validation average loss is 9.123966651037335\n",
      "07/27/2023 18:16:15 - INFO - __main__ - Per validation step average loss is 0.18581213057041168\n",
      "07/27/2023 18:16:15 - INFO - __main__ - Cumulative validation average loss is 9.309778781607747\n",
      "07/27/2023 18:16:16 - INFO - __main__ - Per validation step average loss is 0.0032393373548984528\n",
      "07/27/2023 18:16:16 - INFO - __main__ - Cumulative validation average loss is 9.313018118962646\n",
      "07/27/2023 18:16:16 - INFO - __main__ - Per validation step average loss is 0.07676013559103012\n",
      "07/27/2023 18:16:16 - INFO - __main__ - Cumulative validation average loss is 9.389778254553676\n",
      "07/27/2023 18:16:16 - INFO - __main__ - Per validation step average loss is 0.0026440767105668783\n",
      "07/27/2023 18:16:16 - INFO - __main__ - Cumulative validation average loss is 9.392422331264243\n",
      "07/27/2023 18:16:17 - INFO - __main__ - Per validation step average loss is 0.15842047333717346\n",
      "07/27/2023 18:16:17 - INFO - __main__ - Cumulative validation average loss is 9.550842804601416\n",
      "07/27/2023 18:16:17 - INFO - __main__ - Per validation step average loss is 0.006779489107429981\n",
      "07/27/2023 18:16:17 - INFO - __main__ - Cumulative validation average loss is 9.557622293708846\n",
      "07/27/2023 18:16:18 - INFO - __main__ - Per validation step average loss is 0.1449350118637085\n",
      "07/27/2023 18:16:18 - INFO - __main__ - Cumulative validation average loss is 9.702557305572554\n",
      "07/27/2023 18:16:18 - INFO - __main__ - Per validation step average loss is 0.03956034779548645\n",
      "07/27/2023 18:16:18 - INFO - __main__ - Cumulative validation average loss is 9.742117653368041\n",
      "07/27/2023 18:16:18 - INFO - __main__ - Per validation step average loss is 0.01688726618885994\n",
      "07/27/2023 18:16:18 - INFO - __main__ - Cumulative validation average loss is 9.7590049195569\n",
      "07/27/2023 18:16:19 - INFO - __main__ - Per validation step average loss is 0.006048297509551048\n",
      "07/27/2023 18:16:19 - INFO - __main__ - Cumulative validation average loss is 9.765053217066452\n",
      "07/27/2023 18:16:19 - INFO - __main__ - Per validation step average loss is 0.12902295589447021\n",
      "07/27/2023 18:16:19 - INFO - __main__ - Cumulative validation average loss is 9.894076172960922\n",
      "07/27/2023 18:16:20 - INFO - __main__ - Per validation step average loss is 0.0011630789376795292\n",
      "07/27/2023 18:16:20 - INFO - __main__ - Cumulative validation average loss is 9.895239251898602\n",
      "07/27/2023 18:16:20 - INFO - __main__ - Per validation step average loss is 0.395072877407074\n",
      "07/27/2023 18:16:20 - INFO - __main__ - Cumulative validation average loss is 10.290312129305676\n",
      "07/27/2023 18:16:20 - INFO - __main__ - Per validation step average loss is 0.00538697000592947\n",
      "07/27/2023 18:16:20 - INFO - __main__ - Cumulative validation average loss is 10.295699099311605\n",
      "07/27/2023 18:16:21 - INFO - __main__ - Per validation step average loss is 0.473029762506485\n",
      "07/27/2023 18:16:21 - INFO - __main__ - Cumulative validation average loss is 10.76872886181809\n",
      "07/27/2023 18:16:21 - INFO - __main__ - Per validation step average loss is 0.07996856421232224\n",
      "07/27/2023 18:16:21 - INFO - __main__ - Cumulative validation average loss is 10.848697426030412\n",
      "07/27/2023 18:16:22 - INFO - __main__ - Per validation step average loss is 0.08221082389354706\n",
      "07/27/2023 18:16:22 - INFO - __main__ - Cumulative validation average loss is 10.93090824992396\n",
      "07/27/2023 18:16:22 - INFO - __main__ - Per validation step average loss is 0.6792178750038147\n",
      "07/27/2023 18:16:22 - INFO - __main__ - Cumulative validation average loss is 11.610126124927774\n",
      "07/27/2023 18:16:23 - INFO - __main__ - Per validation step average loss is 0.004902693443000317\n",
      "07/27/2023 18:16:23 - INFO - __main__ - Cumulative validation average loss is 11.615028818370774\n",
      "07/27/2023 18:16:23 - INFO - __main__ - Per validation step average loss is 0.048035722225904465\n",
      "07/27/2023 18:16:23 - INFO - __main__ - Cumulative validation average loss is 11.663064540596679\n",
      "07/27/2023 18:16:23 - INFO - __main__ - Average validation loss for Epoch 11 is 0.14763372836198327\n",
      "07/27/2023 18:16:23 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:17:20 - INFO - __main__ - Starting epoch 12\n",
      "07/27/2023 18:17:21 - INFO - __main__ - train loss is 0.31423234939575195\n",
      "Steps:  24%|▏| 3637/15000 [32:32<86:56:38, 27.55s/it, lr=0.000453, step_loss=0.307/27/2023 18:17:21 - INFO - __main__ - train loss is 0.3815496861934662\n",
      "Steps:  24%|▏| 3638/15000 [32:32<61:02:29, 19.34s/it, lr=0.000453, step_loss=0.007/27/2023 18:17:22 - INFO - __main__ - train loss is 0.39200504403561354\n",
      "Steps:  24%|▏| 3639/15000 [32:32<42:53:59, 13.59s/it, lr=0.000453, step_loss=0.007/27/2023 18:17:22 - INFO - __main__ - train loss is 0.39610812347382307\n",
      "Steps:  24%|▏| 3640/15000 [32:32<30:12:01,  9.57s/it, lr=0.000453, step_loss=0.007/27/2023 18:17:22 - INFO - __main__ - train loss is 1.105695459060371\n",
      "Steps:  24%|▏| 3641/15000 [32:32<21:18:51,  6.76s/it, lr=0.000454, step_loss=0.707/27/2023 18:17:22 - INFO - __main__ - train loss is 1.2667701272293925\n",
      "Steps:  24%|▏| 3642/15000 [32:32<15:05:30,  4.78s/it, lr=0.000454, step_loss=0.107/27/2023 18:17:22 - INFO - __main__ - train loss is 1.2760667717084289\n",
      "Steps:  24%|▏| 3643/15000 [32:33<10:44:12,  3.40s/it, lr=0.000454, step_loss=0.007/27/2023 18:17:23 - INFO - __main__ - train loss is 1.2798577276989818\n",
      "Steps:  24%|▏| 3644/15000 [32:33<7:41:10,  2.44s/it, lr=0.000454, step_loss=0.0007/27/2023 18:17:23 - INFO - __main__ - train loss is 1.355214330367744\n",
      "Steps:  24%|▏| 3645/15000 [32:33<5:33:03,  1.76s/it, lr=0.000454, step_loss=0.0707/27/2023 18:17:23 - INFO - __main__ - train loss is 1.359849154483527\n",
      "Steps:  24%|▏| 3646/15000 [32:33<4:03:33,  1.29s/it, lr=0.000454, step_loss=0.0007/27/2023 18:17:23 - INFO - __main__ - train loss is 1.3808320458047092\n",
      "Steps:  24%|▏| 3647/15000 [32:33<3:00:54,  1.05it/s, lr=0.000454, step_loss=0.0207/27/2023 18:17:23 - INFO - __main__ - train loss is 1.5618834192864597\n",
      "Steps:  24%|▏| 3648/15000 [32:34<2:16:51,  1.38it/s, lr=0.000454, step_loss=0.1807/27/2023 18:17:23 - INFO - __main__ - train loss is 1.8258929247967899\n",
      "Steps:  24%|▏| 3649/15000 [32:34<1:45:54,  1.79it/s, lr=0.000455, step_loss=0.2607/27/2023 18:17:24 - INFO - __main__ - train loss is 2.179850101005286\n",
      "Steps:  24%|▏| 3650/15000 [32:34<1:24:15,  2.25it/s, lr=0.000455, step_loss=0.3507/27/2023 18:17:24 - INFO - __main__ - train loss is 2.44558948231861\n",
      "Steps:  24%|▏| 3651/15000 [32:34<1:09:08,  2.74it/s, lr=0.000455, step_loss=0.2607/27/2023 18:17:24 - INFO - __main__ - train loss is 2.454341250937432\n",
      "Steps:  24%|▏| 3652/15000 [32:34<58:30,  3.23it/s, lr=0.000455, step_loss=0.008707/27/2023 18:17:24 - INFO - __main__ - train loss is 2.5480173262767494\n",
      "Steps:  24%|▏| 3653/15000 [32:34<51:23,  3.68it/s, lr=0.000455, step_loss=0.093707/27/2023 18:17:24 - INFO - __main__ - train loss is 2.79215745953843\n",
      "Steps:  24%|▏| 3654/15000 [32:35<46:15,  4.09it/s, lr=0.000455, step_loss=0.244]07/27/2023 18:17:25 - INFO - __main__ - train loss is 2.80232224939391\n",
      "Steps:  24%|▏| 3655/15000 [32:35<42:31,  4.45it/s, lr=0.000455, step_loss=0.010207/27/2023 18:17:25 - INFO - __main__ - train loss is 3.102514188271016\n",
      "Steps:  24%|▋  | 3656/15000 [32:35<39:55,  4.73it/s, lr=0.000455, step_loss=0.3]07/27/2023 18:17:25 - INFO - __main__ - train loss is 3.1437092828564346\n",
      "Steps:  24%|▏| 3657/15000 [32:35<38:26,  4.92it/s, lr=0.000456, step_loss=0.041207/27/2023 18:17:25 - INFO - __main__ - train loss is 3.2086860346607864\n",
      "Steps:  24%|▏| 3658/15000 [32:35<37:18,  5.07it/s, lr=0.000456, step_loss=0.065]07/27/2023 18:17:25 - INFO - __main__ - train loss is 3.2446177336387336\n",
      "Steps:  24%|▏| 3659/15000 [32:36<36:16,  5.21it/s, lr=0.000456, step_loss=0.035907/27/2023 18:17:25 - INFO - __main__ - train loss is 3.2499054381623864\n",
      "Steps:  24%|▏| 3660/15000 [32:36<35:38,  5.30it/s, lr=0.000456, step_loss=0.005207/27/2023 18:17:26 - INFO - __main__ - train loss is 3.478669465519488\n",
      "Steps:  24%|▏| 3661/15000 [32:36<35:08,  5.38it/s, lr=0.000456, step_loss=0.229]07/27/2023 18:17:26 - INFO - __main__ - train loss is 4.002182484604418\n",
      "Steps:  24%|▏| 3662/15000 [32:36<34:45,  5.44it/s, lr=0.000456, step_loss=0.524]07/27/2023 18:17:26 - INFO - __main__ - train loss is 4.006082441657782\n",
      "Steps:  24%|▏| 3663/15000 [32:36<34:30,  5.48it/s, lr=0.000456, step_loss=0.003907/27/2023 18:17:26 - INFO - __main__ - train loss is 4.108703639358282\n",
      "Steps:  24%|▏| 3664/15000 [32:36<34:18,  5.51it/s, lr=0.000456, step_loss=0.103]07/27/2023 18:17:26 - INFO - __main__ - train loss is 4.290230330079794\n",
      "Steps:  24%|▏| 3665/15000 [32:37<34:14,  5.52it/s, lr=0.000457, step_loss=0.182]07/27/2023 18:17:27 - INFO - __main__ - train loss is 4.293177084764466\n",
      "Steps:  24%|▏| 3666/15000 [32:37<34:08,  5.53it/s, lr=0.000457, step_loss=0.002907/27/2023 18:17:27 - INFO - __main__ - train loss is 4.309354895493016\n",
      "Steps:  24%|▏| 3667/15000 [32:37<34:09,  5.53it/s, lr=0.000457, step_loss=0.016207/27/2023 18:17:27 - INFO - __main__ - train loss is 4.726270610233769\n",
      "Steps:  24%|▏| 3668/15000 [32:37<34:04,  5.54it/s, lr=0.000457, step_loss=0.417]07/27/2023 18:17:27 - INFO - __main__ - train loss is 4.98708021058701\n",
      "Steps:  24%|▏| 3669/15000 [32:37<34:14,  5.52it/s, lr=0.000457, step_loss=0.261]07/27/2023 18:17:27 - INFO - __main__ - train loss is 5.2077594043221325\n",
      "Steps:  24%|▏| 3670/15000 [32:38<35:09,  5.37it/s, lr=0.000457, step_loss=0.221]07/27/2023 18:17:27 - INFO - __main__ - train loss is 5.2166960274335\n",
      "Steps:  24%|▏| 3671/15000 [32:38<35:28,  5.32it/s, lr=0.000457, step_loss=0.008907/27/2023 18:17:28 - INFO - __main__ - train loss is 5.269461992895231\n",
      "Steps:  24%|▏| 3672/15000 [32:38<35:51,  5.27it/s, lr=0.000457, step_loss=0.052807/27/2023 18:17:28 - INFO - __main__ - train loss is 5.271155315102078\n",
      "Steps:  24%|▏| 3673/15000 [32:38<36:08,  5.22it/s, lr=0.000458, step_loss=0.001607/27/2023 18:17:28 - INFO - __main__ - train loss is 5.4773696238407865\n",
      "Steps:  24%|▏| 3674/15000 [32:38<35:51,  5.27it/s, lr=0.000458, step_loss=0.206]07/27/2023 18:17:28 - INFO - __main__ - train loss is 5.642447369755246\n",
      "Steps:  24%|▏| 3675/15000 [32:39<35:33,  5.31it/s, lr=0.000458, step_loss=0.165]07/27/2023 18:17:28 - INFO - __main__ - train loss is 5.670962410629727\n",
      "Steps:  25%|▏| 3676/15000 [32:39<35:15,  5.35it/s, lr=0.000458, step_loss=0.028507/27/2023 18:17:29 - INFO - __main__ - train loss is 5.680355324060656\n",
      "Steps:  25%|▏| 3677/15000 [32:39<34:49,  5.42it/s, lr=0.000458, step_loss=0.009307/27/2023 18:17:29 - INFO - __main__ - train loss is 5.7695418210932985\n",
      "Steps:  25%|▏| 3678/15000 [32:39<34:31,  5.46it/s, lr=0.000458, step_loss=0.089207/27/2023 18:17:29 - INFO - __main__ - train loss is 5.852545491070487\n",
      "Steps:  25%|▏| 3679/15000 [32:39<34:19,  5.50it/s, lr=0.000458, step_loss=0.083]07/27/2023 18:17:29 - INFO - __main__ - train loss is 5.862180304364301\n",
      "Steps:  25%|▏| 3680/15000 [32:39<34:10,  5.52it/s, lr=0.000458, step_loss=0.009607/27/2023 18:17:29 - INFO - __main__ - train loss is 6.05038787110243\n",
      "Steps:  25%|▏| 3681/15000 [32:40<34:16,  5.50it/s, lr=0.000459, step_loss=0.188]07/27/2023 18:17:29 - INFO - __main__ - train loss is 6.12103899999056\n",
      "Steps:  25%|▏| 3682/15000 [32:40<34:26,  5.48it/s, lr=0.000459, step_loss=0.070707/27/2023 18:17:30 - INFO - __main__ - train loss is 6.19332946522627\n",
      "Steps:  25%|▏| 3683/15000 [32:40<34:22,  5.49it/s, lr=0.000459, step_loss=0.072307/27/2023 18:17:30 - INFO - __main__ - train loss is 6.640263956622221\n",
      "Steps:  25%|▏| 3684/15000 [32:40<34:31,  5.46it/s, lr=0.000459, step_loss=0.447]07/27/2023 18:17:30 - INFO - __main__ - train loss is 6.641232798283454\n",
      "Steps:  25%|▏| 3685/15000 [32:40<34:26,  5.48it/s, lr=0.000459, step_loss=0.000907/27/2023 18:17:30 - INFO - __main__ - train loss is 6.834350878780242\n",
      "Steps:  25%|▏| 3686/15000 [32:41<34:14,  5.51it/s, lr=0.000459, step_loss=0.193]07/27/2023 18:17:30 - INFO - __main__ - train loss is 6.843561262299772\n",
      "Steps:  25%|▏| 3687/15000 [32:41<34:05,  5.53it/s, lr=0.000459, step_loss=0.009207/27/2023 18:17:31 - INFO - __main__ - train loss is 6.964890063216444\n",
      "Steps:  25%|▏| 3688/15000 [32:41<34:18,  5.50it/s, lr=0.000459, step_loss=0.121]07/27/2023 18:17:31 - INFO - __main__ - train loss is 7.317045927455183\n",
      "Steps:  25%|▍ | 3689/15000 [32:41<34:28,  5.47it/s, lr=0.00046, step_loss=0.352]07/27/2023 18:17:31 - INFO - __main__ - train loss is 7.426567450573202\n",
      "Steps:  25%|▋  | 3690/15000 [32:41<34:39,  5.44it/s, lr=0.00046, step_loss=0.11]07/27/2023 18:17:31 - INFO - __main__ - train loss is 7.854237690975424\n",
      "Steps:  25%|▍ | 3691/15000 [32:41<34:45,  5.42it/s, lr=0.00046, step_loss=0.428]07/27/2023 18:17:31 - INFO - __main__ - train loss is 7.864469827560242\n",
      "Steps:  25%|▏| 3692/15000 [32:42<34:35,  5.45it/s, lr=0.00046, step_loss=0.0102]07/27/2023 18:17:31 - INFO - __main__ - train loss is 7.86571838328382\n",
      "Steps:  25%|▏| 3693/15000 [32:42<34:26,  5.47it/s, lr=0.00046, step_loss=0.0012507/27/2023 18:17:32 - INFO - __main__ - train loss is 7.8678247695206665\n",
      "Steps:  25%|▏| 3694/15000 [32:42<34:16,  5.50it/s, lr=0.00046, step_loss=0.0021107/27/2023 18:17:32 - INFO - __main__ - train loss is 8.053949243330862\n",
      "Steps:  25%|▍ | 3695/15000 [32:42<34:09,  5.52it/s, lr=0.00046, step_loss=0.186]07/27/2023 18:17:32 - INFO - __main__ - train loss is 8.921857125067618\n",
      "Steps:  25%|▍ | 3696/15000 [32:42<34:04,  5.53it/s, lr=0.00046, step_loss=0.868]07/27/2023 18:17:32 - INFO - __main__ - train loss is 8.955082549655344\n",
      "Steps:  25%|▏| 3697/15000 [32:43<34:16,  5.50it/s, lr=0.000461, step_loss=0.033207/27/2023 18:17:32 - INFO - __main__ - train loss is 8.96867352904519\n",
      "Steps:  25%|▏| 3698/15000 [32:43<34:06,  5.52it/s, lr=0.000461, step_loss=0.013607/27/2023 18:17:33 - INFO - __main__ - train loss is 8.981711795495357\n",
      "Steps:  25%|▏| 3699/15000 [32:43<33:59,  5.54it/s, lr=0.000461, step_loss=0.013]07/27/2023 18:17:33 - INFO - __main__ - train loss is 9.044930359290447\n",
      "Steps:  25%|▏| 3700/15000 [32:43<33:54,  5.55it/s, lr=0.000461, step_loss=0.063207/27/2023 18:17:33 - INFO - __main__ - train loss is 9.371680637763347\n",
      "Steps:  25%|▏| 3701/15000 [32:43<33:50,  5.56it/s, lr=0.000461, step_loss=0.327]07/27/2023 18:17:33 - INFO - __main__ - train loss is 9.377285730966832\n",
      "Steps:  25%|▏| 3702/15000 [32:43<33:48,  5.57it/s, lr=0.000461, step_loss=0.005607/27/2023 18:17:33 - INFO - __main__ - train loss is 9.434510138758924\n",
      "Steps:  25%|▏| 3703/15000 [32:44<33:47,  5.57it/s, lr=0.000461, step_loss=0.057207/27/2023 18:17:33 - INFO - __main__ - train loss is 9.60538893652847\n",
      "Steps:  25%|▏| 3704/15000 [32:44<33:46,  5.57it/s, lr=0.000461, step_loss=0.171]07/27/2023 18:17:34 - INFO - __main__ - train loss is 9.607298887509387\n",
      "Steps:  25%|▏| 3705/15000 [32:44<33:46,  5.58it/s, lr=0.000462, step_loss=0.001907/27/2023 18:17:34 - INFO - __main__ - train loss is 9.960844046610873\n",
      "Steps:  25%|▏| 3706/15000 [32:44<33:45,  5.58it/s, lr=0.000462, step_loss=0.354]07/27/2023 18:17:34 - INFO - __main__ - train loss is 9.990983127790969\n",
      "Steps:  25%|▏| 3707/15000 [32:44<33:45,  5.58it/s, lr=0.000462, step_loss=0.030107/27/2023 18:17:34 - INFO - __main__ - train loss is 10.0731011472526\n",
      "Steps:  25%|▏| 3708/15000 [32:44<33:45,  5.58it/s, lr=0.000462, step_loss=0.082107/27/2023 18:17:34 - INFO - __main__ - train loss is 10.077629643667024\n",
      "Steps:  25%|▏| 3709/15000 [32:45<33:44,  5.58it/s, lr=0.000462, step_loss=0.004507/27/2023 18:17:35 - INFO - __main__ - train loss is 10.106690616521519\n",
      "Steps:  25%|▏| 3710/15000 [32:45<33:44,  5.58it/s, lr=0.000462, step_loss=0.029107/27/2023 18:17:35 - INFO - __main__ - train loss is 10.137649093929213\n",
      "Steps:  25%|▏| 3711/15000 [32:45<33:45,  5.57it/s, lr=0.000462, step_loss=0.031]07/27/2023 18:17:35 - INFO - __main__ - train loss is 10.417131637397688\n",
      "Steps:  25%|▏| 3712/15000 [32:45<33:45,  5.57it/s, lr=0.000462, step_loss=0.279]07/27/2023 18:17:35 - INFO - __main__ - train loss is 10.68754449969856\n",
      "Steps:  25%|▍ | 3713/15000 [32:45<33:51,  5.56it/s, lr=0.000463, step_loss=0.27]07/27/2023 18:17:35 - INFO - __main__ - train loss is 10.72680981567828\n",
      "Steps:  25%|▏| 3714/15000 [32:46<33:49,  5.56it/s, lr=0.000463, step_loss=0.039307/27/2023 18:17:35 - INFO - __main__ - train loss is 10.763514508667868\n",
      "Steps:  25%|▏| 3715/15000 [32:46<33:47,  5.57it/s, lr=0.000463, step_loss=0.036707/27/2023 18:17:36 - INFO - __main__ - train loss is 10.941568126145285\n",
      "Steps:  25%|▏| 3716/15000 [32:46<33:44,  5.57it/s, lr=0.000463, step_loss=0.178]07/27/2023 18:17:36 - INFO - __main__ - train loss is 10.946078339766245\n",
      "Steps:  25%|▏| 3717/15000 [32:46<33:44,  5.57it/s, lr=0.000463, step_loss=0.004507/27/2023 18:17:36 - INFO - __main__ - train loss is 10.980608387093525\n",
      "Steps:  25%|▏| 3718/15000 [32:46<33:52,  5.55it/s, lr=0.000463, step_loss=0.034507/27/2023 18:17:36 - INFO - __main__ - train loss is 11.218826098542195\n",
      "Steps:  25%|▏| 3719/15000 [32:46<33:48,  5.56it/s, lr=0.000463, step_loss=0.238]07/27/2023 18:17:36 - INFO - __main__ - train loss is 11.238882491539698\n",
      "Steps:  25%|▏| 3720/15000 [32:47<33:46,  5.57it/s, lr=0.000463, step_loss=0.020107/27/2023 18:17:37 - INFO - __main__ - train loss is 11.268203029583674\n",
      "Steps:  25%|▏| 3721/15000 [32:47<33:48,  5.56it/s, lr=0.000464, step_loss=0.029307/27/2023 18:17:37 - INFO - __main__ - train loss is 11.270964294846635\n",
      "Steps:  25%|▏| 3722/15000 [32:47<33:46,  5.57it/s, lr=0.000464, step_loss=0.002707/27/2023 18:17:37 - INFO - __main__ - train loss is 11.324594427074771\n",
      "Steps:  25%|▏| 3723/15000 [32:47<33:44,  5.57it/s, lr=0.000464, step_loss=0.053607/27/2023 18:17:37 - INFO - __main__ - train loss is 11.65475266071735\n",
      "Steps:  25%|▍ | 3724/15000 [32:47<33:44,  5.57it/s, lr=0.000464, step_loss=0.33]07/27/2023 18:17:37 - INFO - __main__ - train loss is 11.880316425289493\n",
      "Steps:  25%|▏| 3725/15000 [32:48<33:47,  5.56it/s, lr=0.000464, step_loss=0.226]07/27/2023 18:17:37 - INFO - __main__ - train loss is 12.140984166588169\n",
      "Steps:  25%|▏| 3726/15000 [32:48<33:45,  5.56it/s, lr=0.000464, step_loss=0.261]07/27/2023 18:17:38 - INFO - __main__ - train loss is 12.151677077810746\n",
      "Steps:  25%|▏| 3727/15000 [32:48<33:47,  5.56it/s, lr=0.000464, step_loss=0.010707/27/2023 18:17:38 - INFO - __main__ - train loss is 12.16299989836989\n",
      "Steps:  25%|▏| 3728/15000 [32:48<33:46,  5.56it/s, lr=0.000464, step_loss=0.011307/27/2023 18:17:38 - INFO - __main__ - train loss is 12.520744472916704\n",
      "Steps:  25%|▏| 3729/15000 [32:48<33:45,  5.56it/s, lr=0.000465, step_loss=0.358]07/27/2023 18:17:38 - INFO - __main__ - train loss is 12.733826428826433\n",
      "Steps:  25%|▏| 3730/15000 [32:48<33:46,  5.56it/s, lr=0.000465, step_loss=0.213]07/27/2023 18:17:38 - INFO - __main__ - train loss is 12.78536765294848\n",
      "Steps:  25%|▏| 3731/15000 [32:49<33:44,  5.57it/s, lr=0.000465, step_loss=0.051507/27/2023 18:17:38 - INFO - __main__ - train loss is 12.927161589439493\n",
      "Steps:  25%|▏| 3732/15000 [32:49<34:43,  5.41it/s, lr=0.000465, step_loss=0.142]07/27/2023 18:17:39 - INFO - __main__ - train loss is 13.728130117233377\n",
      "Steps:  25%|▏| 3733/15000 [32:49<36:41,  5.12it/s, lr=0.000465, step_loss=0.801]07/27/2023 18:17:39 - INFO - __main__ - train loss is 13.734865965030622\n",
      "Steps:  25%|▏| 3734/15000 [32:49<38:11,  4.92it/s, lr=0.000465, step_loss=0.006707/27/2023 18:17:39 - INFO - __main__ - train loss is 13.915615679405164\n",
      "Steps:  25%|▏| 3735/15000 [32:49<37:30,  5.01it/s, lr=0.000465, step_loss=0.181]07/27/2023 18:17:39 - INFO - __main__ - train loss is 14.089094700000715\n",
      "Steps:  25%|▏| 3736/15000 [32:50<36:31,  5.14it/s, lr=0.000465, step_loss=0.173]07/27/2023 18:17:40 - INFO - __main__ - train loss is 14.12284421332879\n",
      "Steps:  25%|▏| 3737/15000 [32:50<35:42,  5.26it/s, lr=0.000466, step_loss=0.033707/27/2023 18:17:40 - INFO - __main__ - train loss is 14.372455188713502\n",
      "Steps:  25%|▍ | 3738/15000 [32:50<35:05,  5.35it/s, lr=0.000466, step_loss=0.25]07/27/2023 18:17:40 - INFO - __main__ - train loss is 14.618145966611337\n",
      "Steps:  25%|▏| 3739/15000 [32:50<34:40,  5.41it/s, lr=0.000466, step_loss=0.246]07/27/2023 18:17:40 - INFO - __main__ - train loss is 14.644374478317332\n",
      "Steps:  25%|▏| 3740/15000 [32:50<34:22,  5.46it/s, lr=0.000466, step_loss=0.026207/27/2023 18:17:40 - INFO - __main__ - train loss is 14.774873945571017\n",
      "Steps:  25%|▍ | 3741/15000 [32:51<34:09,  5.49it/s, lr=0.000466, step_loss=0.13]07/27/2023 18:17:40 - INFO - __main__ - train loss is 14.784158398106229\n",
      "Steps:  25%|▏| 3742/15000 [32:51<34:00,  5.52it/s, lr=0.000466, step_loss=0.009207/27/2023 18:17:41 - INFO - __main__ - train loss is 14.89890164573444\n",
      "Steps:  25%|▏| 3743/15000 [32:51<33:54,  5.53it/s, lr=0.000466, step_loss=0.115]07/27/2023 18:17:41 - INFO - __main__ - train loss is 14.933780152990948\n",
      "Steps:  25%|▏| 3744/15000 [32:51<33:49,  5.55it/s, lr=0.000466, step_loss=0.034907/27/2023 18:17:41 - INFO - __main__ - train loss is 15.040542502596509\n",
      "Steps:  25%|▏| 3745/15000 [32:51<33:49,  5.55it/s, lr=0.000467, step_loss=0.107]07/27/2023 18:17:41 - INFO - __main__ - train loss is 15.480144281580579\n",
      "Steps:  25%|▍ | 3746/15000 [32:51<33:52,  5.54it/s, lr=0.000467, step_loss=0.44]07/27/2023 18:17:41 - INFO - __main__ - train loss is 15.747752030089032\n",
      "Steps:  25%|▏| 3747/15000 [32:52<33:47,  5.55it/s, lr=0.000467, step_loss=0.268]07/27/2023 18:17:41 - INFO - __main__ - train loss is 15.750303274195176\n",
      "Steps:  25%|▏| 3748/15000 [32:52<33:59,  5.52it/s, lr=0.000467, step_loss=0.002507/27/2023 18:17:42 - INFO - __main__ - train loss is 15.756233439955395\n",
      "Steps:  25%|▏| 3749/15000 [32:52<33:51,  5.54it/s, lr=0.000467, step_loss=0.005907/27/2023 18:17:42 - INFO - __main__ - train loss is 15.757789706985932\n",
      "Steps:  25%|▎| 3750/15000 [32:52<33:46,  5.55it/s, lr=0.000467, step_loss=0.001507/27/2023 18:17:42 - INFO - __main__ - train loss is 15.983551299374085\n",
      "Steps:  25%|▎| 3751/15000 [32:52<33:43,  5.56it/s, lr=0.000467, step_loss=0.226]07/27/2023 18:17:42 - INFO - __main__ - train loss is 16.502011871139985\n",
      "Steps:  25%|▎| 3752/15000 [32:53<33:41,  5.56it/s, lr=0.000467, step_loss=0.518]07/27/2023 18:17:42 - INFO - __main__ - train loss is 16.597477620642167\n",
      "Steps:  25%|▎| 3753/15000 [32:53<33:39,  5.57it/s, lr=0.000468, step_loss=0.095507/27/2023 18:17:43 - INFO - __main__ - train loss is 16.605143115099054\n",
      "Steps:  25%|▎| 3754/15000 [32:53<33:38,  5.57it/s, lr=0.000468, step_loss=0.007607/27/2023 18:17:43 - INFO - __main__ - train loss is 16.893787607725244\n",
      "Steps:  25%|▎| 3755/15000 [32:53<33:56,  5.52it/s, lr=0.000468, step_loss=0.289]07/27/2023 18:17:43 - INFO - __main__ - train loss is 16.896959471225273\n",
      "Steps:  25%|▎| 3756/15000 [32:53<33:56,  5.52it/s, lr=0.000468, step_loss=0.003107/27/2023 18:17:43 - INFO - __main__ - train loss is 16.981523799418937\n",
      "Steps:  25%|▎| 3757/15000 [32:53<33:50,  5.54it/s, lr=0.000468, step_loss=0.084607/27/2023 18:17:43 - INFO - __main__ - train loss is 16.982780639256816\n",
      "Steps:  25%|▎| 3758/15000 [32:54<33:46,  5.55it/s, lr=0.000468, step_loss=0.001207/27/2023 18:17:43 - INFO - __main__ - train loss is 16.995624178263824\n",
      "Steps:  25%|▎| 3759/15000 [32:54<33:42,  5.56it/s, lr=0.000468, step_loss=0.012807/27/2023 18:17:44 - INFO - __main__ - train loss is 16.997249057341833\n",
      "Steps:  25%|▎| 3760/15000 [32:54<33:40,  5.56it/s, lr=0.000468, step_loss=0.001607/27/2023 18:17:44 - INFO - __main__ - train loss is 17.208930602122564\n",
      "Steps:  25%|▎| 3761/15000 [32:54<33:53,  5.53it/s, lr=0.000469, step_loss=0.212]07/27/2023 18:17:44 - INFO - __main__ - train loss is 17.250906577159185\n",
      "Steps:  25%|▎| 3762/15000 [32:54<34:06,  5.49it/s, lr=0.000469, step_loss=0.042]07/27/2023 18:17:44 - INFO - __main__ - train loss is 17.55184405093314\n",
      "Steps:  25%|▎| 3763/15000 [32:54<33:59,  5.51it/s, lr=0.000469, step_loss=0.301]07/27/2023 18:17:44 - INFO - __main__ - train loss is 17.602595889766235\n",
      "Steps:  25%|▎| 3764/15000 [32:55<34:12,  5.47it/s, lr=0.000469, step_loss=0.050807/27/2023 18:17:45 - INFO - __main__ - train loss is 17.649654233653564\n",
      "Steps:  25%|▎| 3765/15000 [32:55<34:06,  5.49it/s, lr=0.000469, step_loss=0.047107/27/2023 18:17:45 - INFO - __main__ - train loss is 17.927364105184097\n",
      "Steps:  25%|▎| 3766/15000 [32:55<33:57,  5.51it/s, lr=0.000469, step_loss=0.278]07/27/2023 18:17:45 - INFO - __main__ - train loss is 17.943961640645284\n",
      "Steps:  25%|▎| 3767/15000 [32:55<34:11,  5.48it/s, lr=0.000469, step_loss=0.016607/27/2023 18:17:45 - INFO - __main__ - train loss is 17.945137307338882\n",
      "Steps:  25%|▎| 3768/15000 [32:55<34:07,  5.49it/s, lr=0.000469, step_loss=0.001107/27/2023 18:17:45 - INFO - __main__ - train loss is 17.971730839752126\n",
      "Steps:  25%|▎| 3769/15000 [32:56<34:06,  5.49it/s, lr=0.000469, step_loss=0.026607/27/2023 18:17:45 - INFO - __main__ - train loss is 18.081679713272024\n",
      "Steps:  25%|▊  | 3770/15000 [32:56<33:57,  5.51it/s, lr=0.00047, step_loss=0.11]07/27/2023 18:17:46 - INFO - __main__ - train loss is 18.396914851211477\n",
      "Steps:  25%|▌ | 3771/15000 [32:56<33:51,  5.53it/s, lr=0.00047, step_loss=0.315]07/27/2023 18:17:46 - INFO - __main__ - train loss is 18.928582202934194\n",
      "Steps:  25%|▌ | 3772/15000 [32:56<33:47,  5.54it/s, lr=0.00047, step_loss=0.532]07/27/2023 18:17:46 - INFO - __main__ - train loss is 18.946793349750806\n",
      "Steps:  25%|▎| 3773/15000 [32:56<33:44,  5.55it/s, lr=0.00047, step_loss=0.0182]07/27/2023 18:17:46 - INFO - __main__ - train loss is 18.952410995785613\n",
      "Steps:  25%|▎| 3774/15000 [32:56<33:41,  5.55it/s, lr=0.00047, step_loss=0.0056207/27/2023 18:17:46 - INFO - __main__ - train loss is 19.11514714342775\n",
      "Steps:  25%|▌ | 3775/15000 [32:57<33:50,  5.53it/s, lr=0.00047, step_loss=0.163]07/27/2023 18:17:47 - INFO - __main__ - train loss is 19.17574847472133\n",
      "Steps:  25%|▎| 3776/15000 [32:57<34:01,  5.50it/s, lr=0.00047, step_loss=0.0606]07/27/2023 18:17:47 - INFO - __main__ - train loss is 19.40630135667743\n",
      "Steps:  25%|▌ | 3777/15000 [32:57<34:09,  5.48it/s, lr=0.00047, step_loss=0.231]07/27/2023 18:17:47 - INFO - __main__ - train loss is 19.626541293982882\n",
      "Steps:  25%|▌ | 3778/15000 [32:57<33:59,  5.50it/s, lr=0.000471, step_loss=0.22]07/27/2023 18:17:47 - INFO - __main__ - train loss is 19.744390696112532\n",
      "Steps:  25%|▎| 3779/15000 [32:57<33:52,  5.52it/s, lr=0.000471, step_loss=0.118]07/27/2023 18:17:47 - INFO - __main__ - train loss is 19.769650894973893\n",
      "Steps:  25%|▎| 3780/15000 [32:58<33:48,  5.53it/s, lr=0.000471, step_loss=0.025307/27/2023 18:17:47 - INFO - __main__ - train loss is 19.86715185997309\n",
      "Steps:  25%|▎| 3781/15000 [32:58<33:43,  5.54it/s, lr=0.000471, step_loss=0.097507/27/2023 18:17:48 - INFO - __main__ - train loss is 20.188747796986718\n",
      "Steps:  25%|▎| 3782/15000 [32:58<33:41,  5.55it/s, lr=0.000471, step_loss=0.322]07/27/2023 18:17:48 - INFO - __main__ - train loss is 20.192229479376692\n",
      "Steps:  25%|▎| 3783/15000 [32:58<33:40,  5.55it/s, lr=0.000471, step_loss=0.003407/27/2023 18:17:48 - INFO - __main__ - train loss is 20.529211312357802\n",
      "Steps:  25%|▎| 3784/15000 [32:58<33:39,  5.55it/s, lr=0.000471, step_loss=0.337]07/27/2023 18:17:48 - INFO - __main__ - train loss is 20.648404016916174\n",
      "Steps:  25%|▎| 3785/15000 [32:58<33:38,  5.56it/s, lr=0.000471, step_loss=0.119]07/27/2023 18:17:48 - INFO - __main__ - train loss is 20.65277891914593\n",
      "Steps:  25%|▎| 3786/15000 [32:59<33:37,  5.56it/s, lr=0.000472, step_loss=0.004307/27/2023 18:17:49 - INFO - __main__ - train loss is 20.694934572384227\n",
      "Steps:  25%|▎| 3787/15000 [32:59<33:36,  5.56it/s, lr=0.000472, step_loss=0.042207/27/2023 18:17:49 - INFO - __main__ - train loss is 20.73500001739012\n",
      "Steps:  25%|▎| 3788/15000 [32:59<33:36,  5.56it/s, lr=0.000472, step_loss=0.040107/27/2023 18:17:49 - INFO - __main__ - train loss is 20.79547288577305\n",
      "Steps:  25%|▎| 3789/15000 [32:59<33:34,  5.57it/s, lr=0.000472, step_loss=0.060507/27/2023 18:17:49 - INFO - __main__ - train loss is 20.79793849500129\n",
      "Steps:  25%|▎| 3790/15000 [32:59<33:33,  5.57it/s, lr=0.000472, step_loss=0.002407/27/2023 18:17:49 - INFO - __main__ - train loss is 21.159141211828683\n",
      "Steps:  25%|▎| 3791/15000 [33:00<33:33,  5.57it/s, lr=0.000472, step_loss=0.361]07/27/2023 18:17:49 - INFO - __main__ - train loss is 21.163609612325672\n",
      "Steps:  25%|▎| 3792/15000 [33:00<33:42,  5.54it/s, lr=0.000472, step_loss=0.004407/27/2023 18:17:50 - INFO - __main__ - train loss is 21.204450551012997\n",
      "Steps:  25%|▎| 3793/15000 [33:00<33:43,  5.54it/s, lr=0.000472, step_loss=0.040807/27/2023 18:17:50 - INFO - __main__ - train loss is 21.336792263726238\n",
      "Steps:  25%|▎| 3794/15000 [33:00<33:40,  5.55it/s, lr=0.000473, step_loss=0.132]07/27/2023 18:17:50 - INFO - __main__ - train loss is 21.34999801736558\n",
      "Steps:  25%|▎| 3795/15000 [33:00<33:42,  5.54it/s, lr=0.000473, step_loss=0.013207/27/2023 18:17:50 - INFO - __main__ - train loss is 21.47233308624709\n",
      "Steps:  25%|▎| 3796/15000 [33:00<33:51,  5.52it/s, lr=0.000473, step_loss=0.122]07/27/2023 18:17:50 - INFO - __main__ - train loss is 21.83129544329131\n",
      "Steps:  25%|▎| 3797/15000 [33:01<33:49,  5.52it/s, lr=0.000473, step_loss=0.359]07/27/2023 18:17:51 - INFO - __main__ - train loss is 21.852062904799823\n",
      "Steps:  25%|▎| 3798/15000 [33:01<34:02,  5.48it/s, lr=0.000473, step_loss=0.020807/27/2023 18:17:51 - INFO - __main__ - train loss is 22.020426982606295\n",
      "Steps:  25%|▎| 3799/15000 [33:01<33:59,  5.49it/s, lr=0.000473, step_loss=0.168]07/27/2023 18:17:51 - INFO - __main__ - train loss is 22.397288346255664\n",
      "Steps:  25%|▎| 3800/15000 [33:01<34:03,  5.48it/s, lr=0.000473, step_loss=0.377]07/27/2023 18:17:51 - INFO - __main__ - train loss is 22.78579368587816\n",
      "Steps:  25%|▎| 3801/15000 [33:01<33:54,  5.51it/s, lr=0.000473, step_loss=0.389]07/27/2023 18:17:51 - INFO - __main__ - train loss is 22.787100782908965\n",
      "Steps:  25%|▎| 3802/15000 [33:02<33:46,  5.53it/s, lr=0.000474, step_loss=0.001307/27/2023 18:17:51 - INFO - __main__ - train loss is 22.864837875880767\n",
      "Steps:  25%|▎| 3803/15000 [33:02<33:52,  5.51it/s, lr=0.000474, step_loss=0.077707/27/2023 18:17:52 - INFO - __main__ - train loss is 22.87064692826243\n",
      "Steps:  25%|▎| 3804/15000 [33:02<34:04,  5.48it/s, lr=0.000474, step_loss=0.005807/27/2023 18:17:52 - INFO - __main__ - train loss is 23.05381453485461\n",
      "Steps:  25%|▎| 3805/15000 [33:02<34:08,  5.47it/s, lr=0.000474, step_loss=0.183]07/27/2023 18:17:52 - INFO - __main__ - train loss is 23.0794750310597\n",
      "Steps:  25%|▎| 3806/15000 [33:02<34:10,  5.46it/s, lr=0.000474, step_loss=0.025707/27/2023 18:17:52 - INFO - __main__ - train loss is 23.220582709473092\n",
      "Steps:  25%|▎| 3807/15000 [33:02<34:10,  5.46it/s, lr=0.000474, step_loss=0.141]07/27/2023 18:17:52 - INFO - __main__ - train loss is 23.225227022368927\n",
      "Steps:  25%|▎| 3808/15000 [33:03<34:12,  5.45it/s, lr=0.000474, step_loss=0.004607/27/2023 18:17:53 - INFO - __main__ - train loss is 23.235341809515376\n",
      "Steps:  25%|▎| 3809/15000 [33:03<34:11,  5.45it/s, lr=0.000474, step_loss=0.010107/27/2023 18:17:53 - INFO - __main__ - train loss is 23.280112109903712\n",
      "Steps:  25%|▎| 3810/15000 [33:03<33:58,  5.49it/s, lr=0.000475, step_loss=0.044807/27/2023 18:17:53 - INFO - __main__ - train loss is 23.282247286348138\n",
      "Steps:  25%|▎| 3811/15000 [33:03<33:49,  5.51it/s, lr=0.000475, step_loss=0.002107/27/2023 18:17:53 - INFO - __main__ - train loss is 23.289021401724312\n",
      "Steps:  25%|▎| 3812/15000 [33:03<33:44,  5.53it/s, lr=0.000475, step_loss=0.006707/27/2023 18:17:53 - INFO - __main__ - train loss is 23.622140734514687\n",
      "Steps:  25%|▎| 3813/15000 [33:04<33:41,  5.53it/s, lr=0.000475, step_loss=0.333]07/27/2023 18:17:53 - INFO - __main__ - train loss is 23.628032643871848\n",
      "Steps:  25%|▎| 3814/15000 [33:04<33:38,  5.54it/s, lr=0.000475, step_loss=0.005807/27/2023 18:17:54 - INFO - __main__ - train loss is 24.006825406628195\n",
      "Steps:  25%|▎| 3815/15000 [33:04<33:35,  5.55it/s, lr=0.000475, step_loss=0.379]07/27/2023 18:17:54 - INFO - __main__ - train loss is 24.018332677485887\n",
      "Steps:  25%|▎| 3816/15000 [33:04<33:34,  5.55it/s, lr=0.000475, step_loss=0.011507/27/2023 18:17:54 - INFO - __main__ - train loss is 24.045340916665737\n",
      "Steps:  25%|▎| 3817/15000 [33:04<33:52,  5.50it/s, lr=0.000476, step_loss=0.027]07/27/2023 18:17:54 - INFO - __main__ - train loss is 24.67875756934518\n",
      "Steps:  25%|▎| 3818/15000 [33:04<34:10,  5.45it/s, lr=0.000476, step_loss=0.633]07/27/2023 18:17:54 - INFO - __main__ - train loss is 24.75321833655471\n",
      "Steps:  25%|▎| 3819/15000 [33:05<34:23,  5.42it/s, lr=0.000476, step_loss=0.074507/27/2023 18:17:55 - INFO - __main__ - train loss is 24.785245976003353\n",
      "Steps:  25%|▎| 3820/15000 [33:05<34:13,  5.45it/s, lr=0.000476, step_loss=0.032]07/27/2023 18:17:55 - INFO - __main__ - train loss is 25.060435018094722\n",
      "Steps:  25%|▎| 3821/15000 [33:05<34:00,  5.48it/s, lr=0.000476, step_loss=0.275]07/27/2023 18:17:55 - INFO - __main__ - train loss is 25.42099948838586\n",
      "Steps:  25%|▎| 3822/15000 [33:05<34:07,  5.46it/s, lr=0.000476, step_loss=0.361]07/27/2023 18:17:55 - INFO - __main__ - train loss is 25.70252808049554\n",
      "Steps:  25%|▎| 3823/15000 [33:05<34:13,  5.44it/s, lr=0.000476, step_loss=0.282]07/27/2023 18:17:55 - INFO - __main__ - train loss is 25.7903233380639\n",
      "Steps:  25%|▎| 3824/15000 [33:06<34:31,  5.40it/s, lr=0.000476, step_loss=0.087807/27/2023 18:17:55 - INFO - __main__ - train loss is 26.170850804599468\n",
      "Steps:  26%|▎| 3825/15000 [33:06<34:11,  5.45it/s, lr=0.000476, step_loss=0.381]07/27/2023 18:17:56 - INFO - __main__ - train loss is 26.477017691882793\n",
      "Steps:  26%|▎| 3826/15000 [33:06<33:58,  5.48it/s, lr=0.000477, step_loss=0.306]07/27/2023 18:17:56 - INFO - __main__ - train loss is 26.478911976970267\n",
      "Steps:  26%|▎| 3827/15000 [33:06<34:01,  5.47it/s, lr=0.000477, step_loss=0.001807/27/2023 18:17:56 - INFO - __main__ - train loss is 26.541436787403654\n",
      "Steps:  26%|▎| 3828/15000 [33:06<33:50,  5.50it/s, lr=0.000477, step_loss=0.062507/27/2023 18:17:56 - INFO - __main__ - train loss is 26.551431046507787\n",
      "Steps:  26%|▎| 3829/15000 [33:06<33:44,  5.52it/s, lr=0.000477, step_loss=0.009907/27/2023 18:17:56 - INFO - __main__ - train loss is 26.72147964098258\n",
      "Steps:  26%|▌ | 3830/15000 [33:07<33:38,  5.53it/s, lr=0.000477, step_loss=0.17]07/27/2023 18:17:57 - INFO - __main__ - train loss is 26.953018502972554\n",
      "Steps:  26%|▎| 3831/15000 [33:07<33:53,  5.49it/s, lr=0.000477, step_loss=0.232]07/27/2023 18:17:57 - INFO - __main__ - train loss is 27.38127617695136\n",
      "Steps:  26%|▎| 3832/15000 [33:07<33:50,  5.50it/s, lr=0.000477, step_loss=0.428]07/27/2023 18:17:57 - INFO - __main__ - train loss is 27.40417796157999\n",
      "Steps:  26%|▎| 3833/15000 [33:07<33:42,  5.52it/s, lr=0.000478, step_loss=0.022907/27/2023 18:17:57 - INFO - __main__ - train loss is 27.419853681407403\n",
      "Steps:  26%|▎| 3834/15000 [33:07<33:36,  5.54it/s, lr=0.000478, step_loss=0.015707/27/2023 18:17:57 - INFO - __main__ - train loss is 27.920929843268823\n",
      "Steps:  26%|▎| 3835/15000 [33:08<33:32,  5.55it/s, lr=0.000478, step_loss=0.501]07/27/2023 18:17:57 - INFO - __main__ - train loss is 27.936272027611267\n",
      "Steps:  26%|▎| 3836/15000 [33:08<33:29,  5.56it/s, lr=0.000478, step_loss=0.015307/27/2023 18:17:58 - INFO - __main__ - train loss is 28.017252566933166\n",
      "Steps:  26%|▎| 3837/15000 [33:08<33:46,  5.51it/s, lr=0.000478, step_loss=0.081]07/27/2023 18:17:58 - INFO - __main__ - train loss is 28.105205329775345\n",
      "Steps:  26%|▎| 3838/15000 [33:08<33:44,  5.51it/s, lr=0.000478, step_loss=0.088]07/27/2023 18:17:58 - INFO - __main__ - train loss is 28.391525837301742\n",
      "Steps:  26%|▎| 3839/15000 [33:08<33:37,  5.53it/s, lr=0.000478, step_loss=0.286]07/27/2023 18:17:58 - INFO - __main__ - train loss is 28.520715060352813\n",
      "Steps:  26%|▎| 3840/15000 [33:08<33:33,  5.54it/s, lr=0.000478, step_loss=0.129]07/27/2023 18:17:58 - INFO - __main__ - train loss is 28.52847759629367\n",
      "Steps:  26%|▎| 3841/15000 [33:09<33:30,  5.55it/s, lr=0.000478, step_loss=0.007707/27/2023 18:17:59 - INFO - __main__ - train loss is 28.5339872596669\n",
      "Steps:  26%|▎| 3842/15000 [33:09<33:28,  5.55it/s, lr=0.000479, step_loss=0.005507/27/2023 18:17:59 - INFO - __main__ - train loss is 28.735958045523148\n",
      "Steps:  26%|▎| 3843/15000 [33:09<33:26,  5.56it/s, lr=0.000479, step_loss=0.202]07/27/2023 18:17:59 - INFO - __main__ - train loss is 29.023620551626664\n",
      "Steps:  26%|▎| 3844/15000 [33:09<33:24,  5.57it/s, lr=0.000479, step_loss=0.288]07/27/2023 18:17:59 - INFO - __main__ - train loss is 29.19768965820549\n",
      "Steps:  26%|▎| 3845/15000 [33:09<33:25,  5.56it/s, lr=0.000479, step_loss=0.174]07/27/2023 18:17:59 - INFO - __main__ - train loss is 29.211430464114528\n",
      "Steps:  26%|▎| 3846/15000 [33:10<33:24,  5.56it/s, lr=0.000479, step_loss=0.013707/27/2023 18:17:59 - INFO - __main__ - train loss is 29.34557126852451\n",
      "Steps:  26%|▎| 3847/15000 [33:10<33:43,  5.51it/s, lr=0.000479, step_loss=0.134]07/27/2023 18:18:00 - INFO - __main__ - train loss is 29.38338413479505\n",
      "Steps:  26%|▎| 3848/15000 [33:10<34:10,  5.44it/s, lr=0.000479, step_loss=0.037807/27/2023 18:18:00 - INFO - __main__ - train loss is 29.403354076843243\n",
      "Steps:  26%|▊  | 3849/15000 [33:10<33:55,  5.48it/s, lr=0.00048, step_loss=0.02]07/27/2023 18:18:00 - INFO - __main__ - train loss is 29.486326812009793\n",
      "Steps:  26%|▌ | 3850/15000 [33:10<33:44,  5.51it/s, lr=0.00048, step_loss=0.083]07/27/2023 18:18:00 - INFO - __main__ - train loss is 29.491308175201993\n",
      "Steps:  26%|▎| 3851/15000 [33:10<33:35,  5.53it/s, lr=0.00048, step_loss=0.0049807/27/2023 18:18:00 - INFO - __main__ - train loss is 29.499578003014904\n",
      "Steps:  26%|▎| 3852/15000 [33:11<33:30,  5.54it/s, lr=0.00048, step_loss=0.0082707/27/2023 18:18:01 - INFO - __main__ - train loss is 29.732850302185398\n",
      "Steps:  26%|▌ | 3853/15000 [33:11<33:27,  5.55it/s, lr=0.00048, step_loss=0.233]07/27/2023 18:18:01 - INFO - __main__ - train loss is 29.764264192606788\n",
      "Steps:  26%|▎| 3854/15000 [33:11<33:24,  5.56it/s, lr=0.00048, step_loss=0.0314]07/27/2023 18:18:01 - INFO - __main__ - train loss is 29.89204501750646\n",
      "Steps:  26%|▌ | 3855/15000 [33:11<33:22,  5.57it/s, lr=0.00048, step_loss=0.128]07/27/2023 18:18:01 - INFO - __main__ - train loss is 30.12998261692701\n",
      "Steps:  26%|▌ | 3856/15000 [33:11<33:20,  5.57it/s, lr=0.00048, step_loss=0.238]07/27/2023 18:18:01 - INFO - __main__ - train loss is 30.268808867956977\n",
      "Steps:  26%|▌ | 3857/15000 [33:12<33:22,  5.56it/s, lr=0.00048, step_loss=0.139]07/27/2023 18:18:01 - INFO - __main__ - train loss is 30.459894549276214\n",
      "Steps:  26%|▎| 3858/15000 [33:12<33:21,  5.57it/s, lr=0.000481, step_loss=0.191]07/27/2023 18:18:02 - INFO - __main__ - train loss is 30.486292993824463\n",
      "Steps:  26%|▎| 3859/15000 [33:12<33:20,  5.57it/s, lr=0.000481, step_loss=0.026407/27/2023 18:18:02 - INFO - __main__ - train loss is 30.52221920172451\n",
      "Steps:  26%|▎| 3860/15000 [33:12<33:19,  5.57it/s, lr=0.000481, step_loss=0.035907/27/2023 18:18:02 - INFO - __main__ - train loss is 30.763206025760155\n",
      "Steps:  26%|▎| 3861/15000 [33:12<33:38,  5.52it/s, lr=0.000481, step_loss=0.241]07/27/2023 18:18:02 - INFO - __main__ - train loss is 30.771566157403868\n",
      "Steps:  26%|▎| 3862/15000 [33:12<33:42,  5.51it/s, lr=0.000481, step_loss=0.008307/27/2023 18:18:02 - INFO - __main__ - train loss is 31.03236154204933\n",
      "Steps:  26%|▎| 3863/15000 [33:13<33:34,  5.53it/s, lr=0.000481, step_loss=0.261]07/27/2023 18:18:02 - INFO - __main__ - train loss is 31.041715995583218\n",
      "Steps:  26%|▎| 3864/15000 [33:13<33:29,  5.54it/s, lr=0.000481, step_loss=0.009307/27/2023 18:18:03 - INFO - __main__ - train loss is 31.624133006844204\n",
      "Steps:  26%|▎| 3865/15000 [33:13<33:43,  5.50it/s, lr=0.000481, step_loss=0.582]07/27/2023 18:18:03 - INFO - __main__ - train loss is 31.831933126959484\n",
      "Steps:  26%|▎| 3866/15000 [33:13<33:54,  5.47it/s, lr=0.000482, step_loss=0.208]07/27/2023 18:18:03 - INFO - __main__ - train loss is 31.905495816085022\n",
      "Steps:  26%|▎| 3867/15000 [33:13<34:05,  5.44it/s, lr=0.000482, step_loss=0.073607/27/2023 18:18:03 - INFO - __main__ - train loss is 31.92192479519872\n",
      "Steps:  26%|▎| 3868/15000 [33:14<33:57,  5.46it/s, lr=0.000482, step_loss=0.016407/27/2023 18:18:03 - INFO - __main__ - train loss is 31.938926725822967\n",
      "Steps:  26%|▎| 3869/15000 [33:14<33:44,  5.50it/s, lr=0.000482, step_loss=0.017]07/27/2023 18:18:04 - INFO - __main__ - train loss is 32.063172056514304\n",
      "Steps:  26%|▎| 3870/15000 [33:14<33:35,  5.52it/s, lr=0.000482, step_loss=0.124]07/27/2023 18:18:04 - INFO - __main__ - train loss is 32.066019443038385\n",
      "Steps:  26%|▎| 3871/15000 [33:14<33:47,  5.49it/s, lr=0.000482, step_loss=0.002807/27/2023 18:18:04 - INFO - __main__ - train loss is 32.082550105813425\n",
      "Steps:  26%|▎| 3872/15000 [33:14<33:47,  5.49it/s, lr=0.000482, step_loss=0.016507/27/2023 18:18:04 - INFO - __main__ - train loss is 32.18509626126615\n",
      "Steps:  26%|▎| 3873/15000 [33:14<33:38,  5.51it/s, lr=0.000483, step_loss=0.103]07/27/2023 18:18:04 - INFO - __main__ - train loss is 32.28962134307949\n",
      "Steps:  26%|▎| 3874/15000 [33:15<33:45,  5.49it/s, lr=0.000483, step_loss=0.105]07/27/2023 18:18:04 - INFO - __main__ - train loss is 32.29615553439362\n",
      "Steps:  26%|▎| 3875/15000 [33:15<33:55,  5.47it/s, lr=0.000483, step_loss=0.006507/27/2023 18:18:05 - INFO - __main__ - train loss is 32.29776112426771\n",
      "Steps:  26%|▎| 3876/15000 [33:15<34:06,  5.43it/s, lr=0.000483, step_loss=0.001607/27/2023 18:18:05 - INFO - __main__ - train loss is 32.29892629914684\n",
      "Steps:  26%|▎| 3877/15000 [33:15<33:51,  5.47it/s, lr=0.000483, step_loss=0.001107/27/2023 18:18:05 - INFO - __main__ - train loss is 32.41075341933174\n",
      "Steps:  26%|▎| 3878/15000 [33:15<33:40,  5.50it/s, lr=0.000483, step_loss=0.112]07/27/2023 18:18:05 - INFO - __main__ - train loss is 32.466501673392486\n",
      "Steps:  26%|▎| 3879/15000 [33:16<33:36,  5.52it/s, lr=0.000483, step_loss=0.055707/27/2023 18:18:05 - INFO - __main__ - train loss is 32.58111978851957\n",
      "Steps:  26%|▎| 3880/15000 [33:16<33:42,  5.50it/s, lr=0.000483, step_loss=0.115]07/27/2023 18:18:06 - INFO - __main__ - train loss is 32.79889979743166\n",
      "Steps:  26%|▎| 3881/15000 [33:16<33:34,  5.52it/s, lr=0.000483, step_loss=0.218]07/27/2023 18:18:06 - INFO - __main__ - train loss is 32.80159924941836\n",
      "Steps:  26%|▎| 3882/15000 [33:16<33:47,  5.48it/s, lr=0.000484, step_loss=0.002707/27/2023 18:18:06 - INFO - __main__ - train loss is 32.90808205323992\n",
      "Steps:  26%|▎| 3883/15000 [33:16<33:43,  5.49it/s, lr=0.000484, step_loss=0.106]07/27/2023 18:18:06 - INFO - __main__ - train loss is 32.99527645128546\n",
      "Steps:  26%|▎| 3884/15000 [33:16<33:54,  5.46it/s, lr=0.000484, step_loss=0.087207/27/2023 18:18:06 - INFO - __main__ - train loss is 33.02723748626886\n",
      "Steps:  26%|▎| 3885/15000 [33:17<33:49,  5.48it/s, lr=0.000484, step_loss=0.032]07/27/2023 18:18:07 - INFO - __main__ - train loss is 33.02924326172797\n",
      "Steps:  26%|▎| 3886/15000 [33:17<33:53,  5.47it/s, lr=0.000484, step_loss=0.002007/27/2023 18:18:07 - INFO - __main__ - train loss is 33.031105360307265\n",
      "Steps:  26%|▎| 3887/15000 [33:17<33:41,  5.50it/s, lr=0.000484, step_loss=0.001807/27/2023 18:18:07 - INFO - __main__ - train loss is 33.413371524133254\n",
      "Steps:  26%|▎| 3888/15000 [33:17<33:32,  5.52it/s, lr=0.000484, step_loss=0.382]07/27/2023 18:18:07 - INFO - __main__ - train loss is 33.421658074774314\n",
      "Steps:  26%|▎| 3889/15000 [33:17<33:45,  5.49it/s, lr=0.000485, step_loss=0.008207/27/2023 18:18:07 - INFO - __main__ - train loss is 33.429655471176375\n",
      "Steps:  26%|▎| 3890/15000 [33:18<33:41,  5.50it/s, lr=0.000485, step_loss=0.008]07/27/2023 18:18:07 - INFO - __main__ - train loss is 33.43272683565738\n",
      "Steps:  26%|▎| 3891/15000 [33:18<33:44,  5.49it/s, lr=0.000485, step_loss=0.003007/27/2023 18:18:08 - INFO - __main__ - train loss is 33.498431732703466\n",
      "Steps:  26%|▎| 3892/15000 [33:18<33:48,  5.48it/s, lr=0.000485, step_loss=0.065707/27/2023 18:18:08 - INFO - __main__ - train loss is 33.60721824859502\n",
      "Steps:  26%|▎| 3893/15000 [33:18<33:37,  5.50it/s, lr=0.000485, step_loss=0.109]07/27/2023 18:18:08 - INFO - __main__ - train loss is 33.60953404690372\n",
      "Steps:  26%|▎| 3894/15000 [33:18<33:50,  5.47it/s, lr=0.000485, step_loss=0.002307/27/2023 18:18:08 - INFO - __main__ - train loss is 33.65431111986982\n",
      "Steps:  26%|▎| 3895/15000 [33:18<33:54,  5.46it/s, lr=0.000485, step_loss=0.044807/27/2023 18:18:08 - INFO - __main__ - train loss is 33.8748320483719\n",
      "Steps:  26%|▎| 3896/15000 [33:19<33:40,  5.49it/s, lr=0.000485, step_loss=0.221]07/27/2023 18:18:09 - INFO - __main__ - train loss is 34.17334447737085\n",
      "Steps:  26%|▎| 3897/15000 [33:19<33:31,  5.52it/s, lr=0.000485, step_loss=0.299]07/27/2023 18:18:09 - INFO - __main__ - train loss is 34.219568397209514\n",
      "Steps:  26%|▎| 3898/15000 [33:19<33:24,  5.54it/s, lr=0.000486, step_loss=0.046207/27/2023 18:18:09 - INFO - __main__ - train loss is 34.34968198399292\n",
      "Steps:  26%|▌ | 3899/15000 [33:19<33:21,  5.55it/s, lr=0.000486, step_loss=0.13]07/27/2023 18:18:09 - INFO - __main__ - train loss is 34.37974161590682\n",
      "Steps:  26%|▎| 3900/15000 [33:19<33:19,  5.55it/s, lr=0.000486, step_loss=0.030107/27/2023 18:18:09 - INFO - __main__ - train loss is 34.55178923095809\n",
      "Steps:  26%|▎| 3901/15000 [33:20<33:37,  5.50it/s, lr=0.000486, step_loss=0.172]07/27/2023 18:18:09 - INFO - __main__ - train loss is 34.6591398337041\n",
      "Steps:  26%|▎| 3902/15000 [33:20<33:55,  5.45it/s, lr=0.000486, step_loss=0.107]07/27/2023 18:18:10 - INFO - __main__ - train loss is 34.905613235489\n",
      "Steps:  26%|▎| 3903/15000 [33:20<33:58,  5.44it/s, lr=0.000486, step_loss=0.246]07/27/2023 18:18:10 - INFO - __main__ - train loss is 34.91364548477577\n",
      "Steps:  26%|▎| 3904/15000 [33:20<33:48,  5.47it/s, lr=0.000486, step_loss=0.008007/27/2023 18:18:10 - INFO - __main__ - train loss is 34.91708494751947\n",
      "Steps:  26%|▎| 3905/15000 [33:20<33:39,  5.49it/s, lr=0.000487, step_loss=0.003407/27/2023 18:18:10 - INFO - __main__ - train loss is 35.07080204813974\n",
      "Steps:  26%|▎| 3906/15000 [33:20<33:32,  5.51it/s, lr=0.000487, step_loss=0.154]07/27/2023 18:18:10 - INFO - __main__ - train loss is 35.10832307144301\n",
      "Steps:  26%|▎| 3907/15000 [33:21<33:28,  5.52it/s, lr=0.000487, step_loss=0.037507/27/2023 18:18:11 - INFO - __main__ - train loss is 35.11804694245802\n",
      "Steps:  26%|▎| 3908/15000 [33:21<33:23,  5.54it/s, lr=0.000487, step_loss=0.009707/27/2023 18:18:11 - INFO - __main__ - train loss is 35.20285353373038\n",
      "Steps:  26%|▎| 3909/15000 [33:21<33:19,  5.55it/s, lr=0.000487, step_loss=0.084807/27/2023 18:18:11 - INFO - __main__ - train loss is 35.20432380150305\n",
      "Steps:  26%|▎| 3910/15000 [33:21<33:17,  5.55it/s, lr=0.000487, step_loss=0.001407/27/2023 18:18:11 - INFO - __main__ - train loss is 35.214416286267806\n",
      "Steps:  26%|▎| 3911/15000 [33:21<33:14,  5.56it/s, lr=0.000487, step_loss=0.010107/27/2023 18:18:11 - INFO - __main__ - train loss is 35.42037256649928\n",
      "Steps:  26%|▎| 3912/15000 [33:22<33:13,  5.56it/s, lr=0.000487, step_loss=0.206]07/27/2023 18:18:11 - INFO - __main__ - train loss is 35.74684800795512\n",
      "Steps:  26%|▎| 3913/15000 [33:22<33:11,  5.57it/s, lr=0.000487, step_loss=0.326]07/27/2023 18:18:12 - INFO - __main__ - train loss is 35.74853887484642\n",
      "Steps:  26%|▎| 3914/15000 [33:22<33:09,  5.57it/s, lr=0.000488, step_loss=0.001607/27/2023 18:18:12 - INFO - __main__ - train loss is 35.752642293286044\n",
      "Steps:  26%|▎| 3915/15000 [33:22<33:09,  5.57it/s, lr=0.000488, step_loss=0.004107/27/2023 18:18:12 - INFO - __main__ - train loss is 35.758310600940604\n",
      "Steps:  26%|▎| 3916/15000 [33:22<33:09,  5.57it/s, lr=0.000488, step_loss=0.005607/27/2023 18:18:12 - INFO - __main__ - train loss is 35.76927774568321\n",
      "Steps:  26%|▎| 3917/15000 [33:22<33:10,  5.57it/s, lr=0.000488, step_loss=0.011]07/27/2023 18:18:12 - INFO - __main__ - train loss is 35.774533114687074\n",
      "Steps:  26%|▎| 3918/15000 [33:23<33:09,  5.57it/s, lr=0.000488, step_loss=0.005207/27/2023 18:18:12 - INFO - __main__ - train loss is 35.78802063810872\n",
      "Steps:  26%|▎| 3919/15000 [33:23<33:09,  5.57it/s, lr=0.000488, step_loss=0.013507/27/2023 18:18:13 - INFO - __main__ - train loss is 35.87600226450013\n",
      "Steps:  26%|▎| 3920/15000 [33:23<33:09,  5.57it/s, lr=0.000488, step_loss=0.088]07/27/2023 18:18:13 - INFO - __main__ - train loss is 36.03716851520585\n",
      "Steps:  26%|▎| 3921/15000 [33:23<33:08,  5.57it/s, lr=0.000489, step_loss=0.161]07/27/2023 18:18:13 - INFO - __main__ - train loss is 36.150452715635765\n",
      "Steps:  26%|▎| 3922/15000 [33:23<33:08,  5.57it/s, lr=0.000489, step_loss=0.113]07/27/2023 18:18:13 - INFO - __main__ - train loss is 36.18864244344877\n",
      "Steps:  26%|▎| 3923/15000 [33:24<33:07,  5.57it/s, lr=0.000489, step_loss=0.038207/27/2023 18:18:13 - INFO - __main__ - train loss is 36.342946873337496\n",
      "Steps:  26%|▎| 3924/15000 [33:24<33:06,  5.58it/s, lr=0.000489, step_loss=0.154]07/27/2023 18:18:14 - INFO - __main__ - train loss is 36.62893597903894\n",
      "Steps:  26%|▎| 3925/15000 [33:24<33:04,  5.58it/s, lr=0.000489, step_loss=0.286]07/27/2023 18:18:14 - INFO - __main__ - train loss is 36.6315595608321\n",
      "Steps:  26%|▎| 3926/15000 [33:24<33:04,  5.58it/s, lr=0.000489, step_loss=0.002607/27/2023 18:18:14 - INFO - __main__ - train loss is 36.6499854575959\n",
      "Steps:  26%|▎| 3927/15000 [33:24<33:02,  5.58it/s, lr=0.000489, step_loss=0.018407/27/2023 18:18:14 - INFO - __main__ - train loss is 36.927130128082354\n",
      "Steps:  26%|▎| 3928/15000 [33:24<33:01,  5.59it/s, lr=0.000489, step_loss=0.277]07/27/2023 18:18:14 - INFO - __main__ - train loss is 37.16393410676392\n",
      "Steps:  26%|▌ | 3929/15000 [33:25<33:00,  5.59it/s, lr=0.00049, step_loss=0.237]07/27/2023 18:18:14 - INFO - __main__ - train loss is 37.198633867141325\n",
      "Steps:  26%|▎| 3930/15000 [33:25<33:00,  5.59it/s, lr=0.00049, step_loss=0.0347]07/27/2023 18:18:15 - INFO - __main__ - train loss is 37.643817174073774\n",
      "Steps:  26%|▌ | 3931/15000 [33:25<32:59,  5.59it/s, lr=0.00049, step_loss=0.445]07/27/2023 18:18:15 - INFO - __main__ - train loss is 37.839395928021986\n",
      "Steps:  26%|▌ | 3932/15000 [33:25<32:59,  5.59it/s, lr=0.00049, step_loss=0.196]07/27/2023 18:18:15 - INFO - __main__ - train loss is 37.85904883482726\n",
      "Steps:  26%|▎| 3933/15000 [33:25<32:59,  5.59it/s, lr=0.00049, step_loss=0.0197]07/27/2023 18:18:15 - INFO - __main__ - train loss is 37.86423630808713\n",
      "Steps:  26%|▎| 3934/15000 [33:25<32:59,  5.59it/s, lr=0.00049, step_loss=0.0051907/27/2023 18:18:15 - INFO - __main__ - train loss is 38.41757483576657\n",
      "Steps:  26%|▌ | 3935/15000 [33:26<33:00,  5.59it/s, lr=0.00049, step_loss=0.553]07/27/2023 18:18:16 - INFO - __main__ - train loss is 38.421608730976004\n",
      "Steps:  26%|▎| 3936/15000 [33:26<33:01,  5.58it/s, lr=0.00049, step_loss=0.0040307/27/2023 18:18:16 - INFO - __main__ - train loss is 38.423149777401704\n",
      "Steps:  26%|▎| 3937/15000 [33:26<33:00,  5.59it/s, lr=0.000491, step_loss=0.001507/27/2023 18:18:16 - INFO - __main__ - train loss is 38.49226535652997\n",
      "Steps:  26%|▎| 3938/15000 [33:26<32:59,  5.59it/s, lr=0.000491, step_loss=0.069107/27/2023 18:18:16 - INFO - __main__ - train loss is 38.49647774809273\n",
      "Steps:  26%|▎| 3939/15000 [33:27<48:38,  3.79it/s, lr=0.000491, step_loss=0.004207/27/2023 18:18:17 - INFO - __main__ - Per validation step average loss is 0.0185194481164217\n",
      "07/27/2023 18:18:17 - INFO - __main__ - Cumulative validation average loss is 0.0185194481164217\n",
      "07/27/2023 18:18:18 - INFO - __main__ - Per validation step average loss is 0.15091900527477264\n",
      "07/27/2023 18:18:18 - INFO - __main__ - Cumulative validation average loss is 0.16943845339119434\n",
      "07/27/2023 18:18:18 - INFO - __main__ - Per validation step average loss is 0.020621787756681442\n",
      "07/27/2023 18:18:18 - INFO - __main__ - Cumulative validation average loss is 0.19006024114787579\n",
      "07/27/2023 18:18:19 - INFO - __main__ - Per validation step average loss is 0.08473947644233704\n",
      "07/27/2023 18:18:19 - INFO - __main__ - Cumulative validation average loss is 0.2747997175902128\n",
      "07/27/2023 18:18:19 - INFO - __main__ - Per validation step average loss is 0.06335189193487167\n",
      "07/27/2023 18:18:19 - INFO - __main__ - Cumulative validation average loss is 0.3381516095250845\n",
      "07/27/2023 18:18:19 - INFO - __main__ - Per validation step average loss is 0.023112602531909943\n",
      "07/27/2023 18:18:19 - INFO - __main__ - Cumulative validation average loss is 0.36126421205699444\n",
      "07/27/2023 18:18:20 - INFO - __main__ - Per validation step average loss is 0.009239420294761658\n",
      "07/27/2023 18:18:20 - INFO - __main__ - Cumulative validation average loss is 0.3705036323517561\n",
      "07/27/2023 18:18:20 - INFO - __main__ - Per validation step average loss is 0.04256298765540123\n",
      "07/27/2023 18:18:20 - INFO - __main__ - Cumulative validation average loss is 0.4130666200071573\n",
      "07/27/2023 18:18:21 - INFO - __main__ - Per validation step average loss is 0.024444984272122383\n",
      "07/27/2023 18:18:21 - INFO - __main__ - Cumulative validation average loss is 0.4375116042792797\n",
      "07/27/2023 18:18:21 - INFO - __main__ - Per validation step average loss is 0.08531602472066879\n",
      "07/27/2023 18:18:21 - INFO - __main__ - Cumulative validation average loss is 0.5228276289999485\n",
      "07/27/2023 18:18:21 - INFO - __main__ - Per validation step average loss is 0.03619881719350815\n",
      "07/27/2023 18:18:21 - INFO - __main__ - Cumulative validation average loss is 0.5590264461934566\n",
      "07/27/2023 18:18:22 - INFO - __main__ - Per validation step average loss is 0.007064818870276213\n",
      "07/27/2023 18:18:22 - INFO - __main__ - Cumulative validation average loss is 0.5660912650637329\n",
      "07/27/2023 18:18:22 - INFO - __main__ - Per validation step average loss is 0.0515240803360939\n",
      "07/27/2023 18:18:22 - INFO - __main__ - Cumulative validation average loss is 0.6176153453998268\n",
      "07/27/2023 18:18:23 - INFO - __main__ - Per validation step average loss is 0.03951948508620262\n",
      "07/27/2023 18:18:23 - INFO - __main__ - Cumulative validation average loss is 0.6571348304860294\n",
      "07/27/2023 18:18:23 - INFO - __main__ - Per validation step average loss is 0.4187508523464203\n",
      "07/27/2023 18:18:23 - INFO - __main__ - Cumulative validation average loss is 1.0758856828324497\n",
      "07/27/2023 18:18:24 - INFO - __main__ - Per validation step average loss is 0.011955340392887592\n",
      "07/27/2023 18:18:24 - INFO - __main__ - Cumulative validation average loss is 1.0878410232253373\n",
      "07/27/2023 18:18:24 - INFO - __main__ - Per validation step average loss is 0.22696542739868164\n",
      "07/27/2023 18:18:24 - INFO - __main__ - Cumulative validation average loss is 1.314806450624019\n",
      "07/27/2023 18:18:24 - INFO - __main__ - Per validation step average loss is 0.433322936296463\n",
      "07/27/2023 18:18:24 - INFO - __main__ - Cumulative validation average loss is 1.748129386920482\n",
      "07/27/2023 18:18:25 - INFO - __main__ - Per validation step average loss is 0.11429497599601746\n",
      "07/27/2023 18:18:25 - INFO - __main__ - Cumulative validation average loss is 1.8624243629164994\n",
      "07/27/2023 18:18:25 - INFO - __main__ - Per validation step average loss is 0.0035479613579809666\n",
      "07/27/2023 18:18:25 - INFO - __main__ - Cumulative validation average loss is 1.8659723242744803\n",
      "07/27/2023 18:18:26 - INFO - __main__ - Per validation step average loss is 0.06301292777061462\n",
      "07/27/2023 18:18:26 - INFO - __main__ - Cumulative validation average loss is 1.928985252045095\n",
      "07/27/2023 18:18:26 - INFO - __main__ - Per validation step average loss is 0.10508784651756287\n",
      "07/27/2023 18:18:26 - INFO - __main__ - Cumulative validation average loss is 2.034073098562658\n",
      "07/27/2023 18:18:26 - INFO - __main__ - Per validation step average loss is 0.04152795672416687\n",
      "07/27/2023 18:18:26 - INFO - __main__ - Cumulative validation average loss is 2.0756010552868247\n",
      "07/27/2023 18:18:27 - INFO - __main__ - Per validation step average loss is 0.01021893322467804\n",
      "07/27/2023 18:18:27 - INFO - __main__ - Cumulative validation average loss is 2.0858199885115027\n",
      "07/27/2023 18:18:27 - INFO - __main__ - Per validation step average loss is 0.08664694428443909\n",
      "07/27/2023 18:18:27 - INFO - __main__ - Cumulative validation average loss is 2.172466932795942\n",
      "07/27/2023 18:18:28 - INFO - __main__ - Per validation step average loss is 0.012755596078932285\n",
      "07/27/2023 18:18:28 - INFO - __main__ - Cumulative validation average loss is 2.185222528874874\n",
      "07/27/2023 18:18:28 - INFO - __main__ - Per validation step average loss is 0.188924640417099\n",
      "07/27/2023 18:18:28 - INFO - __main__ - Cumulative validation average loss is 2.374147169291973\n",
      "07/27/2023 18:18:28 - INFO - __main__ - Per validation step average loss is 0.2152058631181717\n",
      "07/27/2023 18:18:28 - INFO - __main__ - Cumulative validation average loss is 2.589353032410145\n",
      "07/27/2023 18:18:29 - INFO - __main__ - Per validation step average loss is 0.001673828111961484\n",
      "07/27/2023 18:18:29 - INFO - __main__ - Cumulative validation average loss is 2.5910268605221063\n",
      "07/27/2023 18:18:29 - INFO - __main__ - Per validation step average loss is 0.02099776268005371\n",
      "07/27/2023 18:18:29 - INFO - __main__ - Cumulative validation average loss is 2.61202462320216\n",
      "07/27/2023 18:18:30 - INFO - __main__ - Per validation step average loss is 0.4136200547218323\n",
      "07/27/2023 18:18:30 - INFO - __main__ - Cumulative validation average loss is 3.0256446779239923\n",
      "07/27/2023 18:18:30 - INFO - __main__ - Per validation step average loss is 0.11697007715702057\n",
      "07/27/2023 18:18:30 - INFO - __main__ - Cumulative validation average loss is 3.142614755081013\n",
      "07/27/2023 18:18:30 - INFO - __main__ - Per validation step average loss is 0.2161954939365387\n",
      "07/27/2023 18:18:30 - INFO - __main__ - Cumulative validation average loss is 3.3588102490175515\n",
      "07/27/2023 18:18:31 - INFO - __main__ - Per validation step average loss is 0.11567044258117676\n",
      "07/27/2023 18:18:31 - INFO - __main__ - Cumulative validation average loss is 3.4744806915987283\n",
      "07/27/2023 18:18:31 - INFO - __main__ - Per validation step average loss is 0.03567887842655182\n",
      "07/27/2023 18:18:31 - INFO - __main__ - Cumulative validation average loss is 3.51015957002528\n",
      "07/27/2023 18:18:32 - INFO - __main__ - Per validation step average loss is 0.013372311368584633\n",
      "07/27/2023 18:18:32 - INFO - __main__ - Cumulative validation average loss is 3.5235318813938648\n",
      "07/27/2023 18:18:32 - INFO - __main__ - Per validation step average loss is 0.051321469247341156\n",
      "07/27/2023 18:18:32 - INFO - __main__ - Cumulative validation average loss is 3.574853350641206\n",
      "07/27/2023 18:18:33 - INFO - __main__ - Per validation step average loss is 0.21198444068431854\n",
      "07/27/2023 18:18:33 - INFO - __main__ - Cumulative validation average loss is 3.7868377913255244\n",
      "07/27/2023 18:18:33 - INFO - __main__ - Per validation step average loss is 0.0013696225360035896\n",
      "07/27/2023 18:18:33 - INFO - __main__ - Cumulative validation average loss is 3.788207413861528\n",
      "07/27/2023 18:18:33 - INFO - __main__ - Per validation step average loss is 0.14578776061534882\n",
      "07/27/2023 18:18:33 - INFO - __main__ - Cumulative validation average loss is 3.933995174476877\n",
      "07/27/2023 18:18:34 - INFO - __main__ - Per validation step average loss is 0.16029682755470276\n",
      "07/27/2023 18:18:34 - INFO - __main__ - Cumulative validation average loss is 4.09429200203158\n",
      "07/27/2023 18:18:34 - INFO - __main__ - Per validation step average loss is 0.03575751930475235\n",
      "07/27/2023 18:18:34 - INFO - __main__ - Cumulative validation average loss is 4.130049521336332\n",
      "07/27/2023 18:18:35 - INFO - __main__ - Per validation step average loss is 0.3137865662574768\n",
      "07/27/2023 18:18:35 - INFO - __main__ - Cumulative validation average loss is 4.443836087593809\n",
      "07/27/2023 18:18:35 - INFO - __main__ - Per validation step average loss is 0.2916817367076874\n",
      "07/27/2023 18:18:35 - INFO - __main__ - Cumulative validation average loss is 4.735517824301496\n",
      "07/27/2023 18:18:35 - INFO - __main__ - Per validation step average loss is 0.2627463638782501\n",
      "07/27/2023 18:18:35 - INFO - __main__ - Cumulative validation average loss is 4.998264188179746\n",
      "07/27/2023 18:18:36 - INFO - __main__ - Per validation step average loss is 0.007087107747793198\n",
      "07/27/2023 18:18:36 - INFO - __main__ - Cumulative validation average loss is 5.0053512959275395\n",
      "07/27/2023 18:18:36 - INFO - __main__ - Per validation step average loss is 0.0025747225154191256\n",
      "07/27/2023 18:18:36 - INFO - __main__ - Cumulative validation average loss is 5.007926018442959\n",
      "07/27/2023 18:18:37 - INFO - __main__ - Per validation step average loss is 0.0038290272932499647\n",
      "07/27/2023 18:18:37 - INFO - __main__ - Cumulative validation average loss is 5.011755045736209\n",
      "07/27/2023 18:18:37 - INFO - __main__ - Per validation step average loss is 0.08577823638916016\n",
      "07/27/2023 18:18:37 - INFO - __main__ - Cumulative validation average loss is 5.097533282125369\n",
      "07/27/2023 18:18:37 - INFO - __main__ - Per validation step average loss is 0.035976480692625046\n",
      "07/27/2023 18:18:37 - INFO - __main__ - Cumulative validation average loss is 5.133509762817994\n",
      "07/27/2023 18:18:38 - INFO - __main__ - Per validation step average loss is 0.023150283843278885\n",
      "07/27/2023 18:18:38 - INFO - __main__ - Cumulative validation average loss is 5.156660046661273\n",
      "07/27/2023 18:18:38 - INFO - __main__ - Per validation step average loss is 0.04345324635505676\n",
      "07/27/2023 18:18:38 - INFO - __main__ - Cumulative validation average loss is 5.200113293016329\n",
      "07/27/2023 18:18:39 - INFO - __main__ - Per validation step average loss is 0.022768644616007805\n",
      "07/27/2023 18:18:39 - INFO - __main__ - Cumulative validation average loss is 5.222881937632337\n",
      "07/27/2023 18:18:39 - INFO - __main__ - Per validation step average loss is 0.0019999092910438776\n",
      "07/27/2023 18:18:39 - INFO - __main__ - Cumulative validation average loss is 5.224881846923381\n",
      "07/27/2023 18:18:39 - INFO - __main__ - Per validation step average loss is 0.35404953360557556\n",
      "07/27/2023 18:18:39 - INFO - __main__ - Cumulative validation average loss is 5.578931380528957\n",
      "07/27/2023 18:18:40 - INFO - __main__ - Per validation step average loss is 0.025467712432146072\n",
      "07/27/2023 18:18:40 - INFO - __main__ - Cumulative validation average loss is 5.604399092961103\n",
      "07/27/2023 18:18:40 - INFO - __main__ - Per validation step average loss is 0.03523491322994232\n",
      "07/27/2023 18:18:40 - INFO - __main__ - Cumulative validation average loss is 5.639634006191045\n",
      "07/27/2023 18:18:41 - INFO - __main__ - Per validation step average loss is 0.3376402258872986\n",
      "07/27/2023 18:18:41 - INFO - __main__ - Cumulative validation average loss is 5.977274232078344\n",
      "07/27/2023 18:18:41 - INFO - __main__ - Per validation step average loss is 0.3088907301425934\n",
      "07/27/2023 18:18:41 - INFO - __main__ - Cumulative validation average loss is 6.286164962220937\n",
      "07/27/2023 18:18:42 - INFO - __main__ - Per validation step average loss is 0.014480160549283028\n",
      "07/27/2023 18:18:42 - INFO - __main__ - Cumulative validation average loss is 6.30064512277022\n",
      "07/27/2023 18:18:42 - INFO - __main__ - Per validation step average loss is 0.11697519570589066\n",
      "07/27/2023 18:18:42 - INFO - __main__ - Cumulative validation average loss is 6.417620318476111\n",
      "07/27/2023 18:18:42 - INFO - __main__ - Per validation step average loss is 0.010960537940263748\n",
      "07/27/2023 18:18:42 - INFO - __main__ - Cumulative validation average loss is 6.4285808564163744\n",
      "07/27/2023 18:18:43 - INFO - __main__ - Per validation step average loss is 0.002293879631906748\n",
      "07/27/2023 18:18:43 - INFO - __main__ - Cumulative validation average loss is 6.430874736048281\n",
      "07/27/2023 18:18:43 - INFO - __main__ - Per validation step average loss is 0.16337113082408905\n",
      "07/27/2023 18:18:43 - INFO - __main__ - Cumulative validation average loss is 6.59424586687237\n",
      "07/27/2023 18:18:44 - INFO - __main__ - Per validation step average loss is 0.021044671535491943\n",
      "07/27/2023 18:18:44 - INFO - __main__ - Cumulative validation average loss is 6.615290538407862\n",
      "07/27/2023 18:18:44 - INFO - __main__ - Per validation step average loss is 0.272230863571167\n",
      "07/27/2023 18:18:44 - INFO - __main__ - Cumulative validation average loss is 6.887521401979029\n",
      "07/27/2023 18:18:44 - INFO - __main__ - Per validation step average loss is 0.0015157172456383705\n",
      "07/27/2023 18:18:44 - INFO - __main__ - Cumulative validation average loss is 6.8890371192246675\n",
      "07/27/2023 18:18:45 - INFO - __main__ - Per validation step average loss is 0.06840281188488007\n",
      "07/27/2023 18:18:45 - INFO - __main__ - Cumulative validation average loss is 6.957439931109548\n",
      "07/27/2023 18:18:45 - INFO - __main__ - Per validation step average loss is 0.1793459951877594\n",
      "07/27/2023 18:18:45 - INFO - __main__ - Cumulative validation average loss is 7.136785926297307\n",
      "07/27/2023 18:18:46 - INFO - __main__ - Per validation step average loss is 0.11685740947723389\n",
      "07/27/2023 18:18:46 - INFO - __main__ - Cumulative validation average loss is 7.253643335774541\n",
      "07/27/2023 18:18:46 - INFO - __main__ - Per validation step average loss is 0.29381513595581055\n",
      "07/27/2023 18:18:46 - INFO - __main__ - Cumulative validation average loss is 7.5474584717303514\n",
      "07/27/2023 18:18:46 - INFO - __main__ - Per validation step average loss is 0.0016038911417126656\n",
      "07/27/2023 18:18:46 - INFO - __main__ - Cumulative validation average loss is 7.549062362872064\n",
      "07/27/2023 18:18:47 - INFO - __main__ - Per validation step average loss is 0.050513118505477905\n",
      "07/27/2023 18:18:47 - INFO - __main__ - Cumulative validation average loss is 7.599575481377542\n",
      "07/27/2023 18:18:47 - INFO - __main__ - Per validation step average loss is 0.1568731665611267\n",
      "07/27/2023 18:18:47 - INFO - __main__ - Cumulative validation average loss is 7.756448647938669\n",
      "07/27/2023 18:18:48 - INFO - __main__ - Per validation step average loss is 0.0035180107224732637\n",
      "07/27/2023 18:18:48 - INFO - __main__ - Cumulative validation average loss is 7.759966658661142\n",
      "07/27/2023 18:18:48 - INFO - __main__ - Per validation step average loss is 0.02780533768236637\n",
      "07/27/2023 18:18:48 - INFO - __main__ - Cumulative validation average loss is 7.787771996343508\n",
      "07/27/2023 18:18:48 - INFO - __main__ - Per validation step average loss is 0.036376915872097015\n",
      "07/27/2023 18:18:48 - INFO - __main__ - Cumulative validation average loss is 7.824148912215605\n",
      "07/27/2023 18:18:49 - INFO - __main__ - Per validation step average loss is 0.10224175453186035\n",
      "07/27/2023 18:18:49 - INFO - __main__ - Cumulative validation average loss is 7.926390666747466\n",
      "07/27/2023 18:18:50 - INFO - __main__ - Per validation step average loss is 0.0012239618226885796\n",
      "07/27/2023 18:18:50 - INFO - __main__ - Cumulative validation average loss is 7.927614628570154\n",
      "07/27/2023 18:18:50 - INFO - __main__ - Average validation loss for Epoch 12 is 0.1003495522603817\n",
      "07/27/2023 18:18:50 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:19:46 - INFO - __main__ - Starting epoch 13\n",
      "07/27/2023 18:19:47 - INFO - __main__ - train loss is 0.019366655498743057\n",
      "Steps:  26%|▎| 3940/15000 [34:58<84:21:39, 27.46s/it, lr=0.000491, step_loss=0.007/27/2023 18:19:47 - INFO - __main__ - train loss is 0.08661552146077156\n",
      "Steps:  26%|▎| 3941/15000 [34:58<59:13:01, 19.28s/it, lr=0.000491, step_loss=0.007/27/2023 18:19:48 - INFO - __main__ - train loss is 0.4112236984074116\n",
      "Steps:  26%|▎| 3942/15000 [34:58<41:36:50, 13.55s/it, lr=0.000491, step_loss=0.307/27/2023 18:19:48 - INFO - __main__ - train loss is 0.41523878276348114\n",
      "Steps:  26%|▎| 3943/15000 [34:58<29:17:29,  9.54s/it, lr=0.000491, step_loss=0.007/27/2023 18:19:48 - INFO - __main__ - train loss is 1.056291624903679\n",
      "Steps:  26%|▎| 3944/15000 [34:58<20:39:59,  6.73s/it, lr=0.000491, step_loss=0.607/27/2023 18:19:48 - INFO - __main__ - train loss is 1.2320316135883331\n",
      "Steps:  26%|▎| 3945/15000 [34:58<14:37:59,  4.77s/it, lr=0.000491, step_loss=0.107/27/2023 18:19:48 - INFO - __main__ - train loss is 1.3530112653970718\n",
      "Steps:  26%|▎| 3946/15000 [34:59<10:24:23,  3.39s/it, lr=0.000492, step_loss=0.107/27/2023 18:19:49 - INFO - __main__ - train loss is 1.3547528245253488\n",
      "Steps:  26%|▎| 3947/15000 [34:59<7:26:52,  2.43s/it, lr=0.000492, step_loss=0.0007/27/2023 18:19:49 - INFO - __main__ - train loss is 1.4968253531260416\n",
      "Steps:  26%|▎| 3948/15000 [34:59<5:22:37,  1.75s/it, lr=0.000492, step_loss=0.1407/27/2023 18:19:49 - INFO - __main__ - train loss is 1.5060488822637126\n",
      "Steps:  26%|▎| 3949/15000 [34:59<3:56:03,  1.28s/it, lr=0.000492, step_loss=0.0007/27/2023 18:19:49 - INFO - __main__ - train loss is 1.8947375955758616\n",
      "Steps:  26%|▎| 3950/15000 [34:59<2:55:03,  1.05it/s, lr=0.000492, step_loss=0.3807/27/2023 18:19:49 - INFO - __main__ - train loss is 1.9015348366228864\n",
      "Steps:  26%|▎| 3951/15000 [35:00<2:12:21,  1.39it/s, lr=0.000492, step_loss=0.0007/27/2023 18:19:49 - INFO - __main__ - train loss is 1.9175010359613225\n",
      "Steps:  26%|▎| 3952/15000 [35:00<1:42:29,  1.80it/s, lr=0.000492, step_loss=0.0107/27/2023 18:19:50 - INFO - __main__ - train loss is 2.0137134975520894\n",
      "Steps:  26%|▎| 3953/15000 [35:00<1:21:40,  2.25it/s, lr=0.000492, step_loss=0.0907/27/2023 18:19:50 - INFO - __main__ - train loss is 2.0275295729516074\n",
      "Steps:  26%|▎| 3954/15000 [35:00<1:07:16,  2.74it/s, lr=0.000493, step_loss=0.0107/27/2023 18:19:50 - INFO - __main__ - train loss is 2.138691177475266\n",
      "Steps:  26%|▎| 3955/15000 [35:00<56:55,  3.23it/s, lr=0.000493, step_loss=0.111]07/27/2023 18:19:50 - INFO - __main__ - train loss is 2.1408491366310045\n",
      "Steps:  26%|▎| 3956/15000 [35:00<49:48,  3.70it/s, lr=0.000493, step_loss=0.002107/27/2023 18:19:50 - INFO - __main__ - train loss is 2.1425103888614103\n",
      "Steps:  26%|▎| 3957/15000 [35:01<44:48,  4.11it/s, lr=0.000493, step_loss=0.001607/27/2023 18:19:50 - INFO - __main__ - train loss is 2.7939335451228544\n",
      "Steps:  26%|▎| 3958/15000 [35:01<41:30,  4.43it/s, lr=0.000493, step_loss=0.651]07/27/2023 18:19:51 - INFO - __main__ - train loss is 2.804673193837516\n",
      "Steps:  26%|▎| 3959/15000 [35:01<39:14,  4.69it/s, lr=0.000493, step_loss=0.010707/27/2023 18:19:51 - INFO - __main__ - train loss is 2.8823901627911255\n",
      "Steps:  26%|▎| 3960/15000 [35:01<37:38,  4.89it/s, lr=0.000493, step_loss=0.077707/27/2023 18:19:51 - INFO - __main__ - train loss is 2.97071795060765\n",
      "Steps:  26%|▎| 3961/15000 [35:01<36:14,  5.08it/s, lr=0.000494, step_loss=0.088307/27/2023 18:19:51 - INFO - __main__ - train loss is 2.998227107222192\n",
      "Steps:  26%|▎| 3962/15000 [35:02<35:27,  5.19it/s, lr=0.000494, step_loss=0.027507/27/2023 18:19:51 - INFO - __main__ - train loss is 3.0400285971118137\n",
      "Steps:  26%|▎| 3963/15000 [35:02<34:42,  5.30it/s, lr=0.000494, step_loss=0.041807/27/2023 18:19:52 - INFO - __main__ - train loss is 3.440161640639417\n",
      "Steps:  26%|▊  | 3964/15000 [35:02<34:10,  5.38it/s, lr=0.000494, step_loss=0.4]07/27/2023 18:19:52 - INFO - __main__ - train loss is 3.468312105978839\n",
      "Steps:  26%|▎| 3965/15000 [35:02<33:47,  5.44it/s, lr=0.000494, step_loss=0.028207/27/2023 18:19:52 - INFO - __main__ - train loss is 3.469912711647339\n",
      "Steps:  26%|▎| 3966/15000 [35:02<33:31,  5.48it/s, lr=0.000494, step_loss=0.001607/27/2023 18:19:52 - INFO - __main__ - train loss is 3.4974304606439546\n",
      "Steps:  26%|▎| 3967/15000 [35:02<33:20,  5.51it/s, lr=0.000494, step_loss=0.027507/27/2023 18:19:52 - INFO - __main__ - train loss is 3.518153373268433\n",
      "Steps:  26%|▎| 3968/15000 [35:03<33:13,  5.54it/s, lr=0.000494, step_loss=0.020707/27/2023 18:19:52 - INFO - __main__ - train loss is 3.5614301116438583\n",
      "Steps:  26%|▎| 3969/15000 [35:03<33:09,  5.54it/s, lr=0.000495, step_loss=0.043307/27/2023 18:19:53 - INFO - __main__ - train loss is 3.9079927356215194\n",
      "Steps:  26%|▎| 3970/15000 [35:03<33:06,  5.55it/s, lr=0.000495, step_loss=0.347]07/27/2023 18:19:53 - INFO - __main__ - train loss is 3.9125999828102067\n",
      "Steps:  26%|▎| 3971/15000 [35:03<33:04,  5.56it/s, lr=0.000495, step_loss=0.004607/27/2023 18:19:53 - INFO - __main__ - train loss is 3.940451303613372\n",
      "Steps:  26%|▎| 3972/15000 [35:03<33:02,  5.56it/s, lr=0.000495, step_loss=0.027907/27/2023 18:19:53 - INFO - __main__ - train loss is 4.008457312476821\n",
      "Steps:  26%|▎| 3973/15000 [35:04<33:00,  5.57it/s, lr=0.000495, step_loss=0.068]07/27/2023 18:19:53 - INFO - __main__ - train loss is 4.043975504231639\n",
      "Steps:  26%|▎| 3974/15000 [35:04<33:10,  5.54it/s, lr=0.000495, step_loss=0.035507/27/2023 18:19:54 - INFO - __main__ - train loss is 4.069764638436027\n",
      "Steps:  26%|▎| 3975/15000 [35:04<33:13,  5.53it/s, lr=0.000495, step_loss=0.025807/27/2023 18:19:54 - INFO - __main__ - train loss is 4.072941187187098\n",
      "Steps:  27%|▎| 3976/15000 [35:04<33:16,  5.52it/s, lr=0.000495, step_loss=0.003107/27/2023 18:19:54 - INFO - __main__ - train loss is 4.347568515106104\n",
      "Steps:  27%|▎| 3977/15000 [35:04<33:18,  5.52it/s, lr=0.000495, step_loss=0.275]07/27/2023 18:19:54 - INFO - __main__ - train loss is 4.4546866895398125\n",
      "Steps:  27%|▎| 3978/15000 [35:04<33:20,  5.51it/s, lr=0.000496, step_loss=0.107]07/27/2023 18:19:54 - INFO - __main__ - train loss is 4.693029019399546\n",
      "Steps:  27%|▎| 3979/15000 [35:05<33:20,  5.51it/s, lr=0.000496, step_loss=0.238]07/27/2023 18:19:54 - INFO - __main__ - train loss is 4.701738777919672\n",
      "Steps:  27%|▎| 3980/15000 [35:05<33:20,  5.51it/s, lr=0.000496, step_loss=0.008707/27/2023 18:19:55 - INFO - __main__ - train loss is 4.714351909584366\n",
      "Steps:  27%|▎| 3981/15000 [35:05<33:20,  5.51it/s, lr=0.000496, step_loss=0.012607/27/2023 18:19:55 - INFO - __main__ - train loss is 4.716815110179596\n",
      "Steps:  27%|▎| 3982/15000 [35:05<33:37,  5.46it/s, lr=0.000496, step_loss=0.002407/27/2023 18:19:55 - INFO - __main__ - train loss is 4.724337347666733\n",
      "Steps:  27%|▎| 3983/15000 [35:05<33:32,  5.47it/s, lr=0.000496, step_loss=0.007507/27/2023 18:19:55 - INFO - __main__ - train loss is 5.401395567576401\n",
      "Steps:  27%|▎| 3984/15000 [35:06<33:44,  5.44it/s, lr=0.000496, step_loss=0.677]07/27/2023 18:19:55 - INFO - __main__ - train loss is 5.42857242829632\n",
      "Steps:  27%|▎| 3985/15000 [35:06<33:37,  5.46it/s, lr=0.000496, step_loss=0.027207/27/2023 18:19:56 - INFO - __main__ - train loss is 5.611859914730303\n",
      "Steps:  27%|▎| 3986/15000 [35:06<33:31,  5.48it/s, lr=0.000497, step_loss=0.183]07/27/2023 18:19:56 - INFO - __main__ - train loss is 5.61786588083487\n",
      "Steps:  27%|▎| 3987/15000 [35:06<33:27,  5.48it/s, lr=0.000497, step_loss=0.006007/27/2023 18:19:56 - INFO - __main__ - train loss is 5.640479994821362\n",
      "Steps:  27%|▎| 3988/15000 [35:06<33:24,  5.49it/s, lr=0.000497, step_loss=0.022607/27/2023 18:19:56 - INFO - __main__ - train loss is 5.642875633551739\n",
      "Steps:  27%|▎| 3989/15000 [35:06<33:34,  5.47it/s, lr=0.000497, step_loss=0.002407/27/2023 18:19:56 - INFO - __main__ - train loss is 5.683375477208756\n",
      "Steps:  27%|▎| 3990/15000 [35:07<33:30,  5.48it/s, lr=0.000497, step_loss=0.040507/27/2023 18:19:56 - INFO - __main__ - train loss is 5.757476515485905\n",
      "Steps:  27%|▎| 3991/15000 [35:07<33:26,  5.49it/s, lr=0.000497, step_loss=0.074107/27/2023 18:19:57 - INFO - __main__ - train loss is 6.474083251669072\n",
      "Steps:  27%|▎| 3992/15000 [35:07<33:22,  5.50it/s, lr=0.000497, step_loss=0.717]07/27/2023 18:19:57 - INFO - __main__ - train loss is 6.5875726559897885\n",
      "Steps:  27%|▎| 3993/15000 [35:07<33:22,  5.50it/s, lr=0.000498, step_loss=0.113]07/27/2023 18:19:57 - INFO - __main__ - train loss is 6.680725283338688\n",
      "Steps:  27%|▎| 3994/15000 [35:07<33:21,  5.50it/s, lr=0.000498, step_loss=0.093207/27/2023 18:19:57 - INFO - __main__ - train loss is 6.73147460015025\n",
      "Steps:  27%|▎| 3995/15000 [35:08<33:22,  5.49it/s, lr=0.000498, step_loss=0.050707/27/2023 18:19:57 - INFO - __main__ - train loss is 6.964746258570813\n",
      "Steps:  27%|▎| 3996/15000 [35:08<33:20,  5.50it/s, lr=0.000498, step_loss=0.233]07/27/2023 18:19:58 - INFO - __main__ - train loss is 7.14045546145644\n",
      "Steps:  27%|▎| 3997/15000 [35:08<33:18,  5.50it/s, lr=0.000498, step_loss=0.176]07/27/2023 18:19:58 - INFO - __main__ - train loss is 7.5717677840730175\n",
      "Steps:  27%|▎| 3998/15000 [35:08<33:17,  5.51it/s, lr=0.000498, step_loss=0.431]07/27/2023 18:19:58 - INFO - __main__ - train loss is 7.8332201013108715\n",
      "Steps:  27%|▎| 3999/15000 [35:08<33:17,  5.51it/s, lr=0.000498, step_loss=0.261]07/27/2023 18:19:58 - INFO - __main__ - train loss is 7.855214554234408\n",
      "Steps:  27%|▎| 4000/15000 [35:08<33:16,  5.51it/s, lr=0.000498, step_loss=0.261]07/27/2023 18:19:58 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-4000\n",
      "07/27/2023 18:19:58 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:19:58,710] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:19:58,714] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-4000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:19:58,714] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-4000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:19:58,721] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-4000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:19:58,721] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-4000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:19:58,727] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-4000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:19:58,727] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-4000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:19:58,728] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:19:58 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-4000/pytorch_model\n",
      "07/27/2023 18:19:58 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-4000/scheduler.bin\n",
      "07/27/2023 18:19:58 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-4000/random_states_0.pkl\n",
      "07/27/2023 18:19:58 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-4000\n",
      "Steps:  27%|▎| 4000/15000 [35:08<33:16,  5.51it/s, lr=0.000498, step_loss=0.022]07/27/2023 18:19:58 - INFO - __main__ - train loss is 7.886282819672488\n",
      "Steps:  27%|▎| 4001/15000 [35:09<34:21,  5.34it/s, lr=0.000499, step_loss=0.031107/27/2023 18:19:59 - INFO - __main__ - train loss is 8.340996104641818\n",
      "Steps:  27%|▎| 4002/15000 [35:09<34:01,  5.39it/s, lr=0.000499, step_loss=0.455]07/27/2023 18:19:59 - INFO - __main__ - train loss is 8.351152855320834\n",
      "Steps:  27%|▎| 4003/15000 [35:09<33:48,  5.42it/s, lr=0.000499, step_loss=0.010207/27/2023 18:19:59 - INFO - __main__ - train loss is 8.359584960504435\n",
      "Steps:  27%|▎| 4004/15000 [35:09<33:36,  5.45it/s, lr=0.000499, step_loss=0.008407/27/2023 18:19:59 - INFO - __main__ - train loss is 8.59201176778879\n",
      "Steps:  27%|▎| 4005/15000 [35:09<33:30,  5.47it/s, lr=0.000499, step_loss=0.232]07/27/2023 18:19:59 - INFO - __main__ - train loss is 8.69927798525896\n",
      "Steps:  27%|▎| 4006/15000 [35:10<33:25,  5.48it/s, lr=0.000499, step_loss=0.107]07/27/2023 18:19:59 - INFO - __main__ - train loss is 8.703577771200798\n",
      "Steps:  27%|▎| 4007/15000 [35:10<33:22,  5.49it/s, lr=0.000499, step_loss=0.004307/27/2023 18:20:00 - INFO - __main__ - train loss is 8.712817747495137\n",
      "Steps:  27%|▎| 4008/15000 [35:10<33:20,  5.49it/s, lr=0.000499, step_loss=0.009207/27/2023 18:20:00 - INFO - __main__ - train loss is 8.714342311606742\n",
      "Steps:  27%|▎| 4009/15000 [35:10<33:18,  5.50it/s, lr=0.0005, step_loss=0.00152]07/27/2023 18:20:00 - INFO - __main__ - train loss is 8.729461820446886\n",
      "Steps:  27%|▌ | 4010/15000 [35:10<33:16,  5.50it/s, lr=0.0005, step_loss=0.0151]07/27/2023 18:20:00 - INFO - __main__ - train loss is 8.73118695593439\n",
      "Steps:  27%|▎| 4011/15000 [35:10<33:15,  5.51it/s, lr=0.0005, step_loss=0.00173]07/27/2023 18:20:00 - INFO - __main__ - train loss is 8.73664941941388\n",
      "Steps:  27%|▎| 4012/15000 [35:11<33:15,  5.51it/s, lr=0.0005, step_loss=0.00546]07/27/2023 18:20:01 - INFO - __main__ - train loss is 8.957752551184967\n",
      "Steps:  27%|▊  | 4013/15000 [35:11<33:14,  5.51it/s, lr=0.0005, step_loss=0.221]07/27/2023 18:20:01 - INFO - __main__ - train loss is 8.995456258999184\n",
      "Steps:  27%|▌ | 4014/15000 [35:11<33:13,  5.51it/s, lr=0.0005, step_loss=0.0377]07/27/2023 18:20:01 - INFO - __main__ - train loss is 8.99784935102798\n",
      "Steps:  27%|▎| 4015/15000 [35:11<33:13,  5.51it/s, lr=0.0005, step_loss=0.00239]07/27/2023 18:20:01 - INFO - __main__ - train loss is 9.010559206129983\n",
      "Steps:  27%|▌ | 4016/15000 [35:11<33:13,  5.51it/s, lr=0.0005, step_loss=0.0127]07/27/2023 18:20:01 - INFO - __main__ - train loss is 9.148110126378015\n",
      "Steps:  27%|▊  | 4017/15000 [35:12<33:12,  5.51it/s, lr=0.0005, step_loss=0.138]07/27/2023 18:20:01 - INFO - __main__ - train loss is 9.251766723813489\n",
      "Steps:  27%|▎| 4018/15000 [35:12<33:10,  5.52it/s, lr=0.000501, step_loss=0.104]07/27/2023 18:20:02 - INFO - __main__ - train loss is 9.275214477675036\n",
      "Steps:  27%|▎| 4019/15000 [35:12<34:58,  5.23it/s, lr=0.000501, step_loss=0.023407/27/2023 18:20:02 - INFO - __main__ - train loss is 9.473070129053667\n",
      "Steps:  27%|▎| 4020/15000 [35:12<36:42,  4.99it/s, lr=0.000501, step_loss=0.198]07/27/2023 18:20:02 - INFO - __main__ - train loss is 9.700284972088411\n",
      "Steps:  27%|▎| 4021/15000 [35:12<36:11,  5.06it/s, lr=0.000501, step_loss=0.227]07/27/2023 18:20:02 - INFO - __main__ - train loss is 9.767100303666666\n",
      "Steps:  27%|▎| 4022/15000 [35:13<36:03,  5.07it/s, lr=0.000501, step_loss=0.066807/27/2023 18:20:02 - INFO - __main__ - train loss is 9.768951831851155\n",
      "Steps:  27%|▎| 4023/15000 [35:13<35:28,  5.16it/s, lr=0.000501, step_loss=0.001807/27/2023 18:20:03 - INFO - __main__ - train loss is 9.858161567244679\n",
      "Steps:  27%|▎| 4024/15000 [35:13<34:40,  5.28it/s, lr=0.000501, step_loss=0.089207/27/2023 18:20:03 - INFO - __main__ - train loss is 9.929358793888241\n",
      "Steps:  27%|▎| 4025/15000 [35:13<34:08,  5.36it/s, lr=0.000501, step_loss=0.071207/27/2023 18:20:03 - INFO - __main__ - train loss is 10.128945513162762\n",
      "Steps:  27%|▊  | 4026/15000 [35:13<33:45,  5.42it/s, lr=0.000502, step_loss=0.2]07/27/2023 18:20:03 - INFO - __main__ - train loss is 10.130754255573265\n",
      "Steps:  27%|▎| 4027/15000 [35:13<33:29,  5.46it/s, lr=0.000502, step_loss=0.001807/27/2023 18:20:03 - INFO - __main__ - train loss is 10.171331361751072\n",
      "Steps:  27%|▎| 4028/15000 [35:14<33:17,  5.49it/s, lr=0.000502, step_loss=0.040607/27/2023 18:20:03 - INFO - __main__ - train loss is 10.195736168767326\n",
      "Steps:  27%|▎| 4029/15000 [35:14<33:13,  5.50it/s, lr=0.000502, step_loss=0.024407/27/2023 18:20:04 - INFO - __main__ - train loss is 10.713536559487693\n",
      "Steps:  27%|▎| 4030/15000 [35:14<33:06,  5.52it/s, lr=0.000502, step_loss=0.518]07/27/2023 18:20:04 - INFO - __main__ - train loss is 10.973764060880058\n",
      "Steps:  27%|▌ | 4031/15000 [35:14<33:00,  5.54it/s, lr=0.000502, step_loss=0.26]07/27/2023 18:20:04 - INFO - __main__ - train loss is 11.13472390070092\n",
      "Steps:  27%|▎| 4032/15000 [35:14<32:54,  5.55it/s, lr=0.000502, step_loss=0.161]07/27/2023 18:20:04 - INFO - __main__ - train loss is 11.54169034853112\n",
      "Steps:  27%|▎| 4033/15000 [35:15<32:51,  5.56it/s, lr=0.000502, step_loss=0.407]07/27/2023 18:20:04 - INFO - __main__ - train loss is 11.586260146345012\n",
      "Steps:  27%|▎| 4034/15000 [35:15<32:48,  5.57it/s, lr=0.000503, step_loss=0.044607/27/2023 18:20:05 - INFO - __main__ - train loss is 11.627562804962508\n",
      "Steps:  27%|▎| 4035/15000 [35:15<32:46,  5.58it/s, lr=0.000503, step_loss=0.041307/27/2023 18:20:05 - INFO - __main__ - train loss is 11.848575665499084\n",
      "Steps:  27%|▎| 4036/15000 [35:15<32:45,  5.58it/s, lr=0.000503, step_loss=0.221]07/27/2023 18:20:05 - INFO - __main__ - train loss is 12.063209219719283\n",
      "Steps:  27%|▎| 4037/15000 [35:15<32:45,  5.58it/s, lr=0.000503, step_loss=0.215]07/27/2023 18:20:05 - INFO - __main__ - train loss is 12.379661126877181\n",
      "Steps:  27%|▎| 4038/15000 [35:15<32:44,  5.58it/s, lr=0.000503, step_loss=0.316]07/27/2023 18:20:05 - INFO - __main__ - train loss is 12.436010553385131\n",
      "Steps:  27%|▎| 4039/15000 [35:16<32:45,  5.58it/s, lr=0.000503, step_loss=0.056307/27/2023 18:20:05 - INFO - __main__ - train loss is 12.911994530702941\n",
      "Steps:  27%|▎| 4040/15000 [35:16<32:44,  5.58it/s, lr=0.000503, step_loss=0.476]07/27/2023 18:20:06 - INFO - __main__ - train loss is 12.986430614138953\n",
      "Steps:  27%|▎| 4041/15000 [35:16<32:44,  5.58it/s, lr=0.000503, step_loss=0.074407/27/2023 18:20:06 - INFO - __main__ - train loss is 12.995065885479562\n",
      "Steps:  27%|▎| 4042/15000 [35:16<32:44,  5.58it/s, lr=0.000504, step_loss=0.008607/27/2023 18:20:06 - INFO - __main__ - train loss is 13.303306477959268\n",
      "Steps:  27%|▎| 4043/15000 [35:16<32:42,  5.58it/s, lr=0.000504, step_loss=0.308]07/27/2023 18:20:06 - INFO - __main__ - train loss is 13.304893444641493\n",
      "Steps:  27%|▎| 4044/15000 [35:16<32:41,  5.58it/s, lr=0.000504, step_loss=0.001507/27/2023 18:20:06 - INFO - __main__ - train loss is 13.514966945513152\n",
      "Steps:  27%|▌ | 4045/15000 [35:17<32:42,  5.58it/s, lr=0.000504, step_loss=0.21]07/27/2023 18:20:07 - INFO - __main__ - train loss is 13.532722193165682\n",
      "Steps:  27%|▎| 4046/15000 [35:17<32:43,  5.58it/s, lr=0.000504, step_loss=0.017807/27/2023 18:20:07 - INFO - __main__ - train loss is 13.573984395130537\n",
      "Steps:  27%|▎| 4047/15000 [35:17<32:43,  5.58it/s, lr=0.000504, step_loss=0.041307/27/2023 18:20:07 - INFO - __main__ - train loss is 13.624487045570277\n",
      "Steps:  27%|▎| 4048/15000 [35:17<32:43,  5.58it/s, lr=0.000504, step_loss=0.050507/27/2023 18:20:07 - INFO - __main__ - train loss is 13.628965296200477\n",
      "Steps:  27%|▎| 4049/15000 [35:17<32:42,  5.58it/s, lr=0.000504, step_loss=0.004407/27/2023 18:20:07 - INFO - __main__ - train loss is 13.956775285652839\n",
      "Steps:  27%|▎| 4050/15000 [35:18<32:41,  5.58it/s, lr=0.000505, step_loss=0.328]07/27/2023 18:20:07 - INFO - __main__ - train loss is 13.967167787603103\n",
      "Steps:  27%|▎| 4051/15000 [35:18<32:41,  5.58it/s, lr=0.000505, step_loss=0.010407/27/2023 18:20:08 - INFO - __main__ - train loss is 14.12076703493949\n",
      "Steps:  27%|▎| 4052/15000 [35:18<32:41,  5.58it/s, lr=0.000505, step_loss=0.154]07/27/2023 18:20:08 - INFO - __main__ - train loss is 14.128626359975897\n",
      "Steps:  27%|▎| 4053/15000 [35:18<32:41,  5.58it/s, lr=0.000505, step_loss=0.007807/27/2023 18:20:08 - INFO - __main__ - train loss is 14.15332872828003\n",
      "Steps:  27%|▎| 4054/15000 [35:18<32:41,  5.58it/s, lr=0.000505, step_loss=0.024707/27/2023 18:20:08 - INFO - __main__ - train loss is 14.546798061928712\n",
      "Steps:  27%|▎| 4055/15000 [35:18<32:40,  5.58it/s, lr=0.000505, step_loss=0.393]07/27/2023 18:20:08 - INFO - __main__ - train loss is 14.57502974232193\n",
      "Steps:  27%|▎| 4056/15000 [35:19<32:40,  5.58it/s, lr=0.000505, step_loss=0.028207/27/2023 18:20:09 - INFO - __main__ - train loss is 14.592813093564473\n",
      "Steps:  27%|▎| 4057/15000 [35:19<32:40,  5.58it/s, lr=0.000505, step_loss=0.017807/27/2023 18:20:09 - INFO - __main__ - train loss is 14.878193933865987\n",
      "Steps:  27%|▎| 4058/15000 [35:19<32:39,  5.58it/s, lr=0.000506, step_loss=0.285]07/27/2023 18:20:09 - INFO - __main__ - train loss is 14.879876002902165\n",
      "Steps:  27%|▎| 4059/15000 [35:19<32:39,  5.58it/s, lr=0.000506, step_loss=0.001607/27/2023 18:20:09 - INFO - __main__ - train loss is 14.883386409841478\n",
      "Steps:  27%|▎| 4060/15000 [35:19<32:38,  5.59it/s, lr=0.000506, step_loss=0.003507/27/2023 18:20:09 - INFO - __main__ - train loss is 14.93887364026159\n",
      "Steps:  27%|▎| 4061/15000 [35:20<32:38,  5.59it/s, lr=0.000506, step_loss=0.055507/27/2023 18:20:09 - INFO - __main__ - train loss is 15.12229525204748\n",
      "Steps:  27%|▎| 4062/15000 [35:20<32:39,  5.58it/s, lr=0.000506, step_loss=0.183]07/27/2023 18:20:10 - INFO - __main__ - train loss is 15.189509390853345\n",
      "Steps:  27%|▎| 4063/15000 [35:20<32:39,  5.58it/s, lr=0.000506, step_loss=0.067207/27/2023 18:20:10 - INFO - __main__ - train loss is 15.219783364795148\n",
      "Steps:  27%|▎| 4064/15000 [35:20<32:39,  5.58it/s, lr=0.000506, step_loss=0.030307/27/2023 18:20:10 - INFO - __main__ - train loss is 15.550220935605466\n",
      "Steps:  27%|▌ | 4065/15000 [35:20<33:10,  5.49it/s, lr=0.000507, step_loss=0.33]07/27/2023 18:20:10 - INFO - __main__ - train loss is 15.603523231111467\n",
      "Steps:  27%|▎| 4066/15000 [35:20<33:15,  5.48it/s, lr=0.000507, step_loss=0.053307/27/2023 18:20:10 - INFO - __main__ - train loss is 15.966892248950899\n",
      "Steps:  27%|▎| 4067/15000 [35:21<33:16,  5.48it/s, lr=0.000507, step_loss=0.363]07/27/2023 18:20:10 - INFO - __main__ - train loss is 16.076880543492734\n",
      "Steps:  27%|▌ | 4068/15000 [35:21<33:05,  5.51it/s, lr=0.000507, step_loss=0.11]07/27/2023 18:20:11 - INFO - __main__ - train loss is 16.12600989919156\n",
      "Steps:  27%|▎| 4069/15000 [35:21<32:59,  5.52it/s, lr=0.000507, step_loss=0.049107/27/2023 18:20:11 - INFO - __main__ - train loss is 16.238697211258113\n",
      "Steps:  27%|▎| 4070/15000 [35:21<32:54,  5.54it/s, lr=0.000507, step_loss=0.113]07/27/2023 18:20:11 - INFO - __main__ - train loss is 16.335708278231323\n",
      "Steps:  27%|▎| 4071/15000 [35:21<32:51,  5.54it/s, lr=0.000507, step_loss=0.097]07/27/2023 18:20:11 - INFO - __main__ - train loss is 16.337911302689463\n",
      "Steps:  27%|▎| 4072/15000 [35:22<32:47,  5.55it/s, lr=0.000507, step_loss=0.002207/27/2023 18:20:11 - INFO - __main__ - train loss is 16.36322114849463\n",
      "Steps:  27%|▎| 4073/15000 [35:22<32:44,  5.56it/s, lr=0.000507, step_loss=0.025307/27/2023 18:20:12 - INFO - __main__ - train loss is 16.632975498680025\n",
      "Steps:  27%|▌ | 4074/15000 [35:22<32:41,  5.57it/s, lr=0.000508, step_loss=0.27]07/27/2023 18:20:12 - INFO - __main__ - train loss is 16.988740334752947\n",
      "Steps:  27%|▎| 4075/15000 [35:22<32:39,  5.57it/s, lr=0.000508, step_loss=0.356]07/27/2023 18:20:12 - INFO - __main__ - train loss is 16.99680443527177\n",
      "Steps:  27%|▎| 4076/15000 [35:22<32:38,  5.58it/s, lr=0.000508, step_loss=0.008007/27/2023 18:20:12 - INFO - __main__ - train loss is 17.161831100005656\n",
      "Steps:  27%|▎| 4077/15000 [35:22<32:37,  5.58it/s, lr=0.000508, step_loss=0.165]07/27/2023 18:20:12 - INFO - __main__ - train loss is 17.265496109146625\n",
      "Steps:  27%|▎| 4078/15000 [35:23<32:37,  5.58it/s, lr=0.000508, step_loss=0.104]07/27/2023 18:20:12 - INFO - __main__ - train loss is 17.285782501567155\n",
      "Steps:  27%|▎| 4079/15000 [35:23<32:56,  5.53it/s, lr=0.000508, step_loss=0.020307/27/2023 18:20:13 - INFO - __main__ - train loss is 17.817462012637407\n",
      "Steps:  27%|▎| 4080/15000 [35:23<33:25,  5.45it/s, lr=0.000508, step_loss=0.532]07/27/2023 18:20:13 - INFO - __main__ - train loss is 17.89476840244606\n",
      "Steps:  27%|▎| 4081/15000 [35:23<33:16,  5.47it/s, lr=0.000508, step_loss=0.077307/27/2023 18:20:13 - INFO - __main__ - train loss is 17.960671723354608\n",
      "Steps:  27%|▎| 4082/15000 [35:23<33:19,  5.46it/s, lr=0.000509, step_loss=0.065907/27/2023 18:20:13 - INFO - __main__ - train loss is 17.973636305425316\n",
      "Steps:  27%|▎| 4083/15000 [35:24<33:06,  5.50it/s, lr=0.000509, step_loss=0.013]07/27/2023 18:20:13 - INFO - __main__ - train loss is 17.980476946104318\n",
      "Steps:  27%|▎| 4084/15000 [35:24<32:57,  5.52it/s, lr=0.000509, step_loss=0.006807/27/2023 18:20:14 - INFO - __main__ - train loss is 18.05110823409632\n",
      "Steps:  27%|▎| 4085/15000 [35:24<32:52,  5.53it/s, lr=0.000509, step_loss=0.070607/27/2023 18:20:14 - INFO - __main__ - train loss is 18.180760197807103\n",
      "Steps:  27%|▌ | 4086/15000 [35:24<32:47,  5.55it/s, lr=0.000509, step_loss=0.13]07/27/2023 18:20:14 - INFO - __main__ - train loss is 18.18591628363356\n",
      "Steps:  27%|▎| 4087/15000 [35:24<32:45,  5.55it/s, lr=0.000509, step_loss=0.005107/27/2023 18:20:14 - INFO - __main__ - train loss is 18.674103477504104\n",
      "Steps:  27%|▎| 4088/15000 [35:24<33:02,  5.50it/s, lr=0.000509, step_loss=0.488]07/27/2023 18:20:14 - INFO - __main__ - train loss is 18.785919272806495\n",
      "Steps:  27%|▎| 4089/15000 [35:25<32:56,  5.52it/s, lr=0.000509, step_loss=0.112]07/27/2023 18:20:14 - INFO - __main__ - train loss is 18.79138136887923\n",
      "Steps:  27%|▎| 4090/15000 [35:25<32:49,  5.54it/s, lr=0.00051, step_loss=0.0054607/27/2023 18:20:15 - INFO - __main__ - train loss is 18.825823391322047\n",
      "Steps:  27%|▎| 4091/15000 [35:25<32:46,  5.55it/s, lr=0.00051, step_loss=0.0344]07/27/2023 18:20:15 - INFO - __main__ - train loss is 19.290820146445185\n",
      "Steps:  27%|▌ | 4092/15000 [35:25<32:43,  5.56it/s, lr=0.00051, step_loss=0.465]07/27/2023 18:20:15 - INFO - __main__ - train loss is 19.521319712046534\n",
      "Steps:  27%|▊  | 4093/15000 [35:25<32:48,  5.54it/s, lr=0.00051, step_loss=0.23]07/27/2023 18:20:15 - INFO - __main__ - train loss is 19.877106125000864\n",
      "Steps:  27%|▌ | 4094/15000 [35:26<32:43,  5.55it/s, lr=0.00051, step_loss=0.356]07/27/2023 18:20:15 - INFO - __main__ - train loss is 19.89649316901341\n",
      "Steps:  27%|▎| 4095/15000 [35:26<32:40,  5.56it/s, lr=0.00051, step_loss=0.0194]07/27/2023 18:20:16 - INFO - __main__ - train loss is 19.93783929431811\n",
      "Steps:  27%|▎| 4096/15000 [35:26<32:37,  5.57it/s, lr=0.00051, step_loss=0.0413]07/27/2023 18:20:16 - INFO - __main__ - train loss is 20.01537915552035\n",
      "Steps:  27%|▎| 4097/15000 [35:26<32:36,  5.57it/s, lr=0.00051, step_loss=0.0775]07/27/2023 18:20:16 - INFO - __main__ - train loss is 20.187258476857096\n",
      "Steps:  27%|▎| 4098/15000 [35:26<32:37,  5.57it/s, lr=0.000511, step_loss=0.172]07/27/2023 18:20:16 - INFO - __main__ - train loss is 20.258394102100283\n",
      "Steps:  27%|▎| 4099/15000 [35:26<32:36,  5.57it/s, lr=0.000511, step_loss=0.071107/27/2023 18:20:16 - INFO - __main__ - train loss is 20.317993859294802\n",
      "Steps:  27%|▎| 4100/15000 [35:27<32:53,  5.52it/s, lr=0.000511, step_loss=0.059607/27/2023 18:20:16 - INFO - __main__ - train loss is 20.819132308010012\n",
      "Steps:  27%|▎| 4101/15000 [35:27<32:49,  5.53it/s, lr=0.000511, step_loss=0.501]07/27/2023 18:20:17 - INFO - __main__ - train loss is 20.9267080524005\n",
      "Steps:  27%|▎| 4102/15000 [35:27<32:43,  5.55it/s, lr=0.000511, step_loss=0.108]07/27/2023 18:20:17 - INFO - __main__ - train loss is 20.951202722731978\n",
      "Steps:  27%|▎| 4103/15000 [35:27<32:39,  5.56it/s, lr=0.000511, step_loss=0.024507/27/2023 18:20:17 - INFO - __main__ - train loss is 21.18567398423329\n",
      "Steps:  27%|▎| 4104/15000 [35:27<32:36,  5.57it/s, lr=0.000511, step_loss=0.234]07/27/2023 18:20:17 - INFO - __main__ - train loss is 21.319894077721983\n",
      "Steps:  27%|▎| 4105/15000 [35:27<32:35,  5.57it/s, lr=0.000512, step_loss=0.134]07/27/2023 18:20:17 - INFO - __main__ - train loss is 21.489502819720656\n",
      "Steps:  27%|▌ | 4106/15000 [35:28<32:33,  5.58it/s, lr=0.000512, step_loss=0.17]07/27/2023 18:20:18 - INFO - __main__ - train loss is 21.61734494799748\n",
      "Steps:  27%|▎| 4107/15000 [35:28<32:33,  5.58it/s, lr=0.000512, step_loss=0.128]07/27/2023 18:20:18 - INFO - __main__ - train loss is 21.627202895004302\n",
      "Steps:  27%|▎| 4108/15000 [35:28<32:30,  5.58it/s, lr=0.000512, step_loss=0.009807/27/2023 18:20:18 - INFO - __main__ - train loss is 21.983229455072433\n",
      "Steps:  27%|▎| 4109/15000 [35:28<32:28,  5.59it/s, lr=0.000512, step_loss=0.356]07/27/2023 18:20:18 - INFO - __main__ - train loss is 22.055927735287696\n",
      "Steps:  27%|▎| 4110/15000 [35:28<32:31,  5.58it/s, lr=0.000512, step_loss=0.072707/27/2023 18:20:18 - INFO - __main__ - train loss is 22.092865210492164\n",
      "Steps:  27%|▎| 4111/15000 [35:29<32:29,  5.59it/s, lr=0.000512, step_loss=0.036907/27/2023 18:20:18 - INFO - __main__ - train loss is 22.13337241159752\n",
      "Steps:  27%|▎| 4112/15000 [35:29<32:29,  5.59it/s, lr=0.000512, step_loss=0.040507/27/2023 18:20:19 - INFO - __main__ - train loss is 22.164407743606716\n",
      "Steps:  27%|▎| 4113/15000 [35:29<32:29,  5.59it/s, lr=0.000512, step_loss=0.031]07/27/2023 18:20:19 - INFO - __main__ - train loss is 22.165950561640784\n",
      "Steps:  27%|▎| 4114/15000 [35:29<32:28,  5.59it/s, lr=0.000513, step_loss=0.001507/27/2023 18:20:19 - INFO - __main__ - train loss is 22.16780151752755\n",
      "Steps:  27%|▎| 4115/15000 [35:29<32:27,  5.59it/s, lr=0.000513, step_loss=0.001807/27/2023 18:20:19 - INFO - __main__ - train loss is 22.17419225955382\n",
      "Steps:  27%|▎| 4116/15000 [35:29<32:27,  5.59it/s, lr=0.000513, step_loss=0.006307/27/2023 18:20:19 - INFO - __main__ - train loss is 22.326202298048884\n",
      "Steps:  27%|▎| 4117/15000 [35:30<32:26,  5.59it/s, lr=0.000513, step_loss=0.152]07/27/2023 18:20:19 - INFO - __main__ - train loss is 22.35312600666657\n",
      "Steps:  27%|▎| 4118/15000 [35:30<32:26,  5.59it/s, lr=0.000513, step_loss=0.026907/27/2023 18:20:20 - INFO - __main__ - train loss is 22.443326564971358\n",
      "Steps:  27%|▎| 4119/15000 [35:30<32:27,  5.59it/s, lr=0.000513, step_loss=0.090207/27/2023 18:20:20 - INFO - __main__ - train loss is 22.45313271926716\n",
      "Steps:  27%|▎| 4120/15000 [35:30<32:27,  5.59it/s, lr=0.000513, step_loss=0.009807/27/2023 18:20:20 - INFO - __main__ - train loss is 22.476208478678018\n",
      "Steps:  27%|▎| 4121/15000 [35:30<32:27,  5.59it/s, lr=0.000513, step_loss=0.023107/27/2023 18:20:20 - INFO - __main__ - train loss is 22.48924973839894\n",
      "Steps:  27%|▎| 4122/15000 [35:31<32:26,  5.59it/s, lr=0.000514, step_loss=0.013]07/27/2023 18:20:20 - INFO - __main__ - train loss is 22.51598089793697\n",
      "Steps:  27%|▎| 4123/15000 [35:31<32:27,  5.59it/s, lr=0.000514, step_loss=0.026707/27/2023 18:20:21 - INFO - __main__ - train loss is 22.520111449528486\n",
      "Steps:  27%|▎| 4124/15000 [35:31<32:31,  5.57it/s, lr=0.000514, step_loss=0.004107/27/2023 18:20:21 - INFO - __main__ - train loss is 22.53474715584889\n",
      "Steps:  28%|▎| 4125/15000 [35:31<32:28,  5.58it/s, lr=0.000514, step_loss=0.014607/27/2023 18:20:21 - INFO - __main__ - train loss is 22.555916088167578\n",
      "Steps:  28%|▎| 4126/15000 [35:31<32:29,  5.58it/s, lr=0.000514, step_loss=0.021207/27/2023 18:20:21 - INFO - __main__ - train loss is 22.65838914597407\n",
      "Steps:  28%|▎| 4127/15000 [35:31<32:28,  5.58it/s, lr=0.000514, step_loss=0.102]07/27/2023 18:20:21 - INFO - __main__ - train loss is 22.66925788903609\n",
      "Steps:  28%|▎| 4128/15000 [35:32<32:28,  5.58it/s, lr=0.000514, step_loss=0.010907/27/2023 18:20:21 - INFO - __main__ - train loss is 22.89021427417174\n",
      "Steps:  28%|▎| 4129/15000 [35:32<32:27,  5.58it/s, lr=0.000514, step_loss=0.221]07/27/2023 18:20:22 - INFO - __main__ - train loss is 22.896688318345696\n",
      "Steps:  28%|▎| 4130/15000 [35:32<32:46,  5.53it/s, lr=0.000515, step_loss=0.006407/27/2023 18:20:22 - INFO - __main__ - train loss is 22.950894682202488\n",
      "Steps:  28%|▎| 4131/15000 [35:32<33:08,  5.46it/s, lr=0.000515, step_loss=0.054207/27/2023 18:20:22 - INFO - __main__ - train loss is 22.973378902766854\n",
      "Steps:  28%|▎| 4132/15000 [35:32<33:06,  5.47it/s, lr=0.000515, step_loss=0.022507/27/2023 18:20:22 - INFO - __main__ - train loss is 22.98052742285654\n",
      "Steps:  28%|▎| 4133/15000 [35:33<32:54,  5.50it/s, lr=0.000515, step_loss=0.007107/27/2023 18:20:22 - INFO - __main__ - train loss is 23.112434200476855\n",
      "Steps:  28%|▎| 4134/15000 [35:33<33:05,  5.47it/s, lr=0.000515, step_loss=0.132]07/27/2023 18:20:23 - INFO - __main__ - train loss is 23.438653222750872\n",
      "Steps:  28%|▎| 4135/15000 [35:33<33:28,  5.41it/s, lr=0.000515, step_loss=0.326]07/27/2023 18:20:23 - INFO - __main__ - train loss is 23.458622391801327\n",
      "Steps:  28%|▌ | 4136/15000 [35:33<33:26,  5.41it/s, lr=0.000515, step_loss=0.02]07/27/2023 18:20:23 - INFO - __main__ - train loss is 23.489893301855773\n",
      "Steps:  28%|▎| 4137/15000 [35:33<33:08,  5.46it/s, lr=0.000516, step_loss=0.031307/27/2023 18:20:23 - INFO - __main__ - train loss is 23.493203938240185\n",
      "Steps:  28%|▎| 4138/15000 [35:33<33:13,  5.45it/s, lr=0.000516, step_loss=0.003307/27/2023 18:20:23 - INFO - __main__ - train loss is 23.650439724558964\n",
      "Steps:  28%|▎| 4139/15000 [35:34<33:04,  5.47it/s, lr=0.000516, step_loss=0.157]07/27/2023 18:20:23 - INFO - __main__ - train loss is 23.944033429259434\n",
      "Steps:  28%|▎| 4140/15000 [35:34<33:12,  5.45it/s, lr=0.000516, step_loss=0.294]07/27/2023 18:20:24 - INFO - __main__ - train loss is 24.03959369682707\n",
      "Steps:  28%|▎| 4141/15000 [35:34<33:04,  5.47it/s, lr=0.000516, step_loss=0.095607/27/2023 18:20:24 - INFO - __main__ - train loss is 24.078061677748337\n",
      "Steps:  28%|▎| 4142/15000 [35:34<33:10,  5.46it/s, lr=0.000516, step_loss=0.038507/27/2023 18:20:24 - INFO - __main__ - train loss is 24.133392829680815\n",
      "Steps:  28%|▎| 4143/15000 [35:34<33:03,  5.47it/s, lr=0.000516, step_loss=0.055307/27/2023 18:20:24 - INFO - __main__ - train loss is 24.21931565203704\n",
      "Steps:  28%|▎| 4144/15000 [35:35<32:51,  5.51it/s, lr=0.000516, step_loss=0.085907/27/2023 18:20:24 - INFO - __main__ - train loss is 24.234409105265513\n",
      "Steps:  28%|▎| 4145/15000 [35:35<32:43,  5.53it/s, lr=0.000516, step_loss=0.015107/27/2023 18:20:25 - INFO - __main__ - train loss is 24.39014356979169\n",
      "Steps:  28%|▎| 4146/15000 [35:35<32:37,  5.54it/s, lr=0.000517, step_loss=0.156]07/27/2023 18:20:25 - INFO - __main__ - train loss is 24.69600474485196\n",
      "Steps:  28%|▎| 4147/15000 [35:35<32:33,  5.56it/s, lr=0.000517, step_loss=0.306]07/27/2023 18:20:25 - INFO - __main__ - train loss is 24.814520988846198\n",
      "Steps:  28%|▎| 4148/15000 [35:35<32:29,  5.57it/s, lr=0.000517, step_loss=0.119]07/27/2023 18:20:25 - INFO - __main__ - train loss is 24.816174320760183\n",
      "Steps:  28%|▎| 4149/15000 [35:35<32:27,  5.57it/s, lr=0.000517, step_loss=0.001607/27/2023 18:20:25 - INFO - __main__ - train loss is 24.829081246512942\n",
      "Steps:  28%|▎| 4150/15000 [35:36<32:25,  5.58it/s, lr=0.000517, step_loss=0.012907/27/2023 18:20:25 - INFO - __main__ - train loss is 25.073093721526675\n",
      "Steps:  28%|▎| 4151/15000 [35:36<32:23,  5.58it/s, lr=0.000517, step_loss=0.244]07/27/2023 18:20:26 - INFO - __main__ - train loss is 25.313401857274584\n",
      "Steps:  28%|▌ | 4152/15000 [35:36<32:23,  5.58it/s, lr=0.000517, step_loss=0.24]07/27/2023 18:20:26 - INFO - __main__ - train loss is 25.659041086095385\n",
      "Steps:  28%|▎| 4153/15000 [35:36<32:40,  5.53it/s, lr=0.000517, step_loss=0.346]07/27/2023 18:20:26 - INFO - __main__ - train loss is 26.039551326888613\n",
      "Steps:  28%|▎| 4154/15000 [35:36<32:47,  5.51it/s, lr=0.000518, step_loss=0.381]07/27/2023 18:20:26 - INFO - __main__ - train loss is 26.085565125453286\n",
      "Steps:  28%|▎| 4155/15000 [35:37<32:40,  5.53it/s, lr=0.000518, step_loss=0.046]07/27/2023 18:20:26 - INFO - __main__ - train loss is 26.099242676864378\n",
      "Steps:  28%|▎| 4156/15000 [35:37<32:35,  5.55it/s, lr=0.000518, step_loss=0.013707/27/2023 18:20:27 - INFO - __main__ - train loss is 26.18836740113329\n",
      "Steps:  28%|▎| 4157/15000 [35:37<32:31,  5.56it/s, lr=0.000518, step_loss=0.089107/27/2023 18:20:27 - INFO - __main__ - train loss is 26.272877265582792\n",
      "Steps:  28%|▎| 4158/15000 [35:37<32:28,  5.56it/s, lr=0.000518, step_loss=0.084507/27/2023 18:20:27 - INFO - __main__ - train loss is 26.296472034300677\n",
      "Steps:  28%|▎| 4159/15000 [35:37<32:26,  5.57it/s, lr=0.000518, step_loss=0.023607/27/2023 18:20:27 - INFO - __main__ - train loss is 26.411637372220866\n",
      "Steps:  28%|▎| 4160/15000 [35:37<32:31,  5.56it/s, lr=0.000518, step_loss=0.115]07/27/2023 18:20:27 - INFO - __main__ - train loss is 26.845875508035533\n",
      "Steps:  28%|▎| 4161/15000 [35:38<32:52,  5.50it/s, lr=0.000518, step_loss=0.434]07/27/2023 18:20:27 - INFO - __main__ - train loss is 26.964925191248767\n",
      "Steps:  28%|▎| 4162/15000 [35:38<33:11,  5.44it/s, lr=0.000519, step_loss=0.119]07/27/2023 18:20:28 - INFO - __main__ - train loss is 26.96668051427696\n",
      "Steps:  28%|▎| 4163/15000 [35:38<33:48,  5.34it/s, lr=0.000519, step_loss=0.001707/27/2023 18:20:28 - INFO - __main__ - train loss is 26.974889510893263\n",
      "Steps:  28%|▎| 4164/15000 [35:38<34:12,  5.28it/s, lr=0.000519, step_loss=0.008207/27/2023 18:20:28 - INFO - __main__ - train loss is 27.140604713582434\n",
      "Steps:  28%|▎| 4165/15000 [35:38<34:29,  5.24it/s, lr=0.000519, step_loss=0.166]07/27/2023 18:20:28 - INFO - __main__ - train loss is 27.610450902604498\n",
      "Steps:  28%|▌ | 4166/15000 [35:39<34:37,  5.21it/s, lr=0.000519, step_loss=0.47]07/27/2023 18:20:28 - INFO - __main__ - train loss is 27.636192610138096\n",
      "Steps:  28%|▎| 4167/15000 [35:39<34:44,  5.20it/s, lr=0.000519, step_loss=0.025707/27/2023 18:20:29 - INFO - __main__ - train loss is 27.639580631745048\n",
      "Steps:  28%|▎| 4168/15000 [35:39<34:48,  5.19it/s, lr=0.000519, step_loss=0.003307/27/2023 18:20:29 - INFO - __main__ - train loss is 27.705413961899467\n",
      "Steps:  28%|▎| 4169/15000 [35:39<34:53,  5.17it/s, lr=0.000519, step_loss=0.065807/27/2023 18:20:29 - INFO - __main__ - train loss is 27.72527253080625\n",
      "Steps:  28%|▎| 4170/15000 [35:39<34:58,  5.16it/s, lr=0.00052, step_loss=0.0199]07/27/2023 18:20:29 - INFO - __main__ - train loss is 28.121081734192558\n",
      "Steps:  28%|▌ | 4171/15000 [35:40<35:13,  5.12it/s, lr=0.00052, step_loss=0.396]07/27/2023 18:20:29 - INFO - __main__ - train loss is 28.157108796876855\n",
      "Steps:  28%|▌ | 4172/15000 [35:40<35:11,  5.13it/s, lr=0.00052, step_loss=0.036]07/27/2023 18:20:30 - INFO - __main__ - train loss is 28.174177134525962\n",
      "Steps:  28%|▎| 4173/15000 [35:40<35:12,  5.13it/s, lr=0.00052, step_loss=0.0171]07/27/2023 18:20:30 - INFO - __main__ - train loss is 28.222961636376567\n",
      "Steps:  28%|▎| 4174/15000 [35:40<35:07,  5.14it/s, lr=0.00052, step_loss=0.0488]07/27/2023 18:20:30 - INFO - __main__ - train loss is 28.2884084378602\n",
      "Steps:  28%|▎| 4175/15000 [35:40<35:07,  5.14it/s, lr=0.00052, step_loss=0.0654]07/27/2023 18:20:30 - INFO - __main__ - train loss is 28.44673887838144\n",
      "Steps:  28%|▌ | 4176/15000 [35:41<35:08,  5.13it/s, lr=0.00052, step_loss=0.158]07/27/2023 18:20:30 - INFO - __main__ - train loss is 28.79670799721498\n",
      "Steps:  28%|▌ | 4177/15000 [35:41<35:08,  5.13it/s, lr=0.000521, step_loss=0.35]07/27/2023 18:20:31 - INFO - __main__ - train loss is 28.8453269173624\n",
      "Steps:  28%|▎| 4178/15000 [35:41<35:05,  5.14it/s, lr=0.000521, step_loss=0.048607/27/2023 18:20:31 - INFO - __main__ - train loss is 28.85982182447333\n",
      "Steps:  28%|▎| 4179/15000 [35:41<35:05,  5.14it/s, lr=0.000521, step_loss=0.014507/27/2023 18:20:31 - INFO - __main__ - train loss is 28.9557457548799\n",
      "Steps:  28%|▎| 4180/15000 [35:41<35:06,  5.14it/s, lr=0.000521, step_loss=0.095907/27/2023 18:20:31 - INFO - __main__ - train loss is 29.046677073580213\n",
      "Steps:  28%|▎| 4181/15000 [35:41<35:09,  5.13it/s, lr=0.000521, step_loss=0.090907/27/2023 18:20:31 - INFO - __main__ - train loss is 29.117257854086347\n",
      "Steps:  28%|▎| 4182/15000 [35:42<35:07,  5.13it/s, lr=0.000521, step_loss=0.070607/27/2023 18:20:32 - INFO - __main__ - train loss is 29.14375501696486\n",
      "Steps:  28%|▎| 4183/15000 [35:42<35:06,  5.14it/s, lr=0.000521, step_loss=0.026507/27/2023 18:20:32 - INFO - __main__ - train loss is 29.346063135308214\n",
      "Steps:  28%|▎| 4184/15000 [35:42<35:06,  5.14it/s, lr=0.000521, step_loss=0.202]07/27/2023 18:20:32 - INFO - __main__ - train loss is 29.673389224451967\n",
      "Steps:  28%|▎| 4185/15000 [35:42<35:05,  5.14it/s, lr=0.000521, step_loss=0.327]07/27/2023 18:20:32 - INFO - __main__ - train loss is 29.675914870458655\n",
      "Steps:  28%|▎| 4186/15000 [35:42<34:38,  5.20it/s, lr=0.000522, step_loss=0.002507/27/2023 18:20:32 - INFO - __main__ - train loss is 29.677173198317178\n",
      "Steps:  28%|▎| 4187/15000 [35:43<34:01,  5.30it/s, lr=0.000522, step_loss=0.001207/27/2023 18:20:32 - INFO - __main__ - train loss is 29.843267516349442\n",
      "Steps:  28%|▎| 4188/15000 [35:43<33:29,  5.38it/s, lr=0.000522, step_loss=0.166]07/27/2023 18:20:33 - INFO - __main__ - train loss is 29.845940800500102\n",
      "Steps:  28%|▎| 4189/15000 [35:43<33:07,  5.44it/s, lr=0.000522, step_loss=0.002607/27/2023 18:20:33 - INFO - __main__ - train loss is 29.905484212678857\n",
      "Steps:  28%|▎| 4190/15000 [35:43<32:52,  5.48it/s, lr=0.000522, step_loss=0.059507/27/2023 18:20:33 - INFO - __main__ - train loss is 29.952276466530748\n",
      "Steps:  28%|▎| 4191/15000 [35:43<32:41,  5.51it/s, lr=0.000522, step_loss=0.046807/27/2023 18:20:33 - INFO - __main__ - train loss is 29.98628768522758\n",
      "Steps:  28%|▎| 4192/15000 [35:44<32:53,  5.48it/s, lr=0.000522, step_loss=0.034]07/27/2023 18:20:33 - INFO - __main__ - train loss is 29.993362878565677\n",
      "Steps:  28%|▎| 4193/15000 [35:44<33:06,  5.44it/s, lr=0.000522, step_loss=0.007007/27/2023 18:20:34 - INFO - __main__ - train loss is 30.085150470142253\n",
      "Steps:  28%|▎| 4194/15000 [35:44<33:16,  5.41it/s, lr=0.000523, step_loss=0.091807/27/2023 18:20:34 - INFO - __main__ - train loss is 30.377069701557048\n",
      "Steps:  28%|▎| 4195/15000 [35:44<33:23,  5.39it/s, lr=0.000523, step_loss=0.292]07/27/2023 18:20:34 - INFO - __main__ - train loss is 30.477576998178847\n",
      "Steps:  28%|▎| 4196/15000 [35:44<33:28,  5.38it/s, lr=0.000523, step_loss=0.101]07/27/2023 18:20:34 - INFO - __main__ - train loss is 30.58590981096495\n",
      "Steps:  28%|▎| 4197/15000 [35:44<33:31,  5.37it/s, lr=0.000523, step_loss=0.108]07/27/2023 18:20:34 - INFO - __main__ - train loss is 30.593504820601083\n",
      "Steps:  28%|▎| 4198/15000 [35:45<33:16,  5.41it/s, lr=0.000523, step_loss=0.007607/27/2023 18:20:35 - INFO - __main__ - train loss is 31.2672956926981\n",
      "Steps:  28%|▎| 4199/15000 [35:45<33:00,  5.45it/s, lr=0.000523, step_loss=0.674]07/27/2023 18:20:35 - INFO - __main__ - train loss is 32.045130167738535\n",
      "Steps:  28%|▎| 4200/15000 [35:45<32:49,  5.48it/s, lr=0.000523, step_loss=0.778]07/27/2023 18:20:35 - INFO - __main__ - train loss is 32.061280035064556\n",
      "Steps:  28%|▎| 4201/15000 [35:45<32:40,  5.51it/s, lr=0.000523, step_loss=0.016107/27/2023 18:20:35 - INFO - __main__ - train loss is 32.11561249254737\n",
      "Steps:  28%|▎| 4202/15000 [35:45<32:34,  5.53it/s, lr=0.000524, step_loss=0.054307/27/2023 18:20:35 - INFO - __main__ - train loss is 32.375166103825904\n",
      "Steps:  28%|▌ | 4203/15000 [35:46<32:28,  5.54it/s, lr=0.000524, step_loss=0.26]07/27/2023 18:20:35 - INFO - __main__ - train loss is 32.591354624019004\n",
      "Steps:  28%|▎| 4204/15000 [35:46<32:24,  5.55it/s, lr=0.000524, step_loss=0.216]07/27/2023 18:20:36 - INFO - __main__ - train loss is 32.606442320742644\n",
      "Steps:  28%|▎| 4205/15000 [35:46<32:21,  5.56it/s, lr=0.000524, step_loss=0.015107/27/2023 18:20:36 - INFO - __main__ - train loss is 32.60999527492095\n",
      "Steps:  28%|▎| 4206/15000 [35:46<32:19,  5.57it/s, lr=0.000524, step_loss=0.003507/27/2023 18:20:36 - INFO - __main__ - train loss is 32.703608571668155\n",
      "Steps:  28%|▎| 4207/15000 [35:46<32:18,  5.57it/s, lr=0.000524, step_loss=0.093607/27/2023 18:20:36 - INFO - __main__ - train loss is 32.70511344273109\n",
      "Steps:  28%|▎| 4208/15000 [35:46<32:16,  5.57it/s, lr=0.000524, step_loss=0.001507/27/2023 18:20:36 - INFO - __main__ - train loss is 32.74596307624597\n",
      "Steps:  28%|▎| 4209/15000 [35:47<32:15,  5.57it/s, lr=0.000525, step_loss=0.040807/27/2023 18:20:36 - INFO - __main__ - train loss is 32.77340038504917\n",
      "Steps:  28%|▎| 4210/15000 [35:47<32:14,  5.58it/s, lr=0.000525, step_loss=0.027407/27/2023 18:20:37 - INFO - __main__ - train loss is 32.793925821897574\n",
      "Steps:  28%|▎| 4211/15000 [35:47<32:13,  5.58it/s, lr=0.000525, step_loss=0.020507/27/2023 18:20:37 - INFO - __main__ - train loss is 32.94602647435386\n",
      "Steps:  28%|▎| 4212/15000 [35:47<32:13,  5.58it/s, lr=0.000525, step_loss=0.152]07/27/2023 18:20:37 - INFO - __main__ - train loss is 33.79590782534797\n",
      "Steps:  28%|▌ | 4213/15000 [35:47<32:18,  5.57it/s, lr=0.000525, step_loss=0.85]07/27/2023 18:20:37 - INFO - __main__ - train loss is 33.82254147727508\n",
      "Steps:  28%|▎| 4214/15000 [35:48<32:35,  5.52it/s, lr=0.000525, step_loss=0.026607/27/2023 18:20:37 - INFO - __main__ - train loss is 33.84009857487399\n",
      "Steps:  28%|▎| 4215/15000 [35:48<32:39,  5.50it/s, lr=0.000525, step_loss=0.017607/27/2023 18:20:38 - INFO - __main__ - train loss is 34.08719784033019\n",
      "Steps:  28%|▎| 4216/15000 [35:48<32:33,  5.52it/s, lr=0.000525, step_loss=0.247]07/27/2023 18:20:38 - INFO - __main__ - train loss is 34.70330554258544\n",
      "Steps:  28%|▎| 4217/15000 [35:48<32:27,  5.54it/s, lr=0.000525, step_loss=0.616]07/27/2023 18:20:38 - INFO - __main__ - train loss is 34.90885651123244\n",
      "Steps:  28%|▎| 4218/15000 [35:48<32:28,  5.53it/s, lr=0.000526, step_loss=0.206]07/27/2023 18:20:38 - INFO - __main__ - train loss is 34.9587064498337\n",
      "Steps:  28%|▎| 4219/15000 [35:48<32:22,  5.55it/s, lr=0.000526, step_loss=0.049807/27/2023 18:20:38 - INFO - __main__ - train loss is 35.19928511616308\n",
      "Steps:  28%|▎| 4220/15000 [35:49<32:39,  5.50it/s, lr=0.000526, step_loss=0.241]07/27/2023 18:20:38 - INFO - __main__ - train loss is 35.20827917766292\n",
      "Steps:  28%|▎| 4221/15000 [35:49<32:56,  5.45it/s, lr=0.000526, step_loss=0.008907/27/2023 18:20:39 - INFO - __main__ - train loss is 35.568962618825026\n",
      "Steps:  28%|▎| 4222/15000 [35:49<33:08,  5.42it/s, lr=0.000526, step_loss=0.361]07/27/2023 18:20:39 - INFO - __main__ - train loss is 35.629099577781744\n",
      "Steps:  28%|▎| 4223/15000 [35:49<32:57,  5.45it/s, lr=0.000526, step_loss=0.060107/27/2023 18:20:39 - INFO - __main__ - train loss is 35.733446121332236\n",
      "Steps:  28%|▎| 4224/15000 [35:49<32:43,  5.49it/s, lr=0.000526, step_loss=0.104]07/27/2023 18:20:39 - INFO - __main__ - train loss is 35.74736832652707\n",
      "Steps:  28%|▎| 4225/15000 [35:50<32:35,  5.51it/s, lr=0.000526, step_loss=0.013907/27/2023 18:20:39 - INFO - __main__ - train loss is 35.82008872006554\n",
      "Steps:  28%|▎| 4226/15000 [35:50<32:26,  5.53it/s, lr=0.000527, step_loss=0.072707/27/2023 18:20:40 - INFO - __main__ - train loss is 35.98533034895081\n",
      "Steps:  28%|▎| 4227/15000 [35:50<32:20,  5.55it/s, lr=0.000527, step_loss=0.165]07/27/2023 18:20:40 - INFO - __main__ - train loss is 36.113532429677434\n",
      "Steps:  28%|▎| 4228/15000 [35:50<32:15,  5.56it/s, lr=0.000527, step_loss=0.128]07/27/2023 18:20:40 - INFO - __main__ - train loss is 36.482929265243\n",
      "Steps:  28%|▎| 4229/15000 [35:50<32:36,  5.51it/s, lr=0.000527, step_loss=0.369]07/27/2023 18:20:40 - INFO - __main__ - train loss is 36.49606206279714\n",
      "Steps:  28%|▎| 4230/15000 [35:50<32:39,  5.50it/s, lr=0.000527, step_loss=0.013107/27/2023 18:20:40 - INFO - __main__ - train loss is 36.509441983071156\n",
      "Steps:  28%|▎| 4231/15000 [35:51<32:29,  5.52it/s, lr=0.000527, step_loss=0.013407/27/2023 18:20:40 - INFO - __main__ - train loss is 36.51713116385508\n",
      "Steps:  28%|▎| 4232/15000 [35:51<32:21,  5.55it/s, lr=0.000527, step_loss=0.007607/27/2023 18:20:41 - INFO - __main__ - train loss is 37.416326179285534\n",
      "Steps:  28%|▎| 4233/15000 [35:51<32:23,  5.54it/s, lr=0.000527, step_loss=0.899]07/27/2023 18:20:41 - INFO - __main__ - train loss is 37.66446475603152\n",
      "Steps:  28%|▎| 4234/15000 [35:51<32:18,  5.55it/s, lr=0.000528, step_loss=0.248]07/27/2023 18:20:41 - INFO - __main__ - train loss is 37.696331418235786\n",
      "Steps:  28%|▎| 4235/15000 [35:51<32:14,  5.56it/s, lr=0.000528, step_loss=0.031907/27/2023 18:20:41 - INFO - __main__ - train loss is 37.704452931066044\n",
      "Steps:  28%|▎| 4236/15000 [35:52<32:10,  5.58it/s, lr=0.000528, step_loss=0.008107/27/2023 18:20:41 - INFO - __main__ - train loss is 38.4223101726966\n",
      "Steps:  28%|▎| 4237/15000 [35:52<32:24,  5.54it/s, lr=0.000528, step_loss=0.718]07/27/2023 18:20:42 - INFO - __main__ - train loss is 38.9372808925109\n",
      "Steps:  28%|▎| 4238/15000 [35:52<32:17,  5.55it/s, lr=0.000528, step_loss=0.515]07/27/2023 18:20:42 - INFO - __main__ - train loss is 39.20781618275214\n",
      "Steps:  28%|▎| 4239/15000 [35:52<32:14,  5.56it/s, lr=0.000528, step_loss=0.271]07/27/2023 18:20:42 - INFO - __main__ - train loss is 39.261953170527704\n",
      "Steps:  28%|▎| 4240/15000 [35:52<32:10,  5.57it/s, lr=0.000528, step_loss=0.054107/27/2023 18:20:42 - INFO - __main__ - train loss is 39.333310398389585\n",
      "Steps:  28%|▎| 4241/15000 [35:52<32:08,  5.58it/s, lr=0.000528, step_loss=0.071407/27/2023 18:20:42 - INFO - __main__ - train loss is 39.34440771967638\n",
      "Steps:  28%|▎| 4242/15000 [35:53<44:00,  4.07it/s, lr=0.000529, step_loss=0.011107/27/2023 18:20:44 - INFO - __main__ - Per validation step average loss is 0.013164274394512177\n",
      "07/27/2023 18:20:44 - INFO - __main__ - Cumulative validation average loss is 0.013164274394512177\n",
      "07/27/2023 18:20:44 - INFO - __main__ - Per validation step average loss is 0.0331115759909153\n",
      "07/27/2023 18:20:44 - INFO - __main__ - Cumulative validation average loss is 0.046275850385427475\n",
      "07/27/2023 18:20:44 - INFO - __main__ - Per validation step average loss is 0.3011718988418579\n",
      "07/27/2023 18:20:44 - INFO - __main__ - Cumulative validation average loss is 0.3474477492272854\n",
      "07/27/2023 18:20:45 - INFO - __main__ - Per validation step average loss is 0.12675683200359344\n",
      "07/27/2023 18:20:45 - INFO - __main__ - Cumulative validation average loss is 0.47420458123087883\n",
      "07/27/2023 18:20:45 - INFO - __main__ - Per validation step average loss is 0.0024894129019230604\n",
      "07/27/2023 18:20:45 - INFO - __main__ - Cumulative validation average loss is 0.4766939941328019\n",
      "07/27/2023 18:20:46 - INFO - __main__ - Per validation step average loss is 0.09286486357450485\n",
      "07/27/2023 18:20:46 - INFO - __main__ - Cumulative validation average loss is 0.5695588577073067\n",
      "07/27/2023 18:20:46 - INFO - __main__ - Per validation step average loss is 0.047167785465717316\n",
      "07/27/2023 18:20:46 - INFO - __main__ - Cumulative validation average loss is 0.6167266431730241\n",
      "07/27/2023 18:20:46 - INFO - __main__ - Per validation step average loss is 0.4179452955722809\n",
      "07/27/2023 18:20:46 - INFO - __main__ - Cumulative validation average loss is 1.034671938745305\n",
      "07/27/2023 18:20:47 - INFO - __main__ - Per validation step average loss is 0.17327836155891418\n",
      "07/27/2023 18:20:47 - INFO - __main__ - Cumulative validation average loss is 1.2079503003042191\n",
      "07/27/2023 18:20:47 - INFO - __main__ - Per validation step average loss is 0.4553361237049103\n",
      "07/27/2023 18:20:47 - INFO - __main__ - Cumulative validation average loss is 1.6632864240091294\n",
      "07/27/2023 18:20:48 - INFO - __main__ - Per validation step average loss is 0.26609548926353455\n",
      "07/27/2023 18:20:48 - INFO - __main__ - Cumulative validation average loss is 1.929381913272664\n",
      "07/27/2023 18:20:48 - INFO - __main__ - Per validation step average loss is 0.20946821570396423\n",
      "07/27/2023 18:20:48 - INFO - __main__ - Cumulative validation average loss is 2.138850128976628\n",
      "07/27/2023 18:20:48 - INFO - __main__ - Per validation step average loss is 0.014079631306231022\n",
      "07/27/2023 18:20:48 - INFO - __main__ - Cumulative validation average loss is 2.152929760282859\n",
      "07/27/2023 18:20:49 - INFO - __main__ - Per validation step average loss is 0.006729282438755035\n",
      "07/27/2023 18:20:49 - INFO - __main__ - Cumulative validation average loss is 2.1596590427216142\n",
      "07/27/2023 18:20:49 - INFO - __main__ - Per validation step average loss is 0.10925475507974625\n",
      "07/27/2023 18:20:49 - INFO - __main__ - Cumulative validation average loss is 2.2689137978013605\n",
      "07/27/2023 18:20:50 - INFO - __main__ - Per validation step average loss is 0.18973974883556366\n",
      "07/27/2023 18:20:50 - INFO - __main__ - Cumulative validation average loss is 2.458653546636924\n",
      "07/27/2023 18:20:50 - INFO - __main__ - Per validation step average loss is 0.059549376368522644\n",
      "07/27/2023 18:20:50 - INFO - __main__ - Cumulative validation average loss is 2.518202923005447\n",
      "07/27/2023 18:20:50 - INFO - __main__ - Per validation step average loss is 0.006828479003161192\n",
      "07/27/2023 18:20:50 - INFO - __main__ - Cumulative validation average loss is 2.525031402008608\n",
      "07/27/2023 18:20:51 - INFO - __main__ - Per validation step average loss is 0.03332880884408951\n",
      "07/27/2023 18:20:51 - INFO - __main__ - Cumulative validation average loss is 2.5583602108526975\n",
      "07/27/2023 18:20:51 - INFO - __main__ - Per validation step average loss is 0.00360998697578907\n",
      "07/27/2023 18:20:51 - INFO - __main__ - Cumulative validation average loss is 2.5619701978284866\n",
      "07/27/2023 18:20:52 - INFO - __main__ - Per validation step average loss is 0.024912424385547638\n",
      "07/27/2023 18:20:52 - INFO - __main__ - Cumulative validation average loss is 2.586882622214034\n",
      "07/27/2023 18:20:52 - INFO - __main__ - Per validation step average loss is 0.17471477389335632\n",
      "07/27/2023 18:20:52 - INFO - __main__ - Cumulative validation average loss is 2.7615973961073905\n",
      "07/27/2023 18:20:53 - INFO - __main__ - Per validation step average loss is 0.029224105179309845\n",
      "07/27/2023 18:20:53 - INFO - __main__ - Cumulative validation average loss is 2.7908215012867004\n",
      "07/27/2023 18:20:53 - INFO - __main__ - Per validation step average loss is 0.1807546615600586\n",
      "07/27/2023 18:20:53 - INFO - __main__ - Cumulative validation average loss is 2.971576162846759\n",
      "07/27/2023 18:20:53 - INFO - __main__ - Per validation step average loss is 0.0022908488754183054\n",
      "07/27/2023 18:20:53 - INFO - __main__ - Cumulative validation average loss is 2.9738670117221773\n",
      "07/27/2023 18:20:54 - INFO - __main__ - Per validation step average loss is 0.21409142017364502\n",
      "07/27/2023 18:20:54 - INFO - __main__ - Cumulative validation average loss is 3.1879584318958223\n",
      "07/27/2023 18:20:54 - INFO - __main__ - Per validation step average loss is 0.0410119965672493\n",
      "07/27/2023 18:20:54 - INFO - __main__ - Cumulative validation average loss is 3.2289704284630716\n",
      "07/27/2023 18:20:55 - INFO - __main__ - Per validation step average loss is 0.002740174764767289\n",
      "07/27/2023 18:20:55 - INFO - __main__ - Cumulative validation average loss is 3.231710603227839\n",
      "07/27/2023 18:20:55 - INFO - __main__ - Per validation step average loss is 0.0035472754389047623\n",
      "07/27/2023 18:20:55 - INFO - __main__ - Cumulative validation average loss is 3.2352578786667436\n",
      "07/27/2023 18:20:55 - INFO - __main__ - Per validation step average loss is 0.10938054323196411\n",
      "07/27/2023 18:20:55 - INFO - __main__ - Cumulative validation average loss is 3.3446384218987077\n",
      "07/27/2023 18:20:56 - INFO - __main__ - Per validation step average loss is 0.3219171166419983\n",
      "07/27/2023 18:20:56 - INFO - __main__ - Cumulative validation average loss is 3.666555538540706\n",
      "07/27/2023 18:20:56 - INFO - __main__ - Per validation step average loss is 0.11879663169384003\n",
      "07/27/2023 18:20:56 - INFO - __main__ - Cumulative validation average loss is 3.785352170234546\n",
      "07/27/2023 18:20:57 - INFO - __main__ - Per validation step average loss is 0.3082609176635742\n",
      "07/27/2023 18:20:57 - INFO - __main__ - Cumulative validation average loss is 4.09361308789812\n",
      "07/27/2023 18:20:57 - INFO - __main__ - Per validation step average loss is 0.05785650759935379\n",
      "07/27/2023 18:20:57 - INFO - __main__ - Cumulative validation average loss is 4.151469595497474\n",
      "07/27/2023 18:20:57 - INFO - __main__ - Per validation step average loss is 0.17150519788265228\n",
      "07/27/2023 18:20:57 - INFO - __main__ - Cumulative validation average loss is 4.322974793380126\n",
      "07/27/2023 18:20:58 - INFO - __main__ - Per validation step average loss is 0.49761128425598145\n",
      "07/27/2023 18:20:58 - INFO - __main__ - Cumulative validation average loss is 4.820586077636108\n",
      "07/27/2023 18:20:58 - INFO - __main__ - Per validation step average loss is 0.003653730731457472\n",
      "07/27/2023 18:20:58 - INFO - __main__ - Cumulative validation average loss is 4.824239808367565\n",
      "07/27/2023 18:20:59 - INFO - __main__ - Per validation step average loss is 0.2357327789068222\n",
      "07/27/2023 18:20:59 - INFO - __main__ - Cumulative validation average loss is 5.0599725872743875\n",
      "07/27/2023 18:20:59 - INFO - __main__ - Per validation step average loss is 0.5274204015731812\n",
      "07/27/2023 18:20:59 - INFO - __main__ - Cumulative validation average loss is 5.587392988847569\n",
      "07/27/2023 18:20:59 - INFO - __main__ - Per validation step average loss is 0.19591392576694489\n",
      "07/27/2023 18:20:59 - INFO - __main__ - Cumulative validation average loss is 5.7833069146145135\n",
      "07/27/2023 18:21:00 - INFO - __main__ - Per validation step average loss is 0.0374409481883049\n",
      "07/27/2023 18:21:00 - INFO - __main__ - Cumulative validation average loss is 5.820747862802818\n",
      "07/27/2023 18:21:00 - INFO - __main__ - Per validation step average loss is 0.003750292817130685\n",
      "07/27/2023 18:21:00 - INFO - __main__ - Cumulative validation average loss is 5.824498155619949\n",
      "07/27/2023 18:21:01 - INFO - __main__ - Per validation step average loss is 0.03263071924448013\n",
      "07/27/2023 18:21:01 - INFO - __main__ - Cumulative validation average loss is 5.857128874864429\n",
      "07/27/2023 18:21:01 - INFO - __main__ - Per validation step average loss is 0.002751326421275735\n",
      "07/27/2023 18:21:01 - INFO - __main__ - Cumulative validation average loss is 5.859880201285705\n",
      "07/27/2023 18:21:01 - INFO - __main__ - Per validation step average loss is 0.06032707542181015\n",
      "07/27/2023 18:21:01 - INFO - __main__ - Cumulative validation average loss is 5.920207276707515\n",
      "07/27/2023 18:21:02 - INFO - __main__ - Per validation step average loss is 0.1744130402803421\n",
      "07/27/2023 18:21:02 - INFO - __main__ - Cumulative validation average loss is 6.094620316987857\n",
      "07/27/2023 18:21:02 - INFO - __main__ - Per validation step average loss is 0.029521694406867027\n",
      "07/27/2023 18:21:02 - INFO - __main__ - Cumulative validation average loss is 6.124142011394724\n",
      "07/27/2023 18:21:03 - INFO - __main__ - Per validation step average loss is 0.19189974665641785\n",
      "07/27/2023 18:21:03 - INFO - __main__ - Cumulative validation average loss is 6.316041758051142\n",
      "07/27/2023 18:21:03 - INFO - __main__ - Per validation step average loss is 0.010382606647908688\n",
      "07/27/2023 18:21:03 - INFO - __main__ - Cumulative validation average loss is 6.326424364699051\n",
      "07/27/2023 18:21:04 - INFO - __main__ - Per validation step average loss is 0.24596655368804932\n",
      "07/27/2023 18:21:04 - INFO - __main__ - Cumulative validation average loss is 6.5723909183871\n",
      "07/27/2023 18:21:04 - INFO - __main__ - Per validation step average loss is 0.05692286789417267\n",
      "07/27/2023 18:21:04 - INFO - __main__ - Cumulative validation average loss is 6.629313786281273\n",
      "07/27/2023 18:21:04 - INFO - __main__ - Per validation step average loss is 0.02741701900959015\n",
      "07/27/2023 18:21:04 - INFO - __main__ - Cumulative validation average loss is 6.656730805290863\n",
      "07/27/2023 18:21:05 - INFO - __main__ - Per validation step average loss is 0.08394600450992584\n",
      "07/27/2023 18:21:05 - INFO - __main__ - Cumulative validation average loss is 6.740676809800789\n",
      "07/27/2023 18:21:05 - INFO - __main__ - Per validation step average loss is 0.0023959067184478045\n",
      "07/27/2023 18:21:05 - INFO - __main__ - Cumulative validation average loss is 6.743072716519237\n",
      "07/27/2023 18:21:06 - INFO - __main__ - Per validation step average loss is 0.0027578752487897873\n",
      "07/27/2023 18:21:06 - INFO - __main__ - Cumulative validation average loss is 6.745830591768026\n",
      "07/27/2023 18:21:06 - INFO - __main__ - Per validation step average loss is 0.20869043469429016\n",
      "07/27/2023 18:21:06 - INFO - __main__ - Cumulative validation average loss is 6.9545210264623165\n",
      "07/27/2023 18:21:06 - INFO - __main__ - Per validation step average loss is 0.06403198838233948\n",
      "07/27/2023 18:21:06 - INFO - __main__ - Cumulative validation average loss is 7.018553014844656\n",
      "07/27/2023 18:21:07 - INFO - __main__ - Per validation step average loss is 0.005698871798813343\n",
      "07/27/2023 18:21:07 - INFO - __main__ - Cumulative validation average loss is 7.024251886643469\n",
      "07/27/2023 18:21:07 - INFO - __main__ - Per validation step average loss is 0.003738304367288947\n",
      "07/27/2023 18:21:07 - INFO - __main__ - Cumulative validation average loss is 7.027990191010758\n",
      "07/27/2023 18:21:08 - INFO - __main__ - Per validation step average loss is 0.05458378046751022\n",
      "07/27/2023 18:21:08 - INFO - __main__ - Cumulative validation average loss is 7.0825739714782685\n",
      "07/27/2023 18:21:08 - INFO - __main__ - Per validation step average loss is 0.1942671835422516\n",
      "07/27/2023 18:21:08 - INFO - __main__ - Cumulative validation average loss is 7.27684115502052\n",
      "07/27/2023 18:21:08 - INFO - __main__ - Per validation step average loss is 0.18756286799907684\n",
      "07/27/2023 18:21:08 - INFO - __main__ - Cumulative validation average loss is 7.464404023019597\n",
      "07/27/2023 18:21:09 - INFO - __main__ - Per validation step average loss is 0.046060994267463684\n",
      "07/27/2023 18:21:09 - INFO - __main__ - Cumulative validation average loss is 7.510465017287061\n",
      "07/27/2023 18:21:09 - INFO - __main__ - Per validation step average loss is 0.16240110993385315\n",
      "07/27/2023 18:21:09 - INFO - __main__ - Cumulative validation average loss is 7.672866127220914\n",
      "07/27/2023 18:21:10 - INFO - __main__ - Per validation step average loss is 0.35793519020080566\n",
      "07/27/2023 18:21:10 - INFO - __main__ - Cumulative validation average loss is 8.03080131742172\n",
      "07/27/2023 18:21:10 - INFO - __main__ - Per validation step average loss is 0.3695792853832245\n",
      "07/27/2023 18:21:10 - INFO - __main__ - Cumulative validation average loss is 8.400380602804944\n",
      "07/27/2023 18:21:11 - INFO - __main__ - Per validation step average loss is 0.008423984050750732\n",
      "07/27/2023 18:21:11 - INFO - __main__ - Cumulative validation average loss is 8.408804586855695\n",
      "07/27/2023 18:21:11 - INFO - __main__ - Per validation step average loss is 0.015986744314432144\n",
      "07/27/2023 18:21:11 - INFO - __main__ - Cumulative validation average loss is 8.424791331170127\n",
      "07/27/2023 18:21:11 - INFO - __main__ - Per validation step average loss is 0.21907737851142883\n",
      "07/27/2023 18:21:11 - INFO - __main__ - Cumulative validation average loss is 8.643868709681556\n",
      "07/27/2023 18:21:12 - INFO - __main__ - Per validation step average loss is 0.15614214539527893\n",
      "07/27/2023 18:21:12 - INFO - __main__ - Cumulative validation average loss is 8.800010855076835\n",
      "07/27/2023 18:21:12 - INFO - __main__ - Per validation step average loss is 0.015723658725619316\n",
      "07/27/2023 18:21:12 - INFO - __main__ - Cumulative validation average loss is 8.815734513802454\n",
      "07/27/2023 18:21:13 - INFO - __main__ - Per validation step average loss is 0.014474467374384403\n",
      "07/27/2023 18:21:13 - INFO - __main__ - Cumulative validation average loss is 8.830208981176838\n",
      "07/27/2023 18:21:13 - INFO - __main__ - Per validation step average loss is 0.08920039236545563\n",
      "07/27/2023 18:21:13 - INFO - __main__ - Cumulative validation average loss is 8.919409373542294\n",
      "07/27/2023 18:21:13 - INFO - __main__ - Per validation step average loss is 0.27866947650909424\n",
      "07/27/2023 18:21:13 - INFO - __main__ - Cumulative validation average loss is 9.198078850051388\n",
      "07/27/2023 18:21:14 - INFO - __main__ - Per validation step average loss is 0.21196435391902924\n",
      "07/27/2023 18:21:14 - INFO - __main__ - Cumulative validation average loss is 9.410043203970417\n",
      "07/27/2023 18:21:14 - INFO - __main__ - Per validation step average loss is 0.13227884471416473\n",
      "07/27/2023 18:21:14 - INFO - __main__ - Cumulative validation average loss is 9.542322048684582\n",
      "07/27/2023 18:21:15 - INFO - __main__ - Per validation step average loss is 0.3884638547897339\n",
      "07/27/2023 18:21:15 - INFO - __main__ - Cumulative validation average loss is 9.930785903474316\n",
      "07/27/2023 18:21:15 - INFO - __main__ - Per validation step average loss is 0.11412196606397629\n",
      "07/27/2023 18:21:15 - INFO - __main__ - Cumulative validation average loss is 10.044907869538292\n",
      "07/27/2023 18:21:16 - INFO - __main__ - Per validation step average loss is 0.011762324720621109\n",
      "07/27/2023 18:21:16 - INFO - __main__ - Cumulative validation average loss is 10.056670194258913\n",
      "07/27/2023 18:21:16 - INFO - __main__ - Average validation loss for Epoch 13 is 0.12729962271213816\n",
      "07/27/2023 18:21:16 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 18:22:13 - INFO - __main__ - Starting epoch 14\n",
      "07/27/2023 18:22:13 - INFO - __main__ - train loss is 0.24757803976535797\n",
      "Steps:  28%|▎| 4243/15000 [37:24<82:01:31, 27.45s/it, lr=0.000529, step_loss=0.207/27/2023 18:22:14 - INFO - __main__ - train loss is 0.31831151992082596\n",
      "Steps:  28%|▎| 4244/15000 [37:24<57:35:01, 19.27s/it, lr=0.000529, step_loss=0.007/27/2023 18:22:14 - INFO - __main__ - train loss is 0.3806805722415447\n",
      "Steps:  28%|▎| 4245/15000 [37:24<40:27:54, 13.54s/it, lr=0.000529, step_loss=0.007/27/2023 18:22:14 - INFO - __main__ - train loss is 0.4037259239703417\n",
      "Steps:  28%|▎| 4246/15000 [37:24<28:29:00,  9.54s/it, lr=0.000529, step_loss=0.007/27/2023 18:22:14 - INFO - __main__ - train loss is 1.025223197415471\n",
      "Steps:  28%|▎| 4247/15000 [37:24<20:05:49,  6.73s/it, lr=0.000529, step_loss=0.607/27/2023 18:22:14 - INFO - __main__ - train loss is 1.2654206175357103\n",
      "Steps:  28%|▎| 4248/15000 [37:25<14:13:44,  4.76s/it, lr=0.000529, step_loss=0.207/27/2023 18:22:15 - INFO - __main__ - train loss is 1.4746164996176958\n",
      "Steps:  28%|▎| 4249/15000 [37:25<10:07:16,  3.39s/it, lr=0.00053, step_loss=0.2007/27/2023 18:22:15 - INFO - __main__ - train loss is 1.5010603796690702\n",
      "Steps:  28%|▎| 4250/15000 [37:25<7:14:58,  2.43s/it, lr=0.00053, step_loss=0.02607/27/2023 18:22:15 - INFO - __main__ - train loss is 1.7789186965674162\n",
      "Steps:  28%|▎| 4251/15000 [37:25<5:14:02,  1.75s/it, lr=0.00053, step_loss=0.27807/27/2023 18:22:15 - INFO - __main__ - train loss is 2.359762979671359\n",
      "Steps:  28%|▎| 4252/15000 [37:25<3:49:23,  1.28s/it, lr=0.00053, step_loss=0.58107/27/2023 18:22:15 - INFO - __main__ - train loss is 2.399437753483653\n",
      "Steps:  28%|▎| 4253/15000 [37:26<2:50:28,  1.05it/s, lr=0.00053, step_loss=0.03907/27/2023 18:22:15 - INFO - __main__ - train loss is 2.5581411104649305\n",
      "Steps:  28%|▎| 4254/15000 [37:26<2:09:02,  1.39it/s, lr=0.00053, step_loss=0.15907/27/2023 18:22:16 - INFO - __main__ - train loss is 2.6713206600397825\n",
      "Steps:  28%|▎| 4255/15000 [37:26<1:39:57,  1.79it/s, lr=0.00053, step_loss=0.11307/27/2023 18:22:16 - INFO - __main__ - train loss is 2.7661895286291838\n",
      "Steps:  28%|▎| 4256/15000 [37:26<1:19:37,  2.25it/s, lr=0.00053, step_loss=0.09407/27/2023 18:22:16 - INFO - __main__ - train loss is 2.8115853797644377\n",
      "Steps:  28%|▎| 4257/15000 [37:26<1:05:25,  2.74it/s, lr=0.00053, step_loss=0.04507/27/2023 18:22:16 - INFO - __main__ - train loss is 3.025907812640071\n",
      "Steps:  28%|▎| 4258/15000 [37:26<55:23,  3.23it/s, lr=0.000531, step_loss=0.214]07/27/2023 18:22:16 - INFO - __main__ - train loss is 3.415142683312297\n",
      "Steps:  28%|▎| 4259/15000 [37:27<48:21,  3.70it/s, lr=0.000531, step_loss=0.389]07/27/2023 18:22:16 - INFO - __main__ - train loss is 3.465123051777482\n",
      "Steps:  28%|▌ | 4260/15000 [37:27<43:34,  4.11it/s, lr=0.000531, step_loss=0.05]07/27/2023 18:22:17 - INFO - __main__ - train loss is 3.5771544370800257\n",
      "Steps:  28%|▎| 4261/15000 [37:27<40:10,  4.46it/s, lr=0.000531, step_loss=0.112]07/27/2023 18:22:17 - INFO - __main__ - train loss is 3.580822056857869\n",
      "Steps:  28%|▎| 4262/15000 [37:27<37:45,  4.74it/s, lr=0.000531, step_loss=0.003607/27/2023 18:22:17 - INFO - __main__ - train loss is 4.013494527665898\n",
      "Steps:  28%|▎| 4263/15000 [37:27<36:08,  4.95it/s, lr=0.000531, step_loss=0.433]07/27/2023 18:22:17 - INFO - __main__ - train loss is 4.108988969353959\n",
      "Steps:  28%|▎| 4264/15000 [37:28<34:55,  5.12it/s, lr=0.000531, step_loss=0.095507/27/2023 18:22:17 - INFO - __main__ - train loss is 4.170360284624621\n",
      "Steps:  28%|▎| 4265/15000 [37:28<34:05,  5.25it/s, lr=0.000531, step_loss=0.061407/27/2023 18:22:18 - INFO - __main__ - train loss is 4.177209006389603\n",
      "Steps:  28%|▎| 4266/15000 [37:28<33:29,  5.34it/s, lr=0.000532, step_loss=0.006807/27/2023 18:22:18 - INFO - __main__ - train loss is 4.338037566980347\n",
      "Steps:  28%|▎| 4267/15000 [37:28<33:03,  5.41it/s, lr=0.000532, step_loss=0.161]07/27/2023 18:22:18 - INFO - __main__ - train loss is 4.393799038371071\n",
      "Steps:  28%|▎| 4268/15000 [37:28<32:45,  5.46it/s, lr=0.000532, step_loss=0.055807/27/2023 18:22:18 - INFO - __main__ - train loss is 4.611236722907051\n",
      "Steps:  28%|▎| 4269/15000 [37:28<32:32,  5.50it/s, lr=0.000532, step_loss=0.217]07/27/2023 18:22:18 - INFO - __main__ - train loss is 4.857398571213707\n",
      "Steps:  28%|▎| 4270/15000 [37:29<32:22,  5.52it/s, lr=0.000532, step_loss=0.246]07/27/2023 18:22:18 - INFO - __main__ - train loss is 5.041223199805245\n",
      "Steps:  28%|▎| 4271/15000 [37:29<32:16,  5.54it/s, lr=0.000532, step_loss=0.184]07/27/2023 18:22:19 - INFO - __main__ - train loss is 5.05626837327145\n",
      "Steps:  28%|▎| 4272/15000 [37:29<32:31,  5.50it/s, lr=0.000532, step_loss=0.015]07/27/2023 18:22:19 - INFO - __main__ - train loss is 5.077596025308594\n",
      "Steps:  28%|▎| 4273/15000 [37:29<32:42,  5.47it/s, lr=0.000532, step_loss=0.021307/27/2023 18:22:19 - INFO - __main__ - train loss is 5.382815675577149\n",
      "Steps:  28%|▎| 4274/15000 [37:29<32:31,  5.50it/s, lr=0.000533, step_loss=0.305]07/27/2023 18:22:19 - INFO - __main__ - train loss is 5.390946451341733\n",
      "Steps:  28%|▎| 4275/15000 [37:30<32:33,  5.49it/s, lr=0.000533, step_loss=0.008107/27/2023 18:22:19 - INFO - __main__ - train loss is 5.911536458646879\n",
      "Steps:  29%|▎| 4276/15000 [37:30<32:25,  5.51it/s, lr=0.000533, step_loss=0.521]07/27/2023 18:22:20 - INFO - __main__ - train loss is 6.081499520456418\n",
      "Steps:  29%|▌ | 4277/15000 [37:30<32:34,  5.49it/s, lr=0.000533, step_loss=0.17]07/27/2023 18:22:20 - INFO - __main__ - train loss is 6.101445767795667\n",
      "Steps:  29%|▎| 4278/15000 [37:30<32:41,  5.47it/s, lr=0.000533, step_loss=0.019907/27/2023 18:22:20 - INFO - __main__ - train loss is 6.105464255204424\n",
      "Steps:  29%|▎| 4279/15000 [37:30<32:30,  5.50it/s, lr=0.000533, step_loss=0.004007/27/2023 18:22:20 - INFO - __main__ - train loss is 6.111202547559515\n",
      "Steps:  29%|▎| 4280/15000 [37:30<32:22,  5.52it/s, lr=0.000533, step_loss=0.005707/27/2023 18:22:20 - INFO - __main__ - train loss is 6.315629089483991\n",
      "Steps:  29%|▎| 4281/15000 [37:31<32:34,  5.49it/s, lr=0.000534, step_loss=0.204]07/27/2023 18:22:20 - INFO - __main__ - train loss is 6.727696651825681\n",
      "Steps:  29%|▎| 4282/15000 [37:31<32:31,  5.49it/s, lr=0.000534, step_loss=0.412]07/27/2023 18:22:21 - INFO - __main__ - train loss is 6.989948773989454\n",
      "Steps:  29%|▎| 4283/15000 [37:31<32:45,  5.45it/s, lr=0.000534, step_loss=0.262]07/27/2023 18:22:21 - INFO - __main__ - train loss is 7.0038321514148265\n",
      "Steps:  29%|▎| 4284/15000 [37:31<32:50,  5.44it/s, lr=0.000534, step_loss=0.013907/27/2023 18:22:21 - INFO - __main__ - train loss is 7.240026776911691\n",
      "Steps:  29%|▎| 4285/15000 [37:31<32:39,  5.47it/s, lr=0.000534, step_loss=0.236]07/27/2023 18:22:21 - INFO - __main__ - train loss is 7.3939287413377315\n",
      "Steps:  29%|▎| 4286/15000 [37:32<32:30,  5.49it/s, lr=0.000534, step_loss=0.154]07/27/2023 18:22:21 - INFO - __main__ - train loss is 7.472152767004445\n",
      "Steps:  29%|▎| 4287/15000 [37:32<32:40,  5.46it/s, lr=0.000534, step_loss=0.078207/27/2023 18:22:22 - INFO - __main__ - train loss is 7.486168504925445\n",
      "Steps:  29%|▎| 4288/15000 [37:32<32:44,  5.45it/s, lr=0.000534, step_loss=0.014]07/27/2023 18:22:22 - INFO - __main__ - train loss is 7.498580429935828\n",
      "Steps:  29%|▎| 4289/15000 [37:32<32:49,  5.44it/s, lr=0.000535, step_loss=0.012407/27/2023 18:22:22 - INFO - __main__ - train loss is 7.513088695937768\n",
      "Steps:  29%|▎| 4290/15000 [37:32<32:51,  5.43it/s, lr=0.000535, step_loss=0.014507/27/2023 18:22:22 - INFO - __main__ - train loss is 8.29339861148037\n",
      "Steps:  29%|▌ | 4291/15000 [37:32<32:51,  5.43it/s, lr=0.000535, step_loss=0.78]07/27/2023 18:22:22 - INFO - __main__ - train loss is 8.401900924975052\n",
      "Steps:  29%|▎| 4292/15000 [37:33<32:34,  5.48it/s, lr=0.000535, step_loss=0.109]07/27/2023 18:22:22 - INFO - __main__ - train loss is 8.788209207588807\n",
      "Steps:  29%|▎| 4293/15000 [37:33<32:24,  5.51it/s, lr=0.000535, step_loss=0.386]07/27/2023 18:22:23 - INFO - __main__ - train loss is 8.927265919977799\n",
      "Steps:  29%|▎| 4294/15000 [37:33<32:17,  5.53it/s, lr=0.000535, step_loss=0.139]07/27/2023 18:22:23 - INFO - __main__ - train loss is 8.92881457542535\n",
      "Steps:  29%|▎| 4295/15000 [37:33<32:11,  5.54it/s, lr=0.000535, step_loss=0.001507/27/2023 18:22:23 - INFO - __main__ - train loss is 9.042446785024367\n",
      "Steps:  29%|▎| 4296/15000 [37:33<32:09,  5.55it/s, lr=0.000535, step_loss=0.114]07/27/2023 18:22:23 - INFO - __main__ - train loss is 9.046995114418678\n",
      "Steps:  29%|▎| 4297/15000 [37:34<32:06,  5.55it/s, lr=0.000535, step_loss=0.004507/27/2023 18:22:23 - INFO - __main__ - train loss is 9.106565598282032\n",
      "Steps:  29%|▎| 4298/15000 [37:34<32:04,  5.56it/s, lr=0.000536, step_loss=0.059607/27/2023 18:22:24 - INFO - __main__ - train loss is 9.132455451297574\n",
      "Steps:  29%|▎| 4299/15000 [37:34<32:03,  5.56it/s, lr=0.000536, step_loss=0.025907/27/2023 18:22:24 - INFO - __main__ - train loss is 9.136834142613225\n",
      "Steps:  29%|▎| 4300/15000 [37:34<32:01,  5.57it/s, lr=0.000536, step_loss=0.004307/27/2023 18:22:24 - INFO - __main__ - train loss is 9.155000926810317\n",
      "Steps:  29%|▎| 4301/15000 [37:34<32:00,  5.57it/s, lr=0.000536, step_loss=0.018207/27/2023 18:22:24 - INFO - __main__ - train loss is 9.483988465624861\n",
      "Steps:  29%|▎| 4302/15000 [37:34<32:01,  5.57it/s, lr=0.000536, step_loss=0.329]07/27/2023 18:22:24 - INFO - __main__ - train loss is 9.536472799140029\n",
      "Steps:  29%|▎| 4303/15000 [37:35<31:59,  5.57it/s, lr=0.000536, step_loss=0.052507/27/2023 18:22:24 - INFO - __main__ - train loss is 9.555361248436384\n",
      "Steps:  29%|▎| 4304/15000 [37:35<31:58,  5.58it/s, lr=0.000536, step_loss=0.018907/27/2023 18:22:25 - INFO - __main__ - train loss is 9.573905669036321\n",
      "Steps:  29%|▎| 4305/15000 [37:35<31:57,  5.58it/s, lr=0.000536, step_loss=0.018507/27/2023 18:22:25 - INFO - __main__ - train loss is 9.859827719512396\n",
      "Steps:  29%|▎| 4306/15000 [37:35<31:57,  5.58it/s, lr=0.000537, step_loss=0.286]07/27/2023 18:22:25 - INFO - __main__ - train loss is 9.864538756548427\n",
      "Steps:  29%|▎| 4307/15000 [37:35<32:11,  5.54it/s, lr=0.000537, step_loss=0.004707/27/2023 18:22:25 - INFO - __main__ - train loss is 10.03227463120129\n",
      "Steps:  29%|▎| 4308/15000 [37:35<32:07,  5.55it/s, lr=0.000537, step_loss=0.168]07/27/2023 18:22:25 - INFO - __main__ - train loss is 10.120012340485118\n",
      "Steps:  29%|▎| 4309/15000 [37:36<32:05,  5.55it/s, lr=0.000537, step_loss=0.087707/27/2023 18:22:26 - INFO - __main__ - train loss is 10.206454542814754\n",
      "Steps:  29%|▎| 4310/15000 [37:36<32:21,  5.51it/s, lr=0.000537, step_loss=0.086407/27/2023 18:22:26 - INFO - __main__ - train loss is 10.254770924686454\n",
      "Steps:  29%|▎| 4311/15000 [37:36<37:08,  4.80it/s, lr=0.000537, step_loss=0.048307/27/2023 18:22:26 - INFO - __main__ - train loss is 10.389925887226127\n",
      "Steps:  29%|▎| 4312/15000 [37:36<36:21,  4.90it/s, lr=0.000537, step_loss=0.135]07/27/2023 18:22:26 - INFO - __main__ - train loss is 10.393673584912904\n",
      "Steps:  29%|▎| 4313/15000 [37:37<35:44,  4.98it/s, lr=0.000538, step_loss=0.003707/27/2023 18:22:26 - INFO - __main__ - train loss is 10.77383218810428\n",
      "Steps:  29%|▌ | 4314/15000 [37:37<35:54,  4.96it/s, lr=0.000538, step_loss=0.38]07/27/2023 18:22:27 - INFO - __main__ - train loss is 10.805599168990739\n",
      "Steps:  29%|▎| 4315/15000 [37:37<35:06,  5.07it/s, lr=0.000538, step_loss=0.031807/27/2023 18:22:27 - INFO - __main__ - train loss is 10.816251551848836\n",
      "Steps:  29%|▎| 4316/15000 [37:37<34:09,  5.21it/s, lr=0.000538, step_loss=0.010707/27/2023 18:22:27 - INFO - __main__ - train loss is 10.852354487520643\n",
      "Steps:  29%|▎| 4317/15000 [37:37<33:33,  5.31it/s, lr=0.000538, step_loss=0.036107/27/2023 18:22:27 - INFO - __main__ - train loss is 10.994266202789731\n",
      "Steps:  29%|▎| 4318/15000 [37:37<33:26,  5.32it/s, lr=0.000538, step_loss=0.142]07/27/2023 18:22:27 - INFO - __main__ - train loss is 11.251053502899595\n",
      "Steps:  29%|▎| 4319/15000 [37:38<33:48,  5.27it/s, lr=0.000538, step_loss=0.257]07/27/2023 18:22:28 - INFO - __main__ - train loss is 11.257589633692987\n",
      "Steps:  29%|▎| 4320/15000 [37:38<33:31,  5.31it/s, lr=0.000538, step_loss=0.006507/27/2023 18:22:28 - INFO - __main__ - train loss is 11.261215841048397\n",
      "Steps:  29%|▎| 4321/15000 [37:38<33:15,  5.35it/s, lr=0.000539, step_loss=0.003607/27/2023 18:22:28 - INFO - __main__ - train loss is 11.54187188076321\n",
      "Steps:  29%|▎| 4322/15000 [37:38<33:04,  5.38it/s, lr=0.000539, step_loss=0.281]07/27/2023 18:22:28 - INFO - __main__ - train loss is 11.662466710084118\n",
      "Steps:  29%|▎| 4323/15000 [37:38<33:07,  5.37it/s, lr=0.000539, step_loss=0.121]07/27/2023 18:22:28 - INFO - __main__ - train loss is 11.674154030741192\n",
      "Steps:  29%|▎| 4324/15000 [37:39<32:59,  5.39it/s, lr=0.000539, step_loss=0.011707/27/2023 18:22:28 - INFO - __main__ - train loss is 11.67823904484976\n",
      "Steps:  29%|▎| 4325/15000 [37:39<32:56,  5.40it/s, lr=0.000539, step_loss=0.004007/27/2023 18:22:29 - INFO - __main__ - train loss is 11.699427361716516\n",
      "Steps:  29%|▎| 4326/15000 [37:39<32:58,  5.39it/s, lr=0.000539, step_loss=0.021207/27/2023 18:22:29 - INFO - __main__ - train loss is 11.975888664950617\n",
      "Steps:  29%|▎| 4327/15000 [37:39<32:53,  5.41it/s, lr=0.000539, step_loss=0.276]07/27/2023 18:22:29 - INFO - __main__ - train loss is 11.99760899238754\n",
      "Steps:  29%|▎| 4328/15000 [37:39<33:03,  5.38it/s, lr=0.000539, step_loss=0.021707/27/2023 18:22:29 - INFO - __main__ - train loss is 12.01313578162808\n",
      "Steps:  29%|▎| 4329/15000 [37:39<32:43,  5.43it/s, lr=0.000539, step_loss=0.015507/27/2023 18:22:29 - INFO - __main__ - train loss is 12.031589394551702\n",
      "Steps:  29%|▎| 4330/15000 [37:40<32:37,  5.45it/s, lr=0.00054, step_loss=0.0185]07/27/2023 18:22:30 - INFO - __main__ - train loss is 12.04251307353843\n",
      "Steps:  29%|▎| 4331/15000 [37:40<32:24,  5.49it/s, lr=0.00054, step_loss=0.0109]07/27/2023 18:22:30 - INFO - __main__ - train loss is 12.254213662003167\n",
      "Steps:  29%|▌ | 4332/15000 [37:40<32:14,  5.51it/s, lr=0.00054, step_loss=0.212]07/27/2023 18:22:30 - INFO - __main__ - train loss is 12.357345075462945\n",
      "Steps:  29%|▌ | 4333/15000 [37:40<32:07,  5.53it/s, lr=0.00054, step_loss=0.103]07/27/2023 18:22:30 - INFO - __main__ - train loss is 12.376320968498476\n",
      "Steps:  29%|▌ | 4334/15000 [37:40<32:03,  5.55it/s, lr=0.00054, step_loss=0.019]07/27/2023 18:22:30 - INFO - __main__ - train loss is 12.530592973460443\n",
      "Steps:  29%|▌ | 4335/15000 [37:41<32:00,  5.55it/s, lr=0.00054, step_loss=0.154]07/27/2023 18:22:30 - INFO - __main__ - train loss is 12.73716136359144\n",
      "Steps:  29%|▌ | 4336/15000 [37:41<31:58,  5.56it/s, lr=0.00054, step_loss=0.207]07/27/2023 18:22:31 - INFO - __main__ - train loss is 13.145426358212717\n",
      "Steps:  29%|▌ | 4337/15000 [37:41<31:56,  5.56it/s, lr=0.00054, step_loss=0.408]07/27/2023 18:22:31 - INFO - __main__ - train loss is 13.148597838473506\n",
      "Steps:  29%|▎| 4338/15000 [37:41<31:56,  5.56it/s, lr=0.000541, step_loss=0.003107/27/2023 18:22:31 - INFO - __main__ - train loss is 13.187938338262029\n",
      "Steps:  29%|▎| 4339/15000 [37:41<31:54,  5.57it/s, lr=0.000541, step_loss=0.039307/27/2023 18:22:31 - INFO - __main__ - train loss is 13.536890840274282\n",
      "Steps:  29%|▎| 4340/15000 [37:41<31:54,  5.57it/s, lr=0.000541, step_loss=0.349]07/27/2023 18:22:31 - INFO - __main__ - train loss is 13.542925796587951\n",
      "Steps:  29%|▎| 4341/15000 [37:42<31:53,  5.57it/s, lr=0.000541, step_loss=0.006007/27/2023 18:22:32 - INFO - __main__ - train loss is 13.633639029343612\n",
      "Steps:  29%|▎| 4342/15000 [37:42<31:53,  5.57it/s, lr=0.000541, step_loss=0.090707/27/2023 18:22:32 - INFO - __main__ - train loss is 13.645712213707156\n",
      "Steps:  29%|▎| 4343/15000 [37:42<31:53,  5.57it/s, lr=0.000541, step_loss=0.012107/27/2023 18:22:32 - INFO - __main__ - train loss is 13.700104734045453\n",
      "Steps:  29%|▎| 4344/15000 [37:42<31:52,  5.57it/s, lr=0.000541, step_loss=0.054407/27/2023 18:22:32 - INFO - __main__ - train loss is 13.731255548191257\n",
      "Steps:  29%|▎| 4345/15000 [37:42<31:51,  5.57it/s, lr=0.000541, step_loss=0.031207/27/2023 18:22:32 - INFO - __main__ - train loss is 14.046778278541751\n",
      "Steps:  29%|▎| 4346/15000 [37:43<31:52,  5.57it/s, lr=0.000542, step_loss=0.316]07/27/2023 18:22:32 - INFO - __main__ - train loss is 14.09102139819879\n",
      "Steps:  29%|▎| 4347/15000 [37:43<31:52,  5.57it/s, lr=0.000542, step_loss=0.044207/27/2023 18:22:33 - INFO - __main__ - train loss is 14.103202941012569\n",
      "Steps:  29%|▎| 4348/15000 [37:43<32:10,  5.52it/s, lr=0.000542, step_loss=0.012207/27/2023 18:22:33 - INFO - __main__ - train loss is 14.545552136492915\n",
      "Steps:  29%|▎| 4349/15000 [37:43<32:11,  5.52it/s, lr=0.000542, step_loss=0.442]07/27/2023 18:22:33 - INFO - __main__ - train loss is 14.550751506933011\n",
      "Steps:  29%|▎| 4350/15000 [37:43<32:05,  5.53it/s, lr=0.000542, step_loss=0.005207/27/2023 18:22:33 - INFO - __main__ - train loss is 14.646033331402577\n",
      "Steps:  29%|▎| 4351/15000 [37:43<32:16,  5.50it/s, lr=0.000542, step_loss=0.095307/27/2023 18:22:33 - INFO - __main__ - train loss is 15.170778795727529\n",
      "Steps:  29%|▎| 4352/15000 [37:44<32:26,  5.47it/s, lr=0.000542, step_loss=0.525]07/27/2023 18:22:34 - INFO - __main__ - train loss is 15.30123703146819\n",
      "Steps:  29%|▌ | 4353/15000 [37:44<32:39,  5.43it/s, lr=0.000543, step_loss=0.13]07/27/2023 18:22:34 - INFO - __main__ - train loss is 15.408177666016854\n",
      "Steps:  29%|▎| 4354/15000 [37:44<32:32,  5.45it/s, lr=0.000543, step_loss=0.107]07/27/2023 18:22:34 - INFO - __main__ - train loss is 15.41144909535069\n",
      "Steps:  29%|▎| 4355/15000 [37:44<32:37,  5.44it/s, lr=0.000543, step_loss=0.003207/27/2023 18:22:34 - INFO - __main__ - train loss is 15.677802225691266\n",
      "Steps:  29%|▎| 4356/15000 [37:44<32:47,  5.41it/s, lr=0.000543, step_loss=0.266]07/27/2023 18:22:34 - INFO - __main__ - train loss is 15.75966315541882\n",
      "Steps:  29%|▎| 4357/15000 [37:45<32:52,  5.40it/s, lr=0.000543, step_loss=0.081907/27/2023 18:22:34 - INFO - __main__ - train loss is 15.761189247830771\n",
      "Steps:  29%|▎| 4358/15000 [37:45<32:37,  5.44it/s, lr=0.000543, step_loss=0.001507/27/2023 18:22:35 - INFO - __main__ - train loss is 15.789658704190515\n",
      "Steps:  29%|▎| 4359/15000 [37:45<32:23,  5.48it/s, lr=0.000543, step_loss=0.028507/27/2023 18:22:35 - INFO - __main__ - train loss is 16.38613239803817\n",
      "Steps:  29%|▎| 4360/15000 [37:45<32:12,  5.51it/s, lr=0.000543, step_loss=0.596]07/27/2023 18:22:35 - INFO - __main__ - train loss is 16.635915303020738\n",
      "Steps:  29%|▌ | 4361/15000 [37:45<32:04,  5.53it/s, lr=0.000544, step_loss=0.25]07/27/2023 18:22:35 - INFO - __main__ - train loss is 16.793773257522844\n",
      "Steps:  29%|▎| 4362/15000 [37:45<31:59,  5.54it/s, lr=0.000544, step_loss=0.158]07/27/2023 18:22:35 - INFO - __main__ - train loss is 16.921951317577623\n",
      "Steps:  29%|▎| 4363/15000 [37:46<31:55,  5.55it/s, lr=0.000544, step_loss=0.128]07/27/2023 18:22:36 - INFO - __main__ - train loss is 16.947323886095546\n",
      "Steps:  29%|▎| 4364/15000 [37:46<31:53,  5.56it/s, lr=0.000544, step_loss=0.025407/27/2023 18:22:36 - INFO - __main__ - train loss is 16.9647264307132\n",
      "Steps:  29%|▎| 4365/15000 [37:46<31:54,  5.56it/s, lr=0.000544, step_loss=0.017407/27/2023 18:22:36 - INFO - __main__ - train loss is 17.148340222775005\n",
      "Steps:  29%|▎| 4366/15000 [37:46<31:52,  5.56it/s, lr=0.000544, step_loss=0.184]07/27/2023 18:22:36 - INFO - __main__ - train loss is 17.16550001257565\n",
      "Steps:  29%|▎| 4367/15000 [37:46<31:50,  5.56it/s, lr=0.000544, step_loss=0.017207/27/2023 18:22:36 - INFO - __main__ - train loss is 17.263343160389923\n",
      "Steps:  29%|▎| 4368/15000 [37:47<32:07,  5.52it/s, lr=0.000544, step_loss=0.097807/27/2023 18:22:36 - INFO - __main__ - train loss is 17.284947657375596\n",
      "Steps:  29%|▎| 4369/15000 [37:47<32:07,  5.52it/s, lr=0.000544, step_loss=0.021607/27/2023 18:22:37 - INFO - __main__ - train loss is 17.364148275344633\n",
      "Steps:  29%|▎| 4370/15000 [37:47<32:02,  5.53it/s, lr=0.000545, step_loss=0.079207/27/2023 18:22:37 - INFO - __main__ - train loss is 17.366863804520108\n",
      "Steps:  29%|▎| 4371/15000 [37:47<31:57,  5.54it/s, lr=0.000545, step_loss=0.002707/27/2023 18:22:37 - INFO - __main__ - train loss is 17.534842657507397\n",
      "Steps:  29%|▎| 4372/15000 [37:47<32:12,  5.50it/s, lr=0.000545, step_loss=0.168]07/27/2023 18:22:37 - INFO - __main__ - train loss is 17.58139790093992\n",
      "Steps:  29%|▎| 4373/15000 [37:47<32:14,  5.49it/s, lr=0.000545, step_loss=0.046607/27/2023 18:22:37 - INFO - __main__ - train loss is 17.935607979656197\n",
      "Steps:  29%|▎| 4374/15000 [37:48<32:06,  5.52it/s, lr=0.000545, step_loss=0.354]07/27/2023 18:22:38 - INFO - __main__ - train loss is 17.945165848941542\n",
      "Steps:  29%|▎| 4375/15000 [37:48<32:00,  5.53it/s, lr=0.000545, step_loss=0.009507/27/2023 18:22:38 - INFO - __main__ - train loss is 17.949598814942874\n",
      "Steps:  29%|▎| 4376/15000 [37:48<31:56,  5.54it/s, lr=0.000545, step_loss=0.004407/27/2023 18:22:38 - INFO - __main__ - train loss is 18.010628964402713\n",
      "Steps:  29%|▎| 4377/15000 [37:48<31:58,  5.54it/s, lr=0.000545, step_loss=0.061]07/27/2023 18:22:38 - INFO - __main__ - train loss is 18.08427229116205\n",
      "Steps:  29%|▎| 4378/15000 [37:48<31:55,  5.55it/s, lr=0.000546, step_loss=0.073607/27/2023 18:22:38 - INFO - __main__ - train loss is 18.169562171795405\n",
      "Steps:  29%|▎| 4379/15000 [37:49<31:54,  5.55it/s, lr=0.000546, step_loss=0.085307/27/2023 18:22:38 - INFO - __main__ - train loss is 18.260448377230205\n",
      "Steps:  29%|▎| 4380/15000 [37:49<31:52,  5.55it/s, lr=0.000546, step_loss=0.090907/27/2023 18:22:39 - INFO - __main__ - train loss is 18.34997105190996\n",
      "Steps:  29%|▎| 4381/15000 [37:49<31:50,  5.56it/s, lr=0.000546, step_loss=0.089507/27/2023 18:22:39 - INFO - __main__ - train loss is 18.52983754465822\n",
      "Steps:  29%|▌ | 4382/15000 [37:49<31:48,  5.56it/s, lr=0.000546, step_loss=0.18]07/27/2023 18:22:39 - INFO - __main__ - train loss is 18.639173116185702\n",
      "Steps:  29%|▎| 4383/15000 [37:49<31:46,  5.57it/s, lr=0.000546, step_loss=0.109]07/27/2023 18:22:39 - INFO - __main__ - train loss is 19.291320588090457\n",
      "Steps:  29%|▎| 4384/15000 [37:49<31:45,  5.57it/s, lr=0.000546, step_loss=0.652]07/27/2023 18:22:39 - INFO - __main__ - train loss is 19.41561316291336\n",
      "Steps:  29%|▎| 4385/15000 [37:50<31:44,  5.57it/s, lr=0.000547, step_loss=0.124]07/27/2023 18:22:39 - INFO - __main__ - train loss is 19.50018706510309\n",
      "Steps:  29%|▎| 4386/15000 [37:50<31:44,  5.57it/s, lr=0.000547, step_loss=0.084607/27/2023 18:22:40 - INFO - __main__ - train loss is 19.688156913616695\n",
      "Steps:  29%|▎| 4387/15000 [37:50<31:43,  5.58it/s, lr=0.000547, step_loss=0.188]07/27/2023 18:22:40 - INFO - __main__ - train loss is 20.137802254059352\n",
      "Steps:  29%|▌ | 4388/15000 [37:50<31:43,  5.58it/s, lr=0.000547, step_loss=0.45]07/27/2023 18:22:40 - INFO - __main__ - train loss is 20.13957311527338\n",
      "Steps:  29%|▎| 4389/15000 [37:50<31:43,  5.57it/s, lr=0.000547, step_loss=0.001707/27/2023 18:22:40 - INFO - __main__ - train loss is 20.141367936390452\n",
      "Steps:  29%|▎| 4390/15000 [37:51<31:45,  5.57it/s, lr=0.000547, step_loss=0.001707/27/2023 18:22:40 - INFO - __main__ - train loss is 20.259420731919818\n",
      "Steps:  29%|▎| 4391/15000 [37:51<31:44,  5.57it/s, lr=0.000547, step_loss=0.118]07/27/2023 18:22:41 - INFO - __main__ - train loss is 20.29045406531077\n",
      "Steps:  29%|▎| 4392/15000 [37:51<31:44,  5.57it/s, lr=0.000547, step_loss=0.031]07/27/2023 18:22:41 - INFO - __main__ - train loss is 20.83799234579783\n",
      "Steps:  29%|▎| 4393/15000 [37:51<31:44,  5.57it/s, lr=0.000548, step_loss=0.548]07/27/2023 18:22:41 - INFO - __main__ - train loss is 20.849722565035336\n",
      "Steps:  29%|▎| 4394/15000 [37:51<31:43,  5.57it/s, lr=0.000548, step_loss=0.011707/27/2023 18:22:41 - INFO - __main__ - train loss is 21.112307281116955\n",
      "Steps:  29%|▎| 4395/15000 [37:51<31:42,  5.57it/s, lr=0.000548, step_loss=0.263]07/27/2023 18:22:41 - INFO - __main__ - train loss is 21.129046269576065\n",
      "Steps:  29%|▎| 4396/15000 [37:52<31:42,  5.57it/s, lr=0.000548, step_loss=0.016707/27/2023 18:22:41 - INFO - __main__ - train loss is 21.138550237636082\n",
      "Steps:  29%|▎| 4397/15000 [37:52<31:42,  5.57it/s, lr=0.000548, step_loss=0.009507/27/2023 18:22:42 - INFO - __main__ - train loss is 21.631116256932728\n",
      "Steps:  29%|▎| 4398/15000 [37:52<31:41,  5.57it/s, lr=0.000548, step_loss=0.493]07/27/2023 18:22:42 - INFO - __main__ - train loss is 21.679779962520115\n",
      "Steps:  29%|▎| 4399/15000 [37:52<31:41,  5.57it/s, lr=0.000548, step_loss=0.048707/27/2023 18:22:42 - INFO - __main__ - train loss is 21.68537979980465\n",
      "Steps:  29%|▎| 4400/15000 [37:52<31:42,  5.57it/s, lr=0.000548, step_loss=0.005607/27/2023 18:22:42 - INFO - __main__ - train loss is 21.724089473835193\n",
      "Steps:  29%|▎| 4401/15000 [37:52<31:42,  5.57it/s, lr=0.000549, step_loss=0.038707/27/2023 18:22:42 - INFO - __main__ - train loss is 22.05201536451932\n",
      "Steps:  29%|▎| 4402/15000 [37:53<31:42,  5.57it/s, lr=0.000549, step_loss=0.328]07/27/2023 18:22:43 - INFO - __main__ - train loss is 22.098080579540692\n",
      "Steps:  29%|▎| 4403/15000 [37:53<31:43,  5.57it/s, lr=0.000549, step_loss=0.046107/27/2023 18:22:43 - INFO - __main__ - train loss is 22.233499888679944\n",
      "Steps:  29%|▎| 4404/15000 [37:53<31:43,  5.57it/s, lr=0.000549, step_loss=0.135]07/27/2023 18:22:43 - INFO - __main__ - train loss is 22.251452844939195\n",
      "Steps:  29%|▎| 4405/15000 [37:53<31:42,  5.57it/s, lr=0.000549, step_loss=0.018]07/27/2023 18:22:43 - INFO - __main__ - train loss is 22.429665904841386\n",
      "Steps:  29%|▎| 4406/15000 [37:53<32:00,  5.52it/s, lr=0.000549, step_loss=0.178]07/27/2023 18:22:43 - INFO - __main__ - train loss is 22.60087020357605\n",
      "Steps:  29%|▎| 4407/15000 [37:54<32:09,  5.49it/s, lr=0.000549, step_loss=0.171]07/27/2023 18:22:43 - INFO - __main__ - train loss is 22.932302486500703\n",
      "Steps:  29%|▎| 4408/15000 [37:54<32:35,  5.42it/s, lr=0.000549, step_loss=0.331]07/27/2023 18:22:44 - INFO - __main__ - train loss is 23.02214258571621\n",
      "Steps:  29%|▎| 4409/15000 [37:54<32:38,  5.41it/s, lr=0.000549, step_loss=0.089807/27/2023 18:22:44 - INFO - __main__ - train loss is 23.103090223274194\n",
      "Steps:  29%|▎| 4410/15000 [37:54<32:21,  5.45it/s, lr=0.00055, step_loss=0.0809]07/27/2023 18:22:44 - INFO - __main__ - train loss is 23.124344362295233\n",
      "Steps:  29%|▎| 4411/15000 [37:54<32:09,  5.49it/s, lr=0.00055, step_loss=0.0213]07/27/2023 18:22:44 - INFO - __main__ - train loss is 23.289577706134878\n",
      "Steps:  29%|▌ | 4412/15000 [37:54<32:01,  5.51it/s, lr=0.00055, step_loss=0.165]07/27/2023 18:22:44 - INFO - __main__ - train loss is 23.3660416736966\n",
      "Steps:  29%|▎| 4413/15000 [37:55<31:56,  5.53it/s, lr=0.00055, step_loss=0.0765]07/27/2023 18:22:45 - INFO - __main__ - train loss is 23.518383754766546\n",
      "Steps:  29%|▌ | 4414/15000 [37:55<32:09,  5.49it/s, lr=0.00055, step_loss=0.152]07/27/2023 18:22:45 - INFO - __main__ - train loss is 23.731598256505094\n",
      "Steps:  29%|▌ | 4415/15000 [37:55<31:59,  5.52it/s, lr=0.00055, step_loss=0.213]07/27/2023 18:22:45 - INFO - __main__ - train loss is 23.7949495598441\n",
      "Steps:  29%|▎| 4416/15000 [37:55<31:53,  5.53it/s, lr=0.00055, step_loss=0.0634]07/27/2023 18:22:45 - INFO - __main__ - train loss is 23.84044172463473\n",
      "Steps:  29%|▎| 4417/15000 [37:55<31:49,  5.54it/s, lr=0.00055, step_loss=0.0455]07/27/2023 18:22:45 - INFO - __main__ - train loss is 24.032586863613687\n",
      "Steps:  29%|▎| 4418/15000 [37:56<31:45,  5.55it/s, lr=0.000551, step_loss=0.192]07/27/2023 18:22:45 - INFO - __main__ - train loss is 24.254374614334665\n",
      "Steps:  29%|▎| 4419/15000 [37:56<31:42,  5.56it/s, lr=0.000551, step_loss=0.222]07/27/2023 18:22:46 - INFO - __main__ - train loss is 24.25649231800344\n",
      "Steps:  29%|▎| 4420/15000 [37:56<31:41,  5.57it/s, lr=0.000551, step_loss=0.002107/27/2023 18:22:46 - INFO - __main__ - train loss is 24.332218529074453\n",
      "Steps:  29%|▎| 4421/15000 [37:56<31:39,  5.57it/s, lr=0.000551, step_loss=0.075707/27/2023 18:22:46 - INFO - __main__ - train loss is 24.58298373350408\n",
      "Steps:  29%|▎| 4422/15000 [37:56<31:38,  5.57it/s, lr=0.000551, step_loss=0.251]07/27/2023 18:22:46 - INFO - __main__ - train loss is 24.59752679837402\n",
      "Steps:  29%|▎| 4423/15000 [37:56<31:37,  5.58it/s, lr=0.000551, step_loss=0.014507/27/2023 18:22:46 - INFO - __main__ - train loss is 24.606533700949512\n",
      "Steps:  29%|▎| 4424/15000 [37:57<31:36,  5.58it/s, lr=0.000551, step_loss=0.009007/27/2023 18:22:47 - INFO - __main__ - train loss is 24.790576661354862\n",
      "Steps:  30%|▎| 4425/15000 [37:57<31:36,  5.58it/s, lr=0.000552, step_loss=0.184]07/27/2023 18:22:47 - INFO - __main__ - train loss is 24.79600630083587\n",
      "Steps:  30%|▎| 4426/15000 [37:57<31:36,  5.58it/s, lr=0.000552, step_loss=0.005407/27/2023 18:22:47 - INFO - __main__ - train loss is 24.80373878858518\n",
      "Steps:  30%|▎| 4427/15000 [37:57<31:35,  5.58it/s, lr=0.000552, step_loss=0.007707/27/2023 18:22:47 - INFO - __main__ - train loss is 24.86306471086573\n",
      "Steps:  30%|▎| 4428/15000 [37:57<31:36,  5.57it/s, lr=0.000552, step_loss=0.059307/27/2023 18:22:47 - INFO - __main__ - train loss is 25.044962559710257\n",
      "Steps:  30%|▎| 4429/15000 [37:58<31:36,  5.58it/s, lr=0.000552, step_loss=0.182]07/27/2023 18:22:47 - INFO - __main__ - train loss is 25.074629899929278\n",
      "Steps:  30%|▎| 4430/15000 [37:58<31:36,  5.57it/s, lr=0.000552, step_loss=0.029707/27/2023 18:22:48 - INFO - __main__ - train loss is 25.07642200065311\n",
      "Steps:  30%|▎| 4431/15000 [37:58<31:36,  5.57it/s, lr=0.000552, step_loss=0.001707/27/2023 18:22:48 - INFO - __main__ - train loss is 25.08450933394488\n",
      "Steps:  30%|▎| 4432/15000 [37:58<31:36,  5.57it/s, lr=0.000552, step_loss=0.008007/27/2023 18:22:48 - INFO - __main__ - train loss is 25.25496803817805\n",
      "Steps:  30%|▌ | 4433/15000 [37:58<31:36,  5.57it/s, lr=0.000553, step_loss=0.17]07/27/2023 18:22:48 - INFO - __main__ - train loss is 25.324889039970003\n",
      "Steps:  30%|▎| 4434/15000 [37:58<31:36,  5.57it/s, lr=0.000553, step_loss=0.069907/27/2023 18:22:48 - INFO - __main__ - train loss is 25.383635213947855\n",
      "Steps:  30%|▎| 4435/15000 [37:59<31:35,  5.57it/s, lr=0.000553, step_loss=0.058707/27/2023 18:22:48 - INFO - __main__ - train loss is 25.386008839239366\n",
      "Steps:  30%|▎| 4436/15000 [37:59<31:36,  5.57it/s, lr=0.000553, step_loss=0.002307/27/2023 18:22:49 - INFO - __main__ - train loss is 25.823451499571092\n",
      "Steps:  30%|▎| 4437/15000 [37:59<31:36,  5.57it/s, lr=0.000553, step_loss=0.437]07/27/2023 18:22:49 - INFO - __main__ - train loss is 26.023584659327753\n",
      "Steps:  30%|▉  | 4438/15000 [37:59<31:35,  5.57it/s, lr=0.000553, step_loss=0.2]07/27/2023 18:22:49 - INFO - __main__ - train loss is 26.147740188171156\n",
      "Steps:  30%|▎| 4439/15000 [37:59<31:34,  5.57it/s, lr=0.000553, step_loss=0.124]07/27/2023 18:22:49 - INFO - __main__ - train loss is 26.506550255347975\n",
      "Steps:  30%|▎| 4440/15000 [38:00<31:34,  5.57it/s, lr=0.000553, step_loss=0.359]07/27/2023 18:22:49 - INFO - __main__ - train loss is 26.51333305251319\n",
      "Steps:  30%|▎| 4441/15000 [38:00<31:35,  5.57it/s, lr=0.000553, step_loss=0.006707/27/2023 18:22:50 - INFO - __main__ - train loss is 26.52800578076858\n",
      "Steps:  30%|▎| 4442/15000 [38:00<31:36,  5.57it/s, lr=0.000554, step_loss=0.014707/27/2023 18:22:50 - INFO - __main__ - train loss is 26.714993106317706\n",
      "Steps:  30%|▎| 4443/15000 [38:00<31:36,  5.57it/s, lr=0.000554, step_loss=0.187]07/27/2023 18:22:50 - INFO - __main__ - train loss is 26.726566559751518\n",
      "Steps:  30%|▎| 4444/15000 [38:00<31:37,  5.56it/s, lr=0.000554, step_loss=0.011607/27/2023 18:22:50 - INFO - __main__ - train loss is 26.988752490957268\n",
      "Steps:  30%|▎| 4445/15000 [38:00<31:35,  5.57it/s, lr=0.000554, step_loss=0.262]07/27/2023 18:22:50 - INFO - __main__ - train loss is 27.310915595968254\n",
      "Steps:  30%|▎| 4446/15000 [38:01<31:35,  5.57it/s, lr=0.000554, step_loss=0.322]07/27/2023 18:22:50 - INFO - __main__ - train loss is 27.360848969896324\n",
      "Steps:  30%|▎| 4447/15000 [38:01<31:34,  5.57it/s, lr=0.000554, step_loss=0.049907/27/2023 18:22:51 - INFO - __main__ - train loss is 27.428777775843628\n",
      "Steps:  30%|▎| 4448/15000 [38:01<31:33,  5.57it/s, lr=0.000554, step_loss=0.067907/27/2023 18:22:51 - INFO - __main__ - train loss is 27.430969786481\n",
      "Steps:  30%|▎| 4449/15000 [38:01<31:33,  5.57it/s, lr=0.000554, step_loss=0.002107/27/2023 18:22:51 - INFO - __main__ - train loss is 27.46548011584673\n",
      "Steps:  30%|▎| 4450/15000 [38:01<31:33,  5.57it/s, lr=0.000555, step_loss=0.034507/27/2023 18:22:51 - INFO - __main__ - train loss is 27.474332229816355\n",
      "Steps:  30%|▎| 4451/15000 [38:01<31:34,  5.57it/s, lr=0.000555, step_loss=0.008807/27/2023 18:22:51 - INFO - __main__ - train loss is 27.496200391673483\n",
      "Steps:  30%|▎| 4452/15000 [38:02<31:33,  5.57it/s, lr=0.000555, step_loss=0.021907/27/2023 18:22:52 - INFO - __main__ - train loss is 27.582053893827833\n",
      "Steps:  30%|▎| 4453/15000 [38:02<31:32,  5.57it/s, lr=0.000555, step_loss=0.085907/27/2023 18:22:52 - INFO - __main__ - train loss is 27.863515192293562\n",
      "Steps:  30%|▎| 4454/15000 [38:02<31:32,  5.57it/s, lr=0.000555, step_loss=0.281]07/27/2023 18:22:52 - INFO - __main__ - train loss is 27.986514808260836\n",
      "Steps:  30%|▎| 4455/15000 [38:02<31:31,  5.57it/s, lr=0.000555, step_loss=0.123]07/27/2023 18:22:52 - INFO - __main__ - train loss is 28.05039868655149\n",
      "Steps:  30%|▎| 4456/15000 [38:02<31:31,  5.57it/s, lr=0.000555, step_loss=0.063907/27/2023 18:22:52 - INFO - __main__ - train loss is 28.054524395265616\n",
      "Steps:  30%|▎| 4457/15000 [38:03<31:31,  5.57it/s, lr=0.000556, step_loss=0.004107/27/2023 18:22:52 - INFO - __main__ - train loss is 28.056912029976957\n",
      "Steps:  30%|▎| 4458/15000 [38:03<31:31,  5.57it/s, lr=0.000556, step_loss=0.002307/27/2023 18:22:53 - INFO - __main__ - train loss is 28.05798010423314\n",
      "Steps:  30%|▎| 4459/15000 [38:03<31:30,  5.58it/s, lr=0.000556, step_loss=0.001007/27/2023 18:22:53 - INFO - __main__ - train loss is 28.29964114620816\n",
      "Steps:  30%|▎| 4460/15000 [38:03<31:29,  5.58it/s, lr=0.000556, step_loss=0.242]07/27/2023 18:22:53 - INFO - __main__ - train loss is 28.319248980726115\n",
      "Steps:  30%|▎| 4461/15000 [38:03<31:29,  5.58it/s, lr=0.000556, step_loss=0.019607/27/2023 18:22:53 - INFO - __main__ - train loss is 28.354109558160417\n",
      "Steps:  30%|▎| 4462/15000 [38:03<31:28,  5.58it/s, lr=0.000556, step_loss=0.034907/27/2023 18:22:53 - INFO - __main__ - train loss is 28.355751913855784\n",
      "Steps:  30%|▎| 4463/15000 [38:04<31:28,  5.58it/s, lr=0.000556, step_loss=0.001607/27/2023 18:22:54 - INFO - __main__ - train loss is 28.74582792527508\n",
      "Steps:  30%|▌ | 4464/15000 [38:04<31:28,  5.58it/s, lr=0.000556, step_loss=0.39]07/27/2023 18:22:54 - INFO - __main__ - train loss is 28.787240647594444\n",
      "Steps:  30%|▎| 4465/15000 [38:04<31:29,  5.58it/s, lr=0.000557, step_loss=0.041407/27/2023 18:22:54 - INFO - __main__ - train loss is 28.87752356461715\n",
      "Steps:  30%|▎| 4466/15000 [38:04<31:30,  5.57it/s, lr=0.000557, step_loss=0.090307/27/2023 18:22:54 - INFO - __main__ - train loss is 28.883356789010577\n",
      "Steps:  30%|▎| 4467/15000 [38:04<31:36,  5.55it/s, lr=0.000557, step_loss=0.005807/27/2023 18:22:54 - INFO - __main__ - train loss is 28.930415520328097\n",
      "Steps:  30%|▎| 4468/15000 [38:05<31:33,  5.56it/s, lr=0.000557, step_loss=0.047107/27/2023 18:22:54 - INFO - __main__ - train loss is 28.961914541083388\n",
      "Steps:  30%|▎| 4469/15000 [38:05<31:32,  5.56it/s, lr=0.000557, step_loss=0.031507/27/2023 18:22:55 - INFO - __main__ - train loss is 29.156522156554274\n",
      "Steps:  30%|▎| 4470/15000 [38:05<31:31,  5.57it/s, lr=0.000557, step_loss=0.195]07/27/2023 18:22:55 - INFO - __main__ - train loss is 29.44102317269426\n",
      "Steps:  30%|▎| 4471/15000 [38:05<31:32,  5.56it/s, lr=0.000557, step_loss=0.285]07/27/2023 18:22:55 - INFO - __main__ - train loss is 29.552309827762656\n",
      "Steps:  30%|▎| 4472/15000 [38:05<31:32,  5.56it/s, lr=0.000557, step_loss=0.111]07/27/2023 18:22:55 - INFO - __main__ - train loss is 29.823595570283942\n",
      "Steps:  30%|▎| 4473/15000 [38:05<31:30,  5.57it/s, lr=0.000558, step_loss=0.271]07/27/2023 18:22:55 - INFO - __main__ - train loss is 30.352934526163153\n",
      "Steps:  30%|▎| 4474/15000 [38:06<31:30,  5.57it/s, lr=0.000558, step_loss=0.529]07/27/2023 18:22:55 - INFO - __main__ - train loss is 30.71620701428037\n",
      "Steps:  30%|▎| 4475/15000 [38:06<31:28,  5.57it/s, lr=0.000558, step_loss=0.363]07/27/2023 18:22:56 - INFO - __main__ - train loss is 30.730580994742922\n",
      "Steps:  30%|▎| 4476/15000 [38:06<31:28,  5.57it/s, lr=0.000558, step_loss=0.014407/27/2023 18:22:56 - INFO - __main__ - train loss is 30.751209748792462\n",
      "Steps:  30%|▎| 4477/15000 [38:06<31:29,  5.57it/s, lr=0.000558, step_loss=0.020607/27/2023 18:22:56 - INFO - __main__ - train loss is 30.755097906454466\n",
      "Steps:  30%|▎| 4478/15000 [38:06<31:29,  5.57it/s, lr=0.000558, step_loss=0.003807/27/2023 18:22:56 - INFO - __main__ - train loss is 30.968436192139052\n",
      "Steps:  30%|▎| 4479/15000 [38:07<31:29,  5.57it/s, lr=0.000558, step_loss=0.213]07/27/2023 18:22:56 - INFO - __main__ - train loss is 30.974622439011\n",
      "Steps:  30%|▎| 4480/15000 [38:07<31:28,  5.57it/s, lr=0.000558, step_loss=0.006107/27/2023 18:22:57 - INFO - __main__ - train loss is 31.449256937368773\n",
      "Steps:  30%|▎| 4481/15000 [38:07<31:28,  5.57it/s, lr=0.000558, step_loss=0.475]07/27/2023 18:22:57 - INFO - __main__ - train loss is 31.452399933128618\n",
      "Steps:  30%|▎| 4482/15000 [38:07<31:28,  5.57it/s, lr=0.000559, step_loss=0.003107/27/2023 18:22:57 - INFO - __main__ - train loss is 31.55155152955558\n",
      "Steps:  30%|▎| 4483/15000 [38:07<31:28,  5.57it/s, lr=0.000559, step_loss=0.099207/27/2023 18:22:57 - INFO - __main__ - train loss is 32.003752806573175\n",
      "Steps:  30%|▎| 4484/15000 [38:07<31:28,  5.57it/s, lr=0.000559, step_loss=0.452]07/27/2023 18:22:57 - INFO - __main__ - train loss is 32.29102984943893\n",
      "Steps:  30%|▎| 4485/15000 [38:08<31:29,  5.56it/s, lr=0.000559, step_loss=0.287]07/27/2023 18:22:57 - INFO - __main__ - train loss is 32.296004143427126\n",
      "Steps:  30%|▎| 4486/15000 [38:08<31:28,  5.57it/s, lr=0.000559, step_loss=0.004907/27/2023 18:22:58 - INFO - __main__ - train loss is 32.323135190526955\n",
      "Steps:  30%|▎| 4487/15000 [38:08<31:26,  5.57it/s, lr=0.000559, step_loss=0.027107/27/2023 18:22:58 - INFO - __main__ - train loss is 32.82682096294593\n",
      "Steps:  30%|▎| 4488/15000 [38:08<31:26,  5.57it/s, lr=0.000559, step_loss=0.504]07/27/2023 18:22:58 - INFO - __main__ - train loss is 32.831392944208346\n",
      "Steps:  30%|▎| 4489/15000 [38:08<31:26,  5.57it/s, lr=0.000559, step_loss=0.004507/27/2023 18:22:58 - INFO - __main__ - train loss is 32.97517326509114\n",
      "Steps:  30%|▌ | 4490/15000 [38:08<31:27,  5.57it/s, lr=0.00056, step_loss=0.144]07/27/2023 18:22:58 - INFO - __main__ - train loss is 33.04154003446456\n",
      "Steps:  30%|▎| 4491/15000 [38:09<31:29,  5.56it/s, lr=0.00056, step_loss=0.0664]07/27/2023 18:22:59 - INFO - __main__ - train loss is 33.18647340720054\n",
      "Steps:  30%|▌ | 4492/15000 [38:09<31:29,  5.56it/s, lr=0.00056, step_loss=0.145]07/27/2023 18:22:59 - INFO - __main__ - train loss is 33.42558050935622\n",
      "Steps:  30%|▌ | 4493/15000 [38:09<31:28,  5.56it/s, lr=0.00056, step_loss=0.239]07/27/2023 18:22:59 - INFO - __main__ - train loss is 33.58765343611594\n",
      "Steps:  30%|▌ | 4494/15000 [38:09<31:29,  5.56it/s, lr=0.00056, step_loss=0.162]07/27/2023 18:22:59 - INFO - __main__ - train loss is 33.960838504484855\n",
      "Steps:  30%|▌ | 4495/15000 [38:09<31:28,  5.56it/s, lr=0.00056, step_loss=0.373]07/27/2023 18:22:59 - INFO - __main__ - train loss is 34.07824122195598\n",
      "Steps:  30%|▌ | 4496/15000 [38:10<31:27,  5.57it/s, lr=0.00056, step_loss=0.117]07/27/2023 18:22:59 - INFO - __main__ - train loss is 34.080560195608996\n",
      "Steps:  30%|▎| 4497/15000 [38:10<31:28,  5.56it/s, lr=0.000561, step_loss=0.002307/27/2023 18:23:00 - INFO - __main__ - train loss is 34.19689575152006\n",
      "Steps:  30%|▎| 4498/15000 [38:10<31:28,  5.56it/s, lr=0.000561, step_loss=0.116]07/27/2023 18:23:00 - INFO - __main__ - train loss is 34.46400803641882\n",
      "Steps:  30%|▎| 4499/15000 [38:10<31:32,  5.55it/s, lr=0.000561, step_loss=0.267]07/27/2023 18:23:00 - INFO - __main__ - train loss is 34.46864023420494\n",
      "Steps:  30%|▎| 4500/15000 [38:10<31:29,  5.56it/s, lr=0.000561, step_loss=0.267]07/27/2023 18:23:00 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-4500\n",
      "07/27/2023 18:23:00 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:23:00,575] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:23:00,579] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-4500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:23:00,579] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-4500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:23:00,586] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-4500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:23:00,586] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-4500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:23:00,593] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-4500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:23:00,593] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-4500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:23:00,593] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:23:00 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-4500/pytorch_model\n",
      "07/27/2023 18:23:00 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-4500/scheduler.bin\n",
      "07/27/2023 18:23:00 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-4500/random_states_0.pkl\n",
      "07/27/2023 18:23:00 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-4500\n",
      "Steps:  30%|▎| 4500/15000 [38:10<31:29,  5.56it/s, lr=0.000561, step_loss=0.004607/27/2023 18:23:00 - INFO - __main__ - train loss is 34.47323500632774\n",
      "Steps:  30%|▎| 4501/15000 [38:10<32:29,  5.38it/s, lr=0.000561, step_loss=0.004507/27/2023 18:23:00 - INFO - __main__ - train loss is 34.47476515697781\n",
      "Steps:  30%|▎| 4502/15000 [38:11<32:09,  5.44it/s, lr=0.000561, step_loss=0.001507/27/2023 18:23:01 - INFO - __main__ - train loss is 34.50934949296061\n",
      "Steps:  30%|▎| 4503/15000 [38:11<31:55,  5.48it/s, lr=0.000561, step_loss=0.034607/27/2023 18:23:01 - INFO - __main__ - train loss is 34.523457800620236\n",
      "Steps:  30%|▎| 4504/15000 [38:11<31:46,  5.51it/s, lr=0.000561, step_loss=0.014107/27/2023 18:23:01 - INFO - __main__ - train loss is 34.527135413256474\n",
      "Steps:  30%|▎| 4505/15000 [38:11<31:38,  5.53it/s, lr=0.000562, step_loss=0.003607/27/2023 18:23:01 - INFO - __main__ - train loss is 34.73551417526323\n",
      "Steps:  30%|▎| 4506/15000 [38:11<31:34,  5.54it/s, lr=0.000562, step_loss=0.208]07/27/2023 18:23:01 - INFO - __main__ - train loss is 34.74750335898716\n",
      "Steps:  30%|▎| 4507/15000 [38:12<31:31,  5.55it/s, lr=0.000562, step_loss=0.012]07/27/2023 18:23:01 - INFO - __main__ - train loss is 34.9718084075721\n",
      "Steps:  30%|▎| 4508/15000 [38:12<31:29,  5.55it/s, lr=0.000562, step_loss=0.224]07/27/2023 18:23:02 - INFO - __main__ - train loss is 35.08246568974573\n",
      "Steps:  30%|▎| 4509/15000 [38:12<31:26,  5.56it/s, lr=0.000562, step_loss=0.111]07/27/2023 18:23:02 - INFO - __main__ - train loss is 35.10889470030088\n",
      "Steps:  30%|▎| 4510/15000 [38:12<31:24,  5.57it/s, lr=0.000562, step_loss=0.026407/27/2023 18:23:02 - INFO - __main__ - train loss is 35.210587935638614\n",
      "Steps:  30%|▎| 4511/15000 [38:12<31:24,  5.57it/s, lr=0.000562, step_loss=0.102]07/27/2023 18:23:02 - INFO - __main__ - train loss is 35.28580831189174\n",
      "Steps:  30%|▎| 4512/15000 [38:12<31:26,  5.56it/s, lr=0.000562, step_loss=0.075207/27/2023 18:23:02 - INFO - __main__ - train loss is 35.893904494238086\n",
      "Steps:  30%|▎| 4513/15000 [38:13<31:24,  5.57it/s, lr=0.000563, step_loss=0.608]07/27/2023 18:23:03 - INFO - __main__ - train loss is 35.90564479504246\n",
      "Steps:  30%|▎| 4514/15000 [38:13<31:22,  5.57it/s, lr=0.000563, step_loss=0.011707/27/2023 18:23:03 - INFO - __main__ - train loss is 35.907593732350506\n",
      "Steps:  30%|▎| 4515/15000 [38:13<31:23,  5.57it/s, lr=0.000563, step_loss=0.001907/27/2023 18:23:03 - INFO - __main__ - train loss is 35.979486276977696\n",
      "Steps:  30%|▎| 4516/15000 [38:13<31:25,  5.56it/s, lr=0.000563, step_loss=0.071907/27/2023 18:23:03 - INFO - __main__ - train loss is 36.38024901377503\n",
      "Steps:  30%|▎| 4517/15000 [38:13<31:24,  5.56it/s, lr=0.000563, step_loss=0.401]07/27/2023 18:23:03 - INFO - __main__ - train loss is 36.46382447856013\n",
      "Steps:  30%|▎| 4518/15000 [38:14<31:22,  5.57it/s, lr=0.000563, step_loss=0.083607/27/2023 18:23:03 - INFO - __main__ - train loss is 36.52071401255671\n",
      "Steps:  30%|▎| 4519/15000 [38:14<31:21,  5.57it/s, lr=0.000563, step_loss=0.056907/27/2023 18:23:04 - INFO - __main__ - train loss is 36.548042278387584\n",
      "Steps:  30%|▎| 4520/15000 [38:14<31:21,  5.57it/s, lr=0.000563, step_loss=0.027307/27/2023 18:23:04 - INFO - __main__ - train loss is 36.76530582795385\n",
      "Steps:  30%|▎| 4521/15000 [38:14<31:20,  5.57it/s, lr=0.000563, step_loss=0.217]07/27/2023 18:23:04 - INFO - __main__ - train loss is 36.84287115524057\n",
      "Steps:  30%|▎| 4522/15000 [38:14<31:20,  5.57it/s, lr=0.000564, step_loss=0.077607/27/2023 18:23:04 - INFO - __main__ - train loss is 37.27102478931192\n",
      "Steps:  30%|▎| 4523/15000 [38:14<31:19,  5.57it/s, lr=0.000564, step_loss=0.428]07/27/2023 18:23:04 - INFO - __main__ - train loss is 37.27461738383863\n",
      "Steps:  30%|▎| 4524/15000 [38:15<31:19,  5.57it/s, lr=0.000564, step_loss=0.003507/27/2023 18:23:04 - INFO - __main__ - train loss is 37.4572763988981\n",
      "Steps:  30%|▎| 4525/15000 [38:15<31:21,  5.57it/s, lr=0.000564, step_loss=0.183]07/27/2023 18:23:05 - INFO - __main__ - train loss is 37.53681277728174\n",
      "Steps:  30%|▎| 4526/15000 [38:15<31:20,  5.57it/s, lr=0.000564, step_loss=0.079507/27/2023 18:23:05 - INFO - __main__ - train loss is 37.72333982086275\n",
      "Steps:  30%|▎| 4527/15000 [38:15<31:20,  5.57it/s, lr=0.000564, step_loss=0.187]07/27/2023 18:23:05 - INFO - __main__ - train loss is 37.80879340565298\n",
      "Steps:  30%|▎| 4528/15000 [38:15<31:19,  5.57it/s, lr=0.000564, step_loss=0.085507/27/2023 18:23:05 - INFO - __main__ - train loss is 38.229339937330224\n",
      "Steps:  30%|▎| 4529/15000 [38:16<31:17,  5.58it/s, lr=0.000565, step_loss=0.421]07/27/2023 18:23:05 - INFO - __main__ - train loss is 38.254592670709826\n",
      "Steps:  30%|▎| 4530/15000 [38:16<31:15,  5.58it/s, lr=0.000565, step_loss=0.025307/27/2023 18:23:06 - INFO - __main__ - train loss is 38.45832733681891\n",
      "Steps:  30%|▎| 4531/15000 [38:16<31:15,  5.58it/s, lr=0.000565, step_loss=0.204]07/27/2023 18:23:06 - INFO - __main__ - train loss is 38.49046002945397\n",
      "Steps:  30%|▎| 4532/15000 [38:16<31:17,  5.57it/s, lr=0.000565, step_loss=0.032107/27/2023 18:23:06 - INFO - __main__ - train loss is 38.49733128549997\n",
      "Steps:  30%|▎| 4533/15000 [38:16<31:15,  5.58it/s, lr=0.000565, step_loss=0.006807/27/2023 18:23:06 - INFO - __main__ - train loss is 38.50914472772274\n",
      "Steps:  30%|▎| 4534/15000 [38:16<31:14,  5.58it/s, lr=0.000565, step_loss=0.011807/27/2023 18:23:06 - INFO - __main__ - train loss is 38.541145776049234\n",
      "Steps:  30%|▎| 4535/15000 [38:17<31:30,  5.54it/s, lr=0.000565, step_loss=0.032]07/27/2023 18:23:06 - INFO - __main__ - train loss is 39.03293580247555\n",
      "Steps:  30%|▎| 4536/15000 [38:17<31:31,  5.53it/s, lr=0.000565, step_loss=0.492]07/27/2023 18:23:07 - INFO - __main__ - train loss is 39.05146680085454\n",
      "Steps:  30%|▎| 4537/15000 [38:17<31:24,  5.55it/s, lr=0.000566, step_loss=0.018507/27/2023 18:23:07 - INFO - __main__ - train loss is 39.23059574572835\n",
      "Steps:  30%|▎| 4538/15000 [38:17<31:19,  5.56it/s, lr=0.000566, step_loss=0.179]07/27/2023 18:23:07 - INFO - __main__ - train loss is 39.53083718626294\n",
      "Steps:  30%|▉  | 4539/15000 [38:17<31:18,  5.57it/s, lr=0.000566, step_loss=0.3]07/27/2023 18:23:07 - INFO - __main__ - train loss is 39.56561270414386\n",
      "Steps:  30%|▎| 4540/15000 [38:17<31:16,  5.57it/s, lr=0.000566, step_loss=0.034807/27/2023 18:23:07 - INFO - __main__ - train loss is 40.1883625095943\n",
      "Steps:  30%|▎| 4541/15000 [38:18<31:13,  5.58it/s, lr=0.000566, step_loss=0.623]07/27/2023 18:23:08 - INFO - __main__ - train loss is 40.19006092811469\n",
      "Steps:  30%|▎| 4542/15000 [38:18<31:10,  5.59it/s, lr=0.000566, step_loss=0.001707/27/2023 18:23:08 - INFO - __main__ - train loss is 40.25826886261348\n",
      "Steps:  30%|▎| 4543/15000 [38:18<31:10,  5.59it/s, lr=0.000566, step_loss=0.068207/27/2023 18:23:08 - INFO - __main__ - train loss is 40.293394252308644\n",
      "Steps:  30%|▎| 4544/15000 [38:18<31:09,  5.59it/s, lr=0.000566, step_loss=0.035107/27/2023 18:23:08 - INFO - __main__ - train loss is 40.30687941762153\n",
      "Steps:  30%|▎| 4545/15000 [38:19<44:20,  3.93it/s, lr=0.000567, step_loss=0.013507/27/2023 18:23:09 - INFO - __main__ - Per validation step average loss is 0.0034802411682903767\n",
      "07/27/2023 18:23:09 - INFO - __main__ - Cumulative validation average loss is 0.0034802411682903767\n",
      "07/27/2023 18:23:10 - INFO - __main__ - Per validation step average loss is 0.00941009446978569\n",
      "07/27/2023 18:23:10 - INFO - __main__ - Cumulative validation average loss is 0.012890335638076067\n",
      "07/27/2023 18:23:10 - INFO - __main__ - Per validation step average loss is 0.132160484790802\n",
      "07/27/2023 18:23:10 - INFO - __main__ - Cumulative validation average loss is 0.14505082042887807\n",
      "07/27/2023 18:23:11 - INFO - __main__ - Per validation step average loss is 0.0013824861962348223\n",
      "07/27/2023 18:23:11 - INFO - __main__ - Cumulative validation average loss is 0.1464333066251129\n",
      "07/27/2023 18:23:11 - INFO - __main__ - Per validation step average loss is 0.3876873254776001\n",
      "07/27/2023 18:23:11 - INFO - __main__ - Cumulative validation average loss is 0.534120632102713\n",
      "07/27/2023 18:23:11 - INFO - __main__ - Per validation step average loss is 0.22397758066654205\n",
      "07/27/2023 18:23:11 - INFO - __main__ - Cumulative validation average loss is 0.758098212769255\n",
      "07/27/2023 18:23:12 - INFO - __main__ - Per validation step average loss is 0.2073054015636444\n",
      "07/27/2023 18:23:12 - INFO - __main__ - Cumulative validation average loss is 0.9654036143328995\n",
      "07/27/2023 18:23:12 - INFO - __main__ - Per validation step average loss is 0.004272374790161848\n",
      "07/27/2023 18:23:12 - INFO - __main__ - Cumulative validation average loss is 0.9696759891230613\n",
      "07/27/2023 18:23:13 - INFO - __main__ - Per validation step average loss is 0.009267891757190228\n",
      "07/27/2023 18:23:13 - INFO - __main__ - Cumulative validation average loss is 0.9789438808802515\n",
      "07/27/2023 18:23:13 - INFO - __main__ - Per validation step average loss is 0.00907091610133648\n",
      "07/27/2023 18:23:13 - INFO - __main__ - Cumulative validation average loss is 0.988014796981588\n",
      "07/27/2023 18:23:13 - INFO - __main__ - Per validation step average loss is 0.3414822220802307\n",
      "07/27/2023 18:23:13 - INFO - __main__ - Cumulative validation average loss is 1.3294970190618187\n",
      "07/27/2023 18:23:14 - INFO - __main__ - Per validation step average loss is 0.01575317233800888\n",
      "07/27/2023 18:23:14 - INFO - __main__ - Cumulative validation average loss is 1.3452501913998276\n",
      "07/27/2023 18:23:14 - INFO - __main__ - Per validation step average loss is 0.03770573064684868\n",
      "07/27/2023 18:23:14 - INFO - __main__ - Cumulative validation average loss is 1.3829559220466763\n",
      "07/27/2023 18:23:15 - INFO - __main__ - Per validation step average loss is 0.0075772348791360855\n",
      "07/27/2023 18:23:15 - INFO - __main__ - Cumulative validation average loss is 1.3905331569258124\n",
      "07/27/2023 18:23:15 - INFO - __main__ - Per validation step average loss is 0.007652283180505037\n",
      "07/27/2023 18:23:15 - INFO - __main__ - Cumulative validation average loss is 1.3981854401063174\n",
      "07/27/2023 18:23:16 - INFO - __main__ - Per validation step average loss is 0.36202579736709595\n",
      "07/27/2023 18:23:16 - INFO - __main__ - Cumulative validation average loss is 1.7602112374734133\n",
      "07/27/2023 18:23:16 - INFO - __main__ - Per validation step average loss is 0.018244057893753052\n",
      "07/27/2023 18:23:16 - INFO - __main__ - Cumulative validation average loss is 1.7784552953671664\n",
      "07/27/2023 18:23:16 - INFO - __main__ - Per validation step average loss is 0.009056344628334045\n",
      "07/27/2023 18:23:16 - INFO - __main__ - Cumulative validation average loss is 1.7875116399955004\n",
      "07/27/2023 18:23:17 - INFO - __main__ - Per validation step average loss is 0.11499868333339691\n",
      "07/27/2023 18:23:17 - INFO - __main__ - Cumulative validation average loss is 1.9025103233288974\n",
      "07/27/2023 18:23:17 - INFO - __main__ - Per validation step average loss is 0.0028681394178420305\n",
      "07/27/2023 18:23:17 - INFO - __main__ - Cumulative validation average loss is 1.9053784627467394\n",
      "07/27/2023 18:23:18 - INFO - __main__ - Per validation step average loss is 0.01069391705095768\n",
      "07/27/2023 18:23:18 - INFO - __main__ - Cumulative validation average loss is 1.916072379797697\n",
      "07/27/2023 18:23:18 - INFO - __main__ - Per validation step average loss is 0.4514535665512085\n",
      "07/27/2023 18:23:18 - INFO - __main__ - Cumulative validation average loss is 2.3675259463489056\n",
      "07/27/2023 18:23:18 - INFO - __main__ - Per validation step average loss is 0.13222378492355347\n",
      "07/27/2023 18:23:18 - INFO - __main__ - Cumulative validation average loss is 2.499749731272459\n",
      "07/27/2023 18:23:19 - INFO - __main__ - Per validation step average loss is 0.5554017424583435\n",
      "07/27/2023 18:23:19 - INFO - __main__ - Cumulative validation average loss is 3.0551514737308025\n",
      "07/27/2023 18:23:19 - INFO - __main__ - Per validation step average loss is 0.03711332380771637\n",
      "07/27/2023 18:23:19 - INFO - __main__ - Cumulative validation average loss is 3.092264797538519\n",
      "07/27/2023 18:23:20 - INFO - __main__ - Per validation step average loss is 0.017581067979335785\n",
      "07/27/2023 18:23:20 - INFO - __main__ - Cumulative validation average loss is 3.1098458655178547\n",
      "07/27/2023 18:23:20 - INFO - __main__ - Per validation step average loss is 0.2365875244140625\n",
      "07/27/2023 18:23:20 - INFO - __main__ - Cumulative validation average loss is 3.346433389931917\n",
      "07/27/2023 18:23:20 - INFO - __main__ - Per validation step average loss is 0.13998277485370636\n",
      "07/27/2023 18:23:20 - INFO - __main__ - Cumulative validation average loss is 3.4864161647856236\n",
      "07/27/2023 18:23:21 - INFO - __main__ - Per validation step average loss is 0.22327804565429688\n",
      "07/27/2023 18:23:21 - INFO - __main__ - Cumulative validation average loss is 3.7096942104399204\n",
      "07/27/2023 18:23:21 - INFO - __main__ - Per validation step average loss is 0.21296599507331848\n",
      "07/27/2023 18:23:21 - INFO - __main__ - Cumulative validation average loss is 3.922660205513239\n",
      "07/27/2023 18:23:22 - INFO - __main__ - Per validation step average loss is 0.003068693447858095\n",
      "07/27/2023 18:23:22 - INFO - __main__ - Cumulative validation average loss is 3.925728898961097\n",
      "07/27/2023 18:23:22 - INFO - __main__ - Per validation step average loss is 0.0034973809961229563\n",
      "07/27/2023 18:23:22 - INFO - __main__ - Cumulative validation average loss is 3.92922627995722\n",
      "07/27/2023 18:23:22 - INFO - __main__ - Per validation step average loss is 0.03267204016447067\n",
      "07/27/2023 18:23:22 - INFO - __main__ - Cumulative validation average loss is 3.9618983201216906\n",
      "07/27/2023 18:23:23 - INFO - __main__ - Per validation step average loss is 0.4324248433113098\n",
      "07/27/2023 18:23:23 - INFO - __main__ - Cumulative validation average loss is 4.3943231634330004\n",
      "07/27/2023 18:23:23 - INFO - __main__ - Per validation step average loss is 0.23698210716247559\n",
      "07/27/2023 18:23:23 - INFO - __main__ - Cumulative validation average loss is 4.631305270595476\n",
      "07/27/2023 18:23:24 - INFO - __main__ - Per validation step average loss is 0.03533853590488434\n",
      "07/27/2023 18:23:24 - INFO - __main__ - Cumulative validation average loss is 4.66664380650036\n",
      "07/27/2023 18:23:24 - INFO - __main__ - Per validation step average loss is 0.017843985930085182\n",
      "07/27/2023 18:23:24 - INFO - __main__ - Cumulative validation average loss is 4.6844877924304456\n",
      "07/27/2023 18:23:25 - INFO - __main__ - Per validation step average loss is 0.32792413234710693\n",
      "07/27/2023 18:23:25 - INFO - __main__ - Cumulative validation average loss is 5.0124119247775525\n",
      "07/27/2023 18:23:25 - INFO - __main__ - Per validation step average loss is 0.017642783001065254\n",
      "07/27/2023 18:23:25 - INFO - __main__ - Cumulative validation average loss is 5.030054707778618\n",
      "07/27/2023 18:23:25 - INFO - __main__ - Per validation step average loss is 0.014179297722876072\n",
      "07/27/2023 18:23:25 - INFO - __main__ - Cumulative validation average loss is 5.044234005501494\n",
      "07/27/2023 18:23:26 - INFO - __main__ - Per validation step average loss is 0.12712249159812927\n",
      "07/27/2023 18:23:26 - INFO - __main__ - Cumulative validation average loss is 5.171356497099623\n",
      "07/27/2023 18:23:26 - INFO - __main__ - Per validation step average loss is 0.02368251234292984\n",
      "07/27/2023 18:23:26 - INFO - __main__ - Cumulative validation average loss is 5.195039009442553\n",
      "07/27/2023 18:23:27 - INFO - __main__ - Per validation step average loss is 0.026160255074501038\n",
      "07/27/2023 18:23:27 - INFO - __main__ - Cumulative validation average loss is 5.221199264517054\n",
      "07/27/2023 18:23:27 - INFO - __main__ - Per validation step average loss is 0.04552764445543289\n",
      "07/27/2023 18:23:27 - INFO - __main__ - Cumulative validation average loss is 5.266726908972487\n",
      "07/27/2023 18:23:27 - INFO - __main__ - Per validation step average loss is 0.1920873075723648\n",
      "07/27/2023 18:23:27 - INFO - __main__ - Cumulative validation average loss is 5.458814216544852\n",
      "07/27/2023 18:23:28 - INFO - __main__ - Per validation step average loss is 0.02477368339896202\n",
      "07/27/2023 18:23:28 - INFO - __main__ - Cumulative validation average loss is 5.483587899943814\n",
      "07/27/2023 18:23:28 - INFO - __main__ - Per validation step average loss is 0.5238466262817383\n",
      "07/27/2023 18:23:28 - INFO - __main__ - Cumulative validation average loss is 6.007434526225552\n",
      "07/27/2023 18:23:29 - INFO - __main__ - Per validation step average loss is 0.06977716088294983\n",
      "07/27/2023 18:23:29 - INFO - __main__ - Cumulative validation average loss is 6.077211687108502\n",
      "07/27/2023 18:23:29 - INFO - __main__ - Per validation step average loss is 0.0026537012308835983\n",
      "07/27/2023 18:23:29 - INFO - __main__ - Cumulative validation average loss is 6.079865388339385\n",
      "07/27/2023 18:23:29 - INFO - __main__ - Per validation step average loss is 0.07269226759672165\n",
      "07/27/2023 18:23:29 - INFO - __main__ - Cumulative validation average loss is 6.152557655936107\n",
      "07/27/2023 18:23:30 - INFO - __main__ - Per validation step average loss is 0.01759602315723896\n",
      "07/27/2023 18:23:30 - INFO - __main__ - Cumulative validation average loss is 6.170153679093346\n",
      "07/27/2023 18:23:30 - INFO - __main__ - Per validation step average loss is 0.024101855233311653\n",
      "07/27/2023 18:23:30 - INFO - __main__ - Cumulative validation average loss is 6.194255534326658\n",
      "07/27/2023 18:23:31 - INFO - __main__ - Per validation step average loss is 0.015098704025149345\n",
      "07/27/2023 18:23:31 - INFO - __main__ - Cumulative validation average loss is 6.209354238351807\n",
      "07/27/2023 18:23:31 - INFO - __main__ - Per validation step average loss is 0.043165408074855804\n",
      "07/27/2023 18:23:31 - INFO - __main__ - Cumulative validation average loss is 6.252519646426663\n",
      "07/27/2023 18:23:31 - INFO - __main__ - Per validation step average loss is 0.006820871494710445\n",
      "07/27/2023 18:23:31 - INFO - __main__ - Cumulative validation average loss is 6.259340517921373\n",
      "07/27/2023 18:23:32 - INFO - __main__ - Per validation step average loss is 0.012075014412403107\n",
      "07/27/2023 18:23:32 - INFO - __main__ - Cumulative validation average loss is 6.271415532333776\n",
      "07/27/2023 18:23:32 - INFO - __main__ - Per validation step average loss is 0.02337096445262432\n",
      "07/27/2023 18:23:32 - INFO - __main__ - Cumulative validation average loss is 6.294786496786401\n",
      "07/27/2023 18:23:33 - INFO - __main__ - Per validation step average loss is 0.049551986157894135\n",
      "07/27/2023 18:23:33 - INFO - __main__ - Cumulative validation average loss is 6.344338482944295\n",
      "07/27/2023 18:23:33 - INFO - __main__ - Per validation step average loss is 0.1235627606511116\n",
      "07/27/2023 18:23:33 - INFO - __main__ - Cumulative validation average loss is 6.467901243595406\n",
      "07/27/2023 18:23:34 - INFO - __main__ - Per validation step average loss is 0.006033491343259811\n",
      "07/27/2023 18:23:34 - INFO - __main__ - Cumulative validation average loss is 6.473934734938666\n",
      "07/27/2023 18:23:34 - INFO - __main__ - Per validation step average loss is 0.004002099856734276\n",
      "07/27/2023 18:23:34 - INFO - __main__ - Cumulative validation average loss is 6.4779368347954005\n",
      "07/27/2023 18:23:34 - INFO - __main__ - Per validation step average loss is 0.004891146440058947\n",
      "07/27/2023 18:23:34 - INFO - __main__ - Cumulative validation average loss is 6.4828279812354594\n",
      "07/27/2023 18:23:35 - INFO - __main__ - Per validation step average loss is 0.09159766137599945\n",
      "07/27/2023 18:23:35 - INFO - __main__ - Cumulative validation average loss is 6.574425642611459\n",
      "07/27/2023 18:23:35 - INFO - __main__ - Per validation step average loss is 0.04633556306362152\n",
      "07/27/2023 18:23:35 - INFO - __main__ - Cumulative validation average loss is 6.62076120567508\n",
      "07/27/2023 18:23:36 - INFO - __main__ - Per validation step average loss is 0.01813584938645363\n",
      "07/27/2023 18:23:36 - INFO - __main__ - Cumulative validation average loss is 6.638897055061534\n",
      "07/27/2023 18:23:36 - INFO - __main__ - Per validation step average loss is 0.24455752968788147\n",
      "07/27/2023 18:23:36 - INFO - __main__ - Cumulative validation average loss is 6.8834545847494155\n",
      "07/27/2023 18:23:36 - INFO - __main__ - Per validation step average loss is 0.0020611807703971863\n",
      "07/27/2023 18:23:36 - INFO - __main__ - Cumulative validation average loss is 6.885515765519813\n",
      "07/27/2023 18:23:37 - INFO - __main__ - Per validation step average loss is 0.10299710184335709\n",
      "07/27/2023 18:23:37 - INFO - __main__ - Cumulative validation average loss is 6.98851286736317\n",
      "07/27/2023 18:23:37 - INFO - __main__ - Per validation step average loss is 0.12673251330852509\n",
      "07/27/2023 18:23:37 - INFO - __main__ - Cumulative validation average loss is 7.115245380671695\n",
      "07/27/2023 18:23:38 - INFO - __main__ - Per validation step average loss is 0.057742901146411896\n",
      "07/27/2023 18:23:38 - INFO - __main__ - Cumulative validation average loss is 7.172988281818107\n",
      "07/27/2023 18:23:38 - INFO - __main__ - Per validation step average loss is 0.0016465513035655022\n",
      "07/27/2023 18:23:38 - INFO - __main__ - Cumulative validation average loss is 7.174634833121672\n",
      "07/27/2023 18:23:38 - INFO - __main__ - Per validation step average loss is 0.2447672188282013\n",
      "07/27/2023 18:23:38 - INFO - __main__ - Cumulative validation average loss is 7.419402051949874\n",
      "07/27/2023 18:23:39 - INFO - __main__ - Per validation step average loss is 0.12929049134254456\n",
      "07/27/2023 18:23:39 - INFO - __main__ - Cumulative validation average loss is 7.548692543292418\n",
      "07/27/2023 18:23:39 - INFO - __main__ - Per validation step average loss is 0.00217635789886117\n",
      "07/27/2023 18:23:39 - INFO - __main__ - Cumulative validation average loss is 7.550868901191279\n",
      "07/27/2023 18:23:40 - INFO - __main__ - Per validation step average loss is 0.06519478559494019\n",
      "07/27/2023 18:23:40 - INFO - __main__ - Cumulative validation average loss is 7.6160636867862195\n",
      "07/27/2023 18:23:40 - INFO - __main__ - Per validation step average loss is 0.0013017308665439487\n",
      "07/27/2023 18:23:40 - INFO - __main__ - Cumulative validation average loss is 7.617365417652763\n",
      "07/27/2023 18:23:41 - INFO - __main__ - Per validation step average loss is 0.6435031294822693\n",
      "07/27/2023 18:23:41 - INFO - __main__ - Cumulative validation average loss is 8.260868547135033\n",
      "07/27/2023 18:23:41 - INFO - __main__ - Per validation step average loss is 0.001619309070520103\n",
      "07/27/2023 18:23:41 - INFO - __main__ - Cumulative validation average loss is 8.262487856205553\n",
      "07/27/2023 18:23:42 - INFO - __main__ - Per validation step average loss is 0.018366815522313118\n",
      "07/27/2023 18:23:42 - INFO - __main__ - Cumulative validation average loss is 8.280854671727866\n",
      "07/27/2023 18:23:42 - INFO - __main__ - Average validation loss for Epoch 14 is 0.10482094521174513\n",
      "07/27/2023 18:23:42 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:24:39 - INFO - __main__ - Starting epoch 15\n",
      "07/27/2023 18:24:39 - INFO - __main__ - train loss is 0.40786212682724\n",
      "Steps:  30%|▎| 4546/15000 [39:50<79:46:48, 27.47s/it, lr=0.000567, step_loss=0.407/27/2023 18:24:39 - INFO - __main__ - train loss is 0.4118273379281163\n",
      "Steps:  30%|▎| 4547/15000 [39:50<55:59:54, 19.29s/it, lr=0.000567, step_loss=0.007/27/2023 18:24:40 - INFO - __main__ - train loss is 0.4130182978697121\n",
      "Steps:  30%|▎| 4548/15000 [39:50<39:21:11, 13.55s/it, lr=0.000567, step_loss=0.007/27/2023 18:24:40 - INFO - __main__ - train loss is 0.7308753547258675\n",
      "Steps:  30%|▎| 4549/15000 [39:50<27:42:03,  9.54s/it, lr=0.000567, step_loss=0.307/27/2023 18:24:40 - INFO - __main__ - train loss is 0.7359526664949954\n",
      "Steps:  30%|▎| 4550/15000 [39:50<19:32:49,  6.73s/it, lr=0.000567, step_loss=0.007/27/2023 18:24:40 - INFO - __main__ - train loss is 0.7956496314145625\n",
      "Steps:  30%|▎| 4551/15000 [39:51<13:50:27,  4.77s/it, lr=0.000567, step_loss=0.007/27/2023 18:24:40 - INFO - __main__ - train loss is 0.8637440637685359\n",
      "Steps:  30%|▎| 4552/15000 [39:51<9:50:39,  3.39s/it, lr=0.000567, step_loss=0.0607/27/2023 18:24:41 - INFO - __main__ - train loss is 0.8741624620743096\n",
      "Steps:  30%|▎| 4553/15000 [39:51<7:02:50,  2.43s/it, lr=0.000567, step_loss=0.0107/27/2023 18:24:41 - INFO - __main__ - train loss is 0.9105783370323479\n",
      "Steps:  30%|▎| 4554/15000 [39:51<5:05:16,  1.75s/it, lr=0.000568, step_loss=0.0307/27/2023 18:24:41 - INFO - __main__ - train loss is 1.2671903637237847\n",
      "Steps:  30%|▎| 4555/15000 [39:51<3:43:04,  1.28s/it, lr=0.000568, step_loss=0.3507/27/2023 18:24:41 - INFO - __main__ - train loss is 1.6131366160698235\n",
      "Steps:  30%|▎| 4556/15000 [39:51<2:45:28,  1.05it/s, lr=0.000568, step_loss=0.3407/27/2023 18:24:41 - INFO - __main__ - train loss is 1.6909543019719422\n",
      "Steps:  30%|▎| 4557/15000 [39:52<2:05:09,  1.39it/s, lr=0.000568, step_loss=0.0707/27/2023 18:24:41 - INFO - __main__ - train loss is 1.7208593268878758\n",
      "Steps:  30%|▎| 4558/15000 [39:52<1:36:56,  1.80it/s, lr=0.000568, step_loss=0.0207/27/2023 18:24:42 - INFO - __main__ - train loss is 1.723144844174385\n",
      "Steps:  30%|▎| 4559/15000 [39:52<1:17:11,  2.25it/s, lr=0.000568, step_loss=0.0007/27/2023 18:24:42 - INFO - __main__ - train loss is 1.8050043284893036\n",
      "Steps:  30%|▎| 4560/15000 [39:52<1:03:23,  2.74it/s, lr=0.000568, step_loss=0.0807/27/2023 18:24:42 - INFO - __main__ - train loss is 1.987962618470192\n",
      "Steps:  30%|▎| 4561/15000 [39:52<53:41,  3.24it/s, lr=0.000568, step_loss=0.183]07/27/2023 18:24:42 - INFO - __main__ - train loss is 1.9980996660888195\n",
      "Steps:  30%|▎| 4562/15000 [39:53<46:54,  3.71it/s, lr=0.000569, step_loss=0.010107/27/2023 18:24:42 - INFO - __main__ - train loss is 2.0281374286860228\n",
      "Steps:  30%|▌ | 4563/15000 [39:53<42:10,  4.12it/s, lr=0.000569, step_loss=0.03]07/27/2023 18:24:43 - INFO - __main__ - train loss is 2.0296617709100246\n",
      "Steps:  30%|▎| 4564/15000 [39:53<38:52,  4.47it/s, lr=0.000569, step_loss=0.001507/27/2023 18:24:43 - INFO - __main__ - train loss is 2.036206156015396\n",
      "Steps:  30%|▎| 4565/15000 [39:53<36:36,  4.75it/s, lr=0.000569, step_loss=0.006507/27/2023 18:24:43 - INFO - __main__ - train loss is 2.038448092294857\n",
      "Steps:  30%|▎| 4566/15000 [39:53<35:01,  4.96it/s, lr=0.000569, step_loss=0.002207/27/2023 18:24:43 - INFO - __main__ - train loss is 2.160525572253391\n",
      "Steps:  30%|▎| 4567/15000 [39:53<33:53,  5.13it/s, lr=0.000569, step_loss=0.122]07/27/2023 18:24:43 - INFO - __main__ - train loss is 2.3235416531097144\n",
      "Steps:  30%|▎| 4568/15000 [39:54<33:04,  5.26it/s, lr=0.000569, step_loss=0.163]07/27/2023 18:24:43 - INFO - __main__ - train loss is 2.3781630515586585\n",
      "Steps:  30%|▎| 4569/15000 [39:54<32:31,  5.34it/s, lr=0.00057, step_loss=0.0546]07/27/2023 18:24:44 - INFO - __main__ - train loss is 2.6083037077914923\n",
      "Steps:  30%|▉  | 4570/15000 [39:54<32:11,  5.40it/s, lr=0.00057, step_loss=0.23]07/27/2023 18:24:44 - INFO - __main__ - train loss is 2.6311958774458617\n",
      "Steps:  30%|▎| 4571/15000 [39:54<31:53,  5.45it/s, lr=0.00057, step_loss=0.0229]07/27/2023 18:24:44 - INFO - __main__ - train loss is 2.6928689263295382\n",
      "Steps:  30%|▎| 4572/15000 [39:54<31:42,  5.48it/s, lr=0.00057, step_loss=0.0617]07/27/2023 18:24:44 - INFO - __main__ - train loss is 2.8204671076964587\n",
      "Steps:  30%|▌ | 4573/15000 [39:54<31:34,  5.50it/s, lr=0.00057, step_loss=0.128]07/27/2023 18:24:44 - INFO - __main__ - train loss is 3.0362944982480258\n",
      "Steps:  30%|▌ | 4574/15000 [39:55<31:29,  5.52it/s, lr=0.00057, step_loss=0.216]07/27/2023 18:24:45 - INFO - __main__ - train loss is 3.039989188313484\n",
      "Steps:  30%|▎| 4575/15000 [39:55<31:22,  5.54it/s, lr=0.00057, step_loss=0.0036907/27/2023 18:24:45 - INFO - __main__ - train loss is 3.0870734490454197\n",
      "Steps:  31%|▎| 4576/15000 [39:55<31:22,  5.54it/s, lr=0.00057, step_loss=0.0471]07/27/2023 18:24:45 - INFO - __main__ - train loss is 3.304592091590166\n",
      "Steps:  31%|▎| 4577/15000 [39:55<31:30,  5.51it/s, lr=0.000571, step_loss=0.218]07/27/2023 18:24:45 - INFO - __main__ - train loss is 3.6009928472340107\n",
      "Steps:  31%|▎| 4578/15000 [39:55<31:41,  5.48it/s, lr=0.000571, step_loss=0.296]07/27/2023 18:24:45 - INFO - __main__ - train loss is 3.603082966990769\n",
      "Steps:  31%|▎| 4579/15000 [39:56<31:53,  5.45it/s, lr=0.000571, step_loss=0.002007/27/2023 18:24:45 - INFO - __main__ - train loss is 3.605773952556774\n",
      "Steps:  31%|▎| 4580/15000 [39:56<31:45,  5.47it/s, lr=0.000571, step_loss=0.002607/27/2023 18:24:46 - INFO - __main__ - train loss is 3.6102952908258885\n",
      "Steps:  31%|▎| 4581/15000 [39:56<31:33,  5.50it/s, lr=0.000571, step_loss=0.004507/27/2023 18:24:46 - INFO - __main__ - train loss is 3.688221963820979\n",
      "Steps:  31%|▎| 4582/15000 [39:56<31:24,  5.53it/s, lr=0.000571, step_loss=0.077907/27/2023 18:24:46 - INFO - __main__ - train loss is 3.7018878541421145\n",
      "Steps:  31%|▎| 4583/15000 [39:56<31:18,  5.54it/s, lr=0.000571, step_loss=0.013707/27/2023 18:24:46 - INFO - __main__ - train loss is 3.982611396117136\n",
      "Steps:  31%|▎| 4584/15000 [39:56<31:14,  5.56it/s, lr=0.000571, step_loss=0.281]07/27/2023 18:24:46 - INFO - __main__ - train loss is 3.9837477137334645\n",
      "Steps:  31%|▎| 4585/15000 [39:57<31:12,  5.56it/s, lr=0.000572, step_loss=0.001107/27/2023 18:24:47 - INFO - __main__ - train loss is 4.087108098436147\n",
      "Steps:  31%|▎| 4586/15000 [39:57<31:10,  5.57it/s, lr=0.000572, step_loss=0.103]07/27/2023 18:24:47 - INFO - __main__ - train loss is 4.351097785402089\n",
      "Steps:  31%|▎| 4587/15000 [39:57<31:26,  5.52it/s, lr=0.000572, step_loss=0.264]07/27/2023 18:24:47 - INFO - __main__ - train loss is 4.6192702879197896\n",
      "Steps:  31%|▎| 4588/15000 [39:57<31:31,  5.50it/s, lr=0.000572, step_loss=0.268]07/27/2023 18:24:47 - INFO - __main__ - train loss is 4.638291366863996\n",
      "Steps:  31%|▎| 4589/15000 [39:57<31:23,  5.53it/s, lr=0.000572, step_loss=0.019]07/27/2023 18:24:47 - INFO - __main__ - train loss is 4.675020069349557\n",
      "Steps:  31%|▎| 4590/15000 [39:58<31:17,  5.54it/s, lr=0.000572, step_loss=0.036707/27/2023 18:24:47 - INFO - __main__ - train loss is 4.7198452656157315\n",
      "Steps:  31%|▎| 4591/15000 [39:58<31:13,  5.56it/s, lr=0.000572, step_loss=0.044807/27/2023 18:24:48 - INFO - __main__ - train loss is 4.734429514501244\n",
      "Steps:  31%|▎| 4592/15000 [39:58<31:23,  5.53it/s, lr=0.000572, step_loss=0.014607/27/2023 18:24:48 - INFO - __main__ - train loss is 4.993722176644951\n",
      "Steps:  31%|▎| 4593/15000 [39:58<31:25,  5.52it/s, lr=0.000572, step_loss=0.259]07/27/2023 18:24:48 - INFO - __main__ - train loss is 5.2368121654726565\n",
      "Steps:  31%|▎| 4594/15000 [39:58<31:19,  5.54it/s, lr=0.000573, step_loss=0.243]07/27/2023 18:24:48 - INFO - __main__ - train loss is 5.388460120651871\n",
      "Steps:  31%|▎| 4595/15000 [39:58<31:14,  5.55it/s, lr=0.000573, step_loss=0.152]07/27/2023 18:24:48 - INFO - __main__ - train loss is 5.396964023355395\n",
      "Steps:  31%|▎| 4596/15000 [39:59<31:11,  5.56it/s, lr=0.000573, step_loss=0.008507/27/2023 18:24:49 - INFO - __main__ - train loss is 5.6178078153170645\n",
      "Steps:  31%|▎| 4597/15000 [39:59<31:09,  5.56it/s, lr=0.000573, step_loss=0.221]07/27/2023 18:24:49 - INFO - __main__ - train loss is 5.653422775212675\n",
      "Steps:  31%|▎| 4598/15000 [39:59<31:08,  5.57it/s, lr=0.000573, step_loss=0.035607/27/2023 18:24:49 - INFO - __main__ - train loss is 5.676567256916314\n",
      "Steps:  31%|▎| 4599/15000 [39:59<31:07,  5.57it/s, lr=0.000573, step_loss=0.023107/27/2023 18:24:49 - INFO - __main__ - train loss is 6.062161744106561\n",
      "Steps:  31%|▎| 4600/15000 [39:59<31:06,  5.57it/s, lr=0.000573, step_loss=0.386]07/27/2023 18:24:49 - INFO - __main__ - train loss is 6.08439425425604\n",
      "Steps:  31%|▎| 4601/15000 [40:00<31:06,  5.57it/s, lr=0.000574, step_loss=0.022207/27/2023 18:24:49 - INFO - __main__ - train loss is 6.118362721521407\n",
      "Steps:  31%|▎| 4602/15000 [40:00<31:05,  5.57it/s, lr=0.000574, step_loss=0.034]07/27/2023 18:24:50 - INFO - __main__ - train loss is 6.135693688411266\n",
      "Steps:  31%|▎| 4603/15000 [40:00<31:12,  5.55it/s, lr=0.000574, step_loss=0.017307/27/2023 18:24:50 - INFO - __main__ - train loss is 6.306353573221713\n",
      "Steps:  31%|▎| 4604/15000 [40:00<31:09,  5.56it/s, lr=0.000574, step_loss=0.171]07/27/2023 18:24:50 - INFO - __main__ - train loss is 6.313920697662979\n",
      "Steps:  31%|▎| 4605/15000 [40:00<31:08,  5.56it/s, lr=0.000574, step_loss=0.007507/27/2023 18:24:50 - INFO - __main__ - train loss is 6.466961896512657\n",
      "Steps:  31%|▎| 4606/15000 [40:00<31:06,  5.57it/s, lr=0.000574, step_loss=0.153]07/27/2023 18:24:50 - INFO - __main__ - train loss is 6.504114656243473\n",
      "Steps:  31%|▎| 4607/15000 [40:01<31:06,  5.57it/s, lr=0.000574, step_loss=0.037207/27/2023 18:24:50 - INFO - __main__ - train loss is 6.706800563726574\n",
      "Steps:  31%|▎| 4608/15000 [40:01<31:04,  5.57it/s, lr=0.000574, step_loss=0.203]07/27/2023 18:24:51 - INFO - __main__ - train loss is 6.792245036456734\n",
      "Steps:  31%|▎| 4609/15000 [40:01<31:13,  5.55it/s, lr=0.000575, step_loss=0.085407/27/2023 18:24:51 - INFO - __main__ - train loss is 6.8147112359292805\n",
      "Steps:  31%|▎| 4610/15000 [40:01<31:10,  5.55it/s, lr=0.000575, step_loss=0.022507/27/2023 18:24:51 - INFO - __main__ - train loss is 6.854135044384748\n",
      "Steps:  31%|▎| 4611/15000 [40:01<31:09,  5.56it/s, lr=0.000575, step_loss=0.039407/27/2023 18:24:51 - INFO - __main__ - train loss is 6.866701717954129\n",
      "Steps:  31%|▎| 4612/15000 [40:02<31:06,  5.56it/s, lr=0.000575, step_loss=0.012607/27/2023 18:24:51 - INFO - __main__ - train loss is 7.451788778882474\n",
      "Steps:  31%|▎| 4613/15000 [40:02<31:05,  5.57it/s, lr=0.000575, step_loss=0.585]07/27/2023 18:24:52 - INFO - __main__ - train loss is 7.677605356555432\n",
      "Steps:  31%|▎| 4614/15000 [40:02<31:03,  5.57it/s, lr=0.000575, step_loss=0.226]07/27/2023 18:24:52 - INFO - __main__ - train loss is 7.720764942001551\n",
      "Steps:  31%|▎| 4615/15000 [40:02<31:02,  5.58it/s, lr=0.000575, step_loss=0.043207/27/2023 18:24:52 - INFO - __main__ - train loss is 8.031735606025904\n",
      "Steps:  31%|▎| 4616/15000 [40:02<31:01,  5.58it/s, lr=0.000575, step_loss=0.311]07/27/2023 18:24:52 - INFO - __main__ - train loss is 8.037146843969822\n",
      "Steps:  31%|▎| 4617/15000 [40:02<31:01,  5.58it/s, lr=0.000576, step_loss=0.005407/27/2023 18:24:52 - INFO - __main__ - train loss is 8.131231680512428\n",
      "Steps:  31%|▎| 4618/15000 [40:03<31:00,  5.58it/s, lr=0.000576, step_loss=0.094107/27/2023 18:24:52 - INFO - __main__ - train loss is 8.374974891543388\n",
      "Steps:  31%|▎| 4619/15000 [40:03<31:00,  5.58it/s, lr=0.000576, step_loss=0.244]07/27/2023 18:24:53 - INFO - __main__ - train loss is 8.39425715059042\n",
      "Steps:  31%|▎| 4620/15000 [40:03<30:59,  5.58it/s, lr=0.000576, step_loss=0.019307/27/2023 18:24:53 - INFO - __main__ - train loss is 8.497189819812775\n",
      "Steps:  31%|▎| 4621/15000 [40:03<31:03,  5.57it/s, lr=0.000576, step_loss=0.103]07/27/2023 18:24:53 - INFO - __main__ - train loss is 8.498227730742656\n",
      "Steps:  31%|▎| 4622/15000 [40:03<31:01,  5.58it/s, lr=0.000576, step_loss=0.001007/27/2023 18:24:53 - INFO - __main__ - train loss is 8.503534493385814\n",
      "Steps:  31%|▎| 4623/15000 [40:03<31:05,  5.56it/s, lr=0.000576, step_loss=0.005307/27/2023 18:24:53 - INFO - __main__ - train loss is 8.506779492250644\n",
      "Steps:  31%|▎| 4624/15000 [40:04<31:04,  5.57it/s, lr=0.000576, step_loss=0.003207/27/2023 18:24:54 - INFO - __main__ - train loss is 8.637171715847217\n",
      "Steps:  31%|▌ | 4625/15000 [40:04<31:03,  5.57it/s, lr=0.000576, step_loss=0.13]07/27/2023 18:24:54 - INFO - __main__ - train loss is 8.700166583410464\n",
      "Steps:  31%|▎| 4626/15000 [40:04<31:03,  5.57it/s, lr=0.000577, step_loss=0.063]07/27/2023 18:24:54 - INFO - __main__ - train loss is 8.87024317716714\n",
      "Steps:  31%|▌ | 4627/15000 [40:04<31:05,  5.56it/s, lr=0.000577, step_loss=0.17]07/27/2023 18:24:54 - INFO - __main__ - train loss is 8.91585091536399\n",
      "Steps:  31%|▎| 4628/15000 [40:04<31:06,  5.56it/s, lr=0.000577, step_loss=0.045607/27/2023 18:24:54 - INFO - __main__ - train loss is 9.111813940457068\n",
      "Steps:  31%|▎| 4629/15000 [40:05<31:07,  5.55it/s, lr=0.000577, step_loss=0.196]07/27/2023 18:24:54 - INFO - __main__ - train loss is 9.116160436882637\n",
      "Steps:  31%|▎| 4630/15000 [40:05<31:09,  5.55it/s, lr=0.000577, step_loss=0.004307/27/2023 18:24:55 - INFO - __main__ - train loss is 9.234170093550347\n",
      "Steps:  31%|▎| 4631/15000 [40:05<31:05,  5.56it/s, lr=0.000577, step_loss=0.118]07/27/2023 18:24:55 - INFO - __main__ - train loss is 9.287576622678898\n",
      "Steps:  31%|▎| 4632/15000 [40:05<37:44,  4.58it/s, lr=0.000577, step_loss=0.053407/27/2023 18:24:55 - INFO - __main__ - train loss is 9.292555123916827\n",
      "Steps:  31%|▎| 4633/15000 [40:06<40:23,  4.28it/s, lr=0.000577, step_loss=0.004907/27/2023 18:24:55 - INFO - __main__ - train loss is 9.319981199107133\n",
      "Steps:  31%|▎| 4634/15000 [40:06<40:12,  4.30it/s, lr=0.000578, step_loss=0.027407/27/2023 18:24:56 - INFO - __main__ - train loss is 9.362621464184485\n",
      "Steps:  31%|▎| 4635/15000 [40:06<37:35,  4.60it/s, lr=0.000578, step_loss=0.042607/27/2023 18:24:56 - INFO - __main__ - train loss is 9.61119338159915\n",
      "Steps:  31%|▎| 4636/15000 [40:06<35:41,  4.84it/s, lr=0.000578, step_loss=0.249]07/27/2023 18:24:56 - INFO - __main__ - train loss is 9.628400268382393\n",
      "Steps:  31%|▎| 4637/15000 [40:06<34:16,  5.04it/s, lr=0.000578, step_loss=0.017207/27/2023 18:24:56 - INFO - __main__ - train loss is 9.721164228743874\n",
      "Steps:  31%|▎| 4638/15000 [40:06<33:16,  5.19it/s, lr=0.000578, step_loss=0.092807/27/2023 18:24:56 - INFO - __main__ - train loss is 9.726683788816445\n",
      "Steps:  31%|▎| 4639/15000 [40:07<32:37,  5.29it/s, lr=0.000578, step_loss=0.005507/27/2023 18:24:57 - INFO - __main__ - train loss is 10.112797194044106\n",
      "Steps:  31%|▎| 4640/15000 [40:07<32:25,  5.33it/s, lr=0.000578, step_loss=0.386]07/27/2023 18:24:57 - INFO - __main__ - train loss is 10.365879260818474\n",
      "Steps:  31%|▎| 4641/15000 [40:07<32:04,  5.38it/s, lr=0.000579, step_loss=0.253]07/27/2023 18:24:57 - INFO - __main__ - train loss is 10.588546984712593\n",
      "Steps:  31%|▎| 4642/15000 [40:07<31:50,  5.42it/s, lr=0.000579, step_loss=0.223]07/27/2023 18:24:57 - INFO - __main__ - train loss is 10.616565559874289\n",
      "Steps:  31%|▎| 4643/15000 [40:07<31:46,  5.43it/s, lr=0.000579, step_loss=0.028]07/27/2023 18:24:57 - INFO - __main__ - train loss is 10.618265343597159\n",
      "Steps:  31%|▎| 4644/15000 [40:08<31:39,  5.45it/s, lr=0.000579, step_loss=0.001707/27/2023 18:24:57 - INFO - __main__ - train loss is 10.84128993540071\n",
      "Steps:  31%|▎| 4645/15000 [40:08<31:35,  5.46it/s, lr=0.000579, step_loss=0.223]07/27/2023 18:24:58 - INFO - __main__ - train loss is 10.926274416735396\n",
      "Steps:  31%|▎| 4646/15000 [40:08<31:32,  5.47it/s, lr=0.000579, step_loss=0.085]07/27/2023 18:24:58 - INFO - __main__ - train loss is 11.377909956267104\n",
      "Steps:  31%|▎| 4647/15000 [40:08<31:29,  5.48it/s, lr=0.000579, step_loss=0.452]07/27/2023 18:24:58 - INFO - __main__ - train loss is 11.444468548288569\n",
      "Steps:  31%|▎| 4648/15000 [40:08<31:27,  5.48it/s, lr=0.000579, step_loss=0.066607/27/2023 18:24:58 - INFO - __main__ - train loss is 11.491622375091538\n",
      "Steps:  31%|▎| 4649/15000 [40:08<31:26,  5.49it/s, lr=0.00058, step_loss=0.0472]07/27/2023 18:24:58 - INFO - __main__ - train loss is 11.493373725330457\n",
      "Steps:  31%|▎| 4650/15000 [40:09<31:25,  5.49it/s, lr=0.00058, step_loss=0.0017507/27/2023 18:24:59 - INFO - __main__ - train loss is 11.520852701505646\n",
      "Steps:  31%|▎| 4651/15000 [40:09<31:27,  5.48it/s, lr=0.00058, step_loss=0.0275]07/27/2023 18:24:59 - INFO - __main__ - train loss is 11.975649939617142\n",
      "Steps:  31%|▌ | 4652/15000 [40:09<31:27,  5.48it/s, lr=0.00058, step_loss=0.455]07/27/2023 18:24:59 - INFO - __main__ - train loss is 12.002368272980675\n",
      "Steps:  31%|▎| 4653/15000 [40:09<31:25,  5.49it/s, lr=0.00058, step_loss=0.0267]07/27/2023 18:24:59 - INFO - __main__ - train loss is 12.010148222791031\n",
      "Steps:  31%|▎| 4654/15000 [40:09<31:26,  5.48it/s, lr=0.00058, step_loss=0.0077807/27/2023 18:24:59 - INFO - __main__ - train loss is 12.094750995980576\n",
      "Steps:  31%|▎| 4655/15000 [40:10<31:24,  5.49it/s, lr=0.00058, step_loss=0.0846]07/27/2023 18:24:59 - INFO - __main__ - train loss is 12.209723900305107\n",
      "Steps:  31%|▌ | 4656/15000 [40:10<31:24,  5.49it/s, lr=0.00058, step_loss=0.115]07/27/2023 18:25:00 - INFO - __main__ - train loss is 12.211956933839247\n",
      "Steps:  31%|▎| 4657/15000 [40:10<31:24,  5.49it/s, lr=0.000581, step_loss=0.002207/27/2023 18:25:00 - INFO - __main__ - train loss is 12.218599940882996\n",
      "Steps:  31%|▎| 4658/15000 [40:10<31:23,  5.49it/s, lr=0.000581, step_loss=0.006607/27/2023 18:25:00 - INFO - __main__ - train loss is 12.251417047576979\n",
      "Steps:  31%|▎| 4659/15000 [40:10<31:24,  5.49it/s, lr=0.000581, step_loss=0.032807/27/2023 18:25:00 - INFO - __main__ - train loss is 12.324608466820791\n",
      "Steps:  31%|▎| 4660/15000 [40:10<31:22,  5.49it/s, lr=0.000581, step_loss=0.073207/27/2023 18:25:00 - INFO - __main__ - train loss is 12.379906020360067\n",
      "Steps:  31%|▎| 4661/15000 [40:11<31:21,  5.49it/s, lr=0.000581, step_loss=0.055307/27/2023 18:25:01 - INFO - __main__ - train loss is 12.38222434045747\n",
      "Steps:  31%|▎| 4662/15000 [40:11<31:22,  5.49it/s, lr=0.000581, step_loss=0.002307/27/2023 18:25:01 - INFO - __main__ - train loss is 12.657907683867961\n",
      "Steps:  31%|▎| 4663/15000 [40:11<31:22,  5.49it/s, lr=0.000581, step_loss=0.276]07/27/2023 18:25:01 - INFO - __main__ - train loss is 12.660544760059565\n",
      "Steps:  31%|▎| 4664/15000 [40:11<31:26,  5.48it/s, lr=0.000581, step_loss=0.002607/27/2023 18:25:01 - INFO - __main__ - train loss is 12.680028344970196\n",
      "Steps:  31%|▎| 4665/15000 [40:11<31:25,  5.48it/s, lr=0.000581, step_loss=0.019507/27/2023 18:25:01 - INFO - __main__ - train loss is 12.773421938996762\n",
      "Steps:  31%|▎| 4666/15000 [40:12<31:23,  5.49it/s, lr=0.000582, step_loss=0.093407/27/2023 18:25:01 - INFO - __main__ - train loss is 12.779835491906852\n",
      "Steps:  31%|▎| 4667/15000 [40:12<31:25,  5.48it/s, lr=0.000582, step_loss=0.006407/27/2023 18:25:02 - INFO - __main__ - train loss is 12.783634555526078\n",
      "Steps:  31%|▎| 4668/15000 [40:12<31:23,  5.49it/s, lr=0.000582, step_loss=0.003807/27/2023 18:25:02 - INFO - __main__ - train loss is 12.78976543340832\n",
      "Steps:  31%|▎| 4669/15000 [40:12<31:26,  5.48it/s, lr=0.000582, step_loss=0.006107/27/2023 18:25:02 - INFO - __main__ - train loss is 13.121064321137965\n",
      "Steps:  31%|▎| 4670/15000 [40:12<31:25,  5.48it/s, lr=0.000582, step_loss=0.331]07/27/2023 18:25:02 - INFO - __main__ - train loss is 13.792525962926447\n",
      "Steps:  31%|▎| 4671/15000 [40:12<31:24,  5.48it/s, lr=0.000582, step_loss=0.671]07/27/2023 18:25:02 - INFO - __main__ - train loss is 14.153155372478068\n",
      "Steps:  31%|▎| 4672/15000 [40:13<31:26,  5.47it/s, lr=0.000582, step_loss=0.361]07/27/2023 18:25:03 - INFO - __main__ - train loss is 14.163221643306315\n",
      "Steps:  31%|▎| 4673/15000 [40:13<31:35,  5.45it/s, lr=0.000583, step_loss=0.010107/27/2023 18:25:03 - INFO - __main__ - train loss is 14.337332979775965\n",
      "Steps:  31%|▎| 4674/15000 [40:13<31:30,  5.46it/s, lr=0.000583, step_loss=0.174]07/27/2023 18:25:03 - INFO - __main__ - train loss is 14.507288769818842\n",
      "Steps:  31%|▌ | 4675/15000 [40:13<31:43,  5.42it/s, lr=0.000583, step_loss=0.17]07/27/2023 18:25:03 - INFO - __main__ - train loss is 14.50854266854003\n",
      "Steps:  31%|▎| 4676/15000 [40:13<31:37,  5.44it/s, lr=0.000583, step_loss=0.001207/27/2023 18:25:03 - INFO - __main__ - train loss is 14.529064499307424\n",
      "Steps:  31%|▎| 4677/15000 [40:14<31:32,  5.46it/s, lr=0.000583, step_loss=0.020507/27/2023 18:25:03 - INFO - __main__ - train loss is 14.621506341267377\n",
      "Steps:  31%|▎| 4678/15000 [40:14<31:30,  5.46it/s, lr=0.000583, step_loss=0.092407/27/2023 18:25:04 - INFO - __main__ - train loss is 14.623330060392618\n",
      "Steps:  31%|▎| 4679/15000 [40:14<31:26,  5.47it/s, lr=0.000583, step_loss=0.001807/27/2023 18:25:04 - INFO - __main__ - train loss is 14.666904907673597\n",
      "Steps:  31%|▎| 4680/15000 [40:14<31:39,  5.43it/s, lr=0.000583, step_loss=0.043607/27/2023 18:25:04 - INFO - __main__ - train loss is 14.67066256236285\n",
      "Steps:  31%|▎| 4681/15000 [40:14<31:31,  5.46it/s, lr=0.000584, step_loss=0.003707/27/2023 18:25:04 - INFO - __main__ - train loss is 14.723524550907314\n",
      "Steps:  31%|▎| 4682/15000 [40:14<31:25,  5.47it/s, lr=0.000584, step_loss=0.052907/27/2023 18:25:04 - INFO - __main__ - train loss is 15.106573085300624\n",
      "Steps:  31%|▎| 4683/15000 [40:15<31:22,  5.48it/s, lr=0.000584, step_loss=0.383]07/27/2023 18:25:05 - INFO - __main__ - train loss is 15.108859985135496\n",
      "Steps:  31%|▎| 4684/15000 [40:15<31:19,  5.49it/s, lr=0.000584, step_loss=0.002207/27/2023 18:25:05 - INFO - __main__ - train loss is 15.29766423907131\n",
      "Steps:  31%|▎| 4685/15000 [40:15<31:19,  5.49it/s, lr=0.000584, step_loss=0.189]07/27/2023 18:25:05 - INFO - __main__ - train loss is 15.307456019334495\n",
      "Steps:  31%|▎| 4686/15000 [40:15<31:17,  5.49it/s, lr=0.000584, step_loss=0.009707/27/2023 18:25:05 - INFO - __main__ - train loss is 15.884047809056938\n",
      "Steps:  31%|▎| 4687/15000 [40:15<31:16,  5.50it/s, lr=0.000584, step_loss=0.577]07/27/2023 18:25:05 - INFO - __main__ - train loss is 15.906934971921146\n",
      "Steps:  31%|▎| 4688/15000 [40:16<31:15,  5.50it/s, lr=0.000584, step_loss=0.022907/27/2023 18:25:05 - INFO - __main__ - train loss is 15.987170229665935\n",
      "Steps:  31%|▎| 4689/15000 [40:16<31:14,  5.50it/s, lr=0.000585, step_loss=0.080207/27/2023 18:25:06 - INFO - __main__ - train loss is 15.988516102544963\n",
      "Steps:  31%|▎| 4690/15000 [40:16<31:13,  5.50it/s, lr=0.000585, step_loss=0.001307/27/2023 18:25:06 - INFO - __main__ - train loss is 16.07054994534701\n",
      "Steps:  31%|▎| 4691/15000 [40:16<31:13,  5.50it/s, lr=0.000585, step_loss=0.082]07/27/2023 18:25:06 - INFO - __main__ - train loss is 16.39351079892367\n",
      "Steps:  31%|▎| 4692/15000 [40:16<31:13,  5.50it/s, lr=0.000585, step_loss=0.323]07/27/2023 18:25:06 - INFO - __main__ - train loss is 16.559470037929714\n",
      "Steps:  31%|▎| 4693/15000 [40:16<31:12,  5.51it/s, lr=0.000585, step_loss=0.166]07/27/2023 18:25:06 - INFO - __main__ - train loss is 16.59621390234679\n",
      "Steps:  31%|▎| 4694/15000 [40:17<31:11,  5.51it/s, lr=0.000585, step_loss=0.036707/27/2023 18:25:07 - INFO - __main__ - train loss is 16.63820361625403\n",
      "Steps:  31%|▎| 4695/15000 [40:17<31:12,  5.50it/s, lr=0.000585, step_loss=0.042]07/27/2023 18:25:07 - INFO - __main__ - train loss is 16.641066235955805\n",
      "Steps:  31%|▎| 4696/15000 [40:17<31:12,  5.50it/s, lr=0.000585, step_loss=0.002807/27/2023 18:25:07 - INFO - __main__ - train loss is 16.918269557412714\n",
      "Steps:  31%|▎| 4697/15000 [40:17<31:11,  5.51it/s, lr=0.000586, step_loss=0.277]07/27/2023 18:25:07 - INFO - __main__ - train loss is 17.27736781304702\n",
      "Steps:  31%|▎| 4698/15000 [40:17<31:11,  5.50it/s, lr=0.000586, step_loss=0.359]07/27/2023 18:25:07 - INFO - __main__ - train loss is 17.27931124099996\n",
      "Steps:  31%|▎| 4699/15000 [40:18<31:12,  5.50it/s, lr=0.000586, step_loss=0.001907/27/2023 18:25:07 - INFO - __main__ - train loss is 17.280736203072593\n",
      "Steps:  31%|▎| 4700/15000 [40:18<31:10,  5.51it/s, lr=0.000586, step_loss=0.001407/27/2023 18:25:08 - INFO - __main__ - train loss is 17.478339100955054\n",
      "Steps:  31%|▎| 4701/15000 [40:18<31:11,  5.50it/s, lr=0.000586, step_loss=0.198]07/27/2023 18:25:08 - INFO - __main__ - train loss is 17.580753470538184\n",
      "Steps:  31%|▎| 4702/15000 [40:18<31:10,  5.50it/s, lr=0.000586, step_loss=0.102]07/27/2023 18:25:08 - INFO - __main__ - train loss is 17.82654401171021\n",
      "Steps:  31%|▎| 4703/15000 [40:18<31:12,  5.50it/s, lr=0.000586, step_loss=0.246]07/27/2023 18:25:08 - INFO - __main__ - train loss is 17.82969762920402\n",
      "Steps:  31%|▎| 4704/15000 [40:18<31:11,  5.50it/s, lr=0.000586, step_loss=0.003107/27/2023 18:25:08 - INFO - __main__ - train loss is 17.831576440948993\n",
      "Steps:  31%|▎| 4705/15000 [40:19<31:11,  5.50it/s, lr=0.000586, step_loss=0.001807/27/2023 18:25:09 - INFO - __main__ - train loss is 17.84940252872184\n",
      "Steps:  31%|▎| 4706/15000 [40:19<31:11,  5.50it/s, lr=0.000587, step_loss=0.017807/27/2023 18:25:09 - INFO - __main__ - train loss is 17.863087819423527\n",
      "Steps:  31%|▎| 4707/15000 [40:19<31:12,  5.50it/s, lr=0.000587, step_loss=0.013707/27/2023 18:25:09 - INFO - __main__ - train loss is 17.867335175629705\n",
      "Steps:  31%|▎| 4708/15000 [40:19<31:10,  5.50it/s, lr=0.000587, step_loss=0.004207/27/2023 18:25:09 - INFO - __main__ - train loss is 17.91165299108252\n",
      "Steps:  31%|▎| 4709/15000 [40:19<31:10,  5.50it/s, lr=0.000587, step_loss=0.044307/27/2023 18:25:09 - INFO - __main__ - train loss is 17.93997606402263\n",
      "Steps:  31%|▎| 4710/15000 [40:20<31:09,  5.50it/s, lr=0.000587, step_loss=0.028307/27/2023 18:25:09 - INFO - __main__ - train loss is 18.025602189358324\n",
      "Steps:  31%|▎| 4711/15000 [40:20<31:09,  5.50it/s, lr=0.000587, step_loss=0.085607/27/2023 18:25:10 - INFO - __main__ - train loss is 18.049291340168566\n",
      "Steps:  31%|▎| 4712/15000 [40:20<31:09,  5.50it/s, lr=0.000587, step_loss=0.023707/27/2023 18:25:10 - INFO - __main__ - train loss is 18.41835924750194\n",
      "Steps:  31%|▎| 4713/15000 [40:20<31:11,  5.50it/s, lr=0.000588, step_loss=0.369]07/27/2023 18:25:10 - INFO - __main__ - train loss is 18.445590583141893\n",
      "Steps:  31%|▎| 4714/15000 [40:20<31:10,  5.50it/s, lr=0.000588, step_loss=0.027207/27/2023 18:25:10 - INFO - __main__ - train loss is 18.479244602378458\n",
      "Steps:  31%|▎| 4715/15000 [40:20<31:10,  5.50it/s, lr=0.000588, step_loss=0.033707/27/2023 18:25:10 - INFO - __main__ - train loss is 18.505806546192616\n",
      "Steps:  31%|▎| 4716/15000 [40:21<31:09,  5.50it/s, lr=0.000588, step_loss=0.026607/27/2023 18:25:11 - INFO - __main__ - train loss is 18.55362670822069\n",
      "Steps:  31%|▎| 4717/15000 [40:21<31:10,  5.50it/s, lr=0.000588, step_loss=0.047807/27/2023 18:25:11 - INFO - __main__ - train loss is 19.03824996156618\n",
      "Steps:  31%|▎| 4718/15000 [40:21<31:10,  5.50it/s, lr=0.000588, step_loss=0.485]07/27/2023 18:25:11 - INFO - __main__ - train loss is 19.04327518772334\n",
      "Steps:  31%|▎| 4719/15000 [40:21<31:08,  5.50it/s, lr=0.000588, step_loss=0.005007/27/2023 18:25:11 - INFO - __main__ - train loss is 19.198692108504474\n",
      "Steps:  31%|▎| 4720/15000 [40:21<31:08,  5.50it/s, lr=0.000588, step_loss=0.155]07/27/2023 18:25:11 - INFO - __main__ - train loss is 19.508076961152256\n",
      "Steps:  31%|▎| 4721/15000 [40:22<31:08,  5.50it/s, lr=0.000589, step_loss=0.309]07/27/2023 18:25:11 - INFO - __main__ - train loss is 19.523196812719107\n",
      "Steps:  31%|▎| 4722/15000 [40:22<31:07,  5.50it/s, lr=0.000589, step_loss=0.015107/27/2023 18:25:12 - INFO - __main__ - train loss is 19.552413627505302\n",
      "Steps:  31%|▎| 4723/15000 [40:22<31:07,  5.50it/s, lr=0.000589, step_loss=0.029207/27/2023 18:25:12 - INFO - __main__ - train loss is 19.89145414531231\n",
      "Steps:  31%|▎| 4724/15000 [40:22<31:07,  5.50it/s, lr=0.000589, step_loss=0.339]07/27/2023 18:25:12 - INFO - __main__ - train loss is 19.921860091388226\n",
      "Steps:  32%|▎| 4725/15000 [40:22<31:07,  5.50it/s, lr=0.000589, step_loss=0.030407/27/2023 18:25:12 - INFO - __main__ - train loss is 20.621495954692364\n",
      "Steps:  32%|▉  | 4726/15000 [40:22<31:07,  5.50it/s, lr=0.000589, step_loss=0.7]07/27/2023 18:25:12 - INFO - __main__ - train loss is 20.63273147493601\n",
      "Steps:  32%|▎| 4727/15000 [40:23<31:07,  5.50it/s, lr=0.000589, step_loss=0.011207/27/2023 18:25:13 - INFO - __main__ - train loss is 20.93460164219141\n",
      "Steps:  32%|▎| 4728/15000 [40:23<31:06,  5.50it/s, lr=0.000589, step_loss=0.302]07/27/2023 18:25:13 - INFO - __main__ - train loss is 20.953935340046883\n",
      "Steps:  32%|▎| 4729/15000 [40:23<31:06,  5.50it/s, lr=0.00059, step_loss=0.0193]07/27/2023 18:25:13 - INFO - __main__ - train loss is 21.088519632816315\n",
      "Steps:  32%|▋ | 4730/15000 [40:23<31:05,  5.51it/s, lr=0.00059, step_loss=0.135]07/27/2023 18:25:13 - INFO - __main__ - train loss is 21.09103071456775\n",
      "Steps:  32%|▎| 4731/15000 [40:23<31:06,  5.50it/s, lr=0.00059, step_loss=0.0025107/27/2023 18:25:13 - INFO - __main__ - train loss is 21.33995342021808\n",
      "Steps:  32%|▋ | 4732/15000 [40:24<31:06,  5.50it/s, lr=0.00059, step_loss=0.249]07/27/2023 18:25:13 - INFO - __main__ - train loss is 21.608896312769502\n",
      "Steps:  32%|▋ | 4733/15000 [40:24<31:05,  5.50it/s, lr=0.00059, step_loss=0.269]07/27/2023 18:25:14 - INFO - __main__ - train loss is 21.640806039329618\n",
      "Steps:  32%|▎| 4734/15000 [40:24<31:05,  5.50it/s, lr=0.00059, step_loss=0.0319]07/27/2023 18:25:14 - INFO - __main__ - train loss is 22.48476012563333\n",
      "Steps:  32%|▋ | 4735/15000 [40:24<31:05,  5.50it/s, lr=0.00059, step_loss=0.844]07/27/2023 18:25:14 - INFO - __main__ - train loss is 22.498996368143708\n",
      "Steps:  32%|▎| 4736/15000 [40:24<31:22,  5.45it/s, lr=0.00059, step_loss=0.0142]07/27/2023 18:25:14 - INFO - __main__ - train loss is 22.66964069614187\n",
      "Steps:  32%|▋ | 4737/15000 [40:24<31:36,  5.41it/s, lr=0.00059, step_loss=0.171]07/27/2023 18:25:14 - INFO - __main__ - train loss is 22.69097231933847\n",
      "Steps:  32%|▎| 4738/15000 [40:25<31:36,  5.41it/s, lr=0.000591, step_loss=0.021307/27/2023 18:25:15 - INFO - __main__ - train loss is 22.693405092693865\n",
      "Steps:  32%|▎| 4739/15000 [40:25<31:20,  5.46it/s, lr=0.000591, step_loss=0.002407/27/2023 18:25:15 - INFO - __main__ - train loss is 22.744612582959235\n",
      "Steps:  32%|▎| 4740/15000 [40:25<31:13,  5.48it/s, lr=0.000591, step_loss=0.051207/27/2023 18:25:15 - INFO - __main__ - train loss is 22.90565384272486\n",
      "Steps:  32%|▎| 4741/15000 [40:25<31:03,  5.51it/s, lr=0.000591, step_loss=0.161]07/27/2023 18:25:15 - INFO - __main__ - train loss is 22.919233742170036\n",
      "Steps:  32%|▎| 4742/15000 [40:25<31:02,  5.51it/s, lr=0.000591, step_loss=0.013607/27/2023 18:25:15 - INFO - __main__ - train loss is 22.921467596199363\n",
      "Steps:  32%|▎| 4743/15000 [40:26<30:56,  5.52it/s, lr=0.000591, step_loss=0.002207/27/2023 18:25:15 - INFO - __main__ - train loss is 23.076674127485603\n",
      "Steps:  32%|▎| 4744/15000 [40:26<30:52,  5.54it/s, lr=0.000591, step_loss=0.155]07/27/2023 18:25:16 - INFO - __main__ - train loss is 23.08048057067208\n",
      "Steps:  32%|▎| 4745/15000 [40:26<30:51,  5.54it/s, lr=0.000592, step_loss=0.003807/27/2023 18:25:16 - INFO - __main__ - train loss is 23.244454870698974\n",
      "Steps:  32%|▎| 4746/15000 [40:26<30:48,  5.55it/s, lr=0.000592, step_loss=0.164]07/27/2023 18:25:16 - INFO - __main__ - train loss is 23.338529894826934\n",
      "Steps:  32%|▎| 4747/15000 [40:26<30:45,  5.56it/s, lr=0.000592, step_loss=0.094107/27/2023 18:25:16 - INFO - __main__ - train loss is 23.59008706617169\n",
      "Steps:  32%|▎| 4748/15000 [40:26<30:42,  5.56it/s, lr=0.000592, step_loss=0.252]07/27/2023 18:25:16 - INFO - __main__ - train loss is 23.59160821151454\n",
      "Steps:  32%|▎| 4749/15000 [40:27<30:41,  5.57it/s, lr=0.000592, step_loss=0.001507/27/2023 18:25:17 - INFO - __main__ - train loss is 23.77106319379527\n",
      "Steps:  32%|▎| 4750/15000 [40:27<30:39,  5.57it/s, lr=0.000592, step_loss=0.179]07/27/2023 18:25:17 - INFO - __main__ - train loss is 23.773523306590505\n",
      "Steps:  32%|▎| 4751/15000 [40:27<30:38,  5.57it/s, lr=0.000592, step_loss=0.002407/27/2023 18:25:17 - INFO - __main__ - train loss is 24.00558852229733\n",
      "Steps:  32%|▎| 4752/15000 [40:27<30:38,  5.57it/s, lr=0.000592, step_loss=0.232]07/27/2023 18:25:17 - INFO - __main__ - train loss is 24.269530793768354\n",
      "Steps:  32%|▎| 4753/15000 [40:27<30:37,  5.58it/s, lr=0.000593, step_loss=0.264]07/27/2023 18:25:17 - INFO - __main__ - train loss is 24.347379101556726\n",
      "Steps:  32%|▎| 4754/15000 [40:28<30:37,  5.58it/s, lr=0.000593, step_loss=0.077807/27/2023 18:25:17 - INFO - __main__ - train loss is 24.34933601494413\n",
      "Steps:  32%|▎| 4755/15000 [40:28<30:37,  5.58it/s, lr=0.000593, step_loss=0.001907/27/2023 18:25:18 - INFO - __main__ - train loss is 24.388573119300418\n",
      "Steps:  32%|▎| 4756/15000 [40:28<30:37,  5.58it/s, lr=0.000593, step_loss=0.039207/27/2023 18:25:18 - INFO - __main__ - train loss is 24.63958028878551\n",
      "Steps:  32%|▎| 4757/15000 [40:28<30:37,  5.57it/s, lr=0.000593, step_loss=0.251]07/27/2023 18:25:18 - INFO - __main__ - train loss is 24.879817942040972\n",
      "Steps:  32%|▋ | 4758/15000 [40:28<30:36,  5.58it/s, lr=0.000593, step_loss=0.24]07/27/2023 18:25:18 - INFO - __main__ - train loss is 24.88435066572856\n",
      "Steps:  32%|▎| 4759/15000 [40:28<30:36,  5.58it/s, lr=0.000593, step_loss=0.004507/27/2023 18:25:18 - INFO - __main__ - train loss is 24.93207728944253\n",
      "Steps:  32%|▎| 4760/15000 [40:29<30:36,  5.58it/s, lr=0.000593, step_loss=0.047707/27/2023 18:25:19 - INFO - __main__ - train loss is 24.979917012969963\n",
      "Steps:  32%|▎| 4761/15000 [40:29<30:35,  5.58it/s, lr=0.000594, step_loss=0.047807/27/2023 18:25:19 - INFO - __main__ - train loss is 24.988305352511816\n",
      "Steps:  32%|▎| 4762/15000 [40:29<30:34,  5.58it/s, lr=0.000594, step_loss=0.008307/27/2023 18:25:19 - INFO - __main__ - train loss is 25.224029235425405\n",
      "Steps:  32%|▎| 4763/15000 [40:29<30:34,  5.58it/s, lr=0.000594, step_loss=0.236]07/27/2023 18:25:19 - INFO - __main__ - train loss is 25.286549173179083\n",
      "Steps:  32%|▎| 4764/15000 [40:29<30:33,  5.58it/s, lr=0.000594, step_loss=0.062507/27/2023 18:25:19 - INFO - __main__ - train loss is 25.365709446254186\n",
      "Steps:  32%|▎| 4765/15000 [40:30<30:34,  5.58it/s, lr=0.000594, step_loss=0.079207/27/2023 18:25:19 - INFO - __main__ - train loss is 25.366968833375722\n",
      "Steps:  32%|▎| 4766/15000 [40:30<30:34,  5.58it/s, lr=0.000594, step_loss=0.001207/27/2023 18:25:20 - INFO - __main__ - train loss is 25.408859722781926\n",
      "Steps:  32%|▎| 4767/15000 [40:30<30:36,  5.57it/s, lr=0.000594, step_loss=0.041907/27/2023 18:25:20 - INFO - __main__ - train loss is 25.577093653846532\n",
      "Steps:  32%|▎| 4768/15000 [40:30<30:36,  5.57it/s, lr=0.000594, step_loss=0.168]07/27/2023 18:25:20 - INFO - __main__ - train loss is 25.57986150844954\n",
      "Steps:  32%|▎| 4769/15000 [40:30<30:35,  5.57it/s, lr=0.000595, step_loss=0.002707/27/2023 18:25:20 - INFO - __main__ - train loss is 25.710637824377045\n",
      "Steps:  32%|▎| 4770/15000 [40:30<30:36,  5.57it/s, lr=0.000595, step_loss=0.131]07/27/2023 18:25:20 - INFO - __main__ - train loss is 26.035122917732224\n",
      "Steps:  32%|▎| 4771/15000 [40:31<30:36,  5.57it/s, lr=0.000595, step_loss=0.324]07/27/2023 18:25:20 - INFO - __main__ - train loss is 26.38857583864592\n",
      "Steps:  32%|▎| 4772/15000 [40:31<30:42,  5.55it/s, lr=0.000595, step_loss=0.353]07/27/2023 18:25:21 - INFO - __main__ - train loss is 26.40105366311036\n",
      "Steps:  32%|▎| 4773/15000 [40:31<30:39,  5.56it/s, lr=0.000595, step_loss=0.012507/27/2023 18:25:21 - INFO - __main__ - train loss is 26.552291121101007\n",
      "Steps:  32%|▎| 4774/15000 [40:31<30:38,  5.56it/s, lr=0.000595, step_loss=0.151]07/27/2023 18:25:21 - INFO - __main__ - train loss is 26.777314897393808\n",
      "Steps:  32%|▎| 4775/15000 [40:31<30:40,  5.55it/s, lr=0.000595, step_loss=0.225]07/27/2023 18:25:21 - INFO - __main__ - train loss is 26.77919412171468\n",
      "Steps:  32%|▎| 4776/15000 [40:32<30:41,  5.55it/s, lr=0.000595, step_loss=0.001807/27/2023 18:25:21 - INFO - __main__ - train loss is 26.901637328322977\n",
      "Steps:  32%|▎| 4777/15000 [40:32<30:43,  5.55it/s, lr=0.000596, step_loss=0.122]07/27/2023 18:25:22 - INFO - __main__ - train loss is 27.187221182044595\n",
      "Steps:  32%|▎| 4778/15000 [40:32<30:52,  5.52it/s, lr=0.000596, step_loss=0.286]07/27/2023 18:25:22 - INFO - __main__ - train loss is 27.388334525283426\n",
      "Steps:  32%|▎| 4779/15000 [40:32<30:46,  5.53it/s, lr=0.000596, step_loss=0.201]07/27/2023 18:25:22 - INFO - __main__ - train loss is 27.927606416400522\n",
      "Steps:  32%|▎| 4780/15000 [40:32<30:43,  5.55it/s, lr=0.000596, step_loss=0.539]07/27/2023 18:25:22 - INFO - __main__ - train loss is 28.16084606712684\n",
      "Steps:  32%|▎| 4781/15000 [40:32<30:40,  5.55it/s, lr=0.000596, step_loss=0.233]07/27/2023 18:25:22 - INFO - __main__ - train loss is 28.630769652780145\n",
      "Steps:  32%|▋ | 4782/15000 [40:33<30:40,  5.55it/s, lr=0.000596, step_loss=0.47]07/27/2023 18:25:22 - INFO - __main__ - train loss is 28.64611523086205\n",
      "Steps:  32%|▎| 4783/15000 [40:33<30:37,  5.56it/s, lr=0.000596, step_loss=0.015307/27/2023 18:25:23 - INFO - __main__ - train loss is 28.683304543141276\n",
      "Steps:  32%|▎| 4784/15000 [40:33<30:40,  5.55it/s, lr=0.000596, step_loss=0.037207/27/2023 18:25:23 - INFO - __main__ - train loss is 28.712344525847584\n",
      "Steps:  32%|▎| 4785/15000 [40:33<30:37,  5.56it/s, lr=0.000597, step_loss=0.029]07/27/2023 18:25:23 - INFO - __main__ - train loss is 28.713781730853952\n",
      "Steps:  32%|▎| 4786/15000 [40:33<30:40,  5.55it/s, lr=0.000597, step_loss=0.001407/27/2023 18:25:23 - INFO - __main__ - train loss is 28.744015479111113\n",
      "Steps:  32%|▎| 4787/15000 [40:33<30:37,  5.56it/s, lr=0.000597, step_loss=0.030207/27/2023 18:25:23 - INFO - __main__ - train loss is 28.747232592548244\n",
      "Steps:  32%|▎| 4788/15000 [40:34<30:35,  5.56it/s, lr=0.000597, step_loss=0.003207/27/2023 18:25:24 - INFO - __main__ - train loss is 28.838766394997947\n",
      "Steps:  32%|▎| 4789/15000 [40:34<30:35,  5.56it/s, lr=0.000597, step_loss=0.091507/27/2023 18:25:24 - INFO - __main__ - train loss is 28.877141977543943\n",
      "Steps:  32%|▎| 4790/15000 [40:34<30:32,  5.57it/s, lr=0.000597, step_loss=0.038407/27/2023 18:25:24 - INFO - __main__ - train loss is 29.5435961735202\n",
      "Steps:  32%|▎| 4791/15000 [40:34<30:36,  5.56it/s, lr=0.000597, step_loss=0.666]07/27/2023 18:25:24 - INFO - __main__ - train loss is 29.572404592181556\n",
      "Steps:  32%|▎| 4792/15000 [40:34<30:33,  5.57it/s, lr=0.000597, step_loss=0.028807/27/2023 18:25:24 - INFO - __main__ - train loss is 29.586871812934987\n",
      "Steps:  32%|▎| 4793/15000 [40:35<30:38,  5.55it/s, lr=0.000598, step_loss=0.014507/27/2023 18:25:24 - INFO - __main__ - train loss is 29.688609043951146\n",
      "Steps:  32%|▎| 4794/15000 [40:35<30:37,  5.55it/s, lr=0.000598, step_loss=0.102]07/27/2023 18:25:25 - INFO - __main__ - train loss is 29.690954598947428\n",
      "Steps:  32%|▎| 4795/15000 [40:35<30:53,  5.51it/s, lr=0.000598, step_loss=0.002307/27/2023 18:25:25 - INFO - __main__ - train loss is 29.959029171033762\n",
      "Steps:  32%|▎| 4796/15000 [40:35<30:52,  5.51it/s, lr=0.000598, step_loss=0.268]07/27/2023 18:25:25 - INFO - __main__ - train loss is 29.96052761701867\n",
      "Steps:  32%|▎| 4797/15000 [40:35<30:47,  5.52it/s, lr=0.000598, step_loss=0.001507/27/2023 18:25:25 - INFO - __main__ - train loss is 30.61213209060952\n",
      "Steps:  32%|▎| 4798/15000 [40:35<30:43,  5.54it/s, lr=0.000598, step_loss=0.652]07/27/2023 18:25:25 - INFO - __main__ - train loss is 30.637439544778317\n",
      "Steps:  32%|▎| 4799/15000 [40:36<30:40,  5.54it/s, lr=0.000598, step_loss=0.025307/27/2023 18:25:26 - INFO - __main__ - train loss is 30.72727195499465\n",
      "Steps:  32%|▎| 4800/15000 [40:36<30:38,  5.55it/s, lr=0.000598, step_loss=0.089807/27/2023 18:25:26 - INFO - __main__ - train loss is 31.214045386295766\n",
      "Steps:  32%|▎| 4801/15000 [40:36<30:48,  5.52it/s, lr=0.000599, step_loss=0.487]07/27/2023 18:25:26 - INFO - __main__ - train loss is 31.251044626813382\n",
      "Steps:  32%|▎| 4802/15000 [40:36<30:42,  5.54it/s, lr=0.000599, step_loss=0.037]07/27/2023 18:25:26 - INFO - __main__ - train loss is 31.325380738358945\n",
      "Steps:  32%|▎| 4803/15000 [40:36<30:39,  5.54it/s, lr=0.000599, step_loss=0.074307/27/2023 18:25:26 - INFO - __main__ - train loss is 31.44194522080943\n",
      "Steps:  32%|▎| 4804/15000 [40:37<30:37,  5.55it/s, lr=0.000599, step_loss=0.117]07/27/2023 18:25:26 - INFO - __main__ - train loss is 31.452567172702402\n",
      "Steps:  32%|▎| 4805/15000 [40:37<30:35,  5.55it/s, lr=0.000599, step_loss=0.010607/27/2023 18:25:27 - INFO - __main__ - train loss is 31.525698719080538\n",
      "Steps:  32%|▎| 4806/15000 [40:37<30:47,  5.52it/s, lr=0.000599, step_loss=0.073107/27/2023 18:25:27 - INFO - __main__ - train loss is 32.041490075644106\n",
      "Steps:  32%|▎| 4807/15000 [40:37<30:41,  5.54it/s, lr=0.000599, step_loss=0.516]07/27/2023 18:25:27 - INFO - __main__ - train loss is 32.26775994664058\n",
      "Steps:  32%|▎| 4808/15000 [40:37<30:41,  5.53it/s, lr=0.000599, step_loss=0.226]07/27/2023 18:25:27 - INFO - __main__ - train loss is 32.47323076194152\n",
      "Steps:  32%|▉  | 4809/15000 [40:37<30:54,  5.50it/s, lr=0.0006, step_loss=0.205]07/27/2023 18:25:27 - INFO - __main__ - train loss is 32.60948250954971\n",
      "Steps:  32%|▉  | 4810/15000 [40:38<31:05,  5.46it/s, lr=0.0006, step_loss=0.136]07/27/2023 18:25:28 - INFO - __main__ - train loss is 32.690457162912935\n",
      "Steps:  32%|▉  | 4811/15000 [40:38<31:21,  5.42it/s, lr=0.0006, step_loss=0.081]07/27/2023 18:25:28 - INFO - __main__ - train loss is 32.71687883650884\n",
      "Steps:  32%|▋ | 4812/15000 [40:38<31:58,  5.31it/s, lr=0.0006, step_loss=0.0264]07/27/2023 18:25:28 - INFO - __main__ - train loss is 33.33135992800817\n",
      "Steps:  32%|▉  | 4813/15000 [40:38<32:25,  5.24it/s, lr=0.0006, step_loss=0.614]07/27/2023 18:25:28 - INFO - __main__ - train loss is 33.69530323660001\n",
      "Steps:  32%|▉  | 4814/15000 [40:38<32:07,  5.28it/s, lr=0.0006, step_loss=0.364]07/27/2023 18:25:28 - INFO - __main__ - train loss is 33.72058447590098\n",
      "Steps:  32%|▋ | 4815/15000 [40:39<31:54,  5.32it/s, lr=0.0006, step_loss=0.0253]07/27/2023 18:25:28 - INFO - __main__ - train loss is 34.042353534605354\n",
      "Steps:  32%|▉  | 4816/15000 [40:39<31:54,  5.32it/s, lr=0.0006, step_loss=0.322]07/27/2023 18:25:29 - INFO - __main__ - train loss is 34.76289513101801\n",
      "Steps:  32%|▎| 4817/15000 [40:39<32:14,  5.26it/s, lr=0.000601, step_loss=0.721]07/27/2023 18:25:29 - INFO - __main__ - train loss is 34.77711374824867\n",
      "Steps:  32%|▎| 4818/15000 [40:39<32:30,  5.22it/s, lr=0.000601, step_loss=0.014207/27/2023 18:25:29 - INFO - __main__ - train loss is 34.789767366368324\n",
      "Steps:  32%|▎| 4819/15000 [40:39<32:44,  5.18it/s, lr=0.000601, step_loss=0.012707/27/2023 18:25:29 - INFO - __main__ - train loss is 34.83484742837027\n",
      "Steps:  32%|▎| 4820/15000 [40:40<32:48,  5.17it/s, lr=0.000601, step_loss=0.045107/27/2023 18:25:29 - INFO - __main__ - train loss is 34.842502298764884\n",
      "Steps:  32%|▎| 4821/15000 [40:40<32:51,  5.16it/s, lr=0.000601, step_loss=0.007607/27/2023 18:25:30 - INFO - __main__ - train loss is 34.846834337338805\n",
      "Steps:  32%|▎| 4822/15000 [40:40<32:53,  5.16it/s, lr=0.000601, step_loss=0.004307/27/2023 18:25:30 - INFO - __main__ - train loss is 35.23694077692926\n",
      "Steps:  32%|▋ | 4823/15000 [40:40<33:32,  5.06it/s, lr=0.000601, step_loss=0.39]07/27/2023 18:25:30 - INFO - __main__ - train loss is 35.68423376046121\n",
      "Steps:  32%|▎| 4824/15000 [40:40<33:35,  5.05it/s, lr=0.000601, step_loss=0.447]07/27/2023 18:25:30 - INFO - __main__ - train loss is 35.9303630348295\n",
      "Steps:  32%|▎| 4825/15000 [40:41<33:22,  5.08it/s, lr=0.000602, step_loss=0.246]07/27/2023 18:25:30 - INFO - __main__ - train loss is 35.93416876764968\n",
      "Steps:  32%|▎| 4826/15000 [40:41<33:15,  5.10it/s, lr=0.000602, step_loss=0.003807/27/2023 18:25:31 - INFO - __main__ - train loss is 35.954796579200774\n",
      "Steps:  32%|▎| 4827/15000 [40:41<33:10,  5.11it/s, lr=0.000602, step_loss=0.020607/27/2023 18:25:31 - INFO - __main__ - train loss is 35.96698723407462\n",
      "Steps:  32%|▎| 4828/15000 [40:41<33:06,  5.12it/s, lr=0.000602, step_loss=0.012207/27/2023 18:25:31 - INFO - __main__ - train loss is 36.67345861764625\n",
      "Steps:  32%|▎| 4829/15000 [40:41<33:04,  5.13it/s, lr=0.000602, step_loss=0.706]07/27/2023 18:25:31 - INFO - __main__ - train loss is 36.84351743431762\n",
      "Steps:  32%|▋ | 4830/15000 [40:42<33:02,  5.13it/s, lr=0.000602, step_loss=0.17]07/27/2023 18:25:31 - INFO - __main__ - train loss is 36.90634649666026\n",
      "Steps:  32%|▎| 4831/15000 [40:42<33:02,  5.13it/s, lr=0.000602, step_loss=0.062807/27/2023 18:25:32 - INFO - __main__ - train loss is 36.93668969394639\n",
      "Steps:  32%|▎| 4832/15000 [40:42<33:02,  5.13it/s, lr=0.000602, step_loss=0.030307/27/2023 18:25:32 - INFO - __main__ - train loss is 36.95802433276549\n",
      "Steps:  32%|▎| 4833/15000 [40:42<33:02,  5.13it/s, lr=0.000603, step_loss=0.021307/27/2023 18:25:32 - INFO - __main__ - train loss is 37.06270659947768\n",
      "Steps:  32%|▎| 4834/15000 [40:42<33:07,  5.12it/s, lr=0.000603, step_loss=0.105]07/27/2023 18:25:32 - INFO - __main__ - train loss is 37.07391945132986\n",
      "Steps:  32%|▎| 4835/15000 [40:43<33:03,  5.13it/s, lr=0.000603, step_loss=0.011207/27/2023 18:25:32 - INFO - __main__ - train loss is 37.077094002394006\n",
      "Steps:  32%|▎| 4836/15000 [40:43<33:01,  5.13it/s, lr=0.000603, step_loss=0.003107/27/2023 18:25:33 - INFO - __main__ - train loss is 37.0851735889446\n",
      "Steps:  32%|▎| 4837/15000 [40:43<33:00,  5.13it/s, lr=0.000603, step_loss=0.008007/27/2023 18:25:33 - INFO - __main__ - train loss is 37.28339291806333\n",
      "Steps:  32%|▎| 4838/15000 [40:43<32:58,  5.14it/s, lr=0.000603, step_loss=0.198]07/27/2023 18:25:33 - INFO - __main__ - train loss is 37.28730748896487\n",
      "Steps:  32%|▎| 4839/15000 [40:43<32:55,  5.14it/s, lr=0.000603, step_loss=0.003907/27/2023 18:25:33 - INFO - __main__ - train loss is 37.294807927450165\n",
      "Steps:  32%|▎| 4840/15000 [40:43<32:56,  5.14it/s, lr=0.000603, step_loss=0.007507/27/2023 18:25:33 - INFO - __main__ - train loss is 37.861134426435456\n",
      "Steps:  32%|▎| 4841/15000 [40:44<33:03,  5.12it/s, lr=0.000604, step_loss=0.566]07/27/2023 18:25:34 - INFO - __main__ - train loss is 37.86668686685152\n",
      "Steps:  32%|▎| 4842/15000 [40:44<33:03,  5.12it/s, lr=0.000604, step_loss=0.005507/27/2023 18:25:34 - INFO - __main__ - train loss is 38.00102311489172\n",
      "Steps:  32%|▎| 4843/15000 [40:44<33:02,  5.12it/s, lr=0.000604, step_loss=0.134]07/27/2023 18:25:34 - INFO - __main__ - train loss is 38.00248282752\n",
      "Steps:  32%|▎| 4844/15000 [40:44<33:06,  5.11it/s, lr=0.000604, step_loss=0.001407/27/2023 18:25:34 - INFO - __main__ - train loss is 38.206186946248636\n",
      "Steps:  32%|▎| 4845/15000 [40:44<33:06,  5.11it/s, lr=0.000604, step_loss=0.204]07/27/2023 18:25:34 - INFO - __main__ - train loss is 38.52698748908006\n",
      "Steps:  32%|▎| 4846/15000 [40:45<32:54,  5.14it/s, lr=0.000604, step_loss=0.321]07/27/2023 18:25:35 - INFO - __main__ - train loss is 38.64114772132598\n",
      "Steps:  32%|▎| 4847/15000 [40:45<32:30,  5.20it/s, lr=0.000604, step_loss=0.114]07/27/2023 18:25:35 - INFO - __main__ - train loss is 38.72314925841056\n",
      "Steps:  32%|▎| 4848/15000 [40:45<43:32,  3.89it/s, lr=0.000604, step_loss=0.082]07/27/2023 18:25:36 - INFO - __main__ - Per validation step average loss is 0.005660483613610268\n",
      "07/27/2023 18:25:36 - INFO - __main__ - Cumulative validation average loss is 0.005660483613610268\n",
      "07/27/2023 18:25:36 - INFO - __main__ - Per validation step average loss is 0.1682087779045105\n",
      "07/27/2023 18:25:36 - INFO - __main__ - Cumulative validation average loss is 0.17386926151812077\n",
      "07/27/2023 18:25:37 - INFO - __main__ - Per validation step average loss is 0.10363759845495224\n",
      "07/27/2023 18:25:37 - INFO - __main__ - Cumulative validation average loss is 0.277506859973073\n",
      "07/27/2023 18:25:37 - INFO - __main__ - Per validation step average loss is 0.001648683100938797\n",
      "07/27/2023 18:25:37 - INFO - __main__ - Cumulative validation average loss is 0.2791555430740118\n",
      "07/27/2023 18:25:38 - INFO - __main__ - Per validation step average loss is 0.0771554633975029\n",
      "07/27/2023 18:25:38 - INFO - __main__ - Cumulative validation average loss is 0.3563110064715147\n",
      "07/27/2023 18:25:38 - INFO - __main__ - Per validation step average loss is 0.16696485877037048\n",
      "07/27/2023 18:25:38 - INFO - __main__ - Cumulative validation average loss is 0.5232758652418852\n",
      "07/27/2023 18:25:38 - INFO - __main__ - Per validation step average loss is 0.017806123942136765\n",
      "07/27/2023 18:25:38 - INFO - __main__ - Cumulative validation average loss is 0.541081989184022\n",
      "07/27/2023 18:25:39 - INFO - __main__ - Per validation step average loss is 0.015956314280629158\n",
      "07/27/2023 18:25:39 - INFO - __main__ - Cumulative validation average loss is 0.5570383034646511\n",
      "07/27/2023 18:25:39 - INFO - __main__ - Per validation step average loss is 0.04194473475217819\n",
      "07/27/2023 18:25:39 - INFO - __main__ - Cumulative validation average loss is 0.5989830382168293\n",
      "07/27/2023 18:25:40 - INFO - __main__ - Per validation step average loss is 0.23359958827495575\n",
      "07/27/2023 18:25:40 - INFO - __main__ - Cumulative validation average loss is 0.832582626491785\n",
      "07/27/2023 18:25:40 - INFO - __main__ - Per validation step average loss is 0.5535517334938049\n",
      "07/27/2023 18:25:40 - INFO - __main__ - Cumulative validation average loss is 1.38613435998559\n",
      "07/27/2023 18:25:40 - INFO - __main__ - Per validation step average loss is 0.14159291982650757\n",
      "07/27/2023 18:25:40 - INFO - __main__ - Cumulative validation average loss is 1.5277272798120975\n",
      "07/27/2023 18:25:41 - INFO - __main__ - Per validation step average loss is 0.40233731269836426\n",
      "07/27/2023 18:25:41 - INFO - __main__ - Cumulative validation average loss is 1.9300645925104618\n",
      "07/27/2023 18:25:41 - INFO - __main__ - Per validation step average loss is 0.5153290629386902\n",
      "07/27/2023 18:25:41 - INFO - __main__ - Cumulative validation average loss is 2.445393655449152\n",
      "07/27/2023 18:25:42 - INFO - __main__ - Per validation step average loss is 0.018738485872745514\n",
      "07/27/2023 18:25:42 - INFO - __main__ - Cumulative validation average loss is 2.4641321413218975\n",
      "07/27/2023 18:25:42 - INFO - __main__ - Per validation step average loss is 0.11533212661743164\n",
      "07/27/2023 18:25:42 - INFO - __main__ - Cumulative validation average loss is 2.579464267939329\n",
      "07/27/2023 18:25:43 - INFO - __main__ - Per validation step average loss is 0.019547991454601288\n",
      "07/27/2023 18:25:43 - INFO - __main__ - Cumulative validation average loss is 2.5990122593939304\n",
      "07/27/2023 18:25:43 - INFO - __main__ - Per validation step average loss is 0.8847168684005737\n",
      "07/27/2023 18:25:43 - INFO - __main__ - Cumulative validation average loss is 3.483729127794504\n",
      "07/27/2023 18:25:43 - INFO - __main__ - Per validation step average loss is 0.13106533885002136\n",
      "07/27/2023 18:25:43 - INFO - __main__ - Cumulative validation average loss is 3.6147944666445255\n",
      "07/27/2023 18:25:44 - INFO - __main__ - Per validation step average loss is 0.05784037709236145\n",
      "07/27/2023 18:25:44 - INFO - __main__ - Cumulative validation average loss is 3.672634843736887\n",
      "07/27/2023 18:25:44 - INFO - __main__ - Per validation step average loss is 0.4080007076263428\n",
      "07/27/2023 18:25:44 - INFO - __main__ - Cumulative validation average loss is 4.08063555136323\n",
      "07/27/2023 18:25:45 - INFO - __main__ - Per validation step average loss is 0.19586317241191864\n",
      "07/27/2023 18:25:45 - INFO - __main__ - Cumulative validation average loss is 4.276498723775148\n",
      "07/27/2023 18:25:45 - INFO - __main__ - Per validation step average loss is 0.1681395322084427\n",
      "07/27/2023 18:25:45 - INFO - __main__ - Cumulative validation average loss is 4.444638255983591\n",
      "07/27/2023 18:25:45 - INFO - __main__ - Per validation step average loss is 0.23803573846817017\n",
      "07/27/2023 18:25:45 - INFO - __main__ - Cumulative validation average loss is 4.682673994451761\n",
      "07/27/2023 18:25:46 - INFO - __main__ - Per validation step average loss is 0.3467852473258972\n",
      "07/27/2023 18:25:46 - INFO - __main__ - Cumulative validation average loss is 5.0294592417776585\n",
      "07/27/2023 18:25:46 - INFO - __main__ - Per validation step average loss is 0.12556807696819305\n",
      "07/27/2023 18:25:46 - INFO - __main__ - Cumulative validation average loss is 5.1550273187458515\n",
      "07/27/2023 18:25:47 - INFO - __main__ - Per validation step average loss is 0.002076669130474329\n",
      "07/27/2023 18:25:47 - INFO - __main__ - Cumulative validation average loss is 5.157103987876326\n",
      "07/27/2023 18:25:47 - INFO - __main__ - Per validation step average loss is 0.051292192190885544\n",
      "07/27/2023 18:25:47 - INFO - __main__ - Cumulative validation average loss is 5.208396180067211\n",
      "07/27/2023 18:25:47 - INFO - __main__ - Per validation step average loss is 0.10556314885616302\n",
      "07/27/2023 18:25:47 - INFO - __main__ - Cumulative validation average loss is 5.313959328923374\n",
      "07/27/2023 18:25:48 - INFO - __main__ - Per validation step average loss is 0.3787418007850647\n",
      "07/27/2023 18:25:48 - INFO - __main__ - Cumulative validation average loss is 5.692701129708439\n",
      "07/27/2023 18:25:48 - INFO - __main__ - Per validation step average loss is 0.09616390615701675\n",
      "07/27/2023 18:25:48 - INFO - __main__ - Cumulative validation average loss is 5.788865035865456\n",
      "07/27/2023 18:25:49 - INFO - __main__ - Per validation step average loss is 0.04706234112381935\n",
      "07/27/2023 18:25:49 - INFO - __main__ - Cumulative validation average loss is 5.835927376989275\n",
      "07/27/2023 18:25:49 - INFO - __main__ - Per validation step average loss is 0.055736616253852844\n",
      "07/27/2023 18:25:49 - INFO - __main__ - Cumulative validation average loss is 5.891663993243128\n",
      "07/27/2023 18:25:49 - INFO - __main__ - Per validation step average loss is 0.4355548620223999\n",
      "07/27/2023 18:25:49 - INFO - __main__ - Cumulative validation average loss is 6.327218855265528\n",
      "07/27/2023 18:25:50 - INFO - __main__ - Per validation step average loss is 0.04121780022978783\n",
      "07/27/2023 18:25:50 - INFO - __main__ - Cumulative validation average loss is 6.368436655495316\n",
      "07/27/2023 18:25:50 - INFO - __main__ - Per validation step average loss is 0.0030394725035876036\n",
      "07/27/2023 18:25:50 - INFO - __main__ - Cumulative validation average loss is 6.371476127998903\n",
      "07/27/2023 18:25:51 - INFO - __main__ - Per validation step average loss is 0.4392378330230713\n",
      "07/27/2023 18:25:51 - INFO - __main__ - Cumulative validation average loss is 6.810713961021975\n",
      "07/27/2023 18:25:51 - INFO - __main__ - Per validation step average loss is 0.18099500238895416\n",
      "07/27/2023 18:25:51 - INFO - __main__ - Cumulative validation average loss is 6.991708963410929\n",
      "07/27/2023 18:25:52 - INFO - __main__ - Per validation step average loss is 0.022070635110139847\n",
      "07/27/2023 18:25:52 - INFO - __main__ - Cumulative validation average loss is 7.013779598521069\n",
      "07/27/2023 18:25:52 - INFO - __main__ - Per validation step average loss is 0.14239558577537537\n",
      "07/27/2023 18:25:52 - INFO - __main__ - Cumulative validation average loss is 7.156175184296444\n",
      "07/27/2023 18:25:52 - INFO - __main__ - Per validation step average loss is 0.20237542688846588\n",
      "07/27/2023 18:25:52 - INFO - __main__ - Cumulative validation average loss is 7.35855061118491\n",
      "07/27/2023 18:25:53 - INFO - __main__ - Per validation step average loss is 0.2555463910102844\n",
      "07/27/2023 18:25:53 - INFO - __main__ - Cumulative validation average loss is 7.614097002195194\n",
      "07/27/2023 18:25:53 - INFO - __main__ - Per validation step average loss is 0.041197389364242554\n",
      "07/27/2023 18:25:53 - INFO - __main__ - Cumulative validation average loss is 7.655294391559437\n",
      "07/27/2023 18:25:54 - INFO - __main__ - Per validation step average loss is 0.1774071455001831\n",
      "07/27/2023 18:25:54 - INFO - __main__ - Cumulative validation average loss is 7.83270153705962\n",
      "07/27/2023 18:25:54 - INFO - __main__ - Per validation step average loss is 0.002226447919383645\n",
      "07/27/2023 18:25:54 - INFO - __main__ - Cumulative validation average loss is 7.834927984979004\n",
      "07/27/2023 18:25:54 - INFO - __main__ - Per validation step average loss is 0.05259714275598526\n",
      "07/27/2023 18:25:54 - INFO - __main__ - Cumulative validation average loss is 7.887525127734989\n",
      "07/27/2023 18:25:55 - INFO - __main__ - Per validation step average loss is 0.0093550318852067\n",
      "07/27/2023 18:25:55 - INFO - __main__ - Cumulative validation average loss is 7.896880159620196\n",
      "07/27/2023 18:25:55 - INFO - __main__ - Per validation step average loss is 0.02286924235522747\n",
      "07/27/2023 18:25:55 - INFO - __main__ - Cumulative validation average loss is 7.919749401975423\n",
      "07/27/2023 18:25:56 - INFO - __main__ - Per validation step average loss is 0.03159548342227936\n",
      "07/27/2023 18:25:56 - INFO - __main__ - Cumulative validation average loss is 7.9513448853977025\n",
      "07/27/2023 18:25:56 - INFO - __main__ - Per validation step average loss is 0.06730237603187561\n",
      "07/27/2023 18:25:56 - INFO - __main__ - Cumulative validation average loss is 8.018647261429578\n",
      "07/27/2023 18:25:56 - INFO - __main__ - Per validation step average loss is 0.3204958438873291\n",
      "07/27/2023 18:25:56 - INFO - __main__ - Cumulative validation average loss is 8.339143105316907\n",
      "07/27/2023 18:25:57 - INFO - __main__ - Per validation step average loss is 0.022763341665267944\n",
      "07/27/2023 18:25:57 - INFO - __main__ - Cumulative validation average loss is 8.361906446982175\n",
      "07/27/2023 18:25:57 - INFO - __main__ - Per validation step average loss is 0.1439959704875946\n",
      "07/27/2023 18:25:57 - INFO - __main__ - Cumulative validation average loss is 8.50590241746977\n",
      "07/27/2023 18:25:58 - INFO - __main__ - Per validation step average loss is 0.33037567138671875\n",
      "07/27/2023 18:25:58 - INFO - __main__ - Cumulative validation average loss is 8.836278088856488\n",
      "07/27/2023 18:25:58 - INFO - __main__ - Per validation step average loss is 0.27312836050987244\n",
      "07/27/2023 18:25:58 - INFO - __main__ - Cumulative validation average loss is 9.109406449366361\n",
      "07/27/2023 18:25:58 - INFO - __main__ - Per validation step average loss is 0.007153794169425964\n",
      "07/27/2023 18:25:58 - INFO - __main__ - Cumulative validation average loss is 9.116560243535787\n",
      "07/27/2023 18:25:59 - INFO - __main__ - Per validation step average loss is 0.02632920816540718\n",
      "07/27/2023 18:25:59 - INFO - __main__ - Cumulative validation average loss is 9.142889451701194\n",
      "07/27/2023 18:25:59 - INFO - __main__ - Per validation step average loss is 0.30741751194000244\n",
      "07/27/2023 18:25:59 - INFO - __main__ - Cumulative validation average loss is 9.450306963641196\n",
      "07/27/2023 18:26:00 - INFO - __main__ - Per validation step average loss is 0.09147249162197113\n",
      "07/27/2023 18:26:00 - INFO - __main__ - Cumulative validation average loss is 9.541779455263168\n",
      "07/27/2023 18:26:00 - INFO - __main__ - Per validation step average loss is 0.273245632648468\n",
      "07/27/2023 18:26:00 - INFO - __main__ - Cumulative validation average loss is 9.815025087911636\n",
      "07/27/2023 18:26:01 - INFO - __main__ - Per validation step average loss is 0.015566143207252026\n",
      "07/27/2023 18:26:01 - INFO - __main__ - Cumulative validation average loss is 9.830591231118888\n",
      "07/27/2023 18:26:01 - INFO - __main__ - Per validation step average loss is 0.011215816251933575\n",
      "07/27/2023 18:26:01 - INFO - __main__ - Cumulative validation average loss is 9.841807047370821\n",
      "07/27/2023 18:26:01 - INFO - __main__ - Per validation step average loss is 0.0023559904657304287\n",
      "07/27/2023 18:26:01 - INFO - __main__ - Cumulative validation average loss is 9.844163037836552\n",
      "07/27/2023 18:26:02 - INFO - __main__ - Per validation step average loss is 0.00887160561978817\n",
      "07/27/2023 18:26:02 - INFO - __main__ - Cumulative validation average loss is 9.85303464345634\n",
      "07/27/2023 18:26:02 - INFO - __main__ - Per validation step average loss is 0.10893528163433075\n",
      "07/27/2023 18:26:02 - INFO - __main__ - Cumulative validation average loss is 9.96196992509067\n",
      "07/27/2023 18:26:03 - INFO - __main__ - Per validation step average loss is 0.09762030839920044\n",
      "07/27/2023 18:26:03 - INFO - __main__ - Cumulative validation average loss is 10.059590233489871\n",
      "07/27/2023 18:26:03 - INFO - __main__ - Per validation step average loss is 0.14832255244255066\n",
      "07/27/2023 18:26:03 - INFO - __main__ - Cumulative validation average loss is 10.207912785932422\n",
      "07/27/2023 18:26:03 - INFO - __main__ - Per validation step average loss is 0.5438501834869385\n",
      "07/27/2023 18:26:03 - INFO - __main__ - Cumulative validation average loss is 10.75176296941936\n",
      "07/27/2023 18:26:04 - INFO - __main__ - Per validation step average loss is 0.07944206893444061\n",
      "07/27/2023 18:26:04 - INFO - __main__ - Cumulative validation average loss is 10.8312050383538\n",
      "07/27/2023 18:26:04 - INFO - __main__ - Per validation step average loss is 0.14875437319278717\n",
      "07/27/2023 18:26:04 - INFO - __main__ - Cumulative validation average loss is 10.979959411546588\n",
      "07/27/2023 18:26:05 - INFO - __main__ - Per validation step average loss is 0.0680592805147171\n",
      "07/27/2023 18:26:05 - INFO - __main__ - Cumulative validation average loss is 11.048018692061305\n",
      "07/27/2023 18:26:05 - INFO - __main__ - Per validation step average loss is 0.1153833344578743\n",
      "07/27/2023 18:26:05 - INFO - __main__ - Cumulative validation average loss is 11.16340202651918\n",
      "07/27/2023 18:26:05 - INFO - __main__ - Per validation step average loss is 0.00967051088809967\n",
      "07/27/2023 18:26:05 - INFO - __main__ - Cumulative validation average loss is 11.173072537407279\n",
      "07/27/2023 18:26:06 - INFO - __main__ - Per validation step average loss is 0.0019780504517257214\n",
      "07/27/2023 18:26:06 - INFO - __main__ - Cumulative validation average loss is 11.175050587859005\n",
      "07/27/2023 18:26:06 - INFO - __main__ - Per validation step average loss is 0.21431787312030792\n",
      "07/27/2023 18:26:06 - INFO - __main__ - Cumulative validation average loss is 11.389368460979313\n",
      "07/27/2023 18:26:07 - INFO - __main__ - Per validation step average loss is 0.03300723806023598\n",
      "07/27/2023 18:26:07 - INFO - __main__ - Cumulative validation average loss is 11.422375699039549\n",
      "07/27/2023 18:26:07 - INFO - __main__ - Per validation step average loss is 0.005388645920902491\n",
      "07/27/2023 18:26:07 - INFO - __main__ - Cumulative validation average loss is 11.427764344960451\n",
      "07/27/2023 18:26:07 - INFO - __main__ - Per validation step average loss is 0.3461361527442932\n",
      "07/27/2023 18:26:07 - INFO - __main__ - Cumulative validation average loss is 11.773900497704744\n",
      "07/27/2023 18:26:08 - INFO - __main__ - Per validation step average loss is 0.2179572880268097\n",
      "07/27/2023 18:26:08 - INFO - __main__ - Cumulative validation average loss is 11.991857785731554\n",
      "07/27/2023 18:26:08 - INFO - __main__ - Average validation loss for Epoch 15 is 0.15179566817381715\n",
      "07/27/2023 18:26:08 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:27:05 - INFO - __main__ - Starting epoch 16\n",
      "07/27/2023 18:27:06 - INFO - __main__ - train loss is 0.01247713528573513\n",
      "Steps:  32%|▎| 4849/15000 [42:16<77:26:14, 27.46s/it, lr=0.000605, step_loss=0.007/27/2023 18:27:06 - INFO - __main__ - train loss is 0.12441075406968594\n",
      "Steps:  32%|▎| 4850/15000 [42:16<54:21:25, 19.28s/it, lr=0.000605, step_loss=0.107/27/2023 18:27:06 - INFO - __main__ - train loss is 0.14422965608537197\n",
      "Steps:  32%|▎| 4851/15000 [42:17<38:12:22, 13.55s/it, lr=0.000605, step_loss=0.007/27/2023 18:27:06 - INFO - __main__ - train loss is 0.3213480766862631\n",
      "Steps:  32%|▎| 4852/15000 [42:17<26:53:55,  9.54s/it, lr=0.000605, step_loss=0.107/27/2023 18:27:07 - INFO - __main__ - train loss is 0.4516644533723593\n",
      "Steps:  32%|▎| 4853/15000 [42:17<18:58:41,  6.73s/it, lr=0.000605, step_loss=0.107/27/2023 18:27:07 - INFO - __main__ - train loss is 0.6218037959188223\n",
      "Steps:  32%|▎| 4854/15000 [42:17<13:26:07,  4.77s/it, lr=0.000605, step_loss=0.107/27/2023 18:27:07 - INFO - __main__ - train loss is 0.6926554199308157\n",
      "Steps:  32%|▎| 4855/15000 [42:17<9:33:29,  3.39s/it, lr=0.000605, step_loss=0.0707/27/2023 18:27:07 - INFO - __main__ - train loss is 0.7530917879194021\n",
      "Steps:  32%|▎| 4856/15000 [42:17<6:50:27,  2.43s/it, lr=0.000605, step_loss=0.0607/27/2023 18:27:07 - INFO - __main__ - train loss is 1.1122163888067007\n",
      "Steps:  32%|▎| 4857/15000 [42:18<4:56:20,  1.75s/it, lr=0.000606, step_loss=0.3507/27/2023 18:27:08 - INFO - __main__ - train loss is 1.3165493961423635\n",
      "Steps:  32%|▎| 4858/15000 [42:18<3:36:28,  1.28s/it, lr=0.000606, step_loss=0.2007/27/2023 18:27:08 - INFO - __main__ - train loss is 1.3735784124583006\n",
      "Steps:  32%|▎| 4859/15000 [42:18<2:40:35,  1.05it/s, lr=0.000606, step_loss=0.0507/27/2023 18:27:08 - INFO - __main__ - train loss is 1.407079664990306\n",
      "Steps:  32%|▎| 4860/15000 [42:18<2:01:27,  1.39it/s, lr=0.000606, step_loss=0.0307/27/2023 18:27:08 - INFO - __main__ - train loss is 1.4897762667387724\n",
      "Steps:  32%|▎| 4861/15000 [42:18<1:34:06,  1.80it/s, lr=0.000606, step_loss=0.0807/27/2023 18:27:08 - INFO - __main__ - train loss is 1.498418758623302\n",
      "Steps:  32%|▎| 4862/15000 [42:19<1:14:54,  2.26it/s, lr=0.000606, step_loss=0.0007/27/2023 18:27:08 - INFO - __main__ - train loss is 1.6903685731813312\n",
      "Steps:  32%|▎| 4863/15000 [42:19<1:01:35,  2.74it/s, lr=0.000606, step_loss=0.1907/27/2023 18:27:09 - INFO - __main__ - train loss is 1.6920102997682989\n",
      "Steps:  32%|▎| 4864/15000 [42:19<52:09,  3.24it/s, lr=0.000606, step_loss=0.001607/27/2023 18:27:09 - INFO - __main__ - train loss is 1.8322014971636236\n",
      "Steps:  32%|▋ | 4865/15000 [42:19<45:36,  3.70it/s, lr=0.000607, step_loss=0.14]07/27/2023 18:27:09 - INFO - __main__ - train loss is 1.8667596220038831\n",
      "Steps:  32%|▎| 4866/15000 [42:19<41:00,  4.12it/s, lr=0.000607, step_loss=0.034607/27/2023 18:27:09 - INFO - __main__ - train loss is 2.058677428867668\n",
      "Steps:  32%|▎| 4867/15000 [42:19<37:47,  4.47it/s, lr=0.000607, step_loss=0.192]07/27/2023 18:27:09 - INFO - __main__ - train loss is 2.115496543701738\n",
      "Steps:  32%|▎| 4868/15000 [42:20<35:32,  4.75it/s, lr=0.000607, step_loss=0.056807/27/2023 18:27:09 - INFO - __main__ - train loss is 2.1221304666250944\n",
      "Steps:  32%|▎| 4869/15000 [42:20<33:56,  4.97it/s, lr=0.000607, step_loss=0.006607/27/2023 18:27:10 - INFO - __main__ - train loss is 2.3407826852053404\n",
      "Steps:  32%|▎| 4870/15000 [42:20<32:51,  5.14it/s, lr=0.000607, step_loss=0.219]07/27/2023 18:27:10 - INFO - __main__ - train loss is 2.470996154472232\n",
      "Steps:  32%|▋ | 4871/15000 [42:20<32:05,  5.26it/s, lr=0.000607, step_loss=0.13]07/27/2023 18:27:10 - INFO - __main__ - train loss is 2.6520067285746336\n",
      "Steps:  32%|▎| 4872/15000 [42:20<31:32,  5.35it/s, lr=0.000607, step_loss=0.181]07/27/2023 18:27:10 - INFO - __main__ - train loss is 2.7198481913655996\n",
      "Steps:  32%|▎| 4873/15000 [42:21<31:09,  5.42it/s, lr=0.000608, step_loss=0.067807/27/2023 18:27:10 - INFO - __main__ - train loss is 2.7211154943797737\n",
      "Steps:  32%|▎| 4874/15000 [42:21<30:52,  5.47it/s, lr=0.000608, step_loss=0.001207/27/2023 18:27:11 - INFO - __main__ - train loss is 3.056505853543058\n",
      "Steps:  32%|▎| 4875/15000 [42:21<30:40,  5.50it/s, lr=0.000608, step_loss=0.335]07/27/2023 18:27:11 - INFO - __main__ - train loss is 3.058657098794356\n",
      "Steps:  33%|▎| 4876/15000 [42:21<30:33,  5.52it/s, lr=0.000608, step_loss=0.002107/27/2023 18:27:11 - INFO - __main__ - train loss is 3.0857736545149237\n",
      "Steps:  33%|▎| 4877/15000 [42:21<30:27,  5.54it/s, lr=0.000608, step_loss=0.027107/27/2023 18:27:11 - INFO - __main__ - train loss is 3.2051323803607374\n",
      "Steps:  33%|▎| 4878/15000 [42:21<30:24,  5.55it/s, lr=0.000608, step_loss=0.119]07/27/2023 18:27:11 - INFO - __main__ - train loss is 3.3492284568492323\n",
      "Steps:  33%|▎| 4879/15000 [42:22<30:21,  5.56it/s, lr=0.000608, step_loss=0.144]07/27/2023 18:27:11 - INFO - __main__ - train loss is 3.6292796882335097\n",
      "Steps:  33%|▋ | 4880/15000 [42:22<30:18,  5.56it/s, lr=0.000608, step_loss=0.28]07/27/2023 18:27:12 - INFO - __main__ - train loss is 3.6303673221264035\n",
      "Steps:  33%|▎| 4881/15000 [42:22<30:16,  5.57it/s, lr=0.000609, step_loss=0.001007/27/2023 18:27:12 - INFO - __main__ - train loss is 3.6342727344017476\n",
      "Steps:  33%|▎| 4882/15000 [42:22<30:15,  5.57it/s, lr=0.000609, step_loss=0.003907/27/2023 18:27:12 - INFO - __main__ - train loss is 3.75544115412049\n",
      "Steps:  33%|▎| 4883/15000 [42:22<30:14,  5.57it/s, lr=0.000609, step_loss=0.121]07/27/2023 18:27:12 - INFO - __main__ - train loss is 3.756662893923931\n",
      "Steps:  33%|▎| 4884/15000 [42:22<30:13,  5.58it/s, lr=0.000609, step_loss=0.001207/27/2023 18:27:12 - INFO - __main__ - train loss is 4.041934538516216\n",
      "Steps:  33%|▎| 4885/15000 [42:23<30:12,  5.58it/s, lr=0.000609, step_loss=0.285]07/27/2023 18:27:13 - INFO - __main__ - train loss is 4.1051423287717625\n",
      "Steps:  33%|▎| 4886/15000 [42:23<30:13,  5.58it/s, lr=0.000609, step_loss=0.063207/27/2023 18:27:13 - INFO - __main__ - train loss is 4.140230826917104\n",
      "Steps:  33%|▎| 4887/15000 [42:23<30:12,  5.58it/s, lr=0.000609, step_loss=0.035107/27/2023 18:27:13 - INFO - __main__ - train loss is 4.303923927131109\n",
      "Steps:  33%|▎| 4888/15000 [42:23<30:13,  5.58it/s, lr=0.000609, step_loss=0.164]07/27/2023 18:27:13 - INFO - __main__ - train loss is 4.327513780328445\n",
      "Steps:  33%|▎| 4889/15000 [42:23<30:12,  5.58it/s, lr=0.00061, step_loss=0.0236]07/27/2023 18:27:13 - INFO - __main__ - train loss is 4.474535908433609\n",
      "Steps:  33%|▋ | 4890/15000 [42:24<30:11,  5.58it/s, lr=0.00061, step_loss=0.147]07/27/2023 18:27:13 - INFO - __main__ - train loss is 4.48641475092154\n",
      "Steps:  33%|▎| 4891/15000 [42:24<30:24,  5.54it/s, lr=0.00061, step_loss=0.0119]07/27/2023 18:27:14 - INFO - __main__ - train loss is 4.735484188306145\n",
      "Steps:  33%|▋ | 4892/15000 [42:24<30:29,  5.52it/s, lr=0.00061, step_loss=0.249]07/27/2023 18:27:14 - INFO - __main__ - train loss is 4.9881708974717185\n",
      "Steps:  33%|▋ | 4893/15000 [42:24<30:42,  5.48it/s, lr=0.00061, step_loss=0.253]07/27/2023 18:27:14 - INFO - __main__ - train loss is 5.15918443154078\n",
      "Steps:  33%|▋ | 4894/15000 [42:24<30:53,  5.45it/s, lr=0.00061, step_loss=0.171]07/27/2023 18:27:14 - INFO - __main__ - train loss is 5.224168306100182\n",
      "Steps:  33%|▋ | 4895/15000 [42:24<30:49,  5.46it/s, lr=0.00061, step_loss=0.065]07/27/2023 18:27:14 - INFO - __main__ - train loss is 5.295196754741482\n",
      "Steps:  33%|▋ | 4896/15000 [42:25<30:45,  5.48it/s, lr=0.00061, step_loss=0.071]07/27/2023 18:27:15 - INFO - __main__ - train loss is 5.49956190388184\n",
      "Steps:  33%|▎| 4897/15000 [42:25<30:43,  5.48it/s, lr=0.000611, step_loss=0.204]07/27/2023 18:27:15 - INFO - __main__ - train loss is 5.763588307308964\n",
      "Steps:  33%|▎| 4898/15000 [42:25<30:41,  5.49it/s, lr=0.000611, step_loss=0.264]07/27/2023 18:27:15 - INFO - __main__ - train loss is 5.895233405637555\n",
      "Steps:  33%|▎| 4899/15000 [42:25<30:40,  5.49it/s, lr=0.000611, step_loss=0.132]07/27/2023 18:27:15 - INFO - __main__ - train loss is 6.115556178498082\n",
      "Steps:  33%|▋ | 4900/15000 [42:25<30:51,  5.45it/s, lr=0.000611, step_loss=0.22]07/27/2023 18:27:15 - INFO - __main__ - train loss is 6.14893539051991\n",
      "Steps:  33%|▎| 4901/15000 [42:26<30:47,  5.47it/s, lr=0.000611, step_loss=0.033407/27/2023 18:27:15 - INFO - __main__ - train loss is 6.289044244098477\n",
      "Steps:  33%|▋ | 4902/15000 [42:26<30:43,  5.48it/s, lr=0.000611, step_loss=0.14]07/27/2023 18:27:16 - INFO - __main__ - train loss is 6.612982017803006\n",
      "Steps:  33%|▎| 4903/15000 [42:26<30:42,  5.48it/s, lr=0.000611, step_loss=0.324]07/27/2023 18:27:16 - INFO - __main__ - train loss is 6.703582366812043\n",
      "Steps:  33%|▎| 4904/15000 [42:26<30:40,  5.49it/s, lr=0.000611, step_loss=0.090607/27/2023 18:27:16 - INFO - __main__ - train loss is 6.708570340531878\n",
      "Steps:  33%|▎| 4905/15000 [42:26<30:38,  5.49it/s, lr=0.000612, step_loss=0.004907/27/2023 18:27:16 - INFO - __main__ - train loss is 7.159792521852069\n",
      "Steps:  33%|▎| 4906/15000 [42:26<30:29,  5.52it/s, lr=0.000612, step_loss=0.451]07/27/2023 18:27:16 - INFO - __main__ - train loss is 7.16317171684932\n",
      "Steps:  33%|▎| 4907/15000 [42:27<30:23,  5.54it/s, lr=0.000612, step_loss=0.003307/27/2023 18:27:17 - INFO - __main__ - train loss is 7.164624804747291\n",
      "Steps:  33%|▎| 4908/15000 [42:27<30:19,  5.55it/s, lr=0.000612, step_loss=0.001407/27/2023 18:27:17 - INFO - __main__ - train loss is 7.201144257676788\n",
      "Steps:  33%|▎| 4909/15000 [42:27<30:16,  5.55it/s, lr=0.000612, step_loss=0.036507/27/2023 18:27:17 - INFO - __main__ - train loss is 7.383821839583106\n",
      "Steps:  33%|▎| 4910/15000 [42:27<30:16,  5.55it/s, lr=0.000612, step_loss=0.183]07/27/2023 18:27:17 - INFO - __main__ - train loss is 7.623161429655738\n",
      "Steps:  33%|▎| 4911/15000 [42:27<30:31,  5.51it/s, lr=0.000612, step_loss=0.239]07/27/2023 18:27:17 - INFO - __main__ - train loss is 7.6447958630742505\n",
      "Steps:  33%|▎| 4912/15000 [42:28<30:59,  5.42it/s, lr=0.000612, step_loss=0.021607/27/2023 18:27:17 - INFO - __main__ - train loss is 7.662916718167253\n",
      "Steps:  33%|▎| 4913/15000 [42:28<30:50,  5.45it/s, lr=0.000613, step_loss=0.018107/27/2023 18:27:18 - INFO - __main__ - train loss is 7.674784759175964\n",
      "Steps:  33%|▎| 4914/15000 [42:28<30:55,  5.44it/s, lr=0.000613, step_loss=0.011907/27/2023 18:27:18 - INFO - __main__ - train loss is 8.0091357921483\n",
      "Steps:  33%|▎| 4915/15000 [42:28<30:52,  5.44it/s, lr=0.000613, step_loss=0.334]07/27/2023 18:27:18 - INFO - __main__ - train loss is 8.089861819637008\n",
      "Steps:  33%|▎| 4916/15000 [42:28<30:48,  5.46it/s, lr=0.000613, step_loss=0.080707/27/2023 18:27:18 - INFO - __main__ - train loss is 8.183548087370582\n",
      "Steps:  33%|▎| 4917/15000 [42:28<30:53,  5.44it/s, lr=0.000613, step_loss=0.093707/27/2023 18:27:18 - INFO - __main__ - train loss is 8.186619350337423\n",
      "Steps:  33%|▎| 4918/15000 [42:29<30:53,  5.44it/s, lr=0.000613, step_loss=0.003007/27/2023 18:27:19 - INFO - __main__ - train loss is 8.207808443927206\n",
      "Steps:  33%|▎| 4919/15000 [42:29<30:52,  5.44it/s, lr=0.000613, step_loss=0.021207/27/2023 18:27:19 - INFO - __main__ - train loss is 8.49563742580358\n",
      "Steps:  33%|▎| 4920/15000 [42:29<30:54,  5.44it/s, lr=0.000613, step_loss=0.288]07/27/2023 18:27:19 - INFO - __main__ - train loss is 8.671244779252447\n",
      "Steps:  33%|▎| 4921/15000 [42:29<30:40,  5.47it/s, lr=0.000614, step_loss=0.176]07/27/2023 18:27:19 - INFO - __main__ - train loss is 8.674035976291634\n",
      "Steps:  33%|▎| 4922/15000 [42:29<30:32,  5.50it/s, lr=0.000614, step_loss=0.002707/27/2023 18:27:19 - INFO - __main__ - train loss is 8.819267044425942\n",
      "Steps:  33%|▎| 4923/15000 [42:30<30:25,  5.52it/s, lr=0.000614, step_loss=0.145]07/27/2023 18:27:19 - INFO - __main__ - train loss is 8.823994819656946\n",
      "Steps:  33%|▎| 4924/15000 [42:30<30:31,  5.50it/s, lr=0.000614, step_loss=0.004707/27/2023 18:27:20 - INFO - __main__ - train loss is 8.933336768881418\n",
      "Steps:  33%|▎| 4925/15000 [42:30<30:25,  5.52it/s, lr=0.000614, step_loss=0.109]07/27/2023 18:27:20 - INFO - __main__ - train loss is 8.956519459025003\n",
      "Steps:  33%|▎| 4926/15000 [42:30<30:20,  5.53it/s, lr=0.000614, step_loss=0.023207/27/2023 18:27:20 - INFO - __main__ - train loss is 9.24388367368374\n",
      "Steps:  33%|▎| 4927/15000 [42:30<30:23,  5.52it/s, lr=0.000614, step_loss=0.287]07/27/2023 18:27:20 - INFO - __main__ - train loss is 9.257192068384029\n",
      "Steps:  33%|▎| 4928/15000 [42:30<30:35,  5.49it/s, lr=0.000614, step_loss=0.013307/27/2023 18:27:20 - INFO - __main__ - train loss is 9.40465153066907\n",
      "Steps:  33%|▎| 4929/15000 [42:31<30:33,  5.49it/s, lr=0.000615, step_loss=0.147]07/27/2023 18:27:21 - INFO - __main__ - train loss is 9.445796669111587\n",
      "Steps:  33%|▎| 4930/15000 [42:31<30:25,  5.52it/s, lr=0.000615, step_loss=0.041107/27/2023 18:27:21 - INFO - __main__ - train loss is 9.511703365133144\n",
      "Steps:  33%|▎| 4931/15000 [42:31<30:28,  5.51it/s, lr=0.000615, step_loss=0.065907/27/2023 18:27:21 - INFO - __main__ - train loss is 9.600955166504718\n",
      "Steps:  33%|▎| 4932/15000 [42:31<30:25,  5.52it/s, lr=0.000615, step_loss=0.089307/27/2023 18:27:21 - INFO - __main__ - train loss is 9.619480934576131\n",
      "Steps:  33%|▎| 4933/15000 [42:31<30:36,  5.48it/s, lr=0.000615, step_loss=0.018507/27/2023 18:27:21 - INFO - __main__ - train loss is 9.661757600144483\n",
      "Steps:  33%|▎| 4934/15000 [42:32<30:46,  5.45it/s, lr=0.000615, step_loss=0.042307/27/2023 18:27:21 - INFO - __main__ - train loss is 9.785684552625753\n",
      "Steps:  33%|▎| 4935/15000 [42:32<30:48,  5.44it/s, lr=0.000615, step_loss=0.124]07/27/2023 18:27:22 - INFO - __main__ - train loss is 9.973108735517599\n",
      "Steps:  33%|▎| 4936/15000 [42:32<30:48,  5.45it/s, lr=0.000615, step_loss=0.187]07/27/2023 18:27:22 - INFO - __main__ - train loss is 10.022398267523386\n",
      "Steps:  33%|▎| 4937/15000 [42:32<30:34,  5.49it/s, lr=0.000616, step_loss=0.049307/27/2023 18:27:22 - INFO - __main__ - train loss is 10.031715283752419\n",
      "Steps:  33%|▎| 4938/15000 [42:32<30:24,  5.51it/s, lr=0.000616, step_loss=0.009307/27/2023 18:27:22 - INFO - __main__ - train loss is 10.045411592931487\n",
      "Steps:  33%|▎| 4939/15000 [42:32<30:18,  5.53it/s, lr=0.000616, step_loss=0.013707/27/2023 18:27:22 - INFO - __main__ - train loss is 10.091095159412362\n",
      "Steps:  33%|▎| 4940/15000 [42:33<30:14,  5.55it/s, lr=0.000616, step_loss=0.045707/27/2023 18:27:23 - INFO - __main__ - train loss is 10.117539935396053\n",
      "Steps:  33%|▎| 4941/15000 [42:33<30:10,  5.55it/s, lr=0.000616, step_loss=0.026407/27/2023 18:27:23 - INFO - __main__ - train loss is 10.123724325210787\n",
      "Steps:  33%|▎| 4942/15000 [42:33<30:09,  5.56it/s, lr=0.000616, step_loss=0.006107/27/2023 18:27:23 - INFO - __main__ - train loss is 10.147447454393841\n",
      "Steps:  33%|▎| 4943/15000 [42:33<30:07,  5.56it/s, lr=0.000616, step_loss=0.023707/27/2023 18:27:23 - INFO - __main__ - train loss is 10.168598851771094\n",
      "Steps:  33%|▎| 4944/15000 [42:33<30:05,  5.57it/s, lr=0.000616, step_loss=0.021207/27/2023 18:27:23 - INFO - __main__ - train loss is 10.463791808695532\n",
      "Steps:  33%|▎| 4945/15000 [42:34<30:05,  5.57it/s, lr=0.000617, step_loss=0.295]07/27/2023 18:27:23 - INFO - __main__ - train loss is 10.52901226899121\n",
      "Steps:  33%|▎| 4946/15000 [42:34<30:05,  5.57it/s, lr=0.000617, step_loss=0.065207/27/2023 18:27:24 - INFO - __main__ - train loss is 10.551519550965168\n",
      "Steps:  33%|▎| 4947/15000 [42:34<30:05,  5.57it/s, lr=0.000617, step_loss=0.022507/27/2023 18:27:24 - INFO - __main__ - train loss is 10.563058645115234\n",
      "Steps:  33%|▎| 4948/15000 [42:34<30:06,  5.57it/s, lr=0.000617, step_loss=0.011507/27/2023 18:27:24 - INFO - __main__ - train loss is 10.577993566752411\n",
      "Steps:  33%|▎| 4949/15000 [42:34<30:04,  5.57it/s, lr=0.000617, step_loss=0.014907/27/2023 18:27:24 - INFO - __main__ - train loss is 10.588065833435394\n",
      "Steps:  33%|▎| 4950/15000 [42:34<30:17,  5.53it/s, lr=0.000617, step_loss=0.010107/27/2023 18:27:24 - INFO - __main__ - train loss is 10.646588598028757\n",
      "Steps:  33%|▎| 4951/15000 [42:35<30:30,  5.49it/s, lr=0.000617, step_loss=0.058507/27/2023 18:27:25 - INFO - __main__ - train loss is 10.720808480517007\n",
      "Steps:  33%|▎| 4952/15000 [42:35<30:27,  5.50it/s, lr=0.000617, step_loss=0.074207/27/2023 18:27:25 - INFO - __main__ - train loss is 10.861063946620561\n",
      "Steps:  33%|▋ | 4953/15000 [42:35<30:19,  5.52it/s, lr=0.000618, step_loss=0.14]07/27/2023 18:27:25 - INFO - __main__ - train loss is 11.007176776067354\n",
      "Steps:  33%|▎| 4954/15000 [42:35<33:28,  5.00it/s, lr=0.000618, step_loss=0.146]07/27/2023 18:27:25 - INFO - __main__ - train loss is 11.070471171871759\n",
      "Steps:  33%|▎| 4955/15000 [42:36<35:54,  4.66it/s, lr=0.000618, step_loss=0.063307/27/2023 18:27:25 - INFO - __main__ - train loss is 11.537788157002069\n",
      "Steps:  33%|▎| 4956/15000 [42:36<35:30,  4.72it/s, lr=0.000618, step_loss=0.467]07/27/2023 18:27:26 - INFO - __main__ - train loss is 11.578712646500207\n",
      "Steps:  33%|▎| 4957/15000 [42:36<34:08,  4.90it/s, lr=0.000618, step_loss=0.040907/27/2023 18:27:26 - INFO - __main__ - train loss is 11.968955878750421\n",
      "Steps:  33%|▋ | 4958/15000 [42:36<32:56,  5.08it/s, lr=0.000618, step_loss=0.39]07/27/2023 18:27:26 - INFO - __main__ - train loss is 11.989509441540577\n",
      "Steps:  33%|▎| 4959/15000 [42:36<32:07,  5.21it/s, lr=0.000618, step_loss=0.020607/27/2023 18:27:26 - INFO - __main__ - train loss is 12.586496390984394\n",
      "Steps:  33%|▎| 4960/15000 [42:36<31:33,  5.30it/s, lr=0.000618, step_loss=0.597]07/27/2023 18:27:26 - INFO - __main__ - train loss is 13.040961213991977\n",
      "Steps:  33%|▎| 4961/15000 [42:37<31:07,  5.37it/s, lr=0.000619, step_loss=0.454]07/27/2023 18:27:26 - INFO - __main__ - train loss is 13.08136677800212\n",
      "Steps:  33%|▎| 4962/15000 [42:37<30:50,  5.43it/s, lr=0.000619, step_loss=0.040407/27/2023 18:27:27 - INFO - __main__ - train loss is 13.144291081116535\n",
      "Steps:  33%|▎| 4963/15000 [42:37<30:34,  5.47it/s, lr=0.000619, step_loss=0.062907/27/2023 18:27:27 - INFO - __main__ - train loss is 13.369185053394176\n",
      "Steps:  33%|▎| 4964/15000 [42:37<30:42,  5.45it/s, lr=0.000619, step_loss=0.225]07/27/2023 18:27:27 - INFO - __main__ - train loss is 13.417480312869884\n",
      "Steps:  33%|▎| 4965/15000 [42:37<30:57,  5.40it/s, lr=0.000619, step_loss=0.048307/27/2023 18:27:27 - INFO - __main__ - train loss is 13.89294176606927\n",
      "Steps:  33%|▎| 4966/15000 [42:38<31:29,  5.31it/s, lr=0.000619, step_loss=0.475]07/27/2023 18:27:27 - INFO - __main__ - train loss is 14.010863707051612\n",
      "Steps:  33%|▎| 4967/15000 [42:38<31:43,  5.27it/s, lr=0.000619, step_loss=0.118]07/27/2023 18:27:28 - INFO - __main__ - train loss is 14.053759120986797\n",
      "Steps:  33%|▎| 4968/15000 [42:38<32:10,  5.20it/s, lr=0.000619, step_loss=0.042907/27/2023 18:27:28 - INFO - __main__ - train loss is 14.863509916351177\n",
      "Steps:  33%|▉  | 4969/15000 [42:38<32:33,  5.13it/s, lr=0.00062, step_loss=0.81]07/27/2023 18:27:28 - INFO - __main__ - train loss is 15.057051919982769\n",
      "Steps:  33%|▋ | 4970/15000 [42:38<32:33,  5.13it/s, lr=0.00062, step_loss=0.194]07/27/2023 18:27:28 - INFO - __main__ - train loss is 15.077628918574192\n",
      "Steps:  33%|▎| 4971/15000 [42:39<32:35,  5.13it/s, lr=0.00062, step_loss=0.0206]07/27/2023 18:27:28 - INFO - __main__ - train loss is 15.083278606762178\n",
      "Steps:  33%|▎| 4972/15000 [42:39<32:39,  5.12it/s, lr=0.00062, step_loss=0.0056507/27/2023 18:27:29 - INFO - __main__ - train loss is 15.14493561827112\n",
      "Steps:  33%|▎| 4973/15000 [42:39<32:09,  5.20it/s, lr=0.00062, step_loss=0.0617]07/27/2023 18:27:29 - INFO - __main__ - train loss is 15.147525002365\n",
      "Steps:  33%|▎| 4974/15000 [42:39<31:48,  5.25it/s, lr=0.00062, step_loss=0.0025907/27/2023 18:27:29 - INFO - __main__ - train loss is 15.150742424302734\n",
      "Steps:  33%|▎| 4975/15000 [42:39<31:35,  5.29it/s, lr=0.00062, step_loss=0.0032207/27/2023 18:27:29 - INFO - __main__ - train loss is 15.340666783624329\n",
      "Steps:  33%|▉  | 4976/15000 [42:39<31:22,  5.33it/s, lr=0.00062, step_loss=0.19]07/27/2023 18:27:29 - INFO - __main__ - train loss is 15.34769501129631\n",
      "Steps:  33%|▎| 4977/15000 [42:40<31:13,  5.35it/s, lr=0.000621, step_loss=0.007007/27/2023 18:27:30 - INFO - __main__ - train loss is 15.432585913338698\n",
      "Steps:  33%|▎| 4978/15000 [42:40<31:10,  5.36it/s, lr=0.000621, step_loss=0.084907/27/2023 18:27:30 - INFO - __main__ - train loss is 15.656873453059234\n",
      "Steps:  33%|▎| 4979/15000 [42:40<31:08,  5.36it/s, lr=0.000621, step_loss=0.224]07/27/2023 18:27:30 - INFO - __main__ - train loss is 15.658870746032335\n",
      "Steps:  33%|▎| 4980/15000 [42:40<31:05,  5.37it/s, lr=0.000621, step_loss=0.002]07/27/2023 18:27:30 - INFO - __main__ - train loss is 15.67062494030688\n",
      "Steps:  33%|▎| 4981/15000 [42:40<31:03,  5.38it/s, lr=0.000621, step_loss=0.011807/27/2023 18:27:30 - INFO - __main__ - train loss is 15.876700459630229\n",
      "Steps:  33%|▎| 4982/15000 [42:41<31:25,  5.31it/s, lr=0.000621, step_loss=0.206]07/27/2023 18:27:30 - INFO - __main__ - train loss is 16.03568032255862\n",
      "Steps:  33%|▎| 4983/15000 [42:41<31:55,  5.23it/s, lr=0.000621, step_loss=0.159]07/27/2023 18:27:31 - INFO - __main__ - train loss is 16.130313089699484\n",
      "Steps:  33%|▎| 4984/15000 [42:41<32:08,  5.19it/s, lr=0.000621, step_loss=0.094607/27/2023 18:27:31 - INFO - __main__ - train loss is 16.247712797136046\n",
      "Steps:  33%|▎| 4985/15000 [42:41<31:36,  5.28it/s, lr=0.000622, step_loss=0.117]07/27/2023 18:27:31 - INFO - __main__ - train loss is 16.25841152726207\n",
      "Steps:  33%|▎| 4986/15000 [42:41<31:33,  5.29it/s, lr=0.000622, step_loss=0.010707/27/2023 18:27:31 - INFO - __main__ - train loss is 16.41369846521411\n",
      "Steps:  33%|▎| 4987/15000 [42:42<31:09,  5.36it/s, lr=0.000622, step_loss=0.155]07/27/2023 18:27:31 - INFO - __main__ - train loss is 16.444120091036893\n",
      "Steps:  33%|▎| 4988/15000 [42:42<30:47,  5.42it/s, lr=0.000622, step_loss=0.030407/27/2023 18:27:32 - INFO - __main__ - train loss is 16.556561243371107\n",
      "Steps:  33%|▎| 4989/15000 [42:42<30:31,  5.47it/s, lr=0.000622, step_loss=0.112]07/27/2023 18:27:32 - INFO - __main__ - train loss is 16.636659402982332\n",
      "Steps:  33%|▎| 4990/15000 [42:42<30:20,  5.50it/s, lr=0.000622, step_loss=0.080107/27/2023 18:27:32 - INFO - __main__ - train loss is 16.708082546130754\n",
      "Steps:  33%|▎| 4991/15000 [42:42<30:12,  5.52it/s, lr=0.000622, step_loss=0.071407/27/2023 18:27:32 - INFO - __main__ - train loss is 16.71562540915329\n",
      "Steps:  33%|▎| 4992/15000 [42:42<30:07,  5.54it/s, lr=0.000622, step_loss=0.007507/27/2023 18:27:32 - INFO - __main__ - train loss is 16.918324474361725\n",
      "Steps:  33%|▎| 4993/15000 [42:43<30:03,  5.55it/s, lr=0.000623, step_loss=0.203]07/27/2023 18:27:32 - INFO - __main__ - train loss is 16.919703872525133\n",
      "Steps:  33%|▎| 4994/15000 [42:43<30:01,  5.56it/s, lr=0.000623, step_loss=0.001307/27/2023 18:27:33 - INFO - __main__ - train loss is 17.147901149117388\n",
      "Steps:  33%|▎| 4995/15000 [42:43<29:59,  5.56it/s, lr=0.000623, step_loss=0.228]07/27/2023 18:27:33 - INFO - __main__ - train loss is 17.259557636105455\n",
      "Steps:  33%|▎| 4996/15000 [42:43<29:58,  5.56it/s, lr=0.000623, step_loss=0.112]07/27/2023 18:27:33 - INFO - __main__ - train loss is 17.359798343502916\n",
      "Steps:  33%|▉  | 4997/15000 [42:43<29:57,  5.57it/s, lr=0.000623, step_loss=0.1]07/27/2023 18:27:33 - INFO - __main__ - train loss is 17.378043125965632\n",
      "Steps:  33%|▎| 4998/15000 [42:44<30:12,  5.52it/s, lr=0.000623, step_loss=0.018207/27/2023 18:27:33 - INFO - __main__ - train loss is 17.575447540380992\n",
      "Steps:  33%|▎| 4999/15000 [42:44<30:22,  5.49it/s, lr=0.000623, step_loss=0.197]07/27/2023 18:27:34 - INFO - __main__ - train loss is 17.60078022594098\n",
      "Steps:  33%|▎| 5000/15000 [42:44<30:21,  5.49it/s, lr=0.000623, step_loss=0.197]07/27/2023 18:27:34 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-5000\n",
      "07/27/2023 18:27:34 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:27:34,168] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:27:34,173] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-5000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:27:34,173] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-5000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:27:34,180] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-5000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:27:34,180] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-5000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:27:34,187] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-5000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:27:34,187] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-5000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:27:34,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:27:34 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-5000/pytorch_model\n",
      "07/27/2023 18:27:34 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-5000/scheduler.bin\n",
      "07/27/2023 18:27:34 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-5000/random_states_0.pkl\n",
      "07/27/2023 18:27:34 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-5000\n",
      "Steps:  33%|▎| 5000/15000 [42:44<30:21,  5.49it/s, lr=0.000623, step_loss=0.025307/27/2023 18:27:34 - INFO - __main__ - train loss is 17.857610232778825\n",
      "Steps:  33%|▎| 5001/15000 [42:44<31:16,  5.33it/s, lr=0.000624, step_loss=0.257]07/27/2023 18:27:34 - INFO - __main__ - train loss is 17.952721349545754\n",
      "Steps:  33%|▎| 5002/15000 [42:44<30:53,  5.39it/s, lr=0.000624, step_loss=0.095107/27/2023 18:27:34 - INFO - __main__ - train loss is 17.955416029901244\n",
      "Steps:  33%|▎| 5003/15000 [42:44<30:36,  5.44it/s, lr=0.000624, step_loss=0.002607/27/2023 18:27:34 - INFO - __main__ - train loss is 18.160938865155913\n",
      "Steps:  33%|▎| 5004/15000 [42:45<30:25,  5.47it/s, lr=0.000624, step_loss=0.206]07/27/2023 18:27:34 - INFO - __main__ - train loss is 18.36346297583077\n",
      "Steps:  33%|▎| 5005/15000 [42:45<30:28,  5.47it/s, lr=0.000624, step_loss=0.203]07/27/2023 18:27:35 - INFO - __main__ - train loss is 18.42174242308829\n",
      "Steps:  33%|▎| 5006/15000 [42:45<30:33,  5.45it/s, lr=0.000624, step_loss=0.058307/27/2023 18:27:35 - INFO - __main__ - train loss is 18.523365779430605\n",
      "Steps:  33%|▎| 5007/15000 [42:45<30:22,  5.48it/s, lr=0.000624, step_loss=0.102]07/27/2023 18:27:35 - INFO - __main__ - train loss is 18.544340132386424\n",
      "Steps:  33%|▎| 5008/15000 [42:45<30:14,  5.51it/s, lr=0.000624, step_loss=0.021]07/27/2023 18:27:35 - INFO - __main__ - train loss is 18.570617884979583\n",
      "Steps:  33%|▎| 5009/15000 [42:46<30:14,  5.51it/s, lr=0.000625, step_loss=0.026307/27/2023 18:27:35 - INFO - __main__ - train loss is 19.110977262840606\n",
      "Steps:  33%|▋ | 5010/15000 [42:46<30:16,  5.50it/s, lr=0.000625, step_loss=0.54]07/27/2023 18:27:36 - INFO - __main__ - train loss is 19.27703736780677\n",
      "Steps:  33%|▎| 5011/15000 [42:46<30:17,  5.50it/s, lr=0.000625, step_loss=0.166]07/27/2023 18:27:36 - INFO - __main__ - train loss is 19.280744528747164\n",
      "Steps:  33%|▎| 5012/15000 [42:46<30:17,  5.50it/s, lr=0.000625, step_loss=0.003707/27/2023 18:27:36 - INFO - __main__ - train loss is 19.287049873149954\n",
      "Steps:  33%|▎| 5013/15000 [42:46<30:16,  5.50it/s, lr=0.000625, step_loss=0.006307/27/2023 18:27:36 - INFO - __main__ - train loss is 19.295975074521266\n",
      "Steps:  33%|▎| 5014/15000 [42:46<30:17,  5.50it/s, lr=0.000625, step_loss=0.008907/27/2023 18:27:36 - INFO - __main__ - train loss is 19.430398539057933\n",
      "Steps:  33%|▎| 5015/15000 [42:47<30:16,  5.50it/s, lr=0.000625, step_loss=0.134]07/27/2023 18:27:37 - INFO - __main__ - train loss is 19.432170969666913\n",
      "Steps:  33%|▎| 5016/15000 [42:47<30:16,  5.50it/s, lr=0.000625, step_loss=0.001707/27/2023 18:27:37 - INFO - __main__ - train loss is 19.440905229421332\n",
      "Steps:  33%|▎| 5017/15000 [42:47<30:16,  5.50it/s, lr=0.000625, step_loss=0.008707/27/2023 18:27:37 - INFO - __main__ - train loss is 19.451471023494378\n",
      "Steps:  33%|▎| 5018/15000 [42:47<30:16,  5.50it/s, lr=0.000626, step_loss=0.010607/27/2023 18:27:37 - INFO - __main__ - train loss is 19.53038077079691\n",
      "Steps:  33%|▎| 5019/15000 [42:47<30:16,  5.49it/s, lr=0.000626, step_loss=0.078907/27/2023 18:27:37 - INFO - __main__ - train loss is 19.57753486954607\n",
      "Steps:  33%|▎| 5020/15000 [42:48<30:16,  5.49it/s, lr=0.000626, step_loss=0.047207/27/2023 18:27:37 - INFO - __main__ - train loss is 19.60647543729283\n",
      "Steps:  33%|▎| 5021/15000 [42:48<30:16,  5.50it/s, lr=0.000626, step_loss=0.028907/27/2023 18:27:38 - INFO - __main__ - train loss is 19.624477489152923\n",
      "Steps:  33%|▎| 5022/15000 [42:48<30:16,  5.49it/s, lr=0.000626, step_loss=0.018]07/27/2023 18:27:38 - INFO - __main__ - train loss is 19.669077320257202\n",
      "Steps:  33%|▎| 5023/15000 [42:48<30:16,  5.49it/s, lr=0.000626, step_loss=0.044607/27/2023 18:27:38 - INFO - __main__ - train loss is 19.750216899672523\n",
      "Steps:  33%|▎| 5024/15000 [42:48<30:16,  5.49it/s, lr=0.000626, step_loss=0.081107/27/2023 18:27:38 - INFO - __main__ - train loss is 19.751892710570246\n",
      "Steps:  34%|▎| 5025/15000 [42:48<30:16,  5.49it/s, lr=0.000626, step_loss=0.001607/27/2023 18:27:38 - INFO - __main__ - train loss is 19.82053785258904\n",
      "Steps:  34%|▎| 5026/15000 [42:49<30:15,  5.50it/s, lr=0.000627, step_loss=0.068607/27/2023 18:27:39 - INFO - __main__ - train loss is 19.846602002624422\n",
      "Steps:  34%|▎| 5027/15000 [42:49<30:15,  5.49it/s, lr=0.000627, step_loss=0.026107/27/2023 18:27:39 - INFO - __main__ - train loss is 19.857307076919824\n",
      "Steps:  34%|▎| 5028/15000 [42:49<30:15,  5.49it/s, lr=0.000627, step_loss=0.010707/27/2023 18:27:39 - INFO - __main__ - train loss is 19.89142293157056\n",
      "Steps:  34%|▎| 5029/15000 [42:49<30:18,  5.48it/s, lr=0.000627, step_loss=0.034107/27/2023 18:27:39 - INFO - __main__ - train loss is 19.97754779877141\n",
      "Steps:  34%|▎| 5030/15000 [42:49<30:17,  5.49it/s, lr=0.000627, step_loss=0.086107/27/2023 18:27:39 - INFO - __main__ - train loss is 20.05740336002782\n",
      "Steps:  34%|▎| 5031/15000 [42:50<30:16,  5.49it/s, lr=0.000627, step_loss=0.079907/27/2023 18:27:39 - INFO - __main__ - train loss is 20.510803524870425\n",
      "Steps:  34%|▎| 5032/15000 [42:50<30:18,  5.48it/s, lr=0.000627, step_loss=0.453]07/27/2023 18:27:40 - INFO - __main__ - train loss is 20.613728885073215\n",
      "Steps:  34%|▎| 5033/15000 [42:50<30:17,  5.48it/s, lr=0.000627, step_loss=0.103]07/27/2023 18:27:40 - INFO - __main__ - train loss is 21.0367956799455\n",
      "Steps:  34%|▎| 5034/15000 [42:50<30:34,  5.43it/s, lr=0.000628, step_loss=0.423]07/27/2023 18:27:40 - INFO - __main__ - train loss is 21.489066396374255\n",
      "Steps:  34%|▎| 5035/15000 [42:50<30:26,  5.46it/s, lr=0.000628, step_loss=0.452]07/27/2023 18:27:40 - INFO - __main__ - train loss is 21.49068902421277\n",
      "Steps:  34%|▎| 5036/15000 [42:50<30:22,  5.47it/s, lr=0.000628, step_loss=0.001607/27/2023 18:27:40 - INFO - __main__ - train loss is 21.49255465704482\n",
      "Steps:  34%|▎| 5037/15000 [42:51<30:20,  5.47it/s, lr=0.000628, step_loss=0.001807/27/2023 18:27:41 - INFO - __main__ - train loss is 22.051110856118612\n",
      "Steps:  34%|▎| 5038/15000 [42:51<30:18,  5.48it/s, lr=0.000628, step_loss=0.559]07/27/2023 18:27:41 - INFO - __main__ - train loss is 22.230393357458524\n",
      "Steps:  34%|▎| 5039/15000 [42:51<30:17,  5.48it/s, lr=0.000628, step_loss=0.179]07/27/2023 18:27:41 - INFO - __main__ - train loss is 22.23246516508516\n",
      "Steps:  34%|▎| 5040/15000 [42:51<30:17,  5.48it/s, lr=0.000628, step_loss=0.002007/27/2023 18:27:41 - INFO - __main__ - train loss is 22.26968340051826\n",
      "Steps:  34%|▎| 5041/15000 [42:51<30:17,  5.48it/s, lr=0.000628, step_loss=0.037207/27/2023 18:27:41 - INFO - __main__ - train loss is 22.575046459562145\n",
      "Steps:  34%|▎| 5042/15000 [42:52<30:16,  5.48it/s, lr=0.000629, step_loss=0.305]07/27/2023 18:27:41 - INFO - __main__ - train loss is 22.673218423849903\n",
      "Steps:  34%|▎| 5043/15000 [42:52<30:15,  5.49it/s, lr=0.000629, step_loss=0.098207/27/2023 18:27:42 - INFO - __main__ - train loss is 22.84132992697414\n",
      "Steps:  34%|▎| 5044/15000 [42:52<30:14,  5.49it/s, lr=0.000629, step_loss=0.168]07/27/2023 18:27:42 - INFO - __main__ - train loss is 22.9397969864076\n",
      "Steps:  34%|▎| 5045/15000 [42:52<30:14,  5.49it/s, lr=0.000629, step_loss=0.098507/27/2023 18:27:42 - INFO - __main__ - train loss is 22.94939703529235\n",
      "Steps:  34%|▎| 5046/15000 [42:52<30:22,  5.46it/s, lr=0.000629, step_loss=0.009607/27/2023 18:27:42 - INFO - __main__ - train loss is 22.952993789105676\n",
      "Steps:  34%|▎| 5047/15000 [42:52<30:18,  5.47it/s, lr=0.000629, step_loss=0.003607/27/2023 18:27:42 - INFO - __main__ - train loss is 22.956105464487337\n",
      "Steps:  34%|▎| 5048/15000 [42:53<30:16,  5.48it/s, lr=0.000629, step_loss=0.003107/27/2023 18:27:43 - INFO - __main__ - train loss is 22.97248928376939\n",
      "Steps:  34%|▎| 5049/15000 [42:53<30:14,  5.48it/s, lr=0.000629, step_loss=0.016407/27/2023 18:27:43 - INFO - __main__ - train loss is 22.992653896450065\n",
      "Steps:  34%|▎| 5050/15000 [42:53<30:14,  5.48it/s, lr=0.00063, step_loss=0.0202]07/27/2023 18:27:43 - INFO - __main__ - train loss is 23.02588641399052\n",
      "Steps:  34%|▎| 5051/15000 [42:53<30:12,  5.49it/s, lr=0.00063, step_loss=0.0332]07/27/2023 18:27:43 - INFO - __main__ - train loss is 23.435301182209514\n",
      "Steps:  34%|▋ | 5052/15000 [42:53<30:12,  5.49it/s, lr=0.00063, step_loss=0.409]07/27/2023 18:27:43 - INFO - __main__ - train loss is 23.890353617607616\n",
      "Steps:  34%|▋ | 5053/15000 [42:54<30:12,  5.49it/s, lr=0.00063, step_loss=0.455]07/27/2023 18:27:43 - INFO - __main__ - train loss is 23.98941436165478\n",
      "Steps:  34%|▎| 5054/15000 [42:54<30:10,  5.49it/s, lr=0.00063, step_loss=0.0991]07/27/2023 18:27:44 - INFO - __main__ - train loss is 23.99284035374876\n",
      "Steps:  34%|▎| 5055/15000 [42:54<30:26,  5.45it/s, lr=0.00063, step_loss=0.0034307/27/2023 18:27:44 - INFO - __main__ - train loss is 23.994161970564164\n",
      "Steps:  34%|▎| 5056/15000 [42:54<30:21,  5.46it/s, lr=0.00063, step_loss=0.0013207/27/2023 18:27:44 - INFO - __main__ - train loss is 24.383442051359452\n",
      "Steps:  34%|▋ | 5057/15000 [42:54<30:18,  5.47it/s, lr=0.00063, step_loss=0.389]07/27/2023 18:27:44 - INFO - __main__ - train loss is 24.384818019461818\n",
      "Steps:  34%|▎| 5058/15000 [42:54<30:15,  5.48it/s, lr=0.000631, step_loss=0.001307/27/2023 18:27:44 - INFO - __main__ - train loss is 24.429318631184287\n",
      "Steps:  34%|▎| 5059/15000 [42:55<30:14,  5.48it/s, lr=0.000631, step_loss=0.044507/27/2023 18:27:45 - INFO - __main__ - train loss is 24.454490874079056\n",
      "Steps:  34%|▎| 5060/15000 [42:55<30:13,  5.48it/s, lr=0.000631, step_loss=0.025207/27/2023 18:27:45 - INFO - __main__ - train loss is 24.776210282114334\n",
      "Steps:  34%|▎| 5061/15000 [42:55<30:12,  5.48it/s, lr=0.000631, step_loss=0.322]07/27/2023 18:27:45 - INFO - __main__ - train loss is 24.812201574561186\n",
      "Steps:  34%|▎| 5062/15000 [42:55<30:29,  5.43it/s, lr=0.000631, step_loss=0.036]07/27/2023 18:27:45 - INFO - __main__ - train loss is 24.83515644457657\n",
      "Steps:  34%|▎| 5063/15000 [42:55<30:47,  5.38it/s, lr=0.000631, step_loss=0.023]07/27/2023 18:27:45 - INFO - __main__ - train loss is 24.96079615142662\n",
      "Steps:  34%|▎| 5064/15000 [42:56<30:34,  5.42it/s, lr=0.000631, step_loss=0.126]07/27/2023 18:27:45 - INFO - __main__ - train loss is 24.97753966797609\n",
      "Steps:  34%|▎| 5065/15000 [42:56<30:31,  5.43it/s, lr=0.000632, step_loss=0.016707/27/2023 18:27:46 - INFO - __main__ - train loss is 25.039206864428706\n",
      "Steps:  34%|▎| 5066/15000 [42:56<30:35,  5.41it/s, lr=0.000632, step_loss=0.061707/27/2023 18:27:46 - INFO - __main__ - train loss is 25.044999987003393\n",
      "Steps:  34%|▎| 5067/15000 [42:56<30:26,  5.44it/s, lr=0.000632, step_loss=0.005707/27/2023 18:27:46 - INFO - __main__ - train loss is 25.45118492853362\n",
      "Steps:  34%|▎| 5068/15000 [42:56<30:17,  5.46it/s, lr=0.000632, step_loss=0.406]07/27/2023 18:27:46 - INFO - __main__ - train loss is 25.560175888356753\n",
      "Steps:  34%|▎| 5069/15000 [42:56<30:07,  5.49it/s, lr=0.000632, step_loss=0.109]07/27/2023 18:27:46 - INFO - __main__ - train loss is 25.585291579482146\n",
      "Steps:  34%|▎| 5070/15000 [42:57<30:01,  5.51it/s, lr=0.000632, step_loss=0.025107/27/2023 18:27:47 - INFO - __main__ - train loss is 25.60017124854494\n",
      "Steps:  34%|▎| 5071/15000 [42:57<30:12,  5.48it/s, lr=0.000632, step_loss=0.014907/27/2023 18:27:47 - INFO - __main__ - train loss is 25.76222623430658\n",
      "Steps:  34%|▎| 5072/15000 [42:57<30:09,  5.49it/s, lr=0.000632, step_loss=0.162]07/27/2023 18:27:47 - INFO - __main__ - train loss is 25.774960761074908\n",
      "Steps:  34%|▎| 5073/15000 [42:57<30:01,  5.51it/s, lr=0.000632, step_loss=0.012707/27/2023 18:27:47 - INFO - __main__ - train loss is 25.791059007053263\n",
      "Steps:  34%|▎| 5074/15000 [42:57<29:56,  5.53it/s, lr=0.000633, step_loss=0.016107/27/2023 18:27:47 - INFO - __main__ - train loss is 25.803948674467392\n",
      "Steps:  34%|▎| 5075/15000 [42:58<29:53,  5.54it/s, lr=0.000633, step_loss=0.012907/27/2023 18:27:47 - INFO - __main__ - train loss is 25.85770725097973\n",
      "Steps:  34%|▎| 5076/15000 [42:58<29:50,  5.54it/s, lr=0.000633, step_loss=0.053807/27/2023 18:27:48 - INFO - __main__ - train loss is 25.97962604847271\n",
      "Steps:  34%|▎| 5077/15000 [42:58<29:47,  5.55it/s, lr=0.000633, step_loss=0.122]07/27/2023 18:27:48 - INFO - __main__ - train loss is 26.014509890344925\n",
      "Steps:  34%|▎| 5078/15000 [42:58<29:56,  5.52it/s, lr=0.000633, step_loss=0.034907/27/2023 18:27:48 - INFO - __main__ - train loss is 26.026451284182258\n",
      "Steps:  34%|▎| 5079/15000 [42:58<29:52,  5.53it/s, lr=0.000633, step_loss=0.011907/27/2023 18:27:48 - INFO - __main__ - train loss is 26.095449591171928\n",
      "Steps:  34%|▎| 5080/15000 [42:58<29:49,  5.54it/s, lr=0.000633, step_loss=0.069]07/27/2023 18:27:48 - INFO - __main__ - train loss is 26.131511831772514\n",
      "Steps:  34%|▎| 5081/15000 [42:59<30:03,  5.50it/s, lr=0.000633, step_loss=0.036107/27/2023 18:27:49 - INFO - __main__ - train loss is 26.145237268065102\n",
      "Steps:  34%|▎| 5082/15000 [42:59<29:57,  5.52it/s, lr=0.000634, step_loss=0.013707/27/2023 18:27:49 - INFO - __main__ - train loss is 26.46431779966224\n",
      "Steps:  34%|▎| 5083/15000 [42:59<29:54,  5.53it/s, lr=0.000634, step_loss=0.319]07/27/2023 18:27:49 - INFO - __main__ - train loss is 26.698986412142403\n",
      "Steps:  34%|▎| 5084/15000 [42:59<30:07,  5.49it/s, lr=0.000634, step_loss=0.235]07/27/2023 18:27:49 - INFO - __main__ - train loss is 26.70249632850755\n",
      "Steps:  34%|▎| 5085/15000 [42:59<30:07,  5.49it/s, lr=0.000634, step_loss=0.003507/27/2023 18:27:49 - INFO - __main__ - train loss is 26.768480041180737\n",
      "Steps:  34%|▎| 5086/15000 [43:00<30:09,  5.48it/s, lr=0.000634, step_loss=0.066]07/27/2023 18:27:49 - INFO - __main__ - train loss is 27.248664059792645\n",
      "Steps:  34%|▋ | 5087/15000 [43:00<30:01,  5.50it/s, lr=0.000634, step_loss=0.48]07/27/2023 18:27:50 - INFO - __main__ - train loss is 27.530890264664777\n",
      "Steps:  34%|▎| 5088/15000 [43:00<30:08,  5.48it/s, lr=0.000634, step_loss=0.282]07/27/2023 18:27:50 - INFO - __main__ - train loss is 27.744829216157086\n",
      "Steps:  34%|▎| 5089/15000 [43:00<30:01,  5.50it/s, lr=0.000634, step_loss=0.214]07/27/2023 18:27:50 - INFO - __main__ - train loss is 27.823006102000363\n",
      "Steps:  34%|▎| 5090/15000 [43:00<30:07,  5.48it/s, lr=0.000635, step_loss=0.078207/27/2023 18:27:50 - INFO - __main__ - train loss is 27.844560804893263\n",
      "Steps:  34%|▎| 5091/15000 [43:00<30:15,  5.46it/s, lr=0.000635, step_loss=0.021607/27/2023 18:27:50 - INFO - __main__ - train loss is 27.934004957904108\n",
      "Steps:  34%|▎| 5092/15000 [43:01<30:10,  5.47it/s, lr=0.000635, step_loss=0.089407/27/2023 18:27:51 - INFO - __main__ - train loss is 28.20249112986494\n",
      "Steps:  34%|▎| 5093/15000 [43:01<30:01,  5.50it/s, lr=0.000635, step_loss=0.268]07/27/2023 18:27:51 - INFO - __main__ - train loss is 28.21004292939324\n",
      "Steps:  34%|▎| 5094/15000 [43:01<30:10,  5.47it/s, lr=0.000635, step_loss=0.007507/27/2023 18:27:51 - INFO - __main__ - train loss is 28.91792032693047\n",
      "Steps:  34%|▎| 5095/15000 [43:01<30:06,  5.48it/s, lr=0.000635, step_loss=0.708]07/27/2023 18:27:51 - INFO - __main__ - train loss is 28.949933542055078\n",
      "Steps:  34%|▎| 5096/15000 [43:01<29:58,  5.51it/s, lr=0.000635, step_loss=0.032]07/27/2023 18:27:51 - INFO - __main__ - train loss is 29.08544520859141\n",
      "Steps:  34%|▎| 5097/15000 [43:02<29:52,  5.52it/s, lr=0.000635, step_loss=0.136]07/27/2023 18:27:51 - INFO - __main__ - train loss is 29.23854796413798\n",
      "Steps:  34%|▎| 5098/15000 [43:02<29:48,  5.53it/s, lr=0.000636, step_loss=0.153]07/27/2023 18:27:52 - INFO - __main__ - train loss is 29.514915509265848\n",
      "Steps:  34%|▎| 5099/15000 [43:02<29:45,  5.54it/s, lr=0.000636, step_loss=0.276]07/27/2023 18:27:52 - INFO - __main__ - train loss is 29.519311071489938\n",
      "Steps:  34%|▎| 5100/15000 [43:02<29:43,  5.55it/s, lr=0.000636, step_loss=0.004407/27/2023 18:27:52 - INFO - __main__ - train loss is 29.93742662773002\n",
      "Steps:  34%|▎| 5101/15000 [43:02<29:45,  5.54it/s, lr=0.000636, step_loss=0.418]07/27/2023 18:27:52 - INFO - __main__ - train loss is 30.058976919506676\n",
      "Steps:  34%|▎| 5102/15000 [43:02<29:43,  5.55it/s, lr=0.000636, step_loss=0.122]07/27/2023 18:27:52 - INFO - __main__ - train loss is 30.356741220806725\n",
      "Steps:  34%|▎| 5103/15000 [43:03<29:46,  5.54it/s, lr=0.000636, step_loss=0.298]07/27/2023 18:27:53 - INFO - __main__ - train loss is 30.39423423365224\n",
      "Steps:  34%|▎| 5104/15000 [43:03<29:42,  5.55it/s, lr=0.000636, step_loss=0.037507/27/2023 18:27:53 - INFO - __main__ - train loss is 30.593788021360524\n",
      "Steps:  34%|█  | 5105/15000 [43:03<29:40,  5.56it/s, lr=0.000637, step_loss=0.2]07/27/2023 18:27:53 - INFO - __main__ - train loss is 30.74146071926225\n",
      "Steps:  34%|▎| 5106/15000 [43:03<29:39,  5.56it/s, lr=0.000637, step_loss=0.148]07/27/2023 18:27:53 - INFO - __main__ - train loss is 30.772202515159734\n",
      "Steps:  34%|▎| 5107/15000 [43:03<29:39,  5.56it/s, lr=0.000637, step_loss=0.030707/27/2023 18:27:53 - INFO - __main__ - train loss is 30.935755246435292\n",
      "Steps:  34%|▎| 5108/15000 [43:04<29:39,  5.56it/s, lr=0.000637, step_loss=0.164]07/27/2023 18:27:53 - INFO - __main__ - train loss is 31.269224518095143\n",
      "Steps:  34%|▎| 5109/15000 [43:04<29:45,  5.54it/s, lr=0.000637, step_loss=0.333]07/27/2023 18:27:54 - INFO - __main__ - train loss is 31.28116896667052\n",
      "Steps:  34%|▎| 5110/15000 [43:04<29:49,  5.53it/s, lr=0.000637, step_loss=0.011907/27/2023 18:27:54 - INFO - __main__ - train loss is 31.326224356074817\n",
      "Steps:  34%|▎| 5111/15000 [43:04<29:52,  5.52it/s, lr=0.000637, step_loss=0.045107/27/2023 18:27:54 - INFO - __main__ - train loss is 31.617005198379047\n",
      "Steps:  34%|▎| 5112/15000 [43:04<29:54,  5.51it/s, lr=0.000637, step_loss=0.291]07/27/2023 18:27:54 - INFO - __main__ - train loss is 31.71781583048869\n",
      "Steps:  34%|▎| 5113/15000 [43:04<29:55,  5.51it/s, lr=0.000637, step_loss=0.101]07/27/2023 18:27:54 - INFO - __main__ - train loss is 31.72193454124499\n",
      "Steps:  34%|▎| 5114/15000 [43:05<29:57,  5.50it/s, lr=0.000638, step_loss=0.004107/27/2023 18:27:55 - INFO - __main__ - train loss is 31.777527100523002\n",
      "Steps:  34%|▎| 5115/15000 [43:05<29:57,  5.50it/s, lr=0.000638, step_loss=0.055607/27/2023 18:27:55 - INFO - __main__ - train loss is 31.793442941387184\n",
      "Steps:  34%|▎| 5116/15000 [43:05<29:58,  5.50it/s, lr=0.000638, step_loss=0.015907/27/2023 18:27:55 - INFO - __main__ - train loss is 31.8001813829178\n",
      "Steps:  34%|▎| 5117/15000 [43:05<29:58,  5.49it/s, lr=0.000638, step_loss=0.006707/27/2023 18:27:55 - INFO - __main__ - train loss is 31.88131208124105\n",
      "Steps:  34%|▎| 5118/15000 [43:05<29:58,  5.50it/s, lr=0.000638, step_loss=0.081107/27/2023 18:27:55 - INFO - __main__ - train loss is 32.14184899034444\n",
      "Steps:  34%|▎| 5119/15000 [43:06<29:57,  5.50it/s, lr=0.000638, step_loss=0.261]07/27/2023 18:27:55 - INFO - __main__ - train loss is 32.167890764423646\n",
      "Steps:  34%|▎| 5120/15000 [43:06<29:57,  5.50it/s, lr=0.000638, step_loss=0.026]07/27/2023 18:27:56 - INFO - __main__ - train loss is 32.30622471089009\n",
      "Steps:  34%|▎| 5121/15000 [43:06<29:56,  5.50it/s, lr=0.000638, step_loss=0.138]07/27/2023 18:27:56 - INFO - __main__ - train loss is 32.30828901019413\n",
      "Steps:  34%|▎| 5122/15000 [43:06<29:56,  5.50it/s, lr=0.000639, step_loss=0.002007/27/2023 18:27:56 - INFO - __main__ - train loss is 32.42542329814751\n",
      "Steps:  34%|▎| 5123/15000 [43:06<29:57,  5.50it/s, lr=0.000639, step_loss=0.117]07/27/2023 18:27:56 - INFO - __main__ - train loss is 32.49510413047392\n",
      "Steps:  34%|▎| 5124/15000 [43:06<29:58,  5.49it/s, lr=0.000639, step_loss=0.069707/27/2023 18:27:56 - INFO - __main__ - train loss is 32.50618098129053\n",
      "Steps:  34%|▎| 5125/15000 [43:07<29:58,  5.49it/s, lr=0.000639, step_loss=0.011107/27/2023 18:27:57 - INFO - __main__ - train loss is 32.628399813664146\n",
      "Steps:  34%|▎| 5126/15000 [43:07<29:58,  5.49it/s, lr=0.000639, step_loss=0.122]07/27/2023 18:27:57 - INFO - __main__ - train loss is 32.66524829168338\n",
      "Steps:  34%|▎| 5127/15000 [43:07<29:57,  5.49it/s, lr=0.000639, step_loss=0.036807/27/2023 18:27:57 - INFO - __main__ - train loss is 32.667770885978825\n",
      "Steps:  34%|▎| 5128/15000 [43:07<29:57,  5.49it/s, lr=0.000639, step_loss=0.002507/27/2023 18:27:57 - INFO - __main__ - train loss is 32.861649864469655\n",
      "Steps:  34%|▎| 5129/15000 [43:07<29:57,  5.49it/s, lr=0.000639, step_loss=0.194]07/27/2023 18:27:57 - INFO - __main__ - train loss is 32.89379672810901\n",
      "Steps:  34%|▎| 5130/15000 [43:08<29:56,  5.49it/s, lr=0.00064, step_loss=0.0321]07/27/2023 18:27:57 - INFO - __main__ - train loss is 32.91612345085014\n",
      "Steps:  34%|▎| 5131/15000 [43:08<29:55,  5.50it/s, lr=0.00064, step_loss=0.0223]07/27/2023 18:27:58 - INFO - __main__ - train loss is 32.917684664949775\n",
      "Steps:  34%|▎| 5132/15000 [43:08<29:55,  5.49it/s, lr=0.00064, step_loss=0.0015607/27/2023 18:27:58 - INFO - __main__ - train loss is 32.92992553859949\n",
      "Steps:  34%|▎| 5133/15000 [43:08<29:55,  5.49it/s, lr=0.00064, step_loss=0.0122]07/27/2023 18:27:58 - INFO - __main__ - train loss is 32.93136202683672\n",
      "Steps:  34%|▎| 5134/15000 [43:08<29:55,  5.49it/s, lr=0.00064, step_loss=0.0014407/27/2023 18:27:58 - INFO - __main__ - train loss is 33.19205521931872\n",
      "Steps:  34%|▋ | 5135/15000 [43:08<29:45,  5.53it/s, lr=0.00064, step_loss=0.261]07/27/2023 18:27:58 - INFO - __main__ - train loss is 33.43740525236353\n",
      "Steps:  34%|▋ | 5136/15000 [43:09<29:55,  5.49it/s, lr=0.00064, step_loss=0.245]07/27/2023 18:27:59 - INFO - __main__ - train loss is 33.44662610767409\n",
      "Steps:  34%|▎| 5137/15000 [43:09<29:52,  5.50it/s, lr=0.000641, step_loss=0.009207/27/2023 18:27:59 - INFO - __main__ - train loss is 33.45988596556708\n",
      "Steps:  34%|▎| 5138/15000 [43:09<29:45,  5.52it/s, lr=0.000641, step_loss=0.013307/27/2023 18:27:59 - INFO - __main__ - train loss is 33.54602241097018\n",
      "Steps:  34%|▎| 5139/15000 [43:09<29:39,  5.54it/s, lr=0.000641, step_loss=0.086107/27/2023 18:27:59 - INFO - __main__ - train loss is 33.5480256290175\n",
      "Steps:  34%|▎| 5140/15000 [43:09<29:45,  5.52it/s, lr=0.000641, step_loss=0.002]07/27/2023 18:27:59 - INFO - __main__ - train loss is 33.56230213539675\n",
      "Steps:  34%|▎| 5141/15000 [43:10<29:54,  5.49it/s, lr=0.000641, step_loss=0.014307/27/2023 18:27:59 - INFO - __main__ - train loss is 34.21114554302767\n",
      "Steps:  34%|▎| 5142/15000 [43:10<29:52,  5.50it/s, lr=0.000641, step_loss=0.649]07/27/2023 18:28:00 - INFO - __main__ - train loss is 34.2883752589114\n",
      "Steps:  34%|▎| 5143/15000 [43:10<29:43,  5.53it/s, lr=0.000641, step_loss=0.077207/27/2023 18:28:00 - INFO - __main__ - train loss is 34.319580361712724\n",
      "Steps:  34%|▎| 5144/15000 [43:10<29:37,  5.54it/s, lr=0.000641, step_loss=0.031207/27/2023 18:28:00 - INFO - __main__ - train loss is 34.49639803217724\n",
      "Steps:  34%|▎| 5145/15000 [43:10<29:33,  5.56it/s, lr=0.000641, step_loss=0.177]07/27/2023 18:28:00 - INFO - __main__ - train loss is 34.4990886754822\n",
      "Steps:  34%|▎| 5146/15000 [43:10<29:31,  5.56it/s, lr=0.000642, step_loss=0.002607/27/2023 18:28:00 - INFO - __main__ - train loss is 34.87455037306063\n",
      "Steps:  34%|▎| 5147/15000 [43:11<29:27,  5.57it/s, lr=0.000642, step_loss=0.375]07/27/2023 18:28:01 - INFO - __main__ - train loss is 35.175947160227224\n",
      "Steps:  34%|▎| 5148/15000 [43:11<29:26,  5.58it/s, lr=0.000642, step_loss=0.301]07/27/2023 18:28:01 - INFO - __main__ - train loss is 35.29790756921284\n",
      "Steps:  34%|▎| 5149/15000 [43:11<29:25,  5.58it/s, lr=0.000642, step_loss=0.122]07/27/2023 18:28:01 - INFO - __main__ - train loss is 35.434049614472315\n",
      "Steps:  34%|▎| 5150/15000 [43:11<29:27,  5.57it/s, lr=0.000642, step_loss=0.136]07/27/2023 18:28:01 - INFO - __main__ - train loss is 35.50841350178234\n",
      "Steps:  34%|▎| 5151/15000 [43:12<40:55,  4.01it/s, lr=0.000642, step_loss=0.074407/27/2023 18:28:02 - INFO - __main__ - Per validation step average loss is 0.09689033776521683\n",
      "07/27/2023 18:28:02 - INFO - __main__ - Cumulative validation average loss is 0.09689033776521683\n",
      "07/27/2023 18:28:03 - INFO - __main__ - Per validation step average loss is 0.41614657640457153\n",
      "07/27/2023 18:28:03 - INFO - __main__ - Cumulative validation average loss is 0.5130369141697884\n",
      "07/27/2023 18:28:03 - INFO - __main__ - Per validation step average loss is 0.034673985093832016\n",
      "07/27/2023 18:28:03 - INFO - __main__ - Cumulative validation average loss is 0.5477108992636204\n",
      "07/27/2023 18:28:04 - INFO - __main__ - Per validation step average loss is 0.11147406697273254\n",
      "07/27/2023 18:28:04 - INFO - __main__ - Cumulative validation average loss is 0.6591849662363529\n",
      "07/27/2023 18:28:04 - INFO - __main__ - Per validation step average loss is 0.13537979125976562\n",
      "07/27/2023 18:28:04 - INFO - __main__ - Cumulative validation average loss is 0.7945647574961185\n",
      "07/27/2023 18:28:04 - INFO - __main__ - Per validation step average loss is 0.6172403693199158\n",
      "07/27/2023 18:28:04 - INFO - __main__ - Cumulative validation average loss is 1.4118051268160343\n",
      "07/27/2023 18:28:05 - INFO - __main__ - Per validation step average loss is 0.0037382571026682854\n",
      "07/27/2023 18:28:05 - INFO - __main__ - Cumulative validation average loss is 1.4155433839187026\n",
      "07/27/2023 18:28:05 - INFO - __main__ - Per validation step average loss is 0.0024768798612058163\n",
      "07/27/2023 18:28:05 - INFO - __main__ - Cumulative validation average loss is 1.4180202637799084\n",
      "07/27/2023 18:28:06 - INFO - __main__ - Per validation step average loss is 0.1957661211490631\n",
      "07/27/2023 18:28:06 - INFO - __main__ - Cumulative validation average loss is 1.6137863849289715\n",
      "07/27/2023 18:28:06 - INFO - __main__ - Per validation step average loss is 0.004373498260974884\n",
      "07/27/2023 18:28:06 - INFO - __main__ - Cumulative validation average loss is 1.6181598831899464\n",
      "07/27/2023 18:28:06 - INFO - __main__ - Per validation step average loss is 0.013653282076120377\n",
      "07/27/2023 18:28:06 - INFO - __main__ - Cumulative validation average loss is 1.6318131652660668\n",
      "07/27/2023 18:28:07 - INFO - __main__ - Per validation step average loss is 0.28594034910202026\n",
      "07/27/2023 18:28:07 - INFO - __main__ - Cumulative validation average loss is 1.917753514368087\n",
      "07/27/2023 18:28:07 - INFO - __main__ - Per validation step average loss is 0.479280024766922\n",
      "07/27/2023 18:28:07 - INFO - __main__ - Cumulative validation average loss is 2.397033539135009\n",
      "07/27/2023 18:28:08 - INFO - __main__ - Per validation step average loss is 0.136195570230484\n",
      "07/27/2023 18:28:08 - INFO - __main__ - Cumulative validation average loss is 2.533229109365493\n",
      "07/27/2023 18:28:08 - INFO - __main__ - Per validation step average loss is 0.235275536775589\n",
      "07/27/2023 18:28:08 - INFO - __main__ - Cumulative validation average loss is 2.768504646141082\n",
      "07/27/2023 18:28:08 - INFO - __main__ - Per validation step average loss is 0.1616840660572052\n",
      "07/27/2023 18:28:08 - INFO - __main__ - Cumulative validation average loss is 2.9301887121982872\n",
      "07/27/2023 18:28:09 - INFO - __main__ - Per validation step average loss is 0.028829941526055336\n",
      "07/27/2023 18:28:09 - INFO - __main__ - Cumulative validation average loss is 2.9590186537243426\n",
      "07/27/2023 18:28:09 - INFO - __main__ - Per validation step average loss is 0.3227921724319458\n",
      "07/27/2023 18:28:09 - INFO - __main__ - Cumulative validation average loss is 3.2818108261562884\n",
      "07/27/2023 18:28:10 - INFO - __main__ - Per validation step average loss is 0.0019702864810824394\n",
      "07/27/2023 18:28:10 - INFO - __main__ - Cumulative validation average loss is 3.283781112637371\n",
      "07/27/2023 18:28:10 - INFO - __main__ - Per validation step average loss is 0.0036941973958164454\n",
      "07/27/2023 18:28:10 - INFO - __main__ - Cumulative validation average loss is 3.2874753100331873\n",
      "07/27/2023 18:28:10 - INFO - __main__ - Per validation step average loss is 0.2890127897262573\n",
      "07/27/2023 18:28:10 - INFO - __main__ - Cumulative validation average loss is 3.5764880997594446\n",
      "07/27/2023 18:28:11 - INFO - __main__ - Per validation step average loss is 0.08373396098613739\n",
      "07/27/2023 18:28:11 - INFO - __main__ - Cumulative validation average loss is 3.660222060745582\n",
      "07/27/2023 18:28:11 - INFO - __main__ - Per validation step average loss is 0.048823535442352295\n",
      "07/27/2023 18:28:11 - INFO - __main__ - Cumulative validation average loss is 3.7090455961879343\n",
      "07/27/2023 18:28:12 - INFO - __main__ - Per validation step average loss is 0.009134963154792786\n",
      "07/27/2023 18:28:12 - INFO - __main__ - Cumulative validation average loss is 3.718180559342727\n",
      "07/27/2023 18:28:12 - INFO - __main__ - Per validation step average loss is 0.11336131393909454\n",
      "07/27/2023 18:28:12 - INFO - __main__ - Cumulative validation average loss is 3.8315418732818216\n",
      "07/27/2023 18:28:13 - INFO - __main__ - Per validation step average loss is 0.3737034797668457\n",
      "07/27/2023 18:28:13 - INFO - __main__ - Cumulative validation average loss is 4.205245353048667\n",
      "07/27/2023 18:28:13 - INFO - __main__ - Per validation step average loss is 0.03731551766395569\n",
      "07/27/2023 18:28:13 - INFO - __main__ - Cumulative validation average loss is 4.242560870712623\n",
      "07/27/2023 18:28:13 - INFO - __main__ - Per validation step average loss is 0.009257260710000992\n",
      "07/27/2023 18:28:13 - INFO - __main__ - Cumulative validation average loss is 4.251818131422624\n",
      "07/27/2023 18:28:14 - INFO - __main__ - Per validation step average loss is 0.0778418779373169\n",
      "07/27/2023 18:28:14 - INFO - __main__ - Cumulative validation average loss is 4.329660009359941\n",
      "07/27/2023 18:28:14 - INFO - __main__ - Per validation step average loss is 0.2212478518486023\n",
      "07/27/2023 18:28:14 - INFO - __main__ - Cumulative validation average loss is 4.550907861208543\n",
      "07/27/2023 18:28:15 - INFO - __main__ - Per validation step average loss is 0.10557703673839569\n",
      "07/27/2023 18:28:15 - INFO - __main__ - Cumulative validation average loss is 4.656484897946939\n",
      "07/27/2023 18:28:15 - INFO - __main__ - Per validation step average loss is 0.004528274293988943\n",
      "07/27/2023 18:28:15 - INFO - __main__ - Cumulative validation average loss is 4.661013172240928\n",
      "07/27/2023 18:28:15 - INFO - __main__ - Per validation step average loss is 0.0994231253862381\n",
      "07/27/2023 18:28:15 - INFO - __main__ - Cumulative validation average loss is 4.760436297627166\n",
      "07/27/2023 18:28:16 - INFO - __main__ - Per validation step average loss is 0.06693675369024277\n",
      "07/27/2023 18:28:16 - INFO - __main__ - Cumulative validation average loss is 4.827373051317409\n",
      "07/27/2023 18:28:16 - INFO - __main__ - Per validation step average loss is 0.3932299315929413\n",
      "07/27/2023 18:28:16 - INFO - __main__ - Cumulative validation average loss is 5.22060298291035\n",
      "07/27/2023 18:28:17 - INFO - __main__ - Per validation step average loss is 0.004593738354742527\n",
      "07/27/2023 18:28:17 - INFO - __main__ - Cumulative validation average loss is 5.2251967212650925\n",
      "07/27/2023 18:28:17 - INFO - __main__ - Per validation step average loss is 0.1526595503091812\n",
      "07/27/2023 18:28:17 - INFO - __main__ - Cumulative validation average loss is 5.377856271574274\n",
      "07/27/2023 18:28:17 - INFO - __main__ - Per validation step average loss is 0.019194170832633972\n",
      "07/27/2023 18:28:17 - INFO - __main__ - Cumulative validation average loss is 5.397050442406908\n",
      "07/27/2023 18:28:18 - INFO - __main__ - Per validation step average loss is 0.01449422724545002\n",
      "07/27/2023 18:28:18 - INFO - __main__ - Cumulative validation average loss is 5.411544669652358\n",
      "07/27/2023 18:28:18 - INFO - __main__ - Per validation step average loss is 0.6424895524978638\n",
      "07/27/2023 18:28:18 - INFO - __main__ - Cumulative validation average loss is 6.0540342221502215\n",
      "07/27/2023 18:28:19 - INFO - __main__ - Per validation step average loss is 0.45346760749816895\n",
      "07/27/2023 18:28:19 - INFO - __main__ - Cumulative validation average loss is 6.50750182964839\n",
      "07/27/2023 18:28:19 - INFO - __main__ - Per validation step average loss is 0.19777989387512207\n",
      "07/27/2023 18:28:19 - INFO - __main__ - Cumulative validation average loss is 6.7052817235235125\n",
      "07/27/2023 18:28:19 - INFO - __main__ - Per validation step average loss is 0.0034611434675753117\n",
      "07/27/2023 18:28:19 - INFO - __main__ - Cumulative validation average loss is 6.708742866991088\n",
      "07/27/2023 18:28:20 - INFO - __main__ - Per validation step average loss is 0.035335443913936615\n",
      "07/27/2023 18:28:20 - INFO - __main__ - Cumulative validation average loss is 6.744078310905024\n",
      "07/27/2023 18:28:20 - INFO - __main__ - Per validation step average loss is 0.14256881177425385\n",
      "07/27/2023 18:28:20 - INFO - __main__ - Cumulative validation average loss is 6.886647122679278\n",
      "07/27/2023 18:28:21 - INFO - __main__ - Per validation step average loss is 0.025011030957102776\n",
      "07/27/2023 18:28:21 - INFO - __main__ - Cumulative validation average loss is 6.911658153636381\n",
      "07/27/2023 18:28:21 - INFO - __main__ - Per validation step average loss is 0.02783246338367462\n",
      "07/27/2023 18:28:21 - INFO - __main__ - Cumulative validation average loss is 6.939490617020056\n",
      "07/27/2023 18:28:21 - INFO - __main__ - Per validation step average loss is 0.20041683316230774\n",
      "07/27/2023 18:28:21 - INFO - __main__ - Cumulative validation average loss is 7.139907450182363\n",
      "07/27/2023 18:28:22 - INFO - __main__ - Per validation step average loss is 0.18551746010780334\n",
      "07/27/2023 18:28:22 - INFO - __main__ - Cumulative validation average loss is 7.325424910290167\n",
      "07/27/2023 18:28:22 - INFO - __main__ - Per validation step average loss is 0.24020588397979736\n",
      "07/27/2023 18:28:22 - INFO - __main__ - Cumulative validation average loss is 7.565630794269964\n",
      "07/27/2023 18:28:23 - INFO - __main__ - Per validation step average loss is 0.032887157052755356\n",
      "07/27/2023 18:28:23 - INFO - __main__ - Cumulative validation average loss is 7.5985179513227195\n",
      "07/27/2023 18:28:23 - INFO - __main__ - Per validation step average loss is 0.04395894706249237\n",
      "07/27/2023 18:28:23 - INFO - __main__ - Cumulative validation average loss is 7.642476898385212\n",
      "07/27/2023 18:28:24 - INFO - __main__ - Per validation step average loss is 0.17843151092529297\n",
      "07/27/2023 18:28:24 - INFO - __main__ - Cumulative validation average loss is 7.820908409310505\n",
      "07/27/2023 18:28:24 - INFO - __main__ - Per validation step average loss is 0.007297482341527939\n",
      "07/27/2023 18:28:24 - INFO - __main__ - Cumulative validation average loss is 7.828205891652033\n",
      "07/27/2023 18:28:24 - INFO - __main__ - Per validation step average loss is 0.1182505339384079\n",
      "07/27/2023 18:28:24 - INFO - __main__ - Cumulative validation average loss is 7.946456425590441\n",
      "07/27/2023 18:28:25 - INFO - __main__ - Per validation step average loss is 0.023158958181738853\n",
      "07/27/2023 18:28:25 - INFO - __main__ - Cumulative validation average loss is 7.9696153837721795\n",
      "07/27/2023 18:28:25 - INFO - __main__ - Per validation step average loss is 0.005740636494010687\n",
      "07/27/2023 18:28:25 - INFO - __main__ - Cumulative validation average loss is 7.97535602026619\n",
      "07/27/2023 18:28:26 - INFO - __main__ - Per validation step average loss is 0.012554138898849487\n",
      "07/27/2023 18:28:26 - INFO - __main__ - Cumulative validation average loss is 7.98791015916504\n",
      "07/27/2023 18:28:26 - INFO - __main__ - Per validation step average loss is 0.06264174729585648\n",
      "07/27/2023 18:28:26 - INFO - __main__ - Cumulative validation average loss is 8.050551906460896\n",
      "07/27/2023 18:28:26 - INFO - __main__ - Per validation step average loss is 0.049935419112443924\n",
      "07/27/2023 18:28:26 - INFO - __main__ - Cumulative validation average loss is 8.10048732557334\n",
      "07/27/2023 18:28:27 - INFO - __main__ - Per validation step average loss is 0.05069119483232498\n",
      "07/27/2023 18:28:27 - INFO - __main__ - Cumulative validation average loss is 8.151178520405665\n",
      "07/27/2023 18:28:27 - INFO - __main__ - Per validation step average loss is 0.0018788301385939121\n",
      "07/27/2023 18:28:27 - INFO - __main__ - Cumulative validation average loss is 8.153057350544259\n",
      "07/27/2023 18:28:28 - INFO - __main__ - Per validation step average loss is 0.006096369586884975\n",
      "07/27/2023 18:28:28 - INFO - __main__ - Cumulative validation average loss is 8.159153720131144\n",
      "07/27/2023 18:28:28 - INFO - __main__ - Per validation step average loss is 0.06587708741426468\n",
      "07/27/2023 18:28:28 - INFO - __main__ - Cumulative validation average loss is 8.225030807545409\n",
      "07/27/2023 18:28:28 - INFO - __main__ - Per validation step average loss is 0.20698286592960358\n",
      "07/27/2023 18:28:28 - INFO - __main__ - Cumulative validation average loss is 8.432013673475012\n",
      "07/27/2023 18:28:29 - INFO - __main__ - Per validation step average loss is 0.03445998951792717\n",
      "07/27/2023 18:28:29 - INFO - __main__ - Cumulative validation average loss is 8.46647366299294\n",
      "07/27/2023 18:28:29 - INFO - __main__ - Per validation step average loss is 0.16279694437980652\n",
      "07/27/2023 18:28:29 - INFO - __main__ - Cumulative validation average loss is 8.629270607372746\n",
      "07/27/2023 18:28:30 - INFO - __main__ - Per validation step average loss is 0.0015487109776586294\n",
      "07/27/2023 18:28:30 - INFO - __main__ - Cumulative validation average loss is 8.630819318350405\n",
      "07/27/2023 18:28:30 - INFO - __main__ - Per validation step average loss is 0.06181660294532776\n",
      "07/27/2023 18:28:30 - INFO - __main__ - Cumulative validation average loss is 8.692635921295732\n",
      "07/27/2023 18:28:31 - INFO - __main__ - Per validation step average loss is 0.07592355459928513\n",
      "07/27/2023 18:28:31 - INFO - __main__ - Cumulative validation average loss is 8.768559475895017\n",
      "07/27/2023 18:28:31 - INFO - __main__ - Per validation step average loss is 0.02409220114350319\n",
      "07/27/2023 18:28:31 - INFO - __main__ - Cumulative validation average loss is 8.79265167703852\n",
      "07/27/2023 18:28:31 - INFO - __main__ - Per validation step average loss is 0.12309220433235168\n",
      "07/27/2023 18:28:31 - INFO - __main__ - Cumulative validation average loss is 8.915743881370872\n",
      "07/27/2023 18:28:32 - INFO - __main__ - Per validation step average loss is 0.008300267159938812\n",
      "07/27/2023 18:28:32 - INFO - __main__ - Cumulative validation average loss is 8.924044148530811\n",
      "07/27/2023 18:28:32 - INFO - __main__ - Per validation step average loss is 0.009475262835621834\n",
      "07/27/2023 18:28:32 - INFO - __main__ - Cumulative validation average loss is 8.933519411366433\n",
      "07/27/2023 18:28:33 - INFO - __main__ - Per validation step average loss is 0.5339128971099854\n",
      "07/27/2023 18:28:33 - INFO - __main__ - Cumulative validation average loss is 9.467432308476418\n",
      "07/27/2023 18:28:33 - INFO - __main__ - Per validation step average loss is 0.03060026839375496\n",
      "07/27/2023 18:28:33 - INFO - __main__ - Cumulative validation average loss is 9.498032576870173\n",
      "07/27/2023 18:28:33 - INFO - __main__ - Per validation step average loss is 0.44440725445747375\n",
      "07/27/2023 18:28:33 - INFO - __main__ - Cumulative validation average loss is 9.942439831327647\n",
      "07/27/2023 18:28:34 - INFO - __main__ - Per validation step average loss is 0.14016716182231903\n",
      "07/27/2023 18:28:34 - INFO - __main__ - Cumulative validation average loss is 10.082606993149966\n",
      "07/27/2023 18:28:34 - INFO - __main__ - Per validation step average loss is 0.00364633253775537\n",
      "07/27/2023 18:28:34 - INFO - __main__ - Cumulative validation average loss is 10.086253325687721\n",
      "07/27/2023 18:28:34 - INFO - __main__ - Average validation loss for Epoch 16 is 0.12767409273022431\n",
      "07/27/2023 18:28:34 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:29:32 - INFO - __main__ - Starting epoch 17\n",
      "07/27/2023 18:29:32 - INFO - __main__ - train loss is 0.19662868976593018\n",
      "Steps:  34%|▎| 5152/15000 [44:43<75:20:12, 27.54s/it, lr=0.000642, step_loss=0.107/27/2023 18:29:33 - INFO - __main__ - train loss is 0.4218917340040207\n",
      "Steps:  34%|▎| 5153/15000 [44:43<52:53:01, 19.33s/it, lr=0.000642, step_loss=0.207/27/2023 18:29:33 - INFO - __main__ - train loss is 0.5411686673760414\n",
      "Steps:  34%|▎| 5154/15000 [44:43<37:09:44, 13.59s/it, lr=0.000643, step_loss=0.107/27/2023 18:29:33 - INFO - __main__ - train loss is 0.7520250454545021\n",
      "Steps:  34%|▎| 5155/15000 [44:43<26:09:28,  9.57s/it, lr=0.000643, step_loss=0.207/27/2023 18:29:33 - INFO - __main__ - train loss is 0.9429513290524483\n",
      "Steps:  34%|▎| 5156/15000 [44:44<18:27:35,  6.75s/it, lr=0.000643, step_loss=0.107/27/2023 18:29:33 - INFO - __main__ - train loss is 0.9477899586781859\n",
      "Steps:  34%|▎| 5157/15000 [44:44<13:04:15,  4.78s/it, lr=0.000643, step_loss=0.007/27/2023 18:29:34 - INFO - __main__ - train loss is 0.9904685420915484\n",
      "Steps:  34%|▎| 5158/15000 [44:44<9:17:43,  3.40s/it, lr=0.000643, step_loss=0.0407/27/2023 18:29:34 - INFO - __main__ - train loss is 1.1245712442323565\n",
      "Steps:  34%|▎| 5159/15000 [44:44<6:39:09,  2.43s/it, lr=0.000643, step_loss=0.1307/27/2023 18:29:34 - INFO - __main__ - train loss is 1.151938290335238\n",
      "Steps:  34%|▎| 5160/15000 [44:44<4:50:32,  1.77s/it, lr=0.000643, step_loss=0.0207/27/2023 18:29:34 - INFO - __main__ - train loss is 1.94625857565552\n",
      "Steps:  34%|▎| 5161/15000 [44:45<3:35:36,  1.31s/it, lr=0.000643, step_loss=0.7907/27/2023 18:29:34 - INFO - __main__ - train loss is 2.0700500616803765\n",
      "Steps:  34%|▎| 5162/15000 [44:45<2:40:15,  1.02it/s, lr=0.000644, step_loss=0.1207/27/2023 18:29:35 - INFO - __main__ - train loss is 2.1853414932265878\n",
      "Steps:  34%|▎| 5163/15000 [44:45<2:02:52,  1.33it/s, lr=0.000644, step_loss=0.1107/27/2023 18:29:35 - INFO - __main__ - train loss is 2.291703970171511\n",
      "Steps:  34%|▎| 5164/15000 [44:45<1:35:07,  1.72it/s, lr=0.000644, step_loss=0.1007/27/2023 18:29:35 - INFO - __main__ - train loss is 2.308393838815391\n",
      "Steps:  34%|▎| 5165/15000 [44:45<1:15:26,  2.17it/s, lr=0.000644, step_loss=0.0107/27/2023 18:29:35 - INFO - __main__ - train loss is 2.3624034700915217\n",
      "Steps:  34%|▎| 5166/15000 [44:46<1:01:36,  2.66it/s, lr=0.000644, step_loss=0.0507/27/2023 18:29:35 - INFO - __main__ - train loss is 2.598261463455856\n",
      "Steps:  34%|▎| 5167/15000 [44:46<51:57,  3.15it/s, lr=0.000644, step_loss=0.236]07/27/2023 18:29:36 - INFO - __main__ - train loss is 2.60142276994884\n",
      "Steps:  34%|▎| 5168/15000 [44:46<45:12,  3.62it/s, lr=0.000644, step_loss=0.003107/27/2023 18:29:36 - INFO - __main__ - train loss is 2.693049831315875\n",
      "Steps:  34%|▎| 5169/15000 [44:46<40:27,  4.05it/s, lr=0.000644, step_loss=0.091607/27/2023 18:29:36 - INFO - __main__ - train loss is 2.7342341151088476\n",
      "Steps:  34%|▎| 5170/15000 [44:46<37:07,  4.41it/s, lr=0.000645, step_loss=0.041207/27/2023 18:29:36 - INFO - __main__ - train loss is 2.736195017118007\n",
      "Steps:  34%|▎| 5171/15000 [44:46<34:56,  4.69it/s, lr=0.000645, step_loss=0.001907/27/2023 18:29:36 - INFO - __main__ - train loss is 2.9784903419204056\n",
      "Steps:  34%|▎| 5172/15000 [44:47<33:17,  4.92it/s, lr=0.000645, step_loss=0.242]07/27/2023 18:29:36 - INFO - __main__ - train loss is 3.058573965448886\n",
      "Steps:  34%|▎| 5173/15000 [44:47<32:24,  5.05it/s, lr=0.000645, step_loss=0.080107/27/2023 18:29:37 - INFO - __main__ - train loss is 3.136783626396209\n",
      "Steps:  34%|▎| 5174/15000 [44:47<31:34,  5.19it/s, lr=0.000645, step_loss=0.078207/27/2023 18:29:37 - INFO - __main__ - train loss is 3.1424709013663232\n",
      "Steps:  34%|▎| 5175/15000 [44:47<30:55,  5.30it/s, lr=0.000645, step_loss=0.005607/27/2023 18:29:37 - INFO - __main__ - train loss is 3.1544213755987585\n",
      "Steps:  35%|▎| 5176/15000 [44:47<30:26,  5.38it/s, lr=0.000645, step_loss=0.012]07/27/2023 18:29:37 - INFO - __main__ - train loss is 3.157300004735589\n",
      "Steps:  35%|▎| 5177/15000 [44:47<30:24,  5.38it/s, lr=0.000646, step_loss=0.002807/27/2023 18:29:37 - INFO - __main__ - train loss is 3.1621838747523725\n",
      "Steps:  35%|▎| 5178/15000 [44:48<30:04,  5.44it/s, lr=0.000646, step_loss=0.004807/27/2023 18:29:38 - INFO - __main__ - train loss is 3.4530859529040754\n",
      "Steps:  35%|▎| 5179/15000 [44:48<29:51,  5.48it/s, lr=0.000646, step_loss=0.291]07/27/2023 18:29:38 - INFO - __main__ - train loss is 3.455123064573854\n",
      "Steps:  35%|▎| 5180/15000 [44:48<29:42,  5.51it/s, lr=0.000646, step_loss=0.002007/27/2023 18:29:38 - INFO - __main__ - train loss is 3.4573173536919057\n",
      "Steps:  35%|▎| 5181/15000 [44:48<29:35,  5.53it/s, lr=0.000646, step_loss=0.002107/27/2023 18:29:38 - INFO - __main__ - train loss is 3.464292253833264\n",
      "Steps:  35%|▎| 5182/15000 [44:48<29:31,  5.54it/s, lr=0.000646, step_loss=0.006907/27/2023 18:29:38 - INFO - __main__ - train loss is 4.104504074435681\n",
      "Steps:  35%|▋ | 5183/15000 [44:49<29:29,  5.55it/s, lr=0.000646, step_loss=0.64]07/27/2023 18:29:38 - INFO - __main__ - train loss is 4.175269010942429\n",
      "Steps:  35%|▎| 5184/15000 [44:49<29:38,  5.52it/s, lr=0.000646, step_loss=0.070807/27/2023 18:29:39 - INFO - __main__ - train loss is 4.1810075752437115\n",
      "Steps:  35%|▎| 5185/15000 [44:49<29:45,  5.50it/s, lr=0.000646, step_loss=0.005707/27/2023 18:29:39 - INFO - __main__ - train loss is 4.209572736173868\n",
      "Steps:  35%|▎| 5186/15000 [44:49<29:49,  5.48it/s, lr=0.000647, step_loss=0.028607/27/2023 18:29:39 - INFO - __main__ - train loss is 4.240400340408087\n",
      "Steps:  35%|▎| 5187/15000 [44:49<29:54,  5.47it/s, lr=0.000647, step_loss=0.030807/27/2023 18:29:39 - INFO - __main__ - train loss is 4.271327735856175\n",
      "Steps:  35%|▎| 5188/15000 [44:49<29:56,  5.46it/s, lr=0.000647, step_loss=0.030907/27/2023 18:29:39 - INFO - __main__ - train loss is 4.273649590089917\n",
      "Steps:  35%|▎| 5189/15000 [44:50<29:59,  5.45it/s, lr=0.000647, step_loss=0.002307/27/2023 18:29:40 - INFO - __main__ - train loss is 4.3115798104554415\n",
      "Steps:  35%|▎| 5190/15000 [44:50<29:48,  5.48it/s, lr=0.000647, step_loss=0.037907/27/2023 18:29:40 - INFO - __main__ - train loss is 4.316298751160502\n",
      "Steps:  35%|▎| 5191/15000 [44:50<29:40,  5.51it/s, lr=0.000647, step_loss=0.004707/27/2023 18:29:40 - INFO - __main__ - train loss is 4.533637804910541\n",
      "Steps:  35%|▎| 5192/15000 [44:50<29:34,  5.53it/s, lr=0.000647, step_loss=0.217]07/27/2023 18:29:40 - INFO - __main__ - train loss is 4.537130435463041\n",
      "Steps:  35%|▎| 5193/15000 [44:50<29:31,  5.54it/s, lr=0.000647, step_loss=0.003407/27/2023 18:29:40 - INFO - __main__ - train loss is 4.542508694343269\n",
      "Steps:  35%|▎| 5194/15000 [44:51<29:28,  5.55it/s, lr=0.000648, step_loss=0.005307/27/2023 18:29:40 - INFO - __main__ - train loss is 4.545954258646816\n",
      "Steps:  35%|▎| 5195/15000 [44:51<29:27,  5.55it/s, lr=0.000648, step_loss=0.003407/27/2023 18:29:41 - INFO - __main__ - train loss is 4.557744500692934\n",
      "Steps:  35%|▎| 5196/15000 [44:51<29:24,  5.56it/s, lr=0.000648, step_loss=0.011807/27/2023 18:29:41 - INFO - __main__ - train loss is 4.61097959196195\n",
      "Steps:  35%|▎| 5197/15000 [44:51<29:24,  5.56it/s, lr=0.000648, step_loss=0.053207/27/2023 18:29:41 - INFO - __main__ - train loss is 4.6381811066530645\n",
      "Steps:  35%|▎| 5198/15000 [44:51<29:22,  5.56it/s, lr=0.000648, step_loss=0.027207/27/2023 18:29:41 - INFO - __main__ - train loss is 4.648498165886849\n",
      "Steps:  35%|▎| 5199/15000 [44:51<29:28,  5.54it/s, lr=0.000648, step_loss=0.010307/27/2023 18:29:41 - INFO - __main__ - train loss is 4.651836449513212\n",
      "Steps:  35%|▎| 5200/15000 [44:52<29:24,  5.55it/s, lr=0.000648, step_loss=0.003307/27/2023 18:29:42 - INFO - __main__ - train loss is 4.803816596278921\n",
      "Steps:  35%|▎| 5201/15000 [44:52<29:23,  5.56it/s, lr=0.000648, step_loss=0.152]07/27/2023 18:29:42 - INFO - __main__ - train loss is 5.165932635078207\n",
      "Steps:  35%|▎| 5202/15000 [44:52<29:36,  5.52it/s, lr=0.000649, step_loss=0.362]07/27/2023 18:29:42 - INFO - __main__ - train loss is 5.168443297967315\n",
      "Steps:  35%|▎| 5203/15000 [44:52<29:42,  5.50it/s, lr=0.000649, step_loss=0.002507/27/2023 18:29:42 - INFO - __main__ - train loss is 5.4959995206445456\n",
      "Steps:  35%|▎| 5204/15000 [44:52<29:51,  5.47it/s, lr=0.000649, step_loss=0.328]07/27/2023 18:29:42 - INFO - __main__ - train loss is 5.5002601146698\n",
      "Steps:  35%|▎| 5205/15000 [44:53<30:11,  5.41it/s, lr=0.000649, step_loss=0.004207/27/2023 18:29:42 - INFO - __main__ - train loss is 5.568773239850998\n",
      "Steps:  35%|▎| 5206/15000 [44:53<30:26,  5.36it/s, lr=0.000649, step_loss=0.068507/27/2023 18:29:43 - INFO - __main__ - train loss is 5.772150099277496\n",
      "Steps:  35%|▎| 5207/15000 [44:53<30:22,  5.37it/s, lr=0.000649, step_loss=0.203]07/27/2023 18:29:43 - INFO - __main__ - train loss is 5.935258865356445\n",
      "Steps:  35%|▎| 5208/15000 [44:53<30:19,  5.38it/s, lr=0.000649, step_loss=0.163]07/27/2023 18:29:43 - INFO - __main__ - train loss is 5.992414962500334\n",
      "Steps:  35%|▎| 5209/15000 [44:53<30:12,  5.40it/s, lr=0.00065, step_loss=0.0572]07/27/2023 18:29:43 - INFO - __main__ - train loss is 6.5414267890155315\n",
      "Steps:  35%|▋ | 5210/15000 [44:54<30:11,  5.40it/s, lr=0.00065, step_loss=0.549]07/27/2023 18:29:43 - INFO - __main__ - train loss is 6.649531971663237\n",
      "Steps:  35%|▋ | 5211/15000 [44:54<30:01,  5.43it/s, lr=0.00065, step_loss=0.108]07/27/2023 18:29:44 - INFO - __main__ - train loss is 6.956815373152494\n",
      "Steps:  35%|▋ | 5212/15000 [44:54<29:48,  5.47it/s, lr=0.00065, step_loss=0.307]07/27/2023 18:29:44 - INFO - __main__ - train loss is 7.061037968844175\n",
      "Steps:  35%|▋ | 5213/15000 [44:54<29:37,  5.50it/s, lr=0.00065, step_loss=0.104]07/27/2023 18:29:44 - INFO - __main__ - train loss is 7.118845965713263\n",
      "Steps:  35%|▎| 5214/15000 [44:54<29:30,  5.53it/s, lr=0.00065, step_loss=0.0578]07/27/2023 18:29:44 - INFO - __main__ - train loss is 7.128157059662044\n",
      "Steps:  35%|▎| 5215/15000 [44:54<29:26,  5.54it/s, lr=0.00065, step_loss=0.0093107/27/2023 18:29:44 - INFO - __main__ - train loss is 7.143652652390301\n",
      "Steps:  35%|▎| 5216/15000 [44:55<29:24,  5.54it/s, lr=0.00065, step_loss=0.0155]07/27/2023 18:29:44 - INFO - __main__ - train loss is 7.2505642445757985\n",
      "Steps:  35%|▋ | 5217/15000 [44:55<29:36,  5.51it/s, lr=0.00065, step_loss=0.107]07/27/2023 18:29:45 - INFO - __main__ - train loss is 7.323878203518689\n",
      "Steps:  35%|▎| 5218/15000 [44:55<29:46,  5.48it/s, lr=0.000651, step_loss=0.073307/27/2023 18:29:45 - INFO - __main__ - train loss is 7.585178975947201\n",
      "Steps:  35%|▎| 5219/15000 [44:55<29:42,  5.49it/s, lr=0.000651, step_loss=0.261]07/27/2023 18:29:45 - INFO - __main__ - train loss is 7.914347891695797\n",
      "Steps:  35%|▎| 5220/15000 [44:55<29:33,  5.51it/s, lr=0.000651, step_loss=0.329]07/27/2023 18:29:45 - INFO - __main__ - train loss is 7.93844501953572\n",
      "Steps:  35%|▎| 5221/15000 [44:55<29:27,  5.53it/s, lr=0.000651, step_loss=0.024107/27/2023 18:29:45 - INFO - __main__ - train loss is 8.178894865326583\n",
      "Steps:  35%|▋ | 5222/15000 [44:56<29:23,  5.54it/s, lr=0.000651, step_loss=0.24]07/27/2023 18:29:46 - INFO - __main__ - train loss is 8.196058333851397\n",
      "Steps:  35%|▎| 5223/15000 [44:56<29:34,  5.51it/s, lr=0.000651, step_loss=0.017207/27/2023 18:29:46 - INFO - __main__ - train loss is 8.204910145141184\n",
      "Steps:  35%|▎| 5224/15000 [44:56<29:39,  5.49it/s, lr=0.000651, step_loss=0.008807/27/2023 18:29:46 - INFO - __main__ - train loss is 8.426293001510203\n",
      "Steps:  35%|▎| 5225/15000 [44:56<29:40,  5.49it/s, lr=0.000651, step_loss=0.221]07/27/2023 18:29:46 - INFO - __main__ - train loss is 8.464335647411644\n",
      "Steps:  35%|▎| 5226/15000 [44:56<29:43,  5.48it/s, lr=0.000652, step_loss=0.038]07/27/2023 18:29:46 - INFO - __main__ - train loss is 8.472115472890437\n",
      "Steps:  35%|▎| 5227/15000 [44:57<29:36,  5.50it/s, lr=0.000652, step_loss=0.007707/27/2023 18:29:46 - INFO - __main__ - train loss is 8.967418567277491\n",
      "Steps:  35%|▎| 5228/15000 [44:57<29:30,  5.52it/s, lr=0.000652, step_loss=0.495]07/27/2023 18:29:47 - INFO - __main__ - train loss is 9.273306713439524\n",
      "Steps:  35%|▎| 5229/15000 [44:57<29:26,  5.53it/s, lr=0.000652, step_loss=0.306]07/27/2023 18:29:47 - INFO - __main__ - train loss is 9.27682435978204\n",
      "Steps:  35%|▎| 5230/15000 [44:57<29:37,  5.50it/s, lr=0.000652, step_loss=0.003507/27/2023 18:29:47 - INFO - __main__ - train loss is 9.28068487928249\n",
      "Steps:  35%|▎| 5231/15000 [44:57<29:47,  5.47it/s, lr=0.000652, step_loss=0.003807/27/2023 18:29:47 - INFO - __main__ - train loss is 9.312055969843641\n",
      "Steps:  35%|▎| 5232/15000 [44:58<30:08,  5.40it/s, lr=0.000652, step_loss=0.031407/27/2023 18:29:47 - INFO - __main__ - train loss is 9.908149982104078\n",
      "Steps:  35%|▎| 5233/15000 [44:58<30:08,  5.40it/s, lr=0.000652, step_loss=0.596]07/27/2023 18:29:48 - INFO - __main__ - train loss is 9.965718211838976\n",
      "Steps:  35%|▎| 5234/15000 [44:58<29:52,  5.45it/s, lr=0.000653, step_loss=0.057607/27/2023 18:29:48 - INFO - __main__ - train loss is 10.202676998684183\n",
      "Steps:  35%|▎| 5235/15000 [44:58<29:39,  5.49it/s, lr=0.000653, step_loss=0.237]07/27/2023 18:29:48 - INFO - __main__ - train loss is 10.206445699790493\n",
      "Steps:  35%|▎| 5236/15000 [44:58<29:30,  5.51it/s, lr=0.000653, step_loss=0.003707/27/2023 18:29:48 - INFO - __main__ - train loss is 10.214519476750866\n",
      "Steps:  35%|▎| 5237/15000 [44:58<29:24,  5.53it/s, lr=0.000653, step_loss=0.008007/27/2023 18:29:48 - INFO - __main__ - train loss is 10.217323856893927\n",
      "Steps:  35%|▎| 5238/15000 [44:59<29:19,  5.55it/s, lr=0.000653, step_loss=0.002807/27/2023 18:29:48 - INFO - __main__ - train loss is 10.220092661678791\n",
      "Steps:  35%|▎| 5239/15000 [44:59<29:17,  5.55it/s, lr=0.000653, step_loss=0.002707/27/2023 18:29:49 - INFO - __main__ - train loss is 10.331002064049244\n",
      "Steps:  35%|▎| 5240/15000 [44:59<29:16,  5.56it/s, lr=0.000653, step_loss=0.111]07/27/2023 18:29:49 - INFO - __main__ - train loss is 10.332278425106779\n",
      "Steps:  35%|▎| 5241/15000 [44:59<29:14,  5.56it/s, lr=0.000654, step_loss=0.001207/27/2023 18:29:49 - INFO - __main__ - train loss is 10.369678849587217\n",
      "Steps:  35%|▎| 5242/15000 [44:59<29:13,  5.56it/s, lr=0.000654, step_loss=0.037407/27/2023 18:29:49 - INFO - __main__ - train loss is 10.595243508229032\n",
      "Steps:  35%|▎| 5243/15000 [44:59<29:13,  5.57it/s, lr=0.000654, step_loss=0.226]07/27/2023 18:29:49 - INFO - __main__ - train loss is 10.605798904085532\n",
      "Steps:  35%|▎| 5244/15000 [45:00<29:11,  5.57it/s, lr=0.000654, step_loss=0.010607/27/2023 18:29:50 - INFO - __main__ - train loss is 11.14575231471099\n",
      "Steps:  35%|▋ | 5245/15000 [45:00<29:10,  5.57it/s, lr=0.000654, step_loss=0.54]07/27/2023 18:29:50 - INFO - __main__ - train loss is 11.148209711303934\n",
      "Steps:  35%|▎| 5246/15000 [45:00<29:09,  5.57it/s, lr=0.000654, step_loss=0.002407/27/2023 18:29:50 - INFO - __main__ - train loss is 11.300358971348032\n",
      "Steps:  35%|▎| 5247/15000 [45:00<29:09,  5.57it/s, lr=0.000654, step_loss=0.152]07/27/2023 18:29:50 - INFO - __main__ - train loss is 12.01387925981544\n",
      "Steps:  35%|▎| 5248/15000 [45:00<29:26,  5.52it/s, lr=0.000654, step_loss=0.714]07/27/2023 18:29:50 - INFO - __main__ - train loss is 12.313490947475657\n",
      "Steps:  35%|█  | 5249/15000 [45:01<29:26,  5.52it/s, lr=0.000655, step_loss=0.3]07/27/2023 18:29:50 - INFO - __main__ - train loss is 12.464003642788157\n",
      "Steps:  35%|▎| 5250/15000 [45:01<29:21,  5.53it/s, lr=0.000655, step_loss=0.151]07/27/2023 18:29:51 - INFO - __main__ - train loss is 12.47041767812334\n",
      "Steps:  35%|▎| 5251/15000 [45:01<29:18,  5.54it/s, lr=0.000655, step_loss=0.006407/27/2023 18:29:51 - INFO - __main__ - train loss is 12.478180553531274\n",
      "Steps:  35%|▎| 5252/15000 [45:01<29:15,  5.55it/s, lr=0.000655, step_loss=0.007707/27/2023 18:29:51 - INFO - __main__ - train loss is 12.548413838958368\n",
      "Steps:  35%|▎| 5253/15000 [45:01<29:13,  5.56it/s, lr=0.000655, step_loss=0.070207/27/2023 18:29:51 - INFO - __main__ - train loss is 12.72636979422532\n",
      "Steps:  35%|▎| 5254/15000 [45:01<29:10,  5.57it/s, lr=0.000655, step_loss=0.178]07/27/2023 18:29:51 - INFO - __main__ - train loss is 13.165997501229867\n",
      "Steps:  35%|▋ | 5255/15000 [45:02<29:09,  5.57it/s, lr=0.000655, step_loss=0.44]07/27/2023 18:29:52 - INFO - __main__ - train loss is 13.194990955060348\n",
      "Steps:  35%|▎| 5256/15000 [45:02<29:12,  5.56it/s, lr=0.000655, step_loss=0.029]07/27/2023 18:29:52 - INFO - __main__ - train loss is 13.260429218178615\n",
      "Steps:  35%|▎| 5257/15000 [45:02<29:11,  5.56it/s, lr=0.000655, step_loss=0.065407/27/2023 18:29:52 - INFO - __main__ - train loss is 13.263629085151479\n",
      "Steps:  35%|▎| 5258/15000 [45:02<29:09,  5.57it/s, lr=0.000656, step_loss=0.003207/27/2023 18:29:52 - INFO - __main__ - train loss is 13.453094429103658\n",
      "Steps:  35%|▎| 5259/15000 [45:02<29:10,  5.56it/s, lr=0.000656, step_loss=0.189]07/27/2023 18:29:52 - INFO - __main__ - train loss is 13.729581421939656\n",
      "Steps:  35%|▎| 5260/15000 [45:03<29:09,  5.57it/s, lr=0.000656, step_loss=0.276]07/27/2023 18:29:52 - INFO - __main__ - train loss is 13.991896128980443\n",
      "Steps:  35%|▎| 5261/15000 [45:03<29:12,  5.56it/s, lr=0.000656, step_loss=0.262]07/27/2023 18:29:53 - INFO - __main__ - train loss is 14.375799781410024\n",
      "Steps:  35%|▎| 5262/15000 [45:03<29:09,  5.56it/s, lr=0.000656, step_loss=0.384]07/27/2023 18:29:53 - INFO - __main__ - train loss is 14.586895665852353\n",
      "Steps:  35%|▎| 5263/15000 [45:03<29:13,  5.55it/s, lr=0.000656, step_loss=0.211]07/27/2023 18:29:53 - INFO - __main__ - train loss is 14.639264478115365\n",
      "Steps:  35%|▎| 5264/15000 [45:03<29:10,  5.56it/s, lr=0.000656, step_loss=0.052407/27/2023 18:29:53 - INFO - __main__ - train loss is 14.883590205339715\n",
      "Steps:  35%|▎| 5265/15000 [45:03<29:09,  5.56it/s, lr=0.000656, step_loss=0.244]07/27/2023 18:29:53 - INFO - __main__ - train loss is 15.335716171888635\n",
      "Steps:  35%|▎| 5266/15000 [45:04<29:10,  5.56it/s, lr=0.000657, step_loss=0.452]07/27/2023 18:29:53 - INFO - __main__ - train loss is 15.43369788560085\n",
      "Steps:  35%|▎| 5267/15000 [45:04<29:08,  5.57it/s, lr=0.000657, step_loss=0.098]07/27/2023 18:29:54 - INFO - __main__ - train loss is 15.46943753096275\n",
      "Steps:  35%|▎| 5268/15000 [45:04<29:07,  5.57it/s, lr=0.000657, step_loss=0.035707/27/2023 18:29:54 - INFO - __main__ - train loss is 15.785262784687802\n",
      "Steps:  35%|▎| 5269/15000 [45:04<29:06,  5.57it/s, lr=0.000657, step_loss=0.316]07/27/2023 18:29:54 - INFO - __main__ - train loss is 15.894363856641576\n",
      "Steps:  35%|▎| 5270/15000 [45:04<29:06,  5.57it/s, lr=0.000657, step_loss=0.109]07/27/2023 18:29:54 - INFO - __main__ - train loss is 16.024065530626103\n",
      "Steps:  35%|▋ | 5271/15000 [45:05<29:06,  5.57it/s, lr=0.000657, step_loss=0.13]07/27/2023 18:29:54 - INFO - __main__ - train loss is 16.050826417980716\n",
      "Steps:  35%|▎| 5272/15000 [45:05<29:05,  5.57it/s, lr=0.000657, step_loss=0.026807/27/2023 18:29:55 - INFO - __main__ - train loss is 16.189424532232806\n",
      "Steps:  35%|▎| 5273/15000 [45:05<29:06,  5.57it/s, lr=0.000657, step_loss=0.139]07/27/2023 18:29:55 - INFO - __main__ - train loss is 16.21601027692668\n",
      "Steps:  35%|▎| 5274/15000 [45:05<29:17,  5.53it/s, lr=0.000658, step_loss=0.026607/27/2023 18:29:55 - INFO - __main__ - train loss is 16.285039466572925\n",
      "Steps:  35%|▎| 5275/15000 [45:05<29:15,  5.54it/s, lr=0.000658, step_loss=0.069]07/27/2023 18:29:55 - INFO - __main__ - train loss is 16.287250695517287\n",
      "Steps:  35%|▎| 5276/15000 [45:05<29:11,  5.55it/s, lr=0.000658, step_loss=0.002207/27/2023 18:29:55 - INFO - __main__ - train loss is 16.28910980152432\n",
      "Steps:  35%|▎| 5277/15000 [45:06<29:09,  5.56it/s, lr=0.000658, step_loss=0.001807/27/2023 18:29:55 - INFO - __main__ - train loss is 16.323537220829166\n",
      "Steps:  35%|▎| 5278/15000 [45:06<29:07,  5.56it/s, lr=0.000658, step_loss=0.034407/27/2023 18:29:56 - INFO - __main__ - train loss is 16.471466218703426\n",
      "Steps:  35%|▎| 5279/15000 [45:06<29:05,  5.57it/s, lr=0.000658, step_loss=0.148]07/27/2023 18:29:56 - INFO - __main__ - train loss is 16.4727128976956\n",
      "Steps:  35%|▎| 5280/15000 [45:06<29:06,  5.56it/s, lr=0.000658, step_loss=0.001207/27/2023 18:29:56 - INFO - __main__ - train loss is 16.474321987014264\n",
      "Steps:  35%|▎| 5281/15000 [45:06<29:04,  5.57it/s, lr=0.000659, step_loss=0.001607/27/2023 18:29:56 - INFO - __main__ - train loss is 16.524260710459203\n",
      "Steps:  35%|▎| 5282/15000 [45:07<29:07,  5.56it/s, lr=0.000659, step_loss=0.049907/27/2023 18:29:56 - INFO - __main__ - train loss is 16.728669609408826\n",
      "Steps:  35%|▎| 5283/15000 [45:07<29:07,  5.56it/s, lr=0.000659, step_loss=0.204]07/27/2023 18:29:57 - INFO - __main__ - train loss is 16.761869143228978\n",
      "Steps:  35%|▎| 5284/15000 [45:07<29:05,  5.57it/s, lr=0.000659, step_loss=0.033207/27/2023 18:29:57 - INFO - __main__ - train loss is 16.80479225842282\n",
      "Steps:  35%|▎| 5285/15000 [45:07<29:15,  5.53it/s, lr=0.000659, step_loss=0.042907/27/2023 18:29:57 - INFO - __main__ - train loss is 16.982515651267022\n",
      "Steps:  35%|▎| 5286/15000 [45:07<29:27,  5.50it/s, lr=0.000659, step_loss=0.178]07/27/2023 18:29:57 - INFO - __main__ - train loss is 17.098994623403996\n",
      "Steps:  35%|▎| 5287/15000 [45:07<29:22,  5.51it/s, lr=0.000659, step_loss=0.116]07/27/2023 18:29:57 - INFO - __main__ - train loss is 17.432027529459447\n",
      "Steps:  35%|▎| 5288/15000 [45:08<29:16,  5.53it/s, lr=0.000659, step_loss=0.333]07/27/2023 18:29:57 - INFO - __main__ - train loss is 17.434471511747688\n",
      "Steps:  35%|▎| 5289/15000 [45:08<29:12,  5.54it/s, lr=0.00066, step_loss=0.0024407/27/2023 18:29:58 - INFO - __main__ - train loss is 17.479119462426752\n",
      "Steps:  35%|▎| 5290/15000 [45:08<29:08,  5.55it/s, lr=0.00066, step_loss=0.0446]07/27/2023 18:29:58 - INFO - __main__ - train loss is 17.992601794656366\n",
      "Steps:  35%|▋ | 5291/15000 [45:08<29:07,  5.56it/s, lr=0.00066, step_loss=0.513]07/27/2023 18:29:58 - INFO - __main__ - train loss is 18.039113929029554\n",
      "Steps:  35%|▎| 5292/15000 [45:08<29:05,  5.56it/s, lr=0.00066, step_loss=0.0465]07/27/2023 18:29:58 - INFO - __main__ - train loss is 18.048703928943723\n",
      "Steps:  35%|▎| 5293/15000 [45:08<29:03,  5.57it/s, lr=0.00066, step_loss=0.0095907/27/2023 18:29:58 - INFO - __main__ - train loss is 18.078226955141872\n",
      "Steps:  35%|▎| 5294/15000 [45:09<29:03,  5.57it/s, lr=0.00066, step_loss=0.0295]07/27/2023 18:29:59 - INFO - __main__ - train loss is 18.117046864237636\n",
      "Steps:  35%|▎| 5295/15000 [45:09<29:03,  5.57it/s, lr=0.00066, step_loss=0.0388]07/27/2023 18:29:59 - INFO - __main__ - train loss is 18.496573270764202\n",
      "Steps:  35%|█  | 5296/15000 [45:09<29:16,  5.52it/s, lr=0.00066, step_loss=0.38]07/27/2023 18:29:59 - INFO - __main__ - train loss is 18.50586787937209\n",
      "Steps:  35%|▎| 5297/15000 [45:09<29:12,  5.54it/s, lr=0.00066, step_loss=0.0092907/27/2023 18:29:59 - INFO - __main__ - train loss is 18.70246035931632\n",
      "Steps:  35%|▎| 5298/15000 [45:09<29:07,  5.55it/s, lr=0.000661, step_loss=0.197]07/27/2023 18:29:59 - INFO - __main__ - train loss is 19.43291003582999\n",
      "Steps:  35%|▋ | 5299/15000 [45:10<29:05,  5.56it/s, lr=0.000661, step_loss=0.73]07/27/2023 18:29:59 - INFO - __main__ - train loss is 19.537259947042912\n",
      "Steps:  35%|▎| 5300/15000 [45:10<29:04,  5.56it/s, lr=0.000661, step_loss=0.104]07/27/2023 18:30:00 - INFO - __main__ - train loss is 19.567081421148032\n",
      "Steps:  35%|▎| 5301/15000 [45:10<29:03,  5.56it/s, lr=0.000661, step_loss=0.029807/27/2023 18:30:00 - INFO - __main__ - train loss is 19.569093029014766\n",
      "Steps:  35%|▎| 5302/15000 [45:10<29:01,  5.57it/s, lr=0.000661, step_loss=0.002007/27/2023 18:30:00 - INFO - __main__ - train loss is 19.601060043089092\n",
      "Steps:  35%|▎| 5303/15000 [45:10<29:01,  5.57it/s, lr=0.000661, step_loss=0.032]07/27/2023 18:30:00 - INFO - __main__ - train loss is 20.035902748815715\n",
      "Steps:  35%|▎| 5304/15000 [45:10<29:00,  5.57it/s, lr=0.000661, step_loss=0.435]07/27/2023 18:30:00 - INFO - __main__ - train loss is 20.0629139887169\n",
      "Steps:  35%|▎| 5305/15000 [45:11<29:02,  5.56it/s, lr=0.000661, step_loss=0.027]07/27/2023 18:30:01 - INFO - __main__ - train loss is 20.36414668429643\n",
      "[2023-07-27 18:30:01,097] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:  35%|▎| 5306/15000 [45:11<28:49,  5.61it/s, lr=0.000661, step_loss=0.301]07/27/2023 18:30:01 - INFO - __main__ - train loss is 20.740631435997784\n",
      "Steps:  35%|▎| 5307/15000 [45:11<28:52,  5.60it/s, lr=0.000662, step_loss=0.376]07/27/2023 18:30:01 - INFO - __main__ - train loss is 20.967072610743344\n",
      "Steps:  35%|▎| 5308/15000 [45:11<28:53,  5.59it/s, lr=0.000662, step_loss=0.226]07/27/2023 18:30:01 - INFO - __main__ - train loss is 21.000399098731577\n",
      "Steps:  35%|▎| 5309/15000 [45:11<28:55,  5.58it/s, lr=0.000662, step_loss=0.033307/27/2023 18:30:01 - INFO - __main__ - train loss is 21.342222318984568\n",
      "Steps:  35%|▎| 5310/15000 [45:12<28:56,  5.58it/s, lr=0.000662, step_loss=0.342]07/27/2023 18:30:01 - INFO - __main__ - train loss is 21.343769691418856\n",
      "Steps:  35%|▎| 5311/15000 [45:12<28:57,  5.58it/s, lr=0.000662, step_loss=0.001507/27/2023 18:30:02 - INFO - __main__ - train loss is 21.495905734132975\n",
      "Steps:  35%|▎| 5312/15000 [45:12<28:57,  5.57it/s, lr=0.000662, step_loss=0.152]07/27/2023 18:30:02 - INFO - __main__ - train loss is 21.502697651274502\n",
      "Steps:  35%|▎| 5313/15000 [45:12<28:58,  5.57it/s, lr=0.000662, step_loss=0.006707/27/2023 18:30:02 - INFO - __main__ - train loss is 21.53535244707018\n",
      "Steps:  35%|▎| 5314/15000 [45:12<28:58,  5.57it/s, lr=0.000663, step_loss=0.032707/27/2023 18:30:02 - INFO - __main__ - train loss is 21.654061899520457\n",
      "Steps:  35%|▎| 5315/15000 [45:12<28:59,  5.57it/s, lr=0.000663, step_loss=0.119]07/27/2023 18:30:02 - INFO - __main__ - train loss is 21.701227539218962\n",
      "Steps:  35%|▎| 5316/15000 [45:13<29:13,  5.52it/s, lr=0.000663, step_loss=0.047207/27/2023 18:30:02 - INFO - __main__ - train loss is 21.809687414206564\n",
      "Steps:  35%|▎| 5317/15000 [45:13<29:08,  5.54it/s, lr=0.000663, step_loss=0.108]07/27/2023 18:30:03 - INFO - __main__ - train loss is 22.078294315375388\n",
      "Steps:  35%|▎| 5318/15000 [45:13<29:04,  5.55it/s, lr=0.000663, step_loss=0.269]07/27/2023 18:30:03 - INFO - __main__ - train loss is 22.109071140177548\n",
      "Steps:  35%|▎| 5319/15000 [45:13<29:04,  5.55it/s, lr=0.000663, step_loss=0.030807/27/2023 18:30:03 - INFO - __main__ - train loss is 22.148832191713154\n",
      "Steps:  35%|▎| 5320/15000 [45:13<29:01,  5.56it/s, lr=0.000663, step_loss=0.039807/27/2023 18:30:03 - INFO - __main__ - train loss is 22.33215603698045\n",
      "Steps:  35%|▎| 5321/15000 [45:14<29:00,  5.56it/s, lr=0.000663, step_loss=0.183]07/27/2023 18:30:03 - INFO - __main__ - train loss is 22.465844039805233\n",
      "Steps:  35%|▎| 5322/15000 [45:14<28:59,  5.56it/s, lr=0.000664, step_loss=0.134]07/27/2023 18:30:04 - INFO - __main__ - train loss is 22.58251552004367\n",
      "Steps:  35%|▎| 5323/15000 [45:14<28:58,  5.57it/s, lr=0.000664, step_loss=0.117]07/27/2023 18:30:04 - INFO - __main__ - train loss is 22.648051512427628\n",
      "Steps:  35%|▎| 5324/15000 [45:14<28:58,  5.57it/s, lr=0.000664, step_loss=0.065507/27/2023 18:30:04 - INFO - __main__ - train loss is 22.7420443193987\n",
      "Steps:  36%|▎| 5325/15000 [45:14<28:57,  5.57it/s, lr=0.000664, step_loss=0.094]07/27/2023 18:30:04 - INFO - __main__ - train loss is 22.77372841257602\n",
      "Steps:  36%|▎| 5326/15000 [45:14<28:56,  5.57it/s, lr=0.000664, step_loss=0.031707/27/2023 18:30:04 - INFO - __main__ - train loss is 23.097284209914505\n",
      "Steps:  36%|▎| 5327/15000 [45:15<28:56,  5.57it/s, lr=0.000664, step_loss=0.324]07/27/2023 18:30:04 - INFO - __main__ - train loss is 23.402852249331772\n",
      "Steps:  36%|▎| 5328/15000 [45:15<28:55,  5.57it/s, lr=0.000664, step_loss=0.306]07/27/2023 18:30:05 - INFO - __main__ - train loss is 23.430996243841946\n",
      "Steps:  36%|▎| 5329/15000 [45:15<28:56,  5.57it/s, lr=0.000664, step_loss=0.028107/27/2023 18:30:05 - INFO - __main__ - train loss is 23.49367579538375\n",
      "Steps:  36%|▎| 5330/15000 [45:15<28:56,  5.57it/s, lr=0.000664, step_loss=0.062707/27/2023 18:30:05 - INFO - __main__ - train loss is 23.76789337117225\n",
      "Steps:  36%|▎| 5331/15000 [45:15<28:55,  5.57it/s, lr=0.000665, step_loss=0.274]07/27/2023 18:30:05 - INFO - __main__ - train loss is 24.13238495308906\n",
      "Steps:  36%|▎| 5332/15000 [45:15<28:54,  5.57it/s, lr=0.000665, step_loss=0.364]07/27/2023 18:30:05 - INFO - __main__ - train loss is 24.139465963933617\n",
      "Steps:  36%|▎| 5333/15000 [45:16<28:53,  5.58it/s, lr=0.000665, step_loss=0.007007/27/2023 18:30:06 - INFO - __main__ - train loss is 24.1464290949516\n",
      "Steps:  36%|▎| 5334/15000 [45:16<28:53,  5.58it/s, lr=0.000665, step_loss=0.006907/27/2023 18:30:06 - INFO - __main__ - train loss is 24.149456733139232\n",
      "Steps:  36%|▎| 5335/15000 [45:16<28:53,  5.57it/s, lr=0.000665, step_loss=0.003007/27/2023 18:30:06 - INFO - __main__ - train loss is 24.180617007659748\n",
      "Steps:  36%|▎| 5336/15000 [45:16<28:53,  5.58it/s, lr=0.000665, step_loss=0.031207/27/2023 18:30:06 - INFO - __main__ - train loss is 24.188379399711266\n",
      "Steps:  36%|▎| 5337/15000 [45:16<28:52,  5.58it/s, lr=0.000665, step_loss=0.007707/27/2023 18:30:06 - INFO - __main__ - train loss is 24.379871629411355\n",
      "Steps:  36%|▎| 5338/15000 [45:17<28:51,  5.58it/s, lr=0.000665, step_loss=0.191]07/27/2023 18:30:06 - INFO - __main__ - train loss is 24.432411927962676\n",
      "Steps:  36%|▎| 5339/15000 [45:17<28:51,  5.58it/s, lr=0.000666, step_loss=0.052507/27/2023 18:30:07 - INFO - __main__ - train loss is 24.435266479384154\n",
      "Steps:  36%|▎| 5340/15000 [45:17<28:51,  5.58it/s, lr=0.000666, step_loss=0.002807/27/2023 18:30:07 - INFO - __main__ - train loss is 25.28953157318756\n",
      "Steps:  36%|▎| 5341/15000 [45:17<28:52,  5.58it/s, lr=0.000666, step_loss=0.854]07/27/2023 18:30:07 - INFO - __main__ - train loss is 25.291019550873898\n",
      "Steps:  36%|▎| 5342/15000 [45:17<28:57,  5.56it/s, lr=0.000666, step_loss=0.001407/27/2023 18:30:07 - INFO - __main__ - train loss is 25.30298607738223\n",
      "Steps:  36%|▎| 5343/15000 [45:17<28:55,  5.57it/s, lr=0.000666, step_loss=0.012]07/27/2023 18:30:07 - INFO - __main__ - train loss is 25.423650524928235\n",
      "Steps:  36%|▎| 5344/15000 [45:18<28:53,  5.57it/s, lr=0.000666, step_loss=0.121]07/27/2023 18:30:08 - INFO - __main__ - train loss is 25.561589486314915\n",
      "Steps:  36%|▎| 5345/15000 [45:18<28:53,  5.57it/s, lr=0.000666, step_loss=0.138]07/27/2023 18:30:08 - INFO - __main__ - train loss is 25.57857116998639\n",
      "Steps:  36%|▎| 5346/15000 [45:18<28:52,  5.57it/s, lr=0.000666, step_loss=0.017]07/27/2023 18:30:08 - INFO - __main__ - train loss is 25.727103873505257\n",
      "Steps:  36%|▎| 5347/15000 [45:18<28:54,  5.57it/s, lr=0.000667, step_loss=0.149]07/27/2023 18:30:08 - INFO - __main__ - train loss is 26.194770916714333\n",
      "Steps:  36%|▎| 5348/15000 [45:18<28:52,  5.57it/s, lr=0.000667, step_loss=0.468]07/27/2023 18:30:08 - INFO - __main__ - train loss is 26.1991652835859\n",
      "Steps:  36%|▎| 5349/15000 [45:19<28:52,  5.57it/s, lr=0.000667, step_loss=0.004307/27/2023 18:30:08 - INFO - __main__ - train loss is 26.206198562285863\n",
      "Steps:  36%|▎| 5350/15000 [45:19<28:51,  5.57it/s, lr=0.000667, step_loss=0.007007/27/2023 18:30:09 - INFO - __main__ - train loss is 26.26877329160925\n",
      "Steps:  36%|▎| 5351/15000 [45:19<28:51,  5.57it/s, lr=0.000667, step_loss=0.062607/27/2023 18:30:09 - INFO - __main__ - train loss is 26.313864440075122\n",
      "Steps:  36%|▎| 5352/15000 [45:19<28:51,  5.57it/s, lr=0.000667, step_loss=0.045107/27/2023 18:30:09 - INFO - __main__ - train loss is 26.64058321749326\n",
      "Steps:  36%|▎| 5353/15000 [45:19<28:51,  5.57it/s, lr=0.000667, step_loss=0.327]07/27/2023 18:30:09 - INFO - __main__ - train loss is 26.646773369400762\n",
      "Steps:  36%|▎| 5354/15000 [45:19<28:51,  5.57it/s, lr=0.000668, step_loss=0.006107/27/2023 18:30:09 - INFO - __main__ - train loss is 26.695155796944164\n",
      "Steps:  36%|▎| 5355/15000 [45:20<28:51,  5.57it/s, lr=0.000668, step_loss=0.048407/27/2023 18:30:09 - INFO - __main__ - train loss is 26.860951778828166\n",
      "Steps:  36%|▎| 5356/15000 [45:20<28:51,  5.57it/s, lr=0.000668, step_loss=0.166]07/27/2023 18:30:10 - INFO - __main__ - train loss is 26.933755231439136\n",
      "Steps:  36%|▎| 5357/15000 [45:20<28:50,  5.57it/s, lr=0.000668, step_loss=0.072807/27/2023 18:30:10 - INFO - __main__ - train loss is 27.08001647645142\n",
      "Steps:  36%|▎| 5358/15000 [45:20<28:50,  5.57it/s, lr=0.000668, step_loss=0.146]07/27/2023 18:30:10 - INFO - __main__ - train loss is 27.239961472689174\n",
      "Steps:  36%|▋ | 5359/15000 [45:20<28:50,  5.57it/s, lr=0.000668, step_loss=0.16]07/27/2023 18:30:10 - INFO - __main__ - train loss is 27.241955293691717\n",
      "Steps:  36%|▎| 5360/15000 [45:21<28:48,  5.58it/s, lr=0.000668, step_loss=0.001907/27/2023 18:30:10 - INFO - __main__ - train loss is 27.266911378479563\n",
      "Steps:  36%|▎| 5361/15000 [45:21<28:48,  5.58it/s, lr=0.000668, step_loss=0.025]07/27/2023 18:30:11 - INFO - __main__ - train loss is 27.297739295638166\n",
      "Steps:  36%|▎| 5362/15000 [45:21<28:49,  5.57it/s, lr=0.000669, step_loss=0.030807/27/2023 18:30:11 - INFO - __main__ - train loss is 27.567285744822584\n",
      "Steps:  36%|▋ | 5363/15000 [45:21<28:49,  5.57it/s, lr=0.000669, step_loss=0.27]07/27/2023 18:30:11 - INFO - __main__ - train loss is 27.66679560986813\n",
      "Steps:  36%|▎| 5364/15000 [45:21<28:49,  5.57it/s, lr=0.000669, step_loss=0.099507/27/2023 18:30:11 - INFO - __main__ - train loss is 28.21969097701367\n",
      "Steps:  36%|▎| 5365/15000 [45:21<28:49,  5.57it/s, lr=0.000669, step_loss=0.553]07/27/2023 18:30:11 - INFO - __main__ - train loss is 28.23028736037668\n",
      "Steps:  36%|▎| 5366/15000 [45:22<28:48,  5.57it/s, lr=0.000669, step_loss=0.010607/27/2023 18:30:11 - INFO - __main__ - train loss is 28.300963813788258\n",
      "Steps:  36%|▎| 5367/15000 [45:22<28:48,  5.57it/s, lr=0.000669, step_loss=0.070707/27/2023 18:30:12 - INFO - __main__ - train loss is 28.31205601838883\n",
      "Steps:  36%|▎| 5368/15000 [45:22<28:50,  5.57it/s, lr=0.000669, step_loss=0.011107/27/2023 18:30:12 - INFO - __main__ - train loss is 28.315242493874393\n",
      "Steps:  36%|▎| 5369/15000 [45:22<28:50,  5.57it/s, lr=0.000669, step_loss=0.003107/27/2023 18:30:12 - INFO - __main__ - train loss is 28.497345948941074\n",
      "Steps:  36%|▎| 5370/15000 [45:22<28:50,  5.57it/s, lr=0.000669, step_loss=0.182]07/27/2023 18:30:12 - INFO - __main__ - train loss is 28.518982963985763\n",
      "Steps:  36%|▎| 5371/15000 [45:22<29:06,  5.51it/s, lr=0.00067, step_loss=0.0216]07/27/2023 18:30:12 - INFO - __main__ - train loss is 28.551711803651415\n",
      "Steps:  36%|▎| 5372/15000 [45:23<29:27,  5.45it/s, lr=0.00067, step_loss=0.0327]07/27/2023 18:30:13 - INFO - __main__ - train loss is 28.862200117087923\n",
      "Steps:  36%|█  | 5373/15000 [45:23<29:30,  5.44it/s, lr=0.00067, step_loss=0.31]07/27/2023 18:30:13 - INFO - __main__ - train loss is 28.88981967640575\n",
      "Steps:  36%|▎| 5374/15000 [45:23<29:18,  5.48it/s, lr=0.00067, step_loss=0.0276]07/27/2023 18:30:13 - INFO - __main__ - train loss is 29.087757239467464\n",
      "Steps:  36%|▋ | 5375/15000 [45:23<29:08,  5.50it/s, lr=0.00067, step_loss=0.198]07/27/2023 18:30:13 - INFO - __main__ - train loss is 29.150666872388683\n",
      "Steps:  36%|▎| 5376/15000 [45:23<29:18,  5.47it/s, lr=0.00067, step_loss=0.0629]07/27/2023 18:30:13 - INFO - __main__ - train loss is 29.16202419565525\n",
      "Steps:  36%|▎| 5377/15000 [45:24<29:22,  5.46it/s, lr=0.00067, step_loss=0.0114]07/27/2023 18:30:13 - INFO - __main__ - train loss is 29.184440034790896\n",
      "Steps:  36%|▎| 5378/15000 [45:24<29:16,  5.48it/s, lr=0.00067, step_loss=0.0224]07/27/2023 18:30:14 - INFO - __main__ - train loss is 29.246686394675635\n",
      "Steps:  36%|▎| 5379/15000 [45:24<29:22,  5.46it/s, lr=0.000671, step_loss=0.062207/27/2023 18:30:14 - INFO - __main__ - train loss is 29.352797086699866\n",
      "Steps:  36%|▎| 5380/15000 [45:24<29:11,  5.49it/s, lr=0.000671, step_loss=0.106]07/27/2023 18:30:14 - INFO - __main__ - train loss is 29.69866191910114\n",
      "Steps:  36%|▎| 5381/15000 [45:24<29:05,  5.51it/s, lr=0.000671, step_loss=0.346]07/27/2023 18:30:14 - INFO - __main__ - train loss is 29.76470881269779\n",
      "Steps:  36%|▎| 5382/15000 [45:25<28:59,  5.53it/s, lr=0.000671, step_loss=0.066]07/27/2023 18:30:14 - INFO - __main__ - train loss is 29.768486931337975\n",
      "Steps:  36%|▎| 5383/15000 [45:25<28:55,  5.54it/s, lr=0.000671, step_loss=0.003707/27/2023 18:30:15 - INFO - __main__ - train loss is 30.073864921345375\n",
      "Steps:  36%|▎| 5384/15000 [45:25<28:51,  5.55it/s, lr=0.000671, step_loss=0.305]07/27/2023 18:30:15 - INFO - __main__ - train loss is 30.256863206042908\n",
      "Steps:  36%|▎| 5385/15000 [45:25<28:53,  5.55it/s, lr=0.000671, step_loss=0.183]07/27/2023 18:30:15 - INFO - __main__ - train loss is 30.302647560252808\n",
      "Steps:  36%|▎| 5386/15000 [45:25<28:51,  5.55it/s, lr=0.000672, step_loss=0.045807/27/2023 18:30:15 - INFO - __main__ - train loss is 30.421270787133835\n",
      "Steps:  36%|▎| 5387/15000 [45:25<28:50,  5.55it/s, lr=0.000672, step_loss=0.119]07/27/2023 18:30:15 - INFO - __main__ - train loss is 30.540237306966446\n",
      "Steps:  36%|▎| 5388/15000 [45:26<28:50,  5.55it/s, lr=0.000672, step_loss=0.119]07/27/2023 18:30:15 - INFO - __main__ - train loss is 30.568151208921336\n",
      "Steps:  36%|▎| 5389/15000 [45:26<28:49,  5.56it/s, lr=0.000672, step_loss=0.027907/27/2023 18:30:16 - INFO - __main__ - train loss is 30.610806509270333\n",
      "Steps:  36%|▎| 5390/15000 [45:26<28:47,  5.56it/s, lr=0.000672, step_loss=0.042707/27/2023 18:30:16 - INFO - __main__ - train loss is 30.642067375942133\n",
      "Steps:  36%|▎| 5391/15000 [45:26<28:46,  5.57it/s, lr=0.000672, step_loss=0.031307/27/2023 18:30:16 - INFO - __main__ - train loss is 30.931550386711024\n",
      "Steps:  36%|▎| 5392/15000 [45:26<28:45,  5.57it/s, lr=0.000672, step_loss=0.289]07/27/2023 18:30:16 - INFO - __main__ - train loss is 31.518110218807124\n",
      "Steps:  36%|▎| 5393/15000 [45:26<28:44,  5.57it/s, lr=0.000672, step_loss=0.587]07/27/2023 18:30:16 - INFO - __main__ - train loss is 31.536462025134824\n",
      "Steps:  36%|▎| 5394/15000 [45:27<28:44,  5.57it/s, lr=0.000673, step_loss=0.018407/27/2023 18:30:17 - INFO - __main__ - train loss is 31.66018422821071\n",
      "Steps:  36%|▎| 5395/15000 [45:27<28:44,  5.57it/s, lr=0.000673, step_loss=0.124]07/27/2023 18:30:17 - INFO - __main__ - train loss is 32.014671468525194\n",
      "Steps:  36%|▎| 5396/15000 [45:27<28:44,  5.57it/s, lr=0.000673, step_loss=0.354]07/27/2023 18:30:17 - INFO - __main__ - train loss is 32.17223950603511\n",
      "Steps:  36%|▎| 5397/15000 [45:27<28:44,  5.57it/s, lr=0.000673, step_loss=0.158]07/27/2023 18:30:17 - INFO - __main__ - train loss is 32.19147913099732\n",
      "Steps:  36%|▎| 5398/15000 [45:27<28:44,  5.57it/s, lr=0.000673, step_loss=0.019207/27/2023 18:30:17 - INFO - __main__ - train loss is 32.51633451820817\n",
      "Steps:  36%|▎| 5399/15000 [45:28<28:43,  5.57it/s, lr=0.000673, step_loss=0.325]07/27/2023 18:30:17 - INFO - __main__ - train loss is 33.14636014343705\n",
      "Steps:  36%|▋ | 5400/15000 [45:28<28:44,  5.57it/s, lr=0.000673, step_loss=0.63]07/27/2023 18:30:18 - INFO - __main__ - train loss is 33.17359164298978\n",
      "Steps:  36%|▎| 5401/15000 [45:28<28:51,  5.55it/s, lr=0.000673, step_loss=0.027207/27/2023 18:30:18 - INFO - __main__ - train loss is 33.18412892182823\n",
      "Steps:  36%|▎| 5402/15000 [45:28<28:48,  5.55it/s, lr=0.000674, step_loss=0.010507/27/2023 18:30:18 - INFO - __main__ - train loss is 33.213793712086044\n",
      "Steps:  36%|▎| 5403/15000 [45:28<28:46,  5.56it/s, lr=0.000674, step_loss=0.029707/27/2023 18:30:18 - INFO - __main__ - train loss is 33.27028564212378\n",
      "Steps:  36%|▎| 5404/15000 [45:28<28:45,  5.56it/s, lr=0.000674, step_loss=0.056507/27/2023 18:30:18 - INFO - __main__ - train loss is 33.78512290713843\n",
      "Steps:  36%|▎| 5405/15000 [45:29<28:44,  5.56it/s, lr=0.000674, step_loss=0.515]07/27/2023 18:30:19 - INFO - __main__ - train loss is 33.787104433286004\n",
      "Steps:  36%|▎| 5406/15000 [45:29<28:43,  5.57it/s, lr=0.000674, step_loss=0.001907/27/2023 18:30:19 - INFO - __main__ - train loss is 33.89196138631087\n",
      "Steps:  36%|▎| 5407/15000 [45:29<28:43,  5.57it/s, lr=0.000674, step_loss=0.105]07/27/2023 18:30:19 - INFO - __main__ - train loss is 33.89807142724749\n",
      "Steps:  36%|▎| 5408/15000 [45:29<28:43,  5.57it/s, lr=0.000674, step_loss=0.006107/27/2023 18:30:19 - INFO - __main__ - train loss is 34.10664329340216\n",
      "Steps:  36%|▎| 5409/15000 [45:29<28:42,  5.57it/s, lr=0.000674, step_loss=0.209]07/27/2023 18:30:19 - INFO - __main__ - train loss is 34.344849113724194\n",
      "Steps:  36%|▎| 5410/15000 [45:30<28:58,  5.52it/s, lr=0.000674, step_loss=0.238]07/27/2023 18:30:19 - INFO - __main__ - train loss is 34.3604024493834\n",
      "Steps:  36%|▎| 5411/15000 [45:30<29:00,  5.51it/s, lr=0.000675, step_loss=0.015607/27/2023 18:30:20 - INFO - __main__ - train loss is 34.568679063930176\n",
      "Steps:  36%|▎| 5412/15000 [45:30<28:54,  5.53it/s, lr=0.000675, step_loss=0.208]07/27/2023 18:30:20 - INFO - __main__ - train loss is 34.572134942165576\n",
      "Steps:  36%|▎| 5413/15000 [45:30<29:01,  5.51it/s, lr=0.000675, step_loss=0.003407/27/2023 18:30:20 - INFO - __main__ - train loss is 34.573617763700895\n",
      "Steps:  36%|▎| 5414/15000 [45:30<29:01,  5.50it/s, lr=0.000675, step_loss=0.001407/27/2023 18:30:20 - INFO - __main__ - train loss is 34.868132598581724\n",
      "Steps:  36%|▎| 5415/15000 [45:30<29:02,  5.50it/s, lr=0.000675, step_loss=0.295]07/27/2023 18:30:20 - INFO - __main__ - train loss is 34.86988068732899\n",
      "Steps:  36%|▎| 5416/15000 [45:31<29:03,  5.50it/s, lr=0.000675, step_loss=0.001707/27/2023 18:30:21 - INFO - __main__ - train loss is 35.198188912007026\n",
      "Steps:  36%|▎| 5417/15000 [45:31<29:03,  5.50it/s, lr=0.000675, step_loss=0.328]07/27/2023 18:30:21 - INFO - __main__ - train loss is 35.25081084284466\n",
      "Steps:  36%|▎| 5418/15000 [45:31<29:03,  5.49it/s, lr=0.000675, step_loss=0.052607/27/2023 18:30:21 - INFO - __main__ - train loss is 35.54270933184307\n",
      "Steps:  36%|▎| 5419/15000 [45:31<29:03,  5.50it/s, lr=0.000676, step_loss=0.292]07/27/2023 18:30:21 - INFO - __main__ - train loss is 35.681006561848335\n",
      "Steps:  36%|▎| 5420/15000 [45:31<29:03,  5.50it/s, lr=0.000676, step_loss=0.138]07/27/2023 18:30:21 - INFO - __main__ - train loss is 35.6925186914159\n",
      "Steps:  36%|▎| 5421/15000 [45:32<29:04,  5.49it/s, lr=0.000676, step_loss=0.011507/27/2023 18:30:21 - INFO - __main__ - train loss is 35.70798670395743\n",
      "Steps:  36%|▎| 5422/15000 [45:32<29:03,  5.49it/s, lr=0.000676, step_loss=0.015507/27/2023 18:30:22 - INFO - __main__ - train loss is 35.710943746729754\n",
      "Steps:  36%|▎| 5423/15000 [45:32<29:03,  5.49it/s, lr=0.000676, step_loss=0.002907/27/2023 18:30:22 - INFO - __main__ - train loss is 36.649507689638995\n",
      "Steps:  36%|▎| 5424/15000 [45:32<29:03,  5.49it/s, lr=0.000676, step_loss=0.939]07/27/2023 18:30:22 - INFO - __main__ - train loss is 36.794272858067416\n",
      "Steps:  36%|▎| 5425/15000 [45:32<28:55,  5.52it/s, lr=0.000676, step_loss=0.145]07/27/2023 18:30:22 - INFO - __main__ - train loss is 37.02843545691576\n",
      "Steps:  36%|▎| 5426/15000 [45:32<28:50,  5.53it/s, lr=0.000677, step_loss=0.234]07/27/2023 18:30:22 - INFO - __main__ - train loss is 37.21390830294695\n",
      "Steps:  36%|▎| 5427/15000 [45:33<28:46,  5.54it/s, lr=0.000677, step_loss=0.185]07/27/2023 18:30:22 - INFO - __main__ - train loss is 37.239458027645014\n",
      "Steps:  36%|▎| 5428/15000 [45:33<28:43,  5.55it/s, lr=0.000677, step_loss=0.025507/27/2023 18:30:23 - INFO - __main__ - train loss is 37.60660595016088\n",
      "Steps:  36%|▎| 5429/15000 [45:33<28:40,  5.56it/s, lr=0.000677, step_loss=0.367]07/27/2023 18:30:23 - INFO - __main__ - train loss is 37.68787364230957\n",
      "Steps:  36%|▎| 5430/15000 [45:33<28:39,  5.57it/s, lr=0.000677, step_loss=0.081307/27/2023 18:30:23 - INFO - __main__ - train loss is 37.73292597697582\n",
      "Steps:  36%|▎| 5431/15000 [45:33<28:37,  5.57it/s, lr=0.000677, step_loss=0.045107/27/2023 18:30:23 - INFO - __main__ - train loss is 37.745433717384\n",
      "Steps:  36%|▎| 5432/15000 [45:34<28:37,  5.57it/s, lr=0.000677, step_loss=0.012507/27/2023 18:30:23 - INFO - __main__ - train loss is 37.74799569172319\n",
      "Steps:  36%|▎| 5433/15000 [45:34<28:38,  5.57it/s, lr=0.000677, step_loss=0.002507/27/2023 18:30:24 - INFO - __main__ - train loss is 37.85222063434776\n",
      "Steps:  36%|▎| 5434/15000 [45:34<28:37,  5.57it/s, lr=0.000678, step_loss=0.104]07/27/2023 18:30:24 - INFO - __main__ - train loss is 37.856752473744564\n",
      "Steps:  36%|▎| 5435/15000 [45:34<28:36,  5.57it/s, lr=0.000678, step_loss=0.004507/27/2023 18:30:24 - INFO - __main__ - train loss is 38.16361834469717\n",
      "Steps:  36%|▎| 5436/15000 [45:34<28:47,  5.54it/s, lr=0.000678, step_loss=0.307]07/27/2023 18:30:24 - INFO - __main__ - train loss is 38.21015621337574\n",
      "Steps:  36%|▎| 5437/15000 [45:34<28:59,  5.50it/s, lr=0.000678, step_loss=0.046507/27/2023 18:30:24 - INFO - __main__ - train loss is 38.3441474995343\n",
      "Steps:  36%|▎| 5438/15000 [45:35<28:56,  5.51it/s, lr=0.000678, step_loss=0.134]07/27/2023 18:30:24 - INFO - __main__ - train loss is 38.35975436295848\n",
      "Steps:  36%|▎| 5439/15000 [45:35<28:48,  5.53it/s, lr=0.000678, step_loss=0.015607/27/2023 18:30:25 - INFO - __main__ - train loss is 38.37349484662991\n",
      "Steps:  36%|▎| 5440/15000 [45:35<28:42,  5.55it/s, lr=0.000678, step_loss=0.013707/27/2023 18:30:25 - INFO - __main__ - train loss is 38.45439965080004\n",
      "Steps:  36%|▎| 5441/15000 [45:35<28:39,  5.56it/s, lr=0.000678, step_loss=0.080907/27/2023 18:30:25 - INFO - __main__ - train loss is 38.50604321609717\n",
      "Steps:  36%|▎| 5442/15000 [45:35<28:37,  5.57it/s, lr=0.000678, step_loss=0.051607/27/2023 18:30:25 - INFO - __main__ - train loss is 38.54590344976168\n",
      "Steps:  36%|▎| 5443/15000 [45:36<28:37,  5.57it/s, lr=0.000679, step_loss=0.039907/27/2023 18:30:25 - INFO - __main__ - train loss is 38.5475973096909\n",
      "Steps:  36%|▎| 5444/15000 [45:36<28:36,  5.57it/s, lr=0.000679, step_loss=0.001607/27/2023 18:30:26 - INFO - __main__ - train loss is 38.671246228856035\n",
      "Steps:  36%|▎| 5445/15000 [45:36<28:37,  5.56it/s, lr=0.000679, step_loss=0.124]07/27/2023 18:30:26 - INFO - __main__ - train loss is 38.85354178969283\n",
      "Steps:  36%|▎| 5446/15000 [45:36<28:50,  5.52it/s, lr=0.000679, step_loss=0.182]07/27/2023 18:30:26 - INFO - __main__ - train loss is 38.863787270267494\n",
      "Steps:  36%|▎| 5447/15000 [45:36<28:49,  5.52it/s, lr=0.000679, step_loss=0.010207/27/2023 18:30:26 - INFO - __main__ - train loss is 39.247350550373085\n",
      "Steps:  36%|▎| 5448/15000 [45:36<28:43,  5.54it/s, lr=0.000679, step_loss=0.384]07/27/2023 18:30:26 - INFO - __main__ - train loss is 39.33005877502728\n",
      "Steps:  36%|▎| 5449/15000 [45:37<28:54,  5.51it/s, lr=0.000679, step_loss=0.082707/27/2023 18:30:26 - INFO - __main__ - train loss is 39.788878551800735\n",
      "Steps:  36%|▎| 5450/15000 [45:37<28:51,  5.51it/s, lr=0.000679, step_loss=0.459]07/27/2023 18:30:27 - INFO - __main__ - train loss is 39.79155301221181\n",
      "Steps:  36%|▎| 5451/15000 [45:37<28:45,  5.53it/s, lr=0.00068, step_loss=0.0026707/27/2023 18:30:27 - INFO - __main__ - train loss is 39.80664889991749\n",
      "Steps:  36%|▎| 5452/15000 [45:37<28:40,  5.55it/s, lr=0.00068, step_loss=0.0151]07/27/2023 18:30:27 - INFO - __main__ - train loss is 39.82524444826413\n",
      "Steps:  36%|▎| 5453/15000 [45:37<28:53,  5.51it/s, lr=0.00068, step_loss=0.0186]07/27/2023 18:30:27 - INFO - __main__ - train loss is 39.89652081497479\n",
      "Steps:  36%|▎| 5454/15000 [45:38<43:25,  3.66it/s, lr=0.00068, step_loss=0.0713]07/27/2023 18:30:29 - INFO - __main__ - Per validation step average loss is 0.052310049533843994\n",
      "07/27/2023 18:30:29 - INFO - __main__ - Cumulative validation average loss is 0.052310049533843994\n",
      "07/27/2023 18:30:29 - INFO - __main__ - Per validation step average loss is 0.6785829663276672\n",
      "07/27/2023 18:30:29 - INFO - __main__ - Cumulative validation average loss is 0.7308930158615112\n",
      "07/27/2023 18:30:29 - INFO - __main__ - Per validation step average loss is 0.008746415376663208\n",
      "07/27/2023 18:30:29 - INFO - __main__ - Cumulative validation average loss is 0.7396394312381744\n",
      "07/27/2023 18:30:30 - INFO - __main__ - Per validation step average loss is 0.015413273125886917\n",
      "07/27/2023 18:30:30 - INFO - __main__ - Cumulative validation average loss is 0.7550527043640614\n",
      "07/27/2023 18:30:30 - INFO - __main__ - Per validation step average loss is 0.26432520151138306\n",
      "07/27/2023 18:30:30 - INFO - __main__ - Cumulative validation average loss is 1.0193779058754444\n",
      "07/27/2023 18:30:31 - INFO - __main__ - Per validation step average loss is 0.16490870714187622\n",
      "07/27/2023 18:30:31 - INFO - __main__ - Cumulative validation average loss is 1.1842866130173206\n",
      "07/27/2023 18:30:31 - INFO - __main__ - Per validation step average loss is 0.07191018015146255\n",
      "07/27/2023 18:30:31 - INFO - __main__ - Cumulative validation average loss is 1.2561967931687832\n",
      "07/27/2023 18:30:32 - INFO - __main__ - Per validation step average loss is 0.05538734793663025\n",
      "07/27/2023 18:30:32 - INFO - __main__ - Cumulative validation average loss is 1.3115841411054134\n",
      "07/27/2023 18:30:32 - INFO - __main__ - Per validation step average loss is 0.015200842171907425\n",
      "07/27/2023 18:30:32 - INFO - __main__ - Cumulative validation average loss is 1.3267849832773209\n",
      "07/27/2023 18:30:32 - INFO - __main__ - Per validation step average loss is 0.291034996509552\n",
      "07/27/2023 18:30:32 - INFO - __main__ - Cumulative validation average loss is 1.6178199797868729\n",
      "07/27/2023 18:30:33 - INFO - __main__ - Per validation step average loss is 0.13079115748405457\n",
      "07/27/2023 18:30:33 - INFO - __main__ - Cumulative validation average loss is 1.7486111372709274\n",
      "07/27/2023 18:30:33 - INFO - __main__ - Per validation step average loss is 0.028691507875919342\n",
      "07/27/2023 18:30:33 - INFO - __main__ - Cumulative validation average loss is 1.7773026451468468\n",
      "07/27/2023 18:30:34 - INFO - __main__ - Per validation step average loss is 0.014106357470154762\n",
      "07/27/2023 18:30:34 - INFO - __main__ - Cumulative validation average loss is 1.7914090026170015\n",
      "07/27/2023 18:30:34 - INFO - __main__ - Per validation step average loss is 0.001355461892671883\n",
      "07/27/2023 18:30:34 - INFO - __main__ - Cumulative validation average loss is 1.7927644645096734\n",
      "07/27/2023 18:30:34 - INFO - __main__ - Per validation step average loss is 0.02179141528904438\n",
      "07/27/2023 18:30:34 - INFO - __main__ - Cumulative validation average loss is 1.8145558797987178\n",
      "07/27/2023 18:30:35 - INFO - __main__ - Per validation step average loss is 0.019545890390872955\n",
      "07/27/2023 18:30:35 - INFO - __main__ - Cumulative validation average loss is 1.8341017701895908\n",
      "07/27/2023 18:30:35 - INFO - __main__ - Per validation step average loss is 0.025868721306324005\n",
      "07/27/2023 18:30:35 - INFO - __main__ - Cumulative validation average loss is 1.8599704914959148\n",
      "07/27/2023 18:30:36 - INFO - __main__ - Per validation step average loss is 0.04334278777241707\n",
      "07/27/2023 18:30:36 - INFO - __main__ - Cumulative validation average loss is 1.9033132792683318\n",
      "07/27/2023 18:30:36 - INFO - __main__ - Per validation step average loss is 0.18855667114257812\n",
      "07/27/2023 18:30:36 - INFO - __main__ - Cumulative validation average loss is 2.09186995041091\n",
      "07/27/2023 18:30:36 - INFO - __main__ - Per validation step average loss is 0.24411338567733765\n",
      "07/27/2023 18:30:36 - INFO - __main__ - Cumulative validation average loss is 2.3359833360882476\n",
      "07/27/2023 18:30:37 - INFO - __main__ - Per validation step average loss is 0.14885196089744568\n",
      "07/27/2023 18:30:37 - INFO - __main__ - Cumulative validation average loss is 2.4848352969856933\n",
      "07/27/2023 18:30:37 - INFO - __main__ - Per validation step average loss is 0.027748504653573036\n",
      "07/27/2023 18:30:37 - INFO - __main__ - Cumulative validation average loss is 2.5125838016392663\n",
      "07/27/2023 18:30:38 - INFO - __main__ - Per validation step average loss is 0.07126333564519882\n",
      "07/27/2023 18:30:38 - INFO - __main__ - Cumulative validation average loss is 2.583847137284465\n",
      "07/27/2023 18:30:38 - INFO - __main__ - Per validation step average loss is 0.0020675291307270527\n",
      "07/27/2023 18:30:38 - INFO - __main__ - Cumulative validation average loss is 2.585914666415192\n",
      "07/27/2023 18:30:39 - INFO - __main__ - Per validation step average loss is 0.003744437824934721\n",
      "07/27/2023 18:30:39 - INFO - __main__ - Cumulative validation average loss is 2.589659104240127\n",
      "07/27/2023 18:30:39 - INFO - __main__ - Per validation step average loss is 0.0028980174101889133\n",
      "07/27/2023 18:30:39 - INFO - __main__ - Cumulative validation average loss is 2.592557121650316\n",
      "07/27/2023 18:30:39 - INFO - __main__ - Per validation step average loss is 0.05662842467427254\n",
      "07/27/2023 18:30:39 - INFO - __main__ - Cumulative validation average loss is 2.6491855463245884\n",
      "07/27/2023 18:30:40 - INFO - __main__ - Per validation step average loss is 0.007046198472380638\n",
      "07/27/2023 18:30:40 - INFO - __main__ - Cumulative validation average loss is 2.656231744796969\n",
      "07/27/2023 18:30:40 - INFO - __main__ - Per validation step average loss is 0.08197438716888428\n",
      "07/27/2023 18:30:40 - INFO - __main__ - Cumulative validation average loss is 2.7382061319658533\n",
      "07/27/2023 18:30:41 - INFO - __main__ - Per validation step average loss is 0.0018096806015819311\n",
      "07/27/2023 18:30:41 - INFO - __main__ - Cumulative validation average loss is 2.740015812567435\n",
      "07/27/2023 18:30:41 - INFO - __main__ - Per validation step average loss is 0.004308286122977734\n",
      "07/27/2023 18:30:41 - INFO - __main__ - Cumulative validation average loss is 2.744324098690413\n",
      "07/27/2023 18:30:41 - INFO - __main__ - Per validation step average loss is 0.08251398801803589\n",
      "07/27/2023 18:30:41 - INFO - __main__ - Cumulative validation average loss is 2.826838086708449\n",
      "07/27/2023 18:30:42 - INFO - __main__ - Per validation step average loss is 0.0015658042393624783\n",
      "07/27/2023 18:30:42 - INFO - __main__ - Cumulative validation average loss is 2.8284038909478113\n",
      "07/27/2023 18:30:42 - INFO - __main__ - Per validation step average loss is 0.3194252848625183\n",
      "07/27/2023 18:30:42 - INFO - __main__ - Cumulative validation average loss is 3.1478291758103296\n",
      "07/27/2023 18:30:43 - INFO - __main__ - Per validation step average loss is 0.33502396941185\n",
      "07/27/2023 18:30:43 - INFO - __main__ - Cumulative validation average loss is 3.4828531452221796\n",
      "07/27/2023 18:30:43 - INFO - __main__ - Per validation step average loss is 0.02714104950428009\n",
      "07/27/2023 18:30:43 - INFO - __main__ - Cumulative validation average loss is 3.5099941947264597\n",
      "07/27/2023 18:30:44 - INFO - __main__ - Per validation step average loss is 0.01763472706079483\n",
      "07/27/2023 18:30:44 - INFO - __main__ - Cumulative validation average loss is 3.5276289217872545\n",
      "07/27/2023 18:30:44 - INFO - __main__ - Per validation step average loss is 0.041651107370853424\n",
      "07/27/2023 18:30:44 - INFO - __main__ - Cumulative validation average loss is 3.569280029158108\n",
      "07/27/2023 18:30:44 - INFO - __main__ - Per validation step average loss is 0.006591525860130787\n",
      "07/27/2023 18:30:44 - INFO - __main__ - Cumulative validation average loss is 3.5758715550182387\n",
      "07/27/2023 18:30:45 - INFO - __main__ - Per validation step average loss is 0.1157461553812027\n",
      "07/27/2023 18:30:45 - INFO - __main__ - Cumulative validation average loss is 3.6916177103994414\n",
      "07/27/2023 18:30:45 - INFO - __main__ - Per validation step average loss is 0.019074195995926857\n",
      "07/27/2023 18:30:45 - INFO - __main__ - Cumulative validation average loss is 3.7106919063953683\n",
      "07/27/2023 18:30:46 - INFO - __main__ - Per validation step average loss is 0.0066219293512403965\n",
      "07/27/2023 18:30:46 - INFO - __main__ - Cumulative validation average loss is 3.7173138357466087\n",
      "07/27/2023 18:30:46 - INFO - __main__ - Per validation step average loss is 0.01206301897764206\n",
      "07/27/2023 18:30:46 - INFO - __main__ - Cumulative validation average loss is 3.7293768547242507\n",
      "07/27/2023 18:30:46 - INFO - __main__ - Per validation step average loss is 0.3039405047893524\n",
      "07/27/2023 18:30:46 - INFO - __main__ - Cumulative validation average loss is 4.033317359513603\n",
      "07/27/2023 18:30:47 - INFO - __main__ - Per validation step average loss is 0.01693752221763134\n",
      "07/27/2023 18:30:47 - INFO - __main__ - Cumulative validation average loss is 4.0502548817312345\n",
      "07/27/2023 18:30:47 - INFO - __main__ - Per validation step average loss is 0.0385565347969532\n",
      "07/27/2023 18:30:47 - INFO - __main__ - Cumulative validation average loss is 4.088811416528188\n",
      "07/27/2023 18:30:48 - INFO - __main__ - Per validation step average loss is 0.005057180766016245\n",
      "07/27/2023 18:30:48 - INFO - __main__ - Cumulative validation average loss is 4.093868597294204\n",
      "07/27/2023 18:30:48 - INFO - __main__ - Per validation step average loss is 0.039241209626197815\n",
      "07/27/2023 18:30:48 - INFO - __main__ - Cumulative validation average loss is 4.133109806920402\n",
      "07/27/2023 18:30:48 - INFO - __main__ - Per validation step average loss is 0.2455325424671173\n",
      "07/27/2023 18:30:48 - INFO - __main__ - Cumulative validation average loss is 4.378642349387519\n",
      "07/27/2023 18:30:49 - INFO - __main__ - Per validation step average loss is 0.005029527936130762\n",
      "07/27/2023 18:30:49 - INFO - __main__ - Cumulative validation average loss is 4.38367187732365\n",
      "07/27/2023 18:30:49 - INFO - __main__ - Per validation step average loss is 0.22482886910438538\n",
      "07/27/2023 18:30:49 - INFO - __main__ - Cumulative validation average loss is 4.608500746428035\n",
      "07/27/2023 18:30:50 - INFO - __main__ - Per validation step average loss is 0.012358162552118301\n",
      "07/27/2023 18:30:50 - INFO - __main__ - Cumulative validation average loss is 4.6208589089801535\n",
      "07/27/2023 18:30:50 - INFO - __main__ - Per validation step average loss is 0.01240520365536213\n",
      "07/27/2023 18:30:50 - INFO - __main__ - Cumulative validation average loss is 4.633264112635516\n",
      "07/27/2023 18:30:51 - INFO - __main__ - Per validation step average loss is 0.007924732752144337\n",
      "07/27/2023 18:30:51 - INFO - __main__ - Cumulative validation average loss is 4.64118884538766\n",
      "07/27/2023 18:30:51 - INFO - __main__ - Per validation step average loss is 0.03479664772748947\n",
      "07/27/2023 18:30:51 - INFO - __main__ - Cumulative validation average loss is 4.675985493115149\n",
      "07/27/2023 18:30:51 - INFO - __main__ - Per validation step average loss is 0.005871277302503586\n",
      "07/27/2023 18:30:51 - INFO - __main__ - Cumulative validation average loss is 4.681856770417653\n",
      "07/27/2023 18:30:52 - INFO - __main__ - Per validation step average loss is 0.1862172782421112\n",
      "07/27/2023 18:30:52 - INFO - __main__ - Cumulative validation average loss is 4.868074048659764\n",
      "07/27/2023 18:30:52 - INFO - __main__ - Per validation step average loss is 0.01125408336520195\n",
      "07/27/2023 18:30:52 - INFO - __main__ - Cumulative validation average loss is 4.879328132024966\n",
      "07/27/2023 18:30:53 - INFO - __main__ - Per validation step average loss is 0.34243544936180115\n",
      "07/27/2023 18:30:53 - INFO - __main__ - Cumulative validation average loss is 5.221763581386767\n",
      "07/27/2023 18:30:53 - INFO - __main__ - Per validation step average loss is 0.10564474016427994\n",
      "07/27/2023 18:30:53 - INFO - __main__ - Cumulative validation average loss is 5.327408321551047\n",
      "07/27/2023 18:30:53 - INFO - __main__ - Per validation step average loss is 0.039344921708106995\n",
      "07/27/2023 18:30:53 - INFO - __main__ - Cumulative validation average loss is 5.366753243259154\n",
      "07/27/2023 18:30:54 - INFO - __main__ - Per validation step average loss is 0.8890578746795654\n",
      "07/27/2023 18:30:54 - INFO - __main__ - Cumulative validation average loss is 6.25581111793872\n",
      "07/27/2023 18:30:54 - INFO - __main__ - Per validation step average loss is 0.3159228265285492\n",
      "07/27/2023 18:30:54 - INFO - __main__ - Cumulative validation average loss is 6.571733944467269\n",
      "07/27/2023 18:30:55 - INFO - __main__ - Per validation step average loss is 0.28695255517959595\n",
      "07/27/2023 18:30:55 - INFO - __main__ - Cumulative validation average loss is 6.858686499646865\n",
      "07/27/2023 18:30:55 - INFO - __main__ - Per validation step average loss is 0.07671568542718887\n",
      "07/27/2023 18:30:55 - INFO - __main__ - Cumulative validation average loss is 6.935402185074054\n",
      "07/27/2023 18:30:56 - INFO - __main__ - Per validation step average loss is 0.0014699131716042757\n",
      "07/27/2023 18:30:56 - INFO - __main__ - Cumulative validation average loss is 6.936872098245658\n",
      "07/27/2023 18:30:56 - INFO - __main__ - Per validation step average loss is 0.35527661442756653\n",
      "07/27/2023 18:30:56 - INFO - __main__ - Cumulative validation average loss is 7.2921487126732245\n",
      "07/27/2023 18:30:56 - INFO - __main__ - Per validation step average loss is 0.05532132089138031\n",
      "07/27/2023 18:30:56 - INFO - __main__ - Cumulative validation average loss is 7.347470033564605\n",
      "07/27/2023 18:30:57 - INFO - __main__ - Per validation step average loss is 0.17648470401763916\n",
      "07/27/2023 18:30:57 - INFO - __main__ - Cumulative validation average loss is 7.523954737582244\n",
      "07/27/2023 18:30:57 - INFO - __main__ - Per validation step average loss is 0.2976987361907959\n",
      "07/27/2023 18:30:57 - INFO - __main__ - Cumulative validation average loss is 7.82165347377304\n",
      "07/27/2023 18:30:58 - INFO - __main__ - Per validation step average loss is 0.0027902971487492323\n",
      "07/27/2023 18:30:58 - INFO - __main__ - Cumulative validation average loss is 7.824443770921789\n",
      "07/27/2023 18:30:58 - INFO - __main__ - Per validation step average loss is 0.413041353225708\n",
      "07/27/2023 18:30:58 - INFO - __main__ - Cumulative validation average loss is 8.237485124147497\n",
      "07/27/2023 18:30:58 - INFO - __main__ - Per validation step average loss is 0.0014391324948519468\n",
      "07/27/2023 18:30:58 - INFO - __main__ - Cumulative validation average loss is 8.238924256642349\n",
      "07/27/2023 18:30:59 - INFO - __main__ - Per validation step average loss is 0.0015693779569119215\n",
      "07/27/2023 18:30:59 - INFO - __main__ - Cumulative validation average loss is 8.240493634599261\n",
      "07/27/2023 18:30:59 - INFO - __main__ - Per validation step average loss is 0.0021242359653115273\n",
      "07/27/2023 18:30:59 - INFO - __main__ - Cumulative validation average loss is 8.242617870564573\n",
      "07/27/2023 18:31:00 - INFO - __main__ - Per validation step average loss is 0.012897778302431107\n",
      "07/27/2023 18:31:00 - INFO - __main__ - Cumulative validation average loss is 8.255515648867004\n",
      "07/27/2023 18:31:00 - INFO - __main__ - Per validation step average loss is 0.010918082669377327\n",
      "07/27/2023 18:31:00 - INFO - __main__ - Cumulative validation average loss is 8.266433731536381\n",
      "07/27/2023 18:31:00 - INFO - __main__ - Per validation step average loss is 0.05963457375764847\n",
      "07/27/2023 18:31:00 - INFO - __main__ - Cumulative validation average loss is 8.32606830529403\n",
      "07/27/2023 18:31:01 - INFO - __main__ - Per validation step average loss is 0.11489644646644592\n",
      "07/27/2023 18:31:01 - INFO - __main__ - Cumulative validation average loss is 8.440964751760475\n",
      "07/27/2023 18:31:01 - INFO - __main__ - Average validation loss for Epoch 17 is 0.10684765508557564\n",
      "07/27/2023 18:31:01 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 18:31:58 - INFO - __main__ - Starting epoch 18\n",
      "07/27/2023 18:31:59 - INFO - __main__ - train loss is 0.08959899842739105\n",
      "Steps:  36%|▎| 5455/15000 [47:09<73:00:30, 27.54s/it, lr=0.00068, step_loss=0.0807/27/2023 18:31:59 - INFO - __main__ - train loss is 0.4823030084371567\n",
      "Steps:  36%|▎| 5456/15000 [47:09<51:15:05, 19.33s/it, lr=0.00068, step_loss=0.3907/27/2023 18:31:59 - INFO - __main__ - train loss is 0.6400994211435318\n",
      "Steps:  36%|▎| 5457/15000 [47:09<36:01:20, 13.59s/it, lr=0.00068, step_loss=0.1507/27/2023 18:31:59 - INFO - __main__ - train loss is 0.6470814002677798\n",
      "Steps:  36%|▎| 5458/15000 [47:10<25:21:21,  9.57s/it, lr=0.000681, step_loss=0.007/27/2023 18:31:59 - INFO - __main__ - train loss is 0.764013092033565\n",
      "Steps:  36%|▎| 5459/15000 [47:10<17:53:25,  6.75s/it, lr=0.000681, step_loss=0.107/27/2023 18:32:00 - INFO - __main__ - train loss is 0.7673841407522559\n",
      "Steps:  36%|▎| 5460/15000 [47:10<12:40:13,  4.78s/it, lr=0.000681, step_loss=0.007/27/2023 18:32:00 - INFO - __main__ - train loss is 0.7694253167137504\n",
      "Steps:  36%|▎| 5461/15000 [47:10<9:00:37,  3.40s/it, lr=0.000681, step_loss=0.0007/27/2023 18:32:00 - INFO - __main__ - train loss is 0.8673678999766707\n",
      "Steps:  36%|▎| 5462/15000 [47:10<6:26:54,  2.43s/it, lr=0.000681, step_loss=0.0907/27/2023 18:32:00 - INFO - __main__ - train loss is 0.8709272970445454\n",
      "Steps:  36%|▎| 5463/15000 [47:10<4:39:21,  1.76s/it, lr=0.000681, step_loss=0.0007/27/2023 18:32:00 - INFO - __main__ - train loss is 0.921350431162864\n",
      "Steps:  36%|▎| 5464/15000 [47:11<3:24:02,  1.28s/it, lr=0.000681, step_loss=0.0507/27/2023 18:32:00 - INFO - __main__ - train loss is 1.0029709083028138\n",
      "Steps:  36%|▎| 5465/15000 [47:11<2:31:21,  1.05it/s, lr=0.000681, step_loss=0.0807/27/2023 18:32:01 - INFO - __main__ - train loss is 1.006153857568279\n",
      "Steps:  36%|▎| 5466/15000 [47:11<1:54:26,  1.39it/s, lr=0.000682, step_loss=0.0007/27/2023 18:32:01 - INFO - __main__ - train loss is 1.504085814813152\n",
      "Steps:  36%|▎| 5467/15000 [47:11<1:28:36,  1.79it/s, lr=0.000682, step_loss=0.4907/27/2023 18:32:01 - INFO - __main__ - train loss is 1.5210035166237503\n",
      "Steps:  36%|▎| 5468/15000 [47:11<1:10:37,  2.25it/s, lr=0.000682, step_loss=0.0107/27/2023 18:32:01 - INFO - __main__ - train loss is 1.736669602105394\n",
      "Steps:  36%|▎| 5469/15000 [47:11<57:56,  2.74it/s, lr=0.000682, step_loss=0.216]07/27/2023 18:32:01 - INFO - __main__ - train loss is 1.7380197793245316\n",
      "Steps:  36%|▎| 5470/15000 [47:12<49:03,  3.24it/s, lr=0.000682, step_loss=0.001307/27/2023 18:32:02 - INFO - __main__ - train loss is 1.7413567246403545\n",
      "Steps:  36%|▎| 5471/15000 [47:12<42:50,  3.71it/s, lr=0.000682, step_loss=0.003307/27/2023 18:32:02 - INFO - __main__ - train loss is 1.7585128487553447\n",
      "Steps:  36%|▎| 5472/15000 [47:12<38:31,  4.12it/s, lr=0.000682, step_loss=0.017207/27/2023 18:32:02 - INFO - __main__ - train loss is 2.1393237055744976\n",
      "Steps:  36%|▎| 5473/15000 [47:12<35:31,  4.47it/s, lr=0.000682, step_loss=0.381]07/27/2023 18:32:02 - INFO - __main__ - train loss is 2.537600511452183\n",
      "Steps:  36%|▎| 5474/15000 [47:12<33:37,  4.72it/s, lr=0.000683, step_loss=0.398]07/27/2023 18:32:02 - INFO - __main__ - train loss is 2.5398905656766146\n",
      "Steps:  36%|▎| 5475/15000 [47:13<32:21,  4.90it/s, lr=0.000683, step_loss=0.002207/27/2023 18:32:02 - INFO - __main__ - train loss is 2.541921551572159\n",
      "Steps:  37%|▎| 5476/15000 [47:13<31:27,  5.05it/s, lr=0.000683, step_loss=0.002007/27/2023 18:32:03 - INFO - __main__ - train loss is 2.588406215654686\n",
      "Steps:  37%|▎| 5477/15000 [47:13<30:34,  5.19it/s, lr=0.000683, step_loss=0.046507/27/2023 18:32:03 - INFO - __main__ - train loss is 3.139164935098961\n",
      "Steps:  37%|▎| 5478/15000 [47:13<30:12,  5.25it/s, lr=0.000683, step_loss=0.551]07/27/2023 18:32:03 - INFO - __main__ - train loss is 3.141374259488657\n",
      "Steps:  37%|▎| 5479/15000 [47:13<30:00,  5.29it/s, lr=0.000683, step_loss=0.002207/27/2023 18:32:03 - INFO - __main__ - train loss is 3.2466946982312948\n",
      "Steps:  37%|▎| 5480/15000 [47:13<29:33,  5.37it/s, lr=0.000683, step_loss=0.105]07/27/2023 18:32:03 - INFO - __main__ - train loss is 3.2481205286458135\n",
      "Steps:  37%|▎| 5481/15000 [47:14<29:12,  5.43it/s, lr=0.000683, step_loss=0.001407/27/2023 18:32:04 - INFO - __main__ - train loss is 3.2780470801517367\n",
      "Steps:  37%|▎| 5482/15000 [47:14<28:59,  5.47it/s, lr=0.000683, step_loss=0.029907/27/2023 18:32:04 - INFO - __main__ - train loss is 3.3838232113048434\n",
      "Steps:  37%|▎| 5483/15000 [47:14<28:48,  5.51it/s, lr=0.000684, step_loss=0.106]07/27/2023 18:32:04 - INFO - __main__ - train loss is 3.4023219542577863\n",
      "Steps:  37%|▎| 5484/15000 [47:14<28:40,  5.53it/s, lr=0.000684, step_loss=0.018507/27/2023 18:32:04 - INFO - __main__ - train loss is 3.437190000899136\n",
      "Steps:  37%|▎| 5485/15000 [47:14<28:35,  5.55it/s, lr=0.000684, step_loss=0.034907/27/2023 18:32:04 - INFO - __main__ - train loss is 3.531966750510037\n",
      "Steps:  37%|▎| 5486/15000 [47:15<28:31,  5.56it/s, lr=0.000684, step_loss=0.094807/27/2023 18:32:04 - INFO - __main__ - train loss is 3.5380125008523464\n",
      "Steps:  37%|▎| 5487/15000 [47:15<28:29,  5.57it/s, lr=0.000684, step_loss=0.006007/27/2023 18:32:05 - INFO - __main__ - train loss is 3.59958827868104\n",
      "Steps:  37%|▎| 5488/15000 [47:15<28:28,  5.57it/s, lr=0.000684, step_loss=0.061607/27/2023 18:32:05 - INFO - __main__ - train loss is 3.783546570688486\n",
      "Steps:  37%|▎| 5489/15000 [47:15<28:27,  5.57it/s, lr=0.000684, step_loss=0.184]07/27/2023 18:32:05 - INFO - __main__ - train loss is 4.117416296154261\n",
      "Steps:  37%|▎| 5490/15000 [47:15<28:40,  5.53it/s, lr=0.000684, step_loss=0.334]07/27/2023 18:32:05 - INFO - __main__ - train loss is 4.13782262802124\n",
      "Steps:  37%|▎| 5491/15000 [47:15<28:35,  5.54it/s, lr=0.000685, step_loss=0.020407/27/2023 18:32:05 - INFO - __main__ - train loss is 4.21196836233139\n",
      "Steps:  37%|▎| 5492/15000 [47:16<28:31,  5.55it/s, lr=0.000685, step_loss=0.074107/27/2023 18:32:06 - INFO - __main__ - train loss is 4.371462300419807\n",
      "Steps:  37%|▎| 5493/15000 [47:16<28:29,  5.56it/s, lr=0.000685, step_loss=0.159]07/27/2023 18:32:06 - INFO - __main__ - train loss is 4.373982953839004\n",
      "Steps:  37%|▎| 5494/15000 [47:16<28:27,  5.57it/s, lr=0.000685, step_loss=0.002507/27/2023 18:32:06 - INFO - __main__ - train loss is 4.484018879942596\n",
      "Steps:  37%|▋ | 5495/15000 [47:16<28:32,  5.55it/s, lr=0.000685, step_loss=0.11]07/27/2023 18:32:06 - INFO - __main__ - train loss is 4.639570596627891\n",
      "Steps:  37%|▎| 5496/15000 [47:16<28:30,  5.55it/s, lr=0.000685, step_loss=0.156]07/27/2023 18:32:06 - INFO - __main__ - train loss is 4.641491914400831\n",
      "Steps:  37%|▎| 5497/15000 [47:17<28:29,  5.56it/s, lr=0.000685, step_loss=0.001907/27/2023 18:32:06 - INFO - __main__ - train loss is 4.647529841633514\n",
      "Steps:  37%|▎| 5498/15000 [47:17<28:28,  5.56it/s, lr=0.000686, step_loss=0.006007/27/2023 18:32:07 - INFO - __main__ - train loss is 4.979675919981673\n",
      "Steps:  37%|▎| 5499/15000 [47:17<28:29,  5.56it/s, lr=0.000686, step_loss=0.332]07/27/2023 18:32:07 - INFO - __main__ - train loss is 4.990743112983182\n",
      "Steps:  37%|▎| 5500/15000 [47:17<28:27,  5.56it/s, lr=0.000686, step_loss=0.332]07/27/2023 18:32:07 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-5500\n",
      "07/27/2023 18:32:07 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:32:07,362] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:32:07,366] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-5500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:32:07,366] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-5500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:32:07,373] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-5500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:32:07,373] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-5500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:32:07,379] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-5500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:32:07,380] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-5500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:32:07,380] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:32:07 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-5500/pytorch_model\n",
      "07/27/2023 18:32:07 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-5500/scheduler.bin\n",
      "07/27/2023 18:32:07 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-5500/random_states_0.pkl\n",
      "07/27/2023 18:32:07 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-5500\n",
      "Steps:  37%|▎| 5500/15000 [47:17<28:27,  5.56it/s, lr=0.000686, step_loss=0.011107/27/2023 18:32:07 - INFO - __main__ - train loss is 5.100356501759961\n",
      "Steps:  37%|▋ | 5501/15000 [47:17<29:21,  5.39it/s, lr=0.000686, step_loss=0.11]07/27/2023 18:32:07 - INFO - __main__ - train loss is 5.104064350016415\n",
      "Steps:  37%|▎| 5502/15000 [47:17<29:09,  5.43it/s, lr=0.000686, step_loss=0.003707/27/2023 18:32:07 - INFO - __main__ - train loss is 5.137667180038989\n",
      "Steps:  37%|▎| 5503/15000 [47:18<28:55,  5.47it/s, lr=0.000686, step_loss=0.033607/27/2023 18:32:08 - INFO - __main__ - train loss is 5.198100776411593\n",
      "Steps:  37%|▎| 5504/15000 [47:18<28:46,  5.50it/s, lr=0.000686, step_loss=0.060407/27/2023 18:32:08 - INFO - __main__ - train loss is 5.351288781501353\n",
      "Steps:  37%|▎| 5505/15000 [47:18<28:39,  5.52it/s, lr=0.000686, step_loss=0.153]07/27/2023 18:32:08 - INFO - __main__ - train loss is 5.3739187167957425\n",
      "Steps:  37%|▎| 5506/15000 [47:18<28:35,  5.53it/s, lr=0.000687, step_loss=0.022607/27/2023 18:32:08 - INFO - __main__ - train loss is 5.552693863399327\n",
      "Steps:  37%|▎| 5507/15000 [47:18<28:36,  5.53it/s, lr=0.000687, step_loss=0.179]07/27/2023 18:32:08 - INFO - __main__ - train loss is 5.955923934467137\n",
      "Steps:  37%|▎| 5508/15000 [47:19<28:32,  5.54it/s, lr=0.000687, step_loss=0.403]07/27/2023 18:32:08 - INFO - __main__ - train loss is 6.859442968852818\n",
      "Steps:  37%|▎| 5509/15000 [47:19<28:34,  5.54it/s, lr=0.000687, step_loss=0.904]07/27/2023 18:32:09 - INFO - __main__ - train loss is 7.041860898025334\n",
      "Steps:  37%|▎| 5510/15000 [47:19<28:32,  5.54it/s, lr=0.000687, step_loss=0.182]07/27/2023 18:32:09 - INFO - __main__ - train loss is 7.12185909319669\n",
      "Steps:  37%|▋ | 5511/15000 [47:19<28:30,  5.55it/s, lr=0.000687, step_loss=0.08]07/27/2023 18:32:09 - INFO - __main__ - train loss is 7.134427858516574\n",
      "Steps:  37%|▎| 5512/15000 [47:19<28:37,  5.52it/s, lr=0.000687, step_loss=0.012607/27/2023 18:32:09 - INFO - __main__ - train loss is 7.253897128626704\n",
      "Steps:  37%|▎| 5513/15000 [47:19<28:32,  5.54it/s, lr=0.000687, step_loss=0.119]07/27/2023 18:32:09 - INFO - __main__ - train loss is 7.508731273934245\n",
      "Steps:  37%|▎| 5514/15000 [47:20<28:28,  5.55it/s, lr=0.000687, step_loss=0.255]07/27/2023 18:32:09 - INFO - __main__ - train loss is 7.567166270688176\n",
      "Steps:  37%|▎| 5515/15000 [47:20<28:25,  5.56it/s, lr=0.000688, step_loss=0.058407/27/2023 18:32:10 - INFO - __main__ - train loss is 7.570016739424318\n",
      "Steps:  37%|▎| 5516/15000 [47:20<28:23,  5.57it/s, lr=0.000688, step_loss=0.002807/27/2023 18:32:10 - INFO - __main__ - train loss is 8.116735277231783\n",
      "Steps:  37%|▎| 5517/15000 [47:20<28:23,  5.57it/s, lr=0.000688, step_loss=0.547]07/27/2023 18:32:10 - INFO - __main__ - train loss is 8.181629804428667\n",
      "Steps:  37%|▎| 5518/15000 [47:20<30:09,  5.24it/s, lr=0.000688, step_loss=0.064907/27/2023 18:32:10 - INFO - __main__ - train loss is 8.515212771948427\n",
      "Steps:  37%|▎| 5519/15000 [47:21<31:45,  4.97it/s, lr=0.000688, step_loss=0.334]07/27/2023 18:32:10 - INFO - __main__ - train loss is 8.581099790986627\n",
      "Steps:  37%|▎| 5520/15000 [47:21<31:46,  4.97it/s, lr=0.000688, step_loss=0.065907/27/2023 18:32:11 - INFO - __main__ - train loss is 8.593751701992005\n",
      "Steps:  37%|▎| 5521/15000 [47:21<31:23,  5.03it/s, lr=0.000688, step_loss=0.012707/27/2023 18:32:11 - INFO - __main__ - train loss is 8.612284522037953\n",
      "Steps:  37%|▎| 5522/15000 [47:21<30:42,  5.14it/s, lr=0.000688, step_loss=0.018507/27/2023 18:32:11 - INFO - __main__ - train loss is 8.672171171288937\n",
      "Steps:  37%|▎| 5523/15000 [47:21<29:59,  5.27it/s, lr=0.000689, step_loss=0.059907/27/2023 18:32:11 - INFO - __main__ - train loss is 8.673998947022483\n",
      "Steps:  37%|▎| 5524/15000 [47:22<29:36,  5.33it/s, lr=0.000689, step_loss=0.001807/27/2023 18:32:11 - INFO - __main__ - train loss is 8.732697236118838\n",
      "Steps:  37%|▎| 5525/15000 [47:22<29:14,  5.40it/s, lr=0.000689, step_loss=0.058707/27/2023 18:32:12 - INFO - __main__ - train loss is 9.162551867542788\n",
      "Steps:  37%|▋ | 5526/15000 [47:22<28:57,  5.45it/s, lr=0.000689, step_loss=0.43]07/27/2023 18:32:12 - INFO - __main__ - train loss is 9.468811380444095\n",
      "Steps:  37%|▎| 5527/15000 [47:22<28:44,  5.49it/s, lr=0.000689, step_loss=0.306]07/27/2023 18:32:12 - INFO - __main__ - train loss is 9.488837993470952\n",
      "Steps:  37%|▋ | 5528/15000 [47:22<28:36,  5.52it/s, lr=0.000689, step_loss=0.02]07/27/2023 18:32:12 - INFO - __main__ - train loss is 9.90380326542072\n",
      "Steps:  37%|▎| 5529/15000 [47:22<28:32,  5.53it/s, lr=0.000689, step_loss=0.415]07/27/2023 18:32:12 - INFO - __main__ - train loss is 9.90518734161742\n",
      "Steps:  37%|▎| 5530/15000 [47:23<28:28,  5.54it/s, lr=0.00069, step_loss=0.0013807/27/2023 18:32:12 - INFO - __main__ - train loss is 9.912191008450463\n",
      "Steps:  37%|▋ | 5531/15000 [47:23<28:26,  5.55it/s, lr=0.00069, step_loss=0.007]07/27/2023 18:32:13 - INFO - __main__ - train loss is 10.40647137654014\n",
      "Steps:  37%|▋ | 5532/15000 [47:23<28:25,  5.55it/s, lr=0.00069, step_loss=0.494]07/27/2023 18:32:13 - INFO - __main__ - train loss is 10.740985696436837\n",
      "Steps:  37%|▋ | 5533/15000 [47:23<28:24,  5.55it/s, lr=0.00069, step_loss=0.335]07/27/2023 18:32:13 - INFO - __main__ - train loss is 10.745228596264496\n",
      "Steps:  37%|▎| 5534/15000 [47:23<28:23,  5.56it/s, lr=0.00069, step_loss=0.0042407/27/2023 18:32:13 - INFO - __main__ - train loss is 10.754236847395077\n",
      "Steps:  37%|▎| 5535/15000 [47:24<28:32,  5.53it/s, lr=0.00069, step_loss=0.0090107/27/2023 18:32:13 - INFO - __main__ - train loss is 10.83835867070593\n",
      "Steps:  37%|▎| 5536/15000 [47:24<28:27,  5.54it/s, lr=0.00069, step_loss=0.0841]07/27/2023 18:32:14 - INFO - __main__ - train loss is 11.551231414312497\n",
      "Steps:  37%|▋ | 5537/15000 [47:24<28:23,  5.55it/s, lr=0.00069, step_loss=0.713]07/27/2023 18:32:14 - INFO - __main__ - train loss is 11.815988928312436\n",
      "Steps:  37%|▎| 5538/15000 [47:24<28:21,  5.56it/s, lr=0.000691, step_loss=0.265]07/27/2023 18:32:14 - INFO - __main__ - train loss is 11.817644065595232\n",
      "Steps:  37%|▎| 5539/15000 [47:24<28:20,  5.56it/s, lr=0.000691, step_loss=0.001607/27/2023 18:32:14 - INFO - __main__ - train loss is 11.965461915708147\n",
      "Steps:  37%|▎| 5540/15000 [47:24<28:20,  5.56it/s, lr=0.000691, step_loss=0.148]07/27/2023 18:32:14 - INFO - __main__ - train loss is 11.987651897943579\n",
      "Steps:  37%|▎| 5541/15000 [47:25<28:19,  5.57it/s, lr=0.000691, step_loss=0.022207/27/2023 18:32:14 - INFO - __main__ - train loss is 11.991300106165\n",
      "Steps:  37%|▎| 5542/15000 [47:25<28:19,  5.57it/s, lr=0.000691, step_loss=0.003607/27/2023 18:32:15 - INFO - __main__ - train loss is 12.061819866416045\n",
      "Steps:  37%|▎| 5543/15000 [47:25<28:34,  5.52it/s, lr=0.000691, step_loss=0.070507/27/2023 18:32:15 - INFO - __main__ - train loss is 12.066116954316385\n",
      "Steps:  37%|▎| 5544/15000 [47:25<28:34,  5.52it/s, lr=0.000691, step_loss=0.004307/27/2023 18:32:15 - INFO - __main__ - train loss is 12.327815855969675\n",
      "Steps:  37%|▎| 5545/15000 [47:25<28:28,  5.53it/s, lr=0.000691, step_loss=0.262]07/27/2023 18:32:15 - INFO - __main__ - train loss is 12.33698694978375\n",
      "Steps:  37%|▎| 5546/15000 [47:26<28:24,  5.55it/s, lr=0.000692, step_loss=0.009107/27/2023 18:32:15 - INFO - __main__ - train loss is 12.375333296251483\n",
      "Steps:  37%|▎| 5547/15000 [47:26<28:20,  5.56it/s, lr=0.000692, step_loss=0.038307/27/2023 18:32:16 - INFO - __main__ - train loss is 12.6575787832262\n",
      "Steps:  37%|▎| 5548/15000 [47:26<28:18,  5.56it/s, lr=0.000692, step_loss=0.282]07/27/2023 18:32:16 - INFO - __main__ - train loss is 12.751483949017711\n",
      "Steps:  37%|▎| 5549/15000 [47:26<28:28,  5.53it/s, lr=0.000692, step_loss=0.093907/27/2023 18:32:16 - INFO - __main__ - train loss is 12.752914801123552\n",
      "Steps:  37%|▎| 5550/15000 [47:26<28:34,  5.51it/s, lr=0.000692, step_loss=0.001407/27/2023 18:32:16 - INFO - __main__ - train loss is 12.842505544307642\n",
      "Steps:  37%|▎| 5551/15000 [47:26<28:28,  5.53it/s, lr=0.000692, step_loss=0.089607/27/2023 18:32:16 - INFO - __main__ - train loss is 12.88642849761527\n",
      "Steps:  37%|▎| 5552/15000 [47:27<28:39,  5.49it/s, lr=0.000692, step_loss=0.043907/27/2023 18:32:16 - INFO - __main__ - train loss is 12.911286130431108\n",
      "Steps:  37%|▎| 5553/15000 [47:27<28:35,  5.51it/s, lr=0.000692, step_loss=0.024907/27/2023 18:32:17 - INFO - __main__ - train loss is 13.176690027001314\n",
      "Steps:  37%|▎| 5554/15000 [47:27<28:44,  5.48it/s, lr=0.000692, step_loss=0.265]07/27/2023 18:32:17 - INFO - __main__ - train loss is 13.19017332221847\n",
      "Steps:  37%|▎| 5555/15000 [47:27<28:44,  5.48it/s, lr=0.000693, step_loss=0.013507/27/2023 18:32:17 - INFO - __main__ - train loss is 13.20639693166595\n",
      "Steps:  37%|▎| 5556/15000 [47:27<28:43,  5.48it/s, lr=0.000693, step_loss=0.016207/27/2023 18:32:17 - INFO - __main__ - train loss is 13.254911916214041\n",
      "Steps:  37%|▎| 5557/15000 [47:28<28:34,  5.51it/s, lr=0.000693, step_loss=0.048507/27/2023 18:32:17 - INFO - __main__ - train loss is 13.26121722755488\n",
      "Steps:  37%|▎| 5558/15000 [47:28<28:30,  5.52it/s, lr=0.000693, step_loss=0.006307/27/2023 18:32:18 - INFO - __main__ - train loss is 13.281971818185411\n",
      "Steps:  37%|▎| 5559/15000 [47:28<28:25,  5.54it/s, lr=0.000693, step_loss=0.020807/27/2023 18:32:18 - INFO - __main__ - train loss is 13.420563718653284\n",
      "Steps:  37%|▎| 5560/15000 [47:28<28:20,  5.55it/s, lr=0.000693, step_loss=0.139]07/27/2023 18:32:18 - INFO - __main__ - train loss is 13.50824860332068\n",
      "Steps:  37%|▎| 5561/15000 [47:28<28:18,  5.56it/s, lr=0.000693, step_loss=0.087707/27/2023 18:32:18 - INFO - __main__ - train loss is 13.585425189114176\n",
      "Steps:  37%|▎| 5562/15000 [47:28<28:32,  5.51it/s, lr=0.000693, step_loss=0.077207/27/2023 18:32:18 - INFO - __main__ - train loss is 13.797813257551752\n",
      "Steps:  37%|▎| 5563/15000 [47:29<28:42,  5.48it/s, lr=0.000694, step_loss=0.212]07/27/2023 18:32:18 - INFO - __main__ - train loss is 13.920813909149729\n",
      "Steps:  37%|▎| 5564/15000 [47:29<28:45,  5.47it/s, lr=0.000694, step_loss=0.123]07/27/2023 18:32:19 - INFO - __main__ - train loss is 14.032453744090162\n",
      "Steps:  37%|▎| 5565/15000 [47:29<28:35,  5.50it/s, lr=0.000694, step_loss=0.112]07/27/2023 18:32:19 - INFO - __main__ - train loss is 14.035665147355758\n",
      "Steps:  37%|▎| 5566/15000 [47:29<28:39,  5.49it/s, lr=0.000694, step_loss=0.003207/27/2023 18:32:19 - INFO - __main__ - train loss is 14.092149019590579\n",
      "Steps:  37%|▎| 5567/15000 [47:29<28:47,  5.46it/s, lr=0.000694, step_loss=0.056507/27/2023 18:32:19 - INFO - __main__ - train loss is 14.103998838341795\n",
      "Steps:  37%|▎| 5568/15000 [47:30<28:42,  5.48it/s, lr=0.000694, step_loss=0.011807/27/2023 18:32:19 - INFO - __main__ - train loss is 14.113196971244179\n",
      "Steps:  37%|▎| 5569/15000 [47:30<28:33,  5.50it/s, lr=0.000694, step_loss=0.009207/27/2023 18:32:20 - INFO - __main__ - train loss is 14.204002591199242\n",
      "Steps:  37%|▎| 5570/15000 [47:30<28:27,  5.52it/s, lr=0.000695, step_loss=0.090807/27/2023 18:32:20 - INFO - __main__ - train loss is 14.493343802518211\n",
      "Steps:  37%|▎| 5571/15000 [47:30<28:23,  5.54it/s, lr=0.000695, step_loss=0.289]07/27/2023 18:32:20 - INFO - __main__ - train loss is 14.521759549505077\n",
      "Steps:  37%|▎| 5572/15000 [47:30<28:19,  5.55it/s, lr=0.000695, step_loss=0.028407/27/2023 18:32:20 - INFO - __main__ - train loss is 15.124982813722454\n",
      "Steps:  37%|▎| 5573/15000 [47:30<28:17,  5.56it/s, lr=0.000695, step_loss=0.603]07/27/2023 18:32:20 - INFO - __main__ - train loss is 15.190628776676022\n",
      "Steps:  37%|▎| 5574/15000 [47:31<28:30,  5.51it/s, lr=0.000695, step_loss=0.065607/27/2023 18:32:20 - INFO - __main__ - train loss is 15.34864840877708\n",
      "Steps:  37%|▎| 5575/15000 [47:31<28:31,  5.51it/s, lr=0.000695, step_loss=0.158]07/27/2023 18:32:21 - INFO - __main__ - train loss is 15.487607995397411\n",
      "Steps:  37%|▎| 5576/15000 [47:31<28:25,  5.52it/s, lr=0.000695, step_loss=0.139]07/27/2023 18:32:21 - INFO - __main__ - train loss is 15.602805266506039\n",
      "Steps:  37%|▎| 5577/15000 [47:31<28:20,  5.54it/s, lr=0.000695, step_loss=0.115]07/27/2023 18:32:21 - INFO - __main__ - train loss is 15.627872409648262\n",
      "Steps:  37%|▎| 5578/15000 [47:31<28:16,  5.55it/s, lr=0.000696, step_loss=0.025107/27/2023 18:32:21 - INFO - __main__ - train loss is 15.64559635927435\n",
      "Steps:  37%|▎| 5579/15000 [47:31<28:13,  5.56it/s, lr=0.000696, step_loss=0.017707/27/2023 18:32:21 - INFO - __main__ - train loss is 16.049431477091275\n",
      "Steps:  37%|▎| 5580/15000 [47:32<28:12,  5.57it/s, lr=0.000696, step_loss=0.404]07/27/2023 18:32:22 - INFO - __main__ - train loss is 16.209852565429173\n",
      "Steps:  37%|▋ | 5581/15000 [47:32<28:10,  5.57it/s, lr=0.000696, step_loss=0.16]07/27/2023 18:32:22 - INFO - __main__ - train loss is 16.213133294018917\n",
      "Steps:  37%|▎| 5582/15000 [47:32<28:22,  5.53it/s, lr=0.000696, step_loss=0.003207/27/2023 18:32:22 - INFO - __main__ - train loss is 16.238175012054853\n",
      "Steps:  37%|▎| 5583/15000 [47:32<28:33,  5.50it/s, lr=0.000696, step_loss=0.025]07/27/2023 18:32:22 - INFO - __main__ - train loss is 16.399670056882314\n",
      "Steps:  37%|▎| 5584/15000 [47:32<28:52,  5.43it/s, lr=0.000696, step_loss=0.161]07/27/2023 18:32:22 - INFO - __main__ - train loss is 16.41646577778738\n",
      "Steps:  37%|▎| 5585/15000 [47:33<28:54,  5.43it/s, lr=0.000696, step_loss=0.016807/27/2023 18:32:22 - INFO - __main__ - train loss is 16.42268369800877\n",
      "Steps:  37%|▎| 5586/15000 [47:33<28:45,  5.45it/s, lr=0.000697, step_loss=0.006207/27/2023 18:32:23 - INFO - __main__ - train loss is 16.502636064658873\n",
      "Steps:  37%|▋ | 5587/15000 [47:33<28:33,  5.49it/s, lr=0.000697, step_loss=0.08]07/27/2023 18:32:23 - INFO - __main__ - train loss is 16.504549512872472\n",
      "Steps:  37%|▎| 5588/15000 [47:33<28:25,  5.52it/s, lr=0.000697, step_loss=0.001907/27/2023 18:32:23 - INFO - __main__ - train loss is 16.946022937307134\n",
      "Steps:  37%|▎| 5589/15000 [47:33<28:19,  5.54it/s, lr=0.000697, step_loss=0.441]07/27/2023 18:32:23 - INFO - __main__ - train loss is 16.955411404604092\n",
      "Steps:  37%|▎| 5590/15000 [47:33<28:15,  5.55it/s, lr=0.000697, step_loss=0.009307/27/2023 18:32:23 - INFO - __main__ - train loss is 17.015746366465464\n",
      "Steps:  37%|▎| 5591/15000 [47:34<28:13,  5.56it/s, lr=0.000697, step_loss=0.060307/27/2023 18:32:24 - INFO - __main__ - train loss is 17.069959070766345\n",
      "Steps:  37%|▎| 5592/15000 [47:34<28:11,  5.56it/s, lr=0.000697, step_loss=0.054207/27/2023 18:32:24 - INFO - __main__ - train loss is 17.081806855509058\n",
      "Steps:  37%|▎| 5593/15000 [47:34<28:08,  5.57it/s, lr=0.000697, step_loss=0.011807/27/2023 18:32:24 - INFO - __main__ - train loss is 17.33677245886065\n",
      "Steps:  37%|▎| 5594/15000 [47:34<28:07,  5.58it/s, lr=0.000697, step_loss=0.255]07/27/2023 18:32:24 - INFO - __main__ - train loss is 17.666909711668268\n",
      "Steps:  37%|▋ | 5595/15000 [47:34<28:05,  5.58it/s, lr=0.000698, step_loss=0.33]07/27/2023 18:32:24 - INFO - __main__ - train loss is 17.761874372372404\n",
      "Steps:  37%|▎| 5596/15000 [47:35<28:04,  5.58it/s, lr=0.000698, step_loss=0.095]07/27/2023 18:32:24 - INFO - __main__ - train loss is 18.160598689923063\n",
      "Steps:  37%|▎| 5597/15000 [47:35<28:04,  5.58it/s, lr=0.000698, step_loss=0.399]07/27/2023 18:32:25 - INFO - __main__ - train loss is 18.169155000010505\n",
      "Steps:  37%|▎| 5598/15000 [47:35<28:05,  5.58it/s, lr=0.000698, step_loss=0.008507/27/2023 18:32:25 - INFO - __main__ - train loss is 18.179946972290054\n",
      "Steps:  37%|▎| 5599/15000 [47:35<28:05,  5.58it/s, lr=0.000698, step_loss=0.010807/27/2023 18:32:25 - INFO - __main__ - train loss is 18.182400743477046\n",
      "Steps:  37%|▎| 5600/15000 [47:35<28:04,  5.58it/s, lr=0.000698, step_loss=0.002407/27/2023 18:32:25 - INFO - __main__ - train loss is 18.266757573001087\n",
      "Steps:  37%|▎| 5601/15000 [47:35<28:05,  5.58it/s, lr=0.000698, step_loss=0.084407/27/2023 18:32:25 - INFO - __main__ - train loss is 18.499391595833004\n",
      "Steps:  37%|▎| 5602/15000 [47:36<28:06,  5.57it/s, lr=0.000699, step_loss=0.233]07/27/2023 18:32:26 - INFO - __main__ - train loss is 18.76695833634585\n",
      "Steps:  37%|▎| 5603/15000 [47:36<28:22,  5.52it/s, lr=0.000699, step_loss=0.268]07/27/2023 18:32:26 - INFO - __main__ - train loss is 18.868289182893932\n",
      "Steps:  37%|▎| 5604/15000 [47:36<28:30,  5.49it/s, lr=0.000699, step_loss=0.101]07/27/2023 18:32:26 - INFO - __main__ - train loss is 19.254743854515254\n",
      "Steps:  37%|▎| 5605/15000 [47:36<28:23,  5.52it/s, lr=0.000699, step_loss=0.386]07/27/2023 18:32:26 - INFO - __main__ - train loss is 19.310289460234344\n",
      "Steps:  37%|▎| 5606/15000 [47:36<28:18,  5.53it/s, lr=0.000699, step_loss=0.055507/27/2023 18:32:26 - INFO - __main__ - train loss is 19.49710655491799\n",
      "Steps:  37%|▎| 5607/15000 [47:37<28:14,  5.54it/s, lr=0.000699, step_loss=0.187]07/27/2023 18:32:26 - INFO - __main__ - train loss is 19.6575467614457\n",
      "Steps:  37%|▋ | 5608/15000 [47:37<28:11,  5.55it/s, lr=0.000699, step_loss=0.16]07/27/2023 18:32:27 - INFO - __main__ - train loss is 19.791731673292816\n",
      "Steps:  37%|▎| 5609/15000 [47:37<28:10,  5.55it/s, lr=0.000699, step_loss=0.134]07/27/2023 18:32:27 - INFO - __main__ - train loss is 19.840787346474826\n",
      "Steps:  37%|▋ | 5610/15000 [47:37<28:10,  5.56it/s, lr=0.0007, step_loss=0.0491]07/27/2023 18:32:27 - INFO - __main__ - train loss is 19.90195524971932\n",
      "Steps:  37%|▋ | 5611/15000 [47:37<28:08,  5.56it/s, lr=0.0007, step_loss=0.0612]07/27/2023 18:32:27 - INFO - __main__ - train loss is 20.204548629932106\n",
      "Steps:  37%|█  | 5612/15000 [47:37<28:32,  5.48it/s, lr=0.0007, step_loss=0.303]07/27/2023 18:32:27 - INFO - __main__ - train loss is 20.215463207103312\n",
      "Steps:  37%|▋ | 5613/15000 [47:38<29:17,  5.34it/s, lr=0.0007, step_loss=0.0109]07/27/2023 18:32:28 - INFO - __main__ - train loss is 20.258140680380166\n",
      "Steps:  37%|▋ | 5614/15000 [47:38<29:27,  5.31it/s, lr=0.0007, step_loss=0.0427]07/27/2023 18:32:28 - INFO - __main__ - train loss is 20.313936685211957\n",
      "Steps:  37%|▋ | 5615/15000 [47:38<29:46,  5.25it/s, lr=0.0007, step_loss=0.0558]07/27/2023 18:32:28 - INFO - __main__ - train loss is 20.327463395893574\n",
      "Steps:  37%|▋ | 5616/15000 [47:38<30:04,  5.20it/s, lr=0.0007, step_loss=0.0135]07/27/2023 18:32:28 - INFO - __main__ - train loss is 20.378243047744036\n",
      "Steps:  37%|▋ | 5617/15000 [47:38<30:13,  5.17it/s, lr=0.0007, step_loss=0.0508]07/27/2023 18:32:28 - INFO - __main__ - train loss is 20.818523604422808\n",
      "Steps:  37%|▋ | 5618/15000 [47:39<30:04,  5.20it/s, lr=0.000701, step_loss=0.44]07/27/2023 18:32:28 - INFO - __main__ - train loss is 21.012835044413805\n",
      "Steps:  37%|▎| 5619/15000 [47:39<30:02,  5.21it/s, lr=0.000701, step_loss=0.194]07/27/2023 18:32:29 - INFO - __main__ - train loss is 21.331794161349535\n",
      "Steps:  37%|▎| 5620/15000 [47:39<30:19,  5.15it/s, lr=0.000701, step_loss=0.319]07/27/2023 18:32:29 - INFO - __main__ - train loss is 21.88603999093175\n",
      "Steps:  37%|▎| 5621/15000 [47:39<30:25,  5.14it/s, lr=0.000701, step_loss=0.554]07/27/2023 18:32:29 - INFO - __main__ - train loss is 21.894571101292968\n",
      "Steps:  37%|▎| 5622/15000 [47:39<30:30,  5.12it/s, lr=0.000701, step_loss=0.008507/27/2023 18:32:29 - INFO - __main__ - train loss is 21.994304155930877\n",
      "Steps:  37%|▎| 5623/15000 [47:40<30:36,  5.10it/s, lr=0.000701, step_loss=0.099707/27/2023 18:32:29 - INFO - __main__ - train loss is 22.155877044424415\n",
      "Steps:  37%|▎| 5624/15000 [47:40<30:38,  5.10it/s, lr=0.000701, step_loss=0.162]07/27/2023 18:32:30 - INFO - __main__ - train loss is 22.175935054197907\n",
      "Steps:  38%|▍| 5625/15000 [47:40<30:42,  5.09it/s, lr=0.000701, step_loss=0.020107/27/2023 18:32:30 - INFO - __main__ - train loss is 22.28815800882876\n",
      "Steps:  38%|▍| 5626/15000 [47:40<30:43,  5.09it/s, lr=0.000701, step_loss=0.112]07/27/2023 18:32:30 - INFO - __main__ - train loss is 22.40031255222857\n",
      "Steps:  38%|▍| 5627/15000 [47:40<30:43,  5.09it/s, lr=0.000702, step_loss=0.112]07/27/2023 18:32:30 - INFO - __main__ - train loss is 22.59145230986178\n",
      "Steps:  38%|▍| 5628/15000 [47:41<31:00,  5.04it/s, lr=0.000702, step_loss=0.191]07/27/2023 18:32:30 - INFO - __main__ - train loss is 22.666831905022264\n",
      "Steps:  38%|▍| 5629/15000 [47:41<30:56,  5.05it/s, lr=0.000702, step_loss=0.075407/27/2023 18:32:31 - INFO - __main__ - train loss is 22.913331070914865\n",
      "Steps:  38%|▍| 5630/15000 [47:41<30:54,  5.05it/s, lr=0.000702, step_loss=0.246]07/27/2023 18:32:31 - INFO - __main__ - train loss is 22.966454589739442\n",
      "Steps:  38%|▍| 5631/15000 [47:41<30:51,  5.06it/s, lr=0.000702, step_loss=0.053107/27/2023 18:32:31 - INFO - __main__ - train loss is 22.97001317841932\n",
      "Steps:  38%|▍| 5632/15000 [47:41<30:47,  5.07it/s, lr=0.000702, step_loss=0.003507/27/2023 18:32:31 - INFO - __main__ - train loss is 22.97750231763348\n",
      "Steps:  38%|▍| 5633/15000 [47:42<30:45,  5.07it/s, lr=0.000702, step_loss=0.007407/27/2023 18:32:31 - INFO - __main__ - train loss is 22.97926636878401\n",
      "Steps:  38%|▍| 5634/15000 [47:42<31:22,  4.97it/s, lr=0.000702, step_loss=0.001707/27/2023 18:32:32 - INFO - __main__ - train loss is 23.751309477724135\n",
      "Steps:  38%|▍| 5635/15000 [47:42<30:51,  5.06it/s, lr=0.000703, step_loss=0.772]07/27/2023 18:32:32 - INFO - __main__ - train loss is 23.781434358097613\n",
      "Steps:  38%|▍| 5636/15000 [47:42<31:59,  4.88it/s, lr=0.000703, step_loss=0.030107/27/2023 18:32:32 - INFO - __main__ - train loss is 23.85899625811726\n",
      "Steps:  38%|▍| 5637/15000 [47:42<31:32,  4.95it/s, lr=0.000703, step_loss=0.077607/27/2023 18:32:32 - INFO - __main__ - train loss is 23.888625939376652\n",
      "Steps:  38%|▍| 5638/15000 [47:43<31:19,  4.98it/s, lr=0.000703, step_loss=0.029607/27/2023 18:32:32 - INFO - __main__ - train loss is 24.05441062618047\n",
      "Steps:  38%|▍| 5639/15000 [47:43<30:58,  5.04it/s, lr=0.000703, step_loss=0.166]07/27/2023 18:32:33 - INFO - __main__ - train loss is 24.11413434240967\n",
      "Steps:  38%|▍| 5640/15000 [47:43<30:56,  5.04it/s, lr=0.000703, step_loss=0.059707/27/2023 18:32:33 - INFO - __main__ - train loss is 24.20514138136059\n",
      "Steps:  38%|▍| 5641/15000 [47:43<30:25,  5.13it/s, lr=0.000703, step_loss=0.091]07/27/2023 18:32:33 - INFO - __main__ - train loss is 24.22080382797867\n",
      "Steps:  38%|▍| 5642/15000 [47:43<29:57,  5.21it/s, lr=0.000704, step_loss=0.015707/27/2023 18:32:33 - INFO - __main__ - train loss is 24.606831372715533\n",
      "Steps:  38%|▍| 5643/15000 [47:44<29:20,  5.32it/s, lr=0.000704, step_loss=0.386]07/27/2023 18:32:33 - INFO - __main__ - train loss is 24.64219729695469\n",
      "Steps:  38%|▍| 5644/15000 [47:44<28:54,  5.39it/s, lr=0.000704, step_loss=0.035407/27/2023 18:32:34 - INFO - __main__ - train loss is 24.643550080247223\n",
      "Steps:  38%|▍| 5645/15000 [47:44<28:36,  5.45it/s, lr=0.000704, step_loss=0.001307/27/2023 18:32:34 - INFO - __main__ - train loss is 24.70534146297723\n",
      "Steps:  38%|▍| 5646/15000 [47:44<28:41,  5.43it/s, lr=0.000704, step_loss=0.061807/27/2023 18:32:34 - INFO - __main__ - train loss is 24.87374058831483\n",
      "Steps:  38%|▍| 5647/15000 [47:44<28:28,  5.48it/s, lr=0.000704, step_loss=0.168]07/27/2023 18:32:34 - INFO - __main__ - train loss is 24.909101699478924\n",
      "Steps:  38%|▍| 5648/15000 [47:44<28:20,  5.50it/s, lr=0.000704, step_loss=0.035407/27/2023 18:32:34 - INFO - __main__ - train loss is 25.192589675076306\n",
      "Steps:  38%|▍| 5649/15000 [47:45<28:12,  5.52it/s, lr=0.000704, step_loss=0.283]07/27/2023 18:32:34 - INFO - __main__ - train loss is 25.197401045821607\n",
      "Steps:  38%|▍| 5650/15000 [47:45<28:08,  5.54it/s, lr=0.000705, step_loss=0.004807/27/2023 18:32:35 - INFO - __main__ - train loss is 25.432918845675886\n",
      "Steps:  38%|▍| 5651/15000 [47:45<28:04,  5.55it/s, lr=0.000705, step_loss=0.236]07/27/2023 18:32:35 - INFO - __main__ - train loss is 25.435137658379972\n",
      "Steps:  38%|▍| 5652/15000 [47:45<28:02,  5.56it/s, lr=0.000705, step_loss=0.002207/27/2023 18:32:35 - INFO - __main__ - train loss is 25.45309917535633\n",
      "Steps:  38%|▍| 5653/15000 [47:45<28:15,  5.51it/s, lr=0.000705, step_loss=0.018]07/27/2023 18:32:35 - INFO - __main__ - train loss is 25.539341269992292\n",
      "Steps:  38%|▍| 5654/15000 [47:46<28:14,  5.52it/s, lr=0.000705, step_loss=0.086207/27/2023 18:32:35 - INFO - __main__ - train loss is 25.5863280845806\n",
      "Steps:  38%|▍| 5655/15000 [47:46<28:09,  5.53it/s, lr=0.000705, step_loss=0.047]07/27/2023 18:32:36 - INFO - __main__ - train loss is 25.611470227129757\n",
      "Steps:  38%|▍| 5656/15000 [47:46<28:05,  5.54it/s, lr=0.000705, step_loss=0.025107/27/2023 18:32:36 - INFO - __main__ - train loss is 25.88160473573953\n",
      "Steps:  38%|▊ | 5657/15000 [47:46<28:02,  5.55it/s, lr=0.000705, step_loss=0.27]07/27/2023 18:32:36 - INFO - __main__ - train loss is 25.94386923778802\n",
      "Steps:  38%|▍| 5658/15000 [47:46<28:05,  5.54it/s, lr=0.000706, step_loss=0.062307/27/2023 18:32:36 - INFO - __main__ - train loss is 26.042836596257985\n",
      "Steps:  38%|▍| 5659/15000 [47:46<28:11,  5.52it/s, lr=0.000706, step_loss=0.099]07/27/2023 18:32:36 - INFO - __main__ - train loss is 26.107185778208077\n",
      "Steps:  38%|▍| 5660/15000 [47:47<28:07,  5.54it/s, lr=0.000706, step_loss=0.064307/27/2023 18:32:36 - INFO - __main__ - train loss is 26.108489607460797\n",
      "Steps:  38%|▍| 5661/15000 [47:47<28:02,  5.55it/s, lr=0.000706, step_loss=0.001307/27/2023 18:32:37 - INFO - __main__ - train loss is 26.368319605477154\n",
      "Steps:  38%|▊ | 5662/15000 [47:47<28:01,  5.55it/s, lr=0.000706, step_loss=0.26]07/27/2023 18:32:37 - INFO - __main__ - train loss is 26.402591002173722\n",
      "Steps:  38%|▍| 5663/15000 [47:47<27:59,  5.56it/s, lr=0.000706, step_loss=0.034307/27/2023 18:32:37 - INFO - __main__ - train loss is 26.590214771218598\n",
      "Steps:  38%|▍| 5664/15000 [47:47<27:58,  5.56it/s, lr=0.000706, step_loss=0.188]07/27/2023 18:32:37 - INFO - __main__ - train loss is 26.5921914242208\n",
      "Steps:  38%|▍| 5665/15000 [47:47<28:02,  5.55it/s, lr=0.000706, step_loss=0.001907/27/2023 18:32:37 - INFO - __main__ - train loss is 26.623357217758894\n",
      "Steps:  38%|▍| 5666/15000 [47:48<28:00,  5.56it/s, lr=0.000706, step_loss=0.031207/27/2023 18:32:38 - INFO - __main__ - train loss is 26.627420575823635\n",
      "Steps:  38%|▍| 5667/15000 [47:48<27:57,  5.56it/s, lr=0.000707, step_loss=0.004007/27/2023 18:32:38 - INFO - __main__ - train loss is 26.841027678456157\n",
      "Steps:  38%|▍| 5668/15000 [47:48<27:57,  5.56it/s, lr=0.000707, step_loss=0.214]07/27/2023 18:32:38 - INFO - __main__ - train loss is 26.91726237675175\n",
      "Steps:  38%|▍| 5669/15000 [47:48<27:57,  5.56it/s, lr=0.000707, step_loss=0.076207/27/2023 18:32:38 - INFO - __main__ - train loss is 26.919460533885285\n",
      "Steps:  38%|▍| 5670/15000 [47:48<27:55,  5.57it/s, lr=0.000707, step_loss=0.002207/27/2023 18:32:38 - INFO - __main__ - train loss is 26.99198882165365\n",
      "Steps:  38%|▍| 5671/15000 [47:49<27:55,  5.57it/s, lr=0.000707, step_loss=0.072507/27/2023 18:32:38 - INFO - __main__ - train loss is 27.000333874253556\n",
      "Steps:  38%|▍| 5672/15000 [47:49<27:53,  5.57it/s, lr=0.000707, step_loss=0.008307/27/2023 18:32:39 - INFO - __main__ - train loss is 27.134135498432443\n",
      "Steps:  38%|▍| 5673/15000 [47:49<27:52,  5.58it/s, lr=0.000707, step_loss=0.134]07/27/2023 18:32:39 - INFO - __main__ - train loss is 27.405975415138528\n",
      "Steps:  38%|▍| 5674/15000 [47:49<27:52,  5.58it/s, lr=0.000708, step_loss=0.272]07/27/2023 18:32:39 - INFO - __main__ - train loss is 27.448421119479463\n",
      "Steps:  38%|▍| 5675/15000 [47:49<27:52,  5.57it/s, lr=0.000708, step_loss=0.042407/27/2023 18:32:39 - INFO - __main__ - train loss is 27.51194818946533\n",
      "Steps:  38%|▍| 5676/15000 [47:49<27:52,  5.58it/s, lr=0.000708, step_loss=0.063507/27/2023 18:32:39 - INFO - __main__ - train loss is 27.52895846660249\n",
      "Steps:  38%|▍| 5677/15000 [47:50<27:51,  5.58it/s, lr=0.000708, step_loss=0.017]07/27/2023 18:32:40 - INFO - __main__ - train loss is 27.609299313975498\n",
      "Steps:  38%|▍| 5678/15000 [47:50<27:50,  5.58it/s, lr=0.000708, step_loss=0.080307/27/2023 18:32:40 - INFO - __main__ - train loss is 27.70652836258523\n",
      "Steps:  38%|▍| 5679/15000 [47:50<27:49,  5.58it/s, lr=0.000708, step_loss=0.097207/27/2023 18:32:40 - INFO - __main__ - train loss is 28.52688151295297\n",
      "Steps:  38%|▊ | 5680/15000 [47:50<27:50,  5.58it/s, lr=0.000708, step_loss=0.82]07/27/2023 18:32:40 - INFO - __main__ - train loss is 28.547998322872445\n",
      "Steps:  38%|▍| 5681/15000 [47:50<27:50,  5.58it/s, lr=0.000708, step_loss=0.021107/27/2023 18:32:40 - INFO - __main__ - train loss is 28.64378103497438\n",
      "Steps:  38%|▍| 5682/15000 [47:51<27:51,  5.58it/s, lr=0.000709, step_loss=0.095807/27/2023 18:32:40 - INFO - __main__ - train loss is 28.66243498469703\n",
      "Steps:  38%|▍| 5683/15000 [47:51<27:50,  5.58it/s, lr=0.000709, step_loss=0.018707/27/2023 18:32:41 - INFO - __main__ - train loss is 29.320110847009346\n",
      "Steps:  38%|▍| 5684/15000 [47:51<27:50,  5.58it/s, lr=0.000709, step_loss=0.658]07/27/2023 18:32:41 - INFO - __main__ - train loss is 29.322403746889904\n",
      "Steps:  38%|▍| 5685/15000 [47:51<27:50,  5.57it/s, lr=0.000709, step_loss=0.002207/27/2023 18:32:41 - INFO - __main__ - train loss is 29.370581872062758\n",
      "Steps:  38%|▍| 5686/15000 [47:51<27:53,  5.57it/s, lr=0.000709, step_loss=0.048207/27/2023 18:32:41 - INFO - __main__ - train loss is 29.516436166362837\n",
      "Steps:  38%|▍| 5687/15000 [47:51<27:52,  5.57it/s, lr=0.000709, step_loss=0.146]07/27/2023 18:32:41 - INFO - __main__ - train loss is 29.5742828019429\n",
      "Steps:  38%|▍| 5688/15000 [47:52<27:52,  5.57it/s, lr=0.000709, step_loss=0.057807/27/2023 18:32:41 - INFO - __main__ - train loss is 29.656816906528547\n",
      "Steps:  38%|▍| 5689/15000 [47:52<27:52,  5.57it/s, lr=0.000709, step_loss=0.082507/27/2023 18:32:42 - INFO - __main__ - train loss is 29.668453083606437\n",
      "Steps:  38%|▍| 5690/15000 [47:52<27:52,  5.57it/s, lr=0.00071, step_loss=0.0116]07/27/2023 18:32:42 - INFO - __main__ - train loss is 29.73539833840914\n",
      "Steps:  38%|▍| 5691/15000 [47:52<28:05,  5.52it/s, lr=0.00071, step_loss=0.0669]07/27/2023 18:32:42 - INFO - __main__ - train loss is 29.83688119170256\n",
      "Steps:  38%|▊ | 5692/15000 [47:52<28:13,  5.50it/s, lr=0.00071, step_loss=0.101]07/27/2023 18:32:42 - INFO - __main__ - train loss is 30.37144443509169\n",
      "Steps:  38%|▊ | 5693/15000 [47:53<28:19,  5.48it/s, lr=0.00071, step_loss=0.535]07/27/2023 18:32:42 - INFO - __main__ - train loss is 30.47692154464312\n",
      "Steps:  38%|▊ | 5694/15000 [47:53<28:26,  5.45it/s, lr=0.00071, step_loss=0.105]07/27/2023 18:32:43 - INFO - __main__ - train loss is 30.85118489083834\n",
      "Steps:  38%|▊ | 5695/15000 [47:53<28:29,  5.44it/s, lr=0.00071, step_loss=0.374]07/27/2023 18:32:43 - INFO - __main__ - train loss is 30.87001567822881\n",
      "Steps:  38%|▍| 5696/15000 [47:53<28:16,  5.49it/s, lr=0.00071, step_loss=0.0188]07/27/2023 18:32:43 - INFO - __main__ - train loss is 30.87536010495387\n",
      "Steps:  38%|▍| 5697/15000 [47:53<28:06,  5.52it/s, lr=0.00071, step_loss=0.0053407/27/2023 18:32:43 - INFO - __main__ - train loss is 30.91056179977022\n",
      "Steps:  38%|▍| 5698/15000 [47:53<28:02,  5.53it/s, lr=0.000711, step_loss=0.035207/27/2023 18:32:43 - INFO - __main__ - train loss is 30.981092281406745\n",
      "Steps:  38%|▍| 5699/15000 [47:54<27:57,  5.54it/s, lr=0.000711, step_loss=0.070507/27/2023 18:32:43 - INFO - __main__ - train loss is 31.22512299544178\n",
      "Steps:  38%|▍| 5700/15000 [47:54<27:55,  5.55it/s, lr=0.000711, step_loss=0.244]07/27/2023 18:32:44 - INFO - __main__ - train loss is 31.229510331293568\n",
      "Steps:  38%|▍| 5701/15000 [47:54<27:52,  5.56it/s, lr=0.000711, step_loss=0.004307/27/2023 18:32:44 - INFO - __main__ - train loss is 31.28926862939261\n",
      "Steps:  38%|▍| 5702/15000 [47:54<27:51,  5.56it/s, lr=0.000711, step_loss=0.059807/27/2023 18:32:44 - INFO - __main__ - train loss is 31.624048905214295\n",
      "Steps:  38%|▍| 5703/15000 [47:54<27:49,  5.57it/s, lr=0.000711, step_loss=0.335]07/27/2023 18:32:44 - INFO - __main__ - train loss is 31.62632957356982\n",
      "Steps:  38%|▍| 5704/15000 [47:55<27:48,  5.57it/s, lr=0.000711, step_loss=0.002207/27/2023 18:32:44 - INFO - __main__ - train loss is 31.763072374043986\n",
      "Steps:  38%|▍| 5705/15000 [47:55<27:50,  5.56it/s, lr=0.000711, step_loss=0.137]07/27/2023 18:32:45 - INFO - __main__ - train loss is 31.969634297071025\n",
      "Steps:  38%|▍| 5706/15000 [47:55<27:49,  5.57it/s, lr=0.000712, step_loss=0.207]07/27/2023 18:32:45 - INFO - __main__ - train loss is 31.998938613338396\n",
      "Steps:  38%|▍| 5707/15000 [47:55<27:49,  5.57it/s, lr=0.000712, step_loss=0.029307/27/2023 18:32:45 - INFO - __main__ - train loss is 32.73380022565834\n",
      "Steps:  38%|▍| 5708/15000 [47:55<27:48,  5.57it/s, lr=0.000712, step_loss=0.735]07/27/2023 18:32:45 - INFO - __main__ - train loss is 32.749909058911726\n",
      "Steps:  38%|▍| 5709/15000 [47:55<27:48,  5.57it/s, lr=0.000712, step_loss=0.016107/27/2023 18:32:45 - INFO - __main__ - train loss is 32.758540550014004\n",
      "Steps:  38%|▍| 5710/15000 [47:56<27:47,  5.57it/s, lr=0.000712, step_loss=0.008607/27/2023 18:32:45 - INFO - __main__ - train loss is 32.973578015109524\n",
      "Steps:  38%|▍| 5711/15000 [47:56<27:47,  5.57it/s, lr=0.000712, step_loss=0.215]07/27/2023 18:32:46 - INFO - __main__ - train loss is 33.02858945145272\n",
      "Steps:  38%|▍| 5712/15000 [47:56<27:50,  5.56it/s, lr=0.000712, step_loss=0.055]07/27/2023 18:32:46 - INFO - __main__ - train loss is 33.261670211097226\n",
      "Steps:  38%|▍| 5713/15000 [47:56<28:03,  5.52it/s, lr=0.000712, step_loss=0.233]07/27/2023 18:32:46 - INFO - __main__ - train loss is 33.384320275625214\n",
      "Steps:  38%|▍| 5714/15000 [47:56<27:58,  5.53it/s, lr=0.000713, step_loss=0.123]07/27/2023 18:32:46 - INFO - __main__ - train loss is 33.56468968256377\n",
      "Steps:  38%|▊ | 5715/15000 [47:57<27:55,  5.54it/s, lr=0.000713, step_loss=0.18]07/27/2023 18:32:46 - INFO - __main__ - train loss is 33.57183842989616\n",
      "Steps:  38%|▍| 5716/15000 [47:57<27:53,  5.55it/s, lr=0.000713, step_loss=0.007107/27/2023 18:32:47 - INFO - __main__ - train loss is 33.57789910561405\n",
      "Steps:  38%|▍| 5717/15000 [47:57<27:52,  5.55it/s, lr=0.000713, step_loss=0.006007/27/2023 18:32:47 - INFO - __main__ - train loss is 33.58543563517742\n",
      "Steps:  38%|▍| 5718/15000 [47:57<27:50,  5.55it/s, lr=0.000713, step_loss=0.007507/27/2023 18:32:47 - INFO - __main__ - train loss is 33.67087041470222\n",
      "Steps:  38%|▍| 5719/15000 [47:57<27:48,  5.56it/s, lr=0.000713, step_loss=0.085407/27/2023 18:32:47 - INFO - __main__ - train loss is 33.7978222433012\n",
      "Steps:  38%|▍| 5720/15000 [47:57<27:47,  5.56it/s, lr=0.000713, step_loss=0.127]07/27/2023 18:32:47 - INFO - __main__ - train loss is 34.21926999720745\n",
      "Steps:  38%|▍| 5721/15000 [47:58<27:46,  5.57it/s, lr=0.000713, step_loss=0.421]07/27/2023 18:32:47 - INFO - __main__ - train loss is 34.43094494077377\n",
      "Steps:  38%|▍| 5722/15000 [47:58<27:45,  5.57it/s, lr=0.000714, step_loss=0.212]07/27/2023 18:32:48 - INFO - __main__ - train loss is 34.432027521543205\n",
      "Steps:  38%|▍| 5723/15000 [47:58<27:44,  5.57it/s, lr=0.000714, step_loss=0.001007/27/2023 18:32:48 - INFO - __main__ - train loss is 34.467652845196426\n",
      "Steps:  38%|▍| 5724/15000 [47:58<27:45,  5.57it/s, lr=0.000714, step_loss=0.035607/27/2023 18:32:48 - INFO - __main__ - train loss is 34.60241113882512\n",
      "Steps:  38%|▍| 5725/15000 [47:58<27:45,  5.57it/s, lr=0.000714, step_loss=0.135]07/27/2023 18:32:48 - INFO - __main__ - train loss is 34.647349811159074\n",
      "Steps:  38%|▍| 5726/15000 [47:58<27:45,  5.57it/s, lr=0.000714, step_loss=0.044907/27/2023 18:32:48 - INFO - __main__ - train loss is 34.979877091012895\n",
      "Steps:  38%|▍| 5727/15000 [47:59<27:44,  5.57it/s, lr=0.000714, step_loss=0.333]07/27/2023 18:32:49 - INFO - __main__ - train loss is 35.0537719046697\n",
      "Steps:  38%|▍| 5728/15000 [47:59<27:44,  5.57it/s, lr=0.000714, step_loss=0.073907/27/2023 18:32:49 - INFO - __main__ - train loss is 35.06380589585751\n",
      "Steps:  38%|▊ | 5729/15000 [47:59<27:44,  5.57it/s, lr=0.000714, step_loss=0.01]07/27/2023 18:32:49 - INFO - __main__ - train loss is 35.08860335778445\n",
      "Steps:  38%|▍| 5730/15000 [47:59<27:44,  5.57it/s, lr=0.000715, step_loss=0.024807/27/2023 18:32:49 - INFO - __main__ - train loss is 35.11338039394468\n",
      "Steps:  38%|▍| 5731/15000 [47:59<27:43,  5.57it/s, lr=0.000715, step_loss=0.024807/27/2023 18:32:49 - INFO - __main__ - train loss is 35.124499414116144\n",
      "Steps:  38%|▍| 5732/15000 [48:00<27:42,  5.57it/s, lr=0.000715, step_loss=0.011107/27/2023 18:32:49 - INFO - __main__ - train loss is 35.12675474770367\n",
      "Steps:  38%|▍| 5733/15000 [48:00<27:42,  5.57it/s, lr=0.000715, step_loss=0.002207/27/2023 18:32:50 - INFO - __main__ - train loss is 35.47315205819905\n",
      "Steps:  38%|▍| 5734/15000 [48:00<27:43,  5.57it/s, lr=0.000715, step_loss=0.346]07/27/2023 18:32:50 - INFO - __main__ - train loss is 35.77365552075207\n",
      "Steps:  38%|▍| 5735/15000 [48:00<27:45,  5.56it/s, lr=0.000715, step_loss=0.301]07/27/2023 18:32:50 - INFO - __main__ - train loss is 36.56308804638684\n",
      "Steps:  38%|▍| 5736/15000 [48:00<27:44,  5.56it/s, lr=0.000715, step_loss=0.789]07/27/2023 18:32:50 - INFO - __main__ - train loss is 36.713311867788434\n",
      "Steps:  38%|▊ | 5737/15000 [48:00<27:59,  5.52it/s, lr=0.000715, step_loss=0.15]07/27/2023 18:32:50 - INFO - __main__ - train loss is 36.72678564861417\n",
      "Steps:  38%|▍| 5738/15000 [48:01<27:57,  5.52it/s, lr=0.000715, step_loss=0.013507/27/2023 18:32:51 - INFO - __main__ - train loss is 37.087148297578096\n",
      "Steps:  38%|▊ | 5739/15000 [48:01<28:06,  5.49it/s, lr=0.000716, step_loss=0.36]07/27/2023 18:32:51 - INFO - __main__ - train loss is 37.10013481229544\n",
      "Steps:  38%|▍| 5740/15000 [48:01<28:14,  5.47it/s, lr=0.000716, step_loss=0.013]07/27/2023 18:32:51 - INFO - __main__ - train loss is 37.24712888151407\n",
      "Steps:  38%|▍| 5741/15000 [48:01<28:24,  5.43it/s, lr=0.000716, step_loss=0.147]07/27/2023 18:32:51 - INFO - __main__ - train loss is 37.25637882668525\n",
      "Steps:  38%|▍| 5742/15000 [48:01<28:17,  5.45it/s, lr=0.000716, step_loss=0.009207/27/2023 18:32:51 - INFO - __main__ - train loss is 37.29510391224176\n",
      "Steps:  38%|▍| 5743/15000 [48:02<28:05,  5.49it/s, lr=0.000716, step_loss=0.038707/27/2023 18:32:51 - INFO - __main__ - train loss is 37.29832541709766\n",
      "Steps:  38%|▍| 5744/15000 [48:02<27:56,  5.52it/s, lr=0.000716, step_loss=0.003207/27/2023 18:32:52 - INFO - __main__ - train loss is 37.30988453095779\n",
      "Steps:  38%|▍| 5745/15000 [48:02<28:02,  5.50it/s, lr=0.000716, step_loss=0.011607/27/2023 18:32:52 - INFO - __main__ - train loss is 37.68273035949096\n",
      "Steps:  38%|▍| 5746/15000 [48:02<27:55,  5.52it/s, lr=0.000717, step_loss=0.373]07/27/2023 18:32:52 - INFO - __main__ - train loss is 37.758635548409075\n",
      "Steps:  38%|▍| 5747/15000 [48:02<27:49,  5.54it/s, lr=0.000717, step_loss=0.075907/27/2023 18:32:52 - INFO - __main__ - train loss is 37.94418847328052\n",
      "Steps:  38%|▍| 5748/15000 [48:02<27:45,  5.56it/s, lr=0.000717, step_loss=0.186]07/27/2023 18:32:52 - INFO - __main__ - train loss is 38.003433474805206\n",
      "Steps:  38%|▍| 5749/15000 [48:03<27:41,  5.57it/s, lr=0.000717, step_loss=0.059207/27/2023 18:32:53 - INFO - __main__ - train loss is 38.284014561679214\n",
      "Steps:  38%|▍| 5750/15000 [48:03<27:39,  5.58it/s, lr=0.000717, step_loss=0.281]07/27/2023 18:32:53 - INFO - __main__ - train loss is 38.28724888432771\n",
      "Steps:  38%|▍| 5751/15000 [48:03<27:36,  5.58it/s, lr=0.000717, step_loss=0.003207/27/2023 18:32:53 - INFO - __main__ - train loss is 38.29053991800174\n",
      "Steps:  38%|▍| 5752/15000 [48:03<27:35,  5.59it/s, lr=0.000717, step_loss=0.003207/27/2023 18:32:53 - INFO - __main__ - train loss is 38.300596822518855\n",
      "Steps:  38%|▍| 5753/15000 [48:03<27:36,  5.58it/s, lr=0.000717, step_loss=0.010107/27/2023 18:32:53 - INFO - __main__ - train loss is 38.317452379036695\n",
      "Steps:  38%|▍| 5754/15000 [48:04<27:35,  5.58it/s, lr=0.000718, step_loss=0.016907/27/2023 18:32:53 - INFO - __main__ - train loss is 38.40420029358938\n",
      "Steps:  38%|▍| 5755/15000 [48:04<27:35,  5.59it/s, lr=0.000718, step_loss=0.086707/27/2023 18:32:54 - INFO - __main__ - train loss is 38.40664291102439\n",
      "Steps:  38%|▍| 5756/15000 [48:04<27:48,  5.54it/s, lr=0.000718, step_loss=0.002407/27/2023 18:32:54 - INFO - __main__ - train loss is 38.543726307339966\n",
      "Steps:  38%|▍| 5757/15000 [48:04<39:50,  3.87it/s, lr=0.000718, step_loss=0.137]07/27/2023 18:32:55 - INFO - __main__ - Per validation step average loss is 0.014724737033247948\n",
      "07/27/2023 18:32:55 - INFO - __main__ - Cumulative validation average loss is 0.014724737033247948\n",
      "07/27/2023 18:32:56 - INFO - __main__ - Per validation step average loss is 0.003510498208925128\n",
      "07/27/2023 18:32:56 - INFO - __main__ - Cumulative validation average loss is 0.018235235242173076\n",
      "07/27/2023 18:32:56 - INFO - __main__ - Per validation step average loss is 0.15665790438652039\n",
      "07/27/2023 18:32:56 - INFO - __main__ - Cumulative validation average loss is 0.17489313962869346\n",
      "07/27/2023 18:32:56 - INFO - __main__ - Per validation step average loss is 0.3086695671081543\n",
      "07/27/2023 18:32:56 - INFO - __main__ - Cumulative validation average loss is 0.48356270673684776\n",
      "07/27/2023 18:32:57 - INFO - __main__ - Per validation step average loss is 0.461740642786026\n",
      "07/27/2023 18:32:57 - INFO - __main__ - Cumulative validation average loss is 0.9453033495228738\n",
      "07/27/2023 18:32:57 - INFO - __main__ - Per validation step average loss is 0.0018670837162062526\n",
      "07/27/2023 18:32:57 - INFO - __main__ - Cumulative validation average loss is 0.94717043323908\n",
      "07/27/2023 18:32:58 - INFO - __main__ - Per validation step average loss is 0.007927412167191505\n",
      "07/27/2023 18:32:58 - INFO - __main__ - Cumulative validation average loss is 0.9550978454062715\n",
      "07/27/2023 18:32:58 - INFO - __main__ - Per validation step average loss is 0.017354056239128113\n",
      "07/27/2023 18:32:58 - INFO - __main__ - Cumulative validation average loss is 0.9724519016453996\n",
      "07/27/2023 18:32:58 - INFO - __main__ - Per validation step average loss is 0.052842844277620316\n",
      "07/27/2023 18:32:58 - INFO - __main__ - Cumulative validation average loss is 1.02529474592302\n",
      "07/27/2023 18:32:59 - INFO - __main__ - Per validation step average loss is 0.125718891620636\n",
      "07/27/2023 18:32:59 - INFO - __main__ - Cumulative validation average loss is 1.151013637543656\n",
      "07/27/2023 18:32:59 - INFO - __main__ - Per validation step average loss is 0.3064979910850525\n",
      "07/27/2023 18:32:59 - INFO - __main__ - Cumulative validation average loss is 1.4575116286287084\n",
      "07/27/2023 18:33:00 - INFO - __main__ - Per validation step average loss is 0.01837240159511566\n",
      "07/27/2023 18:33:00 - INFO - __main__ - Cumulative validation average loss is 1.475884030223824\n",
      "07/27/2023 18:33:00 - INFO - __main__ - Per validation step average loss is 0.023071788251399994\n",
      "07/27/2023 18:33:00 - INFO - __main__ - Cumulative validation average loss is 1.498955818475224\n",
      "07/27/2023 18:33:01 - INFO - __main__ - Per validation step average loss is 0.28797316551208496\n",
      "07/27/2023 18:33:01 - INFO - __main__ - Cumulative validation average loss is 1.786928983987309\n",
      "07/27/2023 18:33:01 - INFO - __main__ - Per validation step average loss is 0.003612297587096691\n",
      "07/27/2023 18:33:01 - INFO - __main__ - Cumulative validation average loss is 1.7905412815744057\n",
      "07/27/2023 18:33:01 - INFO - __main__ - Per validation step average loss is 0.08712825179100037\n",
      "07/27/2023 18:33:01 - INFO - __main__ - Cumulative validation average loss is 1.877669533365406\n",
      "07/27/2023 18:33:02 - INFO - __main__ - Per validation step average loss is 0.003304405603557825\n",
      "07/27/2023 18:33:02 - INFO - __main__ - Cumulative validation average loss is 1.880973938968964\n",
      "07/27/2023 18:33:02 - INFO - __main__ - Per validation step average loss is 0.2930675148963928\n",
      "07/27/2023 18:33:02 - INFO - __main__ - Cumulative validation average loss is 2.1740414538653567\n",
      "07/27/2023 18:33:03 - INFO - __main__ - Per validation step average loss is 0.15100380778312683\n",
      "07/27/2023 18:33:03 - INFO - __main__ - Cumulative validation average loss is 2.3250452616484836\n",
      "07/27/2023 18:33:03 - INFO - __main__ - Per validation step average loss is 0.0023440627846866846\n",
      "07/27/2023 18:33:03 - INFO - __main__ - Cumulative validation average loss is 2.3273893244331703\n",
      "07/27/2023 18:33:03 - INFO - __main__ - Per validation step average loss is 0.1731753647327423\n",
      "07/27/2023 18:33:03 - INFO - __main__ - Cumulative validation average loss is 2.5005646891659126\n",
      "07/27/2023 18:33:04 - INFO - __main__ - Per validation step average loss is 0.008975217118859291\n",
      "07/27/2023 18:33:04 - INFO - __main__ - Cumulative validation average loss is 2.509539906284772\n",
      "07/27/2023 18:33:04 - INFO - __main__ - Per validation step average loss is 0.019159814342856407\n",
      "07/27/2023 18:33:04 - INFO - __main__ - Cumulative validation average loss is 2.5286997206276283\n",
      "07/27/2023 18:33:05 - INFO - __main__ - Per validation step average loss is 0.6459876298904419\n",
      "07/27/2023 18:33:05 - INFO - __main__ - Cumulative validation average loss is 3.17468735051807\n",
      "07/27/2023 18:33:05 - INFO - __main__ - Per validation step average loss is 0.04253268986940384\n",
      "07/27/2023 18:33:05 - INFO - __main__ - Cumulative validation average loss is 3.217220040387474\n",
      "07/27/2023 18:33:05 - INFO - __main__ - Per validation step average loss is 0.0036937405820935965\n",
      "07/27/2023 18:33:05 - INFO - __main__ - Cumulative validation average loss is 3.2209137809695676\n",
      "07/27/2023 18:33:06 - INFO - __main__ - Per validation step average loss is 0.21932485699653625\n",
      "07/27/2023 18:33:06 - INFO - __main__ - Cumulative validation average loss is 3.440238637966104\n",
      "07/27/2023 18:33:06 - INFO - __main__ - Per validation step average loss is 0.09952519834041595\n",
      "07/27/2023 18:33:06 - INFO - __main__ - Cumulative validation average loss is 3.53976383630652\n",
      "07/27/2023 18:33:07 - INFO - __main__ - Per validation step average loss is 0.004730628337711096\n",
      "07/27/2023 18:33:07 - INFO - __main__ - Cumulative validation average loss is 3.544494464644231\n",
      "07/27/2023 18:33:07 - INFO - __main__ - Per validation step average loss is 0.07791582494974136\n",
      "07/27/2023 18:33:07 - INFO - __main__ - Cumulative validation average loss is 3.6224102895939723\n",
      "07/27/2023 18:33:08 - INFO - __main__ - Per validation step average loss is 0.15782751142978668\n",
      "07/27/2023 18:33:08 - INFO - __main__ - Cumulative validation average loss is 3.780237801023759\n",
      "07/27/2023 18:33:08 - INFO - __main__ - Per validation step average loss is 0.01922687329351902\n",
      "07/27/2023 18:33:08 - INFO - __main__ - Cumulative validation average loss is 3.799464674317278\n",
      "07/27/2023 18:33:08 - INFO - __main__ - Per validation step average loss is 0.13004472851753235\n",
      "07/27/2023 18:33:08 - INFO - __main__ - Cumulative validation average loss is 3.9295094028348103\n",
      "07/27/2023 18:33:09 - INFO - __main__ - Per validation step average loss is 0.20098373293876648\n",
      "07/27/2023 18:33:09 - INFO - __main__ - Cumulative validation average loss is 4.130493135773577\n",
      "07/27/2023 18:33:09 - INFO - __main__ - Per validation step average loss is 0.2176169455051422\n",
      "07/27/2023 18:33:09 - INFO - __main__ - Cumulative validation average loss is 4.348110081278719\n",
      "07/27/2023 18:33:10 - INFO - __main__ - Per validation step average loss is 0.05859196186065674\n",
      "07/27/2023 18:33:10 - INFO - __main__ - Cumulative validation average loss is 4.406702043139376\n",
      "07/27/2023 18:33:10 - INFO - __main__ - Per validation step average loss is 0.044600725173950195\n",
      "07/27/2023 18:33:10 - INFO - __main__ - Cumulative validation average loss is 4.451302768313326\n",
      "07/27/2023 18:33:10 - INFO - __main__ - Per validation step average loss is 0.006134154740720987\n",
      "07/27/2023 18:33:10 - INFO - __main__ - Cumulative validation average loss is 4.457436923054047\n",
      "07/27/2023 18:33:11 - INFO - __main__ - Per validation step average loss is 0.0035514915362000465\n",
      "07/27/2023 18:33:11 - INFO - __main__ - Cumulative validation average loss is 4.460988414590247\n",
      "07/27/2023 18:33:11 - INFO - __main__ - Per validation step average loss is 0.06441750377416611\n",
      "07/27/2023 18:33:11 - INFO - __main__ - Cumulative validation average loss is 4.525405918364413\n",
      "07/27/2023 18:33:12 - INFO - __main__ - Per validation step average loss is 0.013857610523700714\n",
      "07/27/2023 18:33:12 - INFO - __main__ - Cumulative validation average loss is 4.539263528888114\n",
      "07/27/2023 18:33:12 - INFO - __main__ - Per validation step average loss is 0.0986195057630539\n",
      "07/27/2023 18:33:12 - INFO - __main__ - Cumulative validation average loss is 4.637883034651168\n",
      "07/27/2023 18:33:12 - INFO - __main__ - Per validation step average loss is 0.0066560423001646996\n",
      "07/27/2023 18:33:12 - INFO - __main__ - Cumulative validation average loss is 4.644539076951332\n",
      "07/27/2023 18:33:13 - INFO - __main__ - Per validation step average loss is 0.014445029199123383\n",
      "07/27/2023 18:33:13 - INFO - __main__ - Cumulative validation average loss is 4.658984106150456\n",
      "07/27/2023 18:33:13 - INFO - __main__ - Per validation step average loss is 0.0028577446937561035\n",
      "07/27/2023 18:33:13 - INFO - __main__ - Cumulative validation average loss is 4.661841850844212\n",
      "07/27/2023 18:33:14 - INFO - __main__ - Per validation step average loss is 0.07119420170783997\n",
      "07/27/2023 18:33:14 - INFO - __main__ - Cumulative validation average loss is 4.733036052552052\n",
      "07/27/2023 18:33:14 - INFO - __main__ - Per validation step average loss is 0.007955131120979786\n",
      "07/27/2023 18:33:14 - INFO - __main__ - Cumulative validation average loss is 4.740991183673032\n",
      "07/27/2023 18:33:14 - INFO - __main__ - Per validation step average loss is 0.11663124710321426\n",
      "07/27/2023 18:33:14 - INFO - __main__ - Cumulative validation average loss is 4.857622430776246\n",
      "07/27/2023 18:33:15 - INFO - __main__ - Per validation step average loss is 0.007948257029056549\n",
      "07/27/2023 18:33:15 - INFO - __main__ - Cumulative validation average loss is 4.865570687805302\n",
      "07/27/2023 18:33:15 - INFO - __main__ - Per validation step average loss is 0.18631215393543243\n",
      "07/27/2023 18:33:15 - INFO - __main__ - Cumulative validation average loss is 5.051882841740735\n",
      "07/27/2023 18:33:16 - INFO - __main__ - Per validation step average loss is 0.06838016957044601\n",
      "07/27/2023 18:33:16 - INFO - __main__ - Cumulative validation average loss is 5.120263011311181\n",
      "07/27/2023 18:33:16 - INFO - __main__ - Per validation step average loss is 0.13665176928043365\n",
      "07/27/2023 18:33:16 - INFO - __main__ - Cumulative validation average loss is 5.2569147805916145\n",
      "07/27/2023 18:33:16 - INFO - __main__ - Per validation step average loss is 0.010920803993940353\n",
      "07/27/2023 18:33:16 - INFO - __main__ - Cumulative validation average loss is 5.267835584585555\n",
      "07/27/2023 18:33:17 - INFO - __main__ - Per validation step average loss is 0.16200579702854156\n",
      "07/27/2023 18:33:17 - INFO - __main__ - Cumulative validation average loss is 5.4298413816140965\n",
      "07/27/2023 18:33:17 - INFO - __main__ - Per validation step average loss is 0.029345300048589706\n",
      "07/27/2023 18:33:17 - INFO - __main__ - Cumulative validation average loss is 5.459186681662686\n",
      "07/27/2023 18:33:18 - INFO - __main__ - Per validation step average loss is 0.03470741957426071\n",
      "07/27/2023 18:33:18 - INFO - __main__ - Cumulative validation average loss is 5.493894101236947\n",
      "07/27/2023 18:33:18 - INFO - __main__ - Per validation step average loss is 0.10871689021587372\n",
      "07/27/2023 18:33:18 - INFO - __main__ - Cumulative validation average loss is 5.602610991452821\n",
      "07/27/2023 18:33:19 - INFO - __main__ - Per validation step average loss is 0.15965025126934052\n",
      "07/27/2023 18:33:19 - INFO - __main__ - Cumulative validation average loss is 5.762261242722161\n",
      "07/27/2023 18:33:19 - INFO - __main__ - Per validation step average loss is 0.046237848699092865\n",
      "07/27/2023 18:33:19 - INFO - __main__ - Cumulative validation average loss is 5.808499091421254\n",
      "07/27/2023 18:33:19 - INFO - __main__ - Per validation step average loss is 0.009890692308545113\n",
      "07/27/2023 18:33:19 - INFO - __main__ - Cumulative validation average loss is 5.818389783729799\n",
      "07/27/2023 18:33:20 - INFO - __main__ - Per validation step average loss is 0.005900670774281025\n",
      "07/27/2023 18:33:20 - INFO - __main__ - Cumulative validation average loss is 5.82429045450408\n",
      "07/27/2023 18:33:20 - INFO - __main__ - Per validation step average loss is 0.2825743556022644\n",
      "07/27/2023 18:33:20 - INFO - __main__ - Cumulative validation average loss is 6.1068648101063445\n",
      "07/27/2023 18:33:21 - INFO - __main__ - Per validation step average loss is 0.19624629616737366\n",
      "07/27/2023 18:33:21 - INFO - __main__ - Cumulative validation average loss is 6.303111106273718\n",
      "07/27/2023 18:33:21 - INFO - __main__ - Per validation step average loss is 0.2913246750831604\n",
      "07/27/2023 18:33:21 - INFO - __main__ - Cumulative validation average loss is 6.594435781356879\n",
      "07/27/2023 18:33:21 - INFO - __main__ - Per validation step average loss is 0.12125813961029053\n",
      "07/27/2023 18:33:21 - INFO - __main__ - Cumulative validation average loss is 6.715693920967169\n",
      "07/27/2023 18:33:22 - INFO - __main__ - Per validation step average loss is 0.3240957260131836\n",
      "07/27/2023 18:33:22 - INFO - __main__ - Cumulative validation average loss is 7.039789646980353\n",
      "07/27/2023 18:33:22 - INFO - __main__ - Per validation step average loss is 0.24401938915252686\n",
      "07/27/2023 18:33:22 - INFO - __main__ - Cumulative validation average loss is 7.2838090361328796\n",
      "07/27/2023 18:33:23 - INFO - __main__ - Per validation step average loss is 0.08737024664878845\n",
      "07/27/2023 18:33:23 - INFO - __main__ - Cumulative validation average loss is 7.371179282781668\n",
      "07/27/2023 18:33:23 - INFO - __main__ - Per validation step average loss is 0.010027818381786346\n",
      "07/27/2023 18:33:23 - INFO - __main__ - Cumulative validation average loss is 7.381207101163454\n",
      "07/27/2023 18:33:23 - INFO - __main__ - Per validation step average loss is 0.2512483298778534\n",
      "07/27/2023 18:33:23 - INFO - __main__ - Cumulative validation average loss is 7.632455431041308\n",
      "07/27/2023 18:33:24 - INFO - __main__ - Per validation step average loss is 0.36495441198349\n",
      "07/27/2023 18:33:24 - INFO - __main__ - Cumulative validation average loss is 7.997409843024798\n",
      "07/27/2023 18:33:24 - INFO - __main__ - Per validation step average loss is 0.004786590114235878\n",
      "07/27/2023 18:33:24 - INFO - __main__ - Cumulative validation average loss is 8.002196433139034\n",
      "07/27/2023 18:33:25 - INFO - __main__ - Per validation step average loss is 0.011345062404870987\n",
      "07/27/2023 18:33:25 - INFO - __main__ - Cumulative validation average loss is 8.013541495543905\n",
      "07/27/2023 18:33:25 - INFO - __main__ - Per validation step average loss is 0.005914393346756697\n",
      "07/27/2023 18:33:25 - INFO - __main__ - Cumulative validation average loss is 8.019455888890661\n",
      "07/27/2023 18:33:26 - INFO - __main__ - Per validation step average loss is 0.004244218580424786\n",
      "07/27/2023 18:33:26 - INFO - __main__ - Cumulative validation average loss is 8.023700107471086\n",
      "07/27/2023 18:33:26 - INFO - __main__ - Per validation step average loss is 0.13830167055130005\n",
      "07/27/2023 18:33:26 - INFO - __main__ - Cumulative validation average loss is 8.162001778022386\n",
      "07/27/2023 18:33:26 - INFO - __main__ - Per validation step average loss is 0.07997942715883255\n",
      "07/27/2023 18:33:26 - INFO - __main__ - Cumulative validation average loss is 8.241981205181219\n",
      "07/27/2023 18:33:27 - INFO - __main__ - Per validation step average loss is 0.05496001988649368\n",
      "07/27/2023 18:33:27 - INFO - __main__ - Cumulative validation average loss is 8.296941225067712\n",
      "07/27/2023 18:33:27 - INFO - __main__ - Per validation step average loss is 0.7333920001983643\n",
      "07/27/2023 18:33:27 - INFO - __main__ - Cumulative validation average loss is 9.030333225266077\n",
      "07/27/2023 18:33:27 - INFO - __main__ - Average validation loss for Epoch 18 is 0.11430801550969717\n",
      "07/27/2023 18:33:27 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:34:24 - INFO - __main__ - Starting epoch 19\n",
      "07/27/2023 18:34:25 - INFO - __main__ - train loss is 0.22859133780002594\n",
      "Steps:  38%|▍| 5758/15000 [49:35<70:40:09, 27.53s/it, lr=0.000718, step_loss=0.207/27/2023 18:34:25 - INFO - __main__ - train loss is 0.2342246137559414\n",
      "Steps:  38%|▍| 5759/15000 [49:36<49:36:03, 19.32s/it, lr=0.000718, step_loss=0.007/27/2023 18:34:26 - INFO - __main__ - train loss is 0.46261418983340263\n",
      "Steps:  38%|▍| 5760/15000 [49:36<34:51:32, 13.58s/it, lr=0.000718, step_loss=0.207/27/2023 18:34:26 - INFO - __main__ - train loss is 0.723195593804121\n",
      "Steps:  38%|▍| 5761/15000 [49:36<24:32:21,  9.56s/it, lr=0.000718, step_loss=0.207/27/2023 18:34:26 - INFO - __main__ - train loss is 0.7384200794622302\n",
      "Steps:  38%|▍| 5762/15000 [49:36<17:18:53,  6.75s/it, lr=0.000719, step_loss=0.007/27/2023 18:34:26 - INFO - __main__ - train loss is 0.8422044543549418\n",
      "Steps:  38%|▍| 5763/15000 [49:36<12:15:43,  4.78s/it, lr=0.000719, step_loss=0.107/27/2023 18:34:26 - INFO - __main__ - train loss is 1.290881815366447\n",
      "Steps:  38%|▍| 5764/15000 [49:37<8:43:19,  3.40s/it, lr=0.000719, step_loss=0.4407/27/2023 18:34:26 - INFO - __main__ - train loss is 1.3777507347986102\n",
      "Steps:  38%|▍| 5765/15000 [49:37<6:14:38,  2.43s/it, lr=0.000719, step_loss=0.0807/27/2023 18:34:27 - INFO - __main__ - train loss is 1.7672791285440326\n",
      "Steps:  38%|▍| 5766/15000 [49:37<4:30:34,  1.76s/it, lr=0.000719, step_loss=0.3907/27/2023 18:34:27 - INFO - __main__ - train loss is 1.8432016177102923\n",
      "Steps:  38%|▍| 5767/15000 [49:37<3:17:43,  1.28s/it, lr=0.000719, step_loss=0.0707/27/2023 18:34:27 - INFO - __main__ - train loss is 1.8475656984373927\n",
      "Steps:  38%|▍| 5768/15000 [49:37<2:26:44,  1.05it/s, lr=0.000719, step_loss=0.0007/27/2023 18:34:27 - INFO - __main__ - train loss is 2.3342175958678126\n",
      "Steps:  38%|▍| 5769/15000 [49:37<1:51:11,  1.38it/s, lr=0.000719, step_loss=0.4807/27/2023 18:34:27 - INFO - __main__ - train loss is 2.3369145905599\n",
      "Steps:  38%|▍| 5770/15000 [49:38<1:26:21,  1.78it/s, lr=0.00072, step_loss=0.00207/27/2023 18:34:28 - INFO - __main__ - train loss is 2.362553467042744\n",
      "Steps:  38%|▍| 5771/15000 [49:38<1:09:02,  2.23it/s, lr=0.00072, step_loss=0.02507/27/2023 18:34:28 - INFO - __main__ - train loss is 2.580430348403752\n",
      "Steps:  38%|▊ | 5772/15000 [49:38<56:47,  2.71it/s, lr=0.00072, step_loss=0.218]07/27/2023 18:34:28 - INFO - __main__ - train loss is 2.8742382125929\n",
      "Steps:  38%|▊ | 5773/15000 [49:38<48:13,  3.19it/s, lr=0.00072, step_loss=0.294]07/27/2023 18:34:28 - INFO - __main__ - train loss is 3.1071926401928067\n",
      "Steps:  38%|▊ | 5774/15000 [49:38<42:21,  3.63it/s, lr=0.00072, step_loss=0.233]07/27/2023 18:34:28 - INFO - __main__ - train loss is 3.1216488545760512\n",
      "Steps:  38%|▍| 5775/15000 [49:39<37:55,  4.05it/s, lr=0.00072, step_loss=0.0145]07/27/2023 18:34:28 - INFO - __main__ - train loss is 3.143488089554012\n",
      "Steps:  39%|▍| 5776/15000 [49:39<34:48,  4.42it/s, lr=0.00072, step_loss=0.0218]07/27/2023 18:34:29 - INFO - __main__ - train loss is 3.5109338564798236\n",
      "Steps:  39%|▊ | 5777/15000 [49:39<32:37,  4.71it/s, lr=0.00072, step_loss=0.367]07/27/2023 18:34:29 - INFO - __main__ - train loss is 3.551147590391338\n",
      "Steps:  39%|▍| 5778/15000 [49:39<31:07,  4.94it/s, lr=0.000721, step_loss=0.040207/27/2023 18:34:29 - INFO - __main__ - train loss is 3.665101836435497\n",
      "Steps:  39%|▍| 5779/15000 [49:39<30:03,  5.11it/s, lr=0.000721, step_loss=0.114]07/27/2023 18:34:29 - INFO - __main__ - train loss is 3.6828055744990706\n",
      "Steps:  39%|▍| 5780/15000 [49:39<29:18,  5.24it/s, lr=0.000721, step_loss=0.017707/27/2023 18:34:29 - INFO - __main__ - train loss is 4.197782195173204\n",
      "Steps:  39%|▍| 5781/15000 [49:40<28:47,  5.34it/s, lr=0.000721, step_loss=0.515]07/27/2023 18:34:30 - INFO - __main__ - train loss is 4.200356853194535\n",
      "Steps:  39%|▍| 5782/15000 [49:40<28:26,  5.40it/s, lr=0.000721, step_loss=0.002507/27/2023 18:34:30 - INFO - __main__ - train loss is 4.222211160697043\n",
      "Steps:  39%|▍| 5783/15000 [49:40<28:11,  5.45it/s, lr=0.000721, step_loss=0.021907/27/2023 18:34:30 - INFO - __main__ - train loss is 4.295164340175688\n",
      "Steps:  39%|▍| 5784/15000 [49:40<28:15,  5.43it/s, lr=0.000721, step_loss=0.073]07/27/2023 18:34:30 - INFO - __main__ - train loss is 4.327477098442614\n",
      "Steps:  39%|▍| 5785/15000 [49:40<28:09,  5.45it/s, lr=0.000721, step_loss=0.032307/27/2023 18:34:30 - INFO - __main__ - train loss is 4.7162604639306664\n",
      "Steps:  39%|▍| 5786/15000 [49:41<27:57,  5.49it/s, lr=0.000722, step_loss=0.389]07/27/2023 18:34:30 - INFO - __main__ - train loss is 4.78951267991215\n",
      "Steps:  39%|▍| 5787/15000 [49:41<27:49,  5.52it/s, lr=0.000722, step_loss=0.073307/27/2023 18:34:31 - INFO - __main__ - train loss is 4.8315183306112885\n",
      "Steps:  39%|▍| 5788/15000 [49:41<27:45,  5.53it/s, lr=0.000722, step_loss=0.042]07/27/2023 18:34:31 - INFO - __main__ - train loss is 5.203708746470511\n",
      "Steps:  39%|▍| 5789/15000 [49:41<27:42,  5.54it/s, lr=0.000722, step_loss=0.372]07/27/2023 18:34:31 - INFO - __main__ - train loss is 5.64275807980448\n",
      "Steps:  39%|▍| 5790/15000 [49:41<27:37,  5.56it/s, lr=0.000722, step_loss=0.439]07/27/2023 18:34:31 - INFO - __main__ - train loss is 5.650371593423188\n",
      "Steps:  39%|▍| 5791/15000 [49:41<27:37,  5.56it/s, lr=0.000722, step_loss=0.007607/27/2023 18:34:31 - INFO - __main__ - train loss is 6.358899158425629\n",
      "Steps:  39%|▍| 5792/15000 [49:42<27:35,  5.56it/s, lr=0.000722, step_loss=0.709]07/27/2023 18:34:32 - INFO - __main__ - train loss is 6.3601009720005095\n",
      "Steps:  39%|▍| 5793/15000 [49:42<27:33,  5.57it/s, lr=0.000722, step_loss=0.001207/27/2023 18:34:32 - INFO - __main__ - train loss is 6.367154242005199\n",
      "Steps:  39%|▍| 5794/15000 [49:42<27:33,  5.57it/s, lr=0.000723, step_loss=0.007007/27/2023 18:34:32 - INFO - __main__ - train loss is 6.478174933698028\n",
      "Steps:  39%|▍| 5795/15000 [49:42<27:33,  5.57it/s, lr=0.000723, step_loss=0.111]07/27/2023 18:34:32 - INFO - __main__ - train loss is 6.67379013588652\n",
      "Steps:  39%|▍| 5796/15000 [49:42<27:33,  5.57it/s, lr=0.000723, step_loss=0.196]07/27/2023 18:34:32 - INFO - __main__ - train loss is 7.058477738406509\n",
      "Steps:  39%|▍| 5797/15000 [49:43<27:32,  5.57it/s, lr=0.000723, step_loss=0.385]07/27/2023 18:34:32 - INFO - __main__ - train loss is 7.069250906351954\n",
      "Steps:  39%|▍| 5798/15000 [49:43<27:32,  5.57it/s, lr=0.000723, step_loss=0.010807/27/2023 18:34:33 - INFO - __main__ - train loss is 7.090060370508581\n",
      "Steps:  39%|▍| 5799/15000 [49:43<27:31,  5.57it/s, lr=0.000723, step_loss=0.020807/27/2023 18:34:33 - INFO - __main__ - train loss is 7.1108291004784405\n",
      "Steps:  39%|▍| 5800/15000 [49:43<27:32,  5.57it/s, lr=0.000723, step_loss=0.020807/27/2023 18:34:33 - INFO - __main__ - train loss is 7.259481534827501\n",
      "Steps:  39%|▍| 5801/15000 [49:43<27:31,  5.57it/s, lr=0.000723, step_loss=0.149]07/27/2023 18:34:33 - INFO - __main__ - train loss is 7.330666721332818\n",
      "Steps:  39%|▍| 5802/15000 [49:43<27:47,  5.52it/s, lr=0.000724, step_loss=0.071207/27/2023 18:34:33 - INFO - __main__ - train loss is 7.547950596082956\n",
      "Steps:  39%|▍| 5803/15000 [49:44<27:42,  5.53it/s, lr=0.000724, step_loss=0.217]07/27/2023 18:34:34 - INFO - __main__ - train loss is 7.61286572413519\n",
      "Steps:  39%|▍| 5804/15000 [49:44<27:38,  5.54it/s, lr=0.000724, step_loss=0.064907/27/2023 18:34:34 - INFO - __main__ - train loss is 8.188620724249631\n",
      "Steps:  39%|▍| 5805/15000 [49:44<27:35,  5.55it/s, lr=0.000724, step_loss=0.576]07/27/2023 18:34:34 - INFO - __main__ - train loss is 8.404575892258435\n",
      "Steps:  39%|▍| 5806/15000 [49:44<27:33,  5.56it/s, lr=0.000724, step_loss=0.216]07/27/2023 18:34:34 - INFO - __main__ - train loss is 8.537736364174634\n",
      "Steps:  39%|▍| 5807/15000 [49:44<27:33,  5.56it/s, lr=0.000724, step_loss=0.133]07/27/2023 18:34:34 - INFO - __main__ - train loss is 8.552009981591254\n",
      "Steps:  39%|▍| 5808/15000 [49:45<27:33,  5.56it/s, lr=0.000724, step_loss=0.014307/27/2023 18:34:34 - INFO - __main__ - train loss is 8.566050774883479\n",
      "Steps:  39%|▍| 5809/15000 [49:45<27:32,  5.56it/s, lr=0.000724, step_loss=0.014]07/27/2023 18:34:35 - INFO - __main__ - train loss is 8.57210639026016\n",
      "Steps:  39%|▍| 5810/15000 [49:45<27:31,  5.56it/s, lr=0.000725, step_loss=0.006007/27/2023 18:34:35 - INFO - __main__ - train loss is 9.020018397830427\n",
      "Steps:  39%|▍| 5811/15000 [49:45<27:31,  5.56it/s, lr=0.000725, step_loss=0.448]07/27/2023 18:34:35 - INFO - __main__ - train loss is 9.07418234553188\n",
      "Steps:  39%|▍| 5812/15000 [49:45<27:31,  5.56it/s, lr=0.000725, step_loss=0.054207/27/2023 18:34:35 - INFO - __main__ - train loss is 9.144148505292833\n",
      "Steps:  39%|▊ | 5813/15000 [49:45<27:30,  5.57it/s, lr=0.000725, step_loss=0.07]07/27/2023 18:34:35 - INFO - __main__ - train loss is 9.14712935499847\n",
      "Steps:  39%|▍| 5814/15000 [49:46<27:29,  5.57it/s, lr=0.000725, step_loss=0.002907/27/2023 18:34:35 - INFO - __main__ - train loss is 9.17923846654594\n",
      "Steps:  39%|▍| 5815/15000 [49:46<27:33,  5.55it/s, lr=0.000725, step_loss=0.032107/27/2023 18:34:36 - INFO - __main__ - train loss is 9.203555567190051\n",
      "Steps:  39%|▍| 5816/15000 [49:46<27:32,  5.56it/s, lr=0.000725, step_loss=0.024307/27/2023 18:34:36 - INFO - __main__ - train loss is 9.207847295794636\n",
      "Steps:  39%|▍| 5817/15000 [49:46<27:31,  5.56it/s, lr=0.000725, step_loss=0.004207/27/2023 18:34:36 - INFO - __main__ - train loss is 9.213347257114947\n",
      "Steps:  39%|▍| 5818/15000 [49:46<27:35,  5.55it/s, lr=0.000726, step_loss=0.005507/27/2023 18:34:36 - INFO - __main__ - train loss is 9.226097737438977\n",
      "Steps:  39%|▍| 5819/15000 [49:47<27:33,  5.55it/s, lr=0.000726, step_loss=0.012807/27/2023 18:34:36 - INFO - __main__ - train loss is 9.23058218602091\n",
      "Steps:  39%|▍| 5820/15000 [49:47<27:31,  5.56it/s, lr=0.000726, step_loss=0.004407/27/2023 18:34:37 - INFO - __main__ - train loss is 9.353540503419936\n",
      "Steps:  39%|▍| 5821/15000 [49:47<27:31,  5.56it/s, lr=0.000726, step_loss=0.123]07/27/2023 18:34:37 - INFO - __main__ - train loss is 9.35511622519698\n",
      "Steps:  39%|▍| 5822/15000 [49:47<27:30,  5.56it/s, lr=0.000726, step_loss=0.001507/27/2023 18:34:37 - INFO - __main__ - train loss is 9.361662744893692\n",
      "Steps:  39%|▍| 5823/15000 [49:47<27:29,  5.56it/s, lr=0.000726, step_loss=0.006507/27/2023 18:34:37 - INFO - __main__ - train loss is 9.50660423876252\n",
      "Steps:  39%|▍| 5824/15000 [49:47<27:28,  5.57it/s, lr=0.000726, step_loss=0.145]07/27/2023 18:34:37 - INFO - __main__ - train loss is 9.705537691130303\n",
      "Steps:  39%|▍| 5825/15000 [49:48<27:28,  5.57it/s, lr=0.000726, step_loss=0.199]07/27/2023 18:34:37 - INFO - __main__ - train loss is 9.707201208453625\n",
      "Steps:  39%|▍| 5826/15000 [49:48<27:28,  5.57it/s, lr=0.000727, step_loss=0.001607/27/2023 18:34:38 - INFO - __main__ - train loss is 9.826452996116132\n",
      "Steps:  39%|▍| 5827/15000 [49:48<27:31,  5.56it/s, lr=0.000727, step_loss=0.119]07/27/2023 18:34:38 - INFO - __main__ - train loss is 9.876330043654889\n",
      "Steps:  39%|▍| 5828/15000 [49:48<27:30,  5.56it/s, lr=0.000727, step_loss=0.049907/27/2023 18:34:38 - INFO - __main__ - train loss is 9.881128855515271\n",
      "Steps:  39%|▍| 5829/15000 [49:48<27:34,  5.54it/s, lr=0.000727, step_loss=0.004807/27/2023 18:34:38 - INFO - __main__ - train loss is 10.207990594673902\n",
      "Steps:  39%|▍| 5830/15000 [49:48<27:32,  5.55it/s, lr=0.000727, step_loss=0.327]07/27/2023 18:34:38 - INFO - __main__ - train loss is 10.210446756100282\n",
      "Steps:  39%|▍| 5831/15000 [49:49<27:36,  5.53it/s, lr=0.000727, step_loss=0.002407/27/2023 18:34:39 - INFO - __main__ - train loss is 10.216130157699808\n",
      "Steps:  39%|▍| 5832/15000 [49:49<27:34,  5.54it/s, lr=0.000727, step_loss=0.005607/27/2023 18:34:39 - INFO - __main__ - train loss is 10.45689626573585\n",
      "Steps:  39%|▍| 5833/15000 [49:49<27:32,  5.55it/s, lr=0.000727, step_loss=0.241]07/27/2023 18:34:39 - INFO - __main__ - train loss is 10.49003548710607\n",
      "Steps:  39%|▍| 5834/15000 [49:49<27:33,  5.54it/s, lr=0.000728, step_loss=0.033107/27/2023 18:34:39 - INFO - __main__ - train loss is 10.512100606923923\n",
      "Steps:  39%|▍| 5835/15000 [49:49<27:31,  5.55it/s, lr=0.000728, step_loss=0.022107/27/2023 18:34:39 - INFO - __main__ - train loss is 10.546609170502052\n",
      "Steps:  39%|▍| 5836/15000 [49:50<27:35,  5.54it/s, lr=0.000728, step_loss=0.034507/27/2023 18:34:39 - INFO - __main__ - train loss is 10.93336708075367\n",
      "Steps:  39%|▍| 5837/15000 [49:50<27:33,  5.54it/s, lr=0.000728, step_loss=0.387]07/27/2023 18:34:40 - INFO - __main__ - train loss is 11.224150247639045\n",
      "Steps:  39%|▍| 5838/15000 [49:50<27:31,  5.55it/s, lr=0.000728, step_loss=0.291]07/27/2023 18:34:40 - INFO - __main__ - train loss is 11.262429427122697\n",
      "Steps:  39%|▍| 5839/15000 [49:50<27:30,  5.55it/s, lr=0.000728, step_loss=0.038307/27/2023 18:34:40 - INFO - __main__ - train loss is 11.556743275141343\n",
      "Steps:  39%|▍| 5840/15000 [49:50<27:31,  5.55it/s, lr=0.000728, step_loss=0.294]07/27/2023 18:34:40 - INFO - __main__ - train loss is 11.595643989508972\n",
      "Steps:  39%|▍| 5841/15000 [49:50<27:34,  5.53it/s, lr=0.000728, step_loss=0.038907/27/2023 18:34:40 - INFO - __main__ - train loss is 11.67872642702423\n",
      "Steps:  39%|▍| 5842/15000 [49:51<27:44,  5.50it/s, lr=0.000729, step_loss=0.083107/27/2023 18:34:41 - INFO - __main__ - train loss is 11.714288882678375\n",
      "Steps:  39%|▍| 5843/15000 [49:51<27:49,  5.48it/s, lr=0.000729, step_loss=0.035607/27/2023 18:34:41 - INFO - __main__ - train loss is 11.724358206382021\n",
      "Steps:  39%|▍| 5844/15000 [49:51<27:44,  5.50it/s, lr=0.000729, step_loss=0.010107/27/2023 18:34:41 - INFO - __main__ - train loss is 12.215269123902544\n",
      "Steps:  39%|▍| 5845/15000 [49:51<27:37,  5.52it/s, lr=0.000729, step_loss=0.491]07/27/2023 18:34:41 - INFO - __main__ - train loss is 12.361156230559573\n",
      "Steps:  39%|▍| 5846/15000 [49:51<27:44,  5.50it/s, lr=0.000729, step_loss=0.146]07/27/2023 18:34:41 - INFO - __main__ - train loss is 12.64748296677135\n",
      "Steps:  39%|▍| 5847/15000 [49:52<27:50,  5.48it/s, lr=0.000729, step_loss=0.286]07/27/2023 18:34:41 - INFO - __main__ - train loss is 12.692024109652266\n",
      "Steps:  39%|▍| 5848/15000 [49:52<27:59,  5.45it/s, lr=0.000729, step_loss=0.044507/27/2023 18:34:42 - INFO - __main__ - train loss is 13.001701025059447\n",
      "Steps:  39%|▊ | 5849/15000 [49:52<28:20,  5.38it/s, lr=0.000729, step_loss=0.31]07/27/2023 18:34:42 - INFO - __main__ - train loss is 13.12613552599214\n",
      "Steps:  39%|▊ | 5850/15000 [49:52<28:17,  5.39it/s, lr=0.00073, step_loss=0.124]07/27/2023 18:34:42 - INFO - __main__ - train loss is 13.13267345703207\n",
      "Steps:  39%|▍| 5851/15000 [49:52<28:17,  5.39it/s, lr=0.00073, step_loss=0.0065407/27/2023 18:34:42 - INFO - __main__ - train loss is 13.416864707833156\n",
      "Steps:  39%|▊ | 5852/15000 [49:53<28:31,  5.34it/s, lr=0.00073, step_loss=0.284]07/27/2023 18:34:42 - INFO - __main__ - train loss is 13.565203338628635\n",
      "Steps:  39%|▊ | 5853/15000 [49:53<28:26,  5.36it/s, lr=0.00073, step_loss=0.148]07/27/2023 18:34:43 - INFO - __main__ - train loss is 13.688467681175098\n",
      "Steps:  39%|▊ | 5854/15000 [49:53<28:22,  5.37it/s, lr=0.00073, step_loss=0.123]07/27/2023 18:34:43 - INFO - __main__ - train loss is 13.707817792659625\n",
      "Steps:  39%|▍| 5855/15000 [49:53<28:16,  5.39it/s, lr=0.00073, step_loss=0.0194]07/27/2023 18:34:43 - INFO - __main__ - train loss is 14.09033852792345\n",
      "Steps:  39%|▊ | 5856/15000 [49:53<28:06,  5.42it/s, lr=0.00073, step_loss=0.383]07/27/2023 18:34:43 - INFO - __main__ - train loss is 14.129455119138584\n",
      "Steps:  39%|▍| 5857/15000 [49:53<27:59,  5.44it/s, lr=0.00073, step_loss=0.0391]07/27/2023 18:34:43 - INFO - __main__ - train loss is 14.205801963573322\n",
      "Steps:  39%|▍| 5858/15000 [49:54<27:53,  5.46it/s, lr=0.000731, step_loss=0.076307/27/2023 18:34:43 - INFO - __main__ - train loss is 14.209911507321522\n",
      "Steps:  39%|▍| 5859/15000 [49:54<27:50,  5.47it/s, lr=0.000731, step_loss=0.004107/27/2023 18:34:44 - INFO - __main__ - train loss is 14.293538932455704\n",
      "Steps:  39%|▍| 5860/15000 [49:54<27:48,  5.48it/s, lr=0.000731, step_loss=0.083607/27/2023 18:34:44 - INFO - __main__ - train loss is 14.300295678665861\n",
      "Steps:  39%|▍| 5861/15000 [49:54<27:46,  5.48it/s, lr=0.000731, step_loss=0.006707/27/2023 18:34:44 - INFO - __main__ - train loss is 14.306786949047819\n",
      "Steps:  39%|▍| 5862/15000 [49:54<27:45,  5.49it/s, lr=0.000731, step_loss=0.006407/27/2023 18:34:44 - INFO - __main__ - train loss is 14.433049181709066\n",
      "Steps:  39%|▍| 5863/15000 [49:55<27:44,  5.49it/s, lr=0.000731, step_loss=0.126]07/27/2023 18:34:44 - INFO - __main__ - train loss is 14.436911331489682\n",
      "Steps:  39%|▍| 5864/15000 [49:55<27:43,  5.49it/s, lr=0.000731, step_loss=0.003807/27/2023 18:34:45 - INFO - __main__ - train loss is 14.438244241522625\n",
      "Steps:  39%|▍| 5865/15000 [49:55<27:42,  5.50it/s, lr=0.000731, step_loss=0.001307/27/2023 18:34:45 - INFO - __main__ - train loss is 14.442803956801072\n",
      "Steps:  39%|▍| 5866/15000 [49:55<27:56,  5.45it/s, lr=0.000732, step_loss=0.004507/27/2023 18:34:45 - INFO - __main__ - train loss is 14.586184017593041\n",
      "Steps:  39%|▍| 5867/15000 [49:55<27:51,  5.46it/s, lr=0.000732, step_loss=0.143]07/27/2023 18:34:45 - INFO - __main__ - train loss is 14.615523804211989\n",
      "Steps:  39%|▍| 5868/15000 [49:55<27:47,  5.48it/s, lr=0.000732, step_loss=0.029307/27/2023 18:34:45 - INFO - __main__ - train loss is 14.954009104752913\n",
      "Steps:  39%|▍| 5869/15000 [49:56<27:45,  5.48it/s, lr=0.000732, step_loss=0.338]07/27/2023 18:34:45 - INFO - __main__ - train loss is 15.004040874773636\n",
      "Steps:  39%|▊ | 5870/15000 [49:56<27:43,  5.49it/s, lr=0.000732, step_loss=0.05]07/27/2023 18:34:46 - INFO - __main__ - train loss is 15.129211895400658\n",
      "Steps:  39%|▍| 5871/15000 [49:56<27:42,  5.49it/s, lr=0.000732, step_loss=0.125]07/27/2023 18:34:46 - INFO - __main__ - train loss is 15.203440569574013\n",
      "Steps:  39%|▍| 5872/15000 [49:56<27:41,  5.49it/s, lr=0.000732, step_loss=0.074207/27/2023 18:34:46 - INFO - __main__ - train loss is 15.252375152194872\n",
      "Steps:  39%|▍| 5873/15000 [49:56<27:40,  5.49it/s, lr=0.000732, step_loss=0.048907/27/2023 18:34:46 - INFO - __main__ - train loss is 15.608295914018527\n",
      "Steps:  39%|▍| 5874/15000 [49:57<27:40,  5.50it/s, lr=0.000733, step_loss=0.356]07/27/2023 18:34:46 - INFO - __main__ - train loss is 15.610572686651722\n",
      "Steps:  39%|▍| 5875/15000 [49:57<27:39,  5.50it/s, lr=0.000733, step_loss=0.002207/27/2023 18:34:47 - INFO - __main__ - train loss is 15.615579089382663\n",
      "Steps:  39%|▍| 5876/15000 [49:57<27:39,  5.50it/s, lr=0.000733, step_loss=0.005007/27/2023 18:34:47 - INFO - __main__ - train loss is 15.743410846451297\n",
      "Steps:  39%|▍| 5877/15000 [49:57<27:39,  5.50it/s, lr=0.000733, step_loss=0.128]07/27/2023 18:34:47 - INFO - __main__ - train loss is 15.865310048917308\n",
      "Steps:  39%|▍| 5878/15000 [49:57<27:38,  5.50it/s, lr=0.000733, step_loss=0.122]07/27/2023 18:34:47 - INFO - __main__ - train loss is 15.874978481093422\n",
      "Steps:  39%|▍| 5879/15000 [49:57<27:40,  5.49it/s, lr=0.000733, step_loss=0.009607/27/2023 18:34:47 - INFO - __main__ - train loss is 15.879006065195426\n",
      "Steps:  39%|▍| 5880/15000 [49:58<27:33,  5.52it/s, lr=0.000733, step_loss=0.004007/27/2023 18:34:47 - INFO - __main__ - train loss is 15.902061767643318\n",
      "Steps:  39%|▍| 5881/15000 [49:58<27:27,  5.53it/s, lr=0.000733, step_loss=0.023107/27/2023 18:34:48 - INFO - __main__ - train loss is 15.928867701208219\n",
      "Steps:  39%|▍| 5882/15000 [49:58<27:23,  5.55it/s, lr=0.000734, step_loss=0.026807/27/2023 18:34:48 - INFO - __main__ - train loss is 15.93647719710134\n",
      "Steps:  39%|▍| 5883/15000 [49:58<27:21,  5.55it/s, lr=0.000734, step_loss=0.007607/27/2023 18:34:48 - INFO - __main__ - train loss is 16.026329992106184\n",
      "Steps:  39%|▍| 5884/15000 [49:58<27:20,  5.56it/s, lr=0.000734, step_loss=0.089907/27/2023 18:34:48 - INFO - __main__ - train loss is 16.387653229525313\n",
      "Steps:  39%|▍| 5885/15000 [49:59<28:16,  5.37it/s, lr=0.000734, step_loss=0.361]07/27/2023 18:34:48 - INFO - __main__ - train loss is 16.403346275677904\n",
      "Steps:  39%|▍| 5886/15000 [49:59<29:27,  5.16it/s, lr=0.000734, step_loss=0.015707/27/2023 18:34:49 - INFO - __main__ - train loss is 16.622193639865145\n",
      "Steps:  39%|▍| 5887/15000 [49:59<28:56,  5.25it/s, lr=0.000734, step_loss=0.219]07/27/2023 18:34:49 - INFO - __main__ - train loss is 16.697723677149042\n",
      "Steps:  39%|▍| 5888/15000 [49:59<31:34,  4.81it/s, lr=0.000734, step_loss=0.075507/27/2023 18:34:49 - INFO - __main__ - train loss is 16.69998450228013\n",
      "Steps:  39%|▍| 5889/15000 [49:59<31:55,  4.76it/s, lr=0.000734, step_loss=0.002207/27/2023 18:34:49 - INFO - __main__ - train loss is 16.723468696931377\n",
      "Steps:  39%|▍| 5890/15000 [50:00<31:04,  4.89it/s, lr=0.000735, step_loss=0.023507/27/2023 18:34:49 - INFO - __main__ - train loss is 16.741526963422075\n",
      "Steps:  39%|▍| 5891/15000 [50:00<30:01,  5.06it/s, lr=0.000735, step_loss=0.018107/27/2023 18:34:50 - INFO - __main__ - train loss is 16.966275649378076\n",
      "Steps:  39%|▍| 5892/15000 [50:00<29:11,  5.20it/s, lr=0.000735, step_loss=0.225]07/27/2023 18:34:50 - INFO - __main__ - train loss is 17.100616486975923\n",
      "Steps:  39%|▍| 5893/15000 [50:00<28:53,  5.25it/s, lr=0.000735, step_loss=0.134]07/27/2023 18:34:50 - INFO - __main__ - train loss is 17.317141922423616\n",
      "Steps:  39%|▍| 5894/15000 [50:00<28:28,  5.33it/s, lr=0.000735, step_loss=0.217]07/27/2023 18:34:50 - INFO - __main__ - train loss is 17.332971927011386\n",
      "Steps:  39%|▍| 5895/15000 [50:00<28:06,  5.40it/s, lr=0.000735, step_loss=0.015807/27/2023 18:34:50 - INFO - __main__ - train loss is 17.47793933399953\n",
      "Steps:  39%|▍| 5896/15000 [50:01<27:50,  5.45it/s, lr=0.000735, step_loss=0.145]07/27/2023 18:34:51 - INFO - __main__ - train loss is 17.482280698837712\n",
      "Steps:  39%|▍| 5897/15000 [50:01<27:39,  5.48it/s, lr=0.000735, step_loss=0.004307/27/2023 18:34:51 - INFO - __main__ - train loss is 17.562722948612645\n",
      "Steps:  39%|▍| 5898/15000 [50:01<27:31,  5.51it/s, lr=0.000736, step_loss=0.080407/27/2023 18:34:51 - INFO - __main__ - train loss is 17.737192658009008\n",
      "Steps:  39%|▍| 5899/15000 [50:01<27:26,  5.53it/s, lr=0.000736, step_loss=0.174]07/27/2023 18:34:51 - INFO - __main__ - train loss is 17.868006331147626\n",
      "Steps:  39%|▍| 5900/15000 [50:01<27:23,  5.54it/s, lr=0.000736, step_loss=0.131]07/27/2023 18:34:51 - INFO - __main__ - train loss is 18.158354801358655\n",
      "Steps:  39%|▊ | 5901/15000 [50:02<27:35,  5.50it/s, lr=0.000736, step_loss=0.29]07/27/2023 18:34:51 - INFO - __main__ - train loss is 18.159592249430716\n",
      "Steps:  39%|▍| 5902/15000 [50:02<27:33,  5.50it/s, lr=0.000736, step_loss=0.001207/27/2023 18:34:52 - INFO - __main__ - train loss is 18.33534396532923\n",
      "Steps:  39%|▍| 5903/15000 [50:02<27:39,  5.48it/s, lr=0.000736, step_loss=0.176]07/27/2023 18:34:52 - INFO - __main__ - train loss is 18.921412237919867\n",
      "Steps:  39%|▍| 5904/15000 [50:02<27:31,  5.51it/s, lr=0.000736, step_loss=0.586]07/27/2023 18:34:52 - INFO - __main__ - train loss is 18.946753148920834\n",
      "Steps:  39%|▍| 5905/15000 [50:02<27:24,  5.53it/s, lr=0.000736, step_loss=0.025307/27/2023 18:34:52 - INFO - __main__ - train loss is 18.95028464589268\n",
      "Steps:  39%|▍| 5906/15000 [50:02<27:21,  5.54it/s, lr=0.000737, step_loss=0.003507/27/2023 18:34:52 - INFO - __main__ - train loss is 18.975931321270764\n",
      "Steps:  39%|▍| 5907/15000 [50:03<27:17,  5.55it/s, lr=0.000737, step_loss=0.025607/27/2023 18:34:53 - INFO - __main__ - train loss is 19.071829539723694\n",
      "Steps:  39%|▍| 5908/15000 [50:03<27:15,  5.56it/s, lr=0.000737, step_loss=0.095907/27/2023 18:34:53 - INFO - __main__ - train loss is 19.18098057527095\n",
      "Steps:  39%|▍| 5909/15000 [50:03<27:13,  5.57it/s, lr=0.000737, step_loss=0.109]07/27/2023 18:34:53 - INFO - __main__ - train loss is 19.442738723941147\n",
      "Steps:  39%|▍| 5910/15000 [50:03<27:12,  5.57it/s, lr=0.000737, step_loss=0.262]07/27/2023 18:34:53 - INFO - __main__ - train loss is 19.48188600409776\n",
      "Steps:  39%|▍| 5911/15000 [50:03<27:11,  5.57it/s, lr=0.000737, step_loss=0.039107/27/2023 18:34:53 - INFO - __main__ - train loss is 19.532924343831837\n",
      "Steps:  39%|▍| 5912/15000 [50:04<27:10,  5.57it/s, lr=0.000737, step_loss=0.051]07/27/2023 18:34:53 - INFO - __main__ - train loss is 19.550386580638587\n",
      "Steps:  39%|▍| 5913/15000 [50:04<27:10,  5.57it/s, lr=0.000737, step_loss=0.017507/27/2023 18:34:54 - INFO - __main__ - train loss is 19.719412612728775\n",
      "Steps:  39%|▍| 5914/15000 [50:04<27:09,  5.58it/s, lr=0.000738, step_loss=0.169]07/27/2023 18:34:54 - INFO - __main__ - train loss is 19.76746147032827\n",
      "Steps:  39%|▍| 5915/15000 [50:04<27:10,  5.57it/s, lr=0.000738, step_loss=0.048]07/27/2023 18:34:54 - INFO - __main__ - train loss is 20.07825433369726\n",
      "Steps:  39%|▍| 5916/15000 [50:04<27:13,  5.56it/s, lr=0.000738, step_loss=0.311]07/27/2023 18:34:54 - INFO - __main__ - train loss is 20.080068883486092\n",
      "Steps:  39%|▍| 5917/15000 [50:04<27:12,  5.56it/s, lr=0.000738, step_loss=0.001807/27/2023 18:34:54 - INFO - __main__ - train loss is 20.187976849265397\n",
      "Steps:  39%|▍| 5918/15000 [50:05<27:16,  5.55it/s, lr=0.000738, step_loss=0.108]07/27/2023 18:34:54 - INFO - __main__ - train loss is 20.26595311332494\n",
      "Steps:  39%|▍| 5919/15000 [50:05<27:14,  5.56it/s, lr=0.000738, step_loss=0.078]07/27/2023 18:34:55 - INFO - __main__ - train loss is 20.766402532346547\n",
      "Steps:  39%|█▏ | 5920/15000 [50:05<27:17,  5.55it/s, lr=0.000738, step_loss=0.5]07/27/2023 18:34:55 - INFO - __main__ - train loss is 20.81280126143247\n",
      "Steps:  39%|▍| 5921/15000 [50:05<27:19,  5.54it/s, lr=0.000738, step_loss=0.046407/27/2023 18:34:55 - INFO - __main__ - train loss is 20.84913265425712\n",
      "Steps:  39%|▍| 5922/15000 [50:05<27:16,  5.55it/s, lr=0.000739, step_loss=0.036307/27/2023 18:34:55 - INFO - __main__ - train loss is 21.0873637618497\n",
      "Steps:  39%|▍| 5923/15000 [50:06<27:17,  5.54it/s, lr=0.000739, step_loss=0.238]07/27/2023 18:34:55 - INFO - __main__ - train loss is 21.33591000456363\n",
      "Steps:  39%|▍| 5924/15000 [50:06<27:14,  5.55it/s, lr=0.000739, step_loss=0.249]07/27/2023 18:34:56 - INFO - __main__ - train loss is 21.488064867444336\n",
      "Steps:  40%|▍| 5925/15000 [50:06<27:17,  5.54it/s, lr=0.000739, step_loss=0.152]07/27/2023 18:34:56 - INFO - __main__ - train loss is 21.85897628683597\n",
      "Steps:  40%|▍| 5926/15000 [50:06<27:15,  5.55it/s, lr=0.000739, step_loss=0.371]07/27/2023 18:34:56 - INFO - __main__ - train loss is 21.99999947566539\n",
      "Steps:  40%|▍| 5927/15000 [50:06<27:13,  5.55it/s, lr=0.000739, step_loss=0.141]07/27/2023 18:34:56 - INFO - __main__ - train loss is 22.17574540991336\n",
      "Steps:  40%|▍| 5928/15000 [50:06<27:13,  5.55it/s, lr=0.000739, step_loss=0.176]07/27/2023 18:34:56 - INFO - __main__ - train loss is 22.285605643875897\n",
      "Steps:  40%|▊ | 5929/15000 [50:07<27:11,  5.56it/s, lr=0.000739, step_loss=0.11]07/27/2023 18:34:56 - INFO - __main__ - train loss is 22.446714361198246\n",
      "Steps:  40%|▊ | 5930/15000 [50:07<27:14,  5.55it/s, lr=0.00074, step_loss=0.161]07/27/2023 18:34:57 - INFO - __main__ - train loss is 22.6626883642748\n",
      "Steps:  40%|▊ | 5931/15000 [50:07<27:12,  5.56it/s, lr=0.00074, step_loss=0.216]07/27/2023 18:34:57 - INFO - __main__ - train loss is 23.26140778232366\n",
      "Steps:  40%|▊ | 5932/15000 [50:07<27:16,  5.54it/s, lr=0.00074, step_loss=0.599]07/27/2023 18:34:57 - INFO - __main__ - train loss is 23.309956808574498\n",
      "Steps:  40%|▍| 5933/15000 [50:07<27:14,  5.55it/s, lr=0.00074, step_loss=0.0485]07/27/2023 18:34:57 - INFO - __main__ - train loss is 23.316020991653204\n",
      "Steps:  40%|▍| 5934/15000 [50:08<27:12,  5.55it/s, lr=0.00074, step_loss=0.0060607/27/2023 18:34:57 - INFO - __main__ - train loss is 23.53840346261859\n",
      "Steps:  40%|▊ | 5935/15000 [50:08<27:13,  5.55it/s, lr=0.00074, step_loss=0.222]07/27/2023 18:34:58 - INFO - __main__ - train loss is 23.617004726082087\n",
      "Steps:  40%|▍| 5936/15000 [50:08<27:10,  5.56it/s, lr=0.00074, step_loss=0.0786]07/27/2023 18:34:58 - INFO - __main__ - train loss is 23.668850537389517\n",
      "Steps:  40%|▍| 5937/15000 [50:08<27:13,  5.55it/s, lr=0.00074, step_loss=0.0518]07/27/2023 18:34:58 - INFO - __main__ - train loss is 23.680269706062973\n",
      "Steps:  40%|▍| 5938/15000 [50:08<27:11,  5.56it/s, lr=0.000741, step_loss=0.011407/27/2023 18:34:58 - INFO - __main__ - train loss is 23.949478494934738\n",
      "Steps:  40%|▍| 5939/15000 [50:08<27:09,  5.56it/s, lr=0.000741, step_loss=0.269]07/27/2023 18:34:58 - INFO - __main__ - train loss is 24.02793266158551\n",
      "Steps:  40%|▍| 5940/15000 [50:09<27:08,  5.56it/s, lr=0.000741, step_loss=0.078507/27/2023 18:34:58 - INFO - __main__ - train loss is 24.167111012153327\n",
      "Steps:  40%|▍| 5941/15000 [50:09<27:08,  5.56it/s, lr=0.000741, step_loss=0.139]07/27/2023 18:34:59 - INFO - __main__ - train loss is 24.168224298977293\n",
      "Steps:  40%|▍| 5942/15000 [50:09<27:07,  5.57it/s, lr=0.000741, step_loss=0.001107/27/2023 18:34:59 - INFO - __main__ - train loss is 24.738225066685118\n",
      "Steps:  40%|▊ | 5943/15000 [50:09<27:06,  5.57it/s, lr=0.000741, step_loss=0.57]07/27/2023 18:34:59 - INFO - __main__ - train loss is 24.744851686642505\n",
      "Steps:  40%|▍| 5944/15000 [50:09<27:05,  5.57it/s, lr=0.000741, step_loss=0.006607/27/2023 18:34:59 - INFO - __main__ - train loss is 24.750016747158952\n",
      "Steps:  40%|▍| 5945/15000 [50:09<27:04,  5.57it/s, lr=0.000741, step_loss=0.005107/27/2023 18:34:59 - INFO - __main__ - train loss is 24.75150663102977\n",
      "Steps:  40%|▍| 5946/15000 [50:10<27:04,  5.57it/s, lr=0.000742, step_loss=0.001407/27/2023 18:35:00 - INFO - __main__ - train loss is 24.847981084836647\n",
      "Steps:  40%|▍| 5947/15000 [50:10<27:04,  5.57it/s, lr=0.000742, step_loss=0.096507/27/2023 18:35:00 - INFO - __main__ - train loss is 25.060709793819115\n",
      "Steps:  40%|▍| 5948/15000 [50:10<27:04,  5.57it/s, lr=0.000742, step_loss=0.213]07/27/2023 18:35:00 - INFO - __main__ - train loss is 25.112107553286478\n",
      "Steps:  40%|▍| 5949/15000 [50:10<27:04,  5.57it/s, lr=0.000742, step_loss=0.051407/27/2023 18:35:00 - INFO - __main__ - train loss is 25.151506409747526\n",
      "Steps:  40%|▍| 5950/15000 [50:10<27:04,  5.57it/s, lr=0.000742, step_loss=0.039407/27/2023 18:35:00 - INFO - __main__ - train loss is 25.15319418848958\n",
      "Steps:  40%|▍| 5951/15000 [50:11<27:04,  5.57it/s, lr=0.000742, step_loss=0.001607/27/2023 18:35:00 - INFO - __main__ - train loss is 25.158124491455965\n",
      "Steps:  40%|▍| 5952/15000 [50:11<27:03,  5.57it/s, lr=0.000742, step_loss=0.004907/27/2023 18:35:01 - INFO - __main__ - train loss is 25.60577435779851\n",
      "Steps:  40%|▍| 5953/15000 [50:11<27:04,  5.57it/s, lr=0.000742, step_loss=0.448]07/27/2023 18:35:01 - INFO - __main__ - train loss is 25.879712805035524\n",
      "Steps:  40%|▍| 5954/15000 [50:11<27:04,  5.57it/s, lr=0.000743, step_loss=0.274]07/27/2023 18:35:01 - INFO - __main__ - train loss is 26.065931200864725\n",
      "Steps:  40%|▍| 5955/15000 [50:11<27:04,  5.57it/s, lr=0.000743, step_loss=0.186]07/27/2023 18:35:01 - INFO - __main__ - train loss is 26.075360221671872\n",
      "Steps:  40%|▍| 5956/15000 [50:11<27:04,  5.57it/s, lr=0.000743, step_loss=0.009407/27/2023 18:35:01 - INFO - __main__ - train loss is 26.371393484878354\n",
      "Steps:  40%|▍| 5957/15000 [50:12<27:04,  5.57it/s, lr=0.000743, step_loss=0.296]07/27/2023 18:35:02 - INFO - __main__ - train loss is 26.66757909755688\n",
      "Steps:  40%|▍| 5958/15000 [50:12<27:06,  5.56it/s, lr=0.000743, step_loss=0.296]07/27/2023 18:35:02 - INFO - __main__ - train loss is 26.669236546964385\n",
      "Steps:  40%|▍| 5959/15000 [50:12<27:09,  5.55it/s, lr=0.000743, step_loss=0.001607/27/2023 18:35:02 - INFO - __main__ - train loss is 26.67101910430938\n",
      "Steps:  40%|▍| 5960/15000 [50:12<27:11,  5.54it/s, lr=0.000743, step_loss=0.001707/27/2023 18:35:02 - INFO - __main__ - train loss is 27.217590239830315\n",
      "Steps:  40%|▍| 5961/15000 [50:12<27:08,  5.55it/s, lr=0.000743, step_loss=0.547]07/27/2023 18:35:02 - INFO - __main__ - train loss is 27.274351716972888\n",
      "Steps:  40%|▍| 5962/15000 [50:13<27:11,  5.54it/s, lr=0.000744, step_loss=0.056807/27/2023 18:35:02 - INFO - __main__ - train loss is 27.322292105294764\n",
      "Steps:  40%|▍| 5963/15000 [50:13<27:10,  5.54it/s, lr=0.000744, step_loss=0.047907/27/2023 18:35:03 - INFO - __main__ - train loss is 27.645539508201182\n",
      "Steps:  40%|▍| 5964/15000 [50:13<27:07,  5.55it/s, lr=0.000744, step_loss=0.323]07/27/2023 18:35:03 - INFO - __main__ - train loss is 28.046811149455607\n",
      "Steps:  40%|▍| 5965/15000 [50:13<27:05,  5.56it/s, lr=0.000744, step_loss=0.401]07/27/2023 18:35:03 - INFO - __main__ - train loss is 28.270862446166575\n",
      "Steps:  40%|▍| 5966/15000 [50:13<27:04,  5.56it/s, lr=0.000744, step_loss=0.224]07/27/2023 18:35:03 - INFO - __main__ - train loss is 28.47758345399052\n",
      "Steps:  40%|▍| 5967/15000 [50:13<27:02,  5.57it/s, lr=0.000744, step_loss=0.207]07/27/2023 18:35:03 - INFO - __main__ - train loss is 28.660087899304926\n",
      "Steps:  40%|▍| 5968/15000 [50:14<27:01,  5.57it/s, lr=0.000744, step_loss=0.183]07/27/2023 18:35:03 - INFO - __main__ - train loss is 28.747175657190382\n",
      "Steps:  40%|▍| 5969/15000 [50:14<27:01,  5.57it/s, lr=0.000744, step_loss=0.087107/27/2023 18:35:04 - INFO - __main__ - train loss is 28.785998814739287\n",
      "Steps:  40%|▍| 5970/15000 [50:14<27:01,  5.57it/s, lr=0.000745, step_loss=0.038807/27/2023 18:35:04 - INFO - __main__ - train loss is 28.8484194772318\n",
      "Steps:  40%|▍| 5971/15000 [50:14<27:02,  5.56it/s, lr=0.000745, step_loss=0.062407/27/2023 18:35:04 - INFO - __main__ - train loss is 29.08437163103372\n",
      "Steps:  40%|▍| 5972/15000 [50:14<27:01,  5.57it/s, lr=0.000745, step_loss=0.236]07/27/2023 18:35:04 - INFO - __main__ - train loss is 29.67512292135507\n",
      "Steps:  40%|▍| 5973/15000 [50:15<27:02,  5.57it/s, lr=0.000745, step_loss=0.591]07/27/2023 18:35:04 - INFO - __main__ - train loss is 29.97074002493173\n",
      "Steps:  40%|▍| 5974/15000 [50:15<27:00,  5.57it/s, lr=0.000745, step_loss=0.296]07/27/2023 18:35:05 - INFO - __main__ - train loss is 30.486255769617856\n",
      "Steps:  40%|▍| 5975/15000 [50:15<27:00,  5.57it/s, lr=0.000745, step_loss=0.516]07/27/2023 18:35:05 - INFO - __main__ - train loss is 30.508632575161755\n",
      "Steps:  40%|▍| 5976/15000 [50:15<27:00,  5.57it/s, lr=0.000745, step_loss=0.022407/27/2023 18:35:05 - INFO - __main__ - train loss is 30.968643550761044\n",
      "Steps:  40%|▊ | 5977/15000 [50:15<26:59,  5.57it/s, lr=0.000745, step_loss=0.46]07/27/2023 18:35:05 - INFO - __main__ - train loss is 31.190507625229657\n",
      "Steps:  40%|▍| 5978/15000 [50:15<27:00,  5.57it/s, lr=0.000746, step_loss=0.222]07/27/2023 18:35:05 - INFO - __main__ - train loss is 31.250806977041066\n",
      "Steps:  40%|▍| 5979/15000 [50:16<27:00,  5.57it/s, lr=0.000746, step_loss=0.060307/27/2023 18:35:05 - INFO - __main__ - train loss is 31.305313897319138\n",
      "Steps:  40%|▍| 5980/15000 [50:16<27:01,  5.56it/s, lr=0.000746, step_loss=0.054507/27/2023 18:35:06 - INFO - __main__ - train loss is 31.329279479570687\n",
      "Steps:  40%|▍| 5981/15000 [50:16<27:00,  5.56it/s, lr=0.000746, step_loss=0.024]07/27/2023 18:35:06 - INFO - __main__ - train loss is 31.356714584864676\n",
      "Steps:  40%|▍| 5982/15000 [50:16<27:00,  5.56it/s, lr=0.000746, step_loss=0.027407/27/2023 18:35:06 - INFO - __main__ - train loss is 31.546701946295798\n",
      "Steps:  40%|▊ | 5983/15000 [50:16<27:14,  5.52it/s, lr=0.000746, step_loss=0.19]07/27/2023 18:35:06 - INFO - __main__ - train loss is 31.79761711601168\n",
      "Steps:  40%|▍| 5984/15000 [50:17<27:09,  5.53it/s, lr=0.000746, step_loss=0.251]07/27/2023 18:35:06 - INFO - __main__ - train loss is 32.058844425715506\n",
      "Steps:  40%|▍| 5985/15000 [50:17<27:07,  5.54it/s, lr=0.000746, step_loss=0.261]07/27/2023 18:35:07 - INFO - __main__ - train loss is 32.08176207076758\n",
      "Steps:  40%|▍| 5986/15000 [50:17<27:04,  5.55it/s, lr=0.000747, step_loss=0.022907/27/2023 18:35:07 - INFO - __main__ - train loss is 32.423462743870914\n",
      "Steps:  40%|▍| 5987/15000 [50:17<27:02,  5.55it/s, lr=0.000747, step_loss=0.342]07/27/2023 18:35:07 - INFO - __main__ - train loss is 32.66768818628043\n",
      "Steps:  40%|▍| 5988/15000 [50:17<27:00,  5.56it/s, lr=0.000747, step_loss=0.244]07/27/2023 18:35:07 - INFO - __main__ - train loss is 32.672343232668936\n",
      "Steps:  40%|▍| 5989/15000 [50:17<27:00,  5.56it/s, lr=0.000747, step_loss=0.004607/27/2023 18:35:07 - INFO - __main__ - train loss is 32.84363667014986\n",
      "Steps:  40%|▍| 5990/15000 [50:18<26:59,  5.56it/s, lr=0.000747, step_loss=0.171]07/27/2023 18:35:07 - INFO - __main__ - train loss is 32.85065138246864\n",
      "Steps:  40%|▍| 5991/15000 [50:18<26:58,  5.57it/s, lr=0.000747, step_loss=0.007007/27/2023 18:35:08 - INFO - __main__ - train loss is 32.85273082507774\n",
      "Steps:  40%|▍| 5992/15000 [50:18<26:58,  5.57it/s, lr=0.000747, step_loss=0.002007/27/2023 18:35:08 - INFO - __main__ - train loss is 32.8858338217251\n",
      "Steps:  40%|▍| 5993/15000 [50:18<26:57,  5.57it/s, lr=0.000747, step_loss=0.033107/27/2023 18:35:08 - INFO - __main__ - train loss is 32.89836217043921\n",
      "Steps:  40%|▍| 5994/15000 [50:18<26:57,  5.57it/s, lr=0.000748, step_loss=0.012507/27/2023 18:35:08 - INFO - __main__ - train loss is 32.904400516767055\n",
      "Steps:  40%|▍| 5995/15000 [50:18<26:57,  5.57it/s, lr=0.000748, step_loss=0.006007/27/2023 18:35:08 - INFO - __main__ - train loss is 32.910475933458656\n",
      "Steps:  40%|▍| 5996/15000 [50:19<26:56,  5.57it/s, lr=0.000748, step_loss=0.006007/27/2023 18:35:09 - INFO - __main__ - train loss is 33.17199485888705\n",
      "Steps:  40%|▍| 5997/15000 [50:19<26:56,  5.57it/s, lr=0.000748, step_loss=0.262]07/27/2023 18:35:09 - INFO - __main__ - train loss is 33.34999822964892\n",
      "Steps:  40%|▍| 5998/15000 [50:19<26:55,  5.57it/s, lr=0.000748, step_loss=0.178]07/27/2023 18:35:09 - INFO - __main__ - train loss is 33.35175585246179\n",
      "Steps:  40%|▍| 5999/15000 [50:19<26:56,  5.57it/s, lr=0.000748, step_loss=0.001707/27/2023 18:35:09 - INFO - __main__ - train loss is 33.35457341710571\n",
      "Steps:  40%|▍| 6000/15000 [50:19<26:56,  5.57it/s, lr=0.000748, step_loss=0.001707/27/2023 18:35:09 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-6000\n",
      "07/27/2023 18:35:09 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:35:09,657] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:35:09,662] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-6000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:35:09,662] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-6000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:35:09,668] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-6000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:35:09,668] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-6000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:35:09,675] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-6000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:35:09,675] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-6000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:35:09,675] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:35:09 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-6000/pytorch_model\n",
      "07/27/2023 18:35:09 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-6000/scheduler.bin\n",
      "07/27/2023 18:35:09 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-6000/random_states_0.pkl\n",
      "07/27/2023 18:35:09 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-6000\n",
      "Steps:  40%|▍| 6000/15000 [50:19<26:56,  5.57it/s, lr=0.000748, step_loss=0.002807/27/2023 18:35:09 - INFO - __main__ - train loss is 33.714263725676574\n",
      "Steps:  40%|▊ | 6001/15000 [50:20<28:05,  5.34it/s, lr=0.000748, step_loss=0.36]07/27/2023 18:35:09 - INFO - __main__ - train loss is 33.765391859808005\n",
      "Steps:  40%|▍| 6002/15000 [50:20<28:06,  5.33it/s, lr=0.000749, step_loss=0.051107/27/2023 18:35:10 - INFO - __main__ - train loss is 34.1045887802029\n",
      "Steps:  40%|▍| 6003/15000 [50:20<27:51,  5.38it/s, lr=0.000749, step_loss=0.339]07/27/2023 18:35:10 - INFO - __main__ - train loss is 34.64541426638607\n",
      "Steps:  40%|▍| 6004/15000 [50:20<27:50,  5.38it/s, lr=0.000749, step_loss=0.541]07/27/2023 18:35:10 - INFO - __main__ - train loss is 34.66978499630932\n",
      "Steps:  40%|▍| 6005/15000 [50:20<27:39,  5.42it/s, lr=0.000749, step_loss=0.024407/27/2023 18:35:10 - INFO - __main__ - train loss is 34.68932366708759\n",
      "Steps:  40%|▍| 6006/15000 [50:21<27:27,  5.46it/s, lr=0.000749, step_loss=0.019507/27/2023 18:35:10 - INFO - __main__ - train loss is 35.16502324084286\n",
      "Steps:  40%|▍| 6007/15000 [50:21<27:18,  5.49it/s, lr=0.000749, step_loss=0.476]07/27/2023 18:35:11 - INFO - __main__ - train loss is 35.16965104325209\n",
      "Steps:  40%|▍| 6008/15000 [50:21<27:12,  5.51it/s, lr=0.000749, step_loss=0.004607/27/2023 18:35:11 - INFO - __main__ - train loss is 35.20462866930757\n",
      "Steps:  40%|▍| 6009/15000 [50:21<27:07,  5.53it/s, lr=0.000749, step_loss=0.035]07/27/2023 18:35:11 - INFO - __main__ - train loss is 35.207012464874424\n",
      "Steps:  40%|▍| 6010/15000 [50:21<27:13,  5.50it/s, lr=0.00075, step_loss=0.0023807/27/2023 18:35:11 - INFO - __main__ - train loss is 35.443633412593044\n",
      "Steps:  40%|▊ | 6011/15000 [50:21<27:06,  5.53it/s, lr=0.00075, step_loss=0.237]07/27/2023 18:35:11 - INFO - __main__ - train loss is 35.454390786238946\n",
      "Steps:  40%|▍| 6012/15000 [50:22<27:01,  5.54it/s, lr=0.00075, step_loss=0.0108]07/27/2023 18:35:11 - INFO - __main__ - train loss is 35.779120288440026\n",
      "Steps:  40%|▊ | 6013/15000 [50:22<26:59,  5.55it/s, lr=0.00075, step_loss=0.325]07/27/2023 18:35:12 - INFO - __main__ - train loss is 35.93011421675328\n",
      "Steps:  40%|▊ | 6014/15000 [50:22<26:57,  5.56it/s, lr=0.00075, step_loss=0.151]07/27/2023 18:35:12 - INFO - __main__ - train loss is 35.9410528257722\n",
      "Steps:  40%|▍| 6015/15000 [50:22<27:06,  5.52it/s, lr=0.00075, step_loss=0.0109]07/27/2023 18:35:12 - INFO - __main__ - train loss is 35.94240649335552\n",
      "Steps:  40%|▍| 6016/15000 [50:22<27:01,  5.54it/s, lr=0.00075, step_loss=0.0013507/27/2023 18:35:12 - INFO - __main__ - train loss is 35.95416864857543\n",
      "Steps:  40%|▍| 6017/15000 [50:22<26:58,  5.55it/s, lr=0.00075, step_loss=0.0118]07/27/2023 18:35:12 - INFO - __main__ - train loss is 35.97447108954657\n",
      "Steps:  40%|▍| 6018/15000 [50:23<26:55,  5.56it/s, lr=0.00075, step_loss=0.0203]07/27/2023 18:35:13 - INFO - __main__ - train loss is 35.99114258878399\n",
      "Steps:  40%|▍| 6019/15000 [50:23<26:54,  5.56it/s, lr=0.000751, step_loss=0.016707/27/2023 18:35:13 - INFO - __main__ - train loss is 36.0638365104096\n",
      "Steps:  40%|▍| 6020/15000 [50:23<26:53,  5.57it/s, lr=0.000751, step_loss=0.072707/27/2023 18:35:13 - INFO - __main__ - train loss is 36.286220575799234\n",
      "Steps:  40%|▍| 6021/15000 [50:23<26:53,  5.57it/s, lr=0.000751, step_loss=0.222]07/27/2023 18:35:13 - INFO - __main__ - train loss is 36.289942494709976\n",
      "Steps:  40%|▍| 6022/15000 [50:23<26:52,  5.57it/s, lr=0.000751, step_loss=0.003707/27/2023 18:35:13 - INFO - __main__ - train loss is 36.29342291515786\n",
      "Steps:  40%|▍| 6023/15000 [50:24<26:51,  5.57it/s, lr=0.000751, step_loss=0.003407/27/2023 18:35:13 - INFO - __main__ - train loss is 36.305668573011644\n",
      "Steps:  40%|▍| 6024/15000 [50:24<26:52,  5.57it/s, lr=0.000751, step_loss=0.012207/27/2023 18:35:14 - INFO - __main__ - train loss is 36.31770153355319\n",
      "Steps:  40%|▍| 6025/15000 [50:24<26:51,  5.57it/s, lr=0.000751, step_loss=0.012]07/27/2023 18:35:14 - INFO - __main__ - train loss is 36.3668369614752\n",
      "Steps:  40%|▍| 6026/15000 [50:24<26:51,  5.57it/s, lr=0.000751, step_loss=0.049107/27/2023 18:35:14 - INFO - __main__ - train loss is 36.533251550165005\n",
      "Steps:  40%|▍| 6027/15000 [50:24<26:50,  5.57it/s, lr=0.000752, step_loss=0.166]07/27/2023 18:35:14 - INFO - __main__ - train loss is 36.696743395295925\n",
      "Steps:  40%|▍| 6028/15000 [50:24<26:52,  5.56it/s, lr=0.000752, step_loss=0.163]07/27/2023 18:35:14 - INFO - __main__ - train loss is 36.71429513033945\n",
      "Steps:  40%|▍| 6029/15000 [50:25<26:53,  5.56it/s, lr=0.000752, step_loss=0.017607/27/2023 18:35:15 - INFO - __main__ - train loss is 36.77580811094958\n",
      "Steps:  40%|▍| 6030/15000 [50:25<26:51,  5.56it/s, lr=0.000752, step_loss=0.061507/27/2023 18:35:15 - INFO - __main__ - train loss is 37.247256770846434\n",
      "Steps:  40%|▍| 6031/15000 [50:25<26:52,  5.56it/s, lr=0.000752, step_loss=0.471]07/27/2023 18:35:15 - INFO - __main__ - train loss is 37.282301440951414\n",
      "Steps:  40%|▍| 6032/15000 [50:25<26:52,  5.56it/s, lr=0.000752, step_loss=0.035]07/27/2023 18:35:15 - INFO - __main__ - train loss is 37.43522162747104\n",
      "Steps:  40%|▍| 6033/15000 [50:25<26:53,  5.56it/s, lr=0.000752, step_loss=0.153]07/27/2023 18:35:15 - INFO - __main__ - train loss is 37.44258728821296\n",
      "Steps:  40%|▍| 6034/15000 [50:26<26:53,  5.56it/s, lr=0.000752, step_loss=0.007307/27/2023 18:35:15 - INFO - __main__ - train loss is 37.495316350949\n",
      "Steps:  40%|▍| 6035/15000 [50:26<26:52,  5.56it/s, lr=0.000753, step_loss=0.052707/27/2023 18:35:16 - INFO - __main__ - train loss is 37.85753642965574\n",
      "Steps:  40%|▍| 6036/15000 [50:26<26:52,  5.56it/s, lr=0.000753, step_loss=0.362]07/27/2023 18:35:16 - INFO - __main__ - train loss is 38.08211515296716\n",
      "Steps:  40%|▍| 6037/15000 [50:26<26:52,  5.56it/s, lr=0.000753, step_loss=0.225]07/27/2023 18:35:16 - INFO - __main__ - train loss is 38.13833936129231\n",
      "Steps:  40%|▍| 6038/15000 [50:26<26:51,  5.56it/s, lr=0.000753, step_loss=0.056207/27/2023 18:35:16 - INFO - __main__ - train loss is 38.2336669472279\n",
      "Steps:  40%|▍| 6039/15000 [50:26<26:50,  5.56it/s, lr=0.000753, step_loss=0.095307/27/2023 18:35:16 - INFO - __main__ - train loss is 38.486051460844465\n",
      "Steps:  40%|▍| 6040/15000 [50:27<27:03,  5.52it/s, lr=0.000753, step_loss=0.252]07/27/2023 18:35:16 - INFO - __main__ - train loss is 38.513388598454185\n",
      "Steps:  40%|▍| 6041/15000 [50:27<26:59,  5.53it/s, lr=0.000753, step_loss=0.027307/27/2023 18:35:17 - INFO - __main__ - train loss is 38.52111231733579\n",
      "Steps:  40%|▍| 6042/15000 [50:27<27:11,  5.49it/s, lr=0.000753, step_loss=0.007707/27/2023 18:35:17 - INFO - __main__ - train loss is 38.903627926600166\n",
      "Steps:  40%|▍| 6043/15000 [50:27<27:19,  5.46it/s, lr=0.000754, step_loss=0.383]07/27/2023 18:35:17 - INFO - __main__ - train loss is 38.9258294646861\n",
      "Steps:  40%|▍| 6044/15000 [50:27<27:23,  5.45it/s, lr=0.000754, step_loss=0.022207/27/2023 18:35:17 - INFO - __main__ - train loss is 38.96577602077741\n",
      "Steps:  40%|▍| 6045/15000 [50:28<27:09,  5.49it/s, lr=0.000754, step_loss=0.039907/27/2023 18:35:17 - INFO - __main__ - train loss is 39.15020872105379\n",
      "Steps:  40%|▍| 6046/15000 [50:28<27:01,  5.52it/s, lr=0.000754, step_loss=0.184]07/27/2023 18:35:18 - INFO - __main__ - train loss is 39.50420690525789\n",
      "Steps:  40%|▍| 6047/15000 [50:28<26:55,  5.54it/s, lr=0.000754, step_loss=0.354]07/27/2023 18:35:18 - INFO - __main__ - train loss is 39.77537129272241\n",
      "Steps:  40%|▍| 6048/15000 [50:28<26:51,  5.56it/s, lr=0.000754, step_loss=0.271]07/27/2023 18:35:18 - INFO - __main__ - train loss is 39.89128960866947\n",
      "Steps:  40%|▍| 6049/15000 [50:28<26:47,  5.57it/s, lr=0.000754, step_loss=0.116]07/27/2023 18:35:18 - INFO - __main__ - train loss is 39.8946694113547\n",
      "Steps:  40%|▍| 6050/15000 [50:28<26:51,  5.55it/s, lr=0.000754, step_loss=0.003307/27/2023 18:35:18 - INFO - __main__ - train loss is 39.9334817804629\n",
      "Steps:  40%|▍| 6051/15000 [50:29<26:47,  5.57it/s, lr=0.000755, step_loss=0.038807/27/2023 18:35:18 - INFO - __main__ - train loss is 40.024064136319794\n",
      "Steps:  40%|▍| 6052/15000 [50:29<26:44,  5.58it/s, lr=0.000755, step_loss=0.090607/27/2023 18:35:19 - INFO - __main__ - train loss is 40.03563809546176\n",
      "Steps:  40%|▍| 6053/15000 [50:29<26:43,  5.58it/s, lr=0.000755, step_loss=0.011607/27/2023 18:35:19 - INFO - __main__ - train loss is 40.09705337288324\n",
      "Steps:  40%|▍| 6054/15000 [50:29<26:42,  5.58it/s, lr=0.000755, step_loss=0.061407/27/2023 18:35:19 - INFO - __main__ - train loss is 40.1807649374241\n",
      "Steps:  40%|▍| 6055/15000 [50:29<26:40,  5.59it/s, lr=0.000755, step_loss=0.083707/27/2023 18:35:19 - INFO - __main__ - train loss is 40.539652460836805\n",
      "Steps:  40%|▍| 6056/15000 [50:30<26:39,  5.59it/s, lr=0.000755, step_loss=0.359]07/27/2023 18:35:19 - INFO - __main__ - train loss is 40.579511800431646\n",
      "Steps:  40%|▍| 6057/15000 [50:30<26:39,  5.59it/s, lr=0.000755, step_loss=0.039907/27/2023 18:35:20 - INFO - __main__ - train loss is 40.77388636174146\n",
      "Steps:  40%|▍| 6058/15000 [50:30<26:41,  5.58it/s, lr=0.000755, step_loss=0.194]07/27/2023 18:35:20 - INFO - __main__ - train loss is 40.77644598914776\n",
      "Steps:  40%|▍| 6059/15000 [50:30<26:40,  5.59it/s, lr=0.000756, step_loss=0.002507/27/2023 18:35:20 - INFO - __main__ - train loss is 40.78220709937159\n",
      "Steps:  40%|▍| 6060/15000 [50:31<40:00,  3.72it/s, lr=0.000756, step_loss=0.005707/27/2023 18:35:21 - INFO - __main__ - Per validation step average loss is 0.0025439439341425896\n",
      "07/27/2023 18:35:21 - INFO - __main__ - Cumulative validation average loss is 0.0025439439341425896\n",
      "07/27/2023 18:35:22 - INFO - __main__ - Per validation step average loss is 0.024447541683912277\n",
      "07/27/2023 18:35:22 - INFO - __main__ - Cumulative validation average loss is 0.026991485618054867\n",
      "07/27/2023 18:35:22 - INFO - __main__ - Per validation step average loss is 0.14829933643341064\n",
      "07/27/2023 18:35:22 - INFO - __main__ - Cumulative validation average loss is 0.1752908220514655\n",
      "07/27/2023 18:35:22 - INFO - __main__ - Per validation step average loss is 0.007569015026092529\n",
      "07/27/2023 18:35:22 - INFO - __main__ - Cumulative validation average loss is 0.18285983707755804\n",
      "07/27/2023 18:35:23 - INFO - __main__ - Per validation step average loss is 0.0012893809471279383\n",
      "07/27/2023 18:35:23 - INFO - __main__ - Cumulative validation average loss is 0.18414921802468598\n",
      "07/27/2023 18:35:23 - INFO - __main__ - Per validation step average loss is 0.19804948568344116\n",
      "07/27/2023 18:35:23 - INFO - __main__ - Cumulative validation average loss is 0.38219870370812714\n",
      "07/27/2023 18:35:24 - INFO - __main__ - Per validation step average loss is 0.25917699933052063\n",
      "07/27/2023 18:35:24 - INFO - __main__ - Cumulative validation average loss is 0.6413757030386478\n",
      "07/27/2023 18:35:24 - INFO - __main__ - Per validation step average loss is 0.31497788429260254\n",
      "07/27/2023 18:35:24 - INFO - __main__ - Cumulative validation average loss is 0.9563535873312503\n",
      "07/27/2023 18:35:25 - INFO - __main__ - Per validation step average loss is 0.05232995003461838\n",
      "07/27/2023 18:35:25 - INFO - __main__ - Cumulative validation average loss is 1.0086835373658687\n",
      "07/27/2023 18:35:25 - INFO - __main__ - Per validation step average loss is 0.11494262516498566\n",
      "07/27/2023 18:35:25 - INFO - __main__ - Cumulative validation average loss is 1.1236261625308543\n",
      "07/27/2023 18:35:25 - INFO - __main__ - Per validation step average loss is 0.11253353953361511\n",
      "07/27/2023 18:35:25 - INFO - __main__ - Cumulative validation average loss is 1.2361597020644695\n",
      "07/27/2023 18:35:26 - INFO - __main__ - Per validation step average loss is 0.017056308686733246\n",
      "07/27/2023 18:35:26 - INFO - __main__ - Cumulative validation average loss is 1.2532160107512027\n",
      "07/27/2023 18:35:26 - INFO - __main__ - Per validation step average loss is 0.1012079268693924\n",
      "07/27/2023 18:35:26 - INFO - __main__ - Cumulative validation average loss is 1.354423937620595\n",
      "07/27/2023 18:35:27 - INFO - __main__ - Per validation step average loss is 0.010512346401810646\n",
      "07/27/2023 18:35:27 - INFO - __main__ - Cumulative validation average loss is 1.3649362840224057\n",
      "07/27/2023 18:35:27 - INFO - __main__ - Per validation step average loss is 0.8415752649307251\n",
      "07/27/2023 18:35:27 - INFO - __main__ - Cumulative validation average loss is 2.206511548953131\n",
      "07/27/2023 18:35:27 - INFO - __main__ - Per validation step average loss is 0.0075207240879535675\n",
      "07/27/2023 18:35:27 - INFO - __main__ - Cumulative validation average loss is 2.2140322730410844\n",
      "07/27/2023 18:35:28 - INFO - __main__ - Per validation step average loss is 0.3547046184539795\n",
      "07/27/2023 18:35:28 - INFO - __main__ - Cumulative validation average loss is 2.568736891495064\n",
      "07/27/2023 18:35:28 - INFO - __main__ - Per validation step average loss is 0.03830084204673767\n",
      "07/27/2023 18:35:28 - INFO - __main__ - Cumulative validation average loss is 2.6070377335418016\n",
      "07/27/2023 18:35:29 - INFO - __main__ - Per validation step average loss is 0.1372859925031662\n",
      "07/27/2023 18:35:29 - INFO - __main__ - Cumulative validation average loss is 2.7443237260449678\n",
      "07/27/2023 18:35:29 - INFO - __main__ - Per validation step average loss is 0.5490195751190186\n",
      "07/27/2023 18:35:29 - INFO - __main__ - Cumulative validation average loss is 3.2933433011639863\n",
      "07/27/2023 18:35:29 - INFO - __main__ - Per validation step average loss is 0.002115256618708372\n",
      "07/27/2023 18:35:29 - INFO - __main__ - Cumulative validation average loss is 3.2954585577826947\n",
      "07/27/2023 18:35:30 - INFO - __main__ - Per validation step average loss is 0.1063627153635025\n",
      "07/27/2023 18:35:30 - INFO - __main__ - Cumulative validation average loss is 3.401821273146197\n",
      "07/27/2023 18:35:30 - INFO - __main__ - Per validation step average loss is 0.007730628363788128\n",
      "07/27/2023 18:35:30 - INFO - __main__ - Cumulative validation average loss is 3.4095519015099853\n",
      "07/27/2023 18:35:31 - INFO - __main__ - Per validation step average loss is 0.0016418574377894402\n",
      "07/27/2023 18:35:31 - INFO - __main__ - Cumulative validation average loss is 3.4111937589477748\n",
      "07/27/2023 18:35:31 - INFO - __main__ - Per validation step average loss is 0.004624614492058754\n",
      "07/27/2023 18:35:31 - INFO - __main__ - Cumulative validation average loss is 3.4158183734398335\n",
      "07/27/2023 18:35:32 - INFO - __main__ - Per validation step average loss is 0.004030538722872734\n",
      "07/27/2023 18:35:32 - INFO - __main__ - Cumulative validation average loss is 3.4198489121627063\n",
      "07/27/2023 18:35:32 - INFO - __main__ - Per validation step average loss is 0.008610968478024006\n",
      "07/27/2023 18:35:32 - INFO - __main__ - Cumulative validation average loss is 3.4284598806407303\n",
      "07/27/2023 18:35:32 - INFO - __main__ - Per validation step average loss is 0.01881132833659649\n",
      "07/27/2023 18:35:32 - INFO - __main__ - Cumulative validation average loss is 3.4472712089773268\n",
      "07/27/2023 18:35:33 - INFO - __main__ - Per validation step average loss is 0.5555830001831055\n",
      "07/27/2023 18:35:33 - INFO - __main__ - Cumulative validation average loss is 4.002854209160432\n",
      "07/27/2023 18:35:33 - INFO - __main__ - Per validation step average loss is 0.11905540525913239\n",
      "07/27/2023 18:35:33 - INFO - __main__ - Cumulative validation average loss is 4.121909614419565\n",
      "07/27/2023 18:35:34 - INFO - __main__ - Per validation step average loss is 0.3029988408088684\n",
      "07/27/2023 18:35:34 - INFO - __main__ - Cumulative validation average loss is 4.424908455228433\n",
      "07/27/2023 18:35:34 - INFO - __main__ - Per validation step average loss is 0.021351097151637077\n",
      "07/27/2023 18:35:34 - INFO - __main__ - Cumulative validation average loss is 4.44625955238007\n",
      "07/27/2023 18:35:34 - INFO - __main__ - Per validation step average loss is 0.48470771312713623\n",
      "07/27/2023 18:35:34 - INFO - __main__ - Cumulative validation average loss is 4.930967265507206\n",
      "07/27/2023 18:35:35 - INFO - __main__ - Per validation step average loss is 0.15640369057655334\n",
      "07/27/2023 18:35:35 - INFO - __main__ - Cumulative validation average loss is 5.08737095608376\n",
      "07/27/2023 18:35:35 - INFO - __main__ - Per validation step average loss is 0.0014335359446704388\n",
      "07/27/2023 18:35:35 - INFO - __main__ - Cumulative validation average loss is 5.08880449202843\n",
      "07/27/2023 18:35:36 - INFO - __main__ - Per validation step average loss is 0.026611775159835815\n",
      "07/27/2023 18:35:36 - INFO - __main__ - Cumulative validation average loss is 5.115416267188266\n",
      "07/27/2023 18:35:36 - INFO - __main__ - Per validation step average loss is 0.11588665097951889\n",
      "07/27/2023 18:35:36 - INFO - __main__ - Cumulative validation average loss is 5.231302918167785\n",
      "07/27/2023 18:35:36 - INFO - __main__ - Per validation step average loss is 0.6622173190116882\n",
      "07/27/2023 18:35:36 - INFO - __main__ - Cumulative validation average loss is 5.893520237179473\n",
      "07/27/2023 18:35:37 - INFO - __main__ - Per validation step average loss is 0.002730240346863866\n",
      "07/27/2023 18:35:37 - INFO - __main__ - Cumulative validation average loss is 5.896250477526337\n",
      "07/27/2023 18:35:37 - INFO - __main__ - Per validation step average loss is 0.17705978453159332\n",
      "07/27/2023 18:35:37 - INFO - __main__ - Cumulative validation average loss is 6.07331026205793\n",
      "07/27/2023 18:35:38 - INFO - __main__ - Per validation step average loss is 0.00335576175712049\n",
      "07/27/2023 18:35:38 - INFO - __main__ - Cumulative validation average loss is 6.076666023815051\n",
      "07/27/2023 18:35:38 - INFO - __main__ - Per validation step average loss is 0.041996173560619354\n",
      "07/27/2023 18:35:38 - INFO - __main__ - Cumulative validation average loss is 6.11866219737567\n",
      "07/27/2023 18:35:38 - INFO - __main__ - Per validation step average loss is 0.011820979416370392\n",
      "07/27/2023 18:35:38 - INFO - __main__ - Cumulative validation average loss is 6.1304831767920405\n",
      "07/27/2023 18:35:39 - INFO - __main__ - Per validation step average loss is 0.012425748631358147\n",
      "07/27/2023 18:35:39 - INFO - __main__ - Cumulative validation average loss is 6.142908925423399\n",
      "07/27/2023 18:35:39 - INFO - __main__ - Per validation step average loss is 0.0021164356730878353\n",
      "07/27/2023 18:35:39 - INFO - __main__ - Cumulative validation average loss is 6.1450253610964864\n",
      "07/27/2023 18:35:40 - INFO - __main__ - Per validation step average loss is 0.0013233774807304144\n",
      "07/27/2023 18:35:40 - INFO - __main__ - Cumulative validation average loss is 6.146348738577217\n",
      "07/27/2023 18:35:40 - INFO - __main__ - Per validation step average loss is 0.058719366788864136\n",
      "07/27/2023 18:35:40 - INFO - __main__ - Cumulative validation average loss is 6.205068105366081\n",
      "07/27/2023 18:35:41 - INFO - __main__ - Per validation step average loss is 0.01893434301018715\n",
      "07/27/2023 18:35:41 - INFO - __main__ - Cumulative validation average loss is 6.224002448376268\n",
      "07/27/2023 18:35:41 - INFO - __main__ - Per validation step average loss is 0.0020958944223821163\n",
      "07/27/2023 18:35:41 - INFO - __main__ - Cumulative validation average loss is 6.22609834279865\n",
      "07/27/2023 18:35:41 - INFO - __main__ - Per validation step average loss is 0.02599984221160412\n",
      "07/27/2023 18:35:41 - INFO - __main__ - Cumulative validation average loss is 6.252098185010254\n",
      "07/27/2023 18:35:42 - INFO - __main__ - Per validation step average loss is 0.24046413600444794\n",
      "07/27/2023 18:35:42 - INFO - __main__ - Cumulative validation average loss is 6.492562321014702\n",
      "07/27/2023 18:35:42 - INFO - __main__ - Per validation step average loss is 0.0030929269269108772\n",
      "07/27/2023 18:35:42 - INFO - __main__ - Cumulative validation average loss is 6.495655247941613\n",
      "07/27/2023 18:35:43 - INFO - __main__ - Per validation step average loss is 0.006457182578742504\n",
      "07/27/2023 18:35:43 - INFO - __main__ - Cumulative validation average loss is 6.502112430520356\n",
      "07/27/2023 18:35:43 - INFO - __main__ - Per validation step average loss is 0.0014693508855998516\n",
      "07/27/2023 18:35:43 - INFO - __main__ - Cumulative validation average loss is 6.5035817814059556\n",
      "07/27/2023 18:35:43 - INFO - __main__ - Per validation step average loss is 0.019361956045031548\n",
      "07/27/2023 18:35:43 - INFO - __main__ - Cumulative validation average loss is 6.522943737450987\n",
      "07/27/2023 18:35:44 - INFO - __main__ - Per validation step average loss is 0.40894436836242676\n",
      "07/27/2023 18:35:44 - INFO - __main__ - Cumulative validation average loss is 6.931888105813414\n",
      "07/27/2023 18:35:44 - INFO - __main__ - Per validation step average loss is 0.46390989422798157\n",
      "07/27/2023 18:35:44 - INFO - __main__ - Cumulative validation average loss is 7.395798000041395\n",
      "07/27/2023 18:35:45 - INFO - __main__ - Per validation step average loss is 0.2633575201034546\n",
      "07/27/2023 18:35:45 - INFO - __main__ - Cumulative validation average loss is 7.65915552014485\n",
      "07/27/2023 18:35:45 - INFO - __main__ - Per validation step average loss is 0.15654334425926208\n",
      "07/27/2023 18:35:45 - INFO - __main__ - Cumulative validation average loss is 7.815698864404112\n",
      "07/27/2023 18:35:45 - INFO - __main__ - Per validation step average loss is 0.03838727995753288\n",
      "07/27/2023 18:35:45 - INFO - __main__ - Cumulative validation average loss is 7.854086144361645\n",
      "07/27/2023 18:35:46 - INFO - __main__ - Per validation step average loss is 0.0017470794264227152\n",
      "07/27/2023 18:35:46 - INFO - __main__ - Cumulative validation average loss is 7.855833223788068\n",
      "07/27/2023 18:35:46 - INFO - __main__ - Per validation step average loss is 0.14444637298583984\n",
      "07/27/2023 18:35:46 - INFO - __main__ - Cumulative validation average loss is 8.000279596773908\n",
      "07/27/2023 18:35:47 - INFO - __main__ - Per validation step average loss is 0.011649258434772491\n",
      "07/27/2023 18:35:47 - INFO - __main__ - Cumulative validation average loss is 8.01192885520868\n",
      "07/27/2023 18:35:47 - INFO - __main__ - Per validation step average loss is 0.12978240847587585\n",
      "07/27/2023 18:35:47 - INFO - __main__ - Cumulative validation average loss is 8.141711263684556\n",
      "07/27/2023 18:35:48 - INFO - __main__ - Per validation step average loss is 0.01049074437469244\n",
      "07/27/2023 18:35:48 - INFO - __main__ - Cumulative validation average loss is 8.152202008059248\n",
      "07/27/2023 18:35:48 - INFO - __main__ - Per validation step average loss is 0.05412706732749939\n",
      "07/27/2023 18:35:48 - INFO - __main__ - Cumulative validation average loss is 8.206329075386748\n",
      "07/27/2023 18:35:48 - INFO - __main__ - Per validation step average loss is 0.23701174557209015\n",
      "07/27/2023 18:35:48 - INFO - __main__ - Cumulative validation average loss is 8.443340820958838\n",
      "07/27/2023 18:35:49 - INFO - __main__ - Per validation step average loss is 0.2299022376537323\n",
      "07/27/2023 18:35:49 - INFO - __main__ - Cumulative validation average loss is 8.67324305861257\n",
      "07/27/2023 18:35:49 - INFO - __main__ - Per validation step average loss is 0.13282456994056702\n",
      "07/27/2023 18:35:49 - INFO - __main__ - Cumulative validation average loss is 8.806067628553137\n",
      "07/27/2023 18:35:50 - INFO - __main__ - Per validation step average loss is 0.014464803971350193\n",
      "07/27/2023 18:35:50 - INFO - __main__ - Cumulative validation average loss is 8.820532432524487\n",
      "07/27/2023 18:35:50 - INFO - __main__ - Per validation step average loss is 0.15439945459365845\n",
      "07/27/2023 18:35:50 - INFO - __main__ - Cumulative validation average loss is 8.974931887118146\n",
      "07/27/2023 18:35:50 - INFO - __main__ - Per validation step average loss is 0.07296458631753922\n",
      "07/27/2023 18:35:50 - INFO - __main__ - Cumulative validation average loss is 9.047896473435685\n",
      "07/27/2023 18:35:51 - INFO - __main__ - Per validation step average loss is 0.23586967587471008\n",
      "07/27/2023 18:35:51 - INFO - __main__ - Cumulative validation average loss is 9.283766149310395\n",
      "07/27/2023 18:35:51 - INFO - __main__ - Per validation step average loss is 0.22413107752799988\n",
      "07/27/2023 18:35:51 - INFO - __main__ - Cumulative validation average loss is 9.507897226838395\n",
      "07/27/2023 18:35:52 - INFO - __main__ - Per validation step average loss is 0.08289344608783722\n",
      "07/27/2023 18:35:52 - INFO - __main__ - Cumulative validation average loss is 9.590790672926232\n",
      "07/27/2023 18:35:52 - INFO - __main__ - Per validation step average loss is 0.022834017872810364\n",
      "07/27/2023 18:35:52 - INFO - __main__ - Cumulative validation average loss is 9.613624690799043\n",
      "07/27/2023 18:35:52 - INFO - __main__ - Per validation step average loss is 0.11195983737707138\n",
      "07/27/2023 18:35:52 - INFO - __main__ - Cumulative validation average loss is 9.725584528176114\n",
      "07/27/2023 18:35:53 - INFO - __main__ - Per validation step average loss is 0.011607836000621319\n",
      "07/27/2023 18:35:53 - INFO - __main__ - Cumulative validation average loss is 9.737192364176735\n",
      "07/27/2023 18:35:54 - INFO - __main__ - Per validation step average loss is 0.1366206407546997\n",
      "07/27/2023 18:35:54 - INFO - __main__ - Cumulative validation average loss is 9.873813004931435\n",
      "07/27/2023 18:35:54 - INFO - __main__ - Average validation loss for Epoch 19 is 0.12498497474596754\n",
      "07/27/2023 18:35:54 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:36:50 - INFO - __main__ - Starting epoch 20\n",
      "07/27/2023 18:36:52 - INFO - __main__ - train loss is 0.0018682703375816345\n",
      "Steps:  40%|▍| 6061/15000 [52:02<68:29:44, 27.59s/it, lr=0.000756, step_loss=0.007/27/2023 18:36:52 - INFO - __main__ - train loss is 0.0184975303709507\n",
      "Steps:  40%|▍| 6062/15000 [52:02<48:19:00, 19.46s/it, lr=0.000756, step_loss=0.007/27/2023 18:36:53 - INFO - __main__ - train loss is 0.10145008936524391\n",
      "Steps:  40%|▍| 6063/15000 [52:03<34:10:55, 13.77s/it, lr=0.000756, step_loss=0.007/27/2023 18:36:53 - INFO - __main__ - train loss is 0.11313819885253906\n",
      "Steps:  40%|▍| 6064/15000 [52:03<24:18:04,  9.79s/it, lr=0.000756, step_loss=0.007/27/2023 18:36:54 - INFO - __main__ - train loss is 0.16542679071426392\n",
      "Steps:  40%|▍| 6065/15000 [52:04<17:22:56,  7.00s/it, lr=0.000756, step_loss=0.007/27/2023 18:36:54 - INFO - __main__ - train loss is 0.3933948129415512\n",
      "Steps:  40%|▍| 6066/15000 [52:04<12:32:37,  5.05s/it, lr=0.000757, step_loss=0.207/27/2023 18:36:55 - INFO - __main__ - train loss is 0.8042660802602768\n",
      "Steps:  40%|▍| 6067/15000 [52:05<9:09:03,  3.69s/it, lr=0.000757, step_loss=0.4107/27/2023 18:36:55 - INFO - __main__ - train loss is 0.9460960924625397\n",
      "Steps:  40%|▍| 6068/15000 [52:05<6:46:37,  2.73s/it, lr=0.000757, step_loss=0.1407/27/2023 18:36:56 - INFO - __main__ - train loss is 1.1098099052906036\n",
      "Steps:  40%|▍| 6069/15000 [52:06<5:07:03,  2.06s/it, lr=0.000757, step_loss=0.1607/27/2023 18:36:56 - INFO - __main__ - train loss is 1.331028401851654\n",
      "Steps:  40%|▍| 6070/15000 [52:06<3:57:20,  1.59s/it, lr=0.000757, step_loss=0.2207/27/2023 18:36:57 - INFO - __main__ - train loss is 1.3350428948178887\n",
      "Steps:  40%|▍| 6071/15000 [52:07<3:08:40,  1.27s/it, lr=0.000757, step_loss=0.0007/27/2023 18:36:57 - INFO - __main__ - train loss is 1.921203793026507\n",
      "Steps:  40%|▍| 6072/15000 [52:07<2:35:04,  1.04s/it, lr=0.000757, step_loss=0.5807/27/2023 18:36:58 - INFO - __main__ - train loss is 1.9247056576423347\n",
      "Steps:  40%|▍| 6073/15000 [52:08<2:10:43,  1.14it/s, lr=0.000757, step_loss=0.0007/27/2023 18:36:58 - INFO - __main__ - train loss is 1.9369511739350855\n",
      "Steps:  40%|▍| 6074/15000 [52:08<1:53:52,  1.31it/s, lr=0.000757, step_loss=0.0107/27/2023 18:36:59 - INFO - __main__ - train loss is 2.0218370095826685\n",
      "Steps:  40%|▍| 6075/15000 [52:09<1:42:13,  1.46it/s, lr=0.000758, step_loss=0.0807/27/2023 18:36:59 - INFO - __main__ - train loss is 2.0505455103702843\n",
      "Steps:  41%|▍| 6076/15000 [52:09<1:33:59,  1.58it/s, lr=0.000758, step_loss=0.0207/27/2023 18:37:00 - INFO - __main__ - train loss is 2.1006667097099125\n",
      "Steps:  41%|▍| 6077/15000 [52:10<1:28:11,  1.69it/s, lr=0.000758, step_loss=0.0507/27/2023 18:37:00 - INFO - __main__ - train loss is 2.204850703943521\n",
      "Steps:  41%|▍| 6078/15000 [52:10<1:23:56,  1.77it/s, lr=0.000758, step_loss=0.1007/27/2023 18:37:01 - INFO - __main__ - train loss is 2.2564613451249897\n",
      "Steps:  41%|▍| 6079/15000 [52:11<1:21:13,  1.83it/s, lr=0.000758, step_loss=0.0507/27/2023 18:37:01 - INFO - __main__ - train loss is 2.5807926882989705\n",
      "Steps:  41%|▍| 6080/15000 [52:11<1:19:29,  1.87it/s, lr=0.000758, step_loss=0.3207/27/2023 18:37:02 - INFO - __main__ - train loss is 2.6850292016752064\n",
      "Steps:  41%|▍| 6081/15000 [52:12<1:18:16,  1.90it/s, lr=0.000758, step_loss=0.1007/27/2023 18:37:02 - INFO - __main__ - train loss is 2.694820346776396\n",
      "Steps:  41%|▍| 6082/15000 [52:12<1:17:19,  1.92it/s, lr=0.000758, step_loss=0.0007/27/2023 18:37:03 - INFO - __main__ - train loss is 2.803237917367369\n",
      "Steps:  41%|▍| 6083/15000 [52:13<1:17:13,  1.92it/s, lr=0.000759, step_loss=0.1007/27/2023 18:37:03 - INFO - __main__ - train loss is 2.8453380675055087\n",
      "Steps:  41%|▍| 6084/15000 [52:13<1:16:35,  1.94it/s, lr=0.000759, step_loss=0.0407/27/2023 18:37:04 - INFO - __main__ - train loss is 2.8565644887275994\n",
      "Steps:  41%|▍| 6085/15000 [52:14<1:20:19,  1.85it/s, lr=0.000759, step_loss=0.0107/27/2023 18:37:04 - INFO - __main__ - train loss is 2.8582253768108785\n",
      "Steps:  41%|▍| 6086/15000 [52:15<1:21:26,  1.82it/s, lr=0.000759, step_loss=0.0007/27/2023 18:37:05 - INFO - __main__ - train loss is 2.9561023502610624\n",
      "Steps:  41%|▍| 6087/15000 [52:15<1:20:20,  1.85it/s, lr=0.000759, step_loss=0.0907/27/2023 18:37:05 - INFO - __main__ - train loss is 2.9631135584786534\n",
      "Steps:  41%|▍| 6088/15000 [52:16<1:19:30,  1.87it/s, lr=0.000759, step_loss=0.0007/27/2023 18:37:06 - INFO - __main__ - train loss is 3.0053929844871163\n",
      "Steps:  41%|▍| 6089/15000 [52:16<1:18:59,  1.88it/s, lr=0.000759, step_loss=0.0407/27/2023 18:37:06 - INFO - __main__ - train loss is 3.1146700838580728\n",
      "Steps:  41%|▍| 6090/15000 [52:17<1:18:25,  1.89it/s, lr=0.000759, step_loss=0.1007/27/2023 18:37:07 - INFO - __main__ - train loss is 3.21606005076319\n",
      "Steps:  41%|▍| 6091/15000 [52:17<1:17:58,  1.90it/s, lr=0.00076, step_loss=0.10107/27/2023 18:37:07 - INFO - __main__ - train loss is 3.2306269770488143\n",
      "Steps:  41%|▍| 6092/15000 [52:18<1:17:37,  1.91it/s, lr=0.00076, step_loss=0.01407/27/2023 18:37:08 - INFO - __main__ - train loss is 3.315939768217504\n",
      "Steps:  41%|▍| 6093/15000 [52:18<1:16:50,  1.93it/s, lr=0.00076, step_loss=0.08507/27/2023 18:37:08 - INFO - __main__ - train loss is 3.3493335088714957\n",
      "Steps:  41%|▍| 6094/15000 [52:19<1:16:17,  1.95it/s, lr=0.00076, step_loss=0.03307/27/2023 18:37:09 - INFO - __main__ - train loss is 3.3562158523127437\n",
      "Steps:  41%|▍| 6095/15000 [52:19<1:15:42,  1.96it/s, lr=0.00076, step_loss=0.00607/27/2023 18:37:09 - INFO - __main__ - train loss is 3.3720254758372903\n",
      "Steps:  41%|▍| 6096/15000 [52:20<1:15:21,  1.97it/s, lr=0.00076, step_loss=0.01507/27/2023 18:37:10 - INFO - __main__ - train loss is 3.493131042458117\n",
      "Steps:  41%|▍| 6097/15000 [52:20<1:15:10,  1.97it/s, lr=0.00076, step_loss=0.12107/27/2023 18:37:10 - INFO - __main__ - train loss is 3.4982961174100637\n",
      "Steps:  41%|▍| 6098/15000 [52:21<1:14:59,  1.98it/s, lr=0.00076, step_loss=0.00507/27/2023 18:37:11 - INFO - __main__ - train loss is 4.057963287457824\n",
      "Steps:  41%|▍| 6099/15000 [52:21<1:15:02,  1.98it/s, lr=0.000761, step_loss=0.5607/27/2023 18:37:11 - INFO - __main__ - train loss is 4.077301496639848\n",
      "Steps:  41%|▍| 6100/15000 [52:22<1:15:14,  1.97it/s, lr=0.000761, step_loss=0.0107/27/2023 18:37:12 - INFO - __main__ - train loss is 4.100314209237695\n",
      "Steps:  41%|▍| 6101/15000 [52:22<1:15:08,  1.97it/s, lr=0.000761, step_loss=0.0207/27/2023 18:37:12 - INFO - __main__ - train loss is 4.377549597993493\n",
      "Steps:  41%|▍| 6102/15000 [52:23<1:14:58,  1.98it/s, lr=0.000761, step_loss=0.2707/27/2023 18:37:13 - INFO - __main__ - train loss is 4.617784628644586\n",
      "Steps:  41%|▍| 6103/15000 [52:23<1:14:56,  1.98it/s, lr=0.000761, step_loss=0.2407/27/2023 18:37:13 - INFO - __main__ - train loss is 4.647703494876623\n",
      "Steps:  41%|▍| 6104/15000 [52:24<1:14:38,  1.99it/s, lr=0.000761, step_loss=0.0207/27/2023 18:37:14 - INFO - __main__ - train loss is 4.887775089591742\n",
      "Steps:  41%|▍| 6105/15000 [52:24<1:14:40,  1.99it/s, lr=0.000761, step_loss=0.2407/27/2023 18:37:14 - INFO - __main__ - train loss is 4.915515620261431\n",
      "Steps:  41%|▍| 6106/15000 [52:25<1:14:21,  1.99it/s, lr=0.000762, step_loss=0.0207/27/2023 18:37:15 - INFO - __main__ - train loss is 5.17152901366353\n",
      "Steps:  41%|▍| 6107/15000 [52:25<1:14:28,  1.99it/s, lr=0.000762, step_loss=0.2507/27/2023 18:37:15 - INFO - __main__ - train loss is 5.315861765295267\n",
      "Steps:  41%|▍| 6108/15000 [52:26<1:14:29,  1.99it/s, lr=0.000762, step_loss=0.1407/27/2023 18:37:16 - INFO - __main__ - train loss is 5.4005234725773335\n",
      "Steps:  41%|▍| 6109/15000 [52:26<1:14:21,  1.99it/s, lr=0.000762, step_loss=0.0807/27/2023 18:37:16 - INFO - __main__ - train loss is 5.450025375932455\n",
      "Steps:  41%|▍| 6110/15000 [52:27<1:14:09,  2.00it/s, lr=0.000762, step_loss=0.0407/27/2023 18:37:17 - INFO - __main__ - train loss is 5.530797924846411\n",
      "Steps:  41%|▍| 6111/15000 [52:27<1:14:17,  1.99it/s, lr=0.000762, step_loss=0.0807/27/2023 18:37:17 - INFO - __main__ - train loss is 5.53995896410197\n",
      "Steps:  41%|▍| 6112/15000 [52:28<1:14:36,  1.99it/s, lr=0.000762, step_loss=0.0007/27/2023 18:37:18 - INFO - __main__ - train loss is 5.789539407007396\n",
      "Steps:  41%|▍| 6113/15000 [52:28<1:15:08,  1.97it/s, lr=0.000762, step_loss=0.2507/27/2023 18:37:18 - INFO - __main__ - train loss is 5.830418146215379\n",
      "Steps:  41%|▍| 6114/15000 [52:29<1:15:00,  1.97it/s, lr=0.000762, step_loss=0.0407/27/2023 18:37:19 - INFO - __main__ - train loss is 5.862454089336097\n",
      "Steps:  41%|▍| 6115/15000 [52:29<1:14:59,  1.97it/s, lr=0.000763, step_loss=0.0307/27/2023 18:37:20 - INFO - __main__ - train loss is 5.9144770456478\n",
      "Steps:  41%|▍| 6116/15000 [52:30<1:15:37,  1.96it/s, lr=0.000763, step_loss=0.0507/27/2023 18:37:20 - INFO - __main__ - train loss is 5.950437176041305\n",
      "Steps:  41%|▍| 6117/15000 [52:30<1:15:14,  1.97it/s, lr=0.000763, step_loss=0.0307/27/2023 18:37:21 - INFO - __main__ - train loss is 5.969644404016435\n",
      "Steps:  41%|▍| 6118/15000 [52:31<1:15:14,  1.97it/s, lr=0.000763, step_loss=0.0107/27/2023 18:37:21 - INFO - __main__ - train loss is 5.972469451837242\n",
      "Steps:  41%|▍| 6119/15000 [52:31<1:15:44,  1.95it/s, lr=0.000763, step_loss=0.0007/27/2023 18:37:22 - INFO - __main__ - train loss is 6.021392705850303\n",
      "Steps:  41%|▍| 6120/15000 [52:32<1:15:23,  1.96it/s, lr=0.000763, step_loss=0.0407/27/2023 18:37:22 - INFO - __main__ - train loss is 6.456382933072746\n",
      "Steps:  41%|▍| 6121/15000 [52:32<1:15:15,  1.97it/s, lr=0.000763, step_loss=0.4307/27/2023 18:37:23 - INFO - __main__ - train loss is 6.5251743523404\n",
      "Steps:  41%|▍| 6122/15000 [52:33<1:15:05,  1.97it/s, lr=0.000763, step_loss=0.0607/27/2023 18:37:23 - INFO - __main__ - train loss is 7.084166380576789\n",
      "Steps:  41%|▍| 6123/15000 [52:33<1:15:15,  1.97it/s, lr=0.000764, step_loss=0.5507/27/2023 18:37:24 - INFO - __main__ - train loss is 7.095652447082102\n",
      "Steps:  41%|▍| 6124/15000 [52:34<1:15:02,  1.97it/s, lr=0.000764, step_loss=0.0107/27/2023 18:37:24 - INFO - __main__ - train loss is 7.215440512634814\n",
      "Steps:  41%|▍| 6125/15000 [52:34<1:15:03,  1.97it/s, lr=0.000764, step_loss=0.1207/27/2023 18:37:25 - INFO - __main__ - train loss is 7.875065804459155\n",
      "Steps:  41%|▍| 6126/15000 [52:35<1:15:13,  1.97it/s, lr=0.000764, step_loss=0.6607/27/2023 18:37:25 - INFO - __main__ - train loss is 7.999325499869883\n",
      "Steps:  41%|▍| 6127/15000 [52:35<1:15:03,  1.97it/s, lr=0.000764, step_loss=0.1207/27/2023 18:37:26 - INFO - __main__ - train loss is 8.076448754407465\n",
      "Steps:  41%|▍| 6128/15000 [52:36<1:14:45,  1.98it/s, lr=0.000764, step_loss=0.0707/27/2023 18:37:26 - INFO - __main__ - train loss is 8.822101489640772\n",
      "Steps:  41%|▍| 6129/15000 [52:36<1:14:36,  1.98it/s, lr=0.000764, step_loss=0.7407/27/2023 18:37:27 - INFO - __main__ - train loss is 9.161238268949091\n",
      "Steps:  41%|▍| 6130/15000 [52:37<1:14:34,  1.98it/s, lr=0.000764, step_loss=0.3307/27/2023 18:37:27 - INFO - __main__ - train loss is 9.239173726178706\n",
      "Steps:  41%|▍| 6131/15000 [52:37<1:14:38,  1.98it/s, lr=0.000765, step_loss=0.0707/27/2023 18:37:28 - INFO - __main__ - train loss is 9.427789674140513\n",
      "Steps:  41%|▍| 6132/15000 [52:38<1:15:56,  1.95it/s, lr=0.000765, step_loss=0.1807/27/2023 18:37:28 - INFO - __main__ - train loss is 9.631223545409739\n",
      "Steps:  41%|▍| 6133/15000 [52:38<1:16:03,  1.94it/s, lr=0.000765, step_loss=0.2007/27/2023 18:37:29 - INFO - __main__ - train loss is 9.649235633201897\n",
      "Steps:  41%|▍| 6134/15000 [52:39<1:15:49,  1.95it/s, lr=0.000765, step_loss=0.0107/27/2023 18:37:29 - INFO - __main__ - train loss is 9.903199669905007\n",
      "Steps:  41%|▍| 6135/15000 [52:40<1:15:41,  1.95it/s, lr=0.000765, step_loss=0.2507/27/2023 18:37:30 - INFO - __main__ - train loss is 10.044365328736603\n",
      "Steps:  41%|▍| 6136/15000 [52:40<1:15:31,  1.96it/s, lr=0.000765, step_loss=0.1407/27/2023 18:37:30 - INFO - __main__ - train loss is 10.207416218705475\n",
      "[2023-07-27 18:37:30,795] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  41%|▍| 6137/15000 [52:41<1:15:11,  1.96it/s, lr=0.000765, step_loss=0.1607/27/2023 18:37:31 - INFO - __main__ - train loss is 10.210726770106703\n",
      "Steps:  41%|▍| 6138/15000 [52:41<1:16:46,  1.92it/s, lr=0.000765, step_loss=0.0007/27/2023 18:37:31 - INFO - __main__ - train loss is 10.220810104627162\n",
      "Steps:  41%|▍| 6139/15000 [52:42<1:19:27,  1.86it/s, lr=0.000766, step_loss=0.0107/27/2023 18:37:32 - INFO - __main__ - train loss is 10.228040191810578\n",
      "Steps:  41%|▍| 6140/15000 [52:42<1:18:21,  1.88it/s, lr=0.000766, step_loss=0.0007/27/2023 18:37:32 - INFO - __main__ - train loss is 10.237330737058073\n",
      "Steps:  41%|▍| 6141/15000 [52:43<1:19:35,  1.86it/s, lr=0.000766, step_loss=0.0007/27/2023 18:37:33 - INFO - __main__ - train loss is 10.287950152996927\n",
      "Steps:  41%|▍| 6142/15000 [52:43<1:19:54,  1.85it/s, lr=0.000766, step_loss=0.0507/27/2023 18:37:33 - INFO - __main__ - train loss is 10.28997836727649\n",
      "Steps:  41%|▍| 6143/15000 [52:44<1:19:28,  1.86it/s, lr=0.000766, step_loss=0.0007/27/2023 18:37:34 - INFO - __main__ - train loss is 10.61898044962436\n",
      "Steps:  41%|▍| 6144/15000 [52:44<1:18:05,  1.89it/s, lr=0.000766, step_loss=0.3207/27/2023 18:37:34 - INFO - __main__ - train loss is 10.718822759576142\n",
      "Steps:  41%|▍| 6145/15000 [52:45<1:17:12,  1.91it/s, lr=0.000766, step_loss=0.0907/27/2023 18:37:35 - INFO - __main__ - train loss is 10.994267505593598\n",
      "Steps:  41%|▍| 6146/15000 [52:45<1:16:23,  1.93it/s, lr=0.000766, step_loss=0.2707/27/2023 18:37:36 - INFO - __main__ - train loss is 11.001503735780716\n",
      "Steps:  41%|▍| 6147/15000 [52:46<1:15:43,  1.95it/s, lr=0.000766, step_loss=0.0007/27/2023 18:37:36 - INFO - __main__ - train loss is 11.057512480765581\n",
      "Steps:  41%|▍| 6148/15000 [52:46<1:15:18,  1.96it/s, lr=0.000767, step_loss=0.0507/27/2023 18:37:37 - INFO - __main__ - train loss is 11.341892797499895\n",
      "Steps:  41%|▍| 6149/15000 [52:47<1:15:18,  1.96it/s, lr=0.000767, step_loss=0.2807/27/2023 18:37:37 - INFO - __main__ - train loss is 11.411526147276163\n",
      "Steps:  41%|▍| 6150/15000 [52:47<1:15:04,  1.96it/s, lr=0.000767, step_loss=0.0607/27/2023 18:37:38 - INFO - __main__ - train loss is 11.738248143345118\n",
      "Steps:  41%|▍| 6151/15000 [52:48<1:14:43,  1.97it/s, lr=0.000767, step_loss=0.3207/27/2023 18:37:38 - INFO - __main__ - train loss is 12.555466327816248\n",
      "Steps:  41%|▍| 6152/15000 [52:48<1:14:46,  1.97it/s, lr=0.000767, step_loss=0.8107/27/2023 18:37:39 - INFO - __main__ - train loss is 12.566757006570697\n",
      "Steps:  41%|▍| 6153/15000 [52:49<1:14:11,  1.99it/s, lr=0.000767, step_loss=0.0107/27/2023 18:37:39 - INFO - __main__ - train loss is 13.159959239885211\n",
      "Steps:  41%|▍| 6154/15000 [52:49<1:14:54,  1.97it/s, lr=0.000767, step_loss=0.5907/27/2023 18:37:40 - INFO - __main__ - train loss is 13.168743815273046\n",
      "Steps:  41%|▍| 6155/15000 [52:50<1:15:00,  1.97it/s, lr=0.000767, step_loss=0.0007/27/2023 18:37:40 - INFO - __main__ - train loss is 13.171065465314314\n",
      "Steps:  41%|▍| 6156/15000 [52:50<1:14:57,  1.97it/s, lr=0.000768, step_loss=0.0007/27/2023 18:37:41 - INFO - __main__ - train loss is 13.364952803356573\n",
      "Steps:  41%|▍| 6157/15000 [52:51<1:14:49,  1.97it/s, lr=0.000768, step_loss=0.1907/27/2023 18:37:41 - INFO - __main__ - train loss is 13.378906291676685\n",
      "Steps:  41%|▍| 6158/15000 [52:51<1:14:32,  1.98it/s, lr=0.000768, step_loss=0.0107/27/2023 18:37:42 - INFO - __main__ - train loss is 13.386279927333817\n",
      "Steps:  41%|▍| 6159/15000 [52:52<1:14:18,  1.98it/s, lr=0.000768, step_loss=0.0007/27/2023 18:37:42 - INFO - __main__ - train loss is 13.493664489826187\n",
      "Steps:  41%|▍| 6160/15000 [52:52<1:14:18,  1.98it/s, lr=0.000768, step_loss=0.1007/27/2023 18:37:43 - INFO - __main__ - train loss is 13.518920931732282\n",
      "Steps:  41%|▍| 6161/15000 [52:53<1:14:54,  1.97it/s, lr=0.000768, step_loss=0.0207/27/2023 18:37:43 - INFO - __main__ - train loss is 13.533543944125995\n",
      "Steps:  41%|▍| 6162/15000 [52:53<1:14:48,  1.97it/s, lr=0.000768, step_loss=0.0107/27/2023 18:37:44 - INFO - __main__ - train loss is 13.551277165999636\n",
      "Steps:  41%|▍| 6163/15000 [52:54<1:14:28,  1.98it/s, lr=0.000768, step_loss=0.0107/27/2023 18:37:44 - INFO - __main__ - train loss is 13.55334725114517\n",
      "Steps:  41%|▍| 6164/15000 [52:54<1:14:25,  1.98it/s, lr=0.000769, step_loss=0.0007/27/2023 18:37:45 - INFO - __main__ - train loss is 14.030845305649564\n",
      "Steps:  41%|▍| 6165/15000 [52:55<1:14:21,  1.98it/s, lr=0.000769, step_loss=0.4707/27/2023 18:37:45 - INFO - __main__ - train loss is 14.662125727860257\n",
      "Steps:  41%|▍| 6166/15000 [52:55<1:14:17,  1.98it/s, lr=0.000769, step_loss=0.6307/27/2023 18:37:46 - INFO - __main__ - train loss is 14.995940825669095\n",
      "Steps:  41%|▍| 6167/15000 [52:56<1:14:50,  1.97it/s, lr=0.000769, step_loss=0.3307/27/2023 18:37:46 - INFO - __main__ - train loss is 15.170196673600003\n",
      "Steps:  41%|▍| 6168/15000 [52:56<1:14:52,  1.97it/s, lr=0.000769, step_loss=0.1707/27/2023 18:37:47 - INFO - __main__ - train loss is 15.212606183020398\n",
      "Steps:  41%|▍| 6169/15000 [52:57<1:14:38,  1.97it/s, lr=0.000769, step_loss=0.0407/27/2023 18:37:47 - INFO - __main__ - train loss is 15.216103618964553\n",
      "Steps:  41%|▍| 6170/15000 [52:57<1:15:09,  1.96it/s, lr=0.000769, step_loss=0.0007/27/2023 18:37:48 - INFO - __main__ - train loss is 15.743950432166457\n",
      "Steps:  41%|▍| 6171/15000 [52:58<1:15:04,  1.96it/s, lr=0.00077, step_loss=0.52807/27/2023 18:37:48 - INFO - __main__ - train loss is 15.917344963178039\n",
      "Steps:  41%|▍| 6172/15000 [52:58<1:14:40,  1.97it/s, lr=0.00077, step_loss=0.17307/27/2023 18:37:49 - INFO - __main__ - train loss is 15.993710434064269\n",
      "Steps:  41%|▍| 6173/15000 [52:59<1:14:39,  1.97it/s, lr=0.00077, step_loss=0.07607/27/2023 18:37:49 - INFO - __main__ - train loss is 15.999389055650681\n",
      "Steps:  41%|▍| 6174/15000 [52:59<1:14:29,  1.97it/s, lr=0.00077, step_loss=0.00507/27/2023 18:37:50 - INFO - __main__ - train loss is 16.13210779754445\n",
      "Steps:  41%|▍| 6175/15000 [53:00<1:14:25,  1.98it/s, lr=0.00077, step_loss=0.13307/27/2023 18:37:50 - INFO - __main__ - train loss is 16.17018188117072\n",
      "Steps:  41%|▍| 6176/15000 [53:01<1:14:26,  1.98it/s, lr=0.00077, step_loss=0.03807/27/2023 18:37:51 - INFO - __main__ - train loss is 16.205014906357974\n",
      "Steps:  41%|▍| 6177/15000 [53:01<1:14:22,  1.98it/s, lr=0.00077, step_loss=0.03407/27/2023 18:37:51 - INFO - __main__ - train loss is 16.230753268580884\n",
      "Steps:  41%|▍| 6178/15000 [53:02<1:14:26,  1.98it/s, lr=0.00077, step_loss=0.02507/27/2023 18:37:52 - INFO - __main__ - train loss is 16.234404502203688\n",
      "Steps:  41%|▍| 6179/15000 [53:02<1:14:16,  1.98it/s, lr=0.000771, step_loss=0.0007/27/2023 18:37:52 - INFO - __main__ - train loss is 16.555766282370314\n",
      "Steps:  41%|▍| 6180/15000 [53:03<1:14:29,  1.97it/s, lr=0.000771, step_loss=0.3207/27/2023 18:37:53 - INFO - __main__ - train loss is 16.586367511888966\n",
      "Steps:  41%|▍| 6181/15000 [53:03<1:14:27,  1.97it/s, lr=0.000771, step_loss=0.0307/27/2023 18:37:53 - INFO - __main__ - train loss is 16.674421244999394\n",
      "Steps:  41%|▍| 6182/15000 [53:04<1:14:29,  1.97it/s, lr=0.000771, step_loss=0.0807/27/2023 18:37:54 - INFO - __main__ - train loss is 16.68285733065568\n",
      "Steps:  41%|▍| 6183/15000 [53:04<1:14:16,  1.98it/s, lr=0.000771, step_loss=0.0007/27/2023 18:37:54 - INFO - __main__ - train loss is 16.729666776722297\n",
      "Steps:  41%|▍| 6184/15000 [53:05<1:14:06,  1.98it/s, lr=0.000771, step_loss=0.0407/27/2023 18:37:55 - INFO - __main__ - train loss is 16.731067065615207\n",
      "Steps:  41%|▍| 6185/15000 [53:05<1:14:04,  1.98it/s, lr=0.000771, step_loss=0.0007/27/2023 18:37:55 - INFO - __main__ - train loss is 16.943481360096484\n",
      "Steps:  41%|▍| 6186/15000 [53:06<1:14:01,  1.98it/s, lr=0.000771, step_loss=0.2107/27/2023 18:37:56 - INFO - __main__ - train loss is 17.00964017631486\n",
      "Steps:  41%|▍| 6187/15000 [53:06<1:14:18,  1.98it/s, lr=0.000771, step_loss=0.0607/27/2023 18:37:56 - INFO - __main__ - train loss is 17.049231194425374\n",
      "Steps:  41%|▍| 6188/15000 [53:07<1:14:22,  1.97it/s, lr=0.000772, step_loss=0.0307/27/2023 18:37:57 - INFO - __main__ - train loss is 17.172978304792196\n",
      "Steps:  41%|▍| 6189/15000 [53:07<1:14:26,  1.97it/s, lr=0.000772, step_loss=0.1207/27/2023 18:37:57 - INFO - __main__ - train loss is 17.177639750298113\n",
      "Steps:  41%|▍| 6190/15000 [53:08<1:14:25,  1.97it/s, lr=0.000772, step_loss=0.0007/27/2023 18:37:58 - INFO - __main__ - train loss is 17.312185106333345\n",
      "Steps:  41%|▍| 6191/15000 [53:08<1:14:44,  1.96it/s, lr=0.000772, step_loss=0.1307/27/2023 18:37:58 - INFO - __main__ - train loss is 17.480110642965883\n",
      "Steps:  41%|▍| 6192/15000 [53:09<1:15:20,  1.95it/s, lr=0.000772, step_loss=0.1607/27/2023 18:37:59 - INFO - __main__ - train loss is 17.94046184187755\n",
      "Steps:  41%|▍| 6193/15000 [53:09<1:24:51,  1.73it/s, lr=0.000772, step_loss=0.4607/27/2023 18:38:00 - INFO - __main__ - train loss is 17.942373348632827\n",
      "Steps:  41%|▍| 6194/15000 [53:10<1:22:33,  1.78it/s, lr=0.000772, step_loss=0.0007/27/2023 18:38:00 - INFO - __main__ - train loss is 18.021770043531433\n",
      "Steps:  41%|▍| 6195/15000 [53:10<1:20:02,  1.83it/s, lr=0.000772, step_loss=0.0707/27/2023 18:38:01 - INFO - __main__ - train loss is 18.026095025474206\n",
      "Steps:  41%|▍| 6196/15000 [53:11<1:18:58,  1.86it/s, lr=0.000773, step_loss=0.0007/27/2023 18:38:01 - INFO - __main__ - train loss is 18.048821404809132\n",
      "Steps:  41%|▍| 6197/15000 [53:11<1:18:30,  1.87it/s, lr=0.000773, step_loss=0.0207/27/2023 18:38:02 - INFO - __main__ - train loss is 18.106677390867844\n",
      "Steps:  41%|▍| 6198/15000 [53:12<1:17:16,  1.90it/s, lr=0.000773, step_loss=0.0507/27/2023 18:38:02 - INFO - __main__ - train loss is 18.11451470782049\n",
      "Steps:  41%|▍| 6199/15000 [53:12<1:16:31,  1.92it/s, lr=0.000773, step_loss=0.0007/27/2023 18:38:03 - INFO - __main__ - train loss is 18.123323051491752\n",
      "Steps:  41%|▍| 6200/15000 [53:13<1:16:24,  1.92it/s, lr=0.000773, step_loss=0.0007/27/2023 18:38:03 - INFO - __main__ - train loss is 18.179011589149013\n",
      "Steps:  41%|▍| 6201/15000 [53:13<1:16:07,  1.93it/s, lr=0.000773, step_loss=0.0507/27/2023 18:38:04 - INFO - __main__ - train loss is 18.242840891936794\n",
      "Steps:  41%|▍| 6202/15000 [53:14<1:15:58,  1.93it/s, lr=0.000773, step_loss=0.0607/27/2023 18:38:04 - INFO - __main__ - train loss is 18.470423883059993\n",
      "Steps:  41%|▍| 6203/15000 [53:15<1:15:45,  1.94it/s, lr=0.000773, step_loss=0.2207/27/2023 18:38:05 - INFO - __main__ - train loss is 18.784031367162243\n",
      "Steps:  41%|▍| 6204/15000 [53:15<1:15:14,  1.95it/s, lr=0.000774, step_loss=0.3107/27/2023 18:38:05 - INFO - __main__ - train loss is 18.789331541629508\n",
      "Steps:  41%|▍| 6205/15000 [53:16<1:14:56,  1.96it/s, lr=0.000774, step_loss=0.0007/27/2023 18:38:06 - INFO - __main__ - train loss is 18.792883038287982\n",
      "Steps:  41%|▍| 6206/15000 [53:16<1:14:33,  1.97it/s, lr=0.000774, step_loss=0.0007/27/2023 18:38:06 - INFO - __main__ - train loss is 19.14831766462885\n",
      "Steps:  41%|▍| 6207/15000 [53:17<1:14:16,  1.97it/s, lr=0.000774, step_loss=0.3507/27/2023 18:38:07 - INFO - __main__ - train loss is 19.24901145673357\n",
      "Steps:  41%|▍| 6208/15000 [53:17<1:14:12,  1.97it/s, lr=0.000774, step_loss=0.1007/27/2023 18:38:07 - INFO - __main__ - train loss is 19.43798315501772\n",
      "Steps:  41%|▍| 6209/15000 [53:18<1:14:27,  1.97it/s, lr=0.000774, step_loss=0.1807/27/2023 18:38:08 - INFO - __main__ - train loss is 19.63829070306383\n",
      "Steps:  41%|▍| 6210/15000 [53:18<1:14:14,  1.97it/s, lr=0.000774, step_loss=0.2]07/27/2023 18:38:08 - INFO - __main__ - train loss is 19.754551276331767\n",
      "Steps:  41%|▍| 6211/15000 [53:19<1:14:04,  1.98it/s, lr=0.000775, step_loss=0.1107/27/2023 18:38:09 - INFO - __main__ - train loss is 20.110077306395397\n",
      "Steps:  41%|▍| 6212/15000 [53:19<1:13:56,  1.98it/s, lr=0.000775, step_loss=0.3507/27/2023 18:38:09 - INFO - __main__ - train loss is 20.12485963734798\n",
      "Steps:  41%|▍| 6213/15000 [53:20<1:13:57,  1.98it/s, lr=0.000775, step_loss=0.0107/27/2023 18:38:10 - INFO - __main__ - train loss is 20.162282596109435\n",
      "Steps:  41%|▍| 6214/15000 [53:20<1:14:01,  1.98it/s, lr=0.000775, step_loss=0.0307/27/2023 18:38:10 - INFO - __main__ - train loss is 20.213990735588595\n",
      "Steps:  41%|▍| 6215/15000 [53:21<1:13:46,  1.98it/s, lr=0.000775, step_loss=0.0507/27/2023 18:38:11 - INFO - __main__ - train loss is 20.403736936626956\n",
      "Steps:  41%|▍| 6216/15000 [53:21<1:14:13,  1.97it/s, lr=0.000775, step_loss=0.1907/27/2023 18:38:11 - INFO - __main__ - train loss is 20.411372791742906\n",
      "Steps:  41%|▍| 6217/15000 [53:22<1:14:01,  1.98it/s, lr=0.000775, step_loss=0.0007/27/2023 18:38:12 - INFO - __main__ - train loss is 20.5940867473837\n",
      "Steps:  41%|▍| 6218/15000 [53:22<1:13:54,  1.98it/s, lr=0.000775, step_loss=0.1807/27/2023 18:38:12 - INFO - __main__ - train loss is 20.60994668654166\n",
      "Steps:  41%|▍| 6219/15000 [53:23<1:13:59,  1.98it/s, lr=0.000775, step_loss=0.0107/27/2023 18:38:13 - INFO - __main__ - train loss is 20.614651486976072\n",
      "Steps:  41%|▍| 6220/15000 [53:23<1:14:03,  1.98it/s, lr=0.000776, step_loss=0.0007/27/2023 18:38:13 - INFO - __main__ - train loss is 20.617549741407856\n",
      "Steps:  41%|▍| 6221/15000 [53:24<1:14:02,  1.98it/s, lr=0.000776, step_loss=0.0007/27/2023 18:38:14 - INFO - __main__ - train loss is 20.992777252336964\n",
      "Steps:  41%|▍| 6222/15000 [53:24<1:14:00,  1.98it/s, lr=0.000776, step_loss=0.3707/27/2023 18:38:14 - INFO - __main__ - train loss is 21.023486844962463\n",
      "Steps:  41%|▍| 6223/15000 [53:25<1:13:50,  1.98it/s, lr=0.000776, step_loss=0.0307/27/2023 18:38:15 - INFO - __main__ - train loss is 21.16689457721077\n",
      "Steps:  41%|▍| 6224/15000 [53:25<1:14:03,  1.97it/s, lr=0.000776, step_loss=0.1407/27/2023 18:38:15 - INFO - __main__ - train loss is 21.2278345299419\n",
      "Steps:  42%|▍| 6225/15000 [53:26<1:14:12,  1.97it/s, lr=0.000776, step_loss=0.0607/27/2023 18:38:16 - INFO - __main__ - train loss is 21.2833944556769\n",
      "Steps:  42%|▍| 6226/15000 [53:26<1:14:09,  1.97it/s, lr=0.000776, step_loss=0.0507/27/2023 18:38:16 - INFO - __main__ - train loss is 21.586743891006336\n",
      "Steps:  42%|▍| 6227/15000 [53:27<1:14:23,  1.97it/s, lr=0.000776, step_loss=0.3007/27/2023 18:38:17 - INFO - __main__ - train loss is 22.015080481534824\n",
      "Steps:  42%|▍| 6228/15000 [53:27<1:14:21,  1.97it/s, lr=0.000777, step_loss=0.4207/27/2023 18:38:17 - INFO - __main__ - train loss is 22.02092039003037\n",
      "Steps:  42%|▍| 6229/15000 [53:28<1:14:23,  1.97it/s, lr=0.000777, step_loss=0.0007/27/2023 18:38:18 - INFO - __main__ - train loss is 22.12249116017483\n",
      "Steps:  42%|▍| 6230/15000 [53:28<1:14:21,  1.97it/s, lr=0.000777, step_loss=0.1007/27/2023 18:38:18 - INFO - __main__ - train loss is 22.142754355212674\n",
      "Steps:  42%|▍| 6231/15000 [53:29<1:14:18,  1.97it/s, lr=0.000777, step_loss=0.0207/27/2023 18:38:19 - INFO - __main__ - train loss is 22.225211748620495\n",
      "Steps:  42%|▍| 6232/15000 [53:29<1:14:14,  1.97it/s, lr=0.000777, step_loss=0.0807/27/2023 18:38:19 - INFO - __main__ - train loss is 22.363890448352322\n",
      "Steps:  42%|▍| 6233/15000 [53:30<1:14:20,  1.97it/s, lr=0.000777, step_loss=0.1307/27/2023 18:38:20 - INFO - __main__ - train loss is 22.39352154894732\n",
      "Steps:  42%|▍| 6234/15000 [53:30<1:14:14,  1.97it/s, lr=0.000777, step_loss=0.0207/27/2023 18:38:20 - INFO - __main__ - train loss is 22.500430533429608\n",
      "Steps:  42%|▍| 6235/15000 [53:31<1:14:13,  1.97it/s, lr=0.000777, step_loss=0.1007/27/2023 18:38:21 - INFO - __main__ - train loss is 22.888705322286114\n",
      "Steps:  42%|▍| 6236/15000 [53:31<1:14:18,  1.97it/s, lr=0.000778, step_loss=0.3807/27/2023 18:38:21 - INFO - __main__ - train loss is 23.252412685891613\n",
      "Steps:  42%|▍| 6237/15000 [53:32<1:13:58,  1.97it/s, lr=0.000778, step_loss=0.3607/27/2023 18:38:22 - INFO - __main__ - train loss is 23.265093171736225\n",
      "Steps:  42%|▍| 6238/15000 [53:32<1:14:01,  1.97it/s, lr=0.000778, step_loss=0.0107/27/2023 18:38:22 - INFO - __main__ - train loss is 23.324143154313788\n",
      "Steps:  42%|▍| 6239/15000 [53:33<1:14:01,  1.97it/s, lr=0.000778, step_loss=0.0507/27/2023 18:38:23 - INFO - __main__ - train loss is 23.349643325200304\n",
      "Steps:  42%|▍| 6240/15000 [53:33<1:14:05,  1.97it/s, lr=0.000778, step_loss=0.0207/27/2023 18:38:23 - INFO - __main__ - train loss is 23.520379876485094\n",
      "Steps:  42%|▍| 6241/15000 [53:34<1:13:54,  1.98it/s, lr=0.000778, step_loss=0.1707/27/2023 18:38:24 - INFO - __main__ - train loss is 23.52222590195015\n",
      "Steps:  42%|▍| 6242/15000 [53:34<1:14:03,  1.97it/s, lr=0.000778, step_loss=0.0007/27/2023 18:38:24 - INFO - __main__ - train loss is 24.454785630572587\n",
      "Steps:  42%|▍| 6243/15000 [53:35<1:14:01,  1.97it/s, lr=0.000779, step_loss=0.9307/27/2023 18:38:25 - INFO - __main__ - train loss is 24.959797069896013\n",
      "Steps:  42%|▍| 6244/15000 [53:35<1:13:54,  1.97it/s, lr=0.000779, step_loss=0.5007/27/2023 18:38:25 - INFO - __main__ - train loss is 25.10041441069916\n",
      "Steps:  42%|▍| 6245/15000 [53:36<1:13:57,  1.97it/s, lr=0.000779, step_loss=0.1407/27/2023 18:38:26 - INFO - __main__ - train loss is 25.14812209131196\n",
      "Steps:  42%|▍| 6246/15000 [53:36<1:13:57,  1.97it/s, lr=0.000779, step_loss=0.0407/27/2023 18:38:27 - INFO - __main__ - train loss is 25.158745125401765\n",
      "Steps:  42%|▍| 6247/15000 [53:37<1:14:02,  1.97it/s, lr=0.000779, step_loss=0.0107/27/2023 18:38:27 - INFO - __main__ - train loss is 25.35512387799099\n",
      "Steps:  42%|▍| 6248/15000 [53:37<1:14:14,  1.96it/s, lr=0.000779, step_loss=0.1907/27/2023 18:38:28 - INFO - __main__ - train loss is 25.417093329597265\n",
      "Steps:  42%|▍| 6249/15000 [53:38<1:14:53,  1.95it/s, lr=0.000779, step_loss=0.0607/27/2023 18:38:28 - INFO - __main__ - train loss is 25.483147882390767\n",
      "Steps:  42%|▍| 6250/15000 [53:38<1:14:47,  1.95it/s, lr=0.000779, step_loss=0.0607/27/2023 18:38:29 - INFO - __main__ - train loss is 25.63220100896433\n",
      "Steps:  42%|▍| 6251/15000 [53:39<1:17:21,  1.88it/s, lr=0.00078, step_loss=0.14907/27/2023 18:38:29 - INFO - __main__ - train loss is 25.63819959340617\n",
      "Steps:  42%|▍| 6252/15000 [53:40<1:18:53,  1.85it/s, lr=0.00078, step_loss=0.00607/27/2023 18:38:30 - INFO - __main__ - train loss is 25.746634136419743\n",
      "Steps:  42%|▍| 6253/15000 [53:40<1:18:53,  1.85it/s, lr=0.00078, step_loss=0.10807/27/2023 18:38:30 - INFO - __main__ - train loss is 25.757275364827365\n",
      "Steps:  42%|▍| 6254/15000 [53:41<1:18:26,  1.86it/s, lr=0.00078, step_loss=0.01007/27/2023 18:38:31 - INFO - __main__ - train loss is 26.215571872424334\n",
      "Steps:  42%|▍| 6255/15000 [53:41<1:18:19,  1.86it/s, lr=0.00078, step_loss=0.45807/27/2023 18:38:31 - INFO - __main__ - train loss is 26.41994886798784\n",
      "Steps:  42%|▍| 6256/15000 [53:42<1:18:17,  1.86it/s, lr=0.00078, step_loss=0.20407/27/2023 18:38:32 - INFO - __main__ - train loss is 26.422652854584157\n",
      "Steps:  42%|▍| 6257/15000 [53:42<1:17:20,  1.88it/s, lr=0.00078, step_loss=0.00207/27/2023 18:38:32 - INFO - __main__ - train loss is 26.428564416244626\n",
      "Steps:  42%|▍| 6258/15000 [53:43<1:16:07,  1.91it/s, lr=0.00078, step_loss=0.00507/27/2023 18:38:33 - INFO - __main__ - train loss is 26.498899349942803\n",
      "Steps:  42%|▍| 6259/15000 [53:43<1:15:04,  1.94it/s, lr=0.00078, step_loss=0.07007/27/2023 18:38:33 - INFO - __main__ - train loss is 26.520224699750543\n",
      "Steps:  42%|▍| 6260/15000 [53:44<1:14:34,  1.95it/s, lr=0.000781, step_loss=0.0207/27/2023 18:38:34 - INFO - __main__ - train loss is 26.532219391316175\n",
      "Steps:  42%|▍| 6261/15000 [53:44<1:14:05,  1.97it/s, lr=0.000781, step_loss=0.0107/27/2023 18:38:34 - INFO - __main__ - train loss is 27.057012241333723\n",
      "Steps:  42%|▍| 6262/15000 [53:45<1:13:39,  1.98it/s, lr=0.000781, step_loss=0.5207/27/2023 18:38:35 - INFO - __main__ - train loss is 27.063988489564508\n",
      "Steps:  42%|▍| 6263/15000 [53:45<1:13:34,  1.98it/s, lr=0.000781, step_loss=0.0007/27/2023 18:38:35 - INFO - __main__ - train loss is 27.14128611749038\n",
      "Steps:  42%|▍| 6264/15000 [53:46<1:13:23,  1.98it/s, lr=0.000781, step_loss=0.0707/27/2023 18:38:36 - INFO - __main__ - train loss is 27.143050264567137\n",
      "Steps:  42%|▍| 6265/15000 [53:46<1:13:29,  1.98it/s, lr=0.000781, step_loss=0.0007/27/2023 18:38:36 - INFO - __main__ - train loss is 27.578526478260756\n",
      "Steps:  42%|▍| 6266/15000 [53:47<1:13:30,  1.98it/s, lr=0.000781, step_loss=0.4307/27/2023 18:38:37 - INFO - __main__ - train loss is 27.72741560265422\n",
      "Steps:  42%|▍| 6267/15000 [53:47<1:13:50,  1.97it/s, lr=0.000781, step_loss=0.1407/27/2023 18:38:37 - INFO - __main__ - train loss is 27.94280780479312\n",
      "Steps:  42%|▍| 6268/15000 [53:48<1:13:45,  1.97it/s, lr=0.000782, step_loss=0.2107/27/2023 18:38:38 - INFO - __main__ - train loss is 28.083098720759153\n",
      "Steps:  42%|▍| 6269/15000 [53:48<1:13:53,  1.97it/s, lr=0.000782, step_loss=0.1407/27/2023 18:38:38 - INFO - __main__ - train loss is 28.214102637022734\n",
      "Steps:  42%|▍| 6270/15000 [53:49<1:14:03,  1.96it/s, lr=0.000782, step_loss=0.1307/27/2023 18:38:39 - INFO - __main__ - train loss is 28.27526381239295\n",
      "Steps:  42%|▍| 6271/15000 [53:49<1:14:12,  1.96it/s, lr=0.000782, step_loss=0.0607/27/2023 18:38:39 - INFO - __main__ - train loss is 28.327439453452826\n",
      "Steps:  42%|▍| 6272/15000 [53:50<1:14:07,  1.96it/s, lr=0.000782, step_loss=0.0507/27/2023 18:38:40 - INFO - __main__ - train loss is 28.382640454918146\n",
      "Steps:  42%|▍| 6273/15000 [53:50<1:14:11,  1.96it/s, lr=0.000782, step_loss=0.0507/27/2023 18:38:40 - INFO - __main__ - train loss is 28.385527291567996\n",
      "Steps:  42%|▍| 6274/15000 [53:51<1:14:04,  1.96it/s, lr=0.000782, step_loss=0.0007/27/2023 18:38:41 - INFO - __main__ - train loss is 28.387845157878473\n",
      "Steps:  42%|▍| 6275/15000 [53:51<1:13:55,  1.97it/s, lr=0.000782, step_loss=0.0007/27/2023 18:38:41 - INFO - __main__ - train loss is 28.456702797906473\n",
      "Steps:  42%|▍| 6276/15000 [53:52<1:13:57,  1.97it/s, lr=0.000783, step_loss=0.0607/27/2023 18:38:42 - INFO - __main__ - train loss is 28.574334531323984\n",
      "Steps:  42%|▍| 6277/15000 [53:52<1:14:16,  1.96it/s, lr=0.000783, step_loss=0.1107/27/2023 18:38:42 - INFO - __main__ - train loss is 28.764439060585573\n",
      "Steps:  42%|▍| 6278/15000 [53:53<1:14:14,  1.96it/s, lr=0.000783, step_loss=0.1907/27/2023 18:38:43 - INFO - __main__ - train loss is 28.831215820508078\n",
      "Steps:  42%|▍| 6279/15000 [53:53<1:14:16,  1.96it/s, lr=0.000783, step_loss=0.0607/27/2023 18:38:44 - INFO - __main__ - train loss is 28.832605325616896\n",
      "Steps:  42%|▍| 6280/15000 [53:54<1:14:12,  1.96it/s, lr=0.000783, step_loss=0.0007/27/2023 18:38:44 - INFO - __main__ - train loss is 28.836784446612\n",
      "Steps:  42%|▍| 6281/15000 [53:54<1:14:14,  1.96it/s, lr=0.000783, step_loss=0.0007/27/2023 18:38:45 - INFO - __main__ - train loss is 28.89768229611218\n",
      "Steps:  42%|▍| 6282/15000 [53:55<1:14:12,  1.96it/s, lr=0.000783, step_loss=0.0607/27/2023 18:38:45 - INFO - __main__ - train loss is 29.026146905496716\n",
      "Steps:  42%|▍| 6283/15000 [53:55<1:14:07,  1.96it/s, lr=0.000784, step_loss=0.1207/27/2023 18:38:46 - INFO - __main__ - train loss is 29.049324611201882\n",
      "Steps:  42%|▍| 6284/15000 [53:56<1:13:52,  1.97it/s, lr=0.000784, step_loss=0.0207/27/2023 18:38:46 - INFO - __main__ - train loss is 29.116113448515534\n",
      "Steps:  42%|▍| 6285/15000 [53:56<1:13:43,  1.97it/s, lr=0.000784, step_loss=0.0607/27/2023 18:38:47 - INFO - __main__ - train loss is 29.79043515957892\n",
      "Steps:  42%|▍| 6286/15000 [53:57<1:13:26,  1.98it/s, lr=0.000784, step_loss=0.6707/27/2023 18:38:47 - INFO - __main__ - train loss is 29.85643487609923\n",
      "Steps:  42%|▍| 6287/15000 [53:57<1:13:14,  1.98it/s, lr=0.000784, step_loss=0.0607/27/2023 18:38:48 - INFO - __main__ - train loss is 29.87667482532561\n",
      "Steps:  42%|▍| 6288/15000 [53:58<1:13:07,  1.99it/s, lr=0.000784, step_loss=0.0207/27/2023 18:38:48 - INFO - __main__ - train loss is 30.300934487953782\n",
      "Steps:  42%|▍| 6289/15000 [53:58<1:12:53,  1.99it/s, lr=0.000784, step_loss=0.4207/27/2023 18:38:49 - INFO - __main__ - train loss is 30.577796483412385\n",
      "Steps:  42%|▍| 6290/15000 [53:59<1:13:23,  1.98it/s, lr=0.000784, step_loss=0.2707/27/2023 18:38:49 - INFO - __main__ - train loss is 30.697636084631085\n",
      "Steps:  42%|▍| 6291/15000 [53:59<1:13:54,  1.96it/s, lr=0.000785, step_loss=0.1207/27/2023 18:38:50 - INFO - __main__ - train loss is 30.816513614729047\n",
      "Steps:  42%|▍| 6292/15000 [54:00<1:14:09,  1.96it/s, lr=0.000785, step_loss=0.1107/27/2023 18:38:50 - INFO - __main__ - train loss is 31.218915777280927\n",
      "Steps:  42%|▍| 6293/15000 [54:00<1:13:53,  1.96it/s, lr=0.000785, step_loss=0.4007/27/2023 18:38:51 - INFO - __main__ - train loss is 31.629954474046826\n",
      "Steps:  42%|▍| 6294/15000 [54:01<1:13:31,  1.97it/s, lr=0.000785, step_loss=0.4107/27/2023 18:38:51 - INFO - __main__ - train loss is 31.633466488216072\n",
      "Steps:  42%|▍| 6295/15000 [54:01<1:13:28,  1.97it/s, lr=0.000785, step_loss=0.0007/27/2023 18:38:52 - INFO - __main__ - train loss is 31.747430732939392\n",
      "Steps:  42%|▍| 6296/15000 [54:02<1:13:20,  1.98it/s, lr=0.000785, step_loss=0.1107/27/2023 18:38:52 - INFO - __main__ - train loss is 31.87128313491121\n",
      "Steps:  42%|▍| 6297/15000 [54:02<1:13:13,  1.98it/s, lr=0.000785, step_loss=0.1207/27/2023 18:38:53 - INFO - __main__ - train loss is 31.927656742278486\n",
      "Steps:  42%|▍| 6298/15000 [54:03<1:13:00,  1.99it/s, lr=0.000785, step_loss=0.0507/27/2023 18:38:53 - INFO - __main__ - train loss is 31.983905697707087\n",
      "Steps:  42%|▍| 6299/15000 [54:03<1:13:09,  1.98it/s, lr=0.000785, step_loss=0.0507/27/2023 18:38:54 - INFO - __main__ - train loss is 31.987538385670632\n",
      "Steps:  42%|▍| 6300/15000 [54:04<1:13:09,  1.98it/s, lr=0.000786, step_loss=0.0007/27/2023 18:38:54 - INFO - __main__ - train loss is 32.55523620871827\n",
      "Steps:  42%|▍| 6301/15000 [54:04<1:13:04,  1.98it/s, lr=0.000786, step_loss=0.5607/27/2023 18:38:55 - INFO - __main__ - train loss is 32.64698175666854\n",
      "Steps:  42%|▍| 6302/15000 [54:05<1:12:54,  1.99it/s, lr=0.000786, step_loss=0.0907/27/2023 18:38:55 - INFO - __main__ - train loss is 32.866237710695714\n",
      "Steps:  42%|▍| 6303/15000 [54:05<1:12:58,  1.99it/s, lr=0.000786, step_loss=0.2107/27/2023 18:38:56 - INFO - __main__ - train loss is 33.03693998930976\n",
      "Steps:  42%|▍| 6304/15000 [54:06<1:12:52,  1.99it/s, lr=0.000786, step_loss=0.1707/27/2023 18:38:56 - INFO - __main__ - train loss is 33.046231287997216\n",
      "Steps:  42%|▍| 6305/15000 [54:06<1:12:57,  1.99it/s, lr=0.000786, step_loss=0.0007/27/2023 18:38:57 - INFO - __main__ - train loss is 33.05663836793974\n",
      "Steps:  42%|▍| 6306/15000 [54:07<1:13:02,  1.98it/s, lr=0.000786, step_loss=0.0107/27/2023 18:38:57 - INFO - __main__ - train loss is 33.18725822167471\n",
      "Steps:  42%|▍| 6307/15000 [54:07<1:12:07,  2.01it/s, lr=0.000786, step_loss=0.1307/27/2023 18:38:58 - INFO - __main__ - train loss is 33.253520869184285\n",
      "Steps:  42%|▍| 6308/15000 [54:08<1:12:31,  2.00it/s, lr=0.000787, step_loss=0.0607/27/2023 18:38:58 - INFO - __main__ - train loss is 33.26213273452595\n",
      "Steps:  42%|▍| 6309/15000 [54:08<1:12:42,  1.99it/s, lr=0.000787, step_loss=0.0007/27/2023 18:38:59 - INFO - __main__ - train loss is 33.334390819538385\n",
      "Steps:  42%|▍| 6310/15000 [54:09<1:12:46,  1.99it/s, lr=0.000787, step_loss=0.0707/27/2023 18:38:59 - INFO - __main__ - train loss is 33.46733170794323\n",
      "Steps:  42%|▍| 6311/15000 [54:09<1:13:23,  1.97it/s, lr=0.000787, step_loss=0.1307/27/2023 18:39:00 - INFO - __main__ - train loss is 33.58893853472546\n",
      "Steps:  42%|▍| 6312/15000 [54:10<1:15:24,  1.92it/s, lr=0.000787, step_loss=0.1207/27/2023 18:39:00 - INFO - __main__ - train loss is 33.705326058436185\n",
      "Steps:  42%|▍| 6313/15000 [54:11<1:19:12,  1.83it/s, lr=0.000787, step_loss=0.1107/27/2023 18:39:01 - INFO - __main__ - train loss is 33.92248318390921\n",
      "Steps:  42%|▍| 6314/15000 [54:11<1:18:33,  1.84it/s, lr=0.000787, step_loss=0.2107/27/2023 18:39:01 - INFO - __main__ - train loss is 33.92538057593629\n",
      "Steps:  42%|▍| 6315/15000 [54:12<1:18:30,  1.84it/s, lr=0.000788, step_loss=0.0007/27/2023 18:39:02 - INFO - __main__ - train loss is 33.93822317151353\n",
      "Steps:  42%|▍| 6316/15000 [54:12<1:17:30,  1.87it/s, lr=0.000788, step_loss=0.0107/27/2023 18:39:02 - INFO - __main__ - train loss is 33.967755091842264\n",
      "Steps:  42%|▍| 6317/15000 [54:13<1:16:52,  1.88it/s, lr=0.000788, step_loss=0.0207/27/2023 18:39:03 - INFO - __main__ - train loss is 33.998088320251554\n",
      "Steps:  42%|▍| 6318/15000 [54:13<1:17:02,  1.88it/s, lr=0.000788, step_loss=0.0307/27/2023 18:39:04 - INFO - __main__ - train loss is 34.000255602411926\n",
      "Steps:  42%|▍| 6319/15000 [54:14<1:16:24,  1.89it/s, lr=0.000788, step_loss=0.0007/27/2023 18:39:04 - INFO - __main__ - train loss is 34.134055900387466\n",
      "Steps:  42%|▍| 6320/15000 [54:14<1:15:49,  1.91it/s, lr=0.000788, step_loss=0.1307/27/2023 18:39:05 - INFO - __main__ - train loss is 34.17526717018336\n",
      "Steps:  42%|▍| 6321/15000 [54:15<1:15:25,  1.92it/s, lr=0.000788, step_loss=0.0407/27/2023 18:39:05 - INFO - __main__ - train loss is 34.19346012081951\n",
      "Steps:  42%|▍| 6322/15000 [54:15<1:15:11,  1.92it/s, lr=0.000788, step_loss=0.0107/27/2023 18:39:06 - INFO - __main__ - train loss is 34.410672082565725\n",
      "Steps:  42%|▍| 6323/15000 [54:16<1:14:55,  1.93it/s, lr=0.000789, step_loss=0.2107/27/2023 18:39:06 - INFO - __main__ - train loss is 34.52044190373272\n",
      "Steps:  42%|▍| 6324/15000 [54:16<1:14:23,  1.94it/s, lr=0.000789, step_loss=0.1107/27/2023 18:39:07 - INFO - __main__ - train loss is 34.645561440847814\n",
      "Steps:  42%|▍| 6325/15000 [54:17<1:14:08,  1.95it/s, lr=0.000789, step_loss=0.1207/27/2023 18:39:07 - INFO - __main__ - train loss is 34.65271974494681\n",
      "Steps:  42%|▍| 6326/15000 [54:17<1:13:55,  1.96it/s, lr=0.000789, step_loss=0.0007/27/2023 18:39:08 - INFO - __main__ - train loss is 34.6796798161231\n",
      "Steps:  42%|▍| 6327/15000 [54:18<1:13:46,  1.96it/s, lr=0.000789, step_loss=0.0207/27/2023 18:39:08 - INFO - __main__ - train loss is 34.79288779711351\n",
      "Steps:  42%|▍| 6328/15000 [54:18<1:13:46,  1.96it/s, lr=0.000789, step_loss=0.1107/27/2023 18:39:09 - INFO - __main__ - train loss is 34.9949133596383\n",
      "Steps:  42%|▍| 6329/15000 [54:19<1:13:49,  1.96it/s, lr=0.000789, step_loss=0.2007/27/2023 18:39:09 - INFO - __main__ - train loss is 35.221684058662504\n",
      "Steps:  42%|▍| 6330/15000 [54:19<1:13:48,  1.96it/s, lr=0.000789, step_loss=0.2207/27/2023 18:39:10 - INFO - __main__ - train loss is 35.46532810246572\n",
      "Steps:  42%|▍| 6331/15000 [54:20<1:13:49,  1.96it/s, lr=0.000789, step_loss=0.2407/27/2023 18:39:10 - INFO - __main__ - train loss is 36.02143168961629\n",
      "Steps:  42%|▍| 6332/15000 [54:20<1:14:18,  1.94it/s, lr=0.00079, step_loss=0.55607/27/2023 18:39:11 - INFO - __main__ - train loss is 36.04245996242389\n",
      "Steps:  42%|▍| 6333/15000 [54:21<1:14:06,  1.95it/s, lr=0.00079, step_loss=0.02107/27/2023 18:39:11 - INFO - __main__ - train loss is 36.08472832059488\n",
      "Steps:  42%|▍| 6334/15000 [54:21<1:14:12,  1.95it/s, lr=0.00079, step_loss=0.04207/27/2023 18:39:12 - INFO - __main__ - train loss is 36.141197280492634\n",
      "Steps:  42%|▍| 6335/15000 [54:22<1:14:13,  1.95it/s, lr=0.00079, step_loss=0.05607/27/2023 18:39:12 - INFO - __main__ - train loss is 36.33692015847191\n",
      "Steps:  42%|▍| 6336/15000 [54:23<1:14:15,  1.94it/s, lr=0.00079, step_loss=0.19607/27/2023 18:39:13 - INFO - __main__ - train loss is 36.340433270903304\n",
      "Steps:  42%|▍| 6337/15000 [54:23<1:14:08,  1.95it/s, lr=0.00079, step_loss=0.00307/27/2023 18:39:13 - INFO - __main__ - train loss is 36.34469838463701\n",
      "Steps:  42%|▍| 6338/15000 [54:24<1:13:57,  1.95it/s, lr=0.00079, step_loss=0.00407/27/2023 18:39:14 - INFO - __main__ - train loss is 36.37372203194536\n",
      "Steps:  42%|▍| 6339/15000 [54:24<1:13:34,  1.96it/s, lr=0.00079, step_loss=0.02907/27/2023 18:39:14 - INFO - __main__ - train loss is 36.38100806926377\n",
      "Steps:  42%|▍| 6340/15000 [54:25<1:13:24,  1.97it/s, lr=0.000791, step_loss=0.0007/27/2023 18:39:15 - INFO - __main__ - train loss is 36.41318231378682\n",
      "Steps:  42%|▍| 6341/15000 [54:25<1:13:39,  1.96it/s, lr=0.000791, step_loss=0.0307/27/2023 18:39:15 - INFO - __main__ - train loss is 36.420929153682664\n",
      "Steps:  42%|▍| 6342/15000 [54:26<1:14:15,  1.94it/s, lr=0.000791, step_loss=0.0007/27/2023 18:39:16 - INFO - __main__ - train loss is 36.509338771225885\n",
      "Steps:  42%|▍| 6343/15000 [54:26<1:13:58,  1.95it/s, lr=0.000791, step_loss=0.0807/27/2023 18:39:16 - INFO - __main__ - train loss is 36.743159835459664\n",
      "Steps:  42%|▍| 6344/15000 [54:27<1:13:50,  1.95it/s, lr=0.000791, step_loss=0.2307/27/2023 18:39:17 - INFO - __main__ - train loss is 37.0269517947454\n",
      "Steps:  42%|▍| 6345/15000 [54:27<1:13:41,  1.96it/s, lr=0.000791, step_loss=0.2807/27/2023 18:39:17 - INFO - __main__ - train loss is 37.20232473802753\n",
      "Steps:  42%|▍| 6346/15000 [54:28<1:13:39,  1.96it/s, lr=0.000791, step_loss=0.1707/27/2023 18:39:18 - INFO - __main__ - train loss is 37.204518902115524\n",
      "Steps:  42%|▍| 6347/15000 [54:28<1:13:51,  1.95it/s, lr=0.000791, step_loss=0.0007/27/2023 18:39:18 - INFO - __main__ - train loss is 37.633296894840896\n",
      "Steps:  42%|▍| 6348/15000 [54:29<1:13:51,  1.95it/s, lr=0.000792, step_loss=0.4207/27/2023 18:39:19 - INFO - __main__ - train loss is 37.66932244505733\n",
      "Steps:  42%|▍| 6349/15000 [54:29<1:13:39,  1.96it/s, lr=0.000792, step_loss=0.0307/27/2023 18:39:19 - INFO - __main__ - train loss is 37.819897948764265\n",
      "Steps:  42%|▍| 6350/15000 [54:30<1:12:39,  1.98it/s, lr=0.000792, step_loss=0.1507/27/2023 18:39:20 - INFO - __main__ - train loss is 38.172643958590925\n",
      "Steps:  42%|▍| 6351/15000 [54:30<1:13:10,  1.97it/s, lr=0.000792, step_loss=0.3507/27/2023 18:39:20 - INFO - __main__ - train loss is 38.174293174175546\n",
      "Steps:  42%|▍| 6352/15000 [54:31<1:13:10,  1.97it/s, lr=0.000792, step_loss=0.0007/27/2023 18:39:21 - INFO - __main__ - train loss is 38.254033415345475\n",
      "Steps:  42%|▍| 6353/15000 [54:31<1:13:12,  1.97it/s, lr=0.000792, step_loss=0.0707/27/2023 18:39:21 - INFO - __main__ - train loss is 38.492094992427155\n",
      "Steps:  42%|▍| 6354/15000 [54:32<1:13:17,  1.97it/s, lr=0.000792, step_loss=0.2307/27/2023 18:39:22 - INFO - __main__ - train loss is 38.61287447693758\n",
      "Steps:  42%|▍| 6355/15000 [54:32<1:13:07,  1.97it/s, lr=0.000793, step_loss=0.1207/27/2023 18:39:22 - INFO - __main__ - train loss is 38.862883954076096\n",
      "Steps:  42%|▍| 6356/15000 [54:33<1:13:12,  1.97it/s, lr=0.000793, step_loss=0.2507/27/2023 18:39:23 - INFO - __main__ - train loss is 38.864923706511036\n",
      "Steps:  42%|▍| 6357/15000 [54:33<1:13:16,  1.97it/s, lr=0.000793, step_loss=0.0007/27/2023 18:39:23 - INFO - __main__ - train loss is 38.87555351876654\n",
      "Steps:  42%|▍| 6358/15000 [54:34<1:13:14,  1.97it/s, lr=0.000793, step_loss=0.0107/27/2023 18:39:24 - INFO - __main__ - train loss is 38.892121026525274\n",
      "Steps:  42%|▍| 6359/15000 [54:34<1:13:33,  1.96it/s, lr=0.000793, step_loss=0.0107/27/2023 18:39:24 - INFO - __main__ - train loss is 38.948797615477815\n",
      "Steps:  42%|▍| 6360/15000 [54:35<1:13:28,  1.96it/s, lr=0.000793, step_loss=0.0507/27/2023 18:39:25 - INFO - __main__ - train loss is 38.96035699383356\n",
      "Steps:  42%|▍| 6361/15000 [54:35<1:13:27,  1.96it/s, lr=0.000793, step_loss=0.0107/27/2023 18:39:25 - INFO - __main__ - train loss is 39.42985020414926\n",
      "Steps:  42%|▍| 6362/15000 [54:36<1:13:46,  1.95it/s, lr=0.000793, step_loss=0.4607/27/2023 18:39:26 - INFO - __main__ - train loss is 39.50066603557207\n",
      "Steps:  42%|▍| 6363/15000 [54:37<1:24:36,  1.70it/s, lr=0.000794, step_loss=0.0707/27/2023 18:39:27 - INFO - __main__ - Per validation step average loss is 0.03170575946569443\n",
      "07/27/2023 18:39:27 - INFO - __main__ - Cumulative validation average loss is 0.03170575946569443\n",
      "07/27/2023 18:39:28 - INFO - __main__ - Per validation step average loss is 0.20487070083618164\n",
      "07/27/2023 18:39:28 - INFO - __main__ - Cumulative validation average loss is 0.23657646030187607\n",
      "07/27/2023 18:39:28 - INFO - __main__ - Per validation step average loss is 0.004362968727946281\n",
      "07/27/2023 18:39:28 - INFO - __main__ - Cumulative validation average loss is 0.24093942902982235\n",
      "07/27/2023 18:39:29 - INFO - __main__ - Per validation step average loss is 0.15767937898635864\n",
      "07/27/2023 18:39:29 - INFO - __main__ - Cumulative validation average loss is 0.398618808016181\n",
      "07/27/2023 18:39:29 - INFO - __main__ - Per validation step average loss is 0.07044783234596252\n",
      "07/27/2023 18:39:29 - INFO - __main__ - Cumulative validation average loss is 0.4690666403621435\n",
      "07/27/2023 18:39:29 - INFO - __main__ - Per validation step average loss is 0.046200890094041824\n",
      "07/27/2023 18:39:29 - INFO - __main__ - Cumulative validation average loss is 0.5152675304561853\n",
      "07/27/2023 18:39:30 - INFO - __main__ - Per validation step average loss is 0.34174197912216187\n",
      "07/27/2023 18:39:30 - INFO - __main__ - Cumulative validation average loss is 0.8570095095783472\n",
      "07/27/2023 18:39:30 - INFO - __main__ - Per validation step average loss is 0.1481785774230957\n",
      "07/27/2023 18:39:30 - INFO - __main__ - Cumulative validation average loss is 1.005188087001443\n",
      "07/27/2023 18:39:31 - INFO - __main__ - Per validation step average loss is 0.06549008935689926\n",
      "07/27/2023 18:39:31 - INFO - __main__ - Cumulative validation average loss is 1.0706781763583422\n",
      "07/27/2023 18:39:31 - INFO - __main__ - Per validation step average loss is 0.06864243000745773\n",
      "07/27/2023 18:39:31 - INFO - __main__ - Cumulative validation average loss is 1.1393206063658\n",
      "07/27/2023 18:39:32 - INFO - __main__ - Per validation step average loss is 0.31898993253707886\n",
      "07/27/2023 18:39:32 - INFO - __main__ - Cumulative validation average loss is 1.4583105389028788\n",
      "07/27/2023 18:39:32 - INFO - __main__ - Per validation step average loss is 0.008523417636752129\n",
      "07/27/2023 18:39:32 - INFO - __main__ - Cumulative validation average loss is 1.466833956539631\n",
      "07/27/2023 18:39:32 - INFO - __main__ - Per validation step average loss is 0.3924519419670105\n",
      "07/27/2023 18:39:32 - INFO - __main__ - Cumulative validation average loss is 1.8592858985066414\n",
      "07/27/2023 18:39:33 - INFO - __main__ - Per validation step average loss is 0.0023116092197597027\n",
      "07/27/2023 18:39:33 - INFO - __main__ - Cumulative validation average loss is 1.861597507726401\n",
      "07/27/2023 18:39:33 - INFO - __main__ - Per validation step average loss is 0.017746221274137497\n",
      "07/27/2023 18:39:33 - INFO - __main__ - Cumulative validation average loss is 1.8793437290005386\n",
      "07/27/2023 18:39:34 - INFO - __main__ - Per validation step average loss is 0.3403417468070984\n",
      "07/27/2023 18:39:34 - INFO - __main__ - Cumulative validation average loss is 2.219685475807637\n",
      "07/27/2023 18:39:34 - INFO - __main__ - Per validation step average loss is 0.013496020808815956\n",
      "07/27/2023 18:39:34 - INFO - __main__ - Cumulative validation average loss is 2.233181496616453\n",
      "07/27/2023 18:39:35 - INFO - __main__ - Per validation step average loss is 0.0015028323978185654\n",
      "07/27/2023 18:39:35 - INFO - __main__ - Cumulative validation average loss is 2.2346843290142715\n",
      "07/27/2023 18:39:35 - INFO - __main__ - Per validation step average loss is 0.2644653618335724\n",
      "07/27/2023 18:39:35 - INFO - __main__ - Cumulative validation average loss is 2.499149690847844\n",
      "07/27/2023 18:39:35 - INFO - __main__ - Per validation step average loss is 0.0081863421946764\n",
      "07/27/2023 18:39:35 - INFO - __main__ - Cumulative validation average loss is 2.5073360330425203\n",
      "07/27/2023 18:39:36 - INFO - __main__ - Per validation step average loss is 0.019273510202765465\n",
      "07/27/2023 18:39:36 - INFO - __main__ - Cumulative validation average loss is 2.5266095432452857\n",
      "07/27/2023 18:39:36 - INFO - __main__ - Per validation step average loss is 0.02081751637160778\n",
      "07/27/2023 18:39:36 - INFO - __main__ - Cumulative validation average loss is 2.5474270596168935\n",
      "07/27/2023 18:39:37 - INFO - __main__ - Per validation step average loss is 0.003978092223405838\n",
      "07/27/2023 18:39:37 - INFO - __main__ - Cumulative validation average loss is 2.5514051518402994\n",
      "07/27/2023 18:39:37 - INFO - __main__ - Per validation step average loss is 0.17487144470214844\n",
      "07/27/2023 18:39:37 - INFO - __main__ - Cumulative validation average loss is 2.726276596542448\n",
      "07/27/2023 18:39:37 - INFO - __main__ - Per validation step average loss is 0.4282751679420471\n",
      "07/27/2023 18:39:37 - INFO - __main__ - Cumulative validation average loss is 3.154551764484495\n",
      "07/27/2023 18:39:38 - INFO - __main__ - Per validation step average loss is 0.029733700677752495\n",
      "07/27/2023 18:39:38 - INFO - __main__ - Cumulative validation average loss is 3.1842854651622474\n",
      "07/27/2023 18:39:38 - INFO - __main__ - Per validation step average loss is 0.0055905175395309925\n",
      "07/27/2023 18:39:38 - INFO - __main__ - Cumulative validation average loss is 3.1898759827017784\n",
      "07/27/2023 18:39:39 - INFO - __main__ - Per validation step average loss is 0.0017185917822644114\n",
      "07/27/2023 18:39:39 - INFO - __main__ - Cumulative validation average loss is 3.191594574484043\n",
      "07/27/2023 18:39:39 - INFO - __main__ - Per validation step average loss is 0.09572248160839081\n",
      "07/27/2023 18:39:39 - INFO - __main__ - Cumulative validation average loss is 3.2873170560924336\n",
      "07/27/2023 18:39:40 - INFO - __main__ - Per validation step average loss is 0.023400403559207916\n",
      "07/27/2023 18:39:40 - INFO - __main__ - Cumulative validation average loss is 3.3107174596516415\n",
      "07/27/2023 18:39:40 - INFO - __main__ - Per validation step average loss is 0.37861108779907227\n",
      "07/27/2023 18:39:40 - INFO - __main__ - Cumulative validation average loss is 3.689328547450714\n",
      "07/27/2023 18:39:40 - INFO - __main__ - Per validation step average loss is 0.30883339047431946\n",
      "07/27/2023 18:39:40 - INFO - __main__ - Cumulative validation average loss is 3.9981619379250333\n",
      "07/27/2023 18:39:41 - INFO - __main__ - Per validation step average loss is 0.16241982579231262\n",
      "07/27/2023 18:39:41 - INFO - __main__ - Cumulative validation average loss is 4.160581763717346\n",
      "07/27/2023 18:39:41 - INFO - __main__ - Per validation step average loss is 0.005794343538582325\n",
      "07/27/2023 18:39:41 - INFO - __main__ - Cumulative validation average loss is 4.166376107255928\n",
      "07/27/2023 18:39:42 - INFO - __main__ - Per validation step average loss is 0.12666821479797363\n",
      "07/27/2023 18:39:42 - INFO - __main__ - Cumulative validation average loss is 4.293044322053902\n",
      "07/27/2023 18:39:42 - INFO - __main__ - Per validation step average loss is 0.22264227271080017\n",
      "07/27/2023 18:39:42 - INFO - __main__ - Cumulative validation average loss is 4.515686594764702\n",
      "07/27/2023 18:39:42 - INFO - __main__ - Per validation step average loss is 0.0653354600071907\n",
      "07/27/2023 18:39:42 - INFO - __main__ - Cumulative validation average loss is 4.581022054771893\n",
      "07/27/2023 18:39:43 - INFO - __main__ - Per validation step average loss is 0.14564573764801025\n",
      "07/27/2023 18:39:43 - INFO - __main__ - Cumulative validation average loss is 4.726667792419903\n",
      "07/27/2023 18:39:43 - INFO - __main__ - Per validation step average loss is 0.002267864067107439\n",
      "07/27/2023 18:39:43 - INFO - __main__ - Cumulative validation average loss is 4.72893565648701\n",
      "07/27/2023 18:39:44 - INFO - __main__ - Per validation step average loss is 0.1161637008190155\n",
      "07/27/2023 18:39:44 - INFO - __main__ - Cumulative validation average loss is 4.845099357306026\n",
      "07/27/2023 18:39:44 - INFO - __main__ - Per validation step average loss is 0.02702990546822548\n",
      "07/27/2023 18:39:44 - INFO - __main__ - Cumulative validation average loss is 4.872129262774251\n",
      "07/27/2023 18:39:44 - INFO - __main__ - Per validation step average loss is 0.009827368892729282\n",
      "07/27/2023 18:39:44 - INFO - __main__ - Cumulative validation average loss is 4.881956631666981\n",
      "07/27/2023 18:39:45 - INFO - __main__ - Per validation step average loss is 0.10197223722934723\n",
      "07/27/2023 18:39:45 - INFO - __main__ - Cumulative validation average loss is 4.983928868896328\n",
      "07/27/2023 18:39:45 - INFO - __main__ - Per validation step average loss is 0.4084395170211792\n",
      "07/27/2023 18:39:45 - INFO - __main__ - Cumulative validation average loss is 5.392368385917507\n",
      "07/27/2023 18:39:46 - INFO - __main__ - Per validation step average loss is 0.002515406347811222\n",
      "07/27/2023 18:39:46 - INFO - __main__ - Cumulative validation average loss is 5.394883792265318\n",
      "07/27/2023 18:39:46 - INFO - __main__ - Per validation step average loss is 0.4442877173423767\n",
      "07/27/2023 18:39:46 - INFO - __main__ - Cumulative validation average loss is 5.839171509607695\n",
      "07/27/2023 18:39:47 - INFO - __main__ - Per validation step average loss is 0.1348554790019989\n",
      "07/27/2023 18:39:47 - INFO - __main__ - Cumulative validation average loss is 5.974026988609694\n",
      "07/27/2023 18:39:47 - INFO - __main__ - Per validation step average loss is 0.10206615179777145\n",
      "07/27/2023 18:39:47 - INFO - __main__ - Cumulative validation average loss is 6.076093140407465\n",
      "07/27/2023 18:39:47 - INFO - __main__ - Per validation step average loss is 0.5387246608734131\n",
      "07/27/2023 18:39:47 - INFO - __main__ - Cumulative validation average loss is 6.6148178012808785\n",
      "07/27/2023 18:39:48 - INFO - __main__ - Per validation step average loss is 0.01257891021668911\n",
      "07/27/2023 18:39:48 - INFO - __main__ - Cumulative validation average loss is 6.627396711497568\n",
      "07/27/2023 18:39:48 - INFO - __main__ - Per validation step average loss is 0.05113669112324715\n",
      "07/27/2023 18:39:48 - INFO - __main__ - Cumulative validation average loss is 6.678533402620815\n",
      "07/27/2023 18:39:49 - INFO - __main__ - Per validation step average loss is 0.001929168589413166\n",
      "07/27/2023 18:39:49 - INFO - __main__ - Cumulative validation average loss is 6.680462571210228\n",
      "07/27/2023 18:39:49 - INFO - __main__ - Per validation step average loss is 0.006683913059532642\n",
      "07/27/2023 18:39:49 - INFO - __main__ - Cumulative validation average loss is 6.6871464842697605\n",
      "07/27/2023 18:39:49 - INFO - __main__ - Per validation step average loss is 0.004179947543889284\n",
      "07/27/2023 18:39:49 - INFO - __main__ - Cumulative validation average loss is 6.69132643181365\n",
      "07/27/2023 18:39:50 - INFO - __main__ - Per validation step average loss is 0.21382471919059753\n",
      "07/27/2023 18:39:50 - INFO - __main__ - Cumulative validation average loss is 6.905151151004247\n",
      "07/27/2023 18:39:50 - INFO - __main__ - Per validation step average loss is 0.3521619141101837\n",
      "07/27/2023 18:39:50 - INFO - __main__ - Cumulative validation average loss is 7.257313065114431\n",
      "07/27/2023 18:39:51 - INFO - __main__ - Per validation step average loss is 0.5624087452888489\n",
      "07/27/2023 18:39:51 - INFO - __main__ - Cumulative validation average loss is 7.81972181040328\n",
      "07/27/2023 18:39:51 - INFO - __main__ - Per validation step average loss is 0.003057741792872548\n",
      "07/27/2023 18:39:51 - INFO - __main__ - Cumulative validation average loss is 7.8227795521961525\n",
      "07/27/2023 18:39:52 - INFO - __main__ - Per validation step average loss is 0.022023601457476616\n",
      "07/27/2023 18:39:52 - INFO - __main__ - Cumulative validation average loss is 7.844803153653629\n",
      "07/27/2023 18:39:52 - INFO - __main__ - Per validation step average loss is 0.05529974400997162\n",
      "07/27/2023 18:39:52 - INFO - __main__ - Cumulative validation average loss is 7.900102897663601\n",
      "07/27/2023 18:39:52 - INFO - __main__ - Per validation step average loss is 0.27608367800712585\n",
      "07/27/2023 18:39:52 - INFO - __main__ - Cumulative validation average loss is 8.176186575670727\n",
      "07/27/2023 18:39:53 - INFO - __main__ - Per validation step average loss is 0.6591560244560242\n",
      "07/27/2023 18:39:53 - INFO - __main__ - Cumulative validation average loss is 8.83534260012675\n",
      "07/27/2023 18:39:53 - INFO - __main__ - Per validation step average loss is 0.016000444069504738\n",
      "07/27/2023 18:39:53 - INFO - __main__ - Cumulative validation average loss is 8.851343044196256\n",
      "07/27/2023 18:39:54 - INFO - __main__ - Per validation step average loss is 0.00854085385799408\n",
      "07/27/2023 18:39:54 - INFO - __main__ - Cumulative validation average loss is 8.85988389805425\n",
      "07/27/2023 18:39:54 - INFO - __main__ - Per validation step average loss is 0.2848808765411377\n",
      "07/27/2023 18:39:54 - INFO - __main__ - Cumulative validation average loss is 9.144764774595387\n",
      "07/27/2023 18:39:55 - INFO - __main__ - Per validation step average loss is 0.048418574035167694\n",
      "07/27/2023 18:39:55 - INFO - __main__ - Cumulative validation average loss is 9.193183348630555\n",
      "07/27/2023 18:39:55 - INFO - __main__ - Per validation step average loss is 0.006758528761565685\n",
      "07/27/2023 18:39:55 - INFO - __main__ - Cumulative validation average loss is 9.19994187739212\n",
      "07/27/2023 18:39:55 - INFO - __main__ - Per validation step average loss is 0.3313683271408081\n",
      "07/27/2023 18:39:55 - INFO - __main__ - Cumulative validation average loss is 9.531310204532929\n",
      "07/27/2023 18:39:56 - INFO - __main__ - Per validation step average loss is 0.5083415508270264\n",
      "07/27/2023 18:39:56 - INFO - __main__ - Cumulative validation average loss is 10.039651755359955\n",
      "07/27/2023 18:39:56 - INFO - __main__ - Per validation step average loss is 0.06910908967256546\n",
      "07/27/2023 18:39:56 - INFO - __main__ - Cumulative validation average loss is 10.10876084503252\n",
      "07/27/2023 18:39:57 - INFO - __main__ - Per validation step average loss is 0.09455931931734085\n",
      "07/27/2023 18:39:57 - INFO - __main__ - Cumulative validation average loss is 10.203320164349861\n",
      "07/27/2023 18:39:57 - INFO - __main__ - Per validation step average loss is 0.12772123515605927\n",
      "07/27/2023 18:39:57 - INFO - __main__ - Cumulative validation average loss is 10.33104139950592\n",
      "07/27/2023 18:39:57 - INFO - __main__ - Per validation step average loss is 0.0023198225535452366\n",
      "07/27/2023 18:39:57 - INFO - __main__ - Cumulative validation average loss is 10.333361222059466\n",
      "07/27/2023 18:39:58 - INFO - __main__ - Per validation step average loss is 0.18475769460201263\n",
      "07/27/2023 18:39:58 - INFO - __main__ - Cumulative validation average loss is 10.518118916661479\n",
      "07/27/2023 18:39:58 - INFO - __main__ - Per validation step average loss is 0.05080382525920868\n",
      "07/27/2023 18:39:58 - INFO - __main__ - Cumulative validation average loss is 10.568922741920687\n",
      "07/27/2023 18:39:59 - INFO - __main__ - Per validation step average loss is 0.06225547194480896\n",
      "07/27/2023 18:39:59 - INFO - __main__ - Cumulative validation average loss is 10.631178213865496\n",
      "07/27/2023 18:39:59 - INFO - __main__ - Per validation step average loss is 0.12957462668418884\n",
      "07/27/2023 18:39:59 - INFO - __main__ - Cumulative validation average loss is 10.760752840549685\n",
      "07/27/2023 18:39:59 - INFO - __main__ - Per validation step average loss is 0.5723403096199036\n",
      "07/27/2023 18:39:59 - INFO - __main__ - Cumulative validation average loss is 11.333093150169589\n",
      "07/27/2023 18:40:00 - INFO - __main__ - Per validation step average loss is 0.597908616065979\n",
      "07/27/2023 18:40:00 - INFO - __main__ - Cumulative validation average loss is 11.931001766235568\n",
      "07/27/2023 18:40:00 - INFO - __main__ - Average validation loss for Epoch 20 is 0.15102533881310845\n",
      "07/27/2023 18:40:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:40:57 - INFO - __main__ - Starting epoch 21\n",
      "07/27/2023 18:40:58 - INFO - __main__ - train loss is 0.22959710657596588\n",
      "Steps:  42%|▍| 6364/15000 [56:08<66:57:27, 27.91s/it, lr=0.000794, step_loss=0.207/27/2023 18:40:58 - INFO - __main__ - train loss is 0.324424147605896\n",
      "Steps:  42%|▍| 6365/15000 [56:08<46:59:47, 19.59s/it, lr=0.000794, step_loss=0.007/27/2023 18:40:58 - INFO - __main__ - train loss is 0.37564950436353683\n",
      "Steps:  42%|▍| 6366/15000 [56:09<33:01:25, 13.77s/it, lr=0.000794, step_loss=0.007/27/2023 18:40:58 - INFO - __main__ - train loss is 0.38948025554418564\n",
      "Steps:  42%|▍| 6367/15000 [56:09<23:14:35,  9.69s/it, lr=0.000794, step_loss=0.007/27/2023 18:40:59 - INFO - __main__ - train loss is 0.39351880829781294\n",
      "Steps:  42%|▍| 6368/15000 [56:09<16:23:54,  6.84s/it, lr=0.000794, step_loss=0.007/27/2023 18:40:59 - INFO - __main__ - train loss is 0.40839356649667025\n",
      "Steps:  42%|▍| 6369/15000 [56:09<11:36:22,  4.84s/it, lr=0.000794, step_loss=0.007/27/2023 18:40:59 - INFO - __main__ - train loss is 0.40969879867043346\n",
      "Steps:  42%|▍| 6370/15000 [56:09<8:15:28,  3.44s/it, lr=0.000794, step_loss=0.0007/27/2023 18:40:59 - INFO - __main__ - train loss is 0.9119494700571522\n",
      "Steps:  42%|▍| 6371/15000 [56:09<5:54:47,  2.47s/it, lr=0.000794, step_loss=0.5007/27/2023 18:40:59 - INFO - __main__ - train loss is 1.5978636288782582\n",
      "Steps:  42%|▍| 6372/15000 [56:10<4:16:14,  1.78s/it, lr=0.000795, step_loss=0.6807/27/2023 18:41:00 - INFO - __main__ - train loss is 1.7408643955131993\n",
      "Steps:  42%|▍| 6373/15000 [56:10<3:07:15,  1.30s/it, lr=0.000795, step_loss=0.1407/27/2023 18:41:00 - INFO - __main__ - train loss is 1.8673066342016682\n",
      "Steps:  42%|▍| 6374/15000 [56:10<2:18:58,  1.03it/s, lr=0.000795, step_loss=0.1207/27/2023 18:41:00 - INFO - __main__ - train loss is 1.8698768810136244\n",
      "Steps:  42%|▍| 6375/15000 [56:10<1:45:08,  1.37it/s, lr=0.000795, step_loss=0.0007/27/2023 18:41:00 - INFO - __main__ - train loss is 1.92941793135833\n",
      "Steps:  43%|▍| 6376/15000 [56:10<1:21:25,  1.77it/s, lr=0.000795, step_loss=0.0507/27/2023 18:41:00 - INFO - __main__ - train loss is 2.0036291637225077\n",
      "Steps:  43%|▍| 6377/15000 [56:11<1:04:42,  2.22it/s, lr=0.000795, step_loss=0.0707/27/2023 18:41:00 - INFO - __main__ - train loss is 2.4291253843111917\n",
      "Steps:  43%|▍| 6378/15000 [56:11<53:15,  2.70it/s, lr=0.000795, step_loss=0.425]07/27/2023 18:41:01 - INFO - __main__ - train loss is 2.738203422049992\n",
      "Steps:  43%|▍| 6379/15000 [56:11<45:06,  3.18it/s, lr=0.000795, step_loss=0.309]07/27/2023 18:41:01 - INFO - __main__ - train loss is 2.7551693179411814\n",
      "Steps:  43%|▍| 6380/15000 [56:11<39:15,  3.66it/s, lr=0.000796, step_loss=0.017]07/27/2023 18:41:01 - INFO - __main__ - train loss is 2.77516324527096\n",
      "Steps:  43%|▊ | 6381/15000 [56:11<35:11,  4.08it/s, lr=0.000796, step_loss=0.02]07/27/2023 18:41:01 - INFO - __main__ - train loss is 2.794080012361519\n",
      "Steps:  43%|▍| 6382/15000 [56:11<32:20,  4.44it/s, lr=0.000796, step_loss=0.018907/27/2023 18:41:01 - INFO - __main__ - train loss is 2.8691416763467714\n",
      "Steps:  43%|▍| 6383/15000 [56:12<30:20,  4.73it/s, lr=0.000796, step_loss=0.075107/27/2023 18:41:02 - INFO - __main__ - train loss is 2.8734456141246483\n",
      "Steps:  43%|▍| 6384/15000 [56:12<29:16,  4.91it/s, lr=0.000796, step_loss=0.004307/27/2023 18:41:02 - INFO - __main__ - train loss is 3.089481308008544\n",
      "Steps:  43%|▍| 6385/15000 [56:12<28:17,  5.07it/s, lr=0.000796, step_loss=0.216]07/27/2023 18:41:02 - INFO - __main__ - train loss is 3.1019493414787576\n",
      "Steps:  43%|▍| 6386/15000 [56:12<27:45,  5.17it/s, lr=0.000796, step_loss=0.012507/27/2023 18:41:02 - INFO - __main__ - train loss is 3.2347486986545846\n",
      "Steps:  43%|▍| 6387/15000 [56:12<27:34,  5.21it/s, lr=0.000797, step_loss=0.133]07/27/2023 18:41:02 - INFO - __main__ - train loss is 3.251173175754957\n",
      "Steps:  43%|▍| 6388/15000 [56:13<27:17,  5.26it/s, lr=0.000797, step_loss=0.016407/27/2023 18:41:02 - INFO - __main__ - train loss is 3.259469114127569\n",
      "Steps:  43%|▍| 6389/15000 [56:13<26:53,  5.34it/s, lr=0.000797, step_loss=0.008307/27/2023 18:41:03 - INFO - __main__ - train loss is 3.266456448356621\n",
      "Steps:  43%|▍| 6390/15000 [56:13<26:47,  5.36it/s, lr=0.000797, step_loss=0.006907/27/2023 18:41:03 - INFO - __main__ - train loss is 3.5255674653453752\n",
      "Steps:  43%|▍| 6391/15000 [56:13<26:28,  5.42it/s, lr=0.000797, step_loss=0.259]07/27/2023 18:41:03 - INFO - __main__ - train loss is 3.5306778921512887\n",
      "Steps:  43%|▍| 6392/15000 [56:13<26:28,  5.42it/s, lr=0.000797, step_loss=0.005107/27/2023 18:41:03 - INFO - __main__ - train loss is 3.5532562675653026\n",
      "Steps:  43%|▍| 6393/15000 [56:14<26:19,  5.45it/s, lr=0.000797, step_loss=0.022607/27/2023 18:41:03 - INFO - __main__ - train loss is 3.6699165570316836\n",
      "Steps:  43%|▍| 6394/15000 [56:14<26:08,  5.49it/s, lr=0.000797, step_loss=0.117]07/27/2023 18:41:04 - INFO - __main__ - train loss is 3.6950842234073207\n",
      "Steps:  43%|▍| 6395/15000 [56:14<26:11,  5.47it/s, lr=0.000798, step_loss=0.025207/27/2023 18:41:04 - INFO - __main__ - train loss is 3.712891416507773\n",
      "Steps:  43%|▍| 6396/15000 [56:14<26:03,  5.50it/s, lr=0.000798, step_loss=0.017807/27/2023 18:41:04 - INFO - __main__ - train loss is 3.715178889106028\n",
      "Steps:  43%|▍| 6397/15000 [56:14<26:08,  5.49it/s, lr=0.000798, step_loss=0.002207/27/2023 18:41:04 - INFO - __main__ - train loss is 3.8241558194858953\n",
      "Steps:  43%|▍| 6398/15000 [56:14<26:07,  5.49it/s, lr=0.000798, step_loss=0.109]07/27/2023 18:41:04 - INFO - __main__ - train loss is 4.1154922366840765\n",
      "Steps:  43%|▍| 6399/15000 [56:15<25:59,  5.52it/s, lr=0.000798, step_loss=0.291]07/27/2023 18:41:04 - INFO - __main__ - train loss is 4.167830937425606\n",
      "Steps:  43%|▍| 6400/15000 [56:15<25:54,  5.53it/s, lr=0.000798, step_loss=0.052307/27/2023 18:41:05 - INFO - __main__ - train loss is 4.171819235081784\n",
      "Steps:  43%|▍| 6401/15000 [56:15<25:51,  5.54it/s, lr=0.000798, step_loss=0.003907/27/2023 18:41:05 - INFO - __main__ - train loss is 4.1767818870721385\n",
      "Steps:  43%|▍| 6402/15000 [56:15<26:03,  5.50it/s, lr=0.000798, step_loss=0.004907/27/2023 18:41:05 - INFO - __main__ - train loss is 4.1871121803997084\n",
      "Steps:  43%|▍| 6403/15000 [56:15<26:06,  5.49it/s, lr=0.000799, step_loss=0.010307/27/2023 18:41:05 - INFO - __main__ - train loss is 4.189804244204424\n",
      "Steps:  43%|▍| 6404/15000 [56:16<26:11,  5.47it/s, lr=0.000799, step_loss=0.002607/27/2023 18:41:05 - INFO - __main__ - train loss is 4.753062415285967\n",
      "Steps:  43%|▍| 6405/15000 [56:16<26:11,  5.47it/s, lr=0.000799, step_loss=0.563]07/27/2023 18:41:06 - INFO - __main__ - train loss is 4.9114070715149865\n",
      "Steps:  43%|▍| 6406/15000 [56:16<26:01,  5.50it/s, lr=0.000799, step_loss=0.158]07/27/2023 18:41:06 - INFO - __main__ - train loss is 5.225277263089083\n",
      "Steps:  43%|▍| 6407/15000 [56:16<26:11,  5.47it/s, lr=0.000799, step_loss=0.314]07/27/2023 18:41:06 - INFO - __main__ - train loss is 5.419142443104647\n",
      "Steps:  43%|▍| 6408/15000 [56:16<26:09,  5.47it/s, lr=0.000799, step_loss=0.194]07/27/2023 18:41:06 - INFO - __main__ - train loss is 5.450677174492739\n",
      "Steps:  43%|▍| 6409/15000 [56:16<26:01,  5.50it/s, lr=0.000799, step_loss=0.031507/27/2023 18:41:06 - INFO - __main__ - train loss is 5.5113206239184365\n",
      "Steps:  43%|▍| 6410/15000 [56:17<25:55,  5.52it/s, lr=0.000799, step_loss=0.060607/27/2023 18:41:06 - INFO - __main__ - train loss is 5.55994621233549\n",
      "Steps:  43%|▍| 6411/15000 [56:17<25:50,  5.54it/s, lr=0.000799, step_loss=0.048607/27/2023 18:41:07 - INFO - __main__ - train loss is 5.5671764923026785\n",
      "Steps:  43%|▍| 6412/15000 [56:17<25:50,  5.54it/s, lr=0.0008, step_loss=0.00723]07/27/2023 18:41:07 - INFO - __main__ - train loss is 5.571645277901553\n",
      "Steps:  43%|▍| 6413/15000 [56:17<25:46,  5.55it/s, lr=0.0008, step_loss=0.00447]07/27/2023 18:41:07 - INFO - __main__ - train loss is 5.63238745869603\n",
      "Steps:  43%|▊ | 6414/15000 [56:17<25:44,  5.56it/s, lr=0.0008, step_loss=0.0607]07/27/2023 18:41:07 - INFO - __main__ - train loss is 5.663555427803658\n",
      "Steps:  43%|▊ | 6415/15000 [56:17<25:42,  5.57it/s, lr=0.0008, step_loss=0.0312]07/27/2023 18:41:07 - INFO - __main__ - train loss is 6.266118689789437\n",
      "Steps:  43%|█▎ | 6416/15000 [56:18<25:41,  5.57it/s, lr=0.0008, step_loss=0.603]07/27/2023 18:41:08 - INFO - __main__ - train loss is 6.300471215858124\n",
      "Steps:  43%|▊ | 6417/15000 [56:18<25:40,  5.57it/s, lr=0.0008, step_loss=0.0344]07/27/2023 18:41:08 - INFO - __main__ - train loss is 6.322495741187595\n",
      "Steps:  43%|█▎ | 6418/15000 [56:18<25:54,  5.52it/s, lr=0.0008, step_loss=0.022]07/27/2023 18:41:08 - INFO - __main__ - train loss is 6.35985206568148\n",
      "Steps:  43%|▊ | 6419/15000 [56:18<26:03,  5.49it/s, lr=0.0008, step_loss=0.0374]07/27/2023 18:41:08 - INFO - __main__ - train loss is 6.37667305895593\n",
      "Steps:  43%|▍| 6420/15000 [56:18<25:54,  5.52it/s, lr=0.000801, step_loss=0.016807/27/2023 18:41:08 - INFO - __main__ - train loss is 6.378537055337802\n",
      "Steps:  43%|▍| 6421/15000 [56:19<26:04,  5.48it/s, lr=0.000801, step_loss=0.001807/27/2023 18:41:08 - INFO - __main__ - train loss is 6.437904112273827\n",
      "Steps:  43%|▍| 6422/15000 [56:19<26:00,  5.50it/s, lr=0.000801, step_loss=0.059407/27/2023 18:41:09 - INFO - __main__ - train loss is 6.715337865287438\n",
      "Steps:  43%|▍| 6423/15000 [56:19<26:07,  5.47it/s, lr=0.000801, step_loss=0.277]07/27/2023 18:41:09 - INFO - __main__ - train loss is 6.8224824669305235\n",
      "Steps:  43%|▍| 6424/15000 [56:19<26:03,  5.49it/s, lr=0.000801, step_loss=0.107]07/27/2023 18:41:09 - INFO - __main__ - train loss is 6.929293506080285\n",
      "Steps:  43%|▍| 6425/15000 [56:19<25:55,  5.51it/s, lr=0.000801, step_loss=0.107]07/27/2023 18:41:09 - INFO - __main__ - train loss is 7.2709154116455466\n",
      "Steps:  43%|▍| 6426/15000 [56:19<25:49,  5.53it/s, lr=0.000801, step_loss=0.342]07/27/2023 18:41:09 - INFO - __main__ - train loss is 7.779479705030099\n",
      "Steps:  43%|▍| 6427/15000 [56:20<25:45,  5.55it/s, lr=0.000802, step_loss=0.509]07/27/2023 18:41:10 - INFO - __main__ - train loss is 7.982649840647355\n",
      "Steps:  43%|▍| 6428/15000 [56:20<25:43,  5.56it/s, lr=0.000802, step_loss=0.203]07/27/2023 18:41:10 - INFO - __main__ - train loss is 8.01513782539405\n",
      "Steps:  43%|▍| 6429/15000 [56:20<25:40,  5.56it/s, lr=0.000802, step_loss=0.032507/27/2023 18:41:10 - INFO - __main__ - train loss is 8.080191049957648\n",
      "Steps:  43%|▍| 6430/15000 [56:20<25:41,  5.56it/s, lr=0.000802, step_loss=0.065107/27/2023 18:41:10 - INFO - __main__ - train loss is 8.515826676273718\n",
      "Steps:  43%|▍| 6431/15000 [56:20<25:40,  5.56it/s, lr=0.000802, step_loss=0.436]07/27/2023 18:41:10 - INFO - __main__ - train loss is 8.531808812404051\n",
      "Steps:  43%|▍| 6432/15000 [56:21<25:38,  5.57it/s, lr=0.000802, step_loss=0.016]07/27/2023 18:41:10 - INFO - __main__ - train loss is 8.599715028190985\n",
      "Steps:  43%|▍| 6433/15000 [56:21<25:36,  5.58it/s, lr=0.000802, step_loss=0.067907/27/2023 18:41:11 - INFO - __main__ - train loss is 8.607550024287775\n",
      "Steps:  43%|▍| 6434/15000 [56:21<25:38,  5.57it/s, lr=0.000802, step_loss=0.007807/27/2023 18:41:11 - INFO - __main__ - train loss is 8.762330039637163\n",
      "Steps:  43%|▍| 6435/15000 [56:21<25:37,  5.57it/s, lr=0.000803, step_loss=0.155]07/27/2023 18:41:11 - INFO - __main__ - train loss is 8.773987342836335\n",
      "Steps:  43%|▍| 6436/15000 [56:21<25:51,  5.52it/s, lr=0.000803, step_loss=0.011707/27/2023 18:41:11 - INFO - __main__ - train loss is 8.777016701875255\n",
      "Steps:  43%|▍| 6437/15000 [56:21<25:55,  5.50it/s, lr=0.000803, step_loss=0.003007/27/2023 18:41:11 - INFO - __main__ - train loss is 8.84777299570851\n",
      "Steps:  43%|▍| 6438/15000 [56:22<25:48,  5.53it/s, lr=0.000803, step_loss=0.070807/27/2023 18:41:12 - INFO - __main__ - train loss is 8.854436293011531\n",
      "Steps:  43%|▍| 6439/15000 [56:22<25:45,  5.54it/s, lr=0.000803, step_loss=0.006607/27/2023 18:41:12 - INFO - __main__ - train loss is 8.86662411945872\n",
      "Steps:  43%|▍| 6440/15000 [56:22<25:44,  5.54it/s, lr=0.000803, step_loss=0.012207/27/2023 18:41:12 - INFO - __main__ - train loss is 8.874435374280438\n",
      "Steps:  43%|▍| 6441/15000 [56:22<25:53,  5.51it/s, lr=0.000803, step_loss=0.007807/27/2023 18:41:12 - INFO - __main__ - train loss is 9.291369685670361\n",
      "Steps:  43%|▍| 6442/15000 [56:22<25:52,  5.51it/s, lr=0.000803, step_loss=0.417]07/27/2023 18:41:12 - INFO - __main__ - train loss is 9.305874922079965\n",
      "Steps:  43%|▍| 6443/15000 [56:23<25:46,  5.53it/s, lr=0.000803, step_loss=0.014507/27/2023 18:41:12 - INFO - __main__ - train loss is 9.311542178271338\n",
      "Steps:  43%|▍| 6444/15000 [56:23<25:46,  5.53it/s, lr=0.000804, step_loss=0.005607/27/2023 18:41:13 - INFO - __main__ - train loss is 9.55892604100518\n",
      "Steps:  43%|▍| 6445/15000 [56:23<25:44,  5.54it/s, lr=0.000804, step_loss=0.247]07/27/2023 18:41:13 - INFO - __main__ - train loss is 9.564265188528225\n",
      "Steps:  43%|▍| 6446/15000 [56:23<25:41,  5.55it/s, lr=0.000804, step_loss=0.005307/27/2023 18:41:13 - INFO - __main__ - train loss is 9.586639483226463\n",
      "Steps:  43%|▍| 6447/15000 [56:23<25:39,  5.56it/s, lr=0.000804, step_loss=0.022407/27/2023 18:41:13 - INFO - __main__ - train loss is 9.689169970108196\n",
      "Steps:  43%|▍| 6448/15000 [56:23<25:37,  5.56it/s, lr=0.000804, step_loss=0.103]07/27/2023 18:41:13 - INFO - __main__ - train loss is 9.704664314864203\n",
      "Steps:  43%|▍| 6449/15000 [56:24<25:36,  5.57it/s, lr=0.000804, step_loss=0.015507/27/2023 18:41:14 - INFO - __main__ - train loss is 9.848182673333213\n",
      "Steps:  43%|▍| 6450/15000 [56:24<25:34,  5.57it/s, lr=0.000804, step_loss=0.144]07/27/2023 18:41:14 - INFO - __main__ - train loss is 10.191406483529136\n",
      "Steps:  43%|▍| 6451/15000 [56:24<25:34,  5.57it/s, lr=0.000804, step_loss=0.343]07/27/2023 18:41:14 - INFO - __main__ - train loss is 10.193334570270963\n",
      "Steps:  43%|▍| 6452/15000 [56:24<25:33,  5.57it/s, lr=0.000805, step_loss=0.001907/27/2023 18:41:14 - INFO - __main__ - train loss is 10.302936909836717\n",
      "Steps:  43%|▊ | 6453/15000 [56:24<25:34,  5.57it/s, lr=0.000805, step_loss=0.11]07/27/2023 18:41:14 - INFO - __main__ - train loss is 10.364994878065772\n",
      "Steps:  43%|▍| 6454/15000 [56:25<25:33,  5.57it/s, lr=0.000805, step_loss=0.062107/27/2023 18:41:14 - INFO - __main__ - train loss is 10.579778606188484\n",
      "Steps:  43%|▍| 6455/15000 [56:25<25:33,  5.57it/s, lr=0.000805, step_loss=0.215]07/27/2023 18:41:15 - INFO - __main__ - train loss is 10.85198300529737\n",
      "Steps:  43%|▍| 6456/15000 [56:25<25:33,  5.57it/s, lr=0.000805, step_loss=0.272]07/27/2023 18:41:15 - INFO - __main__ - train loss is 10.853746727574617\n",
      "Steps:  43%|▍| 6457/15000 [56:25<25:32,  5.57it/s, lr=0.000805, step_loss=0.001707/27/2023 18:41:15 - INFO - __main__ - train loss is 10.856229006312788\n",
      "Steps:  43%|▍| 6458/15000 [56:25<25:32,  5.57it/s, lr=0.000805, step_loss=0.002407/27/2023 18:41:15 - INFO - __main__ - train loss is 11.06526569928974\n",
      "Steps:  43%|▍| 6459/15000 [56:25<25:31,  5.58it/s, lr=0.000806, step_loss=0.209]07/27/2023 18:41:15 - INFO - __main__ - train loss is 11.08500092010945\n",
      "Steps:  43%|▍| 6460/15000 [56:26<25:30,  5.58it/s, lr=0.000806, step_loss=0.019707/27/2023 18:41:15 - INFO - __main__ - train loss is 11.224122899584472\n",
      "Steps:  43%|▍| 6461/15000 [56:26<25:30,  5.58it/s, lr=0.000806, step_loss=0.139]07/27/2023 18:41:16 - INFO - __main__ - train loss is 11.328959505073726\n",
      "Steps:  43%|▍| 6462/15000 [56:26<25:29,  5.58it/s, lr=0.000806, step_loss=0.105]07/27/2023 18:41:16 - INFO - __main__ - train loss is 11.358484623022377\n",
      "Steps:  43%|▍| 6463/15000 [56:26<25:30,  5.58it/s, lr=0.000806, step_loss=0.029507/27/2023 18:41:16 - INFO - __main__ - train loss is 11.385846083052456\n",
      "Steps:  43%|▍| 6464/15000 [56:26<25:30,  5.58it/s, lr=0.000806, step_loss=0.027407/27/2023 18:41:16 - INFO - __main__ - train loss is 11.506230582483113\n",
      "Steps:  43%|▊ | 6465/15000 [56:27<25:29,  5.58it/s, lr=0.000806, step_loss=0.12]07/27/2023 18:41:16 - INFO - __main__ - train loss is 12.34204261470586\n",
      "Steps:  43%|▍| 6466/15000 [56:27<25:30,  5.58it/s, lr=0.000806, step_loss=0.836]07/27/2023 18:41:17 - INFO - __main__ - train loss is 12.394563873298466\n",
      "Steps:  43%|▍| 6467/15000 [56:27<25:30,  5.58it/s, lr=0.000807, step_loss=0.052507/27/2023 18:41:17 - INFO - __main__ - train loss is 12.570173700340092\n",
      "Steps:  43%|▍| 6468/15000 [56:27<25:29,  5.58it/s, lr=0.000807, step_loss=0.176]07/27/2023 18:41:17 - INFO - __main__ - train loss is 12.573805646970868\n",
      "Steps:  43%|▍| 6469/15000 [56:27<25:31,  5.57it/s, lr=0.000807, step_loss=0.003607/27/2023 18:41:17 - INFO - __main__ - train loss is 12.988706486299634\n",
      "Steps:  43%|▍| 6470/15000 [56:27<25:30,  5.57it/s, lr=0.000807, step_loss=0.415]07/27/2023 18:41:17 - INFO - __main__ - train loss is 12.990421940456145\n",
      "Steps:  43%|▍| 6471/15000 [56:28<25:30,  5.57it/s, lr=0.000807, step_loss=0.001707/27/2023 18:41:17 - INFO - __main__ - train loss is 13.082726296852343\n",
      "Steps:  43%|▍| 6472/15000 [56:28<25:29,  5.58it/s, lr=0.000807, step_loss=0.092307/27/2023 18:41:18 - INFO - __main__ - train loss is 13.494700905750506\n",
      "Steps:  43%|▍| 6473/15000 [56:28<25:30,  5.57it/s, lr=0.000807, step_loss=0.412]07/27/2023 18:41:18 - INFO - __main__ - train loss is 13.499191827955656\n",
      "Steps:  43%|▍| 6474/15000 [56:28<25:29,  5.57it/s, lr=0.000807, step_loss=0.004407/27/2023 18:41:18 - INFO - __main__ - train loss is 13.641826934996061\n",
      "Steps:  43%|▍| 6475/15000 [56:28<25:29,  5.57it/s, lr=0.000808, step_loss=0.143]07/27/2023 18:41:18 - INFO - __main__ - train loss is 13.683932617190294\n",
      "Steps:  43%|▍| 6476/15000 [56:28<25:29,  5.57it/s, lr=0.000808, step_loss=0.042107/27/2023 18:41:18 - INFO - __main__ - train loss is 13.707448834436946\n",
      "Steps:  43%|▍| 6477/15000 [56:29<25:29,  5.57it/s, lr=0.000808, step_loss=0.023507/27/2023 18:41:19 - INFO - __main__ - train loss is 13.864428797620349\n",
      "Steps:  43%|▍| 6478/15000 [56:29<25:28,  5.58it/s, lr=0.000808, step_loss=0.157]07/27/2023 18:41:19 - INFO - __main__ - train loss is 13.880337985116057\n",
      "Steps:  43%|▍| 6479/15000 [56:29<25:29,  5.57it/s, lr=0.000808, step_loss=0.015907/27/2023 18:41:19 - INFO - __main__ - train loss is 14.196196468430571\n",
      "Steps:  43%|▍| 6480/15000 [56:29<25:28,  5.57it/s, lr=0.000808, step_loss=0.316]07/27/2023 18:41:19 - INFO - __main__ - train loss is 14.408534603076987\n",
      "Steps:  43%|▍| 6481/15000 [56:29<25:28,  5.57it/s, lr=0.000808, step_loss=0.212]07/27/2023 18:41:19 - INFO - __main__ - train loss is 14.708597915130667\n",
      "Steps:  43%|█▎ | 6482/15000 [56:30<25:27,  5.58it/s, lr=0.000808, step_loss=0.3]07/27/2023 18:41:19 - INFO - __main__ - train loss is 14.711813713773154\n",
      "Steps:  43%|▍| 6483/15000 [56:30<25:58,  5.47it/s, lr=0.000808, step_loss=0.003207/27/2023 18:41:20 - INFO - __main__ - train loss is 14.780821319087408\n",
      "Steps:  43%|▍| 6484/15000 [56:30<29:32,  4.80it/s, lr=0.000809, step_loss=0.069]07/27/2023 18:41:20 - INFO - __main__ - train loss is 14.785956738865934\n",
      "Steps:  43%|▍| 6485/15000 [56:30<29:48,  4.76it/s, lr=0.000809, step_loss=0.005107/27/2023 18:41:20 - INFO - __main__ - train loss is 14.878457246697508\n",
      "Steps:  43%|▍| 6486/15000 [56:30<31:24,  4.52it/s, lr=0.000809, step_loss=0.092507/27/2023 18:41:20 - INFO - __main__ - train loss is 14.982071860111319\n",
      "Steps:  43%|▍| 6487/15000 [56:31<30:01,  4.73it/s, lr=0.000809, step_loss=0.104]07/27/2023 18:41:21 - INFO - __main__ - train loss is 15.13740284589585\n",
      "Steps:  43%|▍| 6488/15000 [56:31<28:50,  4.92it/s, lr=0.000809, step_loss=0.155]07/27/2023 18:41:21 - INFO - __main__ - train loss is 15.146110532223247\n",
      "Steps:  43%|▍| 6489/15000 [56:31<28:05,  5.05it/s, lr=0.000809, step_loss=0.008707/27/2023 18:41:21 - INFO - __main__ - train loss is 15.388443303643726\n",
      "Steps:  43%|▍| 6490/15000 [56:31<27:32,  5.15it/s, lr=0.000809, step_loss=0.242]07/27/2023 18:41:21 - INFO - __main__ - train loss is 15.779443455277942\n",
      "Steps:  43%|▍| 6491/15000 [56:31<27:20,  5.19it/s, lr=0.000809, step_loss=0.391]07/27/2023 18:41:21 - INFO - __main__ - train loss is 15.824249011813663\n",
      "Steps:  43%|▍| 6492/15000 [56:32<26:46,  5.30it/s, lr=0.00081, step_loss=0.0448]07/27/2023 18:41:21 - INFO - __main__ - train loss is 16.752897066413425\n",
      "Steps:  43%|▊ | 6493/15000 [56:32<26:35,  5.33it/s, lr=0.00081, step_loss=0.929]07/27/2023 18:41:22 - INFO - __main__ - train loss is 16.75867276394274\n",
      "Steps:  43%|▍| 6494/15000 [56:32<26:27,  5.36it/s, lr=0.00081, step_loss=0.0057807/27/2023 18:41:22 - INFO - __main__ - train loss is 17.13483940565493\n",
      "Steps:  43%|▊ | 6495/15000 [56:32<26:15,  5.40it/s, lr=0.00081, step_loss=0.376]07/27/2023 18:41:22 - INFO - __main__ - train loss is 17.696450879215263\n",
      "Steps:  43%|▊ | 6496/15000 [56:32<26:06,  5.43it/s, lr=0.00081, step_loss=0.562]07/27/2023 18:41:22 - INFO - __main__ - train loss is 17.896803011535667\n",
      "Steps:  43%|█▋  | 6497/15000 [56:33<26:00,  5.45it/s, lr=0.00081, step_loss=0.2]07/27/2023 18:41:22 - INFO - __main__ - train loss is 17.916833655326627\n",
      "Steps:  43%|█▎ | 6498/15000 [56:33<25:55,  5.47it/s, lr=0.00081, step_loss=0.02]07/27/2023 18:41:23 - INFO - __main__ - train loss is 18.026307733147405\n",
      "Steps:  43%|▍| 6499/15000 [56:33<25:52,  5.48it/s, lr=0.000811, step_loss=0.109]07/27/2023 18:41:23 - INFO - __main__ - train loss is 18.110215881257318\n",
      "Steps:  43%|▍| 6500/15000 [56:33<25:49,  5.49it/s, lr=0.000811, step_loss=0.109]07/27/2023 18:41:23 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-6500\n",
      "07/27/2023 18:41:23 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:41:23,324] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:41:23,328] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-6500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:41:23,328] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-6500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:41:23,335] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-6500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:41:23,335] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-6500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:41:23,341] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-6500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:41:23,342] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-6500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:41:23,342] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:41:23 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-6500/pytorch_model\n",
      "07/27/2023 18:41:23 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-6500/scheduler.bin\n",
      "07/27/2023 18:41:23 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-6500/random_states_0.pkl\n",
      "07/27/2023 18:41:23 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-6500\n",
      "Steps:  43%|▍| 6500/15000 [56:33<25:49,  5.49it/s, lr=0.000811, step_loss=0.083907/27/2023 18:41:23 - INFO - __main__ - train loss is 18.116568059078418\n",
      "Steps:  43%|▍| 6501/15000 [56:33<26:46,  5.29it/s, lr=0.000811, step_loss=0.006307/27/2023 18:41:23 - INFO - __main__ - train loss is 18.851809591404162\n",
      "Steps:  43%|▍| 6502/15000 [56:33<26:27,  5.35it/s, lr=0.000811, step_loss=0.735]07/27/2023 18:41:23 - INFO - __main__ - train loss is 18.87381746096071\n",
      "Steps:  43%|▍| 6503/15000 [56:34<26:14,  5.40it/s, lr=0.000811, step_loss=0.022]07/27/2023 18:41:23 - INFO - __main__ - train loss is 18.961705642170273\n",
      "Steps:  43%|▍| 6504/15000 [56:34<26:06,  5.42it/s, lr=0.000811, step_loss=0.087907/27/2023 18:41:24 - INFO - __main__ - train loss is 19.006473766989075\n",
      "Steps:  43%|▍| 6505/15000 [56:34<25:59,  5.45it/s, lr=0.000811, step_loss=0.044807/27/2023 18:41:24 - INFO - __main__ - train loss is 19.01723297254648\n",
      "Steps:  43%|▍| 6506/15000 [56:34<25:55,  5.46it/s, lr=0.000811, step_loss=0.010807/27/2023 18:41:24 - INFO - __main__ - train loss is 19.019618352060206\n",
      "Steps:  43%|▍| 6507/15000 [56:34<25:51,  5.47it/s, lr=0.000812, step_loss=0.002307/27/2023 18:41:24 - INFO - __main__ - train loss is 19.024476393242367\n",
      "Steps:  43%|▍| 6508/15000 [56:35<25:49,  5.48it/s, lr=0.000812, step_loss=0.004807/27/2023 18:41:24 - INFO - __main__ - train loss is 19.026633050176315\n",
      "Steps:  43%|▍| 6509/15000 [56:35<25:47,  5.49it/s, lr=0.000812, step_loss=0.002107/27/2023 18:41:25 - INFO - __main__ - train loss is 19.114664208027534\n",
      "Steps:  43%|▍| 6510/15000 [56:35<25:45,  5.49it/s, lr=0.000812, step_loss=0.088]07/27/2023 18:41:25 - INFO - __main__ - train loss is 19.28532246861141\n",
      "Steps:  43%|▍| 6511/15000 [56:35<25:45,  5.49it/s, lr=0.000812, step_loss=0.171]07/27/2023 18:41:25 - INFO - __main__ - train loss is 19.533110421034507\n",
      "Steps:  43%|▍| 6512/15000 [56:35<25:37,  5.52it/s, lr=0.000812, step_loss=0.248]07/27/2023 18:41:25 - INFO - __main__ - train loss is 19.93320713553112\n",
      "Steps:  43%|█▎ | 6513/15000 [56:35<25:31,  5.54it/s, lr=0.000812, step_loss=0.4]07/27/2023 18:41:25 - INFO - __main__ - train loss is 19.943459946545772\n",
      "Steps:  43%|▍| 6514/15000 [56:36<25:28,  5.55it/s, lr=0.000812, step_loss=0.010307/27/2023 18:41:25 - INFO - __main__ - train loss is 20.372846800717525\n",
      "Steps:  43%|▍| 6515/15000 [56:36<25:26,  5.56it/s, lr=0.000813, step_loss=0.429]07/27/2023 18:41:26 - INFO - __main__ - train loss is 20.374466032604687\n",
      "Steps:  43%|▍| 6516/15000 [56:36<25:24,  5.56it/s, lr=0.000813, step_loss=0.001607/27/2023 18:41:26 - INFO - __main__ - train loss is 20.594344586948864\n",
      "Steps:  43%|▊ | 6517/15000 [56:36<25:23,  5.57it/s, lr=0.000813, step_loss=0.22]07/27/2023 18:41:26 - INFO - __main__ - train loss is 20.77179682336282\n",
      "Steps:  43%|▍| 6518/15000 [56:36<25:22,  5.57it/s, lr=0.000813, step_loss=0.177]07/27/2023 18:41:26 - INFO - __main__ - train loss is 20.884265095810406\n",
      "Steps:  43%|▍| 6519/15000 [56:37<25:21,  5.57it/s, lr=0.000813, step_loss=0.112]07/27/2023 18:41:26 - INFO - __main__ - train loss is 21.046168760280125\n",
      "Steps:  43%|▍| 6520/15000 [56:37<25:21,  5.57it/s, lr=0.000813, step_loss=0.162]07/27/2023 18:41:27 - INFO - __main__ - train loss is 21.130429387907498\n",
      "Steps:  43%|▍| 6521/15000 [56:37<25:21,  5.57it/s, lr=0.000813, step_loss=0.084307/27/2023 18:41:27 - INFO - __main__ - train loss is 21.141100476379506\n",
      "Steps:  43%|▍| 6522/15000 [56:37<25:20,  5.57it/s, lr=0.000813, step_loss=0.010707/27/2023 18:41:27 - INFO - __main__ - train loss is 21.14671628677752\n",
      "Steps:  43%|▍| 6523/15000 [56:37<25:20,  5.58it/s, lr=0.000813, step_loss=0.005607/27/2023 18:41:27 - INFO - __main__ - train loss is 21.296848108409904\n",
      "Steps:  43%|▊ | 6524/15000 [56:37<25:32,  5.53it/s, lr=0.000814, step_loss=0.15]07/27/2023 18:41:27 - INFO - __main__ - train loss is 21.29833087977022\n",
      "Steps:  44%|▍| 6525/15000 [56:38<26:02,  5.42it/s, lr=0.000814, step_loss=0.001407/27/2023 18:41:27 - INFO - __main__ - train loss is 21.305681923404336\n",
      "Steps:  44%|▍| 6526/15000 [56:38<26:42,  5.29it/s, lr=0.000814, step_loss=0.007307/27/2023 18:41:28 - INFO - __main__ - train loss is 21.308398451190442\n",
      "Steps:  44%|▍| 6527/15000 [56:38<26:30,  5.33it/s, lr=0.000814, step_loss=0.002707/27/2023 18:41:28 - INFO - __main__ - train loss is 21.34685970423743\n",
      "Steps:  44%|▍| 6528/15000 [56:38<26:17,  5.37it/s, lr=0.000814, step_loss=0.038507/27/2023 18:41:28 - INFO - __main__ - train loss is 21.513463492970914\n",
      "Steps:  44%|▍| 6529/15000 [56:38<27:02,  5.22it/s, lr=0.000814, step_loss=0.167]07/27/2023 18:41:28 - INFO - __main__ - train loss is 21.555512267630547\n",
      "Steps:  44%|▍| 6530/15000 [56:39<27:09,  5.20it/s, lr=0.000814, step_loss=0.042]07/27/2023 18:41:28 - INFO - __main__ - train loss is 21.64897259650752\n",
      "Steps:  44%|▍| 6531/15000 [56:39<27:16,  5.18it/s, lr=0.000815, step_loss=0.093507/27/2023 18:41:29 - INFO - __main__ - train loss is 21.919730480294675\n",
      "Steps:  44%|▍| 6532/15000 [56:39<27:24,  5.15it/s, lr=0.000815, step_loss=0.271]07/27/2023 18:41:29 - INFO - __main__ - train loss is 22.467221673112363\n",
      "Steps:  44%|▍| 6533/15000 [56:39<27:25,  5.15it/s, lr=0.000815, step_loss=0.547]07/27/2023 18:41:29 - INFO - __main__ - train loss is 22.97006856976077\n",
      "Steps:  44%|▍| 6534/15000 [56:39<27:14,  5.18it/s, lr=0.000815, step_loss=0.503]07/27/2023 18:41:29 - INFO - __main__ - train loss is 23.026295709889382\n",
      "Steps:  44%|▍| 6535/15000 [56:40<27:19,  5.16it/s, lr=0.000815, step_loss=0.056207/27/2023 18:41:29 - INFO - __main__ - train loss is 23.20757009414956\n",
      "Steps:  44%|▍| 6536/15000 [56:40<27:25,  5.14it/s, lr=0.000815, step_loss=0.181]07/27/2023 18:41:30 - INFO - __main__ - train loss is 23.220863265451044\n",
      "Steps:  44%|▍| 6537/15000 [56:40<27:31,  5.12it/s, lr=0.000815, step_loss=0.013307/27/2023 18:41:30 - INFO - __main__ - train loss is 23.38723395531997\n",
      "Steps:  44%|▍| 6538/15000 [56:40<27:33,  5.12it/s, lr=0.000815, step_loss=0.166]07/27/2023 18:41:30 - INFO - __main__ - train loss is 23.909158331807703\n",
      "Steps:  44%|▍| 6539/15000 [56:40<27:32,  5.12it/s, lr=0.000816, step_loss=0.522]07/27/2023 18:41:30 - INFO - __main__ - train loss is 23.9778586900793\n",
      "Steps:  44%|▍| 6540/15000 [56:41<27:31,  5.12it/s, lr=0.000816, step_loss=0.068707/27/2023 18:41:30 - INFO - __main__ - train loss is 24.020094589795917\n",
      "Steps:  44%|▍| 6541/15000 [56:41<27:29,  5.13it/s, lr=0.000816, step_loss=0.042207/27/2023 18:41:31 - INFO - __main__ - train loss is 24.05395664414391\n",
      "Steps:  44%|▍| 6542/15000 [56:41<27:29,  5.13it/s, lr=0.000816, step_loss=0.033907/27/2023 18:41:31 - INFO - __main__ - train loss is 24.10134700825438\n",
      "Steps:  44%|▍| 6543/15000 [56:41<27:30,  5.13it/s, lr=0.000816, step_loss=0.047407/27/2023 18:41:31 - INFO - __main__ - train loss is 24.12914360826835\n",
      "Steps:  44%|▍| 6544/15000 [56:41<27:28,  5.13it/s, lr=0.000816, step_loss=0.027807/27/2023 18:41:31 - INFO - __main__ - train loss is 24.62711997097358\n",
      "Steps:  44%|▍| 6545/15000 [56:41<27:28,  5.13it/s, lr=0.000816, step_loss=0.498]07/27/2023 18:41:31 - INFO - __main__ - train loss is 24.629382574697956\n",
      "Steps:  44%|▍| 6546/15000 [56:42<27:28,  5.13it/s, lr=0.000816, step_loss=0.002207/27/2023 18:41:32 - INFO - __main__ - train loss is 24.644778781337664\n",
      "Steps:  44%|▍| 6547/15000 [56:42<27:28,  5.13it/s, lr=0.000817, step_loss=0.015407/27/2023 18:41:32 - INFO - __main__ - train loss is 24.647031277650967\n",
      "Steps:  44%|▍| 6548/15000 [56:42<27:28,  5.13it/s, lr=0.000817, step_loss=0.002207/27/2023 18:41:32 - INFO - __main__ - train loss is 25.033112287754193\n",
      "Steps:  44%|▍| 6549/15000 [56:42<27:31,  5.12it/s, lr=0.000817, step_loss=0.386]07/27/2023 18:41:32 - INFO - __main__ - train loss is 25.037563843419775\n",
      "Steps:  44%|▍| 6550/15000 [56:42<27:56,  5.04it/s, lr=0.000817, step_loss=0.004407/27/2023 18:41:32 - INFO - __main__ - train loss is 25.09633427648805\n",
      "Steps:  44%|▍| 6551/15000 [56:43<27:50,  5.06it/s, lr=0.000817, step_loss=0.058807/27/2023 18:41:33 - INFO - __main__ - train loss is 25.15112338750623\n",
      "Steps:  44%|▍| 6552/15000 [56:43<27:42,  5.08it/s, lr=0.000817, step_loss=0.054807/27/2023 18:41:33 - INFO - __main__ - train loss is 25.17114075436257\n",
      "Steps:  44%|▊ | 6553/15000 [56:43<27:33,  5.11it/s, lr=0.000817, step_loss=0.02]07/27/2023 18:41:33 - INFO - __main__ - train loss is 25.486199879786\n",
      "Steps:  44%|▍| 6554/15000 [56:43<27:10,  5.18it/s, lr=0.000817, step_loss=0.315]07/27/2023 18:41:33 - INFO - __main__ - train loss is 25.582667046925053\n",
      "Steps:  44%|▍| 6555/15000 [56:43<26:36,  5.29it/s, lr=0.000817, step_loss=0.096507/27/2023 18:41:33 - INFO - __main__ - train loss is 25.58988055610098\n",
      "Steps:  44%|▍| 6556/15000 [56:44<26:17,  5.35it/s, lr=0.000818, step_loss=0.007207/27/2023 18:41:33 - INFO - __main__ - train loss is 25.59423842956312\n",
      "Steps:  44%|▍| 6557/15000 [56:44<26:09,  5.38it/s, lr=0.000818, step_loss=0.004307/27/2023 18:41:34 - INFO - __main__ - train loss is 25.5968475996051\n",
      "Steps:  44%|▍| 6558/15000 [56:44<25:52,  5.44it/s, lr=0.000818, step_loss=0.002607/27/2023 18:41:34 - INFO - __main__ - train loss is 25.65288714156486\n",
      "Steps:  44%|▍| 6559/15000 [56:44<25:44,  5.46it/s, lr=0.000818, step_loss=0.056]07/27/2023 18:41:34 - INFO - __main__ - train loss is 25.78551716194488\n",
      "Steps:  44%|▍| 6560/15000 [56:44<25:36,  5.49it/s, lr=0.000818, step_loss=0.133]07/27/2023 18:41:34 - INFO - __main__ - train loss is 25.792847354197875\n",
      "Steps:  44%|▍| 6561/15000 [56:45<25:39,  5.48it/s, lr=0.000818, step_loss=0.007307/27/2023 18:41:34 - INFO - __main__ - train loss is 25.867177698994055\n",
      "Steps:  44%|▍| 6562/15000 [56:45<25:31,  5.51it/s, lr=0.000818, step_loss=0.074307/27/2023 18:41:35 - INFO - __main__ - train loss is 25.93865915038623\n",
      "Steps:  44%|▍| 6563/15000 [56:45<25:28,  5.52it/s, lr=0.000819, step_loss=0.071507/27/2023 18:41:35 - INFO - __main__ - train loss is 26.09459314146079\n",
      "Steps:  44%|▍| 6564/15000 [56:45<25:25,  5.53it/s, lr=0.000819, step_loss=0.156]07/27/2023 18:41:35 - INFO - __main__ - train loss is 26.394269321346655\n",
      "Steps:  44%|█▎ | 6565/15000 [56:45<25:21,  5.54it/s, lr=0.000819, step_loss=0.3]07/27/2023 18:41:35 - INFO - __main__ - train loss is 27.061983559513465\n",
      "Steps:  44%|▍| 6566/15000 [56:45<25:21,  5.54it/s, lr=0.000819, step_loss=0.668]07/27/2023 18:41:35 - INFO - __main__ - train loss is 27.423919651890174\n",
      "Steps:  44%|▍| 6567/15000 [56:46<25:18,  5.55it/s, lr=0.000819, step_loss=0.362]07/27/2023 18:41:35 - INFO - __main__ - train loss is 27.924514923477545\n",
      "Steps:  44%|▍| 6568/15000 [56:46<25:20,  5.55it/s, lr=0.000819, step_loss=0.501]07/27/2023 18:41:36 - INFO - __main__ - train loss is 27.93756584939547\n",
      "Steps:  44%|▍| 6569/15000 [56:46<25:17,  5.56it/s, lr=0.000819, step_loss=0.013107/27/2023 18:41:36 - INFO - __main__ - train loss is 27.94650457543321\n",
      "Steps:  44%|▍| 6570/15000 [56:46<25:17,  5.56it/s, lr=0.000819, step_loss=0.008907/27/2023 18:41:36 - INFO - __main__ - train loss is 27.968888513045385\n",
      "Steps:  44%|▍| 6571/15000 [56:46<25:17,  5.56it/s, lr=0.00082, step_loss=0.0224]07/27/2023 18:41:36 - INFO - __main__ - train loss is 28.718270651297644\n",
      "Steps:  44%|▉ | 6572/15000 [56:46<25:15,  5.56it/s, lr=0.00082, step_loss=0.749]07/27/2023 18:41:36 - INFO - __main__ - train loss is 29.092636755900458\n",
      "Steps:  44%|▉ | 6573/15000 [56:47<25:17,  5.55it/s, lr=0.00082, step_loss=0.374]07/27/2023 18:41:37 - INFO - __main__ - train loss is 29.095246255164966\n",
      "Steps:  44%|▍| 6574/15000 [56:47<25:14,  5.56it/s, lr=0.00082, step_loss=0.0026107/27/2023 18:41:37 - INFO - __main__ - train loss is 29.098281581653282\n",
      "Steps:  44%|▍| 6575/15000 [56:47<25:13,  5.57it/s, lr=0.00082, step_loss=0.0030407/27/2023 18:41:37 - INFO - __main__ - train loss is 29.176763717783615\n",
      "Steps:  44%|▍| 6576/15000 [56:47<25:12,  5.57it/s, lr=0.00082, step_loss=0.0785]07/27/2023 18:41:37 - INFO - __main__ - train loss is 29.26603450323455\n",
      "Steps:  44%|▍| 6577/15000 [56:47<25:13,  5.56it/s, lr=0.00082, step_loss=0.0893]07/27/2023 18:41:37 - INFO - __main__ - train loss is 29.2938066131901\n",
      "Steps:  44%|▍| 6578/15000 [56:48<25:14,  5.56it/s, lr=0.00082, step_loss=0.0278]07/27/2023 18:41:37 - INFO - __main__ - train loss is 29.316219399450347\n",
      "Steps:  44%|▍| 6579/15000 [56:48<25:13,  5.56it/s, lr=0.000821, step_loss=0.022407/27/2023 18:41:38 - INFO - __main__ - train loss is 29.548438052413985\n",
      "Steps:  44%|▍| 6580/15000 [56:48<25:13,  5.56it/s, lr=0.000821, step_loss=0.232]07/27/2023 18:41:38 - INFO - __main__ - train loss is 29.600823472021148\n",
      "Steps:  44%|▍| 6581/15000 [56:48<25:12,  5.57it/s, lr=0.000821, step_loss=0.052407/27/2023 18:41:38 - INFO - __main__ - train loss is 29.605002891039476\n",
      "Steps:  44%|▍| 6582/15000 [56:48<25:12,  5.56it/s, lr=0.000821, step_loss=0.004107/27/2023 18:41:38 - INFO - __main__ - train loss is 29.614356422564015\n",
      "Steps:  44%|▍| 6583/15000 [56:48<25:13,  5.56it/s, lr=0.000821, step_loss=0.009307/27/2023 18:41:38 - INFO - __main__ - train loss is 29.665462659439072\n",
      "Steps:  44%|▍| 6584/15000 [56:49<25:12,  5.56it/s, lr=0.000821, step_loss=0.051107/27/2023 18:41:39 - INFO - __main__ - train loss is 29.734832579037175\n",
      "Steps:  44%|▍| 6585/15000 [56:49<25:11,  5.57it/s, lr=0.000821, step_loss=0.069407/27/2023 18:41:39 - INFO - __main__ - train loss is 29.87330319895409\n",
      "Steps:  44%|▍| 6586/15000 [56:49<25:14,  5.56it/s, lr=0.000821, step_loss=0.138]07/27/2023 18:41:39 - INFO - __main__ - train loss is 29.88254048465751\n",
      "Steps:  44%|▍| 6587/15000 [56:49<25:12,  5.56it/s, lr=0.000822, step_loss=0.009207/27/2023 18:41:39 - INFO - __main__ - train loss is 29.894092362141237\n",
      "Steps:  44%|▍| 6588/15000 [56:49<25:11,  5.57it/s, lr=0.000822, step_loss=0.011607/27/2023 18:41:39 - INFO - __main__ - train loss is 30.014166351174936\n",
      "Steps:  44%|▉ | 6589/15000 [56:50<25:10,  5.57it/s, lr=0.000822, step_loss=0.12]07/27/2023 18:41:39 - INFO - __main__ - train loss is 30.125064994907007\n",
      "Steps:  44%|▍| 6590/15000 [56:50<25:09,  5.57it/s, lr=0.000822, step_loss=0.111]07/27/2023 18:41:40 - INFO - __main__ - train loss is 30.530649926280603\n",
      "Steps:  44%|▍| 6591/15000 [56:50<25:09,  5.57it/s, lr=0.000822, step_loss=0.406]07/27/2023 18:41:40 - INFO - __main__ - train loss is 30.54564588307403\n",
      "Steps:  44%|▍| 6592/15000 [56:50<25:09,  5.57it/s, lr=0.000822, step_loss=0.015]07/27/2023 18:41:40 - INFO - __main__ - train loss is 31.02892800210975\n",
      "Steps:  44%|▍| 6593/15000 [56:50<25:08,  5.57it/s, lr=0.000822, step_loss=0.483]07/27/2023 18:41:40 - INFO - __main__ - train loss is 31.186908980598673\n",
      "Steps:  44%|▍| 6594/15000 [56:50<25:07,  5.58it/s, lr=0.000822, step_loss=0.158]07/27/2023 18:41:40 - INFO - __main__ - train loss is 31.510106524219736\n",
      "Steps:  44%|▍| 6595/15000 [56:51<25:06,  5.58it/s, lr=0.000822, step_loss=0.323]07/27/2023 18:41:40 - INFO - __main__ - train loss is 31.65569612919353\n",
      "Steps:  44%|▍| 6596/15000 [56:51<25:05,  5.58it/s, lr=0.000823, step_loss=0.146]07/27/2023 18:41:41 - INFO - __main__ - train loss is 31.69294158159755\n",
      "Steps:  44%|▍| 6597/15000 [56:51<25:06,  5.58it/s, lr=0.000823, step_loss=0.037207/27/2023 18:41:41 - INFO - __main__ - train loss is 31.930968975415453\n",
      "Steps:  44%|▍| 6598/15000 [56:51<25:08,  5.57it/s, lr=0.000823, step_loss=0.238]07/27/2023 18:41:41 - INFO - __main__ - train loss is 32.04322559922002\n",
      "Steps:  44%|▍| 6599/15000 [56:51<25:07,  5.57it/s, lr=0.000823, step_loss=0.112]07/27/2023 18:41:41 - INFO - __main__ - train loss is 32.063021924113855\n",
      "Steps:  44%|▍| 6600/15000 [56:52<25:07,  5.57it/s, lr=0.000823, step_loss=0.019807/27/2023 18:41:41 - INFO - __main__ - train loss is 32.080956540768966\n",
      "Steps:  44%|▍| 6601/15000 [56:52<25:18,  5.53it/s, lr=0.000823, step_loss=0.017907/27/2023 18:41:42 - INFO - __main__ - train loss is 32.12653662241064\n",
      "Steps:  44%|▍| 6602/15000 [56:52<25:14,  5.55it/s, lr=0.000823, step_loss=0.045607/27/2023 18:41:42 - INFO - __main__ - train loss is 32.37172032869421\n",
      "Steps:  44%|▍| 6603/15000 [56:52<25:11,  5.56it/s, lr=0.000824, step_loss=0.245]07/27/2023 18:41:42 - INFO - __main__ - train loss is 32.3745015503373\n",
      "Steps:  44%|▍| 6604/15000 [56:52<25:08,  5.57it/s, lr=0.000824, step_loss=0.002707/27/2023 18:41:42 - INFO - __main__ - train loss is 32.62873666896485\n",
      "Steps:  44%|▍| 6605/15000 [56:52<25:07,  5.57it/s, lr=0.000824, step_loss=0.254]07/27/2023 18:41:42 - INFO - __main__ - train loss is 32.63208735152148\n",
      "Steps:  44%|▍| 6606/15000 [56:53<25:05,  5.58it/s, lr=0.000824, step_loss=0.003307/27/2023 18:41:42 - INFO - __main__ - train loss is 32.65403262502514\n",
      "Steps:  44%|▍| 6607/15000 [56:53<25:04,  5.58it/s, lr=0.000824, step_loss=0.021907/27/2023 18:41:43 - INFO - __main__ - train loss is 32.71078244573437\n",
      "Steps:  44%|▍| 6608/15000 [56:53<25:04,  5.58it/s, lr=0.000824, step_loss=0.056707/27/2023 18:41:43 - INFO - __main__ - train loss is 32.72241522069089\n",
      "Steps:  44%|▍| 6609/15000 [56:53<25:03,  5.58it/s, lr=0.000824, step_loss=0.011607/27/2023 18:41:43 - INFO - __main__ - train loss is 32.86201668973081\n",
      "Steps:  44%|▉ | 6610/15000 [56:53<25:13,  5.54it/s, lr=0.000824, step_loss=0.14]07/27/2023 18:41:43 - INFO - __main__ - train loss is 32.87272431771271\n",
      "Steps:  44%|▍| 6611/15000 [56:53<25:10,  5.55it/s, lr=0.000825, step_loss=0.010707/27/2023 18:41:43 - INFO - __main__ - train loss is 32.98205972532742\n",
      "Steps:  44%|▍| 6612/15000 [56:54<25:22,  5.51it/s, lr=0.000825, step_loss=0.109]07/27/2023 18:41:44 - INFO - __main__ - train loss is 33.36129403929226\n",
      "Steps:  44%|▍| 6613/15000 [56:54<25:24,  5.50it/s, lr=0.000825, step_loss=0.379]07/27/2023 18:41:44 - INFO - __main__ - train loss is 33.36439395486377\n",
      "Steps:  44%|▍| 6614/15000 [56:54<25:25,  5.50it/s, lr=0.000825, step_loss=0.003107/27/2023 18:41:44 - INFO - __main__ - train loss is 33.60875684558414\n",
      "Steps:  44%|▍| 6615/15000 [56:54<25:18,  5.52it/s, lr=0.000825, step_loss=0.244]07/27/2023 18:41:44 - INFO - __main__ - train loss is 33.63406229368411\n",
      "Steps:  44%|▍| 6616/15000 [56:54<25:14,  5.54it/s, lr=0.000825, step_loss=0.025307/27/2023 18:41:44 - INFO - __main__ - train loss is 33.66538814804517\n",
      "Steps:  44%|▍| 6617/15000 [56:55<25:21,  5.51it/s, lr=0.000825, step_loss=0.031307/27/2023 18:41:44 - INFO - __main__ - train loss is 33.84193490049802\n",
      "Steps:  44%|▍| 6618/15000 [56:55<25:16,  5.53it/s, lr=0.000825, step_loss=0.177]07/27/2023 18:41:45 - INFO - __main__ - train loss is 33.94857869646512\n",
      "Steps:  44%|▍| 6619/15000 [56:55<25:13,  5.54it/s, lr=0.000826, step_loss=0.107]07/27/2023 18:41:45 - INFO - __main__ - train loss is 34.21159614226781\n",
      "Steps:  44%|▍| 6620/15000 [56:55<25:11,  5.55it/s, lr=0.000826, step_loss=0.263]07/27/2023 18:41:45 - INFO - __main__ - train loss is 34.26302573434077\n",
      "Steps:  44%|▍| 6621/15000 [56:55<25:08,  5.55it/s, lr=0.000826, step_loss=0.051407/27/2023 18:41:45 - INFO - __main__ - train loss is 34.26528966263868\n",
      "Steps:  44%|▍| 6622/15000 [56:55<25:09,  5.55it/s, lr=0.000826, step_loss=0.002207/27/2023 18:41:45 - INFO - __main__ - train loss is 34.27570155472495\n",
      "Steps:  44%|▍| 6623/15000 [56:56<25:07,  5.56it/s, lr=0.000826, step_loss=0.010407/27/2023 18:41:46 - INFO - __main__ - train loss is 34.291457724059\n",
      "Steps:  44%|▍| 6624/15000 [56:56<25:07,  5.55it/s, lr=0.000826, step_loss=0.015807/27/2023 18:41:46 - INFO - __main__ - train loss is 34.30443124403246\n",
      "Steps:  44%|▍| 6625/15000 [56:56<25:06,  5.56it/s, lr=0.000826, step_loss=0.013]07/27/2023 18:41:46 - INFO - __main__ - train loss is 34.39129501511343\n",
      "Steps:  44%|▍| 6626/15000 [56:56<25:06,  5.56it/s, lr=0.000826, step_loss=0.086907/27/2023 18:41:46 - INFO - __main__ - train loss is 34.50524216820486\n",
      "Steps:  44%|▍| 6627/15000 [56:56<25:06,  5.56it/s, lr=0.000826, step_loss=0.114]07/27/2023 18:41:46 - INFO - __main__ - train loss is 34.50840391567908\n",
      "Steps:  44%|▍| 6628/15000 [56:57<25:04,  5.57it/s, lr=0.000827, step_loss=0.003107/27/2023 18:41:46 - INFO - __main__ - train loss is 34.625276926672086\n",
      "Steps:  44%|▍| 6629/15000 [56:57<25:05,  5.56it/s, lr=0.000827, step_loss=0.117]07/27/2023 18:41:47 - INFO - __main__ - train loss is 34.64890504977666\n",
      "Steps:  44%|▍| 6630/15000 [56:57<25:04,  5.56it/s, lr=0.000827, step_loss=0.023607/27/2023 18:41:47 - INFO - __main__ - train loss is 34.693526446586475\n",
      "Steps:  44%|▍| 6631/15000 [56:57<25:03,  5.57it/s, lr=0.000827, step_loss=0.044607/27/2023 18:41:47 - INFO - __main__ - train loss is 34.96097844815813\n",
      "Steps:  44%|▍| 6632/15000 [56:57<25:02,  5.57it/s, lr=0.000827, step_loss=0.267]07/27/2023 18:41:47 - INFO - __main__ - train loss is 34.96334070363082\n",
      "Steps:  44%|▍| 6633/15000 [56:57<25:02,  5.57it/s, lr=0.000827, step_loss=0.002307/27/2023 18:41:47 - INFO - __main__ - train loss is 34.9663227905985\n",
      "Steps:  44%|▍| 6634/15000 [56:58<25:01,  5.57it/s, lr=0.000827, step_loss=0.002907/27/2023 18:41:48 - INFO - __main__ - train loss is 35.13248732290231\n",
      "Steps:  44%|▍| 6635/15000 [56:58<25:00,  5.57it/s, lr=0.000828, step_loss=0.166]07/27/2023 18:41:48 - INFO - __main__ - train loss is 35.140909902518615\n",
      "Steps:  44%|▍| 6636/15000 [56:58<25:00,  5.57it/s, lr=0.000828, step_loss=0.008407/27/2023 18:41:48 - INFO - __main__ - train loss is 35.25276195979677\n",
      "Steps:  44%|▍| 6637/15000 [56:58<25:01,  5.57it/s, lr=0.000828, step_loss=0.112]07/27/2023 18:41:48 - INFO - __main__ - train loss is 35.324556804960594\n",
      "Steps:  44%|▍| 6638/15000 [56:58<25:01,  5.57it/s, lr=0.000828, step_loss=0.071807/27/2023 18:41:48 - INFO - __main__ - train loss is 35.54646451002918\n",
      "Steps:  44%|▍| 6639/15000 [56:59<25:00,  5.57it/s, lr=0.000828, step_loss=0.222]07/27/2023 18:41:48 - INFO - __main__ - train loss is 35.605330146616325\n",
      "Steps:  44%|▍| 6640/15000 [56:59<24:59,  5.58it/s, lr=0.000828, step_loss=0.058907/27/2023 18:41:49 - INFO - __main__ - train loss is 35.62083857669495\n",
      "Steps:  44%|▍| 6641/15000 [56:59<24:58,  5.58it/s, lr=0.000828, step_loss=0.015507/27/2023 18:41:49 - INFO - __main__ - train loss is 35.91988446726464\n",
      "Steps:  44%|▍| 6642/15000 [56:59<25:00,  5.57it/s, lr=0.000828, step_loss=0.299]07/27/2023 18:41:49 - INFO - __main__ - train loss is 36.173921251436695\n",
      "Steps:  44%|▍| 6643/15000 [56:59<25:07,  5.55it/s, lr=0.000829, step_loss=0.254]07/27/2023 18:41:49 - INFO - __main__ - train loss is 36.24193852557801\n",
      "Steps:  44%|▍| 6644/15000 [56:59<25:14,  5.52it/s, lr=0.000829, step_loss=0.068]07/27/2023 18:41:49 - INFO - __main__ - train loss is 36.25652187108062\n",
      "Steps:  44%|▍| 6645/15000 [57:00<25:21,  5.49it/s, lr=0.000829, step_loss=0.014607/27/2023 18:41:49 - INFO - __main__ - train loss is 36.468823885312304\n",
      "Steps:  44%|▍| 6646/15000 [57:00<25:28,  5.47it/s, lr=0.000829, step_loss=0.212]07/27/2023 18:41:50 - INFO - __main__ - train loss is 36.908904468407854\n",
      "Steps:  44%|▉ | 6647/15000 [57:00<25:24,  5.48it/s, lr=0.000829, step_loss=0.44]07/27/2023 18:41:50 - INFO - __main__ - train loss is 36.963439440121874\n",
      "Steps:  44%|▍| 6648/15000 [57:00<25:17,  5.50it/s, lr=0.000829, step_loss=0.054507/27/2023 18:41:50 - INFO - __main__ - train loss is 37.05424544750713\n",
      "Steps:  44%|▍| 6649/15000 [57:00<25:11,  5.53it/s, lr=0.000829, step_loss=0.090807/27/2023 18:41:50 - INFO - __main__ - train loss is 37.32058731256984\n",
      "Steps:  44%|▍| 6650/15000 [57:01<25:05,  5.55it/s, lr=0.000829, step_loss=0.266]07/27/2023 18:41:50 - INFO - __main__ - train loss is 37.32476390223019\n",
      "Steps:  44%|▍| 6651/15000 [57:01<25:01,  5.56it/s, lr=0.00083, step_loss=0.0041807/27/2023 18:41:51 - INFO - __main__ - train loss is 37.63660166482441\n",
      "Steps:  44%|▉ | 6652/15000 [57:01<24:58,  5.57it/s, lr=0.00083, step_loss=0.312]07/27/2023 18:41:51 - INFO - __main__ - train loss is 37.64309197827242\n",
      "Steps:  44%|▍| 6653/15000 [57:01<25:10,  5.53it/s, lr=0.00083, step_loss=0.0064907/27/2023 18:41:51 - INFO - __main__ - train loss is 37.690445417305455\n",
      "Steps:  44%|▍| 6654/15000 [57:01<25:08,  5.53it/s, lr=0.00083, step_loss=0.0474]07/27/2023 18:41:51 - INFO - __main__ - train loss is 37.725013876101\n",
      "Steps:  44%|▍| 6655/15000 [57:01<25:10,  5.52it/s, lr=0.00083, step_loss=0.0346]07/27/2023 18:41:51 - INFO - __main__ - train loss is 38.65169277205132\n",
      "Steps:  44%|▉ | 6656/15000 [57:02<25:05,  5.54it/s, lr=0.00083, step_loss=0.927]07/27/2023 18:41:51 - INFO - __main__ - train loss is 38.66311188763939\n",
      "Steps:  44%|▍| 6657/15000 [57:02<25:03,  5.55it/s, lr=0.00083, step_loss=0.0114]07/27/2023 18:41:52 - INFO - __main__ - train loss is 38.755012072389945\n",
      "Steps:  44%|▍| 6658/15000 [57:02<25:10,  5.52it/s, lr=0.00083, step_loss=0.0919]07/27/2023 18:41:52 - INFO - __main__ - train loss is 39.118387438124046\n",
      "Steps:  44%|▍| 6659/15000 [57:02<25:13,  5.51it/s, lr=0.000831, step_loss=0.363]07/27/2023 18:41:52 - INFO - __main__ - train loss is 39.12107721110806\n",
      "Steps:  44%|▍| 6660/15000 [57:02<25:19,  5.49it/s, lr=0.000831, step_loss=0.002607/27/2023 18:41:52 - INFO - __main__ - train loss is 39.435638756956905\n",
      "Steps:  44%|▍| 6661/15000 [57:03<25:24,  5.47it/s, lr=0.000831, step_loss=0.315]07/27/2023 18:41:52 - INFO - __main__ - train loss is 39.454369665589184\n",
      "Steps:  44%|▍| 6662/15000 [57:03<25:19,  5.49it/s, lr=0.000831, step_loss=0.018707/27/2023 18:41:53 - INFO - __main__ - train loss is 40.00554108759388\n",
      "Steps:  44%|▍| 6663/15000 [57:03<25:11,  5.52it/s, lr=0.000831, step_loss=0.551]07/27/2023 18:41:53 - INFO - __main__ - train loss is 40.059575082268566\n",
      "Steps:  44%|▍| 6664/15000 [57:03<25:05,  5.54it/s, lr=0.000831, step_loss=0.054]07/27/2023 18:41:53 - INFO - __main__ - train loss is 40.277567328419536\n",
      "Steps:  44%|▍| 6665/15000 [57:03<25:00,  5.55it/s, lr=0.000831, step_loss=0.218]07/27/2023 18:41:53 - INFO - __main__ - train loss is 40.336628878023475\n",
      "Steps:  44%|▍| 6666/15000 [57:04<34:49,  3.99it/s, lr=0.000831, step_loss=0.059107/27/2023 18:41:54 - INFO - __main__ - Per validation step average loss is 0.10526607930660248\n",
      "07/27/2023 18:41:54 - INFO - __main__ - Cumulative validation average loss is 0.10526607930660248\n",
      "07/27/2023 18:41:55 - INFO - __main__ - Per validation step average loss is 0.018229369074106216\n",
      "07/27/2023 18:41:55 - INFO - __main__ - Cumulative validation average loss is 0.1234954483807087\n",
      "07/27/2023 18:41:55 - INFO - __main__ - Per validation step average loss is 0.24591578543186188\n",
      "07/27/2023 18:41:55 - INFO - __main__ - Cumulative validation average loss is 0.36941123381257057\n",
      "07/27/2023 18:41:56 - INFO - __main__ - Per validation step average loss is 0.053092069923877716\n",
      "07/27/2023 18:41:56 - INFO - __main__ - Cumulative validation average loss is 0.4225033037364483\n",
      "07/27/2023 18:41:56 - INFO - __main__ - Per validation step average loss is 0.03357553854584694\n",
      "07/27/2023 18:41:56 - INFO - __main__ - Cumulative validation average loss is 0.4560788422822952\n",
      "07/27/2023 18:41:57 - INFO - __main__ - Per validation step average loss is 0.028168989345431328\n",
      "07/27/2023 18:41:57 - INFO - __main__ - Cumulative validation average loss is 0.48424783162772655\n",
      "07/27/2023 18:41:57 - INFO - __main__ - Per validation step average loss is 0.05127685144543648\n",
      "07/27/2023 18:41:57 - INFO - __main__ - Cumulative validation average loss is 0.535524683073163\n",
      "07/27/2023 18:41:57 - INFO - __main__ - Per validation step average loss is 0.05174253135919571\n",
      "07/27/2023 18:41:57 - INFO - __main__ - Cumulative validation average loss is 0.5872672144323587\n",
      "07/27/2023 18:41:58 - INFO - __main__ - Per validation step average loss is 0.02646687999367714\n",
      "07/27/2023 18:41:58 - INFO - __main__ - Cumulative validation average loss is 0.6137340944260359\n",
      "07/27/2023 18:41:58 - INFO - __main__ - Per validation step average loss is 0.010207707062363625\n",
      "07/27/2023 18:41:58 - INFO - __main__ - Cumulative validation average loss is 0.6239418014883995\n",
      "07/27/2023 18:41:59 - INFO - __main__ - Per validation step average loss is 0.19751563668251038\n",
      "07/27/2023 18:41:59 - INFO - __main__ - Cumulative validation average loss is 0.8214574381709099\n",
      "07/27/2023 18:41:59 - INFO - __main__ - Per validation step average loss is 0.4654209613800049\n",
      "07/27/2023 18:41:59 - INFO - __main__ - Cumulative validation average loss is 1.2868783995509148\n",
      "07/27/2023 18:41:59 - INFO - __main__ - Per validation step average loss is 0.10562014579772949\n",
      "07/27/2023 18:41:59 - INFO - __main__ - Cumulative validation average loss is 1.3924985453486443\n",
      "07/27/2023 18:42:00 - INFO - __main__ - Per validation step average loss is 0.16933514177799225\n",
      "07/27/2023 18:42:00 - INFO - __main__ - Cumulative validation average loss is 1.5618336871266365\n",
      "07/27/2023 18:42:00 - INFO - __main__ - Per validation step average loss is 0.005114031955599785\n",
      "07/27/2023 18:42:00 - INFO - __main__ - Cumulative validation average loss is 1.5669477190822363\n",
      "07/27/2023 18:42:01 - INFO - __main__ - Per validation step average loss is 0.08308609575033188\n",
      "07/27/2023 18:42:01 - INFO - __main__ - Cumulative validation average loss is 1.6500338148325682\n",
      "07/27/2023 18:42:01 - INFO - __main__ - Per validation step average loss is 0.09792834520339966\n",
      "07/27/2023 18:42:01 - INFO - __main__ - Cumulative validation average loss is 1.7479621600359678\n",
      "07/27/2023 18:42:02 - INFO - __main__ - Per validation step average loss is 0.005341747775673866\n",
      "07/27/2023 18:42:02 - INFO - __main__ - Cumulative validation average loss is 1.7533039078116417\n",
      "07/27/2023 18:42:02 - INFO - __main__ - Per validation step average loss is 0.4130841791629791\n",
      "07/27/2023 18:42:02 - INFO - __main__ - Cumulative validation average loss is 2.166388086974621\n",
      "07/27/2023 18:42:02 - INFO - __main__ - Per validation step average loss is 0.03475786745548248\n",
      "07/27/2023 18:42:02 - INFO - __main__ - Cumulative validation average loss is 2.2011459544301033\n",
      "07/27/2023 18:42:03 - INFO - __main__ - Per validation step average loss is 0.001700062770396471\n",
      "07/27/2023 18:42:03 - INFO - __main__ - Cumulative validation average loss is 2.2028460172004998\n",
      "07/27/2023 18:42:03 - INFO - __main__ - Per validation step average loss is 0.09524478763341904\n",
      "07/27/2023 18:42:03 - INFO - __main__ - Cumulative validation average loss is 2.298090804833919\n",
      "07/27/2023 18:42:04 - INFO - __main__ - Per validation step average loss is 0.30496716499328613\n",
      "07/27/2023 18:42:04 - INFO - __main__ - Cumulative validation average loss is 2.603057969827205\n",
      "07/27/2023 18:42:04 - INFO - __main__ - Per validation step average loss is 0.4952142834663391\n",
      "07/27/2023 18:42:04 - INFO - __main__ - Cumulative validation average loss is 3.098272253293544\n",
      "07/27/2023 18:42:04 - INFO - __main__ - Per validation step average loss is 0.008662457577884197\n",
      "07/27/2023 18:42:04 - INFO - __main__ - Cumulative validation average loss is 3.1069347108714283\n",
      "07/27/2023 18:42:05 - INFO - __main__ - Per validation step average loss is 0.07849661260843277\n",
      "07/27/2023 18:42:05 - INFO - __main__ - Cumulative validation average loss is 3.185431323479861\n",
      "07/27/2023 18:42:05 - INFO - __main__ - Per validation step average loss is 0.007144023664295673\n",
      "07/27/2023 18:42:05 - INFO - __main__ - Cumulative validation average loss is 3.1925753471441567\n",
      "07/27/2023 18:42:06 - INFO - __main__ - Per validation step average loss is 0.007337368093430996\n",
      "07/27/2023 18:42:06 - INFO - __main__ - Cumulative validation average loss is 3.1999127152375877\n",
      "07/27/2023 18:42:06 - INFO - __main__ - Per validation step average loss is 0.02486031875014305\n",
      "07/27/2023 18:42:06 - INFO - __main__ - Cumulative validation average loss is 3.2247730339877307\n",
      "07/27/2023 18:42:07 - INFO - __main__ - Per validation step average loss is 0.0031333088409155607\n",
      "07/27/2023 18:42:07 - INFO - __main__ - Cumulative validation average loss is 3.2279063428286463\n",
      "07/27/2023 18:42:07 - INFO - __main__ - Per validation step average loss is 0.039010293781757355\n",
      "07/27/2023 18:42:07 - INFO - __main__ - Cumulative validation average loss is 3.2669166366104037\n",
      "07/27/2023 18:42:07 - INFO - __main__ - Per validation step average loss is 0.04977355897426605\n",
      "07/27/2023 18:42:07 - INFO - __main__ - Cumulative validation average loss is 3.3166901955846697\n",
      "07/27/2023 18:42:08 - INFO - __main__ - Per validation step average loss is 0.012404539622366428\n",
      "07/27/2023 18:42:08 - INFO - __main__ - Cumulative validation average loss is 3.329094735207036\n",
      "07/27/2023 18:42:08 - INFO - __main__ - Per validation step average loss is 0.10258826613426208\n",
      "07/27/2023 18:42:08 - INFO - __main__ - Cumulative validation average loss is 3.4316830013412982\n",
      "07/27/2023 18:42:09 - INFO - __main__ - Per validation step average loss is 0.005330893211066723\n",
      "07/27/2023 18:42:09 - INFO - __main__ - Cumulative validation average loss is 3.437013894552365\n",
      "07/27/2023 18:42:09 - INFO - __main__ - Per validation step average loss is 0.16735593974590302\n",
      "07/27/2023 18:42:09 - INFO - __main__ - Cumulative validation average loss is 3.604369834298268\n",
      "07/27/2023 18:42:09 - INFO - __main__ - Per validation step average loss is 0.010443080216646194\n",
      "07/27/2023 18:42:09 - INFO - __main__ - Cumulative validation average loss is 3.614812914514914\n",
      "07/27/2023 18:42:10 - INFO - __main__ - Per validation step average loss is 0.24926821887493134\n",
      "07/27/2023 18:42:10 - INFO - __main__ - Cumulative validation average loss is 3.8640811333898455\n",
      "07/27/2023 18:42:10 - INFO - __main__ - Per validation step average loss is 0.052792299538850784\n",
      "07/27/2023 18:42:10 - INFO - __main__ - Cumulative validation average loss is 3.9168734329286963\n",
      "07/27/2023 18:42:11 - INFO - __main__ - Per validation step average loss is 0.47470492124557495\n",
      "07/27/2023 18:42:11 - INFO - __main__ - Cumulative validation average loss is 4.391578354174271\n",
      "07/27/2023 18:42:11 - INFO - __main__ - Per validation step average loss is 0.10635792464017868\n",
      "07/27/2023 18:42:11 - INFO - __main__ - Cumulative validation average loss is 4.49793627881445\n",
      "07/27/2023 18:42:11 - INFO - __main__ - Per validation step average loss is 0.01013870444148779\n",
      "07/27/2023 18:42:11 - INFO - __main__ - Cumulative validation average loss is 4.508074983255938\n",
      "07/27/2023 18:42:12 - INFO - __main__ - Per validation step average loss is 0.2452421635389328\n",
      "07/27/2023 18:42:12 - INFO - __main__ - Cumulative validation average loss is 4.7533171467948705\n",
      "07/27/2023 18:42:12 - INFO - __main__ - Per validation step average loss is 0.012472408823668957\n",
      "07/27/2023 18:42:12 - INFO - __main__ - Cumulative validation average loss is 4.7657895556185395\n",
      "07/27/2023 18:42:13 - INFO - __main__ - Per validation step average loss is 0.004040705040097237\n",
      "07/27/2023 18:42:13 - INFO - __main__ - Cumulative validation average loss is 4.769830260658637\n",
      "07/27/2023 18:42:13 - INFO - __main__ - Per validation step average loss is 0.571648359298706\n",
      "07/27/2023 18:42:13 - INFO - __main__ - Cumulative validation average loss is 5.341478619957343\n",
      "07/27/2023 18:42:14 - INFO - __main__ - Per validation step average loss is 0.13924866914749146\n",
      "07/27/2023 18:42:14 - INFO - __main__ - Cumulative validation average loss is 5.480727289104834\n",
      "07/27/2023 18:42:14 - INFO - __main__ - Per validation step average loss is 0.1263592541217804\n",
      "07/27/2023 18:42:14 - INFO - __main__ - Cumulative validation average loss is 5.607086543226615\n",
      "07/27/2023 18:42:14 - INFO - __main__ - Per validation step average loss is 0.14464110136032104\n",
      "07/27/2023 18:42:14 - INFO - __main__ - Cumulative validation average loss is 5.751727644586936\n",
      "07/27/2023 18:42:15 - INFO - __main__ - Per validation step average loss is 0.05039605498313904\n",
      "07/27/2023 18:42:15 - INFO - __main__ - Cumulative validation average loss is 5.802123699570075\n",
      "07/27/2023 18:42:15 - INFO - __main__ - Per validation step average loss is 0.14832095801830292\n",
      "07/27/2023 18:42:15 - INFO - __main__ - Cumulative validation average loss is 5.950444657588378\n",
      "07/27/2023 18:42:16 - INFO - __main__ - Per validation step average loss is 0.023570062592625618\n",
      "07/27/2023 18:42:16 - INFO - __main__ - Cumulative validation average loss is 5.974014720181003\n",
      "07/27/2023 18:42:16 - INFO - __main__ - Per validation step average loss is 0.024820247665047646\n",
      "07/27/2023 18:42:16 - INFO - __main__ - Cumulative validation average loss is 5.998834967846051\n",
      "07/27/2023 18:42:16 - INFO - __main__ - Per validation step average loss is 0.1665019989013672\n",
      "07/27/2023 18:42:16 - INFO - __main__ - Cumulative validation average loss is 6.165336966747418\n",
      "07/27/2023 18:42:17 - INFO - __main__ - Per validation step average loss is 0.054768916219472885\n",
      "07/27/2023 18:42:17 - INFO - __main__ - Cumulative validation average loss is 6.220105882966891\n",
      "07/27/2023 18:42:17 - INFO - __main__ - Per validation step average loss is 0.29828083515167236\n",
      "07/27/2023 18:42:17 - INFO - __main__ - Cumulative validation average loss is 6.518386718118563\n",
      "07/27/2023 18:42:18 - INFO - __main__ - Per validation step average loss is 0.48238831758499146\n",
      "07/27/2023 18:42:18 - INFO - __main__ - Cumulative validation average loss is 7.000775035703555\n",
      "07/27/2023 18:42:18 - INFO - __main__ - Per validation step average loss is 0.005984228570014238\n",
      "07/27/2023 18:42:18 - INFO - __main__ - Cumulative validation average loss is 7.006759264273569\n",
      "07/27/2023 18:42:18 - INFO - __main__ - Per validation step average loss is 0.016782671213150024\n",
      "07/27/2023 18:42:18 - INFO - __main__ - Cumulative validation average loss is 7.023541935486719\n",
      "07/27/2023 18:42:19 - INFO - __main__ - Per validation step average loss is 0.2368137687444687\n",
      "07/27/2023 18:42:19 - INFO - __main__ - Cumulative validation average loss is 7.260355704231188\n",
      "07/27/2023 18:42:19 - INFO - __main__ - Per validation step average loss is 0.771722674369812\n",
      "07/27/2023 18:42:19 - INFO - __main__ - Cumulative validation average loss is 8.032078378601\n",
      "07/27/2023 18:42:20 - INFO - __main__ - Per validation step average loss is 0.15182983875274658\n",
      "07/27/2023 18:42:20 - INFO - __main__ - Cumulative validation average loss is 8.183908217353746\n",
      "07/27/2023 18:42:20 - INFO - __main__ - Per validation step average loss is 0.2171122431755066\n",
      "07/27/2023 18:42:20 - INFO - __main__ - Cumulative validation average loss is 8.401020460529253\n",
      "07/27/2023 18:42:21 - INFO - __main__ - Per validation step average loss is 0.05886969715356827\n",
      "07/27/2023 18:42:21 - INFO - __main__ - Cumulative validation average loss is 8.459890157682821\n",
      "07/27/2023 18:42:21 - INFO - __main__ - Per validation step average loss is 0.320620059967041\n",
      "07/27/2023 18:42:21 - INFO - __main__ - Cumulative validation average loss is 8.780510217649862\n",
      "07/27/2023 18:42:21 - INFO - __main__ - Per validation step average loss is 0.14138484001159668\n",
      "07/27/2023 18:42:21 - INFO - __main__ - Cumulative validation average loss is 8.921895057661459\n",
      "07/27/2023 18:42:22 - INFO - __main__ - Per validation step average loss is 0.028368039056658745\n",
      "07/27/2023 18:42:22 - INFO - __main__ - Cumulative validation average loss is 8.950263096718118\n",
      "07/27/2023 18:42:22 - INFO - __main__ - Per validation step average loss is 0.0016299792332574725\n",
      "07/27/2023 18:42:22 - INFO - __main__ - Cumulative validation average loss is 8.951893075951375\n",
      "07/27/2023 18:42:23 - INFO - __main__ - Per validation step average loss is 0.05021064355969429\n",
      "07/27/2023 18:42:23 - INFO - __main__ - Cumulative validation average loss is 9.00210371951107\n",
      "07/27/2023 18:42:23 - INFO - __main__ - Per validation step average loss is 0.0019870116375386715\n",
      "07/27/2023 18:42:23 - INFO - __main__ - Cumulative validation average loss is 9.004090731148608\n",
      "07/27/2023 18:42:23 - INFO - __main__ - Per validation step average loss is 0.004610483534634113\n",
      "07/27/2023 18:42:23 - INFO - __main__ - Cumulative validation average loss is 9.008701214683242\n",
      "07/27/2023 18:42:24 - INFO - __main__ - Per validation step average loss is 0.001644657924771309\n",
      "07/27/2023 18:42:24 - INFO - __main__ - Cumulative validation average loss is 9.010345872608013\n",
      "07/27/2023 18:42:24 - INFO - __main__ - Per validation step average loss is 0.059092774987220764\n",
      "07/27/2023 18:42:24 - INFO - __main__ - Cumulative validation average loss is 9.069438647595234\n",
      "07/27/2023 18:42:25 - INFO - __main__ - Per validation step average loss is 0.0019149247091263533\n",
      "07/27/2023 18:42:25 - INFO - __main__ - Cumulative validation average loss is 9.07135357230436\n",
      "07/27/2023 18:42:25 - INFO - __main__ - Per validation step average loss is 0.008535805158317089\n",
      "07/27/2023 18:42:25 - INFO - __main__ - Cumulative validation average loss is 9.079889377462678\n",
      "07/27/2023 18:42:26 - INFO - __main__ - Per validation step average loss is 0.0030454020015895367\n",
      "07/27/2023 18:42:26 - INFO - __main__ - Cumulative validation average loss is 9.082934779464267\n",
      "07/27/2023 18:42:26 - INFO - __main__ - Per validation step average loss is 0.0772814154624939\n",
      "07/27/2023 18:42:26 - INFO - __main__ - Cumulative validation average loss is 9.160216194926761\n",
      "07/27/2023 18:42:26 - INFO - __main__ - Per validation step average loss is 0.0898209661245346\n",
      "07/27/2023 18:42:26 - INFO - __main__ - Cumulative validation average loss is 9.250037161051296\n",
      "07/27/2023 18:42:27 - INFO - __main__ - Per validation step average loss is 0.04988113045692444\n",
      "07/27/2023 18:42:27 - INFO - __main__ - Cumulative validation average loss is 9.29991829150822\n",
      "07/27/2023 18:42:27 - INFO - __main__ - Average validation loss for Epoch 21 is 0.1177204847026357\n",
      "07/27/2023 18:42:27 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:43:24 - INFO - __main__ - Starting epoch 22\n",
      "07/27/2023 18:43:25 - INFO - __main__ - train loss is 0.017416369169950485\n",
      "Steps:  44%|▍| 6667/15000 [58:35<63:53:46, 27.60s/it, lr=0.000831, step_loss=0.007/27/2023 18:43:25 - INFO - __main__ - train loss is 0.11964961513876915\n",
      "Steps:  44%|▍| 6668/15000 [58:35<44:51:37, 19.38s/it, lr=0.000832, step_loss=0.107/27/2023 18:43:25 - INFO - __main__ - train loss is 0.466214831918478\n",
      "Steps:  44%|▍| 6669/15000 [58:35<31:31:55, 13.63s/it, lr=0.000832, step_loss=0.307/27/2023 18:43:25 - INFO - __main__ - train loss is 0.4687165846116841\n",
      "Steps:  44%|▍| 6670/15000 [58:36<22:11:57,  9.59s/it, lr=0.000832, step_loss=0.007/27/2023 18:43:26 - INFO - __main__ - train loss is 0.7503903736360371\n",
      "Steps:  44%|▍| 6671/15000 [58:36<15:39:50,  6.77s/it, lr=0.000832, step_loss=0.207/27/2023 18:43:26 - INFO - __main__ - train loss is 0.8565983180887997\n",
      "Steps:  44%|▍| 6672/15000 [58:36<11:05:20,  4.79s/it, lr=0.000832, step_loss=0.107/27/2023 18:43:26 - INFO - __main__ - train loss is 0.9193762843497097\n",
      "Steps:  44%|▍| 6673/15000 [58:36<7:53:17,  3.41s/it, lr=0.000832, step_loss=0.0607/27/2023 18:43:26 - INFO - __main__ - train loss is 0.9439203408546746\n",
      "Steps:  44%|▍| 6674/15000 [58:36<5:38:43,  2.44s/it, lr=0.000832, step_loss=0.0207/27/2023 18:43:26 - INFO - __main__ - train loss is 1.1590090659447014\n",
      "Steps:  44%|▍| 6675/15000 [58:37<4:04:31,  1.76s/it, lr=0.000833, step_loss=0.2107/27/2023 18:43:26 - INFO - __main__ - train loss is 1.1906528291292489\n",
      "Steps:  45%|▍| 6676/15000 [58:37<2:58:33,  1.29s/it, lr=0.000833, step_loss=0.0307/27/2023 18:43:27 - INFO - __main__ - train loss is 1.1922995024360716\n",
      "Steps:  45%|▍| 6677/15000 [58:37<2:12:24,  1.05it/s, lr=0.000833, step_loss=0.0007/27/2023 18:43:27 - INFO - __main__ - train loss is 1.4587817364372313\n",
      "Steps:  45%|▍| 6678/15000 [58:37<1:40:08,  1.39it/s, lr=0.000833, step_loss=0.2607/27/2023 18:43:27 - INFO - __main__ - train loss is 1.4733888045884669\n",
      "Steps:  45%|▍| 6679/15000 [58:37<1:17:32,  1.79it/s, lr=0.000833, step_loss=0.0107/27/2023 18:43:27 - INFO - __main__ - train loss is 1.671566589269787\n",
      "Steps:  45%|▍| 6680/15000 [58:37<1:01:58,  2.24it/s, lr=0.000833, step_loss=0.1907/27/2023 18:43:27 - INFO - __main__ - train loss is 1.6743469922803342\n",
      "Steps:  45%|▍| 6681/15000 [58:38<51:08,  2.71it/s, lr=0.000833, step_loss=0.002707/27/2023 18:43:28 - INFO - __main__ - train loss is 1.7262369967065752\n",
      "Steps:  45%|▍| 6682/15000 [58:38<43:25,  3.19it/s, lr=0.000833, step_loss=0.051907/27/2023 18:43:28 - INFO - __main__ - train loss is 1.734323329757899\n",
      "Steps:  45%|▍| 6683/15000 [58:38<38:11,  3.63it/s, lr=0.000834, step_loss=0.008007/27/2023 18:43:28 - INFO - __main__ - train loss is 1.7805250394158065\n",
      "Steps:  45%|▍| 6684/15000 [58:38<34:27,  4.02it/s, lr=0.000834, step_loss=0.046207/27/2023 18:43:28 - INFO - __main__ - train loss is 2.0412592100910842\n",
      "Steps:  45%|▍| 6685/15000 [58:38<31:34,  4.39it/s, lr=0.000834, step_loss=0.261]07/27/2023 18:43:28 - INFO - __main__ - train loss is 2.109236072283238\n",
      "Steps:  45%|▍| 6686/15000 [58:39<29:35,  4.68it/s, lr=0.000834, step_loss=0.068]07/27/2023 18:43:28 - INFO - __main__ - train loss is 2.541437159758061\n",
      "Steps:  45%|▍| 6687/15000 [58:39<28:10,  4.92it/s, lr=0.000834, step_loss=0.432]07/27/2023 18:43:29 - INFO - __main__ - train loss is 2.59180412767455\n",
      "Steps:  45%|▍| 6688/15000 [58:39<27:24,  5.05it/s, lr=0.000834, step_loss=0.050407/27/2023 18:43:29 - INFO - __main__ - train loss is 2.703934635501355\n",
      "Steps:  45%|▍| 6689/15000 [58:39<26:37,  5.20it/s, lr=0.000834, step_loss=0.112]07/27/2023 18:43:29 - INFO - __main__ - train loss is 2.749033513944596\n",
      "Steps:  45%|▍| 6690/15000 [58:39<26:05,  5.31it/s, lr=0.000834, step_loss=0.045107/27/2023 18:43:29 - INFO - __main__ - train loss is 2.9628733727149665\n",
      "Steps:  45%|▍| 6691/15000 [58:39<25:41,  5.39it/s, lr=0.000835, step_loss=0.214]07/27/2023 18:43:29 - INFO - __main__ - train loss is 3.722986492794007\n",
      "Steps:  45%|▉ | 6692/15000 [58:40<25:26,  5.44it/s, lr=0.000835, step_loss=0.76]07/27/2023 18:43:30 - INFO - __main__ - train loss is 3.7257544349413365\n",
      "Steps:  45%|▍| 6693/15000 [58:40<25:15,  5.48it/s, lr=0.000835, step_loss=0.002707/27/2023 18:43:30 - INFO - __main__ - train loss is 3.727562112500891\n",
      "Steps:  45%|▍| 6694/15000 [58:40<25:07,  5.51it/s, lr=0.000835, step_loss=0.001807/27/2023 18:43:30 - INFO - __main__ - train loss is 3.8774074444081634\n",
      "Steps:  45%|▉ | 6695/15000 [58:40<25:03,  5.52it/s, lr=0.000835, step_loss=0.15]07/27/2023 18:43:30 - INFO - __main__ - train loss is 4.304594112327322\n",
      "Steps:  45%|▍| 6696/15000 [58:40<25:00,  5.53it/s, lr=0.000835, step_loss=0.427]07/27/2023 18:43:30 - INFO - __main__ - train loss is 4.31113626039587\n",
      "Steps:  45%|▍| 6697/15000 [58:41<24:57,  5.54it/s, lr=0.000835, step_loss=0.006507/27/2023 18:43:30 - INFO - __main__ - train loss is 4.3409095702227205\n",
      "Steps:  45%|▍| 6698/15000 [58:41<24:54,  5.55it/s, lr=0.000835, step_loss=0.029807/27/2023 18:43:31 - INFO - __main__ - train loss is 4.403691999381408\n",
      "Steps:  45%|▍| 6699/15000 [58:41<24:53,  5.56it/s, lr=0.000836, step_loss=0.062807/27/2023 18:43:31 - INFO - __main__ - train loss is 4.406190914101899\n",
      "Steps:  45%|▍| 6700/15000 [58:41<24:52,  5.56it/s, lr=0.000836, step_loss=0.002507/27/2023 18:43:31 - INFO - __main__ - train loss is 4.735861194320023\n",
      "Steps:  45%|▉ | 6701/15000 [58:41<24:51,  5.56it/s, lr=0.000836, step_loss=0.33]07/27/2023 18:43:31 - INFO - __main__ - train loss is 4.73829013062641\n",
      "Steps:  45%|▍| 6702/15000 [58:41<24:51,  5.56it/s, lr=0.000836, step_loss=0.002407/27/2023 18:43:31 - INFO - __main__ - train loss is 4.856624364387244\n",
      "Steps:  45%|▍| 6703/15000 [58:42<24:50,  5.57it/s, lr=0.000836, step_loss=0.118]07/27/2023 18:43:32 - INFO - __main__ - train loss is 4.876539185177535\n",
      "Steps:  45%|▍| 6704/15000 [58:42<24:49,  5.57it/s, lr=0.000836, step_loss=0.019907/27/2023 18:43:32 - INFO - __main__ - train loss is 4.91798848612234\n",
      "Steps:  45%|▍| 6705/15000 [58:42<24:48,  5.57it/s, lr=0.000836, step_loss=0.041407/27/2023 18:43:32 - INFO - __main__ - train loss is 5.51177305681631\n",
      "Steps:  45%|▍| 6706/15000 [58:42<24:48,  5.57it/s, lr=0.000836, step_loss=0.594]07/27/2023 18:43:32 - INFO - __main__ - train loss is 5.521915573161095\n",
      "Steps:  45%|▍| 6707/15000 [58:42<24:48,  5.57it/s, lr=0.000837, step_loss=0.010107/27/2023 18:43:32 - INFO - __main__ - train loss is 6.195424217265099\n",
      "Steps:  45%|▍| 6708/15000 [58:43<24:47,  5.57it/s, lr=0.000837, step_loss=0.674]07/27/2023 18:43:32 - INFO - __main__ - train loss is 6.198810360394418\n",
      "Steps:  45%|▍| 6709/15000 [58:43<24:48,  5.57it/s, lr=0.000837, step_loss=0.003307/27/2023 18:43:33 - INFO - __main__ - train loss is 6.4659059857949615\n",
      "Steps:  45%|▍| 6710/15000 [58:43<24:47,  5.57it/s, lr=0.000837, step_loss=0.267]07/27/2023 18:43:33 - INFO - __main__ - train loss is 6.479090195149183\n",
      "Steps:  45%|▍| 6711/15000 [58:43<24:48,  5.57it/s, lr=0.000837, step_loss=0.013207/27/2023 18:43:33 - INFO - __main__ - train loss is 6.763459127396345\n",
      "Steps:  45%|▍| 6712/15000 [58:43<24:48,  5.57it/s, lr=0.000837, step_loss=0.284]07/27/2023 18:43:33 - INFO - __main__ - train loss is 6.981880720704794\n",
      "Steps:  45%|▍| 6713/15000 [58:43<24:49,  5.57it/s, lr=0.000837, step_loss=0.218]07/27/2023 18:43:33 - INFO - __main__ - train loss is 7.102518435567617\n",
      "Steps:  45%|▍| 6714/15000 [58:44<24:49,  5.56it/s, lr=0.000837, step_loss=0.121]07/27/2023 18:43:33 - INFO - __main__ - train loss is 7.312665428966284\n",
      "Steps:  45%|▉ | 6715/15000 [58:44<24:48,  5.56it/s, lr=0.000838, step_loss=0.21]07/27/2023 18:43:34 - INFO - __main__ - train loss is 7.368707049638033\n",
      "Steps:  45%|▍| 6716/15000 [58:44<24:47,  5.57it/s, lr=0.000838, step_loss=0.056]07/27/2023 18:43:34 - INFO - __main__ - train loss is 7.455872196704149\n",
      "Steps:  45%|▍| 6717/15000 [58:44<24:48,  5.57it/s, lr=0.000838, step_loss=0.087207/27/2023 18:43:34 - INFO - __main__ - train loss is 7.577198062092066\n",
      "Steps:  45%|▍| 6718/15000 [58:44<24:48,  5.57it/s, lr=0.000838, step_loss=0.121]07/27/2023 18:43:34 - INFO - __main__ - train loss is 7.949275646358728\n",
      "Steps:  45%|▍| 6719/15000 [58:45<24:47,  5.57it/s, lr=0.000838, step_loss=0.372]07/27/2023 18:43:34 - INFO - __main__ - train loss is 8.007882177829742\n",
      "Steps:  45%|▍| 6720/15000 [58:45<24:46,  5.57it/s, lr=0.000838, step_loss=0.058607/27/2023 18:43:35 - INFO - __main__ - train loss is 8.067978046834469\n",
      "Steps:  45%|▍| 6721/15000 [58:45<24:47,  5.56it/s, lr=0.000838, step_loss=0.060107/27/2023 18:43:35 - INFO - __main__ - train loss is 8.069847497390583\n",
      "Steps:  45%|▍| 6722/15000 [58:45<24:48,  5.56it/s, lr=0.000838, step_loss=0.001807/27/2023 18:43:35 - INFO - __main__ - train loss is 8.300667095230892\n",
      "Steps:  45%|▍| 6723/15000 [58:45<24:58,  5.52it/s, lr=0.000839, step_loss=0.231]07/27/2023 18:43:35 - INFO - __main__ - train loss is 8.308975529158488\n",
      "Steps:  45%|▍| 6724/15000 [58:45<25:02,  5.51it/s, lr=0.000839, step_loss=0.008307/27/2023 18:43:35 - INFO - __main__ - train loss is 8.610815655672923\n",
      "Steps:  45%|▍| 6725/15000 [58:46<25:07,  5.49it/s, lr=0.000839, step_loss=0.302]07/27/2023 18:43:35 - INFO - __main__ - train loss is 8.680364813888445\n",
      "Steps:  45%|▍| 6726/15000 [58:46<25:00,  5.52it/s, lr=0.000839, step_loss=0.069507/27/2023 18:43:36 - INFO - __main__ - train loss is 8.78968269773759\n",
      "Steps:  45%|▍| 6727/15000 [58:46<24:55,  5.53it/s, lr=0.000839, step_loss=0.109]07/27/2023 18:43:36 - INFO - __main__ - train loss is 9.369963836157694\n",
      "Steps:  45%|▉ | 6728/15000 [58:46<24:55,  5.53it/s, lr=0.000839, step_loss=0.58]07/27/2023 18:43:36 - INFO - __main__ - train loss is 9.408230975503102\n",
      "Steps:  45%|▍| 6729/15000 [58:46<24:54,  5.53it/s, lr=0.000839, step_loss=0.038307/27/2023 18:43:36 - INFO - __main__ - train loss is 9.889116391772404\n",
      "Steps:  45%|▍| 6730/15000 [58:46<24:53,  5.54it/s, lr=0.000839, step_loss=0.481]07/27/2023 18:43:36 - INFO - __main__ - train loss is 9.975138157838956\n",
      "Steps:  45%|▉ | 6731/15000 [58:47<24:53,  5.54it/s, lr=0.00084, step_loss=0.086]07/27/2023 18:43:37 - INFO - __main__ - train loss is 9.979275235207751\n",
      "Steps:  45%|▍| 6732/15000 [58:47<24:52,  5.54it/s, lr=0.00084, step_loss=0.0041407/27/2023 18:43:37 - INFO - __main__ - train loss is 9.98169852909632\n",
      "Steps:  45%|▍| 6733/15000 [58:47<24:51,  5.54it/s, lr=0.00084, step_loss=0.0024207/27/2023 18:43:37 - INFO - __main__ - train loss is 10.025562976719812\n",
      "Steps:  45%|▍| 6734/15000 [58:47<24:50,  5.55it/s, lr=0.00084, step_loss=0.0439]07/27/2023 18:43:37 - INFO - __main__ - train loss is 10.026750260731205\n",
      "Steps:  45%|▍| 6735/15000 [58:47<25:03,  5.50it/s, lr=0.00084, step_loss=0.0011907/27/2023 18:43:37 - INFO - __main__ - train loss is 10.366840356728062\n",
      "Steps:  45%|█▎ | 6736/15000 [58:48<25:22,  5.43it/s, lr=0.00084, step_loss=0.34]07/27/2023 18:43:37 - INFO - __main__ - train loss is 10.37011579819955\n",
      "Steps:  45%|▍| 6737/15000 [58:48<25:18,  5.44it/s, lr=0.00084, step_loss=0.0032807/27/2023 18:43:38 - INFO - __main__ - train loss is 10.38368644961156\n",
      "Steps:  45%|▍| 6738/15000 [58:48<25:17,  5.45it/s, lr=0.00084, step_loss=0.0136]07/27/2023 18:43:38 - INFO - __main__ - train loss is 10.385929333046079\n",
      "Steps:  45%|▍| 6739/15000 [58:48<25:07,  5.48it/s, lr=0.00084, step_loss=0.0022407/27/2023 18:43:38 - INFO - __main__ - train loss is 10.771675692871213\n",
      "Steps:  45%|▍| 6740/15000 [58:48<25:01,  5.50it/s, lr=0.000841, step_loss=0.386]07/27/2023 18:43:38 - INFO - __main__ - train loss is 11.034598277881742\n",
      "Steps:  45%|▍| 6741/15000 [58:49<24:55,  5.52it/s, lr=0.000841, step_loss=0.263]07/27/2023 18:43:38 - INFO - __main__ - train loss is 11.447123097255826\n",
      "Steps:  45%|▍| 6742/15000 [58:49<25:04,  5.49it/s, lr=0.000841, step_loss=0.413]07/27/2023 18:43:39 - INFO - __main__ - train loss is 11.457748943939805\n",
      "Steps:  45%|▍| 6743/15000 [58:49<25:12,  5.46it/s, lr=0.000841, step_loss=0.010607/27/2023 18:43:39 - INFO - __main__ - train loss is 11.485600780695677\n",
      "Steps:  45%|▍| 6744/15000 [58:49<25:16,  5.44it/s, lr=0.000841, step_loss=0.027907/27/2023 18:43:39 - INFO - __main__ - train loss is 11.489856449887156\n",
      "Steps:  45%|▍| 6745/15000 [58:49<25:06,  5.48it/s, lr=0.000841, step_loss=0.004207/27/2023 18:43:39 - INFO - __main__ - train loss is 11.770636646077037\n",
      "Steps:  45%|▍| 6746/15000 [58:49<25:02,  5.49it/s, lr=0.000841, step_loss=0.281]07/27/2023 18:43:39 - INFO - __main__ - train loss is 11.864609507843852\n",
      "Steps:  45%|▍| 6747/15000 [58:50<25:09,  5.47it/s, lr=0.000842, step_loss=0.094]07/27/2023 18:43:39 - INFO - __main__ - train loss is 11.940217716619372\n",
      "Steps:  45%|▍| 6748/15000 [58:50<25:02,  5.49it/s, lr=0.000842, step_loss=0.075607/27/2023 18:43:40 - INFO - __main__ - train loss is 11.9425656106323\n",
      "Steps:  45%|▍| 6749/15000 [58:50<24:55,  5.52it/s, lr=0.000842, step_loss=0.002307/27/2023 18:43:40 - INFO - __main__ - train loss is 12.235273679718375\n",
      "Steps:  45%|▍| 6750/15000 [58:50<25:05,  5.48it/s, lr=0.000842, step_loss=0.293]07/27/2023 18:43:40 - INFO - __main__ - train loss is 12.274740485474467\n",
      "Steps:  45%|▍| 6751/15000 [58:50<25:08,  5.47it/s, lr=0.000842, step_loss=0.039507/27/2023 18:43:40 - INFO - __main__ - train loss is 12.311518946662545\n",
      "Steps:  45%|▍| 6752/15000 [58:51<25:03,  5.49it/s, lr=0.000842, step_loss=0.036807/27/2023 18:43:40 - INFO - __main__ - train loss is 12.407401556149125\n",
      "Steps:  45%|▍| 6753/15000 [58:51<24:56,  5.51it/s, lr=0.000842, step_loss=0.095907/27/2023 18:43:41 - INFO - __main__ - train loss is 12.414536162279546\n",
      "Steps:  45%|▍| 6754/15000 [58:51<24:55,  5.51it/s, lr=0.000842, step_loss=0.007107/27/2023 18:43:41 - INFO - __main__ - train loss is 12.68427203502506\n",
      "Steps:  45%|▉ | 6755/15000 [58:51<24:50,  5.53it/s, lr=0.000843, step_loss=0.27]07/27/2023 18:43:41 - INFO - __main__ - train loss is 12.840026780031621\n",
      "Steps:  45%|▍| 6756/15000 [58:51<24:46,  5.54it/s, lr=0.000843, step_loss=0.156]07/27/2023 18:43:41 - INFO - __main__ - train loss is 13.04344294872135\n",
      "Steps:  45%|▍| 6757/15000 [58:51<24:45,  5.55it/s, lr=0.000843, step_loss=0.203]07/27/2023 18:43:41 - INFO - __main__ - train loss is 13.057263110764325\n",
      "Steps:  45%|▍| 6758/15000 [58:52<24:55,  5.51it/s, lr=0.000843, step_loss=0.013807/27/2023 18:43:41 - INFO - __main__ - train loss is 13.776860331185162\n",
      "Steps:  45%|▉ | 6759/15000 [58:52<24:53,  5.52it/s, lr=0.000843, step_loss=0.72]07/27/2023 18:43:42 - INFO - __main__ - train loss is 13.779573521809652\n",
      "Steps:  45%|▍| 6760/15000 [58:52<24:49,  5.53it/s, lr=0.000843, step_loss=0.002707/27/2023 18:43:42 - INFO - __main__ - train loss is 13.783212651032954\n",
      "Steps:  45%|▍| 6761/15000 [58:52<24:46,  5.54it/s, lr=0.000843, step_loss=0.003607/27/2023 18:43:42 - INFO - __main__ - train loss is 14.205813754815608\n",
      "Steps:  45%|▍| 6762/15000 [58:52<24:44,  5.55it/s, lr=0.000843, step_loss=0.423]07/27/2023 18:43:42 - INFO - __main__ - train loss is 14.368286539334804\n",
      "Steps:  45%|▍| 6763/15000 [58:52<24:43,  5.55it/s, lr=0.000844, step_loss=0.162]07/27/2023 18:43:42 - INFO - __main__ - train loss is 14.577866841573268\n",
      "Steps:  45%|▉ | 6764/15000 [58:53<24:41,  5.56it/s, lr=0.000844, step_loss=0.21]07/27/2023 18:43:43 - INFO - __main__ - train loss is 14.589824268128723\n",
      "Steps:  45%|▍| 6765/15000 [58:53<24:41,  5.56it/s, lr=0.000844, step_loss=0.012]07/27/2023 18:43:43 - INFO - __main__ - train loss is 14.634990045335144\n",
      "Steps:  45%|▍| 6766/15000 [58:53<24:40,  5.56it/s, lr=0.000844, step_loss=0.045207/27/2023 18:43:43 - INFO - __main__ - train loss is 14.795122885610908\n",
      "Steps:  45%|▉ | 6767/15000 [58:53<24:40,  5.56it/s, lr=0.000844, step_loss=0.16]07/27/2023 18:43:43 - INFO - __main__ - train loss is 14.801261224318296\n",
      "Steps:  45%|▍| 6768/15000 [58:53<24:39,  5.56it/s, lr=0.000844, step_loss=0.006107/27/2023 18:43:43 - INFO - __main__ - train loss is 14.936884128022939\n",
      "Steps:  45%|▍| 6769/15000 [58:54<24:39,  5.56it/s, lr=0.000844, step_loss=0.136]07/27/2023 18:43:43 - INFO - __main__ - train loss is 15.027832441497594\n",
      "Steps:  45%|▍| 6770/15000 [58:54<24:39,  5.56it/s, lr=0.000844, step_loss=0.090907/27/2023 18:43:44 - INFO - __main__ - train loss is 15.044193778652698\n",
      "Steps:  45%|▍| 6771/15000 [58:54<24:39,  5.56it/s, lr=0.000845, step_loss=0.016407/27/2023 18:43:44 - INFO - __main__ - train loss is 15.045825061621144\n",
      "Steps:  45%|▍| 6772/15000 [58:54<24:38,  5.57it/s, lr=0.000845, step_loss=0.001607/27/2023 18:43:44 - INFO - __main__ - train loss is 15.15317610395141\n",
      "Steps:  45%|▍| 6773/15000 [58:54<24:38,  5.57it/s, lr=0.000845, step_loss=0.107]07/27/2023 18:43:44 - INFO - __main__ - train loss is 15.165414695860818\n",
      "Steps:  45%|▍| 6774/15000 [58:54<24:37,  5.57it/s, lr=0.000845, step_loss=0.012207/27/2023 18:43:44 - INFO - __main__ - train loss is 15.190566906007007\n",
      "Steps:  45%|▍| 6775/15000 [58:55<24:37,  5.57it/s, lr=0.000845, step_loss=0.025207/27/2023 18:43:45 - INFO - __main__ - train loss is 15.209068197058514\n",
      "Steps:  45%|▍| 6776/15000 [58:55<24:35,  5.57it/s, lr=0.000845, step_loss=0.018507/27/2023 18:43:45 - INFO - __main__ - train loss is 15.27451592986472\n",
      "Steps:  45%|▍| 6777/15000 [58:55<24:35,  5.57it/s, lr=0.000845, step_loss=0.065407/27/2023 18:43:45 - INFO - __main__ - train loss is 15.279179206350818\n",
      "Steps:  45%|▍| 6778/15000 [58:55<24:35,  5.57it/s, lr=0.000845, step_loss=0.004607/27/2023 18:43:45 - INFO - __main__ - train loss is 15.282990823732689\n",
      "Steps:  45%|▍| 6779/15000 [58:55<24:36,  5.57it/s, lr=0.000846, step_loss=0.003807/27/2023 18:43:45 - INFO - __main__ - train loss is 15.77987367962487\n",
      "Steps:  45%|▍| 6780/15000 [58:56<24:35,  5.57it/s, lr=0.000846, step_loss=0.497]07/27/2023 18:43:45 - INFO - __main__ - train loss is 15.805184877710417\n",
      "Steps:  45%|▍| 6781/15000 [58:56<24:35,  5.57it/s, lr=0.000846, step_loss=0.025307/27/2023 18:43:46 - INFO - __main__ - train loss is 15.816998941125348\n",
      "Steps:  45%|▍| 6782/15000 [58:56<24:35,  5.57it/s, lr=0.000846, step_loss=0.011807/27/2023 18:43:46 - INFO - __main__ - train loss is 15.835883538471535\n",
      "Steps:  45%|▍| 6783/15000 [58:56<24:35,  5.57it/s, lr=0.000846, step_loss=0.018907/27/2023 18:43:46 - INFO - __main__ - train loss is 15.977780456887558\n",
      "Steps:  45%|▍| 6784/15000 [58:56<24:35,  5.57it/s, lr=0.000846, step_loss=0.142]07/27/2023 18:43:46 - INFO - __main__ - train loss is 16.04412692342885\n",
      "Steps:  45%|▍| 6785/15000 [58:56<24:36,  5.57it/s, lr=0.000846, step_loss=0.066307/27/2023 18:43:46 - INFO - __main__ - train loss is 16.379682059632614\n",
      "Steps:  45%|▍| 6786/15000 [58:57<24:35,  5.57it/s, lr=0.000846, step_loss=0.336]07/27/2023 18:43:46 - INFO - __main__ - train loss is 16.409150782274082\n",
      "Steps:  45%|▍| 6787/15000 [58:57<26:05,  5.25it/s, lr=0.000847, step_loss=0.029507/27/2023 18:43:47 - INFO - __main__ - train loss is 16.411420559044927\n",
      "Steps:  45%|▍| 6788/15000 [58:57<27:44,  4.93it/s, lr=0.000847, step_loss=0.002207/27/2023 18:43:47 - INFO - __main__ - train loss is 16.58581963693723\n",
      "Steps:  45%|▍| 6789/15000 [58:57<27:10,  5.04it/s, lr=0.000847, step_loss=0.174]07/27/2023 18:43:47 - INFO - __main__ - train loss is 16.87577644502744\n",
      "Steps:  45%|▉ | 6790/15000 [58:57<27:56,  4.90it/s, lr=0.000847, step_loss=0.29]07/27/2023 18:43:47 - INFO - __main__ - train loss is 16.946430256124586\n",
      "Steps:  45%|▍| 6791/15000 [58:58<27:15,  5.02it/s, lr=0.000847, step_loss=0.070707/27/2023 18:43:48 - INFO - __main__ - train loss is 17.04878912633285\n",
      "Steps:  45%|▍| 6792/15000 [58:58<26:33,  5.15it/s, lr=0.000847, step_loss=0.102]07/27/2023 18:43:48 - INFO - __main__ - train loss is 17.088860114570707\n",
      "Steps:  45%|▍| 6793/15000 [58:58<26:05,  5.24it/s, lr=0.000847, step_loss=0.040107/27/2023 18:43:48 - INFO - __main__ - train loss is 17.09121147939004\n",
      "Steps:  45%|▍| 6794/15000 [58:58<25:45,  5.31it/s, lr=0.000847, step_loss=0.002307/27/2023 18:43:48 - INFO - __main__ - train loss is 17.23565773316659\n",
      "Steps:  45%|▍| 6795/15000 [58:58<25:33,  5.35it/s, lr=0.000848, step_loss=0.144]07/27/2023 18:43:48 - INFO - __main__ - train loss is 17.271315463120118\n",
      "Steps:  45%|▍| 6796/15000 [58:59<25:21,  5.39it/s, lr=0.000848, step_loss=0.035707/27/2023 18:43:48 - INFO - __main__ - train loss is 17.280244152294472\n",
      "Steps:  45%|▍| 6797/15000 [58:59<25:12,  5.42it/s, lr=0.000848, step_loss=0.008907/27/2023 18:43:49 - INFO - __main__ - train loss is 17.49896092270501\n",
      "Steps:  45%|▍| 6798/15000 [58:59<25:07,  5.44it/s, lr=0.000848, step_loss=0.219]07/27/2023 18:43:49 - INFO - __main__ - train loss is 17.627737949835137\n",
      "Steps:  45%|▍| 6799/15000 [58:59<25:03,  5.46it/s, lr=0.000848, step_loss=0.129]07/27/2023 18:43:49 - INFO - __main__ - train loss is 17.634678836213425\n",
      "Steps:  45%|▍| 6800/15000 [58:59<25:00,  5.47it/s, lr=0.000848, step_loss=0.006907/27/2023 18:43:49 - INFO - __main__ - train loss is 17.83300633286126\n",
      "Steps:  45%|▍| 6801/15000 [58:59<24:59,  5.47it/s, lr=0.000848, step_loss=0.198]07/27/2023 18:43:49 - INFO - __main__ - train loss is 17.863778124796227\n",
      "Steps:  45%|▍| 6802/15000 [59:00<24:57,  5.47it/s, lr=0.000848, step_loss=0.030807/27/2023 18:43:50 - INFO - __main__ - train loss is 18.29147932981141\n",
      "Steps:  45%|▍| 6803/15000 [59:00<24:56,  5.48it/s, lr=0.000849, step_loss=0.428]07/27/2023 18:43:50 - INFO - __main__ - train loss is 18.46544478391297\n",
      "Steps:  45%|▍| 6804/15000 [59:00<24:55,  5.48it/s, lr=0.000849, step_loss=0.174]07/27/2023 18:43:50 - INFO - __main__ - train loss is 18.479589817347005\n",
      "Steps:  45%|▍| 6805/15000 [59:00<24:54,  5.48it/s, lr=0.000849, step_loss=0.014107/27/2023 18:43:50 - INFO - __main__ - train loss is 18.74226298672147\n",
      "Steps:  45%|▍| 6806/15000 [59:00<25:04,  5.44it/s, lr=0.000849, step_loss=0.263]07/27/2023 18:43:50 - INFO - __main__ - train loss is 18.867241968633607\n",
      "Steps:  45%|▍| 6807/15000 [59:01<24:54,  5.48it/s, lr=0.000849, step_loss=0.125]07/27/2023 18:43:50 - INFO - __main__ - train loss is 19.00703399372287\n",
      "Steps:  45%|▉ | 6808/15000 [59:01<24:48,  5.50it/s, lr=0.000849, step_loss=0.14]07/27/2023 18:43:51 - INFO - __main__ - train loss is 19.21547526610084\n",
      "Steps:  45%|▍| 6809/15000 [59:01<24:43,  5.52it/s, lr=0.000849, step_loss=0.208]07/27/2023 18:43:51 - INFO - __main__ - train loss is 19.397564684273675\n",
      "Steps:  45%|▍| 6810/15000 [59:01<24:40,  5.53it/s, lr=0.000849, step_loss=0.182]07/27/2023 18:43:51 - INFO - __main__ - train loss is 19.610437711002305\n",
      "Steps:  45%|▉ | 6811/15000 [59:01<24:36,  5.54it/s, lr=0.00085, step_loss=0.213]07/27/2023 18:43:51 - INFO - __main__ - train loss is 19.6400136325974\n",
      "Steps:  45%|▍| 6812/15000 [59:01<24:35,  5.55it/s, lr=0.00085, step_loss=0.0296]07/27/2023 18:43:51 - INFO - __main__ - train loss is 19.691183743299916\n",
      "Steps:  45%|▍| 6813/15000 [59:02<24:33,  5.55it/s, lr=0.00085, step_loss=0.0512]07/27/2023 18:43:52 - INFO - __main__ - train loss is 19.850217727245763\n",
      "Steps:  45%|▉ | 6814/15000 [59:02<24:33,  5.56it/s, lr=0.00085, step_loss=0.159]07/27/2023 18:43:52 - INFO - __main__ - train loss is 19.86223292374052\n",
      "Steps:  45%|▉ | 6815/15000 [59:02<24:32,  5.56it/s, lr=0.00085, step_loss=0.012]07/27/2023 18:43:52 - INFO - __main__ - train loss is 20.458065748447552\n",
      "Steps:  45%|▉ | 6816/15000 [59:02<24:32,  5.56it/s, lr=0.00085, step_loss=0.596]07/27/2023 18:43:52 - INFO - __main__ - train loss is 20.71756312274374\n",
      "Steps:  45%|▉ | 6817/15000 [59:02<24:31,  5.56it/s, lr=0.00085, step_loss=0.259]07/27/2023 18:43:52 - INFO - __main__ - train loss is 20.742329340660945\n",
      "Steps:  45%|▍| 6818/15000 [59:03<24:30,  5.56it/s, lr=0.00085, step_loss=0.0248]07/27/2023 18:43:52 - INFO - __main__ - train loss is 20.753151955315843\n",
      "Steps:  45%|▍| 6819/15000 [59:03<24:30,  5.56it/s, lr=0.000851, step_loss=0.010807/27/2023 18:43:53 - INFO - __main__ - train loss is 21.44375986070372\n",
      "Steps:  45%|▍| 6820/15000 [59:03<24:30,  5.56it/s, lr=0.000851, step_loss=0.691]07/27/2023 18:43:53 - INFO - __main__ - train loss is 21.60245275706984\n",
      "Steps:  45%|▍| 6821/15000 [59:03<24:30,  5.56it/s, lr=0.000851, step_loss=0.159]07/27/2023 18:43:53 - INFO - __main__ - train loss is 21.750504585215822\n",
      "Steps:  45%|▍| 6822/15000 [59:03<24:30,  5.56it/s, lr=0.000851, step_loss=0.148]07/27/2023 18:43:53 - INFO - __main__ - train loss is 21.862242365488783\n",
      "Steps:  45%|▍| 6823/15000 [59:03<24:30,  5.56it/s, lr=0.000851, step_loss=0.112]07/27/2023 18:43:53 - INFO - __main__ - train loss is 21.897303531179205\n",
      "Steps:  45%|▍| 6824/15000 [59:04<24:31,  5.56it/s, lr=0.000851, step_loss=0.035107/27/2023 18:43:54 - INFO - __main__ - train loss is 22.077316204318777\n",
      "Steps:  46%|▉ | 6825/15000 [59:04<24:30,  5.56it/s, lr=0.000851, step_loss=0.18]07/27/2023 18:43:54 - INFO - __main__ - train loss is 22.113833898911253\n",
      "Steps:  46%|▍| 6826/15000 [59:04<24:30,  5.56it/s, lr=0.000851, step_loss=0.036507/27/2023 18:43:54 - INFO - __main__ - train loss is 22.117443449329585\n",
      "Steps:  46%|▍| 6827/15000 [59:04<24:29,  5.56it/s, lr=0.000852, step_loss=0.003607/27/2023 18:43:54 - INFO - __main__ - train loss is 22.127535257022828\n",
      "Steps:  46%|▍| 6828/15000 [59:04<24:28,  5.56it/s, lr=0.000852, step_loss=0.010107/27/2023 18:43:54 - INFO - __main__ - train loss is 22.23668863205239\n",
      "Steps:  46%|▍| 6829/15000 [59:05<24:29,  5.56it/s, lr=0.000852, step_loss=0.109]07/27/2023 18:43:54 - INFO - __main__ - train loss is 22.25618596887216\n",
      "Steps:  46%|▍| 6830/15000 [59:05<24:28,  5.56it/s, lr=0.000852, step_loss=0.019507/27/2023 18:43:55 - INFO - __main__ - train loss is 22.289426108356565\n",
      "Steps:  46%|▍| 6831/15000 [59:05<24:28,  5.56it/s, lr=0.000852, step_loss=0.033207/27/2023 18:43:55 - INFO - __main__ - train loss is 22.30894730752334\n",
      "Steps:  46%|▍| 6832/15000 [59:05<24:28,  5.56it/s, lr=0.000852, step_loss=0.019507/27/2023 18:43:55 - INFO - __main__ - train loss is 22.538970453199\n",
      "Steps:  46%|▉ | 6833/15000 [59:05<24:28,  5.56it/s, lr=0.000852, step_loss=0.23]07/27/2023 18:43:55 - INFO - __main__ - train loss is 22.97530142730102\n",
      "Steps:  46%|▍| 6834/15000 [59:05<24:28,  5.56it/s, lr=0.000852, step_loss=0.436]07/27/2023 18:43:55 - INFO - __main__ - train loss is 23.150144589599222\n",
      "Steps:  46%|▍| 6835/15000 [59:06<24:27,  5.56it/s, lr=0.000853, step_loss=0.175]07/27/2023 18:43:55 - INFO - __main__ - train loss is 23.158653320278972\n",
      "Steps:  46%|▍| 6836/15000 [59:06<24:26,  5.57it/s, lr=0.000853, step_loss=0.008507/27/2023 18:43:56 - INFO - __main__ - train loss is 23.518322946038097\n",
      "Steps:  46%|▉ | 6837/15000 [59:06<24:26,  5.57it/s, lr=0.000853, step_loss=0.36]07/27/2023 18:43:56 - INFO - __main__ - train loss is 23.522160975262523\n",
      "Steps:  46%|▍| 6838/15000 [59:06<24:26,  5.57it/s, lr=0.000853, step_loss=0.003807/27/2023 18:43:56 - INFO - __main__ - train loss is 23.574573745951056\n",
      "Steps:  46%|▍| 6839/15000 [59:06<24:25,  5.57it/s, lr=0.000853, step_loss=0.052407/27/2023 18:43:56 - INFO - __main__ - train loss is 23.79901205562055\n",
      "Steps:  46%|▍| 6840/15000 [59:07<24:25,  5.57it/s, lr=0.000853, step_loss=0.224]07/27/2023 18:43:56 - INFO - __main__ - train loss is 23.81208387762308\n",
      "Steps:  46%|▍| 6841/15000 [59:07<24:25,  5.57it/s, lr=0.000853, step_loss=0.013107/27/2023 18:43:57 - INFO - __main__ - train loss is 23.933598287403584\n",
      "Steps:  46%|▍| 6842/15000 [59:07<24:25,  5.57it/s, lr=0.000853, step_loss=0.122]07/27/2023 18:43:57 - INFO - __main__ - train loss is 24.007202737033367\n",
      "Steps:  46%|▍| 6843/15000 [59:07<24:24,  5.57it/s, lr=0.000854, step_loss=0.073607/27/2023 18:43:57 - INFO - __main__ - train loss is 24.296881429851055\n",
      "Steps:  46%|▉ | 6844/15000 [59:07<24:24,  5.57it/s, lr=0.000854, step_loss=0.29]07/27/2023 18:43:57 - INFO - __main__ - train loss is 24.82990049570799\n",
      "Steps:  46%|▍| 6845/15000 [59:07<24:24,  5.57it/s, lr=0.000854, step_loss=0.533]07/27/2023 18:43:57 - INFO - __main__ - train loss is 24.839369253255427\n",
      "Steps:  46%|▍| 6846/15000 [59:08<24:24,  5.57it/s, lr=0.000854, step_loss=0.009407/27/2023 18:43:57 - INFO - __main__ - train loss is 24.882219248451293\n",
      "Steps:  46%|▍| 6847/15000 [59:08<24:23,  5.57it/s, lr=0.000854, step_loss=0.042807/27/2023 18:43:58 - INFO - __main__ - train loss is 25.149765842594206\n",
      "Steps:  46%|▍| 6848/15000 [59:08<24:23,  5.57it/s, lr=0.000854, step_loss=0.268]07/27/2023 18:43:58 - INFO - __main__ - train loss is 25.21698282007128\n",
      "Steps:  46%|▍| 6849/15000 [59:08<24:23,  5.57it/s, lr=0.000854, step_loss=0.067207/27/2023 18:43:58 - INFO - __main__ - train loss is 25.23469829838723\n",
      "Steps:  46%|▍| 6850/15000 [59:08<24:22,  5.57it/s, lr=0.000854, step_loss=0.017707/27/2023 18:43:58 - INFO - __main__ - train loss is 25.255406358279288\n",
      "Steps:  46%|▍| 6851/15000 [59:08<24:22,  5.57it/s, lr=0.000855, step_loss=0.020707/27/2023 18:43:58 - INFO - __main__ - train loss is 25.345044338144362\n",
      "Steps:  46%|▍| 6852/15000 [59:09<24:22,  5.57it/s, lr=0.000855, step_loss=0.089607/27/2023 18:43:59 - INFO - __main__ - train loss is 25.376100317575037\n",
      "Steps:  46%|▍| 6853/15000 [59:09<24:22,  5.57it/s, lr=0.000855, step_loss=0.031107/27/2023 18:43:59 - INFO - __main__ - train loss is 25.54431000445038\n",
      "Steps:  46%|▍| 6854/15000 [59:09<24:21,  5.57it/s, lr=0.000855, step_loss=0.168]07/27/2023 18:43:59 - INFO - __main__ - train loss is 25.583327018655837\n",
      "Steps:  46%|▍| 6855/15000 [59:09<24:21,  5.57it/s, lr=0.000855, step_loss=0.039]07/27/2023 18:43:59 - INFO - __main__ - train loss is 25.720088326372206\n",
      "Steps:  46%|▍| 6856/15000 [59:09<24:21,  5.57it/s, lr=0.000855, step_loss=0.137]07/27/2023 18:43:59 - INFO - __main__ - train loss is 26.01318743173033\n",
      "Steps:  46%|▍| 6857/15000 [59:10<24:21,  5.57it/s, lr=0.000855, step_loss=0.293]07/27/2023 18:43:59 - INFO - __main__ - train loss is 26.016276742797345\n",
      "Steps:  46%|▍| 6858/15000 [59:10<24:22,  5.57it/s, lr=0.000855, step_loss=0.003007/27/2023 18:44:00 - INFO - __main__ - train loss is 26.439268376212567\n",
      "Steps:  46%|▍| 6859/15000 [59:10<24:20,  5.57it/s, lr=0.000856, step_loss=0.423]07/27/2023 18:44:00 - INFO - __main__ - train loss is 26.681337754707783\n",
      "Steps:  46%|▍| 6860/15000 [59:10<24:20,  5.57it/s, lr=0.000856, step_loss=0.242]07/27/2023 18:44:00 - INFO - __main__ - train loss is 26.832643907051533\n",
      "Steps:  46%|▍| 6861/15000 [59:10<24:20,  5.57it/s, lr=0.000856, step_loss=0.151]07/27/2023 18:44:00 - INFO - __main__ - train loss is 26.888211138080806\n",
      "Steps:  46%|▍| 6862/15000 [59:10<24:20,  5.57it/s, lr=0.000856, step_loss=0.055607/27/2023 18:44:00 - INFO - __main__ - train loss is 27.066009439062327\n",
      "Steps:  46%|▍| 6863/15000 [59:11<24:20,  5.57it/s, lr=0.000856, step_loss=0.178]07/27/2023 18:44:01 - INFO - __main__ - train loss is 27.232022322248667\n",
      "Steps:  46%|▍| 6864/15000 [59:11<24:20,  5.57it/s, lr=0.000856, step_loss=0.166]07/27/2023 18:44:01 - INFO - __main__ - train loss is 27.290302864741534\n",
      "Steps:  46%|▍| 6865/15000 [59:11<24:20,  5.57it/s, lr=0.000856, step_loss=0.058307/27/2023 18:44:01 - INFO - __main__ - train loss is 27.298884176183492\n",
      "Steps:  46%|▍| 6866/15000 [59:11<24:19,  5.57it/s, lr=0.000856, step_loss=0.008507/27/2023 18:44:01 - INFO - __main__ - train loss is 27.98599710362032\n",
      "Steps:  46%|▍| 6867/15000 [59:11<24:19,  5.57it/s, lr=0.000857, step_loss=0.687]07/27/2023 18:44:01 - INFO - __main__ - train loss is 28.70076944725588\n",
      "Steps:  46%|▍| 6868/15000 [59:12<24:19,  5.57it/s, lr=0.000857, step_loss=0.715]07/27/2023 18:44:01 - INFO - __main__ - train loss is 29.01984377996996\n",
      "Steps:  46%|▍| 6869/15000 [59:12<24:18,  5.57it/s, lr=0.000857, step_loss=0.319]07/27/2023 18:44:02 - INFO - __main__ - train loss is 29.283510946203023\n",
      "Steps:  46%|▍| 6870/15000 [59:12<24:19,  5.57it/s, lr=0.000857, step_loss=0.264]07/27/2023 18:44:02 - INFO - __main__ - train loss is 29.418085091281682\n",
      "Steps:  46%|▍| 6871/15000 [59:12<24:18,  5.57it/s, lr=0.000857, step_loss=0.135]07/27/2023 18:44:02 - INFO - __main__ - train loss is 29.423903338145465\n",
      "Steps:  46%|▍| 6872/15000 [59:12<24:19,  5.57it/s, lr=0.000857, step_loss=0.005807/27/2023 18:44:02 - INFO - __main__ - train loss is 29.564283199142665\n",
      "Steps:  46%|▉ | 6873/15000 [59:12<24:19,  5.57it/s, lr=0.000857, step_loss=0.14]07/27/2023 18:44:02 - INFO - __main__ - train loss is 29.891441531013697\n",
      "Steps:  46%|▍| 6874/15000 [59:13<24:19,  5.57it/s, lr=0.000857, step_loss=0.327]07/27/2023 18:44:02 - INFO - __main__ - train loss is 29.898665680084378\n",
      "Steps:  46%|▍| 6875/15000 [59:13<24:19,  5.57it/s, lr=0.000858, step_loss=0.007207/27/2023 18:44:03 - INFO - __main__ - train loss is 30.126183761749417\n",
      "Steps:  46%|▍| 6876/15000 [59:13<24:19,  5.57it/s, lr=0.000858, step_loss=0.228]07/27/2023 18:44:03 - INFO - __main__ - train loss is 30.25385439256206\n",
      "Steps:  46%|▍| 6877/15000 [59:13<24:18,  5.57it/s, lr=0.000858, step_loss=0.128]07/27/2023 18:44:03 - INFO - __main__ - train loss is 30.258669040631503\n",
      "Steps:  46%|▍| 6878/15000 [59:13<24:19,  5.57it/s, lr=0.000858, step_loss=0.004807/27/2023 18:44:03 - INFO - __main__ - train loss is 30.35550133092329\n",
      "Steps:  46%|▍| 6879/15000 [59:14<24:19,  5.57it/s, lr=0.000858, step_loss=0.096807/27/2023 18:44:03 - INFO - __main__ - train loss is 30.60058707697317\n",
      "Steps:  46%|▍| 6880/15000 [59:14<24:19,  5.56it/s, lr=0.000858, step_loss=0.245]07/27/2023 18:44:04 - INFO - __main__ - train loss is 30.725129201542586\n",
      "Steps:  46%|▍| 6881/15000 [59:14<24:19,  5.56it/s, lr=0.000858, step_loss=0.125]07/27/2023 18:44:04 - INFO - __main__ - train loss is 30.728472067508847\n",
      "Steps:  46%|▍| 6882/15000 [59:14<24:18,  5.57it/s, lr=0.000858, step_loss=0.003307/27/2023 18:44:04 - INFO - __main__ - train loss is 30.73891880409792\n",
      "Steps:  46%|▍| 6883/15000 [59:14<24:18,  5.56it/s, lr=0.000859, step_loss=0.010407/27/2023 18:44:04 - INFO - __main__ - train loss is 30.74730288190767\n",
      "Steps:  46%|▍| 6884/15000 [59:14<24:18,  5.56it/s, lr=0.000859, step_loss=0.008307/27/2023 18:44:04 - INFO - __main__ - train loss is 30.760145660024136\n",
      "Steps:  46%|▍| 6885/15000 [59:15<24:19,  5.56it/s, lr=0.000859, step_loss=0.012807/27/2023 18:44:04 - INFO - __main__ - train loss is 30.932693760376424\n",
      "Steps:  46%|▍| 6886/15000 [59:15<24:21,  5.55it/s, lr=0.000859, step_loss=0.173]07/27/2023 18:44:05 - INFO - __main__ - train loss is 31.352772395592183\n",
      "Steps:  46%|▉ | 6887/15000 [59:15<24:20,  5.55it/s, lr=0.000859, step_loss=0.42]07/27/2023 18:44:05 - INFO - __main__ - train loss is 31.47302624164149\n",
      "Steps:  46%|▉ | 6888/15000 [59:15<24:19,  5.56it/s, lr=0.000859, step_loss=0.12]07/27/2023 18:44:05 - INFO - __main__ - train loss is 31.655943568330258\n",
      "Steps:  46%|▍| 6889/15000 [59:15<24:18,  5.56it/s, lr=0.000859, step_loss=0.183]07/27/2023 18:44:05 - INFO - __main__ - train loss is 31.829349632840604\n",
      "Steps:  46%|▍| 6890/15000 [59:15<24:18,  5.56it/s, lr=0.000859, step_loss=0.173]07/27/2023 18:44:05 - INFO - __main__ - train loss is 31.859117358457297\n",
      "Steps:  46%|▍| 6891/15000 [59:16<24:17,  5.56it/s, lr=0.00086, step_loss=0.0298]07/27/2023 18:44:06 - INFO - __main__ - train loss is 32.0953334714286\n",
      "Steps:  46%|▉ | 6892/15000 [59:16<24:17,  5.56it/s, lr=0.00086, step_loss=0.236]07/27/2023 18:44:06 - INFO - __main__ - train loss is 32.237832113634795\n",
      "Steps:  46%|▉ | 6893/15000 [59:16<24:19,  5.56it/s, lr=0.00086, step_loss=0.142]07/27/2023 18:44:06 - INFO - __main__ - train loss is 32.38588227285072\n",
      "Steps:  46%|▉ | 6894/15000 [59:16<24:18,  5.56it/s, lr=0.00086, step_loss=0.148]07/27/2023 18:44:06 - INFO - __main__ - train loss is 32.45408898545429\n",
      "Steps:  46%|▍| 6895/15000 [59:16<24:18,  5.56it/s, lr=0.00086, step_loss=0.0682]07/27/2023 18:44:06 - INFO - __main__ - train loss is 32.760077505838126\n",
      "Steps:  46%|▉ | 6896/15000 [59:17<24:17,  5.56it/s, lr=0.00086, step_loss=0.306]07/27/2023 18:44:06 - INFO - __main__ - train loss is 33.00250074220821\n",
      "Steps:  46%|▉ | 6897/15000 [59:17<24:16,  5.56it/s, lr=0.00086, step_loss=0.242]07/27/2023 18:44:07 - INFO - __main__ - train loss is 33.01258276915178\n",
      "Steps:  46%|▍| 6898/15000 [59:17<24:15,  5.56it/s, lr=0.00086, step_loss=0.0101]07/27/2023 18:44:07 - INFO - __main__ - train loss is 33.01361410866957\n",
      "Steps:  46%|▍| 6899/15000 [59:17<24:15,  5.56it/s, lr=0.000861, step_loss=0.001007/27/2023 18:44:07 - INFO - __main__ - train loss is 33.01586216397118\n",
      "Steps:  46%|▍| 6900/15000 [59:17<24:15,  5.57it/s, lr=0.000861, step_loss=0.002207/27/2023 18:44:07 - INFO - __main__ - train loss is 33.01732488616835\n",
      "Steps:  46%|▍| 6901/15000 [59:17<24:14,  5.57it/s, lr=0.000861, step_loss=0.001407/27/2023 18:44:07 - INFO - __main__ - train loss is 33.03330220922362\n",
      "Steps:  46%|▍| 6902/15000 [59:18<24:13,  5.57it/s, lr=0.000861, step_loss=0.016]07/27/2023 18:44:08 - INFO - __main__ - train loss is 33.09931853308808\n",
      "Steps:  46%|▍| 6903/15000 [59:18<24:13,  5.57it/s, lr=0.000861, step_loss=0.066]07/27/2023 18:44:08 - INFO - __main__ - train loss is 33.10975306376349\n",
      "Steps:  46%|▍| 6904/15000 [59:18<24:13,  5.57it/s, lr=0.000861, step_loss=0.010407/27/2023 18:44:08 - INFO - __main__ - train loss is 33.14019730768632\n",
      "Steps:  46%|▍| 6905/15000 [59:18<24:13,  5.57it/s, lr=0.000861, step_loss=0.030407/27/2023 18:44:08 - INFO - __main__ - train loss is 33.41902369342279\n",
      "Steps:  46%|▍| 6906/15000 [59:18<24:12,  5.57it/s, lr=0.000861, step_loss=0.279]07/27/2023 18:44:08 - INFO - __main__ - train loss is 33.45985484204721\n",
      "Steps:  46%|▍| 6907/15000 [59:19<24:12,  5.57it/s, lr=0.000862, step_loss=0.040807/27/2023 18:44:08 - INFO - __main__ - train loss is 33.463757111807354\n",
      "Steps:  46%|▍| 6908/15000 [59:19<24:12,  5.57it/s, lr=0.000862, step_loss=0.003907/27/2023 18:44:09 - INFO - __main__ - train loss is 33.47089446906466\n",
      "Steps:  46%|▍| 6909/15000 [59:19<24:25,  5.52it/s, lr=0.000862, step_loss=0.007107/27/2023 18:44:09 - INFO - __main__ - train loss is 33.47351391927805\n",
      "Steps:  46%|▍| 6910/15000 [59:19<24:21,  5.54it/s, lr=0.000862, step_loss=0.002607/27/2023 18:44:09 - INFO - __main__ - train loss is 33.49946129263844\n",
      "Steps:  46%|▍| 6911/15000 [59:19<24:18,  5.54it/s, lr=0.000862, step_loss=0.025907/27/2023 18:44:09 - INFO - __main__ - train loss is 33.701357751502655\n",
      "Steps:  46%|▍| 6912/15000 [59:19<24:17,  5.55it/s, lr=0.000862, step_loss=0.202]07/27/2023 18:44:09 - INFO - __main__ - train loss is 34.014636843814515\n",
      "Steps:  46%|▍| 6913/15000 [59:20<24:15,  5.56it/s, lr=0.000862, step_loss=0.313]07/27/2023 18:44:10 - INFO - __main__ - train loss is 34.01590539270546\n",
      "Steps:  46%|▍| 6914/15000 [59:20<24:13,  5.56it/s, lr=0.000862, step_loss=0.001207/27/2023 18:44:10 - INFO - __main__ - train loss is 34.02323395514395\n",
      "Steps:  46%|▍| 6915/15000 [59:20<24:13,  5.56it/s, lr=0.000863, step_loss=0.007307/27/2023 18:44:10 - INFO - __main__ - train loss is 34.03381781128701\n",
      "Steps:  46%|▍| 6916/15000 [59:20<24:12,  5.56it/s, lr=0.000863, step_loss=0.010607/27/2023 18:44:10 - INFO - __main__ - train loss is 34.07517629710492\n",
      "Steps:  46%|▍| 6917/15000 [59:20<24:11,  5.57it/s, lr=0.000863, step_loss=0.041407/27/2023 18:44:10 - INFO - __main__ - train loss is 34.231008885777555\n",
      "Steps:  46%|▍| 6918/15000 [59:21<24:12,  5.57it/s, lr=0.000863, step_loss=0.156]07/27/2023 18:44:10 - INFO - __main__ - train loss is 34.254828082746826\n",
      "Steps:  46%|▍| 6919/15000 [59:21<24:12,  5.57it/s, lr=0.000863, step_loss=0.023807/27/2023 18:44:11 - INFO - __main__ - train loss is 34.32607472164091\n",
      "Steps:  46%|▍| 6920/15000 [59:21<24:11,  5.57it/s, lr=0.000863, step_loss=0.071207/27/2023 18:44:11 - INFO - __main__ - train loss is 34.59048557502683\n",
      "Steps:  46%|▍| 6921/15000 [59:21<24:11,  5.57it/s, lr=0.000863, step_loss=0.264]07/27/2023 18:44:11 - INFO - __main__ - train loss is 34.71349731308874\n",
      "Steps:  46%|▍| 6922/15000 [59:21<24:12,  5.56it/s, lr=0.000863, step_loss=0.123]07/27/2023 18:44:11 - INFO - __main__ - train loss is 34.89369635505136\n",
      "Steps:  46%|▉ | 6923/15000 [59:21<24:11,  5.56it/s, lr=0.000864, step_loss=0.18]07/27/2023 18:44:11 - INFO - __main__ - train loss is 34.89650128304493\n",
      "Steps:  46%|▍| 6924/15000 [59:22<24:10,  5.57it/s, lr=0.000864, step_loss=0.002807/27/2023 18:44:11 - INFO - __main__ - train loss is 34.90293524588924\n",
      "Steps:  46%|▍| 6925/15000 [59:22<24:11,  5.56it/s, lr=0.000864, step_loss=0.006407/27/2023 18:44:12 - INFO - __main__ - train loss is 35.030637824791484\n",
      "Steps:  46%|▍| 6926/15000 [59:22<24:10,  5.57it/s, lr=0.000864, step_loss=0.128]07/27/2023 18:44:12 - INFO - __main__ - train loss is 35.05364909383934\n",
      "Steps:  46%|▍| 6927/15000 [59:22<24:10,  5.57it/s, lr=0.000864, step_loss=0.023]07/27/2023 18:44:12 - INFO - __main__ - train loss is 35.216050740214996\n",
      "Steps:  46%|▍| 6928/15000 [59:22<24:10,  5.56it/s, lr=0.000864, step_loss=0.162]07/27/2023 18:44:12 - INFO - __main__ - train loss is 35.2928560039727\n",
      "Steps:  46%|▍| 6929/15000 [59:23<24:10,  5.57it/s, lr=0.000864, step_loss=0.076807/27/2023 18:44:12 - INFO - __main__ - train loss is 35.37277937296312\n",
      "Steps:  46%|▍| 6930/15000 [59:23<24:10,  5.56it/s, lr=0.000864, step_loss=0.079907/27/2023 18:44:13 - INFO - __main__ - train loss is 35.42411265138071\n",
      "Steps:  46%|▍| 6931/15000 [59:23<24:09,  5.57it/s, lr=0.000865, step_loss=0.051307/27/2023 18:44:13 - INFO - __main__ - train loss is 35.995357844862156\n",
      "Steps:  46%|▍| 6932/15000 [59:23<24:09,  5.57it/s, lr=0.000865, step_loss=0.571]07/27/2023 18:44:13 - INFO - __main__ - train loss is 36.02181982982438\n",
      "Steps:  46%|▍| 6933/15000 [59:23<24:09,  5.57it/s, lr=0.000865, step_loss=0.026507/27/2023 18:44:13 - INFO - __main__ - train loss is 36.35294252622407\n",
      "Steps:  46%|▍| 6934/15000 [59:23<24:08,  5.57it/s, lr=0.000865, step_loss=0.331]07/27/2023 18:44:13 - INFO - __main__ - train loss is 36.53293055284303\n",
      "Steps:  46%|▉ | 6935/15000 [59:24<24:09,  5.56it/s, lr=0.000865, step_loss=0.18]07/27/2023 18:44:13 - INFO - __main__ - train loss is 36.536180958966725\n",
      "Steps:  46%|▍| 6936/15000 [59:24<24:10,  5.56it/s, lr=0.000865, step_loss=0.003207/27/2023 18:44:14 - INFO - __main__ - train loss is 36.54177482321393\n",
      "Steps:  46%|▍| 6937/15000 [59:24<24:10,  5.56it/s, lr=0.000865, step_loss=0.005507/27/2023 18:44:14 - INFO - __main__ - train loss is 36.59655912860762\n",
      "Steps:  46%|▍| 6938/15000 [59:24<24:09,  5.56it/s, lr=0.000865, step_loss=0.054807/27/2023 18:44:14 - INFO - __main__ - train loss is 36.75234111293685\n",
      "Steps:  46%|▍| 6939/15000 [59:24<24:09,  5.56it/s, lr=0.000866, step_loss=0.156]07/27/2023 18:44:14 - INFO - __main__ - train loss is 36.87687941535842\n",
      "Steps:  46%|▍| 6940/15000 [59:24<24:08,  5.56it/s, lr=0.000866, step_loss=0.125]07/27/2023 18:44:14 - INFO - __main__ - train loss is 37.17320426448714\n",
      "Steps:  46%|▍| 6941/15000 [59:25<24:08,  5.56it/s, lr=0.000866, step_loss=0.296]07/27/2023 18:44:15 - INFO - __main__ - train loss is 37.20230683579575\n",
      "Steps:  46%|▍| 6942/15000 [59:25<24:08,  5.56it/s, lr=0.000866, step_loss=0.029107/27/2023 18:44:15 - INFO - __main__ - train loss is 37.54769748344552\n",
      "Steps:  46%|▍| 6943/15000 [59:25<24:08,  5.56it/s, lr=0.000866, step_loss=0.345]07/27/2023 18:44:15 - INFO - __main__ - train loss is 37.58014637127053\n",
      "Steps:  46%|▍| 6944/15000 [59:25<24:07,  5.57it/s, lr=0.000866, step_loss=0.032407/27/2023 18:44:15 - INFO - __main__ - train loss is 37.610392666305415\n",
      "Steps:  46%|▍| 6945/15000 [59:25<24:07,  5.57it/s, lr=0.000866, step_loss=0.030207/27/2023 18:44:15 - INFO - __main__ - train loss is 37.6321070183767\n",
      "Steps:  46%|▍| 6946/15000 [59:26<24:06,  5.57it/s, lr=0.000866, step_loss=0.021707/27/2023 18:44:15 - INFO - __main__ - train loss is 37.84455405070912\n",
      "Steps:  46%|▍| 6947/15000 [59:26<24:06,  5.57it/s, lr=0.000867, step_loss=0.212]07/27/2023 18:44:16 - INFO - __main__ - train loss is 37.864902290399186\n",
      "Steps:  46%|▍| 6948/15000 [59:26<24:06,  5.57it/s, lr=0.000867, step_loss=0.020307/27/2023 18:44:16 - INFO - __main__ - train loss is 37.96518849104177\n",
      "Steps:  46%|█▍ | 6949/15000 [59:26<24:06,  5.57it/s, lr=0.000867, step_loss=0.1]07/27/2023 18:44:16 - INFO - __main__ - train loss is 38.39992566674482\n",
      "Steps:  46%|▍| 6950/15000 [59:26<24:13,  5.54it/s, lr=0.000867, step_loss=0.435]07/27/2023 18:44:16 - INFO - __main__ - train loss is 38.5263522741152\n",
      "Steps:  46%|▍| 6951/15000 [59:26<24:26,  5.49it/s, lr=0.000867, step_loss=0.126]07/27/2023 18:44:16 - INFO - __main__ - train loss is 38.57250764861237\n",
      "Steps:  46%|▍| 6952/15000 [59:27<24:19,  5.51it/s, lr=0.000867, step_loss=0.046207/27/2023 18:44:17 - INFO - __main__ - train loss is 38.58128723397385\n",
      "Steps:  46%|▍| 6953/15000 [59:27<24:13,  5.54it/s, lr=0.000867, step_loss=0.008707/27/2023 18:44:17 - INFO - __main__ - train loss is 38.974319844390266\n",
      "Steps:  46%|▍| 6954/15000 [59:27<24:08,  5.55it/s, lr=0.000867, step_loss=0.393]07/27/2023 18:44:17 - INFO - __main__ - train loss is 38.982499220292084\n",
      "Steps:  46%|▍| 6955/15000 [59:27<24:06,  5.56it/s, lr=0.000868, step_loss=0.008107/27/2023 18:44:17 - INFO - __main__ - train loss is 39.106656082789414\n",
      "Steps:  46%|▍| 6956/15000 [59:27<24:06,  5.56it/s, lr=0.000868, step_loss=0.124]07/27/2023 18:44:17 - INFO - __main__ - train loss is 39.16738450608682\n",
      "Steps:  46%|▍| 6957/15000 [59:28<24:04,  5.57it/s, lr=0.000868, step_loss=0.060707/27/2023 18:44:17 - INFO - __main__ - train loss is 39.2036848225398\n",
      "Steps:  46%|▍| 6958/15000 [59:28<24:05,  5.56it/s, lr=0.000868, step_loss=0.036307/27/2023 18:44:18 - INFO - __main__ - train loss is 39.249721870641224\n",
      "Steps:  46%|▍| 6959/15000 [59:28<24:04,  5.57it/s, lr=0.000868, step_loss=0.046]07/27/2023 18:44:18 - INFO - __main__ - train loss is 39.558937714318745\n",
      "Steps:  46%|▍| 6960/15000 [59:28<24:07,  5.56it/s, lr=0.000868, step_loss=0.309]07/27/2023 18:44:18 - INFO - __main__ - train loss is 39.565279282513075\n",
      "Steps:  46%|▍| 6961/15000 [59:28<24:03,  5.57it/s, lr=0.000868, step_loss=0.006307/27/2023 18:44:18 - INFO - __main__ - train loss is 39.77776882785838\n",
      "Steps:  46%|▍| 6962/15000 [59:28<24:08,  5.55it/s, lr=0.000868, step_loss=0.212]07/27/2023 18:44:18 - INFO - __main__ - train loss is 40.07428786891978\n",
      "Steps:  46%|▍| 6963/15000 [59:29<24:07,  5.55it/s, lr=0.000869, step_loss=0.297]07/27/2023 18:44:18 - INFO - __main__ - train loss is 40.08710039395373\n",
      "Steps:  46%|▍| 6964/15000 [59:29<24:04,  5.56it/s, lr=0.000869, step_loss=0.012807/27/2023 18:44:19 - INFO - __main__ - train loss is 40.090850878390484\n",
      "Steps:  46%|▍| 6965/15000 [59:29<24:10,  5.54it/s, lr=0.000869, step_loss=0.003707/27/2023 18:44:19 - INFO - __main__ - train loss is 40.130879361066036\n",
      "Steps:  46%|▉ | 6966/15000 [59:29<24:18,  5.51it/s, lr=0.000869, step_loss=0.04]07/27/2023 18:44:19 - INFO - __main__ - train loss is 40.3191175943939\n",
      "Steps:  46%|▍| 6967/15000 [59:29<24:12,  5.53it/s, lr=0.000869, step_loss=0.188]07/27/2023 18:44:19 - INFO - __main__ - train loss is 40.34774850856047\n",
      "Steps:  46%|▍| 6968/15000 [59:30<24:08,  5.55it/s, lr=0.000869, step_loss=0.028607/27/2023 18:44:20 - INFO - __main__ - train loss is 40.51262431393843\n",
      "Steps:  46%|▍| 6969/15000 [59:30<33:02,  4.05it/s, lr=0.000869, step_loss=0.165]07/27/2023 18:44:21 - INFO - __main__ - Per validation step average loss is 0.0622924268245697\n",
      "07/27/2023 18:44:21 - INFO - __main__ - Cumulative validation average loss is 0.0622924268245697\n",
      "07/27/2023 18:44:21 - INFO - __main__ - Per validation step average loss is 0.036767683923244476\n",
      "07/27/2023 18:44:21 - INFO - __main__ - Cumulative validation average loss is 0.09906011074781418\n",
      "07/27/2023 18:44:21 - INFO - __main__ - Per validation step average loss is 0.08853446692228317\n",
      "07/27/2023 18:44:21 - INFO - __main__ - Cumulative validation average loss is 0.18759457767009735\n",
      "07/27/2023 18:44:22 - INFO - __main__ - Per validation step average loss is 0.0017515504732728004\n",
      "07/27/2023 18:44:22 - INFO - __main__ - Cumulative validation average loss is 0.18934612814337015\n",
      "07/27/2023 18:44:22 - INFO - __main__ - Per validation step average loss is 0.014628969132900238\n",
      "07/27/2023 18:44:22 - INFO - __main__ - Cumulative validation average loss is 0.2039750972762704\n",
      "07/27/2023 18:44:23 - INFO - __main__ - Per validation step average loss is 0.0033664300572127104\n",
      "07/27/2023 18:44:23 - INFO - __main__ - Cumulative validation average loss is 0.2073415273334831\n",
      "07/27/2023 18:44:23 - INFO - __main__ - Per validation step average loss is 0.23972755670547485\n",
      "07/27/2023 18:44:23 - INFO - __main__ - Cumulative validation average loss is 0.44706908403895795\n",
      "07/27/2023 18:44:23 - INFO - __main__ - Per validation step average loss is 0.07232454419136047\n",
      "07/27/2023 18:44:23 - INFO - __main__ - Cumulative validation average loss is 0.5193936282303184\n",
      "07/27/2023 18:44:24 - INFO - __main__ - Per validation step average loss is 0.12020165473222733\n",
      "07/27/2023 18:44:24 - INFO - __main__ - Cumulative validation average loss is 0.6395952829625458\n",
      "07/27/2023 18:44:24 - INFO - __main__ - Per validation step average loss is 0.01587618701159954\n",
      "07/27/2023 18:44:24 - INFO - __main__ - Cumulative validation average loss is 0.6554714699741453\n",
      "07/27/2023 18:44:25 - INFO - __main__ - Per validation step average loss is 0.001948887133039534\n",
      "07/27/2023 18:44:25 - INFO - __main__ - Cumulative validation average loss is 0.6574203571071848\n",
      "07/27/2023 18:44:25 - INFO - __main__ - Per validation step average loss is 0.022407781332731247\n",
      "07/27/2023 18:44:25 - INFO - __main__ - Cumulative validation average loss is 0.6798281384399161\n",
      "07/27/2023 18:44:26 - INFO - __main__ - Per validation step average loss is 0.049725908786058426\n",
      "07/27/2023 18:44:26 - INFO - __main__ - Cumulative validation average loss is 0.7295540472259745\n",
      "07/27/2023 18:44:26 - INFO - __main__ - Per validation step average loss is 0.006872427649796009\n",
      "07/27/2023 18:44:26 - INFO - __main__ - Cumulative validation average loss is 0.7364264748757705\n",
      "07/27/2023 18:44:26 - INFO - __main__ - Per validation step average loss is 0.07126735150814056\n",
      "07/27/2023 18:44:26 - INFO - __main__ - Cumulative validation average loss is 0.8076938263839111\n",
      "07/27/2023 18:44:27 - INFO - __main__ - Per validation step average loss is 0.1535549759864807\n",
      "07/27/2023 18:44:27 - INFO - __main__ - Cumulative validation average loss is 0.9612488023703918\n",
      "07/27/2023 18:44:27 - INFO - __main__ - Per validation step average loss is 0.0016588433645665646\n",
      "07/27/2023 18:44:27 - INFO - __main__ - Cumulative validation average loss is 0.9629076457349584\n",
      "07/27/2023 18:44:28 - INFO - __main__ - Per validation step average loss is 0.31096839904785156\n",
      "07/27/2023 18:44:28 - INFO - __main__ - Cumulative validation average loss is 1.27387604478281\n",
      "07/27/2023 18:44:28 - INFO - __main__ - Per validation step average loss is 0.30026039481163025\n",
      "07/27/2023 18:44:28 - INFO - __main__ - Cumulative validation average loss is 1.5741364395944402\n",
      "07/27/2023 18:44:29 - INFO - __main__ - Per validation step average loss is 0.2225254327058792\n",
      "07/27/2023 18:44:29 - INFO - __main__ - Cumulative validation average loss is 1.7966618723003194\n",
      "07/27/2023 18:44:29 - INFO - __main__ - Per validation step average loss is 0.39986711740493774\n",
      "07/27/2023 18:44:29 - INFO - __main__ - Cumulative validation average loss is 2.196528989705257\n",
      "07/27/2023 18:44:29 - INFO - __main__ - Per validation step average loss is 0.020877404138445854\n",
      "07/27/2023 18:44:29 - INFO - __main__ - Cumulative validation average loss is 2.217406393843703\n",
      "07/27/2023 18:44:30 - INFO - __main__ - Per validation step average loss is 0.020418083295226097\n",
      "07/27/2023 18:44:30 - INFO - __main__ - Cumulative validation average loss is 2.237824477138929\n",
      "07/27/2023 18:44:30 - INFO - __main__ - Per validation step average loss is 0.00885062012821436\n",
      "07/27/2023 18:44:30 - INFO - __main__ - Cumulative validation average loss is 2.2466750972671434\n",
      "07/27/2023 18:44:31 - INFO - __main__ - Per validation step average loss is 0.08096858859062195\n",
      "07/27/2023 18:44:31 - INFO - __main__ - Cumulative validation average loss is 2.3276436858577654\n",
      "07/27/2023 18:44:31 - INFO - __main__ - Per validation step average loss is 0.0035862314980477095\n",
      "07/27/2023 18:44:31 - INFO - __main__ - Cumulative validation average loss is 2.331229917355813\n",
      "07/27/2023 18:44:31 - INFO - __main__ - Per validation step average loss is 0.06619644165039062\n",
      "07/27/2023 18:44:31 - INFO - __main__ - Cumulative validation average loss is 2.3974263590062037\n",
      "07/27/2023 18:44:32 - INFO - __main__ - Per validation step average loss is 0.10443885624408722\n",
      "07/27/2023 18:44:32 - INFO - __main__ - Cumulative validation average loss is 2.501865215250291\n",
      "07/27/2023 18:44:32 - INFO - __main__ - Per validation step average loss is 0.35915762186050415\n",
      "07/27/2023 18:44:32 - INFO - __main__ - Cumulative validation average loss is 2.861022837110795\n",
      "07/27/2023 18:44:33 - INFO - __main__ - Per validation step average loss is 0.17514845728874207\n",
      "07/27/2023 18:44:33 - INFO - __main__ - Cumulative validation average loss is 3.036171294399537\n",
      "07/27/2023 18:44:33 - INFO - __main__ - Per validation step average loss is 0.2923744320869446\n",
      "07/27/2023 18:44:33 - INFO - __main__ - Cumulative validation average loss is 3.3285457264864817\n",
      "07/27/2023 18:44:34 - INFO - __main__ - Per validation step average loss is 0.004078012425452471\n",
      "07/27/2023 18:44:34 - INFO - __main__ - Cumulative validation average loss is 3.332623738911934\n",
      "07/27/2023 18:44:34 - INFO - __main__ - Per validation step average loss is 0.5793865919113159\n",
      "07/27/2023 18:44:34 - INFO - __main__ - Cumulative validation average loss is 3.91201033082325\n",
      "07/27/2023 18:44:34 - INFO - __main__ - Per validation step average loss is 0.22001606225967407\n",
      "07/27/2023 18:44:34 - INFO - __main__ - Cumulative validation average loss is 4.132026393082924\n",
      "07/27/2023 18:44:35 - INFO - __main__ - Per validation step average loss is 0.002170854015275836\n",
      "07/27/2023 18:44:35 - INFO - __main__ - Cumulative validation average loss is 4.1341972470982\n",
      "07/27/2023 18:44:35 - INFO - __main__ - Per validation step average loss is 0.15897546708583832\n",
      "07/27/2023 18:44:35 - INFO - __main__ - Cumulative validation average loss is 4.293172714184038\n",
      "07/27/2023 18:44:36 - INFO - __main__ - Per validation step average loss is 0.11232790350914001\n",
      "07/27/2023 18:44:36 - INFO - __main__ - Cumulative validation average loss is 4.405500617693178\n",
      "07/27/2023 18:44:36 - INFO - __main__ - Per validation step average loss is 0.0055013420060276985\n",
      "07/27/2023 18:44:36 - INFO - __main__ - Cumulative validation average loss is 4.411001959699206\n",
      "07/27/2023 18:44:36 - INFO - __main__ - Per validation step average loss is 0.051388196647167206\n",
      "07/27/2023 18:44:36 - INFO - __main__ - Cumulative validation average loss is 4.462390156346373\n",
      "07/27/2023 18:44:37 - INFO - __main__ - Per validation step average loss is 0.02565193921327591\n",
      "07/27/2023 18:44:37 - INFO - __main__ - Cumulative validation average loss is 4.488042095559649\n",
      "07/27/2023 18:44:37 - INFO - __main__ - Per validation step average loss is 0.07575449347496033\n",
      "07/27/2023 18:44:37 - INFO - __main__ - Cumulative validation average loss is 4.5637965890346095\n",
      "07/27/2023 18:44:38 - INFO - __main__ - Per validation step average loss is 0.0033224152866750956\n",
      "07/27/2023 18:44:38 - INFO - __main__ - Cumulative validation average loss is 4.567119004321285\n",
      "07/27/2023 18:44:38 - INFO - __main__ - Per validation step average loss is 0.012577112764120102\n",
      "07/27/2023 18:44:38 - INFO - __main__ - Cumulative validation average loss is 4.579696117085405\n",
      "07/27/2023 18:44:39 - INFO - __main__ - Per validation step average loss is 0.00760161317884922\n",
      "07/27/2023 18:44:39 - INFO - __main__ - Cumulative validation average loss is 4.587297730264254\n",
      "07/27/2023 18:44:39 - INFO - __main__ - Per validation step average loss is 0.05573495477437973\n",
      "07/27/2023 18:44:39 - INFO - __main__ - Cumulative validation average loss is 4.643032685038634\n",
      "07/27/2023 18:44:39 - INFO - __main__ - Per validation step average loss is 0.178020641207695\n",
      "07/27/2023 18:44:39 - INFO - __main__ - Cumulative validation average loss is 4.821053326246329\n",
      "07/27/2023 18:44:40 - INFO - __main__ - Per validation step average loss is 0.10149496793746948\n",
      "07/27/2023 18:44:40 - INFO - __main__ - Cumulative validation average loss is 4.922548294183798\n",
      "07/27/2023 18:44:40 - INFO - __main__ - Per validation step average loss is 0.05018524080514908\n",
      "07/27/2023 18:44:40 - INFO - __main__ - Cumulative validation average loss is 4.972733534988947\n",
      "07/27/2023 18:44:41 - INFO - __main__ - Per validation step average loss is 0.10194654017686844\n",
      "07/27/2023 18:44:41 - INFO - __main__ - Cumulative validation average loss is 5.074680075165816\n",
      "07/27/2023 18:44:41 - INFO - __main__ - Per validation step average loss is 0.08787120878696442\n",
      "07/27/2023 18:44:41 - INFO - __main__ - Cumulative validation average loss is 5.16255128395278\n",
      "07/27/2023 18:44:41 - INFO - __main__ - Per validation step average loss is 0.21336543560028076\n",
      "07/27/2023 18:44:41 - INFO - __main__ - Cumulative validation average loss is 5.375916719553061\n",
      "07/27/2023 18:44:42 - INFO - __main__ - Per validation step average loss is 0.005012040957808495\n",
      "07/27/2023 18:44:42 - INFO - __main__ - Cumulative validation average loss is 5.380928760510869\n",
      "07/27/2023 18:44:42 - INFO - __main__ - Per validation step average loss is 0.043177343904972076\n",
      "07/27/2023 18:44:42 - INFO - __main__ - Cumulative validation average loss is 5.424106104415841\n",
      "07/27/2023 18:44:43 - INFO - __main__ - Per validation step average loss is 0.25240570306777954\n",
      "07/27/2023 18:44:43 - INFO - __main__ - Cumulative validation average loss is 5.676511807483621\n",
      "07/27/2023 18:44:43 - INFO - __main__ - Per validation step average loss is 0.027868518605828285\n",
      "07/27/2023 18:44:43 - INFO - __main__ - Cumulative validation average loss is 5.704380326089449\n",
      "07/27/2023 18:44:43 - INFO - __main__ - Per validation step average loss is 0.1978265792131424\n",
      "07/27/2023 18:44:43 - INFO - __main__ - Cumulative validation average loss is 5.902206905302592\n",
      "07/27/2023 18:44:44 - INFO - __main__ - Per validation step average loss is 0.1588648557662964\n",
      "07/27/2023 18:44:44 - INFO - __main__ - Cumulative validation average loss is 6.061071761068888\n",
      "07/27/2023 18:44:44 - INFO - __main__ - Per validation step average loss is 0.17147797346115112\n",
      "07/27/2023 18:44:44 - INFO - __main__ - Cumulative validation average loss is 6.232549734530039\n",
      "07/27/2023 18:44:45 - INFO - __main__ - Per validation step average loss is 0.5572307705879211\n",
      "07/27/2023 18:44:45 - INFO - __main__ - Cumulative validation average loss is 6.78978050511796\n",
      "07/27/2023 18:44:45 - INFO - __main__ - Per validation step average loss is 0.002043912187218666\n",
      "07/27/2023 18:44:45 - INFO - __main__ - Cumulative validation average loss is 6.791824417305179\n",
      "07/27/2023 18:44:46 - INFO - __main__ - Per validation step average loss is 0.37220093607902527\n",
      "07/27/2023 18:44:46 - INFO - __main__ - Cumulative validation average loss is 7.164025353384204\n",
      "07/27/2023 18:44:46 - INFO - __main__ - Per validation step average loss is 0.0066925473511219025\n",
      "07/27/2023 18:44:46 - INFO - __main__ - Cumulative validation average loss is 7.170717900735326\n",
      "07/27/2023 18:44:46 - INFO - __main__ - Per validation step average loss is 0.06264738738536835\n",
      "07/27/2023 18:44:46 - INFO - __main__ - Cumulative validation average loss is 7.2333652881206945\n",
      "07/27/2023 18:44:47 - INFO - __main__ - Per validation step average loss is 0.12010271847248077\n",
      "07/27/2023 18:44:47 - INFO - __main__ - Cumulative validation average loss is 7.353468006593175\n",
      "07/27/2023 18:44:47 - INFO - __main__ - Per validation step average loss is 0.0022691264748573303\n",
      "07/27/2023 18:44:47 - INFO - __main__ - Cumulative validation average loss is 7.355737133068033\n",
      "07/27/2023 18:44:48 - INFO - __main__ - Per validation step average loss is 0.12401539087295532\n",
      "07/27/2023 18:44:48 - INFO - __main__ - Cumulative validation average loss is 7.479752523940988\n",
      "07/27/2023 18:44:48 - INFO - __main__ - Per validation step average loss is 0.0022439579479396343\n",
      "07/27/2023 18:44:48 - INFO - __main__ - Cumulative validation average loss is 7.4819964818889275\n",
      "07/27/2023 18:44:48 - INFO - __main__ - Per validation step average loss is 0.3170434832572937\n",
      "07/27/2023 18:44:48 - INFO - __main__ - Cumulative validation average loss is 7.799039965146221\n",
      "07/27/2023 18:44:49 - INFO - __main__ - Per validation step average loss is 0.001250148518010974\n",
      "07/27/2023 18:44:49 - INFO - __main__ - Cumulative validation average loss is 7.800290113664232\n",
      "07/27/2023 18:44:49 - INFO - __main__ - Per validation step average loss is 0.32667285203933716\n",
      "07/27/2023 18:44:49 - INFO - __main__ - Cumulative validation average loss is 8.12696296570357\n",
      "07/27/2023 18:44:50 - INFO - __main__ - Per validation step average loss is 0.0037274835631251335\n",
      "07/27/2023 18:44:50 - INFO - __main__ - Cumulative validation average loss is 8.130690449266694\n",
      "07/27/2023 18:44:50 - INFO - __main__ - Per validation step average loss is 0.07507268339395523\n",
      "07/27/2023 18:44:50 - INFO - __main__ - Cumulative validation average loss is 8.20576313266065\n",
      "07/27/2023 18:44:51 - INFO - __main__ - Per validation step average loss is 0.057489827275276184\n",
      "07/27/2023 18:44:51 - INFO - __main__ - Cumulative validation average loss is 8.263252959935926\n",
      "07/27/2023 18:44:51 - INFO - __main__ - Per validation step average loss is 0.005049949511885643\n",
      "07/27/2023 18:44:51 - INFO - __main__ - Cumulative validation average loss is 8.268302909447812\n",
      "07/27/2023 18:44:51 - INFO - __main__ - Per validation step average loss is 0.028106065467000008\n",
      "07/27/2023 18:44:51 - INFO - __main__ - Cumulative validation average loss is 8.296408974914812\n",
      "07/27/2023 18:44:52 - INFO - __main__ - Per validation step average loss is 0.009844811633229256\n",
      "07/27/2023 18:44:52 - INFO - __main__ - Cumulative validation average loss is 8.30625378654804\n",
      "07/27/2023 18:44:52 - INFO - __main__ - Per validation step average loss is 0.06906846165657043\n",
      "07/27/2023 18:44:52 - INFO - __main__ - Cumulative validation average loss is 8.375322248204611\n",
      "07/27/2023 18:44:53 - INFO - __main__ - Per validation step average loss is 0.02378917671740055\n",
      "07/27/2023 18:44:53 - INFO - __main__ - Cumulative validation average loss is 8.399111424922012\n",
      "07/27/2023 18:44:53 - INFO - __main__ - Per validation step average loss is 0.07940027117729187\n",
      "07/27/2023 18:44:53 - INFO - __main__ - Cumulative validation average loss is 8.478511696099304\n",
      "07/27/2023 18:44:53 - INFO - __main__ - Average validation loss for Epoch 22 is 0.1073229328620165\n",
      "07/27/2023 18:44:53 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:45:50 - INFO - __main__ - Starting epoch 23\n",
      "07/27/2023 18:45:51 - INFO - __main__ - train loss is 0.172443687915802\n",
      "Steps:  46%|▍| 6970/15000 [1:01:01<61:35:24, 27.61s/it, lr=0.000869, step_loss=007/27/2023 18:45:51 - INFO - __main__ - train loss is 0.2514461874961853\n",
      "Steps:  46%|▍| 6971/15000 [1:01:02<43:13:39, 19.38s/it, lr=0.00087, step_loss=0.07/27/2023 18:45:51 - INFO - __main__ - train loss is 0.2987532839179039\n",
      "Steps:  46%|▍| 6972/15000 [1:01:02<30:22:29, 13.62s/it, lr=0.00087, step_loss=0.07/27/2023 18:45:52 - INFO - __main__ - train loss is 0.4143766835331917\n",
      "Steps:  46%|▍| 6973/15000 [1:01:02<21:22:44,  9.59s/it, lr=0.00087, step_loss=0.07/27/2023 18:45:52 - INFO - __main__ - train loss is 0.43329353630542755\n",
      "Steps:  46%|▍| 6974/15000 [1:01:02<15:04:57,  6.77s/it, lr=0.00087, step_loss=0.07/27/2023 18:45:52 - INFO - __main__ - train loss is 0.4427915681153536\n",
      "Steps:  46%|▍| 6975/15000 [1:01:02<10:40:38,  4.79s/it, lr=0.00087, step_loss=0.07/27/2023 18:45:52 - INFO - __main__ - train loss is 0.45620942302048206\n",
      "Steps:  47%|▍| 6976/15000 [1:01:02<7:35:42,  3.41s/it, lr=0.00087, step_loss=0.007/27/2023 18:45:52 - INFO - __main__ - train loss is 0.531617583706975\n",
      "Steps:  47%|▍| 6977/15000 [1:01:03<5:26:06,  2.44s/it, lr=0.00087, step_loss=0.007/27/2023 18:45:53 - INFO - __main__ - train loss is 0.5365722049027681\n",
      "Steps:  47%|▍| 6978/15000 [1:01:03<3:55:24,  1.76s/it, lr=0.00087, step_loss=0.007/27/2023 18:45:53 - INFO - __main__ - train loss is 0.83506147749722\n",
      "Steps:  47%|▍| 6979/15000 [1:01:03<2:52:10,  1.29s/it, lr=0.000871, step_loss=0.07/27/2023 18:45:53 - INFO - __main__ - train loss is 0.8962821271270514\n",
      "Steps:  47%|▍| 6980/15000 [1:01:03<2:07:58,  1.04it/s, lr=0.000871, step_loss=0.07/27/2023 18:45:53 - INFO - __main__ - train loss is 0.9986597951501608\n",
      "Steps:  47%|▍| 6981/15000 [1:01:03<1:36:52,  1.38it/s, lr=0.000871, step_loss=0.07/27/2023 18:45:53 - INFO - __main__ - train loss is 1.068424640223384\n",
      "Steps:  47%|▍| 6982/15000 [1:01:04<1:15:12,  1.78it/s, lr=0.000871, step_loss=0.07/27/2023 18:45:53 - INFO - __main__ - train loss is 1.09357943944633\n",
      "Steps:  47%|▍| 6983/15000 [1:01:04<59:50,  2.23it/s, lr=0.000871, step_loss=0.0207/27/2023 18:45:54 - INFO - __main__ - train loss is 1.7472449820488691\n",
      "Steps:  47%|▍| 6984/15000 [1:01:04<49:03,  2.72it/s, lr=0.000871, step_loss=0.6507/27/2023 18:45:54 - INFO - __main__ - train loss is 1.7500649739522487\n",
      "Steps:  47%|▍| 6985/15000 [1:01:04<41:42,  3.20it/s, lr=0.000871, step_loss=0.0007/27/2023 18:45:54 - INFO - __main__ - train loss is 1.810629827203229\n",
      "Steps:  47%|▍| 6986/15000 [1:01:04<36:21,  3.67it/s, lr=0.000871, step_loss=0.0607/27/2023 18:45:54 - INFO - __main__ - train loss is 2.209228915395215\n",
      "Steps:  47%|▍| 6987/15000 [1:01:04<32:37,  4.09it/s, lr=0.000872, step_loss=0.3907/27/2023 18:45:54 - INFO - __main__ - train loss is 2.229248131858185\n",
      "Steps:  47%|▍| 6988/15000 [1:01:05<30:00,  4.45it/s, lr=0.000872, step_loss=0.0207/27/2023 18:45:55 - INFO - __main__ - train loss is 2.2377793055493385\n",
      "Steps:  47%|▍| 6989/15000 [1:01:05<28:11,  4.73it/s, lr=0.000872, step_loss=0.0007/27/2023 18:45:55 - INFO - __main__ - train loss is 2.35840763268061\n",
      "Steps:  47%|▍| 6990/15000 [1:01:05<26:54,  4.96it/s, lr=0.000872, step_loss=0.1207/27/2023 18:45:55 - INFO - __main__ - train loss is 2.434694291325286\n",
      "Steps:  47%|▍| 6991/15000 [1:01:05<26:01,  5.13it/s, lr=0.000872, step_loss=0.0707/27/2023 18:45:55 - INFO - __main__ - train loss is 2.4384264620020986\n",
      "Steps:  47%|▍| 6992/15000 [1:01:05<25:22,  5.26it/s, lr=0.000872, step_loss=0.0007/27/2023 18:45:55 - INFO - __main__ - train loss is 2.5114363403990865\n",
      "Steps:  47%|▍| 6993/15000 [1:01:06<24:56,  5.35it/s, lr=0.000872, step_loss=0.0707/27/2023 18:45:55 - INFO - __main__ - train loss is 2.5154989240691066\n",
      "Steps:  47%|▍| 6994/15000 [1:01:06<24:37,  5.42it/s, lr=0.000872, step_loss=0.0007/27/2023 18:45:56 - INFO - __main__ - train loss is 2.5172150004655123\n",
      "Steps:  47%|▍| 6995/15000 [1:01:06<24:25,  5.46it/s, lr=0.000873, step_loss=0.0007/27/2023 18:45:56 - INFO - __main__ - train loss is 2.5287964437156916\n",
      "Steps:  47%|▍| 6996/15000 [1:01:06<24:26,  5.46it/s, lr=0.000873, step_loss=0.0107/27/2023 18:45:56 - INFO - __main__ - train loss is 2.538355856202543\n",
      "Steps:  47%|▍| 6997/15000 [1:01:06<24:17,  5.49it/s, lr=0.000873, step_loss=0.0007/27/2023 18:45:56 - INFO - __main__ - train loss is 2.5401102358009666\n",
      "Steps:  47%|▍| 6998/15000 [1:01:06<24:12,  5.51it/s, lr=0.000873, step_loss=0.0007/27/2023 18:45:56 - INFO - __main__ - train loss is 2.76059684692882\n",
      "Steps:  47%|▍| 6999/15000 [1:01:07<24:05,  5.53it/s, lr=0.000873, step_loss=0.2207/27/2023 18:45:56 - INFO - __main__ - train loss is 2.7783021514769644\n",
      "Steps:  47%|▍| 7000/15000 [1:01:07<24:01,  5.55it/s, lr=0.000873, step_loss=0.2207/27/2023 18:45:57 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-7000\n",
      "07/27/2023 18:45:57 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:45:57,084] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:45:57,089] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-7000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:45:57,089] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-7000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:45:57,095] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-7000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:45:57,096] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-7000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:45:57,102] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-7000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:45:57,102] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-7000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:45:57,102] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:45:57 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-7000/pytorch_model\n",
      "07/27/2023 18:45:57 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-7000/scheduler.bin\n",
      "07/27/2023 18:45:57 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-7000/random_states_0.pkl\n",
      "07/27/2023 18:45:57 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-7000\n",
      "Steps:  47%|▍| 7000/15000 [1:01:07<24:01,  5.55it/s, lr=0.000873, step_loss=0.0107/27/2023 18:45:57 - INFO - __main__ - train loss is 2.8305363242980093\n",
      "Steps:  47%|▍| 7001/15000 [1:01:07<24:45,  5.38it/s, lr=0.000873, step_loss=0.0507/27/2023 18:45:57 - INFO - __main__ - train loss is 2.8321719706291333\n",
      "Steps:  47%|▍| 7002/15000 [1:01:07<24:30,  5.44it/s, lr=0.000873, step_loss=0.0007/27/2023 18:45:57 - INFO - __main__ - train loss is 2.8352322642458603\n",
      "Steps:  47%|▍| 7003/15000 [1:01:07<24:18,  5.48it/s, lr=0.000874, step_loss=0.0007/27/2023 18:45:57 - INFO - __main__ - train loss is 2.837688641040586\n",
      "Steps:  47%|▍| 7004/15000 [1:01:08<24:12,  5.51it/s, lr=0.000874, step_loss=0.0007/27/2023 18:45:57 - INFO - __main__ - train loss is 2.9403388214996085\n",
      "Steps:  47%|▍| 7005/15000 [1:01:08<24:05,  5.53it/s, lr=0.000874, step_loss=0.1007/27/2023 18:45:58 - INFO - __main__ - train loss is 2.953290203004144\n",
      "Steps:  47%|▍| 7006/15000 [1:01:08<24:00,  5.55it/s, lr=0.000874, step_loss=0.0107/27/2023 18:45:58 - INFO - __main__ - train loss is 3.0413060871651396\n",
      "Steps:  47%|▍| 7007/15000 [1:01:08<23:58,  5.56it/s, lr=0.000874, step_loss=0.0807/27/2023 18:45:58 - INFO - __main__ - train loss is 3.0483297201571986\n",
      "Steps:  47%|▍| 7008/15000 [1:01:08<23:55,  5.57it/s, lr=0.000874, step_loss=0.0007/27/2023 18:45:58 - INFO - __main__ - train loss is 3.0509357795817778\n",
      "Steps:  47%|▍| 7009/15000 [1:01:08<23:53,  5.57it/s, lr=0.000874, step_loss=0.0007/27/2023 18:45:58 - INFO - __main__ - train loss is 3.0954652436776087\n",
      "Steps:  47%|▍| 7010/15000 [1:01:09<23:52,  5.58it/s, lr=0.000874, step_loss=0.0407/27/2023 18:45:58 - INFO - __main__ - train loss is 3.128071290324442\n",
      "Steps:  47%|▍| 7011/15000 [1:01:09<23:52,  5.58it/s, lr=0.000875, step_loss=0.0307/27/2023 18:45:59 - INFO - __main__ - train loss is 3.1768912830157205\n",
      "Steps:  47%|▍| 7012/15000 [1:01:09<23:52,  5.58it/s, lr=0.000875, step_loss=0.0407/27/2023 18:45:59 - INFO - __main__ - train loss is 3.596683756331913\n",
      "Steps:  47%|▍| 7013/15000 [1:01:09<23:54,  5.57it/s, lr=0.000875, step_loss=0.4207/27/2023 18:45:59 - INFO - __main__ - train loss is 3.7893822946352884\n",
      "Steps:  47%|▍| 7014/15000 [1:01:09<24:06,  5.52it/s, lr=0.000875, step_loss=0.1907/27/2023 18:45:59 - INFO - __main__ - train loss is 3.930662886123173\n",
      "Steps:  47%|▍| 7015/15000 [1:01:10<24:07,  5.52it/s, lr=0.000875, step_loss=0.1407/27/2023 18:45:59 - INFO - __main__ - train loss is 3.9422385644866154\n",
      "Steps:  47%|▍| 7016/15000 [1:01:10<24:02,  5.53it/s, lr=0.000875, step_loss=0.0107/27/2023 18:46:00 - INFO - __main__ - train loss is 3.989013309474103\n",
      "Steps:  47%|▍| 7017/15000 [1:01:10<24:00,  5.54it/s, lr=0.000875, step_loss=0.0407/27/2023 18:46:00 - INFO - __main__ - train loss is 4.013924672151916\n",
      "Steps:  47%|▍| 7018/15000 [1:01:10<23:57,  5.55it/s, lr=0.000875, step_loss=0.0207/27/2023 18:46:00 - INFO - __main__ - train loss is 4.474151505972259\n",
      "Steps:  47%|▍| 7019/15000 [1:01:10<24:06,  5.52it/s, lr=0.000875, step_loss=0.4607/27/2023 18:46:00 - INFO - __main__ - train loss is 4.716616465593688\n",
      "Steps:  47%|▍| 7020/15000 [1:01:10<24:08,  5.51it/s, lr=0.000876, step_loss=0.2407/27/2023 18:46:00 - INFO - __main__ - train loss is 4.718096239375882\n",
      "Steps:  47%|▍| 7021/15000 [1:01:11<24:12,  5.49it/s, lr=0.000876, step_loss=0.0007/27/2023 18:46:00 - INFO - __main__ - train loss is 4.755750222015195\n",
      "Steps:  47%|▍| 7022/15000 [1:01:11<24:17,  5.47it/s, lr=0.000876, step_loss=0.0307/27/2023 18:46:01 - INFO - __main__ - train loss is 4.785009657847695\n",
      "Steps:  47%|▍| 7023/15000 [1:01:11<24:09,  5.50it/s, lr=0.000876, step_loss=0.0207/27/2023 18:46:01 - INFO - __main__ - train loss is 4.833430206286721\n",
      "Steps:  47%|▍| 7024/15000 [1:01:11<24:03,  5.53it/s, lr=0.000876, step_loss=0.0407/27/2023 18:46:01 - INFO - __main__ - train loss is 4.969446739065461\n",
      "Steps:  47%|▍| 7025/15000 [1:01:11<24:14,  5.48it/s, lr=0.000876, step_loss=0.1307/27/2023 18:46:01 - INFO - __main__ - train loss is 4.979199048015289\n",
      "Steps:  47%|▍| 7026/15000 [1:01:12<24:11,  5.49it/s, lr=0.000876, step_loss=0.0007/27/2023 18:46:01 - INFO - __main__ - train loss is 5.19017238530796\n",
      "Steps:  47%|▍| 7027/15000 [1:01:12<24:04,  5.52it/s, lr=0.000877, step_loss=0.2107/27/2023 18:46:02 - INFO - __main__ - train loss is 5.23691881808918\n",
      "Steps:  47%|▍| 7028/15000 [1:01:12<23:59,  5.54it/s, lr=0.000877, step_loss=0.0407/27/2023 18:46:02 - INFO - __main__ - train loss is 5.28675021964591\n",
      "Steps:  47%|▍| 7029/15000 [1:01:12<24:09,  5.50it/s, lr=0.000877, step_loss=0.0407/27/2023 18:46:02 - INFO - __main__ - train loss is 5.321307692560367\n",
      "Steps:  47%|▍| 7030/15000 [1:01:12<24:07,  5.50it/s, lr=0.000877, step_loss=0.0307/27/2023 18:46:02 - INFO - __main__ - train loss is 5.741987887653522\n",
      "Steps:  47%|▍| 7031/15000 [1:01:12<24:01,  5.53it/s, lr=0.000877, step_loss=0.4207/27/2023 18:46:02 - INFO - __main__ - train loss is 5.908199373516254\n",
      "Steps:  47%|▍| 7032/15000 [1:01:13<23:58,  5.54it/s, lr=0.000877, step_loss=0.1607/27/2023 18:46:02 - INFO - __main__ - train loss is 6.058457229170017\n",
      "Steps:  47%|▍| 7033/15000 [1:01:13<23:55,  5.55it/s, lr=0.000877, step_loss=0.1507/27/2023 18:46:03 - INFO - __main__ - train loss is 6.504141304525547\n",
      "Steps:  47%|▍| 7034/15000 [1:01:13<23:53,  5.56it/s, lr=0.000877, step_loss=0.4407/27/2023 18:46:03 - INFO - __main__ - train loss is 6.550319675239734\n",
      "Steps:  47%|▍| 7035/15000 [1:01:13<23:52,  5.56it/s, lr=0.000877, step_loss=0.0407/27/2023 18:46:03 - INFO - __main__ - train loss is 6.5549331231741235\n",
      "Steps:  47%|▍| 7036/15000 [1:01:13<23:51,  5.56it/s, lr=0.000878, step_loss=0.0007/27/2023 18:46:03 - INFO - __main__ - train loss is 6.655942760291509\n",
      "Steps:  47%|▍| 7037/15000 [1:01:14<23:51,  5.56it/s, lr=0.000878, step_loss=0.1007/27/2023 18:46:03 - INFO - __main__ - train loss is 6.745818398776464\n",
      "Steps:  47%|▍| 7038/15000 [1:01:14<24:04,  5.51it/s, lr=0.000878, step_loss=0.0807/27/2023 18:46:04 - INFO - __main__ - train loss is 6.764966938528232\n",
      "Steps:  47%|▍| 7039/15000 [1:01:14<24:03,  5.51it/s, lr=0.000878, step_loss=0.0107/27/2023 18:46:04 - INFO - __main__ - train loss is 6.806206252309494\n",
      "Steps:  47%|▍| 7040/15000 [1:01:14<23:58,  5.53it/s, lr=0.000878, step_loss=0.0407/27/2023 18:46:04 - INFO - __main__ - train loss is 6.822429291787557\n",
      "Steps:  47%|▍| 7041/15000 [1:01:14<24:00,  5.52it/s, lr=0.000878, step_loss=0.0107/27/2023 18:46:04 - INFO - __main__ - train loss is 6.991135202231817\n",
      "Steps:  47%|▍| 7042/15000 [1:01:14<24:09,  5.49it/s, lr=0.000878, step_loss=0.1607/27/2023 18:46:04 - INFO - __main__ - train loss is 7.1591748668579385\n",
      "Steps:  47%|▍| 7043/15000 [1:01:15<24:07,  5.50it/s, lr=0.000878, step_loss=0.1607/27/2023 18:46:04 - INFO - __main__ - train loss is 7.364654309931211\n",
      "Steps:  47%|▍| 7044/15000 [1:01:15<23:59,  5.53it/s, lr=0.000879, step_loss=0.2007/27/2023 18:46:05 - INFO - __main__ - train loss is 7.370346751878969\n",
      "Steps:  47%|▍| 7045/15000 [1:01:15<23:56,  5.54it/s, lr=0.000879, step_loss=0.0007/27/2023 18:46:05 - INFO - __main__ - train loss is 7.417765905032866\n",
      "Steps:  47%|▍| 7046/15000 [1:01:15<23:53,  5.55it/s, lr=0.000879, step_loss=0.0407/27/2023 18:46:05 - INFO - __main__ - train loss is 7.442084000329487\n",
      "Steps:  47%|▍| 7047/15000 [1:01:15<23:50,  5.56it/s, lr=0.000879, step_loss=0.0207/27/2023 18:46:05 - INFO - __main__ - train loss is 7.445750587969087\n",
      "Steps:  47%|▍| 7048/15000 [1:01:15<23:48,  5.57it/s, lr=0.000879, step_loss=0.0007/27/2023 18:46:05 - INFO - __main__ - train loss is 8.019710653810762\n",
      "Steps:  47%|▍| 7049/15000 [1:01:16<23:47,  5.57it/s, lr=0.000879, step_loss=0.5707/27/2023 18:46:06 - INFO - __main__ - train loss is 8.33113121369388\n",
      "Steps:  47%|▍| 7050/15000 [1:01:16<23:46,  5.57it/s, lr=0.000879, step_loss=0.3107/27/2023 18:46:06 - INFO - __main__ - train loss is 8.785356753855012\n",
      "Steps:  47%|▍| 7051/15000 [1:01:16<24:04,  5.50it/s, lr=0.000879, step_loss=0.4507/27/2023 18:46:06 - INFO - __main__ - train loss is 8.89769537129905\n",
      "Steps:  47%|▍| 7052/15000 [1:01:16<23:58,  5.52it/s, lr=0.00088, step_loss=0.11207/27/2023 18:46:06 - INFO - __main__ - train loss is 9.055254289298318\n",
      "Steps:  47%|▍| 7053/15000 [1:01:16<23:55,  5.53it/s, lr=0.00088, step_loss=0.15807/27/2023 18:46:06 - INFO - __main__ - train loss is 9.267787971883081\n",
      "Steps:  47%|▍| 7054/15000 [1:01:17<23:52,  5.55it/s, lr=0.00088, step_loss=0.21307/27/2023 18:46:06 - INFO - __main__ - train loss is 9.430779823451303\n",
      "Steps:  47%|▍| 7055/15000 [1:01:17<23:50,  5.55it/s, lr=0.00088, step_loss=0.16307/27/2023 18:46:07 - INFO - __main__ - train loss is 9.432207690784708\n",
      "Steps:  47%|▍| 7056/15000 [1:01:17<23:59,  5.52it/s, lr=0.00088, step_loss=0.00107/27/2023 18:46:07 - INFO - __main__ - train loss is 9.611392157385126\n",
      "Steps:  47%|▍| 7057/15000 [1:01:17<23:55,  5.53it/s, lr=0.00088, step_loss=0.17907/27/2023 18:46:07 - INFO - __main__ - train loss is 9.645263901213184\n",
      "Steps:  47%|▍| 7058/15000 [1:01:17<23:51,  5.55it/s, lr=0.00088, step_loss=0.03307/27/2023 18:46:07 - INFO - __main__ - train loss is 9.650810718303546\n",
      "Steps:  47%|▍| 7059/15000 [1:01:17<23:48,  5.56it/s, lr=0.00088, step_loss=0.00507/27/2023 18:46:07 - INFO - __main__ - train loss is 9.690424345200881\n",
      "Steps:  47%|▍| 7060/15000 [1:01:18<23:46,  5.56it/s, lr=0.000881, step_loss=0.0307/27/2023 18:46:08 - INFO - __main__ - train loss is 9.716016882797703\n",
      "Steps:  47%|▍| 7061/15000 [1:01:18<23:45,  5.57it/s, lr=0.000881, step_loss=0.0207/27/2023 18:46:08 - INFO - __main__ - train loss is 9.771089507034048\n",
      "Steps:  47%|▍| 7062/15000 [1:01:18<23:44,  5.57it/s, lr=0.000881, step_loss=0.0507/27/2023 18:46:08 - INFO - __main__ - train loss is 9.88011166988872\n",
      "Steps:  47%|▍| 7063/15000 [1:01:18<23:44,  5.57it/s, lr=0.000881, step_loss=0.1007/27/2023 18:46:08 - INFO - __main__ - train loss is 9.913393744966015\n",
      "Steps:  47%|▍| 7064/15000 [1:01:18<23:43,  5.57it/s, lr=0.000881, step_loss=0.0307/27/2023 18:46:08 - INFO - __main__ - train loss is 10.367911467095837\n",
      "Steps:  47%|▍| 7065/15000 [1:01:19<23:43,  5.57it/s, lr=0.000881, step_loss=0.4507/27/2023 18:46:08 - INFO - __main__ - train loss is 10.564098128816113\n",
      "Steps:  47%|▍| 7066/15000 [1:01:19<23:43,  5.57it/s, lr=0.000881, step_loss=0.1907/27/2023 18:46:09 - INFO - __main__ - train loss is 10.667513021966442\n",
      "Steps:  47%|▍| 7067/15000 [1:01:19<23:43,  5.57it/s, lr=0.000882, step_loss=0.1007/27/2023 18:46:09 - INFO - __main__ - train loss is 10.774144435068592\n",
      "Steps:  47%|▍| 7068/15000 [1:01:19<23:43,  5.57it/s, lr=0.000882, step_loss=0.1007/27/2023 18:46:09 - INFO - __main__ - train loss is 10.86829743697308\n",
      "Steps:  47%|▍| 7069/15000 [1:01:19<23:43,  5.57it/s, lr=0.000882, step_loss=0.0907/27/2023 18:46:09 - INFO - __main__ - train loss is 11.178250828525051\n",
      "Steps:  47%|▍| 7070/15000 [1:01:19<23:42,  5.57it/s, lr=0.000882, step_loss=0.3107/27/2023 18:46:09 - INFO - __main__ - train loss is 11.220620406558737\n",
      "Steps:  47%|▍| 7071/15000 [1:01:20<23:42,  5.58it/s, lr=0.000882, step_loss=0.0407/27/2023 18:46:09 - INFO - __main__ - train loss is 11.230994913494214\n",
      "Steps:  47%|▍| 7072/15000 [1:01:20<23:41,  5.58it/s, lr=0.000882, step_loss=0.0107/27/2023 18:46:10 - INFO - __main__ - train loss is 11.521399441873655\n",
      "Steps:  47%|▍| 7073/15000 [1:01:20<23:42,  5.57it/s, lr=0.000882, step_loss=0.2907/27/2023 18:46:10 - INFO - __main__ - train loss is 11.588194276904687\n",
      "Steps:  47%|▍| 7074/15000 [1:01:20<23:43,  5.57it/s, lr=0.000882, step_loss=0.0607/27/2023 18:46:10 - INFO - __main__ - train loss is 11.699454139685258\n",
      "Steps:  47%|▍| 7075/15000 [1:01:20<23:43,  5.57it/s, lr=0.000882, step_loss=0.1107/27/2023 18:46:10 - INFO - __main__ - train loss is 11.947092454647645\n",
      "Steps:  47%|▍| 7076/15000 [1:01:21<23:45,  5.56it/s, lr=0.000883, step_loss=0.2407/27/2023 18:46:10 - INFO - __main__ - train loss is 12.13346393010579\n",
      "Steps:  47%|▍| 7077/15000 [1:01:21<23:44,  5.56it/s, lr=0.000883, step_loss=0.1807/27/2023 18:46:11 - INFO - __main__ - train loss is 12.137307640397921\n",
      "Steps:  47%|▍| 7078/15000 [1:01:21<23:45,  5.56it/s, lr=0.000883, step_loss=0.0007/27/2023 18:46:11 - INFO - __main__ - train loss is 12.392089780652896\n",
      "Steps:  47%|▍| 7079/15000 [1:01:21<23:49,  5.54it/s, lr=0.000883, step_loss=0.2507/27/2023 18:46:11 - INFO - __main__ - train loss is 12.486692849779502\n",
      "Steps:  47%|▍| 7080/15000 [1:01:21<23:48,  5.54it/s, lr=0.000883, step_loss=0.0907/27/2023 18:46:11 - INFO - __main__ - train loss is 12.497604487696663\n",
      "Steps:  47%|▍| 7081/15000 [1:01:21<23:48,  5.54it/s, lr=0.000883, step_loss=0.0107/27/2023 18:46:11 - INFO - __main__ - train loss is 12.499490681337193\n",
      "Steps:  47%|▍| 7082/15000 [1:01:22<23:59,  5.50it/s, lr=0.000883, step_loss=0.0007/27/2023 18:46:11 - INFO - __main__ - train loss is 12.514006064506248\n",
      "Steps:  47%|▍| 7083/15000 [1:01:22<23:54,  5.52it/s, lr=0.000883, step_loss=0.0107/27/2023 18:46:12 - INFO - __main__ - train loss is 12.525990664260462\n",
      "Steps:  47%|▍| 7084/15000 [1:01:22<23:49,  5.54it/s, lr=0.000884, step_loss=0.0107/27/2023 18:46:12 - INFO - __main__ - train loss is 12.56337223877199\n",
      "Steps:  47%|▍| 7085/15000 [1:01:22<23:46,  5.55it/s, lr=0.000884, step_loss=0.0307/27/2023 18:46:12 - INFO - __main__ - train loss is 12.59367239405401\n",
      "Steps:  47%|▍| 7086/15000 [1:01:22<23:49,  5.54it/s, lr=0.000884, step_loss=0.0307/27/2023 18:46:12 - INFO - __main__ - train loss is 12.617209098534659\n",
      "Steps:  47%|▍| 7087/15000 [1:01:23<23:46,  5.55it/s, lr=0.000884, step_loss=0.0207/27/2023 18:46:12 - INFO - __main__ - train loss is 12.758033550577238\n",
      "Steps:  47%|▍| 7088/15000 [1:01:23<23:43,  5.56it/s, lr=0.000884, step_loss=0.1407/27/2023 18:46:13 - INFO - __main__ - train loss is 12.965882784919813\n",
      "Steps:  47%|▍| 7089/15000 [1:01:23<23:43,  5.56it/s, lr=0.000884, step_loss=0.2007/27/2023 18:46:13 - INFO - __main__ - train loss is 12.971144734648988\n",
      "Steps:  47%|▍| 7090/15000 [1:01:23<23:41,  5.56it/s, lr=0.000884, step_loss=0.0007/27/2023 18:46:13 - INFO - __main__ - train loss is 13.032809852389619\n",
      "Steps:  47%|▍| 7091/15000 [1:01:23<23:40,  5.57it/s, lr=0.000884, step_loss=0.0607/27/2023 18:46:13 - INFO - __main__ - train loss is 13.266796975163743\n",
      "Steps:  47%|▍| 7092/15000 [1:01:23<23:39,  5.57it/s, lr=0.000885, step_loss=0.2307/27/2023 18:46:13 - INFO - __main__ - train loss is 13.542937247781083\n",
      "Steps:  47%|▍| 7093/15000 [1:01:24<23:38,  5.57it/s, lr=0.000885, step_loss=0.2707/27/2023 18:46:13 - INFO - __main__ - train loss is 13.844235985307023\n",
      "Steps:  47%|▍| 7094/15000 [1:01:24<23:38,  5.58it/s, lr=0.000885, step_loss=0.3007/27/2023 18:46:14 - INFO - __main__ - train loss is 13.849819825263694\n",
      "Steps:  47%|▍| 7095/15000 [1:01:24<23:37,  5.58it/s, lr=0.000885, step_loss=0.0007/27/2023 18:46:14 - INFO - __main__ - train loss is 13.85209133173339\n",
      "Steps:  47%|▍| 7096/15000 [1:01:24<23:36,  5.58it/s, lr=0.000885, step_loss=0.0007/27/2023 18:46:14 - INFO - __main__ - train loss is 14.102424521697685\n",
      "Steps:  47%|▍| 7097/15000 [1:01:24<23:36,  5.58it/s, lr=0.000885, step_loss=0.2507/27/2023 18:46:14 - INFO - __main__ - train loss is 14.156082243425772\n",
      "Steps:  47%|▍| 7098/15000 [1:01:24<23:35,  5.58it/s, lr=0.000885, step_loss=0.0507/27/2023 18:46:14 - INFO - __main__ - train loss is 14.406033218605444\n",
      "Steps:  47%|▍| 7099/15000 [1:01:25<23:36,  5.58it/s, lr=0.000886, step_loss=0.2507/27/2023 18:46:15 - INFO - __main__ - train loss is 14.455776658607647\n",
      "Steps:  47%|▍| 7100/15000 [1:01:25<23:53,  5.51it/s, lr=0.000886, step_loss=0.0407/27/2023 18:46:15 - INFO - __main__ - train loss is 14.47410753252916\n",
      "Steps:  47%|▍| 7101/15000 [1:01:25<24:33,  5.36it/s, lr=0.000886, step_loss=0.0107/27/2023 18:46:15 - INFO - __main__ - train loss is 14.585927634267136\n",
      "Steps:  47%|▍| 7102/15000 [1:01:25<28:16,  4.65it/s, lr=0.000886, step_loss=0.1107/27/2023 18:46:15 - INFO - __main__ - train loss is 14.60744052263908\n",
      "Steps:  47%|▍| 7103/15000 [1:01:26<28:36,  4.60it/s, lr=0.000886, step_loss=0.0207/27/2023 18:46:15 - INFO - __main__ - train loss is 14.638411941705272\n",
      "Steps:  47%|▍| 7104/15000 [1:01:26<28:51,  4.56it/s, lr=0.000886, step_loss=0.0307/27/2023 18:46:16 - INFO - __main__ - train loss is 15.355044188676402\n",
      "Steps:  47%|▍| 7105/15000 [1:01:26<27:33,  4.77it/s, lr=0.000886, step_loss=0.7107/27/2023 18:46:16 - INFO - __main__ - train loss is 15.545080768642947\n",
      "Steps:  47%|▍| 7106/15000 [1:01:26<26:39,  4.94it/s, lr=0.000886, step_loss=0.1907/27/2023 18:46:16 - INFO - __main__ - train loss is 15.56596724386327\n",
      "Steps:  47%|▍| 7107/15000 [1:01:26<25:49,  5.09it/s, lr=0.000887, step_loss=0.0207/27/2023 18:46:16 - INFO - __main__ - train loss is 15.665561598492786\n",
      "Steps:  47%|▍| 7108/15000 [1:01:27<25:13,  5.22it/s, lr=0.000887, step_loss=0.0907/27/2023 18:46:16 - INFO - __main__ - train loss is 15.70150897349231\n",
      "Steps:  47%|▍| 7109/15000 [1:01:27<24:47,  5.31it/s, lr=0.000887, step_loss=0.0307/27/2023 18:46:17 - INFO - __main__ - train loss is 15.79972541029565\n",
      "Steps:  47%|▍| 7110/15000 [1:01:27<24:37,  5.34it/s, lr=0.000887, step_loss=0.0907/27/2023 18:46:17 - INFO - __main__ - train loss is 15.802914042724296\n",
      "Steps:  47%|▍| 7111/15000 [1:01:27<24:19,  5.41it/s, lr=0.000887, step_loss=0.0007/27/2023 18:46:17 - INFO - __main__ - train loss is 16.062652696622536\n",
      "Steps:  47%|▍| 7112/15000 [1:01:27<24:19,  5.41it/s, lr=0.000887, step_loss=0.2607/27/2023 18:46:17 - INFO - __main__ - train loss is 16.086703673703596\n",
      "Steps:  47%|▍| 7113/15000 [1:01:27<24:11,  5.43it/s, lr=0.000887, step_loss=0.0207/27/2023 18:46:17 - INFO - __main__ - train loss is 16.148342032684013\n",
      "Steps:  47%|▍| 7114/15000 [1:01:28<24:05,  5.46it/s, lr=0.000887, step_loss=0.0607/27/2023 18:46:17 - INFO - __main__ - train loss is 16.178882618201897\n",
      "Steps:  47%|▍| 7115/15000 [1:01:28<24:01,  5.47it/s, lr=0.000887, step_loss=0.0307/27/2023 18:46:18 - INFO - __main__ - train loss is 16.18438701587729\n",
      "Steps:  47%|▍| 7116/15000 [1:01:28<23:59,  5.48it/s, lr=0.000888, step_loss=0.0007/27/2023 18:46:18 - INFO - __main__ - train loss is 16.57946421462111\n",
      "Steps:  47%|▍| 7117/15000 [1:01:28<23:57,  5.48it/s, lr=0.000888, step_loss=0.3907/27/2023 18:46:18 - INFO - __main__ - train loss is 16.597616872517392\n",
      "Steps:  47%|▍| 7118/15000 [1:01:28<23:56,  5.49it/s, lr=0.000888, step_loss=0.0107/27/2023 18:46:18 - INFO - __main__ - train loss is 16.616352594224736\n",
      "Steps:  47%|▍| 7119/15000 [1:01:29<23:55,  5.49it/s, lr=0.000888, step_loss=0.0107/27/2023 18:46:18 - INFO - __main__ - train loss is 16.830146006075665\n",
      "Steps:  47%|▍| 7120/15000 [1:01:29<23:54,  5.49it/s, lr=0.000888, step_loss=0.2107/27/2023 18:46:19 - INFO - __main__ - train loss is 16.90496716531925\n",
      "Steps:  47%|▍| 7121/15000 [1:01:29<23:53,  5.49it/s, lr=0.000888, step_loss=0.0707/27/2023 18:46:19 - INFO - __main__ - train loss is 16.912516857730225\n",
      "Steps:  47%|▍| 7122/15000 [1:01:29<23:53,  5.50it/s, lr=0.000888, step_loss=0.0007/27/2023 18:46:19 - INFO - __main__ - train loss is 17.022970888065174\n",
      "Steps:  47%|▍| 7123/15000 [1:01:29<23:52,  5.50it/s, lr=0.000888, step_loss=0.1107/27/2023 18:46:19 - INFO - __main__ - train loss is 17.02532510808669\n",
      "Steps:  47%|▍| 7124/15000 [1:01:29<23:51,  5.50it/s, lr=0.000889, step_loss=0.0007/27/2023 18:46:19 - INFO - __main__ - train loss is 17.13002499542199\n",
      "Steps:  48%|▍| 7125/15000 [1:01:30<23:51,  5.50it/s, lr=0.000889, step_loss=0.1007/27/2023 18:46:19 - INFO - __main__ - train loss is 17.186211358522996\n",
      "Steps:  48%|▍| 7126/15000 [1:01:30<23:50,  5.50it/s, lr=0.000889, step_loss=0.0507/27/2023 18:46:20 - INFO - __main__ - train loss is 17.336634646868333\n",
      "Steps:  48%|▍| 7127/15000 [1:01:30<23:50,  5.50it/s, lr=0.000889, step_loss=0.1507/27/2023 18:46:20 - INFO - __main__ - train loss is 17.434395167743787\n",
      "Steps:  48%|▍| 7128/15000 [1:01:30<23:50,  5.50it/s, lr=0.000889, step_loss=0.0907/27/2023 18:46:20 - INFO - __main__ - train loss is 17.851645562564954\n",
      "Steps:  48%|▍| 7129/15000 [1:01:30<23:49,  5.50it/s, lr=0.000889, step_loss=0.4107/27/2023 18:46:20 - INFO - __main__ - train loss is 18.266312841093168\n",
      "Steps:  48%|▍| 7130/15000 [1:01:31<23:50,  5.50it/s, lr=0.000889, step_loss=0.4107/27/2023 18:46:20 - INFO - __main__ - train loss is 18.31282664067112\n",
      "Steps:  48%|▍| 7131/15000 [1:01:31<23:50,  5.50it/s, lr=0.000889, step_loss=0.0407/27/2023 18:46:21 - INFO - __main__ - train loss is 18.345022476976737\n",
      "Steps:  48%|▍| 7132/15000 [1:01:31<23:49,  5.50it/s, lr=0.00089, step_loss=0.03207/27/2023 18:46:21 - INFO - __main__ - train loss is 19.055104829138145\n",
      "Steps:  48%|▍| 7133/15000 [1:01:31<23:52,  5.49it/s, lr=0.00089, step_loss=0.71]07/27/2023 18:46:21 - INFO - __main__ - train loss is 19.06231702421792\n",
      "Steps:  48%|▍| 7134/15000 [1:01:31<23:52,  5.49it/s, lr=0.00089, step_loss=0.00707/27/2023 18:46:21 - INFO - __main__ - train loss is 19.203967581735924\n",
      "Steps:  48%|▍| 7135/15000 [1:01:31<23:52,  5.49it/s, lr=0.00089, step_loss=0.14207/27/2023 18:46:21 - INFO - __main__ - train loss is 19.590859185205773\n",
      "Steps:  48%|▍| 7136/15000 [1:01:32<23:51,  5.50it/s, lr=0.00089, step_loss=0.38707/27/2023 18:46:21 - INFO - __main__ - train loss is 19.664766769157723\n",
      "Steps:  48%|▍| 7137/15000 [1:01:32<23:50,  5.50it/s, lr=0.00089, step_loss=0.07307/27/2023 18:46:22 - INFO - __main__ - train loss is 19.825545410858467\n",
      "Steps:  48%|▍| 7138/15000 [1:01:32<23:50,  5.50it/s, lr=0.00089, step_loss=0.16107/27/2023 18:46:22 - INFO - __main__ - train loss is 19.96495671127923\n",
      "Steps:  48%|▍| 7139/15000 [1:01:32<23:49,  5.50it/s, lr=0.000891, step_loss=0.1307/27/2023 18:46:22 - INFO - __main__ - train loss is 19.97011026297696\n",
      "Steps:  48%|▍| 7140/15000 [1:01:32<23:42,  5.52it/s, lr=0.000891, step_loss=0.0007/27/2023 18:46:22 - INFO - __main__ - train loss is 20.006524707423523\n",
      "Steps:  48%|▍| 7141/15000 [1:01:33<23:38,  5.54it/s, lr=0.000891, step_loss=0.0307/27/2023 18:46:22 - INFO - __main__ - train loss is 20.019928156631067\n",
      "Steps:  48%|▍| 7142/15000 [1:01:33<23:35,  5.55it/s, lr=0.000891, step_loss=0.0107/27/2023 18:46:23 - INFO - __main__ - train loss is 20.18180903722532\n",
      "Steps:  48%|▍| 7143/15000 [1:01:33<23:32,  5.56it/s, lr=0.000891, step_loss=0.1607/27/2023 18:46:23 - INFO - __main__ - train loss is 20.51582422782667\n",
      "Steps:  48%|▍| 7144/15000 [1:01:33<23:33,  5.56it/s, lr=0.000891, step_loss=0.3307/27/2023 18:46:23 - INFO - __main__ - train loss is 20.594214557902887\n",
      "Steps:  48%|▍| 7145/15000 [1:01:33<23:32,  5.56it/s, lr=0.000891, step_loss=0.0707/27/2023 18:46:23 - INFO - __main__ - train loss is 20.611417268635705\n",
      "Steps:  48%|▍| 7146/15000 [1:01:33<23:33,  5.56it/s, lr=0.000891, step_loss=0.0107/27/2023 18:46:23 - INFO - __main__ - train loss is 20.78129053604789\n",
      "Steps:  48%|▍| 7147/15000 [1:01:34<23:31,  5.56it/s, lr=0.000891, step_loss=0.1707/27/2023 18:46:23 - INFO - __main__ - train loss is 20.78254738182295\n",
      "Steps:  48%|▍| 7148/15000 [1:01:34<23:32,  5.56it/s, lr=0.000892, step_loss=0.0007/27/2023 18:46:24 - INFO - __main__ - train loss is 20.784690356231295\n",
      "Steps:  48%|▍| 7149/15000 [1:01:34<23:32,  5.56it/s, lr=0.000892, step_loss=0.0007/27/2023 18:46:24 - INFO - __main__ - train loss is 20.798658964573406\n",
      "Steps:  48%|▍| 7150/15000 [1:01:34<23:30,  5.57it/s, lr=0.000892, step_loss=0.0107/27/2023 18:46:24 - INFO - __main__ - train loss is 20.811353900819086\n",
      "Steps:  48%|▍| 7151/15000 [1:01:34<23:31,  5.56it/s, lr=0.000892, step_loss=0.0107/27/2023 18:46:24 - INFO - __main__ - train loss is 21.36664084473159\n",
      "Steps:  48%|▍| 7152/15000 [1:01:34<23:29,  5.57it/s, lr=0.000892, step_loss=0.5507/27/2023 18:46:24 - INFO - __main__ - train loss is 21.444213674752973\n",
      "Steps:  48%|▍| 7153/15000 [1:01:35<23:34,  5.55it/s, lr=0.000892, step_loss=0.0707/27/2023 18:46:25 - INFO - __main__ - train loss is 21.44906462810468\n",
      "Steps:  48%|▍| 7154/15000 [1:01:35<23:37,  5.53it/s, lr=0.000892, step_loss=0.0007/27/2023 18:46:25 - INFO - __main__ - train loss is 21.463185672531836\n",
      "Steps:  48%|▍| 7155/15000 [1:01:35<23:34,  5.55it/s, lr=0.000892, step_loss=0.0107/27/2023 18:46:25 - INFO - __main__ - train loss is 21.504699666867964\n",
      "Steps:  48%|▍| 7156/15000 [1:01:35<23:31,  5.56it/s, lr=0.000893, step_loss=0.0407/27/2023 18:46:25 - INFO - __main__ - train loss is 21.530021686921827\n",
      "Steps:  48%|▍| 7157/15000 [1:01:35<23:28,  5.57it/s, lr=0.000893, step_loss=0.0207/27/2023 18:46:25 - INFO - __main__ - train loss is 21.532196398708038\n",
      "Steps:  48%|▍| 7158/15000 [1:01:36<23:27,  5.57it/s, lr=0.000893, step_loss=0.0007/27/2023 18:46:25 - INFO - __main__ - train loss is 21.53808122209739\n",
      "Steps:  48%|▍| 7159/15000 [1:01:36<23:26,  5.57it/s, lr=0.000893, step_loss=0.0007/27/2023 18:46:26 - INFO - __main__ - train loss is 21.708880149642937\n",
      "Steps:  48%|▍| 7160/15000 [1:01:36<23:30,  5.56it/s, lr=0.000893, step_loss=0.1707/27/2023 18:46:26 - INFO - __main__ - train loss is 21.84980287484359\n",
      "Steps:  48%|▍| 7161/15000 [1:01:36<23:42,  5.51it/s, lr=0.000893, step_loss=0.1407/27/2023 18:46:26 - INFO - __main__ - train loss is 22.20131271413993\n",
      "Steps:  48%|▍| 7162/15000 [1:01:36<23:51,  5.47it/s, lr=0.000893, step_loss=0.3507/27/2023 18:46:26 - INFO - __main__ - train loss is 22.210666591185145\n",
      "Steps:  48%|▍| 7163/15000 [1:01:36<23:54,  5.46it/s, lr=0.000893, step_loss=0.0007/27/2023 18:46:26 - INFO - __main__ - train loss is 22.553213233011775\n",
      "Steps:  48%|▍| 7164/15000 [1:01:37<23:58,  5.45it/s, lr=0.000894, step_loss=0.3407/27/2023 18:46:27 - INFO - __main__ - train loss is 22.883023166912608\n",
      "Steps:  48%|▍| 7165/15000 [1:01:37<24:00,  5.44it/s, lr=0.000894, step_loss=0.3307/27/2023 18:46:27 - INFO - __main__ - train loss is 23.03014163102489\n",
      "Steps:  48%|▍| 7166/15000 [1:01:37<24:01,  5.43it/s, lr=0.000894, step_loss=0.1407/27/2023 18:46:27 - INFO - __main__ - train loss is 23.06965210090857\n",
      "Steps:  48%|▍| 7167/15000 [1:01:37<24:04,  5.42it/s, lr=0.000894, step_loss=0.0307/27/2023 18:46:27 - INFO - __main__ - train loss is 23.093130135792308\n",
      "Steps:  48%|▍| 7168/15000 [1:01:37<24:10,  5.40it/s, lr=0.000894, step_loss=0.0207/27/2023 18:46:27 - INFO - __main__ - train loss is 23.098851151647978\n",
      "Steps:  48%|▍| 7169/15000 [1:01:38<24:04,  5.42it/s, lr=0.000894, step_loss=0.0007/27/2023 18:46:27 - INFO - __main__ - train loss is 23.212697915616445\n",
      "Steps:  48%|▍| 7170/15000 [1:01:38<24:01,  5.43it/s, lr=0.000894, step_loss=0.1107/27/2023 18:46:28 - INFO - __main__ - train loss is 23.313792250934057\n",
      "Steps:  48%|▍| 7171/15000 [1:01:38<24:06,  5.41it/s, lr=0.000895, step_loss=0.1007/27/2023 18:46:28 - INFO - __main__ - train loss is 23.3161878088722\n",
      "Steps:  48%|▍| 7172/15000 [1:01:38<24:05,  5.42it/s, lr=0.000895, step_loss=0.0007/27/2023 18:46:28 - INFO - __main__ - train loss is 23.3199502407806\n",
      "Steps:  48%|▍| 7173/15000 [1:01:38<24:21,  5.36it/s, lr=0.000895, step_loss=0.0007/27/2023 18:46:28 - INFO - __main__ - train loss is 23.373195539345033\n",
      "Steps:  48%|▍| 7174/15000 [1:01:39<24:40,  5.29it/s, lr=0.000895, step_loss=0.0507/27/2023 18:46:28 - INFO - __main__ - train loss is 23.39462789997924\n",
      "Steps:  48%|▍| 7175/15000 [1:01:39<25:03,  5.21it/s, lr=0.000895, step_loss=0.0207/27/2023 18:46:29 - INFO - __main__ - train loss is 23.408030993421562\n",
      "Steps:  48%|▍| 7176/15000 [1:01:39<25:16,  5.16it/s, lr=0.000895, step_loss=0.0107/27/2023 18:46:29 - INFO - __main__ - train loss is 23.47525740333367\n",
      "Steps:  48%|▍| 7177/15000 [1:01:39<25:20,  5.14it/s, lr=0.000895, step_loss=0.0607/27/2023 18:46:29 - INFO - __main__ - train loss is 23.952945626457222\n",
      "Steps:  48%|▍| 7178/15000 [1:01:39<25:59,  5.02it/s, lr=0.000895, step_loss=0.4707/27/2023 18:46:29 - INFO - __main__ - train loss is 24.23090419836808\n",
      "Steps:  48%|▍| 7179/15000 [1:01:40<25:52,  5.04it/s, lr=0.000896, step_loss=0.2707/27/2023 18:46:29 - INFO - __main__ - train loss is 24.703673756797798\n",
      "Steps:  48%|▍| 7180/15000 [1:01:40<25:44,  5.06it/s, lr=0.000896, step_loss=0.4707/27/2023 18:46:30 - INFO - __main__ - train loss is 24.727646964718588\n",
      "Steps:  48%|▍| 7181/15000 [1:01:40<25:42,  5.07it/s, lr=0.000896, step_loss=0.0207/27/2023 18:46:30 - INFO - __main__ - train loss is 24.84045630984474\n",
      "Steps:  48%|▍| 7182/15000 [1:01:40<25:39,  5.08it/s, lr=0.000896, step_loss=0.1107/27/2023 18:46:30 - INFO - __main__ - train loss is 25.431474152137525\n",
      "Steps:  48%|▍| 7183/15000 [1:01:40<25:37,  5.09it/s, lr=0.000896, step_loss=0.5907/27/2023 18:46:30 - INFO - __main__ - train loss is 25.452142399852164\n",
      "Steps:  48%|▍| 7184/15000 [1:01:41<25:38,  5.08it/s, lr=0.000896, step_loss=0.0207/27/2023 18:46:30 - INFO - __main__ - train loss is 25.533841994707473\n",
      "Steps:  48%|▍| 7185/15000 [1:01:41<25:38,  5.08it/s, lr=0.000896, step_loss=0.0807/27/2023 18:46:31 - INFO - __main__ - train loss is 25.827514645759948\n",
      "Steps:  48%|▍| 7186/15000 [1:01:41<25:41,  5.07it/s, lr=0.000896, step_loss=0.2907/27/2023 18:46:31 - INFO - __main__ - train loss is 25.890119095449336\n",
      "Steps:  48%|▍| 7187/15000 [1:01:41<25:40,  5.07it/s, lr=0.000896, step_loss=0.0607/27/2023 18:46:31 - INFO - __main__ - train loss is 26.010669638519175\n",
      "Steps:  48%|▍| 7188/15000 [1:01:41<25:34,  5.09it/s, lr=0.000897, step_loss=0.1207/27/2023 18:46:31 - INFO - __main__ - train loss is 26.05799253017176\n",
      "Steps:  48%|▍| 7189/15000 [1:01:41<25:31,  5.10it/s, lr=0.000897, step_loss=0.0407/27/2023 18:46:31 - INFO - __main__ - train loss is 26.508813512627967\n",
      "Steps:  48%|▍| 7190/15000 [1:01:42<25:31,  5.10it/s, lr=0.000897, step_loss=0.4507/27/2023 18:46:32 - INFO - __main__ - train loss is 26.642480698530562\n",
      "Steps:  48%|▍| 7191/15000 [1:01:42<26:01,  5.00it/s, lr=0.000897, step_loss=0.1307/27/2023 18:46:32 - INFO - __main__ - train loss is 26.643846368067898\n",
      "Steps:  48%|▍| 7192/15000 [1:01:42<25:53,  5.03it/s, lr=0.000897, step_loss=0.0007/27/2023 18:46:32 - INFO - __main__ - train loss is 26.651648688712157\n",
      "Steps:  48%|▍| 7193/15000 [1:01:42<25:46,  5.05it/s, lr=0.000897, step_loss=0.0007/27/2023 18:46:32 - INFO - __main__ - train loss is 26.933102834620513\n",
      "Steps:  48%|▍| 7194/15000 [1:01:42<25:42,  5.06it/s, lr=0.000897, step_loss=0.2807/27/2023 18:46:32 - INFO - __main__ - train loss is 26.94329069799278\n",
      "Steps:  48%|▍| 7195/15000 [1:01:43<25:43,  5.06it/s, lr=0.000897, step_loss=0.0107/27/2023 18:46:33 - INFO - __main__ - train loss is 27.260321366251446\n",
      "Steps:  48%|▍| 7196/15000 [1:01:43<25:43,  5.06it/s, lr=0.000898, step_loss=0.3107/27/2023 18:46:33 - INFO - __main__ - train loss is 27.376436891616322\n",
      "Steps:  48%|▍| 7197/15000 [1:01:43<25:37,  5.08it/s, lr=0.000898, step_loss=0.1107/27/2023 18:46:33 - INFO - __main__ - train loss is 27.687765004695393\n",
      "Steps:  48%|▍| 7198/15000 [1:01:43<25:34,  5.09it/s, lr=0.000898, step_loss=0.3107/27/2023 18:46:33 - INFO - __main__ - train loss is 27.81462723261211\n",
      "Steps:  48%|▍| 7199/15000 [1:01:43<25:38,  5.07it/s, lr=0.000898, step_loss=0.1207/27/2023 18:46:33 - INFO - __main__ - train loss is 28.31569588428829\n",
      "Steps:  48%|▍| 7200/15000 [1:01:44<25:21,  5.13it/s, lr=0.000898, step_loss=0.5007/27/2023 18:46:34 - INFO - __main__ - train loss is 28.554073067964055\n",
      "Steps:  48%|▍| 7201/15000 [1:01:44<24:52,  5.23it/s, lr=0.000898, step_loss=0.2307/27/2023 18:46:34 - INFO - __main__ - train loss is 28.766312005580403\n",
      "Steps:  48%|▍| 7202/15000 [1:01:44<24:35,  5.29it/s, lr=0.000898, step_loss=0.2107/27/2023 18:46:34 - INFO - __main__ - train loss is 28.841335254372098\n",
      "Steps:  48%|▍| 7203/15000 [1:01:44<24:45,  5.25it/s, lr=0.000898, step_loss=0.0707/27/2023 18:46:34 - INFO - __main__ - train loss is 28.84430304041598\n",
      "Steps:  48%|▍| 7204/15000 [1:01:44<25:00,  5.19it/s, lr=0.000899, step_loss=0.0007/27/2023 18:46:34 - INFO - __main__ - train loss is 29.056522755534388\n",
      "Steps:  48%|▍| 7205/15000 [1:01:45<25:10,  5.16it/s, lr=0.000899, step_loss=0.2107/27/2023 18:46:34 - INFO - __main__ - train loss is 29.076931369141676\n",
      "Steps:  48%|▍| 7206/15000 [1:01:45<25:20,  5.13it/s, lr=0.000899, step_loss=0.0207/27/2023 18:46:35 - INFO - __main__ - train loss is 29.123519037500955\n",
      "Steps:  48%|▍| 7207/15000 [1:01:45<25:25,  5.11it/s, lr=0.000899, step_loss=0.0407/27/2023 18:46:35 - INFO - __main__ - train loss is 29.134747635223903\n",
      "Steps:  48%|▍| 7208/15000 [1:01:45<25:30,  5.09it/s, lr=0.000899, step_loss=0.0107/27/2023 18:46:35 - INFO - __main__ - train loss is 29.257811393239535\n",
      "Steps:  48%|▍| 7209/15000 [1:01:45<25:18,  5.13it/s, lr=0.000899, step_loss=0.1207/27/2023 18:46:35 - INFO - __main__ - train loss is 29.355259280302562\n",
      "Steps:  48%|▍| 7210/15000 [1:01:46<25:21,  5.12it/s, lr=0.000899, step_loss=0.0907/27/2023 18:46:35 - INFO - __main__ - train loss is 29.35927942825947\n",
      "Steps:  48%|▍| 7211/15000 [1:01:46<25:24,  5.11it/s, lr=0.0009, step_loss=0.004007/27/2023 18:46:36 - INFO - __main__ - train loss is 29.477042187587358\n",
      "Steps:  48%|▍| 7212/15000 [1:01:46<25:25,  5.11it/s, lr=0.0009, step_loss=0.118]07/27/2023 18:46:36 - INFO - __main__ - train loss is 29.480310002923943\n",
      "Steps:  48%|▍| 7213/15000 [1:01:46<25:07,  5.17it/s, lr=0.0009, step_loss=0.003207/27/2023 18:46:36 - INFO - __main__ - train loss is 29.52633061504457\n",
      "Steps:  48%|▍| 7214/15000 [1:01:46<24:36,  5.27it/s, lr=0.0009, step_loss=0.046]07/27/2023 18:46:36 - INFO - __main__ - train loss is 29.530563993030228\n",
      "Steps:  48%|▍| 7215/15000 [1:01:47<24:13,  5.36it/s, lr=0.0009, step_loss=0.004207/27/2023 18:46:36 - INFO - __main__ - train loss is 30.059719008975662\n",
      "Steps:  48%|▍| 7216/15000 [1:01:47<23:57,  5.42it/s, lr=0.0009, step_loss=0.529]07/27/2023 18:46:37 - INFO - __main__ - train loss is 30.411688280873932\n",
      "Steps:  48%|▍| 7217/15000 [1:01:47<23:45,  5.46it/s, lr=0.0009, step_loss=0.352]07/27/2023 18:46:37 - INFO - __main__ - train loss is 30.417717062518932\n",
      "Steps:  48%|▍| 7218/15000 [1:01:47<23:36,  5.49it/s, lr=0.0009, step_loss=0.006007/27/2023 18:46:37 - INFO - __main__ - train loss is 30.660951696918346\n",
      "Steps:  48%|▍| 7219/15000 [1:01:47<23:31,  5.51it/s, lr=0.0009, step_loss=0.243]07/27/2023 18:46:37 - INFO - __main__ - train loss is 30.819990702555515\n",
      "Steps:  48%|▍| 7220/15000 [1:01:47<23:28,  5.53it/s, lr=0.000901, step_loss=0.1507/27/2023 18:46:37 - INFO - __main__ - train loss is 30.98291731684003\n",
      "Steps:  48%|▍| 7221/15000 [1:01:48<23:25,  5.54it/s, lr=0.000901, step_loss=0.1607/27/2023 18:46:37 - INFO - __main__ - train loss is 31.165903382585384\n",
      "Steps:  48%|▍| 7222/15000 [1:01:48<23:23,  5.54it/s, lr=0.000901, step_loss=0.1807/27/2023 18:46:38 - INFO - __main__ - train loss is 31.180781664908864\n",
      "Steps:  48%|▍| 7223/15000 [1:01:48<23:22,  5.55it/s, lr=0.000901, step_loss=0.0107/27/2023 18:46:38 - INFO - __main__ - train loss is 31.18446473486256\n",
      "Steps:  48%|▍| 7224/15000 [1:01:48<23:20,  5.55it/s, lr=0.000901, step_loss=0.0007/27/2023 18:46:38 - INFO - __main__ - train loss is 31.219489228795283\n",
      "Steps:  48%|▍| 7225/15000 [1:01:48<23:19,  5.56it/s, lr=0.000901, step_loss=0.0307/27/2023 18:46:38 - INFO - __main__ - train loss is 31.22484988567885\n",
      "Steps:  48%|▍| 7226/15000 [1:01:49<23:18,  5.56it/s, lr=0.000901, step_loss=0.0007/27/2023 18:46:38 - INFO - __main__ - train loss is 31.459456479526125\n",
      "Steps:  48%|▍| 7227/15000 [1:01:49<23:18,  5.56it/s, lr=0.000901, step_loss=0.2307/27/2023 18:46:39 - INFO - __main__ - train loss is 31.469488473958336\n",
      "Steps:  48%|▍| 7228/15000 [1:01:49<23:17,  5.56it/s, lr=0.000902, step_loss=0.0107/27/2023 18:46:39 - INFO - __main__ - train loss is 31.584078999585472\n",
      "Steps:  48%|▍| 7229/15000 [1:01:49<23:16,  5.56it/s, lr=0.000902, step_loss=0.1107/27/2023 18:46:39 - INFO - __main__ - train loss is 31.62292080221232\n",
      "Steps:  48%|▍| 7230/15000 [1:01:49<23:15,  5.57it/s, lr=0.000902, step_loss=0.0307/27/2023 18:46:39 - INFO - __main__ - train loss is 31.624295045854524\n",
      "Steps:  48%|▍| 7231/15000 [1:01:49<23:15,  5.57it/s, lr=0.000902, step_loss=0.0007/27/2023 18:46:39 - INFO - __main__ - train loss is 31.757100959541276\n",
      "Steps:  48%|▍| 7232/15000 [1:01:50<23:28,  5.52it/s, lr=0.000902, step_loss=0.1307/27/2023 18:46:39 - INFO - __main__ - train loss is 31.792244491400197\n",
      "Steps:  48%|▍| 7233/15000 [1:01:50<23:33,  5.50it/s, lr=0.000902, step_loss=0.0307/27/2023 18:46:40 - INFO - __main__ - train loss is 32.527994451345876\n",
      "Steps:  48%|▍| 7234/15000 [1:01:50<23:27,  5.52it/s, lr=0.000902, step_loss=0.7307/27/2023 18:46:40 - INFO - __main__ - train loss is 32.5571940515656\n",
      "Steps:  48%|▍| 7235/15000 [1:01:50<23:23,  5.53it/s, lr=0.000902, step_loss=0.0207/27/2023 18:46:40 - INFO - __main__ - train loss is 32.91270422679372\n",
      "Steps:  48%|▍| 7236/15000 [1:01:50<23:21,  5.54it/s, lr=0.000903, step_loss=0.3507/27/2023 18:46:40 - INFO - __main__ - train loss is 32.92186110955663\n",
      "Steps:  48%|▍| 7237/15000 [1:01:51<23:19,  5.55it/s, lr=0.000903, step_loss=0.0007/27/2023 18:46:40 - INFO - __main__ - train loss is 33.12003889423795\n",
      "Steps:  48%|▍| 7238/15000 [1:01:51<23:17,  5.55it/s, lr=0.000903, step_loss=0.1907/27/2023 18:46:41 - INFO - __main__ - train loss is 33.31836917740293\n",
      "Steps:  48%|▍| 7239/15000 [1:01:51<23:16,  5.56it/s, lr=0.000903, step_loss=0.1907/27/2023 18:46:41 - INFO - __main__ - train loss is 33.322818405227736\n",
      "Steps:  48%|▍| 7240/15000 [1:01:51<23:19,  5.55it/s, lr=0.000903, step_loss=0.0007/27/2023 18:46:41 - INFO - __main__ - train loss is 33.38271595467813\n",
      "Steps:  48%|▍| 7241/15000 [1:01:51<23:16,  5.56it/s, lr=0.000903, step_loss=0.0507/27/2023 18:46:41 - INFO - __main__ - train loss is 33.70955289830454\n",
      "Steps:  48%|▍| 7242/15000 [1:01:51<23:14,  5.56it/s, lr=0.000903, step_loss=0.3207/27/2023 18:46:41 - INFO - __main__ - train loss is 33.7151974698063\n",
      "Steps:  48%|▍| 7243/15000 [1:01:52<23:12,  5.57it/s, lr=0.000904, step_loss=0.0007/27/2023 18:46:41 - INFO - __main__ - train loss is 33.72247475455515\n",
      "Steps:  48%|▍| 7244/15000 [1:01:52<23:11,  5.57it/s, lr=0.000904, step_loss=0.0007/27/2023 18:46:42 - INFO - __main__ - train loss is 33.764763572020456\n",
      "Steps:  48%|▍| 7245/15000 [1:01:52<23:10,  5.58it/s, lr=0.000904, step_loss=0.0407/27/2023 18:46:42 - INFO - __main__ - train loss is 34.34871826390736\n",
      "Steps:  48%|▍| 7246/15000 [1:01:52<23:10,  5.58it/s, lr=0.000904, step_loss=0.5807/27/2023 18:46:42 - INFO - __main__ - train loss is 34.358252617297694\n",
      "Steps:  48%|▍| 7247/15000 [1:01:52<23:10,  5.58it/s, lr=0.000904, step_loss=0.0007/27/2023 18:46:42 - INFO - __main__ - train loss is 34.361618290888146\n",
      "Steps:  48%|▍| 7248/15000 [1:01:52<23:09,  5.58it/s, lr=0.000904, step_loss=0.0007/27/2023 18:46:42 - INFO - __main__ - train loss is 34.4310614571441\n",
      "Steps:  48%|▍| 7249/15000 [1:01:53<23:10,  5.57it/s, lr=0.000904, step_loss=0.0607/27/2023 18:46:43 - INFO - __main__ - train loss is 34.68296141480096\n",
      "Steps:  48%|▍| 7250/15000 [1:01:53<23:09,  5.58it/s, lr=0.000904, step_loss=0.2507/27/2023 18:46:43 - INFO - __main__ - train loss is 34.68811396253295\n",
      "Steps:  48%|▍| 7251/15000 [1:01:53<23:09,  5.58it/s, lr=0.000905, step_loss=0.0007/27/2023 18:46:43 - INFO - __main__ - train loss is 34.99133918178268\n",
      "Steps:  48%|▍| 7252/15000 [1:01:53<23:08,  5.58it/s, lr=0.000905, step_loss=0.3007/27/2023 18:46:43 - INFO - __main__ - train loss is 34.99890540377237\n",
      "Steps:  48%|▍| 7253/15000 [1:01:53<23:22,  5.52it/s, lr=0.000905, step_loss=0.0007/27/2023 18:46:43 - INFO - __main__ - train loss is 35.01840323605575\n",
      "Steps:  48%|▍| 7254/15000 [1:01:54<23:22,  5.52it/s, lr=0.000905, step_loss=0.0107/27/2023 18:46:43 - INFO - __main__ - train loss is 35.04960406781174\n",
      "Steps:  48%|▍| 7255/15000 [1:01:54<23:18,  5.54it/s, lr=0.000905, step_loss=0.0307/27/2023 18:46:44 - INFO - __main__ - train loss is 35.308398017892614\n",
      "Steps:  48%|▍| 7256/15000 [1:01:54<23:14,  5.55it/s, lr=0.000905, step_loss=0.2507/27/2023 18:46:44 - INFO - __main__ - train loss is 35.413563834736124\n",
      "Steps:  48%|▍| 7257/15000 [1:01:54<23:16,  5.55it/s, lr=0.000905, step_loss=0.1007/27/2023 18:46:44 - INFO - __main__ - train loss is 35.484760301420465\n",
      "Steps:  48%|▍| 7258/15000 [1:01:54<23:20,  5.53it/s, lr=0.000905, step_loss=0.0707/27/2023 18:46:44 - INFO - __main__ - train loss is 35.79848982603289\n",
      "Steps:  48%|▍| 7259/15000 [1:01:54<23:14,  5.55it/s, lr=0.000905, step_loss=0.3107/27/2023 18:46:44 - INFO - __main__ - train loss is 36.26053242594935\n",
      "Steps:  48%|▍| 7260/15000 [1:01:55<23:27,  5.50it/s, lr=0.000906, step_loss=0.4607/27/2023 18:46:45 - INFO - __main__ - train loss is 36.27656772197224\n",
      "Steps:  48%|▍| 7261/15000 [1:01:55<23:58,  5.38it/s, lr=0.000906, step_loss=0.0107/27/2023 18:46:45 - INFO - __main__ - train loss is 36.28765335516073\n",
      "Steps:  48%|▍| 7262/15000 [1:01:55<24:44,  5.21it/s, lr=0.000906, step_loss=0.0107/27/2023 18:46:45 - INFO - __main__ - train loss is 36.38205468491651\n",
      "Steps:  48%|▍| 7263/15000 [1:01:55<25:28,  5.06it/s, lr=0.000906, step_loss=0.0907/27/2023 18:46:45 - INFO - __main__ - train loss is 36.39111125306226\n",
      "Steps:  48%|▍| 7264/15000 [1:01:55<25:02,  5.15it/s, lr=0.000906, step_loss=0.0007/27/2023 18:46:45 - INFO - __main__ - train loss is 36.39531333115883\n",
      "Steps:  48%|▍| 7265/15000 [1:01:56<24:27,  5.27it/s, lr=0.000906, step_loss=0.0007/27/2023 18:46:45 - INFO - __main__ - train loss is 36.43541653570719\n",
      "Steps:  48%|▍| 7266/15000 [1:01:56<24:03,  5.36it/s, lr=0.000906, step_loss=0.0407/27/2023 18:46:46 - INFO - __main__ - train loss is 36.449717219220474\n",
      "Steps:  48%|▍| 7267/15000 [1:01:56<23:45,  5.42it/s, lr=0.000906, step_loss=0.0107/27/2023 18:46:46 - INFO - __main__ - train loss is 36.79517203127034\n",
      "Steps:  48%|▍| 7268/15000 [1:01:56<23:44,  5.43it/s, lr=0.000907, step_loss=0.3407/27/2023 18:46:46 - INFO - __main__ - train loss is 36.90502296690829\n",
      "Steps:  48%|▍| 7269/15000 [1:01:56<23:32,  5.47it/s, lr=0.000907, step_loss=0.1107/27/2023 18:46:46 - INFO - __main__ - train loss is 36.97310833935626\n",
      "Steps:  48%|▍| 7270/15000 [1:01:57<23:23,  5.51it/s, lr=0.000907, step_loss=0.0607/27/2023 18:46:46 - INFO - __main__ - train loss is 37.002382464008406\n",
      "Steps:  48%|▍| 7271/15000 [1:01:57<23:18,  5.53it/s, lr=0.000907, step_loss=0.0207/27/2023 18:46:47 - INFO - __main__ - train loss is 37.01919609797187\n",
      "Steps:  48%|▍| 7272/15000 [1:01:57<32:09,  4.01it/s, lr=0.000907, step_loss=0.0107/27/2023 18:46:48 - INFO - __main__ - Per validation step average loss is 0.20892608165740967\n",
      "07/27/2023 18:46:48 - INFO - __main__ - Cumulative validation average loss is 0.20892608165740967\n",
      "07/27/2023 18:46:48 - INFO - __main__ - Per validation step average loss is 0.29056206345558167\n",
      "07/27/2023 18:46:48 - INFO - __main__ - Cumulative validation average loss is 0.49948814511299133\n",
      "07/27/2023 18:46:49 - INFO - __main__ - Per validation step average loss is 0.004060172941535711\n",
      "07/27/2023 18:46:49 - INFO - __main__ - Cumulative validation average loss is 0.503548318054527\n",
      "07/27/2023 18:46:49 - INFO - __main__ - Per validation step average loss is 0.1196058839559555\n",
      "07/27/2023 18:46:49 - INFO - __main__ - Cumulative validation average loss is 0.6231542020104825\n",
      "07/27/2023 18:46:49 - INFO - __main__ - Per validation step average loss is 0.06969338655471802\n",
      "07/27/2023 18:46:49 - INFO - __main__ - Cumulative validation average loss is 0.6928475885652006\n",
      "07/27/2023 18:46:50 - INFO - __main__ - Per validation step average loss is 0.3001711964607239\n",
      "07/27/2023 18:46:50 - INFO - __main__ - Cumulative validation average loss is 0.9930187850259244\n",
      "07/27/2023 18:46:50 - INFO - __main__ - Per validation step average loss is 0.5777040719985962\n",
      "07/27/2023 18:46:50 - INFO - __main__ - Cumulative validation average loss is 1.5707228570245206\n",
      "07/27/2023 18:46:51 - INFO - __main__ - Per validation step average loss is 0.0208890363574028\n",
      "07/27/2023 18:46:51 - INFO - __main__ - Cumulative validation average loss is 1.5916118933819234\n",
      "07/27/2023 18:46:51 - INFO - __main__ - Per validation step average loss is 0.0426919162273407\n",
      "07/27/2023 18:46:51 - INFO - __main__ - Cumulative validation average loss is 1.6343038096092641\n",
      "07/27/2023 18:46:52 - INFO - __main__ - Per validation step average loss is 0.03440086916089058\n",
      "07/27/2023 18:46:52 - INFO - __main__ - Cumulative validation average loss is 1.6687046787701547\n",
      "07/27/2023 18:46:52 - INFO - __main__ - Per validation step average loss is 0.39852702617645264\n",
      "07/27/2023 18:46:52 - INFO - __main__ - Cumulative validation average loss is 2.0672317049466074\n",
      "07/27/2023 18:46:52 - INFO - __main__ - Per validation step average loss is 0.00562647171318531\n",
      "07/27/2023 18:46:52 - INFO - __main__ - Cumulative validation average loss is 2.0728581766597927\n",
      "07/27/2023 18:46:53 - INFO - __main__ - Per validation step average loss is 0.016508040949702263\n",
      "07/27/2023 18:46:53 - INFO - __main__ - Cumulative validation average loss is 2.089366217609495\n",
      "07/27/2023 18:46:53 - INFO - __main__ - Per validation step average loss is 0.34840789437294006\n",
      "07/27/2023 18:46:53 - INFO - __main__ - Cumulative validation average loss is 2.437774111982435\n",
      "07/27/2023 18:46:54 - INFO - __main__ - Per validation step average loss is 0.25678080320358276\n",
      "07/27/2023 18:46:54 - INFO - __main__ - Cumulative validation average loss is 2.6945549151860178\n",
      "07/27/2023 18:46:54 - INFO - __main__ - Per validation step average loss is 0.22844983637332916\n",
      "07/27/2023 18:46:54 - INFO - __main__ - Cumulative validation average loss is 2.923004751559347\n",
      "07/27/2023 18:46:54 - INFO - __main__ - Per validation step average loss is 0.08515185117721558\n",
      "07/27/2023 18:46:54 - INFO - __main__ - Cumulative validation average loss is 3.0081566027365625\n",
      "07/27/2023 18:46:55 - INFO - __main__ - Per validation step average loss is 0.01027417927980423\n",
      "07/27/2023 18:46:55 - INFO - __main__ - Cumulative validation average loss is 3.0184307820163667\n",
      "07/27/2023 18:46:55 - INFO - __main__ - Per validation step average loss is 0.1835552304983139\n",
      "07/27/2023 18:46:55 - INFO - __main__ - Cumulative validation average loss is 3.2019860125146806\n",
      "07/27/2023 18:46:56 - INFO - __main__ - Per validation step average loss is 0.004262726753950119\n",
      "07/27/2023 18:46:56 - INFO - __main__ - Cumulative validation average loss is 3.2062487392686307\n",
      "07/27/2023 18:46:56 - INFO - __main__ - Per validation step average loss is 0.23271498084068298\n",
      "07/27/2023 18:46:56 - INFO - __main__ - Cumulative validation average loss is 3.4389637201093137\n",
      "07/27/2023 18:46:57 - INFO - __main__ - Per validation step average loss is 0.968614935874939\n",
      "07/27/2023 18:46:57 - INFO - __main__ - Cumulative validation average loss is 4.407578655984253\n",
      "07/27/2023 18:46:57 - INFO - __main__ - Per validation step average loss is 0.0651874914765358\n",
      "07/27/2023 18:46:57 - INFO - __main__ - Cumulative validation average loss is 4.4727661474607885\n",
      "07/27/2023 18:46:57 - INFO - __main__ - Per validation step average loss is 0.5137466192245483\n",
      "07/27/2023 18:46:57 - INFO - __main__ - Cumulative validation average loss is 4.986512766685337\n",
      "07/27/2023 18:46:58 - INFO - __main__ - Per validation step average loss is 0.3053494989871979\n",
      "07/27/2023 18:46:58 - INFO - __main__ - Cumulative validation average loss is 5.291862265672535\n",
      "07/27/2023 18:46:58 - INFO - __main__ - Per validation step average loss is 0.23971202969551086\n",
      "07/27/2023 18:46:58 - INFO - __main__ - Cumulative validation average loss is 5.531574295368046\n",
      "07/27/2023 18:46:59 - INFO - __main__ - Per validation step average loss is 0.0032698384020477533\n",
      "07/27/2023 18:46:59 - INFO - __main__ - Cumulative validation average loss is 5.534844133770093\n",
      "07/27/2023 18:46:59 - INFO - __main__ - Per validation step average loss is 0.3697960376739502\n",
      "07/27/2023 18:46:59 - INFO - __main__ - Cumulative validation average loss is 5.9046401714440435\n",
      "07/27/2023 18:46:59 - INFO - __main__ - Per validation step average loss is 0.016725724563002586\n",
      "07/27/2023 18:46:59 - INFO - __main__ - Cumulative validation average loss is 5.921365896007046\n",
      "07/27/2023 18:47:00 - INFO - __main__ - Per validation step average loss is 0.03284841775894165\n",
      "07/27/2023 18:47:00 - INFO - __main__ - Cumulative validation average loss is 5.954214313765988\n",
      "07/27/2023 18:47:00 - INFO - __main__ - Per validation step average loss is 0.3354630470275879\n",
      "07/27/2023 18:47:00 - INFO - __main__ - Cumulative validation average loss is 6.289677360793576\n",
      "07/27/2023 18:47:01 - INFO - __main__ - Per validation step average loss is 0.25653791427612305\n",
      "07/27/2023 18:47:01 - INFO - __main__ - Cumulative validation average loss is 6.546215275069699\n",
      "07/27/2023 18:47:01 - INFO - __main__ - Per validation step average loss is 0.11541226506233215\n",
      "07/27/2023 18:47:01 - INFO - __main__ - Cumulative validation average loss is 6.661627540132031\n",
      "07/27/2023 18:47:01 - INFO - __main__ - Per validation step average loss is 0.0011783865047618747\n",
      "07/27/2023 18:47:01 - INFO - __main__ - Cumulative validation average loss is 6.662805926636793\n",
      "07/27/2023 18:47:02 - INFO - __main__ - Per validation step average loss is 0.4922698736190796\n",
      "07/27/2023 18:47:02 - INFO - __main__ - Cumulative validation average loss is 7.155075800255872\n",
      "07/27/2023 18:47:02 - INFO - __main__ - Per validation step average loss is 0.3614567518234253\n",
      "07/27/2023 18:47:02 - INFO - __main__ - Cumulative validation average loss is 7.516532552079298\n",
      "07/27/2023 18:47:03 - INFO - __main__ - Per validation step average loss is 0.03676503151655197\n",
      "07/27/2023 18:47:03 - INFO - __main__ - Cumulative validation average loss is 7.55329758359585\n",
      "07/27/2023 18:47:03 - INFO - __main__ - Per validation step average loss is 0.006234034895896912\n",
      "07/27/2023 18:47:03 - INFO - __main__ - Cumulative validation average loss is 7.5595316184917465\n",
      "07/27/2023 18:47:04 - INFO - __main__ - Per validation step average loss is 0.08860166370868683\n",
      "07/27/2023 18:47:04 - INFO - __main__ - Cumulative validation average loss is 7.648133282200433\n",
      "07/27/2023 18:47:04 - INFO - __main__ - Per validation step average loss is 0.001739773666486144\n",
      "07/27/2023 18:47:04 - INFO - __main__ - Cumulative validation average loss is 7.6498730558669195\n",
      "07/27/2023 18:47:04 - INFO - __main__ - Per validation step average loss is 0.005775902885943651\n",
      "07/27/2023 18:47:04 - INFO - __main__ - Cumulative validation average loss is 7.655648958752863\n",
      "07/27/2023 18:47:05 - INFO - __main__ - Per validation step average loss is 0.0025338022969663143\n",
      "07/27/2023 18:47:05 - INFO - __main__ - Cumulative validation average loss is 7.658182761049829\n",
      "07/27/2023 18:47:05 - INFO - __main__ - Per validation step average loss is 0.07040762901306152\n",
      "07/27/2023 18:47:05 - INFO - __main__ - Cumulative validation average loss is 7.728590390062891\n",
      "07/27/2023 18:47:06 - INFO - __main__ - Per validation step average loss is 0.04487244412302971\n",
      "07/27/2023 18:47:06 - INFO - __main__ - Cumulative validation average loss is 7.773462834185921\n",
      "07/27/2023 18:47:06 - INFO - __main__ - Per validation step average loss is 0.3067747950553894\n",
      "07/27/2023 18:47:06 - INFO - __main__ - Cumulative validation average loss is 8.08023762924131\n",
      "07/27/2023 18:47:06 - INFO - __main__ - Per validation step average loss is 0.0013127934653311968\n",
      "07/27/2023 18:47:06 - INFO - __main__ - Cumulative validation average loss is 8.081550422706641\n",
      "07/27/2023 18:47:07 - INFO - __main__ - Per validation step average loss is 0.013989618979394436\n",
      "07/27/2023 18:47:07 - INFO - __main__ - Cumulative validation average loss is 8.095540041686036\n",
      "07/27/2023 18:47:07 - INFO - __main__ - Per validation step average loss is 0.49698692560195923\n",
      "07/27/2023 18:47:07 - INFO - __main__ - Cumulative validation average loss is 8.592526967287995\n",
      "07/27/2023 18:47:08 - INFO - __main__ - Per validation step average loss is 0.01020877156406641\n",
      "07/27/2023 18:47:08 - INFO - __main__ - Cumulative validation average loss is 8.602735738852061\n",
      "07/27/2023 18:47:08 - INFO - __main__ - Per validation step average loss is 0.0066778999753296375\n",
      "07/27/2023 18:47:08 - INFO - __main__ - Cumulative validation average loss is 8.609413638827391\n",
      "07/27/2023 18:47:08 - INFO - __main__ - Per validation step average loss is 0.14664927124977112\n",
      "07/27/2023 18:47:08 - INFO - __main__ - Cumulative validation average loss is 8.756062910077162\n",
      "07/27/2023 18:47:09 - INFO - __main__ - Per validation step average loss is 0.0027742385864257812\n",
      "07/27/2023 18:47:09 - INFO - __main__ - Cumulative validation average loss is 8.758837148663588\n",
      "07/27/2023 18:47:09 - INFO - __main__ - Per validation step average loss is 0.16220256686210632\n",
      "07/27/2023 18:47:09 - INFO - __main__ - Cumulative validation average loss is 8.921039715525694\n",
      "07/27/2023 18:47:10 - INFO - __main__ - Per validation step average loss is 0.009330293163657188\n",
      "07/27/2023 18:47:10 - INFO - __main__ - Cumulative validation average loss is 8.930370008689351\n",
      "07/27/2023 18:47:10 - INFO - __main__ - Per validation step average loss is 0.2776139974594116\n",
      "07/27/2023 18:47:10 - INFO - __main__ - Cumulative validation average loss is 9.207984006148763\n",
      "07/27/2023 18:47:11 - INFO - __main__ - Per validation step average loss is 0.31073349714279175\n",
      "07/27/2023 18:47:11 - INFO - __main__ - Cumulative validation average loss is 9.518717503291555\n",
      "07/27/2023 18:47:11 - INFO - __main__ - Per validation step average loss is 0.23025871813297272\n",
      "07/27/2023 18:47:11 - INFO - __main__ - Cumulative validation average loss is 9.748976221424527\n",
      "07/27/2023 18:47:11 - INFO - __main__ - Per validation step average loss is 0.05504179745912552\n",
      "07/27/2023 18:47:11 - INFO - __main__ - Cumulative validation average loss is 9.804018018883653\n",
      "07/27/2023 18:47:12 - INFO - __main__ - Per validation step average loss is 0.18994523584842682\n",
      "07/27/2023 18:47:12 - INFO - __main__ - Cumulative validation average loss is 9.99396325473208\n",
      "07/27/2023 18:47:12 - INFO - __main__ - Per validation step average loss is 0.21589070558547974\n",
      "07/27/2023 18:47:12 - INFO - __main__ - Cumulative validation average loss is 10.20985396031756\n",
      "07/27/2023 18:47:13 - INFO - __main__ - Per validation step average loss is 0.014663275331258774\n",
      "07/27/2023 18:47:13 - INFO - __main__ - Cumulative validation average loss is 10.224517235648818\n",
      "07/27/2023 18:47:13 - INFO - __main__ - Per validation step average loss is 0.037090789526700974\n",
      "07/27/2023 18:47:13 - INFO - __main__ - Cumulative validation average loss is 10.26160802517552\n",
      "07/27/2023 18:47:13 - INFO - __main__ - Per validation step average loss is 0.003650871105492115\n",
      "07/27/2023 18:47:13 - INFO - __main__ - Cumulative validation average loss is 10.265258896281011\n",
      "07/27/2023 18:47:14 - INFO - __main__ - Per validation step average loss is 0.2697964906692505\n",
      "07/27/2023 18:47:14 - INFO - __main__ - Cumulative validation average loss is 10.535055386950262\n",
      "07/27/2023 18:47:14 - INFO - __main__ - Per validation step average loss is 0.15821807086467743\n",
      "07/27/2023 18:47:14 - INFO - __main__ - Cumulative validation average loss is 10.69327345781494\n",
      "07/27/2023 18:47:15 - INFO - __main__ - Per validation step average loss is 0.004451246466487646\n",
      "07/27/2023 18:47:15 - INFO - __main__ - Cumulative validation average loss is 10.697724704281427\n",
      "07/27/2023 18:47:15 - INFO - __main__ - Per validation step average loss is 0.03797472268342972\n",
      "07/27/2023 18:47:15 - INFO - __main__ - Cumulative validation average loss is 10.735699426964857\n",
      "07/27/2023 18:47:16 - INFO - __main__ - Per validation step average loss is 0.007279898971319199\n",
      "07/27/2023 18:47:16 - INFO - __main__ - Cumulative validation average loss is 10.742979325936176\n",
      "07/27/2023 18:47:16 - INFO - __main__ - Per validation step average loss is 0.03369361534714699\n",
      "07/27/2023 18:47:16 - INFO - __main__ - Cumulative validation average loss is 10.776672941283323\n",
      "07/27/2023 18:47:16 - INFO - __main__ - Per validation step average loss is 0.028609976172447205\n",
      "07/27/2023 18:47:16 - INFO - __main__ - Cumulative validation average loss is 10.80528291745577\n",
      "07/27/2023 18:47:17 - INFO - __main__ - Per validation step average loss is 0.2528122663497925\n",
      "07/27/2023 18:47:17 - INFO - __main__ - Cumulative validation average loss is 11.058095183805563\n",
      "07/27/2023 18:47:17 - INFO - __main__ - Per validation step average loss is 0.18784412741661072\n",
      "07/27/2023 18:47:17 - INFO - __main__ - Cumulative validation average loss is 11.245939311222173\n",
      "07/27/2023 18:47:18 - INFO - __main__ - Per validation step average loss is 0.40495565533638\n",
      "07/27/2023 18:47:18 - INFO - __main__ - Cumulative validation average loss is 11.650894966558553\n",
      "07/27/2023 18:47:18 - INFO - __main__ - Per validation step average loss is 0.0025922912172973156\n",
      "07/27/2023 18:47:18 - INFO - __main__ - Cumulative validation average loss is 11.65348725777585\n",
      "07/27/2023 18:47:18 - INFO - __main__ - Per validation step average loss is 0.08128673583269119\n",
      "07/27/2023 18:47:18 - INFO - __main__ - Cumulative validation average loss is 11.734773993608542\n",
      "07/27/2023 18:47:19 - INFO - __main__ - Per validation step average loss is 0.2712709903717041\n",
      "07/27/2023 18:47:19 - INFO - __main__ - Cumulative validation average loss is 12.006044983980246\n",
      "07/27/2023 18:47:19 - INFO - __main__ - Per validation step average loss is 0.2935253381729126\n",
      "07/27/2023 18:47:19 - INFO - __main__ - Cumulative validation average loss is 12.299570322153158\n",
      "07/27/2023 18:47:20 - INFO - __main__ - Per validation step average loss is 0.02894805744290352\n",
      "07/27/2023 18:47:20 - INFO - __main__ - Cumulative validation average loss is 12.328518379596062\n",
      "07/27/2023 18:47:20 - INFO - __main__ - Per validation step average loss is 0.03608420863747597\n",
      "07/27/2023 18:47:20 - INFO - __main__ - Cumulative validation average loss is 12.364602588233538\n",
      "07/27/2023 18:47:20 - INFO - __main__ - Average validation loss for Epoch 23 is 0.15651395681308275\n",
      "07/27/2023 18:47:20 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:48:17 - INFO - __main__ - Starting epoch 24\n",
      "07/27/2023 18:48:18 - INFO - __main__ - train loss is 0.11035467684268951\n",
      "Steps:  48%|▍| 7273/15000 [1:03:28<59:07:36, 27.55s/it, lr=0.000907, step_loss=007/27/2023 18:48:18 - INFO - __main__ - train loss is 0.19743690639734268\n",
      "Steps:  48%|▍| 7274/15000 [1:03:29<41:30:15, 19.34s/it, lr=0.000907, step_loss=007/27/2023 18:48:18 - INFO - __main__ - train loss is 0.23016365244984627\n",
      "Steps:  48%|▍| 7275/15000 [1:03:29<29:10:01, 13.59s/it, lr=0.000907, step_loss=007/27/2023 18:48:19 - INFO - __main__ - train loss is 0.33958202973008156\n",
      "Steps:  49%|▍| 7276/15000 [1:03:29<20:31:46,  9.57s/it, lr=0.000908, step_loss=007/27/2023 18:48:19 - INFO - __main__ - train loss is 0.4182470478117466\n",
      "Steps:  49%|▍| 7277/15000 [1:03:29<14:29:02,  6.75s/it, lr=0.000908, step_loss=007/27/2023 18:48:19 - INFO - __main__ - train loss is 0.4294124562293291\n",
      "Steps:  49%|▍| 7278/15000 [1:03:29<10:15:09,  4.78s/it, lr=0.000908, step_loss=007/27/2023 18:48:19 - INFO - __main__ - train loss is 0.5021533984690905\n",
      "Steps:  49%|▍| 7279/15000 [1:03:29<7:17:37,  3.40s/it, lr=0.000908, step_loss=0.07/27/2023 18:48:19 - INFO - __main__ - train loss is 0.5046174437738955\n",
      "Steps:  49%|▍| 7280/15000 [1:03:30<5:13:16,  2.43s/it, lr=0.000908, step_loss=0.07/27/2023 18:48:19 - INFO - __main__ - train loss is 0.8466691882349551\n",
      "Steps:  49%|▍| 7281/15000 [1:03:30<3:46:15,  1.76s/it, lr=0.000908, step_loss=0.07/27/2023 18:48:20 - INFO - __main__ - train loss is 0.9151859343983233\n",
      "Steps:  49%|▍| 7282/15000 [1:03:30<2:45:21,  1.29s/it, lr=0.000908, step_loss=0.07/27/2023 18:48:20 - INFO - __main__ - train loss is 1.350591963622719\n",
      "Steps:  49%|▍| 7283/15000 [1:03:30<2:02:43,  1.05it/s, lr=0.000909, step_loss=0.07/27/2023 18:48:20 - INFO - __main__ - train loss is 1.3535487446933985\n",
      "Steps:  49%|▍| 7284/15000 [1:03:30<1:32:52,  1.38it/s, lr=0.000909, step_loss=0.07/27/2023 18:48:20 - INFO - __main__ - train loss is 1.4790665451437235\n",
      "Steps:  49%|▍| 7285/15000 [1:03:31<1:12:00,  1.79it/s, lr=0.000909, step_loss=0.07/27/2023 18:48:20 - INFO - __main__ - train loss is 1.4990802872925997\n",
      "Steps:  49%|▍| 7286/15000 [1:03:31<57:23,  2.24it/s, lr=0.000909, step_loss=0.0207/27/2023 18:48:21 - INFO - __main__ - train loss is 1.9755325485020876\n",
      "Steps:  49%|▍| 7287/15000 [1:03:31<47:10,  2.72it/s, lr=0.000909, step_loss=0.4707/27/2023 18:48:21 - INFO - __main__ - train loss is 1.9916626773774624\n",
      "Steps:  49%|▍| 7288/15000 [1:03:31<40:00,  3.21it/s, lr=0.000909, step_loss=0.0107/27/2023 18:48:21 - INFO - __main__ - train loss is 2.284170176833868\n",
      "Steps:  49%|▍| 7289/15000 [1:03:31<34:52,  3.69it/s, lr=0.000909, step_loss=0.2907/27/2023 18:48:21 - INFO - __main__ - train loss is 2.3898937962949276\n",
      "Steps:  49%|▍| 7290/15000 [1:03:31<31:31,  4.08it/s, lr=0.000909, step_loss=0.1007/27/2023 18:48:21 - INFO - __main__ - train loss is 2.488063495606184\n",
      "Steps:  49%|▍| 7291/15000 [1:03:32<28:57,  4.44it/s, lr=0.00091, step_loss=0.09807/27/2023 18:48:21 - INFO - __main__ - train loss is 2.5278989374637604\n",
      "Steps:  49%|▍| 7292/15000 [1:03:32<27:09,  4.73it/s, lr=0.00091, step_loss=0.03907/27/2023 18:48:22 - INFO - __main__ - train loss is 2.573193073272705\n",
      "Steps:  49%|▍| 7293/15000 [1:03:32<25:54,  4.96it/s, lr=0.00091, step_loss=0.04507/27/2023 18:48:22 - INFO - __main__ - train loss is 2.575006331782788\n",
      "Steps:  49%|▍| 7294/15000 [1:03:32<25:02,  5.13it/s, lr=0.00091, step_loss=0.00107/27/2023 18:48:22 - INFO - __main__ - train loss is 2.586775620933622\n",
      "Steps:  49%|▍| 7295/15000 [1:03:32<24:26,  5.25it/s, lr=0.00091, step_loss=0.01107/27/2023 18:48:22 - INFO - __main__ - train loss is 3.3149549565277994\n",
      "Steps:  49%|▍| 7296/15000 [1:03:33<24:01,  5.34it/s, lr=0.00091, step_loss=0.72807/27/2023 18:48:22 - INFO - __main__ - train loss is 3.4983460954390466\n",
      "Steps:  49%|▍| 7297/15000 [1:03:33<23:43,  5.41it/s, lr=0.00091, step_loss=0.18307/27/2023 18:48:23 - INFO - __main__ - train loss is 3.7601949921809137\n",
      "Steps:  49%|▍| 7298/15000 [1:03:33<23:31,  5.46it/s, lr=0.00091, step_loss=0.26207/27/2023 18:48:23 - INFO - __main__ - train loss is 3.790982903447002\n",
      "Steps:  49%|▍| 7299/15000 [1:03:33<23:22,  5.49it/s, lr=0.00091, step_loss=0.03007/27/2023 18:48:23 - INFO - __main__ - train loss is 3.800384601112455\n",
      "Steps:  49%|▍| 7300/15000 [1:03:33<23:16,  5.51it/s, lr=0.000911, step_loss=0.0007/27/2023 18:48:23 - INFO - __main__ - train loss is 4.263343801256269\n",
      "Steps:  49%|▍| 7301/15000 [1:03:33<23:21,  5.49it/s, lr=0.000911, step_loss=0.4607/27/2023 18:48:23 - INFO - __main__ - train loss is 4.697326709982008\n",
      "Steps:  49%|▍| 7302/15000 [1:03:34<23:20,  5.50it/s, lr=0.000911, step_loss=0.4307/27/2023 18:48:23 - INFO - __main__ - train loss is 4.97928993916139\n",
      "Steps:  49%|▍| 7303/15000 [1:03:34<23:23,  5.48it/s, lr=0.000911, step_loss=0.2807/27/2023 18:48:24 - INFO - __main__ - train loss is 5.181457614060491\n",
      "Steps:  49%|▍| 7304/15000 [1:03:34<23:28,  5.46it/s, lr=0.000911, step_loss=0.2007/27/2023 18:48:24 - INFO - __main__ - train loss is 5.202767958398908\n",
      "Steps:  49%|▍| 7305/15000 [1:03:34<23:23,  5.48it/s, lr=0.000911, step_loss=0.0207/27/2023 18:48:24 - INFO - __main__ - train loss is 5.209264064673334\n",
      "Steps:  49%|▍| 7306/15000 [1:03:34<23:23,  5.48it/s, lr=0.000911, step_loss=0.0007/27/2023 18:48:24 - INFO - __main__ - train loss is 5.210143287607934\n",
      "Steps:  49%|▍| 7307/15000 [1:03:35<23:28,  5.46it/s, lr=0.000911, step_loss=0.0007/27/2023 18:48:24 - INFO - __main__ - train loss is 5.218175399990287\n",
      "Steps:  49%|▍| 7308/15000 [1:03:35<23:19,  5.50it/s, lr=0.000912, step_loss=0.0007/27/2023 18:48:25 - INFO - __main__ - train loss is 5.227990867511835\n",
      "Steps:  49%|▍| 7309/15000 [1:03:35<23:13,  5.52it/s, lr=0.000912, step_loss=0.0007/27/2023 18:48:25 - INFO - __main__ - train loss is 5.269448189006653\n",
      "Steps:  49%|▍| 7310/15000 [1:03:35<23:13,  5.52it/s, lr=0.000912, step_loss=0.0407/27/2023 18:48:25 - INFO - __main__ - train loss is 5.40639194654068\n",
      "Steps:  49%|▍| 7311/15000 [1:03:35<23:14,  5.51it/s, lr=0.000912, step_loss=0.1307/27/2023 18:48:25 - INFO - __main__ - train loss is 5.41559203149518\n",
      "Steps:  49%|▍| 7312/15000 [1:03:35<23:16,  5.51it/s, lr=0.000912, step_loss=0.0007/27/2023 18:48:25 - INFO - __main__ - train loss is 5.925034182087984\n",
      "[2023-07-27 18:48:25,876] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  49%|▍| 7313/15000 [1:03:36<23:09,  5.53it/s, lr=0.000912, step_loss=0.5007/27/2023 18:48:25 - INFO - __main__ - train loss is 6.189715282933321\n",
      "Steps:  49%|▍| 7314/15000 [1:03:36<23:10,  5.53it/s, lr=0.000912, step_loss=0.2607/27/2023 18:48:26 - INFO - __main__ - train loss is 6.1939763184054755\n",
      "Steps:  49%|▍| 7315/15000 [1:03:36<23:15,  5.51it/s, lr=0.000912, step_loss=0.0007/27/2023 18:48:26 - INFO - __main__ - train loss is 6.198354426713195\n",
      "Steps:  49%|▍| 7316/15000 [1:03:36<23:16,  5.50it/s, lr=0.000913, step_loss=0.0007/27/2023 18:48:26 - INFO - __main__ - train loss is 6.204981655755546\n",
      "Steps:  49%|▍| 7317/15000 [1:03:36<23:15,  5.51it/s, lr=0.000913, step_loss=0.0007/27/2023 18:48:26 - INFO - __main__ - train loss is 6.245290064194705\n",
      "Steps:  49%|▍| 7318/15000 [1:03:37<23:17,  5.50it/s, lr=0.000913, step_loss=0.0407/27/2023 18:48:26 - INFO - __main__ - train loss is 6.2654639453976415\n",
      "Steps:  49%|▍| 7319/15000 [1:03:37<23:16,  5.50it/s, lr=0.000913, step_loss=0.0207/27/2023 18:48:27 - INFO - __main__ - train loss is 6.314051111170556\n",
      "Steps:  49%|▍| 7320/15000 [1:03:37<23:16,  5.50it/s, lr=0.000913, step_loss=0.0407/27/2023 18:48:27 - INFO - __main__ - train loss is 6.67461790604284\n",
      "Steps:  49%|▍| 7321/15000 [1:03:37<23:16,  5.50it/s, lr=0.000913, step_loss=0.3607/27/2023 18:48:27 - INFO - __main__ - train loss is 6.854471822211053\n",
      "Steps:  49%|▍| 7322/15000 [1:03:37<23:16,  5.50it/s, lr=0.000913, step_loss=0.1807/27/2023 18:48:27 - INFO - __main__ - train loss is 6.861557584197726\n",
      "Steps:  49%|▍| 7323/15000 [1:03:37<23:19,  5.49it/s, lr=0.000913, step_loss=0.0007/27/2023 18:48:27 - INFO - __main__ - train loss is 6.869244431552943\n",
      "Steps:  49%|▍| 7324/15000 [1:03:38<23:26,  5.46it/s, lr=0.000914, step_loss=0.0007/27/2023 18:48:27 - INFO - __main__ - train loss is 6.909961608645972\n",
      "Steps:  49%|▍| 7325/15000 [1:03:38<24:13,  5.28it/s, lr=0.000914, step_loss=0.0407/27/2023 18:48:28 - INFO - __main__ - train loss is 7.006297839281615\n",
      "Steps:  49%|▍| 7326/15000 [1:03:38<24:17,  5.27it/s, lr=0.000914, step_loss=0.0907/27/2023 18:48:28 - INFO - __main__ - train loss is 7.029640120861586\n",
      "Steps:  49%|▍| 7327/15000 [1:03:38<24:05,  5.31it/s, lr=0.000914, step_loss=0.0207/27/2023 18:48:28 - INFO - __main__ - train loss is 7.036297347804066\n",
      "Steps:  49%|▍| 7328/15000 [1:03:38<24:01,  5.32it/s, lr=0.000914, step_loss=0.0007/27/2023 18:48:28 - INFO - __main__ - train loss is 7.238093432446476\n",
      "Steps:  49%|▍| 7329/15000 [1:03:39<24:07,  5.30it/s, lr=0.000914, step_loss=0.2007/27/2023 18:48:28 - INFO - __main__ - train loss is 7.253396179003175\n",
      "Steps:  49%|▍| 7330/15000 [1:03:39<23:55,  5.34it/s, lr=0.000914, step_loss=0.0107/27/2023 18:48:29 - INFO - __main__ - train loss is 7.281972933036741\n",
      "Steps:  49%|▍| 7331/15000 [1:03:39<23:59,  5.33it/s, lr=0.000914, step_loss=0.0207/27/2023 18:48:29 - INFO - __main__ - train loss is 7.3776997657842\n",
      "Steps:  49%|▍| 7332/15000 [1:03:39<24:19,  5.26it/s, lr=0.000914, step_loss=0.0907/27/2023 18:48:29 - INFO - __main__ - train loss is 7.494589615089353\n",
      "Steps:  49%|▍| 7333/15000 [1:03:39<24:31,  5.21it/s, lr=0.000915, step_loss=0.1107/27/2023 18:48:29 - INFO - __main__ - train loss is 7.606436583620962\n",
      "Steps:  49%|▍| 7334/15000 [1:03:40<24:41,  5.17it/s, lr=0.000915, step_loss=0.1107/27/2023 18:48:29 - INFO - __main__ - train loss is 8.00093424640363\n",
      "Steps:  49%|▍| 7335/15000 [1:03:40<24:45,  5.16it/s, lr=0.000915, step_loss=0.3907/27/2023 18:48:30 - INFO - __main__ - train loss is 8.001951846003067\n",
      "Steps:  49%|▍| 7336/15000 [1:03:40<24:35,  5.19it/s, lr=0.000915, step_loss=0.0007/27/2023 18:48:30 - INFO - __main__ - train loss is 8.023209868639242\n",
      "Steps:  49%|▍| 7337/15000 [1:03:40<24:22,  5.24it/s, lr=0.000915, step_loss=0.0207/27/2023 18:48:30 - INFO - __main__ - train loss is 8.569058953493368\n",
      "Steps:  49%|▍| 7338/15000 [1:03:40<23:59,  5.32it/s, lr=0.000915, step_loss=0.5407/27/2023 18:48:30 - INFO - __main__ - train loss is 8.6868484604056\n",
      "Steps:  49%|▍| 7339/15000 [1:03:40<23:44,  5.38it/s, lr=0.000915, step_loss=0.1107/27/2023 18:48:30 - INFO - __main__ - train loss is 8.698759700811934\n",
      "Steps:  49%|▍| 7340/15000 [1:03:41<23:34,  5.42it/s, lr=0.000915, step_loss=0.0107/27/2023 18:48:31 - INFO - __main__ - train loss is 9.014424707449507\n",
      "Steps:  49%|▍| 7341/15000 [1:03:41<23:27,  5.44it/s, lr=0.000916, step_loss=0.3107/27/2023 18:48:31 - INFO - __main__ - train loss is 9.219427283562254\n",
      "Steps:  49%|▍| 7342/15000 [1:03:41<23:22,  5.46it/s, lr=0.000916, step_loss=0.2007/27/2023 18:48:31 - INFO - __main__ - train loss is 9.282465722120833\n",
      "Steps:  49%|▍| 7343/15000 [1:03:41<23:19,  5.47it/s, lr=0.000916, step_loss=0.0607/27/2023 18:48:31 - INFO - __main__ - train loss is 9.301892595074605\n",
      "Steps:  49%|▍| 7344/15000 [1:03:41<23:17,  5.48it/s, lr=0.000916, step_loss=0.0107/27/2023 18:48:31 - INFO - __main__ - train loss is 9.354850033007096\n",
      "Steps:  49%|▍| 7345/15000 [1:03:42<23:16,  5.48it/s, lr=0.000916, step_loss=0.0507/27/2023 18:48:31 - INFO - __main__ - train loss is 9.358141185191926\n",
      "Steps:  49%|▍| 7346/15000 [1:03:42<23:14,  5.49it/s, lr=0.000916, step_loss=0.0007/27/2023 18:48:32 - INFO - __main__ - train loss is 9.359787602617871\n",
      "Steps:  49%|▍| 7347/15000 [1:03:42<23:25,  5.44it/s, lr=0.000916, step_loss=0.0007/27/2023 18:48:32 - INFO - __main__ - train loss is 9.517945189669263\n",
      "Steps:  49%|▍| 7348/15000 [1:03:42<23:26,  5.44it/s, lr=0.000916, step_loss=0.1507/27/2023 18:48:32 - INFO - __main__ - train loss is 9.521268990065437\n",
      "Steps:  49%|▍| 7349/15000 [1:03:42<23:15,  5.48it/s, lr=0.000917, step_loss=0.0007/27/2023 18:48:32 - INFO - __main__ - train loss is 9.523638461425435\n",
      "Steps:  49%|▍| 7350/15000 [1:03:42<23:08,  5.51it/s, lr=0.000917, step_loss=0.0007/27/2023 18:48:32 - INFO - __main__ - train loss is 9.542045374109875\n",
      "Steps:  49%|▍| 7351/15000 [1:03:43<23:03,  5.53it/s, lr=0.000917, step_loss=0.0107/27/2023 18:48:33 - INFO - __main__ - train loss is 9.71528529067291\n",
      "Steps:  49%|▍| 7352/15000 [1:03:43<22:59,  5.54it/s, lr=0.000917, step_loss=0.1707/27/2023 18:48:33 - INFO - __main__ - train loss is 9.761038635566365\n",
      "Steps:  49%|▍| 7353/15000 [1:03:43<22:59,  5.54it/s, lr=0.000917, step_loss=0.0407/27/2023 18:48:33 - INFO - __main__ - train loss is 9.784886550798547\n",
      "Steps:  49%|▍| 7354/15000 [1:03:43<23:08,  5.51it/s, lr=0.000917, step_loss=0.0207/27/2023 18:48:33 - INFO - __main__ - train loss is 9.82372231100453\n",
      "Steps:  49%|▍| 7355/15000 [1:03:43<23:03,  5.53it/s, lr=0.000917, step_loss=0.0307/27/2023 18:48:33 - INFO - __main__ - train loss is 9.825471413030755\n",
      "Steps:  49%|▍| 7356/15000 [1:03:44<22:58,  5.54it/s, lr=0.000918, step_loss=0.0007/27/2023 18:48:33 - INFO - __main__ - train loss is 10.347813022031914\n",
      "Steps:  49%|▍| 7357/15000 [1:03:44<22:55,  5.56it/s, lr=0.000918, step_loss=0.5207/27/2023 18:48:34 - INFO - __main__ - train loss is 10.503838997974526\n",
      "Steps:  49%|▍| 7358/15000 [1:03:44<22:52,  5.57it/s, lr=0.000918, step_loss=0.1507/27/2023 18:48:34 - INFO - __main__ - train loss is 10.549547672912013\n",
      "Steps:  49%|▍| 7359/15000 [1:03:44<22:51,  5.57it/s, lr=0.000918, step_loss=0.0407/27/2023 18:48:34 - INFO - __main__ - train loss is 10.757087052508723\n",
      "Steps:  49%|▍| 7360/15000 [1:03:44<22:51,  5.57it/s, lr=0.000918, step_loss=0.2007/27/2023 18:48:34 - INFO - __main__ - train loss is 10.768010833009612\n",
      "Steps:  49%|▍| 7361/15000 [1:03:44<22:50,  5.57it/s, lr=0.000918, step_loss=0.0107/27/2023 18:48:34 - INFO - __main__ - train loss is 10.888097145303618\n",
      "Steps:  49%|▍| 7362/15000 [1:03:45<22:50,  5.57it/s, lr=0.000918, step_loss=0.1207/27/2023 18:48:34 - INFO - __main__ - train loss is 10.889581391762476\n",
      "Steps:  49%|▍| 7363/15000 [1:03:45<23:02,  5.53it/s, lr=0.000918, step_loss=0.0007/27/2023 18:48:35 - INFO - __main__ - train loss is 10.90291574242292\n",
      "Steps:  49%|▍| 7364/15000 [1:03:45<23:11,  5.49it/s, lr=0.000919, step_loss=0.0107/27/2023 18:48:35 - INFO - __main__ - train loss is 11.119135376240592\n",
      "Steps:  49%|▍| 7365/15000 [1:03:45<23:04,  5.51it/s, lr=0.000919, step_loss=0.2107/27/2023 18:48:35 - INFO - __main__ - train loss is 11.532414701010566\n",
      "Steps:  49%|▍| 7366/15000 [1:03:45<23:09,  5.50it/s, lr=0.000919, step_loss=0.4107/27/2023 18:48:35 - INFO - __main__ - train loss is 11.575177759106737\n",
      "Steps:  49%|▍| 7367/15000 [1:03:46<23:09,  5.50it/s, lr=0.000919, step_loss=0.0407/27/2023 18:48:35 - INFO - __main__ - train loss is 11.638013839896303\n",
      "Steps:  49%|▍| 7368/15000 [1:03:46<23:03,  5.52it/s, lr=0.000919, step_loss=0.0607/27/2023 18:48:36 - INFO - __main__ - train loss is 11.73539620655356\n",
      "Steps:  49%|▍| 7369/15000 [1:03:46<22:59,  5.53it/s, lr=0.000919, step_loss=0.0907/27/2023 18:48:36 - INFO - __main__ - train loss is 11.739259871363174\n",
      "Steps:  49%|▍| 7370/15000 [1:03:46<22:56,  5.54it/s, lr=0.000919, step_loss=0.0007/27/2023 18:48:36 - INFO - __main__ - train loss is 12.059257360815536\n",
      "Steps:  49%|▍| 7371/15000 [1:03:46<22:54,  5.55it/s, lr=0.000919, step_loss=0.3207/27/2023 18:48:36 - INFO - __main__ - train loss is 12.14961914968444\n",
      "Steps:  49%|▍| 7372/15000 [1:03:46<22:59,  5.53it/s, lr=0.000919, step_loss=0.0907/27/2023 18:48:36 - INFO - __main__ - train loss is 12.485293107747566\n",
      "Steps:  49%|▍| 7373/15000 [1:03:47<22:54,  5.55it/s, lr=0.00092, step_loss=0.33607/27/2023 18:48:36 - INFO - __main__ - train loss is 12.620317238091957\n",
      "Steps:  49%|▍| 7374/15000 [1:03:47<23:04,  5.51it/s, lr=0.00092, step_loss=0.13507/27/2023 18:48:37 - INFO - __main__ - train loss is 12.622078323445749\n",
      "Steps:  49%|▍| 7375/15000 [1:03:47<23:12,  5.48it/s, lr=0.00092, step_loss=0.00107/27/2023 18:48:37 - INFO - __main__ - train loss is 13.438615107617807\n",
      "Steps:  49%|▍| 7376/15000 [1:03:47<23:27,  5.42it/s, lr=0.00092, step_loss=0.81707/27/2023 18:48:37 - INFO - __main__ - train loss is 14.123117470822763\n",
      "Steps:  49%|▍| 7377/15000 [1:03:47<23:32,  5.40it/s, lr=0.00092, step_loss=0.68507/27/2023 18:48:37 - INFO - __main__ - train loss is 14.168454261205625\n",
      "Steps:  49%|▍| 7378/15000 [1:03:48<23:29,  5.41it/s, lr=0.00092, step_loss=0.04507/27/2023 18:48:37 - INFO - __main__ - train loss is 14.344789804599714\n",
      "Steps:  49%|▍| 7379/15000 [1:03:48<23:16,  5.46it/s, lr=0.00092, step_loss=0.17607/27/2023 18:48:38 - INFO - __main__ - train loss is 14.369285223714542\n",
      "Steps:  49%|▍| 7380/15000 [1:03:48<23:12,  5.47it/s, lr=0.00092, step_loss=0.02407/27/2023 18:48:38 - INFO - __main__ - train loss is 14.656941471330356\n",
      "Steps:  49%|▍| 7381/15000 [1:03:48<23:04,  5.50it/s, lr=0.000921, step_loss=0.2807/27/2023 18:48:38 - INFO - __main__ - train loss is 14.658239821961615\n",
      "Steps:  49%|▍| 7382/15000 [1:03:48<22:58,  5.53it/s, lr=0.000921, step_loss=0.0007/27/2023 18:48:38 - INFO - __main__ - train loss is 14.70288440870354\n",
      "Steps:  49%|▍| 7383/15000 [1:03:48<22:54,  5.54it/s, lr=0.000921, step_loss=0.0407/27/2023 18:48:38 - INFO - __main__ - train loss is 14.71245956333587\n",
      "Steps:  49%|▍| 7384/15000 [1:03:49<22:51,  5.55it/s, lr=0.000921, step_loss=0.0007/27/2023 18:48:38 - INFO - __main__ - train loss is 14.719695617968682\n",
      "Steps:  49%|▍| 7385/15000 [1:03:49<22:48,  5.56it/s, lr=0.000921, step_loss=0.0007/27/2023 18:48:39 - INFO - __main__ - train loss is 14.725110824743751\n",
      "Steps:  49%|▍| 7386/15000 [1:03:49<22:58,  5.52it/s, lr=0.000921, step_loss=0.0007/27/2023 18:48:39 - INFO - __main__ - train loss is 14.738440766523127\n",
      "Steps:  49%|▍| 7387/15000 [1:03:49<23:02,  5.51it/s, lr=0.000921, step_loss=0.0107/27/2023 18:48:39 - INFO - __main__ - train loss is 14.740265034895856\n",
      "Steps:  49%|▍| 7388/15000 [1:03:49<23:09,  5.48it/s, lr=0.000922, step_loss=0.0007/27/2023 18:48:39 - INFO - __main__ - train loss is 15.094294869166333\n",
      "Steps:  49%|▍| 7389/15000 [1:03:50<23:17,  5.45it/s, lr=0.000922, step_loss=0.3507/27/2023 18:48:39 - INFO - __main__ - train loss is 15.160501085978467\n",
      "Steps:  49%|▍| 7390/15000 [1:03:50<23:19,  5.44it/s, lr=0.000922, step_loss=0.0607/27/2023 18:48:40 - INFO - __main__ - train loss is 15.270673476916272\n",
      "Steps:  49%|▍| 7391/15000 [1:03:50<23:13,  5.46it/s, lr=0.000922, step_loss=0.1107/27/2023 18:48:40 - INFO - __main__ - train loss is 15.416847997170407\n",
      "Steps:  49%|▍| 7392/15000 [1:03:50<23:05,  5.49it/s, lr=0.000922, step_loss=0.1407/27/2023 18:48:40 - INFO - __main__ - train loss is 15.551729791623075\n",
      "Steps:  49%|▍| 7393/15000 [1:03:50<23:11,  5.47it/s, lr=0.000922, step_loss=0.1307/27/2023 18:48:40 - INFO - __main__ - train loss is 15.802510195237119\n",
      "Steps:  49%|▍| 7394/15000 [1:03:50<23:07,  5.48it/s, lr=0.000922, step_loss=0.2507/27/2023 18:48:40 - INFO - __main__ - train loss is 16.03611271904083\n",
      "Steps:  49%|▍| 7395/15000 [1:03:51<22:59,  5.51it/s, lr=0.000922, step_loss=0.2307/27/2023 18:48:40 - INFO - __main__ - train loss is 16.127602704626042\n",
      "Steps:  49%|▍| 7396/15000 [1:03:51<22:55,  5.53it/s, lr=0.000923, step_loss=0.0907/27/2023 18:48:41 - INFO - __main__ - train loss is 16.135262846772093\n",
      "Steps:  49%|▍| 7397/15000 [1:03:51<23:05,  5.49it/s, lr=0.000923, step_loss=0.0007/27/2023 18:48:41 - INFO - __main__ - train loss is 16.150458882388193\n",
      "Steps:  49%|▍| 7398/15000 [1:03:51<23:03,  5.49it/s, lr=0.000923, step_loss=0.0107/27/2023 18:48:41 - INFO - __main__ - train loss is 16.165159040887374\n",
      "Steps:  49%|▍| 7399/15000 [1:03:51<22:58,  5.51it/s, lr=0.000923, step_loss=0.0107/27/2023 18:48:41 - INFO - __main__ - train loss is 16.3549712242675\n",
      "Steps:  49%|▍| 7400/15000 [1:03:52<23:06,  5.48it/s, lr=0.000923, step_loss=0.1907/27/2023 18:48:41 - INFO - __main__ - train loss is 16.479499714274425\n",
      "Steps:  49%|▍| 7401/15000 [1:03:52<23:01,  5.50it/s, lr=0.000923, step_loss=0.1207/27/2023 18:48:42 - INFO - __main__ - train loss is 16.54894267191412\n",
      "Steps:  49%|▍| 7402/15000 [1:03:52<22:56,  5.52it/s, lr=0.000923, step_loss=0.0607/27/2023 18:48:42 - INFO - __main__ - train loss is 16.5666699463618\n",
      "Steps:  49%|▍| 7403/15000 [1:03:52<23:01,  5.50it/s, lr=0.000923, step_loss=0.0107/27/2023 18:48:42 - INFO - __main__ - train loss is 16.61018268187763\n",
      "Steps:  49%|▍| 7404/15000 [1:03:52<23:08,  5.47it/s, lr=0.000924, step_loss=0.0407/27/2023 18:48:42 - INFO - __main__ - train loss is 16.70353064854862\n",
      "Steps:  49%|▍| 7405/15000 [1:03:52<23:14,  5.45it/s, lr=0.000924, step_loss=0.0907/27/2023 18:48:42 - INFO - __main__ - train loss is 16.71501304564299\n",
      "Steps:  49%|▍| 7406/15000 [1:03:53<23:05,  5.48it/s, lr=0.000924, step_loss=0.0107/27/2023 18:48:43 - INFO - __main__ - train loss is 16.716240285953972\n",
      "Steps:  49%|▍| 7407/15000 [1:03:53<22:58,  5.51it/s, lr=0.000924, step_loss=0.0007/27/2023 18:48:43 - INFO - __main__ - train loss is 17.124260007462\n",
      "Steps:  49%|▍| 7408/15000 [1:03:53<23:07,  5.47it/s, lr=0.000924, step_loss=0.4007/27/2023 18:48:43 - INFO - __main__ - train loss is 17.17713681521127\n",
      "Steps:  49%|▍| 7409/15000 [1:03:53<23:04,  5.48it/s, lr=0.000924, step_loss=0.0507/27/2023 18:48:43 - INFO - __main__ - train loss is 17.333075440546963\n",
      "Steps:  49%|▍| 7410/15000 [1:03:53<22:57,  5.51it/s, lr=0.000924, step_loss=0.1507/27/2023 18:48:43 - INFO - __main__ - train loss is 17.380003034195397\n",
      "Steps:  49%|▍| 7411/15000 [1:03:54<23:04,  5.48it/s, lr=0.000924, step_loss=0.0407/27/2023 18:48:43 - INFO - __main__ - train loss is 17.431384868046734\n",
      "Steps:  49%|▍| 7412/15000 [1:03:54<22:56,  5.51it/s, lr=0.000924, step_loss=0.0507/27/2023 18:48:44 - INFO - __main__ - train loss is 17.534118033072446\n",
      "Steps:  49%|▍| 7413/15000 [1:03:54<22:51,  5.53it/s, lr=0.000925, step_loss=0.1007/27/2023 18:48:44 - INFO - __main__ - train loss is 17.773657388112042\n",
      "Steps:  49%|▍| 7414/15000 [1:03:54<22:48,  5.54it/s, lr=0.000925, step_loss=0.2407/27/2023 18:48:44 - INFO - __main__ - train loss is 17.839257395884488\n",
      "Steps:  49%|▍| 7415/15000 [1:03:54<22:46,  5.55it/s, lr=0.000925, step_loss=0.0607/27/2023 18:48:44 - INFO - __main__ - train loss is 18.010245896002743\n",
      "Steps:  49%|▍| 7416/15000 [1:03:54<22:45,  5.55it/s, lr=0.000925, step_loss=0.1707/27/2023 18:48:44 - INFO - __main__ - train loss is 18.052154733857606\n",
      "Steps:  49%|▍| 7417/15000 [1:03:55<22:44,  5.56it/s, lr=0.000925, step_loss=0.0407/27/2023 18:48:44 - INFO - __main__ - train loss is 18.396482839307282\n",
      "Steps:  49%|▍| 7418/15000 [1:03:55<22:43,  5.56it/s, lr=0.000925, step_loss=0.3407/27/2023 18:48:45 - INFO - __main__ - train loss is 18.40192447794834\n",
      "Steps:  49%|▍| 7419/15000 [1:03:55<22:42,  5.56it/s, lr=0.000925, step_loss=0.0007/27/2023 18:48:45 - INFO - __main__ - train loss is 18.47331325901905\n",
      "Steps:  49%|▍| 7420/15000 [1:03:55<22:42,  5.56it/s, lr=0.000925, step_loss=0.0707/27/2023 18:48:45 - INFO - __main__ - train loss is 18.830842183961067\n",
      "Steps:  49%|▍| 7421/15000 [1:03:55<22:41,  5.56it/s, lr=0.000926, step_loss=0.3507/27/2023 18:48:45 - INFO - __main__ - train loss is 18.838017748726998\n",
      "Steps:  49%|▍| 7422/15000 [1:03:56<22:41,  5.56it/s, lr=0.000926, step_loss=0.0007/27/2023 18:48:45 - INFO - __main__ - train loss is 18.93294030620018\n",
      "Steps:  49%|▍| 7423/15000 [1:03:56<22:42,  5.56it/s, lr=0.000926, step_loss=0.0907/27/2023 18:48:46 - INFO - __main__ - train loss is 19.028303856088314\n",
      "Steps:  49%|▍| 7424/15000 [1:03:56<22:41,  5.57it/s, lr=0.000926, step_loss=0.0907/27/2023 18:48:46 - INFO - __main__ - train loss is 19.075698686821852\n",
      "Steps:  50%|▍| 7425/15000 [1:03:56<23:10,  5.45it/s, lr=0.000926, step_loss=0.0407/27/2023 18:48:46 - INFO - __main__ - train loss is 19.17751005111495\n",
      "Steps:  50%|▍| 7426/15000 [1:03:56<26:50,  4.70it/s, lr=0.000926, step_loss=0.1007/27/2023 18:48:46 - INFO - __main__ - train loss is 19.21455276949564\n",
      "Steps:  50%|▍| 7427/15000 [1:03:57<26:05,  4.84it/s, lr=0.000926, step_loss=0.0307/27/2023 18:48:46 - INFO - __main__ - train loss is 19.21997741429368\n",
      "Steps:  50%|▍| 7428/15000 [1:03:57<26:15,  4.81it/s, lr=0.000927, step_loss=0.0007/27/2023 18:48:47 - INFO - __main__ - train loss is 19.579570120258722\n",
      "Steps:  50%|▍| 7429/15000 [1:03:57<25:23,  4.97it/s, lr=0.000927, step_loss=0.3607/27/2023 18:48:47 - INFO - __main__ - train loss is 19.60228540567914\n",
      "Steps:  50%|▍| 7430/15000 [1:03:57<24:46,  5.09it/s, lr=0.000927, step_loss=0.0207/27/2023 18:48:47 - INFO - __main__ - train loss is 19.72263126639882\n",
      "Steps:  50%|▍| 7431/15000 [1:03:57<24:10,  5.22it/s, lr=0.000927, step_loss=0.1207/27/2023 18:48:47 - INFO - __main__ - train loss is 19.7249815222458\n",
      "Steps:  50%|▍| 7432/15000 [1:03:57<23:58,  5.26it/s, lr=0.000927, step_loss=0.0007/27/2023 18:48:47 - INFO - __main__ - train loss is 19.74863870633999\n",
      "Steps:  50%|▍| 7433/15000 [1:03:58<23:58,  5.26it/s, lr=0.000927, step_loss=0.0207/27/2023 18:48:48 - INFO - __main__ - train loss is 19.880684064759407\n",
      "Steps:  50%|▍| 7434/15000 [1:03:58<24:00,  5.25it/s, lr=0.000927, step_loss=0.1307/27/2023 18:48:48 - INFO - __main__ - train loss is 19.990898387564812\n",
      "Steps:  50%|▍| 7435/15000 [1:03:58<23:44,  5.31it/s, lr=0.000927, step_loss=0.1107/27/2023 18:48:48 - INFO - __main__ - train loss is 19.992370741500054\n",
      "Steps:  50%|▍| 7436/15000 [1:03:58<23:28,  5.37it/s, lr=0.000928, step_loss=0.0007/27/2023 18:48:48 - INFO - __main__ - train loss is 20.320245163573418\n",
      "Steps:  50%|▍| 7437/15000 [1:03:58<23:12,  5.43it/s, lr=0.000928, step_loss=0.3207/27/2023 18:48:48 - INFO - __main__ - train loss is 20.32604394858936\n",
      "Steps:  50%|▍| 7438/15000 [1:03:59<23:02,  5.47it/s, lr=0.000928, step_loss=0.0007/27/2023 18:48:48 - INFO - __main__ - train loss is 20.857121810375247\n",
      "Steps:  50%|▍| 7439/15000 [1:03:59<22:55,  5.50it/s, lr=0.000928, step_loss=0.5307/27/2023 18:48:49 - INFO - __main__ - train loss is 21.032262846885715\n",
      "Steps:  50%|▍| 7440/15000 [1:03:59<22:49,  5.52it/s, lr=0.000928, step_loss=0.1707/27/2023 18:48:49 - INFO - __main__ - train loss is 21.065979339240585\n",
      "Steps:  50%|▍| 7441/15000 [1:03:59<22:47,  5.53it/s, lr=0.000928, step_loss=0.0307/27/2023 18:48:49 - INFO - __main__ - train loss is 21.134837247489486\n",
      "Steps:  50%|▍| 7442/15000 [1:03:59<22:44,  5.54it/s, lr=0.000928, step_loss=0.0607/27/2023 18:48:49 - INFO - __main__ - train loss is 21.227973736880813\n",
      "Steps:  50%|▍| 7443/15000 [1:03:59<22:46,  5.53it/s, lr=0.000928, step_loss=0.0907/27/2023 18:48:49 - INFO - __main__ - train loss is 21.46776411688188\n",
      "Steps:  50%|▍| 7444/15000 [1:04:00<22:42,  5.54it/s, lr=0.000928, step_loss=0.2407/27/2023 18:48:50 - INFO - __main__ - train loss is 21.666333623288665\n",
      "Steps:  50%|▍| 7445/15000 [1:04:00<22:40,  5.55it/s, lr=0.000929, step_loss=0.1907/27/2023 18:48:50 - INFO - __main__ - train loss is 21.735014125762973\n",
      "Steps:  50%|▍| 7446/15000 [1:04:00<22:40,  5.55it/s, lr=0.000929, step_loss=0.0607/27/2023 18:48:50 - INFO - __main__ - train loss is 22.20459710067371\n",
      "Steps:  50%|▍| 7447/15000 [1:04:00<22:38,  5.56it/s, lr=0.000929, step_loss=0.4707/27/2023 18:48:50 - INFO - __main__ - train loss is 22.21674923883984\n",
      "Steps:  50%|▍| 7448/15000 [1:04:00<22:40,  5.55it/s, lr=0.000929, step_loss=0.0107/27/2023 18:48:50 - INFO - __main__ - train loss is 22.222212592198048\n",
      "Steps:  50%|▍| 7449/15000 [1:04:01<22:38,  5.56it/s, lr=0.000929, step_loss=0.0007/27/2023 18:48:50 - INFO - __main__ - train loss is 22.34233753575245\n",
      "Steps:  50%|▍| 7450/15000 [1:04:01<22:41,  5.55it/s, lr=0.000929, step_loss=0.1207/27/2023 18:48:51 - INFO - __main__ - train loss is 22.608515756262932\n",
      "Steps:  50%|▍| 7451/15000 [1:04:01<22:39,  5.55it/s, lr=0.000929, step_loss=0.2607/27/2023 18:48:51 - INFO - __main__ - train loss is 22.862785028351936\n",
      "Steps:  50%|▍| 7452/15000 [1:04:01<22:37,  5.56it/s, lr=0.000929, step_loss=0.2507/27/2023 18:48:51 - INFO - __main__ - train loss is 22.86944576917449\n",
      "Steps:  50%|▍| 7453/15000 [1:04:01<22:35,  5.57it/s, lr=0.00093, step_loss=0.00607/27/2023 18:48:51 - INFO - __main__ - train loss is 23.154331712110434\n",
      "Steps:  50%|▍| 7454/15000 [1:04:01<22:34,  5.57it/s, lr=0.00093, step_loss=0.28507/27/2023 18:48:51 - INFO - __main__ - train loss is 23.27604037342826\n",
      "Steps:  50%|▍| 7455/15000 [1:04:02<22:33,  5.57it/s, lr=0.00093, step_loss=0.12207/27/2023 18:48:52 - INFO - __main__ - train loss is 23.417223272903357\n",
      "Steps:  50%|▍| 7456/15000 [1:04:02<22:33,  5.57it/s, lr=0.00093, step_loss=0.14107/27/2023 18:48:52 - INFO - __main__ - train loss is 23.621471969468985\n",
      "Steps:  50%|▍| 7457/15000 [1:04:02<22:33,  5.57it/s, lr=0.00093, step_loss=0.20407/27/2023 18:48:52 - INFO - __main__ - train loss is 23.633570903970394\n",
      "Steps:  50%|▍| 7458/15000 [1:04:02<22:33,  5.57it/s, lr=0.00093, step_loss=0.01207/27/2023 18:48:52 - INFO - __main__ - train loss is 23.63892037147889\n",
      "Steps:  50%|▍| 7459/15000 [1:04:02<22:32,  5.57it/s, lr=0.00093, step_loss=0.00507/27/2023 18:48:52 - INFO - __main__ - train loss is 23.799282555526588\n",
      "Steps:  50%|▍| 7460/15000 [1:04:03<22:32,  5.57it/s, lr=0.000931, step_loss=0.1607/27/2023 18:48:52 - INFO - __main__ - train loss is 23.8008640295011\n",
      "Steps:  50%|▍| 7461/15000 [1:04:03<22:32,  5.57it/s, lr=0.000931, step_loss=0.0007/27/2023 18:48:53 - INFO - __main__ - train loss is 24.105970132921357\n",
      "Steps:  50%|▍| 7462/15000 [1:04:03<22:32,  5.57it/s, lr=0.000931, step_loss=0.3007/27/2023 18:48:53 - INFO - __main__ - train loss is 24.168510053132195\n",
      "Steps:  50%|▍| 7463/15000 [1:04:03<22:31,  5.58it/s, lr=0.000931, step_loss=0.0607/27/2023 18:48:53 - INFO - __main__ - train loss is 24.339739356015343\n",
      "Steps:  50%|▍| 7464/15000 [1:04:03<22:31,  5.58it/s, lr=0.000931, step_loss=0.1707/27/2023 18:48:53 - INFO - __main__ - train loss is 24.360155083064456\n",
      "Steps:  50%|▍| 7465/15000 [1:04:03<22:31,  5.58it/s, lr=0.000931, step_loss=0.0207/27/2023 18:48:53 - INFO - __main__ - train loss is 24.381338383827824\n",
      "Steps:  50%|▍| 7466/15000 [1:04:04<22:31,  5.57it/s, lr=0.000931, step_loss=0.0207/27/2023 18:48:53 - INFO - __main__ - train loss is 24.46354420093121\n",
      "Steps:  50%|▍| 7467/15000 [1:04:04<22:30,  5.58it/s, lr=0.000931, step_loss=0.0807/27/2023 18:48:54 - INFO - __main__ - train loss is 24.95981354621472\n",
      "Steps:  50%|▍| 7468/15000 [1:04:04<22:31,  5.57it/s, lr=0.000932, step_loss=0.4907/27/2023 18:48:54 - INFO - __main__ - train loss is 25.014689888630528\n",
      "Steps:  50%|▍| 7469/15000 [1:04:04<22:31,  5.57it/s, lr=0.000932, step_loss=0.0507/27/2023 18:48:54 - INFO - __main__ - train loss is 25.084447305474896\n",
      "Steps:  50%|▍| 7470/15000 [1:04:04<22:31,  5.57it/s, lr=0.000932, step_loss=0.0607/27/2023 18:48:54 - INFO - __main__ - train loss is 25.237632792268414\n",
      "Steps:  50%|▍| 7471/15000 [1:04:05<22:31,  5.57it/s, lr=0.000932, step_loss=0.1507/27/2023 18:48:54 - INFO - __main__ - train loss is 25.497851233754773\n",
      "Steps:  50%|▍| 7472/15000 [1:04:05<22:30,  5.57it/s, lr=0.000932, step_loss=0.2607/27/2023 18:48:55 - INFO - __main__ - train loss is 25.502645256754477\n",
      "Steps:  50%|▍| 7473/15000 [1:04:05<22:29,  5.58it/s, lr=0.000932, step_loss=0.0007/27/2023 18:48:55 - INFO - __main__ - train loss is 26.070608678099234\n",
      "Steps:  50%|▍| 7474/15000 [1:04:05<22:29,  5.58it/s, lr=0.000932, step_loss=0.5607/27/2023 18:48:55 - INFO - __main__ - train loss is 26.204816895362455\n",
      "Steps:  50%|▍| 7475/15000 [1:04:05<22:28,  5.58it/s, lr=0.000932, step_loss=0.1307/27/2023 18:48:55 - INFO - __main__ - train loss is 26.328055138525087\n",
      "Steps:  50%|▍| 7476/15000 [1:04:05<22:29,  5.58it/s, lr=0.000933, step_loss=0.1207/27/2023 18:48:55 - INFO - __main__ - train loss is 26.35272462927969\n",
      "Steps:  50%|▍| 7477/15000 [1:04:06<22:29,  5.58it/s, lr=0.000933, step_loss=0.0207/27/2023 18:48:55 - INFO - __main__ - train loss is 26.3883053761092\n",
      "Steps:  50%|▍| 7478/15000 [1:04:06<22:29,  5.57it/s, lr=0.000933, step_loss=0.0307/27/2023 18:48:56 - INFO - __main__ - train loss is 26.66014082246693\n",
      "Steps:  50%|▍| 7479/15000 [1:04:06<22:29,  5.57it/s, lr=0.000933, step_loss=0.2707/27/2023 18:48:56 - INFO - __main__ - train loss is 26.706819205370266\n",
      "Steps:  50%|▍| 7480/15000 [1:04:06<22:29,  5.57it/s, lr=0.000933, step_loss=0.0407/27/2023 18:48:56 - INFO - __main__ - train loss is 26.719766539346892\n",
      "Steps:  50%|▍| 7481/15000 [1:04:06<22:28,  5.57it/s, lr=0.000933, step_loss=0.0107/27/2023 18:48:56 - INFO - __main__ - train loss is 26.72674021619605\n",
      "Steps:  50%|▍| 7482/15000 [1:04:06<22:29,  5.57it/s, lr=0.000933, step_loss=0.0007/27/2023 18:48:56 - INFO - __main__ - train loss is 26.78916623193072\n",
      "Steps:  50%|▍| 7483/15000 [1:04:07<22:28,  5.58it/s, lr=0.000933, step_loss=0.0607/27/2023 18:48:57 - INFO - __main__ - train loss is 27.521651824295986\n",
      "Steps:  50%|▍| 7484/15000 [1:04:07<22:28,  5.57it/s, lr=0.000933, step_loss=0.7307/27/2023 18:48:57 - INFO - __main__ - train loss is 27.730561395466793\n",
      "Steps:  50%|▍| 7485/15000 [1:04:07<22:27,  5.58it/s, lr=0.000934, step_loss=0.2007/27/2023 18:48:57 - INFO - __main__ - train loss is 27.948183675587643\n",
      "Steps:  50%|▍| 7486/15000 [1:04:07<22:27,  5.58it/s, lr=0.000934, step_loss=0.2107/27/2023 18:48:57 - INFO - __main__ - train loss is 27.952364918135572\n",
      "Steps:  50%|▍| 7487/15000 [1:04:07<22:26,  5.58it/s, lr=0.000934, step_loss=0.0007/27/2023 18:48:57 - INFO - __main__ - train loss is 27.975150946818758\n",
      "Steps:  50%|▍| 7488/15000 [1:04:08<22:27,  5.57it/s, lr=0.000934, step_loss=0.0207/27/2023 18:48:57 - INFO - __main__ - train loss is 28.35353213950293\n",
      "Steps:  50%|▍| 7489/15000 [1:04:08<22:39,  5.52it/s, lr=0.000934, step_loss=0.3707/27/2023 18:48:58 - INFO - __main__ - train loss is 28.702344958030153\n",
      "Steps:  50%|▍| 7490/15000 [1:04:08<22:43,  5.51it/s, lr=0.000934, step_loss=0.3407/27/2023 18:48:58 - INFO - __main__ - train loss is 29.25204849644797\n",
      "Steps:  50%|▍| 7491/15000 [1:04:08<22:38,  5.53it/s, lr=0.000934, step_loss=0.5507/27/2023 18:48:58 - INFO - __main__ - train loss is 29.397276405536104\n",
      "Steps:  50%|▍| 7492/15000 [1:04:08<22:46,  5.49it/s, lr=0.000935, step_loss=0.1407/27/2023 18:48:58 - INFO - __main__ - train loss is 29.572493095241953\n",
      "Steps:  50%|▍| 7493/15000 [1:04:08<22:40,  5.52it/s, lr=0.000935, step_loss=0.1707/27/2023 18:48:58 - INFO - __main__ - train loss is 29.73838885530131\n",
      "Steps:  50%|▍| 7494/15000 [1:04:09<22:36,  5.53it/s, lr=0.000935, step_loss=0.1607/27/2023 18:48:59 - INFO - __main__ - train loss is 29.795415271364618\n",
      "Steps:  50%|▍| 7495/15000 [1:04:09<22:33,  5.55it/s, lr=0.000935, step_loss=0.0507/27/2023 18:48:59 - INFO - __main__ - train loss is 30.312282551371027\n",
      "Steps:  50%|▍| 7496/15000 [1:04:09<22:43,  5.50it/s, lr=0.000935, step_loss=0.5107/27/2023 18:48:59 - INFO - __main__ - train loss is 30.314595274452586\n",
      "Steps:  50%|▍| 7497/15000 [1:04:09<22:49,  5.48it/s, lr=0.000935, step_loss=0.0007/27/2023 18:48:59 - INFO - __main__ - train loss is 30.32592763361754\n",
      "Steps:  50%|▍| 7498/15000 [1:04:09<22:42,  5.51it/s, lr=0.000935, step_loss=0.0107/27/2023 18:48:59 - INFO - __main__ - train loss is 30.335318725381512\n",
      "Steps:  50%|▍| 7499/15000 [1:04:10<22:48,  5.48it/s, lr=0.000935, step_loss=0.0007/27/2023 18:48:59 - INFO - __main__ - train loss is 30.371603581879754\n",
      "Steps:  50%|▌| 7500/15000 [1:04:10<22:42,  5.50it/s, lr=0.000935, step_loss=0.0007/27/2023 18:49:00 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-7500\n",
      "07/27/2023 18:49:00 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:49:00,034] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:49:00,038] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-7500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:49:00,038] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-7500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:49:00,044] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-7500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:49:00,045] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-7500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:49:00,051] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-7500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:49:00,051] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-7500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:49:00,051] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:49:00 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-7500/pytorch_model\n",
      "07/27/2023 18:49:00 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-7500/scheduler.bin\n",
      "07/27/2023 18:49:00 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-7500/random_states_0.pkl\n",
      "07/27/2023 18:49:00 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-7500\n",
      "Steps:  50%|▌| 7500/15000 [1:04:10<22:42,  5.50it/s, lr=0.000936, step_loss=0.0307/27/2023 18:49:00 - INFO - __main__ - train loss is 30.84923008439364\n",
      "Steps:  50%|▌| 7501/15000 [1:04:10<23:29,  5.32it/s, lr=0.000936, step_loss=0.4707/27/2023 18:49:00 - INFO - __main__ - train loss is 30.851134848140646\n",
      "Steps:  50%|▌| 7502/15000 [1:04:10<23:35,  5.30it/s, lr=0.000936, step_loss=0.0007/27/2023 18:49:00 - INFO - __main__ - train loss is 31.042467337392736\n",
      "Steps:  50%|▌| 7503/15000 [1:04:10<23:38,  5.29it/s, lr=0.000936, step_loss=0.1907/27/2023 18:49:00 - INFO - __main__ - train loss is 31.090009328268934\n",
      "Steps:  50%|▌| 7504/15000 [1:04:11<23:28,  5.32it/s, lr=0.000936, step_loss=0.0407/27/2023 18:49:00 - INFO - __main__ - train loss is 31.09554593107896\n",
      "Steps:  50%|▌| 7505/15000 [1:04:11<23:10,  5.39it/s, lr=0.000936, step_loss=0.0007/27/2023 18:49:01 - INFO - __main__ - train loss is 31.107734402932692\n",
      "Steps:  50%|▌| 7506/15000 [1:04:11<22:57,  5.44it/s, lr=0.000936, step_loss=0.0107/27/2023 18:49:01 - INFO - __main__ - train loss is 31.119774391234387\n",
      "Steps:  50%|▌| 7507/15000 [1:04:11<23:00,  5.43it/s, lr=0.000936, step_loss=0.0107/27/2023 18:49:01 - INFO - __main__ - train loss is 31.136642880097497\n",
      "Steps:  50%|▌| 7508/15000 [1:04:11<22:54,  5.45it/s, lr=0.000937, step_loss=0.0107/27/2023 18:49:01 - INFO - __main__ - train loss is 31.298348433629144\n",
      "Steps:  50%|▌| 7509/15000 [1:04:11<22:46,  5.48it/s, lr=0.000937, step_loss=0.1607/27/2023 18:49:01 - INFO - __main__ - train loss is 31.34697291936027\n",
      "Steps:  50%|▌| 7510/15000 [1:04:12<22:40,  5.51it/s, lr=0.000937, step_loss=0.0407/27/2023 18:49:01 - INFO - __main__ - train loss is 31.349139815021772\n",
      "Steps:  50%|▌| 7511/15000 [1:04:12<22:35,  5.53it/s, lr=0.000937, step_loss=0.0007/27/2023 18:49:02 - INFO - __main__ - train loss is 31.422928137530107\n",
      "Steps:  50%|▌| 7512/15000 [1:04:12<22:32,  5.54it/s, lr=0.000937, step_loss=0.0707/27/2023 18:49:02 - INFO - __main__ - train loss is 31.508010906924028\n",
      "Steps:  50%|▌| 7513/15000 [1:04:12<22:30,  5.54it/s, lr=0.000937, step_loss=0.0807/27/2023 18:49:02 - INFO - __main__ - train loss is 31.526419237081427\n",
      "Steps:  50%|▌| 7514/15000 [1:04:12<22:28,  5.55it/s, lr=0.000937, step_loss=0.0107/27/2023 18:49:02 - INFO - __main__ - train loss is 31.617079123680014\n",
      "Steps:  50%|▌| 7515/15000 [1:04:13<22:27,  5.56it/s, lr=0.000937, step_loss=0.0907/27/2023 18:49:02 - INFO - __main__ - train loss is 31.63037199137034\n",
      "Steps:  50%|▌| 7516/15000 [1:04:13<22:27,  5.55it/s, lr=0.000937, step_loss=0.0107/27/2023 18:49:03 - INFO - __main__ - train loss is 31.974775615904946\n",
      "Steps:  50%|▌| 7517/15000 [1:04:13<22:27,  5.55it/s, lr=0.000938, step_loss=0.3407/27/2023 18:49:03 - INFO - __main__ - train loss is 32.25839370844187\n",
      "Steps:  50%|▌| 7518/15000 [1:04:13<22:25,  5.56it/s, lr=0.000938, step_loss=0.2807/27/2023 18:49:03 - INFO - __main__ - train loss is 32.26303849677788\n",
      "Steps:  50%|▌| 7519/15000 [1:04:13<22:24,  5.56it/s, lr=0.000938, step_loss=0.0007/27/2023 18:49:03 - INFO - __main__ - train loss is 32.265489725221414\n",
      "Steps:  50%|▌| 7520/15000 [1:04:13<22:23,  5.57it/s, lr=0.000938, step_loss=0.0007/27/2023 18:49:03 - INFO - __main__ - train loss is 32.27035910991253\n",
      "Steps:  50%|▌| 7521/15000 [1:04:14<22:23,  5.57it/s, lr=0.000938, step_loss=0.0007/27/2023 18:49:03 - INFO - __main__ - train loss is 32.64016724732937\n",
      "Steps:  50%|▌| 7522/15000 [1:04:14<22:22,  5.57it/s, lr=0.000938, step_loss=0.3707/27/2023 18:49:04 - INFO - __main__ - train loss is 32.645315459754784\n",
      "Steps:  50%|▌| 7523/15000 [1:04:14<22:21,  5.58it/s, lr=0.000938, step_loss=0.0007/27/2023 18:49:04 - INFO - __main__ - train loss is 32.6499260601704\n",
      "Steps:  50%|▌| 7524/15000 [1:04:14<22:20,  5.58it/s, lr=0.000938, step_loss=0.0007/27/2023 18:49:04 - INFO - __main__ - train loss is 32.73153417679714\n",
      "Steps:  50%|▌| 7525/15000 [1:04:14<22:21,  5.57it/s, lr=0.000939, step_loss=0.0807/27/2023 18:49:04 - INFO - __main__ - train loss is 32.76468476775335\n",
      "Steps:  50%|▌| 7526/15000 [1:04:14<22:22,  5.57it/s, lr=0.000939, step_loss=0.0307/27/2023 18:49:04 - INFO - __main__ - train loss is 32.76708324748324\n",
      "Steps:  50%|▌| 7527/15000 [1:04:15<22:22,  5.57it/s, lr=0.000939, step_loss=0.0007/27/2023 18:49:05 - INFO - __main__ - train loss is 32.7921310060774\n",
      "Steps:  50%|▌| 7528/15000 [1:04:15<22:22,  5.57it/s, lr=0.000939, step_loss=0.0207/27/2023 18:49:05 - INFO - __main__ - train loss is 32.98850905831205\n",
      "Steps:  50%|▌| 7529/15000 [1:04:15<22:26,  5.55it/s, lr=0.000939, step_loss=0.1907/27/2023 18:49:05 - INFO - __main__ - train loss is 33.10533483262407\n",
      "Steps:  50%|▌| 7530/15000 [1:04:15<22:29,  5.54it/s, lr=0.000939, step_loss=0.1107/27/2023 18:49:05 - INFO - __main__ - train loss is 33.50195850367891\n",
      "Steps:  50%|▌| 7531/15000 [1:04:15<22:26,  5.55it/s, lr=0.000939, step_loss=0.3907/27/2023 18:49:05 - INFO - __main__ - train loss is 33.6968742304598\n",
      "Steps:  50%|▌| 7532/15000 [1:04:16<22:29,  5.53it/s, lr=0.00094, step_loss=0.19507/27/2023 18:49:05 - INFO - __main__ - train loss is 33.72660881961929\n",
      "Steps:  50%|▌| 7533/15000 [1:04:16<22:32,  5.52it/s, lr=0.00094, step_loss=0.02907/27/2023 18:49:06 - INFO - __main__ - train loss is 33.94107995118247\n",
      "Steps:  50%|▌| 7534/15000 [1:04:16<22:29,  5.53it/s, lr=0.00094, step_loss=0.21407/27/2023 18:49:06 - INFO - __main__ - train loss is 33.97358757565962\n",
      "Steps:  50%|▌| 7535/15000 [1:04:16<22:30,  5.53it/s, lr=0.00094, step_loss=0.03207/27/2023 18:49:06 - INFO - __main__ - train loss is 33.978308665857185\n",
      "Steps:  50%|▌| 7536/15000 [1:04:16<22:28,  5.53it/s, lr=0.00094, step_loss=0.00407/27/2023 18:49:06 - INFO - __main__ - train loss is 33.98474968300434\n",
      "Steps:  50%|▌| 7537/15000 [1:04:16<22:30,  5.53it/s, lr=0.00094, step_loss=0.00607/27/2023 18:49:06 - INFO - __main__ - train loss is 34.03841748909326\n",
      "Steps:  50%|▌| 7538/15000 [1:04:17<22:27,  5.54it/s, lr=0.00094, step_loss=0.05307/27/2023 18:49:07 - INFO - __main__ - train loss is 34.08869978861185\n",
      "Steps:  50%|▌| 7539/15000 [1:04:17<22:25,  5.55it/s, lr=0.00094, step_loss=0.05007/27/2023 18:49:07 - INFO - __main__ - train loss is 34.36286977009149\n",
      "Steps:  50%|▌| 7540/15000 [1:04:17<22:24,  5.55it/s, lr=0.000941, step_loss=0.2707/27/2023 18:49:07 - INFO - __main__ - train loss is 35.13842770532938\n",
      "Steps:  50%|▌| 7541/15000 [1:04:17<22:23,  5.55it/s, lr=0.000941, step_loss=0.7707/27/2023 18:49:07 - INFO - __main__ - train loss is 35.44258788303705\n",
      "Steps:  50%|▌| 7542/15000 [1:04:17<22:23,  5.55it/s, lr=0.000941, step_loss=0.3007/27/2023 18:49:07 - INFO - __main__ - train loss is 35.92487835959764\n",
      "Steps:  50%|▌| 7543/15000 [1:04:18<22:22,  5.56it/s, lr=0.000941, step_loss=0.4807/27/2023 18:49:07 - INFO - __main__ - train loss is 36.34910103754373\n",
      "Steps:  50%|▌| 7544/15000 [1:04:18<22:24,  5.54it/s, lr=0.000941, step_loss=0.4207/27/2023 18:49:08 - INFO - __main__ - train loss is 36.56330648140283\n",
      "Steps:  50%|▌| 7545/15000 [1:04:18<22:22,  5.55it/s, lr=0.000941, step_loss=0.2107/27/2023 18:49:08 - INFO - __main__ - train loss is 36.57148641423555\n",
      "Steps:  50%|▌| 7546/15000 [1:04:18<22:21,  5.56it/s, lr=0.000941, step_loss=0.0007/27/2023 18:49:08 - INFO - __main__ - train loss is 36.82375165895792\n",
      "Steps:  50%|▌| 7547/15000 [1:04:18<22:20,  5.56it/s, lr=0.000941, step_loss=0.2507/27/2023 18:49:08 - INFO - __main__ - train loss is 36.865391221654136\n",
      "Steps:  50%|▌| 7548/15000 [1:04:18<22:18,  5.57it/s, lr=0.000942, step_loss=0.0407/27/2023 18:49:08 - INFO - __main__ - train loss is 37.04978288413258\n",
      "Steps:  50%|▌| 7549/15000 [1:04:19<22:17,  5.57it/s, lr=0.000942, step_loss=0.1807/27/2023 18:49:08 - INFO - __main__ - train loss is 37.05831451230915\n",
      "Steps:  50%|▌| 7550/15000 [1:04:19<22:17,  5.57it/s, lr=0.000942, step_loss=0.0007/27/2023 18:49:09 - INFO - __main__ - train loss is 37.065163896244485\n",
      "Steps:  50%|▌| 7551/15000 [1:04:19<22:17,  5.57it/s, lr=0.000942, step_loss=0.0007/27/2023 18:49:09 - INFO - __main__ - train loss is 37.319366828363854\n",
      "Steps:  50%|▌| 7552/15000 [1:04:19<22:17,  5.57it/s, lr=0.000942, step_loss=0.2507/27/2023 18:49:09 - INFO - __main__ - train loss is 37.925334469240624\n",
      "Steps:  50%|▌| 7553/15000 [1:04:19<22:16,  5.57it/s, lr=0.000942, step_loss=0.6007/27/2023 18:49:09 - INFO - __main__ - train loss is 37.927808811247814\n",
      "Steps:  50%|▌| 7554/15000 [1:04:20<22:16,  5.57it/s, lr=0.000942, step_loss=0.0007/27/2023 18:49:09 - INFO - __main__ - train loss is 37.96235788363265\n",
      "Steps:  50%|▌| 7555/15000 [1:04:20<22:15,  5.57it/s, lr=0.000942, step_loss=0.0307/27/2023 18:49:10 - INFO - __main__ - train loss is 38.055397642136086\n",
      "Steps:  50%|▌| 7556/15000 [1:04:20<22:16,  5.57it/s, lr=0.000942, step_loss=0.0907/27/2023 18:49:10 - INFO - __main__ - train loss is 38.05830785195576\n",
      "Steps:  50%|▌| 7557/15000 [1:04:20<22:16,  5.57it/s, lr=0.000943, step_loss=0.0007/27/2023 18:49:10 - INFO - __main__ - train loss is 38.112608979747165\n",
      "Steps:  50%|▌| 7558/15000 [1:04:20<22:19,  5.55it/s, lr=0.000943, step_loss=0.0507/27/2023 18:49:10 - INFO - __main__ - train loss is 38.124640520021785\n",
      "Steps:  50%|▌| 7559/15000 [1:04:20<22:28,  5.52it/s, lr=0.000943, step_loss=0.0107/27/2023 18:49:10 - INFO - __main__ - train loss is 38.36523921351181\n",
      "Steps:  50%|▌| 7560/15000 [1:04:21<22:23,  5.54it/s, lr=0.000943, step_loss=0.2407/27/2023 18:49:10 - INFO - __main__ - train loss is 38.457460995123256\n",
      "Steps:  50%|▌| 7561/15000 [1:04:21<22:19,  5.56it/s, lr=0.000943, step_loss=0.0907/27/2023 18:49:11 - INFO - __main__ - train loss is 38.60492364625679\n",
      "Steps:  50%|▌| 7562/15000 [1:04:21<22:16,  5.57it/s, lr=0.000943, step_loss=0.1407/27/2023 18:49:11 - INFO - __main__ - train loss is 38.64931728999363\n",
      "Steps:  50%|▌| 7563/15000 [1:04:21<22:14,  5.57it/s, lr=0.000943, step_loss=0.0407/27/2023 18:49:11 - INFO - __main__ - train loss is 38.66426833282458\n",
      "Steps:  50%|▌| 7564/15000 [1:04:21<22:13,  5.58it/s, lr=0.000944, step_loss=0.0107/27/2023 18:49:11 - INFO - __main__ - train loss is 38.81214154075133\n",
      "Steps:  50%|▌| 7565/15000 [1:04:22<22:13,  5.57it/s, lr=0.000944, step_loss=0.1407/27/2023 18:49:11 - INFO - __main__ - train loss is 38.85276030312525\n",
      "Steps:  50%|▌| 7566/15000 [1:04:22<22:13,  5.57it/s, lr=0.000944, step_loss=0.0407/27/2023 18:49:12 - INFO - __main__ - train loss is 38.91525304253446\n",
      "Steps:  50%|▌| 7567/15000 [1:04:22<22:22,  5.54it/s, lr=0.000944, step_loss=0.0607/27/2023 18:49:12 - INFO - __main__ - train loss is 39.62091755802976\n",
      "Steps:  50%|▌| 7568/15000 [1:04:22<22:25,  5.53it/s, lr=0.000944, step_loss=0.7007/27/2023 18:49:12 - INFO - __main__ - train loss is 39.639326419041026\n",
      "Steps:  50%|▌| 7569/15000 [1:04:22<22:28,  5.51it/s, lr=0.000944, step_loss=0.0107/27/2023 18:49:12 - INFO - __main__ - train loss is 39.9304019169067\n",
      "Steps:  50%|▌| 7570/15000 [1:04:22<22:31,  5.50it/s, lr=0.000944, step_loss=0.2907/27/2023 18:49:12 - INFO - __main__ - train loss is 40.04336966882693\n",
      "Steps:  50%|▌| 7571/15000 [1:04:23<22:37,  5.47it/s, lr=0.000944, step_loss=0.1107/27/2023 18:49:12 - INFO - __main__ - train loss is 40.32744802843081\n",
      "Steps:  50%|▌| 7572/15000 [1:04:23<22:31,  5.50it/s, lr=0.000945, step_loss=0.2807/27/2023 18:49:13 - INFO - __main__ - train loss is 40.35791561874794\n",
      "Steps:  50%|▌| 7573/15000 [1:04:23<22:23,  5.53it/s, lr=0.000945, step_loss=0.0307/27/2023 18:49:13 - INFO - __main__ - train loss is 40.85918227705406\n",
      "Steps:  50%|▌| 7574/15000 [1:04:23<22:19,  5.55it/s, lr=0.000945, step_loss=0.5007/27/2023 18:49:13 - INFO - __main__ - train loss is 41.67334941896843\n",
      "Steps:  50%|▌| 7575/15000 [1:04:24<31:01,  3.99it/s, lr=0.000945, step_loss=0.8107/27/2023 18:49:14 - INFO - __main__ - Per validation step average loss is 0.003996433690190315\n",
      "07/27/2023 18:49:14 - INFO - __main__ - Cumulative validation average loss is 0.003996433690190315\n",
      "07/27/2023 18:49:15 - INFO - __main__ - Per validation step average loss is 0.19977474212646484\n",
      "07/27/2023 18:49:15 - INFO - __main__ - Cumulative validation average loss is 0.20377117581665516\n",
      "07/27/2023 18:49:15 - INFO - __main__ - Per validation step average loss is 0.001486556837335229\n",
      "07/27/2023 18:49:15 - INFO - __main__ - Cumulative validation average loss is 0.2052577326539904\n",
      "07/27/2023 18:49:16 - INFO - __main__ - Per validation step average loss is 0.07559234648942947\n",
      "07/27/2023 18:49:16 - INFO - __main__ - Cumulative validation average loss is 0.28085007914341986\n",
      "07/27/2023 18:49:16 - INFO - __main__ - Per validation step average loss is 0.24120604991912842\n",
      "07/27/2023 18:49:16 - INFO - __main__ - Cumulative validation average loss is 0.5220561290625483\n",
      "07/27/2023 18:49:16 - INFO - __main__ - Per validation step average loss is 0.007532667368650436\n",
      "07/27/2023 18:49:16 - INFO - __main__ - Cumulative validation average loss is 0.5295887964311987\n",
      "07/27/2023 18:49:17 - INFO - __main__ - Per validation step average loss is 0.008564481511712074\n",
      "07/27/2023 18:49:17 - INFO - __main__ - Cumulative validation average loss is 0.5381532779429108\n",
      "07/27/2023 18:49:17 - INFO - __main__ - Per validation step average loss is 0.1158154159784317\n",
      "07/27/2023 18:49:17 - INFO - __main__ - Cumulative validation average loss is 0.6539686939213425\n",
      "07/27/2023 18:49:18 - INFO - __main__ - Per validation step average loss is 0.0038938061334192753\n",
      "07/27/2023 18:49:18 - INFO - __main__ - Cumulative validation average loss is 0.6578625000547618\n",
      "07/27/2023 18:49:18 - INFO - __main__ - Per validation step average loss is 0.12773114442825317\n",
      "07/27/2023 18:49:18 - INFO - __main__ - Cumulative validation average loss is 0.7855936444830149\n",
      "07/27/2023 18:49:18 - INFO - __main__ - Per validation step average loss is 0.0046804966405034065\n",
      "07/27/2023 18:49:18 - INFO - __main__ - Cumulative validation average loss is 0.7902741411235183\n",
      "07/27/2023 18:49:19 - INFO - __main__ - Per validation step average loss is 0.06473622471094131\n",
      "07/27/2023 18:49:19 - INFO - __main__ - Cumulative validation average loss is 0.8550103658344597\n",
      "07/27/2023 18:49:19 - INFO - __main__ - Per validation step average loss is 0.0020412204321473837\n",
      "07/27/2023 18:49:19 - INFO - __main__ - Cumulative validation average loss is 0.857051586266607\n",
      "07/27/2023 18:49:20 - INFO - __main__ - Per validation step average loss is 0.4712637960910797\n",
      "07/27/2023 18:49:20 - INFO - __main__ - Cumulative validation average loss is 1.3283153823576868\n",
      "07/27/2023 18:49:20 - INFO - __main__ - Per validation step average loss is 0.030505727976560593\n",
      "07/27/2023 18:49:20 - INFO - __main__ - Cumulative validation average loss is 1.3588211103342474\n",
      "07/27/2023 18:49:21 - INFO - __main__ - Per validation step average loss is 0.02092742547392845\n",
      "07/27/2023 18:49:21 - INFO - __main__ - Cumulative validation average loss is 1.3797485358081758\n",
      "07/27/2023 18:49:21 - INFO - __main__ - Per validation step average loss is 0.14032915234565735\n",
      "07/27/2023 18:49:21 - INFO - __main__ - Cumulative validation average loss is 1.5200776881538332\n",
      "07/27/2023 18:49:21 - INFO - __main__ - Per validation step average loss is 0.3782332241535187\n",
      "07/27/2023 18:49:21 - INFO - __main__ - Cumulative validation average loss is 1.8983109123073518\n",
      "07/27/2023 18:49:22 - INFO - __main__ - Per validation step average loss is 0.02980598248541355\n",
      "07/27/2023 18:49:22 - INFO - __main__ - Cumulative validation average loss is 1.9281168947927654\n",
      "07/27/2023 18:49:22 - INFO - __main__ - Per validation step average loss is 0.0534985288977623\n",
      "07/27/2023 18:49:22 - INFO - __main__ - Cumulative validation average loss is 1.9816154236905277\n",
      "07/27/2023 18:49:23 - INFO - __main__ - Per validation step average loss is 0.00550367496907711\n",
      "07/27/2023 18:49:23 - INFO - __main__ - Cumulative validation average loss is 1.9871190986596048\n",
      "07/27/2023 18:49:23 - INFO - __main__ - Per validation step average loss is 0.0016456627054139972\n",
      "07/27/2023 18:49:23 - INFO - __main__ - Cumulative validation average loss is 1.9887647613650188\n",
      "07/27/2023 18:49:23 - INFO - __main__ - Per validation step average loss is 0.1122780591249466\n",
      "07/27/2023 18:49:23 - INFO - __main__ - Cumulative validation average loss is 2.1010428204899654\n",
      "07/27/2023 18:49:24 - INFO - __main__ - Per validation step average loss is 0.07596807181835175\n",
      "07/27/2023 18:49:24 - INFO - __main__ - Cumulative validation average loss is 2.177010892308317\n",
      "07/27/2023 18:49:24 - INFO - __main__ - Per validation step average loss is 0.02071094699203968\n",
      "07/27/2023 18:49:24 - INFO - __main__ - Cumulative validation average loss is 2.197721839300357\n",
      "07/27/2023 18:49:25 - INFO - __main__ - Per validation step average loss is 0.29441142082214355\n",
      "07/27/2023 18:49:25 - INFO - __main__ - Cumulative validation average loss is 2.4921332601225004\n",
      "07/27/2023 18:49:25 - INFO - __main__ - Per validation step average loss is 0.122515007853508\n",
      "07/27/2023 18:49:25 - INFO - __main__ - Cumulative validation average loss is 2.6146482679760084\n",
      "07/27/2023 18:49:26 - INFO - __main__ - Per validation step average loss is 0.8356574177742004\n",
      "07/27/2023 18:49:26 - INFO - __main__ - Cumulative validation average loss is 3.450305685750209\n",
      "07/27/2023 18:49:26 - INFO - __main__ - Per validation step average loss is 0.3437908887863159\n",
      "07/27/2023 18:49:26 - INFO - __main__ - Cumulative validation average loss is 3.7940965745365247\n",
      "07/27/2023 18:49:26 - INFO - __main__ - Per validation step average loss is 0.01644572615623474\n",
      "07/27/2023 18:49:26 - INFO - __main__ - Cumulative validation average loss is 3.8105423006927595\n",
      "07/27/2023 18:49:27 - INFO - __main__ - Per validation step average loss is 0.0369550846517086\n",
      "07/27/2023 18:49:27 - INFO - __main__ - Cumulative validation average loss is 3.847497385344468\n",
      "07/27/2023 18:49:27 - INFO - __main__ - Per validation step average loss is 0.010552505031228065\n",
      "07/27/2023 18:49:27 - INFO - __main__ - Cumulative validation average loss is 3.858049890375696\n",
      "07/27/2023 18:49:28 - INFO - __main__ - Per validation step average loss is 0.40777260065078735\n",
      "07/27/2023 18:49:28 - INFO - __main__ - Cumulative validation average loss is 4.2658224910264835\n",
      "07/27/2023 18:49:28 - INFO - __main__ - Per validation step average loss is 0.7821369171142578\n",
      "07/27/2023 18:49:28 - INFO - __main__ - Cumulative validation average loss is 5.047959408140741\n",
      "07/27/2023 18:49:28 - INFO - __main__ - Per validation step average loss is 0.11394774168729782\n",
      "07/27/2023 18:49:28 - INFO - __main__ - Cumulative validation average loss is 5.161907149828039\n",
      "07/27/2023 18:49:29 - INFO - __main__ - Per validation step average loss is 0.005229894071817398\n",
      "07/27/2023 18:49:29 - INFO - __main__ - Cumulative validation average loss is 5.1671370438998565\n",
      "07/27/2023 18:49:29 - INFO - __main__ - Per validation step average loss is 0.009738919325172901\n",
      "07/27/2023 18:49:29 - INFO - __main__ - Cumulative validation average loss is 5.176875963225029\n",
      "07/27/2023 18:49:30 - INFO - __main__ - Per validation step average loss is 0.005753181874752045\n",
      "07/27/2023 18:49:30 - INFO - __main__ - Cumulative validation average loss is 5.1826291450997815\n",
      "07/27/2023 18:49:30 - INFO - __main__ - Per validation step average loss is 0.18025442957878113\n",
      "07/27/2023 18:49:30 - INFO - __main__ - Cumulative validation average loss is 5.362883574678563\n",
      "07/27/2023 18:49:31 - INFO - __main__ - Per validation step average loss is 0.011827298440039158\n",
      "07/27/2023 18:49:31 - INFO - __main__ - Cumulative validation average loss is 5.374710873118602\n",
      "07/27/2023 18:49:31 - INFO - __main__ - Per validation step average loss is 0.08503338694572449\n",
      "07/27/2023 18:49:31 - INFO - __main__ - Cumulative validation average loss is 5.459744260064326\n",
      "07/27/2023 18:49:31 - INFO - __main__ - Per validation step average loss is 0.002330187940970063\n",
      "07/27/2023 18:49:31 - INFO - __main__ - Cumulative validation average loss is 5.462074448005296\n",
      "07/27/2023 18:49:32 - INFO - __main__ - Per validation step average loss is 0.11249122768640518\n",
      "07/27/2023 18:49:32 - INFO - __main__ - Cumulative validation average loss is 5.5745656756917015\n",
      "07/27/2023 18:49:32 - INFO - __main__ - Per validation step average loss is 0.7571815252304077\n",
      "07/27/2023 18:49:32 - INFO - __main__ - Cumulative validation average loss is 6.331747200922109\n",
      "07/27/2023 18:49:33 - INFO - __main__ - Per validation step average loss is 0.07029782235622406\n",
      "07/27/2023 18:49:33 - INFO - __main__ - Cumulative validation average loss is 6.402045023278333\n",
      "07/27/2023 18:49:33 - INFO - __main__ - Per validation step average loss is 0.020037153735756874\n",
      "07/27/2023 18:49:33 - INFO - __main__ - Cumulative validation average loss is 6.42208217701409\n",
      "07/27/2023 18:49:34 - INFO - __main__ - Per validation step average loss is 0.4052623510360718\n",
      "07/27/2023 18:49:34 - INFO - __main__ - Cumulative validation average loss is 6.827344528050162\n",
      "07/27/2023 18:49:34 - INFO - __main__ - Per validation step average loss is 0.29032832384109497\n",
      "07/27/2023 18:49:34 - INFO - __main__ - Cumulative validation average loss is 7.117672851891257\n",
      "07/27/2023 18:49:34 - INFO - __main__ - Per validation step average loss is 0.0953352302312851\n",
      "07/27/2023 18:49:34 - INFO - __main__ - Cumulative validation average loss is 7.213008082122542\n",
      "07/27/2023 18:49:35 - INFO - __main__ - Per validation step average loss is 0.437774658203125\n",
      "07/27/2023 18:49:35 - INFO - __main__ - Cumulative validation average loss is 7.650782740325667\n",
      "07/27/2023 18:49:35 - INFO - __main__ - Per validation step average loss is 0.04265817627310753\n",
      "07/27/2023 18:49:35 - INFO - __main__ - Cumulative validation average loss is 7.6934409165987745\n",
      "07/27/2023 18:49:36 - INFO - __main__ - Per validation step average loss is 0.07128507643938065\n",
      "07/27/2023 18:49:36 - INFO - __main__ - Cumulative validation average loss is 7.764725993038155\n",
      "07/27/2023 18:49:36 - INFO - __main__ - Per validation step average loss is 0.31782451272010803\n",
      "07/27/2023 18:49:36 - INFO - __main__ - Cumulative validation average loss is 8.082550505758263\n",
      "07/27/2023 18:49:37 - INFO - __main__ - Per validation step average loss is 0.0025311429053545\n",
      "07/27/2023 18:49:37 - INFO - __main__ - Cumulative validation average loss is 8.085081648663618\n",
      "07/27/2023 18:49:37 - INFO - __main__ - Per validation step average loss is 0.15677812695503235\n",
      "07/27/2023 18:49:37 - INFO - __main__ - Cumulative validation average loss is 8.24185977561865\n",
      "07/27/2023 18:49:37 - INFO - __main__ - Per validation step average loss is 0.3374454975128174\n",
      "07/27/2023 18:49:37 - INFO - __main__ - Cumulative validation average loss is 8.579305273131467\n",
      "07/27/2023 18:49:38 - INFO - __main__ - Per validation step average loss is 0.0026073455810546875\n",
      "07/27/2023 18:49:38 - INFO - __main__ - Cumulative validation average loss is 8.581912618712522\n",
      "07/27/2023 18:49:38 - INFO - __main__ - Per validation step average loss is 0.16752079129219055\n",
      "07/27/2023 18:49:38 - INFO - __main__ - Cumulative validation average loss is 8.749433410004713\n",
      "07/27/2023 18:49:39 - INFO - __main__ - Per validation step average loss is 0.004221203736960888\n",
      "07/27/2023 18:49:39 - INFO - __main__ - Cumulative validation average loss is 8.753654613741674\n",
      "07/27/2023 18:49:39 - INFO - __main__ - Per validation step average loss is 0.2324197143316269\n",
      "07/27/2023 18:49:39 - INFO - __main__ - Cumulative validation average loss is 8.9860743280733\n",
      "07/27/2023 18:49:39 - INFO - __main__ - Per validation step average loss is 0.19292429089546204\n",
      "07/27/2023 18:49:39 - INFO - __main__ - Cumulative validation average loss is 9.178998618968762\n",
      "07/27/2023 18:49:40 - INFO - __main__ - Per validation step average loss is 0.5890759825706482\n",
      "07/27/2023 18:49:40 - INFO - __main__ - Cumulative validation average loss is 9.76807460153941\n",
      "07/27/2023 18:49:40 - INFO - __main__ - Per validation step average loss is 0.0025252168998122215\n",
      "07/27/2023 18:49:40 - INFO - __main__ - Cumulative validation average loss is 9.770599818439223\n",
      "07/27/2023 18:49:41 - INFO - __main__ - Per validation step average loss is 0.09684985131025314\n",
      "07/27/2023 18:49:41 - INFO - __main__ - Cumulative validation average loss is 9.867449669749476\n",
      "07/27/2023 18:49:41 - INFO - __main__ - Per validation step average loss is 0.0017599654383957386\n",
      "07/27/2023 18:49:41 - INFO - __main__ - Cumulative validation average loss is 9.869209635187872\n",
      "07/27/2023 18:49:42 - INFO - __main__ - Per validation step average loss is 0.13696256279945374\n",
      "07/27/2023 18:49:42 - INFO - __main__ - Cumulative validation average loss is 10.006172197987325\n",
      "07/27/2023 18:49:42 - INFO - __main__ - Per validation step average loss is 0.05986475944519043\n",
      "07/27/2023 18:49:42 - INFO - __main__ - Cumulative validation average loss is 10.066036957432516\n",
      "07/27/2023 18:49:42 - INFO - __main__ - Per validation step average loss is 0.003271876834332943\n",
      "07/27/2023 18:49:42 - INFO - __main__ - Cumulative validation average loss is 10.069308834266849\n",
      "07/27/2023 18:49:43 - INFO - __main__ - Per validation step average loss is 0.48199033737182617\n",
      "07/27/2023 18:49:43 - INFO - __main__ - Cumulative validation average loss is 10.551299171638675\n",
      "07/27/2023 18:49:43 - INFO - __main__ - Per validation step average loss is 0.28420037031173706\n",
      "07/27/2023 18:49:43 - INFO - __main__ - Cumulative validation average loss is 10.835499541950412\n",
      "07/27/2023 18:49:44 - INFO - __main__ - Per validation step average loss is 0.005657698027789593\n",
      "07/27/2023 18:49:44 - INFO - __main__ - Cumulative validation average loss is 10.841157239978202\n",
      "07/27/2023 18:49:44 - INFO - __main__ - Per validation step average loss is 0.01289946399629116\n",
      "07/27/2023 18:49:44 - INFO - __main__ - Cumulative validation average loss is 10.854056703974493\n",
      "07/27/2023 18:49:44 - INFO - __main__ - Per validation step average loss is 0.023387402296066284\n",
      "07/27/2023 18:49:44 - INFO - __main__ - Cumulative validation average loss is 10.87744410627056\n",
      "07/27/2023 18:49:45 - INFO - __main__ - Per validation step average loss is 0.2175932675600052\n",
      "07/27/2023 18:49:45 - INFO - __main__ - Cumulative validation average loss is 11.095037373830564\n",
      "07/27/2023 18:49:45 - INFO - __main__ - Per validation step average loss is 0.005300511140376329\n",
      "07/27/2023 18:49:45 - INFO - __main__ - Cumulative validation average loss is 11.10033788497094\n",
      "07/27/2023 18:49:46 - INFO - __main__ - Per validation step average loss is 0.0029995874501764774\n",
      "07/27/2023 18:49:46 - INFO - __main__ - Cumulative validation average loss is 11.103337472421117\n",
      "07/27/2023 18:49:46 - INFO - __main__ - Per validation step average loss is 0.006706933490931988\n",
      "07/27/2023 18:49:46 - INFO - __main__ - Cumulative validation average loss is 11.11004440591205\n",
      "07/27/2023 18:49:47 - INFO - __main__ - Per validation step average loss is 0.6750034093856812\n",
      "07/27/2023 18:49:47 - INFO - __main__ - Cumulative validation average loss is 11.78504781529773\n",
      "07/27/2023 18:49:47 - INFO - __main__ - Per validation step average loss is 0.003576581832021475\n",
      "07/27/2023 18:49:47 - INFO - __main__ - Cumulative validation average loss is 11.788624397129752\n",
      "07/27/2023 18:49:47 - INFO - __main__ - Average validation loss for Epoch 24 is 0.14922309363455383\n",
      "07/27/2023 18:49:47 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 18:50:44 - INFO - __main__ - Starting epoch 25\n",
      "07/27/2023 18:50:45 - INFO - __main__ - train loss is 0.002367490204051137\n",
      "Steps:  51%|▌| 7576/15000 [1:05:55<57:04:09, 27.67s/it, lr=0.000945, step_loss=007/27/2023 18:50:45 - INFO - __main__ - train loss is 0.08331538108177483\n",
      "Steps:  51%|▌| 7577/15000 [1:05:55<40:03:25, 19.43s/it, lr=0.000945, step_loss=007/27/2023 18:50:45 - INFO - __main__ - train loss is 0.1098393548745662\n",
      "Steps:  51%|▌| 7578/15000 [1:05:56<28:08:48, 13.65s/it, lr=0.000945, step_loss=007/27/2023 18:50:45 - INFO - __main__ - train loss is 0.2393760581035167\n",
      "Steps:  51%|▌| 7579/15000 [1:05:56<19:48:42,  9.61s/it, lr=0.000945, step_loss=007/27/2023 18:50:46 - INFO - __main__ - train loss is 0.4073786784429103\n",
      "Steps:  51%|▌| 7580/15000 [1:05:56<13:58:36,  6.78s/it, lr=0.000946, step_loss=007/27/2023 18:50:46 - INFO - __main__ - train loss is 0.5256950978655368\n",
      "Steps:  51%|▌| 7581/15000 [1:05:56<9:53:48,  4.80s/it, lr=0.000946, step_loss=0.07/27/2023 18:50:46 - INFO - __main__ - train loss is 0.5482022960204631\n",
      "Steps:  51%|▌| 7582/15000 [1:05:56<7:02:20,  3.42s/it, lr=0.000946, step_loss=0.07/27/2023 18:50:46 - INFO - __main__ - train loss is 0.6483711723703891\n",
      "Steps:  51%|▌| 7583/15000 [1:05:56<5:02:19,  2.45s/it, lr=0.000946, step_loss=0.07/27/2023 18:50:46 - INFO - __main__ - train loss is 0.7405091051477939\n",
      "Steps:  51%|▌| 7584/15000 [1:05:57<3:38:18,  1.77s/it, lr=0.000946, step_loss=0.07/27/2023 18:50:47 - INFO - __main__ - train loss is 0.7692702033091336\n",
      "Steps:  51%|▌| 7585/15000 [1:05:57<2:39:31,  1.29s/it, lr=0.000946, step_loss=0.07/27/2023 18:50:47 - INFO - __main__ - train loss is 0.8039451122749597\n",
      "Steps:  51%|▌| 7586/15000 [1:05:57<1:58:21,  1.04it/s, lr=0.000946, step_loss=0.07/27/2023 18:50:47 - INFO - __main__ - train loss is 0.9459278762806207\n",
      "Steps:  51%|▌| 7587/15000 [1:05:57<1:29:33,  1.38it/s, lr=0.000946, step_loss=0.07/27/2023 18:50:47 - INFO - __main__ - train loss is 0.95555713144131\n",
      "Steps:  51%|▌| 7588/15000 [1:05:57<1:09:23,  1.78it/s, lr=0.000947, step_loss=0.07/27/2023 18:50:47 - INFO - __main__ - train loss is 1.0117320429999381\n",
      "Steps:  51%|▌| 7589/15000 [1:05:58<55:17,  2.23it/s, lr=0.000947, step_loss=0.0507/27/2023 18:50:47 - INFO - __main__ - train loss is 1.232898310991004\n",
      "Steps:  51%|▌| 7590/15000 [1:05:58<45:26,  2.72it/s, lr=0.000947, step_loss=0.2207/27/2023 18:50:48 - INFO - __main__ - train loss is 1.2663379770237952\n",
      "Steps:  51%|▌| 7591/15000 [1:05:58<38:30,  3.21it/s, lr=0.000947, step_loss=0.0307/27/2023 18:50:48 - INFO - __main__ - train loss is 1.2681620521470904\n",
      "Steps:  51%|▌| 7592/15000 [1:05:58<33:39,  3.67it/s, lr=0.000947, step_loss=0.0007/27/2023 18:50:48 - INFO - __main__ - train loss is 1.5573512120172381\n",
      "Steps:  51%|▌| 7593/15000 [1:05:58<30:17,  4.08it/s, lr=0.000947, step_loss=0.2807/27/2023 18:50:48 - INFO - __main__ - train loss is 1.5822553457692266\n",
      "Steps:  51%|▌| 7594/15000 [1:05:58<27:55,  4.42it/s, lr=0.000947, step_loss=0.0207/27/2023 18:50:48 - INFO - __main__ - train loss is 1.6392679335549474\n",
      "Steps:  51%|▌| 7595/15000 [1:05:59<26:16,  4.70it/s, lr=0.000947, step_loss=0.0507/27/2023 18:50:49 - INFO - __main__ - train loss is 1.8168469788506627\n",
      "Steps:  51%|▌| 7596/15000 [1:05:59<25:07,  4.91it/s, lr=0.000947, step_loss=0.1707/27/2023 18:50:49 - INFO - __main__ - train loss is 1.822380661033094\n",
      "Steps:  51%|▌| 7597/15000 [1:05:59<24:19,  5.07it/s, lr=0.000948, step_loss=0.0007/27/2023 18:50:49 - INFO - __main__ - train loss is 1.8258116650395095\n",
      "Steps:  51%|▌| 7598/15000 [1:05:59<23:46,  5.19it/s, lr=0.000948, step_loss=0.0007/27/2023 18:50:49 - INFO - __main__ - train loss is 2.021123494487256\n",
      "Steps:  51%|▌| 7599/15000 [1:05:59<23:22,  5.28it/s, lr=0.000948, step_loss=0.1907/27/2023 18:50:49 - INFO - __main__ - train loss is 2.0544174346141517\n",
      "Steps:  51%|▌| 7600/15000 [1:06:00<23:05,  5.34it/s, lr=0.000948, step_loss=0.0307/27/2023 18:50:49 - INFO - __main__ - train loss is 2.615440550725907\n",
      "Steps:  51%|▌| 7601/15000 [1:06:00<22:53,  5.39it/s, lr=0.000948, step_loss=0.5607/27/2023 18:50:50 - INFO - __main__ - train loss is 2.8797411951236427\n",
      "Steps:  51%|▌| 7602/15000 [1:06:00<22:45,  5.42it/s, lr=0.000948, step_loss=0.2607/27/2023 18:50:50 - INFO - __main__ - train loss is 2.942221842240542\n",
      "Steps:  51%|▌| 7603/15000 [1:06:00<22:39,  5.44it/s, lr=0.000948, step_loss=0.0607/27/2023 18:50:50 - INFO - __main__ - train loss is 2.973599340301007\n",
      "Steps:  51%|▌| 7604/15000 [1:06:00<22:47,  5.41it/s, lr=0.000949, step_loss=0.0307/27/2023 18:50:50 - INFO - __main__ - train loss is 3.0494258287362754\n",
      "Steps:  51%|▌| 7605/15000 [1:06:00<22:40,  5.43it/s, lr=0.000949, step_loss=0.0707/27/2023 18:50:50 - INFO - __main__ - train loss is 3.051352773560211\n",
      "Steps:  51%|▌| 7606/15000 [1:06:01<22:36,  5.45it/s, lr=0.000949, step_loss=0.0007/27/2023 18:50:51 - INFO - __main__ - train loss is 3.1150812848936766\n",
      "Steps:  51%|▌| 7607/15000 [1:06:01<22:33,  5.46it/s, lr=0.000949, step_loss=0.0607/27/2023 18:50:51 - INFO - __main__ - train loss is 3.6315673931967467\n",
      "Steps:  51%|▌| 7608/15000 [1:06:01<22:31,  5.47it/s, lr=0.000949, step_loss=0.5107/27/2023 18:50:51 - INFO - __main__ - train loss is 3.6592954031657428\n",
      "Steps:  51%|▌| 7609/15000 [1:06:01<22:30,  5.47it/s, lr=0.000949, step_loss=0.0207/27/2023 18:50:51 - INFO - __main__ - train loss is 3.796683870954439\n",
      "Steps:  51%|▌| 7610/15000 [1:06:01<22:28,  5.48it/s, lr=0.000949, step_loss=0.1307/27/2023 18:50:51 - INFO - __main__ - train loss is 4.391049467725679\n",
      "Steps:  51%|▌| 7611/15000 [1:06:02<22:30,  5.47it/s, lr=0.000949, step_loss=0.5907/27/2023 18:50:51 - INFO - __main__ - train loss is 4.867883019847795\n",
      "Steps:  51%|▌| 7612/15000 [1:06:02<22:28,  5.48it/s, lr=0.00095, step_loss=0.47707/27/2023 18:50:52 - INFO - __main__ - train loss is 4.87563220015727\n",
      "Steps:  51%|▌| 7613/15000 [1:06:02<22:27,  5.48it/s, lr=0.00095, step_loss=0.00707/27/2023 18:50:52 - INFO - __main__ - train loss is 4.9006923136767\n",
      "Steps:  51%|▌| 7614/15000 [1:06:02<22:38,  5.44it/s, lr=0.00095, step_loss=0.02507/27/2023 18:50:52 - INFO - __main__ - train loss is 4.901975947315805\n",
      "Steps:  51%|▌| 7615/15000 [1:06:02<22:34,  5.45it/s, lr=0.00095, step_loss=0.00107/27/2023 18:50:52 - INFO - __main__ - train loss is 4.927020494709723\n",
      "Steps:  51%|▌| 7616/15000 [1:06:02<22:37,  5.44it/s, lr=0.00095, step_loss=0.02507/27/2023 18:50:52 - INFO - __main__ - train loss is 4.940475682611577\n",
      "Steps:  51%|▌| 7617/15000 [1:06:03<22:33,  5.46it/s, lr=0.00095, step_loss=0.01307/27/2023 18:50:53 - INFO - __main__ - train loss is 5.5860845249844715\n",
      "Steps:  51%|▌| 7618/15000 [1:06:03<22:29,  5.47it/s, lr=0.00095, step_loss=0.64607/27/2023 18:50:53 - INFO - __main__ - train loss is 5.704525272245519\n",
      "Steps:  51%|▌| 7619/15000 [1:06:03<22:27,  5.48it/s, lr=0.00095, step_loss=0.11807/27/2023 18:50:53 - INFO - __main__ - train loss is 5.712438921327703\n",
      "Steps:  51%|▌| 7620/15000 [1:06:03<22:27,  5.48it/s, lr=0.000951, step_loss=0.0007/27/2023 18:50:53 - INFO - __main__ - train loss is 5.729068766231649\n",
      "Steps:  51%|▌| 7621/15000 [1:06:03<22:20,  5.50it/s, lr=0.000951, step_loss=0.0107/27/2023 18:50:53 - INFO - __main__ - train loss is 5.742406146484427\n",
      "Steps:  51%|▌| 7622/15000 [1:06:04<22:19,  5.51it/s, lr=0.000951, step_loss=0.0107/27/2023 18:50:53 - INFO - __main__ - train loss is 5.9708079564152285\n",
      "Steps:  51%|▌| 7623/15000 [1:06:04<22:14,  5.53it/s, lr=0.000951, step_loss=0.2207/27/2023 18:50:54 - INFO - __main__ - train loss is 6.030712099629454\n",
      "Steps:  51%|▌| 7624/15000 [1:06:04<22:11,  5.54it/s, lr=0.000951, step_loss=0.0507/27/2023 18:50:54 - INFO - __main__ - train loss is 6.349759997683577\n",
      "Steps:  51%|▌| 7625/15000 [1:06:04<22:09,  5.55it/s, lr=0.000951, step_loss=0.3107/27/2023 18:50:54 - INFO - __main__ - train loss is 6.564827712136321\n",
      "Steps:  51%|▌| 7626/15000 [1:06:04<22:07,  5.56it/s, lr=0.000951, step_loss=0.2107/27/2023 18:50:54 - INFO - __main__ - train loss is 6.747093232232146\n",
      "Steps:  51%|▌| 7627/15000 [1:06:04<22:06,  5.56it/s, lr=0.000951, step_loss=0.1807/27/2023 18:50:54 - INFO - __main__ - train loss is 7.0522760468302295\n",
      "Steps:  51%|▌| 7628/15000 [1:06:05<22:05,  5.56it/s, lr=0.000951, step_loss=0.3007/27/2023 18:50:55 - INFO - __main__ - train loss is 7.063670048373751\n",
      "Steps:  51%|▌| 7629/15000 [1:06:05<22:04,  5.56it/s, lr=0.000952, step_loss=0.0107/27/2023 18:50:55 - INFO - __main__ - train loss is 7.0883160213707015\n",
      "Steps:  51%|▌| 7630/15000 [1:06:05<22:04,  5.56it/s, lr=0.000952, step_loss=0.0207/27/2023 18:50:55 - INFO - __main__ - train loss is 7.100130463833921\n",
      "Steps:  51%|▌| 7631/15000 [1:06:05<22:04,  5.56it/s, lr=0.000952, step_loss=0.0107/27/2023 18:50:55 - INFO - __main__ - train loss is 7.208312849397771\n",
      "Steps:  51%|▌| 7632/15000 [1:06:05<22:04,  5.56it/s, lr=0.000952, step_loss=0.1007/27/2023 18:50:55 - INFO - __main__ - train loss is 7.313295724685304\n",
      "Steps:  51%|▌| 7633/15000 [1:06:06<22:04,  5.56it/s, lr=0.000952, step_loss=0.1007/27/2023 18:50:55 - INFO - __main__ - train loss is 7.49815394252073\n",
      "Steps:  51%|▌| 7634/15000 [1:06:06<22:04,  5.56it/s, lr=0.000952, step_loss=0.1807/27/2023 18:50:56 - INFO - __main__ - train loss is 7.537547710235231\n",
      "Steps:  51%|▌| 7635/15000 [1:06:06<22:03,  5.57it/s, lr=0.000952, step_loss=0.0307/27/2023 18:50:56 - INFO - __main__ - train loss is 7.7317696389509365\n",
      "Steps:  51%|▌| 7636/15000 [1:06:06<22:02,  5.57it/s, lr=0.000953, step_loss=0.1907/27/2023 18:50:56 - INFO - __main__ - train loss is 7.914995270664804\n",
      "Steps:  51%|▌| 7637/15000 [1:06:06<22:01,  5.57it/s, lr=0.000953, step_loss=0.1807/27/2023 18:50:56 - INFO - __main__ - train loss is 8.031161132152192\n",
      "Steps:  51%|▌| 7638/15000 [1:06:06<22:01,  5.57it/s, lr=0.000953, step_loss=0.1107/27/2023 18:50:56 - INFO - __main__ - train loss is 8.068438458140008\n",
      "Steps:  51%|▌| 7639/15000 [1:06:07<22:01,  5.57it/s, lr=0.000953, step_loss=0.0307/27/2023 18:50:57 - INFO - __main__ - train loss is 8.07961937400978\n",
      "Steps:  51%|▌| 7640/15000 [1:06:07<22:02,  5.57it/s, lr=0.000953, step_loss=0.0107/27/2023 18:50:57 - INFO - __main__ - train loss is 8.502797003719024\n",
      "Steps:  51%|▌| 7641/15000 [1:06:07<22:01,  5.57it/s, lr=0.000953, step_loss=0.4207/27/2023 18:50:57 - INFO - __main__ - train loss is 8.522406495991163\n",
      "Steps:  51%|▌| 7642/15000 [1:06:07<22:02,  5.56it/s, lr=0.000953, step_loss=0.0107/27/2023 18:50:57 - INFO - __main__ - train loss is 8.524727304815315\n",
      "Steps:  51%|▌| 7643/15000 [1:06:07<22:02,  5.56it/s, lr=0.000953, step_loss=0.0007/27/2023 18:50:57 - INFO - __main__ - train loss is 8.530802018358372\n",
      "Steps:  51%|▌| 7644/15000 [1:06:08<22:01,  5.57it/s, lr=0.000954, step_loss=0.0007/27/2023 18:50:57 - INFO - __main__ - train loss is 8.625621616258286\n",
      "Steps:  51%|▌| 7645/15000 [1:06:08<22:01,  5.57it/s, lr=0.000954, step_loss=0.0907/27/2023 18:50:58 - INFO - __main__ - train loss is 8.734486244036816\n",
      "Steps:  51%|▌| 7646/15000 [1:06:08<22:00,  5.57it/s, lr=0.000954, step_loss=0.1007/27/2023 18:50:58 - INFO - __main__ - train loss is 8.738695295411162\n",
      "Steps:  51%|▌| 7647/15000 [1:06:08<22:00,  5.57it/s, lr=0.000954, step_loss=0.0007/27/2023 18:50:58 - INFO - __main__ - train loss is 8.741068743751384\n",
      "Steps:  51%|▌| 7648/15000 [1:06:08<22:00,  5.57it/s, lr=0.000954, step_loss=0.0007/27/2023 18:50:58 - INFO - __main__ - train loss is 8.74521824310068\n",
      "Steps:  51%|▌| 7649/15000 [1:06:08<21:59,  5.57it/s, lr=0.000954, step_loss=0.0007/27/2023 18:50:58 - INFO - __main__ - train loss is 8.746476174681447\n",
      "Steps:  51%|▌| 7650/15000 [1:06:09<21:59,  5.57it/s, lr=0.000954, step_loss=0.0007/27/2023 18:50:58 - INFO - __main__ - train loss is 8.939410032122396\n",
      "Steps:  51%|▌| 7651/15000 [1:06:09<21:59,  5.57it/s, lr=0.000954, step_loss=0.1907/27/2023 18:50:59 - INFO - __main__ - train loss is 8.959370828582905\n",
      "Steps:  51%|▌| 7652/15000 [1:06:09<21:58,  5.57it/s, lr=0.000955, step_loss=0.0207/27/2023 18:50:59 - INFO - __main__ - train loss is 8.96526969957631\n",
      "Steps:  51%|▌| 7653/15000 [1:06:09<21:58,  5.57it/s, lr=0.000955, step_loss=0.0007/27/2023 18:50:59 - INFO - __main__ - train loss is 8.967067922349088\n",
      "Steps:  51%|▌| 7654/15000 [1:06:09<21:59,  5.57it/s, lr=0.000955, step_loss=0.0007/27/2023 18:50:59 - INFO - __main__ - train loss is 9.024936075205915\n",
      "Steps:  51%|▌| 7655/15000 [1:06:10<21:59,  5.57it/s, lr=0.000955, step_loss=0.0507/27/2023 18:50:59 - INFO - __main__ - train loss is 9.157502899761312\n",
      "Steps:  51%|▌| 7656/15000 [1:06:10<21:58,  5.57it/s, lr=0.000955, step_loss=0.1307/27/2023 18:51:00 - INFO - __main__ - train loss is 9.432553092832677\n",
      "Steps:  51%|▌| 7657/15000 [1:06:10<21:58,  5.57it/s, lr=0.000955, step_loss=0.2707/27/2023 18:51:00 - INFO - __main__ - train loss is 9.85244778811466\n",
      "Steps:  51%|▌| 7658/15000 [1:06:10<21:58,  5.57it/s, lr=0.000955, step_loss=0.4207/27/2023 18:51:00 - INFO - __main__ - train loss is 9.97214909165632\n",
      "Steps:  51%|▌| 7659/15000 [1:06:10<21:59,  5.56it/s, lr=0.000955, step_loss=0.1207/27/2023 18:51:00 - INFO - __main__ - train loss is 10.027250717277639\n",
      "Steps:  51%|▌| 7660/15000 [1:06:10<21:58,  5.57it/s, lr=0.000956, step_loss=0.0507/27/2023 18:51:00 - INFO - __main__ - train loss is 10.199685702915303\n",
      "Steps:  51%|▌| 7661/15000 [1:06:11<21:58,  5.57it/s, lr=0.000956, step_loss=0.1707/27/2023 18:51:00 - INFO - __main__ - train loss is 10.517024109954946\n",
      "Steps:  51%|▌| 7662/15000 [1:06:11<21:58,  5.57it/s, lr=0.000956, step_loss=0.3107/27/2023 18:51:01 - INFO - __main__ - train loss is 10.52653406735044\n",
      "Steps:  51%|▌| 7663/15000 [1:06:11<21:58,  5.57it/s, lr=0.000956, step_loss=0.0007/27/2023 18:51:01 - INFO - __main__ - train loss is 10.823807256179862\n",
      "Steps:  51%|▌| 7664/15000 [1:06:11<21:58,  5.56it/s, lr=0.000956, step_loss=0.2907/27/2023 18:51:01 - INFO - __main__ - train loss is 11.585024492698722\n",
      "Steps:  51%|▌| 7665/15000 [1:06:11<21:58,  5.56it/s, lr=0.000956, step_loss=0.7607/27/2023 18:51:01 - INFO - __main__ - train loss is 11.834960089880042\n",
      "Steps:  51%|▌| 7666/15000 [1:06:11<22:00,  5.56it/s, lr=0.000956, step_loss=0.2507/27/2023 18:51:01 - INFO - __main__ - train loss is 11.852375278132968\n",
      "Steps:  51%|▌| 7667/15000 [1:06:12<21:59,  5.56it/s, lr=0.000956, step_loss=0.0107/27/2023 18:51:02 - INFO - __main__ - train loss is 11.93345982756\n",
      "Steps:  51%|▌| 7668/15000 [1:06:12<22:07,  5.53it/s, lr=0.000956, step_loss=0.0807/27/2023 18:51:02 - INFO - __main__ - train loss is 11.998990679043345\n",
      "Steps:  51%|▌| 7669/15000 [1:06:12<22:04,  5.54it/s, lr=0.000957, step_loss=0.0607/27/2023 18:51:02 - INFO - __main__ - train loss is 12.466317439335398\n",
      "Steps:  51%|▌| 7670/15000 [1:06:12<22:01,  5.55it/s, lr=0.000957, step_loss=0.4607/27/2023 18:51:02 - INFO - __main__ - train loss is 12.630756476777606\n",
      "Steps:  51%|▌| 7671/15000 [1:06:12<22:00,  5.55it/s, lr=0.000957, step_loss=0.1607/27/2023 18:51:02 - INFO - __main__ - train loss is 12.642373995739035\n",
      "Steps:  51%|▌| 7672/15000 [1:06:13<21:59,  5.55it/s, lr=0.000957, step_loss=0.0107/27/2023 18:51:02 - INFO - __main__ - train loss is 12.93666048522573\n",
      "Steps:  51%|▌| 7673/15000 [1:06:13<21:58,  5.56it/s, lr=0.000957, step_loss=0.2907/27/2023 18:51:03 - INFO - __main__ - train loss is 12.938791839987971\n",
      "Steps:  51%|▌| 7674/15000 [1:06:13<22:10,  5.51it/s, lr=0.000957, step_loss=0.0007/27/2023 18:51:03 - INFO - __main__ - train loss is 13.160119144828059\n",
      "Steps:  51%|▌| 7675/15000 [1:06:13<22:09,  5.51it/s, lr=0.000957, step_loss=0.2207/27/2023 18:51:03 - INFO - __main__ - train loss is 13.18272027245257\n",
      "Steps:  51%|▌| 7676/15000 [1:06:13<22:17,  5.47it/s, lr=0.000958, step_loss=0.0207/27/2023 18:51:03 - INFO - __main__ - train loss is 13.184632699238136\n",
      "Steps:  51%|▌| 7677/15000 [1:06:13<22:34,  5.41it/s, lr=0.000958, step_loss=0.0007/27/2023 18:51:03 - INFO - __main__ - train loss is 13.34617933188565\n",
      "Steps:  51%|▌| 7678/15000 [1:06:14<22:37,  5.40it/s, lr=0.000958, step_loss=0.1607/27/2023 18:51:04 - INFO - __main__ - train loss is 13.429680350469425\n",
      "Steps:  51%|▌| 7679/15000 [1:06:14<22:28,  5.43it/s, lr=0.000958, step_loss=0.0807/27/2023 18:51:04 - INFO - __main__ - train loss is 13.533368955599144\n",
      "Steps:  51%|▌| 7680/15000 [1:06:14<22:19,  5.46it/s, lr=0.000958, step_loss=0.1007/27/2023 18:51:04 - INFO - __main__ - train loss is 13.748139600502327\n",
      "Steps:  51%|▌| 7681/15000 [1:06:14<22:12,  5.49it/s, lr=0.000958, step_loss=0.2107/27/2023 18:51:04 - INFO - __main__ - train loss is 13.756006692769006\n",
      "Steps:  51%|▌| 7682/15000 [1:06:14<22:07,  5.51it/s, lr=0.000958, step_loss=0.0007/27/2023 18:51:04 - INFO - __main__ - train loss is 13.855815668823197\n",
      "Steps:  51%|▌| 7683/15000 [1:06:15<22:03,  5.53it/s, lr=0.000958, step_loss=0.0907/27/2023 18:51:04 - INFO - __main__ - train loss is 14.086620022775605\n",
      "Steps:  51%|▌| 7684/15000 [1:06:15<22:01,  5.54it/s, lr=0.000959, step_loss=0.2307/27/2023 18:51:05 - INFO - __main__ - train loss is 14.928939153673127\n",
      "Steps:  51%|▌| 7685/15000 [1:06:15<21:59,  5.54it/s, lr=0.000959, step_loss=0.8407/27/2023 18:51:05 - INFO - __main__ - train loss is 14.95180421997793\n",
      "Steps:  51%|▌| 7686/15000 [1:06:15<21:58,  5.55it/s, lr=0.000959, step_loss=0.0207/27/2023 18:51:05 - INFO - __main__ - train loss is 15.161054282682016\n",
      "Steps:  51%|▌| 7687/15000 [1:06:15<22:09,  5.50it/s, lr=0.000959, step_loss=0.2007/27/2023 18:51:05 - INFO - __main__ - train loss is 15.494806437985972\n",
      "Steps:  51%|▌| 7688/15000 [1:06:15<22:07,  5.51it/s, lr=0.000959, step_loss=0.3307/27/2023 18:51:05 - INFO - __main__ - train loss is 15.496156319859438\n",
      "Steps:  51%|▌| 7689/15000 [1:06:16<22:04,  5.52it/s, lr=0.000959, step_loss=0.0007/27/2023 18:51:06 - INFO - __main__ - train loss is 15.505472759599797\n",
      "Steps:  51%|▌| 7690/15000 [1:06:16<22:01,  5.53it/s, lr=0.000959, step_loss=0.0007/27/2023 18:51:06 - INFO - __main__ - train loss is 15.593428621883504\n",
      "Steps:  51%|▌| 7691/15000 [1:06:16<21:59,  5.54it/s, lr=0.000959, step_loss=0.0807/27/2023 18:51:06 - INFO - __main__ - train loss is 15.679146821494214\n",
      "Steps:  51%|▌| 7692/15000 [1:06:16<22:10,  5.49it/s, lr=0.00096, step_loss=0.08507/27/2023 18:51:06 - INFO - __main__ - train loss is 15.6825741577195\n",
      "Steps:  51%|▌| 7693/15000 [1:06:16<22:18,  5.46it/s, lr=0.00096, step_loss=0.00307/27/2023 18:51:06 - INFO - __main__ - train loss is 15.751439963583834\n",
      "Steps:  51%|▌| 7694/15000 [1:06:17<22:10,  5.49it/s, lr=0.00096, step_loss=0.06807/27/2023 18:51:06 - INFO - __main__ - train loss is 15.754435821785592\n",
      "Steps:  51%|▌| 7695/15000 [1:06:17<22:05,  5.51it/s, lr=0.00096, step_loss=0.00307/27/2023 18:51:07 - INFO - __main__ - train loss is 15.866865142597817\n",
      "Steps:  51%|▌| 7696/15000 [1:06:17<22:07,  5.50it/s, lr=0.00096, step_loss=0.11207/27/2023 18:51:07 - INFO - __main__ - train loss is 15.878321938565932\n",
      "Steps:  51%|▌| 7697/15000 [1:06:17<22:03,  5.52it/s, lr=0.00096, step_loss=0.01107/27/2023 18:51:07 - INFO - __main__ - train loss is 15.914579056552611\n",
      "Steps:  51%|▌| 7698/15000 [1:06:17<22:00,  5.53it/s, lr=0.00096, step_loss=0.03607/27/2023 18:51:07 - INFO - __main__ - train loss is 15.953471586457454\n",
      "Steps:  51%|▌| 7699/15000 [1:06:17<21:57,  5.54it/s, lr=0.00096, step_loss=0.03807/27/2023 18:51:07 - INFO - __main__ - train loss is 16.243744835606776\n",
      "Steps:  51%|▌| 7700/15000 [1:06:18<21:55,  5.55it/s, lr=0.000961, step_loss=0.2907/27/2023 18:51:08 - INFO - __main__ - train loss is 16.4072195146\n",
      "Steps:  51%|▌| 7701/15000 [1:06:18<21:53,  5.56it/s, lr=0.000961, step_loss=0.1607/27/2023 18:51:08 - INFO - __main__ - train loss is 16.462374482653104\n",
      "Steps:  51%|▌| 7702/15000 [1:06:18<21:52,  5.56it/s, lr=0.000961, step_loss=0.0507/27/2023 18:51:08 - INFO - __main__ - train loss is 16.733651195070706\n",
      "Steps:  51%|▌| 7703/15000 [1:06:18<21:51,  5.56it/s, lr=0.000961, step_loss=0.2707/27/2023 18:51:08 - INFO - __main__ - train loss is 16.776839845231734\n",
      "Steps:  51%|▌| 7704/15000 [1:06:18<21:51,  5.56it/s, lr=0.000961, step_loss=0.0407/27/2023 18:51:08 - INFO - __main__ - train loss is 16.77891620679293\n",
      "Steps:  51%|▌| 7705/15000 [1:06:19<21:51,  5.56it/s, lr=0.000961, step_loss=0.0007/27/2023 18:51:08 - INFO - __main__ - train loss is 17.285394993261434\n",
      "Steps:  51%|▌| 7706/15000 [1:06:19<21:50,  5.57it/s, lr=0.000961, step_loss=0.5007/27/2023 18:51:09 - INFO - __main__ - train loss is 17.29120479116682\n",
      "Steps:  51%|▌| 7707/15000 [1:06:19<21:49,  5.57it/s, lr=0.000961, step_loss=0.0007/27/2023 18:51:09 - INFO - __main__ - train loss is 17.29262224480044\n",
      "Steps:  51%|▌| 7708/15000 [1:06:19<21:49,  5.57it/s, lr=0.000962, step_loss=0.0007/27/2023 18:51:09 - INFO - __main__ - train loss is 17.43780515238177\n",
      "Steps:  51%|▌| 7709/15000 [1:06:19<21:48,  5.57it/s, lr=0.000962, step_loss=0.1407/27/2023 18:51:09 - INFO - __main__ - train loss is 17.515462047304027\n",
      "Steps:  51%|▌| 7710/15000 [1:06:19<21:49,  5.57it/s, lr=0.000962, step_loss=0.0707/27/2023 18:51:09 - INFO - __main__ - train loss is 17.52146906114649\n",
      "Steps:  51%|▌| 7711/15000 [1:06:20<21:48,  5.57it/s, lr=0.000962, step_loss=0.0007/27/2023 18:51:10 - INFO - __main__ - train loss is 17.74661516107153\n",
      "Steps:  51%|▌| 7712/15000 [1:06:20<21:47,  5.57it/s, lr=0.000962, step_loss=0.2207/27/2023 18:51:10 - INFO - __main__ - train loss is 17.83239463425707\n",
      "Steps:  51%|▌| 7713/15000 [1:06:20<21:48,  5.57it/s, lr=0.000962, step_loss=0.0807/27/2023 18:51:10 - INFO - __main__ - train loss is 17.86743943102192\n",
      "Steps:  51%|▌| 7714/15000 [1:06:20<21:48,  5.57it/s, lr=0.000962, step_loss=0.0307/27/2023 18:51:10 - INFO - __main__ - train loss is 18.134714555810206\n",
      "Steps:  51%|▌| 7715/15000 [1:06:20<21:47,  5.57it/s, lr=0.000962, step_loss=0.2607/27/2023 18:51:10 - INFO - __main__ - train loss is 18.146096091601066\n",
      "Steps:  51%|▌| 7716/15000 [1:06:21<21:48,  5.57it/s, lr=0.000963, step_loss=0.0107/27/2023 18:51:10 - INFO - __main__ - train loss is 18.15323563932907\n",
      "Steps:  51%|▌| 7717/15000 [1:06:21<21:47,  5.57it/s, lr=0.000963, step_loss=0.0007/27/2023 18:51:11 - INFO - __main__ - train loss is 18.167770287836902\n",
      "Steps:  51%|▌| 7718/15000 [1:06:21<21:47,  5.57it/s, lr=0.000963, step_loss=0.0107/27/2023 18:51:11 - INFO - __main__ - train loss is 18.89690782770049\n",
      "Steps:  51%|▌| 7719/15000 [1:06:21<21:46,  5.57it/s, lr=0.000963, step_loss=0.7207/27/2023 18:51:11 - INFO - __main__ - train loss is 18.959785616840236\n",
      "Steps:  51%|▌| 7720/15000 [1:06:21<21:46,  5.57it/s, lr=0.000963, step_loss=0.0607/27/2023 18:51:11 - INFO - __main__ - train loss is 19.072618550504558\n",
      "Steps:  51%|▌| 7721/15000 [1:06:21<21:46,  5.57it/s, lr=0.000963, step_loss=0.1107/27/2023 18:51:11 - INFO - __main__ - train loss is 19.203078484977596\n",
      "Steps:  51%|▌| 7722/15000 [1:06:22<21:45,  5.57it/s, lr=0.000963, step_loss=0.1307/27/2023 18:51:11 - INFO - __main__ - train loss is 19.206165261217393\n",
      "Steps:  51%|▌| 7723/15000 [1:06:22<21:45,  5.57it/s, lr=0.000963, step_loss=0.0007/27/2023 18:51:12 - INFO - __main__ - train loss is 19.299225955852307\n",
      "Steps:  51%|▌| 7724/15000 [1:06:22<21:45,  5.57it/s, lr=0.000964, step_loss=0.0907/27/2023 18:51:12 - INFO - __main__ - train loss is 19.33644144947175\n",
      "Steps:  52%|▌| 7725/15000 [1:06:22<21:45,  5.57it/s, lr=0.000964, step_loss=0.0307/27/2023 18:51:12 - INFO - __main__ - train loss is 19.438354730256833\n",
      "Steps:  52%|▌| 7726/15000 [1:06:22<21:45,  5.57it/s, lr=0.000964, step_loss=0.1007/27/2023 18:51:12 - INFO - __main__ - train loss is 19.831369071849622\n",
      "Steps:  52%|▌| 7727/15000 [1:06:23<21:45,  5.57it/s, lr=0.000964, step_loss=0.3907/27/2023 18:51:12 - INFO - __main__ - train loss is 19.870834614732303\n",
      "Steps:  52%|▌| 7728/15000 [1:06:23<21:45,  5.57it/s, lr=0.000964, step_loss=0.0307/27/2023 18:51:13 - INFO - __main__ - train loss is 19.91349902341608\n",
      "Steps:  52%|▌| 7729/15000 [1:06:23<21:45,  5.57it/s, lr=0.000964, step_loss=0.0407/27/2023 18:51:13 - INFO - __main__ - train loss is 19.98595261166338\n",
      "Steps:  52%|▌| 7730/15000 [1:06:23<21:44,  5.57it/s, lr=0.000964, step_loss=0.0707/27/2023 18:51:13 - INFO - __main__ - train loss is 19.98744830035139\n",
      "Steps:  52%|▌| 7731/15000 [1:06:23<21:44,  5.57it/s, lr=0.000964, step_loss=0.0007/27/2023 18:51:13 - INFO - __main__ - train loss is 20.426028068293817\n",
      "Steps:  52%|▌| 7732/15000 [1:06:23<21:44,  5.57it/s, lr=0.000965, step_loss=0.4307/27/2023 18:51:13 - INFO - __main__ - train loss is 20.54330910288263\n",
      "Steps:  52%|▌| 7733/15000 [1:06:24<21:45,  5.57it/s, lr=0.000965, step_loss=0.1107/27/2023 18:51:13 - INFO - __main__ - train loss is 20.547254729201086\n",
      "Steps:  52%|▌| 7734/15000 [1:06:24<21:45,  5.57it/s, lr=0.000965, step_loss=0.0007/27/2023 18:51:14 - INFO - __main__ - train loss is 20.587154998560436\n",
      "Steps:  52%|▌| 7735/15000 [1:06:24<21:45,  5.56it/s, lr=0.000965, step_loss=0.0307/27/2023 18:51:14 - INFO - __main__ - train loss is 20.602078038384207\n",
      "Steps:  52%|▌| 7736/15000 [1:06:24<21:45,  5.56it/s, lr=0.000965, step_loss=0.0107/27/2023 18:51:14 - INFO - __main__ - train loss is 20.692885953118093\n",
      "Steps:  52%|▌| 7737/15000 [1:06:24<21:45,  5.56it/s, lr=0.000965, step_loss=0.0907/27/2023 18:51:14 - INFO - __main__ - train loss is 20.816410052706487\n",
      "Steps:  52%|▌| 7738/15000 [1:06:24<21:45,  5.56it/s, lr=0.000965, step_loss=0.1207/27/2023 18:51:14 - INFO - __main__ - train loss is 20.824723146040924\n",
      "Steps:  52%|▌| 7739/15000 [1:06:25<21:45,  5.56it/s, lr=0.000965, step_loss=0.0007/27/2023 18:51:15 - INFO - __main__ - train loss is 20.93897367932368\n",
      "Steps:  52%|▌| 7740/15000 [1:06:25<21:44,  5.56it/s, lr=0.000965, step_loss=0.1107/27/2023 18:51:15 - INFO - __main__ - train loss is 21.328425183077343\n",
      "Steps:  52%|▌| 7741/15000 [1:06:25<21:44,  5.56it/s, lr=0.000966, step_loss=0.3807/27/2023 18:51:15 - INFO - __main__ - train loss is 21.589654310722835\n",
      "Steps:  52%|▌| 7742/15000 [1:06:25<21:44,  5.56it/s, lr=0.000966, step_loss=0.2607/27/2023 18:51:15 - INFO - __main__ - train loss is 21.94299064495135\n",
      "Steps:  52%|▌| 7743/15000 [1:06:25<21:44,  5.56it/s, lr=0.000966, step_loss=0.3507/27/2023 18:51:15 - INFO - __main__ - train loss is 21.95671167515684\n",
      "Steps:  52%|▌| 7744/15000 [1:06:26<21:43,  5.57it/s, lr=0.000966, step_loss=0.0107/27/2023 18:51:15 - INFO - __main__ - train loss is 22.41315331601072\n",
      "Steps:  52%|▌| 7745/15000 [1:06:26<21:42,  5.57it/s, lr=0.000966, step_loss=0.4507/27/2023 18:51:16 - INFO - __main__ - train loss is 22.724024738301523\n",
      "Steps:  52%|▌| 7746/15000 [1:06:26<21:42,  5.57it/s, lr=0.000966, step_loss=0.3107/27/2023 18:51:16 - INFO - __main__ - train loss is 22.783025427837856\n",
      "Steps:  52%|▌| 7747/15000 [1:06:26<21:46,  5.55it/s, lr=0.000966, step_loss=0.0507/27/2023 18:51:16 - INFO - __main__ - train loss is 22.78570163657423\n",
      "Steps:  52%|▌| 7748/15000 [1:06:26<21:44,  5.56it/s, lr=0.000967, step_loss=0.0007/27/2023 18:51:16 - INFO - __main__ - train loss is 22.93088490178343\n",
      "Steps:  52%|▌| 7749/15000 [1:06:26<21:44,  5.56it/s, lr=0.000967, step_loss=0.1407/27/2023 18:51:16 - INFO - __main__ - train loss is 23.056337703368627\n",
      "Steps:  52%|▌| 7750/15000 [1:06:27<21:44,  5.56it/s, lr=0.000967, step_loss=0.1207/27/2023 18:51:17 - INFO - __main__ - train loss is 23.297585416934453\n",
      "Steps:  52%|▌| 7751/15000 [1:06:27<21:43,  5.56it/s, lr=0.000967, step_loss=0.2407/27/2023 18:51:17 - INFO - __main__ - train loss is 23.56083973159548\n",
      "Steps:  52%|▌| 7752/15000 [1:06:27<21:42,  5.56it/s, lr=0.000967, step_loss=0.2607/27/2023 18:51:17 - INFO - __main__ - train loss is 23.61875474860426\n",
      "Steps:  52%|▌| 7753/15000 [1:06:27<21:43,  5.56it/s, lr=0.000967, step_loss=0.0507/27/2023 18:51:17 - INFO - __main__ - train loss is 23.625441369018517\n",
      "Steps:  52%|▌| 7754/15000 [1:06:27<21:45,  5.55it/s, lr=0.000967, step_loss=0.0007/27/2023 18:51:17 - INFO - __main__ - train loss is 23.63136609259527\n",
      "Steps:  52%|▌| 7755/15000 [1:06:28<21:44,  5.56it/s, lr=0.000967, step_loss=0.0007/27/2023 18:51:17 - INFO - __main__ - train loss is 23.633326537325047\n",
      "Steps:  52%|▌| 7756/15000 [1:06:28<21:43,  5.56it/s, lr=0.000968, step_loss=0.0007/27/2023 18:51:18 - INFO - __main__ - train loss is 24.44426036567893\n",
      "Steps:  52%|▌| 7757/15000 [1:06:28<21:42,  5.56it/s, lr=0.000968, step_loss=0.8107/27/2023 18:51:18 - INFO - __main__ - train loss is 24.74132347793784\n",
      "Steps:  52%|▌| 7758/15000 [1:06:28<21:55,  5.50it/s, lr=0.000968, step_loss=0.2907/27/2023 18:51:18 - INFO - __main__ - train loss is 24.753437363891862\n",
      "Steps:  52%|▌| 7759/15000 [1:06:28<22:39,  5.33it/s, lr=0.000968, step_loss=0.0107/27/2023 18:51:18 - INFO - __main__ - train loss is 24.93495898821857\n",
      "Steps:  52%|▌| 7760/15000 [1:06:29<23:54,  5.05it/s, lr=0.000968, step_loss=0.1807/27/2023 18:51:18 - INFO - __main__ - train loss is 24.956496087252162\n",
      "Steps:  52%|▌| 7761/15000 [1:06:29<25:02,  4.82it/s, lr=0.000968, step_loss=0.0207/27/2023 18:51:19 - INFO - __main__ - train loss is 24.972046926035546\n",
      "Steps:  52%|▌| 7762/15000 [1:06:29<24:58,  4.83it/s, lr=0.000968, step_loss=0.0107/27/2023 18:51:19 - INFO - __main__ - train loss is 24.99936114565935\n",
      "Steps:  52%|▌| 7763/15000 [1:06:29<24:05,  5.01it/s, lr=0.000968, step_loss=0.0207/27/2023 18:51:19 - INFO - __main__ - train loss is 25.00600618624594\n",
      "Steps:  52%|▌| 7764/15000 [1:06:29<23:22,  5.16it/s, lr=0.000969, step_loss=0.0007/27/2023 18:51:19 - INFO - __main__ - train loss is 25.01573924475815\n",
      "Steps:  52%|▌| 7765/15000 [1:06:29<23:00,  5.24it/s, lr=0.000969, step_loss=0.0007/27/2023 18:51:19 - INFO - __main__ - train loss is 25.22551183158066\n",
      "Steps:  52%|▌| 7766/15000 [1:06:30<22:36,  5.33it/s, lr=0.000969, step_loss=0.2107/27/2023 18:51:20 - INFO - __main__ - train loss is 25.245817295624875\n",
      "Steps:  52%|▌| 7767/15000 [1:06:30<22:21,  5.39it/s, lr=0.000969, step_loss=0.0207/27/2023 18:51:20 - INFO - __main__ - train loss is 25.247427484602667\n",
      "Steps:  52%|▌| 7768/15000 [1:06:30<22:08,  5.44it/s, lr=0.000969, step_loss=0.0007/27/2023 18:51:20 - INFO - __main__ - train loss is 25.382588884443976\n",
      "Steps:  52%|▌| 7769/15000 [1:06:30<21:59,  5.48it/s, lr=0.000969, step_loss=0.1307/27/2023 18:51:20 - INFO - __main__ - train loss is 25.384191478486173\n",
      "Steps:  52%|▌| 7770/15000 [1:06:30<21:53,  5.51it/s, lr=0.000969, step_loss=0.0007/27/2023 18:51:20 - INFO - __main__ - train loss is 25.428107610787265\n",
      "Steps:  52%|▌| 7771/15000 [1:06:31<21:48,  5.53it/s, lr=0.000969, step_loss=0.0407/27/2023 18:51:20 - INFO - __main__ - train loss is 25.547800033236854\n",
      "Steps:  52%|▌| 7772/15000 [1:06:31<21:45,  5.54it/s, lr=0.00097, step_loss=0.12]07/27/2023 18:51:21 - INFO - __main__ - train loss is 25.68126690282952\n",
      "Steps:  52%|▌| 7773/15000 [1:06:31<21:43,  5.54it/s, lr=0.00097, step_loss=0.13307/27/2023 18:51:21 - INFO - __main__ - train loss is 25.854542239452712\n",
      "Steps:  52%|▌| 7774/15000 [1:06:31<21:44,  5.54it/s, lr=0.00097, step_loss=0.17307/27/2023 18:51:21 - INFO - __main__ - train loss is 25.856250632554293\n",
      "Steps:  52%|▌| 7775/15000 [1:06:31<21:43,  5.54it/s, lr=0.00097, step_loss=0.00107/27/2023 18:51:21 - INFO - __main__ - train loss is 25.897351700812578\n",
      "Steps:  52%|▌| 7776/15000 [1:06:31<21:41,  5.55it/s, lr=0.00097, step_loss=0.04107/27/2023 18:51:21 - INFO - __main__ - train loss is 26.051398057490587\n",
      "Steps:  52%|▌| 7777/15000 [1:06:32<21:39,  5.56it/s, lr=0.00097, step_loss=0.15407/27/2023 18:51:22 - INFO - __main__ - train loss is 26.156933043152094\n",
      "Steps:  52%|▌| 7778/15000 [1:06:32<21:38,  5.56it/s, lr=0.00097, step_loss=0.10607/27/2023 18:51:22 - INFO - __main__ - train loss is 26.39431319013238\n",
      "Steps:  52%|▌| 7779/15000 [1:06:32<21:38,  5.56it/s, lr=0.00097, step_loss=0.23707/27/2023 18:51:22 - INFO - __main__ - train loss is 26.49004776403308\n",
      "Steps:  52%|▌| 7780/15000 [1:06:32<21:37,  5.57it/s, lr=0.000971, step_loss=0.0907/27/2023 18:51:22 - INFO - __main__ - train loss is 26.83099151775241\n",
      "Steps:  52%|▌| 7781/15000 [1:06:32<21:37,  5.57it/s, lr=0.000971, step_loss=0.3407/27/2023 18:51:22 - INFO - __main__ - train loss is 26.83733136765659\n",
      "Steps:  52%|▌| 7782/15000 [1:06:33<21:37,  5.56it/s, lr=0.000971, step_loss=0.0007/27/2023 18:51:22 - INFO - __main__ - train loss is 26.979559926316142\n",
      "Steps:  52%|▌| 7783/15000 [1:06:33<21:37,  5.56it/s, lr=0.000971, step_loss=0.1407/27/2023 18:51:23 - INFO - __main__ - train loss is 26.981337207602337\n",
      "Steps:  52%|▌| 7784/15000 [1:06:33<21:36,  5.57it/s, lr=0.000971, step_loss=0.0007/27/2023 18:51:23 - INFO - __main__ - train loss is 26.995017471024767\n",
      "Steps:  52%|▌| 7785/15000 [1:06:33<21:36,  5.57it/s, lr=0.000971, step_loss=0.0107/27/2023 18:51:23 - INFO - __main__ - train loss is 27.041602293262258\n",
      "Steps:  52%|▌| 7786/15000 [1:06:33<21:55,  5.49it/s, lr=0.000971, step_loss=0.0407/27/2023 18:51:23 - INFO - __main__ - train loss is 27.06738070421852\n",
      "Steps:  52%|▌| 7787/15000 [1:06:33<21:48,  5.51it/s, lr=0.000971, step_loss=0.0207/27/2023 18:51:23 - INFO - __main__ - train loss is 27.530043103033677\n",
      "Steps:  52%|▌| 7788/15000 [1:06:34<21:44,  5.53it/s, lr=0.000972, step_loss=0.4607/27/2023 18:51:24 - INFO - __main__ - train loss is 27.55836352170445\n",
      "Steps:  52%|▌| 7789/15000 [1:06:34<21:42,  5.54it/s, lr=0.000972, step_loss=0.0207/27/2023 18:51:24 - INFO - __main__ - train loss is 27.560988276498392\n",
      "Steps:  52%|▌| 7790/15000 [1:06:34<21:39,  5.55it/s, lr=0.000972, step_loss=0.0007/27/2023 18:51:24 - INFO - __main__ - train loss is 27.56284196639899\n",
      "Steps:  52%|▌| 7791/15000 [1:06:34<21:38,  5.55it/s, lr=0.000972, step_loss=0.0007/27/2023 18:51:24 - INFO - __main__ - train loss is 27.564883529325016\n",
      "Steps:  52%|▌| 7792/15000 [1:06:34<21:37,  5.56it/s, lr=0.000972, step_loss=0.0007/27/2023 18:51:24 - INFO - __main__ - train loss is 27.588235077564605\n",
      "Steps:  52%|▌| 7793/15000 [1:06:35<21:36,  5.56it/s, lr=0.000972, step_loss=0.0207/27/2023 18:51:24 - INFO - __main__ - train loss is 27.775805202429183\n",
      "Steps:  52%|▌| 7794/15000 [1:06:35<21:36,  5.56it/s, lr=0.000972, step_loss=0.1807/27/2023 18:51:25 - INFO - __main__ - train loss is 27.811124396626838\n",
      "Steps:  52%|▌| 7795/15000 [1:06:35<21:36,  5.56it/s, lr=0.000972, step_loss=0.0307/27/2023 18:51:25 - INFO - __main__ - train loss is 28.01061802834738\n",
      "Steps:  52%|▌| 7796/15000 [1:06:35<21:36,  5.56it/s, lr=0.000973, step_loss=0.1907/27/2023 18:51:25 - INFO - __main__ - train loss is 28.015584500622936\n",
      "Steps:  52%|▌| 7797/15000 [1:06:35<21:35,  5.56it/s, lr=0.000973, step_loss=0.0007/27/2023 18:51:25 - INFO - __main__ - train loss is 28.0489151236834\n",
      "Steps:  52%|▌| 7798/15000 [1:06:35<21:35,  5.56it/s, lr=0.000973, step_loss=0.0307/27/2023 18:51:25 - INFO - __main__ - train loss is 28.06084642012138\n",
      "Steps:  52%|▌| 7799/15000 [1:06:36<21:35,  5.56it/s, lr=0.000973, step_loss=0.0107/27/2023 18:51:25 - INFO - __main__ - train loss is 28.106664067250676\n",
      "Steps:  52%|▌| 7800/15000 [1:06:36<21:34,  5.56it/s, lr=0.000973, step_loss=0.0407/27/2023 18:51:26 - INFO - __main__ - train loss is 28.116300402325578\n",
      "Steps:  52%|▌| 7801/15000 [1:06:36<21:35,  5.56it/s, lr=0.000973, step_loss=0.0007/27/2023 18:51:26 - INFO - __main__ - train loss is 28.285838825744577\n",
      "Steps:  52%|▌| 7802/15000 [1:06:36<21:35,  5.56it/s, lr=0.000973, step_loss=0.1707/27/2023 18:51:26 - INFO - __main__ - train loss is 28.54057352070231\n",
      "Steps:  52%|▌| 7803/15000 [1:06:36<21:34,  5.56it/s, lr=0.000973, step_loss=0.2507/27/2023 18:51:26 - INFO - __main__ - train loss is 28.9019921553554\n",
      "Steps:  52%|▌| 7804/15000 [1:06:37<21:34,  5.56it/s, lr=0.000974, step_loss=0.3607/27/2023 18:51:26 - INFO - __main__ - train loss is 29.00625027541537\n",
      "Steps:  52%|▌| 7805/15000 [1:06:37<21:34,  5.56it/s, lr=0.000974, step_loss=0.1007/27/2023 18:51:27 - INFO - __main__ - train loss is 29.053184175980277\n",
      "Steps:  52%|▌| 7806/15000 [1:06:37<21:33,  5.56it/s, lr=0.000974, step_loss=0.0407/27/2023 18:51:27 - INFO - __main__ - train loss is 29.099579064291902\n",
      "Steps:  52%|▌| 7807/15000 [1:06:37<21:33,  5.56it/s, lr=0.000974, step_loss=0.0407/27/2023 18:51:27 - INFO - __main__ - train loss is 29.3140812945785\n",
      "Steps:  52%|▌| 7808/15000 [1:06:37<21:32,  5.56it/s, lr=0.000974, step_loss=0.2107/27/2023 18:51:27 - INFO - __main__ - train loss is 29.62534673337359\n",
      "Steps:  52%|▌| 7809/15000 [1:06:37<21:54,  5.47it/s, lr=0.000974, step_loss=0.3107/27/2023 18:51:27 - INFO - __main__ - train loss is 29.645552801084705\n",
      "Steps:  52%|▌| 7810/15000 [1:06:38<22:24,  5.35it/s, lr=0.000974, step_loss=0.0207/27/2023 18:51:27 - INFO - __main__ - train loss is 29.881105231237598\n",
      "Steps:  52%|▌| 7811/15000 [1:06:38<22:43,  5.27it/s, lr=0.000974, step_loss=0.2307/27/2023 18:51:28 - INFO - __main__ - train loss is 29.99906513292808\n",
      "Steps:  52%|▌| 7812/15000 [1:06:38<23:00,  5.21it/s, lr=0.000975, step_loss=0.1107/27/2023 18:51:28 - INFO - __main__ - train loss is 30.054054128122516\n",
      "Steps:  52%|▌| 7813/15000 [1:06:38<22:57,  5.22it/s, lr=0.000975, step_loss=0.0507/27/2023 18:51:28 - INFO - __main__ - train loss is 30.18440655071754\n",
      "Steps:  52%|▌| 7814/15000 [1:06:38<22:44,  5.27it/s, lr=0.000975, step_loss=0.1307/27/2023 18:51:28 - INFO - __main__ - train loss is 30.243012307328172\n",
      "Steps:  52%|▌| 7815/15000 [1:06:39<22:29,  5.32it/s, lr=0.000975, step_loss=0.0507/27/2023 18:51:28 - INFO - __main__ - train loss is 30.38020896736998\n",
      "Steps:  52%|▌| 7816/15000 [1:06:39<22:33,  5.31it/s, lr=0.000975, step_loss=0.1307/27/2023 18:51:29 - INFO - __main__ - train loss is 30.741980521124788\n",
      "Steps:  52%|▌| 7817/15000 [1:06:39<22:21,  5.35it/s, lr=0.000975, step_loss=0.3607/27/2023 18:51:29 - INFO - __main__ - train loss is 30.75514009979088\n",
      "Steps:  52%|▌| 7818/15000 [1:06:39<22:15,  5.38it/s, lr=0.000975, step_loss=0.0107/27/2023 18:51:29 - INFO - __main__ - train loss is 30.898474309709854\n",
      "Steps:  52%|▌| 7819/15000 [1:06:39<22:22,  5.35it/s, lr=0.000975, step_loss=0.1407/27/2023 18:51:29 - INFO - __main__ - train loss is 30.938194606569596\n",
      "Steps:  52%|▌| 7820/15000 [1:06:40<22:39,  5.28it/s, lr=0.000976, step_loss=0.0307/27/2023 18:51:29 - INFO - __main__ - train loss is 31.37611666705925\n",
      "Steps:  52%|▌| 7821/15000 [1:06:40<22:33,  5.30it/s, lr=0.000976, step_loss=0.4307/27/2023 18:51:30 - INFO - __main__ - train loss is 31.61273885157425\n",
      "Steps:  52%|▌| 7822/15000 [1:06:40<23:02,  5.19it/s, lr=0.000976, step_loss=0.2307/27/2023 18:51:30 - INFO - __main__ - train loss is 31.71206653502304\n",
      "Steps:  52%|▌| 7823/15000 [1:06:40<22:54,  5.22it/s, lr=0.000976, step_loss=0.0907/27/2023 18:51:30 - INFO - __main__ - train loss is 31.719146237359382\n",
      "Steps:  52%|▌| 7824/15000 [1:06:40<22:39,  5.28it/s, lr=0.000976, step_loss=0.0007/27/2023 18:51:30 - INFO - __main__ - train loss is 31.833953396067955\n",
      "Steps:  52%|▌| 7825/15000 [1:06:40<22:48,  5.24it/s, lr=0.000976, step_loss=0.1107/27/2023 18:51:30 - INFO - __main__ - train loss is 32.09482722042594\n",
      "Steps:  52%|▌| 7826/15000 [1:06:41<22:58,  5.21it/s, lr=0.000976, step_loss=0.2607/27/2023 18:51:31 - INFO - __main__ - train loss is 32.10655570181552\n",
      "Steps:  52%|▌| 7827/15000 [1:06:41<23:06,  5.17it/s, lr=0.000976, step_loss=0.0107/27/2023 18:51:31 - INFO - __main__ - train loss is 32.113369696890004\n",
      "Steps:  52%|▌| 7828/15000 [1:06:41<23:11,  5.16it/s, lr=0.000977, step_loss=0.0007/27/2023 18:51:31 - INFO - __main__ - train loss is 32.34362187341321\n",
      "Steps:  52%|▌| 7829/15000 [1:06:41<23:17,  5.13it/s, lr=0.000977, step_loss=0.2307/27/2023 18:51:31 - INFO - __main__ - train loss is 32.36206111044157\n",
      "Steps:  52%|▌| 7830/15000 [1:06:41<23:17,  5.13it/s, lr=0.000977, step_loss=0.0107/27/2023 18:51:31 - INFO - __main__ - train loss is 32.65529408783186\n",
      "Steps:  52%|▌| 7831/15000 [1:06:42<23:18,  5.13it/s, lr=0.000977, step_loss=0.2907/27/2023 18:51:32 - INFO - __main__ - train loss is 32.65762979129795\n",
      "Steps:  52%|▌| 7832/15000 [1:06:42<23:19,  5.12it/s, lr=0.000977, step_loss=0.0007/27/2023 18:51:32 - INFO - __main__ - train loss is 33.085086498060264\n",
      "Steps:  52%|▌| 7833/15000 [1:06:42<23:37,  5.06it/s, lr=0.000977, step_loss=0.4207/27/2023 18:51:32 - INFO - __main__ - train loss is 33.18525116483215\n",
      "Steps:  52%|▌| 7834/15000 [1:06:42<23:33,  5.07it/s, lr=0.000977, step_loss=0.1]07/27/2023 18:51:32 - INFO - __main__ - train loss is 33.207724988111295\n",
      "Steps:  52%|▌| 7835/15000 [1:06:42<23:30,  5.08it/s, lr=0.000977, step_loss=0.0207/27/2023 18:51:32 - INFO - __main__ - train loss is 33.48584613169078\n",
      "Steps:  52%|▌| 7836/15000 [1:06:43<23:27,  5.09it/s, lr=0.000978, step_loss=0.2707/27/2023 18:51:33 - INFO - __main__ - train loss is 33.838540792115964\n",
      "Steps:  52%|▌| 7837/15000 [1:06:43<23:25,  5.10it/s, lr=0.000978, step_loss=0.3507/27/2023 18:51:33 - INFO - __main__ - train loss is 33.955702840932645\n",
      "Steps:  52%|▌| 7838/15000 [1:06:43<23:24,  5.10it/s, lr=0.000978, step_loss=0.1107/27/2023 18:51:33 - INFO - __main__ - train loss is 33.96453779900912\n",
      "Steps:  52%|▌| 7839/15000 [1:06:43<23:23,  5.10it/s, lr=0.000978, step_loss=0.0007/27/2023 18:51:33 - INFO - __main__ - train loss is 34.525880932458676\n",
      "Steps:  52%|▌| 7840/15000 [1:06:43<23:23,  5.10it/s, lr=0.000978, step_loss=0.5607/27/2023 18:51:33 - INFO - __main__ - train loss is 34.688369214185514\n",
      "Steps:  52%|▌| 7841/15000 [1:06:44<23:25,  5.09it/s, lr=0.000978, step_loss=0.1607/27/2023 18:51:33 - INFO - __main__ - train loss is 34.693406121456064\n",
      "Steps:  52%|▌| 7842/15000 [1:06:44<23:24,  5.10it/s, lr=0.000978, step_loss=0.0007/27/2023 18:51:34 - INFO - __main__ - train loss is 34.84986625763122\n",
      "Steps:  52%|▌| 7843/15000 [1:06:44<23:26,  5.09it/s, lr=0.000978, step_loss=0.1507/27/2023 18:51:34 - INFO - __main__ - train loss is 35.13259808870498\n",
      "Steps:  52%|▌| 7844/15000 [1:06:44<23:24,  5.09it/s, lr=0.000978, step_loss=0.2807/27/2023 18:51:34 - INFO - __main__ - train loss is 35.34540794941131\n",
      "Steps:  52%|▌| 7845/15000 [1:06:44<23:22,  5.10it/s, lr=0.000979, step_loss=0.2107/27/2023 18:51:34 - INFO - __main__ - train loss is 35.37132102961186\n",
      "Steps:  52%|▌| 7846/15000 [1:06:45<23:21,  5.10it/s, lr=0.000979, step_loss=0.0207/27/2023 18:51:34 - INFO - __main__ - train loss is 35.59415175730828\n",
      "Steps:  52%|▌| 7847/15000 [1:06:45<23:20,  5.11it/s, lr=0.000979, step_loss=0.2207/27/2023 18:51:35 - INFO - __main__ - train loss is 35.62689941714052\n",
      "Steps:  52%|▌| 7848/15000 [1:06:45<23:19,  5.11it/s, lr=0.000979, step_loss=0.0307/27/2023 18:51:35 - INFO - __main__ - train loss is 35.8094004947925\n",
      "Steps:  52%|▌| 7849/15000 [1:06:45<23:21,  5.10it/s, lr=0.000979, step_loss=0.1807/27/2023 18:51:35 - INFO - __main__ - train loss is 35.819432939984836\n",
      "Steps:  52%|▌| 7850/15000 [1:06:45<23:20,  5.10it/s, lr=0.000979, step_loss=0.0107/27/2023 18:51:35 - INFO - __main__ - train loss is 35.96867696533445\n",
      "Steps:  52%|▌| 7851/15000 [1:06:46<23:29,  5.07it/s, lr=0.000979, step_loss=0.1407/27/2023 18:51:35 - INFO - __main__ - train loss is 35.97777215356473\n",
      "Steps:  52%|▌| 7852/15000 [1:06:46<23:24,  5.09it/s, lr=0.00098, step_loss=0.00907/27/2023 18:51:36 - INFO - __main__ - train loss is 36.2293784689391\n",
      "Steps:  52%|▌| 7853/15000 [1:06:46<23:25,  5.09it/s, lr=0.00098, step_loss=0.25207/27/2023 18:51:36 - INFO - __main__ - train loss is 36.53271091694478\n",
      "Steps:  52%|▌| 7854/15000 [1:06:46<23:17,  5.11it/s, lr=0.00098, step_loss=0.30307/27/2023 18:51:36 - INFO - __main__ - train loss is 36.553382549085654\n",
      "Steps:  52%|▌| 7855/15000 [1:06:46<23:23,  5.09it/s, lr=0.00098, step_loss=0.02007/27/2023 18:51:36 - INFO - __main__ - train loss is 36.6662622425938\n",
      "Steps:  52%|▌| 7856/15000 [1:06:47<23:24,  5.08it/s, lr=0.00098, step_loss=0.11307/27/2023 18:51:36 - INFO - __main__ - train loss is 36.70110628346447\n",
      "Steps:  52%|▌| 7857/15000 [1:06:47<23:22,  5.09it/s, lr=0.00098, step_loss=0.03407/27/2023 18:51:37 - INFO - __main__ - train loss is 36.70772459509317\n",
      "Steps:  52%|▌| 7858/15000 [1:06:47<23:23,  5.09it/s, lr=0.00098, step_loss=0.00607/27/2023 18:51:37 - INFO - __main__ - train loss is 36.74053128215019\n",
      "Steps:  52%|▌| 7859/15000 [1:06:47<23:22,  5.09it/s, lr=0.00098, step_loss=0.03207/27/2023 18:51:37 - INFO - __main__ - train loss is 36.94878903182689\n",
      "Steps:  52%|▌| 7860/15000 [1:06:47<23:01,  5.17it/s, lr=0.000981, step_loss=0.2007/27/2023 18:51:37 - INFO - __main__ - train loss is 36.95035707869101\n",
      "Steps:  52%|▌| 7861/15000 [1:06:48<22:40,  5.25it/s, lr=0.000981, step_loss=0.0007/27/2023 18:51:37 - INFO - __main__ - train loss is 37.05549250461627\n",
      "Steps:  52%|▌| 7862/15000 [1:06:48<22:16,  5.34it/s, lr=0.000981, step_loss=0.1007/27/2023 18:51:38 - INFO - __main__ - train loss is 37.0588232743321\n",
      "Steps:  52%|▌| 7863/15000 [1:06:48<21:58,  5.41it/s, lr=0.000981, step_loss=0.0007/27/2023 18:51:38 - INFO - __main__ - train loss is 37.06083535181824\n",
      "Steps:  52%|▌| 7864/15000 [1:06:48<21:45,  5.47it/s, lr=0.000981, step_loss=0.0007/27/2023 18:51:38 - INFO - __main__ - train loss is 37.281994973891415\n",
      "Steps:  52%|▌| 7865/15000 [1:06:48<21:36,  5.50it/s, lr=0.000981, step_loss=0.2207/27/2023 18:51:38 - INFO - __main__ - train loss is 37.28576017811429\n",
      "Steps:  52%|▌| 7866/15000 [1:06:48<21:32,  5.52it/s, lr=0.000981, step_loss=0.0007/27/2023 18:51:38 - INFO - __main__ - train loss is 37.33812447160017\n",
      "Steps:  52%|▌| 7867/15000 [1:06:49<21:27,  5.54it/s, lr=0.000981, step_loss=0.0507/27/2023 18:51:38 - INFO - __main__ - train loss is 37.36670700169634\n",
      "Steps:  52%|▌| 7868/15000 [1:06:49<21:23,  5.56it/s, lr=0.000982, step_loss=0.0207/27/2023 18:51:39 - INFO - __main__ - train loss is 37.40532592765521\n",
      "Steps:  52%|▌| 7869/15000 [1:06:49<21:20,  5.57it/s, lr=0.000982, step_loss=0.0307/27/2023 18:51:39 - INFO - __main__ - train loss is 37.53447700373363\n",
      "Steps:  52%|▌| 7870/15000 [1:06:49<21:20,  5.57it/s, lr=0.000982, step_loss=0.1207/27/2023 18:51:39 - INFO - __main__ - train loss is 37.67176056734752\n",
      "Steps:  52%|▌| 7871/15000 [1:06:49<21:18,  5.57it/s, lr=0.000982, step_loss=0.1307/27/2023 18:51:39 - INFO - __main__ - train loss is 37.88244878582191\n",
      "Steps:  52%|▌| 7872/15000 [1:06:49<21:17,  5.58it/s, lr=0.000982, step_loss=0.2107/27/2023 18:51:39 - INFO - __main__ - train loss is 37.95645909837913\n",
      "Steps:  52%|▌| 7873/15000 [1:06:50<21:16,  5.58it/s, lr=0.000982, step_loss=0.0707/27/2023 18:51:40 - INFO - __main__ - train loss is 37.9714334475575\n",
      "Steps:  52%|▌| 7874/15000 [1:06:50<21:16,  5.58it/s, lr=0.000982, step_loss=0.0107/27/2023 18:51:40 - INFO - __main__ - train loss is 37.99344956304412\n",
      "Steps:  52%|▌| 7875/15000 [1:06:50<21:15,  5.58it/s, lr=0.000982, step_loss=0.0207/27/2023 18:51:40 - INFO - __main__ - train loss is 37.99611766997259\n",
      "Steps:  53%|▌| 7876/15000 [1:06:50<21:15,  5.59it/s, lr=0.000983, step_loss=0.0007/27/2023 18:51:40 - INFO - __main__ - train loss is 38.005298294941895\n",
      "Steps:  53%|▌| 7877/15000 [1:06:50<21:14,  5.59it/s, lr=0.000983, step_loss=0.0007/27/2023 18:51:40 - INFO - __main__ - train loss is 38.01589273835998\n",
      "Steps:  53%|▌| 7878/15000 [1:06:51<29:00,  4.09it/s, lr=0.000983, step_loss=0.0107/27/2023 18:51:42 - INFO - __main__ - Per validation step average loss is 0.003821855876594782\n",
      "07/27/2023 18:51:42 - INFO - __main__ - Cumulative validation average loss is 0.003821855876594782\n",
      "07/27/2023 18:51:42 - INFO - __main__ - Per validation step average loss is 0.013384751975536346\n",
      "07/27/2023 18:51:42 - INFO - __main__ - Cumulative validation average loss is 0.01720660785213113\n",
      "07/27/2023 18:51:42 - INFO - __main__ - Per validation step average loss is 0.06632769852876663\n",
      "07/27/2023 18:51:42 - INFO - __main__ - Cumulative validation average loss is 0.08353430638089776\n",
      "07/27/2023 18:51:43 - INFO - __main__ - Per validation step average loss is 0.003171166405081749\n",
      "07/27/2023 18:51:43 - INFO - __main__ - Cumulative validation average loss is 0.08670547278597951\n",
      "07/27/2023 18:51:43 - INFO - __main__ - Per validation step average loss is 0.005208729766309261\n",
      "07/27/2023 18:51:43 - INFO - __main__ - Cumulative validation average loss is 0.09191420255228877\n",
      "07/27/2023 18:51:44 - INFO - __main__ - Per validation step average loss is 0.002480589086189866\n",
      "07/27/2023 18:51:44 - INFO - __main__ - Cumulative validation average loss is 0.09439479163847864\n",
      "07/27/2023 18:51:44 - INFO - __main__ - Per validation step average loss is 0.06933870911598206\n",
      "07/27/2023 18:51:44 - INFO - __main__ - Cumulative validation average loss is 0.1637335007544607\n",
      "07/27/2023 18:51:44 - INFO - __main__ - Per validation step average loss is 0.01613663136959076\n",
      "07/27/2023 18:51:44 - INFO - __main__ - Cumulative validation average loss is 0.17987013212405145\n",
      "07/27/2023 18:51:45 - INFO - __main__ - Per validation step average loss is 0.0889732614159584\n",
      "07/27/2023 18:51:45 - INFO - __main__ - Cumulative validation average loss is 0.26884339354000986\n",
      "07/27/2023 18:51:45 - INFO - __main__ - Per validation step average loss is 0.34892311692237854\n",
      "07/27/2023 18:51:45 - INFO - __main__ - Cumulative validation average loss is 0.6177665104623884\n",
      "07/27/2023 18:51:46 - INFO - __main__ - Per validation step average loss is 0.007920400239527225\n",
      "07/27/2023 18:51:46 - INFO - __main__ - Cumulative validation average loss is 0.6256869107019156\n",
      "07/27/2023 18:51:46 - INFO - __main__ - Per validation step average loss is 0.25943708419799805\n",
      "07/27/2023 18:51:46 - INFO - __main__ - Cumulative validation average loss is 0.8851239948999137\n",
      "07/27/2023 18:51:47 - INFO - __main__ - Per validation step average loss is 0.1281149685382843\n",
      "07/27/2023 18:51:47 - INFO - __main__ - Cumulative validation average loss is 1.013238963438198\n",
      "07/27/2023 18:51:47 - INFO - __main__ - Per validation step average loss is 0.0362519845366478\n",
      "07/27/2023 18:51:47 - INFO - __main__ - Cumulative validation average loss is 1.0494909479748458\n",
      "07/27/2023 18:51:47 - INFO - __main__ - Per validation step average loss is 0.36079829931259155\n",
      "07/27/2023 18:51:47 - INFO - __main__ - Cumulative validation average loss is 1.4102892472874373\n",
      "07/27/2023 18:51:48 - INFO - __main__ - Per validation step average loss is 0.1974656581878662\n",
      "07/27/2023 18:51:48 - INFO - __main__ - Cumulative validation average loss is 1.6077549054753035\n",
      "07/27/2023 18:51:48 - INFO - __main__ - Per validation step average loss is 0.0195884108543396\n",
      "07/27/2023 18:51:48 - INFO - __main__ - Cumulative validation average loss is 1.6273433163296431\n",
      "07/27/2023 18:51:49 - INFO - __main__ - Per validation step average loss is 0.11670044809579849\n",
      "07/27/2023 18:51:49 - INFO - __main__ - Cumulative validation average loss is 1.7440437644254416\n",
      "07/27/2023 18:51:49 - INFO - __main__ - Per validation step average loss is 0.004129266366362572\n",
      "07/27/2023 18:51:49 - INFO - __main__ - Cumulative validation average loss is 1.7481730307918042\n",
      "07/27/2023 18:51:49 - INFO - __main__ - Per validation step average loss is 0.13532334566116333\n",
      "07/27/2023 18:51:49 - INFO - __main__ - Cumulative validation average loss is 1.8834963764529675\n",
      "07/27/2023 18:51:50 - INFO - __main__ - Per validation step average loss is 0.13152353465557098\n",
      "07/27/2023 18:51:50 - INFO - __main__ - Cumulative validation average loss is 2.0150199111085385\n",
      "07/27/2023 18:51:50 - INFO - __main__ - Per validation step average loss is 0.026058178395032883\n",
      "07/27/2023 18:51:50 - INFO - __main__ - Cumulative validation average loss is 2.0410780895035714\n",
      "07/27/2023 18:51:51 - INFO - __main__ - Per validation step average loss is 0.011711223050951958\n",
      "07/27/2023 18:51:51 - INFO - __main__ - Cumulative validation average loss is 2.0527893125545233\n",
      "07/27/2023 18:51:51 - INFO - __main__ - Per validation step average loss is 0.48399829864501953\n",
      "07/27/2023 18:51:51 - INFO - __main__ - Cumulative validation average loss is 2.536787611199543\n",
      "07/27/2023 18:51:52 - INFO - __main__ - Per validation step average loss is 0.31865718960762024\n",
      "07/27/2023 18:51:52 - INFO - __main__ - Cumulative validation average loss is 2.855444800807163\n",
      "07/27/2023 18:51:52 - INFO - __main__ - Per validation step average loss is 0.1270979642868042\n",
      "07/27/2023 18:51:52 - INFO - __main__ - Cumulative validation average loss is 2.9825427650939673\n",
      "07/27/2023 18:51:52 - INFO - __main__ - Per validation step average loss is 0.038568515330553055\n",
      "07/27/2023 18:51:52 - INFO - __main__ - Cumulative validation average loss is 3.0211112804245204\n",
      "07/27/2023 18:51:53 - INFO - __main__ - Per validation step average loss is 0.01988164521753788\n",
      "07/27/2023 18:51:53 - INFO - __main__ - Cumulative validation average loss is 3.0409929256420583\n",
      "07/27/2023 18:51:53 - INFO - __main__ - Per validation step average loss is 0.06576260924339294\n",
      "07/27/2023 18:51:53 - INFO - __main__ - Cumulative validation average loss is 3.106755534885451\n",
      "07/27/2023 18:51:54 - INFO - __main__ - Per validation step average loss is 0.27887389063835144\n",
      "07/27/2023 18:51:54 - INFO - __main__ - Cumulative validation average loss is 3.3856294255238026\n",
      "07/27/2023 18:51:54 - INFO - __main__ - Per validation step average loss is 0.003402919741347432\n",
      "07/27/2023 18:51:54 - INFO - __main__ - Cumulative validation average loss is 3.38903234526515\n",
      "07/27/2023 18:51:54 - INFO - __main__ - Per validation step average loss is 0.3583044707775116\n",
      "07/27/2023 18:51:54 - INFO - __main__ - Cumulative validation average loss is 3.7473368160426617\n",
      "07/27/2023 18:51:55 - INFO - __main__ - Per validation step average loss is 0.15694943070411682\n",
      "07/27/2023 18:51:55 - INFO - __main__ - Cumulative validation average loss is 3.9042862467467785\n",
      "07/27/2023 18:51:55 - INFO - __main__ - Per validation step average loss is 0.12408283352851868\n",
      "07/27/2023 18:51:55 - INFO - __main__ - Cumulative validation average loss is 4.028369080275297\n",
      "07/27/2023 18:51:56 - INFO - __main__ - Per validation step average loss is 0.7685375213623047\n",
      "07/27/2023 18:51:56 - INFO - __main__ - Cumulative validation average loss is 4.796906601637602\n",
      "07/27/2023 18:51:56 - INFO - __main__ - Per validation step average loss is 0.02672550082206726\n",
      "07/27/2023 18:51:56 - INFO - __main__ - Cumulative validation average loss is 4.823632102459669\n",
      "07/27/2023 18:51:56 - INFO - __main__ - Per validation step average loss is 0.7236003875732422\n",
      "07/27/2023 18:51:56 - INFO - __main__ - Cumulative validation average loss is 5.547232490032911\n",
      "07/27/2023 18:51:57 - INFO - __main__ - Per validation step average loss is 0.13786718249320984\n",
      "07/27/2023 18:51:57 - INFO - __main__ - Cumulative validation average loss is 5.685099672526121\n",
      "07/27/2023 18:51:57 - INFO - __main__ - Per validation step average loss is 0.02762291394174099\n",
      "07/27/2023 18:51:57 - INFO - __main__ - Cumulative validation average loss is 5.712722586467862\n",
      "07/27/2023 18:51:58 - INFO - __main__ - Per validation step average loss is 0.0601080060005188\n",
      "07/27/2023 18:51:58 - INFO - __main__ - Cumulative validation average loss is 5.772830592468381\n",
      "07/27/2023 18:51:58 - INFO - __main__ - Per validation step average loss is 0.001722460612654686\n",
      "07/27/2023 18:51:58 - INFO - __main__ - Cumulative validation average loss is 5.774553053081036\n",
      "07/27/2023 18:51:59 - INFO - __main__ - Per validation step average loss is 0.4563228189945221\n",
      "07/27/2023 18:51:59 - INFO - __main__ - Cumulative validation average loss is 6.230875872075558\n",
      "07/27/2023 18:51:59 - INFO - __main__ - Per validation step average loss is 0.008474553003907204\n",
      "07/27/2023 18:51:59 - INFO - __main__ - Cumulative validation average loss is 6.239350425079465\n",
      "07/27/2023 18:51:59 - INFO - __main__ - Per validation step average loss is 0.2816896438598633\n",
      "07/27/2023 18:51:59 - INFO - __main__ - Cumulative validation average loss is 6.521040068939328\n",
      "07/27/2023 18:52:00 - INFO - __main__ - Per validation step average loss is 0.11601777374744415\n",
      "07/27/2023 18:52:00 - INFO - __main__ - Cumulative validation average loss is 6.637057842686772\n",
      "07/27/2023 18:52:00 - INFO - __main__ - Per validation step average loss is 0.03821834921836853\n",
      "07/27/2023 18:52:00 - INFO - __main__ - Cumulative validation average loss is 6.675276191905141\n",
      "07/27/2023 18:52:01 - INFO - __main__ - Per validation step average loss is 0.010254225693643093\n",
      "07/27/2023 18:52:01 - INFO - __main__ - Cumulative validation average loss is 6.685530417598784\n",
      "07/27/2023 18:52:01 - INFO - __main__ - Per validation step average loss is 0.025402618572115898\n",
      "07/27/2023 18:52:01 - INFO - __main__ - Cumulative validation average loss is 6.7109330361709\n",
      "07/27/2023 18:52:01 - INFO - __main__ - Per validation step average loss is 0.2182069718837738\n",
      "07/27/2023 18:52:01 - INFO - __main__ - Cumulative validation average loss is 6.929140008054674\n",
      "07/27/2023 18:52:02 - INFO - __main__ - Per validation step average loss is 0.08294201642274857\n",
      "07/27/2023 18:52:02 - INFO - __main__ - Cumulative validation average loss is 7.012082024477422\n",
      "07/27/2023 18:52:02 - INFO - __main__ - Per validation step average loss is 0.15331965684890747\n",
      "07/27/2023 18:52:02 - INFO - __main__ - Cumulative validation average loss is 7.16540168132633\n",
      "07/27/2023 18:52:03 - INFO - __main__ - Per validation step average loss is 0.1865759938955307\n",
      "07/27/2023 18:52:03 - INFO - __main__ - Cumulative validation average loss is 7.35197767522186\n",
      "07/27/2023 18:52:03 - INFO - __main__ - Per validation step average loss is 0.11473043262958527\n",
      "07/27/2023 18:52:03 - INFO - __main__ - Cumulative validation average loss is 7.466708107851446\n",
      "07/27/2023 18:52:04 - INFO - __main__ - Per validation step average loss is 0.025949550792574883\n",
      "07/27/2023 18:52:04 - INFO - __main__ - Cumulative validation average loss is 7.492657658644021\n",
      "07/27/2023 18:52:04 - INFO - __main__ - Per validation step average loss is 0.07447728514671326\n",
      "07/27/2023 18:52:04 - INFO - __main__ - Cumulative validation average loss is 7.567134943790734\n",
      "07/27/2023 18:52:04 - INFO - __main__ - Per validation step average loss is 0.08295261859893799\n",
      "07/27/2023 18:52:04 - INFO - __main__ - Cumulative validation average loss is 7.650087562389672\n",
      "07/27/2023 18:52:05 - INFO - __main__ - Per validation step average loss is 0.08786985278129578\n",
      "07/27/2023 18:52:05 - INFO - __main__ - Cumulative validation average loss is 7.737957415170968\n",
      "07/27/2023 18:52:05 - INFO - __main__ - Per validation step average loss is 0.10892078280448914\n",
      "07/27/2023 18:52:05 - INFO - __main__ - Cumulative validation average loss is 7.846878197975457\n",
      "07/27/2023 18:52:06 - INFO - __main__ - Per validation step average loss is 0.1789594143629074\n",
      "07/27/2023 18:52:06 - INFO - __main__ - Cumulative validation average loss is 8.025837612338364\n",
      "07/27/2023 18:52:06 - INFO - __main__ - Per validation step average loss is 0.2785484492778778\n",
      "07/27/2023 18:52:06 - INFO - __main__ - Cumulative validation average loss is 8.304386061616242\n",
      "07/27/2023 18:52:06 - INFO - __main__ - Per validation step average loss is 0.108305424451828\n",
      "07/27/2023 18:52:06 - INFO - __main__ - Cumulative validation average loss is 8.41269148606807\n",
      "07/27/2023 18:52:07 - INFO - __main__ - Per validation step average loss is 0.06216169521212578\n",
      "07/27/2023 18:52:07 - INFO - __main__ - Cumulative validation average loss is 8.474853181280196\n",
      "07/27/2023 18:52:07 - INFO - __main__ - Per validation step average loss is 0.07188019901514053\n",
      "07/27/2023 18:52:07 - INFO - __main__ - Cumulative validation average loss is 8.546733380295336\n",
      "07/27/2023 18:52:08 - INFO - __main__ - Per validation step average loss is 0.16721267998218536\n",
      "07/27/2023 18:52:08 - INFO - __main__ - Cumulative validation average loss is 8.713946060277522\n",
      "07/27/2023 18:52:08 - INFO - __main__ - Per validation step average loss is 0.023880485445261\n",
      "07/27/2023 18:52:08 - INFO - __main__ - Cumulative validation average loss is 8.737826545722783\n",
      "07/27/2023 18:52:08 - INFO - __main__ - Per validation step average loss is 0.029878411442041397\n",
      "07/27/2023 18:52:08 - INFO - __main__ - Cumulative validation average loss is 8.767704957164824\n",
      "07/27/2023 18:52:09 - INFO - __main__ - Per validation step average loss is 0.08403933048248291\n",
      "07/27/2023 18:52:09 - INFO - __main__ - Cumulative validation average loss is 8.851744287647307\n",
      "07/27/2023 18:52:09 - INFO - __main__ - Per validation step average loss is 0.005631226114928722\n",
      "07/27/2023 18:52:09 - INFO - __main__ - Cumulative validation average loss is 8.857375513762236\n",
      "07/27/2023 18:52:10 - INFO - __main__ - Per validation step average loss is 0.05324489623308182\n",
      "07/27/2023 18:52:10 - INFO - __main__ - Cumulative validation average loss is 8.910620409995317\n",
      "07/27/2023 18:52:10 - INFO - __main__ - Per validation step average loss is 0.009637176990509033\n",
      "07/27/2023 18:52:10 - INFO - __main__ - Cumulative validation average loss is 8.920257586985826\n",
      "07/27/2023 18:52:11 - INFO - __main__ - Per validation step average loss is 0.011887378990650177\n",
      "07/27/2023 18:52:11 - INFO - __main__ - Cumulative validation average loss is 8.932144965976477\n",
      "07/27/2023 18:52:11 - INFO - __main__ - Per validation step average loss is 0.21246972680091858\n",
      "07/27/2023 18:52:11 - INFO - __main__ - Cumulative validation average loss is 9.144614692777395\n",
      "07/27/2023 18:52:11 - INFO - __main__ - Per validation step average loss is 0.007531627081334591\n",
      "07/27/2023 18:52:11 - INFO - __main__ - Cumulative validation average loss is 9.15214631985873\n",
      "07/27/2023 18:52:12 - INFO - __main__ - Per validation step average loss is 0.149500772356987\n",
      "07/27/2023 18:52:12 - INFO - __main__ - Cumulative validation average loss is 9.301647092215717\n",
      "07/27/2023 18:52:12 - INFO - __main__ - Per validation step average loss is 0.0032767322845757008\n",
      "07/27/2023 18:52:12 - INFO - __main__ - Cumulative validation average loss is 9.304923824500293\n",
      "07/27/2023 18:52:13 - INFO - __main__ - Per validation step average loss is 0.2875823378562927\n",
      "07/27/2023 18:52:13 - INFO - __main__ - Cumulative validation average loss is 9.592506162356585\n",
      "07/27/2023 18:52:13 - INFO - __main__ - Per validation step average loss is 0.01179688610136509\n",
      "07/27/2023 18:52:13 - INFO - __main__ - Cumulative validation average loss is 9.60430304845795\n",
      "07/27/2023 18:52:13 - INFO - __main__ - Per validation step average loss is 0.03029695898294449\n",
      "07/27/2023 18:52:13 - INFO - __main__ - Cumulative validation average loss is 9.634600007440895\n",
      "07/27/2023 18:52:14 - INFO - __main__ - Per validation step average loss is 0.08400855958461761\n",
      "07/27/2023 18:52:14 - INFO - __main__ - Cumulative validation average loss is 9.718608567025512\n",
      "07/27/2023 18:52:14 - INFO - __main__ - Average validation loss for Epoch 25 is 0.12302036160791788\n",
      "07/27/2023 18:52:14 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:53:11 - INFO - __main__ - Starting epoch 26\n",
      "07/27/2023 18:53:12 - INFO - __main__ - train loss is 0.059524860233068466\n",
      "Steps:  53%|▌| 7879/15000 [1:08:22<54:46:03, 27.69s/it, lr=0.000983, step_loss=007/27/2023 18:53:12 - INFO - __main__ - train loss is 0.06740338541567326\n",
      "Steps:  53%|▌| 7880/15000 [1:08:23<38:26:18, 19.44s/it, lr=0.000983, step_loss=007/27/2023 18:53:13 - INFO - __main__ - train loss is 0.15089617855846882\n",
      "Steps:  53%|▌| 7881/15000 [1:08:23<27:00:39, 13.66s/it, lr=0.000983, step_loss=007/27/2023 18:53:13 - INFO - __main__ - train loss is 0.24891566671431065\n",
      "Steps:  53%|▌| 7882/15000 [1:08:23<19:00:40,  9.62s/it, lr=0.000983, step_loss=007/27/2023 18:53:13 - INFO - __main__ - train loss is 0.4466035459190607\n",
      "Steps:  53%|▌| 7883/15000 [1:08:23<13:24:43,  6.78s/it, lr=0.000983, step_loss=007/27/2023 18:53:13 - INFO - __main__ - train loss is 0.6699284706264734\n",
      "Steps:  53%|▌| 7884/15000 [1:08:23<9:29:35,  4.80s/it, lr=0.000983, step_loss=0.07/27/2023 18:53:13 - INFO - __main__ - train loss is 1.3464287910610437\n",
      "Steps:  53%|▌| 7885/15000 [1:08:24<6:45:04,  3.42s/it, lr=0.000984, step_loss=0.07/27/2023 18:53:13 - INFO - __main__ - train loss is 1.5913274977356195\n",
      "Steps:  53%|▌| 7886/15000 [1:08:24<4:49:52,  2.44s/it, lr=0.000984, step_loss=0.07/27/2023 18:53:14 - INFO - __main__ - train loss is 1.607272082939744\n",
      "Steps:  53%|▌| 7887/15000 [1:08:24<3:29:15,  1.77s/it, lr=0.000984, step_loss=0.07/27/2023 18:53:14 - INFO - __main__ - train loss is 1.6180120650678873\n",
      "Steps:  53%|▌| 7888/15000 [1:08:24<2:33:00,  1.29s/it, lr=0.000984, step_loss=0.07/27/2023 18:53:14 - INFO - __main__ - train loss is 1.7060070279985666\n",
      "Steps:  53%|▌| 7889/15000 [1:08:24<1:56:46,  1.01it/s, lr=0.000984, step_loss=0.07/27/2023 18:53:14 - INFO - __main__ - train loss is 1.7098493939265609\n",
      "Steps:  53%|▌| 7890/15000 [1:08:25<1:28:47,  1.33it/s, lr=0.000984, step_loss=0.07/27/2023 18:53:14 - INFO - __main__ - train loss is 2.051590329967439\n",
      "Steps:  53%|▌| 7891/15000 [1:08:25<1:09:24,  1.71it/s, lr=0.000984, step_loss=0.07/27/2023 18:53:15 - INFO - __main__ - train loss is 2.0555527289398015\n",
      "Steps:  53%|▌| 7892/15000 [1:08:25<55:08,  2.15it/s, lr=0.000985, step_loss=0.0007/27/2023 18:53:15 - INFO - __main__ - train loss is 2.05866942089051\n",
      "Steps:  53%|▌| 7893/15000 [1:08:25<44:59,  2.63it/s, lr=0.000985, step_loss=0.0007/27/2023 18:53:15 - INFO - __main__ - train loss is 2.175373229198158\n",
      "Steps:  53%|▌| 7894/15000 [1:08:25<37:54,  3.12it/s, lr=0.000985, step_loss=0.1107/27/2023 18:53:15 - INFO - __main__ - train loss is 2.178233085665852\n",
      "Steps:  53%|▌| 7895/15000 [1:08:26<32:53,  3.60it/s, lr=0.000985, step_loss=0.0007/27/2023 18:53:15 - INFO - __main__ - train loss is 2.5474917576648295\n",
      "Steps:  53%|▌| 7896/15000 [1:08:26<29:24,  4.03it/s, lr=0.000985, step_loss=0.3607/27/2023 18:53:16 - INFO - __main__ - train loss is 2.7607399211265147\n",
      "Steps:  53%|▌| 7897/15000 [1:08:26<26:57,  4.39it/s, lr=0.000985, step_loss=0.2107/27/2023 18:53:16 - INFO - __main__ - train loss is 2.7631093496456742\n",
      "Steps:  53%|▌| 7898/15000 [1:08:26<25:14,  4.69it/s, lr=0.000985, step_loss=0.0007/27/2023 18:53:16 - INFO - __main__ - train loss is 2.9958405727520585\n",
      "Steps:  53%|▌| 7899/15000 [1:08:26<24:03,  4.92it/s, lr=0.000985, step_loss=0.2307/27/2023 18:53:16 - INFO - __main__ - train loss is 2.998319759964943\n",
      "Steps:  53%|▌| 7900/15000 [1:08:26<23:14,  5.09it/s, lr=0.000986, step_loss=0.0007/27/2023 18:53:16 - INFO - __main__ - train loss is 3.138982802629471\n",
      "Steps:  53%|▌| 7901/15000 [1:08:27<22:39,  5.22it/s, lr=0.000986, step_loss=0.1407/27/2023 18:53:16 - INFO - __main__ - train loss is 3.144773503765464\n",
      "Steps:  53%|▌| 7902/15000 [1:08:27<22:13,  5.32it/s, lr=0.000986, step_loss=0.0007/27/2023 18:53:17 - INFO - __main__ - train loss is 3.1559175960719585\n",
      "Steps:  53%|▌| 7903/15000 [1:08:27<21:55,  5.40it/s, lr=0.000986, step_loss=0.0107/27/2023 18:53:17 - INFO - __main__ - train loss is 3.1986957378685474\n",
      "Steps:  53%|▌| 7904/15000 [1:08:27<21:42,  5.45it/s, lr=0.000986, step_loss=0.0407/27/2023 18:53:17 - INFO - __main__ - train loss is 3.3702042140066624\n",
      "Steps:  53%|▌| 7905/15000 [1:08:27<21:32,  5.49it/s, lr=0.000986, step_loss=0.1707/27/2023 18:53:17 - INFO - __main__ - train loss is 3.4200387187302113\n",
      "Steps:  53%|▌| 7906/15000 [1:08:27<21:26,  5.51it/s, lr=0.000986, step_loss=0.0407/27/2023 18:53:17 - INFO - __main__ - train loss is 3.4276870181784034\n",
      "Steps:  53%|▌| 7907/15000 [1:08:28<21:22,  5.53it/s, lr=0.000986, step_loss=0.0007/27/2023 18:53:18 - INFO - __main__ - train loss is 3.4320334726944566\n",
      "Steps:  53%|▌| 7908/15000 [1:08:28<21:30,  5.50it/s, lr=0.000986, step_loss=0.0007/27/2023 18:53:18 - INFO - __main__ - train loss is 3.734356158412993\n",
      "Steps:  53%|▌| 7909/15000 [1:08:28<21:26,  5.51it/s, lr=0.000987, step_loss=0.3007/27/2023 18:53:18 - INFO - __main__ - train loss is 4.276713007129729\n",
      "Steps:  53%|▌| 7910/15000 [1:08:28<21:22,  5.53it/s, lr=0.000987, step_loss=0.5407/27/2023 18:53:18 - INFO - __main__ - train loss is 4.471038036979735\n",
      "Steps:  53%|▌| 7911/15000 [1:08:28<21:19,  5.54it/s, lr=0.000987, step_loss=0.1907/27/2023 18:53:18 - INFO - __main__ - train loss is 4.610406749881804\n",
      "Steps:  53%|▌| 7912/15000 [1:08:29<21:18,  5.55it/s, lr=0.000987, step_loss=0.1307/27/2023 18:53:18 - INFO - __main__ - train loss is 4.824886583723128\n",
      "Steps:  53%|▌| 7913/15000 [1:08:29<21:16,  5.55it/s, lr=0.000987, step_loss=0.2107/27/2023 18:53:19 - INFO - __main__ - train loss is 4.828944863751531\n",
      "Steps:  53%|▌| 7914/15000 [1:08:29<21:15,  5.56it/s, lr=0.000987, step_loss=0.0007/27/2023 18:53:19 - INFO - __main__ - train loss is 4.83120894129388\n",
      "Steps:  53%|▌| 7915/15000 [1:08:29<21:14,  5.56it/s, lr=0.000987, step_loss=0.0007/27/2023 18:53:19 - INFO - __main__ - train loss is 4.872908142162487\n",
      "Steps:  53%|▌| 7916/15000 [1:08:29<21:13,  5.56it/s, lr=0.000988, step_loss=0.0407/27/2023 18:53:19 - INFO - __main__ - train loss is 4.914204344851896\n",
      "Steps:  53%|▌| 7917/15000 [1:08:29<21:12,  5.57it/s, lr=0.000988, step_loss=0.0407/27/2023 18:53:19 - INFO - __main__ - train loss is 4.986969993216917\n",
      "Steps:  53%|▌| 7918/15000 [1:08:30<21:12,  5.56it/s, lr=0.000988, step_loss=0.0707/27/2023 18:53:20 - INFO - __main__ - train loss is 5.311576352221891\n",
      "Steps:  53%|▌| 7919/15000 [1:08:30<21:13,  5.56it/s, lr=0.000988, step_loss=0.3207/27/2023 18:53:20 - INFO - __main__ - train loss is 5.392938644392416\n",
      "Steps:  53%|▌| 7920/15000 [1:08:30<21:12,  5.56it/s, lr=0.000988, step_loss=0.0807/27/2023 18:53:20 - INFO - __main__ - train loss is 5.429729097289965\n",
      "Steps:  53%|▌| 7921/15000 [1:08:30<21:10,  5.57it/s, lr=0.000988, step_loss=0.0307/27/2023 18:53:20 - INFO - __main__ - train loss is 5.53943218360655\n",
      "Steps:  53%|▌| 7922/15000 [1:08:30<21:11,  5.57it/s, lr=0.000988, step_loss=0.1107/27/2023 18:53:20 - INFO - __main__ - train loss is 5.74792091618292\n",
      "Steps:  53%|▌| 7923/15000 [1:08:31<21:11,  5.57it/s, lr=0.000988, step_loss=0.2007/27/2023 18:53:20 - INFO - __main__ - train loss is 5.7550055149476975\n",
      "Steps:  53%|▌| 7924/15000 [1:08:31<21:11,  5.57it/s, lr=0.000989, step_loss=0.0007/27/2023 18:53:21 - INFO - __main__ - train loss is 5.762718379730359\n",
      "Steps:  53%|▌| 7925/15000 [1:08:31<21:12,  5.56it/s, lr=0.000989, step_loss=0.0007/27/2023 18:53:21 - INFO - __main__ - train loss is 5.819147609407082\n",
      "Steps:  53%|▌| 7926/15000 [1:08:31<21:11,  5.56it/s, lr=0.000989, step_loss=0.0507/27/2023 18:53:21 - INFO - __main__ - train loss is 5.834725093329325\n",
      "Steps:  53%|▌| 7927/15000 [1:08:31<21:12,  5.56it/s, lr=0.000989, step_loss=0.0107/27/2023 18:53:21 - INFO - __main__ - train loss is 6.174656909191981\n",
      "Steps:  53%|▌| 7928/15000 [1:08:31<21:11,  5.56it/s, lr=0.000989, step_loss=0.3407/27/2023 18:53:21 - INFO - __main__ - train loss is 6.216391887748614\n",
      "Steps:  53%|▌| 7929/15000 [1:08:32<21:10,  5.57it/s, lr=0.000989, step_loss=0.0407/27/2023 18:53:22 - INFO - __main__ - train loss is 6.277600284898654\n",
      "Steps:  53%|▌| 7930/15000 [1:08:32<21:09,  5.57it/s, lr=0.000989, step_loss=0.0607/27/2023 18:53:22 - INFO - __main__ - train loss is 6.317649957025424\n",
      "Steps:  53%|▌| 7931/15000 [1:08:32<21:10,  5.57it/s, lr=0.000989, step_loss=0.0407/27/2023 18:53:22 - INFO - __main__ - train loss is 6.647230383241549\n",
      "Steps:  53%|▌| 7932/15000 [1:08:32<21:10,  5.57it/s, lr=0.00099, step_loss=0.33]07/27/2023 18:53:22 - INFO - __main__ - train loss is 6.795151677215472\n",
      "Steps:  53%|▌| 7933/15000 [1:08:32<21:09,  5.57it/s, lr=0.00099, step_loss=0.14807/27/2023 18:53:22 - INFO - __main__ - train loss is 6.7991876567248255\n",
      "Steps:  53%|▌| 7934/15000 [1:08:33<21:08,  5.57it/s, lr=0.00099, step_loss=0.00407/27/2023 18:53:22 - INFO - __main__ - train loss is 6.994985398137942\n",
      "Steps:  53%|▌| 7935/15000 [1:08:33<21:07,  5.57it/s, lr=0.00099, step_loss=0.19607/27/2023 18:53:23 - INFO - __main__ - train loss is 7.0066169986967\n",
      "Steps:  53%|▌| 7936/15000 [1:08:33<21:08,  5.57it/s, lr=0.00099, step_loss=0.01107/27/2023 18:53:23 - INFO - __main__ - train loss is 7.216428954387084\n",
      "Steps:  53%|▌| 7937/15000 [1:08:33<21:07,  5.57it/s, lr=0.00099, step_loss=0.21]07/27/2023 18:53:23 - INFO - __main__ - train loss is 7.219391696155071\n",
      "Steps:  53%|▌| 7938/15000 [1:08:33<21:07,  5.57it/s, lr=0.00099, step_loss=0.00207/27/2023 18:53:23 - INFO - __main__ - train loss is 7.398935221135616\n",
      "Steps:  53%|▌| 7939/15000 [1:08:33<21:09,  5.56it/s, lr=0.00099, step_loss=0.18]07/27/2023 18:53:23 - INFO - __main__ - train loss is 7.839183442294598\n",
      "Steps:  53%|▌| 7940/15000 [1:08:34<21:10,  5.56it/s, lr=0.000991, step_loss=0.4407/27/2023 18:53:23 - INFO - __main__ - train loss is 7.9477770403027534\n",
      "Steps:  53%|▌| 7941/15000 [1:08:34<21:09,  5.56it/s, lr=0.000991, step_loss=0.1007/27/2023 18:53:24 - INFO - __main__ - train loss is 8.324317522346973\n",
      "Steps:  53%|▌| 7942/15000 [1:08:34<21:08,  5.56it/s, lr=0.000991, step_loss=0.3707/27/2023 18:53:24 - INFO - __main__ - train loss is 8.327454617712647\n",
      "Steps:  53%|▌| 7943/15000 [1:08:34<21:09,  5.56it/s, lr=0.000991, step_loss=0.0007/27/2023 18:53:24 - INFO - __main__ - train loss is 8.33138454798609\n",
      "Steps:  53%|▌| 7944/15000 [1:08:34<21:08,  5.56it/s, lr=0.000991, step_loss=0.0007/27/2023 18:53:24 - INFO - __main__ - train loss is 8.382779066450894\n",
      "Steps:  53%|▌| 7945/15000 [1:08:35<21:09,  5.56it/s, lr=0.000991, step_loss=0.0507/27/2023 18:53:24 - INFO - __main__ - train loss is 8.386343121062964\n",
      "Steps:  53%|▌| 7946/15000 [1:08:35<21:07,  5.56it/s, lr=0.000991, step_loss=0.0007/27/2023 18:53:25 - INFO - __main__ - train loss is 8.53560110880062\n",
      "Steps:  53%|▌| 7947/15000 [1:08:35<21:10,  5.55it/s, lr=0.000991, step_loss=0.1407/27/2023 18:53:25 - INFO - __main__ - train loss is 8.562421680893749\n",
      "Steps:  53%|▌| 7948/15000 [1:08:35<21:08,  5.56it/s, lr=0.000991, step_loss=0.0207/27/2023 18:53:25 - INFO - __main__ - train loss is 8.719234289135784\n",
      "Steps:  53%|▌| 7949/15000 [1:08:35<21:11,  5.55it/s, lr=0.000992, step_loss=0.1507/27/2023 18:53:25 - INFO - __main__ - train loss is 8.725100725423545\n",
      "Steps:  53%|▌| 7950/15000 [1:08:35<21:10,  5.55it/s, lr=0.000992, step_loss=0.0007/27/2023 18:53:25 - INFO - __main__ - train loss is 8.737025893758982\n",
      "Steps:  53%|▌| 7951/15000 [1:08:36<21:09,  5.55it/s, lr=0.000992, step_loss=0.0107/27/2023 18:53:25 - INFO - __main__ - train loss is 9.018066711258143\n",
      "Steps:  53%|▌| 7952/15000 [1:08:36<21:09,  5.55it/s, lr=0.000992, step_loss=0.2807/27/2023 18:53:26 - INFO - __main__ - train loss is 9.040710566099733\n",
      "Steps:  53%|▌| 7953/15000 [1:08:36<21:08,  5.56it/s, lr=0.000992, step_loss=0.0207/27/2023 18:53:26 - INFO - __main__ - train loss is 9.785047886427492\n",
      "Steps:  53%|▌| 7954/15000 [1:08:36<21:10,  5.54it/s, lr=0.000992, step_loss=0.7407/27/2023 18:53:26 - INFO - __main__ - train loss is 9.787405553739518\n",
      "Steps:  53%|▌| 7955/15000 [1:08:36<21:08,  5.55it/s, lr=0.000992, step_loss=0.0007/27/2023 18:53:26 - INFO - __main__ - train loss is 9.85225499002263\n",
      "Steps:  53%|▌| 7956/15000 [1:08:36<21:07,  5.56it/s, lr=0.000993, step_loss=0.0607/27/2023 18:53:26 - INFO - __main__ - train loss is 10.32134962407872\n",
      "Steps:  53%|▌| 7957/15000 [1:08:37<21:07,  5.56it/s, lr=0.000993, step_loss=0.4607/27/2023 18:53:27 - INFO - __main__ - train loss is 10.427144456189126\n",
      "Steps:  53%|▌| 7958/15000 [1:08:37<21:06,  5.56it/s, lr=0.000993, step_loss=0.1007/27/2023 18:53:27 - INFO - __main__ - train loss is 10.452571158763021\n",
      "Steps:  53%|▌| 7959/15000 [1:08:37<21:07,  5.56it/s, lr=0.000993, step_loss=0.0207/27/2023 18:53:27 - INFO - __main__ - train loss is 10.455984172178432\n",
      "Steps:  53%|▌| 7960/15000 [1:08:37<21:06,  5.56it/s, lr=0.000993, step_loss=0.0007/27/2023 18:53:27 - INFO - __main__ - train loss is 10.605407056165859\n",
      "Steps:  53%|▌| 7961/15000 [1:08:37<21:08,  5.55it/s, lr=0.000993, step_loss=0.1407/27/2023 18:53:27 - INFO - __main__ - train loss is 11.104074475122616\n",
      "Steps:  53%|▌| 7962/15000 [1:08:38<21:19,  5.50it/s, lr=0.000993, step_loss=0.4907/27/2023 18:53:27 - INFO - __main__ - train loss is 11.452333626104519\n",
      "Steps:  53%|▌| 7963/15000 [1:08:38<21:35,  5.43it/s, lr=0.000993, step_loss=0.3407/27/2023 18:53:28 - INFO - __main__ - train loss is 11.662136462284252\n",
      "Steps:  53%|▌| 7964/15000 [1:08:38<22:02,  5.32it/s, lr=0.000994, step_loss=0.2107/27/2023 18:53:28 - INFO - __main__ - train loss is 11.692626029951498\n",
      "Steps:  53%|▌| 7965/15000 [1:08:38<22:16,  5.26it/s, lr=0.000994, step_loss=0.0307/27/2023 18:53:28 - INFO - __main__ - train loss is 12.079983026487753\n",
      "Steps:  53%|▌| 7966/15000 [1:08:38<22:29,  5.21it/s, lr=0.000994, step_loss=0.3807/27/2023 18:53:28 - INFO - __main__ - train loss is 12.081174384220503\n",
      "Steps:  53%|▌| 7967/15000 [1:08:39<22:37,  5.18it/s, lr=0.000994, step_loss=0.0007/27/2023 18:53:28 - INFO - __main__ - train loss is 12.094327823608182\n",
      "Steps:  53%|▌| 7968/15000 [1:08:39<22:42,  5.16it/s, lr=0.000994, step_loss=0.0107/27/2023 18:53:29 - INFO - __main__ - train loss is 12.301420853822492\n",
      "Steps:  53%|▌| 7969/15000 [1:08:39<22:47,  5.14it/s, lr=0.000994, step_loss=0.2007/27/2023 18:53:29 - INFO - __main__ - train loss is 12.303326146444306\n",
      "Steps:  53%|▌| 7970/15000 [1:08:39<22:51,  5.13it/s, lr=0.000994, step_loss=0.0007/27/2023 18:53:29 - INFO - __main__ - train loss is 12.386670307954773\n",
      "Steps:  53%|▌| 7971/15000 [1:08:39<22:40,  5.17it/s, lr=0.000994, step_loss=0.0807/27/2023 18:53:29 - INFO - __main__ - train loss is 12.41554475738667\n",
      "Steps:  53%|▌| 7972/15000 [1:08:40<22:19,  5.25it/s, lr=0.000995, step_loss=0.0207/27/2023 18:53:29 - INFO - __main__ - train loss is 12.423090646741912\n",
      "Steps:  53%|▌| 7973/15000 [1:08:40<22:06,  5.30it/s, lr=0.000995, step_loss=0.0007/27/2023 18:53:30 - INFO - __main__ - train loss is 12.433070356724784\n",
      "Steps:  53%|▌| 7974/15000 [1:08:40<22:15,  5.26it/s, lr=0.000995, step_loss=0.0007/27/2023 18:53:30 - INFO - __main__ - train loss is 12.449026270536706\n",
      "Steps:  53%|▌| 7975/15000 [1:08:40<22:27,  5.22it/s, lr=0.000995, step_loss=0.0107/27/2023 18:53:30 - INFO - __main__ - train loss is 12.907079829601571\n",
      "Steps:  53%|▌| 7976/15000 [1:08:40<22:37,  5.17it/s, lr=0.000995, step_loss=0.4507/27/2023 18:53:30 - INFO - __main__ - train loss is 12.914740791311488\n",
      "Steps:  53%|▌| 7977/15000 [1:08:40<22:43,  5.15it/s, lr=0.000995, step_loss=0.0007/27/2023 18:53:30 - INFO - __main__ - train loss is 13.195741286268458\n",
      "Steps:  53%|▌| 7978/15000 [1:08:41<22:47,  5.13it/s, lr=0.000995, step_loss=0.2807/27/2023 18:53:31 - INFO - __main__ - train loss is 13.507412871113047\n",
      "Steps:  53%|▌| 7979/15000 [1:08:41<22:52,  5.11it/s, lr=0.000995, step_loss=0.3107/27/2023 18:53:31 - INFO - __main__ - train loss is 13.513988077873364\n",
      "Steps:  53%|▌| 7980/15000 [1:08:41<22:30,  5.20it/s, lr=0.000996, step_loss=0.0007/27/2023 18:53:31 - INFO - __main__ - train loss is 13.553607031935826\n",
      "Steps:  53%|▌| 7981/15000 [1:08:41<22:09,  5.28it/s, lr=0.000996, step_loss=0.0307/27/2023 18:53:31 - INFO - __main__ - train loss is 13.654582791263238\n",
      "Steps:  53%|▌| 7982/15000 [1:08:41<21:48,  5.36it/s, lr=0.000996, step_loss=0.1007/27/2023 18:53:31 - INFO - __main__ - train loss is 14.074194215470925\n",
      "Steps:  53%|▌| 7983/15000 [1:08:42<21:34,  5.42it/s, lr=0.000996, step_loss=0.4207/27/2023 18:53:31 - INFO - __main__ - train loss is 14.254509814316407\n",
      "Steps:  53%|▌| 7984/15000 [1:08:42<21:24,  5.46it/s, lr=0.000996, step_loss=0.1807/27/2023 18:53:32 - INFO - __main__ - train loss is 14.854221351677552\n",
      "Steps:  53%|▌| 7985/15000 [1:08:42<21:18,  5.49it/s, lr=0.000996, step_loss=0.6]07/27/2023 18:53:32 - INFO - __main__ - train loss is 14.856282153399661\n",
      "Steps:  53%|▌| 7986/15000 [1:08:42<21:13,  5.51it/s, lr=0.000996, step_loss=0.0007/27/2023 18:53:32 - INFO - __main__ - train loss is 14.85840765782632\n",
      "Steps:  53%|▌| 7987/15000 [1:08:42<21:09,  5.52it/s, lr=0.000996, step_loss=0.0007/27/2023 18:53:32 - INFO - __main__ - train loss is 15.09181521483697\n",
      "Steps:  53%|▌| 7988/15000 [1:08:42<21:06,  5.54it/s, lr=0.000996, step_loss=0.2307/27/2023 18:53:32 - INFO - __main__ - train loss is 15.096221260493621\n",
      "Steps:  53%|▌| 7989/15000 [1:08:43<21:05,  5.54it/s, lr=0.000997, step_loss=0.0007/27/2023 18:53:33 - INFO - __main__ - train loss is 15.378249279921874\n",
      "Steps:  53%|▌| 7990/15000 [1:08:43<21:12,  5.51it/s, lr=0.000997, step_loss=0.2807/27/2023 18:53:33 - INFO - __main__ - train loss is 15.977897517150268\n",
      "Steps:  53%|▌| 7991/15000 [1:08:43<21:08,  5.53it/s, lr=0.000997, step_loss=0.6]07/27/2023 18:53:33 - INFO - __main__ - train loss is 16.108398131793365\n",
      "Steps:  53%|▌| 7992/15000 [1:08:43<21:05,  5.54it/s, lr=0.000997, step_loss=0.1307/27/2023 18:53:33 - INFO - __main__ - train loss is 16.114676307188347\n",
      "Steps:  53%|▌| 7993/15000 [1:08:43<21:02,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 18:53:33 - INFO - __main__ - train loss is 16.12261486169882\n",
      "Steps:  53%|▌| 7994/15000 [1:08:44<21:01,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 18:53:33 - INFO - __main__ - train loss is 16.175458119483665\n",
      "Steps:  53%|▌| 7995/15000 [1:08:44<21:00,  5.56it/s, lr=0.000997, step_loss=0.0507/27/2023 18:53:34 - INFO - __main__ - train loss is 16.644037143560126\n",
      "Steps:  53%|▌| 7996/15000 [1:08:44<20:58,  5.57it/s, lr=0.000998, step_loss=0.4607/27/2023 18:53:34 - INFO - __main__ - train loss is 16.855459408136085\n",
      "Steps:  53%|▌| 7997/15000 [1:08:44<20:57,  5.57it/s, lr=0.000998, step_loss=0.2107/27/2023 18:53:34 - INFO - __main__ - train loss is 16.89818085101433\n",
      "Steps:  53%|▌| 7998/15000 [1:08:44<20:57,  5.57it/s, lr=0.000998, step_loss=0.0407/27/2023 18:53:34 - INFO - __main__ - train loss is 16.93350833770819\n",
      "Steps:  53%|▌| 7999/15000 [1:08:44<20:56,  5.57it/s, lr=0.000998, step_loss=0.0307/27/2023 18:53:34 - INFO - __main__ - train loss is 17.249355734558776\n",
      "Steps:  53%|▌| 8000/15000 [1:08:45<20:56,  5.57it/s, lr=0.000998, step_loss=0.0307/27/2023 18:53:34 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-8000\n",
      "07/27/2023 18:53:34 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:53:34,933] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:53:34,938] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-8000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:53:34,938] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-8000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:53:34,944] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-8000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:53:34,944] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-8000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:53:34,951] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-8000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:53:34,951] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-8000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:53:34,951] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:53:34 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-8000/pytorch_model\n",
      "07/27/2023 18:53:34 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-8000/scheduler.bin\n",
      "07/27/2023 18:53:34 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-8000/random_states_0.pkl\n",
      "07/27/2023 18:53:34 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-8000\n",
      "Steps:  53%|▌| 8000/15000 [1:08:45<20:56,  5.57it/s, lr=0.000998, step_loss=0.3107/27/2023 18:53:35 - INFO - __main__ - train loss is 17.269185045035556\n",
      "Steps:  53%|▌| 8001/15000 [1:08:45<21:37,  5.39it/s, lr=0.000998, step_loss=0.0107/27/2023 18:53:35 - INFO - __main__ - train loss is 17.29256940749474\n",
      "Steps:  53%|▌| 8002/15000 [1:08:45<21:25,  5.44it/s, lr=0.000998, step_loss=0.0207/27/2023 18:53:35 - INFO - __main__ - train loss is 17.295314062619582\n",
      "Steps:  53%|▌| 8003/15000 [1:08:45<21:17,  5.48it/s, lr=0.000998, step_loss=0.0007/27/2023 18:53:35 - INFO - __main__ - train loss is 17.32242700853385\n",
      "Steps:  53%|▌| 8004/15000 [1:08:45<21:10,  5.51it/s, lr=0.000999, step_loss=0.0207/27/2023 18:53:35 - INFO - __main__ - train loss is 17.716310505056754\n",
      "Steps:  53%|▌| 8005/15000 [1:08:46<21:06,  5.52it/s, lr=0.000999, step_loss=0.3907/27/2023 18:53:35 - INFO - __main__ - train loss is 17.88236217596568\n",
      "Steps:  53%|▌| 8006/15000 [1:08:46<21:04,  5.53it/s, lr=0.000999, step_loss=0.1607/27/2023 18:53:36 - INFO - __main__ - train loss is 17.883870219113305\n",
      "Steps:  53%|▌| 8007/15000 [1:08:46<21:01,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 18:53:36 - INFO - __main__ - train loss is 17.98295541596599\n",
      "Steps:  53%|▌| 8008/15000 [1:08:46<21:01,  5.54it/s, lr=0.000999, step_loss=0.0907/27/2023 18:53:36 - INFO - __main__ - train loss is 18.534223516704515\n",
      "Steps:  53%|▌| 8009/15000 [1:08:46<20:59,  5.55it/s, lr=0.000999, step_loss=0.5507/27/2023 18:53:36 - INFO - __main__ - train loss is 18.577061687828973\n",
      "Steps:  53%|▌| 8010/15000 [1:08:46<20:58,  5.55it/s, lr=0.000999, step_loss=0.0407/27/2023 18:53:36 - INFO - __main__ - train loss is 18.884159271838143\n",
      "Steps:  53%|▌| 8011/15000 [1:08:47<20:58,  5.55it/s, lr=0.000999, step_loss=0.3007/27/2023 18:53:37 - INFO - __main__ - train loss is 19.132880931021646\n",
      "Steps:  53%|█ | 8012/15000 [1:08:47<20:57,  5.56it/s, lr=0.001, step_loss=0.249]07/27/2023 18:53:37 - INFO - __main__ - train loss is 19.344182108761743\n",
      "Steps:  53%|█ | 8013/15000 [1:08:47<20:57,  5.56it/s, lr=0.001, step_loss=0.211]07/27/2023 18:53:37 - INFO - __main__ - train loss is 19.584843491436914\n",
      "Steps:  53%|█ | 8014/15000 [1:08:47<20:56,  5.56it/s, lr=0.001, step_loss=0.241]07/27/2023 18:53:37 - INFO - __main__ - train loss is 19.63772523147054\n",
      "Steps:  53%|▌| 8015/15000 [1:08:47<20:56,  5.56it/s, lr=0.001, step_loss=0.0529]07/27/2023 18:53:37 - INFO - __main__ - train loss is 19.648339109728113\n",
      "Steps:  53%|▌| 8016/15000 [1:08:48<20:55,  5.56it/s, lr=0.001, step_loss=0.0106]07/27/2023 18:53:37 - INFO - __main__ - train loss is 19.66501601994969\n",
      "Steps:  53%|▌| 8017/15000 [1:08:48<20:55,  5.56it/s, lr=0.001, step_loss=0.0167]07/27/2023 18:53:38 - INFO - __main__ - train loss is 19.70834060595371\n",
      "Steps:  53%|▌| 8018/15000 [1:08:48<20:55,  5.56it/s, lr=0.001, step_loss=0.0433]07/27/2023 18:53:38 - INFO - __main__ - train loss is 19.71262042154558\n",
      "Steps:  53%|▌| 8019/15000 [1:08:48<20:54,  5.56it/s, lr=0.001, step_loss=0.0042807/27/2023 18:53:38 - INFO - __main__ - train loss is 19.790664351778105\n",
      "Steps:  53%|█ | 8020/15000 [1:08:48<20:55,  5.56it/s, lr=0.001, step_loss=0.078]07/27/2023 18:53:38 - INFO - __main__ - train loss is 19.83634516526945\n",
      "Steps:  53%|▌| 8021/15000 [1:08:48<20:55,  5.56it/s, lr=0.001, step_loss=0.0457]07/27/2023 18:53:38 - INFO - __main__ - train loss is 19.931791207985952\n",
      "Steps:  53%|▌| 8022/15000 [1:08:49<20:56,  5.55it/s, lr=0.001, step_loss=0.0954]07/27/2023 18:53:39 - INFO - __main__ - train loss is 20.083379469113424\n",
      "Steps:  53%|█ | 8023/15000 [1:08:49<20:55,  5.56it/s, lr=0.001, step_loss=0.152]07/27/2023 18:53:39 - INFO - __main__ - train loss is 20.1208843246568\n",
      "Steps:  53%|▌| 8024/15000 [1:08:49<20:55,  5.56it/s, lr=0.001, step_loss=0.0375]07/27/2023 18:53:39 - INFO - __main__ - train loss is 20.400698508368805\n",
      "Steps:  54%|█▌ | 8025/15000 [1:08:49<20:55,  5.55it/s, lr=0.001, step_loss=0.28]07/27/2023 18:53:39 - INFO - __main__ - train loss is 20.473379682051018\n",
      "Steps:  54%|▌| 8026/15000 [1:08:49<20:55,  5.56it/s, lr=0.001, step_loss=0.0727]07/27/2023 18:53:39 - INFO - __main__ - train loss is 20.480358166852966\n",
      "Steps:  54%|▌| 8027/15000 [1:08:50<20:54,  5.56it/s, lr=0.001, step_loss=0.0069807/27/2023 18:53:39 - INFO - __main__ - train loss is 20.97685377136804\n",
      "Steps:  54%|█ | 8028/15000 [1:08:50<20:56,  5.55it/s, lr=0.001, step_loss=0.496]07/27/2023 18:53:40 - INFO - __main__ - train loss is 21.038668537745252\n",
      "Steps:  54%|▌| 8029/15000 [1:08:50<20:55,  5.55it/s, lr=0.001, step_loss=0.0618]07/27/2023 18:53:40 - INFO - __main__ - train loss is 21.039922420633957\n",
      "Steps:  54%|▌| 8030/15000 [1:08:50<20:54,  5.56it/s, lr=0.001, step_loss=0.0012507/27/2023 18:53:40 - INFO - __main__ - train loss is 21.052128528943285\n",
      "Steps:  54%|▌| 8031/15000 [1:08:50<20:53,  5.56it/s, lr=0.001, step_loss=0.0122]07/27/2023 18:53:40 - INFO - __main__ - train loss is 21.075950905447826\n",
      "Steps:  54%|▌| 8032/15000 [1:08:50<20:53,  5.56it/s, lr=0.001, step_loss=0.0238]07/27/2023 18:53:40 - INFO - __main__ - train loss is 21.113697990542278\n",
      "Steps:  54%|▌| 8033/15000 [1:08:51<20:53,  5.56it/s, lr=0.001, step_loss=0.0377]07/27/2023 18:53:40 - INFO - __main__ - train loss is 21.681692525511608\n",
      "Steps:  54%|█ | 8034/15000 [1:08:51<21:05,  5.51it/s, lr=0.001, step_loss=0.568]07/27/2023 18:53:41 - INFO - __main__ - train loss is 22.302950665121898\n",
      "Steps:  54%|█ | 8035/15000 [1:08:51<21:07,  5.50it/s, lr=0.001, step_loss=0.621]07/27/2023 18:53:41 - INFO - __main__ - train loss is 22.313002449227497\n",
      "Steps:  54%|▌| 8036/15000 [1:08:51<21:06,  5.50it/s, lr=0.001, step_loss=0.0101]07/27/2023 18:53:41 - INFO - __main__ - train loss is 22.32082006218843\n",
      "Steps:  54%|▌| 8037/15000 [1:08:51<21:01,  5.52it/s, lr=0.001, step_loss=0.0078207/27/2023 18:53:41 - INFO - __main__ - train loss is 22.72410875442438\n",
      "Steps:  54%|█ | 8038/15000 [1:08:52<20:58,  5.53it/s, lr=0.001, step_loss=0.403]07/27/2023 18:53:41 - INFO - __main__ - train loss is 22.73743140581064\n",
      "Steps:  54%|▌| 8039/15000 [1:08:52<20:55,  5.54it/s, lr=0.001, step_loss=0.0133]07/27/2023 18:53:42 - INFO - __main__ - train loss is 23.06451782467775\n",
      "Steps:  54%|█ | 8040/15000 [1:08:52<20:53,  5.55it/s, lr=0.001, step_loss=0.327]07/27/2023 18:53:42 - INFO - __main__ - train loss is 23.091342803789303\n",
      "Steps:  54%|▌| 8041/15000 [1:08:52<20:52,  5.55it/s, lr=0.001, step_loss=0.0268]07/27/2023 18:53:42 - INFO - __main__ - train loss is 23.106035898206756\n",
      "Steps:  54%|▌| 8042/15000 [1:08:52<20:52,  5.56it/s, lr=0.001, step_loss=0.0147]07/27/2023 18:53:42 - INFO - __main__ - train loss is 23.14000857132487\n",
      "Steps:  54%|█ | 8043/15000 [1:08:52<20:52,  5.56it/s, lr=0.001, step_loss=0.034]07/27/2023 18:53:42 - INFO - __main__ - train loss is 23.195714409230277\n",
      "Steps:  54%|▌| 8044/15000 [1:08:53<20:51,  5.56it/s, lr=0.001, step_loss=0.0557]07/27/2023 18:53:42 - INFO - __main__ - train loss is 23.30542121338658\n",
      "Steps:  54%|█▌ | 8045/15000 [1:08:53<20:50,  5.56it/s, lr=0.001, step_loss=0.11]07/27/2023 18:53:43 - INFO - __main__ - train loss is 23.306836840463802\n",
      "Steps:  54%|▌| 8046/15000 [1:08:53<20:50,  5.56it/s, lr=0.001, step_loss=0.0014207/27/2023 18:53:43 - INFO - __main__ - train loss is 23.326496652094647\n",
      "Steps:  54%|▌| 8047/15000 [1:08:53<20:49,  5.56it/s, lr=0.001, step_loss=0.0197]07/27/2023 18:53:43 - INFO - __main__ - train loss is 23.731785527197644\n",
      "Steps:  54%|█ | 8048/15000 [1:08:53<20:49,  5.56it/s, lr=0.001, step_loss=0.405]07/27/2023 18:53:43 - INFO - __main__ - train loss is 24.18377338978462\n",
      "Steps:  54%|█ | 8049/15000 [1:08:53<20:48,  5.57it/s, lr=0.001, step_loss=0.452]07/27/2023 18:53:43 - INFO - __main__ - train loss is 24.62343796226196\n",
      "Steps:  54%|█▌ | 8050/15000 [1:08:54<20:48,  5.57it/s, lr=0.001, step_loss=0.44]07/27/2023 18:53:44 - INFO - __main__ - train loss is 24.64237170177512\n",
      "Steps:  54%|▌| 8051/15000 [1:08:54<20:48,  5.57it/s, lr=0.001, step_loss=0.0189]07/27/2023 18:53:44 - INFO - __main__ - train loss is 24.84605539101176\n",
      "Steps:  54%|█ | 8052/15000 [1:08:54<20:48,  5.56it/s, lr=0.001, step_loss=0.204]07/27/2023 18:53:44 - INFO - __main__ - train loss is 24.883351172087714\n",
      "Steps:  54%|▌| 8053/15000 [1:08:54<20:49,  5.56it/s, lr=0.001, step_loss=0.0373]07/27/2023 18:53:44 - INFO - __main__ - train loss is 25.153093392727897\n",
      "Steps:  54%|█▌ | 8054/15000 [1:08:54<20:48,  5.56it/s, lr=0.001, step_loss=0.27]07/27/2023 18:53:44 - INFO - __main__ - train loss is 25.180849532363936\n",
      "Steps:  54%|▌| 8055/15000 [1:08:55<20:48,  5.56it/s, lr=0.001, step_loss=0.0278]07/27/2023 18:53:44 - INFO - __main__ - train loss is 25.42474106955342\n",
      "Steps:  54%|█ | 8056/15000 [1:08:55<20:48,  5.56it/s, lr=0.001, step_loss=0.244]07/27/2023 18:53:45 - INFO - __main__ - train loss is 25.443584902910516\n",
      "Steps:  54%|▌| 8057/15000 [1:08:55<20:48,  5.56it/s, lr=0.001, step_loss=0.0188]07/27/2023 18:53:45 - INFO - __main__ - train loss is 25.596394686726853\n",
      "Steps:  54%|█ | 8058/15000 [1:08:55<20:47,  5.56it/s, lr=0.001, step_loss=0.153]07/27/2023 18:53:45 - INFO - __main__ - train loss is 25.848316966323182\n",
      "Steps:  54%|█ | 8059/15000 [1:08:55<20:47,  5.57it/s, lr=0.001, step_loss=0.252]07/27/2023 18:53:45 - INFO - __main__ - train loss is 26.375286160735413\n",
      "Steps:  54%|█ | 8060/15000 [1:08:55<20:45,  5.57it/s, lr=0.001, step_loss=0.527]07/27/2023 18:53:45 - INFO - __main__ - train loss is 26.499788268236443\n",
      "Steps:  54%|█ | 8061/15000 [1:08:56<20:44,  5.57it/s, lr=0.001, step_loss=0.125]07/27/2023 18:53:46 - INFO - __main__ - train loss is 26.5996479827445\n",
      "Steps:  54%|▌| 8062/15000 [1:08:56<20:44,  5.57it/s, lr=0.001, step_loss=0.0999]07/27/2023 18:53:46 - INFO - __main__ - train loss is 26.605240030912682\n",
      "Steps:  54%|▌| 8063/15000 [1:08:56<20:45,  5.57it/s, lr=0.001, step_loss=0.0055907/27/2023 18:53:46 - INFO - __main__ - train loss is 26.91267733159475\n",
      "Steps:  54%|█ | 8064/15000 [1:08:56<20:46,  5.57it/s, lr=0.001, step_loss=0.307]07/27/2023 18:53:46 - INFO - __main__ - train loss is 27.458721085218713\n",
      "Steps:  54%|█ | 8065/15000 [1:08:56<20:45,  5.57it/s, lr=0.001, step_loss=0.546]07/27/2023 18:53:46 - INFO - __main__ - train loss is 27.470085476292297\n",
      "Steps:  54%|▌| 8066/15000 [1:08:57<20:45,  5.57it/s, lr=0.001, step_loss=0.0114]07/27/2023 18:53:46 - INFO - __main__ - train loss is 27.533458132995293\n",
      "Steps:  54%|▌| 8067/15000 [1:08:57<20:45,  5.57it/s, lr=0.001, step_loss=0.0634]07/27/2023 18:53:47 - INFO - __main__ - train loss is 27.674613226903602\n",
      "Steps:  54%|█ | 8068/15000 [1:08:57<20:44,  5.57it/s, lr=0.001, step_loss=0.141]07/27/2023 18:53:47 - INFO - __main__ - train loss is 27.990983028663322\n",
      "Steps:  54%|█ | 8069/15000 [1:08:57<20:44,  5.57it/s, lr=0.001, step_loss=0.316]07/27/2023 18:53:47 - INFO - __main__ - train loss is 28.194046114338562\n",
      "Steps:  54%|█ | 8070/15000 [1:08:57<20:44,  5.57it/s, lr=0.001, step_loss=0.203]07/27/2023 18:53:47 - INFO - __main__ - train loss is 28.196056303801015\n",
      "Steps:  54%|▌| 8071/15000 [1:08:57<20:44,  5.57it/s, lr=0.001, step_loss=0.0020107/27/2023 18:53:47 - INFO - __main__ - train loss is 28.26963680726476\n",
      "Steps:  54%|▌| 8072/15000 [1:08:58<20:45,  5.56it/s, lr=0.001, step_loss=0.0736]07/27/2023 18:53:47 - INFO - __main__ - train loss is 28.310261086793616\n",
      "Steps:  54%|▌| 8073/15000 [1:08:58<20:45,  5.56it/s, lr=0.001, step_loss=0.0406]07/27/2023 18:53:48 - INFO - __main__ - train loss is 28.42070745048113\n",
      "Steps:  54%|█▌ | 8074/15000 [1:08:58<20:45,  5.56it/s, lr=0.001, step_loss=0.11]07/27/2023 18:53:48 - INFO - __main__ - train loss is 28.500349381240085\n",
      "Steps:  54%|▌| 8075/15000 [1:08:58<20:45,  5.56it/s, lr=0.001, step_loss=0.0796]07/27/2023 18:53:48 - INFO - __main__ - train loss is 28.61376448837109\n",
      "Steps:  54%|█ | 8076/15000 [1:08:58<20:45,  5.56it/s, lr=0.001, step_loss=0.113]07/27/2023 18:53:48 - INFO - __main__ - train loss is 29.08629443612881\n",
      "Steps:  54%|█ | 8077/15000 [1:08:59<20:45,  5.56it/s, lr=0.001, step_loss=0.473]07/27/2023 18:53:48 - INFO - __main__ - train loss is 29.177016311557963\n",
      "Steps:  54%|▌| 8078/15000 [1:08:59<20:46,  5.56it/s, lr=0.001, step_loss=0.0907]07/27/2023 18:53:49 - INFO - __main__ - train loss is 29.217894786270335\n",
      "Steps:  54%|▌| 8079/15000 [1:08:59<20:45,  5.56it/s, lr=0.001, step_loss=0.0409]07/27/2023 18:53:49 - INFO - __main__ - train loss is 29.219781252206303\n",
      "Steps:  54%|▌| 8080/15000 [1:08:59<20:45,  5.56it/s, lr=0.001, step_loss=0.0018907/27/2023 18:53:49 - INFO - __main__ - train loss is 29.277724976302125\n",
      "Steps:  54%|▌| 8081/15000 [1:08:59<20:44,  5.56it/s, lr=0.001, step_loss=0.0579]07/27/2023 18:53:49 - INFO - __main__ - train loss is 29.74491270876024\n",
      "Steps:  54%|█ | 8082/15000 [1:08:59<20:44,  5.56it/s, lr=0.001, step_loss=0.467]07/27/2023 18:53:49 - INFO - __main__ - train loss is 29.862514185369946\n",
      "Steps:  54%|█ | 8083/15000 [1:09:00<20:45,  5.55it/s, lr=0.001, step_loss=0.118]07/27/2023 18:53:49 - INFO - __main__ - train loss is 30.04154145962093\n",
      "Steps:  54%|█ | 8084/15000 [1:09:00<20:44,  5.56it/s, lr=0.001, step_loss=0.179]07/27/2023 18:53:50 - INFO - __main__ - train loss is 30.05454681313131\n",
      "Steps:  54%|█ | 8085/15000 [1:09:00<20:44,  5.56it/s, lr=0.001, step_loss=0.013]07/27/2023 18:53:50 - INFO - __main__ - train loss is 30.093040953041054\n",
      "Steps:  54%|▌| 8086/15000 [1:09:00<20:44,  5.56it/s, lr=0.001, step_loss=0.0385]07/27/2023 18:53:50 - INFO - __main__ - train loss is 30.122277042479254\n",
      "Steps:  54%|▌| 8087/15000 [1:09:00<20:44,  5.56it/s, lr=0.001, step_loss=0.0292]07/27/2023 18:53:50 - INFO - __main__ - train loss is 30.130869364948012\n",
      "Steps:  54%|▌| 8088/15000 [1:09:01<20:43,  5.56it/s, lr=0.001, step_loss=0.0085907/27/2023 18:53:50 - INFO - __main__ - train loss is 30.177455431432463\n",
      "Steps:  54%|▌| 8089/15000 [1:09:01<20:43,  5.56it/s, lr=0.001, step_loss=0.0466]07/27/2023 18:53:51 - INFO - __main__ - train loss is 30.230470678419806\n",
      "Steps:  54%|█ | 8090/15000 [1:09:01<20:43,  5.56it/s, lr=0.001, step_loss=0.053]07/27/2023 18:53:51 - INFO - __main__ - train loss is 30.311062744469382\n",
      "Steps:  54%|▌| 8091/15000 [1:09:01<20:42,  5.56it/s, lr=0.001, step_loss=0.0806]07/27/2023 18:53:51 - INFO - __main__ - train loss is 30.80245490989182\n",
      "Steps:  54%|█ | 8092/15000 [1:09:01<20:43,  5.56it/s, lr=0.001, step_loss=0.491]07/27/2023 18:53:51 - INFO - __main__ - train loss is 30.82840118429158\n",
      "Steps:  54%|▌| 8093/15000 [1:09:01<20:41,  5.56it/s, lr=0.001, step_loss=0.0259]07/27/2023 18:53:51 - INFO - __main__ - train loss is 30.84814126288984\n",
      "Steps:  54%|▌| 8094/15000 [1:09:02<20:41,  5.56it/s, lr=0.001, step_loss=0.0197]07/27/2023 18:53:51 - INFO - __main__ - train loss is 30.850292579154484\n",
      "Steps:  54%|▌| 8095/15000 [1:09:02<20:42,  5.56it/s, lr=0.001, step_loss=0.0021507/27/2023 18:53:52 - INFO - __main__ - train loss is 31.247336254338734\n",
      "Steps:  54%|█ | 8096/15000 [1:09:02<20:41,  5.56it/s, lr=0.001, step_loss=0.397]07/27/2023 18:53:52 - INFO - __main__ - train loss is 31.308679261128418\n",
      "Steps:  54%|▌| 8097/15000 [1:09:02<20:41,  5.56it/s, lr=0.001, step_loss=0.0613]07/27/2023 18:53:52 - INFO - __main__ - train loss is 31.31050648924429\n",
      "Steps:  54%|▌| 8098/15000 [1:09:02<20:41,  5.56it/s, lr=0.001, step_loss=0.0018307/27/2023 18:53:52 - INFO - __main__ - train loss is 31.6098484658869\n",
      "Steps:  54%|█ | 8099/15000 [1:09:02<20:41,  5.56it/s, lr=0.001, step_loss=0.299]07/27/2023 18:53:52 - INFO - __main__ - train loss is 31.793326612678356\n",
      "Steps:  54%|█ | 8100/15000 [1:09:03<20:41,  5.56it/s, lr=0.001, step_loss=0.183]07/27/2023 18:53:53 - INFO - __main__ - train loss is 31.79886329045985\n",
      "Steps:  54%|▌| 8101/15000 [1:09:03<20:40,  5.56it/s, lr=0.001, step_loss=0.0055407/27/2023 18:53:53 - INFO - __main__ - train loss is 31.99345788231585\n",
      "Steps:  54%|█ | 8102/15000 [1:09:03<20:40,  5.56it/s, lr=0.001, step_loss=0.195]07/27/2023 18:53:53 - INFO - __main__ - train loss is 32.17116780451033\n",
      "Steps:  54%|█ | 8103/15000 [1:09:03<20:40,  5.56it/s, lr=0.001, step_loss=0.178]07/27/2023 18:53:53 - INFO - __main__ - train loss is 32.25616419187281\n",
      "Steps:  54%|█ | 8104/15000 [1:09:03<20:44,  5.54it/s, lr=0.001, step_loss=0.085]07/27/2023 18:53:53 - INFO - __main__ - train loss is 32.39260646572802\n",
      "Steps:  54%|█ | 8105/15000 [1:09:04<20:42,  5.55it/s, lr=0.001, step_loss=0.136]07/27/2023 18:53:53 - INFO - __main__ - train loss is 32.64039336016867\n",
      "Steps:  54%|█ | 8106/15000 [1:09:04<20:45,  5.54it/s, lr=0.001, step_loss=0.248]07/27/2023 18:53:54 - INFO - __main__ - train loss is 32.67318190506194\n",
      "Steps:  54%|▌| 8107/15000 [1:09:04<20:46,  5.53it/s, lr=0.001, step_loss=0.0328]07/27/2023 18:53:54 - INFO - __main__ - train loss is 32.680802906514145\n",
      "Steps:  54%|▌| 8108/15000 [1:09:04<20:43,  5.54it/s, lr=0.001, step_loss=0.0076207/27/2023 18:53:54 - INFO - __main__ - train loss is 32.795610273838975\n",
      "Steps:  54%|█ | 8109/15000 [1:09:04<20:41,  5.55it/s, lr=0.001, step_loss=0.115]07/27/2023 18:53:54 - INFO - __main__ - train loss is 32.79793070501182\n",
      "Steps:  54%|▌| 8110/15000 [1:09:04<20:41,  5.55it/s, lr=0.001, step_loss=0.0023207/27/2023 18:53:54 - INFO - __main__ - train loss is 32.79965147806797\n",
      "Steps:  54%|▌| 8111/15000 [1:09:05<20:39,  5.56it/s, lr=0.001, step_loss=0.0017207/27/2023 18:53:55 - INFO - __main__ - train loss is 32.80605022946838\n",
      "Steps:  54%|▌| 8112/15000 [1:09:05<20:39,  5.56it/s, lr=0.001, step_loss=0.0064]07/27/2023 18:53:55 - INFO - __main__ - train loss is 32.859842311241664\n",
      "Steps:  54%|▌| 8113/15000 [1:09:05<20:40,  5.55it/s, lr=0.001, step_loss=0.0538]07/27/2023 18:53:55 - INFO - __main__ - train loss is 33.53313876281027\n",
      "Steps:  54%|█ | 8114/15000 [1:09:05<20:51,  5.50it/s, lr=0.001, step_loss=0.673]07/27/2023 18:53:55 - INFO - __main__ - train loss is 33.543911693268456\n",
      "Steps:  54%|▌| 8115/15000 [1:09:05<20:51,  5.50it/s, lr=0.001, step_loss=0.0108]07/27/2023 18:53:55 - INFO - __main__ - train loss is 33.64897568302695\n",
      "Steps:  54%|█ | 8116/15000 [1:09:06<20:59,  5.47it/s, lr=0.001, step_loss=0.105]07/27/2023 18:53:55 - INFO - __main__ - train loss is 33.782562998705544\n",
      "Steps:  54%|█ | 8117/15000 [1:09:06<20:56,  5.48it/s, lr=0.001, step_loss=0.134]07/27/2023 18:53:56 - INFO - __main__ - train loss is 33.79765597230289\n",
      "Steps:  54%|▌| 8118/15000 [1:09:06<20:57,  5.47it/s, lr=0.001, step_loss=0.0151]07/27/2023 18:53:56 - INFO - __main__ - train loss is 33.821776519180275\n",
      "Steps:  54%|▌| 8119/15000 [1:09:06<20:52,  5.50it/s, lr=0.001, step_loss=0.0241]07/27/2023 18:53:56 - INFO - __main__ - train loss is 33.83364300860558\n",
      "Steps:  54%|▌| 8120/15000 [1:09:06<20:48,  5.51it/s, lr=0.001, step_loss=0.0119]07/27/2023 18:53:56 - INFO - __main__ - train loss is 33.85237566998694\n",
      "Steps:  54%|▌| 8121/15000 [1:09:06<20:44,  5.53it/s, lr=0.001, step_loss=0.0187]07/27/2023 18:53:56 - INFO - __main__ - train loss is 33.85413733974565\n",
      "Steps:  54%|▌| 8122/15000 [1:09:07<20:42,  5.54it/s, lr=0.001, step_loss=0.0017607/27/2023 18:53:57 - INFO - __main__ - train loss is 34.424054005299695\n",
      "Steps:  54%|█▌ | 8123/15000 [1:09:07<20:40,  5.54it/s, lr=0.001, step_loss=0.57]07/27/2023 18:53:57 - INFO - __main__ - train loss is 34.429892095853575\n",
      "Steps:  54%|▌| 8124/15000 [1:09:07<20:39,  5.55it/s, lr=0.001, step_loss=0.0058407/27/2023 18:53:57 - INFO - __main__ - train loss is 34.90776935510803\n",
      "Steps:  54%|█ | 8125/15000 [1:09:07<20:38,  5.55it/s, lr=0.001, step_loss=0.478]07/27/2023 18:53:57 - INFO - __main__ - train loss is 34.90900141943712\n",
      "Steps:  54%|▌| 8126/15000 [1:09:07<20:37,  5.55it/s, lr=0.001, step_loss=0.0012307/27/2023 18:53:57 - INFO - __main__ - train loss is 34.92296374880243\n",
      "Steps:  54%|█ | 8127/15000 [1:09:08<20:37,  5.55it/s, lr=0.001, step_loss=0.014]07/27/2023 18:53:57 - INFO - __main__ - train loss is 35.62631119333673\n",
      "Steps:  54%|█ | 8128/15000 [1:09:08<20:48,  5.50it/s, lr=0.001, step_loss=0.703]07/27/2023 18:53:58 - INFO - __main__ - train loss is 35.81917048536707\n",
      "Steps:  54%|█ | 8129/15000 [1:09:08<20:56,  5.47it/s, lr=0.001, step_loss=0.193]07/27/2023 18:53:58 - INFO - __main__ - train loss is 35.86330792598892\n",
      "Steps:  54%|▌| 8130/15000 [1:09:08<21:05,  5.43it/s, lr=0.001, step_loss=0.0441]07/27/2023 18:53:58 - INFO - __main__ - train loss is 35.865054841386154\n",
      "Steps:  54%|▌| 8131/15000 [1:09:08<21:09,  5.41it/s, lr=0.001, step_loss=0.0017507/27/2023 18:53:58 - INFO - __main__ - train loss is 35.89006945420988\n",
      "Steps:  54%|█ | 8132/15000 [1:09:08<21:00,  5.45it/s, lr=0.001, step_loss=0.025]07/27/2023 18:53:58 - INFO - __main__ - train loss is 36.00587597419508\n",
      "Steps:  54%|█ | 8133/15000 [1:09:09<21:04,  5.43it/s, lr=0.001, step_loss=0.116]07/27/2023 18:53:59 - INFO - __main__ - train loss is 36.04001261596568\n",
      "Steps:  54%|▌| 8134/15000 [1:09:09<21:06,  5.42it/s, lr=0.001, step_loss=0.0341]07/27/2023 18:53:59 - INFO - __main__ - train loss is 36.14377226983197\n",
      "Steps:  54%|█ | 8135/15000 [1:09:09<20:57,  5.46it/s, lr=0.001, step_loss=0.104]07/27/2023 18:53:59 - INFO - __main__ - train loss is 36.310760150896385\n",
      "Steps:  54%|█ | 8136/15000 [1:09:09<20:50,  5.49it/s, lr=0.001, step_loss=0.167]07/27/2023 18:53:59 - INFO - __main__ - train loss is 36.43324917857535\n",
      "Steps:  54%|█ | 8137/15000 [1:09:09<20:44,  5.51it/s, lr=0.001, step_loss=0.122]07/27/2023 18:53:59 - INFO - __main__ - train loss is 36.72571850125678\n",
      "Steps:  54%|█ | 8138/15000 [1:09:10<20:42,  5.52it/s, lr=0.001, step_loss=0.292]07/27/2023 18:53:59 - INFO - __main__ - train loss is 36.852588090347126\n",
      "Steps:  54%|█ | 8139/15000 [1:09:10<20:41,  5.53it/s, lr=0.001, step_loss=0.127]07/27/2023 18:54:00 - INFO - __main__ - train loss is 37.042314934777096\n",
      "Steps:  54%|█▋ | 8140/15000 [1:09:10<20:38,  5.54it/s, lr=0.001, step_loss=0.19]07/27/2023 18:54:00 - INFO - __main__ - train loss is 37.047403786564246\n",
      "Steps:  54%|▌| 8141/15000 [1:09:10<20:37,  5.54it/s, lr=0.001, step_loss=0.0050907/27/2023 18:54:00 - INFO - __main__ - train loss is 37.058039063820615\n",
      "Steps:  54%|▌| 8142/15000 [1:09:10<20:36,  5.55it/s, lr=0.001, step_loss=0.0106]07/27/2023 18:54:00 - INFO - __main__ - train loss is 37.228808487067\n",
      "Steps:  54%|█ | 8143/15000 [1:09:10<20:34,  5.55it/s, lr=0.001, step_loss=0.171]07/27/2023 18:54:00 - INFO - __main__ - train loss is 37.25710398913361\n",
      "Steps:  54%|▌| 8144/15000 [1:09:11<20:34,  5.55it/s, lr=0.001, step_loss=0.0283]07/27/2023 18:54:01 - INFO - __main__ - train loss is 37.45990018011071\n",
      "Steps:  54%|█ | 8145/15000 [1:09:11<20:32,  5.56it/s, lr=0.001, step_loss=0.203]07/27/2023 18:54:01 - INFO - __main__ - train loss is 37.487413527676836\n",
      "Steps:  54%|▌| 8146/15000 [1:09:11<20:32,  5.56it/s, lr=0.001, step_loss=0.0275]07/27/2023 18:54:01 - INFO - __main__ - train loss is 37.74016192764975\n",
      "Steps:  54%|█ | 8147/15000 [1:09:11<20:31,  5.56it/s, lr=0.001, step_loss=0.253]07/27/2023 18:54:01 - INFO - __main__ - train loss is 37.74267510813661\n",
      "Steps:  54%|▌| 8148/15000 [1:09:11<20:31,  5.56it/s, lr=0.001, step_loss=0.0025107/27/2023 18:54:01 - INFO - __main__ - train loss is 37.749239936703816\n",
      "Steps:  54%|▌| 8149/15000 [1:09:12<20:30,  5.57it/s, lr=0.001, step_loss=0.0065607/27/2023 18:54:01 - INFO - __main__ - train loss is 38.13280887925066\n",
      "Steps:  54%|█ | 8150/15000 [1:09:12<20:30,  5.57it/s, lr=0.001, step_loss=0.384]07/27/2023 18:54:02 - INFO - __main__ - train loss is 38.15385458082892\n",
      "Steps:  54%|█ | 8151/15000 [1:09:12<20:29,  5.57it/s, lr=0.001, step_loss=0.021]07/27/2023 18:54:02 - INFO - __main__ - train loss is 38.15747919376008\n",
      "Steps:  54%|▌| 8152/15000 [1:09:12<20:29,  5.57it/s, lr=0.001, step_loss=0.0036207/27/2023 18:54:02 - INFO - __main__ - train loss is 38.40242260391824\n",
      "Steps:  54%|█ | 8153/15000 [1:09:12<20:30,  5.56it/s, lr=0.001, step_loss=0.245]07/27/2023 18:54:02 - INFO - __main__ - train loss is 38.56848075683229\n",
      "Steps:  54%|█ | 8154/15000 [1:09:12<20:30,  5.56it/s, lr=0.001, step_loss=0.166]07/27/2023 18:54:02 - INFO - __main__ - train loss is 38.61835933919065\n",
      "Steps:  54%|▌| 8155/15000 [1:09:13<20:30,  5.56it/s, lr=0.001, step_loss=0.0499]07/27/2023 18:54:02 - INFO - __main__ - train loss is 38.68492439086549\n",
      "Steps:  54%|▌| 8156/15000 [1:09:13<20:30,  5.56it/s, lr=0.001, step_loss=0.0666]07/27/2023 18:54:03 - INFO - __main__ - train loss is 38.79073922033422\n",
      "Steps:  54%|█ | 8157/15000 [1:09:13<20:29,  5.56it/s, lr=0.001, step_loss=0.106]07/27/2023 18:54:03 - INFO - __main__ - train loss is 38.84293096954934\n",
      "Steps:  54%|▌| 8158/15000 [1:09:13<20:29,  5.56it/s, lr=0.001, step_loss=0.0522]07/27/2023 18:54:03 - INFO - __main__ - train loss is 38.84645322035067\n",
      "Steps:  54%|▌| 8159/15000 [1:09:13<20:29,  5.56it/s, lr=0.001, step_loss=0.0035207/27/2023 18:54:03 - INFO - __main__ - train loss is 38.88299261103384\n",
      "Steps:  54%|▌| 8160/15000 [1:09:14<20:29,  5.56it/s, lr=0.001, step_loss=0.0365]07/27/2023 18:54:03 - INFO - __main__ - train loss is 38.897179583786055\n",
      "Steps:  54%|▌| 8161/15000 [1:09:14<20:28,  5.57it/s, lr=0.001, step_loss=0.0142]07/27/2023 18:54:04 - INFO - __main__ - train loss is 39.02112395572476\n",
      "Steps:  54%|█ | 8162/15000 [1:09:14<20:29,  5.56it/s, lr=0.001, step_loss=0.124]07/27/2023 18:54:04 - INFO - __main__ - train loss is 39.0363953046035\n",
      "Steps:  54%|▌| 8163/15000 [1:09:14<20:29,  5.56it/s, lr=0.001, step_loss=0.0153]07/27/2023 18:54:04 - INFO - __main__ - train loss is 39.428151302738115\n",
      "Steps:  54%|█ | 8164/15000 [1:09:14<20:28,  5.56it/s, lr=0.001, step_loss=0.392]07/27/2023 18:54:04 - INFO - __main__ - train loss is 39.68638285319321\n",
      "Steps:  54%|█ | 8165/15000 [1:09:14<20:28,  5.57it/s, lr=0.001, step_loss=0.258]07/27/2023 18:54:04 - INFO - __main__ - train loss is 39.804026269121096\n",
      "Steps:  54%|█ | 8166/15000 [1:09:15<20:34,  5.54it/s, lr=0.001, step_loss=0.118]07/27/2023 18:54:04 - INFO - __main__ - train loss is 39.98734863917343\n",
      "Steps:  54%|█ | 8167/15000 [1:09:15<20:31,  5.55it/s, lr=0.001, step_loss=0.183]07/27/2023 18:54:05 - INFO - __main__ - train loss is 40.0758207149338\n",
      "Steps:  54%|▌| 8168/15000 [1:09:15<20:29,  5.56it/s, lr=0.001, step_loss=0.0885]07/27/2023 18:54:05 - INFO - __main__ - train loss is 40.158900872571394\n",
      "Steps:  54%|▌| 8169/15000 [1:09:15<20:40,  5.51it/s, lr=0.001, step_loss=0.0831]07/27/2023 18:54:05 - INFO - __main__ - train loss is 40.18923719297163\n",
      "Steps:  54%|▌| 8170/15000 [1:09:15<20:40,  5.51it/s, lr=0.001, step_loss=0.0303]07/27/2023 18:54:05 - INFO - __main__ - train loss is 40.19061229773797\n",
      "Steps:  54%|▌| 8171/15000 [1:09:16<20:35,  5.53it/s, lr=0.001, step_loss=0.0013807/27/2023 18:54:05 - INFO - __main__ - train loss is 40.19655425217934\n",
      "Steps:  54%|▌| 8172/15000 [1:09:16<20:40,  5.50it/s, lr=0.001, step_loss=0.0059407/27/2023 18:54:06 - INFO - __main__ - train loss is 40.19784519565292\n",
      "Steps:  54%|▌| 8173/15000 [1:09:16<20:45,  5.48it/s, lr=0.001, step_loss=0.0012907/27/2023 18:54:06 - INFO - __main__ - train loss is 40.33705771458335\n",
      "Steps:  54%|█ | 8174/15000 [1:09:16<20:38,  5.51it/s, lr=0.001, step_loss=0.139]07/27/2023 18:54:06 - INFO - __main__ - train loss is 40.42694549751468\n",
      "Steps:  55%|▌| 8175/15000 [1:09:16<20:33,  5.53it/s, lr=0.001, step_loss=0.0899]07/27/2023 18:54:06 - INFO - __main__ - train loss is 40.43248755042441\n",
      "Steps:  55%|▌| 8176/15000 [1:09:16<20:30,  5.55it/s, lr=0.001, step_loss=0.0055407/27/2023 18:54:06 - INFO - __main__ - train loss is 40.4666371375788\n",
      "Steps:  55%|▌| 8177/15000 [1:09:17<20:27,  5.56it/s, lr=0.001, step_loss=0.0341]07/27/2023 18:54:06 - INFO - __main__ - train loss is 40.53475232725032\n",
      "Steps:  55%|▌| 8178/15000 [1:09:17<20:26,  5.56it/s, lr=0.001, step_loss=0.0681]07/27/2023 18:54:07 - INFO - __main__ - train loss is 40.68487628106959\n",
      "Steps:  55%|█▋ | 8179/15000 [1:09:17<20:28,  5.55it/s, lr=0.001, step_loss=0.15]07/27/2023 18:54:07 - INFO - __main__ - train loss is 40.96611149911769\n",
      "Steps:  55%|█ | 8180/15000 [1:09:17<20:26,  5.56it/s, lr=0.001, step_loss=0.281]07/27/2023 18:54:07 - INFO - __main__ - train loss is 40.97601707116701\n",
      "Steps:  55%|▌| 8181/15000 [1:09:18<28:56,  3.93it/s, lr=0.001, step_loss=0.0099107/27/2023 18:54:08 - INFO - __main__ - Per validation step average loss is 0.020559903234243393\n",
      "07/27/2023 18:54:08 - INFO - __main__ - Cumulative validation average loss is 0.020559903234243393\n",
      "07/27/2023 18:54:09 - INFO - __main__ - Per validation step average loss is 0.42199385166168213\n",
      "07/27/2023 18:54:09 - INFO - __main__ - Cumulative validation average loss is 0.4425537548959255\n",
      "07/27/2023 18:54:09 - INFO - __main__ - Per validation step average loss is 0.1942540407180786\n",
      "07/27/2023 18:54:09 - INFO - __main__ - Cumulative validation average loss is 0.6368077956140041\n",
      "07/27/2023 18:54:09 - INFO - __main__ - Per validation step average loss is 0.17665573954582214\n",
      "07/27/2023 18:54:09 - INFO - __main__ - Cumulative validation average loss is 0.8134635351598263\n",
      "07/27/2023 18:54:10 - INFO - __main__ - Per validation step average loss is 0.030107121914625168\n",
      "07/27/2023 18:54:10 - INFO - __main__ - Cumulative validation average loss is 0.8435706570744514\n",
      "07/27/2023 18:54:10 - INFO - __main__ - Per validation step average loss is 0.011439093388617039\n",
      "07/27/2023 18:54:10 - INFO - __main__ - Cumulative validation average loss is 0.8550097504630685\n",
      "07/27/2023 18:54:11 - INFO - __main__ - Per validation step average loss is 0.21740522980690002\n",
      "07/27/2023 18:54:11 - INFO - __main__ - Cumulative validation average loss is 1.0724149802699685\n",
      "07/27/2023 18:54:11 - INFO - __main__ - Per validation step average loss is 0.019908087328076363\n",
      "07/27/2023 18:54:11 - INFO - __main__ - Cumulative validation average loss is 1.0923230675980449\n",
      "07/27/2023 18:54:12 - INFO - __main__ - Per validation step average loss is 0.019460491836071014\n",
      "07/27/2023 18:54:12 - INFO - __main__ - Cumulative validation average loss is 1.1117835594341159\n",
      "07/27/2023 18:54:12 - INFO - __main__ - Per validation step average loss is 0.020238950848579407\n",
      "07/27/2023 18:54:12 - INFO - __main__ - Cumulative validation average loss is 1.1320225102826953\n",
      "07/27/2023 18:54:12 - INFO - __main__ - Per validation step average loss is 0.05176115408539772\n",
      "07/27/2023 18:54:12 - INFO - __main__ - Cumulative validation average loss is 1.183783664368093\n",
      "07/27/2023 18:54:13 - INFO - __main__ - Per validation step average loss is 0.22362391650676727\n",
      "07/27/2023 18:54:13 - INFO - __main__ - Cumulative validation average loss is 1.4074075808748603\n",
      "07/27/2023 18:54:13 - INFO - __main__ - Per validation step average loss is 0.02977188490331173\n",
      "07/27/2023 18:54:13 - INFO - __main__ - Cumulative validation average loss is 1.437179465778172\n",
      "07/27/2023 18:54:14 - INFO - __main__ - Per validation step average loss is 0.005081711336970329\n",
      "07/27/2023 18:54:14 - INFO - __main__ - Cumulative validation average loss is 1.4422611771151423\n",
      "07/27/2023 18:54:14 - INFO - __main__ - Per validation step average loss is 0.34834444522857666\n",
      "07/27/2023 18:54:14 - INFO - __main__ - Cumulative validation average loss is 1.790605622343719\n",
      "07/27/2023 18:54:14 - INFO - __main__ - Per validation step average loss is 0.016735058277845383\n",
      "07/27/2023 18:54:14 - INFO - __main__ - Cumulative validation average loss is 1.8073406806215644\n",
      "07/27/2023 18:54:15 - INFO - __main__ - Per validation step average loss is 0.012851063162088394\n",
      "07/27/2023 18:54:15 - INFO - __main__ - Cumulative validation average loss is 1.8201917437836528\n",
      "07/27/2023 18:54:15 - INFO - __main__ - Per validation step average loss is 0.31949299573898315\n",
      "07/27/2023 18:54:15 - INFO - __main__ - Cumulative validation average loss is 2.139684739522636\n",
      "07/27/2023 18:54:16 - INFO - __main__ - Per validation step average loss is 0.4746818542480469\n",
      "07/27/2023 18:54:16 - INFO - __main__ - Cumulative validation average loss is 2.614366593770683\n",
      "07/27/2023 18:54:16 - INFO - __main__ - Per validation step average loss is 0.3592562973499298\n",
      "07/27/2023 18:54:16 - INFO - __main__ - Cumulative validation average loss is 2.9736228911206126\n",
      "07/27/2023 18:54:17 - INFO - __main__ - Per validation step average loss is 0.015117691829800606\n",
      "07/27/2023 18:54:17 - INFO - __main__ - Cumulative validation average loss is 2.9887405829504132\n",
      "07/27/2023 18:54:17 - INFO - __main__ - Per validation step average loss is 0.004526929929852486\n",
      "07/27/2023 18:54:17 - INFO - __main__ - Cumulative validation average loss is 2.9932675128802657\n",
      "07/27/2023 18:54:17 - INFO - __main__ - Per validation step average loss is 0.5202162265777588\n",
      "07/27/2023 18:54:17 - INFO - __main__ - Cumulative validation average loss is 3.5134837394580245\n",
      "07/27/2023 18:54:18 - INFO - __main__ - Per validation step average loss is 0.028765898197889328\n",
      "07/27/2023 18:54:18 - INFO - __main__ - Cumulative validation average loss is 3.542249637655914\n",
      "07/27/2023 18:54:18 - INFO - __main__ - Per validation step average loss is 0.005113913677632809\n",
      "07/27/2023 18:54:18 - INFO - __main__ - Cumulative validation average loss is 3.5473635513335466\n",
      "07/27/2023 18:54:19 - INFO - __main__ - Per validation step average loss is 0.0184120275080204\n",
      "07/27/2023 18:54:19 - INFO - __main__ - Cumulative validation average loss is 3.565775578841567\n",
      "07/27/2023 18:54:19 - INFO - __main__ - Per validation step average loss is 0.10130059719085693\n",
      "07/27/2023 18:54:19 - INFO - __main__ - Cumulative validation average loss is 3.667076176032424\n",
      "07/27/2023 18:54:19 - INFO - __main__ - Per validation step average loss is 0.012917839922010899\n",
      "07/27/2023 18:54:19 - INFO - __main__ - Cumulative validation average loss is 3.679994015954435\n",
      "07/27/2023 18:54:20 - INFO - __main__ - Per validation step average loss is 0.17189860343933105\n",
      "07/27/2023 18:54:20 - INFO - __main__ - Cumulative validation average loss is 3.851892619393766\n",
      "07/27/2023 18:54:20 - INFO - __main__ - Per validation step average loss is 0.04239208251237869\n",
      "07/27/2023 18:54:20 - INFO - __main__ - Cumulative validation average loss is 3.8942847019061446\n",
      "07/27/2023 18:54:21 - INFO - __main__ - Per validation step average loss is 0.01448608934879303\n",
      "07/27/2023 18:54:21 - INFO - __main__ - Cumulative validation average loss is 3.9087707912549376\n",
      "07/27/2023 18:54:21 - INFO - __main__ - Per validation step average loss is 0.011374369263648987\n",
      "07/27/2023 18:54:21 - INFO - __main__ - Cumulative validation average loss is 3.9201451605185866\n",
      "07/27/2023 18:54:21 - INFO - __main__ - Per validation step average loss is 0.0029020546935498714\n",
      "07/27/2023 18:54:21 - INFO - __main__ - Cumulative validation average loss is 3.9230472152121365\n",
      "07/27/2023 18:54:22 - INFO - __main__ - Per validation step average loss is 0.03672141581773758\n",
      "07/27/2023 18:54:22 - INFO - __main__ - Cumulative validation average loss is 3.959768631029874\n",
      "07/27/2023 18:54:22 - INFO - __main__ - Per validation step average loss is 0.00486043281853199\n",
      "07/27/2023 18:54:22 - INFO - __main__ - Cumulative validation average loss is 3.964629063848406\n",
      "07/27/2023 18:54:23 - INFO - __main__ - Per validation step average loss is 0.04218734800815582\n",
      "07/27/2023 18:54:23 - INFO - __main__ - Cumulative validation average loss is 4.006816411856562\n",
      "07/27/2023 18:54:23 - INFO - __main__ - Per validation step average loss is 0.24354805052280426\n",
      "07/27/2023 18:54:23 - INFO - __main__ - Cumulative validation average loss is 4.250364462379366\n",
      "07/27/2023 18:54:24 - INFO - __main__ - Per validation step average loss is 0.003774643409997225\n",
      "07/27/2023 18:54:24 - INFO - __main__ - Cumulative validation average loss is 4.254139105789363\n",
      "07/27/2023 18:54:24 - INFO - __main__ - Per validation step average loss is 0.2970225512981415\n",
      "07/27/2023 18:54:24 - INFO - __main__ - Cumulative validation average loss is 4.551161657087505\n",
      "07/27/2023 18:54:24 - INFO - __main__ - Per validation step average loss is 0.2916540503501892\n",
      "07/27/2023 18:54:24 - INFO - __main__ - Cumulative validation average loss is 4.842815707437694\n",
      "07/27/2023 18:54:25 - INFO - __main__ - Per validation step average loss is 0.018311675637960434\n",
      "07/27/2023 18:54:25 - INFO - __main__ - Cumulative validation average loss is 4.8611273830756545\n",
      "07/27/2023 18:54:25 - INFO - __main__ - Per validation step average loss is 0.11364124715328217\n",
      "07/27/2023 18:54:25 - INFO - __main__ - Cumulative validation average loss is 4.974768630228937\n",
      "07/27/2023 18:54:26 - INFO - __main__ - Per validation step average loss is 0.02966904267668724\n",
      "07/27/2023 18:54:26 - INFO - __main__ - Cumulative validation average loss is 5.004437672905624\n",
      "07/27/2023 18:54:26 - INFO - __main__ - Per validation step average loss is 0.006910805590450764\n",
      "07/27/2023 18:54:26 - INFO - __main__ - Cumulative validation average loss is 5.011348478496075\n",
      "07/27/2023 18:54:26 - INFO - __main__ - Per validation step average loss is 0.02531515061855316\n",
      "07/27/2023 18:54:26 - INFO - __main__ - Cumulative validation average loss is 5.036663629114628\n",
      "07/27/2023 18:54:27 - INFO - __main__ - Per validation step average loss is 0.00733755761757493\n",
      "07/27/2023 18:54:27 - INFO - __main__ - Cumulative validation average loss is 5.044001186732203\n",
      "07/27/2023 18:54:27 - INFO - __main__ - Per validation step average loss is 0.002943438710644841\n",
      "07/27/2023 18:54:27 - INFO - __main__ - Cumulative validation average loss is 5.046944625442848\n",
      "07/27/2023 18:54:28 - INFO - __main__ - Per validation step average loss is 0.24016177654266357\n",
      "07/27/2023 18:54:28 - INFO - __main__ - Cumulative validation average loss is 5.287106401985511\n",
      "07/27/2023 18:54:28 - INFO - __main__ - Per validation step average loss is 0.2305046021938324\n",
      "07/27/2023 18:54:28 - INFO - __main__ - Cumulative validation average loss is 5.517611004179344\n",
      "07/27/2023 18:54:29 - INFO - __main__ - Per validation step average loss is 0.10959906876087189\n",
      "07/27/2023 18:54:29 - INFO - __main__ - Cumulative validation average loss is 5.6272100729402155\n",
      "07/27/2023 18:54:29 - INFO - __main__ - Per validation step average loss is 0.008714708499610424\n",
      "07/27/2023 18:54:29 - INFO - __main__ - Cumulative validation average loss is 5.635924781439826\n",
      "07/27/2023 18:54:29 - INFO - __main__ - Per validation step average loss is 0.1067734807729721\n",
      "07/27/2023 18:54:29 - INFO - __main__ - Cumulative validation average loss is 5.742698262212798\n",
      "07/27/2023 18:54:30 - INFO - __main__ - Per validation step average loss is 0.0826549082994461\n",
      "07/27/2023 18:54:30 - INFO - __main__ - Cumulative validation average loss is 5.825353170512244\n",
      "07/27/2023 18:54:30 - INFO - __main__ - Per validation step average loss is 0.06201387941837311\n",
      "07/27/2023 18:54:30 - INFO - __main__ - Cumulative validation average loss is 5.887367049930617\n",
      "07/27/2023 18:54:31 - INFO - __main__ - Per validation step average loss is 0.13969409465789795\n",
      "07/27/2023 18:54:31 - INFO - __main__ - Cumulative validation average loss is 6.027061144588515\n",
      "07/27/2023 18:54:31 - INFO - __main__ - Per validation step average loss is 0.004596706945449114\n",
      "07/27/2023 18:54:31 - INFO - __main__ - Cumulative validation average loss is 6.031657851533964\n",
      "07/27/2023 18:54:31 - INFO - __main__ - Per validation step average loss is 0.01039960514754057\n",
      "07/27/2023 18:54:31 - INFO - __main__ - Cumulative validation average loss is 6.042057456681505\n",
      "07/27/2023 18:54:32 - INFO - __main__ - Per validation step average loss is 0.06379686295986176\n",
      "07/27/2023 18:54:32 - INFO - __main__ - Cumulative validation average loss is 6.105854319641367\n",
      "07/27/2023 18:54:32 - INFO - __main__ - Per validation step average loss is 0.049091942608356476\n",
      "07/27/2023 18:54:32 - INFO - __main__ - Cumulative validation average loss is 6.154946262249723\n",
      "07/27/2023 18:54:33 - INFO - __main__ - Per validation step average loss is 0.014295913279056549\n",
      "07/27/2023 18:54:33 - INFO - __main__ - Cumulative validation average loss is 6.16924217552878\n",
      "07/27/2023 18:54:33 - INFO - __main__ - Per validation step average loss is 0.012503473088145256\n",
      "07/27/2023 18:54:33 - INFO - __main__ - Cumulative validation average loss is 6.181745648616925\n",
      "07/27/2023 18:54:34 - INFO - __main__ - Per validation step average loss is 0.015048645436763763\n",
      "07/27/2023 18:54:34 - INFO - __main__ - Cumulative validation average loss is 6.196794294053689\n",
      "07/27/2023 18:54:34 - INFO - __main__ - Per validation step average loss is 0.01825626939535141\n",
      "07/27/2023 18:54:34 - INFO - __main__ - Cumulative validation average loss is 6.21505056344904\n",
      "07/27/2023 18:54:34 - INFO - __main__ - Per validation step average loss is 0.09173901379108429\n",
      "07/27/2023 18:54:34 - INFO - __main__ - Cumulative validation average loss is 6.306789577240124\n",
      "07/27/2023 18:54:35 - INFO - __main__ - Per validation step average loss is 0.10421156883239746\n",
      "07/27/2023 18:54:35 - INFO - __main__ - Cumulative validation average loss is 6.411001146072522\n",
      "07/27/2023 18:54:35 - INFO - __main__ - Per validation step average loss is 0.21188649535179138\n",
      "07/27/2023 18:54:35 - INFO - __main__ - Cumulative validation average loss is 6.622887641424313\n",
      "07/27/2023 18:54:36 - INFO - __main__ - Per validation step average loss is 0.010443995706737041\n",
      "07/27/2023 18:54:36 - INFO - __main__ - Cumulative validation average loss is 6.63333163713105\n",
      "07/27/2023 18:54:36 - INFO - __main__ - Per validation step average loss is 0.07145076990127563\n",
      "07/27/2023 18:54:36 - INFO - __main__ - Cumulative validation average loss is 6.704782407032326\n",
      "07/27/2023 18:54:36 - INFO - __main__ - Per validation step average loss is 0.17793019115924835\n",
      "07/27/2023 18:54:36 - INFO - __main__ - Cumulative validation average loss is 6.882712598191574\n",
      "07/27/2023 18:54:37 - INFO - __main__ - Per validation step average loss is 0.013554321601986885\n",
      "07/27/2023 18:54:37 - INFO - __main__ - Cumulative validation average loss is 6.896266919793561\n",
      "07/27/2023 18:54:37 - INFO - __main__ - Per validation step average loss is 0.0014221961610019207\n",
      "07/27/2023 18:54:37 - INFO - __main__ - Cumulative validation average loss is 6.897689115954563\n",
      "07/27/2023 18:54:38 - INFO - __main__ - Per validation step average loss is 0.0014053268823772669\n",
      "07/27/2023 18:54:38 - INFO - __main__ - Cumulative validation average loss is 6.89909444283694\n",
      "07/27/2023 18:54:38 - INFO - __main__ - Per validation step average loss is 0.258551687002182\n",
      "07/27/2023 18:54:38 - INFO - __main__ - Cumulative validation average loss is 7.157646129839122\n",
      "07/27/2023 18:54:39 - INFO - __main__ - Per validation step average loss is 0.022243022918701172\n",
      "07/27/2023 18:54:39 - INFO - __main__ - Cumulative validation average loss is 7.1798891527578235\n",
      "07/27/2023 18:54:39 - INFO - __main__ - Per validation step average loss is 0.13986343145370483\n",
      "07/27/2023 18:54:39 - INFO - __main__ - Cumulative validation average loss is 7.319752584211528\n",
      "07/27/2023 18:54:39 - INFO - __main__ - Per validation step average loss is 0.03873313218355179\n",
      "07/27/2023 18:54:39 - INFO - __main__ - Cumulative validation average loss is 7.35848571639508\n",
      "07/27/2023 18:54:40 - INFO - __main__ - Per validation step average loss is 0.004652998875826597\n",
      "07/27/2023 18:54:40 - INFO - __main__ - Cumulative validation average loss is 7.363138715270907\n",
      "07/27/2023 18:54:40 - INFO - __main__ - Per validation step average loss is 0.05400533229112625\n",
      "07/27/2023 18:54:40 - INFO - __main__ - Cumulative validation average loss is 7.417144047562033\n",
      "07/27/2023 18:54:41 - INFO - __main__ - Per validation step average loss is 0.013660626485943794\n",
      "07/27/2023 18:54:41 - INFO - __main__ - Cumulative validation average loss is 7.430804674047977\n",
      "07/27/2023 18:54:41 - INFO - __main__ - Average validation loss for Epoch 26 is 0.09406081865883514\n",
      "07/27/2023 18:54:41 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 18:55:38 - INFO - __main__ - Starting epoch 27\n",
      "07/27/2023 18:55:38 - INFO - __main__ - train loss is 0.17338773608207703\n",
      "Steps:  55%|▌| 8182/15000 [1:10:49<52:10:12, 27.55s/it, lr=0.001, step_loss=0.1707/27/2023 18:55:39 - INFO - __main__ - train loss is 0.18838145770132542\n",
      "Steps:  55%|▌| 8183/15000 [1:10:49<36:37:08, 19.34s/it, lr=0.001, step_loss=0.0107/27/2023 18:55:39 - INFO - __main__ - train loss is 0.2258691731840372\n",
      "Steps:  55%|▌| 8184/15000 [1:10:49<25:43:53, 13.59s/it, lr=0.001, step_loss=0.0307/27/2023 18:55:39 - INFO - __main__ - train loss is 0.22912547551095486\n",
      "Steps:  55%|▌| 8185/15000 [1:10:49<18:06:46,  9.57s/it, lr=0.001, step_loss=0.0007/27/2023 18:55:39 - INFO - __main__ - train loss is 0.42547947727143764\n",
      "Steps:  55%|▌| 8186/15000 [1:10:50<12:46:45,  6.75s/it, lr=0.001, step_loss=0.1907/27/2023 18:55:39 - INFO - __main__ - train loss is 0.47285614348948\n",
      "Steps:  55%|▌| 8187/15000 [1:10:50<9:02:48,  4.78s/it, lr=0.001, step_loss=0.04707/27/2023 18:55:40 - INFO - __main__ - train loss is 0.5001770947128534\n",
      "Steps:  55%|▌| 8188/15000 [1:10:50<6:26:03,  3.40s/it, lr=0.001, step_loss=0.02707/27/2023 18:55:40 - INFO - __main__ - train loss is 1.0517079923301935\n",
      "Steps:  55%|▌| 8189/15000 [1:10:50<4:36:16,  2.43s/it, lr=0.001, step_loss=0.55207/27/2023 18:55:40 - INFO - __main__ - train loss is 1.197633856907487\n",
      "Steps:  55%|▌| 8190/15000 [1:10:50<3:19:27,  1.76s/it, lr=0.001, step_loss=0.14607/27/2023 18:55:40 - INFO - __main__ - train loss is 1.2020828975364566\n",
      "Steps:  55%|▌| 8191/15000 [1:10:50<2:25:41,  1.28s/it, lr=0.001, step_loss=0.00407/27/2023 18:55:40 - INFO - __main__ - train loss is 1.3641177518293262\n",
      "Steps:  55%|▌| 8192/15000 [1:10:51<1:48:04,  1.05it/s, lr=0.001, step_loss=0.16207/27/2023 18:55:40 - INFO - __main__ - train loss is 1.8295645220205188\n",
      "Steps:  55%|▌| 8193/15000 [1:10:51<1:21:43,  1.39it/s, lr=0.001, step_loss=0.46507/27/2023 18:55:41 - INFO - __main__ - train loss is 1.8401491334661841\n",
      "Steps:  55%|▌| 8194/15000 [1:10:51<1:03:17,  1.79it/s, lr=0.001, step_loss=0.01007/27/2023 18:55:41 - INFO - __main__ - train loss is 2.0918565383180976\n",
      "Steps:  55%|█ | 8195/15000 [1:10:51<50:25,  2.25it/s, lr=0.001, step_loss=0.252]07/27/2023 18:55:41 - INFO - __main__ - train loss is 2.0952598145231605\n",
      "Steps:  55%|▌| 8196/15000 [1:10:51<41:23,  2.74it/s, lr=0.001, step_loss=0.0034]07/27/2023 18:55:41 - INFO - __main__ - train loss is 2.122971416451037\n",
      "Steps:  55%|▌| 8197/15000 [1:10:51<35:04,  3.23it/s, lr=0.001, step_loss=0.0277]07/27/2023 18:55:41 - INFO - __main__ - train loss is 2.3627631375566125\n",
      "Steps:  55%|█▋ | 8198/15000 [1:10:52<30:39,  3.70it/s, lr=0.001, step_loss=0.24]07/27/2023 18:55:42 - INFO - __main__ - train loss is 2.5709964940324426\n",
      "Steps:  55%|█ | 8199/15000 [1:10:52<27:34,  4.11it/s, lr=0.001, step_loss=0.208]07/27/2023 18:55:42 - INFO - __main__ - train loss is 3.065998257137835\n",
      "Steps:  55%|█ | 8200/15000 [1:10:52<25:24,  4.46it/s, lr=0.001, step_loss=0.495]07/27/2023 18:55:42 - INFO - __main__ - train loss is 3.098030191846192\n",
      "Steps:  55%|█ | 8201/15000 [1:10:52<23:53,  4.74it/s, lr=0.001, step_loss=0.032]07/27/2023 18:55:42 - INFO - __main__ - train loss is 3.2842589141801\n",
      "Steps:  55%|█ | 8202/15000 [1:10:52<22:49,  4.96it/s, lr=0.001, step_loss=0.186]07/27/2023 18:55:42 - INFO - __main__ - train loss is 3.289600568357855\n",
      "Steps:  55%|▌| 8203/15000 [1:10:53<22:05,  5.13it/s, lr=0.001, step_loss=0.0053407/27/2023 18:55:42 - INFO - __main__ - train loss is 3.2946293633431196\n",
      "Steps:  55%|▌| 8204/15000 [1:10:53<21:34,  5.25it/s, lr=0.001, step_loss=0.0050307/27/2023 18:55:43 - INFO - __main__ - train loss is 3.29720676317811\n",
      "Steps:  55%|▌| 8205/15000 [1:10:53<21:12,  5.34it/s, lr=0.001, step_loss=0.0025807/27/2023 18:55:43 - INFO - __main__ - train loss is 3.353672619909048\n",
      "Steps:  55%|▌| 8206/15000 [1:10:53<20:59,  5.40it/s, lr=0.001, step_loss=0.0565]07/27/2023 18:55:43 - INFO - __main__ - train loss is 3.3595170667394996\n",
      "Steps:  55%|▌| 8207/15000 [1:10:53<20:55,  5.41it/s, lr=0.001, step_loss=0.0058407/27/2023 18:55:43 - INFO - __main__ - train loss is 3.363838715478778\n",
      "Steps:  55%|▌| 8208/15000 [1:10:53<20:45,  5.45it/s, lr=0.001, step_loss=0.0043207/27/2023 18:55:43 - INFO - __main__ - train loss is 3.791316730901599\n",
      "Steps:  55%|█ | 8209/15000 [1:10:54<20:39,  5.48it/s, lr=0.001, step_loss=0.427]07/27/2023 18:55:44 - INFO - __main__ - train loss is 3.801183675415814\n",
      "Steps:  55%|▌| 8210/15000 [1:10:54<20:32,  5.51it/s, lr=0.001, step_loss=0.0098707/27/2023 18:55:44 - INFO - __main__ - train loss is 3.958350454457104\n",
      "Steps:  55%|█ | 8211/15000 [1:10:54<20:28,  5.53it/s, lr=0.001, step_loss=0.157]07/27/2023 18:55:44 - INFO - __main__ - train loss is 4.727236484177411\n",
      "Steps:  55%|█ | 8212/15000 [1:10:54<20:25,  5.54it/s, lr=0.001, step_loss=0.769]07/27/2023 18:55:44 - INFO - __main__ - train loss is 4.736902835778892\n",
      "Steps:  55%|▌| 8213/15000 [1:10:54<20:24,  5.54it/s, lr=0.001, step_loss=0.0096707/27/2023 18:55:44 - INFO - __main__ - train loss is 4.742251572199166\n",
      "Steps:  55%|▌| 8214/15000 [1:10:55<20:22,  5.55it/s, lr=0.001, step_loss=0.0053507/27/2023 18:55:44 - INFO - __main__ - train loss is 4.759788277558982\n",
      "Steps:  55%|▌| 8215/15000 [1:10:55<20:28,  5.53it/s, lr=0.001, step_loss=0.0175]07/27/2023 18:55:45 - INFO - __main__ - train loss is 5.35676038544625\n",
      "Steps:  55%|█ | 8216/15000 [1:10:55<20:25,  5.53it/s, lr=0.001, step_loss=0.597]07/27/2023 18:55:45 - INFO - __main__ - train loss is 5.566756698302925\n",
      "Steps:  55%|█▋ | 8217/15000 [1:10:55<20:24,  5.54it/s, lr=0.001, step_loss=0.21]07/27/2023 18:55:45 - INFO - __main__ - train loss is 5.569817929528654\n",
      "Steps:  55%|▌| 8218/15000 [1:10:55<20:32,  5.50it/s, lr=0.001, step_loss=0.0030607/27/2023 18:55:45 - INFO - __main__ - train loss is 5.625453247688711\n",
      "Steps:  55%|▌| 8219/15000 [1:10:55<20:28,  5.52it/s, lr=0.001, step_loss=0.0556]07/27/2023 18:55:45 - INFO - __main__ - train loss is 6.196864261291921\n",
      "Steps:  55%|█ | 8220/15000 [1:10:56<20:25,  5.53it/s, lr=0.001, step_loss=0.571]07/27/2023 18:55:46 - INFO - __main__ - train loss is 6.288118838332593\n",
      "Steps:  55%|▌| 8221/15000 [1:10:56<20:23,  5.54it/s, lr=0.001, step_loss=0.0913]07/27/2023 18:55:46 - INFO - __main__ - train loss is 6.415479241870344\n",
      "Steps:  55%|█ | 8222/15000 [1:10:56<20:21,  5.55it/s, lr=0.001, step_loss=0.127]07/27/2023 18:55:46 - INFO - __main__ - train loss is 6.44100699480623\n",
      "Steps:  55%|▌| 8223/15000 [1:10:56<20:20,  5.55it/s, lr=0.001, step_loss=0.0255]07/27/2023 18:55:46 - INFO - __main__ - train loss is 6.4497923934832215\n",
      "Steps:  55%|▌| 8224/15000 [1:10:56<20:20,  5.55it/s, lr=0.001, step_loss=0.0087907/27/2023 18:55:46 - INFO - __main__ - train loss is 6.670377233065665\n",
      "Steps:  55%|█ | 8225/15000 [1:10:57<20:19,  5.56it/s, lr=0.001, step_loss=0.221]07/27/2023 18:55:46 - INFO - __main__ - train loss is 6.759105988778174\n",
      "Steps:  55%|▌| 8226/15000 [1:10:57<20:18,  5.56it/s, lr=0.001, step_loss=0.0887]07/27/2023 18:55:47 - INFO - __main__ - train loss is 6.760513403452933\n",
      "Steps:  55%|▌| 8227/15000 [1:10:57<20:24,  5.53it/s, lr=0.001, step_loss=0.0014107/27/2023 18:55:47 - INFO - __main__ - train loss is 6.763268067967147\n",
      "Steps:  55%|▌| 8228/15000 [1:10:57<20:21,  5.54it/s, lr=0.001, step_loss=0.0027507/27/2023 18:55:47 - INFO - __main__ - train loss is 6.770008057821542\n",
      "Steps:  55%|▌| 8229/15000 [1:10:57<20:20,  5.55it/s, lr=0.001, step_loss=0.0067407/27/2023 18:55:47 - INFO - __main__ - train loss is 7.176666915882379\n",
      "Steps:  55%|█ | 8230/15000 [1:10:57<20:19,  5.55it/s, lr=0.001, step_loss=0.407]07/27/2023 18:55:47 - INFO - __main__ - train loss is 7.206707640085369\n",
      "Steps:  55%|█▋ | 8231/15000 [1:10:58<20:20,  5.55it/s, lr=0.001, step_loss=0.03]07/27/2023 18:55:47 - INFO - __main__ - train loss is 7.213043872732669\n",
      "Steps:  55%|▌| 8232/15000 [1:10:58<20:19,  5.55it/s, lr=0.001, step_loss=0.0063407/27/2023 18:55:48 - INFO - __main__ - train loss is 7.78579479875043\n",
      "Steps:  55%|█ | 8233/15000 [1:10:58<20:21,  5.54it/s, lr=0.001, step_loss=0.573]07/27/2023 18:55:48 - INFO - __main__ - train loss is 7.840583257842809\n",
      "Steps:  55%|▌| 8234/15000 [1:10:58<20:30,  5.50it/s, lr=0.001, step_loss=0.0548]07/27/2023 18:55:48 - INFO - __main__ - train loss is 7.8455089018680155\n",
      "Steps:  55%|▌| 8235/15000 [1:10:58<20:25,  5.52it/s, lr=0.001, step_loss=0.0049307/27/2023 18:55:48 - INFO - __main__ - train loss is 7.998604326043278\n",
      "Steps:  55%|█ | 8236/15000 [1:10:59<20:31,  5.49it/s, lr=0.001, step_loss=0.153]07/27/2023 18:55:48 - INFO - __main__ - train loss is 8.053849356714636\n",
      "Steps:  55%|▌| 8237/15000 [1:10:59<20:34,  5.48it/s, lr=0.001, step_loss=0.0552]07/27/2023 18:55:49 - INFO - __main__ - train loss is 8.055168435326777\n",
      "Steps:  55%|▌| 8238/15000 [1:10:59<20:40,  5.45it/s, lr=0.001, step_loss=0.0013207/27/2023 18:55:49 - INFO - __main__ - train loss is 8.069822041667067\n",
      "Steps:  55%|▌| 8239/15000 [1:10:59<20:37,  5.47it/s, lr=0.001, step_loss=0.0147]07/27/2023 18:55:49 - INFO - __main__ - train loss is 8.521320162690245\n",
      "Steps:  55%|█ | 8240/15000 [1:10:59<20:30,  5.49it/s, lr=0.001, step_loss=0.451]07/27/2023 18:55:49 - INFO - __main__ - train loss is 8.772996155894361\n",
      "Steps:  55%|█ | 8241/15000 [1:10:59<20:33,  5.48it/s, lr=0.001, step_loss=0.252]07/27/2023 18:55:49 - INFO - __main__ - train loss is 8.809671962982975\n",
      "Steps:  55%|▌| 8242/15000 [1:11:00<20:37,  5.46it/s, lr=0.001, step_loss=0.0367]07/27/2023 18:55:49 - INFO - __main__ - train loss is 8.829999141744338\n",
      "Steps:  55%|▌| 8243/15000 [1:11:00<20:37,  5.46it/s, lr=0.001, step_loss=0.0203]07/27/2023 18:55:50 - INFO - __main__ - train loss is 8.849146705470048\n",
      "Steps:  55%|▌| 8244/15000 [1:11:00<20:31,  5.49it/s, lr=0.001, step_loss=0.0191]07/27/2023 18:55:50 - INFO - __main__ - train loss is 8.890010763308965\n",
      "Steps:  55%|▌| 8245/15000 [1:11:00<20:26,  5.51it/s, lr=0.001, step_loss=0.0409]07/27/2023 18:55:50 - INFO - __main__ - train loss is 9.305905152461492\n",
      "Steps:  55%|█ | 8246/15000 [1:11:00<20:52,  5.39it/s, lr=0.001, step_loss=0.416]07/27/2023 18:55:50 - INFO - __main__ - train loss is 9.365441698930226\n",
      "Steps:  55%|▌| 8247/15000 [1:11:01<21:38,  5.20it/s, lr=0.001, step_loss=0.0595]07/27/2023 18:55:50 - INFO - __main__ - train loss is 9.366766584222205\n",
      "Steps:  55%|▌| 8248/15000 [1:11:01<21:27,  5.24it/s, lr=0.001, step_loss=0.0013207/27/2023 18:55:51 - INFO - __main__ - train loss is 9.379681215737946\n",
      "Steps:  55%|▌| 8249/15000 [1:11:01<21:34,  5.21it/s, lr=0.001, step_loss=0.0129]07/27/2023 18:55:51 - INFO - __main__ - train loss is 10.267685757135041\n",
      "Steps:  55%|█ | 8250/15000 [1:11:01<21:53,  5.14it/s, lr=0.001, step_loss=0.888]07/27/2023 18:55:51 - INFO - __main__ - train loss is 10.842964396928437\n",
      "Steps:  55%|█ | 8251/15000 [1:11:01<21:24,  5.25it/s, lr=0.001, step_loss=0.575]07/27/2023 18:55:51 - INFO - __main__ - train loss is 10.904710100148804\n",
      "Steps:  55%|▌| 8252/15000 [1:11:02<21:02,  5.35it/s, lr=0.001, step_loss=0.0617]07/27/2023 18:55:51 - INFO - __main__ - train loss is 11.206395642017014\n",
      "Steps:  55%|█ | 8253/15000 [1:11:02<20:47,  5.41it/s, lr=0.001, step_loss=0.302]07/27/2023 18:55:52 - INFO - __main__ - train loss is 11.293137327884324\n",
      "Steps:  55%|▌| 8254/15000 [1:11:02<20:39,  5.44it/s, lr=0.001, step_loss=0.0867]07/27/2023 18:55:52 - INFO - __main__ - train loss is 11.480675027822144\n",
      "Steps:  55%|█ | 8255/15000 [1:11:02<20:32,  5.47it/s, lr=0.001, step_loss=0.188]07/27/2023 18:55:52 - INFO - __main__ - train loss is 11.63927501544822\n",
      "Steps:  55%|█ | 8256/15000 [1:11:02<20:26,  5.50it/s, lr=0.001, step_loss=0.159]07/27/2023 18:55:52 - INFO - __main__ - train loss is 11.82210077450145\n",
      "Steps:  55%|█ | 8257/15000 [1:11:02<20:22,  5.52it/s, lr=0.001, step_loss=0.183]07/27/2023 18:55:52 - INFO - __main__ - train loss is 11.975999520276673\n",
      "Steps:  55%|█ | 8258/15000 [1:11:03<20:18,  5.53it/s, lr=0.001, step_loss=0.154]07/27/2023 18:55:52 - INFO - __main__ - train loss is 11.98984304361511\n",
      "Steps:  55%|▌| 8259/15000 [1:11:03<20:16,  5.54it/s, lr=0.001, step_loss=0.0138]07/27/2023 18:55:53 - INFO - __main__ - train loss is 12.517590734292753\n",
      "Steps:  55%|█ | 8260/15000 [1:11:03<20:14,  5.55it/s, lr=0.001, step_loss=0.528]07/27/2023 18:55:53 - INFO - __main__ - train loss is 12.6670393376844\n",
      "Steps:  55%|█ | 8261/15000 [1:11:03<20:12,  5.56it/s, lr=0.001, step_loss=0.149]07/27/2023 18:55:53 - INFO - __main__ - train loss is 12.870926412870176\n",
      "Steps:  55%|█ | 8262/15000 [1:11:03<20:11,  5.56it/s, lr=0.001, step_loss=0.204]07/27/2023 18:55:53 - INFO - __main__ - train loss is 13.487787219812162\n",
      "Steps:  55%|█ | 8263/15000 [1:11:03<20:10,  5.57it/s, lr=0.001, step_loss=0.617]07/27/2023 18:55:53 - INFO - __main__ - train loss is 13.499023999203928\n",
      "Steps:  55%|▌| 8264/15000 [1:11:04<20:09,  5.57it/s, lr=0.001, step_loss=0.0112]07/27/2023 18:55:54 - INFO - __main__ - train loss is 13.517791823600419\n",
      "Steps:  55%|▌| 8265/15000 [1:11:04<20:26,  5.49it/s, lr=0.001, step_loss=0.0188]07/27/2023 18:55:54 - INFO - __main__ - train loss is 13.562591553782113\n",
      "Steps:  55%|▌| 8266/15000 [1:11:04<20:20,  5.52it/s, lr=0.001, step_loss=0.0448]07/27/2023 18:55:54 - INFO - __main__ - train loss is 13.796912209247239\n",
      "Steps:  55%|█ | 8267/15000 [1:11:04<20:16,  5.54it/s, lr=0.001, step_loss=0.234]07/27/2023 18:55:54 - INFO - __main__ - train loss is 13.911400684271939\n",
      "Steps:  55%|█ | 8268/15000 [1:11:04<20:13,  5.55it/s, lr=0.001, step_loss=0.114]07/27/2023 18:55:54 - INFO - __main__ - train loss is 13.913323877146468\n",
      "Steps:  55%|▌| 8269/15000 [1:11:05<20:11,  5.56it/s, lr=0.001, step_loss=0.0019207/27/2023 18:55:54 - INFO - __main__ - train loss is 14.015336764743552\n",
      "Steps:  55%|█ | 8270/15000 [1:11:05<20:09,  5.56it/s, lr=0.001, step_loss=0.102]07/27/2023 18:55:55 - INFO - __main__ - train loss is 14.019567523850128\n",
      "Steps:  55%|▌| 8271/15000 [1:11:05<20:09,  5.56it/s, lr=0.001, step_loss=0.0042307/27/2023 18:55:55 - INFO - __main__ - train loss is 14.06188312987797\n",
      "Steps:  55%|▌| 8272/15000 [1:11:05<20:09,  5.56it/s, lr=0.001, step_loss=0.0423]07/27/2023 18:55:55 - INFO - __main__ - train loss is 14.431077995104715\n",
      "Steps:  55%|█ | 8273/15000 [1:11:05<20:09,  5.56it/s, lr=0.001, step_loss=0.369]07/27/2023 18:55:55 - INFO - __main__ - train loss is 14.453894515288994\n",
      "Steps:  55%|▌| 8274/15000 [1:11:05<20:08,  5.56it/s, lr=0.001, step_loss=0.0228]07/27/2023 18:55:55 - INFO - __main__ - train loss is 14.749748189700767\n",
      "Steps:  55%|█ | 8275/15000 [1:11:06<20:08,  5.56it/s, lr=0.001, step_loss=0.296]07/27/2023 18:55:56 - INFO - __main__ - train loss is 14.759460876462981\n",
      "Steps:  55%|▌| 8276/15000 [1:11:06<20:08,  5.56it/s, lr=0.001, step_loss=0.0097107/27/2023 18:55:56 - INFO - __main__ - train loss is 14.924859816906974\n",
      "Steps:  55%|█ | 8277/15000 [1:11:06<20:07,  5.57it/s, lr=0.001, step_loss=0.165]07/27/2023 18:55:56 - INFO - __main__ - train loss is 15.002250279067084\n",
      "Steps:  55%|▌| 8278/15000 [1:11:06<20:19,  5.51it/s, lr=0.001, step_loss=0.0774]07/27/2023 18:55:56 - INFO - __main__ - train loss is 15.004875577287748\n",
      "Steps:  55%|▌| 8279/15000 [1:11:06<20:23,  5.49it/s, lr=0.001, step_loss=0.0026307/27/2023 18:55:56 - INFO - __main__ - train loss is 15.2146696515847\n",
      "Steps:  55%|█▋ | 8280/15000 [1:11:07<20:19,  5.51it/s, lr=0.001, step_loss=0.21]07/27/2023 18:55:56 - INFO - __main__ - train loss is 15.232090573059395\n",
      "Steps:  55%|▌| 8281/15000 [1:11:07<20:19,  5.51it/s, lr=0.001, step_loss=0.0174]07/27/2023 18:55:57 - INFO - __main__ - train loss is 15.240257537225261\n",
      "Steps:  55%|▌| 8282/15000 [1:11:07<20:21,  5.50it/s, lr=0.001, step_loss=0.0081707/27/2023 18:55:57 - INFO - __main__ - train loss is 15.24555944581516\n",
      "Steps:  55%|▌| 8283/15000 [1:11:07<20:33,  5.45it/s, lr=0.001, step_loss=0.0053]07/27/2023 18:55:57 - INFO - __main__ - train loss is 15.420788905816153\n",
      "Steps:  55%|█ | 8284/15000 [1:11:07<20:29,  5.46it/s, lr=0.001, step_loss=0.175]07/27/2023 18:55:57 - INFO - __main__ - train loss is 15.43092265096493\n",
      "Steps:  55%|▌| 8285/15000 [1:11:07<20:22,  5.49it/s, lr=0.001, step_loss=0.0101]07/27/2023 18:55:57 - INFO - __main__ - train loss is 15.442869774298742\n",
      "Steps:  55%|▌| 8286/15000 [1:11:08<20:16,  5.52it/s, lr=0.001, step_loss=0.0119]07/27/2023 18:55:58 - INFO - __main__ - train loss is 15.451520894886926\n",
      "Steps:  55%|▌| 8287/15000 [1:11:08<20:13,  5.53it/s, lr=0.001, step_loss=0.0086507/27/2023 18:55:58 - INFO - __main__ - train loss is 15.606979941250756\n",
      "Steps:  55%|█ | 8288/15000 [1:11:08<20:10,  5.55it/s, lr=0.001, step_loss=0.155]07/27/2023 18:55:58 - INFO - __main__ - train loss is 15.61179486173205\n",
      "Steps:  55%|▌| 8289/15000 [1:11:08<20:08,  5.55it/s, lr=0.001, step_loss=0.0048107/27/2023 18:55:58 - INFO - __main__ - train loss is 15.67682351428084\n",
      "Steps:  55%|█ | 8290/15000 [1:11:08<20:07,  5.56it/s, lr=0.001, step_loss=0.065]07/27/2023 18:55:58 - INFO - __main__ - train loss is 15.924869405804202\n",
      "Steps:  55%|█ | 8291/15000 [1:11:09<20:07,  5.56it/s, lr=0.001, step_loss=0.248]07/27/2023 18:55:58 - INFO - __main__ - train loss is 15.957461300073192\n",
      "Steps:  55%|▌| 8292/15000 [1:11:09<20:06,  5.56it/s, lr=0.001, step_loss=0.0326]07/27/2023 18:55:59 - INFO - __main__ - train loss is 16.005839395103976\n",
      "Steps:  55%|▌| 8293/15000 [1:11:09<20:10,  5.54it/s, lr=0.001, step_loss=0.0484]07/27/2023 18:55:59 - INFO - __main__ - train loss is 16.115950139937922\n",
      "Steps:  55%|█▋ | 8294/15000 [1:11:09<20:18,  5.50it/s, lr=0.001, step_loss=0.11]07/27/2023 18:55:59 - INFO - __main__ - train loss is 16.118491374421865\n",
      "Steps:  55%|▌| 8295/15000 [1:11:09<20:19,  5.50it/s, lr=0.001, step_loss=0.0025407/27/2023 18:55:59 - INFO - __main__ - train loss is 16.18699047761038\n",
      "Steps:  55%|▌| 8296/15000 [1:11:09<20:14,  5.52it/s, lr=0.001, step_loss=0.0685]07/27/2023 18:55:59 - INFO - __main__ - train loss is 16.329514913726598\n",
      "Steps:  55%|█ | 8297/15000 [1:11:10<20:10,  5.54it/s, lr=0.001, step_loss=0.143]07/27/2023 18:56:00 - INFO - __main__ - train loss is 16.36366843478754\n",
      "Steps:  55%|▌| 8298/15000 [1:11:10<20:09,  5.54it/s, lr=0.001, step_loss=0.0342]07/27/2023 18:56:00 - INFO - __main__ - train loss is 16.44852599548176\n",
      "Steps:  55%|▌| 8299/15000 [1:11:10<20:07,  5.55it/s, lr=0.001, step_loss=0.0849]07/27/2023 18:56:00 - INFO - __main__ - train loss is 16.52332052635029\n",
      "Steps:  55%|▌| 8300/15000 [1:11:10<20:06,  5.55it/s, lr=0.001, step_loss=0.0748]07/27/2023 18:56:00 - INFO - __main__ - train loss is 16.59176517324522\n",
      "Steps:  55%|▌| 8301/15000 [1:11:10<20:05,  5.56it/s, lr=0.001, step_loss=0.0684]07/27/2023 18:56:00 - INFO - __main__ - train loss is 16.751374520827085\n",
      "Steps:  55%|█▋ | 8302/15000 [1:11:11<20:04,  5.56it/s, lr=0.001, step_loss=0.16]07/27/2023 18:56:00 - INFO - __main__ - train loss is 16.752749968552962\n",
      "Steps:  55%|▌| 8303/15000 [1:11:11<20:03,  5.56it/s, lr=0.001, step_loss=0.0013807/27/2023 18:56:01 - INFO - __main__ - train loss is 16.765083198668435\n",
      "Steps:  55%|▌| 8304/15000 [1:11:11<20:02,  5.57it/s, lr=0.001, step_loss=0.0123]07/27/2023 18:56:01 - INFO - __main__ - train loss is 16.843235184671357\n",
      "Steps:  55%|▌| 8305/15000 [1:11:11<20:03,  5.56it/s, lr=0.001, step_loss=0.0782]07/27/2023 18:56:01 - INFO - __main__ - train loss is 17.149165977956727\n",
      "Steps:  55%|█ | 8306/15000 [1:11:11<20:02,  5.57it/s, lr=0.001, step_loss=0.306]07/27/2023 18:56:01 - INFO - __main__ - train loss is 17.175109788076952\n",
      "Steps:  55%|▌| 8307/15000 [1:11:11<20:02,  5.57it/s, lr=0.001, step_loss=0.0259]07/27/2023 18:56:01 - INFO - __main__ - train loss is 17.435389205114916\n",
      "Steps:  55%|█▋ | 8308/15000 [1:11:12<20:03,  5.56it/s, lr=0.001, step_loss=0.26]07/27/2023 18:56:01 - INFO - __main__ - train loss is 17.468743755714968\n",
      "Steps:  55%|▌| 8309/15000 [1:11:12<20:03,  5.56it/s, lr=0.001, step_loss=0.0334]07/27/2023 18:56:02 - INFO - __main__ - train loss is 17.585794790880755\n",
      "Steps:  55%|█ | 8310/15000 [1:11:12<20:05,  5.55it/s, lr=0.001, step_loss=0.117]07/27/2023 18:56:02 - INFO - __main__ - train loss is 17.69933986593969\n",
      "Steps:  55%|█ | 8311/15000 [1:11:12<20:15,  5.50it/s, lr=0.001, step_loss=0.114]07/27/2023 18:56:02 - INFO - __main__ - train loss is 17.728490812005475\n",
      "Steps:  55%|▌| 8312/15000 [1:11:12<20:15,  5.50it/s, lr=0.001, step_loss=0.0292]07/27/2023 18:56:02 - INFO - __main__ - train loss is 17.869748902739957\n",
      "Steps:  55%|█ | 8313/15000 [1:11:13<20:11,  5.52it/s, lr=0.001, step_loss=0.141]07/27/2023 18:56:02 - INFO - __main__ - train loss is 18.03705318016\n",
      "Steps:  55%|█ | 8314/15000 [1:11:13<20:07,  5.53it/s, lr=0.001, step_loss=0.167]07/27/2023 18:56:03 - INFO - __main__ - train loss is 18.045562627958134\n",
      "Steps:  55%|▌| 8315/15000 [1:11:13<20:05,  5.54it/s, lr=0.001, step_loss=0.0085107/27/2023 18:56:03 - INFO - __main__ - train loss is 18.364714118884876\n",
      "Steps:  55%|█ | 8316/15000 [1:11:13<20:04,  5.55it/s, lr=0.001, step_loss=0.319]07/27/2023 18:56:03 - INFO - __main__ - train loss is 18.37291193031706\n",
      "Steps:  55%|▌| 8317/15000 [1:11:13<20:14,  5.50it/s, lr=0.001, step_loss=0.0082]07/27/2023 18:56:03 - INFO - __main__ - train loss is 18.401469128439203\n",
      "Steps:  55%|▌| 8318/15000 [1:11:13<20:09,  5.52it/s, lr=0.001, step_loss=0.0286]07/27/2023 18:56:03 - INFO - __main__ - train loss is 18.439378356793895\n",
      "Steps:  55%|▌| 8319/15000 [1:11:14<20:06,  5.54it/s, lr=0.001, step_loss=0.0379]07/27/2023 18:56:03 - INFO - __main__ - train loss is 18.50434764311649\n",
      "Steps:  55%|█ | 8320/15000 [1:11:14<20:04,  5.55it/s, lr=0.001, step_loss=0.065]07/27/2023 18:56:04 - INFO - __main__ - train loss is 18.506934948265553\n",
      "Steps:  55%|▌| 8321/15000 [1:11:14<20:03,  5.55it/s, lr=0.001, step_loss=0.0025907/27/2023 18:56:04 - INFO - __main__ - train loss is 18.515903279185295\n",
      "Steps:  55%|▌| 8322/15000 [1:11:14<20:05,  5.54it/s, lr=0.001, step_loss=0.0089707/27/2023 18:56:04 - INFO - __main__ - train loss is 18.68619252741337\n",
      "Steps:  55%|█▋ | 8323/15000 [1:11:14<20:09,  5.52it/s, lr=0.001, step_loss=0.17]07/27/2023 18:56:04 - INFO - __main__ - train loss is 18.687947999103926\n",
      "Steps:  55%|▌| 8324/15000 [1:11:15<20:17,  5.48it/s, lr=0.001, step_loss=0.0017607/27/2023 18:56:04 - INFO - __main__ - train loss is 18.75445051805582\n",
      "Steps:  56%|▌| 8325/15000 [1:11:15<20:34,  5.41it/s, lr=0.001, step_loss=0.0665]07/27/2023 18:56:05 - INFO - __main__ - train loss is 18.82608994410839\n",
      "Steps:  56%|▌| 8326/15000 [1:11:15<20:34,  5.41it/s, lr=0.001, step_loss=0.0716]07/27/2023 18:56:05 - INFO - __main__ - train loss is 18.828089312301017\n",
      "Steps:  56%|█ | 8327/15000 [1:11:15<20:23,  5.45it/s, lr=0.001, step_loss=0.002]07/27/2023 18:56:05 - INFO - __main__ - train loss is 18.850700259790756\n",
      "Steps:  56%|▌| 8328/15000 [1:11:15<20:18,  5.47it/s, lr=0.001, step_loss=0.0226]07/27/2023 18:56:05 - INFO - __main__ - train loss is 18.859294130117632\n",
      "Steps:  56%|▌| 8329/15000 [1:11:15<20:12,  5.50it/s, lr=0.001, step_loss=0.0085907/27/2023 18:56:05 - INFO - __main__ - train loss is 18.892340107471682\n",
      "Steps:  56%|█ | 8330/15000 [1:11:16<20:12,  5.50it/s, lr=0.001, step_loss=0.033]07/27/2023 18:56:05 - INFO - __main__ - train loss is 19.454328163177706\n",
      "Steps:  56%|█ | 8331/15000 [1:11:16<20:08,  5.52it/s, lr=0.001, step_loss=0.562]07/27/2023 18:56:06 - INFO - __main__ - train loss is 19.486170741380192\n",
      "Steps:  56%|▌| 8332/15000 [1:11:16<20:04,  5.54it/s, lr=0.001, step_loss=0.0318]07/27/2023 18:56:06 - INFO - __main__ - train loss is 19.875198634923436\n",
      "Steps:  56%|█ | 8333/15000 [1:11:16<20:02,  5.55it/s, lr=0.001, step_loss=0.389]07/27/2023 18:56:06 - INFO - __main__ - train loss is 20.254706653417088\n",
      "Steps:  56%|█▋ | 8334/15000 [1:11:16<20:01,  5.55it/s, lr=0.001, step_loss=0.38]07/27/2023 18:56:06 - INFO - __main__ - train loss is 20.311021058470942\n",
      "Steps:  56%|▌| 8335/15000 [1:11:17<19:59,  5.56it/s, lr=0.001, step_loss=0.0563]07/27/2023 18:56:06 - INFO - __main__ - train loss is 20.328756049857475\n",
      "Steps:  56%|▌| 8336/15000 [1:11:17<19:58,  5.56it/s, lr=0.001, step_loss=0.0177]07/27/2023 18:56:07 - INFO - __main__ - train loss is 20.452222914085723\n",
      "Steps:  56%|█ | 8337/15000 [1:11:17<19:58,  5.56it/s, lr=0.001, step_loss=0.123]07/27/2023 18:56:07 - INFO - __main__ - train loss is 20.541061439202167\n",
      "Steps:  56%|▌| 8338/15000 [1:11:17<20:09,  5.51it/s, lr=0.001, step_loss=0.0888]07/27/2023 18:56:07 - INFO - __main__ - train loss is 20.568663687095977\n",
      "Steps:  56%|▌| 8339/15000 [1:11:17<20:18,  5.47it/s, lr=0.001, step_loss=0.0276]07/27/2023 18:56:07 - INFO - __main__ - train loss is 21.30216273723636\n",
      "Steps:  56%|█ | 8340/15000 [1:11:17<20:22,  5.45it/s, lr=0.001, step_loss=0.733]07/27/2023 18:56:07 - INFO - __main__ - train loss is 21.30461592937354\n",
      "Steps:  56%|▌| 8341/15000 [1:11:18<20:13,  5.49it/s, lr=0.001, step_loss=0.0024507/27/2023 18:56:07 - INFO - __main__ - train loss is 21.306235631462187\n",
      "Steps:  56%|▌| 8342/15000 [1:11:18<20:08,  5.51it/s, lr=0.001, step_loss=0.0016207/27/2023 18:56:08 - INFO - __main__ - train loss is 21.537706022616476\n",
      "Steps:  56%|█ | 8343/15000 [1:11:18<20:04,  5.53it/s, lr=0.001, step_loss=0.231]07/27/2023 18:56:08 - INFO - __main__ - train loss is 21.58135695522651\n",
      "Steps:  56%|▌| 8344/15000 [1:11:18<20:01,  5.54it/s, lr=0.001, step_loss=0.0437]07/27/2023 18:56:08 - INFO - __main__ - train loss is 21.7622013813816\n",
      "Steps:  56%|█ | 8345/15000 [1:11:18<19:59,  5.55it/s, lr=0.001, step_loss=0.181]07/27/2023 18:56:08 - INFO - __main__ - train loss is 21.797522974666208\n",
      "Steps:  56%|▌| 8346/15000 [1:11:19<19:57,  5.56it/s, lr=0.001, step_loss=0.0353]07/27/2023 18:56:08 - INFO - __main__ - train loss is 22.11468015378341\n",
      "Steps:  56%|█ | 8347/15000 [1:11:19<19:56,  5.56it/s, lr=0.001, step_loss=0.317]07/27/2023 18:56:09 - INFO - __main__ - train loss is 22.158465889748186\n",
      "Steps:  56%|▌| 8348/15000 [1:11:19<19:55,  5.56it/s, lr=0.001, step_loss=0.0438]07/27/2023 18:56:09 - INFO - __main__ - train loss is 22.1633373349905\n",
      "Steps:  56%|▌| 8349/15000 [1:11:19<19:55,  5.56it/s, lr=0.001, step_loss=0.0048707/27/2023 18:56:09 - INFO - __main__ - train loss is 22.186851343140006\n",
      "Steps:  56%|▌| 8350/15000 [1:11:19<19:56,  5.56it/s, lr=0.001, step_loss=0.0235]07/27/2023 18:56:09 - INFO - __main__ - train loss is 22.487429639324546\n",
      "Steps:  56%|█ | 8351/15000 [1:11:19<19:56,  5.56it/s, lr=0.001, step_loss=0.301]07/27/2023 18:56:09 - INFO - __main__ - train loss is 22.645141890272498\n",
      "Steps:  56%|█ | 8352/15000 [1:11:20<19:55,  5.56it/s, lr=0.001, step_loss=0.158]07/27/2023 18:56:09 - INFO - __main__ - train loss is 22.65817992016673\n",
      "Steps:  56%|█ | 8353/15000 [1:11:20<19:55,  5.56it/s, lr=0.001, step_loss=0.013]07/27/2023 18:56:10 - INFO - __main__ - train loss is 22.687981417402625\n",
      "Steps:  56%|▌| 8354/15000 [1:11:20<19:55,  5.56it/s, lr=0.001, step_loss=0.0298]07/27/2023 18:56:10 - INFO - __main__ - train loss is 22.8007069285959\n",
      "Steps:  56%|█ | 8355/15000 [1:11:20<19:55,  5.56it/s, lr=0.001, step_loss=0.113]07/27/2023 18:56:10 - INFO - __main__ - train loss is 23.14155743084848\n",
      "Steps:  56%|█ | 8356/15000 [1:11:20<19:54,  5.56it/s, lr=0.001, step_loss=0.341]07/27/2023 18:56:10 - INFO - __main__ - train loss is 23.263331478461623\n",
      "Steps:  56%|█ | 8357/15000 [1:11:20<19:54,  5.56it/s, lr=0.001, step_loss=0.122]07/27/2023 18:56:10 - INFO - __main__ - train loss is 23.297286869958043\n",
      "Steps:  56%|█ | 8358/15000 [1:11:21<19:54,  5.56it/s, lr=0.001, step_loss=0.034]07/27/2023 18:56:11 - INFO - __main__ - train loss is 23.369893239811063\n",
      "Steps:  56%|▌| 8359/15000 [1:11:21<19:54,  5.56it/s, lr=0.001, step_loss=0.0726]07/27/2023 18:56:11 - INFO - __main__ - train loss is 23.434986555948853\n",
      "Steps:  56%|▌| 8360/15000 [1:11:21<19:53,  5.56it/s, lr=0.001, step_loss=0.0651]07/27/2023 18:56:11 - INFO - __main__ - train loss is 23.550065154209733\n",
      "Steps:  56%|█ | 8361/15000 [1:11:21<19:53,  5.56it/s, lr=0.001, step_loss=0.115]07/27/2023 18:56:11 - INFO - __main__ - train loss is 23.789745355024934\n",
      "Steps:  56%|█▋ | 8362/15000 [1:11:21<19:52,  5.56it/s, lr=0.001, step_loss=0.24]07/27/2023 18:56:11 - INFO - __main__ - train loss is 23.88566462881863\n",
      "Steps:  56%|▌| 8363/15000 [1:11:22<20:04,  5.51it/s, lr=0.001, step_loss=0.0959]07/27/2023 18:56:11 - INFO - __main__ - train loss is 23.998628752306104\n",
      "Steps:  56%|█ | 8364/15000 [1:11:22<20:21,  5.43it/s, lr=0.001, step_loss=0.113]07/27/2023 18:56:12 - INFO - __main__ - train loss is 24.34299452789128\n",
      "Steps:  56%|█ | 8365/15000 [1:11:22<20:21,  5.43it/s, lr=0.001, step_loss=0.344]07/27/2023 18:56:12 - INFO - __main__ - train loss is 24.35543634183705\n",
      "Steps:  56%|▌| 8366/15000 [1:11:22<20:23,  5.42it/s, lr=0.001, step_loss=0.0124]07/27/2023 18:56:12 - INFO - __main__ - train loss is 24.51618251390755\n",
      "Steps:  56%|█ | 8367/15000 [1:11:22<20:18,  5.45it/s, lr=0.001, step_loss=0.161]07/27/2023 18:56:12 - INFO - __main__ - train loss is 24.538277545943856\n",
      "Steps:  56%|▌| 8368/15000 [1:11:22<20:10,  5.48it/s, lr=0.001, step_loss=0.0221]07/27/2023 18:56:12 - INFO - __main__ - train loss is 24.540371236857027\n",
      "Steps:  56%|▌| 8369/15000 [1:11:23<20:11,  5.47it/s, lr=0.001, step_loss=0.0020907/27/2023 18:56:13 - INFO - __main__ - train loss is 24.696218413766474\n",
      "Steps:  56%|█ | 8370/15000 [1:11:23<20:05,  5.50it/s, lr=0.001, step_loss=0.156]07/27/2023 18:56:13 - INFO - __main__ - train loss is 24.916898844297975\n",
      "Steps:  56%|█ | 8371/15000 [1:11:23<20:12,  5.47it/s, lr=0.001, step_loss=0.221]07/27/2023 18:56:13 - INFO - __main__ - train loss is 25.210795877035707\n",
      "Steps:  56%|█ | 8372/15000 [1:11:23<20:07,  5.49it/s, lr=0.001, step_loss=0.294]07/27/2023 18:56:13 - INFO - __main__ - train loss is 25.41757118469104\n",
      "Steps:  56%|█ | 8373/15000 [1:11:23<20:02,  5.51it/s, lr=0.001, step_loss=0.207]07/27/2023 18:56:13 - INFO - __main__ - train loss is 25.46789744263515\n",
      "Steps:  56%|▌| 8374/15000 [1:11:24<19:58,  5.53it/s, lr=0.001, step_loss=0.0503]07/27/2023 18:56:13 - INFO - __main__ - train loss is 25.603730706032366\n",
      "Steps:  56%|█ | 8375/15000 [1:11:24<19:55,  5.54it/s, lr=0.001, step_loss=0.136]07/27/2023 18:56:14 - INFO - __main__ - train loss is 25.699930330272764\n",
      "Steps:  56%|▌| 8376/15000 [1:11:24<19:54,  5.55it/s, lr=0.001, step_loss=0.0962]07/27/2023 18:56:14 - INFO - __main__ - train loss is 25.788048645015806\n",
      "Steps:  56%|▌| 8377/15000 [1:11:24<19:52,  5.55it/s, lr=0.001, step_loss=0.0881]07/27/2023 18:56:14 - INFO - __main__ - train loss is 25.98812866723165\n",
      "Steps:  56%|██▏ | 8378/15000 [1:11:24<19:52,  5.55it/s, lr=0.001, step_loss=0.2]07/27/2023 18:56:14 - INFO - __main__ - train loss is 25.991491516819224\n",
      "Steps:  56%|▌| 8379/15000 [1:11:24<19:51,  5.56it/s, lr=0.001, step_loss=0.0033607/27/2023 18:56:14 - INFO - __main__ - train loss is 26.051606049528345\n",
      "Steps:  56%|▌| 8380/15000 [1:11:25<19:50,  5.56it/s, lr=0.001, step_loss=0.0601]07/27/2023 18:56:15 - INFO - __main__ - train loss is 26.299756860127673\n",
      "Steps:  56%|█ | 8381/15000 [1:11:25<20:01,  5.51it/s, lr=0.001, step_loss=0.248]07/27/2023 18:56:15 - INFO - __main__ - train loss is 26.334312936058268\n",
      "Steps:  56%|▌| 8382/15000 [1:11:25<20:01,  5.51it/s, lr=0.001, step_loss=0.0346]07/27/2023 18:56:15 - INFO - __main__ - train loss is 26.344068445032462\n",
      "Steps:  56%|▌| 8383/15000 [1:11:25<19:57,  5.53it/s, lr=0.001, step_loss=0.0097607/27/2023 18:56:15 - INFO - __main__ - train loss is 26.43258886761032\n",
      "Steps:  56%|▌| 8384/15000 [1:11:25<19:54,  5.54it/s, lr=0.001, step_loss=0.0885]07/27/2023 18:56:15 - INFO - __main__ - train loss is 26.471106476848945\n",
      "Steps:  56%|▌| 8385/15000 [1:11:26<19:52,  5.55it/s, lr=0.001, step_loss=0.0385]07/27/2023 18:56:15 - INFO - __main__ - train loss is 26.602335028117523\n",
      "Steps:  56%|█ | 8386/15000 [1:11:26<19:51,  5.55it/s, lr=0.001, step_loss=0.131]07/27/2023 18:56:16 - INFO - __main__ - train loss is 26.608990122796968\n",
      "Steps:  56%|▌| 8387/15000 [1:11:26<19:50,  5.56it/s, lr=0.001, step_loss=0.0066607/27/2023 18:56:16 - INFO - __main__ - train loss is 26.94083129358478\n",
      "Steps:  56%|█ | 8388/15000 [1:11:26<19:49,  5.56it/s, lr=0.001, step_loss=0.332]07/27/2023 18:56:16 - INFO - __main__ - train loss is 27.082857837202027\n",
      "Steps:  56%|█ | 8389/15000 [1:11:26<19:49,  5.56it/s, lr=0.001, step_loss=0.142]07/27/2023 18:56:16 - INFO - __main__ - train loss is 27.14228490856476\n",
      "Steps:  56%|▌| 8390/15000 [1:11:26<19:48,  5.56it/s, lr=0.001, step_loss=0.0594]07/27/2023 18:56:16 - INFO - __main__ - train loss is 27.566022196086124\n",
      "Steps:  56%|█ | 8391/15000 [1:11:27<19:48,  5.56it/s, lr=0.001, step_loss=0.424]07/27/2023 18:56:17 - INFO - __main__ - train loss is 27.630156331928447\n",
      "Steps:  56%|▌| 8392/15000 [1:11:27<19:47,  5.56it/s, lr=0.001, step_loss=0.0641]07/27/2023 18:56:17 - INFO - __main__ - train loss is 27.76354014244862\n",
      "Steps:  56%|█ | 8393/15000 [1:11:27<19:47,  5.57it/s, lr=0.001, step_loss=0.133]07/27/2023 18:56:17 - INFO - __main__ - train loss is 27.769861220614985\n",
      "Steps:  56%|▌| 8394/15000 [1:11:27<19:46,  5.57it/s, lr=0.001, step_loss=0.0063207/27/2023 18:56:17 - INFO - __main__ - train loss is 27.84856943716295\n",
      "Steps:  56%|▌| 8395/15000 [1:11:27<19:46,  5.57it/s, lr=0.001, step_loss=0.0787]07/27/2023 18:56:17 - INFO - __main__ - train loss is 28.04375784029253\n",
      "Steps:  56%|█ | 8396/15000 [1:11:28<19:46,  5.57it/s, lr=0.001, step_loss=0.195]07/27/2023 18:56:17 - INFO - __main__ - train loss is 28.124550356762484\n",
      "Steps:  56%|▌| 8397/15000 [1:11:28<19:45,  5.57it/s, lr=0.001, step_loss=0.0808]07/27/2023 18:56:18 - INFO - __main__ - train loss is 28.451869203941897\n",
      "Steps:  56%|█ | 8398/15000 [1:11:28<19:45,  5.57it/s, lr=0.001, step_loss=0.327]07/27/2023 18:56:18 - INFO - __main__ - train loss is 28.50022607226856\n",
      "Steps:  56%|▌| 8399/15000 [1:11:28<19:44,  5.57it/s, lr=0.001, step_loss=0.0484]07/27/2023 18:56:18 - INFO - __main__ - train loss is 28.53218679060228\n",
      "Steps:  56%|█ | 8400/15000 [1:11:28<19:44,  5.57it/s, lr=0.001, step_loss=0.032]07/27/2023 18:56:18 - INFO - __main__ - train loss is 28.54271568194963\n",
      "Steps:  56%|▌| 8401/15000 [1:11:28<19:44,  5.57it/s, lr=0.001, step_loss=0.0105]07/27/2023 18:56:18 - INFO - __main__ - train loss is 28.551046619424596\n",
      "Steps:  56%|▌| 8402/15000 [1:11:29<19:44,  5.57it/s, lr=0.001, step_loss=0.0083307/27/2023 18:56:18 - INFO - __main__ - train loss is 28.565564392367378\n",
      "Steps:  56%|▌| 8403/15000 [1:11:29<19:44,  5.57it/s, lr=0.001, step_loss=0.0145]07/27/2023 18:56:19 - INFO - __main__ - train loss is 28.9378786070738\n",
      "Steps:  56%|█ | 8404/15000 [1:11:29<19:44,  5.57it/s, lr=0.001, step_loss=0.372]07/27/2023 18:56:19 - INFO - __main__ - train loss is 28.94935119175352\n",
      "Steps:  56%|▌| 8405/15000 [1:11:29<19:44,  5.57it/s, lr=0.001, step_loss=0.0115]07/27/2023 18:56:19 - INFO - __main__ - train loss is 28.979278734186664\n",
      "Steps:  56%|▌| 8406/15000 [1:11:29<19:44,  5.57it/s, lr=0.001, step_loss=0.0299]07/27/2023 18:56:19 - INFO - __main__ - train loss is 29.00253843725659\n",
      "Steps:  56%|▌| 8407/15000 [1:11:30<19:44,  5.56it/s, lr=0.001, step_loss=0.0233]07/27/2023 18:56:19 - INFO - __main__ - train loss is 29.06390622840263\n",
      "Steps:  56%|▌| 8408/15000 [1:11:30<19:44,  5.57it/s, lr=0.001, step_loss=0.0614]07/27/2023 18:56:20 - INFO - __main__ - train loss is 29.516747093060985\n",
      "Steps:  56%|█ | 8409/15000 [1:11:30<19:43,  5.57it/s, lr=0.001, step_loss=0.453]07/27/2023 18:56:20 - INFO - __main__ - train loss is 30.055401301244274\n",
      "Steps:  56%|█ | 8410/15000 [1:11:30<19:44,  5.57it/s, lr=0.001, step_loss=0.539]07/27/2023 18:56:20 - INFO - __main__ - train loss is 30.082583943614736\n",
      "Steps:  56%|▌| 8411/15000 [1:11:30<19:43,  5.57it/s, lr=0.001, step_loss=0.0272]07/27/2023 18:56:20 - INFO - __main__ - train loss is 30.482153276214376\n",
      "Steps:  56%|██▏ | 8412/15000 [1:11:30<19:42,  5.57it/s, lr=0.001, step_loss=0.4]07/27/2023 18:56:20 - INFO - __main__ - train loss is 30.489184773759916\n",
      "Steps:  56%|▌| 8413/15000 [1:11:31<19:43,  5.57it/s, lr=0.001, step_loss=0.0070307/27/2023 18:56:20 - INFO - __main__ - train loss is 30.54517226596363\n",
      "Steps:  56%|█ | 8414/15000 [1:11:31<19:43,  5.57it/s, lr=0.001, step_loss=0.056]07/27/2023 18:56:21 - INFO - __main__ - train loss is 30.548366678180173\n",
      "Steps:  56%|▌| 8415/15000 [1:11:31<19:43,  5.56it/s, lr=0.001, step_loss=0.0031907/27/2023 18:56:21 - INFO - __main__ - train loss is 30.74437324446626\n",
      "Steps:  56%|█ | 8416/15000 [1:11:31<19:44,  5.56it/s, lr=0.001, step_loss=0.196]07/27/2023 18:56:21 - INFO - __main__ - train loss is 31.40454034251161\n",
      "Steps:  56%|█▋ | 8417/15000 [1:11:31<19:44,  5.56it/s, lr=0.001, step_loss=0.66]07/27/2023 18:56:21 - INFO - __main__ - train loss is 31.540695620002225\n",
      "Steps:  56%|█ | 8418/15000 [1:11:31<19:52,  5.52it/s, lr=0.001, step_loss=0.136]07/27/2023 18:56:21 - INFO - __main__ - train loss is 31.782224607886747\n",
      "Steps:  56%|█ | 8419/15000 [1:11:32<19:53,  5.52it/s, lr=0.001, step_loss=0.242]07/27/2023 18:56:22 - INFO - __main__ - train loss is 32.22447491926141\n",
      "Steps:  56%|█ | 8420/15000 [1:11:32<19:49,  5.53it/s, lr=0.001, step_loss=0.442]07/27/2023 18:56:22 - INFO - __main__ - train loss is 32.253251874120906\n",
      "Steps:  56%|▌| 8421/15000 [1:11:32<19:47,  5.54it/s, lr=0.001, step_loss=0.0288]07/27/2023 18:56:22 - INFO - __main__ - train loss is 32.315509223612025\n",
      "Steps:  56%|▌| 8422/15000 [1:11:32<19:56,  5.50it/s, lr=0.001, step_loss=0.0623]07/27/2023 18:56:22 - INFO - __main__ - train loss is 32.31774630048312\n",
      "Steps:  56%|▌| 8423/15000 [1:11:32<20:06,  5.45it/s, lr=0.001, step_loss=0.0022407/27/2023 18:56:22 - INFO - __main__ - train loss is 32.32739852019586\n",
      "Steps:  56%|▌| 8424/15000 [1:11:33<20:06,  5.45it/s, lr=0.001, step_loss=0.0096507/27/2023 18:56:22 - INFO - __main__ - train loss is 32.38988706492819\n",
      "Steps:  56%|▌| 8425/15000 [1:11:33<20:12,  5.42it/s, lr=0.001, step_loss=0.0625]07/27/2023 18:56:23 - INFO - __main__ - train loss is 32.909512013429776\n",
      "Steps:  56%|█▋ | 8426/15000 [1:11:33<20:20,  5.39it/s, lr=0.001, step_loss=0.52]07/27/2023 18:56:23 - INFO - __main__ - train loss is 32.91369394608773\n",
      "Steps:  56%|▌| 8427/15000 [1:11:33<20:09,  5.43it/s, lr=0.001, step_loss=0.0041807/27/2023 18:56:23 - INFO - __main__ - train loss is 32.916341261938214\n",
      "Steps:  56%|▌| 8428/15000 [1:11:33<20:02,  5.47it/s, lr=0.001, step_loss=0.0026507/27/2023 18:56:23 - INFO - __main__ - train loss is 33.05332772620022\n",
      "Steps:  56%|█ | 8429/15000 [1:11:34<19:58,  5.48it/s, lr=0.001, step_loss=0.137]07/27/2023 18:56:23 - INFO - __main__ - train loss is 33.15617016144097\n",
      "Steps:  56%|█ | 8430/15000 [1:11:34<19:53,  5.50it/s, lr=0.001, step_loss=0.103]07/27/2023 18:56:24 - INFO - __main__ - train loss is 33.191848957911134\n",
      "Steps:  56%|▌| 8431/15000 [1:11:34<19:58,  5.48it/s, lr=0.001, step_loss=0.0357]07/27/2023 18:56:24 - INFO - __main__ - train loss is 33.63594346679747\n",
      "Steps:  56%|█ | 8432/15000 [1:11:34<20:04,  5.45it/s, lr=0.001, step_loss=0.444]07/27/2023 18:56:24 - INFO - __main__ - train loss is 33.73197958804667\n",
      "Steps:  56%|█ | 8433/15000 [1:11:34<20:06,  5.44it/s, lr=0.001, step_loss=0.096]07/27/2023 18:56:24 - INFO - __main__ - train loss is 33.73314409307204\n",
      "Steps:  56%|▌| 8434/15000 [1:11:34<19:58,  5.48it/s, lr=0.001, step_loss=0.0011607/27/2023 18:56:24 - INFO - __main__ - train loss is 33.85800804547034\n",
      "Steps:  56%|█ | 8435/15000 [1:11:35<19:53,  5.50it/s, lr=0.001, step_loss=0.125]07/27/2023 18:56:24 - INFO - __main__ - train loss is 33.98931531957351\n",
      "Steps:  56%|█ | 8436/15000 [1:11:35<19:50,  5.51it/s, lr=0.001, step_loss=0.131]07/27/2023 18:56:25 - INFO - __main__ - train loss is 33.990892001078464\n",
      "Steps:  56%|▌| 8437/15000 [1:11:35<19:47,  5.53it/s, lr=0.001, step_loss=0.0015807/27/2023 18:56:25 - INFO - __main__ - train loss is 34.2070005616406\n",
      "Steps:  56%|█▏| 8438/15000 [1:11:35<19:44,  5.54it/s, lr=0.001, step_loss=0.216]07/27/2023 18:56:25 - INFO - __main__ - train loss is 34.83433998434339\n",
      "Steps:  56%|█▏| 8439/15000 [1:11:35<19:45,  5.54it/s, lr=0.001, step_loss=0.627]07/27/2023 18:56:25 - INFO - __main__ - train loss is 34.88057567237411\n",
      "Steps:  56%|▌| 8440/15000 [1:11:36<19:44,  5.54it/s, lr=0.001, step_loss=0.0462]07/27/2023 18:56:25 - INFO - __main__ - train loss is 35.11970585642848\n",
      "Steps:  56%|█▏| 8441/15000 [1:11:36<19:43,  5.54it/s, lr=0.001, step_loss=0.239]07/27/2023 18:56:26 - INFO - __main__ - train loss is 35.25651469884906\n",
      "Steps:  56%|█▏| 8442/15000 [1:11:36<19:54,  5.49it/s, lr=0.001, step_loss=0.137]07/27/2023 18:56:26 - INFO - __main__ - train loss is 35.675703853950836\n",
      "Steps:  56%|█▏| 8443/15000 [1:11:36<20:01,  5.46it/s, lr=0.001, step_loss=0.419]07/27/2023 18:56:26 - INFO - __main__ - train loss is 35.699372742907144\n",
      "Steps:  56%|▌| 8444/15000 [1:11:36<20:02,  5.45it/s, lr=0.001, step_loss=0.0237]07/27/2023 18:56:26 - INFO - __main__ - train loss is 35.7786719991127\n",
      "Steps:  56%|▌| 8445/15000 [1:11:36<20:05,  5.44it/s, lr=0.001, step_loss=0.0793]07/27/2023 18:56:26 - INFO - __main__ - train loss is 35.785071803373285\n",
      "Steps:  56%|▌| 8446/15000 [1:11:37<20:09,  5.42it/s, lr=0.001, step_loss=0.0064]07/27/2023 18:56:26 - INFO - __main__ - train loss is 35.81305874150712\n",
      "Steps:  56%|█▏| 8447/15000 [1:11:37<20:01,  5.45it/s, lr=0.001, step_loss=0.028]07/27/2023 18:56:27 - INFO - __main__ - train loss is 35.97651048761327\n",
      "Steps:  56%|█▏| 8448/15000 [1:11:37<19:55,  5.48it/s, lr=0.001, step_loss=0.163]07/27/2023 18:56:27 - INFO - __main__ - train loss is 35.98377582349349\n",
      "Steps:  56%|▌| 8449/15000 [1:11:37<19:59,  5.46it/s, lr=0.001, step_loss=0.0072707/27/2023 18:56:27 - INFO - __main__ - train loss is 35.994442331721075\n",
      "Steps:  56%|▌| 8450/15000 [1:11:37<19:55,  5.48it/s, lr=0.001, step_loss=0.0107]07/27/2023 18:56:27 - INFO - __main__ - train loss is 36.00094344292302\n",
      "Steps:  56%|▌| 8451/15000 [1:11:38<20:03,  5.44it/s, lr=0.001, step_loss=0.0065]07/27/2023 18:56:27 - INFO - __main__ - train loss is 36.00631262373645\n",
      "Steps:  56%|▌| 8452/15000 [1:11:38<20:14,  5.39it/s, lr=0.001, step_loss=0.0053707/27/2023 18:56:28 - INFO - __main__ - train loss is 36.332376346108504\n",
      "Steps:  56%|█▏| 8453/15000 [1:11:38<20:26,  5.34it/s, lr=0.001, step_loss=0.326]07/27/2023 18:56:28 - INFO - __main__ - train loss is 36.339200466056354\n",
      "Steps:  56%|▌| 8454/15000 [1:11:38<20:47,  5.25it/s, lr=0.001, step_loss=0.0068207/27/2023 18:56:28 - INFO - __main__ - train loss is 36.34895206906367\n",
      "Steps:  56%|▌| 8455/15000 [1:11:38<21:01,  5.19it/s, lr=0.001, step_loss=0.0097507/27/2023 18:56:28 - INFO - __main__ - train loss is 36.53586770512629\n",
      "Steps:  56%|█▏| 8456/15000 [1:11:38<21:05,  5.17it/s, lr=0.001, step_loss=0.187]07/27/2023 18:56:28 - INFO - __main__ - train loss is 36.71099810220767\n",
      "Steps:  56%|█▏| 8457/15000 [1:11:39<21:13,  5.14it/s, lr=0.001, step_loss=0.175]07/27/2023 18:56:29 - INFO - __main__ - train loss is 36.71429652615916\n",
      "Steps:  56%|▌| 8458/15000 [1:11:39<21:19,  5.11it/s, lr=0.001, step_loss=0.0033]07/27/2023 18:56:29 - INFO - __main__ - train loss is 37.09939477487933\n",
      "Steps:  56%|█▏| 8459/15000 [1:11:39<21:22,  5.10it/s, lr=0.001, step_loss=0.385]07/27/2023 18:56:29 - INFO - __main__ - train loss is 37.70881161733996\n",
      "Steps:  56%|█▏| 8460/15000 [1:11:39<21:23,  5.10it/s, lr=0.001, step_loss=0.609]07/27/2023 18:56:29 - INFO - __main__ - train loss is 38.16112864657771\n",
      "Steps:  56%|█▏| 8461/15000 [1:11:39<21:20,  5.11it/s, lr=0.001, step_loss=0.452]07/27/2023 18:56:29 - INFO - __main__ - train loss is 38.20009582012426\n",
      "Steps:  56%|█▏| 8462/15000 [1:11:40<21:18,  5.11it/s, lr=0.001, step_loss=0.039]07/27/2023 18:56:30 - INFO - __main__ - train loss is 38.322776774759404\n",
      "Steps:  56%|█▏| 8463/15000 [1:11:40<21:19,  5.11it/s, lr=0.001, step_loss=0.123]07/27/2023 18:56:30 - INFO - __main__ - train loss is 38.869045059080236\n",
      "Steps:  56%|█▏| 8464/15000 [1:11:40<21:23,  5.09it/s, lr=0.001, step_loss=0.546]07/27/2023 18:56:30 - INFO - __main__ - train loss is 39.669653813238256\n",
      "Steps:  56%|█▏| 8465/15000 [1:11:40<21:21,  5.10it/s, lr=0.001, step_loss=0.801]07/27/2023 18:56:30 - INFO - __main__ - train loss is 39.696285839076154\n",
      "Steps:  56%|▌| 8466/15000 [1:11:40<21:20,  5.10it/s, lr=0.001, step_loss=0.0266]07/27/2023 18:56:30 - INFO - __main__ - train loss is 39.69891958485823\n",
      "Steps:  56%|▌| 8467/15000 [1:11:41<21:26,  5.08it/s, lr=0.001, step_loss=0.0026307/27/2023 18:56:31 - INFO - __main__ - train loss is 39.765737404930405\n",
      "Steps:  56%|▌| 8468/15000 [1:11:41<21:24,  5.09it/s, lr=0.001, step_loss=0.0668]07/27/2023 18:56:31 - INFO - __main__ - train loss is 39.86680105130654\n",
      "Steps:  56%|█▏| 8469/15000 [1:11:41<21:22,  5.09it/s, lr=0.001, step_loss=0.101]07/27/2023 18:56:31 - INFO - __main__ - train loss is 40.05546471278649\n",
      "Steps:  56%|█▏| 8470/15000 [1:11:41<21:20,  5.10it/s, lr=0.001, step_loss=0.189]07/27/2023 18:56:31 - INFO - __main__ - train loss is 40.12442794244271\n",
      "Steps:  56%|█▏| 8471/15000 [1:11:41<21:23,  5.09it/s, lr=0.001, step_loss=0.069]07/27/2023 18:56:31 - INFO - __main__ - train loss is 40.12786064611282\n",
      "Steps:  56%|▌| 8472/15000 [1:11:42<21:23,  5.08it/s, lr=0.001, step_loss=0.0034307/27/2023 18:56:32 - INFO - __main__ - train loss is 40.16662445233669\n",
      "Steps:  56%|▌| 8473/15000 [1:11:42<21:20,  5.10it/s, lr=0.001, step_loss=0.0388]07/27/2023 18:56:32 - INFO - __main__ - train loss is 40.908173705800436\n",
      "Steps:  56%|█▏| 8474/15000 [1:11:42<21:20,  5.10it/s, lr=0.001, step_loss=0.742]07/27/2023 18:56:32 - INFO - __main__ - train loss is 40.92004999460187\n",
      "Steps:  56%|▌| 8475/15000 [1:11:42<21:21,  5.09it/s, lr=0.001, step_loss=0.0119]07/27/2023 18:56:32 - INFO - __main__ - train loss is 40.9514525787672\n",
      "Steps:  57%|▌| 8476/15000 [1:11:42<21:18,  5.10it/s, lr=0.001, step_loss=0.0314]07/27/2023 18:56:32 - INFO - __main__ - train loss is 40.96203574107494\n",
      "Steps:  57%|▌| 8477/15000 [1:11:43<21:18,  5.10it/s, lr=0.001, step_loss=0.0106]07/27/2023 18:56:32 - INFO - __main__ - train loss is 40.99593665392604\n",
      "Steps:  57%|▌| 8478/15000 [1:11:43<21:18,  5.10it/s, lr=0.001, step_loss=0.0339]07/27/2023 18:56:33 - INFO - __main__ - train loss is 41.23736178071704\n",
      "Steps:  57%|█▏| 8479/15000 [1:11:43<21:18,  5.10it/s, lr=0.001, step_loss=0.241]07/27/2023 18:56:33 - INFO - __main__ - train loss is 41.77164100797381\n",
      "Steps:  57%|█▏| 8480/15000 [1:11:43<21:16,  5.11it/s, lr=0.001, step_loss=0.534]07/27/2023 18:56:33 - INFO - __main__ - train loss is 41.93921456427779\n",
      "Steps:  57%|█▏| 8481/15000 [1:11:43<21:14,  5.11it/s, lr=0.001, step_loss=0.168]07/27/2023 18:56:33 - INFO - __main__ - train loss is 42.04140629561152\n",
      "Steps:  57%|█▏| 8482/15000 [1:11:44<21:15,  5.11it/s, lr=0.001, step_loss=0.102]07/27/2023 18:56:33 - INFO - __main__ - train loss is 42.30333503277507\n",
      "Steps:  57%|█▏| 8483/15000 [1:11:44<21:16,  5.11it/s, lr=0.001, step_loss=0.262]07/27/2023 18:56:34 - INFO - __main__ - train loss is 42.341054237796925\n",
      "Steps:  57%|▌| 8484/15000 [1:11:44<30:26,  3.57it/s, lr=0.001, step_loss=0.0377]07/27/2023 18:56:35 - INFO - __main__ - Per validation step average loss is 0.048856817185878754\n",
      "07/27/2023 18:56:35 - INFO - __main__ - Cumulative validation average loss is 0.048856817185878754\n",
      "07/27/2023 18:56:36 - INFO - __main__ - Per validation step average loss is 0.05327535420656204\n",
      "07/27/2023 18:56:36 - INFO - __main__ - Cumulative validation average loss is 0.1021321713924408\n",
      "07/27/2023 18:56:36 - INFO - __main__ - Per validation step average loss is 0.0045616514980793\n",
      "07/27/2023 18:56:36 - INFO - __main__ - Cumulative validation average loss is 0.1066938228905201\n",
      "07/27/2023 18:56:36 - INFO - __main__ - Per validation step average loss is 0.312383770942688\n",
      "07/27/2023 18:56:36 - INFO - __main__ - Cumulative validation average loss is 0.4190775938332081\n",
      "07/27/2023 18:56:37 - INFO - __main__ - Per validation step average loss is 0.07019771635532379\n",
      "07/27/2023 18:56:37 - INFO - __main__ - Cumulative validation average loss is 0.4892753101885319\n",
      "07/27/2023 18:56:37 - INFO - __main__ - Per validation step average loss is 0.018089741468429565\n",
      "07/27/2023 18:56:37 - INFO - __main__ - Cumulative validation average loss is 0.5073650516569614\n",
      "07/27/2023 18:56:38 - INFO - __main__ - Per validation step average loss is 0.019882328808307648\n",
      "07/27/2023 18:56:38 - INFO - __main__ - Cumulative validation average loss is 0.5272473804652691\n",
      "07/27/2023 18:56:38 - INFO - __main__ - Per validation step average loss is 0.022118307650089264\n",
      "07/27/2023 18:56:38 - INFO - __main__ - Cumulative validation average loss is 0.5493656881153584\n",
      "07/27/2023 18:56:38 - INFO - __main__ - Per validation step average loss is 0.3123818635940552\n",
      "07/27/2023 18:56:38 - INFO - __main__ - Cumulative validation average loss is 0.8617475517094135\n",
      "07/27/2023 18:56:39 - INFO - __main__ - Per validation step average loss is 0.6966127753257751\n",
      "07/27/2023 18:56:39 - INFO - __main__ - Cumulative validation average loss is 1.5583603270351887\n",
      "07/27/2023 18:56:39 - INFO - __main__ - Per validation step average loss is 0.03274460509419441\n",
      "07/27/2023 18:56:39 - INFO - __main__ - Cumulative validation average loss is 1.591104932129383\n",
      "07/27/2023 18:56:40 - INFO - __main__ - Per validation step average loss is 0.13286836445331573\n",
      "07/27/2023 18:56:40 - INFO - __main__ - Cumulative validation average loss is 1.7239732965826988\n",
      "07/27/2023 18:56:40 - INFO - __main__ - Per validation step average loss is 0.03038473054766655\n",
      "07/27/2023 18:56:40 - INFO - __main__ - Cumulative validation average loss is 1.7543580271303654\n",
      "07/27/2023 18:56:41 - INFO - __main__ - Per validation step average loss is 0.0026740990579128265\n",
      "07/27/2023 18:56:41 - INFO - __main__ - Cumulative validation average loss is 1.7570321261882782\n",
      "07/27/2023 18:56:41 - INFO - __main__ - Per validation step average loss is 0.03955905884504318\n",
      "07/27/2023 18:56:41 - INFO - __main__ - Cumulative validation average loss is 1.7965911850333214\n",
      "07/27/2023 18:56:41 - INFO - __main__ - Per validation step average loss is 0.11600011587142944\n",
      "07/27/2023 18:56:41 - INFO - __main__ - Cumulative validation average loss is 1.9125913009047508\n",
      "07/27/2023 18:56:42 - INFO - __main__ - Per validation step average loss is 0.0059393709525465965\n",
      "07/27/2023 18:56:42 - INFO - __main__ - Cumulative validation average loss is 1.9185306718572974\n",
      "07/27/2023 18:56:42 - INFO - __main__ - Per validation step average loss is 0.25007379055023193\n",
      "07/27/2023 18:56:42 - INFO - __main__ - Cumulative validation average loss is 2.1686044624075294\n",
      "07/27/2023 18:56:43 - INFO - __main__ - Per validation step average loss is 0.1778813600540161\n",
      "07/27/2023 18:56:43 - INFO - __main__ - Cumulative validation average loss is 2.3464858224615455\n",
      "07/27/2023 18:56:43 - INFO - __main__ - Per validation step average loss is 0.31153398752212524\n",
      "07/27/2023 18:56:43 - INFO - __main__ - Cumulative validation average loss is 2.6580198099836707\n",
      "07/27/2023 18:56:43 - INFO - __main__ - Per validation step average loss is 0.03288991376757622\n",
      "07/27/2023 18:56:43 - INFO - __main__ - Cumulative validation average loss is 2.690909723751247\n",
      "07/27/2023 18:56:44 - INFO - __main__ - Per validation step average loss is 0.03142696991562843\n",
      "07/27/2023 18:56:44 - INFO - __main__ - Cumulative validation average loss is 2.7223366936668754\n",
      "07/27/2023 18:56:44 - INFO - __main__ - Per validation step average loss is 0.08239388465881348\n",
      "07/27/2023 18:56:44 - INFO - __main__ - Cumulative validation average loss is 2.804730578325689\n",
      "07/27/2023 18:56:45 - INFO - __main__ - Per validation step average loss is 0.06975285708904266\n",
      "07/27/2023 18:56:45 - INFO - __main__ - Cumulative validation average loss is 2.8744834354147315\n",
      "07/27/2023 18:56:45 - INFO - __main__ - Per validation step average loss is 0.07478506863117218\n",
      "07/27/2023 18:56:45 - INFO - __main__ - Cumulative validation average loss is 2.9492685040459037\n",
      "07/27/2023 18:56:46 - INFO - __main__ - Per validation step average loss is 0.279619038105011\n",
      "07/27/2023 18:56:46 - INFO - __main__ - Cumulative validation average loss is 3.2288875421509147\n",
      "07/27/2023 18:56:46 - INFO - __main__ - Per validation step average loss is 0.07104811072349548\n",
      "07/27/2023 18:56:46 - INFO - __main__ - Cumulative validation average loss is 3.29993565287441\n",
      "07/27/2023 18:56:46 - INFO - __main__ - Per validation step average loss is 0.0615481398999691\n",
      "07/27/2023 18:56:46 - INFO - __main__ - Cumulative validation average loss is 3.3614837927743793\n",
      "07/27/2023 18:56:47 - INFO - __main__ - Per validation step average loss is 0.03119739517569542\n",
      "07/27/2023 18:56:47 - INFO - __main__ - Cumulative validation average loss is 3.3926811879500747\n",
      "07/27/2023 18:56:47 - INFO - __main__ - Per validation step average loss is 0.33924198150634766\n",
      "07/27/2023 18:56:47 - INFO - __main__ - Cumulative validation average loss is 3.7319231694564223\n",
      "07/27/2023 18:56:48 - INFO - __main__ - Per validation step average loss is 0.028902489691972733\n",
      "07/27/2023 18:56:48 - INFO - __main__ - Cumulative validation average loss is 3.760825659148395\n",
      "07/27/2023 18:56:48 - INFO - __main__ - Per validation step average loss is 0.2507067322731018\n",
      "07/27/2023 18:56:48 - INFO - __main__ - Cumulative validation average loss is 4.011532391421497\n",
      "07/27/2023 18:56:48 - INFO - __main__ - Per validation step average loss is 0.013136273249983788\n",
      "07/27/2023 18:56:48 - INFO - __main__ - Cumulative validation average loss is 4.024668664671481\n",
      "07/27/2023 18:56:49 - INFO - __main__ - Per validation step average loss is 0.011800505220890045\n",
      "07/27/2023 18:56:49 - INFO - __main__ - Cumulative validation average loss is 4.036469169892371\n",
      "07/27/2023 18:56:49 - INFO - __main__ - Per validation step average loss is 0.7614238262176514\n",
      "07/27/2023 18:56:49 - INFO - __main__ - Cumulative validation average loss is 4.797892996110022\n",
      "07/27/2023 18:56:50 - INFO - __main__ - Per validation step average loss is 0.27104413509368896\n",
      "07/27/2023 18:56:50 - INFO - __main__ - Cumulative validation average loss is 5.068937131203711\n",
      "07/27/2023 18:56:50 - INFO - __main__ - Per validation step average loss is 0.4679940640926361\n",
      "07/27/2023 18:56:50 - INFO - __main__ - Cumulative validation average loss is 5.536931195296347\n",
      "07/27/2023 18:56:51 - INFO - __main__ - Per validation step average loss is 0.4462292194366455\n",
      "07/27/2023 18:56:51 - INFO - __main__ - Cumulative validation average loss is 5.983160414732993\n",
      "07/27/2023 18:56:51 - INFO - __main__ - Per validation step average loss is 0.13702793419361115\n",
      "07/27/2023 18:56:51 - INFO - __main__ - Cumulative validation average loss is 6.120188348926604\n",
      "07/27/2023 18:56:51 - INFO - __main__ - Per validation step average loss is 0.5673359632492065\n",
      "07/27/2023 18:56:51 - INFO - __main__ - Cumulative validation average loss is 6.68752431217581\n",
      "07/27/2023 18:56:52 - INFO - __main__ - Per validation step average loss is 0.012781398370862007\n",
      "07/27/2023 18:56:52 - INFO - __main__ - Cumulative validation average loss is 6.700305710546672\n",
      "07/27/2023 18:56:52 - INFO - __main__ - Per validation step average loss is 0.0032203118316829205\n",
      "07/27/2023 18:56:52 - INFO - __main__ - Cumulative validation average loss is 6.703526022378355\n",
      "07/27/2023 18:56:53 - INFO - __main__ - Per validation step average loss is 0.4250943958759308\n",
      "07/27/2023 18:56:53 - INFO - __main__ - Cumulative validation average loss is 7.128620418254286\n",
      "07/27/2023 18:56:53 - INFO - __main__ - Per validation step average loss is 0.014529413543641567\n",
      "07/27/2023 18:56:53 - INFO - __main__ - Cumulative validation average loss is 7.143149831797928\n",
      "07/27/2023 18:56:53 - INFO - __main__ - Per validation step average loss is 0.04181555658578873\n",
      "07/27/2023 18:56:53 - INFO - __main__ - Cumulative validation average loss is 7.184965388383716\n",
      "07/27/2023 18:56:54 - INFO - __main__ - Per validation step average loss is 0.15769034624099731\n",
      "07/27/2023 18:56:54 - INFO - __main__ - Cumulative validation average loss is 7.342655734624714\n",
      "07/27/2023 18:56:54 - INFO - __main__ - Per validation step average loss is 0.05379107594490051\n",
      "07/27/2023 18:56:54 - INFO - __main__ - Cumulative validation average loss is 7.396446810569614\n",
      "07/27/2023 18:56:55 - INFO - __main__ - Per validation step average loss is 0.013817138969898224\n",
      "07/27/2023 18:56:55 - INFO - __main__ - Cumulative validation average loss is 7.410263949539512\n",
      "07/27/2023 18:56:55 - INFO - __main__ - Per validation step average loss is 0.2227182537317276\n",
      "07/27/2023 18:56:55 - INFO - __main__ - Cumulative validation average loss is 7.63298220327124\n",
      "07/27/2023 18:56:55 - INFO - __main__ - Per validation step average loss is 0.011995865032076836\n",
      "07/27/2023 18:56:55 - INFO - __main__ - Cumulative validation average loss is 7.644978068303317\n",
      "07/27/2023 18:56:56 - INFO - __main__ - Per validation step average loss is 0.02968529611825943\n",
      "07/27/2023 18:56:56 - INFO - __main__ - Cumulative validation average loss is 7.674663364421576\n",
      "07/27/2023 18:56:56 - INFO - __main__ - Per validation step average loss is 0.15702131390571594\n",
      "07/27/2023 18:56:56 - INFO - __main__ - Cumulative validation average loss is 7.831684678327292\n",
      "07/27/2023 18:56:57 - INFO - __main__ - Per validation step average loss is 0.015438562259078026\n",
      "07/27/2023 18:56:57 - INFO - __main__ - Cumulative validation average loss is 7.84712324058637\n",
      "07/27/2023 18:56:57 - INFO - __main__ - Per validation step average loss is 0.0021832839120179415\n",
      "07/27/2023 18:56:57 - INFO - __main__ - Cumulative validation average loss is 7.849306524498388\n",
      "07/27/2023 18:56:58 - INFO - __main__ - Per validation step average loss is 0.01457200013101101\n",
      "07/27/2023 18:56:58 - INFO - __main__ - Cumulative validation average loss is 7.863878524629399\n",
      "07/27/2023 18:56:58 - INFO - __main__ - Per validation step average loss is 0.07699014991521835\n",
      "07/27/2023 18:56:58 - INFO - __main__ - Cumulative validation average loss is 7.9408686745446175\n",
      "07/27/2023 18:56:58 - INFO - __main__ - Per validation step average loss is 0.09967310726642609\n",
      "07/27/2023 18:56:58 - INFO - __main__ - Cumulative validation average loss is 8.040541781811044\n",
      "07/27/2023 18:56:59 - INFO - __main__ - Per validation step average loss is 0.023514986038208008\n",
      "07/27/2023 18:56:59 - INFO - __main__ - Cumulative validation average loss is 8.064056767849252\n",
      "07/27/2023 18:56:59 - INFO - __main__ - Per validation step average loss is 0.019839821383357048\n",
      "07/27/2023 18:56:59 - INFO - __main__ - Cumulative validation average loss is 8.083896589232609\n",
      "07/27/2023 18:57:00 - INFO - __main__ - Per validation step average loss is 0.02285703271627426\n",
      "07/27/2023 18:57:00 - INFO - __main__ - Cumulative validation average loss is 8.106753621948883\n",
      "07/27/2023 18:57:00 - INFO - __main__ - Per validation step average loss is 0.12389934808015823\n",
      "07/27/2023 18:57:00 - INFO - __main__ - Cumulative validation average loss is 8.230652970029041\n",
      "07/27/2023 18:57:00 - INFO - __main__ - Per validation step average loss is 0.003020787611603737\n",
      "07/27/2023 18:57:00 - INFO - __main__ - Cumulative validation average loss is 8.233673757640645\n",
      "07/27/2023 18:57:01 - INFO - __main__ - Per validation step average loss is 0.003938085399568081\n",
      "07/27/2023 18:57:01 - INFO - __main__ - Cumulative validation average loss is 8.237611843040213\n",
      "07/27/2023 18:57:01 - INFO - __main__ - Per validation step average loss is 0.17397116124629974\n",
      "07/27/2023 18:57:01 - INFO - __main__ - Cumulative validation average loss is 8.411583004286513\n",
      "07/27/2023 18:57:02 - INFO - __main__ - Per validation step average loss is 0.037463586777448654\n",
      "07/27/2023 18:57:02 - INFO - __main__ - Cumulative validation average loss is 8.449046591063961\n",
      "07/27/2023 18:57:02 - INFO - __main__ - Per validation step average loss is 0.0028415927663445473\n",
      "07/27/2023 18:57:02 - INFO - __main__ - Cumulative validation average loss is 8.451888183830306\n",
      "07/27/2023 18:57:03 - INFO - __main__ - Per validation step average loss is 0.009959675371646881\n",
      "07/27/2023 18:57:03 - INFO - __main__ - Cumulative validation average loss is 8.461847859201953\n",
      "07/27/2023 18:57:03 - INFO - __main__ - Per validation step average loss is 0.25122979283332825\n",
      "07/27/2023 18:57:03 - INFO - __main__ - Cumulative validation average loss is 8.713077652035281\n",
      "07/27/2023 18:57:03 - INFO - __main__ - Per validation step average loss is 0.0328274630010128\n",
      "07/27/2023 18:57:03 - INFO - __main__ - Cumulative validation average loss is 8.745905115036294\n",
      "07/27/2023 18:57:04 - INFO - __main__ - Per validation step average loss is 0.41635605692863464\n",
      "07/27/2023 18:57:04 - INFO - __main__ - Cumulative validation average loss is 9.162261171964929\n",
      "07/27/2023 18:57:04 - INFO - __main__ - Per validation step average loss is 0.07260842621326447\n",
      "07/27/2023 18:57:04 - INFO - __main__ - Cumulative validation average loss is 9.234869598178193\n",
      "07/27/2023 18:57:05 - INFO - __main__ - Per validation step average loss is 0.3588210940361023\n",
      "07/27/2023 18:57:05 - INFO - __main__ - Cumulative validation average loss is 9.593690692214295\n",
      "07/27/2023 18:57:05 - INFO - __main__ - Per validation step average loss is 0.26972705125808716\n",
      "07/27/2023 18:57:05 - INFO - __main__ - Cumulative validation average loss is 9.863417743472382\n",
      "07/27/2023 18:57:05 - INFO - __main__ - Per validation step average loss is 0.0026971171610057354\n",
      "07/27/2023 18:57:05 - INFO - __main__ - Cumulative validation average loss is 9.866114860633388\n",
      "07/27/2023 18:57:06 - INFO - __main__ - Per validation step average loss is 0.13221517205238342\n",
      "07/27/2023 18:57:06 - INFO - __main__ - Cumulative validation average loss is 9.998330032685772\n",
      "07/27/2023 18:57:06 - INFO - __main__ - Per validation step average loss is 0.0017643487080931664\n",
      "07/27/2023 18:57:06 - INFO - __main__ - Cumulative validation average loss is 10.000094381393865\n",
      "07/27/2023 18:57:07 - INFO - __main__ - Per validation step average loss is 0.06127810850739479\n",
      "07/27/2023 18:57:07 - INFO - __main__ - Cumulative validation average loss is 10.06137248990126\n",
      "07/27/2023 18:57:07 - INFO - __main__ - Per validation step average loss is 0.10141042619943619\n",
      "07/27/2023 18:57:07 - INFO - __main__ - Cumulative validation average loss is 10.162782916100696\n",
      "07/27/2023 18:57:08 - INFO - __main__ - Per validation step average loss is 0.43505045771598816\n",
      "07/27/2023 18:57:08 - INFO - __main__ - Cumulative validation average loss is 10.597833373816684\n",
      "07/27/2023 18:57:08 - INFO - __main__ - Average validation loss for Epoch 27 is 0.13414978954198334\n",
      "07/27/2023 18:57:08 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 18:58:04 - INFO - __main__ - Starting epoch 28\n",
      "07/27/2023 18:58:05 - INFO - __main__ - train loss is 0.018555011600255966\n",
      "Steps:  57%|▌| 8485/15000 [1:13:16<49:54:06, 27.57s/it, lr=0.001, step_loss=0.0107/27/2023 18:58:05 - INFO - __main__ - train loss is 0.10410889610648155\n",
      "Steps:  57%|▌| 8486/15000 [1:13:16<35:01:36, 19.36s/it, lr=0.001, step_loss=0.0807/27/2023 18:58:06 - INFO - __main__ - train loss is 0.1135056372731924\n",
      "Steps:  57%|▌| 8487/15000 [1:13:16<24:36:45, 13.60s/it, lr=0.001, step_loss=0.0007/27/2023 18:58:06 - INFO - __main__ - train loss is 0.2009300049394369\n",
      "Steps:  57%|▌| 8488/15000 [1:13:16<17:19:24,  9.58s/it, lr=0.001, step_loss=0.0807/27/2023 18:58:06 - INFO - __main__ - train loss is 0.20257776963990182\n",
      "Steps:  57%|▌| 8489/15000 [1:13:16<12:13:18,  6.76s/it, lr=0.001, step_loss=0.0007/27/2023 18:58:06 - INFO - __main__ - train loss is 0.24230898160021752\n",
      "Steps:  57%|▌| 8490/15000 [1:13:16<8:39:11,  4.79s/it, lr=0.001, step_loss=0.03907/27/2023 18:58:06 - INFO - __main__ - train loss is 0.28872109937947243\n",
      "Steps:  57%|▌| 8491/15000 [1:13:17<6:09:13,  3.40s/it, lr=0.001, step_loss=0.04607/27/2023 18:58:06 - INFO - __main__ - train loss is 0.29753135691862553\n",
      "Steps:  57%|▌| 8492/15000 [1:13:17<4:24:13,  2.44s/it, lr=0.001, step_loss=0.00807/27/2023 18:58:07 - INFO - __main__ - train loss is 0.6397982741473243\n",
      "Steps:  57%|▌| 8493/15000 [1:13:17<3:10:43,  1.76s/it, lr=0.001, step_loss=0.34207/27/2023 18:58:07 - INFO - __main__ - train loss is 0.754138087737374\n",
      "Steps:  57%|▌| 8494/15000 [1:13:17<2:19:18,  1.28s/it, lr=0.001, step_loss=0.11407/27/2023 18:58:07 - INFO - __main__ - train loss is 0.8017960319994017\n",
      "Steps:  57%|▌| 8495/15000 [1:13:17<1:43:18,  1.05it/s, lr=0.001, step_loss=0.04707/27/2023 18:58:07 - INFO - __main__ - train loss is 1.0521996746538207\n",
      "Steps:  57%|▌| 8496/15000 [1:13:18<1:18:06,  1.39it/s, lr=0.001, step_loss=0.25]07/27/2023 18:58:07 - INFO - __main__ - train loss is 1.0691056082723662\n",
      "Steps:  57%|▌| 8497/15000 [1:13:18<1:00:28,  1.79it/s, lr=0.001, step_loss=0.01607/27/2023 18:58:08 - INFO - __main__ - train loss is 1.0817593483952805\n",
      "Steps:  57%|▌| 8498/15000 [1:13:18<48:08,  2.25it/s, lr=0.001, step_loss=0.0127]07/27/2023 18:58:08 - INFO - __main__ - train loss is 1.2201911507872865\n",
      "Steps:  57%|█▏| 8499/15000 [1:13:18<39:31,  2.74it/s, lr=0.001, step_loss=0.138]07/27/2023 18:58:08 - INFO - __main__ - train loss is 1.382801383617334\n",
      "Steps:  57%|█▏| 8500/15000 [1:13:18<33:27,  3.24it/s, lr=0.001, step_loss=0.138]07/27/2023 18:58:08 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-8500\n",
      "07/27/2023 18:58:08 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 18:58:08,506] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 18:58:08,510] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-8500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 18:58:08,510] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-8500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 18:58:08,516] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-8500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 18:58:08,517] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-8500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 18:58:08,523] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-8500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 18:58:08,523] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-8500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 18:58:08,523] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 18:58:08 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-8500/pytorch_model\n",
      "07/27/2023 18:58:08 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-8500/scheduler.bin\n",
      "07/27/2023 18:58:08 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-8500/random_states_0.pkl\n",
      "07/27/2023 18:58:08 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-8500\n",
      "Steps:  57%|█▏| 8500/15000 [1:13:18<33:27,  3.24it/s, lr=0.001, step_loss=0.163]07/27/2023 18:58:08 - INFO - __main__ - train loss is 1.3936893864301965\n",
      "Steps:  57%|▌| 8501/15000 [1:13:18<29:50,  3.63it/s, lr=0.001, step_loss=0.0109]07/27/2023 18:58:08 - INFO - __main__ - train loss is 1.6075732334284112\n",
      "Steps:  57%|█▏| 8502/15000 [1:13:19<26:51,  4.03it/s, lr=0.001, step_loss=0.214]07/27/2023 18:58:08 - INFO - __main__ - train loss is 1.8121686204103753\n",
      "Steps:  57%|█▏| 8503/15000 [1:13:19<24:36,  4.40it/s, lr=0.001, step_loss=0.205]07/27/2023 18:58:09 - INFO - __main__ - train loss is 1.8141200507525355\n",
      "Steps:  57%|▌| 8504/15000 [1:13:19<23:13,  4.66it/s, lr=0.001, step_loss=0.0019507/27/2023 18:58:09 - INFO - __main__ - train loss is 1.915578548097983\n",
      "Steps:  57%|█▏| 8505/15000 [1:13:19<22:12,  4.88it/s, lr=0.001, step_loss=0.101]07/27/2023 18:58:09 - INFO - __main__ - train loss is 2.073373172665015\n",
      "Steps:  57%|█▏| 8506/15000 [1:13:19<21:21,  5.07it/s, lr=0.001, step_loss=0.158]07/27/2023 18:58:09 - INFO - __main__ - train loss is 2.153161052847281\n",
      "Steps:  57%|▌| 8507/15000 [1:13:20<20:46,  5.21it/s, lr=0.001, step_loss=0.0798]07/27/2023 18:58:09 - INFO - __main__ - train loss is 2.1814737806562334\n",
      "Steps:  57%|▌| 8508/15000 [1:13:20<20:20,  5.32it/s, lr=0.001, step_loss=0.0283]07/27/2023 18:58:10 - INFO - __main__ - train loss is 2.1834102449938655\n",
      "Steps:  57%|▌| 8509/15000 [1:13:20<20:02,  5.40it/s, lr=0.001, step_loss=0.0019407/27/2023 18:58:10 - INFO - __main__ - train loss is 2.3066547689959407\n",
      "Steps:  57%|█▏| 8510/15000 [1:13:20<19:50,  5.45it/s, lr=0.001, step_loss=0.123]07/27/2023 18:58:10 - INFO - __main__ - train loss is 2.7003916976973414\n",
      "Steps:  57%|█▏| 8511/15000 [1:13:20<19:41,  5.49it/s, lr=0.001, step_loss=0.394]07/27/2023 18:58:10 - INFO - __main__ - train loss is 2.8002112014219165\n",
      "Steps:  57%|▌| 8512/15000 [1:13:20<19:35,  5.52it/s, lr=0.001, step_loss=0.0998]07/27/2023 18:58:10 - INFO - __main__ - train loss is 2.8313152650371194\n",
      "Steps:  57%|▌| 8513/15000 [1:13:21<19:31,  5.54it/s, lr=0.001, step_loss=0.0311]07/27/2023 18:58:10 - INFO - __main__ - train loss is 2.975766167975962\n",
      "Steps:  57%|█▏| 8514/15000 [1:13:21<19:28,  5.55it/s, lr=0.001, step_loss=0.144]07/27/2023 18:58:11 - INFO - __main__ - train loss is 3.5635990956798196\n",
      "Steps:  57%|█▏| 8515/15000 [1:13:21<19:26,  5.56it/s, lr=0.001, step_loss=0.588]07/27/2023 18:58:11 - INFO - __main__ - train loss is 3.567863369360566\n",
      "Steps:  57%|▌| 8516/15000 [1:13:21<19:24,  5.57it/s, lr=0.001, step_loss=0.0042607/27/2023 18:58:11 - INFO - __main__ - train loss is 3.6238127443939447\n",
      "Steps:  57%|▌| 8517/15000 [1:13:21<19:23,  5.57it/s, lr=0.001, step_loss=0.0559]07/27/2023 18:58:11 - INFO - __main__ - train loss is 3.625471699400805\n",
      "Steps:  57%|▌| 8518/15000 [1:13:21<19:23,  5.57it/s, lr=0.001, step_loss=0.0016607/27/2023 18:58:11 - INFO - __main__ - train loss is 3.7677063377341256\n",
      "Steps:  57%|█▏| 8519/15000 [1:13:22<19:22,  5.57it/s, lr=0.001, step_loss=0.142]07/27/2023 18:58:12 - INFO - __main__ - train loss is 3.8272833408555016\n",
      "Steps:  57%|▌| 8520/15000 [1:13:22<19:22,  5.57it/s, lr=0.001, step_loss=0.0596]07/27/2023 18:58:12 - INFO - __main__ - train loss is 4.155322748585604\n",
      "Steps:  57%|█▏| 8521/15000 [1:13:22<19:22,  5.57it/s, lr=0.001, step_loss=0.328]07/27/2023 18:58:12 - INFO - __main__ - train loss is 4.690322119160555\n",
      "Steps:  57%|█▏| 8522/15000 [1:13:22<19:22,  5.57it/s, lr=0.001, step_loss=0.535]07/27/2023 18:58:12 - INFO - __main__ - train loss is 5.054646629258059\n",
      "Steps:  57%|█▏| 8523/15000 [1:13:22<19:22,  5.57it/s, lr=0.001, step_loss=0.364]07/27/2023 18:58:12 - INFO - __main__ - train loss is 5.059290844365023\n",
      "Steps:  57%|▌| 8524/15000 [1:13:23<19:22,  5.57it/s, lr=0.001, step_loss=0.0046407/27/2023 18:58:12 - INFO - __main__ - train loss is 5.0639092832570896\n",
      "Steps:  57%|▌| 8525/15000 [1:13:23<19:34,  5.51it/s, lr=0.001, step_loss=0.0046207/27/2023 18:58:13 - INFO - __main__ - train loss is 5.072432673885487\n",
      "Steps:  57%|▌| 8526/15000 [1:13:23<19:39,  5.49it/s, lr=0.001, step_loss=0.0085207/27/2023 18:58:13 - INFO - __main__ - train loss is 5.7664962181588635\n",
      "Steps:  57%|█▏| 8527/15000 [1:13:23<19:33,  5.52it/s, lr=0.001, step_loss=0.694]07/27/2023 18:58:13 - INFO - __main__ - train loss is 5.793118625297211\n",
      "Steps:  57%|▌| 8528/15000 [1:13:23<19:29,  5.53it/s, lr=0.001, step_loss=0.0266]07/27/2023 18:58:13 - INFO - __main__ - train loss is 5.811555500491522\n",
      "Steps:  57%|▌| 8529/15000 [1:13:23<19:27,  5.54it/s, lr=0.001, step_loss=0.0184]07/27/2023 18:58:13 - INFO - __main__ - train loss is 5.840211752220057\n",
      "Steps:  57%|▌| 8530/15000 [1:13:24<19:25,  5.55it/s, lr=0.001, step_loss=0.0287]07/27/2023 18:58:14 - INFO - __main__ - train loss is 6.11822730617132\n",
      "Steps:  57%|█▏| 8531/15000 [1:13:24<19:23,  5.56it/s, lr=0.001, step_loss=0.278]07/27/2023 18:58:14 - INFO - __main__ - train loss is 6.125585402711295\n",
      "Steps:  57%|▌| 8532/15000 [1:13:24<19:22,  5.56it/s, lr=0.001, step_loss=0.0073607/27/2023 18:58:14 - INFO - __main__ - train loss is 6.2160333128413185\n",
      "Steps:  57%|▌| 8533/15000 [1:13:24<19:21,  5.57it/s, lr=0.001, step_loss=0.0904]07/27/2023 18:58:14 - INFO - __main__ - train loss is 6.387278083129786\n",
      "Steps:  57%|█▏| 8534/15000 [1:13:24<19:20,  5.57it/s, lr=0.001, step_loss=0.171]07/27/2023 18:58:14 - INFO - __main__ - train loss is 6.477104026242159\n",
      "Steps:  57%|▌| 8535/15000 [1:13:25<19:19,  5.57it/s, lr=0.001, step_loss=0.0898]07/27/2023 18:58:14 - INFO - __main__ - train loss is 6.794992941780947\n",
      "Steps:  57%|█▏| 8536/15000 [1:13:25<19:20,  5.57it/s, lr=0.001, step_loss=0.318]07/27/2023 18:58:15 - INFO - __main__ - train loss is 6.81668504641857\n",
      "Steps:  57%|▌| 8537/15000 [1:13:25<19:20,  5.57it/s, lr=0.001, step_loss=0.0217]07/27/2023 18:58:15 - INFO - __main__ - train loss is 7.117053474648856\n",
      "Steps:  57%|██▎ | 8538/15000 [1:13:25<19:30,  5.52it/s, lr=0.001, step_loss=0.3]07/27/2023 18:58:15 - INFO - __main__ - train loss is 7.122777786455117\n",
      "Steps:  57%|▌| 8539/15000 [1:13:25<19:27,  5.54it/s, lr=0.001, step_loss=0.0057207/27/2023 18:58:15 - INFO - __main__ - train loss is 7.1342186745023355\n",
      "Steps:  57%|▌| 8540/15000 [1:13:25<19:24,  5.55it/s, lr=0.001, step_loss=0.0114]07/27/2023 18:58:15 - INFO - __main__ - train loss is 7.17103179206606\n",
      "Steps:  57%|▌| 8541/15000 [1:13:26<19:23,  5.55it/s, lr=0.001, step_loss=0.0368]07/27/2023 18:58:15 - INFO - __main__ - train loss is 7.23502459784504\n",
      "Steps:  57%|█▏| 8542/15000 [1:13:26<19:22,  5.56it/s, lr=0.001, step_loss=0.064]07/27/2023 18:58:16 - INFO - __main__ - train loss is 7.2418404122581705\n",
      "Steps:  57%|▌| 8543/15000 [1:13:26<19:21,  5.56it/s, lr=0.001, step_loss=0.0068207/27/2023 18:58:16 - INFO - __main__ - train loss is 7.24706309789326\n",
      "Steps:  57%|▌| 8544/15000 [1:13:26<19:20,  5.57it/s, lr=0.001, step_loss=0.0052207/27/2023 18:58:16 - INFO - __main__ - train loss is 7.27901081123855\n",
      "Steps:  57%|▌| 8545/15000 [1:13:26<19:19,  5.57it/s, lr=0.001, step_loss=0.0319]07/27/2023 18:58:16 - INFO - __main__ - train loss is 7.314433635561727\n",
      "Steps:  57%|▌| 8546/15000 [1:13:27<19:18,  5.57it/s, lr=0.001, step_loss=0.0354]07/27/2023 18:58:16 - INFO - __main__ - train loss is 7.391714581637643\n",
      "Steps:  57%|▌| 8547/15000 [1:13:27<19:17,  5.57it/s, lr=0.001, step_loss=0.0773]07/27/2023 18:58:17 - INFO - __main__ - train loss is 7.403396897367202\n",
      "Steps:  57%|▌| 8548/15000 [1:13:27<19:17,  5.58it/s, lr=0.001, step_loss=0.0117]07/27/2023 18:58:17 - INFO - __main__ - train loss is 7.935331933549605\n",
      "Steps:  57%|█▏| 8549/15000 [1:13:27<19:17,  5.57it/s, lr=0.001, step_loss=0.532]07/27/2023 18:58:17 - INFO - __main__ - train loss is 7.937043823651038\n",
      "Steps:  57%|▌| 8550/15000 [1:13:27<19:18,  5.57it/s, lr=0.001, step_loss=0.0017107/27/2023 18:58:17 - INFO - __main__ - train loss is 8.686512090614997\n",
      "Steps:  57%|█▏| 8551/15000 [1:13:27<19:17,  5.57it/s, lr=0.001, step_loss=0.749]07/27/2023 18:58:17 - INFO - __main__ - train loss is 8.859689571312629\n",
      "Steps:  57%|█▏| 8552/15000 [1:13:28<19:17,  5.57it/s, lr=0.001, step_loss=0.173]07/27/2023 18:58:17 - INFO - __main__ - train loss is 8.862506573670544\n",
      "Steps:  57%|▌| 8553/15000 [1:13:28<19:23,  5.54it/s, lr=0.001, step_loss=0.0028207/27/2023 18:58:18 - INFO - __main__ - train loss is 8.938274023705162\n",
      "Steps:  57%|▌| 8554/15000 [1:13:28<19:20,  5.55it/s, lr=0.001, step_loss=0.0758]07/27/2023 18:58:18 - INFO - __main__ - train loss is 8.965300604351796\n",
      "Steps:  57%|█▏| 8555/15000 [1:13:28<19:19,  5.56it/s, lr=0.001, step_loss=0.027]07/27/2023 18:58:18 - INFO - __main__ - train loss is 8.968731022556312\n",
      "Steps:  57%|▌| 8556/15000 [1:13:28<19:28,  5.52it/s, lr=0.001, step_loss=0.0034307/27/2023 18:58:18 - INFO - __main__ - train loss is 9.025990280439146\n",
      "Steps:  57%|▌| 8557/15000 [1:13:29<19:32,  5.50it/s, lr=0.001, step_loss=0.0573]07/27/2023 18:58:18 - INFO - __main__ - train loss is 9.091553229023702\n",
      "Steps:  57%|▌| 8558/15000 [1:13:29<19:38,  5.47it/s, lr=0.001, step_loss=0.0656]07/27/2023 18:58:19 - INFO - __main__ - train loss is 9.279695320059545\n",
      "Steps:  57%|█▏| 8559/15000 [1:13:29<19:34,  5.48it/s, lr=0.001, step_loss=0.188]07/27/2023 18:58:19 - INFO - __main__ - train loss is 9.450220841099508\n",
      "Steps:  57%|█▏| 8560/15000 [1:13:29<19:28,  5.51it/s, lr=0.001, step_loss=0.171]07/27/2023 18:58:19 - INFO - __main__ - train loss is 9.711164492298849\n",
      "Steps:  57%|█▏| 8561/15000 [1:13:29<19:24,  5.53it/s, lr=0.001, step_loss=0.261]07/27/2023 18:58:19 - INFO - __main__ - train loss is 9.747672311146744\n",
      "Steps:  57%|▌| 8562/15000 [1:13:29<19:21,  5.54it/s, lr=0.001, step_loss=0.0365]07/27/2023 18:58:19 - INFO - __main__ - train loss is 10.082233867724426\n",
      "Steps:  57%|█▏| 8563/15000 [1:13:30<19:30,  5.50it/s, lr=0.001, step_loss=0.335]07/27/2023 18:58:19 - INFO - __main__ - train loss is 10.185449554701336\n",
      "Steps:  57%|█▏| 8564/15000 [1:13:30<19:29,  5.50it/s, lr=0.001, step_loss=0.103]07/27/2023 18:58:20 - INFO - __main__ - train loss is 11.109731747885235\n",
      "Steps:  57%|█▏| 8565/15000 [1:13:30<19:25,  5.52it/s, lr=0.001, step_loss=0.924]07/27/2023 18:58:20 - INFO - __main__ - train loss is 11.196979052503593\n",
      "Steps:  57%|▌| 8566/15000 [1:13:30<19:32,  5.49it/s, lr=0.001, step_loss=0.0872]07/27/2023 18:58:20 - INFO - __main__ - train loss is 11.203757418435998\n",
      "Steps:  57%|▌| 8567/15000 [1:13:30<19:30,  5.50it/s, lr=0.001, step_loss=0.0067807/27/2023 18:58:20 - INFO - __main__ - train loss is 11.223035866511054\n",
      "Steps:  57%|▌| 8568/15000 [1:13:31<19:25,  5.52it/s, lr=0.001, step_loss=0.0193]07/27/2023 18:58:20 - INFO - __main__ - train loss is 11.290976250660606\n",
      "Steps:  57%|▌| 8569/15000 [1:13:31<19:21,  5.54it/s, lr=0.001, step_loss=0.0679]07/27/2023 18:58:21 - INFO - __main__ - train loss is 11.378054821980186\n",
      "Steps:  57%|▌| 8570/15000 [1:13:31<19:18,  5.55it/s, lr=0.001, step_loss=0.0871]07/27/2023 18:58:21 - INFO - __main__ - train loss is 11.392758697387762\n",
      "Steps:  57%|▌| 8571/15000 [1:13:31<19:19,  5.54it/s, lr=0.001, step_loss=0.0147]07/27/2023 18:58:21 - INFO - __main__ - train loss is 11.396900500752963\n",
      "Steps:  57%|▌| 8572/15000 [1:13:31<19:18,  5.55it/s, lr=0.001, step_loss=0.0041407/27/2023 18:58:21 - INFO - __main__ - train loss is 11.399121774476953\n",
      "Steps:  57%|▌| 8573/15000 [1:13:31<19:17,  5.55it/s, lr=0.001, step_loss=0.0022207/27/2023 18:58:21 - INFO - __main__ - train loss is 11.507145455223508\n",
      "Steps:  57%|█▏| 8574/15000 [1:13:32<19:16,  5.56it/s, lr=0.001, step_loss=0.108]07/27/2023 18:58:21 - INFO - __main__ - train loss is 11.701979285222478\n",
      "Steps:  57%|█▏| 8575/15000 [1:13:32<19:22,  5.53it/s, lr=0.001, step_loss=0.195]07/27/2023 18:58:22 - INFO - __main__ - train loss is 11.746821938198991\n",
      "Steps:  57%|▌| 8576/15000 [1:13:32<19:21,  5.53it/s, lr=0.001, step_loss=0.0448]07/27/2023 18:58:22 - INFO - __main__ - train loss is 11.877567736548372\n",
      "Steps:  57%|█▏| 8577/15000 [1:13:32<19:19,  5.54it/s, lr=0.001, step_loss=0.131]07/27/2023 18:58:22 - INFO - __main__ - train loss is 11.90225131821353\n",
      "Steps:  57%|▌| 8578/15000 [1:13:32<19:27,  5.50it/s, lr=0.001, step_loss=0.0247]07/27/2023 18:58:22 - INFO - __main__ - train loss is 12.014610111829825\n",
      "Steps:  57%|█▏| 8579/15000 [1:13:32<19:30,  5.49it/s, lr=0.001, step_loss=0.112]07/27/2023 18:58:22 - INFO - __main__ - train loss is 12.58203381311614\n",
      "Steps:  57%|█▏| 8580/15000 [1:13:33<19:34,  5.47it/s, lr=0.001, step_loss=0.567]07/27/2023 18:58:23 - INFO - __main__ - train loss is 12.760562539217062\n",
      "Steps:  57%|█▏| 8581/15000 [1:13:33<19:28,  5.50it/s, lr=0.001, step_loss=0.179]07/27/2023 18:58:23 - INFO - __main__ - train loss is 12.864239126560278\n",
      "Steps:  57%|█▏| 8582/15000 [1:13:33<19:23,  5.52it/s, lr=0.001, step_loss=0.104]07/27/2023 18:58:23 - INFO - __main__ - train loss is 12.924446757999249\n",
      "Steps:  57%|▌| 8583/15000 [1:13:33<19:19,  5.53it/s, lr=0.001, step_loss=0.0602]07/27/2023 18:58:23 - INFO - __main__ - train loss is 12.94149574835319\n",
      "Steps:  57%|█▏| 8584/15000 [1:13:33<19:17,  5.54it/s, lr=0.001, step_loss=0.017]07/27/2023 18:58:23 - INFO - __main__ - train loss is 12.964855753001757\n",
      "Steps:  57%|▌| 8585/15000 [1:13:34<19:15,  5.55it/s, lr=0.001, step_loss=0.0234]07/27/2023 18:58:23 - INFO - __main__ - train loss is 13.056466788169928\n",
      "Steps:  57%|▌| 8586/15000 [1:13:34<19:13,  5.56it/s, lr=0.001, step_loss=0.0916]07/27/2023 18:58:24 - INFO - __main__ - train loss is 13.072877690312453\n",
      "Steps:  57%|▌| 8587/15000 [1:13:34<19:12,  5.56it/s, lr=0.001, step_loss=0.0164]07/27/2023 18:58:24 - INFO - __main__ - train loss is 13.097919743624516\n",
      "Steps:  57%|█▏| 8588/15000 [1:13:34<19:12,  5.56it/s, lr=0.001, step_loss=0.025]07/27/2023 18:58:24 - INFO - __main__ - train loss is 13.146393966046162\n",
      "Steps:  57%|▌| 8589/15000 [1:13:34<19:12,  5.56it/s, lr=0.001, step_loss=0.0485]07/27/2023 18:58:24 - INFO - __main__ - train loss is 13.149409967591055\n",
      "Steps:  57%|▌| 8590/15000 [1:13:34<19:11,  5.57it/s, lr=0.001, step_loss=0.0030207/27/2023 18:58:24 - INFO - __main__ - train loss is 13.376021164585836\n",
      "Steps:  57%|█▏| 8591/15000 [1:13:35<19:11,  5.57it/s, lr=0.001, step_loss=0.227]07/27/2023 18:58:25 - INFO - __main__ - train loss is 13.39260942034889\n",
      "Steps:  57%|▌| 8592/15000 [1:13:35<19:10,  5.57it/s, lr=0.001, step_loss=0.0166]07/27/2023 18:58:25 - INFO - __main__ - train loss is 13.470550644327886\n",
      "Steps:  57%|▌| 8593/15000 [1:13:35<19:10,  5.57it/s, lr=0.001, step_loss=0.0779]07/27/2023 18:58:25 - INFO - __main__ - train loss is 13.505330923129804\n",
      "Steps:  57%|▌| 8594/15000 [1:13:35<19:10,  5.57it/s, lr=0.001, step_loss=0.0348]07/27/2023 18:58:25 - INFO - __main__ - train loss is 13.521288366173394\n",
      "Steps:  57%|█▏| 8595/15000 [1:13:35<19:08,  5.57it/s, lr=0.001, step_loss=0.016]07/27/2023 18:58:25 - INFO - __main__ - train loss is 13.82925412163604\n",
      "Steps:  57%|█▏| 8596/15000 [1:13:36<19:08,  5.58it/s, lr=0.001, step_loss=0.308]07/27/2023 18:58:25 - INFO - __main__ - train loss is 14.375166208599694\n",
      "Steps:  57%|█▏| 8597/15000 [1:13:36<19:08,  5.57it/s, lr=0.001, step_loss=0.546]07/27/2023 18:58:26 - INFO - __main__ - train loss is 14.396211587940343\n",
      "Steps:  57%|█▏| 8598/15000 [1:13:36<19:08,  5.57it/s, lr=0.001, step_loss=0.021]07/27/2023 18:58:26 - INFO - __main__ - train loss is 14.548359447275288\n",
      "Steps:  57%|█▏| 8599/15000 [1:13:36<19:08,  5.57it/s, lr=0.001, step_loss=0.152]07/27/2023 18:58:26 - INFO - __main__ - train loss is 14.55542993650306\n",
      "Steps:  57%|▌| 8600/15000 [1:13:36<19:08,  5.57it/s, lr=0.001, step_loss=0.0070707/27/2023 18:58:26 - INFO - __main__ - train loss is 14.861733974074014\n",
      "Steps:  57%|█▏| 8601/15000 [1:13:36<19:44,  5.40it/s, lr=0.001, step_loss=0.306]07/27/2023 18:58:26 - INFO - __main__ - train loss is 15.52614218101371\n",
      "Steps:  57%|█▏| 8602/15000 [1:13:37<23:28,  4.54it/s, lr=0.001, step_loss=0.664]07/27/2023 18:58:27 - INFO - __main__ - train loss is 15.527443077182397\n",
      "Steps:  57%|▌| 8603/15000 [1:13:37<22:23,  4.76it/s, lr=0.001, step_loss=0.0013]07/27/2023 18:58:27 - INFO - __main__ - train loss is 15.602069701766595\n",
      "Steps:  57%|▌| 8604/15000 [1:13:37<22:11,  4.81it/s, lr=0.001, step_loss=0.0746]07/27/2023 18:58:27 - INFO - __main__ - train loss is 15.604960186872631\n",
      "Steps:  57%|▌| 8605/15000 [1:13:37<22:11,  4.80it/s, lr=0.001, step_loss=0.0028907/27/2023 18:58:27 - INFO - __main__ - train loss is 15.700750975403935\n",
      "Steps:  57%|▌| 8606/15000 [1:13:38<22:15,  4.79it/s, lr=0.001, step_loss=0.0958]07/27/2023 18:58:27 - INFO - __main__ - train loss is 16.013105718884617\n",
      "Steps:  57%|█▏| 8607/15000 [1:13:38<21:57,  4.85it/s, lr=0.001, step_loss=0.312]07/27/2023 18:58:28 - INFO - __main__ - train loss is 16.283893226180226\n",
      "Steps:  57%|█▏| 8608/15000 [1:13:38<21:38,  4.92it/s, lr=0.001, step_loss=0.271]07/27/2023 18:58:28 - INFO - __main__ - train loss is 16.296146845910698\n",
      "Steps:  57%|▌| 8609/15000 [1:13:38<21:25,  4.97it/s, lr=0.001, step_loss=0.0123]07/27/2023 18:58:28 - INFO - __main__ - train loss is 16.339893198106438\n",
      "Steps:  57%|▌| 8610/15000 [1:13:38<21:14,  5.01it/s, lr=0.001, step_loss=0.0437]07/27/2023 18:58:28 - INFO - __main__ - train loss is 16.371649204287678\n",
      "Steps:  57%|▌| 8611/15000 [1:13:39<21:06,  5.05it/s, lr=0.001, step_loss=0.0318]07/27/2023 18:58:28 - INFO - __main__ - train loss is 16.435390940401703\n",
      "Steps:  57%|▌| 8612/15000 [1:13:39<21:03,  5.06it/s, lr=0.001, step_loss=0.0637]07/27/2023 18:58:29 - INFO - __main__ - train loss is 16.467932975385338\n",
      "Steps:  57%|▌| 8613/15000 [1:13:39<20:51,  5.10it/s, lr=0.001, step_loss=0.0325]07/27/2023 18:58:29 - INFO - __main__ - train loss is 16.50086875492707\n",
      "Steps:  57%|▌| 8614/15000 [1:13:39<20:49,  5.11it/s, lr=0.001, step_loss=0.0329]07/27/2023 18:58:29 - INFO - __main__ - train loss is 16.54335733363405\n",
      "Steps:  57%|▌| 8615/15000 [1:13:39<20:51,  5.10it/s, lr=0.001, step_loss=0.0425]07/27/2023 18:58:29 - INFO - __main__ - train loss is 16.63988425442949\n",
      "Steps:  57%|▌| 8616/15000 [1:13:40<20:54,  5.09it/s, lr=0.001, step_loss=0.0965]07/27/2023 18:58:29 - INFO - __main__ - train loss is 16.649826168548316\n",
      "Steps:  57%|▌| 8617/15000 [1:13:40<20:52,  5.10it/s, lr=0.001, step_loss=0.0099407/27/2023 18:58:30 - INFO - __main__ - train loss is 16.724796898197383\n",
      "Steps:  57%|█▏| 8618/15000 [1:13:40<20:50,  5.10it/s, lr=0.001, step_loss=0.075]07/27/2023 18:58:30 - INFO - __main__ - train loss is 16.72736070607789\n",
      "Steps:  57%|▌| 8619/15000 [1:13:40<20:45,  5.12it/s, lr=0.001, step_loss=0.0025607/27/2023 18:58:30 - INFO - __main__ - train loss is 16.844165574060753\n",
      "Steps:  57%|█▏| 8620/15000 [1:13:40<20:47,  5.11it/s, lr=0.001, step_loss=0.117]07/27/2023 18:58:30 - INFO - __main__ - train loss is 17.116159091936424\n",
      "Steps:  57%|█▏| 8621/15000 [1:13:41<20:51,  5.10it/s, lr=0.001, step_loss=0.272]07/27/2023 18:58:30 - INFO - __main__ - train loss is 17.32481066440232\n",
      "Steps:  57%|█▏| 8622/15000 [1:13:41<20:39,  5.14it/s, lr=0.001, step_loss=0.209]07/27/2023 18:58:31 - INFO - __main__ - train loss is 17.32901985035278\n",
      "Steps:  57%|▌| 8623/15000 [1:13:41<20:28,  5.19it/s, lr=0.001, step_loss=0.0042107/27/2023 18:58:31 - INFO - __main__ - train loss is 17.414820781210437\n",
      "Steps:  57%|▌| 8624/15000 [1:13:41<20:34,  5.16it/s, lr=0.001, step_loss=0.0858]07/27/2023 18:58:31 - INFO - __main__ - train loss is 17.520969091216102\n",
      "Steps:  57%|█▏| 8625/15000 [1:13:41<20:40,  5.14it/s, lr=0.001, step_loss=0.106]07/27/2023 18:58:31 - INFO - __main__ - train loss is 17.589184103766456\n",
      "Steps:  58%|▌| 8626/15000 [1:13:41<20:46,  5.11it/s, lr=0.001, step_loss=0.0682]07/27/2023 18:58:31 - INFO - __main__ - train loss is 17.855127988616005\n",
      "Steps:  58%|█▏| 8627/15000 [1:13:42<20:47,  5.11it/s, lr=0.001, step_loss=0.266]07/27/2023 18:58:32 - INFO - __main__ - train loss is 18.198505399981514\n",
      "Steps:  58%|█▏| 8628/15000 [1:13:42<20:49,  5.10it/s, lr=0.001, step_loss=0.343]07/27/2023 18:58:32 - INFO - __main__ - train loss is 18.70190536812879\n",
      "Steps:  58%|█▏| 8629/15000 [1:13:42<20:47,  5.11it/s, lr=0.001, step_loss=0.503]07/27/2023 18:58:32 - INFO - __main__ - train loss is 18.747489223489538\n",
      "Steps:  58%|▌| 8630/15000 [1:13:42<20:38,  5.14it/s, lr=0.001, step_loss=0.0456]07/27/2023 18:58:32 - INFO - __main__ - train loss is 18.753279629396275\n",
      "Steps:  58%|▌| 8631/15000 [1:13:42<20:27,  5.19it/s, lr=0.001, step_loss=0.0057907/27/2023 18:58:32 - INFO - __main__ - train loss is 18.812807238893583\n",
      "Steps:  58%|▌| 8632/15000 [1:13:43<20:33,  5.16it/s, lr=0.001, step_loss=0.0595]07/27/2023 18:58:33 - INFO - __main__ - train loss is 19.10011727293022\n",
      "Steps:  58%|█▏| 8633/15000 [1:13:43<20:36,  5.15it/s, lr=0.001, step_loss=0.287]07/27/2023 18:58:33 - INFO - __main__ - train loss is 19.19867481966503\n",
      "Steps:  58%|▌| 8634/15000 [1:13:43<20:39,  5.14it/s, lr=0.001, step_loss=0.0986]07/27/2023 18:58:33 - INFO - __main__ - train loss is 19.29649258335121\n",
      "Steps:  58%|▌| 8635/15000 [1:13:43<20:40,  5.13it/s, lr=0.001, step_loss=0.0978]07/27/2023 18:58:33 - INFO - __main__ - train loss is 19.618439114885405\n",
      "Steps:  58%|█▏| 8636/15000 [1:13:43<20:41,  5.12it/s, lr=0.001, step_loss=0.322]07/27/2023 18:58:33 - INFO - __main__ - train loss is 19.62227528821677\n",
      "Steps:  58%|▌| 8637/15000 [1:13:44<20:24,  5.20it/s, lr=0.001, step_loss=0.0038407/27/2023 18:58:33 - INFO - __main__ - train loss is 20.21580671798438\n",
      "Steps:  58%|█▏| 8638/15000 [1:13:44<20:02,  5.29it/s, lr=0.001, step_loss=0.594]07/27/2023 18:58:34 - INFO - __main__ - train loss is 20.30422968696803\n",
      "Steps:  58%|▌| 8639/15000 [1:13:44<19:44,  5.37it/s, lr=0.001, step_loss=0.0884]07/27/2023 18:58:34 - INFO - __main__ - train loss is 20.563010702840984\n",
      "Steps:  58%|█▏| 8640/15000 [1:13:44<19:31,  5.43it/s, lr=0.001, step_loss=0.259]07/27/2023 18:58:34 - INFO - __main__ - train loss is 20.585909108631313\n",
      "Steps:  58%|▌| 8641/15000 [1:13:44<19:21,  5.47it/s, lr=0.001, step_loss=0.0229]07/27/2023 18:58:34 - INFO - __main__ - train loss is 20.60475862491876\n",
      "Steps:  58%|▌| 8642/15000 [1:13:45<19:15,  5.50it/s, lr=0.001, step_loss=0.0188]07/27/2023 18:58:34 - INFO - __main__ - train loss is 21.033916597254574\n",
      "Steps:  58%|█▏| 8643/15000 [1:13:45<19:11,  5.52it/s, lr=0.001, step_loss=0.429]07/27/2023 18:58:35 - INFO - __main__ - train loss is 21.151593883521855\n",
      "Steps:  58%|█▏| 8644/15000 [1:13:45<19:08,  5.54it/s, lr=0.001, step_loss=0.118]07/27/2023 18:58:35 - INFO - __main__ - train loss is 21.153284040628932\n",
      "Steps:  58%|▌| 8645/15000 [1:13:45<19:05,  5.55it/s, lr=0.001, step_loss=0.0016907/27/2023 18:58:35 - INFO - __main__ - train loss is 21.238219191669486\n",
      "Steps:  58%|▌| 8646/15000 [1:13:45<19:03,  5.56it/s, lr=0.001, step_loss=0.0849]07/27/2023 18:58:35 - INFO - __main__ - train loss is 21.241563387098722\n",
      "Steps:  58%|▌| 8647/15000 [1:13:45<19:01,  5.56it/s, lr=0.001, step_loss=0.0033407/27/2023 18:58:35 - INFO - __main__ - train loss is 21.2457997900201\n",
      "Steps:  58%|▌| 8648/15000 [1:13:46<19:01,  5.57it/s, lr=0.001, step_loss=0.0042407/27/2023 18:58:35 - INFO - __main__ - train loss is 21.248451527557336\n",
      "Steps:  58%|▌| 8649/15000 [1:13:46<19:00,  5.57it/s, lr=0.001, step_loss=0.0026507/27/2023 18:58:36 - INFO - __main__ - train loss is 21.444889601669274\n",
      "Steps:  58%|█▏| 8650/15000 [1:13:46<19:01,  5.56it/s, lr=0.001, step_loss=0.196]07/27/2023 18:58:36 - INFO - __main__ - train loss is 21.447503201081418\n",
      "Steps:  58%|▌| 8651/15000 [1:13:46<19:00,  5.57it/s, lr=0.001, step_loss=0.0026107/27/2023 18:58:36 - INFO - __main__ - train loss is 21.58860426337924\n",
      "Steps:  58%|█▏| 8652/15000 [1:13:46<19:00,  5.57it/s, lr=0.001, step_loss=0.141]07/27/2023 18:58:36 - INFO - __main__ - train loss is 21.597813350497745\n",
      "Steps:  58%|▌| 8653/15000 [1:13:46<18:59,  5.57it/s, lr=0.001, step_loss=0.0092107/27/2023 18:58:36 - INFO - __main__ - train loss is 21.59964815317653\n",
      "Steps:  58%|▌| 8654/15000 [1:13:47<18:59,  5.57it/s, lr=0.001, step_loss=0.0018307/27/2023 18:58:37 - INFO - __main__ - train loss is 21.60128796461504\n",
      "Steps:  58%|▌| 8655/15000 [1:13:47<18:59,  5.57it/s, lr=0.001, step_loss=0.0016407/27/2023 18:58:37 - INFO - __main__ - train loss is 21.71376164618414\n",
      "Steps:  58%|█▏| 8656/15000 [1:13:47<18:58,  5.57it/s, lr=0.001, step_loss=0.112]07/27/2023 18:58:37 - INFO - __main__ - train loss is 21.722262330236845\n",
      "Steps:  58%|▌| 8657/15000 [1:13:47<19:09,  5.52it/s, lr=0.001, step_loss=0.0085]07/27/2023 18:58:37 - INFO - __main__ - train loss is 21.725133297615685\n",
      "Steps:  58%|▌| 8658/15000 [1:13:47<19:20,  5.46it/s, lr=0.001, step_loss=0.0028707/27/2023 18:58:37 - INFO - __main__ - train loss is 21.890662399702705\n",
      "Steps:  58%|█▏| 8659/15000 [1:13:48<19:17,  5.48it/s, lr=0.001, step_loss=0.166]07/27/2023 18:58:37 - INFO - __main__ - train loss is 22.195387599640526\n",
      "Steps:  58%|█▏| 8660/15000 [1:13:48<19:12,  5.50it/s, lr=0.001, step_loss=0.305]07/27/2023 18:58:38 - INFO - __main__ - train loss is 22.272900497191586\n",
      "Steps:  58%|▌| 8661/15000 [1:13:48<19:07,  5.52it/s, lr=0.001, step_loss=0.0775]07/27/2023 18:58:38 - INFO - __main__ - train loss is 22.812227880232967\n",
      "Steps:  58%|█▏| 8662/15000 [1:13:48<19:03,  5.54it/s, lr=0.001, step_loss=0.539]07/27/2023 18:58:38 - INFO - __main__ - train loss is 22.814194670994766\n",
      "Steps:  58%|▌| 8663/15000 [1:13:48<19:01,  5.55it/s, lr=0.001, step_loss=0.0019707/27/2023 18:58:38 - INFO - __main__ - train loss is 22.815840463037603\n",
      "Steps:  58%|▌| 8664/15000 [1:13:48<18:59,  5.56it/s, lr=0.001, step_loss=0.0016507/27/2023 18:58:38 - INFO - __main__ - train loss is 22.918959933216684\n",
      "Steps:  58%|█▏| 8665/15000 [1:13:49<18:58,  5.56it/s, lr=0.001, step_loss=0.103]07/27/2023 18:58:39 - INFO - __main__ - train loss is 23.483473080093972\n",
      "Steps:  58%|█▏| 8666/15000 [1:13:49<18:57,  5.57it/s, lr=0.001, step_loss=0.565]07/27/2023 18:58:39 - INFO - __main__ - train loss is 23.87905140488874\n",
      "Steps:  58%|█▏| 8667/15000 [1:13:49<19:07,  5.52it/s, lr=0.001, step_loss=0.396]07/27/2023 18:58:39 - INFO - __main__ - train loss is 23.880480055580847\n",
      "Steps:  58%|▌| 8668/15000 [1:13:49<19:07,  5.52it/s, lr=0.001, step_loss=0.0014307/27/2023 18:58:39 - INFO - __main__ - train loss is 24.335862581501715\n",
      "Steps:  58%|█▏| 8669/15000 [1:13:49<19:04,  5.53it/s, lr=0.001, step_loss=0.455]07/27/2023 18:58:39 - INFO - __main__ - train loss is 24.548114125500433\n",
      "Steps:  58%|█▏| 8670/15000 [1:13:50<19:01,  5.55it/s, lr=0.001, step_loss=0.212]07/27/2023 18:58:39 - INFO - __main__ - train loss is 25.05476367927622\n",
      "Steps:  58%|█▏| 8671/15000 [1:13:50<18:59,  5.56it/s, lr=0.001, step_loss=0.507]07/27/2023 18:58:40 - INFO - __main__ - train loss is 25.08742087043356\n",
      "Steps:  58%|▌| 8672/15000 [1:13:50<18:57,  5.56it/s, lr=0.001, step_loss=0.0327]07/27/2023 18:58:40 - INFO - __main__ - train loss is 25.194935497711413\n",
      "Steps:  58%|█▏| 8673/15000 [1:13:50<18:56,  5.57it/s, lr=0.001, step_loss=0.108]07/27/2023 18:58:40 - INFO - __main__ - train loss is 25.499218848417513\n",
      "Steps:  58%|█▏| 8674/15000 [1:13:50<18:56,  5.57it/s, lr=0.001, step_loss=0.304]07/27/2023 18:58:40 - INFO - __main__ - train loss is 25.506084510008805\n",
      "Steps:  58%|▌| 8675/15000 [1:13:50<18:56,  5.56it/s, lr=0.001, step_loss=0.0068707/27/2023 18:58:40 - INFO - __main__ - train loss is 25.78825212351512\n",
      "Steps:  58%|█▏| 8676/15000 [1:13:51<18:56,  5.56it/s, lr=0.001, step_loss=0.282]07/27/2023 18:58:41 - INFO - __main__ - train loss is 25.807518095592968\n",
      "Steps:  58%|▌| 8677/15000 [1:13:51<18:55,  5.57it/s, lr=0.001, step_loss=0.0193]07/27/2023 18:58:41 - INFO - __main__ - train loss is 25.810241434373893\n",
      "Steps:  58%|▌| 8678/15000 [1:13:51<18:54,  5.57it/s, lr=0.001, step_loss=0.0027207/27/2023 18:58:41 - INFO - __main__ - train loss is 25.816512956400402\n",
      "Steps:  58%|▌| 8679/15000 [1:13:51<19:04,  5.52it/s, lr=0.001, step_loss=0.0062707/27/2023 18:58:41 - INFO - __main__ - train loss is 25.8272596282186\n",
      "Steps:  58%|▌| 8680/15000 [1:13:51<19:13,  5.48it/s, lr=0.001, step_loss=0.0107]07/27/2023 18:58:41 - INFO - __main__ - train loss is 26.17015775863547\n",
      "Steps:  58%|█▏| 8681/15000 [1:13:52<19:14,  5.47it/s, lr=0.001, step_loss=0.343]07/27/2023 18:58:41 - INFO - __main__ - train loss is 26.173696612589993\n",
      "Steps:  58%|▌| 8682/15000 [1:13:52<19:14,  5.47it/s, lr=0.001, step_loss=0.0035407/27/2023 18:58:42 - INFO - __main__ - train loss is 26.292850536876358\n",
      "Steps:  58%|█▏| 8683/15000 [1:13:52<19:08,  5.50it/s, lr=0.001, step_loss=0.119]07/27/2023 18:58:42 - INFO - __main__ - train loss is 26.367940498166718\n",
      "Steps:  58%|▌| 8684/15000 [1:13:52<19:03,  5.52it/s, lr=0.001, step_loss=0.0751]07/27/2023 18:58:42 - INFO - __main__ - train loss is 26.36982942780014\n",
      "Steps:  58%|▌| 8685/15000 [1:13:52<19:13,  5.48it/s, lr=0.001, step_loss=0.0018907/27/2023 18:58:42 - INFO - __main__ - train loss is 26.66068263014313\n",
      "Steps:  58%|█▏| 8686/15000 [1:13:52<19:10,  5.49it/s, lr=0.001, step_loss=0.291]07/27/2023 18:58:42 - INFO - __main__ - train loss is 26.83143055101391\n",
      "Steps:  58%|█▏| 8687/15000 [1:13:53<19:05,  5.51it/s, lr=0.001, step_loss=0.171]07/27/2023 18:58:43 - INFO - __main__ - train loss is 26.833071430562995\n",
      "Steps:  58%|▌| 8688/15000 [1:13:53<19:01,  5.53it/s, lr=0.001, step_loss=0.0016407/27/2023 18:58:43 - INFO - __main__ - train loss is 26.976154645322822\n",
      "Steps:  58%|█▏| 8689/15000 [1:13:53<18:59,  5.54it/s, lr=0.001, step_loss=0.143]07/27/2023 18:58:43 - INFO - __main__ - train loss is 27.0836696078768\n",
      "Steps:  58%|█▏| 8690/15000 [1:13:53<18:57,  5.55it/s, lr=0.001, step_loss=0.108]07/27/2023 18:58:43 - INFO - __main__ - train loss is 27.41568738722708\n",
      "Steps:  58%|█▏| 8691/15000 [1:13:53<18:56,  5.55it/s, lr=0.001, step_loss=0.332]07/27/2023 18:58:43 - INFO - __main__ - train loss is 28.050125425099395\n",
      "Steps:  58%|█▏| 8692/15000 [1:13:54<18:55,  5.56it/s, lr=0.001, step_loss=0.634]07/27/2023 18:58:43 - INFO - __main__ - train loss is 28.12168679141905\n",
      "Steps:  58%|▌| 8693/15000 [1:13:54<18:53,  5.56it/s, lr=0.001, step_loss=0.0716]07/27/2023 18:58:44 - INFO - __main__ - train loss is 28.314999495982192\n",
      "Steps:  58%|█▏| 8694/15000 [1:13:54<18:52,  5.57it/s, lr=0.001, step_loss=0.193]07/27/2023 18:58:44 - INFO - __main__ - train loss is 28.351870620041154\n",
      "Steps:  58%|▌| 8695/15000 [1:13:54<19:00,  5.53it/s, lr=0.001, step_loss=0.0369]07/27/2023 18:58:44 - INFO - __main__ - train loss is 28.388189570396207\n",
      "Steps:  58%|▌| 8696/15000 [1:13:54<19:06,  5.50it/s, lr=0.001, step_loss=0.0363]07/27/2023 18:58:44 - INFO - __main__ - train loss is 28.432990090339445\n",
      "Steps:  58%|▌| 8697/15000 [1:13:54<19:11,  5.48it/s, lr=0.001, step_loss=0.0448]07/27/2023 18:58:44 - INFO - __main__ - train loss is 28.441043532802723\n",
      "Steps:  58%|▌| 8698/15000 [1:13:55<19:12,  5.47it/s, lr=0.001, step_loss=0.0080507/27/2023 18:58:45 - INFO - __main__ - train loss is 28.487082167877816\n",
      "Steps:  58%|█▏| 8699/15000 [1:13:55<19:15,  5.45it/s, lr=0.001, step_loss=0.046]07/27/2023 18:58:45 - INFO - __main__ - train loss is 28.788040533079766\n",
      "Steps:  58%|█▏| 8700/15000 [1:13:55<19:14,  5.46it/s, lr=0.001, step_loss=0.301]07/27/2023 18:58:45 - INFO - __main__ - train loss is 29.01961395086255\n",
      "Steps:  58%|█▏| 8701/15000 [1:13:55<19:17,  5.44it/s, lr=0.001, step_loss=0.232]07/27/2023 18:58:45 - INFO - __main__ - train loss is 29.497010290040635\n",
      "Steps:  58%|█▏| 8702/15000 [1:13:55<19:10,  5.47it/s, lr=0.001, step_loss=0.477]07/27/2023 18:58:45 - INFO - __main__ - train loss is 29.74608659686055\n",
      "Steps:  58%|█▏| 8703/15000 [1:13:56<19:04,  5.50it/s, lr=0.001, step_loss=0.249]07/27/2023 18:58:45 - INFO - __main__ - train loss is 29.959629549994133\n",
      "Steps:  58%|█▏| 8704/15000 [1:13:56<19:00,  5.52it/s, lr=0.001, step_loss=0.214]07/27/2023 18:58:46 - INFO - __main__ - train loss is 30.171102538122796\n",
      "Steps:  58%|█▏| 8705/15000 [1:13:56<18:57,  5.54it/s, lr=0.001, step_loss=0.211]07/27/2023 18:58:46 - INFO - __main__ - train loss is 30.180255763581954\n",
      "Steps:  58%|▌| 8706/15000 [1:13:56<18:56,  5.54it/s, lr=0.001, step_loss=0.0091507/27/2023 18:58:46 - INFO - __main__ - train loss is 30.443200223497115\n",
      "Steps:  58%|█▏| 8707/15000 [1:13:56<18:54,  5.55it/s, lr=0.001, step_loss=0.263]07/27/2023 18:58:46 - INFO - __main__ - train loss is 30.548008479527198\n",
      "Steps:  58%|█▏| 8708/15000 [1:13:56<18:53,  5.55it/s, lr=0.001, step_loss=0.105]07/27/2023 18:58:46 - INFO - __main__ - train loss is 30.60375032236334\n",
      "Steps:  58%|▌| 8709/15000 [1:13:57<18:59,  5.52it/s, lr=0.001, step_loss=0.0557]07/27/2023 18:58:47 - INFO - __main__ - train loss is 30.636570852599107\n",
      "Steps:  58%|▌| 8710/15000 [1:13:57<18:56,  5.53it/s, lr=0.001, step_loss=0.0328]07/27/2023 18:58:47 - INFO - __main__ - train loss is 30.78265462478157\n",
      "Steps:  58%|█▏| 8711/15000 [1:13:57<18:54,  5.54it/s, lr=0.001, step_loss=0.146]07/27/2023 18:58:47 - INFO - __main__ - train loss is 30.79470836778637\n",
      "Steps:  58%|▌| 8712/15000 [1:13:57<18:53,  5.55it/s, lr=0.001, step_loss=0.0121]07/27/2023 18:58:47 - INFO - __main__ - train loss is 31.300728198490106\n",
      "Steps:  58%|█▏| 8713/15000 [1:13:57<18:51,  5.56it/s, lr=0.001, step_loss=0.506]07/27/2023 18:58:47 - INFO - __main__ - train loss is 31.449777301750146\n",
      "Steps:  58%|█▏| 8714/15000 [1:13:58<18:50,  5.56it/s, lr=0.001, step_loss=0.149]07/27/2023 18:58:47 - INFO - __main__ - train loss is 31.451646210742183\n",
      "Steps:  58%|▌| 8715/15000 [1:13:58<18:49,  5.57it/s, lr=0.001, step_loss=0.0018707/27/2023 18:58:48 - INFO - __main__ - train loss is 31.81160345871467\n",
      "Steps:  58%|█▋ | 8716/15000 [1:13:58<18:48,  5.57it/s, lr=0.001, step_loss=0.36]07/27/2023 18:58:48 - INFO - __main__ - train loss is 31.925453292322345\n",
      "Steps:  58%|█▏| 8717/15000 [1:13:58<18:48,  5.57it/s, lr=0.001, step_loss=0.114]07/27/2023 18:58:48 - INFO - __main__ - train loss is 32.0483064224245\n",
      "Steps:  58%|█▏| 8718/15000 [1:13:58<18:48,  5.57it/s, lr=0.001, step_loss=0.123]07/27/2023 18:58:48 - INFO - __main__ - train loss is 32.222209202242084\n",
      "Steps:  58%|█▏| 8719/15000 [1:13:58<18:48,  5.57it/s, lr=0.001, step_loss=0.174]07/27/2023 18:58:48 - INFO - __main__ - train loss is 32.44329056341667\n",
      "Steps:  58%|█▏| 8720/15000 [1:13:59<18:48,  5.56it/s, lr=0.001, step_loss=0.221]07/27/2023 18:58:48 - INFO - __main__ - train loss is 32.449729480431415\n",
      "Steps:  58%|▌| 8721/15000 [1:13:59<18:48,  5.56it/s, lr=0.001, step_loss=0.0064407/27/2023 18:58:49 - INFO - __main__ - train loss is 32.606060483143665\n",
      "Steps:  58%|█▏| 8722/15000 [1:13:59<18:49,  5.56it/s, lr=0.001, step_loss=0.156]07/27/2023 18:58:49 - INFO - __main__ - train loss is 32.648706216947176\n",
      "Steps:  58%|▌| 8723/15000 [1:13:59<18:48,  5.56it/s, lr=0.001, step_loss=0.0426]07/27/2023 18:58:49 - INFO - __main__ - train loss is 32.92482044233475\n",
      "Steps:  58%|█▏| 8724/15000 [1:13:59<18:57,  5.52it/s, lr=0.001, step_loss=0.276]07/27/2023 18:58:49 - INFO - __main__ - train loss is 32.94202239869628\n",
      "Steps:  58%|▌| 8725/15000 [1:14:00<18:53,  5.53it/s, lr=0.001, step_loss=0.0172]07/27/2023 18:58:49 - INFO - __main__ - train loss is 32.944325598771684\n",
      "Steps:  58%|▌| 8726/15000 [1:14:00<18:51,  5.54it/s, lr=0.001, step_loss=0.0023]07/27/2023 18:58:50 - INFO - __main__ - train loss is 32.97143557376694\n",
      "Steps:  58%|▌| 8727/15000 [1:14:00<18:49,  5.56it/s, lr=0.001, step_loss=0.0271]07/27/2023 18:58:50 - INFO - __main__ - train loss is 33.29164290137123\n",
      "Steps:  58%|█▋ | 8728/15000 [1:14:00<18:48,  5.56it/s, lr=0.001, step_loss=0.32]07/27/2023 18:58:50 - INFO - __main__ - train loss is 33.43956784612965\n",
      "Steps:  58%|█▏| 8729/15000 [1:14:00<18:47,  5.56it/s, lr=0.001, step_loss=0.148]07/27/2023 18:58:50 - INFO - __main__ - train loss is 33.476897996733896\n",
      "Steps:  58%|▌| 8730/15000 [1:14:00<18:46,  5.57it/s, lr=0.001, step_loss=0.0373]07/27/2023 18:58:50 - INFO - __main__ - train loss is 33.77394415147137\n",
      "Steps:  58%|█▏| 8731/15000 [1:14:01<18:46,  5.57it/s, lr=0.001, step_loss=0.297]07/27/2023 18:58:50 - INFO - __main__ - train loss is 33.78297334059607\n",
      "Steps:  58%|▌| 8732/15000 [1:14:01<18:45,  5.57it/s, lr=0.001, step_loss=0.0090307/27/2023 18:58:51 - INFO - __main__ - train loss is 34.031777641619556\n",
      "Steps:  58%|█▏| 8733/15000 [1:14:01<18:45,  5.57it/s, lr=0.001, step_loss=0.249]07/27/2023 18:58:51 - INFO - __main__ - train loss is 34.040884594316594\n",
      "Steps:  58%|▌| 8734/15000 [1:14:01<18:45,  5.57it/s, lr=0.001, step_loss=0.0091107/27/2023 18:58:51 - INFO - __main__ - train loss is 34.04520360834431\n",
      "Steps:  58%|▌| 8735/15000 [1:14:01<18:45,  5.57it/s, lr=0.001, step_loss=0.0043207/27/2023 18:58:51 - INFO - __main__ - train loss is 34.26627208001446\n",
      "Steps:  58%|█▏| 8736/15000 [1:14:01<18:45,  5.57it/s, lr=0.001, step_loss=0.221]07/27/2023 18:58:51 - INFO - __main__ - train loss is 34.27267726312857\n",
      "Steps:  58%|▌| 8737/15000 [1:14:02<18:45,  5.56it/s, lr=0.001, step_loss=0.0064107/27/2023 18:58:52 - INFO - __main__ - train loss is 34.303002675878815\n",
      "Steps:  58%|▌| 8738/15000 [1:14:02<18:45,  5.56it/s, lr=0.001, step_loss=0.0303]07/27/2023 18:58:52 - INFO - __main__ - train loss is 34.307963119237684\n",
      "Steps:  58%|▌| 8739/15000 [1:14:02<18:45,  5.56it/s, lr=0.001, step_loss=0.0049607/27/2023 18:58:52 - INFO - __main__ - train loss is 34.36143062391784\n",
      "Steps:  58%|▌| 8740/15000 [1:14:02<18:45,  5.56it/s, lr=0.001, step_loss=0.0535]07/27/2023 18:58:52 - INFO - __main__ - train loss is 34.36960468941834\n",
      "Steps:  58%|▌| 8741/15000 [1:14:02<18:44,  5.57it/s, lr=0.001, step_loss=0.0081707/27/2023 18:58:52 - INFO - __main__ - train loss is 34.486196411191486\n",
      "Steps:  58%|█▏| 8742/15000 [1:14:03<18:44,  5.57it/s, lr=0.001, step_loss=0.117]07/27/2023 18:58:52 - INFO - __main__ - train loss is 34.611049128114246\n",
      "Steps:  58%|█▏| 8743/15000 [1:14:03<18:43,  5.57it/s, lr=0.001, step_loss=0.125]07/27/2023 18:58:53 - INFO - __main__ - train loss is 34.651799512444995\n",
      "Steps:  58%|▌| 8744/15000 [1:14:03<18:43,  5.57it/s, lr=0.001, step_loss=0.0408]07/27/2023 18:58:53 - INFO - __main__ - train loss is 34.73463277274277\n",
      "Steps:  58%|▌| 8745/15000 [1:14:03<18:42,  5.57it/s, lr=0.001, step_loss=0.0828]07/27/2023 18:58:53 - INFO - __main__ - train loss is 34.7372761167353\n",
      "Steps:  58%|▌| 8746/15000 [1:14:03<18:51,  5.53it/s, lr=0.001, step_loss=0.0026407/27/2023 18:58:53 - INFO - __main__ - train loss is 34.766781738377176\n",
      "Steps:  58%|▌| 8747/15000 [1:14:03<18:50,  5.53it/s, lr=0.001, step_loss=0.0295]07/27/2023 18:58:53 - INFO - __main__ - train loss is 34.78310116229113\n",
      "Steps:  58%|▌| 8748/15000 [1:14:04<18:59,  5.49it/s, lr=0.001, step_loss=0.0163]07/27/2023 18:58:54 - INFO - __main__ - train loss is 34.79365912859794\n",
      "Steps:  58%|▌| 8749/15000 [1:14:04<19:10,  5.43it/s, lr=0.001, step_loss=0.0106]07/27/2023 18:58:54 - INFO - __main__ - train loss is 34.800399788073264\n",
      "Steps:  58%|▌| 8750/15000 [1:14:04<19:03,  5.47it/s, lr=0.001, step_loss=0.0067407/27/2023 18:58:54 - INFO - __main__ - train loss is 35.45226777379867\n",
      "Steps:  58%|█▏| 8751/15000 [1:14:04<18:56,  5.50it/s, lr=0.001, step_loss=0.652]07/27/2023 18:58:54 - INFO - __main__ - train loss is 35.47673795407172\n",
      "Steps:  58%|▌| 8752/15000 [1:14:04<18:51,  5.52it/s, lr=0.001, step_loss=0.0245]07/27/2023 18:58:54 - INFO - __main__ - train loss is 35.48018082266208\n",
      "Steps:  58%|▌| 8753/15000 [1:14:05<18:48,  5.54it/s, lr=0.001, step_loss=0.0034407/27/2023 18:58:54 - INFO - __main__ - train loss is 35.84891828184482\n",
      "Steps:  58%|█▏| 8754/15000 [1:14:05<18:45,  5.55it/s, lr=0.001, step_loss=0.369]07/27/2023 18:58:55 - INFO - __main__ - train loss is 35.85079969128128\n",
      "Steps:  58%|▌| 8755/15000 [1:14:05<18:43,  5.56it/s, lr=0.001, step_loss=0.0018807/27/2023 18:58:55 - INFO - __main__ - train loss is 36.109191876254044\n",
      "Steps:  58%|█▏| 8756/15000 [1:14:05<18:42,  5.56it/s, lr=0.001, step_loss=0.258]07/27/2023 18:58:55 - INFO - __main__ - train loss is 36.146164328209125\n",
      "Steps:  58%|▌| 8757/15000 [1:14:05<18:41,  5.57it/s, lr=0.000999, step_loss=0.0307/27/2023 18:58:55 - INFO - __main__ - train loss is 36.3193672898924\n",
      "Steps:  58%|▌| 8758/15000 [1:14:05<18:40,  5.57it/s, lr=0.000999, step_loss=0.1707/27/2023 18:58:55 - INFO - __main__ - train loss is 36.36353014444467\n",
      "Steps:  58%|▌| 8759/15000 [1:14:06<18:39,  5.57it/s, lr=0.000999, step_loss=0.0407/27/2023 18:58:56 - INFO - __main__ - train loss is 36.39308957417961\n",
      "Steps:  58%|▌| 8760/15000 [1:14:06<18:39,  5.57it/s, lr=0.000999, step_loss=0.0207/27/2023 18:58:56 - INFO - __main__ - train loss is 36.52022353967186\n",
      "Steps:  58%|▌| 8761/15000 [1:14:06<18:39,  5.58it/s, lr=0.000999, step_loss=0.1207/27/2023 18:58:56 - INFO - __main__ - train loss is 36.70204673369881\n",
      "Steps:  58%|▌| 8762/15000 [1:14:06<18:38,  5.58it/s, lr=0.000999, step_loss=0.1807/27/2023 18:58:56 - INFO - __main__ - train loss is 36.70497210265603\n",
      "Steps:  58%|▌| 8763/15000 [1:14:06<18:37,  5.58it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:56 - INFO - __main__ - train loss is 36.71651076094713\n",
      "Steps:  58%|▌| 8764/15000 [1:14:07<18:38,  5.58it/s, lr=0.000999, step_loss=0.0107/27/2023 18:58:56 - INFO - __main__ - train loss is 36.723802158026956\n",
      "Steps:  58%|▌| 8765/15000 [1:14:07<18:38,  5.58it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:57 - INFO - __main__ - train loss is 36.73857009259518\n",
      "Steps:  58%|▌| 8766/15000 [1:14:07<18:38,  5.57it/s, lr=0.000999, step_loss=0.0107/27/2023 18:58:57 - INFO - __main__ - train loss is 36.745560266426764\n",
      "Steps:  58%|▌| 8767/15000 [1:14:07<18:37,  5.58it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:57 - INFO - __main__ - train loss is 36.78715736081358\n",
      "Steps:  58%|▌| 8768/15000 [1:14:07<18:40,  5.56it/s, lr=0.000999, step_loss=0.0407/27/2023 18:58:57 - INFO - __main__ - train loss is 37.128472868702374\n",
      "Steps:  58%|▌| 8769/15000 [1:14:07<18:40,  5.56it/s, lr=0.000999, step_loss=0.3407/27/2023 18:58:57 - INFO - __main__ - train loss is 37.16607256641146\n",
      "Steps:  58%|▌| 8770/15000 [1:14:08<18:43,  5.55it/s, lr=0.000999, step_loss=0.0307/27/2023 18:58:57 - INFO - __main__ - train loss is 37.16986164462287\n",
      "Steps:  58%|▌| 8771/15000 [1:14:08<18:41,  5.55it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:58 - INFO - __main__ - train loss is 37.1777371839853\n",
      "Steps:  58%|▌| 8772/15000 [1:14:08<18:39,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:58 - INFO - __main__ - train loss is 37.36806374054868\n",
      "[2023-07-27 18:58:58,426] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  58%|▌| 8773/15000 [1:14:08<18:31,  5.60it/s, lr=0.000999, step_loss=0.1907/27/2023 18:58:58 - INFO - __main__ - train loss is 37.373667934094556\n",
      "Steps:  58%|▌| 8774/15000 [1:14:08<18:32,  5.60it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:58 - INFO - __main__ - train loss is 37.375787849654444\n",
      "Steps:  58%|▌| 8775/15000 [1:14:09<18:41,  5.55it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:58 - INFO - __main__ - train loss is 37.56225898407865\n",
      "Steps:  59%|▌| 8776/15000 [1:14:09<18:37,  5.57it/s, lr=0.000999, step_loss=0.1807/27/2023 18:58:59 - INFO - __main__ - train loss is 37.671641360153444\n",
      "Steps:  59%|▌| 8777/15000 [1:14:09<18:36,  5.58it/s, lr=0.000999, step_loss=0.1007/27/2023 18:58:59 - INFO - __main__ - train loss is 37.86030987941194\n",
      "Steps:  59%|▌| 8778/15000 [1:14:09<18:34,  5.58it/s, lr=0.000999, step_loss=0.1807/27/2023 18:58:59 - INFO - __main__ - train loss is 37.881439969991334\n",
      "Steps:  59%|▌| 8779/15000 [1:14:09<18:33,  5.59it/s, lr=0.000999, step_loss=0.0207/27/2023 18:58:59 - INFO - __main__ - train loss is 37.890324140083976\n",
      "Steps:  59%|▌| 8780/15000 [1:14:09<18:33,  5.59it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:59 - INFO - __main__ - train loss is 37.89953914855141\n",
      "Steps:  59%|▌| 8781/15000 [1:14:10<18:33,  5.58it/s, lr=0.000999, step_loss=0.0007/27/2023 18:58:59 - INFO - __main__ - train loss is 38.31086338136811\n",
      "Steps:  59%|▌| 8782/15000 [1:14:10<18:33,  5.58it/s, lr=0.000999, step_loss=0.4107/27/2023 18:59:00 - INFO - __main__ - train loss is 38.317363709793426\n",
      "Steps:  59%|▌| 8783/15000 [1:14:10<18:33,  5.59it/s, lr=0.000999, step_loss=0.0007/27/2023 18:59:00 - INFO - __main__ - train loss is 38.324450960964896\n",
      "Steps:  59%|▌| 8784/15000 [1:14:10<18:32,  5.59it/s, lr=0.000999, step_loss=0.0007/27/2023 18:59:00 - INFO - __main__ - train loss is 38.332310244091786\n",
      "Steps:  59%|▌| 8785/15000 [1:14:10<18:32,  5.59it/s, lr=0.000999, step_loss=0.0007/27/2023 18:59:00 - INFO - __main__ - train loss is 38.37560116464738\n",
      "Steps:  59%|▌| 8786/15000 [1:14:10<18:32,  5.59it/s, lr=0.000999, step_loss=0.0407/27/2023 18:59:01 - INFO - __main__ - train loss is 38.50044643844012\n",
      "Steps:  59%|▌| 8787/15000 [1:14:11<25:35,  4.05it/s, lr=0.000999, step_loss=0.1207/27/2023 18:59:02 - INFO - __main__ - Per validation step average loss is 0.003225139807909727\n",
      "07/27/2023 18:59:02 - INFO - __main__ - Cumulative validation average loss is 0.003225139807909727\n",
      "07/27/2023 18:59:02 - INFO - __main__ - Per validation step average loss is 0.29092830419540405\n",
      "07/27/2023 18:59:02 - INFO - __main__ - Cumulative validation average loss is 0.2941534440033138\n",
      "07/27/2023 18:59:02 - INFO - __main__ - Per validation step average loss is 0.11315180361270905\n",
      "07/27/2023 18:59:02 - INFO - __main__ - Cumulative validation average loss is 0.4073052476160228\n",
      "07/27/2023 18:59:03 - INFO - __main__ - Per validation step average loss is 0.0031339176930487156\n",
      "07/27/2023 18:59:03 - INFO - __main__ - Cumulative validation average loss is 0.41043916530907154\n",
      "07/27/2023 18:59:03 - INFO - __main__ - Per validation step average loss is 0.2353379726409912\n",
      "07/27/2023 18:59:03 - INFO - __main__ - Cumulative validation average loss is 0.6457771379500628\n",
      "07/27/2023 18:59:04 - INFO - __main__ - Per validation step average loss is 0.15226809680461884\n",
      "07/27/2023 18:59:04 - INFO - __main__ - Cumulative validation average loss is 0.7980452347546816\n",
      "07/27/2023 18:59:04 - INFO - __main__ - Per validation step average loss is 0.002749089617282152\n",
      "07/27/2023 18:59:04 - INFO - __main__ - Cumulative validation average loss is 0.8007943243719637\n",
      "07/27/2023 18:59:05 - INFO - __main__ - Per validation step average loss is 0.02251644805073738\n",
      "07/27/2023 18:59:05 - INFO - __main__ - Cumulative validation average loss is 0.8233107724227011\n",
      "07/27/2023 18:59:05 - INFO - __main__ - Per validation step average loss is 0.09996199607849121\n",
      "07/27/2023 18:59:05 - INFO - __main__ - Cumulative validation average loss is 0.9232727685011923\n",
      "07/27/2023 18:59:05 - INFO - __main__ - Per validation step average loss is 0.3624163866043091\n",
      "07/27/2023 18:59:05 - INFO - __main__ - Cumulative validation average loss is 1.2856891551055014\n",
      "07/27/2023 18:59:06 - INFO - __main__ - Per validation step average loss is 0.33746206760406494\n",
      "07/27/2023 18:59:06 - INFO - __main__ - Cumulative validation average loss is 1.6231512227095664\n",
      "07/27/2023 18:59:06 - INFO - __main__ - Per validation step average loss is 0.04649753123521805\n",
      "07/27/2023 18:59:06 - INFO - __main__ - Cumulative validation average loss is 1.6696487539447844\n",
      "07/27/2023 18:59:07 - INFO - __main__ - Per validation step average loss is 0.1782151311635971\n",
      "07/27/2023 18:59:07 - INFO - __main__ - Cumulative validation average loss is 1.8478638851083815\n",
      "07/27/2023 18:59:07 - INFO - __main__ - Per validation step average loss is 0.37889909744262695\n",
      "07/27/2023 18:59:07 - INFO - __main__ - Cumulative validation average loss is 2.2267629825510085\n",
      "07/27/2023 18:59:07 - INFO - __main__ - Per validation step average loss is 0.07011634111404419\n",
      "07/27/2023 18:59:07 - INFO - __main__ - Cumulative validation average loss is 2.2968793236650527\n",
      "07/27/2023 18:59:08 - INFO - __main__ - Per validation step average loss is 0.015070471912622452\n",
      "07/27/2023 18:59:08 - INFO - __main__ - Cumulative validation average loss is 2.311949795577675\n",
      "07/27/2023 18:59:08 - INFO - __main__ - Per validation step average loss is 0.0019141482189297676\n",
      "07/27/2023 18:59:08 - INFO - __main__ - Cumulative validation average loss is 2.313863943796605\n",
      "07/27/2023 18:59:09 - INFO - __main__ - Per validation step average loss is 0.38368991017341614\n",
      "07/27/2023 18:59:09 - INFO - __main__ - Cumulative validation average loss is 2.697553853970021\n",
      "07/27/2023 18:59:09 - INFO - __main__ - Per validation step average loss is 0.17712870240211487\n",
      "07/27/2023 18:59:09 - INFO - __main__ - Cumulative validation average loss is 2.874682556372136\n",
      "07/27/2023 18:59:10 - INFO - __main__ - Per validation step average loss is 0.0548819899559021\n",
      "07/27/2023 18:59:10 - INFO - __main__ - Cumulative validation average loss is 2.929564546328038\n",
      "07/27/2023 18:59:10 - INFO - __main__ - Per validation step average loss is 0.019673198461532593\n",
      "07/27/2023 18:59:10 - INFO - __main__ - Cumulative validation average loss is 2.9492377447895706\n",
      "07/27/2023 18:59:10 - INFO - __main__ - Per validation step average loss is 0.38012343645095825\n",
      "07/27/2023 18:59:10 - INFO - __main__ - Cumulative validation average loss is 3.329361181240529\n",
      "07/27/2023 18:59:11 - INFO - __main__ - Per validation step average loss is 0.01682485081255436\n",
      "07/27/2023 18:59:11 - INFO - __main__ - Cumulative validation average loss is 3.346186032053083\n",
      "07/27/2023 18:59:11 - INFO - __main__ - Per validation step average loss is 0.0033412459306418896\n",
      "07/27/2023 18:59:11 - INFO - __main__ - Cumulative validation average loss is 3.349527277983725\n",
      "07/27/2023 18:59:12 - INFO - __main__ - Per validation step average loss is 0.013111570850014687\n",
      "07/27/2023 18:59:12 - INFO - __main__ - Cumulative validation average loss is 3.3626388488337398\n",
      "07/27/2023 18:59:12 - INFO - __main__ - Per validation step average loss is 0.0012032645754516125\n",
      "07/27/2023 18:59:12 - INFO - __main__ - Cumulative validation average loss is 3.3638421134091914\n",
      "07/27/2023 18:59:12 - INFO - __main__ - Per validation step average loss is 0.004039412830024958\n",
      "07/27/2023 18:59:12 - INFO - __main__ - Cumulative validation average loss is 3.3678815262392163\n",
      "07/27/2023 18:59:13 - INFO - __main__ - Per validation step average loss is 0.0019660168327391148\n",
      "07/27/2023 18:59:13 - INFO - __main__ - Cumulative validation average loss is 3.3698475430719554\n",
      "07/27/2023 18:59:13 - INFO - __main__ - Per validation step average loss is 0.09271156787872314\n",
      "07/27/2023 18:59:13 - INFO - __main__ - Cumulative validation average loss is 3.4625591109506786\n",
      "07/27/2023 18:59:14 - INFO - __main__ - Per validation step average loss is 0.02861776016652584\n",
      "07/27/2023 18:59:14 - INFO - __main__ - Cumulative validation average loss is 3.4911768711172044\n",
      "07/27/2023 18:59:14 - INFO - __main__ - Per validation step average loss is 0.17751765251159668\n",
      "07/27/2023 18:59:14 - INFO - __main__ - Cumulative validation average loss is 3.668694523628801\n",
      "07/27/2023 18:59:14 - INFO - __main__ - Per validation step average loss is 0.11389800906181335\n",
      "07/27/2023 18:59:14 - INFO - __main__ - Cumulative validation average loss is 3.7825925326906145\n",
      "07/27/2023 18:59:15 - INFO - __main__ - Per validation step average loss is 0.04063311219215393\n",
      "07/27/2023 18:59:15 - INFO - __main__ - Cumulative validation average loss is 3.8232256448827684\n",
      "07/27/2023 18:59:15 - INFO - __main__ - Per validation step average loss is 0.014757088385522366\n",
      "07/27/2023 18:59:15 - INFO - __main__ - Cumulative validation average loss is 3.8379827332682908\n",
      "07/27/2023 18:59:16 - INFO - __main__ - Per validation step average loss is 0.03471251577138901\n",
      "07/27/2023 18:59:16 - INFO - __main__ - Cumulative validation average loss is 3.8726952490396798\n",
      "07/27/2023 18:59:16 - INFO - __main__ - Per validation step average loss is 0.025914181023836136\n",
      "07/27/2023 18:59:16 - INFO - __main__ - Cumulative validation average loss is 3.898609430063516\n",
      "07/27/2023 18:59:17 - INFO - __main__ - Per validation step average loss is 0.2076883316040039\n",
      "07/27/2023 18:59:17 - INFO - __main__ - Cumulative validation average loss is 4.10629776166752\n",
      "07/27/2023 18:59:17 - INFO - __main__ - Per validation step average loss is 0.4213256537914276\n",
      "07/27/2023 18:59:17 - INFO - __main__ - Cumulative validation average loss is 4.527623415458947\n",
      "07/27/2023 18:59:17 - INFO - __main__ - Per validation step average loss is 0.029643241316080093\n",
      "07/27/2023 18:59:17 - INFO - __main__ - Cumulative validation average loss is 4.5572666567750275\n",
      "07/27/2023 18:59:18 - INFO - __main__ - Per validation step average loss is 0.052298687398433685\n",
      "07/27/2023 18:59:18 - INFO - __main__ - Cumulative validation average loss is 4.609565344173461\n",
      "07/27/2023 18:59:18 - INFO - __main__ - Per validation step average loss is 0.34976714849472046\n",
      "07/27/2023 18:59:18 - INFO - __main__ - Cumulative validation average loss is 4.959332492668182\n",
      "07/27/2023 18:59:19 - INFO - __main__ - Per validation step average loss is 0.3591771125793457\n",
      "07/27/2023 18:59:19 - INFO - __main__ - Cumulative validation average loss is 5.318509605247527\n",
      "07/27/2023 18:59:19 - INFO - __main__ - Per validation step average loss is 0.09427105635404587\n",
      "07/27/2023 18:59:19 - INFO - __main__ - Cumulative validation average loss is 5.412780661601573\n",
      "07/27/2023 18:59:19 - INFO - __main__ - Per validation step average loss is 0.005644794553518295\n",
      "07/27/2023 18:59:19 - INFO - __main__ - Cumulative validation average loss is 5.4184254561550915\n",
      "07/27/2023 18:59:20 - INFO - __main__ - Per validation step average loss is 0.12371212989091873\n",
      "07/27/2023 18:59:20 - INFO - __main__ - Cumulative validation average loss is 5.54213758604601\n",
      "07/27/2023 18:59:20 - INFO - __main__ - Per validation step average loss is 0.15273936092853546\n",
      "07/27/2023 18:59:20 - INFO - __main__ - Cumulative validation average loss is 5.694876946974546\n",
      "07/27/2023 18:59:21 - INFO - __main__ - Per validation step average loss is 0.029739059507846832\n",
      "07/27/2023 18:59:21 - INFO - __main__ - Cumulative validation average loss is 5.7246160064823925\n",
      "07/27/2023 18:59:21 - INFO - __main__ - Per validation step average loss is 0.4868502616882324\n",
      "07/27/2023 18:59:21 - INFO - __main__ - Cumulative validation average loss is 6.211466268170625\n",
      "07/27/2023 18:59:21 - INFO - __main__ - Per validation step average loss is 0.21596935391426086\n",
      "07/27/2023 18:59:21 - INFO - __main__ - Cumulative validation average loss is 6.427435622084886\n",
      "07/27/2023 18:59:22 - INFO - __main__ - Per validation step average loss is 0.04334276169538498\n",
      "07/27/2023 18:59:22 - INFO - __main__ - Cumulative validation average loss is 6.470778383780271\n",
      "07/27/2023 18:59:22 - INFO - __main__ - Per validation step average loss is 0.1974986493587494\n",
      "07/27/2023 18:59:22 - INFO - __main__ - Cumulative validation average loss is 6.66827703313902\n",
      "07/27/2023 18:59:23 - INFO - __main__ - Per validation step average loss is 0.041039466857910156\n",
      "07/27/2023 18:59:23 - INFO - __main__ - Cumulative validation average loss is 6.70931649999693\n",
      "07/27/2023 18:59:23 - INFO - __main__ - Per validation step average loss is 0.015772949904203415\n",
      "07/27/2023 18:59:23 - INFO - __main__ - Cumulative validation average loss is 6.725089449901134\n",
      "07/27/2023 18:59:24 - INFO - __main__ - Per validation step average loss is 0.09360949695110321\n",
      "07/27/2023 18:59:24 - INFO - __main__ - Cumulative validation average loss is 6.818698946852237\n",
      "07/27/2023 18:59:24 - INFO - __main__ - Per validation step average loss is 0.28627637028694153\n",
      "07/27/2023 18:59:24 - INFO - __main__ - Cumulative validation average loss is 7.1049753171391785\n",
      "07/27/2023 18:59:24 - INFO - __main__ - Per validation step average loss is 0.0018487154738977551\n",
      "07/27/2023 18:59:24 - INFO - __main__ - Cumulative validation average loss is 7.106824032613076\n",
      "07/27/2023 18:59:25 - INFO - __main__ - Per validation step average loss is 0.3540155291557312\n",
      "07/27/2023 18:59:25 - INFO - __main__ - Cumulative validation average loss is 7.4608395617688075\n",
      "07/27/2023 18:59:25 - INFO - __main__ - Per validation step average loss is 0.0199732705950737\n",
      "07/27/2023 18:59:25 - INFO - __main__ - Cumulative validation average loss is 7.480812832363881\n",
      "07/27/2023 18:59:26 - INFO - __main__ - Per validation step average loss is 0.23785880208015442\n",
      "07/27/2023 18:59:26 - INFO - __main__ - Cumulative validation average loss is 7.718671634444036\n",
      "07/27/2023 18:59:26 - INFO - __main__ - Per validation step average loss is 0.010405587032437325\n",
      "07/27/2023 18:59:26 - INFO - __main__ - Cumulative validation average loss is 7.729077221476473\n",
      "07/27/2023 18:59:26 - INFO - __main__ - Per validation step average loss is 0.008869422599673271\n",
      "07/27/2023 18:59:26 - INFO - __main__ - Cumulative validation average loss is 7.737946644076146\n",
      "07/27/2023 18:59:27 - INFO - __main__ - Per validation step average loss is 0.18808802962303162\n",
      "07/27/2023 18:59:27 - INFO - __main__ - Cumulative validation average loss is 7.926034673699178\n",
      "07/27/2023 18:59:27 - INFO - __main__ - Per validation step average loss is 0.24378445744514465\n",
      "07/27/2023 18:59:27 - INFO - __main__ - Cumulative validation average loss is 8.169819131144322\n",
      "07/27/2023 18:59:28 - INFO - __main__ - Per validation step average loss is 0.7062869071960449\n",
      "07/27/2023 18:59:28 - INFO - __main__ - Cumulative validation average loss is 8.876106038340367\n",
      "07/27/2023 18:59:28 - INFO - __main__ - Per validation step average loss is 0.06069481372833252\n",
      "07/27/2023 18:59:28 - INFO - __main__ - Cumulative validation average loss is 8.9368008520687\n",
      "07/27/2023 18:59:29 - INFO - __main__ - Per validation step average loss is 0.1359998881816864\n",
      "07/27/2023 18:59:29 - INFO - __main__ - Cumulative validation average loss is 9.072800740250386\n",
      "07/27/2023 18:59:29 - INFO - __main__ - Per validation step average loss is 0.21476754546165466\n",
      "07/27/2023 18:59:29 - INFO - __main__ - Cumulative validation average loss is 9.287568285712041\n",
      "07/27/2023 18:59:29 - INFO - __main__ - Per validation step average loss is 0.2343822419643402\n",
      "07/27/2023 18:59:29 - INFO - __main__ - Cumulative validation average loss is 9.521950527676381\n",
      "07/27/2023 18:59:30 - INFO - __main__ - Per validation step average loss is 0.0025383150205016136\n",
      "07/27/2023 18:59:30 - INFO - __main__ - Cumulative validation average loss is 9.524488842696883\n",
      "07/27/2023 18:59:30 - INFO - __main__ - Per validation step average loss is 0.018198616802692413\n",
      "07/27/2023 18:59:30 - INFO - __main__ - Cumulative validation average loss is 9.542687459499575\n",
      "07/27/2023 18:59:31 - INFO - __main__ - Per validation step average loss is 0.0021759828086942434\n",
      "07/27/2023 18:59:31 - INFO - __main__ - Cumulative validation average loss is 9.54486344230827\n",
      "07/27/2023 18:59:31 - INFO - __main__ - Per validation step average loss is 0.382797509431839\n",
      "07/27/2023 18:59:31 - INFO - __main__ - Cumulative validation average loss is 9.927660951740108\n",
      "07/27/2023 18:59:32 - INFO - __main__ - Per validation step average loss is 0.010766955092549324\n",
      "07/27/2023 18:59:32 - INFO - __main__ - Cumulative validation average loss is 9.938427906832658\n",
      "07/27/2023 18:59:32 - INFO - __main__ - Per validation step average loss is 0.7232959866523743\n",
      "07/27/2023 18:59:32 - INFO - __main__ - Cumulative validation average loss is 10.661723893485032\n",
      "07/27/2023 18:59:32 - INFO - __main__ - Per validation step average loss is 0.0939379334449768\n",
      "07/27/2023 18:59:32 - INFO - __main__ - Cumulative validation average loss is 10.755661826930009\n",
      "07/27/2023 18:59:33 - INFO - __main__ - Per validation step average loss is 0.008601197972893715\n",
      "07/27/2023 18:59:33 - INFO - __main__ - Cumulative validation average loss is 10.764263024902903\n",
      "07/27/2023 18:59:33 - INFO - __main__ - Per validation step average loss is 0.007975518703460693\n",
      "07/27/2023 18:59:33 - INFO - __main__ - Cumulative validation average loss is 10.772238543606363\n",
      "07/27/2023 18:59:34 - INFO - __main__ - Per validation step average loss is 0.2629407048225403\n",
      "07/27/2023 18:59:34 - INFO - __main__ - Cumulative validation average loss is 11.035179248428904\n",
      "07/27/2023 18:59:34 - INFO - __main__ - Per validation step average loss is 0.05687334015965462\n",
      "07/27/2023 18:59:34 - INFO - __main__ - Cumulative validation average loss is 11.092052588588558\n",
      "07/27/2023 18:59:34 - INFO - __main__ - Average validation loss for Epoch 28 is 0.14040572896947542\n",
      "07/27/2023 18:59:34 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 19:00:31 - INFO - __main__ - Starting epoch 29\n",
      "07/27/2023 19:00:32 - INFO - __main__ - train loss is 0.634487509727478\n",
      "Steps:  59%|▌| 8788/15000 [1:15:42<47:31:23, 27.54s/it, lr=0.000999, step_loss=007/27/2023 19:00:32 - INFO - __main__ - train loss is 0.7679972499608994\n",
      "Steps:  59%|▌| 8789/15000 [1:15:42<33:21:18, 19.33s/it, lr=0.000999, step_loss=007/27/2023 19:00:32 - INFO - __main__ - train loss is 1.101264163851738\n",
      "Steps:  59%|▌| 8790/15000 [1:15:42<23:26:14, 13.59s/it, lr=0.000999, step_loss=007/27/2023 19:00:32 - INFO - __main__ - train loss is 1.1330491527915\n",
      "Steps:  59%|▌| 8791/15000 [1:15:43<16:29:46,  9.56s/it, lr=0.000999, step_loss=007/27/2023 19:00:33 - INFO - __main__ - train loss is 1.1970821097493172\n",
      "Steps:  59%|▌| 8792/15000 [1:15:43<11:38:16,  6.75s/it, lr=0.000999, step_loss=007/27/2023 19:00:33 - INFO - __main__ - train loss is 1.207332756370306\n",
      "Steps:  59%|▌| 8793/15000 [1:15:43<8:14:20,  4.78s/it, lr=0.000999, step_loss=0.07/27/2023 19:00:33 - INFO - __main__ - train loss is 1.2730047442018986\n",
      "Steps:  59%|▌| 8794/15000 [1:15:43<5:51:31,  3.40s/it, lr=0.000999, step_loss=0.07/27/2023 19:00:33 - INFO - __main__ - train loss is 1.6023934222757816\n",
      "Steps:  59%|▌| 8795/15000 [1:15:43<4:11:34,  2.43s/it, lr=0.000999, step_loss=0.07/27/2023 19:00:33 - INFO - __main__ - train loss is 1.6575130745768547\n",
      "Steps:  59%|▌| 8796/15000 [1:15:44<3:01:37,  1.76s/it, lr=0.000999, step_loss=0.07/27/2023 19:00:33 - INFO - __main__ - train loss is 1.6718226931989193\n",
      "Steps:  59%|▌| 8797/15000 [1:15:44<2:12:39,  1.28s/it, lr=0.000999, step_loss=0.07/27/2023 19:00:34 - INFO - __main__ - train loss is 1.6901421323418617\n",
      "Steps:  59%|▌| 8798/15000 [1:15:44<1:38:24,  1.05it/s, lr=0.000999, step_loss=0.07/27/2023 19:00:34 - INFO - __main__ - train loss is 1.6962156649678946\n",
      "Steps:  59%|▌| 8799/15000 [1:15:44<1:14:24,  1.39it/s, lr=0.000999, step_loss=0.07/27/2023 19:00:34 - INFO - __main__ - train loss is 2.1772395726293325\n",
      "Steps:  59%|▌| 8800/15000 [1:15:44<57:37,  1.79it/s, lr=0.000999, step_loss=0.4807/27/2023 19:00:34 - INFO - __main__ - train loss is 2.220756722614169\n",
      "Steps:  59%|▌| 8801/15000 [1:15:44<45:53,  2.25it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:34 - INFO - __main__ - train loss is 2.228192353621125\n",
      "Steps:  59%|▌| 8802/15000 [1:15:45<37:39,  2.74it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:34 - INFO - __main__ - train loss is 2.5320409182459116\n",
      "Steps:  59%|▌| 8803/15000 [1:15:45<31:55,  3.23it/s, lr=0.000999, step_loss=0.3007/27/2023 19:00:35 - INFO - __main__ - train loss is 2.7745143715292215\n",
      "Steps:  59%|▌| 8804/15000 [1:15:45<27:54,  3.70it/s, lr=0.000999, step_loss=0.2407/27/2023 19:00:35 - INFO - __main__ - train loss is 2.778807848226279\n",
      "Steps:  59%|▌| 8805/15000 [1:15:45<25:06,  4.11it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:35 - INFO - __main__ - train loss is 2.8260864946059883\n",
      "Steps:  59%|▌| 8806/15000 [1:15:45<23:07,  4.46it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:35 - INFO - __main__ - train loss is 2.8291726973839104\n",
      "Steps:  59%|▌| 8807/15000 [1:15:46<21:44,  4.75it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:35 - INFO - __main__ - train loss is 2.831311261281371\n",
      "Steps:  59%|▌| 8808/15000 [1:15:46<20:55,  4.93it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:36 - INFO - __main__ - train loss is 2.8344502130057663\n",
      "Steps:  59%|▌| 8809/15000 [1:15:46<20:23,  5.06it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:36 - INFO - __main__ - train loss is 2.866752186557278\n",
      "Steps:  59%|▌| 8810/15000 [1:15:46<19:58,  5.16it/s, lr=0.000999, step_loss=0.0307/27/2023 19:00:36 - INFO - __main__ - train loss is 2.886802581837401\n",
      "Steps:  59%|▌| 8811/15000 [1:15:46<19:39,  5.25it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:36 - INFO - __main__ - train loss is 3.2864385524298996\n",
      "Steps:  59%|▌| 8812/15000 [1:15:46<19:29,  5.29it/s, lr=0.000999, step_loss=0.4]07/27/2023 19:00:36 - INFO - __main__ - train loss is 3.304357969900593\n",
      "Steps:  59%|▌| 8813/15000 [1:15:47<19:30,  5.29it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:37 - INFO - __main__ - train loss is 3.325860181590542\n",
      "Steps:  59%|▌| 8814/15000 [1:15:47<19:20,  5.33it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:37 - INFO - __main__ - train loss is 3.335423629498109\n",
      "Steps:  59%|▌| 8815/15000 [1:15:47<19:06,  5.40it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:37 - INFO - __main__ - train loss is 3.5232179870363325\n",
      "Steps:  59%|▌| 8816/15000 [1:15:47<18:56,  5.44it/s, lr=0.000999, step_loss=0.1807/27/2023 19:00:37 - INFO - __main__ - train loss is 3.5643902157898992\n",
      "Steps:  59%|▌| 8817/15000 [1:15:47<18:49,  5.48it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:37 - INFO - __main__ - train loss is 3.6333275695797056\n",
      "Steps:  59%|▌| 8818/15000 [1:15:48<18:43,  5.50it/s, lr=0.000999, step_loss=0.0607/27/2023 19:00:37 - INFO - __main__ - train loss is 3.883203621720895\n",
      "Steps:  59%|▌| 8819/15000 [1:15:48<18:39,  5.52it/s, lr=0.000999, step_loss=0.2507/27/2023 19:00:38 - INFO - __main__ - train loss is 4.242133911466226\n",
      "Steps:  59%|▌| 8820/15000 [1:15:48<18:36,  5.54it/s, lr=0.000999, step_loss=0.3507/27/2023 19:00:38 - INFO - __main__ - train loss is 4.247117439983413\n",
      "Steps:  59%|▌| 8821/15000 [1:15:48<18:33,  5.55it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:38 - INFO - __main__ - train loss is 4.496665472863242\n",
      "Steps:  59%|▌| 8822/15000 [1:15:48<18:32,  5.55it/s, lr=0.000999, step_loss=0.2507/27/2023 19:00:38 - INFO - __main__ - train loss is 4.686873639700934\n",
      "Steps:  59%|▌| 8823/15000 [1:15:48<18:31,  5.56it/s, lr=0.000999, step_loss=0.1907/27/2023 19:00:38 - INFO - __main__ - train loss is 5.070643360493705\n",
      "Steps:  59%|▌| 8824/15000 [1:15:49<18:31,  5.56it/s, lr=0.000999, step_loss=0.3807/27/2023 19:00:38 - INFO - __main__ - train loss is 5.073005395242944\n",
      "Steps:  59%|▌| 8825/15000 [1:15:49<18:30,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:39 - INFO - __main__ - train loss is 5.0775950870011\n",
      "Steps:  59%|▌| 8826/15000 [1:15:49<18:29,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:39 - INFO - __main__ - train loss is 5.081048745894805\n",
      "Steps:  59%|▌| 8827/15000 [1:15:49<18:29,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:39 - INFO - __main__ - train loss is 5.085923037724569\n",
      "Steps:  59%|▌| 8828/15000 [1:15:49<18:28,  5.57it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:39 - INFO - __main__ - train loss is 5.150739900069311\n",
      "Steps:  59%|▌| 8829/15000 [1:15:50<18:28,  5.57it/s, lr=0.000999, step_loss=0.0607/27/2023 19:00:39 - INFO - __main__ - train loss is 5.198540426092222\n",
      "Steps:  59%|▌| 8830/15000 [1:15:50<18:28,  5.56it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:40 - INFO - __main__ - train loss is 5.348894304828718\n",
      "Steps:  59%|▌| 8831/15000 [1:15:50<18:28,  5.56it/s, lr=0.000999, step_loss=0.1507/27/2023 19:00:40 - INFO - __main__ - train loss is 5.411483898060396\n",
      "Steps:  59%|▌| 8832/15000 [1:15:50<18:28,  5.57it/s, lr=0.000999, step_loss=0.0607/27/2023 19:00:40 - INFO - __main__ - train loss is 5.554866626160219\n",
      "Steps:  59%|▌| 8833/15000 [1:15:50<18:27,  5.57it/s, lr=0.000999, step_loss=0.1407/27/2023 19:00:40 - INFO - __main__ - train loss is 5.721472590463236\n",
      "Steps:  59%|▌| 8834/15000 [1:15:50<18:27,  5.57it/s, lr=0.000999, step_loss=0.1607/27/2023 19:00:40 - INFO - __main__ - train loss is 6.046744673745707\n",
      "Steps:  59%|▌| 8835/15000 [1:15:51<18:27,  5.57it/s, lr=0.000999, step_loss=0.3207/27/2023 19:00:40 - INFO - __main__ - train loss is 6.196789249079302\n",
      "Steps:  59%|▌| 8836/15000 [1:15:51<18:27,  5.57it/s, lr=0.000999, step_loss=0.1507/27/2023 19:00:41 - INFO - __main__ - train loss is 6.314396872418001\n",
      "Steps:  59%|▌| 8837/15000 [1:15:51<18:27,  5.57it/s, lr=0.000999, step_loss=0.1107/27/2023 19:00:41 - INFO - __main__ - train loss is 6.593208416597918\n",
      "Steps:  59%|▌| 8838/15000 [1:15:51<18:36,  5.52it/s, lr=0.000999, step_loss=0.2707/27/2023 19:00:41 - INFO - __main__ - train loss is 6.692465662257746\n",
      "Steps:  59%|▌| 8839/15000 [1:15:51<18:44,  5.48it/s, lr=0.000999, step_loss=0.0907/27/2023 19:00:41 - INFO - __main__ - train loss is 6.703436116920784\n",
      "Steps:  59%|▌| 8840/15000 [1:15:51<18:39,  5.50it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:41 - INFO - __main__ - train loss is 7.104252915130928\n",
      "Steps:  59%|▌| 8841/15000 [1:15:52<18:36,  5.52it/s, lr=0.000999, step_loss=0.4007/27/2023 19:00:42 - INFO - __main__ - train loss is 7.360817472683266\n",
      "Steps:  59%|▌| 8842/15000 [1:15:52<18:33,  5.53it/s, lr=0.000999, step_loss=0.2507/27/2023 19:00:42 - INFO - __main__ - train loss is 7.369493092643097\n",
      "Steps:  59%|▌| 8843/15000 [1:15:52<18:42,  5.48it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:42 - INFO - __main__ - train loss is 7.3891802795697\n",
      "Steps:  59%|▌| 8844/15000 [1:15:52<18:51,  5.44it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:42 - INFO - __main__ - train loss is 7.795244372682646\n",
      "Steps:  59%|▌| 8845/15000 [1:15:52<18:47,  5.46it/s, lr=0.000999, step_loss=0.4007/27/2023 19:00:42 - INFO - __main__ - train loss is 7.969359404640272\n",
      "Steps:  59%|▌| 8846/15000 [1:15:53<18:51,  5.44it/s, lr=0.000999, step_loss=0.1707/27/2023 19:00:42 - INFO - __main__ - train loss is 8.06169620831497\n",
      "Steps:  59%|▌| 8847/15000 [1:15:53<18:56,  5.42it/s, lr=0.000999, step_loss=0.0907/27/2023 19:00:43 - INFO - __main__ - train loss is 8.597370303468779\n",
      "Steps:  59%|▌| 8848/15000 [1:15:53<18:46,  5.46it/s, lr=0.000999, step_loss=0.5307/27/2023 19:00:43 - INFO - __main__ - train loss is 8.899747944669798\n",
      "Steps:  59%|▌| 8849/15000 [1:15:53<18:48,  5.45it/s, lr=0.000999, step_loss=0.3007/27/2023 19:00:43 - INFO - __main__ - train loss is 8.907775695668533\n",
      "Steps:  59%|▌| 8850/15000 [1:15:53<18:51,  5.44it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:43 - INFO - __main__ - train loss is 8.913721304619685\n",
      "Steps:  59%|▌| 8851/15000 [1:15:54<18:47,  5.46it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:43 - INFO - __main__ - train loss is 9.017952885711566\n",
      "Steps:  59%|▌| 8852/15000 [1:15:54<18:50,  5.44it/s, lr=0.000999, step_loss=0.1007/27/2023 19:00:44 - INFO - __main__ - train loss is 9.0492425004486\n",
      "Steps:  59%|▌| 8853/15000 [1:15:54<18:46,  5.46it/s, lr=0.000999, step_loss=0.0307/27/2023 19:00:44 - INFO - __main__ - train loss is 9.281235072994605\n",
      "Steps:  59%|▌| 8854/15000 [1:15:54<18:39,  5.49it/s, lr=0.000999, step_loss=0.2307/27/2023 19:00:44 - INFO - __main__ - train loss is 9.284942309372127\n",
      "Steps:  59%|▌| 8855/15000 [1:15:54<18:35,  5.51it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:44 - INFO - __main__ - train loss is 9.311201578937471\n",
      "Steps:  59%|▌| 8856/15000 [1:15:54<18:31,  5.53it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:44 - INFO - __main__ - train loss is 9.601053244434297\n",
      "Steps:  59%|▌| 8857/15000 [1:15:55<18:28,  5.54it/s, lr=0.000999, step_loss=0.2907/27/2023 19:00:44 - INFO - __main__ - train loss is 9.974947935901582\n",
      "Steps:  59%|▌| 8858/15000 [1:15:55<18:27,  5.55it/s, lr=0.000999, step_loss=0.3707/27/2023 19:00:45 - INFO - __main__ - train loss is 10.212979367934167\n",
      "Steps:  59%|▌| 8859/15000 [1:15:55<18:36,  5.50it/s, lr=0.000999, step_loss=0.2307/27/2023 19:00:45 - INFO - __main__ - train loss is 10.21469729556702\n",
      "Steps:  59%|▌| 8860/15000 [1:15:55<18:31,  5.52it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:45 - INFO - __main__ - train loss is 10.283320853253826\n",
      "Steps:  59%|▌| 8861/15000 [1:15:55<18:39,  5.48it/s, lr=0.000999, step_loss=0.0607/27/2023 19:00:45 - INFO - __main__ - train loss is 10.496833571931347\n",
      "Steps:  59%|▌| 8862/15000 [1:15:56<18:48,  5.44it/s, lr=0.000999, step_loss=0.2107/27/2023 19:00:45 - INFO - __main__ - train loss is 11.188053438207135\n",
      "Steps:  59%|▌| 8863/15000 [1:15:56<18:43,  5.46it/s, lr=0.000999, step_loss=0.6907/27/2023 19:00:46 - INFO - __main__ - train loss is 11.203277198364958\n",
      "Steps:  59%|▌| 8864/15000 [1:15:56<18:36,  5.50it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:46 - INFO - __main__ - train loss is 11.430382845690474\n",
      "Steps:  59%|▌| 8865/15000 [1:15:56<18:37,  5.49it/s, lr=0.000999, step_loss=0.2207/27/2023 19:00:46 - INFO - __main__ - train loss is 11.440575381508097\n",
      "Steps:  59%|▌| 8866/15000 [1:15:56<18:43,  5.46it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:46 - INFO - __main__ - train loss is 11.468578923260793\n",
      "Steps:  59%|▌| 8867/15000 [1:15:56<18:46,  5.44it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:46 - INFO - __main__ - train loss is 11.543385538971052\n",
      "Steps:  59%|▌| 8868/15000 [1:15:57<18:38,  5.48it/s, lr=0.000999, step_loss=0.0707/27/2023 19:00:46 - INFO - __main__ - train loss is 11.668491784250364\n",
      "Steps:  59%|▌| 8869/15000 [1:15:57<18:34,  5.50it/s, lr=0.000999, step_loss=0.1207/27/2023 19:00:47 - INFO - __main__ - train loss is 11.889995340025052\n",
      "Steps:  59%|▌| 8870/15000 [1:15:57<18:30,  5.52it/s, lr=0.000999, step_loss=0.2207/27/2023 19:00:47 - INFO - __main__ - train loss is 12.040774095570669\n",
      "Steps:  59%|▌| 8871/15000 [1:15:57<18:28,  5.53it/s, lr=0.000999, step_loss=0.1507/27/2023 19:00:47 - INFO - __main__ - train loss is 12.542360294377431\n",
      "Steps:  59%|▌| 8872/15000 [1:15:57<18:26,  5.54it/s, lr=0.000999, step_loss=0.5007/27/2023 19:00:47 - INFO - __main__ - train loss is 12.583513110643253\n",
      "Steps:  59%|▌| 8873/15000 [1:15:58<18:25,  5.54it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:47 - INFO - __main__ - train loss is 12.59105212497525\n",
      "Steps:  59%|▌| 8874/15000 [1:15:58<18:24,  5.55it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:48 - INFO - __main__ - train loss is 12.698783266125247\n",
      "Steps:  59%|▌| 8875/15000 [1:15:58<18:23,  5.55it/s, lr=0.000999, step_loss=0.1007/27/2023 19:00:48 - INFO - __main__ - train loss is 12.844043212709948\n",
      "Steps:  59%|▌| 8876/15000 [1:15:58<18:22,  5.56it/s, lr=0.000999, step_loss=0.1407/27/2023 19:00:48 - INFO - __main__ - train loss is 13.103583293734118\n",
      "Steps:  59%|▌| 8877/15000 [1:15:58<18:21,  5.56it/s, lr=0.000999, step_loss=0.2607/27/2023 19:00:48 - INFO - __main__ - train loss is 13.824183779535815\n",
      "Steps:  59%|▌| 8878/15000 [1:15:58<18:20,  5.56it/s, lr=0.000999, step_loss=0.7207/27/2023 19:00:48 - INFO - __main__ - train loss is 13.905108864186332\n",
      "Steps:  59%|▌| 8879/15000 [1:15:59<18:20,  5.56it/s, lr=0.000999, step_loss=0.0807/27/2023 19:00:48 - INFO - __main__ - train loss is 13.906446271343157\n",
      "Steps:  59%|▌| 8880/15000 [1:15:59<18:19,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:49 - INFO - __main__ - train loss is 13.93532929639332\n",
      "Steps:  59%|▌| 8881/15000 [1:15:59<18:20,  5.56it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:49 - INFO - __main__ - train loss is 13.961642504436895\n",
      "Steps:  59%|▌| 8882/15000 [1:15:59<18:20,  5.56it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:49 - INFO - __main__ - train loss is 14.051732749445364\n",
      "Steps:  59%|▌| 8883/15000 [1:15:59<18:21,  5.55it/s, lr=0.000999, step_loss=0.0907/27/2023 19:00:49 - INFO - __main__ - train loss is 14.088049926562235\n",
      "Steps:  59%|▌| 8884/15000 [1:15:59<18:19,  5.56it/s, lr=0.000999, step_loss=0.0307/27/2023 19:00:49 - INFO - __main__ - train loss is 14.2368484667968\n",
      "Steps:  59%|▌| 8885/15000 [1:16:00<18:19,  5.56it/s, lr=0.000999, step_loss=0.1407/27/2023 19:00:50 - INFO - __main__ - train loss is 14.338618487818167\n",
      "Steps:  59%|▌| 8886/15000 [1:16:00<18:29,  5.51it/s, lr=0.000999, step_loss=0.1007/27/2023 19:00:50 - INFO - __main__ - train loss is 14.341241549700499\n",
      "Steps:  59%|▌| 8887/15000 [1:16:00<18:25,  5.53it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:50 - INFO - __main__ - train loss is 14.560543935745955\n",
      "Steps:  59%|▌| 8888/15000 [1:16:00<18:23,  5.54it/s, lr=0.000999, step_loss=0.2107/27/2023 19:00:50 - INFO - __main__ - train loss is 14.573006376624107\n",
      "Steps:  59%|▌| 8889/15000 [1:16:00<18:21,  5.55it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:50 - INFO - __main__ - train loss is 14.57410706486553\n",
      "Steps:  59%|▌| 8890/15000 [1:16:01<18:19,  5.55it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:50 - INFO - __main__ - train loss is 14.630429889075458\n",
      "Steps:  59%|▌| 8891/15000 [1:16:01<18:18,  5.56it/s, lr=0.000999, step_loss=0.0507/27/2023 19:00:51 - INFO - __main__ - train loss is 14.972063208930194\n",
      "Steps:  59%|▌| 8892/15000 [1:16:01<18:18,  5.56it/s, lr=0.000999, step_loss=0.3407/27/2023 19:00:51 - INFO - __main__ - train loss is 15.104684422723949\n",
      "Steps:  59%|▌| 8893/15000 [1:16:01<18:17,  5.56it/s, lr=0.000999, step_loss=0.1307/27/2023 19:00:51 - INFO - __main__ - train loss is 15.404996554367244\n",
      "Steps:  59%|▌| 8894/15000 [1:16:01<18:17,  5.56it/s, lr=0.000999, step_loss=0.3]07/27/2023 19:00:51 - INFO - __main__ - train loss is 15.484567801468074\n",
      "Steps:  59%|▌| 8895/15000 [1:16:01<18:17,  5.56it/s, lr=0.000999, step_loss=0.0707/27/2023 19:00:51 - INFO - __main__ - train loss is 15.569996024481952\n",
      "Steps:  59%|▌| 8896/15000 [1:16:02<18:16,  5.57it/s, lr=0.000999, step_loss=0.0807/27/2023 19:00:52 - INFO - __main__ - train loss is 15.594185371883214\n",
      "Steps:  59%|▌| 8897/15000 [1:16:02<18:16,  5.56it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:52 - INFO - __main__ - train loss is 15.775112678296864\n",
      "Steps:  59%|▌| 8898/15000 [1:16:02<18:17,  5.56it/s, lr=0.000999, step_loss=0.1807/27/2023 19:00:52 - INFO - __main__ - train loss is 15.884793144650757\n",
      "Steps:  59%|▌| 8899/15000 [1:16:02<18:17,  5.56it/s, lr=0.000999, step_loss=0.1107/27/2023 19:00:52 - INFO - __main__ - train loss is 15.94057494122535\n",
      "Steps:  59%|▌| 8900/15000 [1:16:02<18:17,  5.56it/s, lr=0.000999, step_loss=0.0507/27/2023 19:00:52 - INFO - __main__ - train loss is 16.2484171660617\n",
      "Steps:  59%|▌| 8901/15000 [1:16:03<18:17,  5.56it/s, lr=0.000999, step_loss=0.3007/27/2023 19:00:52 - INFO - __main__ - train loss is 16.89645924884826\n",
      "Steps:  59%|▌| 8902/15000 [1:16:03<18:17,  5.56it/s, lr=0.000999, step_loss=0.6407/27/2023 19:00:53 - INFO - __main__ - train loss is 16.963299815542996\n",
      "Steps:  59%|▌| 8903/15000 [1:16:03<18:16,  5.56it/s, lr=0.000999, step_loss=0.0607/27/2023 19:00:53 - INFO - __main__ - train loss is 16.991871529258788\n",
      "Steps:  59%|▌| 8904/15000 [1:16:03<18:16,  5.56it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:53 - INFO - __main__ - train loss is 17.031223290599883\n",
      "Steps:  59%|▌| 8905/15000 [1:16:03<18:17,  5.56it/s, lr=0.000999, step_loss=0.0307/27/2023 19:00:53 - INFO - __main__ - train loss is 17.032716567162424\n",
      "Steps:  59%|▌| 8906/15000 [1:16:03<18:16,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:53 - INFO - __main__ - train loss is 17.042524136137217\n",
      "Steps:  59%|▌| 8907/15000 [1:16:04<18:27,  5.50it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:54 - INFO - __main__ - train loss is 17.16629197401926\n",
      "Steps:  59%|▌| 8908/15000 [1:16:04<18:26,  5.50it/s, lr=0.000999, step_loss=0.1207/27/2023 19:00:54 - INFO - __main__ - train loss is 17.359646670054644\n",
      "Steps:  59%|▌| 8909/15000 [1:16:04<18:22,  5.52it/s, lr=0.000999, step_loss=0.1907/27/2023 19:00:54 - INFO - __main__ - train loss is 17.476925663184375\n",
      "Steps:  59%|▌| 8910/15000 [1:16:04<18:19,  5.54it/s, lr=0.000999, step_loss=0.1107/27/2023 19:00:54 - INFO - __main__ - train loss is 17.70592615706846\n",
      "Steps:  59%|▌| 8911/15000 [1:16:04<18:27,  5.50it/s, lr=0.000999, step_loss=0.2207/27/2023 19:00:54 - INFO - __main__ - train loss is 17.71036272449419\n",
      "Steps:  59%|▌| 8912/15000 [1:16:05<18:28,  5.49it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:54 - INFO - __main__ - train loss is 17.811170152854174\n",
      "Steps:  59%|▌| 8913/15000 [1:16:05<18:23,  5.52it/s, lr=0.000999, step_loss=0.1007/27/2023 19:00:55 - INFO - __main__ - train loss is 17.82754525868222\n",
      "Steps:  59%|▌| 8914/15000 [1:16:05<18:20,  5.53it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:55 - INFO - __main__ - train loss is 17.88776798127219\n",
      "Steps:  59%|▌| 8915/15000 [1:16:05<18:17,  5.54it/s, lr=0.000999, step_loss=0.0607/27/2023 19:00:55 - INFO - __main__ - train loss is 17.963634740095586\n",
      "Steps:  59%|▌| 8916/15000 [1:16:05<18:16,  5.55it/s, lr=0.000999, step_loss=0.0707/27/2023 19:00:55 - INFO - __main__ - train loss is 18.11573625681922\n",
      "Steps:  59%|▌| 8917/15000 [1:16:05<18:15,  5.55it/s, lr=0.000999, step_loss=0.1507/27/2023 19:00:55 - INFO - __main__ - train loss is 18.14774526981637\n",
      "Steps:  59%|▌| 8918/15000 [1:16:06<18:13,  5.56it/s, lr=0.000999, step_loss=0.0307/27/2023 19:00:55 - INFO - __main__ - train loss is 18.220442581456155\n",
      "Steps:  59%|▌| 8919/15000 [1:16:06<18:12,  5.56it/s, lr=0.000999, step_loss=0.0707/27/2023 19:00:56 - INFO - __main__ - train loss is 18.260682690422982\n",
      "Steps:  59%|▌| 8920/15000 [1:16:06<18:14,  5.55it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:56 - INFO - __main__ - train loss is 18.307722400408238\n",
      "Steps:  59%|▌| 8921/15000 [1:16:06<18:13,  5.56it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:56 - INFO - __main__ - train loss is 18.934643934946507\n",
      "Steps:  59%|▌| 8922/15000 [1:16:06<18:22,  5.51it/s, lr=0.000999, step_loss=0.6207/27/2023 19:00:56 - INFO - __main__ - train loss is 19.07165117142722\n",
      "Steps:  59%|▌| 8923/15000 [1:16:07<18:30,  5.47it/s, lr=0.000999, step_loss=0.1307/27/2023 19:00:56 - INFO - __main__ - train loss is 19.082353963982314\n",
      "Steps:  59%|▌| 8924/15000 [1:16:07<18:36,  5.44it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:57 - INFO - __main__ - train loss is 19.083689021179453\n",
      "Steps:  60%|▌| 8925/15000 [1:16:07<18:41,  5.42it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:57 - INFO - __main__ - train loss is 19.13001045049168\n",
      "Steps:  60%|▌| 8926/15000 [1:16:07<18:32,  5.46it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:57 - INFO - __main__ - train loss is 19.132024514954537\n",
      "Steps:  60%|▌| 8927/15000 [1:16:07<18:26,  5.49it/s, lr=0.000999, step_loss=0.0007/27/2023 19:00:57 - INFO - __main__ - train loss is 19.176957480143756\n",
      "Steps:  60%|▌| 8928/15000 [1:16:07<18:22,  5.51it/s, lr=0.000999, step_loss=0.0407/27/2023 19:00:57 - INFO - __main__ - train loss is 19.35416706604883\n",
      "Steps:  60%|▌| 8929/15000 [1:16:08<18:19,  5.52it/s, lr=0.000999, step_loss=0.1707/27/2023 19:00:57 - INFO - __main__ - train loss is 19.36605654237792\n",
      "Steps:  60%|▌| 8930/15000 [1:16:08<18:16,  5.54it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:58 - INFO - __main__ - train loss is 19.45000660000369\n",
      "Steps:  60%|▌| 8931/15000 [1:16:08<18:13,  5.55it/s, lr=0.000999, step_loss=0.0807/27/2023 19:00:58 - INFO - __main__ - train loss is 19.732656832318753\n",
      "Steps:  60%|▌| 8932/15000 [1:16:08<18:12,  5.56it/s, lr=0.000999, step_loss=0.2807/27/2023 19:00:58 - INFO - __main__ - train loss is 19.809224735479802\n",
      "Steps:  60%|▌| 8933/15000 [1:16:08<18:11,  5.56it/s, lr=0.000999, step_loss=0.0707/27/2023 19:00:58 - INFO - __main__ - train loss is 20.032288040500134\n",
      "Steps:  60%|▌| 8934/15000 [1:16:09<18:11,  5.56it/s, lr=0.000999, step_loss=0.2207/27/2023 19:00:58 - INFO - __main__ - train loss is 20.352479006629437\n",
      "Steps:  60%|▌| 8935/15000 [1:16:09<18:11,  5.56it/s, lr=0.000999, step_loss=0.3207/27/2023 19:00:59 - INFO - __main__ - train loss is 20.50642717955634\n",
      "Steps:  60%|▌| 8936/15000 [1:16:09<18:10,  5.56it/s, lr=0.000999, step_loss=0.1507/27/2023 19:00:59 - INFO - __main__ - train loss is 20.521407790016383\n",
      "Steps:  60%|▌| 8937/15000 [1:16:09<18:10,  5.56it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:59 - INFO - __main__ - train loss is 20.547263100277632\n",
      "Steps:  60%|▌| 8938/15000 [1:16:09<18:20,  5.51it/s, lr=0.000999, step_loss=0.0207/27/2023 19:00:59 - INFO - __main__ - train loss is 20.562863206025213\n",
      "Steps:  60%|▌| 8939/15000 [1:16:09<18:27,  5.47it/s, lr=0.000999, step_loss=0.0107/27/2023 19:00:59 - INFO - __main__ - train loss is 21.32468399917707\n",
      "Steps:  60%|▌| 8940/15000 [1:16:10<18:35,  5.43it/s, lr=0.000999, step_loss=0.7607/27/2023 19:00:59 - INFO - __main__ - train loss is 21.592926328536123\n",
      "Steps:  60%|▌| 8941/15000 [1:16:10<18:27,  5.47it/s, lr=0.000999, step_loss=0.2607/27/2023 19:01:00 - INFO - __main__ - train loss is 21.937794571276754\n",
      "Steps:  60%|▌| 8942/15000 [1:16:10<18:21,  5.50it/s, lr=0.000999, step_loss=0.3407/27/2023 19:01:00 - INFO - __main__ - train loss is 22.145761673804373\n",
      "Steps:  60%|▌| 8943/15000 [1:16:10<18:27,  5.47it/s, lr=0.000999, step_loss=0.2007/27/2023 19:01:00 - INFO - __main__ - train loss is 22.47832373296842\n",
      "Steps:  60%|▌| 8944/15000 [1:16:10<18:28,  5.46it/s, lr=0.000999, step_loss=0.3307/27/2023 19:01:00 - INFO - __main__ - train loss is 22.51050586393103\n",
      "Steps:  60%|▌| 8945/15000 [1:16:11<18:31,  5.45it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:00 - INFO - __main__ - train loss is 22.516499855089933\n",
      "Steps:  60%|▌| 8946/15000 [1:16:11<18:29,  5.46it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:01 - INFO - __main__ - train loss is 22.64039368974045\n",
      "Steps:  60%|▌| 8947/15000 [1:16:11<18:30,  5.45it/s, lr=0.000999, step_loss=0.1207/27/2023 19:01:01 - INFO - __main__ - train loss is 22.743475579191\n",
      "Steps:  60%|▌| 8948/15000 [1:16:11<18:33,  5.44it/s, lr=0.000999, step_loss=0.1007/27/2023 19:01:01 - INFO - __main__ - train loss is 22.78434128733352\n",
      "Steps:  60%|▌| 8949/15000 [1:16:11<18:33,  5.43it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:01 - INFO - __main__ - train loss is 22.79485080530867\n",
      "Steps:  60%|▌| 8950/15000 [1:16:11<18:25,  5.47it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:01 - INFO - __main__ - train loss is 22.796433398732916\n",
      "Steps:  60%|▌| 8951/15000 [1:16:12<18:27,  5.46it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:02 - INFO - __main__ - train loss is 22.846734492341056\n",
      "Steps:  60%|▌| 8952/15000 [1:16:12<18:29,  5.45it/s, lr=0.000999, step_loss=0.0507/27/2023 19:01:02 - INFO - __main__ - train loss is 22.860194654436782\n",
      "Steps:  60%|▌| 8953/15000 [1:16:12<18:32,  5.44it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:02 - INFO - __main__ - train loss is 22.86196005693637\n",
      "Steps:  60%|▌| 8954/15000 [1:16:12<18:31,  5.44it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:02 - INFO - __main__ - train loss is 22.92603736720048\n",
      "Steps:  60%|▌| 8955/15000 [1:16:12<18:24,  5.47it/s, lr=0.000999, step_loss=0.0607/27/2023 19:01:02 - INFO - __main__ - train loss is 22.9994448160287\n",
      "Steps:  60%|▌| 8956/15000 [1:16:13<18:18,  5.50it/s, lr=0.000999, step_loss=0.0707/27/2023 19:01:02 - INFO - __main__ - train loss is 23.82259950391017\n",
      "Steps:  60%|▌| 8957/15000 [1:16:13<18:15,  5.52it/s, lr=0.000999, step_loss=0.8207/27/2023 19:01:03 - INFO - __main__ - train loss is 23.83403959660791\n",
      "Steps:  60%|▌| 8958/15000 [1:16:13<18:15,  5.52it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:03 - INFO - __main__ - train loss is 23.84267489775084\n",
      "Steps:  60%|▌| 8959/15000 [1:16:13<18:11,  5.53it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:03 - INFO - __main__ - train loss is 23.85562754399143\n",
      "Steps:  60%|▌| 8960/15000 [1:16:13<18:09,  5.54it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:03 - INFO - __main__ - train loss is 24.559805638855323\n",
      "Steps:  60%|▌| 8961/15000 [1:16:13<18:07,  5.55it/s, lr=0.000999, step_loss=0.7007/27/2023 19:01:03 - INFO - __main__ - train loss is 24.654558911686763\n",
      "Steps:  60%|▌| 8962/15000 [1:16:14<18:06,  5.56it/s, lr=0.000999, step_loss=0.0907/27/2023 19:01:03 - INFO - __main__ - train loss is 24.742173433071002\n",
      "Steps:  60%|▌| 8963/15000 [1:16:14<18:06,  5.56it/s, lr=0.000999, step_loss=0.0807/27/2023 19:01:04 - INFO - __main__ - train loss is 24.7985891175922\n",
      "Steps:  60%|▌| 8964/15000 [1:16:14<18:05,  5.56it/s, lr=0.000999, step_loss=0.0507/27/2023 19:01:04 - INFO - __main__ - train loss is 24.826989143854007\n",
      "Steps:  60%|▌| 8965/15000 [1:16:14<18:05,  5.56it/s, lr=0.000999, step_loss=0.0207/27/2023 19:01:04 - INFO - __main__ - train loss is 24.828788603073917\n",
      "Steps:  60%|▌| 8966/15000 [1:16:14<18:05,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:04 - INFO - __main__ - train loss is 24.928463319665752\n",
      "Steps:  60%|▌| 8967/15000 [1:16:15<18:05,  5.56it/s, lr=0.000999, step_loss=0.0907/27/2023 19:01:04 - INFO - __main__ - train loss is 24.970830725855194\n",
      "Steps:  60%|▌| 8968/15000 [1:16:15<18:04,  5.56it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:05 - INFO - __main__ - train loss is 24.972833212348633\n",
      "Steps:  60%|▌| 8969/15000 [1:16:15<18:04,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:05 - INFO - __main__ - train loss is 25.048401031526737\n",
      "Steps:  60%|▌| 8970/15000 [1:16:15<18:03,  5.57it/s, lr=0.000999, step_loss=0.0707/27/2023 19:01:05 - INFO - __main__ - train loss is 25.09389659378212\n",
      "Steps:  60%|▌| 8971/15000 [1:16:15<18:03,  5.57it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:05 - INFO - __main__ - train loss is 25.135222699376754\n",
      "Steps:  60%|▌| 8972/15000 [1:16:15<18:02,  5.57it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:05 - INFO - __main__ - train loss is 25.138420907664113\n",
      "Steps:  60%|▌| 8973/15000 [1:16:16<21:30,  4.67it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:06 - INFO - __main__ - train loss is 25.140738967689686\n",
      "Steps:  60%|▌| 8974/15000 [1:16:16<23:15,  4.32it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:06 - INFO - __main__ - train loss is 25.18765158194583\n",
      "Steps:  60%|▌| 8975/15000 [1:16:16<22:55,  4.38it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:06 - INFO - __main__ - train loss is 25.422344528022222\n",
      "Steps:  60%|▌| 8976/15000 [1:16:16<21:55,  4.58it/s, lr=0.000999, step_loss=0.2307/27/2023 19:01:06 - INFO - __main__ - train loss is 25.45317984360736\n",
      "Steps:  60%|▌| 8977/15000 [1:16:17<20:48,  4.83it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:06 - INFO - __main__ - train loss is 25.852530218544416\n",
      "Steps:  60%|▌| 8978/15000 [1:16:17<20:04,  5.00it/s, lr=0.000999, step_loss=0.3907/27/2023 19:01:07 - INFO - __main__ - train loss is 26.134694374981336\n",
      "Steps:  60%|▌| 8979/15000 [1:16:17<19:27,  5.16it/s, lr=0.000999, step_loss=0.2807/27/2023 19:01:07 - INFO - __main__ - train loss is 26.2065693809418\n",
      "Steps:  60%|▌| 8980/15000 [1:16:17<19:01,  5.27it/s, lr=0.000999, step_loss=0.0707/27/2023 19:01:07 - INFO - __main__ - train loss is 26.217224446008913\n",
      "Steps:  60%|▌| 8981/15000 [1:16:17<18:45,  5.35it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:07 - INFO - __main__ - train loss is 26.335396130452864\n",
      "Steps:  60%|▌| 8982/15000 [1:16:17<18:31,  5.42it/s, lr=0.000999, step_loss=0.1107/27/2023 19:01:07 - INFO - __main__ - train loss is 26.40336467779707\n",
      "Steps:  60%|▌| 8983/15000 [1:16:18<18:21,  5.46it/s, lr=0.000999, step_loss=0.0607/27/2023 19:01:08 - INFO - __main__ - train loss is 26.405205580289476\n",
      "Steps:  60%|▌| 8984/15000 [1:16:18<18:14,  5.50it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:08 - INFO - __main__ - train loss is 26.47114045440685\n",
      "Steps:  60%|▌| 8985/15000 [1:16:18<18:09,  5.52it/s, lr=0.000999, step_loss=0.0607/27/2023 19:01:08 - INFO - __main__ - train loss is 26.477072959183715\n",
      "Steps:  60%|▌| 8986/15000 [1:16:18<18:06,  5.53it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:08 - INFO - __main__ - train loss is 26.478506023879163\n",
      "Steps:  60%|▌| 8987/15000 [1:16:18<18:05,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:08 - INFO - __main__ - train loss is 26.60773577808868\n",
      "Steps:  60%|▌| 8988/15000 [1:16:19<18:03,  5.55it/s, lr=0.000999, step_loss=0.1207/27/2023 19:01:08 - INFO - __main__ - train loss is 26.638983177836053\n",
      "Steps:  60%|▌| 8989/15000 [1:16:19<18:02,  5.55it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:09 - INFO - __main__ - train loss is 26.65277722745668\n",
      "Steps:  60%|▌| 8990/15000 [1:16:19<18:01,  5.56it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:09 - INFO - __main__ - train loss is 27.062967601115815\n",
      "Steps:  60%|▌| 8991/15000 [1:16:19<18:02,  5.55it/s, lr=0.000999, step_loss=0.4107/27/2023 19:01:09 - INFO - __main__ - train loss is 27.371392729575746\n",
      "Steps:  60%|▌| 8992/15000 [1:16:19<18:01,  5.56it/s, lr=0.000999, step_loss=0.3007/27/2023 19:01:09 - INFO - __main__ - train loss is 27.374686562106945\n",
      "Steps:  60%|▌| 8993/15000 [1:16:19<18:00,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:09 - INFO - __main__ - train loss is 27.41228690801654\n",
      "Steps:  60%|▌| 8994/15000 [1:16:20<18:00,  5.56it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:10 - INFO - __main__ - train loss is 27.506817438290454\n",
      "Steps:  60%|▌| 8995/15000 [1:16:20<18:00,  5.56it/s, lr=0.000999, step_loss=0.0907/27/2023 19:01:10 - INFO - __main__ - train loss is 27.561828114674427\n",
      "Steps:  60%|▌| 8996/15000 [1:16:20<17:59,  5.56it/s, lr=0.000999, step_loss=0.0507/27/2023 19:01:10 - INFO - __main__ - train loss is 27.673910894081928\n",
      "Steps:  60%|▌| 8997/15000 [1:16:20<17:59,  5.56it/s, lr=0.000999, step_loss=0.1107/27/2023 19:01:10 - INFO - __main__ - train loss is 27.698334906832315\n",
      "Steps:  60%|▌| 8998/15000 [1:16:20<17:58,  5.56it/s, lr=0.000999, step_loss=0.0207/27/2023 19:01:10 - INFO - __main__ - train loss is 27.826143924728967\n",
      "Steps:  60%|▌| 8999/15000 [1:16:21<17:58,  5.56it/s, lr=0.000999, step_loss=0.1207/27/2023 19:01:10 - INFO - __main__ - train loss is 27.96983418299351\n",
      "Steps:  60%|▌| 9000/15000 [1:16:21<18:08,  5.51it/s, lr=0.000999, step_loss=0.1207/27/2023 19:01:11 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-9000\n",
      "07/27/2023 19:01:11 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:01:11,008] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:01:11,013] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-9000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:01:11,014] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-9000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:01:11,020] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-9000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:01:11,021] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-9000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:01:11,027] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-9000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:01:11,027] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-9000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:01:11,027] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:01:11 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-9000/pytorch_model\n",
      "07/27/2023 19:01:11 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-9000/scheduler.bin\n",
      "07/27/2023 19:01:11 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-9000/random_states_0.pkl\n",
      "07/27/2023 19:01:11 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-9000\n",
      "Steps:  60%|▌| 9000/15000 [1:16:21<18:08,  5.51it/s, lr=0.000999, step_loss=0.1407/27/2023 19:01:11 - INFO - __main__ - train loss is 28.058219072059728\n",
      "Steps:  60%|▌| 9001/15000 [1:16:21<18:43,  5.34it/s, lr=0.000999, step_loss=0.0807/27/2023 19:01:11 - INFO - __main__ - train loss is 28.291528475121595\n",
      "Steps:  60%|▌| 9002/15000 [1:16:21<18:39,  5.36it/s, lr=0.000999, step_loss=0.2307/27/2023 19:01:11 - INFO - __main__ - train loss is 28.293187653413042\n",
      "Steps:  60%|▌| 9003/15000 [1:16:21<18:29,  5.40it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:11 - INFO - __main__ - train loss is 28.302055909996852\n",
      "Steps:  60%|▌| 9004/15000 [1:16:21<18:19,  5.45it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:11 - INFO - __main__ - train loss is 28.38156099594198\n",
      "Steps:  60%|▌| 9005/15000 [1:16:22<18:12,  5.49it/s, lr=0.000999, step_loss=0.0707/27/2023 19:01:12 - INFO - __main__ - train loss is 28.52357444143854\n",
      "Steps:  60%|▌| 9006/15000 [1:16:22<18:07,  5.51it/s, lr=0.000999, step_loss=0.1407/27/2023 19:01:12 - INFO - __main__ - train loss is 28.930719792610034\n",
      "Steps:  60%|▌| 9007/15000 [1:16:22<18:04,  5.52it/s, lr=0.000999, step_loss=0.4007/27/2023 19:01:12 - INFO - __main__ - train loss is 29.279562294250354\n",
      "Steps:  60%|▌| 9008/15000 [1:16:22<18:02,  5.54it/s, lr=0.000999, step_loss=0.3407/27/2023 19:01:12 - INFO - __main__ - train loss is 29.282601944636554\n",
      "Steps:  60%|▌| 9009/15000 [1:16:22<18:00,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:12 - INFO - __main__ - train loss is 29.379256948363036\n",
      "Steps:  60%|▌| 9010/15000 [1:16:23<17:59,  5.55it/s, lr=0.000999, step_loss=0.0907/27/2023 19:01:12 - INFO - __main__ - train loss is 29.416116795968264\n",
      "Steps:  60%|▌| 9011/15000 [1:16:23<17:58,  5.55it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:13 - INFO - __main__ - train loss is 29.568697548937052\n",
      "Steps:  60%|▌| 9012/15000 [1:16:23<17:57,  5.56it/s, lr=0.000999, step_loss=0.1507/27/2023 19:01:13 - INFO - __main__ - train loss is 29.645437515806407\n",
      "Steps:  60%|▌| 9013/15000 [1:16:23<17:56,  5.56it/s, lr=0.000999, step_loss=0.0707/27/2023 19:01:13 - INFO - __main__ - train loss is 29.655572951305658\n",
      "Steps:  60%|▌| 9014/15000 [1:16:23<17:55,  5.56it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:13 - INFO - __main__ - train loss is 29.65866174735129\n",
      "Steps:  60%|▌| 9015/15000 [1:16:23<17:56,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:13 - INFO - __main__ - train loss is 29.91525467671454\n",
      "Steps:  60%|▌| 9016/15000 [1:16:24<17:55,  5.56it/s, lr=0.000999, step_loss=0.2507/27/2023 19:01:14 - INFO - __main__ - train loss is 30.351210916414857\n",
      "Steps:  60%|▌| 9017/15000 [1:16:24<17:55,  5.56it/s, lr=0.000999, step_loss=0.4307/27/2023 19:01:14 - INFO - __main__ - train loss is 30.641939098015428\n",
      "Steps:  60%|▌| 9018/15000 [1:16:24<17:54,  5.56it/s, lr=0.000999, step_loss=0.2907/27/2023 19:01:14 - INFO - __main__ - train loss is 30.644318078178912\n",
      "Steps:  60%|▌| 9019/15000 [1:16:24<17:54,  5.57it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:14 - INFO - __main__ - train loss is 31.14345083059743\n",
      "Steps:  60%|▌| 9020/15000 [1:16:24<17:54,  5.57it/s, lr=0.000999, step_loss=0.4907/27/2023 19:01:14 - INFO - __main__ - train loss is 31.40657324017957\n",
      "Steps:  60%|▌| 9021/15000 [1:16:25<17:55,  5.56it/s, lr=0.000999, step_loss=0.2607/27/2023 19:01:14 - INFO - __main__ - train loss is 31.40903939306736\n",
      "Steps:  60%|▌| 9022/15000 [1:16:25<17:54,  5.57it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:15 - INFO - __main__ - train loss is 31.63398252427578\n",
      "Steps:  60%|▌| 9023/15000 [1:16:25<17:53,  5.57it/s, lr=0.000999, step_loss=0.2207/27/2023 19:01:15 - INFO - __main__ - train loss is 31.688350550830364\n",
      "Steps:  60%|▌| 9024/15000 [1:16:25<17:54,  5.56it/s, lr=0.000999, step_loss=0.0507/27/2023 19:01:15 - INFO - __main__ - train loss is 31.845312885940075\n",
      "Steps:  60%|▌| 9025/15000 [1:16:25<17:54,  5.56it/s, lr=0.000999, step_loss=0.1507/27/2023 19:01:15 - INFO - __main__ - train loss is 31.910052113234997\n",
      "Steps:  60%|▌| 9026/15000 [1:16:25<17:54,  5.56it/s, lr=0.000999, step_loss=0.0607/27/2023 19:01:15 - INFO - __main__ - train loss is 32.19483055919409\n",
      "Steps:  60%|▌| 9027/15000 [1:16:26<17:54,  5.56it/s, lr=0.000999, step_loss=0.2807/27/2023 19:01:15 - INFO - __main__ - train loss is 32.19716144609265\n",
      "Steps:  60%|▌| 9028/15000 [1:16:26<17:53,  5.56it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:16 - INFO - __main__ - train loss is 32.62378306197934\n",
      "Steps:  60%|▌| 9029/15000 [1:16:26<17:53,  5.56it/s, lr=0.000999, step_loss=0.4207/27/2023 19:01:16 - INFO - __main__ - train loss is 32.686812984524295\n",
      "Steps:  60%|▌| 9030/15000 [1:16:26<17:53,  5.56it/s, lr=0.000999, step_loss=0.0607/27/2023 19:01:16 - INFO - __main__ - train loss is 32.690104039618745\n",
      "Steps:  60%|▌| 9031/15000 [1:16:26<17:54,  5.55it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:16 - INFO - __main__ - train loss is 32.69886020035483\n",
      "Steps:  60%|▌| 9032/15000 [1:16:27<17:57,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:16 - INFO - __main__ - train loss is 32.71398372598924\n",
      "Steps:  60%|▌| 9033/15000 [1:16:27<17:55,  5.55it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:17 - INFO - __main__ - train loss is 32.71873604762368\n",
      "Steps:  60%|▌| 9034/15000 [1:16:27<18:01,  5.52it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:17 - INFO - __main__ - train loss is 32.85874585318379\n",
      "Steps:  60%|▌| 9035/15000 [1:16:27<18:08,  5.48it/s, lr=0.000999, step_loss=0.1407/27/2023 19:01:17 - INFO - __main__ - train loss is 33.138686458347365\n",
      "Steps:  60%|▌| 9036/15000 [1:16:27<18:06,  5.49it/s, lr=0.000999, step_loss=0.2807/27/2023 19:01:17 - INFO - __main__ - train loss is 33.18642726051621\n",
      "Steps:  60%|▌| 9037/15000 [1:16:27<18:02,  5.51it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:17 - INFO - __main__ - train loss is 33.2282645504456\n",
      "Steps:  60%|▌| 9038/15000 [1:16:28<17:59,  5.52it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:17 - INFO - __main__ - train loss is 33.802461365936324\n",
      "Steps:  60%|▌| 9039/15000 [1:16:28<18:05,  5.49it/s, lr=0.000999, step_loss=0.5707/27/2023 19:01:18 - INFO - __main__ - train loss is 33.83569991099648\n",
      "Steps:  60%|▌| 9040/15000 [1:16:28<18:00,  5.52it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:18 - INFO - __main__ - train loss is 33.871677244780585\n",
      "Steps:  60%|▌| 9041/15000 [1:16:28<18:07,  5.48it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:18 - INFO - __main__ - train loss is 33.87526859273203\n",
      "Steps:  60%|▌| 9042/15000 [1:16:28<18:10,  5.47it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:18 - INFO - __main__ - train loss is 33.921528584556654\n",
      "Steps:  60%|▌| 9043/15000 [1:16:29<18:04,  5.49it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:18 - INFO - __main__ - train loss is 33.92402866506018\n",
      "Steps:  60%|▌| 9044/15000 [1:16:29<17:59,  5.52it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:19 - INFO - __main__ - train loss is 33.929805864812806\n",
      "Steps:  60%|▌| 9045/15000 [1:16:29<17:56,  5.53it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:19 - INFO - __main__ - train loss is 33.97697312873788\n",
      "Steps:  60%|▌| 9046/15000 [1:16:29<18:04,  5.49it/s, lr=0.000999, step_loss=0.0407/27/2023 19:01:19 - INFO - __main__ - train loss is 34.44500715774484\n",
      "Steps:  60%|▌| 9047/15000 [1:16:29<18:12,  5.45it/s, lr=0.000999, step_loss=0.4607/27/2023 19:01:19 - INFO - __main__ - train loss is 34.99683715146966\n",
      "Steps:  60%|▌| 9048/15000 [1:16:29<18:09,  5.46it/s, lr=0.000999, step_loss=0.5507/27/2023 19:01:19 - INFO - __main__ - train loss is 35.0197787147481\n",
      "Steps:  60%|▌| 9049/15000 [1:16:30<18:04,  5.49it/s, lr=0.000999, step_loss=0.0207/27/2023 19:01:19 - INFO - __main__ - train loss is 35.02318457211368\n",
      "Steps:  60%|▌| 9050/15000 [1:16:30<17:59,  5.51it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:20 - INFO - __main__ - train loss is 35.46189552987926\n",
      "Steps:  60%|▌| 9051/15000 [1:16:30<17:55,  5.53it/s, lr=0.000999, step_loss=0.4307/27/2023 19:01:20 - INFO - __main__ - train loss is 35.47692550974898\n",
      "Steps:  60%|▌| 9052/15000 [1:16:30<17:53,  5.54it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:20 - INFO - __main__ - train loss is 35.48362890142016\n",
      "Steps:  60%|▌| 9053/15000 [1:16:30<17:58,  5.51it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:20 - INFO - __main__ - train loss is 35.486057336907834\n",
      "Steps:  60%|▌| 9054/15000 [1:16:31<17:54,  5.53it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:20 - INFO - __main__ - train loss is 35.49294461682439\n",
      "Steps:  60%|▌| 9055/15000 [1:16:31<17:52,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:21 - INFO - __main__ - train loss is 35.5091425254941\n",
      "Steps:  60%|▌| 9056/15000 [1:16:31<17:50,  5.55it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:21 - INFO - __main__ - train loss is 35.59612997621298\n",
      "Steps:  60%|▌| 9057/15000 [1:16:31<17:49,  5.56it/s, lr=0.000999, step_loss=0.0807/27/2023 19:01:21 - INFO - __main__ - train loss is 35.67075555771589\n",
      "Steps:  60%|▌| 9058/15000 [1:16:31<17:56,  5.52it/s, lr=0.000999, step_loss=0.0707/27/2023 19:01:21 - INFO - __main__ - train loss is 35.789317309856415\n",
      "Steps:  60%|▌| 9059/15000 [1:16:31<18:02,  5.49it/s, lr=0.000999, step_loss=0.1107/27/2023 19:01:21 - INFO - __main__ - train loss is 35.79336443450302\n",
      "Steps:  60%|▌| 9060/15000 [1:16:32<18:07,  5.46it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:21 - INFO - __main__ - train loss is 35.79986971523613\n",
      "Steps:  60%|▌| 9061/15000 [1:16:32<18:20,  5.40it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:22 - INFO - __main__ - train loss is 36.30772906448692\n",
      "Steps:  60%|▌| 9062/15000 [1:16:32<18:14,  5.43it/s, lr=0.000999, step_loss=0.5007/27/2023 19:01:22 - INFO - __main__ - train loss is 36.532685338519514\n",
      "Steps:  60%|▌| 9063/15000 [1:16:32<18:06,  5.47it/s, lr=0.000999, step_loss=0.2207/27/2023 19:01:22 - INFO - __main__ - train loss is 36.63838183041662\n",
      "Steps:  60%|▌| 9064/15000 [1:16:32<18:00,  5.50it/s, lr=0.000999, step_loss=0.1007/27/2023 19:01:22 - INFO - __main__ - train loss is 36.641046011587605\n",
      "Steps:  60%|▌| 9065/15000 [1:16:33<17:56,  5.51it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:22 - INFO - __main__ - train loss is 36.64819472725503\n",
      "Steps:  60%|▌| 9066/15000 [1:16:33<17:54,  5.52it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:23 - INFO - __main__ - train loss is 36.661185363074765\n",
      "Steps:  60%|▌| 9067/15000 [1:16:33<17:51,  5.53it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:23 - INFO - __main__ - train loss is 36.66612875391729\n",
      "Steps:  60%|▌| 9068/15000 [1:16:33<17:50,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:23 - INFO - __main__ - train loss is 36.982103049056605\n",
      "Steps:  60%|▌| 9069/15000 [1:16:33<17:59,  5.49it/s, lr=0.000999, step_loss=0.3107/27/2023 19:01:23 - INFO - __main__ - train loss is 37.0547902204562\n",
      "Steps:  60%|▌| 9070/15000 [1:16:33<17:57,  5.50it/s, lr=0.000999, step_loss=0.0707/27/2023 19:01:23 - INFO - __main__ - train loss is 37.074273442151025\n",
      "Steps:  60%|▌| 9071/15000 [1:16:34<18:02,  5.47it/s, lr=0.000999, step_loss=0.0107/27/2023 19:01:23 - INFO - __main__ - train loss is 37.100554504664615\n",
      "Steps:  60%|▌| 9072/15000 [1:16:34<17:57,  5.50it/s, lr=0.000999, step_loss=0.0207/27/2023 19:01:24 - INFO - __main__ - train loss is 37.125958473654464\n",
      "Steps:  60%|▌| 9073/15000 [1:16:34<17:54,  5.52it/s, lr=0.000999, step_loss=0.0207/27/2023 19:01:24 - INFO - __main__ - train loss is 37.12816331745125\n",
      "Steps:  60%|▌| 9074/15000 [1:16:34<17:59,  5.49it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:24 - INFO - __main__ - train loss is 37.222836742410436\n",
      "Steps:  60%|▌| 9075/15000 [1:16:34<17:53,  5.52it/s, lr=0.000999, step_loss=0.0907/27/2023 19:01:24 - INFO - __main__ - train loss is 37.34924745024182\n",
      "Steps:  61%|▌| 9076/15000 [1:16:35<17:59,  5.49it/s, lr=0.000999, step_loss=0.1207/27/2023 19:01:24 - INFO - __main__ - train loss is 37.832475835690275\n",
      "Steps:  61%|▌| 9077/15000 [1:16:35<18:03,  5.47it/s, lr=0.000999, step_loss=0.4807/27/2023 19:01:25 - INFO - __main__ - train loss is 38.094108218559995\n",
      "Steps:  61%|▌| 9078/15000 [1:16:35<17:59,  5.48it/s, lr=0.000999, step_loss=0.2607/27/2023 19:01:25 - INFO - __main__ - train loss is 38.098549257265404\n",
      "Steps:  61%|▌| 9079/15000 [1:16:35<17:53,  5.51it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:25 - INFO - __main__ - train loss is 38.50083495234139\n",
      "Steps:  61%|▌| 9080/15000 [1:16:35<17:54,  5.51it/s, lr=0.000999, step_loss=0.4007/27/2023 19:01:25 - INFO - __main__ - train loss is 39.37082804297097\n",
      "Steps:  61%|▌| 9081/15000 [1:16:35<17:49,  5.54it/s, lr=0.000999, step_loss=0.8707/27/2023 19:01:25 - INFO - __main__ - train loss is 39.37291331286542\n",
      "Steps:  61%|▌| 9082/15000 [1:16:36<17:49,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:25 - INFO - __main__ - train loss is 39.40443037147634\n",
      "Steps:  61%|▌| 9083/15000 [1:16:36<17:46,  5.55it/s, lr=0.000999, step_loss=0.0307/27/2023 19:01:26 - INFO - __main__ - train loss is 39.62485694582574\n",
      "Steps:  61%|▌| 9084/15000 [1:16:36<17:44,  5.56it/s, lr=0.000999, step_loss=0.2207/27/2023 19:01:26 - INFO - __main__ - train loss is 39.756742504192516\n",
      "Steps:  61%|▌| 9085/15000 [1:16:36<17:48,  5.54it/s, lr=0.000999, step_loss=0.1307/27/2023 19:01:26 - INFO - __main__ - train loss is 40.07837161119096\n",
      "Steps:  61%|▌| 9086/15000 [1:16:36<17:45,  5.55it/s, lr=0.000999, step_loss=0.3207/27/2023 19:01:26 - INFO - __main__ - train loss is 40.16329825366847\n",
      "Steps:  61%|▌| 9087/15000 [1:16:37<17:50,  5.52it/s, lr=0.000999, step_loss=0.0807/27/2023 19:01:26 - INFO - __main__ - train loss is 40.171625778777525\n",
      "Steps:  61%|▌| 9088/15000 [1:16:37<17:46,  5.54it/s, lr=0.000999, step_loss=0.0007/27/2023 19:01:27 - INFO - __main__ - train loss is 40.22888222406618\n",
      "Steps:  61%|▌| 9089/15000 [1:16:37<17:47,  5.54it/s, lr=0.000999, step_loss=0.0507/27/2023 19:01:27 - INFO - __main__ - train loss is 40.27998395333998\n",
      "Steps:  61%|▌| 9090/15000 [1:16:37<24:35,  4.01it/s, lr=0.000999, step_loss=0.0507/27/2023 19:01:28 - INFO - __main__ - Per validation step average loss is 0.005239407531917095\n",
      "07/27/2023 19:01:28 - INFO - __main__ - Cumulative validation average loss is 0.005239407531917095\n",
      "07/27/2023 19:01:29 - INFO - __main__ - Per validation step average loss is 0.06215379387140274\n",
      "07/27/2023 19:01:29 - INFO - __main__ - Cumulative validation average loss is 0.06739320140331984\n",
      "07/27/2023 19:01:29 - INFO - __main__ - Per validation step average loss is 0.009242497384548187\n",
      "07/27/2023 19:01:29 - INFO - __main__ - Cumulative validation average loss is 0.07663569878786802\n",
      "07/27/2023 19:01:29 - INFO - __main__ - Per validation step average loss is 0.0025253810454159975\n",
      "07/27/2023 19:01:29 - INFO - __main__ - Cumulative validation average loss is 0.07916107983328402\n",
      "07/27/2023 19:01:30 - INFO - __main__ - Per validation step average loss is 0.02128516137599945\n",
      "07/27/2023 19:01:30 - INFO - __main__ - Cumulative validation average loss is 0.10044624120928347\n",
      "07/27/2023 19:01:30 - INFO - __main__ - Per validation step average loss is 0.21142110228538513\n",
      "07/27/2023 19:01:30 - INFO - __main__ - Cumulative validation average loss is 0.3118673434946686\n",
      "07/27/2023 19:01:31 - INFO - __main__ - Per validation step average loss is 0.059630539268255234\n",
      "07/27/2023 19:01:31 - INFO - __main__ - Cumulative validation average loss is 0.37149788276292384\n",
      "07/27/2023 19:01:31 - INFO - __main__ - Per validation step average loss is 0.22769901156425476\n",
      "07/27/2023 19:01:31 - INFO - __main__ - Cumulative validation average loss is 0.5991968943271786\n",
      "07/27/2023 19:01:31 - INFO - __main__ - Per validation step average loss is 0.012414101511240005\n",
      "07/27/2023 19:01:31 - INFO - __main__ - Cumulative validation average loss is 0.6116109958384186\n",
      "07/27/2023 19:01:32 - INFO - __main__ - Per validation step average loss is 0.07100793719291687\n",
      "07/27/2023 19:01:32 - INFO - __main__ - Cumulative validation average loss is 0.6826189330313355\n",
      "07/27/2023 19:01:32 - INFO - __main__ - Per validation step average loss is 0.0677701085805893\n",
      "07/27/2023 19:01:32 - INFO - __main__ - Cumulative validation average loss is 0.7503890416119248\n",
      "07/27/2023 19:01:33 - INFO - __main__ - Per validation step average loss is 0.5554623007774353\n",
      "07/27/2023 19:01:33 - INFO - __main__ - Cumulative validation average loss is 1.30585134238936\n",
      "07/27/2023 19:01:33 - INFO - __main__ - Per validation step average loss is 0.06178002059459686\n",
      "07/27/2023 19:01:33 - INFO - __main__ - Cumulative validation average loss is 1.367631362983957\n",
      "07/27/2023 19:01:34 - INFO - __main__ - Per validation step average loss is 0.008273722603917122\n",
      "07/27/2023 19:01:34 - INFO - __main__ - Cumulative validation average loss is 1.375905085587874\n",
      "07/27/2023 19:01:34 - INFO - __main__ - Per validation step average loss is 0.23164799809455872\n",
      "07/27/2023 19:01:34 - INFO - __main__ - Cumulative validation average loss is 1.6075530836824328\n",
      "07/27/2023 19:01:34 - INFO - __main__ - Per validation step average loss is 0.01728285476565361\n",
      "07/27/2023 19:01:34 - INFO - __main__ - Cumulative validation average loss is 1.6248359384480864\n",
      "07/27/2023 19:01:35 - INFO - __main__ - Per validation step average loss is 0.17029665410518646\n",
      "07/27/2023 19:01:35 - INFO - __main__ - Cumulative validation average loss is 1.7951325925532728\n",
      "07/27/2023 19:01:35 - INFO - __main__ - Per validation step average loss is 0.15944670140743256\n",
      "07/27/2023 19:01:35 - INFO - __main__ - Cumulative validation average loss is 1.9545792939607054\n",
      "07/27/2023 19:01:36 - INFO - __main__ - Per validation step average loss is 0.37073659896850586\n",
      "07/27/2023 19:01:36 - INFO - __main__ - Cumulative validation average loss is 2.3253158929292113\n",
      "07/27/2023 19:01:36 - INFO - __main__ - Per validation step average loss is 0.7877026796340942\n",
      "07/27/2023 19:01:36 - INFO - __main__ - Cumulative validation average loss is 3.1130185725633055\n",
      "07/27/2023 19:01:36 - INFO - __main__ - Per validation step average loss is 0.031062129884958267\n",
      "07/27/2023 19:01:36 - INFO - __main__ - Cumulative validation average loss is 3.1440807024482638\n",
      "07/27/2023 19:01:37 - INFO - __main__ - Per validation step average loss is 0.07862196117639542\n",
      "07/27/2023 19:01:37 - INFO - __main__ - Cumulative validation average loss is 3.222702663624659\n",
      "07/27/2023 19:01:37 - INFO - __main__ - Per validation step average loss is 0.0023611297365278006\n",
      "07/27/2023 19:01:37 - INFO - __main__ - Cumulative validation average loss is 3.225063793361187\n",
      "07/27/2023 19:01:38 - INFO - __main__ - Per validation step average loss is 0.002960425103083253\n",
      "07/27/2023 19:01:38 - INFO - __main__ - Cumulative validation average loss is 3.2280242184642702\n",
      "07/27/2023 19:01:38 - INFO - __main__ - Per validation step average loss is 0.21655602753162384\n",
      "07/27/2023 19:01:38 - INFO - __main__ - Cumulative validation average loss is 3.444580245995894\n",
      "07/27/2023 19:01:39 - INFO - __main__ - Per validation step average loss is 0.04010160267353058\n",
      "07/27/2023 19:01:39 - INFO - __main__ - Cumulative validation average loss is 3.4846818486694247\n",
      "07/27/2023 19:01:39 - INFO - __main__ - Per validation step average loss is 0.002242584712803364\n",
      "07/27/2023 19:01:39 - INFO - __main__ - Cumulative validation average loss is 3.486924433382228\n",
      "07/27/2023 19:01:39 - INFO - __main__ - Per validation step average loss is 0.4520338773727417\n",
      "07/27/2023 19:01:39 - INFO - __main__ - Cumulative validation average loss is 3.9389583107549697\n",
      "07/27/2023 19:01:40 - INFO - __main__ - Per validation step average loss is 0.2743392884731293\n",
      "07/27/2023 19:01:40 - INFO - __main__ - Cumulative validation average loss is 4.213297599228099\n",
      "07/27/2023 19:01:40 - INFO - __main__ - Per validation step average loss is 0.1595727801322937\n",
      "07/27/2023 19:01:40 - INFO - __main__ - Cumulative validation average loss is 4.372870379360393\n",
      "07/27/2023 19:01:41 - INFO - __main__ - Per validation step average loss is 0.030779827386140823\n",
      "07/27/2023 19:01:41 - INFO - __main__ - Cumulative validation average loss is 4.4036502067465335\n",
      "07/27/2023 19:01:41 - INFO - __main__ - Per validation step average loss is 0.005836837459355593\n",
      "07/27/2023 19:01:41 - INFO - __main__ - Cumulative validation average loss is 4.409487044205889\n",
      "07/27/2023 19:01:41 - INFO - __main__ - Per validation step average loss is 0.10136456042528152\n",
      "07/27/2023 19:01:41 - INFO - __main__ - Cumulative validation average loss is 4.510851604631171\n",
      "07/27/2023 19:01:42 - INFO - __main__ - Per validation step average loss is 0.48264801502227783\n",
      "07/27/2023 19:01:42 - INFO - __main__ - Cumulative validation average loss is 4.9934996196534485\n",
      "07/27/2023 19:01:42 - INFO - __main__ - Per validation step average loss is 0.11262626945972443\n",
      "07/27/2023 19:01:42 - INFO - __main__ - Cumulative validation average loss is 5.106125889113173\n",
      "07/27/2023 19:01:43 - INFO - __main__ - Per validation step average loss is 0.020607993006706238\n",
      "07/27/2023 19:01:43 - INFO - __main__ - Cumulative validation average loss is 5.126733882119879\n",
      "07/27/2023 19:01:43 - INFO - __main__ - Per validation step average loss is 0.03152254596352577\n",
      "07/27/2023 19:01:43 - INFO - __main__ - Cumulative validation average loss is 5.158256428083405\n",
      "07/27/2023 19:01:44 - INFO - __main__ - Per validation step average loss is 0.017520444467663765\n",
      "07/27/2023 19:01:44 - INFO - __main__ - Cumulative validation average loss is 5.175776872551069\n",
      "07/27/2023 19:01:44 - INFO - __main__ - Per validation step average loss is 0.027040623128414154\n",
      "07/27/2023 19:01:44 - INFO - __main__ - Cumulative validation average loss is 5.202817495679483\n",
      "07/27/2023 19:01:44 - INFO - __main__ - Per validation step average loss is 0.3298167884349823\n",
      "07/27/2023 19:01:44 - INFO - __main__ - Cumulative validation average loss is 5.532634284114465\n",
      "07/27/2023 19:01:45 - INFO - __main__ - Per validation step average loss is 0.07168136537075043\n",
      "07/27/2023 19:01:45 - INFO - __main__ - Cumulative validation average loss is 5.6043156494852155\n",
      "07/27/2023 19:01:45 - INFO - __main__ - Per validation step average loss is 0.021930504590272903\n",
      "07/27/2023 19:01:45 - INFO - __main__ - Cumulative validation average loss is 5.6262461540754884\n",
      "07/27/2023 19:01:46 - INFO - __main__ - Per validation step average loss is 0.0013897859025746584\n",
      "07/27/2023 19:01:46 - INFO - __main__ - Cumulative validation average loss is 5.627635939978063\n",
      "07/27/2023 19:01:46 - INFO - __main__ - Per validation step average loss is 0.11615001410245895\n",
      "07/27/2023 19:01:46 - INFO - __main__ - Cumulative validation average loss is 5.743785954080522\n",
      "07/27/2023 19:01:46 - INFO - __main__ - Per validation step average loss is 0.27121251821517944\n",
      "07/27/2023 19:01:46 - INFO - __main__ - Cumulative validation average loss is 6.0149984722957015\n",
      "07/27/2023 19:01:47 - INFO - __main__ - Per validation step average loss is 0.04696696251630783\n",
      "07/27/2023 19:01:47 - INFO - __main__ - Cumulative validation average loss is 6.061965434812009\n",
      "07/27/2023 19:01:47 - INFO - __main__ - Per validation step average loss is 0.028764955699443817\n",
      "07/27/2023 19:01:47 - INFO - __main__ - Cumulative validation average loss is 6.090730390511453\n",
      "07/27/2023 19:01:48 - INFO - __main__ - Per validation step average loss is 0.4570807218551636\n",
      "07/27/2023 19:01:48 - INFO - __main__ - Cumulative validation average loss is 6.547811112366617\n",
      "07/27/2023 19:01:48 - INFO - __main__ - Per validation step average loss is 0.06772974133491516\n",
      "07/27/2023 19:01:48 - INFO - __main__ - Cumulative validation average loss is 6.615540853701532\n",
      "07/27/2023 19:01:48 - INFO - __main__ - Per validation step average loss is 0.0033578788861632347\n",
      "07/27/2023 19:01:48 - INFO - __main__ - Cumulative validation average loss is 6.618898732587695\n",
      "07/27/2023 19:01:49 - INFO - __main__ - Per validation step average loss is 0.0488007515668869\n",
      "07/27/2023 19:01:49 - INFO - __main__ - Cumulative validation average loss is 6.667699484154582\n",
      "07/27/2023 19:01:49 - INFO - __main__ - Per validation step average loss is 0.016515234485268593\n",
      "07/27/2023 19:01:49 - INFO - __main__ - Cumulative validation average loss is 6.684214718639851\n",
      "07/27/2023 19:01:50 - INFO - __main__ - Per validation step average loss is 0.00301560596562922\n",
      "07/27/2023 19:01:50 - INFO - __main__ - Cumulative validation average loss is 6.68723032460548\n",
      "07/27/2023 19:01:50 - INFO - __main__ - Per validation step average loss is 0.00260121445171535\n",
      "07/27/2023 19:01:50 - INFO - __main__ - Cumulative validation average loss is 6.689831539057195\n",
      "07/27/2023 19:01:51 - INFO - __main__ - Per validation step average loss is 0.07383695244789124\n",
      "07/27/2023 19:01:51 - INFO - __main__ - Cumulative validation average loss is 6.763668491505086\n",
      "07/27/2023 19:01:51 - INFO - __main__ - Per validation step average loss is 0.40026989579200745\n",
      "07/27/2023 19:01:51 - INFO - __main__ - Cumulative validation average loss is 7.163938387297094\n",
      "07/27/2023 19:01:51 - INFO - __main__ - Per validation step average loss is 0.32246512174606323\n",
      "07/27/2023 19:01:51 - INFO - __main__ - Cumulative validation average loss is 7.486403509043157\n",
      "07/27/2023 19:01:52 - INFO - __main__ - Per validation step average loss is 0.13311222195625305\n",
      "07/27/2023 19:01:52 - INFO - __main__ - Cumulative validation average loss is 7.61951573099941\n",
      "07/27/2023 19:01:52 - INFO - __main__ - Per validation step average loss is 0.16830676794052124\n",
      "07/27/2023 19:01:52 - INFO - __main__ - Cumulative validation average loss is 7.787822498939931\n",
      "07/27/2023 19:01:53 - INFO - __main__ - Per validation step average loss is 0.2980743646621704\n",
      "07/27/2023 19:01:53 - INFO - __main__ - Cumulative validation average loss is 8.085896863602102\n",
      "07/27/2023 19:01:53 - INFO - __main__ - Per validation step average loss is 0.12107322365045547\n",
      "07/27/2023 19:01:53 - INFO - __main__ - Cumulative validation average loss is 8.206970087252557\n",
      "07/27/2023 19:01:53 - INFO - __main__ - Per validation step average loss is 0.030259298160672188\n",
      "07/27/2023 19:01:53 - INFO - __main__ - Cumulative validation average loss is 8.23722938541323\n",
      "07/27/2023 19:01:54 - INFO - __main__ - Per validation step average loss is 0.13780060410499573\n",
      "07/27/2023 19:01:54 - INFO - __main__ - Cumulative validation average loss is 8.375029989518225\n",
      "07/27/2023 19:01:54 - INFO - __main__ - Per validation step average loss is 0.1156696230173111\n",
      "07/27/2023 19:01:54 - INFO - __main__ - Cumulative validation average loss is 8.490699612535536\n",
      "07/27/2023 19:01:55 - INFO - __main__ - Per validation step average loss is 0.015229067765176296\n",
      "07/27/2023 19:01:55 - INFO - __main__ - Cumulative validation average loss is 8.505928680300713\n",
      "07/27/2023 19:01:55 - INFO - __main__ - Per validation step average loss is 0.0026717428117990494\n",
      "07/27/2023 19:01:55 - INFO - __main__ - Cumulative validation average loss is 8.508600423112512\n",
      "07/27/2023 19:01:56 - INFO - __main__ - Per validation step average loss is 0.16412115097045898\n",
      "07/27/2023 19:01:56 - INFO - __main__ - Cumulative validation average loss is 8.67272157408297\n",
      "07/27/2023 19:01:56 - INFO - __main__ - Per validation step average loss is 0.0021693657618016005\n",
      "07/27/2023 19:01:56 - INFO - __main__ - Cumulative validation average loss is 8.674890939844772\n",
      "07/27/2023 19:01:56 - INFO - __main__ - Per validation step average loss is 0.010502535849809647\n",
      "07/27/2023 19:01:56 - INFO - __main__ - Cumulative validation average loss is 8.685393475694582\n",
      "07/27/2023 19:01:57 - INFO - __main__ - Per validation step average loss is 0.17395126819610596\n",
      "07/27/2023 19:01:57 - INFO - __main__ - Cumulative validation average loss is 8.859344743890688\n",
      "07/27/2023 19:01:57 - INFO - __main__ - Per validation step average loss is 0.0051756915636360645\n",
      "07/27/2023 19:01:57 - INFO - __main__ - Cumulative validation average loss is 8.864520435454324\n",
      "07/27/2023 19:01:58 - INFO - __main__ - Per validation step average loss is 0.004174173343926668\n",
      "07/27/2023 19:01:58 - INFO - __main__ - Cumulative validation average loss is 8.86869460879825\n",
      "07/27/2023 19:01:58 - INFO - __main__ - Per validation step average loss is 0.32493752241134644\n",
      "07/27/2023 19:01:58 - INFO - __main__ - Cumulative validation average loss is 9.193632131209597\n",
      "07/27/2023 19:01:58 - INFO - __main__ - Per validation step average loss is 0.221443772315979\n",
      "07/27/2023 19:01:58 - INFO - __main__ - Cumulative validation average loss is 9.415075903525576\n",
      "07/27/2023 19:01:59 - INFO - __main__ - Per validation step average loss is 0.23006418347358704\n",
      "07/27/2023 19:01:59 - INFO - __main__ - Cumulative validation average loss is 9.645140086999163\n",
      "07/27/2023 19:01:59 - INFO - __main__ - Per validation step average loss is 0.05110248178243637\n",
      "07/27/2023 19:01:59 - INFO - __main__ - Cumulative validation average loss is 9.6962425687816\n",
      "07/27/2023 19:02:00 - INFO - __main__ - Per validation step average loss is 0.005902789067476988\n",
      "07/27/2023 19:02:00 - INFO - __main__ - Cumulative validation average loss is 9.702145357849076\n",
      "07/27/2023 19:02:00 - INFO - __main__ - Per validation step average loss is 0.011451534926891327\n",
      "07/27/2023 19:02:00 - INFO - __main__ - Cumulative validation average loss is 9.713596892775968\n",
      "07/27/2023 19:02:01 - INFO - __main__ - Per validation step average loss is 0.19433298707008362\n",
      "07/27/2023 19:02:01 - INFO - __main__ - Cumulative validation average loss is 9.907929879846051\n",
      "07/27/2023 19:02:01 - INFO - __main__ - Average validation loss for Epoch 29 is 0.12541683392210193\n",
      "07/27/2023 19:02:01 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 19:02:57 - INFO - __main__ - Starting epoch 30\n",
      "07/27/2023 19:02:59 - INFO - __main__ - train loss is 0.02962522953748703\n",
      "Steps:  61%|▌| 9091/15000 [1:18:09<45:22:13, 27.64s/it, lr=0.000999, step_loss=007/27/2023 19:02:59 - INFO - __main__ - train loss is 0.18600168079137802\n",
      "Steps:  61%|▌| 9092/15000 [1:18:09<32:00:21, 19.50s/it, lr=0.000999, step_loss=007/27/2023 19:03:00 - INFO - __main__ - train loss is 0.38781213015317917\n",
      "Steps:  61%|▌| 9093/15000 [1:18:10<22:39:00, 13.80s/it, lr=0.000999, step_loss=007/27/2023 19:03:00 - INFO - __main__ - train loss is 0.7389302179217339\n",
      "Steps:  61%|▌| 9094/15000 [1:18:10<16:06:14,  9.82s/it, lr=0.000999, step_loss=007/27/2023 19:03:01 - INFO - __main__ - train loss is 0.854888804256916\n",
      "Steps:  61%|▌| 9095/15000 [1:18:11<11:31:26,  7.03s/it, lr=0.000999, step_loss=007/27/2023 19:03:01 - INFO - __main__ - train loss is 1.1013973131775856\n",
      "Steps:  61%|▌| 9096/15000 [1:18:11<8:19:04,  5.07s/it, lr=0.000999, step_loss=0.07/27/2023 19:03:02 - INFO - __main__ - train loss is 1.4446137621998787\n",
      "Steps:  61%|▌| 9097/15000 [1:18:12<6:04:24,  3.70s/it, lr=0.000999, step_loss=0.07/27/2023 19:03:02 - INFO - __main__ - train loss is 1.6087489947676659\n",
      "Steps:  61%|▌| 9098/15000 [1:18:12<4:30:15,  2.75s/it, lr=0.000999, step_loss=0.07/27/2023 19:03:03 - INFO - __main__ - train loss is 1.6216530622914433\n",
      "Steps:  61%|▌| 9099/15000 [1:18:13<3:24:07,  2.08s/it, lr=0.000999, step_loss=0.07/27/2023 19:03:03 - INFO - __main__ - train loss is 1.6232516500167549\n",
      "Steps:  61%|▌| 9100/15000 [1:18:13<2:37:57,  1.61s/it, lr=0.000999, step_loss=0.07/27/2023 19:03:04 - INFO - __main__ - train loss is 1.6384737412445247\n",
      "Steps:  61%|▌| 9101/15000 [1:18:14<2:05:33,  1.28s/it, lr=0.000999, step_loss=0.07/27/2023 19:03:04 - INFO - __main__ - train loss is 2.039685360621661\n",
      "Steps:  61%|▌| 9102/15000 [1:18:14<1:43:04,  1.05s/it, lr=0.000999, step_loss=0.07/27/2023 19:03:05 - INFO - __main__ - train loss is 2.048736689146608\n",
      "Steps:  61%|▌| 9103/15000 [1:18:15<1:27:17,  1.13it/s, lr=0.000999, step_loss=0.07/27/2023 19:03:05 - INFO - __main__ - train loss is 2.2584139979444444\n",
      "Steps:  61%|▌| 9104/15000 [1:18:15<1:16:00,  1.29it/s, lr=0.000999, step_loss=0.07/27/2023 19:03:06 - INFO - __main__ - train loss is 2.5896033025346696\n",
      "Steps:  61%|▌| 9105/15000 [1:18:16<1:08:55,  1.43it/s, lr=0.000999, step_loss=0.07/27/2023 19:03:06 - INFO - __main__ - train loss is 2.7842335081659257\n",
      "Steps:  61%|▌| 9106/15000 [1:18:17<1:04:52,  1.51it/s, lr=0.000999, step_loss=0.07/27/2023 19:03:07 - INFO - __main__ - train loss is 2.9149858034215868\n",
      "Steps:  61%|▌| 9107/15000 [1:18:17<1:00:54,  1.61it/s, lr=0.000999, step_loss=0.07/27/2023 19:03:07 - INFO - __main__ - train loss is 3.1119127101264894\n",
      "Steps:  61%|▌| 9108/15000 [1:18:18<57:41,  1.70it/s, lr=0.000999, step_loss=0.1907/27/2023 19:03:08 - INFO - __main__ - train loss is 3.1226008008234203\n",
      "Steps:  61%|▌| 9109/15000 [1:18:18<55:16,  1.78it/s, lr=0.000999, step_loss=0.0107/27/2023 19:03:08 - INFO - __main__ - train loss is 3.189488924574107\n",
      "Steps:  61%|▌| 9110/15000 [1:18:19<53:47,  1.82it/s, lr=0.000999, step_loss=0.0607/27/2023 19:03:09 - INFO - __main__ - train loss is 3.367308400105685\n",
      "Steps:  61%|▌| 9111/15000 [1:18:19<52:41,  1.86it/s, lr=0.000999, step_loss=0.1707/27/2023 19:03:09 - INFO - __main__ - train loss is 3.4912215094082057\n",
      "Steps:  61%|▌| 9112/15000 [1:18:20<51:57,  1.89it/s, lr=0.000999, step_loss=0.1207/27/2023 19:03:10 - INFO - __main__ - train loss is 3.5267564761452377\n",
      "Steps:  61%|▌| 9113/15000 [1:18:20<51:09,  1.92it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:10 - INFO - __main__ - train loss is 3.570545732509345\n",
      "Steps:  61%|▌| 9114/15000 [1:18:21<50:50,  1.93it/s, lr=0.000999, step_loss=0.0407/27/2023 19:03:11 - INFO - __main__ - train loss is 3.6943348492495716\n",
      "Steps:  61%|▌| 9115/15000 [1:18:21<50:34,  1.94it/s, lr=0.000999, step_loss=0.1207/27/2023 19:03:11 - INFO - __main__ - train loss is 3.9744829977862537\n",
      "Steps:  61%|▌| 9116/15000 [1:18:22<50:17,  1.95it/s, lr=0.000999, step_loss=0.2807/27/2023 19:03:12 - INFO - __main__ - train loss is 4.009480654727668\n",
      "Steps:  61%|▌| 9117/15000 [1:18:22<50:11,  1.95it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:12 - INFO - __main__ - train loss is 4.129823058377951\n",
      "Steps:  61%|▌| 9118/15000 [1:18:23<50:07,  1.96it/s, lr=0.000999, step_loss=0.1207/27/2023 19:03:13 - INFO - __main__ - train loss is 4.1342957415618\n",
      "Steps:  61%|▌| 9119/15000 [1:18:23<50:15,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:13 - INFO - __main__ - train loss is 4.687739173416048\n",
      "Steps:  61%|▌| 9120/15000 [1:18:24<50:03,  1.96it/s, lr=0.000999, step_loss=0.5507/27/2023 19:03:14 - INFO - __main__ - train loss is 4.797036605421454\n",
      "Steps:  61%|▌| 9121/15000 [1:18:24<49:57,  1.96it/s, lr=0.000999, step_loss=0.1007/27/2023 19:03:14 - INFO - __main__ - train loss is 4.806034407112747\n",
      "Steps:  61%|▌| 9122/15000 [1:18:25<49:46,  1.97it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:15 - INFO - __main__ - train loss is 5.275641462299973\n",
      "Steps:  61%|▌| 9123/15000 [1:18:25<49:43,  1.97it/s, lr=0.000999, step_loss=0.4707/27/2023 19:03:15 - INFO - __main__ - train loss is 5.279914166312665\n",
      "Steps:  61%|▌| 9124/15000 [1:18:26<49:44,  1.97it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:16 - INFO - __main__ - train loss is 5.352797027211636\n",
      "Steps:  61%|▌| 9125/15000 [1:18:26<49:44,  1.97it/s, lr=0.000999, step_loss=0.0707/27/2023 19:03:16 - INFO - __main__ - train loss is 5.412672739010304\n",
      "Steps:  61%|▌| 9126/15000 [1:18:27<49:43,  1.97it/s, lr=0.000999, step_loss=0.0507/27/2023 19:03:17 - INFO - __main__ - train loss is 5.414385694311932\n",
      "Steps:  61%|▌| 9127/15000 [1:18:27<49:42,  1.97it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:17 - INFO - __main__ - train loss is 5.463801714824513\n",
      "Steps:  61%|▌| 9128/15000 [1:18:28<49:38,  1.97it/s, lr=0.000999, step_loss=0.0407/27/2023 19:03:18 - INFO - __main__ - train loss is 5.5191143930424005\n",
      "Steps:  61%|▌| 9129/15000 [1:18:28<49:39,  1.97it/s, lr=0.000999, step_loss=0.0507/27/2023 19:03:18 - INFO - __main__ - train loss is 5.52081682276912\n",
      "Steps:  61%|▌| 9130/15000 [1:18:29<49:35,  1.97it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:19 - INFO - __main__ - train loss is 5.553354186238721\n",
      "Steps:  61%|▌| 9131/15000 [1:18:29<49:38,  1.97it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:20 - INFO - __main__ - train loss is 5.592206043424085\n",
      "Steps:  61%|▌| 9132/15000 [1:18:30<49:37,  1.97it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:20 - INFO - __main__ - train loss is 5.958700639428571\n",
      "Steps:  61%|▌| 9133/15000 [1:18:30<49:45,  1.97it/s, lr=0.000999, step_loss=0.3607/27/2023 19:03:21 - INFO - __main__ - train loss is 6.126162720145658\n",
      "Steps:  61%|▌| 9134/15000 [1:18:31<49:44,  1.97it/s, lr=0.000999, step_loss=0.1607/27/2023 19:03:21 - INFO - __main__ - train loss is 6.1373920638579875\n",
      "Steps:  61%|▌| 9135/15000 [1:18:31<49:49,  1.96it/s, lr=0.000999, step_loss=0.0107/27/2023 19:03:22 - INFO - __main__ - train loss is 6.177305487217382\n",
      "Steps:  61%|▌| 9136/15000 [1:18:32<49:44,  1.96it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:22 - INFO - __main__ - train loss is 6.2558416177053005\n",
      "Steps:  61%|▌| 9137/15000 [1:18:32<50:01,  1.95it/s, lr=0.000999, step_loss=0.0707/27/2023 19:03:23 - INFO - __main__ - train loss is 6.55698395264335\n",
      "Steps:  61%|▌| 9138/15000 [1:18:33<50:06,  1.95it/s, lr=0.000999, step_loss=0.3007/27/2023 19:03:23 - INFO - __main__ - train loss is 6.577143329428509\n",
      "Steps:  61%|▌| 9139/15000 [1:18:33<49:57,  1.96it/s, lr=0.000999, step_loss=0.0207/27/2023 19:03:24 - INFO - __main__ - train loss is 6.581450518919155\n",
      "Steps:  61%|▌| 9140/15000 [1:18:34<49:58,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:24 - INFO - __main__ - train loss is 6.652057123137638\n",
      "Steps:  61%|▌| 9141/15000 [1:18:34<49:51,  1.96it/s, lr=0.000999, step_loss=0.0707/27/2023 19:03:25 - INFO - __main__ - train loss is 7.101919335080311\n",
      "Steps:  61%|▌| 9142/15000 [1:18:35<49:44,  1.96it/s, lr=0.000999, step_loss=0.4507/27/2023 19:03:25 - INFO - __main__ - train loss is 7.132584050996229\n",
      "Steps:  61%|▌| 9143/15000 [1:18:35<49:53,  1.96it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:26 - INFO - __main__ - train loss is 7.1362879641819745\n",
      "Steps:  61%|▌| 9144/15000 [1:18:36<49:58,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:26 - INFO - __main__ - train loss is 7.353997267084196\n",
      "Steps:  61%|▌| 9145/15000 [1:18:36<49:55,  1.95it/s, lr=0.000999, step_loss=0.2107/27/2023 19:03:27 - INFO - __main__ - train loss is 7.370752972783521\n",
      "Steps:  61%|▌| 9146/15000 [1:18:37<50:02,  1.95it/s, lr=0.000999, step_loss=0.0107/27/2023 19:03:27 - INFO - __main__ - train loss is 7.431487859459594\n",
      "Steps:  61%|▌| 9147/15000 [1:18:37<50:10,  1.94it/s, lr=0.000999, step_loss=0.0607/27/2023 19:03:28 - INFO - __main__ - train loss is 7.55558676389046\n",
      "Steps:  61%|▌| 9148/15000 [1:18:38<50:38,  1.93it/s, lr=0.000999, step_loss=0.1207/27/2023 19:03:28 - INFO - __main__ - train loss is 7.6236522879917175\n",
      "Steps:  61%|▌| 9149/15000 [1:18:39<50:50,  1.92it/s, lr=0.000999, step_loss=0.0607/27/2023 19:03:29 - INFO - __main__ - train loss is 7.627281697234139\n",
      "Steps:  61%|▌| 9150/15000 [1:18:39<51:06,  1.91it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:29 - INFO - __main__ - train loss is 7.703448923071846\n",
      "Steps:  61%|▌| 9151/15000 [1:18:40<51:03,  1.91it/s, lr=0.000999, step_loss=0.0707/27/2023 19:03:30 - INFO - __main__ - train loss is 8.029906781157479\n",
      "Steps:  61%|▌| 9152/15000 [1:18:40<51:08,  1.91it/s, lr=0.000999, step_loss=0.3207/27/2023 19:03:30 - INFO - __main__ - train loss is 8.307032437762246\n",
      "Steps:  61%|▌| 9153/15000 [1:18:41<50:46,  1.92it/s, lr=0.000999, step_loss=0.2707/27/2023 19:03:31 - INFO - __main__ - train loss is 8.688596309861168\n",
      "Steps:  61%|▌| 9154/15000 [1:18:41<50:35,  1.93it/s, lr=0.000999, step_loss=0.3807/27/2023 19:03:31 - INFO - __main__ - train loss is 8.744020307203755\n",
      "Steps:  61%|▌| 9155/15000 [1:18:42<50:20,  1.94it/s, lr=0.000999, step_loss=0.0507/27/2023 19:03:32 - INFO - __main__ - train loss is 9.665052974363789\n",
      "Steps:  61%|▌| 9156/15000 [1:18:42<50:09,  1.94it/s, lr=0.000999, step_loss=0.9207/27/2023 19:03:32 - INFO - __main__ - train loss is 9.682628551265225\n",
      "Steps:  61%|▌| 9157/15000 [1:18:43<50:04,  1.94it/s, lr=0.000999, step_loss=0.0107/27/2023 19:03:33 - INFO - __main__ - train loss is 9.803576240083203\n",
      "Steps:  61%|▌| 9158/15000 [1:18:43<49:50,  1.95it/s, lr=0.000999, step_loss=0.1207/27/2023 19:03:33 - INFO - __main__ - train loss is 10.029217520495877\n",
      "Steps:  61%|▌| 9159/15000 [1:18:44<49:47,  1.96it/s, lr=0.000999, step_loss=0.2207/27/2023 19:03:34 - INFO - __main__ - train loss is 10.094418899854645\n",
      "Steps:  61%|▌| 9160/15000 [1:18:44<49:33,  1.96it/s, lr=0.000999, step_loss=0.0607/27/2023 19:03:34 - INFO - __main__ - train loss is 11.017311768373474\n",
      "Steps:  61%|▌| 9161/15000 [1:18:45<49:39,  1.96it/s, lr=0.000999, step_loss=0.9207/27/2023 19:03:35 - INFO - __main__ - train loss is 11.102095739683136\n",
      "Steps:  61%|▌| 9162/15000 [1:18:45<49:28,  1.97it/s, lr=0.000999, step_loss=0.0807/27/2023 19:03:35 - INFO - __main__ - train loss is 11.125836318125948\n",
      "Steps:  61%|▌| 9163/15000 [1:18:46<49:30,  1.97it/s, lr=0.000999, step_loss=0.0207/27/2023 19:03:36 - INFO - __main__ - train loss is 11.216933434596285\n",
      "Steps:  61%|▌| 9164/15000 [1:18:46<49:35,  1.96it/s, lr=0.000999, step_loss=0.0907/27/2023 19:03:36 - INFO - __main__ - train loss is 11.42576134740375\n",
      "Steps:  61%|▌| 9165/15000 [1:18:47<49:34,  1.96it/s, lr=0.000999, step_loss=0.2007/27/2023 19:03:37 - INFO - __main__ - train loss is 11.447877874365076\n",
      "Steps:  61%|▌| 9166/15000 [1:18:47<49:31,  1.96it/s, lr=0.000999, step_loss=0.0207/27/2023 19:03:37 - INFO - __main__ - train loss is 11.456795980921015\n",
      "Steps:  61%|▌| 9167/15000 [1:18:48<49:48,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:38 - INFO - __main__ - train loss is 11.496026998152956\n",
      "Steps:  61%|▌| 9168/15000 [1:18:48<49:47,  1.95it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:39 - INFO - __main__ - train loss is 12.079182987799868\n",
      "Steps:  61%|▌| 9169/15000 [1:18:49<49:52,  1.95it/s, lr=0.000999, step_loss=0.5807/27/2023 19:03:39 - INFO - __main__ - train loss is 12.12998710363172\n",
      "Steps:  61%|▌| 9170/15000 [1:18:49<49:50,  1.95it/s, lr=0.000999, step_loss=0.0507/27/2023 19:03:40 - INFO - __main__ - train loss is 12.13317230436951\n",
      "Steps:  61%|▌| 9171/15000 [1:18:50<49:43,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:40 - INFO - __main__ - train loss is 12.146039274521172\n",
      "Steps:  61%|▌| 9172/15000 [1:18:50<49:29,  1.96it/s, lr=0.000999, step_loss=0.0107/27/2023 19:03:41 - INFO - __main__ - train loss is 12.152615355327725\n",
      "Steps:  61%|▌| 9173/15000 [1:18:51<49:28,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:41 - INFO - __main__ - train loss is 12.161482755094767\n",
      "Steps:  61%|▌| 9174/15000 [1:18:51<49:25,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:42 - INFO - __main__ - train loss is 12.29764847829938\n",
      "Steps:  61%|▌| 9175/15000 [1:18:52<49:20,  1.97it/s, lr=0.000999, step_loss=0.1307/27/2023 19:03:42 - INFO - __main__ - train loss is 12.453335244208574\n",
      "Steps:  61%|▌| 9176/15000 [1:18:52<49:25,  1.96it/s, lr=0.000999, step_loss=0.1507/27/2023 19:03:43 - INFO - __main__ - train loss is 12.723314840346575\n",
      "Steps:  61%|▌| 9177/15000 [1:18:53<49:23,  1.96it/s, lr=0.000999, step_loss=0.2707/27/2023 19:03:43 - INFO - __main__ - train loss is 12.876882884651423\n",
      "Steps:  61%|▌| 9178/15000 [1:18:53<49:20,  1.97it/s, lr=0.000999, step_loss=0.1507/27/2023 19:03:44 - INFO - __main__ - train loss is 13.444441828876734\n",
      "Steps:  61%|▌| 9179/15000 [1:18:54<49:28,  1.96it/s, lr=0.000999, step_loss=0.5607/27/2023 19:03:44 - INFO - __main__ - train loss is 13.447020373307168\n",
      "Steps:  61%|▌| 9180/15000 [1:18:54<49:33,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:45 - INFO - __main__ - train loss is 13.547685510478914\n",
      "Steps:  61%|▌| 9181/15000 [1:18:55<49:27,  1.96it/s, lr=0.000999, step_loss=0.1007/27/2023 19:03:45 - INFO - __main__ - train loss is 13.666736758314073\n",
      "Steps:  61%|▌| 9182/15000 [1:18:55<49:31,  1.96it/s, lr=0.000999, step_loss=0.1107/27/2023 19:03:46 - INFO - __main__ - train loss is 13.727564751170576\n",
      "Steps:  61%|▌| 9183/15000 [1:18:56<50:46,  1.91it/s, lr=0.000999, step_loss=0.0607/27/2023 19:03:46 - INFO - __main__ - train loss is 13.73115323856473\n",
      "Steps:  61%|▌| 9184/15000 [1:18:57<52:04,  1.86it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:47 - INFO - __main__ - train loss is 13.809725288301706\n",
      "Steps:  61%|▌| 9185/15000 [1:18:57<54:47,  1.77it/s, lr=0.000999, step_loss=0.0707/27/2023 19:03:47 - INFO - __main__ - train loss is 13.82261916063726\n",
      "Steps:  61%|▌| 9186/15000 [1:18:58<53:53,  1.80it/s, lr=0.000999, step_loss=0.0107/27/2023 19:03:48 - INFO - __main__ - train loss is 13.861423877999187\n",
      "Steps:  61%|▌| 9187/15000 [1:18:58<52:38,  1.84it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:48 - INFO - __main__ - train loss is 14.088717667385936\n",
      "Steps:  61%|▌| 9188/15000 [1:18:59<52:00,  1.86it/s, lr=0.000999, step_loss=0.2207/27/2023 19:03:49 - INFO - __main__ - train loss is 14.146688198670745\n",
      "Steps:  61%|▌| 9189/15000 [1:18:59<51:11,  1.89it/s, lr=0.000999, step_loss=0.0507/27/2023 19:03:49 - INFO - __main__ - train loss is 14.450369691476226\n",
      "Steps:  61%|▌| 9190/15000 [1:19:00<50:46,  1.91it/s, lr=0.000999, step_loss=0.3007/27/2023 19:03:50 - INFO - __main__ - train loss is 14.489529324695468\n",
      "Steps:  61%|▌| 9191/15000 [1:19:00<50:21,  1.92it/s, lr=0.000999, step_loss=0.0307/27/2023 19:03:50 - INFO - __main__ - train loss is 14.57003934495151\n",
      "Steps:  61%|▌| 9192/15000 [1:19:01<50:04,  1.93it/s, lr=0.000999, step_loss=0.0807/27/2023 19:03:51 - INFO - __main__ - train loss is 15.080612255260348\n",
      "Steps:  61%|▌| 9193/15000 [1:19:01<49:50,  1.94it/s, lr=0.000999, step_loss=0.5107/27/2023 19:03:52 - INFO - __main__ - train loss is 15.151257200166583\n",
      "Steps:  61%|▌| 9194/15000 [1:19:02<49:42,  1.95it/s, lr=0.000999, step_loss=0.0707/27/2023 19:03:52 - INFO - __main__ - train loss is 15.382320059463382\n",
      "Steps:  61%|▌| 9195/15000 [1:19:02<49:37,  1.95it/s, lr=0.000999, step_loss=0.2307/27/2023 19:03:53 - INFO - __main__ - train loss is 15.386860495898873\n",
      "Steps:  61%|▌| 9196/15000 [1:19:03<49:33,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:53 - INFO - __main__ - train loss is 15.389145755209029\n",
      "Steps:  61%|▌| 9197/15000 [1:19:03<49:40,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:54 - INFO - __main__ - train loss is 15.397442446090281\n",
      "Steps:  61%|▌| 9198/15000 [1:19:04<49:36,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:54 - INFO - __main__ - train loss is 15.553199545480311\n",
      "Steps:  61%|▌| 9199/15000 [1:19:04<49:33,  1.95it/s, lr=0.000999, step_loss=0.1507/27/2023 19:03:55 - INFO - __main__ - train loss is 16.28056670818478\n",
      "Steps:  61%|▌| 9200/15000 [1:19:05<49:34,  1.95it/s, lr=0.000999, step_loss=0.7207/27/2023 19:03:55 - INFO - __main__ - train loss is 16.32820133958012\n",
      "Steps:  61%|▌| 9201/15000 [1:19:05<49:24,  1.96it/s, lr=0.000999, step_loss=0.0407/27/2023 19:03:56 - INFO - __main__ - train loss is 16.408722155727446\n",
      "Steps:  61%|▌| 9202/15000 [1:19:06<49:49,  1.94it/s, lr=0.000999, step_loss=0.0807/27/2023 19:03:56 - INFO - __main__ - train loss is 16.64708059374243\n",
      "Steps:  61%|▌| 9203/15000 [1:19:06<49:40,  1.94it/s, lr=0.000999, step_loss=0.2307/27/2023 19:03:57 - INFO - __main__ - train loss is 17.211163216270506\n",
      "Steps:  61%|▌| 9204/15000 [1:19:07<49:31,  1.95it/s, lr=0.000999, step_loss=0.5607/27/2023 19:03:57 - INFO - __main__ - train loss is 17.28372620884329\n",
      "Steps:  61%|▌| 9205/15000 [1:19:07<49:21,  1.96it/s, lr=0.000999, step_loss=0.0707/27/2023 19:03:58 - INFO - __main__ - train loss is 17.2880983017385\n",
      "Steps:  61%|▌| 9206/15000 [1:19:08<49:22,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:58 - INFO - __main__ - train loss is 17.29130293428898\n",
      "Steps:  61%|▌| 9207/15000 [1:19:08<49:12,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:03:59 - INFO - __main__ - train loss is 17.48652584850788\n",
      "Steps:  61%|▌| 9208/15000 [1:19:09<49:19,  1.96it/s, lr=0.000999, step_loss=0.1907/27/2023 19:03:59 - INFO - __main__ - train loss is 17.50266246497631\n",
      "Steps:  61%|▌| 9209/15000 [1:19:10<49:10,  1.96it/s, lr=0.000999, step_loss=0.0107/27/2023 19:04:00 - INFO - __main__ - train loss is 17.54051200300455\n",
      "Steps:  61%|▌| 9210/15000 [1:19:10<49:12,  1.96it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:00 - INFO - __main__ - train loss is 17.637193225324154\n",
      "Steps:  61%|▌| 9211/15000 [1:19:11<49:10,  1.96it/s, lr=0.000999, step_loss=0.0907/27/2023 19:04:01 - INFO - __main__ - train loss is 17.639876573346555\n",
      "Steps:  61%|▌| 9212/15000 [1:19:11<49:05,  1.97it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:01 - INFO - __main__ - train loss is 17.688639081083238\n",
      "Steps:  61%|▌| 9213/15000 [1:19:12<49:08,  1.96it/s, lr=0.000999, step_loss=0.0407/27/2023 19:04:02 - INFO - __main__ - train loss is 17.708829880692065\n",
      "Steps:  61%|▌| 9214/15000 [1:19:12<49:04,  1.97it/s, lr=0.000999, step_loss=0.0207/27/2023 19:04:02 - INFO - __main__ - train loss is 17.976212442852557\n",
      "Steps:  61%|▌| 9215/15000 [1:19:13<49:13,  1.96it/s, lr=0.000999, step_loss=0.2607/27/2023 19:04:03 - INFO - __main__ - train loss is 17.983018931001425\n",
      "Steps:  61%|▌| 9216/15000 [1:19:13<49:10,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:03 - INFO - __main__ - train loss is 18.014829132705927\n",
      "Steps:  61%|▌| 9217/15000 [1:19:14<49:12,  1.96it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:04 - INFO - __main__ - train loss is 18.21850484982133\n",
      "Steps:  61%|▌| 9218/15000 [1:19:14<49:23,  1.95it/s, lr=0.000999, step_loss=0.2007/27/2023 19:04:04 - INFO - __main__ - train loss is 18.258194904774427\n",
      "Steps:  61%|▌| 9219/15000 [1:19:15<49:23,  1.95it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:05 - INFO - __main__ - train loss is 18.344941210001707\n",
      "Steps:  61%|▌| 9220/15000 [1:19:15<49:24,  1.95it/s, lr=0.000999, step_loss=0.0807/27/2023 19:04:05 - INFO - __main__ - train loss is 18.937632512301207\n",
      "Steps:  61%|▌| 9221/15000 [1:19:16<49:24,  1.95it/s, lr=0.000999, step_loss=0.5907/27/2023 19:04:06 - INFO - __main__ - train loss is 18.999154027551413\n",
      "Steps:  61%|▌| 9222/15000 [1:19:16<49:25,  1.95it/s, lr=0.000999, step_loss=0.0607/27/2023 19:04:06 - INFO - __main__ - train loss is 19.034104898571968\n",
      "Steps:  61%|▌| 9223/15000 [1:19:17<49:29,  1.95it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:07 - INFO - __main__ - train loss is 19.20805774629116\n",
      "Steps:  61%|▌| 9224/15000 [1:19:17<49:25,  1.95it/s, lr=0.000999, step_loss=0.1707/27/2023 19:04:07 - INFO - __main__ - train loss is 19.258398074656725\n",
      "Steps:  62%|▌| 9225/15000 [1:19:18<49:56,  1.93it/s, lr=0.000999, step_loss=0.0507/27/2023 19:04:08 - INFO - __main__ - train loss is 19.526123482733965\n",
      "Steps:  62%|▌| 9226/15000 [1:19:18<49:42,  1.94it/s, lr=0.000999, step_loss=0.2607/27/2023 19:04:08 - INFO - __main__ - train loss is 19.616476643830538\n",
      "Steps:  62%|▌| 9227/15000 [1:19:19<49:27,  1.95it/s, lr=0.000999, step_loss=0.0907/27/2023 19:04:09 - INFO - __main__ - train loss is 19.65955438837409\n",
      "Steps:  62%|▌| 9228/15000 [1:19:19<49:14,  1.95it/s, lr=0.000999, step_loss=0.0407/27/2023 19:04:09 - INFO - __main__ - train loss is 19.73369374498725\n",
      "Steps:  62%|▌| 9229/15000 [1:19:20<49:12,  1.95it/s, lr=0.000999, step_loss=0.0707/27/2023 19:04:10 - INFO - __main__ - train loss is 19.86762162670493\n",
      "Steps:  62%|▌| 9230/15000 [1:19:20<49:10,  1.96it/s, lr=0.000999, step_loss=0.1307/27/2023 19:04:10 - INFO - __main__ - train loss is 19.873231237754226\n",
      "Steps:  62%|▌| 9231/15000 [1:19:21<48:29,  1.98it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:11 - INFO - __main__ - train loss is 19.8986509218812\n",
      "Steps:  62%|▌| 9232/15000 [1:19:21<48:44,  1.97it/s, lr=0.000999, step_loss=0.0207/27/2023 19:04:11 - INFO - __main__ - train loss is 19.89968391880393\n",
      "Steps:  62%|▌| 9233/15000 [1:19:22<49:08,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:12 - INFO - __main__ - train loss is 19.90856774803251\n",
      "Steps:  62%|▌| 9234/15000 [1:19:22<49:07,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:12 - INFO - __main__ - train loss is 19.91237133089453\n",
      "Steps:  62%|▌| 9235/15000 [1:19:23<49:00,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:13 - INFO - __main__ - train loss is 20.092982255853713\n",
      "Steps:  62%|▌| 9236/15000 [1:19:23<49:10,  1.95it/s, lr=0.000999, step_loss=0.1807/27/2023 19:04:14 - INFO - __main__ - train loss is 20.258222662843764\n",
      "Steps:  62%|▌| 9237/15000 [1:19:24<48:58,  1.96it/s, lr=0.000999, step_loss=0.1607/27/2023 19:04:14 - INFO - __main__ - train loss is 20.293403149582446\n",
      "Steps:  62%|▌| 9238/15000 [1:19:24<48:57,  1.96it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:15 - INFO - __main__ - train loss is 20.303079877980053\n",
      "Steps:  62%|▌| 9239/15000 [1:19:25<48:39,  1.97it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:15 - INFO - __main__ - train loss is 20.920922671444714\n",
      "Steps:  62%|▌| 9240/15000 [1:19:25<48:45,  1.97it/s, lr=0.000999, step_loss=0.6107/27/2023 19:04:16 - INFO - __main__ - train loss is 21.61258313525468\n",
      "Steps:  62%|▌| 9241/15000 [1:19:26<48:48,  1.97it/s, lr=0.000999, step_loss=0.6907/27/2023 19:04:16 - INFO - __main__ - train loss is 21.649092067964375\n",
      "Steps:  62%|▌| 9242/15000 [1:19:26<48:43,  1.97it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:17 - INFO - __main__ - train loss is 21.657817314378917\n",
      "Steps:  62%|▌| 9243/15000 [1:19:27<48:42,  1.97it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:17 - INFO - __main__ - train loss is 21.894807959906757\n",
      "Steps:  62%|▌| 9244/15000 [1:19:27<48:45,  1.97it/s, lr=0.000999, step_loss=0.2307/27/2023 19:04:18 - INFO - __main__ - train loss is 21.906644091941416\n",
      "Steps:  62%|▌| 9245/15000 [1:19:28<48:44,  1.97it/s, lr=0.000999, step_loss=0.0107/27/2023 19:04:18 - INFO - __main__ - train loss is 22.324736521579325\n",
      "Steps:  62%|▌| 9246/15000 [1:19:28<48:51,  1.96it/s, lr=0.000999, step_loss=0.4107/27/2023 19:04:19 - INFO - __main__ - train loss is 22.32847364526242\n",
      "Steps:  62%|▌| 9247/15000 [1:19:29<48:52,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:19 - INFO - __main__ - train loss is 22.530488925985992\n",
      "Steps:  62%|▌| 9248/15000 [1:19:29<48:51,  1.96it/s, lr=0.000999, step_loss=0.2007/27/2023 19:04:20 - INFO - __main__ - train loss is 22.81232653837651\n",
      "Steps:  62%|▌| 9249/15000 [1:19:30<48:53,  1.96it/s, lr=0.000999, step_loss=0.2807/27/2023 19:04:20 - INFO - __main__ - train loss is 22.81857474707067\n",
      "Steps:  62%|▌| 9250/15000 [1:19:30<49:00,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:21 - INFO - __main__ - train loss is 22.863309456035495\n",
      "Steps:  62%|▌| 9251/15000 [1:19:31<49:13,  1.95it/s, lr=0.000999, step_loss=0.0407/27/2023 19:04:21 - INFO - __main__ - train loss is 22.867370071820915\n",
      "Steps:  62%|▌| 9252/15000 [1:19:31<49:00,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:22 - INFO - __main__ - train loss is 22.985755148343742\n",
      "Steps:  62%|▌| 9253/15000 [1:19:32<48:52,  1.96it/s, lr=0.000999, step_loss=0.1107/27/2023 19:04:22 - INFO - __main__ - train loss is 22.987826447933912\n",
      "Steps:  62%|▌| 9254/15000 [1:19:32<48:51,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:23 - INFO - __main__ - train loss is 23.546750526875257\n",
      "Steps:  62%|▌| 9255/15000 [1:19:33<48:47,  1.96it/s, lr=0.000999, step_loss=0.5507/27/2023 19:04:23 - INFO - __main__ - train loss is 23.957501631230116\n",
      "Steps:  62%|▌| 9256/15000 [1:19:34<48:51,  1.96it/s, lr=0.000999, step_loss=0.4107/27/2023 19:04:24 - INFO - __main__ - train loss is 24.01484813168645\n",
      "Steps:  62%|▌| 9257/15000 [1:19:34<48:53,  1.96it/s, lr=0.000999, step_loss=0.0507/27/2023 19:04:24 - INFO - __main__ - train loss is 24.04737586900592\n",
      "Steps:  62%|▌| 9258/15000 [1:19:35<48:51,  1.96it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:25 - INFO - __main__ - train loss is 24.06037433911115\n",
      "Steps:  62%|▌| 9259/15000 [1:19:35<48:46,  1.96it/s, lr=0.000999, step_loss=0.0107/27/2023 19:04:25 - INFO - __main__ - train loss is 24.066089088097215\n",
      "Steps:  62%|▌| 9260/15000 [1:19:36<48:53,  1.96it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:26 - INFO - __main__ - train loss is 24.08399142511189\n",
      "Steps:  62%|▌| 9261/15000 [1:19:36<48:49,  1.96it/s, lr=0.000999, step_loss=0.0107/27/2023 19:04:26 - INFO - __main__ - train loss is 24.090922213625163\n",
      "Steps:  62%|▌| 9262/15000 [1:19:37<48:58,  1.95it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:27 - INFO - __main__ - train loss is 24.132352638524026\n",
      "Steps:  62%|▌| 9263/15000 [1:19:37<51:56,  1.84it/s, lr=0.000999, step_loss=0.0407/27/2023 19:04:27 - INFO - __main__ - train loss is 24.279265764635056\n",
      "Steps:  62%|▌| 9264/15000 [1:19:38<53:47,  1.78it/s, lr=0.000999, step_loss=0.1407/27/2023 19:04:28 - INFO - __main__ - train loss is 24.28137993137352\n",
      "Steps:  62%|▌| 9265/15000 [1:19:38<53:24,  1.79it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:29 - INFO - __main__ - train loss is 24.41559883276932\n",
      "Steps:  62%|▌| 9266/15000 [1:19:39<53:39,  1.78it/s, lr=0.000999, step_loss=0.1307/27/2023 19:04:29 - INFO - __main__ - train loss is 24.505461149616167\n",
      "Steps:  62%|▌| 9267/15000 [1:19:39<52:46,  1.81it/s, lr=0.000999, step_loss=0.0807/27/2023 19:04:30 - INFO - __main__ - train loss is 24.53022899548523\n",
      "Steps:  62%|▌| 9268/15000 [1:19:40<52:00,  1.84it/s, lr=0.000999, step_loss=0.0207/27/2023 19:04:30 - INFO - __main__ - train loss is 24.537237563403323\n",
      "Steps:  62%|▌| 9269/15000 [1:19:41<51:55,  1.84it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:31 - INFO - __main__ - train loss is 24.538998291129246\n",
      "Steps:  62%|▌| 9270/15000 [1:19:41<51:47,  1.84it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:31 - INFO - __main__ - train loss is 24.63213185989298\n",
      "Steps:  62%|▌| 9271/15000 [1:19:42<52:01,  1.84it/s, lr=0.000999, step_loss=0.0907/27/2023 19:04:32 - INFO - __main__ - train loss is 25.236331030959263\n",
      "Steps:  62%|▌| 9272/15000 [1:19:42<51:30,  1.85it/s, lr=0.000999, step_loss=0.6007/27/2023 19:04:32 - INFO - __main__ - train loss is 25.23996174079366\n",
      "Steps:  62%|▌| 9273/15000 [1:19:43<50:56,  1.87it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:33 - INFO - __main__ - train loss is 25.643528339685872\n",
      "Steps:  62%|▌| 9274/15000 [1:19:43<50:34,  1.89it/s, lr=0.000999, step_loss=0.4007/27/2023 19:04:33 - INFO - __main__ - train loss is 25.967184302629903\n",
      "Steps:  62%|▌| 9275/15000 [1:19:44<50:25,  1.89it/s, lr=0.000999, step_loss=0.3207/27/2023 19:04:34 - INFO - __main__ - train loss is 26.00012977910228\n",
      "Steps:  62%|▌| 9276/15000 [1:19:44<50:03,  1.91it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:34 - INFO - __main__ - train loss is 26.012707750545815\n",
      "Steps:  62%|▌| 9277/15000 [1:19:45<49:42,  1.92it/s, lr=0.000999, step_loss=0.0107/27/2023 19:04:35 - INFO - __main__ - train loss is 26.032028473215178\n",
      "Steps:  62%|▌| 9278/15000 [1:19:45<49:25,  1.93it/s, lr=0.000999, step_loss=0.0107/27/2023 19:04:35 - INFO - __main__ - train loss is 26.236219353275374\n",
      "Steps:  62%|▌| 9279/15000 [1:19:46<49:13,  1.94it/s, lr=0.000999, step_loss=0.2007/27/2023 19:04:36 - INFO - __main__ - train loss is 27.07404202898033\n",
      "Steps:  62%|▌| 9280/15000 [1:19:46<49:06,  1.94it/s, lr=0.000999, step_loss=0.8307/27/2023 19:04:36 - INFO - __main__ - train loss is 27.118788219289854\n",
      "Steps:  62%|▌| 9281/15000 [1:19:47<49:04,  1.94it/s, lr=0.000999, step_loss=0.0407/27/2023 19:04:37 - INFO - __main__ - train loss is 27.127973365830258\n",
      "Steps:  62%|▌| 9282/15000 [1:19:47<49:14,  1.94it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:37 - INFO - __main__ - train loss is 27.597841578768566\n",
      "Steps:  62%|▌| 9283/15000 [1:19:48<49:00,  1.94it/s, lr=0.000999, step_loss=0.4707/27/2023 19:04:38 - INFO - __main__ - train loss is 27.879889625357464\n",
      "Steps:  62%|▌| 9284/15000 [1:19:48<48:50,  1.95it/s, lr=0.000999, step_loss=0.2807/27/2023 19:04:39 - INFO - __main__ - train loss is 28.179587471531704\n",
      "Steps:  62%|▌| 9285/15000 [1:19:49<48:46,  1.95it/s, lr=0.000999, step_loss=0.3]07/27/2023 19:04:39 - INFO - __main__ - train loss is 28.210847976850346\n",
      "Steps:  62%|▌| 9286/15000 [1:19:49<48:53,  1.95it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:40 - INFO - __main__ - train loss is 28.22892630030401\n",
      "Steps:  62%|▌| 9287/15000 [1:19:50<48:45,  1.95it/s, lr=0.000999, step_loss=0.0107/27/2023 19:04:40 - INFO - __main__ - train loss is 28.273954301374033\n",
      "Steps:  62%|▌| 9288/15000 [1:19:50<48:44,  1.95it/s, lr=0.000999, step_loss=0.0407/27/2023 19:04:41 - INFO - __main__ - train loss is 28.543726979987696\n",
      "Steps:  62%|▌| 9289/15000 [1:19:51<48:48,  1.95it/s, lr=0.000999, step_loss=0.2707/27/2023 19:04:41 - INFO - __main__ - train loss is 28.579677320318297\n",
      "Steps:  62%|▌| 9290/15000 [1:19:51<48:48,  1.95it/s, lr=0.000999, step_loss=0.0307/27/2023 19:04:42 - INFO - __main__ - train loss is 28.777506060199812\n",
      "Steps:  62%|▌| 9291/15000 [1:19:52<48:56,  1.94it/s, lr=0.000999, step_loss=0.1907/27/2023 19:04:42 - INFO - __main__ - train loss is 28.78457621135749\n",
      "Steps:  62%|▌| 9292/15000 [1:19:52<48:57,  1.94it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:43 - INFO - __main__ - train loss is 28.907150972867385\n",
      "Steps:  62%|▌| 9293/15000 [1:19:53<49:10,  1.93it/s, lr=0.000999, step_loss=0.1207/27/2023 19:04:43 - INFO - __main__ - train loss is 28.969743464374915\n",
      "Steps:  62%|▌| 9294/15000 [1:19:53<49:08,  1.93it/s, lr=0.000999, step_loss=0.0607/27/2023 19:04:44 - INFO - __main__ - train loss is 29.116375494981185\n",
      "Steps:  62%|▌| 9295/15000 [1:19:54<49:14,  1.93it/s, lr=0.000999, step_loss=0.1407/27/2023 19:04:44 - INFO - __main__ - train loss is 29.159466359997168\n",
      "Steps:  62%|▌| 9296/15000 [1:19:54<49:01,  1.94it/s, lr=0.000999, step_loss=0.0407/27/2023 19:04:45 - INFO - __main__ - train loss is 29.16108057880774\n",
      "Steps:  62%|▌| 9297/15000 [1:19:55<49:00,  1.94it/s, lr=0.000999, step_loss=0.0007/27/2023 19:04:45 - INFO - __main__ - train loss is 29.185325211379677\n",
      "Steps:  62%|▌| 9298/15000 [1:19:56<48:34,  1.96it/s, lr=0.000999, step_loss=0.0207/27/2023 19:04:46 - INFO - __main__ - train loss is 29.32937506446615\n",
      "Steps:  62%|▌| 9299/15000 [1:19:56<48:40,  1.95it/s, lr=0.000999, step_loss=0.1407/27/2023 19:04:46 - INFO - __main__ - train loss is 29.688645428512245\n",
      "Steps:  62%|▌| 9300/15000 [1:19:57<48:42,  1.95it/s, lr=0.000998, step_loss=0.3507/27/2023 19:04:47 - INFO - __main__ - train loss is 29.69189987750724\n",
      "Steps:  62%|▌| 9301/15000 [1:19:57<48:39,  1.95it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:47 - INFO - __main__ - train loss is 29.71596181811765\n",
      "Steps:  62%|▌| 9302/15000 [1:19:58<48:29,  1.96it/s, lr=0.000998, step_loss=0.0207/27/2023 19:04:48 - INFO - __main__ - train loss is 29.9066849690862\n",
      "Steps:  62%|▌| 9303/15000 [1:19:58<48:33,  1.96it/s, lr=0.000998, step_loss=0.1907/27/2023 19:04:48 - INFO - __main__ - train loss is 29.916529344860464\n",
      "Steps:  62%|▌| 9304/15000 [1:19:59<48:33,  1.96it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:49 - INFO - __main__ - train loss is 30.25432692700997\n",
      "Steps:  62%|▌| 9305/15000 [1:19:59<48:57,  1.94it/s, lr=0.000998, step_loss=0.3307/27/2023 19:04:49 - INFO - __main__ - train loss is 30.508175330702215\n",
      "Steps:  62%|▌| 9306/15000 [1:20:00<48:44,  1.95it/s, lr=0.000998, step_loss=0.2507/27/2023 19:04:50 - INFO - __main__ - train loss is 30.564900929573923\n",
      "Steps:  62%|▌| 9307/15000 [1:20:00<48:39,  1.95it/s, lr=0.000998, step_loss=0.0507/27/2023 19:04:50 - INFO - __main__ - train loss is 30.67439170414582\n",
      "Steps:  62%|▌| 9308/15000 [1:20:01<48:32,  1.95it/s, lr=0.000998, step_loss=0.1007/27/2023 19:04:51 - INFO - __main__ - train loss is 30.78306325012818\n",
      "Steps:  62%|▌| 9309/15000 [1:20:01<48:52,  1.94it/s, lr=0.000998, step_loss=0.1007/27/2023 19:04:51 - INFO - __main__ - train loss is 30.88417402142659\n",
      "Steps:  62%|▌| 9310/15000 [1:20:02<48:52,  1.94it/s, lr=0.000998, step_loss=0.1007/27/2023 19:04:52 - INFO - __main__ - train loss is 30.886879005935043\n",
      "Steps:  62%|▌| 9311/15000 [1:20:02<48:58,  1.94it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:52 - INFO - __main__ - train loss is 30.896092215087265\n",
      "Steps:  62%|▌| 9312/15000 [1:20:03<48:51,  1.94it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:53 - INFO - __main__ - train loss is 30.901030876673758\n",
      "Steps:  62%|▌| 9313/15000 [1:20:03<48:47,  1.94it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:53 - INFO - __main__ - train loss is 30.924099472351372\n",
      "Steps:  62%|▌| 9314/15000 [1:20:04<48:37,  1.95it/s, lr=0.000998, step_loss=0.0207/27/2023 19:04:54 - INFO - __main__ - train loss is 30.93398772086948\n",
      "Steps:  62%|▌| 9315/15000 [1:20:04<48:33,  1.95it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:54 - INFO - __main__ - train loss is 31.154047592543066\n",
      "Steps:  62%|▌| 9316/15000 [1:20:05<48:38,  1.95it/s, lr=0.000998, step_loss=0.2207/27/2023 19:04:55 - INFO - __main__ - train loss is 31.226356266997755\n",
      "Steps:  62%|▌| 9317/15000 [1:20:05<48:23,  1.96it/s, lr=0.000998, step_loss=0.0707/27/2023 19:04:55 - INFO - __main__ - train loss is 31.232171356212348\n",
      "Steps:  62%|▌| 9318/15000 [1:20:06<48:22,  1.96it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:56 - INFO - __main__ - train loss is 31.360264390241355\n",
      "Steps:  62%|▌| 9319/15000 [1:20:06<48:35,  1.95it/s, lr=0.000998, step_loss=0.1207/27/2023 19:04:56 - INFO - __main__ - train loss is 31.621145337354392\n",
      "Steps:  62%|▌| 9320/15000 [1:20:07<48:29,  1.95it/s, lr=0.000998, step_loss=0.2607/27/2023 19:04:57 - INFO - __main__ - train loss is 31.623378356685862\n",
      "Steps:  62%|▌| 9321/15000 [1:20:07<48:24,  1.96it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:58 - INFO - __main__ - train loss is 32.15261908411048\n",
      "Steps:  62%|▌| 9322/15000 [1:20:08<48:27,  1.95it/s, lr=0.000998, step_loss=0.5207/27/2023 19:04:58 - INFO - __main__ - train loss is 32.160030625527725\n",
      "Steps:  62%|▌| 9323/15000 [1:20:08<48:31,  1.95it/s, lr=0.000998, step_loss=0.0007/27/2023 19:04:59 - INFO - __main__ - train loss is 32.33767046756111\n",
      "Steps:  62%|▌| 9324/15000 [1:20:09<48:22,  1.96it/s, lr=0.000998, step_loss=0.1707/27/2023 19:04:59 - INFO - __main__ - train loss is 32.37110675848089\n",
      "Steps:  62%|▌| 9325/15000 [1:20:09<48:17,  1.96it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:00 - INFO - __main__ - train loss is 32.460714287823066\n",
      "Steps:  62%|▌| 9326/15000 [1:20:10<48:19,  1.96it/s, lr=0.000998, step_loss=0.0807/27/2023 19:05:00 - INFO - __main__ - train loss is 32.47022231738083\n",
      "Steps:  62%|▌| 9327/15000 [1:20:10<48:20,  1.96it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:01 - INFO - __main__ - train loss is 32.6121827296447\n",
      "Steps:  62%|▌| 9328/15000 [1:20:11<48:24,  1.95it/s, lr=0.000998, step_loss=0.1407/27/2023 19:05:01 - INFO - __main__ - train loss is 32.61481454526074\n",
      "Steps:  62%|▌| 9329/15000 [1:20:11<48:28,  1.95it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:02 - INFO - __main__ - train loss is 32.62207708437927\n",
      "Steps:  62%|▌| 9330/15000 [1:20:12<48:29,  1.95it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:02 - INFO - __main__ - train loss is 32.77997056324966\n",
      "Steps:  62%|▌| 9331/15000 [1:20:12<48:21,  1.95it/s, lr=0.000998, step_loss=0.1507/27/2023 19:05:03 - INFO - __main__ - train loss is 32.79962994647212\n",
      "Steps:  62%|▌| 9332/15000 [1:20:13<48:20,  1.95it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:03 - INFO - __main__ - train loss is 33.11320598912425\n",
      "Steps:  62%|▌| 9333/15000 [1:20:13<48:16,  1.96it/s, lr=0.000998, step_loss=0.3107/27/2023 19:05:04 - INFO - __main__ - train loss is 33.16566135850735\n",
      "Steps:  62%|▌| 9334/15000 [1:20:14<48:19,  1.95it/s, lr=0.000998, step_loss=0.0507/27/2023 19:05:04 - INFO - __main__ - train loss is 33.16925246664323\n",
      "Steps:  62%|▌| 9335/15000 [1:20:14<48:11,  1.96it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:05 - INFO - __main__ - train loss is 33.18550233566202\n",
      "Steps:  62%|▌| 9336/15000 [1:20:15<48:10,  1.96it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:05 - INFO - __main__ - train loss is 33.366194263333455\n",
      "Steps:  62%|▌| 9337/15000 [1:20:15<48:06,  1.96it/s, lr=0.000998, step_loss=0.1807/27/2023 19:05:06 - INFO - __main__ - train loss is 33.59046858572401\n",
      "Steps:  62%|▌| 9338/15000 [1:20:16<48:06,  1.96it/s, lr=0.000998, step_loss=0.2207/27/2023 19:05:06 - INFO - __main__ - train loss is 33.81589302443899\n",
      "Steps:  62%|▌| 9339/15000 [1:20:17<48:02,  1.96it/s, lr=0.000998, step_loss=0.2207/27/2023 19:05:07 - INFO - __main__ - train loss is 33.8946979122702\n",
      "Steps:  62%|▌| 9340/15000 [1:20:17<48:00,  1.97it/s, lr=0.000998, step_loss=0.0707/27/2023 19:05:07 - INFO - __main__ - train loss is 33.97907202714123\n",
      "Steps:  62%|▌| 9341/15000 [1:20:18<47:56,  1.97it/s, lr=0.000998, step_loss=0.0807/27/2023 19:05:08 - INFO - __main__ - train loss is 34.00748245068826\n",
      "Steps:  62%|▌| 9342/15000 [1:20:18<47:52,  1.97it/s, lr=0.000998, step_loss=0.0207/27/2023 19:05:08 - INFO - __main__ - train loss is 34.15247992821969\n",
      "Steps:  62%|▌| 9343/15000 [1:20:19<47:57,  1.97it/s, lr=0.000998, step_loss=0.1407/27/2023 19:05:09 - INFO - __main__ - train loss is 34.273450795793906\n",
      "Steps:  62%|▌| 9344/15000 [1:20:19<47:53,  1.97it/s, lr=0.000998, step_loss=0.1207/27/2023 19:05:09 - INFO - __main__ - train loss is 34.33537435927428\n",
      "Steps:  62%|▌| 9345/15000 [1:20:20<47:54,  1.97it/s, lr=0.000998, step_loss=0.0607/27/2023 19:05:10 - INFO - __main__ - train loss is 34.675322596216574\n",
      "Steps:  62%|▌| 9346/15000 [1:20:20<48:55,  1.93it/s, lr=0.000998, step_loss=0.3407/27/2023 19:05:10 - INFO - __main__ - train loss is 34.859907780075446\n",
      "Steps:  62%|▌| 9347/15000 [1:20:21<50:35,  1.86it/s, lr=0.000998, step_loss=0.1807/27/2023 19:05:11 - INFO - __main__ - train loss is 34.87869332008995\n",
      "Steps:  62%|▌| 9348/15000 [1:20:21<50:51,  1.85it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:11 - INFO - __main__ - train loss is 35.08599064522423\n",
      "Steps:  62%|▌| 9349/15000 [1:20:22<50:14,  1.87it/s, lr=0.000998, step_loss=0.2007/27/2023 19:05:12 - INFO - __main__ - train loss is 35.64576713019051\n",
      "Steps:  62%|▌| 9350/15000 [1:20:22<50:22,  1.87it/s, lr=0.000998, step_loss=0.5607/27/2023 19:05:12 - INFO - __main__ - train loss is 35.71976114832796\n",
      "Steps:  62%|▌| 9351/15000 [1:20:23<50:27,  1.87it/s, lr=0.000998, step_loss=0.0707/27/2023 19:05:13 - INFO - __main__ - train loss is 35.850961938733235\n",
      "Steps:  62%|▌| 9352/15000 [1:20:23<49:39,  1.90it/s, lr=0.000998, step_loss=0.1307/27/2023 19:05:14 - INFO - __main__ - train loss is 36.02946914755739\n",
      "Steps:  62%|▌| 9353/15000 [1:20:24<49:10,  1.91it/s, lr=0.000998, step_loss=0.1707/27/2023 19:05:14 - INFO - __main__ - train loss is 36.26728183054365\n",
      "Steps:  62%|▌| 9354/15000 [1:20:24<48:24,  1.94it/s, lr=0.000998, step_loss=0.2307/27/2023 19:05:15 - INFO - __main__ - train loss is 36.30712077044882\n",
      "Steps:  62%|▌| 9355/15000 [1:20:25<48:42,  1.93it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:15 - INFO - __main__ - train loss is 36.31993069150485\n",
      "Steps:  62%|▌| 9356/15000 [1:20:25<48:51,  1.93it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:16 - INFO - __main__ - train loss is 36.33732157968916\n",
      "Steps:  62%|▌| 9357/15000 [1:20:26<48:29,  1.94it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:16 - INFO - __main__ - train loss is 36.37024777405895\n",
      "Steps:  62%|▌| 9358/15000 [1:20:26<48:19,  1.95it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:17 - INFO - __main__ - train loss is 36.90072970860638\n",
      "Steps:  62%|▌| 9359/15000 [1:20:27<48:10,  1.95it/s, lr=0.000998, step_loss=0.5307/27/2023 19:05:17 - INFO - __main__ - train loss is 36.93445656471886\n",
      "Steps:  62%|▌| 9360/15000 [1:20:27<48:00,  1.96it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:18 - INFO - __main__ - train loss is 37.27597925835289\n",
      "Steps:  62%|▌| 9361/15000 [1:20:28<47:56,  1.96it/s, lr=0.000998, step_loss=0.3407/27/2023 19:05:18 - INFO - __main__ - train loss is 37.66618011170067\n",
      "Steps:  62%|▌| 9362/15000 [1:20:28<48:03,  1.96it/s, lr=0.000998, step_loss=0.3907/27/2023 19:05:19 - INFO - __main__ - train loss is 37.69536402844824\n",
      "Steps:  62%|▌| 9363/15000 [1:20:29<47:49,  1.96it/s, lr=0.000998, step_loss=0.0207/27/2023 19:05:19 - INFO - __main__ - train loss is 37.70756275416352\n",
      "Steps:  62%|▌| 9364/15000 [1:20:29<47:47,  1.97it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:20 - INFO - __main__ - train loss is 37.756538352230564\n",
      "Steps:  62%|▌| 9365/15000 [1:20:30<47:50,  1.96it/s, lr=0.000998, step_loss=0.0407/27/2023 19:05:20 - INFO - __main__ - train loss is 37.76941286143847\n",
      "Steps:  62%|▌| 9366/15000 [1:20:30<48:00,  1.96it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:21 - INFO - __main__ - train loss is 37.77913280879147\n",
      "Steps:  62%|▌| 9367/15000 [1:20:31<47:50,  1.96it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:21 - INFO - __main__ - train loss is 38.13151728664525\n",
      "Steps:  62%|▌| 9368/15000 [1:20:32<48:16,  1.94it/s, lr=0.000998, step_loss=0.3507/27/2023 19:05:22 - INFO - __main__ - train loss is 38.30666651879437\n",
      "Steps:  62%|▌| 9369/15000 [1:20:32<48:15,  1.95it/s, lr=0.000998, step_loss=0.1707/27/2023 19:05:22 - INFO - __main__ - train loss is 39.07708766614087\n",
      "Steps:  62%|▌| 9370/15000 [1:20:33<48:07,  1.95it/s, lr=0.000998, step_loss=0.7707/27/2023 19:05:23 - INFO - __main__ - train loss is 39.137946396367624\n",
      "Steps:  62%|▌| 9371/15000 [1:20:33<48:01,  1.95it/s, lr=0.000998, step_loss=0.0607/27/2023 19:05:23 - INFO - __main__ - train loss is 39.32350061764009\n",
      "Steps:  62%|▌| 9372/15000 [1:20:34<47:56,  1.96it/s, lr=0.000998, step_loss=0.1807/27/2023 19:05:24 - INFO - __main__ - train loss is 39.360872118966654\n",
      "Steps:  62%|▌| 9373/15000 [1:20:34<47:51,  1.96it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:24 - INFO - __main__ - train loss is 39.708698391215876\n",
      "Steps:  62%|▌| 9374/15000 [1:20:35<47:39,  1.97it/s, lr=0.000998, step_loss=0.3407/27/2023 19:05:25 - INFO - __main__ - train loss is 40.28401982714422\n",
      "Steps:  62%|▋| 9375/15000 [1:20:35<47:46,  1.96it/s, lr=0.000998, step_loss=0.5707/27/2023 19:05:25 - INFO - __main__ - train loss is 40.318967825965956\n",
      "Steps:  63%|▋| 9376/15000 [1:20:36<47:35,  1.97it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:26 - INFO - __main__ - train loss is 40.544487393694\n",
      "Steps:  63%|▋| 9377/15000 [1:20:36<47:46,  1.96it/s, lr=0.000998, step_loss=0.2207/27/2023 19:05:26 - INFO - __main__ - train loss is 40.759687564568594\n",
      "Steps:  63%|▋| 9378/15000 [1:20:37<47:44,  1.96it/s, lr=0.000998, step_loss=0.2107/27/2023 19:05:27 - INFO - __main__ - train loss is 40.79500991036184\n",
      "Steps:  63%|▋| 9379/15000 [1:20:37<47:35,  1.97it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:27 - INFO - __main__ - train loss is 40.79674243973568\n",
      "Steps:  63%|▋| 9380/15000 [1:20:38<47:52,  1.96it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:28 - INFO - __main__ - train loss is 40.92578297900036\n",
      "Steps:  63%|▋| 9381/15000 [1:20:38<48:34,  1.93it/s, lr=0.000998, step_loss=0.1207/27/2023 19:05:28 - INFO - __main__ - train loss is 40.92776367953047\n",
      "Steps:  63%|▋| 9382/15000 [1:20:39<48:37,  1.93it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:29 - INFO - __main__ - train loss is 41.15341799845919\n",
      "Steps:  63%|▋| 9383/15000 [1:20:39<48:26,  1.93it/s, lr=0.000998, step_loss=0.2207/27/2023 19:05:29 - INFO - __main__ - train loss is 41.15812649996951\n",
      "Steps:  63%|▋| 9384/15000 [1:20:40<48:23,  1.93it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:30 - INFO - __main__ - train loss is 41.193630610127\n",
      "Steps:  63%|▋| 9385/15000 [1:20:40<48:30,  1.93it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:30 - INFO - __main__ - train loss is 41.195111253182404\n",
      "Steps:  63%|▋| 9386/15000 [1:20:41<48:49,  1.92it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:31 - INFO - __main__ - train loss is 41.20423349447083\n",
      "Steps:  63%|▋| 9387/15000 [1:20:41<49:01,  1.91it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:32 - INFO - __main__ - train loss is 41.25459387234878\n",
      "Steps:  63%|▋| 9388/15000 [1:20:42<49:12,  1.90it/s, lr=0.000998, step_loss=0.0507/27/2023 19:05:32 - INFO - __main__ - train loss is 41.42448230914306\n",
      "Steps:  63%|▋| 9389/15000 [1:20:42<49:27,  1.89it/s, lr=0.000998, step_loss=0.1707/27/2023 19:05:33 - INFO - __main__ - train loss is 41.62961324385833\n",
      "Steps:  63%|▋| 9390/15000 [1:20:43<49:21,  1.89it/s, lr=0.000998, step_loss=0.2007/27/2023 19:05:33 - INFO - __main__ - train loss is 41.63387623045128\n",
      "Steps:  63%|▋| 9391/15000 [1:20:43<49:19,  1.90it/s, lr=0.000998, step_loss=0.0007/27/2023 19:05:34 - INFO - __main__ - train loss is 41.651107825222425\n",
      "Steps:  63%|▋| 9392/15000 [1:20:44<48:56,  1.91it/s, lr=0.000998, step_loss=0.0107/27/2023 19:05:34 - INFO - __main__ - train loss is 41.68409004795831\n",
      "Steps:  63%|▋| 9393/15000 [1:20:45<55:09,  1.69it/s, lr=0.000998, step_loss=0.0307/27/2023 19:05:35 - INFO - __main__ - Per validation step average loss is 0.1092524379491806\n",
      "07/27/2023 19:05:35 - INFO - __main__ - Cumulative validation average loss is 0.1092524379491806\n",
      "07/27/2023 19:05:36 - INFO - __main__ - Per validation step average loss is 0.004066157154738903\n",
      "07/27/2023 19:05:36 - INFO - __main__ - Cumulative validation average loss is 0.1133185951039195\n",
      "07/27/2023 19:05:36 - INFO - __main__ - Per validation step average loss is 0.00914342887699604\n",
      "07/27/2023 19:05:36 - INFO - __main__ - Cumulative validation average loss is 0.12246202398091555\n",
      "07/27/2023 19:05:37 - INFO - __main__ - Per validation step average loss is 0.0033577498979866505\n",
      "07/27/2023 19:05:37 - INFO - __main__ - Cumulative validation average loss is 0.1258197738789022\n",
      "07/27/2023 19:05:37 - INFO - __main__ - Per validation step average loss is 0.0022489989642053843\n",
      "07/27/2023 19:05:37 - INFO - __main__ - Cumulative validation average loss is 0.12806877284310758\n",
      "07/27/2023 19:05:37 - INFO - __main__ - Per validation step average loss is 0.12482142448425293\n",
      "07/27/2023 19:05:37 - INFO - __main__ - Cumulative validation average loss is 0.2528901973273605\n",
      "07/27/2023 19:05:38 - INFO - __main__ - Per validation step average loss is 0.08108591288328171\n",
      "07/27/2023 19:05:38 - INFO - __main__ - Cumulative validation average loss is 0.3339761102106422\n",
      "07/27/2023 19:05:38 - INFO - __main__ - Per validation step average loss is 0.0013975868932902813\n",
      "07/27/2023 19:05:38 - INFO - __main__ - Cumulative validation average loss is 0.3353736971039325\n",
      "07/27/2023 19:05:39 - INFO - __main__ - Per validation step average loss is 0.07756827026605606\n",
      "07/27/2023 19:05:39 - INFO - __main__ - Cumulative validation average loss is 0.41294196736998856\n",
      "07/27/2023 19:05:39 - INFO - __main__ - Per validation step average loss is 0.0427803099155426\n",
      "07/27/2023 19:05:39 - INFO - __main__ - Cumulative validation average loss is 0.45572227728553116\n",
      "07/27/2023 19:05:40 - INFO - __main__ - Per validation step average loss is 0.441433846950531\n",
      "07/27/2023 19:05:40 - INFO - __main__ - Cumulative validation average loss is 0.8971561242360622\n",
      "07/27/2023 19:05:40 - INFO - __main__ - Per validation step average loss is 0.4446922540664673\n",
      "07/27/2023 19:05:40 - INFO - __main__ - Cumulative validation average loss is 1.3418483783025295\n",
      "07/27/2023 19:05:40 - INFO - __main__ - Per validation step average loss is 0.0395350344479084\n",
      "07/27/2023 19:05:40 - INFO - __main__ - Cumulative validation average loss is 1.3813834127504379\n",
      "07/27/2023 19:05:41 - INFO - __main__ - Per validation step average loss is 0.019236735999584198\n",
      "07/27/2023 19:05:41 - INFO - __main__ - Cumulative validation average loss is 1.400620148750022\n",
      "07/27/2023 19:05:41 - INFO - __main__ - Per validation step average loss is 0.13575544953346252\n",
      "07/27/2023 19:05:41 - INFO - __main__ - Cumulative validation average loss is 1.5363755982834846\n",
      "07/27/2023 19:05:42 - INFO - __main__ - Per validation step average loss is 0.17413929104804993\n",
      "07/27/2023 19:05:42 - INFO - __main__ - Cumulative validation average loss is 1.7105148893315345\n",
      "07/27/2023 19:05:42 - INFO - __main__ - Per validation step average loss is 0.10575952380895615\n",
      "07/27/2023 19:05:42 - INFO - __main__ - Cumulative validation average loss is 1.8162744131404907\n",
      "07/27/2023 19:05:42 - INFO - __main__ - Per validation step average loss is 0.0019064820371568203\n",
      "07/27/2023 19:05:42 - INFO - __main__ - Cumulative validation average loss is 1.8181808951776475\n",
      "07/27/2023 19:05:43 - INFO - __main__ - Per validation step average loss is 0.031588245183229446\n",
      "07/27/2023 19:05:43 - INFO - __main__ - Cumulative validation average loss is 1.849769140360877\n",
      "07/27/2023 19:05:43 - INFO - __main__ - Per validation step average loss is 0.4782991409301758\n",
      "07/27/2023 19:05:43 - INFO - __main__ - Cumulative validation average loss is 2.3280682812910527\n",
      "07/27/2023 19:05:44 - INFO - __main__ - Per validation step average loss is 0.06406845897436142\n",
      "07/27/2023 19:05:44 - INFO - __main__ - Cumulative validation average loss is 2.392136740265414\n",
      "07/27/2023 19:05:44 - INFO - __main__ - Per validation step average loss is 0.043661486357450485\n",
      "07/27/2023 19:05:44 - INFO - __main__ - Cumulative validation average loss is 2.4357982266228646\n",
      "07/27/2023 19:05:45 - INFO - __main__ - Per validation step average loss is 0.0193555299192667\n",
      "07/27/2023 19:05:45 - INFO - __main__ - Cumulative validation average loss is 2.4551537565421313\n",
      "07/27/2023 19:05:45 - INFO - __main__ - Per validation step average loss is 0.025366563349962234\n",
      "07/27/2023 19:05:45 - INFO - __main__ - Cumulative validation average loss is 2.4805203198920935\n",
      "07/27/2023 19:05:45 - INFO - __main__ - Per validation step average loss is 0.22978079319000244\n",
      "07/27/2023 19:05:45 - INFO - __main__ - Cumulative validation average loss is 2.710301113082096\n",
      "07/27/2023 19:05:46 - INFO - __main__ - Per validation step average loss is 0.4700447916984558\n",
      "07/27/2023 19:05:46 - INFO - __main__ - Cumulative validation average loss is 3.180345904780552\n",
      "07/27/2023 19:05:46 - INFO - __main__ - Per validation step average loss is 0.05599251016974449\n",
      "07/27/2023 19:05:46 - INFO - __main__ - Cumulative validation average loss is 3.2363384149502963\n",
      "07/27/2023 19:05:47 - INFO - __main__ - Per validation step average loss is 0.06742461025714874\n",
      "07/27/2023 19:05:47 - INFO - __main__ - Cumulative validation average loss is 3.303763025207445\n",
      "07/27/2023 19:05:47 - INFO - __main__ - Per validation step average loss is 0.09224109351634979\n",
      "07/27/2023 19:05:47 - INFO - __main__ - Cumulative validation average loss is 3.396004118723795\n",
      "07/27/2023 19:05:47 - INFO - __main__ - Per validation step average loss is 0.041671328246593475\n",
      "07/27/2023 19:05:47 - INFO - __main__ - Cumulative validation average loss is 3.4376754469703883\n",
      "07/27/2023 19:05:48 - INFO - __main__ - Per validation step average loss is 0.0077552348375320435\n",
      "07/27/2023 19:05:48 - INFO - __main__ - Cumulative validation average loss is 3.4454306818079203\n",
      "07/27/2023 19:05:48 - INFO - __main__ - Per validation step average loss is 0.12253592163324356\n",
      "07/27/2023 19:05:48 - INFO - __main__ - Cumulative validation average loss is 3.567966603441164\n",
      "07/27/2023 19:05:49 - INFO - __main__ - Per validation step average loss is 0.058815598487854004\n",
      "07/27/2023 19:05:49 - INFO - __main__ - Cumulative validation average loss is 3.626782201929018\n",
      "07/27/2023 19:05:49 - INFO - __main__ - Per validation step average loss is 0.2299390435218811\n",
      "07/27/2023 19:05:49 - INFO - __main__ - Cumulative validation average loss is 3.856721245450899\n",
      "07/27/2023 19:05:49 - INFO - __main__ - Per validation step average loss is 0.006639736704528332\n",
      "07/27/2023 19:05:49 - INFO - __main__ - Cumulative validation average loss is 3.8633609821554273\n",
      "07/27/2023 19:05:50 - INFO - __main__ - Per validation step average loss is 0.005957016255706549\n",
      "07/27/2023 19:05:50 - INFO - __main__ - Cumulative validation average loss is 3.869317998411134\n",
      "07/27/2023 19:05:50 - INFO - __main__ - Per validation step average loss is 0.3470759987831116\n",
      "07/27/2023 19:05:50 - INFO - __main__ - Cumulative validation average loss is 4.2163939971942455\n",
      "07/27/2023 19:05:51 - INFO - __main__ - Per validation step average loss is 0.2971613109111786\n",
      "07/27/2023 19:05:51 - INFO - __main__ - Cumulative validation average loss is 4.513555308105424\n",
      "07/27/2023 19:05:51 - INFO - __main__ - Per validation step average loss is 0.03038126602768898\n",
      "07/27/2023 19:05:51 - INFO - __main__ - Cumulative validation average loss is 4.543936574133113\n",
      "07/27/2023 19:05:52 - INFO - __main__ - Per validation step average loss is 0.18173973262310028\n",
      "07/27/2023 19:05:52 - INFO - __main__ - Cumulative validation average loss is 4.725676306756213\n",
      "07/27/2023 19:05:52 - INFO - __main__ - Per validation step average loss is 0.002889328170567751\n",
      "07/27/2023 19:05:52 - INFO - __main__ - Cumulative validation average loss is 4.728565634926781\n",
      "07/27/2023 19:05:52 - INFO - __main__ - Per validation step average loss is 0.15265950560569763\n",
      "07/27/2023 19:05:52 - INFO - __main__ - Cumulative validation average loss is 4.881225140532479\n",
      "07/27/2023 19:05:53 - INFO - __main__ - Per validation step average loss is 0.004167299717664719\n",
      "07/27/2023 19:05:53 - INFO - __main__ - Cumulative validation average loss is 4.885392440250143\n",
      "07/27/2023 19:05:53 - INFO - __main__ - Per validation step average loss is 0.006663177162408829\n",
      "07/27/2023 19:05:53 - INFO - __main__ - Cumulative validation average loss is 4.892055617412552\n",
      "07/27/2023 19:05:54 - INFO - __main__ - Per validation step average loss is 0.17340850830078125\n",
      "07/27/2023 19:05:54 - INFO - __main__ - Cumulative validation average loss is 5.0654641257133335\n",
      "07/27/2023 19:05:54 - INFO - __main__ - Per validation step average loss is 0.07025908678770065\n",
      "07/27/2023 19:05:54 - INFO - __main__ - Cumulative validation average loss is 5.135723212501034\n",
      "07/27/2023 19:05:54 - INFO - __main__ - Per validation step average loss is 0.0024623095523566008\n",
      "07/27/2023 19:05:54 - INFO - __main__ - Cumulative validation average loss is 5.138185522053391\n",
      "07/27/2023 19:05:55 - INFO - __main__ - Per validation step average loss is 0.23782330751419067\n",
      "07/27/2023 19:05:55 - INFO - __main__ - Cumulative validation average loss is 5.376008829567581\n",
      "07/27/2023 19:05:55 - INFO - __main__ - Per validation step average loss is 0.2219122350215912\n",
      "07/27/2023 19:05:55 - INFO - __main__ - Cumulative validation average loss is 5.597921064589173\n",
      "07/27/2023 19:05:56 - INFO - __main__ - Per validation step average loss is 0.04305011406540871\n",
      "07/27/2023 19:05:56 - INFO - __main__ - Cumulative validation average loss is 5.640971178654581\n",
      "07/27/2023 19:05:56 - INFO - __main__ - Per validation step average loss is 0.010551171377301216\n",
      "07/27/2023 19:05:56 - INFO - __main__ - Cumulative validation average loss is 5.6515223500318825\n",
      "07/27/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.1557427942752838\n",
      "07/27/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 5.807265144307166\n",
      "07/27/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.3230412006378174\n",
      "07/27/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 6.130306344944984\n",
      "07/27/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.2001824975013733\n",
      "07/27/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 6.330488842446357\n",
      "07/27/2023 19:05:58 - INFO - __main__ - Per validation step average loss is 0.013478455133736134\n",
      "07/27/2023 19:05:58 - INFO - __main__ - Cumulative validation average loss is 6.343967297580093\n",
      "07/27/2023 19:05:58 - INFO - __main__ - Per validation step average loss is 0.3034159541130066\n",
      "07/27/2023 19:05:58 - INFO - __main__ - Cumulative validation average loss is 6.6473832516931\n",
      "07/27/2023 19:05:59 - INFO - __main__ - Per validation step average loss is 0.24918776750564575\n",
      "07/27/2023 19:05:59 - INFO - __main__ - Cumulative validation average loss is 6.8965710191987455\n",
      "07/27/2023 19:05:59 - INFO - __main__ - Per validation step average loss is 0.014491308480501175\n",
      "07/27/2023 19:05:59 - INFO - __main__ - Cumulative validation average loss is 6.911062327679247\n",
      "07/27/2023 19:05:59 - INFO - __main__ - Per validation step average loss is 0.016173332929611206\n",
      "07/27/2023 19:05:59 - INFO - __main__ - Cumulative validation average loss is 6.927235660608858\n",
      "07/27/2023 19:06:00 - INFO - __main__ - Per validation step average loss is 0.01152578555047512\n",
      "07/27/2023 19:06:00 - INFO - __main__ - Cumulative validation average loss is 6.938761446159333\n",
      "07/27/2023 19:06:00 - INFO - __main__ - Per validation step average loss is 0.001907588797621429\n",
      "07/27/2023 19:06:00 - INFO - __main__ - Cumulative validation average loss is 6.940669034956954\n",
      "07/27/2023 19:06:01 - INFO - __main__ - Per validation step average loss is 0.02544848620891571\n",
      "07/27/2023 19:06:01 - INFO - __main__ - Cumulative validation average loss is 6.96611752116587\n",
      "07/27/2023 19:06:01 - INFO - __main__ - Per validation step average loss is 0.25944870710372925\n",
      "07/27/2023 19:06:01 - INFO - __main__ - Cumulative validation average loss is 7.225566228269599\n",
      "07/27/2023 19:06:02 - INFO - __main__ - Per validation step average loss is 0.09863165020942688\n",
      "07/27/2023 19:06:02 - INFO - __main__ - Cumulative validation average loss is 7.324197878479026\n",
      "07/27/2023 19:06:02 - INFO - __main__ - Per validation step average loss is 0.292430579662323\n",
      "07/27/2023 19:06:02 - INFO - __main__ - Cumulative validation average loss is 7.616628458141349\n",
      "07/27/2023 19:06:02 - INFO - __main__ - Per validation step average loss is 0.11154656112194061\n",
      "07/27/2023 19:06:02 - INFO - __main__ - Cumulative validation average loss is 7.72817501926329\n",
      "07/27/2023 19:06:03 - INFO - __main__ - Per validation step average loss is 0.24271726608276367\n",
      "07/27/2023 19:06:03 - INFO - __main__ - Cumulative validation average loss is 7.9708922853460535\n",
      "07/27/2023 19:06:03 - INFO - __main__ - Per validation step average loss is 0.6040042638778687\n",
      "07/27/2023 19:06:03 - INFO - __main__ - Cumulative validation average loss is 8.574896549223922\n",
      "07/27/2023 19:06:04 - INFO - __main__ - Per validation step average loss is 0.17172151803970337\n",
      "07/27/2023 19:06:04 - INFO - __main__ - Cumulative validation average loss is 8.746618067263626\n",
      "07/27/2023 19:06:04 - INFO - __main__ - Per validation step average loss is 0.3226158618927002\n",
      "07/27/2023 19:06:04 - INFO - __main__ - Cumulative validation average loss is 9.069233929156326\n",
      "07/27/2023 19:06:04 - INFO - __main__ - Per validation step average loss is 0.20431974530220032\n",
      "07/27/2023 19:06:04 - INFO - __main__ - Cumulative validation average loss is 9.273553674458526\n",
      "07/27/2023 19:06:05 - INFO - __main__ - Per validation step average loss is 0.030819490551948547\n",
      "07/27/2023 19:06:05 - INFO - __main__ - Cumulative validation average loss is 9.304373165010475\n",
      "07/27/2023 19:06:05 - INFO - __main__ - Per validation step average loss is 0.03591720759868622\n",
      "07/27/2023 19:06:05 - INFO - __main__ - Cumulative validation average loss is 9.34029037260916\n",
      "07/27/2023 19:06:06 - INFO - __main__ - Per validation step average loss is 0.09178034216165543\n",
      "07/27/2023 19:06:06 - INFO - __main__ - Cumulative validation average loss is 9.432070714770816\n",
      "07/27/2023 19:06:06 - INFO - __main__ - Per validation step average loss is 0.0029677506536245346\n",
      "07/27/2023 19:06:06 - INFO - __main__ - Cumulative validation average loss is 9.43503846542444\n",
      "07/27/2023 19:06:07 - INFO - __main__ - Per validation step average loss is 0.003667286131531\n",
      "07/27/2023 19:06:07 - INFO - __main__ - Cumulative validation average loss is 9.438705751555972\n",
      "07/27/2023 19:06:07 - INFO - __main__ - Per validation step average loss is 0.047214314341545105\n",
      "07/27/2023 19:06:07 - INFO - __main__ - Cumulative validation average loss is 9.485920065897517\n",
      "07/27/2023 19:06:07 - INFO - __main__ - Per validation step average loss is 0.30039793252944946\n",
      "07/27/2023 19:06:07 - INFO - __main__ - Cumulative validation average loss is 9.786317998426966\n",
      "07/27/2023 19:06:08 - INFO - __main__ - Per validation step average loss is 0.775768518447876\n",
      "07/27/2023 19:06:08 - INFO - __main__ - Cumulative validation average loss is 10.562086516874842\n",
      "07/27/2023 19:06:08 - INFO - __main__ - Average validation loss for Epoch 30 is 0.13369729768196004\n",
      "07/27/2023 19:06:08 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:07:05 - INFO - __main__ - Starting epoch 31\n",
      "07/27/2023 19:07:06 - INFO - __main__ - train loss is 0.004802379757165909\n",
      "Steps:  63%|▋| 9394/15000 [1:22:16<43:27:15, 27.90s/it, lr=0.000998, step_loss=007/27/2023 19:07:06 - INFO - __main__ - train loss is 0.05074809864163399\n",
      "Steps:  63%|▋| 9395/15000 [1:22:16<30:29:53, 19.59s/it, lr=0.000998, step_loss=007/27/2023 19:07:06 - INFO - __main__ - train loss is 0.05344917019829154\n",
      "Steps:  63%|▋| 9396/15000 [1:22:17<21:25:43, 13.77s/it, lr=0.000998, step_loss=007/27/2023 19:07:07 - INFO - __main__ - train loss is 0.2514507635496557\n",
      "Steps:  63%|▋| 9397/15000 [1:22:17<15:05:00,  9.69s/it, lr=0.000998, step_loss=007/27/2023 19:07:07 - INFO - __main__ - train loss is 0.2830319865606725\n",
      "Steps:  63%|▋| 9398/15000 [1:22:17<10:38:26,  6.84s/it, lr=0.000998, step_loss=007/27/2023 19:07:07 - INFO - __main__ - train loss is 0.3588975085876882\n",
      "Steps:  63%|▋| 9399/15000 [1:22:17<7:31:57,  4.84s/it, lr=0.000998, step_loss=0.07/27/2023 19:07:07 - INFO - __main__ - train loss is 0.7670147432945669\n",
      "Steps:  63%|▋| 9400/15000 [1:22:17<5:21:21,  3.44s/it, lr=0.000998, step_loss=0.07/27/2023 19:07:07 - INFO - __main__ - train loss is 0.7690450381487608\n",
      "Steps:  63%|▋| 9401/15000 [1:22:18<3:49:54,  2.46s/it, lr=0.000998, step_loss=0.07/27/2023 19:07:07 - INFO - __main__ - train loss is 1.4847878646105528\n",
      "Steps:  63%|▋| 9402/15000 [1:22:18<2:45:53,  1.78s/it, lr=0.000998, step_loss=0.07/27/2023 19:07:08 - INFO - __main__ - train loss is 1.5270725656300783\n",
      "Steps:  63%|▋| 9403/15000 [1:22:18<2:01:04,  1.30s/it, lr=0.000998, step_loss=0.07/27/2023 19:07:08 - INFO - __main__ - train loss is 1.6723191607743502\n",
      "Steps:  63%|▋| 9404/15000 [1:22:18<1:29:43,  1.04it/s, lr=0.000998, step_loss=0.07/27/2023 19:07:08 - INFO - __main__ - train loss is 1.937495993450284\n",
      "Steps:  63%|▋| 9405/15000 [1:22:18<1:07:46,  1.38it/s, lr=0.000998, step_loss=0.07/27/2023 19:07:08 - INFO - __main__ - train loss is 1.9457372035831213\n",
      "Steps:  63%|▋| 9406/15000 [1:22:18<52:25,  1.78it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:08 - INFO - __main__ - train loss is 2.065417906269431\n",
      "Steps:  63%|▋| 9407/15000 [1:22:19<41:40,  2.24it/s, lr=0.000998, step_loss=0.1207/27/2023 19:07:09 - INFO - __main__ - train loss is 2.1863882448524237\n",
      "Steps:  63%|▋| 9408/15000 [1:22:19<34:11,  2.73it/s, lr=0.000998, step_loss=0.1207/27/2023 19:07:09 - INFO - __main__ - train loss is 2.2182355541735888\n",
      "Steps:  63%|▋| 9409/15000 [1:22:19<28:54,  3.22it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:09 - INFO - __main__ - train loss is 2.4651920963078737\n",
      "Steps:  63%|▋| 9410/15000 [1:22:19<25:13,  3.69it/s, lr=0.000998, step_loss=0.2407/27/2023 19:07:09 - INFO - __main__ - train loss is 2.5446051377803087\n",
      "Steps:  63%|▋| 9411/15000 [1:22:19<22:39,  4.11it/s, lr=0.000998, step_loss=0.0707/27/2023 19:07:09 - INFO - __main__ - train loss is 2.588398242369294\n",
      "Steps:  63%|▋| 9412/15000 [1:22:20<20:51,  4.46it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:09 - INFO - __main__ - train loss is 2.589736844995059\n",
      "Steps:  63%|▋| 9413/15000 [1:22:20<19:36,  4.75it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:10 - INFO - __main__ - train loss is 2.5910183161031455\n",
      "Steps:  63%|▋| 9414/15000 [1:22:20<18:43,  4.97it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:10 - INFO - __main__ - train loss is 2.5924678107257932\n",
      "Steps:  63%|▋| 9415/15000 [1:22:20<18:06,  5.14it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:10 - INFO - __main__ - train loss is 2.761697437381372\n",
      "Steps:  63%|▋| 9416/15000 [1:22:20<17:40,  5.26it/s, lr=0.000998, step_loss=0.1607/27/2023 19:07:10 - INFO - __main__ - train loss is 2.767141471384093\n",
      "Steps:  63%|▋| 9417/15000 [1:22:20<17:22,  5.35it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:10 - INFO - __main__ - train loss is 2.8151382009964436\n",
      "Steps:  63%|▋| 9418/15000 [1:22:21<17:09,  5.42it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:10 - INFO - __main__ - train loss is 2.859488258836791\n",
      "Steps:  63%|▋| 9419/15000 [1:22:21<17:01,  5.46it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:11 - INFO - __main__ - train loss is 2.8634797723498195\n",
      "Steps:  63%|▋| 9420/15000 [1:22:21<16:54,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:11 - INFO - __main__ - train loss is 2.8795419649686664\n",
      "Steps:  63%|▋| 9421/15000 [1:22:21<16:50,  5.52it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:11 - INFO - __main__ - train loss is 2.8926814978476614\n",
      "Steps:  63%|▋| 9422/15000 [1:22:21<16:46,  5.54it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:11 - INFO - __main__ - train loss is 2.910069884499535\n",
      "Steps:  63%|▋| 9423/15000 [1:22:22<16:44,  5.55it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:11 - INFO - __main__ - train loss is 2.927238885080442\n",
      "Steps:  63%|▋| 9424/15000 [1:22:22<16:42,  5.56it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:12 - INFO - __main__ - train loss is 3.1854012941475958\n",
      "Steps:  63%|▋| 9425/15000 [1:22:22<16:40,  5.57it/s, lr=0.000998, step_loss=0.2507/27/2023 19:07:12 - INFO - __main__ - train loss is 3.2196629454847425\n",
      "Steps:  63%|▋| 9426/15000 [1:22:22<16:40,  5.57it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:12 - INFO - __main__ - train loss is 3.230562948388979\n",
      "Steps:  63%|▋| 9427/15000 [1:22:22<16:39,  5.57it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:12 - INFO - __main__ - train loss is 3.794680618448183\n",
      "Steps:  63%|▋| 9428/15000 [1:22:22<16:38,  5.58it/s, lr=0.000998, step_loss=0.5607/27/2023 19:07:12 - INFO - __main__ - train loss is 3.8389559618663043\n",
      "Steps:  63%|▋| 9429/15000 [1:22:23<16:37,  5.58it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:12 - INFO - __main__ - train loss is 3.9765242419671267\n",
      "Steps:  63%|▋| 9430/15000 [1:22:23<16:37,  5.58it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:13 - INFO - __main__ - train loss is 4.031957124127075\n",
      "Steps:  63%|▋| 9431/15000 [1:22:23<16:37,  5.58it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:13 - INFO - __main__ - train loss is 4.27972509409301\n",
      "Steps:  63%|▋| 9432/15000 [1:22:23<16:37,  5.58it/s, lr=0.000998, step_loss=0.2407/27/2023 19:07:13 - INFO - __main__ - train loss is 4.558103252900764\n",
      "Steps:  63%|▋| 9433/15000 [1:22:23<16:37,  5.58it/s, lr=0.000998, step_loss=0.2707/27/2023 19:07:13 - INFO - __main__ - train loss is 4.563294742023572\n",
      "Steps:  63%|▋| 9434/15000 [1:22:23<16:37,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:13 - INFO - __main__ - train loss is 4.57142024836503\n",
      "Steps:  63%|▋| 9435/15000 [1:22:24<16:37,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:14 - INFO - __main__ - train loss is 4.776315819239244\n",
      "Steps:  63%|▋| 9436/15000 [1:22:24<16:37,  5.58it/s, lr=0.000998, step_loss=0.2007/27/2023 19:07:14 - INFO - __main__ - train loss is 4.778691926738247\n",
      "Steps:  63%|▋| 9437/15000 [1:22:24<16:37,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:14 - INFO - __main__ - train loss is 4.806025711586699\n",
      "Steps:  63%|▋| 9438/15000 [1:22:24<16:36,  5.58it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:14 - INFO - __main__ - train loss is 5.621314970543608\n",
      "Steps:  63%|▋| 9439/15000 [1:22:24<16:36,  5.58it/s, lr=0.000998, step_loss=0.8107/27/2023 19:07:14 - INFO - __main__ - train loss is 5.780424235155806\n",
      "Steps:  63%|▋| 9440/15000 [1:22:25<16:36,  5.58it/s, lr=0.000998, step_loss=0.1507/27/2023 19:07:14 - INFO - __main__ - train loss is 5.782090309658088\n",
      "Steps:  63%|▋| 9441/15000 [1:22:25<16:35,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:15 - INFO - __main__ - train loss is 5.925171229639091\n",
      "Steps:  63%|▋| 9442/15000 [1:22:25<16:35,  5.58it/s, lr=0.000998, step_loss=0.1407/27/2023 19:07:15 - INFO - __main__ - train loss is 5.954794851713814\n",
      "Steps:  63%|▋| 9443/15000 [1:22:25<16:35,  5.58it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:15 - INFO - __main__ - train loss is 6.436187116079964\n",
      "Steps:  63%|▋| 9444/15000 [1:22:25<16:35,  5.58it/s, lr=0.000998, step_loss=0.4807/27/2023 19:07:15 - INFO - __main__ - train loss is 6.437785167596303\n",
      "Steps:  63%|▋| 9445/15000 [1:22:25<16:35,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:15 - INFO - __main__ - train loss is 6.503990780911408\n",
      "Steps:  63%|▋| 9446/15000 [1:22:26<16:44,  5.53it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:16 - INFO - __main__ - train loss is 6.508958587306552\n",
      "Steps:  63%|▋| 9447/15000 [1:22:26<16:48,  5.51it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:16 - INFO - __main__ - train loss is 6.521607147413306\n",
      "Steps:  63%|▋| 9448/15000 [1:22:26<16:49,  5.50it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:16 - INFO - __main__ - train loss is 6.807030724245124\n",
      "Steps:  63%|▋| 9449/15000 [1:22:26<16:45,  5.52it/s, lr=0.000998, step_loss=0.2807/27/2023 19:07:16 - INFO - __main__ - train loss is 7.336056755739264\n",
      "Steps:  63%|▋| 9450/15000 [1:22:26<16:42,  5.54it/s, lr=0.000998, step_loss=0.5207/27/2023 19:07:16 - INFO - __main__ - train loss is 7.536649064975791\n",
      "Steps:  63%|▋| 9451/15000 [1:22:27<16:47,  5.51it/s, lr=0.000998, step_loss=0.2007/27/2023 19:07:16 - INFO - __main__ - train loss is 7.541178206331097\n",
      "Steps:  63%|▋| 9452/15000 [1:22:27<16:51,  5.48it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:17 - INFO - __main__ - train loss is 7.543714569765143\n",
      "Steps:  63%|▋| 9453/15000 [1:22:27<16:46,  5.51it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:17 - INFO - __main__ - train loss is 7.549798493622802\n",
      "Steps:  63%|▋| 9454/15000 [1:22:27<16:42,  5.53it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:17 - INFO - __main__ - train loss is 7.556255183066241\n",
      "Steps:  63%|▋| 9455/15000 [1:22:27<16:39,  5.55it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:17 - INFO - __main__ - train loss is 7.567980510066263\n",
      "Steps:  63%|▋| 9456/15000 [1:22:27<16:37,  5.56it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:17 - INFO - __main__ - train loss is 7.621467904071324\n",
      "Steps:  63%|▋| 9457/15000 [1:22:28<16:36,  5.56it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:17 - INFO - __main__ - train loss is 7.6236602537101135\n",
      "Steps:  63%|▋| 9458/15000 [1:22:28<16:35,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:18 - INFO - __main__ - train loss is 7.625664206105284\n",
      "Steps:  63%|▋| 9459/15000 [1:22:28<16:34,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:18 - INFO - __main__ - train loss is 7.6302856978727505\n",
      "Steps:  63%|▋| 9460/15000 [1:22:28<16:33,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:18 - INFO - __main__ - train loss is 7.682476769085042\n",
      "Steps:  63%|▋| 9461/15000 [1:22:28<16:33,  5.58it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:18 - INFO - __main__ - train loss is 8.199467013473623\n",
      "Steps:  63%|▋| 9462/15000 [1:22:29<16:41,  5.53it/s, lr=0.000998, step_loss=0.5107/27/2023 19:07:18 - INFO - __main__ - train loss is 8.356051037902944\n",
      "Steps:  63%|▋| 9463/15000 [1:22:29<16:46,  5.50it/s, lr=0.000998, step_loss=0.1507/27/2023 19:07:19 - INFO - __main__ - train loss is 8.803371946210973\n",
      "Steps:  63%|▋| 9464/15000 [1:22:29<16:41,  5.53it/s, lr=0.000998, step_loss=0.4407/27/2023 19:07:19 - INFO - __main__ - train loss is 8.929753462667577\n",
      "Steps:  63%|▋| 9465/15000 [1:22:29<16:38,  5.55it/s, lr=0.000998, step_loss=0.1207/27/2023 19:07:19 - INFO - __main__ - train loss is 8.93174810090568\n",
      "Steps:  63%|▋| 9466/15000 [1:22:29<16:45,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:19 - INFO - __main__ - train loss is 8.959954490303062\n",
      "Steps:  63%|▋| 9467/15000 [1:22:29<16:53,  5.46it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:19 - INFO - __main__ - train loss is 9.362907101749443\n",
      "Steps:  63%|▋| 9468/15000 [1:22:30<16:49,  5.48it/s, lr=0.000998, step_loss=0.4007/27/2023 19:07:19 - INFO - __main__ - train loss is 9.364749237778597\n",
      "Steps:  63%|▋| 9469/15000 [1:22:30<16:44,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:20 - INFO - __main__ - train loss is 9.676933571579866\n",
      "Steps:  63%|▋| 9470/15000 [1:22:30<16:41,  5.52it/s, lr=0.000998, step_loss=0.3107/27/2023 19:07:20 - INFO - __main__ - train loss is 9.788111656787805\n",
      "Steps:  63%|▋| 9471/15000 [1:22:30<16:38,  5.54it/s, lr=0.000998, step_loss=0.1107/27/2023 19:07:20 - INFO - __main__ - train loss is 10.300251811626367\n",
      "Steps:  63%|▋| 9472/15000 [1:22:30<16:36,  5.55it/s, lr=0.000998, step_loss=0.5107/27/2023 19:07:20 - INFO - __main__ - train loss is 10.302131620701402\n",
      "Steps:  63%|▋| 9473/15000 [1:22:31<16:35,  5.55it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:20 - INFO - __main__ - train loss is 10.553770211990923\n",
      "Steps:  63%|▋| 9474/15000 [1:22:31<16:34,  5.56it/s, lr=0.000998, step_loss=0.2507/27/2023 19:07:21 - INFO - __main__ - train loss is 10.556263771373779\n",
      "Steps:  63%|▋| 9475/15000 [1:22:31<16:33,  5.56it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:21 - INFO - __main__ - train loss is 10.758256104309112\n",
      "Steps:  63%|▋| 9476/15000 [1:22:31<16:32,  5.57it/s, lr=0.000998, step_loss=0.2007/27/2023 19:07:21 - INFO - __main__ - train loss is 10.933898326475173\n",
      "Steps:  63%|▋| 9477/15000 [1:22:31<16:41,  5.52it/s, lr=0.000998, step_loss=0.1707/27/2023 19:07:21 - INFO - __main__ - train loss is 10.985803585965186\n",
      "Steps:  63%|▋| 9478/15000 [1:22:31<16:50,  5.47it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:21 - INFO - __main__ - train loss is 10.991470970679075\n",
      "Steps:  63%|▋| 9479/15000 [1:22:32<16:53,  5.45it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:21 - INFO - __main__ - train loss is 11.158260204363614\n",
      "Steps:  63%|▋| 9480/15000 [1:22:32<16:46,  5.49it/s, lr=0.000998, step_loss=0.1607/27/2023 19:07:22 - INFO - __main__ - train loss is 11.16021340712905\n",
      "Steps:  63%|▋| 9481/15000 [1:22:32<16:48,  5.47it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:22 - INFO - __main__ - train loss is 11.181534191593528\n",
      "Steps:  63%|▋| 9482/15000 [1:22:32<16:51,  5.45it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:22 - INFO - __main__ - train loss is 11.318753561004996\n",
      "Steps:  63%|▋| 9483/15000 [1:22:32<16:48,  5.47it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:22 - INFO - __main__ - train loss is 11.321367967873812\n",
      "Steps:  63%|▋| 9484/15000 [1:22:33<16:43,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:22 - INFO - __main__ - train loss is 11.335479144006968\n",
      "Steps:  63%|▋| 9485/15000 [1:22:33<16:38,  5.52it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:23 - INFO - __main__ - train loss is 11.341254388447851\n",
      "Steps:  63%|▋| 9486/15000 [1:22:33<16:34,  5.54it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:23 - INFO - __main__ - train loss is 11.352804597001523\n",
      "Steps:  63%|▋| 9487/15000 [1:22:33<16:32,  5.56it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:23 - INFO - __main__ - train loss is 11.361133090686053\n",
      "Steps:  63%|▋| 9488/15000 [1:22:33<16:31,  5.56it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:23 - INFO - __main__ - train loss is 11.495482153724879\n",
      "Steps:  63%|▋| 9489/15000 [1:22:33<16:30,  5.57it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:23 - INFO - __main__ - train loss is 11.787314928602427\n",
      "Steps:  63%|▋| 9490/15000 [1:22:34<16:28,  5.57it/s, lr=0.000998, step_loss=0.2907/27/2023 19:07:23 - INFO - __main__ - train loss is 11.855599864851683\n",
      "Steps:  63%|▋| 9491/15000 [1:22:34<16:34,  5.54it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:24 - INFO - __main__ - train loss is 11.85971963731572\n",
      "Steps:  63%|▋| 9492/15000 [1:22:34<16:40,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:24 - INFO - __main__ - train loss is 11.998892921488732\n",
      "Steps:  63%|▋| 9493/15000 [1:22:34<16:38,  5.52it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:24 - INFO - __main__ - train loss is 12.00183156086132\n",
      "Steps:  63%|▋| 9494/15000 [1:22:34<16:35,  5.53it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:24 - INFO - __main__ - train loss is 12.00380172720179\n",
      "Steps:  63%|▋| 9495/15000 [1:22:35<16:32,  5.55it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:24 - INFO - __main__ - train loss is 12.01710951840505\n",
      "Steps:  63%|▋| 9496/15000 [1:22:35<16:31,  5.55it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:25 - INFO - __main__ - train loss is 12.133586955722421\n",
      "Steps:  63%|▋| 9497/15000 [1:22:35<16:29,  5.56it/s, lr=0.000998, step_loss=0.1107/27/2023 19:07:25 - INFO - __main__ - train loss is 12.175777269061655\n",
      "Steps:  63%|▋| 9498/15000 [1:22:35<16:28,  5.56it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:25 - INFO - __main__ - train loss is 12.179253014503047\n",
      "Steps:  63%|▋| 9499/15000 [1:22:35<16:34,  5.53it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:25 - INFO - __main__ - train loss is 12.440210642991588\n",
      "Steps:  63%|▋| 9500/15000 [1:22:35<16:31,  5.55it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:25 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-9500\n",
      "07/27/2023 19:07:25 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:07:25,687] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:07:25,692] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-9500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:07:25,692] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-9500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:07:25,698] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-9500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:07:25,699] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-9500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:07:25,705] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-9500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:07:25,705] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-9500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:07:25,705] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:07:25 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-9500/pytorch_model\n",
      "07/27/2023 19:07:25 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-9500/scheduler.bin\n",
      "07/27/2023 19:07:25 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-9500/random_states_0.pkl\n",
      "07/27/2023 19:07:25 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-9500\n",
      "Steps:  63%|▋| 9500/15000 [1:22:35<16:31,  5.55it/s, lr=0.000998, step_loss=0.2607/27/2023 19:07:25 - INFO - __main__ - train loss is 12.455459187505767\n",
      "Steps:  63%|▋| 9501/15000 [1:22:36<17:02,  5.38it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:25 - INFO - __main__ - train loss is 12.47941659274511\n",
      "Steps:  63%|▋| 9502/15000 [1:22:36<16:51,  5.43it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:26 - INFO - __main__ - train loss is 12.48084166739136\n",
      "Steps:  63%|▋| 9503/15000 [1:22:36<16:44,  5.47it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:26 - INFO - __main__ - train loss is 12.485841436777264\n",
      "Steps:  63%|▋| 9504/15000 [1:22:36<16:38,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:26 - INFO - __main__ - train loss is 12.522258053068072\n",
      "Steps:  63%|▋| 9505/15000 [1:22:36<16:34,  5.52it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:26 - INFO - __main__ - train loss is 12.524117191089317\n",
      "Steps:  63%|▋| 9506/15000 [1:22:37<16:32,  5.54it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:26 - INFO - __main__ - train loss is 12.748753581894562\n",
      "Steps:  63%|▋| 9507/15000 [1:22:37<16:29,  5.55it/s, lr=0.000998, step_loss=0.2207/27/2023 19:07:27 - INFO - __main__ - train loss is 12.900270630372688\n",
      "Steps:  63%|▋| 9508/15000 [1:22:37<16:27,  5.56it/s, lr=0.000998, step_loss=0.1507/27/2023 19:07:27 - INFO - __main__ - train loss is 12.922096100402996\n",
      "Steps:  63%|▋| 9509/15000 [1:22:37<16:26,  5.57it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:27 - INFO - __main__ - train loss is 12.940394880948588\n",
      "Steps:  63%|▋| 9510/15000 [1:22:37<16:25,  5.57it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:27 - INFO - __main__ - train loss is 13.113473358331248\n",
      "Steps:  63%|▋| 9511/15000 [1:22:37<16:36,  5.51it/s, lr=0.000998, step_loss=0.1707/27/2023 19:07:27 - INFO - __main__ - train loss is 13.123125060228631\n",
      "Steps:  63%|▋| 9512/15000 [1:22:38<16:38,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:27 - INFO - __main__ - train loss is 13.127282210392877\n",
      "Steps:  63%|▋| 9513/15000 [1:22:38<16:51,  5.43it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:28 - INFO - __main__ - train loss is 13.171844967408106\n",
      "Steps:  63%|▋| 9514/15000 [1:22:38<17:01,  5.37it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:28 - INFO - __main__ - train loss is 13.183824428124353\n",
      "Steps:  63%|▋| 9515/15000 [1:22:38<16:57,  5.39it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:28 - INFO - __main__ - train loss is 13.304063954157755\n",
      "Steps:  63%|▋| 9516/15000 [1:22:38<17:02,  5.36it/s, lr=0.000998, step_loss=0.1207/27/2023 19:07:28 - INFO - __main__ - train loss is 13.369532012147829\n",
      "Steps:  63%|▋| 9517/15000 [1:22:39<17:07,  5.34it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:28 - INFO - __main__ - train loss is 13.392750723985955\n",
      "Steps:  63%|▋| 9518/15000 [1:22:39<17:01,  5.37it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:29 - INFO - __main__ - train loss is 13.454894124297425\n",
      "Steps:  63%|▋| 9519/15000 [1:22:39<17:10,  5.32it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:29 - INFO - __main__ - train loss is 13.459979726234451\n",
      "Steps:  63%|▋| 9520/15000 [1:22:39<17:21,  5.26it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:29 - INFO - __main__ - train loss is 13.473063967423514\n",
      "Steps:  63%|▋| 9521/15000 [1:22:39<17:22,  5.26it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:29 - INFO - __main__ - train loss is 13.525175615446642\n",
      "Steps:  63%|▋| 9522/15000 [1:22:40<18:01,  5.07it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:29 - INFO - __main__ - train loss is 13.53644032520242\n",
      "Steps:  63%|▋| 9523/15000 [1:22:40<18:02,  5.06it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:30 - INFO - __main__ - train loss is 13.538841457804665\n",
      "Steps:  63%|▋| 9524/15000 [1:22:40<18:03,  5.05it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:30 - INFO - __main__ - train loss is 13.681978227337822\n",
      "Steps:  64%|▋| 9525/15000 [1:22:40<18:12,  5.01it/s, lr=0.000998, step_loss=0.1407/27/2023 19:07:30 - INFO - __main__ - train loss is 13.690893394639716\n",
      "Steps:  64%|▋| 9526/15000 [1:22:40<17:48,  5.13it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:30 - INFO - __main__ - train loss is 13.72290894179605\n",
      "Steps:  64%|▋| 9527/15000 [1:22:40<17:27,  5.22it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:30 - INFO - __main__ - train loss is 13.736502745887265\n",
      "Steps:  64%|▋| 9528/15000 [1:22:41<17:41,  5.15it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:31 - INFO - __main__ - train loss is 13.739670622861013\n",
      "Steps:  64%|▋| 9529/15000 [1:22:41<17:45,  5.13it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:31 - INFO - __main__ - train loss is 14.091517735039815\n",
      "Steps:  64%|▋| 9530/15000 [1:22:41<17:49,  5.12it/s, lr=0.000998, step_loss=0.3507/27/2023 19:07:31 - INFO - __main__ - train loss is 14.18707849434577\n",
      "Steps:  64%|▋| 9531/15000 [1:22:41<17:42,  5.15it/s, lr=0.000998, step_loss=0.0907/27/2023 19:07:31 - INFO - __main__ - train loss is 14.345627281581983\n",
      "Steps:  64%|▋| 9532/15000 [1:22:41<17:37,  5.17it/s, lr=0.000998, step_loss=0.1507/27/2023 19:07:31 - INFO - __main__ - train loss is 14.376032173400745\n",
      "Steps:  64%|▋| 9533/15000 [1:22:42<17:20,  5.25it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:32 - INFO - __main__ - train loss is 14.61655868566595\n",
      "Steps:  64%|▋| 9534/15000 [1:22:42<17:10,  5.31it/s, lr=0.000998, step_loss=0.2407/27/2023 19:07:32 - INFO - __main__ - train loss is 14.62724182358943\n",
      "Steps:  64%|▋| 9535/15000 [1:22:42<17:09,  5.31it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:32 - INFO - __main__ - train loss is 14.791432413971052\n",
      "Steps:  64%|▋| 9536/15000 [1:22:42<17:24,  5.23it/s, lr=0.000998, step_loss=0.1607/27/2023 19:07:32 - INFO - __main__ - train loss is 14.876142713939771\n",
      "Steps:  64%|▋| 9537/15000 [1:22:42<17:29,  5.20it/s, lr=0.000998, step_loss=0.0807/27/2023 19:07:32 - INFO - __main__ - train loss is 15.005394030129537\n",
      "Steps:  64%|▋| 9538/15000 [1:22:43<17:39,  5.15it/s, lr=0.000998, step_loss=0.1207/27/2023 19:07:32 - INFO - __main__ - train loss is 15.348802555119619\n",
      "Steps:  64%|▋| 9539/15000 [1:22:43<17:42,  5.14it/s, lr=0.000998, step_loss=0.3407/27/2023 19:07:33 - INFO - __main__ - train loss is 15.533129293238744\n",
      "Steps:  64%|▋| 9540/15000 [1:22:43<17:43,  5.13it/s, lr=0.000998, step_loss=0.1807/27/2023 19:07:33 - INFO - __main__ - train loss is 15.536007981281728\n",
      "Steps:  64%|▋| 9541/15000 [1:22:43<17:44,  5.13it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:33 - INFO - __main__ - train loss is 15.548939861822873\n",
      "Steps:  64%|▋| 9542/15000 [1:22:43<17:45,  5.12it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:33 - INFO - __main__ - train loss is 15.686326243449003\n",
      "Steps:  64%|▋| 9543/15000 [1:22:44<17:46,  5.12it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:33 - INFO - __main__ - train loss is 15.810744427610189\n",
      "Steps:  64%|▋| 9544/15000 [1:22:44<17:46,  5.12it/s, lr=0.000998, step_loss=0.1207/27/2023 19:07:34 - INFO - __main__ - train loss is 15.813480420969427\n",
      "Steps:  64%|▋| 9545/15000 [1:22:44<17:55,  5.07it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:34 - INFO - __main__ - train loss is 16.37874965276569\n",
      "Steps:  64%|▋| 9546/15000 [1:22:44<18:43,  4.85it/s, lr=0.000998, step_loss=0.5607/27/2023 19:07:34 - INFO - __main__ - train loss is 16.395952119491994\n",
      "Steps:  64%|▋| 9547/15000 [1:22:44<19:26,  4.68it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:34 - INFO - __main__ - train loss is 16.409785063937306\n",
      "Steps:  64%|▋| 9548/15000 [1:22:45<18:54,  4.81it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:34 - INFO - __main__ - train loss is 16.414303665980697\n",
      "Steps:  64%|▋| 9549/15000 [1:22:45<18:08,  5.01it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:35 - INFO - __main__ - train loss is 16.483229180797935\n",
      "Steps:  64%|▋| 9550/15000 [1:22:45<17:35,  5.16it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:35 - INFO - __main__ - train loss is 17.043653270229697\n",
      "Steps:  64%|▋| 9551/15000 [1:22:45<17:12,  5.28it/s, lr=0.000998, step_loss=0.5607/27/2023 19:07:35 - INFO - __main__ - train loss is 17.062387062236667\n",
      "Steps:  64%|▋| 9552/15000 [1:22:45<16:56,  5.36it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:35 - INFO - __main__ - train loss is 17.195979116484523\n",
      "Steps:  64%|▋| 9553/15000 [1:22:46<16:44,  5.42it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:35 - INFO - __main__ - train loss is 17.279118662700057\n",
      "Steps:  64%|▋| 9554/15000 [1:22:46<16:36,  5.47it/s, lr=0.000998, step_loss=0.0807/27/2023 19:07:36 - INFO - __main__ - train loss is 17.310790242627263\n",
      "Steps:  64%|▋| 9555/15000 [1:22:46<16:30,  5.50it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:36 - INFO - __main__ - train loss is 17.322935335338116\n",
      "Steps:  64%|▋| 9556/15000 [1:22:46<16:25,  5.52it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:36 - INFO - __main__ - train loss is 17.32737903529778\n",
      "Steps:  64%|▋| 9557/15000 [1:22:46<16:22,  5.54it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:36 - INFO - __main__ - train loss is 17.665806876961142\n",
      "Steps:  64%|▋| 9558/15000 [1:22:46<16:21,  5.55it/s, lr=0.000998, step_loss=0.3307/27/2023 19:07:36 - INFO - __main__ - train loss is 17.949808525387198\n",
      "[2023-07-27 19:07:36,876] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576\n",
      "Steps:  64%|▋| 9559/15000 [1:22:47<16:13,  5.59it/s, lr=0.000998, step_loss=0.2807/27/2023 19:07:36 - INFO - __main__ - train loss is 17.96100429398939\n",
      "Steps:  64%|▋| 9560/15000 [1:22:47<16:13,  5.59it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:37 - INFO - __main__ - train loss is 18.177101738285273\n",
      "Steps:  64%|▋| 9561/15000 [1:22:47<16:22,  5.54it/s, lr=0.000998, step_loss=0.2107/27/2023 19:07:37 - INFO - __main__ - train loss is 18.46857190830633\n",
      "Steps:  64%|▋| 9562/15000 [1:22:47<16:21,  5.54it/s, lr=0.000998, step_loss=0.2907/27/2023 19:07:37 - INFO - __main__ - train loss is 18.493760292883962\n",
      "Steps:  64%|▋| 9563/15000 [1:22:47<16:20,  5.55it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:37 - INFO - __main__ - train loss is 18.684839551802725\n",
      "Steps:  64%|▋| 9564/15000 [1:22:48<16:21,  5.54it/s, lr=0.000998, step_loss=0.1907/27/2023 19:07:37 - INFO - __main__ - train loss is 19.33436674391851\n",
      "Steps:  64%|▋| 9565/15000 [1:22:48<16:19,  5.55it/s, lr=0.000998, step_loss=0.6507/27/2023 19:07:38 - INFO - __main__ - train loss is 19.472738882061094\n",
      "Steps:  64%|▋| 9566/15000 [1:22:48<16:22,  5.53it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:38 - INFO - __main__ - train loss is 20.38589992141351\n",
      "Steps:  64%|▋| 9567/15000 [1:22:48<16:27,  5.50it/s, lr=0.000998, step_loss=0.9107/27/2023 19:07:38 - INFO - __main__ - train loss is 20.436181706842035\n",
      "Steps:  64%|▋| 9568/15000 [1:22:48<16:23,  5.52it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:38 - INFO - __main__ - train loss is 20.832933468278497\n",
      "Steps:  64%|▋| 9569/15000 [1:22:48<16:26,  5.51it/s, lr=0.000998, step_loss=0.3907/27/2023 19:07:38 - INFO - __main__ - train loss is 20.89331213152036\n",
      "Steps:  64%|▋| 9570/15000 [1:22:49<16:22,  5.52it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:38 - INFO - __main__ - train loss is 21.030354177113622\n",
      "Steps:  64%|▋| 9571/15000 [1:22:49<16:20,  5.54it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:39 - INFO - __main__ - train loss is 21.263183718081564\n",
      "Steps:  64%|▋| 9572/15000 [1:22:49<16:19,  5.54it/s, lr=0.000998, step_loss=0.2307/27/2023 19:07:39 - INFO - __main__ - train loss is 21.297033180948347\n",
      "Steps:  64%|▋| 9573/15000 [1:22:49<16:26,  5.50it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:39 - INFO - __main__ - train loss is 21.34587406134233\n",
      "Steps:  64%|▋| 9574/15000 [1:22:49<16:25,  5.51it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:39 - INFO - __main__ - train loss is 21.43659951305017\n",
      "Steps:  64%|▋| 9575/15000 [1:22:49<16:26,  5.50it/s, lr=0.000998, step_loss=0.0907/27/2023 19:07:39 - INFO - __main__ - train loss is 21.709841986652464\n",
      "Steps:  64%|▋| 9576/15000 [1:22:50<16:22,  5.52it/s, lr=0.000998, step_loss=0.2707/27/2023 19:07:40 - INFO - __main__ - train loss is 21.788820778485388\n",
      "Steps:  64%|▋| 9577/15000 [1:22:50<16:19,  5.54it/s, lr=0.000998, step_loss=0.0707/27/2023 19:07:40 - INFO - __main__ - train loss is 21.94735755538568\n",
      "Steps:  64%|▋| 9578/15000 [1:22:50<16:16,  5.55it/s, lr=0.000998, step_loss=0.1507/27/2023 19:07:40 - INFO - __main__ - train loss is 22.55642553186044\n",
      "Steps:  64%|▋| 9579/15000 [1:22:50<16:15,  5.56it/s, lr=0.000998, step_loss=0.6007/27/2023 19:07:40 - INFO - __main__ - train loss is 22.586409722920507\n",
      "Steps:  64%|▋| 9580/15000 [1:22:50<16:13,  5.57it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:40 - INFO - __main__ - train loss is 22.656372604425997\n",
      "Steps:  64%|▋| 9581/15000 [1:22:51<16:13,  5.57it/s, lr=0.000998, step_loss=0.0707/27/2023 19:07:40 - INFO - __main__ - train loss is 22.70391278481111\n",
      "Steps:  64%|▋| 9582/15000 [1:22:51<16:13,  5.57it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:41 - INFO - __main__ - train loss is 22.841351648326963\n",
      "Steps:  64%|▋| 9583/15000 [1:22:51<16:12,  5.57it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:41 - INFO - __main__ - train loss is 23.326920052524656\n",
      "Steps:  64%|▋| 9584/15000 [1:22:51<16:12,  5.57it/s, lr=0.000998, step_loss=0.4807/27/2023 19:07:41 - INFO - __main__ - train loss is 23.329651064239442\n",
      "Steps:  64%|▋| 9585/15000 [1:22:51<16:20,  5.52it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:41 - INFO - __main__ - train loss is 23.365800975821912\n",
      "Steps:  64%|▋| 9586/15000 [1:22:51<16:17,  5.54it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:41 - INFO - __main__ - train loss is 23.38212529849261\n",
      "Steps:  64%|▋| 9587/15000 [1:22:52<16:14,  5.55it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:42 - INFO - __main__ - train loss is 23.44628346990794\n",
      "Steps:  64%|▋| 9588/15000 [1:22:52<16:13,  5.56it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:42 - INFO - __main__ - train loss is 23.4553368287161\n",
      "Steps:  64%|▋| 9589/15000 [1:22:52<16:12,  5.56it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:42 - INFO - __main__ - train loss is 23.480744159780443\n",
      "Steps:  64%|▋| 9590/15000 [1:22:52<16:11,  5.57it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:42 - INFO - __main__ - train loss is 23.489090469665825\n",
      "Steps:  64%|▋| 9591/15000 [1:22:52<16:11,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:42 - INFO - __main__ - train loss is 23.497756184078753\n",
      "Steps:  64%|▋| 9592/15000 [1:22:53<16:10,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:42 - INFO - __main__ - train loss is 23.499541450291872\n",
      "Steps:  64%|▋| 9593/15000 [1:22:53<16:10,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:43 - INFO - __main__ - train loss is 23.519081085920334\n",
      "Steps:  64%|▋| 9594/15000 [1:22:53<16:12,  5.56it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:43 - INFO - __main__ - train loss is 23.529394986107945\n",
      "Steps:  64%|▋| 9595/15000 [1:22:53<16:11,  5.57it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:43 - INFO - __main__ - train loss is 23.539298865944147\n",
      "Steps:  64%|▋| 9596/15000 [1:22:53<16:10,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:43 - INFO - __main__ - train loss is 23.608206678181887\n",
      "Steps:  64%|▋| 9597/15000 [1:22:53<16:09,  5.57it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:43 - INFO - __main__ - train loss is 23.61096539068967\n",
      "Steps:  64%|▋| 9598/15000 [1:22:54<16:08,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:44 - INFO - __main__ - train loss is 23.619372735731304\n",
      "Steps:  64%|▋| 9599/15000 [1:22:54<16:08,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:44 - INFO - __main__ - train loss is 24.170856128446758\n",
      "Steps:  64%|▋| 9600/15000 [1:22:54<16:08,  5.58it/s, lr=0.000998, step_loss=0.5507/27/2023 19:07:44 - INFO - __main__ - train loss is 24.172730242018588\n",
      "Steps:  64%|▋| 9601/15000 [1:22:54<16:07,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:44 - INFO - __main__ - train loss is 24.21886384964455\n",
      "Steps:  64%|▋| 9602/15000 [1:22:54<16:07,  5.58it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:44 - INFO - __main__ - train loss is 24.241223597084172\n",
      "Steps:  64%|▋| 9603/15000 [1:22:55<16:07,  5.58it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:44 - INFO - __main__ - train loss is 24.256827925448306\n",
      "Steps:  64%|▋| 9604/15000 [1:22:55<16:07,  5.58it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:45 - INFO - __main__ - train loss is 24.272508465801366\n",
      "Steps:  64%|▋| 9605/15000 [1:22:55<16:07,  5.58it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:45 - INFO - __main__ - train loss is 24.436497309361584\n",
      "Steps:  64%|▋| 9606/15000 [1:22:55<16:06,  5.58it/s, lr=0.000998, step_loss=0.1607/27/2023 19:07:45 - INFO - __main__ - train loss is 24.439749525976367\n",
      "Steps:  64%|▋| 9607/15000 [1:22:55<16:06,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:45 - INFO - __main__ - train loss is 24.66714620788116\n",
      "Steps:  64%|▋| 9608/15000 [1:22:55<16:06,  5.58it/s, lr=0.000998, step_loss=0.2207/27/2023 19:07:45 - INFO - __main__ - train loss is 24.671132378396578\n",
      "Steps:  64%|▋| 9609/15000 [1:22:56<16:06,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:45 - INFO - __main__ - train loss is 24.672597553697415\n",
      "Steps:  64%|▋| 9610/15000 [1:22:56<16:06,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:46 - INFO - __main__ - train loss is 24.686716190655716\n",
      "Steps:  64%|▋| 9611/15000 [1:22:56<16:06,  5.57it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:46 - INFO - __main__ - train loss is 24.690727186971344\n",
      "Steps:  64%|▋| 9612/15000 [1:22:56<16:06,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:46 - INFO - __main__ - train loss is 24.89357678371016\n",
      "Steps:  64%|▋| 9613/15000 [1:22:56<16:06,  5.57it/s, lr=0.000998, step_loss=0.2007/27/2023 19:07:46 - INFO - __main__ - train loss is 24.90292926656548\n",
      "Steps:  64%|▋| 9614/15000 [1:22:57<16:05,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:46 - INFO - __main__ - train loss is 24.911043787025847\n",
      "Steps:  64%|▋| 9615/15000 [1:22:57<16:05,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:47 - INFO - __main__ - train loss is 24.912596860784106\n",
      "Steps:  64%|▋| 9616/15000 [1:22:57<16:05,  5.58it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:47 - INFO - __main__ - train loss is 24.950723709422164\n",
      "Steps:  64%|▋| 9617/15000 [1:22:57<16:05,  5.58it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:47 - INFO - __main__ - train loss is 24.953112813294865\n",
      "Steps:  64%|▋| 9618/15000 [1:22:57<16:05,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:47 - INFO - __main__ - train loss is 25.179142999113537\n",
      "Steps:  64%|▋| 9619/15000 [1:22:57<16:05,  5.58it/s, lr=0.000998, step_loss=0.2207/27/2023 19:07:47 - INFO - __main__ - train loss is 25.189104106859304\n",
      "Steps:  64%|▋| 9620/15000 [1:22:58<16:05,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:47 - INFO - __main__ - train loss is 25.19729880115483\n",
      "Steps:  64%|▋| 9621/15000 [1:22:58<16:04,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:48 - INFO - __main__ - train loss is 25.3100976558635\n",
      "Steps:  64%|▋| 9622/15000 [1:22:58<16:04,  5.57it/s, lr=0.000998, step_loss=0.1107/27/2023 19:07:48 - INFO - __main__ - train loss is 25.312706170487218\n",
      "Steps:  64%|▋| 9623/15000 [1:22:58<16:05,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:48 - INFO - __main__ - train loss is 25.375702543067746\n",
      "Steps:  64%|▋| 9624/15000 [1:22:58<16:05,  5.57it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:48 - INFO - __main__ - train loss is 25.393742235261016\n",
      "Steps:  64%|▋| 9625/15000 [1:22:58<16:05,  5.57it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:48 - INFO - __main__ - train loss is 25.626298280316405\n",
      "Steps:  64%|▋| 9626/15000 [1:22:59<16:04,  5.57it/s, lr=0.000998, step_loss=0.2307/27/2023 19:07:49 - INFO - __main__ - train loss is 25.716327981906943\n",
      "Steps:  64%|▋| 9627/15000 [1:22:59<16:04,  5.57it/s, lr=0.000998, step_loss=0.0907/27/2023 19:07:49 - INFO - __main__ - train loss is 25.718673179741018\n",
      "Steps:  64%|▋| 9628/15000 [1:22:59<16:13,  5.52it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:49 - INFO - __main__ - train loss is 25.73767616681289\n",
      "Steps:  64%|▋| 9629/15000 [1:22:59<16:16,  5.50it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:49 - INFO - __main__ - train loss is 25.93725790909957\n",
      "Steps:  64%|▋| 9630/15000 [1:22:59<16:15,  5.50it/s, lr=0.000998, step_loss=0.2]07/27/2023 19:07:49 - INFO - __main__ - train loss is 25.953865234623663\n",
      "Steps:  64%|▋| 9631/15000 [1:23:00<16:12,  5.52it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:49 - INFO - __main__ - train loss is 25.963200610945933\n",
      "Steps:  64%|▋| 9632/15000 [1:23:00<16:09,  5.54it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:50 - INFO - __main__ - train loss is 26.21908329136204\n",
      "Steps:  64%|▋| 9633/15000 [1:23:00<16:07,  5.55it/s, lr=0.000998, step_loss=0.2507/27/2023 19:07:50 - INFO - __main__ - train loss is 26.259001497994177\n",
      "Steps:  64%|▋| 9634/15000 [1:23:00<16:05,  5.56it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:50 - INFO - __main__ - train loss is 26.26666101568844\n",
      "Steps:  64%|▋| 9635/15000 [1:23:00<16:04,  5.56it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:50 - INFO - __main__ - train loss is 26.325002526282333\n",
      "Steps:  64%|▋| 9636/15000 [1:23:00<16:04,  5.56it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:50 - INFO - __main__ - train loss is 26.46390563750174\n",
      "Steps:  64%|▋| 9637/15000 [1:23:01<16:04,  5.56it/s, lr=0.000998, step_loss=0.1307/27/2023 19:07:51 - INFO - __main__ - train loss is 26.495771770714782\n",
      "Steps:  64%|▋| 9638/15000 [1:23:01<16:11,  5.52it/s, lr=0.000998, step_loss=0.0307/27/2023 19:07:51 - INFO - __main__ - train loss is 26.88839793705847\n",
      "Steps:  64%|▋| 9639/15000 [1:23:01<16:17,  5.49it/s, lr=0.000998, step_loss=0.3907/27/2023 19:07:51 - INFO - __main__ - train loss is 26.889944034744985\n",
      "Steps:  64%|▋| 9640/15000 [1:23:01<16:25,  5.44it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:51 - INFO - __main__ - train loss is 26.901610311237164\n",
      "Steps:  64%|▋| 9641/15000 [1:23:01<16:19,  5.47it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:51 - INFO - __main__ - train loss is 26.90307318069972\n",
      "Steps:  64%|▋| 9642/15000 [1:23:02<16:13,  5.50it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:51 - INFO - __main__ - train loss is 26.953200545394793\n",
      "Steps:  64%|▋| 9643/15000 [1:23:02<16:09,  5.52it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:52 - INFO - __main__ - train loss is 26.956716617802158\n",
      "Steps:  64%|▋| 9644/15000 [1:23:02<16:14,  5.49it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:52 - INFO - __main__ - train loss is 27.10463750944473\n",
      "Steps:  64%|▋| 9645/15000 [1:23:02<16:10,  5.52it/s, lr=0.000998, step_loss=0.1407/27/2023 19:07:52 - INFO - __main__ - train loss is 27.312166085699573\n",
      "Steps:  64%|▋| 9646/15000 [1:23:02<16:07,  5.53it/s, lr=0.000998, step_loss=0.2007/27/2023 19:07:52 - INFO - __main__ - train loss is 27.356454214314\n",
      "Steps:  64%|▋| 9647/15000 [1:23:02<16:05,  5.54it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:52 - INFO - __main__ - train loss is 27.405479284236208\n",
      "Steps:  64%|▋| 9648/15000 [1:23:03<16:04,  5.55it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:53 - INFO - __main__ - train loss is 27.460741067538038\n",
      "Steps:  64%|▋| 9649/15000 [1:23:03<16:03,  5.55it/s, lr=0.000998, step_loss=0.0507/27/2023 19:07:53 - INFO - __main__ - train loss is 27.508037699619308\n",
      "Steps:  64%|▋| 9650/15000 [1:23:03<16:02,  5.56it/s, lr=0.000998, step_loss=0.0407/27/2023 19:07:53 - INFO - __main__ - train loss is 27.528434908250347\n",
      "Steps:  64%|▋| 9651/15000 [1:23:03<16:02,  5.56it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:53 - INFO - __main__ - train loss is 28.05332604632713\n",
      "Steps:  64%|▋| 9652/15000 [1:23:03<16:03,  5.55it/s, lr=0.000998, step_loss=0.5207/27/2023 19:07:53 - INFO - __main__ - train loss is 28.12238002405502\n",
      "Steps:  64%|▋| 9653/15000 [1:23:04<16:03,  5.55it/s, lr=0.000998, step_loss=0.0607/27/2023 19:07:53 - INFO - __main__ - train loss is 28.12397003348451\n",
      "Steps:  64%|▋| 9654/15000 [1:23:04<16:03,  5.55it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:54 - INFO - __main__ - train loss is 28.373345615225844\n",
      "Steps:  64%|▋| 9655/15000 [1:23:04<16:03,  5.55it/s, lr=0.000998, step_loss=0.2407/27/2023 19:07:54 - INFO - __main__ - train loss is 28.3848104205681\n",
      "Steps:  64%|▋| 9656/15000 [1:23:04<16:02,  5.55it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:54 - INFO - __main__ - train loss is 29.289761516149156\n",
      "Steps:  64%|▋| 9657/15000 [1:23:04<16:07,  5.52it/s, lr=0.000998, step_loss=0.9007/27/2023 19:07:54 - INFO - __main__ - train loss is 29.500704753096215\n",
      "Steps:  64%|▋| 9658/15000 [1:23:04<16:07,  5.52it/s, lr=0.000998, step_loss=0.2107/27/2023 19:07:54 - INFO - __main__ - train loss is 29.506455314694904\n",
      "Steps:  64%|▋| 9659/15000 [1:23:05<16:04,  5.54it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:54 - INFO - __main__ - train loss is 29.521397052682005\n",
      "Steps:  64%|▋| 9660/15000 [1:23:05<16:02,  5.55it/s, lr=0.000998, step_loss=0.0107/27/2023 19:07:55 - INFO - __main__ - train loss is 29.526696384768\n",
      "Steps:  64%|▋| 9661/15000 [1:23:05<16:01,  5.55it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:55 - INFO - __main__ - train loss is 29.668786109308712\n",
      "Steps:  64%|▋| 9662/15000 [1:23:05<15:59,  5.56it/s, lr=0.000998, step_loss=0.1407/27/2023 19:07:55 - INFO - __main__ - train loss is 30.075200916151516\n",
      "Steps:  64%|▋| 9663/15000 [1:23:05<15:58,  5.57it/s, lr=0.000998, step_loss=0.4007/27/2023 19:07:55 - INFO - __main__ - train loss is 30.14912639639806\n",
      "Steps:  64%|▋| 9664/15000 [1:23:06<15:58,  5.57it/s, lr=0.000998, step_loss=0.0707/27/2023 19:07:55 - INFO - __main__ - train loss is 30.17100012570154\n",
      "Steps:  64%|▋| 9665/15000 [1:23:06<15:58,  5.57it/s, lr=0.000998, step_loss=0.0207/27/2023 19:07:56 - INFO - __main__ - train loss is 30.17957271717023\n",
      "Steps:  64%|▋| 9666/15000 [1:23:06<15:57,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:56 - INFO - __main__ - train loss is 30.573220566730015\n",
      "Steps:  64%|▋| 9667/15000 [1:23:06<15:56,  5.57it/s, lr=0.000998, step_loss=0.3907/27/2023 19:07:56 - INFO - __main__ - train loss is 30.726401061634533\n",
      "Steps:  64%|▋| 9668/15000 [1:23:06<15:56,  5.57it/s, lr=0.000998, step_loss=0.1507/27/2023 19:07:56 - INFO - __main__ - train loss is 30.944219202618115\n",
      "Steps:  64%|▋| 9669/15000 [1:23:06<15:57,  5.57it/s, lr=0.000998, step_loss=0.2107/27/2023 19:07:56 - INFO - __main__ - train loss is 30.946928874705918\n",
      "Steps:  64%|▋| 9670/15000 [1:23:07<15:56,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:56 - INFO - __main__ - train loss is 31.210446671699174\n",
      "Steps:  64%|▋| 9671/15000 [1:23:07<15:56,  5.57it/s, lr=0.000998, step_loss=0.2607/27/2023 19:07:57 - INFO - __main__ - train loss is 31.218802823801525\n",
      "Steps:  64%|▋| 9672/15000 [1:23:07<15:56,  5.57it/s, lr=0.000998, step_loss=0.0007/27/2023 19:07:57 - INFO - __main__ - train loss is 31.520626916666515\n",
      "Steps:  64%|▋| 9673/15000 [1:23:07<15:56,  5.57it/s, lr=0.000998, step_loss=0.3007/27/2023 19:07:57 - INFO - __main__ - train loss is 31.601859836955555\n",
      "Steps:  64%|▋| 9674/15000 [1:23:07<15:55,  5.57it/s, lr=0.000997, step_loss=0.0807/27/2023 19:07:57 - INFO - __main__ - train loss is 31.97151425399352\n",
      "Steps:  64%|▋| 9675/15000 [1:23:07<15:54,  5.58it/s, lr=0.000997, step_loss=0.3707/27/2023 19:07:57 - INFO - __main__ - train loss is 32.00514567561913\n",
      "Steps:  65%|▋| 9676/15000 [1:23:08<15:54,  5.58it/s, lr=0.000997, step_loss=0.0307/27/2023 19:07:58 - INFO - __main__ - train loss is 32.361129826982506\n",
      "Steps:  65%|▋| 9677/15000 [1:23:08<16:04,  5.52it/s, lr=0.000997, step_loss=0.3507/27/2023 19:07:58 - INFO - __main__ - train loss is 32.53866382606793\n",
      "Steps:  65%|▋| 9678/15000 [1:23:08<16:03,  5.52it/s, lr=0.000997, step_loss=0.1707/27/2023 19:07:58 - INFO - __main__ - train loss is 32.56784499541391\n",
      "Steps:  65%|▋| 9679/15000 [1:23:08<16:01,  5.54it/s, lr=0.000997, step_loss=0.0207/27/2023 19:07:58 - INFO - __main__ - train loss is 32.57125850592274\n",
      "Steps:  65%|▋| 9680/15000 [1:23:08<16:07,  5.50it/s, lr=0.000997, step_loss=0.0007/27/2023 19:07:58 - INFO - __main__ - train loss is 32.578741468605585\n",
      "Steps:  65%|▋| 9681/15000 [1:23:09<16:06,  5.50it/s, lr=0.000997, step_loss=0.0007/27/2023 19:07:58 - INFO - __main__ - train loss is 32.58874053612817\n",
      "Steps:  65%|▋| 9682/15000 [1:23:09<16:09,  5.48it/s, lr=0.000997, step_loss=0.0107/27/2023 19:07:59 - INFO - __main__ - train loss is 32.67248153791297\n",
      "Steps:  65%|▋| 9683/15000 [1:23:09<16:13,  5.46it/s, lr=0.000997, step_loss=0.0807/27/2023 19:07:59 - INFO - __main__ - train loss is 32.815032602404244\n",
      "Steps:  65%|▋| 9684/15000 [1:23:09<16:14,  5.46it/s, lr=0.000997, step_loss=0.1407/27/2023 19:07:59 - INFO - __main__ - train loss is 32.82878900237847\n",
      "Steps:  65%|▋| 9685/15000 [1:23:09<16:12,  5.46it/s, lr=0.000997, step_loss=0.0107/27/2023 19:07:59 - INFO - __main__ - train loss is 32.92692264087964\n",
      "Steps:  65%|▋| 9686/15000 [1:23:10<16:11,  5.47it/s, lr=0.000997, step_loss=0.0907/27/2023 19:07:59 - INFO - __main__ - train loss is 32.9320205898257\n",
      "Steps:  65%|▋| 9687/15000 [1:23:10<16:10,  5.48it/s, lr=0.000997, step_loss=0.0007/27/2023 19:08:00 - INFO - __main__ - train loss is 33.13285253953654\n",
      "Steps:  65%|▋| 9688/15000 [1:23:10<16:11,  5.47it/s, lr=0.000997, step_loss=0.2007/27/2023 19:08:00 - INFO - __main__ - train loss is 33.15181517240126\n",
      "Steps:  65%|▋| 9689/15000 [1:23:10<16:05,  5.50it/s, lr=0.000997, step_loss=0.0107/27/2023 19:08:00 - INFO - __main__ - train loss is 33.254908006754704\n",
      "Steps:  65%|▋| 9690/15000 [1:23:10<16:09,  5.48it/s, lr=0.000997, step_loss=0.1007/27/2023 19:08:00 - INFO - __main__ - train loss is 33.35966802027542\n",
      "Steps:  65%|▋| 9691/15000 [1:23:10<16:05,  5.50it/s, lr=0.000997, step_loss=0.1007/27/2023 19:08:00 - INFO - __main__ - train loss is 33.39736779418308\n",
      "Steps:  65%|▋| 9692/15000 [1:23:11<16:01,  5.52it/s, lr=0.000997, step_loss=0.0307/27/2023 19:08:00 - INFO - __main__ - train loss is 33.42151806887705\n",
      "Steps:  65%|▋| 9693/15000 [1:23:11<15:57,  5.54it/s, lr=0.000997, step_loss=0.0207/27/2023 19:08:01 - INFO - __main__ - train loss is 33.67916331824381\n",
      "Steps:  65%|▋| 9694/15000 [1:23:11<15:55,  5.56it/s, lr=0.000997, step_loss=0.2507/27/2023 19:08:01 - INFO - __main__ - train loss is 33.86971436080057\n",
      "Steps:  65%|▋| 9695/15000 [1:23:11<16:01,  5.52it/s, lr=0.000997, step_loss=0.1907/27/2023 19:08:01 - INFO - __main__ - train loss is 34.556645374861546\n",
      "Steps:  65%|▋| 9696/15000 [1:23:12<22:09,  3.99it/s, lr=0.000997, step_loss=0.6807/27/2023 19:08:02 - INFO - __main__ - Per validation step average loss is 0.13787080347537994\n",
      "07/27/2023 19:08:02 - INFO - __main__ - Cumulative validation average loss is 0.13787080347537994\n",
      "07/27/2023 19:08:03 - INFO - __main__ - Per validation step average loss is 0.003766413778066635\n",
      "07/27/2023 19:08:03 - INFO - __main__ - Cumulative validation average loss is 0.14163721725344658\n",
      "07/27/2023 19:08:03 - INFO - __main__ - Per validation step average loss is 0.045469120144844055\n",
      "07/27/2023 19:08:03 - INFO - __main__ - Cumulative validation average loss is 0.18710633739829063\n",
      "07/27/2023 19:08:03 - INFO - __main__ - Per validation step average loss is 0.09845372289419174\n",
      "07/27/2023 19:08:03 - INFO - __main__ - Cumulative validation average loss is 0.2855600602924824\n",
      "07/27/2023 19:08:04 - INFO - __main__ - Per validation step average loss is 0.03909620642662048\n",
      "07/27/2023 19:08:04 - INFO - __main__ - Cumulative validation average loss is 0.32465626671910286\n",
      "07/27/2023 19:08:04 - INFO - __main__ - Per validation step average loss is 0.02212510071694851\n",
      "07/27/2023 19:08:04 - INFO - __main__ - Cumulative validation average loss is 0.34678136743605137\n",
      "07/27/2023 19:08:05 - INFO - __main__ - Per validation step average loss is 0.12237571179866791\n",
      "07/27/2023 19:08:05 - INFO - __main__ - Cumulative validation average loss is 0.4691570792347193\n",
      "07/27/2023 19:08:05 - INFO - __main__ - Per validation step average loss is 0.020268050953745842\n",
      "07/27/2023 19:08:05 - INFO - __main__ - Cumulative validation average loss is 0.4894251301884651\n",
      "07/27/2023 19:08:06 - INFO - __main__ - Per validation step average loss is 0.35403507947921753\n",
      "07/27/2023 19:08:06 - INFO - __main__ - Cumulative validation average loss is 0.8434602096676826\n",
      "07/27/2023 19:08:06 - INFO - __main__ - Per validation step average loss is 0.10777886211872101\n",
      "07/27/2023 19:08:06 - INFO - __main__ - Cumulative validation average loss is 0.9512390717864037\n",
      "07/27/2023 19:08:06 - INFO - __main__ - Per validation step average loss is 0.35070937871932983\n",
      "07/27/2023 19:08:06 - INFO - __main__ - Cumulative validation average loss is 1.3019484505057335\n",
      "07/27/2023 19:08:07 - INFO - __main__ - Per validation step average loss is 0.3349633514881134\n",
      "07/27/2023 19:08:07 - INFO - __main__ - Cumulative validation average loss is 1.636911801993847\n",
      "07/27/2023 19:08:07 - INFO - __main__ - Per validation step average loss is 0.004911935422569513\n",
      "07/27/2023 19:08:07 - INFO - __main__ - Cumulative validation average loss is 1.6418237374164164\n",
      "07/27/2023 19:08:08 - INFO - __main__ - Per validation step average loss is 0.06291595101356506\n",
      "07/27/2023 19:08:08 - INFO - __main__ - Cumulative validation average loss is 1.7047396884299815\n",
      "07/27/2023 19:08:08 - INFO - __main__ - Per validation step average loss is 0.08892681449651718\n",
      "07/27/2023 19:08:08 - INFO - __main__ - Cumulative validation average loss is 1.7936665029264987\n",
      "07/27/2023 19:08:08 - INFO - __main__ - Per validation step average loss is 0.006677163299173117\n",
      "07/27/2023 19:08:08 - INFO - __main__ - Cumulative validation average loss is 1.8003436662256718\n",
      "07/27/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.003950817044824362\n",
      "07/27/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 1.8042944832704961\n",
      "07/27/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.21009308099746704\n",
      "07/27/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 2.014387564267963\n",
      "07/27/2023 19:08:10 - INFO - __main__ - Per validation step average loss is 0.22722630202770233\n",
      "07/27/2023 19:08:10 - INFO - __main__ - Cumulative validation average loss is 2.2416138662956655\n",
      "07/27/2023 19:08:10 - INFO - __main__ - Per validation step average loss is 0.5329993963241577\n",
      "07/27/2023 19:08:10 - INFO - __main__ - Cumulative validation average loss is 2.774613262619823\n",
      "07/27/2023 19:08:11 - INFO - __main__ - Per validation step average loss is 0.046887047588825226\n",
      "07/27/2023 19:08:11 - INFO - __main__ - Cumulative validation average loss is 2.8215003102086484\n",
      "07/27/2023 19:08:11 - INFO - __main__ - Per validation step average loss is 0.017953887581825256\n",
      "07/27/2023 19:08:11 - INFO - __main__ - Cumulative validation average loss is 2.8394541977904737\n",
      "07/27/2023 19:08:11 - INFO - __main__ - Per validation step average loss is 0.6110343337059021\n",
      "07/27/2023 19:08:11 - INFO - __main__ - Cumulative validation average loss is 3.450488531496376\n",
      "07/27/2023 19:08:12 - INFO - __main__ - Per validation step average loss is 0.4595091640949249\n",
      "07/27/2023 19:08:12 - INFO - __main__ - Cumulative validation average loss is 3.9099976955913007\n",
      "07/27/2023 19:08:12 - INFO - __main__ - Per validation step average loss is 0.14387470483779907\n",
      "07/27/2023 19:08:12 - INFO - __main__ - Cumulative validation average loss is 4.0538724004291\n",
      "07/27/2023 19:08:13 - INFO - __main__ - Per validation step average loss is 0.005460591986775398\n",
      "07/27/2023 19:08:13 - INFO - __main__ - Cumulative validation average loss is 4.059332992415875\n",
      "07/27/2023 19:08:13 - INFO - __main__ - Per validation step average loss is 0.19733144342899323\n",
      "07/27/2023 19:08:13 - INFO - __main__ - Cumulative validation average loss is 4.256664435844868\n",
      "07/27/2023 19:08:13 - INFO - __main__ - Per validation step average loss is 0.1893223226070404\n",
      "07/27/2023 19:08:13 - INFO - __main__ - Cumulative validation average loss is 4.445986758451909\n",
      "07/27/2023 19:08:14 - INFO - __main__ - Per validation step average loss is 0.22652491927146912\n",
      "07/27/2023 19:08:14 - INFO - __main__ - Cumulative validation average loss is 4.672511677723378\n",
      "07/27/2023 19:08:14 - INFO - __main__ - Per validation step average loss is 0.4283309578895569\n",
      "07/27/2023 19:08:14 - INFO - __main__ - Cumulative validation average loss is 5.100842635612935\n",
      "07/27/2023 19:08:15 - INFO - __main__ - Per validation step average loss is 0.19239965081214905\n",
      "07/27/2023 19:08:15 - INFO - __main__ - Cumulative validation average loss is 5.293242286425084\n",
      "07/27/2023 19:08:15 - INFO - __main__ - Per validation step average loss is 0.1430966556072235\n",
      "07/27/2023 19:08:15 - INFO - __main__ - Cumulative validation average loss is 5.436338942032307\n",
      "07/27/2023 19:08:15 - INFO - __main__ - Per validation step average loss is 0.3134053349494934\n",
      "07/27/2023 19:08:15 - INFO - __main__ - Cumulative validation average loss is 5.749744276981801\n",
      "07/27/2023 19:08:16 - INFO - __main__ - Per validation step average loss is 0.31375178694725037\n",
      "07/27/2023 19:08:16 - INFO - __main__ - Cumulative validation average loss is 6.063496063929051\n",
      "07/27/2023 19:08:16 - INFO - __main__ - Per validation step average loss is 0.0015256854239851236\n",
      "07/27/2023 19:08:16 - INFO - __main__ - Cumulative validation average loss is 6.065021749353036\n",
      "07/27/2023 19:08:17 - INFO - __main__ - Per validation step average loss is 0.24452485144138336\n",
      "07/27/2023 19:08:17 - INFO - __main__ - Cumulative validation average loss is 6.30954660079442\n",
      "07/27/2023 19:08:17 - INFO - __main__ - Per validation step average loss is 0.05810333043336868\n",
      "07/27/2023 19:08:17 - INFO - __main__ - Cumulative validation average loss is 6.367649931227788\n",
      "07/27/2023 19:08:18 - INFO - __main__ - Per validation step average loss is 0.005316582508385181\n",
      "07/27/2023 19:08:18 - INFO - __main__ - Cumulative validation average loss is 6.3729665137361735\n",
      "07/27/2023 19:08:18 - INFO - __main__ - Per validation step average loss is 0.0879381075501442\n",
      "07/27/2023 19:08:18 - INFO - __main__ - Cumulative validation average loss is 6.460904621286318\n",
      "07/27/2023 19:08:18 - INFO - __main__ - Per validation step average loss is 0.6296103000640869\n",
      "07/27/2023 19:08:18 - INFO - __main__ - Cumulative validation average loss is 7.090514921350405\n",
      "07/27/2023 19:08:19 - INFO - __main__ - Per validation step average loss is 0.1835518479347229\n",
      "07/27/2023 19:08:19 - INFO - __main__ - Cumulative validation average loss is 7.2740667692851275\n",
      "07/27/2023 19:08:19 - INFO - __main__ - Per validation step average loss is 0.2165411114692688\n",
      "07/27/2023 19:08:19 - INFO - __main__ - Cumulative validation average loss is 7.490607880754396\n",
      "07/27/2023 19:08:20 - INFO - __main__ - Per validation step average loss is 0.13534852862358093\n",
      "07/27/2023 19:08:20 - INFO - __main__ - Cumulative validation average loss is 7.625956409377977\n",
      "07/27/2023 19:08:20 - INFO - __main__ - Per validation step average loss is 0.10681864619255066\n",
      "07/27/2023 19:08:20 - INFO - __main__ - Cumulative validation average loss is 7.732775055570528\n",
      "07/27/2023 19:08:20 - INFO - __main__ - Per validation step average loss is 0.002055359072983265\n",
      "07/27/2023 19:08:20 - INFO - __main__ - Cumulative validation average loss is 7.734830414643511\n",
      "07/27/2023 19:08:21 - INFO - __main__ - Per validation step average loss is 0.1817111372947693\n",
      "07/27/2023 19:08:21 - INFO - __main__ - Cumulative validation average loss is 7.9165415519382805\n",
      "07/27/2023 19:08:21 - INFO - __main__ - Per validation step average loss is 0.1128726601600647\n",
      "07/27/2023 19:08:21 - INFO - __main__ - Cumulative validation average loss is 8.029414212098345\n",
      "07/27/2023 19:08:22 - INFO - __main__ - Per validation step average loss is 0.0017776741879060864\n",
      "07/27/2023 19:08:22 - INFO - __main__ - Cumulative validation average loss is 8.031191886286251\n",
      "07/27/2023 19:08:22 - INFO - __main__ - Per validation step average loss is 0.03796485438942909\n",
      "07/27/2023 19:08:22 - INFO - __main__ - Cumulative validation average loss is 8.06915674067568\n",
      "07/27/2023 19:08:23 - INFO - __main__ - Per validation step average loss is 0.33334895968437195\n",
      "07/27/2023 19:08:23 - INFO - __main__ - Cumulative validation average loss is 8.402505700360052\n",
      "07/27/2023 19:08:23 - INFO - __main__ - Per validation step average loss is 0.07373085618019104\n",
      "07/27/2023 19:08:23 - INFO - __main__ - Cumulative validation average loss is 8.476236556540243\n",
      "07/27/2023 19:08:23 - INFO - __main__ - Per validation step average loss is 0.018707791343331337\n",
      "07/27/2023 19:08:23 - INFO - __main__ - Cumulative validation average loss is 8.494944347883575\n",
      "07/27/2023 19:08:24 - INFO - __main__ - Per validation step average loss is 0.10727977752685547\n",
      "07/27/2023 19:08:24 - INFO - __main__ - Cumulative validation average loss is 8.60222412541043\n",
      "07/27/2023 19:08:24 - INFO - __main__ - Per validation step average loss is 0.005241736304014921\n",
      "07/27/2023 19:08:24 - INFO - __main__ - Cumulative validation average loss is 8.607465861714445\n",
      "07/27/2023 19:08:25 - INFO - __main__ - Per validation step average loss is 0.19697001576423645\n",
      "07/27/2023 19:08:25 - INFO - __main__ - Cumulative validation average loss is 8.804435877478682\n",
      "07/27/2023 19:08:25 - INFO - __main__ - Per validation step average loss is 0.431277334690094\n",
      "07/27/2023 19:08:25 - INFO - __main__ - Cumulative validation average loss is 9.235713212168775\n",
      "07/27/2023 19:08:25 - INFO - __main__ - Per validation step average loss is 0.18626323342323303\n",
      "07/27/2023 19:08:25 - INFO - __main__ - Cumulative validation average loss is 9.421976445592009\n",
      "07/27/2023 19:08:26 - INFO - __main__ - Per validation step average loss is 0.018247228115797043\n",
      "07/27/2023 19:08:26 - INFO - __main__ - Cumulative validation average loss is 9.440223673707806\n",
      "07/27/2023 19:08:26 - INFO - __main__ - Per validation step average loss is 0.09496652334928513\n",
      "07/27/2023 19:08:26 - INFO - __main__ - Cumulative validation average loss is 9.53519019705709\n",
      "07/27/2023 19:08:27 - INFO - __main__ - Per validation step average loss is 0.03904701769351959\n",
      "07/27/2023 19:08:27 - INFO - __main__ - Cumulative validation average loss is 9.57423721475061\n",
      "07/27/2023 19:08:27 - INFO - __main__ - Per validation step average loss is 0.007969348691403866\n",
      "07/27/2023 19:08:27 - INFO - __main__ - Cumulative validation average loss is 9.582206563442014\n",
      "07/27/2023 19:08:28 - INFO - __main__ - Per validation step average loss is 0.01974400505423546\n",
      "07/27/2023 19:08:28 - INFO - __main__ - Cumulative validation average loss is 9.60195056849625\n",
      "07/27/2023 19:08:28 - INFO - __main__ - Per validation step average loss is 0.0029801346827298403\n",
      "07/27/2023 19:08:28 - INFO - __main__ - Cumulative validation average loss is 9.60493070317898\n",
      "07/27/2023 19:08:28 - INFO - __main__ - Per validation step average loss is 0.02032553032040596\n",
      "07/27/2023 19:08:28 - INFO - __main__ - Cumulative validation average loss is 9.625256233499385\n",
      "07/27/2023 19:08:29 - INFO - __main__ - Per validation step average loss is 0.5771251916885376\n",
      "07/27/2023 19:08:29 - INFO - __main__ - Cumulative validation average loss is 10.202381425187923\n",
      "07/27/2023 19:08:29 - INFO - __main__ - Per validation step average loss is 0.002217056229710579\n",
      "07/27/2023 19:08:29 - INFO - __main__ - Cumulative validation average loss is 10.204598481417634\n",
      "07/27/2023 19:08:30 - INFO - __main__ - Per validation step average loss is 0.07045362144708633\n",
      "07/27/2023 19:08:30 - INFO - __main__ - Cumulative validation average loss is 10.27505210286472\n",
      "07/27/2023 19:08:30 - INFO - __main__ - Per validation step average loss is 0.10117296874523163\n",
      "07/27/2023 19:08:30 - INFO - __main__ - Cumulative validation average loss is 10.376225071609952\n",
      "07/27/2023 19:08:30 - INFO - __main__ - Per validation step average loss is 0.1641440987586975\n",
      "07/27/2023 19:08:30 - INFO - __main__ - Cumulative validation average loss is 10.540369170368649\n",
      "07/27/2023 19:08:31 - INFO - __main__ - Per validation step average loss is 0.0022013834677636623\n",
      "07/27/2023 19:08:31 - INFO - __main__ - Cumulative validation average loss is 10.542570553836413\n",
      "07/27/2023 19:08:31 - INFO - __main__ - Per validation step average loss is 0.005261977668851614\n",
      "07/27/2023 19:08:31 - INFO - __main__ - Cumulative validation average loss is 10.547832531505264\n",
      "07/27/2023 19:08:32 - INFO - __main__ - Per validation step average loss is 0.0028863283805549145\n",
      "07/27/2023 19:08:32 - INFO - __main__ - Cumulative validation average loss is 10.55071885988582\n",
      "07/27/2023 19:08:32 - INFO - __main__ - Per validation step average loss is 0.31481635570526123\n",
      "07/27/2023 19:08:32 - INFO - __main__ - Cumulative validation average loss is 10.86553521559108\n",
      "07/27/2023 19:08:33 - INFO - __main__ - Per validation step average loss is 0.05876617506146431\n",
      "07/27/2023 19:08:33 - INFO - __main__ - Cumulative validation average loss is 10.924301390652545\n",
      "07/27/2023 19:08:33 - INFO - __main__ - Per validation step average loss is 0.003738866653293371\n",
      "07/27/2023 19:08:33 - INFO - __main__ - Cumulative validation average loss is 10.928040257305838\n",
      "07/27/2023 19:08:33 - INFO - __main__ - Per validation step average loss is 0.0018989054951816797\n",
      "07/27/2023 19:08:33 - INFO - __main__ - Cumulative validation average loss is 10.92993916280102\n",
      "07/27/2023 19:08:34 - INFO - __main__ - Per validation step average loss is 0.0439230278134346\n",
      "07/27/2023 19:08:34 - INFO - __main__ - Cumulative validation average loss is 10.973862190614454\n",
      "07/27/2023 19:08:34 - INFO - __main__ - Per validation step average loss is 0.12304522097110748\n",
      "07/27/2023 19:08:34 - INFO - __main__ - Cumulative validation average loss is 11.096907411585562\n",
      "07/27/2023 19:08:35 - INFO - __main__ - Per validation step average loss is 0.2806341350078583\n",
      "07/27/2023 19:08:35 - INFO - __main__ - Cumulative validation average loss is 11.37754154659342\n",
      "07/27/2023 19:08:35 - INFO - __main__ - Average validation loss for Epoch 31 is 0.14401951324801798\n",
      "07/27/2023 19:08:35 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:09:32 - INFO - __main__ - Starting epoch 32\n",
      "07/27/2023 19:09:33 - INFO - __main__ - train loss is 0.016624759882688522\n",
      "Steps:  65%|▋| 9697/15000 [1:24:43<40:36:45, 27.57s/it, lr=0.000997, step_loss=007/27/2023 19:09:33 - INFO - __main__ - train loss is 0.3063873164355755\n",
      "Steps:  65%|▋| 9698/15000 [1:24:43<28:30:19, 19.35s/it, lr=0.000997, step_loss=007/27/2023 19:09:33 - INFO - __main__ - train loss is 0.3291938714683056\n",
      "Steps:  65%|▋| 9699/15000 [1:24:43<20:01:55, 13.60s/it, lr=0.000997, step_loss=007/27/2023 19:09:33 - INFO - __main__ - train loss is 0.38895637169480324\n",
      "Steps:  65%|▋| 9700/15000 [1:24:43<14:06:06,  9.58s/it, lr=0.000997, step_loss=007/27/2023 19:09:33 - INFO - __main__ - train loss is 0.4015716724097729\n",
      "Steps:  65%|▋| 9701/15000 [1:24:44<9:56:54,  6.76s/it, lr=0.000997, step_loss=0.07/27/2023 19:09:33 - INFO - __main__ - train loss is 0.4372883178293705\n",
      "Steps:  65%|▋| 9702/15000 [1:24:44<7:02:34,  4.79s/it, lr=0.000997, step_loss=0.07/27/2023 19:09:34 - INFO - __main__ - train loss is 0.4590658061206341\n",
      "Steps:  65%|▋| 9703/15000 [1:24:44<5:00:34,  3.40s/it, lr=0.000997, step_loss=0.07/27/2023 19:09:34 - INFO - __main__ - train loss is 0.5723728574812412\n",
      "Steps:  65%|▋| 9704/15000 [1:24:44<3:35:05,  2.44s/it, lr=0.000997, step_loss=0.07/27/2023 19:09:34 - INFO - __main__ - train loss is 0.5795276500284672\n",
      "Steps:  65%|▋| 9705/15000 [1:24:44<2:35:15,  1.76s/it, lr=0.000997, step_loss=0.07/27/2023 19:09:34 - INFO - __main__ - train loss is 0.7286142595112324\n",
      "Steps:  65%|▋| 9706/15000 [1:24:44<1:53:23,  1.29s/it, lr=0.000997, step_loss=0.07/27/2023 19:09:34 - INFO - __main__ - train loss is 0.7621941976249218\n",
      "Steps:  65%|▋| 9707/15000 [1:24:45<1:24:14,  1.05it/s, lr=0.000997, step_loss=0.07/27/2023 19:09:35 - INFO - __main__ - train loss is 0.8309973292052746\n",
      "Steps:  65%|▋| 9708/15000 [1:24:45<1:03:43,  1.38it/s, lr=0.000997, step_loss=0.07/27/2023 19:09:35 - INFO - __main__ - train loss is 0.8783962316811085\n",
      "Steps:  65%|▋| 9709/15000 [1:24:45<49:19,  1.79it/s, lr=0.000997, step_loss=0.0407/27/2023 19:09:35 - INFO - __main__ - train loss is 1.1809119768440723\n",
      "Steps:  65%|▋| 9710/15000 [1:24:45<39:16,  2.25it/s, lr=0.000997, step_loss=0.3007/27/2023 19:09:35 - INFO - __main__ - train loss is 1.31565834954381\n",
      "Steps:  65%|▋| 9711/15000 [1:24:45<32:12,  2.74it/s, lr=0.000997, step_loss=0.1307/27/2023 19:09:35 - INFO - __main__ - train loss is 1.5927443988621235\n",
      "Steps:  65%|▋| 9712/15000 [1:24:46<27:16,  3.23it/s, lr=0.000997, step_loss=0.2707/27/2023 19:09:35 - INFO - __main__ - train loss is 1.7242813296616077\n",
      "Steps:  65%|▋| 9713/15000 [1:24:46<23:48,  3.70it/s, lr=0.000997, step_loss=0.1307/27/2023 19:09:36 - INFO - __main__ - train loss is 1.8474356718361378\n",
      "Steps:  65%|▋| 9714/15000 [1:24:46<21:24,  4.11it/s, lr=0.000997, step_loss=0.1207/27/2023 19:09:36 - INFO - __main__ - train loss is 2.54259504750371\n",
      "Steps:  65%|▋| 9715/15000 [1:24:46<19:54,  4.42it/s, lr=0.000997, step_loss=0.6907/27/2023 19:09:36 - INFO - __main__ - train loss is 2.5611687153577805\n",
      "Steps:  65%|▋| 9716/15000 [1:24:46<18:44,  4.70it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:36 - INFO - __main__ - train loss is 2.6498914510011673\n",
      "Steps:  65%|▋| 9717/15000 [1:24:46<17:52,  4.92it/s, lr=0.000997, step_loss=0.0807/27/2023 19:09:36 - INFO - __main__ - train loss is 2.6577825667336583\n",
      "Steps:  65%|▋| 9718/15000 [1:24:47<17:25,  5.05it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:37 - INFO - __main__ - train loss is 3.056501221843064\n",
      "Steps:  65%|▋| 9719/15000 [1:24:47<17:11,  5.12it/s, lr=0.000997, step_loss=0.3907/27/2023 19:09:37 - INFO - __main__ - train loss is 3.06222702935338\n",
      "Steps:  65%|▋| 9720/15000 [1:24:47<16:45,  5.25it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:37 - INFO - __main__ - train loss is 3.218520049005747\n",
      "Steps:  65%|▋| 9721/15000 [1:24:47<16:28,  5.34it/s, lr=0.000997, step_loss=0.1507/27/2023 19:09:37 - INFO - __main__ - train loss is 3.8679976500570774\n",
      "Steps:  65%|▋| 9722/15000 [1:24:47<16:17,  5.40it/s, lr=0.000997, step_loss=0.6407/27/2023 19:09:37 - INFO - __main__ - train loss is 4.317884687334299\n",
      "Steps:  65%|▋| 9723/15000 [1:24:48<16:07,  5.45it/s, lr=0.000997, step_loss=0.4507/27/2023 19:09:37 - INFO - __main__ - train loss is 4.384080994874239\n",
      "Steps:  65%|▋| 9724/15000 [1:24:48<16:01,  5.49it/s, lr=0.000997, step_loss=0.0607/27/2023 19:09:38 - INFO - __main__ - train loss is 4.413932370021939\n",
      "Steps:  65%|▋| 9725/15000 [1:24:48<15:56,  5.51it/s, lr=0.000997, step_loss=0.0207/27/2023 19:09:38 - INFO - __main__ - train loss is 4.695932434871793\n",
      "Steps:  65%|▋| 9726/15000 [1:24:48<15:53,  5.53it/s, lr=0.000997, step_loss=0.2807/27/2023 19:09:38 - INFO - __main__ - train loss is 4.7162849847227335\n",
      "Steps:  65%|▋| 9727/15000 [1:24:48<15:51,  5.54it/s, lr=0.000997, step_loss=0.0207/27/2023 19:09:38 - INFO - __main__ - train loss is 4.945494631305337\n",
      "Steps:  65%|▋| 9728/15000 [1:24:48<15:49,  5.55it/s, lr=0.000997, step_loss=0.2207/27/2023 19:09:38 - INFO - __main__ - train loss is 5.439891854301095\n",
      "Steps:  65%|▋| 9729/15000 [1:24:49<15:48,  5.56it/s, lr=0.000997, step_loss=0.4907/27/2023 19:09:39 - INFO - __main__ - train loss is 5.452863705344498\n",
      "Steps:  65%|▋| 9730/15000 [1:24:49<15:47,  5.56it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:39 - INFO - __main__ - train loss is 5.466467109508812\n",
      "Steps:  65%|▋| 9731/15000 [1:24:49<15:46,  5.57it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:39 - INFO - __main__ - train loss is 5.616714117117226\n",
      "Steps:  65%|▋| 9732/15000 [1:24:49<15:46,  5.57it/s, lr=0.000997, step_loss=0.1507/27/2023 19:09:39 - INFO - __main__ - train loss is 5.796418366022408\n",
      "Steps:  65%|▋| 9733/15000 [1:24:49<15:45,  5.57it/s, lr=0.000997, step_loss=0.1807/27/2023 19:09:39 - INFO - __main__ - train loss is 6.2618144722655416\n",
      "Steps:  65%|▋| 9734/15000 [1:24:50<15:44,  5.57it/s, lr=0.000997, step_loss=0.4607/27/2023 19:09:39 - INFO - __main__ - train loss is 6.285413260571659\n",
      "Steps:  65%|▋| 9735/15000 [1:24:50<15:44,  5.57it/s, lr=0.000997, step_loss=0.0207/27/2023 19:09:40 - INFO - __main__ - train loss is 6.291948800906539\n",
      "Steps:  65%|▋| 9736/15000 [1:24:50<15:44,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:40 - INFO - __main__ - train loss is 6.361394761130214\n",
      "Steps:  65%|▋| 9737/15000 [1:24:50<15:48,  5.55it/s, lr=0.000997, step_loss=0.0607/27/2023 19:09:40 - INFO - __main__ - train loss is 6.364297865424305\n",
      "Steps:  65%|▋| 9738/15000 [1:24:50<15:47,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:40 - INFO - __main__ - train loss is 6.367401606403291\n",
      "Steps:  65%|▋| 9739/15000 [1:24:50<15:46,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:40 - INFO - __main__ - train loss is 6.455695143900812\n",
      "Steps:  65%|▋| 9740/15000 [1:24:51<15:45,  5.57it/s, lr=0.000997, step_loss=0.0807/27/2023 19:09:41 - INFO - __main__ - train loss is 6.469238919205964\n",
      "Steps:  65%|▋| 9741/15000 [1:24:51<15:48,  5.55it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:41 - INFO - __main__ - train loss is 6.718851652927697\n",
      "Steps:  65%|▋| 9742/15000 [1:24:51<15:46,  5.56it/s, lr=0.000997, step_loss=0.2507/27/2023 19:09:41 - INFO - __main__ - train loss is 6.772912275977433\n",
      "Steps:  65%|▋| 9743/15000 [1:24:51<15:44,  5.56it/s, lr=0.000997, step_loss=0.0507/27/2023 19:09:41 - INFO - __main__ - train loss is 6.827348423190415\n",
      "Steps:  65%|▋| 9744/15000 [1:24:51<15:44,  5.56it/s, lr=0.000997, step_loss=0.0507/27/2023 19:09:41 - INFO - __main__ - train loss is 6.917786625213921\n",
      "Steps:  65%|▋| 9745/15000 [1:24:52<15:52,  5.52it/s, lr=0.000997, step_loss=0.0907/27/2023 19:09:41 - INFO - __main__ - train loss is 6.9491899544373155\n",
      "Steps:  65%|▋| 9746/15000 [1:24:52<15:52,  5.52it/s, lr=0.000997, step_loss=0.0307/27/2023 19:09:42 - INFO - __main__ - train loss is 7.031524048186839\n",
      "Steps:  65%|▋| 9747/15000 [1:24:52<15:50,  5.53it/s, lr=0.000997, step_loss=0.0807/27/2023 19:09:42 - INFO - __main__ - train loss is 7.353844062425196\n",
      "Steps:  65%|▋| 9748/15000 [1:24:52<15:47,  5.54it/s, lr=0.000997, step_loss=0.3207/27/2023 19:09:42 - INFO - __main__ - train loss is 7.934515253640711\n",
      "Steps:  65%|▋| 9749/15000 [1:24:52<15:45,  5.55it/s, lr=0.000997, step_loss=0.5807/27/2023 19:09:42 - INFO - __main__ - train loss is 8.217740670777857\n",
      "Steps:  65%|▋| 9750/15000 [1:24:52<15:44,  5.56it/s, lr=0.000997, step_loss=0.2807/27/2023 19:09:42 - INFO - __main__ - train loss is 8.353251249529421\n",
      "Steps:  65%|▋| 9751/15000 [1:24:53<15:43,  5.56it/s, lr=0.000997, step_loss=0.1307/27/2023 19:09:42 - INFO - __main__ - train loss is 8.528723732568324\n",
      "Steps:  65%|▋| 9752/15000 [1:24:53<15:43,  5.56it/s, lr=0.000997, step_loss=0.1707/27/2023 19:09:43 - INFO - __main__ - train loss is 8.551366477273405\n",
      "Steps:  65%|▋| 9753/15000 [1:24:53<15:42,  5.57it/s, lr=0.000997, step_loss=0.0207/27/2023 19:09:43 - INFO - __main__ - train loss is 8.55408932408318\n",
      "Steps:  65%|▋| 9754/15000 [1:24:53<15:42,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:43 - INFO - __main__ - train loss is 8.562145778443664\n",
      "Steps:  65%|▋| 9755/15000 [1:24:53<15:42,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:43 - INFO - __main__ - train loss is 8.71299017360434\n",
      "Steps:  65%|▋| 9756/15000 [1:24:54<15:42,  5.56it/s, lr=0.000997, step_loss=0.1507/27/2023 19:09:43 - INFO - __main__ - train loss is 8.714172640698962\n",
      "Steps:  65%|▋| 9757/15000 [1:24:54<15:41,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:44 - INFO - __main__ - train loss is 8.729288621689193\n",
      "Steps:  65%|▋| 9758/15000 [1:24:54<15:41,  5.57it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:44 - INFO - __main__ - train loss is 9.046672000433318\n",
      "Steps:  65%|▋| 9759/15000 [1:24:54<15:44,  5.55it/s, lr=0.000997, step_loss=0.3107/27/2023 19:09:44 - INFO - __main__ - train loss is 9.052980279433541\n",
      "Steps:  65%|▋| 9760/15000 [1:24:54<15:43,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:44 - INFO - __main__ - train loss is 9.208139901864342\n",
      "Steps:  65%|▋| 9761/15000 [1:24:54<15:42,  5.56it/s, lr=0.000997, step_loss=0.1507/27/2023 19:09:44 - INFO - __main__ - train loss is 9.30344620149117\n",
      "Steps:  65%|▋| 9762/15000 [1:24:55<15:41,  5.56it/s, lr=0.000997, step_loss=0.0907/27/2023 19:09:44 - INFO - __main__ - train loss is 9.499374223756604\n",
      "Steps:  65%|▋| 9763/15000 [1:24:55<15:40,  5.57it/s, lr=0.000997, step_loss=0.1907/27/2023 19:09:45 - INFO - __main__ - train loss is 9.513023435953073\n",
      "Steps:  65%|▋| 9764/15000 [1:24:55<15:40,  5.57it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:45 - INFO - __main__ - train loss is 9.643784537795\n",
      "Steps:  65%|▋| 9765/15000 [1:24:55<15:39,  5.57it/s, lr=0.000997, step_loss=0.1307/27/2023 19:09:45 - INFO - __main__ - train loss is 9.714195258799009\n",
      "Steps:  65%|▋| 9766/15000 [1:24:55<15:39,  5.57it/s, lr=0.000997, step_loss=0.0707/27/2023 19:09:45 - INFO - __main__ - train loss is 9.745558760943823\n",
      "Steps:  65%|▋| 9767/15000 [1:24:55<15:38,  5.57it/s, lr=0.000997, step_loss=0.0307/27/2023 19:09:45 - INFO - __main__ - train loss is 9.748759782291017\n",
      "Steps:  65%|▋| 9768/15000 [1:24:56<15:38,  5.58it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:46 - INFO - __main__ - train loss is 9.903455769992433\n",
      "Steps:  65%|▋| 9769/15000 [1:24:56<15:38,  5.57it/s, lr=0.000997, step_loss=0.1507/27/2023 19:09:46 - INFO - __main__ - train loss is 9.907417157082818\n",
      "Steps:  65%|▋| 9770/15000 [1:24:56<15:38,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:46 - INFO - __main__ - train loss is 10.08103298523929\n",
      "Steps:  65%|▋| 9771/15000 [1:24:56<15:38,  5.57it/s, lr=0.000997, step_loss=0.1707/27/2023 19:09:46 - INFO - __main__ - train loss is 10.088589650462382\n",
      "Steps:  65%|▋| 9772/15000 [1:24:56<15:37,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:46 - INFO - __main__ - train loss is 10.48111794597935\n",
      "Steps:  65%|▋| 9773/15000 [1:24:57<15:37,  5.57it/s, lr=0.000997, step_loss=0.3907/27/2023 19:09:46 - INFO - __main__ - train loss is 10.48769430804532\n",
      "Steps:  65%|▋| 9774/15000 [1:24:57<15:37,  5.58it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:47 - INFO - __main__ - train loss is 10.490543728810735\n",
      "Steps:  65%|▋| 9775/15000 [1:24:57<15:36,  5.58it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:47 - INFO - __main__ - train loss is 10.790118401986547\n",
      "Steps:  65%|▋| 9776/15000 [1:24:57<15:36,  5.58it/s, lr=0.000997, step_loss=0.3]07/27/2023 19:09:47 - INFO - __main__ - train loss is 11.299956148606725\n",
      "Steps:  65%|▋| 9777/15000 [1:24:57<15:36,  5.58it/s, lr=0.000997, step_loss=0.5107/27/2023 19:09:47 - INFO - __main__ - train loss is 11.548197215539403\n",
      "Steps:  65%|▋| 9778/15000 [1:24:57<15:36,  5.58it/s, lr=0.000997, step_loss=0.2407/27/2023 19:09:47 - INFO - __main__ - train loss is 11.807135408860631\n",
      "Steps:  65%|▋| 9779/15000 [1:24:58<15:36,  5.58it/s, lr=0.000997, step_loss=0.2507/27/2023 19:09:48 - INFO - __main__ - train loss is 11.814115419168957\n",
      "Steps:  65%|▋| 9780/15000 [1:24:58<15:36,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:48 - INFO - __main__ - train loss is 11.89736503281165\n",
      "Steps:  65%|▋| 9781/15000 [1:24:58<15:36,  5.58it/s, lr=0.000997, step_loss=0.0807/27/2023 19:09:48 - INFO - __main__ - train loss is 11.965235329349525\n",
      "Steps:  65%|▋| 9782/15000 [1:24:58<15:35,  5.58it/s, lr=0.000997, step_loss=0.0607/27/2023 19:09:48 - INFO - __main__ - train loss is 12.068940936704166\n",
      "Steps:  65%|▋| 9783/15000 [1:24:58<15:35,  5.58it/s, lr=0.000997, step_loss=0.1007/27/2023 19:09:48 - INFO - __main__ - train loss is 12.18473191477824\n",
      "Steps:  65%|▋| 9784/15000 [1:24:59<15:35,  5.57it/s, lr=0.000997, step_loss=0.1107/27/2023 19:09:48 - INFO - __main__ - train loss is 12.52394921996165\n",
      "Steps:  65%|▋| 9785/15000 [1:24:59<15:35,  5.58it/s, lr=0.000997, step_loss=0.3307/27/2023 19:09:49 - INFO - __main__ - train loss is 12.526373610948212\n",
      "Steps:  65%|▋| 9786/15000 [1:24:59<15:35,  5.58it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:49 - INFO - __main__ - train loss is 12.531609767233022\n",
      "Steps:  65%|▋| 9787/15000 [1:24:59<15:34,  5.58it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:49 - INFO - __main__ - train loss is 12.551687163417228\n",
      "Steps:  65%|▋| 9788/15000 [1:24:59<15:34,  5.58it/s, lr=0.000997, step_loss=0.0207/27/2023 19:09:49 - INFO - __main__ - train loss is 12.570900087361224\n",
      "Steps:  65%|▋| 9789/15000 [1:24:59<15:43,  5.53it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:49 - INFO - __main__ - train loss is 12.626678993110545\n",
      "Steps:  65%|▋| 9790/15000 [1:25:00<15:44,  5.52it/s, lr=0.000997, step_loss=0.0507/27/2023 19:09:49 - INFO - __main__ - train loss is 13.016274144058116\n",
      "Steps:  65%|▋| 9791/15000 [1:25:00<15:41,  5.53it/s, lr=0.000997, step_loss=0.3907/27/2023 19:09:50 - INFO - __main__ - train loss is 13.073270087246783\n",
      "Steps:  65%|▋| 9792/15000 [1:25:00<15:40,  5.54it/s, lr=0.000997, step_loss=0.0507/27/2023 19:09:50 - INFO - __main__ - train loss is 13.08258114673663\n",
      "Steps:  65%|▋| 9793/15000 [1:25:00<15:46,  5.50it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:50 - INFO - __main__ - train loss is 13.649029358406551\n",
      "Steps:  65%|▋| 9794/15000 [1:25:00<15:42,  5.53it/s, lr=0.000997, step_loss=0.5607/27/2023 19:09:50 - INFO - __main__ - train loss is 13.662708925199695\n",
      "Steps:  65%|▋| 9795/15000 [1:25:01<15:39,  5.54it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:50 - INFO - __main__ - train loss is 13.984091000747867\n",
      "Steps:  65%|▋| 9796/15000 [1:25:01<15:37,  5.55it/s, lr=0.000997, step_loss=0.3207/27/2023 19:09:51 - INFO - __main__ - train loss is 14.031433159601875\n",
      "Steps:  65%|▋| 9797/15000 [1:25:01<15:36,  5.56it/s, lr=0.000997, step_loss=0.0407/27/2023 19:09:51 - INFO - __main__ - train loss is 14.697396451723762\n",
      "Steps:  65%|▋| 9798/15000 [1:25:01<15:35,  5.56it/s, lr=0.000997, step_loss=0.6607/27/2023 19:09:51 - INFO - __main__ - train loss is 14.871241489541717\n",
      "Steps:  65%|▋| 9799/15000 [1:25:01<15:34,  5.57it/s, lr=0.000997, step_loss=0.1707/27/2023 19:09:51 - INFO - __main__ - train loss is 15.110378245008178\n",
      "Steps:  65%|▋| 9800/15000 [1:25:01<15:33,  5.57it/s, lr=0.000997, step_loss=0.2307/27/2023 19:09:51 - INFO - __main__ - train loss is 15.113656206638552\n",
      "Steps:  65%|▋| 9801/15000 [1:25:02<15:32,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:51 - INFO - __main__ - train loss is 15.260602040798403\n",
      "Steps:  65%|▋| 9802/15000 [1:25:02<15:32,  5.58it/s, lr=0.000997, step_loss=0.1407/27/2023 19:09:52 - INFO - __main__ - train loss is 15.268048630678095\n",
      "Steps:  65%|▋| 9803/15000 [1:25:02<15:31,  5.58it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:52 - INFO - __main__ - train loss is 15.27324171049986\n",
      "Steps:  65%|▋| 9804/15000 [1:25:02<15:32,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:52 - INFO - __main__ - train loss is 15.281696532503702\n",
      "Steps:  65%|▋| 9805/15000 [1:25:02<15:40,  5.52it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:52 - INFO - __main__ - train loss is 15.292798083857633\n",
      "Steps:  65%|▋| 9806/15000 [1:25:03<15:40,  5.52it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:52 - INFO - __main__ - train loss is 15.462280285195448\n",
      "Steps:  65%|▋| 9807/15000 [1:25:03<15:38,  5.53it/s, lr=0.000997, step_loss=0.1607/27/2023 19:09:53 - INFO - __main__ - train loss is 15.467875463073142\n",
      "Steps:  65%|▋| 9808/15000 [1:25:03<15:36,  5.54it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:53 - INFO - __main__ - train loss is 15.47105262929108\n",
      "Steps:  65%|▋| 9809/15000 [1:25:03<15:34,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:53 - INFO - __main__ - train loss is 15.485170148662291\n",
      "Steps:  65%|▋| 9810/15000 [1:25:03<15:33,  5.56it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:53 - INFO - __main__ - train loss is 15.68266678636428\n",
      "Steps:  65%|▋| 9811/15000 [1:25:03<15:31,  5.57it/s, lr=0.000997, step_loss=0.1907/27/2023 19:09:53 - INFO - __main__ - train loss is 15.844015457085334\n",
      "Steps:  65%|▋| 9812/15000 [1:25:04<15:31,  5.57it/s, lr=0.000997, step_loss=0.1607/27/2023 19:09:53 - INFO - __main__ - train loss is 16.04300624912139\n",
      "Steps:  65%|▋| 9813/15000 [1:25:04<15:30,  5.57it/s, lr=0.000997, step_loss=0.1907/27/2023 19:09:54 - INFO - __main__ - train loss is 16.13316327368375\n",
      "Steps:  65%|▋| 9814/15000 [1:25:04<15:30,  5.57it/s, lr=0.000997, step_loss=0.0907/27/2023 19:09:54 - INFO - __main__ - train loss is 16.232046008459292\n",
      "Steps:  65%|▋| 9815/15000 [1:25:04<15:36,  5.54it/s, lr=0.000997, step_loss=0.0907/27/2023 19:09:54 - INFO - __main__ - train loss is 16.40821065043565\n",
      "Steps:  65%|▋| 9816/15000 [1:25:04<15:34,  5.55it/s, lr=0.000997, step_loss=0.1707/27/2023 19:09:54 - INFO - __main__ - train loss is 16.506292105070315\n",
      "Steps:  65%|▋| 9817/15000 [1:25:04<15:32,  5.56it/s, lr=0.000997, step_loss=0.0907/27/2023 19:09:54 - INFO - __main__ - train loss is 16.5633933696663\n",
      "Steps:  65%|▋| 9818/15000 [1:25:05<15:32,  5.56it/s, lr=0.000997, step_loss=0.0507/27/2023 19:09:55 - INFO - __main__ - train loss is 17.295911684981547\n",
      "Steps:  65%|▋| 9819/15000 [1:25:05<15:31,  5.56it/s, lr=0.000997, step_loss=0.7307/27/2023 19:09:55 - INFO - __main__ - train loss is 17.663351372233592\n",
      "Steps:  65%|▋| 9820/15000 [1:25:05<15:30,  5.57it/s, lr=0.000997, step_loss=0.3607/27/2023 19:09:55 - INFO - __main__ - train loss is 17.66509674291592\n",
      "Steps:  65%|▋| 9821/15000 [1:25:05<15:36,  5.53it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:55 - INFO - __main__ - train loss is 17.67977050121408\n",
      "Steps:  65%|▋| 9822/15000 [1:25:05<15:33,  5.55it/s, lr=0.000997, step_loss=0.0107/27/2023 19:09:55 - INFO - __main__ - train loss is 17.682250991812907\n",
      "Steps:  65%|▋| 9823/15000 [1:25:06<15:32,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:55 - INFO - __main__ - train loss is 17.68613768031355\n",
      "Steps:  65%|▋| 9824/15000 [1:25:06<15:31,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:56 - INFO - __main__ - train loss is 17.887452993891202\n",
      "Steps:  66%|▋| 9825/15000 [1:25:06<15:30,  5.56it/s, lr=0.000997, step_loss=0.2007/27/2023 19:09:56 - INFO - __main__ - train loss is 18.008076977333985\n",
      "Steps:  66%|▋| 9826/15000 [1:25:06<15:30,  5.56it/s, lr=0.000997, step_loss=0.1207/27/2023 19:09:56 - INFO - __main__ - train loss is 18.010914966347627\n",
      "Steps:  66%|▋| 9827/15000 [1:25:06<15:29,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:56 - INFO - __main__ - train loss is 18.222091719391756\n",
      "Steps:  66%|▋| 9828/15000 [1:25:06<15:29,  5.56it/s, lr=0.000997, step_loss=0.2107/27/2023 19:09:56 - INFO - __main__ - train loss is 18.338270000997\n",
      "Steps:  66%|▋| 9829/15000 [1:25:07<15:28,  5.57it/s, lr=0.000997, step_loss=0.1107/27/2023 19:09:57 - INFO - __main__ - train loss is 18.457347527029924\n",
      "Steps:  66%|▋| 9830/15000 [1:25:07<15:28,  5.57it/s, lr=0.000997, step_loss=0.1107/27/2023 19:09:57 - INFO - __main__ - train loss is 18.74060650158208\n",
      "Steps:  66%|▋| 9831/15000 [1:25:07<15:28,  5.57it/s, lr=0.000997, step_loss=0.2807/27/2023 19:09:57 - INFO - __main__ - train loss is 18.938937768223695\n",
      "Steps:  66%|▋| 9832/15000 [1:25:07<15:27,  5.57it/s, lr=0.000997, step_loss=0.1907/27/2023 19:09:57 - INFO - __main__ - train loss is 19.341148719075136\n",
      "Steps:  66%|▋| 9833/15000 [1:25:07<15:27,  5.57it/s, lr=0.000997, step_loss=0.4007/27/2023 19:09:57 - INFO - __main__ - train loss is 19.451793581130914\n",
      "Steps:  66%|▋| 9834/15000 [1:25:08<15:28,  5.57it/s, lr=0.000997, step_loss=0.1107/27/2023 19:09:57 - INFO - __main__ - train loss is 19.603666245820932\n",
      "Steps:  66%|▋| 9835/15000 [1:25:08<15:27,  5.57it/s, lr=0.000997, step_loss=0.1507/27/2023 19:09:58 - INFO - __main__ - train loss is 20.117497026803903\n",
      "Steps:  66%|▋| 9836/15000 [1:25:08<15:27,  5.57it/s, lr=0.000997, step_loss=0.5107/27/2023 19:09:58 - INFO - __main__ - train loss is 20.2809136955766\n",
      "Steps:  66%|▋| 9837/15000 [1:25:08<15:27,  5.56it/s, lr=0.000997, step_loss=0.1607/27/2023 19:09:58 - INFO - __main__ - train loss is 20.4853732137708\n",
      "Steps:  66%|▋| 9838/15000 [1:25:08<15:28,  5.56it/s, lr=0.000997, step_loss=0.2007/27/2023 19:09:58 - INFO - __main__ - train loss is 20.509555237251334\n",
      "Steps:  66%|▋| 9839/15000 [1:25:08<15:28,  5.56it/s, lr=0.000997, step_loss=0.0207/27/2023 19:09:58 - INFO - __main__ - train loss is 20.648616300779395\n",
      "Steps:  66%|▋| 9840/15000 [1:25:09<15:28,  5.56it/s, lr=0.000997, step_loss=0.1307/27/2023 19:09:58 - INFO - __main__ - train loss is 20.65005323884543\n",
      "Steps:  66%|▋| 9841/15000 [1:25:09<15:27,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:09:59 - INFO - __main__ - train loss is 20.71171846834477\n",
      "Steps:  66%|▋| 9842/15000 [1:25:09<15:27,  5.56it/s, lr=0.000997, step_loss=0.0607/27/2023 19:09:59 - INFO - __main__ - train loss is 21.193611769354902\n",
      "Steps:  66%|▋| 9843/15000 [1:25:09<15:35,  5.51it/s, lr=0.000997, step_loss=0.4807/27/2023 19:09:59 - INFO - __main__ - train loss is 21.258037565625273\n",
      "Steps:  66%|▋| 9844/15000 [1:25:09<15:39,  5.49it/s, lr=0.000997, step_loss=0.0607/27/2023 19:09:59 - INFO - __main__ - train loss is 21.459225444472395\n",
      "Steps:  66%|▋| 9845/15000 [1:25:10<15:41,  5.47it/s, lr=0.000997, step_loss=0.2007/27/2023 19:09:59 - INFO - __main__ - train loss is 21.462032928946428\n",
      "Steps:  66%|▋| 9846/15000 [1:25:10<15:37,  5.50it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:00 - INFO - __main__ - train loss is 21.472698249737732\n",
      "Steps:  66%|▋| 9847/15000 [1:25:10<15:34,  5.52it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:00 - INFO - __main__ - train loss is 21.47857494361233\n",
      "Steps:  66%|▋| 9848/15000 [1:25:10<15:31,  5.53it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:00 - INFO - __main__ - train loss is 21.495046735624783\n",
      "Steps:  66%|▋| 9849/15000 [1:25:10<15:29,  5.54it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:00 - INFO - __main__ - train loss is 21.592475511948578\n",
      "Steps:  66%|▋| 9850/15000 [1:25:10<15:28,  5.55it/s, lr=0.000997, step_loss=0.0907/27/2023 19:10:00 - INFO - __main__ - train loss is 21.608535931329243\n",
      "Steps:  66%|▋| 9851/15000 [1:25:11<15:27,  5.55it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:00 - INFO - __main__ - train loss is 21.804043755750172\n",
      "Steps:  66%|▋| 9852/15000 [1:25:11<15:27,  5.55it/s, lr=0.000997, step_loss=0.1907/27/2023 19:10:01 - INFO - __main__ - train loss is 21.807877145591192\n",
      "Steps:  66%|▋| 9853/15000 [1:25:11<15:26,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:01 - INFO - __main__ - train loss is 22.121795616927557\n",
      "Steps:  66%|▋| 9854/15000 [1:25:11<15:25,  5.56it/s, lr=0.000997, step_loss=0.3107/27/2023 19:10:01 - INFO - __main__ - train loss is 22.273673944058828\n",
      "Steps:  66%|▋| 9855/15000 [1:25:11<15:25,  5.56it/s, lr=0.000997, step_loss=0.1507/27/2023 19:10:01 - INFO - __main__ - train loss is 22.61318122583907\n",
      "Steps:  66%|▋| 9856/15000 [1:25:12<15:25,  5.56it/s, lr=0.000997, step_loss=0.3407/27/2023 19:10:01 - INFO - __main__ - train loss is 22.64555893826764\n",
      "Steps:  66%|▋| 9857/15000 [1:25:12<15:25,  5.56it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:02 - INFO - __main__ - train loss is 22.647724442533217\n",
      "Steps:  66%|▋| 9858/15000 [1:25:12<15:24,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:02 - INFO - __main__ - train loss is 22.699438132694922\n",
      "Steps:  66%|▋| 9859/15000 [1:25:12<15:24,  5.56it/s, lr=0.000997, step_loss=0.0507/27/2023 19:10:02 - INFO - __main__ - train loss is 22.74826908891555\n",
      "Steps:  66%|▋| 9860/15000 [1:25:12<15:23,  5.56it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:02 - INFO - __main__ - train loss is 22.815552972606383\n",
      "Steps:  66%|▋| 9861/15000 [1:25:12<15:30,  5.52it/s, lr=0.000997, step_loss=0.0607/27/2023 19:10:02 - INFO - __main__ - train loss is 22.87255263736006\n",
      "Steps:  66%|▋| 9862/15000 [1:25:13<15:27,  5.54it/s, lr=0.000997, step_loss=0.0507/27/2023 19:10:02 - INFO - __main__ - train loss is 22.875364268780686\n",
      "Steps:  66%|▋| 9863/15000 [1:25:13<15:32,  5.51it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:03 - INFO - __main__ - train loss is 22.87797958345618\n",
      "Steps:  66%|▋| 9864/15000 [1:25:13<15:29,  5.53it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:03 - INFO - __main__ - train loss is 22.890103417797945\n",
      "Steps:  66%|▋| 9865/15000 [1:25:13<15:26,  5.54it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:03 - INFO - __main__ - train loss is 23.537878650589846\n",
      "Steps:  66%|▋| 9866/15000 [1:25:13<15:25,  5.55it/s, lr=0.000997, step_loss=0.6407/27/2023 19:10:03 - INFO - __main__ - train loss is 23.54613209643867\n",
      "Steps:  66%|▋| 9867/15000 [1:25:13<15:23,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:03 - INFO - __main__ - train loss is 23.952692934661172\n",
      "Steps:  66%|▋| 9868/15000 [1:25:14<15:22,  5.56it/s, lr=0.000997, step_loss=0.4007/27/2023 19:10:04 - INFO - __main__ - train loss is 24.211058565764688\n",
      "Steps:  66%|▋| 9869/15000 [1:25:14<15:32,  5.50it/s, lr=0.000997, step_loss=0.2507/27/2023 19:10:04 - INFO - __main__ - train loss is 24.21599922410678\n",
      "Steps:  66%|▋| 9870/15000 [1:25:14<16:40,  5.13it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:04 - INFO - __main__ - train loss is 24.27931087545585\n",
      "Steps:  66%|▋| 9871/15000 [1:25:14<18:09,  4.71it/s, lr=0.000997, step_loss=0.0607/27/2023 19:10:04 - INFO - __main__ - train loss is 24.289292476023547\n",
      "Steps:  66%|▋| 9872/15000 [1:25:15<17:49,  4.79it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:04 - INFO - __main__ - train loss is 24.30527206964325\n",
      "Steps:  66%|▋| 9873/15000 [1:25:15<17:45,  4.81it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:05 - INFO - __main__ - train loss is 24.510893580387346\n",
      "Steps:  66%|▋| 9874/15000 [1:25:15<17:02,  5.02it/s, lr=0.000997, step_loss=0.2007/27/2023 19:10:05 - INFO - __main__ - train loss is 25.050680396030657\n",
      "Steps:  66%|▋| 9875/15000 [1:25:15<16:31,  5.17it/s, lr=0.000997, step_loss=0.5407/27/2023 19:10:05 - INFO - __main__ - train loss is 25.54613411135506\n",
      "Steps:  66%|▋| 9876/15000 [1:25:15<16:10,  5.28it/s, lr=0.000997, step_loss=0.4907/27/2023 19:10:05 - INFO - __main__ - train loss is 25.56021329096984\n",
      "Steps:  66%|▋| 9877/15000 [1:25:15<15:55,  5.36it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:05 - INFO - __main__ - train loss is 25.599306628922932\n",
      "Steps:  66%|▋| 9878/15000 [1:25:16<15:45,  5.42it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:06 - INFO - __main__ - train loss is 25.7161152967019\n",
      "Steps:  66%|▋| 9879/15000 [1:25:16<15:37,  5.46it/s, lr=0.000997, step_loss=0.1107/27/2023 19:10:06 - INFO - __main__ - train loss is 25.719563318765722\n",
      "Steps:  66%|▋| 9880/15000 [1:25:16<15:32,  5.49it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:06 - INFO - __main__ - train loss is 25.78818726388272\n",
      "Steps:  66%|▋| 9881/15000 [1:25:16<15:28,  5.51it/s, lr=0.000997, step_loss=0.0607/27/2023 19:10:06 - INFO - __main__ - train loss is 26.035610733903013\n",
      "Steps:  66%|▋| 9882/15000 [1:25:16<15:25,  5.53it/s, lr=0.000997, step_loss=0.2407/27/2023 19:10:06 - INFO - __main__ - train loss is 26.23783415404614\n",
      "Steps:  66%|▋| 9883/15000 [1:25:17<15:32,  5.49it/s, lr=0.000997, step_loss=0.2007/27/2023 19:10:06 - INFO - __main__ - train loss is 26.273860944784246\n",
      "Steps:  66%|▋| 9884/15000 [1:25:17<15:33,  5.48it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:07 - INFO - __main__ - train loss is 26.345465509570204\n",
      "Steps:  66%|▋| 9885/15000 [1:25:17<15:29,  5.50it/s, lr=0.000997, step_loss=0.0707/27/2023 19:10:07 - INFO - __main__ - train loss is 26.840088276541792\n",
      "Steps:  66%|▋| 9886/15000 [1:25:17<15:26,  5.52it/s, lr=0.000997, step_loss=0.4907/27/2023 19:10:07 - INFO - __main__ - train loss is 26.876376284635626\n",
      "Steps:  66%|▋| 9887/15000 [1:25:17<15:32,  5.48it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:07 - INFO - __main__ - train loss is 26.91750341502484\n",
      "Steps:  66%|▋| 9888/15000 [1:25:17<15:38,  5.45it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:07 - INFO - __main__ - train loss is 27.124728320515715\n",
      "Steps:  66%|▋| 9889/15000 [1:25:18<15:37,  5.45it/s, lr=0.000997, step_loss=0.2007/27/2023 19:10:08 - INFO - __main__ - train loss is 27.159624321735464\n",
      "Steps:  66%|▋| 9890/15000 [1:25:18<15:30,  5.49it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:08 - INFO - __main__ - train loss is 27.173663703142665\n",
      "Steps:  66%|▋| 9891/15000 [1:25:18<15:28,  5.50it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:08 - INFO - __main__ - train loss is 27.345040065585636\n",
      "Steps:  66%|▋| 9892/15000 [1:25:18<15:24,  5.53it/s, lr=0.000997, step_loss=0.1707/27/2023 19:10:08 - INFO - __main__ - train loss is 27.34806086437311\n",
      "Steps:  66%|▋| 9893/15000 [1:25:18<15:23,  5.53it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:08 - INFO - __main__ - train loss is 27.357344369753264\n",
      "Steps:  66%|▋| 9894/15000 [1:25:19<15:21,  5.54it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:08 - INFO - __main__ - train loss is 27.688691477640532\n",
      "Steps:  66%|▋| 9895/15000 [1:25:19<15:24,  5.52it/s, lr=0.000997, step_loss=0.3307/27/2023 19:10:09 - INFO - __main__ - train loss is 27.695175005472265\n",
      "Steps:  66%|▋| 9896/15000 [1:25:19<15:31,  5.48it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:09 - INFO - __main__ - train loss is 27.99579079297837\n",
      "Steps:  66%|▋| 9897/15000 [1:25:19<15:28,  5.49it/s, lr=0.000997, step_loss=0.3007/27/2023 19:10:09 - INFO - __main__ - train loss is 28.050219131982885\n",
      "Steps:  66%|▋| 9898/15000 [1:25:19<15:24,  5.52it/s, lr=0.000997, step_loss=0.0507/27/2023 19:10:09 - INFO - __main__ - train loss is 28.05372381734196\n",
      "Steps:  66%|▋| 9899/15000 [1:25:19<15:22,  5.53it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:09 - INFO - __main__ - train loss is 28.10147676395718\n",
      "Steps:  66%|▋| 9900/15000 [1:25:20<15:19,  5.54it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:10 - INFO - __main__ - train loss is 28.10364178882446\n",
      "Steps:  66%|▋| 9901/15000 [1:25:20<15:18,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:10 - INFO - __main__ - train loss is 28.10670228942763\n",
      "Steps:  66%|▋| 9902/15000 [1:25:20<15:17,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:10 - INFO - __main__ - train loss is 28.559553763712756\n",
      "Steps:  66%|▋| 9903/15000 [1:25:20<15:16,  5.56it/s, lr=0.000997, step_loss=0.4507/27/2023 19:10:10 - INFO - __main__ - train loss is 28.600410095299594\n",
      "Steps:  66%|▋| 9904/15000 [1:25:20<15:15,  5.57it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:10 - INFO - __main__ - train loss is 28.640374033595435\n",
      "Steps:  66%|▋| 9905/15000 [1:25:21<15:14,  5.57it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:10 - INFO - __main__ - train loss is 28.678975987131707\n",
      "Steps:  66%|▋| 9906/15000 [1:25:21<15:14,  5.57it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:11 - INFO - __main__ - train loss is 28.72820540785324\n",
      "Steps:  66%|▋| 9907/15000 [1:25:21<15:14,  5.57it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:11 - INFO - __main__ - train loss is 28.8114214342786\n",
      "Steps:  66%|▋| 9908/15000 [1:25:21<15:21,  5.52it/s, lr=0.000997, step_loss=0.0807/27/2023 19:10:11 - INFO - __main__ - train loss is 29.131662259693258\n",
      "Steps:  66%|▋| 9909/15000 [1:25:21<15:20,  5.53it/s, lr=0.000997, step_loss=0.3207/27/2023 19:10:11 - INFO - __main__ - train loss is 29.137603034148924\n",
      "Steps:  66%|▋| 9910/15000 [1:25:21<15:24,  5.51it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:11 - INFO - __main__ - train loss is 29.225193043123\n",
      "Steps:  66%|▋| 9911/15000 [1:25:22<15:27,  5.48it/s, lr=0.000997, step_loss=0.0807/27/2023 19:10:11 - INFO - __main__ - train loss is 29.263049383531325\n",
      "Steps:  66%|▋| 9912/15000 [1:25:22<15:30,  5.47it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:12 - INFO - __main__ - train loss is 29.277734092320316\n",
      "Steps:  66%|▋| 9913/15000 [1:25:22<15:32,  5.46it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:12 - INFO - __main__ - train loss is 29.288663790444843\n",
      "Steps:  66%|▋| 9914/15000 [1:25:22<15:33,  5.45it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:12 - INFO - __main__ - train loss is 29.414546013693325\n",
      "Steps:  66%|▋| 9915/15000 [1:25:22<15:27,  5.48it/s, lr=0.000997, step_loss=0.1207/27/2023 19:10:12 - INFO - __main__ - train loss is 29.51234424195718\n",
      "Steps:  66%|▋| 9916/15000 [1:25:23<15:23,  5.51it/s, lr=0.000997, step_loss=0.0907/27/2023 19:10:12 - INFO - __main__ - train loss is 29.552337185363285\n",
      "Steps:  66%|▋| 9917/15000 [1:25:23<15:19,  5.53it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:13 - INFO - __main__ - train loss is 29.56823441281449\n",
      "Steps:  66%|▋| 9918/15000 [1:25:23<15:16,  5.54it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:13 - INFO - __main__ - train loss is 29.731510876561515\n",
      "Steps:  66%|▋| 9919/15000 [1:25:23<15:14,  5.55it/s, lr=0.000997, step_loss=0.1607/27/2023 19:10:13 - INFO - __main__ - train loss is 29.74107093072962\n",
      "Steps:  66%|▋| 9920/15000 [1:25:23<15:13,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:13 - INFO - __main__ - train loss is 29.813735668431036\n",
      "Steps:  66%|▋| 9921/15000 [1:25:23<15:12,  5.56it/s, lr=0.000997, step_loss=0.0707/27/2023 19:10:13 - INFO - __main__ - train loss is 29.829093973967247\n",
      "Steps:  66%|▋| 9922/15000 [1:25:24<15:12,  5.56it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:13 - INFO - __main__ - train loss is 30.05387414607685\n",
      "Steps:  66%|▋| 9923/15000 [1:25:24<15:12,  5.56it/s, lr=0.000997, step_loss=0.2207/27/2023 19:10:14 - INFO - __main__ - train loss is 30.197944398852997\n",
      "Steps:  66%|▋| 9924/15000 [1:25:24<15:12,  5.56it/s, lr=0.000997, step_loss=0.1407/27/2023 19:10:14 - INFO - __main__ - train loss is 30.20292967639398\n",
      "Steps:  66%|▋| 9925/15000 [1:25:24<15:19,  5.52it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:14 - INFO - __main__ - train loss is 30.2153842569096\n",
      "Steps:  66%|▋| 9926/15000 [1:25:24<15:22,  5.50it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:14 - INFO - __main__ - train loss is 30.223399715381674\n",
      "Steps:  66%|▋| 9927/15000 [1:25:25<15:19,  5.51it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:14 - INFO - __main__ - train loss is 30.286845425027423\n",
      "Steps:  66%|▋| 9928/15000 [1:25:25<15:16,  5.53it/s, lr=0.000997, step_loss=0.0607/27/2023 19:10:15 - INFO - __main__ - train loss is 30.313038192573003\n",
      "Steps:  66%|▋| 9929/15000 [1:25:25<15:14,  5.54it/s, lr=0.000997, step_loss=0.0207/27/2023 19:10:15 - INFO - __main__ - train loss is 30.496687240782194\n",
      "Steps:  66%|▋| 9930/15000 [1:25:25<15:13,  5.55it/s, lr=0.000997, step_loss=0.1807/27/2023 19:10:15 - INFO - __main__ - train loss is 30.49932835798245\n",
      "Steps:  66%|▋| 9931/15000 [1:25:25<15:17,  5.53it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:15 - INFO - __main__ - train loss is 30.5009087867802\n",
      "Steps:  66%|▋| 9932/15000 [1:25:25<15:14,  5.54it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:15 - INFO - __main__ - train loss is 30.504097754019313\n",
      "Steps:  66%|▋| 9933/15000 [1:25:26<15:12,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:15 - INFO - __main__ - train loss is 30.613461771863513\n",
      "Steps:  66%|▋| 9934/15000 [1:25:26<15:11,  5.56it/s, lr=0.000997, step_loss=0.1007/27/2023 19:10:16 - INFO - __main__ - train loss is 30.681498030084185\n",
      "Steps:  66%|▋| 9935/15000 [1:25:26<15:11,  5.56it/s, lr=0.000997, step_loss=0.0607/27/2023 19:10:16 - INFO - __main__ - train loss is 31.08991066541057\n",
      "Steps:  66%|▋| 9936/15000 [1:25:26<15:10,  5.56it/s, lr=0.000997, step_loss=0.4007/27/2023 19:10:16 - INFO - __main__ - train loss is 31.123353576171212\n",
      "Steps:  66%|▋| 9937/15000 [1:25:26<15:09,  5.56it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:16 - INFO - __main__ - train loss is 31.141834793495946\n",
      "Steps:  66%|▋| 9938/15000 [1:25:26<15:09,  5.57it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:16 - INFO - __main__ - train loss is 31.312879113364033\n",
      "Steps:  66%|▋| 9939/15000 [1:25:27<15:26,  5.46it/s, lr=0.000997, step_loss=0.1707/27/2023 19:10:17 - INFO - __main__ - train loss is 32.024259475874715\n",
      "Steps:  66%|▋| 9940/15000 [1:25:27<15:23,  5.48it/s, lr=0.000997, step_loss=0.7107/27/2023 19:10:17 - INFO - __main__ - train loss is 32.03748638450634\n",
      "Steps:  66%|▋| 9941/15000 [1:25:27<15:24,  5.47it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:17 - INFO - __main__ - train loss is 32.076002518530004\n",
      "Steps:  66%|▋| 9942/15000 [1:25:27<15:19,  5.50it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:17 - INFO - __main__ - train loss is 32.67403725802433\n",
      "Steps:  66%|▋| 9943/15000 [1:25:27<15:15,  5.53it/s, lr=0.000997, step_loss=0.5907/27/2023 19:10:17 - INFO - __main__ - train loss is 32.688150438363664\n",
      "Steps:  66%|▋| 9944/15000 [1:25:28<15:12,  5.54it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:17 - INFO - __main__ - train loss is 32.70052375632804\n",
      "Steps:  66%|▋| 9945/15000 [1:25:28<15:10,  5.55it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:18 - INFO - __main__ - train loss is 32.70250567642506\n",
      "Steps:  66%|▋| 9946/15000 [1:25:28<15:09,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:18 - INFO - __main__ - train loss is 32.70400903536938\n",
      "Steps:  66%|▋| 9947/15000 [1:25:28<15:08,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:18 - INFO - __main__ - train loss is 32.730052986880764\n",
      "Steps:  66%|▋| 9948/15000 [1:25:28<15:07,  5.57it/s, lr=0.000997, step_loss=0.0207/27/2023 19:10:18 - INFO - __main__ - train loss is 32.734369362005964\n",
      "Steps:  66%|▋| 9949/15000 [1:25:28<15:06,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:18 - INFO - __main__ - train loss is 32.74860725947656\n",
      "Steps:  66%|▋| 9950/15000 [1:25:29<15:06,  5.57it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:19 - INFO - __main__ - train loss is 32.756679760525\n",
      "Steps:  66%|▋| 9951/15000 [1:25:29<15:06,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:19 - INFO - __main__ - train loss is 32.774509113514796\n",
      "Steps:  66%|▋| 9952/15000 [1:25:29<15:05,  5.57it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:19 - INFO - __main__ - train loss is 32.79896520846523\n",
      "Steps:  66%|▋| 9953/15000 [1:25:29<15:05,  5.57it/s, lr=0.000997, step_loss=0.0207/27/2023 19:10:19 - INFO - __main__ - train loss is 32.80058299237862\n",
      "Steps:  66%|▋| 9954/15000 [1:25:29<15:05,  5.57it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:19 - INFO - __main__ - train loss is 32.86624068999663\n",
      "Steps:  66%|▋| 9955/15000 [1:25:30<15:05,  5.57it/s, lr=0.000997, step_loss=0.0607/27/2023 19:10:19 - INFO - __main__ - train loss is 32.91428812080994\n",
      "Steps:  66%|▋| 9956/15000 [1:25:30<15:04,  5.57it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:20 - INFO - __main__ - train loss is 32.91746430005878\n",
      "Steps:  66%|▋| 9957/15000 [1:25:30<15:04,  5.58it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:20 - INFO - __main__ - train loss is 32.92854560725391\n",
      "Steps:  66%|▋| 9958/15000 [1:25:30<15:04,  5.57it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:20 - INFO - __main__ - train loss is 33.30184815637767\n",
      "Steps:  66%|▋| 9959/15000 [1:25:30<15:04,  5.57it/s, lr=0.000997, step_loss=0.3707/27/2023 19:10:20 - INFO - __main__ - train loss is 33.65615944378078\n",
      "Steps:  66%|▋| 9960/15000 [1:25:30<15:04,  5.57it/s, lr=0.000997, step_loss=0.3507/27/2023 19:10:20 - INFO - __main__ - train loss is 34.06326497904956\n",
      "Steps:  66%|▋| 9961/15000 [1:25:31<15:04,  5.57it/s, lr=0.000997, step_loss=0.4007/27/2023 19:10:21 - INFO - __main__ - train loss is 34.152839897200465\n",
      "Steps:  66%|▋| 9962/15000 [1:25:31<15:04,  5.57it/s, lr=0.000997, step_loss=0.0807/27/2023 19:10:21 - INFO - __main__ - train loss is 34.377398861572146\n",
      "Steps:  66%|▋| 9963/15000 [1:25:31<15:05,  5.56it/s, lr=0.000997, step_loss=0.2207/27/2023 19:10:21 - INFO - __main__ - train loss is 34.37876408803277\n",
      "Steps:  66%|▋| 9964/15000 [1:25:31<15:05,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:21 - INFO - __main__ - train loss is 34.381834351690486\n",
      "Steps:  66%|▋| 9965/15000 [1:25:31<15:11,  5.52it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:21 - INFO - __main__ - train loss is 35.05909093585797\n",
      "Steps:  66%|▋| 9966/15000 [1:25:32<15:09,  5.53it/s, lr=0.000997, step_loss=0.6707/27/2023 19:10:21 - INFO - __main__ - train loss is 35.060456497827545\n",
      "Steps:  66%|▋| 9967/15000 [1:25:32<15:07,  5.54it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:22 - INFO - __main__ - train loss is 35.07115514785983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:16.126613, resuming normal operation.\n",
      "Steps:  66%|▋| 9968/15000 [1:25:32<15:06,  5.55it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:22 - INFO - __main__ - train loss is 35.083992475876585\n",
      "Steps:  66%|▋| 9969/15000 [1:25:32<15:05,  5.56it/s, lr=0.000997, step_loss=0.0107/27/2023 19:10:22 - INFO - __main__ - train loss is 35.10761179612018\n",
      "Steps:  66%|▋| 9970/15000 [1:25:32<15:04,  5.56it/s, lr=0.000997, step_loss=0.0207/27/2023 19:10:22 - INFO - __main__ - train loss is 35.15016551897861\n",
      "Steps:  66%|▋| 9971/15000 [1:25:32<15:03,  5.57it/s, lr=0.000997, step_loss=0.0407/27/2023 19:10:22 - INFO - __main__ - train loss is 35.18848610506393\n",
      "Steps:  66%|▋| 9972/15000 [1:25:33<15:02,  5.57it/s, lr=0.000997, step_loss=0.0307/27/2023 19:10:22 - INFO - __main__ - train loss is 35.3144907115493\n",
      "Steps:  66%|▋| 9973/15000 [1:25:33<15:02,  5.57it/s, lr=0.000997, step_loss=0.1207/27/2023 19:10:23 - INFO - __main__ - train loss is 35.400954922894016\n",
      "Steps:  66%|▋| 9974/15000 [1:25:33<15:01,  5.57it/s, lr=0.000997, step_loss=0.0807/27/2023 19:10:23 - INFO - __main__ - train loss is 35.45372632727958\n",
      "Steps:  66%|▋| 9975/15000 [1:25:33<15:07,  5.54it/s, lr=0.000997, step_loss=0.0507/27/2023 19:10:23 - INFO - __main__ - train loss is 35.462595050456\n",
      "Steps:  67%|▋| 9976/15000 [1:25:33<15:05,  5.55it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:23 - INFO - __main__ - train loss is 35.469652318162844\n",
      "Steps:  67%|▋| 9977/15000 [1:25:34<15:03,  5.56it/s, lr=0.000997, step_loss=0.0007/27/2023 19:10:23 - INFO - __main__ - train loss is 35.94228502432816\n",
      "Steps:  67%|▋| 9978/15000 [1:25:34<15:02,  5.56it/s, lr=0.000996, step_loss=0.4707/27/2023 19:10:24 - INFO - __main__ - train loss is 36.44875665823929\n",
      "Steps:  67%|▋| 9979/15000 [1:25:34<15:01,  5.57it/s, lr=0.000996, step_loss=0.5007/27/2023 19:10:24 - INFO - __main__ - train loss is 36.55673845927231\n",
      "Steps:  67%|▋| 9980/15000 [1:25:34<15:09,  5.52it/s, lr=0.000996, step_loss=0.1007/27/2023 19:10:24 - INFO - __main__ - train loss is 36.578169596148655\n",
      "Steps:  67%|▋| 9981/15000 [1:25:34<15:10,  5.52it/s, lr=0.000996, step_loss=0.0207/27/2023 19:10:24 - INFO - __main__ - train loss is 36.66841059620492\n",
      "Steps:  67%|▋| 9982/15000 [1:25:34<15:07,  5.53it/s, lr=0.000996, step_loss=0.0907/27/2023 19:10:24 - INFO - __main__ - train loss is 36.673969440860674\n",
      "Steps:  67%|▋| 9983/15000 [1:25:35<15:04,  5.55it/s, lr=0.000996, step_loss=0.0007/27/2023 19:10:24 - INFO - __main__ - train loss is 36.708132800413296\n",
      "Steps:  67%|▋| 9984/15000 [1:25:35<15:02,  5.56it/s, lr=0.000996, step_loss=0.0307/27/2023 19:10:25 - INFO - __main__ - train loss is 36.821394425584\n",
      "Steps:  67%|▋| 9985/15000 [1:25:35<15:09,  5.52it/s, lr=0.000996, step_loss=0.1107/27/2023 19:10:25 - INFO - __main__ - train loss is 36.99787200684659\n",
      "Steps:  67%|▋| 9986/15000 [1:25:35<15:08,  5.52it/s, lr=0.000996, step_loss=0.1707/27/2023 19:10:25 - INFO - __main__ - train loss is 37.18645268375985\n",
      "Steps:  67%|▋| 9987/15000 [1:25:35<15:04,  5.54it/s, lr=0.000996, step_loss=0.1807/27/2023 19:10:25 - INFO - __main__ - train loss is 37.41295332903974\n",
      "Steps:  67%|▋| 9988/15000 [1:25:36<15:02,  5.56it/s, lr=0.000996, step_loss=0.2207/27/2023 19:10:25 - INFO - __main__ - train loss is 37.660498779965565\n",
      "Steps:  67%|▋| 9989/15000 [1:25:36<15:00,  5.56it/s, lr=0.000996, step_loss=0.2407/27/2023 19:10:26 - INFO - __main__ - train loss is 37.6642744585406\n",
      "Steps:  67%|▋| 9990/15000 [1:25:36<14:59,  5.57it/s, lr=0.000996, step_loss=0.0007/27/2023 19:10:26 - INFO - __main__ - train loss is 37.96930554951541\n",
      "Steps:  67%|▋| 9991/15000 [1:25:36<14:58,  5.58it/s, lr=0.000996, step_loss=0.3007/27/2023 19:10:26 - INFO - __main__ - train loss is 38.09483698452823\n",
      "Steps:  67%|▋| 9992/15000 [1:25:36<14:57,  5.58it/s, lr=0.000996, step_loss=0.1207/27/2023 19:10:26 - INFO - __main__ - train loss is 38.39574796403758\n",
      "Steps:  67%|▋| 9993/15000 [1:25:36<14:56,  5.58it/s, lr=0.000996, step_loss=0.3007/27/2023 19:10:26 - INFO - __main__ - train loss is 38.44054578314535\n",
      "Steps:  67%|▋| 9994/15000 [1:25:37<15:00,  5.56it/s, lr=0.000996, step_loss=0.0407/27/2023 19:10:26 - INFO - __main__ - train loss is 38.443500647554174\n",
      "Steps:  67%|▋| 9995/15000 [1:25:37<14:59,  5.57it/s, lr=0.000996, step_loss=0.0007/27/2023 19:10:27 - INFO - __main__ - train loss is 38.484874518821016\n",
      "Steps:  67%|▋| 9996/15000 [1:25:37<14:58,  5.57it/s, lr=0.000996, step_loss=0.0407/27/2023 19:10:27 - INFO - __main__ - train loss is 38.48676126578357\n",
      "Steps:  67%|▋| 9997/15000 [1:25:37<14:56,  5.58it/s, lr=0.000996, step_loss=0.0007/27/2023 19:10:27 - INFO - __main__ - train loss is 38.664265164523385\n",
      "Steps:  67%|▋| 9998/15000 [1:25:37<14:59,  5.56it/s, lr=0.000996, step_loss=0.1707/27/2023 19:10:27 - INFO - __main__ - train loss is 38.817843460827135\n",
      "Steps:  67%|▋| 9999/15000 [1:25:38<22:32,  3.70it/s, lr=0.000996, step_loss=0.1507/27/2023 19:10:29 - INFO - __main__ - Per validation step average loss is 0.02519425004720688\n",
      "07/27/2023 19:10:29 - INFO - __main__ - Cumulative validation average loss is 0.02519425004720688\n",
      "07/27/2023 19:10:29 - INFO - __main__ - Per validation step average loss is 0.01506883092224598\n",
      "07/27/2023 19:10:29 - INFO - __main__ - Cumulative validation average loss is 0.04026308096945286\n",
      "07/27/2023 19:10:29 - INFO - __main__ - Per validation step average loss is 0.0027329130098223686\n",
      "07/27/2023 19:10:29 - INFO - __main__ - Cumulative validation average loss is 0.04299599397927523\n",
      "07/27/2023 19:10:30 - INFO - __main__ - Per validation step average loss is 0.17181238532066345\n",
      "07/27/2023 19:10:30 - INFO - __main__ - Cumulative validation average loss is 0.21480837929993868\n",
      "07/27/2023 19:10:30 - INFO - __main__ - Per validation step average loss is 0.06901557743549347\n",
      "07/27/2023 19:10:30 - INFO - __main__ - Cumulative validation average loss is 0.28382395673543215\n",
      "07/27/2023 19:10:31 - INFO - __main__ - Per validation step average loss is 0.32396236062049866\n",
      "07/27/2023 19:10:31 - INFO - __main__ - Cumulative validation average loss is 0.6077863173559308\n",
      "07/27/2023 19:10:31 - INFO - __main__ - Per validation step average loss is 0.11830488592386246\n",
      "07/27/2023 19:10:31 - INFO - __main__ - Cumulative validation average loss is 0.7260912032797933\n",
      "07/27/2023 19:10:31 - INFO - __main__ - Per validation step average loss is 0.0013433133717626333\n",
      "07/27/2023 19:10:31 - INFO - __main__ - Cumulative validation average loss is 0.7274345166515559\n",
      "07/27/2023 19:10:32 - INFO - __main__ - Per validation step average loss is 0.0662841796875\n",
      "07/27/2023 19:10:32 - INFO - __main__ - Cumulative validation average loss is 0.7937186963390559\n",
      "07/27/2023 19:10:32 - INFO - __main__ - Per validation step average loss is 0.03955206274986267\n",
      "07/27/2023 19:10:32 - INFO - __main__ - Cumulative validation average loss is 0.8332707590889186\n",
      "07/27/2023 19:10:33 - INFO - __main__ - Per validation step average loss is 0.07657541334629059\n",
      "07/27/2023 19:10:33 - INFO - __main__ - Cumulative validation average loss is 0.9098461724352092\n",
      "07/27/2023 19:10:33 - INFO - __main__ - Per validation step average loss is 0.033578962087631226\n",
      "07/27/2023 19:10:33 - INFO - __main__ - Cumulative validation average loss is 0.9434251345228404\n",
      "07/27/2023 19:10:34 - INFO - __main__ - Per validation step average loss is 0.23436394333839417\n",
      "07/27/2023 19:10:34 - INFO - __main__ - Cumulative validation average loss is 1.1777890778612345\n",
      "07/27/2023 19:10:34 - INFO - __main__ - Per validation step average loss is 0.01339899841696024\n",
      "07/27/2023 19:10:34 - INFO - __main__ - Cumulative validation average loss is 1.1911880762781948\n",
      "07/27/2023 19:10:34 - INFO - __main__ - Per validation step average loss is 0.181058868765831\n",
      "07/27/2023 19:10:34 - INFO - __main__ - Cumulative validation average loss is 1.3722469450440258\n",
      "07/27/2023 19:10:35 - INFO - __main__ - Per validation step average loss is 0.12034135311841965\n",
      "07/27/2023 19:10:35 - INFO - __main__ - Cumulative validation average loss is 1.4925882981624454\n",
      "07/27/2023 19:10:35 - INFO - __main__ - Per validation step average loss is 0.18180596828460693\n",
      "07/27/2023 19:10:35 - INFO - __main__ - Cumulative validation average loss is 1.6743942664470524\n",
      "07/27/2023 19:10:36 - INFO - __main__ - Per validation step average loss is 0.002578550484031439\n",
      "07/27/2023 19:10:36 - INFO - __main__ - Cumulative validation average loss is 1.6769728169310838\n",
      "07/27/2023 19:10:36 - INFO - __main__ - Per validation step average loss is 0.029813628643751144\n",
      "07/27/2023 19:10:36 - INFO - __main__ - Cumulative validation average loss is 1.706786445574835\n",
      "07/27/2023 19:10:36 - INFO - __main__ - Per validation step average loss is 0.5210320949554443\n",
      "07/27/2023 19:10:36 - INFO - __main__ - Cumulative validation average loss is 2.2278185405302793\n",
      "07/27/2023 19:10:37 - INFO - __main__ - Per validation step average loss is 0.23154333233833313\n",
      "07/27/2023 19:10:37 - INFO - __main__ - Cumulative validation average loss is 2.4593618728686124\n",
      "07/27/2023 19:10:37 - INFO - __main__ - Per validation step average loss is 0.15667571127414703\n",
      "07/27/2023 19:10:37 - INFO - __main__ - Cumulative validation average loss is 2.6160375841427594\n",
      "07/27/2023 19:10:38 - INFO - __main__ - Per validation step average loss is 0.012141542509198189\n",
      "07/27/2023 19:10:38 - INFO - __main__ - Cumulative validation average loss is 2.6281791266519576\n",
      "07/27/2023 19:10:38 - INFO - __main__ - Per validation step average loss is 0.013272209092974663\n",
      "07/27/2023 19:10:38 - INFO - __main__ - Cumulative validation average loss is 2.6414513357449323\n",
      "07/27/2023 19:10:39 - INFO - __main__ - Per validation step average loss is 0.3516410291194916\n",
      "07/27/2023 19:10:39 - INFO - __main__ - Cumulative validation average loss is 2.993092364864424\n",
      "07/27/2023 19:10:39 - INFO - __main__ - Per validation step average loss is 0.11208219826221466\n",
      "07/27/2023 19:10:39 - INFO - __main__ - Cumulative validation average loss is 3.1051745631266385\n",
      "07/27/2023 19:10:39 - INFO - __main__ - Per validation step average loss is 0.27438902854919434\n",
      "07/27/2023 19:10:39 - INFO - __main__ - Cumulative validation average loss is 3.379563591675833\n",
      "07/27/2023 19:10:40 - INFO - __main__ - Per validation step average loss is 0.002428764710202813\n",
      "07/27/2023 19:10:40 - INFO - __main__ - Cumulative validation average loss is 3.3819923563860357\n",
      "07/27/2023 19:10:40 - INFO - __main__ - Per validation step average loss is 0.0018757106736302376\n",
      "07/27/2023 19:10:40 - INFO - __main__ - Cumulative validation average loss is 3.383868067059666\n",
      "07/27/2023 19:10:41 - INFO - __main__ - Per validation step average loss is 0.5279547572135925\n",
      "07/27/2023 19:10:41 - INFO - __main__ - Cumulative validation average loss is 3.9118228242732584\n",
      "07/27/2023 19:10:41 - INFO - __main__ - Per validation step average loss is 0.0016720660496503115\n",
      "07/27/2023 19:10:41 - INFO - __main__ - Cumulative validation average loss is 3.9134948903229088\n",
      "07/27/2023 19:10:42 - INFO - __main__ - Per validation step average loss is 0.03374665230512619\n",
      "07/27/2023 19:10:42 - INFO - __main__ - Cumulative validation average loss is 3.947241542628035\n",
      "07/27/2023 19:10:42 - INFO - __main__ - Per validation step average loss is 0.15527121722698212\n",
      "07/27/2023 19:10:42 - INFO - __main__ - Cumulative validation average loss is 4.102512759855017\n",
      "07/27/2023 19:10:42 - INFO - __main__ - Per validation step average loss is 0.08025189489126205\n",
      "07/27/2023 19:10:42 - INFO - __main__ - Cumulative validation average loss is 4.182764654746279\n",
      "07/27/2023 19:10:43 - INFO - __main__ - Per validation step average loss is 0.005189178511500359\n",
      "07/27/2023 19:10:43 - INFO - __main__ - Cumulative validation average loss is 4.1879538332577795\n",
      "07/27/2023 19:10:43 - INFO - __main__ - Per validation step average loss is 0.03632356598973274\n",
      "07/27/2023 19:10:43 - INFO - __main__ - Cumulative validation average loss is 4.224277399247512\n",
      "07/27/2023 19:10:44 - INFO - __main__ - Per validation step average loss is 0.6102586984634399\n",
      "07/27/2023 19:10:44 - INFO - __main__ - Cumulative validation average loss is 4.834536097710952\n",
      "07/27/2023 19:10:44 - INFO - __main__ - Per validation step average loss is 0.010507892817258835\n",
      "07/27/2023 19:10:44 - INFO - __main__ - Cumulative validation average loss is 4.845043990528211\n",
      "07/27/2023 19:10:44 - INFO - __main__ - Per validation step average loss is 0.0216158889234066\n",
      "07/27/2023 19:10:44 - INFO - __main__ - Cumulative validation average loss is 4.866659879451618\n",
      "07/27/2023 19:10:45 - INFO - __main__ - Per validation step average loss is 0.1759614199399948\n",
      "07/27/2023 19:10:45 - INFO - __main__ - Cumulative validation average loss is 5.042621299391612\n",
      "07/27/2023 19:10:45 - INFO - __main__ - Per validation step average loss is 0.027127351611852646\n",
      "07/27/2023 19:10:45 - INFO - __main__ - Cumulative validation average loss is 5.069748651003465\n",
      "07/27/2023 19:10:46 - INFO - __main__ - Per validation step average loss is 0.0021505882032215595\n",
      "07/27/2023 19:10:46 - INFO - __main__ - Cumulative validation average loss is 5.071899239206687\n",
      "07/27/2023 19:10:46 - INFO - __main__ - Per validation step average loss is 0.006689929869025946\n",
      "07/27/2023 19:10:46 - INFO - __main__ - Cumulative validation average loss is 5.078589169075713\n",
      "07/27/2023 19:10:46 - INFO - __main__ - Per validation step average loss is 0.017746763303875923\n",
      "07/27/2023 19:10:46 - INFO - __main__ - Cumulative validation average loss is 5.0963359323795885\n",
      "07/27/2023 19:10:47 - INFO - __main__ - Per validation step average loss is 0.1727694571018219\n",
      "07/27/2023 19:10:47 - INFO - __main__ - Cumulative validation average loss is 5.26910538948141\n",
      "07/27/2023 19:10:47 - INFO - __main__ - Per validation step average loss is 0.06891293078660965\n",
      "07/27/2023 19:10:47 - INFO - __main__ - Cumulative validation average loss is 5.33801832026802\n",
      "07/27/2023 19:10:48 - INFO - __main__ - Per validation step average loss is 0.2459803819656372\n",
      "07/27/2023 19:10:48 - INFO - __main__ - Cumulative validation average loss is 5.583998702233657\n",
      "07/27/2023 19:10:48 - INFO - __main__ - Per validation step average loss is 0.08217112720012665\n",
      "07/27/2023 19:10:48 - INFO - __main__ - Cumulative validation average loss is 5.666169829433784\n",
      "07/27/2023 19:10:49 - INFO - __main__ - Per validation step average loss is 0.01653459295630455\n",
      "07/27/2023 19:10:49 - INFO - __main__ - Cumulative validation average loss is 5.682704422390088\n",
      "07/27/2023 19:10:49 - INFO - __main__ - Per validation step average loss is 0.009283417835831642\n",
      "07/27/2023 19:10:49 - INFO - __main__ - Cumulative validation average loss is 5.69198784022592\n",
      "07/27/2023 19:10:49 - INFO - __main__ - Per validation step average loss is 0.12817448377609253\n",
      "07/27/2023 19:10:49 - INFO - __main__ - Cumulative validation average loss is 5.820162324002013\n",
      "07/27/2023 19:10:50 - INFO - __main__ - Per validation step average loss is 0.05448559671640396\n",
      "07/27/2023 19:10:50 - INFO - __main__ - Cumulative validation average loss is 5.874647920718417\n",
      "07/27/2023 19:10:50 - INFO - __main__ - Per validation step average loss is 0.3465504050254822\n",
      "07/27/2023 19:10:50 - INFO - __main__ - Cumulative validation average loss is 6.221198325743899\n",
      "07/27/2023 19:10:51 - INFO - __main__ - Per validation step average loss is 0.025824446231126785\n",
      "07/27/2023 19:10:51 - INFO - __main__ - Cumulative validation average loss is 6.2470227719750255\n",
      "07/27/2023 19:10:51 - INFO - __main__ - Per validation step average loss is 0.003185801673680544\n",
      "07/27/2023 19:10:51 - INFO - __main__ - Cumulative validation average loss is 6.250208573648706\n",
      "07/27/2023 19:10:51 - INFO - __main__ - Per validation step average loss is 0.10768117010593414\n",
      "07/27/2023 19:10:51 - INFO - __main__ - Cumulative validation average loss is 6.35788974375464\n",
      "07/27/2023 19:10:52 - INFO - __main__ - Per validation step average loss is 0.06880764663219452\n",
      "07/27/2023 19:10:52 - INFO - __main__ - Cumulative validation average loss is 6.426697390386835\n",
      "07/27/2023 19:10:52 - INFO - __main__ - Per validation step average loss is 0.014787999913096428\n",
      "07/27/2023 19:10:52 - INFO - __main__ - Cumulative validation average loss is 6.441485390299931\n",
      "07/27/2023 19:10:53 - INFO - __main__ - Per validation step average loss is 0.10681548714637756\n",
      "07/27/2023 19:10:53 - INFO - __main__ - Cumulative validation average loss is 6.548300877446309\n",
      "07/27/2023 19:10:53 - INFO - __main__ - Per validation step average loss is 0.010362141765654087\n",
      "07/27/2023 19:10:53 - INFO - __main__ - Cumulative validation average loss is 6.558663019211963\n",
      "07/27/2023 19:10:54 - INFO - __main__ - Per validation step average loss is 0.18935708701610565\n",
      "07/27/2023 19:10:54 - INFO - __main__ - Cumulative validation average loss is 6.7480201062280685\n",
      "07/27/2023 19:10:54 - INFO - __main__ - Per validation step average loss is 0.05470554903149605\n",
      "07/27/2023 19:10:54 - INFO - __main__ - Cumulative validation average loss is 6.8027256552595645\n",
      "07/27/2023 19:10:54 - INFO - __main__ - Per validation step average loss is 0.0028960248455405235\n",
      "07/27/2023 19:10:54 - INFO - __main__ - Cumulative validation average loss is 6.805621680105105\n",
      "07/27/2023 19:10:55 - INFO - __main__ - Per validation step average loss is 0.14802217483520508\n",
      "07/27/2023 19:10:55 - INFO - __main__ - Cumulative validation average loss is 6.95364385494031\n",
      "07/27/2023 19:10:55 - INFO - __main__ - Per validation step average loss is 0.011176174506545067\n",
      "07/27/2023 19:10:55 - INFO - __main__ - Cumulative validation average loss is 6.964820029446855\n",
      "07/27/2023 19:10:56 - INFO - __main__ - Per validation step average loss is 0.08558521419763565\n",
      "07/27/2023 19:10:56 - INFO - __main__ - Cumulative validation average loss is 7.050405243644491\n",
      "07/27/2023 19:10:56 - INFO - __main__ - Per validation step average loss is 0.03791268542408943\n",
      "07/27/2023 19:10:56 - INFO - __main__ - Cumulative validation average loss is 7.08831792906858\n",
      "07/27/2023 19:10:56 - INFO - __main__ - Per validation step average loss is 0.03748198226094246\n",
      "07/27/2023 19:10:56 - INFO - __main__ - Cumulative validation average loss is 7.125799911329523\n",
      "07/27/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.10418953746557236\n",
      "07/27/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 7.229989448795095\n",
      "07/27/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.06034446507692337\n",
      "07/27/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 7.2903339138720185\n",
      "07/27/2023 19:10:58 - INFO - __main__ - Per validation step average loss is 0.002851752797141671\n",
      "07/27/2023 19:10:58 - INFO - __main__ - Cumulative validation average loss is 7.29318566666916\n",
      "07/27/2023 19:10:58 - INFO - __main__ - Per validation step average loss is 0.560383141040802\n",
      "07/27/2023 19:10:58 - INFO - __main__ - Cumulative validation average loss is 7.853568807709962\n",
      "07/27/2023 19:10:58 - INFO - __main__ - Per validation step average loss is 0.14893437922000885\n",
      "07/27/2023 19:10:58 - INFO - __main__ - Cumulative validation average loss is 8.002503186929971\n",
      "07/27/2023 19:10:59 - INFO - __main__ - Per validation step average loss is 0.16043661534786224\n",
      "07/27/2023 19:10:59 - INFO - __main__ - Cumulative validation average loss is 8.162939802277833\n",
      "07/27/2023 19:10:59 - INFO - __main__ - Per validation step average loss is 0.001172708231024444\n",
      "07/27/2023 19:10:59 - INFO - __main__ - Cumulative validation average loss is 8.164112510508858\n",
      "07/27/2023 19:11:00 - INFO - __main__ - Per validation step average loss is 0.14759281277656555\n",
      "07/27/2023 19:11:00 - INFO - __main__ - Cumulative validation average loss is 8.311705323285423\n",
      "07/27/2023 19:11:00 - INFO - __main__ - Per validation step average loss is 0.04026370495557785\n",
      "07/27/2023 19:11:00 - INFO - __main__ - Cumulative validation average loss is 8.351969028241001\n",
      "07/27/2023 19:11:01 - INFO - __main__ - Per validation step average loss is 0.011557749472558498\n",
      "07/27/2023 19:11:01 - INFO - __main__ - Cumulative validation average loss is 8.36352677771356\n",
      "07/27/2023 19:11:01 - INFO - __main__ - Per validation step average loss is 0.008307804353535175\n",
      "07/27/2023 19:11:01 - INFO - __main__ - Cumulative validation average loss is 8.371834582067095\n",
      "07/27/2023 19:11:01 - INFO - __main__ - Average validation loss for Epoch 32 is 0.10597258964641892\n",
      "07/27/2023 19:11:01 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:11:58 - INFO - __main__ - Starting epoch 33\n",
      "07/27/2023 19:11:59 - INFO - __main__ - train loss is 0.11222304403781891\n",
      "Steps:  67%|▋| 10000/15000 [1:27:09<38:23:28, 27.64s/it, lr=0.000996, step_loss=07/27/2023 19:11:59 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-10000\n",
      "07/27/2023 19:11:59 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:11:59,568] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:11:59,572] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-10000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:11:59,572] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-10000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:11:59,579] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-10000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:11:59,579] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-10000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:11:59,586] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-10000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:11:59,587] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-10000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:11:59,587] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:11:59 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-10000/pytorch_model\n",
      "07/27/2023 19:11:59 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-10000/scheduler.bin\n",
      "07/27/2023 19:11:59 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-10000/random_states_0.pkl\n",
      "07/27/2023 19:11:59 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-10000\n",
      "Steps:  67%|▋| 10000/15000 [1:27:09<38:23:28, 27.64s/it, lr=0.000996, step_loss=07/27/2023 19:11:59 - INFO - __main__ - train loss is 0.12119514867663383\n",
      "Steps:  67%|▋| 10001/15000 [1:27:09<26:57:06, 19.41s/it, lr=0.000996, step_loss=07/27/2023 19:11:59 - INFO - __main__ - train loss is 0.33999861404299736\n",
      "Steps:  67%|▋| 10002/15000 [1:27:10<18:56:14, 13.64s/it, lr=0.000996, step_loss=07/27/2023 19:12:00 - INFO - __main__ - train loss is 0.4406803958117962\n",
      "Steps:  67%|▋| 10003/15000 [1:27:10<13:19:41,  9.60s/it, lr=0.000996, step_loss=07/27/2023 19:12:00 - INFO - __main__ - train loss is 0.4662727974355221\n",
      "Steps:  67%|▋| 10004/15000 [1:27:10<9:24:09,  6.78s/it, lr=0.000996, step_loss=007/27/2023 19:12:00 - INFO - __main__ - train loss is 0.46760289440862834\n",
      "Steps:  67%|▋| 10005/15000 [1:27:10<6:39:20,  4.80s/it, lr=0.000996, step_loss=007/27/2023 19:12:00 - INFO - __main__ - train loss is 0.4796273361425847\n",
      "Steps:  67%|▋| 10006/15000 [1:27:10<4:44:02,  3.41s/it, lr=0.000996, step_loss=007/27/2023 19:12:00 - INFO - __main__ - train loss is 0.48932350683026016\n",
      "Steps:  67%|▋| 10007/15000 [1:27:11<3:23:15,  2.44s/it, lr=0.000996, step_loss=007/27/2023 19:12:00 - INFO - __main__ - train loss is 0.4934013627935201\n",
      "Steps:  67%|▋| 10008/15000 [1:27:11<2:26:51,  1.77s/it, lr=0.000996, step_loss=007/27/2023 19:12:01 - INFO - __main__ - train loss is 0.527339554624632\n",
      "Steps:  67%|▋| 10009/15000 [1:27:11<1:47:27,  1.29s/it, lr=0.000996, step_loss=007/27/2023 19:12:01 - INFO - __main__ - train loss is 0.7623182900715619\n",
      "Steps:  67%|▋| 10010/15000 [1:27:11<1:19:43,  1.04it/s, lr=0.000996, step_loss=007/27/2023 19:12:01 - INFO - __main__ - train loss is 0.8063595735002309\n",
      "Steps:  67%|▋| 10011/15000 [1:27:11<1:00:18,  1.38it/s, lr=0.000996, step_loss=007/27/2023 19:12:01 - INFO - __main__ - train loss is 1.0045888714957982\n",
      "Steps:  67%|▋| 10012/15000 [1:27:11<46:48,  1.78it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:01 - INFO - __main__ - train loss is 1.006937623489648\n",
      "Steps:  67%|▋| 10013/15000 [1:27:12<37:15,  2.23it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:02 - INFO - __main__ - train loss is 1.3638871614821255\n",
      "Steps:  67%|▋| 10014/15000 [1:27:12<30:41,  2.71it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:02 - INFO - __main__ - train loss is 1.5071681593544781\n",
      "Steps:  67%|▋| 10015/15000 [1:27:12<26:04,  3.19it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:02 - INFO - __main__ - train loss is 2.4686052654869854\n",
      "Steps:  67%|▋| 10016/15000 [1:27:12<22:42,  3.66it/s, lr=0.000996, step_loss=0.907/27/2023 19:12:02 - INFO - __main__ - train loss is 2.5039479550905526\n",
      "Steps:  67%|▋| 10017/15000 [1:27:12<20:22,  4.08it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:02 - INFO - __main__ - train loss is 3.045726161915809\n",
      "Steps:  67%|▋| 10018/15000 [1:27:13<18:44,  4.43it/s, lr=0.000996, step_loss=0.507/27/2023 19:12:02 - INFO - __main__ - train loss is 3.133577909786254\n",
      "Steps:  67%|▋| 10019/15000 [1:27:13<17:35,  4.72it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:03 - INFO - __main__ - train loss is 3.538586523849517\n",
      "Steps:  67%|▋| 10020/15000 [1:27:13<16:54,  4.91it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:03 - INFO - __main__ - train loss is 3.779393043834716\n",
      "Steps:  67%|▋| 10021/15000 [1:27:13<16:18,  5.09it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:03 - INFO - __main__ - train loss is 3.954492059070617\n",
      "Steps:  67%|▋| 10022/15000 [1:27:13<16:01,  5.18it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:03 - INFO - __main__ - train loss is 4.26346715958789\n",
      "Steps:  67%|▋| 10023/15000 [1:27:13<15:56,  5.20it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:03 - INFO - __main__ - train loss is 4.269316826015711\n",
      "Steps:  67%|▋| 10024/15000 [1:27:14<15:44,  5.27it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:04 - INFO - __main__ - train loss is 4.625650737434626\n",
      "Steps:  67%|▋| 10025/15000 [1:27:14<15:31,  5.34it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:04 - INFO - __main__ - train loss is 4.627874954137951\n",
      "Steps:  67%|▋| 10026/15000 [1:27:14<15:28,  5.36it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:04 - INFO - __main__ - train loss is 4.631836799904704\n",
      "Steps:  67%|▋| 10027/15000 [1:27:14<15:33,  5.33it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:04 - INFO - __main__ - train loss is 4.634669698774815\n",
      "Steps:  67%|▋| 10028/15000 [1:27:14<15:29,  5.35it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:04 - INFO - __main__ - train loss is 4.658614810556173\n",
      "Steps:  67%|▋| 10029/15000 [1:27:15<15:19,  5.41it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:04 - INFO - __main__ - train loss is 4.862997021526098\n",
      "Steps:  67%|▋| 10030/15000 [1:27:15<15:13,  5.44it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:05 - INFO - __main__ - train loss is 4.8641138665843755\n",
      "Steps:  67%|▋| 10031/15000 [1:27:15<15:08,  5.47it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:05 - INFO - __main__ - train loss is 4.868523356271908\n",
      "Steps:  67%|▋| 10032/15000 [1:27:15<15:11,  5.45it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:05 - INFO - __main__ - train loss is 5.528082784963772\n",
      "Steps:  67%|▋| 10033/15000 [1:27:15<15:05,  5.49it/s, lr=0.000996, step_loss=0.607/27/2023 19:12:05 - INFO - __main__ - train loss is 5.5587108850013465\n",
      "Steps:  67%|▋| 10034/15000 [1:27:16<15:01,  5.51it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:05 - INFO - __main__ - train loss is 5.894439709139988\n",
      "Steps:  67%|▋| 10035/15000 [1:27:16<14:58,  5.53it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:06 - INFO - __main__ - train loss is 6.062511873198673\n",
      "Steps:  67%|▋| 10036/15000 [1:27:16<14:56,  5.54it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:06 - INFO - __main__ - train loss is 6.1087591394316405\n",
      "Steps:  67%|▋| 10037/15000 [1:27:16<14:58,  5.53it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:06 - INFO - __main__ - train loss is 6.12900145794265\n",
      "Steps:  67%|▋| 10038/15000 [1:27:16<14:55,  5.54it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:06 - INFO - __main__ - train loss is 6.182961066020653\n",
      "Steps:  67%|▋| 10039/15000 [1:27:16<14:54,  5.55it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:06 - INFO - __main__ - train loss is 6.186947537818924\n",
      "Steps:  67%|▋| 10040/15000 [1:27:17<14:53,  5.55it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:06 - INFO - __main__ - train loss is 6.1944467921275645\n",
      "Steps:  67%|▋| 10041/15000 [1:27:17<14:52,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:07 - INFO - __main__ - train loss is 6.215304753975943\n",
      "Steps:  67%|▋| 10042/15000 [1:27:17<14:51,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:07 - INFO - __main__ - train loss is 6.217572937486693\n",
      "Steps:  67%|▋| 10043/15000 [1:27:17<14:51,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:07 - INFO - __main__ - train loss is 6.2192530437605456\n",
      "Steps:  67%|▋| 10044/15000 [1:27:17<14:50,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:07 - INFO - __main__ - train loss is 6.23752801597584\n",
      "Steps:  67%|▋| 10045/15000 [1:27:17<14:50,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:07 - INFO - __main__ - train loss is 6.368691225652583\n",
      "Steps:  67%|▋| 10046/15000 [1:27:18<14:50,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:08 - INFO - __main__ - train loss is 6.445330907707103\n",
      "Steps:  67%|▋| 10047/15000 [1:27:18<14:49,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:08 - INFO - __main__ - train loss is 6.534835544531234\n",
      "Steps:  67%|▋| 10048/15000 [1:27:18<14:48,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:08 - INFO - __main__ - train loss is 6.550134563003667\n",
      "Steps:  67%|▋| 10049/15000 [1:27:18<14:48,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:08 - INFO - __main__ - train loss is 6.6133533652173355\n",
      "Steps:  67%|▋| 10050/15000 [1:27:18<14:48,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:08 - INFO - __main__ - train loss is 6.890937202726491\n",
      "Steps:  67%|▋| 10051/15000 [1:27:19<14:47,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:08 - INFO - __main__ - train loss is 6.969001972232945\n",
      "Steps:  67%|▋| 10052/15000 [1:27:19<14:47,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:09 - INFO - __main__ - train loss is 6.974116753903218\n",
      "Steps:  67%|▋| 10053/15000 [1:27:19<14:47,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:09 - INFO - __main__ - train loss is 6.97827727033291\n",
      "Steps:  67%|▋| 10054/15000 [1:27:19<14:47,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:09 - INFO - __main__ - train loss is 7.138675395981409\n",
      "Steps:  67%|▋| 10055/15000 [1:27:19<14:47,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:09 - INFO - __main__ - train loss is 7.230514292255975\n",
      "Steps:  67%|▋| 10056/15000 [1:27:19<14:47,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:09 - INFO - __main__ - train loss is 7.396688540116884\n",
      "Steps:  67%|▋| 10057/15000 [1:27:20<14:47,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:10 - INFO - __main__ - train loss is 7.972955305711366\n",
      "Steps:  67%|▋| 10058/15000 [1:27:20<14:47,  5.57it/s, lr=0.000996, step_loss=0.507/27/2023 19:12:10 - INFO - __main__ - train loss is 7.981704865233041\n",
      "Steps:  67%|▋| 10059/15000 [1:27:20<14:47,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:10 - INFO - __main__ - train loss is 8.055843759910204\n",
      "Steps:  67%|▋| 10060/15000 [1:27:20<14:47,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:10 - INFO - __main__ - train loss is 8.424333025352098\n",
      "Steps:  67%|▋| 10061/15000 [1:27:20<14:46,  5.57it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:10 - INFO - __main__ - train loss is 8.759006072417833\n",
      "Steps:  67%|▋| 10062/15000 [1:27:21<14:46,  5.57it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:10 - INFO - __main__ - train loss is 8.761521330685355\n",
      "Steps:  67%|▋| 10063/15000 [1:27:21<14:46,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:11 - INFO - __main__ - train loss is 8.80369755497668\n",
      "Steps:  67%|▋| 10064/15000 [1:27:21<14:45,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:11 - INFO - __main__ - train loss is 8.822708802879788\n",
      "Steps:  67%|▋| 10065/15000 [1:27:21<14:45,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:11 - INFO - __main__ - train loss is 8.824446272919886\n",
      "Steps:  67%|▋| 10066/15000 [1:27:21<14:45,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:11 - INFO - __main__ - train loss is 9.015463334391825\n",
      "Steps:  67%|▋| 10067/15000 [1:27:21<14:45,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:11 - INFO - __main__ - train loss is 9.017510072677396\n",
      "Steps:  67%|▋| 10068/15000 [1:27:22<14:45,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:11 - INFO - __main__ - train loss is 9.0413919625571\n",
      "Steps:  67%|▋| 10069/15000 [1:27:22<14:45,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:12 - INFO - __main__ - train loss is 9.058686361997388\n",
      "Steps:  67%|▋| 10070/15000 [1:27:22<14:45,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:12 - INFO - __main__ - train loss is 9.814376936643384\n",
      "Steps:  67%|▋| 10071/15000 [1:27:22<14:44,  5.57it/s, lr=0.000996, step_loss=0.707/27/2023 19:12:12 - INFO - __main__ - train loss is 9.83224526362028\n",
      "Steps:  67%|▋| 10072/15000 [1:27:22<14:44,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:12 - INFO - __main__ - train loss is 9.847241110517643\n",
      "Steps:  67%|▋| 10073/15000 [1:27:23<14:44,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:12 - INFO - __main__ - train loss is 9.851107309688814\n",
      "Steps:  67%|▋| 10074/15000 [1:27:23<14:44,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:13 - INFO - __main__ - train loss is 9.853965243906714\n",
      "Steps:  67%|▋| 10075/15000 [1:27:23<14:44,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:13 - INFO - __main__ - train loss is 9.986242374987341\n",
      "Steps:  67%|▋| 10076/15000 [1:27:23<14:43,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:13 - INFO - __main__ - train loss is 10.002496060566045\n",
      "Steps:  67%|▋| 10077/15000 [1:27:23<14:43,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:13 - INFO - __main__ - train loss is 10.011247128830291\n",
      "Steps:  67%|▋| 10078/15000 [1:27:23<14:42,  5.58it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:13 - INFO - __main__ - train loss is 10.107525706873275\n",
      "Steps:  67%|▋| 10079/15000 [1:27:24<14:45,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:13 - INFO - __main__ - train loss is 10.170017339871265\n",
      "Steps:  67%|▋| 10080/15000 [1:27:24<14:44,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:14 - INFO - __main__ - train loss is 10.181356732384302\n",
      "Steps:  67%|▋| 10081/15000 [1:27:24<14:44,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:14 - INFO - __main__ - train loss is 10.21844573749695\n",
      "Steps:  67%|▋| 10082/15000 [1:27:24<14:44,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:14 - INFO - __main__ - train loss is 10.237374149844982\n",
      "Steps:  67%|▋| 10083/15000 [1:27:24<14:43,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:14 - INFO - __main__ - train loss is 10.244314036914147\n",
      "Steps:  67%|▋| 10084/15000 [1:27:24<14:43,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:14 - INFO - __main__ - train loss is 10.319720051833428\n",
      "Steps:  67%|▋| 10085/15000 [1:27:25<14:42,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:15 - INFO - __main__ - train loss is 10.327205539331771\n",
      "Steps:  67%|▋| 10086/15000 [1:27:25<14:42,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:15 - INFO - __main__ - train loss is 10.331427570083179\n",
      "Steps:  67%|▋| 10087/15000 [1:27:25<14:42,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:15 - INFO - __main__ - train loss is 10.410278688766994\n",
      "Steps:  67%|▋| 10088/15000 [1:27:25<14:42,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:15 - INFO - __main__ - train loss is 10.638275634148158\n",
      "Steps:  67%|▋| 10089/15000 [1:27:25<14:42,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:15 - INFO - __main__ - train loss is 10.864408980705775\n",
      "Steps:  67%|▋| 10090/15000 [1:27:26<14:41,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:15 - INFO - __main__ - train loss is 10.907360385754146\n",
      "Steps:  67%|▋| 10091/15000 [1:27:26<14:41,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:16 - INFO - __main__ - train loss is 11.209274839260615\n",
      "Steps:  67%|▋| 10092/15000 [1:27:26<14:40,  5.57it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:16 - INFO - __main__ - train loss is 11.22061499080155\n",
      "Steps:  67%|▋| 10093/15000 [1:27:26<14:40,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:16 - INFO - __main__ - train loss is 11.483271292061545\n",
      "Steps:  67%|▋| 10094/15000 [1:27:26<14:40,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:16 - INFO - __main__ - train loss is 11.50073327368591\n",
      "Steps:  67%|▋| 10095/15000 [1:27:26<14:40,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:16 - INFO - __main__ - train loss is 11.55399437865708\n",
      "Steps:  67%|▋| 10096/15000 [1:27:27<14:40,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:17 - INFO - __main__ - train loss is 11.578405375243165\n",
      "Steps:  67%|▋| 10097/15000 [1:27:27<14:40,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:17 - INFO - __main__ - train loss is 11.692490527988411\n",
      "Steps:  67%|▋| 10098/15000 [1:27:27<14:40,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:17 - INFO - __main__ - train loss is 11.818756158114411\n",
      "Steps:  67%|▋| 10099/15000 [1:27:27<14:39,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:17 - INFO - __main__ - train loss is 11.964793215156533\n",
      "Steps:  67%|▋| 10100/15000 [1:27:27<14:39,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:17 - INFO - __main__ - train loss is 11.983765299082734\n",
      "Steps:  67%|▋| 10101/15000 [1:27:28<14:38,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:17 - INFO - __main__ - train loss is 12.228396947146393\n",
      "Steps:  67%|▋| 10102/15000 [1:27:28<14:38,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:18 - INFO - __main__ - train loss is 12.342047179699875\n",
      "Steps:  67%|▋| 10103/15000 [1:27:28<14:38,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:18 - INFO - __main__ - train loss is 13.119509781361558\n",
      "Steps:  67%|▋| 10104/15000 [1:27:28<14:38,  5.57it/s, lr=0.000996, step_loss=0.707/27/2023 19:12:18 - INFO - __main__ - train loss is 13.134316502721049\n",
      "Steps:  67%|▋| 10105/15000 [1:27:28<14:38,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:18 - INFO - __main__ - train loss is 13.179780630976893\n",
      "Steps:  67%|▋| 10106/15000 [1:27:28<14:38,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:18 - INFO - __main__ - train loss is 13.544941662461497\n",
      "Steps:  67%|▋| 10107/15000 [1:27:29<14:38,  5.57it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:18 - INFO - __main__ - train loss is 13.546937354956754\n",
      "Steps:  67%|▋| 10108/15000 [1:27:29<14:37,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:19 - INFO - __main__ - train loss is 13.71297241107095\n",
      "Steps:  67%|▋| 10109/15000 [1:27:29<14:37,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:19 - INFO - __main__ - train loss is 14.208754279767163\n",
      "Steps:  67%|▋| 10110/15000 [1:27:29<14:37,  5.57it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:19 - INFO - __main__ - train loss is 14.290578187559731\n",
      "Steps:  67%|▋| 10111/15000 [1:27:29<14:37,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:19 - INFO - __main__ - train loss is 14.503049091552384\n",
      "Steps:  67%|▋| 10112/15000 [1:27:30<14:37,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:19 - INFO - __main__ - train loss is 14.50551721744705\n",
      "Steps:  67%|▋| 10113/15000 [1:27:30<14:36,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:20 - INFO - __main__ - train loss is 14.715492787887342\n",
      "Steps:  67%|▋| 10114/15000 [1:27:30<14:36,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:20 - INFO - __main__ - train loss is 14.987546864082105\n",
      "Steps:  67%|▋| 10115/15000 [1:27:30<14:36,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:20 - INFO - __main__ - train loss is 15.40856966667343\n",
      "Steps:  67%|▋| 10116/15000 [1:27:30<14:36,  5.57it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:20 - INFO - __main__ - train loss is 15.506212140549906\n",
      "Steps:  67%|▋| 10117/15000 [1:27:30<14:36,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:20 - INFO - __main__ - train loss is 16.0493041529553\n",
      "Steps:  67%|▋| 10118/15000 [1:27:31<14:36,  5.57it/s, lr=0.000996, step_loss=0.507/27/2023 19:12:20 - INFO - __main__ - train loss is 16.069289502804168\n",
      "Steps:  67%|▋| 10119/15000 [1:27:31<14:36,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:21 - INFO - __main__ - train loss is 16.412634936277755\n",
      "Steps:  67%|▋| 10120/15000 [1:27:31<14:36,  5.57it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:21 - INFO - __main__ - train loss is 16.414344960823655\n",
      "Steps:  67%|▋| 10121/15000 [1:27:31<14:35,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:21 - INFO - __main__ - train loss is 16.4156304463977\n",
      "Steps:  67%|▋| 10122/15000 [1:27:31<14:36,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:21 - INFO - __main__ - train loss is 16.628159688436426\n",
      "Steps:  67%|▋| 10123/15000 [1:27:31<14:36,  5.56it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:21 - INFO - __main__ - train loss is 16.656576916226186\n",
      "Steps:  67%|▋| 10124/15000 [1:27:32<14:37,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:22 - INFO - __main__ - train loss is 16.93259941006545\n",
      "Steps:  68%|▋| 10125/15000 [1:27:32<14:42,  5.53it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:22 - INFO - __main__ - train loss is 16.966966166743077\n",
      "Steps:  68%|▋| 10126/15000 [1:27:32<14:48,  5.49it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:22 - INFO - __main__ - train loss is 16.97214525064919\n",
      "Steps:  68%|▋| 10127/15000 [1:27:32<14:44,  5.51it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:22 - INFO - __main__ - train loss is 17.436379066319205\n",
      "Steps:  68%|▋| 10128/15000 [1:27:32<14:47,  5.49it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:22 - INFO - __main__ - train loss is 17.807484260411\n",
      "Steps:  68%|▋| 10129/15000 [1:27:33<14:52,  5.46it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:22 - INFO - __main__ - train loss is 18.244802227825858\n",
      "Steps:  68%|▋| 10130/15000 [1:27:33<14:46,  5.50it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:23 - INFO - __main__ - train loss is 18.326177886337973\n",
      "Steps:  68%|▋| 10131/15000 [1:27:33<14:41,  5.52it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:23 - INFO - __main__ - train loss is 18.335248819203116\n",
      "Steps:  68%|▋| 10132/15000 [1:27:33<14:39,  5.54it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:23 - INFO - __main__ - train loss is 18.841251185745932\n",
      "Steps:  68%|▋| 10133/15000 [1:27:33<14:45,  5.49it/s, lr=0.000996, step_loss=0.507/27/2023 19:12:23 - INFO - __main__ - train loss is 19.290449491352774\n",
      "Steps:  68%|▋| 10134/15000 [1:27:33<14:44,  5.50it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:23 - INFO - __main__ - train loss is 19.295253429212607\n",
      "Steps:  68%|▋| 10135/15000 [1:27:34<14:41,  5.52it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:24 - INFO - __main__ - train loss is 19.427897039451636\n",
      "Steps:  68%|▋| 10136/15000 [1:27:34<14:38,  5.54it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:24 - INFO - __main__ - train loss is 19.5922618691111\n",
      "Steps:  68%|▋| 10137/15000 [1:27:34<14:36,  5.55it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:24 - INFO - __main__ - train loss is 19.915374118485488\n",
      "Steps:  68%|▋| 10138/15000 [1:27:34<14:35,  5.55it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:24 - INFO - __main__ - train loss is 20.006343934335746\n",
      "Steps:  68%|▋| 10139/15000 [1:27:34<14:34,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:24 - INFO - __main__ - train loss is 20.137499827542342\n",
      "Steps:  68%|▋| 10140/15000 [1:27:35<14:34,  5.56it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:24 - INFO - __main__ - train loss is 20.531543571152724\n",
      "Steps:  68%|▋| 10141/15000 [1:27:35<14:33,  5.56it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:25 - INFO - __main__ - train loss is 20.70436473528389\n",
      "Steps:  68%|▋| 10142/15000 [1:27:35<14:32,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:25 - INFO - __main__ - train loss is 20.88745099643711\n",
      "Steps:  68%|▋| 10143/15000 [1:27:35<14:32,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:25 - INFO - __main__ - train loss is 21.034205916919746\n",
      "Steps:  68%|▋| 10144/15000 [1:27:35<14:31,  5.57it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:25 - INFO - __main__ - train loss is 21.050856204354204\n",
      "Steps:  68%|▋| 10145/15000 [1:27:35<14:32,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:25 - INFO - __main__ - train loss is 21.095034094178118\n",
      "Steps:  68%|▋| 10146/15000 [1:27:36<14:31,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:26 - INFO - __main__ - train loss is 21.09831252915319\n",
      "Steps:  68%|▋| 10147/15000 [1:27:36<14:40,  5.51it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:26 - INFO - __main__ - train loss is 21.17074065131601\n",
      "Steps:  68%|▋| 10148/15000 [1:27:36<14:39,  5.52it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:26 - INFO - __main__ - train loss is 21.230615051812492\n",
      "Steps:  68%|▋| 10149/15000 [1:27:36<14:36,  5.53it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:26 - INFO - __main__ - train loss is 21.71102187258657\n",
      "Steps:  68%|▋| 10150/15000 [1:27:36<14:40,  5.51it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:26 - INFO - __main__ - train loss is 21.7717988997465\n",
      "Steps:  68%|▋| 10151/15000 [1:27:37<14:45,  5.48it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:26 - INFO - __main__ - train loss is 21.792929979390465\n",
      "Steps:  68%|▋| 10152/15000 [1:27:37<14:47,  5.46it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:27 - INFO - __main__ - train loss is 21.79690024338197\n",
      "Steps:  68%|▋| 10153/15000 [1:27:37<14:50,  5.44it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:27 - INFO - __main__ - train loss is 21.990924940328114\n",
      "Steps:  68%|▋| 10154/15000 [1:27:37<14:52,  5.43it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:27 - INFO - __main__ - train loss is 22.091119074146263\n",
      "Steps:  68%|▋| 10155/15000 [1:27:37<14:45,  5.47it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:27 - INFO - __main__ - train loss is 22.66558166674804\n",
      "Steps:  68%|▋| 10156/15000 [1:27:37<14:59,  5.38it/s, lr=0.000996, step_loss=0.507/27/2023 19:12:27 - INFO - __main__ - train loss is 23.376742803375237\n",
      "Steps:  68%|▋| 10157/15000 [1:27:38<15:18,  5.27it/s, lr=0.000996, step_loss=0.707/27/2023 19:12:28 - INFO - __main__ - train loss is 23.399532579700463\n",
      "Steps:  68%|▋| 10158/15000 [1:27:38<15:26,  5.23it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:28 - INFO - __main__ - train loss is 23.401810772600584\n",
      "Steps:  68%|▋| 10159/15000 [1:27:38<15:31,  5.20it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:28 - INFO - __main__ - train loss is 23.566494352999143\n",
      "Steps:  68%|▋| 10160/15000 [1:27:38<15:35,  5.18it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:28 - INFO - __main__ - train loss is 23.580117644625716\n",
      "Steps:  68%|▋| 10161/15000 [1:27:38<15:37,  5.16it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:28 - INFO - __main__ - train loss is 24.00004106934648\n",
      "Steps:  68%|▋| 10162/15000 [1:27:39<15:39,  5.15it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:29 - INFO - __main__ - train loss is 24.108453320222907\n",
      "Steps:  68%|▋| 10163/15000 [1:27:39<15:41,  5.14it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:29 - INFO - __main__ - train loss is 24.420257853227668\n",
      "Steps:  68%|▋| 10164/15000 [1:27:39<15:41,  5.14it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:29 - INFO - __main__ - train loss is 24.444920761394314\n",
      "Steps:  68%|▋| 10165/15000 [1:27:39<15:42,  5.13it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:29 - INFO - __main__ - train loss is 24.683230711030774\n",
      "Steps:  68%|▋| 10166/15000 [1:27:39<15:42,  5.13it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:29 - INFO - __main__ - train loss is 24.992642236757092\n",
      "Steps:  68%|▋| 10167/15000 [1:27:40<15:43,  5.12it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:30 - INFO - __main__ - train loss is 24.99475787335541\n",
      "Steps:  68%|▋| 10168/15000 [1:27:40<15:43,  5.12it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:30 - INFO - __main__ - train loss is 24.998323283274658\n",
      "Steps:  68%|▋| 10169/15000 [1:27:40<15:40,  5.14it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:30 - INFO - __main__ - train loss is 25.07791304506827\n",
      "Steps:  68%|▋| 10170/15000 [1:27:40<15:39,  5.14it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:30 - INFO - __main__ - train loss is 25.239030956407078\n",
      "Steps:  68%|▋| 10171/15000 [1:27:40<15:41,  5.13it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:30 - INFO - __main__ - train loss is 25.254917447571643\n",
      "Steps:  68%|▋| 10172/15000 [1:27:41<15:41,  5.13it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:30 - INFO - __main__ - train loss is 25.272748815943487\n",
      "Steps:  68%|▋| 10173/15000 [1:27:41<15:41,  5.12it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:31 - INFO - __main__ - train loss is 25.76832188956905\n",
      "Steps:  68%|▋| 10174/15000 [1:27:41<15:42,  5.12it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:31 - INFO - __main__ - train loss is 25.789701833506115\n",
      "Steps:  68%|▋| 10175/15000 [1:27:41<15:42,  5.12it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:31 - INFO - __main__ - train loss is 25.793553289142437\n",
      "Steps:  68%|▋| 10176/15000 [1:27:41<15:42,  5.12it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:31 - INFO - __main__ - train loss is 25.900914106634445\n",
      "Steps:  68%|▋| 10177/15000 [1:27:42<15:41,  5.12it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:31 - INFO - __main__ - train loss is 26.092752251890488\n",
      "Steps:  68%|▋| 10178/15000 [1:27:42<15:42,  5.12it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:32 - INFO - __main__ - train loss is 26.14434159931261\n",
      "Steps:  68%|▋| 10179/15000 [1:27:42<15:41,  5.12it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:32 - INFO - __main__ - train loss is 26.149897612282075\n",
      "Steps:  68%|▋| 10180/15000 [1:27:42<15:43,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:32 - INFO - __main__ - train loss is 26.215227357693948\n",
      "Steps:  68%|▋| 10181/15000 [1:27:42<15:42,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:32 - INFO - __main__ - train loss is 26.26160786265973\n",
      "Steps:  68%|▋| 10182/15000 [1:27:43<15:43,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:32 - INFO - __main__ - train loss is 26.331484652706422\n",
      "Steps:  68%|▋| 10183/15000 [1:27:43<15:43,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:33 - INFO - __main__ - train loss is 26.33507461438421\n",
      "Steps:  68%|▋| 10184/15000 [1:27:43<15:42,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:33 - INFO - __main__ - train loss is 26.505597483017482\n",
      "Steps:  68%|▋| 10185/15000 [1:27:43<15:41,  5.11it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:33 - INFO - __main__ - train loss is 26.511858876910992\n",
      "Steps:  68%|▋| 10186/15000 [1:27:43<15:41,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:33 - INFO - __main__ - train loss is 26.516436916892417\n",
      "Steps:  68%|▋| 10187/15000 [1:27:44<15:43,  5.10it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:33 - INFO - __main__ - train loss is 26.59338294446934\n",
      "Steps:  68%|▋| 10188/15000 [1:27:44<15:42,  5.10it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:34 - INFO - __main__ - train loss is 26.594948163139634\n",
      "Steps:  68%|▋| 10189/15000 [1:27:44<15:42,  5.10it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:34 - INFO - __main__ - train loss is 26.596997867454775\n",
      "Steps:  68%|▋| 10190/15000 [1:27:44<15:41,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:34 - INFO - __main__ - train loss is 26.761829505790956\n",
      "Steps:  68%|▋| 10191/15000 [1:27:44<15:40,  5.11it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:34 - INFO - __main__ - train loss is 26.814423485775478\n",
      "Steps:  68%|▋| 10192/15000 [1:27:45<15:41,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:34 - INFO - __main__ - train loss is 26.89179675944615\n",
      "Steps:  68%|▋| 10193/15000 [1:27:45<15:40,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:35 - INFO - __main__ - train loss is 26.91218297474552\n",
      "Steps:  68%|▋| 10194/15000 [1:27:45<15:40,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:35 - INFO - __main__ - train loss is 26.923173703369685\n",
      "Steps:  68%|▋| 10195/15000 [1:27:45<15:40,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:35 - INFO - __main__ - train loss is 27.0373643116327\n",
      "Steps:  68%|▋| 10196/15000 [1:27:45<15:39,  5.11it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:35 - INFO - __main__ - train loss is 27.060010276851244\n",
      "Steps:  68%|▋| 10197/15000 [1:27:46<15:39,  5.11it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:35 - INFO - __main__ - train loss is 27.06158882379532\n",
      "Steps:  68%|▋| 10198/15000 [1:27:46<15:34,  5.14it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:36 - INFO - __main__ - train loss is 27.528064727783203\n",
      "Steps:  68%|▋| 10199/15000 [1:27:46<15:18,  5.23it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:36 - INFO - __main__ - train loss is 27.83802032470703\n",
      "Steps:  68%|▋| 10200/15000 [1:27:46<16:22,  4.88it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:36 - INFO - __main__ - train loss is 28.077251568436623\n",
      "Steps:  68%|▋| 10201/15000 [1:27:46<18:07,  4.41it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:36 - INFO - __main__ - train loss is 28.13580410555005\n",
      "Steps:  68%|▋| 10202/15000 [1:27:47<17:55,  4.46it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:37 - INFO - __main__ - train loss is 28.197434570640326\n",
      "Steps:  68%|▋| 10203/15000 [1:27:47<17:19,  4.62it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:37 - INFO - __main__ - train loss is 28.41270538792014\n",
      "Steps:  68%|▋| 10204/15000 [1:27:47<16:32,  4.83it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:37 - INFO - __main__ - train loss is 28.445085044950247\n",
      "Steps:  68%|▋| 10205/15000 [1:27:47<15:52,  5.03it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:37 - INFO - __main__ - train loss is 28.726587142795324\n",
      "Steps:  68%|▋| 10206/15000 [1:27:47<15:26,  5.17it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:37 - INFO - __main__ - train loss is 28.954331930726767\n",
      "Steps:  68%|▋| 10207/15000 [1:27:48<15:07,  5.28it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:37 - INFO - __main__ - train loss is 29.162458192557096\n",
      "Steps:  68%|▋| 10208/15000 [1:27:48<14:52,  5.37it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:38 - INFO - __main__ - train loss is 29.30101167783141\n",
      "Steps:  68%|▋| 10209/15000 [1:27:48<14:42,  5.43it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:38 - INFO - __main__ - train loss is 29.49479576572776\n",
      "Steps:  68%|▋| 10210/15000 [1:27:48<14:35,  5.47it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:38 - INFO - __main__ - train loss is 29.496869625523686\n",
      "Steps:  68%|▋| 10211/15000 [1:27:48<14:30,  5.50it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:38 - INFO - __main__ - train loss is 29.63603080995381\n",
      "Steps:  68%|▋| 10212/15000 [1:27:48<14:26,  5.52it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:38 - INFO - __main__ - train loss is 29.92544518597424\n",
      "Steps:  68%|▋| 10213/15000 [1:27:49<14:24,  5.54it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:38 - INFO - __main__ - train loss is 29.937217337079346\n",
      "Steps:  68%|▋| 10214/15000 [1:27:49<14:22,  5.55it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:39 - INFO - __main__ - train loss is 29.958755516447127\n",
      "Steps:  68%|▋| 10215/15000 [1:27:49<14:21,  5.55it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:39 - INFO - __main__ - train loss is 30.04932448361069\n",
      "Steps:  68%|▋| 10216/15000 [1:27:49<14:21,  5.55it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:39 - INFO - __main__ - train loss is 30.062054702080786\n",
      "Steps:  68%|▋| 10217/15000 [1:27:49<14:19,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:39 - INFO - __main__ - train loss is 30.068939143326133\n",
      "Steps:  68%|▋| 10218/15000 [1:27:50<14:19,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:39 - INFO - __main__ - train loss is 30.16850116243586\n",
      "Steps:  68%|▋| 10219/15000 [1:27:50<14:18,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:40 - INFO - __main__ - train loss is 30.69658269872889\n",
      "Steps:  68%|▋| 10220/15000 [1:27:50<14:17,  5.57it/s, lr=0.000996, step_loss=0.507/27/2023 19:12:40 - INFO - __main__ - train loss is 30.900983744766563\n",
      "Steps:  68%|▋| 10221/15000 [1:27:50<14:17,  5.57it/s, lr=0.000996, step_loss=0.207/27/2023 19:12:40 - INFO - __main__ - train loss is 30.902859501889907\n",
      "Steps:  68%|▋| 10222/15000 [1:27:50<14:17,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:40 - INFO - __main__ - train loss is 30.93084960838314\n",
      "Steps:  68%|▋| 10223/15000 [1:27:50<14:17,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:40 - INFO - __main__ - train loss is 31.270398434600793\n",
      "Steps:  68%|▋| 10224/15000 [1:27:51<14:17,  5.57it/s, lr=0.000996, step_loss=0.307/27/2023 19:12:40 - INFO - __main__ - train loss is 31.280533394194208\n",
      "Steps:  68%|▋| 10225/15000 [1:27:51<14:17,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:41 - INFO - __main__ - train loss is 31.28494163916912\n",
      "Steps:  68%|▋| 10226/15000 [1:27:51<14:16,  5.57it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:41 - INFO - __main__ - train loss is 31.286699217162095\n",
      "Steps:  68%|▋| 10227/15000 [1:27:51<14:19,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:41 - INFO - __main__ - train loss is 31.37316137214657\n",
      "Steps:  68%|▋| 10228/15000 [1:27:51<14:18,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:41 - INFO - __main__ - train loss is 31.384199036634527\n",
      "Steps:  68%|▋| 10229/15000 [1:27:51<14:18,  5.56it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:41 - INFO - __main__ - train loss is 31.42514956218656\n",
      "Steps:  68%|▋| 10230/15000 [1:27:52<14:27,  5.50it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:42 - INFO - __main__ - train loss is 31.496116632944904\n",
      "Steps:  68%|▋| 10231/15000 [1:27:52<14:26,  5.50it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:42 - INFO - __main__ - train loss is 31.55248884705361\n",
      "Steps:  68%|▋| 10232/15000 [1:27:52<14:22,  5.53it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:42 - INFO - __main__ - train loss is 31.559179218369536\n",
      "Steps:  68%|▋| 10233/15000 [1:27:52<14:28,  5.49it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:42 - INFO - __main__ - train loss is 31.581608895095997\n",
      "Steps:  68%|▋| 10234/15000 [1:27:52<14:31,  5.47it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:42 - INFO - __main__ - train loss is 31.597996625932865\n",
      "Steps:  68%|▋| 10235/15000 [1:27:53<14:31,  5.47it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:42 - INFO - __main__ - train loss is 32.42853215697687\n",
      "Steps:  68%|▋| 10236/15000 [1:27:53<14:26,  5.50it/s, lr=0.000996, step_loss=0.807/27/2023 19:12:43 - INFO - __main__ - train loss is 32.88107499841135\n",
      "Steps:  68%|▋| 10237/15000 [1:27:53<14:23,  5.52it/s, lr=0.000996, step_loss=0.407/27/2023 19:12:43 - INFO - __main__ - train loss is 32.90899384196382\n",
      "Steps:  68%|▋| 10238/15000 [1:27:53<14:20,  5.53it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:43 - INFO - __main__ - train loss is 32.92505329276901\n",
      "Steps:  68%|▋| 10239/15000 [1:27:53<14:18,  5.55it/s, lr=0.000996, step_loss=0.007/27/2023 19:12:43 - INFO - __main__ - train loss is 33.12326634849887\n",
      "Steps:  68%|▋| 10240/15000 [1:27:53<14:16,  5.56it/s, lr=0.000996, step_loss=0.107/27/2023 19:12:43 - INFO - __main__ - train loss is 33.12793161475565\n",
      "Steps:  68%|▋| 10241/15000 [1:27:54<14:17,  5.55it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:44 - INFO - __main__ - train loss is 33.58530046546366\n",
      "Steps:  68%|▋| 10242/15000 [1:27:54<14:16,  5.56it/s, lr=0.000995, step_loss=0.407/27/2023 19:12:44 - INFO - __main__ - train loss is 33.72269554936793\n",
      "Steps:  68%|▋| 10243/15000 [1:27:54<14:15,  5.56it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:44 - INFO - __main__ - train loss is 33.988137414096855\n",
      "Steps:  68%|▋| 10244/15000 [1:27:54<14:23,  5.51it/s, lr=0.000995, step_loss=0.207/27/2023 19:12:44 - INFO - __main__ - train loss is 33.99330812494736\n",
      "Steps:  68%|▋| 10245/15000 [1:27:54<14:37,  5.42it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:44 - INFO - __main__ - train loss is 34.1653813252924\n",
      "Steps:  68%|▋| 10246/15000 [1:27:55<14:30,  5.46it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:44 - INFO - __main__ - train loss is 34.17984292830806\n",
      "Steps:  68%|▋| 10247/15000 [1:27:55<14:24,  5.50it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:45 - INFO - __main__ - train loss is 34.20567662816029\n",
      "Steps:  68%|▋| 10248/15000 [1:27:55<14:20,  5.52it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:45 - INFO - __main__ - train loss is 34.21248519967776\n",
      "Steps:  68%|▋| 10249/15000 [1:27:55<14:26,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:45 - INFO - __main__ - train loss is 34.24699051852804\n",
      "Steps:  68%|▋| 10250/15000 [1:27:55<14:24,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:45 - INFO - __main__ - train loss is 34.298649707692675\n",
      "Steps:  68%|▋| 10251/15000 [1:27:55<14:21,  5.51it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:45 - INFO - __main__ - train loss is 34.637193599599414\n",
      "Steps:  68%|▋| 10252/15000 [1:27:56<14:18,  5.53it/s, lr=0.000995, step_loss=0.307/27/2023 19:12:46 - INFO - __main__ - train loss is 34.63972932181787\n",
      "Steps:  68%|▋| 10253/15000 [1:27:56<14:16,  5.55it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:46 - INFO - __main__ - train loss is 34.82653763971757\n",
      "Steps:  68%|▋| 10254/15000 [1:27:56<14:14,  5.56it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:46 - INFO - __main__ - train loss is 35.49694028578233\n",
      "Steps:  68%|▋| 10255/15000 [1:27:56<14:13,  5.56it/s, lr=0.000995, step_loss=0.607/27/2023 19:12:46 - INFO - __main__ - train loss is 35.6271949269576\n",
      "Steps:  68%|▋| 10256/15000 [1:27:56<14:13,  5.56it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:46 - INFO - __main__ - train loss is 35.640469215693884\n",
      "Steps:  68%|▋| 10257/15000 [1:27:57<14:13,  5.56it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:46 - INFO - __main__ - train loss is 35.69508777174633\n",
      "Steps:  68%|▋| 10258/15000 [1:27:57<14:12,  5.56it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:47 - INFO - __main__ - train loss is 35.99305127176922\n",
      "Steps:  68%|▋| 10259/15000 [1:27:57<14:12,  5.56it/s, lr=0.000995, step_loss=0.207/27/2023 19:12:47 - INFO - __main__ - train loss is 36.0195663793711\n",
      "Steps:  68%|▋| 10260/15000 [1:27:57<14:12,  5.56it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:47 - INFO - __main__ - train loss is 36.022778726532124\n",
      "Steps:  68%|▋| 10261/15000 [1:27:57<14:12,  5.56it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:47 - INFO - __main__ - train loss is 36.42817694635596\n",
      "Steps:  68%|▋| 10262/15000 [1:27:57<14:12,  5.56it/s, lr=0.000995, step_loss=0.407/27/2023 19:12:47 - INFO - __main__ - train loss is 36.464949122979306\n",
      "Steps:  68%|▋| 10263/15000 [1:27:58<14:11,  5.56it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:48 - INFO - __main__ - train loss is 36.72558843286242\n",
      "Steps:  68%|▋| 10264/15000 [1:27:58<14:19,  5.51it/s, lr=0.000995, step_loss=0.207/27/2023 19:12:48 - INFO - __main__ - train loss is 36.749983909889124\n",
      "Steps:  68%|▋| 10265/15000 [1:27:58<14:16,  5.53it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:48 - INFO - __main__ - train loss is 36.758466852246784\n",
      "Steps:  68%|▋| 10266/15000 [1:27:58<14:14,  5.54it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:48 - INFO - __main__ - train loss is 36.759798232931644\n",
      "Steps:  68%|▋| 10267/15000 [1:27:58<14:13,  5.55it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:48 - INFO - __main__ - train loss is 36.76582931866869\n",
      "Steps:  68%|▋| 10268/15000 [1:27:59<14:11,  5.55it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:48 - INFO - __main__ - train loss is 36.783825458493084\n",
      "Steps:  68%|▋| 10269/15000 [1:27:59<14:11,  5.56it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:49 - INFO - __main__ - train loss is 36.90480099758133\n",
      "Steps:  68%|▋| 10270/15000 [1:27:59<14:10,  5.56it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:49 - INFO - __main__ - train loss is 36.94189434265718\n",
      "Steps:  68%|▋| 10271/15000 [1:27:59<14:10,  5.56it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:49 - INFO - __main__ - train loss is 36.996116736438125\n",
      "Steps:  68%|▋| 10272/15000 [1:27:59<14:09,  5.57it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:49 - INFO - __main__ - train loss is 37.15664627542719\n",
      "Steps:  68%|▋| 10273/15000 [1:27:59<14:08,  5.57it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:49 - INFO - __main__ - train loss is 37.49974631657824\n",
      "Steps:  68%|▋| 10274/15000 [1:28:00<14:09,  5.56it/s, lr=0.000995, step_loss=0.307/27/2023 19:12:49 - INFO - __main__ - train loss is 37.849055820610374\n",
      "Steps:  68%|▋| 10275/15000 [1:28:00<14:09,  5.56it/s, lr=0.000995, step_loss=0.307/27/2023 19:12:50 - INFO - __main__ - train loss is 38.25963341584429\n",
      "Steps:  69%|▋| 10276/15000 [1:28:00<14:09,  5.56it/s, lr=0.000995, step_loss=0.407/27/2023 19:12:50 - INFO - __main__ - train loss is 38.77905028453097\n",
      "Steps:  69%|▋| 10277/15000 [1:28:00<14:09,  5.56it/s, lr=0.000995, step_loss=0.507/27/2023 19:12:50 - INFO - __main__ - train loss is 38.803937665652484\n",
      "Steps:  69%|▋| 10278/15000 [1:28:00<14:08,  5.57it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:50 - INFO - __main__ - train loss is 38.82233478082344\n",
      "Steps:  69%|▋| 10279/15000 [1:28:01<14:08,  5.57it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:50 - INFO - __main__ - train loss is 39.15285877836868\n",
      "Steps:  69%|▋| 10280/15000 [1:28:01<14:07,  5.57it/s, lr=0.000995, step_loss=0.307/27/2023 19:12:51 - INFO - __main__ - train loss is 39.27905546082184\n",
      "Steps:  69%|▋| 10281/15000 [1:28:01<14:07,  5.57it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:51 - INFO - __main__ - train loss is 39.445897444617\n",
      "Steps:  69%|▋| 10282/15000 [1:28:01<14:06,  5.57it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:51 - INFO - __main__ - train loss is 39.45954796066508\n",
      "Steps:  69%|▋| 10283/15000 [1:28:01<14:06,  5.57it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:51 - INFO - __main__ - train loss is 39.46324157435447\n",
      "Steps:  69%|▋| 10284/15000 [1:28:01<14:06,  5.57it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:51 - INFO - __main__ - train loss is 39.60102377552539\n",
      "Steps:  69%|▋| 10285/15000 [1:28:02<14:06,  5.57it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:51 - INFO - __main__ - train loss is 39.877093833871186\n",
      "Steps:  69%|▋| 10286/15000 [1:28:02<14:05,  5.58it/s, lr=0.000995, step_loss=0.207/27/2023 19:12:52 - INFO - __main__ - train loss is 39.896129184402525\n",
      "Steps:  69%|▋| 10287/15000 [1:28:02<14:06,  5.57it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:52 - INFO - __main__ - train loss is 39.94771554041654\n",
      "Steps:  69%|▋| 10288/15000 [1:28:02<14:05,  5.57it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:52 - INFO - __main__ - train loss is 40.10468695033342\n",
      "Steps:  69%|▋| 10289/15000 [1:28:02<14:04,  5.58it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:52 - INFO - __main__ - train loss is 40.27286559808999\n",
      "Steps:  69%|▋| 10290/15000 [1:28:02<14:03,  5.58it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:52 - INFO - __main__ - train loss is 40.534462039358914\n",
      "Steps:  69%|▋| 10291/15000 [1:28:03<14:03,  5.58it/s, lr=0.000995, step_loss=0.207/27/2023 19:12:53 - INFO - __main__ - train loss is 40.56874577794224\n",
      "Steps:  69%|▋| 10292/15000 [1:28:03<14:03,  5.58it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:53 - INFO - __main__ - train loss is 40.62590725813061\n",
      "Steps:  69%|▋| 10293/15000 [1:28:03<14:03,  5.58it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:53 - INFO - __main__ - train loss is 40.93437458667904\n",
      "Steps:  69%|▋| 10294/15000 [1:28:03<14:02,  5.58it/s, lr=0.000995, step_loss=0.307/27/2023 19:12:53 - INFO - __main__ - train loss is 40.944753226824105\n",
      "Steps:  69%|▋| 10295/15000 [1:28:03<14:02,  5.59it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:53 - INFO - __main__ - train loss is 41.05691882688552\n",
      "Steps:  69%|▋| 10296/15000 [1:28:04<14:01,  5.59it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:53 - INFO - __main__ - train loss is 41.06401111185551\n",
      "Steps:  69%|▋| 10297/15000 [1:28:04<14:01,  5.59it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:54 - INFO - __main__ - train loss is 41.28718914091587\n",
      "Steps:  69%|▋| 10298/15000 [1:28:04<14:01,  5.59it/s, lr=0.000995, step_loss=0.207/27/2023 19:12:54 - INFO - __main__ - train loss is 42.110058560967445\n",
      "Steps:  69%|▋| 10299/15000 [1:28:04<14:01,  5.59it/s, lr=0.000995, step_loss=0.807/27/2023 19:12:54 - INFO - __main__ - train loss is 42.214861288666725\n",
      "Steps:  69%|▋| 10300/15000 [1:28:04<14:00,  5.59it/s, lr=0.000995, step_loss=0.107/27/2023 19:12:54 - INFO - __main__ - train loss is 42.25939365848899\n",
      "Steps:  69%|▋| 10301/15000 [1:28:04<14:00,  5.59it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:55 - INFO - __main__ - train loss is 42.30846953392029\n",
      "Steps:  69%|▋| 10302/15000 [1:28:05<19:25,  4.03it/s, lr=0.000995, step_loss=0.007/27/2023 19:12:56 - INFO - __main__ - Per validation step average loss is 0.1066916212439537\n",
      "07/27/2023 19:12:56 - INFO - __main__ - Cumulative validation average loss is 0.1066916212439537\n",
      "07/27/2023 19:12:56 - INFO - __main__ - Per validation step average loss is 0.1932889223098755\n",
      "07/27/2023 19:12:56 - INFO - __main__ - Cumulative validation average loss is 0.2999805435538292\n",
      "07/27/2023 19:12:56 - INFO - __main__ - Per validation step average loss is 0.06094515696167946\n",
      "07/27/2023 19:12:56 - INFO - __main__ - Cumulative validation average loss is 0.36092570051550865\n",
      "07/27/2023 19:12:57 - INFO - __main__ - Per validation step average loss is 0.5156214237213135\n",
      "07/27/2023 19:12:57 - INFO - __main__ - Cumulative validation average loss is 0.8765471242368221\n",
      "07/27/2023 19:12:57 - INFO - __main__ - Per validation step average loss is 0.003174994606524706\n",
      "07/27/2023 19:12:57 - INFO - __main__ - Cumulative validation average loss is 0.8797221188433468\n",
      "07/27/2023 19:12:58 - INFO - __main__ - Per validation step average loss is 0.042601749300956726\n",
      "07/27/2023 19:12:58 - INFO - __main__ - Cumulative validation average loss is 0.9223238681443036\n",
      "07/27/2023 19:12:58 - INFO - __main__ - Per validation step average loss is 0.14515197277069092\n",
      "07/27/2023 19:12:58 - INFO - __main__ - Cumulative validation average loss is 1.0674758409149945\n",
      "07/27/2023 19:12:58 - INFO - __main__ - Per validation step average loss is 0.01169892679899931\n",
      "07/27/2023 19:12:58 - INFO - __main__ - Cumulative validation average loss is 1.0791747677139938\n",
      "07/27/2023 19:12:59 - INFO - __main__ - Per validation step average loss is 0.17272230982780457\n",
      "07/27/2023 19:12:59 - INFO - __main__ - Cumulative validation average loss is 1.2518970775417984\n",
      "07/27/2023 19:12:59 - INFO - __main__ - Per validation step average loss is 0.02364368736743927\n",
      "07/27/2023 19:12:59 - INFO - __main__ - Cumulative validation average loss is 1.2755407649092376\n",
      "07/27/2023 19:13:00 - INFO - __main__ - Per validation step average loss is 0.02022559382021427\n",
      "07/27/2023 19:13:00 - INFO - __main__ - Cumulative validation average loss is 1.295766358729452\n",
      "07/27/2023 19:13:00 - INFO - __main__ - Per validation step average loss is 0.0017879148945212364\n",
      "07/27/2023 19:13:00 - INFO - __main__ - Cumulative validation average loss is 1.2975542736239731\n",
      "07/27/2023 19:13:01 - INFO - __main__ - Per validation step average loss is 0.12022428959608078\n",
      "07/27/2023 19:13:01 - INFO - __main__ - Cumulative validation average loss is 1.417778563220054\n",
      "07/27/2023 19:13:01 - INFO - __main__ - Per validation step average loss is 0.04746738076210022\n",
      "07/27/2023 19:13:01 - INFO - __main__ - Cumulative validation average loss is 1.4652459439821541\n",
      "07/27/2023 19:13:01 - INFO - __main__ - Per validation step average loss is 0.0036753362510353327\n",
      "07/27/2023 19:13:01 - INFO - __main__ - Cumulative validation average loss is 1.4689212802331895\n",
      "07/27/2023 19:13:02 - INFO - __main__ - Per validation step average loss is 0.14178064465522766\n",
      "07/27/2023 19:13:02 - INFO - __main__ - Cumulative validation average loss is 1.6107019248884171\n",
      "07/27/2023 19:13:02 - INFO - __main__ - Per validation step average loss is 0.055997222661972046\n",
      "07/27/2023 19:13:02 - INFO - __main__ - Cumulative validation average loss is 1.6666991475503892\n",
      "07/27/2023 19:13:03 - INFO - __main__ - Per validation step average loss is 0.7426646947860718\n",
      "07/27/2023 19:13:03 - INFO - __main__ - Cumulative validation average loss is 2.409363842336461\n",
      "07/27/2023 19:13:03 - INFO - __main__ - Per validation step average loss is 0.21777261793613434\n",
      "07/27/2023 19:13:03 - INFO - __main__ - Cumulative validation average loss is 2.6271364602725953\n",
      "07/27/2023 19:13:03 - INFO - __main__ - Per validation step average loss is 0.16244371235370636\n",
      "07/27/2023 19:13:03 - INFO - __main__ - Cumulative validation average loss is 2.7895801726263016\n",
      "07/27/2023 19:13:04 - INFO - __main__ - Per validation step average loss is 0.0023860321380198\n",
      "07/27/2023 19:13:04 - INFO - __main__ - Cumulative validation average loss is 2.7919662047643214\n",
      "07/27/2023 19:13:04 - INFO - __main__ - Per validation step average loss is 0.31363874673843384\n",
      "07/27/2023 19:13:04 - INFO - __main__ - Cumulative validation average loss is 3.1056049515027553\n",
      "07/27/2023 19:13:05 - INFO - __main__ - Per validation step average loss is 0.05129988491535187\n",
      "07/27/2023 19:13:05 - INFO - __main__ - Cumulative validation average loss is 3.156904836418107\n",
      "07/27/2023 19:13:05 - INFO - __main__ - Per validation step average loss is 0.00902520027011633\n",
      "07/27/2023 19:13:05 - INFO - __main__ - Cumulative validation average loss is 3.1659300366882235\n",
      "07/27/2023 19:13:06 - INFO - __main__ - Per validation step average loss is 0.007520217914134264\n",
      "07/27/2023 19:13:06 - INFO - __main__ - Cumulative validation average loss is 3.1734502546023577\n",
      "07/27/2023 19:13:06 - INFO - __main__ - Per validation step average loss is 0.23768335580825806\n",
      "07/27/2023 19:13:06 - INFO - __main__ - Cumulative validation average loss is 3.411133610410616\n",
      "07/27/2023 19:13:06 - INFO - __main__ - Per validation step average loss is 0.17123830318450928\n",
      "07/27/2023 19:13:06 - INFO - __main__ - Cumulative validation average loss is 3.582371913595125\n",
      "07/27/2023 19:13:07 - INFO - __main__ - Per validation step average loss is 0.0014658323489129543\n",
      "07/27/2023 19:13:07 - INFO - __main__ - Cumulative validation average loss is 3.583837745944038\n",
      "07/27/2023 19:13:07 - INFO - __main__ - Per validation step average loss is 0.33385413885116577\n",
      "07/27/2023 19:13:07 - INFO - __main__ - Cumulative validation average loss is 3.917691884795204\n",
      "07/27/2023 19:13:08 - INFO - __main__ - Per validation step average loss is 0.004549448378384113\n",
      "07/27/2023 19:13:08 - INFO - __main__ - Cumulative validation average loss is 3.922241333173588\n",
      "07/27/2023 19:13:08 - INFO - __main__ - Per validation step average loss is 0.23640236258506775\n",
      "07/27/2023 19:13:08 - INFO - __main__ - Cumulative validation average loss is 4.158643695758656\n",
      "07/27/2023 19:13:08 - INFO - __main__ - Per validation step average loss is 0.10337064415216446\n",
      "07/27/2023 19:13:08 - INFO - __main__ - Cumulative validation average loss is 4.26201433991082\n",
      "07/27/2023 19:13:09 - INFO - __main__ - Per validation step average loss is 0.3126465082168579\n",
      "07/27/2023 19:13:09 - INFO - __main__ - Cumulative validation average loss is 4.574660848127678\n",
      "07/27/2023 19:13:09 - INFO - __main__ - Per validation step average loss is 0.6068470478057861\n",
      "07/27/2023 19:13:09 - INFO - __main__ - Cumulative validation average loss is 5.181507895933464\n",
      "07/27/2023 19:13:10 - INFO - __main__ - Per validation step average loss is 0.01570139080286026\n",
      "07/27/2023 19:13:10 - INFO - __main__ - Cumulative validation average loss is 5.197209286736324\n",
      "07/27/2023 19:13:10 - INFO - __main__ - Per validation step average loss is 0.20116198062896729\n",
      "07/27/2023 19:13:10 - INFO - __main__ - Cumulative validation average loss is 5.398371267365292\n",
      "07/27/2023 19:13:10 - INFO - __main__ - Per validation step average loss is 0.019519731402397156\n",
      "07/27/2023 19:13:10 - INFO - __main__ - Cumulative validation average loss is 5.417890998767689\n",
      "07/27/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.09908431768417358\n",
      "07/27/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 5.5169753164518625\n",
      "07/27/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.49210110306739807\n",
      "07/27/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 6.0090764195192605\n",
      "07/27/2023 19:13:12 - INFO - __main__ - Per validation step average loss is 0.07493209093809128\n",
      "07/27/2023 19:13:12 - INFO - __main__ - Cumulative validation average loss is 6.084008510457352\n",
      "07/27/2023 19:13:12 - INFO - __main__ - Per validation step average loss is 0.5959517955780029\n",
      "07/27/2023 19:13:12 - INFO - __main__ - Cumulative validation average loss is 6.679960306035355\n",
      "07/27/2023 19:13:13 - INFO - __main__ - Per validation step average loss is 0.0029713986441493034\n",
      "07/27/2023 19:13:13 - INFO - __main__ - Cumulative validation average loss is 6.682931704679504\n",
      "07/27/2023 19:13:13 - INFO - __main__ - Per validation step average loss is 0.017280975356698036\n",
      "07/27/2023 19:13:13 - INFO - __main__ - Cumulative validation average loss is 6.700212680036202\n",
      "07/27/2023 19:13:13 - INFO - __main__ - Per validation step average loss is 0.0021318672224879265\n",
      "07/27/2023 19:13:13 - INFO - __main__ - Cumulative validation average loss is 6.70234454725869\n",
      "07/27/2023 19:13:14 - INFO - __main__ - Per validation step average loss is 0.04799644649028778\n",
      "07/27/2023 19:13:14 - INFO - __main__ - Cumulative validation average loss is 6.750340993748978\n",
      "07/27/2023 19:13:14 - INFO - __main__ - Per validation step average loss is 0.05519995465874672\n",
      "07/27/2023 19:13:14 - INFO - __main__ - Cumulative validation average loss is 6.8055409484077245\n",
      "07/27/2023 19:13:15 - INFO - __main__ - Per validation step average loss is 0.006402348633855581\n",
      "07/27/2023 19:13:15 - INFO - __main__ - Cumulative validation average loss is 6.81194329704158\n",
      "07/27/2023 19:13:15 - INFO - __main__ - Per validation step average loss is 0.13814911246299744\n",
      "07/27/2023 19:13:15 - INFO - __main__ - Cumulative validation average loss is 6.9500924095045775\n",
      "07/27/2023 19:13:15 - INFO - __main__ - Per validation step average loss is 0.9141316413879395\n",
      "07/27/2023 19:13:15 - INFO - __main__ - Cumulative validation average loss is 7.864224050892517\n",
      "07/27/2023 19:13:16 - INFO - __main__ - Per validation step average loss is 0.027617182582616806\n",
      "07/27/2023 19:13:16 - INFO - __main__ - Cumulative validation average loss is 7.891841233475134\n",
      "07/27/2023 19:13:16 - INFO - __main__ - Per validation step average loss is 0.049268074333667755\n",
      "07/27/2023 19:13:16 - INFO - __main__ - Cumulative validation average loss is 7.9411093078088015\n",
      "07/27/2023 19:13:17 - INFO - __main__ - Per validation step average loss is 0.3856234848499298\n",
      "07/27/2023 19:13:17 - INFO - __main__ - Cumulative validation average loss is 8.326732792658731\n",
      "07/27/2023 19:13:17 - INFO - __main__ - Per validation step average loss is 0.31000426411628723\n",
      "07/27/2023 19:13:17 - INFO - __main__ - Cumulative validation average loss is 8.636737056775019\n",
      "07/27/2023 19:13:17 - INFO - __main__ - Per validation step average loss is 0.004860018379986286\n",
      "07/27/2023 19:13:17 - INFO - __main__ - Cumulative validation average loss is 8.641597075155005\n",
      "07/27/2023 19:13:18 - INFO - __main__ - Per validation step average loss is 0.0448138564825058\n",
      "07/27/2023 19:13:18 - INFO - __main__ - Cumulative validation average loss is 8.68641093163751\n",
      "07/27/2023 19:13:18 - INFO - __main__ - Per validation step average loss is 0.23243770003318787\n",
      "07/27/2023 19:13:18 - INFO - __main__ - Cumulative validation average loss is 8.918848631670699\n",
      "07/27/2023 19:13:19 - INFO - __main__ - Per validation step average loss is 0.003610304556787014\n",
      "07/27/2023 19:13:19 - INFO - __main__ - Cumulative validation average loss is 8.922458936227486\n",
      "07/27/2023 19:13:19 - INFO - __main__ - Per validation step average loss is 0.0242052860558033\n",
      "07/27/2023 19:13:19 - INFO - __main__ - Cumulative validation average loss is 8.946664222283289\n",
      "07/27/2023 19:13:20 - INFO - __main__ - Per validation step average loss is 0.2614842653274536\n",
      "07/27/2023 19:13:20 - INFO - __main__ - Cumulative validation average loss is 9.208148487610742\n",
      "07/27/2023 19:13:20 - INFO - __main__ - Per validation step average loss is 0.09104882925748825\n",
      "07/27/2023 19:13:20 - INFO - __main__ - Cumulative validation average loss is 9.29919731686823\n",
      "07/27/2023 19:13:20 - INFO - __main__ - Per validation step average loss is 0.002103065839037299\n",
      "07/27/2023 19:13:20 - INFO - __main__ - Cumulative validation average loss is 9.301300382707268\n",
      "07/27/2023 19:13:21 - INFO - __main__ - Per validation step average loss is 0.3097378611564636\n",
      "07/27/2023 19:13:21 - INFO - __main__ - Cumulative validation average loss is 9.611038243863732\n",
      "07/27/2023 19:13:21 - INFO - __main__ - Per validation step average loss is 0.016230929642915726\n",
      "07/27/2023 19:13:21 - INFO - __main__ - Cumulative validation average loss is 9.627269173506647\n",
      "07/27/2023 19:13:22 - INFO - __main__ - Per validation step average loss is 0.16188514232635498\n",
      "07/27/2023 19:13:22 - INFO - __main__ - Cumulative validation average loss is 9.789154315833002\n",
      "07/27/2023 19:13:22 - INFO - __main__ - Per validation step average loss is 0.32055097818374634\n",
      "07/27/2023 19:13:22 - INFO - __main__ - Cumulative validation average loss is 10.109705294016749\n",
      "07/27/2023 19:13:22 - INFO - __main__ - Per validation step average loss is 0.004146629013121128\n",
      "07/27/2023 19:13:22 - INFO - __main__ - Cumulative validation average loss is 10.11385192302987\n",
      "07/27/2023 19:13:23 - INFO - __main__ - Per validation step average loss is 0.01294209435582161\n",
      "07/27/2023 19:13:23 - INFO - __main__ - Cumulative validation average loss is 10.126794017385691\n",
      "07/27/2023 19:13:23 - INFO - __main__ - Per validation step average loss is 0.005628413986414671\n",
      "07/27/2023 19:13:23 - INFO - __main__ - Cumulative validation average loss is 10.132422431372106\n",
      "07/27/2023 19:13:24 - INFO - __main__ - Per validation step average loss is 0.003477452788501978\n",
      "07/27/2023 19:13:24 - INFO - __main__ - Cumulative validation average loss is 10.135899884160608\n",
      "07/27/2023 19:13:24 - INFO - __main__ - Per validation step average loss is 0.0029600090347230434\n",
      "07/27/2023 19:13:24 - INFO - __main__ - Cumulative validation average loss is 10.138859893195331\n",
      "07/27/2023 19:13:25 - INFO - __main__ - Per validation step average loss is 0.012217508628964424\n",
      "07/27/2023 19:13:25 - INFO - __main__ - Cumulative validation average loss is 10.151077401824296\n",
      "07/27/2023 19:13:25 - INFO - __main__ - Per validation step average loss is 0.023731932044029236\n",
      "07/27/2023 19:13:25 - INFO - __main__ - Cumulative validation average loss is 10.174809333868325\n",
      "07/27/2023 19:13:25 - INFO - __main__ - Per validation step average loss is 0.0037760096602141857\n",
      "07/27/2023 19:13:25 - INFO - __main__ - Cumulative validation average loss is 10.178585343528539\n",
      "07/27/2023 19:13:26 - INFO - __main__ - Per validation step average loss is 0.22052402794361115\n",
      "07/27/2023 19:13:26 - INFO - __main__ - Cumulative validation average loss is 10.39910937147215\n",
      "07/27/2023 19:13:26 - INFO - __main__ - Per validation step average loss is 0.40025216341018677\n",
      "07/27/2023 19:13:26 - INFO - __main__ - Cumulative validation average loss is 10.799361534882337\n",
      "07/27/2023 19:13:27 - INFO - __main__ - Per validation step average loss is 0.06983962655067444\n",
      "07/27/2023 19:13:27 - INFO - __main__ - Cumulative validation average loss is 10.869201161433011\n",
      "07/27/2023 19:13:27 - INFO - __main__ - Per validation step average loss is 0.03782934695482254\n",
      "07/27/2023 19:13:27 - INFO - __main__ - Cumulative validation average loss is 10.907030508387834\n",
      "07/27/2023 19:13:27 - INFO - __main__ - Per validation step average loss is 0.1733759194612503\n",
      "07/27/2023 19:13:27 - INFO - __main__ - Cumulative validation average loss is 11.080406427849084\n",
      "07/27/2023 19:13:28 - INFO - __main__ - Per validation step average loss is 0.057659365236759186\n",
      "07/27/2023 19:13:28 - INFO - __main__ - Cumulative validation average loss is 11.138065793085843\n",
      "07/27/2023 19:13:28 - INFO - __main__ - Average validation loss for Epoch 33 is 0.14098817459602334\n",
      "07/27/2023 19:13:28 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:14:25 - INFO - __main__ - Starting epoch 34\n",
      "07/27/2023 19:14:26 - INFO - __main__ - train loss is 0.0037235263735055923\n",
      "Steps:  69%|▋| 10303/15000 [1:29:36<36:03:13, 27.63s/it, lr=0.000995, step_loss=07/27/2023 19:14:26 - INFO - __main__ - train loss is 0.009125736076384783\n",
      "Steps:  69%|▋| 10304/15000 [1:29:37<25:18:16, 19.40s/it, lr=0.000995, step_loss=07/27/2023 19:14:26 - INFO - __main__ - train loss is 0.03482072660699487\n",
      "Steps:  69%|▋| 10305/15000 [1:29:37<17:46:53, 13.63s/it, lr=0.000995, step_loss=07/27/2023 19:14:27 - INFO - __main__ - train loss is 0.04275631392374635\n",
      "Steps:  69%|▋| 10306/15000 [1:29:37<12:31:01,  9.60s/it, lr=0.000995, step_loss=07/27/2023 19:14:27 - INFO - __main__ - train loss is 0.8390636988915503\n",
      "Steps:  69%|▋| 10307/15000 [1:29:37<8:49:47,  6.77s/it, lr=0.000995, step_loss=007/27/2023 19:14:27 - INFO - __main__ - train loss is 0.847343631554395\n",
      "Steps:  69%|▋| 10308/15000 [1:29:37<6:15:11,  4.80s/it, lr=0.000995, step_loss=007/27/2023 19:14:27 - INFO - __main__ - train loss is 0.8508476454298943\n",
      "Steps:  69%|▋| 10309/15000 [1:29:38<4:27:16,  3.42s/it, lr=0.000995, step_loss=007/27/2023 19:14:27 - INFO - __main__ - train loss is 1.142219765810296\n",
      "Steps:  69%|▋| 10310/15000 [1:29:38<3:11:39,  2.45s/it, lr=0.000995, step_loss=007/27/2023 19:14:28 - INFO - __main__ - train loss is 1.3354422885458916\n",
      "Steps:  69%|▋| 10311/15000 [1:29:38<2:18:41,  1.77s/it, lr=0.000995, step_loss=007/27/2023 19:14:28 - INFO - __main__ - train loss is 1.390950760571286\n",
      "Steps:  69%|▋| 10312/15000 [1:29:38<1:41:37,  1.30s/it, lr=0.000995, step_loss=007/27/2023 19:14:28 - INFO - __main__ - train loss is 1.4752430233638734\n",
      "Steps:  69%|▋| 10313/15000 [1:29:38<1:15:27,  1.04it/s, lr=0.000995, step_loss=007/27/2023 19:14:28 - INFO - __main__ - train loss is 1.480253332061693\n",
      "Steps:  69%|▋| 10314/15000 [1:29:38<57:00,  1.37it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:28 - INFO - __main__ - train loss is 1.4897162120323628\n",
      "Steps:  69%|▋| 10315/15000 [1:29:39<44:17,  1.76it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:29 - INFO - __main__ - train loss is 2.256913165329024\n",
      "Steps:  69%|▋| 10316/15000 [1:29:39<35:32,  2.20it/s, lr=0.000995, step_loss=0.707/27/2023 19:14:29 - INFO - __main__ - train loss is 2.2870699006598443\n",
      "Steps:  69%|▋| 10317/15000 [1:29:39<29:18,  2.66it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:29 - INFO - __main__ - train loss is 2.3002708756830543\n",
      "Steps:  69%|▋| 10318/15000 [1:29:39<24:44,  3.15it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:29 - INFO - __main__ - train loss is 2.3171595146413893\n",
      "Steps:  69%|▋| 10319/15000 [1:29:39<21:38,  3.61it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:29 - INFO - __main__ - train loss is 3.0003750135656446\n",
      "Steps:  69%|▋| 10320/15000 [1:29:40<19:20,  4.03it/s, lr=0.000995, step_loss=0.607/27/2023 19:14:29 - INFO - __main__ - train loss is 3.263976495480165\n",
      "Steps:  69%|▋| 10321/15000 [1:29:40<17:52,  4.36it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:30 - INFO - __main__ - train loss is 3.2684757958631963\n",
      "Steps:  69%|▋| 10322/15000 [1:29:40<16:59,  4.59it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:30 - INFO - __main__ - train loss is 3.5401101063471287\n",
      "Steps:  69%|▋| 10323/15000 [1:29:40<16:22,  4.76it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:30 - INFO - __main__ - train loss is 3.5827189709525555\n",
      "Steps:  69%|▋| 10324/15000 [1:29:40<15:49,  4.92it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:30 - INFO - __main__ - train loss is 3.783805313287303\n",
      "Steps:  69%|▋| 10325/15000 [1:29:41<15:21,  5.07it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:30 - INFO - __main__ - train loss is 3.799856302095577\n",
      "Steps:  69%|▋| 10326/15000 [1:29:41<15:01,  5.19it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:31 - INFO - __main__ - train loss is 3.8601357012521476\n",
      "Steps:  69%|▋| 10327/15000 [1:29:41<14:51,  5.24it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:31 - INFO - __main__ - train loss is 3.9772413938771933\n",
      "Steps:  69%|▋| 10328/15000 [1:29:41<14:45,  5.27it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:31 - INFO - __main__ - train loss is 4.008773137582466\n",
      "Steps:  69%|▋| 10329/15000 [1:29:41<14:32,  5.35it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:31 - INFO - __main__ - train loss is 4.145228420151398\n",
      "Steps:  69%|▋| 10330/15000 [1:29:41<14:23,  5.41it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:31 - INFO - __main__ - train loss is 4.25837564910762\n",
      "Steps:  69%|▋| 10331/15000 [1:29:42<14:22,  5.41it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:32 - INFO - __main__ - train loss is 4.319101855857298\n",
      "Steps:  69%|▋| 10332/15000 [1:29:42<14:23,  5.41it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:32 - INFO - __main__ - train loss is 4.364261650247499\n",
      "Steps:  69%|▋| 10333/15000 [1:29:42<14:15,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:32 - INFO - __main__ - train loss is 4.691551678581163\n",
      "Steps:  69%|▋| 10334/15000 [1:29:42<14:15,  5.45it/s, lr=0.000995, step_loss=0.307/27/2023 19:14:32 - INFO - __main__ - train loss is 4.693679263582453\n",
      "Steps:  69%|▋| 10335/15000 [1:29:42<14:11,  5.48it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:32 - INFO - __main__ - train loss is 4.788142589619383\n",
      "Steps:  69%|▋| 10336/15000 [1:29:43<14:16,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:32 - INFO - __main__ - train loss is 4.805432716151699\n",
      "Steps:  69%|▋| 10337/15000 [1:29:43<14:20,  5.42it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:33 - INFO - __main__ - train loss is 4.808398615801707\n",
      "Steps:  69%|▋| 10338/15000 [1:29:43<14:19,  5.42it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:33 - INFO - __main__ - train loss is 4.836786512518302\n",
      "Steps:  69%|▋| 10339/15000 [1:29:43<14:28,  5.36it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:33 - INFO - __main__ - train loss is 4.9370636532548815\n",
      "Steps:  69%|▋| 10340/15000 [1:29:43<14:33,  5.34it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:33 - INFO - __main__ - train loss is 5.212548155570403\n",
      "Steps:  69%|▋| 10341/15000 [1:29:43<14:25,  5.38it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:33 - INFO - __main__ - train loss is 5.257340636337176\n",
      "Steps:  69%|▋| 10342/15000 [1:29:44<14:23,  5.39it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:34 - INFO - __main__ - train loss is 5.2628936937544495\n",
      "Steps:  69%|▋| 10343/15000 [1:29:44<14:20,  5.41it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:34 - INFO - __main__ - train loss is 5.271866996074095\n",
      "Steps:  69%|▋| 10344/15000 [1:29:44<14:13,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:34 - INFO - __main__ - train loss is 5.670845080399886\n",
      "Steps:  69%|▋| 10345/15000 [1:29:44<14:17,  5.43it/s, lr=0.000995, step_loss=0.307/27/2023 19:14:34 - INFO - __main__ - train loss is 5.708459727698937\n",
      "Steps:  69%|▋| 10346/15000 [1:29:44<14:25,  5.38it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:34 - INFO - __main__ - train loss is 5.830447025829926\n",
      "Steps:  69%|▋| 10347/15000 [1:29:45<14:20,  5.41it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:34 - INFO - __main__ - train loss is 5.9082537370268255\n",
      "Steps:  69%|▋| 10348/15000 [1:29:45<14:14,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:35 - INFO - __main__ - train loss is 5.911368525819853\n",
      "Steps:  69%|▋| 10349/15000 [1:29:45<14:15,  5.43it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:35 - INFO - __main__ - train loss is 6.048525116639212\n",
      "Steps:  69%|▋| 10350/15000 [1:29:45<14:09,  5.47it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:35 - INFO - __main__ - train loss is 6.077054403023794\n",
      "Steps:  69%|▋| 10351/15000 [1:29:45<14:04,  5.50it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:35 - INFO - __main__ - train loss is 6.099102643551305\n",
      "Steps:  69%|▋| 10352/15000 [1:29:46<14:13,  5.44it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:35 - INFO - __main__ - train loss is 6.525138405384496\n",
      "Steps:  69%|▋| 10353/15000 [1:29:46<14:21,  5.40it/s, lr=0.000995, step_loss=0.407/27/2023 19:14:36 - INFO - __main__ - train loss is 6.707023618044332\n",
      "Steps:  69%|▋| 10354/15000 [1:29:46<14:13,  5.44it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:36 - INFO - __main__ - train loss is 6.723072153748944\n",
      "Steps:  69%|▋| 10355/15000 [1:29:46<14:15,  5.43it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:36 - INFO - __main__ - train loss is 6.724190425360575\n",
      "Steps:  69%|▋| 10356/15000 [1:29:46<14:18,  5.41it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:36 - INFO - __main__ - train loss is 7.085203152382746\n",
      "Steps:  69%|▋| 10357/15000 [1:29:46<14:10,  5.46it/s, lr=0.000995, step_loss=0.307/27/2023 19:14:36 - INFO - __main__ - train loss is 7.102770393947139\n",
      "Steps:  69%|▋| 10358/15000 [1:29:47<14:07,  5.48it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:36 - INFO - __main__ - train loss is 7.263110777596012\n",
      "Steps:  69%|▋| 10359/15000 [1:29:47<14:11,  5.45it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:37 - INFO - __main__ - train loss is 7.264652229845524\n",
      "Steps:  69%|▋| 10360/15000 [1:29:47<14:11,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:37 - INFO - __main__ - train loss is 7.317461803555489\n",
      "Steps:  69%|▋| 10361/15000 [1:29:47<14:11,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:37 - INFO - __main__ - train loss is 7.4169222712516785\n",
      "Steps:  69%|▋| 10362/15000 [1:29:47<14:06,  5.48it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:37 - INFO - __main__ - train loss is 7.419513278407976\n",
      "Steps:  69%|▋| 10363/15000 [1:29:48<14:03,  5.50it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:37 - INFO - __main__ - train loss is 7.423526253318414\n",
      "Steps:  69%|▋| 10364/15000 [1:29:48<14:08,  5.46it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:38 - INFO - __main__ - train loss is 7.472973402356729\n",
      "Steps:  69%|▋| 10365/15000 [1:29:48<14:10,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:38 - INFO - __main__ - train loss is 7.825241889571771\n",
      "Steps:  69%|▋| 10366/15000 [1:29:48<14:06,  5.48it/s, lr=0.000995, step_loss=0.307/27/2023 19:14:38 - INFO - __main__ - train loss is 8.040149669861421\n",
      "Steps:  69%|▋| 10367/15000 [1:29:48<14:05,  5.48it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:38 - INFO - __main__ - train loss is 8.064242265885696\n",
      "Steps:  69%|▋| 10368/15000 [1:29:48<14:01,  5.50it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:38 - INFO - __main__ - train loss is 8.286573104327545\n",
      "Steps:  69%|▋| 10369/15000 [1:29:49<13:59,  5.52it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:38 - INFO - __main__ - train loss is 8.297062935074791\n",
      "Steps:  69%|▋| 10370/15000 [1:29:49<14:20,  5.38it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:39 - INFO - __main__ - train loss is 8.6524132208433\n",
      "Steps:  69%|▋| 10371/15000 [1:29:49<14:13,  5.42it/s, lr=0.000995, step_loss=0.307/27/2023 19:14:39 - INFO - __main__ - train loss is 9.154866548022255\n",
      "Steps:  69%|▋| 10372/15000 [1:29:49<14:08,  5.46it/s, lr=0.000995, step_loss=0.507/27/2023 19:14:39 - INFO - __main__ - train loss is 9.162721268599853\n",
      "Steps:  69%|▋| 10373/15000 [1:29:49<14:07,  5.46it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:39 - INFO - __main__ - train loss is 9.183578982716426\n",
      "Steps:  69%|▋| 10374/15000 [1:29:50<14:03,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:39 - INFO - __main__ - train loss is 9.381836369400844\n",
      "Steps:  69%|▋| 10375/15000 [1:29:50<14:00,  5.50it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:40 - INFO - __main__ - train loss is 9.412048754980788\n",
      "Steps:  69%|▋| 10376/15000 [1:29:50<14:01,  5.50it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:40 - INFO - __main__ - train loss is 9.487121550133452\n",
      "Steps:  69%|▋| 10377/15000 [1:29:50<13:59,  5.51it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:40 - INFO - __main__ - train loss is 9.540470419218764\n",
      "Steps:  69%|▋| 10378/15000 [1:29:50<13:57,  5.52it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:40 - INFO - __main__ - train loss is 9.882539419224486\n",
      "Steps:  69%|▋| 10379/15000 [1:29:50<14:01,  5.49it/s, lr=0.000995, step_loss=0.307/27/2023 19:14:40 - INFO - __main__ - train loss is 10.099184600403532\n",
      "Steps:  69%|▋| 10380/15000 [1:29:51<13:59,  5.50it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:40 - INFO - __main__ - train loss is 10.341455233981833\n",
      "Steps:  69%|▋| 10381/15000 [1:29:51<13:59,  5.50it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:41 - INFO - __main__ - train loss is 10.34321184118744\n",
      "Steps:  69%|▋| 10382/15000 [1:29:51<14:11,  5.43it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:41 - INFO - __main__ - train loss is 10.344719826127402\n",
      "Steps:  69%|▋| 10383/15000 [1:29:51<15:07,  5.09it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:41 - INFO - __main__ - train loss is 10.504101290251128\n",
      "Steps:  69%|▋| 10384/15000 [1:29:51<14:56,  5.15it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:41 - INFO - __main__ - train loss is 10.59568862512242\n",
      "Steps:  69%|▋| 10385/15000 [1:29:52<14:47,  5.20it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:41 - INFO - __main__ - train loss is 10.599271901301108\n",
      "Steps:  69%|▋| 10386/15000 [1:29:52<14:47,  5.20it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:42 - INFO - __main__ - train loss is 10.816647418192588\n",
      "Steps:  69%|▋| 10387/15000 [1:29:52<14:38,  5.25it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:42 - INFO - __main__ - train loss is 10.936301157227717\n",
      "Steps:  69%|▋| 10388/15000 [1:29:52<14:30,  5.30it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:42 - INFO - __main__ - train loss is 11.101485848776065\n",
      "Steps:  69%|▋| 10389/15000 [1:29:52<14:18,  5.37it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:42 - INFO - __main__ - train loss is 11.140794892213307\n",
      "Steps:  69%|▋| 10390/15000 [1:29:53<14:10,  5.42it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:42 - INFO - __main__ - train loss is 11.355607275268994\n",
      "Steps:  69%|▋| 10391/15000 [1:29:53<14:10,  5.42it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:43 - INFO - __main__ - train loss is 11.443224851391278\n",
      "Steps:  69%|▋| 10392/15000 [1:29:53<14:04,  5.46it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:43 - INFO - __main__ - train loss is 11.47460006957408\n",
      "Steps:  69%|▋| 10393/15000 [1:29:53<13:59,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:43 - INFO - __main__ - train loss is 12.032075874856673\n",
      "Steps:  69%|▋| 10394/15000 [1:29:53<13:58,  5.49it/s, lr=0.000995, step_loss=0.507/27/2023 19:14:43 - INFO - __main__ - train loss is 12.037944071809761\n",
      "Steps:  69%|▋| 10395/15000 [1:29:53<13:58,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:43 - INFO - __main__ - train loss is 12.04493479419034\n",
      "Steps:  69%|▋| 10396/15000 [1:29:54<13:58,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:43 - INFO - __main__ - train loss is 12.79471711802762\n",
      "Steps:  69%|▋| 10397/15000 [1:29:54<13:54,  5.51it/s, lr=0.000995, step_loss=0.707/27/2023 19:14:44 - INFO - __main__ - train loss is 12.879131749155931\n",
      "Steps:  69%|▋| 10398/15000 [1:29:54<13:51,  5.53it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:44 - INFO - __main__ - train loss is 13.329774960759096\n",
      "Steps:  69%|▋| 10399/15000 [1:29:54<13:51,  5.53it/s, lr=0.000995, step_loss=0.407/27/2023 19:14:44 - INFO - __main__ - train loss is 13.345985567080788\n",
      "Steps:  69%|▋| 10400/15000 [1:29:54<13:57,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:44 - INFO - __main__ - train loss is 13.381166128325276\n",
      "Steps:  69%|▋| 10401/15000 [1:29:55<14:05,  5.44it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:44 - INFO - __main__ - train loss is 13.436423575389199\n",
      "Steps:  69%|▋| 10402/15000 [1:29:55<13:59,  5.47it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:45 - INFO - __main__ - train loss is 13.452974218758754\n",
      "Steps:  69%|▋| 10403/15000 [1:29:55<13:57,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:45 - INFO - __main__ - train loss is 13.584658998879604\n",
      "Steps:  69%|▋| 10404/15000 [1:29:55<13:59,  5.48it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:45 - INFO - __main__ - train loss is 13.748215485247783\n",
      "Steps:  69%|▋| 10405/15000 [1:29:55<13:55,  5.50it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:45 - INFO - __main__ - train loss is 13.755261843907647\n",
      "Steps:  69%|▋| 10406/15000 [1:29:55<13:57,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:45 - INFO - __main__ - train loss is 13.90526506851893\n",
      "Steps:  69%|▋| 10407/15000 [1:29:56<13:56,  5.49it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:45 - INFO - __main__ - train loss is 13.950889719533734\n",
      "Steps:  69%|▋| 10408/15000 [1:29:56<14:01,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:46 - INFO - __main__ - train loss is 13.95439111709129\n",
      "Steps:  69%|▋| 10409/15000 [1:29:56<14:07,  5.42it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:46 - INFO - __main__ - train loss is 13.969939291360788\n",
      "Steps:  69%|▋| 10410/15000 [1:29:56<14:10,  5.40it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:46 - INFO - __main__ - train loss is 14.201247885706834\n",
      "Steps:  69%|▋| 10411/15000 [1:29:56<14:03,  5.44it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:46 - INFO - __main__ - train loss is 14.656544610741548\n",
      "Steps:  69%|▋| 10412/15000 [1:29:57<14:03,  5.44it/s, lr=0.000995, step_loss=0.407/27/2023 19:14:46 - INFO - __main__ - train loss is 14.665189528721385\n",
      "Steps:  69%|▋| 10413/15000 [1:29:57<14:01,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:47 - INFO - __main__ - train loss is 14.666781080537476\n",
      "Steps:  69%|▋| 10414/15000 [1:29:57<14:08,  5.40it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:47 - INFO - __main__ - train loss is 14.679080081754364\n",
      "Steps:  69%|▋| 10415/15000 [1:29:57<14:02,  5.44it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:47 - INFO - __main__ - train loss is 14.700648517929949\n",
      "Steps:  69%|▋| 10416/15000 [1:29:57<14:00,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:47 - INFO - __main__ - train loss is 15.310580523335375\n",
      "Steps:  69%|▋| 10417/15000 [1:29:57<13:56,  5.48it/s, lr=0.000995, step_loss=0.607/27/2023 19:14:47 - INFO - __main__ - train loss is 15.40200164320413\n",
      "Steps:  69%|▋| 10418/15000 [1:29:58<13:58,  5.47it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:48 - INFO - __main__ - train loss is 15.452738882624544\n",
      "Steps:  69%|▋| 10419/15000 [1:29:58<14:01,  5.44it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:48 - INFO - __main__ - train loss is 15.485403051250614\n",
      "Steps:  69%|▋| 10420/15000 [1:29:58<14:03,  5.43it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:48 - INFO - __main__ - train loss is 15.487516989116557\n",
      "Steps:  69%|▋| 10421/15000 [1:29:58<14:10,  5.38it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:48 - INFO - __main__ - train loss is 15.626871128682978\n",
      "Steps:  69%|▋| 10422/15000 [1:29:58<14:09,  5.39it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:48 - INFO - __main__ - train loss is 15.653196134720929\n",
      "Steps:  69%|▋| 10423/15000 [1:29:59<14:10,  5.38it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:48 - INFO - __main__ - train loss is 16.182252922211774\n",
      "Steps:  69%|▋| 10424/15000 [1:29:59<14:03,  5.43it/s, lr=0.000995, step_loss=0.507/27/2023 19:14:49 - INFO - __main__ - train loss is 16.199250453268178\n",
      "Steps:  70%|▋| 10425/15000 [1:29:59<13:58,  5.46it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:49 - INFO - __main__ - train loss is 16.372584232245572\n",
      "Steps:  70%|▋| 10426/15000 [1:29:59<13:54,  5.48it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:49 - INFO - __main__ - train loss is 16.501013481174596\n",
      "Steps:  70%|▋| 10427/15000 [1:29:59<13:55,  5.47it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:49 - INFO - __main__ - train loss is 16.50242187792901\n",
      "Steps:  70%|▋| 10428/15000 [1:29:59<13:52,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:49 - INFO - __main__ - train loss is 16.61425004119519\n",
      "Steps:  70%|▋| 10429/15000 [1:30:00<14:30,  5.25it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:50 - INFO - __main__ - train loss is 16.61581854010001\n",
      "Steps:  70%|▋| 10430/15000 [1:30:00<14:21,  5.31it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:50 - INFO - __main__ - train loss is 16.688705320004374\n",
      "Steps:  70%|▋| 10431/15000 [1:30:00<14:11,  5.36it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:50 - INFO - __main__ - train loss is 16.857774848584086\n",
      "Steps:  70%|▋| 10432/15000 [1:30:00<14:08,  5.39it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:50 - INFO - __main__ - train loss is 16.891704434994608\n",
      "Steps:  70%|▋| 10433/15000 [1:30:00<14:03,  5.42it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:50 - INFO - __main__ - train loss is 17.461711938027292\n",
      "Steps:  70%|▋| 10434/15000 [1:30:01<14:00,  5.43it/s, lr=0.000995, step_loss=0.507/27/2023 19:14:50 - INFO - __main__ - train loss is 17.563102076295763\n",
      "Steps:  70%|▋| 10435/15000 [1:30:01<14:06,  5.40it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:51 - INFO - __main__ - train loss is 17.58013910287991\n",
      "Steps:  70%|▋| 10436/15000 [1:30:01<14:07,  5.38it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:51 - INFO - __main__ - train loss is 17.73426196211949\n",
      "Steps:  70%|▋| 10437/15000 [1:30:01<14:08,  5.38it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:51 - INFO - __main__ - train loss is 17.82053534919396\n",
      "Steps:  70%|▋| 10438/15000 [1:30:01<14:07,  5.38it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:51 - INFO - __main__ - train loss is 18.21042768890038\n",
      "Steps:  70%|▋| 10439/15000 [1:30:02<14:11,  5.36it/s, lr=0.000995, step_loss=0.307/27/2023 19:14:51 - INFO - __main__ - train loss is 18.257318737450987\n",
      "Steps:  70%|▋| 10440/15000 [1:30:02<14:02,  5.41it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:52 - INFO - __main__ - train loss is 18.49807673925534\n",
      "Steps:  70%|▋| 10441/15000 [1:30:02<14:03,  5.40it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:52 - INFO - __main__ - train loss is 18.549518572632223\n",
      "Steps:  70%|▋| 10442/15000 [1:30:02<13:57,  5.44it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:52 - INFO - __main__ - train loss is 18.615110153798014\n",
      "Steps:  70%|▋| 10443/15000 [1:30:02<14:21,  5.29it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:52 - INFO - __main__ - train loss is 18.853887448552996\n",
      "Steps:  70%|▋| 10444/15000 [1:30:02<14:22,  5.28it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:52 - INFO - __main__ - train loss is 19.016119609121233\n",
      "Steps:  70%|▋| 10445/15000 [1:30:03<14:21,  5.29it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:53 - INFO - __main__ - train loss is 19.08575832331553\n",
      "Steps:  70%|▋| 10446/15000 [1:30:03<14:22,  5.28it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:53 - INFO - __main__ - train loss is 19.12171249696985\n",
      "Steps:  70%|▋| 10447/15000 [1:30:03<14:27,  5.25it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:53 - INFO - __main__ - train loss is 19.410412094090134\n",
      "Steps:  70%|▋| 10448/15000 [1:30:03<14:18,  5.30it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:53 - INFO - __main__ - train loss is 19.427886175457388\n",
      "Steps:  70%|▋| 10449/15000 [1:30:03<14:15,  5.32it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:53 - INFO - __main__ - train loss is 19.456783740315586\n",
      "Steps:  70%|▋| 10450/15000 [1:30:04<14:07,  5.37it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:53 - INFO - __main__ - train loss is 19.471154674421996\n",
      "Steps:  70%|▋| 10451/15000 [1:30:04<14:11,  5.34it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:54 - INFO - __main__ - train loss is 19.674426450859755\n",
      "Steps:  70%|▋| 10452/15000 [1:30:04<14:05,  5.38it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:54 - INFO - __main__ - train loss is 19.903881221543998\n",
      "Steps:  70%|▋| 10453/15000 [1:30:04<14:15,  5.31it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:54 - INFO - __main__ - train loss is 20.00951861543581\n",
      "Steps:  70%|▋| 10454/15000 [1:30:04<14:04,  5.38it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:54 - INFO - __main__ - train loss is 20.23268239898607\n",
      "Steps:  70%|▋| 10455/15000 [1:30:05<13:56,  5.43it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:54 - INFO - __main__ - train loss is 20.26625072909519\n",
      "Steps:  70%|▋| 10456/15000 [1:30:05<13:50,  5.47it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:55 - INFO - __main__ - train loss is 20.297075815033168\n",
      "Steps:  70%|▋| 10457/15000 [1:30:05<13:48,  5.48it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:55 - INFO - __main__ - train loss is 20.347610894124955\n",
      "Steps:  70%|▋| 10458/15000 [1:30:05<13:47,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:55 - INFO - __main__ - train loss is 20.360135048162192\n",
      "Steps:  70%|▋| 10459/15000 [1:30:05<13:44,  5.51it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:55 - INFO - __main__ - train loss is 20.420714944135398\n",
      "Steps:  70%|▋| 10460/15000 [1:30:05<13:41,  5.53it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:55 - INFO - __main__ - train loss is 20.445857245009392\n",
      "Steps:  70%|▋| 10461/15000 [1:30:06<13:47,  5.49it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:55 - INFO - __main__ - train loss is 20.45623017800972\n",
      "Steps:  70%|▋| 10462/15000 [1:30:06<13:45,  5.50it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:56 - INFO - __main__ - train loss is 20.464536857325584\n",
      "Steps:  70%|▋| 10463/15000 [1:30:06<13:47,  5.48it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:56 - INFO - __main__ - train loss is 20.479420842137188\n",
      "Steps:  70%|▋| 10464/15000 [1:30:06<13:52,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:56 - INFO - __main__ - train loss is 20.51226652180776\n",
      "Steps:  70%|▋| 10465/15000 [1:30:06<13:51,  5.45it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:56 - INFO - __main__ - train loss is 20.521363749634475\n",
      "Steps:  70%|▋| 10466/15000 [1:30:07<14:02,  5.38it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:56 - INFO - __main__ - train loss is 20.543475420679897\n",
      "Steps:  70%|▋| 10467/15000 [1:30:07<13:54,  5.43it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:57 - INFO - __main__ - train loss is 20.568804908078164\n",
      "Steps:  70%|▋| 10468/15000 [1:30:07<13:49,  5.46it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:57 - INFO - __main__ - train loss is 20.716995659749955\n",
      "Steps:  70%|▋| 10469/15000 [1:30:07<13:45,  5.49it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:57 - INFO - __main__ - train loss is 20.74897975055501\n",
      "Steps:  70%|▋| 10470/15000 [1:30:07<13:42,  5.51it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:57 - INFO - __main__ - train loss is 20.77186872018501\n",
      "Steps:  70%|▋| 10471/15000 [1:30:07<13:49,  5.46it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:57 - INFO - __main__ - train loss is 20.899959712754935\n",
      "Steps:  70%|▋| 10472/15000 [1:30:08<13:57,  5.41it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:57 - INFO - __main__ - train loss is 20.927888329606503\n",
      "Steps:  70%|▋| 10473/15000 [1:30:08<13:52,  5.44it/s, lr=0.000995, step_loss=0.007/27/2023 19:14:58 - INFO - __main__ - train loss is 21.17176344571635\n",
      "Steps:  70%|▋| 10474/15000 [1:30:08<13:56,  5.41it/s, lr=0.000995, step_loss=0.207/27/2023 19:14:58 - INFO - __main__ - train loss is 21.344117622356862\n",
      "Steps:  70%|▋| 10475/15000 [1:30:08<14:07,  5.34it/s, lr=0.000995, step_loss=0.107/27/2023 19:14:58 - INFO - __main__ - train loss is 21.34582192765083\n",
      "Steps:  70%|▋| 10476/15000 [1:30:08<14:05,  5.35it/s, lr=0.000994, step_loss=0.007/27/2023 19:14:58 - INFO - __main__ - train loss is 21.878573607071303\n",
      "Steps:  70%|▋| 10477/15000 [1:30:09<14:22,  5.24it/s, lr=0.000994, step_loss=0.507/27/2023 19:14:58 - INFO - __main__ - train loss is 21.970506157143973\n",
      "Steps:  70%|▋| 10478/15000 [1:30:09<14:22,  5.24it/s, lr=0.000994, step_loss=0.007/27/2023 19:14:59 - INFO - __main__ - train loss is 22.59694477485027\n",
      "Steps:  70%|▋| 10479/15000 [1:30:09<14:15,  5.29it/s, lr=0.000994, step_loss=0.607/27/2023 19:14:59 - INFO - __main__ - train loss is 22.612895432277583\n",
      "Steps:  70%|▋| 10480/15000 [1:30:09<14:06,  5.34it/s, lr=0.000994, step_loss=0.007/27/2023 19:14:59 - INFO - __main__ - train loss is 22.74243870691862\n",
      "Steps:  70%|▋| 10481/15000 [1:30:09<13:56,  5.40it/s, lr=0.000994, step_loss=0.107/27/2023 19:14:59 - INFO - __main__ - train loss is 22.879290464683436\n",
      "Steps:  70%|▋| 10482/15000 [1:30:09<13:48,  5.45it/s, lr=0.000994, step_loss=0.107/27/2023 19:14:59 - INFO - __main__ - train loss is 23.005672308965586\n",
      "Steps:  70%|▋| 10483/15000 [1:30:10<13:53,  5.42it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:00 - INFO - __main__ - train loss is 23.059591791941784\n",
      "Steps:  70%|▋| 10484/15000 [1:30:10<13:58,  5.39it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:00 - INFO - __main__ - train loss is 23.06130978791043\n",
      "Steps:  70%|▋| 10485/15000 [1:30:10<13:51,  5.43it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:00 - INFO - __main__ - train loss is 23.453328523319215\n",
      "Steps:  70%|▋| 10486/15000 [1:30:10<13:52,  5.42it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:00 - INFO - __main__ - train loss is 23.713749292772263\n",
      "Steps:  70%|▋| 10487/15000 [1:30:10<13:46,  5.46it/s, lr=0.000994, step_loss=0.207/27/2023 19:15:00 - INFO - __main__ - train loss is 23.799879122059792\n",
      "Steps:  70%|▋| 10488/15000 [1:30:11<13:41,  5.49it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:00 - INFO - __main__ - train loss is 23.819091462995857\n",
      "Steps:  70%|▋| 10489/15000 [1:30:11<13:54,  5.41it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:01 - INFO - __main__ - train loss is 24.07255479088053\n",
      "Steps:  70%|▋| 10490/15000 [1:30:11<13:59,  5.37it/s, lr=0.000994, step_loss=0.207/27/2023 19:15:01 - INFO - __main__ - train loss is 24.40580722084269\n",
      "Steps:  70%|▋| 10491/15000 [1:30:11<13:58,  5.38it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:01 - INFO - __main__ - train loss is 25.138766610529274\n",
      "Steps:  70%|▋| 10492/15000 [1:30:11<14:07,  5.32it/s, lr=0.000994, step_loss=0.707/27/2023 19:15:01 - INFO - __main__ - train loss is 25.146436107810587\n",
      "Steps:  70%|▋| 10493/15000 [1:30:12<14:11,  5.29it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:01 - INFO - __main__ - train loss is 25.174569386523217\n",
      "Steps:  70%|▋| 10494/15000 [1:30:12<14:09,  5.30it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:02 - INFO - __main__ - train loss is 25.26782366959378\n",
      "Steps:  70%|▋| 10495/15000 [1:30:12<14:08,  5.31it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:02 - INFO - __main__ - train loss is 25.275493828114122\n",
      "Steps:  70%|▋| 10496/15000 [1:30:12<13:58,  5.37it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:02 - INFO - __main__ - train loss is 25.28693457180634\n",
      "Steps:  70%|▋| 10497/15000 [1:30:12<13:55,  5.39it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:02 - INFO - __main__ - train loss is 25.289042674936354\n",
      "Steps:  70%|▋| 10498/15000 [1:30:12<13:51,  5.41it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:02 - INFO - __main__ - train loss is 25.376036413945258\n",
      "Steps:  70%|▋| 10499/15000 [1:30:13<13:48,  5.43it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:03 - INFO - __main__ - train loss is 25.50215555075556\n",
      "Steps:  70%|▋| 10500/15000 [1:30:13<13:46,  5.44it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:03 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-10500\n",
      "07/27/2023 19:15:03 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:15:03,114] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:15:03,118] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-10500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:15:03,118] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-10500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:15:03,127] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-10500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:15:03,128] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-10500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:15:03,138] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-10500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:15:03,138] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-10500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:15:03,138] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:15:03 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-10500/pytorch_model\n",
      "07/27/2023 19:15:03 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-10500/scheduler.bin\n",
      "07/27/2023 19:15:03 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-10500/random_states_0.pkl\n",
      "07/27/2023 19:15:03 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-10500\n",
      "Steps:  70%|▋| 10500/15000 [1:30:13<13:46,  5.44it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:03 - INFO - __main__ - train loss is 25.52246985118836\n",
      "Steps:  70%|▋| 10501/15000 [1:30:13<14:22,  5.22it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:03 - INFO - __main__ - train loss is 25.5352804902941\n",
      "Steps:  70%|▋| 10502/15000 [1:30:13<14:09,  5.29it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:03 - INFO - __main__ - train loss is 25.537283855956048\n",
      "Steps:  70%|▋| 10503/15000 [1:30:13<14:03,  5.33it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:03 - INFO - __main__ - train loss is 25.627764027100056\n",
      "Steps:  70%|▋| 10504/15000 [1:30:14<13:57,  5.37it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:03 - INFO - __main__ - train loss is 25.656291305553168\n",
      "Steps:  70%|▋| 10505/15000 [1:30:14<13:52,  5.40it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:04 - INFO - __main__ - train loss is 25.840911656152457\n",
      "Steps:  70%|▋| 10506/15000 [1:30:14<13:48,  5.42it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:04 - INFO - __main__ - train loss is 25.84208954870701\n",
      "Steps:  70%|▋| 10507/15000 [1:30:14<13:47,  5.43it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:04 - INFO - __main__ - train loss is 25.86260907165706\n",
      "Steps:  70%|▋| 10508/15000 [1:30:14<13:45,  5.44it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:04 - INFO - __main__ - train loss is 25.924476506188512\n",
      "Steps:  70%|▋| 10509/15000 [1:30:15<13:47,  5.43it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:04 - INFO - __main__ - train loss is 25.932879062369466\n",
      "Steps:  70%|▋| 10510/15000 [1:30:15<13:45,  5.44it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:05 - INFO - __main__ - train loss is 25.99099368788302\n",
      "Steps:  70%|▋| 10511/15000 [1:30:15<13:47,  5.42it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:05 - INFO - __main__ - train loss is 26.03842324949801\n",
      "Steps:  70%|▋| 10512/15000 [1:30:15<13:48,  5.42it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:05 - INFO - __main__ - train loss is 26.135902056470513\n",
      "Steps:  70%|▋| 10513/15000 [1:30:15<13:50,  5.40it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:05 - INFO - __main__ - train loss is 26.25230243243277\n",
      "Steps:  70%|▋| 10514/15000 [1:30:15<13:52,  5.39it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:05 - INFO - __main__ - train loss is 26.552840257063508\n",
      "Steps:  70%|▋| 10515/15000 [1:30:16<13:47,  5.42it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:05 - INFO - __main__ - train loss is 26.554882935015485\n",
      "Steps:  70%|▋| 10516/15000 [1:30:16<13:46,  5.42it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:06 - INFO - __main__ - train loss is 26.608930500922725\n",
      "Steps:  70%|▋| 10517/15000 [1:30:16<13:40,  5.46it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:06 - INFO - __main__ - train loss is 26.61191768036224\n",
      "Steps:  70%|▋| 10518/15000 [1:30:16<13:39,  5.47it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:06 - INFO - __main__ - train loss is 26.67610881314613\n",
      "Steps:  70%|▋| 10519/15000 [1:30:16<13:43,  5.44it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:06 - INFO - __main__ - train loss is 26.893798789242283\n",
      "Steps:  70%|▋| 10520/15000 [1:30:17<13:49,  5.40it/s, lr=0.000994, step_loss=0.207/27/2023 19:15:06 - INFO - __main__ - train loss is 27.04619528935291\n",
      "Steps:  70%|▋| 10521/15000 [1:30:17<13:50,  5.39it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:07 - INFO - __main__ - train loss is 27.482603838900104\n",
      "Steps:  70%|▋| 10522/15000 [1:30:17<13:50,  5.39it/s, lr=0.000994, step_loss=0.407/27/2023 19:15:07 - INFO - __main__ - train loss is 27.6795755981002\n",
      "Steps:  70%|▋| 10523/15000 [1:30:17<13:50,  5.39it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:07 - INFO - __main__ - train loss is 27.75253159389831\n",
      "Steps:  70%|▋| 10524/15000 [1:30:17<13:52,  5.38it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:07 - INFO - __main__ - train loss is 28.20122784958221\n",
      "Steps:  70%|▋| 10525/15000 [1:30:17<13:50,  5.39it/s, lr=0.000994, step_loss=0.407/27/2023 19:15:07 - INFO - __main__ - train loss is 28.45484200702049\n",
      "Steps:  70%|▋| 10526/15000 [1:30:18<13:48,  5.40it/s, lr=0.000994, step_loss=0.207/27/2023 19:15:08 - INFO - __main__ - train loss is 28.457802540855482\n",
      "Steps:  70%|▋| 10527/15000 [1:30:18<13:41,  5.44it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:08 - INFO - __main__ - train loss is 28.553583964006975\n",
      "Steps:  70%|▋| 10528/15000 [1:30:18<13:38,  5.46it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:08 - INFO - __main__ - train loss is 28.563601911300793\n",
      "Steps:  70%|▋| 10529/15000 [1:30:18<13:35,  5.48it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:08 - INFO - __main__ - train loss is 28.574636798584834\n",
      "Steps:  70%|▋| 10530/15000 [1:30:18<13:37,  5.47it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:08 - INFO - __main__ - train loss is 28.590197916375473\n",
      "Steps:  70%|▋| 10531/15000 [1:30:19<13:33,  5.49it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:08 - INFO - __main__ - train loss is 28.913010473595932\n",
      "Steps:  70%|▋| 10532/15000 [1:30:19<13:32,  5.50it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:09 - INFO - __main__ - train loss is 28.941374733345583\n",
      "Steps:  70%|▋| 10533/15000 [1:30:19<13:37,  5.46it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:09 - INFO - __main__ - train loss is 28.948393459198996\n",
      "Steps:  70%|▋| 10534/15000 [1:30:19<13:51,  5.37it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:09 - INFO - __main__ - train loss is 28.952125009382144\n",
      "Steps:  70%|▋| 10535/15000 [1:30:19<14:55,  4.98it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:09 - INFO - __main__ - train loss is 29.0101364555303\n",
      "Steps:  70%|▋| 10536/15000 [1:30:20<15:51,  4.69it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:09 - INFO - __main__ - train loss is 29.033087350660935\n",
      "Steps:  70%|▋| 10537/15000 [1:30:20<15:23,  4.83it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:10 - INFO - __main__ - train loss is 29.052049590507522\n",
      "Steps:  70%|▋| 10538/15000 [1:30:20<15:12,  4.89it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:10 - INFO - __main__ - train loss is 29.11348512978293\n",
      "Steps:  70%|▋| 10539/15000 [1:30:20<14:42,  5.05it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:10 - INFO - __main__ - train loss is 29.298248114297166\n",
      "Steps:  70%|▋| 10540/15000 [1:30:20<14:22,  5.17it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:10 - INFO - __main__ - train loss is 29.451799663016573\n",
      "Steps:  70%|▋| 10541/15000 [1:30:21<14:10,  5.24it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:10 - INFO - __main__ - train loss is 29.49357128352858\n",
      "Steps:  70%|▋| 10542/15000 [1:30:21<13:56,  5.33it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:11 - INFO - __main__ - train loss is 29.596822249004617\n",
      "Steps:  70%|▋| 10543/15000 [1:30:21<13:52,  5.35it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:11 - INFO - __main__ - train loss is 29.636148305842653\n",
      "Steps:  70%|▋| 10544/15000 [1:30:21<13:51,  5.36it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:11 - INFO - __main__ - train loss is 29.662918858462945\n",
      "Steps:  70%|▋| 10545/15000 [1:30:21<13:45,  5.40it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:11 - INFO - __main__ - train loss is 29.665674693649635\n",
      "Steps:  70%|▋| 10546/15000 [1:30:21<13:38,  5.44it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:11 - INFO - __main__ - train loss is 30.102942324941978\n",
      "Steps:  70%|▋| 10547/15000 [1:30:22<13:45,  5.39it/s, lr=0.000994, step_loss=0.407/27/2023 19:15:12 - INFO - __main__ - train loss is 30.177335940068588\n",
      "Steps:  70%|▋| 10548/15000 [1:30:22<13:54,  5.34it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:12 - INFO - __main__ - train loss is 30.17863574938383\n",
      "Steps:  70%|▋| 10549/15000 [1:30:22<13:54,  5.34it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:12 - INFO - __main__ - train loss is 30.339795592590235\n",
      "Steps:  70%|▋| 10550/15000 [1:30:22<13:52,  5.34it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:12 - INFO - __main__ - train loss is 30.391447550966404\n",
      "Steps:  70%|▋| 10551/15000 [1:30:22<13:52,  5.34it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:12 - INFO - __main__ - train loss is 30.633867076947354\n",
      "Steps:  70%|▋| 10552/15000 [1:30:23<13:58,  5.31it/s, lr=0.000994, step_loss=0.207/27/2023 19:15:12 - INFO - __main__ - train loss is 30.826225928380154\n",
      "Steps:  70%|▋| 10553/15000 [1:30:23<13:59,  5.30it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:13 - INFO - __main__ - train loss is 31.41785674483981\n",
      "Steps:  70%|▋| 10554/15000 [1:30:23<13:53,  5.34it/s, lr=0.000994, step_loss=0.507/27/2023 19:15:13 - INFO - __main__ - train loss is 31.966433815076016\n",
      "Steps:  70%|▋| 10555/15000 [1:30:23<13:53,  5.33it/s, lr=0.000994, step_loss=0.507/27/2023 19:15:13 - INFO - __main__ - train loss is 32.29940687806811\n",
      "Steps:  70%|▋| 10556/15000 [1:30:23<13:51,  5.35it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:13 - INFO - __main__ - train loss is 32.479427687241696\n",
      "Steps:  70%|▋| 10557/15000 [1:30:24<13:49,  5.35it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:13 - INFO - __main__ - train loss is 32.61231221945491\n",
      "Steps:  70%|▋| 10558/15000 [1:30:24<13:46,  5.38it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:14 - INFO - __main__ - train loss is 32.763596377684735\n",
      "Steps:  70%|▋| 10559/15000 [1:30:24<13:45,  5.38it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:14 - INFO - __main__ - train loss is 32.77079251117539\n",
      "Steps:  70%|▋| 10560/15000 [1:30:24<13:39,  5.42it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:14 - INFO - __main__ - train loss is 32.788944083149545\n",
      "Steps:  70%|▋| 10561/15000 [1:30:24<13:42,  5.39it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:14 - INFO - __main__ - train loss is 32.90784739970695\n",
      "Steps:  70%|▋| 10562/15000 [1:30:24<13:35,  5.44it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:14 - INFO - __main__ - train loss is 33.06507464766037\n",
      "Steps:  70%|▋| 10563/15000 [1:30:25<13:30,  5.47it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:14 - INFO - __main__ - train loss is 33.09364674880635\n",
      "Steps:  70%|▋| 10564/15000 [1:30:25<13:26,  5.50it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:15 - INFO - __main__ - train loss is 33.517364843632095\n",
      "Steps:  70%|▋| 10565/15000 [1:30:25<13:27,  5.49it/s, lr=0.000994, step_loss=0.407/27/2023 19:15:15 - INFO - __main__ - train loss is 33.930611177231185\n",
      "Steps:  70%|▋| 10566/15000 [1:30:25<13:24,  5.51it/s, lr=0.000994, step_loss=0.407/27/2023 19:15:15 - INFO - __main__ - train loss is 34.23927698924672\n",
      "Steps:  70%|▋| 10567/15000 [1:30:25<13:22,  5.52it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:15 - INFO - __main__ - train loss is 34.25958829082083\n",
      "Steps:  70%|▋| 10568/15000 [1:30:26<13:22,  5.52it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:15 - INFO - __main__ - train loss is 34.42764296091627\n",
      "Steps:  70%|▋| 10569/15000 [1:30:26<13:34,  5.44it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:16 - INFO - __main__ - train loss is 34.42991740943398\n",
      "Steps:  70%|▋| 10570/15000 [1:30:26<13:35,  5.43it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:16 - INFO - __main__ - train loss is 34.61835874558892\n",
      "Steps:  70%|▋| 10571/15000 [1:30:26<13:29,  5.47it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:16 - INFO - __main__ - train loss is 34.626374544925056\n",
      "Steps:  70%|▋| 10572/15000 [1:30:26<13:25,  5.50it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:16 - INFO - __main__ - train loss is 34.62987877649721\n",
      "Steps:  70%|▋| 10573/15000 [1:30:26<13:23,  5.51it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:16 - INFO - __main__ - train loss is 34.64359338989016\n",
      "Steps:  70%|▋| 10574/15000 [1:30:27<13:22,  5.52it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:16 - INFO - __main__ - train loss is 34.663004530943\n",
      "Steps:  70%|▋| 10575/15000 [1:30:27<13:22,  5.51it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:17 - INFO - __main__ - train loss is 35.13826034811791\n",
      "Steps:  71%|▋| 10576/15000 [1:30:27<13:20,  5.53it/s, lr=0.000994, step_loss=0.407/27/2023 19:15:17 - INFO - __main__ - train loss is 35.242550647235475\n",
      "Steps:  71%|▋| 10577/15000 [1:30:27<13:18,  5.54it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:17 - INFO - __main__ - train loss is 35.309285795665346\n",
      "Steps:  71%|▋| 10578/15000 [1:30:27<13:19,  5.53it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:17 - INFO - __main__ - train loss is 35.69851711986121\n",
      "Steps:  71%|▋| 10579/15000 [1:30:28<13:20,  5.53it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:17 - INFO - __main__ - train loss is 35.752213420695625\n",
      "Steps:  71%|▋| 10580/15000 [1:30:28<13:18,  5.53it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:18 - INFO - __main__ - train loss is 35.85421780718025\n",
      "Steps:  71%|▋| 10581/15000 [1:30:28<13:19,  5.53it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:18 - INFO - __main__ - train loss is 36.200456360704266\n",
      "Steps:  71%|▋| 10582/15000 [1:30:28<13:25,  5.48it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:18 - INFO - __main__ - train loss is 36.77852414024528\n",
      "Steps:  71%|▋| 10583/15000 [1:30:28<13:29,  5.46it/s, lr=0.000994, step_loss=0.507/27/2023 19:15:18 - INFO - __main__ - train loss is 37.388481954461895\n",
      "Steps:  71%|▋| 10584/15000 [1:30:28<13:26,  5.47it/s, lr=0.000994, step_loss=0.607/27/2023 19:15:18 - INFO - __main__ - train loss is 37.3919875981519\n",
      "Steps:  71%|▋| 10585/15000 [1:30:29<13:23,  5.49it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:18 - INFO - __main__ - train loss is 37.39823696541134\n",
      "Steps:  71%|▋| 10586/15000 [1:30:29<13:22,  5.50it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:19 - INFO - __main__ - train loss is 37.412478660815395\n",
      "Steps:  71%|▋| 10587/15000 [1:30:29<13:19,  5.52it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:19 - INFO - __main__ - train loss is 37.63567592727486\n",
      "Steps:  71%|▋| 10588/15000 [1:30:29<13:27,  5.47it/s, lr=0.000994, step_loss=0.207/27/2023 19:15:19 - INFO - __main__ - train loss is 37.7916385732824\n",
      "Steps:  71%|▋| 10589/15000 [1:30:29<13:36,  5.40it/s, lr=0.000994, step_loss=0.107/27/2023 19:15:19 - INFO - __main__ - train loss is 37.8139991738135\n",
      "Steps:  71%|▋| 10590/15000 [1:30:30<13:38,  5.39it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:19 - INFO - __main__ - train loss is 38.113523481064476\n",
      "Steps:  71%|▋| 10591/15000 [1:30:30<13:31,  5.43it/s, lr=0.000994, step_loss=0.307/27/2023 19:15:20 - INFO - __main__ - train loss is 38.14108752424363\n",
      "Steps:  71%|▋| 10592/15000 [1:30:30<13:32,  5.42it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:20 - INFO - __main__ - train loss is 38.14246073493268\n",
      "Steps:  71%|▋| 10593/15000 [1:30:30<13:26,  5.46it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:20 - INFO - __main__ - train loss is 38.42873188981321\n",
      "Steps:  71%|▋| 10594/15000 [1:30:30<13:23,  5.48it/s, lr=0.000994, step_loss=0.207/27/2023 19:15:20 - INFO - __main__ - train loss is 38.4327864338411\n",
      "Steps:  71%|▋| 10595/15000 [1:30:30<13:25,  5.47it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:20 - INFO - __main__ - train loss is 38.435609895619564\n",
      "Steps:  71%|▋| 10596/15000 [1:30:31<13:22,  5.49it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:21 - INFO - __main__ - train loss is 38.43860920344014\n",
      "Steps:  71%|▋| 10597/15000 [1:30:31<13:25,  5.47it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:21 - INFO - __main__ - train loss is 38.47646737669129\n",
      "Steps:  71%|▋| 10598/15000 [1:30:31<13:22,  5.49it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:21 - INFO - __main__ - train loss is 38.492532502976246\n",
      "Steps:  71%|▋| 10599/15000 [1:30:31<13:19,  5.51it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:21 - INFO - __main__ - train loss is 38.51463561702985\n",
      "Steps:  71%|▋| 10600/15000 [1:30:31<13:18,  5.51it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:21 - INFO - __main__ - train loss is 38.54194386128802\n",
      "Steps:  71%|▋| 10601/15000 [1:30:32<13:16,  5.52it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:21 - INFO - __main__ - train loss is 38.54525305784773\n",
      "Steps:  71%|▋| 10602/15000 [1:30:32<13:14,  5.53it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:22 - INFO - __main__ - train loss is 38.547476138104685\n",
      "Steps:  71%|▋| 10603/15000 [1:30:32<13:15,  5.53it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:22 - INFO - __main__ - train loss is 38.54971742245834\n",
      "Steps:  71%|▋| 10604/15000 [1:30:32<13:16,  5.52it/s, lr=0.000994, step_loss=0.007/27/2023 19:15:22 - INFO - __main__ - train loss is 39.03160351130646\n",
      "Steps:  71%|▋| 10605/15000 [1:30:33<19:00,  3.85it/s, lr=0.000994, step_loss=0.407/27/2023 19:15:23 - INFO - __main__ - Per validation step average loss is 0.004594268277287483\n",
      "07/27/2023 19:15:23 - INFO - __main__ - Cumulative validation average loss is 0.004594268277287483\n",
      "07/27/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.0077962069772183895\n",
      "07/27/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.012390475254505873\n",
      "07/27/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.001956280553713441\n",
      "07/27/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.014346755808219314\n",
      "07/27/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.11368727684020996\n",
      "07/27/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.12803403264842927\n",
      "07/27/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.005135593004524708\n",
      "07/27/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 0.13316962565295398\n",
      "07/27/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.012999188154935837\n",
      "07/27/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 0.14616881380788982\n",
      "07/27/2023 19:15:26 - INFO - __main__ - Per validation step average loss is 0.009613020345568657\n",
      "07/27/2023 19:15:26 - INFO - __main__ - Cumulative validation average loss is 0.15578183415345848\n",
      "07/27/2023 19:15:26 - INFO - __main__ - Per validation step average loss is 0.0509769506752491\n",
      "07/27/2023 19:15:26 - INFO - __main__ - Cumulative validation average loss is 0.20675878482870758\n",
      "07/27/2023 19:15:27 - INFO - __main__ - Per validation step average loss is 0.26381224393844604\n",
      "07/27/2023 19:15:27 - INFO - __main__ - Cumulative validation average loss is 0.4705710287671536\n",
      "07/27/2023 19:15:27 - INFO - __main__ - Per validation step average loss is 0.1872287392616272\n",
      "07/27/2023 19:15:27 - INFO - __main__ - Cumulative validation average loss is 0.6577997680287808\n",
      "07/27/2023 19:15:27 - INFO - __main__ - Per validation step average loss is 0.004842295311391354\n",
      "07/27/2023 19:15:27 - INFO - __main__ - Cumulative validation average loss is 0.6626420633401722\n",
      "07/27/2023 19:15:28 - INFO - __main__ - Per validation step average loss is 0.35445111989974976\n",
      "07/27/2023 19:15:28 - INFO - __main__ - Cumulative validation average loss is 1.017093183239922\n",
      "07/27/2023 19:15:28 - INFO - __main__ - Per validation step average loss is 0.07857346534729004\n",
      "07/27/2023 19:15:28 - INFO - __main__ - Cumulative validation average loss is 1.095666648587212\n",
      "07/27/2023 19:15:29 - INFO - __main__ - Per validation step average loss is 0.08306354284286499\n",
      "07/27/2023 19:15:29 - INFO - __main__ - Cumulative validation average loss is 1.178730191430077\n",
      "07/27/2023 19:15:29 - INFO - __main__ - Per validation step average loss is 0.47464048862457275\n",
      "07/27/2023 19:15:29 - INFO - __main__ - Cumulative validation average loss is 1.6533706800546497\n",
      "07/27/2023 19:15:29 - INFO - __main__ - Per validation step average loss is 0.3429502546787262\n",
      "07/27/2023 19:15:29 - INFO - __main__ - Cumulative validation average loss is 1.996320934733376\n",
      "07/27/2023 19:15:30 - INFO - __main__ - Per validation step average loss is 0.021856553852558136\n",
      "07/27/2023 19:15:30 - INFO - __main__ - Cumulative validation average loss is 2.018177488585934\n",
      "07/27/2023 19:15:30 - INFO - __main__ - Per validation step average loss is 0.007839287631213665\n",
      "07/27/2023 19:15:30 - INFO - __main__ - Cumulative validation average loss is 2.0260167762171477\n",
      "07/27/2023 19:15:31 - INFO - __main__ - Per validation step average loss is 0.0043649375438690186\n",
      "07/27/2023 19:15:31 - INFO - __main__ - Cumulative validation average loss is 2.0303817137610167\n",
      "07/27/2023 19:15:31 - INFO - __main__ - Per validation step average loss is 0.2706611156463623\n",
      "07/27/2023 19:15:31 - INFO - __main__ - Cumulative validation average loss is 2.301042829407379\n",
      "07/27/2023 19:15:32 - INFO - __main__ - Per validation step average loss is 0.018103614449501038\n",
      "07/27/2023 19:15:32 - INFO - __main__ - Cumulative validation average loss is 2.31914644385688\n",
      "07/27/2023 19:15:32 - INFO - __main__ - Per validation step average loss is 0.07273189723491669\n",
      "07/27/2023 19:15:32 - INFO - __main__ - Cumulative validation average loss is 2.3918783410917968\n",
      "07/27/2023 19:15:32 - INFO - __main__ - Per validation step average loss is 0.015947476029396057\n",
      "07/27/2023 19:15:32 - INFO - __main__ - Cumulative validation average loss is 2.407825817121193\n",
      "07/27/2023 19:15:33 - INFO - __main__ - Per validation step average loss is 0.6777531504631042\n",
      "07/27/2023 19:15:33 - INFO - __main__ - Cumulative validation average loss is 3.085578967584297\n",
      "07/27/2023 19:15:33 - INFO - __main__ - Per validation step average loss is 0.003903547301888466\n",
      "07/27/2023 19:15:33 - INFO - __main__ - Cumulative validation average loss is 3.0894825148861855\n",
      "07/27/2023 19:15:34 - INFO - __main__ - Per validation step average loss is 0.07306690514087677\n",
      "07/27/2023 19:15:34 - INFO - __main__ - Cumulative validation average loss is 3.1625494200270623\n",
      "07/27/2023 19:15:34 - INFO - __main__ - Per validation step average loss is 0.012843186035752296\n",
      "07/27/2023 19:15:34 - INFO - __main__ - Cumulative validation average loss is 3.1753926060628146\n",
      "07/27/2023 19:15:34 - INFO - __main__ - Per validation step average loss is 0.030480852350592613\n",
      "07/27/2023 19:15:34 - INFO - __main__ - Cumulative validation average loss is 3.205873458413407\n",
      "07/27/2023 19:15:35 - INFO - __main__ - Per validation step average loss is 0.11609028279781342\n",
      "07/27/2023 19:15:35 - INFO - __main__ - Cumulative validation average loss is 3.3219637412112206\n",
      "07/27/2023 19:15:35 - INFO - __main__ - Per validation step average loss is 0.002425943035632372\n",
      "07/27/2023 19:15:35 - INFO - __main__ - Cumulative validation average loss is 3.324389684246853\n",
      "07/27/2023 19:15:36 - INFO - __main__ - Per validation step average loss is 0.008302424103021622\n",
      "07/27/2023 19:15:36 - INFO - __main__ - Cumulative validation average loss is 3.3326921083498746\n",
      "07/27/2023 19:15:36 - INFO - __main__ - Per validation step average loss is 0.040599361062049866\n",
      "07/27/2023 19:15:36 - INFO - __main__ - Cumulative validation average loss is 3.3732914694119245\n",
      "07/27/2023 19:15:37 - INFO - __main__ - Per validation step average loss is 0.0015019437996670604\n",
      "07/27/2023 19:15:37 - INFO - __main__ - Cumulative validation average loss is 3.3747934132115915\n",
      "07/27/2023 19:15:37 - INFO - __main__ - Per validation step average loss is 0.2860797345638275\n",
      "07/27/2023 19:15:37 - INFO - __main__ - Cumulative validation average loss is 3.660873147775419\n",
      "07/27/2023 19:15:37 - INFO - __main__ - Per validation step average loss is 0.5212260484695435\n",
      "07/27/2023 19:15:37 - INFO - __main__ - Cumulative validation average loss is 4.1820991962449625\n",
      "07/27/2023 19:15:38 - INFO - __main__ - Per validation step average loss is 0.07622574269771576\n",
      "07/27/2023 19:15:38 - INFO - __main__ - Cumulative validation average loss is 4.258324938942678\n",
      "07/27/2023 19:15:38 - INFO - __main__ - Per validation step average loss is 0.17284715175628662\n",
      "07/27/2023 19:15:38 - INFO - __main__ - Cumulative validation average loss is 4.431172090698965\n",
      "07/27/2023 19:15:39 - INFO - __main__ - Per validation step average loss is 0.23771081864833832\n",
      "07/27/2023 19:15:39 - INFO - __main__ - Cumulative validation average loss is 4.668882909347303\n",
      "07/27/2023 19:15:39 - INFO - __main__ - Per validation step average loss is 0.3935287594795227\n",
      "07/27/2023 19:15:39 - INFO - __main__ - Cumulative validation average loss is 5.062411668826826\n",
      "07/27/2023 19:15:39 - INFO - __main__ - Per validation step average loss is 0.2248222976922989\n",
      "07/27/2023 19:15:39 - INFO - __main__ - Cumulative validation average loss is 5.287233966519125\n",
      "07/27/2023 19:15:40 - INFO - __main__ - Per validation step average loss is 0.12610340118408203\n",
      "07/27/2023 19:15:40 - INFO - __main__ - Cumulative validation average loss is 5.413337367703207\n",
      "07/27/2023 19:15:40 - INFO - __main__ - Per validation step average loss is 0.2784377336502075\n",
      "07/27/2023 19:15:40 - INFO - __main__ - Cumulative validation average loss is 5.691775101353414\n",
      "07/27/2023 19:15:41 - INFO - __main__ - Per validation step average loss is 0.08242001384496689\n",
      "07/27/2023 19:15:41 - INFO - __main__ - Cumulative validation average loss is 5.774195115198381\n",
      "07/27/2023 19:15:41 - INFO - __main__ - Per validation step average loss is 0.011171432211995125\n",
      "07/27/2023 19:15:41 - INFO - __main__ - Cumulative validation average loss is 5.785366547410376\n",
      "07/27/2023 19:15:41 - INFO - __main__ - Per validation step average loss is 0.001864102785475552\n",
      "07/27/2023 19:15:41 - INFO - __main__ - Cumulative validation average loss is 5.787230650195852\n",
      "07/27/2023 19:15:42 - INFO - __main__ - Per validation step average loss is 0.008385049179196358\n",
      "07/27/2023 19:15:42 - INFO - __main__ - Cumulative validation average loss is 5.795615699375048\n",
      "07/27/2023 19:15:42 - INFO - __main__ - Per validation step average loss is 0.03949685022234917\n",
      "07/27/2023 19:15:42 - INFO - __main__ - Cumulative validation average loss is 5.8351125495973974\n",
      "07/27/2023 19:15:43 - INFO - __main__ - Per validation step average loss is 0.2658855617046356\n",
      "07/27/2023 19:15:43 - INFO - __main__ - Cumulative validation average loss is 6.100998111302033\n",
      "07/27/2023 19:15:43 - INFO - __main__ - Per validation step average loss is 0.13799914717674255\n",
      "07/27/2023 19:15:43 - INFO - __main__ - Cumulative validation average loss is 6.238997258478776\n",
      "07/27/2023 19:15:44 - INFO - __main__ - Per validation step average loss is 0.0033708710689097643\n",
      "07/27/2023 19:15:44 - INFO - __main__ - Cumulative validation average loss is 6.242368129547685\n",
      "07/27/2023 19:15:44 - INFO - __main__ - Per validation step average loss is 0.0028572692535817623\n",
      "07/27/2023 19:15:44 - INFO - __main__ - Cumulative validation average loss is 6.245225398801267\n",
      "07/27/2023 19:15:44 - INFO - __main__ - Per validation step average loss is 0.26440954208374023\n",
      "07/27/2023 19:15:44 - INFO - __main__ - Cumulative validation average loss is 6.509634940885007\n",
      "07/27/2023 19:15:45 - INFO - __main__ - Per validation step average loss is 0.04623335227370262\n",
      "07/27/2023 19:15:45 - INFO - __main__ - Cumulative validation average loss is 6.55586829315871\n",
      "07/27/2023 19:15:45 - INFO - __main__ - Per validation step average loss is 0.22268888354301453\n",
      "07/27/2023 19:15:45 - INFO - __main__ - Cumulative validation average loss is 6.7785571767017245\n",
      "07/27/2023 19:15:46 - INFO - __main__ - Per validation step average loss is 0.015260023064911366\n",
      "07/27/2023 19:15:46 - INFO - __main__ - Cumulative validation average loss is 6.793817199766636\n",
      "07/27/2023 19:15:46 - INFO - __main__ - Per validation step average loss is 0.1597115397453308\n",
      "07/27/2023 19:15:46 - INFO - __main__ - Cumulative validation average loss is 6.953528739511967\n",
      "07/27/2023 19:15:46 - INFO - __main__ - Per validation step average loss is 0.08146768808364868\n",
      "07/27/2023 19:15:46 - INFO - __main__ - Cumulative validation average loss is 7.034996427595615\n",
      "07/27/2023 19:15:47 - INFO - __main__ - Per validation step average loss is 0.1137051209807396\n",
      "07/27/2023 19:15:47 - INFO - __main__ - Cumulative validation average loss is 7.148701548576355\n",
      "07/27/2023 19:15:47 - INFO - __main__ - Per validation step average loss is 0.20260602235794067\n",
      "07/27/2023 19:15:47 - INFO - __main__ - Cumulative validation average loss is 7.351307570934296\n",
      "07/27/2023 19:15:48 - INFO - __main__ - Per validation step average loss is 0.05040426179766655\n",
      "07/27/2023 19:15:48 - INFO - __main__ - Cumulative validation average loss is 7.401711832731962\n",
      "07/27/2023 19:15:48 - INFO - __main__ - Per validation step average loss is 0.09622293710708618\n",
      "07/27/2023 19:15:48 - INFO - __main__ - Cumulative validation average loss is 7.497934769839048\n",
      "07/27/2023 19:15:49 - INFO - __main__ - Per validation step average loss is 0.016125820577144623\n",
      "07/27/2023 19:15:49 - INFO - __main__ - Cumulative validation average loss is 7.514060590416193\n",
      "07/27/2023 19:15:49 - INFO - __main__ - Per validation step average loss is 0.003103154245764017\n",
      "07/27/2023 19:15:49 - INFO - __main__ - Cumulative validation average loss is 7.517163744661957\n",
      "07/27/2023 19:15:49 - INFO - __main__ - Per validation step average loss is 0.15234333276748657\n",
      "07/27/2023 19:15:49 - INFO - __main__ - Cumulative validation average loss is 7.669507077429444\n",
      "07/27/2023 19:15:50 - INFO - __main__ - Per validation step average loss is 0.6043441891670227\n",
      "07/27/2023 19:15:50 - INFO - __main__ - Cumulative validation average loss is 8.273851266596466\n",
      "07/27/2023 19:15:50 - INFO - __main__ - Per validation step average loss is 0.5112133622169495\n",
      "07/27/2023 19:15:50 - INFO - __main__ - Cumulative validation average loss is 8.785064628813416\n",
      "07/27/2023 19:15:51 - INFO - __main__ - Per validation step average loss is 0.0036509642377495766\n",
      "07/27/2023 19:15:51 - INFO - __main__ - Cumulative validation average loss is 8.788715593051165\n",
      "07/27/2023 19:15:51 - INFO - __main__ - Per validation step average loss is 0.11601647734642029\n",
      "07/27/2023 19:15:51 - INFO - __main__ - Cumulative validation average loss is 8.904732070397586\n",
      "07/27/2023 19:15:51 - INFO - __main__ - Per validation step average loss is 0.04254193603992462\n",
      "07/27/2023 19:15:51 - INFO - __main__ - Cumulative validation average loss is 8.94727400643751\n",
      "07/27/2023 19:15:52 - INFO - __main__ - Per validation step average loss is 0.8783376216888428\n",
      "07/27/2023 19:15:52 - INFO - __main__ - Cumulative validation average loss is 9.825611628126353\n",
      "07/27/2023 19:15:52 - INFO - __main__ - Per validation step average loss is 0.2592282295227051\n",
      "07/27/2023 19:15:52 - INFO - __main__ - Cumulative validation average loss is 10.084839857649058\n",
      "07/27/2023 19:15:53 - INFO - __main__ - Per validation step average loss is 0.0015784024726599455\n",
      "07/27/2023 19:15:53 - INFO - __main__ - Cumulative validation average loss is 10.086418260121718\n",
      "07/27/2023 19:15:53 - INFO - __main__ - Per validation step average loss is 0.027191873639822006\n",
      "07/27/2023 19:15:53 - INFO - __main__ - Cumulative validation average loss is 10.11361013376154\n",
      "07/27/2023 19:15:53 - INFO - __main__ - Per validation step average loss is 0.18546682596206665\n",
      "07/27/2023 19:15:53 - INFO - __main__ - Cumulative validation average loss is 10.299076959723607\n",
      "07/27/2023 19:15:54 - INFO - __main__ - Per validation step average loss is 0.008370159193873405\n",
      "07/27/2023 19:15:54 - INFO - __main__ - Cumulative validation average loss is 10.30744711891748\n",
      "07/27/2023 19:15:54 - INFO - __main__ - Per validation step average loss is 0.15295661985874176\n",
      "07/27/2023 19:15:54 - INFO - __main__ - Cumulative validation average loss is 10.460403738776222\n",
      "07/27/2023 19:15:55 - INFO - __main__ - Per validation step average loss is 0.14803096652030945\n",
      "07/27/2023 19:15:55 - INFO - __main__ - Cumulative validation average loss is 10.608434705296531\n",
      "07/27/2023 19:15:55 - INFO - __main__ - Per validation step average loss is 0.06323344260454178\n",
      "07/27/2023 19:15:55 - INFO - __main__ - Cumulative validation average loss is 10.671668147901073\n",
      "07/27/2023 19:15:56 - INFO - __main__ - Per validation step average loss is 0.0066188485361635685\n",
      "07/27/2023 19:15:56 - INFO - __main__ - Cumulative validation average loss is 10.678286996437237\n",
      "07/27/2023 19:15:56 - INFO - __main__ - Average validation loss for Epoch 34 is 0.13516818982831946\n",
      "07/27/2023 19:15:56 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 19:16:52 - INFO - __main__ - Starting epoch 35\n",
      "07/27/2023 19:16:53 - INFO - __main__ - train loss is 0.10555679351091385\n",
      "Steps:  71%|▋| 10606/15000 [1:32:03<33:31:34, 27.47s/it, lr=0.000994, step_loss=07/27/2023 19:16:53 - INFO - __main__ - train loss is 0.19588033109903336\n",
      "Steps:  71%|▋| 10607/15000 [1:32:04<23:31:52, 19.28s/it, lr=0.000994, step_loss=07/27/2023 19:16:54 - INFO - __main__ - train loss is 0.38265156000852585\n",
      "Steps:  71%|▋| 10608/15000 [1:32:04<16:32:01, 13.55s/it, lr=0.000994, step_loss=07/27/2023 19:16:54 - INFO - __main__ - train loss is 0.3899421989917755\n",
      "Steps:  71%|▋| 10609/15000 [1:32:04<11:38:11,  9.54s/it, lr=0.000994, step_loss=07/27/2023 19:16:54 - INFO - __main__ - train loss is 0.8375068604946136\n",
      "Steps:  71%|▋| 10610/15000 [1:32:04<8:12:33,  6.73s/it, lr=0.000994, step_loss=007/27/2023 19:16:54 - INFO - __main__ - train loss is 0.856410900130868\n",
      "Steps:  71%|▋| 10611/15000 [1:32:04<5:48:43,  4.77s/it, lr=0.000994, step_loss=007/27/2023 19:16:54 - INFO - __main__ - train loss is 0.8574626342160627\n",
      "Steps:  71%|▋| 10612/15000 [1:32:05<4:08:07,  3.39s/it, lr=0.000994, step_loss=007/27/2023 19:16:54 - INFO - __main__ - train loss is 1.0058040962321684\n",
      "Steps:  71%|▋| 10613/15000 [1:32:05<2:57:36,  2.43s/it, lr=0.000994, step_loss=007/27/2023 19:16:55 - INFO - __main__ - train loss is 1.0963317797286436\n",
      "Steps:  71%|▋| 10614/15000 [1:32:05<2:08:13,  1.75s/it, lr=0.000994, step_loss=007/27/2023 19:16:55 - INFO - __main__ - train loss is 1.2773126409156248\n",
      "Steps:  71%|▋| 10615/15000 [1:32:05<1:33:39,  1.28s/it, lr=0.000994, step_loss=007/27/2023 19:16:55 - INFO - __main__ - train loss is 1.2802892507752404\n",
      "Steps:  71%|▋| 10616/15000 [1:32:05<1:09:32,  1.05it/s, lr=0.000994, step_loss=007/27/2023 19:16:55 - INFO - __main__ - train loss is 1.2827487414469942\n",
      "Steps:  71%|▋| 10617/15000 [1:32:05<52:42,  1.39it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:55 - INFO - __main__ - train loss is 1.5448065822711214\n",
      "Steps:  71%|▋| 10618/15000 [1:32:06<40:50,  1.79it/s, lr=0.000994, step_loss=0.207/27/2023 19:16:56 - INFO - __main__ - train loss is 1.5524567052489147\n",
      "Steps:  71%|▋| 10619/15000 [1:32:06<32:36,  2.24it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:56 - INFO - __main__ - train loss is 1.726814641035162\n",
      "Steps:  71%|▋| 10620/15000 [1:32:06<26:51,  2.72it/s, lr=0.000994, step_loss=0.107/27/2023 19:16:56 - INFO - __main__ - train loss is 2.227600409067236\n",
      "Steps:  71%|▋| 10621/15000 [1:32:06<22:44,  3.21it/s, lr=0.000994, step_loss=0.507/27/2023 19:16:56 - INFO - __main__ - train loss is 2.2335728857433423\n",
      "Steps:  71%|▋| 10622/15000 [1:32:06<19:49,  3.68it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:56 - INFO - __main__ - train loss is 2.2620352137601003\n",
      "Steps:  71%|▋| 10623/15000 [1:32:07<17:48,  4.10it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:56 - INFO - __main__ - train loss is 2.498716377071105\n",
      "Steps:  71%|▋| 10624/15000 [1:32:07<16:23,  4.45it/s, lr=0.000994, step_loss=0.207/27/2023 19:16:57 - INFO - __main__ - train loss is 2.568295605829917\n",
      "Steps:  71%|▋| 10625/15000 [1:32:07<15:24,  4.73it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:57 - INFO - __main__ - train loss is 2.8411918360507116\n",
      "Steps:  71%|▋| 10626/15000 [1:32:07<14:50,  4.91it/s, lr=0.000994, step_loss=0.207/27/2023 19:16:57 - INFO - __main__ - train loss is 2.8569708712166175\n",
      "Steps:  71%|▋| 10627/15000 [1:32:07<14:26,  5.05it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:57 - INFO - __main__ - train loss is 2.87748732639011\n",
      "Steps:  71%|▋| 10628/15000 [1:32:07<14:08,  5.16it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:57 - INFO - __main__ - train loss is 2.983040402061306\n",
      "Steps:  71%|▋| 10629/15000 [1:32:08<13:53,  5.24it/s, lr=0.000994, step_loss=0.107/27/2023 19:16:58 - INFO - __main__ - train loss is 2.988375804736279\n",
      "Steps:  71%|▋| 10630/15000 [1:32:08<13:38,  5.34it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:58 - INFO - __main__ - train loss is 3.086335457279347\n",
      "Steps:  71%|▋| 10631/15000 [1:32:08<13:28,  5.40it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:58 - INFO - __main__ - train loss is 3.232739574625157\n",
      "Steps:  71%|▋| 10632/15000 [1:32:08<13:28,  5.41it/s, lr=0.000994, step_loss=0.107/27/2023 19:16:58 - INFO - __main__ - train loss is 3.3536571705481037\n",
      "Steps:  71%|▋| 10633/15000 [1:32:08<13:28,  5.40it/s, lr=0.000994, step_loss=0.107/27/2023 19:16:58 - INFO - __main__ - train loss is 3.3657856344943866\n",
      "Steps:  71%|▋| 10634/15000 [1:32:09<13:27,  5.40it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:58 - INFO - __main__ - train loss is 3.383756462833844\n",
      "Steps:  71%|▋| 10635/15000 [1:32:09<13:23,  5.43it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:59 - INFO - __main__ - train loss is 3.576451573870145\n",
      "Steps:  71%|▋| 10636/15000 [1:32:09<13:17,  5.47it/s, lr=0.000994, step_loss=0.107/27/2023 19:16:59 - INFO - __main__ - train loss is 3.5980439953273162\n",
      "Steps:  71%|▋| 10637/15000 [1:32:09<13:20,  5.45it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:59 - INFO - __main__ - train loss is 3.634784320718609\n",
      "Steps:  71%|▋| 10638/15000 [1:32:09<13:27,  5.41it/s, lr=0.000994, step_loss=0.007/27/2023 19:16:59 - INFO - __main__ - train loss is 3.891866723424755\n",
      "Steps:  71%|▋| 10639/15000 [1:32:09<13:24,  5.42it/s, lr=0.000994, step_loss=0.207/27/2023 19:16:59 - INFO - __main__ - train loss is 3.9157481029396877\n",
      "Steps:  71%|▋| 10640/15000 [1:32:10<13:23,  5.42it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:00 - INFO - __main__ - train loss is 3.9208645256003365\n",
      "Steps:  71%|▋| 10641/15000 [1:32:10<13:21,  5.44it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:00 - INFO - __main__ - train loss is 4.501571181579493\n",
      "Steps:  71%|▋| 10642/15000 [1:32:10<13:15,  5.48it/s, lr=0.000994, step_loss=0.507/27/2023 19:17:00 - INFO - __main__ - train loss is 4.602328303619288\n",
      "Steps:  71%|▋| 10643/15000 [1:32:10<13:16,  5.47it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:00 - INFO - __main__ - train loss is 4.606689759879373\n",
      "Steps:  71%|▋| 10644/15000 [1:32:10<13:18,  5.45it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:00 - INFO - __main__ - train loss is 4.889750548987649\n",
      "Steps:  71%|▋| 10645/15000 [1:32:11<13:16,  5.47it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:00 - INFO - __main__ - train loss is 4.899172001867555\n",
      "Steps:  71%|▋| 10646/15000 [1:32:11<13:11,  5.50it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:01 - INFO - __main__ - train loss is 4.901495480560698\n",
      "Steps:  71%|▋| 10647/15000 [1:32:11<13:09,  5.52it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:01 - INFO - __main__ - train loss is 5.48459556105081\n",
      "Steps:  71%|▋| 10648/15000 [1:32:11<13:06,  5.53it/s, lr=0.000994, step_loss=0.507/27/2023 19:17:01 - INFO - __main__ - train loss is 5.502713132300414\n",
      "Steps:  71%|▋| 10649/15000 [1:32:11<13:05,  5.54it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:01 - INFO - __main__ - train loss is 5.507677129120566\n",
      "Steps:  71%|▋| 10650/15000 [1:32:11<13:04,  5.55it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:01 - INFO - __main__ - train loss is 5.510903035406955\n",
      "Steps:  71%|▋| 10651/15000 [1:32:12<13:10,  5.50it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:02 - INFO - __main__ - train loss is 5.541639576782472\n",
      "Steps:  71%|▋| 10652/15000 [1:32:12<13:12,  5.49it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:02 - INFO - __main__ - train loss is 5.613021279801615\n",
      "Steps:  71%|▋| 10653/15000 [1:32:12<13:10,  5.50it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:02 - INFO - __main__ - train loss is 5.934059823979624\n",
      "Steps:  71%|▋| 10654/15000 [1:32:12<13:12,  5.48it/s, lr=0.000994, step_loss=0.307/27/2023 19:17:02 - INFO - __main__ - train loss is 5.956203482230194\n",
      "Steps:  71%|▋| 10655/15000 [1:32:12<13:14,  5.47it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:02 - INFO - __main__ - train loss is 5.981775527005084\n",
      "Steps:  71%|▋| 10656/15000 [1:32:13<13:16,  5.45it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:02 - INFO - __main__ - train loss is 6.5394328880356625\n",
      "Steps:  71%|▋| 10657/15000 [1:32:13<13:16,  5.45it/s, lr=0.000994, step_loss=0.507/27/2023 19:17:03 - INFO - __main__ - train loss is 7.438498263363726\n",
      "Steps:  71%|▋| 10658/15000 [1:32:13<13:11,  5.49it/s, lr=0.000994, step_loss=0.807/27/2023 19:17:03 - INFO - __main__ - train loss is 7.649332900648005\n",
      "Steps:  71%|▋| 10659/15000 [1:32:13<13:14,  5.46it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:03 - INFO - __main__ - train loss is 8.017029722337611\n",
      "Steps:  71%|▋| 10660/15000 [1:32:13<13:14,  5.46it/s, lr=0.000994, step_loss=0.307/27/2023 19:17:03 - INFO - __main__ - train loss is 8.156009544734843\n",
      "Steps:  71%|▋| 10661/15000 [1:32:14<13:13,  5.47it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:03 - INFO - __main__ - train loss is 8.438235213165171\n",
      "Steps:  71%|▋| 10662/15000 [1:32:14<13:08,  5.50it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:04 - INFO - __main__ - train loss is 8.711679746513255\n",
      "Steps:  71%|▋| 10663/15000 [1:32:14<13:10,  5.49it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:04 - INFO - __main__ - train loss is 8.842546870117076\n",
      "Steps:  71%|▋| 10664/15000 [1:32:14<13:06,  5.51it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:04 - INFO - __main__ - train loss is 8.956118543748744\n",
      "Steps:  71%|▋| 10665/15000 [1:32:14<13:10,  5.48it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:04 - INFO - __main__ - train loss is 9.507986982469447\n",
      "Steps:  71%|▋| 10666/15000 [1:32:14<13:15,  5.45it/s, lr=0.000994, step_loss=0.507/27/2023 19:17:04 - INFO - __main__ - train loss is 9.558440142427571\n",
      "Steps:  71%|▋| 10667/15000 [1:32:15<13:14,  5.45it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:04 - INFO - __main__ - train loss is 9.562604341306724\n",
      "Steps:  71%|▋| 10668/15000 [1:32:15<13:09,  5.49it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:05 - INFO - __main__ - train loss is 9.612173501052894\n",
      "Steps:  71%|▋| 10669/15000 [1:32:15<13:05,  5.51it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:05 - INFO - __main__ - train loss is 10.264920714893378\n",
      "Steps:  71%|▋| 10670/15000 [1:32:15<13:04,  5.52it/s, lr=0.000994, step_loss=0.607/27/2023 19:17:05 - INFO - __main__ - train loss is 10.303439709939994\n",
      "Steps:  71%|▋| 10671/15000 [1:32:15<13:01,  5.54it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:05 - INFO - __main__ - train loss is 10.404759619035758\n",
      "Steps:  71%|▋| 10672/15000 [1:32:16<13:00,  5.55it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:05 - INFO - __main__ - train loss is 10.858853075304069\n",
      "Steps:  71%|▋| 10673/15000 [1:32:16<12:59,  5.55it/s, lr=0.000994, step_loss=0.407/27/2023 19:17:06 - INFO - __main__ - train loss is 11.287679586210288\n",
      "Steps:  71%|▋| 10674/15000 [1:32:16<13:00,  5.54it/s, lr=0.000994, step_loss=0.407/27/2023 19:17:06 - INFO - __main__ - train loss is 11.325404125847854\n",
      "Steps:  71%|▋| 10675/15000 [1:32:16<12:58,  5.55it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:06 - INFO - __main__ - train loss is 11.326338415266946\n",
      "Steps:  71%|▋| 10676/15000 [1:32:16<12:57,  5.56it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:06 - INFO - __main__ - train loss is 11.492013906361535\n",
      "Steps:  71%|▋| 10677/15000 [1:32:16<12:56,  5.57it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:06 - INFO - __main__ - train loss is 11.49384762684349\n",
      "Steps:  71%|▋| 10678/15000 [1:32:17<12:55,  5.57it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:06 - INFO - __main__ - train loss is 11.506271734484471\n",
      "Steps:  71%|▋| 10679/15000 [1:32:17<13:00,  5.54it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:07 - INFO - __main__ - train loss is 11.5076925389003\n",
      "Steps:  71%|▋| 10680/15000 [1:32:17<12:58,  5.55it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:07 - INFO - __main__ - train loss is 11.521994278533384\n",
      "Steps:  71%|▋| 10681/15000 [1:32:17<12:58,  5.55it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:07 - INFO - __main__ - train loss is 11.535300613148138\n",
      "Steps:  71%|▋| 10682/15000 [1:32:17<12:57,  5.55it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:07 - INFO - __main__ - train loss is 11.623867944581434\n",
      "Steps:  71%|▋| 10683/15000 [1:32:17<12:56,  5.56it/s, lr=0.000994, step_loss=0.007/27/2023 19:17:07 - INFO - __main__ - train loss is 11.780800298554823\n",
      "Steps:  71%|▋| 10684/15000 [1:32:18<12:55,  5.56it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:08 - INFO - __main__ - train loss is 12.03246818552725\n",
      "Steps:  71%|▋| 10685/15000 [1:32:18<12:55,  5.57it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:08 - INFO - __main__ - train loss is 12.193895146949217\n",
      "Steps:  71%|▋| 10686/15000 [1:32:18<12:59,  5.53it/s, lr=0.000994, step_loss=0.107/27/2023 19:17:08 - INFO - __main__ - train loss is 12.424065098864958\n",
      "Steps:  71%|▋| 10687/15000 [1:32:18<13:04,  5.50it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:08 - INFO - __main__ - train loss is 12.719695375068113\n",
      "Steps:  71%|▋| 10688/15000 [1:32:18<13:04,  5.50it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:08 - INFO - __main__ - train loss is 12.991735444171354\n",
      "Steps:  71%|▋| 10689/15000 [1:32:19<13:05,  5.49it/s, lr=0.000994, step_loss=0.207/27/2023 19:17:08 - INFO - __main__ - train loss is 13.049650114728138\n",
      "Steps:  71%|▋| 10690/15000 [1:32:19<13:01,  5.51it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:09 - INFO - __main__ - train loss is 13.066505542723462\n",
      "Steps:  71%|▋| 10691/15000 [1:32:19<12:59,  5.53it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:09 - INFO - __main__ - train loss is 13.241712650982663\n",
      "Steps:  71%|▋| 10692/15000 [1:32:19<13:02,  5.51it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:09 - INFO - __main__ - train loss is 13.266928394092247\n",
      "Steps:  71%|▋| 10693/15000 [1:32:19<13:06,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:09 - INFO - __main__ - train loss is 13.289213516516611\n",
      "Steps:  71%|▋| 10694/15000 [1:32:19<13:04,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:09 - INFO - __main__ - train loss is 13.296257154783234\n",
      "Steps:  71%|▋| 10695/15000 [1:32:20<13:01,  5.51it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:10 - INFO - __main__ - train loss is 13.340863769641146\n",
      "Steps:  71%|▋| 10696/15000 [1:32:20<12:58,  5.53it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:10 - INFO - __main__ - train loss is 13.379476690432057\n",
      "Steps:  71%|▋| 10697/15000 [1:32:20<12:56,  5.54it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:10 - INFO - __main__ - train loss is 13.677808308741078\n",
      "Steps:  71%|▋| 10698/15000 [1:32:20<12:58,  5.52it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:10 - INFO - __main__ - train loss is 13.703146146377549\n",
      "Steps:  71%|▋| 10699/15000 [1:32:20<12:56,  5.54it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:10 - INFO - __main__ - train loss is 14.286683963378891\n",
      "Steps:  71%|▋| 10700/15000 [1:32:21<13:01,  5.50it/s, lr=0.000993, step_loss=0.507/27/2023 19:17:10 - INFO - __main__ - train loss is 14.295214403187856\n",
      "Steps:  71%|▋| 10701/15000 [1:32:21<13:12,  5.43it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:11 - INFO - __main__ - train loss is 14.366402152692899\n",
      "Steps:  71%|▋| 10702/15000 [1:32:21<13:12,  5.42it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:11 - INFO - __main__ - train loss is 14.653336766874418\n",
      "Steps:  71%|▋| 10703/15000 [1:32:21<13:12,  5.42it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:11 - INFO - __main__ - train loss is 14.692962605273351\n",
      "Steps:  71%|▋| 10704/15000 [1:32:21<13:08,  5.45it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:11 - INFO - __main__ - train loss is 14.885599363362417\n",
      "Steps:  71%|▋| 10705/15000 [1:32:21<13:03,  5.48it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:11 - INFO - __main__ - train loss is 14.996635410701856\n",
      "Steps:  71%|▋| 10706/15000 [1:32:22<12:59,  5.51it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:12 - INFO - __main__ - train loss is 15.05748051754199\n",
      "Steps:  71%|▋| 10707/15000 [1:32:22<12:56,  5.53it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:12 - INFO - __main__ - train loss is 15.088699593907222\n",
      "Steps:  71%|▋| 10708/15000 [1:32:22<12:54,  5.54it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:12 - INFO - __main__ - train loss is 15.269175126915798\n",
      "Steps:  71%|▋| 10709/15000 [1:32:22<12:53,  5.55it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:12 - INFO - __main__ - train loss is 15.353059656685218\n",
      "Steps:  71%|▋| 10710/15000 [1:32:22<12:51,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:12 - INFO - __main__ - train loss is 15.391491785412654\n",
      "Steps:  71%|▋| 10711/15000 [1:32:23<12:50,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:12 - INFO - __main__ - train loss is 15.401580744190142\n",
      "Steps:  71%|▋| 10712/15000 [1:32:23<12:49,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:13 - INFO - __main__ - train loss is 15.756983750266954\n",
      "Steps:  71%|▋| 10713/15000 [1:32:23<12:49,  5.57it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:13 - INFO - __main__ - train loss is 15.83757867733948\n",
      "Steps:  71%|▋| 10714/15000 [1:32:23<12:56,  5.52it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:13 - INFO - __main__ - train loss is 16.059795790119097\n",
      "Steps:  71%|▋| 10715/15000 [1:32:23<12:56,  5.52it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:13 - INFO - __main__ - train loss is 16.19251810829155\n",
      "Steps:  71%|▋| 10716/15000 [1:32:23<13:01,  5.48it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:13 - INFO - __main__ - train loss is 16.42690356890671\n",
      "Steps:  71%|▋| 10717/15000 [1:32:24<13:02,  5.47it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:14 - INFO - __main__ - train loss is 16.49341441760771\n",
      "Steps:  71%|▋| 10718/15000 [1:32:24<13:01,  5.48it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:14 - INFO - __main__ - train loss is 16.585556448204443\n",
      "Steps:  71%|▋| 10719/15000 [1:32:24<13:01,  5.48it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:14 - INFO - __main__ - train loss is 16.587812239304185\n",
      "Steps:  71%|▋| 10720/15000 [1:32:24<13:04,  5.45it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:14 - INFO - __main__ - train loss is 16.991220558062196\n",
      "Steps:  71%|▋| 10721/15000 [1:32:24<13:03,  5.46it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:14 - INFO - __main__ - train loss is 17.07699135877192\n",
      "Steps:  71%|▋| 10722/15000 [1:32:25<13:02,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:14 - INFO - __main__ - train loss is 17.142328614369035\n",
      "Steps:  71%|▋| 10723/15000 [1:32:25<13:01,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:15 - INFO - __main__ - train loss is 17.194488057866693\n",
      "Steps:  71%|▋| 10724/15000 [1:32:25<13:00,  5.48it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:15 - INFO - __main__ - train loss is 17.209483118727803\n",
      "Steps:  72%|▋| 10725/15000 [1:32:25<12:59,  5.48it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:15 - INFO - __main__ - train loss is 17.28073355741799\n",
      "Steps:  72%|▋| 10726/15000 [1:32:25<13:05,  5.44it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:15 - INFO - __main__ - train loss is 17.31747164018452\n",
      "Steps:  72%|▋| 10727/15000 [1:32:25<13:03,  5.45it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:15 - INFO - __main__ - train loss is 17.446056025102735\n",
      "Steps:  72%|▋| 10728/15000 [1:32:26<13:01,  5.47it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:16 - INFO - __main__ - train loss is 17.741490500047803\n",
      "Steps:  72%|▋| 10729/15000 [1:32:26<13:00,  5.47it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:16 - INFO - __main__ - train loss is 17.76120970584452\n",
      "Steps:  72%|▋| 10730/15000 [1:32:26<12:59,  5.48it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:16 - INFO - __main__ - train loss is 17.76737651322037\n",
      "Steps:  72%|▋| 10731/15000 [1:32:26<12:58,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:16 - INFO - __main__ - train loss is 17.841823027469218\n",
      "Steps:  72%|▋| 10732/15000 [1:32:26<13:04,  5.44it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:16 - INFO - __main__ - train loss is 17.934408345259726\n",
      "Steps:  72%|▋| 10733/15000 [1:32:27<13:07,  5.42it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:16 - INFO - __main__ - train loss is 18.048931264318526\n",
      "Steps:  72%|▋| 10734/15000 [1:32:27<13:07,  5.42it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:17 - INFO - __main__ - train loss is 18.05299150152132\n",
      "Steps:  72%|▋| 10735/15000 [1:32:27<13:03,  5.45it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:17 - INFO - __main__ - train loss is 18.853535048197955\n",
      "Steps:  72%|▋| 10736/15000 [1:32:27<12:57,  5.49it/s, lr=0.000993, step_loss=0.807/27/2023 19:17:17 - INFO - __main__ - train loss is 18.86987875169143\n",
      "Steps:  72%|▋| 10737/15000 [1:32:27<12:53,  5.51it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:17 - INFO - __main__ - train loss is 18.885089326184243\n",
      "Steps:  72%|▋| 10738/15000 [1:32:27<12:50,  5.53it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:17 - INFO - __main__ - train loss is 18.907287964131683\n",
      "Steps:  72%|▋| 10739/15000 [1:32:28<12:55,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:18 - INFO - __main__ - train loss is 18.90951883373782\n",
      "Steps:  72%|▋| 10740/15000 [1:32:28<13:00,  5.46it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:18 - INFO - __main__ - train loss is 18.98208290664479\n",
      "Steps:  72%|▋| 10741/15000 [1:32:28<13:06,  5.41it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:18 - INFO - __main__ - train loss is 19.402410361450166\n",
      "Steps:  72%|▋| 10742/15000 [1:32:28<13:00,  5.46it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:18 - INFO - __main__ - train loss is 19.561479869764298\n",
      "Steps:  72%|▋| 10743/15000 [1:32:28<12:55,  5.49it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:18 - INFO - __main__ - train loss is 19.615970510523766\n",
      "Steps:  72%|▋| 10744/15000 [1:32:29<12:55,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:18 - INFO - __main__ - train loss is 19.646706124302\n",
      "Steps:  72%|▋| 10745/15000 [1:32:29<12:54,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:19 - INFO - __main__ - train loss is 19.651353794150054\n",
      "Steps:  72%|▋| 10746/15000 [1:32:29<12:54,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:19 - INFO - __main__ - train loss is 20.392290371470153\n",
      "Steps:  72%|▋| 10747/15000 [1:32:29<13:01,  5.44it/s, lr=0.000993, step_loss=0.707/27/2023 19:17:19 - INFO - __main__ - train loss is 20.466299983672798\n",
      "Steps:  72%|▋| 10748/15000 [1:32:29<12:58,  5.46it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:19 - INFO - __main__ - train loss is 21.126662763766944\n",
      "Steps:  72%|▋| 10749/15000 [1:32:30<12:53,  5.49it/s, lr=0.000993, step_loss=0.607/27/2023 19:17:19 - INFO - __main__ - train loss is 21.865830334834754\n",
      "Steps:  72%|▋| 10750/15000 [1:32:30<12:50,  5.52it/s, lr=0.000993, step_loss=0.707/27/2023 19:17:20 - INFO - __main__ - train loss is 22.220738443545997\n",
      "Steps:  72%|▋| 10751/15000 [1:32:30<12:48,  5.53it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:20 - INFO - __main__ - train loss is 22.224104413297027\n",
      "Steps:  72%|▋| 10752/15000 [1:32:30<12:46,  5.54it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:20 - INFO - __main__ - train loss is 22.22579067957122\n",
      "Steps:  72%|▋| 10753/15000 [1:32:30<12:52,  5.50it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:20 - INFO - __main__ - train loss is 22.317512348410673\n",
      "Steps:  72%|▋| 10754/15000 [1:32:30<12:53,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:20 - INFO - __main__ - train loss is 22.411483630654402\n",
      "Steps:  72%|▋| 10755/15000 [1:32:31<12:55,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:20 - INFO - __main__ - train loss is 22.417360652820207\n",
      "Steps:  72%|▋| 10756/15000 [1:32:31<12:56,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:21 - INFO - __main__ - train loss is 22.449192930595018\n",
      "Steps:  72%|▋| 10757/15000 [1:32:31<12:51,  5.50it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:21 - INFO - __main__ - train loss is 22.79343112243805\n",
      "Steps:  72%|▋| 10758/15000 [1:32:31<12:47,  5.52it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:21 - INFO - __main__ - train loss is 22.796190685010515\n",
      "Steps:  72%|▋| 10759/15000 [1:32:31<12:45,  5.54it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:21 - INFO - __main__ - train loss is 23.129117256379686\n",
      "Steps:  72%|▋| 10760/15000 [1:32:31<12:44,  5.55it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:21 - INFO - __main__ - train loss is 23.156924086040817\n",
      "Steps:  72%|▋| 10761/15000 [1:32:32<12:43,  5.55it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:22 - INFO - __main__ - train loss is 23.158182657905854\n",
      "Steps:  72%|▋| 10762/15000 [1:32:32<12:42,  5.55it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:22 - INFO - __main__ - train loss is 23.296904466697015\n",
      "Steps:  72%|▋| 10763/15000 [1:32:32<12:42,  5.55it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:22 - INFO - __main__ - train loss is 23.60323347861413\n",
      "Steps:  72%|▋| 10764/15000 [1:32:32<12:42,  5.56it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:22 - INFO - __main__ - train loss is 23.70132810587529\n",
      "Steps:  72%|▋| 10765/15000 [1:32:32<12:41,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:22 - INFO - __main__ - train loss is 23.735199547954835\n",
      "Steps:  72%|▋| 10766/15000 [1:32:33<12:41,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:22 - INFO - __main__ - train loss is 23.737661569030024\n",
      "Steps:  72%|▋| 10767/15000 [1:32:33<12:40,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:23 - INFO - __main__ - train loss is 23.95688807836268\n",
      "Steps:  72%|▋| 10768/15000 [1:32:33<12:39,  5.57it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:23 - INFO - __main__ - train loss is 23.965960220084526\n",
      "Steps:  72%|▋| 10769/15000 [1:32:33<12:39,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:23 - INFO - __main__ - train loss is 24.168087155208923\n",
      "Steps:  72%|▋| 10770/15000 [1:32:33<12:39,  5.57it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:23 - INFO - __main__ - train loss is 24.18213907966856\n",
      "Steps:  72%|▋| 10771/15000 [1:32:33<12:38,  5.58it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:23 - INFO - __main__ - train loss is 24.369396458962\n",
      "Steps:  72%|▋| 10772/15000 [1:32:34<12:38,  5.58it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:24 - INFO - __main__ - train loss is 24.407978381612338\n",
      "Steps:  72%|▋| 10773/15000 [1:32:34<12:38,  5.58it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:24 - INFO - __main__ - train loss is 24.41151469864417\n",
      "Steps:  72%|▋| 10774/15000 [1:32:34<12:38,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:24 - INFO - __main__ - train loss is 24.41301004018169\n",
      "Steps:  72%|▋| 10775/15000 [1:32:34<12:38,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:24 - INFO - __main__ - train loss is 24.465721895801835\n",
      "Steps:  72%|▋| 10776/15000 [1:32:34<12:38,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:24 - INFO - __main__ - train loss is 24.46808245999273\n",
      "Steps:  72%|▋| 10777/15000 [1:32:35<12:43,  5.53it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:24 - INFO - __main__ - train loss is 24.663588973111473\n",
      "Steps:  72%|▋| 10778/15000 [1:32:35<12:47,  5.50it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:25 - INFO - __main__ - train loss is 25.083209546632133\n",
      "Steps:  72%|▋| 10779/15000 [1:32:35<12:44,  5.52it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:25 - INFO - __main__ - train loss is 25.219161080545746\n",
      "Steps:  72%|▋| 10780/15000 [1:32:35<12:44,  5.52it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:25 - INFO - __main__ - train loss is 25.24152990465518\n",
      "Steps:  72%|▋| 10781/15000 [1:32:35<12:42,  5.54it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:25 - INFO - __main__ - train loss is 25.370112412027083\n",
      "Steps:  72%|▋| 10782/15000 [1:32:35<12:40,  5.55it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:25 - INFO - __main__ - train loss is 25.721585803083144\n",
      "Steps:  72%|▋| 10783/15000 [1:32:36<12:46,  5.50it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:26 - INFO - __main__ - train loss is 25.72364851029124\n",
      "Steps:  72%|▋| 10784/15000 [1:32:36<12:50,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:26 - INFO - __main__ - train loss is 25.806667960598134\n",
      "Steps:  72%|▋| 10785/15000 [1:32:36<12:47,  5.49it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:26 - INFO - __main__ - train loss is 25.810347897117026\n",
      "Steps:  72%|▋| 10786/15000 [1:32:36<12:50,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:26 - INFO - __main__ - train loss is 25.96374888450373\n",
      "Steps:  72%|▋| 10787/15000 [1:32:36<12:49,  5.47it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:26 - INFO - __main__ - train loss is 26.408498508040793\n",
      "Steps:  72%|▋| 10788/15000 [1:32:37<12:51,  5.46it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:26 - INFO - __main__ - train loss is 26.417864132788964\n",
      "Steps:  72%|▋| 10789/15000 [1:32:37<12:46,  5.50it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:27 - INFO - __main__ - train loss is 26.45594353612978\n",
      "Steps:  72%|▋| 10790/15000 [1:32:37<12:42,  5.52it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:27 - INFO - __main__ - train loss is 26.45782317861449\n",
      "Steps:  72%|▋| 10791/15000 [1:32:37<12:43,  5.51it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:27 - INFO - __main__ - train loss is 26.47566836781334\n",
      "Steps:  72%|▋| 10792/15000 [1:32:37<12:40,  5.53it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:27 - INFO - __main__ - train loss is 26.81752365536522\n",
      "Steps:  72%|▋| 10793/15000 [1:32:37<12:42,  5.52it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:27 - INFO - __main__ - train loss is 26.893305529723875\n",
      "Steps:  72%|▋| 10794/15000 [1:32:38<12:45,  5.50it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:28 - INFO - __main__ - train loss is 27.097343583474867\n",
      "Steps:  72%|▋| 10795/15000 [1:32:38<13:08,  5.34it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:28 - INFO - __main__ - train loss is 27.232556049595587\n",
      "Steps:  72%|▋| 10796/15000 [1:32:38<13:24,  5.22it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:28 - INFO - __main__ - train loss is 27.40415361977648\n",
      "Steps:  72%|▋| 10797/15000 [1:32:38<13:28,  5.20it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:28 - INFO - __main__ - train loss is 27.520889063249342\n",
      "Steps:  72%|▋| 10798/15000 [1:32:38<13:34,  5.16it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:28 - INFO - __main__ - train loss is 27.528699748567306\n",
      "Steps:  72%|▋| 10799/15000 [1:32:39<13:37,  5.14it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:29 - INFO - __main__ - train loss is 27.807519100955687\n",
      "Steps:  72%|▋| 10800/15000 [1:32:39<13:38,  5.13it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:29 - INFO - __main__ - train loss is 28.016463153413497\n",
      "Steps:  72%|▋| 10801/15000 [1:32:39<13:40,  5.12it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:29 - INFO - __main__ - train loss is 28.09689019655343\n",
      "Steps:  72%|▋| 10802/15000 [1:32:39<13:38,  5.13it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:29 - INFO - __main__ - train loss is 28.19149294530507\n",
      "Steps:  72%|▋| 10803/15000 [1:32:39<13:38,  5.13it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:29 - INFO - __main__ - train loss is 28.199907207279466\n",
      "Steps:  72%|▋| 10804/15000 [1:32:40<13:39,  5.12it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:29 - INFO - __main__ - train loss is 28.65559025981929\n",
      "Steps:  72%|▋| 10805/15000 [1:32:40<13:38,  5.13it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:30 - INFO - __main__ - train loss is 29.10456433275249\n",
      "Steps:  72%|▋| 10806/15000 [1:32:40<13:39,  5.12it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:30 - INFO - __main__ - train loss is 29.510517352609895\n",
      "Steps:  72%|▋| 10807/15000 [1:32:40<13:38,  5.12it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:30 - INFO - __main__ - train loss is 29.961382651119493\n",
      "Steps:  72%|▋| 10808/15000 [1:32:40<13:39,  5.12it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:30 - INFO - __main__ - train loss is 29.972977055585943\n",
      "Steps:  72%|▋| 10809/15000 [1:32:41<13:39,  5.11it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:30 - INFO - __main__ - train loss is 30.134418351924978\n",
      "Steps:  72%|▋| 10810/15000 [1:32:41<13:37,  5.12it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:31 - INFO - __main__ - train loss is 30.153516531339847\n",
      "Steps:  72%|▋| 10811/15000 [1:32:41<13:37,  5.12it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:31 - INFO - __main__ - train loss is 30.745024800649844\n",
      "Steps:  72%|▋| 10812/15000 [1:32:41<13:38,  5.12it/s, lr=0.000993, step_loss=0.507/27/2023 19:17:31 - INFO - __main__ - train loss is 30.77905127813574\n",
      "Steps:  72%|▋| 10813/15000 [1:32:41<13:37,  5.12it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:31 - INFO - __main__ - train loss is 31.082551602623425\n",
      "Steps:  72%|▋| 10814/15000 [1:32:42<13:38,  5.12it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:31 - INFO - __main__ - train loss is 31.335042659542523\n",
      "Steps:  72%|▋| 10815/15000 [1:32:42<13:32,  5.15it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:32 - INFO - __main__ - train loss is 31.344017164199613\n",
      "Steps:  72%|▋| 10816/15000 [1:32:42<13:34,  5.13it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:32 - INFO - __main__ - train loss is 31.352475871681236\n",
      "Steps:  72%|▋| 10817/15000 [1:32:42<13:36,  5.12it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:32 - INFO - __main__ - train loss is 31.355786329717375\n",
      "Steps:  72%|▋| 10818/15000 [1:32:42<13:36,  5.12it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:32 - INFO - __main__ - train loss is 31.366693702177145\n",
      "Steps:  72%|▋| 10819/15000 [1:32:43<13:35,  5.12it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:32 - INFO - __main__ - train loss is 31.731114056543447\n",
      "Steps:  72%|▋| 10820/15000 [1:32:43<13:37,  5.12it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:33 - INFO - __main__ - train loss is 31.7728320552269\n",
      "Steps:  72%|▋| 10821/15000 [1:32:43<13:37,  5.11it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:33 - INFO - __main__ - train loss is 31.814125352189876\n",
      "Steps:  72%|▋| 10822/15000 [1:32:43<13:38,  5.10it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:33 - INFO - __main__ - train loss is 32.21100320725236\n",
      "Steps:  72%|▋| 10823/15000 [1:32:43<13:38,  5.10it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:33 - INFO - __main__ - train loss is 32.400974490330555\n",
      "Steps:  72%|▋| 10824/15000 [1:32:44<13:42,  5.07it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:33 - INFO - __main__ - train loss is 32.59288067428861\n",
      "Steps:  72%|▋| 10825/15000 [1:32:44<13:32,  5.14it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:34 - INFO - __main__ - train loss is 32.63039474620018\n",
      "Steps:  72%|▋| 10826/15000 [1:32:44<13:24,  5.19it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:34 - INFO - __main__ - train loss is 32.68439734412823\n",
      "Steps:  72%|▋| 10827/15000 [1:32:44<13:14,  5.25it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:34 - INFO - __main__ - train loss is 32.68917627132032\n",
      "Steps:  72%|▋| 10828/15000 [1:32:44<13:14,  5.25it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:34 - INFO - __main__ - train loss is 32.69230180897284\n",
      "Steps:  72%|▋| 10829/15000 [1:32:44<13:20,  5.21it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:34 - INFO - __main__ - train loss is 32.77676892944146\n",
      "Steps:  72%|▋| 10830/15000 [1:32:45<13:26,  5.17it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:35 - INFO - __main__ - train loss is 32.81365153111983\n",
      "Steps:  72%|▋| 10831/15000 [1:32:45<13:29,  5.15it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:35 - INFO - __main__ - train loss is 33.14460325159598\n",
      "Steps:  72%|▋| 10832/15000 [1:32:45<13:31,  5.14it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:35 - INFO - __main__ - train loss is 33.16408229165245\n",
      "Steps:  72%|▋| 10833/15000 [1:32:45<13:53,  5.00it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:35 - INFO - __main__ - train loss is 33.29148666851688\n",
      "Steps:  72%|▋| 10834/15000 [1:32:45<13:48,  5.03it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:35 - INFO - __main__ - train loss is 33.335670541157015\n",
      "Steps:  72%|▋| 10835/15000 [1:32:46<13:44,  5.05it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:36 - INFO - __main__ - train loss is 33.37984744750429\n",
      "Steps:  72%|▋| 10836/15000 [1:32:46<13:41,  5.07it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:36 - INFO - __main__ - train loss is 33.71128986321855\n",
      "Steps:  72%|▋| 10837/15000 [1:32:46<13:39,  5.08it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:36 - INFO - __main__ - train loss is 33.91539836965967\n",
      "Steps:  72%|▋| 10838/15000 [1:32:46<13:37,  5.09it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:36 - INFO - __main__ - train loss is 33.96477118798066\n",
      "Steps:  72%|▋| 10839/15000 [1:32:46<13:35,  5.10it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:36 - INFO - __main__ - train loss is 33.9796347982483\n",
      "Steps:  72%|▋| 10840/15000 [1:32:47<13:35,  5.10it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:37 - INFO - __main__ - train loss is 34.013988546212204\n",
      "Steps:  72%|▋| 10841/15000 [1:32:47<13:35,  5.10it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:37 - INFO - __main__ - train loss is 34.08304188319016\n",
      "Steps:  72%|▋| 10842/15000 [1:32:47<13:36,  5.10it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:37 - INFO - __main__ - train loss is 34.15196462639142\n",
      "Steps:  72%|▋| 10843/15000 [1:32:47<13:37,  5.08it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:37 - INFO - __main__ - train loss is 34.40691908367444\n",
      "Steps:  72%|▋| 10844/15000 [1:32:47<13:37,  5.08it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:37 - INFO - __main__ - train loss is 34.45188031636644\n",
      "Steps:  72%|▋| 10845/15000 [1:32:48<13:41,  5.06it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:38 - INFO - __main__ - train loss is 34.46787115104962\n",
      "Steps:  72%|▋| 10846/15000 [1:32:48<13:39,  5.07it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:38 - INFO - __main__ - train loss is 34.471144106355496\n",
      "Steps:  72%|▋| 10847/15000 [1:32:48<13:41,  5.05it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:38 - INFO - __main__ - train loss is 34.89516901609022\n",
      "Steps:  72%|▋| 10848/15000 [1:32:48<13:33,  5.10it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:38 - INFO - __main__ - train loss is 35.04288483795244\n",
      "Steps:  72%|▋| 10849/15000 [1:32:48<13:19,  5.19it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:38 - INFO - __main__ - train loss is 35.07731478300411\n",
      "Steps:  72%|▋| 10850/15000 [1:32:49<13:17,  5.20it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:38 - INFO - __main__ - train loss is 35.10298504692037\n",
      "Steps:  72%|▋| 10851/15000 [1:32:49<13:20,  5.18it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:39 - INFO - __main__ - train loss is 35.387796275434084\n",
      "Steps:  72%|▋| 10852/15000 [1:32:49<13:11,  5.24it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:39 - INFO - __main__ - train loss is 35.699262790498324\n",
      "Steps:  72%|▋| 10853/15000 [1:32:49<13:09,  5.25it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:39 - INFO - __main__ - train loss is 36.02699648600537\n",
      "Steps:  72%|▋| 10854/15000 [1:32:49<12:57,  5.33it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:39 - INFO - __main__ - train loss is 36.06610748928506\n",
      "Steps:  72%|▋| 10855/15000 [1:32:50<12:54,  5.35it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:39 - INFO - __main__ - train loss is 36.0700579584809\n",
      "Steps:  72%|▋| 10856/15000 [1:32:50<12:52,  5.36it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:40 - INFO - __main__ - train loss is 36.351594835636206\n",
      "Steps:  72%|▋| 10857/15000 [1:32:50<12:43,  5.42it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:40 - INFO - __main__ - train loss is 36.40761039417703\n",
      "Steps:  72%|▋| 10858/15000 [1:32:50<12:37,  5.47it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:40 - INFO - __main__ - train loss is 36.740602322039194\n",
      "Steps:  72%|▋| 10859/15000 [1:32:50<12:35,  5.48it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:40 - INFO - __main__ - train loss is 36.93748045724351\n",
      "Steps:  72%|▋| 10860/15000 [1:32:50<12:31,  5.51it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:40 - INFO - __main__ - train loss is 36.93916275619995\n",
      "Steps:  72%|▋| 10861/15000 [1:32:51<12:28,  5.53it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:40 - INFO - __main__ - train loss is 37.17406460165512\n",
      "Steps:  72%|▋| 10862/15000 [1:32:51<12:26,  5.54it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:41 - INFO - __main__ - train loss is 37.18532609927934\n",
      "Steps:  72%|▋| 10863/15000 [1:32:51<12:25,  5.55it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:41 - INFO - __main__ - train loss is 37.18721662776079\n",
      "Steps:  72%|▋| 10864/15000 [1:32:51<12:24,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:41 - INFO - __main__ - train loss is 37.20928322838154\n",
      "Steps:  72%|▋| 10865/15000 [1:32:51<12:23,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:41 - INFO - __main__ - train loss is 37.23947773815598\n",
      "Steps:  72%|▋| 10866/15000 [1:32:52<12:23,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:41 - INFO - __main__ - train loss is 37.254870278178714\n",
      "Steps:  72%|▋| 10867/15000 [1:32:52<12:23,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:42 - INFO - __main__ - train loss is 37.51818684989121\n",
      "Steps:  72%|▋| 10868/15000 [1:32:52<12:24,  5.55it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:42 - INFO - __main__ - train loss is 37.81475309783127\n",
      "Steps:  72%|▋| 10869/15000 [1:32:52<12:24,  5.55it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:42 - INFO - __main__ - train loss is 37.85717500129249\n",
      "Steps:  72%|▋| 10870/15000 [1:32:52<12:23,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:42 - INFO - __main__ - train loss is 37.92412055411842\n",
      "Steps:  72%|▋| 10871/15000 [1:32:52<12:23,  5.55it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:42 - INFO - __main__ - train loss is 37.92547356279101\n",
      "Steps:  72%|▋| 10872/15000 [1:32:53<12:22,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:42 - INFO - __main__ - train loss is 37.92723751126323\n",
      "Steps:  72%|▋| 10873/15000 [1:32:53<12:24,  5.55it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:43 - INFO - __main__ - train loss is 38.20362657366786\n",
      "Steps:  72%|▋| 10874/15000 [1:32:53<12:22,  5.55it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:43 - INFO - __main__ - train loss is 38.20623355626594\n",
      "Steps:  72%|▋| 10875/15000 [1:32:53<12:22,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:43 - INFO - __main__ - train loss is 38.35553439974319\n",
      "Steps:  73%|▋| 10876/15000 [1:32:53<12:21,  5.56it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:43 - INFO - __main__ - train loss is 38.60768618702423\n",
      "Steps:  73%|▋| 10877/15000 [1:32:53<12:21,  5.56it/s, lr=0.000993, step_loss=0.207/27/2023 19:17:43 - INFO - __main__ - train loss is 38.61423083383124\n",
      "Steps:  73%|▋| 10878/15000 [1:32:54<12:21,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:44 - INFO - __main__ - train loss is 38.6251308870269\n",
      "Steps:  73%|▋| 10879/15000 [1:32:54<12:20,  5.56it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:44 - INFO - __main__ - train loss is 38.683398711378686\n",
      "Steps:  73%|▋| 10880/15000 [1:32:54<12:20,  5.57it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:44 - INFO - __main__ - train loss is 38.74526035308372\n",
      "Steps:  73%|▋| 10881/15000 [1:32:54<12:27,  5.51it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:44 - INFO - __main__ - train loss is 38.848176280851476\n",
      "Steps:  73%|▋| 10882/15000 [1:32:54<14:06,  4.87it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:44 - INFO - __main__ - train loss is 38.86038058891427\n",
      "Steps:  73%|▋| 10883/15000 [1:32:55<14:21,  4.78it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:45 - INFO - __main__ - train loss is 39.29775565757882\n",
      "Steps:  73%|▋| 10884/15000 [1:32:55<14:01,  4.89it/s, lr=0.000993, step_loss=0.407/27/2023 19:17:45 - INFO - __main__ - train loss is 39.69173186912667\n",
      "Steps:  73%|▋| 10885/15000 [1:32:55<14:11,  4.83it/s, lr=0.000993, step_loss=0.307/27/2023 19:17:45 - INFO - __main__ - train loss is 39.69678886036854\n",
      "Steps:  73%|▋| 10886/15000 [1:32:55<13:38,  5.03it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:45 - INFO - __main__ - train loss is 39.708089271443896\n",
      "Steps:  73%|▋| 10887/15000 [1:32:55<13:14,  5.18it/s, lr=0.000993, step_loss=0.007/27/2023 19:17:45 - INFO - __main__ - train loss is 39.888147214311175\n",
      "Steps:  73%|▋| 10888/15000 [1:32:56<13:01,  5.26it/s, lr=0.000993, step_loss=0.107/27/2023 19:17:46 - INFO - __main__ - train loss is 39.90216051961761\n",
      "Steps:  73%|▋| 10889/15000 [1:32:56<12:49,  5.34it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:46 - INFO - __main__ - train loss is 39.96347922261339\n",
      "Steps:  73%|▋| 10890/15000 [1:32:56<12:39,  5.41it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:46 - INFO - __main__ - train loss is 40.14588973100763\n",
      "Steps:  73%|▋| 10891/15000 [1:32:56<12:33,  5.46it/s, lr=0.000992, step_loss=0.107/27/2023 19:17:46 - INFO - __main__ - train loss is 40.40022114093881\n",
      "Steps:  73%|▋| 10892/15000 [1:32:56<12:28,  5.49it/s, lr=0.000992, step_loss=0.207/27/2023 19:17:46 - INFO - __main__ - train loss is 40.40510835114401\n",
      "Steps:  73%|▋| 10893/15000 [1:32:57<12:24,  5.52it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:46 - INFO - __main__ - train loss is 40.58049098018091\n",
      "Steps:  73%|▋| 10894/15000 [1:32:57<12:21,  5.54it/s, lr=0.000992, step_loss=0.107/27/2023 19:17:47 - INFO - __main__ - train loss is 40.74811157945078\n",
      "Steps:  73%|▋| 10895/15000 [1:32:57<12:20,  5.55it/s, lr=0.000992, step_loss=0.107/27/2023 19:17:47 - INFO - __main__ - train loss is 40.76032769482117\n",
      "Steps:  73%|▋| 10896/15000 [1:32:57<12:25,  5.51it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:47 - INFO - __main__ - train loss is 41.00468358199578\n",
      "Steps:  73%|▋| 10897/15000 [1:32:57<12:28,  5.48it/s, lr=0.000992, step_loss=0.207/27/2023 19:17:47 - INFO - __main__ - train loss is 41.0110050359508\n",
      "Steps:  73%|▋| 10898/15000 [1:32:57<12:31,  5.46it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:47 - INFO - __main__ - train loss is 41.02906680421438\n",
      "Steps:  73%|▋| 10899/15000 [1:32:58<12:27,  5.49it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:48 - INFO - __main__ - train loss is 41.05110775434878\n",
      "Steps:  73%|▋| 10900/15000 [1:32:58<12:27,  5.48it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:48 - INFO - __main__ - train loss is 41.527847220539115\n",
      "Steps:  73%|▋| 10901/15000 [1:32:58<12:32,  5.45it/s, lr=0.000992, step_loss=0.407/27/2023 19:17:48 - INFO - __main__ - train loss is 41.87346266710665\n",
      "Steps:  73%|▋| 10902/15000 [1:32:58<12:37,  5.41it/s, lr=0.000992, step_loss=0.307/27/2023 19:17:48 - INFO - __main__ - train loss is 41.90996166446712\n",
      "Steps:  73%|▋| 10903/15000 [1:32:58<12:36,  5.41it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:48 - INFO - __main__ - train loss is 41.93029217177536\n",
      "Steps:  73%|▋| 10904/15000 [1:32:59<12:36,  5.42it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:48 - INFO - __main__ - train loss is 42.30412049347069\n",
      "Steps:  73%|▋| 10905/15000 [1:32:59<12:29,  5.46it/s, lr=0.000992, step_loss=0.307/27/2023 19:17:49 - INFO - __main__ - train loss is 42.310990569530986\n",
      "Steps:  73%|▋| 10906/15000 [1:32:59<12:31,  5.45it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:49 - INFO - __main__ - train loss is 42.337127651437186\n",
      "Steps:  73%|▋| 10907/15000 [1:32:59<12:28,  5.47it/s, lr=0.000992, step_loss=0.007/27/2023 19:17:49 - INFO - __main__ - train loss is 42.730684961541556\n",
      "Steps:  73%|▋| 10908/15000 [1:33:00<16:48,  4.06it/s, lr=0.000992, step_loss=0.307/27/2023 19:17:50 - INFO - __main__ - Per validation step average loss is 0.15601807832717896\n",
      "07/27/2023 19:17:50 - INFO - __main__ - Cumulative validation average loss is 0.15601807832717896\n",
      "07/27/2023 19:17:51 - INFO - __main__ - Per validation step average loss is 0.11043322086334229\n",
      "07/27/2023 19:17:51 - INFO - __main__ - Cumulative validation average loss is 0.26645129919052124\n",
      "07/27/2023 19:17:51 - INFO - __main__ - Per validation step average loss is 0.178340882062912\n",
      "07/27/2023 19:17:51 - INFO - __main__ - Cumulative validation average loss is 0.4447921812534332\n",
      "07/27/2023 19:17:51 - INFO - __main__ - Per validation step average loss is 0.0018543823389336467\n",
      "07/27/2023 19:17:51 - INFO - __main__ - Cumulative validation average loss is 0.4466465635923669\n",
      "07/27/2023 19:17:52 - INFO - __main__ - Per validation step average loss is 0.07417372614145279\n",
      "07/27/2023 19:17:52 - INFO - __main__ - Cumulative validation average loss is 0.5208202897338197\n",
      "07/27/2023 19:17:52 - INFO - __main__ - Per validation step average loss is 0.0022390102967619896\n",
      "07/27/2023 19:17:52 - INFO - __main__ - Cumulative validation average loss is 0.5230593000305817\n",
      "07/27/2023 19:17:53 - INFO - __main__ - Per validation step average loss is 0.304256796836853\n",
      "07/27/2023 19:17:53 - INFO - __main__ - Cumulative validation average loss is 0.8273160968674347\n",
      "07/27/2023 19:17:53 - INFO - __main__ - Per validation step average loss is 0.16354835033416748\n",
      "07/27/2023 19:17:53 - INFO - __main__ - Cumulative validation average loss is 0.9908644472016022\n",
      "07/27/2023 19:17:54 - INFO - __main__ - Per validation step average loss is 0.0335267037153244\n",
      "07/27/2023 19:17:54 - INFO - __main__ - Cumulative validation average loss is 1.0243911509169266\n",
      "07/27/2023 19:17:54 - INFO - __main__ - Per validation step average loss is 0.010531002655625343\n",
      "07/27/2023 19:17:54 - INFO - __main__ - Cumulative validation average loss is 1.034922153572552\n",
      "07/27/2023 19:17:54 - INFO - __main__ - Per validation step average loss is 0.029068581759929657\n",
      "07/27/2023 19:17:54 - INFO - __main__ - Cumulative validation average loss is 1.0639907353324816\n",
      "07/27/2023 19:17:55 - INFO - __main__ - Per validation step average loss is 0.011983342468738556\n",
      "07/27/2023 19:17:55 - INFO - __main__ - Cumulative validation average loss is 1.0759740778012201\n",
      "07/27/2023 19:17:55 - INFO - __main__ - Per validation step average loss is 0.0031318035908043385\n",
      "07/27/2023 19:17:55 - INFO - __main__ - Cumulative validation average loss is 1.0791058813920245\n",
      "07/27/2023 19:17:56 - INFO - __main__ - Per validation step average loss is 0.5402483344078064\n",
      "07/27/2023 19:17:56 - INFO - __main__ - Cumulative validation average loss is 1.6193542157998309\n",
      "07/27/2023 19:17:56 - INFO - __main__ - Per validation step average loss is 0.04160703718662262\n",
      "07/27/2023 19:17:56 - INFO - __main__ - Cumulative validation average loss is 1.6609612529864535\n",
      "07/27/2023 19:17:56 - INFO - __main__ - Per validation step average loss is 0.10612024366855621\n",
      "07/27/2023 19:17:56 - INFO - __main__ - Cumulative validation average loss is 1.7670814966550097\n",
      "07/27/2023 19:17:57 - INFO - __main__ - Per validation step average loss is 0.060217395424842834\n",
      "07/27/2023 19:17:57 - INFO - __main__ - Cumulative validation average loss is 1.8272988920798525\n",
      "07/27/2023 19:17:57 - INFO - __main__ - Per validation step average loss is 0.11441826820373535\n",
      "07/27/2023 19:17:57 - INFO - __main__ - Cumulative validation average loss is 1.9417171602835879\n",
      "07/27/2023 19:17:58 - INFO - __main__ - Per validation step average loss is 0.8440505266189575\n",
      "07/27/2023 19:17:58 - INFO - __main__ - Cumulative validation average loss is 2.7857676869025454\n",
      "07/27/2023 19:17:58 - INFO - __main__ - Per validation step average loss is 0.04996512085199356\n",
      "07/27/2023 19:17:58 - INFO - __main__ - Cumulative validation average loss is 2.835732807754539\n",
      "07/27/2023 19:17:59 - INFO - __main__ - Per validation step average loss is 0.003248578403145075\n",
      "07/27/2023 19:17:59 - INFO - __main__ - Cumulative validation average loss is 2.838981386157684\n",
      "07/27/2023 19:17:59 - INFO - __main__ - Per validation step average loss is 0.06722845137119293\n",
      "07/27/2023 19:17:59 - INFO - __main__ - Cumulative validation average loss is 2.906209837528877\n",
      "07/27/2023 19:17:59 - INFO - __main__ - Per validation step average loss is 0.43976402282714844\n",
      "07/27/2023 19:17:59 - INFO - __main__ - Cumulative validation average loss is 3.3459738603560254\n",
      "07/27/2023 19:18:00 - INFO - __main__ - Per validation step average loss is 0.46030330657958984\n",
      "07/27/2023 19:18:00 - INFO - __main__ - Cumulative validation average loss is 3.8062771669356152\n",
      "07/27/2023 19:18:00 - INFO - __main__ - Per validation step average loss is 0.46130383014678955\n",
      "07/27/2023 19:18:00 - INFO - __main__ - Cumulative validation average loss is 4.267580997082405\n",
      "07/27/2023 19:18:01 - INFO - __main__ - Per validation step average loss is 0.3003806471824646\n",
      "07/27/2023 19:18:01 - INFO - __main__ - Cumulative validation average loss is 4.567961644264869\n",
      "07/27/2023 19:18:01 - INFO - __main__ - Per validation step average loss is 0.14002074301242828\n",
      "07/27/2023 19:18:01 - INFO - __main__ - Cumulative validation average loss is 4.707982387277298\n",
      "07/27/2023 19:18:01 - INFO - __main__ - Per validation step average loss is 0.0749315470457077\n",
      "07/27/2023 19:18:01 - INFO - __main__ - Cumulative validation average loss is 4.782913934323005\n",
      "07/27/2023 19:18:02 - INFO - __main__ - Per validation step average loss is 0.025804217904806137\n",
      "07/27/2023 19:18:02 - INFO - __main__ - Cumulative validation average loss is 4.8087181522278115\n",
      "07/27/2023 19:18:02 - INFO - __main__ - Per validation step average loss is 0.0673709362745285\n",
      "07/27/2023 19:18:02 - INFO - __main__ - Cumulative validation average loss is 4.87608908850234\n",
      "07/27/2023 19:18:03 - INFO - __main__ - Per validation step average loss is 0.005283796228468418\n",
      "07/27/2023 19:18:03 - INFO - __main__ - Cumulative validation average loss is 4.881372884730808\n",
      "07/27/2023 19:18:03 - INFO - __main__ - Per validation step average loss is 0.015763869509100914\n",
      "07/27/2023 19:18:03 - INFO - __main__ - Cumulative validation average loss is 4.897136754239909\n",
      "07/27/2023 19:18:04 - INFO - __main__ - Per validation step average loss is 0.550098180770874\n",
      "07/27/2023 19:18:04 - INFO - __main__ - Cumulative validation average loss is 5.447234935010783\n",
      "07/27/2023 19:18:04 - INFO - __main__ - Per validation step average loss is 0.02487010508775711\n",
      "07/27/2023 19:18:04 - INFO - __main__ - Cumulative validation average loss is 5.4721050400985405\n",
      "07/27/2023 19:18:04 - INFO - __main__ - Per validation step average loss is 0.21126145124435425\n",
      "07/27/2023 19:18:04 - INFO - __main__ - Cumulative validation average loss is 5.683366491342895\n",
      "07/27/2023 19:18:05 - INFO - __main__ - Per validation step average loss is 0.018229007720947266\n",
      "07/27/2023 19:18:05 - INFO - __main__ - Cumulative validation average loss is 5.701595499063842\n",
      "07/27/2023 19:18:05 - INFO - __main__ - Per validation step average loss is 0.017185138538479805\n",
      "07/27/2023 19:18:05 - INFO - __main__ - Cumulative validation average loss is 5.718780637602322\n",
      "07/27/2023 19:18:06 - INFO - __main__ - Per validation step average loss is 0.013213960453867912\n",
      "07/27/2023 19:18:06 - INFO - __main__ - Cumulative validation average loss is 5.73199459805619\n",
      "07/27/2023 19:18:06 - INFO - __main__ - Per validation step average loss is 0.022227918729186058\n",
      "07/27/2023 19:18:06 - INFO - __main__ - Cumulative validation average loss is 5.754222516785376\n",
      "07/27/2023 19:18:06 - INFO - __main__ - Per validation step average loss is 0.02226729318499565\n",
      "07/27/2023 19:18:06 - INFO - __main__ - Cumulative validation average loss is 5.776489809970371\n",
      "07/27/2023 19:18:07 - INFO - __main__ - Per validation step average loss is 0.3408716320991516\n",
      "07/27/2023 19:18:07 - INFO - __main__ - Cumulative validation average loss is 6.117361442069523\n",
      "07/27/2023 19:18:07 - INFO - __main__ - Per validation step average loss is 0.011596176773309708\n",
      "07/27/2023 19:18:07 - INFO - __main__ - Cumulative validation average loss is 6.128957618842833\n",
      "07/27/2023 19:18:08 - INFO - __main__ - Per validation step average loss is 0.40653371810913086\n",
      "07/27/2023 19:18:08 - INFO - __main__ - Cumulative validation average loss is 6.535491336951964\n",
      "07/27/2023 19:18:08 - INFO - __main__ - Per validation step average loss is 0.05636734887957573\n",
      "07/27/2023 19:18:08 - INFO - __main__ - Cumulative validation average loss is 6.591858685831539\n",
      "07/27/2023 19:18:08 - INFO - __main__ - Per validation step average loss is 0.08795934915542603\n",
      "07/27/2023 19:18:08 - INFO - __main__ - Cumulative validation average loss is 6.679818034986965\n",
      "07/27/2023 19:18:09 - INFO - __main__ - Per validation step average loss is 0.0015832750359550118\n",
      "07/27/2023 19:18:09 - INFO - __main__ - Cumulative validation average loss is 6.68140131002292\n",
      "07/27/2023 19:18:09 - INFO - __main__ - Per validation step average loss is 0.10081746429204941\n",
      "07/27/2023 19:18:09 - INFO - __main__ - Cumulative validation average loss is 6.78221877431497\n",
      "07/27/2023 19:18:10 - INFO - __main__ - Per validation step average loss is 0.003464651061221957\n",
      "07/27/2023 19:18:10 - INFO - __main__ - Cumulative validation average loss is 6.785683425376192\n",
      "07/27/2023 19:18:10 - INFO - __main__ - Per validation step average loss is 0.3293743133544922\n",
      "07/27/2023 19:18:10 - INFO - __main__ - Cumulative validation average loss is 7.115057738730684\n",
      "07/27/2023 19:18:11 - INFO - __main__ - Per validation step average loss is 0.006080674007534981\n",
      "07/27/2023 19:18:11 - INFO - __main__ - Cumulative validation average loss is 7.121138412738219\n",
      "07/27/2023 19:18:11 - INFO - __main__ - Per validation step average loss is 0.011886393651366234\n",
      "07/27/2023 19:18:11 - INFO - __main__ - Cumulative validation average loss is 7.133024806389585\n",
      "07/27/2023 19:18:11 - INFO - __main__ - Per validation step average loss is 0.07054497301578522\n",
      "07/27/2023 19:18:11 - INFO - __main__ - Cumulative validation average loss is 7.20356977940537\n",
      "07/27/2023 19:18:12 - INFO - __main__ - Per validation step average loss is 0.3399336636066437\n",
      "07/27/2023 19:18:12 - INFO - __main__ - Cumulative validation average loss is 7.543503443012014\n",
      "07/27/2023 19:18:12 - INFO - __main__ - Per validation step average loss is 0.13850823044776917\n",
      "07/27/2023 19:18:12 - INFO - __main__ - Cumulative validation average loss is 7.682011673459783\n",
      "07/27/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.08912700414657593\n",
      "07/27/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 7.771138677606359\n",
      "07/27/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.009831772185862064\n",
      "07/27/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 7.780970449792221\n",
      "07/27/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.011379394680261612\n",
      "07/27/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 7.792349844472483\n",
      "07/27/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.005525057669728994\n",
      "07/27/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 7.797874902142212\n",
      "07/27/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.029080141335725784\n",
      "07/27/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 7.826955043477938\n",
      "07/27/2023 19:18:15 - INFO - __main__ - Per validation step average loss is 0.01978791505098343\n",
      "07/27/2023 19:18:15 - INFO - __main__ - Cumulative validation average loss is 7.846742958528921\n",
      "07/27/2023 19:18:15 - INFO - __main__ - Per validation step average loss is 0.16077348589897156\n",
      "07/27/2023 19:18:15 - INFO - __main__ - Cumulative validation average loss is 8.007516444427893\n",
      "07/27/2023 19:18:16 - INFO - __main__ - Per validation step average loss is 0.05640632286667824\n",
      "07/27/2023 19:18:16 - INFO - __main__ - Cumulative validation average loss is 8.06392276729457\n",
      "07/27/2023 19:18:16 - INFO - __main__ - Per validation step average loss is 0.005668368190526962\n",
      "07/27/2023 19:18:16 - INFO - __main__ - Cumulative validation average loss is 8.069591135485098\n",
      "07/27/2023 19:18:16 - INFO - __main__ - Per validation step average loss is 0.11853548884391785\n",
      "07/27/2023 19:18:16 - INFO - __main__ - Cumulative validation average loss is 8.188126624329016\n",
      "07/27/2023 19:18:17 - INFO - __main__ - Per validation step average loss is 0.14727771282196045\n",
      "07/27/2023 19:18:17 - INFO - __main__ - Cumulative validation average loss is 8.335404337150976\n",
      "07/27/2023 19:18:17 - INFO - __main__ - Per validation step average loss is 0.04302823543548584\n",
      "07/27/2023 19:18:17 - INFO - __main__ - Cumulative validation average loss is 8.378432572586462\n",
      "07/27/2023 19:18:18 - INFO - __main__ - Per validation step average loss is 0.12636232376098633\n",
      "07/27/2023 19:18:18 - INFO - __main__ - Cumulative validation average loss is 8.504794896347448\n",
      "07/27/2023 19:18:18 - INFO - __main__ - Per validation step average loss is 0.2671854496002197\n",
      "07/27/2023 19:18:18 - INFO - __main__ - Cumulative validation average loss is 8.771980345947668\n",
      "07/27/2023 19:18:18 - INFO - __main__ - Per validation step average loss is 0.010351656936109066\n",
      "07/27/2023 19:18:18 - INFO - __main__ - Cumulative validation average loss is 8.782332002883777\n",
      "07/27/2023 19:18:19 - INFO - __main__ - Per validation step average loss is 0.00860860850661993\n",
      "07/27/2023 19:18:19 - INFO - __main__ - Cumulative validation average loss is 8.790940611390397\n",
      "07/27/2023 19:18:19 - INFO - __main__ - Per validation step average loss is 0.4244975447654724\n",
      "07/27/2023 19:18:19 - INFO - __main__ - Cumulative validation average loss is 9.21543815615587\n",
      "07/27/2023 19:18:20 - INFO - __main__ - Per validation step average loss is 0.14426656067371368\n",
      "07/27/2023 19:18:20 - INFO - __main__ - Cumulative validation average loss is 9.359704716829583\n",
      "07/27/2023 19:18:20 - INFO - __main__ - Per validation step average loss is 0.24786925315856934\n",
      "07/27/2023 19:18:20 - INFO - __main__ - Cumulative validation average loss is 9.607573969988152\n",
      "07/27/2023 19:18:20 - INFO - __main__ - Per validation step average loss is 0.22979065775871277\n",
      "07/27/2023 19:18:20 - INFO - __main__ - Cumulative validation average loss is 9.837364627746865\n",
      "07/27/2023 19:18:21 - INFO - __main__ - Per validation step average loss is 0.35638096928596497\n",
      "07/27/2023 19:18:21 - INFO - __main__ - Cumulative validation average loss is 10.19374559703283\n",
      "07/27/2023 19:18:21 - INFO - __main__ - Per validation step average loss is 0.16814526915550232\n",
      "07/27/2023 19:18:21 - INFO - __main__ - Cumulative validation average loss is 10.361890866188332\n",
      "07/27/2023 19:18:22 - INFO - __main__ - Per validation step average loss is 0.013991598039865494\n",
      "07/27/2023 19:18:22 - INFO - __main__ - Cumulative validation average loss is 10.375882464228198\n",
      "07/27/2023 19:18:22 - INFO - __main__ - Per validation step average loss is 0.08926290273666382\n",
      "07/27/2023 19:18:22 - INFO - __main__ - Cumulative validation average loss is 10.465145366964862\n",
      "07/27/2023 19:18:23 - INFO - __main__ - Per validation step average loss is 0.006558533757925034\n",
      "07/27/2023 19:18:23 - INFO - __main__ - Cumulative validation average loss is 10.471703900722787\n",
      "07/27/2023 19:18:23 - INFO - __main__ - Average validation loss for Epoch 35 is 0.13255321393319983\n",
      "07/27/2023 19:18:23 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:19:20 - INFO - __main__ - Starting epoch 36\n",
      "07/27/2023 19:19:20 - INFO - __main__ - train loss is 0.3307911157608032\n",
      "Steps:  73%|▋| 10909/15000 [1:34:31<31:13:53, 27.48s/it, lr=0.000992, step_loss=07/27/2023 19:19:20 - INFO - __main__ - train loss is 0.355737978592515\n",
      "Steps:  73%|▋| 10910/15000 [1:34:31<21:55:09, 19.29s/it, lr=0.000992, step_loss=07/27/2023 19:19:21 - INFO - __main__ - train loss is 0.6941711250692606\n",
      "Steps:  73%|▋| 10911/15000 [1:34:31<15:24:02, 13.56s/it, lr=0.000992, step_loss=07/27/2023 19:19:21 - INFO - __main__ - train loss is 0.9192219618707895\n",
      "Steps:  73%|▋| 10912/15000 [1:34:31<10:50:26,  9.55s/it, lr=0.000992, step_loss=07/27/2023 19:19:21 - INFO - __main__ - train loss is 1.0739290360361338\n",
      "Steps:  73%|▋| 10913/15000 [1:34:31<7:38:53,  6.74s/it, lr=0.000992, step_loss=007/27/2023 19:19:21 - INFO - __main__ - train loss is 1.7208470944315195\n",
      "Steps:  73%|▋| 10914/15000 [1:34:31<5:24:51,  4.77s/it, lr=0.000992, step_loss=007/27/2023 19:19:21 - INFO - __main__ - train loss is 2.4857986215502024\n",
      "Steps:  73%|▋| 10915/15000 [1:34:32<3:51:05,  3.39s/it, lr=0.000992, step_loss=007/27/2023 19:19:22 - INFO - __main__ - train loss is 2.5171812307089567\n",
      "Steps:  73%|▋| 10916/15000 [1:34:32<2:45:22,  2.43s/it, lr=0.000992, step_loss=007/27/2023 19:19:22 - INFO - __main__ - train loss is 2.5278247697278857\n",
      "Steps:  73%|▋| 10917/15000 [1:34:32<1:59:23,  1.75s/it, lr=0.000992, step_loss=007/27/2023 19:19:22 - INFO - __main__ - train loss is 2.52925377630163\n",
      "Steps:  73%|▋| 10918/15000 [1:34:32<1:27:12,  1.28s/it, lr=0.000992, step_loss=007/27/2023 19:19:22 - INFO - __main__ - train loss is 2.5552186026470736\n",
      "Steps:  73%|▋| 10919/15000 [1:34:32<1:04:41,  1.05it/s, lr=0.000992, step_loss=007/27/2023 19:19:22 - INFO - __main__ - train loss is 2.6428518696920946\n",
      "Steps:  73%|▋| 10920/15000 [1:34:33<48:55,  1.39it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:22 - INFO - __main__ - train loss is 2.6480518352473155\n",
      "Steps:  73%|▋| 10921/15000 [1:34:33<37:53,  1.79it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:23 - INFO - __main__ - train loss is 2.8160166513407603\n",
      "Steps:  73%|▋| 10922/15000 [1:34:33<30:10,  2.25it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:23 - INFO - __main__ - train loss is 2.8498768095159903\n",
      "Steps:  73%|▋| 10923/15000 [1:34:33<24:50,  2.74it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:23 - INFO - __main__ - train loss is 2.902820225455798\n",
      "Steps:  73%|▋| 10924/15000 [1:34:33<21:02,  3.23it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:23 - INFO - __main__ - train loss is 3.197858627536334\n",
      "Steps:  73%|▋| 10925/15000 [1:34:33<18:22,  3.70it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:23 - INFO - __main__ - train loss is 3.200678003602661\n",
      "Steps:  73%|▋| 10926/15000 [1:34:34<16:31,  4.11it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:23 - INFO - __main__ - train loss is 3.207368068047799\n",
      "Steps:  73%|▋| 10927/15000 [1:34:34<15:13,  4.46it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:24 - INFO - __main__ - train loss is 3.260543815442361\n",
      "Steps:  73%|▋| 10928/15000 [1:34:34<14:18,  4.74it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:24 - INFO - __main__ - train loss is 3.6014594059670344\n",
      "Steps:  73%|▋| 10929/15000 [1:34:34<13:40,  4.96it/s, lr=0.000992, step_loss=0.307/27/2023 19:19:24 - INFO - __main__ - train loss is 3.604762581293471\n",
      "Steps:  73%|▋| 10930/15000 [1:34:34<13:13,  5.13it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:24 - INFO - __main__ - train loss is 3.6438999223755673\n",
      "Steps:  73%|▋| 10931/15000 [1:34:35<12:54,  5.25it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:24 - INFO - __main__ - train loss is 3.982495819334872\n",
      "Steps:  73%|▋| 10932/15000 [1:34:35<12:41,  5.34it/s, lr=0.000992, step_loss=0.307/27/2023 19:19:25 - INFO - __main__ - train loss is 4.276798402075656\n",
      "Steps:  73%|▋| 10933/15000 [1:34:35<12:31,  5.41it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:25 - INFO - __main__ - train loss is 4.296020127017982\n",
      "Steps:  73%|▋| 10934/15000 [1:34:35<12:25,  5.45it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:25 - INFO - __main__ - train loss is 4.474775320966728\n",
      "Steps:  73%|▋| 10935/15000 [1:34:35<12:20,  5.49it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:25 - INFO - __main__ - train loss is 4.660781777580269\n",
      "Steps:  73%|▋| 10936/15000 [1:34:35<12:17,  5.51it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:25 - INFO - __main__ - train loss is 4.694205365260132\n",
      "Steps:  73%|▋| 10937/15000 [1:34:36<12:15,  5.53it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:25 - INFO - __main__ - train loss is 4.712264224071987\n",
      "Steps:  73%|▋| 10938/15000 [1:34:36<12:19,  5.49it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:26 - INFO - __main__ - train loss is 4.720641230349429\n",
      "Steps:  73%|▋| 10939/15000 [1:34:36<12:15,  5.52it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:26 - INFO - __main__ - train loss is 4.768519912962802\n",
      "Steps:  73%|▋| 10940/15000 [1:34:36<12:13,  5.53it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:26 - INFO - __main__ - train loss is 4.788952161674388\n",
      "Steps:  73%|▋| 10941/15000 [1:34:36<12:11,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:26 - INFO - __main__ - train loss is 4.816089064930566\n",
      "Steps:  73%|▋| 10942/15000 [1:34:36<12:10,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:26 - INFO - __main__ - train loss is 4.9207661162363365\n",
      "Steps:  73%|▋| 10943/15000 [1:34:37<12:09,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:27 - INFO - __main__ - train loss is 4.924568183370866\n",
      "Steps:  73%|▋| 10944/15000 [1:34:37<12:09,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:27 - INFO - __main__ - train loss is 5.198532618233003\n",
      "Steps:  73%|▋| 10945/15000 [1:34:37<12:16,  5.51it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:27 - INFO - __main__ - train loss is 5.267479300149716\n",
      "Steps:  73%|▋| 10946/15000 [1:34:37<12:15,  5.51it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:27 - INFO - __main__ - train loss is 5.2801628556335345\n",
      "Steps:  73%|▋| 10947/15000 [1:34:37<12:24,  5.45it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:27 - INFO - __main__ - train loss is 5.560070678242482\n",
      "Steps:  73%|▋| 10948/15000 [1:34:38<12:36,  5.35it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:27 - INFO - __main__ - train loss is 5.561921935877763\n",
      "Steps:  73%|▋| 10949/15000 [1:34:38<12:47,  5.28it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:28 - INFO - __main__ - train loss is 5.5789002537494525\n",
      "Steps:  73%|▋| 10950/15000 [1:34:38<12:54,  5.23it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:28 - INFO - __main__ - train loss is 5.714881247258745\n",
      "Steps:  73%|▋| 10951/15000 [1:34:38<13:01,  5.18it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:28 - INFO - __main__ - train loss is 5.840931689715944\n",
      "Steps:  73%|▋| 10952/15000 [1:34:38<13:59,  4.82it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:28 - INFO - __main__ - train loss is 6.072809731937014\n",
      "Steps:  73%|▋| 10953/15000 [1:34:39<14:54,  4.52it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:29 - INFO - __main__ - train loss is 6.0744679886847734\n",
      "Steps:  73%|▋| 10954/15000 [1:34:39<14:26,  4.67it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:29 - INFO - __main__ - train loss is 6.239089163020253\n",
      "Steps:  73%|▋| 10955/15000 [1:34:39<14:13,  4.74it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:29 - INFO - __main__ - train loss is 6.269171187654138\n",
      "Steps:  73%|▋| 10956/15000 [1:34:39<13:55,  4.84it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:29 - INFO - __main__ - train loss is 6.43633327819407\n",
      "Steps:  73%|▋| 10957/15000 [1:34:39<13:34,  4.97it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:29 - INFO - __main__ - train loss is 6.43942368356511\n",
      "Steps:  73%|▋| 10958/15000 [1:34:40<13:16,  5.07it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:30 - INFO - __main__ - train loss is 6.46132881147787\n",
      "Steps:  73%|▋| 10959/15000 [1:34:40<12:59,  5.18it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:30 - INFO - __main__ - train loss is 6.6681650946848094\n",
      "Steps:  73%|▋| 10960/15000 [1:34:40<13:06,  5.14it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:30 - INFO - __main__ - train loss is 6.706068455707282\n",
      "Steps:  73%|▋| 10961/15000 [1:34:40<12:53,  5.22it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:30 - INFO - __main__ - train loss is 6.712649504188448\n",
      "Steps:  73%|▋| 10962/15000 [1:34:40<12:38,  5.32it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:30 - INFO - __main__ - train loss is 6.79677856201306\n",
      "Steps:  73%|▋| 10963/15000 [1:34:41<12:27,  5.40it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:30 - INFO - __main__ - train loss is 7.011624845210463\n",
      "Steps:  73%|▋| 10964/15000 [1:34:41<12:20,  5.45it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:31 - INFO - __main__ - train loss is 7.033693122211844\n",
      "Steps:  73%|▋| 10965/15000 [1:34:41<12:15,  5.49it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:31 - INFO - __main__ - train loss is 7.1139743202365935\n",
      "Steps:  73%|▋| 10966/15000 [1:34:41<12:11,  5.51it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:31 - INFO - __main__ - train loss is 7.401075439993292\n",
      "Steps:  73%|▋| 10967/15000 [1:34:41<12:09,  5.53it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:31 - INFO - __main__ - train loss is 7.425750514958054\n",
      "Steps:  73%|▋| 10968/15000 [1:34:41<12:07,  5.54it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:31 - INFO - __main__ - train loss is 7.596176645252854\n",
      "Steps:  73%|▋| 10969/15000 [1:34:42<12:06,  5.55it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:32 - INFO - __main__ - train loss is 7.763406789395958\n",
      "Steps:  73%|▋| 10970/15000 [1:34:42<12:05,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:32 - INFO - __main__ - train loss is 7.769515340682119\n",
      "Steps:  73%|▋| 10971/15000 [1:34:42<12:04,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:32 - INFO - __main__ - train loss is 7.928989177104086\n",
      "Steps:  73%|▋| 10972/15000 [1:34:42<12:06,  5.55it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:32 - INFO - __main__ - train loss is 8.24004984414205\n",
      "Steps:  73%|▋| 10973/15000 [1:34:42<12:05,  5.55it/s, lr=0.000992, step_loss=0.307/27/2023 19:19:32 - INFO - __main__ - train loss is 8.61602217471227\n",
      "Steps:  73%|▋| 10974/15000 [1:34:43<12:04,  5.56it/s, lr=0.000992, step_loss=0.307/27/2023 19:19:32 - INFO - __main__ - train loss is 8.620915822684765\n",
      "Steps:  73%|▋| 10975/15000 [1:34:43<12:04,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:33 - INFO - __main__ - train loss is 8.766880236566067\n",
      "Steps:  73%|▋| 10976/15000 [1:34:43<12:02,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:33 - INFO - __main__ - train loss is 8.771911883726716\n",
      "Steps:  73%|▋| 10977/15000 [1:34:43<12:04,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:33 - INFO - __main__ - train loss is 8.883335733786225\n",
      "Steps:  73%|▋| 10978/15000 [1:34:43<12:03,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:33 - INFO - __main__ - train loss is 8.886441560927778\n",
      "Steps:  73%|▋| 10979/15000 [1:34:43<12:05,  5.54it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:33 - INFO - __main__ - train loss is 8.893131963443011\n",
      "Steps:  73%|▋| 10980/15000 [1:34:44<12:04,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:34 - INFO - __main__ - train loss is 8.898165868595243\n",
      "Steps:  73%|▋| 10981/15000 [1:34:44<12:03,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:34 - INFO - __main__ - train loss is 9.113276155665517\n",
      "Steps:  73%|▋| 10982/15000 [1:34:44<12:03,  5.55it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:34 - INFO - __main__ - train loss is 9.115203907247633\n",
      "Steps:  73%|▋| 10983/15000 [1:34:44<12:02,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:34 - INFO - __main__ - train loss is 9.366403212305158\n",
      "Steps:  73%|▋| 10984/15000 [1:34:44<12:03,  5.55it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:34 - INFO - __main__ - train loss is 9.466767480131239\n",
      "Steps:  73%|▋| 10985/15000 [1:34:45<12:02,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:34 - INFO - __main__ - train loss is 9.479523297864944\n",
      "Steps:  73%|▋| 10986/15000 [1:34:45<12:03,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:35 - INFO - __main__ - train loss is 9.56526766391471\n",
      "Steps:  73%|▋| 10987/15000 [1:34:45<12:02,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:35 - INFO - __main__ - train loss is 9.620409686584026\n",
      "Steps:  73%|▋| 10988/15000 [1:34:45<12:08,  5.51it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:35 - INFO - __main__ - train loss is 9.766757045406848\n",
      "Steps:  73%|▋| 10989/15000 [1:34:45<12:06,  5.52it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:35 - INFO - __main__ - train loss is 9.769802792230621\n",
      "Steps:  73%|▋| 10990/15000 [1:34:45<12:04,  5.53it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:35 - INFO - __main__ - train loss is 9.79513910622336\n",
      "Steps:  73%|▋| 10991/15000 [1:34:46<12:05,  5.53it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:35 - INFO - __main__ - train loss is 9.925118508050218\n",
      "Steps:  73%|▋| 10992/15000 [1:34:46<12:03,  5.54it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:36 - INFO - __main__ - train loss is 10.143554510781541\n",
      "Steps:  73%|▋| 10993/15000 [1:34:46<12:02,  5.55it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:36 - INFO - __main__ - train loss is 10.165685350308195\n",
      "Steps:  73%|▋| 10994/15000 [1:34:46<12:01,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:36 - INFO - __main__ - train loss is 10.350489670643583\n",
      "Steps:  73%|▋| 10995/15000 [1:34:46<12:00,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:36 - INFO - __main__ - train loss is 10.634297186741605\n",
      "Steps:  73%|▋| 10996/15000 [1:34:47<12:01,  5.55it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:36 - INFO - __main__ - train loss is 10.64304490503855\n",
      "Steps:  73%|▋| 10997/15000 [1:34:47<12:00,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:37 - INFO - __main__ - train loss is 10.705590219469741\n",
      "Steps:  73%|▋| 10998/15000 [1:34:47<12:02,  5.54it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:37 - INFO - __main__ - train loss is 10.843533502193168\n",
      "Steps:  73%|▋| 10999/15000 [1:34:47<12:00,  5.55it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:37 - INFO - __main__ - train loss is 10.846493217162788\n",
      "Steps:  73%|▋| 11000/15000 [1:34:47<11:59,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:37 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-11000\n",
      "07/27/2023 19:19:37 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:19:37,515] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:19:37,520] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-11000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:19:37,520] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-11000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:19:37,526] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-11000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:19:37,527] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-11000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:19:37,533] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-11000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:19:37,533] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-11000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:19:37,534] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:19:37 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-11000/pytorch_model\n",
      "07/27/2023 19:19:37 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-11000/scheduler.bin\n",
      "07/27/2023 19:19:37 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-11000/random_states_0.pkl\n",
      "07/27/2023 19:19:37 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-11000\n",
      "Steps:  73%|▋| 11000/15000 [1:34:47<11:59,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:37 - INFO - __main__ - train loss is 11.023367556743324\n",
      "Steps:  73%|▋| 11001/15000 [1:34:47<12:22,  5.38it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:37 - INFO - __main__ - train loss is 11.026219453662634\n",
      "Steps:  73%|▋| 11002/15000 [1:34:48<12:14,  5.44it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:37 - INFO - __main__ - train loss is 11.054311484098434\n",
      "Steps:  73%|▋| 11003/15000 [1:34:48<12:09,  5.48it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:38 - INFO - __main__ - train loss is 11.062381647527218\n",
      "Steps:  73%|▋| 11004/15000 [1:34:48<12:06,  5.50it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:38 - INFO - __main__ - train loss is 11.070071370806545\n",
      "Steps:  73%|▋| 11005/15000 [1:34:48<12:06,  5.50it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:38 - INFO - __main__ - train loss is 11.27853258093819\n",
      "Steps:  73%|▋| 11006/15000 [1:34:48<12:05,  5.50it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:38 - INFO - __main__ - train loss is 11.284914226271212\n",
      "Steps:  73%|▋| 11007/15000 [1:34:49<12:02,  5.53it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:38 - INFO - __main__ - train loss is 11.537474454380572\n",
      "Steps:  73%|▋| 11008/15000 [1:34:49<12:06,  5.50it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:39 - INFO - __main__ - train loss is 11.74292051885277\n",
      "Steps:  73%|▋| 11009/15000 [1:34:49<12:03,  5.52it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:39 - INFO - __main__ - train loss is 11.89380265865475\n",
      "Steps:  73%|▋| 11010/15000 [1:34:49<12:01,  5.53it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:39 - INFO - __main__ - train loss is 12.396585420705378\n",
      "Steps:  73%|▋| 11011/15000 [1:34:49<12:00,  5.53it/s, lr=0.000992, step_loss=0.507/27/2023 19:19:39 - INFO - __main__ - train loss is 12.639395670033991\n",
      "Steps:  73%|▋| 11012/15000 [1:34:49<11:59,  5.54it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:39 - INFO - __main__ - train loss is 12.65205442532897\n",
      "Steps:  73%|▋| 11013/15000 [1:34:50<11:58,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:39 - INFO - __main__ - train loss is 12.662355212494731\n",
      "Steps:  73%|▋| 11014/15000 [1:34:50<11:57,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:40 - INFO - __main__ - train loss is 12.708792580291629\n",
      "Steps:  73%|▋| 11015/15000 [1:34:50<11:57,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:40 - INFO - __main__ - train loss is 12.763197241351008\n",
      "Steps:  73%|▋| 11016/15000 [1:34:50<11:56,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:40 - INFO - __main__ - train loss is 12.779968338087201\n",
      "Steps:  73%|▋| 11017/15000 [1:34:50<11:56,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:40 - INFO - __main__ - train loss is 12.947853254154325\n",
      "Steps:  73%|▋| 11018/15000 [1:34:50<11:55,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:40 - INFO - __main__ - train loss is 12.949232916813344\n",
      "Steps:  73%|▋| 11019/15000 [1:34:51<11:55,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:41 - INFO - __main__ - train loss is 13.036435167770833\n",
      "Steps:  73%|▋| 11020/15000 [1:34:51<11:55,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:41 - INFO - __main__ - train loss is 13.05216434923932\n",
      "Steps:  73%|▋| 11021/15000 [1:34:51<11:55,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:41 - INFO - __main__ - train loss is 13.073503419291228\n",
      "Steps:  73%|▋| 11022/15000 [1:34:51<11:55,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:41 - INFO - __main__ - train loss is 13.075970337959006\n",
      "Steps:  73%|▋| 11023/15000 [1:34:51<11:55,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:41 - INFO - __main__ - train loss is 13.237434135051444\n",
      "Steps:  73%|▋| 11024/15000 [1:34:52<11:55,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:41 - INFO - __main__ - train loss is 13.262116334633902\n",
      "Steps:  74%|▋| 11025/15000 [1:34:52<11:54,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:42 - INFO - __main__ - train loss is 13.311493172543123\n",
      "Steps:  74%|▋| 11026/15000 [1:34:52<11:54,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:42 - INFO - __main__ - train loss is 13.314262674190104\n",
      "Steps:  74%|▋| 11027/15000 [1:34:52<11:54,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:42 - INFO - __main__ - train loss is 13.345696502365172\n",
      "Steps:  74%|▋| 11028/15000 [1:34:52<11:53,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:42 - INFO - __main__ - train loss is 13.978773766197264\n",
      "Steps:  74%|▋| 11029/15000 [1:34:52<11:53,  5.57it/s, lr=0.000992, step_loss=0.607/27/2023 19:19:42 - INFO - __main__ - train loss is 13.985107876360416\n",
      "Steps:  74%|▋| 11030/15000 [1:34:53<11:53,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:43 - INFO - __main__ - train loss is 14.345121718943119\n",
      "Steps:  74%|▋| 11031/15000 [1:34:53<11:52,  5.57it/s, lr=0.000992, step_loss=0.307/27/2023 19:19:43 - INFO - __main__ - train loss is 14.390642046928406\n",
      "Steps:  74%|▋| 11032/15000 [1:34:53<11:52,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:43 - INFO - __main__ - train loss is 14.397726092021912\n",
      "Steps:  74%|▋| 11033/15000 [1:34:53<11:52,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:43 - INFO - __main__ - train loss is 14.40044296393171\n",
      "Steps:  74%|▋| 11034/15000 [1:34:53<11:52,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:43 - INFO - __main__ - train loss is 14.887878513429314\n",
      "Steps:  74%|▋| 11035/15000 [1:34:54<11:51,  5.57it/s, lr=0.000992, step_loss=0.407/27/2023 19:19:43 - INFO - __main__ - train loss is 14.954242444131523\n",
      "Steps:  74%|▋| 11036/15000 [1:34:54<11:51,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:44 - INFO - __main__ - train loss is 15.121330237481743\n",
      "Steps:  74%|▋| 11037/15000 [1:34:54<11:50,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:44 - INFO - __main__ - train loss is 15.220708450768143\n",
      "Steps:  74%|▋| 11038/15000 [1:34:54<11:50,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:44 - INFO - __main__ - train loss is 15.227940743323416\n",
      "Steps:  74%|▋| 11039/15000 [1:34:54<11:50,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:44 - INFO - __main__ - train loss is 15.240797049831599\n",
      "Steps:  74%|▋| 11040/15000 [1:34:54<11:50,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:44 - INFO - __main__ - train loss is 15.24331229319796\n",
      "Steps:  74%|▋| 11041/15000 [1:34:55<11:50,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:45 - INFO - __main__ - train loss is 15.373544925358146\n",
      "Steps:  74%|▋| 11042/15000 [1:34:55<11:50,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:45 - INFO - __main__ - train loss is 15.618470215704292\n",
      "Steps:  74%|▋| 11043/15000 [1:34:55<11:50,  5.57it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:45 - INFO - __main__ - train loss is 15.726884075906128\n",
      "Steps:  74%|▋| 11044/15000 [1:34:55<11:50,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:45 - INFO - __main__ - train loss is 15.839678259100765\n",
      "Steps:  74%|▋| 11045/15000 [1:34:55<11:49,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:45 - INFO - __main__ - train loss is 15.84146813233383\n",
      "Steps:  74%|▋| 11046/15000 [1:34:56<11:49,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:45 - INFO - __main__ - train loss is 16.276202298002318\n",
      "Steps:  74%|▋| 11047/15000 [1:34:56<11:49,  5.57it/s, lr=0.000992, step_loss=0.407/27/2023 19:19:46 - INFO - __main__ - train loss is 16.36741508473642\n",
      "Steps:  74%|▋| 11048/15000 [1:34:56<11:49,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:46 - INFO - __main__ - train loss is 16.44757180591114\n",
      "Steps:  74%|▋| 11049/15000 [1:34:56<11:49,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:46 - INFO - __main__ - train loss is 16.808800867991522\n",
      "Steps:  74%|▋| 11050/15000 [1:34:56<11:49,  5.57it/s, lr=0.000992, step_loss=0.307/27/2023 19:19:46 - INFO - __main__ - train loss is 16.9280485578347\n",
      "Steps:  74%|▋| 11051/15000 [1:34:56<11:48,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:46 - INFO - __main__ - train loss is 16.94838450406678\n",
      "Steps:  74%|▋| 11052/15000 [1:34:57<11:48,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:46 - INFO - __main__ - train loss is 17.190183396684006\n",
      "Steps:  74%|▋| 11053/15000 [1:34:57<11:48,  5.57it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:47 - INFO - __main__ - train loss is 17.31661097262986\n",
      "Steps:  74%|▋| 11054/15000 [1:34:57<11:48,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:47 - INFO - __main__ - train loss is 17.495918731437996\n",
      "Steps:  74%|▋| 11055/15000 [1:34:57<11:55,  5.51it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:47 - INFO - __main__ - train loss is 17.500066542299464\n",
      "Steps:  74%|▋| 11056/15000 [1:34:57<11:59,  5.48it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:47 - INFO - __main__ - train loss is 17.511618512915447\n",
      "Steps:  74%|▋| 11057/15000 [1:34:58<11:55,  5.51it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:47 - INFO - __main__ - train loss is 17.561499818461016\n",
      "Steps:  74%|▋| 11058/15000 [1:34:58<11:53,  5.53it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:48 - INFO - __main__ - train loss is 17.563738990109414\n",
      "Steps:  74%|▋| 11059/15000 [1:34:58<11:51,  5.54it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:48 - INFO - __main__ - train loss is 17.794693786185235\n",
      "Steps:  74%|▋| 11060/15000 [1:34:58<11:50,  5.55it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:48 - INFO - __main__ - train loss is 17.801123212557286\n",
      "Steps:  74%|▋| 11061/15000 [1:34:58<11:49,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:48 - INFO - __main__ - train loss is 17.814085613470525\n",
      "Steps:  74%|▋| 11062/15000 [1:34:58<11:49,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:48 - INFO - __main__ - train loss is 17.817902189679444\n",
      "Steps:  74%|▋| 11063/15000 [1:34:59<11:48,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:48 - INFO - __main__ - train loss is 17.966736403293908\n",
      "Steps:  74%|▋| 11064/15000 [1:34:59<11:47,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:49 - INFO - __main__ - train loss is 18.116238814778626\n",
      "Steps:  74%|▋| 11065/15000 [1:34:59<11:47,  5.56it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:49 - INFO - __main__ - train loss is 18.1916993977502\n",
      "Steps:  74%|▋| 11066/15000 [1:34:59<11:47,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:49 - INFO - __main__ - train loss is 18.445892435498536\n",
      "Steps:  74%|▋| 11067/15000 [1:34:59<11:46,  5.57it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:49 - INFO - __main__ - train loss is 18.492986728437245\n",
      "Steps:  74%|▋| 11068/15000 [1:34:59<11:46,  5.57it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:49 - INFO - __main__ - train loss is 18.679047097451985\n",
      "Steps:  74%|▋| 11069/15000 [1:35:00<11:46,  5.57it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:50 - INFO - __main__ - train loss is 18.685967065393925\n",
      "Steps:  74%|▋| 11070/15000 [1:35:00<11:46,  5.56it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:50 - INFO - __main__ - train loss is 18.852483995258808\n",
      "Steps:  74%|▋| 11071/15000 [1:35:00<11:48,  5.54it/s, lr=0.000992, step_loss=0.107/27/2023 19:19:50 - INFO - __main__ - train loss is 19.233849354088306\n",
      "Steps:  74%|▋| 11072/15000 [1:35:00<11:47,  5.55it/s, lr=0.000992, step_loss=0.307/27/2023 19:19:50 - INFO - __main__ - train loss is 19.313109256327152\n",
      "Steps:  74%|▋| 11073/15000 [1:35:00<11:47,  5.55it/s, lr=0.000992, step_loss=0.007/27/2023 19:19:50 - INFO - __main__ - train loss is 19.586568392813206\n",
      "Steps:  74%|▋| 11074/15000 [1:35:01<11:46,  5.56it/s, lr=0.000992, step_loss=0.207/27/2023 19:19:50 - INFO - __main__ - train loss is 19.613638328388333\n",
      "Steps:  74%|▋| 11075/15000 [1:35:01<11:45,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:51 - INFO - __main__ - train loss is 19.838669853284955\n",
      "Steps:  74%|▋| 11076/15000 [1:35:01<11:45,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:19:51 - INFO - __main__ - train loss is 19.870522433891892\n",
      "Steps:  74%|▋| 11077/15000 [1:35:01<11:45,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:51 - INFO - __main__ - train loss is 20.448401445522904\n",
      "Steps:  74%|▋| 11078/15000 [1:35:01<11:47,  5.55it/s, lr=0.000991, step_loss=0.507/27/2023 19:19:51 - INFO - __main__ - train loss is 20.89300643838942\n",
      "Steps:  74%|▋| 11079/15000 [1:35:01<11:46,  5.55it/s, lr=0.000991, step_loss=0.407/27/2023 19:19:51 - INFO - __main__ - train loss is 21.031877214089036\n",
      "Steps:  74%|▋| 11080/15000 [1:35:02<11:46,  5.55it/s, lr=0.000991, step_loss=0.107/27/2023 19:19:52 - INFO - __main__ - train loss is 21.046519136056304\n",
      "Steps:  74%|▋| 11081/15000 [1:35:02<11:45,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:52 - INFO - __main__ - train loss is 21.598926400765777\n",
      "Steps:  74%|▋| 11082/15000 [1:35:02<11:45,  5.56it/s, lr=0.000991, step_loss=0.507/27/2023 19:19:52 - INFO - __main__ - train loss is 21.647220076993108\n",
      "Steps:  74%|▋| 11083/15000 [1:35:02<11:44,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:52 - INFO - __main__ - train loss is 21.690380277112126\n",
      "Steps:  74%|▋| 11084/15000 [1:35:02<11:44,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:52 - INFO - __main__ - train loss is 21.82186654396355\n",
      "Steps:  74%|▋| 11085/15000 [1:35:03<11:44,  5.56it/s, lr=0.000991, step_loss=0.107/27/2023 19:19:52 - INFO - __main__ - train loss is 21.9717407990247\n",
      "Steps:  74%|▋| 11086/15000 [1:35:03<11:43,  5.56it/s, lr=0.000991, step_loss=0.107/27/2023 19:19:53 - INFO - __main__ - train loss is 21.975033829919994\n",
      "Steps:  74%|▋| 11087/15000 [1:35:03<11:42,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:53 - INFO - __main__ - train loss is 22.007444850169122\n",
      "Steps:  74%|▋| 11088/15000 [1:35:03<11:42,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:53 - INFO - __main__ - train loss is 22.013126271776855\n",
      "Steps:  74%|▋| 11089/15000 [1:35:03<11:42,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:53 - INFO - __main__ - train loss is 22.080479758791625\n",
      "Steps:  74%|▋| 11090/15000 [1:35:03<11:43,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:53 - INFO - __main__ - train loss is 22.118201467208564\n",
      "Steps:  74%|▋| 11091/15000 [1:35:04<11:43,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:53 - INFO - __main__ - train loss is 22.388578119687736\n",
      "Steps:  74%|▋| 11092/15000 [1:35:04<11:43,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:19:54 - INFO - __main__ - train loss is 22.498841213993728\n",
      "Steps:  74%|▋| 11093/15000 [1:35:04<11:43,  5.55it/s, lr=0.000991, step_loss=0.107/27/2023 19:19:54 - INFO - __main__ - train loss is 22.728858727030456\n",
      "Steps:  74%|▋| 11094/15000 [1:35:04<11:42,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:19:54 - INFO - __main__ - train loss is 22.740386527962983\n",
      "Steps:  74%|▋| 11095/15000 [1:35:04<11:44,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:54 - INFO - __main__ - train loss is 22.74562876764685\n",
      "Steps:  74%|▋| 11096/15000 [1:35:05<11:43,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:54 - INFO - __main__ - train loss is 22.771063190884888\n",
      "Steps:  74%|▋| 11097/15000 [1:35:05<11:44,  5.54it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:55 - INFO - __main__ - train loss is 23.20309237856418\n",
      "Steps:  74%|▋| 11098/15000 [1:35:05<11:43,  5.54it/s, lr=0.000991, step_loss=0.407/27/2023 19:19:55 - INFO - __main__ - train loss is 23.225292888469994\n",
      "Steps:  74%|▋| 11099/15000 [1:35:05<11:42,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:55 - INFO - __main__ - train loss is 23.532112506218255\n",
      "Steps:  74%|▋| 11100/15000 [1:35:05<11:42,  5.55it/s, lr=0.000991, step_loss=0.307/27/2023 19:19:55 - INFO - __main__ - train loss is 23.542436541058123\n",
      "Steps:  74%|▋| 11101/15000 [1:35:05<11:41,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:55 - INFO - __main__ - train loss is 23.546623142436147\n",
      "Steps:  74%|▋| 11102/15000 [1:35:06<11:42,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:55 - INFO - __main__ - train loss is 23.598941715434194\n",
      "Steps:  74%|▋| 11103/15000 [1:35:06<11:41,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:56 - INFO - __main__ - train loss is 24.125149639323354\n",
      "Steps:  74%|▋| 11104/15000 [1:35:06<11:43,  5.54it/s, lr=0.000991, step_loss=0.507/27/2023 19:19:56 - INFO - __main__ - train loss is 24.12822821061127\n",
      "Steps:  74%|▋| 11105/15000 [1:35:06<11:42,  5.54it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:56 - INFO - __main__ - train loss is 24.41010179440491\n",
      "Steps:  74%|▋| 11106/15000 [1:35:06<11:41,  5.55it/s, lr=0.000991, step_loss=0.207/27/2023 19:19:56 - INFO - __main__ - train loss is 24.51323835621588\n",
      "Steps:  74%|▋| 11107/15000 [1:35:07<11:42,  5.54it/s, lr=0.000991, step_loss=0.107/27/2023 19:19:56 - INFO - __main__ - train loss is 24.51718731201254\n",
      "Steps:  74%|▋| 11108/15000 [1:35:07<11:41,  5.54it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:57 - INFO - __main__ - train loss is 24.653611182933673\n",
      "Steps:  74%|▋| 11109/15000 [1:35:07<11:41,  5.55it/s, lr=0.000991, step_loss=0.107/27/2023 19:19:57 - INFO - __main__ - train loss is 25.15269613242708\n",
      "Steps:  74%|▋| 11110/15000 [1:35:07<11:40,  5.55it/s, lr=0.000991, step_loss=0.407/27/2023 19:19:57 - INFO - __main__ - train loss is 25.160076536005363\n",
      "Steps:  74%|▋| 11111/15000 [1:35:07<11:39,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:57 - INFO - __main__ - train loss is 25.35327250487171\n",
      "Steps:  74%|▋| 11112/15000 [1:35:07<11:38,  5.56it/s, lr=0.000991, step_loss=0.107/27/2023 19:19:57 - INFO - __main__ - train loss is 25.990118272369727\n",
      "Steps:  74%|▋| 11113/15000 [1:35:08<11:38,  5.56it/s, lr=0.000991, step_loss=0.607/27/2023 19:19:57 - INFO - __main__ - train loss is 26.303851075237617\n",
      "Steps:  74%|▋| 11114/15000 [1:35:08<11:41,  5.54it/s, lr=0.000991, step_loss=0.307/27/2023 19:19:58 - INFO - __main__ - train loss is 26.98447734839283\n",
      "Steps:  74%|▋| 11115/15000 [1:35:08<11:40,  5.54it/s, lr=0.000991, step_loss=0.607/27/2023 19:19:58 - INFO - __main__ - train loss is 26.985928514623083\n",
      "Steps:  74%|▋| 11116/15000 [1:35:08<11:39,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:58 - INFO - __main__ - train loss is 26.991310880170204\n",
      "Steps:  74%|▋| 11117/15000 [1:35:08<11:39,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:58 - INFO - __main__ - train loss is 27.014296040521003\n",
      "Steps:  74%|▋| 11118/15000 [1:35:08<11:38,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:58 - INFO - __main__ - train loss is 27.030762987793423\n",
      "Steps:  74%|▋| 11119/15000 [1:35:09<11:37,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:59 - INFO - __main__ - train loss is 27.413772242725827\n",
      "Steps:  74%|▋| 11120/15000 [1:35:09<11:37,  5.56it/s, lr=0.000991, step_loss=0.307/27/2023 19:19:59 - INFO - __main__ - train loss is 27.42768841201905\n",
      "Steps:  74%|▋| 11121/15000 [1:35:09<11:37,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:59 - INFO - __main__ - train loss is 27.779009095975198\n",
      "Steps:  74%|▋| 11122/15000 [1:35:09<11:37,  5.56it/s, lr=0.000991, step_loss=0.307/27/2023 19:19:59 - INFO - __main__ - train loss is 27.78106535144616\n",
      "Steps:  74%|▋| 11123/15000 [1:35:09<11:36,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:59 - INFO - __main__ - train loss is 27.7898575469153\n",
      "Steps:  74%|▋| 11124/15000 [1:35:10<11:36,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:19:59 - INFO - __main__ - train loss is 27.85610629164148\n",
      "Steps:  74%|▋| 11125/15000 [1:35:10<11:36,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:00 - INFO - __main__ - train loss is 27.869312754948623\n",
      "Steps:  74%|▋| 11126/15000 [1:35:10<11:36,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:00 - INFO - __main__ - train loss is 28.247804365237243\n",
      "Steps:  74%|▋| 11127/15000 [1:35:10<11:36,  5.56it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:00 - INFO - __main__ - train loss is 28.642431876738556\n",
      "Steps:  74%|▋| 11128/15000 [1:35:10<11:36,  5.56it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:00 - INFO - __main__ - train loss is 28.64576608024072\n",
      "Steps:  74%|▋| 11129/15000 [1:35:10<11:36,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:00 - INFO - __main__ - train loss is 28.705366649548523\n",
      "Steps:  74%|▋| 11130/15000 [1:35:11<11:36,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:01 - INFO - __main__ - train loss is 29.020017661969177\n",
      "Steps:  74%|▋| 11131/15000 [1:35:11<11:36,  5.56it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:01 - INFO - __main__ - train loss is 29.078285851399414\n",
      "Steps:  74%|▋| 11132/15000 [1:35:11<11:38,  5.54it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:01 - INFO - __main__ - train loss is 29.163344778935425\n",
      "Steps:  74%|▋| 11133/15000 [1:35:11<11:39,  5.52it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:01 - INFO - __main__ - train loss is 29.402018078486435\n",
      "Steps:  74%|▋| 11134/15000 [1:35:11<11:41,  5.51it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:01 - INFO - __main__ - train loss is 29.428183625335805\n",
      "Steps:  74%|▋| 11135/15000 [1:35:12<11:42,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:01 - INFO - __main__ - train loss is 29.42946589027997\n",
      "Steps:  74%|▋| 11136/15000 [1:35:12<11:42,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:02 - INFO - __main__ - train loss is 29.652377784601413\n",
      "Steps:  74%|▋| 11137/15000 [1:35:12<11:42,  5.50it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:02 - INFO - __main__ - train loss is 29.720653653494082\n",
      "Steps:  74%|▋| 11138/15000 [1:35:12<11:42,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:02 - INFO - __main__ - train loss is 29.775508832535706\n",
      "Steps:  74%|▋| 11139/15000 [1:35:12<11:42,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:02 - INFO - __main__ - train loss is 30.138245594105683\n",
      "Steps:  74%|▋| 11140/15000 [1:35:12<11:42,  5.49it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:02 - INFO - __main__ - train loss is 30.191403366974555\n",
      "Steps:  74%|▋| 11141/15000 [1:35:13<11:42,  5.49it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:03 - INFO - __main__ - train loss is 30.432107083848678\n",
      "Steps:  74%|▋| 11142/15000 [1:35:13<11:42,  5.49it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:03 - INFO - __main__ - train loss is 30.78496383910533\n",
      "Steps:  74%|▋| 11143/15000 [1:35:13<11:49,  5.44it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:03 - INFO - __main__ - train loss is 30.80895890702959\n",
      "Steps:  74%|▋| 11144/15000 [1:35:13<11:46,  5.46it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:03 - INFO - __main__ - train loss is 31.150912065408193\n",
      "Steps:  74%|▋| 11145/15000 [1:35:13<11:41,  5.49it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:03 - INFO - __main__ - train loss is 31.176822815439664\n",
      "Steps:  74%|▋| 11146/15000 [1:35:14<11:38,  5.52it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:03 - INFO - __main__ - train loss is 31.24897170474287\n",
      "Steps:  74%|▋| 11147/15000 [1:35:14<11:36,  5.53it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:04 - INFO - __main__ - train loss is 31.275565067655407\n",
      "Steps:  74%|▋| 11148/15000 [1:35:14<11:34,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:04 - INFO - __main__ - train loss is 31.278320888173766\n",
      "Steps:  74%|▋| 11149/15000 [1:35:14<11:33,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:04 - INFO - __main__ - train loss is 31.299963886034675\n",
      "Steps:  74%|▋| 11150/15000 [1:35:14<11:32,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:04 - INFO - __main__ - train loss is 31.55643855978269\n",
      "Steps:  74%|▋| 11151/15000 [1:35:14<11:32,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:04 - INFO - __main__ - train loss is 31.56639775459189\n",
      "Steps:  74%|▋| 11152/15000 [1:35:15<11:32,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:05 - INFO - __main__ - train loss is 31.97173449222464\n",
      "Steps:  74%|▋| 11153/15000 [1:35:15<11:34,  5.54it/s, lr=0.000991, step_loss=0.407/27/2023 19:20:05 - INFO - __main__ - train loss is 32.12338870589156\n",
      "Steps:  74%|▋| 11154/15000 [1:35:15<11:35,  5.53it/s, lr=0.000991, step_loss=0.107/27/2023 19:20:05 - INFO - __main__ - train loss is 32.42586487357039\n",
      "Steps:  74%|▋| 11155/15000 [1:35:15<11:37,  5.51it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:05 - INFO - __main__ - train loss is 32.43241870973725\n",
      "Steps:  74%|▋| 11156/15000 [1:35:15<11:39,  5.49it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:05 - INFO - __main__ - train loss is 32.43565274833236\n",
      "Steps:  74%|▋| 11157/15000 [1:35:16<11:46,  5.44it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:05 - INFO - __main__ - train loss is 32.43784281902481\n",
      "Steps:  74%|▋| 11158/15000 [1:35:16<11:53,  5.39it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:06 - INFO - __main__ - train loss is 32.496318317134865\n",
      "Steps:  74%|▋| 11159/15000 [1:35:16<11:48,  5.42it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:06 - INFO - __main__ - train loss is 32.50166814925615\n",
      "Steps:  74%|▋| 11160/15000 [1:35:16<11:43,  5.46it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:06 - INFO - __main__ - train loss is 32.51067433471326\n",
      "Steps:  74%|▋| 11161/15000 [1:35:16<11:45,  5.44it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:06 - INFO - __main__ - train loss is 32.52366797497962\n",
      "Steps:  74%|▋| 11162/15000 [1:35:16<11:42,  5.46it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:06 - INFO - __main__ - train loss is 32.54775146080647\n",
      "Steps:  74%|▋| 11163/15000 [1:35:17<11:38,  5.49it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:07 - INFO - __main__ - train loss is 33.008142624632455\n",
      "Steps:  74%|▋| 11164/15000 [1:35:17<11:36,  5.51it/s, lr=0.000991, step_loss=0.407/27/2023 19:20:07 - INFO - __main__ - train loss is 33.359738443628885\n",
      "Steps:  74%|▋| 11165/15000 [1:35:17<11:34,  5.52it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:07 - INFO - __main__ - train loss is 33.413662568316795\n",
      "Steps:  74%|▋| 11166/15000 [1:35:17<11:32,  5.53it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:07 - INFO - __main__ - train loss is 33.662839785800315\n",
      "Steps:  74%|▋| 11167/15000 [1:35:17<11:31,  5.54it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:07 - INFO - __main__ - train loss is 33.74772413133178\n",
      "Steps:  74%|▋| 11168/15000 [1:35:18<11:30,  5.55it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:07 - INFO - __main__ - train loss is 34.028309926972724\n",
      "Steps:  74%|▋| 11169/15000 [1:35:18<11:29,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:08 - INFO - __main__ - train loss is 34.29420261143241\n",
      "Steps:  74%|▋| 11170/15000 [1:35:18<11:29,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:08 - INFO - __main__ - train loss is 34.31022276787553\n",
      "Steps:  74%|▋| 11171/15000 [1:35:18<11:28,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:08 - INFO - __main__ - train loss is 34.316968759172596\n",
      "Steps:  74%|▋| 11172/15000 [1:35:18<11:28,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:08 - INFO - __main__ - train loss is 34.33686924132053\n",
      "Steps:  74%|▋| 11173/15000 [1:35:18<11:27,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:08 - INFO - __main__ - train loss is 34.467845888459124\n",
      "Steps:  74%|▋| 11174/15000 [1:35:19<11:27,  5.56it/s, lr=0.000991, step_loss=0.107/27/2023 19:20:09 - INFO - __main__ - train loss is 34.48568948137108\n",
      "Steps:  74%|▋| 11175/15000 [1:35:19<11:26,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:09 - INFO - __main__ - train loss is 34.79011841642205\n",
      "Steps:  75%|▋| 11176/15000 [1:35:19<11:26,  5.57it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:09 - INFO - __main__ - train loss is 34.92997985112015\n",
      "Steps:  75%|▋| 11177/15000 [1:35:19<11:26,  5.57it/s, lr=0.000991, step_loss=0.107/27/2023 19:20:09 - INFO - __main__ - train loss is 35.01621915923897\n",
      "Steps:  75%|▋| 11178/15000 [1:35:19<11:26,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:09 - INFO - __main__ - train loss is 35.47877438890282\n",
      "Steps:  75%|▋| 11179/15000 [1:35:20<11:26,  5.57it/s, lr=0.000991, step_loss=0.407/27/2023 19:20:09 - INFO - __main__ - train loss is 36.03653695213143\n",
      "Steps:  75%|▋| 11180/15000 [1:35:20<11:26,  5.57it/s, lr=0.000991, step_loss=0.507/27/2023 19:20:10 - INFO - __main__ - train loss is 36.04448371718172\n",
      "Steps:  75%|▋| 11181/15000 [1:35:20<11:25,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:10 - INFO - __main__ - train loss is 36.45084368775133\n",
      "Steps:  75%|▋| 11182/15000 [1:35:20<11:26,  5.57it/s, lr=0.000991, step_loss=0.407/27/2023 19:20:10 - INFO - __main__ - train loss is 36.49863233754877\n",
      "Steps:  75%|▋| 11183/15000 [1:35:20<11:26,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:10 - INFO - __main__ - train loss is 36.50228600774426\n",
      "Steps:  75%|▋| 11184/15000 [1:35:20<11:25,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:10 - INFO - __main__ - train loss is 36.77454488549847\n",
      "Steps:  75%|▋| 11185/15000 [1:35:21<11:25,  5.57it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:10 - INFO - __main__ - train loss is 36.922142407041974\n",
      "Steps:  75%|▋| 11186/15000 [1:35:21<11:25,  5.57it/s, lr=0.000991, step_loss=0.107/27/2023 19:20:11 - INFO - __main__ - train loss is 36.98242078919429\n",
      "Steps:  75%|▋| 11187/15000 [1:35:21<11:24,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:11 - INFO - __main__ - train loss is 37.34763167996425\n",
      "Steps:  75%|▋| 11188/15000 [1:35:21<11:24,  5.57it/s, lr=0.000991, step_loss=0.307/27/2023 19:20:11 - INFO - __main__ - train loss is 37.39839745883364\n",
      "Steps:  75%|▋| 11189/15000 [1:35:21<11:25,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:11 - INFO - __main__ - train loss is 38.07304526690859\n",
      "Steps:  75%|▋| 11190/15000 [1:35:22<11:24,  5.56it/s, lr=0.000991, step_loss=0.607/27/2023 19:20:11 - INFO - __main__ - train loss is 38.08021485817153\n",
      "Steps:  75%|▋| 11191/15000 [1:35:22<11:25,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:12 - INFO - __main__ - train loss is 38.37102282058913\n",
      "Steps:  75%|▋| 11192/15000 [1:35:22<11:24,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:12 - INFO - __main__ - train loss is 38.392728038248606\n",
      "Steps:  75%|▋| 11193/15000 [1:35:22<11:24,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:12 - INFO - __main__ - train loss is 38.42662340414245\n",
      "Steps:  75%|▋| 11194/15000 [1:35:22<11:23,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:12 - INFO - __main__ - train loss is 38.4315950620221\n",
      "Steps:  75%|▋| 11195/15000 [1:35:22<11:22,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:12 - INFO - __main__ - train loss is 38.548698661033995\n",
      "Steps:  75%|▋| 11196/15000 [1:35:23<11:22,  5.58it/s, lr=0.000991, step_loss=0.107/27/2023 19:20:12 - INFO - __main__ - train loss is 38.63220774859656\n",
      "Steps:  75%|▋| 11197/15000 [1:35:23<11:21,  5.58it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:13 - INFO - __main__ - train loss is 38.66437054902781\n",
      "Steps:  75%|▋| 11198/15000 [1:35:23<11:23,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:13 - INFO - __main__ - train loss is 38.71095174283255\n",
      "Steps:  75%|▋| 11199/15000 [1:35:23<11:22,  5.57it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:13 - INFO - __main__ - train loss is 38.93651862174738\n",
      "Steps:  75%|▋| 11200/15000 [1:35:23<11:21,  5.58it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:13 - INFO - __main__ - train loss is 39.17947548360098\n",
      "Steps:  75%|▋| 11201/15000 [1:35:23<11:21,  5.57it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:13 - INFO - __main__ - train loss is 39.4006406936096\n",
      "Steps:  75%|▋| 11202/15000 [1:35:24<11:21,  5.58it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:14 - INFO - __main__ - train loss is 39.48858266801108\n",
      "Steps:  75%|▋| 11203/15000 [1:35:24<11:22,  5.56it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:14 - INFO - __main__ - train loss is 39.74819907278288\n",
      "Steps:  75%|▋| 11204/15000 [1:35:24<11:21,  5.57it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:14 - INFO - __main__ - train loss is 39.894388434593566\n",
      "Steps:  75%|▋| 11205/15000 [1:35:24<11:23,  5.55it/s, lr=0.000991, step_loss=0.107/27/2023 19:20:14 - INFO - __main__ - train loss is 40.108476293389685\n",
      "Steps:  75%|▋| 11206/15000 [1:35:24<11:22,  5.56it/s, lr=0.000991, step_loss=0.207/27/2023 19:20:14 - INFO - __main__ - train loss is 40.180841033463366\n",
      "Steps:  75%|▋| 11207/15000 [1:35:25<11:24,  5.54it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:14 - INFO - __main__ - train loss is 40.18216167332139\n",
      "Steps:  75%|▋| 11208/15000 [1:35:25<11:23,  5.54it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:15 - INFO - __main__ - train loss is 40.18427067401353\n",
      "Steps:  75%|▋| 11209/15000 [1:35:25<11:28,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:15 - INFO - __main__ - train loss is 40.18946516804863\n",
      "Steps:  75%|▋| 11210/15000 [1:35:25<11:29,  5.49it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:15 - INFO - __main__ - train loss is 40.20583282888401\n",
      "Steps:  75%|▋| 11211/15000 [1:35:26<16:00,  3.94it/s, lr=0.000991, step_loss=0.007/27/2023 19:20:16 - INFO - __main__ - Per validation step average loss is 0.06826362758874893\n",
      "07/27/2023 19:20:16 - INFO - __main__ - Cumulative validation average loss is 0.06826362758874893\n",
      "07/27/2023 19:20:17 - INFO - __main__ - Per validation step average loss is 0.03795637562870979\n",
      "07/27/2023 19:20:17 - INFO - __main__ - Cumulative validation average loss is 0.10622000321745872\n",
      "07/27/2023 19:20:17 - INFO - __main__ - Per validation step average loss is 0.11169689148664474\n",
      "07/27/2023 19:20:17 - INFO - __main__ - Cumulative validation average loss is 0.21791689470410347\n",
      "07/27/2023 19:20:17 - INFO - __main__ - Per validation step average loss is 0.015612130053341389\n",
      "07/27/2023 19:20:17 - INFO - __main__ - Cumulative validation average loss is 0.23352902475744486\n",
      "07/27/2023 19:20:18 - INFO - __main__ - Per validation step average loss is 0.09187617897987366\n",
      "07/27/2023 19:20:18 - INFO - __main__ - Cumulative validation average loss is 0.3254052037373185\n",
      "07/27/2023 19:20:18 - INFO - __main__ - Per validation step average loss is 0.243880957365036\n",
      "07/27/2023 19:20:18 - INFO - __main__ - Cumulative validation average loss is 0.5692861611023545\n",
      "07/27/2023 19:20:19 - INFO - __main__ - Per validation step average loss is 0.00498367752879858\n",
      "07/27/2023 19:20:19 - INFO - __main__ - Cumulative validation average loss is 0.5742698386311531\n",
      "07/27/2023 19:20:19 - INFO - __main__ - Per validation step average loss is 0.11309202015399933\n",
      "07/27/2023 19:20:19 - INFO - __main__ - Cumulative validation average loss is 0.6873618587851524\n",
      "07/27/2023 19:20:20 - INFO - __main__ - Per validation step average loss is 0.007828857749700546\n",
      "07/27/2023 19:20:20 - INFO - __main__ - Cumulative validation average loss is 0.695190716534853\n",
      "07/27/2023 19:20:20 - INFO - __main__ - Per validation step average loss is 0.03393445163965225\n",
      "07/27/2023 19:20:20 - INFO - __main__ - Cumulative validation average loss is 0.7291251681745052\n",
      "07/27/2023 19:20:20 - INFO - __main__ - Per validation step average loss is 0.12823447585105896\n",
      "07/27/2023 19:20:20 - INFO - __main__ - Cumulative validation average loss is 0.8573596440255642\n",
      "07/27/2023 19:20:21 - INFO - __main__ - Per validation step average loss is 0.010207765735685825\n",
      "07/27/2023 19:20:21 - INFO - __main__ - Cumulative validation average loss is 0.86756740976125\n",
      "07/27/2023 19:20:21 - INFO - __main__ - Per validation step average loss is 0.3934798836708069\n",
      "07/27/2023 19:20:21 - INFO - __main__ - Cumulative validation average loss is 1.261047293432057\n",
      "07/27/2023 19:20:22 - INFO - __main__ - Per validation step average loss is 0.0698765441775322\n",
      "07/27/2023 19:20:22 - INFO - __main__ - Cumulative validation average loss is 1.330923837609589\n",
      "07/27/2023 19:20:22 - INFO - __main__ - Per validation step average loss is 0.019661210477352142\n",
      "07/27/2023 19:20:22 - INFO - __main__ - Cumulative validation average loss is 1.3505850480869412\n",
      "07/27/2023 19:20:22 - INFO - __main__ - Per validation step average loss is 0.6771601438522339\n",
      "07/27/2023 19:20:22 - INFO - __main__ - Cumulative validation average loss is 2.027745191939175\n",
      "07/27/2023 19:20:23 - INFO - __main__ - Per validation step average loss is 0.01778053306043148\n",
      "07/27/2023 19:20:23 - INFO - __main__ - Cumulative validation average loss is 2.0455257249996066\n",
      "07/27/2023 19:20:23 - INFO - __main__ - Per validation step average loss is 0.4762047827243805\n",
      "07/27/2023 19:20:23 - INFO - __main__ - Cumulative validation average loss is 2.521730507723987\n",
      "07/27/2023 19:20:24 - INFO - __main__ - Per validation step average loss is 0.003525935113430023\n",
      "07/27/2023 19:20:24 - INFO - __main__ - Cumulative validation average loss is 2.525256442837417\n",
      "07/27/2023 19:20:24 - INFO - __main__ - Per validation step average loss is 0.23914411664009094\n",
      "07/27/2023 19:20:24 - INFO - __main__ - Cumulative validation average loss is 2.764400559477508\n",
      "07/27/2023 19:20:25 - INFO - __main__ - Per validation step average loss is 0.05764177069067955\n",
      "07/27/2023 19:20:25 - INFO - __main__ - Cumulative validation average loss is 2.8220423301681876\n",
      "07/27/2023 19:20:25 - INFO - __main__ - Per validation step average loss is 0.004226315766572952\n",
      "07/27/2023 19:20:25 - INFO - __main__ - Cumulative validation average loss is 2.8262686459347606\n",
      "07/27/2023 19:20:25 - INFO - __main__ - Per validation step average loss is 0.5821572542190552\n",
      "07/27/2023 19:20:25 - INFO - __main__ - Cumulative validation average loss is 3.4084259001538157\n",
      "07/27/2023 19:20:26 - INFO - __main__ - Per validation step average loss is 0.005968966521322727\n",
      "07/27/2023 19:20:26 - INFO - __main__ - Cumulative validation average loss is 3.4143948666751385\n",
      "07/27/2023 19:20:26 - INFO - __main__ - Per validation step average loss is 0.006329145282506943\n",
      "07/27/2023 19:20:26 - INFO - __main__ - Cumulative validation average loss is 3.4207240119576454\n",
      "07/27/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.030413083732128143\n",
      "07/27/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 3.4511370956897736\n",
      "07/27/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.002969256602227688\n",
      "07/27/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 3.4541063522920012\n",
      "07/27/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.24537503719329834\n",
      "07/27/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 3.6994813894852996\n",
      "07/27/2023 19:20:28 - INFO - __main__ - Per validation step average loss is 0.45749402046203613\n",
      "07/27/2023 19:20:28 - INFO - __main__ - Cumulative validation average loss is 4.156975409947336\n",
      "07/27/2023 19:20:28 - INFO - __main__ - Per validation step average loss is 0.002208111574873328\n",
      "07/27/2023 19:20:28 - INFO - __main__ - Cumulative validation average loss is 4.159183521522209\n",
      "07/27/2023 19:20:29 - INFO - __main__ - Per validation step average loss is 0.038380879908800125\n",
      "07/27/2023 19:20:29 - INFO - __main__ - Cumulative validation average loss is 4.197564401431009\n",
      "07/27/2023 19:20:29 - INFO - __main__ - Per validation step average loss is 0.09344695508480072\n",
      "07/27/2023 19:20:29 - INFO - __main__ - Cumulative validation average loss is 4.29101135651581\n",
      "07/27/2023 19:20:29 - INFO - __main__ - Per validation step average loss is 0.011314131319522858\n",
      "07/27/2023 19:20:29 - INFO - __main__ - Cumulative validation average loss is 4.302325487835333\n",
      "07/27/2023 19:20:30 - INFO - __main__ - Per validation step average loss is 0.26762425899505615\n",
      "07/27/2023 19:20:30 - INFO - __main__ - Cumulative validation average loss is 4.569949746830389\n",
      "07/27/2023 19:20:30 - INFO - __main__ - Per validation step average loss is 0.009712516330182552\n",
      "07/27/2023 19:20:30 - INFO - __main__ - Cumulative validation average loss is 4.5796622631605715\n",
      "07/27/2023 19:20:31 - INFO - __main__ - Per validation step average loss is 0.02606876567006111\n",
      "07/27/2023 19:20:31 - INFO - __main__ - Cumulative validation average loss is 4.605731028830633\n",
      "07/27/2023 19:20:31 - INFO - __main__ - Per validation step average loss is 0.007210730575025082\n",
      "07/27/2023 19:20:31 - INFO - __main__ - Cumulative validation average loss is 4.612941759405658\n",
      "07/27/2023 19:20:32 - INFO - __main__ - Per validation step average loss is 0.0019173382315784693\n",
      "07/27/2023 19:20:32 - INFO - __main__ - Cumulative validation average loss is 4.614859097637236\n",
      "07/27/2023 19:20:32 - INFO - __main__ - Per validation step average loss is 0.2713862359523773\n",
      "07/27/2023 19:20:32 - INFO - __main__ - Cumulative validation average loss is 4.886245333589613\n",
      "07/27/2023 19:20:32 - INFO - __main__ - Per validation step average loss is 0.017479581758379936\n",
      "07/27/2023 19:20:32 - INFO - __main__ - Cumulative validation average loss is 4.903724915347993\n",
      "07/27/2023 19:20:33 - INFO - __main__ - Per validation step average loss is 0.30905681848526\n",
      "07/27/2023 19:20:33 - INFO - __main__ - Cumulative validation average loss is 5.212781733833253\n",
      "07/27/2023 19:20:33 - INFO - __main__ - Per validation step average loss is 0.0073324162513017654\n",
      "07/27/2023 19:20:33 - INFO - __main__ - Cumulative validation average loss is 5.220114150084555\n",
      "07/27/2023 19:20:34 - INFO - __main__ - Per validation step average loss is 0.01296909712255001\n",
      "07/27/2023 19:20:34 - INFO - __main__ - Cumulative validation average loss is 5.233083247207105\n",
      "07/27/2023 19:20:34 - INFO - __main__ - Per validation step average loss is 0.08393353223800659\n",
      "07/27/2023 19:20:34 - INFO - __main__ - Cumulative validation average loss is 5.317016779445112\n",
      "07/27/2023 19:20:34 - INFO - __main__ - Per validation step average loss is 0.07682330906391144\n",
      "07/27/2023 19:20:34 - INFO - __main__ - Cumulative validation average loss is 5.393840088509023\n",
      "07/27/2023 19:20:35 - INFO - __main__ - Per validation step average loss is 0.00822143442928791\n",
      "07/27/2023 19:20:35 - INFO - __main__ - Cumulative validation average loss is 5.402061522938311\n",
      "07/27/2023 19:20:35 - INFO - __main__ - Per validation step average loss is 0.014202821999788284\n",
      "07/27/2023 19:20:35 - INFO - __main__ - Cumulative validation average loss is 5.416264344938099\n",
      "07/27/2023 19:20:36 - INFO - __main__ - Per validation step average loss is 0.010562722571194172\n",
      "07/27/2023 19:20:36 - INFO - __main__ - Cumulative validation average loss is 5.426827067509294\n",
      "07/27/2023 19:20:36 - INFO - __main__ - Per validation step average loss is 0.4233139753341675\n",
      "07/27/2023 19:20:36 - INFO - __main__ - Cumulative validation average loss is 5.850141042843461\n",
      "07/27/2023 19:20:37 - INFO - __main__ - Per validation step average loss is 0.3018355369567871\n",
      "07/27/2023 19:20:37 - INFO - __main__ - Cumulative validation average loss is 6.151976579800248\n",
      "07/27/2023 19:20:37 - INFO - __main__ - Per validation step average loss is 0.14343127608299255\n",
      "07/27/2023 19:20:37 - INFO - __main__ - Cumulative validation average loss is 6.295407855883241\n",
      "07/27/2023 19:20:37 - INFO - __main__ - Per validation step average loss is 0.0859326496720314\n",
      "07/27/2023 19:20:37 - INFO - __main__ - Cumulative validation average loss is 6.381340505555272\n",
      "07/27/2023 19:20:38 - INFO - __main__ - Per validation step average loss is 0.007552802562713623\n",
      "07/27/2023 19:20:38 - INFO - __main__ - Cumulative validation average loss is 6.388893308117986\n",
      "07/27/2023 19:20:38 - INFO - __main__ - Per validation step average loss is 0.012265234254300594\n",
      "07/27/2023 19:20:38 - INFO - __main__ - Cumulative validation average loss is 6.401158542372286\n",
      "07/27/2023 19:20:39 - INFO - __main__ - Per validation step average loss is 0.16307488083839417\n",
      "07/27/2023 19:20:39 - INFO - __main__ - Cumulative validation average loss is 6.5642334232106805\n",
      "07/27/2023 19:20:39 - INFO - __main__ - Per validation step average loss is 0.05815112963318825\n",
      "07/27/2023 19:20:39 - INFO - __main__ - Cumulative validation average loss is 6.622384552843869\n",
      "07/27/2023 19:20:40 - INFO - __main__ - Per validation step average loss is 0.0018380051478743553\n",
      "07/27/2023 19:20:40 - INFO - __main__ - Cumulative validation average loss is 6.624222557991743\n",
      "07/27/2023 19:20:40 - INFO - __main__ - Per validation step average loss is 0.35690179467201233\n",
      "07/27/2023 19:20:40 - INFO - __main__ - Cumulative validation average loss is 6.981124352663755\n",
      "07/27/2023 19:20:40 - INFO - __main__ - Per validation step average loss is 0.005748400930315256\n",
      "07/27/2023 19:20:40 - INFO - __main__ - Cumulative validation average loss is 6.986872753594071\n",
      "07/27/2023 19:20:41 - INFO - __main__ - Per validation step average loss is 0.11866739392280579\n",
      "07/27/2023 19:20:41 - INFO - __main__ - Cumulative validation average loss is 7.1055401475168765\n",
      "07/27/2023 19:20:41 - INFO - __main__ - Per validation step average loss is 0.055427491664886475\n",
      "07/27/2023 19:20:41 - INFO - __main__ - Cumulative validation average loss is 7.160967639181763\n",
      "07/27/2023 19:20:42 - INFO - __main__ - Per validation step average loss is 0.03829663619399071\n",
      "07/27/2023 19:20:42 - INFO - __main__ - Cumulative validation average loss is 7.199264275375754\n",
      "07/27/2023 19:20:42 - INFO - __main__ - Per validation step average loss is 0.036957237869501114\n",
      "07/27/2023 19:20:42 - INFO - __main__ - Cumulative validation average loss is 7.236221513245255\n",
      "07/27/2023 19:20:42 - INFO - __main__ - Per validation step average loss is 0.2068690061569214\n",
      "07/27/2023 19:20:42 - INFO - __main__ - Cumulative validation average loss is 7.443090519402176\n",
      "07/27/2023 19:20:43 - INFO - __main__ - Per validation step average loss is 0.12691357731819153\n",
      "07/27/2023 19:20:43 - INFO - __main__ - Cumulative validation average loss is 7.570004096720368\n",
      "07/27/2023 19:20:43 - INFO - __main__ - Per validation step average loss is 0.0014021601527929306\n",
      "07/27/2023 19:20:43 - INFO - __main__ - Cumulative validation average loss is 7.571406256873161\n",
      "07/27/2023 19:20:44 - INFO - __main__ - Per validation step average loss is 0.10796709358692169\n",
      "07/27/2023 19:20:44 - INFO - __main__ - Cumulative validation average loss is 7.679373350460082\n",
      "07/27/2023 19:20:44 - INFO - __main__ - Per validation step average loss is 0.0019836830906569958\n",
      "07/27/2023 19:20:44 - INFO - __main__ - Cumulative validation average loss is 7.681357033550739\n",
      "07/27/2023 19:20:45 - INFO - __main__ - Per validation step average loss is 0.013075804337859154\n",
      "07/27/2023 19:20:45 - INFO - __main__ - Cumulative validation average loss is 7.694432837888598\n",
      "07/27/2023 19:20:45 - INFO - __main__ - Per validation step average loss is 0.005277163349092007\n",
      "07/27/2023 19:20:45 - INFO - __main__ - Cumulative validation average loss is 7.6997100012376904\n",
      "07/27/2023 19:20:45 - INFO - __main__ - Per validation step average loss is 0.12450230866670609\n",
      "07/27/2023 19:20:45 - INFO - __main__ - Cumulative validation average loss is 7.8242123099043965\n",
      "07/27/2023 19:20:46 - INFO - __main__ - Per validation step average loss is 0.2848927080631256\n",
      "07/27/2023 19:20:46 - INFO - __main__ - Cumulative validation average loss is 8.109105017967522\n",
      "07/27/2023 19:20:46 - INFO - __main__ - Per validation step average loss is 0.08295586705207825\n",
      "07/27/2023 19:20:46 - INFO - __main__ - Cumulative validation average loss is 8.1920608850196\n",
      "07/27/2023 19:20:47 - INFO - __main__ - Per validation step average loss is 0.09785996377468109\n",
      "07/27/2023 19:20:47 - INFO - __main__ - Cumulative validation average loss is 8.289920848794281\n",
      "07/27/2023 19:20:47 - INFO - __main__ - Per validation step average loss is 0.024664247408509254\n",
      "07/27/2023 19:20:47 - INFO - __main__ - Cumulative validation average loss is 8.31458509620279\n",
      "07/27/2023 19:20:47 - INFO - __main__ - Per validation step average loss is 0.0015488510252907872\n",
      "07/27/2023 19:20:47 - INFO - __main__ - Cumulative validation average loss is 8.316133947228082\n",
      "07/27/2023 19:20:48 - INFO - __main__ - Per validation step average loss is 0.32124829292297363\n",
      "07/27/2023 19:20:48 - INFO - __main__ - Cumulative validation average loss is 8.637382240151055\n",
      "07/27/2023 19:20:48 - INFO - __main__ - Per validation step average loss is 0.02085297368466854\n",
      "07/27/2023 19:20:48 - INFO - __main__ - Cumulative validation average loss is 8.658235213835724\n",
      "07/27/2023 19:20:49 - INFO - __main__ - Per validation step average loss is 0.016584401950240135\n",
      "07/27/2023 19:20:49 - INFO - __main__ - Cumulative validation average loss is 8.674819615785964\n",
      "07/27/2023 19:20:49 - INFO - __main__ - Average validation loss for Epoch 36 is 0.109807843237797\n",
      "07/27/2023 19:20:49 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:21:46 - INFO - __main__ - Starting epoch 37\n",
      "07/27/2023 19:21:47 - INFO - __main__ - train loss is 0.08314735442399979\n",
      "Steps:  75%|▋| 11212/15000 [1:36:57<29:05:52, 27.65s/it, lr=0.000991, step_loss=07/27/2023 19:21:47 - INFO - __main__ - train loss is 0.43776003271341324\n",
      "Steps:  75%|▋| 11213/15000 [1:36:57<20:25:13, 19.41s/it, lr=0.000991, step_loss=07/27/2023 19:21:47 - INFO - __main__ - train loss is 0.44462808687239885\n",
      "Steps:  75%|▋| 11214/15000 [1:36:57<14:20:48, 13.64s/it, lr=0.000991, step_loss=07/27/2023 19:21:47 - INFO - __main__ - train loss is 0.4729558555409312\n",
      "Steps:  75%|▋| 11215/15000 [1:36:58<10:05:52,  9.60s/it, lr=0.000991, step_loss=07/27/2023 19:21:48 - INFO - __main__ - train loss is 0.5359534053131938\n",
      "Steps:  75%|▋| 11216/15000 [1:36:58<7:07:27,  6.78s/it, lr=0.000991, step_loss=007/27/2023 19:21:48 - INFO - __main__ - train loss is 0.6104100299999118\n",
      "Steps:  75%|▋| 11217/15000 [1:36:58<5:02:34,  4.80s/it, lr=0.000991, step_loss=007/27/2023 19:21:48 - INFO - __main__ - train loss is 0.6664594477042556\n",
      "Steps:  75%|▋| 11218/15000 [1:36:58<3:35:21,  3.42s/it, lr=0.000991, step_loss=007/27/2023 19:21:48 - INFO - __main__ - train loss is 0.7722425824031234\n",
      "Steps:  75%|▋| 11219/15000 [1:36:58<2:34:12,  2.45s/it, lr=0.000991, step_loss=007/27/2023 19:21:48 - INFO - __main__ - train loss is 0.7745990208350122\n",
      "Steps:  75%|▋| 11220/15000 [1:36:59<1:51:20,  1.77s/it, lr=0.000991, step_loss=007/27/2023 19:21:48 - INFO - __main__ - train loss is 0.7860853183083236\n",
      "Steps:  75%|▋| 11221/15000 [1:36:59<1:21:19,  1.29s/it, lr=0.000991, step_loss=007/27/2023 19:21:49 - INFO - __main__ - train loss is 0.8134911614470184\n",
      "Steps:  75%|▋| 11222/15000 [1:36:59<1:00:19,  1.04it/s, lr=0.000991, step_loss=007/27/2023 19:21:49 - INFO - __main__ - train loss is 0.9163634064607322\n",
      "Steps:  75%|▋| 11223/15000 [1:36:59<45:38,  1.38it/s, lr=0.000991, step_loss=0.107/27/2023 19:21:49 - INFO - __main__ - train loss is 0.9187143915332854\n",
      "Steps:  75%|▋| 11224/15000 [1:36:59<35:20,  1.78it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:49 - INFO - __main__ - train loss is 0.9232147582806647\n",
      "Steps:  75%|▋| 11225/15000 [1:36:59<28:09,  2.23it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:49 - INFO - __main__ - train loss is 1.2081443914212286\n",
      "Steps:  75%|▋| 11226/15000 [1:37:00<23:07,  2.72it/s, lr=0.000991, step_loss=0.207/27/2023 19:21:50 - INFO - __main__ - train loss is 1.4438363858498633\n",
      "Steps:  75%|▋| 11227/15000 [1:37:00<19:35,  3.21it/s, lr=0.000991, step_loss=0.207/27/2023 19:21:50 - INFO - __main__ - train loss is 1.751941675785929\n",
      "Steps:  75%|▋| 11228/15000 [1:37:00<17:08,  3.67it/s, lr=0.000991, step_loss=0.307/27/2023 19:21:50 - INFO - __main__ - train loss is 1.8151125484146178\n",
      "Steps:  75%|▋| 11229/15000 [1:37:00<15:25,  4.07it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:50 - INFO - __main__ - train loss is 1.8610387132503092\n",
      "Steps:  75%|▋| 11230/15000 [1:37:00<14:12,  4.42it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:50 - INFO - __main__ - train loss is 1.9298533559776843\n",
      "Steps:  75%|▋| 11231/15000 [1:37:01<13:22,  4.70it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:50 - INFO - __main__ - train loss is 1.9681215793825686\n",
      "Steps:  75%|▋| 11232/15000 [1:37:01<12:46,  4.92it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:51 - INFO - __main__ - train loss is 2.2937538833357394\n",
      "Steps:  75%|▋| 11233/15000 [1:37:01<12:21,  5.08it/s, lr=0.000991, step_loss=0.307/27/2023 19:21:51 - INFO - __main__ - train loss is 2.625632664654404\n",
      "Steps:  75%|▋| 11234/15000 [1:37:01<12:04,  5.20it/s, lr=0.000991, step_loss=0.307/27/2023 19:21:51 - INFO - __main__ - train loss is 2.901937982533127\n",
      "Steps:  75%|▋| 11235/15000 [1:37:01<11:51,  5.29it/s, lr=0.000991, step_loss=0.207/27/2023 19:21:51 - INFO - __main__ - train loss is 2.908969187643379\n",
      "Steps:  75%|▋| 11236/15000 [1:37:01<11:43,  5.35it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:51 - INFO - __main__ - train loss is 2.9294061376713216\n",
      "Steps:  75%|▋| 11237/15000 [1:37:02<11:37,  5.40it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:52 - INFO - __main__ - train loss is 3.301536829676479\n",
      "Steps:  75%|▋| 11238/15000 [1:37:02<11:32,  5.43it/s, lr=0.000991, step_loss=0.307/27/2023 19:21:52 - INFO - __main__ - train loss is 3.304374486207962\n",
      "Steps:  75%|▋| 11239/15000 [1:37:02<11:29,  5.45it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:52 - INFO - __main__ - train loss is 3.3156409356743097\n",
      "Steps:  75%|▋| 11240/15000 [1:37:02<11:27,  5.47it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:52 - INFO - __main__ - train loss is 3.3420229014009237\n",
      "Steps:  75%|▋| 11241/15000 [1:37:02<11:26,  5.47it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:52 - INFO - __main__ - train loss is 3.3988005127757788\n",
      "Steps:  75%|▋| 11242/15000 [1:37:03<11:25,  5.48it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:52 - INFO - __main__ - train loss is 3.5936161186546087\n",
      "Steps:  75%|▋| 11243/15000 [1:37:03<11:24,  5.49it/s, lr=0.000991, step_loss=0.107/27/2023 19:21:53 - INFO - __main__ - train loss is 3.5964167879428715\n",
      "Steps:  75%|▋| 11244/15000 [1:37:03<11:23,  5.49it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:53 - INFO - __main__ - train loss is 3.601750672562048\n",
      "Steps:  75%|▋| 11245/15000 [1:37:03<11:23,  5.49it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:53 - INFO - __main__ - train loss is 3.622522474033758\n",
      "Steps:  75%|▋| 11246/15000 [1:37:03<11:23,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:53 - INFO - __main__ - train loss is 3.7444303340744227\n",
      "Steps:  75%|▋| 11247/15000 [1:37:03<11:22,  5.50it/s, lr=0.000991, step_loss=0.107/27/2023 19:21:53 - INFO - __main__ - train loss is 3.7584787036757916\n",
      "Steps:  75%|▋| 11248/15000 [1:37:04<11:22,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:54 - INFO - __main__ - train loss is 3.7630532139446586\n",
      "Steps:  75%|▋| 11249/15000 [1:37:04<11:22,  5.50it/s, lr=0.000991, step_loss=0.007/27/2023 19:21:54 - INFO - __main__ - train loss is 3.9086339080240577\n",
      "Steps:  75%|▊| 11250/15000 [1:37:04<11:21,  5.50it/s, lr=0.00099, step_loss=0.1407/27/2023 19:21:54 - INFO - __main__ - train loss is 3.9136073214467615\n",
      "Steps:  75%|▊| 11251/15000 [1:37:04<11:21,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:21:54 - INFO - __main__ - train loss is 4.453292988007888\n",
      "Steps:  75%|▊| 11252/15000 [1:37:04<11:21,  5.50it/s, lr=0.00099, step_loss=0.5407/27/2023 19:21:54 - INFO - __main__ - train loss is 4.640132881468162\n",
      "Steps:  75%|▊| 11253/15000 [1:37:05<11:21,  5.50it/s, lr=0.00099, step_loss=0.1807/27/2023 19:21:54 - INFO - __main__ - train loss is 4.6420000966172665\n",
      "Steps:  75%|▊| 11254/15000 [1:37:05<11:21,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:21:55 - INFO - __main__ - train loss is 5.066946643171832\n",
      "Steps:  75%|▊| 11255/15000 [1:37:05<11:21,  5.50it/s, lr=0.00099, step_loss=0.4207/27/2023 19:21:55 - INFO - __main__ - train loss is 5.071925899712369\n",
      "Steps:  75%|▊| 11256/15000 [1:37:05<11:21,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:21:55 - INFO - __main__ - train loss is 5.108403323916718\n",
      "Steps:  75%|▊| 11257/15000 [1:37:05<11:21,  5.49it/s, lr=0.00099, step_loss=0.0307/27/2023 19:21:55 - INFO - __main__ - train loss is 5.216115816263482\n",
      "Steps:  75%|▊| 11258/15000 [1:37:05<11:20,  5.50it/s, lr=0.00099, step_loss=0.1007/27/2023 19:21:55 - INFO - __main__ - train loss is 5.234052303014323\n",
      "Steps:  75%|▊| 11259/15000 [1:37:06<11:20,  5.50it/s, lr=0.00099, step_loss=0.0107/27/2023 19:21:56 - INFO - __main__ - train loss is 5.501774254022166\n",
      "Steps:  75%|▊| 11260/15000 [1:37:06<11:20,  5.50it/s, lr=0.00099, step_loss=0.2607/27/2023 19:21:56 - INFO - __main__ - train loss is 5.6493835772853345\n",
      "Steps:  75%|▊| 11261/15000 [1:37:06<11:20,  5.50it/s, lr=0.00099, step_loss=0.1407/27/2023 19:21:56 - INFO - __main__ - train loss is 5.650649075745605\n",
      "Steps:  75%|▊| 11262/15000 [1:37:06<11:26,  5.44it/s, lr=0.00099, step_loss=0.0007/27/2023 19:21:56 - INFO - __main__ - train loss is 5.800176431774162\n",
      "Steps:  75%|▊| 11263/15000 [1:37:06<11:24,  5.46it/s, lr=0.00099, step_loss=0.1507/27/2023 19:21:56 - INFO - __main__ - train loss is 5.979766463278793\n",
      "Steps:  75%|▊| 11264/15000 [1:37:07<11:22,  5.47it/s, lr=0.00099, step_loss=0.1807/27/2023 19:21:56 - INFO - __main__ - train loss is 5.984911936684512\n",
      "Steps:  75%|▊| 11265/15000 [1:37:07<11:21,  5.48it/s, lr=0.00099, step_loss=0.0007/27/2023 19:21:57 - INFO - __main__ - train loss is 6.321357327862643\n",
      "Steps:  75%|▊| 11266/15000 [1:37:07<11:20,  5.49it/s, lr=0.00099, step_loss=0.3307/27/2023 19:21:57 - INFO - __main__ - train loss is 6.543405342265032\n",
      "Steps:  75%|▊| 11267/15000 [1:37:07<11:20,  5.49it/s, lr=0.00099, step_loss=0.2207/27/2023 19:21:57 - INFO - __main__ - train loss is 6.56301170529332\n",
      "Steps:  75%|▊| 11268/15000 [1:37:07<11:20,  5.49it/s, lr=0.00099, step_loss=0.0107/27/2023 19:21:57 - INFO - __main__ - train loss is 6.5906292566796765\n",
      "Steps:  75%|▊| 11269/15000 [1:37:07<11:19,  5.49it/s, lr=0.00099, step_loss=0.0207/27/2023 19:21:57 - INFO - __main__ - train loss is 6.7005606883903965\n",
      "Steps:  75%|▊| 11270/15000 [1:37:08<11:24,  5.45it/s, lr=0.00099, step_loss=0.1107/27/2023 19:21:58 - INFO - __main__ - train loss is 6.8412807726999745\n",
      "Steps:  75%|▊| 11271/15000 [1:37:08<11:25,  5.44it/s, lr=0.00099, step_loss=0.1407/27/2023 19:21:58 - INFO - __main__ - train loss is 6.9374925860902295\n",
      "Steps:  75%|▊| 11272/15000 [1:37:08<11:22,  5.46it/s, lr=0.00099, step_loss=0.0907/27/2023 19:21:58 - INFO - __main__ - train loss is 6.960477208136581\n",
      "Steps:  75%|▊| 11273/15000 [1:37:08<11:18,  5.49it/s, lr=0.00099, step_loss=0.0207/27/2023 19:21:58 - INFO - __main__ - train loss is 7.582376693724655\n",
      "Steps:  75%|▊| 11274/15000 [1:37:08<11:15,  5.52it/s, lr=0.00099, step_loss=0.6207/27/2023 19:21:58 - INFO - __main__ - train loss is 7.599427459179424\n",
      "Steps:  75%|▊| 11275/15000 [1:37:09<11:13,  5.53it/s, lr=0.00099, step_loss=0.0107/27/2023 19:21:58 - INFO - __main__ - train loss is 7.605275329085998\n",
      "Steps:  75%|▊| 11276/15000 [1:37:09<11:11,  5.54it/s, lr=0.00099, step_loss=0.0007/27/2023 19:21:59 - INFO - __main__ - train loss is 7.89378803584259\n",
      "Steps:  75%|▊| 11277/15000 [1:37:09<11:10,  5.55it/s, lr=0.00099, step_loss=0.2807/27/2023 19:21:59 - INFO - __main__ - train loss is 7.993885781499557\n",
      "Steps:  75%|▊| 11278/15000 [1:37:09<11:09,  5.56it/s, lr=0.00099, step_loss=0.1]07/27/2023 19:21:59 - INFO - __main__ - train loss is 8.597474362584762\n",
      "Steps:  75%|▊| 11279/15000 [1:37:09<11:09,  5.56it/s, lr=0.00099, step_loss=0.6007/27/2023 19:21:59 - INFO - __main__ - train loss is 8.617604860919528\n",
      "Steps:  75%|▊| 11280/15000 [1:37:09<11:08,  5.57it/s, lr=0.00099, step_loss=0.0207/27/2023 19:21:59 - INFO - __main__ - train loss is 8.725851008552127\n",
      "Steps:  75%|▊| 11281/15000 [1:37:10<11:07,  5.57it/s, lr=0.00099, step_loss=0.1007/27/2023 19:22:00 - INFO - __main__ - train loss is 9.259652862208895\n",
      "Steps:  75%|▊| 11282/15000 [1:37:10<11:08,  5.56it/s, lr=0.00099, step_loss=0.5307/27/2023 19:22:00 - INFO - __main__ - train loss is 9.397365609067492\n",
      "Steps:  75%|▊| 11283/15000 [1:37:10<11:07,  5.57it/s, lr=0.00099, step_loss=0.1307/27/2023 19:22:00 - INFO - __main__ - train loss is 9.461946720140986\n",
      "Steps:  75%|▊| 11284/15000 [1:37:10<11:07,  5.57it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:00 - INFO - __main__ - train loss is 9.468087287037633\n",
      "Steps:  75%|▊| 11285/15000 [1:37:10<11:07,  5.57it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:00 - INFO - __main__ - train loss is 9.532649607746862\n",
      "Steps:  75%|▊| 11286/15000 [1:37:11<11:06,  5.57it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:00 - INFO - __main__ - train loss is 9.935141058056615\n",
      "Steps:  75%|▊| 11287/15000 [1:37:11<11:06,  5.57it/s, lr=0.00099, step_loss=0.4007/27/2023 19:22:01 - INFO - __main__ - train loss is 9.9995742602041\n",
      "Steps:  75%|▊| 11288/15000 [1:37:11<11:06,  5.57it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:01 - INFO - __main__ - train loss is 10.428314821212552\n",
      "Steps:  75%|▊| 11289/15000 [1:37:11<11:06,  5.57it/s, lr=0.00099, step_loss=0.4207/27/2023 19:22:01 - INFO - __main__ - train loss is 10.547179551213048\n",
      "Steps:  75%|▊| 11290/15000 [1:37:11<11:06,  5.57it/s, lr=0.00099, step_loss=0.1107/27/2023 19:22:01 - INFO - __main__ - train loss is 11.018825919716619\n",
      "Steps:  75%|▊| 11291/15000 [1:37:11<11:12,  5.52it/s, lr=0.00099, step_loss=0.4707/27/2023 19:22:01 - INFO - __main__ - train loss is 11.020539005170576\n",
      "Steps:  75%|▊| 11292/15000 [1:37:12<11:13,  5.51it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:02 - INFO - __main__ - train loss is 11.164588798652403\n",
      "Steps:  75%|▊| 11293/15000 [1:37:12<11:18,  5.47it/s, lr=0.00099, step_loss=0.1407/27/2023 19:22:02 - INFO - __main__ - train loss is 11.174690351705067\n",
      "Steps:  75%|▊| 11294/15000 [1:37:12<11:16,  5.47it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:02 - INFO - __main__ - train loss is 11.239681997220032\n",
      "Steps:  75%|▊| 11295/15000 [1:37:12<11:16,  5.48it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:02 - INFO - __main__ - train loss is 11.350953944842331\n",
      "Steps:  75%|▊| 11296/15000 [1:37:12<11:15,  5.48it/s, lr=0.00099, step_loss=0.1107/27/2023 19:22:02 - INFO - __main__ - train loss is 11.511122339288704\n",
      "Steps:  75%|▊| 11297/15000 [1:37:13<11:16,  5.48it/s, lr=0.00099, step_loss=0.1607/27/2023 19:22:02 - INFO - __main__ - train loss is 11.601512842695229\n",
      "Steps:  75%|▊| 11298/15000 [1:37:13<11:15,  5.48it/s, lr=0.00099, step_loss=0.0907/27/2023 19:22:03 - INFO - __main__ - train loss is 11.604256471036933\n",
      "Steps:  75%|▊| 11299/15000 [1:37:13<11:14,  5.48it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:03 - INFO - __main__ - train loss is 11.683993538259529\n",
      "Steps:  75%|▊| 11300/15000 [1:37:13<11:14,  5.49it/s, lr=0.00099, step_loss=0.0707/27/2023 19:22:03 - INFO - __main__ - train loss is 11.685154139413498\n",
      "Steps:  75%|▊| 11301/15000 [1:37:13<11:19,  5.44it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:03 - INFO - __main__ - train loss is 11.751300945295952\n",
      "Steps:  75%|▊| 11302/15000 [1:37:13<11:17,  5.46it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:03 - INFO - __main__ - train loss is 11.767654509632848\n",
      "Steps:  75%|▊| 11303/15000 [1:37:14<11:13,  5.49it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:04 - INFO - __main__ - train loss is 12.507508428185247\n",
      "Steps:  75%|▊| 11304/15000 [1:37:14<11:10,  5.51it/s, lr=0.00099, step_loss=0.7407/27/2023 19:22:04 - INFO - __main__ - train loss is 12.905570657341741\n",
      "Steps:  75%|▊| 11305/15000 [1:37:14<11:07,  5.53it/s, lr=0.00099, step_loss=0.3907/27/2023 19:22:04 - INFO - __main__ - train loss is 13.060638488619588\n",
      "Steps:  75%|▊| 11306/15000 [1:37:14<11:11,  5.50it/s, lr=0.00099, step_loss=0.1507/27/2023 19:22:04 - INFO - __main__ - train loss is 13.066192795406096\n",
      "Steps:  75%|▊| 11307/15000 [1:37:14<11:09,  5.51it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:04 - INFO - __main__ - train loss is 13.091468182276003\n",
      "Steps:  75%|▊| 11308/15000 [1:37:15<12:29,  4.92it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:05 - INFO - __main__ - train loss is 13.172463324735872\n",
      "Steps:  75%|▊| 11309/15000 [1:37:15<14:05,  4.36it/s, lr=0.00099, step_loss=0.0807/27/2023 19:22:05 - INFO - __main__ - train loss is 13.218500261078589\n",
      "Steps:  75%|▊| 11310/15000 [1:37:15<13:23,  4.59it/s, lr=0.00099, step_loss=0.0407/27/2023 19:22:05 - INFO - __main__ - train loss is 13.254430715809576\n",
      "Steps:  75%|▊| 11311/15000 [1:37:15<12:50,  4.79it/s, lr=0.00099, step_loss=0.0307/27/2023 19:22:05 - INFO - __main__ - train loss is 13.456672613392584\n",
      "Steps:  75%|▊| 11312/15000 [1:37:15<12:20,  4.98it/s, lr=0.00099, step_loss=0.2007/27/2023 19:22:05 - INFO - __main__ - train loss is 13.479606662760489\n",
      "Steps:  75%|▊| 11313/15000 [1:37:16<12:00,  5.12it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:06 - INFO - __main__ - train loss is 13.730625335942023\n",
      "Steps:  75%|▊| 11314/15000 [1:37:16<11:42,  5.24it/s, lr=0.00099, step_loss=0.2507/27/2023 19:22:06 - INFO - __main__ - train loss is 13.733116066432558\n",
      "Steps:  75%|▊| 11315/15000 [1:37:16<11:31,  5.33it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:06 - INFO - __main__ - train loss is 13.90522449312266\n",
      "Steps:  75%|▊| 11316/15000 [1:37:16<11:22,  5.40it/s, lr=0.00099, step_loss=0.1707/27/2023 19:22:06 - INFO - __main__ - train loss is 13.927040430135094\n",
      "Steps:  75%|▊| 11317/15000 [1:37:16<11:15,  5.45it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:06 - INFO - __main__ - train loss is 13.92873059073463\n",
      "Steps:  75%|▊| 11318/15000 [1:37:17<11:11,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:06 - INFO - __main__ - train loss is 13.930107441730797\n",
      "Steps:  75%|▊| 11319/15000 [1:37:17<11:08,  5.51it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:07 - INFO - __main__ - train loss is 14.154990759678185\n",
      "Steps:  75%|▊| 11320/15000 [1:37:17<11:05,  5.53it/s, lr=0.00099, step_loss=0.2207/27/2023 19:22:07 - INFO - __main__ - train loss is 14.241573211736977\n",
      "Steps:  75%|▊| 11321/15000 [1:37:17<11:10,  5.48it/s, lr=0.00099, step_loss=0.0807/27/2023 19:22:07 - INFO - __main__ - train loss is 14.710486945696175\n",
      "Steps:  75%|▊| 11322/15000 [1:37:17<11:07,  5.51it/s, lr=0.00099, step_loss=0.4607/27/2023 19:22:07 - INFO - __main__ - train loss is 15.088850763626397\n",
      "Steps:  75%|▊| 11323/15000 [1:37:17<11:05,  5.52it/s, lr=0.00099, step_loss=0.3707/27/2023 19:22:07 - INFO - __main__ - train loss is 15.27035838086158\n",
      "Steps:  75%|▊| 11324/15000 [1:37:18<11:09,  5.49it/s, lr=0.00099, step_loss=0.1807/27/2023 19:22:08 - INFO - __main__ - train loss is 15.371598166413605\n",
      "Steps:  76%|▊| 11325/15000 [1:37:18<11:08,  5.50it/s, lr=0.00099, step_loss=0.1007/27/2023 19:22:08 - INFO - __main__ - train loss is 15.379106484819204\n",
      "Steps:  76%|▊| 11326/15000 [1:37:18<11:05,  5.52it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:08 - INFO - __main__ - train loss is 15.412648845929652\n",
      "Steps:  76%|▊| 11327/15000 [1:37:18<11:03,  5.54it/s, lr=0.00099, step_loss=0.0307/27/2023 19:22:08 - INFO - __main__ - train loss is 15.635089774150401\n",
      "Steps:  76%|▊| 11328/15000 [1:37:18<11:01,  5.55it/s, lr=0.00099, step_loss=0.2207/27/2023 19:22:08 - INFO - __main__ - train loss is 15.697034359443933\n",
      "Steps:  76%|▊| 11329/15000 [1:37:19<11:00,  5.56it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:08 - INFO - __main__ - train loss is 15.86608098493889\n",
      "Steps:  76%|▊| 11330/15000 [1:37:19<11:05,  5.51it/s, lr=0.00099, step_loss=0.1607/27/2023 19:22:09 - INFO - __main__ - train loss is 15.8950977739878\n",
      "Steps:  76%|▊| 11331/15000 [1:37:19<11:05,  5.52it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:09 - INFO - __main__ - train loss is 16.05030508013442\n",
      "Steps:  76%|▊| 11332/15000 [1:37:19<11:05,  5.51it/s, lr=0.00099, step_loss=0.1507/27/2023 19:22:09 - INFO - __main__ - train loss is 16.346191209275275\n",
      "Steps:  76%|▊| 11333/15000 [1:37:19<11:11,  5.46it/s, lr=0.00099, step_loss=0.2907/27/2023 19:22:09 - INFO - __main__ - train loss is 16.59965268941596\n",
      "Steps:  76%|▊| 11334/15000 [1:37:19<11:09,  5.47it/s, lr=0.00099, step_loss=0.2507/27/2023 19:22:09 - INFO - __main__ - train loss is 16.606110886204988\n",
      "Steps:  76%|▊| 11335/15000 [1:37:20<11:08,  5.48it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:10 - INFO - __main__ - train loss is 16.796411246526986\n",
      "Steps:  76%|▊| 11336/15000 [1:37:20<11:07,  5.49it/s, lr=0.00099, step_loss=0.1907/27/2023 19:22:10 - INFO - __main__ - train loss is 17.72657558368519\n",
      "Steps:  76%|▊| 11337/15000 [1:37:20<11:07,  5.49it/s, lr=0.00099, step_loss=0.9307/27/2023 19:22:10 - INFO - __main__ - train loss is 18.25535520957783\n",
      "Steps:  76%|▊| 11338/15000 [1:37:20<11:12,  5.44it/s, lr=0.00099, step_loss=0.5207/27/2023 19:22:10 - INFO - __main__ - train loss is 18.256981996819377\n",
      "Steps:  76%|▊| 11339/15000 [1:37:20<11:10,  5.46it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:10 - INFO - __main__ - train loss is 18.358407450839877\n",
      "Steps:  76%|▊| 11340/15000 [1:37:21<11:09,  5.47it/s, lr=0.00099, step_loss=0.1007/27/2023 19:22:10 - INFO - __main__ - train loss is 18.740835620090365\n",
      "Steps:  76%|▊| 11341/15000 [1:37:21<11:08,  5.47it/s, lr=0.00099, step_loss=0.3807/27/2023 19:22:11 - INFO - __main__ - train loss is 18.760424187406898\n",
      "Steps:  76%|▊| 11342/15000 [1:37:21<11:07,  5.48it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:11 - INFO - __main__ - train loss is 18.94887170754373\n",
      "Steps:  76%|▊| 11343/15000 [1:37:21<11:07,  5.48it/s, lr=0.00099, step_loss=0.1807/27/2023 19:22:11 - INFO - __main__ - train loss is 18.95295195793733\n",
      "Steps:  76%|▊| 11344/15000 [1:37:21<11:06,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:11 - INFO - __main__ - train loss is 18.9857108569704\n",
      "Steps:  76%|▊| 11345/15000 [1:37:21<11:05,  5.49it/s, lr=0.00099, step_loss=0.0307/27/2023 19:22:11 - INFO - __main__ - train loss is 18.989430153975263\n",
      "Steps:  76%|▊| 11346/15000 [1:37:22<11:05,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:12 - INFO - __main__ - train loss is 18.991357295424677\n",
      "Steps:  76%|▊| 11347/15000 [1:37:22<11:04,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:12 - INFO - __main__ - train loss is 19.035308601916768\n",
      "Steps:  76%|▊| 11348/15000 [1:37:22<11:04,  5.50it/s, lr=0.00099, step_loss=0.0407/27/2023 19:22:12 - INFO - __main__ - train loss is 19.342913779080845\n",
      "Steps:  76%|▊| 11349/15000 [1:37:22<11:04,  5.50it/s, lr=0.00099, step_loss=0.3007/27/2023 19:22:12 - INFO - __main__ - train loss is 19.349042416200973\n",
      "Steps:  76%|▊| 11350/15000 [1:37:22<11:04,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:12 - INFO - __main__ - train loss is 19.359960648813285\n",
      "Steps:  76%|▊| 11351/15000 [1:37:23<11:04,  5.49it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:12 - INFO - __main__ - train loss is 19.622776660718955\n",
      "Steps:  76%|▊| 11352/15000 [1:37:23<11:04,  5.49it/s, lr=0.00099, step_loss=0.2607/27/2023 19:22:13 - INFO - __main__ - train loss is 19.640343408682384\n",
      "Steps:  76%|▊| 11353/15000 [1:37:23<11:04,  5.49it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:13 - INFO - __main__ - train loss is 19.70217173511628\n",
      "Steps:  76%|▊| 11354/15000 [1:37:23<11:03,  5.49it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:13 - INFO - __main__ - train loss is 19.90936987812165\n",
      "Steps:  76%|▊| 11355/15000 [1:37:23<11:03,  5.49it/s, lr=0.00099, step_loss=0.2007/27/2023 19:22:13 - INFO - __main__ - train loss is 20.316710702725686\n",
      "Steps:  76%|▊| 11356/15000 [1:37:23<11:03,  5.49it/s, lr=0.00099, step_loss=0.4007/27/2023 19:22:13 - INFO - __main__ - train loss is 20.68683569843415\n",
      "Steps:  76%|▊| 11357/15000 [1:37:24<11:03,  5.49it/s, lr=0.00099, step_loss=0.3707/27/2023 19:22:14 - INFO - __main__ - train loss is 20.72115879098419\n",
      "Steps:  76%|▊| 11358/15000 [1:37:24<11:03,  5.49it/s, lr=0.00099, step_loss=0.0307/27/2023 19:22:14 - INFO - __main__ - train loss is 20.72257435496431\n",
      "Steps:  76%|▊| 11359/15000 [1:37:24<11:02,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:14 - INFO - __main__ - train loss is 20.808729978161864\n",
      "Steps:  76%|▊| 11360/15000 [1:37:24<11:08,  5.45it/s, lr=0.00099, step_loss=0.0807/27/2023 19:22:14 - INFO - __main__ - train loss is 21.18727931554895\n",
      "Steps:  76%|▊| 11361/15000 [1:37:24<11:06,  5.46it/s, lr=0.00099, step_loss=0.3707/27/2023 19:22:14 - INFO - __main__ - train loss is 21.251347565907054\n",
      "Steps:  76%|▊| 11362/15000 [1:37:25<11:04,  5.47it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:14 - INFO - __main__ - train loss is 21.38028984691482\n",
      "Steps:  76%|▊| 11363/15000 [1:37:25<11:08,  5.44it/s, lr=0.00099, step_loss=0.1207/27/2023 19:22:15 - INFO - __main__ - train loss is 21.42701980646234\n",
      "Steps:  76%|▊| 11364/15000 [1:37:25<11:11,  5.41it/s, lr=0.00099, step_loss=0.0407/27/2023 19:22:15 - INFO - __main__ - train loss is 21.595121191698126\n",
      "Steps:  76%|▊| 11365/15000 [1:37:25<11:08,  5.44it/s, lr=0.00099, step_loss=0.1607/27/2023 19:22:15 - INFO - __main__ - train loss is 21.747907774406485\n",
      "Steps:  76%|▊| 11366/15000 [1:37:25<11:05,  5.46it/s, lr=0.00099, step_loss=0.1507/27/2023 19:22:15 - INFO - __main__ - train loss is 21.792398439603858\n",
      "Steps:  76%|▊| 11367/15000 [1:37:25<11:04,  5.47it/s, lr=0.00099, step_loss=0.0407/27/2023 19:22:15 - INFO - __main__ - train loss is 21.804766187327914\n",
      "Steps:  76%|▊| 11368/15000 [1:37:26<11:02,  5.48it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:16 - INFO - __main__ - train loss is 21.905275860684924\n",
      "Steps:  76%|▊| 11369/15000 [1:37:26<11:01,  5.49it/s, lr=0.00099, step_loss=0.1007/27/2023 19:22:16 - INFO - __main__ - train loss is 22.6146438511787\n",
      "Steps:  76%|▊| 11370/15000 [1:37:26<11:01,  5.49it/s, lr=0.00099, step_loss=0.7007/27/2023 19:22:16 - INFO - __main__ - train loss is 22.811401674407534\n",
      "Steps:  76%|▊| 11371/15000 [1:37:26<11:00,  5.49it/s, lr=0.00099, step_loss=0.1907/27/2023 19:22:16 - INFO - __main__ - train loss is 22.81326289579738\n",
      "Steps:  76%|▊| 11372/15000 [1:37:26<11:00,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:16 - INFO - __main__ - train loss is 22.818312741001137\n",
      "Steps:  76%|▊| 11373/15000 [1:37:27<11:00,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:16 - INFO - __main__ - train loss is 22.919117934186943\n",
      "Steps:  76%|▊| 11374/15000 [1:37:27<10:59,  5.50it/s, lr=0.00099, step_loss=0.1007/27/2023 19:22:17 - INFO - __main__ - train loss is 22.97369307570625\n",
      "Steps:  76%|▊| 11375/15000 [1:37:27<10:59,  5.50it/s, lr=0.00099, step_loss=0.0507/27/2023 19:22:17 - INFO - __main__ - train loss is 22.979661131394096\n",
      "Steps:  76%|▊| 11376/15000 [1:37:27<10:58,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:17 - INFO - __main__ - train loss is 23.52390691090841\n",
      "Steps:  76%|▊| 11377/15000 [1:37:27<10:58,  5.50it/s, lr=0.00099, step_loss=0.5407/27/2023 19:22:17 - INFO - __main__ - train loss is 23.54170111392159\n",
      "Steps:  76%|▊| 11378/15000 [1:37:27<10:58,  5.50it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:17 - INFO - __main__ - train loss is 23.759810632211156\n",
      "Steps:  76%|▊| 11379/15000 [1:37:28<10:58,  5.50it/s, lr=0.00099, step_loss=0.2107/27/2023 19:22:18 - INFO - __main__ - train loss is 23.788956526783295\n",
      "Steps:  76%|▊| 11380/15000 [1:37:28<10:58,  5.50it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:18 - INFO - __main__ - train loss is 24.044991735485382\n",
      "Steps:  76%|▊| 11381/15000 [1:37:28<10:58,  5.50it/s, lr=0.00099, step_loss=0.2507/27/2023 19:22:18 - INFO - __main__ - train loss is 24.17514188971836\n",
      "Steps:  76%|▊| 11382/15000 [1:37:28<10:58,  5.50it/s, lr=0.00099, step_loss=0.1307/27/2023 19:22:18 - INFO - __main__ - train loss is 24.193777486798353\n",
      "Steps:  76%|▊| 11383/15000 [1:37:28<10:57,  5.50it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:18 - INFO - __main__ - train loss is 24.19949229725171\n",
      "Steps:  76%|▊| 11384/15000 [1:37:29<10:57,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:18 - INFO - __main__ - train loss is 24.287617757101543\n",
      "Steps:  76%|▊| 11385/15000 [1:37:29<10:57,  5.50it/s, lr=0.00099, step_loss=0.0807/27/2023 19:22:19 - INFO - __main__ - train loss is 24.290997289237566\n",
      "Steps:  76%|▊| 11386/15000 [1:37:29<10:56,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:19 - INFO - __main__ - train loss is 24.294165013707243\n",
      "Steps:  76%|▊| 11387/15000 [1:37:29<10:56,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:19 - INFO - __main__ - train loss is 24.35535816324409\n",
      "Steps:  76%|▊| 11388/15000 [1:37:29<10:56,  5.50it/s, lr=0.00099, step_loss=0.0607/27/2023 19:22:19 - INFO - __main__ - train loss is 25.019128362066112\n",
      "Steps:  76%|▊| 11389/15000 [1:37:29<10:56,  5.50it/s, lr=0.00099, step_loss=0.6607/27/2023 19:22:19 - INFO - __main__ - train loss is 25.02309188095387\n",
      "Steps:  76%|▊| 11390/15000 [1:37:30<10:56,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:20 - INFO - __main__ - train loss is 25.175264595425688\n",
      "Steps:  76%|▊| 11391/15000 [1:37:30<10:56,  5.50it/s, lr=0.00099, step_loss=0.1507/27/2023 19:22:20 - INFO - __main__ - train loss is 25.260292640305124\n",
      "Steps:  76%|▊| 11392/15000 [1:37:30<10:55,  5.50it/s, lr=0.00099, step_loss=0.0807/27/2023 19:22:20 - INFO - __main__ - train loss is 25.341099961078726\n",
      "Steps:  76%|▊| 11393/15000 [1:37:30<10:55,  5.50it/s, lr=0.00099, step_loss=0.0807/27/2023 19:22:20 - INFO - __main__ - train loss is 25.369417863315903\n",
      "Steps:  76%|▊| 11394/15000 [1:37:30<10:55,  5.50it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:20 - INFO - __main__ - train loss is 25.633428233093582\n",
      "Steps:  76%|▊| 11395/15000 [1:37:31<10:55,  5.50it/s, lr=0.00099, step_loss=0.2607/27/2023 19:22:20 - INFO - __main__ - train loss is 26.085879491991363\n",
      "Steps:  76%|▊| 11396/15000 [1:37:31<10:55,  5.50it/s, lr=0.00099, step_loss=0.4507/27/2023 19:22:21 - INFO - __main__ - train loss is 26.143966259784065\n",
      "Steps:  76%|▊| 11397/15000 [1:37:31<10:55,  5.50it/s, lr=0.00099, step_loss=0.0507/27/2023 19:22:21 - INFO - __main__ - train loss is 26.14546142006293\n",
      "Steps:  76%|▊| 11398/15000 [1:37:31<10:54,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:21 - INFO - __main__ - train loss is 26.308706054929644\n",
      "Steps:  76%|▊| 11399/15000 [1:37:31<10:54,  5.50it/s, lr=0.00099, step_loss=0.1607/27/2023 19:22:21 - INFO - __main__ - train loss is 26.50697887921706\n",
      "Steps:  76%|▊| 11400/15000 [1:37:31<10:54,  5.50it/s, lr=0.00099, step_loss=0.1907/27/2023 19:22:21 - INFO - __main__ - train loss is 26.50899274321273\n",
      "Steps:  76%|▊| 11401/15000 [1:37:32<10:54,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:22 - INFO - __main__ - train loss is 26.51900725858286\n",
      "Steps:  76%|▊| 11402/15000 [1:37:32<10:53,  5.50it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:22 - INFO - __main__ - train loss is 26.641627610195428\n",
      "Steps:  76%|▊| 11403/15000 [1:37:32<10:53,  5.50it/s, lr=0.00099, step_loss=0.1207/27/2023 19:22:22 - INFO - __main__ - train loss is 26.766888529527932\n",
      "Steps:  76%|▊| 11404/15000 [1:37:32<10:53,  5.50it/s, lr=0.00099, step_loss=0.1207/27/2023 19:22:22 - INFO - __main__ - train loss is 26.856297038961202\n",
      "Steps:  76%|▊| 11405/15000 [1:37:32<10:54,  5.50it/s, lr=0.00099, step_loss=0.0807/27/2023 19:22:22 - INFO - __main__ - train loss is 26.858322005486116\n",
      "Steps:  76%|▊| 11406/15000 [1:37:33<10:54,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:22 - INFO - __main__ - train loss is 26.86450435151346\n",
      "Steps:  76%|▊| 11407/15000 [1:37:33<10:53,  5.50it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:23 - INFO - __main__ - train loss is 27.26603589882143\n",
      "Steps:  76%|▊| 11408/15000 [1:37:33<10:53,  5.50it/s, lr=0.00099, step_loss=0.4007/27/2023 19:22:23 - INFO - __main__ - train loss is 27.338086783187464\n",
      "Steps:  76%|▊| 11409/15000 [1:37:33<10:53,  5.50it/s, lr=0.00099, step_loss=0.0707/27/2023 19:22:23 - INFO - __main__ - train loss is 27.35847602155991\n",
      "Steps:  76%|▊| 11410/15000 [1:37:33<10:52,  5.50it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:23 - INFO - __main__ - train loss is 27.647791722090915\n",
      "Steps:  76%|▊| 11411/15000 [1:37:33<10:52,  5.50it/s, lr=0.00099, step_loss=0.2807/27/2023 19:22:23 - INFO - __main__ - train loss is 27.673702680738643\n",
      "Steps:  76%|▊| 11412/15000 [1:37:34<10:52,  5.50it/s, lr=0.00099, step_loss=0.0207/27/2023 19:22:24 - INFO - __main__ - train loss is 28.03550096717663\n",
      "Steps:  76%|▊| 11413/15000 [1:37:34<10:54,  5.48it/s, lr=0.00099, step_loss=0.3607/27/2023 19:22:24 - INFO - __main__ - train loss is 28.078489509643987\n",
      "Steps:  76%|▊| 11414/15000 [1:37:34<10:53,  5.49it/s, lr=0.00099, step_loss=0.0407/27/2023 19:22:24 - INFO - __main__ - train loss is 28.084734182571992\n",
      "Steps:  76%|▊| 11415/15000 [1:37:34<10:53,  5.49it/s, lr=0.00099, step_loss=0.0007/27/2023 19:22:24 - INFO - __main__ - train loss is 28.100505865877494\n",
      "Steps:  76%|▊| 11416/15000 [1:37:34<10:52,  5.49it/s, lr=0.00099, step_loss=0.0107/27/2023 19:22:24 - INFO - __main__ - train loss is 28.140464663272724\n",
      "Steps:  76%|▊| 11417/15000 [1:37:35<10:49,  5.52it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:24 - INFO - __main__ - train loss is 28.65298593020998\n",
      "Steps:  76%|▊| 11418/15000 [1:37:35<10:47,  5.53it/s, lr=0.000989, step_loss=0.507/27/2023 19:22:25 - INFO - __main__ - train loss is 28.890452712541446\n",
      "Steps:  76%|▊| 11419/15000 [1:37:35<10:45,  5.54it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:25 - INFO - __main__ - train loss is 29.195808678632602\n",
      "Steps:  76%|▊| 11420/15000 [1:37:35<10:44,  5.55it/s, lr=0.000989, step_loss=0.307/27/2023 19:22:25 - INFO - __main__ - train loss is 29.58652424789034\n",
      "Steps:  76%|▊| 11421/15000 [1:37:35<10:44,  5.56it/s, lr=0.000989, step_loss=0.307/27/2023 19:22:25 - INFO - __main__ - train loss is 29.85244768834673\n",
      "Steps:  76%|▊| 11422/15000 [1:37:35<10:43,  5.56it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:25 - INFO - __main__ - train loss is 29.892627257620916\n",
      "Steps:  76%|▊| 11423/15000 [1:37:36<10:42,  5.56it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:26 - INFO - __main__ - train loss is 29.93376589915715\n",
      "Steps:  76%|▊| 11424/15000 [1:37:36<10:46,  5.53it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:26 - INFO - __main__ - train loss is 29.936603891430423\n",
      "Steps:  76%|▊| 11425/15000 [1:37:36<10:50,  5.49it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:26 - INFO - __main__ - train loss is 29.940630723023787\n",
      "Steps:  76%|▊| 11426/15000 [1:37:36<10:58,  5.43it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:26 - INFO - __main__ - train loss is 29.98071749159135\n",
      "Steps:  76%|▊| 11427/15000 [1:37:36<10:55,  5.45it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:26 - INFO - __main__ - train loss is 30.097204704070464\n",
      "Steps:  76%|▊| 11428/15000 [1:37:37<10:51,  5.48it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:26 - INFO - __main__ - train loss is 30.100208448944613\n",
      "Steps:  76%|▊| 11429/15000 [1:37:37<10:48,  5.51it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:27 - INFO - __main__ - train loss is 30.592312979279086\n",
      "Steps:  76%|▊| 11430/15000 [1:37:37<10:46,  5.52it/s, lr=0.000989, step_loss=0.407/27/2023 19:22:27 - INFO - __main__ - train loss is 30.763884278712794\n",
      "Steps:  76%|▊| 11431/15000 [1:37:37<10:50,  5.49it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:27 - INFO - __main__ - train loss is 30.776792908785865\n",
      "Steps:  76%|▊| 11432/15000 [1:37:37<10:48,  5.50it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:27 - INFO - __main__ - train loss is 31.03334334003739\n",
      "Steps:  76%|▊| 11433/15000 [1:37:37<10:45,  5.52it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:27 - INFO - __main__ - train loss is 31.092999859480187\n",
      "Steps:  76%|▊| 11434/15000 [1:37:38<10:43,  5.54it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:28 - INFO - __main__ - train loss is 31.203243030933663\n",
      "Steps:  76%|▊| 11435/15000 [1:37:38<10:42,  5.54it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:28 - INFO - __main__ - train loss is 31.24593377741985\n",
      "Steps:  76%|▊| 11436/15000 [1:37:38<10:45,  5.52it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:28 - INFO - __main__ - train loss is 31.422425425378606\n",
      "Steps:  76%|▊| 11437/15000 [1:37:38<10:46,  5.51it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:28 - INFO - __main__ - train loss is 31.456954425899312\n",
      "Steps:  76%|▊| 11438/15000 [1:37:38<10:47,  5.50it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:28 - INFO - __main__ - train loss is 31.69941402110271\n",
      "Steps:  76%|▊| 11439/15000 [1:37:39<10:48,  5.49it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:28 - INFO - __main__ - train loss is 31.79348102840595\n",
      "Steps:  76%|▊| 11440/15000 [1:37:39<10:49,  5.48it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:29 - INFO - __main__ - train loss is 31.812053001252934\n",
      "Steps:  76%|▊| 11441/15000 [1:37:39<10:48,  5.49it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:29 - INFO - __main__ - train loss is 32.389171874849126\n",
      "Steps:  76%|▊| 11442/15000 [1:37:39<10:50,  5.47it/s, lr=0.000989, step_loss=0.507/27/2023 19:22:29 - INFO - __main__ - train loss is 32.568407020298764\n",
      "Steps:  76%|▊| 11443/15000 [1:37:39<10:51,  5.46it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:29 - INFO - __main__ - train loss is 32.57621610001661\n",
      "Steps:  76%|▊| 11444/15000 [1:37:40<10:56,  5.42it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:29 - INFO - __main__ - train loss is 32.674798844615\n",
      "Steps:  76%|▊| 11445/15000 [1:37:40<10:59,  5.39it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:30 - INFO - __main__ - train loss is 32.90864018932916\n",
      "Steps:  76%|▊| 11446/15000 [1:37:40<11:13,  5.28it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:30 - INFO - __main__ - train loss is 33.11523072258569\n",
      "Steps:  76%|▊| 11447/15000 [1:37:40<11:19,  5.23it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:30 - INFO - __main__ - train loss is 33.11981792957522\n",
      "Steps:  76%|▊| 11448/15000 [1:37:40<11:24,  5.19it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:30 - INFO - __main__ - train loss is 33.449244575807825\n",
      "Steps:  76%|▊| 11449/15000 [1:37:40<11:27,  5.16it/s, lr=0.000989, step_loss=0.307/27/2023 19:22:30 - INFO - __main__ - train loss is 33.52491352916695\n",
      "Steps:  76%|▊| 11450/15000 [1:37:41<11:29,  5.15it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:31 - INFO - __main__ - train loss is 33.72664121747948\n",
      "Steps:  76%|▊| 11451/15000 [1:37:41<11:29,  5.15it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:31 - INFO - __main__ - train loss is 33.74165628221817\n",
      "Steps:  76%|▊| 11452/15000 [1:37:41<11:30,  5.14it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:31 - INFO - __main__ - train loss is 33.86283148196526\n",
      "Steps:  76%|▊| 11453/15000 [1:37:41<11:31,  5.13it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:31 - INFO - __main__ - train loss is 33.867441883543506\n",
      "Steps:  76%|▊| 11454/15000 [1:37:41<11:33,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:31 - INFO - __main__ - train loss is 34.001035204390064\n",
      "Steps:  76%|▊| 11455/15000 [1:37:42<11:33,  5.11it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:32 - INFO - __main__ - train loss is 34.007703818148\n",
      "Steps:  76%|▊| 11456/15000 [1:37:42<11:33,  5.11it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:32 - INFO - __main__ - train loss is 34.018594646593556\n",
      "Steps:  76%|▊| 11457/15000 [1:37:42<11:32,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:32 - INFO - __main__ - train loss is 34.12631362094544\n",
      "Steps:  76%|▊| 11458/15000 [1:37:42<11:31,  5.12it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:32 - INFO - __main__ - train loss is 34.20077268197201\n",
      "Steps:  76%|▊| 11459/15000 [1:37:42<11:30,  5.13it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:32 - INFO - __main__ - train loss is 34.404438564321026\n",
      "Steps:  76%|▊| 11460/15000 [1:37:43<11:31,  5.12it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:32 - INFO - __main__ - train loss is 34.417289266129956\n",
      "Steps:  76%|▊| 11461/15000 [1:37:43<11:30,  5.13it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:33 - INFO - __main__ - train loss is 34.46419012709521\n",
      "Steps:  76%|▊| 11462/15000 [1:37:43<11:30,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:33 - INFO - __main__ - train loss is 34.56693189009093\n",
      "Steps:  76%|▊| 11463/15000 [1:37:43<11:31,  5.12it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:33 - INFO - __main__ - train loss is 34.58762098639272\n",
      "Steps:  76%|▊| 11464/15000 [1:37:43<11:31,  5.11it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:33 - INFO - __main__ - train loss is 34.94405303685926\n",
      "Steps:  76%|▊| 11465/15000 [1:37:44<11:30,  5.12it/s, lr=0.000989, step_loss=0.307/27/2023 19:22:33 - INFO - __main__ - train loss is 35.13444582908414\n",
      "Steps:  76%|▊| 11466/15000 [1:37:44<11:29,  5.12it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:34 - INFO - __main__ - train loss is 35.43676851480268\n",
      "Steps:  76%|▊| 11467/15000 [1:37:44<11:28,  5.13it/s, lr=0.000989, step_loss=0.307/27/2023 19:22:34 - INFO - __main__ - train loss is 35.55109987943433\n",
      "Steps:  76%|▊| 11468/15000 [1:37:44<11:28,  5.13it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:34 - INFO - __main__ - train loss is 35.56251826859079\n",
      "Steps:  76%|▊| 11469/15000 [1:37:44<11:29,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:34 - INFO - __main__ - train loss is 35.568662457866594\n",
      "Steps:  76%|▊| 11470/15000 [1:37:45<11:28,  5.13it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:34 - INFO - __main__ - train loss is 35.89448215882294\n",
      "Steps:  76%|▊| 11471/15000 [1:37:45<11:28,  5.13it/s, lr=0.000989, step_loss=0.307/27/2023 19:22:35 - INFO - __main__ - train loss is 36.09826623718254\n",
      "Steps:  76%|▊| 11472/15000 [1:37:45<11:29,  5.12it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:35 - INFO - __main__ - train loss is 36.12829803745262\n",
      "Steps:  76%|▊| 11473/15000 [1:37:45<11:28,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:35 - INFO - __main__ - train loss is 36.20879641990177\n",
      "Steps:  76%|▊| 11474/15000 [1:37:45<11:28,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:35 - INFO - __main__ - train loss is 36.26244166563265\n",
      "Steps:  76%|▊| 11475/15000 [1:37:46<11:16,  5.21it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:35 - INFO - __main__ - train loss is 36.3643008924555\n",
      "Steps:  77%|▊| 11476/15000 [1:37:46<11:09,  5.26it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:36 - INFO - __main__ - train loss is 36.45165792922489\n",
      "Steps:  77%|▊| 11477/15000 [1:37:46<11:10,  5.26it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:36 - INFO - __main__ - train loss is 37.318417944712564\n",
      "Steps:  77%|▊| 11478/15000 [1:37:46<11:04,  5.30it/s, lr=0.000989, step_loss=0.807/27/2023 19:22:36 - INFO - __main__ - train loss is 37.347541701747105\n",
      "Steps:  77%|▊| 11479/15000 [1:37:46<11:00,  5.33it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:36 - INFO - __main__ - train loss is 37.41209822590463\n",
      "Steps:  77%|▊| 11480/15000 [1:37:46<10:58,  5.35it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:36 - INFO - __main__ - train loss is 37.41369273653254\n",
      "Steps:  77%|▊| 11481/15000 [1:37:47<11:15,  5.21it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:37 - INFO - __main__ - train loss is 37.42474073683843\n",
      "Steps:  77%|▊| 11482/15000 [1:37:47<11:23,  5.15it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:37 - INFO - __main__ - train loss is 37.43311925185844\n",
      "Steps:  77%|▊| 11483/15000 [1:37:47<11:25,  5.13it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:37 - INFO - __main__ - train loss is 37.51893080724403\n",
      "Steps:  77%|▊| 11484/15000 [1:37:47<11:24,  5.13it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:37 - INFO - __main__ - train loss is 37.80431230319664\n",
      "Steps:  77%|▊| 11485/15000 [1:37:47<11:25,  5.13it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:37 - INFO - __main__ - train loss is 37.8856697822921\n",
      "Steps:  77%|▊| 11486/15000 [1:37:48<11:25,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:38 - INFO - __main__ - train loss is 37.89515395509079\n",
      "Steps:  77%|▊| 11487/15000 [1:37:48<11:25,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:38 - INFO - __main__ - train loss is 38.031328067649156\n",
      "Steps:  77%|▊| 11488/15000 [1:37:48<11:24,  5.13it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:38 - INFO - __main__ - train loss is 38.044131093192846\n",
      "Steps:  77%|▊| 11489/15000 [1:37:48<11:24,  5.13it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:38 - INFO - __main__ - train loss is 38.392858379054815\n",
      "Steps:  77%|▊| 11490/15000 [1:37:48<11:25,  5.12it/s, lr=0.000989, step_loss=0.307/27/2023 19:22:38 - INFO - __main__ - train loss is 38.53080018656328\n",
      "Steps:  77%|▊| 11491/15000 [1:37:49<11:24,  5.13it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:39 - INFO - __main__ - train loss is 38.69876714842394\n",
      "Steps:  77%|▊| 11492/15000 [1:37:49<11:24,  5.13it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:39 - INFO - __main__ - train loss is 38.70022453437559\n",
      "Steps:  77%|▊| 11493/15000 [1:37:49<11:24,  5.13it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:39 - INFO - __main__ - train loss is 38.70139686902985\n",
      "Steps:  77%|▊| 11494/15000 [1:37:49<11:24,  5.12it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:39 - INFO - __main__ - train loss is 38.88054852327332\n",
      "Steps:  77%|▊| 11495/15000 [1:37:49<11:31,  5.07it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:39 - INFO - __main__ - train loss is 39.06897033890709\n",
      "Steps:  77%|▊| 11496/15000 [1:37:50<11:22,  5.14it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:39 - INFO - __main__ - train loss is 39.159575880970806\n",
      "Steps:  77%|▊| 11497/15000 [1:37:50<11:15,  5.19it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:40 - INFO - __main__ - train loss is 39.40982645889744\n",
      "Steps:  77%|▊| 11498/15000 [1:37:50<11:18,  5.16it/s, lr=0.000989, step_loss=0.207/27/2023 19:22:40 - INFO - __main__ - train loss is 39.56508688768372\n",
      "Steps:  77%|▊| 11499/15000 [1:37:50<11:19,  5.15it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:40 - INFO - __main__ - train loss is 39.576541082467884\n",
      "Steps:  77%|▊| 11500/15000 [1:37:50<11:20,  5.14it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:40 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-11500\n",
      "07/27/2023 19:22:40 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:22:40,663] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:22:40,669] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-11500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:22:40,669] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-11500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:22:40,677] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-11500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:22:40,678] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-11500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:22:40,687] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-11500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:22:40,688] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-11500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:22:40,688] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:22:40 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-11500/pytorch_model\n",
      "07/27/2023 19:22:40 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-11500/scheduler.bin\n",
      "07/27/2023 19:22:40 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-11500/random_states_0.pkl\n",
      "07/27/2023 19:22:40 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-11500\n",
      "Steps:  77%|▊| 11500/15000 [1:37:50<11:20,  5.14it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:40 - INFO - __main__ - train loss is 39.59058338450268\n",
      "Steps:  77%|▊| 11501/15000 [1:37:51<11:45,  4.96it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:40 - INFO - __main__ - train loss is 39.62298604892567\n",
      "Steps:  77%|▊| 11502/15000 [1:37:51<11:39,  5.00it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:41 - INFO - __main__ - train loss is 39.78552931593731\n",
      "Steps:  77%|▊| 11503/15000 [1:37:51<11:34,  5.03it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:41 - INFO - __main__ - train loss is 39.84057810949162\n",
      "Steps:  77%|▊| 11504/15000 [1:37:51<11:30,  5.06it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:41 - INFO - __main__ - train loss is 39.84779321588576\n",
      "Steps:  77%|▊| 11505/15000 [1:37:51<11:29,  5.07it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:41 - INFO - __main__ - train loss is 39.86706403456628\n",
      "Steps:  77%|▊| 11506/15000 [1:37:52<11:27,  5.08it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:41 - INFO - __main__ - train loss is 39.90499193407595\n",
      "Steps:  77%|▊| 11507/15000 [1:37:52<11:24,  5.10it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:42 - INFO - __main__ - train loss is 39.90673879964743\n",
      "Steps:  77%|▊| 11508/15000 [1:37:52<11:23,  5.11it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:42 - INFO - __main__ - train loss is 40.03806118352804\n",
      "Steps:  77%|▊| 11509/15000 [1:37:52<11:12,  5.19it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:42 - INFO - __main__ - train loss is 40.168094289139844\n",
      "Steps:  77%|▊| 11510/15000 [1:37:52<11:03,  5.26it/s, lr=0.000989, step_loss=0.107/27/2023 19:22:42 - INFO - __main__ - train loss is 40.185972851351835\n",
      "Steps:  77%|▊| 11511/15000 [1:37:53<10:53,  5.34it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:42 - INFO - __main__ - train loss is 40.18830017384607\n",
      "Steps:  77%|▊| 11512/15000 [1:37:53<10:44,  5.41it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:43 - INFO - __main__ - train loss is 40.18957360892091\n",
      "Steps:  77%|▊| 11513/15000 [1:37:53<10:38,  5.46it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:43 - INFO - __main__ - train loss is 40.20380643068347\n",
      "Steps:  77%|▊| 11514/15000 [1:37:53<15:05,  3.85it/s, lr=0.000989, step_loss=0.007/27/2023 19:22:44 - INFO - __main__ - Per validation step average loss is 0.05193910002708435\n",
      "07/27/2023 19:22:44 - INFO - __main__ - Cumulative validation average loss is 0.05193910002708435\n",
      "07/27/2023 19:22:44 - INFO - __main__ - Per validation step average loss is 0.20856158435344696\n",
      "07/27/2023 19:22:44 - INFO - __main__ - Cumulative validation average loss is 0.2605006843805313\n",
      "07/27/2023 19:22:45 - INFO - __main__ - Per validation step average loss is 0.3784557580947876\n",
      "07/27/2023 19:22:45 - INFO - __main__ - Cumulative validation average loss is 0.6389564424753189\n",
      "07/27/2023 19:22:45 - INFO - __main__ - Per validation step average loss is 0.030383611097931862\n",
      "07/27/2023 19:22:45 - INFO - __main__ - Cumulative validation average loss is 0.6693400535732508\n",
      "07/27/2023 19:22:46 - INFO - __main__ - Per validation step average loss is 0.03572240471839905\n",
      "07/27/2023 19:22:46 - INFO - __main__ - Cumulative validation average loss is 0.7050624582916498\n",
      "07/27/2023 19:22:46 - INFO - __main__ - Per validation step average loss is 0.0200600977987051\n",
      "07/27/2023 19:22:46 - INFO - __main__ - Cumulative validation average loss is 0.7251225560903549\n",
      "07/27/2023 19:22:47 - INFO - __main__ - Per validation step average loss is 0.11573578417301178\n",
      "07/27/2023 19:22:47 - INFO - __main__ - Cumulative validation average loss is 0.8408583402633667\n",
      "07/27/2023 19:22:47 - INFO - __main__ - Per validation step average loss is 0.0492890402674675\n",
      "07/27/2023 19:22:47 - INFO - __main__ - Cumulative validation average loss is 0.8901473805308342\n",
      "07/27/2023 19:22:47 - INFO - __main__ - Per validation step average loss is 0.03419741243124008\n",
      "07/27/2023 19:22:47 - INFO - __main__ - Cumulative validation average loss is 0.9243447929620743\n",
      "07/27/2023 19:22:48 - INFO - __main__ - Per validation step average loss is 0.03175373375415802\n",
      "07/27/2023 19:22:48 - INFO - __main__ - Cumulative validation average loss is 0.9560985267162323\n",
      "07/27/2023 19:22:48 - INFO - __main__ - Per validation step average loss is 0.007364990189671516\n",
      "07/27/2023 19:22:48 - INFO - __main__ - Cumulative validation average loss is 0.9634635169059038\n",
      "07/27/2023 19:22:49 - INFO - __main__ - Per validation step average loss is 0.3592005968093872\n",
      "07/27/2023 19:22:49 - INFO - __main__ - Cumulative validation average loss is 1.322664113715291\n",
      "07/27/2023 19:22:49 - INFO - __main__ - Per validation step average loss is 0.342587411403656\n",
      "07/27/2023 19:22:49 - INFO - __main__ - Cumulative validation average loss is 1.665251525118947\n",
      "07/27/2023 19:22:49 - INFO - __main__ - Per validation step average loss is 0.19629104435443878\n",
      "07/27/2023 19:22:49 - INFO - __main__ - Cumulative validation average loss is 1.8615425694733858\n",
      "07/27/2023 19:22:50 - INFO - __main__ - Per validation step average loss is 0.1892065405845642\n",
      "07/27/2023 19:22:50 - INFO - __main__ - Cumulative validation average loss is 2.05074911005795\n",
      "07/27/2023 19:22:50 - INFO - __main__ - Per validation step average loss is 0.07315148413181305\n",
      "07/27/2023 19:22:50 - INFO - __main__ - Cumulative validation average loss is 2.123900594189763\n",
      "07/27/2023 19:22:51 - INFO - __main__ - Per validation step average loss is 0.03165264055132866\n",
      "07/27/2023 19:22:51 - INFO - __main__ - Cumulative validation average loss is 2.1555532347410917\n",
      "07/27/2023 19:22:51 - INFO - __main__ - Per validation step average loss is 0.04664408788084984\n",
      "07/27/2023 19:22:51 - INFO - __main__ - Cumulative validation average loss is 2.2021973226219416\n",
      "07/27/2023 19:22:52 - INFO - __main__ - Per validation step average loss is 0.0043433355167508125\n",
      "07/27/2023 19:22:52 - INFO - __main__ - Cumulative validation average loss is 2.2065406581386924\n",
      "07/27/2023 19:22:52 - INFO - __main__ - Per validation step average loss is 0.3526512682437897\n",
      "07/27/2023 19:22:52 - INFO - __main__ - Cumulative validation average loss is 2.559191926382482\n",
      "07/27/2023 19:22:52 - INFO - __main__ - Per validation step average loss is 0.5084832906723022\n",
      "07/27/2023 19:22:52 - INFO - __main__ - Cumulative validation average loss is 3.0676752170547843\n",
      "07/27/2023 19:22:53 - INFO - __main__ - Per validation step average loss is 0.21567115187644958\n",
      "07/27/2023 19:22:53 - INFO - __main__ - Cumulative validation average loss is 3.283346368931234\n",
      "07/27/2023 19:22:53 - INFO - __main__ - Per validation step average loss is 0.002603854751214385\n",
      "07/27/2023 19:22:53 - INFO - __main__ - Cumulative validation average loss is 3.2859502236824483\n",
      "07/27/2023 19:22:54 - INFO - __main__ - Per validation step average loss is 0.3909291923046112\n",
      "07/27/2023 19:22:54 - INFO - __main__ - Cumulative validation average loss is 3.6768794159870595\n",
      "07/27/2023 19:22:54 - INFO - __main__ - Per validation step average loss is 0.0014413759345188737\n",
      "07/27/2023 19:22:54 - INFO - __main__ - Cumulative validation average loss is 3.6783207919215783\n",
      "07/27/2023 19:22:54 - INFO - __main__ - Per validation step average loss is 0.010242070071399212\n",
      "07/27/2023 19:22:54 - INFO - __main__ - Cumulative validation average loss is 3.6885628619929776\n",
      "07/27/2023 19:22:55 - INFO - __main__ - Per validation step average loss is 0.31555378437042236\n",
      "07/27/2023 19:22:55 - INFO - __main__ - Cumulative validation average loss is 4.0041166463634\n",
      "07/27/2023 19:22:55 - INFO - __main__ - Per validation step average loss is 0.08019789308309555\n",
      "07/27/2023 19:22:55 - INFO - __main__ - Cumulative validation average loss is 4.0843145394464955\n",
      "07/27/2023 19:22:56 - INFO - __main__ - Per validation step average loss is 0.007556784898042679\n",
      "07/27/2023 19:22:56 - INFO - __main__ - Cumulative validation average loss is 4.091871324344538\n",
      "07/27/2023 19:22:56 - INFO - __main__ - Per validation step average loss is 0.29118335247039795\n",
      "07/27/2023 19:22:56 - INFO - __main__ - Cumulative validation average loss is 4.383054676814936\n",
      "07/27/2023 19:22:56 - INFO - __main__ - Per validation step average loss is 0.45372939109802246\n",
      "07/27/2023 19:22:56 - INFO - __main__ - Cumulative validation average loss is 4.836784067912959\n",
      "07/27/2023 19:22:57 - INFO - __main__ - Per validation step average loss is 0.0029865961987525225\n",
      "07/27/2023 19:22:57 - INFO - __main__ - Cumulative validation average loss is 4.839770664111711\n",
      "07/27/2023 19:22:57 - INFO - __main__ - Per validation step average loss is 0.08339107036590576\n",
      "07/27/2023 19:22:57 - INFO - __main__ - Cumulative validation average loss is 4.923161734477617\n",
      "07/27/2023 19:22:58 - INFO - __main__ - Per validation step average loss is 0.24773043394088745\n",
      "07/27/2023 19:22:58 - INFO - __main__ - Cumulative validation average loss is 5.170892168418504\n",
      "07/27/2023 19:22:58 - INFO - __main__ - Per validation step average loss is 0.02379540167748928\n",
      "07/27/2023 19:22:58 - INFO - __main__ - Cumulative validation average loss is 5.194687570095994\n",
      "07/27/2023 19:22:59 - INFO - __main__ - Per validation step average loss is 0.3163418471813202\n",
      "07/27/2023 19:22:59 - INFO - __main__ - Cumulative validation average loss is 5.511029417277314\n",
      "07/27/2023 19:22:59 - INFO - __main__ - Per validation step average loss is 0.32862067222595215\n",
      "07/27/2023 19:22:59 - INFO - __main__ - Cumulative validation average loss is 5.839650089503266\n",
      "07/27/2023 19:22:59 - INFO - __main__ - Per validation step average loss is 0.02122103050351143\n",
      "07/27/2023 19:22:59 - INFO - __main__ - Cumulative validation average loss is 5.860871120006777\n",
      "07/27/2023 19:23:00 - INFO - __main__ - Per validation step average loss is 0.09920130670070648\n",
      "07/27/2023 19:23:00 - INFO - __main__ - Cumulative validation average loss is 5.960072426707484\n",
      "07/27/2023 19:23:00 - INFO - __main__ - Per validation step average loss is 0.3382778763771057\n",
      "07/27/2023 19:23:00 - INFO - __main__ - Cumulative validation average loss is 6.2983503030845895\n",
      "07/27/2023 19:23:01 - INFO - __main__ - Per validation step average loss is 0.03477738797664642\n",
      "07/27/2023 19:23:01 - INFO - __main__ - Cumulative validation average loss is 6.333127691061236\n",
      "07/27/2023 19:23:01 - INFO - __main__ - Per validation step average loss is 0.006323915906250477\n",
      "07/27/2023 19:23:01 - INFO - __main__ - Cumulative validation average loss is 6.339451606967486\n",
      "07/27/2023 19:23:01 - INFO - __main__ - Per validation step average loss is 0.03320597857236862\n",
      "07/27/2023 19:23:01 - INFO - __main__ - Cumulative validation average loss is 6.372657585539855\n",
      "07/27/2023 19:23:02 - INFO - __main__ - Per validation step average loss is 0.0011579830897971988\n",
      "07/27/2023 19:23:02 - INFO - __main__ - Cumulative validation average loss is 6.373815568629652\n",
      "07/27/2023 19:23:02 - INFO - __main__ - Per validation step average loss is 0.013696678914129734\n",
      "07/27/2023 19:23:02 - INFO - __main__ - Cumulative validation average loss is 6.387512247543782\n",
      "07/27/2023 19:23:03 - INFO - __main__ - Per validation step average loss is 0.31406623125076294\n",
      "07/27/2023 19:23:03 - INFO - __main__ - Cumulative validation average loss is 6.701578478794545\n",
      "07/27/2023 19:23:03 - INFO - __main__ - Per validation step average loss is 0.014642215333878994\n",
      "07/27/2023 19:23:03 - INFO - __main__ - Cumulative validation average loss is 6.716220694128424\n",
      "07/27/2023 19:23:03 - INFO - __main__ - Per validation step average loss is 0.01623283512890339\n",
      "07/27/2023 19:23:03 - INFO - __main__ - Cumulative validation average loss is 6.732453529257327\n",
      "07/27/2023 19:23:04 - INFO - __main__ - Per validation step average loss is 0.2802804708480835\n",
      "07/27/2023 19:23:04 - INFO - __main__ - Cumulative validation average loss is 7.012734000105411\n",
      "07/27/2023 19:23:04 - INFO - __main__ - Per validation step average loss is 0.0015506939962506294\n",
      "07/27/2023 19:23:04 - INFO - __main__ - Cumulative validation average loss is 7.014284694101661\n",
      "07/27/2023 19:23:05 - INFO - __main__ - Per validation step average loss is 0.00955711118876934\n",
      "07/27/2023 19:23:05 - INFO - __main__ - Cumulative validation average loss is 7.023841805290431\n",
      "07/27/2023 19:23:05 - INFO - __main__ - Per validation step average loss is 0.07643149793148041\n",
      "07/27/2023 19:23:05 - INFO - __main__ - Cumulative validation average loss is 7.100273303221911\n",
      "07/27/2023 19:23:06 - INFO - __main__ - Per validation step average loss is 0.025823481380939484\n",
      "07/27/2023 19:23:06 - INFO - __main__ - Cumulative validation average loss is 7.126096784602851\n",
      "07/27/2023 19:23:06 - INFO - __main__ - Per validation step average loss is 0.28729498386383057\n",
      "07/27/2023 19:23:06 - INFO - __main__ - Cumulative validation average loss is 7.413391768466681\n",
      "07/27/2023 19:23:06 - INFO - __main__ - Per validation step average loss is 0.07478588819503784\n",
      "07/27/2023 19:23:06 - INFO - __main__ - Cumulative validation average loss is 7.488177656661719\n",
      "07/27/2023 19:23:07 - INFO - __main__ - Per validation step average loss is 0.15113936364650726\n",
      "07/27/2023 19:23:07 - INFO - __main__ - Cumulative validation average loss is 7.639317020308226\n",
      "07/27/2023 19:23:07 - INFO - __main__ - Per validation step average loss is 0.09648842364549637\n",
      "07/27/2023 19:23:07 - INFO - __main__ - Cumulative validation average loss is 7.735805443953723\n",
      "07/27/2023 19:23:08 - INFO - __main__ - Per validation step average loss is 0.3933139443397522\n",
      "07/27/2023 19:23:08 - INFO - __main__ - Cumulative validation average loss is 8.129119388293475\n",
      "07/27/2023 19:23:08 - INFO - __main__ - Per validation step average loss is 0.013481905683875084\n",
      "07/27/2023 19:23:08 - INFO - __main__ - Cumulative validation average loss is 8.14260129397735\n",
      "07/27/2023 19:23:08 - INFO - __main__ - Per validation step average loss is 0.04534777253866196\n",
      "07/27/2023 19:23:08 - INFO - __main__ - Cumulative validation average loss is 8.187949066516012\n",
      "07/27/2023 19:23:09 - INFO - __main__ - Per validation step average loss is 0.007873055525124073\n",
      "07/27/2023 19:23:09 - INFO - __main__ - Cumulative validation average loss is 8.195822122041136\n",
      "07/27/2023 19:23:09 - INFO - __main__ - Per validation step average loss is 0.16487713158130646\n",
      "07/27/2023 19:23:09 - INFO - __main__ - Cumulative validation average loss is 8.360699253622442\n",
      "07/27/2023 19:23:10 - INFO - __main__ - Per validation step average loss is 0.11536000669002533\n",
      "07/27/2023 19:23:10 - INFO - __main__ - Cumulative validation average loss is 8.476059260312468\n",
      "07/27/2023 19:23:10 - INFO - __main__ - Per validation step average loss is 0.0025045466609299183\n",
      "07/27/2023 19:23:10 - INFO - __main__ - Cumulative validation average loss is 8.478563806973398\n",
      "07/27/2023 19:23:11 - INFO - __main__ - Per validation step average loss is 0.30606138706207275\n",
      "07/27/2023 19:23:11 - INFO - __main__ - Cumulative validation average loss is 8.78462519403547\n",
      "07/27/2023 19:23:11 - INFO - __main__ - Per validation step average loss is 0.3718695342540741\n",
      "07/27/2023 19:23:11 - INFO - __main__ - Cumulative validation average loss is 9.156494728289545\n",
      "07/27/2023 19:23:11 - INFO - __main__ - Per validation step average loss is 0.009092886000871658\n",
      "07/27/2023 19:23:11 - INFO - __main__ - Cumulative validation average loss is 9.165587614290416\n",
      "07/27/2023 19:23:12 - INFO - __main__ - Per validation step average loss is 0.07309523224830627\n",
      "07/27/2023 19:23:12 - INFO - __main__ - Cumulative validation average loss is 9.238682846538723\n",
      "07/27/2023 19:23:12 - INFO - __main__ - Per validation step average loss is 0.035316094756126404\n",
      "07/27/2023 19:23:12 - INFO - __main__ - Cumulative validation average loss is 9.273998941294849\n",
      "07/27/2023 19:23:13 - INFO - __main__ - Per validation step average loss is 0.4323407709598541\n",
      "07/27/2023 19:23:13 - INFO - __main__ - Cumulative validation average loss is 9.706339712254703\n",
      "07/27/2023 19:23:13 - INFO - __main__ - Per validation step average loss is 0.011545638553798199\n",
      "07/27/2023 19:23:13 - INFO - __main__ - Cumulative validation average loss is 9.717885350808501\n",
      "07/27/2023 19:23:13 - INFO - __main__ - Per validation step average loss is 0.04719341918826103\n",
      "07/27/2023 19:23:13 - INFO - __main__ - Cumulative validation average loss is 9.765078769996762\n",
      "07/27/2023 19:23:14 - INFO - __main__ - Per validation step average loss is 0.0014503458514809608\n",
      "07/27/2023 19:23:14 - INFO - __main__ - Cumulative validation average loss is 9.766529115848243\n",
      "07/27/2023 19:23:14 - INFO - __main__ - Per validation step average loss is 0.031032439321279526\n",
      "07/27/2023 19:23:14 - INFO - __main__ - Cumulative validation average loss is 9.797561555169523\n",
      "07/27/2023 19:23:15 - INFO - __main__ - Per validation step average loss is 0.2051159143447876\n",
      "07/27/2023 19:23:15 - INFO - __main__ - Cumulative validation average loss is 10.00267746951431\n",
      "07/27/2023 19:23:15 - INFO - __main__ - Per validation step average loss is 0.023911844938993454\n",
      "07/27/2023 19:23:15 - INFO - __main__ - Cumulative validation average loss is 10.026589314453304\n",
      "07/27/2023 19:23:16 - INFO - __main__ - Per validation step average loss is 0.08048354834318161\n",
      "07/27/2023 19:23:16 - INFO - __main__ - Cumulative validation average loss is 10.107072862796485\n",
      "07/27/2023 19:23:16 - INFO - __main__ - Per validation step average loss is 0.41892683506011963\n",
      "07/27/2023 19:23:16 - INFO - __main__ - Cumulative validation average loss is 10.525999697856605\n",
      "07/27/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.0035556380171328783\n",
      "07/27/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 10.529555335873738\n",
      "07/27/2023 19:23:17 - INFO - __main__ - Average validation loss for Epoch 37 is 0.13328551058068022\n",
      "07/27/2023 19:23:17 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:24:14 - INFO - __main__ - Starting epoch 38\n",
      "07/27/2023 19:24:14 - INFO - __main__ - train loss is 0.0024782957043498755\n",
      "Steps:  77%|▊| 11515/15000 [1:39:25<26:41:14, 27.57s/it, lr=0.000989, step_loss=07/27/2023 19:24:14 - INFO - __main__ - train loss is 0.005664417752996087\n",
      "Steps:  77%|▊| 11516/15000 [1:39:25<18:43:41, 19.35s/it, lr=0.000989, step_loss=07/27/2023 19:24:15 - INFO - __main__ - train loss is 0.24825970293022692\n",
      "Steps:  77%|▊| 11517/15000 [1:39:25<13:09:29, 13.60s/it, lr=0.000989, step_loss=07/27/2023 19:24:15 - INFO - __main__ - train loss is 0.28035757900215685\n",
      "Steps:  77%|▊| 11518/15000 [1:39:25<9:15:42,  9.58s/it, lr=0.000989, step_loss=007/27/2023 19:24:15 - INFO - __main__ - train loss is 0.2879273712169379\n",
      "Steps:  77%|▊| 11519/15000 [1:39:25<6:31:59,  6.76s/it, lr=0.000989, step_loss=007/27/2023 19:24:15 - INFO - __main__ - train loss is 0.3284699588548392\n",
      "Steps:  77%|▊| 11520/15000 [1:39:26<4:37:25,  4.78s/it, lr=0.000989, step_loss=007/27/2023 19:24:15 - INFO - __main__ - train loss is 0.4736244350206107\n",
      "Steps:  77%|▊| 11521/15000 [1:39:26<3:17:18,  3.40s/it, lr=0.000989, step_loss=007/27/2023 19:24:16 - INFO - __main__ - train loss is 0.826883104396984\n",
      "Steps:  77%|▊| 11522/15000 [1:39:26<2:21:11,  2.44s/it, lr=0.000989, step_loss=007/27/2023 19:24:16 - INFO - __main__ - train loss is 0.8614351272117347\n",
      "Steps:  77%|▊| 11523/15000 [1:39:26<1:41:54,  1.76s/it, lr=0.000989, step_loss=007/27/2023 19:24:16 - INFO - __main__ - train loss is 1.2634195804130286\n",
      "Steps:  77%|▊| 11524/15000 [1:39:26<1:14:25,  1.28s/it, lr=0.000989, step_loss=007/27/2023 19:24:16 - INFO - __main__ - train loss is 1.2852630920242518\n",
      "Steps:  77%|▊| 11525/15000 [1:39:26<55:13,  1.05it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:16 - INFO - __main__ - train loss is 1.2973567366134375\n",
      "Steps:  77%|▊| 11526/15000 [1:39:27<41:44,  1.39it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:16 - INFO - __main__ - train loss is 1.3049530067946762\n",
      "Steps:  77%|▊| 11527/15000 [1:39:27<32:20,  1.79it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:17 - INFO - __main__ - train loss is 1.3074756243731827\n",
      "Steps:  77%|▊| 11528/15000 [1:39:27<25:49,  2.24it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:17 - INFO - __main__ - train loss is 1.4399249532725662\n",
      "Steps:  77%|▊| 11529/15000 [1:39:27<21:13,  2.73it/s, lr=0.000989, step_loss=0.107/27/2023 19:24:17 - INFO - __main__ - train loss is 1.4623629001434892\n",
      "Steps:  77%|▊| 11530/15000 [1:39:27<17:58,  3.22it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:17 - INFO - __main__ - train loss is 1.4923113395925611\n",
      "Steps:  77%|▊| 11531/15000 [1:39:27<15:40,  3.69it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:17 - INFO - __main__ - train loss is 1.6410915513988584\n",
      "Steps:  77%|▊| 11532/15000 [1:39:28<14:05,  4.10it/s, lr=0.000989, step_loss=0.107/27/2023 19:24:18 - INFO - __main__ - train loss is 1.6665994075592607\n",
      "Steps:  77%|▊| 11533/15000 [1:39:28<12:57,  4.46it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:18 - INFO - __main__ - train loss is 1.6874773630406708\n",
      "Steps:  77%|▊| 11534/15000 [1:39:28<12:14,  4.72it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:18 - INFO - __main__ - train loss is 1.6896125110797584\n",
      "Steps:  77%|▊| 11535/15000 [1:39:28<11:40,  4.95it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:18 - INFO - __main__ - train loss is 1.884113613050431\n",
      "Steps:  77%|▊| 11536/15000 [1:39:28<11:16,  5.12it/s, lr=0.000989, step_loss=0.107/27/2023 19:24:18 - INFO - __main__ - train loss is 1.930506098549813\n",
      "Steps:  77%|▊| 11537/15000 [1:39:29<10:59,  5.25it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:18 - INFO - __main__ - train loss is 1.9647349673323333\n",
      "Steps:  77%|▊| 11538/15000 [1:39:29<10:48,  5.34it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:19 - INFO - __main__ - train loss is 2.5161674576811492\n",
      "Steps:  77%|▊| 11539/15000 [1:39:29<10:39,  5.41it/s, lr=0.000989, step_loss=0.507/27/2023 19:24:19 - INFO - __main__ - train loss is 2.5463433298282325\n",
      "Steps:  77%|▊| 11540/15000 [1:39:29<10:33,  5.46it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:19 - INFO - __main__ - train loss is 2.5761772743426263\n",
      "Steps:  77%|▊| 11541/15000 [1:39:29<10:29,  5.49it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:19 - INFO - __main__ - train loss is 2.5789592498913407\n",
      "Steps:  77%|▊| 11542/15000 [1:39:29<10:26,  5.52it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:19 - INFO - __main__ - train loss is 2.914087944664061\n",
      "Steps:  77%|▊| 11543/15000 [1:39:30<10:24,  5.54it/s, lr=0.000989, step_loss=0.307/27/2023 19:24:20 - INFO - __main__ - train loss is 2.921618909575045\n",
      "Steps:  77%|▊| 11544/15000 [1:39:30<10:22,  5.55it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:20 - INFO - __main__ - train loss is 3.2718448350206017\n",
      "Steps:  77%|▊| 11545/15000 [1:39:30<10:20,  5.57it/s, lr=0.000989, step_loss=0.307/27/2023 19:24:20 - INFO - __main__ - train loss is 3.275876567699015\n",
      "Steps:  77%|▊| 11546/15000 [1:39:30<10:20,  5.57it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:20 - INFO - __main__ - train loss is 3.2774023830424994\n",
      "Steps:  77%|▊| 11547/15000 [1:39:30<10:19,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:20 - INFO - __main__ - train loss is 3.2795735562685877\n",
      "Steps:  77%|▊| 11548/15000 [1:39:31<10:18,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:20 - INFO - __main__ - train loss is 3.2822496036533266\n",
      "Steps:  77%|▊| 11549/15000 [1:39:31<10:18,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:21 - INFO - __main__ - train loss is 3.61692575016059\n",
      "Steps:  77%|▊| 11550/15000 [1:39:31<10:17,  5.58it/s, lr=0.000989, step_loss=0.307/27/2023 19:24:21 - INFO - __main__ - train loss is 3.9391398469451815\n",
      "Steps:  77%|▊| 11551/15000 [1:39:31<10:17,  5.59it/s, lr=0.000989, step_loss=0.307/27/2023 19:24:21 - INFO - __main__ - train loss is 3.9413482372183353\n",
      "Steps:  77%|▊| 11552/15000 [1:39:31<10:17,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:21 - INFO - __main__ - train loss is 4.005330068292096\n",
      "Steps:  77%|▊| 11553/15000 [1:39:31<10:17,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:21 - INFO - __main__ - train loss is 4.297404331387952\n",
      "Steps:  77%|▊| 11554/15000 [1:39:32<10:17,  5.58it/s, lr=0.000989, step_loss=0.207/27/2023 19:24:21 - INFO - __main__ - train loss is 4.355459624202922\n",
      "Steps:  77%|▊| 11555/15000 [1:39:32<10:17,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:22 - INFO - __main__ - train loss is 4.4447479483205825\n",
      "Steps:  77%|▊| 11556/15000 [1:39:32<10:17,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:22 - INFO - __main__ - train loss is 4.644568854244426\n",
      "Steps:  77%|▊| 11557/15000 [1:39:32<10:19,  5.56it/s, lr=0.000989, step_loss=0.207/27/2023 19:24:22 - INFO - __main__ - train loss is 4.720396020682529\n",
      "Steps:  77%|▊| 11558/15000 [1:39:32<10:24,  5.51it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:22 - INFO - __main__ - train loss is 4.726620435947552\n",
      "Steps:  77%|▊| 11559/15000 [1:39:33<10:24,  5.51it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:22 - INFO - __main__ - train loss is 5.064929127926007\n",
      "Steps:  77%|▊| 11560/15000 [1:39:33<10:21,  5.53it/s, lr=0.000989, step_loss=0.307/27/2023 19:24:23 - INFO - __main__ - train loss is 5.070290346862748\n",
      "Steps:  77%|▊| 11561/15000 [1:39:33<10:20,  5.55it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:23 - INFO - __main__ - train loss is 5.113764581503347\n",
      "Steps:  77%|▊| 11562/15000 [1:39:33<10:18,  5.56it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:23 - INFO - __main__ - train loss is 5.11688229884021\n",
      "Steps:  77%|▊| 11563/15000 [1:39:33<10:17,  5.57it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:23 - INFO - __main__ - train loss is 5.393501792801544\n",
      "Steps:  77%|▊| 11564/15000 [1:39:33<10:16,  5.57it/s, lr=0.000989, step_loss=0.207/27/2023 19:24:23 - INFO - __main__ - train loss is 5.474335108650848\n",
      "Steps:  77%|▊| 11565/15000 [1:39:34<10:16,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:23 - INFO - __main__ - train loss is 5.4783208824228495\n",
      "Steps:  77%|▊| 11566/15000 [1:39:34<10:15,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:24 - INFO - __main__ - train loss is 5.744709715945646\n",
      "Steps:  77%|▊| 11567/15000 [1:39:34<10:15,  5.58it/s, lr=0.000989, step_loss=0.207/27/2023 19:24:24 - INFO - __main__ - train loss is 5.747660786611959\n",
      "Steps:  77%|▊| 11568/15000 [1:39:34<10:15,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:24 - INFO - __main__ - train loss is 6.160918206674978\n",
      "Steps:  77%|▊| 11569/15000 [1:39:34<10:15,  5.58it/s, lr=0.000989, step_loss=0.407/27/2023 19:24:24 - INFO - __main__ - train loss is 6.162265866296366\n",
      "Steps:  77%|▊| 11570/15000 [1:39:34<10:14,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:24 - INFO - __main__ - train loss is 6.76067206193693\n",
      "Steps:  77%|▊| 11571/15000 [1:39:35<10:14,  5.58it/s, lr=0.000989, step_loss=0.507/27/2023 19:24:25 - INFO - __main__ - train loss is 6.84363232483156\n",
      "Steps:  77%|▊| 11572/15000 [1:39:35<10:14,  5.58it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:25 - INFO - __main__ - train loss is 6.854794560233131\n",
      "Steps:  77%|▊| 11573/15000 [1:39:35<10:15,  5.57it/s, lr=0.000989, step_loss=0.007/27/2023 19:24:25 - INFO - __main__ - train loss is 7.006834386149421\n",
      "Steps:  77%|▊| 11574/15000 [1:39:35<10:15,  5.57it/s, lr=0.000989, step_loss=0.107/27/2023 19:24:25 - INFO - __main__ - train loss is 7.166680066147819\n",
      "Steps:  77%|▊| 11575/15000 [1:39:35<10:15,  5.57it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:25 - INFO - __main__ - train loss is 7.200780777493492\n",
      "Steps:  77%|▊| 11576/15000 [1:39:36<10:15,  5.56it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:25 - INFO - __main__ - train loss is 7.342884211102501\n",
      "Steps:  77%|▊| 11577/15000 [1:39:36<10:14,  5.57it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:26 - INFO - __main__ - train loss is 7.956218330422416\n",
      "Steps:  77%|▊| 11578/15000 [1:39:36<10:15,  5.56it/s, lr=0.000988, step_loss=0.607/27/2023 19:24:26 - INFO - __main__ - train loss is 7.957286191987805\n",
      "Steps:  77%|▊| 11579/15000 [1:39:36<10:20,  5.52it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:26 - INFO - __main__ - train loss is 7.988575393217616\n",
      "Steps:  77%|▊| 11580/15000 [1:39:36<10:19,  5.52it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:26 - INFO - __main__ - train loss is 8.221758672851138\n",
      "Steps:  77%|▊| 11581/15000 [1:39:36<10:18,  5.53it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:26 - INFO - __main__ - train loss is 8.292426610249095\n",
      "Steps:  77%|▊| 11582/15000 [1:39:37<10:16,  5.54it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:27 - INFO - __main__ - train loss is 8.61471077229362\n",
      "Steps:  77%|▊| 11583/15000 [1:39:37<10:19,  5.52it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:27 - INFO - __main__ - train loss is 8.622709952178411\n",
      "Steps:  77%|▊| 11584/15000 [1:39:37<10:22,  5.49it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:27 - INFO - __main__ - train loss is 8.625120211741887\n",
      "Steps:  77%|▊| 11585/15000 [1:39:37<10:25,  5.46it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:27 - INFO - __main__ - train loss is 8.673105772933923\n",
      "Steps:  77%|▊| 11586/15000 [1:39:37<10:41,  5.32it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:27 - INFO - __main__ - train loss is 8.674861604929902\n",
      "Steps:  77%|▊| 11587/15000 [1:39:38<10:53,  5.22it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:27 - INFO - __main__ - train loss is 8.68399940954987\n",
      "Steps:  77%|▊| 11588/15000 [1:39:38<10:58,  5.18it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:28 - INFO - __main__ - train loss is 8.694432584219612\n",
      "Steps:  77%|▊| 11589/15000 [1:39:38<10:59,  5.17it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:28 - INFO - __main__ - train loss is 8.85151844995562\n",
      "Steps:  77%|▊| 11590/15000 [1:39:38<11:01,  5.16it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:28 - INFO - __main__ - train loss is 9.273475942783989\n",
      "Steps:  77%|▊| 11591/15000 [1:39:38<11:02,  5.15it/s, lr=0.000988, step_loss=0.407/27/2023 19:24:28 - INFO - __main__ - train loss is 9.424152446561493\n",
      "Steps:  77%|▊| 11592/15000 [1:39:39<11:03,  5.14it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:28 - INFO - __main__ - train loss is 9.633363766246475\n",
      "Steps:  77%|▊| 11593/15000 [1:39:39<11:04,  5.13it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:29 - INFO - __main__ - train loss is 9.665999216609634\n",
      "Steps:  77%|▊| 11594/15000 [1:39:39<11:04,  5.13it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:29 - INFO - __main__ - train loss is 9.97658060269896\n",
      "Steps:  77%|▊| 11595/15000 [1:39:39<11:02,  5.14it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:29 - INFO - __main__ - train loss is 10.004558158689179\n",
      "Steps:  77%|▊| 11596/15000 [1:39:39<10:49,  5.24it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:29 - INFO - __main__ - train loss is 10.071647731238045\n",
      "Steps:  77%|▊| 11597/15000 [1:39:40<10:48,  5.25it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:29 - INFO - __main__ - train loss is 10.157395777874626\n",
      "Steps:  77%|▊| 11598/15000 [1:39:40<10:43,  5.29it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:30 - INFO - __main__ - train loss is 10.337722194963135\n",
      "Steps:  77%|▊| 11599/15000 [1:39:40<11:01,  5.14it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:30 - INFO - __main__ - train loss is 10.35490296187345\n",
      "Steps:  77%|▊| 11600/15000 [1:39:40<11:02,  5.13it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:30 - INFO - __main__ - train loss is 10.39173737692181\n",
      "Steps:  77%|▊| 11601/15000 [1:39:40<11:02,  5.13it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:30 - INFO - __main__ - train loss is 10.536761318915524\n",
      "Steps:  77%|▊| 11602/15000 [1:39:41<11:03,  5.12it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:30 - INFO - __main__ - train loss is 10.538943654973991\n",
      "Steps:  77%|▊| 11603/15000 [1:39:41<11:03,  5.12it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:31 - INFO - __main__ - train loss is 10.691287300665863\n",
      "Steps:  77%|▊| 11604/15000 [1:39:41<11:03,  5.12it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:31 - INFO - __main__ - train loss is 10.90697850950528\n",
      "Steps:  77%|▊| 11605/15000 [1:39:41<11:03,  5.12it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:31 - INFO - __main__ - train loss is 10.936105174128897\n",
      "Steps:  77%|▊| 11606/15000 [1:39:41<11:02,  5.12it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:31 - INFO - __main__ - train loss is 11.19348133832682\n",
      "Steps:  77%|▊| 11607/15000 [1:39:41<11:02,  5.12it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:31 - INFO - __main__ - train loss is 11.21373234607745\n",
      "Steps:  77%|▊| 11608/15000 [1:39:42<11:03,  5.11it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:32 - INFO - __main__ - train loss is 11.373300864477642\n",
      "Steps:  77%|▊| 11609/15000 [1:39:42<11:02,  5.12it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:32 - INFO - __main__ - train loss is 11.375495973858051\n",
      "Steps:  77%|▊| 11610/15000 [1:39:42<10:58,  5.14it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:32 - INFO - __main__ - train loss is 11.508541542920284\n",
      "Steps:  77%|▊| 11611/15000 [1:39:42<10:44,  5.25it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:32 - INFO - __main__ - train loss is 12.031397897633724\n",
      "Steps:  77%|▊| 11612/15000 [1:39:42<10:33,  5.35it/s, lr=0.000988, step_loss=0.507/27/2023 19:24:32 - INFO - __main__ - train loss is 12.033431412302889\n",
      "Steps:  77%|▊| 11613/15000 [1:39:43<10:31,  5.36it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:32 - INFO - __main__ - train loss is 12.03777591290418\n",
      "Steps:  77%|▊| 11614/15000 [1:39:43<10:25,  5.41it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:33 - INFO - __main__ - train loss is 12.126704895519651\n",
      "Steps:  77%|▊| 11615/15000 [1:39:43<10:19,  5.46it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:33 - INFO - __main__ - train loss is 12.47499706747476\n",
      "Steps:  77%|▊| 11616/15000 [1:39:43<10:19,  5.46it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:33 - INFO - __main__ - train loss is 12.508621839457192\n",
      "Steps:  77%|▊| 11617/15000 [1:39:43<10:15,  5.50it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:33 - INFO - __main__ - train loss is 12.602785749011673\n",
      "Steps:  77%|▊| 11618/15000 [1:39:44<10:12,  5.52it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:33 - INFO - __main__ - train loss is 12.620012825005688\n",
      "Steps:  77%|▊| 11619/15000 [1:39:44<10:10,  5.54it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:34 - INFO - __main__ - train loss is 12.780651351087727\n",
      "Steps:  77%|▊| 11620/15000 [1:39:44<10:09,  5.55it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:34 - INFO - __main__ - train loss is 12.79868858831469\n",
      "Steps:  77%|▊| 11621/15000 [1:39:44<10:07,  5.56it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:34 - INFO - __main__ - train loss is 12.865678561502136\n",
      "Steps:  77%|▊| 11622/15000 [1:39:44<10:06,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:34 - INFO - __main__ - train loss is 12.867839116719551\n",
      "Steps:  77%|▊| 11623/15000 [1:39:44<10:06,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:34 - INFO - __main__ - train loss is 12.906319368747063\n",
      "Steps:  77%|▊| 11624/15000 [1:39:45<10:06,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:34 - INFO - __main__ - train loss is 12.910117098479532\n",
      "Steps:  78%|▊| 11625/15000 [1:39:45<10:05,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:35 - INFO - __main__ - train loss is 13.02011340239551\n",
      "Steps:  78%|▊| 11626/15000 [1:39:45<10:05,  5.57it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:35 - INFO - __main__ - train loss is 13.070357867865823\n",
      "Steps:  78%|▊| 11627/15000 [1:39:45<10:05,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:35 - INFO - __main__ - train loss is 13.19795999804046\n",
      "Steps:  78%|▊| 11628/15000 [1:39:45<10:04,  5.57it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:35 - INFO - __main__ - train loss is 13.253522047190927\n",
      "Steps:  78%|▊| 11629/15000 [1:39:46<10:09,  5.53it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:35 - INFO - __main__ - train loss is 13.338125006644987\n",
      "Steps:  78%|▊| 11630/15000 [1:39:46<10:07,  5.54it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:36 - INFO - __main__ - train loss is 13.469004319398664\n",
      "Steps:  78%|▊| 11631/15000 [1:39:46<10:08,  5.54it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:36 - INFO - __main__ - train loss is 13.525502083241008\n",
      "Steps:  78%|▊| 11632/15000 [1:39:46<10:06,  5.55it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:36 - INFO - __main__ - train loss is 13.57963268214371\n",
      "Steps:  78%|▊| 11633/15000 [1:39:46<10:11,  5.50it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:36 - INFO - __main__ - train loss is 13.955908638774417\n",
      "Steps:  78%|▊| 11634/15000 [1:39:46<10:16,  5.46it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:36 - INFO - __main__ - train loss is 14.269917411147617\n",
      "Steps:  78%|▊| 11635/15000 [1:39:47<10:13,  5.48it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:36 - INFO - __main__ - train loss is 14.433374447165988\n",
      "Steps:  78%|▊| 11636/15000 [1:39:47<10:10,  5.51it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:37 - INFO - __main__ - train loss is 14.449739358737133\n",
      "Steps:  78%|▊| 11637/15000 [1:39:47<10:08,  5.53it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:37 - INFO - __main__ - train loss is 14.861850879504345\n",
      "Steps:  78%|▊| 11638/15000 [1:39:47<10:12,  5.49it/s, lr=0.000988, step_loss=0.407/27/2023 19:24:37 - INFO - __main__ - train loss is 14.870555539964698\n",
      "Steps:  78%|▊| 11639/15000 [1:39:47<10:16,  5.45it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:37 - INFO - __main__ - train loss is 15.098357473849319\n",
      "Steps:  78%|▊| 11640/15000 [1:39:48<10:15,  5.46it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:37 - INFO - __main__ - train loss is 15.121714436798356\n",
      "Steps:  78%|▊| 11641/15000 [1:39:48<10:11,  5.49it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:38 - INFO - __main__ - train loss is 15.625999653129838\n",
      "Steps:  78%|▊| 11642/15000 [1:39:48<10:09,  5.51it/s, lr=0.000988, step_loss=0.507/27/2023 19:24:38 - INFO - __main__ - train loss is 15.63258170883637\n",
      "Steps:  78%|▊| 11643/15000 [1:39:48<10:07,  5.52it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:38 - INFO - __main__ - train loss is 15.73377726774197\n",
      "Steps:  78%|▊| 11644/15000 [1:39:48<10:06,  5.54it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:38 - INFO - __main__ - train loss is 15.735035240300931\n",
      "Steps:  78%|▊| 11645/15000 [1:39:48<10:04,  5.55it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:38 - INFO - __main__ - train loss is 15.796858083107509\n",
      "Steps:  78%|▊| 11646/15000 [1:39:49<10:03,  5.55it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:38 - INFO - __main__ - train loss is 15.998921494581737\n",
      "Steps:  78%|▊| 11647/15000 [1:39:49<10:02,  5.56it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:39 - INFO - __main__ - train loss is 16.01798265206162\n",
      "Steps:  78%|▊| 11648/15000 [1:39:49<10:02,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:39 - INFO - __main__ - train loss is 16.020800357568078\n",
      "Steps:  78%|▊| 11649/15000 [1:39:49<10:01,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:39 - INFO - __main__ - train loss is 16.023343173903413\n",
      "Steps:  78%|▊| 11650/15000 [1:39:49<10:00,  5.58it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:39 - INFO - __main__ - train loss is 16.43544652883429\n",
      "Steps:  78%|▊| 11651/15000 [1:39:49<10:00,  5.58it/s, lr=0.000988, step_loss=0.407/27/2023 19:24:39 - INFO - __main__ - train loss is 16.72572296683211\n",
      "Steps:  78%|▊| 11652/15000 [1:39:50<10:00,  5.58it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:40 - INFO - __main__ - train loss is 16.79148168687243\n",
      "Steps:  78%|▊| 11653/15000 [1:39:50<10:00,  5.58it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:40 - INFO - __main__ - train loss is 16.81163387943525\n",
      "Steps:  78%|▊| 11654/15000 [1:39:50<10:00,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:40 - INFO - __main__ - train loss is 16.83206780080218\n",
      "Steps:  78%|▊| 11655/15000 [1:39:50<10:01,  5.56it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:40 - INFO - __main__ - train loss is 16.84068675537128\n",
      "Steps:  78%|▊| 11656/15000 [1:39:50<10:00,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:40 - INFO - __main__ - train loss is 17.107101665926166\n",
      "Steps:  78%|▊| 11657/15000 [1:39:51<10:00,  5.57it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:40 - INFO - __main__ - train loss is 17.12243966490496\n",
      "Steps:  78%|▊| 11658/15000 [1:39:51<10:04,  5.53it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:41 - INFO - __main__ - train loss is 17.197496411507018\n",
      "Steps:  78%|▊| 11659/15000 [1:39:51<10:02,  5.54it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:41 - INFO - __main__ - train loss is 17.294194166664965\n",
      "Steps:  78%|▊| 11660/15000 [1:39:51<10:01,  5.55it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:41 - INFO - __main__ - train loss is 17.377446104888804\n",
      "Steps:  78%|▊| 11661/15000 [1:39:51<10:00,  5.56it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:41 - INFO - __main__ - train loss is 18.098997105960734\n",
      "Steps:  78%|▊| 11662/15000 [1:39:51<10:00,  5.56it/s, lr=0.000988, step_loss=0.707/27/2023 19:24:41 - INFO - __main__ - train loss is 18.244839464430697\n",
      "Steps:  78%|▊| 11663/15000 [1:39:52<09:59,  5.56it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:42 - INFO - __main__ - train loss is 18.70772800326813\n",
      "Steps:  78%|▊| 11664/15000 [1:39:52<09:59,  5.57it/s, lr=0.000988, step_loss=0.407/27/2023 19:24:42 - INFO - __main__ - train loss is 18.71676413260866\n",
      "Steps:  78%|▊| 11665/15000 [1:39:52<09:58,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:42 - INFO - __main__ - train loss is 18.878304134239443\n",
      "Steps:  78%|▊| 11666/15000 [1:39:52<09:59,  5.56it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:42 - INFO - __main__ - train loss is 18.88000390760135\n",
      "Steps:  78%|▊| 11667/15000 [1:39:52<09:58,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:42 - INFO - __main__ - train loss is 19.002900929073803\n",
      "Steps:  78%|▊| 11668/15000 [1:39:53<10:05,  5.50it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:42 - INFO - __main__ - train loss is 19.012338532018475\n",
      "Steps:  78%|▊| 11669/15000 [1:39:53<10:23,  5.34it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:43 - INFO - __main__ - train loss is 19.098279682802968\n",
      "Steps:  78%|▊| 11670/15000 [1:39:53<11:38,  4.77it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:43 - INFO - __main__ - train loss is 19.10182703693863\n",
      "Steps:  78%|▊| 11671/15000 [1:39:53<11:39,  4.76it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:43 - INFO - __main__ - train loss is 19.127171889296733\n",
      "Steps:  78%|▊| 11672/15000 [1:39:53<11:42,  4.74it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:43 - INFO - __main__ - train loss is 19.271867886534892\n",
      "Steps:  78%|▊| 11673/15000 [1:39:54<11:16,  4.92it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:43 - INFO - __main__ - train loss is 19.279876634827815\n",
      "Steps:  78%|▊| 11674/15000 [1:39:54<10:55,  5.07it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:44 - INFO - __main__ - train loss is 19.284981510951184\n",
      "Steps:  78%|▊| 11675/15000 [1:39:54<10:39,  5.20it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:44 - INFO - __main__ - train loss is 19.669584176852368\n",
      "Steps:  78%|▊| 11676/15000 [1:39:54<10:27,  5.30it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:44 - INFO - __main__ - train loss is 19.674117421149276\n",
      "Steps:  78%|▊| 11677/15000 [1:39:54<10:18,  5.38it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:44 - INFO - __main__ - train loss is 19.73408768081572\n",
      "Steps:  78%|▊| 11678/15000 [1:39:55<10:12,  5.43it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:44 - INFO - __main__ - train loss is 19.756269703968428\n",
      "Steps:  78%|▊| 11679/15000 [1:39:55<10:07,  5.47it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:45 - INFO - __main__ - train loss is 19.75995950528886\n",
      "Steps:  78%|▊| 11680/15000 [1:39:55<10:03,  5.50it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:45 - INFO - __main__ - train loss is 19.76529909891542\n",
      "Steps:  78%|▊| 11681/15000 [1:39:55<10:01,  5.52it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:45 - INFO - __main__ - train loss is 19.936969431466423\n",
      "Steps:  78%|▊| 11682/15000 [1:39:55<09:59,  5.54it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:45 - INFO - __main__ - train loss is 20.135174723691307\n",
      "Steps:  78%|▊| 11683/15000 [1:39:55<09:57,  5.55it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:45 - INFO - __main__ - train loss is 20.156088164425455\n",
      "Steps:  78%|▊| 11684/15000 [1:39:56<09:57,  5.55it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:45 - INFO - __main__ - train loss is 20.187068907893263\n",
      "Steps:  78%|▊| 11685/15000 [1:39:56<09:56,  5.56it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:46 - INFO - __main__ - train loss is 20.202780373743735\n",
      "Steps:  78%|▊| 11686/15000 [1:39:56<09:56,  5.56it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:46 - INFO - __main__ - train loss is 20.285091109923087\n",
      "Steps:  78%|▊| 11687/15000 [1:39:56<09:55,  5.56it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:46 - INFO - __main__ - train loss is 20.286721925949678\n",
      "Steps:  78%|▊| 11688/15000 [1:39:56<09:54,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:46 - INFO - __main__ - train loss is 20.325106862699613\n",
      "Steps:  78%|▊| 11689/15000 [1:39:56<09:54,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:46 - INFO - __main__ - train loss is 20.345015320694074\n",
      "Steps:  78%|▊| 11690/15000 [1:39:57<09:54,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:47 - INFO - __main__ - train loss is 20.518390867626294\n",
      "Steps:  78%|▊| 11691/15000 [1:39:57<09:53,  5.57it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:47 - INFO - __main__ - train loss is 20.65754062286578\n",
      "Steps:  78%|▊| 11692/15000 [1:39:57<09:53,  5.57it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:47 - INFO - __main__ - train loss is 20.67534242174588\n",
      "Steps:  78%|▊| 11693/15000 [1:39:57<09:53,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:47 - INFO - __main__ - train loss is 20.91298283240758\n",
      "Steps:  78%|▊| 11694/15000 [1:39:57<09:53,  5.57it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:47 - INFO - __main__ - train loss is 20.928501149406657\n",
      "Steps:  78%|▊| 11695/15000 [1:39:58<09:53,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:47 - INFO - __main__ - train loss is 20.931284612743184\n",
      "Steps:  78%|▊| 11696/15000 [1:39:58<09:53,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:48 - INFO - __main__ - train loss is 20.955429314402863\n",
      "Steps:  78%|▊| 11697/15000 [1:39:58<09:53,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:48 - INFO - __main__ - train loss is 21.258749245433137\n",
      "Steps:  78%|▊| 11698/15000 [1:39:58<09:53,  5.56it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:48 - INFO - __main__ - train loss is 21.308026767103\n",
      "Steps:  78%|▊| 11699/15000 [1:39:58<09:52,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:48 - INFO - __main__ - train loss is 21.312805782305077\n",
      "Steps:  78%|▊| 11700/15000 [1:39:58<09:52,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:48 - INFO - __main__ - train loss is 21.374520006822422\n",
      "Steps:  78%|▊| 11701/15000 [1:39:59<09:52,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:49 - INFO - __main__ - train loss is 21.567349287914112\n",
      "Steps:  78%|▊| 11702/15000 [1:39:59<09:52,  5.57it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:49 - INFO - __main__ - train loss is 21.570238495012745\n",
      "Steps:  78%|▊| 11703/15000 [1:39:59<09:51,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:49 - INFO - __main__ - train loss is 21.594398515066132\n",
      "Steps:  78%|▊| 11704/15000 [1:39:59<09:51,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:49 - INFO - __main__ - train loss is 21.60931566148065\n",
      "Steps:  78%|▊| 11705/15000 [1:39:59<09:51,  5.57it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:49 - INFO - __main__ - train loss is 21.616303585236892\n",
      "Steps:  78%|▊| 11706/15000 [1:40:00<09:55,  5.53it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:49 - INFO - __main__ - train loss is 21.834389693802223\n",
      "Steps:  78%|▊| 11707/15000 [1:40:00<09:56,  5.52it/s, lr=0.000988, step_loss=0.207/27/2023 19:24:50 - INFO - __main__ - train loss is 21.89652695483528\n",
      "Steps:  78%|▊| 11708/15000 [1:40:00<10:00,  5.48it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:50 - INFO - __main__ - train loss is 22.029029465978965\n",
      "Steps:  78%|▊| 11709/15000 [1:40:00<10:00,  5.48it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:50 - INFO - __main__ - train loss is 22.05469963303767\n",
      "Steps:  78%|▊| 11710/15000 [1:40:00<10:05,  5.43it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:50 - INFO - __main__ - train loss is 22.094240579521284\n",
      "Steps:  78%|▊| 11711/15000 [1:40:00<10:03,  5.45it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:50 - INFO - __main__ - train loss is 22.10134609020315\n",
      "Steps:  78%|▊| 11712/15000 [1:40:01<10:01,  5.47it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:51 - INFO - __main__ - train loss is 22.10337246907875\n",
      "Steps:  78%|▊| 11713/15000 [1:40:01<10:00,  5.47it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:51 - INFO - __main__ - train loss is 22.25955583108589\n",
      "Steps:  78%|▊| 11714/15000 [1:40:01<09:59,  5.48it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:51 - INFO - __main__ - train loss is 22.276299686636776\n",
      "Steps:  78%|▊| 11715/15000 [1:40:01<10:04,  5.44it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:51 - INFO - __main__ - train loss is 22.29205049900338\n",
      "Steps:  78%|▊| 11716/15000 [1:40:01<10:01,  5.46it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:51 - INFO - __main__ - train loss is 22.31825293181464\n",
      "Steps:  78%|▊| 11717/15000 [1:40:02<10:03,  5.44it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:51 - INFO - __main__ - train loss is 22.326155635993928\n",
      "Steps:  78%|▊| 11718/15000 [1:40:02<10:01,  5.45it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:52 - INFO - __main__ - train loss is 22.344184446614236\n",
      "Steps:  78%|▊| 11719/15000 [1:40:02<10:00,  5.46it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:52 - INFO - __main__ - train loss is 22.6535178902559\n",
      "Steps:  78%|▊| 11720/15000 [1:40:02<09:59,  5.47it/s, lr=0.000988, step_loss=0.307/27/2023 19:24:52 - INFO - __main__ - train loss is 22.749764162581414\n",
      "Steps:  78%|▊| 11721/15000 [1:40:02<09:58,  5.48it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:52 - INFO - __main__ - train loss is 23.16900422004983\n",
      "Steps:  78%|▊| 11722/15000 [1:40:02<09:58,  5.48it/s, lr=0.000988, step_loss=0.407/27/2023 19:24:52 - INFO - __main__ - train loss is 23.272797110956162\n",
      "Steps:  78%|▊| 11723/15000 [1:40:03<09:57,  5.48it/s, lr=0.000988, step_loss=0.107/27/2023 19:24:53 - INFO - __main__ - train loss is 23.357261675875634\n",
      "Steps:  78%|▊| 11724/15000 [1:40:03<09:57,  5.48it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:53 - INFO - __main__ - train loss is 23.997839409392327\n",
      "Steps:  78%|▊| 11725/15000 [1:40:03<09:56,  5.49it/s, lr=0.000988, step_loss=0.607/27/2023 19:24:53 - INFO - __main__ - train loss is 24.007709194440395\n",
      "Steps:  78%|▊| 11726/15000 [1:40:03<09:56,  5.49it/s, lr=0.000988, step_loss=0.007/27/2023 19:24:53 - INFO - __main__ - train loss is 24.127170946914703\n",
      "Steps:  78%|▊| 11727/15000 [1:40:03<09:56,  5.49it/s, lr=0.000987, step_loss=0.107/27/2023 19:24:53 - INFO - __main__ - train loss is 24.148563735652715\n",
      "Steps:  78%|▊| 11728/15000 [1:40:04<09:56,  5.49it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:53 - INFO - __main__ - train loss is 24.185304508078843\n",
      "Steps:  78%|▊| 11729/15000 [1:40:04<10:00,  5.45it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:54 - INFO - __main__ - train loss is 24.398521319497377\n",
      "Steps:  78%|▊| 11730/15000 [1:40:04<09:58,  5.47it/s, lr=0.000987, step_loss=0.207/27/2023 19:24:54 - INFO - __main__ - train loss is 24.46439951704815\n",
      "Steps:  78%|▊| 11731/15000 [1:40:04<09:56,  5.48it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:54 - INFO - __main__ - train loss is 24.705158278811723\n",
      "Steps:  78%|▊| 11732/15000 [1:40:04<09:55,  5.48it/s, lr=0.000987, step_loss=0.207/27/2023 19:24:54 - INFO - __main__ - train loss is 24.715669338125736\n",
      "Steps:  78%|▊| 11733/15000 [1:40:04<10:00,  5.44it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:54 - INFO - __main__ - train loss is 24.736902853939682\n",
      "Steps:  78%|▊| 11734/15000 [1:40:05<09:58,  5.45it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:55 - INFO - __main__ - train loss is 24.91554372617975\n",
      "Steps:  78%|▊| 11735/15000 [1:40:05<09:57,  5.47it/s, lr=0.000987, step_loss=0.107/27/2023 19:24:55 - INFO - __main__ - train loss is 24.91972487932071\n",
      "Steps:  78%|▊| 11736/15000 [1:40:05<09:56,  5.48it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:55 - INFO - __main__ - train loss is 24.93315364373848\n",
      "Steps:  78%|▊| 11737/15000 [1:40:05<09:55,  5.48it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:55 - INFO - __main__ - train loss is 24.981716237496585\n",
      "Steps:  78%|▊| 11738/15000 [1:40:05<09:54,  5.49it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:55 - INFO - __main__ - train loss is 25.03528933180496\n",
      "Steps:  78%|▊| 11739/15000 [1:40:06<09:53,  5.49it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:55 - INFO - __main__ - train loss is 25.263832821976393\n",
      "Steps:  78%|▊| 11740/15000 [1:40:06<09:53,  5.49it/s, lr=0.000987, step_loss=0.207/27/2023 19:24:56 - INFO - __main__ - train loss is 25.329675033222884\n",
      "Steps:  78%|▊| 11741/15000 [1:40:06<09:53,  5.49it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:56 - INFO - __main__ - train loss is 25.550228610169142\n",
      "Steps:  78%|▊| 11742/15000 [1:40:06<09:53,  5.49it/s, lr=0.000987, step_loss=0.207/27/2023 19:24:56 - INFO - __main__ - train loss is 25.64437363995239\n",
      "Steps:  78%|▊| 11743/15000 [1:40:06<09:50,  5.52it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:56 - INFO - __main__ - train loss is 25.793390735518187\n",
      "Steps:  78%|▊| 11744/15000 [1:40:06<09:48,  5.53it/s, lr=0.000987, step_loss=0.107/27/2023 19:24:56 - INFO - __main__ - train loss is 25.797903266269714\n",
      "Steps:  78%|▊| 11745/15000 [1:40:07<09:47,  5.54it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:57 - INFO - __main__ - train loss is 25.885678958613425\n",
      "Steps:  78%|▊| 11746/15000 [1:40:07<09:45,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:57 - INFO - __main__ - train loss is 25.897260670084506\n",
      "Steps:  78%|▊| 11747/15000 [1:40:07<09:44,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:57 - INFO - __main__ - train loss is 25.96081939758733\n",
      "Steps:  78%|▊| 11748/15000 [1:40:07<09:44,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:57 - INFO - __main__ - train loss is 26.130181286949664\n",
      "Steps:  78%|▊| 11749/15000 [1:40:07<09:44,  5.57it/s, lr=0.000987, step_loss=0.107/27/2023 19:24:57 - INFO - __main__ - train loss is 26.27234495105222\n",
      "Steps:  78%|▊| 11750/15000 [1:40:08<09:43,  5.57it/s, lr=0.000987, step_loss=0.107/27/2023 19:24:57 - INFO - __main__ - train loss is 27.01818049373105\n",
      "Steps:  78%|▊| 11751/15000 [1:40:08<09:43,  5.57it/s, lr=0.000987, step_loss=0.707/27/2023 19:24:58 - INFO - __main__ - train loss is 27.250455368775874\n",
      "Steps:  78%|▊| 11752/15000 [1:40:08<09:43,  5.57it/s, lr=0.000987, step_loss=0.207/27/2023 19:24:58 - INFO - __main__ - train loss is 27.25390401482582\n",
      "Steps:  78%|▊| 11753/15000 [1:40:08<09:42,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:58 - INFO - __main__ - train loss is 27.271232172846794\n",
      "Steps:  78%|▊| 11754/15000 [1:40:08<09:42,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:58 - INFO - __main__ - train loss is 27.64375214278698\n",
      "Steps:  78%|▊| 11755/15000 [1:40:08<09:42,  5.57it/s, lr=0.000987, step_loss=0.307/27/2023 19:24:58 - INFO - __main__ - train loss is 27.96367059648037\n",
      "Steps:  78%|▊| 11756/15000 [1:40:09<09:41,  5.57it/s, lr=0.000987, step_loss=0.307/27/2023 19:24:59 - INFO - __main__ - train loss is 28.09016688168049\n",
      "Steps:  78%|▊| 11757/15000 [1:40:09<09:41,  5.58it/s, lr=0.000987, step_loss=0.107/27/2023 19:24:59 - INFO - __main__ - train loss is 28.334370642900467\n",
      "Steps:  78%|▊| 11758/15000 [1:40:09<09:41,  5.58it/s, lr=0.000987, step_loss=0.207/27/2023 19:24:59 - INFO - __main__ - train loss is 28.33607025712263\n",
      "Steps:  78%|▊| 11759/15000 [1:40:09<09:41,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:59 - INFO - __main__ - train loss is 28.35527364432346\n",
      "Steps:  78%|▊| 11760/15000 [1:40:09<09:41,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:59 - INFO - __main__ - train loss is 28.4105969396187\n",
      "Steps:  78%|▊| 11761/15000 [1:40:10<09:41,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:24:59 - INFO - __main__ - train loss is 28.574298563296907\n",
      "Steps:  78%|▊| 11762/15000 [1:40:10<09:41,  5.57it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:00 - INFO - __main__ - train loss is 28.59595234959852\n",
      "Steps:  78%|▊| 11763/15000 [1:40:10<09:45,  5.53it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:00 - INFO - __main__ - train loss is 28.796521949465387\n",
      "Steps:  78%|▊| 11764/15000 [1:40:10<09:43,  5.54it/s, lr=0.000987, step_loss=0.207/27/2023 19:25:00 - INFO - __main__ - train loss is 28.935551064903848\n",
      "Steps:  78%|▊| 11765/15000 [1:40:10<09:42,  5.55it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:00 - INFO - __main__ - train loss is 28.95107144943904\n",
      "Steps:  78%|▊| 11766/15000 [1:40:10<09:42,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:00 - INFO - __main__ - train loss is 29.01394153467845\n",
      "Steps:  78%|▊| 11767/15000 [1:40:11<09:41,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:00 - INFO - __main__ - train loss is 29.019640731974505\n",
      "Steps:  78%|▊| 11768/15000 [1:40:11<09:40,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:01 - INFO - __main__ - train loss is 29.19868472532835\n",
      "Steps:  78%|▊| 11769/15000 [1:40:11<09:40,  5.57it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:01 - INFO - __main__ - train loss is 29.21014989388641\n",
      "Steps:  78%|▊| 11770/15000 [1:40:11<09:40,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:01 - INFO - __main__ - train loss is 29.255334833986126\n",
      "Steps:  78%|▊| 11771/15000 [1:40:11<09:39,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:01 - INFO - __main__ - train loss is 29.259706420241855\n",
      "Steps:  78%|▊| 11772/15000 [1:40:12<09:39,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:01 - INFO - __main__ - train loss is 29.38614322000649\n",
      "Steps:  78%|▊| 11773/15000 [1:40:12<09:39,  5.57it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:02 - INFO - __main__ - train loss is 29.395842434256338\n",
      "Steps:  78%|▊| 11774/15000 [1:40:12<09:39,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:02 - INFO - __main__ - train loss is 29.50149346271064\n",
      "Steps:  78%|▊| 11775/15000 [1:40:12<09:39,  5.57it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:02 - INFO - __main__ - train loss is 29.544793391018175\n",
      "Steps:  79%|▊| 11776/15000 [1:40:12<09:41,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:02 - INFO - __main__ - train loss is 29.675773823051713\n",
      "Steps:  79%|▊| 11777/15000 [1:40:12<09:40,  5.55it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:02 - INFO - __main__ - train loss is 29.69339136162307\n",
      "Steps:  79%|▊| 11778/15000 [1:40:13<09:39,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:02 - INFO - __main__ - train loss is 30.393417992978357\n",
      "Steps:  79%|▊| 11779/15000 [1:40:13<09:39,  5.56it/s, lr=0.000987, step_loss=0.707/27/2023 19:25:03 - INFO - __main__ - train loss is 30.738655277877115\n",
      "Steps:  79%|▊| 11780/15000 [1:40:13<09:39,  5.56it/s, lr=0.000987, step_loss=0.307/27/2023 19:25:03 - INFO - __main__ - train loss is 30.800229278742336\n",
      "Steps:  79%|▊| 11781/15000 [1:40:13<09:44,  5.51it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:03 - INFO - __main__ - train loss is 30.972773624002002\n",
      "Steps:  79%|▊| 11782/15000 [1:40:13<09:52,  5.43it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:03 - INFO - __main__ - train loss is 31.03877133631613\n",
      "Steps:  79%|▊| 11783/15000 [1:40:14<09:52,  5.43it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:03 - INFO - __main__ - train loss is 31.674274449585937\n",
      "Steps:  79%|▊| 11784/15000 [1:40:14<09:47,  5.47it/s, lr=0.000987, step_loss=0.607/27/2023 19:25:04 - INFO - __main__ - train loss is 31.67591916839592\n",
      "Steps:  79%|▊| 11785/15000 [1:40:14<09:44,  5.50it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:04 - INFO - __main__ - train loss is 31.678640587022528\n",
      "Steps:  79%|▊| 11786/15000 [1:40:14<09:42,  5.52it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:04 - INFO - __main__ - train loss is 31.724200499942526\n",
      "Steps:  79%|▊| 11787/15000 [1:40:14<09:40,  5.53it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:04 - INFO - __main__ - train loss is 32.05990175693296\n",
      "Steps:  79%|▊| 11788/15000 [1:40:14<09:39,  5.54it/s, lr=0.000987, step_loss=0.307/27/2023 19:25:04 - INFO - __main__ - train loss is 32.06243946473114\n",
      "Steps:  79%|▊| 11789/15000 [1:40:15<09:38,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:04 - INFO - __main__ - train loss is 32.07931424560957\n",
      "Steps:  79%|▊| 11790/15000 [1:40:15<09:38,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:05 - INFO - __main__ - train loss is 32.49258561315946\n",
      "Steps:  79%|▊| 11791/15000 [1:40:15<09:37,  5.56it/s, lr=0.000987, step_loss=0.407/27/2023 19:25:05 - INFO - __main__ - train loss is 32.49598976387642\n",
      "Steps:  79%|▊| 11792/15000 [1:40:15<09:37,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:05 - INFO - __main__ - train loss is 32.60020066215657\n",
      "Steps:  79%|▊| 11793/15000 [1:40:15<09:36,  5.56it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:05 - INFO - __main__ - train loss is 32.64330985560082\n",
      "Steps:  79%|▊| 11794/15000 [1:40:15<09:36,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:05 - INFO - __main__ - train loss is 32.76953470124863\n",
      "Steps:  79%|▊| 11795/15000 [1:40:16<09:35,  5.57it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:06 - INFO - __main__ - train loss is 33.26040672673844\n",
      "Steps:  79%|▊| 11796/15000 [1:40:16<09:35,  5.57it/s, lr=0.000987, step_loss=0.407/27/2023 19:25:06 - INFO - __main__ - train loss is 33.32601944520138\n",
      "Steps:  79%|▊| 11797/15000 [1:40:16<09:35,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:06 - INFO - __main__ - train loss is 33.328885725233704\n",
      "Steps:  79%|▊| 11798/15000 [1:40:16<09:34,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:06 - INFO - __main__ - train loss is 33.33062460878864\n",
      "Steps:  79%|▊| 11799/15000 [1:40:16<09:34,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:06 - INFO - __main__ - train loss is 33.35388339171186\n",
      "Steps:  79%|▊| 11800/15000 [1:40:17<09:34,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:06 - INFO - __main__ - train loss is 33.41304638097063\n",
      "Steps:  79%|▊| 11801/15000 [1:40:17<09:33,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:07 - INFO - __main__ - train loss is 33.49818406859413\n",
      "Steps:  79%|▊| 11802/15000 [1:40:17<09:33,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:07 - INFO - __main__ - train loss is 33.55138906696811\n",
      "Steps:  79%|▊| 11803/15000 [1:40:17<09:36,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:07 - INFO - __main__ - train loss is 33.83187094191089\n",
      "Steps:  79%|▊| 11804/15000 [1:40:17<09:34,  5.56it/s, lr=0.000987, step_loss=0.207/27/2023 19:25:07 - INFO - __main__ - train loss is 33.91547180572525\n",
      "Steps:  79%|▊| 11805/15000 [1:40:17<09:33,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:07 - INFO - __main__ - train loss is 33.9320084922947\n",
      "Steps:  79%|▊| 11806/15000 [1:40:18<09:33,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:08 - INFO - __main__ - train loss is 34.07583749527112\n",
      "Steps:  79%|▊| 11807/15000 [1:40:18<09:32,  5.58it/s, lr=0.000987, step_loss=0.107/27/2023 19:25:08 - INFO - __main__ - train loss is 34.277648034039885\n",
      "Steps:  79%|▊| 11808/15000 [1:40:18<09:32,  5.57it/s, lr=0.000987, step_loss=0.207/27/2023 19:25:08 - INFO - __main__ - train loss is 34.28318381449208\n",
      "Steps:  79%|▊| 11809/15000 [1:40:18<09:32,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:08 - INFO - __main__ - train loss is 34.56100237509236\n",
      "Steps:  79%|▊| 11810/15000 [1:40:18<09:32,  5.58it/s, lr=0.000987, step_loss=0.207/27/2023 19:25:08 - INFO - __main__ - train loss is 34.64761680504307\n",
      "Steps:  79%|▊| 11811/15000 [1:40:19<09:31,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:08 - INFO - __main__ - train loss is 34.6704555763863\n",
      "Steps:  79%|▊| 11812/15000 [1:40:19<09:31,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:09 - INFO - __main__ - train loss is 34.68204463412985\n",
      "Steps:  79%|▊| 11813/15000 [1:40:19<09:31,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:09 - INFO - __main__ - train loss is 34.695289469789714\n",
      "Steps:  79%|▊| 11814/15000 [1:40:19<09:30,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:09 - INFO - __main__ - train loss is 34.77918382687494\n",
      "Steps:  79%|▊| 11815/15000 [1:40:19<09:30,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:09 - INFO - __main__ - train loss is 34.870364762376994\n",
      "Steps:  79%|▊| 11816/15000 [1:40:19<09:30,  5.58it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:10 - INFO - __main__ - train loss is 34.87226531933993\n",
      "Steps:  79%|▊| 11817/15000 [1:40:20<13:13,  4.01it/s, lr=0.000987, step_loss=0.007/27/2023 19:25:11 - INFO - __main__ - Per validation step average loss is 0.2745426893234253\n",
      "07/27/2023 19:25:11 - INFO - __main__ - Cumulative validation average loss is 0.2745426893234253\n",
      "07/27/2023 19:25:11 - INFO - __main__ - Per validation step average loss is 0.15976759791374207\n",
      "07/27/2023 19:25:11 - INFO - __main__ - Cumulative validation average loss is 0.43431028723716736\n",
      "07/27/2023 19:25:11 - INFO - __main__ - Per validation step average loss is 0.032142262905836105\n",
      "07/27/2023 19:25:11 - INFO - __main__ - Cumulative validation average loss is 0.46645255014300346\n",
      "07/27/2023 19:25:12 - INFO - __main__ - Per validation step average loss is 0.12168283015489578\n",
      "07/27/2023 19:25:12 - INFO - __main__ - Cumulative validation average loss is 0.5881353802978992\n",
      "07/27/2023 19:25:12 - INFO - __main__ - Per validation step average loss is 0.004700000863522291\n",
      "07/27/2023 19:25:12 - INFO - __main__ - Cumulative validation average loss is 0.5928353811614215\n",
      "07/27/2023 19:25:13 - INFO - __main__ - Per validation step average loss is 0.3009682893753052\n",
      "07/27/2023 19:25:13 - INFO - __main__ - Cumulative validation average loss is 0.8938036705367267\n",
      "07/27/2023 19:25:13 - INFO - __main__ - Per validation step average loss is 0.18725842237472534\n",
      "07/27/2023 19:25:13 - INFO - __main__ - Cumulative validation average loss is 1.081062092911452\n",
      "07/27/2023 19:25:13 - INFO - __main__ - Per validation step average loss is 0.0013836155412718654\n",
      "07/27/2023 19:25:13 - INFO - __main__ - Cumulative validation average loss is 1.082445708452724\n",
      "07/27/2023 19:25:14 - INFO - __main__ - Per validation step average loss is 0.12766793370246887\n",
      "07/27/2023 19:25:14 - INFO - __main__ - Cumulative validation average loss is 1.2101136421551928\n",
      "07/27/2023 19:25:14 - INFO - __main__ - Per validation step average loss is 0.33915841579437256\n",
      "07/27/2023 19:25:14 - INFO - __main__ - Cumulative validation average loss is 1.5492720579495654\n",
      "07/27/2023 19:25:15 - INFO - __main__ - Per validation step average loss is 0.29613885283470154\n",
      "07/27/2023 19:25:15 - INFO - __main__ - Cumulative validation average loss is 1.845410910784267\n",
      "07/27/2023 19:25:15 - INFO - __main__ - Per validation step average loss is 0.00627321470528841\n",
      "07/27/2023 19:25:15 - INFO - __main__ - Cumulative validation average loss is 1.8516841254895553\n",
      "07/27/2023 19:25:16 - INFO - __main__ - Per validation step average loss is 0.007786101195961237\n",
      "07/27/2023 19:25:16 - INFO - __main__ - Cumulative validation average loss is 1.8594702266855165\n",
      "07/27/2023 19:25:16 - INFO - __main__ - Per validation step average loss is 0.005582614801824093\n",
      "07/27/2023 19:25:16 - INFO - __main__ - Cumulative validation average loss is 1.8650528414873406\n",
      "07/27/2023 19:25:16 - INFO - __main__ - Per validation step average loss is 0.2419964075088501\n",
      "07/27/2023 19:25:16 - INFO - __main__ - Cumulative validation average loss is 2.1070492489961907\n",
      "07/27/2023 19:25:17 - INFO - __main__ - Per validation step average loss is 0.0017030854942277074\n",
      "07/27/2023 19:25:17 - INFO - __main__ - Cumulative validation average loss is 2.1087523344904184\n",
      "07/27/2023 19:25:17 - INFO - __main__ - Per validation step average loss is 0.26153862476348877\n",
      "07/27/2023 19:25:17 - INFO - __main__ - Cumulative validation average loss is 2.370290959253907\n",
      "07/27/2023 19:25:18 - INFO - __main__ - Per validation step average loss is 0.0022781388834118843\n",
      "07/27/2023 19:25:18 - INFO - __main__ - Cumulative validation average loss is 2.372569098137319\n",
      "07/27/2023 19:25:18 - INFO - __main__ - Per validation step average loss is 0.04276273027062416\n",
      "07/27/2023 19:25:18 - INFO - __main__ - Cumulative validation average loss is 2.4153318284079432\n",
      "07/27/2023 19:25:18 - INFO - __main__ - Per validation step average loss is 0.0020466167479753494\n",
      "07/27/2023 19:25:18 - INFO - __main__ - Cumulative validation average loss is 2.4173784451559186\n",
      "07/27/2023 19:25:19 - INFO - __main__ - Per validation step average loss is 0.05685549974441528\n",
      "07/27/2023 19:25:19 - INFO - __main__ - Cumulative validation average loss is 2.474233944900334\n",
      "07/27/2023 19:25:19 - INFO - __main__ - Per validation step average loss is 0.017703019082546234\n",
      "07/27/2023 19:25:19 - INFO - __main__ - Cumulative validation average loss is 2.49193696398288\n",
      "07/27/2023 19:25:20 - INFO - __main__ - Per validation step average loss is 0.031263090670108795\n",
      "07/27/2023 19:25:20 - INFO - __main__ - Cumulative validation average loss is 2.523200054652989\n",
      "07/27/2023 19:25:20 - INFO - __main__ - Per validation step average loss is 0.012804673984646797\n",
      "07/27/2023 19:25:20 - INFO - __main__ - Cumulative validation average loss is 2.5360047286376357\n",
      "07/27/2023 19:25:20 - INFO - __main__ - Per validation step average loss is 0.4495852589607239\n",
      "07/27/2023 19:25:20 - INFO - __main__ - Cumulative validation average loss is 2.9855899875983596\n",
      "07/27/2023 19:25:21 - INFO - __main__ - Per validation step average loss is 0.20066425204277039\n",
      "07/27/2023 19:25:21 - INFO - __main__ - Cumulative validation average loss is 3.18625423964113\n",
      "07/27/2023 19:25:21 - INFO - __main__ - Per validation step average loss is 0.0016851640539243817\n",
      "07/27/2023 19:25:21 - INFO - __main__ - Cumulative validation average loss is 3.1879394036950544\n",
      "07/27/2023 19:25:22 - INFO - __main__ - Per validation step average loss is 0.2546384036540985\n",
      "07/27/2023 19:25:22 - INFO - __main__ - Cumulative validation average loss is 3.442577807349153\n",
      "07/27/2023 19:25:22 - INFO - __main__ - Per validation step average loss is 0.0067038568668067455\n",
      "07/27/2023 19:25:22 - INFO - __main__ - Cumulative validation average loss is 3.4492816642159596\n",
      "07/27/2023 19:25:23 - INFO - __main__ - Per validation step average loss is 0.012386069633066654\n",
      "07/27/2023 19:25:23 - INFO - __main__ - Cumulative validation average loss is 3.4616677338490263\n",
      "07/27/2023 19:25:23 - INFO - __main__ - Per validation step average loss is 0.35743817687034607\n",
      "07/27/2023 19:25:23 - INFO - __main__ - Cumulative validation average loss is 3.8191059107193723\n",
      "07/27/2023 19:25:23 - INFO - __main__ - Per validation step average loss is 0.0013808879302814603\n",
      "07/27/2023 19:25:23 - INFO - __main__ - Cumulative validation average loss is 3.820486798649654\n",
      "07/27/2023 19:25:24 - INFO - __main__ - Per validation step average loss is 0.20695430040359497\n",
      "07/27/2023 19:25:24 - INFO - __main__ - Cumulative validation average loss is 4.027441099053249\n",
      "07/27/2023 19:25:24 - INFO - __main__ - Per validation step average loss is 0.011392535641789436\n",
      "07/27/2023 19:25:24 - INFO - __main__ - Cumulative validation average loss is 4.038833634695038\n",
      "07/27/2023 19:25:25 - INFO - __main__ - Per validation step average loss is 0.04487131908535957\n",
      "07/27/2023 19:25:25 - INFO - __main__ - Cumulative validation average loss is 4.083704953780398\n",
      "07/27/2023 19:25:25 - INFO - __main__ - Per validation step average loss is 0.22371384501457214\n",
      "07/27/2023 19:25:25 - INFO - __main__ - Cumulative validation average loss is 4.30741879879497\n",
      "07/27/2023 19:25:25 - INFO - __main__ - Per validation step average loss is 0.11735110729932785\n",
      "07/27/2023 19:25:25 - INFO - __main__ - Cumulative validation average loss is 4.424769906094298\n",
      "07/27/2023 19:25:26 - INFO - __main__ - Per validation step average loss is 0.011343591846525669\n",
      "07/27/2023 19:25:26 - INFO - __main__ - Cumulative validation average loss is 4.436113497940823\n",
      "07/27/2023 19:25:26 - INFO - __main__ - Per validation step average loss is 0.15578235685825348\n",
      "07/27/2023 19:25:26 - INFO - __main__ - Cumulative validation average loss is 4.591895854799077\n",
      "07/27/2023 19:25:27 - INFO - __main__ - Per validation step average loss is 0.09582659602165222\n",
      "07/27/2023 19:25:27 - INFO - __main__ - Cumulative validation average loss is 4.687722450820729\n",
      "07/27/2023 19:25:27 - INFO - __main__ - Per validation step average loss is 0.31174197793006897\n",
      "07/27/2023 19:25:27 - INFO - __main__ - Cumulative validation average loss is 4.999464428750798\n",
      "07/27/2023 19:25:27 - INFO - __main__ - Per validation step average loss is 0.19579803943634033\n",
      "07/27/2023 19:25:27 - INFO - __main__ - Cumulative validation average loss is 5.195262468187138\n",
      "07/27/2023 19:25:28 - INFO - __main__ - Per validation step average loss is 0.032386355102062225\n",
      "07/27/2023 19:25:28 - INFO - __main__ - Cumulative validation average loss is 5.227648823289201\n",
      "07/27/2023 19:25:28 - INFO - __main__ - Per validation step average loss is 0.2568175792694092\n",
      "07/27/2023 19:25:28 - INFO - __main__ - Cumulative validation average loss is 5.48446640255861\n",
      "07/27/2023 19:25:29 - INFO - __main__ - Per validation step average loss is 0.005346650257706642\n",
      "07/27/2023 19:25:29 - INFO - __main__ - Cumulative validation average loss is 5.4898130528163165\n",
      "07/27/2023 19:25:29 - INFO - __main__ - Per validation step average loss is 0.006125083193182945\n",
      "07/27/2023 19:25:29 - INFO - __main__ - Cumulative validation average loss is 5.495938136009499\n",
      "07/27/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.14655297994613647\n",
      "07/27/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 5.642491115955636\n",
      "07/27/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.6845120787620544\n",
      "07/27/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 6.32700319471769\n",
      "07/27/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.04297596588730812\n",
      "07/27/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 6.3699791606049985\n",
      "07/27/2023 19:25:31 - INFO - __main__ - Per validation step average loss is 0.0014632767997682095\n",
      "07/27/2023 19:25:31 - INFO - __main__ - Cumulative validation average loss is 6.371442437404767\n",
      "07/27/2023 19:25:31 - INFO - __main__ - Per validation step average loss is 0.29232025146484375\n",
      "07/27/2023 19:25:31 - INFO - __main__ - Cumulative validation average loss is 6.66376268886961\n",
      "07/27/2023 19:25:32 - INFO - __main__ - Per validation step average loss is 0.061155810952186584\n",
      "07/27/2023 19:25:32 - INFO - __main__ - Cumulative validation average loss is 6.724918499821797\n",
      "07/27/2023 19:25:32 - INFO - __main__ - Per validation step average loss is 0.08427919447422028\n",
      "07/27/2023 19:25:32 - INFO - __main__ - Cumulative validation average loss is 6.809197694296017\n",
      "07/27/2023 19:25:33 - INFO - __main__ - Per validation step average loss is 0.0979042574763298\n",
      "07/27/2023 19:25:33 - INFO - __main__ - Cumulative validation average loss is 6.907101951772347\n",
      "07/27/2023 19:25:33 - INFO - __main__ - Per validation step average loss is 0.09047703444957733\n",
      "07/27/2023 19:25:33 - INFO - __main__ - Cumulative validation average loss is 6.997578986221924\n",
      "07/27/2023 19:25:33 - INFO - __main__ - Per validation step average loss is 0.01926320046186447\n",
      "07/27/2023 19:25:33 - INFO - __main__ - Cumulative validation average loss is 7.016842186683789\n",
      "07/27/2023 19:25:34 - INFO - __main__ - Per validation step average loss is 0.2045849859714508\n",
      "07/27/2023 19:25:34 - INFO - __main__ - Cumulative validation average loss is 7.22142717265524\n",
      "07/27/2023 19:25:34 - INFO - __main__ - Per validation step average loss is 0.004673542454838753\n",
      "07/27/2023 19:25:34 - INFO - __main__ - Cumulative validation average loss is 7.2261007151100785\n",
      "07/27/2023 19:25:35 - INFO - __main__ - Per validation step average loss is 0.15531107783317566\n",
      "07/27/2023 19:25:35 - INFO - __main__ - Cumulative validation average loss is 7.381411792943254\n",
      "07/27/2023 19:25:35 - INFO - __main__ - Per validation step average loss is 0.004571068566292524\n",
      "07/27/2023 19:25:35 - INFO - __main__ - Cumulative validation average loss is 7.385982861509547\n",
      "07/27/2023 19:25:36 - INFO - __main__ - Per validation step average loss is 0.09203687310218811\n",
      "07/27/2023 19:25:36 - INFO - __main__ - Cumulative validation average loss is 7.478019734611735\n",
      "07/27/2023 19:25:36 - INFO - __main__ - Per validation step average loss is 0.06299374252557755\n",
      "07/27/2023 19:25:36 - INFO - __main__ - Cumulative validation average loss is 7.541013477137312\n",
      "07/27/2023 19:25:36 - INFO - __main__ - Per validation step average loss is 0.01578657701611519\n",
      "07/27/2023 19:25:36 - INFO - __main__ - Cumulative validation average loss is 7.5568000541534275\n",
      "07/27/2023 19:25:37 - INFO - __main__ - Per validation step average loss is 0.22455111145973206\n",
      "07/27/2023 19:25:37 - INFO - __main__ - Cumulative validation average loss is 7.7813511656131595\n",
      "07/27/2023 19:25:37 - INFO - __main__ - Per validation step average loss is 0.14593324065208435\n",
      "07/27/2023 19:25:37 - INFO - __main__ - Cumulative validation average loss is 7.927284406265244\n",
      "07/27/2023 19:25:38 - INFO - __main__ - Per validation step average loss is 0.353523850440979\n",
      "07/27/2023 19:25:38 - INFO - __main__ - Cumulative validation average loss is 8.280808256706223\n",
      "07/27/2023 19:25:38 - INFO - __main__ - Per validation step average loss is 0.09715615212917328\n",
      "07/27/2023 19:25:38 - INFO - __main__ - Cumulative validation average loss is 8.377964408835396\n",
      "07/27/2023 19:25:38 - INFO - __main__ - Per validation step average loss is 0.051055535674095154\n",
      "07/27/2023 19:25:38 - INFO - __main__ - Cumulative validation average loss is 8.429019944509491\n",
      "07/27/2023 19:25:39 - INFO - __main__ - Per validation step average loss is 0.03412274271249771\n",
      "07/27/2023 19:25:39 - INFO - __main__ - Cumulative validation average loss is 8.463142687221989\n",
      "07/27/2023 19:25:39 - INFO - __main__ - Per validation step average loss is 0.020920265465974808\n",
      "07/27/2023 19:25:39 - INFO - __main__ - Cumulative validation average loss is 8.484062952687964\n",
      "07/27/2023 19:25:40 - INFO - __main__ - Per validation step average loss is 0.10091812908649445\n",
      "07/27/2023 19:25:40 - INFO - __main__ - Cumulative validation average loss is 8.584981081774458\n",
      "07/27/2023 19:25:40 - INFO - __main__ - Per validation step average loss is 0.172593355178833\n",
      "07/27/2023 19:25:40 - INFO - __main__ - Cumulative validation average loss is 8.757574436953291\n",
      "07/27/2023 19:25:41 - INFO - __main__ - Per validation step average loss is 0.03644911199808121\n",
      "07/27/2023 19:25:41 - INFO - __main__ - Cumulative validation average loss is 8.794023548951373\n",
      "07/27/2023 19:25:41 - INFO - __main__ - Per validation step average loss is 0.004060129169374704\n",
      "07/27/2023 19:25:41 - INFO - __main__ - Cumulative validation average loss is 8.798083678120747\n",
      "07/27/2023 19:25:41 - INFO - __main__ - Per validation step average loss is 0.015864897519350052\n",
      "07/27/2023 19:25:41 - INFO - __main__ - Cumulative validation average loss is 8.813948575640097\n",
      "07/27/2023 19:25:42 - INFO - __main__ - Per validation step average loss is 0.003194024320691824\n",
      "07/27/2023 19:25:42 - INFO - __main__ - Cumulative validation average loss is 8.817142599960789\n",
      "07/27/2023 19:25:42 - INFO - __main__ - Per validation step average loss is 0.021907245740294456\n",
      "07/27/2023 19:25:42 - INFO - __main__ - Cumulative validation average loss is 8.839049845701084\n",
      "07/27/2023 19:25:43 - INFO - __main__ - Per validation step average loss is 0.005467086099088192\n",
      "07/27/2023 19:25:43 - INFO - __main__ - Cumulative validation average loss is 8.844516931800172\n",
      "07/27/2023 19:25:43 - INFO - __main__ - Per validation step average loss is 0.02041914500296116\n",
      "07/27/2023 19:25:43 - INFO - __main__ - Cumulative validation average loss is 8.864936076803133\n",
      "07/27/2023 19:25:43 - INFO - __main__ - Average validation loss for Epoch 38 is 0.112214380719027\n",
      "07/27/2023 19:25:43 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:26:40 - INFO - __main__ - Starting epoch 39\n",
      "07/27/2023 19:26:41 - INFO - __main__ - train loss is 0.32918238639831543\n",
      "Steps:  79%|▊| 11818/15000 [1:41:51<24:24:28, 27.61s/it, lr=0.000987, step_loss=07/27/2023 19:26:41 - INFO - __main__ - train loss is 0.37344948574900627\n",
      "Steps:  79%|▊| 11819/15000 [1:41:52<17:07:51, 19.39s/it, lr=0.000987, step_loss=07/27/2023 19:26:41 - INFO - __main__ - train loss is 0.41335540637373924\n",
      "Steps:  79%|▊| 11820/15000 [1:41:52<12:02:06, 13.62s/it, lr=0.000987, step_loss=07/27/2023 19:26:42 - INFO - __main__ - train loss is 0.44874148443341255\n",
      "Steps:  79%|▊| 11821/15000 [1:41:52<8:28:10,  9.59s/it, lr=0.000987, step_loss=007/27/2023 19:26:42 - INFO - __main__ - train loss is 0.47770241647958755\n",
      "Steps:  79%|▊| 11822/15000 [1:41:52<5:58:32,  6.77s/it, lr=0.000987, step_loss=007/27/2023 19:26:42 - INFO - __main__ - train loss is 0.5271486192941666\n",
      "Steps:  79%|▊| 11823/15000 [1:41:52<4:13:55,  4.80s/it, lr=0.000987, step_loss=007/27/2023 19:26:42 - INFO - __main__ - train loss is 0.7440603375434875\n",
      "Steps:  79%|▊| 11824/15000 [1:41:52<3:00:45,  3.41s/it, lr=0.000987, step_loss=007/27/2023 19:26:42 - INFO - __main__ - train loss is 0.7470336332917213\n",
      "Steps:  79%|▊| 11825/15000 [1:41:53<2:09:29,  2.45s/it, lr=0.000987, step_loss=007/27/2023 19:26:42 - INFO - __main__ - train loss is 0.9681494906544685\n",
      "Steps:  79%|▊| 11826/15000 [1:41:53<1:33:32,  1.77s/it, lr=0.000987, step_loss=007/27/2023 19:26:43 - INFO - __main__ - train loss is 0.9908201266080141\n",
      "Steps:  79%|▊| 11827/15000 [1:41:53<1:08:23,  1.29s/it, lr=0.000987, step_loss=007/27/2023 19:26:43 - INFO - __main__ - train loss is 1.3209157157689333\n",
      "Steps:  79%|▊| 11828/15000 [1:41:53<50:42,  1.04it/s, lr=0.000987, step_loss=0.307/27/2023 19:26:43 - INFO - __main__ - train loss is 1.4713966716080904\n",
      "Steps:  79%|▊| 11829/15000 [1:41:53<38:22,  1.38it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:43 - INFO - __main__ - train loss is 2.283808099105954\n",
      "Steps:  79%|▊| 11830/15000 [1:41:54<29:47,  1.77it/s, lr=0.000987, step_loss=0.807/27/2023 19:26:43 - INFO - __main__ - train loss is 2.303257869556546\n",
      "Steps:  79%|▊| 11831/15000 [1:41:54<23:48,  2.22it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:44 - INFO - __main__ - train loss is 2.309895874466747\n",
      "Steps:  79%|▊| 11832/15000 [1:41:54<19:35,  2.69it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:44 - INFO - __main__ - train loss is 2.7500799312256277\n",
      "Steps:  79%|▊| 11833/15000 [1:41:54<16:37,  3.18it/s, lr=0.000987, step_loss=0.407/27/2023 19:26:44 - INFO - __main__ - train loss is 2.8946007206104696\n",
      "Steps:  79%|▊| 11834/15000 [1:41:54<14:27,  3.65it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:44 - INFO - __main__ - train loss is 2.9105809475295246\n",
      "Steps:  79%|▊| 11835/15000 [1:41:54<12:58,  4.07it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:44 - INFO - __main__ - train loss is 2.925085071939975\n",
      "Steps:  79%|▊| 11836/15000 [1:41:55<11:55,  4.42it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:45 - INFO - __main__ - train loss is 3.151813317555934\n",
      "Steps:  79%|▊| 11837/15000 [1:41:55<11:16,  4.68it/s, lr=0.000987, step_loss=0.207/27/2023 19:26:45 - INFO - __main__ - train loss is 3.2283871141262352\n",
      "Steps:  79%|▊| 11838/15000 [1:41:55<10:45,  4.90it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:45 - INFO - __main__ - train loss is 3.230482748709619\n",
      "Steps:  79%|▊| 11839/15000 [1:41:55<10:27,  5.03it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:45 - INFO - __main__ - train loss is 3.3443145221099257\n",
      "Steps:  79%|▊| 11840/15000 [1:41:55<10:18,  5.11it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:45 - INFO - __main__ - train loss is 3.3580871587619185\n",
      "Steps:  79%|▊| 11841/15000 [1:41:56<10:03,  5.24it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:45 - INFO - __main__ - train loss is 3.460158190689981\n",
      "Steps:  79%|▊| 11842/15000 [1:41:56<09:52,  5.33it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:46 - INFO - __main__ - train loss is 3.6346940910443664\n",
      "Steps:  79%|▊| 11843/15000 [1:41:56<09:44,  5.40it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:46 - INFO - __main__ - train loss is 3.9569428777322173\n",
      "Steps:  79%|▊| 11844/15000 [1:41:56<09:39,  5.45it/s, lr=0.000987, step_loss=0.307/27/2023 19:26:46 - INFO - __main__ - train loss is 3.984036804176867\n",
      "Steps:  79%|▊| 11845/15000 [1:41:56<09:35,  5.48it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:46 - INFO - __main__ - train loss is 4.094539881683886\n",
      "Steps:  79%|▊| 11846/15000 [1:41:56<09:32,  5.51it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:46 - INFO - __main__ - train loss is 4.564672173000872\n",
      "Steps:  79%|▊| 11847/15000 [1:41:57<09:31,  5.52it/s, lr=0.000987, step_loss=0.407/27/2023 19:26:47 - INFO - __main__ - train loss is 4.608044327236712\n",
      "Steps:  79%|▊| 11848/15000 [1:41:57<09:29,  5.53it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:47 - INFO - __main__ - train loss is 4.611392457503825\n",
      "Steps:  79%|▊| 11849/15000 [1:41:57<09:28,  5.54it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:47 - INFO - __main__ - train loss is 4.6187942936085165\n",
      "Steps:  79%|▊| 11850/15000 [1:41:57<09:27,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:47 - INFO - __main__ - train loss is 4.632391207385808\n",
      "Steps:  79%|▊| 11851/15000 [1:41:57<09:27,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:47 - INFO - __main__ - train loss is 4.647782285232097\n",
      "Steps:  79%|▊| 11852/15000 [1:41:58<09:26,  5.55it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:47 - INFO - __main__ - train loss is 5.076482136268169\n",
      "Steps:  79%|▊| 11853/15000 [1:41:58<09:26,  5.55it/s, lr=0.000987, step_loss=0.407/27/2023 19:26:48 - INFO - __main__ - train loss is 5.082306788768619\n",
      "Steps:  79%|▊| 11854/15000 [1:41:58<09:26,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:48 - INFO - __main__ - train loss is 5.097177915740758\n",
      "Steps:  79%|▊| 11855/15000 [1:41:58<09:25,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:48 - INFO - __main__ - train loss is 5.131528385449201\n",
      "Steps:  79%|▊| 11856/15000 [1:41:58<09:25,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:48 - INFO - __main__ - train loss is 5.286896713543683\n",
      "Steps:  79%|▊| 11857/15000 [1:41:58<09:25,  5.56it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:48 - INFO - __main__ - train loss is 5.324044168461114\n",
      "Steps:  79%|▊| 11858/15000 [1:41:59<09:25,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:48 - INFO - __main__ - train loss is 5.552632660139352\n",
      "Steps:  79%|▊| 11859/15000 [1:41:59<09:24,  5.56it/s, lr=0.000987, step_loss=0.207/27/2023 19:26:49 - INFO - __main__ - train loss is 5.774971381295472\n",
      "Steps:  79%|▊| 11860/15000 [1:41:59<09:24,  5.56it/s, lr=0.000987, step_loss=0.207/27/2023 19:26:49 - INFO - __main__ - train loss is 6.490416005719453\n",
      "[2023-07-27 19:26:49,433] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  79%|▊| 11861/15000 [1:41:59<09:20,  5.60it/s, lr=0.000987, step_loss=0.707/27/2023 19:26:49 - INFO - __main__ - train loss is 6.511324169579893\n",
      "Steps:  79%|▊| 11862/15000 [1:41:59<09:21,  5.59it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:49 - INFO - __main__ - train loss is 6.854309799615294\n",
      "Steps:  79%|▊| 11863/15000 [1:42:00<09:21,  5.58it/s, lr=0.000987, step_loss=0.307/27/2023 19:26:49 - INFO - __main__ - train loss is 7.017787846270949\n",
      "Steps:  79%|▊| 11864/15000 [1:42:00<09:22,  5.58it/s, lr=0.000987, step_loss=0.107/27/2023 19:26:50 - INFO - __main__ - train loss is 7.075345838908106\n",
      "Steps:  79%|▊| 11865/15000 [1:42:00<09:22,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:50 - INFO - __main__ - train loss is 7.104839088860899\n",
      "Steps:  79%|▊| 11866/15000 [1:42:00<09:22,  5.57it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:50 - INFO - __main__ - train loss is 7.409939768258482\n",
      "Steps:  79%|▊| 11867/15000 [1:42:00<09:23,  5.56it/s, lr=0.000987, step_loss=0.307/27/2023 19:26:50 - INFO - __main__ - train loss is 7.417276042979211\n",
      "Steps:  79%|▊| 11868/15000 [1:42:00<09:22,  5.56it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:50 - INFO - __main__ - train loss is 7.978140968363732\n",
      "Steps:  79%|▊| 11869/15000 [1:42:01<09:28,  5.51it/s, lr=0.000987, step_loss=0.507/27/2023 19:26:50 - INFO - __main__ - train loss is 7.986473815049976\n",
      "Steps:  79%|▊| 11870/15000 [1:42:01<09:26,  5.52it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:51 - INFO - __main__ - train loss is 7.9987902021966875\n",
      "Steps:  79%|▊| 11871/15000 [1:42:01<09:25,  5.53it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:51 - INFO - __main__ - train loss is 8.040702966507524\n",
      "Steps:  79%|▊| 11872/15000 [1:42:01<09:25,  5.53it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:51 - INFO - __main__ - train loss is 8.090338168200105\n",
      "Steps:  79%|▊| 11873/15000 [1:42:01<09:24,  5.54it/s, lr=0.000987, step_loss=0.007/27/2023 19:26:51 - INFO - __main__ - train loss is 8.351964888628572\n",
      "Steps:  79%|▊| 11874/15000 [1:42:02<09:23,  5.54it/s, lr=0.000987, step_loss=0.207/27/2023 19:26:51 - INFO - __main__ - train loss is 8.485736472066492\n",
      "Steps:  79%|▊| 11875/15000 [1:42:02<09:23,  5.54it/s, lr=0.000986, step_loss=0.107/27/2023 19:26:52 - INFO - __main__ - train loss is 8.493548239115626\n",
      "Steps:  79%|▊| 11876/15000 [1:42:02<09:22,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:52 - INFO - __main__ - train loss is 8.507982762996107\n",
      "Steps:  79%|▊| 11877/15000 [1:42:02<09:22,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:52 - INFO - __main__ - train loss is 8.70479384297505\n",
      "Steps:  79%|▊| 11878/15000 [1:42:02<09:21,  5.56it/s, lr=0.000986, step_loss=0.107/27/2023 19:26:52 - INFO - __main__ - train loss is 8.889549347106367\n",
      "Steps:  79%|▊| 11879/15000 [1:42:02<09:21,  5.56it/s, lr=0.000986, step_loss=0.107/27/2023 19:26:52 - INFO - __main__ - train loss is 8.899083465803415\n",
      "Steps:  79%|▊| 11880/15000 [1:42:03<09:21,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:52 - INFO - __main__ - train loss is 9.283304363954812\n",
      "Steps:  79%|▊| 11881/15000 [1:42:03<09:20,  5.56it/s, lr=0.000986, step_loss=0.307/27/2023 19:26:53 - INFO - __main__ - train loss is 9.496491760481149\n",
      "Steps:  79%|▊| 11882/15000 [1:42:03<09:20,  5.56it/s, lr=0.000986, step_loss=0.207/27/2023 19:26:53 - INFO - __main__ - train loss is 9.634454802144319\n",
      "Steps:  79%|▊| 11883/15000 [1:42:03<09:25,  5.51it/s, lr=0.000986, step_loss=0.107/27/2023 19:26:53 - INFO - __main__ - train loss is 9.929044530261308\n",
      "Steps:  79%|▊| 11884/15000 [1:42:03<09:23,  5.53it/s, lr=0.000986, step_loss=0.207/27/2023 19:26:53 - INFO - __main__ - train loss is 9.96147931041196\n",
      "Steps:  79%|▊| 11885/15000 [1:42:03<09:22,  5.54it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:53 - INFO - __main__ - train loss is 9.966103129088879\n",
      "Steps:  79%|▊| 11886/15000 [1:42:04<09:21,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:54 - INFO - __main__ - train loss is 9.97889632359147\n",
      "Steps:  79%|▊| 11887/15000 [1:42:04<09:21,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:54 - INFO - __main__ - train loss is 9.993160379119217\n",
      "Steps:  79%|▊| 11888/15000 [1:42:04<09:20,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:54 - INFO - __main__ - train loss is 10.019518253393471\n",
      "Steps:  79%|▊| 11889/15000 [1:42:04<09:19,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:54 - INFO - __main__ - train loss is 10.408005771227181\n",
      "Steps:  79%|▊| 11890/15000 [1:42:04<09:19,  5.56it/s, lr=0.000986, step_loss=0.307/27/2023 19:26:54 - INFO - __main__ - train loss is 10.45227959472686\n",
      "Steps:  79%|▊| 11891/15000 [1:42:05<09:19,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:54 - INFO - __main__ - train loss is 10.504984316416085\n",
      "Steps:  79%|▊| 11892/15000 [1:42:05<09:18,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:55 - INFO - __main__ - train loss is 10.603868586011231\n",
      "Steps:  79%|▊| 11893/15000 [1:42:05<09:18,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:55 - INFO - __main__ - train loss is 10.611160553526133\n",
      "Steps:  79%|▊| 11894/15000 [1:42:05<09:18,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:55 - INFO - __main__ - train loss is 10.635180137585849\n",
      "Steps:  79%|▊| 11895/15000 [1:42:05<09:21,  5.53it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:55 - INFO - __main__ - train loss is 10.843263498973101\n",
      "Steps:  79%|▊| 11896/15000 [1:42:05<09:25,  5.49it/s, lr=0.000986, step_loss=0.207/27/2023 19:26:55 - INFO - __main__ - train loss is 11.471365503501147\n",
      "Steps:  79%|▊| 11897/15000 [1:42:06<09:22,  5.51it/s, lr=0.000986, step_loss=0.607/27/2023 19:26:56 - INFO - __main__ - train loss is 11.866046003531665\n",
      "Steps:  79%|▊| 11898/15000 [1:42:06<09:20,  5.53it/s, lr=0.000986, step_loss=0.307/27/2023 19:26:56 - INFO - __main__ - train loss is 11.91749507887289\n",
      "Steps:  79%|▊| 11899/15000 [1:42:06<09:19,  5.54it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:56 - INFO - __main__ - train loss is 12.17200607759878\n",
      "Steps:  79%|▊| 11900/15000 [1:42:06<09:19,  5.54it/s, lr=0.000986, step_loss=0.207/27/2023 19:26:56 - INFO - __main__ - train loss is 12.1796058206819\n",
      "Steps:  79%|▊| 11901/15000 [1:42:06<09:18,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:56 - INFO - __main__ - train loss is 12.185989866498858\n",
      "Steps:  79%|▊| 11902/15000 [1:42:07<09:18,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:56 - INFO - __main__ - train loss is 12.514891067985445\n",
      "Steps:  79%|▊| 11903/15000 [1:42:07<09:17,  5.55it/s, lr=0.000986, step_loss=0.307/27/2023 19:26:57 - INFO - __main__ - train loss is 12.966298917774111\n",
      "Steps:  79%|▊| 11904/15000 [1:42:07<09:17,  5.56it/s, lr=0.000986, step_loss=0.407/27/2023 19:26:57 - INFO - __main__ - train loss is 12.97260301047936\n",
      "Steps:  79%|▊| 11905/15000 [1:42:07<09:16,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:57 - INFO - __main__ - train loss is 12.982223853003234\n",
      "Steps:  79%|▊| 11906/15000 [1:42:07<09:16,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:57 - INFO - __main__ - train loss is 13.059837623964995\n",
      "Steps:  79%|▊| 11907/15000 [1:42:07<09:16,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:57 - INFO - __main__ - train loss is 13.103320039343089\n",
      "Steps:  79%|▊| 11908/15000 [1:42:08<09:16,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:57 - INFO - __main__ - train loss is 13.270635611843318\n",
      "Steps:  79%|▊| 11909/15000 [1:42:08<09:16,  5.56it/s, lr=0.000986, step_loss=0.107/27/2023 19:26:58 - INFO - __main__ - train loss is 13.273303380701691\n",
      "Steps:  79%|▊| 11910/15000 [1:42:08<09:16,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:58 - INFO - __main__ - train loss is 13.289964939001948\n",
      "Steps:  79%|▊| 11911/15000 [1:42:08<09:16,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:58 - INFO - __main__ - train loss is 13.301462145056576\n",
      "Steps:  79%|▊| 11912/15000 [1:42:08<09:15,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:58 - INFO - __main__ - train loss is 13.4293322279118\n",
      "Steps:  79%|▊| 11913/15000 [1:42:09<09:15,  5.55it/s, lr=0.000986, step_loss=0.107/27/2023 19:26:58 - INFO - __main__ - train loss is 13.719761253800243\n",
      "Steps:  79%|▊| 11914/15000 [1:42:09<09:15,  5.56it/s, lr=0.000986, step_loss=0.207/27/2023 19:26:59 - INFO - __main__ - train loss is 13.950674252118915\n",
      "Steps:  79%|▊| 11915/15000 [1:42:09<09:15,  5.56it/s, lr=0.000986, step_loss=0.207/27/2023 19:26:59 - INFO - __main__ - train loss is 14.00732217496261\n",
      "Steps:  79%|▊| 11916/15000 [1:42:09<09:15,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:59 - INFO - __main__ - train loss is 14.216116977389902\n",
      "Steps:  79%|▊| 11917/15000 [1:42:09<09:14,  5.56it/s, lr=0.000986, step_loss=0.207/27/2023 19:26:59 - INFO - __main__ - train loss is 14.349948552902788\n",
      "Steps:  79%|▊| 11918/15000 [1:42:09<09:14,  5.56it/s, lr=0.000986, step_loss=0.107/27/2023 19:26:59 - INFO - __main__ - train loss is 14.36946647753939\n",
      "Steps:  79%|▊| 11919/15000 [1:42:10<09:14,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:26:59 - INFO - __main__ - train loss is 14.804201954510063\n",
      "Steps:  79%|▊| 11920/15000 [1:42:10<09:14,  5.55it/s, lr=0.000986, step_loss=0.407/27/2023 19:27:00 - INFO - __main__ - train loss is 15.128083223011345\n",
      "Steps:  79%|▊| 11921/15000 [1:42:10<09:18,  5.51it/s, lr=0.000986, step_loss=0.307/27/2023 19:27:00 - INFO - __main__ - train loss is 15.276686632540077\n",
      "Steps:  79%|▊| 11922/15000 [1:42:10<09:16,  5.53it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:00 - INFO - __main__ - train loss is 15.4031737386249\n",
      "Steps:  79%|▊| 11923/15000 [1:42:10<09:17,  5.52it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:00 - INFO - __main__ - train loss is 15.50909093907103\n",
      "Steps:  79%|▊| 11924/15000 [1:42:11<09:16,  5.53it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:00 - INFO - __main__ - train loss is 15.674038121011108\n",
      "Steps:  80%|▊| 11925/15000 [1:42:11<09:15,  5.54it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:01 - INFO - __main__ - train loss is 15.683428738731891\n",
      "Steps:  80%|▊| 11926/15000 [1:42:11<09:14,  5.54it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:01 - INFO - __main__ - train loss is 15.77083494188264\n",
      "Steps:  80%|▊| 11927/15000 [1:42:11<09:18,  5.50it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:01 - INFO - __main__ - train loss is 15.791950002778322\n",
      "Steps:  80%|▊| 11928/15000 [1:42:11<09:19,  5.49it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:01 - INFO - __main__ - train loss is 15.817425113637\n",
      "Steps:  80%|▊| 11929/15000 [1:42:11<09:17,  5.51it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:01 - INFO - __main__ - train loss is 16.025464456994087\n",
      "Steps:  80%|▊| 11930/15000 [1:42:12<09:15,  5.52it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:01 - INFO - __main__ - train loss is 16.068384621758014\n",
      "Steps:  80%|▊| 11931/15000 [1:42:12<09:14,  5.53it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:02 - INFO - __main__ - train loss is 16.509628866333514\n",
      "Steps:  80%|▊| 11932/15000 [1:42:12<09:13,  5.55it/s, lr=0.000986, step_loss=0.407/27/2023 19:27:02 - INFO - __main__ - train loss is 16.61278935195878\n",
      "Steps:  80%|▊| 11933/15000 [1:42:12<09:12,  5.55it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:02 - INFO - __main__ - train loss is 16.728058126289397\n",
      "Steps:  80%|▊| 11934/15000 [1:42:12<09:12,  5.55it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:02 - INFO - __main__ - train loss is 17.067160275299102\n",
      "Steps:  80%|▊| 11935/15000 [1:42:13<09:11,  5.56it/s, lr=0.000986, step_loss=0.307/27/2023 19:27:02 - INFO - __main__ - train loss is 17.073251945897937\n",
      "Steps:  80%|▊| 11936/15000 [1:42:13<09:11,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:03 - INFO - __main__ - train loss is 17.11993226222694\n",
      "Steps:  80%|▊| 11937/15000 [1:42:13<09:11,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:03 - INFO - __main__ - train loss is 17.33937027864158\n",
      "Steps:  80%|▊| 11938/15000 [1:42:13<09:14,  5.52it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:03 - INFO - __main__ - train loss is 17.52813166193664\n",
      "Steps:  80%|▊| 11939/15000 [1:42:13<09:13,  5.53it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:03 - INFO - __main__ - train loss is 17.75204831175506\n",
      "Steps:  80%|▊| 11940/15000 [1:42:13<09:14,  5.52it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:03 - INFO - __main__ - train loss is 17.764120489358902\n",
      "Steps:  80%|▊| 11941/15000 [1:42:14<09:12,  5.54it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:03 - INFO - __main__ - train loss is 17.893080413341522\n",
      "Steps:  80%|▊| 11942/15000 [1:42:14<09:11,  5.54it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:04 - INFO - __main__ - train loss is 17.89555327105336\n",
      "Steps:  80%|▊| 11943/15000 [1:42:14<09:10,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:04 - INFO - __main__ - train loss is 18.338255087612197\n",
      "Steps:  80%|▊| 11944/15000 [1:42:14<09:10,  5.56it/s, lr=0.000986, step_loss=0.407/27/2023 19:27:04 - INFO - __main__ - train loss is 18.5421050589066\n",
      "Steps:  80%|▊| 11945/15000 [1:42:14<09:09,  5.56it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:04 - INFO - __main__ - train loss is 19.062795678852126\n",
      "Steps:  80%|▊| 11946/15000 [1:42:14<09:09,  5.56it/s, lr=0.000986, step_loss=0.507/27/2023 19:27:04 - INFO - __main__ - train loss is 19.179439577041194\n",
      "Steps:  80%|▊| 11947/15000 [1:42:15<09:09,  5.56it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:05 - INFO - __main__ - train loss is 19.336490037618205\n",
      "Steps:  80%|▊| 11948/15000 [1:42:15<09:08,  5.56it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:05 - INFO - __main__ - train loss is 19.337795878527686\n",
      "Steps:  80%|▊| 11949/15000 [1:42:15<09:08,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:05 - INFO - __main__ - train loss is 19.37729365634732\n",
      "Steps:  80%|▊| 11950/15000 [1:42:15<09:08,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:05 - INFO - __main__ - train loss is 19.837704728124663\n",
      "Steps:  80%|▊| 11951/15000 [1:42:15<09:08,  5.56it/s, lr=0.000986, step_loss=0.407/27/2023 19:27:05 - INFO - __main__ - train loss is 19.895089256344363\n",
      "Steps:  80%|▊| 11952/15000 [1:42:16<09:08,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:05 - INFO - __main__ - train loss is 19.90670531964861\n",
      "Steps:  80%|▊| 11953/15000 [1:42:16<09:07,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:06 - INFO - __main__ - train loss is 19.909736669855192\n",
      "Steps:  80%|▊| 11954/15000 [1:42:16<09:11,  5.52it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:06 - INFO - __main__ - train loss is 19.91894232505001\n",
      "Steps:  80%|▊| 11955/15000 [1:42:16<09:12,  5.51it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:06 - INFO - __main__ - train loss is 19.93514822074212\n",
      "Steps:  80%|▊| 11956/15000 [1:42:16<09:13,  5.50it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:06 - INFO - __main__ - train loss is 20.50689707347192\n",
      "Steps:  80%|▊| 11957/15000 [1:42:16<09:13,  5.50it/s, lr=0.000986, step_loss=0.507/27/2023 19:27:06 - INFO - __main__ - train loss is 20.636993911350146\n",
      "Steps:  80%|▊| 11958/15000 [1:42:17<09:11,  5.52it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:07 - INFO - __main__ - train loss is 20.8213359976653\n",
      "Steps:  80%|▊| 11959/15000 [1:42:17<09:09,  5.53it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:07 - INFO - __main__ - train loss is 20.82350422348827\n",
      "Steps:  80%|▊| 11960/15000 [1:42:17<09:08,  5.54it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:07 - INFO - __main__ - train loss is 20.84367140289396\n",
      "Steps:  80%|▊| 11961/15000 [1:42:17<09:07,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:07 - INFO - __main__ - train loss is 20.932824692688882\n",
      "Steps:  80%|▊| 11962/15000 [1:42:17<09:06,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:07 - INFO - __main__ - train loss is 21.021678148768842\n",
      "Steps:  80%|▊| 11963/15000 [1:42:18<09:06,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:07 - INFO - __main__ - train loss is 21.205629377625883\n",
      "Steps:  80%|▊| 11964/15000 [1:42:18<09:06,  5.56it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:08 - INFO - __main__ - train loss is 21.438427119515836\n",
      "Steps:  80%|▊| 11965/15000 [1:42:18<09:06,  5.56it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:08 - INFO - __main__ - train loss is 21.440109221963212\n",
      "Steps:  80%|▊| 11966/15000 [1:42:18<09:05,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:08 - INFO - __main__ - train loss is 21.465472132666036\n",
      "Steps:  80%|▊| 11967/15000 [1:42:18<09:05,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:08 - INFO - __main__ - train loss is 21.466957387630828\n",
      "Steps:  80%|▊| 11968/15000 [1:42:18<09:05,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:08 - INFO - __main__ - train loss is 21.469129109871574\n",
      "Steps:  80%|▊| 11969/15000 [1:42:19<09:05,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:09 - INFO - __main__ - train loss is 21.47084048797842\n",
      "Steps:  80%|▊| 11970/15000 [1:42:19<09:05,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:09 - INFO - __main__ - train loss is 21.501554301357828\n",
      "Steps:  80%|▊| 11971/15000 [1:42:19<09:04,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:09 - INFO - __main__ - train loss is 21.805166831589304\n",
      "Steps:  80%|▊| 11972/15000 [1:42:19<09:04,  5.56it/s, lr=0.000986, step_loss=0.307/27/2023 19:27:09 - INFO - __main__ - train loss is 22.55178164539393\n",
      "Steps:  80%|▊| 11973/15000 [1:42:19<09:04,  5.56it/s, lr=0.000986, step_loss=0.707/27/2023 19:27:09 - INFO - __main__ - train loss is 22.577385740703903\n",
      "Steps:  80%|▊| 11974/15000 [1:42:20<09:04,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:09 - INFO - __main__ - train loss is 22.921821968979202\n",
      "Steps:  80%|▊| 11975/15000 [1:42:20<09:09,  5.50it/s, lr=0.000986, step_loss=0.307/27/2023 19:27:10 - INFO - __main__ - train loss is 22.980461651808582\n",
      "Steps:  80%|▊| 11976/15000 [1:42:20<09:11,  5.49it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:10 - INFO - __main__ - train loss is 23.830561692244373\n",
      "Steps:  80%|▊| 11977/15000 [1:42:20<09:08,  5.51it/s, lr=0.000986, step_loss=0.807/27/2023 19:27:10 - INFO - __main__ - train loss is 23.832419265294448\n",
      "Steps:  80%|▊| 11978/15000 [1:42:20<09:07,  5.52it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:10 - INFO - __main__ - train loss is 23.833893767325208\n",
      "Steps:  80%|▊| 11979/15000 [1:42:20<09:05,  5.53it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:10 - INFO - __main__ - train loss is 23.84034310397692\n",
      "Steps:  80%|▊| 11980/15000 [1:42:21<09:04,  5.54it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:10 - INFO - __main__ - train loss is 24.054285721154884\n",
      "Steps:  80%|▊| 11981/15000 [1:42:21<09:08,  5.50it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:11 - INFO - __main__ - train loss is 24.319209502311423\n",
      "Steps:  80%|▊| 11982/15000 [1:42:21<09:10,  5.49it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:11 - INFO - __main__ - train loss is 24.480841235490516\n",
      "Steps:  80%|▊| 11983/15000 [1:42:21<09:07,  5.51it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:11 - INFO - __main__ - train loss is 24.966401593061164\n",
      "Steps:  80%|▊| 11984/15000 [1:42:21<09:05,  5.53it/s, lr=0.000986, step_loss=0.407/27/2023 19:27:11 - INFO - __main__ - train loss is 25.36306651053019\n",
      "Steps:  80%|▊| 11985/15000 [1:42:22<09:04,  5.54it/s, lr=0.000986, step_loss=0.307/27/2023 19:27:11 - INFO - __main__ - train loss is 25.41314018634148\n",
      "Steps:  80%|▊| 11986/15000 [1:42:22<09:03,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:12 - INFO - __main__ - train loss is 25.416345057776198\n",
      "Steps:  80%|▊| 11987/15000 [1:42:22<09:02,  5.56it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:12 - INFO - __main__ - train loss is 25.62432768731378\n",
      "Steps:  80%|▊| 11988/15000 [1:42:22<09:01,  5.56it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:12 - INFO - __main__ - train loss is 26.064530042698607\n",
      "Steps:  80%|▊| 11989/15000 [1:42:22<09:01,  5.56it/s, lr=0.000986, step_loss=0.407/27/2023 19:27:12 - INFO - __main__ - train loss is 26.395671931793913\n",
      "Steps:  80%|▊| 11990/15000 [1:42:22<09:02,  5.55it/s, lr=0.000986, step_loss=0.307/27/2023 19:27:12 - INFO - __main__ - train loss is 26.48225969611667\n",
      "Steps:  80%|▊| 11991/15000 [1:42:23<09:06,  5.51it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:12 - INFO - __main__ - train loss is 26.508810570230708\n",
      "Steps:  80%|▊| 11992/15000 [1:42:23<09:04,  5.52it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:13 - INFO - __main__ - train loss is 26.511008949251845\n",
      "Steps:  80%|▊| 11993/15000 [1:42:23<09:08,  5.48it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:13 - INFO - __main__ - train loss is 26.81058564898558\n",
      "Steps:  80%|▊| 11994/15000 [1:42:23<09:09,  5.47it/s, lr=0.000986, step_loss=0.307/27/2023 19:27:13 - INFO - __main__ - train loss is 26.880791844101623\n",
      "Steps:  80%|▊| 11995/15000 [1:42:23<09:11,  5.45it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:13 - INFO - __main__ - train loss is 26.89929842320271\n",
      "Steps:  80%|▊| 11996/15000 [1:42:24<09:11,  5.45it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:13 - INFO - __main__ - train loss is 26.931078759254888\n",
      "Steps:  80%|▊| 11997/15000 [1:42:24<09:07,  5.48it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:14 - INFO - __main__ - train loss is 27.229316738666967\n",
      "Steps:  80%|▊| 11998/15000 [1:42:24<09:05,  5.50it/s, lr=0.000986, step_loss=0.207/27/2023 19:27:14 - INFO - __main__ - train loss is 27.24847569433041\n",
      "Steps:  80%|▊| 11999/15000 [1:42:24<09:03,  5.52it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:14 - INFO - __main__ - train loss is 27.345795371802524\n",
      "Steps:  80%|▊| 12000/15000 [1:42:24<09:02,  5.53it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:14 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-12000\n",
      "07/27/2023 19:27:14 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:27:14,530] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:27:14,534] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-12000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:27:14,534] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-12000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:27:14,540] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-12000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:27:14,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-12000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:27:14,548] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-12000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:27:14,548] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-12000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:27:14,548] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:27:14 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-12000/pytorch_model\n",
      "07/27/2023 19:27:14 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-12000/scheduler.bin\n",
      "07/27/2023 19:27:14 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-12000/random_states_0.pkl\n",
      "07/27/2023 19:27:14 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-12000\n",
      "Steps:  80%|▊| 12000/15000 [1:42:24<09:02,  5.53it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:14 - INFO - __main__ - train loss is 27.389409699710086\n",
      "Steps:  80%|▊| 12001/15000 [1:42:24<09:20,  5.35it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:14 - INFO - __main__ - train loss is 27.398287714691833\n",
      "Steps:  80%|▊| 12002/15000 [1:42:25<09:17,  5.38it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:15 - INFO - __main__ - train loss is 27.477794856997207\n",
      "Steps:  80%|▊| 12003/15000 [1:42:25<09:16,  5.38it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:15 - INFO - __main__ - train loss is 27.485160040436313\n",
      "Steps:  80%|▊| 12004/15000 [1:42:25<09:13,  5.42it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:15 - INFO - __main__ - train loss is 27.487182861426845\n",
      "Steps:  80%|▊| 12005/15000 [1:42:25<09:08,  5.46it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:15 - INFO - __main__ - train loss is 27.639895355561748\n",
      "Steps:  80%|▊| 12006/15000 [1:42:25<09:05,  5.49it/s, lr=0.000986, step_loss=0.107/27/2023 19:27:15 - INFO - __main__ - train loss is 27.687863974133506\n",
      "Steps:  80%|▊| 12007/15000 [1:42:26<09:04,  5.50it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:15 - INFO - __main__ - train loss is 27.691401939606294\n",
      "Steps:  80%|▊| 12008/15000 [1:42:26<09:02,  5.51it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:16 - INFO - __main__ - train loss is 27.74571118107997\n",
      "Steps:  80%|▊| 12009/15000 [1:42:26<09:01,  5.53it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:16 - INFO - __main__ - train loss is 27.75489144749008\n",
      "Steps:  80%|▊| 12010/15000 [1:42:26<08:59,  5.54it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:16 - INFO - __main__ - train loss is 27.76522385305725\n",
      "Steps:  80%|▊| 12011/15000 [1:42:26<08:58,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:16 - INFO - __main__ - train loss is 27.76704457984306\n",
      "Steps:  80%|▊| 12012/15000 [1:42:26<08:57,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:16 - INFO - __main__ - train loss is 28.30483595118858\n",
      "Steps:  80%|▊| 12013/15000 [1:42:27<08:58,  5.55it/s, lr=0.000986, step_loss=0.507/27/2023 19:27:16 - INFO - __main__ - train loss is 28.39725106046535\n",
      "Steps:  80%|▊| 12014/15000 [1:42:27<08:57,  5.55it/s, lr=0.000986, step_loss=0.007/27/2023 19:27:17 - INFO - __main__ - train loss is 28.593881791690364\n",
      "Steps:  80%|▊| 12015/15000 [1:42:27<08:56,  5.56it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:17 - INFO - __main__ - train loss is 28.693939237156883\n",
      "Steps:  80%|▊| 12016/15000 [1:42:27<09:01,  5.51it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:17 - INFO - __main__ - train loss is 28.701845614472404\n",
      "Steps:  80%|▊| 12017/15000 [1:42:27<09:06,  5.45it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:17 - INFO - __main__ - train loss is 28.711525533581153\n",
      "Steps:  80%|▊| 12018/15000 [1:42:28<09:05,  5.47it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:17 - INFO - __main__ - train loss is 28.713748999871314\n",
      "Steps:  80%|▊| 12019/15000 [1:42:28<09:02,  5.49it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:18 - INFO - __main__ - train loss is 29.114341625012457\n",
      "Steps:  80%|▊| 12020/15000 [1:42:28<09:00,  5.51it/s, lr=0.000985, step_loss=0.407/27/2023 19:27:18 - INFO - __main__ - train loss is 29.636874207295477\n",
      "Steps:  80%|▊| 12021/15000 [1:42:28<08:58,  5.53it/s, lr=0.000985, step_loss=0.507/27/2023 19:27:18 - INFO - __main__ - train loss is 29.82955350819975\n",
      "Steps:  80%|▊| 12022/15000 [1:42:28<08:57,  5.54it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:18 - INFO - __main__ - train loss is 30.079795234836638\n",
      "Steps:  80%|▊| 12023/15000 [1:42:28<08:56,  5.54it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:18 - INFO - __main__ - train loss is 30.259474867023528\n",
      "Steps:  80%|▊| 12024/15000 [1:42:29<08:56,  5.54it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:18 - INFO - __main__ - train loss is 30.385672905482352\n",
      "Steps:  80%|▊| 12025/15000 [1:42:29<08:56,  5.54it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:19 - INFO - __main__ - train loss is 30.615140804089606\n",
      "Steps:  80%|▊| 12026/15000 [1:42:29<08:55,  5.55it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:19 - INFO - __main__ - train loss is 30.668314312584698\n",
      "Steps:  80%|▊| 12027/15000 [1:42:29<08:55,  5.55it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:19 - INFO - __main__ - train loss is 30.672867900691926\n",
      "Steps:  80%|▊| 12028/15000 [1:42:29<08:54,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:19 - INFO - __main__ - train loss is 30.812942705117166\n",
      "Steps:  80%|▊| 12029/15000 [1:42:30<08:54,  5.56it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:19 - INFO - __main__ - train loss is 30.946214056573808\n",
      "Steps:  80%|▊| 12030/15000 [1:42:30<08:54,  5.56it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:20 - INFO - __main__ - train loss is 30.986211518757045\n",
      "Steps:  80%|▊| 12031/15000 [1:42:30<08:54,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:20 - INFO - __main__ - train loss is 31.00449103023857\n",
      "Steps:  80%|▊| 12032/15000 [1:42:30<08:53,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:20 - INFO - __main__ - train loss is 31.00976575911045\n",
      "Steps:  80%|▊| 12033/15000 [1:42:30<08:53,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:20 - INFO - __main__ - train loss is 31.02707713097334\n",
      "Steps:  80%|▊| 12034/15000 [1:42:30<08:53,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:20 - INFO - __main__ - train loss is 31.036465807817876\n",
      "Steps:  80%|▊| 12035/15000 [1:42:31<08:53,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:20 - INFO - __main__ - train loss is 31.038330047857016\n",
      "Steps:  80%|▊| 12036/15000 [1:42:31<08:52,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:21 - INFO - __main__ - train loss is 31.040681298822165\n",
      "Steps:  80%|▊| 12037/15000 [1:42:31<08:52,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:21 - INFO - __main__ - train loss is 31.045579163357615\n",
      "Steps:  80%|▊| 12038/15000 [1:42:31<08:52,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:21 - INFO - __main__ - train loss is 31.053787630982697\n",
      "Steps:  80%|▊| 12039/15000 [1:42:31<08:52,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:21 - INFO - __main__ - train loss is 31.127189208753407\n",
      "Steps:  80%|▊| 12040/15000 [1:42:31<08:52,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:21 - INFO - __main__ - train loss is 31.132217960432172\n",
      "Steps:  80%|▊| 12041/15000 [1:42:32<09:01,  5.47it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:22 - INFO - __main__ - train loss is 31.202941806986928\n",
      "Steps:  80%|▊| 12042/15000 [1:42:32<10:52,  4.53it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:22 - INFO - __main__ - train loss is 31.37414443679154\n",
      "Steps:  80%|▊| 12043/15000 [1:42:32<10:39,  4.62it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:22 - INFO - __main__ - train loss is 31.594635577872396\n",
      "Steps:  80%|▊| 12044/15000 [1:42:32<10:41,  4.61it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:22 - INFO - __main__ - train loss is 31.72102731652558\n",
      "Steps:  80%|▊| 12045/15000 [1:42:33<10:10,  4.84it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:22 - INFO - __main__ - train loss is 32.379052402451634\n",
      "Steps:  80%|▊| 12046/15000 [1:42:33<09:46,  5.03it/s, lr=0.000985, step_loss=0.607/27/2023 19:27:23 - INFO - __main__ - train loss is 32.57752959616482\n",
      "Steps:  80%|▊| 12047/15000 [1:42:33<09:31,  5.17it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:23 - INFO - __main__ - train loss is 32.58900936041027\n",
      "Steps:  80%|▊| 12048/15000 [1:42:33<09:20,  5.27it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:23 - INFO - __main__ - train loss is 32.59479418955743\n",
      "Steps:  80%|▊| 12049/15000 [1:42:33<09:11,  5.35it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:23 - INFO - __main__ - train loss is 32.635204864665866\n",
      "Steps:  80%|▊| 12050/15000 [1:42:34<09:05,  5.41it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:23 - INFO - __main__ - train loss is 32.74889452569187\n",
      "Steps:  80%|▊| 12051/15000 [1:42:34<09:00,  5.45it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:24 - INFO - __main__ - train loss is 33.05788723938167\n",
      "Steps:  80%|▊| 12052/15000 [1:42:34<08:57,  5.48it/s, lr=0.000985, step_loss=0.307/27/2023 19:27:24 - INFO - __main__ - train loss is 33.32296575419605\n",
      "Steps:  80%|▊| 12053/15000 [1:42:34<08:55,  5.50it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:24 - INFO - __main__ - train loss is 33.50161453895271\n",
      "Steps:  80%|▊| 12054/15000 [1:42:34<08:53,  5.52it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:24 - INFO - __main__ - train loss is 34.07896795682609\n",
      "Steps:  80%|▊| 12055/15000 [1:42:34<08:52,  5.53it/s, lr=0.000985, step_loss=0.507/27/2023 19:27:24 - INFO - __main__ - train loss is 34.25869652442634\n",
      "Steps:  80%|▊| 12056/15000 [1:42:35<08:51,  5.54it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:24 - INFO - __main__ - train loss is 34.43520456366241\n",
      "Steps:  80%|▊| 12057/15000 [1:42:35<08:50,  5.55it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:25 - INFO - __main__ - train loss is 34.87722798995674\n",
      "Steps:  80%|▊| 12058/15000 [1:42:35<08:50,  5.54it/s, lr=0.000985, step_loss=0.407/27/2023 19:27:25 - INFO - __main__ - train loss is 35.26672932319343\n",
      "Steps:  80%|▊| 12059/15000 [1:42:35<08:49,  5.55it/s, lr=0.000985, step_loss=0.307/27/2023 19:27:25 - INFO - __main__ - train loss is 35.297255236655474\n",
      "Steps:  80%|▊| 12060/15000 [1:42:35<08:49,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:25 - INFO - __main__ - train loss is 35.350440945476294\n",
      "Steps:  80%|▊| 12061/15000 [1:42:35<08:48,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:25 - INFO - __main__ - train loss is 35.353795550530776\n",
      "Steps:  80%|▊| 12062/15000 [1:42:36<08:48,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:26 - INFO - __main__ - train loss is 35.37266460782848\n",
      "Steps:  80%|▊| 12063/15000 [1:42:36<08:49,  5.55it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:26 - INFO - __main__ - train loss is 35.50485835201107\n",
      "Steps:  80%|▊| 12064/15000 [1:42:36<08:48,  5.55it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:26 - INFO - __main__ - train loss is 35.584888003533706\n",
      "Steps:  80%|▊| 12065/15000 [1:42:36<08:48,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:26 - INFO - __main__ - train loss is 35.71613799757324\n",
      "Steps:  80%|▊| 12066/15000 [1:42:36<08:47,  5.56it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:26 - INFO - __main__ - train loss is 35.724256898975\n",
      "Steps:  80%|▊| 12067/15000 [1:42:37<08:47,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:26 - INFO - __main__ - train loss is 35.904182221507654\n",
      "Steps:  80%|▊| 12068/15000 [1:42:37<08:47,  5.56it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:27 - INFO - __main__ - train loss is 35.908717713085935\n",
      "Steps:  80%|▊| 12069/15000 [1:42:37<08:47,  5.56it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:27 - INFO - __main__ - train loss is 36.13874568673782\n",
      "Steps:  80%|▊| 12070/15000 [1:42:37<08:46,  5.56it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:27 - INFO - __main__ - train loss is 36.326480290619656\n",
      "Steps:  80%|▊| 12071/15000 [1:42:37<08:46,  5.56it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:27 - INFO - __main__ - train loss is 36.450243084458634\n",
      "Steps:  80%|▊| 12072/15000 [1:42:37<08:47,  5.55it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:27 - INFO - __main__ - train loss is 36.462764179101214\n",
      "Steps:  80%|▊| 12073/15000 [1:42:38<08:51,  5.51it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:28 - INFO - __main__ - train loss is 36.960667168488726\n",
      "Steps:  80%|▊| 12074/15000 [1:42:38<09:01,  5.40it/s, lr=0.000985, step_loss=0.407/27/2023 19:27:28 - INFO - __main__ - train loss is 37.05105811893009\n",
      "Steps:  80%|▊| 12075/15000 [1:42:38<09:12,  5.30it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:28 - INFO - __main__ - train loss is 37.35419798432849\n",
      "Steps:  81%|▊| 12076/15000 [1:42:38<09:19,  5.23it/s, lr=0.000985, step_loss=0.307/27/2023 19:27:28 - INFO - __main__ - train loss is 37.89893699227832\n",
      "Steps:  81%|▊| 12077/15000 [1:42:38<09:23,  5.18it/s, lr=0.000985, step_loss=0.507/27/2023 19:27:28 - INFO - __main__ - train loss is 38.433903818717226\n",
      "Steps:  81%|▊| 12078/15000 [1:42:39<09:26,  5.16it/s, lr=0.000985, step_loss=0.507/27/2023 19:27:29 - INFO - __main__ - train loss is 38.54466307698749\n",
      "Steps:  81%|▊| 12079/15000 [1:42:39<09:30,  5.12it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:29 - INFO - __main__ - train loss is 38.67612729012035\n",
      "Steps:  81%|▊| 12080/15000 [1:42:39<09:26,  5.15it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:29 - INFO - __main__ - train loss is 39.42592868744396\n",
      "Steps:  81%|▊| 12081/15000 [1:42:39<09:28,  5.13it/s, lr=0.000985, step_loss=0.707/27/2023 19:27:29 - INFO - __main__ - train loss is 39.60853101848625\n",
      "Steps:  81%|▊| 12082/15000 [1:42:39<09:26,  5.15it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:29 - INFO - __main__ - train loss is 39.629599556094036\n",
      "Steps:  81%|▊| 12083/15000 [1:42:40<09:22,  5.19it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:29 - INFO - __main__ - train loss is 40.245043858652934\n",
      "Steps:  81%|▊| 12084/15000 [1:42:40<09:25,  5.16it/s, lr=0.000985, step_loss=0.607/27/2023 19:27:30 - INFO - __main__ - train loss is 40.34698029584251\n",
      "Steps:  81%|▊| 12085/15000 [1:42:40<09:28,  5.13it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:30 - INFO - __main__ - train loss is 40.35123678087257\n",
      "Steps:  81%|▊| 12086/15000 [1:42:40<09:29,  5.12it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:30 - INFO - __main__ - train loss is 40.372682181885466\n",
      "Steps:  81%|▊| 12087/15000 [1:42:40<09:30,  5.11it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:30 - INFO - __main__ - train loss is 40.4748255291488\n",
      "Steps:  81%|▊| 12088/15000 [1:42:41<09:30,  5.10it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:30 - INFO - __main__ - train loss is 40.47678038594313\n",
      "Steps:  81%|▊| 12089/15000 [1:42:41<09:31,  5.10it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:31 - INFO - __main__ - train loss is 40.48246822622605\n",
      "Steps:  81%|▊| 12090/15000 [1:42:41<09:23,  5.17it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:31 - INFO - __main__ - train loss is 40.67265581456013\n",
      "Steps:  81%|▊| 12091/15000 [1:42:41<09:21,  5.18it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:31 - INFO - __main__ - train loss is 40.75563638028689\n",
      "Steps:  81%|▊| 12092/15000 [1:42:41<09:25,  5.14it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:31 - INFO - __main__ - train loss is 40.91419303533621\n",
      "Steps:  81%|▊| 12093/15000 [1:42:42<09:44,  4.97it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:31 - INFO - __main__ - train loss is 40.92323440336622\n",
      "Steps:  81%|▊| 12094/15000 [1:42:42<09:40,  5.00it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:32 - INFO - __main__ - train loss is 41.06019188486971\n",
      "Steps:  81%|▊| 12095/15000 [1:42:42<09:38,  5.02it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:32 - INFO - __main__ - train loss is 41.089485459262505\n",
      "Steps:  81%|▊| 12096/15000 [1:42:42<09:36,  5.04it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:32 - INFO - __main__ - train loss is 41.10263639711775\n",
      "Steps:  81%|▊| 12097/15000 [1:42:42<09:34,  5.05it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:32 - INFO - __main__ - train loss is 41.14396897354163\n",
      "Steps:  81%|▊| 12098/15000 [1:42:43<09:38,  5.02it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:32 - INFO - __main__ - train loss is 41.15399666992016\n",
      "Steps:  81%|▊| 12099/15000 [1:42:43<09:34,  5.05it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:33 - INFO - __main__ - train loss is 41.160664775175974\n",
      "Steps:  81%|▊| 12100/15000 [1:42:43<09:32,  5.07it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:33 - INFO - __main__ - train loss is 41.43992004613392\n",
      "Steps:  81%|▊| 12101/15000 [1:42:43<09:31,  5.07it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:33 - INFO - __main__ - train loss is 41.44568390655331\n",
      "Steps:  81%|▊| 12102/15000 [1:42:43<09:32,  5.06it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:33 - INFO - __main__ - train loss is 41.49548565107398\n",
      "Steps:  81%|▊| 12103/15000 [1:42:44<09:31,  5.07it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:33 - INFO - __main__ - train loss is 41.60906016337685\n",
      "Steps:  81%|▊| 12104/15000 [1:42:44<09:30,  5.08it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:34 - INFO - __main__ - train loss is 41.62284659850411\n",
      "Steps:  81%|▊| 12105/15000 [1:42:44<09:31,  5.07it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:34 - INFO - __main__ - train loss is 41.62518931156956\n",
      "Steps:  81%|▊| 12106/15000 [1:42:44<09:29,  5.08it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:34 - INFO - __main__ - train loss is 41.897134102648124\n",
      "Steps:  81%|▊| 12107/15000 [1:42:44<09:30,  5.07it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:34 - INFO - __main__ - train loss is 41.899152390193194\n",
      "Steps:  81%|▊| 12108/15000 [1:42:45<09:29,  5.08it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:34 - INFO - __main__ - train loss is 42.41494487924501\n",
      "Steps:  81%|▊| 12109/15000 [1:42:45<09:30,  5.07it/s, lr=0.000985, step_loss=0.507/27/2023 19:27:35 - INFO - __main__ - train loss is 42.416784796630964\n",
      "Steps:  81%|▊| 12110/15000 [1:42:45<09:29,  5.08it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:35 - INFO - __main__ - train loss is 42.846167627489194\n",
      "Steps:  81%|▊| 12111/15000 [1:42:45<09:30,  5.07it/s, lr=0.000985, step_loss=0.407/27/2023 19:27:35 - INFO - __main__ - train loss is 42.847321061533876\n",
      "Steps:  81%|▊| 12112/15000 [1:42:45<09:30,  5.06it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:35 - INFO - __main__ - train loss is 42.97633871261496\n",
      "Steps:  81%|▊| 12113/15000 [1:42:46<09:31,  5.05it/s, lr=0.000985, step_loss=0.107/27/2023 19:27:35 - INFO - __main__ - train loss is 42.99173758935649\n",
      "Steps:  81%|▊| 12114/15000 [1:42:46<09:30,  5.05it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:36 - INFO - __main__ - train loss is 43.005786464666016\n",
      "Steps:  81%|▊| 12115/15000 [1:42:46<09:30,  5.06it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:36 - INFO - __main__ - train loss is 43.020885775913484\n",
      "Steps:  81%|▊| 12116/15000 [1:42:46<09:30,  5.06it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:36 - INFO - __main__ - train loss is 43.092370557715185\n",
      "Steps:  81%|▊| 12117/15000 [1:42:46<09:30,  5.05it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:36 - INFO - __main__ - train loss is 43.328551533748396\n",
      "Steps:  81%|▊| 12118/15000 [1:42:47<09:25,  5.10it/s, lr=0.000985, step_loss=0.207/27/2023 19:27:36 - INFO - __main__ - train loss is 43.34376722027082\n",
      "Steps:  81%|▊| 12119/15000 [1:42:47<09:16,  5.17it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:37 - INFO - __main__ - train loss is 43.35725801170338\n",
      "Steps:  81%|▊| 12120/15000 [1:42:47<12:56,  3.71it/s, lr=0.000985, step_loss=0.007/27/2023 19:27:38 - INFO - __main__ - Per validation step average loss is 0.0019867513328790665\n",
      "07/27/2023 19:27:38 - INFO - __main__ - Cumulative validation average loss is 0.0019867513328790665\n",
      "07/27/2023 19:27:38 - INFO - __main__ - Per validation step average loss is 0.0029549915343523026\n",
      "07/27/2023 19:27:38 - INFO - __main__ - Cumulative validation average loss is 0.004941742867231369\n",
      "07/27/2023 19:27:39 - INFO - __main__ - Per validation step average loss is 0.004050291143357754\n",
      "07/27/2023 19:27:39 - INFO - __main__ - Cumulative validation average loss is 0.008992034010589123\n",
      "07/27/2023 19:27:39 - INFO - __main__ - Per validation step average loss is 0.11118684709072113\n",
      "07/27/2023 19:27:39 - INFO - __main__ - Cumulative validation average loss is 0.12017888110131025\n",
      "07/27/2023 19:27:40 - INFO - __main__ - Per validation step average loss is 0.015199474059045315\n",
      "07/27/2023 19:27:40 - INFO - __main__ - Cumulative validation average loss is 0.13537835516035557\n",
      "07/27/2023 19:27:40 - INFO - __main__ - Per validation step average loss is 0.05673932284116745\n",
      "07/27/2023 19:27:40 - INFO - __main__ - Cumulative validation average loss is 0.19211767800152302\n",
      "07/27/2023 19:27:40 - INFO - __main__ - Per validation step average loss is 0.0023043835535645485\n",
      "07/27/2023 19:27:40 - INFO - __main__ - Cumulative validation average loss is 0.19442206155508757\n",
      "07/27/2023 19:27:41 - INFO - __main__ - Per validation step average loss is 0.001826003659516573\n",
      "07/27/2023 19:27:41 - INFO - __main__ - Cumulative validation average loss is 0.19624806521460414\n",
      "07/27/2023 19:27:41 - INFO - __main__ - Per validation step average loss is 0.5677632689476013\n",
      "07/27/2023 19:27:41 - INFO - __main__ - Cumulative validation average loss is 0.7640113341622055\n",
      "07/27/2023 19:27:42 - INFO - __main__ - Per validation step average loss is 0.19230899214744568\n",
      "07/27/2023 19:27:42 - INFO - __main__ - Cumulative validation average loss is 0.9563203263096511\n",
      "07/27/2023 19:27:42 - INFO - __main__ - Per validation step average loss is 0.10915812104940414\n",
      "07/27/2023 19:27:42 - INFO - __main__ - Cumulative validation average loss is 1.0654784473590553\n",
      "07/27/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.2795719802379608\n",
      "07/27/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 1.345050427597016\n",
      "07/27/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.03266938030719757\n",
      "07/27/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 1.3777198079042137\n",
      "07/27/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.12362819164991379\n",
      "07/27/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 1.5013479995541275\n",
      "07/27/2023 19:27:44 - INFO - __main__ - Per validation step average loss is 0.053044699132442474\n",
      "07/27/2023 19:27:44 - INFO - __main__ - Cumulative validation average loss is 1.55439269868657\n",
      "07/27/2023 19:27:44 - INFO - __main__ - Per validation step average loss is 0.08037051558494568\n",
      "07/27/2023 19:27:44 - INFO - __main__ - Cumulative validation average loss is 1.6347632142715156\n",
      "07/27/2023 19:27:45 - INFO - __main__ - Per validation step average loss is 0.0037387371994554996\n",
      "07/27/2023 19:27:45 - INFO - __main__ - Cumulative validation average loss is 1.638501951470971\n",
      "07/27/2023 19:27:45 - INFO - __main__ - Per validation step average loss is 0.03121015429496765\n",
      "07/27/2023 19:27:45 - INFO - __main__ - Cumulative validation average loss is 1.6697121057659388\n",
      "07/27/2023 19:27:45 - INFO - __main__ - Per validation step average loss is 0.008655495941638947\n",
      "07/27/2023 19:27:45 - INFO - __main__ - Cumulative validation average loss is 1.6783676017075777\n",
      "07/27/2023 19:27:46 - INFO - __main__ - Per validation step average loss is 0.014035002328455448\n",
      "07/27/2023 19:27:46 - INFO - __main__ - Cumulative validation average loss is 1.6924026040360332\n",
      "07/27/2023 19:27:46 - INFO - __main__ - Per validation step average loss is 0.19201582670211792\n",
      "07/27/2023 19:27:46 - INFO - __main__ - Cumulative validation average loss is 1.884418430738151\n",
      "07/27/2023 19:27:47 - INFO - __main__ - Per validation step average loss is 0.19011953473091125\n",
      "07/27/2023 19:27:47 - INFO - __main__ - Cumulative validation average loss is 2.0745379654690623\n",
      "07/27/2023 19:27:47 - INFO - __main__ - Per validation step average loss is 0.009870745241641998\n",
      "07/27/2023 19:27:47 - INFO - __main__ - Cumulative validation average loss is 2.0844087107107043\n",
      "07/27/2023 19:27:48 - INFO - __main__ - Per validation step average loss is 0.10703729093074799\n",
      "07/27/2023 19:27:48 - INFO - __main__ - Cumulative validation average loss is 2.1914460016414523\n",
      "07/27/2023 19:27:48 - INFO - __main__ - Per validation step average loss is 0.07949341088533401\n",
      "07/27/2023 19:27:48 - INFO - __main__ - Cumulative validation average loss is 2.2709394125267863\n",
      "07/27/2023 19:27:48 - INFO - __main__ - Per validation step average loss is 0.1346093863248825\n",
      "07/27/2023 19:27:48 - INFO - __main__ - Cumulative validation average loss is 2.405548798851669\n",
      "07/27/2023 19:27:49 - INFO - __main__ - Per validation step average loss is 0.4793609082698822\n",
      "07/27/2023 19:27:49 - INFO - __main__ - Cumulative validation average loss is 2.884909707121551\n",
      "07/27/2023 19:27:49 - INFO - __main__ - Per validation step average loss is 0.074932761490345\n",
      "07/27/2023 19:27:49 - INFO - __main__ - Cumulative validation average loss is 2.959842468611896\n",
      "07/27/2023 19:27:50 - INFO - __main__ - Per validation step average loss is 0.006485817953944206\n",
      "07/27/2023 19:27:50 - INFO - __main__ - Cumulative validation average loss is 2.9663282865658402\n",
      "07/27/2023 19:27:50 - INFO - __main__ - Per validation step average loss is 0.030971238389611244\n",
      "07/27/2023 19:27:50 - INFO - __main__ - Cumulative validation average loss is 2.9972995249554515\n",
      "07/27/2023 19:27:50 - INFO - __main__ - Per validation step average loss is 0.23030567169189453\n",
      "07/27/2023 19:27:50 - INFO - __main__ - Cumulative validation average loss is 3.227605196647346\n",
      "07/27/2023 19:27:51 - INFO - __main__ - Per validation step average loss is 0.11888768523931503\n",
      "07/27/2023 19:27:51 - INFO - __main__ - Cumulative validation average loss is 3.346492881886661\n",
      "07/27/2023 19:27:51 - INFO - __main__ - Per validation step average loss is 0.04113880917429924\n",
      "07/27/2023 19:27:51 - INFO - __main__ - Cumulative validation average loss is 3.3876316910609603\n",
      "07/27/2023 19:27:52 - INFO - __main__ - Per validation step average loss is 0.0138145936653018\n",
      "07/27/2023 19:27:52 - INFO - __main__ - Cumulative validation average loss is 3.401446284726262\n",
      "07/27/2023 19:27:52 - INFO - __main__ - Per validation step average loss is 0.05828843265771866\n",
      "07/27/2023 19:27:52 - INFO - __main__ - Cumulative validation average loss is 3.4597347173839808\n",
      "07/27/2023 19:27:53 - INFO - __main__ - Per validation step average loss is 0.014192866161465645\n",
      "07/27/2023 19:27:53 - INFO - __main__ - Cumulative validation average loss is 3.4739275835454464\n",
      "07/27/2023 19:27:53 - INFO - __main__ - Per validation step average loss is 0.08670073002576828\n",
      "07/27/2023 19:27:53 - INFO - __main__ - Cumulative validation average loss is 3.5606283135712147\n",
      "07/27/2023 19:27:53 - INFO - __main__ - Per validation step average loss is 0.005508412607014179\n",
      "07/27/2023 19:27:53 - INFO - __main__ - Cumulative validation average loss is 3.566136726178229\n",
      "07/27/2023 19:27:54 - INFO - __main__ - Per validation step average loss is 0.002864986192435026\n",
      "07/27/2023 19:27:54 - INFO - __main__ - Cumulative validation average loss is 3.569001712370664\n",
      "07/27/2023 19:27:54 - INFO - __main__ - Per validation step average loss is 0.001958006527274847\n",
      "07/27/2023 19:27:54 - INFO - __main__ - Cumulative validation average loss is 3.5709597188979387\n",
      "07/27/2023 19:27:55 - INFO - __main__ - Per validation step average loss is 0.1908935308456421\n",
      "07/27/2023 19:27:55 - INFO - __main__ - Cumulative validation average loss is 3.761853249743581\n",
      "07/27/2023 19:27:55 - INFO - __main__ - Per validation step average loss is 0.010529235005378723\n",
      "07/27/2023 19:27:55 - INFO - __main__ - Cumulative validation average loss is 3.7723824847489595\n",
      "07/27/2023 19:27:55 - INFO - __main__ - Per validation step average loss is 0.1680808812379837\n",
      "07/27/2023 19:27:55 - INFO - __main__ - Cumulative validation average loss is 3.9404633659869432\n",
      "07/27/2023 19:27:56 - INFO - __main__ - Per validation step average loss is 0.1638655662536621\n",
      "07/27/2023 19:27:56 - INFO - __main__ - Cumulative validation average loss is 4.104328932240605\n",
      "07/27/2023 19:27:56 - INFO - __main__ - Per validation step average loss is 0.11614631861448288\n",
      "07/27/2023 19:27:56 - INFO - __main__ - Cumulative validation average loss is 4.220475250855088\n",
      "07/27/2023 19:27:57 - INFO - __main__ - Per validation step average loss is 0.0027882098220288754\n",
      "07/27/2023 19:27:57 - INFO - __main__ - Cumulative validation average loss is 4.223263460677117\n",
      "07/27/2023 19:27:57 - INFO - __main__ - Per validation step average loss is 0.23257455229759216\n",
      "07/27/2023 19:27:57 - INFO - __main__ - Cumulative validation average loss is 4.455838012974709\n",
      "07/27/2023 19:27:57 - INFO - __main__ - Per validation step average loss is 0.22697553038597107\n",
      "07/27/2023 19:27:57 - INFO - __main__ - Cumulative validation average loss is 4.68281354336068\n",
      "07/27/2023 19:27:58 - INFO - __main__ - Per validation step average loss is 0.017882851883769035\n",
      "07/27/2023 19:27:58 - INFO - __main__ - Cumulative validation average loss is 4.700696395244449\n",
      "07/27/2023 19:27:58 - INFO - __main__ - Per validation step average loss is 0.024414867162704468\n",
      "07/27/2023 19:27:58 - INFO - __main__ - Cumulative validation average loss is 4.725111262407154\n",
      "07/27/2023 19:27:59 - INFO - __main__ - Per validation step average loss is 0.16895347833633423\n",
      "07/27/2023 19:27:59 - INFO - __main__ - Cumulative validation average loss is 4.894064740743488\n",
      "07/27/2023 19:27:59 - INFO - __main__ - Per validation step average loss is 0.5464804768562317\n",
      "07/27/2023 19:27:59 - INFO - __main__ - Cumulative validation average loss is 5.44054521759972\n",
      "07/27/2023 19:28:00 - INFO - __main__ - Per validation step average loss is 0.003222349099814892\n",
      "07/27/2023 19:28:00 - INFO - __main__ - Cumulative validation average loss is 5.443767566699535\n",
      "07/27/2023 19:28:00 - INFO - __main__ - Per validation step average loss is 0.23548951745033264\n",
      "07/27/2023 19:28:00 - INFO - __main__ - Cumulative validation average loss is 5.679257084149867\n",
      "07/27/2023 19:28:00 - INFO - __main__ - Per validation step average loss is 0.06286025792360306\n",
      "07/27/2023 19:28:00 - INFO - __main__ - Cumulative validation average loss is 5.74211734207347\n",
      "07/27/2023 19:28:01 - INFO - __main__ - Per validation step average loss is 0.002536097075790167\n",
      "07/27/2023 19:28:01 - INFO - __main__ - Cumulative validation average loss is 5.7446534391492605\n",
      "07/27/2023 19:28:01 - INFO - __main__ - Per validation step average loss is 0.015684500336647034\n",
      "07/27/2023 19:28:01 - INFO - __main__ - Cumulative validation average loss is 5.7603379394859076\n",
      "07/27/2023 19:28:02 - INFO - __main__ - Per validation step average loss is 0.2066681981086731\n",
      "07/27/2023 19:28:02 - INFO - __main__ - Cumulative validation average loss is 5.967006137594581\n",
      "07/27/2023 19:28:02 - INFO - __main__ - Per validation step average loss is 0.1411188840866089\n",
      "07/27/2023 19:28:02 - INFO - __main__ - Cumulative validation average loss is 6.1081250216811895\n",
      "07/27/2023 19:28:02 - INFO - __main__ - Per validation step average loss is 0.0039127059280872345\n",
      "07/27/2023 19:28:02 - INFO - __main__ - Cumulative validation average loss is 6.112037727609277\n",
      "07/27/2023 19:28:03 - INFO - __main__ - Per validation step average loss is 0.17828065156936646\n",
      "07/27/2023 19:28:03 - INFO - __main__ - Cumulative validation average loss is 6.290318379178643\n",
      "07/27/2023 19:28:03 - INFO - __main__ - Per validation step average loss is 0.0029698244761675596\n",
      "07/27/2023 19:28:03 - INFO - __main__ - Cumulative validation average loss is 6.293288203654811\n",
      "07/27/2023 19:28:04 - INFO - __main__ - Per validation step average loss is 0.0054136840626597404\n",
      "07/27/2023 19:28:04 - INFO - __main__ - Cumulative validation average loss is 6.2987018877174705\n",
      "07/27/2023 19:28:04 - INFO - __main__ - Per validation step average loss is 0.06767391413450241\n",
      "07/27/2023 19:28:04 - INFO - __main__ - Cumulative validation average loss is 6.366375801851973\n",
      "07/27/2023 19:28:05 - INFO - __main__ - Per validation step average loss is 0.03189057111740112\n",
      "07/27/2023 19:28:05 - INFO - __main__ - Cumulative validation average loss is 6.398266372969374\n",
      "07/27/2023 19:28:05 - INFO - __main__ - Per validation step average loss is 0.42384597659111023\n",
      "07/27/2023 19:28:05 - INFO - __main__ - Cumulative validation average loss is 6.822112349560484\n",
      "07/27/2023 19:28:05 - INFO - __main__ - Per validation step average loss is 0.14197777211666107\n",
      "07/27/2023 19:28:05 - INFO - __main__ - Cumulative validation average loss is 6.964090121677145\n",
      "07/27/2023 19:28:06 - INFO - __main__ - Per validation step average loss is 0.03575945645570755\n",
      "07/27/2023 19:28:06 - INFO - __main__ - Cumulative validation average loss is 6.999849578132853\n",
      "07/27/2023 19:28:06 - INFO - __main__ - Per validation step average loss is 0.07220804691314697\n",
      "07/27/2023 19:28:06 - INFO - __main__ - Cumulative validation average loss is 7.072057625046\n",
      "07/27/2023 19:28:07 - INFO - __main__ - Per validation step average loss is 0.0033070624340325594\n",
      "07/27/2023 19:28:07 - INFO - __main__ - Cumulative validation average loss is 7.075364687480032\n",
      "07/27/2023 19:28:07 - INFO - __main__ - Per validation step average loss is 0.002678689081221819\n",
      "07/27/2023 19:28:07 - INFO - __main__ - Cumulative validation average loss is 7.078043376561254\n",
      "07/27/2023 19:28:07 - INFO - __main__ - Per validation step average loss is 0.0019031151896342635\n",
      "07/27/2023 19:28:07 - INFO - __main__ - Cumulative validation average loss is 7.0799464917508885\n",
      "07/27/2023 19:28:08 - INFO - __main__ - Per validation step average loss is 0.07312114536762238\n",
      "07/27/2023 19:28:08 - INFO - __main__ - Cumulative validation average loss is 7.153067637118511\n",
      "07/27/2023 19:28:08 - INFO - __main__ - Per validation step average loss is 0.005265244282782078\n",
      "07/27/2023 19:28:08 - INFO - __main__ - Cumulative validation average loss is 7.158332881401293\n",
      "07/27/2023 19:28:09 - INFO - __main__ - Per validation step average loss is 0.16603714227676392\n",
      "07/27/2023 19:28:09 - INFO - __main__ - Cumulative validation average loss is 7.324370023678057\n",
      "07/27/2023 19:28:09 - INFO - __main__ - Per validation step average loss is 0.1516493856906891\n",
      "07/27/2023 19:28:09 - INFO - __main__ - Cumulative validation average loss is 7.476019409368746\n",
      "07/27/2023 19:28:10 - INFO - __main__ - Per validation step average loss is 0.004828704986721277\n",
      "07/27/2023 19:28:10 - INFO - __main__ - Cumulative validation average loss is 7.480848114355467\n",
      "07/27/2023 19:28:10 - INFO - __main__ - Per validation step average loss is 0.08357930928468704\n",
      "07/27/2023 19:28:10 - INFO - __main__ - Cumulative validation average loss is 7.564427423640154\n",
      "07/27/2023 19:28:11 - INFO - __main__ - Per validation step average loss is 0.020881660282611847\n",
      "07/27/2023 19:28:11 - INFO - __main__ - Cumulative validation average loss is 7.585309083922766\n",
      "07/27/2023 19:28:11 - INFO - __main__ - Average validation loss for Epoch 39 is 0.09601657068256667\n",
      "07/27/2023 19:28:11 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:29:08 - INFO - __main__ - Starting epoch 40\n",
      "07/27/2023 19:29:09 - INFO - __main__ - train loss is 0.2870291471481323\n",
      "Steps:  81%|▊| 12121/15000 [1:44:19<22:12:02, 27.76s/it, lr=0.000985, step_loss=07/27/2023 19:29:09 - INFO - __main__ - train loss is 0.3321157246828079\n",
      "Steps:  81%|▊| 12122/15000 [1:44:20<15:39:27, 19.59s/it, lr=0.000985, step_loss=07/27/2023 19:29:10 - INFO - __main__ - train loss is 0.33417402766644955\n",
      "Steps:  81%|▊| 12123/15000 [1:44:20<11:04:45, 13.86s/it, lr=0.000985, step_loss=07/27/2023 19:29:10 - INFO - __main__ - train loss is 0.38039584271609783\n",
      "Steps:  81%|▊| 12124/15000 [1:44:21<7:52:40,  9.86s/it, lr=0.000985, step_loss=007/27/2023 19:29:11 - INFO - __main__ - train loss is 0.4190779011696577\n",
      "Steps:  81%|▊| 12125/15000 [1:44:21<5:38:03,  7.06s/it, lr=0.000985, step_loss=007/27/2023 19:29:11 - INFO - __main__ - train loss is 0.9940001051872969\n",
      "Steps:  81%|▊| 12126/15000 [1:44:22<4:03:56,  5.09s/it, lr=0.000985, step_loss=007/27/2023 19:29:12 - INFO - __main__ - train loss is 1.0328597854822874\n",
      "Steps:  81%|▊| 12127/15000 [1:44:22<2:58:01,  3.72s/it, lr=0.000985, step_loss=007/27/2023 19:29:12 - INFO - __main__ - train loss is 1.3059175442904234\n",
      "Steps:  81%|▊| 12128/15000 [1:44:23<2:11:53,  2.76s/it, lr=0.000985, step_loss=007/27/2023 19:29:13 - INFO - __main__ - train loss is 1.3177637849003077\n",
      "Steps:  81%|▊| 12129/15000 [1:44:23<1:39:36,  2.08s/it, lr=0.000985, step_loss=007/27/2023 19:29:13 - INFO - __main__ - train loss is 1.3235283633694053\n",
      "Steps:  81%|▊| 12130/15000 [1:44:24<1:17:02,  1.61s/it, lr=0.000985, step_loss=007/27/2023 19:29:14 - INFO - __main__ - train loss is 1.3629800928756595\n",
      "Steps:  81%|▊| 12131/15000 [1:44:24<1:01:11,  1.28s/it, lr=0.000985, step_loss=007/27/2023 19:29:14 - INFO - __main__ - train loss is 1.4773779911920428\n",
      "Steps:  81%|▊| 12132/15000 [1:44:25<50:06,  1.05s/it, lr=0.000985, step_loss=0.107/27/2023 19:29:15 - INFO - __main__ - train loss is 1.4789086182136089\n",
      "Steps:  81%|▊| 12133/15000 [1:44:25<42:18,  1.13it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:15 - INFO - __main__ - train loss is 1.4942913150880486\n",
      "Steps:  81%|▊| 12134/15000 [1:44:26<36:54,  1.29it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:16 - INFO - __main__ - train loss is 1.7951595878694206\n",
      "Steps:  81%|▊| 12135/15000 [1:44:26<33:10,  1.44it/s, lr=0.000985, step_loss=0.307/27/2023 19:29:16 - INFO - __main__ - train loss is 2.1236619150731713\n",
      "Steps:  81%|▊| 12136/15000 [1:44:27<30:28,  1.57it/s, lr=0.000985, step_loss=0.307/27/2023 19:29:17 - INFO - __main__ - train loss is 2.729473034152761\n",
      "Steps:  81%|▊| 12137/15000 [1:44:27<28:46,  1.66it/s, lr=0.000985, step_loss=0.607/27/2023 19:29:17 - INFO - __main__ - train loss is 2.8273125833366066\n",
      "Steps:  81%|▊| 12138/15000 [1:44:28<27:26,  1.74it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:18 - INFO - __main__ - train loss is 3.272365356096998\n",
      "Steps:  81%|▊| 12139/15000 [1:44:28<26:40,  1.79it/s, lr=0.000985, step_loss=0.407/27/2023 19:29:18 - INFO - __main__ - train loss is 3.3510771489236504\n",
      "Steps:  81%|▊| 12140/15000 [1:44:29<26:12,  1.82it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:19 - INFO - __main__ - train loss is 3.530390272149816\n",
      "Steps:  81%|▊| 12141/15000 [1:44:29<25:39,  1.86it/s, lr=0.000985, step_loss=0.107/27/2023 19:29:19 - INFO - __main__ - train loss is 3.6597020274493843\n",
      "Steps:  81%|▊| 12142/15000 [1:44:30<25:09,  1.89it/s, lr=0.000985, step_loss=0.107/27/2023 19:29:20 - INFO - __main__ - train loss is 3.682676492491737\n",
      "Steps:  81%|▊| 12143/15000 [1:44:30<24:51,  1.92it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:21 - INFO - __main__ - train loss is 4.2484823449049145\n",
      "Steps:  81%|▊| 12144/15000 [1:44:31<24:40,  1.93it/s, lr=0.000985, step_loss=0.507/27/2023 19:29:21 - INFO - __main__ - train loss is 4.301483979681507\n",
      "Steps:  81%|▊| 12145/15000 [1:44:31<24:30,  1.94it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:22 - INFO - __main__ - train loss is 4.3240502460394055\n",
      "Steps:  81%|▊| 12146/15000 [1:44:32<24:23,  1.95it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:22 - INFO - __main__ - train loss is 4.418910099426284\n",
      "Steps:  81%|▊| 12147/15000 [1:44:32<24:22,  1.95it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:23 - INFO - __main__ - train loss is 4.4213748902548105\n",
      "Steps:  81%|▊| 12148/15000 [1:44:33<24:16,  1.96it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:23 - INFO - __main__ - train loss is 4.442684757756069\n",
      "Steps:  81%|▊| 12149/15000 [1:44:33<24:15,  1.96it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:24 - INFO - __main__ - train loss is 4.444461272214539\n",
      "Steps:  81%|▊| 12150/15000 [1:44:34<24:15,  1.96it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:24 - INFO - __main__ - train loss is 4.529540994320996\n",
      "Steps:  81%|▊| 12151/15000 [1:44:34<24:14,  1.96it/s, lr=0.000985, step_loss=0.007/27/2023 19:29:25 - INFO - __main__ - train loss is 4.778962382231839\n",
      "Steps:  81%|▊| 12152/15000 [1:44:35<24:09,  1.97it/s, lr=0.000984, step_loss=0.207/27/2023 19:29:25 - INFO - __main__ - train loss is 4.7929960183100775\n",
      "Steps:  81%|▊| 12153/15000 [1:44:35<24:07,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:26 - INFO - __main__ - train loss is 5.09067299880553\n",
      "Steps:  81%|▊| 12154/15000 [1:44:36<24:10,  1.96it/s, lr=0.000984, step_loss=0.207/27/2023 19:29:26 - INFO - __main__ - train loss is 5.096377220121212\n",
      "Steps:  81%|▊| 12155/15000 [1:44:36<24:10,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:27 - INFO - __main__ - train loss is 5.201266702380963\n",
      "Steps:  81%|▊| 12156/15000 [1:44:37<24:09,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:27 - INFO - __main__ - train loss is 5.216071847942658\n",
      "Steps:  81%|▊| 12157/15000 [1:44:37<24:14,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:28 - INFO - __main__ - train loss is 5.391174454358406\n",
      "Steps:  81%|▊| 12158/15000 [1:44:38<24:18,  1.95it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:28 - INFO - __main__ - train loss is 5.449455764261074\n",
      "Steps:  81%|▊| 12159/15000 [1:44:38<24:19,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:29 - INFO - __main__ - train loss is 5.4722634927602485\n",
      "Steps:  81%|▊| 12160/15000 [1:44:39<24:24,  1.94it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:29 - INFO - __main__ - train loss is 5.529741987702437\n",
      "Steps:  81%|▊| 12161/15000 [1:44:40<24:29,  1.93it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:30 - INFO - __main__ - train loss is 5.61920309078414\n",
      "Steps:  81%|▊| 12162/15000 [1:44:40<24:35,  1.92it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:30 - INFO - __main__ - train loss is 5.636124774930067\n",
      "Steps:  81%|▊| 12163/15000 [1:44:41<24:22,  1.94it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:31 - INFO - __main__ - train loss is 5.897188082453795\n",
      "Steps:  81%|▊| 12164/15000 [1:44:41<24:15,  1.95it/s, lr=0.000984, step_loss=0.207/27/2023 19:29:31 - INFO - __main__ - train loss is 6.033610299346037\n",
      "Steps:  81%|▊| 12165/15000 [1:44:42<24:11,  1.95it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:32 - INFO - __main__ - train loss is 6.036228250828572\n",
      "Steps:  81%|▊| 12166/15000 [1:44:42<24:06,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:32 - INFO - __main__ - train loss is 6.525762271252461\n",
      "Steps:  81%|▊| 12167/15000 [1:44:43<24:09,  1.96it/s, lr=0.000984, step_loss=0.407/27/2023 19:29:33 - INFO - __main__ - train loss is 6.531330062192865\n",
      "Steps:  81%|▊| 12168/15000 [1:44:43<24:11,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:33 - INFO - __main__ - train loss is 6.536557489191182\n",
      "Steps:  81%|▊| 12169/15000 [1:44:44<24:04,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:34 - INFO - __main__ - train loss is 6.557533302460797\n",
      "Steps:  81%|▊| 12170/15000 [1:44:44<24:05,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:34 - INFO - __main__ - train loss is 6.662693553720601\n",
      "Steps:  81%|▊| 12171/15000 [1:44:45<24:11,  1.95it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:35 - INFO - __main__ - train loss is 6.875644349609502\n",
      "Steps:  81%|▊| 12172/15000 [1:44:45<24:12,  1.95it/s, lr=0.000984, step_loss=0.207/27/2023 19:29:35 - INFO - __main__ - train loss is 6.948476308141835\n",
      "Steps:  81%|▊| 12173/15000 [1:44:46<24:07,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:36 - INFO - __main__ - train loss is 7.145067059551366\n",
      "Steps:  81%|▊| 12174/15000 [1:44:46<24:02,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:36 - INFO - __main__ - train loss is 7.4672532613622025\n",
      "Steps:  81%|▊| 12175/15000 [1:44:47<24:02,  1.96it/s, lr=0.000984, step_loss=0.307/27/2023 19:29:37 - INFO - __main__ - train loss is 7.479108427767642\n",
      "Steps:  81%|▊| 12176/15000 [1:44:47<24:00,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:37 - INFO - __main__ - train loss is 7.48718264058698\n",
      "Steps:  81%|▊| 12177/15000 [1:44:48<24:00,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:38 - INFO - __main__ - train loss is 7.588463292573579\n",
      "Steps:  81%|▊| 12178/15000 [1:44:48<23:58,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:38 - INFO - __main__ - train loss is 7.597945148241706\n",
      "Steps:  81%|▊| 12179/15000 [1:44:49<23:58,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:39 - INFO - __main__ - train loss is 7.888791853678413\n",
      "Steps:  81%|▊| 12180/15000 [1:44:49<23:56,  1.96it/s, lr=0.000984, step_loss=0.207/27/2023 19:29:39 - INFO - __main__ - train loss is 8.505965763819404\n",
      "Steps:  81%|▊| 12181/15000 [1:44:50<23:55,  1.96it/s, lr=0.000984, step_loss=0.607/27/2023 19:29:40 - INFO - __main__ - train loss is 8.513154334505089\n",
      "Steps:  81%|▊| 12182/15000 [1:44:50<23:53,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:40 - INFO - __main__ - train loss is 8.566252260585316\n",
      "Steps:  81%|▊| 12183/15000 [1:44:51<23:55,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:41 - INFO - __main__ - train loss is 8.959359615226276\n",
      "Steps:  81%|▊| 12184/15000 [1:44:51<23:58,  1.96it/s, lr=0.000984, step_loss=0.307/27/2023 19:29:41 - INFO - __main__ - train loss is 9.08704757608939\n",
      "Steps:  81%|▊| 12185/15000 [1:44:52<23:59,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:42 - INFO - __main__ - train loss is 9.126442446489818\n",
      "Steps:  81%|▊| 12186/15000 [1:44:52<23:59,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:42 - INFO - __main__ - train loss is 9.13834275782574\n",
      "Steps:  81%|▊| 12187/15000 [1:44:53<23:58,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:43 - INFO - __main__ - train loss is 9.982739825849421\n",
      "Steps:  81%|▊| 12188/15000 [1:44:53<23:55,  1.96it/s, lr=0.000984, step_loss=0.807/27/2023 19:29:43 - INFO - __main__ - train loss is 10.184854109887965\n",
      "Steps:  81%|▊| 12189/15000 [1:44:54<23:38,  1.98it/s, lr=0.000984, step_loss=0.207/27/2023 19:29:44 - INFO - __main__ - train loss is 10.253309947554953\n",
      "Steps:  81%|▊| 12190/15000 [1:44:54<23:46,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:45 - INFO - __main__ - train loss is 10.84111664921511\n",
      "Steps:  81%|▊| 12191/15000 [1:44:55<23:47,  1.97it/s, lr=0.000984, step_loss=0.507/27/2023 19:29:45 - INFO - __main__ - train loss is 11.022806597058661\n",
      "Steps:  81%|▊| 12192/15000 [1:44:55<23:43,  1.97it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:46 - INFO - __main__ - train loss is 11.745968890492804\n",
      "Steps:  81%|▊| 12193/15000 [1:44:56<23:41,  1.97it/s, lr=0.000984, step_loss=0.707/27/2023 19:29:46 - INFO - __main__ - train loss is 11.818879802827723\n",
      "Steps:  81%|▊| 12194/15000 [1:44:56<23:44,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:47 - INFO - __main__ - train loss is 11.82107221300248\n",
      "Steps:  81%|▊| 12195/15000 [1:44:57<23:48,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:47 - INFO - __main__ - train loss is 11.906627311953343\n",
      "Steps:  81%|▊| 12196/15000 [1:44:57<23:48,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:48 - INFO - __main__ - train loss is 12.046038254746236\n",
      "Steps:  81%|▊| 12197/15000 [1:44:58<23:49,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:48 - INFO - __main__ - train loss is 12.67450283432845\n",
      "Steps:  81%|▊| 12198/15000 [1:44:58<23:51,  1.96it/s, lr=0.000984, step_loss=0.607/27/2023 19:29:49 - INFO - __main__ - train loss is 12.68798648531083\n",
      "Steps:  81%|▊| 12199/15000 [1:44:59<23:48,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:49 - INFO - __main__ - train loss is 12.849835179396905\n",
      "Steps:  81%|▊| 12200/15000 [1:44:59<23:50,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:50 - INFO - __main__ - train loss is 12.937812342890538\n",
      "Steps:  81%|▊| 12201/15000 [1:45:00<23:46,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:50 - INFO - __main__ - train loss is 12.952439235174097\n",
      "Steps:  81%|▊| 12202/15000 [1:45:00<23:50,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:51 - INFO - __main__ - train loss is 13.047235788428225\n",
      "Steps:  81%|▊| 12203/15000 [1:45:01<23:55,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:51 - INFO - __main__ - train loss is 13.088812360190786\n",
      "Steps:  81%|▊| 12204/15000 [1:45:01<23:53,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:52 - INFO - __main__ - train loss is 13.092503875610419\n",
      "Steps:  81%|▊| 12205/15000 [1:45:02<23:54,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:52 - INFO - __main__ - train loss is 13.108415644732304\n",
      "Steps:  81%|▊| 12206/15000 [1:45:02<23:53,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:53 - INFO - __main__ - train loss is 13.221543867257424\n",
      "Steps:  81%|▊| 12207/15000 [1:45:03<23:50,  1.95it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:53 - INFO - __main__ - train loss is 13.546284455922432\n",
      "Steps:  81%|▊| 12208/15000 [1:45:04<23:46,  1.96it/s, lr=0.000984, step_loss=0.307/27/2023 19:29:54 - INFO - __main__ - train loss is 13.558092454564758\n",
      "Steps:  81%|▊| 12209/15000 [1:45:04<23:50,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:54 - INFO - __main__ - train loss is 13.571347052347846\n",
      "Steps:  81%|▊| 12210/15000 [1:45:05<23:50,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:55 - INFO - __main__ - train loss is 13.950125211966224\n",
      "Steps:  81%|▊| 12211/15000 [1:45:05<23:47,  1.95it/s, lr=0.000984, step_loss=0.307/27/2023 19:29:55 - INFO - __main__ - train loss is 14.338737214100547\n",
      "Steps:  81%|▊| 12212/15000 [1:45:06<23:48,  1.95it/s, lr=0.000984, step_loss=0.307/27/2023 19:29:56 - INFO - __main__ - train loss is 15.184550905716605\n",
      "Steps:  81%|▊| 12213/15000 [1:45:06<23:47,  1.95it/s, lr=0.000984, step_loss=0.807/27/2023 19:29:56 - INFO - __main__ - train loss is 15.21213754650671\n",
      "Steps:  81%|▊| 12214/15000 [1:45:07<23:49,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:57 - INFO - __main__ - train loss is 15.214860688545741\n",
      "Steps:  81%|▊| 12215/15000 [1:45:07<23:50,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:57 - INFO - __main__ - train loss is 15.53197426686529\n",
      "Steps:  81%|▊| 12216/15000 [1:45:08<23:45,  1.95it/s, lr=0.000984, step_loss=0.307/27/2023 19:29:58 - INFO - __main__ - train loss is 16.068784664967097\n",
      "Steps:  81%|▊| 12217/15000 [1:45:08<23:43,  1.96it/s, lr=0.000984, step_loss=0.507/27/2023 19:29:58 - INFO - __main__ - train loss is 16.22306270489935\n",
      "Steps:  81%|▊| 12218/15000 [1:45:09<23:43,  1.95it/s, lr=0.000984, step_loss=0.107/27/2023 19:29:59 - INFO - __main__ - train loss is 16.225245683803223\n",
      "Steps:  81%|▊| 12219/15000 [1:45:09<23:45,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:29:59 - INFO - __main__ - train loss is 16.235224617063068\n",
      "Steps:  81%|▊| 12220/15000 [1:45:10<23:44,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:00 - INFO - __main__ - train loss is 16.335859571932815\n",
      "Steps:  81%|▊| 12221/15000 [1:45:10<23:42,  1.95it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:00 - INFO - __main__ - train loss is 16.353092669858597\n",
      "Steps:  81%|▊| 12222/15000 [1:45:11<23:43,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:01 - INFO - __main__ - train loss is 16.370330979465507\n",
      "Steps:  81%|▊| 12223/15000 [1:45:11<23:38,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:01 - INFO - __main__ - train loss is 16.51909827196505\n",
      "Steps:  81%|▊| 12224/15000 [1:45:12<23:37,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:02 - INFO - __main__ - train loss is 16.673357149004005\n",
      "Steps:  82%|▊| 12225/15000 [1:45:12<23:37,  1.96it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:02 - INFO - __main__ - train loss is 16.6980430012336\n",
      "Steps:  82%|▊| 12226/15000 [1:45:13<23:36,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:03 - INFO - __main__ - train loss is 16.707671546726488\n",
      "Steps:  82%|▊| 12227/15000 [1:45:13<24:41,  1.87it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:04 - INFO - __main__ - train loss is 16.751156860380433\n",
      "Steps:  82%|▊| 12228/15000 [1:45:14<25:20,  1.82it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:04 - INFO - __main__ - train loss is 17.223610573797487\n",
      "Steps:  82%|▊| 12229/15000 [1:45:14<25:00,  1.85it/s, lr=0.000984, step_loss=0.407/27/2023 19:30:05 - INFO - __main__ - train loss is 17.253380489884876\n",
      "Steps:  82%|▊| 12230/15000 [1:45:15<25:06,  1.84it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:05 - INFO - __main__ - train loss is 17.271160093485378\n",
      "Steps:  82%|▊| 12231/15000 [1:45:16<25:53,  1.78it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:06 - INFO - __main__ - train loss is 17.33283533656504\n",
      "Steps:  82%|▊| 12232/15000 [1:45:16<25:14,  1.83it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:06 - INFO - __main__ - train loss is 17.3343321896391\n",
      "Steps:  82%|▊| 12233/15000 [1:45:17<24:43,  1.86it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:07 - INFO - __main__ - train loss is 17.471260837395675\n",
      "Steps:  82%|▊| 12234/15000 [1:45:17<24:28,  1.88it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:07 - INFO - __main__ - train loss is 17.55207030393649\n",
      "Steps:  82%|▊| 12235/15000 [1:45:18<24:16,  1.90it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:08 - INFO - __main__ - train loss is 17.55875493318308\n",
      "Steps:  82%|▊| 12236/15000 [1:45:18<24:09,  1.91it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:08 - INFO - __main__ - train loss is 18.19687820703257\n",
      "Steps:  82%|▊| 12237/15000 [1:45:19<24:07,  1.91it/s, lr=0.000984, step_loss=0.607/27/2023 19:30:09 - INFO - __main__ - train loss is 18.56361289054621\n",
      "Steps:  82%|▊| 12238/15000 [1:45:19<24:05,  1.91it/s, lr=0.000984, step_loss=0.307/27/2023 19:30:09 - INFO - __main__ - train loss is 18.582426392589696\n",
      "Steps:  82%|▊| 12239/15000 [1:45:20<23:57,  1.92it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:10 - INFO - __main__ - train loss is 18.58464845234994\n",
      "Steps:  82%|▊| 12240/15000 [1:45:20<23:55,  1.92it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:10 - INFO - __main__ - train loss is 19.041334412642755\n",
      "Steps:  82%|▊| 12241/15000 [1:45:21<23:47,  1.93it/s, lr=0.000984, step_loss=0.407/27/2023 19:30:11 - INFO - __main__ - train loss is 19.060938600101508\n",
      "Steps:  82%|▊| 12242/15000 [1:45:21<23:40,  1.94it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:11 - INFO - __main__ - train loss is 19.125085848965682\n",
      "Steps:  82%|▊| 12243/15000 [1:45:22<23:39,  1.94it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:12 - INFO - __main__ - train loss is 19.21448609570507\n",
      "Steps:  82%|▊| 12244/15000 [1:45:22<23:35,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:12 - INFO - __main__ - train loss is 19.41363472084049\n",
      "Steps:  82%|▊| 12245/15000 [1:45:23<23:37,  1.94it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:13 - INFO - __main__ - train loss is 19.418182186898775\n",
      "Steps:  82%|▊| 12246/15000 [1:45:23<23:30,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:13 - INFO - __main__ - train loss is 19.428286498528905\n",
      "Steps:  82%|▊| 12247/15000 [1:45:24<23:33,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:14 - INFO - __main__ - train loss is 19.443492492777295\n",
      "Steps:  82%|▊| 12248/15000 [1:45:24<23:35,  1.94it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:15 - INFO - __main__ - train loss is 19.715182444197126\n",
      "Steps:  82%|▊| 12249/15000 [1:45:25<23:34,  1.95it/s, lr=0.000984, step_loss=0.207/27/2023 19:30:15 - INFO - __main__ - train loss is 19.721563741215505\n",
      "Steps:  82%|▊| 12250/15000 [1:45:25<23:33,  1.95it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:16 - INFO - __main__ - train loss is 19.823464348562993\n",
      "Steps:  82%|▊| 12251/15000 [1:45:26<23:32,  1.95it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:16 - INFO - __main__ - train loss is 20.222714021452703\n",
      "Steps:  82%|▊| 12252/15000 [1:45:26<23:22,  1.96it/s, lr=0.000984, step_loss=0.307/27/2023 19:30:17 - INFO - __main__ - train loss is 20.284372448571958\n",
      "Steps:  82%|▊| 12253/15000 [1:45:27<23:20,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:17 - INFO - __main__ - train loss is 20.286158195813186\n",
      "Steps:  82%|▊| 12254/15000 [1:45:27<23:16,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:18 - INFO - __main__ - train loss is 20.384101218660362\n",
      "Steps:  82%|▊| 12255/15000 [1:45:28<23:13,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:18 - INFO - __main__ - train loss is 20.93050873943139\n",
      "Steps:  82%|▊| 12256/15000 [1:45:28<23:22,  1.96it/s, lr=0.000984, step_loss=0.507/27/2023 19:30:19 - INFO - __main__ - train loss is 21.31197724409867\n",
      "Steps:  82%|▊| 12257/15000 [1:45:29<23:21,  1.96it/s, lr=0.000984, step_loss=0.307/27/2023 19:30:19 - INFO - __main__ - train loss is 21.32265421852935\n",
      "Steps:  82%|▊| 12258/15000 [1:45:29<23:19,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:20 - INFO - __main__ - train loss is 21.347057850216515\n",
      "Steps:  82%|▊| 12259/15000 [1:45:30<23:18,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:20 - INFO - __main__ - train loss is 21.682541878079064\n",
      "Steps:  82%|▊| 12260/15000 [1:45:30<23:20,  1.96it/s, lr=0.000984, step_loss=0.307/27/2023 19:30:21 - INFO - __main__ - train loss is 21.686006207135506\n",
      "Steps:  82%|▊| 12261/15000 [1:45:31<23:16,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:21 - INFO - __main__ - train loss is 21.976509589818306\n",
      "Steps:  82%|▊| 12262/15000 [1:45:31<23:14,  1.96it/s, lr=0.000984, step_loss=0.207/27/2023 19:30:22 - INFO - __main__ - train loss is 22.04189225670416\n",
      "Steps:  82%|▊| 12263/15000 [1:45:32<23:13,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:22 - INFO - __main__ - train loss is 22.0665417854907\n",
      "Steps:  82%|▊| 12264/15000 [1:45:32<23:09,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:23 - INFO - __main__ - train loss is 22.08662549976725\n",
      "Steps:  82%|▊| 12265/15000 [1:45:33<23:05,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:23 - INFO - __main__ - train loss is 22.094004096579738\n",
      "Steps:  82%|▊| 12266/15000 [1:45:33<23:05,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:24 - INFO - __main__ - train loss is 22.180794434738345\n",
      "Steps:  82%|▊| 12267/15000 [1:45:34<23:17,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:24 - INFO - __main__ - train loss is 22.510205136728473\n",
      "Steps:  82%|▊| 12268/15000 [1:45:35<23:14,  1.96it/s, lr=0.000984, step_loss=0.307/27/2023 19:30:25 - INFO - __main__ - train loss is 22.78824605245609\n",
      "Steps:  82%|▊| 12269/15000 [1:45:35<23:14,  1.96it/s, lr=0.000984, step_loss=0.207/27/2023 19:30:25 - INFO - __main__ - train loss is 22.809908526134677\n",
      "Steps:  82%|▊| 12270/15000 [1:45:36<23:14,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:26 - INFO - __main__ - train loss is 22.875567944836803\n",
      "Steps:  82%|▊| 12271/15000 [1:45:36<23:10,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:26 - INFO - __main__ - train loss is 22.894196068984456\n",
      "Steps:  82%|▊| 12272/15000 [1:45:37<23:11,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:27 - INFO - __main__ - train loss is 22.90074614447076\n",
      "Steps:  82%|▊| 12273/15000 [1:45:37<23:07,  1.97it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:27 - INFO - __main__ - train loss is 22.923917586100288\n",
      "Steps:  82%|▊| 12274/15000 [1:45:38<23:09,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:28 - INFO - __main__ - train loss is 22.943962177378125\n",
      "Steps:  82%|▊| 12275/15000 [1:45:38<23:13,  1.96it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:28 - INFO - __main__ - train loss is 22.96218927029986\n",
      "Steps:  82%|▊| 12276/15000 [1:45:39<23:21,  1.94it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:29 - INFO - __main__ - train loss is 23.050394101184793\n",
      "Steps:  82%|▊| 12277/15000 [1:45:39<23:33,  1.93it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:29 - INFO - __main__ - train loss is 23.427355958265252\n",
      "Steps:  82%|▊| 12278/15000 [1:45:40<23:29,  1.93it/s, lr=0.000984, step_loss=0.307/27/2023 19:30:30 - INFO - __main__ - train loss is 23.450210208189674\n",
      "Steps:  82%|▊| 12279/15000 [1:45:40<23:30,  1.93it/s, lr=0.000984, step_loss=0.007/27/2023 19:30:30 - INFO - __main__ - train loss is 23.76229202200193\n",
      "Steps:  82%|▊| 12280/15000 [1:45:41<23:31,  1.93it/s, lr=0.000984, step_loss=0.307/27/2023 19:30:31 - INFO - __main__ - train loss is 23.949417049181648\n",
      "Steps:  82%|▊| 12281/15000 [1:45:41<23:32,  1.93it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:31 - INFO - __main__ - train loss is 24.181334594381042\n",
      "Steps:  82%|▊| 12282/15000 [1:45:42<23:30,  1.93it/s, lr=0.000984, step_loss=0.207/27/2023 19:30:32 - INFO - __main__ - train loss is 24.296101311338134\n",
      "Steps:  82%|▊| 12283/15000 [1:45:42<23:33,  1.92it/s, lr=0.000984, step_loss=0.107/27/2023 19:30:32 - INFO - __main__ - train loss is 24.528488764655776\n",
      "Steps:  82%|▊| 12284/15000 [1:45:43<23:28,  1.93it/s, lr=0.000983, step_loss=0.207/27/2023 19:30:33 - INFO - __main__ - train loss is 24.68216897000093\n",
      "Steps:  82%|▊| 12285/15000 [1:45:43<23:39,  1.91it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:34 - INFO - __main__ - train loss is 24.68372266564984\n",
      "Steps:  82%|▊| 12286/15000 [1:45:44<23:35,  1.92it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:34 - INFO - __main__ - train loss is 25.273620417458005\n",
      "Steps:  82%|▊| 12287/15000 [1:45:44<23:41,  1.91it/s, lr=0.000983, step_loss=0.507/27/2023 19:30:35 - INFO - __main__ - train loss is 25.297278447193094\n",
      "Steps:  82%|▊| 12288/15000 [1:45:45<23:37,  1.91it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:35 - INFO - __main__ - train loss is 25.519559620064683\n",
      "Steps:  82%|▊| 12289/15000 [1:45:45<23:26,  1.93it/s, lr=0.000983, step_loss=0.207/27/2023 19:30:36 - INFO - __main__ - train loss is 25.65944655064959\n",
      "Steps:  82%|▊| 12290/15000 [1:45:46<23:21,  1.93it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:36 - INFO - __main__ - train loss is 25.741573093575425\n",
      "Steps:  82%|▊| 12291/15000 [1:45:46<23:16,  1.94it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:37 - INFO - __main__ - train loss is 25.743302599177696\n",
      "Steps:  82%|▊| 12292/15000 [1:45:47<23:11,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:37 - INFO - __main__ - train loss is 25.752154216752388\n",
      "Steps:  82%|▊| 12293/15000 [1:45:47<23:06,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:38 - INFO - __main__ - train loss is 25.796385489986278\n",
      "Steps:  82%|▊| 12294/15000 [1:45:48<23:02,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:38 - INFO - __main__ - train loss is 25.991461448953487\n",
      "Steps:  82%|▊| 12295/15000 [1:45:48<23:02,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:39 - INFO - __main__ - train loss is 26.147984482930042\n",
      "Steps:  82%|▊| 12296/15000 [1:45:49<23:09,  1.95it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:39 - INFO - __main__ - train loss is 26.21706952212844\n",
      "Steps:  82%|▊| 12297/15000 [1:45:49<23:16,  1.94it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:40 - INFO - __main__ - train loss is 26.338864081189968\n",
      "Steps:  82%|▊| 12298/15000 [1:45:50<23:14,  1.94it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:40 - INFO - __main__ - train loss is 26.38350963278208\n",
      "Steps:  82%|▊| 12299/15000 [1:45:51<23:08,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:41 - INFO - __main__ - train loss is 26.385253034415655\n",
      "Steps:  82%|▊| 12300/15000 [1:45:51<22:59,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:41 - INFO - __main__ - train loss is 26.609115920844488\n",
      "Steps:  82%|▊| 12301/15000 [1:45:52<22:53,  1.96it/s, lr=0.000983, step_loss=0.207/27/2023 19:30:42 - INFO - __main__ - train loss is 26.646740987780504\n",
      "Steps:  82%|▊| 12302/15000 [1:45:52<22:53,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:42 - INFO - __main__ - train loss is 26.910571768763475\n",
      "Steps:  82%|▊| 12303/15000 [1:45:53<22:51,  1.97it/s, lr=0.000983, step_loss=0.207/27/2023 19:30:43 - INFO - __main__ - train loss is 27.417270257952623\n",
      "Steps:  82%|▊| 12304/15000 [1:45:53<22:51,  1.97it/s, lr=0.000983, step_loss=0.507/27/2023 19:30:43 - INFO - __main__ - train loss is 27.908442780259065\n",
      "Steps:  82%|▊| 12305/15000 [1:45:54<22:56,  1.96it/s, lr=0.000983, step_loss=0.407/27/2023 19:30:44 - INFO - __main__ - train loss is 27.920392587664537\n",
      "Steps:  82%|▊| 12306/15000 [1:45:54<22:55,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:44 - INFO - __main__ - train loss is 27.94731673959177\n",
      "Steps:  82%|▊| 12307/15000 [1:45:55<22:53,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:45 - INFO - __main__ - train loss is 28.48999640706461\n",
      "Steps:  82%|▊| 12308/15000 [1:45:55<22:52,  1.96it/s, lr=0.000983, step_loss=0.507/27/2023 19:30:45 - INFO - __main__ - train loss is 28.665605593356304\n",
      "Steps:  82%|▊| 12309/15000 [1:45:56<22:52,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:46 - INFO - __main__ - train loss is 28.724742181482725\n",
      "Steps:  82%|▊| 12310/15000 [1:45:56<22:53,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:46 - INFO - __main__ - train loss is 28.746288105729036\n",
      "Steps:  82%|▊| 12311/15000 [1:45:57<22:52,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:47 - INFO - __main__ - train loss is 28.751641898299567\n",
      "Steps:  82%|▊| 12312/15000 [1:45:57<22:53,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:47 - INFO - __main__ - train loss is 28.8417296995176\n",
      "Steps:  82%|▊| 12313/15000 [1:45:58<22:50,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:48 - INFO - __main__ - train loss is 29.100757597829215\n",
      "Steps:  82%|▊| 12314/15000 [1:45:58<22:48,  1.96it/s, lr=0.000983, step_loss=0.207/27/2023 19:30:48 - INFO - __main__ - train loss is 29.72118514671456\n",
      "Steps:  82%|▊| 12315/15000 [1:45:59<22:43,  1.97it/s, lr=0.000983, step_loss=0.607/27/2023 19:30:49 - INFO - __main__ - train loss is 29.96713183715474\n",
      "Steps:  82%|▊| 12316/15000 [1:45:59<22:45,  1.97it/s, lr=0.000983, step_loss=0.207/27/2023 19:30:49 - INFO - __main__ - train loss is 30.161793648148887\n",
      "Steps:  82%|▊| 12317/15000 [1:46:00<22:49,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:50 - INFO - __main__ - train loss is 30.16367222275585\n",
      "Steps:  82%|▊| 12318/15000 [1:46:00<22:49,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:50 - INFO - __main__ - train loss is 30.52592988219112\n",
      "Steps:  82%|▊| 12319/15000 [1:46:01<22:47,  1.96it/s, lr=0.000983, step_loss=0.307/27/2023 19:30:51 - INFO - __main__ - train loss is 31.002606286667287\n",
      "Steps:  82%|▊| 12320/15000 [1:46:01<22:42,  1.97it/s, lr=0.000983, step_loss=0.407/27/2023 19:30:51 - INFO - __main__ - train loss is 31.014022811315954\n",
      "Steps:  82%|▊| 12321/15000 [1:46:02<22:41,  1.97it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:52 - INFO - __main__ - train loss is 31.078917323611677\n",
      "Steps:  82%|▊| 12322/15000 [1:46:02<22:38,  1.97it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:52 - INFO - __main__ - train loss is 31.096331228502095\n",
      "Steps:  82%|▊| 12323/15000 [1:46:03<22:40,  1.97it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:53 - INFO - __main__ - train loss is 31.17518459726125\n",
      "Steps:  82%|▊| 12324/15000 [1:46:03<22:40,  1.97it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:53 - INFO - __main__ - train loss is 31.190030720084906\n",
      "Steps:  82%|▊| 12325/15000 [1:46:04<22:31,  1.98it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:54 - INFO - __main__ - train loss is 31.229355324059725\n",
      "Steps:  82%|▊| 12326/15000 [1:46:04<22:29,  1.98it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:54 - INFO - __main__ - train loss is 31.268508456647396\n",
      "Steps:  82%|▊| 12327/15000 [1:46:05<22:30,  1.98it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:55 - INFO - __main__ - train loss is 31.290406780317426\n",
      "Steps:  82%|▊| 12328/15000 [1:46:05<22:41,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:55 - INFO - __main__ - train loss is 31.323672084137797\n",
      "Steps:  82%|▊| 12329/15000 [1:46:06<22:50,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:56 - INFO - __main__ - train loss is 31.841199247166514\n",
      "Steps:  82%|▊| 12330/15000 [1:46:06<22:45,  1.95it/s, lr=0.000983, step_loss=0.507/27/2023 19:30:56 - INFO - __main__ - train loss is 31.842778550228104\n",
      "Steps:  82%|▊| 12331/15000 [1:46:07<22:47,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:57 - INFO - __main__ - train loss is 31.87212343676947\n",
      "Steps:  82%|▊| 12332/15000 [1:46:08<25:09,  1.77it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:58 - INFO - __main__ - train loss is 31.89562744065188\n",
      "Steps:  82%|▊| 12333/15000 [1:46:08<25:12,  1.76it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:58 - INFO - __main__ - train loss is 32.06705698533915\n",
      "Steps:  82%|▊| 12334/15000 [1:46:09<24:15,  1.83it/s, lr=0.000983, step_loss=0.107/27/2023 19:30:59 - INFO - __main__ - train loss is 32.073245293227956\n",
      "Steps:  82%|▊| 12335/15000 [1:46:09<23:55,  1.86it/s, lr=0.000983, step_loss=0.007/27/2023 19:30:59 - INFO - __main__ - train loss is 32.14015506836586\n",
      "Steps:  82%|▊| 12336/15000 [1:46:10<24:08,  1.84it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:00 - INFO - __main__ - train loss is 32.16701071592979\n",
      "Steps:  82%|▊| 12337/15000 [1:46:10<23:59,  1.85it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:00 - INFO - __main__ - train loss is 32.372203848091885\n",
      "Steps:  82%|▊| 12338/15000 [1:46:11<23:50,  1.86it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:01 - INFO - __main__ - train loss is 32.40181616204791\n",
      "Steps:  82%|▊| 12339/15000 [1:46:11<23:31,  1.89it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:01 - INFO - __main__ - train loss is 32.40921147703193\n",
      "Steps:  82%|▊| 12340/15000 [1:46:12<23:21,  1.90it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:02 - INFO - __main__ - train loss is 32.54595022439025\n",
      "Steps:  82%|▊| 12341/15000 [1:46:12<23:06,  1.92it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:02 - INFO - __main__ - train loss is 32.57061196654104\n",
      "Steps:  82%|▊| 12342/15000 [1:46:13<22:57,  1.93it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:03 - INFO - __main__ - train loss is 32.57294075633399\n",
      "Steps:  82%|▊| 12343/15000 [1:46:13<22:47,  1.94it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:03 - INFO - __main__ - train loss is 32.769439180148765\n",
      "Steps:  82%|▊| 12344/15000 [1:46:14<22:46,  1.94it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:04 - INFO - __main__ - train loss is 32.86635019327514\n",
      "Steps:  82%|▊| 12345/15000 [1:46:14<22:40,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:04 - INFO - __main__ - train loss is 33.092528720153496\n",
      "Steps:  82%|▊| 12346/15000 [1:46:15<22:36,  1.96it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:05 - INFO - __main__ - train loss is 33.09579612943344\n",
      "Steps:  82%|▊| 12347/15000 [1:46:15<22:39,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:06 - INFO - __main__ - train loss is 33.11163820582442\n",
      "Steps:  82%|▊| 12348/15000 [1:46:16<22:36,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:06 - INFO - __main__ - train loss is 33.21141188102774\n",
      "Steps:  82%|▊| 12349/15000 [1:46:16<22:32,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:07 - INFO - __main__ - train loss is 33.24561126786284\n",
      "Steps:  82%|▊| 12350/15000 [1:46:17<22:30,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:07 - INFO - __main__ - train loss is 33.39120120066218\n",
      "Steps:  82%|▊| 12351/15000 [1:46:17<22:39,  1.95it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:08 - INFO - __main__ - train loss is 33.3946372801438\n",
      "Steps:  82%|▊| 12352/15000 [1:46:18<22:37,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:08 - INFO - __main__ - train loss is 33.399128968827426\n",
      "Steps:  82%|▊| 12353/15000 [1:46:18<22:35,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:09 - INFO - __main__ - train loss is 33.475141438655555\n",
      "Steps:  82%|▊| 12354/15000 [1:46:19<22:34,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:09 - INFO - __main__ - train loss is 33.562833609990776\n",
      "Steps:  82%|▊| 12355/15000 [1:46:19<22:30,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:10 - INFO - __main__ - train loss is 33.682914095930755\n",
      "Steps:  82%|▊| 12356/15000 [1:46:20<22:30,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:10 - INFO - __main__ - train loss is 33.959797638468444\n",
      "Steps:  82%|▊| 12357/15000 [1:46:20<22:38,  1.95it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:11 - INFO - __main__ - train loss is 34.1968087432906\n",
      "Steps:  82%|▊| 12358/15000 [1:46:21<22:35,  1.95it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:11 - INFO - __main__ - train loss is 34.20576848927885\n",
      "Steps:  82%|▊| 12359/15000 [1:46:21<22:36,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:12 - INFO - __main__ - train loss is 34.21257953252643\n",
      "Steps:  82%|▊| 12360/15000 [1:46:22<22:37,  1.94it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:12 - INFO - __main__ - train loss is 34.715511246584356\n",
      "Steps:  82%|▊| 12361/15000 [1:46:22<22:35,  1.95it/s, lr=0.000983, step_loss=0.507/27/2023 19:31:13 - INFO - __main__ - train loss is 34.84277720656246\n",
      "Steps:  82%|▊| 12362/15000 [1:46:23<22:33,  1.95it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:13 - INFO - __main__ - train loss is 34.8669106727466\n",
      "Steps:  82%|▊| 12363/15000 [1:46:24<22:28,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:14 - INFO - __main__ - train loss is 35.00392808672041\n",
      "Steps:  82%|▊| 12364/15000 [1:46:24<22:24,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:14 - INFO - __main__ - train loss is 35.034606714732945\n",
      "Steps:  82%|▊| 12365/15000 [1:46:25<22:24,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:15 - INFO - __main__ - train loss is 35.259503294713795\n",
      "Steps:  82%|▊| 12366/15000 [1:46:25<22:22,  1.96it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:15 - INFO - __main__ - train loss is 35.60629825759679\n",
      "Steps:  82%|▊| 12367/15000 [1:46:26<22:25,  1.96it/s, lr=0.000983, step_loss=0.307/27/2023 19:31:16 - INFO - __main__ - train loss is 35.63744531664997\n",
      "Steps:  82%|▊| 12368/15000 [1:46:26<22:25,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:16 - INFO - __main__ - train loss is 35.86428538057953\n",
      "Steps:  82%|▊| 12369/15000 [1:46:27<22:23,  1.96it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:17 - INFO - __main__ - train loss is 36.00673666689545\n",
      "Steps:  82%|▊| 12370/15000 [1:46:27<22:20,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:17 - INFO - __main__ - train loss is 36.43766975495964\n",
      "Steps:  82%|▊| 12371/15000 [1:46:28<22:20,  1.96it/s, lr=0.000983, step_loss=0.407/27/2023 19:31:18 - INFO - __main__ - train loss is 36.886004210449755\n",
      "Steps:  82%|▊| 12372/15000 [1:46:28<22:22,  1.96it/s, lr=0.000983, step_loss=0.407/27/2023 19:31:18 - INFO - __main__ - train loss is 36.917782195843756\n",
      "Steps:  82%|▊| 12373/15000 [1:46:29<22:22,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:19 - INFO - __main__ - train loss is 37.02685243729502\n",
      "Steps:  82%|▊| 12374/15000 [1:46:29<22:20,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:19 - INFO - __main__ - train loss is 37.24078592006117\n",
      "Steps:  82%|▊| 12375/15000 [1:46:30<22:22,  1.95it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:20 - INFO - __main__ - train loss is 37.249859970994294\n",
      "Steps:  83%|▊| 12376/15000 [1:46:30<22:20,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:20 - INFO - __main__ - train loss is 37.25306316814385\n",
      "Steps:  83%|▊| 12377/15000 [1:46:31<22:20,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:21 - INFO - __main__ - train loss is 37.30131875327788\n",
      "Steps:  83%|▊| 12378/15000 [1:46:31<22:19,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:21 - INFO - __main__ - train loss is 37.64669035724364\n",
      "Steps:  83%|▊| 12379/15000 [1:46:32<22:17,  1.96it/s, lr=0.000983, step_loss=0.307/27/2023 19:31:22 - INFO - __main__ - train loss is 37.648455303977244\n",
      "Steps:  83%|▊| 12380/15000 [1:46:32<22:16,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:22 - INFO - __main__ - train loss is 37.65108000661712\n",
      "Steps:  83%|▊| 12381/15000 [1:46:33<22:16,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:23 - INFO - __main__ - train loss is 38.141749406117015\n",
      "Steps:  83%|▊| 12382/15000 [1:46:33<22:17,  1.96it/s, lr=0.000983, step_loss=0.407/27/2023 19:31:23 - INFO - __main__ - train loss is 38.36233013297897\n",
      "Steps:  83%|▊| 12383/15000 [1:46:34<22:20,  1.95it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:24 - INFO - __main__ - train loss is 38.39812638040166\n",
      "Steps:  83%|▊| 12384/15000 [1:46:34<22:20,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:24 - INFO - __main__ - train loss is 38.65539701457601\n",
      "Steps:  83%|▊| 12385/15000 [1:46:35<22:15,  1.96it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:25 - INFO - __main__ - train loss is 38.79899867053609\n",
      "Steps:  83%|▊| 12386/15000 [1:46:35<22:15,  1.96it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:25 - INFO - __main__ - train loss is 38.803532614256255\n",
      "Steps:  83%|▊| 12387/15000 [1:46:36<22:13,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:26 - INFO - __main__ - train loss is 38.84209712489974\n",
      "Steps:  83%|▊| 12388/15000 [1:46:36<22:09,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:26 - INFO - __main__ - train loss is 39.4224311922444\n",
      "Steps:  83%|▊| 12389/15000 [1:46:37<22:10,  1.96it/s, lr=0.000983, step_loss=0.507/27/2023 19:31:27 - INFO - __main__ - train loss is 39.4379333833931\n",
      "Steps:  83%|▊| 12390/15000 [1:46:37<22:14,  1.96it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:28 - INFO - __main__ - train loss is 39.444471055525355\n",
      "Steps:  83%|▊| 12391/15000 [1:46:38<22:24,  1.94it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:28 - INFO - __main__ - train loss is 39.44716330466326\n",
      "Steps:  83%|▊| 12392/15000 [1:46:38<22:30,  1.93it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:29 - INFO - __main__ - train loss is 39.584992071962915\n",
      "Steps:  83%|▊| 12393/15000 [1:46:39<22:33,  1.93it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:29 - INFO - __main__ - train loss is 39.60522782092448\n",
      "Steps:  83%|▊| 12394/15000 [1:46:39<22:44,  1.91it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:30 - INFO - __main__ - train loss is 40.109582297853194\n",
      "Steps:  83%|▊| 12395/15000 [1:46:40<22:43,  1.91it/s, lr=0.000983, step_loss=0.507/27/2023 19:31:30 - INFO - __main__ - train loss is 40.116450331988744\n",
      "Steps:  83%|▊| 12396/15000 [1:46:40<22:41,  1.91it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:31 - INFO - __main__ - train loss is 40.296842552605085\n",
      "Steps:  83%|▊| 12397/15000 [1:46:41<22:43,  1.91it/s, lr=0.000983, step_loss=0.107/27/2023 19:31:31 - INFO - __main__ - train loss is 40.298029298428446\n",
      "Steps:  83%|▊| 12398/15000 [1:46:42<22:52,  1.90it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:32 - INFO - __main__ - train loss is 40.62090655649081\n",
      "Steps:  83%|▊| 12399/15000 [1:46:42<22:48,  1.90it/s, lr=0.000983, step_loss=0.307/27/2023 19:31:32 - INFO - __main__ - train loss is 40.62199667422101\n",
      "Steps:  83%|▊| 12400/15000 [1:46:43<22:42,  1.91it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:33 - INFO - __main__ - train loss is 40.63090078579262\n",
      "Steps:  83%|▊| 12401/15000 [1:46:43<22:49,  1.90it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:33 - INFO - __main__ - train loss is 41.1534805749543\n",
      "Steps:  83%|▊| 12402/15000 [1:46:44<22:54,  1.89it/s, lr=0.000983, step_loss=0.507/27/2023 19:31:34 - INFO - __main__ - train loss is 41.246303365100175\n",
      "Steps:  83%|▊| 12403/15000 [1:46:44<22:53,  1.89it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:34 - INFO - __main__ - train loss is 41.285029348451644\n",
      "Steps:  83%|▊| 12404/15000 [1:46:45<22:49,  1.90it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:35 - INFO - __main__ - train loss is 41.287000947166234\n",
      "Steps:  83%|▊| 12405/15000 [1:46:45<22:43,  1.90it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:35 - INFO - __main__ - train loss is 41.379966356325895\n",
      "Steps:  83%|▊| 12406/15000 [1:46:46<22:29,  1.92it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:36 - INFO - __main__ - train loss is 41.776559718418866\n",
      "Steps:  83%|▊| 12407/15000 [1:46:46<22:20,  1.93it/s, lr=0.000983, step_loss=0.307/27/2023 19:31:36 - INFO - __main__ - train loss is 41.78266262821853\n",
      "Steps:  83%|▊| 12408/15000 [1:46:47<22:13,  1.94it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:37 - INFO - __main__ - train loss is 41.815686067566276\n",
      "Steps:  83%|▊| 12409/15000 [1:46:47<22:07,  1.95it/s, lr=0.000983, step_loss=0.007/27/2023 19:31:37 - INFO - __main__ - train loss is 42.11422382853925\n",
      "Steps:  83%|▊| 12410/15000 [1:46:48<22:06,  1.95it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:38 - INFO - __main__ - train loss is 42.3776861038059\n",
      "Steps:  83%|▊| 12411/15000 [1:46:48<22:02,  1.96it/s, lr=0.000983, step_loss=0.207/27/2023 19:31:38 - INFO - __main__ - train loss is 42.46717522107065\n",
      "Steps:  83%|▊| 12412/15000 [1:46:49<22:06,  1.95it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:39 - INFO - __main__ - train loss is 42.50476302392781\n",
      "Steps:  83%|▊| 12413/15000 [1:46:49<22:17,  1.93it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:39 - INFO - __main__ - train loss is 42.57339365966618\n",
      "Steps:  83%|▊| 12414/15000 [1:46:50<22:18,  1.93it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:40 - INFO - __main__ - train loss is 42.57549443235621\n",
      "Steps:  83%|▊| 12415/15000 [1:46:50<22:10,  1.94it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:41 - INFO - __main__ - train loss is 42.73646354069933\n",
      "Steps:  83%|▊| 12416/15000 [1:46:51<22:06,  1.95it/s, lr=0.000982, step_loss=0.107/27/2023 19:31:41 - INFO - __main__ - train loss is 42.741178875323385\n",
      "Steps:  83%|▊| 12417/15000 [1:46:51<22:11,  1.94it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:42 - INFO - __main__ - train loss is 42.7567973411642\n",
      "Steps:  83%|▊| 12418/15000 [1:46:52<22:06,  1.95it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:42 - INFO - __main__ - train loss is 43.116131452377886\n",
      "Steps:  83%|▊| 12419/15000 [1:46:52<22:02,  1.95it/s, lr=0.000982, step_loss=0.307/27/2023 19:31:43 - INFO - __main__ - train loss is 43.209460710641\n",
      "Steps:  83%|▊| 12420/15000 [1:46:53<22:01,  1.95it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:43 - INFO - __main__ - train loss is 43.40999571001157\n",
      "Steps:  83%|▊| 12421/15000 [1:46:53<21:57,  1.96it/s, lr=0.000982, step_loss=0.207/27/2023 19:31:44 - INFO - __main__ - train loss is 43.63291702186689\n",
      "Steps:  83%|▊| 12422/15000 [1:46:54<21:52,  1.96it/s, lr=0.000982, step_loss=0.207/27/2023 19:31:44 - INFO - __main__ - train loss is 43.65231749927625\n",
      "Steps:  83%|▊| 12423/15000 [1:46:55<25:14,  1.70it/s, lr=0.000982, step_loss=0.007/27/2023 19:31:45 - INFO - __main__ - Per validation step average loss is 0.09313994646072388\n",
      "07/27/2023 19:31:45 - INFO - __main__ - Cumulative validation average loss is 0.09313994646072388\n",
      "07/27/2023 19:31:46 - INFO - __main__ - Per validation step average loss is 0.01936763897538185\n",
      "07/27/2023 19:31:46 - INFO - __main__ - Cumulative validation average loss is 0.11250758543610573\n",
      "07/27/2023 19:31:46 - INFO - __main__ - Per validation step average loss is 0.2116779237985611\n",
      "07/27/2023 19:31:46 - INFO - __main__ - Cumulative validation average loss is 0.3241855092346668\n",
      "07/27/2023 19:31:47 - INFO - __main__ - Per validation step average loss is 0.3419346213340759\n",
      "07/27/2023 19:31:47 - INFO - __main__ - Cumulative validation average loss is 0.6661201305687428\n",
      "07/27/2023 19:31:47 - INFO - __main__ - Per validation step average loss is 0.27572840452194214\n",
      "07/27/2023 19:31:47 - INFO - __main__ - Cumulative validation average loss is 0.9418485350906849\n",
      "07/27/2023 19:31:48 - INFO - __main__ - Per validation step average loss is 0.2299501597881317\n",
      "07/27/2023 19:31:48 - INFO - __main__ - Cumulative validation average loss is 1.1717986948788166\n",
      "07/27/2023 19:31:48 - INFO - __main__ - Per validation step average loss is 0.014858830720186234\n",
      "07/27/2023 19:31:48 - INFO - __main__ - Cumulative validation average loss is 1.1866575255990028\n",
      "07/27/2023 19:31:48 - INFO - __main__ - Per validation step average loss is 0.12002597749233246\n",
      "07/27/2023 19:31:48 - INFO - __main__ - Cumulative validation average loss is 1.3066835030913353\n",
      "07/27/2023 19:31:49 - INFO - __main__ - Per validation step average loss is 0.021899934858083725\n",
      "07/27/2023 19:31:49 - INFO - __main__ - Cumulative validation average loss is 1.328583437949419\n",
      "07/27/2023 19:31:49 - INFO - __main__ - Per validation step average loss is 0.058784276247024536\n",
      "07/27/2023 19:31:49 - INFO - __main__ - Cumulative validation average loss is 1.3873677141964436\n",
      "07/27/2023 19:31:50 - INFO - __main__ - Per validation step average loss is 0.4652930796146393\n",
      "07/27/2023 19:31:50 - INFO - __main__ - Cumulative validation average loss is 1.8526607938110828\n",
      "07/27/2023 19:31:50 - INFO - __main__ - Per validation step average loss is 0.0029615554958581924\n",
      "07/27/2023 19:31:50 - INFO - __main__ - Cumulative validation average loss is 1.855622349306941\n",
      "07/27/2023 19:31:50 - INFO - __main__ - Per validation step average loss is 0.10117565095424652\n",
      "07/27/2023 19:31:50 - INFO - __main__ - Cumulative validation average loss is 1.9567980002611876\n",
      "07/27/2023 19:31:51 - INFO - __main__ - Per validation step average loss is 0.17616786062717438\n",
      "07/27/2023 19:31:51 - INFO - __main__ - Cumulative validation average loss is 2.132965860888362\n",
      "07/27/2023 19:31:51 - INFO - __main__ - Per validation step average loss is 0.0015301411040127277\n",
      "07/27/2023 19:31:51 - INFO - __main__ - Cumulative validation average loss is 2.1344960019923747\n",
      "07/27/2023 19:31:52 - INFO - __main__ - Per validation step average loss is 0.006621761247515678\n",
      "07/27/2023 19:31:52 - INFO - __main__ - Cumulative validation average loss is 2.1411177632398903\n",
      "07/27/2023 19:31:52 - INFO - __main__ - Per validation step average loss is 0.010620777495205402\n",
      "07/27/2023 19:31:52 - INFO - __main__ - Cumulative validation average loss is 2.1517385407350957\n",
      "07/27/2023 19:31:53 - INFO - __main__ - Per validation step average loss is 0.07910517603158951\n",
      "07/27/2023 19:31:53 - INFO - __main__ - Cumulative validation average loss is 2.2308437167666852\n",
      "07/27/2023 19:31:53 - INFO - __main__ - Per validation step average loss is 0.37790071964263916\n",
      "07/27/2023 19:31:53 - INFO - __main__ - Cumulative validation average loss is 2.6087444364093244\n",
      "07/27/2023 19:31:53 - INFO - __main__ - Per validation step average loss is 0.4055262804031372\n",
      "07/27/2023 19:31:53 - INFO - __main__ - Cumulative validation average loss is 3.0142707168124616\n",
      "07/27/2023 19:31:54 - INFO - __main__ - Per validation step average loss is 0.4544488787651062\n",
      "07/27/2023 19:31:54 - INFO - __main__ - Cumulative validation average loss is 3.468719595577568\n",
      "07/27/2023 19:31:54 - INFO - __main__ - Per validation step average loss is 0.028498953208327293\n",
      "07/27/2023 19:31:54 - INFO - __main__ - Cumulative validation average loss is 3.497218548785895\n",
      "07/27/2023 19:31:55 - INFO - __main__ - Per validation step average loss is 0.5434095859527588\n",
      "07/27/2023 19:31:55 - INFO - __main__ - Cumulative validation average loss is 4.040628134738654\n",
      "07/27/2023 19:31:55 - INFO - __main__ - Per validation step average loss is 0.050413258373737335\n",
      "07/27/2023 19:31:55 - INFO - __main__ - Cumulative validation average loss is 4.091041393112391\n",
      "07/27/2023 19:31:56 - INFO - __main__ - Per validation step average loss is 0.011994952335953712\n",
      "07/27/2023 19:31:56 - INFO - __main__ - Cumulative validation average loss is 4.103036345448345\n",
      "07/27/2023 19:31:56 - INFO - __main__ - Per validation step average loss is 0.535621702671051\n",
      "07/27/2023 19:31:56 - INFO - __main__ - Cumulative validation average loss is 4.638658048119396\n",
      "07/27/2023 19:31:56 - INFO - __main__ - Per validation step average loss is 0.011690947227180004\n",
      "07/27/2023 19:31:56 - INFO - __main__ - Cumulative validation average loss is 4.650348995346576\n",
      "07/27/2023 19:31:57 - INFO - __main__ - Per validation step average loss is 0.0037333983927965164\n",
      "07/27/2023 19:31:57 - INFO - __main__ - Cumulative validation average loss is 4.6540823937393725\n",
      "07/27/2023 19:31:57 - INFO - __main__ - Per validation step average loss is 0.22325065732002258\n",
      "07/27/2023 19:31:57 - INFO - __main__ - Cumulative validation average loss is 4.877333051059395\n",
      "07/27/2023 19:31:58 - INFO - __main__ - Per validation step average loss is 0.0801788792014122\n",
      "07/27/2023 19:31:58 - INFO - __main__ - Cumulative validation average loss is 4.957511930260807\n",
      "07/27/2023 19:31:58 - INFO - __main__ - Per validation step average loss is 0.003915503155440092\n",
      "07/27/2023 19:31:58 - INFO - __main__ - Cumulative validation average loss is 4.961427433416247\n",
      "07/27/2023 19:31:58 - INFO - __main__ - Per validation step average loss is 0.023688264191150665\n",
      "07/27/2023 19:31:58 - INFO - __main__ - Cumulative validation average loss is 4.985115697607398\n",
      "07/27/2023 19:31:59 - INFO - __main__ - Per validation step average loss is 0.009635692462325096\n",
      "07/27/2023 19:31:59 - INFO - __main__ - Cumulative validation average loss is 4.994751390069723\n",
      "07/27/2023 19:31:59 - INFO - __main__ - Per validation step average loss is 0.05403833091259003\n",
      "07/27/2023 19:31:59 - INFO - __main__ - Cumulative validation average loss is 5.048789720982313\n",
      "07/27/2023 19:32:00 - INFO - __main__ - Per validation step average loss is 0.008154946379363537\n",
      "07/27/2023 19:32:00 - INFO - __main__ - Cumulative validation average loss is 5.056944667361677\n",
      "07/27/2023 19:32:00 - INFO - __main__ - Per validation step average loss is 0.023180536925792694\n",
      "07/27/2023 19:32:00 - INFO - __main__ - Cumulative validation average loss is 5.080125204287469\n",
      "07/27/2023 19:32:01 - INFO - __main__ - Per validation step average loss is 0.40593957901000977\n",
      "07/27/2023 19:32:01 - INFO - __main__ - Cumulative validation average loss is 5.486064783297479\n",
      "07/27/2023 19:32:01 - INFO - __main__ - Per validation step average loss is 0.07695260643959045\n",
      "07/27/2023 19:32:01 - INFO - __main__ - Cumulative validation average loss is 5.56301738973707\n",
      "07/27/2023 19:32:01 - INFO - __main__ - Per validation step average loss is 0.4295603334903717\n",
      "07/27/2023 19:32:01 - INFO - __main__ - Cumulative validation average loss is 5.992577723227441\n",
      "07/27/2023 19:32:02 - INFO - __main__ - Per validation step average loss is 0.034064628183841705\n",
      "07/27/2023 19:32:02 - INFO - __main__ - Cumulative validation average loss is 6.026642351411283\n",
      "07/27/2023 19:32:02 - INFO - __main__ - Per validation step average loss is 0.060497038066387177\n",
      "07/27/2023 19:32:02 - INFO - __main__ - Cumulative validation average loss is 6.08713938947767\n",
      "07/27/2023 19:32:03 - INFO - __main__ - Per validation step average loss is 0.008307009004056454\n",
      "07/27/2023 19:32:03 - INFO - __main__ - Cumulative validation average loss is 6.095446398481727\n",
      "07/27/2023 19:32:03 - INFO - __main__ - Per validation step average loss is 0.0393565334379673\n",
      "07/27/2023 19:32:03 - INFO - __main__ - Cumulative validation average loss is 6.134802931919694\n",
      "07/27/2023 19:32:03 - INFO - __main__ - Per validation step average loss is 0.032817285507917404\n",
      "07/27/2023 19:32:03 - INFO - __main__ - Cumulative validation average loss is 6.167620217427611\n",
      "07/27/2023 19:32:04 - INFO - __main__ - Per validation step average loss is 0.1708386391401291\n",
      "07/27/2023 19:32:04 - INFO - __main__ - Cumulative validation average loss is 6.33845885656774\n",
      "07/27/2023 19:32:04 - INFO - __main__ - Per validation step average loss is 0.4756951332092285\n",
      "07/27/2023 19:32:04 - INFO - __main__ - Cumulative validation average loss is 6.814153989776969\n",
      "07/27/2023 19:32:05 - INFO - __main__ - Per validation step average loss is 0.06467655301094055\n",
      "07/27/2023 19:32:05 - INFO - __main__ - Cumulative validation average loss is 6.8788305427879095\n",
      "07/27/2023 19:32:05 - INFO - __main__ - Per validation step average loss is 0.3929405212402344\n",
      "07/27/2023 19:32:05 - INFO - __main__ - Cumulative validation average loss is 7.271771064028144\n",
      "07/27/2023 19:32:05 - INFO - __main__ - Per validation step average loss is 0.02071557380259037\n",
      "07/27/2023 19:32:05 - INFO - __main__ - Cumulative validation average loss is 7.292486637830734\n",
      "07/27/2023 19:32:06 - INFO - __main__ - Per validation step average loss is 0.07397317886352539\n",
      "07/27/2023 19:32:06 - INFO - __main__ - Cumulative validation average loss is 7.36645981669426\n",
      "07/27/2023 19:32:06 - INFO - __main__ - Per validation step average loss is 0.1687455028295517\n",
      "07/27/2023 19:32:06 - INFO - __main__ - Cumulative validation average loss is 7.535205319523811\n",
      "07/27/2023 19:32:07 - INFO - __main__ - Per validation step average loss is 0.21289275586605072\n",
      "07/27/2023 19:32:07 - INFO - __main__ - Cumulative validation average loss is 7.748098075389862\n",
      "07/27/2023 19:32:07 - INFO - __main__ - Per validation step average loss is 0.3758848309516907\n",
      "07/27/2023 19:32:07 - INFO - __main__ - Cumulative validation average loss is 8.123982906341553\n",
      "07/27/2023 19:32:08 - INFO - __main__ - Per validation step average loss is 0.5488464832305908\n",
      "07/27/2023 19:32:08 - INFO - __main__ - Cumulative validation average loss is 8.672829389572144\n",
      "07/27/2023 19:32:08 - INFO - __main__ - Per validation step average loss is 0.19364212453365326\n",
      "07/27/2023 19:32:08 - INFO - __main__ - Cumulative validation average loss is 8.866471514105797\n",
      "07/27/2023 19:32:08 - INFO - __main__ - Per validation step average loss is 0.02467619627714157\n",
      "07/27/2023 19:32:08 - INFO - __main__ - Cumulative validation average loss is 8.891147710382938\n",
      "07/27/2023 19:32:09 - INFO - __main__ - Per validation step average loss is 0.012949090451002121\n",
      "07/27/2023 19:32:09 - INFO - __main__ - Cumulative validation average loss is 8.90409680083394\n",
      "07/27/2023 19:32:09 - INFO - __main__ - Per validation step average loss is 0.02287263795733452\n",
      "07/27/2023 19:32:09 - INFO - __main__ - Cumulative validation average loss is 8.926969438791275\n",
      "07/27/2023 19:32:10 - INFO - __main__ - Per validation step average loss is 0.041745852679014206\n",
      "07/27/2023 19:32:10 - INFO - __main__ - Cumulative validation average loss is 8.96871529147029\n",
      "07/27/2023 19:32:10 - INFO - __main__ - Per validation step average loss is 0.0675591453909874\n",
      "07/27/2023 19:32:10 - INFO - __main__ - Cumulative validation average loss is 9.036274436861277\n",
      "07/27/2023 19:32:10 - INFO - __main__ - Per validation step average loss is 0.03688405081629753\n",
      "07/27/2023 19:32:10 - INFO - __main__ - Cumulative validation average loss is 9.073158487677574\n",
      "07/27/2023 19:32:11 - INFO - __main__ - Per validation step average loss is 0.2823607921600342\n",
      "07/27/2023 19:32:11 - INFO - __main__ - Cumulative validation average loss is 9.355519279837608\n",
      "07/27/2023 19:32:11 - INFO - __main__ - Per validation step average loss is 0.32310840487480164\n",
      "07/27/2023 19:32:11 - INFO - __main__ - Cumulative validation average loss is 9.67862768471241\n",
      "07/27/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.08918343484401703\n",
      "07/27/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 9.767811119556427\n",
      "07/27/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.0520637109875679\n",
      "07/27/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 9.819874830543995\n",
      "07/27/2023 19:32:13 - INFO - __main__ - Per validation step average loss is 0.1963736116886139\n",
      "07/27/2023 19:32:13 - INFO - __main__ - Cumulative validation average loss is 10.016248442232609\n",
      "07/27/2023 19:32:13 - INFO - __main__ - Per validation step average loss is 0.0013932237634435296\n",
      "07/27/2023 19:32:13 - INFO - __main__ - Cumulative validation average loss is 10.017641665996052\n",
      "07/27/2023 19:32:13 - INFO - __main__ - Per validation step average loss is 0.13165763020515442\n",
      "07/27/2023 19:32:13 - INFO - __main__ - Cumulative validation average loss is 10.149299296201207\n",
      "07/27/2023 19:32:14 - INFO - __main__ - Per validation step average loss is 0.037012889981269836\n",
      "07/27/2023 19:32:14 - INFO - __main__ - Cumulative validation average loss is 10.186312186182477\n",
      "07/27/2023 19:32:14 - INFO - __main__ - Per validation step average loss is 0.09678232669830322\n",
      "07/27/2023 19:32:14 - INFO - __main__ - Cumulative validation average loss is 10.28309451288078\n",
      "07/27/2023 19:32:15 - INFO - __main__ - Per validation step average loss is 0.0044066691771149635\n",
      "07/27/2023 19:32:15 - INFO - __main__ - Cumulative validation average loss is 10.287501182057895\n",
      "07/27/2023 19:32:15 - INFO - __main__ - Per validation step average loss is 0.004753396846354008\n",
      "07/27/2023 19:32:15 - INFO - __main__ - Cumulative validation average loss is 10.292254578904249\n",
      "07/27/2023 19:32:15 - INFO - __main__ - Per validation step average loss is 0.06047862023115158\n",
      "07/27/2023 19:32:15 - INFO - __main__ - Cumulative validation average loss is 10.3527331991354\n",
      "07/27/2023 19:32:16 - INFO - __main__ - Per validation step average loss is 0.02251129224896431\n",
      "07/27/2023 19:32:16 - INFO - __main__ - Cumulative validation average loss is 10.375244491384365\n",
      "07/27/2023 19:32:16 - INFO - __main__ - Per validation step average loss is 0.0236675888299942\n",
      "07/27/2023 19:32:16 - INFO - __main__ - Cumulative validation average loss is 10.398912080214359\n",
      "07/27/2023 19:32:17 - INFO - __main__ - Per validation step average loss is 0.5536178946495056\n",
      "07/27/2023 19:32:17 - INFO - __main__ - Cumulative validation average loss is 10.952529974863864\n",
      "07/27/2023 19:32:17 - INFO - __main__ - Per validation step average loss is 0.25804805755615234\n",
      "07/27/2023 19:32:17 - INFO - __main__ - Cumulative validation average loss is 11.210578032420017\n",
      "07/27/2023 19:32:18 - INFO - __main__ - Per validation step average loss is 0.025468356907367706\n",
      "07/27/2023 19:32:18 - INFO - __main__ - Cumulative validation average loss is 11.236046389327385\n",
      "07/27/2023 19:32:18 - INFO - __main__ - Per validation step average loss is 0.0210573673248291\n",
      "07/27/2023 19:32:18 - INFO - __main__ - Cumulative validation average loss is 11.257103756652214\n",
      "07/27/2023 19:32:18 - INFO - __main__ - Average validation loss for Epoch 40 is 0.14249498426142043\n",
      "07/27/2023 19:32:18 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 19:33:15 - INFO - __main__ - Starting epoch 41\n",
      "07/27/2023 19:33:16 - INFO - __main__ - train loss is 0.0059368242509663105\n",
      "Steps:  83%|▊| 12424/15000 [1:48:26<19:59:57, 27.95s/it, lr=0.000982, step_loss=07/27/2023 19:33:16 - INFO - __main__ - train loss is 0.2825016309507191\n",
      "Steps:  83%|▊| 12425/15000 [1:48:27<14:02:01, 19.62s/it, lr=0.000982, step_loss=07/27/2023 19:33:17 - INFO - __main__ - train loss is 0.29978393064811826\n",
      "Steps:  83%|▊| 12426/15000 [1:48:27<9:51:30, 13.79s/it, lr=0.000982, step_loss=007/27/2023 19:33:17 - INFO - __main__ - train loss is 0.309544010553509\n",
      "Steps:  83%|▊| 12427/15000 [1:48:27<6:56:14,  9.71s/it, lr=0.000982, step_loss=007/27/2023 19:33:17 - INFO - __main__ - train loss is 0.3140359311364591\n",
      "Steps:  83%|▊| 12428/15000 [1:48:27<4:53:34,  6.85s/it, lr=0.000982, step_loss=007/27/2023 19:33:17 - INFO - __main__ - train loss is 0.616301694419235\n",
      "Steps:  83%|▊| 12429/15000 [1:48:27<3:27:46,  4.85s/it, lr=0.000982, step_loss=007/27/2023 19:33:17 - INFO - __main__ - train loss is 0.6199708378408104\n",
      "Steps:  83%|▊| 12430/15000 [1:48:28<2:27:47,  3.45s/it, lr=0.000982, step_loss=007/27/2023 19:33:17 - INFO - __main__ - train loss is 0.6771843007300049\n",
      "Steps:  83%|▊| 12431/15000 [1:48:28<1:45:47,  2.47s/it, lr=0.000982, step_loss=007/27/2023 19:33:18 - INFO - __main__ - train loss is 0.7991702205035836\n",
      "Steps:  83%|▊| 12432/15000 [1:48:28<1:16:20,  1.78s/it, lr=0.000982, step_loss=007/27/2023 19:33:18 - INFO - __main__ - train loss is 0.9500010556075722\n",
      "Steps:  83%|▊| 12433/15000 [1:48:28<55:42,  1.30s/it, lr=0.000982, step_loss=0.107/27/2023 19:33:18 - INFO - __main__ - train loss is 0.9650575725827366\n",
      "Steps:  83%|▊| 12434/15000 [1:48:28<41:16,  1.04it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:18 - INFO - __main__ - train loss is 0.9664810554822907\n",
      "Steps:  83%|▊| 12435/15000 [1:48:28<31:10,  1.37it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:18 - INFO - __main__ - train loss is 1.4315165536245331\n",
      "Steps:  83%|▊| 12436/15000 [1:48:29<24:06,  1.77it/s, lr=0.000982, step_loss=0.407/27/2023 19:33:18 - INFO - __main__ - train loss is 1.7830683247884735\n",
      "Steps:  83%|▊| 12437/15000 [1:48:29<19:09,  2.23it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:19 - INFO - __main__ - train loss is 1.7921185049926862\n",
      "Steps:  83%|▊| 12438/15000 [1:48:29<15:43,  2.71it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:19 - INFO - __main__ - train loss is 1.8639729175483808\n",
      "Steps:  83%|▊| 12439/15000 [1:48:29<13:17,  3.21it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:19 - INFO - __main__ - train loss is 1.866134544252418\n",
      "Steps:  83%|▊| 12440/15000 [1:48:29<11:36,  3.68it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:19 - INFO - __main__ - train loss is 2.04448940360453\n",
      "Steps:  83%|▊| 12441/15000 [1:48:30<10:25,  4.09it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:19 - INFO - __main__ - train loss is 2.361705203889869\n",
      "Steps:  83%|▊| 12442/15000 [1:48:30<09:35,  4.45it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:20 - INFO - __main__ - train loss is 2.3995281358947977\n",
      "Steps:  83%|▊| 12443/15000 [1:48:30<09:01,  4.72it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:20 - INFO - __main__ - train loss is 2.4790602376451716\n",
      "Steps:  83%|▊| 12444/15000 [1:48:30<08:40,  4.91it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:20 - INFO - __main__ - train loss is 2.5612350379815325\n",
      "Steps:  83%|▊| 12445/15000 [1:48:30<08:25,  5.05it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:20 - INFO - __main__ - train loss is 2.5914538440993056\n",
      "Steps:  83%|▊| 12446/15000 [1:48:30<08:11,  5.20it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:20 - INFO - __main__ - train loss is 2.6215356508037075\n",
      "Steps:  83%|▊| 12447/15000 [1:48:31<08:01,  5.30it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:20 - INFO - __main__ - train loss is 2.931242219521664\n",
      "Steps:  83%|▊| 12448/15000 [1:48:31<07:54,  5.38it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:21 - INFO - __main__ - train loss is 3.009822263731621\n",
      "Steps:  83%|▊| 12449/15000 [1:48:31<07:52,  5.40it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:21 - INFO - __main__ - train loss is 3.154193683876656\n",
      "Steps:  83%|▊| 12450/15000 [1:48:31<07:49,  5.43it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:21 - INFO - __main__ - train loss is 3.422561510815285\n",
      "Steps:  83%|▊| 12451/15000 [1:48:31<07:45,  5.47it/s, lr=0.000982, step_loss=0.207/27/2023 19:33:21 - INFO - __main__ - train loss is 3.4240792943164706\n",
      "Steps:  83%|▊| 12452/15000 [1:48:32<07:45,  5.47it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:21 - INFO - __main__ - train loss is 3.642839456908405\n",
      "Steps:  83%|▊| 12453/15000 [1:48:32<07:44,  5.48it/s, lr=0.000982, step_loss=0.207/27/2023 19:33:22 - INFO - __main__ - train loss is 3.7070958791300654\n",
      "Steps:  83%|▊| 12454/15000 [1:48:32<07:45,  5.48it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:22 - INFO - __main__ - train loss is 4.121200460009277\n",
      "[2023-07-27 19:33:22,344] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576\n",
      "Steps:  83%|▊| 12455/15000 [1:48:32<07:39,  5.53it/s, lr=0.000982, step_loss=0.407/27/2023 19:33:22 - INFO - __main__ - train loss is 4.182782377116382\n",
      "Steps:  83%|▊| 12456/15000 [1:48:32<07:38,  5.55it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:22 - INFO - __main__ - train loss is 4.278808425180614\n",
      "Steps:  83%|▊| 12457/15000 [1:48:32<07:41,  5.51it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:22 - INFO - __main__ - train loss is 4.280773599166423\n",
      "Steps:  83%|▊| 12458/15000 [1:48:33<07:41,  5.51it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:22 - INFO - __main__ - train loss is 4.4682712447829545\n",
      "Steps:  83%|▊| 12459/15000 [1:48:33<07:44,  5.47it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:23 - INFO - __main__ - train loss is 4.470941866980866\n",
      "Steps:  83%|▊| 12460/15000 [1:48:33<07:43,  5.49it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:23 - INFO - __main__ - train loss is 4.574852551566437\n",
      "Steps:  83%|▊| 12461/15000 [1:48:33<07:40,  5.51it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:23 - INFO - __main__ - train loss is 4.577501647407189\n",
      "Steps:  83%|▊| 12462/15000 [1:48:33<07:38,  5.53it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:23 - INFO - __main__ - train loss is 4.653271511429921\n",
      "Steps:  83%|▊| 12463/15000 [1:48:34<07:37,  5.54it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:23 - INFO - __main__ - train loss is 5.143046394223347\n",
      "Steps:  83%|▊| 12464/15000 [1:48:34<07:36,  5.55it/s, lr=0.000982, step_loss=0.407/27/2023 19:33:24 - INFO - __main__ - train loss is 5.149685613112524\n",
      "Steps:  83%|▊| 12465/15000 [1:48:34<07:36,  5.56it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:24 - INFO - __main__ - train loss is 5.658099762396887\n",
      "Steps:  83%|▊| 12466/15000 [1:48:34<07:35,  5.56it/s, lr=0.000982, step_loss=0.507/27/2023 19:33:24 - INFO - __main__ - train loss is 5.677139058010653\n",
      "Steps:  83%|▊| 12467/15000 [1:48:34<07:35,  5.56it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:24 - INFO - __main__ - train loss is 5.680364535888657\n",
      "Steps:  83%|▊| 12468/15000 [1:48:34<07:34,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:24 - INFO - __main__ - train loss is 5.836503119906411\n",
      "Steps:  83%|▊| 12469/15000 [1:48:35<07:34,  5.57it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:24 - INFO - __main__ - train loss is 5.839483019663021\n",
      "Steps:  83%|▊| 12470/15000 [1:48:35<07:33,  5.58it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:25 - INFO - __main__ - train loss is 5.8568315773736686\n",
      "Steps:  83%|▊| 12471/15000 [1:48:35<07:33,  5.58it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:25 - INFO - __main__ - train loss is 6.181203511310741\n",
      "Steps:  83%|▊| 12472/15000 [1:48:35<07:33,  5.58it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:25 - INFO - __main__ - train loss is 6.314470645738766\n",
      "Steps:  83%|▊| 12473/15000 [1:48:35<07:33,  5.58it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:25 - INFO - __main__ - train loss is 6.33629482309334\n",
      "Steps:  83%|▊| 12474/15000 [1:48:35<07:33,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:25 - INFO - __main__ - train loss is 6.358643826795742\n",
      "Steps:  83%|▊| 12475/15000 [1:48:36<07:33,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:26 - INFO - __main__ - train loss is 6.3964777670335025\n",
      "Steps:  83%|▊| 12476/15000 [1:48:36<07:32,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:26 - INFO - __main__ - train loss is 6.4040007123257965\n",
      "Steps:  83%|▊| 12477/15000 [1:48:36<07:32,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:26 - INFO - __main__ - train loss is 6.661296618869528\n",
      "Steps:  83%|▊| 12478/15000 [1:48:36<07:32,  5.57it/s, lr=0.000982, step_loss=0.207/27/2023 19:33:26 - INFO - __main__ - train loss is 6.664516442688182\n",
      "Steps:  83%|▊| 12479/15000 [1:48:36<07:32,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:26 - INFO - __main__ - train loss is 6.7507270213682204\n",
      "Steps:  83%|▊| 12480/15000 [1:48:37<07:32,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:26 - INFO - __main__ - train loss is 6.841259279521182\n",
      "Steps:  83%|▊| 12481/15000 [1:48:37<07:32,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:27 - INFO - __main__ - train loss is 6.844859970500693\n",
      "Steps:  83%|▊| 12482/15000 [1:48:37<07:32,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:27 - INFO - __main__ - train loss is 6.944748623063788\n",
      "Steps:  83%|▊| 12483/15000 [1:48:37<07:31,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:27 - INFO - __main__ - train loss is 7.009578613331541\n",
      "Steps:  83%|▊| 12484/15000 [1:48:37<07:31,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:27 - INFO - __main__ - train loss is 7.1997252681758255\n",
      "Steps:  83%|▊| 12485/15000 [1:48:37<07:33,  5.55it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:27 - INFO - __main__ - train loss is 7.4394416937138885\n",
      "Steps:  83%|▊| 12486/15000 [1:48:38<07:38,  5.48it/s, lr=0.000982, step_loss=0.207/27/2023 19:33:28 - INFO - __main__ - train loss is 7.45304019912146\n",
      "Steps:  83%|▊| 12487/15000 [1:48:38<07:42,  5.44it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:28 - INFO - __main__ - train loss is 7.5119077728595585\n",
      "Steps:  83%|▊| 12488/15000 [1:48:38<07:45,  5.39it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:28 - INFO - __main__ - train loss is 7.551785418530926\n",
      "Steps:  83%|▊| 12489/15000 [1:48:38<07:44,  5.40it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:28 - INFO - __main__ - train loss is 7.730711811920628\n",
      "Steps:  83%|▊| 12490/15000 [1:48:38<07:43,  5.41it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:28 - INFO - __main__ - train loss is 7.801370689412579\n",
      "Steps:  83%|▊| 12491/15000 [1:48:39<07:50,  5.33it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:28 - INFO - __main__ - train loss is 7.814603583654389\n",
      "Steps:  83%|▊| 12492/15000 [1:48:39<07:48,  5.35it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:29 - INFO - __main__ - train loss is 7.876083573093638\n",
      "Steps:  83%|▊| 12493/15000 [1:48:39<07:47,  5.36it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:29 - INFO - __main__ - train loss is 7.943694842746481\n",
      "Steps:  83%|▊| 12494/15000 [1:48:39<07:51,  5.32it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:29 - INFO - __main__ - train loss is 7.960228895535693\n",
      "Steps:  83%|▊| 12495/15000 [1:48:39<07:49,  5.34it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:29 - INFO - __main__ - train loss is 8.26674542366527\n",
      "Steps:  83%|▊| 12496/15000 [1:48:40<07:47,  5.35it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:29 - INFO - __main__ - train loss is 8.277030121302232\n",
      "Steps:  83%|▊| 12497/15000 [1:48:40<07:46,  5.36it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:30 - INFO - __main__ - train loss is 8.684261571383104\n",
      "Steps:  83%|▊| 12498/15000 [1:48:40<07:45,  5.38it/s, lr=0.000982, step_loss=0.407/27/2023 19:33:30 - INFO - __main__ - train loss is 8.689375508343801\n",
      "Steps:  83%|▊| 12499/15000 [1:48:40<07:52,  5.29it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:30 - INFO - __main__ - train loss is 8.796793225919828\n",
      "Steps:  83%|▊| 12500/15000 [1:48:40<07:59,  5.21it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:30 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-12500\n",
      "07/27/2023 19:33:30 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:33:30,572] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:33:30,576] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-12500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:33:30,576] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-12500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:33:30,583] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-12500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:33:30,583] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-12500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:33:30,590] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-12500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:33:30,590] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-12500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:33:30,590] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:33:30 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-12500/pytorch_model\n",
      "07/27/2023 19:33:30 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-12500/scheduler.bin\n",
      "07/27/2023 19:33:30 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-12500/random_states_0.pkl\n",
      "07/27/2023 19:33:30 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-12500\n",
      "Steps:  83%|▊| 12500/15000 [1:48:40<07:59,  5.21it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:30 - INFO - __main__ - train loss is 8.80176405631937\n",
      "Steps:  83%|▊| 12501/15000 [1:48:40<08:10,  5.09it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:30 - INFO - __main__ - train loss is 8.953480288619176\n",
      "Steps:  83%|▊| 12502/15000 [1:48:41<08:05,  5.15it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:31 - INFO - __main__ - train loss is 8.955435978714377\n",
      "Steps:  83%|▊| 12503/15000 [1:48:41<07:58,  5.22it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:31 - INFO - __main__ - train loss is 9.319171147886664\n",
      "Steps:  83%|▊| 12504/15000 [1:48:41<07:54,  5.26it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:31 - INFO - __main__ - train loss is 9.346187290269881\n",
      "Steps:  83%|▊| 12505/15000 [1:48:41<07:54,  5.26it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:31 - INFO - __main__ - train loss is 9.347555160755292\n",
      "Steps:  83%|▊| 12506/15000 [1:48:41<08:00,  5.19it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:31 - INFO - __main__ - train loss is 9.436045289272442\n",
      "Steps:  83%|▊| 12507/15000 [1:48:42<08:01,  5.17it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:32 - INFO - __main__ - train loss is 9.601402700180188\n",
      "Steps:  83%|▊| 12508/15000 [1:48:42<08:03,  5.16it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:32 - INFO - __main__ - train loss is 9.781056687468663\n",
      "Steps:  83%|▊| 12509/15000 [1:48:42<08:04,  5.15it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:32 - INFO - __main__ - train loss is 10.1362078639213\n",
      "Steps:  83%|▊| 12510/15000 [1:48:42<08:04,  5.14it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:32 - INFO - __main__ - train loss is 10.139035511529073\n",
      "Steps:  83%|▊| 12511/15000 [1:48:42<08:05,  5.13it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:32 - INFO - __main__ - train loss is 10.531819987809286\n",
      "Steps:  83%|▊| 12512/15000 [1:48:43<08:03,  5.14it/s, lr=0.000982, step_loss=0.307/27/2023 19:33:32 - INFO - __main__ - train loss is 10.651135895168409\n",
      "Steps:  83%|▊| 12513/15000 [1:48:43<07:55,  5.23it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:33 - INFO - __main__ - train loss is 10.753489661728963\n",
      "Steps:  83%|▊| 12514/15000 [1:48:43<07:46,  5.33it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:33 - INFO - __main__ - train loss is 11.200286376988515\n",
      "Steps:  83%|▊| 12515/15000 [1:48:43<07:39,  5.40it/s, lr=0.000982, step_loss=0.407/27/2023 19:33:33 - INFO - __main__ - train loss is 11.202383861644194\n",
      "Steps:  83%|▊| 12516/15000 [1:48:43<07:35,  5.46it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:33 - INFO - __main__ - train loss is 11.2611349679064\n",
      "Steps:  83%|▊| 12517/15000 [1:48:44<07:32,  5.49it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:33 - INFO - __main__ - train loss is 11.419850171310827\n",
      "Steps:  83%|▊| 12518/15000 [1:48:44<07:29,  5.52it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:34 - INFO - __main__ - train loss is 11.514375270111486\n",
      "Steps:  83%|▊| 12519/15000 [1:48:44<07:28,  5.53it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:34 - INFO - __main__ - train loss is 11.65929374168627\n",
      "Steps:  83%|▊| 12520/15000 [1:48:44<07:27,  5.54it/s, lr=0.000982, step_loss=0.107/27/2023 19:33:34 - INFO - __main__ - train loss is 11.958629161817953\n",
      "Steps:  83%|▊| 12521/15000 [1:48:44<07:26,  5.55it/s, lr=0.000982, step_loss=0.207/27/2023 19:33:34 - INFO - __main__ - train loss is 12.384034038288519\n",
      "Steps:  83%|▊| 12522/15000 [1:48:44<07:25,  5.56it/s, lr=0.000982, step_loss=0.407/27/2023 19:33:34 - INFO - __main__ - train loss is 12.636493236524984\n",
      "Steps:  83%|▊| 12523/15000 [1:48:45<07:25,  5.56it/s, lr=0.000982, step_loss=0.207/27/2023 19:33:34 - INFO - __main__ - train loss is 12.638963509118184\n",
      "Steps:  83%|▊| 12524/15000 [1:48:45<07:24,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:35 - INFO - __main__ - train loss is 12.871386725222692\n",
      "Steps:  84%|▊| 12525/15000 [1:48:45<07:24,  5.57it/s, lr=0.000982, step_loss=0.207/27/2023 19:33:35 - INFO - __main__ - train loss is 12.876733696786687\n",
      "Steps:  84%|▊| 12526/15000 [1:48:45<07:24,  5.56it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:35 - INFO - __main__ - train loss is 13.3776747349184\n",
      "Steps:  84%|▊| 12527/15000 [1:48:45<07:24,  5.57it/s, lr=0.000982, step_loss=0.507/27/2023 19:33:35 - INFO - __main__ - train loss is 13.405752098886296\n",
      "Steps:  84%|▊| 12528/15000 [1:48:45<07:23,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:35 - INFO - __main__ - train loss is 13.433288599131629\n",
      "Steps:  84%|▊| 12529/15000 [1:48:46<07:23,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:36 - INFO - __main__ - train loss is 13.493181253550574\n",
      "Steps:  84%|▊| 12530/15000 [1:48:46<07:23,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:36 - INFO - __main__ - train loss is 13.584528508363292\n",
      "Steps:  84%|▊| 12531/15000 [1:48:46<07:23,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:36 - INFO - __main__ - train loss is 13.586129447445273\n",
      "Steps:  84%|▊| 12532/15000 [1:48:46<07:23,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:36 - INFO - __main__ - train loss is 13.591883069835603\n",
      "Steps:  84%|▊| 12533/15000 [1:48:46<07:22,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:36 - INFO - __main__ - train loss is 13.594110046047717\n",
      "Steps:  84%|▊| 12534/15000 [1:48:47<07:22,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:36 - INFO - __main__ - train loss is 13.598690590355545\n",
      "Steps:  84%|▊| 12535/15000 [1:48:47<07:22,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:37 - INFO - __main__ - train loss is 13.657969875726849\n",
      "Steps:  84%|▊| 12536/15000 [1:48:47<07:21,  5.57it/s, lr=0.000982, step_loss=0.007/27/2023 19:33:37 - INFO - __main__ - train loss is 13.870147629175335\n",
      "Steps:  84%|▊| 12537/15000 [1:48:47<07:22,  5.57it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:37 - INFO - __main__ - train loss is 14.606623335275799\n",
      "Steps:  84%|▊| 12538/15000 [1:48:47<07:25,  5.53it/s, lr=0.000981, step_loss=0.707/27/2023 19:33:37 - INFO - __main__ - train loss is 14.621909024659544\n",
      "Steps:  84%|▊| 12539/15000 [1:48:47<07:27,  5.50it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:37 - INFO - __main__ - train loss is 14.955529036466032\n",
      "Steps:  84%|▊| 12540/15000 [1:48:48<07:25,  5.52it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:38 - INFO - __main__ - train loss is 15.22469580406323\n",
      "Steps:  84%|▊| 12541/15000 [1:48:48<07:24,  5.54it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:38 - INFO - __main__ - train loss is 15.550475152675062\n",
      "Steps:  84%|▊| 12542/15000 [1:48:48<07:24,  5.53it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:38 - INFO - __main__ - train loss is 15.566830074880272\n",
      "Steps:  84%|▊| 12543/15000 [1:48:48<07:23,  5.54it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:38 - INFO - __main__ - train loss is 15.5773576782085\n",
      "Steps:  84%|▊| 12544/15000 [1:48:48<07:26,  5.50it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:38 - INFO - __main__ - train loss is 15.693366049323231\n",
      "Steps:  84%|▊| 12545/15000 [1:48:49<07:28,  5.47it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:38 - INFO - __main__ - train loss is 15.735813012812287\n",
      "Steps:  84%|▊| 12546/15000 [1:48:49<07:29,  5.46it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:39 - INFO - __main__ - train loss is 16.11379604646936\n",
      "Steps:  84%|▊| 12547/15000 [1:48:49<07:26,  5.49it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:39 - INFO - __main__ - train loss is 16.221985614392906\n",
      "Steps:  84%|▊| 12548/15000 [1:48:49<07:24,  5.52it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:39 - INFO - __main__ - train loss is 16.67966518411413\n",
      "Steps:  84%|▊| 12549/15000 [1:48:49<07:23,  5.53it/s, lr=0.000981, step_loss=0.407/27/2023 19:33:39 - INFO - __main__ - train loss is 16.758708393666893\n",
      "Steps:  84%|▊| 12550/15000 [1:48:49<07:22,  5.54it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:39 - INFO - __main__ - train loss is 16.76448716269806\n",
      "Steps:  84%|▊| 12551/15000 [1:48:50<07:21,  5.55it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:40 - INFO - __main__ - train loss is 16.77561848377809\n",
      "Steps:  84%|▊| 12552/15000 [1:48:50<07:20,  5.55it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:40 - INFO - __main__ - train loss is 16.777989285998046\n",
      "Steps:  84%|▊| 12553/15000 [1:48:50<07:20,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:40 - INFO - __main__ - train loss is 16.781716763507575\n",
      "Steps:  84%|▊| 12554/15000 [1:48:50<07:19,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:40 - INFO - __main__ - train loss is 16.942112296354026\n",
      "Steps:  84%|▊| 12555/15000 [1:48:50<07:19,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:40 - INFO - __main__ - train loss is 16.943830892909318\n",
      "Steps:  84%|▊| 12556/15000 [1:48:51<07:18,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:40 - INFO - __main__ - train loss is 17.354960427153856\n",
      "Steps:  84%|▊| 12557/15000 [1:48:51<07:20,  5.55it/s, lr=0.000981, step_loss=0.407/27/2023 19:33:41 - INFO - __main__ - train loss is 17.35712300799787\n",
      "Steps:  84%|▊| 12558/15000 [1:48:51<07:19,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:41 - INFO - __main__ - train loss is 17.369903706014156\n",
      "Steps:  84%|▊| 12559/15000 [1:48:51<07:19,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:41 - INFO - __main__ - train loss is 17.691040985286236\n",
      "Steps:  84%|▊| 12560/15000 [1:48:51<07:18,  5.57it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:41 - INFO - __main__ - train loss is 17.695355623029172\n",
      "Steps:  84%|▊| 12561/15000 [1:48:51<07:18,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:41 - INFO - __main__ - train loss is 17.788391991518438\n",
      "Steps:  84%|▊| 12562/15000 [1:48:52<07:17,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:41 - INFO - __main__ - train loss is 18.012183292768896\n",
      "Steps:  84%|▊| 12563/15000 [1:48:52<07:17,  5.57it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:42 - INFO - __main__ - train loss is 18.37856803741306\n",
      "Steps:  84%|▊| 12564/15000 [1:48:52<07:17,  5.56it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:42 - INFO - __main__ - train loss is 18.488276570104063\n",
      "Steps:  84%|▊| 12565/15000 [1:48:52<07:17,  5.56it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:42 - INFO - __main__ - train loss is 18.552932440303266\n",
      "Steps:  84%|▊| 12566/15000 [1:48:52<07:17,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:42 - INFO - __main__ - train loss is 18.703624605201185\n",
      "Steps:  84%|▊| 12567/15000 [1:48:53<07:17,  5.56it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:42 - INFO - __main__ - train loss is 18.707191106164828\n",
      "Steps:  84%|▊| 12568/15000 [1:48:53<07:17,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:43 - INFO - __main__ - train loss is 18.833034541690722\n",
      "Steps:  84%|▊| 12569/15000 [1:48:53<07:16,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:43 - INFO - __main__ - train loss is 18.85916519188322\n",
      "Steps:  84%|▊| 12570/15000 [1:48:53<07:16,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:43 - INFO - __main__ - train loss is 19.104763612383977\n",
      "Steps:  84%|▊| 12571/15000 [1:48:53<07:16,  5.57it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:43 - INFO - __main__ - train loss is 19.11046046880074\n",
      "Steps:  84%|▊| 12572/15000 [1:48:53<07:15,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:43 - INFO - __main__ - train loss is 19.516551771434024\n",
      "Steps:  84%|▊| 12573/15000 [1:48:54<07:15,  5.57it/s, lr=0.000981, step_loss=0.407/27/2023 19:33:43 - INFO - __main__ - train loss is 19.518854664405808\n",
      "Steps:  84%|▊| 12574/15000 [1:48:54<07:15,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:44 - INFO - __main__ - train loss is 19.528226149035618\n",
      "Steps:  84%|▊| 12575/15000 [1:48:54<07:15,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:44 - INFO - __main__ - train loss is 19.530586062232032\n",
      "Steps:  84%|▊| 12576/15000 [1:48:54<07:15,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:44 - INFO - __main__ - train loss is 19.573423912981525\n",
      "Steps:  84%|▊| 12577/15000 [1:48:54<07:15,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:44 - INFO - __main__ - train loss is 19.65207409695722\n",
      "Steps:  84%|▊| 12578/15000 [1:48:55<07:15,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:44 - INFO - __main__ - train loss is 19.65513903950341\n",
      "Steps:  84%|▊| 12579/15000 [1:48:55<07:14,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:45 - INFO - __main__ - train loss is 19.65981213678606\n",
      "Steps:  84%|▊| 12580/15000 [1:48:55<07:14,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:45 - INFO - __main__ - train loss is 19.66196101694368\n",
      "Steps:  84%|▊| 12581/15000 [1:48:55<07:13,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:45 - INFO - __main__ - train loss is 19.99447208433412\n",
      "Steps:  84%|▊| 12582/15000 [1:48:55<07:13,  5.57it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:45 - INFO - __main__ - train loss is 19.999252051813528\n",
      "Steps:  84%|▊| 12583/15000 [1:48:55<07:15,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:45 - INFO - __main__ - train loss is 20.3100858933758\n",
      "Steps:  84%|▊| 12584/15000 [1:48:56<07:14,  5.56it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:45 - INFO - __main__ - train loss is 20.31219267868437\n",
      "Steps:  84%|▊| 12585/15000 [1:48:56<07:14,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:46 - INFO - __main__ - train loss is 20.326451344648376\n",
      "Steps:  84%|▊| 12586/15000 [1:48:56<07:13,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:46 - INFO - __main__ - train loss is 20.33089735195972\n",
      "Steps:  84%|▊| 12587/15000 [1:48:56<07:13,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:46 - INFO - __main__ - train loss is 20.442139914492145\n",
      "Steps:  84%|▊| 12588/15000 [1:48:56<07:13,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:46 - INFO - __main__ - train loss is 21.115314772585407\n",
      "Steps:  84%|▊| 12589/15000 [1:48:56<07:12,  5.57it/s, lr=0.000981, step_loss=0.607/27/2023 19:33:46 - INFO - __main__ - train loss is 21.32342635677196\n",
      "Steps:  84%|▊| 12590/15000 [1:48:57<07:12,  5.57it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:47 - INFO - __main__ - train loss is 21.732490113237873\n",
      "Steps:  84%|▊| 12591/15000 [1:48:57<07:12,  5.57it/s, lr=0.000981, step_loss=0.407/27/2023 19:33:47 - INFO - __main__ - train loss is 21.733897401718423\n",
      "Steps:  84%|▊| 12592/15000 [1:48:57<07:12,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:47 - INFO - __main__ - train loss is 21.735720005235635\n",
      "Steps:  84%|▊| 12593/15000 [1:48:57<07:11,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:47 - INFO - __main__ - train loss is 21.971356179914437\n",
      "Steps:  84%|▊| 12594/15000 [1:48:57<07:11,  5.57it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:47 - INFO - __main__ - train loss is 22.014200341305695\n",
      "Steps:  84%|▊| 12595/15000 [1:48:58<07:11,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:47 - INFO - __main__ - train loss is 22.08859127422329\n",
      "Steps:  84%|▊| 12596/15000 [1:48:58<07:11,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:48 - INFO - __main__ - train loss is 22.486408498487435\n",
      "Steps:  84%|▊| 12597/15000 [1:48:58<07:11,  5.57it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:48 - INFO - __main__ - train loss is 22.49902934988495\n",
      "Steps:  84%|▊| 12598/15000 [1:48:58<07:10,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:48 - INFO - __main__ - train loss is 22.685558196506463\n",
      "Steps:  84%|▊| 12599/15000 [1:48:58<07:10,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:48 - INFO - __main__ - train loss is 22.727165498188697\n",
      "Steps:  84%|▊| 12600/15000 [1:48:58<07:10,  5.58it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:48 - INFO - __main__ - train loss is 22.773269128403626\n",
      "Steps:  84%|▊| 12601/15000 [1:48:59<07:10,  5.58it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:48 - INFO - __main__ - train loss is 22.86523192783352\n",
      "Steps:  84%|▊| 12602/15000 [1:48:59<07:10,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:49 - INFO - __main__ - train loss is 23.005603891215287\n",
      "Steps:  84%|▊| 12603/15000 [1:48:59<07:10,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:49 - INFO - __main__ - train loss is 23.012311163241975\n",
      "Steps:  84%|▊| 12604/15000 [1:48:59<07:10,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:49 - INFO - __main__ - train loss is 23.014808613224886\n",
      "Steps:  84%|▊| 12605/15000 [1:48:59<07:09,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:49 - INFO - __main__ - train loss is 23.43648107664194\n",
      "Steps:  84%|▊| 12606/15000 [1:49:00<07:09,  5.57it/s, lr=0.000981, step_loss=0.407/27/2023 19:33:49 - INFO - __main__ - train loss is 23.43942677124869\n",
      "Steps:  84%|▊| 12607/15000 [1:49:00<07:09,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:50 - INFO - __main__ - train loss is 23.44101429230068\n",
      "Steps:  84%|▊| 12608/15000 [1:49:00<07:09,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:50 - INFO - __main__ - train loss is 23.52524571365211\n",
      "Steps:  84%|▊| 12609/15000 [1:49:00<07:08,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:50 - INFO - __main__ - train loss is 23.722822191775776\n",
      "Steps:  84%|▊| 12610/15000 [1:49:00<07:08,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:50 - INFO - __main__ - train loss is 23.86932194477413\n",
      "Steps:  84%|▊| 12611/15000 [1:49:00<07:08,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:50 - INFO - __main__ - train loss is 23.94399228191469\n",
      "Steps:  84%|▊| 12612/15000 [1:49:01<07:08,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:50 - INFO - __main__ - train loss is 23.946180950966664\n",
      "Steps:  84%|▊| 12613/15000 [1:49:01<07:08,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:51 - INFO - __main__ - train loss is 24.812650930252858\n",
      "Steps:  84%|▊| 12614/15000 [1:49:01<07:08,  5.57it/s, lr=0.000981, step_loss=0.807/27/2023 19:33:51 - INFO - __main__ - train loss is 24.829102791962214\n",
      "Steps:  84%|▊| 12615/15000 [1:49:01<07:08,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:51 - INFO - __main__ - train loss is 24.84674429532606\n",
      "Steps:  84%|▊| 12616/15000 [1:49:01<07:07,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:51 - INFO - __main__ - train loss is 24.858836444211192\n",
      "Steps:  84%|▊| 12617/15000 [1:49:02<07:07,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:51 - INFO - __main__ - train loss is 24.881590146687813\n",
      "Steps:  84%|▊| 12618/15000 [1:49:02<07:07,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:52 - INFO - __main__ - train loss is 24.921490278211422\n",
      "Steps:  84%|▊| 12619/15000 [1:49:02<07:07,  5.57it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:52 - INFO - __main__ - train loss is 25.03997733083088\n",
      "Steps:  84%|▊| 12620/15000 [1:49:02<07:07,  5.57it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:52 - INFO - __main__ - train loss is 25.05719859164674\n",
      "Steps:  84%|▊| 12621/15000 [1:49:02<07:08,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:52 - INFO - __main__ - train loss is 25.12763531517703\n",
      "Steps:  84%|▊| 12622/15000 [1:49:02<07:07,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:52 - INFO - __main__ - train loss is 25.159620016929694\n",
      "Steps:  84%|▊| 12623/15000 [1:49:03<07:07,  5.56it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:52 - INFO - __main__ - train loss is 25.16969913255889\n",
      "Steps:  84%|▊| 12624/15000 [1:49:03<07:08,  5.55it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:53 - INFO - __main__ - train loss is 25.364172279951163\n",
      "Steps:  84%|▊| 12625/15000 [1:49:03<07:07,  5.55it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:53 - INFO - __main__ - train loss is 25.368113423814066\n",
      "Steps:  84%|▊| 12626/15000 [1:49:03<07:08,  5.54it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:53 - INFO - __main__ - train loss is 25.457039739121683\n",
      "Steps:  84%|▊| 12627/15000 [1:49:03<07:07,  5.55it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:53 - INFO - __main__ - train loss is 25.54660409979988\n",
      "Steps:  84%|▊| 12628/15000 [1:49:03<07:07,  5.55it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:53 - INFO - __main__ - train loss is 25.942942920257337\n",
      "Steps:  84%|▊| 12629/15000 [1:49:04<07:07,  5.55it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:54 - INFO - __main__ - train loss is 25.977959322859533\n",
      "Steps:  84%|▊| 12630/15000 [1:49:04<07:06,  5.55it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:54 - INFO - __main__ - train loss is 26.50751404755283\n",
      "Steps:  84%|▊| 12631/15000 [1:49:04<07:07,  5.55it/s, lr=0.000981, step_loss=0.507/27/2023 19:33:54 - INFO - __main__ - train loss is 26.619858215679415\n",
      "Steps:  84%|▊| 12632/15000 [1:49:04<07:06,  5.55it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:54 - INFO - __main__ - train loss is 26.650854933192022\n",
      "Steps:  84%|▊| 12633/15000 [1:49:04<07:08,  5.53it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:54 - INFO - __main__ - train loss is 26.66347210027743\n",
      "Steps:  84%|▊| 12634/15000 [1:49:05<07:10,  5.50it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:54 - INFO - __main__ - train loss is 26.957087203045376\n",
      "Steps:  84%|▊| 12635/15000 [1:49:05<07:09,  5.51it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:55 - INFO - __main__ - train loss is 27.24439208128024\n",
      "Steps:  84%|▊| 12636/15000 [1:49:05<07:07,  5.53it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:55 - INFO - __main__ - train loss is 27.584096117992885\n",
      "Steps:  84%|▊| 12637/15000 [1:49:05<07:06,  5.54it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:55 - INFO - __main__ - train loss is 27.873380049248226\n",
      "Steps:  84%|▊| 12638/15000 [1:49:05<07:05,  5.55it/s, lr=0.000981, step_loss=0.207/27/2023 19:33:55 - INFO - __main__ - train loss is 27.89235453598667\n",
      "Steps:  84%|▊| 12639/15000 [1:49:05<07:05,  5.55it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:55 - INFO - __main__ - train loss is 28.052319037844427\n",
      "Steps:  84%|▊| 12640/15000 [1:49:06<07:08,  5.51it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:56 - INFO - __main__ - train loss is 28.14209005527664\n",
      "Steps:  84%|▊| 12641/15000 [1:49:06<07:09,  5.49it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:56 - INFO - __main__ - train loss is 28.14947373198811\n",
      "Steps:  84%|▊| 12642/15000 [1:49:06<07:09,  5.49it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:56 - INFO - __main__ - train loss is 28.15054680360481\n",
      "Steps:  84%|▊| 12643/15000 [1:49:06<07:07,  5.51it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:56 - INFO - __main__ - train loss is 28.53997929347679\n",
      "Steps:  84%|▊| 12644/15000 [1:49:06<07:06,  5.52it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:56 - INFO - __main__ - train loss is 28.98880861653015\n",
      "Steps:  84%|▊| 12645/15000 [1:49:07<07:06,  5.53it/s, lr=0.000981, step_loss=0.407/27/2023 19:33:56 - INFO - __main__ - train loss is 29.14781244052574\n",
      "Steps:  84%|▊| 12646/15000 [1:49:07<07:05,  5.53it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:57 - INFO - __main__ - train loss is 29.556255772244185\n",
      "Steps:  84%|▊| 12647/15000 [1:49:07<07:12,  5.44it/s, lr=0.000981, step_loss=0.407/27/2023 19:33:57 - INFO - __main__ - train loss is 29.570179582107812\n",
      "Steps:  84%|▊| 12648/15000 [1:49:07<08:27,  4.63it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:57 - INFO - __main__ - train loss is 29.638648830819875\n",
      "Steps:  84%|▊| 12649/15000 [1:49:07<08:10,  4.79it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:57 - INFO - __main__ - train loss is 29.724494606722146\n",
      "Steps:  84%|▊| 12650/15000 [1:49:08<08:25,  4.65it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:58 - INFO - __main__ - train loss is 30.113366812933236\n",
      "Steps:  84%|▊| 12651/15000 [1:49:08<08:01,  4.88it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:58 - INFO - __main__ - train loss is 30.28628806816414\n",
      "Steps:  84%|▊| 12652/15000 [1:49:08<07:45,  5.04it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:58 - INFO - __main__ - train loss is 30.36290202336386\n",
      "Steps:  84%|▊| 12653/15000 [1:49:08<07:32,  5.18it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:58 - INFO - __main__ - train loss is 30.503819175530225\n",
      "Steps:  84%|▊| 12654/15000 [1:49:08<07:27,  5.24it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:58 - INFO - __main__ - train loss is 30.616025723982602\n",
      "Steps:  84%|▊| 12655/15000 [1:49:09<07:23,  5.29it/s, lr=0.000981, step_loss=0.107/27/2023 19:33:58 - INFO - __main__ - train loss is 30.61899867327884\n",
      "Steps:  84%|▊| 12656/15000 [1:49:09<07:16,  5.37it/s, lr=0.000981, step_loss=0.007/27/2023 19:33:59 - INFO - __main__ - train loss is 30.940725204069167\n",
      "Steps:  84%|▊| 12657/15000 [1:49:09<07:11,  5.43it/s, lr=0.000981, step_loss=0.307/27/2023 19:33:59 - INFO - __main__ - train loss is 31.249409076292068\n",
      "Steps:  84%|▊| 12658/15000 [1:49:09<07:08,  5.47it/s, lr=0.00098, step_loss=0.3007/27/2023 19:33:59 - INFO - __main__ - train loss is 31.278326232451946\n",
      "Steps:  84%|▊| 12659/15000 [1:49:09<07:06,  5.50it/s, lr=0.00098, step_loss=0.0207/27/2023 19:33:59 - INFO - __main__ - train loss is 31.59458174230531\n",
      "Steps:  84%|▊| 12660/15000 [1:49:09<07:04,  5.51it/s, lr=0.00098, step_loss=0.3107/27/2023 19:33:59 - INFO - __main__ - train loss is 31.773878802079707\n",
      "Steps:  84%|▊| 12661/15000 [1:49:10<07:03,  5.53it/s, lr=0.00098, step_loss=0.1707/27/2023 19:34:00 - INFO - __main__ - train loss is 31.909051795024425\n",
      "Steps:  84%|▊| 12662/15000 [1:49:10<07:02,  5.53it/s, lr=0.00098, step_loss=0.1307/27/2023 19:34:00 - INFO - __main__ - train loss is 31.977769259829074\n",
      "Steps:  84%|▊| 12663/15000 [1:49:10<07:01,  5.54it/s, lr=0.00098, step_loss=0.0607/27/2023 19:34:00 - INFO - __main__ - train loss is 31.98198626935482\n",
      "Steps:  84%|▊| 12664/15000 [1:49:10<07:01,  5.55it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:00 - INFO - __main__ - train loss is 31.989944295957685\n",
      "Steps:  84%|▊| 12665/15000 [1:49:10<07:00,  5.55it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:00 - INFO - __main__ - train loss is 32.040473433211446\n",
      "Steps:  84%|▊| 12666/15000 [1:49:11<07:00,  5.56it/s, lr=0.00098, step_loss=0.0507/27/2023 19:34:00 - INFO - __main__ - train loss is 32.45502093620598\n",
      "Steps:  84%|▊| 12667/15000 [1:49:11<06:59,  5.56it/s, lr=0.00098, step_loss=0.4107/27/2023 19:34:01 - INFO - __main__ - train loss is 32.457242279313505\n",
      "Steps:  84%|▊| 12668/15000 [1:49:11<07:02,  5.51it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:01 - INFO - __main__ - train loss is 32.467754343524575\n",
      "Steps:  84%|▊| 12669/15000 [1:49:11<07:01,  5.53it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:01 - INFO - __main__ - train loss is 32.5707435104996\n",
      "Steps:  84%|▊| 12670/15000 [1:49:11<07:03,  5.50it/s, lr=0.00098, step_loss=0.1007/27/2023 19:34:01 - INFO - __main__ - train loss is 32.62028458528221\n",
      "Steps:  84%|▊| 12671/15000 [1:49:11<07:02,  5.52it/s, lr=0.00098, step_loss=0.0407/27/2023 19:34:01 - INFO - __main__ - train loss is 32.62350109824911\n",
      "Steps:  84%|▊| 12672/15000 [1:49:12<07:03,  5.50it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:01 - INFO - __main__ - train loss is 32.63538470165804\n",
      "Steps:  84%|▊| 12673/15000 [1:49:12<07:02,  5.51it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:02 - INFO - __main__ - train loss is 32.64091756241396\n",
      "Steps:  84%|▊| 12674/15000 [1:49:12<07:01,  5.52it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:02 - INFO - __main__ - train loss is 33.008709483314306\n",
      "Steps:  84%|▊| 12675/15000 [1:49:12<07:04,  5.48it/s, lr=0.00098, step_loss=0.3607/27/2023 19:34:02 - INFO - __main__ - train loss is 33.10816334979609\n",
      "Steps:  85%|▊| 12676/15000 [1:49:12<07:03,  5.49it/s, lr=0.00098, step_loss=0.0907/27/2023 19:34:02 - INFO - __main__ - train loss is 33.34964052634314\n",
      "Steps:  85%|▊| 12677/15000 [1:49:13<07:03,  5.49it/s, lr=0.00098, step_loss=0.2407/27/2023 19:34:02 - INFO - __main__ - train loss is 33.367863670457155\n",
      "Steps:  85%|▊| 12678/15000 [1:49:13<07:01,  5.51it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:03 - INFO - __main__ - train loss is 33.65438123093918\n",
      "Steps:  85%|▊| 12679/15000 [1:49:13<07:03,  5.48it/s, lr=0.00098, step_loss=0.2807/27/2023 19:34:03 - INFO - __main__ - train loss is 33.901127592194825\n",
      "Steps:  85%|▊| 12680/15000 [1:49:13<07:02,  5.49it/s, lr=0.00098, step_loss=0.2407/27/2023 19:34:03 - INFO - __main__ - train loss is 33.90806189319119\n",
      "Steps:  85%|▊| 12681/15000 [1:49:13<07:00,  5.51it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:03 - INFO - __main__ - train loss is 34.21472364803776\n",
      "Steps:  85%|▊| 12682/15000 [1:49:13<06:59,  5.53it/s, lr=0.00098, step_loss=0.3007/27/2023 19:34:03 - INFO - __main__ - train loss is 34.384152533020824\n",
      "Steps:  85%|▊| 12683/15000 [1:49:14<06:58,  5.54it/s, lr=0.00098, step_loss=0.1607/27/2023 19:34:03 - INFO - __main__ - train loss is 34.53850227734074\n",
      "Steps:  85%|▊| 12684/15000 [1:49:14<06:57,  5.55it/s, lr=0.00098, step_loss=0.1507/27/2023 19:34:04 - INFO - __main__ - train loss is 34.75456485291943\n",
      "Steps:  85%|▊| 12685/15000 [1:49:14<06:56,  5.55it/s, lr=0.00098, step_loss=0.2107/27/2023 19:34:04 - INFO - __main__ - train loss is 34.84969560941681\n",
      "Steps:  85%|▊| 12686/15000 [1:49:14<06:56,  5.56it/s, lr=0.00098, step_loss=0.0907/27/2023 19:34:04 - INFO - __main__ - train loss is 34.94040969153866\n",
      "Steps:  85%|▊| 12687/15000 [1:49:14<06:56,  5.55it/s, lr=0.00098, step_loss=0.0907/27/2023 19:34:04 - INFO - __main__ - train loss is 35.588879556860775\n",
      "Steps:  85%|▊| 12688/15000 [1:49:15<06:56,  5.56it/s, lr=0.00098, step_loss=0.6407/27/2023 19:34:04 - INFO - __main__ - train loss is 35.59613811271265\n",
      "Steps:  85%|▊| 12689/15000 [1:49:15<06:56,  5.55it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:05 - INFO - __main__ - train loss is 35.62162021966651\n",
      "Steps:  85%|▊| 12690/15000 [1:49:15<06:55,  5.55it/s, lr=0.00098, step_loss=0.0207/27/2023 19:34:05 - INFO - __main__ - train loss is 35.80314479442313\n",
      "Steps:  85%|▊| 12691/15000 [1:49:15<06:55,  5.56it/s, lr=0.00098, step_loss=0.1807/27/2023 19:34:05 - INFO - __main__ - train loss is 35.854386527556926\n",
      "Steps:  85%|▊| 12692/15000 [1:49:15<06:55,  5.56it/s, lr=0.00098, step_loss=0.0507/27/2023 19:34:05 - INFO - __main__ - train loss is 35.858822773676366\n",
      "Steps:  85%|▊| 12693/15000 [1:49:15<06:54,  5.56it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:05 - INFO - __main__ - train loss is 35.860613925149664\n",
      "Steps:  85%|▊| 12694/15000 [1:49:16<06:54,  5.56it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:05 - INFO - __main__ - train loss is 36.171154571464285\n",
      "Steps:  85%|▊| 12695/15000 [1:49:16<06:54,  5.57it/s, lr=0.00098, step_loss=0.3107/27/2023 19:34:06 - INFO - __main__ - train loss is 36.46406842558645\n",
      "Steps:  85%|▊| 12696/15000 [1:49:16<06:55,  5.55it/s, lr=0.00098, step_loss=0.2907/27/2023 19:34:06 - INFO - __main__ - train loss is 36.581021008780226\n",
      "Steps:  85%|▊| 12697/15000 [1:49:16<06:54,  5.55it/s, lr=0.00098, step_loss=0.1107/27/2023 19:34:06 - INFO - __main__ - train loss is 36.6234938853886\n",
      "Steps:  85%|▊| 12698/15000 [1:49:16<06:55,  5.54it/s, lr=0.00098, step_loss=0.0407/27/2023 19:34:06 - INFO - __main__ - train loss is 36.63735819212161\n",
      "Steps:  85%|▊| 12699/15000 [1:49:17<06:55,  5.54it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:06 - INFO - __main__ - train loss is 36.679205033695325\n",
      "Steps:  85%|▊| 12700/15000 [1:49:17<06:54,  5.55it/s, lr=0.00098, step_loss=0.0407/27/2023 19:34:07 - INFO - __main__ - train loss is 36.69944026111625\n",
      "Steps:  85%|▊| 12701/15000 [1:49:17<06:54,  5.54it/s, lr=0.00098, step_loss=0.0207/27/2023 19:34:07 - INFO - __main__ - train loss is 36.70111789298244\n",
      "Steps:  85%|▊| 12702/15000 [1:49:17<06:54,  5.55it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:07 - INFO - __main__ - train loss is 36.711787211941555\n",
      "Steps:  85%|▊| 12703/15000 [1:49:17<06:54,  5.54it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:07 - INFO - __main__ - train loss is 36.85927728121169\n",
      "Steps:  85%|▊| 12704/15000 [1:49:17<06:56,  5.52it/s, lr=0.00098, step_loss=0.1407/27/2023 19:34:07 - INFO - __main__ - train loss is 36.88369489018805\n",
      "Steps:  85%|▊| 12705/15000 [1:49:18<06:56,  5.51it/s, lr=0.00098, step_loss=0.0207/27/2023 19:34:07 - INFO - __main__ - train loss is 36.95755404536612\n",
      "Steps:  85%|▊| 12706/15000 [1:49:18<06:55,  5.52it/s, lr=0.00098, step_loss=0.0707/27/2023 19:34:08 - INFO - __main__ - train loss is 37.4997524053324\n",
      "Steps:  85%|▊| 12707/15000 [1:49:18<06:54,  5.54it/s, lr=0.00098, step_loss=0.5407/27/2023 19:34:08 - INFO - __main__ - train loss is 37.60784578626044\n",
      "Steps:  85%|▊| 12708/15000 [1:49:18<06:54,  5.53it/s, lr=0.00098, step_loss=0.1007/27/2023 19:34:08 - INFO - __main__ - train loss is 37.60949993378017\n",
      "Steps:  85%|▊| 12709/15000 [1:49:18<06:53,  5.54it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:08 - INFO - __main__ - train loss is 37.90552783256862\n",
      "Steps:  85%|▊| 12710/15000 [1:49:18<06:52,  5.56it/s, lr=0.00098, step_loss=0.2907/27/2023 19:34:08 - INFO - __main__ - train loss is 37.9101788677508\n",
      "Steps:  85%|▊| 12711/15000 [1:49:19<06:51,  5.56it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:09 - INFO - __main__ - train loss is 37.94190867024008\n",
      "Steps:  85%|▊| 12712/15000 [1:49:19<06:50,  5.57it/s, lr=0.00098, step_loss=0.0307/27/2023 19:34:09 - INFO - __main__ - train loss is 38.23485739307944\n",
      "Steps:  85%|▊| 12713/15000 [1:49:19<06:50,  5.58it/s, lr=0.00098, step_loss=0.2907/27/2023 19:34:09 - INFO - __main__ - train loss is 38.2366534214234\n",
      "Steps:  85%|▊| 12714/15000 [1:49:19<06:49,  5.58it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:09 - INFO - __main__ - train loss is 38.47471374680754\n",
      "Steps:  85%|▊| 12715/15000 [1:49:19<06:49,  5.58it/s, lr=0.00098, step_loss=0.2307/27/2023 19:34:09 - INFO - __main__ - train loss is 38.4966222908115\n",
      "Steps:  85%|▊| 12716/15000 [1:49:20<06:49,  5.58it/s, lr=0.00098, step_loss=0.0207/27/2023 19:34:09 - INFO - __main__ - train loss is 38.511999316862784\n",
      "Steps:  85%|▊| 12717/15000 [1:49:20<06:49,  5.58it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:10 - INFO - __main__ - train loss is 38.60611088608857\n",
      "Steps:  85%|▊| 12718/15000 [1:49:20<06:48,  5.58it/s, lr=0.00098, step_loss=0.0907/27/2023 19:34:10 - INFO - __main__ - train loss is 38.64430954342242\n",
      "Steps:  85%|▊| 12719/15000 [1:49:20<06:48,  5.59it/s, lr=0.00098, step_loss=0.0307/27/2023 19:34:10 - INFO - __main__ - train loss is 38.67226507735904\n",
      "Steps:  85%|▊| 12720/15000 [1:49:20<06:48,  5.58it/s, lr=0.00098, step_loss=0.0207/27/2023 19:34:10 - INFO - __main__ - train loss is 39.00792779994663\n",
      "Steps:  85%|▊| 12721/15000 [1:49:20<06:48,  5.58it/s, lr=0.00098, step_loss=0.3307/27/2023 19:34:10 - INFO - __main__ - train loss is 39.04514438507613\n",
      "Steps:  85%|▊| 12722/15000 [1:49:21<06:47,  5.59it/s, lr=0.00098, step_loss=0.0307/27/2023 19:34:11 - INFO - __main__ - train loss is 39.05720150319394\n",
      "Steps:  85%|▊| 12723/15000 [1:49:21<06:47,  5.59it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:11 - INFO - __main__ - train loss is 39.06484065426048\n",
      "Steps:  85%|▊| 12724/15000 [1:49:21<06:47,  5.59it/s, lr=0.00098, step_loss=0.0007/27/2023 19:34:11 - INFO - __main__ - train loss is 39.0790258286288\n",
      "Steps:  85%|▊| 12725/15000 [1:49:21<06:47,  5.59it/s, lr=0.00098, step_loss=0.0107/27/2023 19:34:11 - INFO - __main__ - train loss is 39.333063447265886\n",
      "Steps:  85%|▊| 12726/15000 [1:49:22<09:32,  3.97it/s, lr=0.00098, step_loss=0.2507/27/2023 19:34:12 - INFO - __main__ - Per validation step average loss is 0.20410460233688354\n",
      "07/27/2023 19:34:12 - INFO - __main__ - Cumulative validation average loss is 0.20410460233688354\n",
      "07/27/2023 19:34:13 - INFO - __main__ - Per validation step average loss is 0.220244899392128\n",
      "07/27/2023 19:34:13 - INFO - __main__ - Cumulative validation average loss is 0.42434950172901154\n",
      "07/27/2023 19:34:13 - INFO - __main__ - Per validation step average loss is 0.2545207440853119\n",
      "07/27/2023 19:34:13 - INFO - __main__ - Cumulative validation average loss is 0.6788702458143234\n",
      "07/27/2023 19:34:14 - INFO - __main__ - Per validation step average loss is 0.21601226925849915\n",
      "07/27/2023 19:34:14 - INFO - __main__ - Cumulative validation average loss is 0.8948825150728226\n",
      "07/27/2023 19:34:14 - INFO - __main__ - Per validation step average loss is 0.16865846514701843\n",
      "07/27/2023 19:34:14 - INFO - __main__ - Cumulative validation average loss is 1.063540980219841\n",
      "07/27/2023 19:34:14 - INFO - __main__ - Per validation step average loss is 0.3065353035926819\n",
      "07/27/2023 19:34:14 - INFO - __main__ - Cumulative validation average loss is 1.3700762838125229\n",
      "07/27/2023 19:34:15 - INFO - __main__ - Per validation step average loss is 0.00826301146298647\n",
      "07/27/2023 19:34:15 - INFO - __main__ - Cumulative validation average loss is 1.3783392952755094\n",
      "07/27/2023 19:34:15 - INFO - __main__ - Per validation step average loss is 0.11352308094501495\n",
      "07/27/2023 19:34:15 - INFO - __main__ - Cumulative validation average loss is 1.4918623762205243\n",
      "07/27/2023 19:34:16 - INFO - __main__ - Per validation step average loss is 0.00144513591658324\n",
      "07/27/2023 19:34:16 - INFO - __main__ - Cumulative validation average loss is 1.4933075121371076\n",
      "07/27/2023 19:34:16 - INFO - __main__ - Per validation step average loss is 0.20543871819972992\n",
      "07/27/2023 19:34:16 - INFO - __main__ - Cumulative validation average loss is 1.6987462303368375\n",
      "07/27/2023 19:34:16 - INFO - __main__ - Per validation step average loss is 0.003167026210576296\n",
      "07/27/2023 19:34:16 - INFO - __main__ - Cumulative validation average loss is 1.7019132565474138\n",
      "07/27/2023 19:34:17 - INFO - __main__ - Per validation step average loss is 0.002971452195197344\n",
      "07/27/2023 19:34:17 - INFO - __main__ - Cumulative validation average loss is 1.704884708742611\n",
      "07/27/2023 19:34:17 - INFO - __main__ - Per validation step average loss is 0.23079721629619598\n",
      "07/27/2023 19:34:17 - INFO - __main__ - Cumulative validation average loss is 1.935681925038807\n",
      "07/27/2023 19:34:18 - INFO - __main__ - Per validation step average loss is 0.00844566896557808\n",
      "07/27/2023 19:34:18 - INFO - __main__ - Cumulative validation average loss is 1.9441275940043852\n",
      "07/27/2023 19:34:18 - INFO - __main__ - Per validation step average loss is 0.2308509349822998\n",
      "07/27/2023 19:34:18 - INFO - __main__ - Cumulative validation average loss is 2.174978528986685\n",
      "07/27/2023 19:34:19 - INFO - __main__ - Per validation step average loss is 0.6245318055152893\n",
      "07/27/2023 19:34:19 - INFO - __main__ - Cumulative validation average loss is 2.7995103345019743\n",
      "07/27/2023 19:34:19 - INFO - __main__ - Per validation step average loss is 0.0017011030577123165\n",
      "07/27/2023 19:34:19 - INFO - __main__ - Cumulative validation average loss is 2.8012114375596866\n",
      "07/27/2023 19:34:19 - INFO - __main__ - Per validation step average loss is 0.5958938002586365\n",
      "07/27/2023 19:34:19 - INFO - __main__ - Cumulative validation average loss is 3.397105237818323\n",
      "07/27/2023 19:34:20 - INFO - __main__ - Per validation step average loss is 0.4077853560447693\n",
      "07/27/2023 19:34:20 - INFO - __main__ - Cumulative validation average loss is 3.8048905938630924\n",
      "07/27/2023 19:34:20 - INFO - __main__ - Per validation step average loss is 0.4461230933666229\n",
      "07/27/2023 19:34:20 - INFO - __main__ - Cumulative validation average loss is 4.251013687229715\n",
      "07/27/2023 19:34:21 - INFO - __main__ - Per validation step average loss is 0.057394467294216156\n",
      "07/27/2023 19:34:21 - INFO - __main__ - Cumulative validation average loss is 4.308408154523931\n",
      "07/27/2023 19:34:21 - INFO - __main__ - Per validation step average loss is 0.0191369466483593\n",
      "07/27/2023 19:34:21 - INFO - __main__ - Cumulative validation average loss is 4.327545101172291\n",
      "07/27/2023 19:34:21 - INFO - __main__ - Per validation step average loss is 0.5661948919296265\n",
      "07/27/2023 19:34:21 - INFO - __main__ - Cumulative validation average loss is 4.893739993101917\n",
      "07/27/2023 19:34:22 - INFO - __main__ - Per validation step average loss is 0.10691981017589569\n",
      "07/27/2023 19:34:22 - INFO - __main__ - Cumulative validation average loss is 5.000659803277813\n",
      "07/27/2023 19:34:22 - INFO - __main__ - Per validation step average loss is 0.009777771309018135\n",
      "07/27/2023 19:34:22 - INFO - __main__ - Cumulative validation average loss is 5.010437574586831\n",
      "07/27/2023 19:34:23 - INFO - __main__ - Per validation step average loss is 0.01032784953713417\n",
      "07/27/2023 19:34:23 - INFO - __main__ - Cumulative validation average loss is 5.020765424123965\n",
      "07/27/2023 19:34:23 - INFO - __main__ - Per validation step average loss is 0.06741507351398468\n",
      "07/27/2023 19:34:23 - INFO - __main__ - Cumulative validation average loss is 5.08818049763795\n",
      "07/27/2023 19:34:24 - INFO - __main__ - Per validation step average loss is 0.06760638952255249\n",
      "07/27/2023 19:34:24 - INFO - __main__ - Cumulative validation average loss is 5.155786887160502\n",
      "07/27/2023 19:34:24 - INFO - __main__ - Per validation step average loss is 0.0018492583185434341\n",
      "07/27/2023 19:34:24 - INFO - __main__ - Cumulative validation average loss is 5.157636145479046\n",
      "07/27/2023 19:34:24 - INFO - __main__ - Per validation step average loss is 0.17030292749404907\n",
      "07/27/2023 19:34:24 - INFO - __main__ - Cumulative validation average loss is 5.327939072973095\n",
      "07/27/2023 19:34:25 - INFO - __main__ - Per validation step average loss is 0.02359519526362419\n",
      "07/27/2023 19:34:25 - INFO - __main__ - Cumulative validation average loss is 5.351534268236719\n",
      "07/27/2023 19:34:25 - INFO - __main__ - Per validation step average loss is 0.023816410452127457\n",
      "07/27/2023 19:34:25 - INFO - __main__ - Cumulative validation average loss is 5.3753506786888465\n",
      "07/27/2023 19:34:26 - INFO - __main__ - Per validation step average loss is 0.00438346341252327\n",
      "07/27/2023 19:34:26 - INFO - __main__ - Cumulative validation average loss is 5.37973414210137\n",
      "07/27/2023 19:34:26 - INFO - __main__ - Per validation step average loss is 0.044244617223739624\n",
      "07/27/2023 19:34:26 - INFO - __main__ - Cumulative validation average loss is 5.423978759325109\n",
      "07/27/2023 19:34:26 - INFO - __main__ - Per validation step average loss is 0.0030865506269037724\n",
      "07/27/2023 19:34:26 - INFO - __main__ - Cumulative validation average loss is 5.427065309952013\n",
      "07/27/2023 19:34:27 - INFO - __main__ - Per validation step average loss is 0.16062939167022705\n",
      "07/27/2023 19:34:27 - INFO - __main__ - Cumulative validation average loss is 5.58769470162224\n",
      "07/27/2023 19:34:27 - INFO - __main__ - Per validation step average loss is 0.26668620109558105\n",
      "07/27/2023 19:34:27 - INFO - __main__ - Cumulative validation average loss is 5.854380902717821\n",
      "07/27/2023 19:34:28 - INFO - __main__ - Per validation step average loss is 0.45510923862457275\n",
      "07/27/2023 19:34:28 - INFO - __main__ - Cumulative validation average loss is 6.309490141342394\n",
      "07/27/2023 19:34:28 - INFO - __main__ - Per validation step average loss is 0.07488022744655609\n",
      "07/27/2023 19:34:28 - INFO - __main__ - Cumulative validation average loss is 6.38437036878895\n",
      "07/27/2023 19:34:28 - INFO - __main__ - Per validation step average loss is 0.036045465618371964\n",
      "07/27/2023 19:34:28 - INFO - __main__ - Cumulative validation average loss is 6.420415834407322\n",
      "07/27/2023 19:34:29 - INFO - __main__ - Per validation step average loss is 0.0012797092786058784\n",
      "07/27/2023 19:34:29 - INFO - __main__ - Cumulative validation average loss is 6.421695543685928\n",
      "07/27/2023 19:34:29 - INFO - __main__ - Per validation step average loss is 0.10417492687702179\n",
      "07/27/2023 19:34:29 - INFO - __main__ - Cumulative validation average loss is 6.52587047056295\n",
      "07/27/2023 19:34:30 - INFO - __main__ - Per validation step average loss is 0.06835631281137466\n",
      "07/27/2023 19:34:30 - INFO - __main__ - Cumulative validation average loss is 6.594226783374324\n",
      "07/27/2023 19:34:30 - INFO - __main__ - Per validation step average loss is 0.012791259214282036\n",
      "07/27/2023 19:34:30 - INFO - __main__ - Cumulative validation average loss is 6.6070180425886065\n",
      "07/27/2023 19:34:31 - INFO - __main__ - Per validation step average loss is 0.0059641022235155106\n",
      "07/27/2023 19:34:31 - INFO - __main__ - Cumulative validation average loss is 6.612982144812122\n",
      "07/27/2023 19:34:31 - INFO - __main__ - Per validation step average loss is 0.43807756900787354\n",
      "07/27/2023 19:34:31 - INFO - __main__ - Cumulative validation average loss is 7.0510597138199955\n",
      "07/27/2023 19:34:31 - INFO - __main__ - Per validation step average loss is 0.005061949137598276\n",
      "07/27/2023 19:34:31 - INFO - __main__ - Cumulative validation average loss is 7.056121662957594\n",
      "07/27/2023 19:34:32 - INFO - __main__ - Per validation step average loss is 0.19109714031219482\n",
      "07/27/2023 19:34:32 - INFO - __main__ - Cumulative validation average loss is 7.247218803269789\n",
      "07/27/2023 19:34:32 - INFO - __main__ - Per validation step average loss is 0.004447205923497677\n",
      "07/27/2023 19:34:32 - INFO - __main__ - Cumulative validation average loss is 7.251666009193286\n",
      "07/27/2023 19:34:33 - INFO - __main__ - Per validation step average loss is 0.19733665883541107\n",
      "07/27/2023 19:34:33 - INFO - __main__ - Cumulative validation average loss is 7.449002668028697\n",
      "07/27/2023 19:34:33 - INFO - __main__ - Per validation step average loss is 0.3257695436477661\n",
      "07/27/2023 19:34:33 - INFO - __main__ - Cumulative validation average loss is 7.7747722116764635\n",
      "07/27/2023 19:34:33 - INFO - __main__ - Per validation step average loss is 0.22453290224075317\n",
      "07/27/2023 19:34:33 - INFO - __main__ - Cumulative validation average loss is 7.999305113917217\n",
      "07/27/2023 19:34:34 - INFO - __main__ - Per validation step average loss is 0.0038809464313089848\n",
      "07/27/2023 19:34:34 - INFO - __main__ - Cumulative validation average loss is 8.003186060348526\n",
      "07/27/2023 19:34:34 - INFO - __main__ - Per validation step average loss is 0.30339735746383667\n",
      "07/27/2023 19:34:34 - INFO - __main__ - Cumulative validation average loss is 8.306583417812362\n",
      "07/27/2023 19:34:35 - INFO - __main__ - Per validation step average loss is 0.01054349821060896\n",
      "07/27/2023 19:34:35 - INFO - __main__ - Cumulative validation average loss is 8.317126916022971\n",
      "07/27/2023 19:34:35 - INFO - __main__ - Per validation step average loss is 0.06886535882949829\n",
      "07/27/2023 19:34:35 - INFO - __main__ - Cumulative validation average loss is 8.38599227485247\n",
      "07/27/2023 19:34:36 - INFO - __main__ - Per validation step average loss is 0.038710884749889374\n",
      "07/27/2023 19:34:36 - INFO - __main__ - Cumulative validation average loss is 8.424703159602359\n",
      "07/27/2023 19:34:36 - INFO - __main__ - Per validation step average loss is 0.025242097675800323\n",
      "07/27/2023 19:34:36 - INFO - __main__ - Cumulative validation average loss is 8.44994525727816\n",
      "07/27/2023 19:34:36 - INFO - __main__ - Per validation step average loss is 0.09545855969190598\n",
      "07/27/2023 19:34:36 - INFO - __main__ - Cumulative validation average loss is 8.545403816970065\n",
      "07/27/2023 19:34:37 - INFO - __main__ - Per validation step average loss is 0.0030804304406046867\n",
      "07/27/2023 19:34:37 - INFO - __main__ - Cumulative validation average loss is 8.54848424741067\n",
      "07/27/2023 19:34:37 - INFO - __main__ - Per validation step average loss is 0.008365734480321407\n",
      "07/27/2023 19:34:37 - INFO - __main__ - Cumulative validation average loss is 8.556849981890991\n",
      "07/27/2023 19:34:38 - INFO - __main__ - Per validation step average loss is 0.04038146510720253\n",
      "07/27/2023 19:34:38 - INFO - __main__ - Cumulative validation average loss is 8.597231446998194\n",
      "07/27/2023 19:34:38 - INFO - __main__ - Per validation step average loss is 0.5445101261138916\n",
      "07/27/2023 19:34:38 - INFO - __main__ - Cumulative validation average loss is 9.141741573112085\n",
      "07/27/2023 19:34:38 - INFO - __main__ - Per validation step average loss is 0.03996610268950462\n",
      "07/27/2023 19:34:38 - INFO - __main__ - Cumulative validation average loss is 9.18170767580159\n",
      "07/27/2023 19:34:39 - INFO - __main__ - Per validation step average loss is 0.49692049622535706\n",
      "07/27/2023 19:34:39 - INFO - __main__ - Cumulative validation average loss is 9.678628172026947\n",
      "07/27/2023 19:34:39 - INFO - __main__ - Per validation step average loss is 0.47318458557128906\n",
      "07/27/2023 19:34:39 - INFO - __main__ - Cumulative validation average loss is 10.151812757598236\n",
      "07/27/2023 19:34:40 - INFO - __main__ - Per validation step average loss is 0.005625546909868717\n",
      "07/27/2023 19:34:40 - INFO - __main__ - Cumulative validation average loss is 10.157438304508105\n",
      "07/27/2023 19:34:40 - INFO - __main__ - Per validation step average loss is 0.028459126129746437\n",
      "07/27/2023 19:34:40 - INFO - __main__ - Cumulative validation average loss is 10.185897430637851\n",
      "07/27/2023 19:34:41 - INFO - __main__ - Per validation step average loss is 0.014374585822224617\n",
      "07/27/2023 19:34:41 - INFO - __main__ - Cumulative validation average loss is 10.200272016460076\n",
      "07/27/2023 19:34:41 - INFO - __main__ - Per validation step average loss is 0.1082703098654747\n",
      "07/27/2023 19:34:41 - INFO - __main__ - Cumulative validation average loss is 10.30854232632555\n",
      "07/27/2023 19:34:41 - INFO - __main__ - Per validation step average loss is 0.035373322665691376\n",
      "07/27/2023 19:34:41 - INFO - __main__ - Cumulative validation average loss is 10.343915648991242\n",
      "07/27/2023 19:34:42 - INFO - __main__ - Per validation step average loss is 0.06586579978466034\n",
      "07/27/2023 19:34:42 - INFO - __main__ - Cumulative validation average loss is 10.409781448775902\n",
      "07/27/2023 19:34:42 - INFO - __main__ - Per validation step average loss is 0.004307588562369347\n",
      "07/27/2023 19:34:42 - INFO - __main__ - Cumulative validation average loss is 10.414089037338272\n",
      "07/27/2023 19:34:43 - INFO - __main__ - Per validation step average loss is 0.47151219844818115\n",
      "07/27/2023 19:34:43 - INFO - __main__ - Cumulative validation average loss is 10.885601235786453\n",
      "07/27/2023 19:34:43 - INFO - __main__ - Per validation step average loss is 0.027510426938533783\n",
      "07/27/2023 19:34:43 - INFO - __main__ - Cumulative validation average loss is 10.913111662724987\n",
      "07/27/2023 19:34:44 - INFO - __main__ - Per validation step average loss is 0.004294516518712044\n",
      "07/27/2023 19:34:44 - INFO - __main__ - Cumulative validation average loss is 10.917406179243699\n",
      "07/27/2023 19:34:44 - INFO - __main__ - Per validation step average loss is 0.31269896030426025\n",
      "07/27/2023 19:34:44 - INFO - __main__ - Cumulative validation average loss is 11.230105139547959\n",
      "07/27/2023 19:34:44 - INFO - __main__ - Per validation step average loss is 0.19225138425827026\n",
      "07/27/2023 19:34:44 - INFO - __main__ - Cumulative validation average loss is 11.42235652380623\n",
      "07/27/2023 19:34:45 - INFO - __main__ - Per validation step average loss is 0.11637532711029053\n",
      "07/27/2023 19:34:45 - INFO - __main__ - Cumulative validation average loss is 11.53873185091652\n",
      "07/27/2023 19:34:45 - INFO - __main__ - Average validation loss for Epoch 41 is 0.14605989684704454\n",
      "07/27/2023 19:34:45 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:35:42 - INFO - __main__ - Starting epoch 42\n",
      "07/27/2023 19:35:43 - INFO - __main__ - train loss is 0.39508286118507385\n",
      "Steps:  85%|▊| 12727/15000 [1:50:53<17:28:17, 27.67s/it, lr=0.00098, step_loss=007/27/2023 19:35:43 - INFO - __main__ - train loss is 0.6019386500120163\n",
      "Steps:  85%|▊| 12728/15000 [1:50:53<12:15:34, 19.43s/it, lr=0.00098, step_loss=007/27/2023 19:35:43 - INFO - __main__ - train loss is 0.6811899840831757\n",
      "Steps:  85%|▊| 12729/15000 [1:50:54<8:36:49, 13.65s/it, lr=0.00098, step_loss=0.07/27/2023 19:35:43 - INFO - __main__ - train loss is 0.8043617606163025\n",
      "Steps:  85%|▊| 12730/15000 [1:50:54<6:03:44,  9.61s/it, lr=0.00098, step_loss=0.07/27/2023 19:35:44 - INFO - __main__ - train loss is 0.8280565291643143\n",
      "Steps:  85%|▊| 12731/15000 [1:50:54<4:16:32,  6.78s/it, lr=0.00098, step_loss=0.07/27/2023 19:35:44 - INFO - __main__ - train loss is 1.0586159229278564\n",
      "Steps:  85%|▊| 12732/15000 [1:50:54<3:01:33,  4.80s/it, lr=0.00098, step_loss=0.07/27/2023 19:35:44 - INFO - __main__ - train loss is 1.2045289874076843\n",
      "Steps:  85%|▊| 12733/15000 [1:50:54<2:09:05,  3.42s/it, lr=0.00098, step_loss=0.07/27/2023 19:35:44 - INFO - __main__ - train loss is 1.8790343403816223\n",
      "Steps:  85%|▊| 12734/15000 [1:50:55<1:32:21,  2.45s/it, lr=0.00098, step_loss=0.07/27/2023 19:35:44 - INFO - __main__ - train loss is 2.0203003883361816\n",
      "Steps:  85%|▊| 12735/15000 [1:50:55<1:06:40,  1.77s/it, lr=0.00098, step_loss=0.07/27/2023 19:35:45 - INFO - __main__ - train loss is 2.071452982723713\n",
      "Steps:  85%|▊| 12736/15000 [1:50:55<48:41,  1.29s/it, lr=0.00098, step_loss=0.0507/27/2023 19:35:45 - INFO - __main__ - train loss is 2.2169300094246864\n",
      "Steps:  85%|▊| 12737/15000 [1:50:55<36:05,  1.05it/s, lr=0.00098, step_loss=0.1407/27/2023 19:35:45 - INFO - __main__ - train loss is 2.2306695617735386\n",
      "Steps:  85%|▊| 12738/15000 [1:50:55<27:20,  1.38it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:45 - INFO - __main__ - train loss is 2.6926532424986362\n",
      "Steps:  85%|▊| 12739/15000 [1:50:55<21:12,  1.78it/s, lr=0.00098, step_loss=0.4607/27/2023 19:35:45 - INFO - __main__ - train loss is 2.7203850150108337\n",
      "Steps:  85%|▊| 12740/15000 [1:50:56<16:59,  2.22it/s, lr=0.00098, step_loss=0.0207/27/2023 19:35:46 - INFO - __main__ - train loss is 2.7422451693564653\n",
      "Steps:  85%|▊| 12741/15000 [1:50:56<14:02,  2.68it/s, lr=0.00098, step_loss=0.0207/27/2023 19:35:46 - INFO - __main__ - train loss is 2.7585601191967726\n",
      "Steps:  85%|▊| 12742/15000 [1:50:56<11:54,  3.16it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:46 - INFO - __main__ - train loss is 2.760891805170104\n",
      "Steps:  85%|▊| 12743/15000 [1:50:56<10:22,  3.63it/s, lr=0.00098, step_loss=0.0007/27/2023 19:35:46 - INFO - __main__ - train loss is 2.8062583233695477\n",
      "Steps:  85%|▊| 12744/15000 [1:50:56<09:16,  4.05it/s, lr=0.00098, step_loss=0.0407/27/2023 19:35:46 - INFO - __main__ - train loss is 2.835527590243146\n",
      "Steps:  85%|▊| 12745/15000 [1:50:57<08:31,  4.41it/s, lr=0.00098, step_loss=0.0207/27/2023 19:35:46 - INFO - __main__ - train loss is 2.87286355975084\n",
      "Steps:  85%|▊| 12746/15000 [1:50:57<07:59,  4.70it/s, lr=0.00098, step_loss=0.0307/27/2023 19:35:47 - INFO - __main__ - train loss is 3.0637401330750436\n",
      "Steps:  85%|▊| 12747/15000 [1:50:57<07:37,  4.93it/s, lr=0.00098, step_loss=0.1907/27/2023 19:35:47 - INFO - __main__ - train loss is 3.1803543108981103\n",
      "Steps:  85%|▊| 12748/15000 [1:50:57<07:21,  5.10it/s, lr=0.00098, step_loss=0.1107/27/2023 19:35:47 - INFO - __main__ - train loss is 3.1898151140194386\n",
      "Steps:  85%|▊| 12749/15000 [1:50:57<07:10,  5.23it/s, lr=0.00098, step_loss=0.0007/27/2023 19:35:47 - INFO - __main__ - train loss is 3.471608469961211\n",
      "Steps:  85%|▊| 12750/15000 [1:50:57<07:02,  5.33it/s, lr=0.00098, step_loss=0.2807/27/2023 19:35:47 - INFO - __main__ - train loss is 3.5937216903548688\n",
      "Steps:  85%|▊| 12751/15000 [1:50:58<06:56,  5.39it/s, lr=0.00098, step_loss=0.1207/27/2023 19:35:47 - INFO - __main__ - train loss is 3.608974863542244\n",
      "Steps:  85%|▊| 12752/15000 [1:50:58<06:53,  5.44it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:48 - INFO - __main__ - train loss is 3.61238527065143\n",
      "Steps:  85%|▊| 12753/15000 [1:50:58<06:50,  5.48it/s, lr=0.00098, step_loss=0.0007/27/2023 19:35:48 - INFO - __main__ - train loss is 3.7704291022382677\n",
      "Steps:  85%|▊| 12754/15000 [1:50:58<06:48,  5.50it/s, lr=0.00098, step_loss=0.1507/27/2023 19:35:48 - INFO - __main__ - train loss is 3.784354734700173\n",
      "Steps:  85%|▊| 12755/15000 [1:50:58<06:46,  5.52it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:48 - INFO - __main__ - train loss is 3.822654217015952\n",
      "Steps:  85%|▊| 12756/15000 [1:50:59<06:45,  5.53it/s, lr=0.00098, step_loss=0.0307/27/2023 19:35:48 - INFO - __main__ - train loss is 4.052834003698081\n",
      "Steps:  85%|▊| 12757/15000 [1:50:59<06:45,  5.53it/s, lr=0.00098, step_loss=0.2307/27/2023 19:35:49 - INFO - __main__ - train loss is 4.2675835634581745\n",
      "Steps:  85%|▊| 12758/15000 [1:50:59<06:44,  5.54it/s, lr=0.00098, step_loss=0.2107/27/2023 19:35:49 - INFO - __main__ - train loss is 4.283340705092996\n",
      "Steps:  85%|▊| 12759/15000 [1:50:59<06:44,  5.55it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:49 - INFO - __main__ - train loss is 4.6094143516384065\n",
      "Steps:  85%|▊| 12760/15000 [1:50:59<06:43,  5.55it/s, lr=0.00098, step_loss=0.3207/27/2023 19:35:49 - INFO - __main__ - train loss is 4.6273897788487375\n",
      "Steps:  85%|▊| 12761/15000 [1:50:59<06:43,  5.55it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:49 - INFO - __main__ - train loss is 4.6905050105415285\n",
      "Steps:  85%|▊| 12762/15000 [1:51:00<06:43,  5.55it/s, lr=0.00098, step_loss=0.0607/27/2023 19:35:49 - INFO - __main__ - train loss is 4.70472078723833\n",
      "Steps:  85%|▊| 12763/15000 [1:51:00<06:42,  5.55it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:50 - INFO - __main__ - train loss is 4.710838101804256\n",
      "Steps:  85%|▊| 12764/15000 [1:51:00<06:42,  5.56it/s, lr=0.00098, step_loss=0.0007/27/2023 19:35:50 - INFO - __main__ - train loss is 4.906421534717083\n",
      "Steps:  85%|▊| 12765/15000 [1:51:00<06:42,  5.56it/s, lr=0.00098, step_loss=0.1907/27/2023 19:35:50 - INFO - __main__ - train loss is 4.98495065420866\n",
      "Steps:  85%|▊| 12766/15000 [1:51:00<06:41,  5.56it/s, lr=0.00098, step_loss=0.0707/27/2023 19:35:50 - INFO - __main__ - train loss is 5.224957726895809\n",
      "Steps:  85%|▊| 12767/15000 [1:51:01<06:41,  5.56it/s, lr=0.00098, step_loss=0.2407/27/2023 19:35:50 - INFO - __main__ - train loss is 5.235824974253774\n",
      "Steps:  85%|▊| 12768/15000 [1:51:01<06:41,  5.56it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:51 - INFO - __main__ - train loss is 5.268579253926873\n",
      "Steps:  85%|▊| 12769/15000 [1:51:01<06:41,  5.56it/s, lr=0.00098, step_loss=0.0307/27/2023 19:35:51 - INFO - __main__ - train loss is 5.270432240329683\n",
      "Steps:  85%|▊| 12770/15000 [1:51:01<06:41,  5.56it/s, lr=0.00098, step_loss=0.0007/27/2023 19:35:51 - INFO - __main__ - train loss is 5.316821760497987\n",
      "Steps:  85%|▊| 12771/15000 [1:51:01<06:40,  5.56it/s, lr=0.00098, step_loss=0.0407/27/2023 19:35:51 - INFO - __main__ - train loss is 5.4734131610020995\n",
      "Steps:  85%|▊| 12772/15000 [1:51:01<06:40,  5.56it/s, lr=0.00098, step_loss=0.1507/27/2023 19:35:51 - INFO - __main__ - train loss is 5.523116937838495\n",
      "Steps:  85%|▊| 12773/15000 [1:51:02<06:40,  5.56it/s, lr=0.00098, step_loss=0.0407/27/2023 19:35:51 - INFO - __main__ - train loss is 5.7511362647637725\n",
      "Steps:  85%|▊| 12774/15000 [1:51:02<06:40,  5.56it/s, lr=0.00098, step_loss=0.2207/27/2023 19:35:52 - INFO - __main__ - train loss is 5.756302897352725\n",
      "Steps:  85%|▊| 12775/15000 [1:51:02<06:40,  5.56it/s, lr=0.00098, step_loss=0.0007/27/2023 19:35:52 - INFO - __main__ - train loss is 5.770437797997147\n",
      "Steps:  85%|▊| 12776/15000 [1:51:02<06:39,  5.56it/s, lr=0.00098, step_loss=0.0107/27/2023 19:35:52 - INFO - __main__ - train loss is 5.781393477227539\n",
      "Steps:  85%|▊| 12777/15000 [1:51:02<06:40,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:52 - INFO - __main__ - train loss is 5.8926021247170866\n",
      "Steps:  85%|▊| 12778/15000 [1:51:02<06:39,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:35:52 - INFO - __main__ - train loss is 5.978596420492977\n",
      "Steps:  85%|▊| 12779/15000 [1:51:03<06:39,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:53 - INFO - __main__ - train loss is 6.105915935244411\n",
      "Steps:  85%|▊| 12780/15000 [1:51:03<06:39,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:35:53 - INFO - __main__ - train loss is 6.209036649670452\n",
      "Steps:  85%|▊| 12781/15000 [1:51:03<06:39,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:35:53 - INFO - __main__ - train loss is 6.221034592483193\n",
      "Steps:  85%|▊| 12782/15000 [1:51:03<06:39,  5.55it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:53 - INFO - __main__ - train loss is 6.319023607764393\n",
      "Steps:  85%|▊| 12783/15000 [1:51:03<06:38,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:53 - INFO - __main__ - train loss is 6.347704239655286\n",
      "Steps:  85%|▊| 12784/15000 [1:51:04<06:38,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:53 - INFO - __main__ - train loss is 6.392274976242334\n",
      "Steps:  85%|▊| 12785/15000 [1:51:04<06:38,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:54 - INFO - __main__ - train loss is 6.395416889339685\n",
      "Steps:  85%|▊| 12786/15000 [1:51:04<06:38,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:54 - INFO - __main__ - train loss is 6.433686815202236\n",
      "Steps:  85%|▊| 12787/15000 [1:51:04<06:38,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:54 - INFO - __main__ - train loss is 6.661474145948887\n",
      "Steps:  85%|▊| 12788/15000 [1:51:04<06:38,  5.56it/s, lr=0.000979, step_loss=0.207/27/2023 19:35:54 - INFO - __main__ - train loss is 6.706999909132719\n",
      "Steps:  85%|▊| 12789/15000 [1:51:04<06:37,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:54 - INFO - __main__ - train loss is 6.806969027966261\n",
      "Steps:  85%|▊| 12790/15000 [1:51:05<06:37,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:35:55 - INFO - __main__ - train loss is 6.833879752084613\n",
      "Steps:  85%|▊| 12791/15000 [1:51:05<06:37,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:55 - INFO - __main__ - train loss is 6.8376653185114264\n",
      "Steps:  85%|▊| 12792/15000 [1:51:05<06:37,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:55 - INFO - __main__ - train loss is 6.8433678438887\n",
      "Steps:  85%|▊| 12793/15000 [1:51:05<06:37,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:55 - INFO - __main__ - train loss is 6.860923613421619\n",
      "Steps:  85%|▊| 12794/15000 [1:51:05<06:37,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:55 - INFO - __main__ - train loss is 6.994859318248928\n",
      "Steps:  85%|▊| 12795/15000 [1:51:06<06:36,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:35:55 - INFO - __main__ - train loss is 7.087074923329055\n",
      "Steps:  85%|▊| 12796/15000 [1:51:06<06:36,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:56 - INFO - __main__ - train loss is 7.1393198957666755\n",
      "Steps:  85%|▊| 12797/15000 [1:51:06<06:36,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:56 - INFO - __main__ - train loss is 7.834261356852949\n",
      "Steps:  85%|▊| 12798/15000 [1:51:06<06:36,  5.56it/s, lr=0.000979, step_loss=0.607/27/2023 19:35:56 - INFO - __main__ - train loss is 7.850776580162346\n",
      "Steps:  85%|▊| 12799/15000 [1:51:06<06:35,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:56 - INFO - __main__ - train loss is 7.881523256190121\n",
      "Steps:  85%|▊| 12800/15000 [1:51:06<06:35,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:56 - INFO - __main__ - train loss is 7.92652524728328\n",
      "Steps:  85%|▊| 12801/15000 [1:51:07<06:35,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:56 - INFO - __main__ - train loss is 7.928427009144798\n",
      "Steps:  85%|▊| 12802/15000 [1:51:07<06:35,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:57 - INFO - __main__ - train loss is 8.131816296139732\n",
      "Steps:  85%|▊| 12803/15000 [1:51:07<06:35,  5.56it/s, lr=0.000979, step_loss=0.207/27/2023 19:35:57 - INFO - __main__ - train loss is 8.142723166616634\n",
      "Steps:  85%|▊| 12804/15000 [1:51:07<06:35,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:57 - INFO - __main__ - train loss is 8.195207447977737\n",
      "Steps:  85%|▊| 12805/15000 [1:51:07<06:34,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:57 - INFO - __main__ - train loss is 8.274533533724025\n",
      "Steps:  85%|▊| 12806/15000 [1:51:08<06:34,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:57 - INFO - __main__ - train loss is 8.492824309738353\n",
      "Steps:  85%|▊| 12807/15000 [1:51:08<06:37,  5.51it/s, lr=0.000979, step_loss=0.207/27/2023 19:35:58 - INFO - __main__ - train loss is 8.541510769398883\n",
      "Steps:  85%|▊| 12808/15000 [1:51:08<06:38,  5.51it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:58 - INFO - __main__ - train loss is 8.82710109022446\n",
      "Steps:  85%|▊| 12809/15000 [1:51:08<06:39,  5.49it/s, lr=0.000979, step_loss=0.207/27/2023 19:35:58 - INFO - __main__ - train loss is 9.155952670844272\n",
      "Steps:  85%|▊| 12810/15000 [1:51:08<06:37,  5.51it/s, lr=0.000979, step_loss=0.307/27/2023 19:35:58 - INFO - __main__ - train loss is 9.1638217123691\n",
      "Steps:  85%|▊| 12811/15000 [1:51:08<06:36,  5.52it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:58 - INFO - __main__ - train loss is 9.208375551039353\n",
      "Steps:  85%|▊| 12812/15000 [1:51:09<06:35,  5.53it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:58 - INFO - __main__ - train loss is 9.270788185531273\n",
      "Steps:  85%|▊| 12813/15000 [1:51:09<06:34,  5.54it/s, lr=0.000979, step_loss=0.007/27/2023 19:35:59 - INFO - __main__ - train loss is 9.438110105926171\n",
      "Steps:  85%|▊| 12814/15000 [1:51:09<06:34,  5.54it/s, lr=0.000979, step_loss=0.107/27/2023 19:35:59 - INFO - __main__ - train loss is 9.663326613837853\n",
      "Steps:  85%|▊| 12815/15000 [1:51:09<06:33,  5.55it/s, lr=0.000979, step_loss=0.207/27/2023 19:35:59 - INFO - __main__ - train loss is 10.30262153618969\n",
      "Steps:  85%|▊| 12816/15000 [1:51:09<06:37,  5.50it/s, lr=0.000979, step_loss=0.607/27/2023 19:35:59 - INFO - __main__ - train loss is 10.702660255366936\n",
      "Steps:  85%|▊| 12817/15000 [1:51:10<06:36,  5.50it/s, lr=0.000979, step_loss=0.407/27/2023 19:35:59 - INFO - __main__ - train loss is 10.720222808653489\n",
      "Steps:  85%|▊| 12818/15000 [1:51:10<06:35,  5.51it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:00 - INFO - __main__ - train loss is 10.801253848010674\n",
      "Steps:  85%|▊| 12819/15000 [1:51:10<06:35,  5.52it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:00 - INFO - __main__ - train loss is 10.840793997282162\n",
      "Steps:  85%|▊| 12820/15000 [1:51:10<06:34,  5.52it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:00 - INFO - __main__ - train loss is 10.954408198827878\n",
      "Steps:  85%|▊| 12821/15000 [1:51:10<06:33,  5.53it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:00 - INFO - __main__ - train loss is 11.304490894312039\n",
      "Steps:  85%|▊| 12822/15000 [1:51:10<06:33,  5.54it/s, lr=0.000979, step_loss=0.307/27/2023 19:36:00 - INFO - __main__ - train loss is 11.334913067752495\n",
      "Steps:  85%|▊| 12823/15000 [1:51:11<06:32,  5.55it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:00 - INFO - __main__ - train loss is 11.567167155677453\n",
      "Steps:  85%|▊| 12824/15000 [1:51:11<06:32,  5.55it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:01 - INFO - __main__ - train loss is 11.570211067562923\n",
      "Steps:  86%|▊| 12825/15000 [1:51:11<06:31,  5.55it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:01 - INFO - __main__ - train loss is 11.694504976039752\n",
      "Steps:  86%|▊| 12826/15000 [1:51:11<06:31,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:01 - INFO - __main__ - train loss is 11.830546110635623\n",
      "Steps:  86%|▊| 12827/15000 [1:51:11<06:30,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:01 - INFO - __main__ - train loss is 12.009709119563922\n",
      "Steps:  86%|▊| 12828/15000 [1:51:11<06:30,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:01 - INFO - __main__ - train loss is 12.019195361761376\n",
      "Steps:  86%|▊| 12829/15000 [1:51:12<06:30,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:02 - INFO - __main__ - train loss is 12.053686908213422\n",
      "Steps:  86%|▊| 12830/15000 [1:51:12<06:30,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:02 - INFO - __main__ - train loss is 12.072509077144787\n",
      "Steps:  86%|▊| 12831/15000 [1:51:12<06:30,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:02 - INFO - __main__ - train loss is 12.296870139194652\n",
      "Steps:  86%|▊| 12832/15000 [1:51:12<06:30,  5.56it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:02 - INFO - __main__ - train loss is 12.461615499807522\n",
      "Steps:  86%|▊| 12833/15000 [1:51:12<06:29,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:02 - INFO - __main__ - train loss is 12.476895515574142\n",
      "Steps:  86%|▊| 12834/15000 [1:51:13<06:29,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:02 - INFO - __main__ - train loss is 12.643480066908523\n",
      "Steps:  86%|▊| 12835/15000 [1:51:13<06:29,  5.56it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:03 - INFO - __main__ - train loss is 12.673900031251833\n",
      "Steps:  86%|▊| 12836/15000 [1:51:13<06:29,  5.56it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:03 - INFO - __main__ - train loss is 12.709442821098492\n",
      "Steps:  86%|▊| 12837/15000 [1:51:13<06:32,  5.51it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:03 - INFO - __main__ - train loss is 12.7510282068979\n",
      "Steps:  86%|▊| 12838/15000 [1:51:13<06:31,  5.52it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:03 - INFO - __main__ - train loss is 12.808645684970543\n",
      "Steps:  86%|▊| 12839/15000 [1:51:13<06:30,  5.53it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:03 - INFO - __main__ - train loss is 12.814753209473565\n",
      "Steps:  86%|▊| 12840/15000 [1:51:14<06:29,  5.54it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:04 - INFO - __main__ - train loss is 13.20772943389602\n",
      "Steps:  86%|▊| 12841/15000 [1:51:14<06:28,  5.55it/s, lr=0.000979, step_loss=0.307/27/2023 19:36:04 - INFO - __main__ - train loss is 13.209100318141282\n",
      "Steps:  86%|▊| 12842/15000 [1:51:14<06:35,  5.46it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:04 - INFO - __main__ - train loss is 13.311504830606282\n",
      "Steps:  86%|▊| 12843/15000 [1:51:14<07:57,  4.52it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:04 - INFO - __main__ - train loss is 13.319601512514055\n",
      "Steps:  86%|▊| 12844/15000 [1:51:15<07:44,  4.64it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:04 - INFO - __main__ - train loss is 13.599417156539857\n",
      "Steps:  86%|▊| 12845/15000 [1:51:15<08:16,  4.34it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:05 - INFO - __main__ - train loss is 13.672875395976007\n",
      "Steps:  86%|▊| 12846/15000 [1:51:15<07:46,  4.62it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:05 - INFO - __main__ - train loss is 13.67848701030016\n",
      "Steps:  86%|▊| 12847/15000 [1:51:15<07:24,  4.84it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:05 - INFO - __main__ - train loss is 13.718537855893373\n",
      "Steps:  86%|▊| 12848/15000 [1:51:15<07:07,  5.04it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:05 - INFO - __main__ - train loss is 13.84366262331605\n",
      "Steps:  86%|▊| 12849/15000 [1:51:16<06:55,  5.17it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:05 - INFO - __main__ - train loss is 13.974184934049845\n",
      "Steps:  86%|▊| 12850/15000 [1:51:16<06:47,  5.28it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:06 - INFO - __main__ - train loss is 14.000495981425047\n",
      "Steps:  86%|▊| 12851/15000 [1:51:16<06:40,  5.36it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:06 - INFO - __main__ - train loss is 14.005530035123229\n",
      "Steps:  86%|▊| 12852/15000 [1:51:16<06:36,  5.42it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:06 - INFO - __main__ - train loss is 14.034411936998367\n",
      "Steps:  86%|▊| 12853/15000 [1:51:16<06:33,  5.46it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:06 - INFO - __main__ - train loss is 14.060725320130587\n",
      "Steps:  86%|▊| 12854/15000 [1:51:16<06:30,  5.49it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:06 - INFO - __main__ - train loss is 14.076983004808426\n",
      "Steps:  86%|▊| 12855/15000 [1:51:17<06:29,  5.51it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:06 - INFO - __main__ - train loss is 14.164796628057957\n",
      "Steps:  86%|▊| 12856/15000 [1:51:17<06:27,  5.53it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:07 - INFO - __main__ - train loss is 14.411646641790867\n",
      "Steps:  86%|▊| 12857/15000 [1:51:17<06:27,  5.54it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:07 - INFO - __main__ - train loss is 14.4448410756886\n",
      "Steps:  86%|▊| 12858/15000 [1:51:17<06:29,  5.51it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:07 - INFO - __main__ - train loss is 14.909752119332552\n",
      "Steps:  86%|▊| 12859/15000 [1:51:17<06:31,  5.47it/s, lr=0.000979, step_loss=0.407/27/2023 19:36:07 - INFO - __main__ - train loss is 14.975299391895533\n",
      "Steps:  86%|▊| 12860/15000 [1:51:18<06:34,  5.43it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:07 - INFO - __main__ - train loss is 15.02814057841897\n",
      "Steps:  86%|▊| 12861/15000 [1:51:18<06:32,  5.45it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:08 - INFO - __main__ - train loss is 15.031765311956406\n",
      "Steps:  86%|▊| 12862/15000 [1:51:18<06:33,  5.43it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:08 - INFO - __main__ - train loss is 15.315912276506424\n",
      "Steps:  86%|▊| 12863/15000 [1:51:18<06:35,  5.40it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:08 - INFO - __main__ - train loss is 15.34289819933474\n",
      "Steps:  86%|▊| 12864/15000 [1:51:18<06:32,  5.44it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:08 - INFO - __main__ - train loss is 15.569027567282319\n",
      "Steps:  86%|▊| 12865/15000 [1:51:18<06:30,  5.47it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:08 - INFO - __main__ - train loss is 15.627251515164971\n",
      "Steps:  86%|▊| 12866/15000 [1:51:19<06:28,  5.50it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:08 - INFO - __main__ - train loss is 15.629742793738842\n",
      "Steps:  86%|▊| 12867/15000 [1:51:19<06:26,  5.52it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:09 - INFO - __main__ - train loss is 15.637002429924905\n",
      "Steps:  86%|▊| 12868/15000 [1:51:19<06:25,  5.53it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:09 - INFO - __main__ - train loss is 15.736924714408815\n",
      "Steps:  86%|▊| 12869/15000 [1:51:19<06:24,  5.54it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:09 - INFO - __main__ - train loss is 15.744937361218035\n",
      "Steps:  86%|▊| 12870/15000 [1:51:19<06:24,  5.54it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:09 - INFO - __main__ - train loss is 15.850876064039767\n",
      "Steps:  86%|▊| 12871/15000 [1:51:20<06:23,  5.55it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:09 - INFO - __main__ - train loss is 15.859309708699584\n",
      "Steps:  86%|▊| 12872/15000 [1:51:20<06:23,  5.55it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:10 - INFO - __main__ - train loss is 15.954668452963233\n",
      "Steps:  86%|▊| 12873/15000 [1:51:20<06:22,  5.55it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:10 - INFO - __main__ - train loss is 16.06294303201139\n",
      "Steps:  86%|▊| 12874/15000 [1:51:20<06:22,  5.55it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:10 - INFO - __main__ - train loss is 16.067455671727657\n",
      "Steps:  86%|▊| 12875/15000 [1:51:20<06:23,  5.53it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:10 - INFO - __main__ - train loss is 16.078713746741414\n",
      "Steps:  86%|▊| 12876/15000 [1:51:20<06:24,  5.52it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:10 - INFO - __main__ - train loss is 16.17476107366383\n",
      "Steps:  86%|▊| 12877/15000 [1:51:21<06:25,  5.51it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:10 - INFO - __main__ - train loss is 16.38302561827004\n",
      "Steps:  86%|▊| 12878/15000 [1:51:21<06:25,  5.50it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:11 - INFO - __main__ - train loss is 16.4065481107682\n",
      "Steps:  86%|▊| 12879/15000 [1:51:21<06:25,  5.50it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:11 - INFO - __main__ - train loss is 16.51493581943214\n",
      "Steps:  86%|▊| 12880/15000 [1:51:21<06:25,  5.50it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:11 - INFO - __main__ - train loss is 17.020490495488048\n",
      "Steps:  86%|▊| 12881/15000 [1:51:21<06:25,  5.50it/s, lr=0.000979, step_loss=0.507/27/2023 19:36:11 - INFO - __main__ - train loss is 17.022312248125672\n",
      "Steps:  86%|▊| 12882/15000 [1:51:22<06:25,  5.50it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:11 - INFO - __main__ - train loss is 17.243253672495484\n",
      "Steps:  86%|▊| 12883/15000 [1:51:22<06:25,  5.49it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:12 - INFO - __main__ - train loss is 17.433987179771066\n",
      "Steps:  86%|▊| 12884/15000 [1:51:22<06:25,  5.49it/s, lr=0.000979, step_loss=0.107/27/2023 19:36:12 - INFO - __main__ - train loss is 17.445409992709756\n",
      "Steps:  86%|▊| 12885/15000 [1:51:22<06:25,  5.49it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:12 - INFO - __main__ - train loss is 17.7242246363312\n",
      "Steps:  86%|▊| 12886/15000 [1:51:22<06:25,  5.49it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:12 - INFO - __main__ - train loss is 17.79286609776318\n",
      "Steps:  86%|▊| 12887/15000 [1:51:22<06:24,  5.49it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:12 - INFO - __main__ - train loss is 17.797366262879223\n",
      "Steps:  86%|▊| 12888/15000 [1:51:23<06:24,  5.49it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:12 - INFO - __main__ - train loss is 17.827395550440997\n",
      "Steps:  86%|▊| 12889/15000 [1:51:23<06:24,  5.49it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:13 - INFO - __main__ - train loss is 18.11819489998743\n",
      "Steps:  86%|▊| 12890/15000 [1:51:23<06:24,  5.49it/s, lr=0.000979, step_loss=0.207/27/2023 19:36:13 - INFO - __main__ - train loss is 18.124201711732894\n",
      "Steps:  86%|▊| 12891/15000 [1:51:23<06:27,  5.44it/s, lr=0.000979, step_loss=0.007/27/2023 19:36:13 - INFO - __main__ - train loss is 18.134018673095852\n",
      "Steps:  86%|▊| 12892/15000 [1:51:23<06:26,  5.46it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:13 - INFO - __main__ - train loss is 18.137882090639323\n",
      "Steps:  86%|▊| 12893/15000 [1:51:24<06:27,  5.43it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:13 - INFO - __main__ - train loss is 18.23861750913784\n",
      "Steps:  86%|▊| 12894/15000 [1:51:24<06:25,  5.47it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:14 - INFO - __main__ - train loss is 18.756270855199546\n",
      "Steps:  86%|▊| 12895/15000 [1:51:24<06:23,  5.50it/s, lr=0.000978, step_loss=0.507/27/2023 19:36:14 - INFO - __main__ - train loss is 18.782540194224566\n",
      "Steps:  86%|▊| 12896/15000 [1:51:24<06:21,  5.51it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:14 - INFO - __main__ - train loss is 18.79758023051545\n",
      "Steps:  86%|▊| 12897/15000 [1:51:24<06:20,  5.52it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:14 - INFO - __main__ - train loss is 19.266356218140572\n",
      "Steps:  86%|▊| 12898/15000 [1:51:24<06:19,  5.53it/s, lr=0.000978, step_loss=0.407/27/2023 19:36:14 - INFO - __main__ - train loss is 19.268156692618504\n",
      "Steps:  86%|▊| 12899/15000 [1:51:25<06:19,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:14 - INFO - __main__ - train loss is 19.30039167799987\n",
      "Steps:  86%|▊| 12900/15000 [1:51:25<06:18,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:15 - INFO - __main__ - train loss is 19.359404769027606\n",
      "Steps:  86%|▊| 12901/15000 [1:51:25<06:18,  5.55it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:15 - INFO - __main__ - train loss is 19.449252497637644\n",
      "Steps:  86%|▊| 12902/15000 [1:51:25<06:18,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:15 - INFO - __main__ - train loss is 19.773694705450907\n",
      "Steps:  86%|▊| 12903/15000 [1:51:25<06:21,  5.50it/s, lr=0.000978, step_loss=0.307/27/2023 19:36:15 - INFO - __main__ - train loss is 19.778221424436197\n",
      "Steps:  86%|▊| 12904/15000 [1:51:26<06:20,  5.51it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:15 - INFO - __main__ - train loss is 19.815956953680143\n",
      "Steps:  86%|▊| 12905/15000 [1:51:26<06:23,  5.46it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:16 - INFO - __main__ - train loss is 19.847277633612975\n",
      "Steps:  86%|▊| 12906/15000 [1:51:26<06:22,  5.47it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:16 - INFO - __main__ - train loss is 19.92560216016136\n",
      "Steps:  86%|▊| 12907/15000 [1:51:26<06:24,  5.44it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:16 - INFO - __main__ - train loss is 19.93110659229569\n",
      "Steps:  86%|▊| 12908/15000 [1:51:26<06:25,  5.43it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:16 - INFO - __main__ - train loss is 19.93966618529521\n",
      "Steps:  86%|▊| 12909/15000 [1:51:26<06:22,  5.47it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:16 - INFO - __main__ - train loss is 19.95839673257433\n",
      "Steps:  86%|▊| 12910/15000 [1:51:27<06:20,  5.49it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:16 - INFO - __main__ - train loss is 20.51907080388628\n",
      "Steps:  86%|▊| 12911/15000 [1:51:27<06:18,  5.51it/s, lr=0.000978, step_loss=0.507/27/2023 19:36:17 - INFO - __main__ - train loss is 20.587613597279415\n",
      "Steps:  86%|▊| 12912/15000 [1:51:27<06:17,  5.53it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:17 - INFO - __main__ - train loss is 21.29637135541998\n",
      "Steps:  86%|▊| 12913/15000 [1:51:27<06:16,  5.54it/s, lr=0.000978, step_loss=0.707/27/2023 19:36:17 - INFO - __main__ - train loss is 21.354677006369457\n",
      "Steps:  86%|▊| 12914/15000 [1:51:27<06:16,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:17 - INFO - __main__ - train loss is 21.815746918087825\n",
      "Steps:  86%|▊| 12915/15000 [1:51:28<06:15,  5.55it/s, lr=0.000978, step_loss=0.407/27/2023 19:36:17 - INFO - __main__ - train loss is 22.34924216545187\n",
      "Steps:  86%|▊| 12916/15000 [1:51:28<06:15,  5.55it/s, lr=0.000978, step_loss=0.507/27/2023 19:36:18 - INFO - __main__ - train loss is 22.577976628905162\n",
      "Steps:  86%|▊| 12917/15000 [1:51:28<06:14,  5.56it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:18 - INFO - __main__ - train loss is 22.68079338944517\n",
      "Steps:  86%|▊| 12918/15000 [1:51:28<06:14,  5.56it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:18 - INFO - __main__ - train loss is 22.750001549487934\n",
      "Steps:  86%|▊| 12919/15000 [1:51:28<06:14,  5.56it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:18 - INFO - __main__ - train loss is 22.916696175700054\n",
      "Steps:  86%|▊| 12920/15000 [1:51:28<06:14,  5.56it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:18 - INFO - __main__ - train loss is 22.922300094505772\n",
      "Steps:  86%|▊| 12921/15000 [1:51:29<06:17,  5.51it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:18 - INFO - __main__ - train loss is 22.93423518887721\n",
      "Steps:  86%|▊| 12922/15000 [1:51:29<06:17,  5.51it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:19 - INFO - __main__ - train loss is 22.952518619364128\n",
      "Steps:  86%|▊| 12923/15000 [1:51:29<06:16,  5.52it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:19 - INFO - __main__ - train loss is 23.147099412744865\n",
      "Steps:  86%|▊| 12924/15000 [1:51:29<06:15,  5.53it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:19 - INFO - __main__ - train loss is 23.15872678696178\n",
      "Steps:  86%|▊| 12925/15000 [1:51:29<06:14,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:19 - INFO - __main__ - train loss is 23.164268919965252\n",
      "Steps:  86%|▊| 12926/15000 [1:51:30<06:14,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:19 - INFO - __main__ - train loss is 23.175073558231816\n",
      "Steps:  86%|▊| 12927/15000 [1:51:30<06:17,  5.49it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:20 - INFO - __main__ - train loss is 23.224121236940846\n",
      "Steps:  86%|▊| 12928/15000 [1:51:30<06:17,  5.49it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:20 - INFO - __main__ - train loss is 23.546057427069172\n",
      "Steps:  86%|▊| 12929/15000 [1:51:30<06:16,  5.49it/s, lr=0.000978, step_loss=0.307/27/2023 19:36:20 - INFO - __main__ - train loss is 23.547762901638635\n",
      "Steps:  86%|▊| 12930/15000 [1:51:30<06:15,  5.51it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:20 - INFO - __main__ - train loss is 23.569879750837572\n",
      "Steps:  86%|▊| 12931/15000 [1:51:30<06:14,  5.53it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:20 - INFO - __main__ - train loss is 23.67415099882055\n",
      "Steps:  86%|▊| 12932/15000 [1:51:31<06:13,  5.54it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:20 - INFO - __main__ - train loss is 23.68970220827032\n",
      "Steps:  86%|▊| 12933/15000 [1:51:31<06:12,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:21 - INFO - __main__ - train loss is 23.755951660801657\n",
      "Steps:  86%|▊| 12934/15000 [1:51:31<06:12,  5.55it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:21 - INFO - __main__ - train loss is 23.842445309390314\n",
      "Steps:  86%|▊| 12935/15000 [1:51:31<06:15,  5.49it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:21 - INFO - __main__ - train loss is 23.865302420337684\n",
      "Steps:  86%|▊| 12936/15000 [1:51:31<06:18,  5.45it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:21 - INFO - __main__ - train loss is 23.87174775369931\n",
      "Steps:  86%|▊| 12937/15000 [1:51:32<06:16,  5.48it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:21 - INFO - __main__ - train loss is 23.9961160562234\n",
      "Steps:  86%|▊| 12938/15000 [1:51:32<06:16,  5.48it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:22 - INFO - __main__ - train loss is 24.175861134310253\n",
      "Steps:  86%|▊| 12939/15000 [1:51:32<06:21,  5.40it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:22 - INFO - __main__ - train loss is 24.465499772806652\n",
      "Steps:  86%|▊| 12940/15000 [1:51:32<06:19,  5.42it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:22 - INFO - __main__ - train loss is 24.581943183322437\n",
      "Steps:  86%|▊| 12941/15000 [1:51:32<06:17,  5.46it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:22 - INFO - __main__ - train loss is 24.812502681394108\n",
      "Steps:  86%|▊| 12942/15000 [1:51:32<06:17,  5.45it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:22 - INFO - __main__ - train loss is 25.0165999076562\n",
      "Steps:  86%|▊| 12943/15000 [1:51:33<06:18,  5.43it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:22 - INFO - __main__ - train loss is 25.175059958477505\n",
      "Steps:  86%|▊| 12944/15000 [1:51:33<06:19,  5.42it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:23 - INFO - __main__ - train loss is 25.222433845628984\n",
      "Steps:  86%|▊| 12945/15000 [1:51:33<06:16,  5.46it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:23 - INFO - __main__ - train loss is 25.49775616370607\n",
      "Steps:  86%|▊| 12946/15000 [1:51:33<06:14,  5.49it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:23 - INFO - __main__ - train loss is 25.527895840932615\n",
      "Steps:  86%|▊| 12947/15000 [1:51:33<06:12,  5.51it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:23 - INFO - __main__ - train loss is 25.529922926449217\n",
      "Steps:  86%|▊| 12948/15000 [1:51:34<06:11,  5.52it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:23 - INFO - __main__ - train loss is 25.62225131096784\n",
      "Steps:  86%|▊| 12949/15000 [1:51:34<06:10,  5.53it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:24 - INFO - __main__ - train loss is 25.624141032923944\n",
      "Steps:  86%|▊| 12950/15000 [1:51:34<06:10,  5.54it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:24 - INFO - __main__ - train loss is 25.98106210969854\n",
      "Steps:  86%|▊| 12951/15000 [1:51:34<06:09,  5.55it/s, lr=0.000978, step_loss=0.307/27/2023 19:36:24 - INFO - __main__ - train loss is 25.98514098126907\n",
      "Steps:  86%|▊| 12952/15000 [1:51:34<06:09,  5.55it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:24 - INFO - __main__ - train loss is 25.98917359916959\n",
      "Steps:  86%|▊| 12953/15000 [1:51:34<06:08,  5.55it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:24 - INFO - __main__ - train loss is 25.99124966620002\n",
      "Steps:  86%|▊| 12954/15000 [1:51:35<06:08,  5.55it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:24 - INFO - __main__ - train loss is 26.032922663376667\n",
      "Steps:  86%|▊| 12955/15000 [1:51:35<06:08,  5.55it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:25 - INFO - __main__ - train loss is 26.054237787262537\n",
      "Steps:  86%|▊| 12956/15000 [1:51:35<06:08,  5.55it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:25 - INFO - __main__ - train loss is 26.59904200269375\n",
      "Steps:  86%|▊| 12957/15000 [1:51:35<06:07,  5.56it/s, lr=0.000978, step_loss=0.507/27/2023 19:36:25 - INFO - __main__ - train loss is 26.61219396966044\n",
      "Steps:  86%|▊| 12958/15000 [1:51:35<06:07,  5.56it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:25 - INFO - __main__ - train loss is 26.613716914784163\n",
      "Steps:  86%|▊| 12959/15000 [1:51:36<06:07,  5.56it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:25 - INFO - __main__ - train loss is 26.64485508343205\n",
      "Steps:  86%|▊| 12960/15000 [1:51:36<06:07,  5.56it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:26 - INFO - __main__ - train loss is 26.65546728624031\n",
      "Steps:  86%|▊| 12961/15000 [1:51:36<06:06,  5.56it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:26 - INFO - __main__ - train loss is 26.70373896835372\n",
      "Steps:  86%|▊| 12962/15000 [1:51:36<06:06,  5.56it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:26 - INFO - __main__ - train loss is 26.762745569925755\n",
      "Steps:  86%|▊| 12963/15000 [1:51:36<06:09,  5.51it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:26 - INFO - __main__ - train loss is 26.817979979794472\n",
      "Steps:  86%|▊| 12964/15000 [1:51:36<06:11,  5.48it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:26 - INFO - __main__ - train loss is 27.06297168461606\n",
      "Steps:  86%|▊| 12965/15000 [1:51:37<06:10,  5.49it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:26 - INFO - __main__ - train loss is 27.081756133120507\n",
      "Steps:  86%|▊| 12966/15000 [1:51:37<06:10,  5.49it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:27 - INFO - __main__ - train loss is 27.084144100546837\n",
      "Steps:  86%|▊| 12967/15000 [1:51:37<06:10,  5.49it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:27 - INFO - __main__ - train loss is 27.173078030347824\n",
      "Steps:  86%|▊| 12968/15000 [1:51:37<06:13,  5.44it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:27 - INFO - __main__ - train loss is 27.291966013610363\n",
      "Steps:  86%|▊| 12969/15000 [1:51:37<06:14,  5.43it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:27 - INFO - __main__ - train loss is 27.305136021226645\n",
      "Steps:  86%|▊| 12970/15000 [1:51:38<06:12,  5.44it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:27 - INFO - __main__ - train loss is 27.75149255618453\n",
      "Steps:  86%|▊| 12971/15000 [1:51:38<06:13,  5.43it/s, lr=0.000978, step_loss=0.407/27/2023 19:36:28 - INFO - __main__ - train loss is 27.854379009455442\n",
      "Steps:  86%|▊| 12972/15000 [1:51:38<06:14,  5.42it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:28 - INFO - __main__ - train loss is 27.97467326000333\n",
      "Steps:  86%|▊| 12973/15000 [1:51:38<06:14,  5.41it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:28 - INFO - __main__ - train loss is 28.435512233525515\n",
      "Steps:  86%|▊| 12974/15000 [1:51:38<06:15,  5.39it/s, lr=0.000978, step_loss=0.407/27/2023 19:36:28 - INFO - __main__ - train loss is 28.643400195986032\n",
      "Steps:  86%|▊| 12975/15000 [1:51:38<06:16,  5.38it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:28 - INFO - __main__ - train loss is 28.645693111233413\n",
      "Steps:  87%|▊| 12976/15000 [1:51:39<06:15,  5.39it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:29 - INFO - __main__ - train loss is 28.664565461687744\n",
      "Steps:  87%|▊| 12977/15000 [1:51:39<06:16,  5.37it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:29 - INFO - __main__ - train loss is 28.676087914034724\n",
      "Steps:  87%|▊| 12978/15000 [1:51:39<06:16,  5.37it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:29 - INFO - __main__ - train loss is 28.949434934183955\n",
      "Steps:  87%|▊| 12979/15000 [1:51:39<06:22,  5.28it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:29 - INFO - __main__ - train loss is 28.987053567543626\n",
      "Steps:  87%|▊| 12980/15000 [1:51:39<06:20,  5.31it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:29 - INFO - __main__ - train loss is 29.094422796741128\n",
      "Steps:  87%|▊| 12981/15000 [1:51:40<06:17,  5.34it/s, lr=0.000978, step_loss=0.107/27/2023 19:36:29 - INFO - __main__ - train loss is 29.513173738494515\n",
      "Steps:  87%|▊| 12982/15000 [1:51:40<06:16,  5.36it/s, lr=0.000978, step_loss=0.407/27/2023 19:36:30 - INFO - __main__ - train loss is 29.850560853257775\n",
      "Steps:  87%|▊| 12983/15000 [1:51:40<06:14,  5.38it/s, lr=0.000978, step_loss=0.307/27/2023 19:36:30 - INFO - __main__ - train loss is 29.86111231148243\n",
      "Steps:  87%|▊| 12984/15000 [1:51:40<06:14,  5.39it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:30 - INFO - __main__ - train loss is 29.904504727572203\n",
      "Steps:  87%|▊| 12985/15000 [1:51:40<06:13,  5.39it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:30 - INFO - __main__ - train loss is 29.986384388059378\n",
      "Steps:  87%|▊| 12986/15000 [1:51:40<06:12,  5.40it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:30 - INFO - __main__ - train loss is 30.369603391736746\n",
      "Steps:  87%|▊| 12987/15000 [1:51:41<06:14,  5.38it/s, lr=0.000978, step_loss=0.307/27/2023 19:36:31 - INFO - __main__ - train loss is 30.43120426312089\n",
      "Steps:  87%|▊| 12988/15000 [1:51:41<06:14,  5.38it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:31 - INFO - __main__ - train loss is 30.74952596798539\n",
      "Steps:  87%|▊| 12989/15000 [1:51:41<06:12,  5.39it/s, lr=0.000978, step_loss=0.307/27/2023 19:36:31 - INFO - __main__ - train loss is 30.752272160258144\n",
      "Steps:  87%|▊| 12990/15000 [1:51:41<06:12,  5.40it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:31 - INFO - __main__ - train loss is 30.770003282930702\n",
      "Steps:  87%|▊| 12991/15000 [1:51:41<06:11,  5.40it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:31 - INFO - __main__ - train loss is 31.273382210638374\n",
      "Steps:  87%|▊| 12992/15000 [1:51:42<06:12,  5.39it/s, lr=0.000978, step_loss=0.507/27/2023 19:36:31 - INFO - __main__ - train loss is 31.294349988456815\n",
      "Steps:  87%|▊| 12993/15000 [1:51:42<06:12,  5.39it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:32 - INFO - __main__ - train loss is 31.295578725868836\n",
      "Steps:  87%|▊| 12994/15000 [1:51:42<06:13,  5.38it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:32 - INFO - __main__ - train loss is 32.06722653680481\n",
      "Steps:  87%|▊| 12995/15000 [1:51:42<06:25,  5.20it/s, lr=0.000978, step_loss=0.707/27/2023 19:36:32 - INFO - __main__ - train loss is 32.11321705603041\n",
      "Steps:  87%|▊| 12996/15000 [1:51:42<06:21,  5.25it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:32 - INFO - __main__ - train loss is 32.37355434917845\n",
      "Steps:  87%|▊| 12997/15000 [1:51:43<06:17,  5.30it/s, lr=0.000978, step_loss=0.207/27/2023 19:36:32 - INFO - __main__ - train loss is 32.391247377032414\n",
      "Steps:  87%|▊| 12998/15000 [1:51:43<06:15,  5.33it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:33 - INFO - __main__ - train loss is 32.42640805267729\n",
      "Steps:  87%|▊| 12999/15000 [1:51:43<06:17,  5.30it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:33 - INFO - __main__ - train loss is 32.846059292787686\n",
      "Steps:  87%|▊| 13000/15000 [1:51:43<06:22,  5.23it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:33 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-13000\n",
      "07/27/2023 19:36:33 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:36:33,414] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:36:33,420] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:36:33,420] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:36:33,429] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:36:33,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-13000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:36:33,439] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-13000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:36:33,440] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-13000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:36:33,440] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:36:33 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-13000/pytorch_model\n",
      "07/27/2023 19:36:33 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-13000/scheduler.bin\n",
      "07/27/2023 19:36:33 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-13000/random_states_0.pkl\n",
      "07/27/2023 19:36:33 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-13000\n",
      "Steps:  87%|▊| 13000/15000 [1:51:43<06:22,  5.23it/s, lr=0.000978, step_loss=0.407/27/2023 19:36:33 - INFO - __main__ - train loss is 33.22720652841963\n",
      "Steps:  87%|▊| 13001/15000 [1:51:43<06:39,  5.00it/s, lr=0.000978, step_loss=0.307/27/2023 19:36:33 - INFO - __main__ - train loss is 34.12407100223936\n",
      "Steps:  87%|▊| 13002/15000 [1:51:44<06:37,  5.03it/s, lr=0.000978, step_loss=0.807/27/2023 19:36:33 - INFO - __main__ - train loss is 34.16601587482728\n",
      "Steps:  87%|▊| 13003/15000 [1:51:44<06:35,  5.05it/s, lr=0.000978, step_loss=0.007/27/2023 19:36:34 - INFO - __main__ - train loss is 34.749170910799876\n",
      "Steps:  87%|▊| 13004/15000 [1:51:44<06:26,  5.16it/s, lr=0.000978, step_loss=0.507/27/2023 19:36:34 - INFO - __main__ - train loss is 34.76028675236739\n",
      "Steps:  87%|▊| 13005/15000 [1:51:44<06:22,  5.22it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:34 - INFO - __main__ - train loss is 35.05928969779052\n",
      "Steps:  87%|▊| 13006/15000 [1:51:44<06:21,  5.22it/s, lr=0.000977, step_loss=0.207/27/2023 19:36:34 - INFO - __main__ - train loss is 35.06063928711228\n",
      "Steps:  87%|▊| 13007/15000 [1:51:45<06:24,  5.18it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:34 - INFO - __main__ - train loss is 35.262147213099524\n",
      "Steps:  87%|▊| 13008/15000 [1:51:45<06:26,  5.16it/s, lr=0.000977, step_loss=0.207/27/2023 19:36:35 - INFO - __main__ - train loss is 35.373263294575736\n",
      "Steps:  87%|▊| 13009/15000 [1:51:45<06:28,  5.13it/s, lr=0.000977, step_loss=0.107/27/2023 19:36:35 - INFO - __main__ - train loss is 35.71650194632821\n",
      "Steps:  87%|▊| 13010/15000 [1:51:45<06:28,  5.12it/s, lr=0.000977, step_loss=0.307/27/2023 19:36:35 - INFO - __main__ - train loss is 35.93502594041638\n",
      "Steps:  87%|▊| 13011/15000 [1:51:45<06:28,  5.11it/s, lr=0.000977, step_loss=0.207/27/2023 19:36:35 - INFO - __main__ - train loss is 35.94100082409568\n",
      "Steps:  87%|▊| 13012/15000 [1:51:45<06:28,  5.11it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:35 - INFO - __main__ - train loss is 35.969058432849124\n",
      "Steps:  87%|▊| 13013/15000 [1:51:46<06:28,  5.11it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:36 - INFO - __main__ - train loss is 35.97336573177017\n",
      "Steps:  87%|▊| 13014/15000 [1:51:46<06:28,  5.11it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:36 - INFO - __main__ - train loss is 36.21857697539963\n",
      "Steps:  87%|▊| 13015/15000 [1:51:46<06:28,  5.12it/s, lr=0.000977, step_loss=0.207/27/2023 19:36:36 - INFO - __main__ - train loss is 36.231118427822366\n",
      "Steps:  87%|▊| 13016/15000 [1:51:46<06:27,  5.12it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:36 - INFO - __main__ - train loss is 36.575606333324686\n",
      "Steps:  87%|▊| 13017/15000 [1:51:46<06:28,  5.11it/s, lr=0.000977, step_loss=0.307/27/2023 19:36:36 - INFO - __main__ - train loss is 36.63503712252714\n",
      "Steps:  87%|▊| 13018/15000 [1:51:47<06:28,  5.10it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:37 - INFO - __main__ - train loss is 36.63685037998948\n",
      "Steps:  87%|▊| 13019/15000 [1:51:47<06:29,  5.08it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:37 - INFO - __main__ - train loss is 36.64495804312173\n",
      "Steps:  87%|▊| 13020/15000 [1:51:47<06:23,  5.16it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:37 - INFO - __main__ - train loss is 36.87369177641813\n",
      "Steps:  87%|▊| 13021/15000 [1:51:47<06:23,  5.17it/s, lr=0.000977, step_loss=0.207/27/2023 19:36:37 - INFO - __main__ - train loss is 36.90918155538384\n",
      "Steps:  87%|▊| 13022/15000 [1:51:47<06:24,  5.15it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:37 - INFO - __main__ - train loss is 37.150264506810345\n",
      "Steps:  87%|▊| 13023/15000 [1:51:48<06:24,  5.14it/s, lr=0.000977, step_loss=0.207/27/2023 19:36:38 - INFO - __main__ - train loss is 37.3434156231815\n",
      "Steps:  87%|▊| 13024/15000 [1:51:48<06:25,  5.13it/s, lr=0.000977, step_loss=0.107/27/2023 19:36:38 - INFO - __main__ - train loss is 37.38630135881249\n",
      "Steps:  87%|▊| 13025/15000 [1:51:48<06:25,  5.13it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:38 - INFO - __main__ - train loss is 37.52375788020436\n",
      "Steps:  87%|▊| 13026/15000 [1:51:48<06:25,  5.12it/s, lr=0.000977, step_loss=0.107/27/2023 19:36:38 - INFO - __main__ - train loss is 37.55407155456487\n",
      "Steps:  87%|▊| 13027/15000 [1:51:48<06:25,  5.12it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:38 - INFO - __main__ - train loss is 37.86152432265226\n",
      "Steps:  87%|▊| 13028/15000 [1:51:49<06:24,  5.12it/s, lr=0.000977, step_loss=0.307/27/2023 19:36:39 - INFO - __main__ - train loss is 37.90280786307994\n",
      "Steps:  87%|▊| 13029/15000 [1:51:49<09:12,  3.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:36:40 - INFO - __main__ - Per validation step average loss is 0.694512665271759\n",
      "07/27/2023 19:36:40 - INFO - __main__ - Cumulative validation average loss is 0.694512665271759\n",
      "07/27/2023 19:36:40 - INFO - __main__ - Per validation step average loss is 0.01677696779370308\n",
      "07/27/2023 19:36:40 - INFO - __main__ - Cumulative validation average loss is 0.7112896330654621\n",
      "07/27/2023 19:36:41 - INFO - __main__ - Per validation step average loss is 0.010153243318200111\n",
      "07/27/2023 19:36:41 - INFO - __main__ - Cumulative validation average loss is 0.7214428763836622\n",
      "07/27/2023 19:36:41 - INFO - __main__ - Per validation step average loss is 0.2816508412361145\n",
      "07/27/2023 19:36:41 - INFO - __main__ - Cumulative validation average loss is 1.0030937176197767\n",
      "07/27/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.27517032623291016\n",
      "07/27/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.2782640438526869\n",
      "07/27/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.5616234540939331\n",
      "07/27/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.83988749794662\n",
      "07/27/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.03332260623574257\n",
      "07/27/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.8732101041823626\n",
      "07/27/2023 19:36:43 - INFO - __main__ - Per validation step average loss is 0.5386335253715515\n",
      "07/27/2023 19:36:43 - INFO - __main__ - Cumulative validation average loss is 2.411843629553914\n",
      "07/27/2023 19:36:43 - INFO - __main__ - Per validation step average loss is 0.1673944890499115\n",
      "07/27/2023 19:36:43 - INFO - __main__ - Cumulative validation average loss is 2.5792381186038256\n",
      "07/27/2023 19:36:44 - INFO - __main__ - Per validation step average loss is 0.0363549068570137\n",
      "07/27/2023 19:36:44 - INFO - __main__ - Cumulative validation average loss is 2.6155930254608393\n",
      "07/27/2023 19:36:44 - INFO - __main__ - Per validation step average loss is 0.1251230537891388\n",
      "07/27/2023 19:36:44 - INFO - __main__ - Cumulative validation average loss is 2.740716079249978\n",
      "07/27/2023 19:36:45 - INFO - __main__ - Per validation step average loss is 0.0029641168657690287\n",
      "07/27/2023 19:36:45 - INFO - __main__ - Cumulative validation average loss is 2.743680196115747\n",
      "07/27/2023 19:36:45 - INFO - __main__ - Per validation step average loss is 0.18345129489898682\n",
      "07/27/2023 19:36:45 - INFO - __main__ - Cumulative validation average loss is 2.927131491014734\n",
      "07/27/2023 19:36:45 - INFO - __main__ - Per validation step average loss is 0.003196321427822113\n",
      "07/27/2023 19:36:45 - INFO - __main__ - Cumulative validation average loss is 2.930327812442556\n",
      "07/27/2023 19:36:46 - INFO - __main__ - Per validation step average loss is 0.06050192564725876\n",
      "07/27/2023 19:36:46 - INFO - __main__ - Cumulative validation average loss is 2.990829738089815\n",
      "07/27/2023 19:36:46 - INFO - __main__ - Per validation step average loss is 0.3088160753250122\n",
      "07/27/2023 19:36:46 - INFO - __main__ - Cumulative validation average loss is 3.299645813414827\n",
      "07/27/2023 19:36:47 - INFO - __main__ - Per validation step average loss is 0.017820797860622406\n",
      "07/27/2023 19:36:47 - INFO - __main__ - Cumulative validation average loss is 3.3174666112754494\n",
      "07/27/2023 19:36:47 - INFO - __main__ - Per validation step average loss is 0.002582297194749117\n",
      "07/27/2023 19:36:47 - INFO - __main__ - Cumulative validation average loss is 3.3200489084701985\n",
      "07/27/2023 19:36:47 - INFO - __main__ - Per validation step average loss is 0.695665180683136\n",
      "07/27/2023 19:36:47 - INFO - __main__ - Cumulative validation average loss is 4.0157140891533345\n",
      "07/27/2023 19:36:48 - INFO - __main__ - Per validation step average loss is 0.20506948232650757\n",
      "07/27/2023 19:36:48 - INFO - __main__ - Cumulative validation average loss is 4.220783571479842\n",
      "07/27/2023 19:36:48 - INFO - __main__ - Per validation step average loss is 0.4945322871208191\n",
      "07/27/2023 19:36:48 - INFO - __main__ - Cumulative validation average loss is 4.715315858600661\n",
      "07/27/2023 19:36:49 - INFO - __main__ - Per validation step average loss is 0.015409142710268497\n",
      "07/27/2023 19:36:49 - INFO - __main__ - Cumulative validation average loss is 4.73072500131093\n",
      "07/27/2023 19:36:49 - INFO - __main__ - Per validation step average loss is 0.3680534064769745\n",
      "07/27/2023 19:36:49 - INFO - __main__ - Cumulative validation average loss is 5.098778407787904\n",
      "07/27/2023 19:36:50 - INFO - __main__ - Per validation step average loss is 0.012866230681538582\n",
      "07/27/2023 19:36:50 - INFO - __main__ - Cumulative validation average loss is 5.111644638469443\n",
      "07/27/2023 19:36:50 - INFO - __main__ - Per validation step average loss is 0.06084952503442764\n",
      "07/27/2023 19:36:50 - INFO - __main__ - Cumulative validation average loss is 5.17249416350387\n",
      "07/27/2023 19:36:50 - INFO - __main__ - Per validation step average loss is 0.5562477111816406\n",
      "07/27/2023 19:36:50 - INFO - __main__ - Cumulative validation average loss is 5.728741874685511\n",
      "07/27/2023 19:36:51 - INFO - __main__ - Per validation step average loss is 0.21862345933914185\n",
      "07/27/2023 19:36:51 - INFO - __main__ - Cumulative validation average loss is 5.947365334024653\n",
      "07/27/2023 19:36:51 - INFO - __main__ - Per validation step average loss is 0.1672637164592743\n",
      "07/27/2023 19:36:51 - INFO - __main__ - Cumulative validation average loss is 6.114629050483927\n",
      "07/27/2023 19:36:52 - INFO - __main__ - Per validation step average loss is 0.47789275646209717\n",
      "07/27/2023 19:36:52 - INFO - __main__ - Cumulative validation average loss is 6.592521806946024\n",
      "07/27/2023 19:36:52 - INFO - __main__ - Per validation step average loss is 0.0028287554159760475\n",
      "07/27/2023 19:36:52 - INFO - __main__ - Cumulative validation average loss is 6.595350562362\n",
      "07/27/2023 19:36:52 - INFO - __main__ - Per validation step average loss is 0.10123969614505768\n",
      "07/27/2023 19:36:52 - INFO - __main__ - Cumulative validation average loss is 6.696590258507058\n",
      "07/27/2023 19:36:53 - INFO - __main__ - Per validation step average loss is 0.002748048398643732\n",
      "07/27/2023 19:36:53 - INFO - __main__ - Cumulative validation average loss is 6.699338306905702\n",
      "07/27/2023 19:36:53 - INFO - __main__ - Per validation step average loss is 0.3364144563674927\n",
      "07/27/2023 19:36:53 - INFO - __main__ - Cumulative validation average loss is 7.035752763273194\n",
      "07/27/2023 19:36:54 - INFO - __main__ - Per validation step average loss is 0.029008282348513603\n",
      "07/27/2023 19:36:54 - INFO - __main__ - Cumulative validation average loss is 7.064761045621708\n",
      "07/27/2023 19:36:54 - INFO - __main__ - Per validation step average loss is 0.06808088719844818\n",
      "07/27/2023 19:36:54 - INFO - __main__ - Cumulative validation average loss is 7.132841932820156\n",
      "07/27/2023 19:36:54 - INFO - __main__ - Per validation step average loss is 0.014201532118022442\n",
      "07/27/2023 19:36:54 - INFO - __main__ - Cumulative validation average loss is 7.147043464938179\n",
      "07/27/2023 19:36:55 - INFO - __main__ - Per validation step average loss is 0.08301199972629547\n",
      "07/27/2023 19:36:55 - INFO - __main__ - Cumulative validation average loss is 7.230055464664474\n",
      "07/27/2023 19:36:55 - INFO - __main__ - Per validation step average loss is 0.16265001893043518\n",
      "07/27/2023 19:36:55 - INFO - __main__ - Cumulative validation average loss is 7.392705483594909\n",
      "07/27/2023 19:36:56 - INFO - __main__ - Per validation step average loss is 0.015578599646687508\n",
      "07/27/2023 19:36:56 - INFO - __main__ - Cumulative validation average loss is 7.408284083241597\n",
      "07/27/2023 19:36:56 - INFO - __main__ - Per validation step average loss is 0.07822999358177185\n",
      "07/27/2023 19:36:56 - INFO - __main__ - Cumulative validation average loss is 7.486514076823369\n",
      "07/27/2023 19:36:57 - INFO - __main__ - Per validation step average loss is 0.5762608051300049\n",
      "07/27/2023 19:36:57 - INFO - __main__ - Cumulative validation average loss is 8.062774881953374\n",
      "07/27/2023 19:36:57 - INFO - __main__ - Per validation step average loss is 0.008197189308702946\n",
      "07/27/2023 19:36:57 - INFO - __main__ - Cumulative validation average loss is 8.070972071262076\n",
      "07/27/2023 19:36:57 - INFO - __main__ - Per validation step average loss is 0.06539358198642731\n",
      "07/27/2023 19:36:57 - INFO - __main__ - Cumulative validation average loss is 8.136365653248504\n",
      "07/27/2023 19:36:58 - INFO - __main__ - Per validation step average loss is 0.07175016403198242\n",
      "07/27/2023 19:36:58 - INFO - __main__ - Cumulative validation average loss is 8.208115817280486\n",
      "07/27/2023 19:36:58 - INFO - __main__ - Per validation step average loss is 0.016236472874879837\n",
      "07/27/2023 19:36:58 - INFO - __main__ - Cumulative validation average loss is 8.224352290155366\n",
      "07/27/2023 19:36:59 - INFO - __main__ - Per validation step average loss is 0.19312527775764465\n",
      "07/27/2023 19:36:59 - INFO - __main__ - Cumulative validation average loss is 8.41747756791301\n",
      "07/27/2023 19:36:59 - INFO - __main__ - Per validation step average loss is 0.1516878306865692\n",
      "07/27/2023 19:36:59 - INFO - __main__ - Cumulative validation average loss is 8.56916539859958\n",
      "07/27/2023 19:36:59 - INFO - __main__ - Per validation step average loss is 0.0038896845653653145\n",
      "07/27/2023 19:36:59 - INFO - __main__ - Cumulative validation average loss is 8.573055083164945\n",
      "07/27/2023 19:37:00 - INFO - __main__ - Per validation step average loss is 0.38814741373062134\n",
      "07/27/2023 19:37:00 - INFO - __main__ - Cumulative validation average loss is 8.961202496895567\n",
      "07/27/2023 19:37:00 - INFO - __main__ - Per validation step average loss is 0.05043061450123787\n",
      "07/27/2023 19:37:00 - INFO - __main__ - Cumulative validation average loss is 9.011633111396804\n",
      "07/27/2023 19:37:01 - INFO - __main__ - Per validation step average loss is 0.016724390909075737\n",
      "07/27/2023 19:37:01 - INFO - __main__ - Cumulative validation average loss is 9.02835750230588\n",
      "07/27/2023 19:37:01 - INFO - __main__ - Per validation step average loss is 0.08310966938734055\n",
      "07/27/2023 19:37:01 - INFO - __main__ - Cumulative validation average loss is 9.11146717169322\n",
      "07/27/2023 19:37:02 - INFO - __main__ - Per validation step average loss is 0.18693819642066956\n",
      "07/27/2023 19:37:02 - INFO - __main__ - Cumulative validation average loss is 9.29840536811389\n",
      "07/27/2023 19:37:02 - INFO - __main__ - Per validation step average loss is 0.13121601939201355\n",
      "07/27/2023 19:37:02 - INFO - __main__ - Cumulative validation average loss is 9.429621387505904\n",
      "07/27/2023 19:37:02 - INFO - __main__ - Per validation step average loss is 0.06325599551200867\n",
      "07/27/2023 19:37:02 - INFO - __main__ - Cumulative validation average loss is 9.492877383017913\n",
      "07/27/2023 19:37:03 - INFO - __main__ - Per validation step average loss is 0.36539727449417114\n",
      "07/27/2023 19:37:03 - INFO - __main__ - Cumulative validation average loss is 9.858274657512084\n",
      "07/27/2023 19:37:03 - INFO - __main__ - Per validation step average loss is 0.39826810359954834\n",
      "07/27/2023 19:37:03 - INFO - __main__ - Cumulative validation average loss is 10.256542761111632\n",
      "07/27/2023 19:37:04 - INFO - __main__ - Per validation step average loss is 0.13596364855766296\n",
      "07/27/2023 19:37:04 - INFO - __main__ - Cumulative validation average loss is 10.392506409669295\n",
      "07/27/2023 19:37:04 - INFO - __main__ - Per validation step average loss is 0.017675764858722687\n",
      "07/27/2023 19:37:04 - INFO - __main__ - Cumulative validation average loss is 10.410182174528018\n",
      "07/27/2023 19:37:05 - INFO - __main__ - Per validation step average loss is 0.04407002031803131\n",
      "07/27/2023 19:37:05 - INFO - __main__ - Cumulative validation average loss is 10.454252194846049\n",
      "07/27/2023 19:37:05 - INFO - __main__ - Per validation step average loss is 0.15227216482162476\n",
      "07/27/2023 19:37:05 - INFO - __main__ - Cumulative validation average loss is 10.606524359667674\n",
      "07/27/2023 19:37:05 - INFO - __main__ - Per validation step average loss is 0.095853291451931\n",
      "07/27/2023 19:37:05 - INFO - __main__ - Cumulative validation average loss is 10.702377651119605\n",
      "07/27/2023 19:37:06 - INFO - __main__ - Per validation step average loss is 0.05577845126390457\n",
      "07/27/2023 19:37:06 - INFO - __main__ - Cumulative validation average loss is 10.75815610238351\n",
      "07/27/2023 19:37:06 - INFO - __main__ - Per validation step average loss is 0.30222320556640625\n",
      "07/27/2023 19:37:06 - INFO - __main__ - Cumulative validation average loss is 11.060379307949916\n",
      "07/27/2023 19:37:07 - INFO - __main__ - Per validation step average loss is 0.024858620017766953\n",
      "07/27/2023 19:37:07 - INFO - __main__ - Cumulative validation average loss is 11.085237927967682\n",
      "07/27/2023 19:37:07 - INFO - __main__ - Per validation step average loss is 0.2045958787202835\n",
      "07/27/2023 19:37:07 - INFO - __main__ - Cumulative validation average loss is 11.289833806687966\n",
      "07/27/2023 19:37:07 - INFO - __main__ - Per validation step average loss is 0.37434014678001404\n",
      "07/27/2023 19:37:07 - INFO - __main__ - Cumulative validation average loss is 11.66417395346798\n",
      "07/27/2023 19:37:08 - INFO - __main__ - Per validation step average loss is 0.04358932375907898\n",
      "07/27/2023 19:37:08 - INFO - __main__ - Cumulative validation average loss is 11.707763277227059\n",
      "07/27/2023 19:37:08 - INFO - __main__ - Per validation step average loss is 0.05725092813372612\n",
      "07/27/2023 19:37:08 - INFO - __main__ - Cumulative validation average loss is 11.765014205360785\n",
      "07/27/2023 19:37:09 - INFO - __main__ - Per validation step average loss is 0.006909949705004692\n",
      "07/27/2023 19:37:09 - INFO - __main__ - Cumulative validation average loss is 11.77192415506579\n",
      "07/27/2023 19:37:09 - INFO - __main__ - Per validation step average loss is 0.0556991882622242\n",
      "07/27/2023 19:37:09 - INFO - __main__ - Cumulative validation average loss is 11.827623343328014\n",
      "07/27/2023 19:37:10 - INFO - __main__ - Per validation step average loss is 0.010313944891095161\n",
      "07/27/2023 19:37:10 - INFO - __main__ - Cumulative validation average loss is 11.83793728821911\n",
      "07/27/2023 19:37:10 - INFO - __main__ - Per validation step average loss is 0.01472858339548111\n",
      "07/27/2023 19:37:10 - INFO - __main__ - Cumulative validation average loss is 11.85266587161459\n",
      "07/27/2023 19:37:10 - INFO - __main__ - Per validation step average loss is 0.0668591633439064\n",
      "07/27/2023 19:37:10 - INFO - __main__ - Cumulative validation average loss is 11.919525034958497\n",
      "07/27/2023 19:37:11 - INFO - __main__ - Per validation step average loss is 0.09731388092041016\n",
      "07/27/2023 19:37:11 - INFO - __main__ - Cumulative validation average loss is 12.016838915878907\n",
      "07/27/2023 19:37:11 - INFO - __main__ - Per validation step average loss is 0.12759220600128174\n",
      "07/27/2023 19:37:11 - INFO - __main__ - Cumulative validation average loss is 12.144431121880189\n",
      "07/27/2023 19:37:12 - INFO - __main__ - Per validation step average loss is 0.17664998769760132\n",
      "07/27/2023 19:37:12 - INFO - __main__ - Cumulative validation average loss is 12.32108110957779\n",
      "07/27/2023 19:37:12 - INFO - __main__ - Per validation step average loss is 0.016924135386943817\n",
      "07/27/2023 19:37:12 - INFO - __main__ - Cumulative validation average loss is 12.338005244964734\n",
      "07/27/2023 19:37:13 - INFO - __main__ - Per validation step average loss is 0.3786964416503906\n",
      "07/27/2023 19:37:13 - INFO - __main__ - Cumulative validation average loss is 12.716701686615124\n",
      "07/27/2023 19:37:13 - INFO - __main__ - Average validation loss for Epoch 42 is 0.1609709074255079\n",
      "07/27/2023 19:37:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:38:10 - INFO - __main__ - Starting epoch 43\n",
      "07/27/2023 19:38:11 - INFO - __main__ - train loss is 0.024864254519343376\n",
      "Steps:  87%|▊| 13030/15000 [1:53:21<15:10:11, 27.72s/it, lr=0.000977, step_loss=07/27/2023 19:38:11 - INFO - __main__ - train loss is 0.09771874360740185\n",
      "Steps:  87%|▊| 13031/15000 [1:53:21<10:38:34, 19.46s/it, lr=0.000977, step_loss=07/27/2023 19:38:11 - INFO - __main__ - train loss is 0.14662512205541134\n",
      "Steps:  87%|▊| 13032/15000 [1:53:21<7:28:33, 13.68s/it, lr=0.000977, step_loss=007/27/2023 19:38:11 - INFO - __main__ - train loss is 0.14903450547717512\n",
      "Steps:  87%|▊| 13033/15000 [1:53:21<5:15:35,  9.63s/it, lr=0.000977, step_loss=007/27/2023 19:38:11 - INFO - __main__ - train loss is 0.1510757750365883\n",
      "Steps:  87%|▊| 13034/15000 [1:53:22<3:42:33,  6.79s/it, lr=0.000977, step_loss=007/27/2023 19:38:11 - INFO - __main__ - train loss is 0.16218560398556292\n",
      "Steps:  87%|▊| 13035/15000 [1:53:22<2:37:31,  4.81s/it, lr=0.000977, step_loss=007/27/2023 19:38:12 - INFO - __main__ - train loss is 0.331162745365873\n",
      "Steps:  87%|▊| 13036/15000 [1:53:22<1:51:58,  3.42s/it, lr=0.000977, step_loss=007/27/2023 19:38:12 - INFO - __main__ - train loss is 0.9385244792792946\n",
      "Steps:  87%|▊| 13037/15000 [1:53:22<1:20:11,  2.45s/it, lr=0.000977, step_loss=007/27/2023 19:38:12 - INFO - __main__ - train loss is 1.2239931768272072\n",
      "Steps:  87%|▊| 13038/15000 [1:53:22<58:34,  1.79s/it, lr=0.000977, step_loss=0.207/27/2023 19:38:12 - INFO - __main__ - train loss is 1.5182161873672158\n",
      "Steps:  87%|▊| 13039/15000 [1:53:23<42:53,  1.31s/it, lr=0.000977, step_loss=0.207/27/2023 19:38:12 - INFO - __main__ - train loss is 1.5798967948649079\n",
      "Steps:  87%|▊| 13040/15000 [1:53:23<31:56,  1.02it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:13 - INFO - __main__ - train loss is 1.6636838263366371\n",
      "Steps:  87%|▊| 13041/15000 [1:53:23<24:12,  1.35it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:13 - INFO - __main__ - train loss is 1.6670885004568845\n",
      "Steps:  87%|▊| 13042/15000 [1:53:23<18:44,  1.74it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:13 - INFO - __main__ - train loss is 1.7765297361183912\n",
      "Steps:  87%|▊| 13043/15000 [1:53:23<14:57,  2.18it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:13 - INFO - __main__ - train loss is 1.8094555654097348\n",
      "Steps:  87%|▊| 13044/15000 [1:53:24<12:19,  2.65it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:13 - INFO - __main__ - train loss is 1.8169704840984195\n",
      "Steps:  87%|▊| 13045/15000 [1:53:24<10:28,  3.11it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:14 - INFO - __main__ - train loss is 1.883855486055836\n",
      "Steps:  87%|▊| 13046/15000 [1:53:24<09:06,  3.58it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:14 - INFO - __main__ - train loss is 2.173216784140095\n",
      "Steps:  87%|▊| 13047/15000 [1:53:24<08:10,  3.98it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:14 - INFO - __main__ - train loss is 2.9018363596405834\n",
      "Steps:  87%|▊| 13048/15000 [1:53:24<07:29,  4.34it/s, lr=0.000977, step_loss=0.707/27/2023 19:38:14 - INFO - __main__ - train loss is 3.073228413006291\n",
      "Steps:  87%|▊| 13049/15000 [1:53:24<07:01,  4.63it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:14 - INFO - __main__ - train loss is 3.10361255495809\n",
      "Steps:  87%|▊| 13050/15000 [1:53:25<06:41,  4.86it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:14 - INFO - __main__ - train loss is 3.113781198626384\n",
      "Steps:  87%|▊| 13051/15000 [1:53:25<06:27,  5.03it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:15 - INFO - __main__ - train loss is 3.687765165930614\n",
      "Steps:  87%|▊| 13052/15000 [1:53:25<06:17,  5.17it/s, lr=0.000977, step_loss=0.507/27/2023 19:38:15 - INFO - __main__ - train loss is 4.099468454485759\n",
      "Steps:  87%|▊| 13053/15000 [1:53:25<06:13,  5.21it/s, lr=0.000977, step_loss=0.407/27/2023 19:38:15 - INFO - __main__ - train loss is 4.102570668095723\n",
      "Steps:  87%|▊| 13054/15000 [1:53:25<06:07,  5.30it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:15 - INFO - __main__ - train loss is 4.3453575077001005\n",
      "Steps:  87%|▊| 13055/15000 [1:53:26<06:02,  5.37it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:15 - INFO - __main__ - train loss is 4.750929028028622\n",
      "Steps:  87%|▊| 13056/15000 [1:53:26<05:58,  5.43it/s, lr=0.000977, step_loss=0.407/27/2023 19:38:16 - INFO - __main__ - train loss is 4.871560730272904\n",
      "Steps:  87%|▊| 13057/15000 [1:53:26<05:55,  5.47it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:16 - INFO - __main__ - train loss is 5.1215829032007605\n",
      "Steps:  87%|▊| 13058/15000 [1:53:26<05:53,  5.50it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:16 - INFO - __main__ - train loss is 5.123231334146112\n",
      "Steps:  87%|▊| 13059/15000 [1:53:26<05:53,  5.49it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:16 - INFO - __main__ - train loss is 5.168905993457884\n",
      "Steps:  87%|▊| 13060/15000 [1:53:26<05:51,  5.51it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:16 - INFO - __main__ - train loss is 5.173669204115868\n",
      "Steps:  87%|▊| 13061/15000 [1:53:27<05:51,  5.51it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:16 - INFO - __main__ - train loss is 5.556240871548653\n",
      "Steps:  87%|▊| 13062/15000 [1:53:27<05:52,  5.49it/s, lr=0.000977, step_loss=0.307/27/2023 19:38:17 - INFO - __main__ - train loss is 5.715286120772362\n",
      "Steps:  87%|▊| 13063/15000 [1:53:27<05:54,  5.47it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:17 - INFO - __main__ - train loss is 5.753152120858431\n",
      "Steps:  87%|▊| 13064/15000 [1:53:27<05:52,  5.50it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:17 - INFO - __main__ - train loss is 6.405326712876558\n",
      "Steps:  87%|▊| 13065/15000 [1:53:27<05:53,  5.48it/s, lr=0.000977, step_loss=0.607/27/2023 19:38:17 - INFO - __main__ - train loss is 6.42687526717782\n",
      "Steps:  87%|▊| 13066/15000 [1:53:28<05:54,  5.46it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:17 - INFO - __main__ - train loss is 6.511253338307142\n",
      "Steps:  87%|▊| 13067/15000 [1:53:28<05:53,  5.47it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:18 - INFO - __main__ - train loss is 6.820069056004286\n",
      "Steps:  87%|▊| 13068/15000 [1:53:28<05:51,  5.50it/s, lr=0.000977, step_loss=0.307/27/2023 19:38:18 - INFO - __main__ - train loss is 7.123151522129774\n",
      "Steps:  87%|▊| 13069/15000 [1:53:28<05:49,  5.52it/s, lr=0.000977, step_loss=0.307/27/2023 19:38:18 - INFO - __main__ - train loss is 7.136293456889689\n",
      "Steps:  87%|▊| 13070/15000 [1:53:28<05:48,  5.53it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:18 - INFO - __main__ - train loss is 7.258858540095389\n",
      "Steps:  87%|▊| 13071/15000 [1:53:28<05:51,  5.49it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:18 - INFO - __main__ - train loss is 7.264209118671715\n",
      "Steps:  87%|▊| 13072/15000 [1:53:29<05:50,  5.49it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:18 - INFO - __main__ - train loss is 7.630619582720101\n",
      "Steps:  87%|▊| 13073/15000 [1:53:29<05:49,  5.51it/s, lr=0.000977, step_loss=0.307/27/2023 19:38:19 - INFO - __main__ - train loss is 8.02467077691108\n",
      "Steps:  87%|▊| 13074/15000 [1:53:29<05:48,  5.53it/s, lr=0.000977, step_loss=0.307/27/2023 19:38:19 - INFO - __main__ - train loss is 8.182914895005524\n",
      "Steps:  87%|▊| 13075/15000 [1:53:29<05:47,  5.55it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:19 - INFO - __main__ - train loss is 8.18587170401588\n",
      "Steps:  87%|▊| 13076/15000 [1:53:29<05:46,  5.55it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:19 - INFO - __main__ - train loss is 8.245150415692478\n",
      "Steps:  87%|▊| 13077/15000 [1:53:30<05:45,  5.56it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:19 - INFO - __main__ - train loss is 8.537974087987095\n",
      "Steps:  87%|▊| 13078/15000 [1:53:30<05:45,  5.56it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:20 - INFO - __main__ - train loss is 8.56288996199146\n",
      "Steps:  87%|▊| 13079/15000 [1:53:30<05:44,  5.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:20 - INFO - __main__ - train loss is 8.644474683795124\n",
      "Steps:  87%|▊| 13080/15000 [1:53:30<05:44,  5.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:20 - INFO - __main__ - train loss is 8.648608322720975\n",
      "Steps:  87%|▊| 13081/15000 [1:53:30<05:44,  5.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:20 - INFO - __main__ - train loss is 8.663436218630522\n",
      "Steps:  87%|▊| 13082/15000 [1:53:30<05:47,  5.52it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:20 - INFO - __main__ - train loss is 9.43611292494461\n",
      "Steps:  87%|▊| 13083/15000 [1:53:31<05:49,  5.49it/s, lr=0.000977, step_loss=0.707/27/2023 19:38:20 - INFO - __main__ - train loss is 9.734348281752318\n",
      "Steps:  87%|▊| 13084/15000 [1:53:31<05:47,  5.51it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:21 - INFO - __main__ - train loss is 9.97024418367073\n",
      "Steps:  87%|▊| 13085/15000 [1:53:31<05:46,  5.53it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:21 - INFO - __main__ - train loss is 10.115137919317931\n",
      "Steps:  87%|▊| 13086/15000 [1:53:31<05:46,  5.52it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:21 - INFO - __main__ - train loss is 10.338422134052962\n",
      "Steps:  87%|▊| 13087/15000 [1:53:31<05:45,  5.54it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:21 - INFO - __main__ - train loss is 10.575204416643828\n",
      "Steps:  87%|▊| 13088/15000 [1:53:31<05:44,  5.54it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:21 - INFO - __main__ - train loss is 10.686488307546824\n",
      "Steps:  87%|▊| 13089/15000 [1:53:32<05:44,  5.55it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:22 - INFO - __main__ - train loss is 10.6996278478764\n",
      "Steps:  87%|▊| 13090/15000 [1:53:32<05:43,  5.56it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:22 - INFO - __main__ - train loss is 10.802496457006782\n",
      "Steps:  87%|▊| 13091/15000 [1:53:32<05:43,  5.56it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:22 - INFO - __main__ - train loss is 11.197189921047539\n",
      "Steps:  87%|▊| 13092/15000 [1:53:32<05:42,  5.56it/s, lr=0.000977, step_loss=0.307/27/2023 19:38:22 - INFO - __main__ - train loss is 11.241422133054584\n",
      "Steps:  87%|▊| 13093/15000 [1:53:32<05:42,  5.56it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:22 - INFO - __main__ - train loss is 11.315746375825256\n",
      "Steps:  87%|▊| 13094/15000 [1:53:33<05:42,  5.56it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:22 - INFO - __main__ - train loss is 11.641033211257309\n",
      "Steps:  87%|▊| 13095/15000 [1:53:33<05:42,  5.56it/s, lr=0.000977, step_loss=0.307/27/2023 19:38:23 - INFO - __main__ - train loss is 11.653833200689405\n",
      "Steps:  87%|▊| 13096/15000 [1:53:33<05:42,  5.56it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:23 - INFO - __main__ - train loss is 11.672934682574123\n",
      "Steps:  87%|▊| 13097/15000 [1:53:33<05:41,  5.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:23 - INFO - __main__ - train loss is 12.18858173629269\n",
      "Steps:  87%|▊| 13098/15000 [1:53:33<05:41,  5.57it/s, lr=0.000977, step_loss=0.507/27/2023 19:38:23 - INFO - __main__ - train loss is 12.350394742097706\n",
      "Steps:  87%|▊| 13099/15000 [1:53:33<05:44,  5.51it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:23 - INFO - __main__ - train loss is 12.406328064855188\n",
      "Steps:  87%|▊| 13100/15000 [1:53:34<05:45,  5.50it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:24 - INFO - __main__ - train loss is 12.44158543040976\n",
      "Steps:  87%|▊| 13101/15000 [1:53:34<05:44,  5.52it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:24 - INFO - __main__ - train loss is 12.720455923583359\n",
      "Steps:  87%|▊| 13102/15000 [1:53:34<05:42,  5.54it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:24 - INFO - __main__ - train loss is 12.845764765050262\n",
      "Steps:  87%|▊| 13103/15000 [1:53:34<05:41,  5.55it/s, lr=0.000977, step_loss=0.107/27/2023 19:38:24 - INFO - __main__ - train loss is 12.908883997704834\n",
      "Steps:  87%|▊| 13104/15000 [1:53:34<05:41,  5.55it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:24 - INFO - __main__ - train loss is 13.133779072668403\n",
      "Steps:  87%|▊| 13105/15000 [1:53:35<05:41,  5.55it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:24 - INFO - __main__ - train loss is 13.6050198613666\n",
      "Steps:  87%|▊| 13106/15000 [1:53:35<05:40,  5.56it/s, lr=0.000977, step_loss=0.407/27/2023 19:38:25 - INFO - __main__ - train loss is 13.81508415332064\n",
      "Steps:  87%|▊| 13107/15000 [1:53:35<05:40,  5.57it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:25 - INFO - __main__ - train loss is 14.024375641252846\n",
      "Steps:  87%|▊| 13108/15000 [1:53:35<05:39,  5.57it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:25 - INFO - __main__ - train loss is 14.091585823800415\n",
      "Steps:  87%|▊| 13109/15000 [1:53:35<05:39,  5.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:25 - INFO - __main__ - train loss is 14.70458705117926\n",
      "Steps:  87%|▊| 13110/15000 [1:53:35<05:39,  5.57it/s, lr=0.000977, step_loss=0.607/27/2023 19:38:25 - INFO - __main__ - train loss is 14.711056843865663\n",
      "Steps:  87%|▊| 13111/15000 [1:53:36<05:39,  5.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:26 - INFO - __main__ - train loss is 15.002767101395875\n",
      "Steps:  87%|▊| 13112/15000 [1:53:36<05:38,  5.57it/s, lr=0.000977, step_loss=0.207/27/2023 19:38:26 - INFO - __main__ - train loss is 15.586519614327699\n",
      "Steps:  87%|▊| 13113/15000 [1:53:36<05:38,  5.57it/s, lr=0.000977, step_loss=0.507/27/2023 19:38:26 - INFO - __main__ - train loss is 15.592150963842869\n",
      "Steps:  87%|▊| 13114/15000 [1:53:36<05:38,  5.57it/s, lr=0.000977, step_loss=0.007/27/2023 19:38:26 - INFO - __main__ - train loss is 15.597448342945427\n",
      "Steps:  87%|▊| 13115/15000 [1:53:36<05:38,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:26 - INFO - __main__ - train loss is 15.914672666694969\n",
      "Steps:  87%|▊| 13116/15000 [1:53:37<05:38,  5.57it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:26 - INFO - __main__ - train loss is 15.998456561472267\n",
      "Steps:  87%|▊| 13117/15000 [1:53:37<05:38,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:27 - INFO - __main__ - train loss is 16.00289634708315\n",
      "Steps:  87%|▊| 13118/15000 [1:53:37<05:37,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:27 - INFO - __main__ - train loss is 16.239456140436232\n",
      "Steps:  87%|▊| 13119/15000 [1:53:37<05:37,  5.57it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:27 - INFO - __main__ - train loss is 16.457541250623763\n",
      "Steps:  87%|▊| 13120/15000 [1:53:37<05:37,  5.57it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:27 - INFO - __main__ - train loss is 16.58766331616789\n",
      "Steps:  87%|▊| 13121/15000 [1:53:37<05:37,  5.57it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:27 - INFO - __main__ - train loss is 16.60668880585581\n",
      "Steps:  87%|▊| 13122/15000 [1:53:38<05:42,  5.49it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:27 - INFO - __main__ - train loss is 16.76847092155367\n",
      "Steps:  87%|▊| 13123/15000 [1:53:38<05:50,  5.36it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:28 - INFO - __main__ - train loss is 16.771567850839347\n",
      "Steps:  87%|▊| 13124/15000 [1:53:38<05:55,  5.27it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:28 - INFO - __main__ - train loss is 16.77727384539321\n",
      "Steps:  88%|▉| 13125/15000 [1:53:38<05:59,  5.22it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:28 - INFO - __main__ - train loss is 16.94255615444854\n",
      "Steps:  88%|▉| 13126/15000 [1:53:38<06:01,  5.18it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:28 - INFO - __main__ - train loss is 16.999417391140014\n",
      "Steps:  88%|▉| 13127/15000 [1:53:39<06:03,  5.16it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:28 - INFO - __main__ - train loss is 17.029251002240926\n",
      "Steps:  88%|▉| 13128/15000 [1:53:39<06:01,  5.18it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:29 - INFO - __main__ - train loss is 17.25033410685137\n",
      "Steps:  88%|▉| 13129/15000 [1:53:39<05:56,  5.25it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:29 - INFO - __main__ - train loss is 17.259208558592945\n",
      "Steps:  88%|▉| 13130/15000 [1:53:39<05:59,  5.21it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:29 - INFO - __main__ - train loss is 17.45500178495422\n",
      "Steps:  88%|▉| 13131/15000 [1:53:39<05:54,  5.27it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:29 - INFO - __main__ - train loss is 17.793770326767117\n",
      "Steps:  88%|▉| 13132/15000 [1:53:40<05:51,  5.31it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:29 - INFO - __main__ - train loss is 17.844807083252817\n",
      "Steps:  88%|▉| 13133/15000 [1:53:40<05:48,  5.35it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:30 - INFO - __main__ - train loss is 17.92691800231114\n",
      "Steps:  88%|▉| 13134/15000 [1:53:40<05:50,  5.33it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:30 - INFO - __main__ - train loss is 17.99884723359719\n",
      "Steps:  88%|▉| 13135/15000 [1:53:40<05:55,  5.25it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:30 - INFO - __main__ - train loss is 18.891301380936056\n",
      "Steps:  88%|▉| 13136/15000 [1:53:40<05:57,  5.21it/s, lr=0.000976, step_loss=0.807/27/2023 19:38:30 - INFO - __main__ - train loss is 19.009132670704275\n",
      "Steps:  88%|▉| 13137/15000 [1:53:41<05:59,  5.19it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:30 - INFO - __main__ - train loss is 19.039953329134732\n",
      "Steps:  88%|▉| 13138/15000 [1:53:41<06:00,  5.17it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:31 - INFO - __main__ - train loss is 19.059735401067883\n",
      "Steps:  88%|▉| 13139/15000 [1:53:41<06:01,  5.15it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:31 - INFO - __main__ - train loss is 19.183344817254692\n",
      "Steps:  88%|▉| 13140/15000 [1:53:41<06:02,  5.13it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:31 - INFO - __main__ - train loss is 19.38429575273767\n",
      "Steps:  88%|▉| 13141/15000 [1:53:41<06:08,  5.05it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:31 - INFO - __main__ - train loss is 19.517428568098694\n",
      "Steps:  88%|▉| 13142/15000 [1:53:41<06:00,  5.16it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:31 - INFO - __main__ - train loss is 20.000862351153046\n",
      "Steps:  88%|▉| 13143/15000 [1:53:42<05:54,  5.24it/s, lr=0.000976, step_loss=0.407/27/2023 19:38:32 - INFO - __main__ - train loss is 20.005779220256954\n",
      "Steps:  88%|▉| 13144/15000 [1:53:42<05:49,  5.31it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:32 - INFO - __main__ - train loss is 20.009593846043572\n",
      "Steps:  88%|▉| 13145/15000 [1:53:42<05:52,  5.27it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:32 - INFO - __main__ - train loss is 20.594678403576836\n",
      "Steps:  88%|▉| 13146/15000 [1:53:42<05:55,  5.21it/s, lr=0.000976, step_loss=0.507/27/2023 19:38:32 - INFO - __main__ - train loss is 20.68341669603251\n",
      "Steps:  88%|▉| 13147/15000 [1:53:42<05:58,  5.17it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:32 - INFO - __main__ - train loss is 20.68884328356944\n",
      "Steps:  88%|▉| 13148/15000 [1:53:43<05:59,  5.15it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:33 - INFO - __main__ - train loss is 21.1508741711732\n",
      "Steps:  88%|▉| 13149/15000 [1:53:43<05:59,  5.15it/s, lr=0.000976, step_loss=0.407/27/2023 19:38:33 - INFO - __main__ - train loss is 21.1838120741304\n",
      "Steps:  88%|▉| 13150/15000 [1:53:43<05:59,  5.15it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:33 - INFO - __main__ - train loss is 21.32130005187355\n",
      "Steps:  88%|▉| 13151/15000 [1:53:43<06:00,  5.13it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:33 - INFO - __main__ - train loss is 21.36295498884283\n",
      "Steps:  88%|▉| 13152/15000 [1:53:43<06:04,  5.07it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:33 - INFO - __main__ - train loss is 21.751197203760967\n",
      "Steps:  88%|▉| 13153/15000 [1:53:44<06:03,  5.08it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:33 - INFO - __main__ - train loss is 21.76066631055437\n",
      "Steps:  88%|▉| 13154/15000 [1:53:44<06:02,  5.09it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:34 - INFO - __main__ - train loss is 21.936560451751575\n",
      "Steps:  88%|▉| 13155/15000 [1:53:44<06:01,  5.10it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:34 - INFO - __main__ - train loss is 22.18359798169695\n",
      "Steps:  88%|▉| 13156/15000 [1:53:44<05:59,  5.13it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:34 - INFO - __main__ - train loss is 22.187768502393737\n",
      "Steps:  88%|▉| 13157/15000 [1:53:44<05:51,  5.25it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:34 - INFO - __main__ - train loss is 22.536243422189727\n",
      "Steps:  88%|▉| 13158/15000 [1:53:45<05:45,  5.34it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:34 - INFO - __main__ - train loss is 22.538954382995144\n",
      "Steps:  88%|▉| 13159/15000 [1:53:45<05:41,  5.40it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:35 - INFO - __main__ - train loss is 22.842470234492794\n",
      "Steps:  88%|▉| 13160/15000 [1:53:45<05:37,  5.45it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:35 - INFO - __main__ - train loss is 22.883595502236858\n",
      "Steps:  88%|▉| 13161/15000 [1:53:45<05:35,  5.48it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:35 - INFO - __main__ - train loss is 22.886920678894967\n",
      "Steps:  88%|▉| 13162/15000 [1:53:45<05:33,  5.50it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:35 - INFO - __main__ - train loss is 23.125872302334756\n",
      "Steps:  88%|▉| 13163/15000 [1:53:45<05:33,  5.51it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:35 - INFO - __main__ - train loss is 23.501987177412957\n",
      "Steps:  88%|▉| 13164/15000 [1:53:46<05:32,  5.53it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:36 - INFO - __main__ - train loss is 23.56394961057231\n",
      "Steps:  88%|▉| 13165/15000 [1:53:46<05:31,  5.54it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:36 - INFO - __main__ - train loss is 23.61960521666333\n",
      "Steps:  88%|▉| 13166/15000 [1:53:46<05:30,  5.55it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:36 - INFO - __main__ - train loss is 23.62188810808584\n",
      "Steps:  88%|▉| 13167/15000 [1:53:46<05:30,  5.55it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:36 - INFO - __main__ - train loss is 23.626205924898386\n",
      "Steps:  88%|▉| 13168/15000 [1:53:46<05:29,  5.56it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:36 - INFO - __main__ - train loss is 23.628141967696138\n",
      "Steps:  88%|▉| 13169/15000 [1:53:47<05:29,  5.56it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:36 - INFO - __main__ - train loss is 23.831263093394227\n",
      "Steps:  88%|▉| 13170/15000 [1:53:47<05:28,  5.57it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:37 - INFO - __main__ - train loss is 24.20054030243773\n",
      "Steps:  88%|▉| 13171/15000 [1:53:47<05:28,  5.57it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:37 - INFO - __main__ - train loss is 24.271821668487974\n",
      "Steps:  88%|▉| 13172/15000 [1:53:47<05:28,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:37 - INFO - __main__ - train loss is 24.353909393888898\n",
      "Steps:  88%|▉| 13173/15000 [1:53:47<05:27,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:37 - INFO - __main__ - train loss is 24.367141922120936\n",
      "Steps:  88%|▉| 13174/15000 [1:53:47<05:27,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:37 - INFO - __main__ - train loss is 24.43837334692944\n",
      "Steps:  88%|▉| 13175/15000 [1:53:48<05:27,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:37 - INFO - __main__ - train loss is 24.71640022576321\n",
      "Steps:  88%|▉| 13176/15000 [1:53:48<05:27,  5.57it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:38 - INFO - __main__ - train loss is 24.92714252055157\n",
      "Steps:  88%|▉| 13177/15000 [1:53:48<05:27,  5.57it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:38 - INFO - __main__ - train loss is 25.080349345807917\n",
      "Steps:  88%|▉| 13178/15000 [1:53:48<05:27,  5.57it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:38 - INFO - __main__ - train loss is 25.08185151196085\n",
      "Steps:  88%|▉| 13179/15000 [1:53:48<05:26,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:38 - INFO - __main__ - train loss is 25.147420570021495\n",
      "Steps:  88%|▉| 13180/15000 [1:53:49<05:26,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:38 - INFO - __main__ - train loss is 25.191447630291805\n",
      "Steps:  88%|▉| 13181/15000 [1:53:49<05:26,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:39 - INFO - __main__ - train loss is 25.273628547554836\n",
      "Steps:  88%|▉| 13182/15000 [1:53:49<05:26,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:39 - INFO - __main__ - train loss is 25.982956424122676\n",
      "Steps:  88%|▉| 13183/15000 [1:53:49<05:26,  5.57it/s, lr=0.000976, step_loss=0.707/27/2023 19:38:39 - INFO - __main__ - train loss is 26.01914807385765\n",
      "Steps:  88%|▉| 13184/15000 [1:53:49<05:26,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:39 - INFO - __main__ - train loss is 26.34595974511467\n",
      "Steps:  88%|▉| 13185/15000 [1:53:49<05:26,  5.56it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:39 - INFO - __main__ - train loss is 26.4706233961042\n",
      "Steps:  88%|▉| 13186/15000 [1:53:50<05:26,  5.56it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:39 - INFO - __main__ - train loss is 26.49144455208443\n",
      "Steps:  88%|▉| 13187/15000 [1:53:50<05:25,  5.56it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:40 - INFO - __main__ - train loss is 26.49996813083999\n",
      "Steps:  88%|▉| 13188/15000 [1:53:50<05:25,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:40 - INFO - __main__ - train loss is 26.61587264831178\n",
      "Steps:  88%|▉| 13189/15000 [1:53:50<05:25,  5.57it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:40 - INFO - __main__ - train loss is 26.812209066702053\n",
      "Steps:  88%|▉| 13190/15000 [1:53:50<05:24,  5.57it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:40 - INFO - __main__ - train loss is 26.89895558054559\n",
      "Steps:  88%|▉| 13191/15000 [1:53:50<05:24,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:40 - INFO - __main__ - train loss is 26.91130827809684\n",
      "Steps:  88%|▉| 13192/15000 [1:53:51<05:24,  5.58it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:41 - INFO - __main__ - train loss is 26.958490655524656\n",
      "Steps:  88%|▉| 13193/15000 [1:53:51<05:24,  5.58it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:41 - INFO - __main__ - train loss is 27.33119182358496\n",
      "Steps:  88%|▉| 13194/15000 [1:53:51<05:23,  5.58it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:41 - INFO - __main__ - train loss is 27.370783773018047\n",
      "Steps:  88%|▉| 13195/15000 [1:53:51<05:23,  5.58it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:41 - INFO - __main__ - train loss is 27.385960072046146\n",
      "Steps:  88%|▉| 13196/15000 [1:53:51<05:24,  5.56it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:41 - INFO - __main__ - train loss is 27.495348572498187\n",
      "Steps:  88%|▉| 13197/15000 [1:53:52<05:24,  5.56it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:41 - INFO - __main__ - train loss is 27.627317756181583\n",
      "Steps:  88%|▉| 13198/15000 [1:53:52<05:23,  5.57it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:42 - INFO - __main__ - train loss is 27.654728904133663\n",
      "Steps:  88%|▉| 13199/15000 [1:53:52<05:23,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:42 - INFO - __main__ - train loss is 27.701747331535444\n",
      "Steps:  88%|▉| 13200/15000 [1:53:52<05:23,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:42 - INFO - __main__ - train loss is 27.71422224282287\n",
      "Steps:  88%|▉| 13201/15000 [1:53:52<05:23,  5.57it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:42 - INFO - __main__ - train loss is 27.813613733043894\n",
      "Steps:  88%|▉| 13202/15000 [1:53:52<05:26,  5.51it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:42 - INFO - __main__ - train loss is 27.884022867074236\n",
      "Steps:  88%|▉| 13203/15000 [1:53:53<05:27,  5.49it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:43 - INFO - __main__ - train loss is 27.918310643872246\n",
      "Steps:  88%|▉| 13204/15000 [1:53:53<05:25,  5.51it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:43 - INFO - __main__ - train loss is 28.112648578127846\n",
      "Steps:  88%|▉| 13205/15000 [1:53:53<05:27,  5.48it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:43 - INFO - __main__ - train loss is 28.36398217245005\n",
      "Steps:  88%|▉| 13206/15000 [1:53:53<05:29,  5.44it/s, lr=0.000976, step_loss=0.207/27/2023 19:38:43 - INFO - __main__ - train loss is 28.487957970937714\n",
      "Steps:  88%|▉| 13207/15000 [1:53:53<05:28,  5.46it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:43 - INFO - __main__ - train loss is 28.552683615824208\n",
      "Steps:  88%|▉| 13208/15000 [1:53:54<05:26,  5.49it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:43 - INFO - __main__ - train loss is 28.882335597416386\n",
      "Steps:  88%|▉| 13209/15000 [1:53:54<05:26,  5.49it/s, lr=0.000976, step_loss=0.307/27/2023 19:38:44 - INFO - __main__ - train loss is 28.942456958582625\n",
      "Steps:  88%|▉| 13210/15000 [1:53:54<05:24,  5.51it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:44 - INFO - __main__ - train loss is 29.084436727454886\n",
      "Steps:  88%|▉| 13211/15000 [1:53:54<05:23,  5.53it/s, lr=0.000976, step_loss=0.107/27/2023 19:38:44 - INFO - __main__ - train loss is 29.110020104562864\n",
      "Steps:  88%|▉| 13212/15000 [1:53:54<05:25,  5.49it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:44 - INFO - __main__ - train loss is 29.185146879171953\n",
      "Steps:  88%|▉| 13213/15000 [1:53:54<05:25,  5.50it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:44 - INFO - __main__ - train loss is 29.23870987049304\n",
      "Steps:  88%|▉| 13214/15000 [1:53:55<05:23,  5.52it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:45 - INFO - __main__ - train loss is 29.24466568767093\n",
      "Steps:  88%|▉| 13215/15000 [1:53:55<05:22,  5.53it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:45 - INFO - __main__ - train loss is 29.75603944598697\n",
      "Steps:  88%|▉| 13216/15000 [1:53:55<05:23,  5.51it/s, lr=0.000976, step_loss=0.507/27/2023 19:38:45 - INFO - __main__ - train loss is 29.757364913471974\n",
      "Steps:  88%|▉| 13217/15000 [1:53:55<05:24,  5.49it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:45 - INFO - __main__ - train loss is 29.794534831889905\n",
      "Steps:  88%|▉| 13218/15000 [1:53:55<05:23,  5.51it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:45 - INFO - __main__ - train loss is 29.804115257808007\n",
      "Steps:  88%|▉| 13219/15000 [1:53:56<05:22,  5.52it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:45 - INFO - __main__ - train loss is 29.821276589878835\n",
      "Steps:  88%|▉| 13220/15000 [1:53:56<05:21,  5.53it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:46 - INFO - __main__ - train loss is 29.845091417082585\n",
      "Steps:  88%|▉| 13221/15000 [1:53:56<05:21,  5.54it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:46 - INFO - __main__ - train loss is 29.873436029651202\n",
      "Steps:  88%|▉| 13222/15000 [1:53:56<05:20,  5.55it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:46 - INFO - __main__ - train loss is 29.913433972396888\n",
      "Steps:  88%|▉| 13223/15000 [1:53:56<05:19,  5.56it/s, lr=0.000976, step_loss=0.007/27/2023 19:38:46 - INFO - __main__ - train loss is 29.962819877662696\n",
      "Steps:  88%|▉| 13224/15000 [1:53:56<05:19,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:46 - INFO - __main__ - train loss is 30.118326726951636\n",
      "Steps:  88%|▉| 13225/15000 [1:53:57<05:21,  5.52it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:47 - INFO - __main__ - train loss is 30.128899188362993\n",
      "Steps:  88%|▉| 13226/15000 [1:53:57<05:20,  5.53it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:47 - INFO - __main__ - train loss is 30.13087586883921\n",
      "Steps:  88%|▉| 13227/15000 [1:53:57<05:20,  5.54it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:47 - INFO - __main__ - train loss is 30.14449375879485\n",
      "Steps:  88%|▉| 13228/15000 [1:53:57<05:19,  5.55it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:47 - INFO - __main__ - train loss is 30.150256664608605\n",
      "Steps:  88%|▉| 13229/15000 [1:53:57<05:18,  5.55it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:47 - INFO - __main__ - train loss is 30.1575284661958\n",
      "Steps:  88%|▉| 13230/15000 [1:53:58<05:18,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:47 - INFO - __main__ - train loss is 30.520997143001296\n",
      "Steps:  88%|▉| 13231/15000 [1:53:58<05:18,  5.56it/s, lr=0.000975, step_loss=0.307/27/2023 19:38:48 - INFO - __main__ - train loss is 30.55271188041661\n",
      "Steps:  88%|▉| 13232/15000 [1:53:58<05:17,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:48 - INFO - __main__ - train loss is 30.637331305653788\n",
      "Steps:  88%|▉| 13233/15000 [1:53:58<05:17,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:48 - INFO - __main__ - train loss is 30.76148146262858\n",
      "Steps:  88%|▉| 13234/15000 [1:53:58<05:17,  5.56it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:48 - INFO - __main__ - train loss is 30.778047653497197\n",
      "Steps:  88%|▉| 13235/15000 [1:53:58<05:17,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:48 - INFO - __main__ - train loss is 30.793497578823008\n",
      "Steps:  88%|▉| 13236/15000 [1:53:59<05:17,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:48 - INFO - __main__ - train loss is 30.858388626598753\n",
      "Steps:  88%|▉| 13237/15000 [1:53:59<05:16,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:49 - INFO - __main__ - train loss is 31.182073199772276\n",
      "Steps:  88%|▉| 13238/15000 [1:53:59<05:16,  5.57it/s, lr=0.000975, step_loss=0.307/27/2023 19:38:49 - INFO - __main__ - train loss is 31.82435455324594\n",
      "Steps:  88%|▉| 13239/15000 [1:53:59<05:16,  5.57it/s, lr=0.000975, step_loss=0.607/27/2023 19:38:49 - INFO - __main__ - train loss is 31.831054442678578\n",
      "Steps:  88%|▉| 13240/15000 [1:53:59<05:16,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:49 - INFO - __main__ - train loss is 31.865707886521704\n",
      "Steps:  88%|▉| 13241/15000 [1:54:00<05:16,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:49 - INFO - __main__ - train loss is 31.938849222962745\n",
      "Steps:  88%|▉| 13242/15000 [1:54:00<05:15,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:50 - INFO - __main__ - train loss is 31.946567798149772\n",
      "Steps:  88%|▉| 13243/15000 [1:54:00<05:15,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:50 - INFO - __main__ - train loss is 31.95008512365166\n",
      "Steps:  88%|▉| 13244/15000 [1:54:00<05:15,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:50 - INFO - __main__ - train loss is 31.969489382230677\n",
      "Steps:  88%|▉| 13245/15000 [1:54:00<05:15,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:50 - INFO - __main__ - train loss is 32.04339726420585\n",
      "Steps:  88%|▉| 13246/15000 [1:54:00<05:16,  5.54it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:50 - INFO - __main__ - train loss is 32.384022907936014\n",
      "Steps:  88%|▉| 13247/15000 [1:54:01<05:18,  5.51it/s, lr=0.000975, step_loss=0.307/27/2023 19:38:50 - INFO - __main__ - train loss is 32.632399664842524\n",
      "Steps:  88%|▉| 13248/15000 [1:54:01<05:17,  5.52it/s, lr=0.000975, step_loss=0.207/27/2023 19:38:51 - INFO - __main__ - train loss is 32.90766482206527\n",
      "Steps:  88%|▉| 13249/15000 [1:54:01<05:18,  5.50it/s, lr=0.000975, step_loss=0.207/27/2023 19:38:51 - INFO - __main__ - train loss is 33.11799878033344\n",
      "Steps:  88%|▉| 13250/15000 [1:54:01<05:16,  5.52it/s, lr=0.000975, step_loss=0.207/27/2023 19:38:51 - INFO - __main__ - train loss is 33.18423866631929\n",
      "Steps:  88%|▉| 13251/15000 [1:54:01<05:15,  5.53it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:51 - INFO - __main__ - train loss is 33.296657377504744\n",
      "Steps:  88%|▉| 13252/15000 [1:54:01<05:15,  5.55it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:51 - INFO - __main__ - train loss is 33.300076077575795\n",
      "Steps:  88%|▉| 13253/15000 [1:54:02<05:14,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:52 - INFO - __main__ - train loss is 33.30851965385955\n",
      "Steps:  88%|▉| 13254/15000 [1:54:02<05:14,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:52 - INFO - __main__ - train loss is 33.32398056413513\n",
      "Steps:  88%|▉| 13255/15000 [1:54:02<05:13,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:52 - INFO - __main__ - train loss is 33.32626700180117\n",
      "Steps:  88%|▉| 13256/15000 [1:54:02<05:13,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:52 - INFO - __main__ - train loss is 33.35576381313149\n",
      "Steps:  88%|▉| 13257/15000 [1:54:02<05:12,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:52 - INFO - __main__ - train loss is 33.43861401604954\n",
      "Steps:  88%|▉| 13258/15000 [1:54:03<05:12,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:52 - INFO - __main__ - train loss is 33.452599265263416\n",
      "Steps:  88%|▉| 13259/15000 [1:54:03<05:12,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:53 - INFO - __main__ - train loss is 33.86746016948018\n",
      "Steps:  88%|▉| 13260/15000 [1:54:03<05:12,  5.57it/s, lr=0.000975, step_loss=0.407/27/2023 19:38:53 - INFO - __main__ - train loss is 33.869535713107325\n",
      "Steps:  88%|▉| 13261/15000 [1:54:03<05:12,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:53 - INFO - __main__ - train loss is 33.90257662406657\n",
      "Steps:  88%|▉| 13262/15000 [1:54:03<05:12,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:53 - INFO - __main__ - train loss is 34.018262280733325\n",
      "Steps:  88%|▉| 13263/15000 [1:54:03<05:12,  5.57it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:53 - INFO - __main__ - train loss is 34.53402294090483\n",
      "Steps:  88%|▉| 13264/15000 [1:54:04<05:11,  5.57it/s, lr=0.000975, step_loss=0.507/27/2023 19:38:54 - INFO - __main__ - train loss is 35.037636532098986\n",
      "Steps:  88%|▉| 13265/15000 [1:54:04<05:11,  5.57it/s, lr=0.000975, step_loss=0.507/27/2023 19:38:54 - INFO - __main__ - train loss is 35.0437959904084\n",
      "Steps:  88%|▉| 13266/15000 [1:54:04<05:12,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:54 - INFO - __main__ - train loss is 35.34484671300743\n",
      "Steps:  88%|▉| 13267/15000 [1:54:04<05:15,  5.50it/s, lr=0.000975, step_loss=0.307/27/2023 19:38:54 - INFO - __main__ - train loss is 35.353053713799454\n",
      "Steps:  88%|▉| 13268/15000 [1:54:04<05:14,  5.51it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:54 - INFO - __main__ - train loss is 35.770382548333146\n",
      "Steps:  88%|▉| 13269/15000 [1:54:05<05:16,  5.47it/s, lr=0.000975, step_loss=0.407/27/2023 19:38:54 - INFO - __main__ - train loss is 35.878697956562974\n",
      "Steps:  88%|▉| 13270/15000 [1:54:05<05:18,  5.43it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:55 - INFO - __main__ - train loss is 36.06052615738008\n",
      "Steps:  88%|▉| 13271/15000 [1:54:05<05:19,  5.41it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:55 - INFO - __main__ - train loss is 36.17274036502931\n",
      "Steps:  88%|▉| 13272/15000 [1:54:05<05:17,  5.45it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:55 - INFO - __main__ - train loss is 36.17394400306512\n",
      "Steps:  88%|▉| 13273/15000 [1:54:05<05:17,  5.43it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:55 - INFO - __main__ - train loss is 36.34212697215844\n",
      "Steps:  88%|▉| 13274/15000 [1:54:05<05:16,  5.45it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:55 - INFO - __main__ - train loss is 36.45816726156045\n",
      "Steps:  88%|▉| 13275/15000 [1:54:06<05:14,  5.49it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:56 - INFO - __main__ - train loss is 36.46053371683229\n",
      "Steps:  89%|▉| 13276/15000 [1:54:06<05:14,  5.48it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:56 - INFO - __main__ - train loss is 36.4734001775505\n",
      "Steps:  89%|▉| 13277/15000 [1:54:06<05:13,  5.50it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:56 - INFO - __main__ - train loss is 36.479740571347065\n",
      "Steps:  89%|▉| 13278/15000 [1:54:06<05:11,  5.52it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:56 - INFO - __main__ - train loss is 36.67338679370005\n",
      "Steps:  89%|▉| 13279/15000 [1:54:06<05:10,  5.54it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:56 - INFO - __main__ - train loss is 36.781827505794354\n",
      "Steps:  89%|▉| 13280/15000 [1:54:07<05:10,  5.54it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:56 - INFO - __main__ - train loss is 36.79743300762493\n",
      "Steps:  89%|▉| 13281/15000 [1:54:07<05:09,  5.55it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:57 - INFO - __main__ - train loss is 36.82453484472353\n",
      "Steps:  89%|▉| 13282/15000 [1:54:07<05:12,  5.50it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:57 - INFO - __main__ - train loss is 36.86273123708088\n",
      "Steps:  89%|▉| 13283/15000 [1:54:07<05:14,  5.45it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:57 - INFO - __main__ - train loss is 36.865025557228364\n",
      "Steps:  89%|▉| 13284/15000 [1:54:07<05:15,  5.43it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:57 - INFO - __main__ - train loss is 36.91660579259042\n",
      "Steps:  89%|▉| 13285/15000 [1:54:07<05:14,  5.45it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:57 - INFO - __main__ - train loss is 36.997663326212205\n",
      "Steps:  89%|▉| 13286/15000 [1:54:08<05:14,  5.44it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:58 - INFO - __main__ - train loss is 37.11948181653861\n",
      "Steps:  89%|▉| 13287/15000 [1:54:08<05:15,  5.43it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:58 - INFO - __main__ - train loss is 37.18645003403071\n",
      "Steps:  89%|▉| 13288/15000 [1:54:08<05:13,  5.46it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:58 - INFO - __main__ - train loss is 37.21722323971335\n",
      "Steps:  89%|▉| 13289/15000 [1:54:08<05:11,  5.49it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:58 - INFO - __main__ - train loss is 37.22854670940433\n",
      "Steps:  89%|▉| 13290/15000 [1:54:08<05:10,  5.51it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:58 - INFO - __main__ - train loss is 37.610227347002365\n",
      "Steps:  89%|▉| 13291/15000 [1:54:09<05:12,  5.47it/s, lr=0.000975, step_loss=0.307/27/2023 19:38:58 - INFO - __main__ - train loss is 37.76890394149814\n",
      "Steps:  89%|▉| 13292/15000 [1:54:09<05:14,  5.43it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:59 - INFO - __main__ - train loss is 37.891909212456085\n",
      "Steps:  89%|▉| 13293/15000 [1:54:09<05:15,  5.40it/s, lr=0.000975, step_loss=0.107/27/2023 19:38:59 - INFO - __main__ - train loss is 37.97698204277549\n",
      "Steps:  89%|▉| 13294/15000 [1:54:09<05:14,  5.43it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:59 - INFO - __main__ - train loss is 37.9816956409486\n",
      "Steps:  89%|▉| 13295/15000 [1:54:09<05:13,  5.44it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:59 - INFO - __main__ - train loss is 37.99346663628239\n",
      "Steps:  89%|▉| 13296/15000 [1:54:10<05:14,  5.42it/s, lr=0.000975, step_loss=0.007/27/2023 19:38:59 - INFO - __main__ - train loss is 38.018478484940715\n",
      "Steps:  89%|▉| 13297/15000 [1:54:10<05:13,  5.43it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:00 - INFO - __main__ - train loss is 38.02047451923136\n",
      "Steps:  89%|▉| 13298/15000 [1:54:10<05:13,  5.43it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:00 - INFO - __main__ - train loss is 38.19217857311014\n",
      "Steps:  89%|▉| 13299/15000 [1:54:10<05:14,  5.41it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:00 - INFO - __main__ - train loss is 38.306100424029864\n",
      "Steps:  89%|▉| 13300/15000 [1:54:10<05:15,  5.39it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:00 - INFO - __main__ - train loss is 38.36465044284705\n",
      "Steps:  89%|▉| 13301/15000 [1:54:10<05:14,  5.41it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:00 - INFO - __main__ - train loss is 38.668110444792546\n",
      "Steps:  89%|▉| 13302/15000 [1:54:11<05:11,  5.45it/s, lr=0.000975, step_loss=0.307/27/2023 19:39:00 - INFO - __main__ - train loss is 38.79680801893119\n",
      "Steps:  89%|▉| 13303/15000 [1:54:11<05:09,  5.48it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:01 - INFO - __main__ - train loss is 38.798048887751065\n",
      "Steps:  89%|▉| 13304/15000 [1:54:11<05:10,  5.45it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:01 - INFO - __main__ - train loss is 38.819994695833884\n",
      "Steps:  89%|▉| 13305/15000 [1:54:11<05:10,  5.47it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:01 - INFO - __main__ - train loss is 38.84373710711952\n",
      "Steps:  89%|▉| 13306/15000 [1:54:11<05:08,  5.49it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:01 - INFO - __main__ - train loss is 38.865871787420474\n",
      "Steps:  89%|▉| 13307/15000 [1:54:12<05:07,  5.51it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:01 - INFO - __main__ - train loss is 38.90258905326482\n",
      "Steps:  89%|▉| 13308/15000 [1:54:12<05:06,  5.51it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:02 - INFO - __main__ - train loss is 38.9496682662284\n",
      "Steps:  89%|▉| 13309/15000 [1:54:12<05:06,  5.53it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:02 - INFO - __main__ - train loss is 39.178706296137534\n",
      "Steps:  89%|▉| 13310/15000 [1:54:12<05:06,  5.52it/s, lr=0.000975, step_loss=0.207/27/2023 19:39:02 - INFO - __main__ - train loss is 39.30414214020129\n",
      "Steps:  89%|▉| 13311/15000 [1:54:12<05:05,  5.53it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:02 - INFO - __main__ - train loss is 39.38887188618537\n",
      "Steps:  89%|▉| 13312/15000 [1:54:12<05:04,  5.54it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:02 - INFO - __main__ - train loss is 39.50376414542552\n",
      "Steps:  89%|▉| 13313/15000 [1:54:13<05:04,  5.54it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:02 - INFO - __main__ - train loss is 39.70029708032962\n",
      "Steps:  89%|▉| 13314/15000 [1:54:13<05:06,  5.50it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:03 - INFO - __main__ - train loss is 39.883083470514975\n",
      "Steps:  89%|▉| 13315/15000 [1:54:13<05:06,  5.50it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:03 - INFO - __main__ - train loss is 39.88658480544109\n",
      "Steps:  89%|▉| 13316/15000 [1:54:13<05:07,  5.47it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:03 - INFO - __main__ - train loss is 40.018332930398174\n",
      "Steps:  89%|▉| 13317/15000 [1:54:13<05:06,  5.49it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:03 - INFO - __main__ - train loss is 40.09851850022096\n",
      "Steps:  89%|▉| 13318/15000 [1:54:14<05:05,  5.51it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:03 - INFO - __main__ - train loss is 40.23293658543844\n",
      "Steps:  89%|▉| 13319/15000 [1:54:14<05:06,  5.49it/s, lr=0.000975, step_loss=0.107/27/2023 19:39:04 - INFO - __main__ - train loss is 40.54004719306249\n",
      "Steps:  89%|▉| 13320/15000 [1:54:14<05:04,  5.52it/s, lr=0.000975, step_loss=0.307/27/2023 19:39:04 - INFO - __main__ - train loss is 41.027335072052665\n",
      "Steps:  89%|▉| 13321/15000 [1:54:14<05:02,  5.54it/s, lr=0.000975, step_loss=0.407/27/2023 19:39:04 - INFO - __main__ - train loss is 41.052632348728366\n",
      "Steps:  89%|▉| 13322/15000 [1:54:14<05:02,  5.55it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:04 - INFO - __main__ - train loss is 41.080425743130036\n",
      "Steps:  89%|▉| 13323/15000 [1:54:14<05:01,  5.56it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:04 - INFO - __main__ - train loss is 41.09100871544797\n",
      "Steps:  89%|▉| 13324/15000 [1:54:15<05:01,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:04 - INFO - __main__ - train loss is 41.15786909323651\n",
      "Steps:  89%|▉| 13325/15000 [1:54:15<05:00,  5.57it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:05 - INFO - __main__ - train loss is 41.56633233290631\n",
      "Steps:  89%|▉| 13326/15000 [1:54:15<05:00,  5.57it/s, lr=0.000975, step_loss=0.407/27/2023 19:39:05 - INFO - __main__ - train loss is 41.85301154118497\n",
      "Steps:  89%|▉| 13327/15000 [1:54:15<05:00,  5.57it/s, lr=0.000975, step_loss=0.207/27/2023 19:39:05 - INFO - __main__ - train loss is 41.92592074733693\n",
      "Steps:  89%|▉| 13328/15000 [1:54:15<04:59,  5.58it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:05 - INFO - __main__ - train loss is 41.93937690008897\n",
      "Steps:  89%|▉| 13329/15000 [1:54:15<04:59,  5.58it/s, lr=0.000975, step_loss=0.007/27/2023 19:39:05 - INFO - __main__ - train loss is 42.410351881873794\n",
      "Steps:  89%|▉| 13330/15000 [1:54:16<04:59,  5.58it/s, lr=0.000974, step_loss=0.407/27/2023 19:39:06 - INFO - __main__ - train loss is 42.448174974066205\n",
      "Steps:  89%|▉| 13331/15000 [1:54:16<04:58,  5.58it/s, lr=0.000974, step_loss=0.007/27/2023 19:39:06 - INFO - __main__ - train loss is 42.5871226695599\n",
      "Steps:  89%|▉| 13332/15000 [1:54:16<07:08,  3.89it/s, lr=0.000974, step_loss=0.107/27/2023 19:39:07 - INFO - __main__ - Per validation step average loss is 0.009190984070301056\n",
      "07/27/2023 19:39:07 - INFO - __main__ - Cumulative validation average loss is 0.009190984070301056\n",
      "07/27/2023 19:39:07 - INFO - __main__ - Per validation step average loss is 0.20948722958564758\n",
      "07/27/2023 19:39:07 - INFO - __main__ - Cumulative validation average loss is 0.21867821365594864\n",
      "07/27/2023 19:39:08 - INFO - __main__ - Per validation step average loss is 0.011014852672815323\n",
      "07/27/2023 19:39:08 - INFO - __main__ - Cumulative validation average loss is 0.22969306632876396\n",
      "07/27/2023 19:39:08 - INFO - __main__ - Per validation step average loss is 0.17912599444389343\n",
      "07/27/2023 19:39:08 - INFO - __main__ - Cumulative validation average loss is 0.4088190607726574\n",
      "07/27/2023 19:39:09 - INFO - __main__ - Per validation step average loss is 0.35694706439971924\n",
      "07/27/2023 19:39:09 - INFO - __main__ - Cumulative validation average loss is 0.7657661251723766\n",
      "07/27/2023 19:39:09 - INFO - __main__ - Per validation step average loss is 0.006378103047609329\n",
      "07/27/2023 19:39:09 - INFO - __main__ - Cumulative validation average loss is 0.772144228219986\n",
      "07/27/2023 19:39:10 - INFO - __main__ - Per validation step average loss is 0.1509460061788559\n",
      "07/27/2023 19:39:10 - INFO - __main__ - Cumulative validation average loss is 0.9230902343988419\n",
      "07/27/2023 19:39:10 - INFO - __main__ - Per validation step average loss is 0.0016858677845448256\n",
      "07/27/2023 19:39:10 - INFO - __main__ - Cumulative validation average loss is 0.9247761021833867\n",
      "07/27/2023 19:39:10 - INFO - __main__ - Per validation step average loss is 0.06452912092208862\n",
      "07/27/2023 19:39:10 - INFO - __main__ - Cumulative validation average loss is 0.9893052231054753\n",
      "07/27/2023 19:39:11 - INFO - __main__ - Per validation step average loss is 0.05112019553780556\n",
      "07/27/2023 19:39:11 - INFO - __main__ - Cumulative validation average loss is 1.0404254186432809\n",
      "07/27/2023 19:39:11 - INFO - __main__ - Per validation step average loss is 0.2286897599697113\n",
      "07/27/2023 19:39:11 - INFO - __main__ - Cumulative validation average loss is 1.2691151786129922\n",
      "07/27/2023 19:39:12 - INFO - __main__ - Per validation step average loss is 0.22418855130672455\n",
      "07/27/2023 19:39:12 - INFO - __main__ - Cumulative validation average loss is 1.4933037299197167\n",
      "07/27/2023 19:39:12 - INFO - __main__ - Per validation step average loss is 0.02994532510638237\n",
      "07/27/2023 19:39:12 - INFO - __main__ - Cumulative validation average loss is 1.523249055026099\n",
      "07/27/2023 19:39:12 - INFO - __main__ - Per validation step average loss is 0.002283473964780569\n",
      "07/27/2023 19:39:12 - INFO - __main__ - Cumulative validation average loss is 1.5255325289908797\n",
      "07/27/2023 19:39:13 - INFO - __main__ - Per validation step average loss is 0.05917667970061302\n",
      "07/27/2023 19:39:13 - INFO - __main__ - Cumulative validation average loss is 1.5847092086914927\n",
      "07/27/2023 19:39:13 - INFO - __main__ - Per validation step average loss is 0.6478705406188965\n",
      "07/27/2023 19:39:13 - INFO - __main__ - Cumulative validation average loss is 2.232579749310389\n",
      "07/27/2023 19:39:14 - INFO - __main__ - Per validation step average loss is 0.024882527068257332\n",
      "07/27/2023 19:39:14 - INFO - __main__ - Cumulative validation average loss is 2.2574622763786465\n",
      "07/27/2023 19:39:14 - INFO - __main__ - Per validation step average loss is 0.1729069948196411\n",
      "07/27/2023 19:39:14 - INFO - __main__ - Cumulative validation average loss is 2.4303692711982876\n",
      "07/27/2023 19:39:15 - INFO - __main__ - Per validation step average loss is 0.020788395777344704\n",
      "07/27/2023 19:39:15 - INFO - __main__ - Cumulative validation average loss is 2.4511576669756323\n",
      "07/27/2023 19:39:15 - INFO - __main__ - Per validation step average loss is 0.17402797937393188\n",
      "07/27/2023 19:39:15 - INFO - __main__ - Cumulative validation average loss is 2.625185646349564\n",
      "07/27/2023 19:39:15 - INFO - __main__ - Per validation step average loss is 0.08424804359674454\n",
      "07/27/2023 19:39:15 - INFO - __main__ - Cumulative validation average loss is 2.7094336899463087\n",
      "07/27/2023 19:39:16 - INFO - __main__ - Per validation step average loss is 0.012779297307133675\n",
      "07/27/2023 19:39:16 - INFO - __main__ - Cumulative validation average loss is 2.7222129872534424\n",
      "07/27/2023 19:39:16 - INFO - __main__ - Per validation step average loss is 0.6744214296340942\n",
      "07/27/2023 19:39:16 - INFO - __main__ - Cumulative validation average loss is 3.3966344168875366\n",
      "07/27/2023 19:39:17 - INFO - __main__ - Per validation step average loss is 0.016774645075201988\n",
      "07/27/2023 19:39:17 - INFO - __main__ - Cumulative validation average loss is 3.4134090619627386\n",
      "07/27/2023 19:39:17 - INFO - __main__ - Per validation step average loss is 0.08926317095756531\n",
      "07/27/2023 19:39:17 - INFO - __main__ - Cumulative validation average loss is 3.502672232920304\n",
      "07/27/2023 19:39:17 - INFO - __main__ - Per validation step average loss is 0.11694762110710144\n",
      "07/27/2023 19:39:17 - INFO - __main__ - Cumulative validation average loss is 3.6196198540274054\n",
      "07/27/2023 19:39:18 - INFO - __main__ - Per validation step average loss is 0.0084462258964777\n",
      "07/27/2023 19:39:18 - INFO - __main__ - Cumulative validation average loss is 3.628066079923883\n",
      "07/27/2023 19:39:18 - INFO - __main__ - Per validation step average loss is 0.0012512996327131987\n",
      "07/27/2023 19:39:18 - INFO - __main__ - Cumulative validation average loss is 3.6293173795565963\n",
      "07/27/2023 19:39:19 - INFO - __main__ - Per validation step average loss is 0.26667746901512146\n",
      "07/27/2023 19:39:19 - INFO - __main__ - Cumulative validation average loss is 3.8959948485717177\n",
      "07/27/2023 19:39:19 - INFO - __main__ - Per validation step average loss is 0.19062092900276184\n",
      "07/27/2023 19:39:19 - INFO - __main__ - Cumulative validation average loss is 4.08661577757448\n",
      "07/27/2023 19:39:20 - INFO - __main__ - Per validation step average loss is 0.0015226817922666669\n",
      "07/27/2023 19:39:20 - INFO - __main__ - Cumulative validation average loss is 4.088138459366746\n",
      "07/27/2023 19:39:20 - INFO - __main__ - Per validation step average loss is 0.3209099769592285\n",
      "07/27/2023 19:39:20 - INFO - __main__ - Cumulative validation average loss is 4.409048436325975\n",
      "07/27/2023 19:39:20 - INFO - __main__ - Per validation step average loss is 0.22242777049541473\n",
      "07/27/2023 19:39:20 - INFO - __main__ - Cumulative validation average loss is 4.6314762068213895\n",
      "07/27/2023 19:39:21 - INFO - __main__ - Per validation step average loss is 0.01030416414141655\n",
      "07/27/2023 19:39:21 - INFO - __main__ - Cumulative validation average loss is 4.641780370962806\n",
      "07/27/2023 19:39:21 - INFO - __main__ - Per validation step average loss is 0.38226085901260376\n",
      "07/27/2023 19:39:21 - INFO - __main__ - Cumulative validation average loss is 5.02404122997541\n",
      "07/27/2023 19:39:22 - INFO - __main__ - Per validation step average loss is 0.04455708712339401\n",
      "07/27/2023 19:39:22 - INFO - __main__ - Cumulative validation average loss is 5.068598317098804\n",
      "07/27/2023 19:39:22 - INFO - __main__ - Per validation step average loss is 0.008264112286269665\n",
      "07/27/2023 19:39:22 - INFO - __main__ - Cumulative validation average loss is 5.0768624293850735\n",
      "07/27/2023 19:39:22 - INFO - __main__ - Per validation step average loss is 0.0019797859713435173\n",
      "07/27/2023 19:39:22 - INFO - __main__ - Cumulative validation average loss is 5.078842215356417\n",
      "07/27/2023 19:39:23 - INFO - __main__ - Per validation step average loss is 0.5963559746742249\n",
      "07/27/2023 19:39:23 - INFO - __main__ - Cumulative validation average loss is 5.675198190030642\n",
      "07/27/2023 19:39:23 - INFO - __main__ - Per validation step average loss is 0.0747983306646347\n",
      "07/27/2023 19:39:23 - INFO - __main__ - Cumulative validation average loss is 5.749996520695277\n",
      "07/27/2023 19:39:24 - INFO - __main__ - Per validation step average loss is 0.04913428798317909\n",
      "07/27/2023 19:39:24 - INFO - __main__ - Cumulative validation average loss is 5.799130808678456\n",
      "07/27/2023 19:39:24 - INFO - __main__ - Per validation step average loss is 0.2661682367324829\n",
      "07/27/2023 19:39:24 - INFO - __main__ - Cumulative validation average loss is 6.065299045410939\n",
      "07/27/2023 19:39:25 - INFO - __main__ - Per validation step average loss is 0.061415158212184906\n",
      "07/27/2023 19:39:25 - INFO - __main__ - Cumulative validation average loss is 6.1267142036231235\n",
      "07/27/2023 19:39:25 - INFO - __main__ - Per validation step average loss is 0.09555195271968842\n",
      "07/27/2023 19:39:25 - INFO - __main__ - Cumulative validation average loss is 6.222266156342812\n",
      "07/27/2023 19:39:25 - INFO - __main__ - Per validation step average loss is 0.0024976427666842937\n",
      "07/27/2023 19:39:25 - INFO - __main__ - Cumulative validation average loss is 6.224763799109496\n",
      "07/27/2023 19:39:26 - INFO - __main__ - Per validation step average loss is 0.0010641571134328842\n",
      "07/27/2023 19:39:26 - INFO - __main__ - Cumulative validation average loss is 6.225827956222929\n",
      "07/27/2023 19:39:26 - INFO - __main__ - Per validation step average loss is 0.006146775558590889\n",
      "07/27/2023 19:39:26 - INFO - __main__ - Cumulative validation average loss is 6.23197473178152\n",
      "07/27/2023 19:39:27 - INFO - __main__ - Per validation step average loss is 0.1618545651435852\n",
      "07/27/2023 19:39:27 - INFO - __main__ - Cumulative validation average loss is 6.393829296925105\n",
      "07/27/2023 19:39:27 - INFO - __main__ - Per validation step average loss is 0.34247663617134094\n",
      "07/27/2023 19:39:27 - INFO - __main__ - Cumulative validation average loss is 6.736305933096446\n",
      "07/27/2023 19:39:27 - INFO - __main__ - Per validation step average loss is 0.0016155042685568333\n",
      "07/27/2023 19:39:27 - INFO - __main__ - Cumulative validation average loss is 6.737921437365003\n",
      "07/27/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.04051220789551735\n",
      "07/27/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 6.77843364526052\n",
      "07/27/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.008909598924219608\n",
      "07/27/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 6.78734324418474\n",
      "07/27/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.24114003777503967\n",
      "07/27/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 7.02848328195978\n",
      "07/27/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.6408450603485107\n",
      "07/27/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 7.66932834230829\n",
      "07/27/2023 19:39:30 - INFO - __main__ - Per validation step average loss is 0.24446368217468262\n",
      "07/27/2023 19:39:30 - INFO - __main__ - Cumulative validation average loss is 7.913792024482973\n",
      "07/27/2023 19:39:30 - INFO - __main__ - Per validation step average loss is 0.005893314257264137\n",
      "07/27/2023 19:39:30 - INFO - __main__ - Cumulative validation average loss is 7.919685338740237\n",
      "07/27/2023 19:39:30 - INFO - __main__ - Per validation step average loss is 0.26718324422836304\n",
      "07/27/2023 19:39:30 - INFO - __main__ - Cumulative validation average loss is 8.1868685829686\n",
      "07/27/2023 19:39:31 - INFO - __main__ - Per validation step average loss is 0.015500415116548538\n",
      "07/27/2023 19:39:31 - INFO - __main__ - Cumulative validation average loss is 8.202368998085149\n",
      "07/27/2023 19:39:31 - INFO - __main__ - Per validation step average loss is 0.22757136821746826\n",
      "07/27/2023 19:39:31 - INFO - __main__ - Cumulative validation average loss is 8.429940366302617\n",
      "07/27/2023 19:39:32 - INFO - __main__ - Per validation step average loss is 0.03453218936920166\n",
      "07/27/2023 19:39:32 - INFO - __main__ - Cumulative validation average loss is 8.464472555671819\n",
      "07/27/2023 19:39:32 - INFO - __main__ - Per validation step average loss is 0.13423989713191986\n",
      "07/27/2023 19:39:32 - INFO - __main__ - Cumulative validation average loss is 8.598712452803738\n",
      "07/27/2023 19:39:33 - INFO - __main__ - Per validation step average loss is 0.009903199970722198\n",
      "07/27/2023 19:39:33 - INFO - __main__ - Cumulative validation average loss is 8.60861565277446\n",
      "07/27/2023 19:39:33 - INFO - __main__ - Per validation step average loss is 0.09290574491024017\n",
      "07/27/2023 19:39:33 - INFO - __main__ - Cumulative validation average loss is 8.7015213976847\n",
      "07/27/2023 19:39:33 - INFO - __main__ - Per validation step average loss is 0.0049709659069776535\n",
      "07/27/2023 19:39:33 - INFO - __main__ - Cumulative validation average loss is 8.706492363591678\n",
      "07/27/2023 19:39:34 - INFO - __main__ - Per validation step average loss is 0.03467923030257225\n",
      "07/27/2023 19:39:34 - INFO - __main__ - Cumulative validation average loss is 8.74117159389425\n",
      "07/27/2023 19:39:34 - INFO - __main__ - Per validation step average loss is 0.3390074074268341\n",
      "07/27/2023 19:39:34 - INFO - __main__ - Cumulative validation average loss is 9.080179001321085\n",
      "07/27/2023 19:39:35 - INFO - __main__ - Per validation step average loss is 0.04019836708903313\n",
      "07/27/2023 19:39:35 - INFO - __main__ - Cumulative validation average loss is 9.120377368410118\n",
      "07/27/2023 19:39:35 - INFO - __main__ - Per validation step average loss is 0.13005779683589935\n",
      "07/27/2023 19:39:35 - INFO - __main__ - Cumulative validation average loss is 9.250435165246017\n",
      "07/27/2023 19:39:35 - INFO - __main__ - Per validation step average loss is 0.0072426991537213326\n",
      "07/27/2023 19:39:35 - INFO - __main__ - Cumulative validation average loss is 9.257677864399739\n",
      "07/27/2023 19:39:36 - INFO - __main__ - Per validation step average loss is 0.05486579239368439\n",
      "07/27/2023 19:39:36 - INFO - __main__ - Cumulative validation average loss is 9.312543656793423\n",
      "07/27/2023 19:39:36 - INFO - __main__ - Per validation step average loss is 0.10574270784854889\n",
      "07/27/2023 19:39:36 - INFO - __main__ - Cumulative validation average loss is 9.418286364641972\n",
      "07/27/2023 19:39:37 - INFO - __main__ - Per validation step average loss is 0.006467180326581001\n",
      "07/27/2023 19:39:37 - INFO - __main__ - Cumulative validation average loss is 9.424753544968553\n",
      "07/27/2023 19:39:37 - INFO - __main__ - Per validation step average loss is 0.17919185757637024\n",
      "07/27/2023 19:39:37 - INFO - __main__ - Cumulative validation average loss is 9.603945402544923\n",
      "07/27/2023 19:39:38 - INFO - __main__ - Per validation step average loss is 0.15910430252552032\n",
      "07/27/2023 19:39:38 - INFO - __main__ - Cumulative validation average loss is 9.763049705070443\n",
      "07/27/2023 19:39:38 - INFO - __main__ - Per validation step average loss is 0.18614356219768524\n",
      "07/27/2023 19:39:38 - INFO - __main__ - Cumulative validation average loss is 9.949193267268129\n",
      "07/27/2023 19:39:38 - INFO - __main__ - Per validation step average loss is 0.42118000984191895\n",
      "07/27/2023 19:39:38 - INFO - __main__ - Cumulative validation average loss is 10.370373277110048\n",
      "07/27/2023 19:39:39 - INFO - __main__ - Per validation step average loss is 0.15738904476165771\n",
      "07/27/2023 19:39:39 - INFO - __main__ - Cumulative validation average loss is 10.527762321871705\n",
      "07/27/2023 19:39:39 - INFO - __main__ - Per validation step average loss is 0.20812058448791504\n",
      "07/27/2023 19:39:39 - INFO - __main__ - Cumulative validation average loss is 10.73588290635962\n",
      "07/27/2023 19:39:40 - INFO - __main__ - Per validation step average loss is 0.9176447987556458\n",
      "07/27/2023 19:39:40 - INFO - __main__ - Cumulative validation average loss is 11.653527705115266\n",
      "07/27/2023 19:39:40 - INFO - __main__ - Average validation loss for Epoch 43 is 0.1475130089255097\n",
      "07/27/2023 19:39:40 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:40:37 - INFO - __main__ - Starting epoch 44\n",
      "07/27/2023 19:40:38 - INFO - __main__ - train loss is 0.038553617894649506\n",
      "Steps:  89%|▉| 13333/15000 [1:55:48<12:51:58, 27.79s/it, lr=0.000974, step_loss=07/27/2023 19:40:38 - INFO - __main__ - train loss is 0.05355958454310894\n",
      "Steps:  89%|▉| 13334/15000 [1:55:48<9:01:33, 19.50s/it, lr=0.000974, step_loss=007/27/2023 19:40:38 - INFO - __main__ - train loss is 0.18761190585792065\n",
      "Steps:  89%|▉| 13335/15000 [1:55:49<6:20:21, 13.71s/it, lr=0.000974, step_loss=007/27/2023 19:40:39 - INFO - __main__ - train loss is 0.35796756856143475\n",
      "Steps:  89%|▉| 13336/15000 [1:55:49<4:27:37,  9.65s/it, lr=0.000974, step_loss=007/27/2023 19:40:39 - INFO - __main__ - train loss is 0.38185875676572323\n",
      "Steps:  89%|▉| 13337/15000 [1:55:49<3:08:44,  6.81s/it, lr=0.000974, step_loss=007/27/2023 19:40:39 - INFO - __main__ - train loss is 0.5531902518123388\n",
      "Steps:  89%|▉| 13338/15000 [1:55:49<2:13:32,  4.82s/it, lr=0.000974, step_loss=007/27/2023 19:40:39 - INFO - __main__ - train loss is 0.8618273045867682\n",
      "Steps:  89%|▉| 13339/15000 [1:55:49<1:34:56,  3.43s/it, lr=0.000974, step_loss=007/27/2023 19:40:39 - INFO - __main__ - train loss is 0.8889055885374546\n",
      "Steps:  89%|▉| 13340/15000 [1:55:50<1:07:54,  2.45s/it, lr=0.000974, step_loss=007/27/2023 19:40:39 - INFO - __main__ - train loss is 1.3867322243750095\n",
      "Steps:  89%|▉| 13341/15000 [1:55:50<49:02,  1.77s/it, lr=0.000974, step_loss=0.407/27/2023 19:40:40 - INFO - __main__ - train loss is 1.5262046940624714\n",
      "Steps:  89%|▉| 13342/15000 [1:55:50<35:48,  1.30s/it, lr=0.000974, step_loss=0.107/27/2023 19:40:40 - INFO - __main__ - train loss is 1.528494896600023\n",
      "Steps:  89%|▉| 13343/15000 [1:55:50<26:33,  1.04it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:40 - INFO - __main__ - train loss is 1.5374575594905764\n",
      "Steps:  89%|▉| 13344/15000 [1:55:50<20:04,  1.37it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:40 - INFO - __main__ - train loss is 1.8468243817333132\n",
      "Steps:  89%|▉| 13345/15000 [1:55:50<15:33,  1.77it/s, lr=0.000974, step_loss=0.307/27/2023 19:40:40 - INFO - __main__ - train loss is 1.9111566732171923\n",
      "Steps:  89%|▉| 13346/15000 [1:55:51<12:23,  2.23it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:41 - INFO - __main__ - train loss is 2.6131148526910692\n",
      "Steps:  89%|▉| 13347/15000 [1:55:51<10:09,  2.71it/s, lr=0.000974, step_loss=0.707/27/2023 19:40:41 - INFO - __main__ - train loss is 2.977867681765929\n",
      "Steps:  89%|▉| 13348/15000 [1:55:51<08:36,  3.20it/s, lr=0.000974, step_loss=0.307/27/2023 19:40:41 - INFO - __main__ - train loss is 3.2595116088632494\n",
      "Steps:  89%|▉| 13349/15000 [1:55:51<07:30,  3.67it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:41 - INFO - __main__ - train loss is 3.3418166677001864\n",
      "Steps:  89%|▉| 13350/15000 [1:55:51<06:44,  4.08it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:41 - INFO - __main__ - train loss is 3.3432017537998036\n",
      "Steps:  89%|▉| 13351/15000 [1:55:52<06:11,  4.44it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:41 - INFO - __main__ - train loss is 3.6086020442890003\n",
      "Steps:  89%|▉| 13352/15000 [1:55:52<05:49,  4.72it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:42 - INFO - __main__ - train loss is 3.8060133430408314\n",
      "Steps:  89%|▉| 13353/15000 [1:55:52<05:33,  4.94it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:42 - INFO - __main__ - train loss is 3.8805758032249287\n",
      "Steps:  89%|▉| 13354/15000 [1:55:52<05:21,  5.11it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:42 - INFO - __main__ - train loss is 4.100098592345603\n",
      "Steps:  89%|▉| 13355/15000 [1:55:52<05:14,  5.24it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:42 - INFO - __main__ - train loss is 4.117986780707724\n",
      "Steps:  89%|▉| 13356/15000 [1:55:52<05:08,  5.33it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:42 - INFO - __main__ - train loss is 4.171544277225621\n",
      "Steps:  89%|▉| 13357/15000 [1:55:53<05:07,  5.35it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:43 - INFO - __main__ - train loss is 4.284218260203488\n",
      "Steps:  89%|▉| 13358/15000 [1:55:53<05:05,  5.37it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:43 - INFO - __main__ - train loss is 4.6007230068789795\n",
      "Steps:  89%|▉| 13359/15000 [1:55:53<05:01,  5.44it/s, lr=0.000974, step_loss=0.307/27/2023 19:40:43 - INFO - __main__ - train loss is 4.732495078002103\n",
      "Steps:  89%|▉| 13360/15000 [1:55:53<04:59,  5.48it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:43 - INFO - __main__ - train loss is 4.756807402824052\n",
      "Steps:  89%|▉| 13361/15000 [1:55:53<04:57,  5.51it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:43 - INFO - __main__ - train loss is 4.834445924614556\n",
      "Steps:  89%|▉| 13362/15000 [1:55:54<04:56,  5.53it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:43 - INFO - __main__ - train loss is 4.907677889917977\n",
      "Steps:  89%|▉| 13363/15000 [1:55:54<04:55,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:44 - INFO - __main__ - train loss is 5.2782454501139\n",
      "Steps:  89%|▉| 13364/15000 [1:55:54<04:54,  5.56it/s, lr=0.000974, step_loss=0.307/27/2023 19:40:44 - INFO - __main__ - train loss is 5.286640132893808\n",
      "Steps:  89%|▉| 13365/15000 [1:55:54<04:53,  5.56it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:44 - INFO - __main__ - train loss is 5.309045662288554\n",
      "Steps:  89%|▉| 13366/15000 [1:55:54<04:53,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:44 - INFO - __main__ - train loss is 5.31135436531622\n",
      "Steps:  89%|▉| 13367/15000 [1:55:54<04:53,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:44 - INFO - __main__ - train loss is 5.550631608930416\n",
      "Steps:  89%|▉| 13368/15000 [1:55:55<04:52,  5.58it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:45 - INFO - __main__ - train loss is 5.581648698193021\n",
      "Steps:  89%|▉| 13369/15000 [1:55:55<04:52,  5.58it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:45 - INFO - __main__ - train loss is 5.787632024032064\n",
      "Steps:  89%|▉| 13370/15000 [1:55:55<04:54,  5.53it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:45 - INFO - __main__ - train loss is 5.8005745188565925\n",
      "Steps:  89%|▉| 13371/15000 [1:55:55<04:53,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:45 - INFO - __main__ - train loss is 5.809373982367106\n",
      "Steps:  89%|▉| 13372/15000 [1:55:55<04:53,  5.55it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:45 - INFO - __main__ - train loss is 5.909507803735323\n",
      "Steps:  89%|▉| 13373/15000 [1:55:56<04:52,  5.56it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:45 - INFO - __main__ - train loss is 6.018394209560938\n",
      "Steps:  89%|▉| 13374/15000 [1:55:56<04:52,  5.56it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:46 - INFO - __main__ - train loss is 6.026473930221982\n",
      "Steps:  89%|▉| 13375/15000 [1:55:56<04:51,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:46 - INFO - __main__ - train loss is 6.518425336224027\n",
      "Steps:  89%|▉| 13376/15000 [1:55:56<04:51,  5.57it/s, lr=0.000974, step_loss=0.407/27/2023 19:40:46 - INFO - __main__ - train loss is 6.549818230909295\n",
      "Steps:  89%|▉| 13377/15000 [1:55:56<04:51,  5.58it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:46 - INFO - __main__ - train loss is 6.583538489532657\n",
      "Steps:  89%|▉| 13378/15000 [1:55:56<04:51,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:46 - INFO - __main__ - train loss is 6.6649590079905465\n",
      "Steps:  89%|▉| 13379/15000 [1:55:57<04:50,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:46 - INFO - __main__ - train loss is 6.6867103521944955\n",
      "Steps:  89%|▉| 13380/15000 [1:55:57<04:52,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:47 - INFO - __main__ - train loss is 7.118118340265937\n",
      "Steps:  89%|▉| 13381/15000 [1:55:57<04:54,  5.50it/s, lr=0.000974, step_loss=0.407/27/2023 19:40:47 - INFO - __main__ - train loss is 7.145459475112148\n",
      "Steps:  89%|▉| 13382/15000 [1:55:57<04:56,  5.45it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:47 - INFO - __main__ - train loss is 7.160380639252253\n",
      "Steps:  89%|▉| 13383/15000 [1:55:57<04:58,  5.42it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:47 - INFO - __main__ - train loss is 7.584576822933741\n",
      "Steps:  89%|▉| 13384/15000 [1:55:58<04:55,  5.46it/s, lr=0.000974, step_loss=0.407/27/2023 19:40:47 - INFO - __main__ - train loss is 8.18826005619485\n",
      "Steps:  89%|▉| 13385/15000 [1:55:58<04:53,  5.50it/s, lr=0.000974, step_loss=0.607/27/2023 19:40:48 - INFO - __main__ - train loss is 8.478221066412516\n",
      "Steps:  89%|▉| 13386/15000 [1:55:58<04:52,  5.53it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:48 - INFO - __main__ - train loss is 9.082170494017191\n",
      "Steps:  89%|▉| 13387/15000 [1:55:58<04:52,  5.51it/s, lr=0.000974, step_loss=0.607/27/2023 19:40:48 - INFO - __main__ - train loss is 9.16203679901082\n",
      "Steps:  89%|▉| 13388/15000 [1:55:58<04:51,  5.53it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:48 - INFO - __main__ - train loss is 9.179085347917862\n",
      "Steps:  89%|▉| 13389/15000 [1:55:58<04:51,  5.52it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:48 - INFO - __main__ - train loss is 9.253469128278084\n",
      "Steps:  89%|▉| 13390/15000 [1:55:59<04:52,  5.51it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:48 - INFO - __main__ - train loss is 9.377244684961624\n",
      "Steps:  89%|▉| 13391/15000 [1:55:59<04:51,  5.51it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:49 - INFO - __main__ - train loss is 9.408763084677048\n",
      "Steps:  89%|▉| 13392/15000 [1:55:59<04:50,  5.53it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:49 - INFO - __main__ - train loss is 9.411322209169157\n",
      "Steps:  89%|▉| 13393/15000 [1:55:59<04:49,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:49 - INFO - __main__ - train loss is 9.716305735637434\n",
      "Steps:  89%|▉| 13394/15000 [1:55:59<04:49,  5.55it/s, lr=0.000974, step_loss=0.307/27/2023 19:40:49 - INFO - __main__ - train loss is 9.72445841517765\n",
      "Steps:  89%|▉| 13395/15000 [1:56:00<04:51,  5.51it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:49 - INFO - __main__ - train loss is 10.02345778432209\n",
      "Steps:  89%|▉| 13396/15000 [1:56:00<04:51,  5.50it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:50 - INFO - __main__ - train loss is 10.069394614663906\n",
      "Steps:  89%|▉| 13397/15000 [1:56:00<04:50,  5.52it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:50 - INFO - __main__ - train loss is 10.079140456509776\n",
      "Steps:  89%|▉| 13398/15000 [1:56:00<04:49,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:50 - INFO - __main__ - train loss is 10.203777300310321\n",
      "Steps:  89%|▉| 13399/15000 [1:56:00<04:48,  5.55it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:50 - INFO - __main__ - train loss is 10.618080096435733\n",
      "Steps:  89%|▉| 13400/15000 [1:56:00<04:47,  5.56it/s, lr=0.000974, step_loss=0.407/27/2023 19:40:50 - INFO - __main__ - train loss is 10.823712783050723\n",
      "Steps:  89%|▉| 13401/15000 [1:56:01<04:47,  5.56it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:50 - INFO - __main__ - train loss is 10.827819745638408\n",
      "Steps:  89%|▉| 13402/15000 [1:56:01<04:47,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:51 - INFO - __main__ - train loss is 10.892944175400771\n",
      "Steps:  89%|▉| 13403/15000 [1:56:01<04:46,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:51 - INFO - __main__ - train loss is 10.898993069888093\n",
      "Steps:  89%|▉| 13404/15000 [1:56:01<04:48,  5.52it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:51 - INFO - __main__ - train loss is 11.326732392073609\n",
      "Steps:  89%|▉| 13405/15000 [1:56:01<04:48,  5.52it/s, lr=0.000974, step_loss=0.407/27/2023 19:40:51 - INFO - __main__ - train loss is 11.33487510366831\n",
      "Steps:  89%|▉| 13406/15000 [1:56:02<04:47,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:51 - INFO - __main__ - train loss is 11.751535770134069\n",
      "Steps:  89%|▉| 13407/15000 [1:56:02<04:46,  5.55it/s, lr=0.000974, step_loss=0.407/27/2023 19:40:52 - INFO - __main__ - train loss is 11.753206535126083\n",
      "Steps:  89%|▉| 13408/15000 [1:56:02<04:48,  5.52it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:52 - INFO - __main__ - train loss is 11.765463317628019\n",
      "Steps:  89%|▉| 13409/15000 [1:56:02<04:47,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:52 - INFO - __main__ - train loss is 12.054835404152982\n",
      "Steps:  89%|▉| 13410/15000 [1:56:02<04:46,  5.55it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:52 - INFO - __main__ - train loss is 12.15154153376352\n",
      "Steps:  89%|▉| 13411/15000 [1:56:02<04:46,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:52 - INFO - __main__ - train loss is 12.164179483312182\n",
      "Steps:  89%|▉| 13412/15000 [1:56:03<04:45,  5.55it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:52 - INFO - __main__ - train loss is 12.909701624768786\n",
      "Steps:  89%|▉| 13413/15000 [1:56:03<04:45,  5.56it/s, lr=0.000974, step_loss=0.707/27/2023 19:40:53 - INFO - __main__ - train loss is 12.91140202304814\n",
      "Steps:  89%|▉| 13414/15000 [1:56:03<04:44,  5.57it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:53 - INFO - __main__ - train loss is 13.053926146239974\n",
      "Steps:  89%|▉| 13415/15000 [1:56:03<04:44,  5.57it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:53 - INFO - __main__ - train loss is 13.406115508289076\n",
      "Steps:  89%|▉| 13416/15000 [1:56:03<04:44,  5.57it/s, lr=0.000974, step_loss=0.307/27/2023 19:40:53 - INFO - __main__ - train loss is 13.591446584672667\n",
      "Steps:  89%|▉| 13417/15000 [1:56:03<04:44,  5.57it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:53 - INFO - __main__ - train loss is 13.592950757360086\n",
      "Steps:  89%|▉| 13418/15000 [1:56:04<04:45,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:54 - INFO - __main__ - train loss is 13.642413276946172\n",
      "Steps:  89%|▉| 13419/15000 [1:56:04<04:45,  5.55it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:54 - INFO - __main__ - train loss is 13.649471265031025\n",
      "Steps:  89%|▉| 13420/15000 [1:56:04<04:44,  5.55it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:54 - INFO - __main__ - train loss is 13.660153597360477\n",
      "Steps:  89%|▉| 13421/15000 [1:56:04<04:43,  5.56it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:54 - INFO - __main__ - train loss is 13.858311280375347\n",
      "Steps:  89%|▉| 13422/15000 [1:56:04<04:46,  5.51it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:54 - INFO - __main__ - train loss is 13.861390621168539\n",
      "Steps:  89%|▉| 13423/15000 [1:56:05<04:46,  5.51it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:54 - INFO - __main__ - train loss is 13.868693220196292\n",
      "Steps:  89%|▉| 13424/15000 [1:56:05<04:45,  5.53it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:55 - INFO - __main__ - train loss is 13.951350609539077\n",
      "Steps:  90%|▉| 13425/15000 [1:56:05<04:43,  5.55it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:55 - INFO - __main__ - train loss is 14.219152132747695\n",
      "Steps:  90%|▉| 13426/15000 [1:56:05<04:43,  5.56it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:55 - INFO - __main__ - train loss is 14.22076662373729\n",
      "Steps:  90%|▉| 13427/15000 [1:56:05<04:45,  5.51it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:55 - INFO - __main__ - train loss is 14.572471638442948\n",
      "Steps:  90%|▉| 13428/15000 [1:56:05<04:44,  5.53it/s, lr=0.000974, step_loss=0.307/27/2023 19:40:55 - INFO - __main__ - train loss is 14.578937276499346\n",
      "Steps:  90%|▉| 13429/15000 [1:56:06<04:43,  5.54it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:56 - INFO - __main__ - train loss is 14.667109190719202\n",
      "Steps:  90%|▉| 13430/15000 [1:56:06<04:42,  5.55it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:56 - INFO - __main__ - train loss is 14.764101720647886\n",
      "Steps:  90%|▉| 13431/15000 [1:56:06<04:42,  5.56it/s, lr=0.000974, step_loss=0.007/27/2023 19:40:56 - INFO - __main__ - train loss is 14.914237327175215\n",
      "Steps:  90%|▉| 13432/15000 [1:56:06<04:41,  5.56it/s, lr=0.000974, step_loss=0.107/27/2023 19:40:56 - INFO - __main__ - train loss is 15.13981073279865\n",
      "Steps:  90%|▉| 13433/15000 [1:56:06<04:41,  5.57it/s, lr=0.000974, step_loss=0.207/27/2023 19:40:56 - INFO - __main__ - train loss is 15.145444489317015\n",
      "Steps:  90%|▉| 13434/15000 [1:56:07<04:40,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:56 - INFO - __main__ - train loss is 15.167722712503746\n",
      "Steps:  90%|▉| 13435/15000 [1:56:07<04:40,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:57 - INFO - __main__ - train loss is 15.171803151490167\n",
      "Steps:  90%|▉| 13436/15000 [1:56:07<04:40,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:57 - INFO - __main__ - train loss is 15.181395824300125\n",
      "Steps:  90%|▉| 13437/15000 [1:56:07<04:40,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:57 - INFO - __main__ - train loss is 15.533754731761292\n",
      "Steps:  90%|▉| 13438/15000 [1:56:07<04:40,  5.58it/s, lr=0.000973, step_loss=0.307/27/2023 19:40:57 - INFO - __main__ - train loss is 15.559502947377041\n",
      "Steps:  90%|▉| 13439/15000 [1:56:07<04:39,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:57 - INFO - __main__ - train loss is 15.612836874322966\n",
      "Steps:  90%|▉| 13440/15000 [1:56:08<04:39,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:57 - INFO - __main__ - train loss is 15.671608566539362\n",
      "Steps:  90%|▉| 13441/15000 [1:56:08<04:39,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:58 - INFO - __main__ - train loss is 15.675432291347533\n",
      "Steps:  90%|▉| 13442/15000 [1:56:08<04:39,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:58 - INFO - __main__ - train loss is 15.69866848597303\n",
      "Steps:  90%|▉| 13443/15000 [1:56:08<04:38,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:58 - INFO - __main__ - train loss is 16.092708921525627\n",
      "Steps:  90%|▉| 13444/15000 [1:56:08<04:38,  5.58it/s, lr=0.000973, step_loss=0.307/27/2023 19:40:58 - INFO - __main__ - train loss is 16.228122657630593\n",
      "Steps:  90%|▉| 13445/15000 [1:56:09<04:38,  5.58it/s, lr=0.000973, step_loss=0.107/27/2023 19:40:58 - INFO - __main__ - train loss is 16.25707343267277\n",
      "Steps:  90%|▉| 13446/15000 [1:56:09<04:38,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:59 - INFO - __main__ - train loss is 16.44979737745598\n",
      "Steps:  90%|▉| 13447/15000 [1:56:09<04:38,  5.58it/s, lr=0.000973, step_loss=0.107/27/2023 19:40:59 - INFO - __main__ - train loss is 16.9929398749955\n",
      "Steps:  90%|▉| 13448/15000 [1:56:09<04:38,  5.58it/s, lr=0.000973, step_loss=0.507/27/2023 19:40:59 - INFO - __main__ - train loss is 17.027200006414205\n",
      "Steps:  90%|▉| 13449/15000 [1:56:09<04:38,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:40:59 - INFO - __main__ - train loss is 17.25319939153269\n",
      "Steps:  90%|▉| 13450/15000 [1:56:09<04:37,  5.58it/s, lr=0.000973, step_loss=0.207/27/2023 19:40:59 - INFO - __main__ - train loss is 17.374577813316137\n",
      "Steps:  90%|▉| 13451/15000 [1:56:10<04:37,  5.58it/s, lr=0.000973, step_loss=0.107/27/2023 19:40:59 - INFO - __main__ - train loss is 17.386236004997045\n",
      "Steps:  90%|▉| 13452/15000 [1:56:10<04:37,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:00 - INFO - __main__ - train loss is 17.51819320814684\n",
      "Steps:  90%|▉| 13453/15000 [1:56:10<04:37,  5.58it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:00 - INFO - __main__ - train loss is 17.529800062533468\n",
      "Steps:  90%|▉| 13454/15000 [1:56:10<04:37,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:00 - INFO - __main__ - train loss is 17.536441447678953\n",
      "Steps:  90%|▉| 13455/15000 [1:56:10<04:36,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:00 - INFO - __main__ - train loss is 17.558539655525237\n",
      "Steps:  90%|▉| 13456/15000 [1:56:10<04:36,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:00 - INFO - __main__ - train loss is 17.561701404862106\n",
      "Steps:  90%|▉| 13457/15000 [1:56:11<04:36,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:01 - INFO - __main__ - train loss is 17.621294434182346\n",
      "Steps:  90%|▉| 13458/15000 [1:56:11<04:36,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:01 - INFO - __main__ - train loss is 17.916010702960193\n",
      "Steps:  90%|▉| 13459/15000 [1:56:11<04:36,  5.58it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:01 - INFO - __main__ - train loss is 18.210171247832477\n",
      "Steps:  90%|▉| 13460/15000 [1:56:11<04:36,  5.58it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:01 - INFO - __main__ - train loss is 18.56703060399741\n",
      "Steps:  90%|▉| 13461/15000 [1:56:11<04:35,  5.58it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:01 - INFO - __main__ - train loss is 18.576619842089713\n",
      "Steps:  90%|▉| 13462/15000 [1:56:12<04:35,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:01 - INFO - __main__ - train loss is 18.627755240537226\n",
      "Steps:  90%|▉| 13463/15000 [1:56:12<04:35,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:02 - INFO - __main__ - train loss is 19.070538715459406\n",
      "Steps:  90%|▉| 13464/15000 [1:56:12<04:39,  5.49it/s, lr=0.000973, step_loss=0.407/27/2023 19:41:02 - INFO - __main__ - train loss is 19.080531376414\n",
      "Steps:  90%|▉| 13465/15000 [1:56:12<04:38,  5.52it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:02 - INFO - __main__ - train loss is 19.173467713408172\n",
      "Steps:  90%|▉| 13466/15000 [1:56:12<04:37,  5.53it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:02 - INFO - __main__ - train loss is 19.479557591490448\n",
      "Steps:  90%|▉| 13467/15000 [1:56:12<04:36,  5.55it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:02 - INFO - __main__ - train loss is 19.69248044770211\n",
      "Steps:  90%|▉| 13468/15000 [1:56:13<04:35,  5.56it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:03 - INFO - __main__ - train loss is 19.69373792805709\n",
      "Steps:  90%|▉| 13469/15000 [1:56:13<04:34,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:03 - INFO - __main__ - train loss is 19.908245090628043\n",
      "Steps:  90%|▉| 13470/15000 [1:56:13<04:34,  5.57it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:03 - INFO - __main__ - train loss is 20.086736742639914\n",
      "Steps:  90%|▉| 13471/15000 [1:56:13<04:34,  5.57it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:03 - INFO - __main__ - train loss is 20.097465036669746\n",
      "Steps:  90%|▉| 13472/15000 [1:56:13<04:33,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:03 - INFO - __main__ - train loss is 20.322584895649925\n",
      "Steps:  90%|▉| 13473/15000 [1:56:14<04:33,  5.58it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:03 - INFO - __main__ - train loss is 20.345760269323364\n",
      "Steps:  90%|▉| 13474/15000 [1:56:14<04:33,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:04 - INFO - __main__ - train loss is 20.388339502969757\n",
      "Steps:  90%|▉| 13475/15000 [1:56:14<04:33,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:04 - INFO - __main__ - train loss is 20.496910555521026\n",
      "Steps:  90%|▉| 13476/15000 [1:56:14<04:33,  5.58it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:04 - INFO - __main__ - train loss is 20.49875461286865\n",
      "Steps:  90%|▉| 13477/15000 [1:56:14<04:33,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:04 - INFO - __main__ - train loss is 20.845305286115035\n",
      "Steps:  90%|▉| 13478/15000 [1:56:14<04:32,  5.58it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:04 - INFO - __main__ - train loss is 21.2046476227697\n",
      "Steps:  90%|▉| 13479/15000 [1:56:15<04:32,  5.57it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:04 - INFO - __main__ - train loss is 21.597295067971572\n",
      "Steps:  90%|▉| 13480/15000 [1:56:15<04:32,  5.57it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:05 - INFO - __main__ - train loss is 21.6119128332939\n",
      "Steps:  90%|▉| 13481/15000 [1:56:15<04:32,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:05 - INFO - __main__ - train loss is 21.62478502630256\n",
      "Steps:  90%|▉| 13482/15000 [1:56:15<04:32,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:05 - INFO - __main__ - train loss is 21.747439285507426\n",
      "Steps:  90%|▉| 13483/15000 [1:56:15<04:32,  5.57it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:05 - INFO - __main__ - train loss is 21.748814557795413\n",
      "Steps:  90%|▉| 13484/15000 [1:56:16<04:31,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:05 - INFO - __main__ - train loss is 21.973951448802836\n",
      "Steps:  90%|▉| 13485/15000 [1:56:16<04:31,  5.58it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:06 - INFO - __main__ - train loss is 22.18379274487961\n",
      "Steps:  90%|▉| 13486/15000 [1:56:16<04:31,  5.58it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:06 - INFO - __main__ - train loss is 22.212963489000686\n",
      "Steps:  90%|▉| 13487/15000 [1:56:16<04:31,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:06 - INFO - __main__ - train loss is 22.218057507299818\n",
      "Steps:  90%|▉| 13488/15000 [1:56:16<04:31,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:06 - INFO - __main__ - train loss is 22.21959493192844\n",
      "Steps:  90%|▉| 13489/15000 [1:56:16<04:31,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:06 - INFO - __main__ - train loss is 22.222607789793983\n",
      "Steps:  90%|▉| 13490/15000 [1:56:17<04:31,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:06 - INFO - __main__ - train loss is 22.22895302553661\n",
      "Steps:  90%|▉| 13491/15000 [1:56:17<04:30,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:07 - INFO - __main__ - train loss is 22.24198718299158\n",
      "Steps:  90%|▉| 13492/15000 [1:56:17<04:30,  5.57it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:07 - INFO - __main__ - train loss is 22.719586207764223\n",
      "Steps:  90%|▉| 13493/15000 [1:56:17<04:30,  5.57it/s, lr=0.000973, step_loss=0.407/27/2023 19:41:07 - INFO - __main__ - train loss is 22.75061185588129\n",
      "Steps:  90%|▉| 13494/15000 [1:56:17<04:30,  5.58it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:07 - INFO - __main__ - train loss is 22.755392429651693\n",
      "Steps:  90%|▉| 13495/15000 [1:56:18<04:32,  5.52it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:07 - INFO - __main__ - train loss is 23.0324714158196\n",
      "Steps:  90%|▉| 13496/15000 [1:56:18<04:32,  5.51it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:08 - INFO - __main__ - train loss is 23.10917113465257\n",
      "Steps:  90%|▉| 13497/15000 [1:56:18<04:32,  5.51it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:08 - INFO - __main__ - train loss is 23.449237716617063\n",
      "Steps:  90%|▉| 13498/15000 [1:56:18<04:32,  5.51it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:08 - INFO - __main__ - train loss is 23.4558389170561\n",
      "Steps:  90%|▉| 13499/15000 [1:56:18<04:32,  5.51it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:08 - INFO - __main__ - train loss is 23.47849920974113\n",
      "Steps:  90%|▉| 13500/15000 [1:56:18<04:32,  5.50it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:08 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-13500\n",
      "07/27/2023 19:41:08 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:41:08,690] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:41:08,694] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-13500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:41:08,694] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-13500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:41:08,701] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-13500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:41:08,701] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-13500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:41:08,708] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-13500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:41:08,708] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-13500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:41:08,708] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:41:08 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-13500/pytorch_model\n",
      "07/27/2023 19:41:08 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-13500/scheduler.bin\n",
      "07/27/2023 19:41:08 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-13500/random_states_0.pkl\n",
      "07/27/2023 19:41:08 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-13500\n",
      "Steps:  90%|▉| 13500/15000 [1:56:18<04:32,  5.50it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:08 - INFO - __main__ - train loss is 23.504853205988184\n",
      "Steps:  90%|▉| 13501/15000 [1:56:19<04:40,  5.33it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:08 - INFO - __main__ - train loss is 23.506111277849413\n",
      "Steps:  90%|▉| 13502/15000 [1:56:19<04:38,  5.38it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:09 - INFO - __main__ - train loss is 23.50800532719586\n",
      "Steps:  90%|▉| 13503/15000 [1:56:19<04:36,  5.41it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:09 - INFO - __main__ - train loss is 23.610102212638594\n",
      "Steps:  90%|▉| 13504/15000 [1:56:19<04:35,  5.43it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:09 - INFO - __main__ - train loss is 23.777938252897002\n",
      "Steps:  90%|▉| 13505/15000 [1:56:19<04:34,  5.45it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:09 - INFO - __main__ - train loss is 23.8025591323385\n",
      "Steps:  90%|▉| 13506/15000 [1:56:20<04:33,  5.46it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:09 - INFO - __main__ - train loss is 23.8267521323869\n",
      "Steps:  90%|▉| 13507/15000 [1:56:20<04:32,  5.47it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:10 - INFO - __main__ - train loss is 23.856607514084317\n",
      "Steps:  90%|▉| 13508/15000 [1:56:20<04:32,  5.48it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:10 - INFO - __main__ - train loss is 23.868474016548134\n",
      "Steps:  90%|▉| 13509/15000 [1:56:20<04:31,  5.49it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:10 - INFO - __main__ - train loss is 24.201676169992425\n",
      "Steps:  90%|▉| 13510/15000 [1:56:20<04:31,  5.49it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:10 - INFO - __main__ - train loss is 24.21562193671707\n",
      "Steps:  90%|▉| 13511/15000 [1:56:20<04:31,  5.49it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:10 - INFO - __main__ - train loss is 24.2600279484177\n",
      "Steps:  90%|▉| 13512/15000 [1:56:21<04:30,  5.49it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:10 - INFO - __main__ - train loss is 24.326427790918387\n",
      "Steps:  90%|▉| 13513/15000 [1:56:21<04:30,  5.50it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:11 - INFO - __main__ - train loss is 24.4919110868359\n",
      "Steps:  90%|▉| 13514/15000 [1:56:21<04:30,  5.50it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:11 - INFO - __main__ - train loss is 24.507697274559177\n",
      "Steps:  90%|▉| 13515/15000 [1:56:21<04:32,  5.45it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:11 - INFO - __main__ - train loss is 24.52072464080993\n",
      "Steps:  90%|▉| 13516/15000 [1:56:21<04:33,  5.44it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:11 - INFO - __main__ - train loss is 24.564734415733255\n",
      "Steps:  90%|▉| 13517/15000 [1:56:22<04:30,  5.48it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:11 - INFO - __main__ - train loss is 24.89628790470306\n",
      "Steps:  90%|▉| 13518/15000 [1:56:22<04:29,  5.49it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:12 - INFO - __main__ - train loss is 25.2479218110675\n",
      "Steps:  90%|▉| 13519/15000 [1:56:22<04:28,  5.51it/s, lr=0.000973, step_loss=0.307/27/2023 19:41:12 - INFO - __main__ - train loss is 25.268602342926897\n",
      "Steps:  90%|▉| 13520/15000 [1:56:22<04:27,  5.53it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:12 - INFO - __main__ - train loss is 25.5122759208316\n",
      "Steps:  90%|▉| 13521/15000 [1:56:22<04:27,  5.52it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:12 - INFO - __main__ - train loss is 25.67130150052253\n",
      "Steps:  90%|▉| 13522/15000 [1:56:22<04:28,  5.51it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:12 - INFO - __main__ - train loss is 25.675268106744625\n",
      "Steps:  90%|▉| 13523/15000 [1:56:23<04:27,  5.53it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:12 - INFO - __main__ - train loss is 25.691530241281725\n",
      "Steps:  90%|▉| 13524/15000 [1:56:23<04:26,  5.54it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:13 - INFO - __main__ - train loss is 25.738002366037108\n",
      "Steps:  90%|▉| 13525/15000 [1:56:23<04:28,  5.50it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:13 - INFO - __main__ - train loss is 26.25102747103665\n",
      "Steps:  90%|▉| 13526/15000 [1:56:23<04:29,  5.47it/s, lr=0.000973, step_loss=0.507/27/2023 19:41:13 - INFO - __main__ - train loss is 26.360964304418303\n",
      "Steps:  90%|▉| 13527/15000 [1:56:23<04:27,  5.51it/s, lr=0.000973, step_loss=0.107/27/2023 19:41:13 - INFO - __main__ - train loss is 26.363340299925767\n",
      "Steps:  90%|▉| 13528/15000 [1:56:24<04:26,  5.53it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:13 - INFO - __main__ - train loss is 26.456779983243905\n",
      "Steps:  90%|▉| 13529/15000 [1:56:24<04:25,  5.54it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:14 - INFO - __main__ - train loss is 26.46043237799313\n",
      "Steps:  90%|▉| 13530/15000 [1:56:24<04:24,  5.55it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:14 - INFO - __main__ - train loss is 26.463245501858182\n",
      "Steps:  90%|▉| 13531/15000 [1:56:24<04:24,  5.56it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:14 - INFO - __main__ - train loss is 26.499978074920364\n",
      "Steps:  90%|▉| 13532/15000 [1:56:24<04:24,  5.54it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:14 - INFO - __main__ - train loss is 26.57561034162063\n",
      "Steps:  90%|▉| 13533/15000 [1:56:24<04:24,  5.55it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:14 - INFO - __main__ - train loss is 26.829730214667507\n",
      "Steps:  90%|▉| 13534/15000 [1:56:25<04:23,  5.56it/s, lr=0.000973, step_loss=0.207/27/2023 19:41:14 - INFO - __main__ - train loss is 26.868989640963264\n",
      "Steps:  90%|▉| 13535/15000 [1:56:25<04:23,  5.56it/s, lr=0.000973, step_loss=0.007/27/2023 19:41:15 - INFO - __main__ - train loss is 26.87163116026204\n",
      "Steps:  90%|▉| 13536/15000 [1:56:25<04:23,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:15 - INFO - __main__ - train loss is 27.340604349854402\n",
      "Steps:  90%|▉| 13537/15000 [1:56:25<04:22,  5.57it/s, lr=0.000972, step_loss=0.407/27/2023 19:41:15 - INFO - __main__ - train loss is 27.343078062520362\n",
      "Steps:  90%|▉| 13538/15000 [1:56:25<04:22,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:15 - INFO - __main__ - train loss is 27.347425753832795\n",
      "Steps:  90%|▉| 13539/15000 [1:56:25<04:22,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:15 - INFO - __main__ - train loss is 27.462671982706524\n",
      "Steps:  90%|▉| 13540/15000 [1:56:26<04:22,  5.57it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:16 - INFO - __main__ - train loss is 27.54827567434404\n",
      "Steps:  90%|▉| 13541/15000 [1:56:26<04:21,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:16 - INFO - __main__ - train loss is 27.607674541533925\n",
      "Steps:  90%|▉| 13542/15000 [1:56:26<04:21,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:16 - INFO - __main__ - train loss is 27.645209687412716\n",
      "Steps:  90%|▉| 13543/15000 [1:56:26<04:21,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:16 - INFO - __main__ - train loss is 27.647885763668455\n",
      "Steps:  90%|▉| 13544/15000 [1:56:26<04:21,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:16 - INFO - __main__ - train loss is 27.904715591692366\n",
      "Steps:  90%|▉| 13545/15000 [1:56:27<04:21,  5.57it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:16 - INFO - __main__ - train loss is 27.93236287275795\n",
      "Steps:  90%|▉| 13546/15000 [1:56:27<04:20,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:17 - INFO - __main__ - train loss is 28.27853454987053\n",
      "Steps:  90%|▉| 13547/15000 [1:56:27<04:20,  5.57it/s, lr=0.000972, step_loss=0.307/27/2023 19:41:17 - INFO - __main__ - train loss is 28.280369686195627\n",
      "Steps:  90%|▉| 13548/15000 [1:56:27<04:20,  5.57it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:17 - INFO - __main__ - train loss is 28.452331440756097\n",
      "Steps:  90%|▉| 13549/15000 [1:56:27<04:20,  5.57it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:17 - INFO - __main__ - train loss is 28.581228034803644\n",
      "Steps:  90%|▉| 13550/15000 [1:56:27<04:20,  5.57it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:17 - INFO - __main__ - train loss is 29.02172871143557\n",
      "Steps:  90%|▉| 13551/15000 [1:56:28<04:22,  5.51it/s, lr=0.000972, step_loss=0.407/27/2023 19:41:18 - INFO - __main__ - train loss is 29.63048549205996\n",
      "Steps:  90%|▉| 13552/15000 [1:56:28<04:23,  5.50it/s, lr=0.000972, step_loss=0.607/27/2023 19:41:18 - INFO - __main__ - train loss is 29.652375823119655\n",
      "Steps:  90%|▉| 13553/15000 [1:56:28<04:22,  5.52it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:18 - INFO - __main__ - train loss is 29.721734753111377\n",
      "Steps:  90%|▉| 13554/15000 [1:56:28<04:21,  5.53it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:18 - INFO - __main__ - train loss is 29.80469266162254\n",
      "Steps:  90%|▉| 13555/15000 [1:56:28<04:20,  5.54it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:18 - INFO - __main__ - train loss is 29.85327477217652\n",
      "Steps:  90%|▉| 13556/15000 [1:56:29<04:22,  5.50it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:18 - INFO - __main__ - train loss is 29.856983805075288\n",
      "Steps:  90%|▉| 13557/15000 [1:56:29<04:22,  5.50it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:19 - INFO - __main__ - train loss is 30.081513041630387\n",
      "Steps:  90%|▉| 13558/15000 [1:56:29<04:22,  5.49it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:19 - INFO - __main__ - train loss is 30.2545097861439\n",
      "Steps:  90%|▉| 13559/15000 [1:56:29<04:21,  5.50it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:19 - INFO - __main__ - train loss is 30.349479461088777\n",
      "Steps:  90%|▉| 13560/15000 [1:56:29<04:20,  5.52it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:19 - INFO - __main__ - train loss is 30.352464783005416\n",
      "Steps:  90%|▉| 13561/15000 [1:56:29<04:21,  5.51it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:19 - INFO - __main__ - train loss is 30.35522096278146\n",
      "Steps:  90%|▉| 13562/15000 [1:56:30<04:20,  5.53it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:20 - INFO - __main__ - train loss is 30.358472243649885\n",
      "Steps:  90%|▉| 13563/15000 [1:56:30<04:19,  5.54it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:20 - INFO - __main__ - train loss is 31.025452033383772\n",
      "Steps:  90%|▉| 13564/15000 [1:56:30<04:21,  5.50it/s, lr=0.000972, step_loss=0.607/27/2023 19:41:20 - INFO - __main__ - train loss is 31.22476522694342\n",
      "Steps:  90%|▉| 13565/15000 [1:56:30<04:19,  5.52it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:20 - INFO - __main__ - train loss is 31.277373135788366\n",
      "Steps:  90%|▉| 13566/15000 [1:56:30<04:18,  5.54it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:20 - INFO - __main__ - train loss is 31.28249302948825\n",
      "Steps:  90%|▉| 13567/15000 [1:56:31<04:18,  5.55it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:20 - INFO - __main__ - train loss is 31.298174117458984\n",
      "Steps:  90%|▉| 13568/15000 [1:56:31<04:17,  5.55it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:21 - INFO - __main__ - train loss is 31.312187070725486\n",
      "Steps:  90%|▉| 13569/15000 [1:56:31<04:17,  5.56it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:21 - INFO - __main__ - train loss is 31.402481685159728\n",
      "Steps:  90%|▉| 13570/15000 [1:56:31<04:19,  5.51it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:21 - INFO - __main__ - train loss is 31.5194913696032\n",
      "Steps:  90%|▉| 13571/15000 [1:56:31<04:19,  5.51it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:21 - INFO - __main__ - train loss is 31.659744302509353\n",
      "Steps:  90%|▉| 13572/15000 [1:56:31<04:18,  5.53it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:21 - INFO - __main__ - train loss is 31.662087246077135\n",
      "Steps:  90%|▉| 13573/15000 [1:56:32<04:17,  5.54it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:22 - INFO - __main__ - train loss is 31.963474138872698\n",
      "Steps:  90%|▉| 13574/15000 [1:56:32<04:16,  5.55it/s, lr=0.000972, step_loss=0.307/27/2023 19:41:22 - INFO - __main__ - train loss is 32.06206817855127\n",
      "Steps:  90%|▉| 13575/15000 [1:56:32<04:16,  5.56it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:22 - INFO - __main__ - train loss is 32.601241304771975\n",
      "Steps:  91%|▉| 13576/15000 [1:56:32<04:15,  5.57it/s, lr=0.000972, step_loss=0.507/27/2023 19:41:22 - INFO - __main__ - train loss is 32.93761448492296\n",
      "Steps:  91%|▉| 13577/15000 [1:56:32<04:17,  5.52it/s, lr=0.000972, step_loss=0.307/27/2023 19:41:22 - INFO - __main__ - train loss is 32.95269347098656\n",
      "Steps:  91%|▉| 13578/15000 [1:56:33<04:17,  5.51it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:22 - INFO - __main__ - train loss is 33.122742125066\n",
      "Steps:  91%|▉| 13579/15000 [1:56:33<04:16,  5.53it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:23 - INFO - __main__ - train loss is 33.473043569596484\n",
      "Steps:  91%|▉| 13580/15000 [1:56:33<04:16,  5.54it/s, lr=0.000972, step_loss=0.307/27/2023 19:41:23 - INFO - __main__ - train loss is 33.544760526390746\n",
      "Steps:  91%|▉| 13581/15000 [1:56:33<04:15,  5.55it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:23 - INFO - __main__ - train loss is 33.895697177620605\n",
      "Steps:  91%|▉| 13582/15000 [1:56:33<04:15,  5.55it/s, lr=0.000972, step_loss=0.307/27/2023 19:41:23 - INFO - __main__ - train loss is 34.08298529800959\n",
      "Steps:  91%|▉| 13583/15000 [1:56:33<04:14,  5.56it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:23 - INFO - __main__ - train loss is 34.12871962902136\n",
      "Steps:  91%|▉| 13584/15000 [1:56:34<04:16,  5.51it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:23 - INFO - __main__ - train loss is 34.20766636845656\n",
      "Steps:  91%|▉| 13585/15000 [1:56:34<04:15,  5.53it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:24 - INFO - __main__ - train loss is 34.21026359242387\n",
      "Steps:  91%|▉| 13586/15000 [1:56:34<04:17,  5.49it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:24 - INFO - __main__ - train loss is 34.5894031052012\n",
      "Steps:  91%|▉| 13587/15000 [1:56:34<04:17,  5.49it/s, lr=0.000972, step_loss=0.307/27/2023 19:41:24 - INFO - __main__ - train loss is 34.73776097339578\n",
      "Steps:  91%|▉| 13588/15000 [1:56:34<04:26,  5.30it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:24 - INFO - __main__ - train loss is 34.956279021920636\n",
      "Steps:  91%|▉| 13589/15000 [1:56:35<05:10,  4.55it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:25 - INFO - __main__ - train loss is 35.070678097428754\n",
      "Steps:  91%|▉| 13590/15000 [1:56:35<05:01,  4.68it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:25 - INFO - __main__ - train loss is 35.07605694117956\n",
      "Steps:  91%|▉| 13591/15000 [1:56:35<05:21,  4.39it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:25 - INFO - __main__ - train loss is 35.08271183283068\n",
      "Steps:  91%|▉| 13592/15000 [1:56:35<05:00,  4.68it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:25 - INFO - __main__ - train loss is 35.1546161940787\n",
      "Steps:  91%|▉| 13593/15000 [1:56:35<04:46,  4.92it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:25 - INFO - __main__ - train loss is 35.180958254495636\n",
      "Steps:  91%|▉| 13594/15000 [1:56:36<04:36,  5.09it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:26 - INFO - __main__ - train loss is 35.18993908376433\n",
      "Steps:  91%|▉| 13595/15000 [1:56:36<04:29,  5.22it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:26 - INFO - __main__ - train loss is 35.391347559401765\n",
      "Steps:  91%|▉| 13596/15000 [1:56:36<04:23,  5.32it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:26 - INFO - __main__ - train loss is 35.53277270705439\n",
      "Steps:  91%|▉| 13597/15000 [1:56:36<04:20,  5.39it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:26 - INFO - __main__ - train loss is 36.2304620614741\n",
      "Steps:  91%|▉| 13598/15000 [1:56:36<04:17,  5.44it/s, lr=0.000972, step_loss=0.607/27/2023 19:41:26 - INFO - __main__ - train loss is 36.371196108171716\n",
      "Steps:  91%|▉| 13599/15000 [1:56:37<04:16,  5.47it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:26 - INFO - __main__ - train loss is 36.79864867241122\n",
      "Steps:  91%|▉| 13600/15000 [1:56:37<04:14,  5.50it/s, lr=0.000972, step_loss=0.407/27/2023 19:41:27 - INFO - __main__ - train loss is 36.80663401377387\n",
      "Steps:  91%|▉| 13601/15000 [1:56:37<04:14,  5.50it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:27 - INFO - __main__ - train loss is 36.82320316811092\n",
      "Steps:  91%|▉| 13602/15000 [1:56:37<04:13,  5.52it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:27 - INFO - __main__ - train loss is 36.828447203850374\n",
      "Steps:  91%|▉| 13603/15000 [1:56:37<04:12,  5.54it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:27 - INFO - __main__ - train loss is 36.85422862670384\n",
      "Steps:  91%|▉| 13604/15000 [1:56:37<04:11,  5.54it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:27 - INFO - __main__ - train loss is 37.10242883465253\n",
      "Steps:  91%|▉| 13605/15000 [1:56:38<04:12,  5.52it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:28 - INFO - __main__ - train loss is 37.389872055267915\n",
      "Steps:  91%|▉| 13606/15000 [1:56:38<04:13,  5.50it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:28 - INFO - __main__ - train loss is 37.391413859440945\n",
      "Steps:  91%|▉| 13607/15000 [1:56:38<04:13,  5.50it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:28 - INFO - __main__ - train loss is 37.397644932731055\n",
      "Steps:  91%|▉| 13608/15000 [1:56:38<04:13,  5.49it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:28 - INFO - __main__ - train loss is 37.468754875822924\n",
      "Steps:  91%|▉| 13609/15000 [1:56:38<04:14,  5.47it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:28 - INFO - __main__ - train loss is 38.34241031424608\n",
      "Steps:  91%|▉| 13610/15000 [1:56:39<04:14,  5.47it/s, lr=0.000972, step_loss=0.807/27/2023 19:41:28 - INFO - __main__ - train loss is 38.34892035170924\n",
      "Steps:  91%|▉| 13611/15000 [1:56:39<04:13,  5.47it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:29 - INFO - __main__ - train loss is 38.38665367558133\n",
      "Steps:  91%|▉| 13612/15000 [1:56:39<04:13,  5.48it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:29 - INFO - __main__ - train loss is 38.43424241885077\n",
      "Steps:  91%|▉| 13613/15000 [1:56:39<04:14,  5.45it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:29 - INFO - __main__ - train loss is 38.43985001870897\n",
      "Steps:  91%|▉| 13614/15000 [1:56:39<04:13,  5.47it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:29 - INFO - __main__ - train loss is 38.675370575278066\n",
      "Steps:  91%|▉| 13615/15000 [1:56:39<04:18,  5.36it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:29 - INFO - __main__ - train loss is 38.779385582893156\n",
      "Steps:  91%|▉| 13616/15000 [1:56:40<04:21,  5.29it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:30 - INFO - __main__ - train loss is 38.82170245924499\n",
      "Steps:  91%|▉| 13617/15000 [1:56:40<04:24,  5.23it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:30 - INFO - __main__ - train loss is 38.92083381989505\n",
      "Steps:  91%|▉| 13618/15000 [1:56:40<04:27,  5.17it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:30 - INFO - __main__ - train loss is 39.111124509363435\n",
      "Steps:  91%|▉| 13619/15000 [1:56:40<04:28,  5.14it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:30 - INFO - __main__ - train loss is 39.11295535392128\n",
      "Steps:  91%|▉| 13620/15000 [1:56:40<04:29,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:30 - INFO - __main__ - train loss is 39.14618196315132\n",
      "Steps:  91%|▉| 13621/15000 [1:56:41<04:28,  5.13it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:31 - INFO - __main__ - train loss is 39.452463917201385\n",
      "Steps:  91%|▉| 13622/15000 [1:56:41<04:28,  5.13it/s, lr=0.000972, step_loss=0.307/27/2023 19:41:31 - INFO - __main__ - train loss is 39.624897219007835\n",
      "Steps:  91%|▉| 13623/15000 [1:56:41<04:28,  5.13it/s, lr=0.000972, step_loss=0.107/27/2023 19:41:31 - INFO - __main__ - train loss is 39.627424887381494\n",
      "Steps:  91%|▉| 13624/15000 [1:56:41<04:28,  5.13it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:31 - INFO - __main__ - train loss is 39.67792676296085\n",
      "Steps:  91%|▉| 13625/15000 [1:56:41<04:28,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:31 - INFO - __main__ - train loss is 39.67949926177971\n",
      "Steps:  91%|▉| 13626/15000 [1:56:42<04:28,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:32 - INFO - __main__ - train loss is 39.70660422812216\n",
      "Steps:  91%|▉| 13627/15000 [1:56:42<04:28,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:32 - INFO - __main__ - train loss is 39.93261963198893\n",
      "Steps:  91%|▉| 13628/15000 [1:56:42<04:28,  5.12it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:32 - INFO - __main__ - train loss is 40.190144032938406\n",
      "Steps:  91%|▉| 13629/15000 [1:56:42<04:28,  5.12it/s, lr=0.000972, step_loss=0.207/27/2023 19:41:32 - INFO - __main__ - train loss is 40.202278482494876\n",
      "Steps:  91%|▉| 13630/15000 [1:56:42<04:27,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:32 - INFO - __main__ - train loss is 40.20418098953087\n",
      "Steps:  91%|▉| 13631/15000 [1:56:43<04:27,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:33 - INFO - __main__ - train loss is 40.20812574878801\n",
      "Steps:  91%|▉| 13632/15000 [1:56:43<04:27,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:33 - INFO - __main__ - train loss is 40.74529186740983\n",
      "Steps:  91%|▉| 13633/15000 [1:56:43<04:26,  5.12it/s, lr=0.000972, step_loss=0.507/27/2023 19:41:33 - INFO - __main__ - train loss is 40.765253768418916\n",
      "Steps:  91%|▉| 13634/15000 [1:56:43<04:26,  5.12it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:33 - INFO - __main__ - train loss is 40.78944710001815\n",
      "Steps:  91%|▉| 13635/15000 [1:56:44<06:21,  3.58it/s, lr=0.000972, step_loss=0.007/27/2023 19:41:34 - INFO - __main__ - Per validation step average loss is 0.005427459254860878\n",
      "07/27/2023 19:41:34 - INFO - __main__ - Cumulative validation average loss is 0.005427459254860878\n",
      "07/27/2023 19:41:35 - INFO - __main__ - Per validation step average loss is 0.024140920490026474\n",
      "07/27/2023 19:41:35 - INFO - __main__ - Cumulative validation average loss is 0.029568379744887352\n",
      "07/27/2023 19:41:35 - INFO - __main__ - Per validation step average loss is 0.2783825993537903\n",
      "07/27/2023 19:41:35 - INFO - __main__ - Cumulative validation average loss is 0.30795097909867764\n",
      "07/27/2023 19:41:36 - INFO - __main__ - Per validation step average loss is 0.005838651210069656\n",
      "07/27/2023 19:41:36 - INFO - __main__ - Cumulative validation average loss is 0.3137896303087473\n",
      "07/27/2023 19:41:36 - INFO - __main__ - Per validation step average loss is 0.014116165228188038\n",
      "07/27/2023 19:41:36 - INFO - __main__ - Cumulative validation average loss is 0.32790579553693533\n",
      "07/27/2023 19:41:37 - INFO - __main__ - Per validation step average loss is 0.09725549817085266\n",
      "07/27/2023 19:41:37 - INFO - __main__ - Cumulative validation average loss is 0.425161293707788\n",
      "07/27/2023 19:41:37 - INFO - __main__ - Per validation step average loss is 0.14751067757606506\n",
      "07/27/2023 19:41:37 - INFO - __main__ - Cumulative validation average loss is 0.572671971283853\n",
      "07/27/2023 19:41:37 - INFO - __main__ - Per validation step average loss is 0.16260334849357605\n",
      "07/27/2023 19:41:37 - INFO - __main__ - Cumulative validation average loss is 0.7352753197774291\n",
      "07/27/2023 19:41:38 - INFO - __main__ - Per validation step average loss is 0.09369368851184845\n",
      "07/27/2023 19:41:38 - INFO - __main__ - Cumulative validation average loss is 0.8289690082892776\n",
      "07/27/2023 19:41:38 - INFO - __main__ - Per validation step average loss is 0.005099940113723278\n",
      "07/27/2023 19:41:38 - INFO - __main__ - Cumulative validation average loss is 0.8340689484030008\n",
      "07/27/2023 19:41:39 - INFO - __main__ - Per validation step average loss is 0.1331588178873062\n",
      "07/27/2023 19:41:39 - INFO - __main__ - Cumulative validation average loss is 0.967227766290307\n",
      "07/27/2023 19:41:39 - INFO - __main__ - Per validation step average loss is 0.0031187108252197504\n",
      "07/27/2023 19:41:39 - INFO - __main__ - Cumulative validation average loss is 0.9703464771155268\n",
      "07/27/2023 19:41:39 - INFO - __main__ - Per validation step average loss is 0.3172438442707062\n",
      "07/27/2023 19:41:39 - INFO - __main__ - Cumulative validation average loss is 1.287590321386233\n",
      "07/27/2023 19:41:40 - INFO - __main__ - Per validation step average loss is 0.06289023160934448\n",
      "07/27/2023 19:41:40 - INFO - __main__ - Cumulative validation average loss is 1.3504805529955775\n",
      "07/27/2023 19:41:40 - INFO - __main__ - Per validation step average loss is 0.05862666666507721\n",
      "07/27/2023 19:41:40 - INFO - __main__ - Cumulative validation average loss is 1.4091072196606547\n",
      "07/27/2023 19:41:41 - INFO - __main__ - Per validation step average loss is 0.33831724524497986\n",
      "07/27/2023 19:41:41 - INFO - __main__ - Cumulative validation average loss is 1.7474244649056345\n",
      "07/27/2023 19:41:41 - INFO - __main__ - Per validation step average loss is 0.15157055854797363\n",
      "07/27/2023 19:41:41 - INFO - __main__ - Cumulative validation average loss is 1.8989950234536082\n",
      "07/27/2023 19:41:42 - INFO - __main__ - Per validation step average loss is 0.06624330580234528\n",
      "07/27/2023 19:41:42 - INFO - __main__ - Cumulative validation average loss is 1.9652383292559534\n",
      "07/27/2023 19:41:42 - INFO - __main__ - Per validation step average loss is 0.012651950120925903\n",
      "07/27/2023 19:41:42 - INFO - __main__ - Cumulative validation average loss is 1.9778902793768793\n",
      "07/27/2023 19:41:42 - INFO - __main__ - Per validation step average loss is 0.004944030195474625\n",
      "07/27/2023 19:41:42 - INFO - __main__ - Cumulative validation average loss is 1.982834309572354\n",
      "07/27/2023 19:41:43 - INFO - __main__ - Per validation step average loss is 0.16540898382663727\n",
      "07/27/2023 19:41:43 - INFO - __main__ - Cumulative validation average loss is 2.1482432933989912\n",
      "07/27/2023 19:41:43 - INFO - __main__ - Per validation step average loss is 0.0016261236742138863\n",
      "07/27/2023 19:41:43 - INFO - __main__ - Cumulative validation average loss is 2.149869417073205\n",
      "07/27/2023 19:41:44 - INFO - __main__ - Per validation step average loss is 0.04787512496113777\n",
      "07/27/2023 19:41:44 - INFO - __main__ - Cumulative validation average loss is 2.197744542034343\n",
      "07/27/2023 19:41:44 - INFO - __main__ - Per validation step average loss is 0.09237419068813324\n",
      "07/27/2023 19:41:44 - INFO - __main__ - Cumulative validation average loss is 2.290118732722476\n",
      "07/27/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.14211611449718475\n",
      "07/27/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 2.432234847219661\n",
      "07/27/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.003970002289861441\n",
      "07/27/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 2.4362048495095223\n",
      "07/27/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.041120000183582306\n",
      "07/27/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 2.4773248496931046\n",
      "07/27/2023 19:41:46 - INFO - __main__ - Per validation step average loss is 0.09081295132637024\n",
      "07/27/2023 19:41:46 - INFO - __main__ - Cumulative validation average loss is 2.568137801019475\n",
      "07/27/2023 19:41:46 - INFO - __main__ - Per validation step average loss is 0.010621677152812481\n",
      "07/27/2023 19:41:46 - INFO - __main__ - Cumulative validation average loss is 2.5787594781722873\n",
      "07/27/2023 19:41:47 - INFO - __main__ - Per validation step average loss is 0.09997677803039551\n",
      "07/27/2023 19:41:47 - INFO - __main__ - Cumulative validation average loss is 2.678736256202683\n",
      "07/27/2023 19:41:47 - INFO - __main__ - Per validation step average loss is 0.020989403128623962\n",
      "07/27/2023 19:41:47 - INFO - __main__ - Cumulative validation average loss is 2.699725659331307\n",
      "07/27/2023 19:41:47 - INFO - __main__ - Per validation step average loss is 0.002537553897127509\n",
      "07/27/2023 19:41:47 - INFO - __main__ - Cumulative validation average loss is 2.7022632132284343\n",
      "07/27/2023 19:41:48 - INFO - __main__ - Per validation step average loss is 0.0018560233293101192\n",
      "07/27/2023 19:41:48 - INFO - __main__ - Cumulative validation average loss is 2.7041192365577444\n",
      "07/27/2023 19:41:48 - INFO - __main__ - Per validation step average loss is 0.3494389057159424\n",
      "07/27/2023 19:41:48 - INFO - __main__ - Cumulative validation average loss is 3.053558142273687\n",
      "07/27/2023 19:41:49 - INFO - __main__ - Per validation step average loss is 0.20207667350769043\n",
      "07/27/2023 19:41:49 - INFO - __main__ - Cumulative validation average loss is 3.2556348157813773\n",
      "07/27/2023 19:41:49 - INFO - __main__ - Per validation step average loss is 0.24658305943012238\n",
      "07/27/2023 19:41:49 - INFO - __main__ - Cumulative validation average loss is 3.5022178752114996\n",
      "07/27/2023 19:41:49 - INFO - __main__ - Per validation step average loss is 0.02967427298426628\n",
      "07/27/2023 19:41:49 - INFO - __main__ - Cumulative validation average loss is 3.531892148195766\n",
      "07/27/2023 19:41:50 - INFO - __main__ - Per validation step average loss is 0.3392547369003296\n",
      "07/27/2023 19:41:50 - INFO - __main__ - Cumulative validation average loss is 3.8711468850960955\n",
      "07/27/2023 19:41:50 - INFO - __main__ - Per validation step average loss is 0.005754193291068077\n",
      "07/27/2023 19:41:50 - INFO - __main__ - Cumulative validation average loss is 3.8769010783871636\n",
      "07/27/2023 19:41:51 - INFO - __main__ - Per validation step average loss is 0.2954341769218445\n",
      "07/27/2023 19:41:51 - INFO - __main__ - Cumulative validation average loss is 4.172335255309008\n",
      "07/27/2023 19:41:51 - INFO - __main__ - Per validation step average loss is 0.010700412094593048\n",
      "07/27/2023 19:41:51 - INFO - __main__ - Cumulative validation average loss is 4.183035667403601\n",
      "07/27/2023 19:41:52 - INFO - __main__ - Per validation step average loss is 0.02573896199464798\n",
      "07/27/2023 19:41:52 - INFO - __main__ - Cumulative validation average loss is 4.208774629398249\n",
      "07/27/2023 19:41:52 - INFO - __main__ - Per validation step average loss is 0.3773510456085205\n",
      "07/27/2023 19:41:52 - INFO - __main__ - Cumulative validation average loss is 4.58612567500677\n",
      "07/27/2023 19:41:52 - INFO - __main__ - Per validation step average loss is 0.20135203003883362\n",
      "07/27/2023 19:41:52 - INFO - __main__ - Cumulative validation average loss is 4.787477705045603\n",
      "07/27/2023 19:41:53 - INFO - __main__ - Per validation step average loss is 0.207099050283432\n",
      "07/27/2023 19:41:53 - INFO - __main__ - Cumulative validation average loss is 4.994576755329035\n",
      "07/27/2023 19:41:53 - INFO - __main__ - Per validation step average loss is 0.024033820256590843\n",
      "07/27/2023 19:41:53 - INFO - __main__ - Cumulative validation average loss is 5.018610575585626\n",
      "07/27/2023 19:41:54 - INFO - __main__ - Per validation step average loss is 0.003847218118607998\n",
      "07/27/2023 19:41:54 - INFO - __main__ - Cumulative validation average loss is 5.022457793704234\n",
      "07/27/2023 19:41:54 - INFO - __main__ - Per validation step average loss is 0.12497054040431976\n",
      "07/27/2023 19:41:54 - INFO - __main__ - Cumulative validation average loss is 5.147428334108554\n",
      "07/27/2023 19:41:54 - INFO - __main__ - Per validation step average loss is 0.007327795494347811\n",
      "07/27/2023 19:41:54 - INFO - __main__ - Cumulative validation average loss is 5.154756129602902\n",
      "07/27/2023 19:41:55 - INFO - __main__ - Per validation step average loss is 0.1107495054602623\n",
      "07/27/2023 19:41:55 - INFO - __main__ - Cumulative validation average loss is 5.265505635063164\n",
      "07/27/2023 19:41:55 - INFO - __main__ - Per validation step average loss is 0.04077933356165886\n",
      "07/27/2023 19:41:55 - INFO - __main__ - Cumulative validation average loss is 5.306284968624823\n",
      "07/27/2023 19:41:56 - INFO - __main__ - Per validation step average loss is 0.005919229239225388\n",
      "07/27/2023 19:41:56 - INFO - __main__ - Cumulative validation average loss is 5.312204197864048\n",
      "07/27/2023 19:41:56 - INFO - __main__ - Per validation step average loss is 0.2300303876399994\n",
      "07/27/2023 19:41:56 - INFO - __main__ - Cumulative validation average loss is 5.542234585504048\n",
      "07/27/2023 19:41:57 - INFO - __main__ - Per validation step average loss is 0.015632139518857002\n",
      "07/27/2023 19:41:57 - INFO - __main__ - Cumulative validation average loss is 5.557866725022905\n",
      "07/27/2023 19:41:57 - INFO - __main__ - Per validation step average loss is 0.04003366455435753\n",
      "07/27/2023 19:41:57 - INFO - __main__ - Cumulative validation average loss is 5.597900389577262\n",
      "07/27/2023 19:41:57 - INFO - __main__ - Per validation step average loss is 0.11024952679872513\n",
      "07/27/2023 19:41:57 - INFO - __main__ - Cumulative validation average loss is 5.708149916375987\n",
      "07/27/2023 19:41:58 - INFO - __main__ - Per validation step average loss is 0.06843408942222595\n",
      "07/27/2023 19:41:58 - INFO - __main__ - Cumulative validation average loss is 5.776584005798213\n",
      "07/27/2023 19:41:58 - INFO - __main__ - Per validation step average loss is 0.011900439858436584\n",
      "07/27/2023 19:41:58 - INFO - __main__ - Cumulative validation average loss is 5.78848444565665\n",
      "07/27/2023 19:41:59 - INFO - __main__ - Per validation step average loss is 0.01933704875409603\n",
      "07/27/2023 19:41:59 - INFO - __main__ - Cumulative validation average loss is 5.807821494410746\n",
      "07/27/2023 19:41:59 - INFO - __main__ - Per validation step average loss is 0.30562907457351685\n",
      "07/27/2023 19:41:59 - INFO - __main__ - Cumulative validation average loss is 6.113450568984263\n",
      "07/27/2023 19:41:59 - INFO - __main__ - Per validation step average loss is 0.018377408385276794\n",
      "07/27/2023 19:41:59 - INFO - __main__ - Cumulative validation average loss is 6.131827977369539\n",
      "07/27/2023 19:42:00 - INFO - __main__ - Per validation step average loss is 0.1178523451089859\n",
      "07/27/2023 19:42:00 - INFO - __main__ - Cumulative validation average loss is 6.249680322478525\n",
      "07/27/2023 19:42:00 - INFO - __main__ - Per validation step average loss is 0.08462268114089966\n",
      "07/27/2023 19:42:00 - INFO - __main__ - Cumulative validation average loss is 6.334303003619425\n",
      "07/27/2023 19:42:01 - INFO - __main__ - Per validation step average loss is 0.07403124868869781\n",
      "07/27/2023 19:42:01 - INFO - __main__ - Cumulative validation average loss is 6.408334252308123\n",
      "07/27/2023 19:42:01 - INFO - __main__ - Per validation step average loss is 0.16901257634162903\n",
      "07/27/2023 19:42:01 - INFO - __main__ - Cumulative validation average loss is 6.577346828649752\n",
      "07/27/2023 19:42:02 - INFO - __main__ - Per validation step average loss is 0.319082111120224\n",
      "07/27/2023 19:42:02 - INFO - __main__ - Cumulative validation average loss is 6.896428939769976\n",
      "07/27/2023 19:42:02 - INFO - __main__ - Per validation step average loss is 0.39195606112480164\n",
      "07/27/2023 19:42:02 - INFO - __main__ - Cumulative validation average loss is 7.2883850008947775\n",
      "07/27/2023 19:42:02 - INFO - __main__ - Per validation step average loss is 0.04972267150878906\n",
      "07/27/2023 19:42:02 - INFO - __main__ - Cumulative validation average loss is 7.3381076724035665\n",
      "07/27/2023 19:42:03 - INFO - __main__ - Per validation step average loss is 0.03673730790615082\n",
      "07/27/2023 19:42:03 - INFO - __main__ - Cumulative validation average loss is 7.374844980309717\n",
      "07/27/2023 19:42:03 - INFO - __main__ - Per validation step average loss is 0.0262829028069973\n",
      "07/27/2023 19:42:03 - INFO - __main__ - Cumulative validation average loss is 7.401127883116715\n",
      "07/27/2023 19:42:04 - INFO - __main__ - Per validation step average loss is 0.28545698523521423\n",
      "07/27/2023 19:42:04 - INFO - __main__ - Cumulative validation average loss is 7.686584868351929\n",
      "07/27/2023 19:42:04 - INFO - __main__ - Per validation step average loss is 0.006466458551585674\n",
      "07/27/2023 19:42:04 - INFO - __main__ - Cumulative validation average loss is 7.693051326903515\n",
      "07/27/2023 19:42:04 - INFO - __main__ - Per validation step average loss is 0.02748364768922329\n",
      "07/27/2023 19:42:04 - INFO - __main__ - Cumulative validation average loss is 7.720534974592738\n",
      "07/27/2023 19:42:05 - INFO - __main__ - Per validation step average loss is 0.01755758933722973\n",
      "07/27/2023 19:42:05 - INFO - __main__ - Cumulative validation average loss is 7.738092563929968\n",
      "07/27/2023 19:42:05 - INFO - __main__ - Per validation step average loss is 0.06406903266906738\n",
      "07/27/2023 19:42:05 - INFO - __main__ - Cumulative validation average loss is 7.802161596599035\n",
      "07/27/2023 19:42:06 - INFO - __main__ - Per validation step average loss is 0.04935018718242645\n",
      "07/27/2023 19:42:06 - INFO - __main__ - Cumulative validation average loss is 7.851511783781461\n",
      "07/27/2023 19:42:06 - INFO - __main__ - Per validation step average loss is 0.005462951492518187\n",
      "07/27/2023 19:42:06 - INFO - __main__ - Cumulative validation average loss is 7.85697473527398\n",
      "07/27/2023 19:42:07 - INFO - __main__ - Per validation step average loss is 0.35358041524887085\n",
      "07/27/2023 19:42:07 - INFO - __main__ - Cumulative validation average loss is 8.21055515052285\n",
      "07/27/2023 19:42:07 - INFO - __main__ - Per validation step average loss is 0.005223741289228201\n",
      "07/27/2023 19:42:07 - INFO - __main__ - Cumulative validation average loss is 8.215778891812079\n",
      "07/27/2023 19:42:07 - INFO - __main__ - Average validation loss for Epoch 44 is 0.10399720116217821\n",
      "07/27/2023 19:42:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:43:04 - INFO - __main__ - Starting epoch 45\n",
      "07/27/2023 19:43:05 - INFO - __main__ - train loss is 0.003645864315330982\n",
      "Steps:  91%|▉| 13636/15000 [1:58:15<10:28:48, 27.66s/it, lr=0.000971, step_loss=07/27/2023 19:43:05 - INFO - __main__ - train loss is 0.0063999120611697435\n",
      "Steps:  91%|▉| 13637/15000 [1:58:15<7:21:06, 19.42s/it, lr=0.000971, step_loss=007/27/2023 19:43:05 - INFO - __main__ - train loss is 0.023448094027116895\n",
      "Steps:  91%|▉| 13638/15000 [1:58:16<5:09:50, 13.65s/it, lr=0.000971, step_loss=007/27/2023 19:43:05 - INFO - __main__ - train loss is 0.07687559654004872\n",
      "Steps:  91%|▉| 13639/15000 [1:58:16<3:38:01,  9.61s/it, lr=0.000971, step_loss=007/27/2023 19:43:06 - INFO - __main__ - train loss is 0.07900311541743577\n",
      "Steps:  91%|▉| 13640/15000 [1:58:16<2:33:47,  6.78s/it, lr=0.000971, step_loss=007/27/2023 19:43:06 - INFO - __main__ - train loss is 0.08420345024205744\n",
      "Steps:  91%|▉| 13641/15000 [1:58:16<1:48:48,  4.80s/it, lr=0.000971, step_loss=007/27/2023 19:43:06 - INFO - __main__ - train loss is 0.09333467693068087\n",
      "Steps:  91%|▉| 13642/15000 [1:58:16<1:17:19,  3.42s/it, lr=0.000971, step_loss=007/27/2023 19:43:06 - INFO - __main__ - train loss is 0.16195833892561495\n",
      "Steps:  91%|▉| 13643/15000 [1:58:17<55:18,  2.45s/it, lr=0.000971, step_loss=0.007/27/2023 19:43:06 - INFO - __main__ - train loss is 0.3941458931658417\n",
      "Steps:  91%|▉| 13644/15000 [1:58:17<39:53,  1.77s/it, lr=0.000971, step_loss=0.207/27/2023 19:43:07 - INFO - __main__ - train loss is 0.4579625225160271\n",
      "Steps:  91%|▉| 13645/15000 [1:58:17<29:06,  1.29s/it, lr=0.000971, step_loss=0.007/27/2023 19:43:07 - INFO - __main__ - train loss is 0.5603985807392746\n",
      "Steps:  91%|▉| 13646/15000 [1:58:17<21:34,  1.05it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:07 - INFO - __main__ - train loss is 0.7148543468210846\n",
      "Steps:  91%|▉| 13647/15000 [1:58:17<16:18,  1.38it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:07 - INFO - __main__ - train loss is 0.719186942325905\n",
      "Steps:  91%|▉| 13648/15000 [1:58:17<12:36,  1.79it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:07 - INFO - __main__ - train loss is 0.7292835304979235\n",
      "Steps:  91%|▉| 13649/15000 [1:58:18<10:06,  2.23it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:07 - INFO - __main__ - train loss is 0.8624762783292681\n",
      "Steps:  91%|▉| 13650/15000 [1:58:18<08:17,  2.71it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:08 - INFO - __main__ - train loss is 0.8637698733946308\n",
      "Steps:  91%|▉| 13651/15000 [1:58:18<07:00,  3.20it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:08 - INFO - __main__ - train loss is 1.0748878264566883\n",
      "Steps:  91%|▉| 13652/15000 [1:58:18<06:06,  3.67it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:08 - INFO - __main__ - train loss is 1.1124438041588292\n",
      "Steps:  91%|▉| 13653/15000 [1:58:18<05:29,  4.09it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:08 - INFO - __main__ - train loss is 1.1179838705575094\n",
      "Steps:  91%|▉| 13654/15000 [1:58:19<05:03,  4.44it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:08 - INFO - __main__ - train loss is 1.7073729563271627\n",
      "Steps:  91%|▉| 13655/15000 [1:58:19<04:44,  4.73it/s, lr=0.000971, step_loss=0.507/27/2023 19:43:09 - INFO - __main__ - train loss is 1.7740253884112462\n",
      "Steps:  91%|▉| 13656/15000 [1:58:19<04:31,  4.95it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:09 - INFO - __main__ - train loss is 1.7757806992158294\n",
      "Steps:  91%|▉| 13657/15000 [1:58:19<04:23,  5.09it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:09 - INFO - __main__ - train loss is 1.780376018024981\n",
      "Steps:  91%|▉| 13658/15000 [1:58:19<04:16,  5.23it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:09 - INFO - __main__ - train loss is 1.7913277177140117\n",
      "Steps:  91%|▉| 13659/15000 [1:58:19<04:11,  5.32it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:09 - INFO - __main__ - train loss is 1.9259521542117\n",
      "Steps:  91%|▉| 13660/15000 [1:58:20<04:08,  5.39it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:09 - INFO - __main__ - train loss is 2.012876587919891\n",
      "Steps:  91%|▉| 13661/15000 [1:58:20<04:06,  5.44it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:10 - INFO - __main__ - train loss is 2.3132803617045283\n",
      "Steps:  91%|▉| 13662/15000 [1:58:20<04:04,  5.48it/s, lr=0.000971, step_loss=0.307/27/2023 19:43:10 - INFO - __main__ - train loss is 2.506853419356048\n",
      "Steps:  91%|▉| 13663/15000 [1:58:20<04:03,  5.50it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:10 - INFO - __main__ - train loss is 2.52946821693331\n",
      "Steps:  91%|▉| 13664/15000 [1:58:20<04:02,  5.52it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:10 - INFO - __main__ - train loss is 2.5992128336802125\n",
      "Steps:  91%|▉| 13665/15000 [1:58:20<04:01,  5.54it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:10 - INFO - __main__ - train loss is 2.7858997071161866\n",
      "Steps:  91%|▉| 13666/15000 [1:58:21<04:00,  5.54it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:11 - INFO - __main__ - train loss is 2.8172263028100133\n",
      "Steps:  91%|▉| 13667/15000 [1:58:21<04:00,  5.55it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:11 - INFO - __main__ - train loss is 3.1587189557030797\n",
      "Steps:  91%|▉| 13668/15000 [1:58:21<03:59,  5.55it/s, lr=0.000971, step_loss=0.307/27/2023 19:43:11 - INFO - __main__ - train loss is 3.1659680223092437\n",
      "Steps:  91%|▉| 13669/15000 [1:58:21<03:59,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:11 - INFO - __main__ - train loss is 3.1757531920447946\n",
      "Steps:  91%|▉| 13670/15000 [1:58:21<03:59,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:11 - INFO - __main__ - train loss is 3.4255188116803765\n",
      "Steps:  91%|▉| 13671/15000 [1:58:22<03:58,  5.56it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:11 - INFO - __main__ - train loss is 3.4270039150724187\n",
      "Steps:  91%|▉| 13672/15000 [1:58:22<04:00,  5.53it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:12 - INFO - __main__ - train loss is 3.440400610328652\n",
      "Steps:  91%|▉| 13673/15000 [1:58:22<03:59,  5.54it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:12 - INFO - __main__ - train loss is 3.45451855531428\n",
      "Steps:  91%|▉| 13674/15000 [1:58:22<04:00,  5.52it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:12 - INFO - __main__ - train loss is 3.5804446624824777\n",
      "Steps:  91%|▉| 13675/15000 [1:58:22<03:59,  5.54it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:12 - INFO - __main__ - train loss is 4.119632332236506\n",
      "Steps:  91%|▉| 13676/15000 [1:58:22<03:58,  5.55it/s, lr=0.000971, step_loss=0.507/27/2023 19:43:12 - INFO - __main__ - train loss is 4.137969460920431\n",
      "Steps:  91%|▉| 13677/15000 [1:58:23<03:58,  5.55it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:13 - INFO - __main__ - train loss is 4.2266320703784\n",
      "Steps:  91%|▉| 13678/15000 [1:58:23<03:57,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:13 - INFO - __main__ - train loss is 4.274539825157262\n",
      "Steps:  91%|▉| 13679/15000 [1:58:23<03:57,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:13 - INFO - __main__ - train loss is 4.279562737443484\n",
      "Steps:  91%|▉| 13680/15000 [1:58:23<03:57,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:13 - INFO - __main__ - train loss is 4.320802028873004\n",
      "Steps:  91%|▉| 13681/15000 [1:58:23<03:57,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:13 - INFO - __main__ - train loss is 4.580679651000537\n",
      "Steps:  91%|▉| 13682/15000 [1:58:24<03:56,  5.57it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:13 - INFO - __main__ - train loss is 4.616247053840198\n",
      "Steps:  91%|▉| 13683/15000 [1:58:24<03:56,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:14 - INFO - __main__ - train loss is 4.6211504630045965\n",
      "Steps:  91%|▉| 13684/15000 [1:58:24<03:57,  5.55it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:14 - INFO - __main__ - train loss is 4.679194911499508\n",
      "Steps:  91%|▉| 13685/15000 [1:58:24<03:56,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:14 - INFO - __main__ - train loss is 4.775978951831348\n",
      "Steps:  91%|▉| 13686/15000 [1:58:24<03:56,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:14 - INFO - __main__ - train loss is 4.863421811838634\n",
      "Steps:  91%|▉| 13687/15000 [1:58:24<03:56,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:14 - INFO - __main__ - train loss is 4.895953974802978\n",
      "Steps:  91%|▉| 13688/15000 [1:58:25<03:55,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:15 - INFO - __main__ - train loss is 5.457207045634277\n",
      "Steps:  91%|▉| 13689/15000 [1:58:25<03:55,  5.57it/s, lr=0.000971, step_loss=0.507/27/2023 19:43:15 - INFO - __main__ - train loss is 5.463298815418966\n",
      "Steps:  91%|▉| 13690/15000 [1:58:25<03:55,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:15 - INFO - __main__ - train loss is 5.665104913641699\n",
      "Steps:  91%|▉| 13691/15000 [1:58:25<03:55,  5.57it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:15 - INFO - __main__ - train loss is 5.667437919531949\n",
      "Steps:  91%|▉| 13692/15000 [1:58:25<03:54,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:15 - INFO - __main__ - train loss is 6.224170097266324\n",
      "Steps:  91%|▉| 13693/15000 [1:58:26<03:54,  5.57it/s, lr=0.000971, step_loss=0.507/27/2023 19:43:15 - INFO - __main__ - train loss is 6.300824658130296\n",
      "Steps:  91%|▉| 13694/15000 [1:58:26<03:54,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:16 - INFO - __main__ - train loss is 6.305680345394649\n",
      "Steps:  91%|▉| 13695/15000 [1:58:26<03:54,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:16 - INFO - __main__ - train loss is 6.352414216496982\n",
      "Steps:  91%|▉| 13696/15000 [1:58:26<03:54,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:16 - INFO - __main__ - train loss is 6.476335998275317\n",
      "Steps:  91%|▉| 13697/15000 [1:58:26<03:54,  5.56it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:16 - INFO - __main__ - train loss is 6.750701304175891\n",
      "Steps:  91%|▉| 13698/15000 [1:58:26<03:53,  5.57it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:16 - INFO - __main__ - train loss is 6.854899648227729\n",
      "Steps:  91%|▉| 13699/15000 [1:58:27<03:54,  5.55it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:16 - INFO - __main__ - train loss is 6.8782968145096675\n",
      "Steps:  91%|▉| 13700/15000 [1:58:27<03:53,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:17 - INFO - __main__ - train loss is 6.954286925145425\n",
      "Steps:  91%|▉| 13701/15000 [1:58:27<03:53,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:17 - INFO - __main__ - train loss is 6.968594096251763\n",
      "Steps:  91%|▉| 13702/15000 [1:58:27<03:53,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:17 - INFO - __main__ - train loss is 6.97420304978732\n",
      "Steps:  91%|▉| 13703/15000 [1:58:27<03:52,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:17 - INFO - __main__ - train loss is 7.276975065120496\n",
      "Steps:  91%|▉| 13704/15000 [1:58:28<03:52,  5.57it/s, lr=0.000971, step_loss=0.307/27/2023 19:43:17 - INFO - __main__ - train loss is 7.2805445060366765\n",
      "Steps:  91%|▉| 13705/15000 [1:58:28<03:52,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:18 - INFO - __main__ - train loss is 7.584947691881098\n",
      "Steps:  91%|▉| 13706/15000 [1:58:28<03:52,  5.57it/s, lr=0.000971, step_loss=0.307/27/2023 19:43:18 - INFO - __main__ - train loss is 7.922839985811152\n",
      "Steps:  91%|▉| 13707/15000 [1:58:28<03:52,  5.57it/s, lr=0.000971, step_loss=0.307/27/2023 19:43:18 - INFO - __main__ - train loss is 7.9447291024262086\n",
      "Steps:  91%|▉| 13708/15000 [1:58:28<03:52,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:18 - INFO - __main__ - train loss is 8.225571138435043\n",
      "Steps:  91%|▉| 13709/15000 [1:58:28<03:52,  5.56it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:18 - INFO - __main__ - train loss is 8.230107762967236\n",
      "Steps:  91%|▉| 13710/15000 [1:58:29<03:52,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:18 - INFO - __main__ - train loss is 8.271862165187486\n",
      "Steps:  91%|▉| 13711/15000 [1:58:29<03:52,  5.55it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:19 - INFO - __main__ - train loss is 8.347376645659097\n",
      "Steps:  91%|▉| 13712/15000 [1:58:29<03:51,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:19 - INFO - __main__ - train loss is 8.463740454171784\n",
      "Steps:  91%|▉| 13713/15000 [1:58:29<03:53,  5.51it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:19 - INFO - __main__ - train loss is 8.553730727289803\n",
      "Steps:  91%|▉| 13714/15000 [1:58:29<03:53,  5.51it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:19 - INFO - __main__ - train loss is 8.560088500962593\n",
      "Steps:  91%|▉| 13715/15000 [1:58:29<03:52,  5.52it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:19 - INFO - __main__ - train loss is 8.623598754988052\n",
      "Steps:  91%|▉| 13716/15000 [1:58:30<03:51,  5.54it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:20 - INFO - __main__ - train loss is 8.806236178264953\n",
      "Steps:  91%|▉| 13717/15000 [1:58:30<03:51,  5.55it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:20 - INFO - __main__ - train loss is 8.834123664186336\n",
      "Steps:  91%|▉| 13718/15000 [1:58:30<03:50,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:20 - INFO - __main__ - train loss is 8.899077796027996\n",
      "Steps:  91%|▉| 13719/15000 [1:58:30<03:50,  5.56it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:20 - INFO - __main__ - train loss is 9.126389168784954\n",
      "Steps:  91%|▉| 13720/15000 [1:58:30<03:52,  5.51it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:20 - INFO - __main__ - train loss is 9.129808928933926\n",
      "Steps:  91%|▉| 13721/15000 [1:58:31<03:54,  5.46it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:20 - INFO - __main__ - train loss is 9.161857973900624\n",
      "Steps:  91%|▉| 13722/15000 [1:58:31<03:55,  5.44it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:21 - INFO - __main__ - train loss is 9.33867902692873\n",
      "Steps:  91%|▉| 13723/15000 [1:58:31<03:54,  5.45it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:21 - INFO - __main__ - train loss is 9.378631439176388\n",
      "Steps:  91%|▉| 13724/15000 [1:58:31<03:54,  5.44it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:21 - INFO - __main__ - train loss is 9.476859193411656\n",
      "Steps:  92%|▉| 13725/15000 [1:58:31<03:54,  5.45it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:21 - INFO - __main__ - train loss is 9.547530997660942\n",
      "Steps:  92%|▉| 13726/15000 [1:58:32<03:52,  5.48it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:21 - INFO - __main__ - train loss is 9.557586707291193\n",
      "Steps:  92%|▉| 13727/15000 [1:58:32<03:50,  5.51it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:22 - INFO - __main__ - train loss is 9.7998594121309\n",
      "Steps:  92%|▉| 13728/15000 [1:58:32<03:49,  5.53it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:22 - INFO - __main__ - train loss is 9.95906382065732\n",
      "Steps:  92%|▉| 13729/15000 [1:58:32<03:49,  5.55it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:22 - INFO - __main__ - train loss is 10.471734337625094\n",
      "Steps:  92%|▉| 13730/15000 [1:58:32<03:48,  5.55it/s, lr=0.000971, step_loss=0.507/27/2023 19:43:22 - INFO - __main__ - train loss is 10.711894087609835\n",
      "Steps:  92%|▉| 13731/15000 [1:58:32<03:48,  5.56it/s, lr=0.000971, step_loss=0.207/27/2023 19:43:22 - INFO - __main__ - train loss is 10.870867289719172\n",
      "Steps:  92%|▉| 13732/15000 [1:58:33<03:47,  5.56it/s, lr=0.000971, step_loss=0.107/27/2023 19:43:22 - INFO - __main__ - train loss is 10.881983505678363\n",
      "Steps:  92%|▉| 13733/15000 [1:58:33<03:47,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:23 - INFO - __main__ - train loss is 10.941957587492652\n",
      "Steps:  92%|▉| 13734/15000 [1:58:33<03:47,  5.57it/s, lr=0.000971, step_loss=0.007/27/2023 19:43:23 - INFO - __main__ - train loss is 10.952766245347448\n",
      "Steps:  92%|▉| 13735/15000 [1:58:33<03:47,  5.57it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:23 - INFO - __main__ - train loss is 10.997324099880643\n",
      "Steps:  92%|▉| 13736/15000 [1:58:33<03:48,  5.53it/s, lr=0.00097, step_loss=0.0407/27/2023 19:43:23 - INFO - __main__ - train loss is 11.310859432560392\n",
      "Steps:  92%|▉| 13737/15000 [1:58:33<03:49,  5.52it/s, lr=0.00097, step_loss=0.3107/27/2023 19:43:23 - INFO - __main__ - train loss is 11.335025061038323\n",
      "Steps:  92%|▉| 13738/15000 [1:58:34<03:48,  5.53it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:24 - INFO - __main__ - train loss is 11.452346678939648\n",
      "Steps:  92%|▉| 13739/15000 [1:58:34<03:47,  5.54it/s, lr=0.00097, step_loss=0.1107/27/2023 19:43:24 - INFO - __main__ - train loss is 11.466743685421534\n",
      "Steps:  92%|▉| 13740/15000 [1:58:34<03:46,  5.55it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:24 - INFO - __main__ - train loss is 11.472733249072917\n",
      "Steps:  92%|▉| 13741/15000 [1:58:34<03:48,  5.52it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:24 - INFO - __main__ - train loss is 11.803568084840663\n",
      "Steps:  92%|▉| 13742/15000 [1:58:34<03:49,  5.48it/s, lr=0.00097, step_loss=0.3307/27/2023 19:43:24 - INFO - __main__ - train loss is 11.805866746348329\n",
      "Steps:  92%|▉| 13743/15000 [1:58:35<03:48,  5.49it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:24 - INFO - __main__ - train loss is 12.018381876987405\n",
      "Steps:  92%|▉| 13744/15000 [1:58:35<03:47,  5.51it/s, lr=0.00097, step_loss=0.2107/27/2023 19:43:25 - INFO - __main__ - train loss is 12.02650947694201\n",
      "Steps:  92%|▉| 13745/15000 [1:58:35<03:47,  5.53it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:25 - INFO - __main__ - train loss is 12.184607518953271\n",
      "Steps:  92%|▉| 13746/15000 [1:58:35<03:46,  5.54it/s, lr=0.00097, step_loss=0.1507/27/2023 19:43:25 - INFO - __main__ - train loss is 12.668769491952844\n",
      "Steps:  92%|▉| 13747/15000 [1:58:35<03:45,  5.55it/s, lr=0.00097, step_loss=0.4807/27/2023 19:43:25 - INFO - __main__ - train loss is 12.681923788157292\n",
      "Steps:  92%|▉| 13748/15000 [1:58:35<03:45,  5.55it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:25 - INFO - __main__ - train loss is 12.745829161372967\n",
      "Steps:  92%|▉| 13749/15000 [1:58:36<03:46,  5.52it/s, lr=0.00097, step_loss=0.0607/27/2023 19:43:26 - INFO - __main__ - train loss is 12.881490107742138\n",
      "Steps:  92%|▉| 13750/15000 [1:58:36<03:47,  5.49it/s, lr=0.00097, step_loss=0.1307/27/2023 19:43:26 - INFO - __main__ - train loss is 12.904854837921448\n",
      "Steps:  92%|▉| 13751/15000 [1:58:36<03:46,  5.52it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:26 - INFO - __main__ - train loss is 13.042673919466324\n",
      "Steps:  92%|▉| 13752/15000 [1:58:36<03:47,  5.50it/s, lr=0.00097, step_loss=0.1307/27/2023 19:43:26 - INFO - __main__ - train loss is 13.548700068262406\n",
      "Steps:  92%|▉| 13753/15000 [1:58:36<03:48,  5.47it/s, lr=0.00097, step_loss=0.5007/27/2023 19:43:26 - INFO - __main__ - train loss is 13.60949786764104\n",
      "Steps:  92%|▉| 13754/15000 [1:58:37<03:47,  5.48it/s, lr=0.00097, step_loss=0.0607/27/2023 19:43:26 - INFO - __main__ - train loss is 13.632979668793269\n",
      "Steps:  92%|▉| 13755/15000 [1:58:37<03:46,  5.51it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:27 - INFO - __main__ - train loss is 13.751178532955237\n",
      "Steps:  92%|▉| 13756/15000 [1:58:37<03:45,  5.53it/s, lr=0.00097, step_loss=0.1107/27/2023 19:43:27 - INFO - __main__ - train loss is 14.150755494949408\n",
      "Steps:  92%|▉| 13757/15000 [1:58:37<03:46,  5.49it/s, lr=0.00097, step_loss=0.4]07/27/2023 19:43:27 - INFO - __main__ - train loss is 14.272314772126265\n",
      "Steps:  92%|▉| 13758/15000 [1:58:37<03:48,  5.44it/s, lr=0.00097, step_loss=0.1207/27/2023 19:43:27 - INFO - __main__ - train loss is 14.552666202303953\n",
      "Steps:  92%|▉| 13759/15000 [1:58:37<03:52,  5.35it/s, lr=0.00097, step_loss=0.2807/27/2023 19:43:27 - INFO - __main__ - train loss is 14.563262911629863\n",
      "Steps:  92%|▉| 13760/15000 [1:58:38<03:53,  5.31it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:28 - INFO - __main__ - train loss is 14.78495204646606\n",
      "Steps:  92%|▉| 13761/15000 [1:58:38<03:55,  5.25it/s, lr=0.00097, step_loss=0.2207/27/2023 19:43:28 - INFO - __main__ - train loss is 14.93336758215446\n",
      "Steps:  92%|▉| 13762/15000 [1:58:38<04:00,  5.15it/s, lr=0.00097, step_loss=0.1407/27/2023 19:43:28 - INFO - __main__ - train loss is 14.951905751717277\n",
      "Steps:  92%|▉| 13763/15000 [1:58:38<04:00,  5.14it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:28 - INFO - __main__ - train loss is 14.969189554569311\n",
      "Steps:  92%|▉| 13764/15000 [1:58:38<04:01,  5.13it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:28 - INFO - __main__ - train loss is 14.988173280027695\n",
      "Steps:  92%|▉| 13765/15000 [1:58:39<04:00,  5.13it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:29 - INFO - __main__ - train loss is 15.090939480927773\n",
      "Steps:  92%|▉| 13766/15000 [1:58:39<04:00,  5.12it/s, lr=0.00097, step_loss=0.1007/27/2023 19:43:29 - INFO - __main__ - train loss is 15.108553111669607\n",
      "Steps:  92%|▉| 13767/15000 [1:58:39<04:00,  5.12it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:29 - INFO - __main__ - train loss is 15.110080478829332\n",
      "Steps:  92%|▉| 13768/15000 [1:58:39<04:00,  5.12it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:29 - INFO - __main__ - train loss is 15.233738510054536\n",
      "Steps:  92%|▉| 13769/15000 [1:58:39<04:00,  5.12it/s, lr=0.00097, step_loss=0.1207/27/2023 19:43:29 - INFO - __main__ - train loss is 15.621341077727266\n",
      "Steps:  92%|▉| 13770/15000 [1:58:40<04:00,  5.12it/s, lr=0.00097, step_loss=0.3807/27/2023 19:43:30 - INFO - __main__ - train loss is 15.623241945169866\n",
      "Steps:  92%|▉| 13771/15000 [1:58:40<03:59,  5.12it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:30 - INFO - __main__ - train loss is 15.695875986479223\n",
      "Steps:  92%|▉| 13772/15000 [1:58:40<03:59,  5.13it/s, lr=0.00097, step_loss=0.0707/27/2023 19:43:30 - INFO - __main__ - train loss is 15.720462112687528\n",
      "Steps:  92%|▉| 13773/15000 [1:58:40<03:59,  5.12it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:30 - INFO - __main__ - train loss is 15.886724918149412\n",
      "Steps:  92%|▉| 13774/15000 [1:58:40<03:59,  5.12it/s, lr=0.00097, step_loss=0.1607/27/2023 19:43:30 - INFO - __main__ - train loss is 16.541363983415067\n",
      "Steps:  92%|▉| 13775/15000 [1:58:41<03:59,  5.12it/s, lr=0.00097, step_loss=0.6507/27/2023 19:43:30 - INFO - __main__ - train loss is 16.77900932636112\n",
      "Steps:  92%|▉| 13776/15000 [1:58:41<03:55,  5.21it/s, lr=0.00097, step_loss=0.2307/27/2023 19:43:31 - INFO - __main__ - train loss is 16.790694296360016\n",
      "Steps:  92%|▉| 13777/15000 [1:58:41<03:54,  5.21it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:31 - INFO - __main__ - train loss is 16.963546693325043\n",
      "Steps:  92%|▉| 13778/15000 [1:58:41<03:55,  5.19it/s, lr=0.00097, step_loss=0.1707/27/2023 19:43:31 - INFO - __main__ - train loss is 17.125996306538582\n",
      "Steps:  92%|▉| 13779/15000 [1:58:41<03:56,  5.16it/s, lr=0.00097, step_loss=0.1607/27/2023 19:43:31 - INFO - __main__ - train loss is 17.304380789399147\n",
      "Steps:  92%|▉| 13780/15000 [1:58:42<03:56,  5.15it/s, lr=0.00097, step_loss=0.1707/27/2023 19:43:31 - INFO - __main__ - train loss is 17.33575975522399\n",
      "Steps:  92%|▉| 13781/15000 [1:58:42<03:57,  5.14it/s, lr=0.00097, step_loss=0.0307/27/2023 19:43:32 - INFO - __main__ - train loss is 17.36116180755198\n",
      "Steps:  92%|▉| 13782/15000 [1:58:42<03:56,  5.16it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:32 - INFO - __main__ - train loss is 17.38393954001367\n",
      "Steps:  92%|▉| 13783/15000 [1:58:42<03:56,  5.14it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:32 - INFO - __main__ - train loss is 17.402356255799532\n",
      "Steps:  92%|▉| 13784/15000 [1:58:42<03:57,  5.13it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:32 - INFO - __main__ - train loss is 17.558392722159624\n",
      "Steps:  92%|▉| 13785/15000 [1:58:43<03:57,  5.12it/s, lr=0.00097, step_loss=0.1507/27/2023 19:43:32 - INFO - __main__ - train loss is 17.687395725399256\n",
      "Steps:  92%|▉| 13786/15000 [1:58:43<03:57,  5.12it/s, lr=0.00097, step_loss=0.1207/27/2023 19:43:33 - INFO - __main__ - train loss is 17.749000880867243\n",
      "Steps:  92%|▉| 13787/15000 [1:58:43<03:57,  5.11it/s, lr=0.00097, step_loss=0.0607/27/2023 19:43:33 - INFO - __main__ - train loss is 17.832768719643354\n",
      "Steps:  92%|▉| 13788/15000 [1:58:43<03:56,  5.12it/s, lr=0.00097, step_loss=0.0807/27/2023 19:43:33 - INFO - __main__ - train loss is 17.849933240562677\n",
      "Steps:  92%|▉| 13789/15000 [1:58:43<03:56,  5.11it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:33 - INFO - __main__ - train loss is 17.859197955578566\n",
      "Steps:  92%|▉| 13790/15000 [1:58:44<03:56,  5.12it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:33 - INFO - __main__ - train loss is 17.887656398117542\n",
      "Steps:  92%|▉| 13791/15000 [1:58:44<03:56,  5.11it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:34 - INFO - __main__ - train loss is 18.21604833751917\n",
      "Steps:  92%|▉| 13792/15000 [1:58:44<03:56,  5.11it/s, lr=0.00097, step_loss=0.3207/27/2023 19:43:34 - INFO - __main__ - train loss is 18.305796794593334\n",
      "Steps:  92%|▉| 13793/15000 [1:58:44<03:56,  5.11it/s, lr=0.00097, step_loss=0.0807/27/2023 19:43:34 - INFO - __main__ - train loss is 18.604876182973385\n",
      "Steps:  92%|▉| 13794/15000 [1:58:44<04:03,  4.96it/s, lr=0.00097, step_loss=0.2907/27/2023 19:43:34 - INFO - __main__ - train loss is 18.628755003213882\n",
      "Steps:  92%|▉| 13795/15000 [1:58:45<04:32,  4.43it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:35 - INFO - __main__ - train loss is 18.70128883421421\n",
      "Steps:  92%|▉| 13796/15000 [1:58:45<04:22,  4.59it/s, lr=0.00097, step_loss=0.0707/27/2023 19:43:35 - INFO - __main__ - train loss is 18.72688391059637\n",
      "Steps:  92%|▉| 13797/15000 [1:58:45<04:18,  4.65it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:35 - INFO - __main__ - train loss is 18.733317754697055\n",
      "Steps:  92%|▉| 13798/15000 [1:58:45<04:11,  4.78it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:35 - INFO - __main__ - train loss is 18.74824753915891\n",
      "Steps:  92%|▉| 13799/15000 [1:58:45<04:03,  4.93it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:35 - INFO - __main__ - train loss is 18.931192090269178\n",
      "Steps:  92%|▉| 13800/15000 [1:58:46<04:00,  4.99it/s, lr=0.00097, step_loss=0.1807/27/2023 19:43:35 - INFO - __main__ - train loss is 18.988675569649786\n",
      "Steps:  92%|▉| 13801/15000 [1:58:46<03:59,  5.02it/s, lr=0.00097, step_loss=0.0507/27/2023 19:43:36 - INFO - __main__ - train loss is 19.483730738516897\n",
      "Steps:  92%|▉| 13802/15000 [1:58:46<03:56,  5.06it/s, lr=0.00097, step_loss=0.4907/27/2023 19:43:36 - INFO - __main__ - train loss is 19.512507199775428\n",
      "Steps:  92%|▉| 13803/15000 [1:58:46<03:56,  5.07it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:36 - INFO - __main__ - train loss is 19.92218881798908\n",
      "Steps:  92%|▉| 13804/15000 [1:58:46<03:55,  5.08it/s, lr=0.00097, step_loss=0.4107/27/2023 19:43:36 - INFO - __main__ - train loss is 20.421281188260764\n",
      "Steps:  92%|▉| 13805/15000 [1:58:47<03:55,  5.08it/s, lr=0.00097, step_loss=0.4907/27/2023 19:43:36 - INFO - __main__ - train loss is 20.590523212682456\n",
      "Steps:  92%|▉| 13806/15000 [1:58:47<03:52,  5.14it/s, lr=0.00097, step_loss=0.1607/27/2023 19:43:37 - INFO - __main__ - train loss is 20.592745087575167\n",
      "Steps:  92%|▉| 13807/15000 [1:58:47<03:48,  5.22it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:37 - INFO - __main__ - train loss is 20.617006085347384\n",
      "Steps:  92%|▉| 13808/15000 [1:58:47<03:46,  5.26it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:37 - INFO - __main__ - train loss is 20.75993291242048\n",
      "Steps:  92%|▉| 13809/15000 [1:58:47<03:42,  5.34it/s, lr=0.00097, step_loss=0.1407/27/2023 19:43:37 - INFO - __main__ - train loss is 20.882552481722087\n",
      "Steps:  92%|▉| 13810/15000 [1:58:48<03:40,  5.41it/s, lr=0.00097, step_loss=0.1207/27/2023 19:43:37 - INFO - __main__ - train loss is 20.920026212465018\n",
      "Steps:  92%|▉| 13811/15000 [1:58:48<03:37,  5.46it/s, lr=0.00097, step_loss=0.0307/27/2023 19:43:38 - INFO - __main__ - train loss is 20.948235678952187\n",
      "Steps:  92%|▉| 13812/15000 [1:58:48<03:36,  5.49it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:38 - INFO - __main__ - train loss is 21.00964904902503\n",
      "Steps:  92%|▉| 13813/15000 [1:58:48<03:35,  5.51it/s, lr=0.00097, step_loss=0.0607/27/2023 19:43:38 - INFO - __main__ - train loss is 21.139972295146435\n",
      "Steps:  92%|▉| 13814/15000 [1:58:48<03:34,  5.53it/s, lr=0.00097, step_loss=0.1307/27/2023 19:43:38 - INFO - __main__ - train loss is 21.184958684723824\n",
      "Steps:  92%|▉| 13815/15000 [1:58:48<03:33,  5.54it/s, lr=0.00097, step_loss=0.0407/27/2023 19:43:38 - INFO - __main__ - train loss is 21.292849365156144\n",
      "Steps:  92%|▉| 13816/15000 [1:58:49<03:33,  5.55it/s, lr=0.00097, step_loss=0.1007/27/2023 19:43:38 - INFO - __main__ - train loss is 21.294245341792703\n",
      "Steps:  92%|▉| 13817/15000 [1:58:49<03:32,  5.56it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:39 - INFO - __main__ - train loss is 21.37981399334967\n",
      "Steps:  92%|▉| 13818/15000 [1:58:49<03:32,  5.56it/s, lr=0.00097, step_loss=0.0807/27/2023 19:43:39 - INFO - __main__ - train loss is 21.391241040080786\n",
      "Steps:  92%|▉| 13819/15000 [1:58:49<03:32,  5.56it/s, lr=0.00097, step_loss=0.0107/27/2023 19:43:39 - INFO - __main__ - train loss is 21.51803858205676\n",
      "Steps:  92%|▉| 13820/15000 [1:58:49<03:32,  5.56it/s, lr=0.00097, step_loss=0.1207/27/2023 19:43:39 - INFO - __main__ - train loss is 21.967093627899885\n",
      "Steps:  92%|▉| 13821/15000 [1:58:49<03:31,  5.56it/s, lr=0.00097, step_loss=0.4407/27/2023 19:43:39 - INFO - __main__ - train loss is 21.97377892397344\n",
      "Steps:  92%|▉| 13822/15000 [1:58:50<03:31,  5.56it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:40 - INFO - __main__ - train loss is 22.057539803907275\n",
      "Steps:  92%|▉| 13823/15000 [1:58:50<03:31,  5.56it/s, lr=0.00097, step_loss=0.0807/27/2023 19:43:40 - INFO - __main__ - train loss is 22.06605075765401\n",
      "Steps:  92%|▉| 13824/15000 [1:58:50<03:31,  5.56it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:40 - INFO - __main__ - train loss is 22.06761858589016\n",
      "Steps:  92%|▉| 13825/15000 [1:58:50<03:31,  5.57it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:40 - INFO - __main__ - train loss is 22.0703975900542\n",
      "Steps:  92%|▉| 13826/15000 [1:58:50<03:31,  5.56it/s, lr=0.00097, step_loss=0.0007/27/2023 19:43:40 - INFO - __main__ - train loss is 22.201687250984833\n",
      "Steps:  92%|▉| 13827/15000 [1:58:51<03:31,  5.55it/s, lr=0.00097, step_loss=0.1307/27/2023 19:43:40 - INFO - __main__ - train loss is 22.557714734924957\n",
      "Steps:  92%|▉| 13828/15000 [1:58:51<03:31,  5.55it/s, lr=0.00097, step_loss=0.3507/27/2023 19:43:41 - INFO - __main__ - train loss is 22.58554117078893\n",
      "Steps:  92%|▉| 13829/15000 [1:58:51<03:30,  5.55it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:41 - INFO - __main__ - train loss is 22.60807003895752\n",
      "Steps:  92%|▉| 13830/15000 [1:58:51<03:31,  5.53it/s, lr=0.00097, step_loss=0.0207/27/2023 19:43:41 - INFO - __main__ - train loss is 22.86981209437363\n",
      "Steps:  92%|▉| 13831/15000 [1:58:51<03:31,  5.52it/s, lr=0.00097, step_loss=0.2607/27/2023 19:43:41 - INFO - __main__ - train loss is 22.882423425791785\n",
      "Steps:  92%|▉| 13832/15000 [1:58:51<03:31,  5.51it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:41 - INFO - __main__ - train loss is 22.985534670529887\n",
      "Steps:  92%|▉| 13833/15000 [1:58:52<03:31,  5.51it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:42 - INFO - __main__ - train loss is 23.86752403038554\n",
      "Steps:  92%|▉| 13834/15000 [1:58:52<03:31,  5.50it/s, lr=0.000969, step_loss=0.807/27/2023 19:43:42 - INFO - __main__ - train loss is 24.008167746244\n",
      "Steps:  92%|▉| 13835/15000 [1:58:52<03:31,  5.50it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:42 - INFO - __main__ - train loss is 24.013714499073103\n",
      "Steps:  92%|▉| 13836/15000 [1:58:52<03:31,  5.50it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:42 - INFO - __main__ - train loss is 24.05701159243472\n",
      "Steps:  92%|▉| 13837/15000 [1:58:52<03:31,  5.50it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:42 - INFO - __main__ - train loss is 24.09028863837011\n",
      "Steps:  92%|▉| 13838/15000 [1:58:53<03:31,  5.49it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:42 - INFO - __main__ - train loss is 24.28053581644781\n",
      "Steps:  92%|▉| 13839/15000 [1:58:53<03:33,  5.45it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:43 - INFO - __main__ - train loss is 24.281616844702512\n",
      "Steps:  92%|▉| 13840/15000 [1:58:53<03:32,  5.47it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:43 - INFO - __main__ - train loss is 24.361026585567743\n",
      "Steps:  92%|▉| 13841/15000 [1:58:53<03:30,  5.50it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:43 - INFO - __main__ - train loss is 24.776987970340997\n",
      "Steps:  92%|▉| 13842/15000 [1:58:53<03:29,  5.52it/s, lr=0.000969, step_loss=0.407/27/2023 19:43:43 - INFO - __main__ - train loss is 24.789116898085922\n",
      "Steps:  92%|▉| 13843/15000 [1:58:53<03:29,  5.54it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:43 - INFO - __main__ - train loss is 25.145309397485107\n",
      "Steps:  92%|▉| 13844/15000 [1:58:54<03:28,  5.55it/s, lr=0.000969, step_loss=0.307/27/2023 19:43:44 - INFO - __main__ - train loss is 25.15520030586049\n",
      "Steps:  92%|▉| 13845/15000 [1:58:54<03:27,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:44 - INFO - __main__ - train loss is 25.213979456108063\n",
      "Steps:  92%|▉| 13846/15000 [1:58:54<03:27,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:44 - INFO - __main__ - train loss is 25.24449167167768\n",
      "Steps:  92%|▉| 13847/15000 [1:58:54<03:27,  5.57it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:44 - INFO - __main__ - train loss is 25.249285890255123\n",
      "Steps:  92%|▉| 13848/15000 [1:58:54<03:26,  5.57it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:44 - INFO - __main__ - train loss is 25.252381164347753\n",
      "Steps:  92%|▉| 13849/15000 [1:58:55<03:26,  5.57it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:44 - INFO - __main__ - train loss is 25.614794242894277\n",
      "Steps:  92%|▉| 13850/15000 [1:58:55<03:26,  5.57it/s, lr=0.000969, step_loss=0.307/27/2023 19:43:45 - INFO - __main__ - train loss is 25.728446040069684\n",
      "Steps:  92%|▉| 13851/15000 [1:58:55<03:26,  5.57it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:45 - INFO - __main__ - train loss is 25.737513401312754\n",
      "Steps:  92%|▉| 13852/15000 [1:58:55<03:26,  5.57it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:45 - INFO - __main__ - train loss is 25.81031645159237\n",
      "Steps:  92%|▉| 13853/15000 [1:58:55<03:26,  5.57it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:45 - INFO - __main__ - train loss is 25.893091940088198\n",
      "Steps:  92%|▉| 13854/15000 [1:58:55<03:26,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:45 - INFO - __main__ - train loss is 25.94711008737795\n",
      "Steps:  92%|▉| 13855/15000 [1:58:56<03:25,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:45 - INFO - __main__ - train loss is 26.876816899282858\n",
      "Steps:  92%|▉| 13856/15000 [1:58:56<03:25,  5.56it/s, lr=0.000969, step_loss=0.907/27/2023 19:43:46 - INFO - __main__ - train loss is 27.55458024214022\n",
      "Steps:  92%|▉| 13857/15000 [1:58:56<03:25,  5.56it/s, lr=0.000969, step_loss=0.607/27/2023 19:43:46 - INFO - __main__ - train loss is 27.656331010861322\n",
      "Steps:  92%|▉| 13858/15000 [1:58:56<03:25,  5.56it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:46 - INFO - __main__ - train loss is 27.813261457486078\n",
      "Steps:  92%|▉| 13859/15000 [1:58:56<03:25,  5.56it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:46 - INFO - __main__ - train loss is 28.009917952818796\n",
      "Steps:  92%|▉| 13860/15000 [1:58:57<03:25,  5.56it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:46 - INFO - __main__ - train loss is 28.015355952782556\n",
      "Steps:  92%|▉| 13861/15000 [1:58:57<03:24,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:47 - INFO - __main__ - train loss is 28.14125391165726\n",
      "Steps:  92%|▉| 13862/15000 [1:58:57<03:24,  5.56it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:47 - INFO - __main__ - train loss is 28.156594577012584\n",
      "Steps:  92%|▉| 13863/15000 [1:58:57<03:24,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:47 - INFO - __main__ - train loss is 28.364035594044253\n",
      "Steps:  92%|▉| 13864/15000 [1:58:57<03:24,  5.56it/s, lr=0.000969, step_loss=0.207/27/2023 19:43:47 - INFO - __main__ - train loss is 28.55778771894984\n",
      "Steps:  92%|▉| 13865/15000 [1:58:57<03:24,  5.56it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:47 - INFO - __main__ - train loss is 28.55892427987419\n",
      "Steps:  92%|▉| 13866/15000 [1:58:58<03:23,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:47 - INFO - __main__ - train loss is 28.94465433782898\n",
      "Steps:  92%|▉| 13867/15000 [1:58:58<03:25,  5.51it/s, lr=0.000969, step_loss=0.307/27/2023 19:43:48 - INFO - __main__ - train loss is 28.993718039011583\n",
      "Steps:  92%|▉| 13868/15000 [1:58:58<03:25,  5.51it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:48 - INFO - __main__ - train loss is 29.01147011271678\n",
      "Steps:  92%|▉| 13869/15000 [1:58:58<03:24,  5.52it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:48 - INFO - __main__ - train loss is 29.09064756683074\n",
      "Steps:  92%|▉| 13870/15000 [1:58:58<03:24,  5.53it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:48 - INFO - __main__ - train loss is 29.252332661068067\n",
      "Steps:  92%|▉| 13871/15000 [1:58:59<03:23,  5.54it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:48 - INFO - __main__ - train loss is 29.331382680451497\n",
      "Steps:  92%|▉| 13872/15000 [1:58:59<03:24,  5.51it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:49 - INFO - __main__ - train loss is 29.611817080294713\n",
      "Steps:  92%|▉| 13873/15000 [1:58:59<03:24,  5.52it/s, lr=0.000969, step_loss=0.207/27/2023 19:43:49 - INFO - __main__ - train loss is 29.993848878657445\n",
      "Steps:  92%|▉| 13874/15000 [1:58:59<03:25,  5.49it/s, lr=0.000969, step_loss=0.307/27/2023 19:43:49 - INFO - __main__ - train loss is 30.522327739512548\n",
      "Steps:  92%|▉| 13875/15000 [1:58:59<03:24,  5.49it/s, lr=0.000969, step_loss=0.507/27/2023 19:43:49 - INFO - __main__ - train loss is 30.696347046410665\n",
      "Steps:  93%|▉| 13876/15000 [1:58:59<03:24,  5.51it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:49 - INFO - __main__ - train loss is 30.724617812549695\n",
      "Steps:  93%|▉| 13877/15000 [1:59:00<03:25,  5.47it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:49 - INFO - __main__ - train loss is 30.726816923124716\n",
      "Steps:  93%|▉| 13878/15000 [1:59:00<03:25,  5.46it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:50 - INFO - __main__ - train loss is 30.775101204169914\n",
      "Steps:  93%|▉| 13879/15000 [1:59:00<03:24,  5.49it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:50 - INFO - __main__ - train loss is 30.929878984345123\n",
      "Steps:  93%|▉| 13880/15000 [1:59:00<03:23,  5.52it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:50 - INFO - __main__ - train loss is 30.998790216399357\n",
      "Steps:  93%|▉| 13881/15000 [1:59:00<03:22,  5.53it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:50 - INFO - __main__ - train loss is 31.024505258305\n",
      "Steps:  93%|▉| 13882/15000 [1:59:01<03:24,  5.48it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:50 - INFO - __main__ - train loss is 31.03255999344401\n",
      "Steps:  93%|▉| 13883/15000 [1:59:01<03:24,  5.45it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:51 - INFO - __main__ - train loss is 31.113796102581546\n",
      "Steps:  93%|▉| 13884/15000 [1:59:01<03:23,  5.49it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:51 - INFO - __main__ - train loss is 31.125993147259578\n",
      "Steps:  93%|▉| 13885/15000 [1:59:01<03:22,  5.51it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:51 - INFO - __main__ - train loss is 31.183922089403495\n",
      "Steps:  93%|▉| 13886/15000 [1:59:01<03:21,  5.52it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:51 - INFO - __main__ - train loss is 31.335797436302528\n",
      "Steps:  93%|▉| 13887/15000 [1:59:01<03:21,  5.54it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:51 - INFO - __main__ - train loss is 31.73347309953533\n",
      "Steps:  93%|▉| 13888/15000 [1:59:02<03:20,  5.54it/s, lr=0.000969, step_loss=0.307/27/2023 19:43:51 - INFO - __main__ - train loss is 31.758034899597988\n",
      "Steps:  93%|▉| 13889/15000 [1:59:02<03:20,  5.55it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:52 - INFO - __main__ - train loss is 31.773037176346406\n",
      "Steps:  93%|▉| 13890/15000 [1:59:02<03:19,  5.55it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:52 - INFO - __main__ - train loss is 31.7775278177578\n",
      "Steps:  93%|▉| 13891/15000 [1:59:02<03:19,  5.55it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:52 - INFO - __main__ - train loss is 31.9147930231411\n",
      "Steps:  93%|▉| 13892/15000 [1:59:02<03:19,  5.55it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:52 - INFO - __main__ - train loss is 31.956255038501695\n",
      "Steps:  93%|▉| 13893/15000 [1:59:03<03:19,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:52 - INFO - __main__ - train loss is 31.962690794607624\n",
      "Steps:  93%|▉| 13894/15000 [1:59:03<03:20,  5.51it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:53 - INFO - __main__ - train loss is 31.96554363775067\n",
      "Steps:  93%|▉| 13895/15000 [1:59:03<03:22,  5.46it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:53 - INFO - __main__ - train loss is 31.966621942119673\n",
      "Steps:  93%|▉| 13896/15000 [1:59:03<03:22,  5.45it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:53 - INFO - __main__ - train loss is 32.07071439106949\n",
      "Steps:  93%|▉| 13897/15000 [1:59:03<03:23,  5.43it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:53 - INFO - __main__ - train loss is 32.163859515683725\n",
      "Steps:  93%|▉| 13898/15000 [1:59:03<03:22,  5.43it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:53 - INFO - __main__ - train loss is 32.37322971154936\n",
      "Steps:  93%|▉| 13899/15000 [1:59:04<03:23,  5.41it/s, lr=0.000969, step_loss=0.207/27/2023 19:43:53 - INFO - __main__ - train loss is 32.75473788310774\n",
      "Steps:  93%|▉| 13900/15000 [1:59:04<03:22,  5.43it/s, lr=0.000969, step_loss=0.307/27/2023 19:43:54 - INFO - __main__ - train loss is 33.25562396575697\n",
      "Steps:  93%|▉| 13901/15000 [1:59:04<03:21,  5.45it/s, lr=0.000969, step_loss=0.507/27/2023 19:43:54 - INFO - __main__ - train loss is 33.52862515975721\n",
      "Steps:  93%|▉| 13902/15000 [1:59:04<03:21,  5.46it/s, lr=0.000969, step_loss=0.207/27/2023 19:43:54 - INFO - __main__ - train loss is 33.74865689803846\n",
      "Steps:  93%|▉| 13903/15000 [1:59:04<03:20,  5.47it/s, lr=0.000969, step_loss=0.207/27/2023 19:43:54 - INFO - __main__ - train loss is 33.753202106105164\n",
      "Steps:  93%|▉| 13904/15000 [1:59:05<03:20,  5.48it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:54 - INFO - __main__ - train loss is 33.7626161465887\n",
      "Steps:  93%|▉| 13905/15000 [1:59:05<03:19,  5.48it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:55 - INFO - __main__ - train loss is 33.81131996237673\n",
      "Steps:  93%|▉| 13906/15000 [1:59:05<03:19,  5.48it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:55 - INFO - __main__ - train loss is 33.935773857170716\n",
      "Steps:  93%|▉| 13907/15000 [1:59:05<03:19,  5.48it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:55 - INFO - __main__ - train loss is 34.3375761883799\n",
      "Steps:  93%|▉| 13908/15000 [1:59:05<03:19,  5.49it/s, lr=0.000969, step_loss=0.407/27/2023 19:43:55 - INFO - __main__ - train loss is 34.408826261991635\n",
      "Steps:  93%|▉| 13909/15000 [1:59:05<03:18,  5.49it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:55 - INFO - __main__ - train loss is 34.45892593287863\n",
      "Steps:  93%|▉| 13910/15000 [1:59:06<03:18,  5.49it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:55 - INFO - __main__ - train loss is 34.549696639413014\n",
      "Steps:  93%|▉| 13911/15000 [1:59:06<03:18,  5.49it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:56 - INFO - __main__ - train loss is 34.70087742828764\n",
      "Steps:  93%|▉| 13912/15000 [1:59:06<03:18,  5.49it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:56 - INFO - __main__ - train loss is 35.121187925571576\n",
      "Steps:  93%|▉| 13913/15000 [1:59:06<03:19,  5.44it/s, lr=0.000969, step_loss=0.407/27/2023 19:43:56 - INFO - __main__ - train loss is 35.27879121922888\n",
      "Steps:  93%|▉| 13914/15000 [1:59:06<03:19,  5.45it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:56 - INFO - __main__ - train loss is 35.30186151736416\n",
      "Steps:  93%|▉| 13915/15000 [1:59:07<03:17,  5.49it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:56 - INFO - __main__ - train loss is 35.30430564028211\n",
      "Steps:  93%|▉| 13916/15000 [1:59:07<03:18,  5.46it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:57 - INFO - __main__ - train loss is 35.31126584508456\n",
      "Steps:  93%|▉| 13917/15000 [1:59:07<03:18,  5.45it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:57 - INFO - __main__ - train loss is 35.367997985566035\n",
      "Steps:  93%|▉| 13918/15000 [1:59:07<03:17,  5.48it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:57 - INFO - __main__ - train loss is 35.41662983992137\n",
      "Steps:  93%|▉| 13919/15000 [1:59:07<03:16,  5.51it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:57 - INFO - __main__ - train loss is 35.530396681511775\n",
      "Steps:  93%|▉| 13920/15000 [1:59:07<03:15,  5.52it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:57 - INFO - __main__ - train loss is 35.550310377264395\n",
      "Steps:  93%|▉| 13921/15000 [1:59:08<03:14,  5.54it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:57 - INFO - __main__ - train loss is 35.65091617801227\n",
      "Steps:  93%|▉| 13922/15000 [1:59:08<03:14,  5.55it/s, lr=0.000969, step_loss=0.107/27/2023 19:43:58 - INFO - __main__ - train loss is 35.6555104192812\n",
      "Steps:  93%|▉| 13923/15000 [1:59:08<03:13,  5.56it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:58 - INFO - __main__ - train loss is 35.889792123110965\n",
      "Steps:  93%|▉| 13924/15000 [1:59:08<03:13,  5.56it/s, lr=0.000969, step_loss=0.207/27/2023 19:43:58 - INFO - __main__ - train loss is 35.89854235132225\n",
      "Steps:  93%|▉| 13925/15000 [1:59:08<03:13,  5.57it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:58 - INFO - __main__ - train loss is 35.90089301695116\n",
      "Steps:  93%|▉| 13926/15000 [1:59:09<03:12,  5.57it/s, lr=0.000969, step_loss=0.007/27/2023 19:43:58 - INFO - __main__ - train loss is 35.915416048141196\n",
      "Steps:  93%|▉| 13927/15000 [1:59:09<03:12,  5.58it/s, lr=0.000968, step_loss=0.007/27/2023 19:43:59 - INFO - __main__ - train loss is 36.321200327249244\n",
      "Steps:  93%|▉| 13928/15000 [1:59:09<03:12,  5.58it/s, lr=0.000968, step_loss=0.407/27/2023 19:43:59 - INFO - __main__ - train loss is 36.59277387079783\n",
      "Steps:  93%|▉| 13929/15000 [1:59:09<03:11,  5.58it/s, lr=0.000968, step_loss=0.207/27/2023 19:43:59 - INFO - __main__ - train loss is 36.66409076866694\n",
      "Steps:  93%|▉| 13930/15000 [1:59:09<03:11,  5.58it/s, lr=0.000968, step_loss=0.007/27/2023 19:43:59 - INFO - __main__ - train loss is 36.70235895854421\n",
      "Steps:  93%|▉| 13931/15000 [1:59:09<03:13,  5.53it/s, lr=0.000968, step_loss=0.007/27/2023 19:43:59 - INFO - __main__ - train loss is 37.0035030816216\n",
      "Steps:  93%|▉| 13932/15000 [1:59:10<03:13,  5.53it/s, lr=0.000968, step_loss=0.307/27/2023 19:43:59 - INFO - __main__ - train loss is 37.07311486941762\n",
      "Steps:  93%|▉| 13933/15000 [1:59:10<03:14,  5.49it/s, lr=0.000968, step_loss=0.007/27/2023 19:44:00 - INFO - __main__ - train loss is 37.09981943038292\n",
      "Steps:  93%|▉| 13934/15000 [1:59:10<03:14,  5.48it/s, lr=0.000968, step_loss=0.007/27/2023 19:44:00 - INFO - __main__ - train loss is 37.13421580311842\n",
      "Steps:  93%|▉| 13935/15000 [1:59:10<03:13,  5.51it/s, lr=0.000968, step_loss=0.007/27/2023 19:44:00 - INFO - __main__ - train loss is 37.21640415606089\n",
      "Steps:  93%|▉| 13936/15000 [1:59:10<03:12,  5.51it/s, lr=0.000968, step_loss=0.007/27/2023 19:44:00 - INFO - __main__ - train loss is 37.5155259531457\n",
      "Steps:  93%|▉| 13937/15000 [1:59:11<03:12,  5.53it/s, lr=0.000968, step_loss=0.207/27/2023 19:44:01 - INFO - __main__ - train loss is 37.55858384189196\n",
      "Steps:  93%|▉| 13938/15000 [1:59:11<04:28,  3.95it/s, lr=0.000968, step_loss=0.007/27/2023 19:44:02 - INFO - __main__ - Per validation step average loss is 0.10940137505531311\n",
      "07/27/2023 19:44:02 - INFO - __main__ - Cumulative validation average loss is 0.10940137505531311\n",
      "07/27/2023 19:44:02 - INFO - __main__ - Per validation step average loss is 0.2775712013244629\n",
      "07/27/2023 19:44:02 - INFO - __main__ - Cumulative validation average loss is 0.386972576379776\n",
      "07/27/2023 19:44:02 - INFO - __main__ - Per validation step average loss is 0.4492192268371582\n",
      "07/27/2023 19:44:02 - INFO - __main__ - Cumulative validation average loss is 0.8361918032169342\n",
      "07/27/2023 19:44:03 - INFO - __main__ - Per validation step average loss is 0.48461154103279114\n",
      "07/27/2023 19:44:03 - INFO - __main__ - Cumulative validation average loss is 1.3208033442497253\n",
      "07/27/2023 19:44:03 - INFO - __main__ - Per validation step average loss is 0.023484496399760246\n",
      "07/27/2023 19:44:03 - INFO - __main__ - Cumulative validation average loss is 1.3442878406494856\n",
      "07/27/2023 19:44:04 - INFO - __main__ - Per validation step average loss is 0.03709612786769867\n",
      "07/27/2023 19:44:04 - INFO - __main__ - Cumulative validation average loss is 1.3813839685171843\n",
      "07/27/2023 19:44:04 - INFO - __main__ - Per validation step average loss is 0.15093901753425598\n",
      "07/27/2023 19:44:04 - INFO - __main__ - Cumulative validation average loss is 1.5323229860514402\n",
      "07/27/2023 19:44:05 - INFO - __main__ - Per validation step average loss is 0.006808186881244183\n",
      "07/27/2023 19:44:05 - INFO - __main__ - Cumulative validation average loss is 1.5391311729326844\n",
      "07/27/2023 19:44:05 - INFO - __main__ - Per validation step average loss is 0.0038044722750782967\n",
      "07/27/2023 19:44:05 - INFO - __main__ - Cumulative validation average loss is 1.5429356452077627\n",
      "07/27/2023 19:44:05 - INFO - __main__ - Per validation step average loss is 0.08115869015455246\n",
      "07/27/2023 19:44:05 - INFO - __main__ - Cumulative validation average loss is 1.6240943353623152\n",
      "07/27/2023 19:44:06 - INFO - __main__ - Per validation step average loss is 0.11299455165863037\n",
      "07/27/2023 19:44:06 - INFO - __main__ - Cumulative validation average loss is 1.7370888870209455\n",
      "07/27/2023 19:44:06 - INFO - __main__ - Per validation step average loss is 0.0648270919919014\n",
      "07/27/2023 19:44:06 - INFO - __main__ - Cumulative validation average loss is 1.801915979012847\n",
      "07/27/2023 19:44:07 - INFO - __main__ - Per validation step average loss is 0.004561739973723888\n",
      "07/27/2023 19:44:07 - INFO - __main__ - Cumulative validation average loss is 1.8064777189865708\n",
      "07/27/2023 19:44:07 - INFO - __main__ - Per validation step average loss is 0.05140852928161621\n",
      "07/27/2023 19:44:07 - INFO - __main__ - Cumulative validation average loss is 1.857886248268187\n",
      "07/27/2023 19:44:07 - INFO - __main__ - Per validation step average loss is 0.02340187318623066\n",
      "07/27/2023 19:44:07 - INFO - __main__ - Cumulative validation average loss is 1.8812881214544177\n",
      "07/27/2023 19:44:08 - INFO - __main__ - Per validation step average loss is 0.07698613405227661\n",
      "07/27/2023 19:44:08 - INFO - __main__ - Cumulative validation average loss is 1.9582742555066943\n",
      "07/27/2023 19:44:08 - INFO - __main__ - Per validation step average loss is 0.0029335692524909973\n",
      "07/27/2023 19:44:08 - INFO - __main__ - Cumulative validation average loss is 1.9612078247591853\n",
      "07/27/2023 19:44:09 - INFO - __main__ - Per validation step average loss is 0.13835738599300385\n",
      "07/27/2023 19:44:09 - INFO - __main__ - Cumulative validation average loss is 2.099565210752189\n",
      "07/27/2023 19:44:09 - INFO - __main__ - Per validation step average loss is 0.08843928575515747\n",
      "07/27/2023 19:44:09 - INFO - __main__ - Cumulative validation average loss is 2.1880044965073466\n",
      "07/27/2023 19:44:10 - INFO - __main__ - Per validation step average loss is 0.09032230824232101\n",
      "07/27/2023 19:44:10 - INFO - __main__ - Cumulative validation average loss is 2.2783268047496676\n",
      "07/27/2023 19:44:10 - INFO - __main__ - Per validation step average loss is 0.30890703201293945\n",
      "07/27/2023 19:44:10 - INFO - __main__ - Cumulative validation average loss is 2.587233836762607\n",
      "07/27/2023 19:44:10 - INFO - __main__ - Per validation step average loss is 0.33166322112083435\n",
      "07/27/2023 19:44:10 - INFO - __main__ - Cumulative validation average loss is 2.9188970578834414\n",
      "07/27/2023 19:44:11 - INFO - __main__ - Per validation step average loss is 0.13553577661514282\n",
      "07/27/2023 19:44:11 - INFO - __main__ - Cumulative validation average loss is 3.0544328344985843\n",
      "07/27/2023 19:44:11 - INFO - __main__ - Per validation step average loss is 0.04784993454813957\n",
      "07/27/2023 19:44:11 - INFO - __main__ - Cumulative validation average loss is 3.102282769046724\n",
      "07/27/2023 19:44:12 - INFO - __main__ - Per validation step average loss is 0.29307541251182556\n",
      "07/27/2023 19:44:12 - INFO - __main__ - Cumulative validation average loss is 3.3953581815585494\n",
      "07/27/2023 19:44:12 - INFO - __main__ - Per validation step average loss is 0.0034865112975239754\n",
      "07/27/2023 19:44:12 - INFO - __main__ - Cumulative validation average loss is 3.3988446928560734\n",
      "07/27/2023 19:44:12 - INFO - __main__ - Per validation step average loss is 0.0017677603755146265\n",
      "07/27/2023 19:44:12 - INFO - __main__ - Cumulative validation average loss is 3.400612453231588\n",
      "07/27/2023 19:44:13 - INFO - __main__ - Per validation step average loss is 0.00855191983282566\n",
      "07/27/2023 19:44:13 - INFO - __main__ - Cumulative validation average loss is 3.4091643730644137\n",
      "07/27/2023 19:44:13 - INFO - __main__ - Per validation step average loss is 0.44499221444129944\n",
      "07/27/2023 19:44:13 - INFO - __main__ - Cumulative validation average loss is 3.854156587505713\n",
      "07/27/2023 19:44:14 - INFO - __main__ - Per validation step average loss is 0.0026828304398804903\n",
      "07/27/2023 19:44:14 - INFO - __main__ - Cumulative validation average loss is 3.8568394179455936\n",
      "07/27/2023 19:44:14 - INFO - __main__ - Per validation step average loss is 0.002116005402058363\n",
      "07/27/2023 19:44:14 - INFO - __main__ - Cumulative validation average loss is 3.858955423347652\n",
      "07/27/2023 19:44:15 - INFO - __main__ - Per validation step average loss is 0.1380341798067093\n",
      "07/27/2023 19:44:15 - INFO - __main__ - Cumulative validation average loss is 3.9969896031543612\n",
      "07/27/2023 19:44:15 - INFO - __main__ - Per validation step average loss is 0.034929074347019196\n",
      "07/27/2023 19:44:15 - INFO - __main__ - Cumulative validation average loss is 4.03191867750138\n",
      "07/27/2023 19:44:15 - INFO - __main__ - Per validation step average loss is 0.3911910653114319\n",
      "07/27/2023 19:44:15 - INFO - __main__ - Cumulative validation average loss is 4.423109742812812\n",
      "07/27/2023 19:44:16 - INFO - __main__ - Per validation step average loss is 0.09447872638702393\n",
      "07/27/2023 19:44:16 - INFO - __main__ - Cumulative validation average loss is 4.517588469199836\n",
      "07/27/2023 19:44:16 - INFO - __main__ - Per validation step average loss is 0.012546185404062271\n",
      "07/27/2023 19:44:16 - INFO - __main__ - Cumulative validation average loss is 4.5301346546038985\n",
      "07/27/2023 19:44:17 - INFO - __main__ - Per validation step average loss is 0.07807254791259766\n",
      "07/27/2023 19:44:17 - INFO - __main__ - Cumulative validation average loss is 4.608207202516496\n",
      "07/27/2023 19:44:17 - INFO - __main__ - Per validation step average loss is 0.10235925018787384\n",
      "07/27/2023 19:44:17 - INFO - __main__ - Cumulative validation average loss is 4.71056645270437\n",
      "07/27/2023 19:44:17 - INFO - __main__ - Per validation step average loss is 0.6100988388061523\n",
      "07/27/2023 19:44:17 - INFO - __main__ - Cumulative validation average loss is 5.320665291510522\n",
      "07/27/2023 19:44:18 - INFO - __main__ - Per validation step average loss is 0.31832414865493774\n",
      "07/27/2023 19:44:18 - INFO - __main__ - Cumulative validation average loss is 5.63898944016546\n",
      "07/27/2023 19:44:18 - INFO - __main__ - Per validation step average loss is 0.19060277938842773\n",
      "07/27/2023 19:44:18 - INFO - __main__ - Cumulative validation average loss is 5.829592219553888\n",
      "07/27/2023 19:44:19 - INFO - __main__ - Per validation step average loss is 0.07773779332637787\n",
      "07/27/2023 19:44:19 - INFO - __main__ - Cumulative validation average loss is 5.907330012880266\n",
      "07/27/2023 19:44:19 - INFO - __main__ - Per validation step average loss is 0.255265474319458\n",
      "07/27/2023 19:44:19 - INFO - __main__ - Cumulative validation average loss is 6.162595487199724\n",
      "07/27/2023 19:44:19 - INFO - __main__ - Per validation step average loss is 0.08554921299219131\n",
      "07/27/2023 19:44:19 - INFO - __main__ - Cumulative validation average loss is 6.248144700191915\n",
      "07/27/2023 19:44:20 - INFO - __main__ - Per validation step average loss is 0.0013657270465046167\n",
      "07/27/2023 19:44:20 - INFO - __main__ - Cumulative validation average loss is 6.24951042723842\n",
      "07/27/2023 19:44:20 - INFO - __main__ - Per validation step average loss is 0.17765836417675018\n",
      "07/27/2023 19:44:20 - INFO - __main__ - Cumulative validation average loss is 6.42716879141517\n",
      "07/27/2023 19:44:21 - INFO - __main__ - Per validation step average loss is 0.00181218096986413\n",
      "07/27/2023 19:44:21 - INFO - __main__ - Cumulative validation average loss is 6.428980972385034\n",
      "07/27/2023 19:44:21 - INFO - __main__ - Per validation step average loss is 0.009766824543476105\n",
      "07/27/2023 19:44:21 - INFO - __main__ - Cumulative validation average loss is 6.43874779692851\n",
      "07/27/2023 19:44:22 - INFO - __main__ - Per validation step average loss is 0.11678269505500793\n",
      "07/27/2023 19:44:22 - INFO - __main__ - Cumulative validation average loss is 6.555530491983518\n",
      "07/27/2023 19:44:22 - INFO - __main__ - Per validation step average loss is 0.028371192514896393\n",
      "07/27/2023 19:44:22 - INFO - __main__ - Cumulative validation average loss is 6.583901684498414\n",
      "07/27/2023 19:44:22 - INFO - __main__ - Per validation step average loss is 0.14112865924835205\n",
      "07/27/2023 19:44:22 - INFO - __main__ - Cumulative validation average loss is 6.7250303437467664\n",
      "07/27/2023 19:44:23 - INFO - __main__ - Per validation step average loss is 0.003332188120111823\n",
      "07/27/2023 19:44:23 - INFO - __main__ - Cumulative validation average loss is 6.728362531866878\n",
      "07/27/2023 19:44:23 - INFO - __main__ - Per validation step average loss is 0.02378934808075428\n",
      "07/27/2023 19:44:23 - INFO - __main__ - Cumulative validation average loss is 6.7521518799476326\n",
      "07/27/2023 19:44:24 - INFO - __main__ - Per validation step average loss is 0.16693685948848724\n",
      "07/27/2023 19:44:24 - INFO - __main__ - Cumulative validation average loss is 6.91908873943612\n",
      "07/27/2023 19:44:24 - INFO - __main__ - Per validation step average loss is 0.2623246908187866\n",
      "07/27/2023 19:44:24 - INFO - __main__ - Cumulative validation average loss is 7.181413430254906\n",
      "07/27/2023 19:44:24 - INFO - __main__ - Per validation step average loss is 0.36683714389801025\n",
      "07/27/2023 19:44:24 - INFO - __main__ - Cumulative validation average loss is 7.548250574152917\n",
      "07/27/2023 19:44:25 - INFO - __main__ - Per validation step average loss is 0.30404961109161377\n",
      "07/27/2023 19:44:25 - INFO - __main__ - Cumulative validation average loss is 7.85230018524453\n",
      "07/27/2023 19:44:25 - INFO - __main__ - Per validation step average loss is 0.013100425712764263\n",
      "07/27/2023 19:44:25 - INFO - __main__ - Cumulative validation average loss is 7.865400610957295\n",
      "07/27/2023 19:44:26 - INFO - __main__ - Per validation step average loss is 0.012371126562356949\n",
      "07/27/2023 19:44:26 - INFO - __main__ - Cumulative validation average loss is 7.877771737519652\n",
      "07/27/2023 19:44:26 - INFO - __main__ - Per validation step average loss is 0.12284010648727417\n",
      "07/27/2023 19:44:26 - INFO - __main__ - Cumulative validation average loss is 8.000611844006926\n",
      "07/27/2023 19:44:27 - INFO - __main__ - Per validation step average loss is 0.05007003992795944\n",
      "07/27/2023 19:44:27 - INFO - __main__ - Cumulative validation average loss is 8.050681883934885\n",
      "07/27/2023 19:44:27 - INFO - __main__ - Per validation step average loss is 0.010859362781047821\n",
      "07/27/2023 19:44:27 - INFO - __main__ - Cumulative validation average loss is 8.061541246715933\n",
      "07/27/2023 19:44:27 - INFO - __main__ - Per validation step average loss is 0.04215309023857117\n",
      "07/27/2023 19:44:27 - INFO - __main__ - Cumulative validation average loss is 8.103694336954504\n",
      "07/27/2023 19:44:28 - INFO - __main__ - Per validation step average loss is 0.004672684706747532\n",
      "07/27/2023 19:44:28 - INFO - __main__ - Cumulative validation average loss is 8.108367021661252\n",
      "07/27/2023 19:44:28 - INFO - __main__ - Per validation step average loss is 0.09791533648967743\n",
      "07/27/2023 19:44:28 - INFO - __main__ - Cumulative validation average loss is 8.20628235815093\n",
      "07/27/2023 19:44:29 - INFO - __main__ - Per validation step average loss is 0.7028378248214722\n",
      "07/27/2023 19:44:29 - INFO - __main__ - Cumulative validation average loss is 8.909120182972401\n",
      "07/27/2023 19:44:29 - INFO - __main__ - Per validation step average loss is 0.02860439009964466\n",
      "07/27/2023 19:44:29 - INFO - __main__ - Cumulative validation average loss is 8.937724573072046\n",
      "07/27/2023 19:44:29 - INFO - __main__ - Per validation step average loss is 0.016664955765008926\n",
      "07/27/2023 19:44:29 - INFO - __main__ - Cumulative validation average loss is 8.954389528837055\n",
      "07/27/2023 19:44:30 - INFO - __main__ - Per validation step average loss is 0.0775170624256134\n",
      "07/27/2023 19:44:30 - INFO - __main__ - Cumulative validation average loss is 9.031906591262668\n",
      "07/27/2023 19:44:30 - INFO - __main__ - Per validation step average loss is 0.08951876312494278\n",
      "07/27/2023 19:44:30 - INFO - __main__ - Cumulative validation average loss is 9.121425354387611\n",
      "07/27/2023 19:44:31 - INFO - __main__ - Per validation step average loss is 0.22429558634757996\n",
      "07/27/2023 19:44:31 - INFO - __main__ - Cumulative validation average loss is 9.345720940735191\n",
      "07/27/2023 19:44:31 - INFO - __main__ - Per validation step average loss is 0.007616443559527397\n",
      "07/27/2023 19:44:31 - INFO - __main__ - Cumulative validation average loss is 9.353337384294719\n",
      "07/27/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.23971134424209595\n",
      "07/27/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 9.593048728536814\n",
      "07/27/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.11779648065567017\n",
      "07/27/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 9.710845209192485\n",
      "07/27/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.013018468394875526\n",
      "07/27/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 9.72386367758736\n",
      "07/27/2023 19:44:33 - INFO - __main__ - Per validation step average loss is 0.1544886976480484\n",
      "07/27/2023 19:44:33 - INFO - __main__ - Cumulative validation average loss is 9.878352375235409\n",
      "07/27/2023 19:44:33 - INFO - __main__ - Per validation step average loss is 0.5682071447372437\n",
      "07/27/2023 19:44:33 - INFO - __main__ - Cumulative validation average loss is 10.446559519972652\n",
      "07/27/2023 19:44:34 - INFO - __main__ - Per validation step average loss is 0.1502029001712799\n",
      "07/27/2023 19:44:34 - INFO - __main__ - Cumulative validation average loss is 10.596762420143932\n",
      "07/27/2023 19:44:34 - INFO - __main__ - Per validation step average loss is 0.060861892998218536\n",
      "07/27/2023 19:44:34 - INFO - __main__ - Cumulative validation average loss is 10.65762431314215\n",
      "07/27/2023 19:44:34 - INFO - __main__ - Average validation loss for Epoch 45 is 0.1349066368752171\n",
      "07/27/2023 19:44:34 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:45:32 - INFO - __main__ - Starting epoch 46\n",
      "07/27/2023 19:45:32 - INFO - __main__ - train loss is 0.003077150322496891\n",
      "Steps:  93%|▉| 13939/15000 [2:00:43<8:09:25, 27.68s/it, lr=0.000968, step_loss=007/27/2023 19:45:32 - INFO - __main__ - train loss is 0.24185614380985498\n",
      "Steps:  93%|▉| 13940/15000 [2:00:43<5:43:14, 19.43s/it, lr=0.000968, step_loss=007/27/2023 19:45:33 - INFO - __main__ - train loss is 0.285332933999598\n",
      "Steps:  93%|▉| 13941/15000 [2:00:43<4:00:59, 13.65s/it, lr=0.000968, step_loss=007/27/2023 19:45:33 - INFO - __main__ - train loss is 0.2886499338783324\n",
      "Steps:  93%|▉| 13942/15000 [2:00:43<2:49:28,  9.61s/it, lr=0.000968, step_loss=007/27/2023 19:45:33 - INFO - __main__ - train loss is 0.323188001755625\n",
      "Steps:  93%|▉| 13943/15000 [2:00:43<1:59:27,  6.78s/it, lr=0.000968, step_loss=007/27/2023 19:45:33 - INFO - __main__ - train loss is 0.35436649108305573\n",
      "Steps:  93%|▉| 13944/15000 [2:00:43<1:24:29,  4.80s/it, lr=0.000968, step_loss=007/27/2023 19:45:33 - INFO - __main__ - train loss is 0.41732396418228745\n",
      "Steps:  93%|▉| 13945/15000 [2:00:44<1:00:04,  3.42s/it, lr=0.000968, step_loss=007/27/2023 19:45:34 - INFO - __main__ - train loss is 0.5681198411621153\n",
      "Steps:  93%|▉| 13946/15000 [2:00:44<42:56,  2.44s/it, lr=0.000968, step_loss=0.107/27/2023 19:45:34 - INFO - __main__ - train loss is 0.5704021407291293\n",
      "Steps:  93%|▉| 13947/15000 [2:00:44<30:58,  1.77s/it, lr=0.000968, step_loss=0.007/27/2023 19:45:34 - INFO - __main__ - train loss is 0.5798804117366672\n",
      "Steps:  93%|▉| 13948/15000 [2:00:44<22:36,  1.29s/it, lr=0.000968, step_loss=0.007/27/2023 19:45:34 - INFO - __main__ - train loss is 0.6488477243110538\n",
      "Steps:  93%|▉| 13949/15000 [2:00:44<16:46,  1.04it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:34 - INFO - __main__ - train loss is 0.6554054599255323\n",
      "Steps:  93%|▉| 13950/15000 [2:00:45<12:43,  1.38it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:34 - INFO - __main__ - train loss is 1.184458551928401\n",
      "Steps:  93%|▉| 13951/15000 [2:00:45<09:50,  1.78it/s, lr=0.000968, step_loss=0.507/27/2023 19:45:35 - INFO - __main__ - train loss is 1.2194682750850916\n",
      "Steps:  93%|▉| 13952/15000 [2:00:45<07:49,  2.23it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:35 - INFO - __main__ - train loss is 1.4415969792753458\n",
      "Steps:  93%|▉| 13953/15000 [2:00:45<06:26,  2.71it/s, lr=0.000968, step_loss=0.207/27/2023 19:45:35 - INFO - __main__ - train loss is 1.5892500225454569\n",
      "Steps:  93%|▉| 13954/15000 [2:00:45<05:26,  3.21it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:35 - INFO - __main__ - train loss is 1.72119296528399\n",
      "Steps:  93%|▉| 13955/15000 [2:00:45<04:44,  3.68it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:35 - INFO - __main__ - train loss is 1.7957810703665018\n",
      "Steps:  93%|▉| 13956/15000 [2:00:46<04:14,  4.10it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:36 - INFO - __main__ - train loss is 1.8448517266660929\n",
      "Steps:  93%|▉| 13957/15000 [2:00:46<03:54,  4.45it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:36 - INFO - __main__ - train loss is 2.7844428960233927\n",
      "Steps:  93%|▉| 13958/15000 [2:00:46<03:39,  4.74it/s, lr=0.000968, step_loss=0.907/27/2023 19:45:36 - INFO - __main__ - train loss is 2.9307813588529825\n",
      "Steps:  93%|▉| 13959/15000 [2:00:46<03:29,  4.96it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:36 - INFO - __main__ - train loss is 2.9338648128323257\n",
      "Steps:  93%|▉| 13960/15000 [2:00:46<03:23,  5.12it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:36 - INFO - __main__ - train loss is 3.175158854108304\n",
      "Steps:  93%|▉| 13961/15000 [2:00:47<03:17,  5.25it/s, lr=0.000968, step_loss=0.207/27/2023 19:45:36 - INFO - __main__ - train loss is 3.1920784707181156\n",
      "Steps:  93%|▉| 13962/15000 [2:00:47<03:14,  5.34it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:37 - INFO - __main__ - train loss is 3.2965151141397655\n",
      "Steps:  93%|▉| 13963/15000 [2:00:47<03:12,  5.39it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:37 - INFO - __main__ - train loss is 3.348603222053498\n",
      "Steps:  93%|▉| 13964/15000 [2:00:47<03:12,  5.39it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:37 - INFO - __main__ - train loss is 3.4139906051568687\n",
      "Steps:  93%|▉| 13965/15000 [2:00:47<03:10,  5.44it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:37 - INFO - __main__ - train loss is 3.670226115267724\n",
      "Steps:  93%|▉| 13966/15000 [2:00:47<03:08,  5.47it/s, lr=0.000968, step_loss=0.207/27/2023 19:45:37 - INFO - __main__ - train loss is 3.6727229247335345\n",
      "Steps:  93%|▉| 13967/15000 [2:00:48<03:08,  5.48it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:38 - INFO - __main__ - train loss is 3.7374304274562746\n",
      "Steps:  93%|▉| 13968/15000 [2:00:48<03:09,  5.46it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:38 - INFO - __main__ - train loss is 3.835070628905669\n",
      "Steps:  93%|▉| 13969/15000 [2:00:48<03:08,  5.47it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:38 - INFO - __main__ - train loss is 3.84336936683394\n",
      "Steps:  93%|▉| 13970/15000 [2:00:48<03:07,  5.49it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:38 - INFO - __main__ - train loss is 3.8509836888406426\n",
      "Steps:  93%|▉| 13971/15000 [2:00:48<03:06,  5.51it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:38 - INFO - __main__ - train loss is 4.190003732452169\n",
      "Steps:  93%|▉| 13972/15000 [2:00:49<03:05,  5.53it/s, lr=0.000968, step_loss=0.307/27/2023 19:45:38 - INFO - __main__ - train loss is 4.210446322569624\n",
      "Steps:  93%|▉| 13973/15000 [2:00:49<03:06,  5.51it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:39 - INFO - __main__ - train loss is 4.3913725859019905\n",
      "Steps:  93%|▉| 13974/15000 [2:00:49<03:05,  5.53it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:39 - INFO - __main__ - train loss is 4.39362910669297\n",
      "Steps:  93%|▉| 13975/15000 [2:00:49<03:04,  5.55it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:39 - INFO - __main__ - train loss is 4.507605041377246\n",
      "Steps:  93%|▉| 13976/15000 [2:00:49<03:04,  5.56it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:39 - INFO - __main__ - train loss is 4.543192642740905\n",
      "Steps:  93%|▉| 13977/15000 [2:00:49<03:06,  5.47it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:39 - INFO - __main__ - train loss is 4.553213185630739\n",
      "Steps:  93%|▉| 13978/15000 [2:00:50<03:07,  5.45it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:40 - INFO - __main__ - train loss is 4.56747277919203\n",
      "Steps:  93%|▉| 13979/15000 [2:00:50<03:07,  5.44it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:40 - INFO - __main__ - train loss is 4.570808998774737\n",
      "Steps:  93%|▉| 13980/15000 [2:00:50<03:06,  5.46it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:40 - INFO - __main__ - train loss is 4.591317651327699\n",
      "Steps:  93%|▉| 13981/15000 [2:00:50<03:05,  5.49it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:40 - INFO - __main__ - train loss is 4.593265417264774\n",
      "Steps:  93%|▉| 13982/15000 [2:00:50<03:04,  5.51it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:40 - INFO - __main__ - train loss is 4.836884069489315\n",
      "Steps:  93%|▉| 13983/15000 [2:00:51<03:03,  5.53it/s, lr=0.000968, step_loss=0.207/27/2023 19:45:40 - INFO - __main__ - train loss is 4.878396711545065\n",
      "Steps:  93%|▉| 13984/15000 [2:00:51<03:03,  5.54it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:41 - INFO - __main__ - train loss is 4.923444635467604\n",
      "Steps:  93%|▉| 13985/15000 [2:00:51<03:02,  5.55it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:41 - INFO - __main__ - train loss is 5.037717371480539\n",
      "Steps:  93%|▉| 13986/15000 [2:00:51<03:04,  5.50it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:41 - INFO - __main__ - train loss is 5.090391180710867\n",
      "Steps:  93%|▉| 13987/15000 [2:00:51<03:05,  5.45it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:41 - INFO - __main__ - train loss is 5.538683972554281\n",
      "Steps:  93%|▉| 13988/15000 [2:00:51<03:06,  5.43it/s, lr=0.000968, step_loss=0.407/27/2023 19:45:41 - INFO - __main__ - train loss is 5.79362954874523\n",
      "Steps:  93%|▉| 13989/15000 [2:00:52<03:06,  5.42it/s, lr=0.000968, step_loss=0.207/27/2023 19:45:42 - INFO - __main__ - train loss is 5.800843298668042\n",
      "Steps:  93%|▉| 13990/15000 [2:00:52<03:05,  5.45it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:42 - INFO - __main__ - train loss is 5.859691627556458\n",
      "Steps:  93%|▉| 13991/15000 [2:00:52<03:03,  5.49it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:42 - INFO - __main__ - train loss is 5.937012791866437\n",
      "Steps:  93%|▉| 13992/15000 [2:00:52<03:02,  5.51it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:42 - INFO - __main__ - train loss is 6.12976497435011\n",
      "Steps:  93%|▉| 13993/15000 [2:00:52<03:02,  5.53it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:42 - INFO - __main__ - train loss is 6.317022949689999\n",
      "Steps:  93%|▉| 13994/15000 [2:00:53<03:01,  5.54it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:42 - INFO - __main__ - train loss is 6.580409527057782\n",
      "Steps:  93%|▉| 13995/15000 [2:00:53<03:00,  5.56it/s, lr=0.000968, step_loss=0.207/27/2023 19:45:43 - INFO - __main__ - train loss is 6.598458150634542\n",
      "Steps:  93%|▉| 13996/15000 [2:00:53<03:00,  5.56it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:43 - INFO - __main__ - train loss is 6.897981623420492\n",
      "Steps:  93%|▉| 13997/15000 [2:00:53<03:00,  5.57it/s, lr=0.000968, step_loss=0.307/27/2023 19:45:43 - INFO - __main__ - train loss is 6.909522790694609\n",
      "Steps:  93%|▉| 13998/15000 [2:00:53<02:59,  5.57it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:43 - INFO - __main__ - train loss is 6.952494696015492\n",
      "Steps:  93%|▉| 13999/15000 [2:00:53<02:59,  5.57it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:43 - INFO - __main__ - train loss is 7.67046506726183\n",
      "Steps:  93%|▉| 14000/15000 [2:00:54<03:01,  5.52it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:43 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-14000\n",
      "07/27/2023 19:45:43 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:45:43,922] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:45:43,927] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:45:43,927] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:45:43,933] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:45:43,933] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-14000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:45:43,940] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-14000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:45:43,940] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-14000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:45:43,940] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:45:43 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-14000/pytorch_model\n",
      "07/27/2023 19:45:43 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-14000/scheduler.bin\n",
      "07/27/2023 19:45:43 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-14000/random_states_0.pkl\n",
      "07/27/2023 19:45:43 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-14000\n",
      "Steps:  93%|▉| 14000/15000 [2:00:54<03:01,  5.52it/s, lr=0.000968, step_loss=0.707/27/2023 19:45:44 - INFO - __main__ - train loss is 7.677831105655059\n",
      "Steps:  93%|▉| 14001/15000 [2:00:54<03:06,  5.37it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:44 - INFO - __main__ - train loss is 7.775546304648742\n",
      "Steps:  93%|▉| 14002/15000 [2:00:54<03:03,  5.43it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:44 - INFO - __main__ - train loss is 7.780706268502399\n",
      "Steps:  93%|▉| 14003/15000 [2:00:54<03:02,  5.47it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:44 - INFO - __main__ - train loss is 7.862624105764553\n",
      "Steps:  93%|▉| 14004/15000 [2:00:54<03:02,  5.45it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:44 - INFO - __main__ - train loss is 7.864475026377477\n",
      "Steps:  93%|▉| 14005/15000 [2:00:55<03:26,  4.81it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:45 - INFO - __main__ - train loss is 7.87269881053362\n",
      "Steps:  93%|▉| 14006/15000 [2:00:55<03:32,  4.69it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:45 - INFO - __main__ - train loss is 8.191365209058858\n",
      "Steps:  93%|▉| 14007/15000 [2:00:55<03:37,  4.57it/s, lr=0.000968, step_loss=0.307/27/2023 19:45:45 - INFO - __main__ - train loss is 8.26108072383795\n",
      "Steps:  93%|▉| 14008/15000 [2:00:55<03:46,  4.37it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:45 - INFO - __main__ - train loss is 8.540812027291395\n",
      "Steps:  93%|▉| 14009/15000 [2:00:56<03:33,  4.65it/s, lr=0.000968, step_loss=0.207/27/2023 19:45:45 - INFO - __main__ - train loss is 8.591308497474529\n",
      "Steps:  93%|▉| 14010/15000 [2:00:56<03:22,  4.88it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:46 - INFO - __main__ - train loss is 8.633910958305933\n",
      "Steps:  93%|▉| 14011/15000 [2:00:56<03:16,  5.03it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:46 - INFO - __main__ - train loss is 8.640627803863026\n",
      "Steps:  93%|▉| 14012/15000 [2:00:56<03:11,  5.16it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:46 - INFO - __main__ - train loss is 8.653526836656965\n",
      "Steps:  93%|▉| 14013/15000 [2:00:56<03:07,  5.25it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:46 - INFO - __main__ - train loss is 8.79893035592977\n",
      "Steps:  93%|▉| 14014/15000 [2:00:56<03:05,  5.33it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:46 - INFO - __main__ - train loss is 8.810402880073525\n",
      "Steps:  93%|▉| 14015/15000 [2:00:57<03:03,  5.38it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:47 - INFO - __main__ - train loss is 8.816649909713306\n",
      "Steps:  93%|▉| 14016/15000 [2:00:57<03:01,  5.41it/s, lr=0.000968, step_loss=0.007/27/2023 19:45:47 - INFO - __main__ - train loss is 9.27708458492998\n",
      "Steps:  93%|▉| 14017/15000 [2:00:57<03:00,  5.44it/s, lr=0.000968, step_loss=0.407/27/2023 19:45:47 - INFO - __main__ - train loss is 9.430366869666614\n",
      "Steps:  93%|▉| 14018/15000 [2:00:57<03:00,  5.45it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:47 - INFO - __main__ - train loss is 9.584911431767978\n",
      "Steps:  93%|▉| 14019/15000 [2:00:57<02:59,  5.47it/s, lr=0.000968, step_loss=0.107/27/2023 19:45:47 - INFO - __main__ - train loss is 10.442633654573001\n",
      "Steps:  93%|▉| 14020/15000 [2:00:58<02:58,  5.48it/s, lr=0.000968, step_loss=0.807/27/2023 19:45:47 - INFO - __main__ - train loss is 10.520996521809138\n",
      "Steps:  93%|▉| 14021/15000 [2:00:58<02:58,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:48 - INFO - __main__ - train loss is 10.589237246313132\n",
      "Steps:  93%|▉| 14022/15000 [2:00:58<02:58,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:48 - INFO - __main__ - train loss is 10.660307574667968\n",
      "Steps:  93%|▉| 14023/15000 [2:00:58<02:59,  5.44it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:48 - INFO - __main__ - train loss is 11.16623811761383\n",
      "Steps:  93%|▉| 14024/15000 [2:00:58<02:58,  5.46it/s, lr=0.000967, step_loss=0.507/27/2023 19:45:48 - INFO - __main__ - train loss is 11.192367991083302\n",
      "Steps:  94%|▉| 14025/15000 [2:00:58<02:57,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:48 - INFO - __main__ - train loss is 11.194720780360512\n",
      "Steps:  94%|▉| 14026/15000 [2:00:59<02:57,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:49 - INFO - __main__ - train loss is 11.367351060616784\n",
      "Steps:  94%|▉| 14027/15000 [2:00:59<02:56,  5.50it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:49 - INFO - __main__ - train loss is 11.677669053780846\n",
      "Steps:  94%|▉| 14028/15000 [2:00:59<02:56,  5.50it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:49 - INFO - __main__ - train loss is 12.067327445256524\n",
      "Steps:  94%|▉| 14029/15000 [2:00:59<02:56,  5.50it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:49 - INFO - __main__ - train loss is 12.578887408482842\n",
      "Steps:  94%|▉| 14030/15000 [2:00:59<02:56,  5.49it/s, lr=0.000967, step_loss=0.507/27/2023 19:45:49 - INFO - __main__ - train loss is 12.693670904147439\n",
      "Steps:  94%|▉| 14031/15000 [2:01:00<02:56,  5.49it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:49 - INFO - __main__ - train loss is 12.848492165911011\n",
      "Steps:  94%|▉| 14032/15000 [2:01:00<02:56,  5.49it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:50 - INFO - __main__ - train loss is 13.19585569750052\n",
      "Steps:  94%|▉| 14033/15000 [2:01:00<02:55,  5.50it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:50 - INFO - __main__ - train loss is 13.19925110496115\n",
      "Steps:  94%|▉| 14034/15000 [2:01:00<02:55,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:50 - INFO - __main__ - train loss is 13.216276732156985\n",
      "Steps:  94%|▉| 14035/15000 [2:01:00<02:55,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:50 - INFO - __main__ - train loss is 13.32997119135689\n",
      "Steps:  94%|▉| 14036/15000 [2:01:00<02:55,  5.50it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:50 - INFO - __main__ - train loss is 13.560417068074457\n",
      "Steps:  94%|▉| 14037/15000 [2:01:01<02:55,  5.50it/s, lr=0.000967, step_loss=0.207/27/2023 19:45:51 - INFO - __main__ - train loss is 13.809123349259607\n",
      "Steps:  94%|▉| 14038/15000 [2:01:01<02:55,  5.50it/s, lr=0.000967, step_loss=0.207/27/2023 19:45:51 - INFO - __main__ - train loss is 13.86851159192156\n",
      "Steps:  94%|▉| 14039/15000 [2:01:01<02:54,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:51 - INFO - __main__ - train loss is 13.872955730068497\n",
      "Steps:  94%|▉| 14040/15000 [2:01:01<02:54,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:51 - INFO - __main__ - train loss is 13.879330157185905\n",
      "Steps:  94%|▉| 14041/15000 [2:01:01<02:54,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:51 - INFO - __main__ - train loss is 14.209730326081626\n",
      "Steps:  94%|▉| 14042/15000 [2:01:02<02:54,  5.50it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:51 - INFO - __main__ - train loss is 14.21101500513032\n",
      "Steps:  94%|▉| 14043/15000 [2:01:02<02:55,  5.47it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:52 - INFO - __main__ - train loss is 14.229375435505062\n",
      "Steps:  94%|▉| 14044/15000 [2:01:02<02:54,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:52 - INFO - __main__ - train loss is 14.31667364994064\n",
      "Steps:  94%|▉| 14045/15000 [2:01:02<02:54,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:52 - INFO - __main__ - train loss is 14.323012469802052\n",
      "Steps:  94%|▉| 14046/15000 [2:01:02<02:53,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:52 - INFO - __main__ - train loss is 14.34675581427291\n",
      "Steps:  94%|▉| 14047/15000 [2:01:02<02:53,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:52 - INFO - __main__ - train loss is 14.35777082433924\n",
      "Steps:  94%|▉| 14048/15000 [2:01:03<02:53,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:53 - INFO - __main__ - train loss is 14.359314822941087\n",
      "Steps:  94%|▉| 14049/15000 [2:01:03<02:53,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:53 - INFO - __main__ - train loss is 14.672235721140169\n",
      "Steps:  94%|▉| 14050/15000 [2:01:03<02:52,  5.49it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:53 - INFO - __main__ - train loss is 15.006282591610216\n",
      "Steps:  94%|▉| 14051/15000 [2:01:03<02:52,  5.49it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:53 - INFO - __main__ - train loss is 15.06838110962417\n",
      "Steps:  94%|▉| 14052/15000 [2:01:03<02:52,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:53 - INFO - __main__ - train loss is 15.07881089427974\n",
      "Steps:  94%|▉| 14053/15000 [2:01:04<02:52,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:53 - INFO - __main__ - train loss is 15.08554933348205\n",
      "Steps:  94%|▉| 14054/15000 [2:01:04<02:52,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:54 - INFO - __main__ - train loss is 15.092941182549112\n",
      "Steps:  94%|▉| 14055/15000 [2:01:04<02:51,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:54 - INFO - __main__ - train loss is 15.20455874770414\n",
      "Steps:  94%|▉| 14056/15000 [2:01:04<02:51,  5.50it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:54 - INFO - __main__ - train loss is 15.205951832933351\n",
      "Steps:  94%|▉| 14057/15000 [2:01:04<02:51,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:54 - INFO - __main__ - train loss is 15.21211580443196\n",
      "Steps:  94%|▉| 14058/15000 [2:01:04<02:51,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:54 - INFO - __main__ - train loss is 15.283604877768084\n",
      "Steps:  94%|▉| 14059/15000 [2:01:05<02:51,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:55 - INFO - __main__ - train loss is 15.867856102762744\n",
      "Steps:  94%|▉| 14060/15000 [2:01:05<02:50,  5.50it/s, lr=0.000967, step_loss=0.507/27/2023 19:45:55 - INFO - __main__ - train loss is 15.900984207866713\n",
      "Steps:  94%|▉| 14061/15000 [2:01:05<02:50,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:55 - INFO - __main__ - train loss is 15.943338426528499\n",
      "Steps:  94%|▉| 14062/15000 [2:01:05<02:50,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:55 - INFO - __main__ - train loss is 16.00841091084294\n",
      "Steps:  94%|▉| 14063/15000 [2:01:05<02:50,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:55 - INFO - __main__ - train loss is 16.42516044783406\n",
      "Steps:  94%|▉| 14064/15000 [2:01:06<02:50,  5.50it/s, lr=0.000967, step_loss=0.407/27/2023 19:45:55 - INFO - __main__ - train loss is 16.43650049599819\n",
      "Steps:  94%|▉| 14065/15000 [2:01:06<02:50,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:56 - INFO - __main__ - train loss is 16.456362682161853\n",
      "Steps:  94%|▉| 14066/15000 [2:01:06<02:50,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:56 - INFO - __main__ - train loss is 16.64084509271197\n",
      "Steps:  94%|▉| 14067/15000 [2:01:06<02:50,  5.49it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:56 - INFO - __main__ - train loss is 16.645706127164885\n",
      "Steps:  94%|▉| 14068/15000 [2:01:06<02:49,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:56 - INFO - __main__ - train loss is 16.661074292613193\n",
      "Steps:  94%|▉| 14069/15000 [2:01:06<02:49,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:56 - INFO - __main__ - train loss is 16.71112880553119\n",
      "Steps:  94%|▉| 14070/15000 [2:01:07<02:49,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:57 - INFO - __main__ - train loss is 16.77978951181285\n",
      "Steps:  94%|▉| 14071/15000 [2:01:07<02:49,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:57 - INFO - __main__ - train loss is 16.78713468206115\n",
      "Steps:  94%|▉| 14072/15000 [2:01:07<02:49,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:57 - INFO - __main__ - train loss is 16.983756770612672\n",
      "Steps:  94%|▉| 14073/15000 [2:01:07<02:49,  5.48it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:57 - INFO - __main__ - train loss is 17.043817063095048\n",
      "Steps:  94%|▉| 14074/15000 [2:01:07<02:49,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:57 - INFO - __main__ - train loss is 17.690368076087907\n",
      "Steps:  94%|▉| 14075/15000 [2:01:08<02:48,  5.48it/s, lr=0.000967, step_loss=0.607/27/2023 19:45:57 - INFO - __main__ - train loss is 17.69187715672888\n",
      "Steps:  94%|▉| 14076/15000 [2:01:08<02:48,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:58 - INFO - __main__ - train loss is 17.816246554488316\n",
      "Steps:  94%|▉| 14077/15000 [2:01:08<02:48,  5.49it/s, lr=0.000967, step_loss=0.107/27/2023 19:45:58 - INFO - __main__ - train loss is 18.16107849800028\n",
      "Steps:  94%|▉| 14078/15000 [2:01:08<02:48,  5.49it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:58 - INFO - __main__ - train loss is 18.1628681384027\n",
      "Steps:  94%|▉| 14079/15000 [2:01:08<02:47,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:58 - INFO - __main__ - train loss is 18.22064385190606\n",
      "Steps:  94%|▉| 14080/15000 [2:01:08<02:47,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:58 - INFO - __main__ - train loss is 18.247153263539076\n",
      "Steps:  94%|▉| 14081/15000 [2:01:09<02:47,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:59 - INFO - __main__ - train loss is 18.629991572350264\n",
      "Steps:  94%|▉| 14082/15000 [2:01:09<02:46,  5.50it/s, lr=0.000967, step_loss=0.307/27/2023 19:45:59 - INFO - __main__ - train loss is 18.674658346921206\n",
      "Steps:  94%|▉| 14083/15000 [2:01:09<02:46,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:59 - INFO - __main__ - train loss is 18.717764750123024\n",
      "Steps:  94%|▉| 14084/15000 [2:01:09<02:46,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:59 - INFO - __main__ - train loss is 18.796031281352043\n",
      "Steps:  94%|▉| 14085/15000 [2:01:09<02:46,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:59 - INFO - __main__ - train loss is 18.79870347213\n",
      "Steps:  94%|▉| 14086/15000 [2:01:10<02:46,  5.50it/s, lr=0.000967, step_loss=0.007/27/2023 19:45:59 - INFO - __main__ - train loss is 18.825042466633022\n",
      "Steps:  94%|▉| 14087/15000 [2:01:10<02:46,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:00 - INFO - __main__ - train loss is 18.82778157782741\n",
      "Steps:  94%|▉| 14088/15000 [2:01:10<02:46,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:00 - INFO - __main__ - train loss is 18.846808432834223\n",
      "Steps:  94%|▉| 14089/15000 [2:01:10<02:46,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:00 - INFO - __main__ - train loss is 19.157908915774897\n",
      "Steps:  94%|▉| 14090/15000 [2:01:10<02:47,  5.44it/s, lr=0.000967, step_loss=0.307/27/2023 19:46:00 - INFO - __main__ - train loss is 19.163075399352238\n",
      "Steps:  94%|▉| 14091/15000 [2:01:10<02:46,  5.45it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:00 - INFO - __main__ - train loss is 19.71204371447675\n",
      "Steps:  94%|▉| 14092/15000 [2:01:11<02:46,  5.47it/s, lr=0.000967, step_loss=0.507/27/2023 19:46:01 - INFO - __main__ - train loss is 19.924626988125965\n",
      "Steps:  94%|▉| 14093/15000 [2:01:11<02:45,  5.47it/s, lr=0.000967, step_loss=0.207/27/2023 19:46:01 - INFO - __main__ - train loss is 19.93156572128646\n",
      "Steps:  94%|▉| 14094/15000 [2:01:11<02:45,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:01 - INFO - __main__ - train loss is 19.934203470591456\n",
      "Steps:  94%|▉| 14095/15000 [2:01:11<02:45,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:01 - INFO - __main__ - train loss is 20.36561023676768\n",
      "Steps:  94%|▉| 14096/15000 [2:01:11<02:44,  5.49it/s, lr=0.000967, step_loss=0.407/27/2023 19:46:01 - INFO - __main__ - train loss is 20.383834736887366\n",
      "Steps:  94%|▉| 14097/15000 [2:01:12<02:44,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:01 - INFO - __main__ - train loss is 20.398312679026276\n",
      "Steps:  94%|▉| 14098/15000 [2:01:12<02:44,  5.49it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:02 - INFO - __main__ - train loss is 20.39974948321469\n",
      "Steps:  94%|▉| 14099/15000 [2:01:12<02:45,  5.46it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:02 - INFO - __main__ - train loss is 20.413234485546127\n",
      "Steps:  94%|▉| 14100/15000 [2:01:12<02:45,  5.43it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:02 - INFO - __main__ - train loss is 20.695803178707138\n",
      "Steps:  94%|▉| 14101/15000 [2:01:12<02:44,  5.45it/s, lr=0.000967, step_loss=0.207/27/2023 19:46:02 - INFO - __main__ - train loss is 20.891664980212227\n",
      "Steps:  94%|▉| 14102/15000 [2:01:12<02:44,  5.47it/s, lr=0.000967, step_loss=0.107/27/2023 19:46:02 - INFO - __main__ - train loss is 20.8957468199078\n",
      "Steps:  94%|▉| 14103/15000 [2:01:13<02:43,  5.47it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:03 - INFO - __main__ - train loss is 21.393081836635247\n",
      "Steps:  94%|▉| 14104/15000 [2:01:13<02:43,  5.48it/s, lr=0.000967, step_loss=0.407/27/2023 19:46:03 - INFO - __main__ - train loss is 21.553369961911812\n",
      "Steps:  94%|▉| 14105/15000 [2:01:13<02:44,  5.45it/s, lr=0.000967, step_loss=0.107/27/2023 19:46:03 - INFO - __main__ - train loss is 21.696907170349732\n",
      "Steps:  94%|▉| 14106/15000 [2:01:13<02:44,  5.42it/s, lr=0.000967, step_loss=0.107/27/2023 19:46:03 - INFO - __main__ - train loss is 21.752149626845494\n",
      "Steps:  94%|▉| 14107/15000 [2:01:13<02:45,  5.39it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:03 - INFO - __main__ - train loss is 21.777773030335084\n",
      "Steps:  94%|▉| 14108/15000 [2:01:14<02:44,  5.42it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:03 - INFO - __main__ - train loss is 22.523072250420228\n",
      "Steps:  94%|▉| 14109/15000 [2:01:14<02:43,  5.44it/s, lr=0.000967, step_loss=0.707/27/2023 19:46:04 - INFO - __main__ - train loss is 22.566308461362496\n",
      "Steps:  94%|▉| 14110/15000 [2:01:14<02:43,  5.46it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:04 - INFO - __main__ - train loss is 22.68021496408619\n",
      "Steps:  94%|▉| 14111/15000 [2:01:14<02:42,  5.47it/s, lr=0.000967, step_loss=0.107/27/2023 19:46:04 - INFO - __main__ - train loss is 23.112775944406167\n",
      "Steps:  94%|▉| 14112/15000 [2:01:14<02:42,  5.48it/s, lr=0.000967, step_loss=0.407/27/2023 19:46:04 - INFO - __main__ - train loss is 23.11788737331517\n",
      "Steps:  94%|▉| 14113/15000 [2:01:15<02:41,  5.48it/s, lr=0.000967, step_loss=0.007/27/2023 19:46:04 - INFO - __main__ - train loss is 23.13080350146629\n",
      "Steps:  94%|▉| 14114/15000 [2:01:15<02:42,  5.45it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:05 - INFO - __main__ - train loss is 23.3625632582698\n",
      "Steps:  94%|▉| 14115/15000 [2:01:15<02:41,  5.49it/s, lr=0.000966, step_loss=0.207/27/2023 19:46:05 - INFO - __main__ - train loss is 23.368367629358545\n",
      "Steps:  94%|▉| 14116/15000 [2:01:15<02:40,  5.51it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:05 - INFO - __main__ - train loss is 24.124618308851495\n",
      "Steps:  94%|▉| 14117/15000 [2:01:15<02:39,  5.53it/s, lr=0.000966, step_loss=0.707/27/2023 19:46:05 - INFO - __main__ - train loss is 24.583504932234064\n",
      "Steps:  94%|▉| 14118/15000 [2:01:15<02:39,  5.54it/s, lr=0.000966, step_loss=0.407/27/2023 19:46:05 - INFO - __main__ - train loss is 24.658080460736528\n",
      "Steps:  94%|▉| 14119/15000 [2:01:16<02:38,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:05 - INFO - __main__ - train loss is 24.69477956951596\n",
      "Steps:  94%|▉| 14120/15000 [2:01:16<02:38,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:06 - INFO - __main__ - train loss is 24.70083574927412\n",
      "Steps:  94%|▉| 14121/15000 [2:01:16<02:37,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:06 - INFO - __main__ - train loss is 24.70315231126733\n",
      "Steps:  94%|▉| 14122/15000 [2:01:16<02:37,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:06 - INFO - __main__ - train loss is 25.620059144916013\n",
      "Steps:  94%|▉| 14123/15000 [2:01:16<02:37,  5.55it/s, lr=0.000966, step_loss=0.907/27/2023 19:46:06 - INFO - __main__ - train loss is 26.058567715110257\n",
      "Steps:  94%|▉| 14124/15000 [2:01:16<02:39,  5.51it/s, lr=0.000966, step_loss=0.407/27/2023 19:46:06 - INFO - __main__ - train loss is 26.10937360790558\n",
      "Steps:  94%|▉| 14125/15000 [2:01:17<02:39,  5.50it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:07 - INFO - __main__ - train loss is 26.116596470354125\n",
      "Steps:  94%|▉| 14126/15000 [2:01:17<02:38,  5.52it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:07 - INFO - __main__ - train loss is 26.137035174993798\n",
      "Steps:  94%|▉| 14127/15000 [2:01:17<02:37,  5.53it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:07 - INFO - __main__ - train loss is 26.23126436653547\n",
      "Steps:  94%|▉| 14128/15000 [2:01:17<02:37,  5.54it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:07 - INFO - __main__ - train loss is 26.258964699460194\n",
      "Steps:  94%|▉| 14129/15000 [2:01:17<02:36,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:07 - INFO - __main__ - train loss is 26.438632500125095\n",
      "Steps:  94%|▉| 14130/15000 [2:01:18<02:37,  5.54it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:07 - INFO - __main__ - train loss is 26.466070600552484\n",
      "Steps:  94%|▉| 14131/15000 [2:01:18<02:36,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:08 - INFO - __main__ - train loss is 26.467594752437435\n",
      "Steps:  94%|▉| 14132/15000 [2:01:18<02:36,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:08 - INFO - __main__ - train loss is 26.531286465353332\n",
      "Steps:  94%|▉| 14133/15000 [2:01:18<02:36,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:08 - INFO - __main__ - train loss is 26.54720608552452\n",
      "Steps:  94%|▉| 14134/15000 [2:01:18<02:35,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:08 - INFO - __main__ - train loss is 26.551423007040285\n",
      "Steps:  94%|▉| 14135/15000 [2:01:18<02:35,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:08 - INFO - __main__ - train loss is 26.557569276425056\n",
      "Steps:  94%|▉| 14136/15000 [2:01:19<02:35,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:09 - INFO - __main__ - train loss is 26.559899035957642\n",
      "Steps:  94%|▉| 14137/15000 [2:01:19<02:35,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:09 - INFO - __main__ - train loss is 26.722927559283562\n",
      "Steps:  94%|▉| 14138/15000 [2:01:19<02:34,  5.57it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:09 - INFO - __main__ - train loss is 26.727404645760544\n",
      "Steps:  94%|▉| 14139/15000 [2:01:19<02:34,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:09 - INFO - __main__ - train loss is 26.956289596040733\n",
      "Steps:  94%|▉| 14140/15000 [2:01:19<02:34,  5.57it/s, lr=0.000966, step_loss=0.207/27/2023 19:46:09 - INFO - __main__ - train loss is 26.973260170896538\n",
      "Steps:  94%|▉| 14141/15000 [2:01:20<02:34,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:09 - INFO - __main__ - train loss is 26.977702015195973\n",
      "Steps:  94%|▉| 14142/15000 [2:01:20<02:33,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:10 - INFO - __main__ - train loss is 27.009955660556443\n",
      "Steps:  94%|▉| 14143/15000 [2:01:20<02:33,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:10 - INFO - __main__ - train loss is 27.14051331684459\n",
      "Steps:  94%|▉| 14144/15000 [2:01:20<02:33,  5.58it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:10 - INFO - __main__ - train loss is 27.289249659632333\n",
      "Steps:  94%|▉| 14145/15000 [2:01:20<02:33,  5.57it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:10 - INFO - __main__ - train loss is 27.30883440852631\n",
      "Steps:  94%|▉| 14146/15000 [2:01:20<02:33,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:10 - INFO - __main__ - train loss is 27.317826974322088\n",
      "Steps:  94%|▉| 14147/15000 [2:01:21<02:33,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:10 - INFO - __main__ - train loss is 27.32128658948932\n",
      "Steps:  94%|▉| 14148/15000 [2:01:21<02:32,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:11 - INFO - __main__ - train loss is 27.326785724260844\n",
      "Steps:  94%|▉| 14149/15000 [2:01:21<02:32,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:11 - INFO - __main__ - train loss is 27.33652913349215\n",
      "Steps:  94%|▉| 14150/15000 [2:01:21<02:32,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:11 - INFO - __main__ - train loss is 27.568613452487625\n",
      "Steps:  94%|▉| 14151/15000 [2:01:21<02:32,  5.58it/s, lr=0.000966, step_loss=0.207/27/2023 19:46:11 - INFO - __main__ - train loss is 27.61012753623072\n",
      "Steps:  94%|▉| 14152/15000 [2:01:22<02:32,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:11 - INFO - __main__ - train loss is 27.745578480535187\n",
      "Steps:  94%|▉| 14153/15000 [2:01:22<02:31,  5.58it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:12 - INFO - __main__ - train loss is 27.82082602160517\n",
      "Steps:  94%|▉| 14154/15000 [2:01:22<02:31,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:12 - INFO - __main__ - train loss is 27.87683982180897\n",
      "Steps:  94%|▉| 14155/15000 [2:01:22<02:31,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:12 - INFO - __main__ - train loss is 28.081561004393734\n",
      "Steps:  94%|▉| 14156/15000 [2:01:22<02:31,  5.58it/s, lr=0.000966, step_loss=0.207/27/2023 19:46:12 - INFO - __main__ - train loss is 28.211009269231\n",
      "Steps:  94%|▉| 14157/15000 [2:01:22<02:31,  5.58it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:12 - INFO - __main__ - train loss is 28.26904199423734\n",
      "Steps:  94%|▉| 14158/15000 [2:01:23<02:32,  5.53it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:12 - INFO - __main__ - train loss is 28.272743319976144\n",
      "Steps:  94%|▉| 14159/15000 [2:01:23<02:31,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:13 - INFO - __main__ - train loss is 28.27561171387788\n",
      "Steps:  94%|▉| 14160/15000 [2:01:23<02:31,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:13 - INFO - __main__ - train loss is 28.348841607919894\n",
      "Steps:  94%|▉| 14161/15000 [2:01:23<02:30,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:13 - INFO - __main__ - train loss is 29.183233797899447\n",
      "Steps:  94%|▉| 14162/15000 [2:01:23<02:32,  5.51it/s, lr=0.000966, step_loss=0.807/27/2023 19:46:13 - INFO - __main__ - train loss is 29.220459703705274\n",
      "Steps:  94%|▉| 14163/15000 [2:01:24<02:31,  5.51it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:13 - INFO - __main__ - train loss is 29.32942910899874\n",
      "Steps:  94%|▉| 14164/15000 [2:01:24<02:31,  5.51it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:14 - INFO - __main__ - train loss is 29.365147333941422\n",
      "Steps:  94%|▉| 14165/15000 [2:01:24<02:31,  5.53it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:14 - INFO - __main__ - train loss is 29.508152585825883\n",
      "Steps:  94%|▉| 14166/15000 [2:01:24<02:31,  5.51it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:14 - INFO - __main__ - train loss is 29.53550424647983\n",
      "Steps:  94%|▉| 14167/15000 [2:01:24<02:30,  5.53it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:14 - INFO - __main__ - train loss is 29.543400720111094\n",
      "Steps:  94%|▉| 14168/15000 [2:01:24<02:30,  5.54it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:14 - INFO - __main__ - train loss is 29.563436746946536\n",
      "Steps:  94%|▉| 14169/15000 [2:01:25<02:31,  5.50it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:14 - INFO - __main__ - train loss is 29.568774568266235\n",
      "Steps:  94%|▉| 14170/15000 [2:01:25<02:30,  5.52it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:15 - INFO - __main__ - train loss is 29.577464979491197\n",
      "Steps:  94%|▉| 14171/15000 [2:01:25<02:31,  5.48it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:15 - INFO - __main__ - train loss is 29.58194510859903\n",
      "Steps:  94%|▉| 14172/15000 [2:01:25<02:30,  5.49it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:15 - INFO - __main__ - train loss is 29.61066583765205\n",
      "Steps:  94%|▉| 14173/15000 [2:01:25<02:29,  5.52it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:15 - INFO - __main__ - train loss is 29.618406134075485\n",
      "Steps:  94%|▉| 14174/15000 [2:01:26<02:29,  5.53it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:15 - INFO - __main__ - train loss is 29.702993611223064\n",
      "Steps:  94%|▉| 14175/15000 [2:01:26<02:28,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:16 - INFO - __main__ - train loss is 29.730984764522873\n",
      "Steps:  95%|▉| 14176/15000 [2:01:26<02:28,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:16 - INFO - __main__ - train loss is 29.747581271803938\n",
      "Steps:  95%|▉| 14177/15000 [2:01:26<02:28,  5.56it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:16 - INFO - __main__ - train loss is 29.91456636635121\n",
      "Steps:  95%|▉| 14178/15000 [2:01:26<02:27,  5.56it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:16 - INFO - __main__ - train loss is 29.91600750386715\n",
      "Steps:  95%|▉| 14179/15000 [2:01:26<02:27,  5.57it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:16 - INFO - __main__ - train loss is 30.76341639459133\n",
      "Steps:  95%|▉| 14180/15000 [2:01:27<02:27,  5.58it/s, lr=0.000966, step_loss=0.807/27/2023 19:46:16 - INFO - __main__ - train loss is 30.772302736528218\n",
      "Steps:  95%|▉| 14181/15000 [2:01:27<02:26,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:17 - INFO - __main__ - train loss is 30.87070517707616\n",
      "Steps:  95%|▉| 14182/15000 [2:01:27<02:26,  5.58it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:17 - INFO - __main__ - train loss is 30.872324126772583\n",
      "Steps:  95%|▉| 14183/15000 [2:01:27<02:27,  5.53it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:17 - INFO - __main__ - train loss is 30.933597679249942\n",
      "Steps:  95%|▉| 14184/15000 [2:01:27<02:27,  5.54it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:17 - INFO - __main__ - train loss is 31.07726443838328\n",
      "Steps:  95%|▉| 14185/15000 [2:01:27<02:26,  5.56it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:17 - INFO - __main__ - train loss is 31.087620972655714\n",
      "Steps:  95%|▉| 14186/15000 [2:01:28<02:27,  5.51it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:18 - INFO - __main__ - train loss is 31.19054791983217\n",
      "Steps:  95%|▉| 14187/15000 [2:01:28<02:29,  5.44it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:18 - INFO - __main__ - train loss is 31.5077541237697\n",
      "Steps:  95%|▉| 14188/15000 [2:01:28<02:30,  5.39it/s, lr=0.000966, step_loss=0.307/27/2023 19:46:18 - INFO - __main__ - train loss is 31.592359281145036\n",
      "Steps:  95%|▉| 14189/15000 [2:01:28<02:29,  5.41it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:18 - INFO - __main__ - train loss is 31.608159719966352\n",
      "Steps:  95%|▉| 14190/15000 [2:01:28<02:28,  5.46it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:18 - INFO - __main__ - train loss is 31.60918964771554\n",
      "Steps:  95%|▉| 14191/15000 [2:01:29<02:27,  5.49it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:18 - INFO - __main__ - train loss is 31.702670592349023\n",
      "Steps:  95%|▉| 14192/15000 [2:01:29<02:26,  5.52it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:19 - INFO - __main__ - train loss is 31.86183302430436\n",
      "Steps:  95%|▉| 14193/15000 [2:01:29<02:25,  5.54it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:19 - INFO - __main__ - train loss is 31.870649514254183\n",
      "Steps:  95%|▉| 14194/15000 [2:01:29<02:26,  5.50it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:19 - INFO - __main__ - train loss is 31.878547079395503\n",
      "Steps:  95%|▉| 14195/15000 [2:01:29<02:26,  5.51it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:19 - INFO - __main__ - train loss is 32.13641012413427\n",
      "Steps:  95%|▉| 14196/15000 [2:01:29<02:25,  5.52it/s, lr=0.000966, step_loss=0.207/27/2023 19:46:19 - INFO - __main__ - train loss is 32.19701187266037\n",
      "Steps:  95%|▉| 14197/15000 [2:01:30<02:25,  5.54it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:20 - INFO - __main__ - train loss is 32.20631956635043\n",
      "Steps:  95%|▉| 14198/15000 [2:01:30<02:24,  5.54it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:20 - INFO - __main__ - train loss is 32.249070204328746\n",
      "Steps:  95%|▉| 14199/15000 [2:01:30<02:24,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:20 - INFO - __main__ - train loss is 32.441337920259684\n",
      "Steps:  95%|▉| 14200/15000 [2:01:30<02:24,  5.54it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:20 - INFO - __main__ - train loss is 32.48996582953259\n",
      "Steps:  95%|▉| 14201/15000 [2:01:30<02:23,  5.55it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:20 - INFO - __main__ - train loss is 32.67781600682065\n",
      "Steps:  95%|▉| 14202/15000 [2:01:31<02:23,  5.54it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:20 - INFO - __main__ - train loss is 32.73038978828117\n",
      "Steps:  95%|▉| 14203/15000 [2:01:31<02:24,  5.50it/s, lr=0.000966, step_loss=0.007/27/2023 19:46:21 - INFO - __main__ - train loss is 32.89658324373886\n",
      "Steps:  95%|▉| 14204/15000 [2:01:31<02:24,  5.51it/s, lr=0.000966, step_loss=0.107/27/2023 19:46:21 - INFO - __main__ - train loss is 32.9043476767838\n",
      "Steps:  95%|▉| 14205/15000 [2:01:31<02:23,  5.53it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:21 - INFO - __main__ - train loss is 33.15549053624272\n",
      "Steps:  95%|▉| 14206/15000 [2:01:31<02:23,  5.55it/s, lr=0.000965, step_loss=0.207/27/2023 19:46:21 - INFO - __main__ - train loss is 33.40016271546483\n",
      "Steps:  95%|▉| 14207/15000 [2:01:31<02:22,  5.55it/s, lr=0.000965, step_loss=0.207/27/2023 19:46:21 - INFO - __main__ - train loss is 33.95868583396077\n",
      "Steps:  95%|▉| 14208/15000 [2:01:32<02:22,  5.56it/s, lr=0.000965, step_loss=0.507/27/2023 19:46:22 - INFO - __main__ - train loss is 34.210193920880556\n",
      "Steps:  95%|▉| 14209/15000 [2:01:32<02:22,  5.56it/s, lr=0.000965, step_loss=0.207/27/2023 19:46:22 - INFO - __main__ - train loss is 34.74666975811124\n",
      "Steps:  95%|▉| 14210/15000 [2:01:32<02:21,  5.57it/s, lr=0.000965, step_loss=0.507/27/2023 19:46:22 - INFO - __main__ - train loss is 34.765111932531\n",
      "Steps:  95%|▉| 14211/15000 [2:01:32<02:21,  5.57it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:22 - INFO - __main__ - train loss is 34.81042764522135\n",
      "Steps:  95%|▉| 14212/15000 [2:01:32<02:21,  5.57it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:22 - INFO - __main__ - train loss is 34.831349002197385\n",
      "Steps:  95%|▉| 14213/15000 [2:01:33<02:21,  5.57it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:22 - INFO - __main__ - train loss is 34.83486836287193\n",
      "Steps:  95%|▉| 14214/15000 [2:01:33<02:21,  5.57it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:23 - INFO - __main__ - train loss is 34.868886842159554\n",
      "Steps:  95%|▉| 14215/15000 [2:01:33<02:21,  5.56it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:23 - INFO - __main__ - train loss is 35.13699503126554\n",
      "Steps:  95%|▉| 14216/15000 [2:01:33<02:20,  5.56it/s, lr=0.000965, step_loss=0.207/27/2023 19:46:23 - INFO - __main__ - train loss is 35.239564201561734\n",
      "Steps:  95%|▉| 14217/15000 [2:01:33<02:20,  5.57it/s, lr=0.000965, step_loss=0.107/27/2023 19:46:23 - INFO - __main__ - train loss is 35.30232477816753\n",
      "Steps:  95%|▉| 14218/15000 [2:01:33<02:20,  5.57it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:23 - INFO - __main__ - train loss is 35.30781083018519\n",
      "Steps:  95%|▉| 14219/15000 [2:01:34<02:20,  5.57it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:24 - INFO - __main__ - train loss is 35.31305478303693\n",
      "Steps:  95%|▉| 14220/15000 [2:01:34<02:19,  5.57it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:24 - INFO - __main__ - train loss is 35.31542708002962\n",
      "Steps:  95%|▉| 14221/15000 [2:01:34<02:19,  5.58it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:24 - INFO - __main__ - train loss is 35.327700468944386\n",
      "Steps:  95%|▉| 14222/15000 [2:01:34<02:19,  5.58it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:24 - INFO - __main__ - train loss is 35.32933026039973\n",
      "Steps:  95%|▉| 14223/15000 [2:01:34<02:19,  5.58it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:24 - INFO - __main__ - train loss is 35.565550873521715\n",
      "Steps:  95%|▉| 14224/15000 [2:01:35<02:19,  5.57it/s, lr=0.000965, step_loss=0.207/27/2023 19:46:24 - INFO - __main__ - train loss is 35.74839478218928\n",
      "Steps:  95%|▉| 14225/15000 [2:01:35<02:18,  5.58it/s, lr=0.000965, step_loss=0.107/27/2023 19:46:25 - INFO - __main__ - train loss is 36.65445559704676\n",
      "Steps:  95%|▉| 14226/15000 [2:01:35<02:18,  5.58it/s, lr=0.000965, step_loss=0.907/27/2023 19:46:25 - INFO - __main__ - train loss is 36.65835477295332\n",
      "Steps:  95%|▉| 14227/15000 [2:01:35<02:18,  5.58it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:25 - INFO - __main__ - train loss is 36.6656959594693\n",
      "Steps:  95%|▉| 14228/15000 [2:01:35<02:18,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:25 - INFO - __main__ - train loss is 36.67780217877589\n",
      "Steps:  95%|▉| 14229/15000 [2:01:35<02:18,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:25 - INFO - __main__ - train loss is 36.858372676884755\n",
      "Steps:  95%|▉| 14230/15000 [2:01:36<02:17,  5.58it/s, lr=0.000965, step_loss=0.107/27/2023 19:46:25 - INFO - __main__ - train loss is 36.862013975856826\n",
      "Steps:  95%|▉| 14231/15000 [2:01:36<02:17,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:26 - INFO - __main__ - train loss is 36.9251537125092\n",
      "Steps:  95%|▉| 14232/15000 [2:01:36<02:17,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:26 - INFO - __main__ - train loss is 37.04033003258519\n",
      "Steps:  95%|▉| 14233/15000 [2:01:36<02:17,  5.59it/s, lr=0.000965, step_loss=0.107/27/2023 19:46:26 - INFO - __main__ - train loss is 37.0722314666491\n",
      "Steps:  95%|▉| 14234/15000 [2:01:36<02:17,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:26 - INFO - __main__ - train loss is 37.20708719897084\n",
      "Steps:  95%|▉| 14235/15000 [2:01:36<02:16,  5.59it/s, lr=0.000965, step_loss=0.107/27/2023 19:46:26 - INFO - __main__ - train loss is 37.21210791612975\n",
      "Steps:  95%|▉| 14236/15000 [2:01:37<02:16,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:27 - INFO - __main__ - train loss is 37.71021177317016\n",
      "Steps:  95%|▉| 14237/15000 [2:01:37<02:16,  5.59it/s, lr=0.000965, step_loss=0.407/27/2023 19:46:27 - INFO - __main__ - train loss is 37.749455597950146\n",
      "Steps:  95%|▉| 14238/15000 [2:01:37<02:16,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:27 - INFO - __main__ - train loss is 37.75776954903267\n",
      "Steps:  95%|▉| 14239/15000 [2:01:37<02:16,  5.59it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:27 - INFO - __main__ - train loss is 38.085169756552204\n",
      "Steps:  95%|▉| 14240/15000 [2:01:37<02:15,  5.59it/s, lr=0.000965, step_loss=0.307/27/2023 19:46:28 - INFO - __main__ - train loss is 38.12388112931512\n",
      "Steps:  95%|▉| 14241/15000 [2:01:38<03:19,  3.80it/s, lr=0.000965, step_loss=0.007/27/2023 19:46:29 - INFO - __main__ - Per validation step average loss is 0.003772204276174307\n",
      "07/27/2023 19:46:29 - INFO - __main__ - Cumulative validation average loss is 0.003772204276174307\n",
      "07/27/2023 19:46:29 - INFO - __main__ - Per validation step average loss is 0.048115044832229614\n",
      "07/27/2023 19:46:29 - INFO - __main__ - Cumulative validation average loss is 0.05188724910840392\n",
      "07/27/2023 19:46:29 - INFO - __main__ - Per validation step average loss is 0.035996366292238235\n",
      "07/27/2023 19:46:29 - INFO - __main__ - Cumulative validation average loss is 0.08788361540064216\n",
      "07/27/2023 19:46:30 - INFO - __main__ - Per validation step average loss is 0.0022109299898147583\n",
      "07/27/2023 19:46:30 - INFO - __main__ - Cumulative validation average loss is 0.09009454539045691\n",
      "07/27/2023 19:46:30 - INFO - __main__ - Per validation step average loss is 0.1379971206188202\n",
      "07/27/2023 19:46:30 - INFO - __main__ - Cumulative validation average loss is 0.2280916660092771\n",
      "07/27/2023 19:46:31 - INFO - __main__ - Per validation step average loss is 0.0021017384715378284\n",
      "07/27/2023 19:46:31 - INFO - __main__ - Cumulative validation average loss is 0.23019340448081493\n",
      "07/27/2023 19:46:31 - INFO - __main__ - Per validation step average loss is 0.08055479824542999\n",
      "07/27/2023 19:46:31 - INFO - __main__ - Cumulative validation average loss is 0.3107482027262449\n",
      "07/27/2023 19:46:32 - INFO - __main__ - Per validation step average loss is 0.015801751986145973\n",
      "07/27/2023 19:46:32 - INFO - __main__ - Cumulative validation average loss is 0.3265499547123909\n",
      "07/27/2023 19:46:32 - INFO - __main__ - Per validation step average loss is 0.0024287248961627483\n",
      "07/27/2023 19:46:32 - INFO - __main__ - Cumulative validation average loss is 0.32897867960855365\n",
      "07/27/2023 19:46:32 - INFO - __main__ - Per validation step average loss is 0.020994558930397034\n",
      "07/27/2023 19:46:32 - INFO - __main__ - Cumulative validation average loss is 0.3499732385389507\n",
      "07/27/2023 19:46:33 - INFO - __main__ - Per validation step average loss is 0.009693322703242302\n",
      "07/27/2023 19:46:33 - INFO - __main__ - Cumulative validation average loss is 0.359666561242193\n",
      "07/27/2023 19:46:33 - INFO - __main__ - Per validation step average loss is 0.21790239214897156\n",
      "07/27/2023 19:46:33 - INFO - __main__ - Cumulative validation average loss is 0.5775689533911645\n",
      "07/27/2023 19:46:34 - INFO - __main__ - Per validation step average loss is 0.035136498510837555\n",
      "07/27/2023 19:46:34 - INFO - __main__ - Cumulative validation average loss is 0.6127054519020021\n",
      "07/27/2023 19:46:34 - INFO - __main__ - Per validation step average loss is 0.5386415123939514\n",
      "07/27/2023 19:46:34 - INFO - __main__ - Cumulative validation average loss is 1.1513469642959535\n",
      "07/27/2023 19:46:34 - INFO - __main__ - Per validation step average loss is 0.16120827198028564\n",
      "07/27/2023 19:46:34 - INFO - __main__ - Cumulative validation average loss is 1.3125552362762392\n",
      "07/27/2023 19:46:35 - INFO - __main__ - Per validation step average loss is 0.3539208769798279\n",
      "07/27/2023 19:46:35 - INFO - __main__ - Cumulative validation average loss is 1.666476113256067\n",
      "07/27/2023 19:46:35 - INFO - __main__ - Per validation step average loss is 0.631162166595459\n",
      "07/27/2023 19:46:35 - INFO - __main__ - Cumulative validation average loss is 2.297638279851526\n",
      "07/27/2023 19:46:36 - INFO - __main__ - Per validation step average loss is 0.006105133332312107\n",
      "07/27/2023 19:46:36 - INFO - __main__ - Cumulative validation average loss is 2.303743413183838\n",
      "07/27/2023 19:46:36 - INFO - __main__ - Per validation step average loss is 0.19741281867027283\n",
      "07/27/2023 19:46:36 - INFO - __main__ - Cumulative validation average loss is 2.501156231854111\n",
      "07/27/2023 19:46:37 - INFO - __main__ - Per validation step average loss is 0.026520967483520508\n",
      "07/27/2023 19:46:37 - INFO - __main__ - Cumulative validation average loss is 2.5276771993376315\n",
      "07/27/2023 19:46:37 - INFO - __main__ - Per validation step average loss is 0.016538631170988083\n",
      "07/27/2023 19:46:37 - INFO - __main__ - Cumulative validation average loss is 2.5442158305086195\n",
      "07/27/2023 19:46:37 - INFO - __main__ - Per validation step average loss is 0.3674192726612091\n",
      "07/27/2023 19:46:37 - INFO - __main__ - Cumulative validation average loss is 2.9116351031698287\n",
      "07/27/2023 19:46:38 - INFO - __main__ - Per validation step average loss is 0.5524345636367798\n",
      "07/27/2023 19:46:38 - INFO - __main__ - Cumulative validation average loss is 3.4640696668066084\n",
      "07/27/2023 19:46:38 - INFO - __main__ - Per validation step average loss is 0.003719711909070611\n",
      "07/27/2023 19:46:38 - INFO - __main__ - Cumulative validation average loss is 3.467789378715679\n",
      "07/27/2023 19:46:39 - INFO - __main__ - Per validation step average loss is 0.5378743410110474\n",
      "07/27/2023 19:46:39 - INFO - __main__ - Cumulative validation average loss is 4.005663719726726\n",
      "07/27/2023 19:46:39 - INFO - __main__ - Per validation step average loss is 0.003626023419201374\n",
      "07/27/2023 19:46:39 - INFO - __main__ - Cumulative validation average loss is 4.009289743145928\n",
      "07/27/2023 19:46:39 - INFO - __main__ - Per validation step average loss is 0.025223247706890106\n",
      "07/27/2023 19:46:39 - INFO - __main__ - Cumulative validation average loss is 4.034512990852818\n",
      "07/27/2023 19:46:40 - INFO - __main__ - Per validation step average loss is 0.010354281403124332\n",
      "07/27/2023 19:46:40 - INFO - __main__ - Cumulative validation average loss is 4.044867272255942\n",
      "07/27/2023 19:46:40 - INFO - __main__ - Per validation step average loss is 0.13618232309818268\n",
      "07/27/2023 19:46:40 - INFO - __main__ - Cumulative validation average loss is 4.181049595354125\n",
      "07/27/2023 19:46:41 - INFO - __main__ - Per validation step average loss is 0.13960102200508118\n",
      "07/27/2023 19:46:41 - INFO - __main__ - Cumulative validation average loss is 4.320650617359206\n",
      "07/27/2023 19:46:41 - INFO - __main__ - Per validation step average loss is 0.14279472827911377\n",
      "07/27/2023 19:46:41 - INFO - __main__ - Cumulative validation average loss is 4.46344534563832\n",
      "07/27/2023 19:46:42 - INFO - __main__ - Per validation step average loss is 0.025419868528842926\n",
      "07/27/2023 19:46:42 - INFO - __main__ - Cumulative validation average loss is 4.488865214167163\n",
      "07/27/2023 19:46:42 - INFO - __main__ - Per validation step average loss is 0.1520293802022934\n",
      "07/27/2023 19:46:42 - INFO - __main__ - Cumulative validation average loss is 4.640894594369456\n",
      "07/27/2023 19:46:42 - INFO - __main__ - Per validation step average loss is 0.009489648044109344\n",
      "07/27/2023 19:46:42 - INFO - __main__ - Cumulative validation average loss is 4.6503842424135655\n",
      "07/27/2023 19:46:43 - INFO - __main__ - Per validation step average loss is 0.517833948135376\n",
      "07/27/2023 19:46:43 - INFO - __main__ - Cumulative validation average loss is 5.1682181905489415\n",
      "07/27/2023 19:46:43 - INFO - __main__ - Per validation step average loss is 0.06680195033550262\n",
      "07/27/2023 19:46:43 - INFO - __main__ - Cumulative validation average loss is 5.235020140884444\n",
      "07/27/2023 19:46:44 - INFO - __main__ - Per validation step average loss is 0.1622248888015747\n",
      "07/27/2023 19:46:44 - INFO - __main__ - Cumulative validation average loss is 5.397245029686019\n",
      "07/27/2023 19:46:44 - INFO - __main__ - Per validation step average loss is 0.11593620479106903\n",
      "07/27/2023 19:46:44 - INFO - __main__ - Cumulative validation average loss is 5.513181234477088\n",
      "07/27/2023 19:46:44 - INFO - __main__ - Per validation step average loss is 0.001090274890884757\n",
      "07/27/2023 19:46:44 - INFO - __main__ - Cumulative validation average loss is 5.514271509367973\n",
      "07/27/2023 19:46:45 - INFO - __main__ - Per validation step average loss is 0.030725669115781784\n",
      "07/27/2023 19:46:45 - INFO - __main__ - Cumulative validation average loss is 5.544997178483754\n",
      "07/27/2023 19:46:45 - INFO - __main__ - Per validation step average loss is 0.08826979994773865\n",
      "07/27/2023 19:46:45 - INFO - __main__ - Cumulative validation average loss is 5.633266978431493\n",
      "07/27/2023 19:46:46 - INFO - __main__ - Per validation step average loss is 0.004885002970695496\n",
      "07/27/2023 19:46:46 - INFO - __main__ - Cumulative validation average loss is 5.6381519814021885\n",
      "07/27/2023 19:46:46 - INFO - __main__ - Per validation step average loss is 0.125118225812912\n",
      "07/27/2023 19:46:46 - INFO - __main__ - Cumulative validation average loss is 5.7632702072151005\n",
      "07/27/2023 19:46:47 - INFO - __main__ - Per validation step average loss is 0.007786129135638475\n",
      "07/27/2023 19:46:47 - INFO - __main__ - Cumulative validation average loss is 5.771056336350739\n",
      "07/27/2023 19:46:47 - INFO - __main__ - Per validation step average loss is 0.1452459990978241\n",
      "07/27/2023 19:46:47 - INFO - __main__ - Cumulative validation average loss is 5.916302335448563\n",
      "07/27/2023 19:46:47 - INFO - __main__ - Per validation step average loss is 0.16319647431373596\n",
      "07/27/2023 19:46:47 - INFO - __main__ - Cumulative validation average loss is 6.079498809762299\n",
      "07/27/2023 19:46:48 - INFO - __main__ - Per validation step average loss is 0.13438400626182556\n",
      "07/27/2023 19:46:48 - INFO - __main__ - Cumulative validation average loss is 6.213882816024125\n",
      "07/27/2023 19:46:48 - INFO - __main__ - Per validation step average loss is 0.03167157620191574\n",
      "07/27/2023 19:46:48 - INFO - __main__ - Cumulative validation average loss is 6.24555439222604\n",
      "07/27/2023 19:46:49 - INFO - __main__ - Per validation step average loss is 0.02864599972963333\n",
      "07/27/2023 19:46:49 - INFO - __main__ - Cumulative validation average loss is 6.274200391955674\n",
      "07/27/2023 19:46:49 - INFO - __main__ - Per validation step average loss is 0.0048994929529726505\n",
      "07/27/2023 19:46:49 - INFO - __main__ - Cumulative validation average loss is 6.279099884908646\n",
      "07/27/2023 19:46:50 - INFO - __main__ - Per validation step average loss is 0.0176292285323143\n",
      "07/27/2023 19:46:50 - INFO - __main__ - Cumulative validation average loss is 6.296729113440961\n",
      "07/27/2023 19:46:50 - INFO - __main__ - Per validation step average loss is 0.09798746556043625\n",
      "07/27/2023 19:46:50 - INFO - __main__ - Cumulative validation average loss is 6.394716579001397\n",
      "07/27/2023 19:46:50 - INFO - __main__ - Per validation step average loss is 0.2495560348033905\n",
      "07/27/2023 19:46:50 - INFO - __main__ - Cumulative validation average loss is 6.644272613804787\n",
      "07/27/2023 19:46:51 - INFO - __main__ - Per validation step average loss is 0.0017501774709671736\n",
      "07/27/2023 19:46:51 - INFO - __main__ - Cumulative validation average loss is 6.646022791275755\n",
      "07/27/2023 19:46:51 - INFO - __main__ - Per validation step average loss is 0.04768548905849457\n",
      "07/27/2023 19:46:51 - INFO - __main__ - Cumulative validation average loss is 6.693708280334249\n",
      "07/27/2023 19:46:52 - INFO - __main__ - Per validation step average loss is 0.03863321244716644\n",
      "07/27/2023 19:46:52 - INFO - __main__ - Cumulative validation average loss is 6.732341492781416\n",
      "07/27/2023 19:46:52 - INFO - __main__ - Per validation step average loss is 0.27393123507499695\n",
      "07/27/2023 19:46:52 - INFO - __main__ - Cumulative validation average loss is 7.0062727278564125\n",
      "07/27/2023 19:46:52 - INFO - __main__ - Per validation step average loss is 0.016171962022781372\n",
      "07/27/2023 19:46:52 - INFO - __main__ - Cumulative validation average loss is 7.022444689879194\n",
      "07/27/2023 19:46:53 - INFO - __main__ - Per validation step average loss is 0.2985677123069763\n",
      "07/27/2023 19:46:53 - INFO - __main__ - Cumulative validation average loss is 7.32101240218617\n",
      "07/27/2023 19:46:53 - INFO - __main__ - Per validation step average loss is 0.014179971069097519\n",
      "07/27/2023 19:46:53 - INFO - __main__ - Cumulative validation average loss is 7.335192373255268\n",
      "07/27/2023 19:46:54 - INFO - __main__ - Per validation step average loss is 0.05720202624797821\n",
      "07/27/2023 19:46:54 - INFO - __main__ - Cumulative validation average loss is 7.392394399503246\n",
      "07/27/2023 19:46:54 - INFO - __main__ - Per validation step average loss is 0.023928746581077576\n",
      "07/27/2023 19:46:54 - INFO - __main__ - Cumulative validation average loss is 7.4163231460843235\n",
      "07/27/2023 19:46:55 - INFO - __main__ - Per validation step average loss is 0.06217897683382034\n",
      "07/27/2023 19:46:55 - INFO - __main__ - Cumulative validation average loss is 7.478502122918144\n",
      "07/27/2023 19:46:55 - INFO - __main__ - Per validation step average loss is 0.3344501256942749\n",
      "07/27/2023 19:46:55 - INFO - __main__ - Cumulative validation average loss is 7.812952248612419\n",
      "07/27/2023 19:46:55 - INFO - __main__ - Per validation step average loss is 0.050274018198251724\n",
      "07/27/2023 19:46:55 - INFO - __main__ - Cumulative validation average loss is 7.8632262668106705\n",
      "07/27/2023 19:46:56 - INFO - __main__ - Per validation step average loss is 0.5389573574066162\n",
      "07/27/2023 19:46:56 - INFO - __main__ - Cumulative validation average loss is 8.402183624217287\n",
      "07/27/2023 19:46:56 - INFO - __main__ - Per validation step average loss is 0.14236073195934296\n",
      "07/27/2023 19:46:56 - INFO - __main__ - Cumulative validation average loss is 8.54454435617663\n",
      "07/27/2023 19:46:57 - INFO - __main__ - Per validation step average loss is 0.17372679710388184\n",
      "07/27/2023 19:46:57 - INFO - __main__ - Cumulative validation average loss is 8.718271153280511\n",
      "07/27/2023 19:46:57 - INFO - __main__ - Per validation step average loss is 0.011051942594349384\n",
      "07/27/2023 19:46:57 - INFO - __main__ - Cumulative validation average loss is 8.72932309587486\n",
      "07/27/2023 19:46:57 - INFO - __main__ - Per validation step average loss is 0.10925139486789703\n",
      "07/27/2023 19:46:57 - INFO - __main__ - Cumulative validation average loss is 8.838574490742758\n",
      "07/27/2023 19:46:58 - INFO - __main__ - Per validation step average loss is 0.06647172570228577\n",
      "07/27/2023 19:46:58 - INFO - __main__ - Cumulative validation average loss is 8.905046216445044\n",
      "07/27/2023 19:46:58 - INFO - __main__ - Per validation step average loss is 0.2577168941497803\n",
      "07/27/2023 19:46:58 - INFO - __main__ - Cumulative validation average loss is 9.162763110594824\n",
      "07/27/2023 19:46:59 - INFO - __main__ - Per validation step average loss is 0.02046021819114685\n",
      "07/27/2023 19:46:59 - INFO - __main__ - Cumulative validation average loss is 9.18322332878597\n",
      "07/27/2023 19:46:59 - INFO - __main__ - Per validation step average loss is 0.0020601009018719196\n",
      "07/27/2023 19:46:59 - INFO - __main__ - Cumulative validation average loss is 9.185283429687843\n",
      "07/27/2023 19:47:00 - INFO - __main__ - Per validation step average loss is 0.22065705060958862\n",
      "07/27/2023 19:47:00 - INFO - __main__ - Cumulative validation average loss is 9.405940480297431\n",
      "07/27/2023 19:47:00 - INFO - __main__ - Per validation step average loss is 0.0344439297914505\n",
      "07/27/2023 19:47:00 - INFO - __main__ - Cumulative validation average loss is 9.440384410088882\n",
      "07/27/2023 19:47:00 - INFO - __main__ - Per validation step average loss is 0.32599252462387085\n",
      "07/27/2023 19:47:00 - INFO - __main__ - Cumulative validation average loss is 9.766376934712753\n",
      "07/27/2023 19:47:01 - INFO - __main__ - Per validation step average loss is 0.24326281249523163\n",
      "07/27/2023 19:47:01 - INFO - __main__ - Cumulative validation average loss is 10.009639747207984\n",
      "07/27/2023 19:47:02 - INFO - __main__ - Per validation step average loss is 0.18712185323238373\n",
      "07/27/2023 19:47:02 - INFO - __main__ - Cumulative validation average loss is 10.196761600440368\n",
      "07/27/2023 19:47:02 - INFO - __main__ - Average validation loss for Epoch 46 is 0.1290729316511439\n",
      "07/27/2023 19:47:02 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/27/2023 19:47:59 - INFO - __main__ - Starting epoch 47\n",
      "07/27/2023 19:47:59 - INFO - __main__ - train loss is 0.01775532402098179\n",
      "Steps:  95%|▉| 14242/15000 [2:03:10<5:49:50, 27.69s/it, lr=0.000965, step_loss=007/27/2023 19:47:59 - INFO - __main__ - train loss is 0.10206103511154652\n",
      "Steps:  95%|▉| 14243/15000 [2:03:10<4:05:14, 19.44s/it, lr=0.000965, step_loss=007/27/2023 19:48:00 - INFO - __main__ - train loss is 0.4463995713740587\n",
      "Steps:  95%|▉| 14244/15000 [2:03:10<2:52:07, 13.66s/it, lr=0.000965, step_loss=007/27/2023 19:48:00 - INFO - __main__ - train loss is 0.447929777787067\n",
      "Steps:  95%|▉| 14245/15000 [2:03:10<2:01:00,  9.62s/it, lr=0.000965, step_loss=007/27/2023 19:48:00 - INFO - __main__ - train loss is 0.48139139323029667\n",
      "Steps:  95%|▉| 14246/15000 [2:03:10<1:25:15,  6.78s/it, lr=0.000965, step_loss=007/27/2023 19:48:00 - INFO - __main__ - train loss is 0.8617798021296039\n",
      "Steps:  95%|▉| 14247/15000 [2:03:10<1:00:17,  4.80s/it, lr=0.000965, step_loss=007/27/2023 19:48:00 - INFO - __main__ - train loss is 0.8689983944641426\n",
      "Steps:  95%|▉| 14248/15000 [2:03:11<42:49,  3.42s/it, lr=0.000965, step_loss=0.007/27/2023 19:48:00 - INFO - __main__ - train loss is 0.8710902902530506\n",
      "Steps:  95%|▉| 14249/15000 [2:03:11<30:36,  2.45s/it, lr=0.000965, step_loss=0.007/27/2023 19:48:01 - INFO - __main__ - train loss is 1.1572971317218617\n",
      "Steps:  95%|▉| 14250/15000 [2:03:11<22:04,  1.77s/it, lr=0.000965, step_loss=0.207/27/2023 19:48:01 - INFO - __main__ - train loss is 1.1634940995136276\n",
      "Steps:  95%|▉| 14251/15000 [2:03:11<16:05,  1.29s/it, lr=0.000965, step_loss=0.007/27/2023 19:48:01 - INFO - __main__ - train loss is 1.4334554566303268\n",
      "Steps:  95%|▉| 14252/15000 [2:03:11<11:55,  1.05it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:01 - INFO - __main__ - train loss is 1.6744832886615768\n",
      "Steps:  95%|▉| 14253/15000 [2:03:12<09:00,  1.38it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:01 - INFO - __main__ - train loss is 1.814428378478624\n",
      "Steps:  95%|▉| 14254/15000 [2:03:12<06:57,  1.79it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:02 - INFO - __main__ - train loss is 2.1952112211147323\n",
      "Steps:  95%|▉| 14255/15000 [2:03:12<05:32,  2.24it/s, lr=0.000965, step_loss=0.307/27/2023 19:48:02 - INFO - __main__ - train loss is 2.367895950214006\n",
      "Steps:  95%|▉| 14256/15000 [2:03:12<04:32,  2.73it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:02 - INFO - __main__ - train loss is 2.3729632823960856\n",
      "Steps:  95%|▉| 14257/15000 [2:03:12<03:50,  3.23it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:02 - INFO - __main__ - train loss is 2.6541480153100565\n",
      "Steps:  95%|▉| 14258/15000 [2:03:12<03:20,  3.69it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:02 - INFO - __main__ - train loss is 2.8000318735139444\n",
      "Steps:  95%|▉| 14259/15000 [2:03:13<03:00,  4.10it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:02 - INFO - __main__ - train loss is 2.8325703806476668\n",
      "Steps:  95%|▉| 14260/15000 [2:03:13<02:46,  4.46it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:03 - INFO - __main__ - train loss is 3.0315080798463896\n",
      "Steps:  95%|▉| 14261/15000 [2:03:13<02:36,  4.74it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:03 - INFO - __main__ - train loss is 3.0445287629263476\n",
      "Steps:  95%|▉| 14262/15000 [2:03:13<02:28,  4.95it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:03 - INFO - __main__ - train loss is 3.1595573752420023\n",
      "Steps:  95%|▉| 14263/15000 [2:03:13<02:24,  5.12it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:03 - INFO - __main__ - train loss is 3.3639862566487864\n",
      "Steps:  95%|▉| 14264/15000 [2:03:13<02:21,  5.21it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:03 - INFO - __main__ - train loss is 4.088077905704267\n",
      "Steps:  95%|▉| 14265/15000 [2:03:14<02:19,  5.27it/s, lr=0.000965, step_loss=0.707/27/2023 19:48:04 - INFO - __main__ - train loss is 4.097205649246462\n",
      "Steps:  95%|▉| 14266/15000 [2:03:14<02:17,  5.35it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:04 - INFO - __main__ - train loss is 4.579768697847612\n",
      "Steps:  95%|▉| 14267/15000 [2:03:14<02:15,  5.41it/s, lr=0.000965, step_loss=0.407/27/2023 19:48:04 - INFO - __main__ - train loss is 4.789106453885324\n",
      "Steps:  95%|▉| 14268/15000 [2:03:14<02:14,  5.46it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:04 - INFO - __main__ - train loss is 4.93725320242811\n",
      "Steps:  95%|▉| 14269/15000 [2:03:14<02:13,  5.49it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:04 - INFO - __main__ - train loss is 4.974283124436624\n",
      "Steps:  95%|▉| 14270/15000 [2:03:15<02:13,  5.46it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:04 - INFO - __main__ - train loss is 5.01275182061363\n",
      "Steps:  95%|▉| 14271/15000 [2:03:15<02:14,  5.42it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:05 - INFO - __main__ - train loss is 5.170124459196813\n",
      "Steps:  95%|▉| 14272/15000 [2:03:15<02:14,  5.42it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:05 - INFO - __main__ - train loss is 5.192785072256811\n",
      "Steps:  95%|▉| 14273/15000 [2:03:15<02:14,  5.41it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:05 - INFO - __main__ - train loss is 5.199226533179171\n",
      "Steps:  95%|▉| 14274/15000 [2:03:15<02:14,  5.42it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:05 - INFO - __main__ - train loss is 5.214742642012425\n",
      "Steps:  95%|▉| 14275/15000 [2:03:16<02:12,  5.46it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:05 - INFO - __main__ - train loss is 5.222008222830482\n",
      "Steps:  95%|▉| 14276/15000 [2:03:16<02:11,  5.49it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:06 - INFO - __main__ - train loss is 5.606486225617118\n",
      "Steps:  95%|▉| 14277/15000 [2:03:16<02:11,  5.51it/s, lr=0.000965, step_loss=0.307/27/2023 19:48:06 - INFO - __main__ - train loss is 6.071882331860252\n",
      "Steps:  95%|▉| 14278/15000 [2:03:16<02:10,  5.53it/s, lr=0.000965, step_loss=0.407/27/2023 19:48:06 - INFO - __main__ - train loss is 6.176382372272201\n",
      "Steps:  95%|▉| 14279/15000 [2:03:16<02:10,  5.54it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:06 - INFO - __main__ - train loss is 6.223992077750154\n",
      "Steps:  95%|▉| 14280/15000 [2:03:16<02:10,  5.54it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:06 - INFO - __main__ - train loss is 6.476997820776887\n",
      "Steps:  95%|▉| 14281/15000 [2:03:17<02:09,  5.54it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:06 - INFO - __main__ - train loss is 6.479711941559799\n",
      "Steps:  95%|▉| 14282/15000 [2:03:17<02:09,  5.54it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:07 - INFO - __main__ - train loss is 6.496228131582029\n",
      "Steps:  95%|▉| 14283/15000 [2:03:17<02:09,  5.55it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:07 - INFO - __main__ - train loss is 6.723976942826994\n",
      "Steps:  95%|▉| 14284/15000 [2:03:17<02:09,  5.54it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:07 - INFO - __main__ - train loss is 7.019579204847105\n",
      "Steps:  95%|▉| 14285/15000 [2:03:17<02:08,  5.55it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:07 - INFO - __main__ - train loss is 7.601321133901365\n",
      "Steps:  95%|▉| 14286/15000 [2:03:17<02:09,  5.51it/s, lr=0.000965, step_loss=0.507/27/2023 19:48:07 - INFO - __main__ - train loss is 7.62410478212405\n",
      "Steps:  95%|▉| 14287/15000 [2:03:18<02:10,  5.48it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:08 - INFO - __main__ - train loss is 7.7401631764369085\n",
      "Steps:  95%|▉| 14288/15000 [2:03:18<02:09,  5.48it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:08 - INFO - __main__ - train loss is 7.840880214353092\n",
      "Steps:  95%|▉| 14289/15000 [2:03:18<02:09,  5.51it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:08 - INFO - __main__ - train loss is 7.8776906608836725\n",
      "Steps:  95%|▉| 14290/15000 [2:03:18<02:08,  5.51it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:08 - INFO - __main__ - train loss is 7.982305581797846\n",
      "Steps:  95%|▉| 14291/15000 [2:03:18<02:09,  5.48it/s, lr=0.000965, step_loss=0.107/27/2023 19:48:08 - INFO - __main__ - train loss is 8.427185352076776\n",
      "Steps:  95%|▉| 14292/15000 [2:03:19<02:08,  5.49it/s, lr=0.000965, step_loss=0.407/27/2023 19:48:08 - INFO - __main__ - train loss is 8.436506411177106\n",
      "Steps:  95%|▉| 14293/15000 [2:03:19<02:08,  5.52it/s, lr=0.000965, step_loss=0.007/27/2023 19:48:09 - INFO - __main__ - train loss is 8.718051662785001\n",
      "Steps:  95%|▉| 14294/15000 [2:03:19<02:07,  5.53it/s, lr=0.000965, step_loss=0.207/27/2023 19:48:09 - INFO - __main__ - train loss is 8.724098043632694\n",
      "Steps:  95%|▉| 14295/15000 [2:03:19<02:07,  5.54it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:09 - INFO - __main__ - train loss is 9.357046561432071\n",
      "Steps:  95%|▉| 14296/15000 [2:03:19<02:08,  5.50it/s, lr=0.000964, step_loss=0.607/27/2023 19:48:09 - INFO - __main__ - train loss is 9.446141215157695\n",
      "Steps:  95%|▉| 14297/15000 [2:03:19<02:09,  5.44it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:09 - INFO - __main__ - train loss is 9.696723075699992\n",
      "Steps:  95%|▉| 14298/15000 [2:03:20<02:08,  5.46it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:10 - INFO - __main__ - train loss is 10.089702757191844\n",
      "Steps:  95%|▉| 14299/15000 [2:03:20<02:07,  5.49it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:10 - INFO - __main__ - train loss is 10.353494854760356\n",
      "Steps:  95%|▉| 14300/15000 [2:03:20<02:06,  5.52it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:10 - INFO - __main__ - train loss is 10.359175350167789\n",
      "Steps:  95%|▉| 14301/15000 [2:03:20<02:06,  5.53it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:10 - INFO - __main__ - train loss is 10.375249629491009\n",
      "Steps:  95%|▉| 14302/15000 [2:03:20<02:05,  5.54it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:10 - INFO - __main__ - train loss is 10.448417884879746\n",
      "Steps:  95%|▉| 14303/15000 [2:03:21<02:05,  5.55it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:10 - INFO - __main__ - train loss is 10.810134214931168\n",
      "Steps:  95%|▉| 14304/15000 [2:03:21<02:05,  5.56it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:11 - INFO - __main__ - train loss is 10.853612636798061\n",
      "Steps:  95%|▉| 14305/15000 [2:03:21<02:04,  5.56it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:11 - INFO - __main__ - train loss is 11.053981845849194\n",
      "Steps:  95%|▉| 14306/15000 [2:03:21<02:04,  5.56it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:11 - INFO - __main__ - train loss is 11.228921120637096\n",
      "Steps:  95%|▉| 14307/15000 [2:03:21<02:05,  5.53it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:11 - INFO - __main__ - train loss is 11.230542142759077\n",
      "Steps:  95%|▉| 14308/15000 [2:03:21<02:05,  5.52it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:11 - INFO - __main__ - train loss is 11.560605664621107\n",
      "Steps:  95%|▉| 14309/15000 [2:03:22<02:04,  5.53it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:12 - INFO - __main__ - train loss is 11.628629264305346\n",
      "Steps:  95%|▉| 14310/15000 [2:03:22<02:04,  5.54it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:12 - INFO - __main__ - train loss is 12.119625982712023\n",
      "Steps:  95%|▉| 14311/15000 [2:03:22<02:04,  5.55it/s, lr=0.000964, step_loss=0.407/27/2023 19:48:12 - INFO - __main__ - train loss is 12.129876457969658\n",
      "Steps:  95%|▉| 14312/15000 [2:03:22<02:03,  5.55it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:12 - INFO - __main__ - train loss is 12.132478798390366\n",
      "Steps:  95%|▉| 14313/15000 [2:03:22<02:04,  5.51it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:12 - INFO - __main__ - train loss is 12.21778677648399\n",
      "Steps:  95%|▉| 14314/15000 [2:03:23<02:05,  5.46it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:12 - INFO - __main__ - train loss is 12.328475447953679\n",
      "Steps:  95%|▉| 14315/15000 [2:03:23<02:06,  5.43it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:13 - INFO - __main__ - train loss is 12.379090073169209\n",
      "Steps:  95%|▉| 14316/15000 [2:03:23<02:06,  5.41it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:13 - INFO - __main__ - train loss is 13.022928299964406\n",
      "Steps:  95%|▉| 14317/15000 [2:03:23<02:06,  5.42it/s, lr=0.000964, step_loss=0.607/27/2023 19:48:13 - INFO - __main__ - train loss is 13.052681910456158\n",
      "Steps:  95%|▉| 14318/15000 [2:03:23<02:04,  5.47it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:13 - INFO - __main__ - train loss is 13.235179858864285\n",
      "Steps:  95%|▉| 14319/15000 [2:03:23<02:03,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:13 - INFO - __main__ - train loss is 13.278328495682217\n",
      "Steps:  95%|▉| 14320/15000 [2:03:24<02:03,  5.52it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:14 - INFO - __main__ - train loss is 13.534021990955807\n",
      "Steps:  95%|▉| 14321/15000 [2:03:24<02:02,  5.54it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:14 - INFO - __main__ - train loss is 13.90428711718414\n",
      "Steps:  95%|▉| 14322/15000 [2:03:24<02:02,  5.55it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:14 - INFO - __main__ - train loss is 13.90784079732839\n",
      "Steps:  95%|▉| 14323/15000 [2:03:24<02:01,  5.55it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:14 - INFO - __main__ - train loss is 13.937871753820218\n",
      "Steps:  95%|▉| 14324/15000 [2:03:24<02:01,  5.56it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:14 - INFO - __main__ - train loss is 13.939670331892557\n",
      "Steps:  96%|▉| 14325/15000 [2:03:25<02:01,  5.56it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:14 - INFO - __main__ - train loss is 14.02200553577859\n",
      "Steps:  96%|▉| 14326/15000 [2:03:25<02:01,  5.56it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:15 - INFO - __main__ - train loss is 14.065527245518751\n",
      "Steps:  96%|▉| 14327/15000 [2:03:25<02:00,  5.57it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:15 - INFO - __main__ - train loss is 14.15004532050807\n",
      "Steps:  96%|▉| 14328/15000 [2:03:25<02:00,  5.57it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:15 - INFO - __main__ - train loss is 14.219936616835184\n",
      "Steps:  96%|▉| 14329/15000 [2:03:25<02:01,  5.54it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:15 - INFO - __main__ - train loss is 14.400150843081065\n",
      "Steps:  96%|▉| 14330/15000 [2:03:25<02:00,  5.55it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:15 - INFO - __main__ - train loss is 14.425575200584717\n",
      "Steps:  96%|▉| 14331/15000 [2:03:26<02:01,  5.52it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:16 - INFO - __main__ - train loss is 14.529184524086304\n",
      "Steps:  96%|▉| 14332/15000 [2:03:26<02:01,  5.49it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:16 - INFO - __main__ - train loss is 14.540771472384222\n",
      "Steps:  96%|▉| 14333/15000 [2:03:26<02:01,  5.47it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:16 - INFO - __main__ - train loss is 14.543019444332458\n",
      "Steps:  96%|▉| 14334/15000 [2:03:26<02:01,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:16 - INFO - __main__ - train loss is 14.714133680448867\n",
      "Steps:  96%|▉| 14335/15000 [2:03:26<02:00,  5.52it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:16 - INFO - __main__ - train loss is 15.024692297563888\n",
      "Steps:  96%|▉| 14336/15000 [2:03:27<02:00,  5.53it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:16 - INFO - __main__ - train loss is 15.031276846886612\n",
      "Steps:  96%|▉| 14337/15000 [2:03:27<01:59,  5.54it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:17 - INFO - __main__ - train loss is 15.042512059793808\n",
      "Steps:  96%|▉| 14338/15000 [2:03:27<01:59,  5.53it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:17 - INFO - __main__ - train loss is 15.154817998991348\n",
      "Steps:  96%|▉| 14339/15000 [2:03:27<01:59,  5.52it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:17 - INFO - __main__ - train loss is 15.172700429917313\n",
      "Steps:  96%|▉| 14340/15000 [2:03:27<01:59,  5.52it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:17 - INFO - __main__ - train loss is 15.196759271086194\n",
      "Steps:  96%|▉| 14341/15000 [2:03:27<01:59,  5.51it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:17 - INFO - __main__ - train loss is 15.384754332364537\n",
      "Steps:  96%|▉| 14342/15000 [2:03:28<01:59,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:18 - INFO - __main__ - train loss is 15.387144527514465\n",
      "Steps:  96%|▉| 14343/15000 [2:03:28<01:59,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:18 - INFO - __main__ - train loss is 15.391481410828419\n",
      "Steps:  96%|▉| 14344/15000 [2:03:28<01:59,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:18 - INFO - __main__ - train loss is 15.480674225953408\n",
      "Steps:  96%|▉| 14345/15000 [2:03:28<01:59,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:18 - INFO - __main__ - train loss is 15.607480574515648\n",
      "Steps:  96%|▉| 14346/15000 [2:03:28<01:58,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:18 - INFO - __main__ - train loss is 15.840955693391152\n",
      "Steps:  96%|▉| 14347/15000 [2:03:29<01:58,  5.50it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:18 - INFO - __main__ - train loss is 15.850324438069947\n",
      "Steps:  96%|▉| 14348/15000 [2:03:29<01:58,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:19 - INFO - __main__ - train loss is 15.973404572461732\n",
      "Steps:  96%|▉| 14349/15000 [2:03:29<01:58,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:19 - INFO - __main__ - train loss is 16.569369838689454\n",
      "Steps:  96%|▉| 14350/15000 [2:03:29<01:58,  5.50it/s, lr=0.000964, step_loss=0.507/27/2023 19:48:19 - INFO - __main__ - train loss is 16.600051277433522\n",
      "Steps:  96%|▉| 14351/15000 [2:03:29<01:57,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:19 - INFO - __main__ - train loss is 16.82061695412267\n",
      "Steps:  96%|▉| 14352/15000 [2:03:29<01:57,  5.50it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:19 - INFO - __main__ - train loss is 17.014195599709637\n",
      "Steps:  96%|▉| 14353/15000 [2:03:30<01:57,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:20 - INFO - __main__ - train loss is 17.058781691943295\n",
      "Steps:  96%|▉| 14354/15000 [2:03:30<01:58,  5.45it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:20 - INFO - __main__ - train loss is 17.08538544655312\n",
      "Steps:  96%|▉| 14355/15000 [2:03:30<01:58,  5.46it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:20 - INFO - __main__ - train loss is 17.122795221512206\n",
      "Steps:  96%|▉| 14356/15000 [2:03:30<01:57,  5.47it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:20 - INFO - __main__ - train loss is 17.521399376098998\n",
      "Steps:  96%|▉| 14357/15000 [2:03:30<01:57,  5.48it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:20 - INFO - __main__ - train loss is 17.56437153473962\n",
      "Steps:  96%|▉| 14358/15000 [2:03:31<01:57,  5.49it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:20 - INFO - __main__ - train loss is 17.62437081814278\n",
      "Steps:  96%|▉| 14359/15000 [2:03:31<01:56,  5.49it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:21 - INFO - __main__ - train loss is 17.89766902208794\n",
      "Steps:  96%|▉| 14360/15000 [2:03:31<01:56,  5.49it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:21 - INFO - __main__ - train loss is 17.916118024964817\n",
      "Steps:  96%|▉| 14361/15000 [2:03:31<01:56,  5.49it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:21 - INFO - __main__ - train loss is 18.569188653607853\n",
      "Steps:  96%|▉| 14362/15000 [2:03:31<01:56,  5.49it/s, lr=0.000964, step_loss=0.607/27/2023 19:48:21 - INFO - __main__ - train loss is 18.673671989818104\n",
      "Steps:  96%|▉| 14363/15000 [2:03:31<01:55,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:21 - INFO - __main__ - train loss is 18.768858372350223\n",
      "Steps:  96%|▉| 14364/15000 [2:03:32<01:55,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:22 - INFO - __main__ - train loss is 18.77537950046826\n",
      "Steps:  96%|▉| 14365/15000 [2:03:32<01:55,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:22 - INFO - __main__ - train loss is 19.071823916514404\n",
      "Steps:  96%|▉| 14366/15000 [2:03:32<01:55,  5.50it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:22 - INFO - __main__ - train loss is 19.184957890887745\n",
      "Steps:  96%|▉| 14367/15000 [2:03:32<01:55,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:22 - INFO - __main__ - train loss is 19.20773724943865\n",
      "Steps:  96%|▉| 14368/15000 [2:03:32<01:54,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:22 - INFO - __main__ - train loss is 19.21296673931647\n",
      "Steps:  96%|▉| 14369/15000 [2:03:33<01:54,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:22 - INFO - __main__ - train loss is 19.474220632691868\n",
      "Steps:  96%|▉| 14370/15000 [2:03:33<01:54,  5.50it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:23 - INFO - __main__ - train loss is 19.824114143033512\n",
      "Steps:  96%|▉| 14371/15000 [2:03:33<01:54,  5.50it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:23 - INFO - __main__ - train loss is 19.9350636593299\n",
      "Steps:  96%|▉| 14372/15000 [2:03:33<01:54,  5.50it/s, lr=0.000964, step_loss=0.107/27/2023 19:48:23 - INFO - __main__ - train loss is 19.950126565177925\n",
      "Steps:  96%|▉| 14373/15000 [2:03:33<01:53,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:23 - INFO - __main__ - train loss is 19.954674477805384\n",
      "Steps:  96%|▉| 14374/15000 [2:03:33<01:53,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:23 - INFO - __main__ - train loss is 20.00560683303047\n",
      "Steps:  96%|▉| 14375/15000 [2:03:34<01:53,  5.50it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:24 - INFO - __main__ - train loss is 20.273658040096052\n",
      "Steps:  96%|▉| 14376/15000 [2:03:34<01:53,  5.52it/s, lr=0.000964, step_loss=0.207/27/2023 19:48:24 - INFO - __main__ - train loss is 20.277856433880515\n",
      "Steps:  96%|▉| 14377/15000 [2:03:34<01:52,  5.54it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:24 - INFO - __main__ - train loss is 20.362566711497493\n",
      "Steps:  96%|▉| 14378/15000 [2:03:34<01:52,  5.55it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:24 - INFO - __main__ - train loss is 20.665921570849605\n",
      "Steps:  96%|▉| 14379/15000 [2:03:34<01:51,  5.55it/s, lr=0.000964, step_loss=0.307/27/2023 19:48:24 - INFO - __main__ - train loss is 20.723295768839307\n",
      "Steps:  96%|▉| 14380/15000 [2:03:35<01:51,  5.56it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:24 - INFO - __main__ - train loss is 20.794597191852517\n",
      "Steps:  96%|▉| 14381/15000 [2:03:35<01:51,  5.56it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:25 - INFO - __main__ - train loss is 21.210087848943658\n",
      "Steps:  96%|▉| 14382/15000 [2:03:35<01:51,  5.57it/s, lr=0.000964, step_loss=0.407/27/2023 19:48:25 - INFO - __main__ - train loss is 21.234009759617038\n",
      "Steps:  96%|▉| 14383/15000 [2:03:35<01:50,  5.57it/s, lr=0.000964, step_loss=0.007/27/2023 19:48:25 - INFO - __main__ - train loss is 21.24414012779016\n",
      "Steps:  96%|▉| 14384/15000 [2:03:35<01:50,  5.57it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:25 - INFO - __main__ - train loss is 21.300686320406385\n",
      "Steps:  96%|▉| 14385/15000 [2:03:35<01:50,  5.57it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:25 - INFO - __main__ - train loss is 21.401614634436555\n",
      "Steps:  96%|▉| 14386/15000 [2:03:36<01:50,  5.57it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:25 - INFO - __main__ - train loss is 21.424011038732715\n",
      "Steps:  96%|▉| 14387/15000 [2:03:36<01:49,  5.58it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:26 - INFO - __main__ - train loss is 21.62793143291492\n",
      "Steps:  96%|▉| 14388/15000 [2:03:36<01:49,  5.57it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:26 - INFO - __main__ - train loss is 21.635297877830453\n",
      "Steps:  96%|▉| 14389/15000 [2:03:36<01:49,  5.57it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:26 - INFO - __main__ - train loss is 21.711789218825288\n",
      "Steps:  96%|▉| 14390/15000 [2:03:36<01:49,  5.57it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:26 - INFO - __main__ - train loss is 21.83955366734881\n",
      "Steps:  96%|▉| 14391/15000 [2:03:37<01:49,  5.57it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:26 - INFO - __main__ - train loss is 21.85963672224898\n",
      "Steps:  96%|▉| 14392/15000 [2:03:37<01:49,  5.57it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:27 - INFO - __main__ - train loss is 21.892046941560693\n",
      "Steps:  96%|▉| 14393/15000 [2:03:37<01:49,  5.57it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:27 - INFO - __main__ - train loss is 21.919992586714216\n",
      "Steps:  96%|▉| 14394/15000 [2:03:37<01:49,  5.52it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:27 - INFO - __main__ - train loss is 21.93709994305391\n",
      "Steps:  96%|▉| 14395/15000 [2:03:37<01:50,  5.48it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:27 - INFO - __main__ - train loss is 21.939510401920415\n",
      "Steps:  96%|▉| 14396/15000 [2:03:37<01:49,  5.50it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:27 - INFO - __main__ - train loss is 21.94062579877209\n",
      "Steps:  96%|▉| 14397/15000 [2:03:38<01:49,  5.50it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:27 - INFO - __main__ - train loss is 21.978295897017233\n",
      "Steps:  96%|▉| 14398/15000 [2:03:38<01:49,  5.48it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:28 - INFO - __main__ - train loss is 22.095157165895216\n",
      "Steps:  96%|▉| 14399/15000 [2:03:38<01:49,  5.48it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:28 - INFO - __main__ - train loss is 22.34707065380644\n",
      "Steps:  96%|▉| 14400/15000 [2:03:38<01:51,  5.40it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:28 - INFO - __main__ - train loss is 22.354278403217904\n",
      "Steps:  96%|▉| 14401/15000 [2:03:38<01:53,  5.30it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:28 - INFO - __main__ - train loss is 22.413602585787885\n",
      "Steps:  96%|▉| 14402/15000 [2:03:39<01:54,  5.24it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:28 - INFO - __main__ - train loss is 22.587295199627988\n",
      "Steps:  96%|▉| 14403/15000 [2:03:39<01:54,  5.20it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:29 - INFO - __main__ - train loss is 22.656429420108907\n",
      "Steps:  96%|▉| 14404/15000 [2:03:39<01:55,  5.18it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:29 - INFO - __main__ - train loss is 22.715386222000234\n",
      "Steps:  96%|▉| 14405/15000 [2:03:39<01:55,  5.16it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:29 - INFO - __main__ - train loss is 22.922711457009427\n",
      "Steps:  96%|▉| 14406/15000 [2:03:39<01:55,  5.15it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:29 - INFO - __main__ - train loss is 23.061722780461423\n",
      "Steps:  96%|▉| 14407/15000 [2:03:40<01:55,  5.13it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:29 - INFO - __main__ - train loss is 23.090626767720096\n",
      "Steps:  96%|▉| 14408/15000 [2:03:40<01:55,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:30 - INFO - __main__ - train loss is 23.647417298401706\n",
      "Steps:  96%|▉| 14409/15000 [2:03:40<01:55,  5.12it/s, lr=0.000963, step_loss=0.507/27/2023 19:48:30 - INFO - __main__ - train loss is 23.655957999522798\n",
      "Steps:  96%|▉| 14410/15000 [2:03:40<01:55,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:30 - INFO - __main__ - train loss is 23.706697969581\n",
      "Steps:  96%|▉| 14411/15000 [2:03:40<01:54,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:30 - INFO - __main__ - train loss is 24.163589744712226\n",
      "Steps:  96%|▉| 14412/15000 [2:03:41<01:54,  5.12it/s, lr=0.000963, step_loss=0.407/27/2023 19:48:30 - INFO - __main__ - train loss is 24.17195019579958\n",
      "Steps:  96%|▉| 14413/15000 [2:03:41<01:54,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:31 - INFO - __main__ - train loss is 24.445288990507834\n",
      "Steps:  96%|▉| 14414/15000 [2:03:41<01:54,  5.11it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:31 - INFO - __main__ - train loss is 24.741390650044195\n",
      "Steps:  96%|▉| 14415/15000 [2:03:41<01:54,  5.11it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:31 - INFO - __main__ - train loss is 24.782982424716465\n",
      "Steps:  96%|▉| 14416/15000 [2:03:41<01:54,  5.11it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:31 - INFO - __main__ - train loss is 25.12767432711553\n",
      "Steps:  96%|▉| 14417/15000 [2:03:42<01:54,  5.11it/s, lr=0.000963, step_loss=0.307/27/2023 19:48:31 - INFO - __main__ - train loss is 25.424785570125096\n",
      "Steps:  96%|▉| 14418/15000 [2:03:42<01:53,  5.12it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:32 - INFO - __main__ - train loss is 25.434097691322677\n",
      "Steps:  96%|▉| 14419/15000 [2:03:42<01:53,  5.11it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:32 - INFO - __main__ - train loss is 25.438909111428075\n",
      "Steps:  96%|▉| 14420/15000 [2:03:42<01:53,  5.11it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:32 - INFO - __main__ - train loss is 25.7249146978138\n",
      "Steps:  96%|▉| 14421/15000 [2:03:42<01:53,  5.12it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:32 - INFO - __main__ - train loss is 25.92647272150498\n",
      "Steps:  96%|▉| 14422/15000 [2:03:42<01:52,  5.12it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:32 - INFO - __main__ - train loss is 25.94663573789876\n",
      "Steps:  96%|▉| 14423/15000 [2:03:43<01:52,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:33 - INFO - __main__ - train loss is 25.949933009105735\n",
      "Steps:  96%|▉| 14424/15000 [2:03:43<01:52,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:33 - INFO - __main__ - train loss is 25.967482004198246\n",
      "Steps:  96%|▉| 14425/15000 [2:03:43<01:52,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:33 - INFO - __main__ - train loss is 26.756375703844242\n",
      "Steps:  96%|▉| 14426/15000 [2:03:43<01:52,  5.12it/s, lr=0.000963, step_loss=0.707/27/2023 19:48:33 - INFO - __main__ - train loss is 26.76114311988931\n",
      "Steps:  96%|▉| 14427/15000 [2:03:43<01:51,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:33 - INFO - __main__ - train loss is 26.768577134120278\n",
      "Steps:  96%|▉| 14428/15000 [2:03:44<01:51,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:34 - INFO - __main__ - train loss is 26.77042633027304\n",
      "Steps:  96%|▉| 14429/15000 [2:03:44<01:51,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:34 - INFO - __main__ - train loss is 26.78608933754731\n",
      "Steps:  96%|▉| 14430/15000 [2:03:44<01:49,  5.20it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:34 - INFO - __main__ - train loss is 26.8882513261633\n",
      "Steps:  96%|▉| 14431/15000 [2:03:44<01:49,  5.21it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:34 - INFO - __main__ - train loss is 27.419514975626953\n",
      "Steps:  96%|▉| 14432/15000 [2:03:44<01:49,  5.18it/s, lr=0.000963, step_loss=0.507/27/2023 19:48:34 - INFO - __main__ - train loss is 27.423236291506328\n",
      "Steps:  96%|▉| 14433/15000 [2:03:45<01:49,  5.16it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:34 - INFO - __main__ - train loss is 27.435475113452412\n",
      "Steps:  96%|▉| 14434/15000 [2:03:45<01:49,  5.15it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:35 - INFO - __main__ - train loss is 27.654103087843396\n",
      "Steps:  96%|▉| 14435/15000 [2:03:45<01:49,  5.14it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:35 - INFO - __main__ - train loss is 27.761267448426224\n",
      "Steps:  96%|▉| 14436/15000 [2:03:45<01:49,  5.13it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:35 - INFO - __main__ - train loss is 27.8228170449147\n",
      "Steps:  96%|▉| 14437/15000 [2:03:45<01:49,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:35 - INFO - __main__ - train loss is 27.840145858586766\n",
      "Steps:  96%|▉| 14438/15000 [2:03:46<01:49,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:35 - INFO - __main__ - train loss is 28.03628245240543\n",
      "Steps:  96%|▉| 14439/15000 [2:03:46<01:49,  5.12it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:36 - INFO - __main__ - train loss is 28.051589844399132\n",
      "Steps:  96%|▉| 14440/15000 [2:03:46<01:49,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:36 - INFO - __main__ - train loss is 28.3346013702685\n",
      "Steps:  96%|▉| 14441/15000 [2:03:46<01:49,  5.12it/s, lr=0.000963, step_loss=0.207/27/2023 19:48:36 - INFO - __main__ - train loss is 28.75179326313082\n",
      "Steps:  96%|▉| 14442/15000 [2:03:46<01:48,  5.12it/s, lr=0.000963, step_loss=0.407/27/2023 19:48:36 - INFO - __main__ - train loss is 28.79385459201876\n",
      "Steps:  96%|▉| 14443/15000 [2:03:47<01:48,  5.13it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:36 - INFO - __main__ - train loss is 28.898203579359688\n",
      "Steps:  96%|▉| 14444/15000 [2:03:47<01:48,  5.13it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:37 - INFO - __main__ - train loss is 29.014566493802704\n",
      "Steps:  96%|▉| 14445/15000 [2:03:47<01:48,  5.12it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:37 - INFO - __main__ - train loss is 29.020686374162324\n",
      "Steps:  96%|▉| 14446/15000 [2:03:47<01:48,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:37 - INFO - __main__ - train loss is 29.111166455899365\n",
      "Steps:  96%|▉| 14447/15000 [2:03:47<01:48,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:37 - INFO - __main__ - train loss is 29.114196282927878\n",
      "Steps:  96%|▉| 14448/15000 [2:03:48<01:47,  5.11it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:37 - INFO - __main__ - train loss is 29.118851807550527\n",
      "Steps:  96%|▉| 14449/15000 [2:03:48<01:47,  5.11it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:38 - INFO - __main__ - train loss is 29.143426640541293\n",
      "Steps:  96%|▉| 14450/15000 [2:03:48<01:47,  5.12it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:38 - INFO - __main__ - train loss is 29.222664392204024\n",
      "Steps:  96%|▉| 14451/15000 [2:03:48<01:45,  5.21it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:38 - INFO - __main__ - train loss is 29.539700722903945\n",
      "Steps:  96%|▉| 14452/15000 [2:03:48<01:44,  5.23it/s, lr=0.000963, step_loss=0.307/27/2023 19:48:38 - INFO - __main__ - train loss is 29.672568506211974\n",
      "Steps:  96%|▉| 14453/15000 [2:03:48<01:43,  5.27it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:38 - INFO - __main__ - train loss is 29.723881370038725\n",
      "Steps:  96%|▉| 14454/15000 [2:03:49<01:43,  5.26it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:39 - INFO - __main__ - train loss is 29.72556326969061\n",
      "Steps:  96%|▉| 14455/15000 [2:03:49<01:45,  5.18it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:39 - INFO - __main__ - train loss is 29.774616856710054\n",
      "Steps:  96%|▉| 14456/15000 [2:03:49<01:44,  5.23it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:39 - INFO - __main__ - train loss is 29.824926559464075\n",
      "Steps:  96%|▉| 14457/15000 [2:03:49<01:43,  5.23it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:39 - INFO - __main__ - train loss is 29.82827269344125\n",
      "Steps:  96%|▉| 14458/15000 [2:03:49<01:42,  5.27it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:39 - INFO - __main__ - train loss is 29.833090163418092\n",
      "Steps:  96%|▉| 14459/15000 [2:03:50<01:41,  5.35it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:39 - INFO - __main__ - train loss is 29.892781316884793\n",
      "Steps:  96%|▉| 14460/15000 [2:03:50<01:39,  5.42it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:40 - INFO - __main__ - train loss is 30.06004606152419\n",
      "Steps:  96%|▉| 14461/15000 [2:03:50<01:38,  5.46it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:40 - INFO - __main__ - train loss is 30.061758720781654\n",
      "Steps:  96%|▉| 14462/15000 [2:03:50<01:37,  5.49it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:40 - INFO - __main__ - train loss is 30.173386180307716\n",
      "Steps:  96%|▉| 14463/15000 [2:03:50<01:37,  5.52it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:40 - INFO - __main__ - train loss is 30.251406812574714\n",
      "Steps:  96%|▉| 14464/15000 [2:03:51<01:36,  5.53it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:40 - INFO - __main__ - train loss is 30.256420439109206\n",
      "Steps:  96%|▉| 14465/15000 [2:03:51<01:36,  5.55it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:41 - INFO - __main__ - train loss is 30.5608627256006\n",
      "Steps:  96%|▉| 14466/15000 [2:03:51<01:36,  5.56it/s, lr=0.000963, step_loss=0.307/27/2023 19:48:41 - INFO - __main__ - train loss is 30.606738282367587\n",
      "Steps:  96%|▉| 14467/15000 [2:03:51<01:35,  5.55it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:41 - INFO - __main__ - train loss is 30.661955991759896\n",
      "Steps:  96%|▉| 14468/15000 [2:03:51<01:35,  5.56it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:41 - INFO - __main__ - train loss is 30.66609873669222\n",
      "Steps:  96%|▉| 14469/15000 [2:03:51<01:35,  5.56it/s, lr=0.000963, step_loss=0.007/27/2023 19:48:41 - INFO - __main__ - train loss is 30.973495327401906\n",
      "Steps:  96%|▉| 14470/15000 [2:03:52<01:35,  5.56it/s, lr=0.000963, step_loss=0.307/27/2023 19:48:41 - INFO - __main__ - train loss is 31.084988214541227\n",
      "Steps:  96%|▉| 14471/15000 [2:03:52<01:35,  5.56it/s, lr=0.000963, step_loss=0.107/27/2023 19:48:42 - INFO - __main__ - train loss is 31.53946588234976\n",
      "Steps:  96%|▉| 14472/15000 [2:03:52<01:34,  5.57it/s, lr=0.000962, step_loss=0.407/27/2023 19:48:42 - INFO - __main__ - train loss is 31.550772244576365\n",
      "Steps:  96%|▉| 14473/15000 [2:03:52<01:34,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:42 - INFO - __main__ - train loss is 31.576323738787323\n",
      "Steps:  96%|▉| 14474/15000 [2:03:52<01:34,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:42 - INFO - __main__ - train loss is 31.745448848698288\n",
      "Steps:  96%|▉| 14475/15000 [2:03:52<01:34,  5.57it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:42 - INFO - __main__ - train loss is 31.89580552885309\n",
      "Steps:  97%|▉| 14476/15000 [2:03:53<01:34,  5.57it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:43 - INFO - __main__ - train loss is 31.897819066187367\n",
      "Steps:  97%|▉| 14477/15000 [2:03:53<01:33,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:43 - INFO - __main__ - train loss is 31.988148862263188\n",
      "Steps:  97%|▉| 14478/15000 [2:03:53<01:33,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:43 - INFO - __main__ - train loss is 32.0048972775694\n",
      "Steps:  97%|▉| 14479/15000 [2:03:53<01:33,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:43 - INFO - __main__ - train loss is 32.102306362008676\n",
      "Steps:  97%|▉| 14480/15000 [2:03:53<01:33,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:43 - INFO - __main__ - train loss is 32.570142950629815\n",
      "Steps:  97%|▉| 14481/15000 [2:03:54<01:33,  5.55it/s, lr=0.000962, step_loss=0.407/27/2023 19:48:43 - INFO - __main__ - train loss is 32.65638628206216\n",
      "Steps:  97%|▉| 14482/15000 [2:03:54<01:33,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:44 - INFO - __main__ - train loss is 32.774618591880426\n",
      "Steps:  97%|▉| 14483/15000 [2:03:54<01:33,  5.56it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:44 - INFO - __main__ - train loss is 32.801984997233376\n",
      "Steps:  97%|▉| 14484/15000 [2:03:54<01:32,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:44 - INFO - __main__ - train loss is 32.928358586272225\n",
      "Steps:  97%|▉| 14485/15000 [2:03:54<01:32,  5.56it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:44 - INFO - __main__ - train loss is 33.2795046584215\n",
      "Steps:  97%|▉| 14486/15000 [2:03:54<01:32,  5.56it/s, lr=0.000962, step_loss=0.307/27/2023 19:48:44 - INFO - __main__ - train loss is 33.55879202648066\n",
      "Steps:  97%|▉| 14487/15000 [2:03:55<01:32,  5.56it/s, lr=0.000962, step_loss=0.207/27/2023 19:48:45 - INFO - __main__ - train loss is 33.56387144769542\n",
      "Steps:  97%|▉| 14488/15000 [2:03:55<01:32,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:45 - INFO - __main__ - train loss is 33.85424629296176\n",
      "Steps:  97%|▉| 14489/15000 [2:03:55<01:31,  5.56it/s, lr=0.000962, step_loss=0.207/27/2023 19:48:45 - INFO - __main__ - train loss is 33.88676992501132\n",
      "Steps:  97%|▉| 14490/15000 [2:03:55<01:32,  5.52it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:45 - INFO - __main__ - train loss is 33.942776386393234\n",
      "Steps:  97%|▉| 14491/15000 [2:03:55<01:32,  5.53it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:45 - INFO - __main__ - train loss is 34.04904388333671\n",
      "Steps:  97%|▉| 14492/15000 [2:03:56<01:31,  5.54it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:45 - INFO - __main__ - train loss is 34.39152788068168\n",
      "Steps:  97%|▉| 14493/15000 [2:03:56<01:31,  5.55it/s, lr=0.000962, step_loss=0.307/27/2023 19:48:46 - INFO - __main__ - train loss is 34.39464070391841\n",
      "Steps:  97%|▉| 14494/15000 [2:03:56<01:31,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:46 - INFO - __main__ - train loss is 34.51566398632713\n",
      "Steps:  97%|▉| 14495/15000 [2:03:56<01:30,  5.56it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:46 - INFO - __main__ - train loss is 34.58541007828899\n",
      "Steps:  97%|▉| 14496/15000 [2:03:56<01:30,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:46 - INFO - __main__ - train loss is 34.70314215612598\n",
      "Steps:  97%|▉| 14497/15000 [2:03:56<01:30,  5.56it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:46 - INFO - __main__ - train loss is 34.78975628805347\n",
      "Steps:  97%|▉| 14498/15000 [2:03:57<01:30,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:47 - INFO - __main__ - train loss is 35.148117353441194\n",
      "Steps:  97%|▉| 14499/15000 [2:03:57<01:30,  5.57it/s, lr=0.000962, step_loss=0.307/27/2023 19:48:47 - INFO - __main__ - train loss is 35.96885227155872\n",
      "Steps:  97%|▉| 14500/15000 [2:03:57<01:29,  5.57it/s, lr=0.000962, step_loss=0.307/27/2023 19:48:47 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-14500\n",
      "07/27/2023 19:48:47 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:48:47,274] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:48:47,279] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-14500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:48:47,279] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-14500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:48:47,285] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-14500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:48:47,285] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-14500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:48:47,292] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-14500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:48:47,292] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-14500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:48:47,292] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:48:47 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-14500/pytorch_model\n",
      "07/27/2023 19:48:47 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-14500/scheduler.bin\n",
      "07/27/2023 19:48:47 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-14500/random_states_0.pkl\n",
      "07/27/2023 19:48:47 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-14500\n",
      "Steps:  97%|▉| 14500/15000 [2:03:57<01:29,  5.57it/s, lr=0.000962, step_loss=0.807/27/2023 19:48:47 - INFO - __main__ - train loss is 35.97965540760197\n",
      "Steps:  97%|▉| 14501/15000 [2:03:57<01:33,  5.36it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:47 - INFO - __main__ - train loss is 36.26843532198109\n",
      "Steps:  97%|▉| 14502/15000 [2:03:57<01:32,  5.37it/s, lr=0.000962, step_loss=0.207/27/2023 19:48:47 - INFO - __main__ - train loss is 36.27595850848593\n",
      "Steps:  97%|▉| 14503/15000 [2:03:58<01:32,  5.38it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:47 - INFO - __main__ - train loss is 36.76510062837042\n",
      "Steps:  97%|▉| 14504/15000 [2:03:58<01:31,  5.43it/s, lr=0.000962, step_loss=0.407/27/2023 19:48:48 - INFO - __main__ - train loss is 36.77549232193269\n",
      "Steps:  97%|▉| 14505/15000 [2:03:58<01:30,  5.47it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:48 - INFO - __main__ - train loss is 37.32840461679734\n",
      "Steps:  97%|▉| 14506/15000 [2:03:58<01:29,  5.50it/s, lr=0.000962, step_loss=0.507/27/2023 19:48:48 - INFO - __main__ - train loss is 37.659017097437754\n",
      "Steps:  97%|▉| 14507/15000 [2:03:58<01:29,  5.52it/s, lr=0.000962, step_loss=0.307/27/2023 19:48:48 - INFO - __main__ - train loss is 37.74512351700105\n",
      "Steps:  97%|▉| 14508/15000 [2:03:58<01:28,  5.54it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:48 - INFO - __main__ - train loss is 37.751192902447656\n",
      "Steps:  97%|▉| 14509/15000 [2:03:59<01:28,  5.55it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:49 - INFO - __main__ - train loss is 37.766741580562666\n",
      "Steps:  97%|▉| 14510/15000 [2:03:59<01:28,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:49 - INFO - __main__ - train loss is 38.068532712059096\n",
      "Steps:  97%|▉| 14511/15000 [2:03:59<01:27,  5.56it/s, lr=0.000962, step_loss=0.307/27/2023 19:48:49 - INFO - __main__ - train loss is 38.18519282271154\n",
      "Steps:  97%|▉| 14512/15000 [2:03:59<01:27,  5.56it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:49 - INFO - __main__ - train loss is 38.42923864652403\n",
      "Steps:  97%|▉| 14513/15000 [2:03:59<01:27,  5.56it/s, lr=0.000962, step_loss=0.207/27/2023 19:48:49 - INFO - __main__ - train loss is 38.46934054349549\n",
      "Steps:  97%|▉| 14514/15000 [2:04:00<01:27,  5.55it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:49 - INFO - __main__ - train loss is 38.5300405502785\n",
      "Steps:  97%|▉| 14515/15000 [2:04:00<01:27,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:50 - INFO - __main__ - train loss is 38.994006145047024\n",
      "Steps:  97%|▉| 14516/15000 [2:04:00<01:27,  5.56it/s, lr=0.000962, step_loss=0.407/27/2023 19:48:50 - INFO - __main__ - train loss is 39.03587935795076\n",
      "Steps:  97%|▉| 14517/15000 [2:04:00<01:26,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:50 - INFO - __main__ - train loss is 39.04280324303545\n",
      "Steps:  97%|▉| 14518/15000 [2:04:00<01:26,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:50 - INFO - __main__ - train loss is 39.12461543106474\n",
      "Steps:  97%|▉| 14519/15000 [2:04:00<01:26,  5.56it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:50 - INFO - __main__ - train loss is 39.139998864615336\n",
      "Steps:  97%|▉| 14520/15000 [2:04:01<01:26,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:50 - INFO - __main__ - train loss is 39.26647895225324\n",
      "Steps:  97%|▉| 14521/15000 [2:04:01<01:26,  5.57it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:51 - INFO - __main__ - train loss is 39.39431696780957\n",
      "Steps:  97%|▉| 14522/15000 [2:04:01<01:25,  5.57it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:51 - INFO - __main__ - train loss is 39.527223106706515\n",
      "Steps:  97%|▉| 14523/15000 [2:04:01<01:25,  5.57it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:51 - INFO - __main__ - train loss is 39.53308523562737\n",
      "Steps:  97%|▉| 14524/15000 [2:04:01<01:25,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:51 - INFO - __main__ - train loss is 40.063873001607135\n",
      "Steps:  97%|▉| 14525/15000 [2:04:02<01:25,  5.57it/s, lr=0.000962, step_loss=0.507/27/2023 19:48:51 - INFO - __main__ - train loss is 40.07979908888228\n",
      "Steps:  97%|▉| 14526/15000 [2:04:02<01:25,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:52 - INFO - __main__ - train loss is 40.12407825817354\n",
      "Steps:  97%|▉| 14527/15000 [2:04:02<01:24,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:52 - INFO - __main__ - train loss is 40.36324784089811\n",
      "Steps:  97%|▉| 14528/15000 [2:04:02<01:24,  5.57it/s, lr=0.000962, step_loss=0.207/27/2023 19:48:52 - INFO - __main__ - train loss is 40.450663595693186\n",
      "Steps:  97%|▉| 14529/15000 [2:04:02<01:24,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:52 - INFO - __main__ - train loss is 40.59685856034048\n",
      "Steps:  97%|▉| 14530/15000 [2:04:02<01:24,  5.58it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:52 - INFO - __main__ - train loss is 40.92053121258505\n",
      "Steps:  97%|▉| 14531/15000 [2:04:03<01:24,  5.58it/s, lr=0.000962, step_loss=0.307/27/2023 19:48:52 - INFO - __main__ - train loss is 40.93355678138323\n",
      "Steps:  97%|▉| 14532/15000 [2:04:03<01:23,  5.58it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:53 - INFO - __main__ - train loss is 41.00416060653515\n",
      "Steps:  97%|▉| 14533/15000 [2:04:03<01:23,  5.57it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:53 - INFO - __main__ - train loss is 41.499528968008235\n",
      "Steps:  97%|▉| 14534/15000 [2:04:03<01:23,  5.58it/s, lr=0.000962, step_loss=0.407/27/2023 19:48:53 - INFO - __main__ - train loss is 41.501441195607185\n",
      "Steps:  97%|▉| 14535/15000 [2:04:03<01:23,  5.58it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:53 - INFO - __main__ - train loss is 41.7359823435545\n",
      "Steps:  97%|▉| 14536/15000 [2:04:03<01:23,  5.58it/s, lr=0.000962, step_loss=0.207/27/2023 19:48:53 - INFO - __main__ - train loss is 42.56836287677288\n",
      "Steps:  97%|▉| 14537/15000 [2:04:04<01:22,  5.58it/s, lr=0.000962, step_loss=0.807/27/2023 19:48:54 - INFO - __main__ - train loss is 42.717114463448524\n",
      "Steps:  97%|▉| 14538/15000 [2:04:04<01:22,  5.58it/s, lr=0.000962, step_loss=0.107/27/2023 19:48:54 - INFO - __main__ - train loss is 42.726187931373715\n",
      "Steps:  97%|▉| 14539/15000 [2:04:04<01:22,  5.58it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:54 - INFO - __main__ - train loss is 42.729399306699634\n",
      "Steps:  97%|▉| 14540/15000 [2:04:04<01:22,  5.58it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:54 - INFO - __main__ - train loss is 42.73377599194646\n",
      "Steps:  97%|▉| 14541/15000 [2:04:04<01:22,  5.58it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:54 - INFO - __main__ - train loss is 43.25841661170125\n",
      "Steps:  97%|▉| 14542/15000 [2:04:05<01:22,  5.58it/s, lr=0.000962, step_loss=0.507/27/2023 19:48:54 - INFO - __main__ - train loss is 43.26182486838661\n",
      "Steps:  97%|▉| 14543/15000 [2:04:05<01:21,  5.58it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:55 - INFO - __main__ - train loss is 43.266164812026545\n",
      "Steps:  97%|▉| 14544/15000 [2:04:05<01:53,  4.02it/s, lr=0.000962, step_loss=0.007/27/2023 19:48:56 - INFO - __main__ - Per validation step average loss is 0.09578800201416016\n",
      "07/27/2023 19:48:56 - INFO - __main__ - Cumulative validation average loss is 0.09578800201416016\n",
      "07/27/2023 19:48:56 - INFO - __main__ - Per validation step average loss is 0.1401819884777069\n",
      "07/27/2023 19:48:56 - INFO - __main__ - Cumulative validation average loss is 0.23596999049186707\n",
      "07/27/2023 19:48:57 - INFO - __main__ - Per validation step average loss is 0.17792460322380066\n",
      "07/27/2023 19:48:57 - INFO - __main__ - Cumulative validation average loss is 0.4138945937156677\n",
      "07/27/2023 19:48:57 - INFO - __main__ - Per validation step average loss is 0.3080906569957733\n",
      "07/27/2023 19:48:57 - INFO - __main__ - Cumulative validation average loss is 0.721985250711441\n",
      "07/27/2023 19:48:58 - INFO - __main__ - Per validation step average loss is 0.17267799377441406\n",
      "07/27/2023 19:48:58 - INFO - __main__ - Cumulative validation average loss is 0.8946632444858551\n",
      "07/27/2023 19:48:58 - INFO - __main__ - Per validation step average loss is 0.029864851385354996\n",
      "07/27/2023 19:48:58 - INFO - __main__ - Cumulative validation average loss is 0.9245280958712101\n",
      "07/27/2023 19:48:58 - INFO - __main__ - Per validation step average loss is 0.09099230170249939\n",
      "07/27/2023 19:48:58 - INFO - __main__ - Cumulative validation average loss is 1.0155203975737095\n",
      "07/27/2023 19:48:59 - INFO - __main__ - Per validation step average loss is 0.07941783219575882\n",
      "07/27/2023 19:48:59 - INFO - __main__ - Cumulative validation average loss is 1.0949382297694683\n",
      "07/27/2023 19:48:59 - INFO - __main__ - Per validation step average loss is 0.001401146175339818\n",
      "07/27/2023 19:48:59 - INFO - __main__ - Cumulative validation average loss is 1.0963393759448081\n",
      "07/27/2023 19:49:00 - INFO - __main__ - Per validation step average loss is 0.007927758619189262\n",
      "07/27/2023 19:49:00 - INFO - __main__ - Cumulative validation average loss is 1.1042671345639974\n",
      "07/27/2023 19:49:00 - INFO - __main__ - Per validation step average loss is 0.041099295020103455\n",
      "07/27/2023 19:49:00 - INFO - __main__ - Cumulative validation average loss is 1.1453664295841008\n",
      "07/27/2023 19:49:00 - INFO - __main__ - Per validation step average loss is 0.024659333750605583\n",
      "07/27/2023 19:49:00 - INFO - __main__ - Cumulative validation average loss is 1.1700257633347064\n",
      "07/27/2023 19:49:01 - INFO - __main__ - Per validation step average loss is 0.0014538501854985952\n",
      "07/27/2023 19:49:01 - INFO - __main__ - Cumulative validation average loss is 1.171479613520205\n",
      "07/27/2023 19:49:01 - INFO - __main__ - Per validation step average loss is 0.18858855962753296\n",
      "07/27/2023 19:49:01 - INFO - __main__ - Cumulative validation average loss is 1.360068173147738\n",
      "07/27/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.46699026226997375\n",
      "07/27/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 1.8270584354177117\n",
      "07/27/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.19155533611774445\n",
      "07/27/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 2.018613771535456\n",
      "07/27/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.11451461166143417\n",
      "07/27/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 2.1331283831968904\n",
      "07/27/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.10012701153755188\n",
      "07/27/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 2.2332553947344422\n",
      "07/27/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.06771451234817505\n",
      "07/27/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 2.3009699070826173\n",
      "07/27/2023 19:49:04 - INFO - __main__ - Per validation step average loss is 0.032999634742736816\n",
      "07/27/2023 19:49:04 - INFO - __main__ - Cumulative validation average loss is 2.333969541825354\n",
      "07/27/2023 19:49:04 - INFO - __main__ - Per validation step average loss is 0.0036604267079383135\n",
      "07/27/2023 19:49:04 - INFO - __main__ - Cumulative validation average loss is 2.3376299685332924\n",
      "07/27/2023 19:49:05 - INFO - __main__ - Per validation step average loss is 0.4976028501987457\n",
      "07/27/2023 19:49:05 - INFO - __main__ - Cumulative validation average loss is 2.835232818732038\n",
      "07/27/2023 19:49:05 - INFO - __main__ - Per validation step average loss is 0.021716225892305374\n",
      "07/27/2023 19:49:05 - INFO - __main__ - Cumulative validation average loss is 2.8569490446243435\n",
      "07/27/2023 19:49:05 - INFO - __main__ - Per validation step average loss is 0.027331531047821045\n",
      "07/27/2023 19:49:05 - INFO - __main__ - Cumulative validation average loss is 2.8842805756721646\n",
      "07/27/2023 19:49:06 - INFO - __main__ - Per validation step average loss is 0.009203222580254078\n",
      "07/27/2023 19:49:06 - INFO - __main__ - Cumulative validation average loss is 2.8934837982524186\n",
      "07/27/2023 19:49:06 - INFO - __main__ - Per validation step average loss is 0.005588497035205364\n",
      "07/27/2023 19:49:06 - INFO - __main__ - Cumulative validation average loss is 2.899072295287624\n",
      "07/27/2023 19:49:07 - INFO - __main__ - Per validation step average loss is 0.018533483147621155\n",
      "07/27/2023 19:49:07 - INFO - __main__ - Cumulative validation average loss is 2.917605778435245\n",
      "07/27/2023 19:49:07 - INFO - __main__ - Per validation step average loss is 0.09042821824550629\n",
      "07/27/2023 19:49:07 - INFO - __main__ - Cumulative validation average loss is 3.0080339966807514\n",
      "07/27/2023 19:49:08 - INFO - __main__ - Per validation step average loss is 0.009258033707737923\n",
      "07/27/2023 19:49:08 - INFO - __main__ - Cumulative validation average loss is 3.0172920303884894\n",
      "07/27/2023 19:49:08 - INFO - __main__ - Per validation step average loss is 0.2505190372467041\n",
      "07/27/2023 19:49:08 - INFO - __main__ - Cumulative validation average loss is 3.2678110676351935\n",
      "07/27/2023 19:49:08 - INFO - __main__ - Per validation step average loss is 0.2923498749732971\n",
      "07/27/2023 19:49:08 - INFO - __main__ - Cumulative validation average loss is 3.5601609426084906\n",
      "07/27/2023 19:49:09 - INFO - __main__ - Per validation step average loss is 0.001000146265141666\n",
      "07/27/2023 19:49:09 - INFO - __main__ - Cumulative validation average loss is 3.5611610888736323\n",
      "07/27/2023 19:49:09 - INFO - __main__ - Per validation step average loss is 0.08041287958621979\n",
      "07/27/2023 19:49:09 - INFO - __main__ - Cumulative validation average loss is 3.641573968459852\n",
      "07/27/2023 19:49:10 - INFO - __main__ - Per validation step average loss is 0.1443071812391281\n",
      "07/27/2023 19:49:10 - INFO - __main__ - Cumulative validation average loss is 3.78588114969898\n",
      "07/27/2023 19:49:10 - INFO - __main__ - Per validation step average loss is 0.15263062715530396\n",
      "07/27/2023 19:49:10 - INFO - __main__ - Cumulative validation average loss is 3.938511776854284\n",
      "07/27/2023 19:49:10 - INFO - __main__ - Per validation step average loss is 0.018482979387044907\n",
      "07/27/2023 19:49:10 - INFO - __main__ - Cumulative validation average loss is 3.956994756241329\n",
      "07/27/2023 19:49:11 - INFO - __main__ - Per validation step average loss is 0.01879609376192093\n",
      "07/27/2023 19:49:11 - INFO - __main__ - Cumulative validation average loss is 3.97579085000325\n",
      "07/27/2023 19:49:11 - INFO - __main__ - Per validation step average loss is 0.3272532820701599\n",
      "07/27/2023 19:49:11 - INFO - __main__ - Cumulative validation average loss is 4.30304413207341\n",
      "07/27/2023 19:49:12 - INFO - __main__ - Per validation step average loss is 0.19841966032981873\n",
      "07/27/2023 19:49:12 - INFO - __main__ - Cumulative validation average loss is 4.501463792403229\n",
      "07/27/2023 19:49:12 - INFO - __main__ - Per validation step average loss is 0.09680995345115662\n",
      "07/27/2023 19:49:12 - INFO - __main__ - Cumulative validation average loss is 4.598273745854385\n",
      "07/27/2023 19:49:13 - INFO - __main__ - Per validation step average loss is 0.3837657570838928\n",
      "07/27/2023 19:49:13 - INFO - __main__ - Cumulative validation average loss is 4.982039502938278\n",
      "07/27/2023 19:49:13 - INFO - __main__ - Per validation step average loss is 0.005167184863239527\n",
      "07/27/2023 19:49:13 - INFO - __main__ - Cumulative validation average loss is 4.9872066878015175\n",
      "07/27/2023 19:49:13 - INFO - __main__ - Per validation step average loss is 0.2994535565376282\n",
      "07/27/2023 19:49:13 - INFO - __main__ - Cumulative validation average loss is 5.286660244339146\n",
      "07/27/2023 19:49:14 - INFO - __main__ - Per validation step average loss is 0.05974934995174408\n",
      "07/27/2023 19:49:14 - INFO - __main__ - Cumulative validation average loss is 5.34640959429089\n",
      "07/27/2023 19:49:14 - INFO - __main__ - Per validation step average loss is 0.08317792415618896\n",
      "07/27/2023 19:49:14 - INFO - __main__ - Cumulative validation average loss is 5.429587518447079\n",
      "07/27/2023 19:49:15 - INFO - __main__ - Per validation step average loss is 0.006880349945276976\n",
      "07/27/2023 19:49:15 - INFO - __main__ - Cumulative validation average loss is 5.436467868392356\n",
      "07/27/2023 19:49:15 - INFO - __main__ - Per validation step average loss is 0.27963656187057495\n",
      "07/27/2023 19:49:15 - INFO - __main__ - Cumulative validation average loss is 5.716104430262931\n",
      "07/27/2023 19:49:15 - INFO - __main__ - Per validation step average loss is 0.05312830209732056\n",
      "07/27/2023 19:49:15 - INFO - __main__ - Cumulative validation average loss is 5.769232732360251\n",
      "07/27/2023 19:49:16 - INFO - __main__ - Per validation step average loss is 0.4542359709739685\n",
      "07/27/2023 19:49:16 - INFO - __main__ - Cumulative validation average loss is 6.22346870333422\n",
      "07/27/2023 19:49:16 - INFO - __main__ - Per validation step average loss is 0.00991527084261179\n",
      "07/27/2023 19:49:16 - INFO - __main__ - Cumulative validation average loss is 6.2333839741768315\n",
      "07/27/2023 19:49:17 - INFO - __main__ - Per validation step average loss is 0.10735419392585754\n",
      "07/27/2023 19:49:17 - INFO - __main__ - Cumulative validation average loss is 6.340738168102689\n",
      "07/27/2023 19:49:17 - INFO - __main__ - Per validation step average loss is 0.18706291913986206\n",
      "07/27/2023 19:49:17 - INFO - __main__ - Cumulative validation average loss is 6.527801087242551\n",
      "07/27/2023 19:49:18 - INFO - __main__ - Per validation step average loss is 0.0326957069337368\n",
      "07/27/2023 19:49:18 - INFO - __main__ - Cumulative validation average loss is 6.560496794176288\n",
      "07/27/2023 19:49:18 - INFO - __main__ - Per validation step average loss is 0.003713345155119896\n",
      "07/27/2023 19:49:18 - INFO - __main__ - Cumulative validation average loss is 6.564210139331408\n",
      "07/27/2023 19:49:18 - INFO - __main__ - Per validation step average loss is 0.1941787451505661\n",
      "07/27/2023 19:49:18 - INFO - __main__ - Cumulative validation average loss is 6.758388884481974\n",
      "07/27/2023 19:49:19 - INFO - __main__ - Per validation step average loss is 0.0627879798412323\n",
      "07/27/2023 19:49:19 - INFO - __main__ - Cumulative validation average loss is 6.821176864323206\n",
      "07/27/2023 19:49:19 - INFO - __main__ - Per validation step average loss is 0.022831907495856285\n",
      "07/27/2023 19:49:19 - INFO - __main__ - Cumulative validation average loss is 6.8440087718190625\n",
      "07/27/2023 19:49:20 - INFO - __main__ - Per validation step average loss is 0.009475862607359886\n",
      "07/27/2023 19:49:20 - INFO - __main__ - Cumulative validation average loss is 6.853484634426422\n",
      "07/27/2023 19:49:20 - INFO - __main__ - Per validation step average loss is 0.010119416750967503\n",
      "07/27/2023 19:49:20 - INFO - __main__ - Cumulative validation average loss is 6.86360405117739\n",
      "07/27/2023 19:49:21 - INFO - __main__ - Per validation step average loss is 0.06575809419155121\n",
      "07/27/2023 19:49:21 - INFO - __main__ - Cumulative validation average loss is 6.929362145368941\n",
      "07/27/2023 19:49:21 - INFO - __main__ - Per validation step average loss is 0.019127171486616135\n",
      "07/27/2023 19:49:21 - INFO - __main__ - Cumulative validation average loss is 6.948489316855557\n",
      "07/27/2023 19:49:21 - INFO - __main__ - Per validation step average loss is 0.2845672369003296\n",
      "07/27/2023 19:49:21 - INFO - __main__ - Cumulative validation average loss is 7.233056553755887\n",
      "07/27/2023 19:49:22 - INFO - __main__ - Per validation step average loss is 0.1737259030342102\n",
      "07/27/2023 19:49:22 - INFO - __main__ - Cumulative validation average loss is 7.406782456790097\n",
      "07/27/2023 19:49:22 - INFO - __main__ - Per validation step average loss is 0.21665823459625244\n",
      "07/27/2023 19:49:22 - INFO - __main__ - Cumulative validation average loss is 7.6234406913863495\n",
      "07/27/2023 19:49:23 - INFO - __main__ - Per validation step average loss is 0.2783797085285187\n",
      "07/27/2023 19:49:23 - INFO - __main__ - Cumulative validation average loss is 7.901820399914868\n",
      "07/27/2023 19:49:23 - INFO - __main__ - Per validation step average loss is 0.001320339972153306\n",
      "07/27/2023 19:49:23 - INFO - __main__ - Cumulative validation average loss is 7.9031407398870215\n",
      "07/27/2023 19:49:23 - INFO - __main__ - Per validation step average loss is 0.04770880192518234\n",
      "07/27/2023 19:49:23 - INFO - __main__ - Cumulative validation average loss is 7.950849541812204\n",
      "07/27/2023 19:49:24 - INFO - __main__ - Per validation step average loss is 0.003469314193353057\n",
      "07/27/2023 19:49:24 - INFO - __main__ - Cumulative validation average loss is 7.954318856005557\n",
      "07/27/2023 19:49:24 - INFO - __main__ - Per validation step average loss is 0.4128691554069519\n",
      "07/27/2023 19:49:24 - INFO - __main__ - Cumulative validation average loss is 8.367188011412509\n",
      "07/27/2023 19:49:25 - INFO - __main__ - Per validation step average loss is 0.004327371716499329\n",
      "07/27/2023 19:49:25 - INFO - __main__ - Cumulative validation average loss is 8.371515383129008\n",
      "07/27/2023 19:49:25 - INFO - __main__ - Per validation step average loss is 0.2852223515510559\n",
      "07/27/2023 19:49:25 - INFO - __main__ - Cumulative validation average loss is 8.656737734680064\n",
      "07/27/2023 19:49:26 - INFO - __main__ - Per validation step average loss is 0.0013125695986673236\n",
      "07/27/2023 19:49:26 - INFO - __main__ - Cumulative validation average loss is 8.658050304278731\n",
      "07/27/2023 19:49:26 - INFO - __main__ - Per validation step average loss is 0.22900906205177307\n",
      "07/27/2023 19:49:26 - INFO - __main__ - Cumulative validation average loss is 8.887059366330504\n",
      "07/27/2023 19:49:26 - INFO - __main__ - Per validation step average loss is 0.07175609469413757\n",
      "07/27/2023 19:49:26 - INFO - __main__ - Cumulative validation average loss is 8.958815461024642\n",
      "07/27/2023 19:49:27 - INFO - __main__ - Per validation step average loss is 0.057043712586164474\n",
      "07/27/2023 19:49:27 - INFO - __main__ - Cumulative validation average loss is 9.015859173610806\n",
      "07/27/2023 19:49:27 - INFO - __main__ - Per validation step average loss is 0.3606104850769043\n",
      "07/27/2023 19:49:27 - INFO - __main__ - Cumulative validation average loss is 9.37646965868771\n",
      "07/27/2023 19:49:28 - INFO - __main__ - Per validation step average loss is 0.009724853560328484\n",
      "07/27/2023 19:49:28 - INFO - __main__ - Cumulative validation average loss is 9.38619451224804\n",
      "07/27/2023 19:49:28 - INFO - __main__ - Per validation step average loss is 0.33116042613983154\n",
      "07/27/2023 19:49:28 - INFO - __main__ - Cumulative validation average loss is 9.71735493838787\n",
      "07/27/2023 19:49:29 - INFO - __main__ - Per validation step average loss is 0.002546871080994606\n",
      "07/27/2023 19:49:29 - INFO - __main__ - Cumulative validation average loss is 9.719901809468865\n",
      "07/27/2023 19:49:29 - INFO - __main__ - Average validation loss for Epoch 47 is 0.12303673176542868\n",
      "07/27/2023 19:49:29 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:50:26 - INFO - __main__ - Starting epoch 48\n",
      "07/27/2023 19:50:27 - INFO - __main__ - train loss is 0.010027661919593811\n",
      "Steps:  97%|▉| 14545/15000 [2:05:37<3:30:29, 27.76s/it, lr=0.000962, step_loss=007/27/2023 19:50:27 - INFO - __main__ - train loss is 0.28344036638736725\n",
      "Steps:  97%|▉| 14546/15000 [2:05:37<2:27:25, 19.48s/it, lr=0.000962, step_loss=007/27/2023 19:50:27 - INFO - __main__ - train loss is 0.5753352493047714\n",
      "Steps:  97%|▉| 14547/15000 [2:05:37<1:43:23, 13.69s/it, lr=0.000962, step_loss=007/27/2023 19:50:27 - INFO - __main__ - train loss is 0.7008086740970612\n",
      "Steps:  97%|▉| 14548/15000 [2:05:38<1:12:39,  9.65s/it, lr=0.000962, step_loss=007/27/2023 19:50:28 - INFO - __main__ - train loss is 0.8565382957458496\n",
      "Steps:  97%|▉| 14549/15000 [2:05:38<51:11,  6.81s/it, lr=0.000962, step_loss=0.107/27/2023 19:50:28 - INFO - __main__ - train loss is 1.1544255912303925\n",
      "Steps:  97%|▉| 14550/15000 [2:05:38<36:11,  4.83s/it, lr=0.000962, step_loss=0.207/27/2023 19:50:28 - INFO - __main__ - train loss is 1.1579806790687144\n",
      "Steps:  97%|▉| 14551/15000 [2:05:38<25:41,  3.43s/it, lr=0.000962, step_loss=0.007/27/2023 19:50:28 - INFO - __main__ - train loss is 1.5071948752738535\n",
      "Steps:  97%|▉| 14552/15000 [2:05:38<18:20,  2.46s/it, lr=0.000962, step_loss=0.307/27/2023 19:50:28 - INFO - __main__ - train loss is 1.5093300566077232\n",
      "Steps:  97%|▉| 14553/15000 [2:05:39<13:12,  1.77s/it, lr=0.000962, step_loss=0.007/27/2023 19:50:28 - INFO - __main__ - train loss is 1.7911614701151848\n",
      "Steps:  97%|▉| 14554/15000 [2:05:39<09:37,  1.30s/it, lr=0.000962, step_loss=0.207/27/2023 19:50:29 - INFO - __main__ - train loss is 1.7974629965610802\n",
      "Steps:  97%|▉| 14555/15000 [2:05:39<07:07,  1.04it/s, lr=0.000962, step_loss=0.007/27/2023 19:50:29 - INFO - __main__ - train loss is 1.912890222389251\n",
      "Steps:  97%|▉| 14556/15000 [2:05:39<05:22,  1.38it/s, lr=0.000962, step_loss=0.107/27/2023 19:50:29 - INFO - __main__ - train loss is 1.917090734001249\n",
      "Steps:  97%|▉| 14557/15000 [2:05:39<04:09,  1.78it/s, lr=0.000962, step_loss=0.007/27/2023 19:50:29 - INFO - __main__ - train loss is 2.0768046877346933\n",
      "Steps:  97%|▉| 14558/15000 [2:05:39<03:17,  2.23it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:29 - INFO - __main__ - train loss is 2.345825721975416\n",
      "Steps:  97%|▉| 14559/15000 [2:05:40<02:41,  2.72it/s, lr=0.000961, step_loss=0.207/27/2023 19:50:30 - INFO - __main__ - train loss is 2.38615964865312\n",
      "Steps:  97%|▉| 14560/15000 [2:05:40<02:16,  3.22it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:30 - INFO - __main__ - train loss is 2.718846758361906\n",
      "Steps:  97%|▉| 14561/15000 [2:05:40<01:59,  3.68it/s, lr=0.000961, step_loss=0.307/27/2023 19:50:30 - INFO - __main__ - train loss is 2.9311048886738718\n",
      "Steps:  97%|▉| 14562/15000 [2:05:40<01:46,  4.10it/s, lr=0.000961, step_loss=0.207/27/2023 19:50:30 - INFO - __main__ - train loss is 2.9362919107079506\n",
      "Steps:  97%|▉| 14563/15000 [2:05:40<01:38,  4.45it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:30 - INFO - __main__ - train loss is 3.5715745463967323\n",
      "Steps:  97%|▉| 14564/15000 [2:05:41<01:32,  4.73it/s, lr=0.000961, step_loss=0.607/27/2023 19:50:30 - INFO - __main__ - train loss is 3.7215723916888237\n",
      "Steps:  97%|▉| 14565/15000 [2:05:41<01:27,  4.95it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:31 - INFO - __main__ - train loss is 3.7235154774971306\n",
      "Steps:  97%|▉| 14566/15000 [2:05:41<01:24,  5.12it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:31 - INFO - __main__ - train loss is 3.744048297870904\n",
      "Steps:  97%|▉| 14567/15000 [2:05:41<01:22,  5.24it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:31 - INFO - __main__ - train loss is 3.816470437217504\n",
      "Steps:  97%|▉| 14568/15000 [2:05:41<01:21,  5.33it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:31 - INFO - __main__ - train loss is 3.832112089265138\n",
      "Steps:  97%|▉| 14569/15000 [2:05:41<01:19,  5.39it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:31 - INFO - __main__ - train loss is 3.9447333817370236\n",
      "Steps:  97%|▉| 14570/15000 [2:05:42<01:19,  5.44it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:32 - INFO - __main__ - train loss is 4.823978424537927\n",
      "Steps:  97%|▉| 14571/15000 [2:05:42<01:18,  5.47it/s, lr=0.000961, step_loss=0.807/27/2023 19:50:32 - INFO - __main__ - train loss is 4.87008296744898\n",
      "Steps:  97%|▉| 14572/15000 [2:05:42<01:17,  5.50it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:32 - INFO - __main__ - train loss is 5.04830949800089\n",
      "Steps:  97%|▉| 14573/15000 [2:05:42<01:17,  5.52it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:32 - INFO - __main__ - train loss is 5.158879645634443\n",
      "Steps:  97%|▉| 14574/15000 [2:05:42<01:17,  5.49it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:32 - INFO - __main__ - train loss is 5.235702746082097\n",
      "Steps:  97%|▉| 14575/15000 [2:05:43<01:17,  5.47it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:32 - INFO - __main__ - train loss is 5.806750409770757\n",
      "Steps:  97%|▉| 14576/15000 [2:05:43<01:17,  5.49it/s, lr=0.000961, step_loss=0.507/27/2023 19:50:33 - INFO - __main__ - train loss is 5.958875917363912\n",
      "Steps:  97%|▉| 14577/15000 [2:05:43<01:16,  5.51it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:33 - INFO - __main__ - train loss is 5.993609425146133\n",
      "Steps:  97%|▉| 14578/15000 [2:05:43<01:16,  5.53it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:33 - INFO - __main__ - train loss is 5.994787471368909\n",
      "Steps:  97%|▉| 14579/15000 [2:05:43<01:16,  5.52it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:33 - INFO - __main__ - train loss is 6.10557028837502\n",
      "Steps:  97%|▉| 14580/15000 [2:05:43<01:15,  5.53it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:33 - INFO - __main__ - train loss is 6.84461590833962\n",
      "Steps:  97%|▉| 14581/15000 [2:05:44<01:15,  5.54it/s, lr=0.000961, step_loss=0.707/27/2023 19:50:34 - INFO - __main__ - train loss is 7.120441289618611\n",
      "Steps:  97%|▉| 14582/15000 [2:05:44<01:15,  5.54it/s, lr=0.000961, step_loss=0.207/27/2023 19:50:34 - INFO - __main__ - train loss is 7.153206115588546\n",
      "Steps:  97%|▉| 14583/15000 [2:05:44<01:15,  5.50it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:34 - INFO - __main__ - train loss is 7.268180249258876\n",
      "Steps:  97%|▉| 14584/15000 [2:05:44<01:16,  5.47it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:34 - INFO - __main__ - train loss is 7.305408461019397\n",
      "Steps:  97%|▉| 14585/15000 [2:05:44<01:15,  5.48it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:34 - INFO - __main__ - train loss is 7.827486677095294\n",
      "Steps:  97%|▉| 14586/15000 [2:05:45<01:15,  5.48it/s, lr=0.000961, step_loss=0.507/27/2023 19:50:34 - INFO - __main__ - train loss is 7.863822435960174\n",
      "Steps:  97%|▉| 14587/15000 [2:05:45<01:15,  5.48it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:35 - INFO - __main__ - train loss is 7.872169018723071\n",
      "Steps:  97%|▉| 14588/15000 [2:05:45<01:15,  5.47it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:35 - INFO - __main__ - train loss is 7.926158976741135\n",
      "Steps:  97%|▉| 14589/15000 [2:05:45<01:15,  5.44it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:35 - INFO - __main__ - train loss is 8.02562012989074\n",
      "Steps:  97%|▉| 14590/15000 [2:05:45<01:14,  5.47it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:35 - INFO - __main__ - train loss is 8.040136857889593\n",
      "Steps:  97%|▉| 14591/15000 [2:05:45<01:14,  5.50it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:35 - INFO - __main__ - train loss is 8.041687403572723\n",
      "Steps:  97%|▉| 14592/15000 [2:05:46<01:14,  5.49it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:36 - INFO - __main__ - train loss is 8.125880268169567\n",
      "Steps:  97%|▉| 14593/15000 [2:05:46<01:13,  5.51it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:36 - INFO - __main__ - train loss is 8.278899040771648\n",
      "Steps:  97%|▉| 14594/15000 [2:05:46<01:13,  5.53it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:36 - INFO - __main__ - train loss is 8.639792767120525\n",
      "Steps:  97%|▉| 14595/15000 [2:05:46<01:13,  5.49it/s, lr=0.000961, step_loss=0.307/27/2023 19:50:36 - INFO - __main__ - train loss is 8.979618993354961\n",
      "Steps:  97%|▉| 14596/15000 [2:05:46<01:13,  5.51it/s, lr=0.000961, step_loss=0.307/27/2023 19:50:36 - INFO - __main__ - train loss is 9.210552599979565\n",
      "Steps:  97%|▉| 14597/15000 [2:05:47<01:12,  5.52it/s, lr=0.000961, step_loss=0.207/27/2023 19:50:36 - INFO - __main__ - train loss is 9.275865976465866\n",
      "Steps:  97%|▉| 14598/15000 [2:05:47<01:12,  5.53it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:37 - INFO - __main__ - train loss is 9.300898431567475\n",
      "Steps:  97%|▉| 14599/15000 [2:05:47<01:12,  5.54it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:37 - INFO - __main__ - train loss is 9.352400588570163\n",
      "Steps:  97%|▉| 14600/15000 [2:05:47<01:12,  5.54it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:37 - INFO - __main__ - train loss is 9.379675063071772\n",
      "Steps:  97%|▉| 14601/15000 [2:05:47<01:12,  5.53it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:37 - INFO - __main__ - train loss is 9.385793160414323\n",
      "Steps:  97%|▉| 14602/15000 [2:05:47<01:11,  5.54it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:37 - INFO - __main__ - train loss is 9.400647638132796\n",
      "Steps:  97%|▉| 14603/15000 [2:05:48<01:11,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:38 - INFO - __main__ - train loss is 9.464069021632895\n",
      "Steps:  97%|▉| 14604/15000 [2:05:48<01:11,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:38 - INFO - __main__ - train loss is 9.468330629402772\n",
      "Steps:  97%|▉| 14605/15000 [2:05:48<01:11,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:38 - INFO - __main__ - train loss is 9.480432484531775\n",
      "Steps:  97%|▉| 14606/15000 [2:05:48<01:10,  5.56it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:38 - INFO - __main__ - train loss is 9.624229166889563\n",
      "Steps:  97%|▉| 14607/15000 [2:05:48<01:10,  5.56it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:38 - INFO - __main__ - train loss is 9.717667181277648\n",
      "Steps:  97%|▉| 14608/15000 [2:05:49<01:10,  5.56it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:38 - INFO - __main__ - train loss is 9.951647985959426\n",
      "Steps:  97%|▉| 14609/15000 [2:05:49<01:10,  5.56it/s, lr=0.000961, step_loss=0.207/27/2023 19:50:39 - INFO - __main__ - train loss is 10.118486125255004\n",
      "Steps:  97%|▉| 14610/15000 [2:05:49<01:10,  5.55it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:39 - INFO - __main__ - train loss is 10.143443176755682\n",
      "Steps:  97%|▉| 14611/15000 [2:05:49<01:10,  5.52it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:39 - INFO - __main__ - train loss is 10.183944339165464\n",
      "Steps:  97%|▉| 14612/15000 [2:05:49<01:10,  5.54it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:39 - INFO - __main__ - train loss is 10.192445443244651\n",
      "Steps:  97%|▉| 14613/15000 [2:05:49<01:09,  5.54it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:39 - INFO - __main__ - train loss is 10.208508023293689\n",
      "Steps:  97%|▉| 14614/15000 [2:05:50<01:09,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:39 - INFO - __main__ - train loss is 10.221042264485732\n",
      "Steps:  97%|▉| 14615/15000 [2:05:50<01:09,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:40 - INFO - __main__ - train loss is 10.247288072714582\n",
      "Steps:  97%|▉| 14616/15000 [2:05:50<01:09,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:40 - INFO - __main__ - train loss is 10.257392147788778\n",
      "Steps:  97%|▉| 14617/15000 [2:05:50<01:08,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:40 - INFO - __main__ - train loss is 10.261164533207193\n",
      "Steps:  97%|▉| 14618/15000 [2:05:50<01:08,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:40 - INFO - __main__ - train loss is 10.518058704445139\n",
      "Steps:  97%|▉| 14619/15000 [2:05:51<01:09,  5.51it/s, lr=0.000961, step_loss=0.207/27/2023 19:50:40 - INFO - __main__ - train loss is 10.542396256932989\n",
      "Steps:  97%|▉| 14620/15000 [2:05:51<01:08,  5.53it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:41 - INFO - __main__ - train loss is 11.335651764879003\n",
      "Steps:  97%|▉| 14621/15000 [2:05:51<01:08,  5.54it/s, lr=0.000961, step_loss=0.707/27/2023 19:50:41 - INFO - __main__ - train loss is 11.339120395015925\n",
      "Steps:  97%|▉| 14622/15000 [2:05:51<01:08,  5.54it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:41 - INFO - __main__ - train loss is 11.405285648535937\n",
      "Steps:  97%|▉| 14623/15000 [2:05:51<01:07,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:41 - INFO - __main__ - train loss is 11.411231345962733\n",
      "Steps:  97%|▉| 14624/15000 [2:05:51<01:07,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:41 - INFO - __main__ - train loss is 11.430574897211045\n",
      "Steps:  98%|▉| 14625/15000 [2:05:52<01:07,  5.55it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:41 - INFO - __main__ - train loss is 11.79940566746518\n",
      "Steps:  98%|▉| 14626/15000 [2:05:52<01:07,  5.55it/s, lr=0.000961, step_loss=0.307/27/2023 19:50:42 - INFO - __main__ - train loss is 12.112283203285187\n",
      "Steps:  98%|▉| 14627/15000 [2:05:52<01:07,  5.56it/s, lr=0.000961, step_loss=0.307/27/2023 19:50:42 - INFO - __main__ - train loss is 12.114351489115506\n",
      "Steps:  98%|▉| 14628/15000 [2:05:52<01:06,  5.56it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:42 - INFO - __main__ - train loss is 12.122438186313957\n",
      "Steps:  98%|▉| 14629/15000 [2:05:52<01:06,  5.56it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:42 - INFO - __main__ - train loss is 12.127299802843481\n",
      "Steps:  98%|▉| 14630/15000 [2:05:53<01:06,  5.56it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:42 - INFO - __main__ - train loss is 12.21249599987641\n",
      "Steps:  98%|▉| 14631/15000 [2:05:53<01:06,  5.56it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:43 - INFO - __main__ - train loss is 12.280905494932085\n",
      "Steps:  98%|▉| 14632/15000 [2:05:53<01:06,  5.56it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:43 - INFO - __main__ - train loss is 12.35692940140143\n",
      "Steps:  98%|▉| 14633/15000 [2:05:53<01:06,  5.52it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:43 - INFO - __main__ - train loss is 12.397467488888651\n",
      "Steps:  98%|▉| 14634/15000 [2:05:53<01:06,  5.49it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:43 - INFO - __main__ - train loss is 12.403780167922378\n",
      "Steps:  98%|▉| 14635/15000 [2:05:53<01:06,  5.45it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:43 - INFO - __main__ - train loss is 12.529950520023704\n",
      "Steps:  98%|▉| 14636/15000 [2:05:54<01:07,  5.41it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:43 - INFO - __main__ - train loss is 12.575084386393428\n",
      "Steps:  98%|▉| 14637/15000 [2:05:54<01:06,  5.46it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:44 - INFO - __main__ - train loss is 12.630661251023412\n",
      "Steps:  98%|▉| 14638/15000 [2:05:54<01:06,  5.44it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:44 - INFO - __main__ - train loss is 12.63227981782984\n",
      "Steps:  98%|▉| 14639/15000 [2:05:54<01:05,  5.48it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:44 - INFO - __main__ - train loss is 12.78485922969412\n",
      "Steps:  98%|▉| 14640/15000 [2:05:54<01:05,  5.51it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:44 - INFO - __main__ - train loss is 12.805000039632432\n",
      "Steps:  98%|▉| 14641/15000 [2:05:55<01:05,  5.52it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:44 - INFO - __main__ - train loss is 12.944849687512033\n",
      "Steps:  98%|▉| 14642/15000 [2:05:55<01:05,  5.49it/s, lr=0.000961, step_loss=0.107/27/2023 19:50:45 - INFO - __main__ - train loss is 12.988429783727042\n",
      "Steps:  98%|▉| 14643/15000 [2:05:55<01:05,  5.47it/s, lr=0.000961, step_loss=0.007/27/2023 19:50:45 - INFO - __main__ - train loss is 13.138053743983619\n",
      "Steps:  98%|▉| 14644/15000 [2:05:55<01:04,  5.49it/s, lr=0.00096, step_loss=0.1507/27/2023 19:50:45 - INFO - __main__ - train loss is 13.757994740153663\n",
      "[2023-07-27 19:50:45,517] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  98%|▉| 14645/15000 [2:05:55<01:04,  5.51it/s, lr=0.00096, step_loss=0.6207/27/2023 19:50:45 - INFO - __main__ - train loss is 14.138448505545966\n",
      "Steps:  98%|▉| 14646/15000 [2:05:55<01:04,  5.51it/s, lr=0.00096, step_loss=0.3807/27/2023 19:50:45 - INFO - __main__ - train loss is 14.201957537676208\n",
      "Steps:  98%|▉| 14647/15000 [2:05:56<01:04,  5.49it/s, lr=0.00096, step_loss=0.0607/27/2023 19:50:45 - INFO - __main__ - train loss is 14.259198292042129\n",
      "Steps:  98%|▉| 14648/15000 [2:05:56<01:03,  5.51it/s, lr=0.00096, step_loss=0.0507/27/2023 19:50:46 - INFO - __main__ - train loss is 14.843922122265212\n",
      "Steps:  98%|▉| 14649/15000 [2:05:56<01:03,  5.52it/s, lr=0.00096, step_loss=0.5807/27/2023 19:50:46 - INFO - __main__ - train loss is 14.84659885277506\n",
      "Steps:  98%|▉| 14650/15000 [2:05:56<01:03,  5.53it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:46 - INFO - __main__ - train loss is 14.977665651938878\n",
      "Steps:  98%|▉| 14651/15000 [2:05:56<01:03,  5.54it/s, lr=0.00096, step_loss=0.1307/27/2023 19:50:46 - INFO - __main__ - train loss is 15.101343077025376\n",
      "Steps:  98%|▉| 14652/15000 [2:05:57<01:02,  5.54it/s, lr=0.00096, step_loss=0.1207/27/2023 19:50:46 - INFO - __main__ - train loss is 15.537366371951066\n",
      "Steps:  98%|▉| 14653/15000 [2:05:57<01:02,  5.55it/s, lr=0.00096, step_loss=0.4307/27/2023 19:50:47 - INFO - __main__ - train loss is 15.609705414972268\n",
      "Steps:  98%|▉| 14654/15000 [2:05:57<01:02,  5.55it/s, lr=0.00096, step_loss=0.0707/27/2023 19:50:47 - INFO - __main__ - train loss is 15.619734907872044\n",
      "Steps:  98%|▉| 14655/15000 [2:05:57<01:02,  5.55it/s, lr=0.00096, step_loss=0.0107/27/2023 19:50:47 - INFO - __main__ - train loss is 15.701265791780315\n",
      "Steps:  98%|▉| 14656/15000 [2:05:57<01:01,  5.55it/s, lr=0.00096, step_loss=0.0807/27/2023 19:50:47 - INFO - __main__ - train loss is 15.883408436900936\n",
      "Steps:  98%|▉| 14657/15000 [2:05:57<01:01,  5.55it/s, lr=0.00096, step_loss=0.1807/27/2023 19:50:47 - INFO - __main__ - train loss is 15.885588247678243\n",
      "Steps:  98%|▉| 14658/15000 [2:05:58<01:01,  5.56it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:47 - INFO - __main__ - train loss is 15.909772722399794\n",
      "Steps:  98%|▉| 14659/15000 [2:05:58<01:01,  5.54it/s, lr=0.00096, step_loss=0.0207/27/2023 19:50:48 - INFO - __main__ - train loss is 15.932054259232245\n",
      "Steps:  98%|▉| 14660/15000 [2:05:58<01:01,  5.55it/s, lr=0.00096, step_loss=0.0207/27/2023 19:50:48 - INFO - __main__ - train loss is 15.935682402574457\n",
      "Steps:  98%|▉| 14661/15000 [2:05:58<01:01,  5.55it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:48 - INFO - __main__ - train loss is 15.942173113231547\n",
      "Steps:  98%|▉| 14662/15000 [2:05:58<01:00,  5.55it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:48 - INFO - __main__ - train loss is 16.36486582935322\n",
      "Steps:  98%|▉| 14663/15000 [2:05:58<01:00,  5.55it/s, lr=0.00096, step_loss=0.4207/27/2023 19:50:48 - INFO - __main__ - train loss is 16.470274862949736\n",
      "Steps:  98%|▉| 14664/15000 [2:05:59<01:00,  5.55it/s, lr=0.00096, step_loss=0.1007/27/2023 19:50:49 - INFO - __main__ - train loss is 16.475320697412826\n",
      "Steps:  98%|▉| 14665/15000 [2:05:59<01:00,  5.56it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:49 - INFO - __main__ - train loss is 16.48359470779542\n",
      "Steps:  98%|▉| 14666/15000 [2:05:59<01:00,  5.54it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:49 - INFO - __main__ - train loss is 16.491240893141367\n",
      "Steps:  98%|▉| 14667/15000 [2:05:59<01:00,  5.54it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:49 - INFO - __main__ - train loss is 16.546057519153692\n",
      "Steps:  98%|▉| 14668/15000 [2:05:59<00:59,  5.55it/s, lr=0.00096, step_loss=0.0507/27/2023 19:50:49 - INFO - __main__ - train loss is 16.718690720037557\n",
      "Steps:  98%|▉| 14669/15000 [2:06:00<00:59,  5.55it/s, lr=0.00096, step_loss=0.1707/27/2023 19:50:49 - INFO - __main__ - train loss is 16.728989931405522\n",
      "Steps:  98%|▉| 14670/15000 [2:06:00<00:59,  5.55it/s, lr=0.00096, step_loss=0.0107/27/2023 19:50:50 - INFO - __main__ - train loss is 16.762052072794177\n",
      "Steps:  98%|▉| 14671/15000 [2:06:00<00:59,  5.55it/s, lr=0.00096, step_loss=0.0307/27/2023 19:50:50 - INFO - __main__ - train loss is 16.78820493130479\n",
      "Steps:  98%|▉| 14672/15000 [2:06:00<00:59,  5.55it/s, lr=0.00096, step_loss=0.0207/27/2023 19:50:50 - INFO - __main__ - train loss is 16.993846320197918\n",
      "Steps:  98%|▉| 14673/15000 [2:06:00<00:58,  5.55it/s, lr=0.00096, step_loss=0.2007/27/2023 19:50:50 - INFO - __main__ - train loss is 17.25763716606889\n",
      "Steps:  98%|▉| 14674/15000 [2:06:00<00:58,  5.56it/s, lr=0.00096, step_loss=0.2607/27/2023 19:50:50 - INFO - __main__ - train loss is 17.266143330023624\n",
      "Steps:  98%|▉| 14675/15000 [2:06:01<00:59,  5.51it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:51 - INFO - __main__ - train loss is 17.267631580703892\n",
      "Steps:  98%|▉| 14676/15000 [2:06:01<00:58,  5.51it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:51 - INFO - __main__ - train loss is 17.31796122121159\n",
      "Steps:  98%|▉| 14677/15000 [2:06:01<00:58,  5.52it/s, lr=0.00096, step_loss=0.0507/27/2023 19:50:51 - INFO - __main__ - train loss is 17.331280423910357\n",
      "Steps:  98%|▉| 14678/15000 [2:06:01<00:58,  5.54it/s, lr=0.00096, step_loss=0.0107/27/2023 19:50:51 - INFO - __main__ - train loss is 17.33454046805855\n",
      "Steps:  98%|▉| 14679/15000 [2:06:01<00:57,  5.55it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:51 - INFO - __main__ - train loss is 17.465933274826966\n",
      "Steps:  98%|▉| 14680/15000 [2:06:02<00:57,  5.55it/s, lr=0.00096, step_loss=0.1307/27/2023 19:50:51 - INFO - __main__ - train loss is 17.566994738182984\n",
      "Steps:  98%|▉| 14681/15000 [2:06:02<00:57,  5.56it/s, lr=0.00096, step_loss=0.1007/27/2023 19:50:52 - INFO - __main__ - train loss is 17.570230072014965\n",
      "Steps:  98%|▉| 14682/15000 [2:06:02<00:57,  5.56it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:52 - INFO - __main__ - train loss is 17.73824930714909\n",
      "Steps:  98%|▉| 14683/15000 [2:06:02<00:57,  5.56it/s, lr=0.00096, step_loss=0.1607/27/2023 19:50:52 - INFO - __main__ - train loss is 17.772114658378996\n",
      "Steps:  98%|▉| 14684/15000 [2:06:02<00:56,  5.56it/s, lr=0.00096, step_loss=0.0307/27/2023 19:50:52 - INFO - __main__ - train loss is 17.775786243961193\n",
      "Steps:  98%|▉| 14685/15000 [2:06:02<00:56,  5.55it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:52 - INFO - __main__ - train loss is 17.884299405501224\n",
      "Steps:  98%|▉| 14686/15000 [2:06:03<00:56,  5.56it/s, lr=0.00096, step_loss=0.1007/27/2023 19:50:53 - INFO - __main__ - train loss is 17.899407316581346\n",
      "Steps:  98%|▉| 14687/15000 [2:06:03<00:56,  5.56it/s, lr=0.00096, step_loss=0.0107/27/2023 19:50:53 - INFO - __main__ - train loss is 17.90325494168792\n",
      "Steps:  98%|▉| 14688/15000 [2:06:03<00:56,  5.53it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:53 - INFO - __main__ - train loss is 18.00318849144969\n",
      "Steps:  98%|▉| 14689/15000 [2:06:03<00:56,  5.52it/s, lr=0.00096, step_loss=0.0907/27/2023 19:50:53 - INFO - __main__ - train loss is 18.088093579397537\n",
      "Steps:  98%|▉| 14690/15000 [2:06:03<00:56,  5.53it/s, lr=0.00096, step_loss=0.0807/27/2023 19:50:53 - INFO - __main__ - train loss is 18.669690192327835\n",
      "Steps:  98%|▉| 14691/15000 [2:06:04<00:55,  5.54it/s, lr=0.00096, step_loss=0.5807/27/2023 19:50:53 - INFO - __main__ - train loss is 18.831753031001426\n",
      "Steps:  98%|▉| 14692/15000 [2:06:04<00:55,  5.54it/s, lr=0.00096, step_loss=0.1607/27/2023 19:50:54 - INFO - __main__ - train loss is 18.875799045548774\n",
      "Steps:  98%|▉| 14693/15000 [2:06:04<00:55,  5.54it/s, lr=0.00096, step_loss=0.0407/27/2023 19:50:54 - INFO - __main__ - train loss is 19.017390892491676\n",
      "Steps:  98%|▉| 14694/15000 [2:06:04<00:55,  5.51it/s, lr=0.00096, step_loss=0.1407/27/2023 19:50:54 - INFO - __main__ - train loss is 19.423120871768333\n",
      "Steps:  98%|▉| 14695/15000 [2:06:04<00:55,  5.47it/s, lr=0.00096, step_loss=0.4007/27/2023 19:50:54 - INFO - __main__ - train loss is 19.486866951570846\n",
      "Steps:  98%|▉| 14696/15000 [2:06:04<00:56,  5.43it/s, lr=0.00096, step_loss=0.0607/27/2023 19:50:54 - INFO - __main__ - train loss is 19.529318929300644\n",
      "Steps:  98%|▉| 14697/15000 [2:06:05<00:55,  5.44it/s, lr=0.00096, step_loss=0.0407/27/2023 19:50:55 - INFO - __main__ - train loss is 19.57131519226823\n",
      "Steps:  98%|▉| 14698/15000 [2:06:05<00:55,  5.47it/s, lr=0.00096, step_loss=0.0407/27/2023 19:50:55 - INFO - __main__ - train loss is 19.593298059538938\n",
      "Steps:  98%|▉| 14699/15000 [2:06:05<00:54,  5.50it/s, lr=0.00096, step_loss=0.0207/27/2023 19:50:55 - INFO - __main__ - train loss is 19.663426276878454\n",
      "Steps:  98%|▉| 14700/15000 [2:06:05<00:54,  5.51it/s, lr=0.00096, step_loss=0.0707/27/2023 19:50:55 - INFO - __main__ - train loss is 19.669425885309465\n",
      "Steps:  98%|▉| 14701/15000 [2:06:05<00:54,  5.53it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:55 - INFO - __main__ - train loss is 20.049956361879595\n",
      "Steps:  98%|▉| 14702/15000 [2:06:06<00:53,  5.54it/s, lr=0.00096, step_loss=0.3807/27/2023 19:50:55 - INFO - __main__ - train loss is 20.19431356631685\n",
      "Steps:  98%|▉| 14703/15000 [2:06:06<00:53,  5.55it/s, lr=0.00096, step_loss=0.1407/27/2023 19:50:56 - INFO - __main__ - train loss is 20.216365791042335\n",
      "Steps:  98%|▉| 14704/15000 [2:06:06<00:53,  5.55it/s, lr=0.00096, step_loss=0.0207/27/2023 19:50:56 - INFO - __main__ - train loss is 20.510194040019996\n",
      "Steps:  98%|▉| 14705/15000 [2:06:06<00:53,  5.56it/s, lr=0.00096, step_loss=0.2907/27/2023 19:50:56 - INFO - __main__ - train loss is 20.709535560687073\n",
      "Steps:  98%|▉| 14706/15000 [2:06:06<00:52,  5.56it/s, lr=0.00096, step_loss=0.1907/27/2023 19:50:56 - INFO - __main__ - train loss is 20.84288560517598\n",
      "Steps:  98%|▉| 14707/15000 [2:06:06<00:52,  5.56it/s, lr=0.00096, step_loss=0.1307/27/2023 19:50:56 - INFO - __main__ - train loss is 20.92880003817845\n",
      "Steps:  98%|▉| 14708/15000 [2:06:07<00:52,  5.52it/s, lr=0.00096, step_loss=0.0807/27/2023 19:50:56 - INFO - __main__ - train loss is 20.935705769457854\n",
      "Steps:  98%|▉| 14709/15000 [2:06:07<00:53,  5.48it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:57 - INFO - __main__ - train loss is 20.939151605241932\n",
      "Steps:  98%|▉| 14710/15000 [2:06:07<00:53,  5.44it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:57 - INFO - __main__ - train loss is 20.961132788681425\n",
      "Steps:  98%|▉| 14711/15000 [2:06:07<00:52,  5.46it/s, lr=0.00096, step_loss=0.0207/27/2023 19:50:57 - INFO - __main__ - train loss is 21.016042975359596\n",
      "Steps:  98%|▉| 14712/15000 [2:06:07<00:52,  5.45it/s, lr=0.00096, step_loss=0.0507/27/2023 19:50:57 - INFO - __main__ - train loss is 21.31418728607241\n",
      "Steps:  98%|▉| 14713/15000 [2:06:08<00:52,  5.44it/s, lr=0.00096, step_loss=0.2907/27/2023 19:50:57 - INFO - __main__ - train loss is 21.345402376377024\n",
      "Steps:  98%|▉| 14714/15000 [2:06:08<00:52,  5.42it/s, lr=0.00096, step_loss=0.0307/27/2023 19:50:58 - INFO - __main__ - train loss is 21.41461443307344\n",
      "Steps:  98%|▉| 14715/15000 [2:06:08<00:52,  5.45it/s, lr=0.00096, step_loss=0.0607/27/2023 19:50:58 - INFO - __main__ - train loss is 21.423540904768743\n",
      "Steps:  98%|▉| 14716/15000 [2:06:08<00:51,  5.48it/s, lr=0.00096, step_loss=0.0007/27/2023 19:50:58 - INFO - __main__ - train loss is 21.546283281990327\n",
      "Steps:  98%|▉| 14717/15000 [2:06:08<00:51,  5.49it/s, lr=0.00096, step_loss=0.1207/27/2023 19:50:58 - INFO - __main__ - train loss is 21.63442283833865\n",
      "Steps:  98%|▉| 14718/15000 [2:06:08<00:51,  5.50it/s, lr=0.00096, step_loss=0.0807/27/2023 19:50:58 - INFO - __main__ - train loss is 21.77450126374606\n",
      "Steps:  98%|▉| 14719/15000 [2:06:09<00:50,  5.52it/s, lr=0.00096, step_loss=0.1407/27/2023 19:50:59 - INFO - __main__ - train loss is 21.874506860622205\n",
      "Steps:  98%|▉| 14720/15000 [2:06:09<00:50,  5.50it/s, lr=0.00096, step_loss=0.1]07/27/2023 19:50:59 - INFO - __main__ - train loss is 22.026647686609067\n",
      "Steps:  98%|▉| 14721/15000 [2:06:09<00:50,  5.48it/s, lr=0.00096, step_loss=0.1507/27/2023 19:50:59 - INFO - __main__ - train loss is 22.263373911031522\n",
      "Steps:  98%|▉| 14722/15000 [2:06:09<00:50,  5.51it/s, lr=0.00096, step_loss=0.2307/27/2023 19:50:59 - INFO - __main__ - train loss is 22.44036172295455\n",
      "Steps:  98%|▉| 14723/15000 [2:06:09<00:50,  5.53it/s, lr=0.00096, step_loss=0.1707/27/2023 19:50:59 - INFO - __main__ - train loss is 22.464476823457517\n",
      "Steps:  98%|▉| 14724/15000 [2:06:10<00:50,  5.49it/s, lr=0.00096, step_loss=0.0207/27/2023 19:50:59 - INFO - __main__ - train loss is 22.466097576427273\n",
      "Steps:  98%|▉| 14725/15000 [2:06:10<00:49,  5.51it/s, lr=0.00096, step_loss=0.0007/27/2023 19:51:00 - INFO - __main__ - train loss is 22.569342343020253\n",
      "Steps:  98%|▉| 14726/15000 [2:06:10<00:49,  5.53it/s, lr=0.00096, step_loss=0.1007/27/2023 19:51:00 - INFO - __main__ - train loss is 22.766032246756367\n",
      "Steps:  98%|▉| 14727/15000 [2:06:10<00:49,  5.54it/s, lr=0.00096, step_loss=0.1907/27/2023 19:51:00 - INFO - __main__ - train loss is 23.589075175928883\n",
      "Steps:  98%|▉| 14728/15000 [2:06:10<00:49,  5.55it/s, lr=0.00096, step_loss=0.8207/27/2023 19:51:00 - INFO - __main__ - train loss is 23.60658952582162\n",
      "Steps:  98%|▉| 14729/15000 [2:06:10<00:48,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:00 - INFO - __main__ - train loss is 23.729730322840624\n",
      "Steps:  98%|▉| 14730/15000 [2:06:11<00:48,  5.55it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:00 - INFO - __main__ - train loss is 23.731088780099526\n",
      "Steps:  98%|▉| 14731/15000 [2:06:11<00:48,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:01 - INFO - __main__ - train loss is 23.758755762362853\n",
      "Steps:  98%|▉| 14732/15000 [2:06:11<00:48,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:01 - INFO - __main__ - train loss is 23.806238051736727\n",
      "Steps:  98%|▉| 14733/15000 [2:06:11<00:48,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:01 - INFO - __main__ - train loss is 23.817507057683542\n",
      "Steps:  98%|▉| 14734/15000 [2:06:11<00:47,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:01 - INFO - __main__ - train loss is 23.823158104671165\n",
      "Steps:  98%|▉| 14735/15000 [2:06:12<00:47,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:01 - INFO - __main__ - train loss is 24.70310076023452\n",
      "Steps:  98%|▉| 14736/15000 [2:06:12<00:47,  5.55it/s, lr=0.000959, step_loss=0.807/27/2023 19:51:02 - INFO - __main__ - train loss is 24.72454139846377\n",
      "Steps:  98%|▉| 14737/15000 [2:06:12<00:47,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:02 - INFO - __main__ - train loss is 24.731987527338788\n",
      "Steps:  98%|▉| 14738/15000 [2:06:12<00:47,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:02 - INFO - __main__ - train loss is 24.888143217889592\n",
      "Steps:  98%|▉| 14739/15000 [2:06:12<00:46,  5.55it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:02 - INFO - __main__ - train loss is 24.909570826916024\n",
      "Steps:  98%|▉| 14740/15000 [2:06:12<00:46,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:02 - INFO - __main__ - train loss is 25.21542020025663\n",
      "Steps:  98%|▉| 14741/15000 [2:06:13<00:46,  5.55it/s, lr=0.000959, step_loss=0.307/27/2023 19:51:02 - INFO - __main__ - train loss is 25.2172949234955\n",
      "Steps:  98%|▉| 14742/15000 [2:06:13<00:46,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:03 - INFO - __main__ - train loss is 25.695337287615985\n",
      "Steps:  98%|▉| 14743/15000 [2:06:13<00:46,  5.55it/s, lr=0.000959, step_loss=0.407/27/2023 19:51:03 - INFO - __main__ - train loss is 25.78661349369213\n",
      "Steps:  98%|▉| 14744/15000 [2:06:13<00:46,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:03 - INFO - __main__ - train loss is 25.790807327255607\n",
      "Steps:  98%|▉| 14745/15000 [2:06:13<00:45,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:03 - INFO - __main__ - train loss is 26.059644212946296\n",
      "Steps:  98%|▉| 14746/15000 [2:06:14<00:45,  5.55it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:03 - INFO - __main__ - train loss is 26.177105551585555\n",
      "Steps:  98%|▉| 14747/15000 [2:06:14<00:45,  5.55it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:04 - INFO - __main__ - train loss is 26.18169373879209\n",
      "Steps:  98%|▉| 14748/15000 [2:06:14<00:45,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:04 - INFO - __main__ - train loss is 26.669594115111977\n",
      "Steps:  98%|▉| 14749/15000 [2:06:14<00:45,  5.55it/s, lr=0.000959, step_loss=0.407/27/2023 19:51:04 - INFO - __main__ - train loss is 27.14403105387464\n",
      "Steps:  98%|▉| 14750/15000 [2:06:14<00:44,  5.56it/s, lr=0.000959, step_loss=0.407/27/2023 19:51:04 - INFO - __main__ - train loss is 27.154113280121237\n",
      "Steps:  98%|▉| 14751/15000 [2:06:14<00:44,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:04 - INFO - __main__ - train loss is 27.174453048501164\n",
      "Steps:  98%|▉| 14752/15000 [2:06:15<00:44,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:04 - INFO - __main__ - train loss is 27.222668836358935\n",
      "Steps:  98%|▉| 14753/15000 [2:06:15<00:44,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:05 - INFO - __main__ - train loss is 27.28504909435287\n",
      "Steps:  98%|▉| 14754/15000 [2:06:15<00:44,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:05 - INFO - __main__ - train loss is 27.513026832137257\n",
      "Steps:  98%|▉| 14755/15000 [2:06:15<00:44,  5.56it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:05 - INFO - __main__ - train loss is 27.665407268796116\n",
      "Steps:  98%|▉| 14756/15000 [2:06:15<00:43,  5.56it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:05 - INFO - __main__ - train loss is 27.671566493343562\n",
      "Steps:  98%|▉| 14757/15000 [2:06:15<00:43,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:05 - INFO - __main__ - train loss is 27.674669415224344\n",
      "Steps:  98%|▉| 14758/15000 [2:06:16<00:43,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:06 - INFO - __main__ - train loss is 27.970405757892877\n",
      "Steps:  98%|▉| 14759/15000 [2:06:16<00:43,  5.56it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:06 - INFO - __main__ - train loss is 27.993385566864163\n",
      "Steps:  98%|▉| 14760/15000 [2:06:16<00:43,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:06 - INFO - __main__ - train loss is 28.023823081050068\n",
      "Steps:  98%|▉| 14761/15000 [2:06:16<00:43,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:06 - INFO - __main__ - train loss is 28.208103670272976\n",
      "Steps:  98%|▉| 14762/15000 [2:06:16<00:42,  5.56it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:06 - INFO - __main__ - train loss is 28.291840753052384\n",
      "Steps:  98%|▉| 14763/15000 [2:06:17<00:42,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:06 - INFO - __main__ - train loss is 28.29694426851347\n",
      "Steps:  98%|▉| 14764/15000 [2:06:17<00:42,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:07 - INFO - __main__ - train loss is 28.396476708818227\n",
      "Steps:  98%|▉| 14765/15000 [2:06:17<00:42,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:07 - INFO - __main__ - train loss is 28.40694935945794\n",
      "Steps:  98%|▉| 14766/15000 [2:06:17<00:42,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:07 - INFO - __main__ - train loss is 28.631460312288254\n",
      "Steps:  98%|▉| 14767/15000 [2:06:17<00:41,  5.56it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:07 - INFO - __main__ - train loss is 28.670329968910664\n",
      "Steps:  98%|▉| 14768/15000 [2:06:17<00:41,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:07 - INFO - __main__ - train loss is 29.03882585046813\n",
      "Steps:  98%|▉| 14769/15000 [2:06:18<00:41,  5.56it/s, lr=0.000959, step_loss=0.307/27/2023 19:51:08 - INFO - __main__ - train loss is 29.237902368884534\n",
      "Steps:  98%|▉| 14770/15000 [2:06:18<00:41,  5.56it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:08 - INFO - __main__ - train loss is 29.257865372579545\n",
      "Steps:  98%|▉| 14771/15000 [2:06:18<00:41,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:08 - INFO - __main__ - train loss is 29.30356518505141\n",
      "Steps:  98%|▉| 14772/15000 [2:06:18<00:41,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:08 - INFO - __main__ - train loss is 29.34900103090331\n",
      "Steps:  98%|▉| 14773/15000 [2:06:18<00:40,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:08 - INFO - __main__ - train loss is 29.40525497077033\n",
      "Steps:  98%|▉| 14774/15000 [2:06:19<00:40,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:08 - INFO - __main__ - train loss is 29.544001575093716\n",
      "Steps:  98%|▉| 14775/15000 [2:06:19<00:40,  5.55it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:09 - INFO - __main__ - train loss is 29.56823951890692\n",
      "Steps:  99%|▉| 14776/15000 [2:06:19<00:40,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:09 - INFO - __main__ - train loss is 29.626025864388794\n",
      "Steps:  99%|▉| 14777/15000 [2:06:19<00:40,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:09 - INFO - __main__ - train loss is 29.870641031768173\n",
      "Steps:  99%|▉| 14778/15000 [2:06:19<00:39,  5.56it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:09 - INFO - __main__ - train loss is 29.90291734552011\n",
      "Steps:  99%|▉| 14779/15000 [2:06:19<00:39,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:09 - INFO - __main__ - train loss is 29.960364637430757\n",
      "Steps:  99%|▉| 14780/15000 [2:06:20<00:39,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:09 - INFO - __main__ - train loss is 30.276319501455873\n",
      "Steps:  99%|▉| 14781/15000 [2:06:20<00:39,  5.56it/s, lr=0.000959, step_loss=0.307/27/2023 19:51:10 - INFO - __main__ - train loss is 30.39319652086124\n",
      "Steps:  99%|▉| 14782/15000 [2:06:20<00:39,  5.56it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:10 - INFO - __main__ - train loss is 30.39614977245219\n",
      "Steps:  99%|▉| 14783/15000 [2:06:20<00:39,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:10 - INFO - __main__ - train loss is 30.80496211652644\n",
      "Steps:  99%|▉| 14784/15000 [2:06:20<00:38,  5.56it/s, lr=0.000959, step_loss=0.407/27/2023 19:51:10 - INFO - __main__ - train loss is 30.960958796786144\n",
      "Steps:  99%|▉| 14785/15000 [2:06:21<00:38,  5.56it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:10 - INFO - __main__ - train loss is 30.99513454292901\n",
      "Steps:  99%|▉| 14786/15000 [2:06:21<00:38,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:11 - INFO - __main__ - train loss is 31.01549745653756\n",
      "Steps:  99%|▉| 14787/15000 [2:06:21<00:38,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:11 - INFO - __main__ - train loss is 31.029473311500624\n",
      "Steps:  99%|▉| 14788/15000 [2:06:21<00:38,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:11 - INFO - __main__ - train loss is 31.092813319759443\n",
      "Steps:  99%|▉| 14789/15000 [2:06:21<00:37,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:11 - INFO - __main__ - train loss is 31.11124314670451\n",
      "Steps:  99%|▉| 14790/15000 [2:06:21<00:37,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:11 - INFO - __main__ - train loss is 31.311092901276425\n",
      "Steps:  99%|▉| 14791/15000 [2:06:22<00:37,  5.56it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:11 - INFO - __main__ - train loss is 31.335435549961403\n",
      "Steps:  99%|▉| 14792/15000 [2:06:22<00:37,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:12 - INFO - __main__ - train loss is 31.339253052836284\n",
      "Steps:  99%|▉| 14793/15000 [2:06:22<00:37,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:12 - INFO - __main__ - train loss is 31.448349445825443\n",
      "Steps:  99%|▉| 14794/15000 [2:06:22<00:37,  5.55it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:12 - INFO - __main__ - train loss is 31.70975849009119\n",
      "Steps:  99%|▉| 14795/15000 [2:06:22<00:36,  5.56it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:12 - INFO - __main__ - train loss is 31.74240408441983\n",
      "Steps:  99%|▉| 14796/15000 [2:06:23<00:36,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:12 - INFO - __main__ - train loss is 31.74840821395628\n",
      "Steps:  99%|▉| 14797/15000 [2:06:23<00:36,  5.56it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:13 - INFO - __main__ - train loss is 31.960284725530073\n",
      "Steps:  99%|▉| 14798/15000 [2:06:23<00:36,  5.55it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:13 - INFO - __main__ - train loss is 32.11418692837469\n",
      "Steps:  99%|▉| 14799/15000 [2:06:23<00:36,  5.56it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:13 - INFO - __main__ - train loss is 32.12653935677372\n",
      "Steps:  99%|▉| 14800/15000 [2:06:23<00:36,  5.55it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:13 - INFO - __main__ - train loss is 32.65802026516758\n",
      "Steps:  99%|▉| 14801/15000 [2:06:23<00:35,  5.55it/s, lr=0.000959, step_loss=0.507/27/2023 19:51:13 - INFO - __main__ - train loss is 32.89853350049816\n",
      "Steps:  99%|▉| 14802/15000 [2:06:24<00:36,  5.49it/s, lr=0.000959, step_loss=0.207/27/2023 19:51:13 - INFO - __main__ - train loss is 33.19833946949802\n",
      "Steps:  99%|▉| 14803/15000 [2:06:24<00:38,  5.15it/s, lr=0.000959, step_loss=0.307/27/2023 19:51:14 - INFO - __main__ - train loss is 33.316219083731994\n",
      "Steps:  99%|▉| 14804/15000 [2:06:24<00:40,  4.88it/s, lr=0.000959, step_loss=0.107/27/2023 19:51:14 - INFO - __main__ - train loss is 33.38507793075405\n",
      "Steps:  99%|▉| 14805/15000 [2:06:24<00:43,  4.46it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:14 - INFO - __main__ - train loss is 33.38635358714964\n",
      "Steps:  99%|▉| 14806/15000 [2:06:24<00:41,  4.70it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:14 - INFO - __main__ - train loss is 33.40708793455269\n",
      "Steps:  99%|▉| 14807/15000 [2:06:25<00:39,  4.91it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:15 - INFO - __main__ - train loss is 33.40950008796062\n",
      "Steps:  99%|▉| 14808/15000 [2:06:25<00:37,  5.08it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:15 - INFO - __main__ - train loss is 33.41100375831593\n",
      "Steps:  99%|▉| 14809/15000 [2:06:25<00:36,  5.21it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:15 - INFO - __main__ - train loss is 33.42783689231146\n",
      "Steps:  99%|▉| 14810/15000 [2:06:25<00:35,  5.29it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:15 - INFO - __main__ - train loss is 33.463002179865725\n",
      "Steps:  99%|▉| 14811/15000 [2:06:25<00:35,  5.36it/s, lr=0.000959, step_loss=0.007/27/2023 19:51:15 - INFO - __main__ - train loss is 33.767211501603015\n",
      "Steps:  99%|▉| 14812/15000 [2:06:26<00:34,  5.42it/s, lr=0.000959, step_loss=0.307/27/2023 19:51:15 - INFO - __main__ - train loss is 33.78037277434487\n",
      "Steps:  99%|▉| 14813/15000 [2:06:26<00:34,  5.46it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:16 - INFO - __main__ - train loss is 33.81851938564796\n",
      "Steps:  99%|▉| 14814/15000 [2:06:26<00:33,  5.49it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:16 - INFO - __main__ - train loss is 33.946199985337444\n",
      "Steps:  99%|▉| 14815/15000 [2:06:26<00:33,  5.51it/s, lr=0.000958, step_loss=0.107/27/2023 19:51:16 - INFO - __main__ - train loss is 33.99165402178187\n",
      "Steps:  99%|▉| 14816/15000 [2:06:26<00:33,  5.52it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:16 - INFO - __main__ - train loss is 34.10939146403689\n",
      "Steps:  99%|▉| 14817/15000 [2:06:26<00:33,  5.48it/s, lr=0.000958, step_loss=0.107/27/2023 19:51:16 - INFO - __main__ - train loss is 34.11566282354761\n",
      "Steps:  99%|▉| 14818/15000 [2:06:27<00:33,  5.48it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:17 - INFO - __main__ - train loss is 34.15639677562285\n",
      "Steps:  99%|▉| 14819/15000 [2:06:27<00:32,  5.51it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:17 - INFO - __main__ - train loss is 34.16036401421297\n",
      "Steps:  99%|▉| 14820/15000 [2:06:27<00:32,  5.47it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:17 - INFO - __main__ - train loss is 34.5241840305971\n",
      "Steps:  99%|▉| 14821/15000 [2:06:27<00:33,  5.40it/s, lr=0.000958, step_loss=0.307/27/2023 19:51:17 - INFO - __main__ - train loss is 34.8218478980707\n",
      "Steps:  99%|▉| 14822/15000 [2:06:27<00:32,  5.41it/s, lr=0.000958, step_loss=0.207/27/2023 19:51:17 - INFO - __main__ - train loss is 34.82570116559509\n",
      "Steps:  99%|▉| 14823/15000 [2:06:28<00:32,  5.44it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:17 - INFO - __main__ - train loss is 34.83043619815726\n",
      "Steps:  99%|▉| 14824/15000 [2:06:28<00:32,  5.47it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:18 - INFO - __main__ - train loss is 34.833310256828554\n",
      "Steps:  99%|▉| 14825/15000 [2:06:28<00:31,  5.48it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:18 - INFO - __main__ - train loss is 34.8350187583128\n",
      "Steps:  99%|▉| 14826/15000 [2:06:28<00:31,  5.50it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:18 - INFO - __main__ - train loss is 34.839711146079935\n",
      "Steps:  99%|▉| 14827/15000 [2:06:28<00:31,  5.52it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:18 - INFO - __main__ - train loss is 34.841605105786584\n",
      "Steps:  99%|▉| 14828/15000 [2:06:28<00:31,  5.53it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:18 - INFO - __main__ - train loss is 35.19012779870536\n",
      "Steps:  99%|▉| 14829/15000 [2:06:29<00:30,  5.54it/s, lr=0.000958, step_loss=0.307/27/2023 19:51:19 - INFO - __main__ - train loss is 35.268218838959\n",
      "Steps:  99%|▉| 14830/15000 [2:06:29<00:30,  5.55it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:19 - INFO - __main__ - train loss is 35.520750427036546\n",
      "Steps:  99%|▉| 14831/15000 [2:06:29<00:30,  5.56it/s, lr=0.000958, step_loss=0.207/27/2023 19:51:19 - INFO - __main__ - train loss is 35.94847609975841\n",
      "Steps:  99%|▉| 14832/15000 [2:06:29<00:30,  5.55it/s, lr=0.000958, step_loss=0.407/27/2023 19:51:19 - INFO - __main__ - train loss is 35.96627819293644\n",
      "Steps:  99%|▉| 14833/15000 [2:06:29<00:30,  5.56it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:19 - INFO - __main__ - train loss is 36.0439380829921\n",
      "Steps:  99%|▉| 14834/15000 [2:06:30<00:29,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:19 - INFO - __main__ - train loss is 36.05313869507518\n",
      "Steps:  99%|▉| 14835/15000 [2:06:30<00:29,  5.56it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:20 - INFO - __main__ - train loss is 36.40293195040431\n",
      "Steps:  99%|▉| 14836/15000 [2:06:30<00:29,  5.57it/s, lr=0.000958, step_loss=0.307/27/2023 19:51:20 - INFO - __main__ - train loss is 36.40616314706858\n",
      "Steps:  99%|▉| 14837/15000 [2:06:30<00:29,  5.56it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:20 - INFO - __main__ - train loss is 36.47464003262576\n",
      "Steps:  99%|▉| 14838/15000 [2:06:30<00:29,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:20 - INFO - __main__ - train loss is 37.130669078207575\n",
      "Steps:  99%|▉| 14839/15000 [2:06:30<00:28,  5.55it/s, lr=0.000958, step_loss=0.607/27/2023 19:51:20 - INFO - __main__ - train loss is 37.13348624377977\n",
      "Steps:  99%|▉| 14840/15000 [2:06:31<00:28,  5.56it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:21 - INFO - __main__ - train loss is 37.193986351485364\n",
      "Steps:  99%|▉| 14841/15000 [2:06:31<00:28,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:21 - INFO - __main__ - train loss is 37.483288134331815\n",
      "Steps:  99%|▉| 14842/15000 [2:06:31<00:28,  5.56it/s, lr=0.000958, step_loss=0.207/27/2023 19:51:21 - INFO - __main__ - train loss is 37.51448558724951\n",
      "Steps:  99%|▉| 14843/15000 [2:06:31<00:28,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:21 - INFO - __main__ - train loss is 37.93057571805548\n",
      "Steps:  99%|▉| 14844/15000 [2:06:31<00:27,  5.57it/s, lr=0.000958, step_loss=0.407/27/2023 19:51:21 - INFO - __main__ - train loss is 37.93506302766036\n",
      "Steps:  99%|▉| 14845/15000 [2:06:32<00:28,  5.52it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:21 - INFO - __main__ - train loss is 37.937920814263634\n",
      "Steps:  99%|▉| 14846/15000 [2:06:32<00:27,  5.52it/s, lr=0.000958, step_loss=0.007/27/2023 19:51:22 - INFO - __main__ - train loss is 38.36206308554392\n",
      "Steps:  99%|▉| 14847/15000 [2:06:32<00:40,  3.80it/s, lr=0.000958, step_loss=0.407/27/2023 19:51:23 - INFO - __main__ - Per validation step average loss is 0.23611624538898468\n",
      "07/27/2023 19:51:23 - INFO - __main__ - Cumulative validation average loss is 0.23611624538898468\n",
      "07/27/2023 19:51:23 - INFO - __main__ - Per validation step average loss is 0.0014021205715835094\n",
      "07/27/2023 19:51:23 - INFO - __main__ - Cumulative validation average loss is 0.2375183659605682\n",
      "07/27/2023 19:51:24 - INFO - __main__ - Per validation step average loss is 0.21189385652542114\n",
      "07/27/2023 19:51:24 - INFO - __main__ - Cumulative validation average loss is 0.44941222248598933\n",
      "07/27/2023 19:51:24 - INFO - __main__ - Per validation step average loss is 0.00398826040327549\n",
      "07/27/2023 19:51:24 - INFO - __main__ - Cumulative validation average loss is 0.4534004828892648\n",
      "07/27/2023 19:51:25 - INFO - __main__ - Per validation step average loss is 0.040063053369522095\n",
      "07/27/2023 19:51:25 - INFO - __main__ - Cumulative validation average loss is 0.4934635362587869\n",
      "07/27/2023 19:51:25 - INFO - __main__ - Per validation step average loss is 0.035974204540252686\n",
      "07/27/2023 19:51:25 - INFO - __main__ - Cumulative validation average loss is 0.5294377407990396\n",
      "07/27/2023 19:51:25 - INFO - __main__ - Per validation step average loss is 0.1920938491821289\n",
      "07/27/2023 19:51:25 - INFO - __main__ - Cumulative validation average loss is 0.7215315899811685\n",
      "07/27/2023 19:51:26 - INFO - __main__ - Per validation step average loss is 0.03774864226579666\n",
      "07/27/2023 19:51:26 - INFO - __main__ - Cumulative validation average loss is 0.7592802322469652\n",
      "07/27/2023 19:51:26 - INFO - __main__ - Per validation step average loss is 0.026800401508808136\n",
      "07/27/2023 19:51:26 - INFO - __main__ - Cumulative validation average loss is 0.7860806337557733\n",
      "07/27/2023 19:51:27 - INFO - __main__ - Per validation step average loss is 0.48981356620788574\n",
      "07/27/2023 19:51:27 - INFO - __main__ - Cumulative validation average loss is 1.275894199963659\n",
      "07/27/2023 19:51:27 - INFO - __main__ - Per validation step average loss is 0.009763984940946102\n",
      "07/27/2023 19:51:27 - INFO - __main__ - Cumulative validation average loss is 1.2856581849046052\n",
      "07/27/2023 19:51:27 - INFO - __main__ - Per validation step average loss is 0.012864120304584503\n",
      "07/27/2023 19:51:27 - INFO - __main__ - Cumulative validation average loss is 1.2985223052091897\n",
      "07/27/2023 19:51:28 - INFO - __main__ - Per validation step average loss is 0.13766688108444214\n",
      "07/27/2023 19:51:28 - INFO - __main__ - Cumulative validation average loss is 1.4361891862936318\n",
      "07/27/2023 19:51:28 - INFO - __main__ - Per validation step average loss is 0.31224676966667175\n",
      "07/27/2023 19:51:28 - INFO - __main__ - Cumulative validation average loss is 1.7484359559603035\n",
      "07/27/2023 19:51:29 - INFO - __main__ - Per validation step average loss is 0.1915181428194046\n",
      "07/27/2023 19:51:29 - INFO - __main__ - Cumulative validation average loss is 1.9399540987797081\n",
      "07/27/2023 19:51:29 - INFO - __main__ - Per validation step average loss is 0.11687932908535004\n",
      "07/27/2023 19:51:29 - INFO - __main__ - Cumulative validation average loss is 2.056833427865058\n",
      "07/27/2023 19:51:30 - INFO - __main__ - Per validation step average loss is 0.12488578259944916\n",
      "07/27/2023 19:51:30 - INFO - __main__ - Cumulative validation average loss is 2.1817192104645073\n",
      "07/27/2023 19:51:30 - INFO - __main__ - Per validation step average loss is 0.35155847668647766\n",
      "07/27/2023 19:51:30 - INFO - __main__ - Cumulative validation average loss is 2.533277687150985\n",
      "07/27/2023 19:51:30 - INFO - __main__ - Per validation step average loss is 0.07779166102409363\n",
      "07/27/2023 19:51:30 - INFO - __main__ - Cumulative validation average loss is 2.6110693481750786\n",
      "07/27/2023 19:51:31 - INFO - __main__ - Per validation step average loss is 0.0021950765512883663\n",
      "07/27/2023 19:51:31 - INFO - __main__ - Cumulative validation average loss is 2.613264424726367\n",
      "07/27/2023 19:51:31 - INFO - __main__ - Per validation step average loss is 0.03562761843204498\n",
      "07/27/2023 19:51:31 - INFO - __main__ - Cumulative validation average loss is 2.648892043158412\n",
      "07/27/2023 19:51:32 - INFO - __main__ - Per validation step average loss is 0.25311458110809326\n",
      "07/27/2023 19:51:32 - INFO - __main__ - Cumulative validation average loss is 2.9020066242665052\n",
      "07/27/2023 19:51:32 - INFO - __main__ - Per validation step average loss is 0.19936643540859222\n",
      "07/27/2023 19:51:32 - INFO - __main__ - Cumulative validation average loss is 3.1013730596750975\n",
      "07/27/2023 19:51:33 - INFO - __main__ - Per validation step average loss is 0.04978439211845398\n",
      "07/27/2023 19:51:33 - INFO - __main__ - Cumulative validation average loss is 3.1511574517935514\n",
      "07/27/2023 19:51:33 - INFO - __main__ - Per validation step average loss is 0.08732765167951584\n",
      "07/27/2023 19:51:33 - INFO - __main__ - Cumulative validation average loss is 3.2384851034730673\n",
      "07/27/2023 19:51:33 - INFO - __main__ - Per validation step average loss is 0.0026208218187093735\n",
      "07/27/2023 19:51:33 - INFO - __main__ - Cumulative validation average loss is 3.2411059252917767\n",
      "07/27/2023 19:51:34 - INFO - __main__ - Per validation step average loss is 0.04570761322975159\n",
      "07/27/2023 19:51:34 - INFO - __main__ - Cumulative validation average loss is 3.2868135385215282\n",
      "07/27/2023 19:51:34 - INFO - __main__ - Per validation step average loss is 0.005011651664972305\n",
      "07/27/2023 19:51:34 - INFO - __main__ - Cumulative validation average loss is 3.2918251901865005\n",
      "07/27/2023 19:51:35 - INFO - __main__ - Per validation step average loss is 0.4860685169696808\n",
      "07/27/2023 19:51:35 - INFO - __main__ - Cumulative validation average loss is 3.7778937071561813\n",
      "07/27/2023 19:51:35 - INFO - __main__ - Per validation step average loss is 0.06980836391448975\n",
      "07/27/2023 19:51:35 - INFO - __main__ - Cumulative validation average loss is 3.847702071070671\n",
      "07/27/2023 19:51:35 - INFO - __main__ - Per validation step average loss is 0.006424497812986374\n",
      "07/27/2023 19:51:35 - INFO - __main__ - Cumulative validation average loss is 3.8541265688836575\n",
      "07/27/2023 19:51:36 - INFO - __main__ - Per validation step average loss is 0.005913315340876579\n",
      "07/27/2023 19:51:36 - INFO - __main__ - Cumulative validation average loss is 3.860039884224534\n",
      "07/27/2023 19:51:36 - INFO - __main__ - Per validation step average loss is 0.02180149406194687\n",
      "07/27/2023 19:51:36 - INFO - __main__ - Cumulative validation average loss is 3.881841378286481\n",
      "07/27/2023 19:51:37 - INFO - __main__ - Per validation step average loss is 0.0038603837601840496\n",
      "07/27/2023 19:51:37 - INFO - __main__ - Cumulative validation average loss is 3.885701762046665\n",
      "07/27/2023 19:51:37 - INFO - __main__ - Per validation step average loss is 0.2797170877456665\n",
      "07/27/2023 19:51:37 - INFO - __main__ - Cumulative validation average loss is 4.1654188497923315\n",
      "07/27/2023 19:51:38 - INFO - __main__ - Per validation step average loss is 0.0036835623905062675\n",
      "07/27/2023 19:51:38 - INFO - __main__ - Cumulative validation average loss is 4.169102412182838\n",
      "07/27/2023 19:51:38 - INFO - __main__ - Per validation step average loss is 0.13337218761444092\n",
      "07/27/2023 19:51:38 - INFO - __main__ - Cumulative validation average loss is 4.302474599797279\n",
      "07/27/2023 19:51:38 - INFO - __main__ - Per validation step average loss is 0.5859199166297913\n",
      "07/27/2023 19:51:38 - INFO - __main__ - Cumulative validation average loss is 4.88839451642707\n",
      "07/27/2023 19:51:39 - INFO - __main__ - Per validation step average loss is 0.005278020165860653\n",
      "07/27/2023 19:51:39 - INFO - __main__ - Cumulative validation average loss is 4.8936725365929306\n",
      "07/27/2023 19:51:39 - INFO - __main__ - Per validation step average loss is 0.0064892852678895\n",
      "07/27/2023 19:51:39 - INFO - __main__ - Cumulative validation average loss is 4.90016182186082\n",
      "07/27/2023 19:51:40 - INFO - __main__ - Per validation step average loss is 0.14988160133361816\n",
      "07/27/2023 19:51:40 - INFO - __main__ - Cumulative validation average loss is 5.050043423194438\n",
      "07/27/2023 19:51:40 - INFO - __main__ - Per validation step average loss is 0.0012008510529994965\n",
      "07/27/2023 19:51:40 - INFO - __main__ - Cumulative validation average loss is 5.051244274247438\n",
      "07/27/2023 19:51:40 - INFO - __main__ - Per validation step average loss is 0.4854547381401062\n",
      "07/27/2023 19:51:40 - INFO - __main__ - Cumulative validation average loss is 5.536699012387544\n",
      "07/27/2023 19:51:41 - INFO - __main__ - Per validation step average loss is 0.02335057035088539\n",
      "07/27/2023 19:51:41 - INFO - __main__ - Cumulative validation average loss is 5.560049582738429\n",
      "07/27/2023 19:51:41 - INFO - __main__ - Per validation step average loss is 0.00697960052639246\n",
      "07/27/2023 19:51:41 - INFO - __main__ - Cumulative validation average loss is 5.567029183264822\n",
      "07/27/2023 19:51:42 - INFO - __main__ - Per validation step average loss is 0.28572916984558105\n",
      "07/27/2023 19:51:42 - INFO - __main__ - Cumulative validation average loss is 5.852758353110403\n",
      "07/27/2023 19:51:42 - INFO - __main__ - Per validation step average loss is 0.40733304619789124\n",
      "07/27/2023 19:51:42 - INFO - __main__ - Cumulative validation average loss is 6.260091399308294\n",
      "07/27/2023 19:51:43 - INFO - __main__ - Per validation step average loss is 0.01627347059547901\n",
      "07/27/2023 19:51:43 - INFO - __main__ - Cumulative validation average loss is 6.276364869903773\n",
      "07/27/2023 19:51:43 - INFO - __main__ - Per validation step average loss is 0.11088278889656067\n",
      "07/27/2023 19:51:43 - INFO - __main__ - Cumulative validation average loss is 6.387247658800334\n",
      "07/27/2023 19:51:43 - INFO - __main__ - Per validation step average loss is 0.09946012496948242\n",
      "07/27/2023 19:51:43 - INFO - __main__ - Cumulative validation average loss is 6.486707783769816\n",
      "07/27/2023 19:51:44 - INFO - __main__ - Per validation step average loss is 0.1574789583683014\n",
      "07/27/2023 19:51:44 - INFO - __main__ - Cumulative validation average loss is 6.6441867421381176\n",
      "07/27/2023 19:51:44 - INFO - __main__ - Per validation step average loss is 0.06700344383716583\n",
      "07/27/2023 19:51:44 - INFO - __main__ - Cumulative validation average loss is 6.711190185975283\n",
      "07/27/2023 19:51:45 - INFO - __main__ - Per validation step average loss is 0.04068627953529358\n",
      "07/27/2023 19:51:45 - INFO - __main__ - Cumulative validation average loss is 6.751876465510577\n",
      "07/27/2023 19:51:45 - INFO - __main__ - Per validation step average loss is 0.815410315990448\n",
      "07/27/2023 19:51:45 - INFO - __main__ - Cumulative validation average loss is 7.567286781501025\n",
      "07/27/2023 19:51:46 - INFO - __main__ - Per validation step average loss is 0.14788588881492615\n",
      "07/27/2023 19:51:46 - INFO - __main__ - Cumulative validation average loss is 7.715172670315951\n",
      "07/27/2023 19:51:46 - INFO - __main__ - Per validation step average loss is 0.029839202761650085\n",
      "07/27/2023 19:51:46 - INFO - __main__ - Cumulative validation average loss is 7.745011873077601\n",
      "07/27/2023 19:51:46 - INFO - __main__ - Per validation step average loss is 0.01829853653907776\n",
      "07/27/2023 19:51:46 - INFO - __main__ - Cumulative validation average loss is 7.763310409616679\n",
      "07/27/2023 19:51:47 - INFO - __main__ - Per validation step average loss is 0.29487499594688416\n",
      "07/27/2023 19:51:47 - INFO - __main__ - Cumulative validation average loss is 8.058185405563563\n",
      "07/27/2023 19:51:47 - INFO - __main__ - Per validation step average loss is 0.049924880266189575\n",
      "07/27/2023 19:51:47 - INFO - __main__ - Cumulative validation average loss is 8.108110285829753\n",
      "07/27/2023 19:51:48 - INFO - __main__ - Per validation step average loss is 0.023853080347180367\n",
      "07/27/2023 19:51:48 - INFO - __main__ - Cumulative validation average loss is 8.131963366176933\n",
      "07/27/2023 19:51:48 - INFO - __main__ - Per validation step average loss is 0.01042739488184452\n",
      "07/27/2023 19:51:48 - INFO - __main__ - Cumulative validation average loss is 8.142390761058778\n",
      "07/27/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.010498007759451866\n",
      "07/27/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 8.15288876881823\n",
      "07/27/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.06981956958770752\n",
      "07/27/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 8.222708338405937\n",
      "07/27/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.13478419184684753\n",
      "07/27/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 8.357492530252784\n",
      "07/27/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.05107149854302406\n",
      "07/27/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 8.408564028795809\n",
      "07/27/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.5733624696731567\n",
      "07/27/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 8.981926498468965\n",
      "07/27/2023 19:51:51 - INFO - __main__ - Per validation step average loss is 0.11032437533140182\n",
      "07/27/2023 19:51:51 - INFO - __main__ - Cumulative validation average loss is 9.092250873800367\n",
      "07/27/2023 19:51:51 - INFO - __main__ - Per validation step average loss is 0.0015006472822278738\n",
      "07/27/2023 19:51:51 - INFO - __main__ - Cumulative validation average loss is 9.093751521082595\n",
      "07/27/2023 19:51:51 - INFO - __main__ - Per validation step average loss is 0.11883682012557983\n",
      "07/27/2023 19:51:51 - INFO - __main__ - Cumulative validation average loss is 9.212588341208175\n",
      "07/27/2023 19:51:52 - INFO - __main__ - Per validation step average loss is 0.15185746550559998\n",
      "07/27/2023 19:51:52 - INFO - __main__ - Cumulative validation average loss is 9.364445806713775\n",
      "07/27/2023 19:51:52 - INFO - __main__ - Per validation step average loss is 0.044094063341617584\n",
      "07/27/2023 19:51:52 - INFO - __main__ - Cumulative validation average loss is 9.408539870055392\n",
      "07/27/2023 19:51:53 - INFO - __main__ - Per validation step average loss is 0.4908526837825775\n",
      "07/27/2023 19:51:53 - INFO - __main__ - Cumulative validation average loss is 9.89939255383797\n",
      "07/27/2023 19:51:53 - INFO - __main__ - Per validation step average loss is 0.0438266322016716\n",
      "07/27/2023 19:51:53 - INFO - __main__ - Cumulative validation average loss is 9.943219186039641\n",
      "07/27/2023 19:51:53 - INFO - __main__ - Per validation step average loss is 0.002445596270263195\n",
      "07/27/2023 19:51:53 - INFO - __main__ - Cumulative validation average loss is 9.945664782309905\n",
      "07/27/2023 19:51:54 - INFO - __main__ - Per validation step average loss is 0.23487898707389832\n",
      "07/27/2023 19:51:54 - INFO - __main__ - Cumulative validation average loss is 10.180543769383803\n",
      "07/27/2023 19:51:54 - INFO - __main__ - Per validation step average loss is 0.002253091661259532\n",
      "07/27/2023 19:51:54 - INFO - __main__ - Cumulative validation average loss is 10.182796861045063\n",
      "07/27/2023 19:51:55 - INFO - __main__ - Per validation step average loss is 0.09871196746826172\n",
      "07/27/2023 19:51:55 - INFO - __main__ - Cumulative validation average loss is 10.281508828513324\n",
      "07/27/2023 19:51:55 - INFO - __main__ - Per validation step average loss is 0.03753769397735596\n",
      "07/27/2023 19:51:55 - INFO - __main__ - Cumulative validation average loss is 10.31904652249068\n",
      "07/27/2023 19:51:56 - INFO - __main__ - Per validation step average loss is 0.07183294743299484\n",
      "07/27/2023 19:51:56 - INFO - __main__ - Cumulative validation average loss is 10.390879469923675\n",
      "07/27/2023 19:51:56 - INFO - __main__ - Average validation loss for Epoch 48 is 0.13153011987245158\n",
      "07/27/2023 19:51:56 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2023 19:52:54 - INFO - __main__ - Starting epoch 49\n",
      "07/27/2023 19:52:54 - INFO - __main__ - train loss is 0.01164859440177679\n",
      "Steps:  99%|▉| 14848/15000 [2:08:05<1:10:40, 27.90s/it, lr=0.000958, step_loss=007/27/2023 19:52:54 - INFO - __main__ - train loss is 0.06754987221211195\n",
      "Steps:  99%|▉| 14849/15000 [2:08:05<49:16, 19.58s/it, lr=0.000958, step_loss=0.007/27/2023 19:52:55 - INFO - __main__ - train loss is 0.3504077671095729\n",
      "Steps:  99%|▉| 14850/15000 [2:08:05<34:24, 13.76s/it, lr=0.000958, step_loss=0.207/27/2023 19:52:55 - INFO - __main__ - train loss is 1.089507925324142\n",
      "Steps:  99%|▉| 14851/15000 [2:08:05<24:03,  9.69s/it, lr=0.000958, step_loss=0.707/27/2023 19:52:55 - INFO - __main__ - train loss is 1.0920968404971063\n",
      "Steps:  99%|▉| 14852/15000 [2:08:05<16:51,  6.84s/it, lr=0.000958, step_loss=0.007/27/2023 19:52:55 - INFO - __main__ - train loss is 1.151447409298271\n",
      "Steps:  99%|▉| 14853/15000 [2:08:05<11:51,  4.84s/it, lr=0.000958, step_loss=0.007/27/2023 19:52:55 - INFO - __main__ - train loss is 1.1582146952860057\n",
      "Steps:  99%|▉| 14854/15000 [2:08:06<08:23,  3.45s/it, lr=0.000958, step_loss=0.007/27/2023 19:52:56 - INFO - __main__ - train loss is 1.1648717648349702\n",
      "Steps:  99%|▉| 14855/15000 [2:08:06<05:58,  2.47s/it, lr=0.000958, step_loss=0.007/27/2023 19:52:56 - INFO - __main__ - train loss is 1.5198296434246004\n",
      "Steps:  99%|▉| 14856/15000 [2:08:06<04:16,  1.78s/it, lr=0.000958, step_loss=0.307/27/2023 19:52:56 - INFO - __main__ - train loss is 1.544262911658734\n",
      "Steps:  99%|▉| 14857/15000 [2:08:06<03:06,  1.30s/it, lr=0.000958, step_loss=0.007/27/2023 19:52:56 - INFO - __main__ - train loss is 1.604417163413018\n",
      "Steps:  99%|▉| 14858/15000 [2:08:06<02:17,  1.03it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:56 - INFO - __main__ - train loss is 1.6517835254780948\n",
      "Steps:  99%|▉| 14859/15000 [2:08:07<01:43,  1.37it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:56 - INFO - __main__ - train loss is 1.725813343655318\n",
      "Steps:  99%|▉| 14860/15000 [2:08:07<01:19,  1.76it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:57 - INFO - __main__ - train loss is 1.8498421157710254\n",
      "Steps:  99%|▉| 14861/15000 [2:08:07<01:02,  2.21it/s, lr=0.000958, step_loss=0.107/27/2023 19:52:57 - INFO - __main__ - train loss is 1.856785459909588\n",
      "Steps:  99%|▉| 14862/15000 [2:08:07<00:51,  2.70it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:57 - INFO - __main__ - train loss is 1.8584790665190667\n",
      "Steps:  99%|▉| 14863/15000 [2:08:07<00:43,  3.17it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:57 - INFO - __main__ - train loss is 1.95688363048248\n",
      "Steps:  99%|▉| 14864/15000 [2:08:08<00:37,  3.62it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:57 - INFO - __main__ - train loss is 1.9699763122480363\n",
      "Steps:  99%|▉| 14865/15000 [2:08:08<00:33,  4.04it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:58 - INFO - __main__ - train loss is 2.4977946940343827\n",
      "Steps:  99%|▉| 14866/15000 [2:08:08<00:30,  4.38it/s, lr=0.000958, step_loss=0.507/27/2023 19:52:58 - INFO - __main__ - train loss is 3.0288226667325944\n",
      "Steps:  99%|▉| 14867/15000 [2:08:08<00:28,  4.66it/s, lr=0.000958, step_loss=0.507/27/2023 19:52:58 - INFO - __main__ - train loss is 3.044505179626867\n",
      "Steps:  99%|▉| 14868/15000 [2:08:08<00:26,  4.90it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:58 - INFO - __main__ - train loss is 3.0478407547343522\n",
      "Steps:  99%|▉| 14869/15000 [2:08:08<00:25,  5.06it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:58 - INFO - __main__ - train loss is 3.054818031610921\n",
      "Steps:  99%|▉| 14870/15000 [2:08:09<00:24,  5.21it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:58 - INFO - __main__ - train loss is 3.303397682728246\n",
      "Steps:  99%|▉| 14871/15000 [2:08:09<00:24,  5.31it/s, lr=0.000958, step_loss=0.207/27/2023 19:52:59 - INFO - __main__ - train loss is 3.4694631670136005\n",
      "Steps:  99%|▉| 14872/15000 [2:08:09<00:23,  5.39it/s, lr=0.000958, step_loss=0.107/27/2023 19:52:59 - INFO - __main__ - train loss is 3.505413604201749\n",
      "Steps:  99%|▉| 14873/15000 [2:08:09<00:23,  5.41it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:59 - INFO - __main__ - train loss is 3.578811501385644\n",
      "Steps:  99%|▉| 14874/15000 [2:08:09<00:23,  5.46it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:59 - INFO - __main__ - train loss is 3.584449582034722\n",
      "Steps:  99%|▉| 14875/15000 [2:08:09<00:22,  5.49it/s, lr=0.000958, step_loss=0.007/27/2023 19:52:59 - INFO - __main__ - train loss is 3.6716911422554404\n",
      "Steps:  99%|▉| 14876/15000 [2:08:10<00:22,  5.52it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:00 - INFO - __main__ - train loss is 3.6746808311436325\n",
      "Steps:  99%|▉| 14877/15000 [2:08:10<00:22,  5.53it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:00 - INFO - __main__ - train loss is 3.861297326395288\n",
      "Steps:  99%|▉| 14878/15000 [2:08:10<00:21,  5.55it/s, lr=0.000958, step_loss=0.107/27/2023 19:53:00 - INFO - __main__ - train loss is 4.057562815258279\n",
      "Steps:  99%|▉| 14879/15000 [2:08:10<00:21,  5.56it/s, lr=0.000958, step_loss=0.107/27/2023 19:53:00 - INFO - __main__ - train loss is 4.173235157737508\n",
      "Steps:  99%|▉| 14880/15000 [2:08:10<00:21,  5.56it/s, lr=0.000958, step_loss=0.107/27/2023 19:53:00 - INFO - __main__ - train loss is 4.209760489175096\n",
      "Steps:  99%|▉| 14881/15000 [2:08:11<00:21,  5.56it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:00 - INFO - __main__ - train loss is 4.300509782740846\n",
      "Steps:  99%|▉| 14882/15000 [2:08:11<00:21,  5.56it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:01 - INFO - __main__ - train loss is 4.307465742575005\n",
      "Steps:  99%|▉| 14883/15000 [2:08:11<00:21,  5.56it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:01 - INFO - __main__ - train loss is 4.589073012815788\n",
      "Steps:  99%|▉| 14884/15000 [2:08:11<00:20,  5.57it/s, lr=0.000958, step_loss=0.207/27/2023 19:53:01 - INFO - __main__ - train loss is 4.633339799242094\n",
      "Steps:  99%|▉| 14885/15000 [2:08:11<00:20,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:01 - INFO - __main__ - train loss is 4.641946782590821\n",
      "Steps:  99%|▉| 14886/15000 [2:08:11<00:20,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:01 - INFO - __main__ - train loss is 4.703982019098476\n",
      "Steps:  99%|▉| 14887/15000 [2:08:12<00:20,  5.58it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:02 - INFO - __main__ - train loss is 4.706991264829412\n",
      "Steps:  99%|▉| 14888/15000 [2:08:12<00:20,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:02 - INFO - __main__ - train loss is 4.709639667766169\n",
      "Steps:  99%|▉| 14889/15000 [2:08:12<00:19,  5.58it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:02 - INFO - __main__ - train loss is 4.768331974046305\n",
      "Steps:  99%|▉| 14890/15000 [2:08:12<00:19,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:02 - INFO - __main__ - train loss is 4.777125799329951\n",
      "Steps:  99%|▉| 14891/15000 [2:08:12<00:19,  5.57it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:02 - INFO - __main__ - train loss is 4.77937244088389\n",
      "Steps:  99%|▉| 14892/15000 [2:08:13<00:19,  5.58it/s, lr=0.000958, step_loss=0.007/27/2023 19:53:02 - INFO - __main__ - train loss is 5.110383736202493\n",
      "Steps:  99%|▉| 14893/15000 [2:08:13<00:19,  5.57it/s, lr=0.000958, step_loss=0.307/27/2023 19:53:03 - INFO - __main__ - train loss is 5.470580892870203\n",
      "Steps:  99%|▉| 14894/15000 [2:08:13<00:19,  5.57it/s, lr=0.000958, step_loss=0.307/27/2023 19:53:03 - INFO - __main__ - train loss is 5.471803324762732\n",
      "Steps:  99%|▉| 14895/15000 [2:08:13<00:18,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:03 - INFO - __main__ - train loss is 5.599620732013136\n",
      "Steps:  99%|▉| 14896/15000 [2:08:13<00:18,  5.57it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:03 - INFO - __main__ - train loss is 5.620500689838082\n",
      "Steps:  99%|▉| 14897/15000 [2:08:13<00:18,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:03 - INFO - __main__ - train loss is 6.0019496739842\n",
      "Steps:  99%|▉| 14898/15000 [2:08:14<00:18,  5.57it/s, lr=0.000957, step_loss=0.307/27/2023 19:53:03 - INFO - __main__ - train loss is 6.005995441693813\n",
      "Steps:  99%|▉| 14899/15000 [2:08:14<00:18,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:04 - INFO - __main__ - train loss is 6.201561440248042\n",
      "Steps:  99%|▉| 14900/15000 [2:08:14<00:17,  5.57it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:04 - INFO - __main__ - train loss is 6.382920686621219\n",
      "Steps:  99%|▉| 14901/15000 [2:08:14<00:17,  5.57it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:04 - INFO - __main__ - train loss is 6.668335024733096\n",
      "Steps:  99%|▉| 14902/15000 [2:08:14<00:17,  5.57it/s, lr=0.000957, step_loss=0.207/27/2023 19:53:04 - INFO - __main__ - train loss is 6.761734161991626\n",
      "Steps:  99%|▉| 14903/15000 [2:08:15<00:17,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:04 - INFO - __main__ - train loss is 7.493978236336261\n",
      "Steps:  99%|▉| 14904/15000 [2:08:15<00:17,  5.57it/s, lr=0.000957, step_loss=0.707/27/2023 19:53:05 - INFO - __main__ - train loss is 7.585802708286792\n",
      "Steps:  99%|▉| 14905/15000 [2:08:15<00:17,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:05 - INFO - __main__ - train loss is 7.597997615579516\n",
      "Steps:  99%|▉| 14906/15000 [2:08:15<00:16,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:05 - INFO - __main__ - train loss is 7.600147962803021\n",
      "Steps:  99%|▉| 14907/15000 [2:08:15<00:16,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:05 - INFO - __main__ - train loss is 7.733644917840138\n",
      "Steps:  99%|▉| 14908/15000 [2:08:15<00:16,  5.57it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:05 - INFO - __main__ - train loss is 7.8231701629702\n",
      "Steps:  99%|▉| 14909/15000 [2:08:16<00:16,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:05 - INFO - __main__ - train loss is 7.827023186953738\n",
      "Steps:  99%|▉| 14910/15000 [2:08:16<00:16,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:06 - INFO - __main__ - train loss is 7.829893736401573\n",
      "Steps:  99%|▉| 14911/15000 [2:08:16<00:16,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:06 - INFO - __main__ - train loss is 7.986465035239235\n",
      "Steps:  99%|▉| 14912/15000 [2:08:16<00:15,  5.55it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:06 - INFO - __main__ - train loss is 8.18319438234903\n",
      "Steps:  99%|▉| 14913/15000 [2:08:16<00:15,  5.50it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:06 - INFO - __main__ - train loss is 8.184986868756823\n",
      "Steps:  99%|▉| 14914/15000 [2:08:17<00:15,  5.51it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:06 - INFO - __main__ - train loss is 8.528439799207263\n",
      "Steps:  99%|▉| 14915/15000 [2:08:17<00:15,  5.52it/s, lr=0.000957, step_loss=0.307/27/2023 19:53:07 - INFO - __main__ - train loss is 8.537328584934585\n",
      "Steps:  99%|▉| 14916/15000 [2:08:17<00:15,  5.54it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:07 - INFO - __main__ - train loss is 8.596161409164779\n",
      "Steps:  99%|▉| 14917/15000 [2:08:17<00:14,  5.53it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:07 - INFO - __main__ - train loss is 8.63478831842076\n",
      "Steps:  99%|▉| 14918/15000 [2:08:17<00:14,  5.55it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:07 - INFO - __main__ - train loss is 8.657038767705671\n",
      "Steps:  99%|▉| 14919/15000 [2:08:17<00:14,  5.54it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:07 - INFO - __main__ - train loss is 8.659828553791158\n",
      "Steps:  99%|▉| 14920/15000 [2:08:18<00:14,  5.54it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:07 - INFO - __main__ - train loss is 8.861291418666951\n",
      "Steps:  99%|▉| 14921/15000 [2:08:18<00:14,  5.55it/s, lr=0.000957, step_loss=0.207/27/2023 19:53:08 - INFO - __main__ - train loss is 8.871265109512024\n",
      "Steps:  99%|▉| 14922/15000 [2:08:18<00:14,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:08 - INFO - __main__ - train loss is 8.9211910701124\n",
      "Steps:  99%|▉| 14923/15000 [2:08:18<00:13,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:08 - INFO - __main__ - train loss is 8.923251538886689\n",
      "Steps:  99%|▉| 14924/15000 [2:08:18<00:13,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:08 - INFO - __main__ - train loss is 8.924403030076064\n",
      "Steps: 100%|▉| 14925/15000 [2:08:18<00:13,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:08 - INFO - __main__ - train loss is 9.101110282936133\n",
      "Steps: 100%|▉| 14926/15000 [2:08:19<00:13,  5.57it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:09 - INFO - __main__ - train loss is 9.121951087960042\n",
      "Steps: 100%|▉| 14927/15000 [2:08:19<00:13,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:09 - INFO - __main__ - train loss is 9.128050919272937\n",
      "Steps: 100%|▉| 14928/15000 [2:08:19<00:12,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:09 - INFO - __main__ - train loss is 9.49384724686388\n",
      "Steps: 100%|▉| 14929/15000 [2:08:19<00:12,  5.57it/s, lr=0.000957, step_loss=0.307/27/2023 19:53:09 - INFO - __main__ - train loss is 9.574891667463817\n",
      "Steps: 100%|▉| 14930/15000 [2:08:19<00:12,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:09 - INFO - __main__ - train loss is 9.700086023309268\n",
      "Steps: 100%|▉| 14931/15000 [2:08:20<00:12,  5.55it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:09 - INFO - __main__ - train loss is 9.708640110329725\n",
      "Steps: 100%|▉| 14932/15000 [2:08:20<00:12,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:10 - INFO - __main__ - train loss is 9.719140288070776\n",
      "Steps: 100%|▉| 14933/15000 [2:08:20<00:12,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:10 - INFO - __main__ - train loss is 9.770806875661947\n",
      "Steps: 100%|▉| 14934/15000 [2:08:20<00:11,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:10 - INFO - __main__ - train loss is 9.873264130786993\n",
      "Steps: 100%|▉| 14935/15000 [2:08:20<00:11,  5.56it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:10 - INFO - __main__ - train loss is 10.390456077293493\n",
      "Steps: 100%|▉| 14936/15000 [2:08:20<00:11,  5.57it/s, lr=0.000957, step_loss=0.507/27/2023 19:53:10 - INFO - __main__ - train loss is 10.39729257777799\n",
      "Steps: 100%|▉| 14937/15000 [2:08:21<00:11,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:11 - INFO - __main__ - train loss is 10.39843824354466\n",
      "Steps: 100%|▉| 14938/15000 [2:08:21<00:11,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:11 - INFO - __main__ - train loss is 10.413700966513716\n",
      "Steps: 100%|▉| 14939/15000 [2:08:21<00:10,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:11 - INFO - __main__ - train loss is 10.418059593415819\n",
      "Steps: 100%|▉| 14940/15000 [2:08:21<00:10,  5.57it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:11 - INFO - __main__ - train loss is 10.710421687341295\n",
      "Steps: 100%|▉| 14941/15000 [2:08:21<00:10,  5.57it/s, lr=0.000957, step_loss=0.207/27/2023 19:53:11 - INFO - __main__ - train loss is 10.775746031082235\n",
      "Steps: 100%|▉| 14942/15000 [2:08:22<00:10,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:11 - INFO - __main__ - train loss is 10.780896008363925\n",
      "Steps: 100%|▉| 14943/15000 [2:08:22<00:10,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:12 - INFO - __main__ - train loss is 10.88783291017171\n",
      "Steps: 100%|▉| 14944/15000 [2:08:22<00:10,  5.51it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:12 - INFO - __main__ - train loss is 10.91699299251195\n",
      "Steps: 100%|▉| 14945/15000 [2:08:22<00:09,  5.50it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:12 - INFO - __main__ - train loss is 10.932703161961399\n",
      "Steps: 100%|▉| 14946/15000 [2:08:22<00:09,  5.52it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:12 - INFO - __main__ - train loss is 10.934363282402046\n",
      "Steps: 100%|▉| 14947/15000 [2:08:22<00:09,  5.52it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:12 - INFO - __main__ - train loss is 10.989982850034721\n",
      "Steps: 100%|▉| 14948/15000 [2:08:23<00:09,  5.48it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:13 - INFO - __main__ - train loss is 10.99346367653925\n",
      "Steps: 100%|▉| 14949/15000 [2:08:23<00:09,  5.49it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:13 - INFO - __main__ - train loss is 11.383051794138737\n",
      "Steps: 100%|▉| 14950/15000 [2:08:23<00:09,  5.52it/s, lr=0.000957, step_loss=0.307/27/2023 19:53:13 - INFO - __main__ - train loss is 12.3067890816601\n",
      "Steps: 100%|▉| 14951/15000 [2:08:23<00:08,  5.50it/s, lr=0.000957, step_loss=0.907/27/2023 19:53:13 - INFO - __main__ - train loss is 12.483358334866352\n",
      "Steps: 100%|▉| 14952/15000 [2:08:23<00:08,  5.52it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:13 - INFO - __main__ - train loss is 12.786757242050953\n",
      "Steps: 100%|▉| 14953/15000 [2:08:24<00:08,  5.53it/s, lr=0.000957, step_loss=0.307/27/2023 19:53:13 - INFO - __main__ - train loss is 12.869777459767647\n",
      "Steps: 100%|▉| 14954/15000 [2:08:24<00:08,  5.49it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:14 - INFO - __main__ - train loss is 12.904797885683365\n",
      "Steps: 100%|▉| 14955/15000 [2:08:24<00:08,  5.45it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:14 - INFO - __main__ - train loss is 12.925365150091238\n",
      "Steps: 100%|▉| 14956/15000 [2:08:24<00:08,  5.43it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:14 - INFO - __main__ - train loss is 13.12051516782958\n",
      "Steps: 100%|▉| 14957/15000 [2:08:24<00:07,  5.47it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:14 - INFO - __main__ - train loss is 13.204036183771677\n",
      "Steps: 100%|▉| 14958/15000 [2:08:24<00:07,  5.50it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:14 - INFO - __main__ - train loss is 13.208024744060822\n",
      "Steps: 100%|▉| 14959/15000 [2:08:25<00:07,  5.51it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:15 - INFO - __main__ - train loss is 13.93069607403595\n",
      "Steps: 100%|▉| 14960/15000 [2:08:25<00:07,  5.50it/s, lr=0.000957, step_loss=0.707/27/2023 19:53:15 - INFO - __main__ - train loss is 13.932738303090446\n",
      "Steps: 100%|▉| 14961/15000 [2:08:25<00:07,  5.52it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:15 - INFO - __main__ - train loss is 13.985327958012931\n",
      "Steps: 100%|▉| 14962/15000 [2:08:25<00:06,  5.53it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:15 - INFO - __main__ - train loss is 14.64821255102288\n",
      "Steps: 100%|▉| 14963/15000 [2:08:25<00:06,  5.54it/s, lr=0.000957, step_loss=0.607/27/2023 19:53:15 - INFO - __main__ - train loss is 14.695530070806853\n",
      "Steps: 100%|▉| 14964/15000 [2:08:26<00:06,  5.55it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:15 - INFO - __main__ - train loss is 15.028796686674468\n",
      "Steps: 100%|▉| 14965/15000 [2:08:26<00:06,  5.56it/s, lr=0.000957, step_loss=0.307/27/2023 19:53:16 - INFO - __main__ - train loss is 15.162804468418472\n",
      "Steps: 100%|▉| 14966/15000 [2:08:26<00:06,  5.56it/s, lr=0.000957, step_loss=0.107/27/2023 19:53:16 - INFO - __main__ - train loss is 15.372180952574126\n",
      "Steps: 100%|▉| 14967/15000 [2:08:26<00:05,  5.52it/s, lr=0.000957, step_loss=0.207/27/2023 19:53:16 - INFO - __main__ - train loss is 15.376623907475732\n",
      "Steps: 100%|▉| 14968/15000 [2:08:26<00:05,  5.48it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:16 - INFO - __main__ - train loss is 15.380956719978712\n",
      "Steps: 100%|▉| 14969/15000 [2:08:26<00:05,  5.51it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:16 - INFO - __main__ - train loss is 15.596135597093962\n",
      "Steps: 100%|▉| 14970/15000 [2:08:27<00:05,  5.53it/s, lr=0.000957, step_loss=0.207/27/2023 19:53:16 - INFO - __main__ - train loss is 15.693993698223494\n",
      "Steps: 100%|▉| 14971/15000 [2:08:27<00:05,  5.53it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:17 - INFO - __main__ - train loss is 15.753032333566807\n",
      "Steps: 100%|▉| 14972/15000 [2:08:27<00:05,  5.55it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:17 - INFO - __main__ - train loss is 15.783326113014482\n",
      "Steps: 100%|▉| 14973/15000 [2:08:27<00:04,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:17 - INFO - __main__ - train loss is 15.803179993643425\n",
      "Steps: 100%|▉| 14974/15000 [2:08:27<00:04,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:17 - INFO - __main__ - train loss is 15.823351377039216\n",
      "Steps: 100%|▉| 14975/15000 [2:08:28<00:04,  5.56it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:17 - INFO - __main__ - train loss is 15.83249678032007\n",
      "Steps: 100%|▉| 14976/15000 [2:08:28<00:04,  5.52it/s, lr=0.000957, step_loss=0.007/27/2023 19:53:18 - INFO - __main__ - train loss is 16.00899495498743\n",
      "Steps: 100%|▉| 14977/15000 [2:08:28<00:04,  5.53it/s, lr=0.000956, step_loss=0.107/27/2023 19:53:18 - INFO - __main__ - train loss is 16.073693688376807\n",
      "Steps: 100%|▉| 14978/15000 [2:08:28<00:03,  5.55it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:18 - INFO - __main__ - train loss is 16.08455788285937\n",
      "Steps: 100%|▉| 14979/15000 [2:08:28<00:03,  5.56it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:18 - INFO - __main__ - train loss is 16.19077075214591\n",
      "Steps: 100%|▉| 14980/15000 [2:08:28<00:03,  5.57it/s, lr=0.000956, step_loss=0.107/27/2023 19:53:18 - INFO - __main__ - train loss is 16.351556442095898\n",
      "Steps: 100%|▉| 14981/15000 [2:08:29<00:03,  5.57it/s, lr=0.000956, step_loss=0.107/27/2023 19:53:18 - INFO - __main__ - train loss is 16.35488551564049\n",
      "Steps: 100%|▉| 14982/15000 [2:08:29<00:03,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:19 - INFO - __main__ - train loss is 16.42113675631117\n",
      "Steps: 100%|▉| 14983/15000 [2:08:29<00:03,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:19 - INFO - __main__ - train loss is 16.46895684010815\n",
      "Steps: 100%|▉| 14984/15000 [2:08:29<00:02,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:19 - INFO - __main__ - train loss is 16.47640501789283\n",
      "Steps: 100%|▉| 14985/15000 [2:08:29<00:02,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:19 - INFO - __main__ - train loss is 16.61850848130416\n",
      "Steps: 100%|▉| 14986/15000 [2:08:29<00:02,  5.57it/s, lr=0.000956, step_loss=0.107/27/2023 19:53:19 - INFO - __main__ - train loss is 16.73680808476638\n",
      "Steps: 100%|▉| 14987/15000 [2:08:30<00:02,  5.57it/s, lr=0.000956, step_loss=0.107/27/2023 19:53:20 - INFO - __main__ - train loss is 16.739646291243844\n",
      "Steps: 100%|▉| 14988/15000 [2:08:30<00:02,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:20 - INFO - __main__ - train loss is 16.756576625513844\n",
      "Steps: 100%|▉| 14989/15000 [2:08:30<00:01,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:20 - INFO - __main__ - train loss is 16.7646909969626\n",
      "Steps: 100%|▉| 14990/15000 [2:08:30<00:01,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:20 - INFO - __main__ - train loss is 16.774483410525136\n",
      "Steps: 100%|▉| 14991/15000 [2:08:30<00:01,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:20 - INFO - __main__ - train loss is 16.797993196058087\n",
      "Steps: 100%|▉| 14992/15000 [2:08:31<00:01,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:20 - INFO - __main__ - train loss is 16.828080849605612\n",
      "Steps: 100%|▉| 14993/15000 [2:08:31<00:01,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:21 - INFO - __main__ - train loss is 16.832269921782427\n",
      "Steps: 100%|▉| 14994/15000 [2:08:31<00:01,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:21 - INFO - __main__ - train loss is 16.84386722173076\n",
      "Steps: 100%|▉| 14995/15000 [2:08:31<00:00,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:21 - INFO - __main__ - train loss is 16.87482413079124\n",
      "Steps: 100%|▉| 14996/15000 [2:08:31<00:00,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:21 - INFO - __main__ - train loss is 16.877738816547208\n",
      "Steps: 100%|▉| 14997/15000 [2:08:31<00:00,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:21 - INFO - __main__ - train loss is 16.88694141700398\n",
      "Steps: 100%|▉| 14998/15000 [2:08:32<00:00,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:22 - INFO - __main__ - train loss is 16.887908799631987\n",
      "Steps: 100%|▉| 14999/15000 [2:08:32<00:00,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:22 - INFO - __main__ - train loss is 16.911775186716113\n",
      "Steps: 100%|█| 15000/15000 [2:08:32<00:00,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:22 - INFO - accelerate.accelerator - Saving current state to ./out/27-07/02/checkpoint-15000\n",
      "07/27/2023 19:53:22 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-27 19:53:22,289] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-27 19:53:22,293] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/27-07/02/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-27 19:53:22,293] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-27 19:53:22,299] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-27 19:53:22,300] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/27-07/02/checkpoint-15000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-27 19:53:22,306] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/27-07/02/checkpoint-15000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-27 19:53:22,306] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/27-07/02/checkpoint-15000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-27 19:53:22,306] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/27/2023 19:53:22 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/27-07/02/checkpoint-15000/pytorch_model\n",
      "07/27/2023 19:53:22 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/27-07/02/checkpoint-15000/scheduler.bin\n",
      "07/27/2023 19:53:22 - INFO - accelerate.checkpointing - Random states saved in ./out/27-07/02/checkpoint-15000/random_states_0.pkl\n",
      "07/27/2023 19:53:22 - INFO - __main__ - Saved state to ./out/27-07/02/checkpoint-15000\n",
      "Steps: 100%|█| 15000/15000 [2:08:32<00:00,  5.57it/s, lr=0.000956, step_loss=0.007/27/2023 19:53:22 - INFO - __main__ - train loss is 16.991134889482055\n",
      "Steps: : 15001it [2:08:32,  5.40it/s, lr=0.000956, step_loss=0.0794]            07/27/2023 19:53:22 - INFO - __main__ - train loss is 16.992743460519705\n",
      "Steps: : 15002it [2:08:32,  5.45it/s, lr=0.000956, step_loss=0.00161]07/27/2023 19:53:22 - INFO - __main__ - train loss is 17.067860005481634\n",
      "Steps: : 15003it [2:08:33,  5.49it/s, lr=0.000956, step_loss=0.0751] 07/27/2023 19:53:22 - INFO - __main__ - train loss is 17.353849647624884\n",
      "Steps: : 15004it [2:08:33,  5.46it/s, lr=0.000956, step_loss=0.286] 07/27/2023 19:53:23 - INFO - __main__ - train loss is 17.61423206148902\n",
      "Steps: : 15005it [2:08:33,  5.43it/s, lr=0.000956, step_loss=0.26] 07/27/2023 19:53:23 - INFO - __main__ - train loss is 17.80466925917426\n",
      "Steps: : 15006it [2:08:33,  5.46it/s, lr=0.000956, step_loss=0.19]07/27/2023 19:53:23 - INFO - __main__ - train loss is 17.97159164963523\n",
      "Steps: : 15007it [2:08:33,  5.45it/s, lr=0.000956, step_loss=0.167]07/27/2023 19:53:23 - INFO - __main__ - train loss is 17.99530385999242\n",
      "Steps: : 15008it [2:08:33,  5.45it/s, lr=0.000956, step_loss=0.0237]07/27/2023 19:53:23 - INFO - __main__ - train loss is 18.009929184860084\n",
      "Steps: : 15009it [2:08:34,  5.43it/s, lr=0.000956, step_loss=0.0146]07/27/2023 19:53:24 - INFO - __main__ - train loss is 18.238792662566993\n",
      "Steps: : 15010it [2:08:34,  5.44it/s, lr=0.000956, step_loss=0.229] 07/27/2023 19:53:24 - INFO - __main__ - train loss is 18.361875747388694\n",
      "Steps: : 15011it [2:08:34,  5.48it/s, lr=0.000956, step_loss=0.123]07/27/2023 19:53:24 - INFO - __main__ - train loss is 18.636191998666618\n",
      "Steps: : 15012it [2:08:34,  5.50it/s, lr=0.000956, step_loss=0.274]07/27/2023 19:53:24 - INFO - __main__ - train loss is 18.8216268318356\n",
      "Steps: : 15013it [2:08:34,  5.52it/s, lr=0.000956, step_loss=0.185]07/27/2023 19:53:24 - INFO - __main__ - train loss is 18.87846254283795\n",
      "Steps: : 15014it [2:08:35,  5.54it/s, lr=0.000956, step_loss=0.0568]07/27/2023 19:53:24 - INFO - __main__ - train loss is 18.88500608416507\n",
      "Steps: : 15015it [2:08:35,  5.55it/s, lr=0.000956, step_loss=0.00654]07/27/2023 19:53:25 - INFO - __main__ - train loss is 18.905760805180762\n",
      "Steps: : 15016it [2:08:35,  5.55it/s, lr=0.000956, step_loss=0.0208] 07/27/2023 19:53:25 - INFO - __main__ - train loss is 19.084307665994857\n",
      "Steps: : 15017it [2:08:35,  5.56it/s, lr=0.000956, step_loss=0.179] 07/27/2023 19:53:25 - INFO - __main__ - train loss is 19.11512670951197\n",
      "Steps: : 15018it [2:08:35,  5.56it/s, lr=0.000956, step_loss=0.0308]07/27/2023 19:53:25 - INFO - __main__ - train loss is 19.190710808208678\n",
      "Steps: : 15019it [2:08:35,  5.56it/s, lr=0.000956, step_loss=0.0756]07/27/2023 19:53:25 - INFO - __main__ - train loss is 19.200784135668073\n",
      "Steps: : 15020it [2:08:36,  5.57it/s, lr=0.000956, step_loss=0.0101]07/27/2023 19:53:26 - INFO - __main__ - train loss is 19.251983150898013\n",
      "Steps: : 15021it [2:08:36,  5.53it/s, lr=0.000956, step_loss=0.0512]07/27/2023 19:53:26 - INFO - __main__ - train loss is 19.472528621612582\n",
      "Steps: : 15022it [2:08:36,  5.49it/s, lr=0.000956, step_loss=0.221] 07/27/2023 19:53:26 - INFO - __main__ - train loss is 19.645312935172115\n",
      "Steps: : 15023it [2:08:36,  5.42it/s, lr=0.000956, step_loss=0.173]07/27/2023 19:53:26 - INFO - __main__ - train loss is 19.66015306400368\n",
      "Steps: : 15024it [2:08:36,  5.43it/s, lr=0.000956, step_loss=0.0148]07/27/2023 19:53:26 - INFO - __main__ - train loss is 19.97792244242737\n",
      "Steps: : 15025it [2:08:37,  5.47it/s, lr=0.000956, step_loss=0.318] 07/27/2023 19:53:26 - INFO - __main__ - train loss is 20.069860401621554\n",
      "Steps: : 15026it [2:08:37,  5.19it/s, lr=0.000956, step_loss=0.0919]07/27/2023 19:53:27 - INFO - __main__ - train loss is 20.137538547685836\n",
      "Steps: : 15027it [2:08:37,  4.76it/s, lr=0.000956, step_loss=0.0677]07/27/2023 19:53:27 - INFO - __main__ - train loss is 20.199112392088864\n",
      "Steps: : 15028it [2:08:37,  4.69it/s, lr=0.000956, step_loss=0.0616]07/27/2023 19:53:27 - INFO - __main__ - train loss is 20.463278806826565\n",
      "Steps: : 15029it [2:08:37,  4.78it/s, lr=0.000956, step_loss=0.264] 07/27/2023 19:53:27 - INFO - __main__ - train loss is 20.46506505209254\n",
      "Steps: : 15030it [2:08:38,  4.92it/s, lr=0.000956, step_loss=0.00179]07/27/2023 19:53:28 - INFO - __main__ - train loss is 20.84528621035861\n",
      "Steps: : 15031it [2:08:38,  5.05it/s, lr=0.000956, step_loss=0.38]   07/27/2023 19:53:28 - INFO - __main__ - train loss is 20.848959339840803\n",
      "Steps: : 15032it [2:08:38,  5.14it/s, lr=0.000956, step_loss=0.00367]07/27/2023 19:53:28 - INFO - __main__ - train loss is 20.85094355844194\n",
      "Steps: : 15033it [2:08:38,  5.22it/s, lr=0.000956, step_loss=0.00198]07/27/2023 19:53:28 - INFO - __main__ - train loss is 21.492484979855362\n",
      "Steps: : 15034it [2:08:38,  5.30it/s, lr=0.000956, step_loss=0.642]  07/27/2023 19:53:28 - INFO - __main__ - train loss is 21.49570266046794\n",
      "Steps: : 15035it [2:08:39,  5.34it/s, lr=0.000956, step_loss=0.00322]07/27/2023 19:53:28 - INFO - __main__ - train loss is 21.503687984135468\n",
      "Steps: : 15036it [2:08:39,  5.38it/s, lr=0.000956, step_loss=0.00799]07/27/2023 19:53:29 - INFO - __main__ - train loss is 21.575395754363853\n",
      "Steps: : 15037it [2:08:39,  5.39it/s, lr=0.000956, step_loss=0.0717] 07/27/2023 19:53:29 - INFO - __main__ - train loss is 21.585214558814187\n",
      "Steps: : 15038it [2:08:39,  5.41it/s, lr=0.000956, step_loss=0.00982]07/27/2023 19:53:29 - INFO - __main__ - train loss is 21.60101895761909\n",
      "Steps: : 15039it [2:08:39,  5.42it/s, lr=0.000956, step_loss=0.0158] 07/27/2023 19:53:29 - INFO - __main__ - train loss is 21.705232962791342\n",
      "Steps: : 15040it [2:08:39,  5.42it/s, lr=0.000956, step_loss=0.104] 07/27/2023 19:53:29 - INFO - __main__ - train loss is 21.848005935375113\n",
      "Steps: : 15041it [2:08:40,  5.42it/s, lr=0.000956, step_loss=0.143]07/27/2023 19:53:30 - INFO - __main__ - train loss is 22.02499102038564\n",
      "Steps: : 15042it [2:08:40,  5.42it/s, lr=0.000956, step_loss=0.177]07/27/2023 19:53:30 - INFO - __main__ - train loss is 22.165037676517386\n",
      "Steps: : 15043it [2:08:40,  5.39it/s, lr=0.000956, step_loss=0.14] 07/27/2023 19:53:30 - INFO - __main__ - train loss is 22.618805482808966\n",
      "Steps: : 15044it [2:08:40,  5.36it/s, lr=0.000956, step_loss=0.454]07/27/2023 19:53:30 - INFO - __main__ - train loss is 22.783953770820517\n",
      "Steps: : 15045it [2:08:40,  5.27it/s, lr=0.000956, step_loss=0.165]07/27/2023 19:53:30 - INFO - __main__ - train loss is 22.827254533593077\n",
      "Steps: : 15046it [2:08:41,  5.21it/s, lr=0.000956, step_loss=0.0433]07/27/2023 19:53:31 - INFO - __main__ - train loss is 23.055982857767958\n",
      "Steps: : 15047it [2:08:41,  5.15it/s, lr=0.000956, step_loss=0.229] 07/27/2023 19:53:31 - INFO - __main__ - train loss is 23.07930563186528\n",
      "Steps: : 15048it [2:08:41,  5.12it/s, lr=0.000956, step_loss=0.0233]07/27/2023 19:53:31 - INFO - __main__ - train loss is 23.450456065882463\n",
      "Steps: : 15049it [2:08:41,  5.12it/s, lr=0.000956, step_loss=0.371] 07/27/2023 19:53:31 - INFO - __main__ - train loss is 23.46351648477139\n",
      "Steps: : 15050it [2:08:41,  5.11it/s, lr=0.000956, step_loss=0.0131]07/27/2023 19:53:31 - INFO - __main__ - train loss is 24.055052351031918\n",
      "Steps: : 15051it [2:08:42,  5.12it/s, lr=0.000956, step_loss=0.592] 07/27/2023 19:53:31 - INFO - __main__ - train loss is 24.068371791217942\n",
      "Steps: : 15052it [2:08:42,  5.11it/s, lr=0.000956, step_loss=0.0133]07/27/2023 19:53:32 - INFO - __main__ - train loss is 24.07796571200015\n",
      "Steps: : 15053it [2:08:42,  5.11it/s, lr=0.000956, step_loss=0.00959]07/27/2023 19:53:32 - INFO - __main__ - train loss is 24.084314549632836\n",
      "Steps: : 15054it [2:08:42,  5.12it/s, lr=0.000956, step_loss=0.00635]07/27/2023 19:53:32 - INFO - __main__ - train loss is 24.2146310157259\n",
      "Steps: : 15055it [2:08:42,  5.12it/s, lr=0.000956, step_loss=0.13]   07/27/2023 19:53:32 - INFO - __main__ - train loss is 24.479786867566872\n",
      "Steps: : 15056it [2:08:43,  5.12it/s, lr=0.000956, step_loss=0.265]07/27/2023 19:53:32 - INFO - __main__ - train loss is 24.941756630607415\n",
      "Steps: : 15057it [2:08:43,  5.12it/s, lr=0.000956, step_loss=0.462]07/27/2023 19:53:33 - INFO - __main__ - train loss is 25.468532109924126\n",
      "Steps: : 15058it [2:08:43,  5.12it/s, lr=0.000955, step_loss=0.527]07/27/2023 19:53:33 - INFO - __main__ - train loss is 25.470024300564546\n",
      "Steps: : 15059it [2:08:43,  5.12it/s, lr=0.000955, step_loss=0.00149]07/27/2023 19:53:33 - INFO - __main__ - train loss is 25.57130188291194\n",
      "Steps: : 15060it [2:08:43,  5.12it/s, lr=0.000955, step_loss=0.101]  07/27/2023 19:53:33 - INFO - __main__ - train loss is 25.576419801742304\n",
      "Steps: : 15061it [2:08:44,  5.12it/s, lr=0.000955, step_loss=0.00512]07/27/2023 19:53:33 - INFO - __main__ - train loss is 25.579667645331938\n",
      "Steps: : 15062it [2:08:44,  5.13it/s, lr=0.000955, step_loss=0.00325]07/27/2023 19:53:34 - INFO - __main__ - train loss is 25.96952267253073\n",
      "Steps: : 15063it [2:08:44,  5.14it/s, lr=0.000955, step_loss=0.39]   07/27/2023 19:53:34 - INFO - __main__ - train loss is 25.983371396374423\n",
      "Steps: : 15064it [2:08:44,  5.12it/s, lr=0.000955, step_loss=0.0138]07/27/2023 19:53:34 - INFO - __main__ - train loss is 25.999298994254787\n",
      "Steps: : 15065it [2:08:44,  5.11it/s, lr=0.000955, step_loss=0.0159]07/27/2023 19:53:34 - INFO - __main__ - train loss is 26.263219837856013\n",
      "Steps: : 15066it [2:08:45,  5.15it/s, lr=0.000955, step_loss=0.264] 07/27/2023 19:53:34 - INFO - __main__ - train loss is 26.37128085346194\n",
      "Steps: : 15067it [2:08:45,  5.14it/s, lr=0.000955, step_loss=0.108]07/27/2023 19:53:35 - INFO - __main__ - train loss is 26.37348491261946\n",
      "Steps: : 15068it [2:08:45,  5.14it/s, lr=0.000955, step_loss=0.0022]07/27/2023 19:53:35 - INFO - __main__ - train loss is 26.38030866283225\n",
      "Steps: : 15069it [2:08:45,  5.13it/s, lr=0.000955, step_loss=0.00682]07/27/2023 19:53:35 - INFO - __main__ - train loss is 26.48342838633107\n",
      "Steps: : 15070it [2:08:45,  5.12it/s, lr=0.000955, step_loss=0.103]  07/27/2023 19:53:35 - INFO - __main__ - train loss is 26.648406205058564\n",
      "Steps: : 15071it [2:08:46,  5.12it/s, lr=0.000955, step_loss=0.165]07/27/2023 19:53:35 - INFO - __main__ - train loss is 26.65280487650307\n",
      "Steps: : 15072it [2:08:46,  5.11it/s, lr=0.000955, step_loss=0.0044]07/27/2023 19:53:36 - INFO - __main__ - train loss is 26.65684377757134\n",
      "Steps: : 15073it [2:08:46,  5.01it/s, lr=0.000955, step_loss=0.00404]07/27/2023 19:53:36 - INFO - __main__ - train loss is 26.771702613506932\n",
      "Steps: : 15074it [2:08:46,  5.04it/s, lr=0.000955, step_loss=0.115]  07/27/2023 19:53:36 - INFO - __main__ - train loss is 27.064296062861104\n",
      "Steps: : 15075it [2:08:46,  5.07it/s, lr=0.000955, step_loss=0.293]07/27/2023 19:53:36 - INFO - __main__ - train loss is 27.069375116203446\n",
      "Steps: : 15076it [2:08:47,  5.08it/s, lr=0.000955, step_loss=0.00508]07/27/2023 19:53:36 - INFO - __main__ - train loss is 27.078622765664477\n",
      "Steps: : 15077it [2:08:47,  5.09it/s, lr=0.000955, step_loss=0.00925]07/27/2023 19:53:37 - INFO - __main__ - train loss is 27.447821922425646\n",
      "Steps: : 15078it [2:08:47,  5.10it/s, lr=0.000955, step_loss=0.369]  07/27/2023 19:53:37 - INFO - __main__ - train loss is 27.795963801268954\n",
      "Steps: : 15079it [2:08:47,  5.11it/s, lr=0.000955, step_loss=0.348]07/27/2023 19:53:37 - INFO - __main__ - train loss is 27.890990309242625\n",
      "Steps: : 15080it [2:08:47,  5.11it/s, lr=0.000955, step_loss=0.095]07/27/2023 19:53:37 - INFO - __main__ - train loss is 27.920158900145907\n",
      "Steps: : 15081it [2:08:47,  5.11it/s, lr=0.000955, step_loss=0.0292]07/27/2023 19:53:37 - INFO - __main__ - train loss is 27.9285236762953\n",
      "Steps: : 15082it [2:08:48,  5.12it/s, lr=0.000955, step_loss=0.00836]07/27/2023 19:53:38 - INFO - __main__ - train loss is 27.94014268257888\n",
      "Steps: : 15083it [2:08:48,  5.12it/s, lr=0.000955, step_loss=0.0116] 07/27/2023 19:53:38 - INFO - __main__ - train loss is 27.999796300020535\n",
      "Steps: : 15084it [2:08:48,  5.12it/s, lr=0.000955, step_loss=0.0597]07/27/2023 19:53:38 - INFO - __main__ - train loss is 28.212939559307415\n",
      "Steps: : 15085it [2:08:48,  5.12it/s, lr=0.000955, step_loss=0.213] 07/27/2023 19:53:38 - INFO - __main__ - train loss is 28.29489458986791\n",
      "Steps: : 15086it [2:08:48,  5.12it/s, lr=0.000955, step_loss=0.082]07/27/2023 19:53:38 - INFO - __main__ - train loss is 28.300631025165785\n",
      "Steps: : 15087it [2:08:49,  5.12it/s, lr=0.000955, step_loss=0.00574]07/27/2023 19:53:39 - INFO - __main__ - train loss is 28.605867364734877\n",
      "Steps: : 15088it [2:08:49,  5.12it/s, lr=0.000955, step_loss=0.305]  07/27/2023 19:53:39 - INFO - __main__ - train loss is 28.74393893155502\n",
      "Steps: : 15089it [2:08:49,  5.12it/s, lr=0.000955, step_loss=0.138]07/27/2023 19:53:39 - INFO - __main__ - train loss is 28.999348529905546\n",
      "Steps: : 15090it [2:08:49,  5.12it/s, lr=0.000955, step_loss=0.255]07/27/2023 19:53:39 - INFO - __main__ - train loss is 29.065352605015505\n",
      "Steps: : 15091it [2:08:49,  5.11it/s, lr=0.000955, step_loss=0.066]07/27/2023 19:53:39 - INFO - __main__ - train loss is 29.122606047720183\n",
      "Steps: : 15092it [2:08:50,  5.12it/s, lr=0.000955, step_loss=0.0573]07/27/2023 19:53:40 - INFO - __main__ - train loss is 29.864694365591276\n",
      "Steps: : 15093it [2:08:50,  5.12it/s, lr=0.000955, step_loss=0.742] 07/27/2023 19:53:40 - INFO - __main__ - train loss is 30.315523960918654\n",
      "Steps: : 15094it [2:08:50,  5.10it/s, lr=0.000955, step_loss=0.451]07/27/2023 19:53:40 - INFO - __main__ - train loss is 30.347163030237425\n",
      "Steps: : 15095it [2:08:50,  5.11it/s, lr=0.000955, step_loss=0.0316]07/27/2023 19:53:40 - INFO - __main__ - train loss is 30.358513926446903\n",
      "Steps: : 15096it [2:08:50,  5.12it/s, lr=0.000955, step_loss=0.0114]07/27/2023 19:53:40 - INFO - __main__ - train loss is 30.428527419746388\n",
      "Steps: : 15097it [2:08:51,  5.12it/s, lr=0.000955, step_loss=0.07]  07/27/2023 19:53:40 - INFO - __main__ - train loss is 30.480236807197798\n",
      "Steps: : 15098it [2:08:51,  5.12it/s, lr=0.000955, step_loss=0.0517]07/27/2023 19:53:41 - INFO - __main__ - train loss is 30.531218865246046\n",
      "Steps: : 15099it [2:08:51,  5.12it/s, lr=0.000955, step_loss=0.051] 07/27/2023 19:53:41 - INFO - __main__ - train loss is 30.5629016396706\n",
      "Steps: : 15100it [2:08:51,  5.12it/s, lr=0.000955, step_loss=0.0317]07/27/2023 19:53:41 - INFO - __main__ - train loss is 30.630654269189108\n",
      "Steps: : 15101it [2:08:51,  5.12it/s, lr=0.000955, step_loss=0.0678]07/27/2023 19:53:41 - INFO - __main__ - train loss is 30.865170025557745\n",
      "Steps: : 15102it [2:08:52,  5.12it/s, lr=0.000955, step_loss=0.235] 07/27/2023 19:53:41 - INFO - __main__ - train loss is 30.926300567865837\n",
      "Steps: : 15103it [2:08:52,  5.18it/s, lr=0.000955, step_loss=0.0611]07/27/2023 19:53:42 - INFO - __main__ - train loss is 31.135968026996125\n",
      "Steps: : 15104it [2:08:52,  5.25it/s, lr=0.000955, step_loss=0.21]  07/27/2023 19:53:42 - INFO - __main__ - train loss is 31.141277999908198\n",
      "Steps: : 15105it [2:08:52,  5.28it/s, lr=0.000955, step_loss=0.00531]07/27/2023 19:53:42 - INFO - __main__ - train loss is 31.289590896398295\n",
      "Steps: : 15106it [2:08:52,  5.37it/s, lr=0.000955, step_loss=0.148]  07/27/2023 19:53:42 - INFO - __main__ - train loss is 31.494482786685694\n",
      "Steps: : 15107it [2:08:53,  5.43it/s, lr=0.000955, step_loss=0.205]07/27/2023 19:53:42 - INFO - __main__ - train loss is 31.5438158561592\n",
      "Steps: : 15108it [2:08:53,  5.47it/s, lr=0.000955, step_loss=0.0493]07/27/2023 19:53:43 - INFO - __main__ - train loss is 31.761135910928715\n",
      "Steps: : 15109it [2:08:53,  5.49it/s, lr=0.000955, step_loss=0.217] 07/27/2023 19:53:43 - INFO - __main__ - train loss is 31.76330073765712\n",
      "Steps: : 15110it [2:08:53,  5.50it/s, lr=0.000955, step_loss=0.00216]07/27/2023 19:53:43 - INFO - __main__ - train loss is 31.810435934283305\n",
      "Steps: : 15111it [2:08:53,  5.51it/s, lr=0.000955, step_loss=0.0471] 07/27/2023 19:53:43 - INFO - __main__ - train loss is 32.02683953783708\n",
      "Steps: : 15112it [2:08:53,  5.53it/s, lr=0.000955, step_loss=0.216] 07/27/2023 19:53:43 - INFO - __main__ - train loss is 32.31616709969239\n",
      "Steps: : 15113it [2:08:54,  5.54it/s, lr=0.000955, step_loss=0.289]07/27/2023 19:53:43 - INFO - __main__ - train loss is 32.37187079183059\n",
      "Steps: : 15114it [2:08:54,  5.55it/s, lr=0.000955, step_loss=0.0557]07/27/2023 19:53:44 - INFO - __main__ - train loss is 32.4495777770062\n",
      "Steps: : 15115it [2:08:54,  5.55it/s, lr=0.000955, step_loss=0.0777]07/27/2023 19:53:44 - INFO - __main__ - train loss is 32.49850226409035\n",
      "Steps: : 15116it [2:08:54,  5.54it/s, lr=0.000955, step_loss=0.0489]07/27/2023 19:53:44 - INFO - __main__ - train loss is 32.570244612463284\n",
      "Steps: : 15117it [2:08:54,  5.53it/s, lr=0.000955, step_loss=0.0717]07/27/2023 19:53:44 - INFO - __main__ - train loss is 32.93628525949316\n",
      "Steps: : 15118it [2:08:54,  5.52it/s, lr=0.000955, step_loss=0.366] 07/27/2023 19:53:44 - INFO - __main__ - train loss is 32.96220661170082\n",
      "Steps: : 15119it [2:08:55,  5.51it/s, lr=0.000955, step_loss=0.0259]07/27/2023 19:53:45 - INFO - __main__ - train loss is 33.403401086397935\n",
      "Steps: : 15120it [2:08:55,  5.51it/s, lr=0.000955, step_loss=0.441] 07/27/2023 19:53:45 - INFO - __main__ - train loss is 34.29058022267418\n",
      "Steps: : 15121it [2:08:55,  5.51it/s, lr=0.000955, step_loss=0.887]07/27/2023 19:53:45 - INFO - __main__ - train loss is 34.29224307468394\n",
      "Steps: : 15122it [2:08:55,  5.50it/s, lr=0.000955, step_loss=0.00166]07/27/2023 19:53:45 - INFO - __main__ - train loss is 34.312630653439555\n",
      "Steps: : 15123it [2:08:55,  5.50it/s, lr=0.000955, step_loss=0.0204] 07/27/2023 19:53:45 - INFO - __main__ - train loss is 34.40860028570751\n",
      "Steps: : 15124it [2:08:56,  5.50it/s, lr=0.000955, step_loss=0.096] 07/27/2023 19:53:45 - INFO - __main__ - train loss is 34.41489689151058\n",
      "Steps: : 15125it [2:08:56,  5.50it/s, lr=0.000955, step_loss=0.0063]07/27/2023 19:53:46 - INFO - __main__ - train loss is 34.4174902223167\n",
      "Steps: : 15126it [2:08:56,  5.50it/s, lr=0.000955, step_loss=0.00259]07/27/2023 19:53:46 - INFO - __main__ - train loss is 34.699590393167455\n",
      "Steps: : 15127it [2:08:56,  5.50it/s, lr=0.000955, step_loss=0.282]  07/27/2023 19:53:46 - INFO - __main__ - train loss is 34.70115169550991\n",
      "Steps: : 15128it [2:08:56,  5.50it/s, lr=0.000955, step_loss=0.00156]07/27/2023 19:53:46 - INFO - __main__ - train loss is 34.709569406171795\n",
      "Steps: : 15129it [2:08:56,  5.50it/s, lr=0.000955, step_loss=0.00842]07/27/2023 19:53:46 - INFO - __main__ - train loss is 34.820176732202526\n",
      "Steps: : 15130it [2:08:57,  5.44it/s, lr=0.000955, step_loss=0.111]  07/27/2023 19:53:47 - INFO - __main__ - train loss is 35.04236769344425\n",
      "Steps: : 15131it [2:08:57,  5.48it/s, lr=0.000955, step_loss=0.222]07/27/2023 19:53:47 - INFO - __main__ - train loss is 35.048332603124436\n",
      "Steps: : 15132it [2:08:57,  5.49it/s, lr=0.000955, step_loss=0.00596]07/27/2023 19:53:47 - INFO - __main__ - train loss is 35.337393076566514\n",
      "Steps: : 15133it [2:08:57,  5.51it/s, lr=0.000955, step_loss=0.289]  07/27/2023 19:53:47 - INFO - __main__ - train loss is 35.38368205860024\n",
      "Steps: : 15134it [2:08:57,  5.53it/s, lr=0.000955, step_loss=0.0463]07/27/2023 19:53:47 - INFO - __main__ - train loss is 35.5000237984932\n",
      "Steps: : 15135it [2:08:58,  5.55it/s, lr=0.000955, step_loss=0.116] 07/27/2023 19:53:47 - INFO - __main__ - train loss is 35.52764766983455\n",
      "Steps: : 15136it [2:08:58,  5.56it/s, lr=0.000955, step_loss=0.0276]07/27/2023 19:53:48 - INFO - __main__ - train loss is 35.73047312669223\n",
      "Steps: : 15137it [2:08:58,  5.57it/s, lr=0.000955, step_loss=0.203] 07/27/2023 19:53:48 - INFO - __main__ - train loss is 35.80291694722837\n",
      "Steps: : 15138it [2:08:58,  5.58it/s, lr=0.000954, step_loss=0.0724]07/27/2023 19:53:48 - INFO - __main__ - train loss is 35.84123971260851\n",
      "Steps: : 15139it [2:08:58,  5.58it/s, lr=0.000954, step_loss=0.0383]07/27/2023 19:53:48 - INFO - __main__ - train loss is 36.14221604861086\n",
      "Steps: : 15140it [2:08:58,  5.58it/s, lr=0.000954, step_loss=0.301] 07/27/2023 19:53:48 - INFO - __main__ - train loss is 36.153134516847786\n",
      "Steps: : 15141it [2:08:59,  5.58it/s, lr=0.000954, step_loss=0.0109]07/27/2023 19:53:49 - INFO - __main__ - train loss is 36.36305230058497\n",
      "Steps: : 15142it [2:08:59,  5.58it/s, lr=0.000954, step_loss=0.21]  07/27/2023 19:53:49 - INFO - __main__ - train loss is 36.36418190476252\n",
      "Steps: : 15143it [2:08:59,  5.58it/s, lr=0.000954, step_loss=0.00113]07/27/2023 19:53:49 - INFO - __main__ - train loss is 36.68552699562861\n",
      "Steps: : 15144it [2:08:59,  5.57it/s, lr=0.000954, step_loss=0.321]  07/27/2023 19:53:49 - INFO - __main__ - train loss is 37.0887840676005\n",
      "Steps: : 15145it [2:08:59,  5.57it/s, lr=0.000954, step_loss=0.403]07/27/2023 19:53:49 - INFO - __main__ - train loss is 37.27930351969553\n",
      "Steps: : 15146it [2:09:00,  5.56it/s, lr=0.000954, step_loss=0.191]07/27/2023 19:53:49 - INFO - __main__ - train loss is 37.37139831361128\n",
      "Steps: : 15147it [2:09:00,  5.55it/s, lr=0.000954, step_loss=0.0921]07/27/2023 19:53:50 - INFO - __main__ - train loss is 37.628696067899\n",
      "Steps: : 15148it [2:09:00,  5.56it/s, lr=0.000954, step_loss=0.257] 07/27/2023 19:53:50 - INFO - __main__ - train loss is 37.66421741124941\n",
      "Steps: : 15149it [2:09:00,  5.57it/s, lr=0.000954, step_loss=0.0355]07/27/2023 19:53:50 - INFO - __main__ - train loss is 37.719885020225774\n",
      "Steps: : 15150it [2:09:00,  4.11it/s, lr=0.000954, step_loss=0.0557]07/27/2023 19:53:51 - INFO - __main__ - Per validation step average loss is 0.019871661439538002\n",
      "07/27/2023 19:53:51 - INFO - __main__ - Cumulative validation average loss is 0.019871661439538002\n",
      "07/27/2023 19:53:52 - INFO - __main__ - Per validation step average loss is 0.18960413336753845\n",
      "07/27/2023 19:53:52 - INFO - __main__ - Cumulative validation average loss is 0.20947579480707645\n",
      "07/27/2023 19:53:52 - INFO - __main__ - Per validation step average loss is 0.006851814687252045\n",
      "07/27/2023 19:53:52 - INFO - __main__ - Cumulative validation average loss is 0.2163276094943285\n",
      "07/27/2023 19:53:52 - INFO - __main__ - Per validation step average loss is 0.007034665439277887\n",
      "07/27/2023 19:53:52 - INFO - __main__ - Cumulative validation average loss is 0.2233622749336064\n",
      "07/27/2023 19:53:53 - INFO - __main__ - Per validation step average loss is 0.0023627611808478832\n",
      "07/27/2023 19:53:53 - INFO - __main__ - Cumulative validation average loss is 0.22572503611445427\n",
      "07/27/2023 19:53:53 - INFO - __main__ - Per validation step average loss is 0.7671346664428711\n",
      "07/27/2023 19:53:53 - INFO - __main__ - Cumulative validation average loss is 0.9928597025573254\n",
      "07/27/2023 19:53:54 - INFO - __main__ - Per validation step average loss is 0.15496423840522766\n",
      "07/27/2023 19:53:54 - INFO - __main__ - Cumulative validation average loss is 1.147823940962553\n",
      "07/27/2023 19:53:54 - INFO - __main__ - Per validation step average loss is 0.013813797384500504\n",
      "07/27/2023 19:53:54 - INFO - __main__ - Cumulative validation average loss is 1.1616377383470535\n",
      "07/27/2023 19:53:54 - INFO - __main__ - Per validation step average loss is 0.3990158438682556\n",
      "07/27/2023 19:53:54 - INFO - __main__ - Cumulative validation average loss is 1.5606535822153091\n",
      "07/27/2023 19:53:55 - INFO - __main__ - Per validation step average loss is 0.25781679153442383\n",
      "07/27/2023 19:53:55 - INFO - __main__ - Cumulative validation average loss is 1.818470373749733\n",
      "07/27/2023 19:53:55 - INFO - __main__ - Per validation step average loss is 0.003961496986448765\n",
      "07/27/2023 19:53:55 - INFO - __main__ - Cumulative validation average loss is 1.8224318707361817\n",
      "07/27/2023 19:53:56 - INFO - __main__ - Per validation step average loss is 0.032780349254608154\n",
      "07/27/2023 19:53:56 - INFO - __main__ - Cumulative validation average loss is 1.85521221999079\n",
      "07/27/2023 19:53:56 - INFO - __main__ - Per validation step average loss is 0.051637545228004456\n",
      "07/27/2023 19:53:56 - INFO - __main__ - Cumulative validation average loss is 1.9068497652187943\n",
      "07/27/2023 19:53:57 - INFO - __main__ - Per validation step average loss is 0.0158042311668396\n",
      "07/27/2023 19:53:57 - INFO - __main__ - Cumulative validation average loss is 1.922653996385634\n",
      "07/27/2023 19:53:57 - INFO - __main__ - Per validation step average loss is 0.0522351935505867\n",
      "07/27/2023 19:53:57 - INFO - __main__ - Cumulative validation average loss is 1.9748891899362206\n",
      "07/27/2023 19:53:57 - INFO - __main__ - Per validation step average loss is 0.0014558074763044715\n",
      "07/27/2023 19:53:57 - INFO - __main__ - Cumulative validation average loss is 1.9763449974125251\n",
      "07/27/2023 19:53:58 - INFO - __main__ - Per validation step average loss is 0.0019543091766536236\n",
      "07/27/2023 19:53:58 - INFO - __main__ - Cumulative validation average loss is 1.9782993065891787\n",
      "07/27/2023 19:53:58 - INFO - __main__ - Per validation step average loss is 0.010645854286849499\n",
      "07/27/2023 19:53:58 - INFO - __main__ - Cumulative validation average loss is 1.9889451608760282\n",
      "07/27/2023 19:53:59 - INFO - __main__ - Per validation step average loss is 0.0016178921796381474\n",
      "07/27/2023 19:53:59 - INFO - __main__ - Cumulative validation average loss is 1.9905630530556664\n",
      "07/27/2023 19:53:59 - INFO - __main__ - Per validation step average loss is 0.1516822725534439\n",
      "07/27/2023 19:53:59 - INFO - __main__ - Cumulative validation average loss is 2.1422453256091103\n",
      "07/27/2023 19:53:59 - INFO - __main__ - Per validation step average loss is 0.2769496440887451\n",
      "07/27/2023 19:53:59 - INFO - __main__ - Cumulative validation average loss is 2.4191949696978554\n",
      "07/27/2023 19:54:00 - INFO - __main__ - Per validation step average loss is 0.0017618124838918447\n",
      "07/27/2023 19:54:00 - INFO - __main__ - Cumulative validation average loss is 2.4209567821817473\n",
      "07/27/2023 19:54:00 - INFO - __main__ - Per validation step average loss is 0.04295622184872627\n",
      "07/27/2023 19:54:00 - INFO - __main__ - Cumulative validation average loss is 2.4639130040304735\n",
      "07/27/2023 19:54:01 - INFO - __main__ - Per validation step average loss is 0.014415748417377472\n",
      "07/27/2023 19:54:01 - INFO - __main__ - Cumulative validation average loss is 2.478328752447851\n",
      "07/27/2023 19:54:01 - INFO - __main__ - Per validation step average loss is 0.5533985495567322\n",
      "07/27/2023 19:54:01 - INFO - __main__ - Cumulative validation average loss is 3.031727302004583\n",
      "07/27/2023 19:54:02 - INFO - __main__ - Per validation step average loss is 0.07592978328466415\n",
      "07/27/2023 19:54:02 - INFO - __main__ - Cumulative validation average loss is 3.1076570852892473\n",
      "07/27/2023 19:54:02 - INFO - __main__ - Per validation step average loss is 0.031012387946248055\n",
      "07/27/2023 19:54:02 - INFO - __main__ - Cumulative validation average loss is 3.1386694732354954\n",
      "07/27/2023 19:54:02 - INFO - __main__ - Per validation step average loss is 0.05586691200733185\n",
      "07/27/2023 19:54:02 - INFO - __main__ - Cumulative validation average loss is 3.1945363852428272\n",
      "07/27/2023 19:54:03 - INFO - __main__ - Per validation step average loss is 0.1119818165898323\n",
      "07/27/2023 19:54:03 - INFO - __main__ - Cumulative validation average loss is 3.3065182018326595\n",
      "07/27/2023 19:54:03 - INFO - __main__ - Per validation step average loss is 0.13586977124214172\n",
      "07/27/2023 19:54:03 - INFO - __main__ - Cumulative validation average loss is 3.4423879730748013\n",
      "07/27/2023 19:54:04 - INFO - __main__ - Per validation step average loss is 0.016922470182180405\n",
      "07/27/2023 19:54:04 - INFO - __main__ - Cumulative validation average loss is 3.4593104432569817\n",
      "07/27/2023 19:54:04 - INFO - __main__ - Per validation step average loss is 0.02807433158159256\n",
      "07/27/2023 19:54:04 - INFO - __main__ - Cumulative validation average loss is 3.4873847748385742\n",
      "07/27/2023 19:54:04 - INFO - __main__ - Per validation step average loss is 0.015616955235600471\n",
      "07/27/2023 19:54:04 - INFO - __main__ - Cumulative validation average loss is 3.5030017300741747\n",
      "07/27/2023 19:54:05 - INFO - __main__ - Per validation step average loss is 0.5133523344993591\n",
      "07/27/2023 19:54:05 - INFO - __main__ - Cumulative validation average loss is 4.016354064573534\n",
      "07/27/2023 19:54:05 - INFO - __main__ - Per validation step average loss is 0.0014411702286452055\n",
      "07/27/2023 19:54:05 - INFO - __main__ - Cumulative validation average loss is 4.017795234802179\n",
      "07/27/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.40089505910873413\n",
      "07/27/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 4.418690293910913\n",
      "07/27/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.013438527472317219\n",
      "07/27/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 4.43212882138323\n",
      "07/27/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.024551784619688988\n",
      "07/27/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 4.456680606002919\n",
      "07/27/2023 19:54:07 - INFO - __main__ - Per validation step average loss is 0.07716717571020126\n",
      "07/27/2023 19:54:07 - INFO - __main__ - Cumulative validation average loss is 4.533847781713121\n",
      "07/27/2023 19:54:07 - INFO - __main__ - Per validation step average loss is 0.38512736558914185\n",
      "07/27/2023 19:54:07 - INFO - __main__ - Cumulative validation average loss is 4.9189751473022625\n",
      "07/27/2023 19:54:08 - INFO - __main__ - Per validation step average loss is 0.042326245456933975\n",
      "07/27/2023 19:54:08 - INFO - __main__ - Cumulative validation average loss is 4.9613013927591965\n",
      "07/27/2023 19:54:08 - INFO - __main__ - Per validation step average loss is 0.010389969684183598\n",
      "07/27/2023 19:54:08 - INFO - __main__ - Cumulative validation average loss is 4.97169136244338\n",
      "07/27/2023 19:54:09 - INFO - __main__ - Per validation step average loss is 0.21849989891052246\n",
      "07/27/2023 19:54:09 - INFO - __main__ - Cumulative validation average loss is 5.1901912613539025\n",
      "07/27/2023 19:54:09 - INFO - __main__ - Per validation step average loss is 0.011355062946677208\n",
      "07/27/2023 19:54:09 - INFO - __main__ - Cumulative validation average loss is 5.20154632430058\n",
      "07/27/2023 19:54:09 - INFO - __main__ - Per validation step average loss is 0.0767192542552948\n",
      "07/27/2023 19:54:09 - INFO - __main__ - Cumulative validation average loss is 5.2782655785558745\n",
      "07/27/2023 19:54:10 - INFO - __main__ - Per validation step average loss is 0.11381494253873825\n",
      "07/27/2023 19:54:10 - INFO - __main__ - Cumulative validation average loss is 5.392080521094613\n",
      "07/27/2023 19:54:10 - INFO - __main__ - Per validation step average loss is 0.00678071565926075\n",
      "07/27/2023 19:54:10 - INFO - __main__ - Cumulative validation average loss is 5.3988612367538735\n",
      "07/27/2023 19:54:11 - INFO - __main__ - Per validation step average loss is 0.08166839182376862\n",
      "07/27/2023 19:54:11 - INFO - __main__ - Cumulative validation average loss is 5.480529628577642\n",
      "07/27/2023 19:54:11 - INFO - __main__ - Per validation step average loss is 0.14847338199615479\n",
      "07/27/2023 19:54:11 - INFO - __main__ - Cumulative validation average loss is 5.629003010573797\n",
      "07/27/2023 19:54:11 - INFO - __main__ - Per validation step average loss is 0.008512279018759727\n",
      "07/27/2023 19:54:11 - INFO - __main__ - Cumulative validation average loss is 5.637515289592557\n",
      "07/27/2023 19:54:12 - INFO - __main__ - Per validation step average loss is 0.02875489369034767\n",
      "07/27/2023 19:54:12 - INFO - __main__ - Cumulative validation average loss is 5.666270183282904\n",
      "07/27/2023 19:54:12 - INFO - __main__ - Per validation step average loss is 0.0796249732375145\n",
      "07/27/2023 19:54:12 - INFO - __main__ - Cumulative validation average loss is 5.745895156520419\n",
      "07/27/2023 19:54:13 - INFO - __main__ - Per validation step average loss is 0.0030321222729980946\n",
      "07/27/2023 19:54:13 - INFO - __main__ - Cumulative validation average loss is 5.748927278793417\n",
      "07/27/2023 19:54:13 - INFO - __main__ - Per validation step average loss is 0.07932472974061966\n",
      "07/27/2023 19:54:13 - INFO - __main__ - Cumulative validation average loss is 5.828252008534037\n",
      "07/27/2023 19:54:14 - INFO - __main__ - Per validation step average loss is 0.10331790894269943\n",
      "07/27/2023 19:54:14 - INFO - __main__ - Cumulative validation average loss is 5.931569917476736\n",
      "07/27/2023 19:54:14 - INFO - __main__ - Per validation step average loss is 0.009815845638513565\n",
      "07/27/2023 19:54:14 - INFO - __main__ - Cumulative validation average loss is 5.94138576311525\n",
      "07/27/2023 19:54:14 - INFO - __main__ - Per validation step average loss is 0.11888480186462402\n",
      "07/27/2023 19:54:14 - INFO - __main__ - Cumulative validation average loss is 6.060270564979874\n",
      "07/27/2023 19:54:15 - INFO - __main__ - Per validation step average loss is 0.14221683144569397\n",
      "07/27/2023 19:54:15 - INFO - __main__ - Cumulative validation average loss is 6.202487396425568\n",
      "07/27/2023 19:54:15 - INFO - __main__ - Per validation step average loss is 0.2022015005350113\n",
      "07/27/2023 19:54:15 - INFO - __main__ - Cumulative validation average loss is 6.404688896960579\n",
      "07/27/2023 19:54:16 - INFO - __main__ - Per validation step average loss is 0.1173819750547409\n",
      "07/27/2023 19:54:16 - INFO - __main__ - Cumulative validation average loss is 6.52207087201532\n",
      "07/27/2023 19:54:16 - INFO - __main__ - Per validation step average loss is 0.3351857662200928\n",
      "07/27/2023 19:54:16 - INFO - __main__ - Cumulative validation average loss is 6.8572566382354125\n",
      "07/27/2023 19:54:16 - INFO - __main__ - Per validation step average loss is 0.20675481855869293\n",
      "07/27/2023 19:54:16 - INFO - __main__ - Cumulative validation average loss is 7.0640114567941055\n",
      "07/27/2023 19:54:17 - INFO - __main__ - Per validation step average loss is 0.00465690391138196\n",
      "07/27/2023 19:54:17 - INFO - __main__ - Cumulative validation average loss is 7.068668360705487\n",
      "07/27/2023 19:54:17 - INFO - __main__ - Per validation step average loss is 0.23177659511566162\n",
      "07/27/2023 19:54:17 - INFO - __main__ - Cumulative validation average loss is 7.300444955821149\n",
      "07/27/2023 19:54:18 - INFO - __main__ - Per validation step average loss is 0.004990085493773222\n",
      "07/27/2023 19:54:18 - INFO - __main__ - Cumulative validation average loss is 7.305435041314922\n",
      "07/27/2023 19:54:18 - INFO - __main__ - Per validation step average loss is 0.01673206128180027\n",
      "07/27/2023 19:54:18 - INFO - __main__ - Cumulative validation average loss is 7.3221671025967225\n",
      "07/27/2023 19:54:19 - INFO - __main__ - Per validation step average loss is 0.007514542900025845\n",
      "07/27/2023 19:54:19 - INFO - __main__ - Cumulative validation average loss is 7.329681645496748\n",
      "07/27/2023 19:54:19 - INFO - __main__ - Per validation step average loss is 0.04411108419299126\n",
      "07/27/2023 19:54:19 - INFO - __main__ - Cumulative validation average loss is 7.37379272968974\n",
      "07/27/2023 19:54:19 - INFO - __main__ - Per validation step average loss is 0.3082997500896454\n",
      "07/27/2023 19:54:19 - INFO - __main__ - Cumulative validation average loss is 7.682092479779385\n",
      "07/27/2023 19:54:20 - INFO - __main__ - Per validation step average loss is 0.007977450266480446\n",
      "07/27/2023 19:54:20 - INFO - __main__ - Cumulative validation average loss is 7.6900699300458655\n",
      "07/27/2023 19:54:20 - INFO - __main__ - Per validation step average loss is 0.2653862237930298\n",
      "07/27/2023 19:54:20 - INFO - __main__ - Cumulative validation average loss is 7.955456153838895\n",
      "07/27/2023 19:54:21 - INFO - __main__ - Per validation step average loss is 0.07370229065418243\n",
      "07/27/2023 19:54:21 - INFO - __main__ - Cumulative validation average loss is 8.029158444493078\n",
      "07/27/2023 19:54:21 - INFO - __main__ - Per validation step average loss is 0.014747606590390205\n",
      "07/27/2023 19:54:21 - INFO - __main__ - Cumulative validation average loss is 8.043906051083468\n",
      "07/27/2023 19:54:21 - INFO - __main__ - Per validation step average loss is 0.12710364162921906\n",
      "07/27/2023 19:54:21 - INFO - __main__ - Cumulative validation average loss is 8.171009692712687\n",
      "07/27/2023 19:54:22 - INFO - __main__ - Per validation step average loss is 0.002305939793586731\n",
      "07/27/2023 19:54:22 - INFO - __main__ - Cumulative validation average loss is 8.173315632506274\n",
      "07/27/2023 19:54:22 - INFO - __main__ - Per validation step average loss is 0.07210935652256012\n",
      "07/27/2023 19:54:22 - INFO - __main__ - Cumulative validation average loss is 8.245424989028834\n",
      "07/27/2023 19:54:23 - INFO - __main__ - Per validation step average loss is 0.2699628174304962\n",
      "07/27/2023 19:54:23 - INFO - __main__ - Cumulative validation average loss is 8.51538780645933\n",
      "07/27/2023 19:54:23 - INFO - __main__ - Per validation step average loss is 0.0049733915366232395\n",
      "07/27/2023 19:54:23 - INFO - __main__ - Cumulative validation average loss is 8.520361197995953\n",
      "07/27/2023 19:54:24 - INFO - __main__ - Per validation step average loss is 0.004085459280759096\n",
      "07/27/2023 19:54:24 - INFO - __main__ - Cumulative validation average loss is 8.524446657276712\n",
      "07/27/2023 19:54:24 - INFO - __main__ - Average validation loss for Epoch 49 is 0.10790438806679382\n",
      "Model weights saved in ./out/27-07/02/pytorch_lora_weights.bin\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'conv_out_kernel', 'conv_in_kernel', 'time_cond_proj_dim', 'resnet_skip_time_act', 'resnet_time_scale_shift', 'timestep_post_act', 'encoder_hid_dim_type', 'class_embed_type', 'encoder_hid_dim', 'dual_cross_attention', 'addition_embed_type', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'class_embeddings_concat', 'only_cross_attention', 'mid_block_type', 'mid_block_only_cross_attention', 'time_embedding_act_fn', 'num_class_embeds', 'time_embedding_dim', 'use_linear_projection', 'upcast_attention', 'time_embedding_type', 'cross_attention_norm'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:03,  8.02it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:02, 12.25it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:01, 13.87it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:00<00:01, 14.56it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:00<00:01, 15.03it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:00<00:01, 15.33it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:00<00:01, 15.52it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:01<00:00, 15.64it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:01<00:00, 15.71it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:01<00:00, 15.75it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:01<00:00, 15.79it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:01<00:00, 15.82it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:01<00:00, 15.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:01<00:00, 15.84it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:01<00:00, 15.30it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:03,  8.02it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:02, 12.66it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:01, 14.15it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:00<00:01, 14.83it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:00<00:01, 15.22it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:00<00:01, 15.44it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:00<00:01, 15.58it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:01<00:00, 15.65it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:01<00:00, 15.70it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:01<00:00, 15.75it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:01<00:00, 15.79it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:01<00:00, 15.81it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:01<00:00, 15.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:01<00:00, 15.84it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:01<00:00, 15.36it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:03,  8.02it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:02, 12.64it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:01, 14.13it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:00<00:01, 14.82it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:00<00:01, 15.20it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:00<00:01, 15.45it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:00<00:01, 15.64it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:01<00:00, 15.70it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:01<00:00, 15.80it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:01<00:00, 15.86it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:01<00:00, 15.92it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:01<00:00, 15.95it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:01<00:00, 15.96it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:01<00:00, 15.98it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:01<00:00, 15.45it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:03,  8.07it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:02, 12.78it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:01, 14.26it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:00<00:01, 14.94it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:00<00:01, 15.32it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:00<00:01, 15.55it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:00<00:01, 15.68it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:01<00:00, 15.73it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:01<00:00, 15.80it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:01<00:00, 15.86it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:01<00:00, 15.87it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:01<00:00, 15.89it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:01<00:00, 15.91it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:01<00:00, 15.91it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:01<00:00, 15.45it/s]\u001b[A\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 4235.193 MB of 4235.193 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_train_loss_per_epoch █▃▅▅▃▂▄▄█▄▄▄▄▂▅▄▄▅▅▃▃▅▆▄▆▁▄▆▇▅▅▁▇▄▃▆▃▃▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_valid_loss_per_epoch ▄▆▄▅▅▃▆▃▄▇▂▄▇▅▂▃▇▃▂█▄▁▅▆▅▆▂▆▅▃▅▃▆▆█▇▅▅▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       training_step_loss ▅▄▁▃▁▅▁▂▁▄▁▅▁▁▁▂▁█▁▂▃▂▁▁▂▃▃▁▁▂▁▁▂▁▁▁▁▃▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_train_loss_per_epoch 0.12449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_valid_loss_per_epoch 0.1079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       training_step_loss 0.05567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmajor-dawn-147\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/3s4fa9rp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 6662 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230727_174444-3s4fa9rp/logs\u001b[0m\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2085: UserWarning: Run (3s4fa9rp) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "Steps: : 15150it [2:09:59,  1.94it/s, lr=0.000954, step_loss=0.0557]\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-03 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --validation_epochs=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=2000 \\\n",
    "  --output_dir=$\"./out/27-07/02\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of acoustic guitar\" \\\n",
    "  --validation_prompt2=\"A spectrogram of cheering\" \\\n",
    "  --validation_prompt3=\"A spectrogram of dog bark\" \\\n",
    "  --validation_prompt4=\"A spectrogram of snare drum\" \\\n",
    "  --validation_prompt5=\"A spectrogram of train horn\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
