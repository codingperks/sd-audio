{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-17 13:01:02,077] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a788ba10105d48598f549caabeaea053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-da7eee62ee4928aa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e32c2452134146b6e56369e71d09c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b643eecb37ca4bde9811cd01dabc83b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3c5d7a59c7443d97127d889aeb4de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a61a44612a4b91a3e8984909b0b2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-da7eee62ee4928aa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-17 11:17:42,898] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-17 11:17:44,971] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-17 11:17:46,158] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-17 11:17:46,158] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-17 11:17:46,158] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/17/2023 11:17:46 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'variance_type', 'sample_max_value', 'clip_sample_range', 'prediction_type', 'thresholding', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'dual_cross_attention', 'conv_out_kernel', 'encoder_hid_dim_type', 'use_linear_projection', 'conv_in_kernel', 'addition_embed_type', 'resnet_time_scale_shift', 'encoder_hid_dim', 'class_embed_type', 'resnet_out_scale_factor', 'upcast_attention', 'addition_embed_type_num_heads', 'mid_block_type', 'time_embedding_type', 'time_embedding_act_fn', 'mid_block_only_cross_attention', 'only_cross_attention', 'num_class_embeds', 'cross_attention_norm', 'resnet_skip_time_act', 'time_embedding_dim', 'projection_class_embeddings_input_dim', 'time_cond_proj_dim', 'timestep_post_act', 'class_embeddings_concat'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|███████████████| 123/123 [00:00<00:00, 672619.81it/s]\n",
      "07/17/2023 11:17:49 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-c5ce92831c385eb9/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1123.27it/s]\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.1910717487335205 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-17 11:17:54,108] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/17/2023 11:17:54 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/17/2023 11:17:54 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-17 11:17:54,143] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-17 11:17:54,143] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-17 11:17:54,143] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-17 11:17:54,149] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 11:17:54,149] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-17 11:17:54,149] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-17 11:17:54,149] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-17 11:17:54,149] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-17 11:17:54,149] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-17 11:17:54,149] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0733332633972168 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-17 11:17:54,339] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-17 11:17:54,339] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 11:17:54,339] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 7.0 GB, percent = 45.0%\n",
      "[2023-07-17 11:17:54,444] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-17 11:17:54,445] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 11:17:54,445] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 7.0 GB, percent = 45.1%\n",
      "[2023-07-17 11:17:54,445] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-17 11:17:54,539] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-17 11:17:54,539] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 11:17:54,539] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 7.0 GB, percent = 45.1%\n",
      "[2023-07-17 11:17:54,544] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 11:17:54,544] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-17 11:17:54,544] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-17 11:17:54,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[(0.9, 0.999)]\n",
      "[2023-07-17 11:17:54,544] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f407cb95ff0>\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-17 11:17:54,545] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-17 11:17:54,546] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0001964569091796875 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230717_111755-6ubxfixm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-mountain-40\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/6ubxfixm\u001b[0m\n",
      "07/17/2023 11:18:00 - INFO - __main__ - ***** Running training *****\n",
      "07/17/2023 11:18:00 - INFO - __main__ -   Num examples = 122\n",
      "07/17/2023 11:18:00 - INFO - __main__ -   Num Epochs = 484\n",
      "07/17/2023 11:18:00 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/17/2023 11:18:00 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/17/2023 11:18:00 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/17/2023 11:18:00 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s][2023-07-17 11:18:02,698] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|   | 1/15000 [00:02<8:57:18,  2.15s/it, lr=0.0001, step_loss=0.0114][2023-07-17 11:18:03,490] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|    | 2/15000 [00:02<5:37:37,  1.35s/it, lr=0.0001, step_loss=0.292][2023-07-17 11:18:04,280] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|    | 3/15000 [00:03<4:33:37,  1.09s/it, lr=0.0001, step_loss=0.258][2023-07-17 11:18:05,073] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|    | 4/15000 [00:04<4:03:48,  1.03it/s, lr=0.0001, step_loss=0.913][2023-07-17 11:18:05,876] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|    | 6/15000 [00:06<3:39:36,  1.14it/s, lr=0.0001, step_loss=0.021][2023-07-17 11:18:07,487] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|    | 7/15000 [00:06<3:33:04,  1.17it/s, lr=0.0001, step_loss=0.318][2023-07-17 11:18:08,286] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|    | 8/15000 [00:07<3:28:47,  1.20it/s, lr=0.0001, step_loss=0.388][2023-07-17 11:18:09,082] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|  | 10/15000 [00:09<3:23:45,  1.23it/s, lr=0.0001, step_loss=0.0973][2023-07-17 11:18:10,681] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%|    | 67/15000 [00:55<3:21:00,  1.24it/s, lr=0.0001, step_loss=0.12]^C\n",
      "\u001b[2;36m[11:18:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Received \u001b[1;36m2\u001b[0m death signal, shutting down workers    \u001b]8;id=79468;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625589;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py#729\u001b\\\u001b[2m729\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Sending process \u001b[1;36m15084\u001b[0m closing signal SIGINT       \u001b]8;id=446230;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=763997;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#698\u001b\\\u001b[2m698\u001b[0m\u001b]8;;\u001b\\\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f40ddf23910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 996, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 778, in main\n",
      "    wandb.log({\"training_images_audio\": [wandb.Audio(image_to_audio(image), sample_rate = 44100, caption=f\"Step {step}\")]})\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 106, in image_to_audio\n",
      "    segment = converter.audio_from_spectrogram_image(\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/../../../data/utils/spectrogram_image_converter.py\", line 85, in audio_from_spectrogram_image\n",
      "    segment = self.converter.audio_from_spectrogram(\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/../../../data/utils/spectrogram_converter.py\", line 146, in audio_from_spectrogram\n",
      "    waveform = self.waveform_from_mel_amplitudes(amplitudes_mel)\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/../../../data/utils/spectrogram_converter.py\", line 201, in waveform_from_mel_amplitudes\n",
      "    amplitudes_linear = self.inverse_mel_scaler(amplitudes_mel)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torchaudio/transforms/_transforms.py\", line 519, in forward\n",
      "    new_loss.backward()\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m996\u001b[0m in \u001b[92m<module>\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m993 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m994 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m995 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m996 \u001b[2m│   \u001b[0mmain()                                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m997 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m778\u001b[0m in \u001b[92mmain\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m775 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m776 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Log the batch of training images and audio\u001b[0m               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m777 \u001b[0m\u001b[2m│   │   │   \u001b[0mwandb.log({\u001b[33m\"\u001b[0m\u001b[33mtraining_images\u001b[0m\u001b[33m\"\u001b[0m: [wandb.Image(batch[\u001b[33m\"\u001b[0m\u001b[33mpixel_va\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m778 \u001b[2m│   │   │   \u001b[0mwandb.log({\u001b[33m\"\u001b[0m\u001b[33mtraining_images_audio\u001b[0m\u001b[33m\"\u001b[0m: [wandb.Audio(image_to_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m779 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m780 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m accelerator.accumulate(unet):                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m781 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Convert images to latent space\u001b[0m                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m106\u001b[0m in \u001b[92mimage_to_audio\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   \u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0mconverter = SpectrogramImageConverter(params=param_sets[\u001b[33m\"\u001b[0m\u001b[33mdefault\u001b[0m\u001b[33m\"\u001b[0m] \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m106 \u001b[2m│   \u001b[0msegment = converter.audio_from_spectrogram_image(                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   \u001b[0mimage=image,                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0mapply_filters=\u001b[94mTrue\u001b[0m                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   \u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/../../../data/utils/\u001b[0m\u001b[1;33mspect\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mrogram_image_converter.py\u001b[0m:\u001b[94m85\u001b[0m in \u001b[92maudio_from_spectrogram_image\u001b[0m                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m82 \u001b[0m\u001b[2m│   │   │   \u001b[0mstereo=\u001b[96mself\u001b[0m.p.stereo,                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m83 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m84 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m85 \u001b[2m│   │   \u001b[0msegment = \u001b[96mself\u001b[0m.converter.audio_from_spectrogram(                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m86 \u001b[0m\u001b[2m│   │   │   \u001b[0mspectrogram,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m87 \u001b[0m\u001b[2m│   │   │   \u001b[0mapply_filters=apply_filters,                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m88 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/../../../data/utils/\u001b[0m\u001b[1;33mspect\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mrogram_converter.py\u001b[0m:\u001b[94m146\u001b[0m in \u001b[92maudio_from_spectrogram\u001b[0m                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   \u001b[0mamplitudes_mel = torch.from_numpy(spectrogram).to(\u001b[96mself\u001b[0m.device) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m145 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Reconstruct the waveform\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m146 \u001b[2m│   │   \u001b[0mwaveform = \u001b[96mself\u001b[0m.waveform_from_mel_amplitudes(amplitudes_mel)   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Convert to audio segment\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m149 \u001b[0m\u001b[2m│   │   \u001b[0msegment = audio_util.audio_from_waveform(                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/../../../data/utils/\u001b[0m\u001b[1;33mspect\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mrogram_converter.py\u001b[0m:\u001b[94m201\u001b[0m in \u001b[92mwaveform_from_mel_amplitudes\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mwaveform: (batch, samples)\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Convert from mel scale to linear\u001b[0m                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   \u001b[0mamplitudes_linear = \u001b[96mself\u001b[0m.inverse_mel_scaler(amplitudes_mel)    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Run the approximate algorithm to compute the phase and recov\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.inverse_spectrogram_func(amplitudes_linear)        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/mo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mdules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torchaudio/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtransforms/\u001b[0m\u001b[1;33m_transforms.py\u001b[0m:\u001b[94m519\u001b[0m in \u001b[92mforward\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 516 \u001b[0m\u001b[2m│   │   │   \u001b[0mnew_loss = diff.pow(\u001b[94m2\u001b[0m).sum(axis=-\u001b[94m1\u001b[0m).mean()                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 517 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# take sum over mel-frequency then average over other dim\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 518 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# so that loss threshold is applied par unit timeframe\u001b[0m    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 519 \u001b[2m│   │   │   \u001b[0mnew_loss.backward()                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 520 \u001b[0m\u001b[2m│   │   │   \u001b[0moptim.step()                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 521 \u001b[0m\u001b[2m│   │   │   \u001b[0mspecgram.data = specgram.data.clamp(\u001b[96mmin\u001b[0m=\u001b[94m0\u001b[0m)                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 522 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33m_tens\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/autog\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mrad/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line fu\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ eng\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into th\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-04 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/17-07\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-17 10:27:34,906] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-17 10:27:37,001] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-17 10:27:38,196] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-17 10:27:38,196] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-17 10:27:38,196] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/17/2023 10:27:38 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'clip_sample_range', 'thresholding', 'sample_max_value', 'prediction_type', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'time_cond_proj_dim', 'conv_out_kernel', 'dual_cross_attention', 'resnet_time_scale_shift', 'use_linear_projection', 'time_embedding_dim', 'only_cross_attention', 'class_embeddings_concat', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'timestep_post_act', 'time_embedding_act_fn', 'addition_embed_type', 'encoder_hid_dim', 'num_class_embeds', 'time_embedding_type', 'class_embed_type', 'encoder_hid_dim_type', 'mid_block_type', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'resnet_out_scale_factor', 'cross_attention_norm', 'upcast_attention', 'mid_block_only_cross_attention'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|███████████████| 123/123 [00:00<00:00, 555327.66it/s]\n",
      "07/17/2023 10:27:41 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-c5ce92831c385eb9/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1156.73it/s]\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.1926474571228027 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-17 10:27:46,312] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/17/2023 10:27:46 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/17/2023 10:27:46 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-17 10:27:46,346] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-17 10:27:46,347] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-17 10:27:46,347] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-17 10:27:46,353] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 10:27:46,353] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-17 10:27:46,353] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07414817810058594 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-17 10:27:46,561] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-17 10:27:46,561] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 10:27:46,561] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 6.83 GB, percent = 43.9%\n",
      "[2023-07-17 10:27:46,665] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-17 10:27:46,666] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 10:27:46,666] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 6.83 GB, percent = 44.0%\n",
      "[2023-07-17 10:27:46,666] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-17 10:27:46,761] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-17 10:27:46,761] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 10:27:46,761] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 6.83 GB, percent = 44.0%\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f59f85e6080>\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00019621849060058594 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230717_102747-5jbkskba\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvolcanic-dew-27\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/5jbkskba\u001b[0m\n",
      "07/17/2023 10:27:52 - INFO - __main__ - ***** Running training *****\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Num examples = 122\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Num Epochs = 484\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1000, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 779, in main\n",
      "    image_grid = make_grid(pixel_values)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torchvision/utils.py\", line 63, in make_grid\n",
      "    raise TypeError(f\"tensor or list of tensors expected, got {type(tensor)}\")\n",
      "TypeError: tensor or list of tensors expected, got <class 'numpy.ndarray'>\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1000\u001b[0m in \u001b[92m<module>\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 997 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 998 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 999 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1000 \u001b[2m│   \u001b[0mmain()                                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1001 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m779\u001b[0m in \u001b[92mmain\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 776 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids = input_ids.cpu().numpy()                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 777 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 778 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Create a grid of images\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 779 \u001b[2m│   │   │   \u001b[0mimage_grid = make_grid(pixel_values)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 780 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 781 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Log the batch of images\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 782 \u001b[0m\u001b[2m│   │   │   \u001b[0mwandb.log({\u001b[33m\"\u001b[0m\u001b[33mbatch_images\u001b[0m\u001b[33m\"\u001b[0m: [wandb.Image(image_grid, capti \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torchvision\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m63\u001b[0m in \u001b[92mmake_grid\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m torch.is_tensor(t):                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mtensor or list of tensors expect\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 63 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mtensor or list of tensors expected, got \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# if list of tensors, convert to a 4D mini-batch Tensor\u001b[0m            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(tensor, \u001b[96mlist\u001b[0m):                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mTypeError: \u001b[0mtensor or list of tensors expected, got \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'numpy.ndarray'\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvolcanic-dew-27\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/5jbkskba\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230717_102747-5jbkskba/logs\u001b[0m\n",
      "\u001b[2;36m[10:28:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m10562\u001b[0m\u001b[1m)\u001b[0m   \u001b]8;id=417658;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=286919;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#672\u001b\\\u001b[2m672\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         of binary:                                        \u001b[2m          \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[35m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[95mpython\u001b[0m    \u001b[2m          \u001b[0m\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m926\u001b[0m in \u001b[92mlaunch_command\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m923 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m924 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m925 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m926 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m927 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m928 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m929 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m671\u001b[0m in \u001b[92mdeepspeed_launcher\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m668 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m669 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m670 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m671 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m672 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m673 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m674 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m785\u001b[0m in \u001b[92mrun\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m782 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m783 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m784 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m785 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92m__call__\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mChildFailedError: \u001b[0m\n",
      "============================================================\n",
      "train_text_to_image_lora.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  \u001b[1m<\u001b[0m\u001b[1;95mNO_OTHER_FAILURES\u001b[0m\u001b[39m>\u001b[0m\n",
      "\u001b[39m------------------------------------------------------------\u001b[0m\n",
      "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m07\u001b[0m\u001b[39m-17_\u001b[0m\u001b[1;92m10:28:00\u001b[0m\n",
      "\u001b[39m  host      : honeybone.lan\u001b[0m\n",
      "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m10562\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
      "  traceback : To enable traceback see: \n",
      "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/13-07/2\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
