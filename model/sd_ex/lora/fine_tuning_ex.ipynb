{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19 12:32:19,537] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87822ed83f464169b722ef8107b923f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5782384a014eb4ad9eea06c1f6c6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789d2d98f3864f90810f1005daca42dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40a78d6f8664576bf83ab1c93d9cc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbeec814ab1473a928b797f8b14154c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" , split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=501x512>,\n",
       " 'prompt': 'a spectrogram of bird song',\n",
       " 'audiofile': './data/Bird vocalization-bird call-bird song/train/-aC8TJIZrtE.wav'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-24 20:03:27,282] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-24 20:03:29,391] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-24 20:03:30,553] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-24 20:03:30,553] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-24 20:03:30,553] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/24/2023 20:03:30 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'prediction_type', 'clip_sample_range', 'thresholding', 'dynamic_thresholding_ratio', 'sample_max_value', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'dual_cross_attention', 'class_embeddings_concat', 'use_linear_projection', 'cross_attention_norm', 'time_embedding_dim', 'num_class_embeds', 'resnet_out_scale_factor', 'resnet_time_scale_shift', 'upcast_attention', 'conv_out_kernel', 'time_cond_proj_dim', 'time_embedding_act_fn', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention', 'conv_in_kernel', 'only_cross_attention', 'resnet_skip_time_act', 'encoder_hid_dim', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type', 'addition_embed_type', 'timestep_post_act', 'class_embed_type', 'time_embedding_type', 'mid_block_type'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 621/621 [00:00<00:00, 779139.33it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 327/327 [00:00<00:00, 681678.63it/s]\n",
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-1fc5199879f5ac42/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n",
      "Downloading data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308/308 [00:00<00:00, 158236.85it/s]\n",
      "Downloading data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:00<00:00, 159419.20it/s]\n",
      "Extracting data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:00<00:00, 4915.76it/s]\n",
      "Downloading data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [00:00<00:00, 153893.10it/s]\n",
      "Downloading data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 166/166 [00:00<00:00, 155240.68it/s]\n",
      "Extracting data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 166/166 [00:00<00:00, 5205.76it/s]\n",
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-1fc5199879f5ac42/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 525.44it/s]\n",
      "07/24/2023 20:03:35 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (1).\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.191807508468628 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-24 20:03:39,381] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/24/2023 20:03:39 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/24/2023 20:03:39 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-24 20:03:39,416] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-24 20:03:39,416] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-24 20:03:39,417] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-24 20:03:39,422] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-24 20:03:39,422] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-24 20:03:39,422] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-24 20:03:39,422] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-24 20:03:39,422] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-24 20:03:39,422] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-24 20:03:39,422] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.09087061882019043 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-24 20:03:39,654] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-24 20:03:39,655] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-24 20:03:39,655] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.6 GB, percent = 55.4%\n",
      "[2023-07-24 20:03:39,760] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-24 20:03:39,761] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-24 20:03:39,761] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.61 GB, percent = 55.4%\n",
      "[2023-07-24 20:03:39,761] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-24 20:03:39,855] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-24 20:03:39,856] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-24 20:03:39,856] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.61 GB, percent = 55.4%\n",
      "[2023-07-24 20:03:39,860] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-24 20:03:39,860] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-24 20:03:39,860] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-24 20:03:39,860] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4ead6e1480>\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-24 20:03:39,861] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-24 20:03:39,862] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00019311904907226562 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230724_200340-5l9anduk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcool-lake-135\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/5l9anduk\u001b[0m\n",
      "07/24/2023 20:03:45 - INFO - __main__ - ***** Running training *****\n",
      "07/24/2023 20:03:45 - INFO - __main__ -   Num examples = 307\n",
      "07/24/2023 20:03:45 - INFO - __main__ -   Num Epochs = 195\n",
      "07/24/2023 20:03:45 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/24/2023 20:03:45 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/24/2023 20:03:45 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/24/2023 20:03:45 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]07/24/2023 20:03:45 - INFO - __main__ - Starting epoch 0\n",
      "07/24/2023 20:03:48 - INFO - __main__ - train loss is 0.30149734020233154\n",
      "[2023-07-24 20:03:48,513] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|        | 1/15000 [00:02<11:39:16,  2.80s/it, lr=0, step_loss=0.301]07/24/2023 20:03:48 - INFO - __main__ - train loss is 0.3898477256298065\n",
      "[2023-07-24 20:03:49,045] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|        | 2/15000 [00:03<6:06:13,  1.47s/it, lr=0, step_loss=0.0884]07/24/2023 20:03:49 - INFO - __main__ - train loss is 0.797949343919754\n",
      "[2023-07-24 20:03:49,575] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|         | 3/15000 [00:03<4:19:24,  1.04s/it, lr=0, step_loss=0.408]07/24/2023 20:03:50 - INFO - __main__ - train loss is 0.8609022498130798\n",
      "[2023-07-24 20:03:50,103] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|         | 4/15000 [00:04<3:29:03,  1.20it/s, lr=0, step_loss=0.063]07/24/2023 20:03:50 - INFO - __main__ - train loss is 0.9782845228910446\n",
      "[2023-07-24 20:03:50,631] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|         | 5/15000 [00:04<3:01:18,  1.38it/s, lr=0, step_loss=0.117]07/24/2023 20:03:51 - INFO - __main__ - train loss is 1.1223269402980804\n",
      "[2023-07-24 20:03:51,170] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|         | 6/15000 [00:05<2:45:25,  1.51it/s, lr=0, step_loss=0.144]07/24/2023 20:03:51 - INFO - __main__ - train loss is 1.2722578644752502\n",
      "[2023-07-24 20:03:51,698] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|          | 7/15000 [00:05<2:34:29,  1.62it/s, lr=0, step_loss=0.15]07/24/2023 20:03:52 - INFO - __main__ - train loss is 1.523135781288147\n",
      "[2023-07-24 20:03:52,233] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|         | 8/15000 [00:06<2:27:48,  1.69it/s, lr=0, step_loss=0.251]07/24/2023 20:03:52 - INFO - __main__ - train loss is 1.5273321121931076\n",
      "Steps:   0%|   | 9/15000 [00:07<2:23:12,  1.74it/s, lr=2.5e-9, step_loss=0.0042]07/24/2023 20:03:53 - INFO - __main__ - train loss is 1.7229731678962708\n",
      "[2023-07-24 20:03:53,290] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%|   | 10/15000 [00:07<2:19:24,  1.79it/s, lr=2.5e-9, step_loss=0.196]07/24/2023 20:03:53 - INFO - __main__ - train loss is 1.747794322669506\n",
      "Steps:   0%|    | 11/15000 [00:08<2:17:00,  1.82it/s, lr=5e-9, step_loss=0.0248]07/24/2023 20:03:54 - INFO - __main__ - train loss is 1.8411423489451408\n",
      "Steps:   0%|  | 12/15000 [00:08<2:15:45,  1.84it/s, lr=7.5e-9, step_loss=0.0933]07/24/2023 20:03:54 - INFO - __main__ - train loss is 1.8447197240311652\n",
      "Steps:   0%|   | 13/15000 [00:09<2:14:51,  1.85it/s, lr=1e-8, step_loss=0.00358]07/24/2023 20:03:55 - INFO - __main__ - train loss is 1.9341148894745857\n",
      "[2023-07-24 20:03:55,412] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   0%|    | 14/15000 [00:09<2:14:13,  1.86it/s, lr=1e-8, step_loss=0.0894]07/24/2023 20:03:55 - INFO - __main__ - train loss is 2.0026068550068885\n",
      "Steps:   0%| | 15/15000 [00:10<2:13:55,  1.86it/s, lr=1.25e-8, step_loss=0.0685]07/24/2023 20:03:56 - INFO - __main__ - train loss is 2.0445822302717716\n",
      "Steps:   0%|   | 16/15000 [00:10<2:13:50,  1.87it/s, lr=1.5e-8, step_loss=0.042]07/24/2023 20:03:56 - INFO - __main__ - train loss is 2.2917600844521075\n",
      "Steps:   0%|  | 17/15000 [00:11<2:13:13,  1.87it/s, lr=1.75e-8, step_loss=0.247]07/24/2023 20:03:57 - INFO - __main__ - train loss is 2.622616169275716\n",
      "Steps:   0%|     | 18/15000 [00:11<2:12:28,  1.88it/s, lr=2e-8, step_loss=0.331]07/24/2023 20:03:57 - INFO - __main__ - train loss is 2.6660738822538406\n",
      "Steps:   0%| | 19/15000 [00:12<2:12:03,  1.89it/s, lr=2.25e-8, step_loss=0.0435]07/24/2023 20:03:58 - INFO - __main__ - train loss is 2.722363115521148\n",
      "Steps:   0%|  | 20/15000 [00:12<2:12:38,  1.88it/s, lr=2.5e-8, step_loss=0.0563]07/24/2023 20:03:59 - INFO - __main__ - train loss is 2.7357744046021253\n",
      "Steps:   0%| | 21/15000 [00:13<2:12:26,  1.89it/s, lr=2.75e-8, step_loss=0.0134]07/24/2023 20:03:59 - INFO - __main__ - train loss is 2.752733401255682\n",
      "Steps:   0%|     | 22/15000 [00:13<2:11:56,  1.89it/s, lr=3e-8, step_loss=0.017]07/24/2023 20:04:00 - INFO - __main__ - train loss is 2.777285772608593\n",
      "Steps:   0%| | 23/15000 [00:14<2:11:57,  1.89it/s, lr=3.25e-8, step_loss=0.0246]07/24/2023 20:04:00 - INFO - __main__ - train loss is 2.9411581933964044\n",
      "Steps:   0%|   | 24/15000 [00:14<2:11:26,  1.90it/s, lr=3.5e-8, step_loss=0.164]07/24/2023 20:04:01 - INFO - __main__ - train loss is 2.9707031392026693\n",
      "Steps:   0%| | 25/15000 [00:15<2:11:46,  1.89it/s, lr=3.75e-8, step_loss=0.0295]07/24/2023 20:04:01 - INFO - __main__ - train loss is 3.0121919803787023\n",
      "Steps:   0%|    | 26/15000 [00:16<2:13:00,  1.88it/s, lr=4e-8, step_loss=0.0415]07/24/2023 20:04:02 - INFO - __main__ - train loss is 3.128328486578539\n",
      "Steps:   0%|  | 27/15000 [00:16<2:14:22,  1.86it/s, lr=4.25e-8, step_loss=0.116]07/24/2023 20:04:02 - INFO - __main__ - train loss is 3.17620727350004\n",
      "Steps:   0%|  | 28/15000 [00:17<2:13:58,  1.86it/s, lr=4.5e-8, step_loss=0.0479]07/24/2023 20:04:03 - INFO - __main__ - train loss is 3.1810233166906983\n",
      "Steps:   0%| | 29/15000 [00:17<2:14:09,  1.86it/s, lr=4.75e-8, step_loss=0.0048207/24/2023 20:04:03 - INFO - __main__ - train loss is 3.192358172731474\n",
      "Steps:   0%|    | 30/15000 [00:18<2:14:02,  1.86it/s, lr=5e-8, step_loss=0.0113]07/24/2023 20:04:04 - INFO - __main__ - train loss is 3.268837533192709\n",
      "Steps:   0%| | 31/15000 [00:18<2:13:14,  1.87it/s, lr=5.25e-8, step_loss=0.0765]07/24/2023 20:04:04 - INFO - __main__ - train loss is 3.275648020906374\n",
      "Steps:   0%| | 32/15000 [00:19<2:13:15,  1.87it/s, lr=5.5e-8, step_loss=0.00681]07/24/2023 20:04:05 - INFO - __main__ - train loss is 3.2783357517328113\n",
      "Steps:   0%| | 33/15000 [00:19<2:13:01,  1.88it/s, lr=5.75e-8, step_loss=0.0026907/24/2023 20:04:05 - INFO - __main__ - train loss is 3.286615896737203\n",
      "Steps:   0%|   | 34/15000 [00:20<2:13:20,  1.87it/s, lr=6e-8, step_loss=0.00828]07/24/2023 20:04:06 - INFO - __main__ - train loss is 3.3933281486388296\n",
      "Steps:   0%|  | 35/15000 [00:20<2:13:24,  1.87it/s, lr=6.25e-8, step_loss=0.107]07/24/2023 20:04:07 - INFO - __main__ - train loss is 3.83184577873908\n",
      "Steps:   0%|   | 36/15000 [00:21<2:13:23,  1.87it/s, lr=6.5e-8, step_loss=0.439]07/24/2023 20:04:07 - INFO - __main__ - train loss is 4.236546773230657\n",
      "Steps:   0%|  | 37/15000 [00:21<2:13:04,  1.87it/s, lr=6.75e-8, step_loss=0.405]07/24/2023 20:04:08 - INFO - __main__ - train loss is 4.252395186340436\n",
      "Steps:   0%|    | 38/15000 [00:22<2:12:42,  1.88it/s, lr=7e-8, step_loss=0.0158]07/24/2023 20:04:08 - INFO - __main__ - train loss is 4.454335812246427\n",
      "Steps:   0%|  | 39/15000 [00:23<2:12:18,  1.88it/s, lr=7.25e-8, step_loss=0.202]07/24/2023 20:04:09 - INFO - __main__ - train loss is 4.665601167595014\n",
      "Steps:   0%|   | 40/15000 [00:23<2:12:22,  1.88it/s, lr=7.5e-8, step_loss=0.211]07/24/2023 20:04:09 - INFO - __main__ - train loss is 4.890853289281949\n",
      "Steps:   0%|  | 41/15000 [00:24<2:12:22,  1.88it/s, lr=7.75e-8, step_loss=0.225]07/24/2023 20:04:10 - INFO - __main__ - train loss is 4.894124037353322\n",
      "Steps:   0%|   | 42/15000 [00:24<2:12:37,  1.88it/s, lr=8e-8, step_loss=0.00327]07/24/2023 20:04:10 - INFO - __main__ - train loss is 4.946748810587451\n",
      "Steps:   0%| | 43/15000 [00:25<2:12:26,  1.88it/s, lr=8.25e-8, step_loss=0.0526]07/24/2023 20:04:11 - INFO - __main__ - train loss is 5.006886447547004\n",
      "Steps:   0%|  | 44/15000 [00:25<2:11:52,  1.89it/s, lr=8.5e-8, step_loss=0.0601]07/24/2023 20:04:11 - INFO - __main__ - train loss is 5.012784074759111\n",
      "Steps:   0%| | 45/15000 [00:26<2:11:54,  1.89it/s, lr=8.75e-8, step_loss=0.0059]07/24/2023 20:04:12 - INFO - __main__ - train loss is 5.169274057960138\n",
      "Steps:   0%|     | 46/15000 [00:26<2:11:54,  1.89it/s, lr=9e-8, step_loss=0.156]07/24/2023 20:04:12 - INFO - __main__ - train loss is 5.325938906287774\n",
      "Steps:   0%|  | 47/15000 [00:27<2:11:40,  1.89it/s, lr=9.25e-8, step_loss=0.157]07/24/2023 20:04:13 - INFO - __main__ - train loss is 5.428211506223306\n",
      "Steps:   0%|   | 48/15000 [00:27<2:11:41,  1.89it/s, lr=9.5e-8, step_loss=0.102]07/24/2023 20:04:13 - INFO - __main__ - train loss is 5.528309348737821\n",
      "Steps:   0%|    | 49/15000 [00:28<2:11:51,  1.89it/s, lr=9.75e-8, step_loss=0.1]07/24/2023 20:04:14 - INFO - __main__ - train loss is 5.770009074127302\n",
      "Steps:   0%|     | 50/15000 [00:28<2:12:29,  1.88it/s, lr=1e-7, step_loss=0.242]07/24/2023 20:04:14 - INFO - __main__ - train loss is 6.179666552459821\n",
      "Steps:   0%|   | 51/15000 [00:29<2:12:23,  1.88it/s, lr=1.03e-7, step_loss=0.41]07/24/2023 20:04:15 - INFO - __main__ - train loss is 6.18958924873732\n",
      "Steps:   0%| | 52/15000 [00:29<2:12:18,  1.88it/s, lr=1.05e-7, step_loss=0.0099207/24/2023 20:04:16 - INFO - __main__ - train loss is 6.476524399360642\n",
      "Steps:   0%|  | 53/15000 [00:30<2:12:18,  1.88it/s, lr=1.08e-7, step_loss=0.287]07/24/2023 20:04:16 - INFO - __main__ - train loss is 6.479665145976469\n",
      "Steps:   0%| | 54/15000 [00:30<2:12:01,  1.89it/s, lr=1.1e-7, step_loss=0.00314]07/24/2023 20:04:17 - INFO - __main__ - train loss is 6.484748555114493\n",
      "Steps:   0%| | 55/15000 [00:31<2:12:12,  1.88it/s, lr=1.13e-7, step_loss=0.0050807/24/2023 20:04:17 - INFO - __main__ - train loss is 6.720414696028456\n",
      "Steps:   0%|  | 56/15000 [00:31<2:10:32,  1.91it/s, lr=1.15e-7, step_loss=0.236]07/24/2023 20:04:18 - INFO - __main__ - train loss is 6.800136578967795\n",
      "Steps:   0%| | 57/15000 [00:32<2:11:46,  1.89it/s, lr=1.18e-7, step_loss=0.0797]07/24/2023 20:04:18 - INFO - __main__ - train loss is 6.8883093723561615\n",
      "Steps:   0%|  | 58/15000 [00:33<2:12:26,  1.88it/s, lr=1.2e-7, step_loss=0.0882]07/24/2023 20:04:19 - INFO - __main__ - train loss is 7.4833639392163604\n",
      "Steps:   0%|  | 59/15000 [00:33<2:12:41,  1.88it/s, lr=1.23e-7, step_loss=0.595]07/24/2023 20:04:19 - INFO - __main__ - train loss is 7.4885154098737985\n",
      "Steps:   0%| | 60/15000 [00:34<2:12:24,  1.88it/s, lr=1.25e-7, step_loss=0.0051507/24/2023 20:04:20 - INFO - __main__ - train loss is 7.829826030181721\n",
      "Steps:   0%|  | 61/15000 [00:34<2:12:46,  1.88it/s, lr=1.27e-7, step_loss=0.341]07/24/2023 20:04:20 - INFO - __main__ - train loss is 7.841582047985867\n",
      "Steps:   0%|  | 62/15000 [00:35<2:12:54,  1.87it/s, lr=1.3e-7, step_loss=0.0118]07/24/2023 20:04:21 - INFO - __main__ - train loss is 8.236287045525387\n",
      "Steps:   0%|  | 63/15000 [00:35<2:14:27,  1.85it/s, lr=1.33e-7, step_loss=0.395]07/24/2023 20:04:21 - INFO - __main__ - train loss is 8.851431775139645\n",
      "Steps:   0%|  | 64/15000 [00:36<2:17:01,  1.82it/s, lr=1.35e-7, step_loss=0.615]07/24/2023 20:04:22 - INFO - __main__ - train loss is 8.858137908624485\n",
      "Steps:   0%| | 65/15000 [00:36<2:16:08,  1.83it/s, lr=1.38e-7, step_loss=0.0067107/24/2023 20:04:23 - INFO - __main__ - train loss is 9.45290011470206\n",
      "Steps:   0%|   | 66/15000 [00:37<2:16:00,  1.83it/s, lr=1.4e-7, step_loss=0.595]07/24/2023 20:04:23 - INFO - __main__ - train loss is 9.462289658607915\n",
      "Steps:   0%| | 67/15000 [00:37<2:14:45,  1.85it/s, lr=1.43e-7, step_loss=0.0093907/24/2023 20:04:24 - INFO - __main__ - train loss is 9.504782018484548\n",
      "Steps:   0%| | 68/15000 [00:38<2:14:54,  1.84it/s, lr=1.45e-7, step_loss=0.0425]07/24/2023 20:04:24 - INFO - __main__ - train loss is 9.514973624842241\n",
      "Steps:   0%| | 69/15000 [00:39<2:13:48,  1.86it/s, lr=1.48e-7, step_loss=0.0102]07/24/2023 20:04:25 - INFO - __main__ - train loss is 9.815838142530993\n",
      "Steps:   0%|   | 70/15000 [00:39<2:13:50,  1.86it/s, lr=1.5e-7, step_loss=0.301]07/24/2023 20:04:25 - INFO - __main__ - train loss is 10.084411247866228\n",
      "Steps:   0%|  | 71/15000 [00:40<2:14:03,  1.86it/s, lr=1.53e-7, step_loss=0.269]07/24/2023 20:04:26 - INFO - __main__ - train loss is 10.093410150380805\n",
      "Steps:   0%|  | 72/15000 [00:40<2:14:30,  1.85it/s, lr=1.55e-7, step_loss=0.009]07/24/2023 20:04:26 - INFO - __main__ - train loss is 10.101527299033478\n",
      "Steps:   0%| | 73/15000 [00:41<2:13:59,  1.86it/s, lr=1.58e-7, step_loss=0.0081207/24/2023 20:04:27 - INFO - __main__ - train loss is 10.106519421795383\n",
      "Steps:   0%| | 74/15000 [00:41<2:14:34,  1.85it/s, lr=1.6e-7, step_loss=0.00499]07/24/2023 20:04:27 - INFO - __main__ - train loss is 10.144927745917812\n",
      "Steps:   0%| | 75/15000 [00:42<2:14:05,  1.85it/s, lr=1.63e-7, step_loss=0.0384]07/24/2023 20:04:28 - INFO - __main__ - train loss is 10.150885216193274\n",
      "Steps:   1%| | 76/15000 [00:42<2:14:16,  1.85it/s, lr=1.65e-7, step_loss=0.0059607/24/2023 20:04:28 - INFO - __main__ - train loss is 10.377618841128424\n",
      "Steps:   1%|  | 77/15000 [00:43<2:14:06,  1.85it/s, lr=1.68e-7, step_loss=0.227]07/24/2023 20:04:29 - INFO - __main__ - train loss is 10.806200734572485\n",
      "Steps:   1%|   | 78/15000 [00:43<2:16:04,  1.83it/s, lr=1.7e-7, step_loss=0.429]07/24/2023 20:04:30 - INFO - __main__ - train loss is 10.940609417157248\n",
      "Steps:   1%|  | 79/15000 [00:44<2:13:24,  1.86it/s, lr=1.73e-7, step_loss=0.134]07/24/2023 20:04:30 - INFO - __main__ - train loss is 10.994656152324751\n",
      "Steps:   1%|  | 80/15000 [00:44<2:14:34,  1.85it/s, lr=1.75e-7, step_loss=0.054]07/24/2023 20:04:31 - INFO - __main__ - train loss is 11.401652760105208\n",
      "Steps:   1%|  | 81/15000 [00:45<2:13:32,  1.86it/s, lr=1.77e-7, step_loss=0.407]07/24/2023 20:04:31 - INFO - __main__ - train loss is 11.492040670709684\n",
      "Steps:   1%|  | 82/15000 [00:46<2:12:44,  1.87it/s, lr=1.8e-7, step_loss=0.0904]07/24/2023 20:04:32 - INFO - __main__ - train loss is 12.054991520242766\n",
      "Steps:   1%|  | 83/15000 [00:46<2:12:52,  1.87it/s, lr=1.82e-7, step_loss=0.563]07/24/2023 20:04:32 - INFO - __main__ - train loss is 12.069318189518526\n",
      "Steps:   1%| | 84/15000 [00:47<2:12:46,  1.87it/s, lr=1.85e-7, step_loss=0.0143]07/24/2023 20:04:33 - INFO - __main__ - train loss is 12.33423764933832\n",
      "Steps:   1%|  | 85/15000 [00:47<2:12:36,  1.87it/s, lr=1.88e-7, step_loss=0.265]07/24/2023 20:04:33 - INFO - __main__ - train loss is 12.370115234749392\n",
      "Steps:   1%|  | 86/15000 [00:48<2:12:04,  1.88it/s, lr=1.9e-7, step_loss=0.0359]07/24/2023 20:04:34 - INFO - __main__ - train loss is 12.459807730512694\n",
      "Steps:   1%| | 87/15000 [00:48<2:12:08,  1.88it/s, lr=1.93e-7, step_loss=0.0897]07/24/2023 20:04:34 - INFO - __main__ - train loss is 12.698556027607992\n",
      "Steps:   1%|  | 88/15000 [00:49<2:12:14,  1.88it/s, lr=1.95e-7, step_loss=0.239]07/24/2023 20:04:35 - INFO - __main__ - train loss is 12.92627393384464\n",
      "Steps:   1%|  | 89/15000 [00:49<2:12:53,  1.87it/s, lr=1.98e-7, step_loss=0.228]07/24/2023 20:04:35 - INFO - __main__ - train loss is 12.958806856768206\n",
      "Steps:   1%|    | 90/15000 [00:50<2:12:36,  1.87it/s, lr=2e-7, step_loss=0.0325]07/24/2023 20:04:36 - INFO - __main__ - train loss is 13.14945453335531\n",
      "Steps:   1%|  | 91/15000 [00:50<2:12:16,  1.88it/s, lr=2.03e-7, step_loss=0.191]07/24/2023 20:04:36 - INFO - __main__ - train loss is 13.290119051234797\n",
      "Steps:   1%|  | 92/15000 [00:51<2:12:26,  1.88it/s, lr=2.05e-7, step_loss=0.141]07/24/2023 20:04:37 - INFO - __main__ - train loss is 13.397928758757189\n",
      "Steps:   1%|  | 93/15000 [00:51<2:12:57,  1.87it/s, lr=2.08e-7, step_loss=0.108]07/24/2023 20:04:38 - INFO - __main__ - train loss is 13.467122956411913\n",
      "Steps:   1%|  | 94/15000 [00:52<2:12:30,  1.87it/s, lr=2.1e-7, step_loss=0.0692]07/24/2023 20:04:38 - INFO - __main__ - train loss is 13.837240799563006\n",
      "Steps:   1%|   | 95/15000 [00:52<2:12:24,  1.88it/s, lr=2.13e-7, step_loss=0.37]07/24/2023 20:04:39 - INFO - __main__ - train loss is 14.33803193201311\n",
      "Steps:   1%|  | 96/15000 [00:53<2:12:17,  1.88it/s, lr=2.15e-7, step_loss=0.501]07/24/2023 20:04:39 - INFO - __main__ - train loss is 14.684047266142443\n",
      "Steps:   1%|  | 97/15000 [00:54<2:12:15,  1.88it/s, lr=2.18e-7, step_loss=0.346]07/24/2023 20:04:40 - INFO - __main__ - train loss is 14.80245981295593\n",
      "Steps:   1%|   | 98/15000 [00:54<2:11:59,  1.88it/s, lr=2.2e-7, step_loss=0.118]07/24/2023 20:04:40 - INFO - __main__ - train loss is 15.04088621516712\n",
      "Steps:   1%|  | 99/15000 [00:55<2:12:36,  1.87it/s, lr=2.23e-7, step_loss=0.238]07/24/2023 20:04:41 - INFO - __main__ - train loss is 15.042713001836091\n",
      "Steps:   1%| | 100/15000 [00:55<2:12:35,  1.87it/s, lr=2.25e-7, step_loss=0.001807/24/2023 20:04:41 - INFO - __main__ - train loss is 15.101935573387891\n",
      "Steps:   1%| | 101/15000 [00:56<2:12:31,  1.87it/s, lr=2.28e-7, step_loss=0.059207/24/2023 20:04:42 - INFO - __main__ - train loss is 15.126299193594605\n",
      "Steps:   1%| | 102/15000 [00:56<2:12:38,  1.87it/s, lr=2.3e-7, step_loss=0.0244]07/24/2023 20:04:42 - INFO - __main__ - train loss is 15.302161625120789\n",
      "Steps:   1%| | 103/15000 [00:57<2:12:32,  1.87it/s, lr=2.33e-7, step_loss=0.176]07/24/2023 20:04:43 - INFO - __main__ - train loss is 15.305764343123883\n",
      "Steps:   1%| | 104/15000 [00:57<2:12:55,  1.87it/s, lr=2.35e-7, step_loss=0.003607/24/2023 20:04:43 - INFO - __main__ - train loss is 15.70212074695155\n",
      "Steps:   1%| | 105/15000 [00:58<2:13:50,  1.85it/s, lr=2.38e-7, step_loss=0.396]07/24/2023 20:04:44 - INFO - __main__ - train loss is 15.708909919951111\n",
      "Steps:   1%| | 106/15000 [00:58<2:13:55,  1.85it/s, lr=2.4e-7, step_loss=0.0067907/24/2023 20:04:45 - INFO - __main__ - train loss is 16.32180832931772\n",
      "Steps:   1%| | 107/15000 [00:59<2:14:03,  1.85it/s, lr=2.43e-7, step_loss=0.613]07/24/2023 20:04:45 - INFO - __main__ - train loss is 16.324928517453372\n",
      "Steps:   1%| | 108/15000 [00:59<2:13:20,  1.86it/s, lr=2.45e-7, step_loss=0.003107/24/2023 20:04:46 - INFO - __main__ - train loss is 16.326808532350697\n",
      "Steps:   1%| | 109/15000 [01:00<2:12:45,  1.87it/s, lr=2.48e-7, step_loss=0.001807/24/2023 20:04:46 - INFO - __main__ - train loss is 17.100543578737415\n",
      "Steps:   1%|  | 110/15000 [01:00<2:12:11,  1.88it/s, lr=2.5e-7, step_loss=0.774]07/24/2023 20:04:47 - INFO - __main__ - train loss is 17.104429944534786\n",
      "Steps:   1%| | 111/15000 [01:01<2:11:40,  1.88it/s, lr=2.53e-7, step_loss=0.003807/24/2023 20:04:47 - INFO - __main__ - train loss is 17.119176110369153\n",
      "Steps:   1%| | 112/15000 [01:02<2:11:38,  1.88it/s, lr=2.55e-7, step_loss=0.014707/24/2023 20:04:48 - INFO - __main__ - train loss is 17.772771557909437\n",
      "Steps:   1%| | 113/15000 [01:02<2:12:56,  1.87it/s, lr=2.58e-7, step_loss=0.654]07/24/2023 20:04:48 - INFO - __main__ - train loss is 17.996144017321058\n",
      "Steps:   1%|  | 114/15000 [01:03<2:13:53,  1.85it/s, lr=2.6e-7, step_loss=0.223]07/24/2023 20:04:49 - INFO - __main__ - train loss is 18.729375800234266\n",
      "Steps:   1%| | 115/15000 [01:03<2:13:19,  1.86it/s, lr=2.63e-7, step_loss=0.733]07/24/2023 20:04:49 - INFO - __main__ - train loss is 18.92430876765866\n",
      "Steps:   1%| | 116/15000 [01:04<2:12:48,  1.87it/s, lr=2.65e-7, step_loss=0.195]07/24/2023 20:04:50 - INFO - __main__ - train loss is 19.24944843922276\n",
      "Steps:   1%| | 117/15000 [01:04<2:12:19,  1.87it/s, lr=2.68e-7, step_loss=0.325]07/24/2023 20:04:50 - INFO - __main__ - train loss is 19.702028533560224\n",
      "Steps:   1%|  | 118/15000 [01:05<2:12:06,  1.88it/s, lr=2.7e-7, step_loss=0.453]07/24/2023 20:04:51 - INFO - __main__ - train loss is 19.950972875696607\n",
      "Steps:   1%| | 119/15000 [01:05<2:11:57,  1.88it/s, lr=2.73e-7, step_loss=0.249]07/24/2023 20:04:51 - INFO - __main__ - train loss is 19.9848222193541\n",
      "Steps:   1%| | 120/15000 [01:06<2:12:03,  1.88it/s, lr=2.75e-7, step_loss=0.033807/24/2023 20:04:52 - INFO - __main__ - train loss is 20.0166975465836\n",
      "Steps:   1%| | 121/15000 [01:06<2:14:25,  1.84it/s, lr=2.78e-7, step_loss=0.031907/24/2023 20:04:53 - INFO - __main__ - train loss is 20.340946396929212\n",
      "Steps:   1%|  | 122/15000 [01:07<2:13:47,  1.85it/s, lr=2.8e-7, step_loss=0.324]07/24/2023 20:04:53 - INFO - __main__ - train loss is 20.447493506711908\n",
      "Steps:   1%| | 123/15000 [01:07<2:13:10,  1.86it/s, lr=2.83e-7, step_loss=0.107]07/24/2023 20:04:54 - INFO - __main__ - train loss is 21.02487350825686\n",
      "Steps:   1%| | 124/15000 [01:08<2:12:40,  1.87it/s, lr=2.85e-7, step_loss=0.577]07/24/2023 20:04:54 - INFO - __main__ - train loss is 21.124614728731103\n",
      "Steps:   1%| | 125/15000 [01:09<2:12:23,  1.87it/s, lr=2.88e-7, step_loss=0.099707/24/2023 20:04:55 - INFO - __main__ - train loss is 21.12914722331334\n",
      "Steps:   1%| | 126/15000 [01:09<2:12:28,  1.87it/s, lr=2.9e-7, step_loss=0.0045307/24/2023 20:04:55 - INFO - __main__ - train loss is 21.16295433335472\n",
      "Steps:   1%| | 127/15000 [01:10<2:12:18,  1.87it/s, lr=2.93e-7, step_loss=0.033807/24/2023 20:04:56 - INFO - __main__ - train loss is 21.822209599544294\n",
      "Steps:   1%| | 128/15000 [01:10<2:13:14,  1.86it/s, lr=2.95e-7, step_loss=0.659]07/24/2023 20:04:56 - INFO - __main__ - train loss is 22.170281413127668\n",
      "Steps:   1%| | 129/15000 [01:11<2:13:21,  1.86it/s, lr=2.98e-7, step_loss=0.348]07/24/2023 20:04:57 - INFO - __main__ - train loss is 22.191259487648495\n",
      "Steps:   1%|    | 130/15000 [01:11<2:12:58,  1.86it/s, lr=3e-7, step_loss=0.021]07/24/2023 20:04:57 - INFO - __main__ - train loss is 22.206983245094307\n",
      "Steps:   1%| | 131/15000 [01:12<2:12:33,  1.87it/s, lr=3.03e-7, step_loss=0.015707/24/2023 20:04:58 - INFO - __main__ - train loss is 22.580111510236748\n",
      "Steps:   1%| | 132/15000 [01:12<2:12:24,  1.87it/s, lr=3.05e-7, step_loss=0.373]07/24/2023 20:04:58 - INFO - __main__ - train loss is 22.754719711025245\n",
      "Steps:   1%| | 133/15000 [01:13<2:12:03,  1.88it/s, lr=3.08e-7, step_loss=0.175]07/24/2023 20:04:59 - INFO - __main__ - train loss is 22.770546897430904\n",
      "Steps:   1%| | 134/15000 [01:13<2:11:53,  1.88it/s, lr=3.1e-7, step_loss=0.0158]07/24/2023 20:04:59 - INFO - __main__ - train loss is 22.82300863706041\n",
      "Steps:   1%| | 135/15000 [01:14<2:12:30,  1.87it/s, lr=3.13e-7, step_loss=0.052507/24/2023 20:05:00 - INFO - __main__ - train loss is 22.869704294134863\n",
      "Steps:   1%| | 136/15000 [01:14<2:14:25,  1.84it/s, lr=3.15e-7, step_loss=0.046707/24/2023 20:05:01 - INFO - __main__ - train loss is 22.91662209026981\n",
      "Steps:   1%| | 137/15000 [01:15<2:14:45,  1.84it/s, lr=3.18e-7, step_loss=0.046907/24/2023 20:05:01 - INFO - __main__ - train loss is 22.94952512078453\n",
      "Steps:   1%| | 138/15000 [01:16<2:14:32,  1.84it/s, lr=3.2e-7, step_loss=0.0329]07/24/2023 20:05:02 - INFO - __main__ - train loss is 23.82286781363655\n",
      "Steps:   1%| | 139/15000 [01:16<2:13:25,  1.86it/s, lr=3.23e-7, step_loss=0.873]07/24/2023 20:05:02 - INFO - __main__ - train loss is 23.967472779680975\n",
      "Steps:   1%| | 140/15000 [01:17<2:13:37,  1.85it/s, lr=3.25e-7, step_loss=0.145]07/24/2023 20:05:03 - INFO - __main__ - train loss is 24.11065282218624\n",
      "Steps:   1%| | 141/15000 [01:17<2:13:23,  1.86it/s, lr=3.28e-7, step_loss=0.143]07/24/2023 20:05:03 - INFO - __main__ - train loss is 24.19086975150276\n",
      "Steps:   1%| | 142/15000 [01:18<2:13:18,  1.86it/s, lr=3.3e-7, step_loss=0.0802]07/24/2023 20:05:04 - INFO - __main__ - train loss is 24.2316507055657\n",
      "Steps:   1%| | 143/15000 [01:18<2:14:16,  1.84it/s, lr=3.33e-7, step_loss=0.040807/24/2023 20:05:04 - INFO - __main__ - train loss is 24.23775161767844\n",
      "Steps:   1%| | 144/15000 [01:19<2:14:18,  1.84it/s, lr=3.35e-7, step_loss=0.006107/24/2023 20:05:05 - INFO - __main__ - train loss is 24.61684955621604\n",
      "Steps:   1%| | 145/15000 [01:19<2:14:00,  1.85it/s, lr=3.38e-7, step_loss=0.379]07/24/2023 20:05:05 - INFO - __main__ - train loss is 24.63159404101316\n",
      "Steps:   1%| | 146/15000 [01:20<2:14:00,  1.85it/s, lr=3.4e-7, step_loss=0.0147]07/24/2023 20:05:06 - INFO - __main__ - train loss is 24.71886620821897\n",
      "Steps:   1%| | 147/15000 [01:20<2:14:01,  1.85it/s, lr=3.43e-7, step_loss=0.087307/24/2023 20:05:07 - INFO - __main__ - train loss is 24.721776631311513\n",
      "Steps:   1%| | 148/15000 [01:21<2:13:01,  1.86it/s, lr=3.45e-7, step_loss=0.002907/24/2023 20:05:07 - INFO - __main__ - train loss is 25.01757192297373\n",
      "Steps:   1%| | 149/15000 [01:21<2:13:03,  1.86it/s, lr=3.48e-7, step_loss=0.296]07/24/2023 20:05:08 - INFO - __main__ - train loss is 25.189786341623403\n",
      "Steps:   1%|  | 150/15000 [01:22<2:13:59,  1.85it/s, lr=3.5e-7, step_loss=0.172]07/24/2023 20:05:08 - INFO - __main__ - train loss is 25.21376501454506\n",
      "Steps:   1%| | 151/15000 [01:23<2:13:05,  1.86it/s, lr=3.53e-7, step_loss=0.024]07/24/2023 20:05:09 - INFO - __main__ - train loss is 25.217937200912274\n",
      "Steps:   1%| | 152/15000 [01:23<2:13:21,  1.86it/s, lr=3.55e-7, step_loss=0.004107/24/2023 20:05:09 - INFO - __main__ - train loss is 25.330899804481305\n",
      "Steps:   1%| | 153/15000 [01:24<2:14:58,  1.83it/s, lr=3.58e-7, step_loss=0.113]07/24/2023 20:05:10 - INFO - __main__ - train loss is 25.334202608210035\n",
      "Steps:   1%| | 154/15000 [01:24<2:14:54,  1.83it/s, lr=3.6e-7, step_loss=0.0033]07/24/2023 20:05:10 - INFO - __main__ - train loss is 25.346431548823602\n",
      "Steps:   1%| | 155/15000 [01:25<2:13:39,  1.85it/s, lr=3.63e-7, step_loss=0.012207/24/2023 20:05:11 - INFO - __main__ - train loss is 25.348651152220555\n",
      "Steps:   1%| | 156/15000 [01:25<2:13:40,  1.85it/s, lr=3.65e-7, step_loss=0.002207/24/2023 20:05:11 - INFO - __main__ - train loss is 25.520703535643406\n",
      "Steps:   1%| | 157/15000 [01:26<2:13:10,  1.86it/s, lr=3.68e-7, step_loss=0.172]07/24/2023 20:05:12 - INFO - __main__ - train loss is 25.545623954501934\n",
      "Steps:   1%| | 158/15000 [01:26<2:12:48,  1.86it/s, lr=3.7e-7, step_loss=0.0249]07/24/2023 20:05:12 - INFO - __main__ - train loss is 25.54830205871258\n",
      "Steps:   1%| | 159/15000 [01:27<2:12:16,  1.87it/s, lr=3.73e-7, step_loss=0.002607/24/2023 20:05:13 - INFO - __main__ - train loss is 25.643335711793043\n",
      "Steps:   1%| | 160/15000 [01:27<2:11:47,  1.88it/s, lr=3.75e-7, step_loss=0.095]07/24/2023 20:05:14 - INFO - __main__ - train loss is 25.652620735228993\n",
      "Steps:   1%| | 161/15000 [01:28<2:12:29,  1.87it/s, lr=3.78e-7, step_loss=0.009207/24/2023 20:05:14 - INFO - __main__ - train loss is 25.838153185904957\n",
      "Steps:   1%|  | 162/15000 [01:28<2:14:42,  1.84it/s, lr=3.8e-7, step_loss=0.186]07/24/2023 20:05:15 - INFO - __main__ - train loss is 26.21920731908176\n",
      "Steps:   1%| | 163/15000 [01:29<2:13:45,  1.85it/s, lr=3.83e-7, step_loss=0.381]07/24/2023 20:05:15 - INFO - __main__ - train loss is 26.525165977538563\n",
      "Steps:   1%| | 164/15000 [01:30<2:14:01,  1.84it/s, lr=3.85e-7, step_loss=0.306]07/24/2023 20:05:16 - INFO - __main__ - train loss is 26.528880951111205\n",
      "Steps:   1%| | 165/15000 [01:30<2:12:55,  1.86it/s, lr=3.88e-7, step_loss=0.003707/24/2023 20:05:16 - INFO - __main__ - train loss is 26.534395214286633\n",
      "Steps:   1%| | 166/15000 [01:31<2:12:38,  1.86it/s, lr=3.9e-7, step_loss=0.0055107/24/2023 20:05:17 - INFO - __main__ - train loss is 26.5548502599122\n",
      "Steps:   1%| | 167/15000 [01:31<2:12:11,  1.87it/s, lr=3.93e-7, step_loss=0.020507/24/2023 20:05:17 - INFO - __main__ - train loss is 26.804840171826072\n",
      "Steps:   1%|  | 168/15000 [01:32<2:12:10,  1.87it/s, lr=3.95e-7, step_loss=0.25]07/24/2023 20:05:18 - INFO - __main__ - train loss is 27.332575524342246\n",
      "Steps:   1%| | 169/15000 [01:32<2:13:40,  1.85it/s, lr=3.98e-7, step_loss=0.528]07/24/2023 20:05:18 - INFO - __main__ - train loss is 27.56541418482084\n",
      "Steps:   1%|    | 170/15000 [01:33<2:12:57,  1.86it/s, lr=4e-7, step_loss=0.233]07/24/2023 20:05:19 - INFO - __main__ - train loss is 27.725292766583152\n",
      "Steps:   1%|  | 171/15000 [01:33<2:19:01,  1.78it/s, lr=4.03e-7, step_loss=0.16]07/24/2023 20:05:20 - INFO - __main__ - train loss is 28.13808375049848\n",
      "Steps:   1%| | 172/15000 [01:34<2:17:28,  1.80it/s, lr=4.05e-7, step_loss=0.413]07/24/2023 20:05:20 - INFO - __main__ - train loss is 28.28864961315412\n",
      "Steps:   1%| | 173/15000 [01:34<2:16:08,  1.82it/s, lr=4.08e-7, step_loss=0.151]07/24/2023 20:05:21 - INFO - __main__ - train loss is 28.64866852213163\n",
      "Steps:   1%|   | 174/15000 [01:35<2:15:33,  1.82it/s, lr=4.1e-7, step_loss=0.36]07/24/2023 20:05:21 - INFO - __main__ - train loss is 28.84443473268766\n",
      "Steps:   1%| | 175/15000 [01:36<2:16:15,  1.81it/s, lr=4.13e-7, step_loss=0.196]07/24/2023 20:05:22 - INFO - __main__ - train loss is 28.95780048717279\n",
      "Steps:   1%| | 176/15000 [01:36<2:14:34,  1.84it/s, lr=4.15e-7, step_loss=0.113]07/24/2023 20:05:22 - INFO - __main__ - train loss is 29.156627008807845\n",
      "Steps:   1%| | 177/15000 [01:37<2:14:21,  1.84it/s, lr=4.18e-7, step_loss=0.199]07/24/2023 20:05:23 - INFO - __main__ - train loss is 29.293315941584297\n",
      "Steps:   1%|  | 178/15000 [01:37<2:13:21,  1.85it/s, lr=4.2e-7, step_loss=0.137]07/24/2023 20:05:23 - INFO - __main__ - train loss is 29.315084539470263\n",
      "Steps:   1%| | 179/15000 [01:38<2:13:08,  1.86it/s, lr=4.23e-7, step_loss=0.021807/24/2023 20:05:24 - INFO - __main__ - train loss is 29.31828309420962\n",
      "Steps:   1%| | 180/15000 [01:38<2:14:25,  1.84it/s, lr=4.25e-7, step_loss=0.003207/24/2023 20:05:24 - INFO - __main__ - train loss is 29.32123762939591\n",
      "Steps:   1%| | 181/15000 [01:39<2:14:29,  1.84it/s, lr=4.28e-7, step_loss=0.002907/24/2023 20:05:25 - INFO - __main__ - train loss is 29.338616116088815\n",
      "Steps:   1%| | 182/15000 [01:39<2:14:31,  1.84it/s, lr=4.3e-7, step_loss=0.0174]07/24/2023 20:05:25 - INFO - __main__ - train loss is 29.403338870150037\n",
      "Steps:   1%| | 183/15000 [01:40<2:12:48,  1.86it/s, lr=4.32e-7, step_loss=0.064707/24/2023 20:05:26 - INFO - __main__ - train loss is 29.65120816801209\n",
      "Steps:   1%| | 184/15000 [01:40<2:12:27,  1.86it/s, lr=4.35e-7, step_loss=0.248]07/24/2023 20:05:27 - INFO - __main__ - train loss is 29.66952520806808\n",
      "Steps:   1%| | 185/15000 [01:41<2:13:32,  1.85it/s, lr=4.37e-7, step_loss=0.018307/24/2023 20:05:27 - INFO - __main__ - train loss is 29.916387649369426\n",
      "Steps:   1%|  | 186/15000 [01:41<2:13:29,  1.85it/s, lr=4.4e-7, step_loss=0.247]07/24/2023 20:05:28 - INFO - __main__ - train loss is 30.345484377932735\n",
      "Steps:   1%| | 187/15000 [01:42<2:14:17,  1.84it/s, lr=4.42e-7, step_loss=0.429]07/24/2023 20:05:28 - INFO - __main__ - train loss is 30.351426466484554\n",
      "Steps:   1%| | 188/15000 [01:43<2:13:17,  1.85it/s, lr=4.45e-7, step_loss=0.005907/24/2023 20:05:29 - INFO - __main__ - train loss is 30.404722775449045\n",
      "Steps:   1%| | 189/15000 [01:43<2:12:49,  1.86it/s, lr=4.48e-7, step_loss=0.053307/24/2023 20:05:29 - INFO - __main__ - train loss is 30.50062715553213\n",
      "Steps:   1%| | 190/15000 [01:44<2:12:51,  1.86it/s, lr=4.5e-7, step_loss=0.0959]07/24/2023 20:05:30 - INFO - __main__ - train loss is 30.54547875665594\n",
      "Steps:   1%| | 191/15000 [01:44<2:12:51,  1.86it/s, lr=4.53e-7, step_loss=0.044907/24/2023 20:05:30 - INFO - __main__ - train loss is 30.5878049536841\n",
      "Steps:   1%| | 192/15000 [01:45<2:17:40,  1.79it/s, lr=4.55e-7, step_loss=0.042307/24/2023 20:05:31 - INFO - __main__ - train loss is 30.844775031437166\n",
      "Steps:   1%| | 193/15000 [01:45<2:17:20,  1.80it/s, lr=4.58e-7, step_loss=0.257]07/24/2023 20:05:32 - INFO - __main__ - train loss is 30.866979922284372\n",
      "Steps:   1%| | 194/15000 [01:46<2:16:25,  1.81it/s, lr=4.6e-7, step_loss=0.0222]07/24/2023 20:05:32 - INFO - __main__ - train loss is 30.891508313943632\n",
      "Steps:   1%| | 195/15000 [01:46<2:15:57,  1.81it/s, lr=4.63e-7, step_loss=0.024507/24/2023 20:05:33 - INFO - __main__ - train loss is 31.280794295598753\n",
      "Steps:   1%| | 196/15000 [01:47<2:15:21,  1.82it/s, lr=4.65e-7, step_loss=0.389]07/24/2023 20:05:33 - INFO - __main__ - train loss is 31.327355693210848\n",
      "Steps:   1%| | 197/15000 [01:48<2:14:39,  1.83it/s, lr=4.68e-7, step_loss=0.046607/24/2023 20:05:34 - INFO - __main__ - train loss is 31.427467811037786\n",
      "Steps:   1%|    | 198/15000 [01:48<2:13:51,  1.84it/s, lr=4.7e-7, step_loss=0.1]07/24/2023 20:05:34 - INFO - __main__ - train loss is 31.479559212108143\n",
      "Steps:   1%| | 199/15000 [01:49<2:13:29,  1.85it/s, lr=4.73e-7, step_loss=0.052107/24/2023 20:05:35 - INFO - __main__ - train loss is 31.794672905583866\n",
      "Steps:   1%| | 200/15000 [01:49<2:13:25,  1.85it/s, lr=4.75e-7, step_loss=0.315]07/24/2023 20:05:35 - INFO - __main__ - train loss is 31.99232351698447\n",
      "Steps:   1%| | 201/15000 [01:50<2:13:01,  1.85it/s, lr=4.78e-7, step_loss=0.198]07/24/2023 20:05:36 - INFO - __main__ - train loss is 32.03313269384671\n",
      "Steps:   1%| | 202/15000 [01:50<2:13:39,  1.85it/s, lr=4.8e-7, step_loss=0.0408]07/24/2023 20:05:36 - INFO - __main__ - train loss is 32.18976565368939\n",
      "Steps:   1%| | 203/15000 [01:51<2:14:52,  1.83it/s, lr=4.83e-7, step_loss=0.157]07/24/2023 20:05:37 - INFO - __main__ - train loss is 32.616293213446625\n",
      "Steps:   1%| | 204/15000 [01:51<2:14:35,  1.83it/s, lr=4.85e-7, step_loss=0.427]07/24/2023 20:05:37 - INFO - __main__ - train loss is 33.29545917280484\n",
      "Steps:   1%| | 205/15000 [01:52<2:14:15,  1.84it/s, lr=4.88e-7, step_loss=0.679]07/24/2023 20:05:38 - INFO - __main__ - train loss is 33.50823948450852\n",
      "Steps:   1%|  | 206/15000 [01:52<2:13:47,  1.84it/s, lr=4.9e-7, step_loss=0.213]07/24/2023 20:05:39 - INFO - __main__ - train loss is 33.516513784532435\n",
      "Steps:   1%| | 207/15000 [01:53<2:13:04,  1.85it/s, lr=4.93e-7, step_loss=0.008207/24/2023 20:05:39 - INFO - __main__ - train loss is 33.69864191592205\n",
      "Steps:   1%| | 208/15000 [01:53<2:13:20,  1.85it/s, lr=4.95e-7, step_loss=0.182]07/24/2023 20:05:40 - INFO - __main__ - train loss is 33.86437143862713\n",
      "Steps:   1%| | 209/15000 [01:54<2:13:02,  1.85it/s, lr=4.98e-7, step_loss=0.166]07/24/2023 20:05:40 - INFO - __main__ - train loss is 33.947287936811335\n",
      "Steps:   1%|   | 210/15000 [01:55<2:12:22,  1.86it/s, lr=5e-7, step_loss=0.0829]07/24/2023 20:05:41 - INFO - __main__ - train loss is 33.951381426420994\n",
      "Steps:   1%| | 211/15000 [01:55<2:12:49,  1.86it/s, lr=5.03e-7, step_loss=0.004007/24/2023 20:05:41 - INFO - __main__ - train loss is 34.63762198027689\n",
      "Steps:   1%| | 212/15000 [01:56<2:12:34,  1.86it/s, lr=5.05e-7, step_loss=0.686]07/24/2023 20:05:42 - INFO - __main__ - train loss is 35.03679488238413\n",
      "Steps:   1%| | 213/15000 [01:56<2:12:41,  1.86it/s, lr=5.08e-7, step_loss=0.399]07/24/2023 20:05:42 - INFO - __main__ - train loss is 35.03982257901225\n",
      "Steps:   1%| | 214/15000 [01:57<2:14:03,  1.84it/s, lr=5.1e-7, step_loss=0.0030307/24/2023 20:05:43 - INFO - __main__ - train loss is 35.09923533408437\n",
      "Steps:   1%| | 215/15000 [01:57<2:13:26,  1.85it/s, lr=5.12e-7, step_loss=0.059407/24/2023 20:05:43 - INFO - __main__ - train loss is 35.23788965551648\n",
      "Steps:   1%| | 216/15000 [01:58<2:13:01,  1.85it/s, lr=5.15e-7, step_loss=0.139]07/24/2023 20:05:44 - INFO - __main__ - train loss is 35.448502921150066\n",
      "Steps:   1%| | 217/15000 [01:58<2:13:02,  1.85it/s, lr=5.18e-7, step_loss=0.211]07/24/2023 20:05:44 - INFO - __main__ - train loss is 35.51215618907008\n",
      "Steps:   1%| | 218/15000 [01:59<2:12:18,  1.86it/s, lr=5.2e-7, step_loss=0.0637]07/24/2023 20:05:45 - INFO - __main__ - train loss is 35.63865235506091\n",
      "Steps:   1%| | 219/15000 [01:59<2:11:53,  1.87it/s, lr=5.22e-7, step_loss=0.126]07/24/2023 20:05:46 - INFO - __main__ - train loss is 35.65354882145766\n",
      "Steps:   1%| | 220/15000 [02:00<2:11:24,  1.87it/s, lr=5.25e-7, step_loss=0.014907/24/2023 20:05:46 - INFO - __main__ - train loss is 35.773276611813344\n",
      "Steps:   1%|  | 221/15000 [02:00<2:11:23,  1.87it/s, lr=5.28e-7, step_loss=0.12]07/24/2023 20:05:47 - INFO - __main__ - train loss is 36.20515920186881\n",
      "Steps:   1%|  | 222/15000 [02:01<2:11:20,  1.88it/s, lr=5.3e-7, step_loss=0.432]07/24/2023 20:05:47 - INFO - __main__ - train loss is 36.20758855796885\n",
      "Steps:   1%| | 223/15000 [02:02<2:11:00,  1.88it/s, lr=5.32e-7, step_loss=0.002407/24/2023 20:05:48 - INFO - __main__ - train loss is 36.35060522414278\n",
      "Steps:   1%| | 224/15000 [02:02<2:10:49,  1.88it/s, lr=5.35e-7, step_loss=0.143]07/24/2023 20:05:48 - INFO - __main__ - train loss is 36.44506478763651\n",
      "Steps:   2%| | 225/15000 [02:03<2:10:41,  1.88it/s, lr=5.38e-7, step_loss=0.094507/24/2023 20:05:49 - INFO - __main__ - train loss is 36.475051698158495\n",
      "Steps:   2%|   | 226/15000 [02:03<2:13:08,  1.85it/s, lr=5.4e-7, step_loss=0.03]07/24/2023 20:05:49 - INFO - __main__ - train loss is 36.4770723375259\n",
      "Steps:   2%| | 227/15000 [02:04<2:14:09,  1.84it/s, lr=5.42e-7, step_loss=0.002007/24/2023 20:05:50 - INFO - __main__ - train loss is 36.83770729030948\n",
      "Steps:   2%| | 228/15000 [02:04<2:14:14,  1.83it/s, lr=5.45e-7, step_loss=0.361]07/24/2023 20:05:50 - INFO - __main__ - train loss is 36.83969631080981\n",
      "Steps:   2%| | 229/15000 [02:05<2:13:39,  1.84it/s, lr=5.48e-7, step_loss=0.001907/24/2023 20:05:51 - INFO - __main__ - train loss is 37.419087075046264\n",
      "Steps:   2%|  | 230/15000 [02:05<2:13:32,  1.84it/s, lr=5.5e-7, step_loss=0.579]07/24/2023 20:05:51 - INFO - __main__ - train loss is 37.76996477728244\n",
      "Steps:   2%| | 231/15000 [02:06<2:12:42,  1.85it/s, lr=5.53e-7, step_loss=0.351]07/24/2023 20:05:52 - INFO - __main__ - train loss is 38.019391306093894\n",
      "Steps:   2%| | 232/15000 [02:06<2:12:52,  1.85it/s, lr=5.55e-7, step_loss=0.249]07/24/2023 20:05:53 - INFO - __main__ - train loss is 38.081698850146495\n",
      "Steps:   2%| | 233/15000 [02:07<2:13:29,  1.84it/s, lr=5.58e-7, step_loss=0.062307/24/2023 20:05:53 - INFO - __main__ - train loss is 38.08584221394267\n",
      "Steps:   2%| | 234/15000 [02:07<2:13:12,  1.85it/s, lr=5.6e-7, step_loss=0.0041407/24/2023 20:05:54 - INFO - __main__ - train loss is 38.34462251455989\n",
      "Steps:   2%| | 235/15000 [02:08<2:13:08,  1.85it/s, lr=5.63e-7, step_loss=0.259]07/24/2023 20:05:54 - INFO - __main__ - train loss is 38.361515310942195\n",
      "Steps:   2%| | 236/15000 [02:09<2:13:18,  1.85it/s, lr=5.65e-7, step_loss=0.016907/24/2023 20:05:55 - INFO - __main__ - train loss is 38.382055125548504\n",
      "Steps:   2%| | 237/15000 [02:09<2:13:06,  1.85it/s, lr=5.68e-7, step_loss=0.020507/24/2023 20:05:55 - INFO - __main__ - train loss is 38.49783401878085\n",
      "Steps:   2%|  | 238/15000 [02:10<2:12:57,  1.85it/s, lr=5.7e-7, step_loss=0.116]07/24/2023 20:05:56 - INFO - __main__ - train loss is 38.50310691667255\n",
      "Steps:   2%| | 239/15000 [02:10<2:13:56,  1.84it/s, lr=5.73e-7, step_loss=0.005207/24/2023 20:05:56 - INFO - __main__ - train loss is 38.78718152118381\n",
      "Steps:   2%| | 240/15000 [02:11<2:15:43,  1.81it/s, lr=5.75e-7, step_loss=0.284]07/24/2023 20:05:57 - INFO - __main__ - train loss is 39.031966740614735\n",
      "Steps:   2%| | 241/15000 [02:11<2:15:59,  1.81it/s, lr=5.78e-7, step_loss=0.245]07/24/2023 20:05:57 - INFO - __main__ - train loss is 39.440434748656116\n",
      "Steps:   2%|  | 242/15000 [02:12<2:14:28,  1.83it/s, lr=5.8e-7, step_loss=0.408]07/24/2023 20:05:58 - INFO - __main__ - train loss is 39.47421485779341\n",
      "Steps:   2%| | 243/15000 [02:12<2:13:18,  1.84it/s, lr=5.83e-7, step_loss=0.033807/24/2023 20:05:59 - INFO - __main__ - train loss is 39.48896910937037\n",
      "Steps:   2%| | 244/15000 [02:13<2:14:26,  1.83it/s, lr=5.85e-7, step_loss=0.014807/24/2023 20:05:59 - INFO - __main__ - train loss is 39.49599711818155\n",
      "Steps:   2%| | 245/15000 [02:13<2:13:06,  1.85it/s, lr=5.87e-7, step_loss=0.007007/24/2023 20:06:00 - INFO - __main__ - train loss is 39.507907418883406\n",
      "Steps:   2%| | 246/15000 [02:14<2:12:33,  1.85it/s, lr=5.9e-7, step_loss=0.0119]07/24/2023 20:06:00 - INFO - __main__ - train loss is 39.619854873395525\n",
      "Steps:   2%| | 247/15000 [02:15<2:11:52,  1.86it/s, lr=5.93e-7, step_loss=0.112]07/24/2023 20:06:01 - INFO - __main__ - train loss is 39.84816569683608\n",
      "Steps:   2%| | 248/15000 [02:15<2:11:20,  1.87it/s, lr=5.95e-7, step_loss=0.228]07/24/2023 20:06:01 - INFO - __main__ - train loss is 40.03263952431735\n",
      "Steps:   2%| | 249/15000 [02:16<2:10:51,  1.88it/s, lr=5.97e-7, step_loss=0.184]07/24/2023 20:06:02 - INFO - __main__ - train loss is 40.72764637169894\n",
      "Steps:   2%|    | 250/15000 [02:16<2:11:20,  1.87it/s, lr=6e-7, step_loss=0.695]07/24/2023 20:06:02 - INFO - __main__ - train loss is 41.16245724854525\n",
      "Steps:   2%| | 251/15000 [02:17<2:11:00,  1.88it/s, lr=6.03e-7, step_loss=0.435]07/24/2023 20:06:03 - INFO - __main__ - train loss is 41.25813678500708\n",
      "Steps:   2%| | 252/15000 [02:17<2:12:42,  1.85it/s, lr=6.05e-7, step_loss=0.095707/24/2023 20:06:03 - INFO - __main__ - train loss is 41.29147447494324\n",
      "Steps:   2%| | 253/15000 [02:18<2:15:11,  1.82it/s, lr=6.08e-7, step_loss=0.033307/24/2023 20:06:04 - INFO - __main__ - train loss is 41.56423057464417\n",
      "Steps:   2%|  | 254/15000 [02:18<2:15:03,  1.82it/s, lr=6.1e-7, step_loss=0.273]07/24/2023 20:06:04 - INFO - __main__ - train loss is 41.623274466372095\n",
      "Steps:   2%| | 255/15000 [02:19<2:13:52,  1.84it/s, lr=6.13e-7, step_loss=0.059]07/24/2023 20:06:05 - INFO - __main__ - train loss is 42.530107995844446\n",
      "Steps:   2%| | 256/15000 [02:19<2:13:12,  1.84it/s, lr=6.15e-7, step_loss=0.907]07/24/2023 20:06:06 - INFO - __main__ - train loss is 42.838869473314844\n",
      "Steps:   2%| | 257/15000 [02:20<2:13:17,  1.84it/s, lr=6.18e-7, step_loss=0.309]07/24/2023 20:06:06 - INFO - __main__ - train loss is 42.8695211004233\n",
      "Steps:   2%| | 258/15000 [02:20<2:12:19,  1.86it/s, lr=6.2e-7, step_loss=0.0307]07/24/2023 20:06:07 - INFO - __main__ - train loss is 43.02099839260336\n",
      "Steps:   2%| | 259/15000 [02:21<2:12:05,  1.86it/s, lr=6.23e-7, step_loss=0.151]07/24/2023 20:06:07 - INFO - __main__ - train loss is 43.149620373151265\n",
      "Steps:   2%| | 260/15000 [02:22<2:11:35,  1.87it/s, lr=6.25e-7, step_loss=0.129]07/24/2023 20:06:08 - INFO - __main__ - train loss is 43.42255868425127\n",
      "Steps:   2%| | 261/15000 [02:22<2:11:26,  1.87it/s, lr=6.28e-7, step_loss=0.273]07/24/2023 20:06:08 - INFO - __main__ - train loss is 43.4425323571777\n",
      "Steps:   2%|   | 262/15000 [02:23<2:12:40,  1.85it/s, lr=6.3e-7, step_loss=0.02]07/24/2023 20:06:09 - INFO - __main__ - train loss is 43.93799468537327\n",
      "Steps:   2%| | 263/15000 [02:23<2:11:51,  1.86it/s, lr=6.33e-7, step_loss=0.495]07/24/2023 20:06:09 - INFO - __main__ - train loss is 44.087268900475465\n",
      "Steps:   2%| | 264/15000 [02:24<2:11:46,  1.86it/s, lr=6.35e-7, step_loss=0.149]07/24/2023 20:06:10 - INFO - __main__ - train loss is 44.08974481455516\n",
      "Steps:   2%| | 265/15000 [02:24<2:11:36,  1.87it/s, lr=6.38e-7, step_loss=0.002407/24/2023 20:06:10 - INFO - __main__ - train loss is 44.095968058216386\n",
      "Steps:   2%| | 266/15000 [02:25<2:12:04,  1.86it/s, lr=6.4e-7, step_loss=0.0062207/24/2023 20:06:11 - INFO - __main__ - train loss is 44.28016825567465\n",
      "[2023-07-24 20:06:11,554] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:   2%|  | 267/15000 [02:25<2:14:23,  1.83it/s, lr=6.4e-7, step_loss=0.184]07/24/2023 20:06:12 - INFO - __main__ - train loss is 44.29745192255359\n",
      "Steps:   2%| | 268/15000 [02:26<2:17:45,  1.78it/s, lr=6.43e-7, step_loss=0.017307/24/2023 20:06:12 - INFO - __main__ - train loss is 44.39809592242818\n",
      "Steps:   2%| | 269/15000 [02:26<2:16:09,  1.80it/s, lr=6.45e-7, step_loss=0.101]07/24/2023 20:06:13 - INFO - __main__ - train loss is 44.43014920677524\n",
      "Steps:   2%| | 270/15000 [02:27<2:14:43,  1.82it/s, lr=6.48e-7, step_loss=0.032107/24/2023 20:06:13 - INFO - __main__ - train loss is 44.44946238945704\n",
      "Steps:   2%| | 271/15000 [02:28<2:13:53,  1.83it/s, lr=6.5e-7, step_loss=0.0193]07/24/2023 20:06:14 - INFO - __main__ - train loss is 44.57389212946873\n",
      "Steps:   2%| | 272/15000 [02:28<2:13:59,  1.83it/s, lr=6.53e-7, step_loss=0.124]07/24/2023 20:06:14 - INFO - __main__ - train loss is 44.61938181321602\n",
      "Steps:   2%| | 273/15000 [02:29<2:13:23,  1.84it/s, lr=6.55e-7, step_loss=0.045507/24/2023 20:06:15 - INFO - __main__ - train loss is 44.62583639041986\n",
      "Steps:   2%| | 274/15000 [02:29<2:12:32,  1.85it/s, lr=6.58e-7, step_loss=0.006407/24/2023 20:06:15 - INFO - __main__ - train loss is 44.649047873332165\n",
      "Steps:   2%| | 275/15000 [02:30<2:11:33,  1.87it/s, lr=6.6e-7, step_loss=0.0232]07/24/2023 20:06:16 - INFO - __main__ - train loss is 44.70195396558847\n",
      "Steps:   2%| | 276/15000 [02:30<2:11:28,  1.87it/s, lr=6.63e-7, step_loss=0.052907/24/2023 20:06:16 - INFO - __main__ - train loss is 44.71656020206865\n",
      "Steps:   2%| | 277/15000 [02:31<2:11:50,  1.86it/s, lr=6.65e-7, step_loss=0.014607/24/2023 20:06:17 - INFO - __main__ - train loss is 44.80692143214401\n",
      "Steps:   2%| | 278/15000 [02:31<2:11:30,  1.87it/s, lr=6.68e-7, step_loss=0.090407/24/2023 20:06:17 - INFO - __main__ - train loss is 44.884788656956516\n",
      "Steps:   2%| | 279/15000 [02:32<2:12:05,  1.86it/s, lr=6.7e-7, step_loss=0.0779]07/24/2023 20:06:18 - INFO - __main__ - train loss is 44.89346867182758\n",
      "Steps:   2%| | 280/15000 [02:32<2:12:14,  1.86it/s, lr=6.73e-7, step_loss=0.008607/24/2023 20:06:19 - INFO - __main__ - train loss is 44.92698348814156\n",
      "Steps:   2%| | 281/15000 [02:33<2:12:30,  1.85it/s, lr=6.75e-7, step_loss=0.033507/24/2023 20:06:19 - INFO - __main__ - train loss is 45.4270634179702\n",
      "Steps:   2%|   | 282/15000 [02:34<2:20:24,  1.75it/s, lr=6.78e-7, step_loss=0.5]07/24/2023 20:06:20 - INFO - __main__ - train loss is 45.47707723581698\n",
      "Steps:   2%|   | 283/15000 [02:34<2:18:09,  1.78it/s, lr=6.8e-7, step_loss=0.05]07/24/2023 20:06:20 - INFO - __main__ - train loss is 45.82052200043108\n",
      "Steps:   2%| | 284/15000 [02:35<2:16:27,  1.80it/s, lr=6.83e-7, step_loss=0.343]07/24/2023 20:06:21 - INFO - __main__ - train loss is 46.08652131760027\n",
      "Steps:   2%| | 285/15000 [02:35<2:16:09,  1.80it/s, lr=6.85e-7, step_loss=0.266]07/24/2023 20:06:21 - INFO - __main__ - train loss is 46.21988559269812\n",
      "Steps:   2%| | 286/15000 [02:36<2:15:10,  1.81it/s, lr=6.88e-7, step_loss=0.133]07/24/2023 20:06:22 - INFO - __main__ - train loss is 46.60566846036818\n",
      "Steps:   2%|  | 287/15000 [02:36<2:13:57,  1.83it/s, lr=6.9e-7, step_loss=0.386]07/24/2023 20:06:22 - INFO - __main__ - train loss is 46.97714749479201\n",
      "Steps:   2%| | 288/15000 [02:37<2:13:08,  1.84it/s, lr=6.93e-7, step_loss=0.371]07/24/2023 20:06:23 - INFO - __main__ - train loss is 47.0291603183141\n",
      "Steps:   2%| | 289/15000 [02:37<2:12:24,  1.85it/s, lr=6.95e-7, step_loss=0.052]07/24/2023 20:06:24 - INFO - __main__ - train loss is 47.143166211782955\n",
      "Steps:   2%| | 290/15000 [02:38<2:12:01,  1.86it/s, lr=6.98e-7, step_loss=0.114]07/24/2023 20:06:24 - INFO - __main__ - train loss is 47.26727634423878\n",
      "Steps:   2%|    | 291/15000 [02:38<2:11:35,  1.86it/s, lr=7e-7, step_loss=0.124]07/24/2023 20:06:25 - INFO - __main__ - train loss is 47.28643838444259\n",
      "Steps:   2%| | 292/15000 [02:39<2:11:21,  1.87it/s, lr=7.03e-7, step_loss=0.019207/24/2023 20:06:25 - INFO - __main__ - train loss is 47.50718329229858\n",
      "Steps:   2%| | 293/15000 [02:39<2:11:04,  1.87it/s, lr=7.05e-7, step_loss=0.221]07/24/2023 20:06:26 - INFO - __main__ - train loss is 47.53335683362093\n",
      "Steps:   2%| | 294/15000 [02:40<2:10:33,  1.88it/s, lr=7.08e-7, step_loss=0.026207/24/2023 20:06:26 - INFO - __main__ - train loss is 47.57047360704746\n",
      "Steps:   2%| | 295/15000 [02:41<2:10:16,  1.88it/s, lr=7.1e-7, step_loss=0.0371]07/24/2023 20:06:27 - INFO - __main__ - train loss is 47.611099108471535\n",
      "Steps:   2%| | 296/15000 [02:41<2:10:53,  1.87it/s, lr=7.12e-7, step_loss=0.040607/24/2023 20:06:27 - INFO - __main__ - train loss is 47.646166115417145\n",
      "Steps:   2%| | 297/15000 [02:42<2:10:43,  1.87it/s, lr=7.15e-7, step_loss=0.035107/24/2023 20:06:28 - INFO - __main__ - train loss is 47.92947480024304\n",
      "Steps:   2%| | 298/15000 [02:42<2:12:09,  1.85it/s, lr=7.18e-7, step_loss=0.283]07/24/2023 20:06:28 - INFO - __main__ - train loss is 47.94544702710118\n",
      "Steps:   2%|  | 299/15000 [02:43<2:14:22,  1.82it/s, lr=7.2e-7, step_loss=0.016]07/24/2023 20:06:29 - INFO - __main__ - train loss is 48.67882806004491\n",
      "Steps:   2%| | 300/15000 [02:43<2:14:23,  1.82it/s, lr=7.22e-7, step_loss=0.733]07/24/2023 20:06:29 - INFO - __main__ - train loss is 48.69543949270155\n",
      "Steps:   2%| | 301/15000 [02:44<2:14:09,  1.83it/s, lr=7.25e-7, step_loss=0.016607/24/2023 20:06:30 - INFO - __main__ - train loss is 48.94806513690855\n",
      "Steps:   2%| | 302/15000 [02:44<2:13:18,  1.84it/s, lr=7.28e-7, step_loss=0.253]07/24/2023 20:06:31 - INFO - __main__ - train loss is 49.02140571677592\n",
      "Steps:   2%| | 303/15000 [02:45<2:12:36,  1.85it/s, lr=7.3e-7, step_loss=0.0733]07/24/2023 20:06:31 - INFO - __main__ - train loss is 49.047472264035605\n",
      "Steps:   2%| | 304/15000 [02:45<2:12:16,  1.85it/s, lr=7.32e-7, step_loss=0.026107/24/2023 20:06:32 - INFO - __main__ - train loss is 49.05024037149269\n",
      "Steps:   2%| | 305/15000 [02:46<2:12:46,  1.84it/s, lr=7.35e-7, step_loss=0.002707/24/2023 20:06:32 - INFO - __main__ - train loss is 49.09870867815334\n",
      "Steps:   2%| | 306/15000 [02:47<2:11:43,  1.86it/s, lr=7.38e-7, step_loss=0.048507/24/2023 20:06:33 - INFO - __main__ - train loss is 49.39815847959835\n",
      "Steps:   2%|  | 307/15000 [02:47<2:20:48,  1.74it/s, lr=7.4e-7, step_loss=0.299]07/24/2023 20:06:34 - INFO - __main__ - Per validation step average loss is 0.007190176285803318\n",
      "07/24/2023 20:06:34 - INFO - __main__ - Cumulative validation average loss is 0.007190176285803318\n",
      "07/24/2023 20:06:34 - INFO - __main__ - Per validation step average loss is 0.2131670117378235\n",
      "07/24/2023 20:06:34 - INFO - __main__ - Cumulative validation average loss is 0.2203571880236268\n",
      "07/24/2023 20:06:35 - INFO - __main__ - Per validation step average loss is 0.12408453971147537\n",
      "07/24/2023 20:06:35 - INFO - __main__ - Cumulative validation average loss is 0.3444417277351022\n",
      "07/24/2023 20:06:35 - INFO - __main__ - Per validation step average loss is 0.2011490911245346\n",
      "07/24/2023 20:06:35 - INFO - __main__ - Cumulative validation average loss is 0.5455908188596368\n",
      "07/24/2023 20:06:36 - INFO - __main__ - Per validation step average loss is 0.04796336963772774\n",
      "07/24/2023 20:06:36 - INFO - __main__ - Cumulative validation average loss is 0.5935541884973645\n",
      "07/24/2023 20:06:36 - INFO - __main__ - Per validation step average loss is 0.512628436088562\n",
      "07/24/2023 20:06:36 - INFO - __main__ - Cumulative validation average loss is 1.1061826245859265\n",
      "07/24/2023 20:06:36 - INFO - __main__ - Per validation step average loss is 0.02871611900627613\n",
      "07/24/2023 20:06:36 - INFO - __main__ - Cumulative validation average loss is 1.1348987435922027\n",
      "07/24/2023 20:06:37 - INFO - __main__ - Per validation step average loss is 0.13889124989509583\n",
      "07/24/2023 20:06:37 - INFO - __main__ - Cumulative validation average loss is 1.2737899934872985\n",
      "07/24/2023 20:06:37 - INFO - __main__ - Per validation step average loss is 0.008328258991241455\n",
      "07/24/2023 20:06:37 - INFO - __main__ - Cumulative validation average loss is 1.28211825247854\n",
      "07/24/2023 20:06:38 - INFO - __main__ - Per validation step average loss is 0.003046842757612467\n",
      "07/24/2023 20:06:38 - INFO - __main__ - Cumulative validation average loss is 1.2851650952361524\n",
      "07/24/2023 20:06:38 - INFO - __main__ - Per validation step average loss is 0.28641241788864136\n",
      "07/24/2023 20:06:38 - INFO - __main__ - Cumulative validation average loss is 1.5715775131247938\n",
      "07/24/2023 20:06:39 - INFO - __main__ - Per validation step average loss is 0.013560573570430279\n",
      "07/24/2023 20:06:39 - INFO - __main__ - Cumulative validation average loss is 1.585138086695224\n",
      "07/24/2023 20:06:39 - INFO - __main__ - Per validation step average loss is 0.6316771507263184\n",
      "07/24/2023 20:06:39 - INFO - __main__ - Cumulative validation average loss is 2.2168152374215424\n",
      "07/24/2023 20:06:40 - INFO - __main__ - Per validation step average loss is 0.016643743962049484\n",
      "07/24/2023 20:06:40 - INFO - __main__ - Cumulative validation average loss is 2.233458981383592\n",
      "07/24/2023 20:06:40 - INFO - __main__ - Per validation step average loss is 0.1422051191329956\n",
      "07/24/2023 20:06:40 - INFO - __main__ - Cumulative validation average loss is 2.3756641005165875\n",
      "07/24/2023 20:06:41 - INFO - __main__ - Per validation step average loss is 0.11525540053844452\n",
      "07/24/2023 20:06:41 - INFO - __main__ - Cumulative validation average loss is 2.490919501055032\n",
      "07/24/2023 20:06:41 - INFO - __main__ - Per validation step average loss is 0.23491522669792175\n",
      "07/24/2023 20:06:41 - INFO - __main__ - Cumulative validation average loss is 2.7258347277529538\n",
      "07/24/2023 20:06:41 - INFO - __main__ - Per validation step average loss is 0.0724828690290451\n",
      "07/24/2023 20:06:41 - INFO - __main__ - Cumulative validation average loss is 2.798317596781999\n",
      "07/24/2023 20:06:42 - INFO - __main__ - Per validation step average loss is 0.15265287458896637\n",
      "07/24/2023 20:06:42 - INFO - __main__ - Cumulative validation average loss is 2.9509704713709652\n",
      "07/24/2023 20:06:42 - INFO - __main__ - Per validation step average loss is 0.10532724857330322\n",
      "07/24/2023 20:06:42 - INFO - __main__ - Cumulative validation average loss is 3.0562977199442685\n",
      "07/24/2023 20:06:43 - INFO - __main__ - Per validation step average loss is 0.04864601790904999\n",
      "07/24/2023 20:06:43 - INFO - __main__ - Cumulative validation average loss is 3.1049437378533185\n",
      "07/24/2023 20:06:43 - INFO - __main__ - Per validation step average loss is 0.006852985359728336\n",
      "07/24/2023 20:06:43 - INFO - __main__ - Cumulative validation average loss is 3.111796723213047\n",
      "07/24/2023 20:06:44 - INFO - __main__ - Per validation step average loss is 0.011933661065995693\n",
      "07/24/2023 20:06:44 - INFO - __main__ - Cumulative validation average loss is 3.1237303842790425\n",
      "07/24/2023 20:06:44 - INFO - __main__ - Per validation step average loss is 0.0021037303376942873\n",
      "07/24/2023 20:06:44 - INFO - __main__ - Cumulative validation average loss is 3.1258341146167368\n",
      "07/24/2023 20:06:45 - INFO - __main__ - Per validation step average loss is 0.010369425639510155\n",
      "07/24/2023 20:06:45 - INFO - __main__ - Cumulative validation average loss is 3.136203540256247\n",
      "07/24/2023 20:06:45 - INFO - __main__ - Per validation step average loss is 0.028497202321887016\n",
      "07/24/2023 20:06:45 - INFO - __main__ - Cumulative validation average loss is 3.164700742578134\n",
      "07/24/2023 20:06:45 - INFO - __main__ - Per validation step average loss is 0.3052959442138672\n",
      "07/24/2023 20:06:45 - INFO - __main__ - Cumulative validation average loss is 3.469996686792001\n",
      "07/24/2023 20:06:46 - INFO - __main__ - Per validation step average loss is 0.012593361549079418\n",
      "07/24/2023 20:06:46 - INFO - __main__ - Cumulative validation average loss is 3.4825900483410805\n",
      "07/24/2023 20:06:46 - INFO - __main__ - Per validation step average loss is 0.003718072548508644\n",
      "07/24/2023 20:06:46 - INFO - __main__ - Cumulative validation average loss is 3.486308120889589\n",
      "07/24/2023 20:06:47 - INFO - __main__ - Per validation step average loss is 0.2540663480758667\n",
      "07/24/2023 20:06:47 - INFO - __main__ - Cumulative validation average loss is 3.740374468965456\n",
      "07/24/2023 20:06:47 - INFO - __main__ - Per validation step average loss is 0.2793046236038208\n",
      "07/24/2023 20:06:47 - INFO - __main__ - Cumulative validation average loss is 4.019679092569277\n",
      "07/24/2023 20:06:48 - INFO - __main__ - Per validation step average loss is 0.441756010055542\n",
      "07/24/2023 20:06:48 - INFO - __main__ - Cumulative validation average loss is 4.461435102624819\n",
      "07/24/2023 20:06:48 - INFO - __main__ - Per validation step average loss is 0.021985100582242012\n",
      "07/24/2023 20:06:48 - INFO - __main__ - Cumulative validation average loss is 4.483420203207061\n",
      "07/24/2023 20:06:49 - INFO - __main__ - Per validation step average loss is 0.028486430644989014\n",
      "07/24/2023 20:06:49 - INFO - __main__ - Cumulative validation average loss is 4.51190663385205\n",
      "07/24/2023 20:06:49 - INFO - __main__ - Per validation step average loss is 0.25274965167045593\n",
      "07/24/2023 20:06:49 - INFO - __main__ - Cumulative validation average loss is 4.764656285522506\n",
      "07/24/2023 20:06:49 - INFO - __main__ - Per validation step average loss is 0.2597065567970276\n",
      "07/24/2023 20:06:49 - INFO - __main__ - Cumulative validation average loss is 5.024362842319533\n",
      "07/24/2023 20:06:50 - INFO - __main__ - Per validation step average loss is 0.027236156165599823\n",
      "07/24/2023 20:06:50 - INFO - __main__ - Cumulative validation average loss is 5.051598998485133\n",
      "07/24/2023 20:06:50 - INFO - __main__ - Per validation step average loss is 0.7466862797737122\n",
      "07/24/2023 20:06:50 - INFO - __main__ - Cumulative validation average loss is 5.798285278258845\n",
      "07/24/2023 20:06:51 - INFO - __main__ - Per validation step average loss is 0.0390578918159008\n",
      "07/24/2023 20:06:51 - INFO - __main__ - Cumulative validation average loss is 5.837343170074746\n",
      "07/24/2023 20:06:51 - INFO - __main__ - Per validation step average loss is 0.24818527698516846\n",
      "07/24/2023 20:06:51 - INFO - __main__ - Cumulative validation average loss is 6.0855284470599145\n",
      "07/24/2023 20:06:52 - INFO - __main__ - Per validation step average loss is 0.6203012466430664\n",
      "07/24/2023 20:06:52 - INFO - __main__ - Cumulative validation average loss is 6.705829693702981\n",
      "07/24/2023 20:06:52 - INFO - __main__ - Per validation step average loss is 0.002542621921747923\n",
      "07/24/2023 20:06:52 - INFO - __main__ - Cumulative validation average loss is 6.708372315624729\n",
      "07/24/2023 20:06:53 - INFO - __main__ - Per validation step average loss is 0.10450508445501328\n",
      "07/24/2023 20:06:53 - INFO - __main__ - Cumulative validation average loss is 6.812877400079742\n",
      "07/24/2023 20:06:53 - INFO - __main__ - Per validation step average loss is 0.2651192247867584\n",
      "07/24/2023 20:06:53 - INFO - __main__ - Cumulative validation average loss is 7.0779966248665005\n",
      "07/24/2023 20:06:53 - INFO - __main__ - Per validation step average loss is 0.03539033606648445\n",
      "07/24/2023 20:06:53 - INFO - __main__ - Cumulative validation average loss is 7.113386960932985\n",
      "07/24/2023 20:06:54 - INFO - __main__ - Per validation step average loss is 0.014810947701334953\n",
      "07/24/2023 20:06:54 - INFO - __main__ - Cumulative validation average loss is 7.12819790863432\n",
      "07/24/2023 20:06:54 - INFO - __main__ - Per validation step average loss is 0.004957505501806736\n",
      "07/24/2023 20:06:54 - INFO - __main__ - Cumulative validation average loss is 7.133155414136127\n",
      "07/24/2023 20:06:55 - INFO - __main__ - Per validation step average loss is 0.004599925130605698\n",
      "07/24/2023 20:06:55 - INFO - __main__ - Cumulative validation average loss is 7.137755339266732\n",
      "07/24/2023 20:06:55 - INFO - __main__ - Per validation step average loss is 0.06820836663246155\n",
      "07/24/2023 20:06:55 - INFO - __main__ - Cumulative validation average loss is 7.205963705899194\n",
      "07/24/2023 20:06:56 - INFO - __main__ - Per validation step average loss is 0.23936980962753296\n",
      "07/24/2023 20:06:56 - INFO - __main__ - Cumulative validation average loss is 7.445333515526727\n",
      "07/24/2023 20:06:56 - INFO - __main__ - Per validation step average loss is 0.03179202973842621\n",
      "07/24/2023 20:06:56 - INFO - __main__ - Cumulative validation average loss is 7.477125545265153\n",
      "07/24/2023 20:06:57 - INFO - __main__ - Per validation step average loss is 0.004960593767464161\n",
      "07/24/2023 20:06:57 - INFO - __main__ - Cumulative validation average loss is 7.482086139032617\n",
      "07/24/2023 20:06:57 - INFO - __main__ - Per validation step average loss is 0.0017483653500676155\n",
      "07/24/2023 20:06:57 - INFO - __main__ - Cumulative validation average loss is 7.483834504382685\n",
      "07/24/2023 20:06:57 - INFO - __main__ - Per validation step average loss is 0.024152033030986786\n",
      "07/24/2023 20:06:57 - INFO - __main__ - Cumulative validation average loss is 7.507986537413672\n",
      "07/24/2023 20:06:58 - INFO - __main__ - Per validation step average loss is 0.14757798612117767\n",
      "07/24/2023 20:06:58 - INFO - __main__ - Cumulative validation average loss is 7.655564523534849\n",
      "07/24/2023 20:06:58 - INFO - __main__ - Per validation step average loss is 0.3068353831768036\n",
      "07/24/2023 20:06:58 - INFO - __main__ - Cumulative validation average loss is 7.962399906711653\n",
      "07/24/2023 20:06:59 - INFO - __main__ - Per validation step average loss is 0.15069212019443512\n",
      "07/24/2023 20:06:59 - INFO - __main__ - Cumulative validation average loss is 8.113092026906088\n",
      "07/24/2023 20:06:59 - INFO - __main__ - Per validation step average loss is 0.04757675528526306\n",
      "07/24/2023 20:06:59 - INFO - __main__ - Cumulative validation average loss is 8.160668782191351\n",
      "07/24/2023 20:07:00 - INFO - __main__ - Per validation step average loss is 0.1896204799413681\n",
      "07/24/2023 20:07:00 - INFO - __main__ - Cumulative validation average loss is 8.35028926213272\n",
      "07/24/2023 20:07:00 - INFO - __main__ - Per validation step average loss is 0.022883471101522446\n",
      "07/24/2023 20:07:00 - INFO - __main__ - Cumulative validation average loss is 8.373172733234242\n",
      "07/24/2023 20:07:00 - INFO - __main__ - Per validation step average loss is 0.15147101879119873\n",
      "07/24/2023 20:07:00 - INFO - __main__ - Cumulative validation average loss is 8.52464375202544\n",
      "07/24/2023 20:07:01 - INFO - __main__ - Per validation step average loss is 0.012311195954680443\n",
      "07/24/2023 20:07:01 - INFO - __main__ - Cumulative validation average loss is 8.53695494798012\n",
      "07/24/2023 20:07:01 - INFO - __main__ - Per validation step average loss is 0.007494089659303427\n",
      "07/24/2023 20:07:01 - INFO - __main__ - Cumulative validation average loss is 8.544449037639424\n",
      "07/24/2023 20:07:02 - INFO - __main__ - Per validation step average loss is 0.02128146030008793\n",
      "07/24/2023 20:07:02 - INFO - __main__ - Cumulative validation average loss is 8.565730497939512\n",
      "07/24/2023 20:07:02 - INFO - __main__ - Per validation step average loss is 0.09197892248630524\n",
      "07/24/2023 20:07:02 - INFO - __main__ - Cumulative validation average loss is 8.657709420425817\n",
      "07/24/2023 20:07:03 - INFO - __main__ - Per validation step average loss is 0.007378929294645786\n",
      "07/24/2023 20:07:03 - INFO - __main__ - Cumulative validation average loss is 8.665088349720463\n",
      "07/24/2023 20:07:03 - INFO - __main__ - Per validation step average loss is 0.272453635931015\n",
      "07/24/2023 20:07:03 - INFO - __main__ - Cumulative validation average loss is 8.937541985651478\n",
      "07/24/2023 20:07:04 - INFO - __main__ - Per validation step average loss is 0.29914751648902893\n",
      "07/24/2023 20:07:04 - INFO - __main__ - Cumulative validation average loss is 9.236689502140507\n",
      "07/24/2023 20:07:04 - INFO - __main__ - Per validation step average loss is 0.19570650160312653\n",
      "07/24/2023 20:07:04 - INFO - __main__ - Cumulative validation average loss is 9.432396003743634\n",
      "07/24/2023 20:07:04 - INFO - __main__ - Per validation step average loss is 0.16067162156105042\n",
      "07/24/2023 20:07:04 - INFO - __main__ - Cumulative validation average loss is 9.593067625304684\n",
      "07/24/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.045124929398298264\n",
      "07/24/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 9.638192554702982\n",
      "07/24/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.4383377134799957\n",
      "07/24/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 10.076530268182978\n",
      "07/24/2023 20:07:06 - INFO - __main__ - Per validation step average loss is 0.0741870105266571\n",
      "07/24/2023 20:07:06 - INFO - __main__ - Cumulative validation average loss is 10.150717278709635\n",
      "07/24/2023 20:07:06 - INFO - __main__ - Per validation step average loss is 0.015930233523249626\n",
      "07/24/2023 20:07:06 - INFO - __main__ - Cumulative validation average loss is 10.166647512232885\n",
      "07/24/2023 20:07:07 - INFO - __main__ - Per validation step average loss is 0.334633469581604\n",
      "07/24/2023 20:07:07 - INFO - __main__ - Cumulative validation average loss is 10.501280981814489\n",
      "07/24/2023 20:07:07 - INFO - __main__ - Per validation step average loss is 0.09878489375114441\n",
      "07/24/2023 20:07:07 - INFO - __main__ - Cumulative validation average loss is 10.600065875565633\n",
      "07/24/2023 20:07:08 - INFO - __main__ - Per validation step average loss is 0.005385236348956823\n",
      "07/24/2023 20:07:08 - INFO - __main__ - Cumulative validation average loss is 10.60545111191459\n",
      "07/24/2023 20:07:08 - INFO - __main__ - Per validation step average loss is 0.0017463560216128826\n",
      "07/24/2023 20:07:08 - INFO - __main__ - Cumulative validation average loss is 10.607197467936203\n",
      "07/24/2023 20:07:08 - INFO - __main__ - Per validation step average loss is 0.003373605664819479\n",
      "07/24/2023 20:07:08 - INFO - __main__ - Cumulative validation average loss is 10.610571073601022\n",
      "07/24/2023 20:07:09 - INFO - __main__ - Per validation step average loss is 0.002480439841747284\n",
      "07/24/2023 20:07:09 - INFO - __main__ - Cumulative validation average loss is 10.61305151344277\n",
      "07/24/2023 20:07:09 - INFO - __main__ - Per validation step average loss is 0.0381288081407547\n",
      "07/24/2023 20:07:09 - INFO - __main__ - Cumulative validation average loss is 10.651180321583524\n",
      "07/24/2023 20:07:10 - INFO - __main__ - Per validation step average loss is 0.056785181164741516\n",
      "07/24/2023 20:07:10 - INFO - __main__ - Cumulative validation average loss is 10.707965502748266\n",
      "07/24/2023 20:07:10 - INFO - __main__ - Per validation step average loss is 0.5873194336891174\n",
      "07/24/2023 20:07:10 - INFO - __main__ - Cumulative validation average loss is 11.295284936437383\n",
      "07/24/2023 20:07:11 - INFO - __main__ - Per validation step average loss is 0.04097864031791687\n",
      "07/24/2023 20:07:11 - INFO - __main__ - Cumulative validation average loss is 11.3362635767553\n",
      "07/24/2023 20:07:11 - INFO - __main__ - Per validation step average loss is 0.15300144255161285\n",
      "07/24/2023 20:07:11 - INFO - __main__ - Cumulative validation average loss is 11.489265019306913\n",
      "07/24/2023 20:07:11 - INFO - __main__ - Per validation step average loss is 0.012938180938363075\n",
      "07/24/2023 20:07:11 - INFO - __main__ - Cumulative validation average loss is 11.502203200245276\n",
      "07/24/2023 20:07:12 - INFO - __main__ - Per validation step average loss is 0.7515328526496887\n",
      "07/24/2023 20:07:12 - INFO - __main__ - Cumulative validation average loss is 12.253736052894965\n",
      "07/24/2023 20:07:12 - INFO - __main__ - Per validation step average loss is 0.3403685688972473\n",
      "07/24/2023 20:07:12 - INFO - __main__ - Cumulative validation average loss is 12.594104621792212\n",
      "07/24/2023 20:07:13 - INFO - __main__ - Per validation step average loss is 0.00836898572742939\n",
      "07/24/2023 20:07:13 - INFO - __main__ - Cumulative validation average loss is 12.602473607519642\n",
      "07/24/2023 20:07:13 - INFO - __main__ - Per validation step average loss is 0.03291422873735428\n",
      "07/24/2023 20:07:13 - INFO - __main__ - Cumulative validation average loss is 12.635387836256996\n",
      "07/24/2023 20:07:14 - INFO - __main__ - Per validation step average loss is 0.09878095239400864\n",
      "07/24/2023 20:07:14 - INFO - __main__ - Cumulative validation average loss is 12.734168788651004\n",
      "07/24/2023 20:07:14 - INFO - __main__ - Per validation step average loss is 0.4719952642917633\n",
      "07/24/2023 20:07:14 - INFO - __main__ - Cumulative validation average loss is 13.206164052942768\n",
      "07/24/2023 20:07:15 - INFO - __main__ - Per validation step average loss is 0.010743038728833199\n",
      "07/24/2023 20:07:15 - INFO - __main__ - Cumulative validation average loss is 13.216907091671601\n",
      "07/24/2023 20:07:15 - INFO - __main__ - Per validation step average loss is 0.07688947021961212\n",
      "07/24/2023 20:07:15 - INFO - __main__ - Cumulative validation average loss is 13.293796561891213\n",
      "07/24/2023 20:07:15 - INFO - __main__ - Per validation step average loss is 0.18413186073303223\n",
      "07/24/2023 20:07:15 - INFO - __main__ - Cumulative validation average loss is 13.477928422624245\n",
      "07/24/2023 20:07:16 - INFO - __main__ - Per validation step average loss is 0.244227796792984\n",
      "07/24/2023 20:07:16 - INFO - __main__ - Cumulative validation average loss is 13.72215621941723\n",
      "07/24/2023 20:07:16 - INFO - __main__ - Per validation step average loss is 0.3309022784233093\n",
      "07/24/2023 20:07:16 - INFO - __main__ - Cumulative validation average loss is 14.053058497840539\n",
      "07/24/2023 20:07:17 - INFO - __main__ - Per validation step average loss is 0.05730123072862625\n",
      "07/24/2023 20:07:17 - INFO - __main__ - Cumulative validation average loss is 14.110359728569165\n",
      "07/24/2023 20:07:17 - INFO - __main__ - Per validation step average loss is 0.046092621982097626\n",
      "07/24/2023 20:07:17 - INFO - __main__ - Cumulative validation average loss is 14.156452350551262\n",
      "07/24/2023 20:07:18 - INFO - __main__ - Per validation step average loss is 0.010934222489595413\n",
      "07/24/2023 20:07:18 - INFO - __main__ - Cumulative validation average loss is 14.167386573040858\n",
      "07/24/2023 20:07:18 - INFO - __main__ - Per validation step average loss is 0.04836961254477501\n",
      "07/24/2023 20:07:18 - INFO - __main__ - Cumulative validation average loss is 14.215756185585633\n",
      "07/24/2023 20:07:19 - INFO - __main__ - Per validation step average loss is 0.068138986825943\n",
      "07/24/2023 20:07:19 - INFO - __main__ - Cumulative validation average loss is 14.283895172411576\n",
      "07/24/2023 20:07:19 - INFO - __main__ - Per validation step average loss is 0.1089073121547699\n",
      "07/24/2023 20:07:19 - INFO - __main__ - Cumulative validation average loss is 14.392802484566346\n",
      "07/24/2023 20:07:19 - INFO - __main__ - Per validation step average loss is 0.29410701990127563\n",
      "07/24/2023 20:07:19 - INFO - __main__ - Cumulative validation average loss is 14.686909504467621\n",
      "07/24/2023 20:07:20 - INFO - __main__ - Per validation step average loss is 0.013084310106933117\n",
      "07/24/2023 20:07:20 - INFO - __main__ - Cumulative validation average loss is 14.699993814574555\n",
      "07/24/2023 20:07:20 - INFO - __main__ - Per validation step average loss is 0.39658036828041077\n",
      "07/24/2023 20:07:20 - INFO - __main__ - Cumulative validation average loss is 15.096574182854965\n",
      "07/24/2023 20:07:21 - INFO - __main__ - Per validation step average loss is 0.004069109447300434\n",
      "07/24/2023 20:07:21 - INFO - __main__ - Cumulative validation average loss is 15.100643292302266\n",
      "07/24/2023 20:07:21 - INFO - __main__ - Per validation step average loss is 0.038457393646240234\n",
      "07/24/2023 20:07:21 - INFO - __main__ - Cumulative validation average loss is 15.139100685948506\n",
      "07/24/2023 20:07:22 - INFO - __main__ - Per validation step average loss is 0.1894107162952423\n",
      "07/24/2023 20:07:22 - INFO - __main__ - Cumulative validation average loss is 15.328511402243748\n",
      "07/24/2023 20:07:22 - INFO - __main__ - Per validation step average loss is 0.08847278356552124\n",
      "07/24/2023 20:07:22 - INFO - __main__ - Cumulative validation average loss is 15.41698418580927\n",
      "07/24/2023 20:07:23 - INFO - __main__ - Per validation step average loss is 0.020906249061226845\n",
      "07/24/2023 20:07:23 - INFO - __main__ - Cumulative validation average loss is 15.437890434870496\n",
      "07/24/2023 20:07:23 - INFO - __main__ - Per validation step average loss is 0.006360743194818497\n",
      "07/24/2023 20:07:23 - INFO - __main__ - Cumulative validation average loss is 15.444251178065315\n",
      "07/24/2023 20:07:23 - INFO - __main__ - Per validation step average loss is 0.009282320737838745\n",
      "07/24/2023 20:07:23 - INFO - __main__ - Cumulative validation average loss is 15.453533498803154\n",
      "07/24/2023 20:07:24 - INFO - __main__ - Per validation step average loss is 0.2132495939731598\n",
      "07/24/2023 20:07:24 - INFO - __main__ - Cumulative validation average loss is 15.666783092776313\n",
      "07/24/2023 20:07:24 - INFO - __main__ - Per validation step average loss is 0.11018479615449905\n",
      "07/24/2023 20:07:24 - INFO - __main__ - Cumulative validation average loss is 15.776967888930812\n",
      "07/24/2023 20:07:25 - INFO - __main__ - Per validation step average loss is 0.047203004360198975\n",
      "07/24/2023 20:07:25 - INFO - __main__ - Cumulative validation average loss is 15.824170893291011\n",
      "07/24/2023 20:07:25 - INFO - __main__ - Per validation step average loss is 0.05610907822847366\n",
      "07/24/2023 20:07:25 - INFO - __main__ - Cumulative validation average loss is 15.880279971519485\n",
      "07/24/2023 20:07:26 - INFO - __main__ - Per validation step average loss is 0.3530104160308838\n",
      "07/24/2023 20:07:26 - INFO - __main__ - Cumulative validation average loss is 16.23329038755037\n",
      "07/24/2023 20:07:26 - INFO - __main__ - Per validation step average loss is 0.3518446981906891\n",
      "07/24/2023 20:07:26 - INFO - __main__ - Cumulative validation average loss is 16.585135085741058\n",
      "07/24/2023 20:07:27 - INFO - __main__ - Per validation step average loss is 0.032759591937065125\n",
      "07/24/2023 20:07:27 - INFO - __main__ - Cumulative validation average loss is 16.617894677678123\n",
      "07/24/2023 20:07:27 - INFO - __main__ - Per validation step average loss is 0.13845381140708923\n",
      "07/24/2023 20:07:27 - INFO - __main__ - Cumulative validation average loss is 16.756348489085212\n",
      "07/24/2023 20:07:28 - INFO - __main__ - Per validation step average loss is 0.0805806815624237\n",
      "07/24/2023 20:07:28 - INFO - __main__ - Cumulative validation average loss is 16.836929170647636\n",
      "07/24/2023 20:07:28 - INFO - __main__ - Per validation step average loss is 0.03643517941236496\n",
      "07/24/2023 20:07:28 - INFO - __main__ - Cumulative validation average loss is 16.87336435006\n",
      "07/24/2023 20:07:28 - INFO - __main__ - Per validation step average loss is 0.006804344244301319\n",
      "07/24/2023 20:07:28 - INFO - __main__ - Cumulative validation average loss is 16.880168694304302\n",
      "07/24/2023 20:07:29 - INFO - __main__ - Per validation step average loss is 0.34049826860427856\n",
      "07/24/2023 20:07:29 - INFO - __main__ - Cumulative validation average loss is 17.22066696290858\n",
      "07/24/2023 20:07:29 - INFO - __main__ - Per validation step average loss is 0.29067787528038025\n",
      "07/24/2023 20:07:29 - INFO - __main__ - Cumulative validation average loss is 17.51134483818896\n",
      "07/24/2023 20:07:30 - INFO - __main__ - Per validation step average loss is 0.1504165530204773\n",
      "07/24/2023 20:07:30 - INFO - __main__ - Cumulative validation average loss is 17.66176139120944\n",
      "07/24/2023 20:07:30 - INFO - __main__ - Per validation step average loss is 0.002790587954223156\n",
      "07/24/2023 20:07:30 - INFO - __main__ - Cumulative validation average loss is 17.66455197916366\n",
      "07/24/2023 20:07:31 - INFO - __main__ - Per validation step average loss is 0.016328712925314903\n",
      "07/24/2023 20:07:31 - INFO - __main__ - Cumulative validation average loss is 17.680880692088977\n",
      "07/24/2023 20:07:31 - INFO - __main__ - Per validation step average loss is 0.013466157019138336\n",
      "07/24/2023 20:07:31 - INFO - __main__ - Cumulative validation average loss is 17.694346849108115\n",
      "07/24/2023 20:07:32 - INFO - __main__ - Per validation step average loss is 0.3126193881034851\n",
      "07/24/2023 20:07:32 - INFO - __main__ - Cumulative validation average loss is 18.0069662372116\n",
      "07/24/2023 20:07:32 - INFO - __main__ - Per validation step average loss is 0.024966027587652206\n",
      "07/24/2023 20:07:32 - INFO - __main__ - Cumulative validation average loss is 18.031932264799252\n",
      "07/24/2023 20:07:32 - INFO - __main__ - Per validation step average loss is 0.35525307059288025\n",
      "07/24/2023 20:07:32 - INFO - __main__ - Cumulative validation average loss is 18.387185335392132\n",
      "07/24/2023 20:07:33 - INFO - __main__ - Per validation step average loss is 0.0855158269405365\n",
      "07/24/2023 20:07:33 - INFO - __main__ - Cumulative validation average loss is 18.47270116233267\n",
      "07/24/2023 20:07:33 - INFO - __main__ - Per validation step average loss is 0.0024038730189204216\n",
      "07/24/2023 20:07:33 - INFO - __main__ - Cumulative validation average loss is 18.47510503535159\n",
      "07/24/2023 20:07:34 - INFO - __main__ - Per validation step average loss is 0.23641008138656616\n",
      "07/24/2023 20:07:34 - INFO - __main__ - Cumulative validation average loss is 18.711515116738155\n",
      "07/24/2023 20:07:34 - INFO - __main__ - Per validation step average loss is 0.153166726231575\n",
      "07/24/2023 20:07:34 - INFO - __main__ - Cumulative validation average loss is 18.86468184296973\n",
      "07/24/2023 20:07:35 - INFO - __main__ - Per validation step average loss is 0.1792914867401123\n",
      "07/24/2023 20:07:35 - INFO - __main__ - Cumulative validation average loss is 19.043973329709843\n",
      "07/24/2023 20:07:35 - INFO - __main__ - Per validation step average loss is 0.028483029454946518\n",
      "07/24/2023 20:07:35 - INFO - __main__ - Cumulative validation average loss is 19.07245635916479\n",
      "07/24/2023 20:07:36 - INFO - __main__ - Per validation step average loss is 0.010311625897884369\n",
      "07/24/2023 20:07:36 - INFO - __main__ - Cumulative validation average loss is 19.082767985062674\n",
      "07/24/2023 20:07:36 - INFO - __main__ - Per validation step average loss is 0.09225775301456451\n",
      "07/24/2023 20:07:36 - INFO - __main__ - Cumulative validation average loss is 19.175025738077238\n",
      "07/24/2023 20:07:36 - INFO - __main__ - Per validation step average loss is 0.01647908054292202\n",
      "07/24/2023 20:07:36 - INFO - __main__ - Cumulative validation average loss is 19.19150481862016\n",
      "07/24/2023 20:07:37 - INFO - __main__ - Per validation step average loss is 0.41145429015159607\n",
      "07/24/2023 20:07:37 - INFO - __main__ - Cumulative validation average loss is 19.602959108771756\n",
      "07/24/2023 20:07:37 - INFO - __main__ - Per validation step average loss is 0.011237763799726963\n",
      "07/24/2023 20:07:37 - INFO - __main__ - Cumulative validation average loss is 19.614196872571483\n",
      "07/24/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.008946134708821774\n",
      "07/24/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 19.623143007280305\n",
      "07/24/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.02781454659998417\n",
      "07/24/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 19.65095755388029\n",
      "07/24/2023 20:07:39 - INFO - __main__ - Per validation step average loss is 0.048204172402620316\n",
      "07/24/2023 20:07:39 - INFO - __main__ - Cumulative validation average loss is 19.69916172628291\n",
      "07/24/2023 20:07:39 - INFO - __main__ - Per validation step average loss is 0.3320159316062927\n",
      "07/24/2023 20:07:39 - INFO - __main__ - Cumulative validation average loss is 20.031177657889202\n",
      "07/24/2023 20:07:40 - INFO - __main__ - Per validation step average loss is 0.0073637389577925205\n",
      "07/24/2023 20:07:40 - INFO - __main__ - Cumulative validation average loss is 20.038541396846995\n",
      "07/24/2023 20:07:40 - INFO - __main__ - Per validation step average loss is 0.026664970442652702\n",
      "07/24/2023 20:07:40 - INFO - __main__ - Cumulative validation average loss is 20.065206367289647\n",
      "07/24/2023 20:07:40 - INFO - __main__ - Per validation step average loss is 0.075229212641716\n",
      "07/24/2023 20:07:40 - INFO - __main__ - Cumulative validation average loss is 20.140435579931363\n",
      "07/24/2023 20:07:41 - INFO - __main__ - Per validation step average loss is 0.32040879130363464\n",
      "07/24/2023 20:07:41 - INFO - __main__ - Cumulative validation average loss is 20.460844371234998\n",
      "07/24/2023 20:07:41 - INFO - __main__ - Per validation step average loss is 0.05781245976686478\n",
      "07/24/2023 20:07:41 - INFO - __main__ - Cumulative validation average loss is 20.518656831001863\n",
      "07/24/2023 20:07:42 - INFO - __main__ - Per validation step average loss is 0.20979762077331543\n",
      "07/24/2023 20:07:42 - INFO - __main__ - Cumulative validation average loss is 20.72845445177518\n",
      "07/24/2023 20:07:42 - INFO - __main__ - Per validation step average loss is 0.03002418577671051\n",
      "07/24/2023 20:07:42 - INFO - __main__ - Cumulative validation average loss is 20.75847863755189\n",
      "07/24/2023 20:07:43 - INFO - __main__ - Per validation step average loss is 0.003101533045992255\n",
      "07/24/2023 20:07:43 - INFO - __main__ - Cumulative validation average loss is 20.76158017059788\n",
      "07/24/2023 20:07:43 - INFO - __main__ - Per validation step average loss is 0.17660218477249146\n",
      "07/24/2023 20:07:43 - INFO - __main__ - Cumulative validation average loss is 20.938182355370373\n",
      "07/24/2023 20:07:44 - INFO - __main__ - Per validation step average loss is 0.17306587100028992\n",
      "07/24/2023 20:07:44 - INFO - __main__ - Cumulative validation average loss is 21.111248226370662\n",
      "07/24/2023 20:07:44 - INFO - __main__ - Per validation step average loss is 0.003534885123372078\n",
      "07/24/2023 20:07:44 - INFO - __main__ - Cumulative validation average loss is 21.114783111494035\n",
      "07/24/2023 20:07:45 - INFO - __main__ - Per validation step average loss is 0.4647647738456726\n",
      "07/24/2023 20:07:45 - INFO - __main__ - Cumulative validation average loss is 21.579547885339707\n",
      "07/24/2023 20:07:45 - INFO - __main__ - Average validation loss for Epoch 0 is 0.13487217428337317\n",
      "07/24/2023 20:07:45 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/24/2023 20:08:44 - INFO - __main__ - Starting epoch 1\n",
      "07/24/2023 20:08:45 - INFO - __main__ - train loss is 0.0731925517320633\n",
      "Steps:   2%| | 308/15000 [04:59<163:03:23, 39.95s/it, lr=7.42e-7, step_loss=0.0707/24/2023 20:08:45 - INFO - __main__ - train loss is 0.07803513668477535\n",
      "Steps:   2%| | 309/15000 [04:59<114:21:35, 28.02s/it, lr=7.45e-7, step_loss=0.0007/24/2023 20:08:45 - INFO - __main__ - train loss is 0.0849272133782506\n",
      "Steps:   2%| | 310/15000 [04:59<80:15:59, 19.67s/it, lr=7.48e-7, step_loss=0.00607/24/2023 20:08:45 - INFO - __main__ - train loss is 0.15340733248740435\n",
      "Steps:   2%| | 311/15000 [05:00<56:24:32, 13.82s/it, lr=7.5e-7, step_loss=0.068507/24/2023 20:08:45 - INFO - __main__ - train loss is 0.1849938901141286\n",
      "Steps:   2%| | 312/15000 [05:00<39:42:22,  9.73s/it, lr=7.52e-7, step_loss=0.03107/24/2023 20:08:46 - INFO - __main__ - train loss is 0.19502531830221415\n",
      "Steps:   2%| | 313/15000 [05:00<28:00:50,  6.87s/it, lr=7.55e-7, step_loss=0.01]07/24/2023 20:08:46 - INFO - __main__ - train loss is 0.21197174582630396\n",
      "Steps:   2%| | 314/15000 [05:00<19:50:09,  4.86s/it, lr=7.58e-7, step_loss=0.01607/24/2023 20:08:46 - INFO - __main__ - train loss is 0.24248278979212046\n",
      "Steps:   2%| | 315/15000 [05:00<14:06:36,  3.46s/it, lr=7.6e-7, step_loss=0.030507/24/2023 20:08:46 - INFO - __main__ - train loss is 0.3522188449278474\n",
      "Steps:   2%| | 316/15000 [05:00<10:05:35,  2.47s/it, lr=7.63e-7, step_loss=0.11]07/24/2023 20:08:46 - INFO - __main__ - train loss is 0.3541637931484729\n",
      "Steps:   2%| | 317/15000 [05:01<7:16:52,  1.79s/it, lr=7.65e-7, step_loss=0.001907/24/2023 20:08:46 - INFO - __main__ - train loss is 0.3617690571118146\n",
      "Steps:   2%| | 318/15000 [05:01<5:18:46,  1.30s/it, lr=7.68e-7, step_loss=0.007607/24/2023 20:08:47 - INFO - __main__ - train loss is 0.8200121589470655\n",
      "Steps:   2%|  | 319/15000 [05:01<3:56:10,  1.04it/s, lr=7.7e-7, step_loss=0.458]07/24/2023 20:08:47 - INFO - __main__ - train loss is 0.8610120110679418\n",
      "Steps:   2%| | 320/15000 [05:01<2:58:18,  1.37it/s, lr=7.73e-7, step_loss=0.041]07/24/2023 20:08:47 - INFO - __main__ - train loss is 0.8953327157068998\n",
      "Steps:   2%| | 321/15000 [05:01<2:17:47,  1.78it/s, lr=7.75e-7, step_loss=0.034307/24/2023 20:08:47 - INFO - __main__ - train loss is 0.9076028887648135\n",
      "Steps:   2%| | 322/15000 [05:02<1:49:46,  2.23it/s, lr=7.78e-7, step_loss=0.012307/24/2023 20:08:47 - INFO - __main__ - train loss is 0.9764009390491992\n",
      "Steps:   2%| | 323/15000 [05:02<1:29:50,  2.72it/s, lr=7.8e-7, step_loss=0.0688]07/24/2023 20:08:48 - INFO - __main__ - train loss is 1.1354346845764667\n",
      "Steps:   2%| | 324/15000 [05:02<1:15:52,  3.22it/s, lr=7.83e-7, step_loss=0.159]07/24/2023 20:08:48 - INFO - __main__ - train loss is 1.174261936219409\n",
      "Steps:   2%| | 325/15000 [05:02<1:06:09,  3.70it/s, lr=7.85e-7, step_loss=0.038807/24/2023 20:08:48 - INFO - __main__ - train loss is 1.185618155868724\n",
      "Steps:   2%|  | 326/15000 [05:02<59:21,  4.12it/s, lr=7.88e-7, step_loss=0.0114]07/24/2023 20:08:48 - INFO - __main__ - train loss is 1.7471235927660018\n",
      "Steps:   2%|    | 327/15000 [05:02<54:34,  4.48it/s, lr=7.9e-7, step_loss=0.562]07/24/2023 20:08:48 - INFO - __main__ - train loss is 1.7759874511975795\n",
      "Steps:   2%|  | 328/15000 [05:03<51:13,  4.77it/s, lr=7.93e-7, step_loss=0.0289]07/24/2023 20:08:48 - INFO - __main__ - train loss is 2.488695089938119\n",
      "Steps:   2%|   | 329/15000 [05:03<48:58,  4.99it/s, lr=7.95e-7, step_loss=0.713]07/24/2023 20:08:49 - INFO - __main__ - train loss is 2.4952072717715055\n",
      "Steps:   2%| | 330/15000 [05:03<47:18,  5.17it/s, lr=7.98e-7, step_loss=0.00651]07/24/2023 20:08:49 - INFO - __main__ - train loss is 3.0222785093355924\n",
      "Steps:   2%|‚ñè     | 331/15000 [05:03<46:07,  5.30it/s, lr=8e-7, step_loss=0.527]07/24/2023 20:08:49 - INFO - __main__ - train loss is 3.134177289204672\n",
      "Steps:   2%|   | 332/15000 [05:03<45:18,  5.40it/s, lr=8.03e-7, step_loss=0.112]07/24/2023 20:08:49 - INFO - __main__ - train loss is 3.1536381982732564\n",
      "Steps:   2%|  | 333/15000 [05:03<44:45,  5.46it/s, lr=8.05e-7, step_loss=0.0195]07/24/2023 20:08:49 - INFO - __main__ - train loss is 3.408422663109377\n",
      "Steps:   2%|   | 334/15000 [05:04<44:46,  5.46it/s, lr=8.08e-7, step_loss=0.255]07/24/2023 20:08:49 - INFO - __main__ - train loss is 3.411559028085321\n",
      "Steps:   2%|  | 335/15000 [05:04<44:35,  5.48it/s, lr=8.1e-7, step_loss=0.00314]07/24/2023 20:08:50 - INFO - __main__ - train loss is 3.7715127891860902\n",
      "Steps:   2%|    | 336/15000 [05:04<44:15,  5.52it/s, lr=8.13e-7, step_loss=0.36]07/24/2023 20:08:50 - INFO - __main__ - train loss is 3.9985911077819765\n",
      "Steps:   2%|   | 337/15000 [05:04<44:01,  5.55it/s, lr=8.15e-7, step_loss=0.227]07/24/2023 20:08:50 - INFO - __main__ - train loss is 4.382422310765833\n",
      "Steps:   2%|   | 338/15000 [05:04<43:49,  5.58it/s, lr=8.18e-7, step_loss=0.384]07/24/2023 20:08:50 - INFO - __main__ - train loss is 4.39737095637247\n",
      "Steps:   2%|   | 339/15000 [05:05<43:42,  5.59it/s, lr=8.2e-7, step_loss=0.0149]07/24/2023 20:08:50 - INFO - __main__ - train loss is 4.477101705502719\n",
      "Steps:   2%|  | 340/15000 [05:05<43:41,  5.59it/s, lr=8.23e-7, step_loss=0.0797]07/24/2023 20:08:51 - INFO - __main__ - train loss is 4.566720567177981\n",
      "Steps:   2%|  | 341/15000 [05:05<43:35,  5.60it/s, lr=8.25e-7, step_loss=0.0896]07/24/2023 20:08:51 - INFO - __main__ - train loss is 4.659438132774085\n",
      "Steps:   2%|  | 342/15000 [05:05<43:30,  5.61it/s, lr=8.28e-7, step_loss=0.0927]07/24/2023 20:08:51 - INFO - __main__ - train loss is 4.97125071240589\n",
      "Steps:   2%|    | 343/15000 [05:05<43:28,  5.62it/s, lr=8.3e-7, step_loss=0.312]07/24/2023 20:08:51 - INFO - __main__ - train loss is 4.9823865299113095\n",
      "Steps:   2%|  | 344/15000 [05:05<43:24,  5.63it/s, lr=8.33e-7, step_loss=0.0111]07/24/2023 20:08:51 - INFO - __main__ - train loss is 5.016588423866779\n",
      "Steps:   2%|  | 345/15000 [05:06<43:24,  5.63it/s, lr=8.35e-7, step_loss=0.0342]07/24/2023 20:08:51 - INFO - __main__ - train loss is 5.252454463858157\n",
      "Steps:   2%|   | 346/15000 [05:06<43:23,  5.63it/s, lr=8.38e-7, step_loss=0.236]07/24/2023 20:08:52 - INFO - __main__ - train loss is 5.385185022372752\n",
      "Steps:   2%|    | 347/15000 [05:06<43:24,  5.63it/s, lr=8.4e-7, step_loss=0.133]07/24/2023 20:08:52 - INFO - __main__ - train loss is 5.675658990163356\n",
      "Steps:   2%|    | 348/15000 [05:06<43:24,  5.63it/s, lr=8.43e-7, step_loss=0.29]07/24/2023 20:08:52 - INFO - __main__ - train loss is 5.711695392150432\n",
      "Steps:   2%|   | 349/15000 [05:06<43:23,  5.63it/s, lr=8.45e-7, step_loss=0.036]07/24/2023 20:08:52 - INFO - __main__ - train loss is 5.824386705178767\n",
      "Steps:   2%|   | 350/15000 [05:07<43:23,  5.63it/s, lr=8.48e-7, step_loss=0.113]07/24/2023 20:08:52 - INFO - __main__ - train loss is 6.242347289342433\n",
      "Steps:   2%|    | 351/15000 [05:07<43:28,  5.62it/s, lr=8.5e-7, step_loss=0.418]07/24/2023 20:08:53 - INFO - __main__ - train loss is 6.415539760608226\n",
      "Steps:   2%|   | 352/15000 [05:07<43:26,  5.62it/s, lr=8.53e-7, step_loss=0.173]07/24/2023 20:08:53 - INFO - __main__ - train loss is 6.535646621603519\n",
      "Steps:   2%|    | 353/15000 [05:07<43:24,  5.62it/s, lr=8.55e-7, step_loss=0.12]07/24/2023 20:08:53 - INFO - __main__ - train loss is 7.290967289824039\n",
      "Steps:   2%|   | 354/15000 [05:07<43:26,  5.62it/s, lr=8.58e-7, step_loss=0.755]07/24/2023 20:08:53 - INFO - __main__ - train loss is 7.355422337073833\n",
      "Steps:   2%|   | 355/15000 [05:07<43:25,  5.62it/s, lr=8.6e-7, step_loss=0.0645]07/24/2023 20:08:53 - INFO - __main__ - train loss is 7.834175844211131\n",
      "Steps:   2%|   | 356/15000 [05:08<43:29,  5.61it/s, lr=8.63e-7, step_loss=0.479]07/24/2023 20:08:53 - INFO - __main__ - train loss is 7.8361291761975735\n",
      "Steps:   2%| | 357/15000 [05:08<43:26,  5.62it/s, lr=8.65e-7, step_loss=0.00195]07/24/2023 20:08:54 - INFO - __main__ - train loss is 8.288118826923892\n",
      "Steps:   2%|   | 358/15000 [05:08<43:25,  5.62it/s, lr=8.68e-7, step_loss=0.452]07/24/2023 20:08:54 - INFO - __main__ - train loss is 8.296707410132512\n",
      "Steps:   2%|  | 359/15000 [05:08<43:25,  5.62it/s, lr=8.7e-7, step_loss=0.00859]07/24/2023 20:08:54 - INFO - __main__ - train loss is 8.300793220987543\n",
      "Steps:   2%| | 360/15000 [05:08<43:23,  5.62it/s, lr=8.73e-7, step_loss=0.00409]07/24/2023 20:08:54 - INFO - __main__ - train loss is 8.600658228388056\n",
      "Steps:   2%|     | 361/15000 [05:08<43:22,  5.62it/s, lr=8.75e-7, step_loss=0.3]07/24/2023 20:08:54 - INFO - __main__ - train loss is 8.715341655304655\n",
      "Steps:   2%|   | 362/15000 [05:09<43:36,  5.59it/s, lr=8.78e-7, step_loss=0.115]07/24/2023 20:08:54 - INFO - __main__ - train loss is 8.729591422481462\n",
      "Steps:   2%|   | 363/15000 [05:09<43:31,  5.60it/s, lr=8.8e-7, step_loss=0.0142]07/24/2023 20:08:55 - INFO - __main__ - train loss is 8.912636109394953\n",
      "Steps:   2%|   | 364/15000 [05:09<43:28,  5.61it/s, lr=8.83e-7, step_loss=0.183]07/24/2023 20:08:55 - INFO - __main__ - train loss is 9.061552711529657\n",
      "Steps:   2%|   | 365/15000 [05:09<43:27,  5.61it/s, lr=8.85e-7, step_loss=0.149]07/24/2023 20:08:55 - INFO - __main__ - train loss is 9.123927705688402\n",
      "Steps:   2%|  | 366/15000 [05:09<43:25,  5.62it/s, lr=8.88e-7, step_loss=0.0624]07/24/2023 20:08:55 - INFO - __main__ - train loss is 9.415678047342226\n",
      "Steps:   2%|    | 367/15000 [05:10<43:44,  5.58it/s, lr=8.9e-7, step_loss=0.292]07/24/2023 20:08:55 - INFO - __main__ - train loss is 9.50564628909342\n",
      "Steps:   2%|    | 368/15000 [05:10<43:39,  5.59it/s, lr=8.93e-7, step_loss=0.09]07/24/2023 20:08:56 - INFO - __main__ - train loss is 10.005504787666723\n",
      "Steps:   2%|     | 369/15000 [05:10<43:34,  5.60it/s, lr=8.95e-7, step_loss=0.5]07/24/2023 20:08:56 - INFO - __main__ - train loss is 10.011156886583194\n",
      "Steps:   2%| | 370/15000 [05:10<43:57,  5.55it/s, lr=8.98e-7, step_loss=0.00565]07/24/2023 20:08:56 - INFO - __main__ - train loss is 10.383142918115482\n",
      "Steps:   2%|‚ñè     | 371/15000 [05:10<44:12,  5.51it/s, lr=9e-7, step_loss=0.372]07/24/2023 20:08:56 - INFO - __main__ - train loss is 10.580177843337879\n",
      "Steps:   2%|   | 372/15000 [05:10<44:06,  5.53it/s, lr=9.03e-7, step_loss=0.197]07/24/2023 20:08:56 - INFO - __main__ - train loss is 10.707105636363849\n",
      "Steps:   2%|   | 373/15000 [05:11<43:53,  5.55it/s, lr=9.05e-7, step_loss=0.127]07/24/2023 20:08:56 - INFO - __main__ - train loss is 10.71384425717406\n",
      "Steps:   2%| | 374/15000 [05:11<43:43,  5.58it/s, lr=9.08e-7, step_loss=0.00674]07/24/2023 20:08:57 - INFO - __main__ - train loss is 11.006584125338122\n",
      "Steps:   2%|    | 375/15000 [05:11<43:34,  5.59it/s, lr=9.1e-7, step_loss=0.293]07/24/2023 20:08:57 - INFO - __main__ - train loss is 11.123484479961917\n",
      "Steps:   3%|   | 376/15000 [05:11<43:27,  5.61it/s, lr=9.13e-7, step_loss=0.117]07/24/2023 20:08:57 - INFO - __main__ - train loss is 11.127787455683574\n",
      "Steps:   3%|  | 377/15000 [05:11<43:24,  5.61it/s, lr=9.15e-7, step_loss=0.0043]07/24/2023 20:08:57 - INFO - __main__ - train loss is 11.160281281685457\n",
      "Steps:   3%|  | 378/15000 [05:12<43:23,  5.62it/s, lr=9.18e-7, step_loss=0.0325]07/24/2023 20:08:57 - INFO - __main__ - train loss is 11.174660511082038\n",
      "Steps:   3%|   | 379/15000 [05:12<43:20,  5.62it/s, lr=9.2e-7, step_loss=0.0144]07/24/2023 20:08:58 - INFO - __main__ - train loss is 11.599688745802268\n",
      "Steps:   3%|   | 380/15000 [05:12<43:18,  5.63it/s, lr=9.23e-7, step_loss=0.425]07/24/2023 20:08:58 - INFO - __main__ - train loss is 11.710277892416343\n",
      "Steps:   3%|   | 381/15000 [05:12<43:17,  5.63it/s, lr=9.25e-7, step_loss=0.111]07/24/2023 20:08:58 - INFO - __main__ - train loss is 11.761167526012287\n",
      "Steps:   3%|  | 382/15000 [05:12<43:20,  5.62it/s, lr=9.28e-7, step_loss=0.0509]07/24/2023 20:08:58 - INFO - __main__ - train loss is 11.966810017591342\n",
      "Steps:   3%|    | 383/15000 [05:12<43:19,  5.62it/s, lr=9.3e-7, step_loss=0.206]07/24/2023 20:08:58 - INFO - __main__ - train loss is 11.968842865666375\n",
      "Steps:   3%| | 384/15000 [05:13<43:17,  5.63it/s, lr=9.33e-7, step_loss=0.00203]07/24/2023 20:08:58 - INFO - __main__ - train loss is 12.192704872926697\n",
      "Steps:   3%|   | 385/15000 [05:13<43:16,  5.63it/s, lr=9.35e-7, step_loss=0.224]07/24/2023 20:08:59 - INFO - __main__ - train loss is 12.605054216226563\n",
      "Steps:   3%|   | 386/15000 [05:13<43:15,  5.63it/s, lr=9.38e-7, step_loss=0.412]07/24/2023 20:08:59 - INFO - __main__ - train loss is 12.950604604324326\n",
      "Steps:   3%|    | 387/15000 [05:13<43:16,  5.63it/s, lr=9.4e-7, step_loss=0.346]07/24/2023 20:08:59 - INFO - __main__ - train loss is 12.95442962856032\n",
      "Steps:   3%| | 388/15000 [05:13<43:15,  5.63it/s, lr=9.43e-7, step_loss=0.00383]07/24/2023 20:08:59 - INFO - __main__ - train loss is 12.95934334746562\n",
      "Steps:   3%| | 389/15000 [05:13<43:40,  5.58it/s, lr=9.45e-7, step_loss=0.00491]07/24/2023 20:08:59 - INFO - __main__ - train loss is 13.601798448478803\n",
      "Steps:   3%|   | 390/15000 [05:14<43:58,  5.54it/s, lr=9.48e-7, step_loss=0.642]07/24/2023 20:08:59 - INFO - __main__ - train loss is 13.870307925855741\n",
      "Steps:   3%|    | 391/15000 [05:14<43:51,  5.55it/s, lr=9.5e-7, step_loss=0.269]07/24/2023 20:09:00 - INFO - __main__ - train loss is 13.937750700628385\n",
      "Steps:   3%|  | 392/15000 [05:14<43:42,  5.57it/s, lr=9.53e-7, step_loss=0.0674]07/24/2023 20:09:00 - INFO - __main__ - train loss is 13.968014143174514\n",
      "Steps:   3%|  | 393/15000 [05:14<43:36,  5.58it/s, lr=9.55e-7, step_loss=0.0303]07/24/2023 20:09:00 - INFO - __main__ - train loss is 13.982344650430605\n",
      "Steps:   3%|  | 394/15000 [05:14<43:29,  5.60it/s, lr=9.58e-7, step_loss=0.0143]07/24/2023 20:09:00 - INFO - __main__ - train loss is 13.997869114158675\n",
      "Steps:   3%|   | 395/15000 [05:15<43:48,  5.56it/s, lr=9.6e-7, step_loss=0.0155]07/24/2023 20:09:00 - INFO - __main__ - train loss is 14.008705688407645\n",
      "Steps:   3%|  | 396/15000 [05:15<43:40,  5.57it/s, lr=9.63e-7, step_loss=0.0108]07/24/2023 20:09:01 - INFO - __main__ - train loss is 14.04484057216905\n",
      "Steps:   3%|  | 397/15000 [05:15<43:35,  5.58it/s, lr=9.65e-7, step_loss=0.0361]07/24/2023 20:09:01 - INFO - __main__ - train loss is 14.046748872380704\n",
      "Steps:   3%| | 398/15000 [05:15<43:44,  5.56it/s, lr=9.68e-7, step_loss=0.00191]07/24/2023 20:09:01 - INFO - __main__ - train loss is 14.097815088462085\n",
      "Steps:   3%|   | 399/15000 [05:15<43:59,  5.53it/s, lr=9.7e-7, step_loss=0.0511]07/24/2023 20:09:01 - INFO - __main__ - train loss is 14.115209524985403\n",
      "Steps:   3%|  | 400/15000 [05:15<43:47,  5.56it/s, lr=9.73e-7, step_loss=0.0174]07/24/2023 20:09:01 - INFO - __main__ - train loss is 14.171418534126133\n",
      "Steps:   3%|  | 401/15000 [05:16<44:04,  5.52it/s, lr=9.75e-7, step_loss=0.0562]07/24/2023 20:09:01 - INFO - __main__ - train loss is 14.174155515152961\n",
      "Steps:   3%| | 402/15000 [05:16<43:53,  5.54it/s, lr=9.78e-7, step_loss=0.00274]07/24/2023 20:09:02 - INFO - __main__ - train loss is 14.23924643965438\n",
      "Steps:   3%|   | 403/15000 [05:16<43:43,  5.56it/s, lr=9.8e-7, step_loss=0.0651]07/24/2023 20:09:02 - INFO - __main__ - train loss is 14.683424424845725\n",
      "Steps:   3%|   | 404/15000 [05:16<43:36,  5.58it/s, lr=9.83e-7, step_loss=0.444]07/24/2023 20:09:02 - INFO - __main__ - train loss is 14.95643736096099\n",
      "Steps:   3%|   | 405/15000 [05:16<43:30,  5.59it/s, lr=9.85e-7, step_loss=0.273]07/24/2023 20:09:02 - INFO - __main__ - train loss is 14.978006929624826\n",
      "Steps:   3%|  | 406/15000 [05:17<43:25,  5.60it/s, lr=9.88e-7, step_loss=0.0216]07/24/2023 20:09:02 - INFO - __main__ - train loss is 15.682324618566781\n",
      "Steps:   3%|    | 407/15000 [05:17<43:24,  5.60it/s, lr=9.9e-7, step_loss=0.704]07/24/2023 20:09:03 - INFO - __main__ - train loss is 15.691389732528478\n",
      "Steps:   3%| | 408/15000 [05:17<43:24,  5.60it/s, lr=9.93e-7, step_loss=0.00907]07/24/2023 20:09:03 - INFO - __main__ - train loss is 15.8339097131975\n",
      "Steps:   3%|   | 409/15000 [05:17<43:28,  5.59it/s, lr=9.95e-7, step_loss=0.143]07/24/2023 20:09:03 - INFO - __main__ - train loss is 16.147887967992574\n",
      "Steps:   3%|   | 410/15000 [05:17<43:26,  5.60it/s, lr=9.98e-7, step_loss=0.314]07/24/2023 20:09:03 - INFO - __main__ - train loss is 16.418560408521444\n",
      "Steps:   3%|‚ñè     | 411/15000 [05:17<43:25,  5.60it/s, lr=1e-6, step_loss=0.271]07/24/2023 20:09:03 - INFO - __main__ - train loss is 16.422902210149914\n",
      "Steps:   3%|    | 412/15000 [05:18<43:23,  5.60it/s, lr=1e-6, step_loss=0.00434]07/24/2023 20:09:03 - INFO - __main__ - train loss is 16.473146798554808\n",
      "Steps:   3%|  | 413/15000 [05:18<43:22,  5.61it/s, lr=1.01e-6, step_loss=0.0502]07/24/2023 20:09:04 - INFO - __main__ - train loss is 16.477714104112238\n",
      "Steps:   3%| | 414/15000 [05:18<43:21,  5.61it/s, lr=1.01e-6, step_loss=0.00457]07/24/2023 20:09:04 - INFO - __main__ - train loss is 16.743395698722452\n",
      "Steps:   3%|   | 415/15000 [05:18<43:22,  5.60it/s, lr=1.01e-6, step_loss=0.266]07/24/2023 20:09:04 - INFO - __main__ - train loss is 16.951210794504732\n",
      "Steps:   3%|   | 416/15000 [05:18<43:21,  5.61it/s, lr=1.01e-6, step_loss=0.208]07/24/2023 20:09:04 - INFO - __main__ - train loss is 17.003733751829714\n",
      "Steps:   3%|  | 417/15000 [05:19<43:20,  5.61it/s, lr=1.02e-6, step_loss=0.0525]07/24/2023 20:09:04 - INFO - __main__ - train loss is 17.037108165677637\n",
      "Steps:   3%|  | 418/15000 [05:19<43:18,  5.61it/s, lr=1.02e-6, step_loss=0.0334]07/24/2023 20:09:04 - INFO - __main__ - train loss is 17.04072173149325\n",
      "Steps:   3%| | 419/15000 [05:19<43:18,  5.61it/s, lr=1.02e-6, step_loss=0.00361]07/24/2023 20:09:05 - INFO - __main__ - train loss is 17.122922884533182\n",
      "Steps:   3%|  | 420/15000 [05:19<43:28,  5.59it/s, lr=1.02e-6, step_loss=0.0822]07/24/2023 20:09:05 - INFO - __main__ - train loss is 17.161453848937526\n",
      "Steps:   3%|  | 421/15000 [05:19<43:25,  5.60it/s, lr=1.02e-6, step_loss=0.0385]07/24/2023 20:09:05 - INFO - __main__ - train loss is 17.1773651430849\n",
      "Steps:   3%|  | 422/15000 [05:19<43:31,  5.58it/s, lr=1.03e-6, step_loss=0.0159]07/24/2023 20:09:05 - INFO - __main__ - train loss is 17.242439408088103\n",
      "Steps:   3%|  | 423/15000 [05:20<43:30,  5.58it/s, lr=1.03e-6, step_loss=0.0651]07/24/2023 20:09:05 - INFO - __main__ - train loss is 17.322368283057585\n",
      "Steps:   3%|  | 424/15000 [05:20<43:25,  5.59it/s, lr=1.03e-6, step_loss=0.0799]07/24/2023 20:09:06 - INFO - __main__ - train loss is 17.343026248971\n",
      "Steps:   3%|  | 425/15000 [05:20<43:37,  5.57it/s, lr=1.04e-6, step_loss=0.0207]07/24/2023 20:09:06 - INFO - __main__ - train loss is 18.06545993522741\n",
      "Steps:   3%|   | 426/15000 [05:20<43:36,  5.57it/s, lr=1.04e-6, step_loss=0.722]07/24/2023 20:09:06 - INFO - __main__ - train loss is 18.271682976046577\n",
      "Steps:   3%|   | 427/15000 [05:20<43:35,  5.57it/s, lr=1.04e-6, step_loss=0.206]07/24/2023 20:09:06 - INFO - __main__ - train loss is 18.430029450217262\n",
      "Steps:   3%|   | 428/15000 [05:20<43:28,  5.59it/s, lr=1.04e-6, step_loss=0.158]07/24/2023 20:09:06 - INFO - __main__ - train loss is 18.562916217604652\n",
      "Steps:   3%|   | 429/15000 [05:21<43:25,  5.59it/s, lr=1.04e-6, step_loss=0.133]07/24/2023 20:09:06 - INFO - __main__ - train loss is 18.56628339155577\n",
      "Steps:   3%| | 430/15000 [05:21<43:39,  5.56it/s, lr=1.05e-6, step_loss=0.00337]07/24/2023 20:09:07 - INFO - __main__ - train loss is 18.570395519724116\n",
      "Steps:   3%| | 431/15000 [05:21<43:38,  5.56it/s, lr=1.05e-6, step_loss=0.00411]07/24/2023 20:09:07 - INFO - __main__ - train loss is 18.650486116996035\n",
      "Steps:   3%|  | 432/15000 [05:21<43:29,  5.58it/s, lr=1.05e-6, step_loss=0.0801]07/24/2023 20:09:07 - INFO - __main__ - train loss is 18.684566309442744\n",
      "Steps:   3%|  | 433/15000 [05:21<43:22,  5.60it/s, lr=1.06e-6, step_loss=0.0341]07/24/2023 20:09:07 - INFO - __main__ - train loss is 18.80607529520057\n",
      "Steps:   3%|   | 434/15000 [05:22<43:18,  5.60it/s, lr=1.06e-6, step_loss=0.122]07/24/2023 20:09:07 - INFO - __main__ - train loss is 18.809244801988825\n",
      "Steps:   3%| | 435/15000 [05:22<43:16,  5.61it/s, lr=1.06e-6, step_loss=0.00317]07/24/2023 20:09:08 - INFO - __main__ - train loss is 18.934635093202814\n",
      "Steps:   3%|   | 436/15000 [05:22<43:13,  5.62it/s, lr=1.06e-6, step_loss=0.125]07/24/2023 20:09:08 - INFO - __main__ - train loss is 19.08168682991527\n",
      "Steps:   3%|   | 437/15000 [05:22<43:11,  5.62it/s, lr=1.06e-6, step_loss=0.147]07/24/2023 20:09:08 - INFO - __main__ - train loss is 19.20487261353992\n",
      "Steps:   3%|   | 438/15000 [05:22<43:10,  5.62it/s, lr=1.07e-6, step_loss=0.123]07/24/2023 20:09:08 - INFO - __main__ - train loss is 19.274167021503672\n",
      "Steps:   3%|  | 439/15000 [05:22<43:11,  5.62it/s, lr=1.07e-6, step_loss=0.0693]07/24/2023 20:09:08 - INFO - __main__ - train loss is 19.281784906750545\n",
      "Steps:   3%| | 440/15000 [05:23<43:11,  5.62it/s, lr=1.07e-6, step_loss=0.00762]07/24/2023 20:09:08 - INFO - __main__ - train loss is 19.47812859690748\n",
      "Steps:   3%|   | 441/15000 [05:23<43:11,  5.62it/s, lr=1.08e-6, step_loss=0.196]07/24/2023 20:09:09 - INFO - __main__ - train loss is 19.98947648680769\n",
      "Steps:   3%|   | 442/15000 [05:23<43:16,  5.61it/s, lr=1.08e-6, step_loss=0.511]07/24/2023 20:09:09 - INFO - __main__ - train loss is 20.18474329984747\n",
      "Steps:   3%|   | 443/15000 [05:23<43:15,  5.61it/s, lr=1.08e-6, step_loss=0.195]07/24/2023 20:09:09 - INFO - __main__ - train loss is 20.21849437034689\n",
      "Steps:   3%|  | 444/15000 [05:23<43:12,  5.61it/s, lr=1.08e-6, step_loss=0.0338]07/24/2023 20:09:09 - INFO - __main__ - train loss is 20.234446489950642\n",
      "Steps:   3%|   | 445/15000 [05:24<43:12,  5.62it/s, lr=1.08e-6, step_loss=0.016]07/24/2023 20:09:09 - INFO - __main__ - train loss is 20.399594450136647\n",
      "Steps:   3%|   | 446/15000 [05:24<43:10,  5.62it/s, lr=1.09e-6, step_loss=0.165]07/24/2023 20:09:09 - INFO - __main__ - train loss is 20.405539106344804\n",
      "Steps:   3%| | 447/15000 [05:24<43:13,  5.61it/s, lr=1.09e-6, step_loss=0.00594]07/24/2023 20:09:10 - INFO - __main__ - train loss is 20.48573075584136\n",
      "Steps:   3%|  | 448/15000 [05:24<43:11,  5.62it/s, lr=1.09e-6, step_loss=0.0802]07/24/2023 20:09:10 - INFO - __main__ - train loss is 20.503460753476247\n",
      "Steps:   3%|   | 449/15000 [05:24<43:32,  5.57it/s, lr=1.1e-6, step_loss=0.0177]07/24/2023 20:09:10 - INFO - __main__ - train loss is 20.563529956853017\n",
      "Steps:   3%|   | 450/15000 [05:24<43:24,  5.59it/s, lr=1.1e-6, step_loss=0.0601]07/24/2023 20:09:10 - INFO - __main__ - train loss is 20.642349671339616\n",
      "Steps:   3%|   | 451/15000 [05:25<43:19,  5.60it/s, lr=1.1e-6, step_loss=0.0788]07/24/2023 20:09:10 - INFO - __main__ - train loss is 20.644731238717213\n",
      "Steps:   3%|  | 452/15000 [05:25<43:16,  5.60it/s, lr=1.1e-6, step_loss=0.00238]07/24/2023 20:09:11 - INFO - __main__ - train loss is 20.681634351843968\n",
      "Steps:   3%|  | 453/15000 [05:25<43:14,  5.61it/s, lr=1.11e-6, step_loss=0.0369]07/24/2023 20:09:11 - INFO - __main__ - train loss is 21.006982550257817\n",
      "Steps:   3%|   | 454/15000 [05:25<43:36,  5.56it/s, lr=1.11e-6, step_loss=0.325]07/24/2023 20:09:11 - INFO - __main__ - train loss is 21.243621066445485\n",
      "Steps:   3%|   | 455/15000 [05:25<43:28,  5.58it/s, lr=1.11e-6, step_loss=0.237]07/24/2023 20:09:11 - INFO - __main__ - train loss is 21.394740358227864\n",
      "Steps:   3%|   | 456/15000 [05:25<43:33,  5.56it/s, lr=1.11e-6, step_loss=0.151]07/24/2023 20:09:11 - INFO - __main__ - train loss is 21.50739297294058\n",
      "Steps:   3%|   | 457/15000 [05:26<43:26,  5.58it/s, lr=1.12e-6, step_loss=0.113]07/24/2023 20:09:11 - INFO - __main__ - train loss is 21.62909796857275\n",
      "Steps:   3%|   | 458/15000 [05:26<43:21,  5.59it/s, lr=1.12e-6, step_loss=0.122]07/24/2023 20:09:12 - INFO - __main__ - train loss is 21.821182012790814\n",
      "Steps:   3%|   | 459/15000 [05:26<43:18,  5.60it/s, lr=1.12e-6, step_loss=0.192]07/24/2023 20:09:12 - INFO - __main__ - train loss is 21.90188129269518\n",
      "Steps:   3%|  | 460/15000 [05:26<43:14,  5.60it/s, lr=1.12e-6, step_loss=0.0807]07/24/2023 20:09:12 - INFO - __main__ - train loss is 21.984046563738957\n",
      "Steps:   3%|  | 461/15000 [05:26<43:14,  5.60it/s, lr=1.13e-6, step_loss=0.0822]07/24/2023 20:09:12 - INFO - __main__ - train loss is 21.996678567724302\n",
      "Steps:   3%|  | 462/15000 [05:27<43:12,  5.61it/s, lr=1.13e-6, step_loss=0.0126]07/24/2023 20:09:12 - INFO - __main__ - train loss is 22.388176179723814\n",
      "Steps:   3%|   | 463/15000 [05:27<43:11,  5.61it/s, lr=1.13e-6, step_loss=0.391]07/24/2023 20:09:13 - INFO - __main__ - train loss is 22.401159783126786\n",
      "Steps:   3%|   | 464/15000 [05:27<43:13,  5.61it/s, lr=1.13e-6, step_loss=0.013]07/24/2023 20:09:13 - INFO - __main__ - train loss is 22.707568963291124\n",
      "Steps:   3%|   | 465/15000 [05:27<43:13,  5.60it/s, lr=1.14e-6, step_loss=0.306]07/24/2023 20:09:13 - INFO - __main__ - train loss is 23.227328260662034\n",
      "Steps:   3%|    | 466/15000 [05:27<43:11,  5.61it/s, lr=1.14e-6, step_loss=0.52]07/24/2023 20:09:13 - INFO - __main__ - train loss is 23.58114927005954\n",
      "Steps:   3%|   | 467/15000 [05:27<43:17,  5.60it/s, lr=1.14e-6, step_loss=0.354]07/24/2023 20:09:13 - INFO - __main__ - train loss is 23.641729139955714\n",
      "Steps:   3%|  | 468/15000 [05:28<43:13,  5.60it/s, lr=1.14e-6, step_loss=0.0606]07/24/2023 20:09:13 - INFO - __main__ - train loss is 23.721261316211894\n",
      "Steps:   3%|  | 469/15000 [05:28<43:12,  5.60it/s, lr=1.15e-6, step_loss=0.0795]07/24/2023 20:09:14 - INFO - __main__ - train loss is 23.773273871513084\n",
      "Steps:   3%|   | 470/15000 [05:28<43:12,  5.60it/s, lr=1.15e-6, step_loss=0.052]07/24/2023 20:09:14 - INFO - __main__ - train loss is 24.049518720479682\n",
      "Steps:   3%|   | 471/15000 [05:28<43:27,  5.57it/s, lr=1.15e-6, step_loss=0.276]07/24/2023 20:09:14 - INFO - __main__ - train loss is 24.170452148886397\n",
      "Steps:   3%|   | 472/15000 [05:28<43:40,  5.54it/s, lr=1.15e-6, step_loss=0.121]07/24/2023 20:09:14 - INFO - __main__ - train loss is 24.1788387990091\n",
      "Steps:   3%| | 473/15000 [05:29<43:37,  5.55it/s, lr=1.16e-6, step_loss=0.00839]07/24/2023 20:09:14 - INFO - __main__ - train loss is 24.21272192732431\n",
      "Steps:   3%|  | 474/15000 [05:29<43:48,  5.53it/s, lr=1.16e-6, step_loss=0.0339]07/24/2023 20:09:15 - INFO - __main__ - train loss is 24.70235343114473\n",
      "Steps:   3%|‚ñè   | 475/15000 [05:29<43:36,  5.55it/s, lr=1.16e-6, step_loss=0.49]07/24/2023 20:09:15 - INFO - __main__ - train loss is 25.096735937753692\n",
      "Steps:   3%|   | 476/15000 [05:29<43:26,  5.57it/s, lr=1.16e-6, step_loss=0.394]07/24/2023 20:09:15 - INFO - __main__ - train loss is 25.29482355550863\n",
      "Steps:   3%|   | 477/15000 [05:29<43:17,  5.59it/s, lr=1.17e-6, step_loss=0.198]07/24/2023 20:09:15 - INFO - __main__ - train loss is 25.88857284025289\n",
      "Steps:   3%|   | 478/15000 [05:29<43:17,  5.59it/s, lr=1.17e-6, step_loss=0.594]07/24/2023 20:09:15 - INFO - __main__ - train loss is 26.767918257275596\n",
      "Steps:   3%|   | 479/15000 [05:30<43:19,  5.59it/s, lr=1.17e-6, step_loss=0.879]07/24/2023 20:09:15 - INFO - __main__ - train loss is 26.770096241263673\n",
      "Steps:   3%| | 480/15000 [05:30<43:16,  5.59it/s, lr=1.17e-6, step_loss=0.00218]07/24/2023 20:09:16 - INFO - __main__ - train loss is 26.824533789185807\n",
      "Steps:   3%|  | 481/15000 [05:30<43:20,  5.58it/s, lr=1.17e-6, step_loss=0.0544]07/24/2023 20:09:16 - INFO - __main__ - train loss is 26.827718458371237\n",
      "Steps:   3%| | 482/15000 [05:30<43:17,  5.59it/s, lr=1.18e-6, step_loss=0.00318]07/24/2023 20:09:16 - INFO - __main__ - train loss is 27.26818560739048\n",
      "Steps:   3%|‚ñè   | 483/15000 [05:30<43:12,  5.60it/s, lr=1.18e-6, step_loss=0.44]07/24/2023 20:09:16 - INFO - __main__ - train loss is 27.425763509469107\n",
      "Steps:   3%|   | 484/15000 [05:30<43:13,  5.60it/s, lr=1.18e-6, step_loss=0.158]07/24/2023 20:09:16 - INFO - __main__ - train loss is 27.440782892750576\n",
      "Steps:   3%|   | 485/15000 [05:31<43:10,  5.60it/s, lr=1.19e-6, step_loss=0.015]07/24/2023 20:09:16 - INFO - __main__ - train loss is 27.445501560578123\n",
      "Steps:   3%| | 486/15000 [05:31<43:09,  5.61it/s, lr=1.19e-6, step_loss=0.00472]07/24/2023 20:09:17 - INFO - __main__ - train loss is 27.49072381691076\n",
      "Steps:   3%|  | 487/15000 [05:31<43:07,  5.61it/s, lr=1.19e-6, step_loss=0.0452]07/24/2023 20:09:17 - INFO - __main__ - train loss is 27.494226689450443\n",
      "Steps:   3%|  | 488/15000 [05:31<43:06,  5.61it/s, lr=1.19e-6, step_loss=0.0035]07/24/2023 20:09:17 - INFO - __main__ - train loss is 27.685812438838184\n",
      "Steps:   3%|   | 489/15000 [05:31<43:04,  5.61it/s, lr=1.19e-6, step_loss=0.192]07/24/2023 20:09:17 - INFO - __main__ - train loss is 27.879013086669147\n",
      "Steps:   3%|‚ñè   | 490/15000 [05:32<43:21,  5.58it/s, lr=1.2e-6, step_loss=0.193]07/24/2023 20:09:17 - INFO - __main__ - train loss is 27.935175011865795\n",
      "Steps:   3%|   | 491/15000 [05:32<43:40,  5.54it/s, lr=1.2e-6, step_loss=0.0562]07/24/2023 20:09:18 - INFO - __main__ - train loss is 27.969730908982456\n",
      "Steps:   3%|   | 492/15000 [05:32<43:57,  5.50it/s, lr=1.2e-6, step_loss=0.0346]07/24/2023 20:09:18 - INFO - __main__ - train loss is 28.038856263272464\n",
      "Steps:   3%|  | 493/15000 [05:32<44:05,  5.48it/s, lr=1.21e-6, step_loss=0.0691]07/24/2023 20:09:18 - INFO - __main__ - train loss is 28.590563292615116\n",
      "Steps:   3%|   | 494/15000 [05:32<44:07,  5.48it/s, lr=1.21e-6, step_loss=0.552]07/24/2023 20:09:18 - INFO - __main__ - train loss is 28.835089112631977\n",
      "Steps:   3%|   | 495/15000 [05:32<44:10,  5.47it/s, lr=1.21e-6, step_loss=0.245]07/24/2023 20:09:18 - INFO - __main__ - train loss is 28.985814626328647\n",
      "Steps:   3%|   | 496/15000 [05:33<43:58,  5.50it/s, lr=1.21e-6, step_loss=0.151]07/24/2023 20:09:18 - INFO - __main__ - train loss is 28.99147789971903\n",
      "Steps:   3%| | 497/15000 [05:33<43:42,  5.53it/s, lr=1.22e-6, step_loss=0.00566]07/24/2023 20:09:19 - INFO - __main__ - train loss is 29.00636802846566\n",
      "Steps:   3%|  | 498/15000 [05:33<43:29,  5.56it/s, lr=1.22e-6, step_loss=0.0149]07/24/2023 20:09:19 - INFO - __main__ - train loss is 29.16442413860932\n",
      "Steps:   3%|   | 499/15000 [05:33<43:50,  5.51it/s, lr=1.22e-6, step_loss=0.158]07/24/2023 20:09:19 - INFO - __main__ - train loss is 29.277243355754763\n",
      "Steps:   3%|   | 500/15000 [05:33<45:04,  5.36it/s, lr=1.22e-6, step_loss=0.158]07/24/2023 20:09:19 - INFO - accelerate.accelerator - Saving current state to ./out/25-07/checkpoint-500\n",
      "07/24/2023 20:09:19 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-24 20:09:19,612] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "[2023-07-24 20:09:19,621] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/25-07/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-24 20:09:19,622] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/25-07/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-24 20:09:19,631] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/25-07/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-24 20:09:19,631] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/25-07/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-24 20:09:19,640] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/25-07/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-24 20:09:19,642] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/25-07/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-24 20:09:19,642] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/24/2023 20:09:19 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/25-07/checkpoint-500/pytorch_model\n",
      "07/24/2023 20:09:19 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/25-07/checkpoint-500/scheduler.bin\n",
      "07/24/2023 20:09:19 - INFO - accelerate.checkpointing - Random states saved in ./out/25-07/checkpoint-500/random_states_0.pkl\n",
      "07/24/2023 20:09:19 - INFO - __main__ - Saved state to ./out/25-07/checkpoint-500\n",
      "Steps:   3%|   | 500/15000 [05:33<45:04,  5.36it/s, lr=1.22e-6, step_loss=0.113]07/24/2023 20:09:19 - INFO - __main__ - train loss is 29.383061850909144\n",
      "Steps:   3%|   | 501/15000 [05:34<46:56,  5.15it/s, lr=1.23e-6, step_loss=0.106]07/24/2023 20:09:19 - INFO - __main__ - train loss is 29.392259562853724\n",
      "Steps:   3%|  | 502/15000 [05:34<45:46,  5.28it/s, lr=1.23e-6, step_loss=0.0092]07/24/2023 20:09:20 - INFO - __main__ - train loss is 29.469921285752207\n",
      "Steps:   3%|  | 503/15000 [05:34<45:11,  5.35it/s, lr=1.23e-6, step_loss=0.0777]07/24/2023 20:09:20 - INFO - __main__ - train loss is 29.473156923428178\n",
      "Steps:   3%| | 504/15000 [05:34<44:55,  5.38it/s, lr=1.23e-6, step_loss=0.00324]07/24/2023 20:09:20 - INFO - __main__ - train loss is 29.4752118550241\n",
      "Steps:   3%| | 505/15000 [05:34<44:35,  5.42it/s, lr=1.24e-6, step_loss=0.00205]07/24/2023 20:09:20 - INFO - __main__ - train loss is 29.61663481220603\n",
      "Steps:   3%|   | 506/15000 [05:35<44:05,  5.48it/s, lr=1.24e-6, step_loss=0.141]07/24/2023 20:09:20 - INFO - __main__ - train loss is 29.8368100784719\n",
      "Steps:   3%|‚ñè   | 507/15000 [05:35<43:48,  5.51it/s, lr=1.24e-6, step_loss=0.22]07/24/2023 20:09:20 - INFO - __main__ - train loss is 29.845949256792665\n",
      "Steps:   3%| | 508/15000 [05:35<43:37,  5.54it/s, lr=1.24e-6, step_loss=0.00914]07/24/2023 20:09:21 - INFO - __main__ - train loss is 29.85585521068424\n",
      "Steps:   3%| | 509/15000 [05:35<43:24,  5.56it/s, lr=1.25e-6, step_loss=0.00991]07/24/2023 20:09:21 - INFO - __main__ - train loss is 29.86076759081334\n",
      "Steps:   3%| | 510/15000 [05:35<43:18,  5.58it/s, lr=1.25e-6, step_loss=0.00491]07/24/2023 20:09:21 - INFO - __main__ - train loss is 29.863117484608665\n",
      "Steps:   3%| | 511/15000 [05:35<43:35,  5.54it/s, lr=1.25e-6, step_loss=0.00235]07/24/2023 20:09:21 - INFO - __main__ - train loss is 29.866411879193038\n",
      "Steps:   3%| | 512/15000 [05:36<43:22,  5.57it/s, lr=1.25e-6, step_loss=0.00329]07/24/2023 20:09:21 - INFO - __main__ - train loss is 29.928017749916762\n",
      "Steps:   3%|  | 513/15000 [05:36<43:19,  5.57it/s, lr=1.26e-6, step_loss=0.0616]07/24/2023 20:09:22 - INFO - __main__ - train loss is 30.43599386466667\n",
      "Steps:   3%|   | 514/15000 [05:36<43:17,  5.58it/s, lr=1.26e-6, step_loss=0.508]07/24/2023 20:09:22 - INFO - __main__ - train loss is 30.600536360871047\n",
      "Steps:   3%|   | 515/15000 [05:36<43:36,  5.54it/s, lr=1.26e-6, step_loss=0.165]07/24/2023 20:09:22 - INFO - __main__ - train loss is 30.611125647556037\n",
      "Steps:   3%|  | 516/15000 [05:36<44:10,  5.46it/s, lr=1.26e-6, step_loss=0.0106]07/24/2023 20:09:22 - INFO - __main__ - train loss is 30.685893468093127\n",
      "Steps:   3%|  | 517/15000 [05:37<44:34,  5.42it/s, lr=1.27e-6, step_loss=0.0748]07/24/2023 20:09:22 - INFO - __main__ - train loss is 30.79792460007593\n",
      "Steps:   3%|   | 518/15000 [05:37<44:28,  5.43it/s, lr=1.27e-6, step_loss=0.112]07/24/2023 20:09:22 - INFO - __main__ - train loss is 30.93619256420061\n",
      "Steps:   3%|   | 519/15000 [05:37<44:12,  5.46it/s, lr=1.27e-6, step_loss=0.138]07/24/2023 20:09:23 - INFO - __main__ - train loss is 30.983067117165774\n",
      "Steps:   3%|  | 520/15000 [05:37<44:06,  5.47it/s, lr=1.27e-6, step_loss=0.0469]07/24/2023 20:09:23 - INFO - __main__ - train loss is 31.12068896694109\n",
      "Steps:   3%|   | 521/15000 [05:37<44:09,  5.47it/s, lr=1.28e-6, step_loss=0.138]07/24/2023 20:09:23 - INFO - __main__ - train loss is 31.142217678483576\n",
      "Steps:   3%|  | 522/15000 [05:37<43:47,  5.51it/s, lr=1.28e-6, step_loss=0.0215]07/24/2023 20:09:23 - INFO - __main__ - train loss is 31.314406228717417\n",
      "Steps:   3%|   | 523/15000 [05:38<43:35,  5.54it/s, lr=1.28e-6, step_loss=0.172]07/24/2023 20:09:23 - INFO - __main__ - train loss is 31.319495800416917\n",
      "Steps:   3%| | 524/15000 [05:38<43:39,  5.53it/s, lr=1.28e-6, step_loss=0.00509]07/24/2023 20:09:24 - INFO - __main__ - train loss is 31.489684614818543\n",
      "Steps:   4%|‚ñè   | 525/15000 [05:38<43:27,  5.55it/s, lr=1.29e-6, step_loss=0.17]07/24/2023 20:09:24 - INFO - __main__ - train loss is 31.703672293107957\n",
      "Steps:   4%|   | 526/15000 [05:38<43:50,  5.50it/s, lr=1.29e-6, step_loss=0.214]07/24/2023 20:09:24 - INFO - __main__ - train loss is 31.75289861811325\n",
      "Steps:   4%|  | 527/15000 [05:38<43:34,  5.54it/s, lr=1.29e-6, step_loss=0.0492]07/24/2023 20:09:24 - INFO - __main__ - train loss is 31.768388451542705\n",
      "Steps:   4%|  | 528/15000 [05:38<43:23,  5.56it/s, lr=1.29e-6, step_loss=0.0155]07/24/2023 20:09:24 - INFO - __main__ - train loss is 31.774136297404766\n",
      "Steps:   4%|  | 529/15000 [05:39<43:13,  5.58it/s, lr=1.3e-6, step_loss=0.00575]07/24/2023 20:09:24 - INFO - __main__ - train loss is 31.777082577580586\n",
      "Steps:   4%|  | 530/15000 [05:39<43:12,  5.58it/s, lr=1.3e-6, step_loss=0.00295]07/24/2023 20:09:25 - INFO - __main__ - train loss is 31.976371124619618\n",
      "Steps:   4%|‚ñè   | 531/15000 [05:39<43:12,  5.58it/s, lr=1.3e-6, step_loss=0.199]07/24/2023 20:09:25 - INFO - __main__ - train loss is 32.20001104497351\n",
      "Steps:   4%|‚ñè   | 532/15000 [05:39<43:05,  5.60it/s, lr=1.3e-6, step_loss=0.224]07/24/2023 20:09:25 - INFO - __main__ - train loss is 32.27178875380196\n",
      "Steps:   4%|  | 533/15000 [05:39<43:03,  5.60it/s, lr=1.31e-6, step_loss=0.0718]07/24/2023 20:09:25 - INFO - __main__ - train loss is 32.31641335436143\n",
      "Steps:   4%|  | 534/15000 [05:40<43:02,  5.60it/s, lr=1.31e-6, step_loss=0.0446]07/24/2023 20:09:25 - INFO - __main__ - train loss is 32.35694529884495\n",
      "Steps:   4%|  | 535/15000 [05:40<43:15,  5.57it/s, lr=1.31e-6, step_loss=0.0405]07/24/2023 20:09:26 - INFO - __main__ - train loss is 32.59821531944908\n",
      "Steps:   4%|   | 536/15000 [05:40<43:08,  5.59it/s, lr=1.31e-6, step_loss=0.241]07/24/2023 20:09:26 - INFO - __main__ - train loss is 32.73234596126713\n",
      "Steps:   4%|   | 537/15000 [05:40<43:07,  5.59it/s, lr=1.32e-6, step_loss=0.134]07/24/2023 20:09:26 - INFO - __main__ - train loss is 33.0316609966103\n",
      "Steps:   4%|   | 538/15000 [05:40<43:04,  5.60it/s, lr=1.32e-6, step_loss=0.299]07/24/2023 20:09:26 - INFO - __main__ - train loss is 33.173780121142045\n",
      "Steps:   4%|   | 539/15000 [05:40<43:01,  5.60it/s, lr=1.32e-6, step_loss=0.142]07/24/2023 20:09:26 - INFO - __main__ - train loss is 33.20195312635042\n",
      "Steps:   4%|  | 540/15000 [05:41<43:00,  5.60it/s, lr=1.32e-6, step_loss=0.0282]07/24/2023 20:09:26 - INFO - __main__ - train loss is 33.2099787669722\n",
      "Steps:   4%| | 541/15000 [05:41<42:57,  5.61it/s, lr=1.33e-6, step_loss=0.00803]07/24/2023 20:09:27 - INFO - __main__ - train loss is 33.27045778208412\n",
      "Steps:   4%|  | 542/15000 [05:41<42:54,  5.62it/s, lr=1.33e-6, step_loss=0.0605]07/24/2023 20:09:27 - INFO - __main__ - train loss is 33.57143125706352\n",
      "Steps:   4%|   | 543/15000 [05:41<42:53,  5.62it/s, lr=1.33e-6, step_loss=0.301]07/24/2023 20:09:27 - INFO - __main__ - train loss is 33.58752029039897\n",
      "Steps:   4%|  | 544/15000 [05:41<43:07,  5.59it/s, lr=1.33e-6, step_loss=0.0161]07/24/2023 20:09:27 - INFO - __main__ - train loss is 33.89273785450496\n",
      "Steps:   4%|   | 545/15000 [05:42<43:03,  5.59it/s, lr=1.34e-6, step_loss=0.305]07/24/2023 20:09:27 - INFO - __main__ - train loss is 33.97859734692611\n",
      "Steps:   4%|  | 546/15000 [05:42<43:02,  5.60it/s, lr=1.34e-6, step_loss=0.0859]07/24/2023 20:09:28 - INFO - __main__ - train loss is 33.99242972792126\n",
      "Steps:   4%|  | 547/15000 [05:42<42:58,  5.60it/s, lr=1.34e-6, step_loss=0.0138]07/24/2023 20:09:28 - INFO - __main__ - train loss is 34.29147973121144\n",
      "Steps:   4%|   | 548/15000 [05:42<42:55,  5.61it/s, lr=1.34e-6, step_loss=0.299]07/24/2023 20:09:28 - INFO - __main__ - train loss is 34.374882648000494\n",
      "Steps:   4%|  | 549/15000 [05:42<42:56,  5.61it/s, lr=1.35e-6, step_loss=0.0834]07/24/2023 20:09:28 - INFO - __main__ - train loss is 34.64249489665963\n",
      "Steps:   4%|   | 550/15000 [05:42<42:54,  5.61it/s, lr=1.35e-6, step_loss=0.268]07/24/2023 20:09:28 - INFO - __main__ - train loss is 34.655583046609536\n",
      "Steps:   4%|  | 551/15000 [05:43<43:13,  5.57it/s, lr=1.35e-6, step_loss=0.0131]07/24/2023 20:09:28 - INFO - __main__ - train loss is 35.06448545330204\n",
      "Steps:   4%|   | 552/15000 [05:43<43:20,  5.56it/s, lr=1.35e-6, step_loss=0.409]07/24/2023 20:09:29 - INFO - __main__ - train loss is 35.0778502470348\n",
      "Steps:   4%|  | 553/15000 [05:43<43:11,  5.58it/s, lr=1.36e-6, step_loss=0.0134]07/24/2023 20:09:29 - INFO - __main__ - train loss is 35.912830436835065\n",
      "Steps:   4%|   | 554/15000 [05:43<43:04,  5.59it/s, lr=1.36e-6, step_loss=0.835]07/24/2023 20:09:29 - INFO - __main__ - train loss is 36.26267575682141\n",
      "Steps:   4%|‚ñè   | 555/15000 [05:43<43:00,  5.60it/s, lr=1.36e-6, step_loss=0.35]07/24/2023 20:09:29 - INFO - __main__ - train loss is 36.27240520180203\n",
      "Steps:   4%| | 556/15000 [05:43<42:57,  5.60it/s, lr=1.36e-6, step_loss=0.00973]07/24/2023 20:09:29 - INFO - __main__ - train loss is 36.30166051001288\n",
      "Steps:   4%|  | 557/15000 [05:44<43:06,  5.58it/s, lr=1.37e-6, step_loss=0.0293]07/24/2023 20:09:29 - INFO - __main__ - train loss is 36.341335417935625\n",
      "Steps:   4%|  | 558/15000 [05:44<43:01,  5.60it/s, lr=1.37e-6, step_loss=0.0397]07/24/2023 20:09:30 - INFO - __main__ - train loss is 36.5907574465964\n",
      "Steps:   4%|   | 559/15000 [05:44<42:57,  5.60it/s, lr=1.37e-6, step_loss=0.249]07/24/2023 20:09:30 - INFO - __main__ - train loss is 36.59286769828759\n",
      "Steps:   4%| | 560/15000 [05:44<42:57,  5.60it/s, lr=1.37e-6, step_loss=0.00211]07/24/2023 20:09:30 - INFO - __main__ - train loss is 36.90175947151147\n",
      "Steps:   4%|   | 561/15000 [05:44<42:53,  5.61it/s, lr=1.38e-6, step_loss=0.309]07/24/2023 20:09:30 - INFO - __main__ - train loss is 37.14173772535287\n",
      "Steps:   4%|‚ñè   | 562/15000 [05:45<42:50,  5.62it/s, lr=1.38e-6, step_loss=0.24]07/24/2023 20:09:30 - INFO - __main__ - train loss is 37.449939992045984\n",
      "Steps:   4%|   | 563/15000 [05:45<42:50,  5.62it/s, lr=1.38e-6, step_loss=0.308]07/24/2023 20:09:31 - INFO - __main__ - train loss is 37.50657835952006\n",
      "Steps:   4%|  | 564/15000 [05:45<42:50,  5.62it/s, lr=1.38e-6, step_loss=0.0566]07/24/2023 20:09:31 - INFO - __main__ - train loss is 37.52611009194516\n",
      "Steps:   4%|  | 565/15000 [05:45<42:50,  5.61it/s, lr=1.39e-6, step_loss=0.0195]07/24/2023 20:09:31 - INFO - __main__ - train loss is 37.532781570916995\n",
      "Steps:   4%| | 566/15000 [05:45<43:09,  5.57it/s, lr=1.39e-6, step_loss=0.00667]07/24/2023 20:09:31 - INFO - __main__ - train loss is 37.66371279931627\n",
      "Steps:   4%|   | 567/15000 [05:45<43:03,  5.59it/s, lr=1.39e-6, step_loss=0.131]07/24/2023 20:09:31 - INFO - __main__ - train loss is 37.6684751806315\n",
      "Steps:   4%| | 568/15000 [05:46<43:20,  5.55it/s, lr=1.39e-6, step_loss=0.00476]07/24/2023 20:09:31 - INFO - __main__ - train loss is 37.699000688036904\n",
      "Steps:   4%|   | 569/15000 [05:46<43:27,  5.53it/s, lr=1.4e-6, step_loss=0.0305]07/24/2023 20:09:32 - INFO - __main__ - train loss is 37.728386683156714\n",
      "Steps:   4%|   | 570/15000 [05:46<43:16,  5.56it/s, lr=1.4e-6, step_loss=0.0294]07/24/2023 20:09:32 - INFO - __main__ - train loss is 38.07721881358884\n",
      "Steps:   4%|‚ñè   | 571/15000 [05:46<43:11,  5.57it/s, lr=1.4e-6, step_loss=0.349]07/24/2023 20:09:32 - INFO - __main__ - train loss is 38.08028173097409\n",
      "Steps:   4%|  | 572/15000 [05:46<43:05,  5.58it/s, lr=1.4e-6, step_loss=0.00306]07/24/2023 20:09:32 - INFO - __main__ - train loss is 38.333583649480715\n",
      "Steps:   4%|   | 573/15000 [05:47<42:59,  5.59it/s, lr=1.41e-6, step_loss=0.253]07/24/2023 20:09:32 - INFO - __main__ - train loss is 38.639486965024844\n",
      "Steps:   4%|   | 574/15000 [05:47<43:05,  5.58it/s, lr=1.41e-6, step_loss=0.306]07/24/2023 20:09:33 - INFO - __main__ - train loss is 38.642308296402916\n",
      "Steps:   4%| | 575/15000 [05:47<43:09,  5.57it/s, lr=1.41e-6, step_loss=0.00282]07/24/2023 20:09:33 - INFO - __main__ - train loss is 38.6925447860267\n",
      "Steps:   4%|  | 576/15000 [05:47<43:04,  5.58it/s, lr=1.41e-6, step_loss=0.0502]07/24/2023 20:09:33 - INFO - __main__ - train loss is 38.701989110326394\n",
      "Steps:   4%| | 577/15000 [05:47<43:11,  5.56it/s, lr=1.42e-6, step_loss=0.00944]07/24/2023 20:09:33 - INFO - __main__ - train loss is 38.73488379991613\n",
      "Steps:   4%|  | 578/15000 [05:47<43:27,  5.53it/s, lr=1.42e-6, step_loss=0.0329]07/24/2023 20:09:33 - INFO - __main__ - train loss is 38.826823599403724\n",
      "Steps:   4%|  | 579/15000 [05:48<43:37,  5.51it/s, lr=1.42e-6, step_loss=0.0919]07/24/2023 20:09:33 - INFO - __main__ - train loss is 38.980014599626884\n",
      "Steps:   4%|   | 580/15000 [05:48<43:22,  5.54it/s, lr=1.42e-6, step_loss=0.153]07/24/2023 20:09:34 - INFO - __main__ - train loss is 39.020938254659995\n",
      "Steps:   4%|  | 581/15000 [05:48<43:14,  5.56it/s, lr=1.42e-6, step_loss=0.0409]07/24/2023 20:09:34 - INFO - __main__ - train loss is 39.05020771524869\n",
      "Steps:   4%|  | 582/15000 [05:48<43:14,  5.56it/s, lr=1.43e-6, step_loss=0.0293]07/24/2023 20:09:34 - INFO - __main__ - train loss is 39.39262072346173\n",
      "Steps:   4%|   | 583/15000 [05:48<43:09,  5.57it/s, lr=1.43e-6, step_loss=0.342]07/24/2023 20:09:34 - INFO - __main__ - train loss is 39.593989711022004\n",
      "Steps:   4%|   | 584/15000 [05:49<43:28,  5.53it/s, lr=1.43e-6, step_loss=0.201]07/24/2023 20:09:34 - INFO - __main__ - train loss is 39.71864739409648\n",
      "Steps:   4%|   | 585/15000 [05:49<43:36,  5.51it/s, lr=1.44e-6, step_loss=0.125]07/24/2023 20:09:35 - INFO - __main__ - train loss is 40.07701388350688\n",
      "Steps:   4%|   | 586/15000 [05:49<43:26,  5.53it/s, lr=1.44e-6, step_loss=0.358]07/24/2023 20:09:35 - INFO - __main__ - train loss is 40.15602058521472\n",
      "Steps:   4%|   | 587/15000 [05:49<43:14,  5.56it/s, lr=1.44e-6, step_loss=0.079]07/24/2023 20:09:35 - INFO - __main__ - train loss is 40.440890315687284\n",
      "Steps:   4%|   | 588/15000 [05:49<43:06,  5.57it/s, lr=1.44e-6, step_loss=0.285]07/24/2023 20:09:35 - INFO - __main__ - train loss is 40.67007989040576\n",
      "Steps:   4%|   | 589/15000 [05:49<43:01,  5.58it/s, lr=1.44e-6, step_loss=0.229]07/24/2023 20:09:35 - INFO - __main__ - train loss is 41.087364349281415\n",
      "Steps:   4%|   | 590/15000 [05:50<42:56,  5.59it/s, lr=1.45e-6, step_loss=0.417]07/24/2023 20:09:35 - INFO - __main__ - train loss is 41.636446330463514\n",
      "Steps:   4%|   | 591/15000 [05:50<42:53,  5.60it/s, lr=1.45e-6, step_loss=0.549]07/24/2023 20:09:36 - INFO - __main__ - train loss is 41.66644533141516\n",
      "Steps:   4%|‚ñè   | 592/15000 [05:50<42:51,  5.60it/s, lr=1.45e-6, step_loss=0.03]07/24/2023 20:09:36 - INFO - __main__ - train loss is 41.66984735871665\n",
      "Steps:   4%|  | 593/15000 [05:50<42:55,  5.59it/s, lr=1.46e-6, step_loss=0.0034]07/24/2023 20:09:36 - INFO - __main__ - train loss is 41.809847687138245\n",
      "Steps:   4%|‚ñè   | 594/15000 [05:50<43:03,  5.58it/s, lr=1.46e-6, step_loss=0.14]07/24/2023 20:09:36 - INFO - __main__ - train loss is 41.86701957578771\n",
      "Steps:   4%|  | 595/15000 [05:50<42:56,  5.59it/s, lr=1.46e-6, step_loss=0.0572]07/24/2023 20:09:36 - INFO - __main__ - train loss is 41.87070885510184\n",
      "Steps:   4%| | 596/15000 [05:51<42:54,  5.59it/s, lr=1.46e-6, step_loss=0.00369]07/24/2023 20:09:36 - INFO - __main__ - train loss is 41.92724199057557\n",
      "Steps:   4%|  | 597/15000 [05:51<43:16,  5.55it/s, lr=1.46e-6, step_loss=0.0565]07/24/2023 20:09:37 - INFO - __main__ - train loss is 42.1497134512756\n",
      "Steps:   4%|   | 598/15000 [05:51<43:37,  5.50it/s, lr=1.47e-6, step_loss=0.222]07/24/2023 20:09:37 - INFO - __main__ - train loss is 42.32208981574513\n",
      "Steps:   4%|   | 599/15000 [05:51<44:05,  5.44it/s, lr=1.47e-6, step_loss=0.172]07/24/2023 20:09:37 - INFO - __main__ - train loss is 42.40984217287041\n",
      "Steps:   4%|  | 600/15000 [05:51<43:51,  5.47it/s, lr=1.47e-6, step_loss=0.0878]07/24/2023 20:09:37 - INFO - __main__ - train loss is 42.41964012128301\n",
      "Steps:   4%|  | 601/15000 [05:52<43:31,  5.51it/s, lr=1.48e-6, step_loss=0.0098]07/24/2023 20:09:37 - INFO - __main__ - train loss is 42.447582244174555\n",
      "Steps:   4%|  | 602/15000 [05:52<43:19,  5.54it/s, lr=1.48e-6, step_loss=0.0279]07/24/2023 20:09:38 - INFO - __main__ - train loss is 42.451594887534156\n",
      "Steps:   4%| | 603/15000 [05:52<43:06,  5.57it/s, lr=1.48e-6, step_loss=0.00401]07/24/2023 20:09:38 - INFO - __main__ - train loss is 42.66821597353555\n",
      "Steps:   4%|   | 604/15000 [05:52<43:02,  5.57it/s, lr=1.48e-6, step_loss=0.217]07/24/2023 20:09:38 - INFO - __main__ - train loss is 42.92169894115068\n",
      "Steps:   4%|   | 605/15000 [05:52<42:56,  5.59it/s, lr=1.48e-6, step_loss=0.253]07/24/2023 20:09:38 - INFO - __main__ - train loss is 43.030748090008274\n",
      "Steps:   4%|   | 606/15000 [05:52<42:51,  5.60it/s, lr=1.49e-6, step_loss=0.109]07/24/2023 20:09:38 - INFO - __main__ - train loss is 43.0400910761673\n",
      "Steps:   4%| | 607/15000 [05:53<42:46,  5.61it/s, lr=1.49e-6, step_loss=0.00934]07/24/2023 20:09:38 - INFO - __main__ - train loss is 43.70509223011322\n",
      "Steps:   4%|   | 608/15000 [05:53<42:54,  5.59it/s, lr=1.49e-6, step_loss=0.665]07/24/2023 20:09:39 - INFO - __main__ - train loss is 43.83718476560898\n",
      "Steps:   4%|‚ñè   | 609/15000 [05:53<42:47,  5.60it/s, lr=1.5e-6, step_loss=0.132]07/24/2023 20:09:39 - INFO - __main__ - train loss is 43.84581864182837\n",
      "Steps:   4%|  | 610/15000 [05:53<43:03,  5.57it/s, lr=1.5e-6, step_loss=0.00863]07/24/2023 20:09:39 - INFO - __main__ - train loss is 43.90313238580711\n",
      "Steps:   4%|   | 611/15000 [05:53<42:54,  5.59it/s, lr=1.5e-6, step_loss=0.0573]07/24/2023 20:09:39 - INFO - __main__ - train loss is 43.93394101341255\n",
      "Steps:   4%|   | 612/15000 [05:54<42:48,  5.60it/s, lr=1.5e-6, step_loss=0.0308]07/24/2023 20:09:39 - INFO - __main__ - train loss is 44.05964771588333\n",
      "Steps:   4%|‚ñè   | 613/15000 [05:54<42:52,  5.59it/s, lr=1.5e-6, step_loss=0.126]07/24/2023 20:09:40 - INFO - __main__ - train loss is 44.114261276321486\n",
      "Steps:   4%|  | 614/15000 [05:54<55:45,  4.30it/s, lr=1.51e-6, step_loss=0.0546]07/24/2023 20:09:41 - INFO - __main__ - Per validation step average loss is 0.011746331118047237\n",
      "07/24/2023 20:09:41 - INFO - __main__ - Cumulative validation average loss is 0.011746331118047237\n",
      "07/24/2023 20:09:41 - INFO - __main__ - Per validation step average loss is 0.3260166347026825\n",
      "07/24/2023 20:09:41 - INFO - __main__ - Cumulative validation average loss is 0.33776296582072973\n",
      "07/24/2023 20:09:42 - INFO - __main__ - Per validation step average loss is 0.07244101911783218\n",
      "07/24/2023 20:09:42 - INFO - __main__ - Cumulative validation average loss is 0.4102039849385619\n",
      "07/24/2023 20:09:42 - INFO - __main__ - Per validation step average loss is 0.028768539428710938\n",
      "07/24/2023 20:09:42 - INFO - __main__ - Cumulative validation average loss is 0.43897252436727285\n",
      "07/24/2023 20:09:42 - INFO - __main__ - Per validation step average loss is 0.3065774440765381\n",
      "07/24/2023 20:09:42 - INFO - __main__ - Cumulative validation average loss is 0.7455499684438109\n",
      "07/24/2023 20:09:43 - INFO - __main__ - Per validation step average loss is 0.017215177416801453\n",
      "07/24/2023 20:09:43 - INFO - __main__ - Cumulative validation average loss is 0.7627651458606124\n",
      "07/24/2023 20:09:43 - INFO - __main__ - Per validation step average loss is 0.10883088409900665\n",
      "07/24/2023 20:09:43 - INFO - __main__ - Cumulative validation average loss is 0.871596029959619\n",
      "07/24/2023 20:09:44 - INFO - __main__ - Per validation step average loss is 0.07047661393880844\n",
      "07/24/2023 20:09:44 - INFO - __main__ - Cumulative validation average loss is 0.9420726438984275\n",
      "07/24/2023 20:09:44 - INFO - __main__ - Per validation step average loss is 0.007491473574191332\n",
      "07/24/2023 20:09:44 - INFO - __main__ - Cumulative validation average loss is 0.9495641174726188\n",
      "07/24/2023 20:09:45 - INFO - __main__ - Per validation step average loss is 0.06301645189523697\n",
      "07/24/2023 20:09:45 - INFO - __main__ - Cumulative validation average loss is 1.0125805693678558\n",
      "07/24/2023 20:09:45 - INFO - __main__ - Per validation step average loss is 0.17334915697574615\n",
      "07/24/2023 20:09:45 - INFO - __main__ - Cumulative validation average loss is 1.185929726343602\n",
      "07/24/2023 20:09:46 - INFO - __main__ - Per validation step average loss is 0.0535421147942543\n",
      "07/24/2023 20:09:46 - INFO - __main__ - Cumulative validation average loss is 1.2394718411378562\n",
      "07/24/2023 20:09:46 - INFO - __main__ - Per validation step average loss is 0.24885953962802887\n",
      "07/24/2023 20:09:46 - INFO - __main__ - Cumulative validation average loss is 1.4883313807658851\n",
      "07/24/2023 20:09:46 - INFO - __main__ - Per validation step average loss is 0.41091424226760864\n",
      "07/24/2023 20:09:46 - INFO - __main__ - Cumulative validation average loss is 1.8992456230334938\n",
      "07/24/2023 20:09:47 - INFO - __main__ - Per validation step average loss is 0.04785742610692978\n",
      "07/24/2023 20:09:47 - INFO - __main__ - Cumulative validation average loss is 1.9471030491404235\n",
      "^C\n",
      "\u001b[2;36m[20:09:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Received \u001b[1;36m2\u001b[0m death signal, shutting down workers    \u001b]8;id=349511;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=832743;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py#729\u001b\\\u001b[2m729\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Sending process \u001b[1;36m7947\u001b[0m closing signal SIGINT        \u001b]8;id=626207;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=881991;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#698\u001b\\\u001b[2m698\u001b[0m\u001b]8;;\u001b\\\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/PIL/ImageFile.py\", line 518, in _save\n",
      "    fh = fp.fileno()\n",
      "AttributeError: '_idat' object has no attribute 'fileno'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1207, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1009, in main\n",
      "    val_images_log.append(wandb.Image(batch[\"pixel_values\"], caption=f\"Epoch {epoch} Step {step}\"))\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/wandb/sdk/data_types/image.py\", line 162, in __init__\n",
      "    self._initialize_from_data(data_or_path, mode)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/wandb/sdk/data_types/image.py\", line 307, in _initialize_from_data\n",
      "    self._image.save(tmp_path, transparency=None)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/PIL/Image.py\", line 2431, in save\n",
      "    save_handler(self, fp, filename)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/PIL/PngImagePlugin.py\", line 1420, in _save\n",
      "    ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/PIL/ImageFile.py\", line 522, in _save\n",
      "    _encode_tile(im, fp, tile, bufsize, None, exc)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/PIL/ImageFile.py\", line 541, in _encode_tile\n",
      "    l, s, d = encoder.encode(bufsize)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --validation_epochs=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=1000 \\\n",
    "  --output_dir=$\"./out/25-07\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of acoustic guitar\" \\\n",
    "  --validation_prompt2=\"A spectrogram of cheering\" \\\n",
    "  --validation_prompt3=\"A spectrogram of dog bark\" \\\n",
    "  --validation_prompt4=\"A spectrogram of snare drum\" \\\n",
    "  --validation_prompt5=\"A spectrogram of train horn\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/13-07/2\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
