{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-18 17:21:52,194] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f044618118854f19b596bf60662a68c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-60ed10d081d7581b/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c0f4df7fd1479f8f53622fcce63914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d78b497655c4860974dcc08b9220f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca196d68d84a4c7ebaa3c3d657249181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b236e0c4f89a4a6193792d6cd9426cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-60ed10d081d7581b/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-18 19:02:58,157] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-18 19:03:00,793] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-18 19:03:02,483] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-18 19:03:02,483] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-18 19:03:02,483] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/18/2023 19:03:02 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'dynamic_thresholding_ratio', 'thresholding', 'variance_type', 'prediction_type', 'clip_sample_range', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'conv_in_kernel', 'resnet_skip_time_act', 'num_class_embeds', 'encoder_hid_dim_type', 'encoder_hid_dim', 'mid_block_type', 'only_cross_attention', 'time_embedding_dim', 'cross_attention_norm', 'addition_embed_type', 'class_embeddings_concat', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'timestep_post_act', 'dual_cross_attention', 'conv_out_kernel', 'upcast_attention', 'class_embed_type', 'use_linear_projection', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim', 'resnet_time_scale_shift', 'mid_block_only_cross_attention', 'addition_embed_type_num_heads', 'time_embedding_type'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|█████████████████| 98/98 [00:00<00:00, 656616.28it/s]\n",
      "07/18/2023 19:03:09 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-0498064ce8e657d3/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1425.66it/s]\n",
      "07/18/2023 19:03:10 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (1).\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.1999545097351074 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-18 19:03:14,874] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/18/2023 19:03:14 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/18/2023 19:03:14 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-18 19:03:14,908] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-18 19:03:14,909] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-18 19:03:14,909] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-18 19:03:14,915] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-18 19:03:14,915] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-18 19:03:14,915] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-18 19:03:14,915] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-18 19:03:14,915] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-18 19:03:14,915] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-18 19:03:14,915] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07358956336975098 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-18 19:03:15,128] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-18 19:03:15,129] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-18 19:03:15,129] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.62 GB, percent = 55.5%\n",
      "[2023-07-18 19:03:15,232] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-18 19:03:15,232] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-18 19:03:15,233] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.63 GB, percent = 55.5%\n",
      "[2023-07-18 19:03:15,233] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-18 19:03:15,327] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-18 19:03:15,327] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-18 19:03:15,327] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.63 GB, percent = 55.5%\n",
      "[2023-07-18 19:03:15,332] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-18 19:03:15,332] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-18 19:03:15,332] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-18 19:03:15,332] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6081f5a050>\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-18 19:03:15,333] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-18 19:03:15,334] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00021982192993164062 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230718_190316-uqudwn7j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrue-frog-103\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/uqudwn7j\u001b[0m\n",
      "07/18/2023 19:03:22 - INFO - __main__ - ***** Running training *****\n",
      "07/18/2023 19:03:22 - INFO - __main__ -   Num examples = 97\n",
      "07/18/2023 19:03:22 - INFO - __main__ -   Num Epochs = 600\n",
      "07/18/2023 19:03:22 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/18/2023 19:03:22 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/18/2023 19:03:22 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/18/2023 19:03:22 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]07/18/2023 19:03:22 - INFO - __main__ - Starting epoch 0\n",
      "07/18/2023 19:03:24 - INFO - __main__ - train loss is 0.24978867173194885\n",
      "[2023-07-18 19:03:24,208] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|       | 1/15000 [00:02<8:21:30,  2.01s/it, lr=1e-5, step_loss=0.25]07/18/2023 19:03:24 - INFO - __main__ - train loss is 0.35710570216178894\n",
      "[2023-07-18 19:03:24,752] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|      | 2/15000 [00:02<4:46:34,  1.15s/it, lr=1e-5, step_loss=0.107]07/18/2023 19:03:25 - INFO - __main__ - train loss is 0.7553671598434448\n",
      "[2023-07-18 19:03:25,302] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|      | 3/15000 [00:03<3:38:23,  1.14it/s, lr=1e-5, step_loss=0.398]07/18/2023 19:03:25 - INFO - __main__ - train loss is 0.8121035248041153\n",
      "[2023-07-18 19:03:25,838] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|     | 4/15000 [00:03<3:05:06,  1.35it/s, lr=1e-5, step_loss=0.0567]07/18/2023 19:03:26 - INFO - __main__ - train loss is 0.9457280933856964\n",
      "[2023-07-18 19:03:26,378] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|      | 5/15000 [00:04<2:46:58,  1.50it/s, lr=1e-5, step_loss=0.134]07/18/2023 19:03:26 - INFO - __main__ - train loss is 1.0750536918640137\n",
      "[2023-07-18 19:03:26,918] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|      | 6/15000 [00:04<2:36:04,  1.60it/s, lr=1e-5, step_loss=0.129]07/18/2023 19:03:27 - INFO - __main__ - train loss is 1.258297622203827\n",
      "[2023-07-18 19:03:27,462] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|      | 7/15000 [00:05<2:29:30,  1.67it/s, lr=1e-5, step_loss=0.183]07/18/2023 19:03:27 - INFO - __main__ - train loss is 1.5020390152931213\n",
      "[2023-07-18 19:03:28,002] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|      | 8/15000 [00:05<2:24:48,  1.73it/s, lr=1e-5, step_loss=0.244]07/18/2023 19:03:28 - INFO - __main__ - train loss is 1.505935720168054\n",
      "Steps:   0%|     | 9/15000 [00:06<2:22:28,  1.75it/s, lr=1e-5, step_loss=0.0039]07/18/2023 19:03:29 - INFO - __main__ - train loss is 1.712998933158815\n",
      "[2023-07-18 19:03:29,091] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%|     | 10/15000 [00:06<2:20:06,  1.78it/s, lr=1e-5, step_loss=0.207]07/18/2023 19:03:29 - INFO - __main__ - train loss is 1.7309219604358077\n",
      "Steps:   0%|    | 11/15000 [00:07<2:18:55,  1.80it/s, lr=1e-5, step_loss=0.0179]07/18/2023 19:03:30 - INFO - __main__ - train loss is 1.8375155022367835\n",
      "Steps:   0%|     | 12/15000 [00:07<2:18:38,  1.80it/s, lr=1e-5, step_loss=0.107]07/18/2023 19:03:30 - INFO - __main__ - train loss is 1.8409305706154555\n",
      "Steps:   0%|   | 13/15000 [00:08<2:18:20,  1.81it/s, lr=1e-5, step_loss=0.00342]07/18/2023 19:03:31 - INFO - __main__ - train loss is 1.918550756527111\n",
      "Steps:   0%|    | 14/15000 [00:09<2:17:45,  1.81it/s, lr=1e-5, step_loss=0.0776]07/18/2023 19:03:31 - INFO - __main__ - train loss is 1.9827935888897628\n",
      "Steps:   0%|    | 15/15000 [00:09<2:17:11,  1.82it/s, lr=1e-5, step_loss=0.0642]07/18/2023 19:03:32 - INFO - __main__ - train loss is 2.0244253545533866\n",
      "Steps:   0%|    | 16/15000 [00:10<2:16:49,  1.83it/s, lr=1e-5, step_loss=0.0416]07/18/2023 19:03:32 - INFO - __main__ - train loss is 2.2369997322093695\n",
      "Steps:   0%|     | 17/15000 [00:10<2:16:29,  1.83it/s, lr=1e-5, step_loss=0.213]07/18/2023 19:03:33 - INFO - __main__ - train loss is 2.6352145492564887\n",
      "Steps:   0%|     | 18/15000 [00:11<2:16:27,  1.83it/s, lr=1e-5, step_loss=0.398]07/18/2023 19:03:33 - INFO - __main__ - train loss is 2.6888617656659335\n",
      "Steps:   0%|    | 19/15000 [00:11<2:16:22,  1.83it/s, lr=1e-5, step_loss=0.0536]07/18/2023 19:03:34 - INFO - __main__ - train loss is 2.728793957037851\n",
      "Steps:   0%|    | 20/15000 [00:12<2:15:49,  1.84it/s, lr=1e-5, step_loss=0.0399]07/18/2023 19:03:35 - INFO - __main__ - train loss is 2.7404072375502437\n",
      "Steps:   0%|    | 21/15000 [00:12<2:15:59,  1.84it/s, lr=1e-5, step_loss=0.0116]07/18/2023 19:03:35 - INFO - __main__ - train loss is 2.7573865053709596\n",
      "Steps:   0%|     | 22/15000 [00:13<2:15:37,  1.84it/s, lr=1e-5, step_loss=0.017]07/18/2023 19:03:36 - INFO - __main__ - train loss is 2.783816616749391\n",
      "Steps:   0%|    | 23/15000 [00:13<2:15:38,  1.84it/s, lr=1e-5, step_loss=0.0264]07/18/2023 19:03:36 - INFO - __main__ - train loss is 2.949634384131059\n",
      "Steps:   0%|     | 24/15000 [00:14<2:15:13,  1.85it/s, lr=1e-5, step_loss=0.166]07/18/2023 19:03:37 - INFO - __main__ - train loss is 2.9760029388125986\n",
      "Steps:   0%|    | 25/15000 [00:15<2:14:40,  1.85it/s, lr=1e-5, step_loss=0.0264]07/18/2023 19:03:37 - INFO - __main__ - train loss is 3.0185905841644853\n",
      "Steps:   0%|    | 26/15000 [00:15<2:14:59,  1.85it/s, lr=1e-5, step_loss=0.0426]07/18/2023 19:03:38 - INFO - __main__ - train loss is 3.118653014069423\n",
      "[2023-07-18 19:03:38,331] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   0%|       | 27/15000 [00:16<2:14:31,  1.86it/s, lr=1e-5, step_loss=0.1]07/18/2023 19:03:38 - INFO - __main__ - train loss is 3.1697336432989687\n",
      "Steps:   0%|    | 28/15000 [00:16<2:14:38,  1.85it/s, lr=1e-5, step_loss=0.0511]07/18/2023 19:03:39 - INFO - __main__ - train loss is 3.174771063728258\n",
      "Steps:   0%|   | 29/15000 [00:17<2:14:53,  1.85it/s, lr=1e-5, step_loss=0.00504]07/18/2023 19:03:39 - INFO - __main__ - train loss is 3.1856280907522887\n",
      "Steps:   0%|    | 30/15000 [00:17<2:14:37,  1.85it/s, lr=1e-5, step_loss=0.0109]07/18/2023 19:03:40 - INFO - __main__ - train loss is 3.2564293190371245\n",
      "Steps:   0%|    | 31/15000 [00:18<2:15:04,  1.85it/s, lr=1e-5, step_loss=0.0708]07/18/2023 19:03:40 - INFO - __main__ - train loss is 3.262461924692616\n",
      "Steps:   0%|   | 32/15000 [00:18<2:15:01,  1.85it/s, lr=1e-5, step_loss=0.00603]07/18/2023 19:03:41 - INFO - __main__ - train loss is 3.2649699102621526\n",
      "Steps:   0%|   | 33/15000 [00:19<2:15:08,  1.85it/s, lr=1e-5, step_loss=0.00251]07/18/2023 19:03:42 - INFO - __main__ - train loss is 3.2738964629825205\n",
      "Steps:   0%|   | 34/15000 [00:19<2:15:49,  1.84it/s, lr=1e-5, step_loss=0.00893]07/18/2023 19:03:42 - INFO - __main__ - train loss is 3.3641489518340677\n",
      "Steps:   0%|    | 35/15000 [00:20<2:15:10,  1.85it/s, lr=1e-5, step_loss=0.0903]07/18/2023 19:03:43 - INFO - __main__ - train loss is 3.7526173961814493\n",
      "Steps:   0%|     | 36/15000 [00:21<2:15:03,  1.85it/s, lr=1e-5, step_loss=0.388]07/18/2023 19:03:43 - INFO - __main__ - train loss is 4.146976895397529\n",
      "Steps:   0%|     | 37/15000 [00:21<2:14:38,  1.85it/s, lr=1e-5, step_loss=0.394]07/18/2023 19:03:44 - INFO - __main__ - train loss is 4.159751454135403\n",
      "Steps:   0%|    | 38/15000 [00:22<2:14:52,  1.85it/s, lr=1e-5, step_loss=0.0128]07/18/2023 19:03:44 - INFO - __main__ - train loss is 4.35342607810162\n",
      "Steps:   0%|     | 39/15000 [00:22<2:14:57,  1.85it/s, lr=1e-5, step_loss=0.194]07/18/2023 19:03:45 - INFO - __main__ - train loss is 4.563090229174122\n",
      "Steps:   0%|      | 40/15000 [00:23<2:16:25,  1.83it/s, lr=1e-5, step_loss=0.21]07/18/2023 19:03:45 - INFO - __main__ - train loss is 4.754758143564686\n",
      "Steps:   0%|     | 41/15000 [00:23<2:16:12,  1.83it/s, lr=1e-5, step_loss=0.192]07/18/2023 19:03:46 - INFO - __main__ - train loss is 4.7585412103217095\n",
      "Steps:   0%|   | 42/15000 [00:24<2:16:11,  1.83it/s, lr=1e-5, step_loss=0.00378]07/18/2023 19:03:46 - INFO - __main__ - train loss is 4.803686964092776\n",
      "Steps:   0%|    | 43/15000 [00:24<2:17:24,  1.81it/s, lr=1e-5, step_loss=0.0451]07/18/2023 19:03:47 - INFO - __main__ - train loss is 4.856393257854506\n",
      "Steps:   0%|    | 44/15000 [00:25<2:16:20,  1.83it/s, lr=1e-5, step_loss=0.0527]07/18/2023 19:03:48 - INFO - __main__ - train loss is 4.862054496770725\n",
      "Steps:   0%|   | 45/15000 [00:25<2:15:45,  1.84it/s, lr=1e-5, step_loss=0.00566]07/18/2023 19:03:48 - INFO - __main__ - train loss is 5.029350965982303\n",
      "Steps:   0%|     | 46/15000 [00:26<2:15:32,  1.84it/s, lr=1e-5, step_loss=0.167]07/18/2023 19:03:49 - INFO - __main__ - train loss is 5.1452633363660425\n",
      "Steps:   0%|     | 47/15000 [00:27<2:15:26,  1.84it/s, lr=1e-5, step_loss=0.116]07/18/2023 19:03:49 - INFO - __main__ - train loss is 5.269608445232734\n",
      "Steps:   0%|     | 48/15000 [00:27<2:16:11,  1.83it/s, lr=1e-5, step_loss=0.124]07/18/2023 19:03:50 - INFO - __main__ - train loss is 5.377230591839179\n",
      "Steps:   0%|     | 49/15000 [00:28<2:16:15,  1.83it/s, lr=1e-5, step_loss=0.108]07/18/2023 19:03:50 - INFO - __main__ - train loss is 5.614805616205558\n",
      "Steps:   0%|     | 50/15000 [00:28<2:16:24,  1.83it/s, lr=1e-5, step_loss=0.238]07/18/2023 19:03:51 - INFO - __main__ - train loss is 5.98765967017971\n",
      "Steps:   0%|     | 51/15000 [00:29<2:16:16,  1.83it/s, lr=1e-5, step_loss=0.373]07/18/2023 19:03:51 - INFO - __main__ - train loss is 5.995766579871997\n",
      "Steps:   0%|   | 52/15000 [00:29<2:16:09,  1.83it/s, lr=1e-5, step_loss=0.00811]07/18/2023 19:03:52 - INFO - __main__ - train loss is 6.3188724217470735\n",
      "Steps:   0%|     | 53/15000 [00:30<2:16:12,  1.83it/s, lr=1e-5, step_loss=0.323]07/18/2023 19:03:52 - INFO - __main__ - train loss is 6.322628853842616\n",
      "Steps:   0%|   | 54/15000 [00:30<2:16:21,  1.83it/s, lr=1e-5, step_loss=0.00376]07/18/2023 19:03:53 - INFO - __main__ - train loss is 6.3281845659948885\n",
      "Steps:   0%|   | 55/15000 [00:31<2:16:29,  1.82it/s, lr=1e-5, step_loss=0.00556]07/18/2023 19:03:54 - INFO - __main__ - train loss is 6.782533666584641\n",
      "Steps:   0%|     | 56/15000 [00:31<2:16:08,  1.83it/s, lr=1e-5, step_loss=0.454]07/18/2023 19:03:54 - INFO - __main__ - train loss is 6.847376665566117\n",
      "Steps:   0%|    | 57/15000 [00:32<2:16:17,  1.83it/s, lr=1e-5, step_loss=0.0648]07/18/2023 19:03:55 - INFO - __main__ - train loss is 6.9356113956309855\n",
      "Steps:   0%|    | 58/15000 [00:33<2:16:24,  1.83it/s, lr=1e-5, step_loss=0.0882]07/18/2023 19:03:55 - INFO - __main__ - train loss is 7.65565779665485\n",
      "Steps:   0%|      | 59/15000 [00:33<2:16:24,  1.83it/s, lr=1e-5, step_loss=0.72]07/18/2023 19:03:56 - INFO - __main__ - train loss is 7.660299823153764\n",
      "Steps:   0%|   | 60/15000 [00:34<2:16:11,  1.83it/s, lr=1e-5, step_loss=0.00464]07/18/2023 19:03:56 - INFO - __main__ - train loss is 8.001438305247575\n",
      "Steps:   0%|     | 61/15000 [00:34<2:16:24,  1.83it/s, lr=1e-5, step_loss=0.341]07/18/2023 19:03:57 - INFO - __main__ - train loss is 8.010645935777575\n",
      "Steps:   0%|   | 62/15000 [00:35<2:16:34,  1.82it/s, lr=1e-5, step_loss=0.00921]07/18/2023 19:03:57 - INFO - __main__ - train loss is 8.341420660261065\n",
      "Steps:   0%|     | 63/15000 [00:35<2:16:25,  1.82it/s, lr=1e-5, step_loss=0.331]07/18/2023 19:03:58 - INFO - __main__ - train loss is 8.999482760671526\n",
      "Steps:   0%|     | 64/15000 [00:36<2:15:30,  1.84it/s, lr=1e-5, step_loss=0.658]07/18/2023 19:03:58 - INFO - __main__ - train loss is 9.005105272401124\n",
      "Steps:   0%|   | 65/15000 [00:36<2:14:49,  1.85it/s, lr=1e-5, step_loss=0.00562]07/18/2023 19:03:59 - INFO - __main__ - train loss is 9.69121338473633\n",
      "Steps:   0%|     | 66/15000 [00:37<2:15:12,  1.84it/s, lr=1e-5, step_loss=0.686]07/18/2023 19:04:00 - INFO - __main__ - train loss is 9.701374730560929\n",
      "Steps:   0%|    | 67/15000 [00:37<2:15:29,  1.84it/s, lr=1e-5, step_loss=0.0102]07/18/2023 19:04:00 - INFO - __main__ - train loss is 9.73190143192187\n",
      "Steps:   0%|    | 68/15000 [00:38<2:15:31,  1.84it/s, lr=1e-5, step_loss=0.0305]07/18/2023 19:04:01 - INFO - __main__ - train loss is 9.741671425756067\n",
      "Steps:   0%|   | 69/15000 [00:39<2:15:37,  1.83it/s, lr=1e-5, step_loss=0.00977]07/18/2023 19:04:01 - INFO - __main__ - train loss is 10.04585270350799\n",
      "Steps:   0%|     | 70/15000 [00:39<2:15:17,  1.84it/s, lr=1e-5, step_loss=0.304]07/18/2023 19:04:02 - INFO - __main__ - train loss is 10.404576105531305\n",
      "Steps:   0%|     | 71/15000 [00:40<2:15:10,  1.84it/s, lr=1e-5, step_loss=0.359]07/18/2023 19:04:02 - INFO - __main__ - train loss is 10.413786911871284\n",
      "Steps:   0%|   | 72/15000 [00:40<2:15:05,  1.84it/s, lr=1e-5, step_loss=0.00921]07/18/2023 19:04:03 - INFO - __main__ - train loss is 10.422600229736418\n",
      "Steps:   0%|   | 73/15000 [00:41<2:14:41,  1.85it/s, lr=1e-5, step_loss=0.00881]07/18/2023 19:04:03 - INFO - __main__ - train loss is 10.42691079294309\n",
      "Steps:   0%|   | 74/15000 [00:41<2:15:14,  1.84it/s, lr=1e-5, step_loss=0.00431]07/18/2023 19:04:04 - INFO - __main__ - train loss is 10.459086639340967\n",
      "Steps:   0%|    | 75/15000 [00:42<2:14:52,  1.84it/s, lr=1e-5, step_loss=0.0322]07/18/2023 19:04:04 - INFO - __main__ - train loss is 10.464555087964982\n",
      "Steps:   1%|   | 76/15000 [00:42<2:14:20,  1.85it/s, lr=1e-5, step_loss=0.00547]07/18/2023 19:04:05 - INFO - __main__ - train loss is 10.680833879392594\n",
      "Steps:   1%|     | 77/15000 [00:43<2:14:45,  1.85it/s, lr=1e-5, step_loss=0.216]07/18/2023 19:04:06 - INFO - __main__ - train loss is 11.096349302213639\n",
      "Steps:   1%|     | 78/15000 [00:43<2:15:04,  1.84it/s, lr=1e-5, step_loss=0.416]07/18/2023 19:04:06 - INFO - __main__ - train loss is 11.348678413312882\n",
      "Steps:   1%|     | 79/15000 [00:44<2:15:57,  1.83it/s, lr=1e-5, step_loss=0.252]07/18/2023 19:04:07 - INFO - __main__ - train loss is 11.398759241681546\n",
      "Steps:   1%|    | 80/15000 [00:45<2:15:42,  1.83it/s, lr=1e-5, step_loss=0.0501]07/18/2023 19:04:07 - INFO - __main__ - train loss is 11.860159094911069\n",
      "Steps:   1%|     | 81/15000 [00:45<2:16:06,  1.83it/s, lr=1e-5, step_loss=0.461]07/18/2023 19:04:08 - INFO - __main__ - train loss is 11.953942950349301\n",
      "Steps:   1%|    | 82/15000 [00:46<2:15:52,  1.83it/s, lr=1e-5, step_loss=0.0938]07/18/2023 19:04:08 - INFO - __main__ - train loss is 12.47559219179675\n",
      "Steps:   1%|     | 83/15000 [00:46<2:16:08,  1.83it/s, lr=1e-5, step_loss=0.522]07/18/2023 19:04:09 - INFO - __main__ - train loss is 12.489341469015926\n",
      "Steps:   1%|    | 84/15000 [00:47<2:17:02,  1.81it/s, lr=1e-5, step_loss=0.0137]07/18/2023 19:04:09 - INFO - __main__ - train loss is 12.73448017379269\n",
      "Steps:   1%|     | 85/15000 [00:47<2:16:30,  1.82it/s, lr=1e-5, step_loss=0.245]07/18/2023 19:04:10 - INFO - __main__ - train loss is 12.772803773637861\n",
      "Steps:   1%|    | 86/15000 [00:48<2:16:11,  1.83it/s, lr=1e-5, step_loss=0.0383]07/18/2023 19:04:10 - INFO - __main__ - train loss is 12.85870680725202\n",
      "Steps:   1%|    | 87/15000 [00:48<2:15:48,  1.83it/s, lr=1e-5, step_loss=0.0859]07/18/2023 19:04:11 - INFO - __main__ - train loss is 13.107744117733091\n",
      "Steps:   1%|     | 88/15000 [00:49<2:16:03,  1.83it/s, lr=1e-5, step_loss=0.249]07/18/2023 19:04:12 - INFO - __main__ - train loss is 13.33109708642587\n",
      "Steps:   1%|     | 89/15000 [00:49<2:15:27,  1.83it/s, lr=1e-5, step_loss=0.223]07/18/2023 19:04:12 - INFO - __main__ - train loss is 13.35625791689381\n",
      "Steps:   1%|    | 90/15000 [00:50<2:16:07,  1.83it/s, lr=1e-5, step_loss=0.0252]07/18/2023 19:04:13 - INFO - __main__ - train loss is 13.537109868135303\n",
      "Steps:   1%|     | 91/15000 [00:51<2:15:35,  1.83it/s, lr=1e-5, step_loss=0.181]07/18/2023 19:04:13 - INFO - __main__ - train loss is 13.677792729344219\n",
      "Steps:   1%|     | 92/15000 [00:51<2:16:30,  1.82it/s, lr=1e-5, step_loss=0.141]07/18/2023 19:04:14 - INFO - __main__ - train loss is 13.76528533687815\n",
      "Steps:   1%|    | 93/15000 [00:52<2:16:06,  1.83it/s, lr=1e-5, step_loss=0.0875]07/18/2023 19:04:14 - INFO - __main__ - train loss is 13.855459557380527\n",
      "Steps:   1%|    | 94/15000 [00:52<2:15:56,  1.83it/s, lr=1e-5, step_loss=0.0902]07/18/2023 19:04:15 - INFO - __main__ - train loss is 14.30417458852753\n",
      "Steps:   1%|     | 95/15000 [00:53<2:17:15,  1.81it/s, lr=1e-5, step_loss=0.449]07/18/2023 19:04:15 - INFO - __main__ - train loss is 14.779660986270756\n",
      "Steps:   1%|     | 96/15000 [00:53<2:16:49,  1.82it/s, lr=1e-5, step_loss=0.475]07/18/2023 19:04:16 - INFO - __main__ - train loss is 15.164701805915684\n",
      "Steps:   1%|     | 97/15000 [00:54<2:27:27,  1.68it/s, lr=1e-5, step_loss=0.385]07/18/2023 19:04:17 - INFO - __main__ - Per validation step average loss is 0.041332535445690155\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Cumulative validation average loss is 0.041332535445690155\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Per validation step average loss is 0.21056929230690002\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Cumulative validation average loss is 0.2519018277525902\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Per validation step average loss is 0.12331663072109222\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Cumulative validation average loss is 0.3752184584736824\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Per validation step average loss is 0.07478029280900955\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Cumulative validation average loss is 0.44999875128269196\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Per validation step average loss is 0.13968265056610107\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Cumulative validation average loss is 0.589681401848793\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Per validation step average loss is 0.0025295917876064777\n",
      "07/18/2023 19:04:17 - INFO - __main__ - Cumulative validation average loss is 0.5922109936363995\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Per validation step average loss is 0.09578921645879745\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Cumulative validation average loss is 0.688000210095197\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Per validation step average loss is 0.0030335169285535812\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Cumulative validation average loss is 0.6910337270237505\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Per validation step average loss is 0.9400597810745239\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Cumulative validation average loss is 1.6310935080982745\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Per validation step average loss is 0.2952926754951477\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Cumulative validation average loss is 1.9263861835934222\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Per validation step average loss is 0.145958811044693\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Cumulative validation average loss is 2.072344994638115\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Per validation step average loss is 0.09601302444934845\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Cumulative validation average loss is 2.1683580190874636\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Average validation loss for Epoch 0 is 0.18069650159062198\n",
      "07/18/2023 19:04:18 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:04:31 - INFO - __main__ - Starting epoch 1\n",
      "07/18/2023 19:04:32 - INFO - __main__ - train loss is 0.39640048146247864\n",
      "Steps:   1%|    | 98/15000 [01:10<21:10:06,  5.11s/it, lr=1e-5, step_loss=0.396]07/18/2023 19:04:32 - INFO - __main__ - train loss is 0.5570459365844727\n",
      "Steps:   1%|    | 99/15000 [01:10<15:02:36,  3.63s/it, lr=1e-5, step_loss=0.161]07/18/2023 19:04:32 - INFO - __main__ - train loss is 0.5608506225980818\n",
      "Steps:   1%|  | 100/15000 [01:10<10:45:45,  2.60s/it, lr=1e-5, step_loss=0.0038]07/18/2023 19:04:32 - INFO - __main__ - train loss is 0.5892218188382685\n",
      "Steps:   1%|   | 101/15000 [01:10<7:45:36,  1.88s/it, lr=1e-5, step_loss=0.0284]07/18/2023 19:04:32 - INFO - __main__ - train loss is 1.171878977213055\n",
      "Steps:   1%|    | 102/15000 [01:10<5:39:44,  1.37s/it, lr=1e-5, step_loss=0.583]07/18/2023 19:04:33 - INFO - __main__ - train loss is 1.2395308227278292\n",
      "Steps:   1%|   | 103/15000 [01:11<4:11:26,  1.01s/it, lr=1e-5, step_loss=0.0677]07/18/2023 19:04:33 - INFO - __main__ - train loss is 1.3315559686161578\n",
      "Steps:   1%|    | 104/15000 [01:11<3:09:43,  1.31it/s, lr=1e-5, step_loss=0.092]07/18/2023 19:04:33 - INFO - __main__ - train loss is 1.3745237574912608\n",
      "Steps:   1%|    | 105/15000 [01:11<2:26:29,  1.69it/s, lr=1e-5, step_loss=0.043]07/18/2023 19:04:33 - INFO - __main__ - train loss is 1.4092193902470171\n",
      "Steps:   1%|   | 106/15000 [01:11<1:55:53,  2.14it/s, lr=1e-5, step_loss=0.0347]07/18/2023 19:04:33 - INFO - __main__ - train loss is 1.42522711167112\n",
      "Steps:   1%|    | 107/15000 [01:11<1:34:29,  2.63it/s, lr=1e-5, step_loss=0.016]07/18/2023 19:04:34 - INFO - __main__ - train loss is 1.8670892179943621\n",
      "Steps:   1%|    | 108/15000 [01:11<1:19:32,  3.12it/s, lr=1e-5, step_loss=0.442]07/18/2023 19:04:34 - INFO - __main__ - train loss is 1.898052825126797\n",
      "Steps:   1%|    | 109/15000 [01:12<1:09:04,  3.59it/s, lr=1e-5, step_loss=0.031]07/18/2023 19:04:34 - INFO - __main__ - train loss is 1.9010793794877827\n",
      "Steps:   1%|  | 110/15000 [01:12<1:01:50,  4.01it/s, lr=1e-5, step_loss=0.00303]07/18/2023 19:04:34 - INFO - __main__ - train loss is 2.3481036056764424\n",
      "Steps:   1%|      | 111/15000 [01:12<56:36,  4.38it/s, lr=1e-5, step_loss=0.447]07/18/2023 19:04:34 - INFO - __main__ - train loss is 2.359872138593346\n",
      "Steps:   1%|     | 112/15000 [01:12<52:56,  4.69it/s, lr=1e-5, step_loss=0.0118]07/18/2023 19:04:34 - INFO - __main__ - train loss is 2.512978753540665\n",
      "Steps:   1%|      | 113/15000 [01:12<50:24,  4.92it/s, lr=1e-5, step_loss=0.153]07/18/2023 19:04:35 - INFO - __main__ - train loss is 2.748332864139229\n",
      "Steps:   1%|      | 114/15000 [01:13<48:52,  5.08it/s, lr=1e-5, step_loss=0.235]07/18/2023 19:04:35 - INFO - __main__ - train loss is 2.753326310776174\n",
      "Steps:   1%|    | 115/15000 [01:13<47:38,  5.21it/s, lr=1e-5, step_loss=0.00499]07/18/2023 19:04:35 - INFO - __main__ - train loss is 2.8157156025990844\n",
      "Steps:   1%|     | 116/15000 [01:13<46:45,  5.31it/s, lr=1e-5, step_loss=0.0624]07/18/2023 19:04:35 - INFO - __main__ - train loss is 3.02666690107435\n",
      "Steps:   1%|      | 117/15000 [01:13<46:06,  5.38it/s, lr=1e-5, step_loss=0.211]07/18/2023 19:04:35 - INFO - __main__ - train loss is 3.039617125876248\n",
      "Steps:   1%|      | 118/15000 [01:13<45:40,  5.43it/s, lr=1e-5, step_loss=0.013]07/18/2023 19:04:36 - INFO - __main__ - train loss is 3.0610823007300496\n",
      "Steps:   1%|     | 119/15000 [01:13<45:21,  5.47it/s, lr=1e-5, step_loss=0.0215]07/18/2023 19:04:36 - INFO - __main__ - train loss is 3.0636690286919475\n",
      "Steps:   1%|    | 120/15000 [01:14<45:08,  5.49it/s, lr=1e-5, step_loss=0.00259]07/18/2023 19:04:36 - INFO - __main__ - train loss is 3.5330704478546977\n",
      "Steps:   1%|      | 121/15000 [01:14<44:59,  5.51it/s, lr=1e-5, step_loss=0.469]07/18/2023 19:04:36 - INFO - __main__ - train loss is 3.7672516284510493\n",
      "Steps:   1%|      | 122/15000 [01:14<44:51,  5.53it/s, lr=1e-5, step_loss=0.234]07/18/2023 19:04:36 - INFO - __main__ - train loss is 3.7994308723136783\n",
      "Steps:   1%|     | 123/15000 [01:14<44:46,  5.54it/s, lr=1e-5, step_loss=0.0322]07/18/2023 19:04:36 - INFO - __main__ - train loss is 3.9374296767637134\n",
      "Steps:   1%|      | 124/15000 [01:14<44:43,  5.54it/s, lr=1e-5, step_loss=0.138]07/18/2023 19:04:37 - INFO - __main__ - train loss is 3.9409353679511696\n",
      "Steps:   1%|    | 125/15000 [01:15<45:08,  5.49it/s, lr=1e-5, step_loss=0.00351]07/18/2023 19:04:37 - INFO - __main__ - train loss is 4.090515787014738\n",
      "Steps:   1%|       | 126/15000 [01:15<44:55,  5.52it/s, lr=1e-5, step_loss=0.15]07/18/2023 19:04:37 - INFO - __main__ - train loss is 4.190344983944669\n",
      "Steps:   1%|     | 127/15000 [01:15<44:40,  5.55it/s, lr=1e-5, step_loss=0.0998]07/18/2023 19:04:37 - INFO - __main__ - train loss is 4.367440143832937\n",
      "Steps:   1%|      | 128/15000 [01:15<44:38,  5.55it/s, lr=1e-5, step_loss=0.177]07/18/2023 19:04:37 - INFO - __main__ - train loss is 4.406405536690727\n",
      "Steps:   1%|      | 129/15000 [01:15<44:38,  5.55it/s, lr=1e-5, step_loss=0.039]07/18/2023 19:04:38 - INFO - __main__ - train loss is 4.45236117974855\n",
      "Steps:   1%|      | 130/15000 [01:15<44:40,  5.55it/s, lr=1e-5, step_loss=0.046]07/18/2023 19:04:38 - INFO - __main__ - train loss is 4.469740689033642\n",
      "Steps:   1%|     | 131/15000 [01:16<44:40,  5.55it/s, lr=1e-5, step_loss=0.0174]07/18/2023 19:04:38 - INFO - __main__ - train loss is 4.479255418526009\n",
      "Steps:   1%|    | 132/15000 [01:16<44:44,  5.54it/s, lr=1e-5, step_loss=0.00951]07/18/2023 19:04:38 - INFO - __main__ - train loss is 4.675205598818138\n",
      "Steps:   1%|      | 133/15000 [01:16<44:46,  5.53it/s, lr=1e-5, step_loss=0.196]07/18/2023 19:04:38 - INFO - __main__ - train loss is 4.686638443963602\n",
      "Steps:   1%|     | 134/15000 [01:16<45:01,  5.50it/s, lr=1e-5, step_loss=0.0114]07/18/2023 19:04:38 - INFO - __main__ - train loss is 4.839415102498606\n",
      "Steps:   1%|      | 135/15000 [01:16<45:16,  5.47it/s, lr=1e-5, step_loss=0.153]07/18/2023 19:04:39 - INFO - __main__ - train loss is 5.463410704629496\n",
      "Steps:   1%|      | 136/15000 [01:17<45:17,  5.47it/s, lr=1e-5, step_loss=0.624]07/18/2023 19:04:39 - INFO - __main__ - train loss is 5.85367754031904\n",
      "Steps:   1%|       | 137/15000 [01:17<44:54,  5.52it/s, lr=1e-5, step_loss=0.39]07/18/2023 19:04:39 - INFO - __main__ - train loss is 6.2912402742076665\n",
      "Steps:   1%|      | 138/15000 [01:17<44:37,  5.55it/s, lr=1e-5, step_loss=0.438]07/18/2023 19:04:39 - INFO - __main__ - train loss is 6.439669593470171\n",
      "Steps:   1%|      | 139/15000 [01:17<44:24,  5.58it/s, lr=1e-5, step_loss=0.148]07/18/2023 19:04:39 - INFO - __main__ - train loss is 6.441827944712713\n",
      "Steps:   1%|    | 140/15000 [01:17<44:16,  5.59it/s, lr=1e-5, step_loss=0.00216]07/18/2023 19:04:40 - INFO - __main__ - train loss is 6.452818564372137\n",
      "Steps:   1%|      | 141/15000 [01:17<44:29,  5.57it/s, lr=1e-5, step_loss=0.011]07/18/2023 19:04:40 - INFO - __main__ - train loss is 6.581177822547033\n",
      "Steps:   1%|      | 142/15000 [01:18<44:19,  5.59it/s, lr=1e-5, step_loss=0.128]07/18/2023 19:04:40 - INFO - __main__ - train loss is 6.600779059575871\n",
      "Steps:   1%|     | 143/15000 [01:18<44:12,  5.60it/s, lr=1e-5, step_loss=0.0196]07/18/2023 19:04:40 - INFO - __main__ - train loss is 6.649698379682377\n",
      "Steps:   1%|     | 144/15000 [01:18<44:32,  5.56it/s, lr=1e-5, step_loss=0.0489]07/18/2023 19:04:40 - INFO - __main__ - train loss is 7.436563018010929\n",
      "Steps:   1%|      | 145/15000 [01:18<44:28,  5.57it/s, lr=1e-5, step_loss=0.787]07/18/2023 19:04:40 - INFO - __main__ - train loss is 7.68903476302512\n",
      "Steps:   1%|      | 146/15000 [01:18<44:19,  5.59it/s, lr=1e-5, step_loss=0.252]07/18/2023 19:04:41 - INFO - __main__ - train loss is 7.9198779196012765\n",
      "Steps:   1%|      | 147/15000 [01:18<44:13,  5.60it/s, lr=1e-5, step_loss=0.231]07/18/2023 19:04:41 - INFO - __main__ - train loss is 7.939161067130044\n",
      "Steps:   1%|     | 148/15000 [01:19<44:07,  5.61it/s, lr=1e-5, step_loss=0.0193]07/18/2023 19:04:41 - INFO - __main__ - train loss is 7.9463641385082155\n",
      "Steps:   1%|     | 149/15000 [01:19<44:03,  5.62it/s, lr=1e-5, step_loss=0.0072]07/18/2023 19:04:41 - INFO - __main__ - train loss is 7.948350601829588\n",
      "Steps:   1%|    | 150/15000 [01:19<44:01,  5.62it/s, lr=1e-5, step_loss=0.00199]07/18/2023 19:04:41 - INFO - __main__ - train loss is 7.962225033901632\n",
      "Steps:   1%|     | 151/15000 [01:19<44:00,  5.62it/s, lr=1e-5, step_loss=0.0139]07/18/2023 19:04:41 - INFO - __main__ - train loss is 8.09807602968067\n",
      "Steps:   1%|      | 152/15000 [01:19<44:00,  5.62it/s, lr=1e-5, step_loss=0.136]07/18/2023 19:04:42 - INFO - __main__ - train loss is 8.470328136347234\n",
      "Steps:   1%|      | 153/15000 [01:20<43:59,  5.63it/s, lr=1e-5, step_loss=0.372]07/18/2023 19:04:42 - INFO - __main__ - train loss is 8.473910965956748\n",
      "Steps:   1%|    | 154/15000 [01:20<43:57,  5.63it/s, lr=1e-5, step_loss=0.00358]07/18/2023 19:04:42 - INFO - __main__ - train loss is 8.498250191099942\n",
      "Steps:   1%|     | 155/15000 [01:20<43:56,  5.63it/s, lr=1e-5, step_loss=0.0243]07/18/2023 19:04:42 - INFO - __main__ - train loss is 8.843606357462704\n",
      "Steps:   1%|      | 156/15000 [01:20<43:55,  5.63it/s, lr=1e-5, step_loss=0.345]07/18/2023 19:04:42 - INFO - __main__ - train loss is 9.613934402354062\n",
      "Steps:   1%|       | 157/15000 [01:20<43:55,  5.63it/s, lr=1e-5, step_loss=0.77]07/18/2023 19:04:43 - INFO - __main__ - train loss is 9.992536847479641\n",
      "Steps:   1%|      | 158/15000 [01:20<43:57,  5.63it/s, lr=1e-5, step_loss=0.379]07/18/2023 19:04:43 - INFO - __main__ - train loss is 10.014367655850947\n",
      "Steps:   1%|     | 159/15000 [01:21<43:57,  5.63it/s, lr=1e-5, step_loss=0.0218]07/18/2023 19:04:43 - INFO - __main__ - train loss is 10.121179752983153\n",
      "Steps:   1%|      | 160/15000 [01:21<43:54,  5.63it/s, lr=1e-5, step_loss=0.107]07/18/2023 19:04:43 - INFO - __main__ - train loss is 10.73899703565985\n",
      "Steps:   1%|      | 161/15000 [01:21<43:53,  5.63it/s, lr=1e-5, step_loss=0.618]07/18/2023 19:04:43 - INFO - __main__ - train loss is 11.33498650137335\n",
      "Steps:   1%|      | 162/15000 [01:21<43:52,  5.64it/s, lr=1e-5, step_loss=0.596]07/18/2023 19:04:43 - INFO - __main__ - train loss is 11.34449493791908\n",
      "Steps:   1%|    | 163/15000 [01:21<43:51,  5.64it/s, lr=1e-5, step_loss=0.00951]07/18/2023 19:04:44 - INFO - __main__ - train loss is 11.597899137996137\n",
      "Steps:   1%|      | 164/15000 [01:22<43:53,  5.63it/s, lr=1e-5, step_loss=0.253]07/18/2023 19:04:44 - INFO - __main__ - train loss is 11.600382640725002\n",
      "Steps:   1%|    | 165/15000 [01:22<43:52,  5.63it/s, lr=1e-5, step_loss=0.00248]07/18/2023 19:04:44 - INFO - __main__ - train loss is 11.613279167329893\n",
      "Steps:   1%|     | 166/15000 [01:22<43:52,  5.63it/s, lr=1e-5, step_loss=0.0129]07/18/2023 19:04:44 - INFO - __main__ - train loss is 11.622168762376532\n",
      "Steps:   1%|    | 167/15000 [01:22<43:52,  5.63it/s, lr=1e-5, step_loss=0.00889]07/18/2023 19:04:44 - INFO - __main__ - train loss is 11.83763170032762\n",
      "Steps:   1%|      | 168/15000 [01:22<43:50,  5.64it/s, lr=1e-5, step_loss=0.215]07/18/2023 19:04:45 - INFO - __main__ - train loss is 11.843952881870791\n",
      "Steps:   1%|    | 169/15000 [01:22<43:51,  5.64it/s, lr=1e-5, step_loss=0.00632]07/18/2023 19:04:45 - INFO - __main__ - train loss is 12.125474023399875\n",
      "Steps:   1%|      | 170/15000 [01:23<43:52,  5.63it/s, lr=1e-5, step_loss=0.282]07/18/2023 19:04:45 - INFO - __main__ - train loss is 12.619423526106402\n",
      "Steps:   1%|      | 171/15000 [01:23<43:54,  5.63it/s, lr=1e-5, step_loss=0.494]07/18/2023 19:04:45 - INFO - __main__ - train loss is 12.625186727149412\n",
      "Steps:   1%|    | 172/15000 [01:23<44:06,  5.60it/s, lr=1e-5, step_loss=0.00576]07/18/2023 19:04:45 - INFO - __main__ - train loss is 12.627955790841952\n",
      "Steps:   1%|    | 173/15000 [01:23<44:26,  5.56it/s, lr=1e-5, step_loss=0.00277]07/18/2023 19:04:45 - INFO - __main__ - train loss is 13.021912750089541\n",
      "Steps:   1%|      | 174/15000 [01:23<44:41,  5.53it/s, lr=1e-5, step_loss=0.394]07/18/2023 19:04:46 - INFO - __main__ - train loss is 13.094506535911933\n",
      "Steps:   1%|     | 175/15000 [01:23<44:55,  5.50it/s, lr=1e-5, step_loss=0.0726]07/18/2023 19:04:46 - INFO - __main__ - train loss is 13.254941050196066\n",
      "Steps:   1%|       | 176/15000 [01:24<44:57,  5.50it/s, lr=1e-5, step_loss=0.16]07/18/2023 19:04:46 - INFO - __main__ - train loss is 13.834704105043784\n",
      "Steps:   1%|       | 177/15000 [01:24<44:39,  5.53it/s, lr=1e-5, step_loss=0.58]07/18/2023 19:04:46 - INFO - __main__ - train loss is 13.852326918626204\n",
      "Steps:   1%|     | 178/15000 [01:24<44:25,  5.56it/s, lr=1e-5, step_loss=0.0176]07/18/2023 19:04:46 - INFO - __main__ - train loss is 13.958912629866973\n",
      "Steps:   1%|      | 179/15000 [01:24<44:17,  5.58it/s, lr=1e-5, step_loss=0.107]07/18/2023 19:04:46 - INFO - __main__ - train loss is 14.077448401832953\n",
      "Steps:   1%|      | 180/15000 [01:24<44:17,  5.58it/s, lr=1e-5, step_loss=0.119]07/18/2023 19:04:47 - INFO - __main__ - train loss is 14.50781798758544\n",
      "Steps:   1%|       | 181/15000 [01:25<44:19,  5.57it/s, lr=1e-5, step_loss=0.43]07/18/2023 19:04:47 - INFO - __main__ - train loss is 14.75777805247344\n",
      "Steps:   1%|       | 182/15000 [01:25<44:08,  5.59it/s, lr=1e-5, step_loss=0.25]07/18/2023 19:04:47 - INFO - __main__ - train loss is 14.77708830521442\n",
      "Steps:   1%|     | 183/15000 [01:25<44:00,  5.61it/s, lr=1e-5, step_loss=0.0193]07/18/2023 19:04:47 - INFO - __main__ - train loss is 14.788821390131488\n",
      "Steps:   1%|     | 184/15000 [01:25<43:55,  5.62it/s, lr=1e-5, step_loss=0.0117]07/18/2023 19:04:47 - INFO - __main__ - train loss is 14.79061550879851\n",
      "Steps:   1%|    | 185/15000 [01:25<43:52,  5.63it/s, lr=1e-5, step_loss=0.00179]07/18/2023 19:04:48 - INFO - __main__ - train loss is 15.222308407071978\n",
      "Steps:   1%|      | 186/15000 [01:25<43:51,  5.63it/s, lr=1e-5, step_loss=0.432]07/18/2023 19:04:48 - INFO - __main__ - train loss is 15.234969127457589\n",
      "Steps:   1%|     | 187/15000 [01:26<43:50,  5.63it/s, lr=1e-5, step_loss=0.0127]07/18/2023 19:04:48 - INFO - __main__ - train loss is 15.245855305809528\n",
      "Steps:   1%|     | 188/15000 [01:26<43:49,  5.63it/s, lr=1e-5, step_loss=0.0109]07/18/2023 19:04:48 - INFO - __main__ - train loss is 15.454721037764102\n",
      "Steps:   1%|      | 189/15000 [01:26<43:48,  5.64it/s, lr=1e-5, step_loss=0.209]07/18/2023 19:04:48 - INFO - __main__ - train loss is 15.513396241236478\n",
      "Steps:   1%|     | 190/15000 [01:26<43:47,  5.64it/s, lr=1e-5, step_loss=0.0587]07/18/2023 19:04:48 - INFO - __main__ - train loss is 15.766941108275205\n",
      "Steps:   1%|      | 191/15000 [01:26<43:47,  5.64it/s, lr=1e-5, step_loss=0.254]07/18/2023 19:04:49 - INFO - __main__ - train loss is 16.340283908415586\n",
      "Steps:   1%|      | 192/15000 [01:27<43:47,  5.64it/s, lr=1e-5, step_loss=0.573]07/18/2023 19:04:49 - INFO - __main__ - train loss is 16.377663717139512\n",
      "Steps:   1%|     | 193/15000 [01:27<43:47,  5.64it/s, lr=1e-5, step_loss=0.0374]07/18/2023 19:04:49 - INFO - __main__ - train loss is 16.466337196994573\n",
      "Steps:   1%|   | 194/15000 [01:27<1:00:03,  4.11it/s, lr=1e-5, step_loss=0.0887]07/18/2023 19:04:50 - INFO - __main__ - Per validation step average loss is 0.003670644713565707\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Cumulative validation average loss is 0.003670644713565707\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Per validation step average loss is 0.08682651072740555\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Cumulative validation average loss is 0.09049715544097126\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Per validation step average loss is 0.8191606998443604\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Cumulative validation average loss is 0.9096578552853316\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Per validation step average loss is 0.023471347987651825\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Cumulative validation average loss is 0.9331292032729834\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Per validation step average loss is 0.04735539108514786\n",
      "07/18/2023 19:04:50 - INFO - __main__ - Cumulative validation average loss is 0.9804845943581313\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Per validation step average loss is 0.004024091642349958\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Cumulative validation average loss is 0.9845086860004812\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Per validation step average loss is 0.04133032634854317\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Cumulative validation average loss is 1.0258390123490244\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Per validation step average loss is 0.2732583284378052\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Cumulative validation average loss is 1.2990973407868296\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Per validation step average loss is 0.2136363685131073\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Cumulative validation average loss is 1.512733709299937\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Per validation step average loss is 0.1340409517288208\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Cumulative validation average loss is 1.6467746610287577\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Per validation step average loss is 0.5993691086769104\n",
      "07/18/2023 19:04:51 - INFO - __main__ - Cumulative validation average loss is 2.246143769705668\n",
      "07/18/2023 19:04:52 - INFO - __main__ - Per validation step average loss is 0.010518605820834637\n",
      "07/18/2023 19:04:52 - INFO - __main__ - Cumulative validation average loss is 2.2566623755265027\n",
      "07/18/2023 19:04:52 - INFO - __main__ - Average validation loss for Epoch 1 is 0.1880551979605419\n",
      "07/18/2023 19:04:52 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:05:04 - INFO - __main__ - Starting epoch 2\n",
      "07/18/2023 19:05:05 - INFO - __main__ - train loss is 0.25631242990493774\n",
      "Steps:   1%|   | 195/15000 [01:43<20:11:00,  4.91s/it, lr=1e-5, step_loss=0.256]07/18/2023 19:05:05 - INFO - __main__ - train loss is 0.2737265955656767\n",
      "Steps:   1%|  | 196/15000 [01:43<14:21:38,  3.49s/it, lr=1e-5, step_loss=0.0174]07/18/2023 19:05:05 - INFO - __main__ - train loss is 0.2800791943445802\n",
      "Steps:   1%| | 197/15000 [01:43<10:16:28,  2.50s/it, lr=1e-5, step_loss=0.00635]07/18/2023 19:05:06 - INFO - __main__ - train loss is 0.4854253614321351\n",
      "Steps:   1%|    | 198/15000 [01:43<7:24:47,  1.80s/it, lr=1e-5, step_loss=0.205]07/18/2023 19:05:06 - INFO - __main__ - train loss is 0.6742408806458116\n",
      "Steps:   1%|    | 199/15000 [01:44<5:24:36,  1.32s/it, lr=1e-5, step_loss=0.189]07/18/2023 19:05:06 - INFO - __main__ - train loss is 1.5259444052353501\n",
      "Steps:   1%|    | 200/15000 [01:44<4:00:19,  1.03it/s, lr=1e-5, step_loss=0.852]07/18/2023 19:05:06 - INFO - __main__ - train loss is 2.2183666760101914\n",
      "Steps:   1%|    | 201/15000 [01:44<3:01:22,  1.36it/s, lr=1e-5, step_loss=0.692]07/18/2023 19:05:06 - INFO - __main__ - train loss is 2.220993662253022\n",
      "Steps:   1%|  | 202/15000 [01:44<2:20:27,  1.76it/s, lr=1e-5, step_loss=0.00263]07/18/2023 19:05:06 - INFO - __main__ - train loss is 2.2262938916683197\n",
      "Steps:   1%|   | 203/15000 [01:44<1:51:32,  2.21it/s, lr=1e-5, step_loss=0.0053]07/18/2023 19:05:07 - INFO - __main__ - train loss is 2.862762898206711\n",
      "Steps:   1%|    | 204/15000 [01:45<1:31:27,  2.70it/s, lr=1e-5, step_loss=0.636]07/18/2023 19:05:07 - INFO - __main__ - train loss is 3.402829021215439\n",
      "Steps:   1%|     | 205/15000 [01:45<1:17:08,  3.20it/s, lr=1e-5, step_loss=0.54]07/18/2023 19:05:07 - INFO - __main__ - train loss is 3.4126763362437487\n",
      "Steps:   1%|  | 206/15000 [01:45<1:07:05,  3.68it/s, lr=1e-5, step_loss=0.00985]07/18/2023 19:05:07 - INFO - __main__ - train loss is 3.462540013715625\n",
      "Steps:   1%|   | 207/15000 [01:45<1:00:01,  4.11it/s, lr=1e-5, step_loss=0.0499]07/18/2023 19:05:07 - INFO - __main__ - train loss is 3.784611029550433\n",
      "Steps:   1%|      | 208/15000 [01:45<55:05,  4.47it/s, lr=1e-5, step_loss=0.322]07/18/2023 19:05:08 - INFO - __main__ - train loss is 3.790949920658022\n",
      "Steps:   1%|    | 209/15000 [01:45<51:41,  4.77it/s, lr=1e-5, step_loss=0.00634]07/18/2023 19:05:08 - INFO - __main__ - train loss is 4.454132715705782\n",
      "Steps:   1%|      | 210/15000 [01:46<49:16,  5.00it/s, lr=1e-5, step_loss=0.663]07/18/2023 19:05:08 - INFO - __main__ - train loss is 4.496487008873373\n",
      "Steps:   1%|     | 211/15000 [01:46<47:39,  5.17it/s, lr=1e-5, step_loss=0.0424]07/18/2023 19:05:08 - INFO - __main__ - train loss is 4.621896716300398\n",
      "Steps:   1%|      | 212/15000 [01:46<46:28,  5.30it/s, lr=1e-5, step_loss=0.125]07/18/2023 19:05:08 - INFO - __main__ - train loss is 4.779385271016508\n",
      "Steps:   1%|      | 213/15000 [01:46<45:40,  5.40it/s, lr=1e-5, step_loss=0.157]07/18/2023 19:05:08 - INFO - __main__ - train loss is 5.05427977675572\n",
      "Steps:   1%|      | 214/15000 [01:46<45:05,  5.46it/s, lr=1e-5, step_loss=0.275]07/18/2023 19:05:09 - INFO - __main__ - train loss is 5.089349089656025\n",
      "Steps:   1%|     | 215/15000 [01:46<44:47,  5.50it/s, lr=1e-5, step_loss=0.0351]07/18/2023 19:05:09 - INFO - __main__ - train loss is 5.1023370255716145\n",
      "Steps:   1%|      | 216/15000 [01:47<44:30,  5.54it/s, lr=1e-5, step_loss=0.013]07/18/2023 19:05:09 - INFO - __main__ - train loss is 5.296662115026265\n",
      "Steps:   1%|      | 217/15000 [01:47<44:16,  5.57it/s, lr=1e-5, step_loss=0.194]07/18/2023 19:05:09 - INFO - __main__ - train loss is 5.764233492780477\n",
      "Steps:   1%|      | 218/15000 [01:47<44:07,  5.58it/s, lr=1e-5, step_loss=0.468]07/18/2023 19:05:09 - INFO - __main__ - train loss is 5.85108131961897\n",
      "Steps:   1%|     | 219/15000 [01:47<44:05,  5.59it/s, lr=1e-5, step_loss=0.0868]07/18/2023 19:05:09 - INFO - __main__ - train loss is 5.909907758701593\n",
      "Steps:   1%|     | 220/15000 [01:47<44:08,  5.58it/s, lr=1e-5, step_loss=0.0588]07/18/2023 19:05:10 - INFO - __main__ - train loss is 5.941293657291681\n",
      "Steps:   1%|     | 221/15000 [01:48<44:36,  5.52it/s, lr=1e-5, step_loss=0.0314]07/18/2023 19:05:10 - INFO - __main__ - train loss is 6.144946575630456\n",
      "Steps:   1%|      | 222/15000 [01:48<44:46,  5.50it/s, lr=1e-5, step_loss=0.204]07/18/2023 19:05:10 - INFO - __main__ - train loss is 6.150266077835113\n",
      "Steps:   1%|    | 223/15000 [01:48<44:47,  5.50it/s, lr=1e-5, step_loss=0.00532]07/18/2023 19:05:10 - INFO - __main__ - train loss is 6.522556867916137\n",
      "Steps:   1%|      | 224/15000 [01:48<44:29,  5.54it/s, lr=1e-5, step_loss=0.372]07/18/2023 19:05:10 - INFO - __main__ - train loss is 6.879656281787902\n",
      "Steps:   2%|      | 225/15000 [01:48<44:15,  5.56it/s, lr=1e-5, step_loss=0.357]07/18/2023 19:05:11 - INFO - __main__ - train loss is 7.3092973795719445\n",
      "Steps:   2%|       | 226/15000 [01:48<44:07,  5.58it/s, lr=1e-5, step_loss=0.43]07/18/2023 19:05:11 - INFO - __main__ - train loss is 7.592698570806533\n",
      "Steps:   2%|      | 227/15000 [01:49<44:02,  5.59it/s, lr=1e-5, step_loss=0.283]07/18/2023 19:05:11 - INFO - __main__ - train loss is 7.712851565796882\n",
      "Steps:   2%|       | 228/15000 [01:49<44:28,  5.54it/s, lr=1e-5, step_loss=0.12]07/18/2023 19:05:11 - INFO - __main__ - train loss is 7.7164110648445785\n",
      "Steps:   2%|    | 229/15000 [01:49<44:17,  5.56it/s, lr=1e-5, step_loss=0.00356]07/18/2023 19:05:11 - INFO - __main__ - train loss is 7.908488269429654\n",
      "Steps:   2%|      | 230/15000 [01:49<44:07,  5.58it/s, lr=1e-5, step_loss=0.192]07/18/2023 19:05:11 - INFO - __main__ - train loss is 8.173466499429196\n",
      "Steps:   2%|      | 231/15000 [01:49<44:01,  5.59it/s, lr=1e-5, step_loss=0.265]07/18/2023 19:05:12 - INFO - __main__ - train loss is 8.50920047936961\n",
      "Steps:   2%|      | 232/15000 [01:50<43:57,  5.60it/s, lr=1e-5, step_loss=0.336]07/18/2023 19:05:12 - INFO - __main__ - train loss is 8.550750549416989\n",
      "Steps:   2%|     | 233/15000 [01:50<43:53,  5.61it/s, lr=1e-5, step_loss=0.0416]07/18/2023 19:05:12 - INFO - __main__ - train loss is 8.60443927673623\n",
      "Steps:   2%|     | 234/15000 [01:50<43:50,  5.61it/s, lr=1e-5, step_loss=0.0537]07/18/2023 19:05:12 - INFO - __main__ - train loss is 8.648003454785794\n",
      "Steps:   2%|     | 235/15000 [01:50<43:48,  5.62it/s, lr=1e-5, step_loss=0.0436]07/18/2023 19:05:12 - INFO - __main__ - train loss is 8.668054744135588\n",
      "Steps:   2%|     | 236/15000 [01:50<43:46,  5.62it/s, lr=1e-5, step_loss=0.0201]07/18/2023 19:05:13 - INFO - __main__ - train loss is 9.030925049912184\n",
      "Steps:   2%|      | 237/15000 [01:50<43:49,  5.62it/s, lr=1e-5, step_loss=0.363]07/18/2023 19:05:13 - INFO - __main__ - train loss is 9.065485666971654\n",
      "Steps:   2%|     | 238/15000 [01:51<43:49,  5.61it/s, lr=1e-5, step_loss=0.0346]07/18/2023 19:05:13 - INFO - __main__ - train loss is 9.069769754540175\n",
      "Steps:   2%|    | 239/15000 [01:51<43:48,  5.62it/s, lr=1e-5, step_loss=0.00428]07/18/2023 19:05:13 - INFO - __main__ - train loss is 9.075911791063845\n",
      "Steps:   2%|    | 240/15000 [01:51<43:49,  5.61it/s, lr=1e-5, step_loss=0.00614]07/18/2023 19:05:13 - INFO - __main__ - train loss is 9.078881687484682\n",
      "Steps:   2%|    | 241/15000 [01:51<43:48,  5.62it/s, lr=1e-5, step_loss=0.00297]07/18/2023 19:05:13 - INFO - __main__ - train loss is 9.081214759731665\n",
      "Steps:   2%|    | 242/15000 [01:51<43:48,  5.62it/s, lr=1e-5, step_loss=0.00233]07/18/2023 19:05:14 - INFO - __main__ - train loss is 9.08763930737041\n",
      "Steps:   2%|    | 243/15000 [01:51<43:47,  5.62it/s, lr=1e-5, step_loss=0.00642]07/18/2023 19:05:14 - INFO - __main__ - train loss is 9.642211293568835\n",
      "Steps:   2%|      | 244/15000 [01:52<44:22,  5.54it/s, lr=1e-5, step_loss=0.555]07/18/2023 19:05:14 - INFO - __main__ - train loss is 9.782866721739992\n",
      "Steps:   2%|      | 245/15000 [01:52<44:15,  5.56it/s, lr=1e-5, step_loss=0.141]07/18/2023 19:05:14 - INFO - __main__ - train loss is 10.078307335963473\n",
      "Steps:   2%|      | 246/15000 [01:52<44:34,  5.52it/s, lr=1e-5, step_loss=0.295]07/18/2023 19:05:14 - INFO - __main__ - train loss is 10.091895207529888\n",
      "Steps:   2%|     | 247/15000 [01:52<44:27,  5.53it/s, lr=1e-5, step_loss=0.0136]07/18/2023 19:05:14 - INFO - __main__ - train loss is 10.140207096701488\n",
      "Steps:   2%|     | 248/15000 [01:52<44:24,  5.54it/s, lr=1e-5, step_loss=0.0483]07/18/2023 19:05:15 - INFO - __main__ - train loss is 10.403557255631313\n",
      "Steps:   2%|      | 249/15000 [01:53<44:23,  5.54it/s, lr=1e-5, step_loss=0.263]07/18/2023 19:05:15 - INFO - __main__ - train loss is 10.656021430855617\n",
      "Steps:   2%|      | 250/15000 [01:53<44:22,  5.54it/s, lr=1e-5, step_loss=0.252]07/18/2023 19:05:15 - INFO - __main__ - train loss is 10.663202362833545\n",
      "Steps:   2%|    | 251/15000 [01:53<44:23,  5.54it/s, lr=1e-5, step_loss=0.00718]07/18/2023 19:05:15 - INFO - __main__ - train loss is 10.737883108435199\n",
      "Steps:   2%|     | 252/15000 [01:53<44:22,  5.54it/s, lr=1e-5, step_loss=0.0747]07/18/2023 19:05:15 - INFO - __main__ - train loss is 11.308822887716815\n",
      "Steps:   2%|      | 253/15000 [01:53<44:20,  5.54it/s, lr=1e-5, step_loss=0.571]07/18/2023 19:05:16 - INFO - __main__ - train loss is 11.502665447769687\n",
      "Steps:   2%|      | 254/15000 [01:53<44:19,  5.54it/s, lr=1e-5, step_loss=0.194]07/18/2023 19:05:16 - INFO - __main__ - train loss is 11.919649350224063\n",
      "Steps:   2%|      | 255/15000 [01:54<44:19,  5.54it/s, lr=1e-5, step_loss=0.417]07/18/2023 19:05:16 - INFO - __main__ - train loss is 11.927928977413103\n",
      "Steps:   2%|    | 256/15000 [01:54<44:19,  5.54it/s, lr=1e-5, step_loss=0.00828]07/18/2023 19:05:16 - INFO - __main__ - train loss is 11.964551501674578\n",
      "Steps:   2%|     | 257/15000 [01:54<44:18,  5.55it/s, lr=1e-5, step_loss=0.0366]07/18/2023 19:05:16 - INFO - __main__ - train loss is 12.193446331424639\n",
      "Steps:   2%|      | 258/15000 [01:54<44:16,  5.55it/s, lr=1e-5, step_loss=0.229]07/18/2023 19:05:16 - INFO - __main__ - train loss is 12.207532559288666\n",
      "Steps:   2%|     | 259/15000 [01:54<44:15,  5.55it/s, lr=1e-5, step_loss=0.0141]07/18/2023 19:05:17 - INFO - __main__ - train loss is 12.22902086819522\n",
      "Steps:   2%|     | 260/15000 [01:55<44:13,  5.55it/s, lr=1e-5, step_loss=0.0215]07/18/2023 19:05:17 - INFO - __main__ - train loss is 12.259313207818195\n",
      "Steps:   2%|     | 261/15000 [01:55<44:13,  5.55it/s, lr=1e-5, step_loss=0.0303]07/18/2023 19:05:17 - INFO - __main__ - train loss is 12.294136670185253\n",
      "Steps:   2%|     | 262/15000 [01:55<44:13,  5.56it/s, lr=1e-5, step_loss=0.0348]07/18/2023 19:05:17 - INFO - __main__ - train loss is 12.296628488460556\n",
      "Steps:   2%|    | 263/15000 [01:55<44:12,  5.56it/s, lr=1e-5, step_loss=0.00249]07/18/2023 19:05:17 - INFO - __main__ - train loss is 12.3370254507754\n",
      "Steps:   2%|     | 264/15000 [01:55<44:12,  5.56it/s, lr=1e-5, step_loss=0.0404]07/18/2023 19:05:18 - INFO - __main__ - train loss is 12.355661161476746\n",
      "Steps:   2%|     | 265/15000 [01:55<44:19,  5.54it/s, lr=1e-5, step_loss=0.0186]07/18/2023 19:05:18 - INFO - __main__ - train loss is 12.358579026535153\n",
      "Steps:   2%|    | 266/15000 [01:56<44:17,  5.54it/s, lr=1e-5, step_loss=0.00292]07/18/2023 19:05:18 - INFO - __main__ - train loss is 12.49237816222012\n",
      "Steps:   2%|      | 267/15000 [01:56<44:16,  5.55it/s, lr=1e-5, step_loss=0.134]07/18/2023 19:05:18 - INFO - __main__ - train loss is 12.662563489750028\n",
      "Steps:   2%|▏      | 268/15000 [01:56<44:15,  5.55it/s, lr=1e-5, step_loss=0.17]07/18/2023 19:05:18 - INFO - __main__ - train loss is 12.732180276885629\n",
      "Steps:   2%|     | 269/15000 [01:56<44:16,  5.55it/s, lr=1e-5, step_loss=0.0696]07/18/2023 19:05:18 - INFO - __main__ - train loss is 13.06493411399424\n",
      "Steps:   2%|      | 270/15000 [01:56<44:18,  5.54it/s, lr=1e-5, step_loss=0.333]07/18/2023 19:05:19 - INFO - __main__ - train loss is 13.173841396346688\n",
      "Steps:   2%|      | 271/15000 [01:57<44:17,  5.54it/s, lr=1e-5, step_loss=0.109]07/18/2023 19:05:19 - INFO - __main__ - train loss is 13.185864385217428\n",
      "Steps:   2%|      | 272/15000 [01:57<44:18,  5.54it/s, lr=1e-5, step_loss=0.012]07/18/2023 19:05:19 - INFO - __main__ - train loss is 13.206976398825645\n",
      "Steps:   2%|     | 273/15000 [01:57<44:17,  5.54it/s, lr=1e-5, step_loss=0.0211]07/18/2023 19:05:19 - INFO - __main__ - train loss is 13.373525634407997\n",
      "Steps:   2%|      | 274/15000 [01:57<44:15,  5.55it/s, lr=1e-5, step_loss=0.167]07/18/2023 19:05:19 - INFO - __main__ - train loss is 13.378540691453964\n",
      "Steps:   2%|    | 275/15000 [01:57<44:01,  5.57it/s, lr=1e-5, step_loss=0.00502]07/18/2023 19:05:20 - INFO - __main__ - train loss is 13.385383774060756\n",
      "Steps:   2%|    | 276/15000 [01:57<43:50,  5.60it/s, lr=1e-5, step_loss=0.00684]07/18/2023 19:05:20 - INFO - __main__ - train loss is 13.616941158194095\n",
      "Steps:   2%|      | 277/15000 [01:58<43:45,  5.61it/s, lr=1e-5, step_loss=0.232]07/18/2023 19:05:20 - INFO - __main__ - train loss is 14.054269407410175\n",
      "Steps:   2%|      | 278/15000 [01:58<43:41,  5.62it/s, lr=1e-5, step_loss=0.437]07/18/2023 19:05:20 - INFO - __main__ - train loss is 14.056974929757416\n",
      "Steps:   2%|    | 279/15000 [01:58<43:38,  5.62it/s, lr=1e-5, step_loss=0.00271]07/18/2023 19:05:20 - INFO - __main__ - train loss is 14.145923887379467\n",
      "Steps:   2%|     | 280/15000 [01:58<43:38,  5.62it/s, lr=1e-5, step_loss=0.0889]07/18/2023 19:05:20 - INFO - __main__ - train loss is 14.320230518467724\n",
      "Steps:   2%|      | 281/15000 [01:58<43:49,  5.60it/s, lr=1e-5, step_loss=0.174]07/18/2023 19:05:21 - INFO - __main__ - train loss is 14.460446541197598\n",
      "Steps:   2%|▏      | 282/15000 [01:58<43:46,  5.60it/s, lr=1e-5, step_loss=0.14]07/18/2023 19:05:21 - INFO - __main__ - train loss is 14.550667603500187\n",
      "Steps:   2%|     | 283/15000 [01:59<43:44,  5.61it/s, lr=1e-5, step_loss=0.0902]07/18/2023 19:05:21 - INFO - __main__ - train loss is 14.558679910376668\n",
      "Steps:   2%|    | 284/15000 [01:59<43:42,  5.61it/s, lr=1e-5, step_loss=0.00801]07/18/2023 19:05:21 - INFO - __main__ - train loss is 14.819093139842153\n",
      "Steps:   2%|▏      | 285/15000 [01:59<43:40,  5.62it/s, lr=1e-5, step_loss=0.26]07/18/2023 19:05:21 - INFO - __main__ - train loss is 14.862168414518237\n",
      "Steps:   2%|     | 286/15000 [01:59<43:36,  5.62it/s, lr=1e-5, step_loss=0.0431]07/18/2023 19:05:21 - INFO - __main__ - train loss is 14.964415116235614\n",
      "Steps:   2%|      | 287/15000 [01:59<43:35,  5.63it/s, lr=1e-5, step_loss=0.102]07/18/2023 19:05:22 - INFO - __main__ - train loss is 15.000525055453181\n",
      "Steps:   2%|     | 288/15000 [02:00<43:39,  5.62it/s, lr=1e-5, step_loss=0.0361]07/18/2023 19:05:22 - INFO - __main__ - train loss is 15.05508173070848\n",
      "Steps:   2%|     | 289/15000 [02:00<43:36,  5.62it/s, lr=1e-5, step_loss=0.0546]07/18/2023 19:05:22 - INFO - __main__ - train loss is 15.437277739867568\n",
      "Steps:   2%|      | 290/15000 [02:00<43:34,  5.63it/s, lr=1e-5, step_loss=0.382]07/18/2023 19:05:22 - INFO - __main__ - train loss is 15.448213305324316\n",
      "Steps:   2%|     | 291/15000 [02:00<58:04,  4.22it/s, lr=1e-5, step_loss=0.0109]07/18/2023 19:05:23 - INFO - __main__ - Per validation step average loss is 0.0019574176985770464\n",
      "07/18/2023 19:05:23 - INFO - __main__ - Cumulative validation average loss is 0.0019574176985770464\n",
      "07/18/2023 19:05:23 - INFO - __main__ - Per validation step average loss is 0.03579600155353546\n",
      "07/18/2023 19:05:23 - INFO - __main__ - Cumulative validation average loss is 0.03775341925211251\n",
      "07/18/2023 19:05:23 - INFO - __main__ - Per validation step average loss is 0.4941328763961792\n",
      "07/18/2023 19:05:23 - INFO - __main__ - Cumulative validation average loss is 0.5318862956482917\n",
      "07/18/2023 19:05:23 - INFO - __main__ - Per validation step average loss is 0.20715439319610596\n",
      "07/18/2023 19:05:23 - INFO - __main__ - Cumulative validation average loss is 0.7390406888443977\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Per validation step average loss is 0.16261716187000275\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Cumulative validation average loss is 0.9016578507144004\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Per validation step average loss is 0.13006338477134705\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Cumulative validation average loss is 1.0317212354857475\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Per validation step average loss is 0.4085446000099182\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Cumulative validation average loss is 1.4402658354956657\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Per validation step average loss is 0.2953406572341919\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Cumulative validation average loss is 1.7356064927298576\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Per validation step average loss is 0.005210577044636011\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Cumulative validation average loss is 1.7408170697744936\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Per validation step average loss is 0.15242135524749756\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Cumulative validation average loss is 1.8932384250219911\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Per validation step average loss is 0.10830284655094147\n",
      "07/18/2023 19:05:24 - INFO - __main__ - Cumulative validation average loss is 2.0015412715729326\n",
      "07/18/2023 19:05:25 - INFO - __main__ - Per validation step average loss is 0.19888973236083984\n",
      "07/18/2023 19:05:25 - INFO - __main__ - Cumulative validation average loss is 2.2004310039337724\n",
      "07/18/2023 19:05:25 - INFO - __main__ - Average validation loss for Epoch 2 is 0.18336925032781437\n",
      "07/18/2023 19:05:25 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:05:37 - INFO - __main__ - Starting epoch 3\n",
      "07/18/2023 19:05:38 - INFO - __main__ - train loss is 0.0656760185956955\n",
      "Steps:   2%|  | 292/15000 [02:16<19:48:18,  4.85s/it, lr=1e-5, step_loss=0.0657]07/18/2023 19:05:38 - INFO - __main__ - train loss is 0.4963366538286209\n",
      "Steps:   2%|   | 293/15000 [02:16<14:05:16,  3.45s/it, lr=1e-5, step_loss=0.431]07/18/2023 19:05:38 - INFO - __main__ - train loss is 0.7035101801156998\n",
      "Steps:   2%|   | 294/15000 [02:16<10:04:40,  2.47s/it, lr=1e-5, step_loss=0.207]07/18/2023 19:05:39 - INFO - __main__ - train loss is 0.9252316355705261\n",
      "Steps:   2%|    | 295/15000 [02:16<7:16:25,  1.78s/it, lr=1e-5, step_loss=0.222]07/18/2023 19:05:39 - INFO - __main__ - train loss is 1.1274387538433075\n",
      "Steps:   2%|    | 296/15000 [02:17<5:18:43,  1.30s/it, lr=1e-5, step_loss=0.202]07/18/2023 19:05:39 - INFO - __main__ - train loss is 1.1676609814167023\n",
      "Steps:   2%|   | 297/15000 [02:17<3:56:21,  1.04it/s, lr=1e-5, step_loss=0.0402]07/18/2023 19:05:39 - INFO - __main__ - train loss is 1.1786162089556456\n",
      "Steps:   2%|    | 298/15000 [02:17<2:58:40,  1.37it/s, lr=1e-5, step_loss=0.011]07/18/2023 19:05:39 - INFO - __main__ - train loss is 1.1843305244110525\n",
      "Steps:   2%|  | 299/15000 [02:17<2:18:09,  1.77it/s, lr=1e-5, step_loss=0.00571]07/18/2023 19:05:39 - INFO - __main__ - train loss is 1.3672648980282247\n",
      "Steps:   2%|    | 300/15000 [02:17<1:49:44,  2.23it/s, lr=1e-5, step_loss=0.183]07/18/2023 19:05:40 - INFO - __main__ - train loss is 1.996752472128719\n",
      "Steps:   2%|    | 301/15000 [02:17<1:29:51,  2.73it/s, lr=1e-5, step_loss=0.629]07/18/2023 19:05:40 - INFO - __main__ - train loss is 2.4984541251324117\n",
      "Steps:   2%|    | 302/15000 [02:18<1:16:04,  3.22it/s, lr=1e-5, step_loss=0.502]07/18/2023 19:05:40 - INFO - __main__ - train loss is 2.5618903948925436\n",
      "Steps:   2%|   | 303/15000 [02:18<1:06:16,  3.70it/s, lr=1e-5, step_loss=0.0634]07/18/2023 19:05:40 - INFO - __main__ - train loss is 2.8686228706501424\n",
      "Steps:   2%|      | 304/15000 [02:18<59:25,  4.12it/s, lr=1e-5, step_loss=0.307]07/18/2023 19:05:40 - INFO - __main__ - train loss is 3.1960262372158468\n",
      "Steps:   2%|      | 305/15000 [02:18<54:37,  4.48it/s, lr=1e-5, step_loss=0.327]07/18/2023 19:05:41 - INFO - __main__ - train loss is 3.296818563248962\n",
      "Steps:   2%|      | 306/15000 [02:18<51:36,  4.74it/s, lr=1e-5, step_loss=0.101]07/18/2023 19:05:41 - INFO - __main__ - train loss is 3.416121387388557\n",
      "Steps:   2%|      | 307/15000 [02:19<49:32,  4.94it/s, lr=1e-5, step_loss=0.119]07/18/2023 19:05:41 - INFO - __main__ - train loss is 3.9018224119208753\n",
      "Steps:   2%|      | 308/15000 [02:19<47:44,  5.13it/s, lr=1e-5, step_loss=0.486]07/18/2023 19:05:41 - INFO - __main__ - train loss is 3.9358941703103483\n",
      "Steps:   2%|     | 309/15000 [02:19<46:28,  5.27it/s, lr=1e-5, step_loss=0.0341]07/18/2023 19:05:41 - INFO - __main__ - train loss is 4.540683308150619\n",
      "Steps:   2%|      | 310/15000 [02:19<45:48,  5.34it/s, lr=1e-5, step_loss=0.605]07/18/2023 19:05:41 - INFO - __main__ - train loss is 4.56330988323316\n",
      "Steps:   2%|     | 311/15000 [02:19<45:07,  5.43it/s, lr=1e-5, step_loss=0.0226]07/18/2023 19:05:42 - INFO - __main__ - train loss is 4.628704672213644\n",
      "Steps:   2%|     | 312/15000 [02:19<44:37,  5.49it/s, lr=1e-5, step_loss=0.0654]07/18/2023 19:05:42 - INFO - __main__ - train loss is 4.922101204749197\n",
      "Steps:   2%|▏     | 313/15000 [02:20<44:18,  5.52it/s, lr=1e-5, step_loss=0.293]07/18/2023 19:05:42 - INFO - __main__ - train loss is 4.957843826618046\n",
      "Steps:   2%|     | 314/15000 [02:20<44:04,  5.55it/s, lr=1e-5, step_loss=0.0357]07/18/2023 19:05:42 - INFO - __main__ - train loss is 5.49788044532761\n",
      "Steps:   2%|▏      | 315/15000 [02:20<43:53,  5.58it/s, lr=1e-5, step_loss=0.54]07/18/2023 19:05:42 - INFO - __main__ - train loss is 5.737537445034832\n",
      "Steps:   2%|▏      | 316/15000 [02:20<43:45,  5.59it/s, lr=1e-5, step_loss=0.24]07/18/2023 19:05:42 - INFO - __main__ - train loss is 5.918825910892338\n",
      "Steps:   2%|▏     | 317/15000 [02:20<43:41,  5.60it/s, lr=1e-5, step_loss=0.181]07/18/2023 19:05:43 - INFO - __main__ - train loss is 5.931623502168804\n",
      "Steps:   2%|     | 318/15000 [02:21<43:38,  5.61it/s, lr=1e-5, step_loss=0.0128]07/18/2023 19:05:43 - INFO - __main__ - train loss is 6.298425062093884\n",
      "Steps:   2%|▏     | 319/15000 [02:21<43:39,  5.60it/s, lr=1e-5, step_loss=0.367]07/18/2023 19:05:43 - INFO - __main__ - train loss is 6.301250820048153\n",
      "Steps:   2%|    | 320/15000 [02:21<43:34,  5.61it/s, lr=1e-5, step_loss=0.00283]07/18/2023 19:05:43 - INFO - __main__ - train loss is 6.435955171473324\n",
      "Steps:   2%|▏     | 321/15000 [02:21<43:31,  5.62it/s, lr=1e-5, step_loss=0.135]07/18/2023 19:05:43 - INFO - __main__ - train loss is 6.44550955016166\n",
      "Steps:   2%|    | 322/15000 [02:21<43:33,  5.62it/s, lr=1e-5, step_loss=0.00955]07/18/2023 19:05:44 - INFO - __main__ - train loss is 6.464093902148306\n",
      "Steps:   2%|     | 323/15000 [02:21<43:33,  5.62it/s, lr=1e-5, step_loss=0.0186]07/18/2023 19:05:44 - INFO - __main__ - train loss is 7.0938625717535615\n",
      "Steps:   2%|▏      | 324/15000 [02:22<43:31,  5.62it/s, lr=1e-5, step_loss=0.63]07/18/2023 19:05:44 - INFO - __main__ - train loss is 7.120999542064965\n",
      "Steps:   2%|     | 325/15000 [02:22<43:31,  5.62it/s, lr=1e-5, step_loss=0.0271]07/18/2023 19:05:44 - INFO - __main__ - train loss is 7.124723233282566\n",
      "Steps:   2%|    | 326/15000 [02:22<43:30,  5.62it/s, lr=1e-5, step_loss=0.00372]07/18/2023 19:05:44 - INFO - __main__ - train loss is 7.1543715707957745\n",
      "Steps:   2%|     | 327/15000 [02:22<43:30,  5.62it/s, lr=1e-5, step_loss=0.0296]07/18/2023 19:05:44 - INFO - __main__ - train loss is 7.202207241207361\n",
      "Steps:   2%|     | 328/15000 [02:22<43:42,  5.59it/s, lr=1e-5, step_loss=0.0478]07/18/2023 19:05:45 - INFO - __main__ - train loss is 7.220652438700199\n",
      "Steps:   2%|     | 329/15000 [02:22<43:38,  5.60it/s, lr=1e-5, step_loss=0.0184]07/18/2023 19:05:45 - INFO - __main__ - train loss is 7.305408641695976\n",
      "Steps:   2%|     | 330/15000 [02:23<43:35,  5.61it/s, lr=1e-5, step_loss=0.0848]07/18/2023 19:05:45 - INFO - __main__ - train loss is 7.479259222745895\n",
      "Steps:   2%|▏     | 331/15000 [02:23<43:34,  5.61it/s, lr=1e-5, step_loss=0.174]07/18/2023 19:05:45 - INFO - __main__ - train loss is 7.756566643714905\n",
      "Steps:   2%|▏     | 332/15000 [02:23<43:31,  5.62it/s, lr=1e-5, step_loss=0.277]07/18/2023 19:05:45 - INFO - __main__ - train loss is 8.145885825157166\n",
      "Steps:   2%|▏     | 333/15000 [02:23<43:31,  5.62it/s, lr=1e-5, step_loss=0.389]07/18/2023 19:05:45 - INFO - __main__ - train loss is 8.187767058610916\n",
      "Steps:   2%|     | 334/15000 [02:23<43:31,  5.62it/s, lr=1e-5, step_loss=0.0419]07/18/2023 19:05:46 - INFO - __main__ - train loss is 8.203260404989123\n",
      "Steps:   2%|     | 335/15000 [02:24<43:30,  5.62it/s, lr=1e-5, step_loss=0.0155]07/18/2023 19:05:46 - INFO - __main__ - train loss is 8.610595954582095\n",
      "Steps:   2%|▏     | 336/15000 [02:24<43:29,  5.62it/s, lr=1e-5, step_loss=0.407]07/18/2023 19:05:46 - INFO - __main__ - train loss is 8.620733321644366\n",
      "Steps:   2%|     | 337/15000 [02:24<43:33,  5.61it/s, lr=1e-5, step_loss=0.0101]07/18/2023 19:05:46 - INFO - __main__ - train loss is 8.925817997194827\n",
      "Steps:   2%|▏     | 338/15000 [02:24<43:32,  5.61it/s, lr=1e-5, step_loss=0.305]07/18/2023 19:05:46 - INFO - __main__ - train loss is 9.270240635611117\n",
      "Steps:   2%|▏     | 339/15000 [02:24<43:31,  5.61it/s, lr=1e-5, step_loss=0.344]07/18/2023 19:05:47 - INFO - __main__ - train loss is 9.63126000855118\n",
      "Steps:   2%|▏     | 340/15000 [02:24<43:31,  5.61it/s, lr=1e-5, step_loss=0.361]07/18/2023 19:05:47 - INFO - __main__ - train loss is 9.867827952839434\n",
      "Steps:   2%|▏     | 341/15000 [02:25<43:29,  5.62it/s, lr=1e-5, step_loss=0.237]07/18/2023 19:05:47 - INFO - __main__ - train loss is 9.983645522035658\n",
      "Steps:   2%|▏     | 342/15000 [02:25<43:32,  5.61it/s, lr=1e-5, step_loss=0.116]07/18/2023 19:05:47 - INFO - __main__ - train loss is 10.08057799283415\n",
      "Steps:   2%|     | 343/15000 [02:25<43:29,  5.62it/s, lr=1e-5, step_loss=0.0969]07/18/2023 19:05:47 - INFO - __main__ - train loss is 10.520122193731368\n",
      "Steps:   2%|▏      | 344/15000 [02:25<43:28,  5.62it/s, lr=1e-5, step_loss=0.44]07/18/2023 19:05:47 - INFO - __main__ - train loss is 10.545879648067057\n",
      "Steps:   2%|     | 345/15000 [02:25<43:32,  5.61it/s, lr=1e-5, step_loss=0.0258]07/18/2023 19:05:48 - INFO - __main__ - train loss is 10.554748062044382\n",
      "Steps:   2%|    | 346/15000 [02:26<43:30,  5.61it/s, lr=1e-5, step_loss=0.00887]07/18/2023 19:05:48 - INFO - __main__ - train loss is 10.867815617471933\n",
      "Steps:   2%|▏     | 347/15000 [02:26<43:30,  5.61it/s, lr=1e-5, step_loss=0.313]07/18/2023 19:05:48 - INFO - __main__ - train loss is 10.872911903075874\n",
      "Steps:   2%|     | 348/15000 [02:26<43:27,  5.62it/s, lr=1e-5, step_loss=0.0051]07/18/2023 19:05:48 - INFO - __main__ - train loss is 11.213287803344429\n",
      "Steps:   2%|▏      | 349/15000 [02:26<43:27,  5.62it/s, lr=1e-5, step_loss=0.34]07/18/2023 19:05:48 - INFO - __main__ - train loss is 11.21772185806185\n",
      "Steps:   2%|    | 350/15000 [02:26<43:27,  5.62it/s, lr=1e-5, step_loss=0.00443]07/18/2023 19:05:49 - INFO - __main__ - train loss is 11.39797502104193\n",
      "Steps:   2%|▏      | 351/15000 [02:26<43:26,  5.62it/s, lr=1e-5, step_loss=0.18]07/18/2023 19:05:49 - INFO - __main__ - train loss is 11.41948155220598\n",
      "Steps:   2%|     | 352/15000 [02:27<43:24,  5.62it/s, lr=1e-5, step_loss=0.0215]07/18/2023 19:05:49 - INFO - __main__ - train loss is 11.422258750069886\n",
      "Steps:   2%|    | 353/15000 [02:27<43:26,  5.62it/s, lr=1e-5, step_loss=0.00278]07/18/2023 19:05:49 - INFO - __main__ - train loss is 11.658381030429155\n",
      "Steps:   2%|▏     | 354/15000 [02:27<43:27,  5.62it/s, lr=1e-5, step_loss=0.236]07/18/2023 19:05:49 - INFO - __main__ - train loss is 11.949861988890916\n",
      "Steps:   2%|▏     | 355/15000 [02:27<43:27,  5.62it/s, lr=1e-5, step_loss=0.291]07/18/2023 19:05:49 - INFO - __main__ - train loss is 11.952176262857392\n",
      "Steps:   2%|    | 356/15000 [02:27<43:27,  5.62it/s, lr=1e-5, step_loss=0.00231]07/18/2023 19:05:50 - INFO - __main__ - train loss is 11.958448812598363\n",
      "Steps:   2%|    | 357/15000 [02:27<43:25,  5.62it/s, lr=1e-5, step_loss=0.00627]07/18/2023 19:05:50 - INFO - __main__ - train loss is 11.964170774677768\n",
      "Steps:   2%|    | 358/15000 [02:28<43:50,  5.57it/s, lr=1e-5, step_loss=0.00572]07/18/2023 19:05:50 - INFO - __main__ - train loss is 11.981547380099073\n",
      "Steps:   2%|     | 359/15000 [02:28<44:16,  5.51it/s, lr=1e-5, step_loss=0.0174]07/18/2023 19:05:50 - INFO - __main__ - train loss is 11.985252448823303\n",
      "Steps:   2%|    | 360/15000 [02:28<44:02,  5.54it/s, lr=1e-5, step_loss=0.00371]07/18/2023 19:05:50 - INFO - __main__ - train loss is 12.160524570848793\n",
      "Steps:   2%|▏     | 361/15000 [02:28<43:50,  5.57it/s, lr=1e-5, step_loss=0.175]07/18/2023 19:05:50 - INFO - __main__ - train loss is 12.513656639959663\n",
      "Steps:   2%|▏     | 362/15000 [02:28<43:43,  5.58it/s, lr=1e-5, step_loss=0.353]07/18/2023 19:05:51 - INFO - __main__ - train loss is 12.576749117579311\n",
      "Steps:   2%|     | 363/15000 [02:29<43:36,  5.59it/s, lr=1e-5, step_loss=0.0631]07/18/2023 19:05:51 - INFO - __main__ - train loss is 12.596559220459312\n",
      "Steps:   2%|     | 364/15000 [02:29<43:31,  5.60it/s, lr=1e-5, step_loss=0.0198]07/18/2023 19:05:51 - INFO - __main__ - train loss is 12.599694442935288\n",
      "Steps:   2%|    | 365/15000 [02:29<43:29,  5.61it/s, lr=1e-5, step_loss=0.00314]07/18/2023 19:05:51 - INFO - __main__ - train loss is 12.628064175136387\n",
      "Steps:   2%|     | 366/15000 [02:29<43:26,  5.61it/s, lr=1e-5, step_loss=0.0284]07/18/2023 19:05:51 - INFO - __main__ - train loss is 12.798747559078038\n",
      "Steps:   2%|▏     | 367/15000 [02:29<43:26,  5.61it/s, lr=1e-5, step_loss=0.171]07/18/2023 19:05:52 - INFO - __main__ - train loss is 12.804993790574372\n",
      "Steps:   2%|    | 368/15000 [02:29<43:45,  5.57it/s, lr=1e-5, step_loss=0.00625]07/18/2023 19:05:52 - INFO - __main__ - train loss is 12.865737033076584\n",
      "Steps:   2%|     | 369/15000 [02:30<44:01,  5.54it/s, lr=1e-5, step_loss=0.0607]07/18/2023 19:05:52 - INFO - __main__ - train loss is 12.894317547790706\n",
      "Steps:   2%|     | 370/15000 [02:30<44:23,  5.49it/s, lr=1e-5, step_loss=0.0286]07/18/2023 19:05:52 - INFO - __main__ - train loss is 12.977423283271492\n",
      "Steps:   2%|     | 371/15000 [02:30<44:05,  5.53it/s, lr=1e-5, step_loss=0.0831]07/18/2023 19:05:52 - INFO - __main__ - train loss is 12.983356126118451\n",
      "Steps:   2%|    | 372/15000 [02:30<44:08,  5.52it/s, lr=1e-5, step_loss=0.00593]07/18/2023 19:05:52 - INFO - __main__ - train loss is 12.997137407306582\n",
      "Steps:   2%|     | 373/15000 [02:30<44:03,  5.53it/s, lr=1e-5, step_loss=0.0138]07/18/2023 19:05:53 - INFO - __main__ - train loss is 13.014770474750549\n",
      "Steps:   2%|     | 374/15000 [02:31<43:49,  5.56it/s, lr=1e-5, step_loss=0.0176]07/18/2023 19:05:53 - INFO - __main__ - train loss is 13.41209700377658\n",
      "Steps:   2%|▏     | 375/15000 [02:31<43:41,  5.58it/s, lr=1e-5, step_loss=0.397]07/18/2023 19:05:53 - INFO - __main__ - train loss is 13.706437018234283\n",
      "Steps:   3%|▏     | 376/15000 [02:31<43:36,  5.59it/s, lr=1e-5, step_loss=0.294]07/18/2023 19:05:53 - INFO - __main__ - train loss is 13.882879402954131\n",
      "Steps:   3%|▏     | 377/15000 [02:31<43:31,  5.60it/s, lr=1e-5, step_loss=0.176]07/18/2023 19:05:53 - INFO - __main__ - train loss is 14.062358867842704\n",
      "Steps:   3%|▏     | 378/15000 [02:31<43:27,  5.61it/s, lr=1e-5, step_loss=0.179]07/18/2023 19:05:54 - INFO - __main__ - train loss is 14.304880094248801\n",
      "Steps:   3%|▏     | 379/15000 [02:31<43:39,  5.58it/s, lr=1e-5, step_loss=0.243]07/18/2023 19:05:54 - INFO - __main__ - train loss is 14.512238037306815\n",
      "Steps:   3%|▏     | 380/15000 [02:32<43:36,  5.59it/s, lr=1e-5, step_loss=0.207]07/18/2023 19:05:54 - INFO - __main__ - train loss is 14.90413148375228\n",
      "Steps:   3%|▏     | 381/15000 [02:32<43:32,  5.60it/s, lr=1e-5, step_loss=0.392]07/18/2023 19:05:54 - INFO - __main__ - train loss is 15.143164914567024\n",
      "Steps:   3%|▏     | 382/15000 [02:32<43:27,  5.61it/s, lr=1e-5, step_loss=0.239]07/18/2023 19:05:54 - INFO - __main__ - train loss is 15.207959417719394\n",
      "Steps:   3%|▏    | 383/15000 [02:32<43:30,  5.60it/s, lr=1e-5, step_loss=0.0648]07/18/2023 19:05:54 - INFO - __main__ - train loss is 15.426143680233508\n",
      "Steps:   3%|▏     | 384/15000 [02:32<43:25,  5.61it/s, lr=1e-5, step_loss=0.218]07/18/2023 19:05:55 - INFO - __main__ - train loss is 15.491073448676616\n",
      "Steps:   3%|▏    | 385/15000 [02:33<43:22,  5.62it/s, lr=1e-5, step_loss=0.0649]07/18/2023 19:05:55 - INFO - __main__ - train loss is 15.541006025392562\n",
      "Steps:   3%|▏    | 386/15000 [02:33<43:19,  5.62it/s, lr=1e-5, step_loss=0.0499]07/18/2023 19:05:55 - INFO - __main__ - train loss is 15.56463490659371\n",
      "Steps:   3%|▏    | 387/15000 [02:33<43:18,  5.62it/s, lr=1e-5, step_loss=0.0236]07/18/2023 19:05:55 - INFO - __main__ - train loss is 15.966791855636984\n",
      "Steps:   3%|▏     | 388/15000 [02:33<58:10,  4.19it/s, lr=1e-5, step_loss=0.402]07/18/2023 19:05:56 - INFO - __main__ - Per validation step average loss is 0.05774053931236267\n",
      "07/18/2023 19:05:56 - INFO - __main__ - Cumulative validation average loss is 0.05774053931236267\n",
      "07/18/2023 19:05:56 - INFO - __main__ - Per validation step average loss is 0.0016980234067887068\n",
      "07/18/2023 19:05:56 - INFO - __main__ - Cumulative validation average loss is 0.05943856271915138\n",
      "07/18/2023 19:05:56 - INFO - __main__ - Per validation step average loss is 0.14419174194335938\n",
      "07/18/2023 19:05:56 - INFO - __main__ - Cumulative validation average loss is 0.20363030466251075\n",
      "07/18/2023 19:05:56 - INFO - __main__ - Per validation step average loss is 0.012123774737119675\n",
      "07/18/2023 19:05:56 - INFO - __main__ - Cumulative validation average loss is 0.21575407939963043\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.29053640365600586\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 0.5062904830556363\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.09291104227304459\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 0.5992015253286809\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.045229289680719376\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 0.6444308150094002\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.5136795043945312\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 1.1581103194039315\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.05056685954332352\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 1.208677178947255\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.020514072850346565\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 1.2291912517976016\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Per validation step average loss is 0.0063870567828416824\n",
      "07/18/2023 19:05:57 - INFO - __main__ - Cumulative validation average loss is 1.2355783085804433\n",
      "07/18/2023 19:05:58 - INFO - __main__ - Per validation step average loss is 0.008451869711279869\n",
      "07/18/2023 19:05:58 - INFO - __main__ - Cumulative validation average loss is 1.2440301782917231\n",
      "07/18/2023 19:05:58 - INFO - __main__ - Average validation loss for Epoch 3 is 0.10366918152431026\n",
      "07/18/2023 19:05:58 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:06:10 - INFO - __main__ - Starting epoch 4\n",
      "07/18/2023 19:06:11 - INFO - __main__ - train loss is 0.18115046620368958\n",
      "Steps:   3%|   | 389/15000 [02:49<19:36:00,  4.83s/it, lr=1e-5, step_loss=0.181]07/18/2023 19:06:11 - INFO - __main__ - train loss is 0.5118287205696106\n",
      "Steps:   3%|   | 390/15000 [02:49<13:57:18,  3.44s/it, lr=1e-5, step_loss=0.331]07/18/2023 19:06:11 - INFO - __main__ - train loss is 0.8739272952079773\n",
      "Steps:   3%|    | 391/15000 [02:49<9:59:58,  2.46s/it, lr=1e-5, step_loss=0.362]07/18/2023 19:06:11 - INFO - __main__ - train loss is 1.0365175008773804\n",
      "Steps:   3%|    | 392/15000 [02:49<7:13:44,  1.78s/it, lr=1e-5, step_loss=0.163]07/18/2023 19:06:12 - INFO - __main__ - train loss is 1.6880167722702026\n",
      "Steps:   3%|    | 393/15000 [02:50<5:16:47,  1.30s/it, lr=1e-5, step_loss=0.651]07/18/2023 19:06:12 - INFO - __main__ - train loss is 1.7145157251507044\n",
      "Steps:   3%|   | 394/15000 [02:50<3:54:46,  1.04it/s, lr=1e-5, step_loss=0.0265]07/18/2023 19:06:12 - INFO - __main__ - train loss is 1.8622342739254236\n",
      "Steps:   3%|    | 395/15000 [02:50<2:57:26,  1.37it/s, lr=1e-5, step_loss=0.148]07/18/2023 19:06:12 - INFO - __main__ - train loss is 2.4864830169826746\n",
      "Steps:   3%|    | 396/15000 [02:50<2:17:10,  1.77it/s, lr=1e-5, step_loss=0.624]07/18/2023 19:06:12 - INFO - __main__ - train loss is 2.524472748860717\n",
      "Steps:   3%|    | 397/15000 [02:50<1:49:00,  2.23it/s, lr=1e-5, step_loss=0.038]07/18/2023 19:06:13 - INFO - __main__ - train loss is 2.741655981168151\n",
      "Steps:   3%|    | 398/15000 [02:50<1:29:16,  2.73it/s, lr=1e-5, step_loss=0.217]07/18/2023 19:06:13 - INFO - __main__ - train loss is 2.743706743698567\n",
      "Steps:   3%|  | 399/15000 [02:51<1:15:29,  3.22it/s, lr=1e-5, step_loss=0.00205]07/18/2023 19:06:13 - INFO - __main__ - train loss is 2.929228852968663\n",
      "Steps:   3%|    | 400/15000 [02:51<1:05:48,  3.70it/s, lr=1e-5, step_loss=0.186]07/18/2023 19:06:13 - INFO - __main__ - train loss is 3.0665058749727905\n",
      "Steps:   3%|▏     | 401/15000 [02:51<59:11,  4.11it/s, lr=1e-5, step_loss=0.137]07/18/2023 19:06:13 - INFO - __main__ - train loss is 3.1244319113902748\n",
      "Steps:   3%|▏    | 402/15000 [02:51<54:20,  4.48it/s, lr=1e-5, step_loss=0.0579]07/18/2023 19:06:13 - INFO - __main__ - train loss is 3.413292172830552\n",
      "Steps:   3%|▏     | 403/15000 [02:51<51:02,  4.77it/s, lr=1e-5, step_loss=0.289]07/18/2023 19:06:14 - INFO - __main__ - train loss is 3.5609314325265586\n",
      "Steps:   3%|▏     | 404/15000 [02:51<48:40,  5.00it/s, lr=1e-5, step_loss=0.148]07/18/2023 19:06:14 - INFO - __main__ - train loss is 3.5763271474279463\n",
      "Steps:   3%|▏    | 405/15000 [02:52<47:02,  5.17it/s, lr=1e-5, step_loss=0.0154]07/18/2023 19:06:14 - INFO - __main__ - train loss is 3.620853389147669\n",
      "Steps:   3%|▏    | 406/15000 [02:52<45:56,  5.29it/s, lr=1e-5, step_loss=0.0445]07/18/2023 19:06:14 - INFO - __main__ - train loss is 3.622917701024562\n",
      "Steps:   3%|    | 407/15000 [02:52<45:10,  5.38it/s, lr=1e-5, step_loss=0.00206]07/18/2023 19:06:14 - INFO - __main__ - train loss is 3.8381704431958497\n",
      "Steps:   3%|▏     | 408/15000 [02:52<44:38,  5.45it/s, lr=1e-5, step_loss=0.215]07/18/2023 19:06:14 - INFO - __main__ - train loss is 4.2953516584821045\n",
      "Steps:   3%|▏     | 409/15000 [02:52<44:13,  5.50it/s, lr=1e-5, step_loss=0.457]07/18/2023 19:06:15 - INFO - __main__ - train loss is 4.348307058680803\n",
      "Steps:   3%|▏     | 410/15000 [02:53<43:59,  5.53it/s, lr=1e-5, step_loss=0.053]07/18/2023 19:06:15 - INFO - __main__ - train loss is 4.424092978704721\n",
      "Steps:   3%|▏    | 411/15000 [02:53<43:50,  5.55it/s, lr=1e-5, step_loss=0.0758]07/18/2023 19:06:15 - INFO - __main__ - train loss is 4.642942637670785\n",
      "Steps:   3%|▏     | 412/15000 [02:53<43:41,  5.57it/s, lr=1e-5, step_loss=0.219]07/18/2023 19:06:15 - INFO - __main__ - train loss is 4.718396604526788\n",
      "Steps:   3%|▏    | 413/15000 [02:53<43:52,  5.54it/s, lr=1e-5, step_loss=0.0755]07/18/2023 19:06:15 - INFO - __main__ - train loss is 4.8570877318270504\n",
      "Steps:   3%|▏     | 414/15000 [02:53<43:39,  5.57it/s, lr=1e-5, step_loss=0.139]07/18/2023 19:06:16 - INFO - __main__ - train loss is 4.873826776165515\n",
      "Steps:   3%|▏    | 415/15000 [02:53<43:32,  5.58it/s, lr=1e-5, step_loss=0.0167]07/18/2023 19:06:16 - INFO - __main__ - train loss is 5.221676741261035\n",
      "Steps:   3%|▏     | 416/15000 [02:54<43:27,  5.59it/s, lr=1e-5, step_loss=0.348]07/18/2023 19:06:16 - INFO - __main__ - train loss is 5.5539765995927155\n",
      "Steps:   3%|▏     | 417/15000 [02:54<43:24,  5.60it/s, lr=1e-5, step_loss=0.332]07/18/2023 19:06:16 - INFO - __main__ - train loss is 5.617949787992984\n",
      "Steps:   3%|▏     | 418/15000 [02:54<43:22,  5.60it/s, lr=1e-5, step_loss=0.064]07/18/2023 19:06:16 - INFO - __main__ - train loss is 5.623463076539338\n",
      "Steps:   3%|    | 419/15000 [02:54<43:32,  5.58it/s, lr=1e-5, step_loss=0.00551]07/18/2023 19:06:16 - INFO - __main__ - train loss is 5.801776480861008\n",
      "Steps:   3%|▏     | 420/15000 [02:54<43:26,  5.59it/s, lr=1e-5, step_loss=0.178]07/18/2023 19:06:17 - INFO - __main__ - train loss is 6.027388376183808\n",
      "Steps:   3%|▏     | 421/15000 [02:55<43:22,  5.60it/s, lr=1e-5, step_loss=0.226]07/18/2023 19:06:17 - INFO - __main__ - train loss is 6.041126175783575\n",
      "Steps:   3%|▏    | 422/15000 [02:55<43:20,  5.61it/s, lr=1e-5, step_loss=0.0137]07/18/2023 19:06:17 - INFO - __main__ - train loss is 6.395602627657354\n",
      "Steps:   3%|▏     | 423/15000 [02:55<43:21,  5.60it/s, lr=1e-5, step_loss=0.354]07/18/2023 19:06:17 - INFO - __main__ - train loss is 6.598109810613096\n",
      "Steps:   3%|▏     | 424/15000 [02:55<43:40,  5.56it/s, lr=1e-5, step_loss=0.203]07/18/2023 19:06:17 - INFO - __main__ - train loss is 6.639739683829248\n",
      "Steps:   3%|▏    | 425/15000 [02:55<43:34,  5.57it/s, lr=1e-5, step_loss=0.0416]07/18/2023 19:06:18 - INFO - __main__ - train loss is 6.814101002179086\n",
      "Steps:   3%|▏     | 426/15000 [02:55<43:51,  5.54it/s, lr=1e-5, step_loss=0.174]07/18/2023 19:06:18 - INFO - __main__ - train loss is 6.817400809377432\n",
      "Steps:   3%|▏    | 427/15000 [02:56<43:43,  5.55it/s, lr=1e-5, step_loss=0.0033]07/18/2023 19:06:18 - INFO - __main__ - train loss is 6.890534300357103\n",
      "Steps:   3%|▏    | 428/15000 [02:56<43:36,  5.57it/s, lr=1e-5, step_loss=0.0731]07/18/2023 19:06:18 - INFO - __main__ - train loss is 7.525825936347246\n",
      "Steps:   3%|▏     | 429/15000 [02:56<43:33,  5.58it/s, lr=1e-5, step_loss=0.635]07/18/2023 19:06:18 - INFO - __main__ - train loss is 7.5826614536345005\n",
      "Steps:   3%|▏    | 430/15000 [02:56<43:29,  5.58it/s, lr=1e-5, step_loss=0.0568]07/18/2023 19:06:18 - INFO - __main__ - train loss is 7.902400318533182\n",
      "[2023-07-18 19:06:19,018] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:   3%|▏      | 431/15000 [02:56<43:10,  5.62it/s, lr=1e-5, step_loss=0.32]07/18/2023 19:06:19 - INFO - __main__ - train loss is 7.956040371209383\n",
      "Steps:   3%|▏    | 432/15000 [02:56<43:10,  5.62it/s, lr=1e-5, step_loss=0.0536]07/18/2023 19:06:19 - INFO - __main__ - train loss is 8.095720071345568\n",
      "Steps:   3%|▏      | 433/15000 [02:57<43:12,  5.62it/s, lr=1e-5, step_loss=0.14]07/18/2023 19:06:19 - INFO - __main__ - train loss is 8.104831381700933\n",
      "Steps:   3%|    | 434/15000 [02:57<43:25,  5.59it/s, lr=1e-5, step_loss=0.00911]07/18/2023 19:06:19 - INFO - __main__ - train loss is 8.110852592624724\n",
      "Steps:   3%|    | 435/15000 [02:57<43:23,  5.59it/s, lr=1e-5, step_loss=0.00602]07/18/2023 19:06:19 - INFO - __main__ - train loss is 8.117233325261623\n",
      "Steps:   3%|    | 436/15000 [02:57<43:18,  5.60it/s, lr=1e-5, step_loss=0.00638]07/18/2023 19:06:20 - INFO - __main__ - train loss is 8.124905353412032\n",
      "Steps:   3%|    | 437/15000 [02:57<43:34,  5.57it/s, lr=1e-5, step_loss=0.00767]07/18/2023 19:06:20 - INFO - __main__ - train loss is 8.49732873402536\n",
      "Steps:   3%|▏     | 438/15000 [02:58<43:29,  5.58it/s, lr=1e-5, step_loss=0.372]07/18/2023 19:06:20 - INFO - __main__ - train loss is 8.500102151185274\n",
      "Steps:   3%|    | 439/15000 [02:58<43:26,  5.59it/s, lr=1e-5, step_loss=0.00277]07/18/2023 19:06:20 - INFO - __main__ - train loss is 8.509273626841605\n",
      "Steps:   3%|    | 440/15000 [02:58<43:20,  5.60it/s, lr=1e-5, step_loss=0.00917]07/18/2023 19:06:20 - INFO - __main__ - train loss is 8.527455766685307\n",
      "Steps:   3%|▏    | 441/15000 [02:58<43:23,  5.59it/s, lr=1e-5, step_loss=0.0182]07/18/2023 19:06:20 - INFO - __main__ - train loss is 8.651955117471516\n",
      "Steps:   3%|▏     | 442/15000 [02:58<43:21,  5.60it/s, lr=1e-5, step_loss=0.124]07/18/2023 19:06:21 - INFO - __main__ - train loss is 8.657791678793728\n",
      "Steps:   3%|    | 443/15000 [02:58<43:18,  5.60it/s, lr=1e-5, step_loss=0.00584]07/18/2023 19:06:21 - INFO - __main__ - train loss is 8.661829467397183\n",
      "Steps:   3%|    | 444/15000 [02:59<43:16,  5.61it/s, lr=1e-5, step_loss=0.00404]07/18/2023 19:06:21 - INFO - __main__ - train loss is 8.930783833842725\n",
      "Steps:   3%|▏     | 445/15000 [02:59<43:14,  5.61it/s, lr=1e-5, step_loss=0.269]07/18/2023 19:06:21 - INFO - __main__ - train loss is 8.991177070420235\n",
      "Steps:   3%|▏    | 446/15000 [02:59<43:38,  5.56it/s, lr=1e-5, step_loss=0.0604]07/18/2023 19:06:21 - INFO - __main__ - train loss is 8.992650386178866\n",
      "Steps:   3%|    | 447/15000 [02:59<43:38,  5.56it/s, lr=1e-5, step_loss=0.00147]07/18/2023 19:06:21 - INFO - __main__ - train loss is 9.171077441656962\n",
      "Steps:   3%|▏     | 448/15000 [02:59<43:54,  5.52it/s, lr=1e-5, step_loss=0.178]07/18/2023 19:06:22 - INFO - __main__ - train loss is 9.527298819506541\n",
      "Steps:   3%|▏     | 449/15000 [03:00<43:44,  5.54it/s, lr=1e-5, step_loss=0.356]07/18/2023 19:06:22 - INFO - __main__ - train loss is 9.578329049283639\n",
      "Steps:   3%|▏     | 450/15000 [03:00<43:33,  5.57it/s, lr=1e-5, step_loss=0.051]07/18/2023 19:06:22 - INFO - __main__ - train loss is 9.61640913807787\n",
      "Steps:   3%|▏    | 451/15000 [03:00<43:27,  5.58it/s, lr=1e-5, step_loss=0.0381]07/18/2023 19:06:22 - INFO - __main__ - train loss is 9.618707395391539\n",
      "Steps:   3%|▏    | 452/15000 [03:00<43:23,  5.59it/s, lr=1e-5, step_loss=0.0023]07/18/2023 19:06:22 - INFO - __main__ - train loss is 9.668805490480736\n",
      "Steps:   3%|▏    | 453/15000 [03:00<43:21,  5.59it/s, lr=1e-5, step_loss=0.0501]07/18/2023 19:06:23 - INFO - __main__ - train loss is 9.673547765472904\n",
      "Steps:   3%|    | 454/15000 [03:00<43:19,  5.60it/s, lr=1e-5, step_loss=0.00474]07/18/2023 19:06:23 - INFO - __main__ - train loss is 9.691821335116401\n",
      "Steps:   3%|▏    | 455/15000 [03:01<43:17,  5.60it/s, lr=1e-5, step_loss=0.0183]07/18/2023 19:06:23 - INFO - __main__ - train loss is 9.834023667732254\n",
      "Steps:   3%|▏     | 456/15000 [03:01<43:16,  5.60it/s, lr=1e-5, step_loss=0.142]07/18/2023 19:06:23 - INFO - __main__ - train loss is 9.83816406247206\n",
      "Steps:   3%|    | 457/15000 [03:01<43:33,  5.57it/s, lr=1e-5, step_loss=0.00414]07/18/2023 19:06:23 - INFO - __main__ - train loss is 9.903473214479163\n",
      "Steps:   3%|▏    | 458/15000 [03:01<43:50,  5.53it/s, lr=1e-5, step_loss=0.0653]07/18/2023 19:06:23 - INFO - __main__ - train loss is 9.904835404944606\n",
      "Steps:   3%|    | 459/15000 [03:01<43:46,  5.54it/s, lr=1e-5, step_loss=0.00136]07/18/2023 19:06:24 - INFO - __main__ - train loss is 10.176130296778865\n",
      "Steps:   3%|▏     | 460/15000 [03:02<43:37,  5.55it/s, lr=1e-5, step_loss=0.271]07/18/2023 19:06:24 - INFO - __main__ - train loss is 10.189028043416329\n",
      "Steps:   3%|▏    | 461/15000 [03:02<43:29,  5.57it/s, lr=1e-5, step_loss=0.0129]07/18/2023 19:06:24 - INFO - __main__ - train loss is 10.265877623227425\n",
      "Steps:   3%|▏    | 462/15000 [03:02<43:23,  5.58it/s, lr=1e-5, step_loss=0.0768]07/18/2023 19:06:24 - INFO - __main__ - train loss is 10.505338598159142\n",
      "Steps:   3%|▏     | 463/15000 [03:02<43:19,  5.59it/s, lr=1e-5, step_loss=0.239]07/18/2023 19:06:24 - INFO - __main__ - train loss is 10.566825766232796\n",
      "Steps:   3%|▏    | 464/15000 [03:02<43:17,  5.60it/s, lr=1e-5, step_loss=0.0615]07/18/2023 19:06:25 - INFO - __main__ - train loss is 10.781420398619957\n",
      "Steps:   3%|▏     | 465/15000 [03:02<43:14,  5.60it/s, lr=1e-5, step_loss=0.215]07/18/2023 19:06:25 - INFO - __main__ - train loss is 10.844298202660866\n",
      "Steps:   3%|▏    | 466/15000 [03:03<43:12,  5.61it/s, lr=1e-5, step_loss=0.0629]07/18/2023 19:06:25 - INFO - __main__ - train loss is 10.846593517693691\n",
      "Steps:   3%|▏    | 467/15000 [03:03<43:14,  5.60it/s, lr=1e-5, step_loss=0.0023]07/18/2023 19:06:25 - INFO - __main__ - train loss is 11.119317609700374\n",
      "Steps:   3%|▏     | 468/15000 [03:03<43:17,  5.60it/s, lr=1e-5, step_loss=0.273]07/18/2023 19:06:25 - INFO - __main__ - train loss is 11.129361981409602\n",
      "Steps:   3%|▏      | 469/15000 [03:03<43:15,  5.60it/s, lr=1e-5, step_loss=0.01]07/18/2023 19:06:25 - INFO - __main__ - train loss is 11.3552896323381\n",
      "Steps:   3%|▏     | 470/15000 [03:03<43:11,  5.61it/s, lr=1e-5, step_loss=0.226]07/18/2023 19:06:26 - INFO - __main__ - train loss is 11.367850106093101\n",
      "Steps:   3%|▏    | 471/15000 [03:03<43:09,  5.61it/s, lr=1e-5, step_loss=0.0126]07/18/2023 19:06:26 - INFO - __main__ - train loss is 11.40508489671629\n",
      "Steps:   3%|▏    | 472/15000 [03:04<43:06,  5.62it/s, lr=1e-5, step_loss=0.0372]07/18/2023 19:06:26 - INFO - __main__ - train loss is 11.485695902141742\n",
      "Steps:   3%|▏    | 473/15000 [03:04<43:04,  5.62it/s, lr=1e-5, step_loss=0.0806]07/18/2023 19:06:26 - INFO - __main__ - train loss is 11.624238151940517\n",
      "Steps:   3%|▏     | 474/15000 [03:04<43:02,  5.63it/s, lr=1e-5, step_loss=0.139]07/18/2023 19:06:26 - INFO - __main__ - train loss is 11.633080409723334\n",
      "Steps:   3%|▏   | 475/15000 [03:04<43:03,  5.62it/s, lr=1e-5, step_loss=0.00884]07/18/2023 19:06:26 - INFO - __main__ - train loss is 11.725952053326182\n",
      "Steps:   3%|▏    | 476/15000 [03:04<43:01,  5.63it/s, lr=1e-5, step_loss=0.0929]07/18/2023 19:06:27 - INFO - __main__ - train loss is 11.868687832611613\n",
      "Steps:   3%|▏     | 477/15000 [03:05<43:01,  5.63it/s, lr=1e-5, step_loss=0.143]07/18/2023 19:06:27 - INFO - __main__ - train loss is 12.14844598795753\n",
      "Steps:   3%|▏      | 478/15000 [03:05<43:01,  5.63it/s, lr=1e-5, step_loss=0.28]07/18/2023 19:06:27 - INFO - __main__ - train loss is 12.214729281025939\n",
      "Steps:   3%|▏    | 479/15000 [03:05<43:01,  5.63it/s, lr=1e-5, step_loss=0.0663]07/18/2023 19:06:27 - INFO - __main__ - train loss is 12.225653035449795\n",
      "Steps:   3%|▏    | 480/15000 [03:05<43:00,  5.63it/s, lr=1e-5, step_loss=0.0109]07/18/2023 19:06:27 - INFO - __main__ - train loss is 12.287398340064101\n",
      "Steps:   3%|▏    | 481/15000 [03:05<43:01,  5.62it/s, lr=1e-5, step_loss=0.0617]07/18/2023 19:06:28 - INFO - __main__ - train loss is 12.29349390778225\n",
      "Steps:   3%|▏    | 482/15000 [03:05<43:15,  5.59it/s, lr=1e-5, step_loss=0.0061]07/18/2023 19:06:28 - INFO - __main__ - train loss is 12.314436517539434\n",
      "Steps:   3%|▏    | 483/15000 [03:06<43:12,  5.60it/s, lr=1e-5, step_loss=0.0209]07/18/2023 19:06:28 - INFO - __main__ - train loss is 12.850853167357855\n",
      "Steps:   3%|▏     | 484/15000 [03:06<43:08,  5.61it/s, lr=1e-5, step_loss=0.536]07/18/2023 19:06:28 - INFO - __main__ - train loss is 12.853191017755307\n",
      "Steps:   3%|▏   | 485/15000 [03:06<58:25,  4.14it/s, lr=1e-5, step_loss=0.00234]07/18/2023 19:06:29 - INFO - __main__ - Per validation step average loss is 0.07415752857923508\n",
      "07/18/2023 19:06:29 - INFO - __main__ - Cumulative validation average loss is 0.07415752857923508\n",
      "07/18/2023 19:06:29 - INFO - __main__ - Per validation step average loss is 0.20220500230789185\n",
      "07/18/2023 19:06:29 - INFO - __main__ - Cumulative validation average loss is 0.2763625308871269\n",
      "07/18/2023 19:06:29 - INFO - __main__ - Per validation step average loss is 0.04022425785660744\n",
      "07/18/2023 19:06:29 - INFO - __main__ - Cumulative validation average loss is 0.31658678874373436\n",
      "07/18/2023 19:06:29 - INFO - __main__ - Per validation step average loss is 0.16211587190628052\n",
      "07/18/2023 19:06:29 - INFO - __main__ - Cumulative validation average loss is 0.4787026606500149\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Per validation step average loss is 0.7343195080757141\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Cumulative validation average loss is 1.213022168725729\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Per validation step average loss is 0.3262389302253723\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Cumulative validation average loss is 1.5392610989511013\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Per validation step average loss is 0.48948198556900024\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Cumulative validation average loss is 2.0287430845201015\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Per validation step average loss is 0.007103446871042252\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Cumulative validation average loss is 2.035846531391144\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Per validation step average loss is 0.5076755881309509\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Cumulative validation average loss is 2.5435221195220947\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Per validation step average loss is 0.0043158321641385555\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Cumulative validation average loss is 2.5478379516862333\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Per validation step average loss is 0.3018384575843811\n",
      "07/18/2023 19:06:30 - INFO - __main__ - Cumulative validation average loss is 2.8496764092706144\n",
      "07/18/2023 19:06:31 - INFO - __main__ - Per validation step average loss is 0.2787448763847351\n",
      "07/18/2023 19:06:31 - INFO - __main__ - Cumulative validation average loss is 3.1284212856553495\n",
      "07/18/2023 19:06:31 - INFO - __main__ - Average validation loss for Epoch 4 is 0.26070177380461246\n",
      "07/18/2023 19:06:31 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:06:43 - INFO - __main__ - Starting epoch 5\n",
      "07/18/2023 19:06:44 - INFO - __main__ - train loss is 0.06415322422981262\n",
      "Steps:   3%|  | 486/15000 [03:22<19:36:47,  4.86s/it, lr=1e-5, step_loss=0.0642]07/18/2023 19:06:44 - INFO - __main__ - train loss is 0.07293509505689144\n",
      "Steps:   3%| | 487/15000 [03:22<13:57:00,  3.46s/it, lr=1e-5, step_loss=0.00878]07/18/2023 19:06:44 - INFO - __main__ - train loss is 0.38387410901486874\n",
      "Steps:   3%|▏   | 488/15000 [03:22<9:59:39,  2.48s/it, lr=1e-5, step_loss=0.311]07/18/2023 19:06:45 - INFO - __main__ - train loss is 0.47367424331605434\n",
      "Steps:   3%|   | 489/15000 [03:22<7:13:23,  1.79s/it, lr=1e-5, step_loss=0.0898]07/18/2023 19:06:45 - INFO - __main__ - train loss is 0.49616862647235394\n",
      "Steps:   3%|   | 490/15000 [03:23<5:16:16,  1.31s/it, lr=1e-5, step_loss=0.0225]07/18/2023 19:06:45 - INFO - __main__ - train loss is 0.5003404715098441\n",
      "Steps:   3%|  | 491/15000 [03:23<3:54:34,  1.03it/s, lr=1e-5, step_loss=0.00417]07/18/2023 19:06:45 - INFO - __main__ - train loss is 0.5104916100390255\n",
      "Steps:   3%|   | 492/15000 [03:23<2:57:06,  1.37it/s, lr=1e-5, step_loss=0.0102]07/18/2023 19:06:45 - INFO - __main__ - train loss is 0.5158664914779365\n",
      "Steps:   3%|  | 493/15000 [03:23<2:16:54,  1.77it/s, lr=1e-5, step_loss=0.00537]07/18/2023 19:06:45 - INFO - __main__ - train loss is 0.5883776652626693\n",
      "Steps:   3%|   | 494/15000 [03:23<1:48:43,  2.22it/s, lr=1e-5, step_loss=0.0725]07/18/2023 19:06:46 - INFO - __main__ - train loss is 0.6537976446561515\n",
      "Steps:   3%|   | 495/15000 [03:23<1:28:59,  2.72it/s, lr=1e-5, step_loss=0.0654]07/18/2023 19:06:46 - INFO - __main__ - train loss is 0.6572770606726408\n",
      "Steps:   3%|  | 496/15000 [03:24<1:15:08,  3.22it/s, lr=1e-5, step_loss=0.00348]07/18/2023 19:06:46 - INFO - __main__ - train loss is 0.6732164490967989\n",
      "Steps:   3%|   | 497/15000 [03:24<1:05:31,  3.69it/s, lr=1e-5, step_loss=0.0159]07/18/2023 19:06:46 - INFO - __main__ - train loss is 0.7048246320337057\n",
      "Steps:   3%|▏    | 498/15000 [03:24<59:07,  4.09it/s, lr=1e-5, step_loss=0.0316]07/18/2023 19:06:46 - INFO - __main__ - train loss is 1.1784547325223684\n",
      "Steps:   3%|▏     | 499/15000 [03:24<54:22,  4.44it/s, lr=1e-5, step_loss=0.474]07/18/2023 19:06:46 - INFO - __main__ - train loss is 1.2108975518494844\n",
      "Steps:   3%|▏     | 500/15000 [03:24<51:10,  4.72it/s, lr=1e-5, step_loss=0.474]07/18/2023 19:06:47 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-500\n",
      "07/18/2023 19:06:47 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:06:47,070] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "[2023-07-18 19:06:47,075] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:06:47,075] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:06:47,082] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:06:47,082] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:06:47,101] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:06:47,101] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:06:47,101] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:06:47 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-500/pytorch_model\n",
      "07/18/2023 19:06:47 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-500/scheduler.bin\n",
      "07/18/2023 19:06:47 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-500/random_states_0.pkl\n",
      "07/18/2023 19:06:47 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-500\n",
      "Steps:   3%|▏    | 500/15000 [03:24<51:10,  4.72it/s, lr=1e-5, step_loss=0.0324]07/18/2023 19:06:47 - INFO - __main__ - train loss is 1.2141307522542775\n",
      "Steps:   3%|▏   | 501/15000 [03:25<51:09,  4.72it/s, lr=1e-5, step_loss=0.00323]07/18/2023 19:06:47 - INFO - __main__ - train loss is 1.4163817544467747\n",
      "Steps:   3%|▏     | 502/15000 [03:25<49:06,  4.92it/s, lr=1e-5, step_loss=0.202]07/18/2023 19:06:47 - INFO - __main__ - train loss is 1.6363265295512974\n",
      "Steps:   3%|▏      | 503/15000 [03:25<47:27,  5.09it/s, lr=1e-5, step_loss=0.22]07/18/2023 19:06:47 - INFO - __main__ - train loss is 1.653176770079881\n",
      "Steps:   3%|▏    | 504/15000 [03:25<46:09,  5.23it/s, lr=1e-5, step_loss=0.0169]07/18/2023 19:06:47 - INFO - __main__ - train loss is 1.6552994339726865\n",
      "Steps:   3%|▏   | 505/15000 [03:25<45:44,  5.28it/s, lr=1e-5, step_loss=0.00212]07/18/2023 19:06:48 - INFO - __main__ - train loss is 1.7906366824172437\n",
      "Steps:   3%|▏     | 506/15000 [03:25<44:57,  5.37it/s, lr=1e-5, step_loss=0.135]07/18/2023 19:06:48 - INFO - __main__ - train loss is 1.7987931775860488\n",
      "Steps:   3%|▏   | 507/15000 [03:26<44:24,  5.44it/s, lr=1e-5, step_loss=0.00816]07/18/2023 19:06:48 - INFO - __main__ - train loss is 2.2032536673359573\n",
      "Steps:   3%|▏     | 508/15000 [03:26<44:11,  5.47it/s, lr=1e-5, step_loss=0.404]07/18/2023 19:06:48 - INFO - __main__ - train loss is 2.214815655257553\n",
      "Steps:   3%|▏    | 509/15000 [03:26<43:51,  5.51it/s, lr=1e-5, step_loss=0.0116]07/18/2023 19:06:48 - INFO - __main__ - train loss is 2.224295617546886\n",
      "Steps:   3%|▏   | 510/15000 [03:26<43:37,  5.54it/s, lr=1e-5, step_loss=0.00948]07/18/2023 19:06:48 - INFO - __main__ - train loss is 2.2627107142470777\n",
      "Steps:   3%|▏    | 511/15000 [03:26<43:27,  5.56it/s, lr=1e-5, step_loss=0.0384]07/18/2023 19:06:49 - INFO - __main__ - train loss is 2.7578603266738355\n",
      "Steps:   3%|▏     | 512/15000 [03:27<43:20,  5.57it/s, lr=1e-5, step_loss=0.495]07/18/2023 19:06:49 - INFO - __main__ - train loss is 2.771752036642283\n",
      "Steps:   3%|▏    | 513/15000 [03:27<43:16,  5.58it/s, lr=1e-5, step_loss=0.0139]07/18/2023 19:06:49 - INFO - __main__ - train loss is 2.792662564199418\n",
      "Steps:   3%|▏    | 514/15000 [03:27<43:12,  5.59it/s, lr=1e-5, step_loss=0.0209]07/18/2023 19:06:49 - INFO - __main__ - train loss is 2.862223300617188\n",
      "Steps:   3%|▏    | 515/15000 [03:27<43:09,  5.59it/s, lr=1e-5, step_loss=0.0696]07/18/2023 19:06:49 - INFO - __main__ - train loss is 2.994555178564042\n",
      "Steps:   3%|▏     | 516/15000 [03:27<43:13,  5.58it/s, lr=1e-5, step_loss=0.132]07/18/2023 19:06:50 - INFO - __main__ - train loss is 3.6609726580791175\n",
      "Steps:   3%|▏     | 517/15000 [03:27<43:13,  5.58it/s, lr=1e-5, step_loss=0.666]07/18/2023 19:06:50 - INFO - __main__ - train loss is 3.8802387448959053\n",
      "Steps:   3%|▏     | 518/15000 [03:28<43:14,  5.58it/s, lr=1e-5, step_loss=0.219]07/18/2023 19:06:50 - INFO - __main__ - train loss is 3.9661799180321395\n",
      "Steps:   3%|▏    | 519/15000 [03:28<43:33,  5.54it/s, lr=1e-5, step_loss=0.0859]07/18/2023 19:06:50 - INFO - __main__ - train loss is 3.974836905952543\n",
      "Steps:   3%|▏   | 520/15000 [03:28<43:48,  5.51it/s, lr=1e-5, step_loss=0.00866]07/18/2023 19:06:50 - INFO - __main__ - train loss is 4.4691217741928995\n",
      "Steps:   3%|▏     | 521/15000 [03:28<43:44,  5.52it/s, lr=1e-5, step_loss=0.494]07/18/2023 19:06:50 - INFO - __main__ - train loss is 4.976727386470884\n",
      "Steps:   3%|▏     | 522/15000 [03:28<43:51,  5.50it/s, lr=1e-5, step_loss=0.508]07/18/2023 19:06:51 - INFO - __main__ - train loss is 5.00221207132563\n",
      "Steps:   3%|▏    | 523/15000 [03:29<43:49,  5.50it/s, lr=1e-5, step_loss=0.0255]07/18/2023 19:06:51 - INFO - __main__ - train loss is 5.540473604109138\n",
      "Steps:   3%|▏     | 524/15000 [03:29<43:35,  5.53it/s, lr=1e-5, step_loss=0.538]07/18/2023 19:06:51 - INFO - __main__ - train loss is 5.542340338695794\n",
      "Steps:   4%|▏   | 525/15000 [03:29<43:24,  5.56it/s, lr=1e-5, step_loss=0.00187]07/18/2023 19:06:51 - INFO - __main__ - train loss is 5.596231997478753\n",
      "Steps:   4%|▏    | 526/15000 [03:29<43:17,  5.57it/s, lr=1e-5, step_loss=0.0539]07/18/2023 19:06:51 - INFO - __main__ - train loss is 5.8826022748835385\n",
      "Steps:   4%|▏     | 527/15000 [03:29<43:12,  5.58it/s, lr=1e-5, step_loss=0.286]07/18/2023 19:06:52 - INFO - __main__ - train loss is 6.084883302915841\n",
      "Steps:   4%|▏     | 528/15000 [03:29<43:08,  5.59it/s, lr=1e-5, step_loss=0.202]07/18/2023 19:06:52 - INFO - __main__ - train loss is 6.2611796711571515\n",
      "Steps:   4%|▏     | 529/15000 [03:30<43:09,  5.59it/s, lr=1e-5, step_loss=0.176]07/18/2023 19:06:52 - INFO - __main__ - train loss is 6.31789155350998\n",
      "Steps:   4%|▏    | 530/15000 [03:30<43:06,  5.60it/s, lr=1e-5, step_loss=0.0567]07/18/2023 19:06:52 - INFO - __main__ - train loss is 6.322005848865956\n",
      "Steps:   4%|▏   | 531/15000 [03:30<43:04,  5.60it/s, lr=1e-5, step_loss=0.00411]07/18/2023 19:06:52 - INFO - __main__ - train loss is 6.622963200788945\n",
      "Steps:   4%|▏     | 532/15000 [03:30<43:01,  5.60it/s, lr=1e-5, step_loss=0.301]07/18/2023 19:06:52 - INFO - __main__ - train loss is 6.883234034758061\n",
      "Steps:   4%|▏      | 533/15000 [03:30<43:31,  5.54it/s, lr=1e-5, step_loss=0.26]07/18/2023 19:06:53 - INFO - __main__ - train loss is 6.900224480312318\n",
      "Steps:   4%|▏     | 534/15000 [03:31<43:34,  5.53it/s, lr=1e-5, step_loss=0.017]07/18/2023 19:06:53 - INFO - __main__ - train loss is 7.026088479440659\n",
      "Steps:   4%|▏     | 535/15000 [03:31<43:26,  5.55it/s, lr=1e-5, step_loss=0.126]07/18/2023 19:06:53 - INFO - __main__ - train loss is 7.166713092010468\n",
      "Steps:   4%|▏     | 536/15000 [03:31<43:21,  5.56it/s, lr=1e-5, step_loss=0.141]07/18/2023 19:06:53 - INFO - __main__ - train loss is 7.357667196076363\n",
      "Steps:   4%|▏     | 537/15000 [03:31<43:16,  5.57it/s, lr=1e-5, step_loss=0.191]07/18/2023 19:06:53 - INFO - __main__ - train loss is 7.439013424795121\n",
      "Steps:   4%|▏    | 538/15000 [03:31<43:12,  5.58it/s, lr=1e-5, step_loss=0.0813]07/18/2023 19:06:54 - INFO - __main__ - train loss is 7.442347920034081\n",
      "Steps:   4%|▏   | 539/15000 [03:31<43:25,  5.55it/s, lr=1e-5, step_loss=0.00333]07/18/2023 19:06:54 - INFO - __main__ - train loss is 7.562305292580277\n",
      "Steps:   4%|▎      | 540/15000 [03:32<43:24,  5.55it/s, lr=1e-5, step_loss=0.12]07/18/2023 19:06:54 - INFO - __main__ - train loss is 7.578018716070801\n",
      "Steps:   4%|▏    | 541/15000 [03:32<43:41,  5.52it/s, lr=1e-5, step_loss=0.0157]07/18/2023 19:06:54 - INFO - __main__ - train loss is 7.648384592030197\n",
      "Steps:   4%|▏    | 542/15000 [03:32<43:36,  5.53it/s, lr=1e-5, step_loss=0.0704]07/18/2023 19:06:54 - INFO - __main__ - train loss is 7.688169880304486\n",
      "Steps:   4%|▏    | 543/15000 [03:32<43:25,  5.55it/s, lr=1e-5, step_loss=0.0398]07/18/2023 19:06:54 - INFO - __main__ - train loss is 8.251526756677777\n",
      "Steps:   4%|▏     | 544/15000 [03:32<43:20,  5.56it/s, lr=1e-5, step_loss=0.563]07/18/2023 19:06:55 - INFO - __main__ - train loss is 8.29734409833327\n",
      "Steps:   4%|▏    | 545/15000 [03:32<43:15,  5.57it/s, lr=1e-5, step_loss=0.0458]07/18/2023 19:06:55 - INFO - __main__ - train loss is 8.383741865400225\n",
      "Steps:   4%|▏    | 546/15000 [03:33<43:11,  5.58it/s, lr=1e-5, step_loss=0.0864]07/18/2023 19:06:55 - INFO - __main__ - train loss is 8.394626999739558\n",
      "Steps:   4%|▏    | 547/15000 [03:33<43:08,  5.58it/s, lr=1e-5, step_loss=0.0109]07/18/2023 19:06:55 - INFO - __main__ - train loss is 8.403401265386492\n",
      "Steps:   4%|▏   | 548/15000 [03:33<43:06,  5.59it/s, lr=1e-5, step_loss=0.00877]07/18/2023 19:06:55 - INFO - __main__ - train loss is 8.430956893134862\n",
      "Steps:   4%|▏    | 549/15000 [03:33<43:02,  5.59it/s, lr=1e-5, step_loss=0.0276]07/18/2023 19:06:56 - INFO - __main__ - train loss is 8.495974757242948\n",
      "Steps:   4%|▏     | 550/15000 [03:33<43:01,  5.60it/s, lr=1e-5, step_loss=0.065]07/18/2023 19:06:56 - INFO - __main__ - train loss is 8.896922357846051\n",
      "Steps:   4%|▏     | 551/15000 [03:34<43:01,  5.60it/s, lr=1e-5, step_loss=0.401]07/18/2023 19:06:56 - INFO - __main__ - train loss is 8.9627480735071\n",
      "Steps:   4%|▏    | 552/15000 [03:34<43:02,  5.59it/s, lr=1e-5, step_loss=0.0658]07/18/2023 19:06:56 - INFO - __main__ - train loss is 9.308436446357518\n",
      "Steps:   4%|▏     | 553/15000 [03:34<42:59,  5.60it/s, lr=1e-5, step_loss=0.346]07/18/2023 19:06:56 - INFO - __main__ - train loss is 9.407598540652543\n",
      "Steps:   4%|▏    | 554/15000 [03:34<42:58,  5.60it/s, lr=1e-5, step_loss=0.0992]07/18/2023 19:06:56 - INFO - __main__ - train loss is 9.781048819888383\n",
      "Steps:   4%|▏     | 555/15000 [03:34<42:59,  5.60it/s, lr=1e-5, step_loss=0.373]07/18/2023 19:06:57 - INFO - __main__ - train loss is 9.81941342400387\n",
      "Steps:   4%|▏    | 556/15000 [03:34<43:01,  5.60it/s, lr=1e-5, step_loss=0.0384]07/18/2023 19:06:57 - INFO - __main__ - train loss is 10.36603355454281\n",
      "Steps:   4%|▏     | 557/15000 [03:35<42:58,  5.60it/s, lr=1e-5, step_loss=0.547]07/18/2023 19:06:57 - INFO - __main__ - train loss is 10.381804559845477\n",
      "Steps:   4%|▏    | 558/15000 [03:35<42:58,  5.60it/s, lr=1e-5, step_loss=0.0158]07/18/2023 19:06:57 - INFO - __main__ - train loss is 10.388356240466237\n",
      "Steps:   4%|▏   | 559/15000 [03:35<42:56,  5.60it/s, lr=1e-5, step_loss=0.00655]07/18/2023 19:06:57 - INFO - __main__ - train loss is 10.544993819668889\n",
      "Steps:   4%|▏     | 560/15000 [03:35<42:57,  5.60it/s, lr=1e-5, step_loss=0.157]07/18/2023 19:06:57 - INFO - __main__ - train loss is 10.547158864792436\n",
      "Steps:   4%|▏   | 561/15000 [03:35<43:24,  5.54it/s, lr=1e-5, step_loss=0.00217]07/18/2023 19:06:58 - INFO - __main__ - train loss is 10.550910599762574\n",
      "Steps:   4%|▏   | 562/15000 [03:36<43:28,  5.53it/s, lr=1e-5, step_loss=0.00375]07/18/2023 19:06:58 - INFO - __main__ - train loss is 10.921622641617432\n",
      "Steps:   4%|▏     | 563/15000 [03:36<43:23,  5.54it/s, lr=1e-5, step_loss=0.371]07/18/2023 19:06:58 - INFO - __main__ - train loss is 10.923437953111716\n",
      "Steps:   4%|▏   | 564/15000 [03:36<43:13,  5.57it/s, lr=1e-5, step_loss=0.00182]07/18/2023 19:06:58 - INFO - __main__ - train loss is 11.16212204110343\n",
      "Steps:   4%|▏     | 565/15000 [03:36<43:06,  5.58it/s, lr=1e-5, step_loss=0.239]07/18/2023 19:06:58 - INFO - __main__ - train loss is 11.401898682233877\n",
      "Steps:   4%|▎      | 566/15000 [03:36<43:05,  5.58it/s, lr=1e-5, step_loss=0.24]07/18/2023 19:06:59 - INFO - __main__ - train loss is 11.406574420747347\n",
      "Steps:   4%|▏   | 567/15000 [03:36<43:00,  5.59it/s, lr=1e-5, step_loss=0.00468]07/18/2023 19:06:59 - INFO - __main__ - train loss is 11.484269760665484\n",
      "Steps:   4%|▏    | 568/15000 [03:37<42:55,  5.60it/s, lr=1e-5, step_loss=0.0777]07/18/2023 19:06:59 - INFO - __main__ - train loss is 11.49420789827127\n",
      "Steps:   4%|▏   | 569/15000 [03:37<42:52,  5.61it/s, lr=1e-5, step_loss=0.00994]07/18/2023 19:06:59 - INFO - __main__ - train loss is 11.496463783201762\n",
      "Steps:   4%|▏   | 570/15000 [03:37<43:03,  5.58it/s, lr=1e-5, step_loss=0.00226]07/18/2023 19:06:59 - INFO - __main__ - train loss is 12.449952490744181\n",
      "Steps:   4%|▏     | 571/15000 [03:37<42:58,  5.60it/s, lr=1e-5, step_loss=0.953]07/18/2023 19:06:59 - INFO - __main__ - train loss is 12.700351484236307\n",
      "Steps:   4%|▎      | 572/15000 [03:37<42:54,  5.61it/s, lr=1e-5, step_loss=0.25]07/18/2023 19:07:00 - INFO - __main__ - train loss is 12.787006624159403\n",
      "Steps:   4%|▏    | 573/15000 [03:38<42:51,  5.61it/s, lr=1e-5, step_loss=0.0867]07/18/2023 19:07:00 - INFO - __main__ - train loss is 13.19166878622491\n",
      "Steps:   4%|▏     | 574/15000 [03:38<42:48,  5.62it/s, lr=1e-5, step_loss=0.405]07/18/2023 19:07:00 - INFO - __main__ - train loss is 13.373703383025713\n",
      "Steps:   4%|▏     | 575/15000 [03:38<42:46,  5.62it/s, lr=1e-5, step_loss=0.182]07/18/2023 19:07:00 - INFO - __main__ - train loss is 13.593141310033388\n",
      "Steps:   4%|▏     | 576/15000 [03:38<42:44,  5.62it/s, lr=1e-5, step_loss=0.219]07/18/2023 19:07:00 - INFO - __main__ - train loss is 13.646247699973173\n",
      "Steps:   4%|▏    | 577/15000 [03:38<42:43,  5.63it/s, lr=1e-5, step_loss=0.0531]07/18/2023 19:07:01 - INFO - __main__ - train loss is 13.837355509516783\n",
      "Steps:   4%|▏     | 578/15000 [03:38<42:43,  5.63it/s, lr=1e-5, step_loss=0.191]07/18/2023 19:07:01 - INFO - __main__ - train loss is 13.921083822962828\n",
      "Steps:   4%|▏    | 579/15000 [03:39<42:43,  5.62it/s, lr=1e-5, step_loss=0.0837]07/18/2023 19:07:01 - INFO - __main__ - train loss is 13.923222424578853\n",
      "Steps:   4%|▏   | 580/15000 [03:39<42:52,  5.61it/s, lr=1e-5, step_loss=0.00214]07/18/2023 19:07:01 - INFO - __main__ - train loss is 13.924679239862598\n",
      "Steps:   4%|▏   | 581/15000 [03:39<43:15,  5.56it/s, lr=1e-5, step_loss=0.00146]07/18/2023 19:07:01 - INFO - __main__ - train loss is 13.927355284919031\n",
      "Steps:   4%|▏   | 582/15000 [03:39<57:38,  4.17it/s, lr=1e-5, step_loss=0.00268]07/18/2023 19:07:02 - INFO - __main__ - Per validation step average loss is 0.2859496474266052\n",
      "07/18/2023 19:07:02 - INFO - __main__ - Cumulative validation average loss is 0.2859496474266052\n",
      "07/18/2023 19:07:02 - INFO - __main__ - Per validation step average loss is 0.019894026219844818\n",
      "07/18/2023 19:07:02 - INFO - __main__ - Cumulative validation average loss is 0.30584367364645004\n",
      "07/18/2023 19:07:02 - INFO - __main__ - Per validation step average loss is 0.008526485413312912\n",
      "07/18/2023 19:07:02 - INFO - __main__ - Cumulative validation average loss is 0.31437015905976295\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Per validation step average loss is 0.06905540823936462\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Cumulative validation average loss is 0.3834255672991276\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Per validation step average loss is 0.0970059186220169\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Cumulative validation average loss is 0.4804314859211445\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Per validation step average loss is 0.11412426829338074\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Cumulative validation average loss is 0.5945557542145252\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Per validation step average loss is 0.19631972908973694\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Cumulative validation average loss is 0.7908754833042622\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Per validation step average loss is 0.008757736533880234\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Cumulative validation average loss is 0.7996332198381424\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Per validation step average loss is 0.22414137423038483\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Cumulative validation average loss is 1.0237745940685272\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Per validation step average loss is 0.4057568907737732\n",
      "07/18/2023 19:07:03 - INFO - __main__ - Cumulative validation average loss is 1.4295314848423004\n",
      "07/18/2023 19:07:04 - INFO - __main__ - Per validation step average loss is 0.15436741709709167\n",
      "07/18/2023 19:07:04 - INFO - __main__ - Cumulative validation average loss is 1.583898901939392\n",
      "07/18/2023 19:07:04 - INFO - __main__ - Per validation step average loss is 0.05952095240354538\n",
      "07/18/2023 19:07:04 - INFO - __main__ - Cumulative validation average loss is 1.6434198543429375\n",
      "07/18/2023 19:07:04 - INFO - __main__ - Average validation loss for Epoch 5 is 0.13695165452857813\n",
      "07/18/2023 19:07:04 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:07:16 - INFO - __main__ - Starting epoch 6\n",
      "07/18/2023 19:07:17 - INFO - __main__ - train loss is 0.10228145867586136\n",
      "Steps:   4%|   | 583/15000 [03:55<19:25:18,  4.85s/it, lr=1e-5, step_loss=0.102]07/18/2023 19:07:17 - INFO - __main__ - train loss is 0.16674388945102692\n",
      "Steps:   4%|  | 584/15000 [03:55<13:48:51,  3.45s/it, lr=1e-5, step_loss=0.0645]07/18/2023 19:07:17 - INFO - __main__ - train loss is 0.2589793726801872\n",
      "Steps:   4%|   | 585/15000 [03:55<9:53:28,  2.47s/it, lr=1e-5, step_loss=0.0922]07/18/2023 19:07:18 - INFO - __main__ - train loss is 0.512357585132122\n",
      "Steps:   4%|▏   | 586/15000 [03:55<7:09:08,  1.79s/it, lr=1e-5, step_loss=0.253]07/18/2023 19:07:18 - INFO - __main__ - train loss is 0.5671067349612713\n",
      "Steps:   4%|   | 587/15000 [03:56<5:13:35,  1.31s/it, lr=1e-5, step_loss=0.0547]07/18/2023 19:07:18 - INFO - __main__ - train loss is 0.9997200779616833\n",
      "Steps:   4%|▏   | 588/15000 [03:56<3:53:15,  1.03it/s, lr=1e-5, step_loss=0.433]07/18/2023 19:07:18 - INFO - __main__ - train loss is 1.0043809292837977\n",
      "Steps:   4%|  | 589/15000 [03:56<2:56:06,  1.36it/s, lr=1e-5, step_loss=0.00466]07/18/2023 19:07:18 - INFO - __main__ - train loss is 1.311302619986236\n",
      "Steps:   4%|▏   | 590/15000 [03:56<2:16:04,  1.76it/s, lr=1e-5, step_loss=0.307]07/18/2023 19:07:18 - INFO - __main__ - train loss is 1.3133722571656108\n",
      "Steps:   4%|  | 591/15000 [03:56<1:48:02,  2.22it/s, lr=1e-5, step_loss=0.00207]07/18/2023 19:07:19 - INFO - __main__ - train loss is 1.5476596234366298\n",
      "Steps:   4%|▏   | 592/15000 [03:57<1:28:23,  2.72it/s, lr=1e-5, step_loss=0.234]07/18/2023 19:07:19 - INFO - __main__ - train loss is 1.6949949143454432\n",
      "Steps:   4%|▏   | 593/15000 [03:57<1:15:02,  3.20it/s, lr=1e-5, step_loss=0.147]07/18/2023 19:07:19 - INFO - __main__ - train loss is 2.0540752885863185\n",
      "Steps:   4%|▏   | 594/15000 [03:57<1:05:20,  3.67it/s, lr=1e-5, step_loss=0.359]07/18/2023 19:07:19 - INFO - __main__ - train loss is 2.2261125771328807\n",
      "Steps:   4%|▏     | 595/15000 [03:57<58:31,  4.10it/s, lr=1e-5, step_loss=0.172]07/18/2023 19:07:19 - INFO - __main__ - train loss is 2.489950659684837\n",
      "Steps:   4%|▏     | 596/15000 [03:57<53:45,  4.47it/s, lr=1e-5, step_loss=0.264]07/18/2023 19:07:20 - INFO - __main__ - train loss is 2.494537303224206\n",
      "Steps:   4%|▏   | 597/15000 [03:57<50:28,  4.76it/s, lr=1e-5, step_loss=0.00459]07/18/2023 19:07:20 - INFO - __main__ - train loss is 2.504137204028666\n",
      "Steps:   4%|▏    | 598/15000 [03:58<48:05,  4.99it/s, lr=1e-5, step_loss=0.0096]07/18/2023 19:07:20 - INFO - __main__ - train loss is 2.7556377509608865\n",
      "Steps:   4%|▏     | 599/15000 [03:58<46:26,  5.17it/s, lr=1e-5, step_loss=0.252]07/18/2023 19:07:20 - INFO - __main__ - train loss is 2.97339537832886\n",
      "Steps:   4%|▏     | 600/15000 [03:58<45:18,  5.30it/s, lr=1e-5, step_loss=0.218]07/18/2023 19:07:20 - INFO - __main__ - train loss is 2.993583773262799\n",
      "Steps:   4%|▏    | 601/15000 [03:58<44:43,  5.37it/s, lr=1e-5, step_loss=0.0202]07/18/2023 19:07:20 - INFO - __main__ - train loss is 3.2372186379507184\n",
      "Steps:   4%|▏     | 602/15000 [03:58<44:26,  5.40it/s, lr=1e-5, step_loss=0.244]07/18/2023 19:07:21 - INFO - __main__ - train loss is 3.5765334563329816\n",
      "Steps:   4%|▏     | 603/15000 [03:59<44:08,  5.43it/s, lr=1e-5, step_loss=0.339]07/18/2023 19:07:21 - INFO - __main__ - train loss is 3.657946732826531\n",
      "Steps:   4%|▏    | 604/15000 [03:59<43:44,  5.49it/s, lr=1e-5, step_loss=0.0814]07/18/2023 19:07:21 - INFO - __main__ - train loss is 3.6790562281385064\n",
      "Steps:   4%|▏    | 605/15000 [03:59<43:28,  5.52it/s, lr=1e-5, step_loss=0.0211]07/18/2023 19:07:21 - INFO - __main__ - train loss is 4.18051737640053\n",
      "Steps:   4%|▏     | 606/15000 [03:59<43:16,  5.54it/s, lr=1e-5, step_loss=0.501]07/18/2023 19:07:21 - INFO - __main__ - train loss is 4.247954824008048\n",
      "Steps:   4%|▏    | 607/15000 [03:59<43:11,  5.55it/s, lr=1e-5, step_loss=0.0674]07/18/2023 19:07:22 - INFO - __main__ - train loss is 4.250177562003955\n",
      "Steps:   4%|▏   | 608/15000 [03:59<43:03,  5.57it/s, lr=1e-5, step_loss=0.00222]07/18/2023 19:07:22 - INFO - __main__ - train loss is 4.405784800415859\n",
      "Steps:   4%|▏     | 609/15000 [04:00<42:58,  5.58it/s, lr=1e-5, step_loss=0.156]07/18/2023 19:07:22 - INFO - __main__ - train loss is 4.5521862951572984\n",
      "Steps:   4%|▏     | 610/15000 [04:00<42:53,  5.59it/s, lr=1e-5, step_loss=0.146]07/18/2023 19:07:22 - INFO - __main__ - train loss is 5.0220471767243\n",
      "Steps:   4%|▎      | 611/15000 [04:00<42:49,  5.60it/s, lr=1e-5, step_loss=0.47]07/18/2023 19:07:22 - INFO - __main__ - train loss is 5.026290237670764\n",
      "Steps:   4%|▏   | 612/15000 [04:00<42:45,  5.61it/s, lr=1e-5, step_loss=0.00424]07/18/2023 19:07:22 - INFO - __main__ - train loss is 5.225980251794681\n",
      "Steps:   4%|▎       | 613/15000 [04:00<43:25,  5.52it/s, lr=1e-5, step_loss=0.2]07/18/2023 19:07:23 - INFO - __main__ - train loss is 5.245302337920293\n",
      "Steps:   4%|▏    | 614/15000 [04:01<43:18,  5.54it/s, lr=1e-5, step_loss=0.0193]07/18/2023 19:07:23 - INFO - __main__ - train loss is 5.721498925006017\n",
      "Steps:   4%|▏     | 615/15000 [04:01<43:06,  5.56it/s, lr=1e-5, step_loss=0.476]07/18/2023 19:07:23 - INFO - __main__ - train loss is 5.7747951408382505\n",
      "Steps:   4%|▏    | 616/15000 [04:01<42:56,  5.58it/s, lr=1e-5, step_loss=0.0533]07/18/2023 19:07:23 - INFO - __main__ - train loss is 5.792879469459876\n",
      "Steps:   4%|▏    | 617/15000 [04:01<42:51,  5.59it/s, lr=1e-5, step_loss=0.0181]07/18/2023 19:07:23 - INFO - __main__ - train loss is 6.021290726726875\n",
      "Steps:   4%|▏     | 618/15000 [04:01<42:49,  5.60it/s, lr=1e-5, step_loss=0.228]07/18/2023 19:07:24 - INFO - __main__ - train loss is 6.029202922945842\n",
      "Steps:   4%|▏   | 619/15000 [04:01<42:45,  5.61it/s, lr=1e-5, step_loss=0.00791]07/18/2023 19:07:24 - INFO - __main__ - train loss is 6.170954212313518\n",
      "Steps:   4%|▏     | 620/15000 [04:02<42:46,  5.60it/s, lr=1e-5, step_loss=0.142]07/18/2023 19:07:24 - INFO - __main__ - train loss is 6.355554431444034\n",
      "Steps:   4%|▏     | 621/15000 [04:02<43:09,  5.55it/s, lr=1e-5, step_loss=0.185]07/18/2023 19:07:24 - INFO - __main__ - train loss is 6.357353942119516\n",
      "Steps:   4%|▏    | 622/15000 [04:02<42:57,  5.58it/s, lr=1e-5, step_loss=0.0018]07/18/2023 19:07:24 - INFO - __main__ - train loss is 6.4035509914392605\n",
      "Steps:   4%|▏    | 623/15000 [04:02<42:53,  5.59it/s, lr=1e-5, step_loss=0.0462]07/18/2023 19:07:24 - INFO - __main__ - train loss is 6.7370655328268185\n",
      "Steps:   4%|▏     | 624/15000 [04:02<42:47,  5.60it/s, lr=1e-5, step_loss=0.334]07/18/2023 19:07:25 - INFO - __main__ - train loss is 7.2170925826067105\n",
      "Steps:   4%|▎      | 625/15000 [04:02<42:46,  5.60it/s, lr=1e-5, step_loss=0.48]07/18/2023 19:07:25 - INFO - __main__ - train loss is 7.516267249011435\n",
      "Steps:   4%|▎     | 626/15000 [04:03<42:42,  5.61it/s, lr=1e-5, step_loss=0.299]07/18/2023 19:07:25 - INFO - __main__ - train loss is 7.636026614927687\n",
      "Steps:   4%|▎      | 627/15000 [04:03<42:41,  5.61it/s, lr=1e-5, step_loss=0.12]07/18/2023 19:07:25 - INFO - __main__ - train loss is 7.643252965644933\n",
      "Steps:   4%|▏   | 628/15000 [04:03<42:39,  5.62it/s, lr=1e-5, step_loss=0.00723]07/18/2023 19:07:25 - INFO - __main__ - train loss is 7.840907779172994\n",
      "Steps:   4%|▎     | 629/15000 [04:03<42:38,  5.62it/s, lr=1e-5, step_loss=0.198]07/18/2023 19:07:25 - INFO - __main__ - train loss is 8.019062277511694\n",
      "Steps:   4%|▎     | 630/15000 [04:03<43:06,  5.56it/s, lr=1e-5, step_loss=0.178]07/18/2023 19:07:26 - INFO - __main__ - train loss is 8.04240050597582\n",
      "Steps:   4%|▏    | 631/15000 [04:04<43:21,  5.52it/s, lr=1e-5, step_loss=0.0233]07/18/2023 19:07:26 - INFO - __main__ - train loss is 8.247540470794775\n",
      "Steps:   4%|▎     | 632/15000 [04:04<43:10,  5.55it/s, lr=1e-5, step_loss=0.205]07/18/2023 19:07:26 - INFO - __main__ - train loss is 8.252516238600947\n",
      "Steps:   4%|▏   | 633/15000 [04:04<43:02,  5.56it/s, lr=1e-5, step_loss=0.00498]07/18/2023 19:07:26 - INFO - __main__ - train loss is 8.267285517067648\n",
      "Steps:   4%|▏    | 634/15000 [04:04<42:59,  5.57it/s, lr=1e-5, step_loss=0.0148]07/18/2023 19:07:26 - INFO - __main__ - train loss is 8.295379823655821\n",
      "Steps:   4%|▏    | 635/15000 [04:04<42:56,  5.58it/s, lr=1e-5, step_loss=0.0281]07/18/2023 19:07:27 - INFO - __main__ - train loss is 8.68942464014981\n",
      "Steps:   4%|▎     | 636/15000 [04:04<42:54,  5.58it/s, lr=1e-5, step_loss=0.394]07/18/2023 19:07:27 - INFO - __main__ - train loss is 8.88420306763146\n",
      "Steps:   4%|▎     | 637/15000 [04:05<42:51,  5.59it/s, lr=1e-5, step_loss=0.195]07/18/2023 19:07:27 - INFO - __main__ - train loss is 9.249285510391928\n",
      "Steps:   4%|▎     | 638/15000 [04:05<42:45,  5.60it/s, lr=1e-5, step_loss=0.365]07/18/2023 19:07:27 - INFO - __main__ - train loss is 9.281762464554049\n",
      "Steps:   4%|▏    | 639/15000 [04:05<42:40,  5.61it/s, lr=1e-5, step_loss=0.0325]07/18/2023 19:07:27 - INFO - __main__ - train loss is 9.369168123812415\n",
      "Steps:   4%|▏    | 640/15000 [04:05<42:36,  5.62it/s, lr=1e-5, step_loss=0.0874]07/18/2023 19:07:27 - INFO - __main__ - train loss is 9.38522504514549\n",
      "Steps:   4%|▏    | 641/15000 [04:05<42:55,  5.57it/s, lr=1e-5, step_loss=0.0161]07/18/2023 19:07:28 - INFO - __main__ - train loss is 9.63211675232742\n",
      "Steps:   4%|▎     | 642/15000 [04:06<42:47,  5.59it/s, lr=1e-5, step_loss=0.247]07/18/2023 19:07:28 - INFO - __main__ - train loss is 9.640267994836904\n",
      "Steps:   4%|▏   | 643/15000 [04:06<42:43,  5.60it/s, lr=1e-5, step_loss=0.00815]07/18/2023 19:07:28 - INFO - __main__ - train loss is 9.76537990255747\n",
      "Steps:   4%|▎     | 644/15000 [04:06<42:39,  5.61it/s, lr=1e-5, step_loss=0.125]07/18/2023 19:07:28 - INFO - __main__ - train loss is 9.84305881394539\n",
      "Steps:   4%|▏    | 645/15000 [04:06<42:37,  5.61it/s, lr=1e-5, step_loss=0.0777]07/18/2023 19:07:28 - INFO - __main__ - train loss is 9.846900506992824\n",
      "Steps:   4%|▏   | 646/15000 [04:06<42:37,  5.61it/s, lr=1e-5, step_loss=0.00384]07/18/2023 19:07:29 - INFO - __main__ - train loss is 10.180083020706661\n",
      "Steps:   4%|▎     | 647/15000 [04:06<42:35,  5.62it/s, lr=1e-5, step_loss=0.333]07/18/2023 19:07:29 - INFO - __main__ - train loss is 10.188592375372536\n",
      "Steps:   4%|▏   | 648/15000 [04:07<42:35,  5.62it/s, lr=1e-5, step_loss=0.00851]07/18/2023 19:07:29 - INFO - __main__ - train loss is 10.335482002352364\n",
      "Steps:   4%|▎     | 649/15000 [04:07<42:33,  5.62it/s, lr=1e-5, step_loss=0.147]07/18/2023 19:07:29 - INFO - __main__ - train loss is 10.338368758209981\n",
      "Steps:   4%|▏   | 650/15000 [04:07<42:46,  5.59it/s, lr=1e-5, step_loss=0.00289]07/18/2023 19:07:29 - INFO - __main__ - train loss is 10.609137341030873\n",
      "Steps:   4%|▎     | 651/15000 [04:07<42:42,  5.60it/s, lr=1e-5, step_loss=0.271]07/18/2023 19:07:29 - INFO - __main__ - train loss is 10.613191152573563\n",
      "Steps:   4%|▏   | 652/15000 [04:07<42:42,  5.60it/s, lr=1e-5, step_loss=0.00405]07/18/2023 19:07:30 - INFO - __main__ - train loss is 10.742487082839943\n",
      "Steps:   4%|▎     | 653/15000 [04:07<42:38,  5.61it/s, lr=1e-5, step_loss=0.129]07/18/2023 19:07:30 - INFO - __main__ - train loss is 10.930558840394951\n",
      "Steps:   4%|▎     | 654/15000 [04:08<42:37,  5.61it/s, lr=1e-5, step_loss=0.188]07/18/2023 19:07:30 - INFO - __main__ - train loss is 11.144257719279267\n",
      "Steps:   4%|▎     | 655/15000 [04:08<42:36,  5.61it/s, lr=1e-5, step_loss=0.214]07/18/2023 19:07:30 - INFO - __main__ - train loss is 11.172293639392592\n",
      "Steps:   4%|▎     | 656/15000 [04:08<42:35,  5.61it/s, lr=1e-5, step_loss=0.028]07/18/2023 19:07:30 - INFO - __main__ - train loss is 11.42445019504521\n",
      "Steps:   4%|▎     | 657/15000 [04:08<42:34,  5.62it/s, lr=1e-5, step_loss=0.252]07/18/2023 19:07:30 - INFO - __main__ - train loss is 11.498440450639464\n",
      "Steps:   4%|▎     | 658/15000 [04:08<43:01,  5.56it/s, lr=1e-5, step_loss=0.074]07/18/2023 19:07:31 - INFO - __main__ - train loss is 11.674876338453032\n",
      "Steps:   4%|▎     | 659/15000 [04:09<43:02,  5.55it/s, lr=1e-5, step_loss=0.176]07/18/2023 19:07:31 - INFO - __main__ - train loss is 11.676634717849083\n",
      "Steps:   4%|▏   | 660/15000 [04:09<42:52,  5.57it/s, lr=1e-5, step_loss=0.00176]07/18/2023 19:07:31 - INFO - __main__ - train loss is 12.104555238154717\n",
      "Steps:   4%|▎     | 661/15000 [04:09<42:46,  5.59it/s, lr=1e-5, step_loss=0.428]07/18/2023 19:07:31 - INFO - __main__ - train loss is 12.26799606170971\n",
      "Steps:   4%|▎     | 662/15000 [04:09<42:41,  5.60it/s, lr=1e-5, step_loss=0.163]07/18/2023 19:07:31 - INFO - __main__ - train loss is 12.295898296055384\n",
      "Steps:   4%|▏    | 663/15000 [04:09<42:37,  5.61it/s, lr=1e-5, step_loss=0.0279]07/18/2023 19:07:32 - INFO - __main__ - train loss is 12.479598738369532\n",
      "Steps:   4%|▎     | 664/15000 [04:09<42:32,  5.62it/s, lr=1e-5, step_loss=0.184]07/18/2023 19:07:32 - INFO - __main__ - train loss is 12.504788419348188\n",
      "Steps:   4%|▏    | 665/15000 [04:10<42:29,  5.62it/s, lr=1e-5, step_loss=0.0252]07/18/2023 19:07:32 - INFO - __main__ - train loss is 12.729966810089536\n",
      "Steps:   4%|▎     | 666/15000 [04:10<42:25,  5.63it/s, lr=1e-5, step_loss=0.225]07/18/2023 19:07:32 - INFO - __main__ - train loss is 13.22939669166226\n",
      "Steps:   4%|▎     | 667/15000 [04:10<42:23,  5.64it/s, lr=1e-5, step_loss=0.499]07/18/2023 19:07:32 - INFO - __main__ - train loss is 13.23608228948433\n",
      "Steps:   4%|▏   | 668/15000 [04:10<42:23,  5.64it/s, lr=1e-5, step_loss=0.00669]07/18/2023 19:07:32 - INFO - __main__ - train loss is 13.322680559125729\n",
      "Steps:   4%|▏    | 669/15000 [04:10<42:45,  5.59it/s, lr=1e-5, step_loss=0.0866]07/18/2023 19:07:33 - INFO - __main__ - train loss is 13.32996275194455\n",
      "Steps:   4%|▏   | 670/15000 [04:11<42:42,  5.59it/s, lr=1e-5, step_loss=0.00728]07/18/2023 19:07:33 - INFO - __main__ - train loss is 13.398463628371246\n",
      "Steps:   4%|▏    | 671/15000 [04:11<42:37,  5.60it/s, lr=1e-5, step_loss=0.0685]07/18/2023 19:07:33 - INFO - __main__ - train loss is 13.405372733832337\n",
      "Steps:   4%|▏   | 672/15000 [04:11<42:33,  5.61it/s, lr=1e-5, step_loss=0.00691]07/18/2023 19:07:33 - INFO - __main__ - train loss is 13.55487432575319\n",
      "Steps:   4%|▎      | 673/15000 [04:11<42:32,  5.61it/s, lr=1e-5, step_loss=0.15]07/18/2023 19:07:33 - INFO - __main__ - train loss is 13.556622430332936\n",
      "Steps:   4%|▏   | 674/15000 [04:11<42:31,  5.62it/s, lr=1e-5, step_loss=0.00175]07/18/2023 19:07:34 - INFO - __main__ - train loss is 13.618211239227094\n",
      "Steps:   4%|▏    | 675/15000 [04:11<42:31,  5.61it/s, lr=1e-5, step_loss=0.0616]07/18/2023 19:07:34 - INFO - __main__ - train loss is 13.814963265904225\n",
      "Steps:   5%|▎     | 676/15000 [04:12<42:27,  5.62it/s, lr=1e-5, step_loss=0.197]07/18/2023 19:07:34 - INFO - __main__ - train loss is 13.826138477423228\n",
      "Steps:   5%|▏    | 677/15000 [04:12<42:25,  5.63it/s, lr=1e-5, step_loss=0.0112]07/18/2023 19:07:34 - INFO - __main__ - train loss is 13.829947545775212\n",
      "Steps:   5%|▏   | 678/15000 [04:12<42:36,  5.60it/s, lr=1e-5, step_loss=0.00381]07/18/2023 19:07:34 - INFO - __main__ - train loss is 13.850624639191665\n",
      "Steps:   5%|▏  | 679/15000 [04:12<1:01:34,  3.88it/s, lr=1e-5, step_loss=0.0207]07/18/2023 19:07:35 - INFO - __main__ - Per validation step average loss is 0.33025097846984863\n",
      "07/18/2023 19:07:35 - INFO - __main__ - Cumulative validation average loss is 0.33025097846984863\n",
      "07/18/2023 19:07:35 - INFO - __main__ - Per validation step average loss is 0.2417774349451065\n",
      "07/18/2023 19:07:35 - INFO - __main__ - Cumulative validation average loss is 0.5720284134149551\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Per validation step average loss is 0.03502174839377403\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Cumulative validation average loss is 0.6070501618087292\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Per validation step average loss is 0.02675006538629532\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Cumulative validation average loss is 0.6338002271950245\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Per validation step average loss is 0.10010680556297302\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Cumulative validation average loss is 0.7339070327579975\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Per validation step average loss is 0.45885995030403137\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Cumulative validation average loss is 1.1927669830620289\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Per validation step average loss is 0.005718076601624489\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Cumulative validation average loss is 1.1984850596636534\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Per validation step average loss is 0.5263705849647522\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Cumulative validation average loss is 1.7248556446284056\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Per validation step average loss is 0.003133225254714489\n",
      "07/18/2023 19:07:36 - INFO - __main__ - Cumulative validation average loss is 1.72798886988312\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Per validation step average loss is 0.0714196115732193\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Cumulative validation average loss is 1.7994084814563394\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Per validation step average loss is 0.1517254263162613\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Cumulative validation average loss is 1.9511339077726007\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Per validation step average loss is 0.1860712766647339\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Cumulative validation average loss is 2.1372051844373345\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Average validation loss for Epoch 6 is 0.17810043203644454\n",
      "07/18/2023 19:07:37 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:07:50 - INFO - __main__ - Starting epoch 7\n",
      "07/18/2023 19:07:50 - INFO - __main__ - train loss is 0.011315283365547657\n",
      "Steps:   5%|  | 680/15000 [04:28<19:34:43,  4.92s/it, lr=1e-5, step_loss=0.0113]07/18/2023 19:07:50 - INFO - __main__ - train loss is 0.014832586515694857\n",
      "Steps:   5%| | 681/15000 [04:28<13:55:34,  3.50s/it, lr=1e-5, step_loss=0.00352]07/18/2023 19:07:51 - INFO - __main__ - train loss is 0.04872240545228124\n",
      "Steps:   5%|▏  | 682/15000 [04:29<9:57:44,  2.50s/it, lr=1e-5, step_loss=0.0339]07/18/2023 19:07:51 - INFO - __main__ - train loss is 0.1732051339931786\n",
      "Steps:   5%|▏   | 683/15000 [04:29<7:11:34,  1.81s/it, lr=1e-5, step_loss=0.124]07/18/2023 19:07:51 - INFO - __main__ - train loss is 0.5549234715290368\n",
      "Steps:   5%|▏   | 684/15000 [04:29<5:14:52,  1.32s/it, lr=1e-5, step_loss=0.382]07/18/2023 19:07:51 - INFO - __main__ - train loss is 0.8162767258472741\n",
      "Steps:   5%|▏   | 685/15000 [04:29<3:53:12,  1.02it/s, lr=1e-5, step_loss=0.261]07/18/2023 19:07:51 - INFO - __main__ - train loss is 0.9076123205013573\n",
      "Steps:   5%|▏  | 686/15000 [04:29<2:55:57,  1.36it/s, lr=1e-5, step_loss=0.0913]07/18/2023 19:07:52 - INFO - __main__ - train loss is 1.7104408708401024\n",
      "Steps:   5%|▏   | 687/15000 [04:29<2:15:53,  1.76it/s, lr=1e-5, step_loss=0.803]07/18/2023 19:07:52 - INFO - __main__ - train loss is 1.9119818178005517\n",
      "Steps:   5%|▏   | 688/15000 [04:30<1:47:50,  2.21it/s, lr=1e-5, step_loss=0.202]07/18/2023 19:07:52 - INFO - __main__ - train loss is 1.9315437306649983\n",
      "Steps:   5%|▏  | 689/15000 [04:30<1:28:36,  2.69it/s, lr=1e-5, step_loss=0.0196]07/18/2023 19:07:52 - INFO - __main__ - train loss is 2.0492613394744694\n",
      "Steps:   5%|▏   | 690/15000 [04:30<1:14:48,  3.19it/s, lr=1e-5, step_loss=0.118]07/18/2023 19:07:52 - INFO - __main__ - train loss is 2.137239657808095\n",
      "Steps:   5%|▏   | 691/15000 [04:30<1:05:03,  3.67it/s, lr=1e-5, step_loss=0.088]07/18/2023 19:07:52 - INFO - __main__ - train loss is 2.14128181245178\n",
      "Steps:   5%|▏   | 692/15000 [04:30<58:41,  4.06it/s, lr=1e-5, step_loss=0.00404]07/18/2023 19:07:53 - INFO - __main__ - train loss is 2.218486479483545\n",
      "Steps:   5%|▏    | 693/15000 [04:31<53:49,  4.43it/s, lr=1e-5, step_loss=0.0772]07/18/2023 19:07:53 - INFO - __main__ - train loss is 2.2317490046843886\n",
      "Steps:   5%|▏    | 694/15000 [04:31<50:25,  4.73it/s, lr=1e-5, step_loss=0.0133]07/18/2023 19:07:53 - INFO - __main__ - train loss is 2.510724670253694\n",
      "Steps:   5%|▎     | 695/15000 [04:31<48:00,  4.97it/s, lr=1e-5, step_loss=0.279]07/18/2023 19:07:53 - INFO - __main__ - train loss is 2.5134491331409663\n",
      "Steps:   5%|▏   | 696/15000 [04:31<46:18,  5.15it/s, lr=1e-5, step_loss=0.00272]07/18/2023 19:07:53 - INFO - __main__ - train loss is 2.697675586445257\n",
      "Steps:   5%|▎     | 697/15000 [04:31<45:10,  5.28it/s, lr=1e-5, step_loss=0.184]07/18/2023 19:07:54 - INFO - __main__ - train loss is 3.00852155755274\n",
      "Steps:   5%|▎     | 698/15000 [04:31<44:23,  5.37it/s, lr=1e-5, step_loss=0.311]07/18/2023 19:07:54 - INFO - __main__ - train loss is 3.397062302334234\n",
      "Steps:   5%|▎     | 699/15000 [04:32<43:49,  5.44it/s, lr=1e-5, step_loss=0.389]07/18/2023 19:07:54 - INFO - __main__ - train loss is 3.4952778078150004\n",
      "Steps:   5%|▏    | 700/15000 [04:32<43:41,  5.46it/s, lr=1e-5, step_loss=0.0982]07/18/2023 19:07:54 - INFO - __main__ - train loss is 3.4974124601576477\n",
      "Steps:   5%|▏   | 701/15000 [04:32<43:19,  5.50it/s, lr=1e-5, step_loss=0.00213]07/18/2023 19:07:54 - INFO - __main__ - train loss is 3.5792655071709305\n",
      "Steps:   5%|▏    | 702/15000 [04:32<43:07,  5.53it/s, lr=1e-5, step_loss=0.0819]07/18/2023 19:07:54 - INFO - __main__ - train loss is 3.582667021546513\n",
      "Steps:   5%|▏    | 703/15000 [04:32<42:55,  5.55it/s, lr=1e-5, step_loss=0.0034]07/18/2023 19:07:55 - INFO - __main__ - train loss is 3.6743783415295184\n",
      "Steps:   5%|▏    | 704/15000 [04:32<42:46,  5.57it/s, lr=1e-5, step_loss=0.0917]07/18/2023 19:07:55 - INFO - __main__ - train loss is 3.68693372560665\n",
      "Steps:   5%|▏    | 705/15000 [04:33<42:41,  5.58it/s, lr=1e-5, step_loss=0.0126]07/18/2023 19:07:55 - INFO - __main__ - train loss is 3.718519716989249\n",
      "Steps:   5%|▏    | 706/15000 [04:33<42:37,  5.59it/s, lr=1e-5, step_loss=0.0316]07/18/2023 19:07:55 - INFO - __main__ - train loss is 4.374196439515799\n",
      "Steps:   5%|▎     | 707/15000 [04:33<42:35,  5.59it/s, lr=1e-5, step_loss=0.656]07/18/2023 19:07:55 - INFO - __main__ - train loss is 4.8026748592965305\n",
      "Steps:   5%|▎     | 708/15000 [04:33<42:38,  5.59it/s, lr=1e-5, step_loss=0.428]07/18/2023 19:07:55 - INFO - __main__ - train loss is 5.03607515944168\n",
      "Steps:   5%|▎     | 709/15000 [04:33<42:36,  5.59it/s, lr=1e-5, step_loss=0.233]07/18/2023 19:07:56 - INFO - __main__ - train loss is 5.3923147465102375\n",
      "Steps:   5%|▎     | 710/15000 [04:34<42:33,  5.60it/s, lr=1e-5, step_loss=0.356]07/18/2023 19:07:56 - INFO - __main__ - train loss is 5.742111697327346\n",
      "Steps:   5%|▎      | 711/15000 [04:34<42:29,  5.60it/s, lr=1e-5, step_loss=0.35]07/18/2023 19:07:56 - INFO - __main__ - train loss is 5.750534142833203\n",
      "Steps:   5%|▏   | 712/15000 [04:34<42:26,  5.61it/s, lr=1e-5, step_loss=0.00842]07/18/2023 19:07:56 - INFO - __main__ - train loss is 5.752588738221675\n",
      "Steps:   5%|▏   | 713/15000 [04:34<42:26,  5.61it/s, lr=1e-5, step_loss=0.00205]07/18/2023 19:07:56 - INFO - __main__ - train loss is 5.776175987441093\n",
      "Steps:   5%|▏    | 714/15000 [04:34<42:25,  5.61it/s, lr=1e-5, step_loss=0.0236]07/18/2023 19:07:57 - INFO - __main__ - train loss is 5.779542732750997\n",
      "Steps:   5%|▏   | 715/15000 [04:34<42:23,  5.62it/s, lr=1e-5, step_loss=0.00337]07/18/2023 19:07:57 - INFO - __main__ - train loss is 5.7990769853349775\n",
      "Steps:   5%|▏    | 716/15000 [04:35<42:32,  5.60it/s, lr=1e-5, step_loss=0.0195]07/18/2023 19:07:57 - INFO - __main__ - train loss is 5.811787915183231\n",
      "Steps:   5%|▏    | 717/15000 [04:35<42:28,  5.60it/s, lr=1e-5, step_loss=0.0127]07/18/2023 19:07:57 - INFO - __main__ - train loss is 5.909361962927505\n",
      "Steps:   5%|▏    | 718/15000 [04:35<42:27,  5.61it/s, lr=1e-5, step_loss=0.0976]07/18/2023 19:07:57 - INFO - __main__ - train loss is 6.210258905543014\n",
      "Steps:   5%|▎     | 719/15000 [04:35<42:26,  5.61it/s, lr=1e-5, step_loss=0.301]07/18/2023 19:07:57 - INFO - __main__ - train loss is 6.517166022909805\n",
      "Steps:   5%|▎     | 720/15000 [04:35<42:25,  5.61it/s, lr=1e-5, step_loss=0.307]07/18/2023 19:07:58 - INFO - __main__ - train loss is 6.6030315204989165\n",
      "Steps:   5%|▏    | 721/15000 [04:36<42:26,  5.61it/s, lr=1e-5, step_loss=0.0859]07/18/2023 19:07:58 - INFO - __main__ - train loss is 6.635435403091833\n",
      "Steps:   5%|▏    | 722/15000 [04:36<42:26,  5.61it/s, lr=1e-5, step_loss=0.0324]07/18/2023 19:07:58 - INFO - __main__ - train loss is 6.638133603846654\n",
      "Steps:   5%|▏    | 723/15000 [04:36<42:24,  5.61it/s, lr=1e-5, step_loss=0.0027]07/18/2023 19:07:58 - INFO - __main__ - train loss is 6.680355075513944\n",
      "Steps:   5%|▏    | 724/15000 [04:36<42:26,  5.61it/s, lr=1e-5, step_loss=0.0422]07/18/2023 19:07:58 - INFO - __main__ - train loss is 6.69528002361767\n",
      "Steps:   5%|▏    | 725/15000 [04:36<42:24,  5.61it/s, lr=1e-5, step_loss=0.0149]07/18/2023 19:07:59 - INFO - __main__ - train loss is 6.808565296931192\n",
      "Steps:   5%|▎     | 726/15000 [04:36<42:24,  5.61it/s, lr=1e-5, step_loss=0.113]07/18/2023 19:07:59 - INFO - __main__ - train loss is 6.948891528649256\n",
      "Steps:   5%|▎      | 727/15000 [04:37<42:26,  5.61it/s, lr=1e-5, step_loss=0.14]07/18/2023 19:07:59 - INFO - __main__ - train loss is 7.511392720742151\n",
      "Steps:   5%|▎     | 728/15000 [04:37<42:27,  5.60it/s, lr=1e-5, step_loss=0.563]07/18/2023 19:07:59 - INFO - __main__ - train loss is 7.717181884450838\n",
      "Steps:   5%|▎     | 729/15000 [04:37<42:25,  5.61it/s, lr=1e-5, step_loss=0.206]07/18/2023 19:07:59 - INFO - __main__ - train loss is 7.767327156616375\n",
      "Steps:   5%|▏    | 730/15000 [04:37<42:24,  5.61it/s, lr=1e-5, step_loss=0.0501]07/18/2023 19:07:59 - INFO - __main__ - train loss is 7.778026738902554\n",
      "Steps:   5%|▏    | 731/15000 [04:37<42:28,  5.60it/s, lr=1e-5, step_loss=0.0107]07/18/2023 19:08:00 - INFO - __main__ - train loss is 8.025947266956791\n",
      "Steps:   5%|▎     | 732/15000 [04:37<42:30,  5.60it/s, lr=1e-5, step_loss=0.248]07/18/2023 19:08:00 - INFO - __main__ - train loss is 8.05004146671854\n",
      "Steps:   5%|▏    | 733/15000 [04:38<42:29,  5.60it/s, lr=1e-5, step_loss=0.0241]07/18/2023 19:08:00 - INFO - __main__ - train loss is 8.080621538450941\n",
      "Steps:   5%|▏    | 734/15000 [04:38<42:30,  5.59it/s, lr=1e-5, step_loss=0.0306]07/18/2023 19:08:00 - INFO - __main__ - train loss is 8.082732579438016\n",
      "Steps:   5%|▏   | 735/15000 [04:38<42:29,  5.60it/s, lr=1e-5, step_loss=0.00211]07/18/2023 19:08:00 - INFO - __main__ - train loss is 8.164542442886159\n",
      "Steps:   5%|▏    | 736/15000 [04:38<42:29,  5.59it/s, lr=1e-5, step_loss=0.0818]07/18/2023 19:08:00 - INFO - __main__ - train loss is 8.24820680054836\n",
      "Steps:   5%|▏    | 737/15000 [04:38<42:37,  5.58it/s, lr=1e-5, step_loss=0.0837]07/18/2023 19:08:01 - INFO - __main__ - train loss is 8.467608607141301\n",
      "Steps:   5%|▎     | 738/15000 [04:39<42:31,  5.59it/s, lr=1e-5, step_loss=0.219]07/18/2023 19:08:01 - INFO - __main__ - train loss is 9.193399823037907\n",
      "Steps:   5%|▎     | 739/15000 [04:39<42:28,  5.60it/s, lr=1e-5, step_loss=0.726]07/18/2023 19:08:01 - INFO - __main__ - train loss is 9.197651122929528\n",
      "Steps:   5%|▏   | 740/15000 [04:39<42:38,  5.57it/s, lr=1e-5, step_loss=0.00425]07/18/2023 19:08:01 - INFO - __main__ - train loss is 9.755453204037622\n",
      "Steps:   5%|▎     | 741/15000 [04:39<42:32,  5.59it/s, lr=1e-5, step_loss=0.558]07/18/2023 19:08:01 - INFO - __main__ - train loss is 9.770998970838264\n",
      "Steps:   5%|▏    | 742/15000 [04:39<42:33,  5.58it/s, lr=1e-5, step_loss=0.0155]07/18/2023 19:08:02 - INFO - __main__ - train loss is 10.045561925740913\n",
      "Steps:   5%|▎     | 743/15000 [04:39<42:28,  5.59it/s, lr=1e-5, step_loss=0.275]07/18/2023 19:08:02 - INFO - __main__ - train loss is 10.679851488443092\n",
      "Steps:   5%|▎     | 744/15000 [04:40<42:28,  5.59it/s, lr=1e-5, step_loss=0.634]07/18/2023 19:08:02 - INFO - __main__ - train loss is 10.940539882751182\n",
      "Steps:   5%|▎     | 745/15000 [04:40<42:26,  5.60it/s, lr=1e-5, step_loss=0.261]07/18/2023 19:08:02 - INFO - __main__ - train loss is 11.041959644528106\n",
      "Steps:   5%|▎     | 746/15000 [04:40<42:26,  5.60it/s, lr=1e-5, step_loss=0.101]07/18/2023 19:08:02 - INFO - __main__ - train loss is 11.489687861176208\n",
      "Steps:   5%|▎     | 747/15000 [04:40<42:45,  5.56it/s, lr=1e-5, step_loss=0.448]07/18/2023 19:08:02 - INFO - __main__ - train loss is 11.555822552414611\n",
      "Steps:   5%|▏    | 748/15000 [04:40<42:39,  5.57it/s, lr=1e-5, step_loss=0.0661]07/18/2023 19:08:03 - INFO - __main__ - train loss is 11.87617260334082\n",
      "Steps:   5%|▎      | 749/15000 [04:41<42:35,  5.58it/s, lr=1e-5, step_loss=0.32]07/18/2023 19:08:03 - INFO - __main__ - train loss is 11.917969563277438\n",
      "Steps:   5%|▎    | 750/15000 [04:41<42:30,  5.59it/s, lr=1e-5, step_loss=0.0418]07/18/2023 19:08:03 - INFO - __main__ - train loss is 11.921720380429178\n",
      "Steps:   5%|▏   | 751/15000 [04:41<42:32,  5.58it/s, lr=1e-5, step_loss=0.00375]07/18/2023 19:08:03 - INFO - __main__ - train loss is 12.141214127186686\n",
      "Steps:   5%|▎     | 752/15000 [04:41<42:28,  5.59it/s, lr=1e-5, step_loss=0.219]07/18/2023 19:08:03 - INFO - __main__ - train loss is 12.240677366498858\n",
      "Steps:   5%|▎    | 753/15000 [04:41<42:23,  5.60it/s, lr=1e-5, step_loss=0.0995]07/18/2023 19:08:04 - INFO - __main__ - train loss is 12.389099220279604\n",
      "Steps:   5%|▎     | 754/15000 [04:41<42:20,  5.61it/s, lr=1e-5, step_loss=0.148]07/18/2023 19:08:04 - INFO - __main__ - train loss is 12.434605086687952\n",
      "Steps:   5%|▎    | 755/15000 [04:42<42:21,  5.61it/s, lr=1e-5, step_loss=0.0455]07/18/2023 19:08:04 - INFO - __main__ - train loss is 12.554553712252527\n",
      "Steps:   5%|▎      | 756/15000 [04:42<42:20,  5.61it/s, lr=1e-5, step_loss=0.12]07/18/2023 19:08:04 - INFO - __main__ - train loss is 12.56852393457666\n",
      "Steps:   5%|▎     | 757/15000 [04:42<42:44,  5.55it/s, lr=1e-5, step_loss=0.014]07/18/2023 19:08:04 - INFO - __main__ - train loss is 12.728383696172386\n",
      "Steps:   5%|▎      | 758/15000 [04:42<42:40,  5.56it/s, lr=1e-5, step_loss=0.16]07/18/2023 19:08:04 - INFO - __main__ - train loss is 12.73334395326674\n",
      "Steps:   5%|▏   | 759/15000 [04:42<42:34,  5.58it/s, lr=1e-5, step_loss=0.00496]07/18/2023 19:08:05 - INFO - __main__ - train loss is 12.74611534923315\n",
      "Steps:   5%|▎    | 760/15000 [04:42<42:32,  5.58it/s, lr=1e-5, step_loss=0.0128]07/18/2023 19:08:05 - INFO - __main__ - train loss is 12.760786143131554\n",
      "Steps:   5%|▎    | 761/15000 [04:43<42:26,  5.59it/s, lr=1e-5, step_loss=0.0147]07/18/2023 19:08:05 - INFO - __main__ - train loss is 12.763001572340727\n",
      "Steps:   5%|▏   | 762/15000 [04:43<42:50,  5.54it/s, lr=1e-5, step_loss=0.00222]07/18/2023 19:08:05 - INFO - __main__ - train loss is 12.828231904655695\n",
      "Steps:   5%|▎    | 763/15000 [04:43<42:45,  5.55it/s, lr=1e-5, step_loss=0.0652]07/18/2023 19:08:05 - INFO - __main__ - train loss is 12.853709368035197\n",
      "Steps:   5%|▎    | 764/15000 [04:43<42:35,  5.57it/s, lr=1e-5, step_loss=0.0255]07/18/2023 19:08:06 - INFO - __main__ - train loss is 12.92349242977798\n",
      "Steps:   5%|▎    | 765/15000 [04:43<42:28,  5.59it/s, lr=1e-5, step_loss=0.0698]07/18/2023 19:08:06 - INFO - __main__ - train loss is 13.008493779227138\n",
      "Steps:   5%|▎     | 766/15000 [04:44<42:47,  5.54it/s, lr=1e-5, step_loss=0.085]07/18/2023 19:08:06 - INFO - __main__ - train loss is 13.013264928478748\n",
      "Steps:   5%|▏   | 767/15000 [04:44<42:45,  5.55it/s, lr=1e-5, step_loss=0.00477]07/18/2023 19:08:06 - INFO - __main__ - train loss is 13.028226711321622\n",
      "Steps:   5%|▎     | 768/15000 [04:44<42:36,  5.57it/s, lr=1e-5, step_loss=0.015]07/18/2023 19:08:06 - INFO - __main__ - train loss is 13.194307931233197\n",
      "Steps:   5%|▎     | 769/15000 [04:44<42:28,  5.58it/s, lr=1e-5, step_loss=0.166]07/18/2023 19:08:06 - INFO - __main__ - train loss is 13.198988765012473\n",
      "Steps:   5%|▏   | 770/15000 [04:44<42:29,  5.58it/s, lr=1e-5, step_loss=0.00468]07/18/2023 19:08:07 - INFO - __main__ - train loss is 13.387782528530806\n",
      "Steps:   5%|▎     | 771/15000 [04:44<42:28,  5.58it/s, lr=1e-5, step_loss=0.189]07/18/2023 19:08:07 - INFO - __main__ - train loss is 13.64828099263832\n",
      "Steps:   5%|▎      | 772/15000 [04:45<42:24,  5.59it/s, lr=1e-5, step_loss=0.26]07/18/2023 19:08:07 - INFO - __main__ - train loss is 13.885439112316817\n",
      "Steps:   5%|▎     | 773/15000 [04:45<42:43,  5.55it/s, lr=1e-5, step_loss=0.237]07/18/2023 19:08:07 - INFO - __main__ - train loss is 13.918068788480014\n",
      "Steps:   5%|▎    | 774/15000 [04:45<42:32,  5.57it/s, lr=1e-5, step_loss=0.0326]07/18/2023 19:08:07 - INFO - __main__ - train loss is 14.024434856604785\n",
      "Steps:   5%|▎     | 775/15000 [04:45<42:25,  5.59it/s, lr=1e-5, step_loss=0.106]07/18/2023 19:08:08 - INFO - __main__ - train loss is 14.173735700082034\n",
      "Steps:   5%|▎     | 776/15000 [04:46<55:50,  4.25it/s, lr=1e-5, step_loss=0.149]07/18/2023 19:08:08 - INFO - __main__ - Per validation step average loss is 0.07012529671192169\n",
      "07/18/2023 19:08:08 - INFO - __main__ - Cumulative validation average loss is 0.07012529671192169\n",
      "07/18/2023 19:08:08 - INFO - __main__ - Per validation step average loss is 0.23950909078121185\n",
      "07/18/2023 19:08:08 - INFO - __main__ - Cumulative validation average loss is 0.30963438749313354\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.20636117458343506\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 0.5159955620765686\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.2215215116739273\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 0.7375170737504959\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.09512850642204285\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 0.8326455801725388\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.48005205392837524\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 1.312697634100914\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.021071814000606537\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 1.3337694481015205\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.046612419188022614\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 1.3803818672895432\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Per validation step average loss is 0.43892747163772583\n",
      "07/18/2023 19:08:09 - INFO - __main__ - Cumulative validation average loss is 1.819309338927269\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Per validation step average loss is 0.026478175073862076\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Cumulative validation average loss is 1.845787514001131\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Per validation step average loss is 0.049603063613176346\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Cumulative validation average loss is 1.8953905776143074\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Per validation step average loss is 0.008454103022813797\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Cumulative validation average loss is 1.9038446806371212\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Average validation loss for Epoch 7 is 0.15865372338642678\n",
      "07/18/2023 19:08:10 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:08:23 - INFO - __main__ - Starting epoch 8\n",
      "07/18/2023 19:08:23 - INFO - __main__ - train loss is 0.04357844218611717\n",
      "Steps:   5%|  | 777/15000 [05:01<19:04:27,  4.83s/it, lr=1e-5, step_loss=0.0436]07/18/2023 19:08:23 - INFO - __main__ - train loss is 0.6736424528062344\n",
      "Steps:   5%|▏   | 778/15000 [05:01<13:34:13,  3.44s/it, lr=1e-5, step_loss=0.63]07/18/2023 19:08:24 - INFO - __main__ - train loss is 1.4185146652162075\n",
      "Steps:   5%|▏   | 779/15000 [05:01<9:43:31,  2.46s/it, lr=1e-5, step_loss=0.745]07/18/2023 19:08:24 - INFO - __main__ - train loss is 1.4215548185165972\n",
      "Steps:   5%|  | 780/15000 [05:02<7:01:28,  1.78s/it, lr=1e-5, step_loss=0.00304]07/18/2023 19:08:24 - INFO - __main__ - train loss is 2.307082667713985\n",
      "Steps:   5%|▏   | 781/15000 [05:02<5:08:01,  1.30s/it, lr=1e-5, step_loss=0.886]07/18/2023 19:08:24 - INFO - __main__ - train loss is 2.3122016701381654\n",
      "Steps:   5%|  | 782/15000 [05:02<3:49:03,  1.03it/s, lr=1e-5, step_loss=0.00512]07/18/2023 19:08:24 - INFO - __main__ - train loss is 2.342411332530901\n",
      "Steps:   5%|▏  | 783/15000 [05:02<2:53:05,  1.37it/s, lr=1e-5, step_loss=0.0302]07/18/2023 19:08:25 - INFO - __main__ - train loss is 2.5926928154658526\n",
      "Steps:   5%|▎    | 784/15000 [05:02<2:13:47,  1.77it/s, lr=1e-5, step_loss=0.25]07/18/2023 19:08:25 - INFO - __main__ - train loss is 2.594928526552394\n",
      "Steps:   5%|  | 785/15000 [05:03<1:46:15,  2.23it/s, lr=1e-5, step_loss=0.00224]07/18/2023 19:08:25 - INFO - __main__ - train loss is 2.719373681815341\n",
      "Steps:   5%|▏   | 786/15000 [05:03<1:26:57,  2.72it/s, lr=1e-5, step_loss=0.124]07/18/2023 19:08:25 - INFO - __main__ - train loss is 2.843453997047618\n",
      "Steps:   5%|▏   | 787/15000 [05:03<1:13:34,  3.22it/s, lr=1e-5, step_loss=0.124]07/18/2023 19:08:25 - INFO - __main__ - train loss is 2.8458322670776397\n",
      "Steps:   5%|  | 788/15000 [05:03<1:04:06,  3.69it/s, lr=1e-5, step_loss=0.00238]07/18/2023 19:08:25 - INFO - __main__ - train loss is 2.890788496704772\n",
      "Steps:   5%|▎     | 789/15000 [05:03<57:26,  4.12it/s, lr=1e-5, step_loss=0.045]07/18/2023 19:08:26 - INFO - __main__ - train loss is 3.2400257599074394\n",
      "Steps:   5%|▎     | 790/15000 [05:03<52:47,  4.49it/s, lr=1e-5, step_loss=0.349]07/18/2023 19:08:26 - INFO - __main__ - train loss is 3.494387448998168\n",
      "Steps:   5%|▎     | 791/15000 [05:04<49:38,  4.77it/s, lr=1e-5, step_loss=0.254]07/18/2023 19:08:26 - INFO - __main__ - train loss is 3.6029316496569663\n",
      "Steps:   5%|▎     | 792/15000 [05:04<47:19,  5.00it/s, lr=1e-5, step_loss=0.109]07/18/2023 19:08:26 - INFO - __main__ - train loss is 3.950535209150985\n",
      "Steps:   5%|▎     | 793/15000 [05:04<45:43,  5.18it/s, lr=1e-5, step_loss=0.348]07/18/2023 19:08:26 - INFO - __main__ - train loss is 4.247485579224303\n",
      "Steps:   5%|▎     | 794/15000 [05:04<45:10,  5.24it/s, lr=1e-5, step_loss=0.297]07/18/2023 19:08:26 - INFO - __main__ - train loss is 4.2510437574237585\n",
      "Steps:   5%|▏   | 795/15000 [05:04<44:48,  5.28it/s, lr=1e-5, step_loss=0.00356]07/18/2023 19:08:27 - INFO - __main__ - train loss is 4.256616679485887\n",
      "Steps:   5%|▏   | 796/15000 [05:05<44:12,  5.35it/s, lr=1e-5, step_loss=0.00557]07/18/2023 19:08:27 - INFO - __main__ - train loss is 4.510627982672304\n",
      "Steps:   5%|▎     | 797/15000 [05:05<43:35,  5.43it/s, lr=1e-5, step_loss=0.254]07/18/2023 19:08:27 - INFO - __main__ - train loss is 5.012790081556886\n",
      "Steps:   5%|▎     | 798/15000 [05:05<43:11,  5.48it/s, lr=1e-5, step_loss=0.502]07/18/2023 19:08:27 - INFO - __main__ - train loss is 5.121541579719633\n",
      "Steps:   5%|▎     | 799/15000 [05:05<42:54,  5.52it/s, lr=1e-5, step_loss=0.109]07/18/2023 19:08:27 - INFO - __main__ - train loss is 5.271121253725141\n",
      "Steps:   5%|▎      | 800/15000 [05:05<42:59,  5.50it/s, lr=1e-5, step_loss=0.15]07/18/2023 19:08:28 - INFO - __main__ - train loss is 5.4856553128920496\n",
      "Steps:   5%|▎     | 801/15000 [05:05<42:49,  5.53it/s, lr=1e-5, step_loss=0.215]07/18/2023 19:08:28 - INFO - __main__ - train loss is 5.500666131731123\n",
      "Steps:   5%|▎     | 802/15000 [05:06<42:41,  5.54it/s, lr=1e-5, step_loss=0.015]07/18/2023 19:08:28 - INFO - __main__ - train loss is 5.8057992360554636\n",
      "Steps:   5%|▎     | 803/15000 [05:06<42:30,  5.57it/s, lr=1e-5, step_loss=0.305]07/18/2023 19:08:28 - INFO - __main__ - train loss is 6.081743439193815\n",
      "Steps:   5%|▎     | 804/15000 [05:06<42:24,  5.58it/s, lr=1e-5, step_loss=0.276]07/18/2023 19:08:28 - INFO - __main__ - train loss is 6.0953741748817265\n",
      "Steps:   5%|▎    | 805/15000 [05:06<42:20,  5.59it/s, lr=1e-5, step_loss=0.0136]07/18/2023 19:08:28 - INFO - __main__ - train loss is 6.103397885803133\n",
      "Steps:   5%|▏   | 806/15000 [05:06<42:37,  5.55it/s, lr=1e-5, step_loss=0.00802]07/18/2023 19:08:29 - INFO - __main__ - train loss is 6.1215837323106825\n",
      "Steps:   5%|▎    | 807/15000 [05:07<42:27,  5.57it/s, lr=1e-5, step_loss=0.0182]07/18/2023 19:08:29 - INFO - __main__ - train loss is 6.635789724532515\n",
      "Steps:   5%|▎     | 808/15000 [05:07<42:21,  5.58it/s, lr=1e-5, step_loss=0.514]07/18/2023 19:08:29 - INFO - __main__ - train loss is 6.6614486486651\n",
      "Steps:   5%|▎    | 809/15000 [05:07<42:28,  5.57it/s, lr=1e-5, step_loss=0.0257]07/18/2023 19:08:29 - INFO - __main__ - train loss is 7.2607368738390505\n",
      "Steps:   5%|▎     | 810/15000 [05:07<42:22,  5.58it/s, lr=1e-5, step_loss=0.599]07/18/2023 19:08:29 - INFO - __main__ - train loss is 7.263259907253087\n",
      "Steps:   5%|▏   | 811/15000 [05:07<42:21,  5.58it/s, lr=1e-5, step_loss=0.00252]07/18/2023 19:08:30 - INFO - __main__ - train loss is 7.584345598705113\n",
      "Steps:   5%|▎     | 812/15000 [05:07<42:39,  5.54it/s, lr=1e-5, step_loss=0.321]07/18/2023 19:08:30 - INFO - __main__ - train loss is 7.603460458107293\n",
      "Steps:   5%|▎    | 813/15000 [05:08<42:55,  5.51it/s, lr=1e-5, step_loss=0.0191]07/18/2023 19:08:30 - INFO - __main__ - train loss is 7.6061972957104445\n",
      "Steps:   5%|▏   | 814/15000 [05:08<43:01,  5.50it/s, lr=1e-5, step_loss=0.00274]07/18/2023 19:08:30 - INFO - __main__ - train loss is 7.629075735807419\n",
      "Steps:   5%|▎    | 815/15000 [05:08<42:45,  5.53it/s, lr=1e-5, step_loss=0.0229]07/18/2023 19:08:30 - INFO - __main__ - train loss is 7.6323532005771995\n",
      "Steps:   5%|▏   | 816/15000 [05:08<42:35,  5.55it/s, lr=1e-5, step_loss=0.00328]07/18/2023 19:08:30 - INFO - __main__ - train loss is 7.681652109138668\n",
      "Steps:   5%|▎    | 817/15000 [05:08<42:27,  5.57it/s, lr=1e-5, step_loss=0.0493]07/18/2023 19:08:31 - INFO - __main__ - train loss is 8.066777656786144\n",
      "Steps:   5%|▎     | 818/15000 [05:08<42:21,  5.58it/s, lr=1e-5, step_loss=0.385]07/18/2023 19:08:31 - INFO - __main__ - train loss is 8.074678084813058\n",
      "Steps:   5%|▎    | 819/15000 [05:09<42:17,  5.59it/s, lr=1e-5, step_loss=0.0079]07/18/2023 19:08:31 - INFO - __main__ - train loss is 8.156814909540117\n",
      "Steps:   5%|▎    | 820/15000 [05:09<42:13,  5.60it/s, lr=1e-5, step_loss=0.0821]07/18/2023 19:08:31 - INFO - __main__ - train loss is 8.226870781742036\n",
      "Steps:   5%|▎    | 821/15000 [05:09<42:11,  5.60it/s, lr=1e-5, step_loss=0.0701]07/18/2023 19:08:31 - INFO - __main__ - train loss is 8.264735146425664\n",
      "Steps:   5%|▎    | 822/15000 [05:09<42:13,  5.60it/s, lr=1e-5, step_loss=0.0379]07/18/2023 19:08:31 - INFO - __main__ - train loss is 8.267435400979593\n",
      "Steps:   5%|▎    | 823/15000 [05:09<42:11,  5.60it/s, lr=1e-5, step_loss=0.0027]07/18/2023 19:08:32 - INFO - __main__ - train loss is 8.555297642247751\n",
      "Steps:   5%|▎     | 824/15000 [05:10<42:11,  5.60it/s, lr=1e-5, step_loss=0.288]07/18/2023 19:08:32 - INFO - __main__ - train loss is 8.57735902373679\n",
      "Steps:   6%|▎    | 825/15000 [05:10<42:09,  5.60it/s, lr=1e-5, step_loss=0.0221]07/18/2023 19:08:32 - INFO - __main__ - train loss is 9.03504830901511\n",
      "Steps:   6%|▎     | 826/15000 [05:10<42:07,  5.61it/s, lr=1e-5, step_loss=0.458]07/18/2023 19:08:32 - INFO - __main__ - train loss is 9.03740332648158\n",
      "Steps:   6%|▏   | 827/15000 [05:10<42:24,  5.57it/s, lr=1e-5, step_loss=0.00236]07/18/2023 19:08:32 - INFO - __main__ - train loss is 9.04496357915923\n",
      "Steps:   6%|▏   | 828/15000 [05:10<42:35,  5.55it/s, lr=1e-5, step_loss=0.00756]07/18/2023 19:08:33 - INFO - __main__ - train loss is 9.066552496980876\n",
      "Steps:   6%|▎    | 829/15000 [05:10<42:26,  5.57it/s, lr=1e-5, step_loss=0.0216]07/18/2023 19:08:33 - INFO - __main__ - train loss is 9.06997334305197\n",
      "Steps:   6%|▏   | 830/15000 [05:11<42:20,  5.58it/s, lr=1e-5, step_loss=0.00342]07/18/2023 19:08:33 - INFO - __main__ - train loss is 9.262602471746504\n",
      "Steps:   6%|▎     | 831/15000 [05:11<42:38,  5.54it/s, lr=1e-5, step_loss=0.193]07/18/2023 19:08:33 - INFO - __main__ - train loss is 9.265287712682039\n",
      "Steps:   6%|▏   | 832/15000 [05:11<42:35,  5.54it/s, lr=1e-5, step_loss=0.00269]07/18/2023 19:08:33 - INFO - __main__ - train loss is 9.283645553980023\n",
      "Steps:   6%|▎    | 833/15000 [05:11<42:26,  5.56it/s, lr=1e-5, step_loss=0.0184]07/18/2023 19:08:33 - INFO - __main__ - train loss is 9.610172195825726\n",
      "Steps:   6%|▎     | 834/15000 [05:11<42:35,  5.54it/s, lr=1e-5, step_loss=0.327]07/18/2023 19:08:34 - INFO - __main__ - train loss is 10.113623841200024\n",
      "Steps:   6%|▎     | 835/15000 [05:12<42:26,  5.56it/s, lr=1e-5, step_loss=0.503]07/18/2023 19:08:34 - INFO - __main__ - train loss is 10.433835668954998\n",
      "Steps:   6%|▍      | 836/15000 [05:12<42:19,  5.58it/s, lr=1e-5, step_loss=0.32]07/18/2023 19:08:34 - INFO - __main__ - train loss is 10.819807691965252\n",
      "Steps:   6%|▎     | 837/15000 [05:12<42:32,  5.55it/s, lr=1e-5, step_loss=0.386]07/18/2023 19:08:34 - INFO - __main__ - train loss is 11.189163430128247\n",
      "Steps:   6%|▎     | 838/15000 [05:12<42:46,  5.52it/s, lr=1e-5, step_loss=0.369]07/18/2023 19:08:34 - INFO - __main__ - train loss is 11.298056213650852\n",
      "Steps:   6%|▎     | 839/15000 [05:12<42:40,  5.53it/s, lr=1e-5, step_loss=0.109]07/18/2023 19:08:35 - INFO - __main__ - train loss is 11.302103991154581\n",
      "Steps:   6%|▏   | 840/15000 [05:12<42:51,  5.51it/s, lr=1e-5, step_loss=0.00405]07/18/2023 19:08:35 - INFO - __main__ - train loss is 11.433562646154314\n",
      "Steps:   6%|▎     | 841/15000 [05:13<43:14,  5.46it/s, lr=1e-5, step_loss=0.131]07/18/2023 19:08:35 - INFO - __main__ - train loss is 11.726768205408007\n",
      "Steps:   6%|▎     | 842/15000 [05:13<43:35,  5.41it/s, lr=1e-5, step_loss=0.293]07/18/2023 19:08:35 - INFO - __main__ - train loss is 11.738768043462187\n",
      "Steps:   6%|▎     | 843/15000 [05:13<43:07,  5.47it/s, lr=1e-5, step_loss=0.012]07/18/2023 19:08:35 - INFO - __main__ - train loss is 11.744163780938834\n",
      "Steps:   6%|▎    | 844/15000 [05:13<43:08,  5.47it/s, lr=1e-5, step_loss=0.0054]07/18/2023 19:08:35 - INFO - __main__ - train loss is 11.765431385021657\n",
      "Steps:   6%|▎    | 845/15000 [05:13<42:48,  5.51it/s, lr=1e-5, step_loss=0.0213]07/18/2023 19:08:36 - INFO - __main__ - train loss is 11.778616543393582\n",
      "Steps:   6%|▎    | 846/15000 [05:14<42:35,  5.54it/s, lr=1e-5, step_loss=0.0132]07/18/2023 19:08:36 - INFO - __main__ - train loss is 11.827988985460252\n",
      "Steps:   6%|▎    | 847/15000 [05:14<42:46,  5.51it/s, lr=1e-5, step_loss=0.0494]07/18/2023 19:08:36 - INFO - __main__ - train loss is 11.863380707334727\n",
      "Steps:   6%|▎    | 848/15000 [05:14<42:45,  5.52it/s, lr=1e-5, step_loss=0.0354]07/18/2023 19:08:36 - INFO - __main__ - train loss is 11.905918605159968\n",
      "Steps:   6%|▎    | 849/15000 [05:14<42:43,  5.52it/s, lr=1e-5, step_loss=0.0425]07/18/2023 19:08:36 - INFO - __main__ - train loss is 11.973200656007975\n",
      "Steps:   6%|▎    | 850/15000 [05:14<42:39,  5.53it/s, lr=1e-5, step_loss=0.0673]07/18/2023 19:08:37 - INFO - __main__ - train loss is 12.419778920244426\n",
      "Steps:   6%|▎     | 851/15000 [05:14<42:38,  5.53it/s, lr=1e-5, step_loss=0.447]07/18/2023 19:08:37 - INFO - __main__ - train loss is 12.510672740172595\n",
      "Steps:   6%|▎    | 852/15000 [05:15<42:40,  5.52it/s, lr=1e-5, step_loss=0.0909]07/18/2023 19:08:37 - INFO - __main__ - train loss is 12.513411319348961\n",
      "Steps:   6%|▏   | 853/15000 [05:15<42:37,  5.53it/s, lr=1e-5, step_loss=0.00274]07/18/2023 19:08:37 - INFO - __main__ - train loss is 12.881312525365502\n",
      "Steps:   6%|▎     | 854/15000 [05:15<42:34,  5.54it/s, lr=1e-5, step_loss=0.368]07/18/2023 19:08:37 - INFO - __main__ - train loss is 12.887429852504283\n",
      "Steps:   6%|▏   | 855/15000 [05:15<42:35,  5.54it/s, lr=1e-5, step_loss=0.00612]07/18/2023 19:08:37 - INFO - __main__ - train loss is 12.911894698161632\n",
      "Steps:   6%|▎    | 856/15000 [05:15<42:34,  5.54it/s, lr=1e-5, step_loss=0.0245]07/18/2023 19:08:38 - INFO - __main__ - train loss is 13.27994765760377\n",
      "Steps:   6%|▎     | 857/15000 [05:16<42:20,  5.57it/s, lr=1e-5, step_loss=0.368]07/18/2023 19:08:38 - INFO - __main__ - train loss is 13.298608631361276\n",
      "Steps:   6%|▎    | 858/15000 [05:16<42:13,  5.58it/s, lr=1e-5, step_loss=0.0187]07/18/2023 19:08:38 - INFO - __main__ - train loss is 13.30347056640312\n",
      "Steps:   6%|▏   | 859/15000 [05:16<42:07,  5.59it/s, lr=1e-5, step_loss=0.00486]07/18/2023 19:08:38 - INFO - __main__ - train loss is 13.343475088011473\n",
      "Steps:   6%|▍      | 860/15000 [05:16<42:01,  5.61it/s, lr=1e-5, step_loss=0.04]07/18/2023 19:08:38 - INFO - __main__ - train loss is 13.451785973738879\n",
      "Steps:   6%|▎     | 861/15000 [05:16<41:57,  5.62it/s, lr=1e-5, step_loss=0.108]07/18/2023 19:08:39 - INFO - __main__ - train loss is 13.880455754231662\n",
      "Steps:   6%|▎     | 862/15000 [05:16<42:00,  5.61it/s, lr=1e-5, step_loss=0.429]07/18/2023 19:08:39 - INFO - __main__ - train loss is 13.93276261491701\n",
      "Steps:   6%|▎    | 863/15000 [05:17<41:57,  5.62it/s, lr=1e-5, step_loss=0.0523]07/18/2023 19:08:39 - INFO - __main__ - train loss is 13.936738498974591\n",
      "Steps:   6%|▏   | 864/15000 [05:17<41:55,  5.62it/s, lr=1e-5, step_loss=0.00398]07/18/2023 19:08:39 - INFO - __main__ - train loss is 13.94042020267807\n",
      "Steps:   6%|▏   | 865/15000 [05:17<42:00,  5.61it/s, lr=1e-5, step_loss=0.00368]07/18/2023 19:08:39 - INFO - __main__ - train loss is 13.949136718874797\n",
      "Steps:   6%| | 866/15000 [05:17<41:56,  5.62it/s, lr=9.99e-6, step_loss=0.00872]07/18/2023 19:08:39 - INFO - __main__ - train loss is 14.389611169463024\n",
      "Steps:   6%|▏   | 867/15000 [05:17<41:54,  5.62it/s, lr=9.99e-6, step_loss=0.44]07/18/2023 19:08:40 - INFO - __main__ - train loss is 14.468976974254474\n",
      "Steps:   6%|  | 868/15000 [05:17<41:52,  5.62it/s, lr=9.99e-6, step_loss=0.0794]07/18/2023 19:08:40 - INFO - __main__ - train loss is 14.487091231858358\n",
      "Steps:   6%|  | 869/15000 [05:18<42:02,  5.60it/s, lr=9.99e-6, step_loss=0.0181]07/18/2023 19:08:40 - INFO - __main__ - train loss is 15.07424907735549\n",
      "Steps:   6%|▏  | 870/15000 [05:18<41:59,  5.61it/s, lr=9.99e-6, step_loss=0.587]07/18/2023 19:08:40 - INFO - __main__ - train loss is 15.461972344433889\n",
      "Steps:   6%|▏  | 871/15000 [05:18<41:58,  5.61it/s, lr=9.99e-6, step_loss=0.388]07/18/2023 19:08:40 - INFO - __main__ - train loss is 15.463645195704885\n",
      "Steps:   6%| | 872/15000 [05:18<41:55,  5.62it/s, lr=9.99e-6, step_loss=0.00167]07/18/2023 19:08:41 - INFO - __main__ - train loss is 15.518260697019286\n",
      "Steps:   6%|  | 873/15000 [05:19<54:38,  4.31it/s, lr=9.99e-6, step_loss=0.0546]07/18/2023 19:08:41 - INFO - __main__ - Per validation step average loss is 0.3671582341194153\n",
      "07/18/2023 19:08:41 - INFO - __main__ - Cumulative validation average loss is 0.3671582341194153\n",
      "07/18/2023 19:08:41 - INFO - __main__ - Per validation step average loss is 0.00282022706232965\n",
      "07/18/2023 19:08:41 - INFO - __main__ - Cumulative validation average loss is 0.36997846118174493\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Per validation step average loss is 0.01471003983169794\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Cumulative validation average loss is 0.3846885010134429\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Per validation step average loss is 0.005617802031338215\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Cumulative validation average loss is 0.3903063030447811\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Per validation step average loss is 0.17883983254432678\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Cumulative validation average loss is 0.5691461355891079\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Per validation step average loss is 0.0431457981467247\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Cumulative validation average loss is 0.6122919337358326\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Per validation step average loss is 0.1280762106180191\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Cumulative validation average loss is 0.7403681443538517\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Per validation step average loss is 0.006291349418461323\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Cumulative validation average loss is 0.746659493772313\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Per validation step average loss is 0.003141739871352911\n",
      "07/18/2023 19:08:42 - INFO - __main__ - Cumulative validation average loss is 0.7498012336436659\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Per validation step average loss is 0.04988325387239456\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Cumulative validation average loss is 0.7996844875160605\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Per validation step average loss is 0.006273371167480946\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Cumulative validation average loss is 0.8059578586835414\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Per validation step average loss is 0.31247085332870483\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Cumulative validation average loss is 1.1184287120122463\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Average validation loss for Epoch 8 is 0.09320239266768719\n",
      "07/18/2023 19:08:43 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:08:56 - INFO - __main__ - Starting epoch 9\n",
      "07/18/2023 19:08:56 - INFO - __main__ - train loss is 0.005737964995205402\n",
      "Steps:   6%| | 874/15000 [05:34<19:02:31,  4.85s/it, lr=9.99e-6, step_loss=0.00507/18/2023 19:08:56 - INFO - __main__ - train loss is 0.018713838420808315\n",
      "Steps:   6%| | 875/15000 [05:34<13:32:33,  3.45s/it, lr=9.99e-6, step_loss=0.01307/18/2023 19:08:57 - INFO - __main__ - train loss is 0.044239952228963375\n",
      "Steps:   6%| | 876/15000 [05:35<9:41:18,  2.47s/it, lr=9.99e-6, step_loss=0.025507/18/2023 19:08:57 - INFO - __main__ - train loss is 0.476106776855886\n",
      "Steps:   6%| | 877/15000 [05:35<6:59:33,  1.78s/it, lr=9.99e-6, step_loss=0.432]07/18/2023 19:08:57 - INFO - __main__ - train loss is 0.478719272185117\n",
      "Steps:   6%| | 878/15000 [05:35<5:06:34,  1.30s/it, lr=9.99e-6, step_loss=0.002607/18/2023 19:08:57 - INFO - __main__ - train loss is 0.5019514099694788\n",
      "Steps:   6%| | 879/15000 [05:35<3:47:15,  1.04it/s, lr=9.99e-6, step_loss=0.023207/18/2023 19:08:57 - INFO - __main__ - train loss is 0.5761715234257281\n",
      "Steps:   6%| | 880/15000 [05:35<2:51:41,  1.37it/s, lr=9.99e-6, step_loss=0.074207/18/2023 19:08:58 - INFO - __main__ - train loss is 0.593270240817219\n",
      "Steps:   6%| | 881/15000 [05:35<2:12:43,  1.77it/s, lr=9.99e-6, step_loss=0.017107/18/2023 19:08:58 - INFO - __main__ - train loss is 0.6290032886900008\n",
      "Steps:   6%| | 882/15000 [05:36<1:45:33,  2.23it/s, lr=9.99e-6, step_loss=0.035707/18/2023 19:08:58 - INFO - __main__ - train loss is 0.6425018082372844\n",
      "Steps:   6%| | 883/15000 [05:36<1:26:48,  2.71it/s, lr=9.99e-6, step_loss=0.013507/18/2023 19:08:58 - INFO - __main__ - train loss is 0.6572908773086965\n",
      "Steps:   6%| | 884/15000 [05:36<1:13:59,  3.18it/s, lr=9.99e-6, step_loss=0.014807/18/2023 19:08:58 - INFO - __main__ - train loss is 0.6703764530830085\n",
      "Steps:   6%| | 885/15000 [05:36<1:04:41,  3.64it/s, lr=9.99e-6, step_loss=0.013107/18/2023 19:08:58 - INFO - __main__ - train loss is 0.6814407161436975\n",
      "Steps:   6%|  | 886/15000 [05:36<57:57,  4.06it/s, lr=9.99e-6, step_loss=0.0111]07/18/2023 19:08:59 - INFO - __main__ - train loss is 0.9736499241553247\n",
      "Steps:   6%|▏  | 887/15000 [05:37<53:24,  4.40it/s, lr=9.99e-6, step_loss=0.292]07/18/2023 19:08:59 - INFO - __main__ - train loss is 0.9756977341603488\n",
      "Steps:   6%| | 888/15000 [05:37<49:55,  4.71it/s, lr=9.99e-6, step_loss=0.00205]07/18/2023 19:08:59 - INFO - __main__ - train loss is 1.7562162659596652\n",
      "Steps:   6%|▏  | 889/15000 [05:37<47:46,  4.92it/s, lr=9.99e-6, step_loss=0.781]07/18/2023 19:08:59 - INFO - __main__ - train loss is 2.0107159696053714\n",
      "Steps:   6%|▏  | 890/15000 [05:37<46:20,  5.07it/s, lr=9.99e-6, step_loss=0.254]07/18/2023 19:08:59 - INFO - __main__ - train loss is 2.1098445139359683\n",
      "Steps:   6%|  | 891/15000 [05:37<45:09,  5.21it/s, lr=9.99e-6, step_loss=0.0991]07/18/2023 19:09:00 - INFO - __main__ - train loss is 2.1821836091112345\n",
      "Steps:   6%|  | 892/15000 [05:37<44:15,  5.31it/s, lr=9.99e-6, step_loss=0.0723]07/18/2023 19:09:00 - INFO - __main__ - train loss is 2.787595675094053\n",
      "Steps:   6%|▏  | 893/15000 [05:38<43:32,  5.40it/s, lr=9.99e-6, step_loss=0.605]07/18/2023 19:09:00 - INFO - __main__ - train loss is 2.817160428268835\n",
      "Steps:   6%|  | 894/15000 [05:38<43:01,  5.46it/s, lr=9.99e-6, step_loss=0.0296]07/18/2023 19:09:00 - INFO - __main__ - train loss is 3.1252021498512477\n",
      "Steps:   6%|▏  | 895/15000 [05:38<42:40,  5.51it/s, lr=9.99e-6, step_loss=0.308]07/18/2023 19:09:00 - INFO - __main__ - train loss is 3.1500369131099433\n",
      "Steps:   6%|  | 896/15000 [05:38<42:29,  5.53it/s, lr=9.99e-6, step_loss=0.0248]07/18/2023 19:09:00 - INFO - __main__ - train loss is 3.1553486168850213\n",
      "Steps:   6%| | 897/15000 [05:38<42:18,  5.56it/s, lr=9.99e-6, step_loss=0.00531]07/18/2023 19:09:01 - INFO - __main__ - train loss is 3.217293477850035\n",
      "Steps:   6%|  | 898/15000 [05:39<42:11,  5.57it/s, lr=9.99e-6, step_loss=0.0619]07/18/2023 19:09:01 - INFO - __main__ - train loss is 3.2214525977615267\n",
      "Steps:   6%| | 899/15000 [05:39<42:07,  5.58it/s, lr=9.99e-6, step_loss=0.00416]07/18/2023 19:09:01 - INFO - __main__ - train loss is 3.3738510499242693\n",
      "Steps:   6%|▏  | 900/15000 [05:39<42:03,  5.59it/s, lr=9.99e-6, step_loss=0.152]07/18/2023 19:09:01 - INFO - __main__ - train loss is 3.555949945235625\n",
      "Steps:   6%|▏  | 901/15000 [05:39<42:00,  5.59it/s, lr=9.99e-6, step_loss=0.182]07/18/2023 19:09:01 - INFO - __main__ - train loss is 3.57481336616911\n",
      "Steps:   6%|  | 902/15000 [05:39<41:58,  5.60it/s, lr=9.99e-6, step_loss=0.0189]07/18/2023 19:09:02 - INFO - __main__ - train loss is 3.808337033027783\n",
      "Steps:   6%|▏  | 903/15000 [05:39<41:53,  5.61it/s, lr=9.99e-6, step_loss=0.234]07/18/2023 19:09:02 - INFO - __main__ - train loss is 3.8105068707372993\n",
      "Steps:   6%| | 904/15000 [05:40<41:51,  5.61it/s, lr=9.99e-6, step_loss=0.00217]07/18/2023 19:09:02 - INFO - __main__ - train loss is 3.9770784282591194\n",
      "Steps:   6%|▏  | 905/15000 [05:40<41:48,  5.62it/s, lr=9.99e-6, step_loss=0.167]07/18/2023 19:09:02 - INFO - __main__ - train loss is 3.9854367522057146\n",
      "Steps:   6%| | 906/15000 [05:40<41:48,  5.62it/s, lr=9.99e-6, step_loss=0.00836]07/18/2023 19:09:02 - INFO - __main__ - train loss is 4.792773142224178\n",
      "Steps:   6%|▏  | 907/15000 [05:40<41:47,  5.62it/s, lr=9.99e-6, step_loss=0.807]07/18/2023 19:09:02 - INFO - __main__ - train loss is 4.926097765332088\n",
      "Steps:   6%|▏  | 908/15000 [05:40<41:50,  5.61it/s, lr=9.99e-6, step_loss=0.133]07/18/2023 19:09:03 - INFO - __main__ - train loss is 5.204961046343669\n",
      "Steps:   6%|▏  | 909/15000 [05:40<42:11,  5.57it/s, lr=9.99e-6, step_loss=0.279]07/18/2023 19:09:03 - INFO - __main__ - train loss is 5.226138591533527\n",
      "Steps:   6%|  | 910/15000 [05:41<42:16,  5.56it/s, lr=9.99e-6, step_loss=0.0212]07/18/2023 19:09:03 - INFO - __main__ - train loss is 5.2605157343205065\n",
      "Steps:   6%|  | 911/15000 [05:41<42:12,  5.56it/s, lr=9.99e-6, step_loss=0.0344]07/18/2023 19:09:03 - INFO - __main__ - train loss is 5.4653228966053575\n",
      "Steps:   6%|▏  | 912/15000 [05:41<42:05,  5.58it/s, lr=9.99e-6, step_loss=0.205]07/18/2023 19:09:03 - INFO - __main__ - train loss is 5.474228312028572\n",
      "Steps:   6%| | 913/15000 [05:41<41:59,  5.59it/s, lr=9.99e-6, step_loss=0.00891]07/18/2023 19:09:03 - INFO - __main__ - train loss is 5.6311405196320266\n",
      "Steps:   6%|▏  | 914/15000 [05:41<41:58,  5.59it/s, lr=9.99e-6, step_loss=0.157]07/18/2023 19:09:04 - INFO - __main__ - train loss is 5.644435668131337\n",
      "Steps:   6%|  | 915/15000 [05:42<41:54,  5.60it/s, lr=9.99e-6, step_loss=0.0133]07/18/2023 19:09:04 - INFO - __main__ - train loss is 5.849360698601231\n",
      "Steps:   6%|▏  | 916/15000 [05:42<41:50,  5.61it/s, lr=9.99e-6, step_loss=0.205]07/18/2023 19:09:04 - INFO - __main__ - train loss is 5.965139562031254\n",
      "Steps:   6%|▏  | 917/15000 [05:42<41:53,  5.60it/s, lr=9.99e-6, step_loss=0.116]07/18/2023 19:09:04 - INFO - __main__ - train loss is 5.9703539030160755\n",
      "Steps:   6%| | 918/15000 [05:42<41:51,  5.61it/s, lr=9.99e-6, step_loss=0.00521]07/18/2023 19:09:04 - INFO - __main__ - train loss is 6.278818310936913\n",
      "Steps:   6%|▏  | 919/15000 [05:42<41:48,  5.61it/s, lr=9.99e-6, step_loss=0.308]07/18/2023 19:09:05 - INFO - __main__ - train loss is 6.662967534502968\n",
      "Steps:   6%|▏  | 920/15000 [05:42<41:46,  5.62it/s, lr=9.99e-6, step_loss=0.384]07/18/2023 19:09:05 - INFO - __main__ - train loss is 6.93800208135508\n",
      "Steps:   6%|▏  | 921/15000 [05:43<41:44,  5.62it/s, lr=9.99e-6, step_loss=0.275]07/18/2023 19:09:05 - INFO - __main__ - train loss is 7.225921751698479\n",
      "Steps:   6%|▏  | 922/15000 [05:43<41:44,  5.62it/s, lr=9.99e-6, step_loss=0.288]07/18/2023 19:09:05 - INFO - __main__ - train loss is 7.99495923682116\n",
      "Steps:   6%|▏  | 923/15000 [05:43<41:43,  5.62it/s, lr=9.99e-6, step_loss=0.769]07/18/2023 19:09:05 - INFO - __main__ - train loss is 8.202401967486367\n",
      "Steps:   6%|▏  | 924/15000 [05:43<41:43,  5.62it/s, lr=9.99e-6, step_loss=0.207]07/18/2023 19:09:05 - INFO - __main__ - train loss is 8.353200824698433\n",
      "Steps:   6%|▏  | 925/15000 [05:43<41:43,  5.62it/s, lr=9.99e-6, step_loss=0.151]07/18/2023 19:09:06 - INFO - __main__ - train loss is 8.355856431415305\n",
      "Steps:   6%| | 926/15000 [05:44<41:44,  5.62it/s, lr=9.99e-6, step_loss=0.00266]07/18/2023 19:09:06 - INFO - __main__ - train loss is 8.618412030627951\n",
      "Steps:   6%|▏  | 927/15000 [05:44<41:48,  5.61it/s, lr=9.99e-6, step_loss=0.263]07/18/2023 19:09:06 - INFO - __main__ - train loss is 8.832140607526526\n",
      "Steps:   6%|▏  | 928/15000 [05:44<41:52,  5.60it/s, lr=9.99e-6, step_loss=0.214]07/18/2023 19:09:06 - INFO - __main__ - train loss is 8.872156152268872\n",
      "Steps:   6%|▏   | 929/15000 [05:44<41:48,  5.61it/s, lr=9.99e-6, step_loss=0.04]07/18/2023 19:09:06 - INFO - __main__ - train loss is 8.884181950008497\n",
      "Steps:   6%|▏  | 930/15000 [05:44<41:47,  5.61it/s, lr=9.99e-6, step_loss=0.012]07/18/2023 19:09:07 - INFO - __main__ - train loss is 8.891519220313057\n",
      "Steps:   6%| | 931/15000 [05:44<41:44,  5.62it/s, lr=9.99e-6, step_loss=0.00734]07/18/2023 19:09:07 - INFO - __main__ - train loss is 9.056787447771057\n",
      "Steps:   6%|▏  | 932/15000 [05:45<41:47,  5.61it/s, lr=9.99e-6, step_loss=0.165]07/18/2023 19:09:07 - INFO - __main__ - train loss is 9.244786934694275\n",
      "Steps:   6%|▏  | 933/15000 [05:45<41:47,  5.61it/s, lr=9.99e-6, step_loss=0.188]07/18/2023 19:09:07 - INFO - __main__ - train loss is 9.529355184873566\n",
      "Steps:   6%|▏  | 934/15000 [05:45<41:46,  5.61it/s, lr=9.99e-6, step_loss=0.285]07/18/2023 19:09:07 - INFO - __main__ - train loss is 9.605035194894299\n",
      "Steps:   6%|  | 935/15000 [05:45<41:45,  5.61it/s, lr=9.99e-6, step_loss=0.0757]07/18/2023 19:09:07 - INFO - __main__ - train loss is 9.641480626305565\n",
      "Steps:   6%|  | 936/15000 [05:45<41:43,  5.62it/s, lr=9.99e-6, step_loss=0.0364]07/18/2023 19:09:08 - INFO - __main__ - train loss is 9.831827284535393\n",
      "Steps:   6%|▏   | 937/15000 [05:45<41:43,  5.62it/s, lr=9.99e-6, step_loss=0.19]07/18/2023 19:09:08 - INFO - __main__ - train loss is 9.835678111296147\n",
      "Steps:   6%| | 938/15000 [05:46<41:43,  5.62it/s, lr=9.99e-6, step_loss=0.00385]07/18/2023 19:09:08 - INFO - __main__ - train loss is 9.8557107928209\n",
      "Steps:   6%|▎   | 939/15000 [05:46<41:43,  5.62it/s, lr=9.99e-6, step_loss=0.02]07/18/2023 19:09:08 - INFO - __main__ - train loss is 9.990481320302933\n",
      "Steps:   6%|▏  | 940/15000 [05:46<41:41,  5.62it/s, lr=9.99e-6, step_loss=0.135]07/18/2023 19:09:08 - INFO - __main__ - train loss is 10.1567491623573\n",
      "Steps:   6%|▏  | 941/15000 [05:46<41:39,  5.62it/s, lr=9.99e-6, step_loss=0.166]07/18/2023 19:09:08 - INFO - __main__ - train loss is 10.264620009344071\n",
      "Steps:   6%|▏  | 942/15000 [05:46<41:39,  5.62it/s, lr=9.99e-6, step_loss=0.108]07/18/2023 19:09:09 - INFO - __main__ - train loss is 10.368006322067231\n",
      "Steps:   6%|▏  | 943/15000 [05:47<42:03,  5.57it/s, lr=9.99e-6, step_loss=0.103]07/18/2023 19:09:09 - INFO - __main__ - train loss is 10.626454267185181\n",
      "Steps:   6%|▏  | 944/15000 [05:47<42:17,  5.54it/s, lr=9.99e-6, step_loss=0.258]07/18/2023 19:09:09 - INFO - __main__ - train loss is 10.686424757819623\n",
      "Steps:   6%|▎   | 945/15000 [05:47<42:07,  5.56it/s, lr=9.99e-6, step_loss=0.06]07/18/2023 19:09:09 - INFO - __main__ - train loss is 10.695896320510656\n",
      "Steps:   6%| | 946/15000 [05:47<41:57,  5.58it/s, lr=9.99e-6, step_loss=0.00947]07/18/2023 19:09:09 - INFO - __main__ - train loss is 10.721128579694778\n",
      "Steps:   6%|▏ | 947/15000 [05:47<41:51,  5.60it/s, lr=9.99e-6, step_loss=0.0252]07/18/2023 19:09:10 - INFO - __main__ - train loss is 10.933912110049278\n",
      "Steps:   6%|▏  | 948/15000 [05:47<41:47,  5.60it/s, lr=9.99e-6, step_loss=0.213]07/18/2023 19:09:10 - INFO - __main__ - train loss is 11.028534036595374\n",
      "Steps:   6%|▏ | 949/15000 [05:48<41:45,  5.61it/s, lr=9.99e-6, step_loss=0.0946]07/18/2023 19:09:10 - INFO - __main__ - train loss is 11.14231999637559\n",
      "Steps:   6%|▏  | 950/15000 [05:48<41:42,  5.61it/s, lr=9.99e-6, step_loss=0.114]07/18/2023 19:09:10 - INFO - __main__ - train loss is 11.300033737439662\n",
      "Steps:   6%|▏  | 951/15000 [05:48<41:40,  5.62it/s, lr=9.99e-6, step_loss=0.158]07/18/2023 19:09:10 - INFO - __main__ - train loss is 11.532317806500942\n",
      "Steps:   6%|▏  | 952/15000 [05:48<41:38,  5.62it/s, lr=9.99e-6, step_loss=0.232]07/18/2023 19:09:10 - INFO - __main__ - train loss is 11.657661561388522\n",
      "Steps:   6%|▏  | 953/15000 [05:48<41:39,  5.62it/s, lr=9.99e-6, step_loss=0.125]07/18/2023 19:09:11 - INFO - __main__ - train loss is 11.659729428589344\n",
      "Steps:   6%| | 954/15000 [05:49<41:35,  5.63it/s, lr=9.99e-6, step_loss=0.00207]07/18/2023 19:09:11 - INFO - __main__ - train loss is 11.866339467465878\n",
      "Steps:   6%|▏  | 955/15000 [05:49<41:36,  5.62it/s, lr=9.99e-6, step_loss=0.207]07/18/2023 19:09:11 - INFO - __main__ - train loss is 12.203776381909847\n",
      "Steps:   6%|▏  | 956/15000 [05:49<41:33,  5.63it/s, lr=9.99e-6, step_loss=0.337]07/18/2023 19:09:11 - INFO - __main__ - train loss is 12.205334784230217\n",
      "Steps:   6%| | 957/15000 [05:49<41:33,  5.63it/s, lr=9.99e-6, step_loss=0.00156]07/18/2023 19:09:11 - INFO - __main__ - train loss is 12.222319453721866\n",
      "Steps:   6%|▏  | 958/15000 [05:49<41:34,  5.63it/s, lr=9.99e-6, step_loss=0.017]07/18/2023 19:09:12 - INFO - __main__ - train loss is 12.238776221638545\n",
      "Steps:   6%|▏ | 959/15000 [05:49<41:33,  5.63it/s, lr=9.99e-6, step_loss=0.0165]07/18/2023 19:09:12 - INFO - __main__ - train loss is 12.249787915265188\n",
      "Steps:   6%|▏  | 960/15000 [05:50<41:32,  5.63it/s, lr=9.99e-6, step_loss=0.011]07/18/2023 19:09:12 - INFO - __main__ - train loss is 12.252871568547562\n",
      "Steps:   6%| | 961/15000 [05:50<41:31,  5.63it/s, lr=9.99e-6, step_loss=0.00308]07/18/2023 19:09:12 - INFO - __main__ - train loss is 12.305182877229527\n",
      "Steps:   6%|▏ | 962/15000 [05:50<41:31,  5.63it/s, lr=9.99e-6, step_loss=0.0523]07/18/2023 19:09:12 - INFO - __main__ - train loss is 12.556307795690373\n",
      "Steps:   6%|▏  | 963/15000 [05:50<41:30,  5.64it/s, lr=9.99e-6, step_loss=0.251]07/18/2023 19:09:12 - INFO - __main__ - train loss is 12.74404454533942\n",
      "Steps:   6%|▏  | 964/15000 [05:50<41:29,  5.64it/s, lr=9.99e-6, step_loss=0.188]07/18/2023 19:09:13 - INFO - __main__ - train loss is 13.271293941186741\n",
      "Steps:   6%|▏  | 965/15000 [05:50<41:30,  5.64it/s, lr=9.99e-6, step_loss=0.527]07/18/2023 19:09:13 - INFO - __main__ - train loss is 13.28804738377221\n",
      "Steps:   6%|▏ | 966/15000 [05:51<41:30,  5.63it/s, lr=9.99e-6, step_loss=0.0168]07/18/2023 19:09:13 - INFO - __main__ - train loss is 13.301044399151579\n",
      "Steps:   6%|▏  | 967/15000 [05:51<41:31,  5.63it/s, lr=9.99e-6, step_loss=0.013]07/18/2023 19:09:13 - INFO - __main__ - train loss is 13.388915600487962\n",
      "Steps:   6%|▏ | 968/15000 [05:51<41:30,  5.64it/s, lr=9.99e-6, step_loss=0.0879]07/18/2023 19:09:13 - INFO - __main__ - train loss is 13.407838529208675\n",
      "Steps:   6%|▏ | 969/15000 [05:51<41:30,  5.63it/s, lr=9.99e-6, step_loss=0.0189]07/18/2023 19:09:14 - INFO - __main__ - train loss is 13.410263372818008\n",
      "Steps:   6%| | 970/15000 [05:52<56:40,  4.13it/s, lr=9.99e-6, step_loss=0.00242]07/18/2023 19:09:14 - INFO - __main__ - Per validation step average loss is 0.049678925424814224\n",
      "07/18/2023 19:09:14 - INFO - __main__ - Cumulative validation average loss is 0.049678925424814224\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Per validation step average loss is 0.2899729907512665\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Cumulative validation average loss is 0.3396519161760807\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Per validation step average loss is 0.7275578379631042\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Cumulative validation average loss is 1.067209754139185\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Per validation step average loss is 0.0018483629683032632\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Cumulative validation average loss is 1.0690581171074882\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Per validation step average loss is 0.005962902680039406\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Cumulative validation average loss is 1.0750210197875276\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Per validation step average loss is 0.013466019183397293\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Cumulative validation average loss is 1.088487038970925\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Per validation step average loss is 0.12700718641281128\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Cumulative validation average loss is 1.2154942253837362\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Per validation step average loss is 0.0017127515748143196\n",
      "07/18/2023 19:09:15 - INFO - __main__ - Cumulative validation average loss is 1.2172069769585505\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Per validation step average loss is 0.0683167576789856\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Cumulative validation average loss is 1.285523734637536\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Per validation step average loss is 0.29827675223350525\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Cumulative validation average loss is 1.5838004868710414\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Per validation step average loss is 0.002339097671210766\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Cumulative validation average loss is 1.5861395845422521\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Per validation step average loss is 0.011323985643684864\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Cumulative validation average loss is 1.597463570185937\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Average validation loss for Epoch 9 is 0.1331219641821614\n",
      "07/18/2023 19:09:16 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:09:29 - INFO - __main__ - Starting epoch 10\n",
      "07/18/2023 19:09:30 - INFO - __main__ - train loss is 0.08459416776895523\n",
      "Steps:   6%| | 971/15000 [06:08<19:24:10,  4.98s/it, lr=9.99e-6, step_loss=0.08407/18/2023 19:09:30 - INFO - __main__ - train loss is 0.6150868311524391\n",
      "Steps:   6%| | 972/15000 [06:08<14:13:54,  3.65s/it, lr=9.99e-6, step_loss=0.53]07/18/2023 19:09:31 - INFO - __main__ - train loss is 0.7480275109410286\n",
      "Steps:   6%| | 973/15000 [06:09<10:36:23,  2.72s/it, lr=9.99e-6, step_loss=0.13307/18/2023 19:09:31 - INFO - __main__ - train loss is 0.7899708971381187\n",
      "Steps:   6%| | 974/15000 [06:09<8:03:03,  2.07s/it, lr=9.99e-6, step_loss=0.041907/18/2023 19:09:32 - INFO - __main__ - train loss is 0.8909981846809387\n",
      "Steps:   6%| | 975/15000 [06:10<6:16:17,  1.61s/it, lr=9.99e-6, step_loss=0.101]07/18/2023 19:09:32 - INFO - __main__ - train loss is 0.9543391838669777\n",
      "Steps:   7%| | 976/15000 [06:10<5:01:08,  1.29s/it, lr=9.99e-6, step_loss=0.063307/18/2023 19:09:33 - INFO - __main__ - train loss is 1.0469728633761406\n",
      "Steps:   7%| | 977/15000 [06:11<4:08:54,  1.06s/it, lr=9.99e-6, step_loss=0.092607/18/2023 19:09:34 - INFO - __main__ - train loss is 1.1315597593784332\n",
      "Steps:   7%| | 978/15000 [06:11<3:32:15,  1.10it/s, lr=9.99e-6, step_loss=0.084607/18/2023 19:09:34 - INFO - __main__ - train loss is 1.1962609589099884\n",
      "Steps:   7%| | 979/15000 [06:12<3:06:15,  1.25it/s, lr=9.99e-6, step_loss=0.064707/18/2023 19:09:35 - INFO - __main__ - train loss is 1.4837311208248138\n",
      "Steps:   7%| | 980/15000 [06:12<2:48:16,  1.39it/s, lr=9.99e-6, step_loss=0.287]07/18/2023 19:09:35 - INFO - __main__ - train loss is 2.0935955345630646\n",
      "Steps:   7%|▏ | 981/15000 [06:13<2:36:39,  1.49it/s, lr=9.99e-6, step_loss=0.61]07/18/2023 19:09:36 - INFO - __main__ - train loss is 2.2776912301778793\n",
      "Steps:   7%| | 982/15000 [06:14<2:27:36,  1.58it/s, lr=9.99e-6, step_loss=0.184]07/18/2023 19:09:36 - INFO - __main__ - train loss is 2.775639310479164\n",
      "Steps:   7%| | 983/15000 [06:14<2:21:37,  1.65it/s, lr=9.99e-6, step_loss=0.498]07/18/2023 19:09:37 - INFO - __main__ - train loss is 2.93316750228405\n",
      "Steps:   7%| | 984/15000 [06:15<2:17:07,  1.70it/s, lr=9.99e-6, step_loss=0.158]07/18/2023 19:09:37 - INFO - __main__ - train loss is 2.9751930087804794\n",
      "Steps:   7%| | 985/15000 [06:15<2:14:06,  1.74it/s, lr=9.99e-6, step_loss=0.042]07/18/2023 19:09:38 - INFO - __main__ - train loss is 2.977250815369189\n",
      "Steps:   7%| | 986/15000 [06:16<2:11:52,  1.77it/s, lr=9.99e-6, step_loss=0.002007/18/2023 19:09:38 - INFO - __main__ - train loss is 3.021178820170462\n",
      "Steps:   7%| | 987/15000 [06:16<2:10:57,  1.78it/s, lr=9.99e-6, step_loss=0.043907/18/2023 19:09:39 - INFO - __main__ - train loss is 3.0879423627629876\n",
      "Steps:   7%| | 988/15000 [06:17<2:09:33,  1.80it/s, lr=9.99e-6, step_loss=0.066807/18/2023 19:09:40 - INFO - __main__ - train loss is 3.120828882791102\n",
      "Steps:   7%| | 989/15000 [06:17<2:09:40,  1.80it/s, lr=9.99e-6, step_loss=0.032907/18/2023 19:09:40 - INFO - __main__ - train loss is 3.1229010480456054\n",
      "Steps:   7%| | 990/15000 [06:18<2:10:11,  1.79it/s, lr=9.99e-6, step_loss=0.002007/18/2023 19:09:41 - INFO - __main__ - train loss is 3.125929923960939\n",
      "Steps:   7%| | 991/15000 [06:19<2:08:59,  1.81it/s, lr=9.99e-6, step_loss=0.003007/18/2023 19:09:41 - INFO - __main__ - train loss is 3.129731134744361\n",
      "Steps:   7%| | 992/15000 [06:19<2:08:50,  1.81it/s, lr=9.99e-6, step_loss=0.003807/18/2023 19:09:42 - INFO - __main__ - train loss is 3.132056381786242\n",
      "Steps:   7%| | 993/15000 [06:20<2:08:47,  1.81it/s, lr=9.99e-6, step_loss=0.002307/18/2023 19:09:42 - INFO - __main__ - train loss is 3.2716246808413416\n",
      "Steps:   7%|▏ | 994/15000 [06:20<2:08:36,  1.81it/s, lr=9.99e-6, step_loss=0.14]07/18/2023 19:09:43 - INFO - __main__ - train loss is 3.55669316300191\n",
      "Steps:   7%| | 995/15000 [06:21<2:08:24,  1.82it/s, lr=9.99e-6, step_loss=0.285]07/18/2023 19:09:43 - INFO - __main__ - train loss is 3.6683978030923754\n",
      "Steps:   7%| | 996/15000 [06:21<2:07:49,  1.83it/s, lr=9.99e-6, step_loss=0.112]07/18/2023 19:09:44 - INFO - __main__ - train loss is 3.700009055668488\n",
      "Steps:   7%| | 997/15000 [06:22<2:07:58,  1.82it/s, lr=9.99e-6, step_loss=0.031607/18/2023 19:09:44 - INFO - __main__ - train loss is 4.037283785874024\n",
      "Steps:   7%| | 998/15000 [06:22<2:07:29,  1.83it/s, lr=9.99e-6, step_loss=0.337]07/18/2023 19:09:45 - INFO - __main__ - train loss is 4.167400159174576\n",
      "Steps:   7%|▏ | 999/15000 [06:23<2:07:26,  1.83it/s, lr=9.99e-6, step_loss=0.13]07/18/2023 19:09:46 - INFO - __main__ - train loss is 4.294976122910157\n",
      "Steps:   7%| | 1000/15000 [06:23<2:07:20,  1.83it/s, lr=9.99e-6, step_loss=0.13]07/18/2023 19:09:46 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-1000\n",
      "07/18/2023 19:09:46 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:09:46,132] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:09:46,136] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:09:46,136] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:09:46,143] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:09:46,143] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:09:46,150] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:09:46,151] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:09:46,151] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:09:46 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-1000/pytorch_model\n",
      "07/18/2023 19:09:46 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-1000/scheduler.bin\n",
      "07/18/2023 19:09:46 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-1000/random_states_0.pkl\n",
      "07/18/2023 19:09:46 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-1000\n",
      "Steps:   7%| | 1000/15000 [06:23<2:07:20,  1.83it/s, lr=9.99e-6, step_loss=0.12807/18/2023 19:09:46 - INFO - __main__ - train loss is 4.299829819472507\n",
      "Steps:   7%| | 1001/15000 [06:24<2:08:59,  1.81it/s, lr=9.99e-6, step_loss=0.00407/18/2023 19:09:47 - INFO - __main__ - train loss is 4.305815921863541\n",
      "Steps:   7%| | 1002/15000 [06:25<2:08:06,  1.82it/s, lr=9.99e-6, step_loss=0.00507/18/2023 19:09:47 - INFO - __main__ - train loss is 5.0198774801101536\n",
      "Steps:   7%| | 1003/15000 [06:25<2:07:52,  1.82it/s, lr=9.99e-6, step_loss=0.71407/18/2023 19:09:48 - INFO - __main__ - train loss is 5.064071515342221\n",
      "Steps:   7%| | 1004/15000 [06:26<2:07:37,  1.83it/s, lr=9.99e-6, step_loss=0.04407/18/2023 19:09:48 - INFO - __main__ - train loss is 5.820838132640347\n",
      "Steps:   7%| | 1005/15000 [06:26<2:07:40,  1.83it/s, lr=9.99e-6, step_loss=0.75707/18/2023 19:09:49 - INFO - __main__ - train loss is 5.829252952476963\n",
      "Steps:   7%| | 1006/15000 [06:27<2:08:05,  1.82it/s, lr=9.99e-6, step_loss=0.00807/18/2023 19:09:49 - INFO - __main__ - train loss is 6.325324291130528\n",
      "Steps:   7%| | 1007/15000 [06:27<2:08:15,  1.82it/s, lr=9.99e-6, step_loss=0.49607/18/2023 19:09:50 - INFO - __main__ - train loss is 6.34441072284244\n",
      "Steps:   7%| | 1008/15000 [06:28<2:08:06,  1.82it/s, lr=9.99e-6, step_loss=0.01907/18/2023 19:09:50 - INFO - __main__ - train loss is 6.477740948786959\n",
      "Steps:   7%| | 1009/15000 [06:28<2:07:43,  1.83it/s, lr=9.99e-6, step_loss=0.13307/18/2023 19:09:51 - INFO - __main__ - train loss is 6.937092786421999\n",
      "Steps:   7%| | 1010/15000 [06:29<2:07:37,  1.83it/s, lr=9.99e-6, step_loss=0.45907/18/2023 19:09:52 - INFO - __main__ - train loss is 7.134922405472025\n",
      "Steps:   7%| | 1011/15000 [06:29<2:07:09,  1.83it/s, lr=9.99e-6, step_loss=0.19807/18/2023 19:09:52 - INFO - __main__ - train loss is 7.144299253588542\n",
      "Steps:   7%| | 1012/15000 [06:30<2:06:59,  1.84it/s, lr=9.99e-6, step_loss=0.00907/18/2023 19:09:53 - INFO - __main__ - train loss is 7.239944979315624\n",
      "Steps:   7%| | 1013/15000 [06:31<2:07:09,  1.83it/s, lr=9.99e-6, step_loss=0.09507/18/2023 19:09:53 - INFO - __main__ - train loss is 7.351981162792072\n",
      "Steps:   7%| | 1014/15000 [06:31<2:07:07,  1.83it/s, lr=9.99e-6, step_loss=0.11207/18/2023 19:09:54 - INFO - __main__ - train loss is 7.415085151558742\n",
      "Steps:   7%| | 1015/15000 [06:32<2:07:14,  1.83it/s, lr=9.99e-6, step_loss=0.06307/18/2023 19:09:54 - INFO - __main__ - train loss is 7.419489059364423\n",
      "Steps:   7%| | 1016/15000 [06:32<2:08:32,  1.81it/s, lr=9.99e-6, step_loss=0.00407/18/2023 19:09:55 - INFO - __main__ - train loss is 7.453701454913244\n",
      "Steps:   7%| | 1017/15000 [06:33<2:07:59,  1.82it/s, lr=9.99e-6, step_loss=0.03407/18/2023 19:09:55 - INFO - __main__ - train loss is 7.463843691861257\n",
      "Steps:   7%| | 1018/15000 [06:33<2:07:56,  1.82it/s, lr=9.99e-6, step_loss=0.01007/18/2023 19:09:56 - INFO - __main__ - train loss is 7.470241991104558\n",
      "Steps:   7%| | 1019/15000 [06:34<2:07:33,  1.83it/s, lr=9.99e-6, step_loss=0.00607/18/2023 19:09:57 - INFO - __main__ - train loss is 7.791124788345769\n",
      "Steps:   7%| | 1020/15000 [06:34<2:07:32,  1.83it/s, lr=9.99e-6, step_loss=0.32107/18/2023 19:09:57 - INFO - __main__ - train loss is 7.808192041935399\n",
      "Steps:   7%| | 1021/15000 [06:35<2:06:43,  1.84it/s, lr=9.99e-6, step_loss=0.01707/18/2023 19:09:58 - INFO - __main__ - train loss is 7.970931214513257\n",
      "Steps:   7%| | 1022/15000 [06:35<2:06:40,  1.84it/s, lr=9.99e-6, step_loss=0.16307/18/2023 19:09:58 - INFO - __main__ - train loss is 8.257347208680585\n",
      "Steps:   7%| | 1023/15000 [06:36<2:07:10,  1.83it/s, lr=9.99e-6, step_loss=0.28607/18/2023 19:09:59 - INFO - __main__ - train loss is 8.302795474650338\n",
      "Steps:   7%| | 1024/15000 [06:37<2:07:17,  1.83it/s, lr=9.99e-6, step_loss=0.04507/18/2023 19:09:59 - INFO - __main__ - train loss is 8.414923493983224\n",
      "Steps:   7%| | 1025/15000 [06:37<2:08:34,  1.81it/s, lr=9.99e-6, step_loss=0.11207/18/2023 19:10:00 - INFO - __main__ - train loss is 8.635231171967462\n",
      "Steps:   7%| | 1026/15000 [06:38<2:08:25,  1.81it/s, lr=9.99e-6, step_loss=0.22]07/18/2023 19:10:00 - INFO - __main__ - train loss is 8.807847385527566\n",
      "Steps:   7%| | 1027/15000 [06:38<2:07:49,  1.82it/s, lr=9.99e-6, step_loss=0.17307/18/2023 19:10:01 - INFO - __main__ - train loss is 8.83002740633674\n",
      "Steps:   7%| | 1028/15000 [06:39<2:07:50,  1.82it/s, lr=9.99e-6, step_loss=0.02207/18/2023 19:10:01 - INFO - __main__ - train loss is 8.962346305372193\n",
      "Steps:   7%| | 1029/15000 [06:39<2:06:58,  1.83it/s, lr=9.99e-6, step_loss=0.13207/18/2023 19:10:02 - INFO - __main__ - train loss is 8.96661260095425\n",
      "Steps:   7%| | 1030/15000 [06:40<2:06:56,  1.83it/s, lr=9.99e-6, step_loss=0.00407/18/2023 19:10:03 - INFO - __main__ - train loss is 9.062996440799907\n",
      "Steps:   7%| | 1031/15000 [06:40<2:06:42,  1.84it/s, lr=9.99e-6, step_loss=0.09607/18/2023 19:10:03 - INFO - __main__ - train loss is 9.19384824601002\n",
      "Steps:   7%| | 1032/15000 [06:41<2:06:36,  1.84it/s, lr=9.99e-6, step_loss=0.13107/18/2023 19:10:04 - INFO - __main__ - train loss is 9.222155085997656\n",
      "Steps:   7%| | 1033/15000 [06:41<2:06:05,  1.85it/s, lr=9.99e-6, step_loss=0.02807/18/2023 19:10:04 - INFO - __main__ - train loss is 9.69194685597904\n",
      "Steps:   7%| | 1034/15000 [06:42<2:07:37,  1.82it/s, lr=9.99e-6, step_loss=0.47]07/18/2023 19:10:05 - INFO - __main__ - train loss is 9.793769455747679\n",
      "Steps:   7%| | 1035/15000 [06:43<2:08:31,  1.81it/s, lr=9.99e-6, step_loss=0.10207/18/2023 19:10:05 - INFO - __main__ - train loss is 9.7997741533909\n",
      "Steps:   7%| | 1036/15000 [06:43<2:07:42,  1.82it/s, lr=9.99e-6, step_loss=0.00607/18/2023 19:10:06 - INFO - __main__ - train loss is 10.272300584474578\n",
      "Steps:   7%| | 1037/15000 [06:44<2:07:14,  1.83it/s, lr=9.99e-6, step_loss=0.47307/18/2023 19:10:06 - INFO - __main__ - train loss is 10.39120668754913\n",
      "Steps:   7%| | 1038/15000 [06:44<2:06:37,  1.84it/s, lr=9.99e-6, step_loss=0.11907/18/2023 19:10:07 - INFO - __main__ - train loss is 10.699895328143612\n",
      "Steps:   7%| | 1039/15000 [06:45<2:06:38,  1.84it/s, lr=9.99e-6, step_loss=0.30907/18/2023 19:10:07 - INFO - __main__ - train loss is 10.994516140082851\n",
      "Steps:   7%| | 1040/15000 [06:45<2:06:18,  1.84it/s, lr=9.99e-6, step_loss=0.29507/18/2023 19:10:08 - INFO - __main__ - train loss is 11.262517815688625\n",
      "Steps:   7%| | 1041/15000 [06:46<2:06:09,  1.84it/s, lr=9.99e-6, step_loss=0.26807/18/2023 19:10:09 - INFO - __main__ - train loss is 11.400790428975597\n",
      "Steps:   7%| | 1042/15000 [06:46<2:06:30,  1.84it/s, lr=9.99e-6, step_loss=0.13807/18/2023 19:10:09 - INFO - __main__ - train loss is 11.640627464512363\n",
      "Steps:   7%| | 1043/15000 [06:47<2:06:34,  1.84it/s, lr=9.99e-6, step_loss=0.24]07/18/2023 19:10:10 - INFO - __main__ - train loss is 11.644376960815862\n",
      "Steps:   7%| | 1044/15000 [06:47<2:06:03,  1.85it/s, lr=9.99e-6, step_loss=0.00307/18/2023 19:10:10 - INFO - __main__ - train loss is 11.670319385128096\n",
      "Steps:   7%| | 1045/15000 [06:48<2:06:09,  1.84it/s, lr=9.99e-6, step_loss=0.02507/18/2023 19:10:11 - INFO - __main__ - train loss is 11.744197494583204\n",
      "Steps:   7%| | 1046/15000 [06:49<2:06:41,  1.84it/s, lr=9.99e-6, step_loss=0.07307/18/2023 19:10:11 - INFO - __main__ - train loss is 11.753835958661512\n",
      "Steps:   7%| | 1047/15000 [06:49<2:06:31,  1.84it/s, lr=9.99e-6, step_loss=0.00907/18/2023 19:10:12 - INFO - __main__ - train loss is 11.860769053222612\n",
      "Steps:   7%| | 1048/15000 [06:50<2:06:23,  1.84it/s, lr=9.99e-6, step_loss=0.10707/18/2023 19:10:12 - INFO - __main__ - train loss is 12.216805418254808\n",
      "Steps:   7%| | 1049/15000 [06:50<2:06:16,  1.84it/s, lr=9.99e-6, step_loss=0.35607/18/2023 19:10:13 - INFO - __main__ - train loss is 12.34286301326938\n",
      "Steps:   7%| | 1050/15000 [06:51<2:05:57,  1.85it/s, lr=9.99e-6, step_loss=0.12607/18/2023 19:10:13 - INFO - __main__ - train loss is 12.416192871751264\n",
      "Steps:   7%| | 1051/15000 [06:51<2:06:05,  1.84it/s, lr=9.99e-6, step_loss=0.07307/18/2023 19:10:14 - INFO - __main__ - train loss is 13.065953594865277\n",
      "Steps:   7%| | 1052/15000 [06:52<2:06:05,  1.84it/s, lr=9.99e-6, step_loss=0.65]07/18/2023 19:10:14 - INFO - __main__ - train loss is 13.118171998532489\n",
      "Steps:   7%| | 1053/15000 [06:52<2:06:55,  1.83it/s, lr=9.99e-6, step_loss=0.05207/18/2023 19:10:15 - INFO - __main__ - train loss is 13.178928689332679\n",
      "Steps:   7%| | 1054/15000 [06:53<2:06:43,  1.83it/s, lr=9.99e-6, step_loss=0.06007/18/2023 19:10:16 - INFO - __main__ - train loss is 13.523882911773399\n",
      "Steps:   7%| | 1055/15000 [06:53<2:06:24,  1.84it/s, lr=9.99e-6, step_loss=0.34507/18/2023 19:10:16 - INFO - __main__ - train loss is 13.536459125811234\n",
      "Steps:   7%| | 1056/15000 [06:54<2:06:36,  1.84it/s, lr=9.99e-6, step_loss=0.01207/18/2023 19:10:17 - INFO - __main__ - train loss is 13.884799756342545\n",
      "Steps:   7%| | 1057/15000 [06:55<2:08:44,  1.81it/s, lr=9.99e-6, step_loss=0.34807/18/2023 19:10:17 - INFO - __main__ - train loss is 13.89321437687613\n",
      "Steps:   7%| | 1058/15000 [06:55<2:07:42,  1.82it/s, lr=9.99e-6, step_loss=0.00807/18/2023 19:10:18 - INFO - __main__ - train loss is 14.055877896258608\n",
      "Steps:   7%| | 1059/15000 [06:56<2:07:13,  1.83it/s, lr=9.99e-6, step_loss=0.16307/18/2023 19:10:18 - INFO - __main__ - train loss is 14.10948764742352\n",
      "Steps:   7%| | 1060/15000 [06:56<2:06:34,  1.84it/s, lr=9.99e-6, step_loss=0.05307/18/2023 19:10:19 - INFO - __main__ - train loss is 14.114708820125088\n",
      "Steps:   7%| | 1061/15000 [06:57<2:05:53,  1.85it/s, lr=9.99e-6, step_loss=0.00507/18/2023 19:10:19 - INFO - __main__ - train loss is 14.507853248855099\n",
      "Steps:   7%| | 1062/15000 [06:57<2:05:48,  1.85it/s, lr=9.99e-6, step_loss=0.39307/18/2023 19:10:20 - INFO - __main__ - train loss is 14.516229244647548\n",
      "Steps:   7%| | 1063/15000 [06:58<2:05:35,  1.85it/s, lr=9.99e-6, step_loss=0.00807/18/2023 19:10:20 - INFO - __main__ - train loss is 14.52559300023131\n",
      "Steps:   7%| | 1064/15000 [06:58<2:05:19,  1.85it/s, lr=9.99e-6, step_loss=0.00907/18/2023 19:10:21 - INFO - __main__ - train loss is 14.753354924498126\n",
      "Steps:   7%| | 1065/15000 [06:59<2:05:15,  1.85it/s, lr=9.99e-6, step_loss=0.22807/18/2023 19:10:22 - INFO - __main__ - train loss is 14.765024595661089\n",
      "Steps:   7%| | 1066/15000 [06:59<2:05:36,  1.85it/s, lr=9.99e-6, step_loss=0.01107/18/2023 19:10:22 - INFO - __main__ - train loss is 14.79199903900735\n",
      "Steps:   7%| | 1067/15000 [07:00<2:23:10,  1.62it/s, lr=9.99e-6, step_loss=0.02707/18/2023 19:10:23 - INFO - __main__ - Per validation step average loss is 0.26441383361816406\n",
      "07/18/2023 19:10:23 - INFO - __main__ - Cumulative validation average loss is 0.26441383361816406\n",
      "07/18/2023 19:10:23 - INFO - __main__ - Per validation step average loss is 0.1803949624300003\n",
      "07/18/2023 19:10:23 - INFO - __main__ - Cumulative validation average loss is 0.44480879604816437\n",
      "07/18/2023 19:10:23 - INFO - __main__ - Per validation step average loss is 0.8396409749984741\n",
      "07/18/2023 19:10:23 - INFO - __main__ - Cumulative validation average loss is 1.2844497710466385\n",
      "07/18/2023 19:10:23 - INFO - __main__ - Per validation step average loss is 0.1682223230600357\n",
      "07/18/2023 19:10:23 - INFO - __main__ - Cumulative validation average loss is 1.4526720941066742\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Per validation step average loss is 0.037775203585624695\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Cumulative validation average loss is 1.490447297692299\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Per validation step average loss is 0.2960100769996643\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Cumulative validation average loss is 1.7864573746919632\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Per validation step average loss is 0.03447332978248596\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Cumulative validation average loss is 1.8209307044744492\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Per validation step average loss is 0.005209409631788731\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Cumulative validation average loss is 1.8261401141062379\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Per validation step average loss is 0.1238747388124466\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Cumulative validation average loss is 1.9500148529186845\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Per validation step average loss is 0.006296258419752121\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Cumulative validation average loss is 1.9563111113384366\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Per validation step average loss is 0.02536684274673462\n",
      "07/18/2023 19:10:24 - INFO - __main__ - Cumulative validation average loss is 1.9816779540851712\n",
      "07/18/2023 19:10:25 - INFO - __main__ - Per validation step average loss is 0.02438555657863617\n",
      "07/18/2023 19:10:25 - INFO - __main__ - Cumulative validation average loss is 2.0060635106638074\n",
      "07/18/2023 19:10:25 - INFO - __main__ - Average validation loss for Epoch 10 is 0.16717195922198394\n",
      "07/18/2023 19:10:25 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:10:37 - INFO - __main__ - Starting epoch 11\n",
      "07/18/2023 19:10:38 - INFO - __main__ - train loss is 0.0025072689168155193\n",
      "Steps:   7%| | 1068/15000 [07:16<19:45:46,  5.11s/it, lr=9.99e-6, step_loss=0.0007/18/2023 19:10:38 - INFO - __main__ - train loss is 0.006980627775192261\n",
      "Steps:   7%| | 1069/15000 [07:16<14:02:26,  3.63s/it, lr=9.99e-6, step_loss=0.0007/18/2023 19:10:38 - INFO - __main__ - train loss is 0.14842744171619415\n",
      "Steps:   7%| | 1070/15000 [07:16<10:02:30,  2.60s/it, lr=9.99e-6, step_loss=0.1407/18/2023 19:10:38 - INFO - __main__ - train loss is 0.15062372060492635\n",
      "Steps:   7%| | 1071/15000 [07:16<7:15:55,  1.88s/it, lr=9.99e-6, step_loss=0.00207/18/2023 19:10:39 - INFO - __main__ - train loss is 0.4103317675180733\n",
      "Steps:   7%| | 1072/15000 [07:17<5:20:54,  1.38s/it, lr=9.99e-6, step_loss=0.26]07/18/2023 19:10:39 - INFO - __main__ - train loss is 0.4207555125467479\n",
      "Steps:   7%| | 1073/15000 [07:17<3:59:59,  1.03s/it, lr=9.99e-6, step_loss=0.01007/18/2023 19:10:39 - INFO - __main__ - train loss is 0.5461586783640087\n",
      "Steps:   7%| | 1074/15000 [07:17<3:02:03,  1.27it/s, lr=9.99e-6, step_loss=0.12507/18/2023 19:10:39 - INFO - __main__ - train loss is 0.5569089171476662\n",
      "Steps:   7%| | 1075/15000 [07:17<2:20:33,  1.65it/s, lr=9.99e-6, step_loss=0.01007/18/2023 19:10:40 - INFO - __main__ - train loss is 0.7491315719671547\n",
      "Steps:   7%| | 1076/15000 [07:17<1:50:52,  2.09it/s, lr=9.99e-6, step_loss=0.19207/18/2023 19:10:40 - INFO - __main__ - train loss is 1.0226953742094338\n",
      "Steps:   7%| | 1077/15000 [07:18<1:29:59,  2.58it/s, lr=9.99e-6, step_loss=0.27407/18/2023 19:10:40 - INFO - __main__ - train loss is 1.0321205467917025\n",
      "Steps:   7%| | 1078/15000 [07:18<1:15:21,  3.08it/s, lr=9.99e-6, step_loss=0.00907/18/2023 19:10:40 - INFO - __main__ - train loss is 1.0470313471741974\n",
      "Steps:   7%| | 1079/15000 [07:18<1:05:07,  3.56it/s, lr=9.99e-6, step_loss=0.01407/18/2023 19:10:40 - INFO - __main__ - train loss is 1.2507980805821717\n",
      "Steps:   7%|▏ | 1080/15000 [07:18<58:20,  3.98it/s, lr=9.99e-6, step_loss=0.204]07/18/2023 19:10:40 - INFO - __main__ - train loss is 1.6635265094228089\n",
      "Steps:   7%|▏ | 1081/15000 [07:18<53:48,  4.31it/s, lr=9.99e-6, step_loss=0.413]07/18/2023 19:10:41 - INFO - __main__ - train loss is 1.66548769059591\n",
      "Steps:   7%| | 1082/15000 [07:18<50:27,  4.60it/s, lr=9.99e-6, step_loss=0.0019607/18/2023 19:10:41 - INFO - __main__ - train loss is 1.6705592449288815\n",
      "Steps:   7%| | 1083/15000 [07:19<47:49,  4.85it/s, lr=9.99e-6, step_loss=0.0050707/18/2023 19:10:41 - INFO - __main__ - train loss is 1.762014391599223\n",
      "Steps:   7%| | 1084/15000 [07:19<45:53,  5.05it/s, lr=9.99e-6, step_loss=0.0915]07/18/2023 19:10:41 - INFO - __main__ - train loss is 1.7658290066756308\n",
      "Steps:   7%| | 1085/15000 [07:19<44:55,  5.16it/s, lr=9.99e-6, step_loss=0.0038107/18/2023 19:10:41 - INFO - __main__ - train loss is 1.7828345824964345\n",
      "Steps:   7%|▏ | 1086/15000 [07:19<43:54,  5.28it/s, lr=9.99e-6, step_loss=0.017]07/18/2023 19:10:42 - INFO - __main__ - train loss is 1.7974876132793725\n",
      "Steps:   7%| | 1087/15000 [07:19<43:15,  5.36it/s, lr=9.99e-6, step_loss=0.0147]07/18/2023 19:10:42 - INFO - __main__ - train loss is 1.800201239529997\n",
      "Steps:   7%| | 1088/15000 [07:20<43:47,  5.29it/s, lr=9.99e-6, step_loss=0.0027107/18/2023 19:10:42 - INFO - __main__ - train loss is 1.8081169188953936\n",
      "Steps:   7%| | 1089/15000 [07:20<44:11,  5.25it/s, lr=9.99e-6, step_loss=0.0079207/18/2023 19:10:42 - INFO - __main__ - train loss is 2.4716675938107073\n",
      "Steps:   7%|▏ | 1090/15000 [07:20<44:19,  5.23it/s, lr=9.99e-6, step_loss=0.664]07/18/2023 19:10:42 - INFO - __main__ - train loss is 2.542470744345337\n",
      "Steps:   7%| | 1091/15000 [07:20<43:24,  5.34it/s, lr=9.99e-6, step_loss=0.0708]07/18/2023 19:10:42 - INFO - __main__ - train loss is 2.550166878849268\n",
      "Steps:   7%| | 1092/15000 [07:20<42:49,  5.41it/s, lr=9.99e-6, step_loss=0.0077]07/18/2023 19:10:43 - INFO - __main__ - train loss is 2.660531673580408\n",
      "Steps:   7%|▏  | 1093/15000 [07:21<42:18,  5.48it/s, lr=9.99e-6, step_loss=0.11]07/18/2023 19:10:43 - INFO - __main__ - train loss is 2.6660014232620597\n",
      "Steps:   7%| | 1094/15000 [07:21<42:01,  5.51it/s, lr=9.99e-6, step_loss=0.0054707/18/2023 19:10:43 - INFO - __main__ - train loss is 2.864272846840322\n",
      "Steps:   7%|▏ | 1095/15000 [07:21<42:01,  5.51it/s, lr=9.99e-6, step_loss=0.198]07/18/2023 19:10:43 - INFO - __main__ - train loss is 2.9506629398092628\n",
      "Steps:   7%| | 1096/15000 [07:21<41:52,  5.53it/s, lr=9.99e-6, step_loss=0.0864]07/18/2023 19:10:43 - INFO - __main__ - train loss is 2.997982426546514\n",
      "Steps:   7%| | 1097/15000 [07:21<41:42,  5.56it/s, lr=9.99e-6, step_loss=0.0473]07/18/2023 19:10:44 - INFO - __main__ - train loss is 3.0189824318513274\n",
      "Steps:   7%|▏ | 1098/15000 [07:21<41:36,  5.57it/s, lr=9.99e-6, step_loss=0.021]07/18/2023 19:10:44 - INFO - __main__ - train loss is 3.249691224656999\n",
      "Steps:   7%|▏ | 1099/15000 [07:22<41:31,  5.58it/s, lr=9.99e-6, step_loss=0.231]07/18/2023 19:10:44 - INFO - __main__ - train loss is 3.3092224961146712\n",
      "Steps:   7%| | 1100/15000 [07:22<41:31,  5.58it/s, lr=9.99e-6, step_loss=0.0595]07/18/2023 19:10:44 - INFO - __main__ - train loss is 3.4455682104453444\n",
      "Steps:   7%|▏ | 1101/15000 [07:22<41:27,  5.59it/s, lr=9.99e-6, step_loss=0.136]07/18/2023 19:10:44 - INFO - __main__ - train loss is 3.4599331533536315\n",
      "Steps:   7%| | 1102/15000 [07:22<41:23,  5.60it/s, lr=9.99e-6, step_loss=0.0144]07/18/2023 19:10:44 - INFO - __main__ - train loss is 3.4632091876119375\n",
      "Steps:   7%| | 1103/15000 [07:22<41:20,  5.60it/s, lr=9.99e-6, step_loss=0.0032807/18/2023 19:10:45 - INFO - __main__ - train loss is 3.4846618101000786\n",
      "Steps:   7%| | 1104/15000 [07:22<41:18,  5.61it/s, lr=9.99e-6, step_loss=0.0215]07/18/2023 19:10:45 - INFO - __main__ - train loss is 3.597094364464283\n",
      "Steps:   7%|▏ | 1105/15000 [07:23<41:20,  5.60it/s, lr=9.99e-6, step_loss=0.112]07/18/2023 19:10:45 - INFO - __main__ - train loss is 3.771945632994175\n",
      "Steps:   7%|▏ | 1106/15000 [07:23<41:35,  5.57it/s, lr=9.99e-6, step_loss=0.175]07/18/2023 19:10:45 - INFO - __main__ - train loss is 3.775995861273259\n",
      "Steps:   7%| | 1107/15000 [07:23<41:30,  5.58it/s, lr=9.99e-6, step_loss=0.0040507/18/2023 19:10:45 - INFO - __main__ - train loss is 4.097806345205754\n",
      "Steps:   7%|▏ | 1108/15000 [07:23<41:29,  5.58it/s, lr=9.99e-6, step_loss=0.322]07/18/2023 19:10:45 - INFO - __main__ - train loss is 4.442324619274586\n",
      "Steps:   7%|▏ | 1109/15000 [07:23<41:25,  5.59it/s, lr=9.99e-6, step_loss=0.345]07/18/2023 19:10:46 - INFO - __main__ - train loss is 4.6738493400625885\n",
      "Steps:   7%|▏ | 1110/15000 [07:24<41:28,  5.58it/s, lr=9.99e-6, step_loss=0.232]07/18/2023 19:10:46 - INFO - __main__ - train loss is 4.727609116118401\n",
      "Steps:   7%| | 1111/15000 [07:24<41:31,  5.58it/s, lr=9.99e-6, step_loss=0.0538]07/18/2023 19:10:46 - INFO - __main__ - train loss is 4.7324762172065675\n",
      "Steps:   7%| | 1112/15000 [07:24<41:25,  5.59it/s, lr=9.99e-6, step_loss=0.0048707/18/2023 19:10:46 - INFO - __main__ - train loss is 4.742341199424118\n",
      "Steps:   7%| | 1113/15000 [07:24<41:21,  5.60it/s, lr=9.99e-6, step_loss=0.0098607/18/2023 19:10:46 - INFO - __main__ - train loss is 4.9018484889529645\n",
      "Steps:   7%|▏  | 1114/15000 [07:24<41:19,  5.60it/s, lr=9.99e-6, step_loss=0.16]07/18/2023 19:10:47 - INFO - __main__ - train loss is 5.314433568622917\n",
      "Steps:   7%|▏ | 1115/15000 [07:24<41:19,  5.60it/s, lr=9.99e-6, step_loss=0.413]07/18/2023 19:10:47 - INFO - __main__ - train loss is 5.473927193786949\n",
      "Steps:   7%|▏ | 1116/15000 [07:25<41:22,  5.59it/s, lr=9.99e-6, step_loss=0.159]07/18/2023 19:10:47 - INFO - __main__ - train loss is 5.496611402835697\n",
      "Steps:   7%| | 1117/15000 [07:25<41:21,  5.59it/s, lr=9.99e-6, step_loss=0.0227]07/18/2023 19:10:47 - INFO - __main__ - train loss is 5.750911758746952\n",
      "Steps:   7%|▏ | 1118/15000 [07:25<41:19,  5.60it/s, lr=9.99e-6, step_loss=0.254]07/18/2023 19:10:47 - INFO - __main__ - train loss is 6.018590347375721\n",
      "Steps:   7%|▏ | 1119/15000 [07:25<41:21,  5.59it/s, lr=9.99e-6, step_loss=0.268]07/18/2023 19:10:47 - INFO - __main__ - train loss is 6.129118965473026\n",
      "Steps:   7%|▏ | 1120/15000 [07:25<41:43,  5.54it/s, lr=9.99e-6, step_loss=0.111]07/18/2023 19:10:48 - INFO - __main__ - train loss is 6.170039632823318\n",
      "Steps:   7%| | 1121/15000 [07:26<42:06,  5.49it/s, lr=9.99e-6, step_loss=0.0409]07/18/2023 19:10:48 - INFO - __main__ - train loss is 6.178034769836813\n",
      "Steps:   7%|▏ | 1122/15000 [07:26<41:55,  5.52it/s, lr=9.99e-6, step_loss=0.008]07/18/2023 19:10:48 - INFO - __main__ - train loss is 6.3362705879844725\n",
      "Steps:   7%|▏ | 1123/15000 [07:26<41:43,  5.54it/s, lr=9.99e-6, step_loss=0.158]07/18/2023 19:10:48 - INFO - __main__ - train loss is 6.65501286322251\n",
      "Steps:   7%|▏ | 1124/15000 [07:26<41:34,  5.56it/s, lr=9.99e-6, step_loss=0.319]07/18/2023 19:10:48 - INFO - __main__ - train loss is 6.682598086539656\n",
      "Steps:   8%| | 1125/15000 [07:26<41:28,  5.58it/s, lr=9.99e-6, step_loss=0.0276]07/18/2023 19:10:49 - INFO - __main__ - train loss is 6.78228277945891\n",
      "Steps:   8%| | 1126/15000 [07:26<41:23,  5.59it/s, lr=9.99e-6, step_loss=0.0997]07/18/2023 19:10:49 - INFO - __main__ - train loss is 6.8134894971735775\n",
      "Steps:   8%| | 1127/15000 [07:27<41:45,  5.54it/s, lr=9.99e-6, step_loss=0.0312]07/18/2023 19:10:49 - INFO - __main__ - train loss is 7.3488169317133725\n",
      "Steps:   8%|▏ | 1128/15000 [07:27<42:10,  5.48it/s, lr=9.99e-6, step_loss=0.535]07/18/2023 19:10:49 - INFO - __main__ - train loss is 7.360928936395794\n",
      "Steps:   8%| | 1129/15000 [07:27<42:01,  5.50it/s, lr=9.99e-6, step_loss=0.0121]07/18/2023 19:10:49 - INFO - __main__ - train loss is 7.364177578594536\n",
      "Steps:   8%| | 1130/15000 [07:27<41:46,  5.53it/s, lr=9.99e-6, step_loss=0.0032507/18/2023 19:10:49 - INFO - __main__ - train loss is 7.637855076696724\n",
      "Steps:   8%|▏ | 1131/15000 [07:27<41:36,  5.56it/s, lr=9.99e-6, step_loss=0.274]07/18/2023 19:10:50 - INFO - __main__ - train loss is 7.658038459252566\n",
      "Steps:   8%| | 1132/15000 [07:28<41:28,  5.57it/s, lr=9.99e-6, step_loss=0.0202]07/18/2023 19:10:50 - INFO - __main__ - train loss is 7.950215272139758\n",
      "Steps:   8%|▏ | 1133/15000 [07:28<42:05,  5.49it/s, lr=9.99e-6, step_loss=0.292]07/18/2023 19:10:50 - INFO - __main__ - train loss is 7.957881997805089\n",
      "Steps:   8%| | 1134/15000 [07:28<41:57,  5.51it/s, lr=9.99e-6, step_loss=0.0076707/18/2023 19:10:50 - INFO - __main__ - train loss is 8.133055012207478\n",
      "Steps:   8%|▏ | 1135/15000 [07:28<41:44,  5.54it/s, lr=9.99e-6, step_loss=0.175]07/18/2023 19:10:50 - INFO - __main__ - train loss is 8.15560683561489\n",
      "Steps:   8%| | 1136/15000 [07:28<41:34,  5.56it/s, lr=9.99e-6, step_loss=0.0226]07/18/2023 19:10:51 - INFO - __main__ - train loss is 8.417597710620612\n",
      "Steps:   8%|▏ | 1137/15000 [07:28<41:28,  5.57it/s, lr=9.99e-6, step_loss=0.262]07/18/2023 19:10:51 - INFO - __main__ - train loss is 8.663091808091849\n",
      "Steps:   8%|▏ | 1138/15000 [07:29<41:26,  5.58it/s, lr=9.99e-6, step_loss=0.245]07/18/2023 19:10:51 - INFO - __main__ - train loss is 8.673671989236027\n",
      "Steps:   8%| | 1139/15000 [07:29<41:23,  5.58it/s, lr=9.99e-6, step_loss=0.0106]07/18/2023 19:10:51 - INFO - __main__ - train loss is 8.702767367009073\n",
      "Steps:   8%| | 1140/15000 [07:29<41:43,  5.54it/s, lr=9.99e-6, step_loss=0.0291]07/18/2023 19:10:51 - INFO - __main__ - train loss is 8.722986391279846\n",
      "Steps:   8%| | 1141/15000 [07:29<41:42,  5.54it/s, lr=9.99e-6, step_loss=0.0202]07/18/2023 19:10:51 - INFO - __main__ - train loss is 9.03151102969423\n",
      "Steps:   8%|▏ | 1142/15000 [07:29<41:56,  5.51it/s, lr=9.99e-6, step_loss=0.309]07/18/2023 19:10:52 - INFO - __main__ - train loss is 9.035453107208014\n",
      "Steps:   8%| | 1143/15000 [07:30<42:03,  5.49it/s, lr=9.99e-6, step_loss=0.0039407/18/2023 19:10:52 - INFO - __main__ - train loss is 9.036944402963854\n",
      "Steps:   8%| | 1144/15000 [07:30<41:51,  5.52it/s, lr=9.99e-6, step_loss=0.0014907/18/2023 19:10:52 - INFO - __main__ - train loss is 9.065436060191132\n",
      "Steps:   8%| | 1145/15000 [07:30<41:39,  5.54it/s, lr=9.99e-6, step_loss=0.0285]07/18/2023 19:10:52 - INFO - __main__ - train loss is 9.446378702879883\n",
      "Steps:   8%|▏ | 1146/15000 [07:30<41:31,  5.56it/s, lr=9.99e-6, step_loss=0.381]07/18/2023 19:10:52 - INFO - __main__ - train loss is 9.485658625722863\n",
      "Steps:   8%| | 1147/15000 [07:30<41:26,  5.57it/s, lr=9.99e-6, step_loss=0.0393]07/18/2023 19:10:53 - INFO - __main__ - train loss is 9.488433905993588\n",
      "Steps:   8%| | 1148/15000 [07:30<41:20,  5.58it/s, lr=9.99e-6, step_loss=0.0027807/18/2023 19:10:53 - INFO - __main__ - train loss is 9.513366571743973\n",
      "Steps:   8%| | 1149/15000 [07:31<41:26,  5.57it/s, lr=9.99e-6, step_loss=0.0249]07/18/2023 19:10:53 - INFO - __main__ - train loss is 9.569845258374698\n",
      "Steps:   8%| | 1150/15000 [07:31<41:26,  5.57it/s, lr=9.99e-6, step_loss=0.0565]07/18/2023 19:10:53 - INFO - __main__ - train loss is 9.91025918640662\n",
      "Steps:   8%|▏  | 1151/15000 [07:31<41:20,  5.58it/s, lr=9.99e-6, step_loss=0.34]07/18/2023 19:10:53 - INFO - __main__ - train loss is 9.948951750178821\n",
      "Steps:   8%| | 1152/15000 [07:31<41:16,  5.59it/s, lr=9.99e-6, step_loss=0.0387]07/18/2023 19:10:53 - INFO - __main__ - train loss is 10.027756161172874\n",
      "Steps:   8%| | 1153/15000 [07:31<41:12,  5.60it/s, lr=9.99e-6, step_loss=0.0788]07/18/2023 19:10:54 - INFO - __main__ - train loss is 10.059951729257591\n",
      "Steps:   8%| | 1154/15000 [07:31<41:11,  5.60it/s, lr=9.99e-6, step_loss=0.0322]07/18/2023 19:10:54 - INFO - __main__ - train loss is 10.126832730253227\n",
      "Steps:   8%| | 1155/15000 [07:32<41:14,  5.60it/s, lr=9.99e-6, step_loss=0.0669]07/18/2023 19:10:54 - INFO - __main__ - train loss is 10.215584329445846\n",
      "Steps:   8%| | 1156/15000 [07:32<41:10,  5.60it/s, lr=9.99e-6, step_loss=0.0888]07/18/2023 19:10:54 - INFO - __main__ - train loss is 10.358905754168518\n",
      "Steps:   8%|▏ | 1157/15000 [07:32<41:13,  5.60it/s, lr=9.99e-6, step_loss=0.143]07/18/2023 19:10:54 - INFO - __main__ - train loss is 11.320704660494812\n",
      "Steps:   8%|▏ | 1158/15000 [07:32<41:11,  5.60it/s, lr=9.99e-6, step_loss=0.962]07/18/2023 19:10:54 - INFO - __main__ - train loss is 11.332077521947213\n",
      "Steps:   8%| | 1159/15000 [07:32<41:09,  5.60it/s, lr=9.99e-6, step_loss=0.0114]07/18/2023 19:10:55 - INFO - __main__ - train loss is 11.921419043210335\n",
      "Steps:   8%|▏ | 1160/15000 [07:33<41:43,  5.53it/s, lr=9.99e-6, step_loss=0.589]07/18/2023 19:10:55 - INFO - __main__ - train loss is 12.465019721654244\n",
      "Steps:   8%|▏ | 1161/15000 [07:33<41:38,  5.54it/s, lr=9.99e-6, step_loss=0.544]07/18/2023 19:10:55 - INFO - __main__ - train loss is 12.639938164618798\n",
      "Steps:   8%|▏ | 1162/15000 [07:33<41:27,  5.56it/s, lr=9.99e-6, step_loss=0.175]07/18/2023 19:10:55 - INFO - __main__ - train loss is 12.701652508345433\n",
      "Steps:   8%| | 1163/15000 [07:33<41:19,  5.58it/s, lr=9.99e-6, step_loss=0.0617]07/18/2023 19:10:56 - INFO - __main__ - train loss is 12.709916168940254\n",
      "Steps:   8%| | 1164/15000 [07:33<56:09,  4.11it/s, lr=9.99e-6, step_loss=0.0082607/18/2023 19:10:56 - INFO - __main__ - Per validation step average loss is 0.2227904498577118\n",
      "07/18/2023 19:10:56 - INFO - __main__ - Cumulative validation average loss is 0.2227904498577118\n",
      "07/18/2023 19:10:56 - INFO - __main__ - Per validation step average loss is 0.45356565713882446\n",
      "07/18/2023 19:10:56 - INFO - __main__ - Cumulative validation average loss is 0.6763561069965363\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.014496766030788422\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 0.6908528730273247\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.17521867156028748\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 0.8660715445876122\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.0048994263634085655\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 0.8709709709510207\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.1777334213256836\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 1.0487043922767043\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.13841339945793152\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 1.1871177917346358\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.5037658214569092\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 1.690883613191545\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Per validation step average loss is 0.30193546414375305\n",
      "07/18/2023 19:10:57 - INFO - __main__ - Cumulative validation average loss is 1.992819077335298\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Per validation step average loss is 0.09849635511636734\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Cumulative validation average loss is 2.0913154324516654\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Per validation step average loss is 0.3859015703201294\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Cumulative validation average loss is 2.477217002771795\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Per validation step average loss is 0.29319971799850464\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Cumulative validation average loss is 2.7704167207702994\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Average validation loss for Epoch 11 is 0.2308680600641916\n",
      "07/18/2023 19:10:58 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:11:11 - INFO - __main__ - Starting epoch 12\n",
      "07/18/2023 19:11:11 - INFO - __main__ - train loss is 0.00748961977660656\n",
      "Steps:   8%| | 1165/15000 [07:49<18:54:38,  4.92s/it, lr=9.99e-6, step_loss=0.0007/18/2023 19:11:12 - INFO - __main__ - train loss is 0.0090650396887213\n",
      "Steps:   8%| | 1166/15000 [07:50<13:27:21,  3.50s/it, lr=9.99e-6, step_loss=0.0007/18/2023 19:11:12 - INFO - __main__ - train loss is 0.0544795470777899\n",
      "Steps:   8%| | 1167/15000 [07:50<9:38:47,  2.51s/it, lr=9.99e-6, step_loss=0.04507/18/2023 19:11:12 - INFO - __main__ - train loss is 0.6083314495626837\n",
      "Steps:   8%| | 1168/15000 [07:50<6:58:12,  1.81s/it, lr=9.99e-6, step_loss=0.55407/18/2023 19:11:12 - INFO - __main__ - train loss is 0.7063847261015326\n",
      "Steps:   8%| | 1169/15000 [07:50<5:05:09,  1.32s/it, lr=9.99e-6, step_loss=0.09807/18/2023 19:11:12 - INFO - __main__ - train loss is 0.7579217853490263\n",
      "Steps:   8%| | 1170/15000 [07:50<3:46:02,  1.02it/s, lr=9.99e-6, step_loss=0.05107/18/2023 19:11:13 - INFO - __main__ - train loss is 0.7630939579103142\n",
      "Steps:   8%| | 1171/15000 [07:50<2:51:05,  1.35it/s, lr=9.99e-6, step_loss=0.00507/18/2023 19:11:13 - INFO - __main__ - train loss is 0.8459269201848656\n",
      "Steps:   8%| | 1172/15000 [07:51<2:12:02,  1.75it/s, lr=9.99e-6, step_loss=0.08207/18/2023 19:11:13 - INFO - __main__ - train loss is 1.125419000396505\n",
      "Steps:   8%| | 1173/15000 [07:51<1:44:47,  2.20it/s, lr=9.99e-6, step_loss=0.27907/18/2023 19:11:13 - INFO - __main__ - train loss is 1.1982700175140053\n",
      "Steps:   8%| | 1174/15000 [07:51<1:25:36,  2.69it/s, lr=9.99e-6, step_loss=0.07207/18/2023 19:11:13 - INFO - __main__ - train loss is 1.3639652824494988\n",
      "Steps:   8%| | 1175/15000 [07:51<1:12:15,  3.19it/s, lr=9.99e-6, step_loss=0.16607/18/2023 19:11:13 - INFO - __main__ - train loss is 1.4724089375231415\n",
      "Steps:   8%| | 1176/15000 [07:51<1:02:47,  3.67it/s, lr=9.99e-6, step_loss=0.10807/18/2023 19:11:14 - INFO - __main__ - train loss is 1.6081489494536072\n",
      "Steps:   8%|▏ | 1177/15000 [07:52<56:16,  4.09it/s, lr=9.99e-6, step_loss=0.136]07/18/2023 19:11:14 - INFO - __main__ - train loss is 1.6186515896115452\n",
      "Steps:   8%| | 1178/15000 [07:52<51:36,  4.46it/s, lr=9.99e-6, step_loss=0.0105]07/18/2023 19:11:14 - INFO - __main__ - train loss is 1.7840012519154698\n",
      "Steps:   8%|▏ | 1179/15000 [07:52<48:27,  4.75it/s, lr=9.99e-6, step_loss=0.165]07/18/2023 19:11:14 - INFO - __main__ - train loss is 2.107362291077152\n",
      "Steps:   8%|▏ | 1180/15000 [07:52<46:29,  4.95it/s, lr=9.99e-6, step_loss=0.323]07/18/2023 19:11:14 - INFO - __main__ - train loss is 2.1227925589773804\n",
      "Steps:   8%| | 1181/15000 [07:52<45:03,  5.11it/s, lr=9.99e-6, step_loss=0.0154]07/18/2023 19:11:15 - INFO - __main__ - train loss is 2.126513133291155\n",
      "Steps:   8%| | 1182/15000 [07:52<43:49,  5.25it/s, lr=9.99e-6, step_loss=0.0037207/18/2023 19:11:15 - INFO - __main__ - train loss is 2.6447599031962454\n",
      "Steps:   8%|▏ | 1183/15000 [07:53<43:01,  5.35it/s, lr=9.99e-6, step_loss=0.518]07/18/2023 19:11:15 - INFO - __main__ - train loss is 2.990963409189135\n",
      "Steps:   8%|▏ | 1184/15000 [07:53<42:34,  5.41it/s, lr=9.99e-6, step_loss=0.346]07/18/2023 19:11:15 - INFO - __main__ - train loss is 3.2119465568102896\n",
      "Steps:   8%|▏ | 1185/15000 [07:53<42:05,  5.47it/s, lr=9.99e-6, step_loss=0.221]07/18/2023 19:11:15 - INFO - __main__ - train loss is 3.2210840242914855\n",
      "Steps:   8%| | 1186/15000 [07:53<41:45,  5.51it/s, lr=9.99e-6, step_loss=0.0091407/18/2023 19:11:15 - INFO - __main__ - train loss is 3.575555022340268\n",
      "Steps:   8%|▏ | 1187/15000 [07:53<41:31,  5.54it/s, lr=9.99e-6, step_loss=0.354]07/18/2023 19:11:16 - INFO - __main__ - train loss is 3.723115067463368\n",
      "Steps:   8%|▏ | 1188/15000 [07:53<41:23,  5.56it/s, lr=9.99e-6, step_loss=0.148]07/18/2023 19:11:16 - INFO - __main__ - train loss is 3.733148972969502\n",
      "Steps:   8%|▏  | 1189/15000 [07:54<41:24,  5.56it/s, lr=9.99e-6, step_loss=0.01]07/18/2023 19:11:16 - INFO - __main__ - train loss is 3.7498906808905303\n",
      "Steps:   8%| | 1190/15000 [07:54<41:28,  5.55it/s, lr=9.99e-6, step_loss=0.0167]07/18/2023 19:11:16 - INFO - __main__ - train loss is 3.765226580668241\n",
      "Steps:   8%| | 1191/15000 [07:54<42:56,  5.36it/s, lr=9.99e-6, step_loss=0.0153]07/18/2023 19:11:16 - INFO - __main__ - train loss is 3.768468040274456\n",
      "Steps:   8%| | 1192/15000 [07:54<42:23,  5.43it/s, lr=9.99e-6, step_loss=0.0032407/18/2023 19:11:17 - INFO - __main__ - train loss is 3.7914183468092233\n",
      "Steps:   8%|▏ | 1193/15000 [07:54<41:57,  5.48it/s, lr=9.99e-6, step_loss=0.023]07/18/2023 19:11:17 - INFO - __main__ - train loss is 3.793738964246586\n",
      "Steps:   8%| | 1194/15000 [07:55<41:39,  5.52it/s, lr=9.99e-6, step_loss=0.0023207/18/2023 19:11:17 - INFO - __main__ - train loss is 3.9999730915296823\n",
      "Steps:   8%|▏ | 1195/15000 [07:55<41:29,  5.55it/s, lr=9.99e-6, step_loss=0.206]07/18/2023 19:11:17 - INFO - __main__ - train loss is 4.008045857073739\n",
      "Steps:   8%| | 1196/15000 [07:55<41:20,  5.57it/s, lr=9.99e-6, step_loss=0.0080707/18/2023 19:11:17 - INFO - __main__ - train loss is 4.025378396036103\n",
      "Steps:   8%| | 1197/15000 [07:55<41:14,  5.58it/s, lr=9.99e-6, step_loss=0.0173]07/18/2023 19:11:17 - INFO - __main__ - train loss is 4.126863953890279\n",
      "Steps:   8%|▏ | 1198/15000 [07:55<41:11,  5.58it/s, lr=9.99e-6, step_loss=0.101]07/18/2023 19:11:18 - INFO - __main__ - train loss is 4.145799993770197\n",
      "Steps:   8%| | 1199/15000 [07:55<41:28,  5.55it/s, lr=9.99e-6, step_loss=0.0189]07/18/2023 19:11:18 - INFO - __main__ - train loss is 4.253062813775614\n",
      "Steps:   8%|▏ | 1200/15000 [07:56<41:20,  5.56it/s, lr=9.99e-6, step_loss=0.107]07/18/2023 19:11:18 - INFO - __main__ - train loss is 4.258781763957813\n",
      "Steps:   8%| | 1201/15000 [07:56<41:15,  5.57it/s, lr=9.99e-6, step_loss=0.0057207/18/2023 19:11:18 - INFO - __main__ - train loss is 4.5544823438394815\n",
      "Steps:   8%|▏ | 1202/15000 [07:56<41:11,  5.58it/s, lr=9.99e-6, step_loss=0.296]07/18/2023 19:11:18 - INFO - __main__ - train loss is 5.0522643357981\n",
      "Steps:   8%|▏ | 1203/15000 [07:56<41:17,  5.57it/s, lr=9.99e-6, step_loss=0.498]07/18/2023 19:11:18 - INFO - __main__ - train loss is 5.256502094911411\n",
      "Steps:   8%|▏ | 1204/15000 [07:56<41:12,  5.58it/s, lr=9.99e-6, step_loss=0.204]07/18/2023 19:11:19 - INFO - __main__ - train loss is 5.269888472976163\n",
      "Steps:   8%| | 1205/15000 [07:57<41:11,  5.58it/s, lr=9.99e-6, step_loss=0.0134]07/18/2023 19:11:19 - INFO - __main__ - train loss is 5.445631948532537\n",
      "Steps:   8%|▏ | 1206/15000 [07:57<41:09,  5.59it/s, lr=9.99e-6, step_loss=0.176]07/18/2023 19:11:19 - INFO - __main__ - train loss is 6.101587263168767\n",
      "Steps:   8%|▏ | 1207/15000 [07:57<41:09,  5.59it/s, lr=9.99e-6, step_loss=0.656]07/18/2023 19:11:19 - INFO - __main__ - train loss is 6.1115946436766535\n",
      "Steps:   8%|▏  | 1208/15000 [07:57<41:11,  5.58it/s, lr=9.99e-6, step_loss=0.01]07/18/2023 19:11:19 - INFO - __main__ - train loss is 6.121912576491013\n",
      "Steps:   8%| | 1209/15000 [07:57<41:10,  5.58it/s, lr=9.99e-6, step_loss=0.0103]07/18/2023 19:11:20 - INFO - __main__ - train loss is 6.134044811362401\n",
      "Steps:   8%| | 1210/15000 [07:57<41:07,  5.59it/s, lr=9.99e-6, step_loss=0.0121]07/18/2023 19:11:20 - INFO - __main__ - train loss is 6.2730749698821455\n",
      "Steps:   8%|▏ | 1211/15000 [07:58<41:07,  5.59it/s, lr=9.99e-6, step_loss=0.139]07/18/2023 19:11:20 - INFO - __main__ - train loss is 6.324368812376633\n",
      "Steps:   8%| | 1212/15000 [07:58<41:05,  5.59it/s, lr=9.99e-6, step_loss=0.0513]07/18/2023 19:11:20 - INFO - __main__ - train loss is 6.345660731429234\n",
      "Steps:   8%| | 1213/15000 [07:58<41:27,  5.54it/s, lr=9.99e-6, step_loss=0.0213]07/18/2023 19:11:20 - INFO - __main__ - train loss is 6.355031891958788\n",
      "Steps:   8%| | 1214/15000 [07:58<41:18,  5.56it/s, lr=9.99e-6, step_loss=0.0093707/18/2023 19:11:20 - INFO - __main__ - train loss is 6.748286887304857\n",
      "Steps:   8%|▏ | 1215/15000 [07:58<41:30,  5.53it/s, lr=9.99e-6, step_loss=0.393]07/18/2023 19:11:21 - INFO - __main__ - train loss is 6.780351932393387\n",
      "Steps:   8%| | 1216/15000 [07:59<41:45,  5.50it/s, lr=9.99e-6, step_loss=0.0321]07/18/2023 19:11:21 - INFO - __main__ - train loss is 7.095607604132965\n",
      "Steps:   8%|▏ | 1217/15000 [07:59<42:06,  5.45it/s, lr=9.99e-6, step_loss=0.315]07/18/2023 19:11:21 - INFO - __main__ - train loss is 7.551935340510681\n",
      "Steps:   8%|▏ | 1218/15000 [07:59<41:51,  5.49it/s, lr=9.99e-6, step_loss=0.456]07/18/2023 19:11:21 - INFO - __main__ - train loss is 7.835228647338226\n",
      "Steps:   8%|▏ | 1219/15000 [07:59<41:36,  5.52it/s, lr=9.99e-6, step_loss=0.283]07/18/2023 19:11:21 - INFO - __main__ - train loss is 7.839363306062296\n",
      "Steps:   8%| | 1220/15000 [07:59<41:26,  5.54it/s, lr=9.99e-6, step_loss=0.0041307/18/2023 19:11:22 - INFO - __main__ - train loss is 8.024155645864084\n",
      "Steps:   8%|▏ | 1221/15000 [07:59<41:16,  5.56it/s, lr=9.99e-6, step_loss=0.185]07/18/2023 19:11:22 - INFO - __main__ - train loss is 8.029977559344843\n",
      "Steps:   8%| | 1222/15000 [08:00<41:13,  5.57it/s, lr=9.99e-6, step_loss=0.0058207/18/2023 19:11:22 - INFO - __main__ - train loss is 8.609327077167109\n",
      "Steps:   8%|▏ | 1223/15000 [08:00<41:08,  5.58it/s, lr=9.99e-6, step_loss=0.579]07/18/2023 19:11:22 - INFO - __main__ - train loss is 9.095546215074137\n",
      "Steps:   8%|▏ | 1224/15000 [08:00<41:02,  5.59it/s, lr=9.99e-6, step_loss=0.486]07/18/2023 19:11:22 - INFO - __main__ - train loss is 9.375592260854319\n",
      "Steps:   8%|▏  | 1225/15000 [08:00<41:01,  5.60it/s, lr=9.99e-6, step_loss=0.28]07/18/2023 19:11:22 - INFO - __main__ - train loss is 9.37834037351422\n",
      "Steps:   8%| | 1226/15000 [08:00<41:16,  5.56it/s, lr=9.99e-6, step_loss=0.0027507/18/2023 19:11:23 - INFO - __main__ - train loss is 9.790804664371535\n",
      "Steps:   8%|▏ | 1227/15000 [08:01<42:11,  5.44it/s, lr=9.99e-6, step_loss=0.412]07/18/2023 19:11:23 - INFO - __main__ - train loss is 9.85621693986468\n",
      "Steps:   8%| | 1228/15000 [08:01<41:50,  5.49it/s, lr=9.99e-6, step_loss=0.0654]07/18/2023 19:11:23 - INFO - __main__ - train loss is 9.912420968292281\n",
      "Steps:   8%| | 1229/15000 [08:01<41:33,  5.52it/s, lr=9.99e-6, step_loss=0.0562]07/18/2023 19:11:23 - INFO - __main__ - train loss is 9.9469643633347\n",
      "Steps:   8%| | 1230/15000 [08:01<41:20,  5.55it/s, lr=9.99e-6, step_loss=0.0345]07/18/2023 19:11:23 - INFO - __main__ - train loss is 10.148294250248\n",
      "Steps:   8%|▏ | 1231/15000 [08:01<41:25,  5.54it/s, lr=9.99e-6, step_loss=0.201]07/18/2023 19:11:24 - INFO - __main__ - train loss is 10.16404607030563\n",
      "Steps:   8%| | 1232/15000 [08:01<41:16,  5.56it/s, lr=9.99e-6, step_loss=0.0158]07/18/2023 19:11:24 - INFO - __main__ - train loss is 10.225228986470029\n",
      "Steps:   8%| | 1233/15000 [08:02<41:33,  5.52it/s, lr=9.99e-6, step_loss=0.0612]07/18/2023 19:11:24 - INFO - __main__ - train loss is 10.47758629056625\n",
      "Steps:   8%|▏ | 1234/15000 [08:02<41:43,  5.50it/s, lr=9.99e-6, step_loss=0.252]07/18/2023 19:11:24 - INFO - __main__ - train loss is 10.484435425838456\n",
      "Steps:   8%| | 1235/15000 [08:02<41:56,  5.47it/s, lr=9.99e-6, step_loss=0.0068507/18/2023 19:11:24 - INFO - __main__ - train loss is 10.649229751667008\n",
      "Steps:   8%|▏ | 1236/15000 [08:02<42:16,  5.43it/s, lr=9.99e-6, step_loss=0.165]07/18/2023 19:11:24 - INFO - __main__ - train loss is 10.70884340791963\n",
      "Steps:   8%| | 1237/15000 [08:02<41:52,  5.48it/s, lr=9.99e-6, step_loss=0.0596]07/18/2023 19:11:25 - INFO - __main__ - train loss is 10.94238538830541\n",
      "Steps:   8%|▏ | 1238/15000 [08:03<41:35,  5.51it/s, lr=9.99e-6, step_loss=0.234]07/18/2023 19:11:25 - INFO - __main__ - train loss is 11.192770136287436\n",
      "Steps:   8%|▏  | 1239/15000 [08:03<41:25,  5.54it/s, lr=9.99e-6, step_loss=0.25]07/18/2023 19:11:25 - INFO - __main__ - train loss is 11.211237713461742\n",
      "Steps:   8%| | 1240/15000 [08:03<41:41,  5.50it/s, lr=9.99e-6, step_loss=0.0185]07/18/2023 19:11:25 - INFO - __main__ - train loss is 11.627333804732189\n",
      "Steps:   8%|▏ | 1241/15000 [08:03<41:27,  5.53it/s, lr=9.99e-6, step_loss=0.416]07/18/2023 19:11:25 - INFO - __main__ - train loss is 11.838736593490466\n",
      "Steps:   8%|▏ | 1242/15000 [08:03<41:14,  5.56it/s, lr=9.99e-6, step_loss=0.211]07/18/2023 19:11:26 - INFO - __main__ - train loss is 12.0940536854323\n",
      "Steps:   8%|▏ | 1243/15000 [08:03<41:07,  5.58it/s, lr=9.99e-6, step_loss=0.255]07/18/2023 19:11:26 - INFO - __main__ - train loss is 12.164419218664989\n",
      "Steps:   8%| | 1244/15000 [08:04<41:03,  5.58it/s, lr=9.99e-6, step_loss=0.0704]07/18/2023 19:11:26 - INFO - __main__ - train loss is 12.490376874571666\n",
      "Steps:   8%|▏ | 1245/15000 [08:04<41:02,  5.59it/s, lr=9.99e-6, step_loss=0.326]07/18/2023 19:11:26 - INFO - __main__ - train loss is 12.506103232270107\n",
      "Steps:   8%| | 1246/15000 [08:04<40:57,  5.60it/s, lr=9.99e-6, step_loss=0.0157]07/18/2023 19:11:26 - INFO - __main__ - train loss is 12.514737214660272\n",
      "Steps:   8%| | 1247/15000 [08:04<40:54,  5.60it/s, lr=9.99e-6, step_loss=0.0086307/18/2023 19:11:26 - INFO - __main__ - train loss is 12.803337301826105\n",
      "Steps:   8%|▏ | 1248/15000 [08:04<40:51,  5.61it/s, lr=9.99e-6, step_loss=0.289]07/18/2023 19:11:27 - INFO - __main__ - train loss is 12.827104350319132\n",
      "Steps:   8%| | 1249/15000 [08:04<40:48,  5.62it/s, lr=9.99e-6, step_loss=0.0238]07/18/2023 19:11:27 - INFO - __main__ - train loss is 13.110913237323985\n",
      "Steps:   8%|▏ | 1250/15000 [08:05<40:45,  5.62it/s, lr=9.99e-6, step_loss=0.284]07/18/2023 19:11:27 - INFO - __main__ - train loss is 13.121814552461728\n",
      "Steps:   8%| | 1251/15000 [08:05<40:46,  5.62it/s, lr=9.99e-6, step_loss=0.0109]07/18/2023 19:11:27 - INFO - __main__ - train loss is 13.124701430089772\n",
      "Steps:   8%| | 1252/15000 [08:05<41:08,  5.57it/s, lr=9.99e-6, step_loss=0.0028907/18/2023 19:11:27 - INFO - __main__ - train loss is 13.801164318807423\n",
      "Steps:   8%|▏ | 1253/15000 [08:05<41:08,  5.57it/s, lr=9.99e-6, step_loss=0.676]07/18/2023 19:11:27 - INFO - __main__ - train loss is 13.802901558578014\n",
      "Steps:   8%| | 1254/15000 [08:05<41:33,  5.51it/s, lr=9.99e-6, step_loss=0.0017407/18/2023 19:11:28 - INFO - __main__ - train loss is 13.804747218149714\n",
      "Steps:   8%| | 1255/15000 [08:06<41:28,  5.52it/s, lr=9.99e-6, step_loss=0.0018507/18/2023 19:11:28 - INFO - __main__ - train loss is 13.806107927579433\n",
      "Steps:   8%| | 1256/15000 [08:06<41:38,  5.50it/s, lr=9.99e-6, step_loss=0.0013607/18/2023 19:11:28 - INFO - __main__ - train loss is 13.811701349914074\n",
      "Steps:   8%| | 1257/15000 [08:06<41:35,  5.51it/s, lr=9.99e-6, step_loss=0.0055907/18/2023 19:11:28 - INFO - __main__ - train loss is 13.989442594349384\n",
      "Steps:   8%|▏ | 1258/15000 [08:06<41:42,  5.49it/s, lr=9.99e-6, step_loss=0.178]07/18/2023 19:11:28 - INFO - __main__ - train loss is 14.088678762316704\n",
      "Steps:   8%| | 1259/15000 [08:06<41:39,  5.50it/s, lr=9.99e-6, step_loss=0.0992]07/18/2023 19:11:29 - INFO - __main__ - train loss is 14.841320797801018\n",
      "Steps:   8%|▏ | 1260/15000 [08:06<41:44,  5.49it/s, lr=9.99e-6, step_loss=0.753]07/18/2023 19:11:29 - INFO - __main__ - train loss is 15.019936189055443\n",
      "Steps:   8%|▏ | 1261/15000 [08:07<55:46,  4.11it/s, lr=9.99e-6, step_loss=0.179]07/18/2023 19:11:30 - INFO - __main__ - Per validation step average loss is 0.3967619240283966\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Cumulative validation average loss is 0.3967619240283966\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Per validation step average loss is 0.06205446273088455\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Cumulative validation average loss is 0.45881638675928116\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Per validation step average loss is 0.6458680629730225\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Cumulative validation average loss is 1.1046844497323036\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Per validation step average loss is 0.3414667844772339\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Cumulative validation average loss is 1.4461512342095375\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Per validation step average loss is 0.15891873836517334\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Cumulative validation average loss is 1.6050699725747108\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Per validation step average loss is 0.0024417126551270485\n",
      "07/18/2023 19:11:30 - INFO - __main__ - Cumulative validation average loss is 1.607511685229838\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Per validation step average loss is 0.1842515766620636\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Cumulative validation average loss is 1.7917632618919015\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Per validation step average loss is 0.3844369351863861\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Cumulative validation average loss is 2.1762001970782876\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Per validation step average loss is 0.002429727930575609\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Cumulative validation average loss is 2.178629925008863\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Per validation step average loss is 0.0129465963691473\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Cumulative validation average loss is 2.1915765213780105\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Per validation step average loss is 0.10227423906326294\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Cumulative validation average loss is 2.2938507604412735\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Per validation step average loss is 0.06445779651403427\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Cumulative validation average loss is 2.3583085569553077\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Average validation loss for Epoch 12 is 0.19652571307960898\n",
      "07/18/2023 19:11:31 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:11:44 - INFO - __main__ - Starting epoch 13\n",
      "07/18/2023 19:11:45 - INFO - __main__ - train loss is 0.17214694619178772\n",
      "Steps:   8%| | 1262/15000 [08:23<18:39:15,  4.89s/it, lr=9.99e-6, step_loss=0.1707/18/2023 19:11:45 - INFO - __main__ - train loss is 0.579885721206665\n",
      "Steps:   8%| | 1263/15000 [08:23<13:16:23,  3.48s/it, lr=9.99e-6, step_loss=0.4007/18/2023 19:11:45 - INFO - __main__ - train loss is 0.5962082929909229\n",
      "Steps:   8%| | 1264/15000 [08:23<9:29:40,  2.49s/it, lr=9.99e-6, step_loss=0.01607/18/2023 19:11:45 - INFO - __main__ - train loss is 0.7255371548235416\n",
      "Steps:   8%| | 1265/15000 [08:23<6:51:08,  1.80s/it, lr=9.99e-6, step_loss=0.12907/18/2023 19:11:45 - INFO - __main__ - train loss is 0.7505405694246292\n",
      "Steps:   8%| | 1266/15000 [08:23<5:00:30,  1.31s/it, lr=9.99e-6, step_loss=0.02507/18/2023 19:11:46 - INFO - __main__ - train loss is 0.8348429501056671\n",
      "Steps:   8%| | 1267/15000 [08:23<3:42:50,  1.03it/s, lr=9.99e-6, step_loss=0.08407/18/2023 19:11:46 - INFO - __main__ - train loss is 1.0488450229167938\n",
      "Steps:   8%| | 1268/15000 [08:24<2:48:10,  1.36it/s, lr=9.99e-6, step_loss=0.21407/18/2023 19:11:46 - INFO - __main__ - train loss is 1.0646088980138302\n",
      "Steps:   8%| | 1269/15000 [08:24<2:09:54,  1.76it/s, lr=9.99e-6, step_loss=0.01507/18/2023 19:11:46 - INFO - __main__ - train loss is 1.0706809870898724\n",
      "Steps:   8%| | 1270/15000 [08:24<1:43:08,  2.22it/s, lr=9.99e-6, step_loss=0.00607/18/2023 19:11:46 - INFO - __main__ - train loss is 1.432689230889082\n",
      "Steps:   8%| | 1271/15000 [08:24<1:24:24,  2.71it/s, lr=9.99e-6, step_loss=0.36207/18/2023 19:11:46 - INFO - __main__ - train loss is 1.5974377803504467\n",
      "Steps:   8%| | 1272/15000 [08:24<1:11:50,  3.18it/s, lr=9.99e-6, step_loss=0.16507/18/2023 19:11:47 - INFO - __main__ - train loss is 1.6119902841746807\n",
      "Steps:   8%| | 1273/15000 [08:25<1:02:30,  3.66it/s, lr=9.99e-6, step_loss=0.01407/18/2023 19:11:47 - INFO - __main__ - train loss is 1.6595157459378242\n",
      "Steps:   8%| | 1274/15000 [08:25<55:58,  4.09it/s, lr=9.99e-6, step_loss=0.0475]07/18/2023 19:11:47 - INFO - __main__ - train loss is 1.8005496636033058\n",
      "Steps:   8%|▏ | 1275/15000 [08:25<51:24,  4.45it/s, lr=9.99e-6, step_loss=0.141]07/18/2023 19:11:47 - INFO - __main__ - train loss is 1.8023971781367436\n",
      "Steps:   9%| | 1276/15000 [08:25<48:09,  4.75it/s, lr=9.99e-6, step_loss=0.0018507/18/2023 19:11:47 - INFO - __main__ - train loss is 2.099457936012186\n",
      "Steps:   9%|▏ | 1277/15000 [08:25<45:58,  4.98it/s, lr=9.99e-6, step_loss=0.297]07/18/2023 19:11:48 - INFO - __main__ - train loss is 2.752513127052225\n",
      "Steps:   9%|▏ | 1278/15000 [08:25<44:35,  5.13it/s, lr=9.99e-6, step_loss=0.653]07/18/2023 19:11:48 - INFO - __main__ - train loss is 3.185805456363596\n",
      "Steps:   9%|▏ | 1279/15000 [08:26<43:27,  5.26it/s, lr=9.99e-6, step_loss=0.433]07/18/2023 19:11:48 - INFO - __main__ - train loss is 3.1950925436103716\n",
      "Steps:   9%| | 1280/15000 [08:26<42:57,  5.32it/s, lr=9.99e-6, step_loss=0.0092907/18/2023 19:11:48 - INFO - __main__ - train loss is 3.217463731416501\n",
      "Steps:   9%| | 1281/15000 [08:26<42:36,  5.37it/s, lr=9.99e-6, step_loss=0.0224]07/18/2023 19:11:48 - INFO - __main__ - train loss is 3.2222422381164506\n",
      "Steps:   9%| | 1282/15000 [08:26<42:04,  5.43it/s, lr=9.99e-6, step_loss=0.0047807/18/2023 19:11:48 - INFO - __main__ - train loss is 3.324203545344062\n",
      "Steps:   9%|▏ | 1283/15000 [08:26<41:43,  5.48it/s, lr=9.99e-6, step_loss=0.102]07/18/2023 19:11:49 - INFO - __main__ - train loss is 3.3393529487075284\n",
      "Steps:   9%| | 1284/15000 [08:27<41:28,  5.51it/s, lr=9.99e-6, step_loss=0.0151]07/18/2023 19:11:49 - INFO - __main__ - train loss is 3.38655374024529\n",
      "Steps:   9%| | 1285/15000 [08:27<41:19,  5.53it/s, lr=9.99e-6, step_loss=0.0472]07/18/2023 19:11:49 - INFO - __main__ - train loss is 3.3977401956217363\n",
      "Steps:   9%| | 1286/15000 [08:27<41:22,  5.53it/s, lr=9.99e-6, step_loss=0.0112]07/18/2023 19:11:49 - INFO - __main__ - train loss is 3.5511861845152453\n",
      "Steps:   9%|▏ | 1287/15000 [08:27<41:12,  5.55it/s, lr=9.99e-6, step_loss=0.153]07/18/2023 19:11:49 - INFO - __main__ - train loss is 3.7134823902742937\n",
      "Steps:   9%|▏ | 1288/15000 [08:27<41:05,  5.56it/s, lr=9.99e-6, step_loss=0.162]07/18/2023 19:11:50 - INFO - __main__ - train loss is 3.8897974892752245\n",
      "Steps:   9%|▏ | 1289/15000 [08:27<41:02,  5.57it/s, lr=9.99e-6, step_loss=0.176]07/18/2023 19:11:50 - INFO - __main__ - train loss is 3.9140216029481962\n",
      "Steps:   9%| | 1290/15000 [08:28<40:59,  5.57it/s, lr=9.99e-6, step_loss=0.0242]07/18/2023 19:11:50 - INFO - __main__ - train loss is 3.922774267499335\n",
      "Steps:   9%| | 1291/15000 [08:28<40:59,  5.57it/s, lr=9.99e-6, step_loss=0.0087507/18/2023 19:11:50 - INFO - __main__ - train loss is 3.927621956099756\n",
      "Steps:   9%| | 1292/15000 [08:28<40:56,  5.58it/s, lr=9.99e-6, step_loss=0.0048507/18/2023 19:11:50 - INFO - __main__ - train loss is 4.235129471053369\n",
      "Steps:   9%|▏ | 1293/15000 [08:28<40:52,  5.59it/s, lr=9.99e-6, step_loss=0.308]07/18/2023 19:11:50 - INFO - __main__ - train loss is 4.245254659210332\n",
      "Steps:   9%| | 1294/15000 [08:28<40:51,  5.59it/s, lr=9.99e-6, step_loss=0.0101]07/18/2023 19:11:51 - INFO - __main__ - train loss is 4.259727497701533\n",
      "Steps:   9%| | 1295/15000 [08:29<40:48,  5.60it/s, lr=9.99e-6, step_loss=0.0145]07/18/2023 19:11:51 - INFO - __main__ - train loss is 4.30065408453811\n",
      "Steps:   9%| | 1296/15000 [08:29<41:00,  5.57it/s, lr=9.99e-6, step_loss=0.0409]07/18/2023 19:11:51 - INFO - __main__ - train loss is 4.3085700563387945\n",
      "Steps:   9%| | 1297/15000 [08:29<41:22,  5.52it/s, lr=9.99e-6, step_loss=0.0079207/18/2023 19:11:51 - INFO - __main__ - train loss is 4.310320091084577\n",
      "Steps:   9%| | 1298/15000 [08:29<42:00,  5.44it/s, lr=9.99e-6, step_loss=0.0017507/18/2023 19:11:51 - INFO - __main__ - train loss is 4.333153715939261\n",
      "Steps:   9%| | 1299/15000 [08:29<41:56,  5.44it/s, lr=9.99e-6, step_loss=0.0228]07/18/2023 19:11:52 - INFO - __main__ - train loss is 4.345411920570768\n",
      "Steps:   9%| | 1300/15000 [08:29<41:35,  5.49it/s, lr=9.99e-6, step_loss=0.0123]07/18/2023 19:11:52 - INFO - __main__ - train loss is 4.383168657892384\n",
      "Steps:   9%| | 1301/15000 [08:30<41:24,  5.51it/s, lr=9.99e-6, step_loss=0.0378]07/18/2023 19:11:52 - INFO - __main__ - train loss is 4.618971919291653\n",
      "Steps:   9%|▏ | 1302/15000 [08:30<41:11,  5.54it/s, lr=9.99e-6, step_loss=0.236]07/18/2023 19:11:52 - INFO - __main__ - train loss is 4.639978222199716\n",
      "Steps:   9%|▏ | 1303/15000 [08:30<41:01,  5.56it/s, lr=9.99e-6, step_loss=0.021]07/18/2023 19:11:52 - INFO - __main__ - train loss is 4.798163614817895\n",
      "Steps:   9%|▏ | 1304/15000 [08:30<40:55,  5.58it/s, lr=9.99e-6, step_loss=0.158]07/18/2023 19:11:52 - INFO - __main__ - train loss is 4.830720096477307\n",
      "Steps:   9%| | 1305/15000 [08:30<41:05,  5.55it/s, lr=9.99e-6, step_loss=0.0326]07/18/2023 19:11:53 - INFO - __main__ - train loss is 4.944072708138265\n",
      "Steps:   9%|▏ | 1306/15000 [08:31<41:33,  5.49it/s, lr=9.99e-6, step_loss=0.113]07/18/2023 19:11:53 - INFO - __main__ - train loss is 5.5374220457160845\n",
      "Steps:   9%|▏ | 1307/15000 [08:31<41:23,  5.51it/s, lr=9.99e-6, step_loss=0.593]07/18/2023 19:11:53 - INFO - __main__ - train loss is 5.555468752630986\n",
      "Steps:   9%|▏ | 1308/15000 [08:31<41:10,  5.54it/s, lr=9.99e-6, step_loss=0.018]07/18/2023 19:11:53 - INFO - __main__ - train loss is 5.6346866335952654\n",
      "Steps:   9%| | 1309/15000 [08:31<41:03,  5.56it/s, lr=9.99e-6, step_loss=0.0792]07/18/2023 19:11:53 - INFO - __main__ - train loss is 5.6657161839539185\n",
      "Steps:   9%|▏ | 1310/15000 [08:31<40:56,  5.57it/s, lr=9.99e-6, step_loss=0.031]07/18/2023 19:11:54 - INFO - __main__ - train loss is 5.667636469355784\n",
      "Steps:   9%| | 1311/15000 [08:31<40:51,  5.58it/s, lr=9.99e-6, step_loss=0.0019207/18/2023 19:11:54 - INFO - __main__ - train loss is 5.730532691231929\n",
      "Steps:   9%| | 1312/15000 [08:32<40:53,  5.58it/s, lr=9.99e-6, step_loss=0.0629]07/18/2023 19:11:54 - INFO - __main__ - train loss is 5.979217201820575\n",
      "Steps:   9%|▏ | 1313/15000 [08:32<40:50,  5.59it/s, lr=9.99e-6, step_loss=0.249]07/18/2023 19:11:54 - INFO - __main__ - train loss is 6.5529989305650815\n",
      "Steps:   9%|▏ | 1314/15000 [08:32<41:09,  5.54it/s, lr=9.99e-6, step_loss=0.574]07/18/2023 19:11:54 - INFO - __main__ - train loss is 7.386797100654803\n",
      "Steps:   9%|▏ | 1315/15000 [08:32<41:23,  5.51it/s, lr=9.99e-6, step_loss=0.834]07/18/2023 19:11:54 - INFO - __main__ - train loss is 7.504430540255271\n",
      "Steps:   9%|▏ | 1316/15000 [08:32<41:08,  5.54it/s, lr=9.99e-6, step_loss=0.118]07/18/2023 19:11:55 - INFO - __main__ - train loss is 7.6390868205344304\n",
      "Steps:   9%|▏ | 1317/15000 [08:32<41:11,  5.54it/s, lr=9.99e-6, step_loss=0.135]07/18/2023 19:11:55 - INFO - __main__ - train loss is 7.900477744988166\n",
      "Steps:   9%|▏ | 1318/15000 [08:33<41:01,  5.56it/s, lr=9.99e-6, step_loss=0.261]07/18/2023 19:11:55 - INFO - __main__ - train loss is 8.002302371314727\n",
      "Steps:   9%|▏ | 1319/15000 [08:33<40:55,  5.57it/s, lr=9.99e-6, step_loss=0.102]07/18/2023 19:11:55 - INFO - __main__ - train loss is 8.120184354833327\n",
      "Steps:   9%|▏ | 1320/15000 [08:33<40:51,  5.58it/s, lr=9.99e-6, step_loss=0.118]07/18/2023 19:11:55 - INFO - __main__ - train loss is 8.124545348226093\n",
      "Steps:   9%| | 1321/15000 [08:33<40:46,  5.59it/s, lr=9.99e-6, step_loss=0.0043607/18/2023 19:11:55 - INFO - __main__ - train loss is 8.171801698743366\n",
      "Steps:   9%| | 1322/15000 [08:33<40:49,  5.58it/s, lr=9.99e-6, step_loss=0.0473]07/18/2023 19:11:56 - INFO - __main__ - train loss is 8.174867101828568\n",
      "Steps:   9%| | 1323/15000 [08:34<40:47,  5.59it/s, lr=9.99e-6, step_loss=0.0030707/18/2023 19:11:56 - INFO - __main__ - train loss is 8.1768325882731\n",
      "Steps:   9%| | 1324/15000 [08:34<40:45,  5.59it/s, lr=9.99e-6, step_loss=0.0019707/18/2023 19:11:56 - INFO - __main__ - train loss is 8.21270565118175\n",
      "Steps:   9%| | 1325/15000 [08:34<40:43,  5.60it/s, lr=9.99e-6, step_loss=0.0359]07/18/2023 19:11:56 - INFO - __main__ - train loss is 8.214660424622707\n",
      "Steps:   9%| | 1326/15000 [08:34<40:43,  5.60it/s, lr=9.99e-6, step_loss=0.0019507/18/2023 19:11:56 - INFO - __main__ - train loss is 8.25056147936266\n",
      "Steps:   9%| | 1327/15000 [08:34<40:44,  5.59it/s, lr=9.99e-6, step_loss=0.0359]07/18/2023 19:11:57 - INFO - __main__ - train loss is 8.691857013734989\n",
      "Steps:   9%|▏ | 1328/15000 [08:34<40:43,  5.60it/s, lr=9.99e-6, step_loss=0.441]07/18/2023 19:11:57 - INFO - __main__ - train loss is 8.923060241970234\n",
      "Steps:   9%|▏ | 1329/15000 [08:35<40:42,  5.60it/s, lr=9.99e-6, step_loss=0.231]07/18/2023 19:11:57 - INFO - __main__ - train loss is 9.364924970897846\n",
      "Steps:   9%|▏ | 1330/15000 [08:35<40:40,  5.60it/s, lr=9.99e-6, step_loss=0.442]07/18/2023 19:11:57 - INFO - __main__ - train loss is 9.396055834251456\n",
      "Steps:   9%| | 1331/15000 [08:35<40:38,  5.61it/s, lr=9.99e-6, step_loss=0.0311]07/18/2023 19:11:57 - INFO - __main__ - train loss is 9.542489664512686\n",
      "Steps:   9%|▏ | 1332/15000 [08:35<40:35,  5.61it/s, lr=9.99e-6, step_loss=0.146]07/18/2023 19:11:57 - INFO - __main__ - train loss is 9.545267666573636\n",
      "Steps:   9%| | 1333/15000 [08:35<40:49,  5.58it/s, lr=9.99e-6, step_loss=0.0027807/18/2023 19:11:58 - INFO - __main__ - train loss is 9.715419228072278\n",
      "Steps:   9%|▎  | 1334/15000 [08:36<40:47,  5.58it/s, lr=9.99e-6, step_loss=0.17]07/18/2023 19:11:58 - INFO - __main__ - train loss is 9.76909774064552\n",
      "Steps:   9%| | 1335/15000 [08:36<40:44,  5.59it/s, lr=9.99e-6, step_loss=0.0537]07/18/2023 19:11:58 - INFO - __main__ - train loss is 9.850638235802762\n",
      "Steps:   9%| | 1336/15000 [08:36<40:41,  5.60it/s, lr=9.99e-6, step_loss=0.0815]07/18/2023 19:11:58 - INFO - __main__ - train loss is 10.02892602502834\n",
      "Steps:   9%|▏ | 1337/15000 [08:36<40:38,  5.60it/s, lr=9.99e-6, step_loss=0.178]07/18/2023 19:11:58 - INFO - __main__ - train loss is 10.128633077139966\n",
      "Steps:   9%| | 1338/15000 [08:36<40:39,  5.60it/s, lr=9.99e-6, step_loss=0.0997]07/18/2023 19:11:59 - INFO - __main__ - train loss is 10.31259320199024\n",
      "Steps:   9%|▏ | 1339/15000 [08:36<40:38,  5.60it/s, lr=9.99e-6, step_loss=0.184]07/18/2023 19:11:59 - INFO - __main__ - train loss is 10.344228128786199\n",
      "Steps:   9%| | 1340/15000 [08:37<40:40,  5.60it/s, lr=9.99e-6, step_loss=0.0316]07/18/2023 19:11:59 - INFO - __main__ - train loss is 10.4092476767255\n",
      "Steps:   9%|▏ | 1341/15000 [08:37<40:40,  5.60it/s, lr=9.99e-6, step_loss=0.065]07/18/2023 19:11:59 - INFO - __main__ - train loss is 10.43542351841461\n",
      "Steps:   9%| | 1342/15000 [08:37<40:38,  5.60it/s, lr=9.99e-6, step_loss=0.0262]07/18/2023 19:11:59 - INFO - __main__ - train loss is 11.013371731038205\n",
      "Steps:   9%|▏ | 1343/15000 [08:37<40:55,  5.56it/s, lr=9.99e-6, step_loss=0.578]07/18/2023 19:11:59 - INFO - __main__ - train loss is 11.041500479797833\n",
      "Steps:   9%| | 1344/15000 [08:37<41:11,  5.52it/s, lr=9.99e-6, step_loss=0.0281]07/18/2023 19:12:00 - INFO - __main__ - train loss is 11.403047562460415\n",
      "Steps:   9%|▏ | 1345/15000 [08:38<41:21,  5.50it/s, lr=9.99e-6, step_loss=0.362]07/18/2023 19:12:00 - INFO - __main__ - train loss is 11.410458567435853\n",
      "Steps:   9%| | 1346/15000 [08:38<41:09,  5.53it/s, lr=9.99e-6, step_loss=0.0074107/18/2023 19:12:00 - INFO - __main__ - train loss is 11.43731537356507\n",
      "Steps:   9%| | 1347/15000 [08:38<40:58,  5.55it/s, lr=9.99e-6, step_loss=0.0269]07/18/2023 19:12:00 - INFO - __main__ - train loss is 11.467254659975879\n",
      "Steps:   9%| | 1348/15000 [08:38<40:59,  5.55it/s, lr=9.99e-6, step_loss=0.0299]07/18/2023 19:12:00 - INFO - __main__ - train loss is 11.537754109944217\n",
      "Steps:   9%| | 1349/15000 [08:38<40:51,  5.57it/s, lr=9.99e-6, step_loss=0.0705]07/18/2023 19:12:01 - INFO - __main__ - train loss is 11.754626727546565\n",
      "Steps:   9%|▏ | 1350/15000 [08:38<40:47,  5.58it/s, lr=9.99e-6, step_loss=0.217]07/18/2023 19:12:01 - INFO - __main__ - train loss is 11.762537406641059\n",
      "Steps:   9%| | 1351/15000 [08:39<40:43,  5.59it/s, lr=9.99e-6, step_loss=0.0079107/18/2023 19:12:01 - INFO - __main__ - train loss is 11.826005646842532\n",
      "Steps:   9%| | 1352/15000 [08:39<40:58,  5.55it/s, lr=9.99e-6, step_loss=0.0635]07/18/2023 19:12:01 - INFO - __main__ - train loss is 11.867075653630309\n",
      "Steps:   9%| | 1353/15000 [08:39<41:17,  5.51it/s, lr=9.99e-6, step_loss=0.0411]07/18/2023 19:12:01 - INFO - __main__ - train loss is 11.869240740896203\n",
      "Steps:   9%| | 1354/15000 [08:39<41:04,  5.54it/s, lr=9.99e-6, step_loss=0.0021707/18/2023 19:12:01 - INFO - __main__ - train loss is 12.058874482871033\n",
      "Steps:   9%|▎  | 1355/15000 [08:39<40:52,  5.56it/s, lr=9.99e-6, step_loss=0.19]07/18/2023 19:12:02 - INFO - __main__ - train loss is 12.193331296206452\n",
      "Steps:   9%|▏ | 1356/15000 [08:39<40:45,  5.58it/s, lr=9.99e-6, step_loss=0.134]07/18/2023 19:12:02 - INFO - __main__ - train loss is 12.33505004143808\n",
      "Steps:   9%|▏ | 1357/15000 [08:40<40:39,  5.59it/s, lr=9.99e-6, step_loss=0.142]07/18/2023 19:12:02 - INFO - __main__ - train loss is 12.352928801090457\n",
      "Steps:   9%| | 1358/15000 [08:40<56:55,  3.99it/s, lr=9.99e-6, step_loss=0.0179]07/18/2023 19:12:03 - INFO - __main__ - Per validation step average loss is 0.11795471608638763\n",
      "07/18/2023 19:12:03 - INFO - __main__ - Cumulative validation average loss is 0.11795471608638763\n",
      "07/18/2023 19:12:03 - INFO - __main__ - Per validation step average loss is 0.09029866755008698\n",
      "07/18/2023 19:12:03 - INFO - __main__ - Cumulative validation average loss is 0.2082533836364746\n",
      "07/18/2023 19:12:03 - INFO - __main__ - Per validation step average loss is 0.4818188548088074\n",
      "07/18/2023 19:12:03 - INFO - __main__ - Cumulative validation average loss is 0.690072238445282\n",
      "07/18/2023 19:12:03 - INFO - __main__ - Per validation step average loss is 0.032497141510248184\n",
      "07/18/2023 19:12:03 - INFO - __main__ - Cumulative validation average loss is 0.7225693799555302\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Per validation step average loss is 0.011519428342580795\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Cumulative validation average loss is 0.734088808298111\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Per validation step average loss is 0.0021127909421920776\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Cumulative validation average loss is 0.736201599240303\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Per validation step average loss is 0.002343341475352645\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Cumulative validation average loss is 0.7385449407156557\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Per validation step average loss is 0.005508336704224348\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Cumulative validation average loss is 0.74405327741988\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Per validation step average loss is 0.03194058686494827\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Cumulative validation average loss is 0.7759938642848283\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Per validation step average loss is 0.0019939260091632605\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Cumulative validation average loss is 0.7779877902939916\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Per validation step average loss is 0.0015726613346487284\n",
      "07/18/2023 19:12:04 - INFO - __main__ - Cumulative validation average loss is 0.7795604516286403\n",
      "07/18/2023 19:12:05 - INFO - __main__ - Per validation step average loss is 0.061115607619285583\n",
      "07/18/2023 19:12:05 - INFO - __main__ - Cumulative validation average loss is 0.8406760592479259\n",
      "07/18/2023 19:12:05 - INFO - __main__ - Average validation loss for Epoch 13 is 0.07005633827066049\n",
      "07/18/2023 19:12:05 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:12:17 - INFO - __main__ - Starting epoch 14\n",
      "07/18/2023 19:12:18 - INFO - __main__ - train loss is 0.01346818171441555\n",
      "Steps:   9%| | 1359/15000 [08:56<18:30:03,  4.88s/it, lr=9.99e-6, step_loss=0.0107/18/2023 19:12:18 - INFO - __main__ - train loss is 0.9524159785360098\n",
      "Steps:   9%| | 1360/15000 [08:56<13:09:49,  3.47s/it, lr=9.99e-6, step_loss=0.9307/18/2023 19:12:18 - INFO - __main__ - train loss is 0.9724101815372705\n",
      "Steps:   9%| | 1361/15000 [08:56<9:25:48,  2.49s/it, lr=9.99e-6, step_loss=0.02]07/18/2023 19:12:18 - INFO - __main__ - train loss is 1.0695476327091455\n",
      "Steps:   9%| | 1362/15000 [08:56<6:48:30,  1.80s/it, lr=9.99e-6, step_loss=0.09707/18/2023 19:12:19 - INFO - __main__ - train loss is 1.0829040771350265\n",
      "Steps:   9%| | 1363/15000 [08:57<4:58:13,  1.31s/it, lr=9.99e-6, step_loss=0.01307/18/2023 19:12:19 - INFO - __main__ - train loss is 1.1264754524454474\n",
      "Steps:   9%| | 1364/15000 [08:57<3:40:53,  1.03it/s, lr=9.99e-6, step_loss=0.04307/18/2023 19:12:19 - INFO - __main__ - train loss is 1.153625006787479\n",
      "Steps:   9%| | 1365/15000 [08:57<2:46:55,  1.36it/s, lr=9.99e-6, step_loss=0.02707/18/2023 19:12:19 - INFO - __main__ - train loss is 1.3409103704616427\n",
      "Steps:   9%| | 1366/15000 [08:57<2:09:49,  1.75it/s, lr=9.99e-6, step_loss=0.18707/18/2023 19:12:19 - INFO - __main__ - train loss is 1.3473255140706897\n",
      "Steps:   9%| | 1367/15000 [08:57<1:43:11,  2.20it/s, lr=9.99e-6, step_loss=0.00607/18/2023 19:12:20 - INFO - __main__ - train loss is 1.3550582118332386\n",
      "Steps:   9%| | 1368/15000 [08:57<1:25:01,  2.67it/s, lr=9.99e-6, step_loss=0.00707/18/2023 19:12:20 - INFO - __main__ - train loss is 1.3813526947051287\n",
      "Steps:   9%| | 1369/15000 [08:58<1:11:49,  3.16it/s, lr=9.99e-6, step_loss=0.02607/18/2023 19:12:20 - INFO - __main__ - train loss is 1.5688299853354692\n",
      "Steps:   9%| | 1370/15000 [08:58<1:02:33,  3.63it/s, lr=9.99e-6, step_loss=0.18707/18/2023 19:12:20 - INFO - __main__ - train loss is 1.6620781142264605\n",
      "Steps:   9%| | 1371/15000 [08:58<56:06,  4.05it/s, lr=9.99e-6, step_loss=0.0932]07/18/2023 19:12:20 - INFO - __main__ - train loss is 1.6682005543261766\n",
      "Steps:   9%| | 1372/15000 [08:58<51:36,  4.40it/s, lr=9.99e-6, step_loss=0.0061207/18/2023 19:12:20 - INFO - __main__ - train loss is 2.2250524181872606\n",
      "Steps:   9%|▏ | 1373/15000 [08:58<48:23,  4.69it/s, lr=9.99e-6, step_loss=0.557]07/18/2023 19:12:21 - INFO - __main__ - train loss is 2.2284032858442515\n",
      "Steps:   9%| | 1374/15000 [08:59<45:57,  4.94it/s, lr=9.99e-6, step_loss=0.0033507/18/2023 19:12:21 - INFO - __main__ - train loss is 2.5055031932424754\n",
      "Steps:   9%|▏ | 1375/15000 [08:59<44:16,  5.13it/s, lr=9.99e-6, step_loss=0.277]07/18/2023 19:12:21 - INFO - __main__ - train loss is 2.6459474868606776\n",
      "Steps:   9%|▎  | 1376/15000 [08:59<43:06,  5.27it/s, lr=9.99e-6, step_loss=0.14]07/18/2023 19:12:21 - INFO - __main__ - train loss is 2.6482440137770027\n",
      "Steps:   9%| | 1377/15000 [08:59<42:24,  5.35it/s, lr=9.99e-6, step_loss=0.0023]07/18/2023 19:12:21 - INFO - __main__ - train loss is 2.6778167949523777\n",
      "Steps:   9%| | 1378/15000 [08:59<41:48,  5.43it/s, lr=9.99e-6, step_loss=0.0296]07/18/2023 19:12:22 - INFO - __main__ - train loss is 2.7649899588432163\n",
      "Steps:   9%| | 1379/15000 [08:59<41:27,  5.47it/s, lr=9.99e-6, step_loss=0.0872]07/18/2023 19:12:22 - INFO - __main__ - train loss is 2.7688620125409216\n",
      "Steps:   9%| | 1380/15000 [09:00<41:08,  5.52it/s, lr=9.99e-6, step_loss=0.0038707/18/2023 19:12:22 - INFO - __main__ - train loss is 2.779349288670346\n",
      "Steps:   9%| | 1381/15000 [09:00<40:53,  5.55it/s, lr=9.99e-6, step_loss=0.0105]07/18/2023 19:12:22 - INFO - __main__ - train loss is 2.9936298939865083\n",
      "Steps:   9%|▏ | 1382/15000 [09:00<40:43,  5.57it/s, lr=9.99e-6, step_loss=0.214]07/18/2023 19:12:22 - INFO - __main__ - train loss is 3.261702677933499\n",
      "Steps:   9%|▏ | 1383/15000 [09:00<40:36,  5.59it/s, lr=9.99e-6, step_loss=0.268]07/18/2023 19:12:22 - INFO - __main__ - train loss is 3.2635340449633077\n",
      "Steps:   9%| | 1384/15000 [09:00<40:35,  5.59it/s, lr=9.99e-6, step_loss=0.0018307/18/2023 19:12:23 - INFO - __main__ - train loss is 3.277693582815118\n",
      "Steps:   9%| | 1385/15000 [09:00<40:35,  5.59it/s, lr=9.99e-6, step_loss=0.0142]07/18/2023 19:12:23 - INFO - __main__ - train loss is 3.2844929724233225\n",
      "Steps:   9%| | 1386/15000 [09:01<40:35,  5.59it/s, lr=9.99e-6, step_loss=0.0068]07/18/2023 19:12:23 - INFO - __main__ - train loss is 3.3359178855316713\n",
      "Steps:   9%| | 1387/15000 [09:01<40:33,  5.59it/s, lr=9.99e-6, step_loss=0.0514]07/18/2023 19:12:23 - INFO - __main__ - train loss is 3.4024124547140673\n",
      "Steps:   9%| | 1388/15000 [09:01<40:35,  5.59it/s, lr=9.99e-6, step_loss=0.0665]07/18/2023 19:12:23 - INFO - __main__ - train loss is 3.4066854995908216\n",
      "Steps:   9%| | 1389/15000 [09:01<40:36,  5.59it/s, lr=9.99e-6, step_loss=0.0042707/18/2023 19:12:23 - INFO - __main__ - train loss is 3.4103379825828597\n",
      "Steps:   9%| | 1390/15000 [09:01<40:32,  5.60it/s, lr=9.99e-6, step_loss=0.0036507/18/2023 19:12:24 - INFO - __main__ - train loss is 3.4982310886261985\n",
      "Steps:   9%| | 1391/15000 [09:02<40:52,  5.55it/s, lr=9.99e-6, step_loss=0.0879]07/18/2023 19:12:24 - INFO - __main__ - train loss is 3.5208697019843385\n",
      "Steps:   9%| | 1392/15000 [09:02<40:49,  5.55it/s, lr=9.99e-6, step_loss=0.0226]07/18/2023 19:12:24 - INFO - __main__ - train loss is 3.676942795398645\n",
      "Steps:   9%|▏ | 1393/15000 [09:02<40:51,  5.55it/s, lr=9.99e-6, step_loss=0.156]07/18/2023 19:12:24 - INFO - __main__ - train loss is 3.824669077876024\n",
      "Steps:   9%|▏ | 1394/15000 [09:02<40:42,  5.57it/s, lr=9.99e-6, step_loss=0.148]07/18/2023 19:12:24 - INFO - __main__ - train loss is 3.8278470734367147\n",
      "Steps:   9%| | 1395/15000 [09:02<40:37,  5.58it/s, lr=9.99e-6, step_loss=0.0031807/18/2023 19:12:25 - INFO - __main__ - train loss is 3.8418994589010254\n",
      "Steps:   9%| | 1396/15000 [09:02<40:56,  5.54it/s, lr=9.99e-6, step_loss=0.0141]07/18/2023 19:12:25 - INFO - __main__ - train loss is 3.919318732456304\n",
      "Steps:   9%| | 1397/15000 [09:03<41:10,  5.51it/s, lr=9.99e-6, step_loss=0.0774]07/18/2023 19:12:25 - INFO - __main__ - train loss is 3.9431614509085193\n",
      "Steps:   9%| | 1398/15000 [09:03<40:53,  5.54it/s, lr=9.99e-6, step_loss=0.0238]07/18/2023 19:12:25 - INFO - __main__ - train loss is 4.22039099840913\n",
      "Steps:   9%|▏ | 1399/15000 [09:03<40:42,  5.57it/s, lr=9.99e-6, step_loss=0.277]07/18/2023 19:12:25 - INFO - __main__ - train loss is 4.553169124410488\n",
      "Steps:   9%|▏ | 1400/15000 [09:03<40:35,  5.59it/s, lr=9.99e-6, step_loss=0.333]07/18/2023 19:12:25 - INFO - __main__ - train loss is 4.724431880400516\n",
      "Steps:   9%|▏ | 1401/15000 [09:03<40:30,  5.59it/s, lr=9.99e-6, step_loss=0.171]07/18/2023 19:12:26 - INFO - __main__ - train loss is 4.725981212104671\n",
      "Steps:   9%| | 1402/15000 [09:04<40:26,  5.60it/s, lr=9.99e-6, step_loss=0.0015507/18/2023 19:12:26 - INFO - __main__ - train loss is 4.732574138208292\n",
      "Steps:   9%| | 1403/15000 [09:04<40:24,  5.61it/s, lr=9.99e-6, step_loss=0.0065907/18/2023 19:12:26 - INFO - __main__ - train loss is 4.735479987110011\n",
      "Steps:   9%| | 1404/15000 [09:04<40:21,  5.61it/s, lr=9.99e-6, step_loss=0.0029107/18/2023 19:12:26 - INFO - __main__ - train loss is 4.869487873162143\n",
      "Steps:   9%|▏ | 1405/15000 [09:04<40:21,  5.61it/s, lr=9.99e-6, step_loss=0.134]07/18/2023 19:12:26 - INFO - __main__ - train loss is 4.919559053028934\n",
      "Steps:   9%| | 1406/15000 [09:04<40:27,  5.60it/s, lr=9.99e-6, step_loss=0.0501]07/18/2023 19:12:27 - INFO - __main__ - train loss is 5.266945234383456\n",
      "Steps:   9%|▏ | 1407/15000 [09:04<40:26,  5.60it/s, lr=9.99e-6, step_loss=0.347]07/18/2023 19:12:27 - INFO - __main__ - train loss is 5.273483055527322\n",
      "Steps:   9%| | 1408/15000 [09:05<40:23,  5.61it/s, lr=9.99e-6, step_loss=0.0065407/18/2023 19:12:27 - INFO - __main__ - train loss is 5.285637792083435\n",
      "Steps:   9%| | 1409/15000 [09:05<40:22,  5.61it/s, lr=9.99e-6, step_loss=0.0122]07/18/2023 19:12:27 - INFO - __main__ - train loss is 5.407652955385856\n",
      "Steps:   9%|▏ | 1410/15000 [09:05<40:22,  5.61it/s, lr=9.99e-6, step_loss=0.122]07/18/2023 19:12:27 - INFO - __main__ - train loss is 5.748775761458091\n",
      "Steps:   9%|▏ | 1411/15000 [09:05<40:20,  5.61it/s, lr=9.99e-6, step_loss=0.341]07/18/2023 19:12:27 - INFO - __main__ - train loss is 5.863553482922725\n",
      "Steps:   9%|▏ | 1412/15000 [09:05<40:23,  5.61it/s, lr=9.99e-6, step_loss=0.115]07/18/2023 19:12:28 - INFO - __main__ - train loss is 6.465349394711666\n",
      "Steps:   9%|▏ | 1413/15000 [09:05<40:24,  5.60it/s, lr=9.99e-6, step_loss=0.602]07/18/2023 19:12:28 - INFO - __main__ - train loss is 6.483069088193588\n",
      "Steps:   9%| | 1414/15000 [09:06<40:27,  5.60it/s, lr=9.99e-6, step_loss=0.0177]07/18/2023 19:12:28 - INFO - __main__ - train loss is 6.647579725715332\n",
      "Steps:   9%|▏ | 1415/15000 [09:06<40:50,  5.54it/s, lr=9.99e-6, step_loss=0.165]07/18/2023 19:12:28 - INFO - __main__ - train loss is 6.745825733873062\n",
      "Steps:   9%| | 1416/15000 [09:06<41:22,  5.47it/s, lr=9.99e-6, step_loss=0.0982]07/18/2023 19:12:28 - INFO - __main__ - train loss is 6.89679823431652\n",
      "Steps:   9%|▏ | 1417/15000 [09:06<41:32,  5.45it/s, lr=9.99e-6, step_loss=0.151]07/18/2023 19:12:29 - INFO - __main__ - train loss is 6.90532477281522\n",
      "Steps:   9%| | 1418/15000 [09:06<41:10,  5.50it/s, lr=9.99e-6, step_loss=0.0085307/18/2023 19:12:29 - INFO - __main__ - train loss is 6.917726726154797\n",
      "Steps:   9%| | 1419/15000 [09:07<40:59,  5.52it/s, lr=9.99e-6, step_loss=0.0124]07/18/2023 19:12:29 - INFO - __main__ - train loss is 7.272994966129772\n",
      "Steps:   9%|▏ | 1420/15000 [09:07<40:55,  5.53it/s, lr=9.99e-6, step_loss=0.355]07/18/2023 19:12:29 - INFO - __main__ - train loss is 7.993555695633404\n",
      "Steps:   9%|▏ | 1421/15000 [09:07<41:08,  5.50it/s, lr=9.99e-6, step_loss=0.721]07/18/2023 19:12:29 - INFO - __main__ - train loss is 7.996575141209178\n",
      "Steps:   9%| | 1422/15000 [09:07<40:54,  5.53it/s, lr=9.99e-6, step_loss=0.0030207/18/2023 19:12:29 - INFO - __main__ - train loss is 8.362649762886576\n",
      "Steps:   9%|▏ | 1423/15000 [09:07<40:43,  5.56it/s, lr=9.99e-6, step_loss=0.366]07/18/2023 19:12:30 - INFO - __main__ - train loss is 8.365752151119523\n",
      "Steps:   9%| | 1424/15000 [09:07<40:34,  5.58it/s, lr=9.99e-6, step_loss=0.0031]07/18/2023 19:12:30 - INFO - __main__ - train loss is 8.407817171770148\n",
      "Steps:  10%| | 1425/15000 [09:08<40:52,  5.54it/s, lr=9.99e-6, step_loss=0.0421]07/18/2023 19:12:30 - INFO - __main__ - train loss is 8.523890653508715\n",
      "Steps:  10%|▏ | 1426/15000 [09:08<40:54,  5.53it/s, lr=9.99e-6, step_loss=0.116]07/18/2023 19:12:30 - INFO - __main__ - train loss is 8.573856675880961\n",
      "Steps:  10%|▎  | 1427/15000 [09:08<41:09,  5.50it/s, lr=9.99e-6, step_loss=0.05]07/18/2023 19:12:30 - INFO - __main__ - train loss is 8.817195052164607\n",
      "Steps:  10%|▏ | 1428/15000 [09:08<41:02,  5.51it/s, lr=9.99e-6, step_loss=0.243]07/18/2023 19:12:30 - INFO - __main__ - train loss is 8.85332928027492\n",
      "Steps:  10%| | 1429/15000 [09:08<41:06,  5.50it/s, lr=9.99e-6, step_loss=0.0361]07/18/2023 19:12:31 - INFO - __main__ - train loss is 9.249938437598757\n",
      "Steps:  10%|▏ | 1430/15000 [09:09<41:17,  5.48it/s, lr=9.99e-6, step_loss=0.397]07/18/2023 19:12:31 - INFO - __main__ - train loss is 9.520124295610003\n",
      "Steps:  10%|▎  | 1431/15000 [09:09<41:16,  5.48it/s, lr=9.99e-6, step_loss=0.27]07/18/2023 19:12:31 - INFO - __main__ - train loss is 9.556398274260573\n",
      "Steps:  10%| | 1432/15000 [09:09<41:00,  5.51it/s, lr=9.99e-6, step_loss=0.0363]07/18/2023 19:12:31 - INFO - __main__ - train loss is 9.56961840193253\n",
      "Steps:  10%| | 1433/15000 [09:09<41:12,  5.49it/s, lr=9.99e-6, step_loss=0.0132]07/18/2023 19:12:31 - INFO - __main__ - train loss is 9.713073043036275\n",
      "Steps:  10%|▏ | 1434/15000 [09:09<41:04,  5.50it/s, lr=9.99e-6, step_loss=0.143]07/18/2023 19:12:32 - INFO - __main__ - train loss is 9.74457886989694\n",
      "Steps:  10%| | 1435/15000 [09:09<40:55,  5.52it/s, lr=9.99e-6, step_loss=0.0315]07/18/2023 19:12:32 - INFO - __main__ - train loss is 9.756668776157312\n",
      "Steps:  10%| | 1436/15000 [09:10<41:03,  5.51it/s, lr=9.99e-6, step_loss=0.0121]07/18/2023 19:12:32 - INFO - __main__ - train loss is 9.9477957932977\n",
      "Steps:  10%|▏ | 1437/15000 [09:10<41:07,  5.50it/s, lr=9.99e-6, step_loss=0.191]07/18/2023 19:12:32 - INFO - __main__ - train loss is 10.211086079361849\n",
      "Steps:  10%|▏ | 1438/15000 [09:10<41:06,  5.50it/s, lr=9.99e-6, step_loss=0.263]07/18/2023 19:12:32 - INFO - __main__ - train loss is 10.2131248092046\n",
      "Steps:  10%| | 1439/15000 [09:10<41:03,  5.50it/s, lr=9.99e-6, step_loss=0.0020407/18/2023 19:12:32 - INFO - __main__ - train loss is 10.216465940116905\n",
      "Steps:  10%| | 1440/15000 [09:10<40:51,  5.53it/s, lr=9.99e-6, step_loss=0.0033407/18/2023 19:12:33 - INFO - __main__ - train loss is 10.65675341093447\n",
      "Steps:  10%|▎  | 1441/15000 [09:11<40:40,  5.56it/s, lr=9.99e-6, step_loss=0.44]07/18/2023 19:12:33 - INFO - __main__ - train loss is 10.902964820503257\n",
      "Steps:  10%|▏ | 1442/15000 [09:11<41:09,  5.49it/s, lr=9.99e-6, step_loss=0.246]07/18/2023 19:12:33 - INFO - __main__ - train loss is 10.905493607162498\n",
      "Steps:  10%| | 1443/15000 [09:11<40:51,  5.53it/s, lr=9.99e-6, step_loss=0.0025307/18/2023 19:12:33 - INFO - __main__ - train loss is 11.150231023668312\n",
      "Steps:  10%|▏ | 1444/15000 [09:11<40:42,  5.55it/s, lr=9.99e-6, step_loss=0.245]07/18/2023 19:12:33 - INFO - __main__ - train loss is 11.825480123399757\n",
      "Steps:  10%|▏ | 1445/15000 [09:11<40:56,  5.52it/s, lr=9.99e-6, step_loss=0.675]07/18/2023 19:12:34 - INFO - __main__ - train loss is 12.039523204206489\n",
      "Steps:  10%|▏ | 1446/15000 [09:11<41:05,  5.50it/s, lr=9.99e-6, step_loss=0.214]07/18/2023 19:12:34 - INFO - __main__ - train loss is 12.054828479303978\n",
      "Steps:  10%| | 1447/15000 [09:12<40:50,  5.53it/s, lr=9.99e-6, step_loss=0.0153]07/18/2023 19:12:34 - INFO - __main__ - train loss is 12.1009513506433\n",
      "Steps:  10%| | 1448/15000 [09:12<40:55,  5.52it/s, lr=9.99e-6, step_loss=0.0461]07/18/2023 19:12:34 - INFO - __main__ - train loss is 12.128116096719168\n",
      "Steps:  10%| | 1449/15000 [09:12<40:47,  5.54it/s, lr=9.99e-6, step_loss=0.0272]07/18/2023 19:12:34 - INFO - __main__ - train loss is 12.261717046960257\n",
      "Steps:  10%|▏ | 1450/15000 [09:12<41:05,  5.50it/s, lr=9.99e-6, step_loss=0.134]07/18/2023 19:12:34 - INFO - __main__ - train loss is 12.405841614468955\n",
      "Steps:  10%|▏ | 1451/15000 [09:12<41:24,  5.45it/s, lr=9.99e-6, step_loss=0.144]07/18/2023 19:12:35 - INFO - __main__ - train loss is 12.409034953801893\n",
      "Steps:  10%| | 1452/15000 [09:13<41:19,  5.46it/s, lr=9.99e-6, step_loss=0.0031907/18/2023 19:12:35 - INFO - __main__ - train loss is 12.68468766042497\n",
      "Steps:  10%|▏ | 1453/15000 [09:13<41:25,  5.45it/s, lr=9.99e-6, step_loss=0.276]07/18/2023 19:12:35 - INFO - __main__ - train loss is 13.0439579350641\n",
      "Steps:  10%|▏ | 1454/15000 [09:13<41:34,  5.43it/s, lr=9.99e-6, step_loss=0.359]07/18/2023 19:12:35 - INFO - __main__ - train loss is 13.0476603199495\n",
      "Steps:  10%| | 1455/15000 [09:13<55:31,  4.07it/s, lr=9.99e-6, step_loss=0.0037]07/18/2023 19:12:36 - INFO - __main__ - Per validation step average loss is 0.1608729362487793\n",
      "07/18/2023 19:12:36 - INFO - __main__ - Cumulative validation average loss is 0.1608729362487793\n",
      "07/18/2023 19:12:36 - INFO - __main__ - Per validation step average loss is 0.22819451987743378\n",
      "07/18/2023 19:12:36 - INFO - __main__ - Cumulative validation average loss is 0.3890674561262131\n",
      "07/18/2023 19:12:36 - INFO - __main__ - Per validation step average loss is 0.19090530276298523\n",
      "07/18/2023 19:12:36 - INFO - __main__ - Cumulative validation average loss is 0.5799727588891983\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Per validation step average loss is 0.008480668067932129\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Cumulative validation average loss is 0.5884534269571304\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Per validation step average loss is 0.7917011976242065\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Cumulative validation average loss is 1.380154624581337\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Per validation step average loss is 0.2163405865430832\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Cumulative validation average loss is 1.5964952111244202\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Per validation step average loss is 0.06495868414640427\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Cumulative validation average loss is 1.6614538952708244\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Per validation step average loss is 0.1926349252462387\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Cumulative validation average loss is 1.8540888205170631\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Per validation step average loss is 0.04259138181805611\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Cumulative validation average loss is 1.8966802023351192\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Per validation step average loss is 0.032175809144973755\n",
      "07/18/2023 19:12:37 - INFO - __main__ - Cumulative validation average loss is 1.928856011480093\n",
      "07/18/2023 19:12:38 - INFO - __main__ - Per validation step average loss is 0.0012560258619487286\n",
      "07/18/2023 19:12:38 - INFO - __main__ - Cumulative validation average loss is 1.9301120373420417\n",
      "07/18/2023 19:12:38 - INFO - __main__ - Per validation step average loss is 0.07331378757953644\n",
      "07/18/2023 19:12:38 - INFO - __main__ - Cumulative validation average loss is 2.003425824921578\n",
      "07/18/2023 19:12:38 - INFO - __main__ - Average validation loss for Epoch 14 is 0.16695215207679817\n",
      "07/18/2023 19:12:38 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:12:51 - INFO - __main__ - Starting epoch 15\n",
      "07/18/2023 19:12:52 - INFO - __main__ - train loss is 0.10715699940919876\n",
      "Steps:  10%| | 1456/15000 [09:30<19:07:26,  5.08s/it, lr=9.99e-6, step_loss=0.1007/18/2023 19:12:52 - INFO - __main__ - train loss is 0.12765357457101345\n",
      "Steps:  10%| | 1457/15000 [09:30<13:35:28,  3.61s/it, lr=9.99e-6, step_loss=0.0207/18/2023 19:12:52 - INFO - __main__ - train loss is 0.49990264140069485\n",
      "Steps:  10%| | 1458/15000 [09:30<9:42:49,  2.58s/it, lr=9.99e-6, step_loss=0.37207/18/2023 19:12:52 - INFO - __main__ - train loss is 0.5445290338248014\n",
      "Steps:  10%| | 1459/15000 [09:30<7:00:20,  1.86s/it, lr=9.99e-6, step_loss=0.04407/18/2023 19:12:53 - INFO - __main__ - train loss is 0.551404235418886\n",
      "Steps:  10%| | 1460/15000 [09:30<5:06:53,  1.36s/it, lr=9.99e-6, step_loss=0.00607/18/2023 19:12:53 - INFO - __main__ - train loss is 0.5558988419361413\n",
      "Steps:  10%| | 1461/15000 [09:31<3:47:02,  1.01s/it, lr=9.99e-6, step_loss=0.00407/18/2023 19:12:53 - INFO - __main__ - train loss is 0.5584231547545642\n",
      "Steps:  10%| | 1462/15000 [09:31<2:50:56,  1.32it/s, lr=9.99e-6, step_loss=0.00207/18/2023 19:12:53 - INFO - __main__ - train loss is 0.6984336904715747\n",
      "Steps:  10%| | 1463/15000 [09:31<2:12:03,  1.71it/s, lr=9.99e-6, step_loss=0.14]07/18/2023 19:12:53 - INFO - __main__ - train loss is 0.9711848727893084\n",
      "Steps:  10%| | 1464/15000 [09:31<1:44:50,  2.15it/s, lr=9.99e-6, step_loss=0.27307/18/2023 19:12:53 - INFO - __main__ - train loss is 1.0271302207838744\n",
      "Steps:  10%| | 1465/15000 [09:31<1:25:24,  2.64it/s, lr=9.99e-6, step_loss=0.05507/18/2023 19:12:54 - INFO - __main__ - train loss is 1.033655792241916\n",
      "Steps:  10%| | 1466/15000 [09:32<1:11:53,  3.14it/s, lr=9.99e-6, step_loss=0.00607/18/2023 19:12:54 - INFO - __main__ - train loss is 1.0738339347299188\n",
      "Steps:  10%| | 1467/15000 [09:32<1:02:26,  3.61it/s, lr=9.99e-6, step_loss=0.04007/18/2023 19:12:54 - INFO - __main__ - train loss is 1.8391553682740778\n",
      "Steps:  10%|▏ | 1468/15000 [09:32<55:47,  4.04it/s, lr=9.99e-6, step_loss=0.765]07/18/2023 19:12:54 - INFO - __main__ - train loss is 1.8466343937907368\n",
      "Steps:  10%| | 1469/15000 [09:32<52:08,  4.32it/s, lr=9.99e-6, step_loss=0.0074807/18/2023 19:12:54 - INFO - __main__ - train loss is 1.8502227189019322\n",
      "Steps:  10%| | 1470/15000 [09:32<48:38,  4.64it/s, lr=9.99e-6, step_loss=0.0035907/18/2023 19:12:55 - INFO - __main__ - train loss is 2.1317151309922338\n",
      "Steps:  10%|▏ | 1471/15000 [09:32<46:06,  4.89it/s, lr=9.99e-6, step_loss=0.281]07/18/2023 19:12:55 - INFO - __main__ - train loss is 2.1972252698615193\n",
      "Steps:  10%| | 1472/15000 [09:33<44:29,  5.07it/s, lr=9.99e-6, step_loss=0.0655]07/18/2023 19:12:55 - INFO - __main__ - train loss is 2.362767410464585\n",
      "Steps:  10%|▏ | 1473/15000 [09:33<43:18,  5.21it/s, lr=9.99e-6, step_loss=0.166]07/18/2023 19:12:55 - INFO - __main__ - train loss is 2.6848887922242284\n",
      "Steps:  10%|▏ | 1474/15000 [09:33<42:38,  5.29it/s, lr=9.99e-6, step_loss=0.322]07/18/2023 19:12:55 - INFO - __main__ - train loss is 2.6971823135390878\n",
      "Steps:  10%| | 1475/15000 [09:33<42:17,  5.33it/s, lr=9.99e-6, step_loss=0.0123]07/18/2023 19:12:55 - INFO - __main__ - train loss is 2.772579492069781\n",
      "Steps:  10%| | 1476/15000 [09:33<41:46,  5.40it/s, lr=9.99e-6, step_loss=0.0754]07/18/2023 19:12:56 - INFO - __main__ - train loss is 2.922930688597262\n",
      "Steps:  10%|▎  | 1477/15000 [09:34<41:42,  5.40it/s, lr=9.99e-6, step_loss=0.15]07/18/2023 19:12:56 - INFO - __main__ - train loss is 2.9466984579339623\n",
      "Steps:  10%| | 1478/15000 [09:34<41:22,  5.45it/s, lr=9.99e-6, step_loss=0.0238]07/18/2023 19:12:56 - INFO - __main__ - train loss is 2.948553215712309\n",
      "Steps:  10%| | 1479/15000 [09:34<40:59,  5.50it/s, lr=9.99e-6, step_loss=0.0018507/18/2023 19:12:56 - INFO - __main__ - train loss is 2.9673573039472103\n",
      "Steps:  10%| | 1480/15000 [09:34<40:44,  5.53it/s, lr=9.99e-6, step_loss=0.0188]07/18/2023 19:12:56 - INFO - __main__ - train loss is 2.974781810771674\n",
      "Steps:  10%| | 1481/15000 [09:34<40:33,  5.56it/s, lr=9.99e-6, step_loss=0.0074207/18/2023 19:12:57 - INFO - __main__ - train loss is 3.1855666036717594\n",
      "Steps:  10%|▏ | 1482/15000 [09:34<40:30,  5.56it/s, lr=9.99e-6, step_loss=0.211]07/18/2023 19:12:57 - INFO - __main__ - train loss is 3.232049040030688\n",
      "Steps:  10%| | 1483/15000 [09:35<40:22,  5.58it/s, lr=9.99e-6, step_loss=0.0465]07/18/2023 19:12:57 - INFO - __main__ - train loss is 3.2363944654352963\n",
      "Steps:  10%| | 1484/15000 [09:35<40:17,  5.59it/s, lr=9.99e-6, step_loss=0.0043507/18/2023 19:12:57 - INFO - __main__ - train loss is 3.2409272543154657\n",
      "Steps:  10%| | 1485/15000 [09:35<40:15,  5.60it/s, lr=9.99e-6, step_loss=0.0045307/18/2023 19:12:57 - INFO - __main__ - train loss is 3.2910484350286424\n",
      "Steps:  10%| | 1486/15000 [09:35<40:19,  5.59it/s, lr=9.99e-6, step_loss=0.0501]07/18/2023 19:12:57 - INFO - __main__ - train loss is 3.542653677519411\n",
      "Steps:  10%|▏ | 1487/15000 [09:35<40:16,  5.59it/s, lr=9.99e-6, step_loss=0.252]07/18/2023 19:12:58 - INFO - __main__ - train loss is 3.580797807779163\n",
      "Steps:  10%| | 1488/15000 [09:35<40:13,  5.60it/s, lr=9.99e-6, step_loss=0.0381]07/18/2023 19:12:58 - INFO - __main__ - train loss is 3.674993598368019\n",
      "Steps:  10%| | 1489/15000 [09:36<40:16,  5.59it/s, lr=9.99e-6, step_loss=0.0942]07/18/2023 19:12:58 - INFO - __main__ - train loss is 3.788750985171646\n",
      "Steps:  10%|▏ | 1490/15000 [09:36<40:34,  5.55it/s, lr=9.99e-6, step_loss=0.114]07/18/2023 19:12:58 - INFO - __main__ - train loss is 4.307770767714828\n",
      "Steps:  10%|▏ | 1491/15000 [09:36<40:50,  5.51it/s, lr=9.98e-6, step_loss=0.519]07/18/2023 19:12:58 - INFO - __main__ - train loss is 4.348726739641279\n",
      "Steps:  10%|▏ | 1492/15000 [09:36<41:00,  5.49it/s, lr=9.98e-6, step_loss=0.041]07/18/2023 19:12:58 - INFO - __main__ - train loss is 4.353644491173327\n",
      "Steps:  10%| | 1493/15000 [09:36<40:52,  5.51it/s, lr=9.98e-6, step_loss=0.0049207/18/2023 19:12:59 - INFO - __main__ - train loss is 4.800413102842867\n",
      "Steps:  10%|▏ | 1494/15000 [09:37<40:41,  5.53it/s, lr=9.98e-6, step_loss=0.447]07/18/2023 19:12:59 - INFO - __main__ - train loss is 4.860197068192065\n",
      "Steps:  10%| | 1495/15000 [09:37<40:33,  5.55it/s, lr=9.98e-6, step_loss=0.0598]07/18/2023 19:12:59 - INFO - __main__ - train loss is 4.863407226745039\n",
      "Steps:  10%| | 1496/15000 [09:37<40:27,  5.56it/s, lr=9.98e-6, step_loss=0.0032107/18/2023 19:12:59 - INFO - __main__ - train loss is 5.579310330096632\n",
      "Steps:  10%|▏ | 1497/15000 [09:37<40:49,  5.51it/s, lr=9.98e-6, step_loss=0.716]07/18/2023 19:12:59 - INFO - __main__ - train loss is 5.830614420119673\n",
      "Steps:  10%|▏ | 1498/15000 [09:37<40:43,  5.52it/s, lr=9.98e-6, step_loss=0.251]07/18/2023 19:13:00 - INFO - __main__ - train loss is 6.087154837790877\n",
      "Steps:  10%|▏ | 1499/15000 [09:37<40:35,  5.54it/s, lr=9.98e-6, step_loss=0.257]07/18/2023 19:13:00 - INFO - __main__ - train loss is 6.097979147452861\n",
      "Steps:  10%|▏ | 1500/15000 [09:38<40:29,  5.56it/s, lr=9.98e-6, step_loss=0.257]07/18/2023 19:13:00 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-1500\n",
      "07/18/2023 19:13:00 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:13:00,344] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:13:00,349] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:13:00,349] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:13:00,357] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:13:00,357] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:13:00,365] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:13:00,365] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:13:00,365] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:13:00 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-1500/pytorch_model\n",
      "07/18/2023 19:13:00 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-1500/scheduler.bin\n",
      "07/18/2023 19:13:00 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-1500/random_states_0.pkl\n",
      "07/18/2023 19:13:00 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-1500\n",
      "Steps:  10%| | 1500/15000 [09:38<40:29,  5.56it/s, lr=9.98e-6, step_loss=0.0108]07/18/2023 19:13:00 - INFO - __main__ - train loss is 6.407310743350536\n",
      "Steps:  10%|▏ | 1501/15000 [09:38<42:09,  5.34it/s, lr=9.98e-6, step_loss=0.309]07/18/2023 19:13:00 - INFO - __main__ - train loss is 6.413608329836279\n",
      "Steps:  10%| | 1502/15000 [09:38<42:15,  5.32it/s, lr=9.98e-6, step_loss=0.0063]07/18/2023 19:13:00 - INFO - __main__ - train loss is 6.473411480430514\n",
      "Steps:  10%| | 1503/15000 [09:38<41:42,  5.39it/s, lr=9.98e-6, step_loss=0.0598]07/18/2023 19:13:01 - INFO - __main__ - train loss is 6.482841346878558\n",
      "Steps:  10%| | 1504/15000 [09:38<41:11,  5.46it/s, lr=9.98e-6, step_loss=0.0094307/18/2023 19:13:01 - INFO - __main__ - train loss is 6.5430889134295285\n",
      "Steps:  10%| | 1505/15000 [09:39<40:55,  5.50it/s, lr=9.98e-6, step_loss=0.0602]07/18/2023 19:13:01 - INFO - __main__ - train loss is 6.620009214151651\n",
      "Steps:  10%| | 1506/15000 [09:39<40:39,  5.53it/s, lr=9.98e-6, step_loss=0.0769]07/18/2023 19:13:01 - INFO - __main__ - train loss is 6.65655578719452\n",
      "Steps:  10%| | 1507/15000 [09:39<40:28,  5.56it/s, lr=9.98e-6, step_loss=0.0365]07/18/2023 19:13:01 - INFO - __main__ - train loss is 6.887190014589578\n",
      "Steps:  10%|▏ | 1508/15000 [09:39<40:21,  5.57it/s, lr=9.98e-6, step_loss=0.231]07/18/2023 19:13:01 - INFO - __main__ - train loss is 6.991213232744485\n",
      "Steps:  10%|▏ | 1509/15000 [09:39<40:18,  5.58it/s, lr=9.98e-6, step_loss=0.104]07/18/2023 19:13:02 - INFO - __main__ - train loss is 6.9930787570774555\n",
      "Steps:  10%| | 1510/15000 [09:39<40:11,  5.59it/s, lr=9.98e-6, step_loss=0.0018707/18/2023 19:13:02 - INFO - __main__ - train loss is 7.257218468934298\n",
      "Steps:  10%|▏ | 1511/15000 [09:40<40:07,  5.60it/s, lr=9.98e-6, step_loss=0.264]07/18/2023 19:13:02 - INFO - __main__ - train loss is 7.263194186147302\n",
      "Steps:  10%| | 1512/15000 [09:40<40:05,  5.61it/s, lr=9.98e-6, step_loss=0.0059807/18/2023 19:13:02 - INFO - __main__ - train loss is 7.279347346629947\n",
      "Steps:  10%| | 1513/15000 [09:40<40:04,  5.61it/s, lr=9.98e-6, step_loss=0.0162]07/18/2023 19:13:02 - INFO - __main__ - train loss is 7.568950669374317\n",
      "Steps:  10%|▎  | 1514/15000 [09:40<40:02,  5.61it/s, lr=9.98e-6, step_loss=0.29]07/18/2023 19:13:02 - INFO - __main__ - train loss is 7.78844560822472\n",
      "Steps:  10%|▏ | 1515/15000 [09:40<40:32,  5.54it/s, lr=9.98e-6, step_loss=0.219]07/18/2023 19:13:03 - INFO - __main__ - train loss is 7.829060086514801\n",
      "Steps:  10%| | 1516/15000 [09:41<40:26,  5.56it/s, lr=9.98e-6, step_loss=0.0406]07/18/2023 19:13:03 - INFO - __main__ - train loss is 7.938432240393013\n",
      "Steps:  10%|▏ | 1517/15000 [09:41<40:21,  5.57it/s, lr=9.98e-6, step_loss=0.109]07/18/2023 19:13:03 - INFO - __main__ - train loss is 8.053648540284485\n",
      "Steps:  10%|▏ | 1518/15000 [09:41<40:14,  5.58it/s, lr=9.98e-6, step_loss=0.115]07/18/2023 19:13:03 - INFO - __main__ - train loss is 8.112736450042576\n",
      "Steps:  10%| | 1519/15000 [09:41<40:11,  5.59it/s, lr=9.98e-6, step_loss=0.0591]07/18/2023 19:13:03 - INFO - __main__ - train loss is 8.124129222240299\n",
      "Steps:  10%| | 1520/15000 [09:41<40:07,  5.60it/s, lr=9.98e-6, step_loss=0.0114]07/18/2023 19:13:04 - INFO - __main__ - train loss is 8.138113885652274\n",
      "Steps:  10%|▏ | 1521/15000 [09:41<40:05,  5.60it/s, lr=9.98e-6, step_loss=0.014]07/18/2023 19:13:04 - INFO - __main__ - train loss is 8.157418569084257\n",
      "Steps:  10%| | 1522/15000 [09:42<40:03,  5.61it/s, lr=9.98e-6, step_loss=0.0193]07/18/2023 19:13:04 - INFO - __main__ - train loss is 8.408035089727491\n",
      "Steps:  10%|▏ | 1523/15000 [09:42<40:08,  5.59it/s, lr=9.98e-6, step_loss=0.251]07/18/2023 19:13:04 - INFO - __main__ - train loss is 9.141714622732252\n",
      "Steps:  10%|▏ | 1524/15000 [09:42<40:27,  5.55it/s, lr=9.98e-6, step_loss=0.734]07/18/2023 19:13:04 - INFO - __main__ - train loss is 9.14399147592485\n",
      "Steps:  10%| | 1525/15000 [09:42<40:23,  5.56it/s, lr=9.98e-6, step_loss=0.0022807/18/2023 19:13:04 - INFO - __main__ - train loss is 9.410557692870498\n",
      "Steps:  10%|▏ | 1526/15000 [09:42<40:17,  5.57it/s, lr=9.98e-6, step_loss=0.267]07/18/2023 19:13:05 - INFO - __main__ - train loss is 9.647564118728042\n",
      "Steps:  10%|▏ | 1527/15000 [09:43<40:15,  5.58it/s, lr=9.98e-6, step_loss=0.237]07/18/2023 19:13:05 - INFO - __main__ - train loss is 10.01403776369989\n",
      "Steps:  10%|▏ | 1528/15000 [09:43<40:11,  5.59it/s, lr=9.98e-6, step_loss=0.366]07/18/2023 19:13:05 - INFO - __main__ - train loss is 10.625909125432372\n",
      "Steps:  10%|▏ | 1529/15000 [09:43<40:09,  5.59it/s, lr=9.98e-6, step_loss=0.612]07/18/2023 19:13:05 - INFO - __main__ - train loss is 10.65858112834394\n",
      "Steps:  10%| | 1530/15000 [09:43<40:30,  5.54it/s, lr=9.98e-6, step_loss=0.0327]07/18/2023 19:13:05 - INFO - __main__ - train loss is 10.981600632891059\n",
      "Steps:  10%|▏ | 1531/15000 [09:43<41:06,  5.46it/s, lr=9.98e-6, step_loss=0.323]07/18/2023 19:13:06 - INFO - __main__ - train loss is 10.994294198229909\n",
      "Steps:  10%| | 1532/15000 [09:43<40:45,  5.51it/s, lr=9.98e-6, step_loss=0.0127]07/18/2023 19:13:06 - INFO - __main__ - train loss is 11.190689684823155\n",
      "Steps:  10%|▏ | 1533/15000 [09:44<40:31,  5.54it/s, lr=9.98e-6, step_loss=0.196]07/18/2023 19:13:06 - INFO - __main__ - train loss is 11.516306759789586\n",
      "Steps:  10%|▏ | 1534/15000 [09:44<40:22,  5.56it/s, lr=9.98e-6, step_loss=0.326]07/18/2023 19:13:06 - INFO - __main__ - train loss is 11.518665167037398\n",
      "Steps:  10%| | 1535/15000 [09:44<40:23,  5.56it/s, lr=9.98e-6, step_loss=0.0023607/18/2023 19:13:06 - INFO - __main__ - train loss is 11.677573966328055\n",
      "Steps:  10%|▏ | 1536/15000 [09:44<40:14,  5.58it/s, lr=9.98e-6, step_loss=0.159]07/18/2023 19:13:06 - INFO - __main__ - train loss is 11.679486095323227\n",
      "Steps:  10%| | 1537/15000 [09:44<40:08,  5.59it/s, lr=9.98e-6, step_loss=0.0019107/18/2023 19:13:07 - INFO - __main__ - train loss is 11.907471954240464\n",
      "Steps:  10%|▏ | 1538/15000 [09:44<40:04,  5.60it/s, lr=9.98e-6, step_loss=0.228]07/18/2023 19:13:07 - INFO - __main__ - train loss is 11.913432428962551\n",
      "Steps:  10%| | 1539/15000 [09:45<40:00,  5.61it/s, lr=9.98e-6, step_loss=0.0059607/18/2023 19:13:07 - INFO - __main__ - train loss is 11.979671189910732\n",
      "Steps:  10%| | 1540/15000 [09:45<39:54,  5.62it/s, lr=9.98e-6, step_loss=0.0662]07/18/2023 19:13:07 - INFO - __main__ - train loss is 12.061986776418053\n",
      "Steps:  10%| | 1541/15000 [09:45<39:53,  5.62it/s, lr=9.98e-6, step_loss=0.0823]07/18/2023 19:13:07 - INFO - __main__ - train loss is 12.070475638261996\n",
      "Steps:  10%| | 1542/15000 [09:45<39:52,  5.63it/s, lr=9.98e-6, step_loss=0.0084907/18/2023 19:13:07 - INFO - __main__ - train loss is 12.434707343927585\n",
      "Steps:  10%|▏ | 1543/15000 [09:45<40:20,  5.56it/s, lr=9.98e-6, step_loss=0.364]07/18/2023 19:13:08 - INFO - __main__ - train loss is 12.549170211306773\n",
      "Steps:  10%|▏ | 1544/15000 [09:46<40:12,  5.58it/s, lr=9.98e-6, step_loss=0.114]07/18/2023 19:13:08 - INFO - __main__ - train loss is 12.798467383137904\n",
      "Steps:  10%|▏ | 1545/15000 [09:46<40:07,  5.59it/s, lr=9.98e-6, step_loss=0.249]07/18/2023 19:13:08 - INFO - __main__ - train loss is 12.865037247887813\n",
      "Steps:  10%| | 1546/15000 [09:46<40:05,  5.59it/s, lr=9.98e-6, step_loss=0.0666]07/18/2023 19:13:08 - INFO - __main__ - train loss is 12.936702363542281\n",
      "Steps:  10%| | 1547/15000 [09:46<40:07,  5.59it/s, lr=9.98e-6, step_loss=0.0717]07/18/2023 19:13:08 - INFO - __main__ - train loss is 12.960055740899406\n",
      "Steps:  10%| | 1548/15000 [09:46<40:00,  5.60it/s, lr=9.98e-6, step_loss=0.0234]07/18/2023 19:13:09 - INFO - __main__ - train loss is 12.962431196472608\n",
      "Steps:  10%| | 1549/15000 [09:46<39:58,  5.61it/s, lr=9.98e-6, step_loss=0.0023807/18/2023 19:13:09 - INFO - __main__ - train loss is 13.277820710442029\n",
      "Steps:  10%|▏ | 1550/15000 [09:47<39:55,  5.61it/s, lr=9.98e-6, step_loss=0.315]07/18/2023 19:13:09 - INFO - __main__ - train loss is 13.282079678378068\n",
      "Steps:  10%| | 1551/15000 [09:47<39:56,  5.61it/s, lr=9.98e-6, step_loss=0.0042607/18/2023 19:13:09 - INFO - __main__ - train loss is 13.290804163902067\n",
      "Steps:  10%| | 1552/15000 [09:47<53:09,  4.22it/s, lr=9.98e-6, step_loss=0.0087207/18/2023 19:13:10 - INFO - __main__ - Per validation step average loss is 0.06278186291456223\n",
      "07/18/2023 19:13:10 - INFO - __main__ - Cumulative validation average loss is 0.06278186291456223\n",
      "07/18/2023 19:13:10 - INFO - __main__ - Per validation step average loss is 0.05245567113161087\n",
      "07/18/2023 19:13:10 - INFO - __main__ - Cumulative validation average loss is 0.1152375340461731\n",
      "07/18/2023 19:13:10 - INFO - __main__ - Per validation step average loss is 0.03633224964141846\n",
      "07/18/2023 19:13:10 - INFO - __main__ - Cumulative validation average loss is 0.15156978368759155\n",
      "07/18/2023 19:13:10 - INFO - __main__ - Per validation step average loss is 0.008440938778221607\n",
      "07/18/2023 19:13:10 - INFO - __main__ - Cumulative validation average loss is 0.16001072246581316\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.14353004097938538\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 0.30354076344519854\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.006220379378646612\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 0.30976114282384515\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.02478674054145813\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 0.3345478833653033\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.007540274411439896\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 0.3420881577767432\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.05906527861952782\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 0.401153436396271\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.04829450696706772\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 0.4494479433633387\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Per validation step average loss is 0.07735404372215271\n",
      "07/18/2023 19:13:11 - INFO - __main__ - Cumulative validation average loss is 0.5268019870854914\n",
      "07/18/2023 19:13:12 - INFO - __main__ - Per validation step average loss is 0.00362762319855392\n",
      "07/18/2023 19:13:12 - INFO - __main__ - Cumulative validation average loss is 0.5304296102840453\n",
      "07/18/2023 19:13:12 - INFO - __main__ - Average validation loss for Epoch 15 is 0.04420246752367044\n",
      "07/18/2023 19:13:12 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:13:24 - INFO - __main__ - Starting epoch 16\n",
      "07/18/2023 19:13:25 - INFO - __main__ - train loss is 0.052487608045339584\n",
      "Steps:  10%| | 1553/15000 [10:03<18:14:29,  4.88s/it, lr=9.98e-6, step_loss=0.0507/18/2023 19:13:25 - INFO - __main__ - train loss is 0.3471289835870266\n",
      "Steps:  10%| | 1554/15000 [10:03<12:58:05,  3.47s/it, lr=9.98e-6, step_loss=0.2907/18/2023 19:13:25 - INFO - __main__ - train loss is 0.34891754016280174\n",
      "Steps:  10%| | 1555/15000 [10:03<9:16:56,  2.49s/it, lr=9.98e-6, step_loss=0.00107/18/2023 19:13:26 - INFO - __main__ - train loss is 0.35382171627134085\n",
      "Steps:  10%| | 1556/15000 [10:03<6:45:01,  1.81s/it, lr=9.98e-6, step_loss=0.00407/18/2023 19:13:26 - INFO - __main__ - train loss is 0.6911466931924224\n",
      "Steps:  10%| | 1557/15000 [10:04<4:55:31,  1.32s/it, lr=9.98e-6, step_loss=0.33707/18/2023 19:13:26 - INFO - __main__ - train loss is 0.7252127146348357\n",
      "Steps:  10%| | 1558/15000 [10:04<3:38:56,  1.02it/s, lr=9.98e-6, step_loss=0.03407/18/2023 19:13:26 - INFO - __main__ - train loss is 1.1232731556519866\n",
      "Steps:  10%| | 1559/15000 [10:04<2:46:36,  1.34it/s, lr=9.98e-6, step_loss=0.39807/18/2023 19:13:26 - INFO - __main__ - train loss is 1.12779825553298\n",
      "Steps:  10%| | 1560/15000 [10:04<2:09:05,  1.74it/s, lr=9.98e-6, step_loss=0.00407/18/2023 19:13:27 - INFO - __main__ - train loss is 1.1657328493893147\n",
      "Steps:  10%| | 1561/15000 [10:04<1:42:17,  2.19it/s, lr=9.98e-6, step_loss=0.03707/18/2023 19:13:27 - INFO - __main__ - train loss is 1.3979082591831684\n",
      "Steps:  10%| | 1562/15000 [10:05<1:23:32,  2.68it/s, lr=9.98e-6, step_loss=0.23207/18/2023 19:13:27 - INFO - __main__ - train loss is 1.8620551116764545\n",
      "Steps:  10%| | 1563/15000 [10:05<1:10:24,  3.18it/s, lr=9.98e-6, step_loss=0.46407/18/2023 19:13:27 - INFO - __main__ - train loss is 2.054317269474268\n",
      "Steps:  10%| | 1564/15000 [10:05<1:01:12,  3.66it/s, lr=9.98e-6, step_loss=0.19207/18/2023 19:13:27 - INFO - __main__ - train loss is 2.0975006110966206\n",
      "Steps:  10%| | 1565/15000 [10:05<54:47,  4.09it/s, lr=9.98e-6, step_loss=0.0432]07/18/2023 19:13:27 - INFO - __main__ - train loss is 2.205975342541933\n",
      "Steps:  10%|▏ | 1566/15000 [10:05<50:24,  4.44it/s, lr=9.98e-6, step_loss=0.108]07/18/2023 19:13:28 - INFO - __main__ - train loss is 2.208082164172083\n",
      "Steps:  10%| | 1567/15000 [10:05<47:18,  4.73it/s, lr=9.98e-6, step_loss=0.0021107/18/2023 19:13:28 - INFO - __main__ - train loss is 2.3651443072594702\n",
      "Steps:  10%|▏ | 1568/15000 [10:06<45:03,  4.97it/s, lr=9.98e-6, step_loss=0.157]07/18/2023 19:13:28 - INFO - __main__ - train loss is 2.7905720421113074\n",
      "Steps:  10%|▏ | 1569/15000 [10:06<43:49,  5.11it/s, lr=9.98e-6, step_loss=0.425]07/18/2023 19:13:28 - INFO - __main__ - train loss is 2.8736547701992095\n",
      "Steps:  10%| | 1570/15000 [10:06<42:43,  5.24it/s, lr=9.98e-6, step_loss=0.0831]07/18/2023 19:13:28 - INFO - __main__ - train loss is 3.037441822234541\n",
      "Steps:  10%|▏ | 1571/15000 [10:06<41:54,  5.34it/s, lr=9.98e-6, step_loss=0.164]07/18/2023 19:13:28 - INFO - __main__ - train loss is 3.75152555340901\n",
      "Steps:  10%|▏ | 1572/15000 [10:06<41:18,  5.42it/s, lr=9.98e-6, step_loss=0.714]07/18/2023 19:13:29 - INFO - __main__ - train loss is 3.853304954711348\n",
      "Steps:  10%|▏ | 1573/15000 [10:07<41:08,  5.44it/s, lr=9.98e-6, step_loss=0.102]07/18/2023 19:13:29 - INFO - __main__ - train loss is 3.884802403394133\n",
      "Steps:  10%| | 1574/15000 [10:07<41:10,  5.44it/s, lr=9.98e-6, step_loss=0.0315]07/18/2023 19:13:29 - INFO - __main__ - train loss is 3.8900470081716776\n",
      "Steps:  10%| | 1575/15000 [10:07<40:54,  5.47it/s, lr=9.98e-6, step_loss=0.0052407/18/2023 19:13:29 - INFO - __main__ - train loss is 3.892391843954101\n",
      "Steps:  11%| | 1576/15000 [10:07<40:51,  5.47it/s, lr=9.98e-6, step_loss=0.0023407/18/2023 19:13:29 - INFO - __main__ - train loss is 4.05548612610437\n",
      "Steps:  11%|▏ | 1577/15000 [10:07<40:34,  5.51it/s, lr=9.98e-6, step_loss=0.163]07/18/2023 19:13:30 - INFO - __main__ - train loss is 4.060091305756941\n",
      "Steps:  11%| | 1578/15000 [10:07<40:27,  5.53it/s, lr=9.98e-6, step_loss=0.0046107/18/2023 19:13:30 - INFO - __main__ - train loss is 4.12518396624364\n",
      "Steps:  11%| | 1579/15000 [10:08<40:23,  5.54it/s, lr=9.98e-6, step_loss=0.0651]07/18/2023 19:13:30 - INFO - __main__ - train loss is 4.510936793172732\n",
      "Steps:  11%|▏ | 1580/15000 [10:08<40:14,  5.56it/s, lr=9.98e-6, step_loss=0.386]07/18/2023 19:13:30 - INFO - __main__ - train loss is 4.52666186937131\n",
      "Steps:  11%| | 1581/15000 [10:08<40:44,  5.49it/s, lr=9.98e-6, step_loss=0.0157]07/18/2023 19:13:30 - INFO - __main__ - train loss is 4.537649922305718\n",
      "Steps:  11%|▏ | 1582/15000 [10:08<40:37,  5.50it/s, lr=9.98e-6, step_loss=0.011]07/18/2023 19:13:30 - INFO - __main__ - train loss is 4.799999617272988\n",
      "Steps:  11%|▏ | 1583/15000 [10:08<40:27,  5.53it/s, lr=9.98e-6, step_loss=0.262]07/18/2023 19:13:31 - INFO - __main__ - train loss is 4.810128659242764\n",
      "Steps:  11%| | 1584/15000 [10:09<40:16,  5.55it/s, lr=9.98e-6, step_loss=0.0101]07/18/2023 19:13:31 - INFO - __main__ - train loss is 5.1020559968892485\n",
      "Steps:  11%|▏ | 1585/15000 [10:09<40:38,  5.50it/s, lr=9.98e-6, step_loss=0.292]07/18/2023 19:13:31 - INFO - __main__ - train loss is 5.1050425509456545\n",
      "Steps:  11%| | 1586/15000 [10:09<40:38,  5.50it/s, lr=9.98e-6, step_loss=0.0029907/18/2023 19:13:31 - INFO - __main__ - train loss is 5.110571782337502\n",
      "Steps:  11%| | 1587/15000 [10:09<40:22,  5.54it/s, lr=9.98e-6, step_loss=0.0055307/18/2023 19:13:31 - INFO - __main__ - train loss is 5.1265355322975665\n",
      "Steps:  11%|▏ | 1588/15000 [10:09<40:12,  5.56it/s, lr=9.98e-6, step_loss=0.016]07/18/2023 19:13:32 - INFO - __main__ - train loss is 5.191631031455472\n",
      "Steps:  11%| | 1589/15000 [10:09<40:07,  5.57it/s, lr=9.98e-6, step_loss=0.0651]07/18/2023 19:13:32 - INFO - __main__ - train loss is 5.19371936423704\n",
      "Steps:  11%| | 1590/15000 [10:10<40:01,  5.58it/s, lr=9.98e-6, step_loss=0.0020907/18/2023 19:13:32 - INFO - __main__ - train loss is 5.227454427164048\n",
      "Steps:  11%| | 1591/15000 [10:10<39:58,  5.59it/s, lr=9.98e-6, step_loss=0.0337]07/18/2023 19:13:32 - INFO - __main__ - train loss is 5.23163374280557\n",
      "Steps:  11%| | 1592/15000 [10:10<39:56,  5.60it/s, lr=9.98e-6, step_loss=0.0041807/18/2023 19:13:32 - INFO - __main__ - train loss is 5.247081757057458\n",
      "Steps:  11%| | 1593/15000 [10:10<40:03,  5.58it/s, lr=9.98e-6, step_loss=0.0154]07/18/2023 19:13:32 - INFO - __main__ - train loss is 5.2590817478485405\n",
      "Steps:  11%|▏ | 1594/15000 [10:10<39:59,  5.59it/s, lr=9.98e-6, step_loss=0.012]07/18/2023 19:13:33 - INFO - __main__ - train loss is 5.4851816711016\n",
      "Steps:  11%|▏ | 1595/15000 [10:11<39:55,  5.60it/s, lr=9.98e-6, step_loss=0.226]07/18/2023 19:13:33 - INFO - __main__ - train loss is 5.9102154788561165\n",
      "Steps:  11%|▏ | 1596/15000 [10:11<39:52,  5.60it/s, lr=9.98e-6, step_loss=0.425]07/18/2023 19:13:33 - INFO - __main__ - train loss is 5.9126230895053595\n",
      "Steps:  11%| | 1597/15000 [10:11<39:51,  5.60it/s, lr=9.98e-6, step_loss=0.0024107/18/2023 19:13:33 - INFO - __main__ - train loss is 5.979735609842464\n",
      "Steps:  11%| | 1598/15000 [10:11<40:06,  5.57it/s, lr=9.98e-6, step_loss=0.0671]07/18/2023 19:13:33 - INFO - __main__ - train loss is 6.001660116715357\n",
      "Steps:  11%| | 1599/15000 [10:11<40:00,  5.58it/s, lr=9.98e-6, step_loss=0.0219]07/18/2023 19:13:34 - INFO - __main__ - train loss is 6.382296689553186\n",
      "Steps:  11%|▏ | 1600/15000 [10:11<39:56,  5.59it/s, lr=9.98e-6, step_loss=0.381]07/18/2023 19:13:34 - INFO - __main__ - train loss is 6.4588920183014125\n",
      "Steps:  11%| | 1601/15000 [10:12<40:00,  5.58it/s, lr=9.98e-6, step_loss=0.0766]07/18/2023 19:13:34 - INFO - __main__ - train loss is 6.462154035456479\n",
      "Steps:  11%| | 1602/15000 [10:12<40:18,  5.54it/s, lr=9.98e-6, step_loss=0.0032607/18/2023 19:13:34 - INFO - __main__ - train loss is 6.571399022825062\n",
      "Steps:  11%|▏ | 1603/15000 [10:12<40:08,  5.56it/s, lr=9.98e-6, step_loss=0.109]07/18/2023 19:13:34 - INFO - __main__ - train loss is 6.610021949745715\n",
      "Steps:  11%| | 1604/15000 [10:12<40:01,  5.58it/s, lr=9.98e-6, step_loss=0.0386]07/18/2023 19:13:34 - INFO - __main__ - train loss is 6.665457856841385\n",
      "Steps:  11%| | 1605/15000 [10:12<40:04,  5.57it/s, lr=9.98e-6, step_loss=0.0554]07/18/2023 19:13:35 - INFO - __main__ - train loss is 6.755663421936333\n",
      "Steps:  11%| | 1606/15000 [10:12<39:59,  5.58it/s, lr=9.98e-6, step_loss=0.0902]07/18/2023 19:13:35 - INFO - __main__ - train loss is 6.9073074432089925\n",
      "Steps:  11%|▏ | 1607/15000 [10:13<39:59,  5.58it/s, lr=9.98e-6, step_loss=0.152]07/18/2023 19:13:35 - INFO - __main__ - train loss is 7.01559975463897\n",
      "Steps:  11%|▏ | 1608/15000 [10:13<39:56,  5.59it/s, lr=9.98e-6, step_loss=0.108]07/18/2023 19:13:35 - INFO - __main__ - train loss is 7.076394350267947\n",
      "Steps:  11%| | 1609/15000 [10:13<39:58,  5.58it/s, lr=9.98e-6, step_loss=0.0608]07/18/2023 19:13:35 - INFO - __main__ - train loss is 7.084670582786202\n",
      "Steps:  11%| | 1610/15000 [10:13<39:54,  5.59it/s, lr=9.98e-6, step_loss=0.0082807/18/2023 19:13:36 - INFO - __main__ - train loss is 7.105275489389896\n",
      "Steps:  11%| | 1611/15000 [10:13<39:51,  5.60it/s, lr=9.98e-6, step_loss=0.0206]07/18/2023 19:13:36 - INFO - __main__ - train loss is 7.272609077394009\n",
      "Steps:  11%|▏ | 1612/15000 [10:14<39:47,  5.61it/s, lr=9.98e-6, step_loss=0.167]07/18/2023 19:13:36 - INFO - __main__ - train loss is 7.355898417532444\n",
      "Steps:  11%| | 1613/15000 [10:14<39:59,  5.58it/s, lr=9.98e-6, step_loss=0.0833]07/18/2023 19:13:36 - INFO - __main__ - train loss is 7.357756031444296\n",
      "Steps:  11%| | 1614/15000 [10:14<39:54,  5.59it/s, lr=9.98e-6, step_loss=0.0018607/18/2023 19:13:36 - INFO - __main__ - train loss is 7.491147143533453\n",
      "Steps:  11%|▏ | 1615/15000 [10:14<40:13,  5.55it/s, lr=9.98e-6, step_loss=0.133]07/18/2023 19:13:36 - INFO - __main__ - train loss is 7.618210715940222\n",
      "Steps:  11%|▏ | 1616/15000 [10:14<40:07,  5.56it/s, lr=9.98e-6, step_loss=0.127]07/18/2023 19:13:37 - INFO - __main__ - train loss is 7.6443831191863865\n",
      "Steps:  11%| | 1617/15000 [10:14<39:59,  5.58it/s, lr=9.98e-6, step_loss=0.0262]07/18/2023 19:13:37 - INFO - __main__ - train loss is 7.746076958021149\n",
      "Steps:  11%|▏ | 1618/15000 [10:15<39:53,  5.59it/s, lr=9.98e-6, step_loss=0.102]07/18/2023 19:13:37 - INFO - __main__ - train loss is 7.7552927730139345\n",
      "Steps:  11%| | 1619/15000 [10:15<39:52,  5.59it/s, lr=9.98e-6, step_loss=0.0092207/18/2023 19:13:37 - INFO - __main__ - train loss is 8.00793582177721\n",
      "Steps:  11%|▏ | 1620/15000 [10:15<39:49,  5.60it/s, lr=9.98e-6, step_loss=0.253]07/18/2023 19:13:37 - INFO - __main__ - train loss is 8.147200226550922\n",
      "Steps:  11%|▏ | 1621/15000 [10:15<39:46,  5.61it/s, lr=9.98e-6, step_loss=0.139]07/18/2023 19:13:37 - INFO - __main__ - train loss is 8.151437036460266\n",
      "Steps:  11%| | 1622/15000 [10:15<40:16,  5.54it/s, lr=9.98e-6, step_loss=0.0042407/18/2023 19:13:38 - INFO - __main__ - train loss is 8.199217844521627\n",
      "Steps:  11%| | 1623/15000 [10:16<40:19,  5.53it/s, lr=9.98e-6, step_loss=0.0478]07/18/2023 19:13:38 - INFO - __main__ - train loss is 8.22890829644166\n",
      "Steps:  11%| | 1624/15000 [10:16<40:13,  5.54it/s, lr=9.98e-6, step_loss=0.0297]07/18/2023 19:13:38 - INFO - __main__ - train loss is 8.2351197313983\n",
      "Steps:  11%| | 1625/15000 [10:16<40:22,  5.52it/s, lr=9.98e-6, step_loss=0.0062107/18/2023 19:13:38 - INFO - __main__ - train loss is 8.28043153625913\n",
      "Steps:  11%| | 1626/15000 [10:16<40:18,  5.53it/s, lr=9.98e-6, step_loss=0.0453]07/18/2023 19:13:38 - INFO - __main__ - train loss is 8.28449487988837\n",
      "Steps:  11%| | 1627/15000 [10:16<40:09,  5.55it/s, lr=9.98e-6, step_loss=0.0040607/18/2023 19:13:39 - INFO - __main__ - train loss is 8.840778473066166\n",
      "Steps:  11%|▏ | 1628/15000 [10:16<40:00,  5.57it/s, lr=9.98e-6, step_loss=0.556]07/18/2023 19:13:39 - INFO - __main__ - train loss is 8.85842791502364\n",
      "Steps:  11%| | 1629/15000 [10:17<39:58,  5.57it/s, lr=9.98e-6, step_loss=0.0176]07/18/2023 19:13:39 - INFO - __main__ - train loss is 8.866591098951176\n",
      "Steps:  11%| | 1630/15000 [10:17<40:05,  5.56it/s, lr=9.98e-6, step_loss=0.0081607/18/2023 19:13:39 - INFO - __main__ - train loss is 9.243650171207264\n",
      "Steps:  11%|▏ | 1631/15000 [10:17<40:01,  5.57it/s, lr=9.98e-6, step_loss=0.377]07/18/2023 19:13:39 - INFO - __main__ - train loss is 9.252225919859484\n",
      "Steps:  11%| | 1632/15000 [10:17<39:55,  5.58it/s, lr=9.98e-6, step_loss=0.0085807/18/2023 19:13:39 - INFO - __main__ - train loss is 9.613832994597033\n",
      "Steps:  11%|▏ | 1633/15000 [10:17<39:50,  5.59it/s, lr=9.98e-6, step_loss=0.362]07/18/2023 19:13:40 - INFO - __main__ - train loss is 10.178856059210375\n",
      "Steps:  11%|▏ | 1634/15000 [10:18<39:46,  5.60it/s, lr=9.98e-6, step_loss=0.565]07/18/2023 19:13:40 - INFO - __main__ - train loss is 10.184322859393433\n",
      "Steps:  11%| | 1635/15000 [10:18<39:43,  5.61it/s, lr=9.98e-6, step_loss=0.0054707/18/2023 19:13:40 - INFO - __main__ - train loss is 10.526296044932678\n",
      "Steps:  11%|▏ | 1636/15000 [10:18<39:41,  5.61it/s, lr=9.98e-6, step_loss=0.342]07/18/2023 19:13:40 - INFO - __main__ - train loss is 10.733600015984848\n",
      "Steps:  11%|▏ | 1637/15000 [10:18<39:40,  5.61it/s, lr=9.98e-6, step_loss=0.207]07/18/2023 19:13:40 - INFO - __main__ - train loss is 10.794420576887205\n",
      "Steps:  11%| | 1638/15000 [10:18<39:53,  5.58it/s, lr=9.98e-6, step_loss=0.0608]07/18/2023 19:13:41 - INFO - __main__ - train loss is 10.796606643358245\n",
      "Steps:  11%| | 1639/15000 [10:18<39:51,  5.59it/s, lr=9.98e-6, step_loss=0.0021907/18/2023 19:13:41 - INFO - __main__ - train loss is 10.847336618462577\n",
      "Steps:  11%| | 1640/15000 [10:19<40:01,  5.56it/s, lr=9.98e-6, step_loss=0.0507]07/18/2023 19:13:41 - INFO - __main__ - train loss is 10.851459498750046\n",
      "Steps:  11%| | 1641/15000 [10:19<39:54,  5.58it/s, lr=9.98e-6, step_loss=0.0041207/18/2023 19:13:41 - INFO - __main__ - train loss is 10.900401274906471\n",
      "Steps:  11%| | 1642/15000 [10:19<39:56,  5.57it/s, lr=9.98e-6, step_loss=0.0489]07/18/2023 19:13:41 - INFO - __main__ - train loss is 11.152525644050911\n",
      "Steps:  11%|▏ | 1643/15000 [10:19<39:50,  5.59it/s, lr=9.98e-6, step_loss=0.252]07/18/2023 19:13:41 - INFO - __main__ - train loss is 11.624349038349465\n",
      "Steps:  11%|▏ | 1644/15000 [10:19<39:46,  5.60it/s, lr=9.98e-6, step_loss=0.472]07/18/2023 19:13:42 - INFO - __main__ - train loss is 11.652889929013327\n",
      "Steps:  11%| | 1645/15000 [10:19<40:03,  5.56it/s, lr=9.98e-6, step_loss=0.0285]07/18/2023 19:13:42 - INFO - __main__ - train loss is 11.661228759447113\n",
      "Steps:  11%| | 1646/15000 [10:20<40:02,  5.56it/s, lr=9.98e-6, step_loss=0.0083407/18/2023 19:13:42 - INFO - __main__ - train loss is 12.109361512819305\n",
      "Steps:  11%|▏ | 1647/15000 [10:20<39:55,  5.57it/s, lr=9.98e-6, step_loss=0.448]07/18/2023 19:13:42 - INFO - __main__ - train loss is 12.12108781025745\n",
      "Steps:  11%| | 1648/15000 [10:20<39:47,  5.59it/s, lr=9.98e-6, step_loss=0.0117]07/18/2023 19:13:43 - INFO - __main__ - train loss is 12.129213886568323\n",
      "Steps:  11%| | 1649/15000 [10:20<53:44,  4.14it/s, lr=9.98e-6, step_loss=0.0081307/18/2023 19:13:43 - INFO - __main__ - Per validation step average loss is 0.6495780944824219\n",
      "07/18/2023 19:13:43 - INFO - __main__ - Cumulative validation average loss is 0.6495780944824219\n",
      "07/18/2023 19:13:43 - INFO - __main__ - Per validation step average loss is 0.014540039002895355\n",
      "07/18/2023 19:13:43 - INFO - __main__ - Cumulative validation average loss is 0.6641181334853172\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Per validation step average loss is 0.0355910062789917\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Cumulative validation average loss is 0.6997091397643089\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Per validation step average loss is 0.06876124441623688\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Cumulative validation average loss is 0.7684703841805458\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Per validation step average loss is 0.030227603390812874\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Cumulative validation average loss is 0.7986979875713587\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Per validation step average loss is 0.5127314925193787\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Cumulative validation average loss is 1.3114294800907373\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Per validation step average loss is 0.0018194550648331642\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Cumulative validation average loss is 1.3132489351555705\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Per validation step average loss is 0.049082960933446884\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Cumulative validation average loss is 1.3623318960890174\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Per validation step average loss is 0.4035963714122772\n",
      "07/18/2023 19:13:44 - INFO - __main__ - Cumulative validation average loss is 1.7659282675012946\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Per validation step average loss is 0.01651829481124878\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Cumulative validation average loss is 1.7824465623125434\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Per validation step average loss is 0.0811302438378334\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Cumulative validation average loss is 1.8635768061503768\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Per validation step average loss is 0.7868145704269409\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Cumulative validation average loss is 2.6503913765773177\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Average validation loss for Epoch 16 is 0.2208659480481098\n",
      "07/18/2023 19:13:45 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:13:58 - INFO - __main__ - Starting epoch 17\n",
      "07/18/2023 19:13:58 - INFO - __main__ - train loss is 0.02383548393845558\n",
      "Steps:  11%| | 1650/15000 [10:36<18:07:17,  4.89s/it, lr=9.98e-6, step_loss=0.0207/18/2023 19:13:58 - INFO - __main__ - train loss is 0.04458730295300484\n",
      "Steps:  11%| | 1651/15000 [10:36<12:53:35,  3.48s/it, lr=9.98e-6, step_loss=0.0207/18/2023 19:13:59 - INFO - __main__ - train loss is 0.07449595257639885\n",
      "Steps:  11%| | 1652/15000 [10:37<9:14:03,  2.49s/it, lr=9.98e-6, step_loss=0.02907/18/2023 19:13:59 - INFO - __main__ - train loss is 0.36536047980189323\n",
      "Steps:  11%| | 1653/15000 [10:37<6:40:26,  1.80s/it, lr=9.98e-6, step_loss=0.29107/18/2023 19:13:59 - INFO - __main__ - train loss is 0.7147195748984814\n",
      "Steps:  11%| | 1654/15000 [10:37<4:52:17,  1.31s/it, lr=9.98e-6, step_loss=0.34907/18/2023 19:13:59 - INFO - __main__ - train loss is 0.739039808511734\n",
      "Steps:  11%| | 1655/15000 [10:37<3:36:33,  1.03it/s, lr=9.98e-6, step_loss=0.02407/18/2023 19:13:59 - INFO - __main__ - train loss is 0.8478228449821472\n",
      "Steps:  11%| | 1656/15000 [10:37<2:43:25,  1.36it/s, lr=9.98e-6, step_loss=0.10907/18/2023 19:14:00 - INFO - __main__ - train loss is 1.0309712588787079\n",
      "Steps:  11%| | 1657/15000 [10:37<2:06:16,  1.76it/s, lr=9.98e-6, step_loss=0.18307/18/2023 19:14:00 - INFO - __main__ - train loss is 1.0408718176186085\n",
      "Steps:  11%| | 1658/15000 [10:38<1:40:13,  2.22it/s, lr=9.98e-6, step_loss=0.00907/18/2023 19:14:00 - INFO - __main__ - train loss is 1.0427339143352583\n",
      "Steps:  11%| | 1659/15000 [10:38<1:22:00,  2.71it/s, lr=9.98e-6, step_loss=0.00107/18/2023 19:14:00 - INFO - __main__ - train loss is 1.1734160251216963\n",
      "Steps:  11%| | 1660/15000 [10:38<1:09:14,  3.21it/s, lr=9.98e-6, step_loss=0.13107/18/2023 19:14:00 - INFO - __main__ - train loss is 1.5632155007915571\n",
      "Steps:  11%| | 1661/15000 [10:38<1:00:18,  3.69it/s, lr=9.98e-6, step_loss=0.39]07/18/2023 19:14:00 - INFO - __main__ - train loss is 1.591219141264446\n",
      "Steps:  11%|▏ | 1662/15000 [10:38<54:06,  4.11it/s, lr=9.98e-6, step_loss=0.028]07/18/2023 19:14:01 - INFO - __main__ - train loss is 1.6290208614664152\n",
      "Steps:  11%| | 1663/15000 [10:38<49:53,  4.45it/s, lr=9.98e-6, step_loss=0.0378]07/18/2023 19:14:01 - INFO - __main__ - train loss is 1.6309491008287296\n",
      "Steps:  11%| | 1664/15000 [10:39<47:07,  4.72it/s, lr=9.98e-6, step_loss=0.0019307/18/2023 19:14:01 - INFO - __main__ - train loss is 1.6780775397783145\n",
      "Steps:  11%| | 1665/15000 [10:39<44:52,  4.95it/s, lr=9.98e-6, step_loss=0.0471]07/18/2023 19:14:01 - INFO - __main__ - train loss is 1.6852076224749908\n",
      "Steps:  11%| | 1666/15000 [10:39<43:17,  5.13it/s, lr=9.98e-6, step_loss=0.0071307/18/2023 19:14:01 - INFO - __main__ - train loss is 1.9263598792022094\n",
      "Steps:  11%|▏ | 1667/15000 [10:39<42:08,  5.27it/s, lr=9.98e-6, step_loss=0.241]07/18/2023 19:14:02 - INFO - __main__ - train loss is 2.1117616466945037\n",
      "Steps:  11%|▏ | 1668/15000 [10:39<41:58,  5.29it/s, lr=9.98e-6, step_loss=0.185]07/18/2023 19:14:02 - INFO - __main__ - train loss is 2.1447469241684303\n",
      "Steps:  11%|▏ | 1669/15000 [10:40<41:17,  5.38it/s, lr=9.98e-6, step_loss=0.033]07/18/2023 19:14:02 - INFO - __main__ - train loss is 2.2008751950925216\n",
      "Steps:  11%| | 1670/15000 [10:40<40:47,  5.45it/s, lr=9.98e-6, step_loss=0.0561]07/18/2023 19:14:02 - INFO - __main__ - train loss is 2.2347109004622325\n",
      "Steps:  11%| | 1671/15000 [10:40<40:28,  5.49it/s, lr=9.98e-6, step_loss=0.0338]07/18/2023 19:14:02 - INFO - __main__ - train loss is 2.7508608385687694\n",
      "Steps:  11%|▏ | 1672/15000 [10:40<40:22,  5.50it/s, lr=9.98e-6, step_loss=0.516]07/18/2023 19:14:02 - INFO - __main__ - train loss is 2.830729743815027\n",
      "Steps:  11%| | 1673/15000 [10:40<40:09,  5.53it/s, lr=9.98e-6, step_loss=0.0799]07/18/2023 19:14:03 - INFO - __main__ - train loss is 2.95421301422175\n",
      "Steps:  11%|▏ | 1674/15000 [10:40<39:57,  5.56it/s, lr=9.98e-6, step_loss=0.123]07/18/2023 19:14:03 - INFO - __main__ - train loss is 3.2695080548292026\n",
      "Steps:  11%|▏ | 1675/15000 [10:41<39:52,  5.57it/s, lr=9.98e-6, step_loss=0.315]07/18/2023 19:14:03 - INFO - __main__ - train loss is 3.3652661353116855\n",
      "Steps:  11%| | 1676/15000 [10:41<39:50,  5.57it/s, lr=9.98e-6, step_loss=0.0958]07/18/2023 19:14:03 - INFO - __main__ - train loss is 3.592816299176775\n",
      "Steps:  11%|▏ | 1677/15000 [10:41<39:46,  5.58it/s, lr=9.98e-6, step_loss=0.228]07/18/2023 19:14:03 - INFO - __main__ - train loss is 3.628766244626604\n",
      "Steps:  11%| | 1678/15000 [10:41<39:42,  5.59it/s, lr=9.98e-6, step_loss=0.0359]07/18/2023 19:14:03 - INFO - __main__ - train loss is 3.6694993659621105\n",
      "Steps:  11%| | 1679/15000 [10:41<40:03,  5.54it/s, lr=9.98e-6, step_loss=0.0407]07/18/2023 19:14:04 - INFO - __main__ - train loss is 3.6847727907588705\n",
      "Steps:  11%| | 1680/15000 [10:42<40:30,  5.48it/s, lr=9.98e-6, step_loss=0.0153]07/18/2023 19:14:04 - INFO - __main__ - train loss is 3.8075329525163397\n",
      "Steps:  11%|▏ | 1681/15000 [10:42<40:33,  5.47it/s, lr=9.98e-6, step_loss=0.123]07/18/2023 19:14:04 - INFO - __main__ - train loss is 3.8836977196624503\n",
      "Steps:  11%| | 1682/15000 [10:42<40:23,  5.50it/s, lr=9.98e-6, step_loss=0.0762]07/18/2023 19:14:04 - INFO - __main__ - train loss is 4.101109759300016\n",
      "Steps:  11%|▏ | 1683/15000 [10:42<40:15,  5.51it/s, lr=9.98e-6, step_loss=0.217]07/18/2023 19:14:04 - INFO - __main__ - train loss is 4.106325988075696\n",
      "Steps:  11%| | 1684/15000 [10:42<40:09,  5.53it/s, lr=9.98e-6, step_loss=0.0052207/18/2023 19:14:05 - INFO - __main__ - train loss is 4.109752675634809\n",
      "Steps:  11%| | 1685/15000 [10:42<40:00,  5.55it/s, lr=9.98e-6, step_loss=0.0034307/18/2023 19:14:05 - INFO - __main__ - train loss is 4.113425744581036\n",
      "Steps:  11%| | 1686/15000 [10:43<40:11,  5.52it/s, lr=9.98e-6, step_loss=0.0036707/18/2023 19:14:05 - INFO - __main__ - train loss is 4.168453732389025\n",
      "Steps:  11%|▏ | 1687/15000 [10:43<40:06,  5.53it/s, lr=9.98e-6, step_loss=0.055]07/18/2023 19:14:05 - INFO - __main__ - train loss is 4.17059815430548\n",
      "Steps:  11%| | 1688/15000 [10:43<40:03,  5.54it/s, lr=9.98e-6, step_loss=0.0021407/18/2023 19:14:05 - INFO - __main__ - train loss is 4.248125885962509\n",
      "Steps:  11%| | 1689/15000 [10:43<39:53,  5.56it/s, lr=9.98e-6, step_loss=0.0775]07/18/2023 19:14:05 - INFO - __main__ - train loss is 4.371923079132102\n",
      "Steps:  11%|▏ | 1690/15000 [10:43<39:51,  5.57it/s, lr=9.98e-6, step_loss=0.124]07/18/2023 19:14:06 - INFO - __main__ - train loss is 4.399465748458169\n",
      "Steps:  11%| | 1691/15000 [10:44<39:46,  5.58it/s, lr=9.98e-6, step_loss=0.0275]07/18/2023 19:14:06 - INFO - __main__ - train loss is 4.696767577319406\n",
      "Steps:  11%|▏ | 1692/15000 [10:44<39:41,  5.59it/s, lr=9.98e-6, step_loss=0.297]07/18/2023 19:14:06 - INFO - __main__ - train loss is 5.1830289451172575\n",
      "Steps:  11%|▏ | 1693/15000 [10:44<39:37,  5.60it/s, lr=9.98e-6, step_loss=0.486]07/18/2023 19:14:06 - INFO - __main__ - train loss is 5.450022497563623\n",
      "Steps:  11%|▏ | 1694/15000 [10:44<39:34,  5.60it/s, lr=9.98e-6, step_loss=0.267]07/18/2023 19:14:06 - INFO - __main__ - train loss is 5.4521384335821494\n",
      "Steps:  11%| | 1695/15000 [10:44<39:32,  5.61it/s, lr=9.98e-6, step_loss=0.0021207/18/2023 19:14:07 - INFO - __main__ - train loss is 5.669743309146725\n",
      "Steps:  11%|▏ | 1696/15000 [10:44<39:48,  5.57it/s, lr=9.98e-6, step_loss=0.218]07/18/2023 19:14:07 - INFO - __main__ - train loss is 6.036762336618267\n",
      "Steps:  11%|▏ | 1697/15000 [10:45<39:44,  5.58it/s, lr=9.98e-6, step_loss=0.367]07/18/2023 19:14:07 - INFO - __main__ - train loss is 6.125221046037041\n",
      "Steps:  11%| | 1698/15000 [10:45<39:39,  5.59it/s, lr=9.98e-6, step_loss=0.0885]07/18/2023 19:14:07 - INFO - __main__ - train loss is 6.187873231596313\n",
      "Steps:  11%| | 1699/15000 [10:45<39:36,  5.60it/s, lr=9.98e-6, step_loss=0.0627]07/18/2023 19:14:07 - INFO - __main__ - train loss is 6.2382180824643\n",
      "Steps:  11%| | 1700/15000 [10:45<39:35,  5.60it/s, lr=9.98e-6, step_loss=0.0503]07/18/2023 19:14:07 - INFO - __main__ - train loss is 6.740041686571203\n",
      "Steps:  11%|▏ | 1701/15000 [10:45<39:39,  5.59it/s, lr=9.98e-6, step_loss=0.502]07/18/2023 19:14:08 - INFO - __main__ - train loss is 7.235378487384878\n",
      "Steps:  11%|▏ | 1702/15000 [10:46<39:58,  5.54it/s, lr=9.98e-6, step_loss=0.495]07/18/2023 19:14:08 - INFO - __main__ - train loss is 7.861394925392233\n",
      "Steps:  11%|▏ | 1703/15000 [10:46<39:50,  5.56it/s, lr=9.98e-6, step_loss=0.626]07/18/2023 19:14:08 - INFO - __main__ - train loss is 7.870461278012954\n",
      "Steps:  11%| | 1704/15000 [10:46<39:43,  5.58it/s, lr=9.98e-6, step_loss=0.0090707/18/2023 19:14:08 - INFO - __main__ - train loss is 8.318775229505263\n",
      "Steps:  11%|▏ | 1705/15000 [10:46<39:49,  5.56it/s, lr=9.98e-6, step_loss=0.448]07/18/2023 19:14:08 - INFO - __main__ - train loss is 8.399731487384997\n",
      "Steps:  11%|▏ | 1706/15000 [10:46<39:41,  5.58it/s, lr=9.98e-6, step_loss=0.081]07/18/2023 19:14:09 - INFO - __main__ - train loss is 8.460867122164927\n",
      "Steps:  11%| | 1707/15000 [10:46<39:36,  5.59it/s, lr=9.98e-6, step_loss=0.0611]07/18/2023 19:14:09 - INFO - __main__ - train loss is 9.107252493849955\n",
      "Steps:  11%|▏ | 1708/15000 [10:47<39:32,  5.60it/s, lr=9.98e-6, step_loss=0.646]07/18/2023 19:14:09 - INFO - __main__ - train loss is 9.199929692200385\n",
      "Steps:  11%| | 1709/15000 [10:47<39:39,  5.59it/s, lr=9.98e-6, step_loss=0.0927]07/18/2023 19:14:09 - INFO - __main__ - train loss is 9.258310102275573\n",
      "Steps:  11%| | 1710/15000 [10:47<39:35,  5.60it/s, lr=9.98e-6, step_loss=0.0584]07/18/2023 19:14:09 - INFO - __main__ - train loss is 9.260478783282451\n",
      "Steps:  11%| | 1711/15000 [10:47<39:33,  5.60it/s, lr=9.98e-6, step_loss=0.0021707/18/2023 19:14:09 - INFO - __main__ - train loss is 9.279451617854647\n",
      "Steps:  11%|▏ | 1712/15000 [10:47<39:31,  5.60it/s, lr=9.98e-6, step_loss=0.019]07/18/2023 19:14:10 - INFO - __main__ - train loss is 9.627857068437152\n",
      "Steps:  11%|▏ | 1713/15000 [10:47<39:35,  5.59it/s, lr=9.98e-6, step_loss=0.348]07/18/2023 19:14:10 - INFO - __main__ - train loss is 9.637734901043586\n",
      "Steps:  11%| | 1714/15000 [10:48<39:34,  5.60it/s, lr=9.98e-6, step_loss=0.0098807/18/2023 19:14:10 - INFO - __main__ - train loss is 9.755064498516731\n",
      "Steps:  11%|▏ | 1715/15000 [10:48<39:55,  5.54it/s, lr=9.98e-6, step_loss=0.117]07/18/2023 19:14:10 - INFO - __main__ - train loss is 10.025067429873161\n",
      "Steps:  11%|▎  | 1716/15000 [10:48<40:15,  5.50it/s, lr=9.98e-6, step_loss=0.27]07/18/2023 19:14:10 - INFO - __main__ - train loss is 10.028994948486798\n",
      "Steps:  11%| | 1717/15000 [10:48<40:00,  5.53it/s, lr=9.98e-6, step_loss=0.0039307/18/2023 19:14:10 - INFO - __main__ - train loss is 10.390037537436001\n",
      "Steps:  11%|▏ | 1718/15000 [10:48<40:07,  5.52it/s, lr=9.98e-6, step_loss=0.361]07/18/2023 19:14:11 - INFO - __main__ - train loss is 10.41879907331895\n",
      "Steps:  11%| | 1719/15000 [10:49<39:55,  5.55it/s, lr=9.98e-6, step_loss=0.0288]07/18/2023 19:14:11 - INFO - __main__ - train loss is 10.439752546022646\n",
      "Steps:  11%|▏ | 1720/15000 [10:49<39:56,  5.54it/s, lr=9.98e-6, step_loss=0.021]07/18/2023 19:14:11 - INFO - __main__ - train loss is 10.449001829954796\n",
      "Steps:  11%| | 1721/15000 [10:49<39:52,  5.55it/s, lr=9.98e-6, step_loss=0.0092507/18/2023 19:14:11 - INFO - __main__ - train loss is 10.453041907283477\n",
      "Steps:  11%| | 1722/15000 [10:49<39:43,  5.57it/s, lr=9.98e-6, step_loss=0.0040407/18/2023 19:14:11 - INFO - __main__ - train loss is 10.468493780936114\n",
      "Steps:  11%| | 1723/15000 [10:49<39:59,  5.53it/s, lr=9.98e-6, step_loss=0.0155]07/18/2023 19:14:12 - INFO - __main__ - train loss is 10.63120845600497\n",
      "Steps:  11%|▏ | 1724/15000 [10:49<39:56,  5.54it/s, lr=9.98e-6, step_loss=0.163]07/18/2023 19:14:12 - INFO - __main__ - train loss is 10.636044063488953\n",
      "Steps:  12%| | 1725/15000 [10:50<39:46,  5.56it/s, lr=9.98e-6, step_loss=0.0048407/18/2023 19:14:12 - INFO - __main__ - train loss is 10.70179411850404\n",
      "Steps:  12%| | 1726/15000 [10:50<39:54,  5.54it/s, lr=9.98e-6, step_loss=0.0658]07/18/2023 19:14:12 - INFO - __main__ - train loss is 11.06063291511964\n",
      "Steps:  12%|▏ | 1727/15000 [10:50<39:44,  5.57it/s, lr=9.98e-6, step_loss=0.359]07/18/2023 19:14:12 - INFO - __main__ - train loss is 11.15121468983125\n",
      "Steps:  12%| | 1728/15000 [10:50<40:01,  5.53it/s, lr=9.98e-6, step_loss=0.0906]07/18/2023 19:14:12 - INFO - __main__ - train loss is 11.346601814846508\n",
      "Steps:  12%|▏ | 1729/15000 [10:50<40:31,  5.46it/s, lr=9.98e-6, step_loss=0.195]07/18/2023 19:14:13 - INFO - __main__ - train loss is 11.4551489361329\n",
      "Steps:  12%|▏ | 1730/15000 [10:51<40:12,  5.50it/s, lr=9.98e-6, step_loss=0.109]07/18/2023 19:14:13 - INFO - __main__ - train loss is 11.912752778152935\n",
      "Steps:  12%|▏ | 1731/15000 [10:51<39:58,  5.53it/s, lr=9.98e-6, step_loss=0.458]07/18/2023 19:14:13 - INFO - __main__ - train loss is 12.512240202049725\n",
      "Steps:  12%|▏ | 1732/15000 [10:51<39:49,  5.55it/s, lr=9.98e-6, step_loss=0.599]07/18/2023 19:14:13 - INFO - __main__ - train loss is 12.551747218589298\n",
      "Steps:  12%| | 1733/15000 [10:51<39:48,  5.56it/s, lr=9.98e-6, step_loss=0.0395]07/18/2023 19:14:13 - INFO - __main__ - train loss is 12.553907433873974\n",
      "Steps:  12%| | 1734/15000 [10:51<39:40,  5.57it/s, lr=9.98e-6, step_loss=0.0021607/18/2023 19:14:14 - INFO - __main__ - train loss is 12.58927820099052\n",
      "Steps:  12%| | 1735/15000 [10:51<39:56,  5.53it/s, lr=9.98e-6, step_loss=0.0354]07/18/2023 19:14:14 - INFO - __main__ - train loss is 12.648256564862095\n",
      "Steps:  12%|▏ | 1736/15000 [10:52<40:06,  5.51it/s, lr=9.98e-6, step_loss=0.059]07/18/2023 19:14:14 - INFO - __main__ - train loss is 13.07901480270084\n",
      "Steps:  12%|▏ | 1737/15000 [10:52<39:58,  5.53it/s, lr=9.98e-6, step_loss=0.431]07/18/2023 19:14:14 - INFO - __main__ - train loss is 13.259089822298847\n",
      "Steps:  12%|▎  | 1738/15000 [10:52<39:48,  5.55it/s, lr=9.98e-6, step_loss=0.18]07/18/2023 19:14:14 - INFO - __main__ - train loss is 13.281608421704732\n",
      "Steps:  12%| | 1739/15000 [10:52<39:40,  5.57it/s, lr=9.98e-6, step_loss=0.0225]07/18/2023 19:14:14 - INFO - __main__ - train loss is 13.376197312376462\n",
      "Steps:  12%| | 1740/15000 [10:52<39:37,  5.58it/s, lr=9.98e-6, step_loss=0.0946]07/18/2023 19:14:15 - INFO - __main__ - train loss is 13.403037194511853\n",
      "Steps:  12%| | 1741/15000 [10:53<39:45,  5.56it/s, lr=9.98e-6, step_loss=0.0268]07/18/2023 19:14:15 - INFO - __main__ - train loss is 13.613464329740964\n",
      "Steps:  12%|▎  | 1742/15000 [10:53<39:56,  5.53it/s, lr=9.98e-6, step_loss=0.21]07/18/2023 19:14:15 - INFO - __main__ - train loss is 14.177965615293942\n",
      "Steps:  12%|▏ | 1743/15000 [10:53<39:47,  5.55it/s, lr=9.98e-6, step_loss=0.565]07/18/2023 19:14:15 - INFO - __main__ - train loss is 14.188660050160252\n",
      "Steps:  12%| | 1744/15000 [10:53<40:00,  5.52it/s, lr=9.98e-6, step_loss=0.0107]07/18/2023 19:14:15 - INFO - __main__ - train loss is 14.448534155613743\n",
      "Steps:  12%|▎  | 1745/15000 [10:53<39:53,  5.54it/s, lr=9.98e-6, step_loss=0.26]07/18/2023 19:14:16 - INFO - __main__ - train loss is 14.474741280428134\n",
      "Steps:  12%| | 1746/15000 [10:54<52:30,  4.21it/s, lr=9.98e-6, step_loss=0.0262]07/18/2023 19:14:17 - INFO - __main__ - Per validation step average loss is 0.004189429804682732\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Cumulative validation average loss is 0.004189429804682732\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Per validation step average loss is 0.4843856394290924\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Cumulative validation average loss is 0.48857506923377514\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Per validation step average loss is 0.5594496726989746\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Cumulative validation average loss is 1.0480247419327497\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Per validation step average loss is 0.25463366508483887\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Cumulative validation average loss is 1.3026584070175886\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Per validation step average loss is 0.029744740575551987\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Cumulative validation average loss is 1.3324031475931406\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Per validation step average loss is 0.18931260704994202\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Cumulative validation average loss is 1.5217157546430826\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Per validation step average loss is 0.13695721328258514\n",
      "07/18/2023 19:14:17 - INFO - __main__ - Cumulative validation average loss is 1.6586729679256678\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Per validation step average loss is 0.11666153371334076\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Cumulative validation average loss is 1.7753345016390085\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Per validation step average loss is 0.2821957468986511\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Cumulative validation average loss is 2.0575302485376596\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Per validation step average loss is 0.0345437228679657\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Cumulative validation average loss is 2.0920739714056253\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Per validation step average loss is 0.33144766092300415\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Cumulative validation average loss is 2.4235216323286295\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Per validation step average loss is 0.19089746475219727\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Cumulative validation average loss is 2.6144190970808268\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Average validation loss for Epoch 17 is 0.2178682580900689\n",
      "07/18/2023 19:14:18 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:14:32 - INFO - __main__ - Starting epoch 18\n",
      "07/18/2023 19:14:32 - INFO - __main__ - train loss is 0.23493795096874237\n",
      "Steps:  12%| | 1747/15000 [11:10<18:44:42,  5.09s/it, lr=9.98e-6, step_loss=0.2307/18/2023 19:14:32 - INFO - __main__ - train loss is 0.3679332286119461\n",
      "Steps:  12%| | 1748/15000 [11:10<13:19:15,  3.62s/it, lr=9.98e-6, step_loss=0.1307/18/2023 19:14:33 - INFO - __main__ - train loss is 0.4079962261021137\n",
      "Steps:  12%| | 1749/15000 [11:10<9:31:13,  2.59s/it, lr=9.98e-6, step_loss=0.04007/18/2023 19:14:33 - INFO - __main__ - train loss is 0.41617272328585386\n",
      "Steps:  12%| | 1750/15000 [11:11<6:51:41,  1.86s/it, lr=9.98e-6, step_loss=0.00807/18/2023 19:14:33 - INFO - __main__ - train loss is 0.5264150006696582\n",
      "Steps:  12%| | 1751/15000 [11:11<5:00:06,  1.36s/it, lr=9.98e-6, step_loss=0.11]07/18/2023 19:14:33 - INFO - __main__ - train loss is 0.5492661138996482\n",
      "Steps:  12%| | 1752/15000 [11:11<3:41:51,  1.00s/it, lr=9.98e-6, step_loss=0.02207/18/2023 19:14:33 - INFO - __main__ - train loss is 0.56661615986377\n",
      "Steps:  12%| | 1753/15000 [11:11<2:47:10,  1.32it/s, lr=9.98e-6, step_loss=0.01707/18/2023 19:14:33 - INFO - __main__ - train loss is 0.6244578817859292\n",
      "Steps:  12%| | 1754/15000 [11:11<2:08:52,  1.71it/s, lr=9.98e-6, step_loss=0.05707/18/2023 19:14:34 - INFO - __main__ - train loss is 0.7472819397225976\n",
      "Steps:  12%| | 1755/15000 [11:11<1:42:01,  2.16it/s, lr=9.98e-6, step_loss=0.12307/18/2023 19:14:34 - INFO - __main__ - train loss is 0.8946952531114221\n",
      "Steps:  12%| | 1756/15000 [11:12<1:23:16,  2.65it/s, lr=9.98e-6, step_loss=0.14707/18/2023 19:14:34 - INFO - __main__ - train loss is 0.9941642442718148\n",
      "Steps:  12%| | 1757/15000 [11:12<1:10:05,  3.15it/s, lr=9.98e-6, step_loss=0.09907/18/2023 19:14:34 - INFO - __main__ - train loss is 1.0960346916690469\n",
      "Steps:  12%| | 1758/15000 [11:12<1:01:00,  3.62it/s, lr=9.98e-6, step_loss=0.10207/18/2023 19:14:34 - INFO - __main__ - train loss is 1.2095753038302064\n",
      "Steps:  12%|▏ | 1759/15000 [11:12<54:26,  4.05it/s, lr=9.98e-6, step_loss=0.114]07/18/2023 19:14:34 - INFO - __main__ - train loss is 1.2280995296314359\n",
      "Steps:  12%| | 1760/15000 [11:12<49:51,  4.43it/s, lr=9.98e-6, step_loss=0.0185]07/18/2023 19:14:35 - INFO - __main__ - train loss is 1.349069301970303\n",
      "Steps:  12%|▏ | 1761/15000 [11:13<46:47,  4.72it/s, lr=9.98e-6, step_loss=0.121]07/18/2023 19:14:35 - INFO - __main__ - train loss is 1.7036723541095853\n",
      "Steps:  12%|▏ | 1762/15000 [11:13<44:32,  4.95it/s, lr=9.98e-6, step_loss=0.355]07/18/2023 19:14:35 - INFO - __main__ - train loss is 1.794572209008038\n",
      "Steps:  12%| | 1763/15000 [11:13<42:56,  5.14it/s, lr=9.98e-6, step_loss=0.0909]07/18/2023 19:14:35 - INFO - __main__ - train loss is 1.9244038509204984\n",
      "Steps:  12%|▎  | 1764/15000 [11:13<41:55,  5.26it/s, lr=9.98e-6, step_loss=0.13]07/18/2023 19:14:35 - INFO - __main__ - train loss is 2.0201743440702558\n",
      "Steps:  12%| | 1765/15000 [11:13<41:08,  5.36it/s, lr=9.98e-6, step_loss=0.0958]07/18/2023 19:14:36 - INFO - __main__ - train loss is 2.107593079097569\n",
      "Steps:  12%| | 1766/15000 [11:13<40:42,  5.42it/s, lr=9.98e-6, step_loss=0.0874]07/18/2023 19:14:36 - INFO - __main__ - train loss is 2.123125188983977\n",
      "Steps:  12%| | 1767/15000 [11:14<40:16,  5.48it/s, lr=9.98e-6, step_loss=0.0155]07/18/2023 19:14:36 - INFO - __main__ - train loss is 2.228715159930289\n",
      "Steps:  12%|▏ | 1768/15000 [11:14<39:59,  5.51it/s, lr=9.98e-6, step_loss=0.106]07/18/2023 19:14:36 - INFO - __main__ - train loss is 2.273130946792662\n",
      "Steps:  12%| | 1769/15000 [11:14<40:15,  5.48it/s, lr=9.98e-6, step_loss=0.0444]07/18/2023 19:14:36 - INFO - __main__ - train loss is 2.2770777279511094\n",
      "Steps:  12%| | 1770/15000 [11:14<40:21,  5.46it/s, lr=9.98e-6, step_loss=0.0039507/18/2023 19:14:36 - INFO - __main__ - train loss is 2.326264259405434\n",
      "Steps:  12%| | 1771/15000 [11:14<40:22,  5.46it/s, lr=9.98e-6, step_loss=0.0492]07/18/2023 19:14:37 - INFO - __main__ - train loss is 2.3351204777136445\n",
      "Steps:  12%| | 1772/15000 [11:15<40:26,  5.45it/s, lr=9.98e-6, step_loss=0.0088607/18/2023 19:14:37 - INFO - __main__ - train loss is 2.486878582276404\n",
      "Steps:  12%|▏ | 1773/15000 [11:15<40:21,  5.46it/s, lr=9.98e-6, step_loss=0.152]07/18/2023 19:14:37 - INFO - __main__ - train loss is 2.4984076004475355\n",
      "Steps:  12%| | 1774/15000 [11:15<40:03,  5.50it/s, lr=9.98e-6, step_loss=0.0115]07/18/2023 19:14:37 - INFO - __main__ - train loss is 2.503500080667436\n",
      "Steps:  12%| | 1775/15000 [11:15<40:09,  5.49it/s, lr=9.98e-6, step_loss=0.0050907/18/2023 19:14:37 - INFO - __main__ - train loss is 2.5310445791110396\n",
      "Steps:  12%| | 1776/15000 [11:15<40:18,  5.47it/s, lr=9.98e-6, step_loss=0.0275]07/18/2023 19:14:38 - INFO - __main__ - train loss is 2.5894521391019225\n",
      "Steps:  12%| | 1777/15000 [11:15<40:11,  5.48it/s, lr=9.98e-6, step_loss=0.0584]07/18/2023 19:14:38 - INFO - __main__ - train loss is 2.7058462416753173\n",
      "Steps:  12%|▏ | 1778/15000 [11:16<39:54,  5.52it/s, lr=9.98e-6, step_loss=0.116]07/18/2023 19:14:38 - INFO - __main__ - train loss is 2.7769196247681975\n",
      "Steps:  12%| | 1779/15000 [11:16<39:43,  5.55it/s, lr=9.98e-6, step_loss=0.0711]07/18/2023 19:14:38 - INFO - __main__ - train loss is 3.151373407803476\n",
      "Steps:  12%|▏ | 1780/15000 [11:16<39:37,  5.56it/s, lr=9.98e-6, step_loss=0.374]07/18/2023 19:14:38 - INFO - __main__ - train loss is 3.1604082761332393\n",
      "Steps:  12%| | 1781/15000 [11:16<39:31,  5.57it/s, lr=9.98e-6, step_loss=0.0090307/18/2023 19:14:38 - INFO - __main__ - train loss is 3.220103676430881\n",
      "Steps:  12%| | 1782/15000 [11:16<39:26,  5.58it/s, lr=9.98e-6, step_loss=0.0597]07/18/2023 19:14:39 - INFO - __main__ - train loss is 3.2231359872967005\n",
      "Steps:  12%| | 1783/15000 [11:17<39:23,  5.59it/s, lr=9.98e-6, step_loss=0.0030307/18/2023 19:14:39 - INFO - __main__ - train loss is 3.3329238910228014\n",
      "Steps:  12%|▎  | 1784/15000 [11:17<39:30,  5.58it/s, lr=9.98e-6, step_loss=0.11]07/18/2023 19:14:39 - INFO - __main__ - train loss is 3.3786933552473783\n",
      "Steps:  12%| | 1785/15000 [11:17<39:24,  5.59it/s, lr=9.98e-6, step_loss=0.0458]07/18/2023 19:14:39 - INFO - __main__ - train loss is 3.4909709822386503\n",
      "Steps:  12%|▏ | 1786/15000 [11:17<39:22,  5.59it/s, lr=9.98e-6, step_loss=0.112]07/18/2023 19:14:39 - INFO - __main__ - train loss is 4.0228588711470366\n",
      "Steps:  12%|▏ | 1787/15000 [11:17<39:19,  5.60it/s, lr=9.98e-6, step_loss=0.532]07/18/2023 19:14:40 - INFO - __main__ - train loss is 4.090963361784816\n",
      "Steps:  12%| | 1788/15000 [11:17<39:17,  5.60it/s, lr=9.98e-6, step_loss=0.0681]07/18/2023 19:14:40 - INFO - __main__ - train loss is 4.118371535092592\n",
      "Steps:  12%| | 1789/15000 [11:18<39:16,  5.61it/s, lr=9.98e-6, step_loss=0.0274]07/18/2023 19:14:40 - INFO - __main__ - train loss is 4.433021653443575\n",
      "Steps:  12%|▏ | 1790/15000 [11:18<39:16,  5.61it/s, lr=9.98e-6, step_loss=0.315]07/18/2023 19:14:40 - INFO - __main__ - train loss is 4.4514440055936575\n",
      "Steps:  12%| | 1791/15000 [11:18<39:15,  5.61it/s, lr=9.98e-6, step_loss=0.0184]07/18/2023 19:14:40 - INFO - __main__ - train loss is 4.459440649487078\n",
      "Steps:  12%|▏ | 1792/15000 [11:18<39:17,  5.60it/s, lr=9.98e-6, step_loss=0.008]07/18/2023 19:14:40 - INFO - __main__ - train loss is 5.044011832214892\n",
      "Steps:  12%|▏ | 1793/15000 [11:18<39:17,  5.60it/s, lr=9.98e-6, step_loss=0.585]07/18/2023 19:14:41 - INFO - __main__ - train loss is 5.050678291358054\n",
      "Steps:  12%| | 1794/15000 [11:18<39:16,  5.60it/s, lr=9.98e-6, step_loss=0.0066707/18/2023 19:14:41 - INFO - __main__ - train loss is 5.294806801714003\n",
      "Steps:  12%|▏ | 1795/15000 [11:19<39:16,  5.60it/s, lr=9.98e-6, step_loss=0.244]07/18/2023 19:14:41 - INFO - __main__ - train loss is 5.297357033472508\n",
      "Steps:  12%| | 1796/15000 [11:19<39:20,  5.59it/s, lr=9.98e-6, step_loss=0.0025507/18/2023 19:14:41 - INFO - __main__ - train loss is 5.442807133775204\n",
      "Steps:  12%|▏ | 1797/15000 [11:19<39:17,  5.60it/s, lr=9.98e-6, step_loss=0.145]07/18/2023 19:14:41 - INFO - __main__ - train loss is 5.472071989905089\n",
      "Steps:  12%| | 1798/15000 [11:19<39:15,  5.60it/s, lr=9.98e-6, step_loss=0.0293]07/18/2023 19:14:41 - INFO - __main__ - train loss is 5.481693414505571\n",
      "Steps:  12%| | 1799/15000 [11:19<39:15,  5.60it/s, lr=9.98e-6, step_loss=0.0096207/18/2023 19:14:42 - INFO - __main__ - train loss is 5.6489675915800035\n",
      "Steps:  12%|▏ | 1800/15000 [11:20<39:14,  5.61it/s, lr=9.98e-6, step_loss=0.167]07/18/2023 19:14:42 - INFO - __main__ - train loss is 6.281485287006944\n",
      "Steps:  12%|▏ | 1801/15000 [11:20<39:11,  5.61it/s, lr=9.98e-6, step_loss=0.633]07/18/2023 19:14:42 - INFO - __main__ - train loss is 6.290326113346964\n",
      "Steps:  12%| | 1802/15000 [11:20<39:11,  5.61it/s, lr=9.98e-6, step_loss=0.0088407/18/2023 19:14:42 - INFO - __main__ - train loss is 6.292251782724634\n",
      "Steps:  12%| | 1803/15000 [11:20<39:12,  5.61it/s, lr=9.98e-6, step_loss=0.0019307/18/2023 19:14:42 - INFO - __main__ - train loss is 6.324751856038347\n",
      "Steps:  12%| | 1804/15000 [11:20<39:11,  5.61it/s, lr=9.98e-6, step_loss=0.0325]07/18/2023 19:14:43 - INFO - __main__ - train loss is 6.417141387471929\n",
      "Steps:  12%| | 1805/15000 [11:20<39:20,  5.59it/s, lr=9.98e-6, step_loss=0.0924]07/18/2023 19:14:43 - INFO - __main__ - train loss is 6.545115689048544\n",
      "Steps:  12%|▏ | 1806/15000 [11:21<39:21,  5.59it/s, lr=9.98e-6, step_loss=0.128]07/18/2023 19:14:43 - INFO - __main__ - train loss is 6.775203028926626\n",
      "Steps:  12%|▎  | 1807/15000 [11:21<39:25,  5.58it/s, lr=9.98e-6, step_loss=0.23]07/18/2023 19:14:43 - INFO - __main__ - train loss is 6.819401158252731\n",
      "Steps:  12%| | 1808/15000 [11:21<39:54,  5.51it/s, lr=9.98e-6, step_loss=0.0442]07/18/2023 19:14:43 - INFO - __main__ - train loss is 7.1114003791008145\n",
      "Steps:  12%|▏ | 1809/15000 [11:21<39:41,  5.54it/s, lr=9.98e-6, step_loss=0.292]07/18/2023 19:14:43 - INFO - __main__ - train loss is 7.221460080007091\n",
      "Steps:  12%|▎  | 1810/15000 [11:21<39:51,  5.52it/s, lr=9.98e-6, step_loss=0.11]07/18/2023 19:14:44 - INFO - __main__ - train loss is 7.258565312484279\n",
      "Steps:  12%| | 1811/15000 [11:22<40:06,  5.48it/s, lr=9.98e-6, step_loss=0.0371]07/18/2023 19:14:44 - INFO - __main__ - train loss is 7.267880412051454\n",
      "Steps:  12%| | 1812/15000 [11:22<39:58,  5.50it/s, lr=9.98e-6, step_loss=0.0093207/18/2023 19:14:44 - INFO - __main__ - train loss is 7.3041600754950196\n",
      "Steps:  12%| | 1813/15000 [11:22<39:43,  5.53it/s, lr=9.98e-6, step_loss=0.0363]07/18/2023 19:14:44 - INFO - __main__ - train loss is 7.708552735159174\n",
      "Steps:  12%|▏ | 1814/15000 [11:22<39:33,  5.55it/s, lr=9.98e-6, step_loss=0.404]07/18/2023 19:14:44 - INFO - __main__ - train loss is 7.710198321728967\n",
      "Steps:  12%| | 1815/15000 [11:22<39:27,  5.57it/s, lr=9.98e-6, step_loss=0.0016507/18/2023 19:14:45 - INFO - __main__ - train loss is 7.716217717970721\n",
      "Steps:  12%| | 1816/15000 [11:22<39:24,  5.58it/s, lr=9.98e-6, step_loss=0.0060207/18/2023 19:14:45 - INFO - __main__ - train loss is 7.757937571848743\n",
      "Steps:  12%| | 1817/15000 [11:23<39:24,  5.58it/s, lr=9.98e-6, step_loss=0.0417]07/18/2023 19:14:45 - INFO - __main__ - train loss is 8.469578287447803\n",
      "Steps:  12%|▏ | 1818/15000 [11:23<39:31,  5.56it/s, lr=9.98e-6, step_loss=0.712]07/18/2023 19:14:45 - INFO - __main__ - train loss is 8.761127791251056\n",
      "Steps:  12%|▏ | 1819/15000 [11:23<39:25,  5.57it/s, lr=9.98e-6, step_loss=0.292]07/18/2023 19:14:45 - INFO - __main__ - train loss is 9.289782366598956\n",
      "Steps:  12%|▏ | 1820/15000 [11:23<39:21,  5.58it/s, lr=9.98e-6, step_loss=0.529]07/18/2023 19:14:45 - INFO - __main__ - train loss is 9.29599882743787\n",
      "Steps:  12%| | 1821/15000 [11:23<39:17,  5.59it/s, lr=9.98e-6, step_loss=0.0062207/18/2023 19:14:46 - INFO - __main__ - train loss is 9.315731393988244\n",
      "Steps:  12%| | 1822/15000 [11:24<39:17,  5.59it/s, lr=9.98e-6, step_loss=0.0197]07/18/2023 19:14:46 - INFO - __main__ - train loss is 9.336670803721063\n",
      "Steps:  12%| | 1823/15000 [11:24<39:15,  5.59it/s, lr=9.98e-6, step_loss=0.0209]07/18/2023 19:14:46 - INFO - __main__ - train loss is 9.650392996962182\n",
      "Steps:  12%|▏ | 1824/15000 [11:24<39:13,  5.60it/s, lr=9.98e-6, step_loss=0.314]07/18/2023 19:14:46 - INFO - __main__ - train loss is 9.88576525717508\n",
      "Steps:  12%|▏ | 1825/15000 [11:24<39:21,  5.58it/s, lr=9.98e-6, step_loss=0.235]07/18/2023 19:14:46 - INFO - __main__ - train loss is 9.88916741067078\n",
      "Steps:  12%| | 1826/15000 [11:24<39:20,  5.58it/s, lr=9.98e-6, step_loss=0.0034]07/18/2023 19:14:47 - INFO - __main__ - train loss is 10.560646516620182\n",
      "Steps:  12%|▏ | 1827/15000 [11:24<39:17,  5.59it/s, lr=9.98e-6, step_loss=0.671]07/18/2023 19:14:47 - INFO - __main__ - train loss is 10.582466719090007\n",
      "Steps:  12%| | 1828/15000 [11:25<39:14,  5.59it/s, lr=9.98e-6, step_loss=0.0218]07/18/2023 19:14:47 - INFO - __main__ - train loss is 10.584037715685554\n",
      "Steps:  12%| | 1829/15000 [11:25<39:34,  5.55it/s, lr=9.98e-6, step_loss=0.0015707/18/2023 19:14:47 - INFO - __main__ - train loss is 11.093481237185188\n",
      "Steps:  12%|▏ | 1830/15000 [11:25<39:44,  5.52it/s, lr=9.98e-6, step_loss=0.509]07/18/2023 19:14:47 - INFO - __main__ - train loss is 11.101679411833175\n",
      "Steps:  12%| | 1831/15000 [11:25<39:34,  5.55it/s, lr=9.98e-6, step_loss=0.0082]07/18/2023 19:14:47 - INFO - __main__ - train loss is 11.337494460050948\n",
      "Steps:  12%|▏ | 1832/15000 [11:25<39:48,  5.51it/s, lr=9.98e-6, step_loss=0.236]07/18/2023 19:14:48 - INFO - __main__ - train loss is 11.535073039238341\n",
      "Steps:  12%|▏ | 1833/15000 [11:25<39:40,  5.53it/s, lr=9.98e-6, step_loss=0.198]07/18/2023 19:14:48 - INFO - __main__ - train loss is 11.656184208695777\n",
      "Steps:  12%|▏ | 1834/15000 [11:26<39:33,  5.55it/s, lr=9.98e-6, step_loss=0.121]07/18/2023 19:14:48 - INFO - __main__ - train loss is 11.875725788180716\n",
      "Steps:  12%|▎  | 1835/15000 [11:26<39:26,  5.56it/s, lr=9.98e-6, step_loss=0.22]07/18/2023 19:14:48 - INFO - __main__ - train loss is 11.93303484201897\n",
      "Steps:  12%| | 1836/15000 [11:26<39:48,  5.51it/s, lr=9.98e-6, step_loss=0.0573]07/18/2023 19:14:48 - INFO - __main__ - train loss is 12.204343383316882\n",
      "Steps:  12%|▏ | 1837/15000 [11:26<39:33,  5.55it/s, lr=9.98e-6, step_loss=0.271]07/18/2023 19:14:48 - INFO - __main__ - train loss is 12.248575733159669\n",
      "Steps:  12%| | 1838/15000 [11:26<39:24,  5.57it/s, lr=9.98e-6, step_loss=0.0442]07/18/2023 19:14:49 - INFO - __main__ - train loss is 12.335014619980939\n",
      "Steps:  12%| | 1839/15000 [11:27<39:26,  5.56it/s, lr=9.98e-6, step_loss=0.0864]07/18/2023 19:14:49 - INFO - __main__ - train loss is 12.342671868042089\n",
      "Steps:  12%| | 1840/15000 [11:27<39:20,  5.57it/s, lr=9.98e-6, step_loss=0.0076607/18/2023 19:14:49 - INFO - __main__ - train loss is 12.346844930783845\n",
      "Steps:  12%| | 1841/15000 [11:27<39:15,  5.59it/s, lr=9.98e-6, step_loss=0.0041707/18/2023 19:14:49 - INFO - __main__ - train loss is 12.501731265918352\n",
      "Steps:  12%|▏ | 1842/15000 [11:27<39:11,  5.60it/s, lr=9.98e-6, step_loss=0.155]07/18/2023 19:14:50 - INFO - __main__ - train loss is 12.535823751823045\n",
      "Steps:  12%| | 1843/15000 [11:27<53:21,  4.11it/s, lr=9.98e-6, step_loss=0.0341]07/18/2023 19:14:50 - INFO - __main__ - Per validation step average loss is 0.06556430459022522\n",
      "07/18/2023 19:14:50 - INFO - __main__ - Cumulative validation average loss is 0.06556430459022522\n",
      "07/18/2023 19:14:50 - INFO - __main__ - Per validation step average loss is 0.18560856580734253\n",
      "07/18/2023 19:14:50 - INFO - __main__ - Cumulative validation average loss is 0.25117287039756775\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Per validation step average loss is 0.12345322966575623\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Cumulative validation average loss is 0.374626100063324\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Per validation step average loss is 0.08562155067920685\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Cumulative validation average loss is 0.4602476507425308\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Per validation step average loss is 0.32171472907066345\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Cumulative validation average loss is 0.7819623798131943\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Per validation step average loss is 0.018288571387529373\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Cumulative validation average loss is 0.8002509512007236\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Per validation step average loss is 0.24979054927825928\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Cumulative validation average loss is 1.050041500478983\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Per validation step average loss is 0.1641048938035965\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Cumulative validation average loss is 1.2141463942825794\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Per validation step average loss is 0.023209530860185623\n",
      "07/18/2023 19:14:51 - INFO - __main__ - Cumulative validation average loss is 1.237355925142765\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Per validation step average loss is 0.006910927593708038\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Cumulative validation average loss is 1.244266852736473\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Per validation step average loss is 0.028398049995303154\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Cumulative validation average loss is 1.2726649027317762\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Per validation step average loss is 0.1223391592502594\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Cumulative validation average loss is 1.3950040619820356\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Average validation loss for Epoch 18 is 0.11625033849850297\n",
      "07/18/2023 19:14:52 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:15:05 - INFO - __main__ - Starting epoch 19\n",
      "07/18/2023 19:15:05 - INFO - __main__ - train loss is 0.004940524697303772\n",
      "Steps:  12%| | 1844/15000 [11:43<17:53:45,  4.90s/it, lr=9.98e-6, step_loss=0.0007/18/2023 19:15:06 - INFO - __main__ - train loss is 0.012753129005432129\n",
      "Steps:  12%| | 1845/15000 [11:43<12:43:37,  3.48s/it, lr=9.98e-6, step_loss=0.0007/18/2023 19:15:06 - INFO - __main__ - train loss is 0.336650550365448\n",
      "Steps:  12%| | 1846/15000 [11:44<9:06:49,  2.49s/it, lr=9.98e-6, step_loss=0.32407/18/2023 19:15:06 - INFO - __main__ - train loss is 0.9017215371131897\n",
      "Steps:  12%| | 1847/15000 [11:44<6:34:28,  1.80s/it, lr=9.98e-6, step_loss=0.56507/18/2023 19:15:06 - INFO - __main__ - train loss is 0.9044308981392533\n",
      "Steps:  12%| | 1848/15000 [11:44<4:47:52,  1.31s/it, lr=9.98e-6, step_loss=0.00207/18/2023 19:15:06 - INFO - __main__ - train loss is 0.9327598011586815\n",
      "Steps:  12%| | 1849/15000 [11:44<3:33:23,  1.03it/s, lr=9.98e-6, step_loss=0.02807/18/2023 19:15:06 - INFO - __main__ - train loss is 0.9495617731008679\n",
      "Steps:  12%| | 1850/15000 [11:44<2:41:16,  1.36it/s, lr=9.98e-6, step_loss=0.01607/18/2023 19:15:07 - INFO - __main__ - train loss is 1.0348026736173779\n",
      "Steps:  12%| | 1851/15000 [11:45<2:04:34,  1.76it/s, lr=9.98e-6, step_loss=0.08507/18/2023 19:15:07 - INFO - __main__ - train loss is 1.1864285750780255\n",
      "Steps:  12%| | 1852/15000 [11:45<1:38:52,  2.22it/s, lr=9.98e-6, step_loss=0.15207/18/2023 19:15:07 - INFO - __main__ - train loss is 1.4041468186769634\n",
      "Steps:  12%| | 1853/15000 [11:45<1:20:51,  2.71it/s, lr=9.98e-6, step_loss=0.21807/18/2023 19:15:07 - INFO - __main__ - train loss is 1.6270814968738705\n",
      "Steps:  12%| | 1854/15000 [11:45<1:08:15,  3.21it/s, lr=9.98e-6, step_loss=0.22307/18/2023 19:15:07 - INFO - __main__ - train loss is 2.015653951326385\n",
      "Steps:  12%|▏ | 1855/15000 [11:45<59:26,  3.69it/s, lr=9.98e-6, step_loss=0.389]07/18/2023 19:15:08 - INFO - __main__ - train loss is 2.1335917024407536\n",
      "Steps:  12%|▏ | 1856/15000 [11:45<53:43,  4.08it/s, lr=9.98e-6, step_loss=0.118]07/18/2023 19:15:08 - INFO - __main__ - train loss is 2.190872455248609\n",
      "Steps:  12%| | 1857/15000 [11:46<49:17,  4.44it/s, lr=9.98e-6, step_loss=0.0573]07/18/2023 19:15:08 - INFO - __main__ - train loss is 2.259666750440374\n",
      "Steps:  12%| | 1858/15000 [11:46<46:16,  4.73it/s, lr=9.98e-6, step_loss=0.0688]07/18/2023 19:15:08 - INFO - __main__ - train loss is 2.2727047067601234\n",
      "Steps:  12%|▏ | 1859/15000 [11:46<44:08,  4.96it/s, lr=9.98e-6, step_loss=0.013]07/18/2023 19:15:08 - INFO - __main__ - train loss is 2.8969826560933143\n",
      "Steps:  12%|▏ | 1860/15000 [11:46<42:32,  5.15it/s, lr=9.98e-6, step_loss=0.624]07/18/2023 19:15:08 - INFO - __main__ - train loss is 2.8988350806757808\n",
      "Steps:  12%| | 1861/15000 [11:46<41:30,  5.28it/s, lr=9.98e-6, step_loss=0.0018507/18/2023 19:15:09 - INFO - __main__ - train loss is 2.9522414607927203\n",
      "Steps:  12%| | 1862/15000 [11:46<40:46,  5.37it/s, lr=9.98e-6, step_loss=0.0534]07/18/2023 19:15:09 - INFO - __main__ - train loss is 2.9828129960224032\n",
      "Steps:  12%| | 1863/15000 [11:47<40:13,  5.44it/s, lr=9.98e-6, step_loss=0.0306]07/18/2023 19:15:09 - INFO - __main__ - train loss is 2.98444787831977\n",
      "Steps:  12%| | 1864/15000 [11:47<39:52,  5.49it/s, lr=9.98e-6, step_loss=0.0016307/18/2023 19:15:09 - INFO - __main__ - train loss is 3.3580628451891243\n",
      "Steps:  12%|▏ | 1865/15000 [11:47<39:36,  5.53it/s, lr=9.98e-6, step_loss=0.374]07/18/2023 19:15:09 - INFO - __main__ - train loss is 3.467104454059154\n",
      "Steps:  12%|▏ | 1866/15000 [11:47<39:31,  5.54it/s, lr=9.98e-6, step_loss=0.109]07/18/2023 19:15:09 - INFO - __main__ - train loss is 3.4802120528183877\n",
      "Steps:  12%| | 1867/15000 [11:47<39:27,  5.55it/s, lr=9.98e-6, step_loss=0.0131]07/18/2023 19:15:10 - INFO - __main__ - train loss is 3.545673137065023\n",
      "Steps:  12%| | 1868/15000 [11:48<39:19,  5.57it/s, lr=9.98e-6, step_loss=0.0655]07/18/2023 19:15:10 - INFO - __main__ - train loss is 3.612924826797098\n",
      "Steps:  12%| | 1869/15000 [11:48<39:14,  5.58it/s, lr=9.98e-6, step_loss=0.0673]07/18/2023 19:15:10 - INFO - __main__ - train loss is 3.6463730200193822\n",
      "Steps:  12%| | 1870/15000 [11:48<39:10,  5.59it/s, lr=9.98e-6, step_loss=0.0334]07/18/2023 19:15:10 - INFO - __main__ - train loss is 3.79506623884663\n",
      "Steps:  12%|▏ | 1871/15000 [11:48<39:11,  5.58it/s, lr=9.98e-6, step_loss=0.149]07/18/2023 19:15:10 - INFO - __main__ - train loss is 3.7980551621876657\n",
      "Steps:  12%| | 1872/15000 [11:48<39:28,  5.54it/s, lr=9.98e-6, step_loss=0.0029907/18/2023 19:15:11 - INFO - __main__ - train loss is 3.8369037485681474\n",
      "Steps:  12%| | 1873/15000 [11:48<39:20,  5.56it/s, lr=9.98e-6, step_loss=0.0388]07/18/2023 19:15:11 - INFO - __main__ - train loss is 3.953469132538885\n",
      "Steps:  12%|▏ | 1874/15000 [11:49<39:18,  5.57it/s, lr=9.98e-6, step_loss=0.117]07/18/2023 19:15:11 - INFO - __main__ - train loss is 3.9566403017379344\n",
      "Steps:  12%|▏| 1875/15000 [11:49<39:12,  5.58it/s, lr=9.98e-6, step_loss=0.0031707/18/2023 19:15:11 - INFO - __main__ - train loss is 4.029968528542668\n",
      "Steps:  13%|▏| 1876/15000 [11:49<39:17,  5.57it/s, lr=9.98e-6, step_loss=0.0733]07/18/2023 19:15:11 - INFO - __main__ - train loss is 4.467754481825978\n",
      "Steps:  13%|▎ | 1877/15000 [11:49<39:11,  5.58it/s, lr=9.98e-6, step_loss=0.438]07/18/2023 19:15:11 - INFO - __main__ - train loss is 4.508291101548821\n",
      "Steps:  13%|▏| 1878/15000 [11:49<39:07,  5.59it/s, lr=9.98e-6, step_loss=0.0405]07/18/2023 19:15:12 - INFO - __main__ - train loss is 4.526463496033102\n",
      "Steps:  13%|▏| 1879/15000 [11:50<39:02,  5.60it/s, lr=9.98e-6, step_loss=0.0182]07/18/2023 19:15:12 - INFO - __main__ - train loss is 4.531535033136606\n",
      "Steps:  13%|▏| 1880/15000 [11:50<39:01,  5.60it/s, lr=9.98e-6, step_loss=0.0050707/18/2023 19:15:12 - INFO - __main__ - train loss is 4.681596163660288\n",
      "Steps:  13%|▍  | 1881/15000 [11:50<38:59,  5.61it/s, lr=9.98e-6, step_loss=0.15]07/18/2023 19:15:12 - INFO - __main__ - train loss is 4.69686687272042\n",
      "Steps:  13%|▏| 1882/15000 [11:50<38:56,  5.61it/s, lr=9.98e-6, step_loss=0.0153]07/18/2023 19:15:12 - INFO - __main__ - train loss is 4.77480227034539\n",
      "Steps:  13%|▏| 1883/15000 [11:50<38:56,  5.61it/s, lr=9.98e-6, step_loss=0.0779]07/18/2023 19:15:13 - INFO - __main__ - train loss is 4.8673560647293925\n",
      "Steps:  13%|▏| 1884/15000 [11:50<39:01,  5.60it/s, lr=9.98e-6, step_loss=0.0926]07/18/2023 19:15:13 - INFO - __main__ - train loss is 4.872042438015342\n",
      "Steps:  13%|▏| 1885/15000 [11:51<39:00,  5.60it/s, lr=9.98e-6, step_loss=0.0046907/18/2023 19:15:13 - INFO - __main__ - train loss is 4.8838312635198236\n",
      "Steps:  13%|▏| 1886/15000 [11:51<38:59,  5.61it/s, lr=9.98e-6, step_loss=0.0118]07/18/2023 19:15:13 - INFO - __main__ - train loss is 4.886457893997431\n",
      "Steps:  13%|▏| 1887/15000 [11:51<39:02,  5.60it/s, lr=9.98e-6, step_loss=0.0026307/18/2023 19:15:13 - INFO - __main__ - train loss is 5.269943509250879\n",
      "Steps:  13%|▎ | 1888/15000 [11:51<39:01,  5.60it/s, lr=9.98e-6, step_loss=0.383]07/18/2023 19:15:13 - INFO - __main__ - train loss is 5.2718074421864\n",
      "Steps:  13%|▏| 1889/15000 [11:51<38:59,  5.60it/s, lr=9.98e-6, step_loss=0.0018607/18/2023 19:15:14 - INFO - __main__ - train loss is 5.324434014735743\n",
      "Steps:  13%|▏| 1890/15000 [11:51<39:25,  5.54it/s, lr=9.98e-6, step_loss=0.0526]07/18/2023 19:15:14 - INFO - __main__ - train loss is 5.457508655963466\n",
      "Steps:  13%|▎ | 1891/15000 [11:52<39:17,  5.56it/s, lr=9.98e-6, step_loss=0.133]07/18/2023 19:15:14 - INFO - __main__ - train loss is 5.462236758554354\n",
      "Steps:  13%|▏| 1892/15000 [11:52<39:10,  5.58it/s, lr=9.98e-6, step_loss=0.0047307/18/2023 19:15:14 - INFO - __main__ - train loss is 5.902989235008135\n",
      "Steps:  13%|▎ | 1893/15000 [11:52<39:05,  5.59it/s, lr=9.98e-6, step_loss=0.441]07/18/2023 19:15:14 - INFO - __main__ - train loss is 5.949871354037896\n",
      "Steps:  13%|▏| 1894/15000 [11:52<39:08,  5.58it/s, lr=9.98e-6, step_loss=0.0469]07/18/2023 19:15:15 - INFO - __main__ - train loss is 6.1090097355190665\n",
      "Steps:  13%|▎ | 1895/15000 [11:52<39:24,  5.54it/s, lr=9.98e-6, step_loss=0.159]07/18/2023 19:15:15 - INFO - __main__ - train loss is 6.133856140309945\n",
      "Steps:  13%|▏| 1896/15000 [11:53<39:15,  5.56it/s, lr=9.98e-6, step_loss=0.0248]07/18/2023 19:15:15 - INFO - __main__ - train loss is 6.365543060237542\n",
      "Steps:  13%|▎ | 1897/15000 [11:53<39:34,  5.52it/s, lr=9.98e-6, step_loss=0.232]07/18/2023 19:15:15 - INFO - __main__ - train loss is 6.398803964490071\n",
      "Steps:  13%|▏| 1898/15000 [11:53<39:22,  5.55it/s, lr=9.98e-6, step_loss=0.0333]07/18/2023 19:15:15 - INFO - __main__ - train loss is 7.112354055279866\n",
      "Steps:  13%|▎ | 1899/15000 [11:53<39:13,  5.57it/s, lr=9.98e-6, step_loss=0.714]07/18/2023 19:15:15 - INFO - __main__ - train loss is 7.5746628197375685\n",
      "Steps:  13%|▎ | 1900/15000 [11:53<39:23,  5.54it/s, lr=9.98e-6, step_loss=0.462]07/18/2023 19:15:16 - INFO - __main__ - train loss is 7.654420919949189\n",
      "Steps:  13%|▏| 1901/15000 [11:53<39:40,  5.50it/s, lr=9.98e-6, step_loss=0.0798]07/18/2023 19:15:16 - INFO - __main__ - train loss is 7.981542714172974\n",
      "Steps:  13%|▎ | 1902/15000 [11:54<39:53,  5.47it/s, lr=9.98e-6, step_loss=0.327]07/18/2023 19:15:16 - INFO - __main__ - train loss is 7.983540569897741\n",
      "Steps:  13%|▎ | 1903/15000 [11:54<39:37,  5.51it/s, lr=9.98e-6, step_loss=0.002]07/18/2023 19:15:16 - INFO - __main__ - train loss is 7.987107190536335\n",
      "Steps:  13%|▏| 1904/15000 [11:54<39:39,  5.50it/s, lr=9.98e-6, step_loss=0.0035707/18/2023 19:15:16 - INFO - __main__ - train loss is 8.273603889392689\n",
      "Steps:  13%|▎ | 1905/15000 [11:54<39:49,  5.48it/s, lr=9.98e-6, step_loss=0.286]07/18/2023 19:15:16 - INFO - __main__ - train loss is 8.315798278199509\n",
      "Steps:  13%|▏| 1906/15000 [11:54<39:32,  5.52it/s, lr=9.98e-6, step_loss=0.0422]07/18/2023 19:15:17 - INFO - __main__ - train loss is 8.404948021518067\n",
      "Steps:  13%|▏| 1907/15000 [11:55<39:42,  5.49it/s, lr=9.98e-6, step_loss=0.0891]07/18/2023 19:15:17 - INFO - __main__ - train loss is 8.637308056699112\n",
      "Steps:  13%|▎ | 1908/15000 [11:55<39:35,  5.51it/s, lr=9.98e-6, step_loss=0.232]07/18/2023 19:15:17 - INFO - __main__ - train loss is 8.729286308633164\n",
      "Steps:  13%|▎ | 1909/15000 [11:55<39:22,  5.54it/s, lr=9.98e-6, step_loss=0.092]07/18/2023 19:15:17 - INFO - __main__ - train loss is 9.003626282559708\n",
      "Steps:  13%|▎ | 1910/15000 [11:55<39:13,  5.56it/s, lr=9.98e-6, step_loss=0.274]07/18/2023 19:15:17 - INFO - __main__ - train loss is 9.010442897910252\n",
      "Steps:  13%|▏| 1911/15000 [11:55<39:11,  5.57it/s, lr=9.98e-6, step_loss=0.0068207/18/2023 19:15:18 - INFO - __main__ - train loss is 9.255023375386372\n",
      "Steps:  13%|▎ | 1912/15000 [11:55<39:27,  5.53it/s, lr=9.98e-6, step_loss=0.245]07/18/2023 19:15:18 - INFO - __main__ - train loss is 9.280338362092152\n",
      "Steps:  13%|▏| 1913/15000 [11:56<39:39,  5.50it/s, lr=9.98e-6, step_loss=0.0253]07/18/2023 19:15:18 - INFO - __main__ - train loss is 9.686716690892354\n",
      "Steps:  13%|▎ | 1914/15000 [11:56<39:52,  5.47it/s, lr=9.98e-6, step_loss=0.406]07/18/2023 19:15:18 - INFO - __main__ - train loss is 9.869169056648389\n",
      "Steps:  13%|▎ | 1915/15000 [11:56<39:41,  5.50it/s, lr=9.98e-6, step_loss=0.182]07/18/2023 19:15:18 - INFO - __main__ - train loss is 9.885057959938422\n",
      "Steps:  13%|▏| 1916/15000 [11:56<39:27,  5.53it/s, lr=9.98e-6, step_loss=0.0159]07/18/2023 19:15:18 - INFO - __main__ - train loss is 10.155903104925528\n",
      "Steps:  13%|▎ | 1917/15000 [11:56<39:17,  5.55it/s, lr=9.98e-6, step_loss=0.271]07/18/2023 19:15:19 - INFO - __main__ - train loss is 10.235630925977603\n",
      "Steps:  13%|▏| 1918/15000 [11:57<39:38,  5.50it/s, lr=9.98e-6, step_loss=0.0797]07/18/2023 19:15:19 - INFO - __main__ - train loss is 10.365092169726267\n",
      "Steps:  13%|▎ | 1919/15000 [11:57<39:34,  5.51it/s, lr=9.98e-6, step_loss=0.129]07/18/2023 19:15:19 - INFO - __main__ - train loss is 10.392351715127006\n",
      "Steps:  13%|▏| 1920/15000 [11:57<39:23,  5.53it/s, lr=9.98e-6, step_loss=0.0273]07/18/2023 19:15:19 - INFO - __main__ - train loss is 10.42762647406198\n",
      "Steps:  13%|▏| 1921/15000 [11:57<39:24,  5.53it/s, lr=9.98e-6, step_loss=0.0353]07/18/2023 19:15:19 - INFO - __main__ - train loss is 10.69612361327745\n",
      "Steps:  13%|▎ | 1922/15000 [11:57<39:19,  5.54it/s, lr=9.97e-6, step_loss=0.268]07/18/2023 19:15:20 - INFO - __main__ - train loss is 10.778908340493217\n",
      "Steps:  13%|▏| 1923/15000 [11:57<39:11,  5.56it/s, lr=9.97e-6, step_loss=0.0828]07/18/2023 19:15:20 - INFO - __main__ - train loss is 10.861832840600982\n",
      "Steps:  13%|▏| 1924/15000 [11:58<39:03,  5.58it/s, lr=9.97e-6, step_loss=0.0829]07/18/2023 19:15:20 - INFO - __main__ - train loss is 10.91755677596666\n",
      "Steps:  13%|▏| 1925/15000 [11:58<39:24,  5.53it/s, lr=9.97e-6, step_loss=0.0557]07/18/2023 19:15:20 - INFO - __main__ - train loss is 10.94842941337265\n",
      "Steps:  13%|▏| 1926/15000 [11:58<39:22,  5.53it/s, lr=9.97e-6, step_loss=0.0309]07/18/2023 19:15:20 - INFO - __main__ - train loss is 11.042823747033253\n",
      "Steps:  13%|▏| 1927/15000 [11:58<39:18,  5.54it/s, lr=9.97e-6, step_loss=0.0944]07/18/2023 19:15:20 - INFO - __main__ - train loss is 11.161083363229409\n",
      "Steps:  13%|▎ | 1928/15000 [11:58<39:22,  5.53it/s, lr=9.97e-6, step_loss=0.118]07/18/2023 19:15:21 - INFO - __main__ - train loss is 11.19711408787407\n",
      "Steps:  13%|▎ | 1929/15000 [11:59<39:17,  5.54it/s, lr=9.97e-6, step_loss=0.036]07/18/2023 19:15:21 - INFO - __main__ - train loss is 11.376466728979722\n",
      "Steps:  13%|▎ | 1930/15000 [11:59<39:12,  5.56it/s, lr=9.97e-6, step_loss=0.179]07/18/2023 19:15:21 - INFO - __main__ - train loss is 11.64957106881775\n",
      "Steps:  13%|▎ | 1931/15000 [11:59<39:05,  5.57it/s, lr=9.97e-6, step_loss=0.273]07/18/2023 19:15:21 - INFO - __main__ - train loss is 11.846335031324998\n",
      "Steps:  13%|▎ | 1932/15000 [11:59<39:25,  5.52it/s, lr=9.97e-6, step_loss=0.197]07/18/2023 19:15:21 - INFO - __main__ - train loss is 12.1491398292128\n",
      "Steps:  13%|▎ | 1933/15000 [11:59<39:43,  5.48it/s, lr=9.97e-6, step_loss=0.303]07/18/2023 19:15:22 - INFO - __main__ - train loss is 12.219575807685032\n",
      "Steps:  13%|▏| 1934/15000 [11:59<39:54,  5.46it/s, lr=9.97e-6, step_loss=0.0704]07/18/2023 19:15:22 - INFO - __main__ - train loss is 12.322124928468838\n",
      "Steps:  13%|▎ | 1935/15000 [12:00<39:37,  5.49it/s, lr=9.97e-6, step_loss=0.103]07/18/2023 19:15:22 - INFO - __main__ - train loss is 12.338103860849515\n",
      "Steps:  13%|▎ | 1936/15000 [12:00<39:21,  5.53it/s, lr=9.97e-6, step_loss=0.016]07/18/2023 19:15:22 - INFO - __main__ - train loss is 12.33984127943404\n",
      "Steps:  13%|▏| 1937/15000 [12:00<39:09,  5.56it/s, lr=9.97e-6, step_loss=0.0017407/18/2023 19:15:22 - INFO - __main__ - train loss is 12.507485452340916\n",
      "Steps:  13%|▎ | 1938/15000 [12:00<39:00,  5.58it/s, lr=9.97e-6, step_loss=0.168]07/18/2023 19:15:22 - INFO - __main__ - train loss is 12.519161471398547\n",
      "Steps:  13%|▏| 1939/15000 [12:00<39:15,  5.54it/s, lr=9.97e-6, step_loss=0.0117]07/18/2023 19:15:23 - INFO - __main__ - train loss is 12.641615689964965\n",
      "Steps:  13%|▎ | 1940/15000 [12:01<52:39,  4.13it/s, lr=9.97e-6, step_loss=0.122]07/18/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.1483776867389679\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.1483776867389679\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.45081424713134766\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.5991919338703156\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.14441615343093872\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.7436080873012543\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.0016426334623247385\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.745250720763579\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.08669564872980118\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.8319463694933802\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Per validation step average loss is 0.062020182609558105\n",
      "07/18/2023 19:15:24 - INFO - __main__ - Cumulative validation average loss is 0.8939665521029383\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.23944997787475586\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 1.1334165299776942\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.00359138660132885\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 1.137007916579023\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.0020466968417167664\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 1.1390546134207398\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.0676608681678772\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 1.206715481588617\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.008487021550536156\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 1.2152025031391531\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Per validation step average loss is 0.003191302064806223\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Cumulative validation average loss is 1.2183938052039593\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Average validation loss for Epoch 19 is 0.10153281710032995\n",
      "07/18/2023 19:15:25 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:15:38 - INFO - __main__ - Starting epoch 20\n",
      "07/18/2023 19:15:39 - INFO - __main__ - train loss is 0.2414752095937729\n",
      "Steps:  13%|▏| 1941/15000 [12:17<18:14:43,  5.03s/it, lr=9.97e-6, step_loss=0.2407/18/2023 19:15:40 - INFO - __main__ - train loss is 0.6485738605260849\n",
      "Steps:  13%|▏| 1942/15000 [12:17<13:21:49,  3.68s/it, lr=9.97e-6, step_loss=0.4007/18/2023 19:15:40 - INFO - __main__ - train loss is 0.7572840303182602\n",
      "Steps:  13%|▏| 1943/15000 [12:18<9:56:35,  2.74s/it, lr=9.97e-6, step_loss=0.10907/18/2023 19:15:41 - INFO - __main__ - train loss is 0.9980849474668503\n",
      "Steps:  13%|▏| 1944/15000 [12:19<7:32:49,  2.08s/it, lr=9.97e-6, step_loss=0.24107/18/2023 19:15:41 - INFO - __main__ - train loss is 1.111810103058815\n",
      "Steps:  13%|▏| 1945/15000 [12:19<5:52:38,  1.62s/it, lr=9.97e-6, step_loss=0.11407/18/2023 19:15:42 - INFO - __main__ - train loss is 1.2054544240236282\n",
      "Steps:  13%|▏| 1946/15000 [12:20<4:42:08,  1.30s/it, lr=9.97e-6, step_loss=0.09307/18/2023 19:15:42 - INFO - __main__ - train loss is 1.2759861648082733\n",
      "Steps:  13%|▏| 1947/15000 [12:20<3:52:48,  1.07s/it, lr=9.97e-6, step_loss=0.07007/18/2023 19:15:43 - INFO - __main__ - train loss is 1.3027847930788994\n",
      "Steps:  13%|▏| 1948/15000 [12:21<3:18:37,  1.10it/s, lr=9.97e-6, step_loss=0.02607/18/2023 19:15:43 - INFO - __main__ - train loss is 1.4039959087967873\n",
      "Steps:  13%|▏| 1949/15000 [12:21<2:55:45,  1.24it/s, lr=9.97e-6, step_loss=0.10107/18/2023 19:15:44 - INFO - __main__ - train loss is 1.4106264365836978\n",
      "Steps:  13%|▏| 1950/15000 [12:22<2:38:59,  1.37it/s, lr=9.97e-6, step_loss=0.00607/18/2023 19:15:45 - INFO - __main__ - train loss is 1.4156459411606193\n",
      "Steps:  13%|▏| 1951/15000 [12:22<2:26:57,  1.48it/s, lr=9.97e-6, step_loss=0.00507/18/2023 19:15:45 - INFO - __main__ - train loss is 1.4176895704586059\n",
      "Steps:  13%|▏| 1952/15000 [12:23<2:18:58,  1.56it/s, lr=9.97e-6, step_loss=0.00207/18/2023 19:15:46 - INFO - __main__ - train loss is 1.5190837841946632\n",
      "Steps:  13%|▏| 1953/15000 [12:23<2:12:28,  1.64it/s, lr=9.97e-6, step_loss=0.10107/18/2023 19:15:46 - INFO - __main__ - train loss is 2.263880417915061\n",
      "Steps:  13%|▏| 1954/15000 [12:24<2:09:38,  1.68it/s, lr=9.97e-6, step_loss=0.74507/18/2023 19:15:47 - INFO - __main__ - train loss is 2.6245972376782447\n",
      "Steps:  13%|▏| 1955/15000 [12:25<2:08:26,  1.69it/s, lr=9.97e-6, step_loss=0.36107/18/2023 19:15:47 - INFO - __main__ - train loss is 2.6938182797748595\n",
      "Steps:  13%|▏| 1956/15000 [12:25<2:04:44,  1.74it/s, lr=9.97e-6, step_loss=0.06907/18/2023 19:15:48 - INFO - __main__ - train loss is 2.9043814328033477\n",
      "Steps:  13%|▏| 1957/15000 [12:26<2:02:57,  1.77it/s, lr=9.97e-6, step_loss=0.21107/18/2023 19:15:48 - INFO - __main__ - train loss is 2.996285953791812\n",
      "Steps:  13%|▏| 1958/15000 [12:26<2:01:17,  1.79it/s, lr=9.97e-6, step_loss=0.09107/18/2023 19:15:49 - INFO - __main__ - train loss is 3.0726161759812385\n",
      "Steps:  13%|▏| 1959/15000 [12:27<2:00:10,  1.81it/s, lr=9.97e-6, step_loss=0.07607/18/2023 19:15:49 - INFO - __main__ - train loss is 3.453618035884574\n",
      "Steps:  13%|▏| 1960/15000 [12:27<1:59:32,  1.82it/s, lr=9.97e-6, step_loss=0.38107/18/2023 19:15:50 - INFO - __main__ - train loss is 3.4605630866717547\n",
      "Steps:  13%|▏| 1961/15000 [12:28<1:59:09,  1.82it/s, lr=9.97e-6, step_loss=0.00607/18/2023 19:15:51 - INFO - __main__ - train loss is 3.931728684110567\n",
      "Steps:  13%|▏| 1962/15000 [12:28<1:59:06,  1.82it/s, lr=9.97e-6, step_loss=0.47107/18/2023 19:15:51 - INFO - __main__ - train loss is 3.9538549974095076\n",
      "Steps:  13%|▏| 1963/15000 [12:29<1:59:05,  1.82it/s, lr=9.97e-6, step_loss=0.02207/18/2023 19:15:52 - INFO - __main__ - train loss is 4.0328412025701255\n",
      "Steps:  13%|▏| 1964/15000 [12:30<1:58:43,  1.83it/s, lr=9.97e-6, step_loss=0.07907/18/2023 19:15:52 - INFO - __main__ - train loss is 4.096473288489506\n",
      "Steps:  13%|▏| 1965/15000 [12:30<1:58:28,  1.83it/s, lr=9.97e-6, step_loss=0.06307/18/2023 19:15:53 - INFO - __main__ - train loss is 4.451735389186069\n",
      "Steps:  13%|▏| 1966/15000 [12:31<1:58:00,  1.84it/s, lr=9.97e-6, step_loss=0.35507/18/2023 19:15:53 - INFO - __main__ - train loss is 4.486046475125477\n",
      "Steps:  13%|▏| 1967/15000 [12:31<1:58:20,  1.84it/s, lr=9.97e-6, step_loss=0.03407/18/2023 19:15:54 - INFO - __main__ - train loss is 5.362529200268909\n",
      "Steps:  13%|▏| 1968/15000 [12:32<1:58:14,  1.84it/s, lr=9.97e-6, step_loss=0.87607/18/2023 19:15:54 - INFO - __main__ - train loss is 5.368299511494115\n",
      "Steps:  13%|▏| 1969/15000 [12:32<2:01:49,  1.78it/s, lr=9.97e-6, step_loss=0.00507/18/2023 19:15:55 - INFO - __main__ - train loss is 5.394291767152026\n",
      "Steps:  13%|▏| 1970/15000 [12:33<2:04:19,  1.75it/s, lr=9.97e-6, step_loss=0.02607/18/2023 19:15:56 - INFO - __main__ - train loss is 5.952715167077258\n",
      "Steps:  13%|▏| 1971/15000 [12:33<2:02:24,  1.77it/s, lr=9.97e-6, step_loss=0.55807/18/2023 19:15:56 - INFO - __main__ - train loss is 6.351733782561496\n",
      "Steps:  13%|▏| 1972/15000 [12:34<2:01:13,  1.79it/s, lr=9.97e-6, step_loss=0.39907/18/2023 19:15:57 - INFO - __main__ - train loss is 6.52190234628506\n",
      "Steps:  13%|▏| 1973/15000 [12:35<2:00:23,  1.80it/s, lr=9.97e-6, step_loss=0.17]07/18/2023 19:15:57 - INFO - __main__ - train loss is 6.591711932094768\n",
      "Steps:  13%|▏| 1974/15000 [12:35<2:00:08,  1.81it/s, lr=9.97e-6, step_loss=0.06907/18/2023 19:15:58 - INFO - __main__ - train loss is 6.597043491201475\n",
      "Steps:  13%|▏| 1975/15000 [12:36<1:59:27,  1.82it/s, lr=9.97e-6, step_loss=0.00507/18/2023 19:15:58 - INFO - __main__ - train loss is 6.880247391061857\n",
      "Steps:  13%|▏| 1976/15000 [12:36<1:58:29,  1.83it/s, lr=9.97e-6, step_loss=0.28307/18/2023 19:15:59 - INFO - __main__ - train loss is 6.887604136718437\n",
      "Steps:  13%|▏| 1977/15000 [12:37<1:58:16,  1.84it/s, lr=9.97e-6, step_loss=0.00707/18/2023 19:15:59 - INFO - __main__ - train loss is 6.8973824789281934\n",
      "Steps:  13%|▏| 1978/15000 [12:37<1:57:50,  1.84it/s, lr=9.97e-6, step_loss=0.00907/18/2023 19:16:00 - INFO - __main__ - train loss is 6.997198495781049\n",
      "Steps:  13%|▏| 1979/15000 [12:38<1:57:40,  1.84it/s, lr=9.97e-6, step_loss=0.09907/18/2023 19:16:00 - INFO - __main__ - train loss is 7.109677675878629\n",
      "Steps:  13%|▏| 1980/15000 [12:38<1:58:01,  1.84it/s, lr=9.97e-6, step_loss=0.11207/18/2023 19:16:01 - INFO - __main__ - train loss is 7.12845168239437\n",
      "Steps:  13%|▏| 1981/15000 [12:39<1:57:59,  1.84it/s, lr=9.97e-6, step_loss=0.01807/18/2023 19:16:02 - INFO - __main__ - train loss is 7.19819638854824\n",
      "Steps:  13%|▏| 1982/15000 [12:39<1:57:36,  1.84it/s, lr=9.97e-6, step_loss=0.06907/18/2023 19:16:02 - INFO - __main__ - train loss is 7.23584260023199\n",
      "Steps:  13%|▏| 1983/15000 [12:40<1:57:42,  1.84it/s, lr=9.97e-6, step_loss=0.03707/18/2023 19:16:03 - INFO - __main__ - train loss is 7.643877163296565\n",
      "Steps:  13%|▏| 1984/15000 [12:41<1:58:01,  1.84it/s, lr=9.97e-6, step_loss=0.40807/18/2023 19:16:03 - INFO - __main__ - train loss is 7.8146963564213365\n",
      "Steps:  13%|▏| 1985/15000 [12:41<1:59:13,  1.82it/s, lr=9.97e-6, step_loss=0.17107/18/2023 19:16:04 - INFO - __main__ - train loss is 8.211003556614742\n",
      "Steps:  13%|▏| 1986/15000 [12:42<2:01:55,  1.78it/s, lr=9.97e-6, step_loss=0.39607/18/2023 19:16:04 - INFO - __main__ - train loss is 8.258565246826038\n",
      "Steps:  13%|▏| 1987/15000 [12:42<2:00:47,  1.80it/s, lr=9.97e-6, step_loss=0.04707/18/2023 19:16:05 - INFO - __main__ - train loss is 8.442148715024814\n",
      "Steps:  13%|▏| 1988/15000 [12:43<1:59:56,  1.81it/s, lr=9.97e-6, step_loss=0.18407/18/2023 19:16:05 - INFO - __main__ - train loss is 8.955502658849582\n",
      "Steps:  13%|▏| 1989/15000 [12:43<1:59:05,  1.82it/s, lr=9.97e-6, step_loss=0.51307/18/2023 19:16:06 - INFO - __main__ - train loss is 9.174697637325153\n",
      "Steps:  13%|▏| 1990/15000 [12:44<1:58:24,  1.83it/s, lr=9.97e-6, step_loss=0.21907/18/2023 19:16:06 - INFO - __main__ - train loss is 9.184400537749752\n",
      "Steps:  13%|▏| 1991/15000 [12:44<1:58:23,  1.83it/s, lr=9.97e-6, step_loss=0.00907/18/2023 19:16:07 - INFO - __main__ - train loss is 9.277048798045143\n",
      "Steps:  13%|▏| 1992/15000 [12:45<1:57:56,  1.84it/s, lr=9.97e-6, step_loss=0.09207/18/2023 19:16:08 - INFO - __main__ - train loss is 9.284685712074861\n",
      "Steps:  13%|▏| 1993/15000 [12:45<1:58:06,  1.84it/s, lr=9.97e-6, step_loss=0.00707/18/2023 19:16:08 - INFO - __main__ - train loss is 9.313477786025032\n",
      "Steps:  13%|▏| 1994/15000 [12:46<1:57:45,  1.84it/s, lr=9.97e-6, step_loss=0.02807/18/2023 19:16:09 - INFO - __main__ - train loss is 9.55513553484343\n",
      "Steps:  13%|▏| 1995/15000 [12:47<1:58:19,  1.83it/s, lr=9.97e-6, step_loss=0.24207/18/2023 19:16:09 - INFO - __main__ - train loss is 9.585271948715672\n",
      "Steps:  13%|▏| 1996/15000 [12:47<1:58:17,  1.83it/s, lr=9.97e-6, step_loss=0.03007/18/2023 19:16:10 - INFO - __main__ - train loss is 9.92566435947083\n",
      "Steps:  13%|▏| 1997/15000 [12:48<1:58:09,  1.83it/s, lr=9.97e-6, step_loss=0.34]07/18/2023 19:16:10 - INFO - __main__ - train loss is 10.060517066856846\n",
      "Steps:  13%|▏| 1998/15000 [12:48<1:57:47,  1.84it/s, lr=9.97e-6, step_loss=0.13507/18/2023 19:16:11 - INFO - __main__ - train loss is 10.290342921158299\n",
      "Steps:  13%|▏| 1999/15000 [12:49<1:57:36,  1.84it/s, lr=9.97e-6, step_loss=0.23]07/18/2023 19:16:11 - INFO - __main__ - train loss is 10.324875456979498\n",
      "Steps:  13%|▏| 2000/15000 [12:49<1:57:26,  1.84it/s, lr=9.97e-6, step_loss=0.23]07/18/2023 19:16:11 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-2000\n",
      "07/18/2023 19:16:11 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:16:11,962] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:16:11,966] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:16:11,966] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:16:11,974] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:16:11,974] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:16:11,998] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:16:11,999] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:16:11,999] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:16:11 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-2000/pytorch_model\n",
      "07/18/2023 19:16:11 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-2000/scheduler.bin\n",
      "07/18/2023 19:16:12 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-2000/random_states_0.pkl\n",
      "07/18/2023 19:16:12 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-2000\n",
      "Steps:  13%|▏| 2000/15000 [12:49<1:57:26,  1.84it/s, lr=9.97e-6, step_loss=0.03407/18/2023 19:16:12 - INFO - __main__ - train loss is 10.456572932889685\n",
      "Steps:  13%|▏| 2001/15000 [12:50<2:00:06,  1.80it/s, lr=9.97e-6, step_loss=0.13207/18/2023 19:16:13 - INFO - __main__ - train loss is 10.489249100675806\n",
      "Steps:  13%|▏| 2002/15000 [12:50<2:03:35,  1.75it/s, lr=9.97e-6, step_loss=0.03207/18/2023 19:16:13 - INFO - __main__ - train loss is 10.523262114962563\n",
      "Steps:  13%|▏| 2003/15000 [12:51<2:02:36,  1.77it/s, lr=9.97e-6, step_loss=0.03407/18/2023 19:16:14 - INFO - __main__ - train loss is 10.53542876872234\n",
      "Steps:  13%|▏| 2004/15000 [12:52<2:00:49,  1.79it/s, lr=9.97e-6, step_loss=0.01207/18/2023 19:16:14 - INFO - __main__ - train loss is 10.64131414028816\n",
      "Steps:  13%|▏| 2005/15000 [12:52<1:59:56,  1.81it/s, lr=9.97e-6, step_loss=0.10607/18/2023 19:16:15 - INFO - __main__ - train loss is 10.721405460266396\n",
      "Steps:  13%|▏| 2006/15000 [12:53<1:59:16,  1.82it/s, lr=9.97e-6, step_loss=0.08007/18/2023 19:16:15 - INFO - __main__ - train loss is 10.771647761343047\n",
      "Steps:  13%|▏| 2007/15000 [12:53<1:59:47,  1.81it/s, lr=9.97e-6, step_loss=0.05007/18/2023 19:16:16 - INFO - __main__ - train loss is 10.824608302442357\n",
      "Steps:  13%|▏| 2008/15000 [12:54<1:58:44,  1.82it/s, lr=9.97e-6, step_loss=0.05307/18/2023 19:16:16 - INFO - __main__ - train loss is 10.826304728165269\n",
      "Steps:  13%|▏| 2009/15000 [12:54<1:58:19,  1.83it/s, lr=9.97e-6, step_loss=0.00107/18/2023 19:16:17 - INFO - __main__ - train loss is 10.892260225489736\n",
      "Steps:  13%|▏| 2010/15000 [12:55<1:57:45,  1.84it/s, lr=9.97e-6, step_loss=0.06607/18/2023 19:16:17 - INFO - __main__ - train loss is 10.89691072423011\n",
      "Steps:  13%|▏| 2011/15000 [12:55<1:57:30,  1.84it/s, lr=9.97e-6, step_loss=0.00407/18/2023 19:16:18 - INFO - __main__ - train loss is 10.90468167560175\n",
      "Steps:  13%|▏| 2012/15000 [12:56<1:57:53,  1.84it/s, lr=9.97e-6, step_loss=0.00707/18/2023 19:16:19 - INFO - __main__ - train loss is 10.91456325026229\n",
      "Steps:  13%|▏| 2013/15000 [12:56<1:57:54,  1.84it/s, lr=9.97e-6, step_loss=0.00907/18/2023 19:16:19 - INFO - __main__ - train loss is 10.940239716786891\n",
      "Steps:  13%|▏| 2014/15000 [12:57<1:57:54,  1.84it/s, lr=9.97e-6, step_loss=0.02507/18/2023 19:16:20 - INFO - __main__ - train loss is 10.94927527429536\n",
      "Steps:  13%|▏| 2015/15000 [12:58<1:57:54,  1.84it/s, lr=9.97e-6, step_loss=0.00907/18/2023 19:16:20 - INFO - __main__ - train loss is 11.135351140517741\n",
      "Steps:  13%|▏| 2016/15000 [12:58<1:57:31,  1.84it/s, lr=9.97e-6, step_loss=0.18607/18/2023 19:16:21 - INFO - __main__ - train loss is 11.141629613470286\n",
      "Steps:  13%|▏| 2017/15000 [12:59<1:57:32,  1.84it/s, lr=9.97e-6, step_loss=0.00607/18/2023 19:16:21 - INFO - __main__ - train loss is 11.264079026412219\n",
      "Steps:  13%|▏| 2018/15000 [12:59<1:58:53,  1.82it/s, lr=9.97e-6, step_loss=0.12207/18/2023 19:16:22 - INFO - __main__ - train loss is 11.29656846402213\n",
      "Steps:  13%|▏| 2019/15000 [13:00<2:00:19,  1.80it/s, lr=9.97e-6, step_loss=0.03207/18/2023 19:16:22 - INFO - __main__ - train loss is 11.340712889563292\n",
      "Steps:  13%|▏| 2020/15000 [13:00<1:59:45,  1.81it/s, lr=9.97e-6, step_loss=0.04407/18/2023 19:16:23 - INFO - __main__ - train loss is 11.587830081116408\n",
      "Steps:  13%|▏| 2021/15000 [13:01<1:58:59,  1.82it/s, lr=9.97e-6, step_loss=0.24707/18/2023 19:16:24 - INFO - __main__ - train loss is 11.592782112769783\n",
      "Steps:  13%|▏| 2022/15000 [13:01<1:58:51,  1.82it/s, lr=9.97e-6, step_loss=0.00407/18/2023 19:16:24 - INFO - __main__ - train loss is 11.595187846105546\n",
      "Steps:  13%|▏| 2023/15000 [13:02<1:58:22,  1.83it/s, lr=9.97e-6, step_loss=0.00207/18/2023 19:16:25 - INFO - __main__ - train loss is 11.614052744116634\n",
      "Steps:  13%|▏| 2024/15000 [13:02<1:58:47,  1.82it/s, lr=9.97e-6, step_loss=0.01807/18/2023 19:16:25 - INFO - __main__ - train loss is 11.616577068343759\n",
      "Steps:  14%|▏| 2025/15000 [13:03<1:58:08,  1.83it/s, lr=9.97e-6, step_loss=0.00207/18/2023 19:16:26 - INFO - __main__ - train loss is 11.6199744513724\n",
      "Steps:  14%|▏| 2026/15000 [13:04<1:57:47,  1.84it/s, lr=9.97e-6, step_loss=0.00307/18/2023 19:16:26 - INFO - __main__ - train loss is 11.621989943552762\n",
      "Steps:  14%|▏| 2027/15000 [13:04<1:57:24,  1.84it/s, lr=9.97e-6, step_loss=0.00207/18/2023 19:16:27 - INFO - __main__ - train loss is 11.6334368432872\n",
      "Steps:  14%|▏| 2028/15000 [13:05<1:57:49,  1.83it/s, lr=9.97e-6, step_loss=0.01107/18/2023 19:16:27 - INFO - __main__ - train loss is 11.812741443049163\n",
      "Steps:  14%|▏| 2029/15000 [13:05<1:58:03,  1.83it/s, lr=9.97e-6, step_loss=0.17907/18/2023 19:16:28 - INFO - __main__ - train loss is 11.871740046422929\n",
      "Steps:  14%|▏| 2030/15000 [13:06<1:58:14,  1.83it/s, lr=9.97e-6, step_loss=0.05907/18/2023 19:16:28 - INFO - __main__ - train loss is 11.938322957139462\n",
      "Steps:  14%|▏| 2031/15000 [13:06<1:58:15,  1.83it/s, lr=9.97e-6, step_loss=0.06607/18/2023 19:16:29 - INFO - __main__ - train loss is 12.710922237019986\n",
      "Steps:  14%|▏| 2032/15000 [13:07<1:58:09,  1.83it/s, lr=9.97e-6, step_loss=0.77307/18/2023 19:16:29 - INFO - __main__ - train loss is 13.017978067975491\n",
      "Steps:  14%|▏| 2033/15000 [13:07<1:57:22,  1.84it/s, lr=9.97e-6, step_loss=0.30707/18/2023 19:16:30 - INFO - __main__ - train loss is 13.688853796105832\n",
      "Steps:  14%|▏| 2034/15000 [13:08<1:57:21,  1.84it/s, lr=9.97e-6, step_loss=0.67107/18/2023 19:16:31 - INFO - __main__ - train loss is 13.692420352250338\n",
      "Steps:  14%|▏| 2035/15000 [13:08<1:57:03,  1.85it/s, lr=9.97e-6, step_loss=0.00307/18/2023 19:16:31 - INFO - __main__ - train loss is 13.750335685908794\n",
      "Steps:  14%|▏| 2036/15000 [13:09<1:58:49,  1.82it/s, lr=9.97e-6, step_loss=0.05707/18/2023 19:16:32 - INFO - __main__ - train loss is 13.773530282080173\n",
      "Steps:  14%|▏| 2037/15000 [13:10<2:15:27,  1.59it/s, lr=9.97e-6, step_loss=0.02307/18/2023 19:16:33 - INFO - __main__ - Per validation step average loss is 0.056873153895139694\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Cumulative validation average loss is 0.056873153895139694\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Per validation step average loss is 0.07469771802425385\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Cumulative validation average loss is 0.13157087191939354\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Per validation step average loss is 0.020584270358085632\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Cumulative validation average loss is 0.15215514227747917\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Per validation step average loss is 0.01957390271127224\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Cumulative validation average loss is 0.1717290449887514\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Per validation step average loss is 0.05821840837597847\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Cumulative validation average loss is 0.22994745336472988\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Per validation step average loss is 0.004867515526711941\n",
      "07/18/2023 19:16:33 - INFO - __main__ - Cumulative validation average loss is 0.23481496889144182\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Per validation step average loss is 0.004786019213497639\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Cumulative validation average loss is 0.23960098810493946\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Per validation step average loss is 0.17959457635879517\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Cumulative validation average loss is 0.4191955644637346\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Per validation step average loss is 0.021071476861834526\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Cumulative validation average loss is 0.44026704132556915\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Per validation step average loss is 0.03927195444703102\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Cumulative validation average loss is 0.4795389957726002\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Per validation step average loss is 0.0111344363540411\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Cumulative validation average loss is 0.4906734321266413\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Per validation step average loss is 0.7977970838546753\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Cumulative validation average loss is 1.2884705159813166\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Average validation loss for Epoch 20 is 0.10737254299844305\n",
      "07/18/2023 19:16:34 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:16:47 - INFO - __main__ - Starting epoch 21\n",
      "07/18/2023 19:16:48 - INFO - __main__ - train loss is 0.5219848155975342\n",
      "Steps:  14%|▏| 2038/15000 [13:25<18:29:27,  5.14s/it, lr=9.97e-6, step_loss=0.5207/18/2023 19:16:48 - INFO - __main__ - train loss is 0.5371271865442395\n",
      "Steps:  14%|▏| 2039/15000 [13:26<13:08:08,  3.65s/it, lr=9.97e-6, step_loss=0.0107/18/2023 19:16:48 - INFO - __main__ - train loss is 1.052564193494618\n",
      "Steps:  14%|▏| 2040/15000 [13:26<9:23:12,  2.61s/it, lr=9.97e-6, step_loss=0.51507/18/2023 19:16:48 - INFO - __main__ - train loss is 1.0952439242973924\n",
      "Steps:  14%|▏| 2041/15000 [13:26<6:45:46,  1.88s/it, lr=9.97e-6, step_loss=0.04207/18/2023 19:16:48 - INFO - __main__ - train loss is 1.2799338782206178\n",
      "Steps:  14%|▏| 2042/15000 [13:26<4:55:32,  1.37s/it, lr=9.97e-6, step_loss=0.18507/18/2023 19:16:49 - INFO - __main__ - train loss is 1.3853846648707986\n",
      "Steps:  14%|▏| 2043/15000 [13:26<3:38:52,  1.01s/it, lr=9.97e-6, step_loss=0.10507/18/2023 19:16:49 - INFO - __main__ - train loss is 2.034931526519358\n",
      "Steps:  14%|▏| 2044/15000 [13:27<2:44:47,  1.31it/s, lr=9.97e-6, step_loss=0.65]07/18/2023 19:16:49 - INFO - __main__ - train loss is 2.0634966986253858\n",
      "Steps:  14%|▏| 2045/15000 [13:27<2:06:51,  1.70it/s, lr=9.97e-6, step_loss=0.02807/18/2023 19:16:49 - INFO - __main__ - train loss is 2.177565415389836\n",
      "Steps:  14%|▏| 2046/15000 [13:27<1:40:17,  2.15it/s, lr=9.97e-6, step_loss=0.11407/18/2023 19:16:49 - INFO - __main__ - train loss is 2.2266651103273034\n",
      "Steps:  14%|▏| 2047/15000 [13:27<1:22:01,  2.63it/s, lr=9.97e-6, step_loss=0.04907/18/2023 19:16:49 - INFO - __main__ - train loss is 2.2343975021503866\n",
      "Steps:  14%|▏| 2048/15000 [13:27<1:08:52,  3.13it/s, lr=9.97e-6, step_loss=0.00707/18/2023 19:16:50 - INFO - __main__ - train loss is 2.27163522830233\n",
      "Steps:  14%|▏| 2049/15000 [13:27<59:57,  3.60it/s, lr=9.97e-6, step_loss=0.0372]07/18/2023 19:16:50 - INFO - __main__ - train loss is 2.2777635478414595\n",
      "Steps:  14%|▏| 2050/15000 [13:28<53:27,  4.04it/s, lr=9.97e-6, step_loss=0.0061307/18/2023 19:16:50 - INFO - __main__ - train loss is 2.3973521911539137\n",
      "Steps:  14%|▍  | 2051/15000 [13:28<48:54,  4.41it/s, lr=9.97e-6, step_loss=0.12]07/18/2023 19:16:50 - INFO - __main__ - train loss is 2.411507740151137\n",
      "Steps:  14%|▏| 2052/15000 [13:28<45:46,  4.71it/s, lr=9.97e-6, step_loss=0.0142]07/18/2023 19:16:50 - INFO - __main__ - train loss is 2.419315901119262\n",
      "Steps:  14%|▏| 2053/15000 [13:28<43:47,  4.93it/s, lr=9.97e-6, step_loss=0.0078107/18/2023 19:16:50 - INFO - __main__ - train loss is 2.4219798168633133\n",
      "Steps:  14%|▏| 2054/15000 [13:28<42:09,  5.12it/s, lr=9.97e-6, step_loss=0.0026607/18/2023 19:16:51 - INFO - __main__ - train loss is 2.484468264738098\n",
      "Steps:  14%|▏| 2055/15000 [13:29<41:03,  5.25it/s, lr=9.97e-6, step_loss=0.0625]07/18/2023 19:16:51 - INFO - __main__ - train loss is 2.730766518274322\n",
      "Steps:  14%|▎ | 2056/15000 [13:29<40:19,  5.35it/s, lr=9.97e-6, step_loss=0.246]07/18/2023 19:16:51 - INFO - __main__ - train loss is 2.81041799322702\n",
      "Steps:  14%|▏| 2057/15000 [13:29<39:53,  5.41it/s, lr=9.97e-6, step_loss=0.0797]07/18/2023 19:16:51 - INFO - __main__ - train loss is 2.812354536377825\n",
      "Steps:  14%|▏| 2058/15000 [13:29<39:28,  5.46it/s, lr=9.97e-6, step_loss=0.0019407/18/2023 19:16:51 - INFO - __main__ - train loss is 2.845422276877798\n",
      "Steps:  14%|▏| 2059/15000 [13:29<39:10,  5.51it/s, lr=9.97e-6, step_loss=0.0331]07/18/2023 19:16:52 - INFO - __main__ - train loss is 2.8858718402916566\n",
      "Steps:  14%|▏| 2060/15000 [13:29<38:59,  5.53it/s, lr=9.97e-6, step_loss=0.0404]07/18/2023 19:16:52 - INFO - __main__ - train loss is 2.8930648408131674\n",
      "Steps:  14%|▏| 2061/15000 [13:30<39:00,  5.53it/s, lr=9.97e-6, step_loss=0.0071907/18/2023 19:16:52 - INFO - __main__ - train loss is 2.9009458135114983\n",
      "Steps:  14%|▏| 2062/15000 [13:30<39:12,  5.50it/s, lr=9.97e-6, step_loss=0.0078807/18/2023 19:16:52 - INFO - __main__ - train loss is 2.90456046781037\n",
      "Steps:  14%|▏| 2063/15000 [13:30<39:19,  5.48it/s, lr=9.97e-6, step_loss=0.0036107/18/2023 19:16:52 - INFO - __main__ - train loss is 2.9157698625931516\n",
      "Steps:  14%|▏| 2064/15000 [13:30<39:04,  5.52it/s, lr=9.97e-6, step_loss=0.0112]07/18/2023 19:16:52 - INFO - __main__ - train loss is 2.9243441509315744\n",
      "Steps:  14%|▏| 2065/15000 [13:30<38:52,  5.54it/s, lr=9.97e-6, step_loss=0.0085707/18/2023 19:16:53 - INFO - __main__ - train loss is 3.539221434504725\n",
      "Steps:  14%|▎ | 2066/15000 [13:31<38:44,  5.56it/s, lr=9.97e-6, step_loss=0.615]07/18/2023 19:16:53 - INFO - __main__ - train loss is 3.596891167224385\n",
      "Steps:  14%|▏| 2067/15000 [13:31<38:39,  5.57it/s, lr=9.97e-6, step_loss=0.0577]07/18/2023 19:16:53 - INFO - __main__ - train loss is 3.6787116999039426\n",
      "Steps:  14%|▏| 2068/15000 [13:31<38:51,  5.55it/s, lr=9.97e-6, step_loss=0.0818]07/18/2023 19:16:53 - INFO - __main__ - train loss is 3.791802259744145\n",
      "Steps:  14%|▎ | 2069/15000 [13:31<39:05,  5.51it/s, lr=9.97e-6, step_loss=0.113]07/18/2023 19:16:53 - INFO - __main__ - train loss is 3.812747466028668\n",
      "Steps:  14%|▏| 2070/15000 [13:31<39:17,  5.48it/s, lr=9.97e-6, step_loss=0.0209]07/18/2023 19:16:54 - INFO - __main__ - train loss is 4.087770866812207\n",
      "Steps:  14%|▎ | 2071/15000 [13:31<39:16,  5.49it/s, lr=9.97e-6, step_loss=0.275]07/18/2023 19:16:54 - INFO - __main__ - train loss is 4.574488418758847\n",
      "Steps:  14%|▎ | 2072/15000 [13:32<39:13,  5.49it/s, lr=9.97e-6, step_loss=0.487]07/18/2023 19:16:54 - INFO - __main__ - train loss is 4.587022062973119\n",
      "Steps:  14%|▏| 2073/15000 [13:32<38:58,  5.53it/s, lr=9.97e-6, step_loss=0.0125]07/18/2023 19:16:54 - INFO - __main__ - train loss is 4.602439354755916\n",
      "Steps:  14%|▏| 2074/15000 [13:32<38:47,  5.55it/s, lr=9.97e-6, step_loss=0.0154]07/18/2023 19:16:54 - INFO - __main__ - train loss is 4.673045087256469\n",
      "Steps:  14%|▏| 2075/15000 [13:32<39:01,  5.52it/s, lr=9.97e-6, step_loss=0.0706]07/18/2023 19:16:54 - INFO - __main__ - train loss is 4.675654702237807\n",
      "Steps:  14%|▏| 2076/15000 [13:32<38:57,  5.53it/s, lr=9.97e-6, step_loss=0.0026107/18/2023 19:16:55 - INFO - __main__ - train loss is 4.898878105334006\n",
      "Steps:  14%|▎ | 2077/15000 [13:33<38:47,  5.55it/s, lr=9.97e-6, step_loss=0.223]07/18/2023 19:16:55 - INFO - __main__ - train loss is 5.111037202528678\n",
      "Steps:  14%|▎ | 2078/15000 [13:33<38:41,  5.57it/s, lr=9.97e-6, step_loss=0.212]07/18/2023 19:16:55 - INFO - __main__ - train loss is 5.152300082496367\n",
      "Steps:  14%|▏| 2079/15000 [13:33<38:34,  5.58it/s, lr=9.97e-6, step_loss=0.0413]07/18/2023 19:16:55 - INFO - __main__ - train loss is 5.268949941149913\n",
      "Steps:  14%|▎ | 2080/15000 [13:33<38:52,  5.54it/s, lr=9.97e-6, step_loss=0.117]07/18/2023 19:16:55 - INFO - __main__ - train loss is 5.307393882772885\n",
      "Steps:  14%|▏| 2081/15000 [13:33<38:42,  5.56it/s, lr=9.97e-6, step_loss=0.0384]07/18/2023 19:16:56 - INFO - __main__ - train loss is 5.449499879381619\n",
      "Steps:  14%|▎ | 2082/15000 [13:33<38:53,  5.54it/s, lr=9.97e-6, step_loss=0.142]07/18/2023 19:16:56 - INFO - __main__ - train loss is 5.663905058405362\n",
      "Steps:  14%|▎ | 2083/15000 [13:34<38:44,  5.56it/s, lr=9.97e-6, step_loss=0.214]07/18/2023 19:16:56 - INFO - __main__ - train loss is 5.824000362656079\n",
      "Steps:  14%|▍  | 2084/15000 [13:34<38:36,  5.57it/s, lr=9.97e-6, step_loss=0.16]07/18/2023 19:16:56 - INFO - __main__ - train loss is 5.83025962987449\n",
      "Steps:  14%|▏| 2085/15000 [13:34<38:30,  5.59it/s, lr=9.97e-6, step_loss=0.0062607/18/2023 19:16:56 - INFO - __main__ - train loss is 6.605539151816629\n",
      "Steps:  14%|▎ | 2086/15000 [13:34<38:28,  5.59it/s, lr=9.97e-6, step_loss=0.775]07/18/2023 19:16:56 - INFO - __main__ - train loss is 6.632800751714967\n",
      "Steps:  14%|▏| 2087/15000 [13:34<38:31,  5.59it/s, lr=9.97e-6, step_loss=0.0273]07/18/2023 19:16:57 - INFO - __main__ - train loss is 7.169827395468019\n",
      "Steps:  14%|▎ | 2088/15000 [13:34<38:47,  5.55it/s, lr=9.97e-6, step_loss=0.537]07/18/2023 19:16:57 - INFO - __main__ - train loss is 7.177948815166019\n",
      "Steps:  14%|▏| 2089/15000 [13:35<38:39,  5.57it/s, lr=9.97e-6, step_loss=0.0081207/18/2023 19:16:57 - INFO - __main__ - train loss is 7.540357721387409\n",
      "Steps:  14%|▎ | 2090/15000 [13:35<38:33,  5.58it/s, lr=9.97e-6, step_loss=0.362]07/18/2023 19:16:57 - INFO - __main__ - train loss is 7.813371462165378\n",
      "Steps:  14%|▎ | 2091/15000 [13:35<38:29,  5.59it/s, lr=9.97e-6, step_loss=0.273]07/18/2023 19:16:57 - INFO - __main__ - train loss is 7.818023239611648\n",
      "Steps:  14%|▏| 2092/15000 [13:35<38:25,  5.60it/s, lr=9.97e-6, step_loss=0.0046507/18/2023 19:16:57 - INFO - __main__ - train loss is 8.052194674848579\n",
      "Steps:  14%|▎ | 2093/15000 [13:35<38:23,  5.60it/s, lr=9.97e-6, step_loss=0.234]07/18/2023 19:16:58 - INFO - __main__ - train loss is 8.17212040477898\n",
      "Steps:  14%|▍  | 2094/15000 [13:36<38:45,  5.55it/s, lr=9.97e-6, step_loss=0.12]07/18/2023 19:16:58 - INFO - __main__ - train loss is 8.610034984885715\n",
      "Steps:  14%|▎ | 2095/15000 [13:36<38:36,  5.57it/s, lr=9.97e-6, step_loss=0.438]07/18/2023 19:16:58 - INFO - __main__ - train loss is 9.038962436257862\n",
      "Steps:  14%|▎ | 2096/15000 [13:36<38:32,  5.58it/s, lr=9.97e-6, step_loss=0.429]07/18/2023 19:16:58 - INFO - __main__ - train loss is 9.048409531242214\n",
      "Steps:  14%|▏| 2097/15000 [13:36<38:31,  5.58it/s, lr=9.97e-6, step_loss=0.0094507/18/2023 19:16:58 - INFO - __main__ - train loss is 9.072380731231533\n",
      "Steps:  14%|▎ | 2098/15000 [13:36<38:27,  5.59it/s, lr=9.97e-6, step_loss=0.024]07/18/2023 19:16:59 - INFO - __main__ - train loss is 9.094253488234244\n",
      "Steps:  14%|▏| 2099/15000 [13:36<38:25,  5.59it/s, lr=9.97e-6, step_loss=0.0219]07/18/2023 19:16:59 - INFO - __main__ - train loss is 9.621036120108329\n",
      "Steps:  14%|▎ | 2100/15000 [13:37<38:24,  5.60it/s, lr=9.97e-6, step_loss=0.527]07/18/2023 19:16:59 - INFO - __main__ - train loss is 9.624143520952202\n",
      "Steps:  14%|▏| 2101/15000 [13:37<38:21,  5.60it/s, lr=9.97e-6, step_loss=0.0031107/18/2023 19:16:59 - INFO - __main__ - train loss is 10.26313052570913\n",
      "Steps:  14%|▎ | 2102/15000 [13:37<38:22,  5.60it/s, lr=9.97e-6, step_loss=0.639]07/18/2023 19:16:59 - INFO - __main__ - train loss is 10.413906613946892\n",
      "Steps:  14%|▎ | 2103/15000 [13:37<38:22,  5.60it/s, lr=9.97e-6, step_loss=0.151]07/18/2023 19:16:59 - INFO - __main__ - train loss is 10.454800846637227\n",
      "Steps:  14%|▏| 2104/15000 [13:37<38:38,  5.56it/s, lr=9.97e-6, step_loss=0.0409]07/18/2023 19:17:00 - INFO - __main__ - train loss is 10.475613032118417\n",
      "Steps:  14%|▏| 2105/15000 [13:38<38:33,  5.57it/s, lr=9.97e-6, step_loss=0.0208]07/18/2023 19:17:00 - INFO - __main__ - train loss is 10.786780689493753\n",
      "Steps:  14%|▎ | 2106/15000 [13:38<38:48,  5.54it/s, lr=9.97e-6, step_loss=0.311]07/18/2023 19:17:00 - INFO - __main__ - train loss is 11.205536071793176\n",
      "Steps:  14%|▎ | 2107/15000 [13:38<38:59,  5.51it/s, lr=9.97e-6, step_loss=0.419]07/18/2023 19:17:00 - INFO - __main__ - train loss is 11.209192207432352\n",
      "Steps:  14%|▏| 2108/15000 [13:38<38:47,  5.54it/s, lr=9.97e-6, step_loss=0.0036607/18/2023 19:17:00 - INFO - __main__ - train loss is 11.80111812648829\n",
      "Steps:  14%|▎ | 2109/15000 [13:38<38:40,  5.55it/s, lr=9.97e-6, step_loss=0.592]07/18/2023 19:17:01 - INFO - __main__ - train loss is 11.851800410426222\n",
      "Steps:  14%|▏| 2110/15000 [13:38<38:36,  5.56it/s, lr=9.97e-6, step_loss=0.0507]07/18/2023 19:17:01 - INFO - __main__ - train loss is 11.917058049119078\n",
      "Steps:  14%|▏| 2111/15000 [13:39<38:30,  5.58it/s, lr=9.97e-6, step_loss=0.0653]07/18/2023 19:17:01 - INFO - __main__ - train loss is 12.845079241669737\n",
      "Steps:  14%|▎ | 2112/15000 [13:39<38:27,  5.59it/s, lr=9.97e-6, step_loss=0.928]07/18/2023 19:17:01 - INFO - __main__ - train loss is 12.870736619806848\n",
      "Steps:  14%|▏| 2113/15000 [13:39<38:23,  5.59it/s, lr=9.97e-6, step_loss=0.0257]07/18/2023 19:17:01 - INFO - __main__ - train loss is 13.26033016142901\n",
      "Steps:  14%|▍  | 2114/15000 [13:39<38:19,  5.60it/s, lr=9.97e-6, step_loss=0.39]07/18/2023 19:17:01 - INFO - __main__ - train loss is 13.334306529141031\n",
      "Steps:  14%|▎ | 2115/15000 [13:39<38:19,  5.60it/s, lr=9.97e-6, step_loss=0.074]07/18/2023 19:17:02 - INFO - __main__ - train loss is 13.368447339511476\n",
      "Steps:  14%|▏| 2116/15000 [13:39<38:20,  5.60it/s, lr=9.97e-6, step_loss=0.0341]07/18/2023 19:17:02 - INFO - __main__ - train loss is 13.423008265323006\n",
      "Steps:  14%|▏| 2117/15000 [13:40<38:42,  5.55it/s, lr=9.97e-6, step_loss=0.0546]07/18/2023 19:17:02 - INFO - __main__ - train loss is 13.460643487400375\n",
      "Steps:  14%|▏| 2118/15000 [13:40<38:32,  5.57it/s, lr=9.97e-6, step_loss=0.0376]07/18/2023 19:17:02 - INFO - __main__ - train loss is 13.881149666733108\n",
      "Steps:  14%|▎ | 2119/15000 [13:40<38:26,  5.59it/s, lr=9.97e-6, step_loss=0.421]07/18/2023 19:17:02 - INFO - __main__ - train loss is 13.897810642025433\n",
      "Steps:  14%|▏| 2120/15000 [13:40<38:20,  5.60it/s, lr=9.97e-6, step_loss=0.0167]07/18/2023 19:17:03 - INFO - __main__ - train loss is 14.226175163290463\n",
      "Steps:  14%|▎ | 2121/15000 [13:40<38:17,  5.61it/s, lr=9.97e-6, step_loss=0.328]07/18/2023 19:17:03 - INFO - __main__ - train loss is 14.660846624872647\n",
      "Steps:  14%|▎ | 2122/15000 [13:41<38:17,  5.61it/s, lr=9.97e-6, step_loss=0.435]07/18/2023 19:17:03 - INFO - __main__ - train loss is 14.662974794278853\n",
      "Steps:  14%|▏| 2123/15000 [13:41<38:15,  5.61it/s, lr=9.97e-6, step_loss=0.0021307/18/2023 19:17:03 - INFO - __main__ - train loss is 14.837008287082426\n",
      "Steps:  14%|▎ | 2124/15000 [13:41<38:14,  5.61it/s, lr=9.97e-6, step_loss=0.174]07/18/2023 19:17:03 - INFO - __main__ - train loss is 14.84132538724225\n",
      "Steps:  14%|▏| 2125/15000 [13:41<38:12,  5.62it/s, lr=9.97e-6, step_loss=0.0043207/18/2023 19:17:03 - INFO - __main__ - train loss is 15.082856193068437\n",
      "Steps:  14%|▎ | 2126/15000 [13:41<38:16,  5.61it/s, lr=9.97e-6, step_loss=0.242]07/18/2023 19:17:04 - INFO - __main__ - train loss is 15.093437235685997\n",
      "Steps:  14%|▏| 2127/15000 [13:41<38:18,  5.60it/s, lr=9.97e-6, step_loss=0.0106]07/18/2023 19:17:04 - INFO - __main__ - train loss is 15.133538856985979\n",
      "Steps:  14%|▏| 2128/15000 [13:42<38:16,  5.61it/s, lr=9.97e-6, step_loss=0.0401]07/18/2023 19:17:04 - INFO - __main__ - train loss is 15.151777971419506\n",
      "Steps:  14%|▏| 2129/15000 [13:42<38:14,  5.61it/s, lr=9.97e-6, step_loss=0.0182]07/18/2023 19:17:04 - INFO - __main__ - train loss is 15.166709868120961\n",
      "Steps:  14%|▏| 2130/15000 [13:42<38:15,  5.61it/s, lr=9.97e-6, step_loss=0.0149]07/18/2023 19:17:04 - INFO - __main__ - train loss is 15.268539918470196\n",
      "Steps:  14%|▎ | 2131/15000 [13:42<38:36,  5.56it/s, lr=9.97e-6, step_loss=0.102]07/18/2023 19:17:04 - INFO - __main__ - train loss is 15.304136143880896\n",
      "Steps:  14%|▏| 2132/15000 [13:42<38:53,  5.51it/s, lr=9.97e-6, step_loss=0.0356]07/18/2023 19:17:05 - INFO - __main__ - train loss is 15.306484468164854\n",
      "Steps:  14%|▏| 2133/15000 [13:43<38:49,  5.52it/s, lr=9.97e-6, step_loss=0.0023507/18/2023 19:17:05 - INFO - __main__ - train loss is 15.680226482334547\n",
      "Steps:  14%|▎ | 2134/15000 [13:43<51:15,  4.18it/s, lr=9.97e-6, step_loss=0.374]07/18/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.14923569560050964\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 0.14923569560050964\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.002774701686576009\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 0.15201039728708565\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.0022899857722222805\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 0.15430038305930793\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.24978402256965637\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 0.4040844056289643\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.0020138570107519627\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 0.40609826263971627\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.04105608910322189\n",
      "07/18/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 0.44715435174293816\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Per validation step average loss is 0.0030961919110268354\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Cumulative validation average loss is 0.450250543653965\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Per validation step average loss is 0.003824128769338131\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Cumulative validation average loss is 0.4540746724233031\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Per validation step average loss is 0.15457594394683838\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Cumulative validation average loss is 0.6086506163701415\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Per validation step average loss is 0.014044920913875103\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Cumulative validation average loss is 0.6226955372840166\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Per validation step average loss is 0.25298401713371277\n",
      "07/18/2023 19:17:07 - INFO - __main__ - Cumulative validation average loss is 0.8756795544177294\n",
      "07/18/2023 19:17:08 - INFO - __main__ - Per validation step average loss is 0.1623431146144867\n",
      "07/18/2023 19:17:08 - INFO - __main__ - Cumulative validation average loss is 1.038022669032216\n",
      "07/18/2023 19:17:08 - INFO - __main__ - Average validation loss for Epoch 21 is 0.08650188908601801\n",
      "07/18/2023 19:17:08 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:17:20 - INFO - __main__ - Starting epoch 22\n",
      "07/18/2023 19:17:21 - INFO - __main__ - train loss is 0.12721416354179382\n",
      "Steps:  14%|▏| 2135/15000 [13:59<17:29:33,  4.89s/it, lr=9.97e-6, step_loss=0.1207/18/2023 19:17:21 - INFO - __main__ - train loss is 0.14406130462884903\n",
      "Steps:  14%|▏| 2136/15000 [13:59<12:26:46,  3.48s/it, lr=9.97e-6, step_loss=0.0107/18/2023 19:17:21 - INFO - __main__ - train loss is 0.6130891814827919\n",
      "Steps:  14%|▏| 2137/15000 [13:59<8:54:10,  2.49s/it, lr=9.97e-6, step_loss=0.46907/18/2023 19:17:21 - INFO - __main__ - train loss is 1.2731253877282143\n",
      "Steps:  14%|▏| 2138/15000 [13:59<6:25:48,  1.80s/it, lr=9.97e-6, step_loss=0.66]07/18/2023 19:17:22 - INFO - __main__ - train loss is 1.3467680141329765\n",
      "Steps:  14%|▏| 2139/15000 [13:59<4:42:03,  1.32s/it, lr=9.97e-6, step_loss=0.07307/18/2023 19:17:22 - INFO - __main__ - train loss is 1.3503996627405286\n",
      "Steps:  14%|▏| 2140/15000 [14:00<3:29:04,  1.03it/s, lr=9.97e-6, step_loss=0.00307/18/2023 19:17:22 - INFO - __main__ - train loss is 1.370550342835486\n",
      "Steps:  14%|▏| 2141/15000 [14:00<2:38:02,  1.36it/s, lr=9.97e-6, step_loss=0.02007/18/2023 19:17:22 - INFO - __main__ - train loss is 1.9896224224939942\n",
      "Steps:  14%|▏| 2142/15000 [14:00<2:02:03,  1.76it/s, lr=9.97e-6, step_loss=0.61907/18/2023 19:17:22 - INFO - __main__ - train loss is 1.9931340357288718\n",
      "Steps:  14%|▏| 2143/15000 [14:00<1:36:54,  2.21it/s, lr=9.97e-6, step_loss=0.00307/18/2023 19:17:22 - INFO - __main__ - train loss is 1.9960996501613408\n",
      "Steps:  14%|▏| 2144/15000 [14:00<1:19:14,  2.70it/s, lr=9.97e-6, step_loss=0.00207/18/2023 19:17:23 - INFO - __main__ - train loss is 2.4478238814044744\n",
      "Steps:  14%|▏| 2145/15000 [14:00<1:06:53,  3.20it/s, lr=9.97e-6, step_loss=0.45207/18/2023 19:17:23 - INFO - __main__ - train loss is 2.449916225625202\n",
      "Steps:  14%|▏| 2146/15000 [14:01<58:14,  3.68it/s, lr=9.97e-6, step_loss=0.0020907/18/2023 19:17:23 - INFO - __main__ - train loss is 3.1141571819316596\n",
      "Steps:  14%|▎ | 2147/15000 [14:01<52:10,  4.11it/s, lr=9.97e-6, step_loss=0.664]07/18/2023 19:17:23 - INFO - __main__ - train loss is 3.174057100666687\n",
      "Steps:  14%|▏| 2148/15000 [14:01<48:03,  4.46it/s, lr=9.97e-6, step_loss=0.0599]07/18/2023 19:17:23 - INFO - __main__ - train loss is 3.3221776231657714\n",
      "Steps:  14%|▎ | 2149/15000 [14:01<45:08,  4.75it/s, lr=9.97e-6, step_loss=0.148]07/18/2023 19:17:24 - INFO - __main__ - train loss is 3.8001285537611693\n",
      "Steps:  14%|▎ | 2150/15000 [14:01<43:17,  4.95it/s, lr=9.97e-6, step_loss=0.478]07/18/2023 19:17:24 - INFO - __main__ - train loss is 3.805558816762641\n",
      "Steps:  14%|▏| 2151/15000 [14:02<42:05,  5.09it/s, lr=9.97e-6, step_loss=0.0054307/18/2023 19:17:24 - INFO - __main__ - train loss is 3.8398682337719947\n",
      "Steps:  14%|▏| 2152/15000 [14:02<41:00,  5.22it/s, lr=9.97e-6, step_loss=0.0343]07/18/2023 19:17:24 - INFO - __main__ - train loss is 3.844768034061417\n",
      "Steps:  14%|▏| 2153/15000 [14:02<43:03,  4.97it/s, lr=9.97e-6, step_loss=0.0049]07/18/2023 19:17:24 - INFO - __main__ - train loss is 4.4386442170944065\n",
      "Steps:  14%|▎ | 2154/15000 [14:02<44:47,  4.78it/s, lr=9.97e-6, step_loss=0.594]07/18/2023 19:17:25 - INFO - __main__ - train loss is 4.59868280752562\n",
      "Steps:  14%|▍  | 2155/15000 [14:02<45:58,  4.66it/s, lr=9.97e-6, step_loss=0.16]07/18/2023 19:17:25 - INFO - __main__ - train loss is 4.872835682472214\n",
      "Steps:  14%|▎ | 2156/15000 [14:03<46:45,  4.58it/s, lr=9.97e-6, step_loss=0.274]07/18/2023 19:17:25 - INFO - __main__ - train loss is 5.182024763664231\n",
      "Steps:  14%|▎ | 2157/15000 [14:03<46:52,  4.57it/s, lr=9.97e-6, step_loss=0.309]07/18/2023 19:17:25 - INFO - __main__ - train loss is 5.191853021038696\n",
      "Steps:  14%|▏| 2158/15000 [14:03<46:21,  4.62it/s, lr=9.97e-6, step_loss=0.0098307/18/2023 19:17:25 - INFO - __main__ - train loss is 5.193984152982011\n",
      "Steps:  14%|▏| 2159/15000 [14:03<44:22,  4.82it/s, lr=9.97e-6, step_loss=0.0021307/18/2023 19:17:26 - INFO - __main__ - train loss is 5.27469445974566\n",
      "Steps:  14%|▏| 2160/15000 [14:03<42:31,  5.03it/s, lr=9.97e-6, step_loss=0.0807]07/18/2023 19:17:26 - INFO - __main__ - train loss is 5.337115904549137\n",
      "Steps:  14%|▏| 2161/15000 [14:04<41:32,  5.15it/s, lr=9.97e-6, step_loss=0.0624]07/18/2023 19:17:26 - INFO - __main__ - train loss is 5.504478922346607\n",
      "Steps:  14%|▎ | 2162/15000 [14:04<40:39,  5.26it/s, lr=9.97e-6, step_loss=0.167]07/18/2023 19:17:26 - INFO - __main__ - train loss is 5.535238674143329\n",
      "Steps:  14%|▏| 2163/15000 [14:04<39:54,  5.36it/s, lr=9.97e-6, step_loss=0.0308]07/18/2023 19:17:26 - INFO - __main__ - train loss is 5.674815526464954\n",
      "Steps:  14%|▍  | 2164/15000 [14:04<39:23,  5.43it/s, lr=9.97e-6, step_loss=0.14]07/18/2023 19:17:26 - INFO - __main__ - train loss is 5.68102727108635\n",
      "Steps:  14%|▏| 2165/15000 [14:04<39:01,  5.48it/s, lr=9.97e-6, step_loss=0.0062107/18/2023 19:17:27 - INFO - __main__ - train loss is 5.702055735746399\n",
      "Steps:  14%|▎ | 2166/15000 [14:05<38:46,  5.52it/s, lr=9.97e-6, step_loss=0.021]07/18/2023 19:17:27 - INFO - __main__ - train loss is 5.76827964768745\n",
      "Steps:  14%|▏| 2167/15000 [14:05<38:35,  5.54it/s, lr=9.97e-6, step_loss=0.0662]07/18/2023 19:17:27 - INFO - __main__ - train loss is 5.770638350164518\n",
      "Steps:  14%|▏| 2168/15000 [14:05<38:27,  5.56it/s, lr=9.97e-6, step_loss=0.0023607/18/2023 19:17:27 - INFO - __main__ - train loss is 5.82158213458024\n",
      "Steps:  14%|▏| 2169/15000 [14:05<38:44,  5.52it/s, lr=9.97e-6, step_loss=0.0509]07/18/2023 19:17:27 - INFO - __main__ - train loss is 5.859312884276733\n",
      "Steps:  14%|▏| 2170/15000 [14:05<38:44,  5.52it/s, lr=9.97e-6, step_loss=0.0377]07/18/2023 19:17:28 - INFO - __main__ - train loss is 5.8670090574305505\n",
      "Steps:  14%|▏| 2171/15000 [14:05<38:49,  5.51it/s, lr=9.97e-6, step_loss=0.0077]07/18/2023 19:17:28 - INFO - __main__ - train loss is 5.869150866288692\n",
      "Steps:  14%|▏| 2172/15000 [14:06<39:00,  5.48it/s, lr=9.97e-6, step_loss=0.0021407/18/2023 19:17:28 - INFO - __main__ - train loss is 6.288623352069408\n",
      "Steps:  14%|▎ | 2173/15000 [14:06<38:47,  5.51it/s, lr=9.97e-6, step_loss=0.419]07/18/2023 19:17:28 - INFO - __main__ - train loss is 6.290730309206992\n",
      "Steps:  14%|▏| 2174/15000 [14:06<38:37,  5.54it/s, lr=9.97e-6, step_loss=0.0021107/18/2023 19:17:28 - INFO - __main__ - train loss is 6.309971601236612\n",
      "Steps:  14%|▏| 2175/15000 [14:06<38:30,  5.55it/s, lr=9.97e-6, step_loss=0.0192]07/18/2023 19:17:28 - INFO - __main__ - train loss is 6.41404925333336\n",
      "Steps:  15%|▎ | 2176/15000 [14:06<38:46,  5.51it/s, lr=9.97e-6, step_loss=0.104]07/18/2023 19:17:29 - INFO - __main__ - train loss is 6.463967606890947\n",
      "Steps:  15%|▏| 2177/15000 [14:07<38:42,  5.52it/s, lr=9.97e-6, step_loss=0.0499]07/18/2023 19:17:29 - INFO - __main__ - train loss is 6.509684157092124\n",
      "Steps:  15%|▏| 2178/15000 [14:07<38:31,  5.55it/s, lr=9.97e-6, step_loss=0.0457]07/18/2023 19:17:29 - INFO - __main__ - train loss is 6.523022151086479\n",
      "Steps:  15%|▏| 2179/15000 [14:07<38:23,  5.57it/s, lr=9.97e-6, step_loss=0.0133]07/18/2023 19:17:29 - INFO - __main__ - train loss is 6.600411108229309\n",
      "Steps:  15%|▏| 2180/15000 [14:07<38:18,  5.58it/s, lr=9.97e-6, step_loss=0.0774]07/18/2023 19:17:29 - INFO - __main__ - train loss is 6.83413307974115\n",
      "Steps:  15%|▎ | 2181/15000 [14:07<38:14,  5.59it/s, lr=9.97e-6, step_loss=0.234]07/18/2023 19:17:30 - INFO - __main__ - train loss is 6.836261504795402\n",
      "Steps:  15%|▏| 2182/15000 [14:07<38:11,  5.59it/s, lr=9.97e-6, step_loss=0.0021307/18/2023 19:17:30 - INFO - __main__ - train loss is 6.838598164031282\n",
      "Steps:  15%|▏| 2183/15000 [14:08<38:10,  5.60it/s, lr=9.97e-6, step_loss=0.0023407/18/2023 19:17:30 - INFO - __main__ - train loss is 6.863153757760301\n",
      "Steps:  15%|▏| 2184/15000 [14:08<38:09,  5.60it/s, lr=9.97e-6, step_loss=0.0246]07/18/2023 19:17:30 - INFO - __main__ - train loss is 6.866707864450291\n",
      "Steps:  15%|▏| 2185/15000 [14:08<38:30,  5.55it/s, lr=9.97e-6, step_loss=0.0035507/18/2023 19:17:30 - INFO - __main__ - train loss is 7.01441780035384\n",
      "Steps:  15%|▎ | 2186/15000 [14:08<38:59,  5.48it/s, lr=9.97e-6, step_loss=0.148]07/18/2023 19:17:30 - INFO - __main__ - train loss is 7.039189561503008\n",
      "Steps:  15%|▏| 2187/15000 [14:08<38:43,  5.52it/s, lr=9.97e-6, step_loss=0.0248]07/18/2023 19:17:31 - INFO - __main__ - train loss is 7.0850370295811445\n",
      "Steps:  15%|▏| 2188/15000 [14:09<38:33,  5.54it/s, lr=9.97e-6, step_loss=0.0458]07/18/2023 19:17:31 - INFO - __main__ - train loss is 7.296596533851698\n",
      "Steps:  15%|▎ | 2189/15000 [14:09<38:26,  5.55it/s, lr=9.97e-6, step_loss=0.212]07/18/2023 19:17:31 - INFO - __main__ - train loss is 7.4349588074255735\n",
      "Steps:  15%|▎ | 2190/15000 [14:09<38:19,  5.57it/s, lr=9.97e-6, step_loss=0.138]07/18/2023 19:17:31 - INFO - __main__ - train loss is 7.436766501516104\n",
      "Steps:  15%|▏| 2191/15000 [14:09<38:31,  5.54it/s, lr=9.97e-6, step_loss=0.0018107/18/2023 19:17:31 - INFO - __main__ - train loss is 7.76836895570159\n",
      "Steps:  15%|▎ | 2192/15000 [14:09<38:45,  5.51it/s, lr=9.97e-6, step_loss=0.332]07/18/2023 19:17:32 - INFO - __main__ - train loss is 7.796094600111246\n",
      "Steps:  15%|▏| 2193/15000 [14:09<38:40,  5.52it/s, lr=9.97e-6, step_loss=0.0277]07/18/2023 19:17:32 - INFO - __main__ - train loss is 7.802779457531869\n",
      "Steps:  15%|▏| 2194/15000 [14:10<38:29,  5.55it/s, lr=9.97e-6, step_loss=0.0066807/18/2023 19:17:32 - INFO - __main__ - train loss is 7.8804664527997375\n",
      "Steps:  15%|▏| 2195/15000 [14:10<38:21,  5.56it/s, lr=9.97e-6, step_loss=0.0777]07/18/2023 19:17:32 - INFO - __main__ - train loss is 7.8836548663675785\n",
      "Steps:  15%|▏| 2196/15000 [14:10<38:19,  5.57it/s, lr=9.97e-6, step_loss=0.0031907/18/2023 19:17:32 - INFO - __main__ - train loss is 7.913903366774321\n",
      "Steps:  15%|▏| 2197/15000 [14:10<38:36,  5.53it/s, lr=9.97e-6, step_loss=0.0302]07/18/2023 19:17:32 - INFO - __main__ - train loss is 8.408813368529081\n",
      "Steps:  15%|▎ | 2198/15000 [14:10<38:43,  5.51it/s, lr=9.97e-6, step_loss=0.495]07/18/2023 19:17:33 - INFO - __main__ - train loss is 9.036160122603178\n",
      "Steps:  15%|▎ | 2199/15000 [14:10<38:32,  5.54it/s, lr=9.97e-6, step_loss=0.627]07/18/2023 19:17:33 - INFO - __main__ - train loss is 9.07473511248827\n",
      "Steps:  15%|▏| 2200/15000 [14:11<38:23,  5.56it/s, lr=9.97e-6, step_loss=0.0386]07/18/2023 19:17:33 - INFO - __main__ - train loss is 9.375725336372852\n",
      "Steps:  15%|▎ | 2201/15000 [14:11<38:17,  5.57it/s, lr=9.97e-6, step_loss=0.301]07/18/2023 19:17:33 - INFO - __main__ - train loss is 9.396897733211517\n",
      "Steps:  15%|▏| 2202/15000 [14:11<38:15,  5.57it/s, lr=9.97e-6, step_loss=0.0212]07/18/2023 19:17:33 - INFO - __main__ - train loss is 9.759281903505325\n",
      "Steps:  15%|▎ | 2203/15000 [14:11<38:13,  5.58it/s, lr=9.97e-6, step_loss=0.362]07/18/2023 19:17:33 - INFO - __main__ - train loss is 9.778813330456614\n",
      "Steps:  15%|▏| 2204/15000 [14:11<38:10,  5.59it/s, lr=9.97e-6, step_loss=0.0195]07/18/2023 19:17:34 - INFO - __main__ - train loss is 10.043274043127894\n",
      "Steps:  15%|▎ | 2205/15000 [14:12<38:27,  5.55it/s, lr=9.97e-6, step_loss=0.264]07/18/2023 19:17:34 - INFO - __main__ - train loss is 10.049957250244915\n",
      "Steps:  15%|▏| 2206/15000 [14:12<38:19,  5.56it/s, lr=9.97e-6, step_loss=0.0066807/18/2023 19:17:34 - INFO - __main__ - train loss is 10.097818140871823\n",
      "Steps:  15%|▏| 2207/15000 [14:12<38:18,  5.57it/s, lr=9.97e-6, step_loss=0.0479]07/18/2023 19:17:34 - INFO - __main__ - train loss is 10.12536461558193\n",
      "Steps:  15%|▏| 2208/15000 [14:12<38:15,  5.57it/s, lr=9.97e-6, step_loss=0.0275]07/18/2023 19:17:34 - INFO - __main__ - train loss is 10.148690431378782\n",
      "Steps:  15%|▏| 2209/15000 [14:12<38:11,  5.58it/s, lr=9.97e-6, step_loss=0.0233]07/18/2023 19:17:35 - INFO - __main__ - train loss is 10.8479546001181\n",
      "Steps:  15%|▎ | 2210/15000 [14:12<38:08,  5.59it/s, lr=9.97e-6, step_loss=0.699]07/18/2023 19:17:35 - INFO - __main__ - train loss is 11.088487937115133\n",
      "Steps:  15%|▎ | 2211/15000 [14:13<38:07,  5.59it/s, lr=9.97e-6, step_loss=0.241]07/18/2023 19:17:35 - INFO - __main__ - train loss is 11.153359710238874\n",
      "Steps:  15%|▏| 2212/15000 [14:13<38:04,  5.60it/s, lr=9.97e-6, step_loss=0.0649]07/18/2023 19:17:35 - INFO - __main__ - train loss is 11.162245682440698\n",
      "Steps:  15%|▏| 2213/15000 [14:13<38:04,  5.60it/s, lr=9.97e-6, step_loss=0.0088907/18/2023 19:17:35 - INFO - __main__ - train loss is 11.591900817118585\n",
      "Steps:  15%|▍  | 2214/15000 [14:13<38:03,  5.60it/s, lr=9.97e-6, step_loss=0.43]07/18/2023 19:17:35 - INFO - __main__ - train loss is 11.758080682717264\n",
      "Steps:  15%|▎ | 2215/15000 [14:13<37:59,  5.61it/s, lr=9.97e-6, step_loss=0.166]07/18/2023 19:17:36 - INFO - __main__ - train loss is 11.794370277784765\n",
      "Steps:  15%|▏| 2216/15000 [14:14<37:57,  5.61it/s, lr=9.97e-6, step_loss=0.0363]07/18/2023 19:17:36 - INFO - __main__ - train loss is 11.828334382735193\n",
      "Steps:  15%|▎ | 2217/15000 [14:14<37:57,  5.61it/s, lr=9.97e-6, step_loss=0.034]07/18/2023 19:17:36 - INFO - __main__ - train loss is 11.842796049080789\n",
      "Steps:  15%|▏| 2218/15000 [14:14<37:55,  5.62it/s, lr=9.97e-6, step_loss=0.0145]07/18/2023 19:17:36 - INFO - __main__ - train loss is 11.853330667130649\n",
      "Steps:  15%|▏| 2219/15000 [14:14<37:54,  5.62it/s, lr=9.97e-6, step_loss=0.0105]07/18/2023 19:17:36 - INFO - __main__ - train loss is 11.85714512085542\n",
      "Steps:  15%|▏| 2220/15000 [14:14<37:53,  5.62it/s, lr=9.97e-6, step_loss=0.0038107/18/2023 19:17:37 - INFO - __main__ - train loss is 11.90799738978967\n",
      "Steps:  15%|▏| 2221/15000 [14:14<37:53,  5.62it/s, lr=9.97e-6, step_loss=0.0509]07/18/2023 19:17:37 - INFO - __main__ - train loss is 12.159800758119673\n",
      "Steps:  15%|▎ | 2222/15000 [14:15<37:53,  5.62it/s, lr=9.97e-6, step_loss=0.252]07/18/2023 19:17:37 - INFO - __main__ - train loss is 12.28868039464578\n",
      "Steps:  15%|▎ | 2223/15000 [14:15<38:07,  5.59it/s, lr=9.97e-6, step_loss=0.129]07/18/2023 19:17:37 - INFO - __main__ - train loss is 12.478164320345968\n",
      "Steps:  15%|▎ | 2224/15000 [14:15<38:01,  5.60it/s, lr=9.97e-6, step_loss=0.189]07/18/2023 19:17:37 - INFO - __main__ - train loss is 12.484159477520734\n",
      "Steps:  15%|▎ | 2225/15000 [14:15<37:59,  5.60it/s, lr=9.97e-6, step_loss=0.006]07/18/2023 19:17:37 - INFO - __main__ - train loss is 12.697612278629094\n",
      "Steps:  15%|▎ | 2226/15000 [14:15<37:57,  5.61it/s, lr=9.97e-6, step_loss=0.213]07/18/2023 19:17:38 - INFO - __main__ - train loss is 12.77723027067259\n",
      "Steps:  15%|▏| 2227/15000 [14:15<37:55,  5.61it/s, lr=9.97e-6, step_loss=0.0796]07/18/2023 19:17:38 - INFO - __main__ - train loss is 13.362712748814374\n",
      "Steps:  15%|▎ | 2228/15000 [14:16<37:53,  5.62it/s, lr=9.97e-6, step_loss=0.585]07/18/2023 19:17:38 - INFO - __main__ - train loss is 13.36443060869351\n",
      "Steps:  15%|▏| 2229/15000 [14:16<37:52,  5.62it/s, lr=9.97e-6, step_loss=0.0017207/18/2023 19:17:38 - INFO - __main__ - train loss is 13.368923214729875\n",
      "Steps:  15%|▏| 2230/15000 [14:16<37:52,  5.62it/s, lr=9.97e-6, step_loss=0.0044907/18/2023 19:17:39 - INFO - __main__ - train loss is 13.37173077231273\n",
      "Steps:  15%|▏| 2231/15000 [14:16<52:08,  4.08it/s, lr=9.97e-6, step_loss=0.0028107/18/2023 19:17:39 - INFO - __main__ - Per validation step average loss is 0.09609220176935196\n",
      "07/18/2023 19:17:39 - INFO - __main__ - Cumulative validation average loss is 0.09609220176935196\n",
      "07/18/2023 19:17:39 - INFO - __main__ - Per validation step average loss is 0.04040418565273285\n",
      "07/18/2023 19:17:39 - INFO - __main__ - Cumulative validation average loss is 0.1364963874220848\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Per validation step average loss is 0.09531857818365097\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Cumulative validation average loss is 0.23181496560573578\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Per validation step average loss is 0.11955183744430542\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Cumulative validation average loss is 0.3513668030500412\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Per validation step average loss is 0.004091019742190838\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Cumulative validation average loss is 0.35545782279223204\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Per validation step average loss is 0.2934250831604004\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Cumulative validation average loss is 0.6488829059526324\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Per validation step average loss is 0.014376958832144737\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Cumulative validation average loss is 0.6632598647847772\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Per validation step average loss is 0.016182782128453255\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Cumulative validation average loss is 0.6794426469132304\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Per validation step average loss is 0.09155119210481644\n",
      "07/18/2023 19:17:40 - INFO - __main__ - Cumulative validation average loss is 0.7709938390180469\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Per validation step average loss is 0.4916642904281616\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Cumulative validation average loss is 1.2626581294462085\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Per validation step average loss is 0.4155654311180115\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Cumulative validation average loss is 1.67822356056422\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Per validation step average loss is 0.02097361907362938\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Cumulative validation average loss is 1.6991971796378493\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Average validation loss for Epoch 22 is 0.14159976496982077\n",
      "07/18/2023 19:17:41 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:17:54 - INFO - __main__ - Starting epoch 23\n",
      "07/18/2023 19:17:54 - INFO - __main__ - train loss is 0.0262894369661808\n",
      "Steps:  15%|▏| 2232/15000 [14:32<17:32:36,  4.95s/it, lr=9.97e-6, step_loss=0.0207/18/2023 19:17:55 - INFO - __main__ - train loss is 0.6574231125414371\n",
      "Steps:  15%|▏| 2233/15000 [14:33<12:28:13,  3.52s/it, lr=9.97e-6, step_loss=0.6307/18/2023 19:17:55 - INFO - __main__ - train loss is 0.6734351627528667\n",
      "Steps:  15%|▏| 2234/15000 [14:33<8:55:01,  2.51s/it, lr=9.97e-6, step_loss=0.01607/18/2023 19:17:55 - INFO - __main__ - train loss is 0.6757162711583078\n",
      "Steps:  15%|▏| 2235/15000 [14:33<6:25:56,  1.81s/it, lr=9.97e-6, step_loss=0.00207/18/2023 19:17:55 - INFO - __main__ - train loss is 1.006715019699186\n",
      "Steps:  15%|▏| 2236/15000 [14:33<4:41:27,  1.32s/it, lr=9.97e-6, step_loss=0.33107/18/2023 19:17:55 - INFO - __main__ - train loss is 1.365212996955961\n",
      "Steps:  15%|▏| 2237/15000 [14:33<3:28:29,  1.02it/s, lr=9.97e-6, step_loss=0.35807/18/2023 19:17:56 - INFO - __main__ - train loss is 1.3975438824854791\n",
      "Steps:  15%|▏| 2238/15000 [14:33<2:37:21,  1.35it/s, lr=9.97e-6, step_loss=0.03207/18/2023 19:17:56 - INFO - __main__ - train loss is 1.6093607149086893\n",
      "Steps:  15%|▏| 2239/15000 [14:34<2:01:29,  1.75it/s, lr=9.97e-6, step_loss=0.21207/18/2023 19:17:56 - INFO - __main__ - train loss is 1.6343668992631137\n",
      "Steps:  15%|▏| 2240/15000 [14:34<1:36:23,  2.21it/s, lr=9.97e-6, step_loss=0.02507/18/2023 19:17:56 - INFO - __main__ - train loss is 1.65691953105852\n",
      "Steps:  15%|▏| 2241/15000 [14:34<1:19:10,  2.69it/s, lr=9.97e-6, step_loss=0.02207/18/2023 19:17:56 - INFO - __main__ - train loss is 2.0485258023254573\n",
      "Steps:  15%|▏| 2242/15000 [14:34<1:07:27,  3.15it/s, lr=9.97e-6, step_loss=0.39207/18/2023 19:17:56 - INFO - __main__ - train loss is 2.075821682345122\n",
      "Steps:  15%|▏| 2243/15000 [14:34<1:00:34,  3.51it/s, lr=9.97e-6, step_loss=0.02707/18/2023 19:17:57 - INFO - __main__ - train loss is 2.336723133455962\n",
      "Steps:  15%|▎ | 2244/15000 [14:35<53:45,  3.96it/s, lr=9.97e-6, step_loss=0.261]07/18/2023 19:17:57 - INFO - __main__ - train loss is 2.3438932807184756\n",
      "Steps:  15%|▏| 2245/15000 [14:35<48:57,  4.34it/s, lr=9.97e-6, step_loss=0.0071707/18/2023 19:17:57 - INFO - __main__ - train loss is 2.5379427284933627\n",
      "Steps:  15%|▎ | 2246/15000 [14:35<45:37,  4.66it/s, lr=9.97e-6, step_loss=0.194]07/18/2023 19:17:57 - INFO - __main__ - train loss is 2.64532063761726\n",
      "Steps:  15%|▎ | 2247/15000 [14:35<43:17,  4.91it/s, lr=9.97e-6, step_loss=0.107]07/18/2023 19:17:57 - INFO - __main__ - train loss is 2.952069325838238\n",
      "Steps:  15%|▎ | 2248/15000 [14:35<41:38,  5.10it/s, lr=9.97e-6, step_loss=0.307]07/18/2023 19:17:58 - INFO - __main__ - train loss is 3.2060703174211085\n",
      "Steps:  15%|▎ | 2249/15000 [14:35<40:33,  5.24it/s, lr=9.97e-6, step_loss=0.254]07/18/2023 19:17:58 - INFO - __main__ - train loss is 3.279856948647648\n",
      "Steps:  15%|▏| 2250/15000 [14:36<39:44,  5.35it/s, lr=9.97e-6, step_loss=0.0738]07/18/2023 19:17:58 - INFO - __main__ - train loss is 3.5385352657176554\n",
      "Steps:  15%|▎ | 2251/15000 [14:36<39:14,  5.41it/s, lr=9.97e-6, step_loss=0.259]07/18/2023 19:17:58 - INFO - __main__ - train loss is 3.5484507526271045\n",
      "Steps:  15%|▏| 2252/15000 [14:36<38:49,  5.47it/s, lr=9.97e-6, step_loss=0.0099207/18/2023 19:17:58 - INFO - __main__ - train loss is 3.5733892577700317\n",
      "Steps:  15%|▏| 2253/15000 [14:36<38:38,  5.50it/s, lr=9.97e-6, step_loss=0.0249]07/18/2023 19:17:58 - INFO - __main__ - train loss is 3.7088677841238678\n",
      "Steps:  15%|▎ | 2254/15000 [14:36<38:41,  5.49it/s, lr=9.97e-6, step_loss=0.135]07/18/2023 19:17:59 - INFO - __main__ - train loss is 3.8446616190485656\n",
      "Steps:  15%|▎ | 2255/15000 [14:36<38:27,  5.52it/s, lr=9.97e-6, step_loss=0.136]07/18/2023 19:17:59 - INFO - __main__ - train loss is 3.967731829266995\n",
      "Steps:  15%|▎ | 2256/15000 [14:37<38:16,  5.55it/s, lr=9.97e-6, step_loss=0.123]07/18/2023 19:17:59 - INFO - __main__ - train loss is 4.015196475666016\n",
      "Steps:  15%|▏| 2257/15000 [14:37<38:08,  5.57it/s, lr=9.97e-6, step_loss=0.0475]07/18/2023 19:17:59 - INFO - __main__ - train loss is 4.107395831029862\n",
      "Steps:  15%|▏| 2258/15000 [14:37<38:03,  5.58it/s, lr=9.97e-6, step_loss=0.0922]07/18/2023 19:17:59 - INFO - __main__ - train loss is 4.145152661483735\n",
      "Steps:  15%|▏| 2259/15000 [14:37<37:59,  5.59it/s, lr=9.97e-6, step_loss=0.0378]07/18/2023 19:18:00 - INFO - __main__ - train loss is 4.380850214045495\n",
      "[2023-07-18 19:18:00,085] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  15%|▎ | 2260/15000 [14:37<37:41,  5.63it/s, lr=9.97e-6, step_loss=0.236]07/18/2023 19:18:00 - INFO - __main__ - train loss is 4.412009451072663\n",
      "Steps:  15%|▏| 2261/15000 [14:38<37:42,  5.63it/s, lr=9.97e-6, step_loss=0.0312]07/18/2023 19:18:00 - INFO - __main__ - train loss is 4.8968696924857795\n",
      "Steps:  15%|▎ | 2262/15000 [14:38<37:45,  5.62it/s, lr=9.97e-6, step_loss=0.485]07/18/2023 19:18:00 - INFO - __main__ - train loss is 5.554491493385285\n",
      "Steps:  15%|▎ | 2263/15000 [14:38<37:44,  5.62it/s, lr=9.97e-6, step_loss=0.658]07/18/2023 19:18:00 - INFO - __main__ - train loss is 5.93488774029538\n",
      "Steps:  15%|▍  | 2264/15000 [14:38<37:45,  5.62it/s, lr=9.97e-6, step_loss=0.38]07/18/2023 19:18:00 - INFO - __main__ - train loss is 6.036559972446412\n",
      "Steps:  15%|▎ | 2265/15000 [14:38<37:47,  5.62it/s, lr=9.97e-6, step_loss=0.102]07/18/2023 19:18:01 - INFO - __main__ - train loss is 6.287665042560548\n",
      "Steps:  15%|▎ | 2266/15000 [14:38<37:49,  5.61it/s, lr=9.97e-6, step_loss=0.251]07/18/2023 19:18:01 - INFO - __main__ - train loss is 6.290589968441054\n",
      "Steps:  15%|▏| 2267/15000 [14:39<38:10,  5.56it/s, lr=9.97e-6, step_loss=0.0029207/18/2023 19:18:01 - INFO - __main__ - train loss is 6.980908731697127\n",
      "Steps:  15%|▍  | 2268/15000 [14:39<38:45,  5.48it/s, lr=9.97e-6, step_loss=0.69]07/18/2023 19:18:01 - INFO - __main__ - train loss is 7.043659950373694\n",
      "Steps:  15%|▏| 2269/15000 [14:39<38:48,  5.47it/s, lr=9.97e-6, step_loss=0.0628]07/18/2023 19:18:01 - INFO - __main__ - train loss is 7.050104108406231\n",
      "Steps:  15%|▏| 2270/15000 [14:39<38:30,  5.51it/s, lr=9.97e-6, step_loss=0.0064407/18/2023 19:18:01 - INFO - __main__ - train loss is 7.41156652267091\n",
      "Steps:  15%|▎ | 2271/15000 [14:39<38:18,  5.54it/s, lr=9.97e-6, step_loss=0.361]07/18/2023 19:18:02 - INFO - __main__ - train loss is 7.728039410663769\n",
      "Steps:  15%|▎ | 2272/15000 [14:40<38:09,  5.56it/s, lr=9.97e-6, step_loss=0.316]07/18/2023 19:18:02 - INFO - __main__ - train loss is 8.113286253763363\n",
      "Steps:  15%|▎ | 2273/15000 [14:40<38:02,  5.57it/s, lr=9.97e-6, step_loss=0.385]07/18/2023 19:18:02 - INFO - __main__ - train loss is 8.501066324068233\n",
      "Steps:  15%|▎ | 2274/15000 [14:40<37:59,  5.58it/s, lr=9.96e-6, step_loss=0.388]07/18/2023 19:18:02 - INFO - __main__ - train loss is 8.567168955458328\n",
      "Steps:  15%|▏| 2275/15000 [14:40<37:56,  5.59it/s, lr=9.96e-6, step_loss=0.0661]07/18/2023 19:18:02 - INFO - __main__ - train loss is 8.570737224305049\n",
      "Steps:  15%|▏| 2276/15000 [14:40<37:53,  5.60it/s, lr=9.96e-6, step_loss=0.0035707/18/2023 19:18:03 - INFO - __main__ - train loss is 8.653049733722582\n",
      "Steps:  15%|▏| 2277/15000 [14:40<37:52,  5.60it/s, lr=9.96e-6, step_loss=0.0823]07/18/2023 19:18:03 - INFO - __main__ - train loss is 9.534017648780718\n",
      "Steps:  15%|▎ | 2278/15000 [14:41<38:01,  5.58it/s, lr=9.96e-6, step_loss=0.881]07/18/2023 19:18:03 - INFO - __main__ - train loss is 9.746262666070834\n",
      "Steps:  15%|▎ | 2279/15000 [14:41<38:16,  5.54it/s, lr=9.96e-6, step_loss=0.212]07/18/2023 19:18:03 - INFO - __main__ - train loss is 9.772566881263629\n",
      "Steps:  15%|▏| 2280/15000 [14:41<38:30,  5.51it/s, lr=9.96e-6, step_loss=0.0263]07/18/2023 19:18:03 - INFO - __main__ - train loss is 9.955601241672412\n",
      "Steps:  15%|▎ | 2281/15000 [14:41<38:43,  5.47it/s, lr=9.96e-6, step_loss=0.183]07/18/2023 19:18:03 - INFO - __main__ - train loss is 10.369885321939364\n",
      "Steps:  15%|▎ | 2282/15000 [14:41<38:25,  5.52it/s, lr=9.96e-6, step_loss=0.414]07/18/2023 19:18:04 - INFO - __main__ - train loss is 10.371561055304483\n",
      "Steps:  15%|▏| 2283/15000 [14:42<38:14,  5.54it/s, lr=9.96e-6, step_loss=0.0016807/18/2023 19:18:04 - INFO - __main__ - train loss is 10.37309004040435\n",
      "Steps:  15%|▏| 2284/15000 [14:42<38:07,  5.56it/s, lr=9.96e-6, step_loss=0.0015307/18/2023 19:18:04 - INFO - __main__ - train loss is 10.375739168841392\n",
      "Steps:  15%|▏| 2285/15000 [14:42<38:00,  5.58it/s, lr=9.96e-6, step_loss=0.0026507/18/2023 19:18:04 - INFO - __main__ - train loss is 10.37750831595622\n",
      "Steps:  15%|▏| 2286/15000 [14:42<37:55,  5.59it/s, lr=9.96e-6, step_loss=0.0017707/18/2023 19:18:04 - INFO - __main__ - train loss is 10.86318365088664\n",
      "Steps:  15%|▎ | 2287/15000 [14:42<37:56,  5.58it/s, lr=9.96e-6, step_loss=0.486]07/18/2023 19:18:05 - INFO - __main__ - train loss is 10.92632682225667\n",
      "Steps:  15%|▏| 2288/15000 [14:42<38:14,  5.54it/s, lr=9.96e-6, step_loss=0.0631]07/18/2023 19:18:05 - INFO - __main__ - train loss is 11.53855688474141\n",
      "Steps:  15%|▎ | 2289/15000 [14:43<38:43,  5.47it/s, lr=9.96e-6, step_loss=0.612]07/18/2023 19:18:05 - INFO - __main__ - train loss is 11.599882401293144\n",
      "Steps:  15%|▏| 2290/15000 [14:43<38:24,  5.51it/s, lr=9.96e-6, step_loss=0.0613]07/18/2023 19:18:05 - INFO - __main__ - train loss is 11.926711298292503\n",
      "Steps:  15%|▎ | 2291/15000 [14:43<38:13,  5.54it/s, lr=9.96e-6, step_loss=0.327]07/18/2023 19:18:05 - INFO - __main__ - train loss is 12.240175045793876\n",
      "Steps:  15%|▎ | 2292/15000 [14:43<38:04,  5.56it/s, lr=9.96e-6, step_loss=0.313]07/18/2023 19:18:05 - INFO - __main__ - train loss is 12.279664732282981\n",
      "Steps:  15%|▏| 2293/15000 [14:43<37:58,  5.58it/s, lr=9.96e-6, step_loss=0.0395]07/18/2023 19:18:06 - INFO - __main__ - train loss is 12.602583206957206\n",
      "Steps:  15%|▎ | 2294/15000 [14:44<37:53,  5.59it/s, lr=9.96e-6, step_loss=0.323]07/18/2023 19:18:06 - INFO - __main__ - train loss is 12.686782218283042\n",
      "Steps:  15%|▏| 2295/15000 [14:44<37:51,  5.59it/s, lr=9.96e-6, step_loss=0.0842]07/18/2023 19:18:06 - INFO - __main__ - train loss is 12.79928870475851\n",
      "Steps:  15%|▎ | 2296/15000 [14:44<37:49,  5.60it/s, lr=9.96e-6, step_loss=0.113]07/18/2023 19:18:06 - INFO - __main__ - train loss is 12.817573150387034\n",
      "Steps:  15%|▏| 2297/15000 [14:44<38:05,  5.56it/s, lr=9.96e-6, step_loss=0.0183]07/18/2023 19:18:06 - INFO - __main__ - train loss is 13.401180704822764\n",
      "Steps:  15%|▎ | 2298/15000 [14:44<37:58,  5.57it/s, lr=9.96e-6, step_loss=0.584]07/18/2023 19:18:07 - INFO - __main__ - train loss is 13.520119344582781\n",
      "Steps:  15%|▎ | 2299/15000 [14:44<37:53,  5.59it/s, lr=9.96e-6, step_loss=0.119]07/18/2023 19:18:07 - INFO - __main__ - train loss is 14.122389351716265\n",
      "Steps:  15%|▎ | 2300/15000 [14:45<38:05,  5.56it/s, lr=9.96e-6, step_loss=0.602]07/18/2023 19:18:07 - INFO - __main__ - train loss is 14.210251739015803\n",
      "Steps:  15%|▏| 2301/15000 [14:45<38:20,  5.52it/s, lr=9.96e-6, step_loss=0.0879]07/18/2023 19:18:07 - INFO - __main__ - train loss is 14.21362431277521\n",
      "Steps:  15%|▏| 2302/15000 [14:45<38:33,  5.49it/s, lr=9.96e-6, step_loss=0.0033707/18/2023 19:18:07 - INFO - __main__ - train loss is 14.232840049313381\n",
      "Steps:  15%|▏| 2303/15000 [14:45<38:25,  5.51it/s, lr=9.96e-6, step_loss=0.0192]07/18/2023 19:18:07 - INFO - __main__ - train loss is 14.269267889903858\n",
      "Steps:  15%|▏| 2304/15000 [14:45<38:12,  5.54it/s, lr=9.96e-6, step_loss=0.0364]07/18/2023 19:18:08 - INFO - __main__ - train loss is 14.675974819110706\n",
      "Steps:  15%|▎ | 2305/15000 [14:45<38:00,  5.57it/s, lr=9.96e-6, step_loss=0.407]07/18/2023 19:18:08 - INFO - __main__ - train loss is 14.824604424880818\n",
      "Steps:  15%|▎ | 2306/15000 [14:46<38:14,  5.53it/s, lr=9.96e-6, step_loss=0.149]07/18/2023 19:18:08 - INFO - __main__ - train loss is 14.860233809100464\n",
      "Steps:  15%|▏| 2307/15000 [14:46<38:03,  5.56it/s, lr=9.96e-6, step_loss=0.0356]07/18/2023 19:18:08 - INFO - __main__ - train loss is 14.888637985335663\n",
      "Steps:  15%|▏| 2308/15000 [14:46<38:02,  5.56it/s, lr=9.96e-6, step_loss=0.0284]07/18/2023 19:18:08 - INFO - __main__ - train loss is 15.537786509143189\n",
      "Steps:  15%|▎ | 2309/15000 [14:46<37:55,  5.58it/s, lr=9.96e-6, step_loss=0.649]07/18/2023 19:18:08 - INFO - __main__ - train loss is 15.56196282361634\n",
      "Steps:  15%|▏| 2310/15000 [14:46<37:49,  5.59it/s, lr=9.96e-6, step_loss=0.0242]07/18/2023 19:18:09 - INFO - __main__ - train loss is 15.926408778177574\n",
      "Steps:  15%|▎ | 2311/15000 [14:47<37:46,  5.60it/s, lr=9.96e-6, step_loss=0.364]07/18/2023 19:18:09 - INFO - __main__ - train loss is 16.01779244397767\n",
      "Steps:  15%|▏| 2312/15000 [14:47<37:42,  5.61it/s, lr=9.96e-6, step_loss=0.0914]07/18/2023 19:18:09 - INFO - __main__ - train loss is 16.0225024682004\n",
      "Steps:  15%|▏| 2313/15000 [14:47<37:39,  5.61it/s, lr=9.96e-6, step_loss=0.0047107/18/2023 19:18:09 - INFO - __main__ - train loss is 16.081514944555238\n",
      "Steps:  15%|▎ | 2314/15000 [14:47<37:36,  5.62it/s, lr=9.96e-6, step_loss=0.059]07/18/2023 19:18:09 - INFO - __main__ - train loss is 16.106939698802307\n",
      "Steps:  15%|▏| 2315/15000 [14:47<37:35,  5.62it/s, lr=9.96e-6, step_loss=0.0254]07/18/2023 19:18:10 - INFO - __main__ - train loss is 16.195459860609844\n",
      "Steps:  15%|▏| 2316/15000 [14:47<37:34,  5.63it/s, lr=9.96e-6, step_loss=0.0885]07/18/2023 19:18:10 - INFO - __main__ - train loss is 16.259489278541878\n",
      "Steps:  15%|▎ | 2317/15000 [14:48<37:34,  5.63it/s, lr=9.96e-6, step_loss=0.064]07/18/2023 19:18:10 - INFO - __main__ - train loss is 16.406937475549057\n",
      "Steps:  15%|▎ | 2318/15000 [14:48<37:34,  5.63it/s, lr=9.96e-6, step_loss=0.147]07/18/2023 19:18:10 - INFO - __main__ - train loss is 16.62459811125882\n",
      "Steps:  15%|▎ | 2319/15000 [14:48<37:34,  5.63it/s, lr=9.96e-6, step_loss=0.218]07/18/2023 19:18:10 - INFO - __main__ - train loss is 17.17458989773877\n",
      "Steps:  15%|▍  | 2320/15000 [14:48<37:33,  5.63it/s, lr=9.96e-6, step_loss=0.55]07/18/2023 19:18:10 - INFO - __main__ - train loss is 17.65414061699994\n",
      "Steps:  15%|▍  | 2321/15000 [14:48<37:32,  5.63it/s, lr=9.96e-6, step_loss=0.48]07/18/2023 19:18:11 - INFO - __main__ - train loss is 17.66402002540417\n",
      "Steps:  15%|▏| 2322/15000 [14:49<37:31,  5.63it/s, lr=9.96e-6, step_loss=0.0098807/18/2023 19:18:11 - INFO - __main__ - train loss is 17.679120287531987\n",
      "Steps:  15%|▏| 2323/15000 [14:49<37:31,  5.63it/s, lr=9.96e-6, step_loss=0.0151]07/18/2023 19:18:11 - INFO - __main__ - train loss is 17.681024761055596\n",
      "Steps:  15%|▏| 2324/15000 [14:49<37:31,  5.63it/s, lr=9.96e-6, step_loss=0.0019]07/18/2023 19:18:11 - INFO - __main__ - train loss is 17.690485228900798\n",
      "Steps:  16%|▏| 2325/15000 [14:49<37:31,  5.63it/s, lr=9.96e-6, step_loss=0.0094607/18/2023 19:18:11 - INFO - __main__ - train loss is 17.696047069621272\n",
      "Steps:  16%|▏| 2326/15000 [14:49<37:30,  5.63it/s, lr=9.96e-6, step_loss=0.0055607/18/2023 19:18:12 - INFO - __main__ - train loss is 17.902891906094737\n",
      "Steps:  16%|▎ | 2327/15000 [14:49<37:30,  5.63it/s, lr=9.96e-6, step_loss=0.207]07/18/2023 19:18:12 - INFO - __main__ - train loss is 18.168968858313747\n",
      "Steps:  16%|▎ | 2328/15000 [14:50<51:36,  4.09it/s, lr=9.96e-6, step_loss=0.266]07/18/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.36941614747047424\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 0.36941614747047424\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.007070494815707207\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 0.37648664228618145\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.12592343986034393\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 0.5024100821465254\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.4591984748840332\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 0.9616085570305586\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.0066233305260539055\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 0.9682318875566125\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Per validation step average loss is 0.31871527433395386\n",
      "07/18/2023 19:18:13 - INFO - __main__ - Cumulative validation average loss is 1.2869471618905663\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.4374708831310272\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 1.7244180450215936\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.010665417648851871\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 1.7350834626704454\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.015831641852855682\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 1.7509151045233011\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.006738817319273949\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 1.757653921842575\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.00515781668946147\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 1.7628117385320365\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Per validation step average loss is 0.014364907518029213\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Cumulative validation average loss is 1.7771766460500658\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Average validation loss for Epoch 23 is 0.1480980538375055\n",
      "07/18/2023 19:18:14 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:18:27 - INFO - __main__ - Starting epoch 24\n",
      "07/18/2023 19:18:28 - INFO - __main__ - train loss is 0.21162787079811096\n",
      "Steps:  16%|▏| 2329/15000 [15:06<17:26:50,  4.96s/it, lr=9.96e-6, step_loss=0.2107/18/2023 19:18:28 - INFO - __main__ - train loss is 0.3733716756105423\n",
      "Steps:  16%|▏| 2330/15000 [15:06<12:24:20,  3.52s/it, lr=9.96e-6, step_loss=0.1607/18/2023 19:18:28 - INFO - __main__ - train loss is 0.4780544936656952\n",
      "Steps:  16%|▏| 2331/15000 [15:06<8:52:22,  2.52s/it, lr=9.96e-6, step_loss=0.10507/18/2023 19:18:28 - INFO - __main__ - train loss is 0.690937727689743\n",
      "Steps:  16%|▏| 2332/15000 [15:06<6:24:03,  1.82s/it, lr=9.96e-6, step_loss=0.21307/18/2023 19:18:29 - INFO - __main__ - train loss is 0.7173195295035839\n",
      "Steps:  16%|▏| 2333/15000 [15:06<4:40:26,  1.33s/it, lr=9.96e-6, step_loss=0.02607/18/2023 19:18:29 - INFO - __main__ - train loss is 0.7302675675600767\n",
      "Steps:  16%|▏| 2334/15000 [15:07<3:27:41,  1.02it/s, lr=9.96e-6, step_loss=0.01207/18/2023 19:18:29 - INFO - __main__ - train loss is 0.732347933575511\n",
      "Steps:  16%|▏| 2335/15000 [15:07<2:36:51,  1.35it/s, lr=9.96e-6, step_loss=0.00207/18/2023 19:18:29 - INFO - __main__ - train loss is 1.008409647271037\n",
      "Steps:  16%|▏| 2336/15000 [15:07<2:01:13,  1.74it/s, lr=9.96e-6, step_loss=0.27607/18/2023 19:18:29 - INFO - __main__ - train loss is 1.0106404575053602\n",
      "Steps:  16%|▏| 2337/15000 [15:07<1:36:35,  2.19it/s, lr=9.96e-6, step_loss=0.00207/18/2023 19:18:30 - INFO - __main__ - train loss is 1.8415841611567885\n",
      "Steps:  16%|▏| 2338/15000 [15:07<1:18:59,  2.67it/s, lr=9.96e-6, step_loss=0.83107/18/2023 19:18:30 - INFO - __main__ - train loss is 2.223870054120198\n",
      "Steps:  16%|▏| 2339/15000 [15:08<1:06:40,  3.17it/s, lr=9.96e-6, step_loss=0.38207/18/2023 19:18:30 - INFO - __main__ - train loss is 2.225774570601061\n",
      "Steps:  16%|▏| 2340/15000 [15:08<58:02,  3.63it/s, lr=9.96e-6, step_loss=0.0019]07/18/2023 19:18:30 - INFO - __main__ - train loss is 2.324905573623255\n",
      "Steps:  16%|▏| 2341/15000 [15:08<52:04,  4.05it/s, lr=9.96e-6, step_loss=0.0991]07/18/2023 19:18:30 - INFO - __main__ - train loss is 2.797150253551081\n",
      "Steps:  16%|▎ | 2342/15000 [15:08<47:49,  4.41it/s, lr=9.96e-6, step_loss=0.472]07/18/2023 19:18:30 - INFO - __main__ - train loss is 2.8356933288741857\n",
      "Steps:  16%|▏| 2343/15000 [15:08<44:51,  4.70it/s, lr=9.96e-6, step_loss=0.0385]07/18/2023 19:18:31 - INFO - __main__ - train loss is 2.851008874597028\n",
      "Steps:  16%|▏| 2344/15000 [15:08<42:46,  4.93it/s, lr=9.96e-6, step_loss=0.0153]07/18/2023 19:18:31 - INFO - __main__ - train loss is 2.858964353101328\n",
      "Steps:  16%|▏| 2345/15000 [15:09<41:19,  5.10it/s, lr=9.96e-6, step_loss=0.0079607/18/2023 19:18:31 - INFO - __main__ - train loss is 3.4034094505477697\n",
      "Steps:  16%|▎ | 2346/15000 [15:09<40:20,  5.23it/s, lr=9.96e-6, step_loss=0.544]07/18/2023 19:18:31 - INFO - __main__ - train loss is 3.59336696495302\n",
      "Steps:  16%|▍  | 2347/15000 [15:09<39:39,  5.32it/s, lr=9.96e-6, step_loss=0.19]07/18/2023 19:18:31 - INFO - __main__ - train loss is 3.663258983986452\n",
      "Steps:  16%|▏| 2348/15000 [15:09<39:09,  5.38it/s, lr=9.96e-6, step_loss=0.0699]07/18/2023 19:18:31 - INFO - __main__ - train loss is 3.8188541375566274\n",
      "Steps:  16%|▎ | 2349/15000 [15:09<38:49,  5.43it/s, lr=9.96e-6, step_loss=0.156]07/18/2023 19:18:32 - INFO - __main__ - train loss is 3.8916102789808065\n",
      "Steps:  16%|▏| 2350/15000 [15:10<38:35,  5.46it/s, lr=9.96e-6, step_loss=0.0728]07/18/2023 19:18:32 - INFO - __main__ - train loss is 3.960789292352274\n",
      "Steps:  16%|▏| 2351/15000 [15:10<38:25,  5.49it/s, lr=9.96e-6, step_loss=0.0692]07/18/2023 19:18:32 - INFO - __main__ - train loss is 4.067269086139277\n",
      "Steps:  16%|▎ | 2352/15000 [15:10<38:18,  5.50it/s, lr=9.96e-6, step_loss=0.106]07/18/2023 19:18:32 - INFO - __main__ - train loss is 4.757547616260126\n",
      "Steps:  16%|▍  | 2353/15000 [15:10<38:12,  5.52it/s, lr=9.96e-6, step_loss=0.69]07/18/2023 19:18:32 - INFO - __main__ - train loss is 4.76329371961765\n",
      "Steps:  16%|▏| 2354/15000 [15:10<38:07,  5.53it/s, lr=9.96e-6, step_loss=0.0057507/18/2023 19:18:33 - INFO - __main__ - train loss is 5.263001627055928\n",
      "Steps:  16%|▋   | 2355/15000 [15:10<38:04,  5.53it/s, lr=9.96e-6, step_loss=0.5]07/18/2023 19:18:33 - INFO - __main__ - train loss is 5.483215010492131\n",
      "Steps:  16%|▍  | 2356/15000 [15:11<38:02,  5.54it/s, lr=9.96e-6, step_loss=0.22]07/18/2023 19:18:33 - INFO - __main__ - train loss is 5.499412975041196\n",
      "Steps:  16%|▏| 2357/15000 [15:11<38:01,  5.54it/s, lr=9.96e-6, step_loss=0.0162]07/18/2023 19:18:33 - INFO - __main__ - train loss is 5.51767015340738\n",
      "Steps:  16%|▏| 2358/15000 [15:11<38:00,  5.54it/s, lr=9.96e-6, step_loss=0.0183]07/18/2023 19:18:33 - INFO - __main__ - train loss is 5.553340195445344\n",
      "Steps:  16%|▏| 2359/15000 [15:11<38:05,  5.53it/s, lr=9.96e-6, step_loss=0.0357]07/18/2023 19:18:33 - INFO - __main__ - train loss is 5.7472885239403695\n",
      "Steps:  16%|▎ | 2360/15000 [15:11<38:04,  5.53it/s, lr=9.96e-6, step_loss=0.194]07/18/2023 19:18:34 - INFO - __main__ - train loss is 5.882627664832398\n",
      "Steps:  16%|▎ | 2361/15000 [15:12<38:04,  5.53it/s, lr=9.96e-6, step_loss=0.135]07/18/2023 19:18:34 - INFO - __main__ - train loss is 5.895450011594221\n",
      "Steps:  16%|▏| 2362/15000 [15:12<37:53,  5.56it/s, lr=9.96e-6, step_loss=0.0128]07/18/2023 19:18:34 - INFO - __main__ - train loss is 6.3302594281267375\n",
      "Steps:  16%|▎ | 2363/15000 [15:12<37:44,  5.58it/s, lr=9.96e-6, step_loss=0.435]07/18/2023 19:18:34 - INFO - __main__ - train loss is 6.343445332488045\n",
      "Steps:  16%|▏| 2364/15000 [15:12<37:40,  5.59it/s, lr=9.96e-6, step_loss=0.0132]07/18/2023 19:18:34 - INFO - __main__ - train loss is 6.347022633301094\n",
      "Steps:  16%|▏| 2365/15000 [15:12<37:37,  5.60it/s, lr=9.96e-6, step_loss=0.0035807/18/2023 19:18:35 - INFO - __main__ - train loss is 6.521944816457108\n",
      "Steps:  16%|▎ | 2366/15000 [15:12<37:33,  5.61it/s, lr=9.96e-6, step_loss=0.175]07/18/2023 19:18:35 - INFO - __main__ - train loss is 6.528301540995017\n",
      "Steps:  16%|▏| 2367/15000 [15:13<37:31,  5.61it/s, lr=9.96e-6, step_loss=0.0063607/18/2023 19:18:35 - INFO - __main__ - train loss is 6.57639491208829\n",
      "Steps:  16%|▏| 2368/15000 [15:13<37:31,  5.61it/s, lr=9.96e-6, step_loss=0.0481]07/18/2023 19:18:35 - INFO - __main__ - train loss is 6.601339787477627\n",
      "Steps:  16%|▏| 2369/15000 [15:13<37:30,  5.61it/s, lr=9.96e-6, step_loss=0.0249]07/18/2023 19:18:35 - INFO - __main__ - train loss is 7.058836430544034\n",
      "Steps:  16%|▎ | 2370/15000 [15:13<37:38,  5.59it/s, lr=9.96e-6, step_loss=0.457]07/18/2023 19:18:35 - INFO - __main__ - train loss is 7.293631434673443\n",
      "Steps:  16%|▎ | 2371/15000 [15:13<37:50,  5.56it/s, lr=9.96e-6, step_loss=0.235]07/18/2023 19:18:36 - INFO - __main__ - train loss is 7.301228199386969\n",
      "Steps:  16%|▏| 2372/15000 [15:14<37:52,  5.56it/s, lr=9.96e-6, step_loss=0.0076]07/18/2023 19:18:36 - INFO - __main__ - train loss is 7.318807060131803\n",
      "Steps:  16%|▏| 2373/15000 [15:14<37:55,  5.55it/s, lr=9.96e-6, step_loss=0.0176]07/18/2023 19:18:36 - INFO - __main__ - train loss is 7.352816807338968\n",
      "Steps:  16%|▎ | 2374/15000 [15:14<37:56,  5.55it/s, lr=9.96e-6, step_loss=0.034]07/18/2023 19:18:36 - INFO - __main__ - train loss is 7.3892759962473065\n",
      "Steps:  16%|▏| 2375/15000 [15:14<37:57,  5.54it/s, lr=9.96e-6, step_loss=0.0365]07/18/2023 19:18:36 - INFO - __main__ - train loss is 7.3908572311047465\n",
      "Steps:  16%|▏| 2376/15000 [15:14<37:57,  5.54it/s, lr=9.96e-6, step_loss=0.0015807/18/2023 19:18:37 - INFO - __main__ - train loss is 7.437730394536629\n",
      "Steps:  16%|▏| 2377/15000 [15:14<37:56,  5.54it/s, lr=9.96e-6, step_loss=0.0469]07/18/2023 19:18:37 - INFO - __main__ - train loss is 7.512113981181756\n",
      "Steps:  16%|▏| 2378/15000 [15:15<37:55,  5.55it/s, lr=9.96e-6, step_loss=0.0744]07/18/2023 19:18:37 - INFO - __main__ - train loss is 8.319695048267022\n",
      "Steps:  16%|▎ | 2379/15000 [15:15<37:56,  5.54it/s, lr=9.96e-6, step_loss=0.808]07/18/2023 19:18:37 - INFO - __main__ - train loss is 8.358362645143643\n",
      "Steps:  16%|▏| 2380/15000 [15:15<38:03,  5.53it/s, lr=9.96e-6, step_loss=0.0387]07/18/2023 19:18:37 - INFO - __main__ - train loss is 8.71619662665762\n",
      "Steps:  16%|▎ | 2381/15000 [15:15<38:32,  5.46it/s, lr=9.96e-6, step_loss=0.358]07/18/2023 19:18:37 - INFO - __main__ - train loss is 8.719949160004035\n",
      "Steps:  16%|▏| 2382/15000 [15:15<38:39,  5.44it/s, lr=9.96e-6, step_loss=0.0037507/18/2023 19:18:38 - INFO - __main__ - train loss is 8.836299319053069\n",
      "Steps:  16%|▎ | 2383/15000 [15:16<38:22,  5.48it/s, lr=9.96e-6, step_loss=0.116]07/18/2023 19:18:38 - INFO - __main__ - train loss is 8.909354958916083\n",
      "Steps:  16%|▏| 2384/15000 [15:16<38:07,  5.51it/s, lr=9.96e-6, step_loss=0.0731]07/18/2023 19:18:38 - INFO - __main__ - train loss is 8.944302376592532\n",
      "Steps:  16%|▏| 2385/15000 [15:16<38:02,  5.53it/s, lr=9.96e-6, step_loss=0.0349]07/18/2023 19:18:38 - INFO - __main__ - train loss is 9.230456199729815\n",
      "Steps:  16%|▎ | 2386/15000 [15:16<37:54,  5.55it/s, lr=9.96e-6, step_loss=0.286]07/18/2023 19:18:38 - INFO - __main__ - train loss is 9.239101784536615\n",
      "Steps:  16%|▏| 2387/15000 [15:16<37:54,  5.55it/s, lr=9.96e-6, step_loss=0.0086507/18/2023 19:18:39 - INFO - __main__ - train loss is 9.46526804775931\n",
      "Steps:  16%|▎ | 2388/15000 [15:16<38:07,  5.51it/s, lr=9.96e-6, step_loss=0.226]07/18/2023 19:18:39 - INFO - __main__ - train loss is 9.48571619973518\n",
      "Steps:  16%|▏| 2389/15000 [15:17<38:17,  5.49it/s, lr=9.96e-6, step_loss=0.0204]07/18/2023 19:18:39 - INFO - __main__ - train loss is 9.489480406278744\n",
      "Steps:  16%|▏| 2390/15000 [15:17<38:09,  5.51it/s, lr=9.96e-6, step_loss=0.0037607/18/2023 19:18:39 - INFO - __main__ - train loss is 9.564263686770573\n",
      "Steps:  16%|▏| 2391/15000 [15:17<38:16,  5.49it/s, lr=9.96e-6, step_loss=0.0748]07/18/2023 19:18:39 - INFO - __main__ - train loss is 9.566764582879841\n",
      "Steps:  16%|▏| 2392/15000 [15:17<38:11,  5.50it/s, lr=9.96e-6, step_loss=0.0025]07/18/2023 19:18:39 - INFO - __main__ - train loss is 9.572411487810314\n",
      "Steps:  16%|▏| 2393/15000 [15:17<38:10,  5.50it/s, lr=9.96e-6, step_loss=0.0056507/18/2023 19:18:40 - INFO - __main__ - train loss is 9.635175372473896\n",
      "Steps:  16%|▏| 2394/15000 [15:17<38:05,  5.52it/s, lr=9.96e-6, step_loss=0.0628]07/18/2023 19:18:40 - INFO - __main__ - train loss is 9.752951408736408\n",
      "Steps:  16%|▎ | 2395/15000 [15:18<38:04,  5.52it/s, lr=9.96e-6, step_loss=0.118]07/18/2023 19:18:40 - INFO - __main__ - train loss is 10.043718065135181\n",
      "Steps:  16%|▎ | 2396/15000 [15:18<38:01,  5.52it/s, lr=9.96e-6, step_loss=0.291]07/18/2023 19:18:40 - INFO - __main__ - train loss is 10.055006100796163\n",
      "Steps:  16%|▏| 2397/15000 [15:18<38:22,  5.47it/s, lr=9.96e-6, step_loss=0.0113]07/18/2023 19:18:40 - INFO - __main__ - train loss is 10.072950773872435\n",
      "Steps:  16%|▏| 2398/15000 [15:18<38:11,  5.50it/s, lr=9.96e-6, step_loss=0.0179]07/18/2023 19:18:41 - INFO - __main__ - train loss is 10.088474240154028\n",
      "Steps:  16%|▏| 2399/15000 [15:18<37:56,  5.54it/s, lr=9.96e-6, step_loss=0.0155]07/18/2023 19:18:41 - INFO - __main__ - train loss is 10.157784711569548\n",
      "Steps:  16%|▏| 2400/15000 [15:19<37:45,  5.56it/s, lr=9.96e-6, step_loss=0.0693]07/18/2023 19:18:41 - INFO - __main__ - train loss is 10.406868945807219\n",
      "Steps:  16%|▎ | 2401/15000 [15:19<37:38,  5.58it/s, lr=9.96e-6, step_loss=0.249]07/18/2023 19:18:41 - INFO - __main__ - train loss is 10.408855796325952\n",
      "Steps:  16%|▏| 2402/15000 [15:19<37:33,  5.59it/s, lr=9.96e-6, step_loss=0.0019907/18/2023 19:18:41 - INFO - __main__ - train loss is 10.684493244159967\n",
      "Steps:  16%|▎ | 2403/15000 [15:19<37:28,  5.60it/s, lr=9.96e-6, step_loss=0.276]07/18/2023 19:18:41 - INFO - __main__ - train loss is 10.799983680713922\n",
      "Steps:  16%|▎ | 2404/15000 [15:19<37:43,  5.56it/s, lr=9.96e-6, step_loss=0.115]07/18/2023 19:18:42 - INFO - __main__ - train loss is 10.814791799057275\n",
      "Steps:  16%|▏| 2405/15000 [15:19<38:04,  5.51it/s, lr=9.96e-6, step_loss=0.0148]07/18/2023 19:18:42 - INFO - __main__ - train loss is 10.895132154691964\n",
      "Steps:  16%|▏| 2406/15000 [15:20<38:05,  5.51it/s, lr=9.96e-6, step_loss=0.0803]07/18/2023 19:18:42 - INFO - __main__ - train loss is 10.918329619336873\n",
      "Steps:  16%|▏| 2407/15000 [15:20<38:31,  5.45it/s, lr=9.96e-6, step_loss=0.0232]07/18/2023 19:18:42 - INFO - __main__ - train loss is 10.990841486025602\n",
      "Steps:  16%|▏| 2408/15000 [15:20<39:07,  5.36it/s, lr=9.96e-6, step_loss=0.0725]07/18/2023 19:18:42 - INFO - __main__ - train loss is 11.030415617395192\n",
      "Steps:  16%|▏| 2409/15000 [15:20<39:57,  5.25it/s, lr=9.96e-6, step_loss=0.0396]07/18/2023 19:18:43 - INFO - __main__ - train loss is 11.034237392246723\n",
      "Steps:  16%|▏| 2410/15000 [15:20<39:23,  5.33it/s, lr=9.96e-6, step_loss=0.0038207/18/2023 19:18:43 - INFO - __main__ - train loss is 11.324204809963703\n",
      "Steps:  16%|▍  | 2411/15000 [15:21<39:29,  5.31it/s, lr=9.96e-6, step_loss=0.29]07/18/2023 19:18:43 - INFO - __main__ - train loss is 11.612977124750614\n",
      "Steps:  16%|▎ | 2412/15000 [15:21<39:51,  5.26it/s, lr=9.96e-6, step_loss=0.289]07/18/2023 19:18:43 - INFO - __main__ - train loss is 11.790295697748661\n",
      "Steps:  16%|▎ | 2413/15000 [15:21<40:03,  5.24it/s, lr=9.96e-6, step_loss=0.177]07/18/2023 19:18:43 - INFO - __main__ - train loss is 11.80561213940382\n",
      "Steps:  16%|▏| 2414/15000 [15:21<40:09,  5.22it/s, lr=9.96e-6, step_loss=0.0153]07/18/2023 19:18:43 - INFO - __main__ - train loss is 11.996399573981762\n",
      "Steps:  16%|▎ | 2415/15000 [15:21<40:15,  5.21it/s, lr=9.96e-6, step_loss=0.191]07/18/2023 19:18:44 - INFO - __main__ - train loss is 12.141273997724056\n",
      "Steps:  16%|▎ | 2416/15000 [15:22<40:05,  5.23it/s, lr=9.96e-6, step_loss=0.145]07/18/2023 19:18:44 - INFO - __main__ - train loss is 12.144514557905495\n",
      "Steps:  16%|▏| 2417/15000 [15:22<39:28,  5.31it/s, lr=9.96e-6, step_loss=0.0032407/18/2023 19:18:44 - INFO - __main__ - train loss is 12.411190626211464\n",
      "Steps:  16%|▎ | 2418/15000 [15:22<38:49,  5.40it/s, lr=9.96e-6, step_loss=0.267]07/18/2023 19:18:44 - INFO - __main__ - train loss is 12.422998924739659\n",
      "Steps:  16%|▏| 2419/15000 [15:22<38:22,  5.46it/s, lr=9.96e-6, step_loss=0.0118]07/18/2023 19:18:44 - INFO - __main__ - train loss is 12.553380687721074\n",
      "Steps:  16%|▍  | 2420/15000 [15:22<38:02,  5.51it/s, lr=9.96e-6, step_loss=0.13]07/18/2023 19:18:45 - INFO - __main__ - train loss is 12.601286162622273\n",
      "Steps:  16%|▏| 2421/15000 [15:22<37:49,  5.54it/s, lr=9.96e-6, step_loss=0.0479]07/18/2023 19:18:45 - INFO - __main__ - train loss is 12.606013515032828\n",
      "Steps:  16%|▏| 2422/15000 [15:23<37:39,  5.57it/s, lr=9.96e-6, step_loss=0.0047307/18/2023 19:18:45 - INFO - __main__ - train loss is 12.870033808983862\n",
      "Steps:  16%|▎ | 2423/15000 [15:23<37:32,  5.58it/s, lr=9.96e-6, step_loss=0.264]07/18/2023 19:18:45 - INFO - __main__ - train loss is 13.454047747887671\n",
      "Steps:  16%|▎ | 2424/15000 [15:23<37:27,  5.60it/s, lr=9.96e-6, step_loss=0.584]07/18/2023 19:18:46 - INFO - __main__ - train loss is 13.594567202962935\n",
      "Steps:  16%|▎ | 2425/15000 [15:23<51:53,  4.04it/s, lr=9.96e-6, step_loss=0.141]07/18/2023 19:18:46 - INFO - __main__ - Per validation step average loss is 0.44777849316596985\n",
      "07/18/2023 19:18:46 - INFO - __main__ - Cumulative validation average loss is 0.44777849316596985\n",
      "07/18/2023 19:18:46 - INFO - __main__ - Per validation step average loss is 0.5053974390029907\n",
      "07/18/2023 19:18:46 - INFO - __main__ - Cumulative validation average loss is 0.9531759321689606\n",
      "07/18/2023 19:18:46 - INFO - __main__ - Per validation step average loss is 0.0076683745719492435\n",
      "07/18/2023 19:18:46 - INFO - __main__ - Cumulative validation average loss is 0.9608443067409098\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Per validation step average loss is 0.08683248609304428\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Cumulative validation average loss is 1.047676792833954\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Per validation step average loss is 0.0025085345841944218\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Cumulative validation average loss is 1.0501853274181485\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Per validation step average loss is 0.08575192093849182\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Cumulative validation average loss is 1.1359372483566403\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Per validation step average loss is 0.003661923110485077\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Cumulative validation average loss is 1.1395991714671254\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Per validation step average loss is 0.0030749565921723843\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Cumulative validation average loss is 1.1426741280592978\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Per validation step average loss is 0.2959291338920593\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Cumulative validation average loss is 1.4386032619513571\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Per validation step average loss is 0.14192265272140503\n",
      "07/18/2023 19:18:47 - INFO - __main__ - Cumulative validation average loss is 1.5805259146727622\n",
      "07/18/2023 19:18:48 - INFO - __main__ - Per validation step average loss is 0.06275470554828644\n",
      "07/18/2023 19:18:48 - INFO - __main__ - Cumulative validation average loss is 1.6432806202210486\n",
      "07/18/2023 19:18:48 - INFO - __main__ - Per validation step average loss is 0.12633395195007324\n",
      "07/18/2023 19:18:48 - INFO - __main__ - Cumulative validation average loss is 1.7696145721711218\n",
      "07/18/2023 19:18:48 - INFO - __main__ - Average validation loss for Epoch 24 is 0.14746788101426014\n",
      "07/18/2023 19:18:48 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:19:01 - INFO - __main__ - Starting epoch 25\n",
      "07/18/2023 19:19:02 - INFO - __main__ - train loss is 0.4451718330383301\n",
      "Steps:  16%|▏| 2426/15000 [15:39<17:24:10,  4.98s/it, lr=9.96e-6, step_loss=0.4407/18/2023 19:19:02 - INFO - __main__ - train loss is 0.5879752337932587\n",
      "Steps:  16%|▏| 2427/15000 [15:40<12:22:28,  3.54s/it, lr=9.96e-6, step_loss=0.1407/18/2023 19:19:02 - INFO - __main__ - train loss is 0.6138001270592213\n",
      "Steps:  16%|▏| 2428/15000 [15:40<8:51:56,  2.54s/it, lr=9.96e-6, step_loss=0.02507/18/2023 19:19:02 - INFO - __main__ - train loss is 0.6171066854149103\n",
      "Steps:  16%|▏| 2429/15000 [15:40<6:25:21,  1.84s/it, lr=9.96e-6, step_loss=0.00307/18/2023 19:19:02 - INFO - __main__ - train loss is 0.6693468559533358\n",
      "Steps:  16%|▏| 2430/15000 [15:40<4:43:46,  1.35s/it, lr=9.96e-6, step_loss=0.05207/18/2023 19:19:03 - INFO - __main__ - train loss is 0.6714926501736045\n",
      "Steps:  16%|▏| 2431/15000 [15:40<3:32:22,  1.01s/it, lr=9.96e-6, step_loss=0.00207/18/2023 19:19:03 - INFO - __main__ - train loss is 0.6881062863394618\n",
      "Steps:  16%|▏| 2432/15000 [15:41<2:42:14,  1.29it/s, lr=9.96e-6, step_loss=0.01607/18/2023 19:19:03 - INFO - __main__ - train loss is 0.6908961469307542\n",
      "Steps:  16%|▏| 2433/15000 [15:41<2:05:26,  1.67it/s, lr=9.96e-6, step_loss=0.00207/18/2023 19:19:03 - INFO - __main__ - train loss is 1.1710307532921433\n",
      "Steps:  16%|▏| 2434/15000 [15:41<1:39:32,  2.10it/s, lr=9.96e-6, step_loss=0.48]07/18/2023 19:19:03 - INFO - __main__ - train loss is 1.1778258420526981\n",
      "Steps:  16%|▏| 2435/15000 [15:41<1:21:11,  2.58it/s, lr=9.96e-6, step_loss=0.00607/18/2023 19:19:04 - INFO - __main__ - train loss is 1.1863199677318335\n",
      "Steps:  16%|▏| 2436/15000 [15:41<1:08:06,  3.07it/s, lr=9.96e-6, step_loss=0.00807/18/2023 19:19:04 - INFO - __main__ - train loss is 1.2151965703815222\n",
      "Steps:  16%|▏| 2437/15000 [15:42<58:50,  3.56it/s, lr=9.96e-6, step_loss=0.0289]07/18/2023 19:19:04 - INFO - __main__ - train loss is 1.429474851116538\n",
      "Steps:  16%|▎ | 2438/15000 [15:42<52:23,  4.00it/s, lr=9.96e-6, step_loss=0.214]07/18/2023 19:19:04 - INFO - __main__ - train loss is 1.5090883951634169\n",
      "Steps:  16%|▏| 2439/15000 [15:42<47:54,  4.37it/s, lr=9.96e-6, step_loss=0.0796]07/18/2023 19:19:04 - INFO - __main__ - train loss is 1.6218068432062864\n",
      "Steps:  16%|▎ | 2440/15000 [15:42<44:40,  4.69it/s, lr=9.96e-6, step_loss=0.113]07/18/2023 19:19:04 - INFO - __main__ - train loss is 1.6842473577708006\n",
      "Steps:  16%|▏| 2441/15000 [15:42<42:24,  4.94it/s, lr=9.96e-6, step_loss=0.0624]07/18/2023 19:19:05 - INFO - __main__ - train loss is 1.6887805350124836\n",
      "Steps:  16%|▏| 2442/15000 [15:42<40:49,  5.13it/s, lr=9.96e-6, step_loss=0.0045307/18/2023 19:19:05 - INFO - __main__ - train loss is 1.6927562518976629\n",
      "Steps:  16%|▏| 2443/15000 [15:43<39:45,  5.26it/s, lr=9.96e-6, step_loss=0.0039807/18/2023 19:19:05 - INFO - __main__ - train loss is 1.7340723215602338\n",
      "Steps:  16%|▏| 2444/15000 [15:43<38:59,  5.37it/s, lr=9.96e-6, step_loss=0.0413]07/18/2023 19:19:05 - INFO - __main__ - train loss is 1.9399368851445615\n",
      "Steps:  16%|▎ | 2445/15000 [15:43<38:28,  5.44it/s, lr=9.96e-6, step_loss=0.206]07/18/2023 19:19:05 - INFO - __main__ - train loss is 2.0420220284722745\n",
      "Steps:  16%|▎ | 2446/15000 [15:43<38:04,  5.49it/s, lr=9.96e-6, step_loss=0.102]07/18/2023 19:19:05 - INFO - __main__ - train loss is 2.2018048404715955\n",
      "Steps:  16%|▍  | 2447/15000 [15:43<37:48,  5.53it/s, lr=9.96e-6, step_loss=0.16]07/18/2023 19:19:06 - INFO - __main__ - train loss is 2.216252268757671\n",
      "Steps:  16%|▏| 2448/15000 [15:44<37:38,  5.56it/s, lr=9.96e-6, step_loss=0.0144]07/18/2023 19:19:06 - INFO - __main__ - train loss is 2.84091687342152\n",
      "Steps:  16%|▎ | 2449/15000 [15:44<37:31,  5.57it/s, lr=9.96e-6, step_loss=0.625]07/18/2023 19:19:06 - INFO - __main__ - train loss is 2.8725745691917837\n",
      "Steps:  16%|▏| 2450/15000 [15:44<37:26,  5.59it/s, lr=9.96e-6, step_loss=0.0317]07/18/2023 19:19:06 - INFO - __main__ - train loss is 2.8875158703885972\n",
      "Steps:  16%|▏| 2451/15000 [15:44<37:21,  5.60it/s, lr=9.96e-6, step_loss=0.0149]07/18/2023 19:19:06 - INFO - __main__ - train loss is 2.916443036403507\n",
      "Steps:  16%|▏| 2452/15000 [15:44<37:20,  5.60it/s, lr=9.96e-6, step_loss=0.0289]07/18/2023 19:19:07 - INFO - __main__ - train loss is 2.9459373555146158\n",
      "Steps:  16%|▏| 2453/15000 [15:44<37:18,  5.61it/s, lr=9.96e-6, step_loss=0.0295]07/18/2023 19:19:07 - INFO - __main__ - train loss is 2.9635295826010406\n",
      "Steps:  16%|▏| 2454/15000 [15:45<37:17,  5.61it/s, lr=9.96e-6, step_loss=0.0176]07/18/2023 19:19:07 - INFO - __main__ - train loss is 3.062271829228848\n",
      "Steps:  16%|▏| 2455/15000 [15:45<37:15,  5.61it/s, lr=9.96e-6, step_loss=0.0987]07/18/2023 19:19:07 - INFO - __main__ - train loss is 3.0696502649225295\n",
      "Steps:  16%|▏| 2456/15000 [15:45<37:15,  5.61it/s, lr=9.96e-6, step_loss=0.0073807/18/2023 19:19:07 - INFO - __main__ - train loss is 3.075258817989379\n",
      "Steps:  16%|▏| 2457/15000 [15:45<37:12,  5.62it/s, lr=9.96e-6, step_loss=0.0056107/18/2023 19:19:07 - INFO - __main__ - train loss is 3.610388603527099\n",
      "Steps:  16%|▎ | 2458/15000 [15:45<37:13,  5.62it/s, lr=9.96e-6, step_loss=0.535]07/18/2023 19:19:08 - INFO - __main__ - train loss is 3.7606256273575127\n",
      "Steps:  16%|▍  | 2459/15000 [15:46<37:11,  5.62it/s, lr=9.96e-6, step_loss=0.15]07/18/2023 19:19:08 - INFO - __main__ - train loss is 3.8357512396760285\n",
      "Steps:  16%|▏| 2460/15000 [15:46<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.0751]07/18/2023 19:19:08 - INFO - __main__ - train loss is 4.470795337576419\n",
      "Steps:  16%|▎ | 2461/15000 [15:46<37:11,  5.62it/s, lr=9.96e-6, step_loss=0.635]07/18/2023 19:19:08 - INFO - __main__ - train loss is 4.52452888013795\n",
      "Steps:  16%|▏| 2462/15000 [15:46<37:11,  5.62it/s, lr=9.96e-6, step_loss=0.0537]07/18/2023 19:19:08 - INFO - __main__ - train loss is 4.527480631601065\n",
      "Steps:  16%|▏| 2463/15000 [15:46<37:12,  5.62it/s, lr=9.96e-6, step_loss=0.0029507/18/2023 19:19:09 - INFO - __main__ - train loss is 4.63141182763502\n",
      "Steps:  16%|▎ | 2464/15000 [15:46<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.104]07/18/2023 19:19:09 - INFO - __main__ - train loss is 4.865155197214335\n",
      "Steps:  16%|▎ | 2465/15000 [15:47<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.234]07/18/2023 19:19:09 - INFO - __main__ - train loss is 5.244301117490977\n",
      "Steps:  16%|▎ | 2466/15000 [15:47<37:09,  5.62it/s, lr=9.96e-6, step_loss=0.379]07/18/2023 19:19:09 - INFO - __main__ - train loss is 5.842327512335032\n",
      "Steps:  16%|▎ | 2467/15000 [15:47<37:08,  5.62it/s, lr=9.96e-6, step_loss=0.598]07/18/2023 19:19:09 - INFO - __main__ - train loss is 5.929372921120375\n",
      "Steps:  16%|▎ | 2468/15000 [15:47<37:09,  5.62it/s, lr=9.96e-6, step_loss=0.087]07/18/2023 19:19:09 - INFO - __main__ - train loss is 6.005502253305167\n",
      "Steps:  16%|▏| 2469/15000 [15:47<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.0761]07/18/2023 19:19:10 - INFO - __main__ - train loss is 6.2754486496560276\n",
      "Steps:  16%|▍  | 2470/15000 [15:47<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.27]07/18/2023 19:19:10 - INFO - __main__ - train loss is 6.278937792405486\n",
      "Steps:  16%|▏| 2471/15000 [15:48<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.0034907/18/2023 19:19:10 - INFO - __main__ - train loss is 6.293531442061067\n",
      "Steps:  16%|▏| 2472/15000 [15:48<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.0146]07/18/2023 19:19:10 - INFO - __main__ - train loss is 6.306122470647097\n",
      "Steps:  16%|▏| 2473/15000 [15:48<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.0126]07/18/2023 19:19:10 - INFO - __main__ - train loss is 6.357910823076963\n",
      "Steps:  16%|▏| 2474/15000 [15:48<37:10,  5.62it/s, lr=9.96e-6, step_loss=0.0518]07/18/2023 19:19:10 - INFO - __main__ - train loss is 6.366070324555039\n",
      "Steps:  16%|▏| 2475/15000 [15:48<37:09,  5.62it/s, lr=9.96e-6, step_loss=0.0081607/18/2023 19:19:11 - INFO - __main__ - train loss is 6.436081016436219\n",
      "Steps:  17%|▍  | 2476/15000 [15:49<37:10,  5.61it/s, lr=9.96e-6, step_loss=0.07]07/18/2023 19:19:11 - INFO - __main__ - train loss is 6.53486361540854\n",
      "Steps:  17%|▏| 2477/15000 [15:49<37:09,  5.62it/s, lr=9.96e-6, step_loss=0.0988]07/18/2023 19:19:11 - INFO - __main__ - train loss is 6.536621091887355\n",
      "Steps:  17%|▏| 2478/15000 [15:49<37:08,  5.62it/s, lr=9.96e-6, step_loss=0.0017607/18/2023 19:19:11 - INFO - __main__ - train loss is 6.792091159150004\n",
      "Steps:  17%|▎ | 2479/15000 [15:49<37:08,  5.62it/s, lr=9.96e-6, step_loss=0.255]07/18/2023 19:19:11 - INFO - __main__ - train loss is 7.539175180718303\n",
      "Steps:  17%|▎ | 2480/15000 [15:49<37:08,  5.62it/s, lr=9.96e-6, step_loss=0.747]07/18/2023 19:19:12 - INFO - __main__ - train loss is 7.715039221569896\n",
      "Steps:  17%|▎ | 2481/15000 [15:49<37:08,  5.62it/s, lr=9.96e-6, step_loss=0.176]07/18/2023 19:19:12 - INFO - __main__ - train loss is 7.7198237823322415\n",
      "Steps:  17%|▏| 2482/15000 [15:50<37:09,  5.61it/s, lr=9.96e-6, step_loss=0.0047807/18/2023 19:19:12 - INFO - __main__ - train loss is 7.814950671978295\n",
      "Steps:  17%|▏| 2483/15000 [15:50<37:08,  5.62it/s, lr=9.96e-6, step_loss=0.0951]07/18/2023 19:19:12 - INFO - __main__ - train loss is 7.821682033129036\n",
      "Steps:  17%|▏| 2484/15000 [15:50<37:08,  5.62it/s, lr=9.96e-6, step_loss=0.0067307/18/2023 19:19:12 - INFO - __main__ - train loss is 7.83304888010025\n",
      "Steps:  17%|▏| 2485/15000 [15:50<37:09,  5.61it/s, lr=9.96e-6, step_loss=0.0114]07/18/2023 19:19:12 - INFO - __main__ - train loss is 8.211933612823486\n",
      "Steps:  17%|▎ | 2486/15000 [15:50<37:09,  5.61it/s, lr=9.96e-6, step_loss=0.379]07/18/2023 19:19:13 - INFO - __main__ - train loss is 8.213449476053938\n",
      "Steps:  17%|▏| 2487/15000 [15:51<37:07,  5.62it/s, lr=9.96e-6, step_loss=0.0015207/18/2023 19:19:13 - INFO - __main__ - train loss is 8.217316079884768\n",
      "Steps:  17%|▏| 2488/15000 [15:51<37:07,  5.62it/s, lr=9.96e-6, step_loss=0.0038707/18/2023 19:19:13 - INFO - __main__ - train loss is 8.581236768513918\n",
      "Steps:  17%|▎ | 2489/15000 [15:51<37:09,  5.61it/s, lr=9.96e-6, step_loss=0.364]07/18/2023 19:19:13 - INFO - __main__ - train loss is 8.586694564204663\n",
      "Steps:  17%|▏| 2490/15000 [15:51<37:09,  5.61it/s, lr=9.96e-6, step_loss=0.0054607/18/2023 19:19:13 - INFO - __main__ - train loss is 8.990542377810925\n",
      "Steps:  17%|▎ | 2491/15000 [15:51<37:09,  5.61it/s, lr=9.96e-6, step_loss=0.404]07/18/2023 19:19:14 - INFO - __main__ - train loss is 8.992187875322998\n",
      "Steps:  17%|▏| 2492/15000 [15:51<37:08,  5.61it/s, lr=9.96e-6, step_loss=0.0016507/18/2023 19:19:14 - INFO - __main__ - train loss is 9.045403278432786\n",
      "Steps:  17%|▏| 2493/15000 [15:52<37:09,  5.61it/s, lr=9.96e-6, step_loss=0.0532]07/18/2023 19:19:14 - INFO - __main__ - train loss is 9.04798122565262\n",
      "Steps:  17%|▏| 2494/15000 [15:52<37:08,  5.61it/s, lr=9.96e-6, step_loss=0.0025807/18/2023 19:19:14 - INFO - __main__ - train loss is 9.244732671184465\n",
      "Steps:  17%|▎ | 2495/15000 [15:52<37:10,  5.61it/s, lr=9.96e-6, step_loss=0.197]07/18/2023 19:19:14 - INFO - __main__ - train loss is 9.402173214359209\n",
      "Steps:  17%|▎ | 2496/15000 [15:52<37:08,  5.61it/s, lr=9.96e-6, step_loss=0.157]07/18/2023 19:19:14 - INFO - __main__ - train loss is 9.569404833717272\n",
      "Steps:  17%|▎ | 2497/15000 [15:52<37:06,  5.62it/s, lr=9.96e-6, step_loss=0.167]07/18/2023 19:19:15 - INFO - __main__ - train loss is 9.723171257181093\n",
      "Steps:  17%|▎ | 2498/15000 [15:52<37:07,  5.61it/s, lr=9.96e-6, step_loss=0.154]07/18/2023 19:19:15 - INFO - __main__ - train loss is 10.018400960369036\n",
      "Steps:  17%|▎ | 2499/15000 [15:53<37:07,  5.61it/s, lr=9.96e-6, step_loss=0.295]07/18/2023 19:19:15 - INFO - __main__ - train loss is 10.039674550993368\n",
      "Steps:  17%|▎ | 2500/15000 [15:53<37:07,  5.61it/s, lr=9.96e-6, step_loss=0.295]07/18/2023 19:19:15 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-2500\n",
      "07/18/2023 19:19:15 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:19:15,521] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:19:15,525] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:19:15,525] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:19:15,532] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:19:15,533] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:19:15,552] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:19:15,558] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:19:15,558] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:19:15 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-2500/pytorch_model\n",
      "07/18/2023 19:19:15 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-2500/scheduler.bin\n",
      "07/18/2023 19:19:15 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-2500/random_states_0.pkl\n",
      "07/18/2023 19:19:15 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-2500\n",
      "Steps:  17%|▏| 2500/15000 [15:53<37:07,  5.61it/s, lr=9.96e-6, step_loss=0.0213]07/18/2023 19:19:15 - INFO - __main__ - train loss is 10.051240142202005\n",
      "Steps:  17%|▏| 2501/15000 [15:53<39:34,  5.26it/s, lr=9.96e-6, step_loss=0.0116]07/18/2023 19:19:15 - INFO - __main__ - train loss is 10.053911647060886\n",
      "Steps:  17%|▏| 2502/15000 [15:53<38:48,  5.37it/s, lr=9.96e-6, step_loss=0.0026707/18/2023 19:19:16 - INFO - __main__ - train loss is 10.126253029564396\n",
      "Steps:  17%|▏| 2503/15000 [15:53<38:17,  5.44it/s, lr=9.96e-6, step_loss=0.0723]07/18/2023 19:19:16 - INFO - __main__ - train loss is 10.131587306270376\n",
      "Steps:  17%|▏| 2504/15000 [15:54<37:55,  5.49it/s, lr=9.96e-6, step_loss=0.0053307/18/2023 19:19:16 - INFO - __main__ - train loss is 10.359490538248792\n",
      "Steps:  17%|▎ | 2505/15000 [15:54<37:39,  5.53it/s, lr=9.96e-6, step_loss=0.228]07/18/2023 19:19:16 - INFO - __main__ - train loss is 10.45606123865582\n",
      "Steps:  17%|▏| 2506/15000 [15:54<37:27,  5.56it/s, lr=9.96e-6, step_loss=0.0966]07/18/2023 19:19:16 - INFO - __main__ - train loss is 10.621989319333807\n",
      "Steps:  17%|▎ | 2507/15000 [15:54<37:17,  5.58it/s, lr=9.96e-6, step_loss=0.166]07/18/2023 19:19:16 - INFO - __main__ - train loss is 10.994383434066549\n",
      "Steps:  17%|▎ | 2508/15000 [15:54<37:11,  5.60it/s, lr=9.96e-6, step_loss=0.372]07/18/2023 19:19:17 - INFO - __main__ - train loss is 11.13595355511643\n",
      "Steps:  17%|▎ | 2509/15000 [15:54<37:05,  5.61it/s, lr=9.96e-6, step_loss=0.142]07/18/2023 19:19:17 - INFO - __main__ - train loss is 11.254574591526762\n",
      "Steps:  17%|▎ | 2510/15000 [15:55<37:07,  5.61it/s, lr=9.96e-6, step_loss=0.119]07/18/2023 19:19:17 - INFO - __main__ - train loss is 11.42348506511189\n",
      "Steps:  17%|▎ | 2511/15000 [15:55<37:21,  5.57it/s, lr=9.96e-6, step_loss=0.169]07/18/2023 19:19:17 - INFO - __main__ - train loss is 11.641495580086485\n",
      "Steps:  17%|▎ | 2512/15000 [15:55<37:36,  5.54it/s, lr=9.96e-6, step_loss=0.218]07/18/2023 19:19:17 - INFO - __main__ - train loss is 11.644655757583678\n",
      "Steps:  17%|▏| 2513/15000 [15:55<37:51,  5.50it/s, lr=9.96e-6, step_loss=0.0031607/18/2023 19:19:17 - INFO - __main__ - train loss is 11.648398332996294\n",
      "Steps:  17%|▏| 2514/15000 [15:55<37:50,  5.50it/s, lr=9.96e-6, step_loss=0.0037407/18/2023 19:19:18 - INFO - __main__ - train loss is 11.742953696055338\n",
      "Steps:  17%|▏| 2515/15000 [15:56<37:45,  5.51it/s, lr=9.96e-6, step_loss=0.0946]07/18/2023 19:19:18 - INFO - __main__ - train loss is 11.810765512986109\n",
      "Steps:  17%|▏| 2516/15000 [15:56<37:31,  5.54it/s, lr=9.96e-6, step_loss=0.0678]07/18/2023 19:19:18 - INFO - __main__ - train loss is 12.204978176159784\n",
      "Steps:  17%|▎ | 2517/15000 [15:56<37:22,  5.57it/s, lr=9.96e-6, step_loss=0.394]07/18/2023 19:19:18 - INFO - __main__ - train loss is 12.218586268601939\n",
      "Steps:  17%|▏| 2518/15000 [15:56<37:15,  5.58it/s, lr=9.96e-6, step_loss=0.0136]07/18/2023 19:19:18 - INFO - __main__ - train loss is 12.278805798618123\n",
      "Steps:  17%|▏| 2519/15000 [15:56<37:10,  5.59it/s, lr=9.96e-6, step_loss=0.0602]07/18/2023 19:19:19 - INFO - __main__ - train loss is 12.28021321061533\n",
      "Steps:  17%|▏| 2520/15000 [15:56<37:05,  5.61it/s, lr=9.96e-6, step_loss=0.0014107/18/2023 19:19:19 - INFO - __main__ - train loss is 12.365385744604282\n",
      "Steps:  17%|▏| 2521/15000 [15:57<37:03,  5.61it/s, lr=9.96e-6, step_loss=0.0852]07/18/2023 19:19:19 - INFO - __main__ - train loss is 12.398417986813001\n",
      "Steps:  17%|▎ | 2522/15000 [15:57<49:29,  4.20it/s, lr=9.96e-6, step_loss=0.033]07/18/2023 19:19:20 - INFO - __main__ - Per validation step average loss is 0.4897919297218323\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Cumulative validation average loss is 0.4897919297218323\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Per validation step average loss is 0.2398795485496521\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Cumulative validation average loss is 0.7296714782714844\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Per validation step average loss is 0.11902663856744766\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Cumulative validation average loss is 0.848698116838932\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Per validation step average loss is 0.027459925040602684\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Cumulative validation average loss is 0.8761580418795347\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Per validation step average loss is 0.24547606706619263\n",
      "07/18/2023 19:19:20 - INFO - __main__ - Cumulative validation average loss is 1.1216341089457273\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Per validation step average loss is 0.04050996154546738\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Cumulative validation average loss is 1.1621440704911947\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Per validation step average loss is 0.07594402134418488\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Cumulative validation average loss is 1.2380880918353796\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Per validation step average loss is 0.6306043863296509\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Cumulative validation average loss is 1.8686924781650305\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Per validation step average loss is 0.21109619736671448\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Cumulative validation average loss is 2.079788675531745\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Per validation step average loss is 0.031394295394420624\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Cumulative validation average loss is 2.1111829709261656\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Per validation step average loss is 0.017814286053180695\n",
      "07/18/2023 19:19:21 - INFO - __main__ - Cumulative validation average loss is 2.1289972569793463\n",
      "07/18/2023 19:19:22 - INFO - __main__ - Per validation step average loss is 0.001372824888676405\n",
      "07/18/2023 19:19:22 - INFO - __main__ - Cumulative validation average loss is 2.1303700818680227\n",
      "07/18/2023 19:19:22 - INFO - __main__ - Average validation loss for Epoch 25 is 0.17753084015566856\n",
      "07/18/2023 19:19:22 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:19:34 - INFO - __main__ - Starting epoch 26\n",
      "07/18/2023 19:19:35 - INFO - __main__ - train loss is 0.20370957255363464\n",
      "Steps:  17%|▏| 2523/15000 [16:13<16:51:19,  4.86s/it, lr=9.96e-6, step_loss=0.2007/18/2023 19:19:35 - INFO - __main__ - train loss is 0.21141708176583052\n",
      "Steps:  17%|▏| 2524/15000 [16:13<11:59:01,  3.46s/it, lr=9.96e-6, step_loss=0.0007/18/2023 19:19:35 - INFO - __main__ - train loss is 0.3546547619625926\n",
      "Steps:  17%|▏| 2525/15000 [16:13<8:34:23,  2.47s/it, lr=9.96e-6, step_loss=0.14307/18/2023 19:19:35 - INFO - __main__ - train loss is 0.40703589003533125\n",
      "Steps:  17%|▏| 2526/15000 [16:13<6:11:26,  1.79s/it, lr=9.96e-6, step_loss=0.05207/18/2023 19:19:35 - INFO - __main__ - train loss is 0.43246078956872225\n",
      "Steps:  17%|▏| 2527/15000 [16:13<4:31:18,  1.31s/it, lr=9.96e-6, step_loss=0.02507/18/2023 19:19:36 - INFO - __main__ - train loss is 0.7158509539440274\n",
      "Steps:  17%|▏| 2528/15000 [16:14<3:21:03,  1.03it/s, lr=9.96e-6, step_loss=0.28307/18/2023 19:19:36 - INFO - __main__ - train loss is 0.7220083754509687\n",
      "Steps:  17%|▏| 2529/15000 [16:14<2:31:51,  1.37it/s, lr=9.96e-6, step_loss=0.00607/18/2023 19:19:36 - INFO - __main__ - train loss is 0.7817107420414686\n",
      "Steps:  17%|▏| 2530/15000 [16:14<1:57:22,  1.77it/s, lr=9.96e-6, step_loss=0.05907/18/2023 19:19:36 - INFO - __main__ - train loss is 1.1921512763947248\n",
      "Steps:  17%|▏| 2531/15000 [16:14<1:33:14,  2.23it/s, lr=9.96e-6, step_loss=0.41]07/18/2023 19:19:36 - INFO - __main__ - train loss is 1.200687400996685\n",
      "Steps:  17%|▏| 2532/15000 [16:14<1:16:20,  2.72it/s, lr=9.96e-6, step_loss=0.00807/18/2023 19:19:37 - INFO - __main__ - train loss is 1.4042418226599693\n",
      "Steps:  17%|▏| 2533/15000 [16:14<1:04:31,  3.22it/s, lr=9.96e-6, step_loss=0.20407/18/2023 19:19:37 - INFO - __main__ - train loss is 1.4062791946344078\n",
      "Steps:  17%|▏| 2534/15000 [16:15<56:14,  3.69it/s, lr=9.96e-6, step_loss=0.0020407/18/2023 19:19:37 - INFO - __main__ - train loss is 1.5305114048533142\n",
      "Steps:  17%|▎ | 2535/15000 [16:15<50:50,  4.09it/s, lr=9.96e-6, step_loss=0.124]07/18/2023 19:19:37 - INFO - __main__ - train loss is 1.6502989488653839\n",
      "Steps:  17%|▌  | 2536/15000 [16:15<47:11,  4.40it/s, lr=9.96e-6, step_loss=0.12]07/18/2023 19:19:37 - INFO - __main__ - train loss is 1.7072728308849037\n",
      "Steps:  17%|▎ | 2537/15000 [16:15<44:15,  4.69it/s, lr=9.96e-6, step_loss=0.057]07/18/2023 19:19:37 - INFO - __main__ - train loss is 1.7716856780461967\n",
      "Steps:  17%|▏| 2538/15000 [16:15<42:03,  4.94it/s, lr=9.96e-6, step_loss=0.0644]07/18/2023 19:19:38 - INFO - __main__ - train loss is 1.861171844881028\n",
      "Steps:  17%|▏| 2539/15000 [16:16<40:51,  5.08it/s, lr=9.96e-6, step_loss=0.0895]07/18/2023 19:19:38 - INFO - __main__ - train loss is 1.8661580462940037\n",
      "Steps:  17%|▏| 2540/15000 [16:16<39:49,  5.21it/s, lr=9.96e-6, step_loss=0.0049907/18/2023 19:19:38 - INFO - __main__ - train loss is 1.9015905712731183\n",
      "Steps:  17%|▏| 2541/15000 [16:16<39:13,  5.29it/s, lr=9.96e-6, step_loss=0.0354]07/18/2023 19:19:38 - INFO - __main__ - train loss is 2.32213829504326\n",
      "Steps:  17%|▎ | 2542/15000 [16:16<38:52,  5.34it/s, lr=9.96e-6, step_loss=0.421]07/18/2023 19:19:38 - INFO - __main__ - train loss is 2.554632887709886\n",
      "Steps:  17%|▎ | 2543/15000 [16:16<38:25,  5.40it/s, lr=9.96e-6, step_loss=0.232]07/18/2023 19:19:39 - INFO - __main__ - train loss is 2.9141914998181164\n",
      "Steps:  17%|▌  | 2544/15000 [16:16<38:19,  5.42it/s, lr=9.96e-6, step_loss=0.36]07/18/2023 19:19:39 - INFO - __main__ - train loss is 2.921332216821611\n",
      "Steps:  17%|▏| 2545/15000 [16:17<38:16,  5.42it/s, lr=9.96e-6, step_loss=0.0071407/18/2023 19:19:39 - INFO - __main__ - train loss is 3.020398817025125\n",
      "Steps:  17%|▏| 2546/15000 [16:17<38:14,  5.43it/s, lr=9.96e-6, step_loss=0.0991]07/18/2023 19:19:39 - INFO - __main__ - train loss is 3.670863709412515\n",
      "Steps:  17%|▌  | 2547/15000 [16:17<37:58,  5.46it/s, lr=9.96e-6, step_loss=0.65]07/18/2023 19:19:39 - INFO - __main__ - train loss is 3.7739106183871627\n",
      "Steps:  17%|▎ | 2548/15000 [16:17<37:41,  5.51it/s, lr=9.96e-6, step_loss=0.103]07/18/2023 19:19:39 - INFO - __main__ - train loss is 3.7878830367699265\n",
      "Steps:  17%|▎ | 2549/15000 [16:17<37:41,  5.50it/s, lr=9.96e-6, step_loss=0.014]07/18/2023 19:19:40 - INFO - __main__ - train loss is 3.89937621448189\n",
      "Steps:  17%|▎ | 2550/15000 [16:18<37:29,  5.53it/s, lr=9.96e-6, step_loss=0.111]07/18/2023 19:19:40 - INFO - __main__ - train loss is 4.604814470745623\n",
      "Steps:  17%|▎ | 2551/15000 [16:18<37:42,  5.50it/s, lr=9.96e-6, step_loss=0.705]07/18/2023 19:19:40 - INFO - __main__ - train loss is 4.908126355148852\n",
      "Steps:  17%|▎ | 2552/15000 [16:18<37:36,  5.52it/s, lr=9.96e-6, step_loss=0.303]07/18/2023 19:19:40 - INFO - __main__ - train loss is 4.926573031581938\n",
      "Steps:  17%|▏| 2553/15000 [16:18<37:24,  5.55it/s, lr=9.96e-6, step_loss=0.0184]07/18/2023 19:19:40 - INFO - __main__ - train loss is 5.214829468168318\n",
      "Steps:  17%|▎ | 2554/15000 [16:18<37:16,  5.56it/s, lr=9.96e-6, step_loss=0.288]07/18/2023 19:19:41 - INFO - __main__ - train loss is 5.235260064713657\n",
      "Steps:  17%|▏| 2555/15000 [16:18<37:11,  5.58it/s, lr=9.96e-6, step_loss=0.0204]07/18/2023 19:19:41 - INFO - __main__ - train loss is 5.25138100143522\n",
      "Steps:  17%|▏| 2556/15000 [16:19<37:07,  5.59it/s, lr=9.96e-6, step_loss=0.0161]07/18/2023 19:19:41 - INFO - __main__ - train loss is 5.4932336723431945\n",
      "Steps:  17%|▎ | 2557/15000 [16:19<37:05,  5.59it/s, lr=9.96e-6, step_loss=0.242]07/18/2023 19:19:41 - INFO - __main__ - train loss is 5.503192761912942\n",
      "Steps:  17%|▏| 2558/15000 [16:19<37:03,  5.59it/s, lr=9.96e-6, step_loss=0.0099607/18/2023 19:19:41 - INFO - __main__ - train loss is 5.619565764442086\n",
      "Steps:  17%|▎ | 2559/15000 [16:19<37:17,  5.56it/s, lr=9.96e-6, step_loss=0.116]07/18/2023 19:19:41 - INFO - __main__ - train loss is 5.654379906132817\n",
      "Steps:  17%|▏| 2560/15000 [16:19<37:37,  5.51it/s, lr=9.96e-6, step_loss=0.0348]07/18/2023 19:19:42 - INFO - __main__ - train loss is 5.658717826008797\n",
      "Steps:  17%|▏| 2561/15000 [16:20<37:59,  5.46it/s, lr=9.96e-6, step_loss=0.0043407/18/2023 19:19:42 - INFO - __main__ - train loss is 6.0274530202150345\n",
      "Steps:  17%|▎ | 2562/15000 [16:20<38:23,  5.40it/s, lr=9.96e-6, step_loss=0.369]07/18/2023 19:19:42 - INFO - __main__ - train loss is 6.188246950507164\n",
      "Steps:  17%|▎ | 2563/15000 [16:20<38:53,  5.33it/s, lr=9.96e-6, step_loss=0.161]07/18/2023 19:19:42 - INFO - __main__ - train loss is 6.4840250462293625\n",
      "Steps:  17%|▎ | 2564/15000 [16:20<38:53,  5.33it/s, lr=9.96e-6, step_loss=0.296]07/18/2023 19:19:42 - INFO - __main__ - train loss is 6.62417171895504\n",
      "Steps:  17%|▌  | 2565/15000 [16:20<38:28,  5.39it/s, lr=9.96e-6, step_loss=0.14]07/18/2023 19:19:43 - INFO - __main__ - train loss is 6.873514547944069\n",
      "Steps:  17%|▎ | 2566/15000 [16:20<38:53,  5.33it/s, lr=9.96e-6, step_loss=0.249]07/18/2023 19:19:43 - INFO - __main__ - train loss is 7.215224102139473\n",
      "Steps:  17%|▎ | 2567/15000 [16:21<39:17,  5.27it/s, lr=9.96e-6, step_loss=0.342]07/18/2023 19:19:43 - INFO - __main__ - train loss is 7.218404450919479\n",
      "Steps:  17%|▏| 2568/15000 [16:21<39:27,  5.25it/s, lr=9.96e-6, step_loss=0.0031807/18/2023 19:19:43 - INFO - __main__ - train loss is 7.2700484856031835\n",
      "Steps:  17%|▏| 2569/15000 [16:21<39:34,  5.24it/s, lr=9.96e-6, step_loss=0.0516]07/18/2023 19:19:43 - INFO - __main__ - train loss is 7.289768998976797\n",
      "Steps:  17%|▏| 2570/15000 [16:21<39:43,  5.22it/s, lr=9.96e-6, step_loss=0.0197]07/18/2023 19:19:44 - INFO - __main__ - train loss is 7.653851096983999\n",
      "Steps:  17%|▎ | 2571/15000 [16:21<39:45,  5.21it/s, lr=9.96e-6, step_loss=0.364]07/18/2023 19:19:44 - INFO - __main__ - train loss is 7.668409780133516\n",
      "Steps:  17%|▏| 2572/15000 [16:22<39:48,  5.20it/s, lr=9.96e-6, step_loss=0.0146]07/18/2023 19:19:44 - INFO - __main__ - train loss is 8.186390296090394\n",
      "Steps:  17%|▎ | 2573/15000 [16:22<39:27,  5.25it/s, lr=9.96e-6, step_loss=0.518]07/18/2023 19:19:44 - INFO - __main__ - train loss is 8.207818782422692\n",
      "Steps:  17%|▏| 2574/15000 [16:22<39:05,  5.30it/s, lr=9.96e-6, step_loss=0.0214]07/18/2023 19:19:44 - INFO - __main__ - train loss is 8.22863218234852\n",
      "Steps:  17%|▏| 2575/15000 [16:22<38:34,  5.37it/s, lr=9.96e-6, step_loss=0.0208]07/18/2023 19:19:44 - INFO - __main__ - train loss is 8.562204450834543\n",
      "Steps:  17%|▎ | 2576/15000 [16:22<38:02,  5.44it/s, lr=9.96e-6, step_loss=0.334]07/18/2023 19:19:45 - INFO - __main__ - train loss is 8.790468246210366\n",
      "Steps:  17%|▎ | 2577/15000 [16:23<37:41,  5.49it/s, lr=9.95e-6, step_loss=0.228]07/18/2023 19:19:45 - INFO - __main__ - train loss is 8.797617961652577\n",
      "Steps:  17%|▏| 2578/15000 [16:23<37:25,  5.53it/s, lr=9.95e-6, step_loss=0.0071507/18/2023 19:19:45 - INFO - __main__ - train loss is 8.800149659160525\n",
      "Steps:  17%|▏| 2579/15000 [16:23<37:16,  5.55it/s, lr=9.95e-6, step_loss=0.0025307/18/2023 19:19:45 - INFO - __main__ - train loss is 9.030973995570093\n",
      "Steps:  17%|▎ | 2580/15000 [16:23<37:08,  5.57it/s, lr=9.95e-6, step_loss=0.231]07/18/2023 19:19:45 - INFO - __main__ - train loss is 9.067937309388071\n",
      "Steps:  17%|▎ | 2581/15000 [16:23<37:01,  5.59it/s, lr=9.95e-6, step_loss=0.037]07/18/2023 19:19:46 - INFO - __main__ - train loss is 9.294735173229128\n",
      "Steps:  17%|▎ | 2582/15000 [16:23<37:04,  5.58it/s, lr=9.95e-6, step_loss=0.227]07/18/2023 19:19:46 - INFO - __main__ - train loss is 9.30194418830797\n",
      "Steps:  17%|▏| 2583/15000 [16:24<37:02,  5.59it/s, lr=9.95e-6, step_loss=0.0072107/18/2023 19:19:46 - INFO - __main__ - train loss is 9.3296203087084\n",
      "Steps:  17%|▏| 2584/15000 [16:24<37:01,  5.59it/s, lr=9.95e-6, step_loss=0.0277]07/18/2023 19:19:46 - INFO - __main__ - train loss is 9.38259320659563\n",
      "Steps:  17%|▎ | 2585/15000 [16:24<36:58,  5.60it/s, lr=9.95e-6, step_loss=0.053]07/18/2023 19:19:46 - INFO - __main__ - train loss is 9.521335593890399\n",
      "Steps:  17%|▎ | 2586/15000 [16:24<36:59,  5.59it/s, lr=9.95e-6, step_loss=0.139]07/18/2023 19:19:46 - INFO - __main__ - train loss is 9.524131736252457\n",
      "Steps:  17%|▏| 2587/15000 [16:24<36:59,  5.59it/s, lr=9.95e-6, step_loss=0.0028]07/18/2023 19:19:47 - INFO - __main__ - train loss is 9.601751929614693\n",
      "Steps:  17%|▏| 2588/15000 [16:24<37:00,  5.59it/s, lr=9.95e-6, step_loss=0.0776]07/18/2023 19:19:47 - INFO - __main__ - train loss is 9.620447606313974\n",
      "Steps:  17%|▏| 2589/15000 [16:25<36:58,  5.59it/s, lr=9.95e-6, step_loss=0.0187]07/18/2023 19:19:47 - INFO - __main__ - train loss is 10.203153640497476\n",
      "Steps:  17%|▎ | 2590/15000 [16:25<36:55,  5.60it/s, lr=9.95e-6, step_loss=0.583]07/18/2023 19:19:47 - INFO - __main__ - train loss is 10.352941394317895\n",
      "Steps:  17%|▌  | 2591/15000 [16:25<36:54,  5.60it/s, lr=9.95e-6, step_loss=0.15]07/18/2023 19:19:47 - INFO - __main__ - train loss is 10.497157723177224\n",
      "Steps:  17%|▎ | 2592/15000 [16:25<36:57,  5.59it/s, lr=9.95e-6, step_loss=0.144]07/18/2023 19:19:47 - INFO - __main__ - train loss is 10.590302110183984\n",
      "Steps:  17%|▏| 2593/15000 [16:25<36:57,  5.60it/s, lr=9.95e-6, step_loss=0.0931]07/18/2023 19:19:48 - INFO - __main__ - train loss is 10.64111190335825\n",
      "Steps:  17%|▏| 2594/15000 [16:26<37:04,  5.58it/s, lr=9.95e-6, step_loss=0.0508]07/18/2023 19:19:48 - INFO - __main__ - train loss is 10.758647270966321\n",
      "Steps:  17%|▎ | 2595/15000 [16:26<37:01,  5.58it/s, lr=9.95e-6, step_loss=0.118]07/18/2023 19:19:48 - INFO - __main__ - train loss is 10.824813299346715\n",
      "Steps:  17%|▏| 2596/15000 [16:26<37:00,  5.59it/s, lr=9.95e-6, step_loss=0.0662]07/18/2023 19:19:48 - INFO - __main__ - train loss is 10.954146303702146\n",
      "Steps:  17%|▎ | 2597/15000 [16:26<36:58,  5.59it/s, lr=9.95e-6, step_loss=0.129]07/18/2023 19:19:48 - INFO - __main__ - train loss is 10.962466410826892\n",
      "Steps:  17%|▏| 2598/15000 [16:26<36:57,  5.59it/s, lr=9.95e-6, step_loss=0.0083207/18/2023 19:19:49 - INFO - __main__ - train loss is 10.973061380442232\n",
      "Steps:  17%|▏| 2599/15000 [16:26<36:56,  5.60it/s, lr=9.95e-6, step_loss=0.0106]07/18/2023 19:19:49 - INFO - __main__ - train loss is 11.00782355805859\n",
      "Steps:  17%|▏| 2600/15000 [16:27<36:55,  5.60it/s, lr=9.95e-6, step_loss=0.0348]07/18/2023 19:19:49 - INFO - __main__ - train loss is 11.009631101507694\n",
      "Steps:  17%|▏| 2601/15000 [16:27<36:54,  5.60it/s, lr=9.95e-6, step_loss=0.0018107/18/2023 19:19:49 - INFO - __main__ - train loss is 11.034890659619123\n",
      "Steps:  17%|▏| 2602/15000 [16:27<36:52,  5.60it/s, lr=9.95e-6, step_loss=0.0253]07/18/2023 19:19:49 - INFO - __main__ - train loss is 11.074850202072412\n",
      "Steps:  17%|▌  | 2603/15000 [16:27<36:50,  5.61it/s, lr=9.95e-6, step_loss=0.04]07/18/2023 19:19:49 - INFO - __main__ - train loss is 11.094151810277253\n",
      "Steps:  17%|▏| 2604/15000 [16:27<36:48,  5.61it/s, lr=9.95e-6, step_loss=0.0193]07/18/2023 19:19:50 - INFO - __main__ - train loss is 11.168423966038972\n",
      "Steps:  17%|▏| 2605/15000 [16:28<36:46,  5.62it/s, lr=9.95e-6, step_loss=0.0743]07/18/2023 19:19:50 - INFO - __main__ - train loss is 11.171133850235492\n",
      "Steps:  17%|▏| 2606/15000 [16:28<36:45,  5.62it/s, lr=9.95e-6, step_loss=0.0027107/18/2023 19:19:50 - INFO - __main__ - train loss is 11.214833047706634\n",
      "Steps:  17%|▏| 2607/15000 [16:28<36:44,  5.62it/s, lr=9.95e-6, step_loss=0.0437]07/18/2023 19:19:50 - INFO - __main__ - train loss is 11.44067842932418\n",
      "Steps:  17%|▎ | 2608/15000 [16:28<36:43,  5.62it/s, lr=9.95e-6, step_loss=0.226]07/18/2023 19:19:50 - INFO - __main__ - train loss is 11.624579322058707\n",
      "Steps:  17%|▎ | 2609/15000 [16:28<36:42,  5.62it/s, lr=9.95e-6, step_loss=0.184]07/18/2023 19:19:51 - INFO - __main__ - train loss is 12.067154538352042\n",
      "Steps:  17%|▎ | 2610/15000 [16:28<36:42,  5.62it/s, lr=9.95e-6, step_loss=0.443]07/18/2023 19:19:51 - INFO - __main__ - train loss is 12.305875998456031\n",
      "Steps:  17%|▎ | 2611/15000 [16:29<36:46,  5.62it/s, lr=9.95e-6, step_loss=0.239]07/18/2023 19:19:51 - INFO - __main__ - train loss is 12.331958674360067\n",
      "Steps:  17%|▏| 2612/15000 [16:29<36:45,  5.62it/s, lr=9.95e-6, step_loss=0.0261]07/18/2023 19:19:51 - INFO - __main__ - train loss is 12.603862487245351\n",
      "Steps:  17%|▎ | 2613/15000 [16:29<36:44,  5.62it/s, lr=9.95e-6, step_loss=0.272]07/18/2023 19:19:51 - INFO - __main__ - train loss is 12.60648673470132\n",
      "Steps:  17%|▏| 2614/15000 [16:29<36:43,  5.62it/s, lr=9.95e-6, step_loss=0.0026207/18/2023 19:19:51 - INFO - __main__ - train loss is 12.700730678392574\n",
      "Steps:  17%|▏| 2615/15000 [16:29<36:44,  5.62it/s, lr=9.95e-6, step_loss=0.0942]07/18/2023 19:19:52 - INFO - __main__ - train loss is 13.017918017460033\n",
      "Steps:  17%|▎ | 2616/15000 [16:29<36:43,  5.62it/s, lr=9.95e-6, step_loss=0.317]07/18/2023 19:19:52 - INFO - __main__ - train loss is 13.021787108620629\n",
      "Steps:  17%|▏| 2617/15000 [16:30<36:44,  5.62it/s, lr=9.95e-6, step_loss=0.0038707/18/2023 19:19:52 - INFO - __main__ - train loss is 13.301486344775185\n",
      "Steps:  17%|▌  | 2618/15000 [16:30<36:43,  5.62it/s, lr=9.95e-6, step_loss=0.28]07/18/2023 19:19:52 - INFO - __main__ - train loss is 13.416192592820153\n",
      "Steps:  17%|▎ | 2619/15000 [16:30<51:21,  4.02it/s, lr=9.95e-6, step_loss=0.115]07/18/2023 19:19:53 - INFO - __main__ - Per validation step average loss is 0.012324124574661255\n",
      "07/18/2023 19:19:53 - INFO - __main__ - Cumulative validation average loss is 0.012324124574661255\n",
      "07/18/2023 19:19:53 - INFO - __main__ - Per validation step average loss is 0.0974750891327858\n",
      "07/18/2023 19:19:53 - INFO - __main__ - Cumulative validation average loss is 0.10979921370744705\n",
      "07/18/2023 19:19:53 - INFO - __main__ - Per validation step average loss is 0.003554299473762512\n",
      "07/18/2023 19:19:53 - INFO - __main__ - Cumulative validation average loss is 0.11335351318120956\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Per validation step average loss is 0.16207867860794067\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Cumulative validation average loss is 0.27543219178915024\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Per validation step average loss is 0.2550836205482483\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Cumulative validation average loss is 0.5305158123373985\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Per validation step average loss is 0.006336497142910957\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Cumulative validation average loss is 0.5368523094803095\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Per validation step average loss is 0.010180914774537086\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Cumulative validation average loss is 0.5470332242548466\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Per validation step average loss is 0.16307780146598816\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Cumulative validation average loss is 0.7101110257208347\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Per validation step average loss is 0.024887654930353165\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Cumulative validation average loss is 0.7349986806511879\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Per validation step average loss is 0.0024002068676054478\n",
      "07/18/2023 19:19:54 - INFO - __main__ - Cumulative validation average loss is 0.7373988875187933\n",
      "07/18/2023 19:19:55 - INFO - __main__ - Per validation step average loss is 0.10866585373878479\n",
      "07/18/2023 19:19:55 - INFO - __main__ - Cumulative validation average loss is 0.8460647412575781\n",
      "07/18/2023 19:19:55 - INFO - __main__ - Per validation step average loss is 0.24075469374656677\n",
      "07/18/2023 19:19:55 - INFO - __main__ - Cumulative validation average loss is 1.086819435004145\n",
      "07/18/2023 19:19:55 - INFO - __main__ - Average validation loss for Epoch 26 is 0.09056828625034541\n",
      "07/18/2023 19:19:55 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:20:08 - INFO - __main__ - Starting epoch 27\n",
      "07/18/2023 19:20:08 - INFO - __main__ - train loss is 0.8194448947906494\n",
      "Steps:  17%|▏| 2620/15000 [16:46<16:57:57,  4.93s/it, lr=9.95e-6, step_loss=0.8107/18/2023 19:20:08 - INFO - __main__ - train loss is 1.2559743225574493\n",
      "Steps:  17%|▏| 2621/15000 [16:46<12:03:48,  3.51s/it, lr=9.95e-6, step_loss=0.4307/18/2023 19:20:09 - INFO - __main__ - train loss is 1.2708968427032232\n",
      "Steps:  17%|▏| 2622/15000 [16:46<8:37:41,  2.51s/it, lr=9.95e-6, step_loss=0.01407/18/2023 19:20:09 - INFO - __main__ - train loss is 1.6051807906478643\n",
      "Steps:  17%|▏| 2623/15000 [16:47<6:13:23,  1.81s/it, lr=9.95e-6, step_loss=0.33407/18/2023 19:20:09 - INFO - __main__ - train loss is 1.6428707744926214\n",
      "Steps:  17%|▏| 2624/15000 [16:47<4:32:41,  1.32s/it, lr=9.95e-6, step_loss=0.03707/18/2023 19:20:09 - INFO - __main__ - train loss is 1.67277985624969\n",
      "Steps:  18%|▏| 2625/15000 [16:47<3:22:09,  1.02it/s, lr=9.95e-6, step_loss=0.02907/18/2023 19:20:09 - INFO - __main__ - train loss is 1.7931821625679731\n",
      "Steps:  18%|▏| 2626/15000 [16:47<2:32:37,  1.35it/s, lr=9.95e-6, step_loss=0.12]07/18/2023 19:20:09 - INFO - __main__ - train loss is 2.113403646275401\n",
      "Steps:  18%|▏| 2627/15000 [16:47<1:57:48,  1.75it/s, lr=9.95e-6, step_loss=0.32]07/18/2023 19:20:10 - INFO - __main__ - train loss is 2.735185829922557\n",
      "Steps:  18%|▏| 2628/15000 [16:48<1:33:39,  2.20it/s, lr=9.95e-6, step_loss=0.62207/18/2023 19:20:10 - INFO - __main__ - train loss is 2.881510866805911\n",
      "Steps:  18%|▏| 2629/15000 [16:48<1:16:32,  2.69it/s, lr=9.95e-6, step_loss=0.14607/18/2023 19:20:10 - INFO - __main__ - train loss is 3.133285416290164\n",
      "Steps:  18%|▏| 2630/15000 [16:48<1:04:34,  3.19it/s, lr=9.95e-6, step_loss=0.25207/18/2023 19:20:10 - INFO - __main__ - train loss is 3.1827671248465776\n",
      "Steps:  18%|▏| 2631/15000 [16:48<56:32,  3.65it/s, lr=9.95e-6, step_loss=0.0495]07/18/2023 19:20:10 - INFO - __main__ - train loss is 3.547570141032338\n",
      "Steps:  18%|▎ | 2632/15000 [16:48<51:13,  4.02it/s, lr=9.95e-6, step_loss=0.365]07/18/2023 19:20:11 - INFO - __main__ - train loss is 4.272248478606343\n",
      "Steps:  18%|▎ | 2633/15000 [16:48<47:56,  4.30it/s, lr=9.95e-6, step_loss=0.725]07/18/2023 19:20:11 - INFO - __main__ - train loss is 4.275729047134519\n",
      "Steps:  18%|▏| 2634/15000 [16:49<44:41,  4.61it/s, lr=9.95e-6, step_loss=0.0034807/18/2023 19:20:11 - INFO - __main__ - train loss is 4.31313650123775\n",
      "Steps:  18%|▏| 2635/15000 [16:49<42:15,  4.88it/s, lr=9.95e-6, step_loss=0.0374]07/18/2023 19:20:11 - INFO - __main__ - train loss is 4.3998267482966185\n",
      "Steps:  18%|▏| 2636/15000 [16:49<40:32,  5.08it/s, lr=9.95e-6, step_loss=0.0867]07/18/2023 19:20:11 - INFO - __main__ - train loss is 4.498831083998084\n",
      "Steps:  18%|▎ | 2637/15000 [16:49<39:23,  5.23it/s, lr=9.95e-6, step_loss=0.099]07/18/2023 19:20:11 - INFO - __main__ - train loss is 4.521011218428612\n",
      "Steps:  18%|▏| 2638/15000 [16:49<38:35,  5.34it/s, lr=9.95e-6, step_loss=0.0222]07/18/2023 19:20:12 - INFO - __main__ - train loss is 4.525874690618366\n",
      "Steps:  18%|▏| 2639/15000 [16:50<38:00,  5.42it/s, lr=9.95e-6, step_loss=0.0048607/18/2023 19:20:12 - INFO - __main__ - train loss is 5.373483376111835\n",
      "Steps:  18%|▎ | 2640/15000 [16:50<37:35,  5.48it/s, lr=9.95e-6, step_loss=0.848]07/18/2023 19:20:12 - INFO - __main__ - train loss is 5.474661947693676\n",
      "Steps:  18%|▎ | 2641/15000 [16:50<37:17,  5.52it/s, lr=9.95e-6, step_loss=0.101]07/18/2023 19:20:12 - INFO - __main__ - train loss is 5.504606874193996\n",
      "Steps:  18%|▏| 2642/15000 [16:50<37:05,  5.55it/s, lr=9.95e-6, step_loss=0.0299]07/18/2023 19:20:12 - INFO - __main__ - train loss is 5.570035660173744\n",
      "Steps:  18%|▏| 2643/15000 [16:50<36:56,  5.58it/s, lr=9.95e-6, step_loss=0.0654]07/18/2023 19:20:13 - INFO - __main__ - train loss is 5.702711725141853\n",
      "Steps:  18%|▎ | 2644/15000 [16:50<36:51,  5.59it/s, lr=9.95e-6, step_loss=0.133]07/18/2023 19:20:13 - INFO - __main__ - train loss is 5.715094614308327\n",
      "Steps:  18%|▏| 2645/15000 [16:51<36:47,  5.60it/s, lr=9.95e-6, step_loss=0.0124]07/18/2023 19:20:13 - INFO - __main__ - train loss is 5.717756014782935\n",
      "Steps:  18%|▏| 2646/15000 [16:51<36:45,  5.60it/s, lr=9.95e-6, step_loss=0.0026607/18/2023 19:20:13 - INFO - __main__ - train loss is 6.044857066590339\n",
      "Steps:  18%|▎ | 2647/15000 [16:51<36:43,  5.61it/s, lr=9.95e-6, step_loss=0.327]07/18/2023 19:20:13 - INFO - __main__ - train loss is 6.052825160790235\n",
      "Steps:  18%|▏| 2648/15000 [16:51<36:42,  5.61it/s, lr=9.95e-6, step_loss=0.0079707/18/2023 19:20:13 - INFO - __main__ - train loss is 6.3295408566482365\n",
      "Steps:  18%|▎ | 2649/15000 [16:51<36:41,  5.61it/s, lr=9.95e-6, step_loss=0.277]07/18/2023 19:20:14 - INFO - __main__ - train loss is 6.334543814416975\n",
      "Steps:  18%|▎ | 2650/15000 [16:52<37:14,  5.53it/s, lr=9.95e-6, step_loss=0.005]07/18/2023 19:20:14 - INFO - __main__ - train loss is 6.363306287210435\n",
      "Steps:  18%|▏| 2651/15000 [16:52<37:43,  5.46it/s, lr=9.95e-6, step_loss=0.0288]07/18/2023 19:20:14 - INFO - __main__ - train loss is 6.408996458631009\n",
      "Steps:  18%|▏| 2652/15000 [16:52<38:03,  5.41it/s, lr=9.95e-6, step_loss=0.0457]07/18/2023 19:20:14 - INFO - __main__ - train loss is 6.459389507304877\n",
      "Steps:  18%|▏| 2653/15000 [16:52<38:11,  5.39it/s, lr=9.95e-6, step_loss=0.0504]07/18/2023 19:20:14 - INFO - __main__ - train loss is 6.4689674959518015\n",
      "Steps:  18%|▏| 2654/15000 [16:52<37:44,  5.45it/s, lr=9.95e-6, step_loss=0.0095807/18/2023 19:20:15 - INFO - __main__ - train loss is 6.891426442656666\n",
      "Steps:  18%|▎ | 2655/15000 [16:52<37:25,  5.50it/s, lr=9.95e-6, step_loss=0.422]07/18/2023 19:20:15 - INFO - __main__ - train loss is 6.93181178951636\n",
      "Steps:  18%|▏| 2656/15000 [16:53<37:32,  5.48it/s, lr=9.95e-6, step_loss=0.0404]07/18/2023 19:20:15 - INFO - __main__ - train loss is 7.0355524071492255\n",
      "Steps:  18%|▎ | 2657/15000 [16:53<37:15,  5.52it/s, lr=9.95e-6, step_loss=0.104]07/18/2023 19:20:15 - INFO - __main__ - train loss is 7.049633894581348\n",
      "Steps:  18%|▏| 2658/15000 [16:53<37:05,  5.55it/s, lr=9.95e-6, step_loss=0.0141]07/18/2023 19:20:15 - INFO - __main__ - train loss is 7.10853559570387\n",
      "Steps:  18%|▏| 2659/15000 [16:53<36:56,  5.57it/s, lr=9.95e-6, step_loss=0.0589]07/18/2023 19:20:15 - INFO - __main__ - train loss is 7.122054085601121\n",
      "Steps:  18%|▏| 2660/15000 [16:53<36:51,  5.58it/s, lr=9.95e-6, step_loss=0.0135]07/18/2023 19:20:16 - INFO - __main__ - train loss is 7.167760104406625\n",
      "Steps:  18%|▏| 2661/15000 [16:54<36:46,  5.59it/s, lr=9.95e-6, step_loss=0.0457]07/18/2023 19:20:16 - INFO - __main__ - train loss is 7.196710164193064\n",
      "Steps:  18%|▎ | 2662/15000 [16:54<36:42,  5.60it/s, lr=9.95e-6, step_loss=0.029]07/18/2023 19:20:16 - INFO - __main__ - train loss is 7.297044272068888\n",
      "Steps:  18%|▋   | 2663/15000 [16:54<36:40,  5.61it/s, lr=9.95e-6, step_loss=0.1]07/18/2023 19:20:16 - INFO - __main__ - train loss is 7.348185258451849\n",
      "Steps:  18%|▏| 2664/15000 [16:54<36:38,  5.61it/s, lr=9.95e-6, step_loss=0.0511]07/18/2023 19:20:16 - INFO - __main__ - train loss is 7.351711555849761\n",
      "Steps:  18%|▏| 2665/15000 [16:54<36:38,  5.61it/s, lr=9.95e-6, step_loss=0.0035307/18/2023 19:20:17 - INFO - __main__ - train loss is 7.355106202419847\n",
      "Steps:  18%|▏| 2666/15000 [16:54<36:38,  5.61it/s, lr=9.95e-6, step_loss=0.0033907/18/2023 19:20:17 - INFO - __main__ - train loss is 7.429065314587206\n",
      "Steps:  18%|▎ | 2667/15000 [16:55<36:58,  5.56it/s, lr=9.95e-6, step_loss=0.074]07/18/2023 19:20:17 - INFO - __main__ - train loss is 7.65685131913051\n",
      "Steps:  18%|▎ | 2668/15000 [16:55<36:59,  5.56it/s, lr=9.95e-6, step_loss=0.228]07/18/2023 19:20:17 - INFO - __main__ - train loss is 7.745348630007356\n",
      "Steps:  18%|▏| 2669/15000 [16:55<36:52,  5.57it/s, lr=9.95e-6, step_loss=0.0885]07/18/2023 19:20:17 - INFO - __main__ - train loss is 8.168822286184877\n",
      "Steps:  18%|▎ | 2670/15000 [16:55<36:48,  5.58it/s, lr=9.95e-6, step_loss=0.423]07/18/2023 19:20:17 - INFO - __main__ - train loss is 8.468530175741762\n",
      "Steps:  18%|▋   | 2671/15000 [16:55<36:46,  5.59it/s, lr=9.95e-6, step_loss=0.3]07/18/2023 19:20:18 - INFO - __main__ - train loss is 8.470105558400974\n",
      "Steps:  18%|▏| 2672/15000 [16:55<36:43,  5.59it/s, lr=9.95e-6, step_loss=0.0015807/18/2023 19:20:18 - INFO - __main__ - train loss is 9.113504320150241\n",
      "Steps:  18%|▎ | 2673/15000 [16:56<36:42,  5.60it/s, lr=9.95e-6, step_loss=0.643]07/18/2023 19:20:18 - INFO - __main__ - train loss is 9.540126412874088\n",
      "Steps:  18%|▎ | 2674/15000 [16:56<36:41,  5.60it/s, lr=9.95e-6, step_loss=0.427]07/18/2023 19:20:18 - INFO - __main__ - train loss is 9.592585164820775\n",
      "Steps:  18%|▏| 2675/15000 [16:56<36:40,  5.60it/s, lr=9.95e-6, step_loss=0.0525]07/18/2023 19:20:18 - INFO - __main__ - train loss is 9.598026259569451\n",
      "Steps:  18%|▏| 2676/15000 [16:56<36:39,  5.60it/s, lr=9.95e-6, step_loss=0.0054407/18/2023 19:20:18 - INFO - __main__ - train loss is 9.642821966437623\n",
      "Steps:  18%|▏| 2677/15000 [16:56<36:39,  5.60it/s, lr=9.95e-6, step_loss=0.0448]07/18/2023 19:20:19 - INFO - __main__ - train loss is 9.647310052765533\n",
      "Steps:  18%|▏| 2678/15000 [16:57<36:58,  5.55it/s, lr=9.95e-6, step_loss=0.0044907/18/2023 19:20:19 - INFO - __main__ - train loss is 9.699403238249943\n",
      "Steps:  18%|▏| 2679/15000 [16:57<37:50,  5.43it/s, lr=9.95e-6, step_loss=0.0521]07/18/2023 19:20:19 - INFO - __main__ - train loss is 9.761688683880493\n",
      "Steps:  18%|▏| 2680/15000 [16:57<37:29,  5.48it/s, lr=9.95e-6, step_loss=0.0623]07/18/2023 19:20:19 - INFO - __main__ - train loss is 10.528425668133423\n",
      "Steps:  18%|▎ | 2681/15000 [16:57<37:15,  5.51it/s, lr=9.95e-6, step_loss=0.767]07/18/2023 19:20:19 - INFO - __main__ - train loss is 10.692071725381538\n",
      "Steps:  18%|▎ | 2682/15000 [16:57<37:26,  5.48it/s, lr=9.95e-6, step_loss=0.164]07/18/2023 19:20:20 - INFO - __main__ - train loss is 10.712991720763966\n",
      "Steps:  18%|▏| 2683/15000 [16:57<37:22,  5.49it/s, lr=9.95e-6, step_loss=0.0209]07/18/2023 19:20:20 - INFO - __main__ - train loss is 10.839872932760045\n",
      "Steps:  18%|▎ | 2684/15000 [16:58<37:08,  5.53it/s, lr=9.95e-6, step_loss=0.127]07/18/2023 19:20:20 - INFO - __main__ - train loss is 11.363149261800572\n",
      "Steps:  18%|▎ | 2685/15000 [16:58<36:59,  5.55it/s, lr=9.95e-6, step_loss=0.523]07/18/2023 19:20:20 - INFO - __main__ - train loss is 11.42960005137138\n",
      "Steps:  18%|▏| 2686/15000 [16:58<37:10,  5.52it/s, lr=9.95e-6, step_loss=0.0665]07/18/2023 19:20:20 - INFO - __main__ - train loss is 11.796283474890515\n",
      "Steps:  18%|▎ | 2687/15000 [16:58<37:20,  5.50it/s, lr=9.95e-6, step_loss=0.367]07/18/2023 19:20:20 - INFO - __main__ - train loss is 12.147519043413922\n",
      "Steps:  18%|▎ | 2688/15000 [16:58<37:41,  5.44it/s, lr=9.95e-6, step_loss=0.351]07/18/2023 19:20:21 - INFO - __main__ - train loss is 12.210381126729771\n",
      "Steps:  18%|▏| 2689/15000 [16:59<37:19,  5.50it/s, lr=9.95e-6, step_loss=0.0629]07/18/2023 19:20:21 - INFO - __main__ - train loss is 12.261604278115556\n",
      "Steps:  18%|▏| 2690/15000 [16:59<37:04,  5.53it/s, lr=9.95e-6, step_loss=0.0512]07/18/2023 19:20:21 - INFO - __main__ - train loss is 12.502137108473107\n",
      "Steps:  18%|▎ | 2691/15000 [16:59<36:53,  5.56it/s, lr=9.95e-6, step_loss=0.241]07/18/2023 19:20:21 - INFO - __main__ - train loss is 12.63236220064573\n",
      "Steps:  18%|▌  | 2692/15000 [16:59<36:47,  5.57it/s, lr=9.95e-6, step_loss=0.13]07/18/2023 19:20:21 - INFO - __main__ - train loss is 12.808228685287759\n",
      "Steps:  18%|▎ | 2693/15000 [16:59<36:42,  5.59it/s, lr=9.95e-6, step_loss=0.176]07/18/2023 19:20:22 - INFO - __main__ - train loss is 12.9703096288722\n",
      "Steps:  18%|▎ | 2694/15000 [16:59<36:38,  5.60it/s, lr=9.95e-6, step_loss=0.162]07/18/2023 19:20:22 - INFO - __main__ - train loss is 12.993653557030484\n",
      "Steps:  18%|▏| 2695/15000 [17:00<36:36,  5.60it/s, lr=9.95e-6, step_loss=0.0233]07/18/2023 19:20:22 - INFO - __main__ - train loss is 13.397958031622693\n",
      "Steps:  18%|▎ | 2696/15000 [17:00<36:35,  5.60it/s, lr=9.95e-6, step_loss=0.404]07/18/2023 19:20:22 - INFO - __main__ - train loss is 13.582289836136624\n",
      "Steps:  18%|▎ | 2697/15000 [17:00<36:33,  5.61it/s, lr=9.95e-6, step_loss=0.184]07/18/2023 19:20:22 - INFO - __main__ - train loss is 13.819600916234776\n",
      "Steps:  18%|▎ | 2698/15000 [17:00<36:34,  5.61it/s, lr=9.95e-6, step_loss=0.237]07/18/2023 19:20:22 - INFO - __main__ - train loss is 13.866041759727523\n",
      "Steps:  18%|▏| 2699/15000 [17:00<36:50,  5.56it/s, lr=9.95e-6, step_loss=0.0464]07/18/2023 19:20:23 - INFO - __main__ - train loss is 14.066098476527259\n",
      "Steps:  18%|▋   | 2700/15000 [17:01<36:43,  5.58it/s, lr=9.95e-6, step_loss=0.2]07/18/2023 19:20:23 - INFO - __main__ - train loss is 14.089654265670106\n",
      "Steps:  18%|▏| 2701/15000 [17:01<36:38,  5.59it/s, lr=9.95e-6, step_loss=0.0236]07/18/2023 19:20:23 - INFO - __main__ - train loss is 14.160198061494157\n",
      "Steps:  18%|▏| 2702/15000 [17:01<36:34,  5.60it/s, lr=9.95e-6, step_loss=0.0705]07/18/2023 19:20:23 - INFO - __main__ - train loss is 14.30379161122255\n",
      "Steps:  18%|▎ | 2703/15000 [17:01<36:30,  5.61it/s, lr=9.95e-6, step_loss=0.144]07/18/2023 19:20:23 - INFO - __main__ - train loss is 14.38531685504131\n",
      "Steps:  18%|▏| 2704/15000 [17:01<36:27,  5.62it/s, lr=9.95e-6, step_loss=0.0815]07/18/2023 19:20:24 - INFO - __main__ - train loss is 14.389561058720574\n",
      "Steps:  18%|▏| 2705/15000 [17:01<36:27,  5.62it/s, lr=9.95e-6, step_loss=0.0042407/18/2023 19:20:24 - INFO - __main__ - train loss is 14.426552252611145\n",
      "Steps:  18%|▎ | 2706/15000 [17:02<36:26,  5.62it/s, lr=9.95e-6, step_loss=0.037]07/18/2023 19:20:24 - INFO - __main__ - train loss is 14.43482444039546\n",
      "Steps:  18%|▏| 2707/15000 [17:02<36:25,  5.62it/s, lr=9.95e-6, step_loss=0.0082707/18/2023 19:20:24 - INFO - __main__ - train loss is 14.44560227333568\n",
      "Steps:  18%|▏| 2708/15000 [17:02<36:25,  5.63it/s, lr=9.95e-6, step_loss=0.0108]07/18/2023 19:20:24 - INFO - __main__ - train loss is 14.514562835684046\n",
      "Steps:  18%|▎ | 2709/15000 [17:02<36:24,  5.63it/s, lr=9.95e-6, step_loss=0.069]07/18/2023 19:20:24 - INFO - __main__ - train loss is 14.767569115152583\n",
      "Steps:  18%|▎ | 2710/15000 [17:02<36:25,  5.62it/s, lr=9.95e-6, step_loss=0.253]07/18/2023 19:20:25 - INFO - __main__ - train loss is 14.906014716019854\n",
      "Steps:  18%|▎ | 2711/15000 [17:02<36:25,  5.62it/s, lr=9.95e-6, step_loss=0.138]07/18/2023 19:20:25 - INFO - __main__ - train loss is 15.161437367787585\n",
      "Steps:  18%|▎ | 2712/15000 [17:03<36:26,  5.62it/s, lr=9.95e-6, step_loss=0.255]07/18/2023 19:20:25 - INFO - __main__ - train loss is 15.173226400977\n",
      "Steps:  18%|▏| 2713/15000 [17:03<36:23,  5.63it/s, lr=9.95e-6, step_loss=0.0118]07/18/2023 19:20:25 - INFO - __main__ - train loss is 15.252399071818218\n",
      "Steps:  18%|▏| 2714/15000 [17:03<36:23,  5.63it/s, lr=9.95e-6, step_loss=0.0792]07/18/2023 19:20:25 - INFO - __main__ - train loss is 15.25604837317951\n",
      "Steps:  18%|▏| 2715/15000 [17:03<36:23,  5.63it/s, lr=9.95e-6, step_loss=0.0036507/18/2023 19:20:26 - INFO - __main__ - train loss is 15.272531762020662\n",
      "Steps:  18%|▏| 2716/15000 [17:04<51:21,  3.99it/s, lr=9.95e-6, step_loss=0.0165]07/18/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.017937418073415756\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 0.017937418073415756\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.17246100306510925\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 0.190398421138525\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.04399571195244789\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 0.2343941330909729\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.09816557914018631\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 0.3325597122311592\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.16219422221183777\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 0.494753934442997\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.1112530305981636\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 0.6060069650411606\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Per validation step average loss is 0.14128172397613525\n",
      "07/18/2023 19:20:27 - INFO - __main__ - Cumulative validation average loss is 0.7472886890172958\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Per validation step average loss is 0.01867072656750679\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Cumulative validation average loss is 0.7659594155848026\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Per validation step average loss is 0.06429657340049744\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Cumulative validation average loss is 0.8302559889853001\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Per validation step average loss is 0.044793494045734406\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Cumulative validation average loss is 0.8750494830310345\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Per validation step average loss is 0.5367826223373413\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Cumulative validation average loss is 1.4118321053683758\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Per validation step average loss is 0.2789178490638733\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Cumulative validation average loss is 1.690749954432249\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Average validation loss for Epoch 27 is 0.14089582953602076\n",
      "07/18/2023 19:20:28 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:20:41 - INFO - __main__ - Starting epoch 28\n",
      "07/18/2023 19:20:42 - INFO - __main__ - train loss is 0.3451603651046753\n",
      "Steps:  18%|▏| 2717/15000 [17:20<16:56:02,  4.96s/it, lr=9.95e-6, step_loss=0.3407/18/2023 19:20:42 - INFO - __main__ - train loss is 0.5184486657381058\n",
      "Steps:  18%|▏| 2718/15000 [17:20<12:02:25,  3.53s/it, lr=9.95e-6, step_loss=0.1707/18/2023 19:20:42 - INFO - __main__ - train loss is 0.5243232203647494\n",
      "Steps:  18%|▏| 2719/15000 [17:20<8:36:54,  2.53s/it, lr=9.95e-6, step_loss=0.00507/18/2023 19:20:42 - INFO - __main__ - train loss is 0.624749499373138\n",
      "Steps:  18%|▎ | 2720/15000 [17:20<6:13:06,  1.82s/it, lr=9.95e-6, step_loss=0.1]07/18/2023 19:20:42 - INFO - __main__ - train loss is 0.6616481496021152\n",
      "Steps:  18%|▏| 2721/15000 [17:20<4:32:56,  1.33s/it, lr=9.95e-6, step_loss=0.03607/18/2023 19:20:43 - INFO - __main__ - train loss is 0.732087547890842\n",
      "Steps:  18%|▏| 2722/15000 [17:20<3:22:25,  1.01it/s, lr=9.95e-6, step_loss=0.07007/18/2023 19:20:43 - INFO - __main__ - train loss is 0.7504587275907397\n",
      "Steps:  18%|▏| 2723/15000 [17:21<2:32:57,  1.34it/s, lr=9.95e-6, step_loss=0.01807/18/2023 19:20:43 - INFO - __main__ - train loss is 0.891081522218883\n",
      "Steps:  18%|▏| 2724/15000 [17:21<1:58:26,  1.73it/s, lr=9.95e-6, step_loss=0.14107/18/2023 19:20:43 - INFO - __main__ - train loss is 1.0010566292330623\n",
      "Steps:  18%|▏| 2725/15000 [17:21<1:34:28,  2.17it/s, lr=9.95e-6, step_loss=0.11]07/18/2023 19:20:43 - INFO - __main__ - train loss is 1.4733834443613887\n",
      "Steps:  18%|▏| 2726/15000 [17:21<1:17:43,  2.63it/s, lr=9.95e-6, step_loss=0.47207/18/2023 19:20:44 - INFO - __main__ - train loss is 1.4753455356694758\n",
      "Steps:  18%|▏| 2727/15000 [17:21<1:05:38,  3.12it/s, lr=9.95e-6, step_loss=0.00107/18/2023 19:20:44 - INFO - __main__ - train loss is 1.6122381226159632\n",
      "Steps:  18%|▎ | 2728/15000 [17:22<57:35,  3.55it/s, lr=9.95e-6, step_loss=0.137]07/18/2023 19:20:44 - INFO - __main__ - train loss is 1.614151527872309\n",
      "Steps:  18%|▏| 2729/15000 [17:22<52:14,  3.91it/s, lr=9.95e-6, step_loss=0.0019107/18/2023 19:20:44 - INFO - __main__ - train loss is 1.6173424010630697\n",
      "Steps:  18%|▏| 2730/15000 [17:22<48:39,  4.20it/s, lr=9.95e-6, step_loss=0.0031907/18/2023 19:20:44 - INFO - __main__ - train loss is 1.6494875473435968\n",
      "Steps:  18%|▏| 2731/15000 [17:22<45:41,  4.48it/s, lr=9.95e-6, step_loss=0.0321]07/18/2023 19:20:44 - INFO - __main__ - train loss is 1.662249613320455\n",
      "Steps:  18%|▏| 2732/15000 [17:22<42:53,  4.77it/s, lr=9.95e-6, step_loss=0.0128]07/18/2023 19:20:45 - INFO - __main__ - train loss is 1.6654466846957803\n",
      "Steps:  18%|▏| 2733/15000 [17:23<41:15,  4.95it/s, lr=9.95e-6, step_loss=0.0032]07/18/2023 19:20:45 - INFO - __main__ - train loss is 2.0450992146506906\n",
      "Steps:  18%|▌  | 2734/15000 [17:23<39:58,  5.11it/s, lr=9.95e-6, step_loss=0.38]07/18/2023 19:20:45 - INFO - __main__ - train loss is 2.20543107483536\n",
      "Steps:  18%|▌  | 2735/15000 [17:23<39:09,  5.22it/s, lr=9.95e-6, step_loss=0.16]07/18/2023 19:20:45 - INFO - __main__ - train loss is 2.257316895760596\n",
      "Steps:  18%|▏| 2736/15000 [17:23<38:31,  5.31it/s, lr=9.95e-6, step_loss=0.0519]07/18/2023 19:20:45 - INFO - __main__ - train loss is 2.2804693104699254\n",
      "Steps:  18%|▏| 2737/15000 [17:23<38:02,  5.37it/s, lr=9.95e-6, step_loss=0.0232]07/18/2023 19:20:46 - INFO - __main__ - train loss is 2.282746714539826\n",
      "Steps:  18%|▏| 2738/15000 [17:23<37:43,  5.42it/s, lr=9.95e-6, step_loss=0.0022807/18/2023 19:20:46 - INFO - __main__ - train loss is 2.2856742362491786\n",
      "Steps:  18%|▏| 2739/15000 [17:24<37:33,  5.44it/s, lr=9.95e-6, step_loss=0.0029307/18/2023 19:20:46 - INFO - __main__ - train loss is 2.2910923059098423\n",
      "Steps:  18%|▏| 2740/15000 [17:24<37:21,  5.47it/s, lr=9.95e-6, step_loss=0.0054207/18/2023 19:20:46 - INFO - __main__ - train loss is 2.315207615029067\n",
      "Steps:  18%|▏| 2741/15000 [17:24<37:30,  5.45it/s, lr=9.95e-6, step_loss=0.0241]07/18/2023 19:20:46 - INFO - __main__ - train loss is 2.3212498067878187\n",
      "Steps:  18%|▏| 2742/15000 [17:24<37:19,  5.47it/s, lr=9.95e-6, step_loss=0.0060407/18/2023 19:20:46 - INFO - __main__ - train loss is 2.3238614448346198\n",
      "Steps:  18%|▏| 2743/15000 [17:24<37:33,  5.44it/s, lr=9.95e-6, step_loss=0.0026107/18/2023 19:20:47 - INFO - __main__ - train loss is 2.406863095704466\n",
      "Steps:  18%|▎ | 2744/15000 [17:25<37:48,  5.40it/s, lr=9.95e-6, step_loss=0.083]07/18/2023 19:20:47 - INFO - __main__ - train loss is 2.907807829324156\n",
      "Steps:  18%|▎ | 2745/15000 [17:25<37:52,  5.39it/s, lr=9.95e-6, step_loss=0.501]07/18/2023 19:20:47 - INFO - __main__ - train loss is 3.178685846272856\n",
      "Steps:  18%|▎ | 2746/15000 [17:25<37:35,  5.43it/s, lr=9.95e-6, step_loss=0.271]07/18/2023 19:20:47 - INFO - __main__ - train loss is 3.1850716951303184\n",
      "Steps:  18%|▏| 2747/15000 [17:25<37:23,  5.46it/s, lr=9.95e-6, step_loss=0.0063907/18/2023 19:20:47 - INFO - __main__ - train loss is 3.3294620397500694\n",
      "Steps:  18%|▎ | 2748/15000 [17:25<37:18,  5.47it/s, lr=9.95e-6, step_loss=0.144]07/18/2023 19:20:48 - INFO - __main__ - train loss is 3.3594704805873334\n",
      "Steps:  18%|▌  | 2749/15000 [17:25<37:28,  5.45it/s, lr=9.95e-6, step_loss=0.03]07/18/2023 19:20:48 - INFO - __main__ - train loss is 3.420269501861185\n",
      "Steps:  18%|▏| 2750/15000 [17:26<37:18,  5.47it/s, lr=9.95e-6, step_loss=0.0608]07/18/2023 19:20:48 - INFO - __main__ - train loss is 3.423737462144345\n",
      "Steps:  18%|▏| 2751/15000 [17:26<37:01,  5.51it/s, lr=9.95e-6, step_loss=0.0034707/18/2023 19:20:48 - INFO - __main__ - train loss is 3.5466324645094573\n",
      "Steps:  18%|▎ | 2752/15000 [17:26<36:48,  5.55it/s, lr=9.95e-6, step_loss=0.123]07/18/2023 19:20:48 - INFO - __main__ - train loss is 3.8038763063959777\n",
      "Steps:  18%|▎ | 2753/15000 [17:26<36:42,  5.56it/s, lr=9.95e-6, step_loss=0.257]07/18/2023 19:20:48 - INFO - __main__ - train loss is 4.211758698802441\n",
      "Steps:  18%|▎ | 2754/15000 [17:26<36:35,  5.58it/s, lr=9.95e-6, step_loss=0.408]07/18/2023 19:20:49 - INFO - __main__ - train loss is 4.37962433276698\n",
      "Steps:  18%|▎ | 2755/15000 [17:27<36:49,  5.54it/s, lr=9.95e-6, step_loss=0.168]07/18/2023 19:20:49 - INFO - __main__ - train loss is 4.38212921959348\n",
      "Steps:  18%|▏| 2756/15000 [17:27<36:41,  5.56it/s, lr=9.95e-6, step_loss=0.0025]07/18/2023 19:20:49 - INFO - __main__ - train loss is 4.469612737419084\n",
      "Steps:  18%|▏| 2757/15000 [17:27<36:36,  5.57it/s, lr=9.95e-6, step_loss=0.0875]07/18/2023 19:20:49 - INFO - __main__ - train loss is 4.536699463846162\n",
      "Steps:  18%|▏| 2758/15000 [17:27<36:32,  5.58it/s, lr=9.95e-6, step_loss=0.0671]07/18/2023 19:20:49 - INFO - __main__ - train loss is 4.567797851981595\n",
      "Steps:  18%|▏| 2759/15000 [17:27<36:28,  5.59it/s, lr=9.95e-6, step_loss=0.0311]07/18/2023 19:20:50 - INFO - __main__ - train loss is 4.639670525910333\n",
      "Steps:  18%|▏| 2760/15000 [17:27<36:25,  5.60it/s, lr=9.95e-6, step_loss=0.0719]07/18/2023 19:20:50 - INFO - __main__ - train loss is 4.71582389366813\n",
      "Steps:  18%|▏| 2761/15000 [17:28<36:24,  5.60it/s, lr=9.95e-6, step_loss=0.0762]07/18/2023 19:20:50 - INFO - __main__ - train loss is 5.418628578307107\n",
      "Steps:  18%|▎ | 2762/15000 [17:28<36:23,  5.61it/s, lr=9.95e-6, step_loss=0.703]07/18/2023 19:20:50 - INFO - __main__ - train loss is 5.760473554255441\n",
      "Steps:  18%|▎ | 2763/15000 [17:28<36:21,  5.61it/s, lr=9.95e-6, step_loss=0.342]07/18/2023 19:20:50 - INFO - __main__ - train loss is 6.140353684546426\n",
      "Steps:  18%|▌  | 2764/15000 [17:28<36:22,  5.61it/s, lr=9.95e-6, step_loss=0.38]07/18/2023 19:20:50 - INFO - __main__ - train loss is 6.143663166789338\n",
      "Steps:  18%|▏| 2765/15000 [17:28<36:22,  5.60it/s, lr=9.95e-6, step_loss=0.0033107/18/2023 19:20:51 - INFO - __main__ - train loss is 6.149993271334097\n",
      "Steps:  18%|▏| 2766/15000 [17:29<36:22,  5.61it/s, lr=9.95e-6, step_loss=0.0063307/18/2023 19:20:51 - INFO - __main__ - train loss is 6.155361700570211\n",
      "Steps:  18%|▏| 2767/15000 [17:29<36:21,  5.61it/s, lr=9.95e-6, step_loss=0.0053707/18/2023 19:20:51 - INFO - __main__ - train loss is 6.21079895994626\n",
      "Steps:  18%|▏| 2768/15000 [17:29<36:22,  5.60it/s, lr=9.95e-6, step_loss=0.0554]07/18/2023 19:20:51 - INFO - __main__ - train loss is 6.361887957667932\n",
      "Steps:  18%|▎ | 2769/15000 [17:29<36:22,  5.60it/s, lr=9.95e-6, step_loss=0.151]07/18/2023 19:20:51 - INFO - __main__ - train loss is 6.394981827354059\n",
      "Steps:  18%|▏| 2770/15000 [17:29<36:24,  5.60it/s, lr=9.95e-6, step_loss=0.0331]07/18/2023 19:20:52 - INFO - __main__ - train loss is 6.889969642972574\n",
      "Steps:  18%|▎ | 2771/15000 [17:29<36:28,  5.59it/s, lr=9.95e-6, step_loss=0.495]07/18/2023 19:20:52 - INFO - __main__ - train loss is 6.9084587001707405\n",
      "Steps:  18%|▏| 2772/15000 [17:30<36:46,  5.54it/s, lr=9.95e-6, step_loss=0.0185]07/18/2023 19:20:52 - INFO - __main__ - train loss is 6.909987928811461\n",
      "Steps:  18%|▏| 2773/15000 [17:30<36:44,  5.55it/s, lr=9.95e-6, step_loss=0.0015307/18/2023 19:20:52 - INFO - __main__ - train loss is 6.91209673229605\n",
      "Steps:  18%|▏| 2774/15000 [17:30<36:36,  5.57it/s, lr=9.95e-6, step_loss=0.0021107/18/2023 19:20:52 - INFO - __main__ - train loss is 7.1775946551933885\n",
      "Steps:  18%|▎ | 2775/15000 [17:30<36:30,  5.58it/s, lr=9.95e-6, step_loss=0.265]07/18/2023 19:20:52 - INFO - __main__ - train loss is 7.4765298599377275\n",
      "Steps:  19%|▎ | 2776/15000 [17:30<36:26,  5.59it/s, lr=9.95e-6, step_loss=0.299]07/18/2023 19:20:53 - INFO - __main__ - train loss is 7.504147876985371\n",
      "Steps:  19%|▏| 2777/15000 [17:30<36:24,  5.59it/s, lr=9.95e-6, step_loss=0.0276]07/18/2023 19:20:53 - INFO - __main__ - train loss is 7.978463371284306\n",
      "Steps:  19%|▎ | 2778/15000 [17:31<36:21,  5.60it/s, lr=9.95e-6, step_loss=0.474]07/18/2023 19:20:53 - INFO - __main__ - train loss is 8.245235343463719\n",
      "Steps:  19%|▎ | 2779/15000 [17:31<36:21,  5.60it/s, lr=9.95e-6, step_loss=0.267]07/18/2023 19:20:53 - INFO - __main__ - train loss is 8.491756890900433\n",
      "Steps:  19%|▎ | 2780/15000 [17:31<36:22,  5.60it/s, lr=9.95e-6, step_loss=0.247]07/18/2023 19:20:53 - INFO - __main__ - train loss is 8.506261530332267\n",
      "Steps:  19%|▏| 2781/15000 [17:31<36:20,  5.60it/s, lr=9.95e-6, step_loss=0.0145]07/18/2023 19:20:54 - INFO - __main__ - train loss is 8.511526696383953\n",
      "Steps:  19%|▏| 2782/15000 [17:31<36:19,  5.61it/s, lr=9.95e-6, step_loss=0.0052707/18/2023 19:20:54 - INFO - __main__ - train loss is 9.075622849166393\n",
      "Steps:  19%|▎ | 2783/15000 [17:32<36:19,  5.60it/s, lr=9.95e-6, step_loss=0.564]07/18/2023 19:20:54 - INFO - __main__ - train loss is 9.108341369777918\n",
      "Steps:  19%|▏| 2784/15000 [17:32<36:18,  5.61it/s, lr=9.95e-6, step_loss=0.0327]07/18/2023 19:20:54 - INFO - __main__ - train loss is 9.120358720421791\n",
      "Steps:  19%|▎ | 2785/15000 [17:32<36:17,  5.61it/s, lr=9.95e-6, step_loss=0.012]07/18/2023 19:20:54 - INFO - __main__ - train loss is 9.242734968662262\n",
      "Steps:  19%|▎ | 2786/15000 [17:32<36:17,  5.61it/s, lr=9.95e-6, step_loss=0.122]07/18/2023 19:20:54 - INFO - __main__ - train loss is 9.412547081708908\n",
      "Steps:  19%|▌  | 2787/15000 [17:32<36:37,  5.56it/s, lr=9.95e-6, step_loss=0.17]07/18/2023 19:20:55 - INFO - __main__ - train loss is 9.63278740644455\n",
      "Steps:  19%|▌  | 2788/15000 [17:32<37:10,  5.48it/s, lr=9.95e-6, step_loss=0.22]07/18/2023 19:20:55 - INFO - __main__ - train loss is 10.451252520084381\n",
      "Steps:  19%|▎ | 2789/15000 [17:33<37:10,  5.48it/s, lr=9.95e-6, step_loss=0.818]07/18/2023 19:20:55 - INFO - __main__ - train loss is 10.819460988044739\n",
      "Steps:  19%|▎ | 2790/15000 [17:33<37:14,  5.46it/s, lr=9.95e-6, step_loss=0.368]07/18/2023 19:20:55 - INFO - __main__ - train loss is 10.88900376856327\n",
      "Steps:  19%|▏| 2791/15000 [17:33<37:14,  5.46it/s, lr=9.95e-6, step_loss=0.0695]07/18/2023 19:20:55 - INFO - __main__ - train loss is 11.58982165157795\n",
      "Steps:  19%|▎ | 2792/15000 [17:33<36:56,  5.51it/s, lr=9.95e-6, step_loss=0.701]07/18/2023 19:20:55 - INFO - __main__ - train loss is 11.63963470607996\n",
      "Steps:  19%|▏| 2793/15000 [17:33<36:46,  5.53it/s, lr=9.95e-6, step_loss=0.0498]07/18/2023 19:20:56 - INFO - __main__ - train loss is 11.716818012297153\n",
      "Steps:  19%|▏| 2794/15000 [17:34<36:37,  5.55it/s, lr=9.95e-6, step_loss=0.0772]07/18/2023 19:20:56 - INFO - __main__ - train loss is 11.928520284593105\n",
      "Steps:  19%|▎ | 2795/15000 [17:34<36:31,  5.57it/s, lr=9.95e-6, step_loss=0.212]07/18/2023 19:20:56 - INFO - __main__ - train loss is 12.145923845469952\n",
      "Steps:  19%|▎ | 2796/15000 [17:34<36:26,  5.58it/s, lr=9.95e-6, step_loss=0.217]07/18/2023 19:20:56 - INFO - __main__ - train loss is 12.29281511157751\n",
      "Steps:  19%|▎ | 2797/15000 [17:34<36:21,  5.59it/s, lr=9.95e-6, step_loss=0.147]07/18/2023 19:20:56 - INFO - __main__ - train loss is 12.294244870892726\n",
      "Steps:  19%|▏| 2798/15000 [17:34<36:17,  5.60it/s, lr=9.95e-6, step_loss=0.0014307/18/2023 19:20:57 - INFO - __main__ - train loss is 12.360072598210536\n",
      "Steps:  19%|▏| 2799/15000 [17:34<36:14,  5.61it/s, lr=9.95e-6, step_loss=0.0658]07/18/2023 19:20:57 - INFO - __main__ - train loss is 12.943408832303248\n",
      "Steps:  19%|▎ | 2800/15000 [17:35<36:13,  5.61it/s, lr=9.95e-6, step_loss=0.583]07/18/2023 19:20:57 - INFO - __main__ - train loss is 12.970552217564546\n",
      "Steps:  19%|▏| 2801/15000 [17:35<36:11,  5.62it/s, lr=9.95e-6, step_loss=0.0271]07/18/2023 19:20:57 - INFO - __main__ - train loss is 13.007025193772279\n",
      "Steps:  19%|▏| 2802/15000 [17:35<36:10,  5.62it/s, lr=9.95e-6, step_loss=0.0365]07/18/2023 19:20:57 - INFO - __main__ - train loss is 13.022645394667052\n",
      "Steps:  19%|▏| 2803/15000 [17:35<36:09,  5.62it/s, lr=9.95e-6, step_loss=0.0156]07/18/2023 19:20:57 - INFO - __main__ - train loss is 13.1271823750576\n",
      "Steps:  19%|▎ | 2804/15000 [17:35<36:10,  5.62it/s, lr=9.95e-6, step_loss=0.105]07/18/2023 19:20:58 - INFO - __main__ - train loss is 13.178122195764445\n",
      "Steps:  19%|▏| 2805/15000 [17:36<36:30,  5.57it/s, lr=9.95e-6, step_loss=0.0509]07/18/2023 19:20:58 - INFO - __main__ - train loss is 13.429979595704935\n",
      "Steps:  19%|▎ | 2806/15000 [17:36<36:29,  5.57it/s, lr=9.95e-6, step_loss=0.252]07/18/2023 19:20:58 - INFO - __main__ - train loss is 13.851453039213084\n",
      "Steps:  19%|▎ | 2807/15000 [17:36<36:23,  5.59it/s, lr=9.95e-6, step_loss=0.421]07/18/2023 19:20:58 - INFO - __main__ - train loss is 13.860323350294493\n",
      "Steps:  19%|▏| 2808/15000 [17:36<36:18,  5.60it/s, lr=9.95e-6, step_loss=0.0088707/18/2023 19:20:58 - INFO - __main__ - train loss is 13.862945203320123\n",
      "Steps:  19%|▏| 2809/15000 [17:36<36:15,  5.60it/s, lr=9.95e-6, step_loss=0.0026207/18/2023 19:20:59 - INFO - __main__ - train loss is 13.885732282535173\n",
      "Steps:  19%|▏| 2810/15000 [17:36<36:13,  5.61it/s, lr=9.95e-6, step_loss=0.0228]07/18/2023 19:20:59 - INFO - __main__ - train loss is 14.017126251594163\n",
      "Steps:  19%|▎ | 2811/15000 [17:37<36:26,  5.58it/s, lr=9.95e-6, step_loss=0.131]07/18/2023 19:20:59 - INFO - __main__ - train loss is 14.3826214565197\n",
      "Steps:  19%|▎ | 2812/15000 [17:37<36:24,  5.58it/s, lr=9.95e-6, step_loss=0.365]07/18/2023 19:20:59 - INFO - __main__ - train loss is 14.49169126583729\n",
      "Steps:  19%|▍ | 2813/15000 [17:37<47:13,  4.30it/s, lr=9.95e-6, step_loss=0.109]07/18/2023 19:21:00 - INFO - __main__ - Per validation step average loss is 0.0026196676772087812\n",
      "07/18/2023 19:21:00 - INFO - __main__ - Cumulative validation average loss is 0.0026196676772087812\n",
      "07/18/2023 19:21:00 - INFO - __main__ - Per validation step average loss is 0.0312435794621706\n",
      "07/18/2023 19:21:00 - INFO - __main__ - Cumulative validation average loss is 0.03386324713937938\n",
      "07/18/2023 19:21:00 - INFO - __main__ - Per validation step average loss is 0.10763639211654663\n",
      "07/18/2023 19:21:00 - INFO - __main__ - Cumulative validation average loss is 0.141499639255926\n",
      "07/18/2023 19:21:00 - INFO - __main__ - Per validation step average loss is 0.43974244594573975\n",
      "07/18/2023 19:21:00 - INFO - __main__ - Cumulative validation average loss is 0.5812420852016658\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Per validation step average loss is 0.14045009016990662\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Cumulative validation average loss is 0.7216921753715724\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Per validation step average loss is 0.005071281921118498\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Cumulative validation average loss is 0.7267634572926909\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Per validation step average loss is 0.07403295487165451\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Cumulative validation average loss is 0.8007964121643454\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Per validation step average loss is 0.039435144513845444\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Cumulative validation average loss is 0.8402315566781908\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Per validation step average loss is 0.12721867859363556\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Cumulative validation average loss is 0.9674502352718264\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Per validation step average loss is 0.002869775053113699\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Cumulative validation average loss is 0.9703200103249401\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Per validation step average loss is 0.008109369315207005\n",
      "07/18/2023 19:21:01 - INFO - __main__ - Cumulative validation average loss is 0.9784293796401471\n",
      "07/18/2023 19:21:02 - INFO - __main__ - Per validation step average loss is 0.05737583339214325\n",
      "07/18/2023 19:21:02 - INFO - __main__ - Cumulative validation average loss is 1.0358052130322903\n",
      "07/18/2023 19:21:02 - INFO - __main__ - Average validation loss for Epoch 28 is 0.0863171010860242\n",
      "07/18/2023 19:21:02 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:21:14 - INFO - __main__ - Starting epoch 29\n",
      "07/18/2023 19:21:15 - INFO - __main__ - train loss is 0.22598476707935333\n",
      "Steps:  19%|▏| 2814/15000 [17:53<16:33:02,  4.89s/it, lr=9.95e-6, step_loss=0.2207/18/2023 19:21:15 - INFO - __main__ - train loss is 0.28114333376288414\n",
      "Steps:  19%|▏| 2815/15000 [17:53<11:45:54,  3.48s/it, lr=9.95e-6, step_loss=0.0507/18/2023 19:21:15 - INFO - __main__ - train loss is 0.7143522165715694\n",
      "Steps:  19%|▏| 2816/15000 [17:53<8:25:16,  2.49s/it, lr=9.95e-6, step_loss=0.43307/18/2023 19:21:16 - INFO - __main__ - train loss is 1.0744878016412258\n",
      "Steps:  19%|▏| 2817/15000 [17:53<6:05:12,  1.80s/it, lr=9.95e-6, step_loss=0.36]07/18/2023 19:21:16 - INFO - __main__ - train loss is 1.1999640576541424\n",
      "Steps:  19%|▏| 2818/15000 [17:54<4:27:26,  1.32s/it, lr=9.95e-6, step_loss=0.12507/18/2023 19:21:16 - INFO - __main__ - train loss is 1.247360933572054\n",
      "Steps:  19%|▏| 2819/15000 [17:54<3:18:41,  1.02it/s, lr=9.95e-6, step_loss=0.04707/18/2023 19:21:16 - INFO - __main__ - train loss is 1.3042336516082287\n",
      "Steps:  19%|▏| 2820/15000 [17:54<2:31:51,  1.34it/s, lr=9.95e-6, step_loss=0.05607/18/2023 19:21:16 - INFO - __main__ - train loss is 1.389857318252325\n",
      "Steps:  19%|▏| 2821/15000 [17:54<1:58:42,  1.71it/s, lr=9.95e-6, step_loss=0.08507/18/2023 19:21:17 - INFO - __main__ - train loss is 1.4119062218815088\n",
      "Steps:  19%|▏| 2822/15000 [17:54<1:36:02,  2.11it/s, lr=9.95e-6, step_loss=0.02207/18/2023 19:21:17 - INFO - __main__ - train loss is 1.726366737857461\n",
      "Steps:  19%|▏| 2823/15000 [17:55<1:18:29,  2.59it/s, lr=9.95e-6, step_loss=0.31407/18/2023 19:21:17 - INFO - __main__ - train loss is 1.7424800544977188\n",
      "Steps:  19%|▏| 2824/15000 [17:55<1:05:44,  3.09it/s, lr=9.95e-6, step_loss=0.01607/18/2023 19:21:17 - INFO - __main__ - train loss is 1.7684131227433681\n",
      "Steps:  19%|▏| 2825/15000 [17:55<57:08,  3.55it/s, lr=9.95e-6, step_loss=0.0259]07/18/2023 19:21:17 - INFO - __main__ - train loss is 2.310827072709799\n",
      "Steps:  19%|▍ | 2826/15000 [17:55<50:53,  3.99it/s, lr=9.95e-6, step_loss=0.542]07/18/2023 19:21:17 - INFO - __main__ - train loss is 2.334487207233906\n",
      "Steps:  19%|▏| 2827/15000 [17:55<46:25,  4.37it/s, lr=9.95e-6, step_loss=0.0237]07/18/2023 19:21:18 - INFO - __main__ - train loss is 2.4812992736697197\n",
      "Steps:  19%|▍ | 2828/15000 [17:56<43:18,  4.68it/s, lr=9.95e-6, step_loss=0.147]07/18/2023 19:21:18 - INFO - __main__ - train loss is 2.653841830790043\n",
      "Steps:  19%|▍ | 2829/15000 [17:56<41:06,  4.93it/s, lr=9.95e-6, step_loss=0.173]07/18/2023 19:21:18 - INFO - __main__ - train loss is 2.8850033655762672\n",
      "Steps:  19%|▍ | 2830/15000 [17:56<39:42,  5.11it/s, lr=9.95e-6, step_loss=0.231]07/18/2023 19:21:18 - INFO - __main__ - train loss is 2.902308590710163\n",
      "Steps:  19%|▏| 2831/15000 [17:56<38:38,  5.25it/s, lr=9.95e-6, step_loss=0.0173]07/18/2023 19:21:18 - INFO - __main__ - train loss is 2.964716974645853\n",
      "Steps:  19%|▏| 2832/15000 [17:56<37:54,  5.35it/s, lr=9.95e-6, step_loss=0.0624]07/18/2023 19:21:19 - INFO - __main__ - train loss is 2.993120802566409\n",
      "Steps:  19%|▏| 2833/15000 [17:56<37:22,  5.43it/s, lr=9.95e-6, step_loss=0.0284]07/18/2023 19:21:19 - INFO - __main__ - train loss is 3.132311863824725\n",
      "Steps:  19%|▍ | 2834/15000 [17:57<37:00,  5.48it/s, lr=9.95e-6, step_loss=0.139]07/18/2023 19:21:19 - INFO - __main__ - train loss is 3.13462490378879\n",
      "Steps:  19%|▏| 2835/15000 [17:57<36:46,  5.51it/s, lr=9.95e-6, step_loss=0.0023107/18/2023 19:21:19 - INFO - __main__ - train loss is 3.136534703662619\n",
      "Steps:  19%|▏| 2836/15000 [17:57<36:35,  5.54it/s, lr=9.95e-6, step_loss=0.0019107/18/2023 19:21:19 - INFO - __main__ - train loss is 3.146630203118548\n",
      "Steps:  19%|▏| 2837/15000 [17:57<36:27,  5.56it/s, lr=9.95e-6, step_loss=0.0101]07/18/2023 19:21:19 - INFO - __main__ - train loss is 3.150681430241093\n",
      "Steps:  19%|▏| 2838/15000 [17:57<36:22,  5.57it/s, lr=9.95e-6, step_loss=0.0040507/18/2023 19:21:20 - INFO - __main__ - train loss is 3.155663703335449\n",
      "Steps:  19%|▏| 2839/15000 [17:57<36:15,  5.59it/s, lr=9.95e-6, step_loss=0.0049807/18/2023 19:21:20 - INFO - __main__ - train loss is 3.343969915760681\n",
      "Steps:  19%|▍ | 2840/15000 [17:58<36:10,  5.60it/s, lr=9.95e-6, step_loss=0.188]07/18/2023 19:21:20 - INFO - __main__ - train loss is 3.346066122641787\n",
      "Steps:  19%|▏| 2841/15000 [17:58<36:08,  5.61it/s, lr=9.95e-6, step_loss=0.0021]07/18/2023 19:21:20 - INFO - __main__ - train loss is 3.4282479339744896\n",
      "Steps:  19%|▏| 2842/15000 [17:58<36:04,  5.62it/s, lr=9.95e-6, step_loss=0.0822]07/18/2023 19:21:20 - INFO - __main__ - train loss is 3.9454373174812645\n",
      "Steps:  19%|▍ | 2843/15000 [17:58<36:05,  5.61it/s, lr=9.95e-6, step_loss=0.517]07/18/2023 19:21:20 - INFO - __main__ - train loss is 4.061042202403769\n",
      "Steps:  19%|▍ | 2844/15000 [17:58<36:04,  5.62it/s, lr=9.95e-6, step_loss=0.116]07/18/2023 19:21:21 - INFO - __main__ - train loss is 4.3417172560002655\n",
      "Steps:  19%|▍ | 2845/15000 [17:59<36:03,  5.62it/s, lr=9.95e-6, step_loss=0.281]07/18/2023 19:21:21 - INFO - __main__ - train loss is 4.484783692052588\n",
      "Steps:  19%|▍ | 2846/15000 [17:59<36:02,  5.62it/s, lr=9.95e-6, step_loss=0.143]07/18/2023 19:21:21 - INFO - __main__ - train loss is 5.036038679769263\n",
      "Steps:  19%|▍ | 2847/15000 [17:59<36:02,  5.62it/s, lr=9.95e-6, step_loss=0.551]07/18/2023 19:21:21 - INFO - __main__ - train loss is 5.4633074530866\n",
      "Steps:  19%|▍ | 2848/15000 [17:59<36:01,  5.62it/s, lr=9.94e-6, step_loss=0.427]07/18/2023 19:21:21 - INFO - __main__ - train loss is 5.494513416429982\n",
      "Steps:  19%|▏| 2849/15000 [17:59<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.0312]07/18/2023 19:21:22 - INFO - __main__ - train loss is 5.528342807432637\n",
      "Steps:  19%|▏| 2850/15000 [17:59<36:01,  5.62it/s, lr=9.94e-6, step_loss=0.0338]07/18/2023 19:21:22 - INFO - __main__ - train loss is 5.6578504831995815\n",
      "Steps:  19%|▌  | 2851/15000 [18:00<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.13]07/18/2023 19:21:22 - INFO - __main__ - train loss is 5.985252806684002\n",
      "Steps:  19%|▍ | 2852/15000 [18:00<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.327]07/18/2023 19:21:22 - INFO - __main__ - train loss is 6.539262303849682\n",
      "Steps:  19%|▍ | 2853/15000 [18:00<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.554]07/18/2023 19:21:22 - INFO - __main__ - train loss is 6.541762177133933\n",
      "Steps:  19%|▏| 2854/15000 [18:00<36:01,  5.62it/s, lr=9.94e-6, step_loss=0.0025]07/18/2023 19:21:22 - INFO - __main__ - train loss is 6.8417997697833925\n",
      "Steps:  19%|▊   | 2855/15000 [18:00<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.3]07/18/2023 19:21:23 - INFO - __main__ - train loss is 6.881676107877865\n",
      "Steps:  19%|▏| 2856/15000 [18:01<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.0399]07/18/2023 19:21:23 - INFO - __main__ - train loss is 6.885024159448221\n",
      "Steps:  19%|▏| 2857/15000 [18:01<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.0033507/18/2023 19:21:23 - INFO - __main__ - train loss is 6.970019771950319\n",
      "Steps:  19%|▍ | 2858/15000 [18:01<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.085]07/18/2023 19:21:23 - INFO - __main__ - train loss is 7.056789874332026\n",
      "Steps:  19%|▏| 2859/15000 [18:01<35:59,  5.62it/s, lr=9.94e-6, step_loss=0.0868]07/18/2023 19:21:23 - INFO - __main__ - train loss is 7.091741970973089\n",
      "Steps:  19%|▍ | 2860/15000 [18:01<35:59,  5.62it/s, lr=9.94e-6, step_loss=0.035]07/18/2023 19:21:24 - INFO - __main__ - train loss is 7.098528526024893\n",
      "Steps:  19%|▏| 2861/15000 [18:01<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.0067907/18/2023 19:21:24 - INFO - __main__ - train loss is 7.1335381858516484\n",
      "Steps:  19%|▍ | 2862/15000 [18:02<35:59,  5.62it/s, lr=9.94e-6, step_loss=0.035]07/18/2023 19:21:24 - INFO - __main__ - train loss is 7.208016238408163\n",
      "Steps:  19%|▏| 2863/15000 [18:02<35:59,  5.62it/s, lr=9.94e-6, step_loss=0.0745]07/18/2023 19:21:24 - INFO - __main__ - train loss is 7.4533192433882505\n",
      "Steps:  19%|▍ | 2864/15000 [18:02<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.245]07/18/2023 19:21:24 - INFO - __main__ - train loss is 7.455224879318848\n",
      "Steps:  19%|▏| 2865/15000 [18:02<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.0019107/18/2023 19:21:24 - INFO - __main__ - train loss is 7.475039759883657\n",
      "Steps:  19%|▏| 2866/15000 [18:02<35:59,  5.62it/s, lr=9.94e-6, step_loss=0.0198]07/18/2023 19:21:25 - INFO - __main__ - train loss is 7.64007998467423\n",
      "Steps:  19%|▍ | 2867/15000 [18:02<35:59,  5.62it/s, lr=9.94e-6, step_loss=0.165]07/18/2023 19:21:25 - INFO - __main__ - train loss is 7.654578722314909\n",
      "Steps:  19%|▏| 2868/15000 [18:03<36:00,  5.62it/s, lr=9.94e-6, step_loss=0.0145]07/18/2023 19:21:25 - INFO - __main__ - train loss is 7.72092769225128\n",
      "Steps:  19%|▏| 2869/15000 [18:03<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.0663]07/18/2023 19:21:25 - INFO - __main__ - train loss is 7.938441432313994\n",
      "Steps:  19%|▍ | 2870/15000 [18:03<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.218]07/18/2023 19:21:25 - INFO - __main__ - train loss is 7.947479105787352\n",
      "Steps:  19%|▏| 2871/15000 [18:03<35:57,  5.62it/s, lr=9.94e-6, step_loss=0.0090407/18/2023 19:21:25 - INFO - __main__ - train loss is 8.161096281604841\n",
      "Steps:  19%|▍ | 2872/15000 [18:03<35:57,  5.62it/s, lr=9.94e-6, step_loss=0.214]07/18/2023 19:21:26 - INFO - __main__ - train loss is 8.23433570493944\n",
      "Steps:  19%|▏| 2873/15000 [18:04<35:56,  5.62it/s, lr=9.94e-6, step_loss=0.0732]07/18/2023 19:21:26 - INFO - __main__ - train loss is 8.240727354073897\n",
      "Steps:  19%|▏| 2874/15000 [18:04<35:56,  5.62it/s, lr=9.94e-6, step_loss=0.0063907/18/2023 19:21:26 - INFO - __main__ - train loss is 8.30778406211175\n",
      "Steps:  19%|▏| 2875/15000 [18:04<35:56,  5.62it/s, lr=9.94e-6, step_loss=0.0671]07/18/2023 19:21:26 - INFO - __main__ - train loss is 8.425122518325225\n",
      "Steps:  19%|▍ | 2876/15000 [18:04<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.117]07/18/2023 19:21:26 - INFO - __main__ - train loss is 8.460700188064948\n",
      "Steps:  19%|▏| 2877/15000 [18:04<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.0356]07/18/2023 19:21:27 - INFO - __main__ - train loss is 8.465488589601591\n",
      "Steps:  19%|▏| 2878/15000 [18:04<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.0047907/18/2023 19:21:27 - INFO - __main__ - train loss is 8.71995962341316\n",
      "Steps:  19%|▍ | 2879/15000 [18:05<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.254]07/18/2023 19:21:27 - INFO - __main__ - train loss is 8.9473678835202\n",
      "Steps:  19%|▍ | 2880/15000 [18:05<35:58,  5.62it/s, lr=9.94e-6, step_loss=0.227]07/18/2023 19:21:27 - INFO - __main__ - train loss is 8.958163300761953\n",
      "Steps:  19%|▏| 2881/15000 [18:05<35:57,  5.62it/s, lr=9.94e-6, step_loss=0.0108]07/18/2023 19:21:27 - INFO - __main__ - train loss is 8.978693748125806\n",
      "Steps:  19%|▏| 2882/15000 [18:05<35:57,  5.62it/s, lr=9.94e-6, step_loss=0.0205]07/18/2023 19:21:27 - INFO - __main__ - train loss is 9.568201208719984\n",
      "Steps:  19%|▌  | 2883/15000 [18:05<35:56,  5.62it/s, lr=9.94e-6, step_loss=0.59]07/18/2023 19:21:28 - INFO - __main__ - train loss is 9.729942390928045\n",
      "Steps:  19%|▍ | 2884/15000 [18:05<35:55,  5.62it/s, lr=9.94e-6, step_loss=0.162]07/18/2023 19:21:28 - INFO - __main__ - train loss is 10.07380653382279\n",
      "Steps:  19%|▍ | 2885/15000 [18:06<35:54,  5.62it/s, lr=9.94e-6, step_loss=0.344]07/18/2023 19:21:28 - INFO - __main__ - train loss is 10.323643574723974\n",
      "Steps:  19%|▌  | 2886/15000 [18:06<35:54,  5.62it/s, lr=9.94e-6, step_loss=0.25]07/18/2023 19:21:28 - INFO - __main__ - train loss is 10.66325611830689\n",
      "Steps:  19%|▌  | 2887/15000 [18:06<35:54,  5.62it/s, lr=9.94e-6, step_loss=0.34]07/18/2023 19:21:28 - INFO - __main__ - train loss is 11.091560611734167\n",
      "Steps:  19%|▍ | 2888/15000 [18:06<35:53,  5.62it/s, lr=9.94e-6, step_loss=0.428]07/18/2023 19:21:28 - INFO - __main__ - train loss is 11.396217415342107\n",
      "Steps:  19%|▍ | 2889/15000 [18:06<35:53,  5.62it/s, lr=9.94e-6, step_loss=0.305]07/18/2023 19:21:29 - INFO - __main__ - train loss is 11.452098889509216\n",
      "Steps:  19%|▏| 2890/15000 [18:07<35:53,  5.62it/s, lr=9.94e-6, step_loss=0.0559]07/18/2023 19:21:29 - INFO - __main__ - train loss is 11.480122765759006\n",
      "Steps:  19%|▍ | 2891/15000 [18:07<35:53,  5.62it/s, lr=9.94e-6, step_loss=0.028]07/18/2023 19:21:29 - INFO - __main__ - train loss is 12.264512857655063\n",
      "Steps:  19%|▍ | 2892/15000 [18:07<35:54,  5.62it/s, lr=9.94e-6, step_loss=0.784]07/18/2023 19:21:29 - INFO - __main__ - train loss is 12.947273096302524\n",
      "Steps:  19%|▍ | 2893/15000 [18:07<36:15,  5.57it/s, lr=9.94e-6, step_loss=0.683]07/18/2023 19:21:29 - INFO - __main__ - train loss is 13.243194869020954\n",
      "Steps:  19%|▍ | 2894/15000 [18:07<36:06,  5.59it/s, lr=9.94e-6, step_loss=0.296]07/18/2023 19:21:30 - INFO - __main__ - train loss is 13.285433432320133\n",
      "Steps:  19%|▏| 2895/15000 [18:07<36:17,  5.56it/s, lr=9.94e-6, step_loss=0.0422]07/18/2023 19:21:30 - INFO - __main__ - train loss is 13.297987793805078\n",
      "Steps:  19%|▏| 2896/15000 [18:08<36:07,  5.59it/s, lr=9.94e-6, step_loss=0.0126]07/18/2023 19:21:30 - INFO - __main__ - train loss is 13.95704219234176\n",
      "Steps:  19%|▍ | 2897/15000 [18:08<36:01,  5.60it/s, lr=9.94e-6, step_loss=0.659]07/18/2023 19:21:30 - INFO - __main__ - train loss is 14.30338001740165\n",
      "Steps:  19%|▍ | 2898/15000 [18:08<35:58,  5.61it/s, lr=9.94e-6, step_loss=0.346]07/18/2023 19:21:30 - INFO - __main__ - train loss is 14.346673843683675\n",
      "Steps:  19%|▏| 2899/15000 [18:08<35:54,  5.62it/s, lr=9.94e-6, step_loss=0.0433]07/18/2023 19:21:30 - INFO - __main__ - train loss is 14.551656824769452\n",
      "Steps:  19%|▍ | 2900/15000 [18:08<35:51,  5.62it/s, lr=9.94e-6, step_loss=0.205]07/18/2023 19:21:31 - INFO - __main__ - train loss is 14.698973131598905\n",
      "Steps:  19%|▍ | 2901/15000 [18:09<35:49,  5.63it/s, lr=9.94e-6, step_loss=0.147]07/18/2023 19:21:31 - INFO - __main__ - train loss is 14.709287218051031\n",
      "Steps:  19%|▏| 2902/15000 [18:09<35:48,  5.63it/s, lr=9.94e-6, step_loss=0.0103]07/18/2023 19:21:31 - INFO - __main__ - train loss is 14.812011032598093\n",
      "Steps:  19%|▍ | 2903/15000 [18:09<36:09,  5.58it/s, lr=9.94e-6, step_loss=0.103]07/18/2023 19:21:31 - INFO - __main__ - train loss is 14.81733209011145\n",
      "Steps:  19%|▏| 2904/15000 [18:09<36:33,  5.51it/s, lr=9.94e-6, step_loss=0.0053207/18/2023 19:21:31 - INFO - __main__ - train loss is 15.211697311373428\n",
      "Steps:  19%|▍ | 2905/15000 [18:09<36:21,  5.54it/s, lr=9.94e-6, step_loss=0.394]07/18/2023 19:21:32 - INFO - __main__ - train loss is 15.7225424956996\n",
      "Steps:  19%|▍ | 2906/15000 [18:09<36:29,  5.52it/s, lr=9.94e-6, step_loss=0.511]07/18/2023 19:21:32 - INFO - __main__ - train loss is 15.848533393116668\n",
      "Steps:  19%|▍ | 2907/15000 [18:10<36:38,  5.50it/s, lr=9.94e-6, step_loss=0.126]07/18/2023 19:21:32 - INFO - __main__ - train loss is 15.906863847048953\n",
      "Steps:  19%|▏| 2908/15000 [18:10<36:24,  5.53it/s, lr=9.94e-6, step_loss=0.0583]07/18/2023 19:21:32 - INFO - __main__ - train loss is 15.923812718363479\n",
      "Steps:  19%|▏| 2909/15000 [18:10<36:30,  5.52it/s, lr=9.94e-6, step_loss=0.0169]07/18/2023 19:21:32 - INFO - __main__ - train loss is 16.018386864336208\n",
      "Steps:  19%|▏| 2910/15000 [18:10<48:30,  4.15it/s, lr=9.94e-6, step_loss=0.0946]07/18/2023 19:21:33 - INFO - __main__ - Per validation step average loss is 0.0332145057618618\n",
      "07/18/2023 19:21:33 - INFO - __main__ - Cumulative validation average loss is 0.0332145057618618\n",
      "07/18/2023 19:21:33 - INFO - __main__ - Per validation step average loss is 0.37174883484840393\n",
      "07/18/2023 19:21:33 - INFO - __main__ - Cumulative validation average loss is 0.40496334061026573\n",
      "07/18/2023 19:21:33 - INFO - __main__ - Per validation step average loss is 0.5025060772895813\n",
      "07/18/2023 19:21:33 - INFO - __main__ - Cumulative validation average loss is 0.907469417899847\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Per validation step average loss is 0.23987001180648804\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Cumulative validation average loss is 1.147339429706335\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Per validation step average loss is 0.007976965978741646\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Cumulative validation average loss is 1.1553163956850767\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Per validation step average loss is 0.11646206676959991\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Cumulative validation average loss is 1.2717784624546766\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Per validation step average loss is 0.006556467153131962\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Cumulative validation average loss is 1.2783349296078086\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Per validation step average loss is 0.16408179700374603\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Cumulative validation average loss is 1.4424167266115546\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Per validation step average loss is 0.30408668518066406\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Cumulative validation average loss is 1.7465034117922187\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Per validation step average loss is 0.11320213973522186\n",
      "07/18/2023 19:21:34 - INFO - __main__ - Cumulative validation average loss is 1.8597055515274405\n",
      "07/18/2023 19:21:35 - INFO - __main__ - Per validation step average loss is 0.37233930826187134\n",
      "07/18/2023 19:21:35 - INFO - __main__ - Cumulative validation average loss is 2.232044859789312\n",
      "07/18/2023 19:21:35 - INFO - __main__ - Per validation step average loss is 0.0031251516193151474\n",
      "07/18/2023 19:21:35 - INFO - __main__ - Cumulative validation average loss is 2.235170011408627\n",
      "07/18/2023 19:21:35 - INFO - __main__ - Average validation loss for Epoch 29 is 0.1862641676173856\n",
      "07/18/2023 19:21:35 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:21:48 - INFO - __main__ - Starting epoch 30\n",
      "07/18/2023 19:21:49 - INFO - __main__ - train loss is 0.19526958465576172\n",
      "Steps:  19%|▏| 2911/15000 [18:26<16:45:12,  4.99s/it, lr=9.94e-6, step_loss=0.1907/18/2023 19:21:49 - INFO - __main__ - train loss is 0.1975639401935041\n",
      "Steps:  19%|▏| 2912/15000 [18:27<12:15:59,  3.65s/it, lr=9.94e-6, step_loss=0.0007/18/2023 19:21:50 - INFO - __main__ - train loss is 0.21576972445473075\n",
      "Steps:  19%|▏| 2913/15000 [18:27<9:07:54,  2.72s/it, lr=9.94e-6, step_loss=0.01807/18/2023 19:21:50 - INFO - __main__ - train loss is 0.25844979425892234\n",
      "Steps:  19%|▏| 2914/15000 [18:28<6:55:37,  2.06s/it, lr=9.94e-6, step_loss=0.04207/18/2023 19:21:51 - INFO - __main__ - train loss is 0.26481245970353484\n",
      "Steps:  19%|▏| 2915/15000 [18:29<5:23:47,  1.61s/it, lr=9.94e-6, step_loss=0.00607/18/2023 19:21:51 - INFO - __main__ - train loss is 0.7405957481823862\n",
      "Steps:  19%|▏| 2916/15000 [18:29<4:19:44,  1.29s/it, lr=9.94e-6, step_loss=0.47607/18/2023 19:21:52 - INFO - __main__ - train loss is 0.797915970440954\n",
      "Steps:  19%|▏| 2917/15000 [18:30<3:34:54,  1.07s/it, lr=9.94e-6, step_loss=0.05707/18/2023 19:21:52 - INFO - __main__ - train loss is 0.7998905458953232\n",
      "Steps:  19%|▏| 2918/15000 [18:30<3:03:20,  1.10it/s, lr=9.94e-6, step_loss=0.00107/18/2023 19:21:53 - INFO - __main__ - train loss is 0.8413250052835792\n",
      "Steps:  19%|▏| 2919/15000 [18:31<2:41:14,  1.25it/s, lr=9.94e-6, step_loss=0.04107/18/2023 19:21:53 - INFO - __main__ - train loss is 0.9167756789829582\n",
      "Steps:  19%|▏| 2920/15000 [18:31<2:25:57,  1.38it/s, lr=9.94e-6, step_loss=0.07507/18/2023 19:21:54 - INFO - __main__ - train loss is 1.0895210260059685\n",
      "Steps:  19%|▏| 2921/15000 [18:32<2:14:58,  1.49it/s, lr=9.94e-6, step_loss=0.17307/18/2023 19:21:55 - INFO - __main__ - train loss is 1.5377844923641533\n",
      "Steps:  19%|▏| 2922/15000 [18:32<2:07:33,  1.58it/s, lr=9.94e-6, step_loss=0.44807/18/2023 19:21:55 - INFO - __main__ - train loss is 1.561892950674519\n",
      "Steps:  19%|▏| 2923/15000 [18:33<2:02:09,  1.65it/s, lr=9.94e-6, step_loss=0.02407/18/2023 19:21:56 - INFO - __main__ - train loss is 1.5847180502023548\n",
      "Steps:  19%|▏| 2924/15000 [18:33<1:58:19,  1.70it/s, lr=9.94e-6, step_loss=0.02207/18/2023 19:21:56 - INFO - __main__ - train loss is 1.6174734958913177\n",
      "Steps:  20%|▏| 2925/15000 [18:34<1:55:34,  1.74it/s, lr=9.94e-6, step_loss=0.03207/18/2023 19:21:57 - INFO - __main__ - train loss is 2.0726045498158783\n",
      "Steps:  20%|▏| 2926/15000 [18:35<1:53:44,  1.77it/s, lr=9.94e-6, step_loss=0.45507/18/2023 19:21:57 - INFO - __main__ - train loss is 2.0874790081288666\n",
      "Steps:  20%|▏| 2927/15000 [18:35<1:52:47,  1.78it/s, lr=9.94e-6, step_loss=0.01407/18/2023 19:21:58 - INFO - __main__ - train loss is 2.09002448618412\n",
      "Steps:  20%|▏| 2928/15000 [18:36<1:52:00,  1.80it/s, lr=9.94e-6, step_loss=0.00207/18/2023 19:21:58 - INFO - __main__ - train loss is 2.413018837571144\n",
      "Steps:  20%|▏| 2929/15000 [18:36<1:51:43,  1.80it/s, lr=9.94e-6, step_loss=0.32307/18/2023 19:21:59 - INFO - __main__ - train loss is 2.7140395790338516\n",
      "Steps:  20%|▏| 2930/15000 [18:37<1:59:51,  1.68it/s, lr=9.94e-6, step_loss=0.30107/18/2023 19:22:00 - INFO - __main__ - train loss is 2.7329003922641277\n",
      "Steps:  20%|▏| 2931/15000 [18:37<1:58:12,  1.70it/s, lr=9.94e-6, step_loss=0.01807/18/2023 19:22:00 - INFO - __main__ - train loss is 3.3473140709102154\n",
      "Steps:  20%|▏| 2932/15000 [18:38<1:56:39,  1.72it/s, lr=9.94e-6, step_loss=0.61407/18/2023 19:22:01 - INFO - __main__ - train loss is 3.3876864798367023\n",
      "Steps:  20%|▏| 2933/15000 [18:39<1:54:26,  1.76it/s, lr=9.94e-6, step_loss=0.04007/18/2023 19:22:01 - INFO - __main__ - train loss is 3.467398028820753\n",
      "Steps:  20%|▏| 2934/15000 [18:39<1:52:56,  1.78it/s, lr=9.94e-6, step_loss=0.07907/18/2023 19:22:02 - INFO - __main__ - train loss is 3.4722867272794247\n",
      "Steps:  20%|▏| 2935/15000 [18:40<1:51:53,  1.80it/s, lr=9.94e-6, step_loss=0.00407/18/2023 19:22:02 - INFO - __main__ - train loss is 3.4817294906824827\n",
      "Steps:  20%|▏| 2936/15000 [18:40<1:51:11,  1.81it/s, lr=9.94e-6, step_loss=0.00907/18/2023 19:22:03 - INFO - __main__ - train loss is 3.489571377635002\n",
      "Steps:  20%|▏| 2937/15000 [18:41<1:51:50,  1.80it/s, lr=9.94e-6, step_loss=0.00707/18/2023 19:22:03 - INFO - __main__ - train loss is 3.53564315661788\n",
      "Steps:  20%|▏| 2938/15000 [18:41<1:51:08,  1.81it/s, lr=9.94e-6, step_loss=0.04607/18/2023 19:22:04 - INFO - __main__ - train loss is 3.690610732883215\n",
      "Steps:  20%|▏| 2939/15000 [18:42<1:50:44,  1.82it/s, lr=9.94e-6, step_loss=0.15507/18/2023 19:22:05 - INFO - __main__ - train loss is 3.7713327519595623\n",
      "Steps:  20%|▏| 2940/15000 [18:42<1:50:19,  1.82it/s, lr=9.94e-6, step_loss=0.08007/18/2023 19:22:05 - INFO - __main__ - train loss is 4.099352192133665\n",
      "Steps:  20%|▏| 2941/15000 [18:43<1:49:46,  1.83it/s, lr=9.94e-6, step_loss=0.32807/18/2023 19:22:06 - INFO - __main__ - train loss is 4.117893096059561\n",
      "Steps:  20%|▏| 2942/15000 [18:44<1:49:42,  1.83it/s, lr=9.94e-6, step_loss=0.01807/18/2023 19:22:06 - INFO - __main__ - train loss is 4.143886335194111\n",
      "Steps:  20%|▏| 2943/15000 [18:44<1:49:45,  1.83it/s, lr=9.94e-6, step_loss=0.02607/18/2023 19:22:07 - INFO - __main__ - train loss is 4.347294203937054\n",
      "Steps:  20%|▏| 2944/15000 [18:45<1:49:26,  1.84it/s, lr=9.94e-6, step_loss=0.20307/18/2023 19:22:07 - INFO - __main__ - train loss is 4.4310653656721115\n",
      "Steps:  20%|▏| 2945/15000 [18:45<1:49:29,  1.83it/s, lr=9.94e-6, step_loss=0.08307/18/2023 19:22:08 - INFO - __main__ - train loss is 4.506706975400448\n",
      "Steps:  20%|▏| 2946/15000 [18:46<1:49:07,  1.84it/s, lr=9.94e-6, step_loss=0.07507/18/2023 19:22:08 - INFO - __main__ - train loss is 4.603203289210796\n",
      "Steps:  20%|▏| 2947/15000 [18:46<1:48:45,  1.85it/s, lr=9.94e-6, step_loss=0.09607/18/2023 19:22:09 - INFO - __main__ - train loss is 4.851212926208973\n",
      "Steps:  20%|▏| 2948/15000 [18:47<1:48:43,  1.85it/s, lr=9.94e-6, step_loss=0.24807/18/2023 19:22:09 - INFO - __main__ - train loss is 5.048531003296375\n",
      "Steps:  20%|▏| 2949/15000 [18:47<1:48:22,  1.85it/s, lr=9.94e-6, step_loss=0.19707/18/2023 19:22:10 - INFO - __main__ - train loss is 5.058656308799982\n",
      "Steps:  20%|▏| 2950/15000 [18:48<1:48:36,  1.85it/s, lr=9.94e-6, step_loss=0.01007/18/2023 19:22:10 - INFO - __main__ - train loss is 5.092715922743082\n",
      "Steps:  20%|▏| 2951/15000 [18:48<1:49:49,  1.83it/s, lr=9.94e-6, step_loss=0.03407/18/2023 19:22:11 - INFO - __main__ - train loss is 5.257252607494593\n",
      "Steps:  20%|▏| 2952/15000 [18:49<1:57:40,  1.71it/s, lr=9.94e-6, step_loss=0.16507/18/2023 19:22:12 - INFO - __main__ - train loss is 5.264471592381597\n",
      "Steps:  20%|▏| 2953/15000 [18:50<1:57:36,  1.71it/s, lr=9.94e-6, step_loss=0.00707/18/2023 19:22:12 - INFO - __main__ - train loss is 5.362668814137578\n",
      "Steps:  20%|▏| 2954/15000 [18:50<1:55:59,  1.73it/s, lr=9.94e-6, step_loss=0.09807/18/2023 19:22:13 - INFO - __main__ - train loss is 5.7024052161723375\n",
      "Steps:  20%|▏| 2955/15000 [18:51<1:53:46,  1.76it/s, lr=9.94e-6, step_loss=0.34]07/18/2023 19:22:13 - INFO - __main__ - train loss is 5.7041169526055455\n",
      "Steps:  20%|▏| 2956/15000 [18:51<1:52:25,  1.79it/s, lr=9.94e-6, step_loss=0.00107/18/2023 19:22:14 - INFO - __main__ - train loss is 5.71116718929261\n",
      "Steps:  20%|▏| 2957/15000 [18:52<1:51:15,  1.80it/s, lr=9.94e-6, step_loss=0.00707/18/2023 19:22:15 - INFO - __main__ - train loss is 6.070121738128364\n",
      "Steps:  20%|▏| 2958/15000 [18:52<1:50:22,  1.82it/s, lr=9.94e-6, step_loss=0.35907/18/2023 19:22:15 - INFO - __main__ - train loss is 6.261025222949684\n",
      "Steps:  20%|▏| 2959/15000 [18:53<1:49:52,  1.83it/s, lr=9.94e-6, step_loss=0.19107/18/2023 19:22:16 - INFO - __main__ - train loss is 6.757930847816169\n",
      "Steps:  20%|▏| 2960/15000 [18:53<1:49:42,  1.83it/s, lr=9.94e-6, step_loss=0.49707/18/2023 19:22:16 - INFO - __main__ - train loss is 6.78131930809468\n",
      "Steps:  20%|▏| 2961/15000 [18:54<1:49:10,  1.84it/s, lr=9.94e-6, step_loss=0.02307/18/2023 19:22:17 - INFO - __main__ - train loss is 6.875670748762786\n",
      "Steps:  20%|▏| 2962/15000 [18:55<1:49:00,  1.84it/s, lr=9.94e-6, step_loss=0.09407/18/2023 19:22:17 - INFO - __main__ - train loss is 7.398976403288543\n",
      "Steps:  20%|▏| 2963/15000 [18:55<1:48:57,  1.84it/s, lr=9.94e-6, step_loss=0.52307/18/2023 19:22:18 - INFO - __main__ - train loss is 7.41378627717495\n",
      "Steps:  20%|▏| 2964/15000 [18:56<1:49:01,  1.84it/s, lr=9.94e-6, step_loss=0.01407/18/2023 19:22:18 - INFO - __main__ - train loss is 7.504988387227058\n",
      "Steps:  20%|▏| 2965/15000 [18:56<1:49:13,  1.84it/s, lr=9.94e-6, step_loss=0.09107/18/2023 19:22:19 - INFO - __main__ - train loss is 7.666791409254074\n",
      "Steps:  20%|▏| 2966/15000 [18:57<1:49:23,  1.83it/s, lr=9.94e-6, step_loss=0.16207/18/2023 19:22:19 - INFO - __main__ - train loss is 7.697499573230743\n",
      "Steps:  20%|▏| 2967/15000 [18:57<1:49:03,  1.84it/s, lr=9.94e-6, step_loss=0.03007/18/2023 19:22:20 - INFO - __main__ - train loss is 7.703704828862101\n",
      "Steps:  20%|▏| 2968/15000 [18:58<1:49:25,  1.83it/s, lr=9.94e-6, step_loss=0.00607/18/2023 19:22:20 - INFO - __main__ - train loss is 7.726262623909861\n",
      "Steps:  20%|▏| 2969/15000 [18:58<1:49:31,  1.83it/s, lr=9.94e-6, step_loss=0.02207/18/2023 19:22:21 - INFO - __main__ - train loss is 7.753068492282182\n",
      "Steps:  20%|▏| 2970/15000 [18:59<1:49:32,  1.83it/s, lr=9.94e-6, step_loss=0.02607/18/2023 19:22:22 - INFO - __main__ - train loss is 7.96143849240616\n",
      "Steps:  20%|▏| 2971/15000 [18:59<1:49:28,  1.83it/s, lr=9.94e-6, step_loss=0.20807/18/2023 19:22:22 - INFO - __main__ - train loss is 7.969493035692722\n",
      "Steps:  20%|▏| 2972/15000 [19:00<1:49:23,  1.83it/s, lr=9.94e-6, step_loss=0.00807/18/2023 19:22:23 - INFO - __main__ - train loss is 8.552671555895358\n",
      "Steps:  20%|▏| 2973/15000 [19:01<1:49:19,  1.83it/s, lr=9.94e-6, step_loss=0.58307/18/2023 19:22:23 - INFO - __main__ - train loss is 8.83216640772298\n",
      "Steps:  20%|▏| 2974/15000 [19:01<1:49:42,  1.83it/s, lr=9.94e-6, step_loss=0.27907/18/2023 19:22:24 - INFO - __main__ - train loss is 9.106024954933673\n",
      "Steps:  20%|▏| 2975/15000 [19:02<1:51:18,  1.80it/s, lr=9.94e-6, step_loss=0.27407/18/2023 19:22:24 - INFO - __main__ - train loss is 9.120500932913274\n",
      "Steps:  20%|▏| 2976/15000 [19:02<1:52:40,  1.78it/s, lr=9.94e-6, step_loss=0.01407/18/2023 19:22:25 - INFO - __main__ - train loss is 9.154797214549035\n",
      "Steps:  20%|▏| 2977/15000 [19:03<1:51:40,  1.79it/s, lr=9.94e-6, step_loss=0.03407/18/2023 19:22:25 - INFO - __main__ - train loss is 9.166318302508444\n",
      "Steps:  20%|▏| 2978/15000 [19:03<1:51:03,  1.80it/s, lr=9.94e-6, step_loss=0.01107/18/2023 19:22:26 - INFO - __main__ - train loss is 9.169548351550475\n",
      "Steps:  20%|▏| 2979/15000 [19:04<1:50:22,  1.82it/s, lr=9.94e-6, step_loss=0.00307/18/2023 19:22:27 - INFO - __main__ - train loss is 9.582285452866927\n",
      "Steps:  20%|▏| 2980/15000 [19:04<1:50:18,  1.82it/s, lr=9.94e-6, step_loss=0.41307/18/2023 19:22:27 - INFO - __main__ - train loss is 9.956832338357344\n",
      "Steps:  20%|▏| 2981/15000 [19:05<1:49:58,  1.82it/s, lr=9.94e-6, step_loss=0.37507/18/2023 19:22:28 - INFO - __main__ - train loss is 10.351071167970076\n",
      "Steps:  20%|▏| 2982/15000 [19:06<1:49:55,  1.82it/s, lr=9.94e-6, step_loss=0.39407/18/2023 19:22:28 - INFO - __main__ - train loss is 10.362284859875217\n",
      "Steps:  20%|▏| 2983/15000 [19:06<1:49:50,  1.82it/s, lr=9.94e-6, step_loss=0.01107/18/2023 19:22:29 - INFO - __main__ - train loss is 10.530178448418155\n",
      "Steps:  20%|▏| 2984/15000 [19:07<1:49:42,  1.83it/s, lr=9.94e-6, step_loss=0.16807/18/2023 19:22:29 - INFO - __main__ - train loss is 10.531944740796462\n",
      "Steps:  20%|▏| 2985/15000 [19:07<1:49:08,  1.83it/s, lr=9.94e-6, step_loss=0.00107/18/2023 19:22:30 - INFO - __main__ - train loss is 10.568924084538594\n",
      "Steps:  20%|▏| 2986/15000 [19:08<1:49:14,  1.83it/s, lr=9.94e-6, step_loss=0.03707/18/2023 19:22:30 - INFO - __main__ - train loss is 10.651100427145138\n",
      "Steps:  20%|▏| 2987/15000 [19:08<1:49:12,  1.83it/s, lr=9.94e-6, step_loss=0.08207/18/2023 19:22:31 - INFO - __main__ - train loss is 10.66956538730301\n",
      "Steps:  20%|▏| 2988/15000 [19:09<1:48:45,  1.84it/s, lr=9.94e-6, step_loss=0.01807/18/2023 19:22:31 - INFO - __main__ - train loss is 10.676681123906747\n",
      "Steps:  20%|▏| 2989/15000 [19:09<1:48:42,  1.84it/s, lr=9.94e-6, step_loss=0.00707/18/2023 19:22:32 - INFO - __main__ - train loss is 11.23827775591053\n",
      "Steps:  20%|▏| 2990/15000 [19:10<1:49:33,  1.83it/s, lr=9.94e-6, step_loss=0.56207/18/2023 19:22:33 - INFO - __main__ - train loss is 11.275689564878121\n",
      "Steps:  20%|▏| 2991/15000 [19:10<1:49:38,  1.83it/s, lr=9.94e-6, step_loss=0.03707/18/2023 19:22:33 - INFO - __main__ - train loss is 11.38292832695879\n",
      "Steps:  20%|▏| 2992/15000 [19:11<1:49:56,  1.82it/s, lr=9.94e-6, step_loss=0.10707/18/2023 19:22:34 - INFO - __main__ - train loss is 11.534708187216893\n",
      "Steps:  20%|▏| 2993/15000 [19:12<1:50:01,  1.82it/s, lr=9.94e-6, step_loss=0.15207/18/2023 19:22:34 - INFO - __main__ - train loss is 11.595841951901093\n",
      "Steps:  20%|▏| 2994/15000 [19:12<1:50:11,  1.82it/s, lr=9.94e-6, step_loss=0.06107/18/2023 19:22:35 - INFO - __main__ - train loss is 11.79613881581463\n",
      "Steps:  20%|▍ | 2995/15000 [19:13<1:50:41,  1.81it/s, lr=9.94e-6, step_loss=0.2]07/18/2023 19:22:35 - INFO - __main__ - train loss is 11.875233613187447\n",
      "Steps:  20%|▏| 2996/15000 [19:13<1:50:41,  1.81it/s, lr=9.94e-6, step_loss=0.07907/18/2023 19:22:36 - INFO - __main__ - train loss is 12.026963971788064\n",
      "Steps:  20%|▏| 2997/15000 [19:14<1:50:03,  1.82it/s, lr=9.94e-6, step_loss=0.15207/18/2023 19:22:36 - INFO - __main__ - train loss is 12.199405454332009\n",
      "Steps:  20%|▏| 2998/15000 [19:14<1:50:01,  1.82it/s, lr=9.94e-6, step_loss=0.17207/18/2023 19:22:37 - INFO - __main__ - train loss is 12.204527852358297\n",
      "Steps:  20%|▏| 2999/15000 [19:15<1:57:22,  1.70it/s, lr=9.94e-6, step_loss=0.00507/18/2023 19:22:38 - INFO - __main__ - train loss is 12.762813327135518\n",
      "Steps:  20%|▏| 3000/15000 [19:16<1:56:59,  1.71it/s, lr=9.94e-6, step_loss=0.00507/18/2023 19:22:38 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-3000\n",
      "07/18/2023 19:22:38 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:22:38,266] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:22:38,272] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:22:38,272] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:22:38,281] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:22:38,282] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:22:38,304] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:22:38,305] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:22:38,305] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:22:38 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-3000/pytorch_model\n",
      "07/18/2023 19:22:38 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-3000/scheduler.bin\n",
      "07/18/2023 19:22:38 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-3000/random_states_0.pkl\n",
      "07/18/2023 19:22:38 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-3000\n",
      "Steps:  20%|▏| 3000/15000 [19:16<1:56:59,  1.71it/s, lr=9.94e-6, step_loss=0.55807/18/2023 19:22:38 - INFO - __main__ - train loss is 13.574984547914937\n",
      "Steps:  20%|▏| 3001/15000 [19:16<1:57:52,  1.70it/s, lr=9.94e-6, step_loss=0.81207/18/2023 19:22:39 - INFO - __main__ - train loss is 13.882669446291402\n",
      "Steps:  20%|▏| 3002/15000 [19:17<1:55:07,  1.74it/s, lr=9.94e-6, step_loss=0.30807/18/2023 19:22:39 - INFO - __main__ - train loss is 14.136309382738546\n",
      "Steps:  20%|▏| 3003/15000 [19:17<1:53:03,  1.77it/s, lr=9.94e-6, step_loss=0.25407/18/2023 19:22:40 - INFO - __main__ - train loss is 14.28610206884332\n",
      "Steps:  20%|▏| 3004/15000 [19:18<1:51:20,  1.80it/s, lr=9.94e-6, step_loss=0.15]07/18/2023 19:22:40 - INFO - __main__ - train loss is 14.812148940982297\n",
      "Steps:  20%|▏| 3005/15000 [19:18<1:50:25,  1.81it/s, lr=9.94e-6, step_loss=0.52607/18/2023 19:22:41 - INFO - __main__ - train loss is 14.961945188464597\n",
      "Steps:  20%|▏| 3006/15000 [19:19<1:49:34,  1.82it/s, lr=9.94e-6, step_loss=0.15]07/18/2023 19:22:42 - INFO - __main__ - train loss is 15.368958008708432\n",
      "Steps:  20%|▏| 3007/15000 [19:20<2:03:31,  1.62it/s, lr=9.94e-6, step_loss=0.40707/18/2023 19:22:43 - INFO - __main__ - Per validation step average loss is 0.2518855035305023\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Cumulative validation average loss is 0.2518855035305023\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Per validation step average loss is 0.0018447546754032373\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Cumulative validation average loss is 0.25373025820590556\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Per validation step average loss is 0.045668624341487885\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Cumulative validation average loss is 0.29939888254739344\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Per validation step average loss is 0.15517549216747284\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Cumulative validation average loss is 0.4545743747148663\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Per validation step average loss is 0.021071208640933037\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Cumulative validation average loss is 0.4756455833557993\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Per validation step average loss is 0.03099321946501732\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Cumulative validation average loss is 0.5066388028208166\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Per validation step average loss is 0.003040058072656393\n",
      "07/18/2023 19:22:43 - INFO - __main__ - Cumulative validation average loss is 0.509678860893473\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Per validation step average loss is 0.06922535598278046\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Cumulative validation average loss is 0.5789042168762535\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Per validation step average loss is 0.22876013815402985\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Cumulative validation average loss is 0.8076643550302833\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Per validation step average loss is 0.11898711323738098\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Cumulative validation average loss is 0.9266514682676643\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Per validation step average loss is 0.0012110447278246284\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Cumulative validation average loss is 0.9278625129954889\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Per validation step average loss is 0.16719399392604828\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Cumulative validation average loss is 1.0950565069215372\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Average validation loss for Epoch 30 is 0.0912547089101281\n",
      "07/18/2023 19:22:44 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:22:57 - INFO - __main__ - Starting epoch 31\n",
      "07/18/2023 19:22:58 - INFO - __main__ - train loss is 0.5291106700897217\n",
      "Steps:  20%|▏| 3008/15000 [19:36<17:22:51,  5.22s/it, lr=9.94e-6, step_loss=0.5207/18/2023 19:22:58 - INFO - __main__ - train loss is 0.6245083883404732\n",
      "Steps:  20%|▏| 3009/15000 [19:36<12:21:58,  3.71s/it, lr=9.94e-6, step_loss=0.0907/18/2023 19:22:58 - INFO - __main__ - train loss is 0.989313580095768\n",
      "Steps:  20%|▏| 3010/15000 [19:36<8:52:15,  2.66s/it, lr=9.94e-6, step_loss=0.36507/18/2023 19:22:58 - INFO - __main__ - train loss is 1.2476577833294868\n",
      "Steps:  20%|▏| 3011/15000 [19:36<6:25:57,  1.93s/it, lr=9.94e-6, step_loss=0.25807/18/2023 19:22:59 - INFO - __main__ - train loss is 1.251316968118772\n",
      "Steps:  20%|▏| 3012/15000 [19:36<4:43:23,  1.42s/it, lr=9.94e-6, step_loss=0.00307/18/2023 19:22:59 - INFO - __main__ - train loss is 1.5537017022725195\n",
      "Steps:  20%|▏| 3013/15000 [19:37<3:30:25,  1.05s/it, lr=9.94e-6, step_loss=0.30207/18/2023 19:22:59 - INFO - __main__ - train loss is 1.6304972951766104\n",
      "Steps:  20%|▏| 3014/15000 [19:37<2:38:18,  1.26it/s, lr=9.94e-6, step_loss=0.07607/18/2023 19:22:59 - INFO - __main__ - train loss is 1.880953270709142\n",
      "Steps:  20%|▏| 3015/15000 [19:37<2:01:28,  1.64it/s, lr=9.94e-6, step_loss=0.25]07/18/2023 19:22:59 - INFO - __main__ - train loss is 2.050831336295232\n",
      "Steps:  20%|▏| 3016/15000 [19:37<1:35:42,  2.09it/s, lr=9.94e-6, step_loss=0.17]07/18/2023 19:22:59 - INFO - __main__ - train loss is 2.654673654353246\n",
      "Steps:  20%|▏| 3017/15000 [19:37<1:17:40,  2.57it/s, lr=9.94e-6, step_loss=0.60407/18/2023 19:23:00 - INFO - __main__ - train loss is 2.7051605691667646\n",
      "Steps:  20%|▏| 3018/15000 [19:38<1:05:22,  3.05it/s, lr=9.94e-6, step_loss=0.05007/18/2023 19:23:00 - INFO - __main__ - train loss is 2.7223364596720785\n",
      "Steps:  20%|▏| 3019/15000 [19:38<56:39,  3.52it/s, lr=9.94e-6, step_loss=0.0172]07/18/2023 19:23:00 - INFO - __main__ - train loss is 2.760951276635751\n",
      "Steps:  20%|▏| 3020/15000 [19:38<50:21,  3.96it/s, lr=9.94e-6, step_loss=0.0386]07/18/2023 19:23:00 - INFO - __main__ - train loss is 3.0352568288799375\n",
      "Steps:  20%|▍ | 3021/15000 [19:38<45:55,  4.35it/s, lr=9.94e-6, step_loss=0.274]07/18/2023 19:23:00 - INFO - __main__ - train loss is 3.343680586433038\n",
      "Steps:  20%|▍ | 3022/15000 [19:38<43:08,  4.63it/s, lr=9.94e-6, step_loss=0.308]07/18/2023 19:23:01 - INFO - __main__ - train loss is 3.356494946172461\n",
      "Steps:  20%|▏| 3023/15000 [19:38<40:58,  4.87it/s, lr=9.94e-6, step_loss=0.0128]07/18/2023 19:23:01 - INFO - __main__ - train loss is 3.3699181058909744\n",
      "Steps:  20%|▏| 3024/15000 [19:39<39:20,  5.07it/s, lr=9.94e-6, step_loss=0.0134]07/18/2023 19:23:01 - INFO - __main__ - train loss is 3.3753627131227404\n",
      "Steps:  20%|▏| 3025/15000 [19:39<38:14,  5.22it/s, lr=9.94e-6, step_loss=0.0054407/18/2023 19:23:01 - INFO - __main__ - train loss is 3.6688617060426623\n",
      "Steps:  20%|▍ | 3026/15000 [19:39<37:29,  5.32it/s, lr=9.94e-6, step_loss=0.293]07/18/2023 19:23:01 - INFO - __main__ - train loss is 3.6711929426528513\n",
      "Steps:  20%|▏| 3027/15000 [19:39<37:15,  5.35it/s, lr=9.94e-6, step_loss=0.0023307/18/2023 19:23:01 - INFO - __main__ - train loss is 3.6735738036222756\n",
      "Steps:  20%|▏| 3028/15000 [19:39<37:12,  5.36it/s, lr=9.94e-6, step_loss=0.0023807/18/2023 19:23:02 - INFO - __main__ - train loss is 3.6783874626271427\n",
      "Steps:  20%|▏| 3029/15000 [19:40<37:10,  5.37it/s, lr=9.94e-6, step_loss=0.0048107/18/2023 19:23:02 - INFO - __main__ - train loss is 3.747832193505019\n",
      "Steps:  20%|▏| 3030/15000 [19:40<37:02,  5.39it/s, lr=9.94e-6, step_loss=0.0694]07/18/2023 19:23:02 - INFO - __main__ - train loss is 4.486113622318953\n",
      "Steps:  20%|▍ | 3031/15000 [19:40<36:52,  5.41it/s, lr=9.94e-6, step_loss=0.738]07/18/2023 19:23:02 - INFO - __main__ - train loss is 4.6287557180039585\n",
      "Steps:  20%|▍ | 3032/15000 [19:40<36:51,  5.41it/s, lr=9.94e-6, step_loss=0.143]07/18/2023 19:23:02 - INFO - __main__ - train loss is 4.869300841819495\n",
      "Steps:  20%|▍ | 3033/15000 [19:40<36:29,  5.46it/s, lr=9.94e-6, step_loss=0.241]07/18/2023 19:23:03 - INFO - __main__ - train loss is 4.906738347839564\n",
      "Steps:  20%|▏| 3034/15000 [19:40<36:13,  5.51it/s, lr=9.94e-6, step_loss=0.0374]07/18/2023 19:23:03 - INFO - __main__ - train loss is 4.916029859799892\n",
      "Steps:  20%|▏| 3035/15000 [19:41<36:03,  5.53it/s, lr=9.94e-6, step_loss=0.0092907/18/2023 19:23:03 - INFO - __main__ - train loss is 4.928067238535732\n",
      "Steps:  20%|▍ | 3036/15000 [19:41<36:10,  5.51it/s, lr=9.94e-6, step_loss=0.012]07/18/2023 19:23:03 - INFO - __main__ - train loss is 4.93965581478551\n",
      "Steps:  20%|▏| 3037/15000 [19:41<36:02,  5.53it/s, lr=9.94e-6, step_loss=0.0116]07/18/2023 19:23:03 - INFO - __main__ - train loss is 5.075007144827396\n",
      "Steps:  20%|▍ | 3038/15000 [19:41<35:56,  5.55it/s, lr=9.94e-6, step_loss=0.135]07/18/2023 19:23:03 - INFO - __main__ - train loss is 5.504962627310306\n",
      "Steps:  20%|▌  | 3039/15000 [19:41<35:51,  5.56it/s, lr=9.94e-6, step_loss=0.43]07/18/2023 19:23:04 - INFO - __main__ - train loss is 5.942239944357425\n",
      "Steps:  20%|▍ | 3040/15000 [19:42<35:49,  5.56it/s, lr=9.94e-6, step_loss=0.437]07/18/2023 19:23:04 - INFO - __main__ - train loss is 5.957644151989371\n",
      "Steps:  20%|▏| 3041/15000 [19:42<35:45,  5.57it/s, lr=9.94e-6, step_loss=0.0154]07/18/2023 19:23:04 - INFO - __main__ - train loss is 5.96487815445289\n",
      "Steps:  20%|▏| 3042/15000 [19:42<35:42,  5.58it/s, lr=9.94e-6, step_loss=0.0072307/18/2023 19:23:04 - INFO - __main__ - train loss is 5.9701976156793535\n",
      "Steps:  20%|▏| 3043/15000 [19:42<35:39,  5.59it/s, lr=9.94e-6, step_loss=0.0053207/18/2023 19:23:04 - INFO - __main__ - train loss is 6.291496691759676\n",
      "Steps:  20%|▍ | 3044/15000 [19:42<35:41,  5.58it/s, lr=9.94e-6, step_loss=0.321]07/18/2023 19:23:05 - INFO - __main__ - train loss is 6.3974658898077905\n",
      "Steps:  20%|▍ | 3045/15000 [19:42<35:40,  5.58it/s, lr=9.94e-6, step_loss=0.106]07/18/2023 19:23:05 - INFO - __main__ - train loss is 6.491869812365621\n",
      "Steps:  20%|▏| 3046/15000 [19:43<35:40,  5.58it/s, lr=9.94e-6, step_loss=0.0944]07/18/2023 19:23:05 - INFO - __main__ - train loss is 6.518247404601425\n",
      "Steps:  20%|▏| 3047/15000 [19:43<35:40,  5.59it/s, lr=9.94e-6, step_loss=0.0264]07/18/2023 19:23:05 - INFO - __main__ - train loss is 6.519889411865734\n",
      "Steps:  20%|▏| 3048/15000 [19:43<35:39,  5.59it/s, lr=9.94e-6, step_loss=0.0016407/18/2023 19:23:05 - INFO - __main__ - train loss is 6.530626590712927\n",
      "Steps:  20%|▏| 3049/15000 [19:43<35:38,  5.59it/s, lr=9.94e-6, step_loss=0.0107]07/18/2023 19:23:05 - INFO - __main__ - train loss is 6.533696443657391\n",
      "Steps:  20%|▏| 3050/15000 [19:43<35:36,  5.59it/s, lr=9.94e-6, step_loss=0.0030707/18/2023 19:23:06 - INFO - __main__ - train loss is 6.899487019400112\n",
      "Steps:  20%|▍ | 3051/15000 [19:44<35:35,  5.60it/s, lr=9.94e-6, step_loss=0.366]07/18/2023 19:23:06 - INFO - __main__ - train loss is 7.331944049219601\n",
      "Steps:  20%|▍ | 3052/15000 [19:44<35:34,  5.60it/s, lr=9.94e-6, step_loss=0.432]07/18/2023 19:23:06 - INFO - __main__ - train loss is 8.07932901463937\n",
      "Steps:  20%|▍ | 3053/15000 [19:44<35:38,  5.59it/s, lr=9.94e-6, step_loss=0.747]07/18/2023 19:23:06 - INFO - __main__ - train loss is 8.31933809898328\n",
      "Steps:  20%|▌  | 3054/15000 [19:44<35:36,  5.59it/s, lr=9.94e-6, step_loss=0.24]07/18/2023 19:23:06 - INFO - __main__ - train loss is 8.324920224375091\n",
      "Steps:  20%|▏| 3055/15000 [19:44<35:34,  5.60it/s, lr=9.94e-6, step_loss=0.0055807/18/2023 19:23:07 - INFO - __main__ - train loss is 8.59456841868814\n",
      "Steps:  20%|▌  | 3056/15000 [19:44<35:33,  5.60it/s, lr=9.94e-6, step_loss=0.27]07/18/2023 19:23:07 - INFO - __main__ - train loss is 9.193775581545196\n",
      "Steps:  20%|▍ | 3057/15000 [19:45<35:32,  5.60it/s, lr=9.94e-6, step_loss=0.599]07/18/2023 19:23:07 - INFO - __main__ - train loss is 9.19901426450815\n",
      "Steps:  20%|▏| 3058/15000 [19:45<35:50,  5.55it/s, lr=9.94e-6, step_loss=0.0052407/18/2023 19:23:07 - INFO - __main__ - train loss is 9.310288134380244\n",
      "Steps:  20%|▍ | 3059/15000 [19:45<36:04,  5.52it/s, lr=9.94e-6, step_loss=0.111]07/18/2023 19:23:07 - INFO - __main__ - train loss is 9.311745114158839\n",
      "Steps:  20%|▏| 3060/15000 [19:45<35:54,  5.54it/s, lr=9.94e-6, step_loss=0.0014607/18/2023 19:23:07 - INFO - __main__ - train loss is 9.363129019271582\n",
      "Steps:  20%|▏| 3061/15000 [19:45<35:46,  5.56it/s, lr=9.94e-6, step_loss=0.0514]07/18/2023 19:23:08 - INFO - __main__ - train loss is 9.813924252521247\n",
      "Steps:  20%|▍ | 3062/15000 [19:45<35:41,  5.57it/s, lr=9.94e-6, step_loss=0.451]07/18/2023 19:23:08 - INFO - __main__ - train loss is 9.81859070667997\n",
      "Steps:  20%|▏| 3063/15000 [19:46<35:57,  5.53it/s, lr=9.94e-6, step_loss=0.0046707/18/2023 19:23:08 - INFO - __main__ - train loss is 9.831208816263825\n",
      "Steps:  20%|▏| 3064/15000 [19:46<36:09,  5.50it/s, lr=9.94e-6, step_loss=0.0126]07/18/2023 19:23:08 - INFO - __main__ - train loss is 9.941928675863892\n",
      "Steps:  20%|▍ | 3065/15000 [19:46<35:57,  5.53it/s, lr=9.94e-6, step_loss=0.111]07/18/2023 19:23:08 - INFO - __main__ - train loss is 9.9464757964015\n",
      "Steps:  20%|▏| 3066/15000 [19:46<35:48,  5.55it/s, lr=9.94e-6, step_loss=0.0045507/18/2023 19:23:09 - INFO - __main__ - train loss is 9.958299942314625\n",
      "Steps:  20%|▏| 3067/15000 [19:46<35:43,  5.57it/s, lr=9.94e-6, step_loss=0.0118]07/18/2023 19:23:09 - INFO - __main__ - train loss is 10.09819132834673\n",
      "Steps:  20%|▌  | 3068/15000 [19:47<35:41,  5.57it/s, lr=9.94e-6, step_loss=0.14]07/18/2023 19:23:09 - INFO - __main__ - train loss is 10.104356088675559\n",
      "Steps:  20%|▏| 3069/15000 [19:47<35:37,  5.58it/s, lr=9.94e-6, step_loss=0.0061607/18/2023 19:23:09 - INFO - __main__ - train loss is 10.156490334309638\n",
      "Steps:  20%|▏| 3070/15000 [19:47<35:32,  5.59it/s, lr=9.94e-6, step_loss=0.0521]07/18/2023 19:23:09 - INFO - __main__ - train loss is 10.356797748245299\n",
      "Steps:  20%|▊   | 3071/15000 [19:47<35:32,  5.59it/s, lr=9.94e-6, step_loss=0.2]07/18/2023 19:23:09 - INFO - __main__ - train loss is 10.429905691184103\n",
      "Steps:  20%|▏| 3072/15000 [19:47<35:30,  5.60it/s, lr=9.94e-6, step_loss=0.0731]07/18/2023 19:23:10 - INFO - __main__ - train loss is 11.031484642066061\n",
      "Steps:  20%|▍ | 3073/15000 [19:47<35:32,  5.59it/s, lr=9.94e-6, step_loss=0.602]07/18/2023 19:23:10 - INFO - __main__ - train loss is 11.039044626057148\n",
      "Steps:  20%|▏| 3074/15000 [19:48<35:31,  5.60it/s, lr=9.94e-6, step_loss=0.0075607/18/2023 19:23:10 - INFO - __main__ - train loss is 11.101418361067772\n",
      "Steps:  20%|▏| 3075/15000 [19:48<35:29,  5.60it/s, lr=9.94e-6, step_loss=0.0624]07/18/2023 19:23:10 - INFO - __main__ - train loss is 11.403790727257729\n",
      "Steps:  21%|▍ | 3076/15000 [19:48<35:29,  5.60it/s, lr=9.94e-6, step_loss=0.302]07/18/2023 19:23:10 - INFO - __main__ - train loss is 11.624059423804283\n",
      "Steps:  21%|▌  | 3077/15000 [19:48<35:28,  5.60it/s, lr=9.94e-6, step_loss=0.22]07/18/2023 19:23:10 - INFO - __main__ - train loss is 12.008911713957787\n",
      "Steps:  21%|▍ | 3078/15000 [19:48<35:28,  5.60it/s, lr=9.94e-6, step_loss=0.385]07/18/2023 19:23:11 - INFO - __main__ - train loss is 12.04884372651577\n",
      "Steps:  21%|▏| 3079/15000 [19:49<35:27,  5.60it/s, lr=9.94e-6, step_loss=0.0399]07/18/2023 19:23:11 - INFO - __main__ - train loss is 12.074034726247191\n",
      "Steps:  21%|▏| 3080/15000 [19:49<35:26,  5.61it/s, lr=9.94e-6, step_loss=0.0252]07/18/2023 19:23:11 - INFO - __main__ - train loss is 12.086769945919514\n",
      "Steps:  21%|▏| 3081/15000 [19:49<35:26,  5.60it/s, lr=9.94e-6, step_loss=0.0127]07/18/2023 19:23:11 - INFO - __main__ - train loss is 12.342082627117634\n",
      "Steps:  21%|▍ | 3082/15000 [19:49<35:27,  5.60it/s, lr=9.94e-6, step_loss=0.255]07/18/2023 19:23:11 - INFO - __main__ - train loss is 12.707733877003193\n",
      "Steps:  21%|▍ | 3083/15000 [19:49<35:26,  5.60it/s, lr=9.94e-6, step_loss=0.366]07/18/2023 19:23:12 - INFO - __main__ - train loss is 12.736843228340149\n",
      "Steps:  21%|▏| 3084/15000 [19:49<35:27,  5.60it/s, lr=9.94e-6, step_loss=0.0291]07/18/2023 19:23:12 - INFO - __main__ - train loss is 12.812782414257526\n",
      "Steps:  21%|▏| 3085/15000 [19:50<35:27,  5.60it/s, lr=9.94e-6, step_loss=0.0759]07/18/2023 19:23:12 - INFO - __main__ - train loss is 12.860302481800318\n",
      "Steps:  21%|▏| 3086/15000 [19:50<35:26,  5.60it/s, lr=9.94e-6, step_loss=0.0475]07/18/2023 19:23:12 - INFO - __main__ - train loss is 12.894803702831268\n",
      "Steps:  21%|▏| 3087/15000 [19:50<35:28,  5.60it/s, lr=9.94e-6, step_loss=0.0345]07/18/2023 19:23:12 - INFO - __main__ - train loss is 13.366213262081146\n",
      "Steps:  21%|▍ | 3088/15000 [19:50<35:27,  5.60it/s, lr=9.94e-6, step_loss=0.471]07/18/2023 19:23:12 - INFO - __main__ - train loss is 13.666096210479736\n",
      "Steps:  21%|▊   | 3089/15000 [19:50<35:25,  5.60it/s, lr=9.94e-6, step_loss=0.3]07/18/2023 19:23:13 - INFO - __main__ - train loss is 13.70775268226862\n",
      "Steps:  21%|▏| 3090/15000 [19:50<35:24,  5.61it/s, lr=9.94e-6, step_loss=0.0417]07/18/2023 19:23:13 - INFO - __main__ - train loss is 13.710872835479677\n",
      "Steps:  21%|▏| 3091/15000 [19:51<35:23,  5.61it/s, lr=9.94e-6, step_loss=0.0031207/18/2023 19:23:13 - INFO - __main__ - train loss is 13.73450758587569\n",
      "Steps:  21%|▏| 3092/15000 [19:51<35:21,  5.61it/s, lr=9.94e-6, step_loss=0.0236]07/18/2023 19:23:13 - INFO - __main__ - train loss is 13.820957469753921\n",
      "Steps:  21%|▏| 3093/15000 [19:51<35:21,  5.61it/s, lr=9.94e-6, step_loss=0.0864]07/18/2023 19:23:13 - INFO - __main__ - train loss is 13.834815556183457\n",
      "Steps:  21%|▏| 3094/15000 [19:51<35:21,  5.61it/s, lr=9.94e-6, step_loss=0.0139]07/18/2023 19:23:13 - INFO - __main__ - train loss is 13.989976892247796\n",
      "Steps:  21%|▍ | 3095/15000 [19:51<35:21,  5.61it/s, lr=9.93e-6, step_loss=0.155]07/18/2023 19:23:14 - INFO - __main__ - train loss is 14.002127850428224\n",
      "Steps:  21%|▏| 3096/15000 [19:52<35:20,  5.61it/s, lr=9.93e-6, step_loss=0.0122]07/18/2023 19:23:14 - INFO - __main__ - train loss is 14.564895475283265\n",
      "Steps:  21%|▍ | 3097/15000 [19:52<35:21,  5.61it/s, lr=9.93e-6, step_loss=0.563]07/18/2023 19:23:14 - INFO - __main__ - train loss is 14.881482923403382\n",
      "Steps:  21%|▍ | 3098/15000 [19:52<35:21,  5.61it/s, lr=9.93e-6, step_loss=0.317]07/18/2023 19:23:14 - INFO - __main__ - train loss is 14.999108040705323\n",
      "Steps:  21%|▍ | 3099/15000 [19:52<35:22,  5.61it/s, lr=9.93e-6, step_loss=0.118]07/18/2023 19:23:14 - INFO - __main__ - train loss is 15.12062711454928\n",
      "Steps:  21%|▍ | 3100/15000 [19:52<35:21,  5.61it/s, lr=9.93e-6, step_loss=0.122]07/18/2023 19:23:15 - INFO - __main__ - train loss is 15.412032613530755\n",
      "Steps:  21%|▍ | 3101/15000 [19:52<35:21,  5.61it/s, lr=9.93e-6, step_loss=0.291]07/18/2023 19:23:15 - INFO - __main__ - train loss is 15.440707152709365\n",
      "Steps:  21%|▏| 3102/15000 [19:53<35:22,  5.61it/s, lr=9.93e-6, step_loss=0.0287]07/18/2023 19:23:15 - INFO - __main__ - train loss is 15.50013474188745\n",
      "Steps:  21%|▏| 3103/15000 [19:53<35:43,  5.55it/s, lr=9.93e-6, step_loss=0.0594]07/18/2023 19:23:15 - INFO - __main__ - train loss is 15.890704309567809\n",
      "Steps:  21%|▍ | 3104/15000 [19:53<47:46,  4.15it/s, lr=9.93e-6, step_loss=0.391]07/18/2023 19:23:16 - INFO - __main__ - Per validation step average loss is 0.003946016542613506\n",
      "07/18/2023 19:23:16 - INFO - __main__ - Cumulative validation average loss is 0.003946016542613506\n",
      "07/18/2023 19:23:16 - INFO - __main__ - Per validation step average loss is 0.013913019560277462\n",
      "07/18/2023 19:23:16 - INFO - __main__ - Cumulative validation average loss is 0.01785903610289097\n",
      "07/18/2023 19:23:16 - INFO - __main__ - Per validation step average loss is 0.2776302397251129\n",
      "07/18/2023 19:23:16 - INFO - __main__ - Cumulative validation average loss is 0.2954892758280039\n",
      "07/18/2023 19:23:16 - INFO - __main__ - Per validation step average loss is 0.12396591901779175\n",
      "07/18/2023 19:23:16 - INFO - __main__ - Cumulative validation average loss is 0.41945519484579563\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.08300085365772247\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 0.5024560485035181\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.0025028735399246216\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 0.5049589220434427\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.3584396243095398\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 0.8633985463529825\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.059182703495025635\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 0.9225812498480082\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.0022845871280878782\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 0.924865836976096\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.0671306625008583\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 0.9919964994769543\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Per validation step average loss is 0.3219711184501648\n",
      "07/18/2023 19:23:17 - INFO - __main__ - Cumulative validation average loss is 1.3139676179271191\n",
      "07/18/2023 19:23:18 - INFO - __main__ - Per validation step average loss is 0.011695646680891514\n",
      "07/18/2023 19:23:18 - INFO - __main__ - Cumulative validation average loss is 1.3256632646080106\n",
      "07/18/2023 19:23:18 - INFO - __main__ - Average validation loss for Epoch 31 is 0.11047193871733423\n",
      "07/18/2023 19:23:18 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:23:31 - INFO - __main__ - Starting epoch 32\n",
      "07/18/2023 19:23:31 - INFO - __main__ - train loss is 0.018526870757341385\n",
      "Steps:  21%|▏| 3105/15000 [20:09<16:09:58,  4.89s/it, lr=9.93e-6, step_loss=0.0107/18/2023 19:23:31 - INFO - __main__ - train loss is 0.2275371141731739\n",
      "Steps:  21%|▏| 3106/15000 [20:09<11:29:36,  3.48s/it, lr=9.93e-6, step_loss=0.2007/18/2023 19:23:31 - INFO - __main__ - train loss is 0.34549396112561226\n",
      "Steps:  21%|▏| 3107/15000 [20:09<8:13:16,  2.49s/it, lr=9.93e-6, step_loss=0.11807/18/2023 19:23:32 - INFO - __main__ - train loss is 0.37798040732741356\n",
      "Steps:  21%|▏| 3108/15000 [20:09<5:56:03,  1.80s/it, lr=9.93e-6, step_loss=0.03207/18/2023 19:23:32 - INFO - __main__ - train loss is 0.48346589878201485\n",
      "Steps:  21%|▏| 3109/15000 [20:10<4:19:47,  1.31s/it, lr=9.93e-6, step_loss=0.10507/18/2023 19:23:32 - INFO - __main__ - train loss is 0.5627055652439594\n",
      "Steps:  21%|▏| 3110/15000 [20:10<3:12:26,  1.03it/s, lr=9.93e-6, step_loss=0.07907/18/2023 19:23:32 - INFO - __main__ - train loss is 0.5673874225467443\n",
      "Steps:  21%|▏| 3111/15000 [20:10<2:25:17,  1.36it/s, lr=9.93e-6, step_loss=0.00407/18/2023 19:23:32 - INFO - __main__ - train loss is 0.8424040880054235\n",
      "Steps:  21%|▏| 3112/15000 [20:10<1:52:15,  1.76it/s, lr=9.93e-6, step_loss=0.27507/18/2023 19:23:32 - INFO - __main__ - train loss is 0.9105569329112768\n",
      "Steps:  21%|▏| 3113/15000 [20:10<1:29:08,  2.22it/s, lr=9.93e-6, step_loss=0.06807/18/2023 19:23:33 - INFO - __main__ - train loss is 1.0057597141712904\n",
      "Steps:  21%|▏| 3114/15000 [20:11<1:12:57,  2.72it/s, lr=9.93e-6, step_loss=0.09507/18/2023 19:23:33 - INFO - __main__ - train loss is 1.0193594172596931\n",
      "Steps:  21%|▏| 3115/15000 [20:11<1:01:38,  3.21it/s, lr=9.93e-6, step_loss=0.01307/18/2023 19:23:33 - INFO - __main__ - train loss is 1.2300549522042274\n",
      "Steps:  21%|▍ | 3116/15000 [20:11<53:44,  3.69it/s, lr=9.93e-6, step_loss=0.211]07/18/2023 19:23:33 - INFO - __main__ - train loss is 1.2322746701538563\n",
      "Steps:  21%|▏| 3117/15000 [20:11<48:10,  4.11it/s, lr=9.93e-6, step_loss=0.0022207/18/2023 19:23:33 - INFO - __main__ - train loss is 1.3628339655697346\n",
      "Steps:  21%|▍ | 3118/15000 [20:11<44:41,  4.43it/s, lr=9.93e-6, step_loss=0.131]07/18/2023 19:23:34 - INFO - __main__ - train loss is 2.1947909481823444\n",
      "Steps:  21%|▍ | 3119/15000 [20:11<42:29,  4.66it/s, lr=9.93e-6, step_loss=0.832]07/18/2023 19:23:34 - INFO - __main__ - train loss is 2.3912871964275837\n",
      "Steps:  21%|▍ | 3120/15000 [20:12<40:42,  4.86it/s, lr=9.93e-6, step_loss=0.196]07/18/2023 19:23:34 - INFO - __main__ - train loss is 2.4407378993928432\n",
      "Steps:  21%|▏| 3121/15000 [20:12<39:41,  4.99it/s, lr=9.93e-6, step_loss=0.0495]07/18/2023 19:23:34 - INFO - __main__ - train loss is 2.449453741312027\n",
      "Steps:  21%|▏| 3122/15000 [20:12<38:31,  5.14it/s, lr=9.93e-6, step_loss=0.0087207/18/2023 19:23:34 - INFO - __main__ - train loss is 2.528216451406479\n",
      "Steps:  21%|▏| 3123/15000 [20:12<37:34,  5.27it/s, lr=9.93e-6, step_loss=0.0788]07/18/2023 19:23:34 - INFO - __main__ - train loss is 2.530558436876163\n",
      "Steps:  21%|▏| 3124/15000 [20:12<36:55,  5.36it/s, lr=9.93e-6, step_loss=0.0023407/18/2023 19:23:35 - INFO - __main__ - train loss is 2.667332172160968\n",
      "Steps:  21%|▍ | 3125/15000 [20:13<36:30,  5.42it/s, lr=9.93e-6, step_loss=0.137]07/18/2023 19:23:35 - INFO - __main__ - train loss is 2.692687360337004\n",
      "Steps:  21%|▏| 3126/15000 [20:13<36:09,  5.47it/s, lr=9.93e-6, step_loss=0.0254]07/18/2023 19:23:35 - INFO - __main__ - train loss is 2.795893115689978\n",
      "Steps:  21%|▍ | 3127/15000 [20:13<35:53,  5.51it/s, lr=9.93e-6, step_loss=0.103]07/18/2023 19:23:35 - INFO - __main__ - train loss is 2.8234765713568777\n",
      "Steps:  21%|▏| 3128/15000 [20:13<35:41,  5.54it/s, lr=9.93e-6, step_loss=0.0276]07/18/2023 19:23:35 - INFO - __main__ - train loss is 2.827877610689029\n",
      "Steps:  21%|▏| 3129/15000 [20:13<35:34,  5.56it/s, lr=9.93e-6, step_loss=0.0044]07/18/2023 19:23:36 - INFO - __main__ - train loss is 2.8473320787306875\n",
      "Steps:  21%|▏| 3130/15000 [20:13<35:28,  5.58it/s, lr=9.93e-6, step_loss=0.0195]07/18/2023 19:23:36 - INFO - __main__ - train loss is 3.022186238085851\n",
      "Steps:  21%|▍ | 3131/15000 [20:14<35:24,  5.59it/s, lr=9.93e-6, step_loss=0.175]07/18/2023 19:23:36 - INFO - __main__ - train loss is 3.0325250911992043\n",
      "Steps:  21%|▏| 3132/15000 [20:14<35:22,  5.59it/s, lr=9.93e-6, step_loss=0.0103]07/18/2023 19:23:36 - INFO - __main__ - train loss is 3.123041285900399\n",
      "Steps:  21%|▏| 3133/15000 [20:14<35:20,  5.60it/s, lr=9.93e-6, step_loss=0.0905]07/18/2023 19:23:36 - INFO - __main__ - train loss is 3.1920942205470055\n",
      "Steps:  21%|▏| 3134/15000 [20:14<35:18,  5.60it/s, lr=9.93e-6, step_loss=0.0691]07/18/2023 19:23:36 - INFO - __main__ - train loss is 3.290162942139432\n",
      "Steps:  21%|▏| 3135/15000 [20:14<35:31,  5.57it/s, lr=9.93e-6, step_loss=0.0981]07/18/2023 19:23:37 - INFO - __main__ - train loss is 3.315155855147168\n",
      "Steps:  21%|▍ | 3136/15000 [20:15<35:45,  5.53it/s, lr=9.93e-6, step_loss=0.025]07/18/2023 19:23:37 - INFO - __main__ - train loss is 3.3443598623853177\n",
      "Steps:  21%|▏| 3137/15000 [20:15<35:36,  5.55it/s, lr=9.93e-6, step_loss=0.0292]07/18/2023 19:23:37 - INFO - __main__ - train loss is 3.346598287113011\n",
      "Steps:  21%|▏| 3138/15000 [20:15<35:44,  5.53it/s, lr=9.93e-6, step_loss=0.0022407/18/2023 19:23:37 - INFO - __main__ - train loss is 3.4991940455511212\n",
      "Steps:  21%|▍ | 3139/15000 [20:15<35:56,  5.50it/s, lr=9.93e-6, step_loss=0.153]07/18/2023 19:23:37 - INFO - __main__ - train loss is 3.50411715824157\n",
      "Steps:  21%|▏| 3140/15000 [20:15<36:08,  5.47it/s, lr=9.93e-6, step_loss=0.0049207/18/2023 19:23:38 - INFO - __main__ - train loss is 4.292136219330132\n",
      "Steps:  21%|▍ | 3141/15000 [20:15<35:53,  5.51it/s, lr=9.93e-6, step_loss=0.788]07/18/2023 19:23:38 - INFO - __main__ - train loss is 4.387869496829808\n",
      "Steps:  21%|▏| 3142/15000 [20:16<36:02,  5.48it/s, lr=9.93e-6, step_loss=0.0957]07/18/2023 19:23:38 - INFO - __main__ - train loss is 4.593685750849545\n",
      "Steps:  21%|▍ | 3143/15000 [20:16<36:24,  5.43it/s, lr=9.93e-6, step_loss=0.206]07/18/2023 19:23:38 - INFO - __main__ - train loss is 4.847088252194226\n",
      "Steps:  21%|▍ | 3144/15000 [20:16<36:20,  5.44it/s, lr=9.93e-6, step_loss=0.253]07/18/2023 19:23:38 - INFO - __main__ - train loss is 4.849118639249355\n",
      "Steps:  21%|▏| 3145/15000 [20:16<36:00,  5.49it/s, lr=9.93e-6, step_loss=0.0020307/18/2023 19:23:38 - INFO - __main__ - train loss is 4.870964475441724\n",
      "Steps:  21%|▏| 3146/15000 [20:16<35:45,  5.52it/s, lr=9.93e-6, step_loss=0.0218]07/18/2023 19:23:39 - INFO - __main__ - train loss is 5.06719682412222\n",
      "Steps:  21%|▍ | 3147/15000 [20:17<35:35,  5.55it/s, lr=9.93e-6, step_loss=0.196]07/18/2023 19:23:39 - INFO - __main__ - train loss is 5.214111485052854\n",
      "Steps:  21%|▍ | 3148/15000 [20:17<35:28,  5.57it/s, lr=9.93e-6, step_loss=0.147]07/18/2023 19:23:39 - INFO - __main__ - train loss is 5.285201587248594\n",
      "Steps:  21%|▏| 3149/15000 [20:17<35:23,  5.58it/s, lr=9.93e-6, step_loss=0.0711]07/18/2023 19:23:39 - INFO - __main__ - train loss is 5.336701535154134\n",
      "Steps:  21%|▏| 3150/15000 [20:17<35:20,  5.59it/s, lr=9.93e-6, step_loss=0.0515]07/18/2023 19:23:39 - INFO - __main__ - train loss is 5.375184998381883\n",
      "Steps:  21%|▏| 3151/15000 [20:17<35:17,  5.60it/s, lr=9.93e-6, step_loss=0.0385]07/18/2023 19:23:40 - INFO - __main__ - train loss is 5.702329621184617\n",
      "Steps:  21%|▍ | 3152/15000 [20:17<35:16,  5.60it/s, lr=9.93e-6, step_loss=0.327]07/18/2023 19:23:40 - INFO - __main__ - train loss is 5.705594326602295\n",
      "Steps:  21%|▏| 3153/15000 [20:18<35:15,  5.60it/s, lr=9.93e-6, step_loss=0.0032607/18/2023 19:23:40 - INFO - __main__ - train loss is 5.720901945838705\n",
      "Steps:  21%|▏| 3154/15000 [20:18<35:15,  5.60it/s, lr=9.93e-6, step_loss=0.0153]07/18/2023 19:23:40 - INFO - __main__ - train loss is 6.309575537452474\n",
      "Steps:  21%|▍ | 3155/15000 [20:18<35:14,  5.60it/s, lr=9.93e-6, step_loss=0.589]07/18/2023 19:23:40 - INFO - __main__ - train loss is 6.314719120739028\n",
      "Steps:  21%|▏| 3156/15000 [20:18<35:12,  5.61it/s, lr=9.93e-6, step_loss=0.0051407/18/2023 19:23:40 - INFO - __main__ - train loss is 6.319604553980753\n",
      "Steps:  21%|▏| 3157/15000 [20:18<35:12,  5.61it/s, lr=9.93e-6, step_loss=0.0048907/18/2023 19:23:41 - INFO - __main__ - train loss is 6.847221591277048\n",
      "Steps:  21%|▍ | 3158/15000 [20:18<35:11,  5.61it/s, lr=9.93e-6, step_loss=0.528]07/18/2023 19:23:41 - INFO - __main__ - train loss is 6.968358956975862\n",
      "Steps:  21%|▍ | 3159/15000 [20:19<35:11,  5.61it/s, lr=9.93e-6, step_loss=0.121]07/18/2023 19:23:41 - INFO - __main__ - train loss is 7.094559275312349\n",
      "Steps:  21%|▍ | 3160/15000 [20:19<35:11,  5.61it/s, lr=9.93e-6, step_loss=0.126]07/18/2023 19:23:41 - INFO - __main__ - train loss is 7.1688809774350375\n",
      "Steps:  21%|▏| 3161/15000 [20:19<35:10,  5.61it/s, lr=9.93e-6, step_loss=0.0743]07/18/2023 19:23:41 - INFO - __main__ - train loss is 7.171010030200705\n",
      "Steps:  21%|▏| 3162/15000 [20:19<35:10,  5.61it/s, lr=9.93e-6, step_loss=0.0021307/18/2023 19:23:41 - INFO - __main__ - train loss is 7.173178341472521\n",
      "Steps:  21%|▏| 3163/15000 [20:19<35:18,  5.59it/s, lr=9.93e-6, step_loss=0.0021707/18/2023 19:23:42 - INFO - __main__ - train loss is 7.245081600034609\n",
      "Steps:  21%|▏| 3164/15000 [20:20<35:27,  5.56it/s, lr=9.93e-6, step_loss=0.0719]07/18/2023 19:23:42 - INFO - __main__ - train loss is 7.2517710358370095\n",
      "Steps:  21%|▏| 3165/15000 [20:20<36:55,  5.34it/s, lr=9.93e-6, step_loss=0.0066907/18/2023 19:23:42 - INFO - __main__ - train loss is 7.5959290594328195\n",
      "Steps:  21%|▍ | 3166/15000 [20:20<37:09,  5.31it/s, lr=9.93e-6, step_loss=0.344]07/18/2023 19:23:42 - INFO - __main__ - train loss is 8.102298650192097\n",
      "Steps:  21%|▍ | 3167/15000 [20:20<36:50,  5.35it/s, lr=9.93e-6, step_loss=0.506]07/18/2023 19:23:42 - INFO - __main__ - train loss is 8.253581407712772\n",
      "Steps:  21%|▍ | 3168/15000 [20:20<36:44,  5.37it/s, lr=9.93e-6, step_loss=0.151]07/18/2023 19:23:43 - INFO - __main__ - train loss is 8.836744430707768\n",
      "Steps:  21%|▍ | 3169/15000 [20:21<36:52,  5.35it/s, lr=9.93e-6, step_loss=0.583]07/18/2023 19:23:43 - INFO - __main__ - train loss is 8.935538227902725\n",
      "Steps:  21%|▏| 3170/15000 [20:21<37:20,  5.28it/s, lr=9.93e-6, step_loss=0.0988]07/18/2023 19:23:43 - INFO - __main__ - train loss is 8.972640577005222\n",
      "Steps:  21%|▏| 3171/15000 [20:21<37:34,  5.25it/s, lr=9.93e-6, step_loss=0.0371]07/18/2023 19:23:43 - INFO - __main__ - train loss is 8.993695431621745\n",
      "Steps:  21%|▏| 3172/15000 [20:21<37:44,  5.22it/s, lr=9.93e-6, step_loss=0.0211]07/18/2023 19:23:43 - INFO - __main__ - train loss is 9.020841182442382\n",
      "Steps:  21%|▏| 3173/15000 [20:21<37:52,  5.20it/s, lr=9.93e-6, step_loss=0.0271]07/18/2023 19:23:44 - INFO - __main__ - train loss is 9.08724778261967\n",
      "Steps:  21%|▏| 3174/15000 [20:21<38:23,  5.13it/s, lr=9.93e-6, step_loss=0.0664]07/18/2023 19:23:44 - INFO - __main__ - train loss is 9.196053655119613\n",
      "Steps:  21%|▍ | 3175/15000 [20:22<38:17,  5.15it/s, lr=9.93e-6, step_loss=0.109]07/18/2023 19:23:44 - INFO - __main__ - train loss is 9.21859531593509\n",
      "Steps:  21%|▏| 3176/15000 [20:22<38:12,  5.16it/s, lr=9.93e-6, step_loss=0.0225]07/18/2023 19:23:44 - INFO - __main__ - train loss is 9.257221312494949\n",
      "Steps:  21%|▏| 3177/15000 [20:22<38:16,  5.15it/s, lr=9.93e-6, step_loss=0.0386]07/18/2023 19:23:44 - INFO - __main__ - train loss is 9.25965751055628\n",
      "Steps:  21%|▏| 3178/15000 [20:22<38:10,  5.16it/s, lr=9.93e-6, step_loss=0.0024407/18/2023 19:23:45 - INFO - __main__ - train loss is 9.283139041624963\n",
      "Steps:  21%|▏| 3179/15000 [20:22<37:48,  5.21it/s, lr=9.93e-6, step_loss=0.0235]07/18/2023 19:23:45 - INFO - __main__ - train loss is 9.289872698485851\n",
      "Steps:  21%|▏| 3180/15000 [20:23<37:22,  5.27it/s, lr=9.93e-6, step_loss=0.0067307/18/2023 19:23:45 - INFO - __main__ - train loss is 9.343459449708462\n",
      "Steps:  21%|▏| 3181/15000 [20:23<37:02,  5.32it/s, lr=9.93e-6, step_loss=0.0536]07/18/2023 19:23:45 - INFO - __main__ - train loss is 9.346701755654067\n",
      "Steps:  21%|▏| 3182/15000 [20:23<37:03,  5.31it/s, lr=9.93e-6, step_loss=0.0032407/18/2023 19:23:45 - INFO - __main__ - train loss is 9.355457793455571\n",
      "Steps:  21%|▏| 3183/15000 [20:23<36:44,  5.36it/s, lr=9.93e-6, step_loss=0.0087607/18/2023 19:23:45 - INFO - __main__ - train loss is 9.436193409841508\n",
      "Steps:  21%|▏| 3184/15000 [20:23<36:16,  5.43it/s, lr=9.93e-6, step_loss=0.0807]07/18/2023 19:23:46 - INFO - __main__ - train loss is 9.549257408361882\n",
      "Steps:  21%|▍ | 3185/15000 [20:24<36:14,  5.43it/s, lr=9.93e-6, step_loss=0.113]07/18/2023 19:23:46 - INFO - __main__ - train loss is 9.642986092250794\n",
      "Steps:  21%|▏| 3186/15000 [20:24<35:59,  5.47it/s, lr=9.93e-6, step_loss=0.0937]07/18/2023 19:23:46 - INFO - __main__ - train loss is 9.667670793365687\n",
      "Steps:  21%|▏| 3187/15000 [20:24<35:42,  5.51it/s, lr=9.93e-6, step_loss=0.0247]07/18/2023 19:23:46 - INFO - __main__ - train loss is 9.681019903626293\n",
      "Steps:  21%|▏| 3188/15000 [20:24<35:36,  5.53it/s, lr=9.93e-6, step_loss=0.0133]07/18/2023 19:23:46 - INFO - __main__ - train loss is 9.734187533613294\n",
      "Steps:  21%|▏| 3189/15000 [20:24<35:32,  5.54it/s, lr=9.93e-6, step_loss=0.0532]07/18/2023 19:23:47 - INFO - __main__ - train loss is 9.893454214092344\n",
      "Steps:  21%|▍ | 3190/15000 [20:24<35:25,  5.56it/s, lr=9.93e-6, step_loss=0.159]07/18/2023 19:23:47 - INFO - __main__ - train loss is 10.077825745102018\n",
      "Steps:  21%|▍ | 3191/15000 [20:25<35:20,  5.57it/s, lr=9.93e-6, step_loss=0.184]07/18/2023 19:23:47 - INFO - __main__ - train loss is 10.341108938213438\n",
      "Steps:  21%|▍ | 3192/15000 [20:25<35:16,  5.58it/s, lr=9.93e-6, step_loss=0.263]07/18/2023 19:23:47 - INFO - __main__ - train loss is 10.359935147222131\n",
      "Steps:  21%|▏| 3193/15000 [20:25<35:26,  5.55it/s, lr=9.93e-6, step_loss=0.0188]07/18/2023 19:23:47 - INFO - __main__ - train loss is 10.380035725887865\n",
      "Steps:  21%|▏| 3194/15000 [20:25<35:19,  5.57it/s, lr=9.93e-6, step_loss=0.0201]07/18/2023 19:23:47 - INFO - __main__ - train loss is 10.776412216480821\n",
      "Steps:  21%|▍ | 3195/15000 [20:25<35:27,  5.55it/s, lr=9.93e-6, step_loss=0.396]07/18/2023 19:23:48 - INFO - __main__ - train loss is 11.115774629171938\n",
      "Steps:  21%|▍ | 3196/15000 [20:26<35:19,  5.57it/s, lr=9.93e-6, step_loss=0.339]07/18/2023 19:23:48 - INFO - __main__ - train loss is 11.23661665385589\n",
      "Steps:  21%|▍ | 3197/15000 [20:26<35:13,  5.58it/s, lr=9.93e-6, step_loss=0.121]07/18/2023 19:23:48 - INFO - __main__ - train loss is 11.286686999257654\n",
      "Steps:  21%|▏| 3198/15000 [20:26<35:10,  5.59it/s, lr=9.93e-6, step_loss=0.0501]07/18/2023 19:23:48 - INFO - __main__ - train loss is 11.291733098216355\n",
      "Steps:  21%|▏| 3199/15000 [20:26<35:27,  5.55it/s, lr=9.93e-6, step_loss=0.0050507/18/2023 19:23:48 - INFO - __main__ - train loss is 11.590709340758622\n",
      "Steps:  21%|▍ | 3200/15000 [20:26<35:25,  5.55it/s, lr=9.93e-6, step_loss=0.299]07/18/2023 19:23:49 - INFO - __main__ - train loss is 12.043689769692719\n",
      "Steps:  21%|▍ | 3201/15000 [20:27<48:44,  4.04it/s, lr=9.93e-6, step_loss=0.453]07/18/2023 19:23:50 - INFO - __main__ - Per validation step average loss is 0.16153481602668762\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Cumulative validation average loss is 0.16153481602668762\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Per validation step average loss is 0.17984539270401\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Cumulative validation average loss is 0.34138020873069763\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Per validation step average loss is 0.03759053349494934\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Cumulative validation average loss is 0.378970742225647\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Per validation step average loss is 0.009791076183319092\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Cumulative validation average loss is 0.38876181840896606\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Per validation step average loss is 0.005109814461320639\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Cumulative validation average loss is 0.3938716328702867\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Per validation step average loss is 0.07478277385234833\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Cumulative validation average loss is 0.46865440672263503\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Per validation step average loss is 0.11639948189258575\n",
      "07/18/2023 19:23:50 - INFO - __main__ - Cumulative validation average loss is 0.5850538886152208\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Per validation step average loss is 0.09970100224018097\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Cumulative validation average loss is 0.6847548908554018\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Per validation step average loss is 0.002805944299325347\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Cumulative validation average loss is 0.6875608351547271\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Per validation step average loss is 0.3262878358364105\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Cumulative validation average loss is 1.0138486709911376\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Per validation step average loss is 0.0046869670040905476\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Cumulative validation average loss is 1.0185356379952282\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Per validation step average loss is 0.0014930793549865484\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Cumulative validation average loss is 1.0200287173502147\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Average validation loss for Epoch 32 is 0.0850023931125179\n",
      "07/18/2023 19:23:51 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:24:04 - INFO - __main__ - Starting epoch 33\n",
      "07/18/2023 19:24:05 - INFO - __main__ - train loss is 0.06597985327243805\n",
      "Steps:  21%|▏| 3202/15000 [20:42<16:03:01,  4.90s/it, lr=9.93e-6, step_loss=0.0607/18/2023 19:24:05 - INFO - __main__ - train loss is 0.49661441147327423\n",
      "Steps:  21%|▏| 3203/15000 [20:43<11:24:45,  3.48s/it, lr=9.93e-6, step_loss=0.4307/18/2023 19:24:05 - INFO - __main__ - train loss is 0.5180926844477654\n",
      "Steps:  21%|▏| 3204/15000 [20:43<8:09:50,  2.49s/it, lr=9.93e-6, step_loss=0.02107/18/2023 19:24:05 - INFO - __main__ - train loss is 1.2203612253069878\n",
      "Steps:  21%|▏| 3205/15000 [20:43<5:53:20,  1.80s/it, lr=9.93e-6, step_loss=0.70207/18/2023 19:24:05 - INFO - __main__ - train loss is 1.259980596601963\n",
      "Steps:  21%|▏| 3206/15000 [20:43<4:17:49,  1.31s/it, lr=9.93e-6, step_loss=0.03907/18/2023 19:24:05 - INFO - __main__ - train loss is 1.2680951114743948\n",
      "Steps:  21%|▏| 3207/15000 [20:43<3:11:07,  1.03it/s, lr=9.93e-6, step_loss=0.00807/18/2023 19:24:06 - INFO - __main__ - train loss is 1.270585621939972\n",
      "Steps:  21%|▏| 3208/15000 [20:43<2:24:18,  1.36it/s, lr=9.93e-6, step_loss=0.00207/18/2023 19:24:06 - INFO - __main__ - train loss is 1.396001409040764\n",
      "Steps:  21%|▏| 3209/15000 [20:44<1:51:31,  1.76it/s, lr=9.93e-6, step_loss=0.12507/18/2023 19:24:06 - INFO - __main__ - train loss is 1.6582147881854326\n",
      "Steps:  21%|▏| 3210/15000 [20:44<1:28:35,  2.22it/s, lr=9.93e-6, step_loss=0.26207/18/2023 19:24:06 - INFO - __main__ - train loss is 1.6745060358662158\n",
      "Steps:  21%|▏| 3211/15000 [20:44<1:12:30,  2.71it/s, lr=9.93e-6, step_loss=0.01607/18/2023 19:24:06 - INFO - __main__ - train loss is 1.7400440324563533\n",
      "Steps:  21%|▏| 3212/15000 [20:44<1:01:24,  3.20it/s, lr=9.93e-6, step_loss=0.06507/18/2023 19:24:06 - INFO - __main__ - train loss is 2.0560687829274684\n",
      "Steps:  21%|▍ | 3213/15000 [20:44<53:26,  3.68it/s, lr=9.93e-6, step_loss=0.316]07/18/2023 19:24:07 - INFO - __main__ - train loss is 2.3894594062585384\n",
      "Steps:  21%|▍ | 3214/15000 [20:45<47:52,  4.10it/s, lr=9.93e-6, step_loss=0.333]07/18/2023 19:24:07 - INFO - __main__ - train loss is 2.412751841591671\n",
      "Steps:  21%|▏| 3215/15000 [20:45<43:58,  4.47it/s, lr=9.93e-6, step_loss=0.0233]07/18/2023 19:24:07 - INFO - __main__ - train loss is 2.7971737266052514\n",
      "Steps:  21%|▍ | 3216/15000 [20:45<41:17,  4.76it/s, lr=9.93e-6, step_loss=0.384]07/18/2023 19:24:07 - INFO - __main__ - train loss is 2.8053914143238217\n",
      "Steps:  21%|▏| 3217/15000 [20:45<39:21,  4.99it/s, lr=9.93e-6, step_loss=0.0082207/18/2023 19:24:07 - INFO - __main__ - train loss is 2.9490556104574353\n",
      "Steps:  21%|▍ | 3218/15000 [20:45<38:00,  5.17it/s, lr=9.93e-6, step_loss=0.144]07/18/2023 19:24:08 - INFO - __main__ - train loss is 3.296489833155647\n",
      "Steps:  21%|▍ | 3219/15000 [20:45<37:05,  5.29it/s, lr=9.93e-6, step_loss=0.347]07/18/2023 19:24:08 - INFO - __main__ - train loss is 3.8926222308073193\n",
      "Steps:  21%|▍ | 3220/15000 [20:46<36:27,  5.38it/s, lr=9.93e-6, step_loss=0.596]07/18/2023 19:24:08 - INFO - __main__ - train loss is 3.8949110300745815\n",
      "Steps:  21%|▏| 3221/15000 [20:46<36:01,  5.45it/s, lr=9.93e-6, step_loss=0.0022907/18/2023 19:24:08 - INFO - __main__ - train loss is 4.007737206062302\n",
      "Steps:  21%|▍ | 3222/15000 [20:46<35:44,  5.49it/s, lr=9.93e-6, step_loss=0.113]07/18/2023 19:24:08 - INFO - __main__ - train loss is 4.025862043490633\n",
      "Steps:  21%|▏| 3223/15000 [20:46<35:31,  5.53it/s, lr=9.93e-6, step_loss=0.0181]07/18/2023 19:24:08 - INFO - __main__ - train loss is 4.07683010189794\n",
      "Steps:  21%|▍ | 3224/15000 [20:46<35:20,  5.55it/s, lr=9.93e-6, step_loss=0.051]07/18/2023 19:24:09 - INFO - __main__ - train loss is 4.166081307223067\n",
      "Steps:  22%|▏| 3225/15000 [20:47<35:14,  5.57it/s, lr=9.93e-6, step_loss=0.0893]07/18/2023 19:24:09 - INFO - __main__ - train loss is 4.7208434322383255\n",
      "Steps:  22%|▍ | 3226/15000 [20:47<35:10,  5.58it/s, lr=9.93e-6, step_loss=0.555]07/18/2023 19:24:09 - INFO - __main__ - train loss is 5.442448971560225\n",
      "Steps:  22%|▍ | 3227/15000 [20:47<35:07,  5.59it/s, lr=9.93e-6, step_loss=0.722]07/18/2023 19:24:09 - INFO - __main__ - train loss is 5.547324461629614\n",
      "Steps:  22%|▍ | 3228/15000 [20:47<35:04,  5.59it/s, lr=9.93e-6, step_loss=0.105]07/18/2023 19:24:09 - INFO - __main__ - train loss is 5.554940470727161\n",
      "Steps:  22%|▏| 3229/15000 [20:47<35:02,  5.60it/s, lr=9.93e-6, step_loss=0.0076207/18/2023 19:24:10 - INFO - __main__ - train loss is 5.874475308926776\n",
      "Steps:  22%|▋  | 3230/15000 [20:47<35:01,  5.60it/s, lr=9.93e-6, step_loss=0.32]07/18/2023 19:24:10 - INFO - __main__ - train loss is 5.888219111831859\n",
      "Steps:  22%|▏| 3231/15000 [20:48<35:00,  5.60it/s, lr=9.93e-6, step_loss=0.0137]07/18/2023 19:24:10 - INFO - __main__ - train loss is 5.912460391642526\n",
      "Steps:  22%|▏| 3232/15000 [20:48<34:59,  5.61it/s, lr=9.93e-6, step_loss=0.0242]07/18/2023 19:24:10 - INFO - __main__ - train loss is 6.057582025649026\n",
      "Steps:  22%|▍ | 3233/15000 [20:48<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.145]07/18/2023 19:24:10 - INFO - __main__ - train loss is 6.123116945149377\n",
      "Steps:  22%|▏| 3234/15000 [20:48<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.0655]07/18/2023 19:24:10 - INFO - __main__ - train loss is 6.124373606173322\n",
      "Steps:  22%|▏| 3235/15000 [20:48<35:00,  5.60it/s, lr=9.93e-6, step_loss=0.0012607/18/2023 19:24:11 - INFO - __main__ - train loss is 6.298466733423993\n",
      "Steps:  22%|▍ | 3236/15000 [20:48<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.174]07/18/2023 19:24:11 - INFO - __main__ - train loss is 6.419437891570851\n",
      "Steps:  22%|▍ | 3237/15000 [20:49<34:58,  5.61it/s, lr=9.93e-6, step_loss=0.121]07/18/2023 19:24:11 - INFO - __main__ - train loss is 6.4337618730496615\n",
      "Steps:  22%|▏| 3238/15000 [20:49<34:57,  5.61it/s, lr=9.93e-6, step_loss=0.0143]07/18/2023 19:24:11 - INFO - __main__ - train loss is 6.8527407727669924\n",
      "Steps:  22%|▍ | 3239/15000 [20:49<34:56,  5.61it/s, lr=9.93e-6, step_loss=0.419]07/18/2023 19:24:11 - INFO - __main__ - train loss is 6.855946587165818\n",
      "Steps:  22%|▏| 3240/15000 [20:49<34:57,  5.61it/s, lr=9.93e-6, step_loss=0.0032107/18/2023 19:24:11 - INFO - __main__ - train loss is 6.933618189534172\n",
      "Steps:  22%|▏| 3241/15000 [20:49<34:57,  5.61it/s, lr=9.93e-6, step_loss=0.0777]07/18/2023 19:24:12 - INFO - __main__ - train loss is 6.9396265188697726\n",
      "Steps:  22%|▏| 3242/15000 [20:50<34:57,  5.61it/s, lr=9.93e-6, step_loss=0.0060107/18/2023 19:24:12 - INFO - __main__ - train loss is 6.942313890205696\n",
      "Steps:  22%|▏| 3243/15000 [20:50<34:57,  5.61it/s, lr=9.93e-6, step_loss=0.0026907/18/2023 19:24:12 - INFO - __main__ - train loss is 7.223656724439934\n",
      "Steps:  22%|▍ | 3244/15000 [20:50<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.281]07/18/2023 19:24:12 - INFO - __main__ - train loss is 7.270743082510307\n",
      "Steps:  22%|▏| 3245/15000 [20:50<35:00,  5.60it/s, lr=9.93e-6, step_loss=0.0471]07/18/2023 19:24:12 - INFO - __main__ - train loss is 7.300268070073798\n",
      "Steps:  22%|▏| 3246/15000 [20:50<35:00,  5.59it/s, lr=9.93e-6, step_loss=0.0295]07/18/2023 19:24:13 - INFO - __main__ - train loss is 7.442354307742789\n",
      "Steps:  22%|▍ | 3247/15000 [20:50<35:00,  5.60it/s, lr=9.93e-6, step_loss=0.142]07/18/2023 19:24:13 - INFO - __main__ - train loss is 7.452614533016458\n",
      "Steps:  22%|▏| 3248/15000 [20:51<34:58,  5.60it/s, lr=9.93e-6, step_loss=0.0103]07/18/2023 19:24:13 - INFO - __main__ - train loss is 7.4608870598021895\n",
      "Steps:  22%|▏| 3249/15000 [20:51<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.0082707/18/2023 19:24:13 - INFO - __main__ - train loss is 7.785865053767338\n",
      "Steps:  22%|▍ | 3250/15000 [20:51<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.325]07/18/2023 19:24:13 - INFO - __main__ - train loss is 7.788965910440311\n",
      "Steps:  22%|▏| 3251/15000 [20:51<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.0031]07/18/2023 19:24:13 - INFO - __main__ - train loss is 7.953041866188869\n",
      "Steps:  22%|▍ | 3252/15000 [20:51<34:59,  5.60it/s, lr=9.93e-6, step_loss=0.164]07/18/2023 19:24:14 - INFO - __main__ - train loss is 7.981993324821815\n",
      "Steps:  22%|▍ | 3253/15000 [20:52<34:59,  5.59it/s, lr=9.93e-6, step_loss=0.029]07/18/2023 19:24:14 - INFO - __main__ - train loss is 8.00704120635055\n",
      "Steps:  22%|▍ | 3254/15000 [20:52<35:00,  5.59it/s, lr=9.93e-6, step_loss=0.025]07/18/2023 19:24:14 - INFO - __main__ - train loss is 8.116854076972231\n",
      "Steps:  22%|▋  | 3255/15000 [20:52<35:00,  5.59it/s, lr=9.93e-6, step_loss=0.11]07/18/2023 19:24:14 - INFO - __main__ - train loss is 8.12385902251117\n",
      "Steps:  22%|▍ | 3256/15000 [20:52<34:59,  5.59it/s, lr=9.93e-6, step_loss=0.007]07/18/2023 19:24:14 - INFO - __main__ - train loss is 8.145028228638694\n",
      "Steps:  22%|▏| 3257/15000 [20:52<34:58,  5.59it/s, lr=9.93e-6, step_loss=0.0212]07/18/2023 19:24:15 - INFO - __main__ - train loss is 8.384051496861503\n",
      "Steps:  22%|▍ | 3258/15000 [20:52<34:57,  5.60it/s, lr=9.93e-6, step_loss=0.239]07/18/2023 19:24:15 - INFO - __main__ - train loss is 8.75425803172402\n",
      "Steps:  22%|▋  | 3259/15000 [20:53<34:56,  5.60it/s, lr=9.93e-6, step_loss=0.37]07/18/2023 19:24:15 - INFO - __main__ - train loss is 8.761414140695706\n",
      "Steps:  22%|▏| 3260/15000 [20:53<34:56,  5.60it/s, lr=9.93e-6, step_loss=0.0071607/18/2023 19:24:15 - INFO - __main__ - train loss is 8.784521909663454\n",
      "Steps:  22%|▏| 3261/15000 [20:53<34:54,  5.60it/s, lr=9.93e-6, step_loss=0.0231]07/18/2023 19:24:15 - INFO - __main__ - train loss is 8.835287435213104\n",
      "Steps:  22%|▏| 3262/15000 [20:53<34:54,  5.61it/s, lr=9.93e-6, step_loss=0.0508]07/18/2023 19:24:15 - INFO - __main__ - train loss is 8.842220067279413\n",
      "Steps:  22%|▏| 3263/15000 [20:53<34:54,  5.60it/s, lr=9.93e-6, step_loss=0.0069307/18/2023 19:24:16 - INFO - __main__ - train loss is 8.844749940792099\n",
      "Steps:  22%|▏| 3264/15000 [20:53<34:57,  5.60it/s, lr=9.93e-6, step_loss=0.0025307/18/2023 19:24:16 - INFO - __main__ - train loss is 8.846954029751942\n",
      "Steps:  22%|▏| 3265/15000 [20:54<34:55,  5.60it/s, lr=9.93e-6, step_loss=0.0022]07/18/2023 19:24:16 - INFO - __main__ - train loss is 9.46827928419225\n",
      "Steps:  22%|▍ | 3266/15000 [20:54<34:54,  5.60it/s, lr=9.93e-6, step_loss=0.621]07/18/2023 19:24:16 - INFO - __main__ - train loss is 9.970546048833057\n",
      "Steps:  22%|▍ | 3267/15000 [20:54<34:53,  5.60it/s, lr=9.93e-6, step_loss=0.502]07/18/2023 19:24:16 - INFO - __main__ - train loss is 10.452988606644794\n",
      "Steps:  22%|▍ | 3268/15000 [20:54<34:53,  5.60it/s, lr=9.93e-6, step_loss=0.482]07/18/2023 19:24:16 - INFO - __main__ - train loss is 10.94759086961858\n",
      "Steps:  22%|▍ | 3269/15000 [20:54<34:54,  5.60it/s, lr=9.93e-6, step_loss=0.495]07/18/2023 19:24:17 - INFO - __main__ - train loss is 11.038326252950355\n",
      "Steps:  22%|▏| 3270/15000 [20:55<34:53,  5.60it/s, lr=9.93e-6, step_loss=0.0907]07/18/2023 19:24:17 - INFO - __main__ - train loss is 11.380061496747658\n",
      "Steps:  22%|▍ | 3271/15000 [20:55<34:54,  5.60it/s, lr=9.93e-6, step_loss=0.342]07/18/2023 19:24:17 - INFO - __main__ - train loss is 11.407367569161579\n",
      "Steps:  22%|▏| 3272/15000 [20:55<34:53,  5.60it/s, lr=9.93e-6, step_loss=0.0273]07/18/2023 19:24:17 - INFO - __main__ - train loss is 11.585702714277431\n",
      "Steps:  22%|▍ | 3273/15000 [20:55<34:53,  5.60it/s, lr=9.93e-6, step_loss=0.178]07/18/2023 19:24:17 - INFO - __main__ - train loss is 11.722778436494991\n",
      "Steps:  22%|▍ | 3274/15000 [20:55<34:54,  5.60it/s, lr=9.93e-6, step_loss=0.137]07/18/2023 19:24:18 - INFO - __main__ - train loss is 11.73804196412675\n",
      "Steps:  22%|▏| 3275/15000 [20:55<35:14,  5.54it/s, lr=9.93e-6, step_loss=0.0153]07/18/2023 19:24:18 - INFO - __main__ - train loss is 12.065767613006756\n",
      "Steps:  22%|▍ | 3276/15000 [20:56<35:14,  5.54it/s, lr=9.93e-6, step_loss=0.328]07/18/2023 19:24:18 - INFO - __main__ - train loss is 12.31804382498376\n",
      "Steps:  22%|▍ | 3277/15000 [20:56<35:08,  5.56it/s, lr=9.93e-6, step_loss=0.252]07/18/2023 19:24:18 - INFO - __main__ - train loss is 12.320095021976158\n",
      "Steps:  22%|▏| 3278/15000 [20:56<35:04,  5.57it/s, lr=9.93e-6, step_loss=0.0020507/18/2023 19:24:18 - INFO - __main__ - train loss is 12.3812864839565\n",
      "Steps:  22%|▏| 3279/15000 [20:56<35:00,  5.58it/s, lr=9.93e-6, step_loss=0.0612]07/18/2023 19:24:18 - INFO - __main__ - train loss is 12.641586703015491\n",
      "Steps:  22%|▋  | 3280/15000 [20:56<35:02,  5.57it/s, lr=9.93e-6, step_loss=0.26]07/18/2023 19:24:19 - INFO - __main__ - train loss is 12.768183869076893\n",
      "Steps:  22%|▍ | 3281/15000 [20:57<35:24,  5.52it/s, lr=9.93e-6, step_loss=0.127]07/18/2023 19:24:19 - INFO - __main__ - train loss is 12.888812226010486\n",
      "Steps:  22%|▍ | 3282/15000 [20:57<35:14,  5.54it/s, lr=9.93e-6, step_loss=0.121]07/18/2023 19:24:19 - INFO - __main__ - train loss is 12.901880018180236\n",
      "Steps:  22%|▏| 3283/15000 [20:57<35:24,  5.52it/s, lr=9.93e-6, step_loss=0.0131]07/18/2023 19:24:19 - INFO - __main__ - train loss is 12.919153712457046\n",
      "Steps:  22%|▏| 3284/15000 [20:57<35:33,  5.49it/s, lr=9.93e-6, step_loss=0.0173]07/18/2023 19:24:19 - INFO - __main__ - train loss is 13.641897164052352\n",
      "Steps:  22%|▍ | 3285/15000 [20:57<35:28,  5.50it/s, lr=9.93e-6, step_loss=0.723]07/18/2023 19:24:20 - INFO - __main__ - train loss is 13.764300174778327\n",
      "Steps:  22%|▍ | 3286/15000 [20:57<35:15,  5.54it/s, lr=9.93e-6, step_loss=0.122]07/18/2023 19:24:20 - INFO - __main__ - train loss is 13.77134908712469\n",
      "Steps:  22%|▏| 3287/15000 [20:58<35:05,  5.56it/s, lr=9.93e-6, step_loss=0.0070507/18/2023 19:24:20 - INFO - __main__ - train loss is 13.788912057643756\n",
      "Steps:  22%|▏| 3288/15000 [20:58<34:58,  5.58it/s, lr=9.93e-6, step_loss=0.0176]07/18/2023 19:24:20 - INFO - __main__ - train loss is 13.844498052960262\n",
      "Steps:  22%|▏| 3289/15000 [20:58<34:52,  5.60it/s, lr=9.93e-6, step_loss=0.0556]07/18/2023 19:24:20 - INFO - __main__ - train loss is 13.899808075046167\n",
      "Steps:  22%|▏| 3290/15000 [20:58<34:49,  5.61it/s, lr=9.93e-6, step_loss=0.0553]07/18/2023 19:24:20 - INFO - __main__ - train loss is 13.903991831699386\n",
      "Steps:  22%|▏| 3291/15000 [20:58<34:46,  5.61it/s, lr=9.93e-6, step_loss=0.0041807/18/2023 19:24:21 - INFO - __main__ - train loss is 14.255511148134246\n",
      "Steps:  22%|▍ | 3292/15000 [20:58<34:44,  5.62it/s, lr=9.93e-6, step_loss=0.352]07/18/2023 19:24:21 - INFO - __main__ - train loss is 14.449689461151138\n",
      "Steps:  22%|▍ | 3293/15000 [20:59<34:42,  5.62it/s, lr=9.93e-6, step_loss=0.194]07/18/2023 19:24:21 - INFO - __main__ - train loss is 14.632928041974083\n",
      "Steps:  22%|▍ | 3294/15000 [20:59<34:44,  5.61it/s, lr=9.93e-6, step_loss=0.183]07/18/2023 19:24:21 - INFO - __main__ - train loss is 14.848557768622413\n",
      "Steps:  22%|▍ | 3295/15000 [20:59<34:44,  5.62it/s, lr=9.93e-6, step_loss=0.216]07/18/2023 19:24:21 - INFO - __main__ - train loss is 15.326573489466682\n",
      "Steps:  22%|▍ | 3296/15000 [20:59<34:45,  5.61it/s, lr=9.93e-6, step_loss=0.478]07/18/2023 19:24:21 - INFO - __main__ - train loss is 15.351162741193548\n",
      "Steps:  22%|▏| 3297/15000 [20:59<34:43,  5.62it/s, lr=9.93e-6, step_loss=0.0246]07/18/2023 19:24:22 - INFO - __main__ - train loss is 15.357650469290093\n",
      "Steps:  22%|▏| 3298/15000 [21:00<46:09,  4.23it/s, lr=9.93e-6, step_loss=0.0064907/18/2023 19:24:23 - INFO - __main__ - Per validation step average loss is 0.03924347087740898\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Cumulative validation average loss is 0.03924347087740898\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Per validation step average loss is 0.002823439659550786\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Cumulative validation average loss is 0.04206691053695977\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Per validation step average loss is 0.005085509270429611\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Cumulative validation average loss is 0.04715241980738938\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Per validation step average loss is 0.7344076037406921\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Cumulative validation average loss is 0.7815600235480815\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Per validation step average loss is 0.02635398507118225\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Cumulative validation average loss is 0.8079140086192638\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Per validation step average loss is 0.15300288796424866\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Cumulative validation average loss is 0.9609168965835124\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Per validation step average loss is 0.258813738822937\n",
      "07/18/2023 19:24:23 - INFO - __main__ - Cumulative validation average loss is 1.2197306354064494\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Per validation step average loss is 0.004563261289149523\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Cumulative validation average loss is 1.224293896695599\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Per validation step average loss is 0.1445995569229126\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Cumulative validation average loss is 1.3688934536185116\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Per validation step average loss is 0.7536819577217102\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Cumulative validation average loss is 2.1225754113402218\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Per validation step average loss is 0.16516238451004028\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Cumulative validation average loss is 2.287737795850262\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Per validation step average loss is 0.003424790920689702\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Cumulative validation average loss is 2.2911625867709517\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Average validation loss for Epoch 33 is 0.19093021556424597\n",
      "07/18/2023 19:24:24 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:24:37 - INFO - __main__ - Starting epoch 34\n",
      "07/18/2023 19:24:38 - INFO - __main__ - train loss is 0.1192224845290184\n",
      "Steps:  22%|▏| 3299/15000 [21:15<15:52:28,  4.88s/it, lr=9.93e-6, step_loss=0.1107/18/2023 19:24:38 - INFO - __main__ - train loss is 0.126255851238966\n",
      "Steps:  22%|▏| 3300/15000 [21:16<11:17:09,  3.47s/it, lr=9.93e-6, step_loss=0.0007/18/2023 19:24:38 - INFO - __main__ - train loss is 0.1398596977815032\n",
      "Steps:  22%|▏| 3301/15000 [21:16<8:04:19,  2.48s/it, lr=9.93e-6, step_loss=0.01307/18/2023 19:24:38 - INFO - __main__ - train loss is 0.20579866226762533\n",
      "Steps:  22%|▏| 3302/15000 [21:16<5:49:35,  1.79s/it, lr=9.93e-6, step_loss=0.06507/18/2023 19:24:38 - INFO - __main__ - train loss is 0.2127707269974053\n",
      "Steps:  22%|▏| 3303/15000 [21:16<4:15:04,  1.31s/it, lr=9.93e-6, step_loss=0.00607/18/2023 19:24:38 - INFO - __main__ - train loss is 0.3775643673725426\n",
      "Steps:  22%|▏| 3304/15000 [21:16<3:09:02,  1.03it/s, lr=9.93e-6, step_loss=0.16507/18/2023 19:24:39 - INFO - __main__ - train loss is 0.3801930039189756\n",
      "Steps:  22%|▏| 3305/15000 [21:17<2:22:42,  1.37it/s, lr=9.93e-6, step_loss=0.00207/18/2023 19:24:39 - INFO - __main__ - train loss is 0.6646602838300169\n",
      "Steps:  22%|▏| 3306/15000 [21:17<1:50:16,  1.77it/s, lr=9.93e-6, step_loss=0.28407/18/2023 19:24:39 - INFO - __main__ - train loss is 0.6762109822593629\n",
      "Steps:  22%|▏| 3307/15000 [21:17<1:27:34,  2.23it/s, lr=9.93e-6, step_loss=0.01107/18/2023 19:24:39 - INFO - __main__ - train loss is 0.7620554468594491\n",
      "Steps:  22%|▏| 3308/15000 [21:17<1:11:41,  2.72it/s, lr=9.93e-6, step_loss=0.08507/18/2023 19:24:39 - INFO - __main__ - train loss is 1.2421152493916452\n",
      "Steps:  22%|▏| 3309/15000 [21:17<1:00:38,  3.21it/s, lr=9.93e-6, step_loss=0.48]07/18/2023 19:24:40 - INFO - __main__ - train loss is 1.390034010168165\n",
      "Steps:  22%|▍ | 3310/15000 [21:17<52:53,  3.68it/s, lr=9.93e-6, step_loss=0.148]07/18/2023 19:24:40 - INFO - __main__ - train loss is 1.4139997414313257\n",
      "Steps:  22%|▍ | 3311/15000 [21:18<47:24,  4.11it/s, lr=9.93e-6, step_loss=0.024]07/18/2023 19:24:40 - INFO - __main__ - train loss is 1.4254229362122715\n",
      "Steps:  22%|▏| 3312/15000 [21:18<43:37,  4.46it/s, lr=9.93e-6, step_loss=0.0114]07/18/2023 19:24:40 - INFO - __main__ - train loss is 1.6894479091279209\n",
      "Steps:  22%|▍ | 3313/15000 [21:18<40:57,  4.76it/s, lr=9.93e-6, step_loss=0.264]07/18/2023 19:24:40 - INFO - __main__ - train loss is 2.0077545936219394\n",
      "Steps:  22%|▍ | 3314/15000 [21:18<39:02,  4.99it/s, lr=9.93e-6, step_loss=0.318]07/18/2023 19:24:40 - INFO - __main__ - train loss is 2.1283510993234813\n",
      "Steps:  22%|▍ | 3315/15000 [21:18<37:43,  5.16it/s, lr=9.93e-6, step_loss=0.121]07/18/2023 19:24:41 - INFO - __main__ - train loss is 2.1871724384836853\n",
      "Steps:  22%|▏| 3316/15000 [21:19<36:49,  5.29it/s, lr=9.93e-6, step_loss=0.0588]07/18/2023 19:24:41 - INFO - __main__ - train loss is 2.3505351203493774\n",
      "Steps:  22%|▍ | 3317/15000 [21:19<36:12,  5.38it/s, lr=9.93e-6, step_loss=0.163]07/18/2023 19:24:41 - INFO - __main__ - train loss is 2.3743840414099395\n",
      "Steps:  22%|▏| 3318/15000 [21:19<35:45,  5.44it/s, lr=9.93e-6, step_loss=0.0238]07/18/2023 19:24:41 - INFO - __main__ - train loss is 2.408849302213639\n",
      "Steps:  22%|▏| 3319/15000 [21:19<35:26,  5.49it/s, lr=9.93e-6, step_loss=0.0345]07/18/2023 19:24:41 - INFO - __main__ - train loss is 2.704373690765351\n",
      "Steps:  22%|▍ | 3320/15000 [21:19<35:12,  5.53it/s, lr=9.93e-6, step_loss=0.296]07/18/2023 19:24:42 - INFO - __main__ - train loss is 2.7065895705018193\n",
      "Steps:  22%|▏| 3321/15000 [21:19<35:18,  5.51it/s, lr=9.93e-6, step_loss=0.0022207/18/2023 19:24:42 - INFO - __main__ - train loss is 3.2524945049080998\n",
      "Steps:  22%|▍ | 3322/15000 [21:20<35:20,  5.51it/s, lr=9.93e-6, step_loss=0.546]07/18/2023 19:24:42 - INFO - __main__ - train loss is 3.2575940263923258\n",
      "Steps:  22%|▏| 3323/15000 [21:20<35:23,  5.50it/s, lr=9.93e-6, step_loss=0.0051]07/18/2023 19:24:42 - INFO - __main__ - train loss is 3.647752441233024\n",
      "Steps:  22%|▋  | 3324/15000 [21:20<35:26,  5.49it/s, lr=9.93e-6, step_loss=0.39]07/18/2023 19:24:42 - INFO - __main__ - train loss is 3.664072656771168\n",
      "Steps:  22%|▏| 3325/15000 [21:20<35:22,  5.50it/s, lr=9.92e-6, step_loss=0.0163]07/18/2023 19:24:42 - INFO - __main__ - train loss is 3.870046252151951\n",
      "Steps:  22%|▍ | 3326/15000 [21:20<35:35,  5.47it/s, lr=9.92e-6, step_loss=0.206]07/18/2023 19:24:43 - INFO - __main__ - train loss is 3.8750803146976978\n",
      "Steps:  22%|▏| 3327/15000 [21:21<35:31,  5.48it/s, lr=9.92e-6, step_loss=0.0050307/18/2023 19:24:43 - INFO - __main__ - train loss is 4.036139098228887\n",
      "Steps:  22%|▍ | 3328/15000 [21:21<35:47,  5.43it/s, lr=9.92e-6, step_loss=0.161]07/18/2023 19:24:43 - INFO - __main__ - train loss is 4.0515500355977565\n",
      "Steps:  22%|▏| 3329/15000 [21:21<36:34,  5.32it/s, lr=9.92e-6, step_loss=0.0154]07/18/2023 19:24:43 - INFO - __main__ - train loss is 4.090380189241841\n",
      "Steps:  22%|▏| 3330/15000 [21:21<37:02,  5.25it/s, lr=9.92e-6, step_loss=0.0388]07/18/2023 19:24:43 - INFO - __main__ - train loss is 4.279179451288655\n",
      "Steps:  22%|▍ | 3331/15000 [21:21<37:23,  5.20it/s, lr=9.92e-6, step_loss=0.189]07/18/2023 19:24:44 - INFO - __main__ - train loss is 4.283561663934961\n",
      "Steps:  22%|▏| 3332/15000 [21:21<37:19,  5.21it/s, lr=9.92e-6, step_loss=0.0043807/18/2023 19:24:44 - INFO - __main__ - train loss is 4.289355440298095\n",
      "Steps:  22%|▏| 3333/15000 [21:22<37:36,  5.17it/s, lr=9.92e-6, step_loss=0.0057907/18/2023 19:24:44 - INFO - __main__ - train loss is 4.302376482868567\n",
      "Steps:  22%|▍ | 3334/15000 [21:22<37:40,  5.16it/s, lr=9.92e-6, step_loss=0.013]07/18/2023 19:24:44 - INFO - __main__ - train loss is 4.822095010662451\n",
      "Steps:  22%|▋  | 3335/15000 [21:22<37:49,  5.14it/s, lr=9.92e-6, step_loss=0.52]07/18/2023 19:24:44 - INFO - __main__ - train loss is 4.8483922521118075\n",
      "Steps:  22%|▏| 3336/15000 [21:22<37:56,  5.12it/s, lr=9.92e-6, step_loss=0.0263]07/18/2023 19:24:45 - INFO - __main__ - train loss is 4.862423727521673\n",
      "Steps:  22%|▍ | 3337/15000 [21:22<38:04,  5.11it/s, lr=9.92e-6, step_loss=0.014]07/18/2023 19:24:45 - INFO - __main__ - train loss is 4.970490927109495\n",
      "Steps:  22%|▍ | 3338/15000 [21:23<38:08,  5.10it/s, lr=9.92e-6, step_loss=0.108]07/18/2023 19:24:45 - INFO - __main__ - train loss is 5.044316524872556\n",
      "Steps:  22%|▏| 3339/15000 [21:23<38:08,  5.10it/s, lr=9.92e-6, step_loss=0.0738]07/18/2023 19:24:45 - INFO - __main__ - train loss is 5.9866939729545265\n",
      "Steps:  22%|▍ | 3340/15000 [21:23<37:38,  5.16it/s, lr=9.92e-6, step_loss=0.942]07/18/2023 19:24:45 - INFO - __main__ - train loss is 6.01744725019671\n",
      "Steps:  22%|▏| 3341/15000 [21:23<36:44,  5.29it/s, lr=9.92e-6, step_loss=0.0308]07/18/2023 19:24:46 - INFO - __main__ - train loss is 6.0464239998254925\n",
      "Steps:  22%|▍ | 3342/15000 [21:23<36:06,  5.38it/s, lr=9.92e-6, step_loss=0.029]07/18/2023 19:24:46 - INFO - __main__ - train loss is 6.2772299780044705\n",
      "Steps:  22%|▍ | 3343/15000 [21:24<35:40,  5.45it/s, lr=9.92e-6, step_loss=0.231]07/18/2023 19:24:46 - INFO - __main__ - train loss is 6.328818267444149\n",
      "Steps:  22%|▏| 3344/15000 [21:24<35:22,  5.49it/s, lr=9.92e-6, step_loss=0.0516]07/18/2023 19:24:46 - INFO - __main__ - train loss is 6.562627768376842\n",
      "Steps:  22%|▍ | 3345/15000 [21:24<35:11,  5.52it/s, lr=9.92e-6, step_loss=0.234]07/18/2023 19:24:46 - INFO - __main__ - train loss is 6.701658299425617\n",
      "Steps:  22%|▍ | 3346/15000 [21:24<35:01,  5.55it/s, lr=9.92e-6, step_loss=0.139]07/18/2023 19:24:46 - INFO - __main__ - train loss is 6.715995576465502\n",
      "Steps:  22%|▏| 3347/15000 [21:24<34:55,  5.56it/s, lr=9.92e-6, step_loss=0.0143]07/18/2023 19:24:47 - INFO - __main__ - train loss is 7.0230291748885065\n",
      "Steps:  22%|▍ | 3348/15000 [21:24<34:51,  5.57it/s, lr=9.92e-6, step_loss=0.307]07/18/2023 19:24:47 - INFO - __main__ - train loss is 7.038872862467542\n",
      "Steps:  22%|▏| 3349/15000 [21:25<34:49,  5.58it/s, lr=9.92e-6, step_loss=0.0158]07/18/2023 19:24:47 - INFO - __main__ - train loss is 7.192543620476499\n",
      "Steps:  22%|▍ | 3350/15000 [21:25<34:45,  5.59it/s, lr=9.92e-6, step_loss=0.154]07/18/2023 19:24:47 - INFO - __main__ - train loss is 7.374548429856077\n",
      "Steps:  22%|▍ | 3351/15000 [21:25<35:00,  5.55it/s, lr=9.92e-6, step_loss=0.182]07/18/2023 19:24:47 - INFO - __main__ - train loss is 7.38852508016862\n",
      "Steps:  22%|▍ | 3352/15000 [21:25<34:54,  5.56it/s, lr=9.92e-6, step_loss=0.014]07/18/2023 19:24:47 - INFO - __main__ - train loss is 7.43057419010438\n",
      "Steps:  22%|▍ | 3353/15000 [21:25<34:51,  5.57it/s, lr=9.92e-6, step_loss=0.042]07/18/2023 19:24:48 - INFO - __main__ - train loss is 7.460301827872172\n",
      "Steps:  22%|▏| 3354/15000 [21:26<34:47,  5.58it/s, lr=9.92e-6, step_loss=0.0297]07/18/2023 19:24:48 - INFO - __main__ - train loss is 7.462886912515387\n",
      "Steps:  22%|▏| 3355/15000 [21:26<34:43,  5.59it/s, lr=9.92e-6, step_loss=0.0025907/18/2023 19:24:48 - INFO - __main__ - train loss is 7.673069147160277\n",
      "Steps:  22%|▋  | 3356/15000 [21:26<34:41,  5.60it/s, lr=9.92e-6, step_loss=0.21]07/18/2023 19:24:48 - INFO - __main__ - train loss is 7.886279938509688\n",
      "Steps:  22%|▍ | 3357/15000 [21:26<34:40,  5.60it/s, lr=9.92e-6, step_loss=0.213]07/18/2023 19:24:48 - INFO - __main__ - train loss is 8.029843447497115\n",
      "Steps:  22%|▍ | 3358/15000 [21:26<34:41,  5.59it/s, lr=9.92e-6, step_loss=0.144]07/18/2023 19:24:49 - INFO - __main__ - train loss is 8.033682908164337\n",
      "Steps:  22%|▏| 3359/15000 [21:26<34:43,  5.59it/s, lr=9.92e-6, step_loss=0.0038407/18/2023 19:24:49 - INFO - __main__ - train loss is 8.081580150173977\n",
      "Steps:  22%|▏| 3360/15000 [21:27<34:40,  5.59it/s, lr=9.92e-6, step_loss=0.0479]07/18/2023 19:24:49 - INFO - __main__ - train loss is 8.100614230381325\n",
      "Steps:  22%|▍ | 3361/15000 [21:27<34:39,  5.60it/s, lr=9.92e-6, step_loss=0.019]07/18/2023 19:24:49 - INFO - __main__ - train loss is 8.104592180112377\n",
      "Steps:  22%|▏| 3362/15000 [21:27<34:37,  5.60it/s, lr=9.92e-6, step_loss=0.0039807/18/2023 19:24:49 - INFO - __main__ - train loss is 8.134934829780832\n",
      "Steps:  22%|▏| 3363/15000 [21:27<34:37,  5.60it/s, lr=9.92e-6, step_loss=0.0303]07/18/2023 19:24:49 - INFO - __main__ - train loss is 8.48050837428309\n",
      "Steps:  22%|▍ | 3364/15000 [21:27<34:37,  5.60it/s, lr=9.92e-6, step_loss=0.346]07/18/2023 19:24:50 - INFO - __main__ - train loss is 8.876196848461404\n",
      "Steps:  22%|▍ | 3365/15000 [21:28<34:36,  5.60it/s, lr=9.92e-6, step_loss=0.396]07/18/2023 19:24:50 - INFO - __main__ - train loss is 9.559301482746378\n",
      "Steps:  22%|▍ | 3366/15000 [21:28<34:36,  5.60it/s, lr=9.92e-6, step_loss=0.683]07/18/2023 19:24:50 - INFO - __main__ - train loss is 9.560799869475886\n",
      "Steps:  22%|▏| 3367/15000 [21:28<34:35,  5.60it/s, lr=9.92e-6, step_loss=0.0015]07/18/2023 19:24:50 - INFO - __main__ - train loss is 9.60508710029535\n",
      "Steps:  22%|▏| 3368/15000 [21:28<34:34,  5.61it/s, lr=9.92e-6, step_loss=0.0443]07/18/2023 19:24:50 - INFO - __main__ - train loss is 9.608423402998596\n",
      "Steps:  22%|▏| 3369/15000 [21:28<34:33,  5.61it/s, lr=9.92e-6, step_loss=0.0033407/18/2023 19:24:51 - INFO - __main__ - train loss is 9.612510648556054\n",
      "Steps:  22%|▏| 3370/15000 [21:28<34:33,  5.61it/s, lr=9.92e-6, step_loss=0.0040907/18/2023 19:24:51 - INFO - __main__ - train loss is 9.63286240492016\n",
      "Steps:  22%|▏| 3371/15000 [21:29<34:33,  5.61it/s, lr=9.92e-6, step_loss=0.0204]07/18/2023 19:24:51 - INFO - __main__ - train loss is 9.990438745357096\n",
      "Steps:  22%|▍ | 3372/15000 [21:29<34:32,  5.61it/s, lr=9.92e-6, step_loss=0.358]07/18/2023 19:24:51 - INFO - __main__ - train loss is 9.994733406230807\n",
      "Steps:  22%|▏| 3373/15000 [21:29<34:31,  5.61it/s, lr=9.92e-6, step_loss=0.0042907/18/2023 19:24:51 - INFO - __main__ - train loss is 10.008905139751732\n",
      "Steps:  22%|▏| 3374/15000 [21:29<34:33,  5.61it/s, lr=9.92e-6, step_loss=0.0142]07/18/2023 19:24:51 - INFO - __main__ - train loss is 10.012501713819802\n",
      "Steps:  22%|▏| 3375/15000 [21:29<34:33,  5.61it/s, lr=9.92e-6, step_loss=0.0036]07/18/2023 19:24:52 - INFO - __main__ - train loss is 10.454675671644509\n",
      "Steps:  23%|▍ | 3376/15000 [21:29<34:32,  5.61it/s, lr=9.92e-6, step_loss=0.442]07/18/2023 19:24:52 - INFO - __main__ - train loss is 10.489256196655333\n",
      "Steps:  23%|▏| 3377/15000 [21:30<34:32,  5.61it/s, lr=9.92e-6, step_loss=0.0346]07/18/2023 19:24:52 - INFO - __main__ - train loss is 10.580855914391577\n",
      "Steps:  23%|▏| 3378/15000 [21:30<34:32,  5.61it/s, lr=9.92e-6, step_loss=0.0916]07/18/2023 19:24:52 - INFO - __main__ - train loss is 10.611196993850172\n",
      "Steps:  23%|▏| 3379/15000 [21:30<34:31,  5.61it/s, lr=9.92e-6, step_loss=0.0303]07/18/2023 19:24:52 - INFO - __main__ - train loss is 10.796980186365545\n",
      "Steps:  23%|▍ | 3380/15000 [21:30<34:30,  5.61it/s, lr=9.92e-6, step_loss=0.186]07/18/2023 19:24:52 - INFO - __main__ - train loss is 10.91551825311035\n",
      "Steps:  23%|▍ | 3381/15000 [21:30<34:29,  5.61it/s, lr=9.92e-6, step_loss=0.119]07/18/2023 19:24:53 - INFO - __main__ - train loss is 11.059402762912214\n",
      "Steps:  23%|▍ | 3382/15000 [21:31<34:28,  5.62it/s, lr=9.92e-6, step_loss=0.144]07/18/2023 19:24:53 - INFO - __main__ - train loss is 11.212668090127409\n",
      "Steps:  23%|▍ | 3383/15000 [21:31<34:28,  5.62it/s, lr=9.92e-6, step_loss=0.153]07/18/2023 19:24:53 - INFO - __main__ - train loss is 11.22409785259515\n",
      "Steps:  23%|▏| 3384/15000 [21:31<34:27,  5.62it/s, lr=9.92e-6, step_loss=0.0114]07/18/2023 19:24:53 - INFO - __main__ - train loss is 11.250415668822825\n",
      "Steps:  23%|▏| 3385/15000 [21:31<35:02,  5.52it/s, lr=9.92e-6, step_loss=0.0263]07/18/2023 19:24:53 - INFO - __main__ - train loss is 11.444307045079768\n",
      "Steps:  23%|▍ | 3386/15000 [21:31<34:51,  5.55it/s, lr=9.92e-6, step_loss=0.194]07/18/2023 19:24:54 - INFO - __main__ - train loss is 11.78493554983288\n",
      "Steps:  23%|▍ | 3387/15000 [21:31<34:44,  5.57it/s, lr=9.92e-6, step_loss=0.341]07/18/2023 19:24:54 - INFO - __main__ - train loss is 11.789094246923923\n",
      "Steps:  23%|▏| 3388/15000 [21:32<35:07,  5.51it/s, lr=9.92e-6, step_loss=0.0041607/18/2023 19:24:54 - INFO - __main__ - train loss is 11.79637535661459\n",
      "Steps:  23%|▏| 3389/15000 [21:32<35:02,  5.52it/s, lr=9.92e-6, step_loss=0.0072807/18/2023 19:24:54 - INFO - __main__ - train loss is 12.01320255547762\n",
      "Steps:  23%|▍ | 3390/15000 [21:32<35:06,  5.51it/s, lr=9.92e-6, step_loss=0.217]07/18/2023 19:24:54 - INFO - __main__ - train loss is 12.192596711218357\n",
      "Steps:  23%|▍ | 3391/15000 [21:32<35:12,  5.49it/s, lr=9.92e-6, step_loss=0.179]07/18/2023 19:24:54 - INFO - __main__ - train loss is 12.195858374005184\n",
      "Steps:  23%|▏| 3392/15000 [21:32<35:00,  5.53it/s, lr=9.92e-6, step_loss=0.0032607/18/2023 19:24:55 - INFO - __main__ - train loss is 12.29647322720848\n",
      "Steps:  23%|▍ | 3393/15000 [21:33<34:55,  5.54it/s, lr=9.92e-6, step_loss=0.101]07/18/2023 19:24:55 - INFO - __main__ - train loss is 12.372480913763866\n",
      "Steps:  23%|▍ | 3394/15000 [21:33<35:04,  5.52it/s, lr=9.92e-6, step_loss=0.076]07/18/2023 19:24:55 - INFO - __main__ - train loss is 12.401162553345785\n",
      "Steps:  23%|▏| 3395/15000 [21:33<47:47,  4.05it/s, lr=9.92e-6, step_loss=0.0287]07/18/2023 19:24:56 - INFO - __main__ - Per validation step average loss is 0.06843908131122589\n",
      "07/18/2023 19:24:56 - INFO - __main__ - Cumulative validation average loss is 0.06843908131122589\n",
      "07/18/2023 19:24:56 - INFO - __main__ - Per validation step average loss is 0.01583140343427658\n",
      "07/18/2023 19:24:56 - INFO - __main__ - Cumulative validation average loss is 0.08427048474550247\n",
      "07/18/2023 19:24:56 - INFO - __main__ - Per validation step average loss is 0.006322524044662714\n",
      "07/18/2023 19:24:56 - INFO - __main__ - Cumulative validation average loss is 0.09059300879016519\n",
      "07/18/2023 19:24:56 - INFO - __main__ - Per validation step average loss is 0.002810569480061531\n",
      "07/18/2023 19:24:56 - INFO - __main__ - Cumulative validation average loss is 0.09340357827022672\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Per validation step average loss is 0.013696752488613129\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Cumulative validation average loss is 0.10710033075883985\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Per validation step average loss is 0.014524709433317184\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Cumulative validation average loss is 0.12162504019215703\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Per validation step average loss is 0.04547795653343201\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Cumulative validation average loss is 0.16710299672558904\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Per validation step average loss is 0.013454579748213291\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Cumulative validation average loss is 0.18055757647380233\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Per validation step average loss is 0.14298510551452637\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Cumulative validation average loss is 0.3235426819883287\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Per validation step average loss is 0.14425760507583618\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Cumulative validation average loss is 0.4678002870641649\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Per validation step average loss is 0.3787933886051178\n",
      "07/18/2023 19:24:57 - INFO - __main__ - Cumulative validation average loss is 0.8465936756692827\n",
      "07/18/2023 19:24:58 - INFO - __main__ - Per validation step average loss is 0.3178084194660187\n",
      "07/18/2023 19:24:58 - INFO - __main__ - Cumulative validation average loss is 1.1644020951353014\n",
      "07/18/2023 19:24:58 - INFO - __main__ - Average validation loss for Epoch 34 is 0.09703350792794178\n",
      "07/18/2023 19:24:58 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:25:10 - INFO - __main__ - Starting epoch 35\n",
      "07/18/2023 19:25:11 - INFO - __main__ - train loss is 0.007505672983825207\n",
      "Steps:  23%|▏| 3396/15000 [21:49<15:53:22,  4.93s/it, lr=9.92e-6, step_loss=0.0007/18/2023 19:25:11 - INFO - __main__ - train loss is 0.0092823535669595\n",
      "Steps:  23%|▏| 3397/15000 [21:49<11:17:40,  3.50s/it, lr=9.92e-6, step_loss=0.0007/18/2023 19:25:11 - INFO - __main__ - train loss is 0.12993778591044247\n",
      "Steps:  23%|▏| 3398/15000 [21:49<8:04:41,  2.51s/it, lr=9.92e-6, step_loss=0.12107/18/2023 19:25:12 - INFO - __main__ - train loss is 0.1320685602258891\n",
      "Steps:  23%|▏| 3399/15000 [21:49<5:49:38,  1.81s/it, lr=9.92e-6, step_loss=0.00207/18/2023 19:25:12 - INFO - __main__ - train loss is 0.1450117330532521\n",
      "Steps:  23%|▏| 3400/15000 [21:50<4:15:17,  1.32s/it, lr=9.92e-6, step_loss=0.01207/18/2023 19:25:12 - INFO - __main__ - train loss is 0.6338830392342061\n",
      "Steps:  23%|▏| 3401/15000 [21:50<3:09:01,  1.02it/s, lr=9.92e-6, step_loss=0.48907/18/2023 19:25:12 - INFO - __main__ - train loss is 0.8686701159458607\n",
      "Steps:  23%|▏| 3402/15000 [21:50<2:22:37,  1.36it/s, lr=9.92e-6, step_loss=0.23507/18/2023 19:25:12 - INFO - __main__ - train loss is 1.0561329673510045\n",
      "Steps:  23%|▏| 3403/15000 [21:50<1:50:08,  1.75it/s, lr=9.92e-6, step_loss=0.18707/18/2023 19:25:13 - INFO - __main__ - train loss is 1.1169675278943032\n",
      "Steps:  23%|▏| 3404/15000 [21:50<1:27:40,  2.20it/s, lr=9.92e-6, step_loss=0.06007/18/2023 19:25:13 - INFO - __main__ - train loss is 1.1240401242394\n",
      "Steps:  23%|▏| 3405/15000 [21:51<1:11:41,  2.70it/s, lr=9.92e-6, step_loss=0.00707/18/2023 19:25:13 - INFO - __main__ - train loss is 1.15507469070144\n",
      "Steps:  23%|▏| 3406/15000 [21:51<1:00:30,  3.19it/s, lr=9.92e-6, step_loss=0.03107/18/2023 19:25:13 - INFO - __main__ - train loss is 1.1586214744020253\n",
      "Steps:  23%|▏| 3407/15000 [21:51<52:37,  3.67it/s, lr=9.92e-6, step_loss=0.0035507/18/2023 19:25:13 - INFO - __main__ - train loss is 1.5466889881063253\n",
      "Steps:  23%|▍ | 3408/15000 [21:51<47:11,  4.09it/s, lr=9.92e-6, step_loss=0.388]07/18/2023 19:25:13 - INFO - __main__ - train loss is 1.799489124910906\n",
      "Steps:  23%|▍ | 3409/15000 [21:51<43:19,  4.46it/s, lr=9.92e-6, step_loss=0.253]07/18/2023 19:25:14 - INFO - __main__ - train loss is 2.587163432734087\n",
      "Steps:  23%|▍ | 3410/15000 [21:51<40:37,  4.75it/s, lr=9.92e-6, step_loss=0.788]07/18/2023 19:25:14 - INFO - __main__ - train loss is 2.727043464081362\n",
      "Steps:  23%|▋  | 3411/15000 [21:52<38:42,  4.99it/s, lr=9.92e-6, step_loss=0.14]07/18/2023 19:25:14 - INFO - __main__ - train loss is 2.8583443604875356\n",
      "Steps:  23%|▍ | 3412/15000 [21:52<37:27,  5.16it/s, lr=9.92e-6, step_loss=0.131]07/18/2023 19:25:14 - INFO - __main__ - train loss is 2.88766875048168\n",
      "Steps:  23%|▏| 3413/15000 [21:52<36:33,  5.28it/s, lr=9.92e-6, step_loss=0.0293]07/18/2023 19:25:14 - INFO - __main__ - train loss is 2.8950756501872092\n",
      "Steps:  23%|▏| 3414/15000 [21:52<35:55,  5.38it/s, lr=9.92e-6, step_loss=0.0074107/18/2023 19:25:14 - INFO - __main__ - train loss is 2.90540997707285\n",
      "Steps:  23%|▏| 3415/15000 [21:52<35:26,  5.45it/s, lr=9.92e-6, step_loss=0.0103]07/18/2023 19:25:15 - INFO - __main__ - train loss is 3.280702397460118\n",
      "Steps:  23%|▍ | 3416/15000 [21:53<35:07,  5.50it/s, lr=9.92e-6, step_loss=0.375]07/18/2023 19:25:15 - INFO - __main__ - train loss is 3.377710312837735\n",
      "Steps:  23%|▍ | 3417/15000 [21:53<34:55,  5.53it/s, lr=9.92e-6, step_loss=0.097]07/18/2023 19:25:15 - INFO - __main__ - train loss is 3.7695160212460905\n",
      "Steps:  23%|▍ | 3418/15000 [21:53<34:46,  5.55it/s, lr=9.92e-6, step_loss=0.392]07/18/2023 19:25:15 - INFO - __main__ - train loss is 3.7729686375241727\n",
      "Steps:  23%|▏| 3419/15000 [21:53<34:39,  5.57it/s, lr=9.92e-6, step_loss=0.0034507/18/2023 19:25:15 - INFO - __main__ - train loss is 4.133033948717639\n",
      "Steps:  23%|▋  | 3420/15000 [21:53<34:34,  5.58it/s, lr=9.92e-6, step_loss=0.36]07/18/2023 19:25:16 - INFO - __main__ - train loss is 4.388200598536059\n",
      "Steps:  23%|▍ | 3421/15000 [21:53<34:31,  5.59it/s, lr=9.92e-6, step_loss=0.255]07/18/2023 19:25:16 - INFO - __main__ - train loss is 4.391192170791328\n",
      "Steps:  23%|▏| 3422/15000 [21:54<34:28,  5.60it/s, lr=9.92e-6, step_loss=0.0029907/18/2023 19:25:16 - INFO - __main__ - train loss is 4.474419246427715\n",
      "Steps:  23%|▏| 3423/15000 [21:54<34:25,  5.60it/s, lr=9.92e-6, step_loss=0.0832]07/18/2023 19:25:16 - INFO - __main__ - train loss is 4.678063104860485\n",
      "Steps:  23%|▍ | 3424/15000 [21:54<34:26,  5.60it/s, lr=9.92e-6, step_loss=0.204]07/18/2023 19:25:16 - INFO - __main__ - train loss is 4.771612177602947\n",
      "Steps:  23%|▏| 3425/15000 [21:54<34:25,  5.60it/s, lr=9.92e-6, step_loss=0.0935]07/18/2023 19:25:16 - INFO - __main__ - train loss is 4.9196215672418475\n",
      "Steps:  23%|▍ | 3426/15000 [21:54<34:25,  5.60it/s, lr=9.92e-6, step_loss=0.148]07/18/2023 19:25:17 - INFO - __main__ - train loss is 4.9554036958143115\n",
      "Steps:  23%|▏| 3427/15000 [21:54<34:24,  5.61it/s, lr=9.92e-6, step_loss=0.0358]07/18/2023 19:25:17 - INFO - __main__ - train loss is 4.959189051762223\n",
      "Steps:  23%|▏| 3428/15000 [21:55<34:23,  5.61it/s, lr=9.92e-6, step_loss=0.0037907/18/2023 19:25:17 - INFO - __main__ - train loss is 5.088275754824281\n",
      "Steps:  23%|▍ | 3429/15000 [21:55<34:23,  5.61it/s, lr=9.92e-6, step_loss=0.129]07/18/2023 19:25:17 - INFO - __main__ - train loss is 5.36135777272284\n",
      "Steps:  23%|▍ | 3430/15000 [21:55<34:23,  5.61it/s, lr=9.92e-6, step_loss=0.273]07/18/2023 19:25:17 - INFO - __main__ - train loss is 5.367957924026996\n",
      "Steps:  23%|▏| 3431/15000 [21:55<34:23,  5.61it/s, lr=9.92e-6, step_loss=0.0066]07/18/2023 19:25:18 - INFO - __main__ - train loss is 5.993813608307391\n",
      "Steps:  23%|▍ | 3432/15000 [21:55<34:23,  5.61it/s, lr=9.92e-6, step_loss=0.626]07/18/2023 19:25:18 - INFO - __main__ - train loss is 6.048168931622058\n",
      "Steps:  23%|▏| 3433/15000 [21:56<34:23,  5.61it/s, lr=9.92e-6, step_loss=0.0544]07/18/2023 19:25:18 - INFO - __main__ - train loss is 6.057090763468295\n",
      "Steps:  23%|▏| 3434/15000 [21:56<34:22,  5.61it/s, lr=9.92e-6, step_loss=0.0089207/18/2023 19:25:18 - INFO - __main__ - train loss is 6.073016899172217\n",
      "Steps:  23%|▏| 3435/15000 [21:56<34:21,  5.61it/s, lr=9.92e-6, step_loss=0.0159]07/18/2023 19:25:18 - INFO - __main__ - train loss is 6.227704840246588\n",
      "Steps:  23%|▍ | 3436/15000 [21:56<34:22,  5.61it/s, lr=9.92e-6, step_loss=0.155]07/18/2023 19:25:18 - INFO - __main__ - train loss is 6.2613764316774905\n",
      "Steps:  23%|▏| 3437/15000 [21:56<34:22,  5.61it/s, lr=9.92e-6, step_loss=0.0337]07/18/2023 19:25:19 - INFO - __main__ - train loss is 6.418963274452835\n",
      "Steps:  23%|▍ | 3438/15000 [21:56<34:24,  5.60it/s, lr=9.92e-6, step_loss=0.158]07/18/2023 19:25:19 - INFO - __main__ - train loss is 6.507619878742844\n",
      "Steps:  23%|▏| 3439/15000 [21:57<34:24,  5.60it/s, lr=9.92e-6, step_loss=0.0887]07/18/2023 19:25:19 - INFO - __main__ - train loss is 6.640124461147934\n",
      "Steps:  23%|▍ | 3440/15000 [21:57<34:23,  5.60it/s, lr=9.92e-6, step_loss=0.133]07/18/2023 19:25:19 - INFO - __main__ - train loss is 6.6541251740418375\n",
      "Steps:  23%|▍ | 3441/15000 [21:57<34:22,  5.61it/s, lr=9.92e-6, step_loss=0.014]07/18/2023 19:25:19 - INFO - __main__ - train loss is 6.729460155125707\n",
      "Steps:  23%|▏| 3442/15000 [21:57<34:22,  5.60it/s, lr=9.92e-6, step_loss=0.0753]07/18/2023 19:25:19 - INFO - __main__ - train loss is 6.73218200635165\n",
      "Steps:  23%|▏| 3443/15000 [21:57<34:23,  5.60it/s, lr=9.92e-6, step_loss=0.0027207/18/2023 19:25:20 - INFO - __main__ - train loss is 7.070476959459484\n",
      "Steps:  23%|▍ | 3444/15000 [21:58<34:22,  5.60it/s, lr=9.92e-6, step_loss=0.338]07/18/2023 19:25:20 - INFO - __main__ - train loss is 7.28242942225188\n",
      "Steps:  23%|▍ | 3445/15000 [21:58<34:21,  5.60it/s, lr=9.92e-6, step_loss=0.212]07/18/2023 19:25:20 - INFO - __main__ - train loss is 7.2849638485349715\n",
      "Steps:  23%|▏| 3446/15000 [21:58<34:19,  5.61it/s, lr=9.92e-6, step_loss=0.0025307/18/2023 19:25:20 - INFO - __main__ - train loss is 7.420273067895323\n",
      "Steps:  23%|▍ | 3447/15000 [21:58<34:20,  5.61it/s, lr=9.92e-6, step_loss=0.135]07/18/2023 19:25:20 - INFO - __main__ - train loss is 7.675087871495634\n",
      "Steps:  23%|▍ | 3448/15000 [21:58<34:20,  5.61it/s, lr=9.92e-6, step_loss=0.255]07/18/2023 19:25:21 - INFO - __main__ - train loss is 7.699813472572714\n",
      "Steps:  23%|▏| 3449/15000 [21:58<34:19,  5.61it/s, lr=9.92e-6, step_loss=0.0247]07/18/2023 19:25:21 - INFO - __main__ - train loss is 8.073353397194296\n",
      "Steps:  23%|▍ | 3450/15000 [21:59<34:19,  5.61it/s, lr=9.92e-6, step_loss=0.374]07/18/2023 19:25:21 - INFO - __main__ - train loss is 8.193898970726877\n",
      "Steps:  23%|▍ | 3451/15000 [21:59<34:19,  5.61it/s, lr=9.92e-6, step_loss=0.121]07/18/2023 19:25:21 - INFO - __main__ - train loss is 8.259301411453635\n",
      "Steps:  23%|▏| 3452/15000 [21:59<34:18,  5.61it/s, lr=9.92e-6, step_loss=0.0654]07/18/2023 19:25:21 - INFO - __main__ - train loss is 8.365002366248518\n",
      "Steps:  23%|▍ | 3453/15000 [21:59<34:18,  5.61it/s, lr=9.92e-6, step_loss=0.106]07/18/2023 19:25:21 - INFO - __main__ - train loss is 8.531575384084135\n",
      "Steps:  23%|▍ | 3454/15000 [21:59<34:18,  5.61it/s, lr=9.92e-6, step_loss=0.167]07/18/2023 19:25:22 - INFO - __main__ - train loss is 8.581133852247149\n",
      "Steps:  23%|▏| 3455/15000 [21:59<34:18,  5.61it/s, lr=9.92e-6, step_loss=0.0496]07/18/2023 19:25:22 - INFO - __main__ - train loss is 8.588185394648463\n",
      "Steps:  23%|▏| 3456/15000 [22:00<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.0070507/18/2023 19:25:22 - INFO - __main__ - train loss is 8.646034436766058\n",
      "Steps:  23%|▏| 3457/15000 [22:00<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.0578]07/18/2023 19:25:22 - INFO - __main__ - train loss is 8.80616337293759\n",
      "Steps:  23%|▋  | 3458/15000 [22:00<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.16]07/18/2023 19:25:22 - INFO - __main__ - train loss is 8.831483625341207\n",
      "Steps:  23%|▏| 3459/15000 [22:00<34:18,  5.61it/s, lr=9.92e-6, step_loss=0.0253]07/18/2023 19:25:22 - INFO - __main__ - train loss is 8.868751269299537\n",
      "Steps:  23%|▏| 3460/15000 [22:00<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.0373]07/18/2023 19:25:23 - INFO - __main__ - train loss is 9.443575006444007\n",
      "Steps:  23%|▍ | 3461/15000 [22:01<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.575]07/18/2023 19:25:23 - INFO - __main__ - train loss is 9.627154481131583\n",
      "Steps:  23%|▍ | 3462/15000 [22:01<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.184]07/18/2023 19:25:23 - INFO - __main__ - train loss is 9.708209794480354\n",
      "Steps:  23%|▏| 3463/15000 [22:01<34:18,  5.60it/s, lr=9.92e-6, step_loss=0.0811]07/18/2023 19:25:23 - INFO - __main__ - train loss is 10.013960700947791\n",
      "Steps:  23%|▍ | 3464/15000 [22:01<34:18,  5.60it/s, lr=9.92e-6, step_loss=0.306]07/18/2023 19:25:23 - INFO - __main__ - train loss is 10.583337527234107\n",
      "Steps:  23%|▍ | 3465/15000 [22:01<34:18,  5.60it/s, lr=9.92e-6, step_loss=0.569]07/18/2023 19:25:24 - INFO - __main__ - train loss is 10.661861386615783\n",
      "Steps:  23%|▏| 3466/15000 [22:01<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.0785]07/18/2023 19:25:24 - INFO - __main__ - train loss is 10.74121653707698\n",
      "Steps:  23%|▏| 3467/15000 [22:02<34:17,  5.61it/s, lr=9.92e-6, step_loss=0.0794]07/18/2023 19:25:24 - INFO - __main__ - train loss is 10.804389406461269\n",
      "Steps:  23%|▏| 3468/15000 [22:02<34:18,  5.60it/s, lr=9.92e-6, step_loss=0.0632]07/18/2023 19:25:24 - INFO - __main__ - train loss is 10.857262287754565\n",
      "Steps:  23%|▏| 3469/15000 [22:02<34:17,  5.60it/s, lr=9.92e-6, step_loss=0.0529]07/18/2023 19:25:24 - INFO - __main__ - train loss is 11.092578877229244\n",
      "Steps:  23%|▍ | 3470/15000 [22:02<34:16,  5.61it/s, lr=9.92e-6, step_loss=0.235]07/18/2023 19:25:24 - INFO - __main__ - train loss is 11.09740656754002\n",
      "Steps:  23%|▏| 3471/15000 [22:02<34:16,  5.60it/s, lr=9.92e-6, step_loss=0.0048307/18/2023 19:25:25 - INFO - __main__ - train loss is 11.099993875715882\n",
      "Steps:  23%|▏| 3472/15000 [22:03<34:18,  5.60it/s, lr=9.92e-6, step_loss=0.0025907/18/2023 19:25:25 - INFO - __main__ - train loss is 11.221434733364731\n",
      "Steps:  23%|▍ | 3473/15000 [22:03<34:17,  5.60it/s, lr=9.92e-6, step_loss=0.121]07/18/2023 19:25:25 - INFO - __main__ - train loss is 11.367154410574585\n",
      "Steps:  23%|▍ | 3474/15000 [22:03<34:15,  5.61it/s, lr=9.92e-6, step_loss=0.146]07/18/2023 19:25:25 - INFO - __main__ - train loss is 11.672292372677475\n",
      "Steps:  23%|▍ | 3475/15000 [22:03<34:16,  5.60it/s, lr=9.92e-6, step_loss=0.305]07/18/2023 19:25:25 - INFO - __main__ - train loss is 11.876567772123963\n",
      "Steps:  23%|▍ | 3476/15000 [22:03<34:16,  5.60it/s, lr=9.92e-6, step_loss=0.204]07/18/2023 19:25:26 - INFO - __main__ - train loss is 12.393085947725922\n",
      "Steps:  23%|▍ | 3477/15000 [22:03<34:14,  5.61it/s, lr=9.92e-6, step_loss=0.517]07/18/2023 19:25:26 - INFO - __main__ - train loss is 12.995993784163147\n",
      "Steps:  23%|▍ | 3478/15000 [22:04<34:12,  5.61it/s, lr=9.92e-6, step_loss=0.603]07/18/2023 19:25:26 - INFO - __main__ - train loss is 13.22669797251001\n",
      "Steps:  23%|▍ | 3479/15000 [22:04<34:12,  5.61it/s, lr=9.92e-6, step_loss=0.231]07/18/2023 19:25:26 - INFO - __main__ - train loss is 13.256514624226838\n",
      "Steps:  23%|▏| 3480/15000 [22:04<34:11,  5.62it/s, lr=9.92e-6, step_loss=0.0298]07/18/2023 19:25:26 - INFO - __main__ - train loss is 13.293464936781675\n",
      "Steps:  23%|▍ | 3481/15000 [22:04<34:10,  5.62it/s, lr=9.92e-6, step_loss=0.037]07/18/2023 19:25:26 - INFO - __main__ - train loss is 13.738416739273816\n",
      "Steps:  23%|▍ | 3482/15000 [22:04<34:09,  5.62it/s, lr=9.92e-6, step_loss=0.445]07/18/2023 19:25:27 - INFO - __main__ - train loss is 13.752576960716397\n",
      "Steps:  23%|▏| 3483/15000 [22:04<34:09,  5.62it/s, lr=9.92e-6, step_loss=0.0142]07/18/2023 19:25:27 - INFO - __main__ - train loss is 13.851386471185833\n",
      "Steps:  23%|▏| 3484/15000 [22:05<34:08,  5.62it/s, lr=9.92e-6, step_loss=0.0988]07/18/2023 19:25:27 - INFO - __main__ - train loss is 14.1618994907476\n",
      "Steps:  23%|▍ | 3485/15000 [22:05<34:10,  5.62it/s, lr=9.92e-6, step_loss=0.311]07/18/2023 19:25:27 - INFO - __main__ - train loss is 14.30032347002998\n",
      "Steps:  23%|▍ | 3486/15000 [22:05<34:09,  5.62it/s, lr=9.92e-6, step_loss=0.138]07/18/2023 19:25:27 - INFO - __main__ - train loss is 14.605116976890713\n",
      "Steps:  23%|▍ | 3487/15000 [22:05<34:08,  5.62it/s, lr=9.92e-6, step_loss=0.305]07/18/2023 19:25:27 - INFO - __main__ - train loss is 14.620027382392436\n",
      "Steps:  23%|▏| 3488/15000 [22:05<34:07,  5.62it/s, lr=9.92e-6, step_loss=0.0149]07/18/2023 19:25:28 - INFO - __main__ - train loss is 14.630307685118169\n",
      "Steps:  23%|▏| 3489/15000 [22:06<34:08,  5.62it/s, lr=9.92e-6, step_loss=0.0103]07/18/2023 19:25:28 - INFO - __main__ - train loss is 14.86292078671977\n",
      "Steps:  23%|▍ | 3490/15000 [22:06<34:07,  5.62it/s, lr=9.92e-6, step_loss=0.233]07/18/2023 19:25:28 - INFO - __main__ - train loss is 15.128915454726666\n",
      "Steps:  23%|▍ | 3491/15000 [22:06<34:06,  5.62it/s, lr=9.92e-6, step_loss=0.266]07/18/2023 19:25:28 - INFO - __main__ - train loss is 15.131073863711208\n",
      "Steps:  23%|▏| 3492/15000 [22:06<45:35,  4.21it/s, lr=9.92e-6, step_loss=0.0021607/18/2023 19:25:29 - INFO - __main__ - Per validation step average loss is 0.003162677399814129\n",
      "07/18/2023 19:25:29 - INFO - __main__ - Cumulative validation average loss is 0.003162677399814129\n",
      "07/18/2023 19:25:29 - INFO - __main__ - Per validation step average loss is 0.29446685314178467\n",
      "07/18/2023 19:25:29 - INFO - __main__ - Cumulative validation average loss is 0.2976295305415988\n",
      "07/18/2023 19:25:29 - INFO - __main__ - Per validation step average loss is 0.07335248589515686\n",
      "07/18/2023 19:25:29 - INFO - __main__ - Cumulative validation average loss is 0.37098201643675566\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.3350251317024231\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 0.7060071481391788\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.015118863433599472\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 0.7211260115727782\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.38986045122146606\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 1.1109864627942443\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.006028142757713795\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 1.117014605551958\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.027901310473680496\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 1.1449159160256386\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.10278919339179993\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 1.2477051094174385\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Per validation step average loss is 0.4570770859718323\n",
      "07/18/2023 19:25:30 - INFO - __main__ - Cumulative validation average loss is 1.7047821953892708\n",
      "07/18/2023 19:25:31 - INFO - __main__ - Per validation step average loss is 0.42260342836380005\n",
      "07/18/2023 19:25:31 - INFO - __main__ - Cumulative validation average loss is 2.127385623753071\n",
      "07/18/2023 19:25:31 - INFO - __main__ - Per validation step average loss is 0.0030424026772379875\n",
      "07/18/2023 19:25:31 - INFO - __main__ - Cumulative validation average loss is 2.130428026430309\n",
      "07/18/2023 19:25:31 - INFO - __main__ - Average validation loss for Epoch 35 is 0.1775356688691924\n",
      "07/18/2023 19:25:31 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:25:44 - INFO - __main__ - Starting epoch 36\n",
      "07/18/2023 19:25:44 - INFO - __main__ - train loss is 0.2729947566986084\n",
      "Steps:  23%|▏| 3493/15000 [22:22<15:53:45,  4.97s/it, lr=9.92e-6, step_loss=0.2707/18/2023 19:25:45 - INFO - __main__ - train loss is 0.3538762852549553\n",
      "Steps:  23%|▏| 3494/15000 [22:23<11:18:56,  3.54s/it, lr=9.92e-6, step_loss=0.0807/18/2023 19:25:45 - INFO - __main__ - train loss is 0.5782704725861549\n",
      "Steps:  23%|▏| 3495/15000 [22:23<8:06:21,  2.54s/it, lr=9.92e-6, step_loss=0.22407/18/2023 19:25:45 - INFO - __main__ - train loss is 0.6335684880614281\n",
      "Steps:  23%|▏| 3496/15000 [22:23<5:51:30,  1.83s/it, lr=9.92e-6, step_loss=0.05507/18/2023 19:25:45 - INFO - __main__ - train loss is 0.9846385940909386\n",
      "Steps:  23%|▏| 3497/15000 [22:23<4:17:16,  1.34s/it, lr=9.92e-6, step_loss=0.35107/18/2023 19:25:45 - INFO - __main__ - train loss is 1.1136032715439796\n",
      "Steps:  23%|▏| 3498/15000 [22:23<3:11:19,  1.00it/s, lr=9.92e-6, step_loss=0.12907/18/2023 19:25:46 - INFO - __main__ - train loss is 1.7005219236016273\n",
      "Steps:  23%|▏| 3499/15000 [22:23<2:25:11,  1.32it/s, lr=9.92e-6, step_loss=0.58707/18/2023 19:25:46 - INFO - __main__ - train loss is 1.7144702784717083\n",
      "Steps:  23%|▏| 3500/15000 [22:24<1:52:07,  1.71it/s, lr=9.92e-6, step_loss=0.58707/18/2023 19:25:46 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-3500\n",
      "07/18/2023 19:25:46 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:25:46,361] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:25:46,366] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-3500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:25:46,366] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-3500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:25:46,373] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-3500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:25:46,374] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-3500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:25:46,395] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-3500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:25:46,395] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-3500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:25:46,396] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:25:46 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-3500/pytorch_model\n",
      "07/18/2023 19:25:46 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-3500/scheduler.bin\n",
      "07/18/2023 19:25:46 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-3500/random_states_0.pkl\n",
      "07/18/2023 19:25:46 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-3500\n",
      "Steps:  23%|▏| 3500/15000 [22:24<1:52:07,  1.71it/s, lr=9.92e-6, step_loss=0.01307/18/2023 19:25:46 - INFO - __main__ - train loss is 1.9632433764636517\n",
      "Steps:  23%|▏| 3501/15000 [22:24<1:30:44,  2.11it/s, lr=9.92e-6, step_loss=0.24907/18/2023 19:25:46 - INFO - __main__ - train loss is 2.547925006598234\n",
      "Steps:  23%|▏| 3502/15000 [22:24<1:13:43,  2.60it/s, lr=9.92e-6, step_loss=0.58507/18/2023 19:25:46 - INFO - __main__ - train loss is 2.829852681607008\n",
      "Steps:  23%|▏| 3503/15000 [22:24<1:01:48,  3.10it/s, lr=9.92e-6, step_loss=0.28207/18/2023 19:25:47 - INFO - __main__ - train loss is 2.833774461876601\n",
      "Steps:  23%|▏| 3504/15000 [22:24<53:29,  3.58it/s, lr=9.92e-6, step_loss=0.0039207/18/2023 19:25:47 - INFO - __main__ - train loss is 3.0374722625128925\n",
      "Steps:  23%|▍ | 3505/15000 [22:25<47:40,  4.02it/s, lr=9.92e-6, step_loss=0.204]07/18/2023 19:25:47 - INFO - __main__ - train loss is 3.0771870496682823\n",
      "Steps:  23%|▏| 3506/15000 [22:25<43:35,  4.39it/s, lr=9.92e-6, step_loss=0.0397]07/18/2023 19:25:47 - INFO - __main__ - train loss is 3.0828265347518027\n",
      "Steps:  23%|▏| 3507/15000 [22:25<40:46,  4.70it/s, lr=9.92e-6, step_loss=0.0056407/18/2023 19:25:47 - INFO - __main__ - train loss is 3.281154299620539\n",
      "Steps:  23%|▍ | 3508/15000 [22:25<38:48,  4.94it/s, lr=9.92e-6, step_loss=0.198]07/18/2023 19:25:47 - INFO - __main__ - train loss is 3.360738838557154\n",
      "Steps:  23%|▏| 3509/15000 [22:25<37:23,  5.12it/s, lr=9.92e-6, step_loss=0.0796]07/18/2023 19:25:48 - INFO - __main__ - train loss is 3.363366312813014\n",
      "Steps:  23%|▏| 3510/15000 [22:25<36:45,  5.21it/s, lr=9.92e-6, step_loss=0.0026307/18/2023 19:25:48 - INFO - __main__ - train loss is 3.7882602284662426\n",
      "Steps:  23%|▍ | 3511/15000 [22:26<36:03,  5.31it/s, lr=9.92e-6, step_loss=0.425]07/18/2023 19:25:48 - INFO - __main__ - train loss is 3.817226273473352\n",
      "Steps:  23%|▍ | 3512/15000 [22:26<35:33,  5.38it/s, lr=9.92e-6, step_loss=0.029]07/18/2023 19:25:48 - INFO - __main__ - train loss is 3.8216996137052774\n",
      "Steps:  23%|▏| 3513/15000 [22:26<35:10,  5.44it/s, lr=9.92e-6, step_loss=0.0044707/18/2023 19:25:48 - INFO - __main__ - train loss is 4.100073331966996\n",
      "Steps:  23%|▍ | 3514/15000 [22:26<34:53,  5.49it/s, lr=9.92e-6, step_loss=0.278]07/18/2023 19:25:48 - INFO - __main__ - train loss is 4.1065980000421405\n",
      "Steps:  23%|▏| 3515/15000 [22:26<35:02,  5.46it/s, lr=9.92e-6, step_loss=0.0065207/18/2023 19:25:49 - INFO - __main__ - train loss is 4.607981423847377\n",
      "Steps:  23%|▍ | 3516/15000 [22:27<34:53,  5.49it/s, lr=9.92e-6, step_loss=0.501]07/18/2023 19:25:49 - INFO - __main__ - train loss is 4.61021101847291\n",
      "Steps:  23%|▏| 3517/15000 [22:27<34:42,  5.51it/s, lr=9.92e-6, step_loss=0.0022307/18/2023 19:25:49 - INFO - __main__ - train loss is 4.786712799221277\n",
      "Steps:  23%|▍ | 3518/15000 [22:27<34:48,  5.50it/s, lr=9.92e-6, step_loss=0.177]07/18/2023 19:25:49 - INFO - __main__ - train loss is 4.95340246334672\n",
      "Steps:  23%|▍ | 3519/15000 [22:27<34:53,  5.48it/s, lr=9.92e-6, step_loss=0.167]07/18/2023 19:25:49 - INFO - __main__ - train loss is 5.048121225088835\n",
      "Steps:  23%|▏| 3520/15000 [22:27<34:43,  5.51it/s, lr=9.92e-6, step_loss=0.0947]07/18/2023 19:25:50 - INFO - __main__ - train loss is 5.09825449809432\n",
      "Steps:  23%|▏| 3521/15000 [22:27<34:31,  5.54it/s, lr=9.92e-6, step_loss=0.0501]07/18/2023 19:25:50 - INFO - __main__ - train loss is 5.455312009900808\n",
      "Steps:  23%|▍ | 3522/15000 [22:28<34:23,  5.56it/s, lr=9.92e-6, step_loss=0.357]07/18/2023 19:25:50 - INFO - __main__ - train loss is 5.71567290648818\n",
      "Steps:  23%|▋  | 3523/15000 [22:28<34:37,  5.52it/s, lr=9.92e-6, step_loss=0.26]07/18/2023 19:25:50 - INFO - __main__ - train loss is 5.950020503252745\n",
      "Steps:  23%|▍ | 3524/15000 [22:28<34:28,  5.55it/s, lr=9.92e-6, step_loss=0.234]07/18/2023 19:25:50 - INFO - __main__ - train loss is 6.291864018887281\n",
      "Steps:  24%|▍ | 3525/15000 [22:28<34:21,  5.57it/s, lr=9.92e-6, step_loss=0.342]07/18/2023 19:25:50 - INFO - __main__ - train loss is 6.306848986074328\n",
      "Steps:  24%|▍ | 3526/15000 [22:28<34:18,  5.57it/s, lr=9.92e-6, step_loss=0.015]07/18/2023 19:25:51 - INFO - __main__ - train loss is 6.41395422630012\n",
      "Steps:  24%|▍ | 3527/15000 [22:29<34:14,  5.58it/s, lr=9.92e-6, step_loss=0.107]07/18/2023 19:25:51 - INFO - __main__ - train loss is 6.512358760461211\n",
      "Steps:  24%|▏| 3528/15000 [22:29<34:11,  5.59it/s, lr=9.92e-6, step_loss=0.0984]07/18/2023 19:25:51 - INFO - __main__ - train loss is 6.538815895095468\n",
      "Steps:  24%|▏| 3529/15000 [22:29<34:09,  5.60it/s, lr=9.92e-6, step_loss=0.0265]07/18/2023 19:25:51 - INFO - __main__ - train loss is 6.642283411696553\n",
      "Steps:  24%|▍ | 3530/15000 [22:29<34:07,  5.60it/s, lr=9.92e-6, step_loss=0.103]07/18/2023 19:25:51 - INFO - __main__ - train loss is 6.828256817534566\n",
      "Steps:  24%|▍ | 3531/15000 [22:29<34:07,  5.60it/s, lr=9.92e-6, step_loss=0.186]07/18/2023 19:25:52 - INFO - __main__ - train loss is 6.925314607098699\n",
      "Steps:  24%|▏| 3532/15000 [22:29<34:07,  5.60it/s, lr=9.92e-6, step_loss=0.0971]07/18/2023 19:25:52 - INFO - __main__ - train loss is 7.652657927945256\n",
      "Steps:  24%|▍ | 3533/15000 [22:30<34:06,  5.60it/s, lr=9.92e-6, step_loss=0.727]07/18/2023 19:25:52 - INFO - __main__ - train loss is 7.706113548949361\n",
      "Steps:  24%|▏| 3534/15000 [22:30<34:05,  5.61it/s, lr=9.92e-6, step_loss=0.0535]07/18/2023 19:25:52 - INFO - __main__ - train loss is 7.7086168909445405\n",
      "Steps:  24%|▏| 3535/15000 [22:30<34:07,  5.60it/s, lr=9.92e-6, step_loss=0.0025]07/18/2023 19:25:52 - INFO - __main__ - train loss is 7.89138073567301\n",
      "Steps:  24%|▍ | 3536/15000 [22:30<34:06,  5.60it/s, lr=9.92e-6, step_loss=0.183]07/18/2023 19:25:52 - INFO - __main__ - train loss is 8.219378241337836\n",
      "Steps:  24%|▍ | 3537/15000 [22:30<34:07,  5.60it/s, lr=9.92e-6, step_loss=0.328]07/18/2023 19:25:53 - INFO - __main__ - train loss is 8.269714851863682\n",
      "Steps:  24%|▏| 3538/15000 [22:31<34:26,  5.55it/s, lr=9.92e-6, step_loss=0.0503]07/18/2023 19:25:53 - INFO - __main__ - train loss is 8.372244422324002\n",
      "Steps:  24%|▍ | 3539/15000 [22:31<34:21,  5.56it/s, lr=9.91e-6, step_loss=0.103]07/18/2023 19:25:53 - INFO - __main__ - train loss is 8.374994030222297\n",
      "Steps:  24%|▏| 3540/15000 [22:31<34:16,  5.57it/s, lr=9.91e-6, step_loss=0.0027507/18/2023 19:25:53 - INFO - __main__ - train loss is 8.38592372648418\n",
      "Steps:  24%|▏| 3541/15000 [22:31<34:12,  5.58it/s, lr=9.91e-6, step_loss=0.0109]07/18/2023 19:25:53 - INFO - __main__ - train loss is 8.473833104595542\n",
      "Steps:  24%|▏| 3542/15000 [22:31<34:09,  5.59it/s, lr=9.91e-6, step_loss=0.0879]07/18/2023 19:25:54 - INFO - __main__ - train loss is 8.476522215409204\n",
      "Steps:  24%|▏| 3543/15000 [22:31<34:07,  5.60it/s, lr=9.91e-6, step_loss=0.0026907/18/2023 19:25:54 - INFO - __main__ - train loss is 8.730920948786661\n",
      "Steps:  24%|▍ | 3544/15000 [22:32<34:05,  5.60it/s, lr=9.91e-6, step_loss=0.254]07/18/2023 19:25:54 - INFO - __main__ - train loss is 8.784363181097433\n",
      "Steps:  24%|▏| 3545/15000 [22:32<34:04,  5.60it/s, lr=9.91e-6, step_loss=0.0534]07/18/2023 19:25:54 - INFO - __main__ - train loss is 9.516452581388876\n",
      "Steps:  24%|▍ | 3546/15000 [22:32<34:05,  5.60it/s, lr=9.91e-6, step_loss=0.732]07/18/2023 19:25:54 - INFO - __main__ - train loss is 9.719967589480802\n",
      "Steps:  24%|▍ | 3547/15000 [22:32<34:04,  5.60it/s, lr=9.91e-6, step_loss=0.204]07/18/2023 19:25:54 - INFO - __main__ - train loss is 10.012050197226927\n",
      "Steps:  24%|▍ | 3548/15000 [22:32<34:03,  5.61it/s, lr=9.91e-6, step_loss=0.292]07/18/2023 19:25:55 - INFO - __main__ - train loss is 10.306147412164137\n",
      "Steps:  24%|▍ | 3549/15000 [22:32<34:03,  5.60it/s, lr=9.91e-6, step_loss=0.294]07/18/2023 19:25:55 - INFO - __main__ - train loss is 10.31739423214458\n",
      "Steps:  24%|▏| 3550/15000 [22:33<34:02,  5.61it/s, lr=9.91e-6, step_loss=0.0112]07/18/2023 19:25:55 - INFO - __main__ - train loss is 10.330876607215032\n",
      "Steps:  24%|▏| 3551/15000 [22:33<33:59,  5.61it/s, lr=9.91e-6, step_loss=0.0135]07/18/2023 19:25:55 - INFO - __main__ - train loss is 10.372927333926782\n",
      "Steps:  24%|▏| 3552/15000 [22:33<33:59,  5.61it/s, lr=9.91e-6, step_loss=0.0421]07/18/2023 19:25:55 - INFO - __main__ - train loss is 10.43821882805787\n",
      "Steps:  24%|▏| 3553/15000 [22:33<34:00,  5.61it/s, lr=9.91e-6, step_loss=0.0653]07/18/2023 19:25:55 - INFO - __main__ - train loss is 10.564103122567758\n",
      "Steps:  24%|▍ | 3554/15000 [22:33<34:01,  5.61it/s, lr=9.91e-6, step_loss=0.126]07/18/2023 19:25:56 - INFO - __main__ - train loss is 10.94405948719941\n",
      "Steps:  24%|▋  | 3555/15000 [22:34<34:00,  5.61it/s, lr=9.91e-6, step_loss=0.38]07/18/2023 19:25:56 - INFO - __main__ - train loss is 11.192961152410135\n",
      "Steps:  24%|▍ | 3556/15000 [22:34<34:00,  5.61it/s, lr=9.91e-6, step_loss=0.249]07/18/2023 19:25:56 - INFO - __main__ - train loss is 11.194817579351366\n",
      "Steps:  24%|▏| 3557/15000 [22:34<34:00,  5.61it/s, lr=9.91e-6, step_loss=0.0018607/18/2023 19:25:56 - INFO - __main__ - train loss is 11.809958673082292\n",
      "Steps:  24%|▍ | 3558/15000 [22:34<34:00,  5.61it/s, lr=9.91e-6, step_loss=0.615]07/18/2023 19:25:56 - INFO - __main__ - train loss is 11.846209450624883\n",
      "Steps:  24%|▏| 3559/15000 [22:34<34:00,  5.61it/s, lr=9.91e-6, step_loss=0.0363]07/18/2023 19:25:57 - INFO - __main__ - train loss is 12.167953892610967\n",
      "Steps:  24%|▍ | 3560/15000 [22:34<34:01,  5.60it/s, lr=9.91e-6, step_loss=0.322]07/18/2023 19:25:57 - INFO - __main__ - train loss is 12.475668742321432\n",
      "Steps:  24%|▍ | 3561/15000 [22:35<34:01,  5.60it/s, lr=9.91e-6, step_loss=0.308]07/18/2023 19:25:57 - INFO - __main__ - train loss is 12.480222584679723\n",
      "Steps:  24%|▏| 3562/15000 [22:35<34:02,  5.60it/s, lr=9.91e-6, step_loss=0.0045507/18/2023 19:25:57 - INFO - __main__ - train loss is 12.838927330449224\n",
      "Steps:  24%|▍ | 3563/15000 [22:35<34:02,  5.60it/s, lr=9.91e-6, step_loss=0.359]07/18/2023 19:25:57 - INFO - __main__ - train loss is 12.892427587881684\n",
      "Steps:  24%|▏| 3564/15000 [22:35<34:00,  5.60it/s, lr=9.91e-6, step_loss=0.0535]07/18/2023 19:25:57 - INFO - __main__ - train loss is 12.902359534054995\n",
      "Steps:  24%|▏| 3565/15000 [22:35<34:01,  5.60it/s, lr=9.91e-6, step_loss=0.0099307/18/2023 19:25:58 - INFO - __main__ - train loss is 12.957795415073633\n",
      "Steps:  24%|▏| 3566/15000 [22:36<34:20,  5.55it/s, lr=9.91e-6, step_loss=0.0554]07/18/2023 19:25:58 - INFO - __main__ - train loss is 12.979556664824486\n",
      "Steps:  24%|▏| 3567/15000 [22:36<34:15,  5.56it/s, lr=9.91e-6, step_loss=0.0218]07/18/2023 19:25:58 - INFO - __main__ - train loss is 13.048985302448273\n",
      "Steps:  24%|▏| 3568/15000 [22:36<34:24,  5.54it/s, lr=9.91e-6, step_loss=0.0694]07/18/2023 19:25:58 - INFO - __main__ - train loss is 13.269118130207062\n",
      "Steps:  24%|▋  | 3569/15000 [22:36<34:36,  5.50it/s, lr=9.91e-6, step_loss=0.22]07/18/2023 19:25:58 - INFO - __main__ - train loss is 13.278148877434433\n",
      "Steps:  24%|▏| 3570/15000 [22:36<34:52,  5.46it/s, lr=9.91e-6, step_loss=0.0090307/18/2023 19:25:59 - INFO - __main__ - train loss is 13.33647623192519\n",
      "Steps:  24%|▏| 3571/15000 [22:36<34:49,  5.47it/s, lr=9.91e-6, step_loss=0.0583]07/18/2023 19:25:59 - INFO - __main__ - train loss is 13.419801439158618\n",
      "Steps:  24%|▏| 3572/15000 [22:37<34:52,  5.46it/s, lr=9.91e-6, step_loss=0.0833]07/18/2023 19:25:59 - INFO - __main__ - train loss is 13.46111602615565\n",
      "Steps:  24%|▏| 3573/15000 [22:37<34:34,  5.51it/s, lr=9.91e-6, step_loss=0.0413]07/18/2023 19:25:59 - INFO - __main__ - train loss is 13.465933254919946\n",
      "Steps:  24%|▏| 3574/15000 [22:37<34:22,  5.54it/s, lr=9.91e-6, step_loss=0.0048207/18/2023 19:25:59 - INFO - __main__ - train loss is 13.494908439926803\n",
      "Steps:  24%|▍ | 3575/15000 [22:37<34:13,  5.56it/s, lr=9.91e-6, step_loss=0.029]07/18/2023 19:25:59 - INFO - __main__ - train loss is 13.775525378994644\n",
      "Steps:  24%|▍ | 3576/15000 [22:37<34:06,  5.58it/s, lr=9.91e-6, step_loss=0.281]07/18/2023 19:26:00 - INFO - __main__ - train loss is 14.07026560883969\n",
      "Steps:  24%|▍ | 3577/15000 [22:37<34:01,  5.59it/s, lr=9.91e-6, step_loss=0.295]07/18/2023 19:26:00 - INFO - __main__ - train loss is 14.089702502824366\n",
      "Steps:  24%|▏| 3578/15000 [22:38<33:58,  5.60it/s, lr=9.91e-6, step_loss=0.0194]07/18/2023 19:26:00 - INFO - __main__ - train loss is 14.101007710210979\n",
      "Steps:  24%|▏| 3579/15000 [22:38<33:56,  5.61it/s, lr=9.91e-6, step_loss=0.0113]07/18/2023 19:26:00 - INFO - __main__ - train loss is 14.386976431123912\n",
      "Steps:  24%|▍ | 3580/15000 [22:38<33:55,  5.61it/s, lr=9.91e-6, step_loss=0.286]07/18/2023 19:26:00 - INFO - __main__ - train loss is 14.62190420459956\n",
      "Steps:  24%|▍ | 3581/15000 [22:38<33:54,  5.61it/s, lr=9.91e-6, step_loss=0.235]07/18/2023 19:26:01 - INFO - __main__ - train loss is 14.71457317750901\n",
      "Steps:  24%|▏| 3582/15000 [22:38<33:53,  5.61it/s, lr=9.91e-6, step_loss=0.0927]07/18/2023 19:26:01 - INFO - __main__ - train loss is 15.078600379638374\n",
      "Steps:  24%|▍ | 3583/15000 [22:39<33:52,  5.62it/s, lr=9.91e-6, step_loss=0.364]07/18/2023 19:26:01 - INFO - __main__ - train loss is 15.082546688616276\n",
      "Steps:  24%|▏| 3584/15000 [22:39<33:51,  5.62it/s, lr=9.91e-6, step_loss=0.0039507/18/2023 19:26:01 - INFO - __main__ - train loss is 15.090526759624481\n",
      "Steps:  24%|▏| 3585/15000 [22:39<33:53,  5.61it/s, lr=9.91e-6, step_loss=0.0079807/18/2023 19:26:01 - INFO - __main__ - train loss is 15.09939694777131\n",
      "Steps:  24%|▏| 3586/15000 [22:39<34:38,  5.49it/s, lr=9.91e-6, step_loss=0.0088707/18/2023 19:26:01 - INFO - __main__ - train loss is 15.156776759773493\n",
      "Steps:  24%|▏| 3587/15000 [22:39<34:23,  5.53it/s, lr=9.91e-6, step_loss=0.0574]07/18/2023 19:26:02 - INFO - __main__ - train loss is 15.482159439474344\n",
      "Steps:  24%|▍ | 3588/15000 [22:39<34:13,  5.56it/s, lr=9.91e-6, step_loss=0.325]07/18/2023 19:26:02 - INFO - __main__ - train loss is 15.581281837075949\n",
      "Steps:  24%|▏| 3589/15000 [22:40<45:46,  4.16it/s, lr=9.91e-6, step_loss=0.0991]07/18/2023 19:26:03 - INFO - __main__ - Per validation step average loss is 0.14494159817695618\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Cumulative validation average loss is 0.14494159817695618\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Per validation step average loss is 0.3269284665584564\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Cumulative validation average loss is 0.4718700647354126\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Per validation step average loss is 0.05919971317052841\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Cumulative validation average loss is 0.531069777905941\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Per validation step average loss is 0.05632222816348076\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Cumulative validation average loss is 0.5873920060694218\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Per validation step average loss is 0.09564495086669922\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Cumulative validation average loss is 0.683036956936121\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Per validation step average loss is 0.18390142917633057\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Cumulative validation average loss is 0.8669383861124516\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Per validation step average loss is 0.05179950222373009\n",
      "07/18/2023 19:26:03 - INFO - __main__ - Cumulative validation average loss is 0.9187378883361816\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Per validation step average loss is 0.005524854641407728\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Cumulative validation average loss is 0.9242627429775894\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Per validation step average loss is 0.0031558889895677567\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Cumulative validation average loss is 0.9274186319671571\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Per validation step average loss is 0.3815903961658478\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Cumulative validation average loss is 1.309009028133005\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Per validation step average loss is 0.0016849841922521591\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Cumulative validation average loss is 1.310694012325257\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Per validation step average loss is 0.04779106378555298\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Cumulative validation average loss is 1.35848507611081\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Average validation loss for Epoch 36 is 0.11320708967590083\n",
      "07/18/2023 19:26:04 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:26:17 - INFO - __main__ - Starting epoch 37\n",
      "07/18/2023 19:26:18 - INFO - __main__ - train loss is 0.031122438609600067\n",
      "Steps:  24%|▏| 3590/15000 [22:56<15:29:34,  4.89s/it, lr=9.91e-6, step_loss=0.0307/18/2023 19:26:18 - INFO - __main__ - train loss is 0.045273127034306526\n",
      "Steps:  24%|▏| 3591/15000 [22:56<11:01:26,  3.48s/it, lr=9.91e-6, step_loss=0.0107/18/2023 19:26:18 - INFO - __main__ - train loss is 0.33831691928207874\n",
      "Steps:  24%|▏| 3592/15000 [22:56<7:54:09,  2.49s/it, lr=9.91e-6, step_loss=0.29307/18/2023 19:26:18 - INFO - __main__ - train loss is 0.36189715936779976\n",
      "Steps:  24%|▏| 3593/15000 [22:56<5:43:01,  1.80s/it, lr=9.91e-6, step_loss=0.02307/18/2023 19:26:18 - INFO - __main__ - train loss is 0.3644455939065665\n",
      "Steps:  24%|▏| 3594/15000 [22:56<4:10:19,  1.32s/it, lr=9.91e-6, step_loss=0.00207/18/2023 19:26:19 - INFO - __main__ - train loss is 0.40325656230561435\n",
      "Steps:  24%|▏| 3595/15000 [22:57<3:05:21,  1.03it/s, lr=9.91e-6, step_loss=0.03807/18/2023 19:26:19 - INFO - __main__ - train loss is 0.6038935601245612\n",
      "Steps:  24%|▏| 3596/15000 [22:57<2:20:02,  1.36it/s, lr=9.91e-6, step_loss=0.20107/18/2023 19:26:19 - INFO - __main__ - train loss is 0.6066311108879745\n",
      "Steps:  24%|▏| 3597/15000 [22:57<1:48:09,  1.76it/s, lr=9.91e-6, step_loss=0.00207/18/2023 19:26:19 - INFO - __main__ - train loss is 0.6550546283833683\n",
      "Steps:  24%|▏| 3598/15000 [22:57<1:25:51,  2.21it/s, lr=9.91e-6, step_loss=0.04807/18/2023 19:26:19 - INFO - __main__ - train loss is 0.8847457314841449\n",
      "Steps:  24%|▏| 3599/15000 [22:57<1:10:15,  2.70it/s, lr=9.91e-6, step_loss=0.23]07/18/2023 19:26:20 - INFO - __main__ - train loss is 1.7449232484214008\n",
      "Steps:  24%|▋  | 3600/15000 [22:57<59:20,  3.20it/s, lr=9.91e-6, step_loss=0.86]07/18/2023 19:26:20 - INFO - __main__ - train loss is 1.755101345013827\n",
      "Steps:  24%|▏| 3601/15000 [22:58<51:47,  3.67it/s, lr=9.91e-6, step_loss=0.0102]07/18/2023 19:26:20 - INFO - __main__ - train loss is 1.7574319089762866\n",
      "Steps:  24%|▏| 3602/15000 [22:58<46:23,  4.09it/s, lr=9.91e-6, step_loss=0.0023307/18/2023 19:26:20 - INFO - __main__ - train loss is 2.0137026156298816\n",
      "Steps:  24%|▍ | 3603/15000 [22:58<42:39,  4.45it/s, lr=9.91e-6, step_loss=0.256]07/18/2023 19:26:20 - INFO - __main__ - train loss is 2.032587646972388\n",
      "Steps:  24%|▏| 3604/15000 [22:58<40:02,  4.74it/s, lr=9.91e-6, step_loss=0.0189]07/18/2023 19:26:20 - INFO - __main__ - train loss is 2.0995417083613575\n",
      "Steps:  24%|▍ | 3605/15000 [22:58<38:10,  4.97it/s, lr=9.91e-6, step_loss=0.067]07/18/2023 19:26:21 - INFO - __main__ - train loss is 2.1063333838246763\n",
      "Steps:  24%|▏| 3606/15000 [22:58<36:55,  5.14it/s, lr=9.91e-6, step_loss=0.0067907/18/2023 19:26:21 - INFO - __main__ - train loss is 2.170993187930435\n",
      "Steps:  24%|▏| 3607/15000 [22:59<36:03,  5.27it/s, lr=9.91e-6, step_loss=0.0647]07/18/2023 19:26:21 - INFO - __main__ - train loss is 2.2086254521273077\n",
      "Steps:  24%|▏| 3608/15000 [22:59<35:23,  5.36it/s, lr=9.91e-6, step_loss=0.0376]07/18/2023 19:26:21 - INFO - __main__ - train loss is 2.6144537194631994\n",
      "Steps:  24%|▍ | 3609/15000 [22:59<34:59,  5.42it/s, lr=9.91e-6, step_loss=0.406]07/18/2023 19:26:21 - INFO - __main__ - train loss is 2.6289323302917182\n",
      "Steps:  24%|▏| 3610/15000 [22:59<34:39,  5.48it/s, lr=9.91e-6, step_loss=0.0145]07/18/2023 19:26:21 - INFO - __main__ - train loss is 2.775891366880387\n",
      "Steps:  24%|▍ | 3611/15000 [22:59<34:25,  5.51it/s, lr=9.91e-6, step_loss=0.147]07/18/2023 19:26:22 - INFO - __main__ - train loss is 2.7948278705589473\n",
      "Steps:  24%|▏| 3612/15000 [23:00<34:13,  5.55it/s, lr=9.91e-6, step_loss=0.0189]07/18/2023 19:26:22 - INFO - __main__ - train loss is 3.1456237356178463\n",
      "Steps:  24%|▍ | 3613/15000 [23:00<34:05,  5.57it/s, lr=9.91e-6, step_loss=0.351]07/18/2023 19:26:22 - INFO - __main__ - train loss is 3.1614904082380235\n",
      "Steps:  24%|▏| 3614/15000 [23:00<34:01,  5.58it/s, lr=9.91e-6, step_loss=0.0159]07/18/2023 19:26:22 - INFO - __main__ - train loss is 3.1630164480302483\n",
      "Steps:  24%|▏| 3615/15000 [23:00<33:56,  5.59it/s, lr=9.91e-6, step_loss=0.0015307/18/2023 19:26:22 - INFO - __main__ - train loss is 3.408872405299917\n",
      "Steps:  24%|▍ | 3616/15000 [23:00<33:55,  5.59it/s, lr=9.91e-6, step_loss=0.246]07/18/2023 19:26:23 - INFO - __main__ - train loss is 3.420232545817271\n",
      "Steps:  24%|▏| 3617/15000 [23:00<33:54,  5.59it/s, lr=9.91e-6, step_loss=0.0114]07/18/2023 19:26:23 - INFO - __main__ - train loss is 3.426599378930405\n",
      "Steps:  24%|▏| 3618/15000 [23:01<33:53,  5.60it/s, lr=9.91e-6, step_loss=0.0063707/18/2023 19:26:23 - INFO - __main__ - train loss is 3.847344155656174\n",
      "Steps:  24%|▍ | 3619/15000 [23:01<33:53,  5.60it/s, lr=9.91e-6, step_loss=0.421]07/18/2023 19:26:23 - INFO - __main__ - train loss is 3.8532408468890935\n",
      "Steps:  24%|▏| 3620/15000 [23:01<33:50,  5.60it/s, lr=9.91e-6, step_loss=0.0059]07/18/2023 19:26:23 - INFO - __main__ - train loss is 3.86185443890281\n",
      "Steps:  24%|▏| 3621/15000 [23:01<33:50,  5.60it/s, lr=9.91e-6, step_loss=0.0086107/18/2023 19:26:23 - INFO - __main__ - train loss is 3.878321710275486\n",
      "Steps:  24%|▏| 3622/15000 [23:01<33:50,  5.60it/s, lr=9.91e-6, step_loss=0.0165]07/18/2023 19:26:24 - INFO - __main__ - train loss is 3.8894287769217044\n",
      "Steps:  24%|▏| 3623/15000 [23:02<34:01,  5.57it/s, lr=9.91e-6, step_loss=0.0111]07/18/2023 19:26:24 - INFO - __main__ - train loss is 3.8974579873029143\n",
      "Steps:  24%|▏| 3624/15000 [23:02<33:57,  5.58it/s, lr=9.91e-6, step_loss=0.0080307/18/2023 19:26:24 - INFO - __main__ - train loss is 4.228759199613705\n",
      "Steps:  24%|▍ | 3625/15000 [23:02<33:54,  5.59it/s, lr=9.91e-6, step_loss=0.331]07/18/2023 19:26:24 - INFO - __main__ - train loss is 4.232537765521556\n",
      "Steps:  24%|▏| 3626/15000 [23:02<33:52,  5.60it/s, lr=9.91e-6, step_loss=0.0037807/18/2023 19:26:24 - INFO - __main__ - train loss is 4.242800564039499\n",
      "Steps:  24%|▏| 3627/15000 [23:02<33:51,  5.60it/s, lr=9.91e-6, step_loss=0.0103]07/18/2023 19:26:25 - INFO - __main__ - train loss is 4.281180240679532\n",
      "Steps:  24%|▏| 3628/15000 [23:02<33:49,  5.60it/s, lr=9.91e-6, step_loss=0.0384]07/18/2023 19:26:25 - INFO - __main__ - train loss is 4.294625012669712\n",
      "Steps:  24%|▏| 3629/15000 [23:03<33:49,  5.60it/s, lr=9.91e-6, step_loss=0.0134]07/18/2023 19:26:25 - INFO - __main__ - train loss is 4.368139243219048\n",
      "Steps:  24%|▏| 3630/15000 [23:03<33:47,  5.61it/s, lr=9.91e-6, step_loss=0.0735]07/18/2023 19:26:25 - INFO - __main__ - train loss is 4.406530326697975\n",
      "Steps:  24%|▏| 3631/15000 [23:03<33:46,  5.61it/s, lr=9.91e-6, step_loss=0.0384]07/18/2023 19:26:25 - INFO - __main__ - train loss is 4.416329112369567\n",
      "Steps:  24%|▏| 3632/15000 [23:03<33:46,  5.61it/s, lr=9.91e-6, step_loss=0.0098]07/18/2023 19:26:25 - INFO - __main__ - train loss is 4.499888886231929\n",
      "Steps:  24%|▏| 3633/15000 [23:03<33:46,  5.61it/s, lr=9.91e-6, step_loss=0.0836]07/18/2023 19:26:26 - INFO - __main__ - train loss is 4.513690202962607\n",
      "Steps:  24%|▏| 3634/15000 [23:03<33:45,  5.61it/s, lr=9.91e-6, step_loss=0.0138]07/18/2023 19:26:26 - INFO - __main__ - train loss is 4.543719961773604\n",
      "Steps:  24%|▋  | 3635/15000 [23:04<33:44,  5.61it/s, lr=9.91e-6, step_loss=0.03]07/18/2023 19:26:26 - INFO - __main__ - train loss is 4.550161298364401\n",
      "Steps:  24%|▏| 3636/15000 [23:04<33:44,  5.61it/s, lr=9.91e-6, step_loss=0.0064407/18/2023 19:26:26 - INFO - __main__ - train loss is 4.560777274891734\n",
      "Steps:  24%|▏| 3637/15000 [23:04<33:43,  5.62it/s, lr=9.91e-6, step_loss=0.0106]07/18/2023 19:26:26 - INFO - __main__ - train loss is 4.609668066725135\n",
      "Steps:  24%|▏| 3638/15000 [23:04<33:42,  5.62it/s, lr=9.91e-6, step_loss=0.0489]07/18/2023 19:26:26 - INFO - __main__ - train loss is 4.639012986794114\n",
      "Steps:  24%|▏| 3639/15000 [23:04<33:43,  5.61it/s, lr=9.91e-6, step_loss=0.0293]07/18/2023 19:26:27 - INFO - __main__ - train loss is 4.721185082569718\n",
      "Steps:  24%|▏| 3640/15000 [23:05<33:44,  5.61it/s, lr=9.91e-6, step_loss=0.0822]07/18/2023 19:26:27 - INFO - __main__ - train loss is 5.315995508804917\n",
      "Steps:  24%|▍ | 3641/15000 [23:05<33:44,  5.61it/s, lr=9.91e-6, step_loss=0.595]07/18/2023 19:26:27 - INFO - __main__ - train loss is 5.600988859310746\n",
      "Steps:  24%|▍ | 3642/15000 [23:05<33:44,  5.61it/s, lr=9.91e-6, step_loss=0.285]07/18/2023 19:26:27 - INFO - __main__ - train loss is 5.682474764063954\n",
      "Steps:  24%|▏| 3643/15000 [23:05<33:43,  5.61it/s, lr=9.91e-6, step_loss=0.0815]07/18/2023 19:26:27 - INFO - __main__ - train loss is 5.839967431500554\n",
      "Steps:  24%|▍ | 3644/15000 [23:05<33:43,  5.61it/s, lr=9.91e-6, step_loss=0.157]07/18/2023 19:26:28 - INFO - __main__ - train loss is 6.035324664786458\n",
      "Steps:  24%|▍ | 3645/15000 [23:05<33:42,  5.61it/s, lr=9.91e-6, step_loss=0.195]07/18/2023 19:26:28 - INFO - __main__ - train loss is 6.039985134731978\n",
      "Steps:  24%|▏| 3646/15000 [23:06<33:43,  5.61it/s, lr=9.91e-6, step_loss=0.0046607/18/2023 19:26:28 - INFO - __main__ - train loss is 6.339125737082213\n",
      "Steps:  24%|▍ | 3647/15000 [23:06<33:43,  5.61it/s, lr=9.91e-6, step_loss=0.299]07/18/2023 19:26:28 - INFO - __main__ - train loss is 6.3410980987828225\n",
      "Steps:  24%|▏| 3648/15000 [23:06<33:43,  5.61it/s, lr=9.91e-6, step_loss=0.0019707/18/2023 19:26:28 - INFO - __main__ - train loss is 6.55295982840471\n",
      "Steps:  24%|▍ | 3649/15000 [23:06<33:43,  5.61it/s, lr=9.91e-6, step_loss=0.212]07/18/2023 19:26:28 - INFO - __main__ - train loss is 7.13786223414354\n",
      "Steps:  24%|▍ | 3650/15000 [23:06<33:42,  5.61it/s, lr=9.91e-6, step_loss=0.585]07/18/2023 19:26:29 - INFO - __main__ - train loss is 7.191344740567729\n",
      "Steps:  24%|▏| 3651/15000 [23:07<33:42,  5.61it/s, lr=9.91e-6, step_loss=0.0535]07/18/2023 19:26:29 - INFO - __main__ - train loss is 7.352099361596629\n",
      "Steps:  24%|▍ | 3652/15000 [23:07<33:42,  5.61it/s, lr=9.91e-6, step_loss=0.161]07/18/2023 19:26:29 - INFO - __main__ - train loss is 7.354496790096164\n",
      "Steps:  24%|▏| 3653/15000 [23:07<33:42,  5.61it/s, lr=9.91e-6, step_loss=0.0024]07/18/2023 19:26:29 - INFO - __main__ - train loss is 7.360395879484713\n",
      "Steps:  24%|▏| 3654/15000 [23:07<33:42,  5.61it/s, lr=9.91e-6, step_loss=0.0059]07/18/2023 19:26:29 - INFO - __main__ - train loss is 7.407811031676829\n",
      "Steps:  24%|▏| 3655/15000 [23:07<33:42,  5.61it/s, lr=9.91e-6, step_loss=0.0474]07/18/2023 19:26:30 - INFO - __main__ - train loss is 7.447370224632323\n",
      "Steps:  24%|▏| 3656/15000 [23:07<33:41,  5.61it/s, lr=9.91e-6, step_loss=0.0396]07/18/2023 19:26:30 - INFO - __main__ - train loss is 7.542865798808634\n",
      "Steps:  24%|▏| 3657/15000 [23:08<33:41,  5.61it/s, lr=9.91e-6, step_loss=0.0955]07/18/2023 19:26:30 - INFO - __main__ - train loss is 7.58471351955086\n",
      "Steps:  24%|▏| 3658/15000 [23:08<33:40,  5.61it/s, lr=9.91e-6, step_loss=0.0418]07/18/2023 19:26:30 - INFO - __main__ - train loss is 7.605210666544735\n",
      "Steps:  24%|▏| 3659/15000 [23:08<33:40,  5.61it/s, lr=9.91e-6, step_loss=0.0205]07/18/2023 19:26:30 - INFO - __main__ - train loss is 7.6326652923598886\n",
      "Steps:  24%|▏| 3660/15000 [23:08<33:40,  5.61it/s, lr=9.91e-6, step_loss=0.0275]07/18/2023 19:26:30 - INFO - __main__ - train loss is 7.78015282843262\n",
      "Steps:  24%|▍ | 3661/15000 [23:08<33:39,  5.62it/s, lr=9.91e-6, step_loss=0.147]07/18/2023 19:26:31 - INFO - __main__ - train loss is 7.960472107864916\n",
      "Steps:  24%|▋  | 3662/15000 [23:08<33:39,  5.61it/s, lr=9.91e-6, step_loss=0.18]07/18/2023 19:26:31 - INFO - __main__ - train loss is 7.9640747650992125\n",
      "Steps:  24%|▏| 3663/15000 [23:09<33:43,  5.60it/s, lr=9.91e-6, step_loss=0.0036]07/18/2023 19:26:31 - INFO - __main__ - train loss is 8.040400271071121\n",
      "Steps:  24%|▏| 3664/15000 [23:09<33:44,  5.60it/s, lr=9.91e-6, step_loss=0.0763]07/18/2023 19:26:31 - INFO - __main__ - train loss is 8.340565268648788\n",
      "Steps:  24%|▉   | 3665/15000 [23:09<33:43,  5.60it/s, lr=9.91e-6, step_loss=0.3]07/18/2023 19:26:31 - INFO - __main__ - train loss is 8.34290904761292\n",
      "Steps:  24%|▏| 3666/15000 [23:09<33:45,  5.60it/s, lr=9.91e-6, step_loss=0.0023407/18/2023 19:26:31 - INFO - __main__ - train loss is 8.352964990073815\n",
      "Steps:  24%|▏| 3667/15000 [23:09<33:44,  5.60it/s, lr=9.91e-6, step_loss=0.0101]07/18/2023 19:26:32 - INFO - __main__ - train loss is 8.683463387424126\n",
      "Steps:  24%|▋  | 3668/15000 [23:10<33:44,  5.60it/s, lr=9.91e-6, step_loss=0.33]07/18/2023 19:26:32 - INFO - __main__ - train loss is 8.689813375705853\n",
      "Steps:  24%|▏| 3669/15000 [23:10<33:43,  5.60it/s, lr=9.91e-6, step_loss=0.0063507/18/2023 19:26:32 - INFO - __main__ - train loss is 8.706935543799773\n",
      "Steps:  24%|▏| 3670/15000 [23:10<33:41,  5.61it/s, lr=9.91e-6, step_loss=0.0171]07/18/2023 19:26:32 - INFO - __main__ - train loss is 8.776267621899024\n",
      "Steps:  24%|▏| 3671/15000 [23:10<33:40,  5.61it/s, lr=9.91e-6, step_loss=0.0693]07/18/2023 19:26:32 - INFO - __main__ - train loss is 8.837705333018675\n",
      "Steps:  24%|▏| 3672/15000 [23:10<33:39,  5.61it/s, lr=9.91e-6, step_loss=0.0614]07/18/2023 19:26:33 - INFO - __main__ - train loss is 9.016906459117308\n",
      "Steps:  24%|▍ | 3673/15000 [23:10<33:38,  5.61it/s, lr=9.91e-6, step_loss=0.179]07/18/2023 19:26:33 - INFO - __main__ - train loss is 9.05943301715888\n",
      "Steps:  24%|▏| 3674/15000 [23:11<33:37,  5.61it/s, lr=9.91e-6, step_loss=0.0425]07/18/2023 19:26:33 - INFO - __main__ - train loss is 9.175685230875388\n",
      "Steps:  24%|▍ | 3675/15000 [23:11<33:36,  5.62it/s, lr=9.91e-6, step_loss=0.116]07/18/2023 19:26:33 - INFO - __main__ - train loss is 9.187736781546846\n",
      "Steps:  25%|▏| 3676/15000 [23:11<33:36,  5.62it/s, lr=9.91e-6, step_loss=0.0121]07/18/2023 19:26:33 - INFO - __main__ - train loss is 9.352135123917833\n",
      "Steps:  25%|▍ | 3677/15000 [23:11<33:37,  5.61it/s, lr=9.91e-6, step_loss=0.164]07/18/2023 19:26:33 - INFO - __main__ - train loss is 9.673201026627794\n",
      "Steps:  25%|▍ | 3678/15000 [23:11<33:36,  5.61it/s, lr=9.91e-6, step_loss=0.321]07/18/2023 19:26:34 - INFO - __main__ - train loss is 9.675355412531644\n",
      "Steps:  25%|▏| 3679/15000 [23:12<33:35,  5.62it/s, lr=9.91e-6, step_loss=0.0021507/18/2023 19:26:34 - INFO - __main__ - train loss is 10.158163644839078\n",
      "Steps:  25%|▍ | 3680/15000 [23:12<33:35,  5.62it/s, lr=9.91e-6, step_loss=0.483]07/18/2023 19:26:34 - INFO - __main__ - train loss is 10.353756107855588\n",
      "Steps:  25%|▍ | 3681/15000 [23:12<33:33,  5.62it/s, lr=9.91e-6, step_loss=0.196]07/18/2023 19:26:34 - INFO - __main__ - train loss is 10.434789315331727\n",
      "Steps:  25%|▍ | 3682/15000 [23:12<33:33,  5.62it/s, lr=9.91e-6, step_loss=0.081]07/18/2023 19:26:34 - INFO - __main__ - train loss is 10.692793146241456\n",
      "Steps:  25%|▍ | 3683/15000 [23:12<33:35,  5.62it/s, lr=9.91e-6, step_loss=0.258]07/18/2023 19:26:35 - INFO - __main__ - train loss is 10.7375521925278\n",
      "Steps:  25%|▏| 3684/15000 [23:12<33:37,  5.61it/s, lr=9.91e-6, step_loss=0.0448]07/18/2023 19:26:35 - INFO - __main__ - train loss is 10.749230219516903\n",
      "Steps:  25%|▏| 3685/15000 [23:13<33:37,  5.61it/s, lr=9.91e-6, step_loss=0.0117]07/18/2023 19:26:35 - INFO - __main__ - train loss is 10.830372697208077\n",
      "Steps:  25%|▏| 3686/15000 [23:13<44:06,  4.28it/s, lr=9.91e-6, step_loss=0.0811]07/18/2023 19:26:36 - INFO - __main__ - Per validation step average loss is 0.15175136923789978\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Cumulative validation average loss is 0.15175136923789978\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Per validation step average loss is 0.11752469837665558\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Cumulative validation average loss is 0.26927606761455536\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Per validation step average loss is 0.11910059303045273\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Cumulative validation average loss is 0.3883766606450081\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Per validation step average loss is 0.37069445848464966\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Cumulative validation average loss is 0.7590711191296577\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Per validation step average loss is 0.43942445516586304\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Cumulative validation average loss is 1.1984955742955208\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Per validation step average loss is 0.48680609464645386\n",
      "07/18/2023 19:26:36 - INFO - __main__ - Cumulative validation average loss is 1.6853016689419746\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Per validation step average loss is 0.05005057901144028\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Cumulative validation average loss is 1.735352247953415\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Per validation step average loss is 0.028674615547060966\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Cumulative validation average loss is 1.7640268635004759\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Per validation step average loss is 0.02250024490058422\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Cumulative validation average loss is 1.78652710840106\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Per validation step average loss is 0.12750229239463806\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Cumulative validation average loss is 1.9140294007956982\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Per validation step average loss is 0.09054214507341385\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Cumulative validation average loss is 2.004571545869112\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Per validation step average loss is 0.029624931514263153\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Cumulative validation average loss is 2.034196477383375\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Average validation loss for Epoch 37 is 0.16951637311528125\n",
      "07/18/2023 19:26:37 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:26:50 - INFO - __main__ - Starting epoch 38\n",
      "07/18/2023 19:26:51 - INFO - __main__ - train loss is 0.04276594519615173\n",
      "Steps:  25%|▏| 3687/15000 [23:29<15:21:15,  4.89s/it, lr=9.91e-6, step_loss=0.0407/18/2023 19:26:51 - INFO - __main__ - train loss is 0.06113685108721256\n",
      "Steps:  25%|▏| 3688/15000 [23:29<10:55:13,  3.48s/it, lr=9.91e-6, step_loss=0.0107/18/2023 19:26:51 - INFO - __main__ - train loss is 0.06778650637716055\n",
      "Steps:  25%|▏| 3689/15000 [23:29<7:49:48,  2.49s/it, lr=9.91e-6, step_loss=0.00607/18/2023 19:26:51 - INFO - __main__ - train loss is 0.08145312033593655\n",
      "Steps:  25%|▏| 3690/15000 [23:29<5:40:24,  1.81s/it, lr=9.91e-6, step_loss=0.01307/18/2023 19:26:52 - INFO - __main__ - train loss is 0.178183039650321\n",
      "Steps:  25%|▏| 3691/15000 [23:29<4:09:53,  1.33s/it, lr=9.91e-6, step_loss=0.09607/18/2023 19:26:52 - INFO - __main__ - train loss is 0.6315810587257147\n",
      "Steps:  25%|▏| 3692/15000 [23:30<3:06:00,  1.01it/s, lr=9.91e-6, step_loss=0.45307/18/2023 19:26:52 - INFO - __main__ - train loss is 0.6384652219712734\n",
      "Steps:  25%|▏| 3693/15000 [23:30<2:20:47,  1.34it/s, lr=9.91e-6, step_loss=0.00607/18/2023 19:26:52 - INFO - __main__ - train loss is 1.183347161859274\n",
      "Steps:  25%|▏| 3694/15000 [23:30<1:48:59,  1.73it/s, lr=9.91e-6, step_loss=0.54507/18/2023 19:26:52 - INFO - __main__ - train loss is 1.212482638657093\n",
      "Steps:  25%|▏| 3695/15000 [23:30<1:26:20,  2.18it/s, lr=9.91e-6, step_loss=0.02907/18/2023 19:26:53 - INFO - __main__ - train loss is 1.525801844894886\n",
      "Steps:  25%|▏| 3696/15000 [23:30<1:10:43,  2.66it/s, lr=9.91e-6, step_loss=0.31307/18/2023 19:26:53 - INFO - __main__ - train loss is 1.654935397207737\n",
      "Steps:  25%|▍ | 3697/15000 [23:31<59:35,  3.16it/s, lr=9.91e-6, step_loss=0.129]07/18/2023 19:26:53 - INFO - __main__ - train loss is 2.2568265572190285\n",
      "Steps:  25%|▍ | 3698/15000 [23:31<51:47,  3.64it/s, lr=9.91e-6, step_loss=0.602]07/18/2023 19:26:53 - INFO - __main__ - train loss is 2.2737778536975384\n",
      "Steps:  25%|▍ | 3699/15000 [23:31<46:19,  4.07it/s, lr=9.91e-6, step_loss=0.017]07/18/2023 19:26:53 - INFO - __main__ - train loss is 3.2031422965228558\n",
      "Steps:  25%|▍ | 3700/15000 [23:31<42:29,  4.43it/s, lr=9.91e-6, step_loss=0.929]07/18/2023 19:26:53 - INFO - __main__ - train loss is 3.2048243650933728\n",
      "Steps:  25%|▏| 3701/15000 [23:31<40:04,  4.70it/s, lr=9.91e-6, step_loss=0.0016807/18/2023 19:26:54 - INFO - __main__ - train loss is 3.2439001569291577\n",
      "Steps:  25%|▏| 3702/15000 [23:31<38:05,  4.94it/s, lr=9.91e-6, step_loss=0.0391]07/18/2023 19:26:54 - INFO - __main__ - train loss is 3.4361727902432904\n",
      "Steps:  25%|▍ | 3703/15000 [23:32<37:00,  5.09it/s, lr=9.91e-6, step_loss=0.192]07/18/2023 19:26:54 - INFO - __main__ - train loss is 3.9146722027799115\n",
      "Steps:  25%|▍ | 3704/15000 [23:32<36:18,  5.18it/s, lr=9.91e-6, step_loss=0.478]07/18/2023 19:26:54 - INFO - __main__ - train loss is 4.685367412283085\n",
      "Steps:  25%|▍ | 3705/15000 [23:32<36:09,  5.21it/s, lr=9.91e-6, step_loss=0.771]07/18/2023 19:26:54 - INFO - __main__ - train loss is 4.8296021887799725\n",
      "Steps:  25%|▍ | 3706/15000 [23:32<35:28,  5.31it/s, lr=9.91e-6, step_loss=0.144]07/18/2023 19:26:55 - INFO - __main__ - train loss is 4.834417106467299\n",
      "Steps:  25%|▏| 3707/15000 [23:32<35:07,  5.36it/s, lr=9.91e-6, step_loss=0.0048107/18/2023 19:26:55 - INFO - __main__ - train loss is 5.022010715561919\n",
      "Steps:  25%|▍ | 3708/15000 [23:33<34:59,  5.38it/s, lr=9.91e-6, step_loss=0.188]07/18/2023 19:26:55 - INFO - __main__ - train loss is 5.024499183404259\n",
      "Steps:  25%|▏| 3709/15000 [23:33<34:39,  5.43it/s, lr=9.91e-6, step_loss=0.0024907/18/2023 19:26:55 - INFO - __main__ - train loss is 5.171206092345528\n",
      "Steps:  25%|▍ | 3710/15000 [23:33<34:39,  5.43it/s, lr=9.91e-6, step_loss=0.147]07/18/2023 19:26:55 - INFO - __main__ - train loss is 5.354061400401406\n",
      "Steps:  25%|▍ | 3711/15000 [23:33<34:28,  5.46it/s, lr=9.91e-6, step_loss=0.183]07/18/2023 19:26:55 - INFO - __main__ - train loss is 5.420315271127038\n",
      "Steps:  25%|▏| 3712/15000 [23:33<34:11,  5.50it/s, lr=9.91e-6, step_loss=0.0663]07/18/2023 19:26:56 - INFO - __main__ - train loss is 5.437228394555859\n",
      "Steps:  25%|▏| 3713/15000 [23:33<34:21,  5.48it/s, lr=9.91e-6, step_loss=0.0169]07/18/2023 19:26:56 - INFO - __main__ - train loss is 5.4414667839882895\n",
      "Steps:  25%|▏| 3714/15000 [23:34<34:12,  5.50it/s, lr=9.91e-6, step_loss=0.0042407/18/2023 19:26:56 - INFO - __main__ - train loss is 5.480962941306643\n",
      "Steps:  25%|▏| 3715/15000 [23:34<34:13,  5.50it/s, lr=9.91e-6, step_loss=0.0395]07/18/2023 19:26:56 - INFO - __main__ - train loss is 5.496362013625912\n",
      "Steps:  25%|▏| 3716/15000 [23:34<34:09,  5.51it/s, lr=9.91e-6, step_loss=0.0154]07/18/2023 19:26:56 - INFO - __main__ - train loss is 5.801361931371503\n",
      "Steps:  25%|▍ | 3717/15000 [23:34<33:58,  5.53it/s, lr=9.91e-6, step_loss=0.305]07/18/2023 19:26:57 - INFO - __main__ - train loss is 6.008198661613278\n",
      "Steps:  25%|▍ | 3718/15000 [23:34<34:08,  5.51it/s, lr=9.91e-6, step_loss=0.207]07/18/2023 19:26:57 - INFO - __main__ - train loss is 6.25588421325665\n",
      "Steps:  25%|▍ | 3719/15000 [23:35<34:02,  5.52it/s, lr=9.91e-6, step_loss=0.248]07/18/2023 19:26:57 - INFO - __main__ - train loss is 6.310237327474169\n",
      "Steps:  25%|▏| 3720/15000 [23:35<34:02,  5.52it/s, lr=9.91e-6, step_loss=0.0544]07/18/2023 19:26:57 - INFO - __main__ - train loss is 6.568026820081286\n",
      "Steps:  25%|▍ | 3721/15000 [23:35<34:00,  5.53it/s, lr=9.91e-6, step_loss=0.258]07/18/2023 19:26:57 - INFO - __main__ - train loss is 6.7212232443271205\n",
      "Steps:  25%|▍ | 3722/15000 [23:35<33:59,  5.53it/s, lr=9.91e-6, step_loss=0.153]07/18/2023 19:26:57 - INFO - __main__ - train loss is 6.735487338970415\n",
      "Steps:  25%|▏| 3723/15000 [23:35<33:58,  5.53it/s, lr=9.91e-6, step_loss=0.0143]07/18/2023 19:26:58 - INFO - __main__ - train loss is 6.750279587577097\n",
      "Steps:  25%|▏| 3724/15000 [23:35<33:57,  5.53it/s, lr=9.91e-6, step_loss=0.0148]07/18/2023 19:26:58 - INFO - __main__ - train loss is 6.778110423008911\n",
      "Steps:  25%|▏| 3725/15000 [23:36<33:57,  5.53it/s, lr=9.91e-6, step_loss=0.0278]07/18/2023 19:26:58 - INFO - __main__ - train loss is 6.779879900976084\n",
      "Steps:  25%|▏| 3726/15000 [23:36<33:57,  5.53it/s, lr=9.91e-6, step_loss=0.0017707/18/2023 19:26:58 - INFO - __main__ - train loss is 7.251302752061747\n",
      "Steps:  25%|▍ | 3727/15000 [23:36<33:57,  5.53it/s, lr=9.91e-6, step_loss=0.471]07/18/2023 19:26:58 - INFO - __main__ - train loss is 7.271675884141587\n",
      "Steps:  25%|▏| 3728/15000 [23:36<34:17,  5.48it/s, lr=9.91e-6, step_loss=0.0204]07/18/2023 19:26:59 - INFO - __main__ - train loss is 7.276060148491524\n",
      "Steps:  25%|▏| 3729/15000 [23:36<34:08,  5.50it/s, lr=9.91e-6, step_loss=0.0043807/18/2023 19:26:59 - INFO - __main__ - train loss is 7.320449593826197\n",
      "Steps:  25%|▏| 3730/15000 [23:37<33:56,  5.53it/s, lr=9.91e-6, step_loss=0.0444]07/18/2023 19:26:59 - INFO - __main__ - train loss is 7.364325936301611\n",
      "Steps:  25%|▏| 3731/15000 [23:37<33:49,  5.55it/s, lr=9.91e-6, step_loss=0.0439]07/18/2023 19:26:59 - INFO - __main__ - train loss is 7.6917143719037995\n",
      "Steps:  25%|▍ | 3732/15000 [23:37<33:43,  5.57it/s, lr=9.91e-6, step_loss=0.327]07/18/2023 19:26:59 - INFO - __main__ - train loss is 7.713053997023962\n",
      "Steps:  25%|▏| 3733/15000 [23:37<33:39,  5.58it/s, lr=9.91e-6, step_loss=0.0213]07/18/2023 19:26:59 - INFO - __main__ - train loss is 7.718463144614361\n",
      "Steps:  25%|▏| 3734/15000 [23:37<33:37,  5.58it/s, lr=9.91e-6, step_loss=0.0054107/18/2023 19:27:00 - INFO - __main__ - train loss is 7.7947370851179585\n",
      "Steps:  25%|▏| 3735/15000 [23:37<33:47,  5.56it/s, lr=9.91e-6, step_loss=0.0763]07/18/2023 19:27:00 - INFO - __main__ - train loss is 7.880877844407223\n",
      "Steps:  25%|▏| 3736/15000 [23:38<33:43,  5.57it/s, lr=9.91e-6, step_loss=0.0861]07/18/2023 19:27:00 - INFO - __main__ - train loss is 7.952199890627526\n",
      "Steps:  25%|▏| 3737/15000 [23:38<33:39,  5.58it/s, lr=9.91e-6, step_loss=0.0713]07/18/2023 19:27:00 - INFO - __main__ - train loss is 8.353396549238823\n",
      "Steps:  25%|▍ | 3738/15000 [23:38<33:48,  5.55it/s, lr=9.91e-6, step_loss=0.401]07/18/2023 19:27:00 - INFO - __main__ - train loss is 8.622276052250527\n",
      "Steps:  25%|▍ | 3739/15000 [23:38<33:43,  5.57it/s, lr=9.91e-6, step_loss=0.269]07/18/2023 19:27:00 - INFO - __main__ - train loss is 8.628373706131242\n",
      "Steps:  25%|▏| 3740/15000 [23:38<33:58,  5.52it/s, lr=9.91e-6, step_loss=0.0061]07/18/2023 19:27:01 - INFO - __main__ - train loss is 8.677976985811256\n",
      "Steps:  25%|▍ | 3741/15000 [23:39<33:58,  5.52it/s, lr=9.9e-6, step_loss=0.0496]07/18/2023 19:27:01 - INFO - __main__ - train loss is 8.679575212416239\n",
      "Steps:  25%|▍ | 3742/15000 [23:39<33:48,  5.55it/s, lr=9.9e-6, step_loss=0.0016]07/18/2023 19:27:01 - INFO - __main__ - train loss is 8.683532931958325\n",
      "Steps:  25%|▏| 3743/15000 [23:39<33:45,  5.56it/s, lr=9.9e-6, step_loss=0.00396]07/18/2023 19:27:01 - INFO - __main__ - train loss is 8.685745145310648\n",
      "Steps:  25%|▏| 3744/15000 [23:39<33:39,  5.57it/s, lr=9.9e-6, step_loss=0.00221]07/18/2023 19:27:01 - INFO - __main__ - train loss is 8.938681001891382\n",
      "Steps:  25%|▋  | 3745/15000 [23:39<33:39,  5.57it/s, lr=9.9e-6, step_loss=0.253]07/18/2023 19:27:02 - INFO - __main__ - train loss is 8.943293324788101\n",
      "Steps:  25%|▏| 3746/15000 [23:39<33:35,  5.58it/s, lr=9.9e-6, step_loss=0.00461]07/18/2023 19:27:02 - INFO - __main__ - train loss is 8.945101404679008\n",
      "Steps:  25%|▏| 3747/15000 [23:40<33:38,  5.58it/s, lr=9.9e-6, step_loss=0.00181]07/18/2023 19:27:02 - INFO - __main__ - train loss is 9.103969285381027\n",
      "Steps:  25%|▋  | 3748/15000 [23:40<33:34,  5.59it/s, lr=9.9e-6, step_loss=0.159]07/18/2023 19:27:02 - INFO - __main__ - train loss is 9.114244848606177\n",
      "Steps:  25%|▍ | 3749/15000 [23:40<33:30,  5.60it/s, lr=9.9e-6, step_loss=0.0103]07/18/2023 19:27:02 - INFO - __main__ - train loss is 9.132202912238427\n",
      "Steps:  25%|▊  | 3750/15000 [23:40<33:30,  5.60it/s, lr=9.9e-6, step_loss=0.018]07/18/2023 19:27:02 - INFO - __main__ - train loss is 9.157069917884655\n",
      "Steps:  25%|▌ | 3751/15000 [23:40<33:28,  5.60it/s, lr=9.9e-6, step_loss=0.0249]07/18/2023 19:27:03 - INFO - __main__ - train loss is 9.49675783154089\n",
      "Steps:  25%|█   | 3752/15000 [23:41<33:27,  5.60it/s, lr=9.9e-6, step_loss=0.34]07/18/2023 19:27:03 - INFO - __main__ - train loss is 9.572780605521984\n",
      "Steps:  25%|▊  | 3753/15000 [23:41<33:25,  5.61it/s, lr=9.9e-6, step_loss=0.076]07/18/2023 19:27:03 - INFO - __main__ - train loss is 9.607012674328871\n",
      "Steps:  25%|▌ | 3754/15000 [23:41<33:25,  5.61it/s, lr=9.9e-6, step_loss=0.0342]07/18/2023 19:27:03 - INFO - __main__ - train loss is 9.89794389915187\n",
      "Steps:  25%|▊  | 3755/15000 [23:41<33:24,  5.61it/s, lr=9.9e-6, step_loss=0.291]07/18/2023 19:27:03 - INFO - __main__ - train loss is 10.264739588019438\n",
      "Steps:  25%|▊  | 3756/15000 [23:41<33:23,  5.61it/s, lr=9.9e-6, step_loss=0.367]07/18/2023 19:27:04 - INFO - __main__ - train loss is 10.272408077609725\n",
      "Steps:  25%|▎| 3757/15000 [23:41<33:22,  5.61it/s, lr=9.9e-6, step_loss=0.00767]07/18/2023 19:27:04 - INFO - __main__ - train loss is 11.056232521426864\n",
      "Steps:  25%|▊  | 3758/15000 [23:42<33:21,  5.62it/s, lr=9.9e-6, step_loss=0.784]07/18/2023 19:27:04 - INFO - __main__ - train loss is 11.061006665346213\n",
      "Steps:  25%|▎| 3759/15000 [23:42<33:21,  5.62it/s, lr=9.9e-6, step_loss=0.00477]07/18/2023 19:27:04 - INFO - __main__ - train loss is 11.242337286588736\n",
      "Steps:  25%|▊  | 3760/15000 [23:42<33:20,  5.62it/s, lr=9.9e-6, step_loss=0.181]07/18/2023 19:27:04 - INFO - __main__ - train loss is 11.326871842262335\n",
      "Steps:  25%|▌ | 3761/15000 [23:42<33:20,  5.62it/s, lr=9.9e-6, step_loss=0.0845]07/18/2023 19:27:04 - INFO - __main__ - train loss is 11.376328904298134\n",
      "Steps:  25%|▌ | 3762/15000 [23:42<33:22,  5.61it/s, lr=9.9e-6, step_loss=0.0495]07/18/2023 19:27:05 - INFO - __main__ - train loss is 11.39708330493886\n",
      "Steps:  25%|▌ | 3763/15000 [23:42<33:22,  5.61it/s, lr=9.9e-6, step_loss=0.0208]07/18/2023 19:27:05 - INFO - __main__ - train loss is 11.49756003182847\n",
      "Steps:  25%|█▎   | 3764/15000 [23:43<33:21,  5.61it/s, lr=9.9e-6, step_loss=0.1]07/18/2023 19:27:05 - INFO - __main__ - train loss is 11.499808098305948\n",
      "Steps:  25%|▎| 3765/15000 [23:43<33:21,  5.61it/s, lr=9.9e-6, step_loss=0.00225]07/18/2023 19:27:05 - INFO - __main__ - train loss is 11.84762027405668\n",
      "Steps:  25%|▊  | 3766/15000 [23:43<33:21,  5.61it/s, lr=9.9e-6, step_loss=0.348]07/18/2023 19:27:05 - INFO - __main__ - train loss is 11.90832753025461\n",
      "Steps:  25%|▌ | 3767/15000 [23:43<33:21,  5.61it/s, lr=9.9e-6, step_loss=0.0607]07/18/2023 19:27:05 - INFO - __main__ - train loss is 12.136001492966898\n",
      "Steps:  25%|▊  | 3768/15000 [23:43<33:20,  5.62it/s, lr=9.9e-6, step_loss=0.228]07/18/2023 19:27:06 - INFO - __main__ - train loss is 12.139343840652145\n",
      "Steps:  25%|▎| 3769/15000 [23:44<33:19,  5.62it/s, lr=9.9e-6, step_loss=0.00334]07/18/2023 19:27:06 - INFO - __main__ - train loss is 12.229481396847405\n",
      "Steps:  25%|▌ | 3770/15000 [23:44<33:18,  5.62it/s, lr=9.9e-6, step_loss=0.0901]07/18/2023 19:27:06 - INFO - __main__ - train loss is 12.392154929810204\n",
      "Steps:  25%|▊  | 3771/15000 [23:44<33:17,  5.62it/s, lr=9.9e-6, step_loss=0.163]07/18/2023 19:27:06 - INFO - __main__ - train loss is 12.428701815777458\n",
      "Steps:  25%|▌ | 3772/15000 [23:44<33:16,  5.62it/s, lr=9.9e-6, step_loss=0.0365]07/18/2023 19:27:06 - INFO - __main__ - train loss is 12.430930027388968\n",
      "Steps:  25%|▎| 3773/15000 [23:44<33:20,  5.61it/s, lr=9.9e-6, step_loss=0.00223]07/18/2023 19:27:07 - INFO - __main__ - train loss is 12.435865221661516\n",
      "Steps:  25%|▎| 3774/15000 [23:44<33:18,  5.62it/s, lr=9.9e-6, step_loss=0.00494]07/18/2023 19:27:07 - INFO - __main__ - train loss is 12.44557636801619\n",
      "Steps:  25%|▎| 3775/15000 [23:45<33:17,  5.62it/s, lr=9.9e-6, step_loss=0.00971]07/18/2023 19:27:07 - INFO - __main__ - train loss is 12.452191418153234\n",
      "Steps:  25%|▎| 3776/15000 [23:45<33:18,  5.62it/s, lr=9.9e-6, step_loss=0.00662]07/18/2023 19:27:07 - INFO - __main__ - train loss is 12.60540670726914\n",
      "Steps:  25%|▊  | 3777/15000 [23:45<33:16,  5.62it/s, lr=9.9e-6, step_loss=0.153]07/18/2023 19:27:07 - INFO - __main__ - train loss is 12.78692389104981\n",
      "Steps:  25%|▊  | 3778/15000 [23:45<33:16,  5.62it/s, lr=9.9e-6, step_loss=0.182]07/18/2023 19:27:07 - INFO - __main__ - train loss is 12.86035030160565\n",
      "Steps:  25%|▌ | 3779/15000 [23:45<33:14,  5.63it/s, lr=9.9e-6, step_loss=0.0734]07/18/2023 19:27:08 - INFO - __main__ - train loss is 13.32113229308743\n",
      "Steps:  25%|▊  | 3780/15000 [23:45<33:14,  5.62it/s, lr=9.9e-6, step_loss=0.461]07/18/2023 19:27:08 - INFO - __main__ - train loss is 13.429126730305143\n",
      "Steps:  25%|▊  | 3781/15000 [23:46<33:15,  5.62it/s, lr=9.9e-6, step_loss=0.108]07/18/2023 19:27:08 - INFO - __main__ - train loss is 13.438126592081971\n",
      "Steps:  25%|▊  | 3782/15000 [23:46<33:14,  5.62it/s, lr=9.9e-6, step_loss=0.009]07/18/2023 19:27:08 - INFO - __main__ - train loss is 13.550952447694726\n",
      "Steps:  25%|▊  | 3783/15000 [23:46<44:38,  4.19it/s, lr=9.9e-6, step_loss=0.113]07/18/2023 19:27:09 - INFO - __main__ - Per validation step average loss is 0.10277273505926132\n",
      "07/18/2023 19:27:09 - INFO - __main__ - Cumulative validation average loss is 0.10277273505926132\n",
      "07/18/2023 19:27:09 - INFO - __main__ - Per validation step average loss is 0.0022850176319479942\n",
      "07/18/2023 19:27:09 - INFO - __main__ - Cumulative validation average loss is 0.10505775269120932\n",
      "07/18/2023 19:27:09 - INFO - __main__ - Per validation step average loss is 0.15181587636470795\n",
      "07/18/2023 19:27:09 - INFO - __main__ - Cumulative validation average loss is 0.25687362905591726\n",
      "07/18/2023 19:27:09 - INFO - __main__ - Per validation step average loss is 0.1827794313430786\n",
      "07/18/2023 19:27:09 - INFO - __main__ - Cumulative validation average loss is 0.4396530603989959\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Per validation step average loss is 0.32173338532447815\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Cumulative validation average loss is 0.761386445723474\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Per validation step average loss is 0.0016681826673448086\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Cumulative validation average loss is 0.7630546283908188\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Per validation step average loss is 0.030688993632793427\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Cumulative validation average loss is 0.7937436220236123\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Per validation step average loss is 0.9430968165397644\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Cumulative validation average loss is 1.7368404385633767\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Per validation step average loss is 0.006332118064165115\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Cumulative validation average loss is 1.7431725566275418\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Per validation step average loss is 0.013097640126943588\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Cumulative validation average loss is 1.7562701967544854\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Per validation step average loss is 0.008492561057209969\n",
      "07/18/2023 19:27:10 - INFO - __main__ - Cumulative validation average loss is 1.7647627578116953\n",
      "07/18/2023 19:27:11 - INFO - __main__ - Per validation step average loss is 0.008837230503559113\n",
      "07/18/2023 19:27:11 - INFO - __main__ - Cumulative validation average loss is 1.7735999883152544\n",
      "07/18/2023 19:27:11 - INFO - __main__ - Average validation loss for Epoch 38 is 0.1477999990262712\n",
      "07/18/2023 19:27:11 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:27:24 - INFO - __main__ - Starting epoch 39\n",
      "07/18/2023 19:27:24 - INFO - __main__ - train loss is 0.2662271559238434\n",
      "Steps:  25%|▎| 3784/15000 [24:02<15:15:04,  4.90s/it, lr=9.9e-6, step_loss=0.26607/18/2023 19:27:24 - INFO - __main__ - train loss is 0.4506005495786667\n",
      "Steps:  25%|▎| 3785/15000 [24:02<10:50:33,  3.48s/it, lr=9.9e-6, step_loss=0.18407/18/2023 19:27:24 - INFO - __main__ - train loss is 0.4575209319591522\n",
      "Steps:  25%|▎| 3786/15000 [24:02<7:45:26,  2.49s/it, lr=9.9e-6, step_loss=0.006907/18/2023 19:27:25 - INFO - __main__ - train loss is 0.7002621591091156\n",
      "Steps:  25%|▎| 3787/15000 [24:03<5:35:54,  1.80s/it, lr=9.9e-6, step_loss=0.243]07/18/2023 19:27:25 - INFO - __main__ - train loss is 0.7266156375408173\n",
      "Steps:  25%|▎| 3788/15000 [24:03<4:05:12,  1.31s/it, lr=9.9e-6, step_loss=0.026407/18/2023 19:27:25 - INFO - __main__ - train loss is 0.7310276040807366\n",
      "Steps:  25%|▎| 3789/15000 [24:03<3:01:44,  1.03it/s, lr=9.9e-6, step_loss=0.004407/18/2023 19:27:25 - INFO - __main__ - train loss is 0.7458057729527354\n",
      "Steps:  25%|▎| 3790/15000 [24:03<2:17:30,  1.36it/s, lr=9.9e-6, step_loss=0.014807/18/2023 19:27:25 - INFO - __main__ - train loss is 1.0573100475594401\n",
      "Steps:  25%|▎| 3791/15000 [24:03<1:46:21,  1.76it/s, lr=9.9e-6, step_loss=0.312]07/18/2023 19:27:26 - INFO - __main__ - train loss is 1.0711232936009765\n",
      "Steps:  25%|▎| 3792/15000 [24:03<1:24:33,  2.21it/s, lr=9.9e-6, step_loss=0.013807/18/2023 19:27:26 - INFO - __main__ - train loss is 1.285087919794023\n",
      "Steps:  25%|▎| 3793/15000 [24:04<1:09:17,  2.70it/s, lr=9.9e-6, step_loss=0.214]07/18/2023 19:27:26 - INFO - __main__ - train loss is 1.3005570881068707\n",
      "Steps:  25%|▌ | 3794/15000 [24:04<58:36,  3.19it/s, lr=9.9e-6, step_loss=0.0155]07/18/2023 19:27:26 - INFO - __main__ - train loss is 1.5623588375747204\n",
      "Steps:  25%|▊  | 3795/15000 [24:04<51:05,  3.65it/s, lr=9.9e-6, step_loss=0.262]07/18/2023 19:27:26 - INFO - __main__ - train loss is 1.5980288162827492\n",
      "Steps:  25%|▌ | 3796/15000 [24:04<45:51,  4.07it/s, lr=9.9e-6, step_loss=0.0357]07/18/2023 19:27:26 - INFO - __main__ - train loss is 2.117008961737156\n",
      "Steps:  25%|▊  | 3797/15000 [24:04<42:09,  4.43it/s, lr=9.9e-6, step_loss=0.519]07/18/2023 19:27:27 - INFO - __main__ - train loss is 2.1224686121568084\n",
      "Steps:  25%|▎| 3798/15000 [24:05<39:57,  4.67it/s, lr=9.9e-6, step_loss=0.00546]07/18/2023 19:27:27 - INFO - __main__ - train loss is 2.131052704527974\n",
      "Steps:  25%|▎| 3799/15000 [24:05<38:15,  4.88it/s, lr=9.9e-6, step_loss=0.00858]07/18/2023 19:27:27 - INFO - __main__ - train loss is 2.389609219506383\n",
      "Steps:  25%|▊  | 3800/15000 [24:05<37:01,  5.04it/s, lr=9.9e-6, step_loss=0.259]07/18/2023 19:27:27 - INFO - __main__ - train loss is 2.4371802899986506\n",
      "Steps:  25%|▌ | 3801/15000 [24:05<35:58,  5.19it/s, lr=9.9e-6, step_loss=0.0476]07/18/2023 19:27:27 - INFO - __main__ - train loss is 2.452617935836315\n",
      "Steps:  25%|▌ | 3802/15000 [24:05<35:08,  5.31it/s, lr=9.9e-6, step_loss=0.0154]07/18/2023 19:27:28 - INFO - __main__ - train loss is 2.511149398982525\n",
      "Steps:  25%|▌ | 3803/15000 [24:05<34:33,  5.40it/s, lr=9.9e-6, step_loss=0.0585]07/18/2023 19:27:28 - INFO - __main__ - train loss is 2.5170688261277974\n",
      "Steps:  25%|▎| 3804/15000 [24:06<34:09,  5.46it/s, lr=9.9e-6, step_loss=0.00592]07/18/2023 19:27:28 - INFO - __main__ - train loss is 2.5194397438317537\n",
      "Steps:  25%|▎| 3805/15000 [24:06<33:54,  5.50it/s, lr=9.9e-6, step_loss=0.00237]07/18/2023 19:27:28 - INFO - __main__ - train loss is 2.530683573335409\n",
      "Steps:  25%|▌ | 3806/15000 [24:06<34:02,  5.48it/s, lr=9.9e-6, step_loss=0.0112]07/18/2023 19:27:28 - INFO - __main__ - train loss is 2.5358311370946467\n",
      "Steps:  25%|▎| 3807/15000 [24:06<33:53,  5.50it/s, lr=9.9e-6, step_loss=0.00515]07/18/2023 19:27:28 - INFO - __main__ - train loss is 2.5393900480121374\n",
      "Steps:  25%|▎| 3808/15000 [24:06<33:40,  5.54it/s, lr=9.9e-6, step_loss=0.00356]07/18/2023 19:27:29 - INFO - __main__ - train loss is 2.910082032904029\n",
      "Steps:  25%|▊  | 3809/15000 [24:07<33:32,  5.56it/s, lr=9.9e-6, step_loss=0.371]07/18/2023 19:27:29 - INFO - __main__ - train loss is 2.9258340690284967\n",
      "Steps:  25%|▌ | 3810/15000 [24:07<33:25,  5.58it/s, lr=9.9e-6, step_loss=0.0158]07/18/2023 19:27:29 - INFO - __main__ - train loss is 3.126995215192437\n",
      "Steps:  25%|▊  | 3811/15000 [24:07<33:21,  5.59it/s, lr=9.9e-6, step_loss=0.201]07/18/2023 19:27:29 - INFO - __main__ - train loss is 3.4114495012909174\n",
      "Steps:  25%|▊  | 3812/15000 [24:07<33:18,  5.60it/s, lr=9.9e-6, step_loss=0.284]07/18/2023 19:27:29 - INFO - __main__ - train loss is 3.505475575104356\n",
      "Steps:  25%|▊  | 3813/15000 [24:07<33:17,  5.60it/s, lr=9.9e-6, step_loss=0.094]07/18/2023 19:27:30 - INFO - __main__ - train loss is 3.8440602365881205\n",
      "Steps:  25%|▊  | 3814/15000 [24:07<33:15,  5.61it/s, lr=9.9e-6, step_loss=0.339]07/18/2023 19:27:30 - INFO - __main__ - train loss is 3.864720357581973\n",
      "Steps:  25%|▌ | 3815/15000 [24:08<33:15,  5.61it/s, lr=9.9e-6, step_loss=0.0207]07/18/2023 19:27:30 - INFO - __main__ - train loss is 3.8691335883922875\n",
      "Steps:  25%|▎| 3816/15000 [24:08<33:13,  5.61it/s, lr=9.9e-6, step_loss=0.00441]07/18/2023 19:27:30 - INFO - __main__ - train loss is 3.997810420114547\n",
      "Steps:  25%|▊  | 3817/15000 [24:08<33:12,  5.61it/s, lr=9.9e-6, step_loss=0.129]07/18/2023 19:27:30 - INFO - __main__ - train loss is 4.2832319107837975\n",
      "Steps:  25%|▊  | 3818/15000 [24:08<33:10,  5.62it/s, lr=9.9e-6, step_loss=0.285]07/18/2023 19:27:30 - INFO - __main__ - train loss is 4.31308730924502\n",
      "Steps:  25%|▌ | 3819/15000 [24:08<33:09,  5.62it/s, lr=9.9e-6, step_loss=0.0299]07/18/2023 19:27:31 - INFO - __main__ - train loss is 4.335533155594021\n",
      "Steps:  25%|▌ | 3820/15000 [24:08<33:07,  5.62it/s, lr=9.9e-6, step_loss=0.0224]07/18/2023 19:27:31 - INFO - __main__ - train loss is 4.34342523990199\n",
      "Steps:  25%|▎| 3821/15000 [24:09<33:06,  5.63it/s, lr=9.9e-6, step_loss=0.00789]07/18/2023 19:27:31 - INFO - __main__ - train loss is 4.508227612357587\n",
      "Steps:  25%|▊  | 3822/15000 [24:09<33:06,  5.63it/s, lr=9.9e-6, step_loss=0.165]07/18/2023 19:27:31 - INFO - __main__ - train loss is 4.552987467031926\n",
      "Steps:  25%|▌ | 3823/15000 [24:09<33:05,  5.63it/s, lr=9.9e-6, step_loss=0.0448]07/18/2023 19:27:31 - INFO - __main__ - train loss is 4.564668434206396\n",
      "Steps:  25%|▌ | 3824/15000 [24:09<33:05,  5.63it/s, lr=9.9e-6, step_loss=0.0117]07/18/2023 19:27:31 - INFO - __main__ - train loss is 4.5665151013527066\n",
      "Steps:  26%|▎| 3825/15000 [24:09<33:06,  5.63it/s, lr=9.9e-6, step_loss=0.00185]07/18/2023 19:27:32 - INFO - __main__ - train loss is 4.5682883120607585\n",
      "Steps:  26%|▎| 3826/15000 [24:10<33:07,  5.62it/s, lr=9.9e-6, step_loss=0.00177]07/18/2023 19:27:32 - INFO - __main__ - train loss is 4.793250784976408\n",
      "Steps:  26%|▊  | 3827/15000 [24:10<33:23,  5.58it/s, lr=9.9e-6, step_loss=0.225]07/18/2023 19:27:32 - INFO - __main__ - train loss is 5.006982580525801\n",
      "Steps:  26%|▊  | 3828/15000 [24:10<33:19,  5.59it/s, lr=9.9e-6, step_loss=0.214]07/18/2023 19:27:32 - INFO - __main__ - train loss is 5.011901097605005\n",
      "Steps:  26%|▎| 3829/15000 [24:10<33:17,  5.59it/s, lr=9.9e-6, step_loss=0.00492]07/18/2023 19:27:32 - INFO - __main__ - train loss is 5.01748236338608\n",
      "Steps:  26%|▎| 3830/15000 [24:10<33:17,  5.59it/s, lr=9.9e-6, step_loss=0.00558]07/18/2023 19:27:33 - INFO - __main__ - train loss is 5.084345781011507\n",
      "Steps:  26%|▌ | 3831/15000 [24:10<33:16,  5.60it/s, lr=9.9e-6, step_loss=0.0669]07/18/2023 19:27:33 - INFO - __main__ - train loss is 5.180760458810255\n",
      "Steps:  26%|▌ | 3832/15000 [24:11<33:15,  5.60it/s, lr=9.9e-6, step_loss=0.0964]07/18/2023 19:27:33 - INFO - __main__ - train loss is 5.886412218911573\n",
      "Steps:  26%|▊  | 3833/15000 [24:11<33:13,  5.60it/s, lr=9.9e-6, step_loss=0.706]07/18/2023 19:27:33 - INFO - __main__ - train loss is 5.952226192457601\n",
      "Steps:  26%|▌ | 3834/15000 [24:11<33:12,  5.60it/s, lr=9.9e-6, step_loss=0.0658]07/18/2023 19:27:33 - INFO - __main__ - train loss is 5.954771157121286\n",
      "Steps:  26%|▎| 3835/15000 [24:11<33:11,  5.61it/s, lr=9.9e-6, step_loss=0.00254]07/18/2023 19:27:33 - INFO - __main__ - train loss is 5.975113749271259\n",
      "Steps:  26%|▌ | 3836/15000 [24:11<33:11,  5.61it/s, lr=9.9e-6, step_loss=0.0203]07/18/2023 19:27:34 - INFO - __main__ - train loss is 6.116060703760013\n",
      "Steps:  26%|▊  | 3837/15000 [24:11<33:11,  5.60it/s, lr=9.9e-6, step_loss=0.141]07/18/2023 19:27:34 - INFO - __main__ - train loss is 6.1315273323562\n",
      "Steps:  26%|▌ | 3838/15000 [24:12<33:10,  5.61it/s, lr=9.9e-6, step_loss=0.0155]07/18/2023 19:27:34 - INFO - __main__ - train loss is 6.151186914881691\n",
      "Steps:  26%|▌ | 3839/15000 [24:12<33:08,  5.61it/s, lr=9.9e-6, step_loss=0.0197]07/18/2023 19:27:34 - INFO - __main__ - train loss is 6.162638377165422\n",
      "Steps:  26%|▌ | 3840/15000 [24:12<33:08,  5.61it/s, lr=9.9e-6, step_loss=0.0115]07/18/2023 19:27:34 - INFO - __main__ - train loss is 6.322367917513475\n",
      "Steps:  26%|█   | 3841/15000 [24:12<33:09,  5.61it/s, lr=9.9e-6, step_loss=0.16]07/18/2023 19:27:34 - INFO - __main__ - train loss is 6.351524576311931\n",
      "Steps:  26%|▌ | 3842/15000 [24:12<33:09,  5.61it/s, lr=9.9e-6, step_loss=0.0292]07/18/2023 19:27:35 - INFO - __main__ - train loss is 6.369210576405749\n",
      "Steps:  26%|▌ | 3843/15000 [24:13<33:09,  5.61it/s, lr=9.9e-6, step_loss=0.0177]07/18/2023 19:27:35 - INFO - __main__ - train loss is 6.372380513930693\n",
      "Steps:  26%|▎| 3844/15000 [24:13<33:08,  5.61it/s, lr=9.9e-6, step_loss=0.00317]07/18/2023 19:27:35 - INFO - __main__ - train loss is 6.379163216101006\n",
      "Steps:  26%|▎| 3845/15000 [24:13<33:07,  5.61it/s, lr=9.9e-6, step_loss=0.00678]07/18/2023 19:27:35 - INFO - __main__ - train loss is 6.380908785155043\n",
      "Steps:  26%|▎| 3846/15000 [24:13<33:06,  5.61it/s, lr=9.9e-6, step_loss=0.00175]07/18/2023 19:27:35 - INFO - __main__ - train loss is 6.531431538751349\n",
      "Steps:  26%|▊  | 3847/15000 [24:13<33:05,  5.62it/s, lr=9.9e-6, step_loss=0.151]07/18/2023 19:27:36 - INFO - __main__ - train loss is 6.905110699823126\n",
      "Steps:  26%|▊  | 3848/15000 [24:13<33:06,  5.62it/s, lr=9.9e-6, step_loss=0.374]07/18/2023 19:27:36 - INFO - __main__ - train loss is 7.011738894274458\n",
      "Steps:  26%|▊  | 3849/15000 [24:14<33:05,  5.62it/s, lr=9.9e-6, step_loss=0.107]07/18/2023 19:27:36 - INFO - __main__ - train loss is 7.017461899900809\n",
      "Steps:  26%|▎| 3850/15000 [24:14<33:04,  5.62it/s, lr=9.9e-6, step_loss=0.00572]07/18/2023 19:27:36 - INFO - __main__ - train loss is 7.019707961939275\n",
      "Steps:  26%|▎| 3851/15000 [24:14<33:03,  5.62it/s, lr=9.9e-6, step_loss=0.00225]07/18/2023 19:27:36 - INFO - __main__ - train loss is 7.382887079380453\n",
      "Steps:  26%|▊  | 3852/15000 [24:14<33:03,  5.62it/s, lr=9.9e-6, step_loss=0.363]07/18/2023 19:27:36 - INFO - __main__ - train loss is 7.677252157591283\n",
      "Steps:  26%|▊  | 3853/15000 [24:14<33:03,  5.62it/s, lr=9.9e-6, step_loss=0.294]07/18/2023 19:27:37 - INFO - __main__ - train loss is 8.507212265394628\n",
      "Steps:  26%|█   | 3854/15000 [24:15<33:03,  5.62it/s, lr=9.9e-6, step_loss=0.83]07/18/2023 19:27:37 - INFO - __main__ - train loss is 8.898948593996465\n",
      "Steps:  26%|▊  | 3855/15000 [24:15<33:02,  5.62it/s, lr=9.9e-6, step_loss=0.392]07/18/2023 19:27:37 - INFO - __main__ - train loss is 9.034242018125951\n",
      "Steps:  26%|▊  | 3856/15000 [24:15<33:02,  5.62it/s, lr=9.9e-6, step_loss=0.135]07/18/2023 19:27:37 - INFO - __main__ - train loss is 9.037180262617767\n",
      "Steps:  26%|▎| 3857/15000 [24:15<33:14,  5.59it/s, lr=9.9e-6, step_loss=0.00294]07/18/2023 19:27:37 - INFO - __main__ - train loss is 9.054694368503988\n",
      "Steps:  26%|▌ | 3858/15000 [24:15<33:21,  5.57it/s, lr=9.9e-6, step_loss=0.0175]07/18/2023 19:27:38 - INFO - __main__ - train loss is 9.068579862825572\n",
      "Steps:  26%|▌ | 3859/15000 [24:15<33:19,  5.57it/s, lr=9.9e-6, step_loss=0.0139]07/18/2023 19:27:38 - INFO - __main__ - train loss is 9.165286938659847\n",
      "Steps:  26%|▌ | 3860/15000 [24:16<33:14,  5.59it/s, lr=9.9e-6, step_loss=0.0967]07/18/2023 19:27:38 - INFO - __main__ - train loss is 9.175514088012278\n",
      "Steps:  26%|▌ | 3861/15000 [24:16<33:10,  5.60it/s, lr=9.9e-6, step_loss=0.0102]07/18/2023 19:27:38 - INFO - __main__ - train loss is 9.178897850681096\n",
      "Steps:  26%|▎| 3862/15000 [24:16<33:07,  5.60it/s, lr=9.9e-6, step_loss=0.00338]07/18/2023 19:27:38 - INFO - __main__ - train loss is 9.219862312544137\n",
      "Steps:  26%|▊  | 3863/15000 [24:16<33:06,  5.61it/s, lr=9.9e-6, step_loss=0.041]07/18/2023 19:27:38 - INFO - __main__ - train loss is 9.635646611917764\n",
      "Steps:  26%|▊  | 3864/15000 [24:16<33:02,  5.62it/s, lr=9.9e-6, step_loss=0.416]07/18/2023 19:27:39 - INFO - __main__ - train loss is 10.089064270723611\n",
      "Steps:  26%|▊  | 3865/15000 [24:16<33:01,  5.62it/s, lr=9.9e-6, step_loss=0.453]07/18/2023 19:27:39 - INFO - __main__ - train loss is 10.106977643910795\n",
      "Steps:  26%|▌ | 3866/15000 [24:17<32:59,  5.63it/s, lr=9.9e-6, step_loss=0.0179]07/18/2023 19:27:39 - INFO - __main__ - train loss is 10.111342134419829\n",
      "Steps:  26%|▎| 3867/15000 [24:17<32:58,  5.63it/s, lr=9.9e-6, step_loss=0.00436]07/18/2023 19:27:39 - INFO - __main__ - train loss is 10.129974252078682\n",
      "Steps:  26%|▌ | 3868/15000 [24:17<32:57,  5.63it/s, lr=9.9e-6, step_loss=0.0186]07/18/2023 19:27:39 - INFO - __main__ - train loss is 10.350380396936089\n",
      "Steps:  26%|█   | 3869/15000 [24:17<32:57,  5.63it/s, lr=9.9e-6, step_loss=0.22]07/18/2023 19:27:39 - INFO - __main__ - train loss is 10.351988799404353\n",
      "Steps:  26%|▎| 3870/15000 [24:17<32:57,  5.63it/s, lr=9.9e-6, step_loss=0.00161]07/18/2023 19:27:40 - INFO - __main__ - train loss is 10.446537173818797\n",
      "Steps:  26%|▌ | 3871/15000 [24:18<33:00,  5.62it/s, lr=9.9e-6, step_loss=0.0945]07/18/2023 19:27:40 - INFO - __main__ - train loss is 10.466695259790868\n",
      "Steps:  26%|▌ | 3872/15000 [24:18<32:59,  5.62it/s, lr=9.9e-6, step_loss=0.0202]07/18/2023 19:27:40 - INFO - __main__ - train loss is 10.470158644486219\n",
      "Steps:  26%|▎| 3873/15000 [24:18<32:56,  5.63it/s, lr=9.9e-6, step_loss=0.00346]07/18/2023 19:27:40 - INFO - __main__ - train loss is 10.49250707635656\n",
      "Steps:  26%|▌ | 3874/15000 [24:18<32:57,  5.63it/s, lr=9.9e-6, step_loss=0.0223]07/18/2023 19:27:40 - INFO - __main__ - train loss is 10.705116188619286\n",
      "Steps:  26%|▊  | 3875/15000 [24:18<32:56,  5.63it/s, lr=9.9e-6, step_loss=0.213]07/18/2023 19:27:41 - INFO - __main__ - train loss is 10.70685666135978\n",
      "Steps:  26%|▎| 3876/15000 [24:18<32:56,  5.63it/s, lr=9.9e-6, step_loss=0.00174]07/18/2023 19:27:41 - INFO - __main__ - train loss is 10.742350266198628\n",
      "Steps:  26%|▌ | 3877/15000 [24:19<32:56,  5.63it/s, lr=9.9e-6, step_loss=0.0355]07/18/2023 19:27:41 - INFO - __main__ - train loss is 10.958053932408802\n",
      "Steps:  26%|▊  | 3878/15000 [24:19<32:55,  5.63it/s, lr=9.9e-6, step_loss=0.216]07/18/2023 19:27:41 - INFO - __main__ - train loss is 10.981846404145472\n",
      "Steps:  26%|▌ | 3879/15000 [24:19<32:54,  5.63it/s, lr=9.9e-6, step_loss=0.0238]07/18/2023 19:27:41 - INFO - __main__ - train loss is 11.273032856057398\n",
      "Steps:  26%|▊  | 3880/15000 [24:19<44:27,  4.17it/s, lr=9.9e-6, step_loss=0.291]07/18/2023 19:27:42 - INFO - __main__ - Per validation step average loss is 0.03372783213853836\n",
      "07/18/2023 19:27:42 - INFO - __main__ - Cumulative validation average loss is 0.03372783213853836\n",
      "07/18/2023 19:27:42 - INFO - __main__ - Per validation step average loss is 0.19067645072937012\n",
      "07/18/2023 19:27:42 - INFO - __main__ - Cumulative validation average loss is 0.22440428286790848\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.004323628731071949\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 0.22872791159898043\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.007699198089540005\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 0.23642710968852043\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.45704105496406555\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 0.693468164652586\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.12126608192920685\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 0.8147342465817928\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.311958909034729\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 1.1266931556165218\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.009539589285850525\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 1.1362327449023724\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Per validation step average loss is 0.26055485010147095\n",
      "07/18/2023 19:27:43 - INFO - __main__ - Cumulative validation average loss is 1.3967875950038433\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Per validation step average loss is 0.0933828130364418\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Cumulative validation average loss is 1.490170408040285\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Per validation step average loss is 0.012117350473999977\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Cumulative validation average loss is 1.502287758514285\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Per validation step average loss is 0.22059564292430878\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Cumulative validation average loss is 1.7228834014385939\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Average validation loss for Epoch 39 is 0.14357361678654948\n",
      "07/18/2023 19:27:44 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:27:57 - INFO - __main__ - Starting epoch 40\n",
      "07/18/2023 19:27:58 - INFO - __main__ - train loss is 0.002395496005192399\n",
      "Steps:  26%|▎| 3881/15000 [24:36<15:45:02,  5.10s/it, lr=9.9e-6, step_loss=0.00207/18/2023 19:27:58 - INFO - __main__ - train loss is 0.15034754597581923\n",
      "Steps:  26%|▎| 3882/15000 [24:36<11:31:37,  3.73s/it, lr=9.9e-6, step_loss=0.14807/18/2023 19:27:59 - INFO - __main__ - train loss is 0.33151561045087874\n",
      "Steps:  26%|▎| 3883/15000 [24:37<8:34:25,  2.78s/it, lr=9.9e-6, step_loss=0.181]07/18/2023 19:28:00 - INFO - __main__ - train loss is 0.6031246187631041\n",
      "Steps:  26%|▎| 3884/15000 [24:37<6:29:52,  2.10s/it, lr=9.9e-6, step_loss=0.272]07/18/2023 19:28:00 - INFO - __main__ - train loss is 0.6950523408595473\n",
      "Steps:  26%|▎| 3885/15000 [24:38<5:03:04,  1.64s/it, lr=9.9e-6, step_loss=0.091907/18/2023 19:28:01 - INFO - __main__ - train loss is 1.2701698096934706\n",
      "Steps:  26%|▎| 3886/15000 [24:39<4:02:11,  1.31s/it, lr=9.9e-6, step_loss=0.575]07/18/2023 19:28:01 - INFO - __main__ - train loss is 1.2734858028125018\n",
      "Steps:  26%|▎| 3887/15000 [24:39<3:19:35,  1.08s/it, lr=9.9e-6, step_loss=0.003307/18/2023 19:28:02 - INFO - __main__ - train loss is 1.3126910894643515\n",
      "Steps:  26%|▎| 3888/15000 [24:40<2:49:54,  1.09it/s, lr=9.9e-6, step_loss=0.039207/18/2023 19:28:02 - INFO - __main__ - train loss is 1.7904582291375846\n",
      "Steps:  26%|▎| 3889/15000 [24:40<2:29:00,  1.24it/s, lr=9.9e-6, step_loss=0.478]07/18/2023 19:28:03 - INFO - __main__ - train loss is 1.798308691708371\n",
      "Steps:  26%|▎| 3890/15000 [24:41<2:14:20,  1.38it/s, lr=9.9e-6, step_loss=0.007807/18/2023 19:28:03 - INFO - __main__ - train loss is 1.8169310938101262\n",
      "Steps:  26%|▎| 3891/15000 [24:41<2:04:46,  1.48it/s, lr=9.9e-6, step_loss=0.018607/18/2023 19:28:04 - INFO - __main__ - train loss is 1.8396608110051602\n",
      "Steps:  26%|▎| 3892/15000 [24:42<1:57:04,  1.58it/s, lr=9.9e-6, step_loss=0.022707/18/2023 19:28:04 - INFO - __main__ - train loss is 1.8490227095317096\n",
      "Steps:  26%|▎| 3893/15000 [24:42<1:51:40,  1.66it/s, lr=9.9e-6, step_loss=0.009307/18/2023 19:28:05 - INFO - __main__ - train loss is 1.8538294651079923\n",
      "Steps:  26%|▎| 3894/15000 [24:43<1:48:03,  1.71it/s, lr=9.9e-6, step_loss=0.004807/18/2023 19:28:05 - INFO - __main__ - train loss is 2.187702826457098\n",
      "Steps:  26%|▎| 3895/15000 [24:43<1:45:40,  1.75it/s, lr=9.9e-6, step_loss=0.334]07/18/2023 19:28:06 - INFO - __main__ - train loss is 2.315704009728506\n",
      "Steps:  26%|▎| 3896/15000 [24:44<1:43:57,  1.78it/s, lr=9.9e-6, step_loss=0.128]07/18/2023 19:28:07 - INFO - __main__ - train loss is 2.323058539768681\n",
      "Steps:  26%|▎| 3897/15000 [24:44<1:42:22,  1.81it/s, lr=9.9e-6, step_loss=0.007307/18/2023 19:28:07 - INFO - __main__ - train loss is 2.4404368565883487\n",
      "Steps:  26%|▎| 3898/15000 [24:45<1:41:34,  1.82it/s, lr=9.9e-6, step_loss=0.117]07/18/2023 19:28:08 - INFO - __main__ - train loss is 2.4420847084838897\n",
      "Steps:  26%|▎| 3899/15000 [24:46<1:40:59,  1.83it/s, lr=9.9e-6, step_loss=0.001607/18/2023 19:28:08 - INFO - __main__ - train loss is 2.6425859567243606\n",
      "Steps:  26%|▎| 3900/15000 [24:46<1:40:34,  1.84it/s, lr=9.9e-6, step_loss=0.201]07/18/2023 19:28:09 - INFO - __main__ - train loss is 2.814996921690181\n",
      "Steps:  26%|▎| 3901/15000 [24:47<1:40:17,  1.84it/s, lr=9.9e-6, step_loss=0.172]07/18/2023 19:28:09 - INFO - __main__ - train loss is 2.9951607522089034\n",
      "Steps:  26%|▌ | 3902/15000 [24:47<1:40:14,  1.85it/s, lr=9.9e-6, step_loss=0.18]07/18/2023 19:28:10 - INFO - __main__ - train loss is 3.029142615618184\n",
      "Steps:  26%|▎| 3903/15000 [24:48<1:40:31,  1.84it/s, lr=9.9e-6, step_loss=0.034]07/18/2023 19:28:10 - INFO - __main__ - train loss is 3.0361057978589088\n",
      "Steps:  26%|▎| 3904/15000 [24:48<1:40:35,  1.84it/s, lr=9.9e-6, step_loss=0.006907/18/2023 19:28:11 - INFO - __main__ - train loss is 3.154514589579776\n",
      "Steps:  26%|▎| 3905/15000 [24:49<1:40:33,  1.84it/s, lr=9.9e-6, step_loss=0.118]07/18/2023 19:28:11 - INFO - __main__ - train loss is 3.4219952013809234\n",
      "Steps:  26%|▎| 3906/15000 [24:49<1:40:36,  1.84it/s, lr=9.9e-6, step_loss=0.267]07/18/2023 19:28:12 - INFO - __main__ - train loss is 3.961066880496219\n",
      "Steps:  26%|▎| 3907/15000 [24:50<1:41:42,  1.82it/s, lr=9.9e-6, step_loss=0.539]07/18/2023 19:28:13 - INFO - __main__ - train loss is 4.0969598677475005\n",
      "Steps:  26%|▎| 3908/15000 [24:51<1:52:02,  1.65it/s, lr=9.9e-6, step_loss=0.136]07/18/2023 19:28:13 - INFO - __main__ - train loss is 4.27820231881924\n",
      "Steps:  26%|▎| 3909/15000 [24:51<1:50:03,  1.68it/s, lr=9.9e-6, step_loss=0.181]07/18/2023 19:28:14 - INFO - __main__ - train loss is 4.282052787253633\n",
      "Steps:  26%|▎| 3910/15000 [24:52<1:47:02,  1.73it/s, lr=9.9e-6, step_loss=0.003807/18/2023 19:28:14 - INFO - __main__ - train loss is 4.3430297954473644\n",
      "Steps:  26%|▎| 3911/15000 [24:52<1:44:39,  1.77it/s, lr=9.9e-6, step_loss=0.061]07/18/2023 19:28:15 - INFO - __main__ - train loss is 4.350220449035987\n",
      "Steps:  26%|▎| 3912/15000 [24:53<1:43:36,  1.78it/s, lr=9.9e-6, step_loss=0.007107/18/2023 19:28:15 - INFO - __main__ - train loss is 4.440731547540054\n",
      "Steps:  26%|▎| 3913/15000 [24:53<1:42:08,  1.81it/s, lr=9.9e-6, step_loss=0.090507/18/2023 19:28:16 - INFO - __main__ - train loss is 4.47754618502222\n",
      "Steps:  26%|▎| 3914/15000 [24:54<1:41:35,  1.82it/s, lr=9.9e-6, step_loss=0.036807/18/2023 19:28:17 - INFO - __main__ - train loss is 4.49564561038278\n",
      "Steps:  26%|▎| 3915/15000 [24:54<1:41:08,  1.83it/s, lr=9.9e-6, step_loss=0.018107/18/2023 19:28:17 - INFO - __main__ - train loss is 4.521270362427458\n",
      "Steps:  26%|▎| 3916/15000 [24:55<1:40:34,  1.84it/s, lr=9.9e-6, step_loss=0.025607/18/2023 19:28:18 - INFO - __main__ - train loss is 4.549411760410294\n",
      "Steps:  26%|▎| 3917/15000 [24:56<1:40:12,  1.84it/s, lr=9.9e-6, step_loss=0.028107/18/2023 19:28:18 - INFO - __main__ - train loss is 4.602056706091389\n",
      "Steps:  26%|▎| 3918/15000 [24:56<1:40:09,  1.84it/s, lr=9.9e-6, step_loss=0.052607/18/2023 19:28:19 - INFO - __main__ - train loss is 4.6103254582267255\n",
      "Steps:  26%|▎| 3919/15000 [24:57<1:40:25,  1.84it/s, lr=9.9e-6, step_loss=0.008207/18/2023 19:28:19 - INFO - __main__ - train loss is 4.874252023873851\n",
      "Steps:  26%|▎| 3920/15000 [24:57<1:39:55,  1.85it/s, lr=9.9e-6, step_loss=0.264]07/18/2023 19:28:20 - INFO - __main__ - train loss is 4.935664160875604\n",
      "Steps:  26%|▎| 3921/15000 [24:58<1:39:48,  1.85it/s, lr=9.9e-6, step_loss=0.061407/18/2023 19:28:20 - INFO - __main__ - train loss is 5.0456032294314355\n",
      "Steps:  26%|▌ | 3922/15000 [24:58<1:39:51,  1.85it/s, lr=9.9e-6, step_loss=0.11]07/18/2023 19:28:21 - INFO - __main__ - train loss is 5.089334699092433\n",
      "Steps:  26%|▎| 3923/15000 [24:59<1:39:34,  1.85it/s, lr=9.9e-6, step_loss=0.043707/18/2023 19:28:21 - INFO - __main__ - train loss is 5.091182491043583\n",
      "Steps:  26%|▎| 3924/15000 [24:59<1:39:47,  1.85it/s, lr=9.9e-6, step_loss=0.001807/18/2023 19:28:22 - INFO - __main__ - train loss is 5.298312237719074\n",
      "Steps:  26%|▎| 3925/15000 [25:00<1:40:13,  1.84it/s, lr=9.9e-6, step_loss=0.207]07/18/2023 19:28:23 - INFO - __main__ - train loss is 5.49257560656406\n",
      "Steps:  26%|▎| 3926/15000 [25:00<1:40:11,  1.84it/s, lr=9.9e-6, step_loss=0.194]07/18/2023 19:28:23 - INFO - __main__ - train loss is 5.865452310303226\n",
      "Steps:  26%|▎| 3927/15000 [25:01<1:39:43,  1.85it/s, lr=9.9e-6, step_loss=0.373]07/18/2023 19:28:24 - INFO - __main__ - train loss is 5.925135528901592\n",
      "Steps:  26%|▎| 3928/15000 [25:01<1:39:37,  1.85it/s, lr=9.9e-6, step_loss=0.059707/18/2023 19:28:24 - INFO - __main__ - train loss is 6.282568311551586\n",
      "Steps:  26%|▎| 3929/15000 [25:02<1:39:40,  1.85it/s, lr=9.9e-6, step_loss=0.357]07/18/2023 19:28:25 - INFO - __main__ - train loss is 6.371115906396881\n",
      "Steps:  26%|▎| 3930/15000 [25:03<1:39:29,  1.85it/s, lr=9.9e-6, step_loss=0.088507/18/2023 19:28:25 - INFO - __main__ - train loss is 6.375684753758833\n",
      "Steps:  26%|▎| 3931/15000 [25:03<1:39:38,  1.85it/s, lr=9.9e-6, step_loss=0.004507/18/2023 19:28:26 - INFO - __main__ - train loss is 6.386643108678982\n",
      "Steps:  26%|▎| 3932/15000 [25:04<1:39:37,  1.85it/s, lr=9.9e-6, step_loss=0.011]07/18/2023 19:28:26 - INFO - __main__ - train loss is 6.852334853960201\n",
      "Steps:  26%|▎| 3933/15000 [25:04<1:39:31,  1.85it/s, lr=9.89e-6, step_loss=0.46607/18/2023 19:28:27 - INFO - __main__ - train loss is 6.874906823737547\n",
      "Steps:  26%|▎| 3934/15000 [25:05<1:39:05,  1.86it/s, lr=9.89e-6, step_loss=0.02207/18/2023 19:28:27 - INFO - __main__ - train loss is 6.906761486781761\n",
      "Steps:  26%|▎| 3935/15000 [25:05<1:39:18,  1.86it/s, lr=9.89e-6, step_loss=0.03107/18/2023 19:28:28 - INFO - __main__ - train loss is 6.908513154368848\n",
      "Steps:  26%|▎| 3936/15000 [25:06<1:40:44,  1.83it/s, lr=9.89e-6, step_loss=0.00107/18/2023 19:28:29 - INFO - __main__ - train loss is 6.966379075776786\n",
      "Steps:  26%|▎| 3937/15000 [25:06<1:47:58,  1.71it/s, lr=9.89e-6, step_loss=0.05707/18/2023 19:28:29 - INFO - __main__ - train loss is 7.223100661765784\n",
      "Steps:  26%|▎| 3938/15000 [25:07<1:47:21,  1.72it/s, lr=9.89e-6, step_loss=0.25707/18/2023 19:28:30 - INFO - __main__ - train loss is 7.239197752904147\n",
      "Steps:  26%|▎| 3939/15000 [25:08<1:45:56,  1.74it/s, lr=9.89e-6, step_loss=0.01607/18/2023 19:28:30 - INFO - __main__ - train loss is 7.744046471547335\n",
      "Steps:  26%|▎| 3940/15000 [25:08<1:44:03,  1.77it/s, lr=9.89e-6, step_loss=0.50507/18/2023 19:28:31 - INFO - __main__ - train loss is 7.925008348654956\n",
      "Steps:  26%|▎| 3941/15000 [25:09<1:42:06,  1.81it/s, lr=9.89e-6, step_loss=0.18107/18/2023 19:28:31 - INFO - __main__ - train loss is 8.023683599662036\n",
      "Steps:  26%|▎| 3942/15000 [25:09<1:40:52,  1.83it/s, lr=9.89e-6, step_loss=0.09807/18/2023 19:28:32 - INFO - __main__ - train loss is 8.027213532943279\n",
      "Steps:  26%|▎| 3943/15000 [25:10<1:40:29,  1.83it/s, lr=9.89e-6, step_loss=0.00307/18/2023 19:28:32 - INFO - __main__ - train loss is 8.045063838828355\n",
      "Steps:  26%|▎| 3944/15000 [25:10<1:40:02,  1.84it/s, lr=9.89e-6, step_loss=0.01707/18/2023 19:28:33 - INFO - __main__ - train loss is 8.355450943578035\n",
      "Steps:  26%|▎| 3945/15000 [25:11<1:39:40,  1.85it/s, lr=9.89e-6, step_loss=0.31]07/18/2023 19:28:33 - INFO - __main__ - train loss is 8.422140315640718\n",
      "Steps:  26%|▎| 3946/15000 [25:11<1:40:02,  1.84it/s, lr=9.89e-6, step_loss=0.06607/18/2023 19:28:34 - INFO - __main__ - train loss is 8.549526259768754\n",
      "Steps:  26%|▎| 3947/15000 [25:12<1:39:43,  1.85it/s, lr=9.89e-6, step_loss=0.12707/18/2023 19:28:35 - INFO - __main__ - train loss is 8.85306577431038\n",
      "Steps:  26%|▎| 3948/15000 [25:12<1:39:44,  1.85it/s, lr=9.89e-6, step_loss=0.30407/18/2023 19:28:35 - INFO - __main__ - train loss is 8.857153278309852\n",
      "Steps:  26%|▎| 3949/15000 [25:13<1:39:20,  1.85it/s, lr=9.89e-6, step_loss=0.00407/18/2023 19:28:36 - INFO - __main__ - train loss is 9.44901828141883\n",
      "Steps:  26%|▎| 3950/15000 [25:14<1:39:36,  1.85it/s, lr=9.89e-6, step_loss=0.59207/18/2023 19:28:36 - INFO - __main__ - train loss is 9.80226318212226\n",
      "Steps:  26%|▎| 3951/15000 [25:14<1:39:18,  1.85it/s, lr=9.89e-6, step_loss=0.35307/18/2023 19:28:37 - INFO - __main__ - train loss is 10.26264099450782\n",
      "Steps:  26%|▎| 3952/15000 [25:15<1:39:15,  1.86it/s, lr=9.89e-6, step_loss=0.46]07/18/2023 19:28:37 - INFO - __main__ - train loss is 10.420945954043418\n",
      "Steps:  26%|▎| 3953/15000 [25:15<1:39:22,  1.85it/s, lr=9.89e-6, step_loss=0.15807/18/2023 19:28:38 - INFO - __main__ - train loss is 10.838894736487418\n",
      "Steps:  26%|▎| 3954/15000 [25:16<1:39:09,  1.86it/s, lr=9.89e-6, step_loss=0.41807/18/2023 19:28:38 - INFO - __main__ - train loss is 11.65224213572219\n",
      "Steps:  26%|▎| 3955/15000 [25:16<1:39:18,  1.85it/s, lr=9.89e-6, step_loss=0.81307/18/2023 19:28:39 - INFO - __main__ - train loss is 11.742420156020671\n",
      "Steps:  26%|▎| 3956/15000 [25:17<1:39:18,  1.85it/s, lr=9.89e-6, step_loss=0.09007/18/2023 19:28:39 - INFO - __main__ - train loss is 11.748294317163527\n",
      "Steps:  26%|▎| 3957/15000 [25:17<1:39:28,  1.85it/s, lr=9.89e-6, step_loss=0.00507/18/2023 19:28:40 - INFO - __main__ - train loss is 11.80152025539428\n",
      "Steps:  26%|▎| 3958/15000 [25:18<1:39:32,  1.85it/s, lr=9.89e-6, step_loss=0.05307/18/2023 19:28:41 - INFO - __main__ - train loss is 12.218545195646584\n",
      "Steps:  26%|▎| 3959/15000 [25:18<1:39:49,  1.84it/s, lr=9.89e-6, step_loss=0.41707/18/2023 19:28:41 - INFO - __main__ - train loss is 12.220731312409043\n",
      "Steps:  26%|▎| 3960/15000 [25:19<1:39:48,  1.84it/s, lr=9.89e-6, step_loss=0.00207/18/2023 19:28:42 - INFO - __main__ - train loss is 12.29837224073708\n",
      "Steps:  26%|▎| 3961/15000 [25:19<1:39:33,  1.85it/s, lr=9.89e-6, step_loss=0.07707/18/2023 19:28:42 - INFO - __main__ - train loss is 12.302726624533534\n",
      "Steps:  26%|▎| 3962/15000 [25:20<1:39:54,  1.84it/s, lr=9.89e-6, step_loss=0.00407/18/2023 19:28:43 - INFO - __main__ - train loss is 12.49802809767425\n",
      "Steps:  26%|▎| 3963/15000 [25:21<1:39:55,  1.84it/s, lr=9.89e-6, step_loss=0.19507/18/2023 19:28:43 - INFO - __main__ - train loss is 12.502274715341628\n",
      "Steps:  26%|▎| 3964/15000 [25:21<1:41:11,  1.82it/s, lr=9.89e-6, step_loss=0.00407/18/2023 19:28:44 - INFO - __main__ - train loss is 12.518184225074947\n",
      "Steps:  26%|▎| 3965/15000 [25:22<1:41:27,  1.81it/s, lr=9.89e-6, step_loss=0.01507/18/2023 19:28:44 - INFO - __main__ - train loss is 12.519990949193016\n",
      "Steps:  26%|▎| 3966/15000 [25:22<1:40:47,  1.82it/s, lr=9.89e-6, step_loss=0.00107/18/2023 19:28:45 - INFO - __main__ - train loss is 12.599610632518306\n",
      "Steps:  26%|▎| 3967/15000 [25:23<1:41:47,  1.81it/s, lr=9.89e-6, step_loss=0.07907/18/2023 19:28:46 - INFO - __main__ - train loss is 12.833585029700771\n",
      "Steps:  26%|▎| 3968/15000 [25:23<1:46:44,  1.72it/s, lr=9.89e-6, step_loss=0.23407/18/2023 19:28:46 - INFO - __main__ - train loss is 12.944485699990764\n",
      "Steps:  26%|▎| 3969/15000 [25:24<1:48:33,  1.69it/s, lr=9.89e-6, step_loss=0.11107/18/2023 19:28:47 - INFO - __main__ - train loss is 13.007082982221618\n",
      "Steps:  26%|▎| 3970/15000 [25:25<1:45:36,  1.74it/s, lr=9.89e-6, step_loss=0.06207/18/2023 19:28:47 - INFO - __main__ - train loss is 13.120386151829734\n",
      "Steps:  26%|▎| 3971/15000 [25:25<1:43:28,  1.78it/s, lr=9.89e-6, step_loss=0.11307/18/2023 19:28:48 - INFO - __main__ - train loss is 13.173140997299924\n",
      "Steps:  26%|▎| 3972/15000 [25:26<1:42:27,  1.79it/s, lr=9.89e-6, step_loss=0.05207/18/2023 19:28:48 - INFO - __main__ - train loss is 13.17495827539824\n",
      "Steps:  26%|▎| 3973/15000 [25:26<1:41:46,  1.81it/s, lr=9.89e-6, step_loss=0.00107/18/2023 19:28:49 - INFO - __main__ - train loss is 13.461589382728562\n",
      "Steps:  26%|▎| 3974/15000 [25:27<1:41:00,  1.82it/s, lr=9.89e-6, step_loss=0.28707/18/2023 19:28:49 - INFO - __main__ - train loss is 13.48125442280434\n",
      "Steps:  26%|▎| 3975/15000 [25:27<1:40:22,  1.83it/s, lr=9.89e-6, step_loss=0.01907/18/2023 19:28:50 - INFO - __main__ - train loss is 13.59329211129807\n",
      "Steps:  27%|▎| 3976/15000 [25:28<1:40:03,  1.84it/s, lr=9.89e-6, step_loss=0.11207/18/2023 19:28:51 - INFO - __main__ - train loss is 13.976657444378361\n",
      "Steps:  27%|▎| 3977/15000 [25:29<1:54:37,  1.60it/s, lr=9.89e-6, step_loss=0.38307/18/2023 19:28:51 - INFO - __main__ - Per validation step average loss is 0.08409252762794495\n",
      "07/18/2023 19:28:51 - INFO - __main__ - Cumulative validation average loss is 0.08409252762794495\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Per validation step average loss is 0.019149404019117355\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Cumulative validation average loss is 0.1032419316470623\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Per validation step average loss is 0.02985343337059021\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Cumulative validation average loss is 0.1330953650176525\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Per validation step average loss is 0.05149106681346893\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Cumulative validation average loss is 0.18458643183112144\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Per validation step average loss is 0.008761978708207607\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Cumulative validation average loss is 0.19334841053932905\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Per validation step average loss is 0.0017265623901039362\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Cumulative validation average loss is 0.195074972929433\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Per validation step average loss is 0.03423242270946503\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Cumulative validation average loss is 0.22930739563889802\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Per validation step average loss is 0.025040725246071815\n",
      "07/18/2023 19:28:52 - INFO - __main__ - Cumulative validation average loss is 0.25434812088496983\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Per validation step average loss is 0.4132298231124878\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Cumulative validation average loss is 0.6675779439974576\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Per validation step average loss is 0.607597291469574\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Cumulative validation average loss is 1.2751752354670316\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Per validation step average loss is 0.0021138719748705626\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Cumulative validation average loss is 1.2772891074419022\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Per validation step average loss is 0.03249596431851387\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Cumulative validation average loss is 1.309785071760416\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Average validation loss for Epoch 40 is 0.10914875598003466\n",
      "07/18/2023 19:28:53 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:29:06 - INFO - __main__ - Starting epoch 41\n",
      "07/18/2023 19:29:07 - INFO - __main__ - train loss is 0.006527100224047899\n",
      "Steps:  27%|▎| 3978/15000 [25:44<15:50:50,  5.18s/it, lr=9.89e-6, step_loss=0.0007/18/2023 19:29:07 - INFO - __main__ - train loss is 0.11549115600064397\n",
      "Steps:  27%|▎| 3979/15000 [25:45<11:15:18,  3.68s/it, lr=9.89e-6, step_loss=0.1007/18/2023 19:29:07 - INFO - __main__ - train loss is 0.11723494261968881\n",
      "Steps:  27%|▎| 3980/15000 [25:45<8:02:27,  2.63s/it, lr=9.89e-6, step_loss=0.00107/18/2023 19:29:07 - INFO - __main__ - train loss is 0.22894790500868112\n",
      "Steps:  27%|▎| 3981/15000 [25:45<5:47:41,  1.89s/it, lr=9.89e-6, step_loss=0.11207/18/2023 19:29:07 - INFO - __main__ - train loss is 0.2718583840178326\n",
      "Steps:  27%|▎| 3982/15000 [25:45<4:13:12,  1.38s/it, lr=9.89e-6, step_loss=0.04207/18/2023 19:29:07 - INFO - __main__ - train loss is 0.27351128857117146\n",
      "Steps:  27%|▎| 3983/15000 [25:45<3:07:01,  1.02s/it, lr=9.89e-6, step_loss=0.00107/18/2023 19:29:08 - INFO - __main__ - train loss is 0.5465645770309493\n",
      "Steps:  27%|▎| 3984/15000 [25:46<2:20:47,  1.30it/s, lr=9.89e-6, step_loss=0.27307/18/2023 19:29:08 - INFO - __main__ - train loss is 0.6643815691350028\n",
      "Steps:  27%|▎| 3985/15000 [25:46<1:48:18,  1.69it/s, lr=9.89e-6, step_loss=0.11807/18/2023 19:29:08 - INFO - __main__ - train loss is 0.7479336614487693\n",
      "Steps:  27%|▎| 3986/15000 [25:46<1:25:34,  2.15it/s, lr=9.89e-6, step_loss=0.08307/18/2023 19:29:08 - INFO - __main__ - train loss is 0.9910894389031455\n",
      "Steps:  27%|▎| 3987/15000 [25:46<1:09:39,  2.64it/s, lr=9.89e-6, step_loss=0.24307/18/2023 19:29:08 - INFO - __main__ - train loss is 1.0067224035738036\n",
      "Steps:  27%|▎| 3988/15000 [25:46<58:30,  3.14it/s, lr=9.89e-6, step_loss=0.0156]07/18/2023 19:29:09 - INFO - __main__ - train loss is 1.2189839909551665\n",
      "Steps:  27%|▌ | 3989/15000 [25:46<50:43,  3.62it/s, lr=9.89e-6, step_loss=0.212]07/18/2023 19:29:09 - INFO - __main__ - train loss is 1.267667321371846\n",
      "Steps:  27%|▎| 3990/15000 [25:47<45:17,  4.05it/s, lr=9.89e-6, step_loss=0.0487]07/18/2023 19:29:09 - INFO - __main__ - train loss is 1.3581831435440108\n",
      "Steps:  27%|▎| 3991/15000 [25:47<41:26,  4.43it/s, lr=9.89e-6, step_loss=0.0905]07/18/2023 19:29:09 - INFO - __main__ - train loss is 1.4402057657716796\n",
      "Steps:  27%|▌ | 3992/15000 [25:47<38:46,  4.73it/s, lr=9.89e-6, step_loss=0.082]07/18/2023 19:29:09 - INFO - __main__ - train loss is 1.4481292375130579\n",
      "Steps:  27%|▎| 3993/15000 [25:47<36:53,  4.97it/s, lr=9.89e-6, step_loss=0.0079207/18/2023 19:29:09 - INFO - __main__ - train loss is 1.4575794552220032\n",
      "Steps:  27%|▎| 3994/15000 [25:47<35:52,  5.11it/s, lr=9.89e-6, step_loss=0.0094507/18/2023 19:29:10 - INFO - __main__ - train loss is 1.5360455726040527\n",
      "Steps:  27%|▎| 3995/15000 [25:47<35:02,  5.23it/s, lr=9.89e-6, step_loss=0.0785]07/18/2023 19:29:10 - INFO - __main__ - train loss is 1.5545698393834755\n",
      "Steps:  27%|▎| 3996/15000 [25:48<34:19,  5.34it/s, lr=9.89e-6, step_loss=0.0185]07/18/2023 19:29:10 - INFO - __main__ - train loss is 1.5569497189717367\n",
      "Steps:  27%|▎| 3997/15000 [25:48<34:00,  5.39it/s, lr=9.89e-6, step_loss=0.0023807/18/2023 19:29:10 - INFO - __main__ - train loss is 2.195312663097866\n",
      "Steps:  27%|▌ | 3998/15000 [25:48<33:34,  5.46it/s, lr=9.89e-6, step_loss=0.638]07/18/2023 19:29:10 - INFO - __main__ - train loss is 2.2048833064036444\n",
      "Steps:  27%|▎| 3999/15000 [25:48<33:20,  5.50it/s, lr=9.89e-6, step_loss=0.0095707/18/2023 19:29:10 - INFO - __main__ - train loss is 2.322338118334301\n",
      "Steps:  27%|▎| 4000/15000 [25:48<33:05,  5.54it/s, lr=9.89e-6, step_loss=0.0095707/18/2023 19:29:11 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-4000\n",
      "07/18/2023 19:29:11 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:29:11,069] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:29:11,074] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-4000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:29:11,074] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-4000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:29:11,081] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-4000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:29:11,081] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-4000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:29:11,102] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-4000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:29:11,103] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-4000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:29:11,103] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:29:11 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-4000/pytorch_model\n",
      "07/18/2023 19:29:11 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-4000/scheduler.bin\n",
      "07/18/2023 19:29:11 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-4000/random_states_0.pkl\n",
      "07/18/2023 19:29:11 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-4000\n",
      "Steps:  27%|▌ | 4000/15000 [25:48<33:05,  5.54it/s, lr=9.89e-6, step_loss=0.117]07/18/2023 19:29:11 - INFO - __main__ - train loss is 2.5328950128750876\n",
      "Steps:  27%|▌ | 4001/15000 [25:49<34:54,  5.25it/s, lr=9.89e-6, step_loss=0.211]07/18/2023 19:29:11 - INFO - __main__ - train loss is 3.098698242683895\n",
      "Steps:  27%|▌ | 4002/15000 [25:49<34:12,  5.36it/s, lr=9.89e-6, step_loss=0.566]07/18/2023 19:29:11 - INFO - __main__ - train loss is 3.480467154760845\n",
      "Steps:  27%|▌ | 4003/15000 [25:49<33:42,  5.44it/s, lr=9.89e-6, step_loss=0.382]07/18/2023 19:29:11 - INFO - __main__ - train loss is 3.573879315634258\n",
      "Steps:  27%|▎| 4004/15000 [25:49<33:35,  5.46it/s, lr=9.89e-6, step_loss=0.0934]07/18/2023 19:29:11 - INFO - __main__ - train loss is 3.833863868494518\n",
      "Steps:  27%|▊  | 4005/15000 [25:49<33:16,  5.51it/s, lr=9.89e-6, step_loss=0.26]07/18/2023 19:29:12 - INFO - __main__ - train loss is 3.8431736036436632\n",
      "Steps:  27%|▎| 4006/15000 [25:49<33:22,  5.49it/s, lr=9.89e-6, step_loss=0.0093107/18/2023 19:29:12 - INFO - __main__ - train loss is 3.8507703413488343\n",
      "Steps:  27%|▎| 4007/15000 [25:50<33:13,  5.51it/s, lr=9.89e-6, step_loss=0.0076]07/18/2023 19:29:12 - INFO - __main__ - train loss is 4.015869828057475\n",
      "Steps:  27%|▌ | 4008/15000 [25:50<33:20,  5.49it/s, lr=9.89e-6, step_loss=0.165]07/18/2023 19:29:12 - INFO - __main__ - train loss is 4.034574912977405\n",
      "Steps:  27%|▎| 4009/15000 [25:50<33:13,  5.51it/s, lr=9.89e-6, step_loss=0.0187]07/18/2023 19:29:12 - INFO - __main__ - train loss is 4.040839075692929\n",
      "Steps:  27%|▎| 4010/15000 [25:50<33:16,  5.51it/s, lr=9.89e-6, step_loss=0.0062607/18/2023 19:29:12 - INFO - __main__ - train loss is 4.046814756584354\n",
      "Steps:  27%|▎| 4011/15000 [25:50<33:07,  5.53it/s, lr=9.89e-6, step_loss=0.0059807/18/2023 19:29:13 - INFO - __main__ - train loss is 4.332054870319553\n",
      "Steps:  27%|▌ | 4012/15000 [25:51<32:58,  5.55it/s, lr=9.89e-6, step_loss=0.285]07/18/2023 19:29:13 - INFO - __main__ - train loss is 4.34444993652869\n",
      "Steps:  27%|▎| 4013/15000 [25:51<32:52,  5.57it/s, lr=9.89e-6, step_loss=0.0124]07/18/2023 19:29:13 - INFO - __main__ - train loss is 4.3628718733089045\n",
      "Steps:  27%|▎| 4014/15000 [25:51<32:47,  5.58it/s, lr=9.89e-6, step_loss=0.0184]07/18/2023 19:29:13 - INFO - __main__ - train loss is 4.537262457539327\n",
      "Steps:  27%|▌ | 4015/15000 [25:51<32:44,  5.59it/s, lr=9.89e-6, step_loss=0.174]07/18/2023 19:29:13 - INFO - __main__ - train loss is 4.541350525454618\n",
      "Steps:  27%|▎| 4016/15000 [25:51<32:45,  5.59it/s, lr=9.89e-6, step_loss=0.0040907/18/2023 19:29:14 - INFO - __main__ - train loss is 5.153754395083524\n",
      "Steps:  27%|▌ | 4017/15000 [25:51<32:41,  5.60it/s, lr=9.89e-6, step_loss=0.612]07/18/2023 19:29:14 - INFO - __main__ - train loss is 5.651609223918058\n",
      "Steps:  27%|▌ | 4018/15000 [25:52<32:42,  5.60it/s, lr=9.89e-6, step_loss=0.498]07/18/2023 19:29:14 - INFO - __main__ - train loss is 5.671799164847471\n",
      "Steps:  27%|▎| 4019/15000 [25:52<32:40,  5.60it/s, lr=9.89e-6, step_loss=0.0202]07/18/2023 19:29:14 - INFO - __main__ - train loss is 5.7737804694334045\n",
      "Steps:  27%|▌ | 4020/15000 [25:52<32:43,  5.59it/s, lr=9.89e-6, step_loss=0.102]07/18/2023 19:29:14 - INFO - __main__ - train loss is 5.776898641255684\n",
      "Steps:  27%|▎| 4021/15000 [25:52<32:41,  5.60it/s, lr=9.89e-6, step_loss=0.0031207/18/2023 19:29:14 - INFO - __main__ - train loss is 5.81188683595974\n",
      "Steps:  27%|▌ | 4022/15000 [25:52<32:38,  5.60it/s, lr=9.89e-6, step_loss=0.035]07/18/2023 19:29:15 - INFO - __main__ - train loss is 5.919950429466553\n",
      "Steps:  27%|▌ | 4023/15000 [25:53<32:36,  5.61it/s, lr=9.89e-6, step_loss=0.108]07/18/2023 19:29:15 - INFO - __main__ - train loss is 5.927564519573934\n",
      "Steps:  27%|▎| 4024/15000 [25:53<32:34,  5.61it/s, lr=9.89e-6, step_loss=0.0076107/18/2023 19:29:15 - INFO - __main__ - train loss is 6.377080666949041\n",
      "Steps:  27%|▊  | 4025/15000 [25:53<32:33,  5.62it/s, lr=9.89e-6, step_loss=0.45]07/18/2023 19:29:15 - INFO - __main__ - train loss is 6.380205525434576\n",
      "Steps:  27%|▎| 4026/15000 [25:53<32:34,  5.62it/s, lr=9.89e-6, step_loss=0.0031207/18/2023 19:29:15 - INFO - __main__ - train loss is 6.3819523678394035\n",
      "Steps:  27%|▎| 4027/15000 [25:53<32:32,  5.62it/s, lr=9.89e-6, step_loss=0.0017507/18/2023 19:29:16 - INFO - __main__ - train loss is 6.445664100465365\n",
      "Steps:  27%|▎| 4028/15000 [25:53<32:46,  5.58it/s, lr=9.89e-6, step_loss=0.0637]07/18/2023 19:29:16 - INFO - __main__ - train loss is 6.540842428919859\n",
      "Steps:  27%|▎| 4029/15000 [25:54<33:02,  5.53it/s, lr=9.89e-6, step_loss=0.0952]07/18/2023 19:29:16 - INFO - __main__ - train loss is 6.62860412907321\n",
      "Steps:  27%|▎| 4030/15000 [25:54<32:56,  5.55it/s, lr=9.89e-6, step_loss=0.0878]07/18/2023 19:29:16 - INFO - __main__ - train loss is 6.6302688192809\n",
      "Steps:  27%|▎| 4031/15000 [25:54<32:55,  5.55it/s, lr=9.89e-6, step_loss=0.0016607/18/2023 19:29:16 - INFO - __main__ - train loss is 6.853910602279939\n",
      "Steps:  27%|▌ | 4032/15000 [25:54<33:07,  5.52it/s, lr=9.89e-6, step_loss=0.224]07/18/2023 19:29:16 - INFO - __main__ - train loss is 6.877615391858853\n",
      "Steps:  27%|▎| 4033/15000 [25:54<32:58,  5.54it/s, lr=9.89e-6, step_loss=0.0237]07/18/2023 19:29:17 - INFO - __main__ - train loss is 6.882457684376277\n",
      "Steps:  27%|▎| 4034/15000 [25:55<32:51,  5.56it/s, lr=9.89e-6, step_loss=0.0048407/18/2023 19:29:17 - INFO - __main__ - train loss is 7.366364102461375\n",
      "Steps:  27%|▌ | 4035/15000 [25:55<32:48,  5.57it/s, lr=9.89e-6, step_loss=0.484]07/18/2023 19:29:17 - INFO - __main__ - train loss is 7.370870909770019\n",
      "Steps:  27%|▎| 4036/15000 [25:55<32:59,  5.54it/s, lr=9.89e-6, step_loss=0.0045107/18/2023 19:29:17 - INFO - __main__ - train loss is 7.42076122679282\n",
      "Steps:  27%|▎| 4037/15000 [25:55<32:51,  5.56it/s, lr=9.89e-6, step_loss=0.0499]07/18/2023 19:29:17 - INFO - __main__ - train loss is 7.8393120161490515\n",
      "Steps:  27%|▌ | 4038/15000 [25:55<32:47,  5.57it/s, lr=9.89e-6, step_loss=0.419]07/18/2023 19:29:18 - INFO - __main__ - train loss is 8.025482594151981\n",
      "Steps:  27%|▌ | 4039/15000 [25:55<32:43,  5.58it/s, lr=9.89e-6, step_loss=0.186]07/18/2023 19:29:18 - INFO - __main__ - train loss is 8.192203029175289\n",
      "Steps:  27%|▌ | 4040/15000 [25:56<32:52,  5.56it/s, lr=9.89e-6, step_loss=0.167]07/18/2023 19:29:18 - INFO - __main__ - train loss is 8.276672645588405\n",
      "Steps:  27%|▎| 4041/15000 [25:56<33:08,  5.51it/s, lr=9.89e-6, step_loss=0.0845]07/18/2023 19:29:18 - INFO - __main__ - train loss is 8.297422896255739\n",
      "Steps:  27%|▎| 4042/15000 [25:56<33:05,  5.52it/s, lr=9.89e-6, step_loss=0.0208]07/18/2023 19:29:18 - INFO - __main__ - train loss is 8.36250686191488\n",
      "Steps:  27%|▎| 4043/15000 [25:56<33:05,  5.52it/s, lr=9.89e-6, step_loss=0.0651]07/18/2023 19:29:18 - INFO - __main__ - train loss is 8.403600311954506\n",
      "Steps:  27%|▎| 4044/15000 [25:56<33:05,  5.52it/s, lr=9.89e-6, step_loss=0.0411]07/18/2023 19:29:19 - INFO - __main__ - train loss is 8.432167722960003\n",
      "Steps:  27%|▎| 4045/15000 [25:56<33:04,  5.52it/s, lr=9.89e-6, step_loss=0.0286]07/18/2023 19:29:19 - INFO - __main__ - train loss is 8.48619352944661\n",
      "Steps:  27%|▌ | 4046/15000 [25:57<33:04,  5.52it/s, lr=9.89e-6, step_loss=0.054]07/18/2023 19:29:19 - INFO - __main__ - train loss is 8.495419425074942\n",
      "Steps:  27%|▎| 4047/15000 [25:57<33:03,  5.52it/s, lr=9.89e-6, step_loss=0.0092307/18/2023 19:29:19 - INFO - __main__ - train loss is 8.511698472429998\n",
      "Steps:  27%|▎| 4048/15000 [25:57<33:03,  5.52it/s, lr=9.89e-6, step_loss=0.0163]07/18/2023 19:29:19 - INFO - __main__ - train loss is 8.557051307638176\n",
      "Steps:  27%|▎| 4049/15000 [25:57<33:03,  5.52it/s, lr=9.89e-6, step_loss=0.0454]07/18/2023 19:29:20 - INFO - __main__ - train loss is 8.974531478364952\n",
      "Steps:  27%|▌ | 4050/15000 [25:57<33:03,  5.52it/s, lr=9.89e-6, step_loss=0.417]07/18/2023 19:29:20 - INFO - __main__ - train loss is 9.292674548109062\n",
      "Steps:  27%|▌ | 4051/15000 [25:58<33:06,  5.51it/s, lr=9.89e-6, step_loss=0.318]07/18/2023 19:29:20 - INFO - __main__ - train loss is 9.512509144027717\n",
      "Steps:  27%|▊  | 4052/15000 [25:58<33:04,  5.52it/s, lr=9.89e-6, step_loss=0.22]07/18/2023 19:29:20 - INFO - __main__ - train loss is 9.645125172217377\n",
      "Steps:  27%|▌ | 4053/15000 [25:58<33:04,  5.52it/s, lr=9.89e-6, step_loss=0.133]07/18/2023 19:29:20 - INFO - __main__ - train loss is 9.654895495739765\n",
      "Steps:  27%|▎| 4054/15000 [25:58<33:04,  5.52it/s, lr=9.89e-6, step_loss=0.0097707/18/2023 19:29:20 - INFO - __main__ - train loss is 9.664246074971743\n",
      "Steps:  27%|▎| 4055/15000 [25:58<33:02,  5.52it/s, lr=9.89e-6, step_loss=0.0093507/18/2023 19:29:21 - INFO - __main__ - train loss is 9.717043094453402\n",
      "Steps:  27%|▎| 4056/15000 [25:58<33:01,  5.52it/s, lr=9.89e-6, step_loss=0.0528]07/18/2023 19:29:21 - INFO - __main__ - train loss is 10.375492267427035\n",
      "Steps:  27%|▌ | 4057/15000 [25:59<33:01,  5.52it/s, lr=9.89e-6, step_loss=0.658]07/18/2023 19:29:21 - INFO - __main__ - train loss is 10.449912861105986\n",
      "Steps:  27%|▎| 4058/15000 [25:59<32:53,  5.54it/s, lr=9.89e-6, step_loss=0.0744]07/18/2023 19:29:21 - INFO - __main__ - train loss is 10.671012878534384\n",
      "Steps:  27%|▌ | 4059/15000 [25:59<33:02,  5.52it/s, lr=9.89e-6, step_loss=0.221]07/18/2023 19:29:21 - INFO - __main__ - train loss is 10.69809870806057\n",
      "Steps:  27%|▎| 4060/15000 [25:59<33:02,  5.52it/s, lr=9.89e-6, step_loss=0.0271]07/18/2023 19:29:21 - INFO - __main__ - train loss is 10.764702472952195\n",
      "Steps:  27%|▎| 4061/15000 [25:59<32:52,  5.55it/s, lr=9.89e-6, step_loss=0.0666]07/18/2023 19:29:22 - INFO - __main__ - train loss is 11.104404602316208\n",
      "Steps:  27%|▊  | 4062/15000 [26:00<32:44,  5.57it/s, lr=9.89e-6, step_loss=0.34]07/18/2023 19:29:22 - INFO - __main__ - train loss is 11.185529906419106\n",
      "Steps:  27%|▎| 4063/15000 [26:00<32:39,  5.58it/s, lr=9.89e-6, step_loss=0.0811]07/18/2023 19:29:22 - INFO - __main__ - train loss is 12.007150251534767\n",
      "Steps:  27%|▌ | 4064/15000 [26:00<32:34,  5.59it/s, lr=9.89e-6, step_loss=0.822]07/18/2023 19:29:22 - INFO - __main__ - train loss is 12.404422838357277\n",
      "Steps:  27%|▌ | 4065/15000 [26:00<32:31,  5.60it/s, lr=9.89e-6, step_loss=0.397]07/18/2023 19:29:22 - INFO - __main__ - train loss is 12.45883003261406\n",
      "Steps:  27%|▎| 4066/15000 [26:00<32:46,  5.56it/s, lr=9.89e-6, step_loss=0.0544]07/18/2023 19:29:23 - INFO - __main__ - train loss is 12.474228242528625\n",
      "Steps:  27%|▎| 4067/15000 [26:00<32:39,  5.58it/s, lr=9.89e-6, step_loss=0.0154]07/18/2023 19:29:23 - INFO - __main__ - train loss is 12.489976963144727\n",
      "Steps:  27%|▎| 4068/15000 [26:01<32:34,  5.59it/s, lr=9.89e-6, step_loss=0.0157]07/18/2023 19:29:23 - INFO - __main__ - train loss is 12.840112051111646\n",
      "Steps:  27%|▊  | 4069/15000 [26:01<32:31,  5.60it/s, lr=9.89e-6, step_loss=0.35]07/18/2023 19:29:23 - INFO - __main__ - train loss is 12.843653868534602\n",
      "Steps:  27%|▎| 4070/15000 [26:01<32:29,  5.61it/s, lr=9.89e-6, step_loss=0.0035407/18/2023 19:29:23 - INFO - __main__ - train loss is 12.976935755112208\n",
      "Steps:  27%|▌ | 4071/15000 [26:01<32:48,  5.55it/s, lr=9.89e-6, step_loss=0.133]07/18/2023 19:29:23 - INFO - __main__ - train loss is 13.15802245924715\n",
      "Steps:  27%|▌ | 4072/15000 [26:01<32:48,  5.55it/s, lr=9.89e-6, step_loss=0.181]07/18/2023 19:29:24 - INFO - __main__ - train loss is 13.160999712185003\n",
      "Steps:  27%|▎| 4073/15000 [26:02<32:41,  5.57it/s, lr=9.89e-6, step_loss=0.0029807/18/2023 19:29:24 - INFO - __main__ - train loss is 13.522447702125646\n",
      "Steps:  27%|▌ | 4074/15000 [26:02<44:18,  4.11it/s, lr=9.89e-6, step_loss=0.361]07/18/2023 19:29:25 - INFO - __main__ - Per validation step average loss is 0.05301915854215622\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Cumulative validation average loss is 0.05301915854215622\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Per validation step average loss is 0.016001366078853607\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Cumulative validation average loss is 0.06902052462100983\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Per validation step average loss is 0.1554332822561264\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Cumulative validation average loss is 0.22445380687713623\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Per validation step average loss is 0.38882824778556824\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Cumulative validation average loss is 0.6132820546627045\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Per validation step average loss is 0.0022598449140787125\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Cumulative validation average loss is 0.6155418995767832\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Per validation step average loss is 0.010500743053853512\n",
      "07/18/2023 19:29:25 - INFO - __main__ - Cumulative validation average loss is 0.6260426426306367\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Per validation step average loss is 0.005249181296676397\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Cumulative validation average loss is 0.6312918239273131\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Per validation step average loss is 0.027421947568655014\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Cumulative validation average loss is 0.6587137714959681\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Per validation step average loss is 0.011335235089063644\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Cumulative validation average loss is 0.6700490065850317\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Per validation step average loss is 0.21071970462799072\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Cumulative validation average loss is 0.8807687112130225\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Per validation step average loss is 0.027407929301261902\n",
      "07/18/2023 19:29:26 - INFO - __main__ - Cumulative validation average loss is 0.9081766405142844\n",
      "07/18/2023 19:29:27 - INFO - __main__ - Per validation step average loss is 0.011886214837431908\n",
      "07/18/2023 19:29:27 - INFO - __main__ - Cumulative validation average loss is 0.9200628553517163\n",
      "07/18/2023 19:29:27 - INFO - __main__ - Average validation loss for Epoch 41 is 0.07667190461264302\n",
      "07/18/2023 19:29:27 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:29:39 - INFO - __main__ - Starting epoch 42\n",
      "07/18/2023 19:29:40 - INFO - __main__ - train loss is 0.0545659139752388\n",
      "Steps:  27%|▎| 4075/15000 [26:18<14:49:07,  4.88s/it, lr=9.89e-6, step_loss=0.0507/18/2023 19:29:40 - INFO - __main__ - train loss is 0.13405712693929672\n",
      "Steps:  27%|▎| 4076/15000 [26:18<10:32:03,  3.47s/it, lr=9.89e-6, step_loss=0.0707/18/2023 19:29:40 - INFO - __main__ - train loss is 0.13541863521095365\n",
      "Steps:  27%|▎| 4077/15000 [26:18<7:32:28,  2.49s/it, lr=9.89e-6, step_loss=0.00107/18/2023 19:29:40 - INFO - __main__ - train loss is 0.15168187429662794\n",
      "Steps:  27%|▎| 4078/15000 [26:18<5:26:59,  1.80s/it, lr=9.89e-6, step_loss=0.01607/18/2023 19:29:40 - INFO - __main__ - train loss is 0.36735606600996107\n",
      "Steps:  27%|▎| 4079/15000 [26:18<3:59:17,  1.31s/it, lr=9.89e-6, step_loss=0.21607/18/2023 19:29:41 - INFO - __main__ - train loss is 0.6380012672161683\n",
      "Steps:  27%|▎| 4080/15000 [26:19<2:57:45,  1.02it/s, lr=9.89e-6, step_loss=0.27107/18/2023 19:29:41 - INFO - __main__ - train loss is 0.6447418736061081\n",
      "Steps:  27%|▎| 4081/15000 [26:19<2:14:09,  1.36it/s, lr=9.89e-6, step_loss=0.00607/18/2023 19:29:41 - INFO - __main__ - train loss is 0.7758578913053498\n",
      "Steps:  27%|▎| 4082/15000 [26:19<1:43:35,  1.76it/s, lr=9.89e-6, step_loss=0.13107/18/2023 19:29:41 - INFO - __main__ - train loss is 1.0025210188468918\n",
      "Steps:  27%|▎| 4083/15000 [26:19<1:22:10,  2.21it/s, lr=9.89e-6, step_loss=0.22707/18/2023 19:29:41 - INFO - __main__ - train loss is 1.026425696327351\n",
      "Steps:  27%|▎| 4084/15000 [26:19<1:07:22,  2.70it/s, lr=9.89e-6, step_loss=0.02307/18/2023 19:29:42 - INFO - __main__ - train loss is 1.0782054098090157\n",
      "Steps:  27%|▎| 4085/15000 [26:19<57:28,  3.16it/s, lr=9.89e-6, step_loss=0.0518]07/18/2023 19:29:42 - INFO - __main__ - train loss is 1.2415348024806008\n",
      "Steps:  27%|▌ | 4086/15000 [26:20<50:47,  3.58it/s, lr=9.89e-6, step_loss=0.163]07/18/2023 19:29:42 - INFO - __main__ - train loss is 1.2438150526722893\n",
      "Steps:  27%|▎| 4087/15000 [26:20<46:11,  3.94it/s, lr=9.89e-6, step_loss=0.0022807/18/2023 19:29:42 - INFO - __main__ - train loss is 1.4708974243840203\n",
      "Steps:  27%|▌ | 4088/15000 [26:20<42:51,  4.24it/s, lr=9.89e-6, step_loss=0.227]07/18/2023 19:29:42 - INFO - __main__ - train loss is 1.5786478550871834\n",
      "Steps:  27%|▌ | 4089/15000 [26:20<40:28,  4.49it/s, lr=9.89e-6, step_loss=0.108]07/18/2023 19:29:43 - INFO - __main__ - train loss is 1.5821930462261662\n",
      "Steps:  27%|▎| 4090/15000 [26:20<38:36,  4.71it/s, lr=9.89e-6, step_loss=0.0035507/18/2023 19:29:43 - INFO - __main__ - train loss is 1.6241893166443333\n",
      "Steps:  27%|▌ | 4091/15000 [26:21<37:36,  4.83it/s, lr=9.89e-6, step_loss=0.042]07/18/2023 19:29:43 - INFO - __main__ - train loss is 1.6359492720803246\n",
      "Steps:  27%|▎| 4092/15000 [26:21<36:52,  4.93it/s, lr=9.89e-6, step_loss=0.0118]07/18/2023 19:29:43 - INFO - __main__ - train loss is 1.8924705566605553\n",
      "Steps:  27%|▌ | 4093/15000 [26:21<35:52,  5.07it/s, lr=9.89e-6, step_loss=0.257]07/18/2023 19:29:43 - INFO - __main__ - train loss is 2.191186982556246\n",
      "Steps:  27%|▌ | 4094/15000 [26:21<35:27,  5.13it/s, lr=9.89e-6, step_loss=0.299]07/18/2023 19:29:43 - INFO - __main__ - train loss is 2.193774177809246\n",
      "Steps:  27%|▎| 4095/15000 [26:21<34:54,  5.21it/s, lr=9.89e-6, step_loss=0.0025907/18/2023 19:29:44 - INFO - __main__ - train loss is 2.1975990255596116\n",
      "Steps:  27%|▎| 4096/15000 [26:22<34:35,  5.25it/s, lr=9.89e-6, step_loss=0.0038207/18/2023 19:29:44 - INFO - __main__ - train loss is 2.5124861617805436\n",
      "Steps:  27%|▌ | 4097/15000 [26:22<34:22,  5.29it/s, lr=9.89e-6, step_loss=0.315]07/18/2023 19:29:44 - INFO - __main__ - train loss is 2.5293933955254033\n",
      "Steps:  27%|▎| 4098/15000 [26:22<34:13,  5.31it/s, lr=9.89e-6, step_loss=0.0169]07/18/2023 19:29:44 - INFO - __main__ - train loss is 2.5938331690849736\n",
      "Steps:  27%|▎| 4099/15000 [26:22<34:09,  5.32it/s, lr=9.89e-6, step_loss=0.0644]07/18/2023 19:29:44 - INFO - __main__ - train loss is 2.6062961743446067\n",
      "Steps:  27%|▎| 4100/15000 [26:22<33:49,  5.37it/s, lr=9.89e-6, step_loss=0.0125]07/18/2023 19:29:45 - INFO - __main__ - train loss is 2.8516676948638633\n",
      "Steps:  27%|▌ | 4101/15000 [26:22<33:32,  5.42it/s, lr=9.89e-6, step_loss=0.245]07/18/2023 19:29:45 - INFO - __main__ - train loss is 3.087513812002726\n",
      "Steps:  27%|▌ | 4102/15000 [26:23<33:22,  5.44it/s, lr=9.89e-6, step_loss=0.236]07/18/2023 19:29:45 - INFO - __main__ - train loss is 3.1692862139316276\n",
      "Steps:  27%|▎| 4103/15000 [26:23<33:13,  5.47it/s, lr=9.89e-6, step_loss=0.0818]07/18/2023 19:29:45 - INFO - __main__ - train loss is 3.189922694233246\n",
      "Steps:  27%|▎| 4104/15000 [26:23<33:06,  5.49it/s, lr=9.89e-6, step_loss=0.0206]07/18/2023 19:29:45 - INFO - __main__ - train loss is 3.4820830860408023\n",
      "Steps:  27%|▌ | 4105/15000 [26:23<33:01,  5.50it/s, lr=9.89e-6, step_loss=0.292]07/18/2023 19:29:46 - INFO - __main__ - train loss is 3.495066546020098\n",
      "Steps:  27%|▌ | 4106/15000 [26:23<32:48,  5.53it/s, lr=9.89e-6, step_loss=0.013]07/18/2023 19:29:46 - INFO - __main__ - train loss is 3.7232372687431052\n",
      "Steps:  27%|▌ | 4107/15000 [26:24<32:40,  5.56it/s, lr=9.89e-6, step_loss=0.228]07/18/2023 19:29:46 - INFO - __main__ - train loss is 3.726469785789959\n",
      "Steps:  27%|▎| 4108/15000 [26:24<32:34,  5.57it/s, lr=9.89e-6, step_loss=0.0032307/18/2023 19:29:46 - INFO - __main__ - train loss is 3.7342023447854444\n",
      "Steps:  27%|▎| 4109/15000 [26:24<32:30,  5.58it/s, lr=9.89e-6, step_loss=0.0077307/18/2023 19:29:46 - INFO - __main__ - train loss is 4.396613736520521\n",
      "Steps:  27%|▌ | 4110/15000 [26:24<32:28,  5.59it/s, lr=9.89e-6, step_loss=0.662]07/18/2023 19:29:46 - INFO - __main__ - train loss is 4.419143014471047\n",
      "Steps:  27%|▎| 4111/15000 [26:24<32:34,  5.57it/s, lr=9.89e-6, step_loss=0.0225]07/18/2023 19:29:47 - INFO - __main__ - train loss is 4.421466662664898\n",
      "Steps:  27%|▎| 4112/15000 [26:24<32:38,  5.56it/s, lr=9.89e-6, step_loss=0.0023207/18/2023 19:29:47 - INFO - __main__ - train loss is 4.437078503076918\n",
      "Steps:  27%|▎| 4113/15000 [26:25<32:48,  5.53it/s, lr=9.89e-6, step_loss=0.0156]07/18/2023 19:29:47 - INFO - __main__ - train loss is 4.5473866808461025\n",
      "Steps:  27%|▊  | 4114/15000 [26:25<33:07,  5.48it/s, lr=9.89e-6, step_loss=0.11]07/18/2023 19:29:47 - INFO - __main__ - train loss is 4.922081207041629\n",
      "Steps:  27%|▌ | 4115/15000 [26:25<33:16,  5.45it/s, lr=9.89e-6, step_loss=0.375]07/18/2023 19:29:47 - INFO - __main__ - train loss is 5.2648337233113125\n",
      "Steps:  27%|▌ | 4116/15000 [26:25<32:58,  5.50it/s, lr=9.89e-6, step_loss=0.343]07/18/2023 19:29:47 - INFO - __main__ - train loss is 5.272899345611222\n",
      "Steps:  27%|▎| 4117/15000 [26:25<32:47,  5.53it/s, lr=9.88e-6, step_loss=0.0080707/18/2023 19:29:48 - INFO - __main__ - train loss is 5.312481493805535\n",
      "Steps:  27%|▎| 4118/15000 [26:26<32:38,  5.56it/s, lr=9.88e-6, step_loss=0.0396]07/18/2023 19:29:48 - INFO - __main__ - train loss is 5.315858357236721\n",
      "Steps:  27%|▎| 4119/15000 [26:26<32:33,  5.57it/s, lr=9.88e-6, step_loss=0.0033807/18/2023 19:29:48 - INFO - __main__ - train loss is 5.336411335156299\n",
      "Steps:  27%|▎| 4120/15000 [26:26<32:28,  5.58it/s, lr=9.88e-6, step_loss=0.0206]07/18/2023 19:29:48 - INFO - __main__ - train loss is 5.337849294883199\n",
      "Steps:  27%|▎| 4121/15000 [26:26<32:25,  5.59it/s, lr=9.88e-6, step_loss=0.0014407/18/2023 19:29:48 - INFO - __main__ - train loss is 5.674504017573781\n",
      "Steps:  27%|▌ | 4122/15000 [26:26<32:24,  5.59it/s, lr=9.88e-6, step_loss=0.337]07/18/2023 19:29:49 - INFO - __main__ - train loss is 5.8117973861517385\n",
      "Steps:  27%|▌ | 4123/15000 [26:26<32:22,  5.60it/s, lr=9.88e-6, step_loss=0.137]07/18/2023 19:29:49 - INFO - __main__ - train loss is 5.915402477723546\n",
      "Steps:  27%|▌ | 4124/15000 [26:27<32:20,  5.60it/s, lr=9.88e-6, step_loss=0.104]07/18/2023 19:29:49 - INFO - __main__ - train loss is 6.153713649255224\n",
      "Steps:  28%|▌ | 4125/15000 [26:27<32:19,  5.61it/s, lr=9.88e-6, step_loss=0.238]07/18/2023 19:29:49 - INFO - __main__ - train loss is 6.155707246274687\n",
      "Steps:  28%|▎| 4126/15000 [26:27<32:18,  5.61it/s, lr=9.88e-6, step_loss=0.0019907/18/2023 19:29:49 - INFO - __main__ - train loss is 6.17393863259349\n",
      "Steps:  28%|▎| 4127/15000 [26:27<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.0182]07/18/2023 19:29:49 - INFO - __main__ - train loss is 6.246216320083477\n",
      "Steps:  28%|▎| 4128/15000 [26:27<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.0723]07/18/2023 19:29:50 - INFO - __main__ - train loss is 6.515368186519481\n",
      "Steps:  28%|▌ | 4129/15000 [26:28<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.269]07/18/2023 19:29:50 - INFO - __main__ - train loss is 6.521056196768768\n",
      "Steps:  28%|▎| 4130/15000 [26:28<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.0056907/18/2023 19:29:50 - INFO - __main__ - train loss is 6.5321713705779985\n",
      "Steps:  28%|▎| 4131/15000 [26:28<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.0111]07/18/2023 19:29:50 - INFO - __main__ - train loss is 6.628884816658683\n",
      "Steps:  28%|▎| 4132/15000 [26:28<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.0967]07/18/2023 19:29:50 - INFO - __main__ - train loss is 6.859712103498168\n",
      "Steps:  28%|▌ | 4133/15000 [26:28<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.231]07/18/2023 19:29:51 - INFO - __main__ - train loss is 6.867610351298936\n",
      "Steps:  28%|▎| 4134/15000 [26:28<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.0079]07/18/2023 19:29:51 - INFO - __main__ - train loss is 6.994129778002389\n",
      "Steps:  28%|▌ | 4135/15000 [26:29<32:17,  5.61it/s, lr=9.88e-6, step_loss=0.127]07/18/2023 19:29:51 - INFO - __main__ - train loss is 7.004274140228517\n",
      "Steps:  28%|▎| 4136/15000 [26:29<32:16,  5.61it/s, lr=9.88e-6, step_loss=0.0101]07/18/2023 19:29:51 - INFO - __main__ - train loss is 7.008085414883681\n",
      "Steps:  28%|▎| 4137/15000 [26:29<32:35,  5.55it/s, lr=9.88e-6, step_loss=0.0038107/18/2023 19:29:51 - INFO - __main__ - train loss is 7.422916695591994\n",
      "Steps:  28%|▌ | 4138/15000 [26:29<32:35,  5.56it/s, lr=9.88e-6, step_loss=0.415]07/18/2023 19:29:51 - INFO - __main__ - train loss is 7.737055942532606\n",
      "Steps:  28%|▌ | 4139/15000 [26:29<32:37,  5.55it/s, lr=9.88e-6, step_loss=0.314]07/18/2023 19:29:52 - INFO - __main__ - train loss is 7.739668819704093\n",
      "Steps:  28%|▎| 4140/15000 [26:29<32:38,  5.54it/s, lr=9.88e-6, step_loss=0.0026107/18/2023 19:29:52 - INFO - __main__ - train loss is 8.399876925745048\n",
      "Steps:  28%|▊  | 4141/15000 [26:30<32:41,  5.54it/s, lr=9.88e-6, step_loss=0.66]07/18/2023 19:29:52 - INFO - __main__ - train loss is 8.54881671408657\n",
      "Steps:  28%|▌ | 4142/15000 [26:30<32:42,  5.53it/s, lr=9.88e-6, step_loss=0.149]07/18/2023 19:29:52 - INFO - __main__ - train loss is 8.863427195348777\n",
      "Steps:  28%|▌ | 4143/15000 [26:30<32:53,  5.50it/s, lr=9.88e-6, step_loss=0.315]07/18/2023 19:29:52 - INFO - __main__ - train loss is 8.86557935376186\n",
      "Steps:  28%|▎| 4144/15000 [26:30<32:49,  5.51it/s, lr=9.88e-6, step_loss=0.0021507/18/2023 19:29:53 - INFO - __main__ - train loss is 8.972832175088115\n",
      "Steps:  28%|▌ | 4145/15000 [26:30<32:47,  5.52it/s, lr=9.88e-6, step_loss=0.107]07/18/2023 19:29:53 - INFO - __main__ - train loss is 9.653962703538127\n",
      "Steps:  28%|▌ | 4146/15000 [26:31<32:46,  5.52it/s, lr=9.88e-6, step_loss=0.681]07/18/2023 19:29:53 - INFO - __main__ - train loss is 9.656855451292358\n",
      "Steps:  28%|▎| 4147/15000 [26:31<32:44,  5.52it/s, lr=9.88e-6, step_loss=0.0028907/18/2023 19:29:53 - INFO - __main__ - train loss is 9.659165835590102\n",
      "Steps:  28%|▎| 4148/15000 [26:31<32:44,  5.52it/s, lr=9.88e-6, step_loss=0.0023107/18/2023 19:29:53 - INFO - __main__ - train loss is 9.670284063206054\n",
      "Steps:  28%|▎| 4149/15000 [26:31<32:43,  5.53it/s, lr=9.88e-6, step_loss=0.0111]07/18/2023 19:29:53 - INFO - __main__ - train loss is 9.672931453562342\n",
      "Steps:  28%|▎| 4150/15000 [26:31<32:42,  5.53it/s, lr=9.88e-6, step_loss=0.0026507/18/2023 19:29:54 - INFO - __main__ - train loss is 10.19631238875445\n",
      "Steps:  28%|▌ | 4151/15000 [26:31<32:42,  5.53it/s, lr=9.88e-6, step_loss=0.523]07/18/2023 19:29:54 - INFO - __main__ - train loss is 10.596459826803766\n",
      "Steps:  28%|█   | 4152/15000 [26:32<33:00,  5.48it/s, lr=9.88e-6, step_loss=0.4]07/18/2023 19:29:54 - INFO - __main__ - train loss is 10.818469813442789\n",
      "Steps:  28%|▌ | 4153/15000 [26:32<32:49,  5.51it/s, lr=9.88e-6, step_loss=0.222]07/18/2023 19:29:54 - INFO - __main__ - train loss is 10.823041925556026\n",
      "Steps:  28%|▎| 4154/15000 [26:32<32:40,  5.53it/s, lr=9.88e-6, step_loss=0.0045707/18/2023 19:29:54 - INFO - __main__ - train loss is 11.037674928433262\n",
      "Steps:  28%|▌ | 4155/15000 [26:32<32:31,  5.56it/s, lr=9.88e-6, step_loss=0.215]07/18/2023 19:29:54 - INFO - __main__ - train loss is 11.078237539506517\n",
      "Steps:  28%|▎| 4156/15000 [26:32<32:26,  5.57it/s, lr=9.88e-6, step_loss=0.0406]07/18/2023 19:29:55 - INFO - __main__ - train loss is 11.083218237268738\n",
      "Steps:  28%|▎| 4157/15000 [26:33<32:20,  5.59it/s, lr=9.88e-6, step_loss=0.0049807/18/2023 19:29:55 - INFO - __main__ - train loss is 11.470207949983887\n",
      "Steps:  28%|▌ | 4158/15000 [26:33<32:18,  5.59it/s, lr=9.88e-6, step_loss=0.387]07/18/2023 19:29:55 - INFO - __main__ - train loss is 11.472871926962398\n",
      "Steps:  28%|▎| 4159/15000 [26:33<32:15,  5.60it/s, lr=9.88e-6, step_loss=0.0026607/18/2023 19:29:55 - INFO - __main__ - train loss is 11.485396266332828\n",
      "Steps:  28%|▎| 4160/15000 [26:33<32:14,  5.60it/s, lr=9.88e-6, step_loss=0.0125]07/18/2023 19:29:55 - INFO - __main__ - train loss is 11.809545100084506\n",
      "Steps:  28%|▌ | 4161/15000 [26:33<32:13,  5.61it/s, lr=9.88e-6, step_loss=0.324]07/18/2023 19:29:56 - INFO - __main__ - train loss is 11.98186150228139\n",
      "Steps:  28%|▌ | 4162/15000 [26:33<32:12,  5.61it/s, lr=9.88e-6, step_loss=0.172]07/18/2023 19:29:56 - INFO - __main__ - train loss is 11.990771219483577\n",
      "Steps:  28%|▎| 4163/15000 [26:34<32:13,  5.61it/s, lr=9.88e-6, step_loss=0.0089107/18/2023 19:29:56 - INFO - __main__ - train loss is 11.995892487815581\n",
      "Steps:  28%|▎| 4164/15000 [26:34<32:17,  5.59it/s, lr=9.88e-6, step_loss=0.0051207/18/2023 19:29:56 - INFO - __main__ - train loss is 12.275444947532378\n",
      "Steps:  28%|▊  | 4165/15000 [26:34<32:14,  5.60it/s, lr=9.88e-6, step_loss=0.28]07/18/2023 19:29:56 - INFO - __main__ - train loss is 12.289038317627273\n",
      "Steps:  28%|▎| 4166/15000 [26:34<32:11,  5.61it/s, lr=9.88e-6, step_loss=0.0136]07/18/2023 19:29:56 - INFO - __main__ - train loss is 12.50015725416597\n",
      "Steps:  28%|▌ | 4167/15000 [26:34<32:09,  5.61it/s, lr=9.88e-6, step_loss=0.211]07/18/2023 19:29:57 - INFO - __main__ - train loss is 12.568715805537067\n",
      "Steps:  28%|▎| 4168/15000 [26:35<32:07,  5.62it/s, lr=9.88e-6, step_loss=0.0686]07/18/2023 19:29:57 - INFO - __main__ - train loss is 12.571787271997891\n",
      "Steps:  28%|▎| 4169/15000 [26:35<32:07,  5.62it/s, lr=9.88e-6, step_loss=0.0030707/18/2023 19:29:57 - INFO - __main__ - train loss is 12.57357322180178\n",
      "Steps:  28%|▎| 4170/15000 [26:35<32:07,  5.62it/s, lr=9.88e-6, step_loss=0.0017907/18/2023 19:29:57 - INFO - __main__ - train loss is 12.883570929407142\n",
      "Steps:  28%|▊  | 4171/15000 [26:35<43:55,  4.11it/s, lr=9.88e-6, step_loss=0.31]07/18/2023 19:29:58 - INFO - __main__ - Per validation step average loss is 0.01232230570167303\n",
      "07/18/2023 19:29:58 - INFO - __main__ - Cumulative validation average loss is 0.01232230570167303\n",
      "07/18/2023 19:29:58 - INFO - __main__ - Per validation step average loss is 0.11338134855031967\n",
      "07/18/2023 19:29:58 - INFO - __main__ - Cumulative validation average loss is 0.1257036542519927\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Per validation step average loss is 0.30799323320388794\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Cumulative validation average loss is 0.43369688745588064\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Per validation step average loss is 0.0031211329624056816\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Cumulative validation average loss is 0.4368180204182863\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Per validation step average loss is 0.12702374160289764\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Cumulative validation average loss is 0.563841762021184\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Per validation step average loss is 0.1344848871231079\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Cumulative validation average loss is 0.6983266491442919\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Per validation step average loss is 0.00221926998347044\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Cumulative validation average loss is 0.7005459191277623\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Per validation step average loss is 0.008146875537931919\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Cumulative validation average loss is 0.7086927946656942\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Per validation step average loss is 0.01597829908132553\n",
      "07/18/2023 19:29:59 - INFO - __main__ - Cumulative validation average loss is 0.7246710937470198\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Per validation step average loss is 0.06601456552743912\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Cumulative validation average loss is 0.7906856592744589\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Per validation step average loss is 0.03977048397064209\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Cumulative validation average loss is 0.830456143245101\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Per validation step average loss is 0.00745772197842598\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Cumulative validation average loss is 0.837913865223527\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Average validation loss for Epoch 42 is 0.06982615543529391\n",
      "07/18/2023 19:30:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:30:13 - INFO - __main__ - Starting epoch 43\n",
      "07/18/2023 19:30:13 - INFO - __main__ - train loss is 0.33070504665374756\n",
      "Steps:  28%|▎| 4172/15000 [26:51<14:48:51,  4.93s/it, lr=9.88e-6, step_loss=0.3307/18/2023 19:30:13 - INFO - __main__ - train loss is 0.4075174033641815\n",
      "Steps:  28%|▎| 4173/15000 [26:51<10:32:17,  3.50s/it, lr=9.88e-6, step_loss=0.0707/18/2023 19:30:14 - INFO - __main__ - train loss is 0.4123637117445469\n",
      "Steps:  28%|▎| 4174/15000 [26:51<7:32:09,  2.51s/it, lr=9.88e-6, step_loss=0.00407/18/2023 19:30:14 - INFO - __main__ - train loss is 1.0330345071852207\n",
      "Steps:  28%|▎| 4175/15000 [26:52<5:26:11,  1.81s/it, lr=9.88e-6, step_loss=0.62107/18/2023 19:30:14 - INFO - __main__ - train loss is 1.3423559106886387\n",
      "Steps:  28%|▎| 4176/15000 [26:52<3:57:58,  1.32s/it, lr=9.88e-6, step_loss=0.30907/18/2023 19:30:14 - INFO - __main__ - train loss is 1.8048179782927036\n",
      "Steps:  28%|▎| 4177/15000 [26:52<2:56:11,  1.02it/s, lr=9.88e-6, step_loss=0.46207/18/2023 19:30:14 - INFO - __main__ - train loss is 1.8512561731040478\n",
      "Steps:  28%|▎| 4178/15000 [26:52<2:12:58,  1.36it/s, lr=9.88e-6, step_loss=0.04607/18/2023 19:30:14 - INFO - __main__ - train loss is 1.8545077731832862\n",
      "Steps:  28%|▎| 4179/15000 [26:52<1:42:43,  1.76it/s, lr=9.88e-6, step_loss=0.00307/18/2023 19:30:15 - INFO - __main__ - train loss is 2.124376087449491\n",
      "Steps:  28%|▎| 4180/15000 [26:53<1:21:33,  2.21it/s, lr=9.88e-6, step_loss=0.27]07/18/2023 19:30:15 - INFO - __main__ - train loss is 2.260406627319753\n",
      "Steps:  28%|▎| 4181/15000 [26:53<1:07:18,  2.68it/s, lr=9.88e-6, step_loss=0.13607/18/2023 19:30:15 - INFO - __main__ - train loss is 2.416128574870527\n",
      "Steps:  28%|▌ | 4182/15000 [26:53<57:28,  3.14it/s, lr=9.88e-6, step_loss=0.156]07/18/2023 19:30:15 - INFO - __main__ - train loss is 2.443145235069096\n",
      "Steps:  28%|▌ | 4183/15000 [26:53<50:16,  3.59it/s, lr=9.88e-6, step_loss=0.027]07/18/2023 19:30:15 - INFO - __main__ - train loss is 2.769360770471394\n",
      "Steps:  28%|▌ | 4184/15000 [26:53<44:46,  4.03it/s, lr=9.88e-6, step_loss=0.326]07/18/2023 19:30:16 - INFO - __main__ - train loss is 3.016080071218312\n",
      "Steps:  28%|▌ | 4185/15000 [26:53<41:09,  4.38it/s, lr=9.88e-6, step_loss=0.247]07/18/2023 19:30:16 - INFO - __main__ - train loss is 3.0189085179008543\n",
      "Steps:  28%|▎| 4186/15000 [26:54<38:43,  4.65it/s, lr=9.88e-6, step_loss=0.0028307/18/2023 19:30:16 - INFO - __main__ - train loss is 3.0312740770168602\n",
      "Steps:  28%|▎| 4187/15000 [26:54<37:03,  4.86it/s, lr=9.88e-6, step_loss=0.0124]07/18/2023 19:30:16 - INFO - __main__ - train loss is 3.086501930374652\n",
      "Steps:  28%|▎| 4188/15000 [26:54<35:36,  5.06it/s, lr=9.88e-6, step_loss=0.0552]07/18/2023 19:30:16 - INFO - __main__ - train loss is 3.3030834537930787\n",
      "Steps:  28%|▌ | 4189/15000 [26:54<34:32,  5.22it/s, lr=9.88e-6, step_loss=0.217]07/18/2023 19:30:16 - INFO - __main__ - train loss is 3.4194065597839653\n",
      "Steps:  28%|▌ | 4190/15000 [26:54<33:47,  5.33it/s, lr=9.88e-6, step_loss=0.116]07/18/2023 19:30:17 - INFO - __main__ - train loss is 3.423904565628618\n",
      "Steps:  28%|▎| 4191/15000 [26:55<33:16,  5.41it/s, lr=9.88e-6, step_loss=0.0045]07/18/2023 19:30:17 - INFO - __main__ - train loss is 3.6325478232465684\n",
      "Steps:  28%|▌ | 4192/15000 [26:55<32:54,  5.47it/s, lr=9.88e-6, step_loss=0.209]07/18/2023 19:30:17 - INFO - __main__ - train loss is 3.6854405901394784\n",
      "Steps:  28%|▎| 4193/15000 [26:55<32:39,  5.52it/s, lr=9.88e-6, step_loss=0.0529]07/18/2023 19:30:17 - INFO - __main__ - train loss is 3.6888462342321873\n",
      "Steps:  28%|▎| 4194/15000 [26:55<32:27,  5.55it/s, lr=9.88e-6, step_loss=0.0034107/18/2023 19:30:17 - INFO - __main__ - train loss is 3.7317642867565155\n",
      "Steps:  28%|▎| 4195/15000 [26:55<32:18,  5.57it/s, lr=9.88e-6, step_loss=0.0429]07/18/2023 19:30:18 - INFO - __main__ - train loss is 4.074602723121643\n",
      "Steps:  28%|▌ | 4196/15000 [26:55<32:13,  5.59it/s, lr=9.88e-6, step_loss=0.343]07/18/2023 19:30:18 - INFO - __main__ - train loss is 4.095754526555538\n",
      "Steps:  28%|▎| 4197/15000 [26:56<32:09,  5.60it/s, lr=9.88e-6, step_loss=0.0212]07/18/2023 19:30:18 - INFO - __main__ - train loss is 4.54239010065794\n",
      "Steps:  28%|▌ | 4198/15000 [26:56<32:24,  5.56it/s, lr=9.88e-6, step_loss=0.447]07/18/2023 19:30:18 - INFO - __main__ - train loss is 4.614946618676186\n",
      "Steps:  28%|▎| 4199/15000 [26:56<32:36,  5.52it/s, lr=9.88e-6, step_loss=0.0726]07/18/2023 19:30:18 - INFO - __main__ - train loss is 4.628724415786564\n",
      "Steps:  28%|▎| 4200/15000 [26:56<32:45,  5.50it/s, lr=9.88e-6, step_loss=0.0138]07/18/2023 19:30:18 - INFO - __main__ - train loss is 4.648331315256655\n",
      "Steps:  28%|▎| 4201/15000 [26:56<32:37,  5.52it/s, lr=9.88e-6, step_loss=0.0196]07/18/2023 19:30:19 - INFO - __main__ - train loss is 4.691010409034789\n",
      "Steps:  28%|▎| 4202/15000 [26:57<32:27,  5.55it/s, lr=9.88e-6, step_loss=0.0427]07/18/2023 19:30:19 - INFO - __main__ - train loss is 4.699701021425426\n",
      "Steps:  28%|▎| 4203/15000 [26:57<32:38,  5.51it/s, lr=9.88e-6, step_loss=0.0086907/18/2023 19:30:19 - INFO - __main__ - train loss is 5.017649243585765\n",
      "Steps:  28%|▌ | 4204/15000 [26:57<32:48,  5.48it/s, lr=9.88e-6, step_loss=0.318]07/18/2023 19:30:19 - INFO - __main__ - train loss is 5.026125299744308\n",
      "Steps:  28%|▎| 4205/15000 [26:57<32:55,  5.46it/s, lr=9.88e-6, step_loss=0.0084807/18/2023 19:30:19 - INFO - __main__ - train loss is 5.116610693745315\n",
      "Steps:  28%|▎| 4206/15000 [26:57<33:09,  5.43it/s, lr=9.88e-6, step_loss=0.0905]07/18/2023 19:30:20 - INFO - __main__ - train loss is 5.168158817104995\n",
      "Steps:  28%|▎| 4207/15000 [26:57<32:49,  5.48it/s, lr=9.88e-6, step_loss=0.0515]07/18/2023 19:30:20 - INFO - __main__ - train loss is 5.346554997377098\n",
      "Steps:  28%|▌ | 4208/15000 [26:58<32:47,  5.48it/s, lr=9.88e-6, step_loss=0.178]07/18/2023 19:30:20 - INFO - __main__ - train loss is 5.366898148320615\n",
      "Steps:  28%|▎| 4209/15000 [26:58<32:42,  5.50it/s, lr=9.88e-6, step_loss=0.0203]07/18/2023 19:30:20 - INFO - __main__ - train loss is 5.378520316444337\n",
      "Steps:  28%|▎| 4210/15000 [26:58<32:33,  5.52it/s, lr=9.88e-6, step_loss=0.0116]07/18/2023 19:30:20 - INFO - __main__ - train loss is 5.395242462866008\n",
      "Steps:  28%|▎| 4211/15000 [26:58<32:23,  5.55it/s, lr=9.88e-6, step_loss=0.0167]07/18/2023 19:30:20 - INFO - __main__ - train loss is 5.522502611391246\n",
      "Steps:  28%|▌ | 4212/15000 [26:58<32:18,  5.56it/s, lr=9.88e-6, step_loss=0.127]07/18/2023 19:30:21 - INFO - __main__ - train loss is 5.547851798124611\n",
      "Steps:  28%|▎| 4213/15000 [26:59<32:12,  5.58it/s, lr=9.88e-6, step_loss=0.0253]07/18/2023 19:30:21 - INFO - __main__ - train loss is 5.57658872846514\n",
      "Steps:  28%|▎| 4214/15000 [26:59<32:26,  5.54it/s, lr=9.88e-6, step_loss=0.0287]07/18/2023 19:30:21 - INFO - __main__ - train loss is 5.679189347662032\n",
      "Steps:  28%|▌ | 4215/15000 [26:59<32:33,  5.52it/s, lr=9.88e-6, step_loss=0.103]07/18/2023 19:30:21 - INFO - __main__ - train loss is 5.689582853578031\n",
      "Steps:  28%|▎| 4216/15000 [26:59<32:41,  5.50it/s, lr=9.88e-6, step_loss=0.0104]07/18/2023 19:30:21 - INFO - __main__ - train loss is 6.2206031968817115\n",
      "Steps:  28%|▌ | 4217/15000 [26:59<32:47,  5.48it/s, lr=9.88e-6, step_loss=0.531]07/18/2023 19:30:22 - INFO - __main__ - train loss is 6.655655174516141\n",
      "Steps:  28%|▌ | 4218/15000 [26:59<32:46,  5.48it/s, lr=9.88e-6, step_loss=0.435]07/18/2023 19:30:22 - INFO - __main__ - train loss is 6.6660504303872585\n",
      "Steps:  28%|▎| 4219/15000 [27:00<32:50,  5.47it/s, lr=9.88e-6, step_loss=0.0104]07/18/2023 19:30:22 - INFO - __main__ - train loss is 6.682856822386384\n",
      "Steps:  28%|▎| 4220/15000 [27:00<32:59,  5.45it/s, lr=9.88e-6, step_loss=0.0168]07/18/2023 19:30:22 - INFO - __main__ - train loss is 6.685741912573576\n",
      "Steps:  28%|▎| 4221/15000 [27:00<32:47,  5.48it/s, lr=9.88e-6, step_loss=0.0028907/18/2023 19:30:22 - INFO - __main__ - train loss is 6.692405822686851\n",
      "Steps:  28%|▎| 4222/15000 [27:00<32:33,  5.52it/s, lr=9.88e-6, step_loss=0.0066607/18/2023 19:30:22 - INFO - __main__ - train loss is 6.755806404165924\n",
      "Steps:  28%|▎| 4223/15000 [27:00<32:29,  5.53it/s, lr=9.88e-6, step_loss=0.0634]07/18/2023 19:30:23 - INFO - __main__ - train loss is 6.816539670340717\n",
      "Steps:  28%|▎| 4224/15000 [27:01<32:20,  5.55it/s, lr=9.88e-6, step_loss=0.0607]07/18/2023 19:30:23 - INFO - __main__ - train loss is 6.840257252566516\n",
      "Steps:  28%|▎| 4225/15000 [27:01<32:13,  5.57it/s, lr=9.88e-6, step_loss=0.0237]07/18/2023 19:30:23 - INFO - __main__ - train loss is 7.149821783415973\n",
      "Steps:  28%|▊  | 4226/15000 [27:01<32:07,  5.59it/s, lr=9.88e-6, step_loss=0.31]07/18/2023 19:30:23 - INFO - __main__ - train loss is 7.1620606211945415\n",
      "Steps:  28%|▎| 4227/15000 [27:01<32:04,  5.60it/s, lr=9.88e-6, step_loss=0.0122]07/18/2023 19:30:23 - INFO - __main__ - train loss is 7.298020082525909\n",
      "Steps:  28%|▌ | 4228/15000 [27:01<32:03,  5.60it/s, lr=9.88e-6, step_loss=0.136]07/18/2023 19:30:24 - INFO - __main__ - train loss is 7.559847014956176\n",
      "Steps:  28%|▌ | 4229/15000 [27:01<32:00,  5.61it/s, lr=9.88e-6, step_loss=0.262]07/18/2023 19:30:24 - INFO - __main__ - train loss is 7.902646022848785\n",
      "Steps:  28%|▌ | 4230/15000 [27:02<31:58,  5.61it/s, lr=9.88e-6, step_loss=0.343]07/18/2023 19:30:24 - INFO - __main__ - train loss is 7.9627595050260425\n",
      "Steps:  28%|▎| 4231/15000 [27:02<31:58,  5.61it/s, lr=9.88e-6, step_loss=0.0601]07/18/2023 19:30:24 - INFO - __main__ - train loss is 7.969749758951366\n",
      "Steps:  28%|▎| 4232/15000 [27:02<31:56,  5.62it/s, lr=9.88e-6, step_loss=0.0069907/18/2023 19:30:24 - INFO - __main__ - train loss is 7.991883267648518\n",
      "Steps:  28%|▎| 4233/15000 [27:02<31:56,  5.62it/s, lr=9.88e-6, step_loss=0.0221]07/18/2023 19:30:24 - INFO - __main__ - train loss is 8.044290945865214\n",
      "Steps:  28%|▎| 4234/15000 [27:02<31:56,  5.62it/s, lr=9.88e-6, step_loss=0.0524]07/18/2023 19:30:25 - INFO - __main__ - train loss is 8.380609259940684\n",
      "Steps:  28%|▌ | 4235/15000 [27:02<31:55,  5.62it/s, lr=9.88e-6, step_loss=0.336]07/18/2023 19:30:25 - INFO - __main__ - train loss is 8.390581368468702\n",
      "Steps:  28%|▎| 4236/15000 [27:03<31:54,  5.62it/s, lr=9.88e-6, step_loss=0.0099707/18/2023 19:30:25 - INFO - __main__ - train loss is 8.394195065833628\n",
      "Steps:  28%|▎| 4237/15000 [27:03<31:55,  5.62it/s, lr=9.88e-6, step_loss=0.0036107/18/2023 19:30:25 - INFO - __main__ - train loss is 8.884555206634104\n",
      "Steps:  28%|▊  | 4238/15000 [27:03<31:54,  5.62it/s, lr=9.88e-6, step_loss=0.49]07/18/2023 19:30:25 - INFO - __main__ - train loss is 8.908711695112288\n",
      "Steps:  28%|▎| 4239/15000 [27:03<31:53,  5.62it/s, lr=9.88e-6, step_loss=0.0242]07/18/2023 19:30:25 - INFO - __main__ - train loss is 9.120852642692626\n",
      "Steps:  28%|▌ | 4240/15000 [27:03<31:53,  5.62it/s, lr=9.88e-6, step_loss=0.212]07/18/2023 19:30:26 - INFO - __main__ - train loss is 9.413101934827864\n",
      "Steps:  28%|▌ | 4241/15000 [27:04<31:53,  5.62it/s, lr=9.88e-6, step_loss=0.292]07/18/2023 19:30:26 - INFO - __main__ - train loss is 9.49759127292782\n",
      "Steps:  28%|▎| 4242/15000 [27:04<31:52,  5.63it/s, lr=9.88e-6, step_loss=0.0845]07/18/2023 19:30:26 - INFO - __main__ - train loss is 9.504229990765452\n",
      "Steps:  28%|▎| 4243/15000 [27:04<31:51,  5.63it/s, lr=9.88e-6, step_loss=0.0066407/18/2023 19:30:26 - INFO - __main__ - train loss is 9.69374486617744\n",
      "Steps:  28%|▊  | 4244/15000 [27:04<31:51,  5.63it/s, lr=9.88e-6, step_loss=0.19]07/18/2023 19:30:26 - INFO - __main__ - train loss is 9.701981818303466\n",
      "Steps:  28%|▎| 4245/15000 [27:04<31:51,  5.63it/s, lr=9.88e-6, step_loss=0.0082407/18/2023 19:30:27 - INFO - __main__ - train loss is 9.72001500800252\n",
      "Steps:  28%|▌ | 4246/15000 [27:04<31:52,  5.62it/s, lr=9.88e-6, step_loss=0.018]07/18/2023 19:30:27 - INFO - __main__ - train loss is 9.79481976851821\n",
      "Steps:  28%|▎| 4247/15000 [27:05<31:52,  5.62it/s, lr=9.88e-6, step_loss=0.0748]07/18/2023 19:30:27 - INFO - __main__ - train loss is 9.97624122723937\n",
      "Steps:  28%|▌ | 4248/15000 [27:05<31:52,  5.62it/s, lr=9.88e-6, step_loss=0.181]07/18/2023 19:30:27 - INFO - __main__ - train loss is 9.990959252230823\n",
      "Steps:  28%|▎| 4249/15000 [27:05<31:52,  5.62it/s, lr=9.88e-6, step_loss=0.0147]07/18/2023 19:30:27 - INFO - __main__ - train loss is 10.190797115676105\n",
      "Steps:  28%|█▏  | 4250/15000 [27:05<31:53,  5.62it/s, lr=9.88e-6, step_loss=0.2]07/18/2023 19:30:27 - INFO - __main__ - train loss is 10.55235495697707\n",
      "Steps:  28%|▌ | 4251/15000 [27:05<31:53,  5.62it/s, lr=9.88e-6, step_loss=0.362]07/18/2023 19:30:28 - INFO - __main__ - train loss is 10.590041278861463\n",
      "Steps:  28%|▎| 4252/15000 [27:06<31:53,  5.62it/s, lr=9.88e-6, step_loss=0.0377]07/18/2023 19:30:28 - INFO - __main__ - train loss is 10.592663424555212\n",
      "Steps:  28%|▎| 4253/15000 [27:06<31:52,  5.62it/s, lr=9.88e-6, step_loss=0.0026207/18/2023 19:30:28 - INFO - __main__ - train loss is 10.598439679015428\n",
      "Steps:  28%|▎| 4254/15000 [27:06<31:50,  5.62it/s, lr=9.88e-6, step_loss=0.0057807/18/2023 19:30:28 - INFO - __main__ - train loss is 10.76057241903618\n",
      "Steps:  28%|▌ | 4255/15000 [27:06<31:49,  5.63it/s, lr=9.88e-6, step_loss=0.162]07/18/2023 19:30:28 - INFO - __main__ - train loss is 10.842210665810853\n",
      "Steps:  28%|▎| 4256/15000 [27:06<31:48,  5.63it/s, lr=9.88e-6, step_loss=0.0816]07/18/2023 19:30:29 - INFO - __main__ - train loss is 11.628232613671571\n",
      "Steps:  28%|▌ | 4257/15000 [27:06<31:48,  5.63it/s, lr=9.88e-6, step_loss=0.786]07/18/2023 19:30:29 - INFO - __main__ - train loss is 11.643671164754778\n",
      "Steps:  28%|▎| 4258/15000 [27:07<31:48,  5.63it/s, lr=9.88e-6, step_loss=0.0154]07/18/2023 19:30:29 - INFO - __main__ - train loss is 11.726388970855623\n",
      "Steps:  28%|▎| 4259/15000 [27:07<31:48,  5.63it/s, lr=9.88e-6, step_loss=0.0827]07/18/2023 19:30:29 - INFO - __main__ - train loss is 11.776717575732619\n",
      "Steps:  28%|▎| 4260/15000 [27:07<31:47,  5.63it/s, lr=9.88e-6, step_loss=0.0503]07/18/2023 19:30:29 - INFO - __main__ - train loss is 11.94020195538178\n",
      "Steps:  28%|▌ | 4261/15000 [27:07<31:46,  5.63it/s, lr=9.88e-6, step_loss=0.163]07/18/2023 19:30:29 - INFO - __main__ - train loss is 12.030881943646818\n",
      "Steps:  28%|▎| 4262/15000 [27:07<31:45,  5.64it/s, lr=9.88e-6, step_loss=0.0907]07/18/2023 19:30:30 - INFO - __main__ - train loss is 12.269294443074614\n",
      "Steps:  28%|▌ | 4263/15000 [27:07<31:48,  5.63it/s, lr=9.88e-6, step_loss=0.238]07/18/2023 19:30:30 - INFO - __main__ - train loss is 12.41904871398583\n",
      "Steps:  28%|▊  | 4264/15000 [27:08<31:47,  5.63it/s, lr=9.88e-6, step_loss=0.15]07/18/2023 19:30:30 - INFO - __main__ - train loss is 12.451833399478346\n",
      "Steps:  28%|▎| 4265/15000 [27:08<31:49,  5.62it/s, lr=9.88e-6, step_loss=0.0328]07/18/2023 19:30:30 - INFO - __main__ - train loss is 12.464737534988672\n",
      "Steps:  28%|▎| 4266/15000 [27:08<31:47,  5.63it/s, lr=9.88e-6, step_loss=0.0129]07/18/2023 19:30:30 - INFO - __main__ - train loss is 12.46905390592292\n",
      "Steps:  28%|▎| 4267/15000 [27:08<31:50,  5.62it/s, lr=9.88e-6, step_loss=0.0043207/18/2023 19:30:31 - INFO - __main__ - train loss is 12.585620027501136\n",
      "Steps:  28%|▌ | 4268/15000 [27:09<42:52,  4.17it/s, lr=9.88e-6, step_loss=0.117]07/18/2023 19:30:31 - INFO - __main__ - Per validation step average loss is 0.01441896427422762\n",
      "07/18/2023 19:30:31 - INFO - __main__ - Cumulative validation average loss is 0.01441896427422762\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Per validation step average loss is 0.11642581969499588\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Cumulative validation average loss is 0.1308447839692235\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Per validation step average loss is 0.7015780210494995\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Cumulative validation average loss is 0.832422805018723\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Per validation step average loss is 0.008635051548480988\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Cumulative validation average loss is 0.841057856567204\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Per validation step average loss is 0.4665433168411255\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Cumulative validation average loss is 1.3076011734083295\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Per validation step average loss is 0.00944474432617426\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Cumulative validation average loss is 1.3170459177345037\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Per validation step average loss is 0.5136762857437134\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Cumulative validation average loss is 1.8307222034782171\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Per validation step average loss is 0.003994854167103767\n",
      "07/18/2023 19:30:32 - INFO - __main__ - Cumulative validation average loss is 1.834717057645321\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Per validation step average loss is 0.2712540030479431\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Cumulative validation average loss is 2.105971060693264\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Per validation step average loss is 0.24009230732917786\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Cumulative validation average loss is 2.346063368022442\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Per validation step average loss is 0.00833418034017086\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Cumulative validation average loss is 2.3543975483626127\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Per validation step average loss is 0.04550699144601822\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Cumulative validation average loss is 2.399904539808631\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Average validation loss for Epoch 43 is 0.19999204498405257\n",
      "07/18/2023 19:30:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:30:46 - INFO - __main__ - Starting epoch 44\n",
      "07/18/2023 19:30:47 - INFO - __main__ - train loss is 0.06742686033248901\n",
      "Steps:  28%|▎| 4269/15000 [27:25<14:47:32,  4.96s/it, lr=9.88e-6, step_loss=0.0607/18/2023 19:30:47 - INFO - __main__ - train loss is 0.19170504808425903\n",
      "Steps:  28%|▎| 4270/15000 [27:25<10:30:47,  3.53s/it, lr=9.88e-6, step_loss=0.1207/18/2023 19:30:47 - INFO - __main__ - train loss is 0.37220731377601624\n",
      "Steps:  28%|▎| 4271/15000 [27:25<7:31:06,  2.52s/it, lr=9.88e-6, step_loss=0.18107/18/2023 19:30:47 - INFO - __main__ - train loss is 0.40883519127964973\n",
      "Steps:  28%|▎| 4272/15000 [27:25<5:25:27,  1.82s/it, lr=9.88e-6, step_loss=0.03607/18/2023 19:30:47 - INFO - __main__ - train loss is 0.4508925750851631\n",
      "Steps:  28%|▎| 4273/15000 [27:25<3:57:33,  1.33s/it, lr=9.88e-6, step_loss=0.04207/18/2023 19:30:48 - INFO - __main__ - train loss is 0.5026140622794628\n",
      "Steps:  28%|▎| 4274/15000 [27:25<2:56:08,  1.01it/s, lr=9.88e-6, step_loss=0.05107/18/2023 19:30:48 - INFO - __main__ - train loss is 0.7587273232638836\n",
      "Steps:  28%|▎| 4275/15000 [27:26<2:13:14,  1.34it/s, lr=9.88e-6, step_loss=0.25607/18/2023 19:30:48 - INFO - __main__ - train loss is 0.7849508076906204\n",
      "Steps:  29%|▎| 4276/15000 [27:26<1:43:04,  1.73it/s, lr=9.88e-6, step_loss=0.02607/18/2023 19:30:48 - INFO - __main__ - train loss is 1.06007619202137\n",
      "Steps:  29%|▎| 4277/15000 [27:26<1:21:58,  2.18it/s, lr=9.88e-6, step_loss=0.27507/18/2023 19:30:48 - INFO - __main__ - train loss is 1.2445329576730728\n",
      "Steps:  29%|▎| 4278/15000 [27:26<1:06:59,  2.67it/s, lr=9.88e-6, step_loss=0.18407/18/2023 19:30:48 - INFO - __main__ - train loss is 1.2674606144428253\n",
      "Steps:  29%|▎| 4279/15000 [27:26<56:25,  3.17it/s, lr=9.88e-6, step_loss=0.0229]07/18/2023 19:30:49 - INFO - __main__ - train loss is 1.4039306938648224\n",
      "Steps:  29%|▌ | 4280/15000 [27:27<49:00,  3.65it/s, lr=9.88e-6, step_loss=0.136]07/18/2023 19:30:49 - INFO - __main__ - train loss is 1.4176014577969909\n",
      "Steps:  29%|▎| 4281/15000 [27:27<43:53,  4.07it/s, lr=9.88e-6, step_loss=0.0137]07/18/2023 19:30:49 - INFO - __main__ - train loss is 1.5205529844388366\n",
      "Steps:  29%|▌ | 4282/15000 [27:27<40:34,  4.40it/s, lr=9.88e-6, step_loss=0.103]07/18/2023 19:30:49 - INFO - __main__ - train loss is 1.8067650711163878\n",
      "Steps:  29%|▌ | 4283/15000 [27:27<38:16,  4.67it/s, lr=9.88e-6, step_loss=0.286]07/18/2023 19:30:49 - INFO - __main__ - train loss is 1.889106503687799\n",
      "Steps:  29%|▎| 4284/15000 [27:27<36:29,  4.89it/s, lr=9.88e-6, step_loss=0.0823]07/18/2023 19:30:50 - INFO - __main__ - train loss is 1.9157967427745461\n",
      "Steps:  29%|▎| 4285/15000 [27:27<35:05,  5.09it/s, lr=9.88e-6, step_loss=0.0267]07/18/2023 19:30:50 - INFO - __main__ - train loss is 1.9758557165041566\n",
      "Steps:  29%|▎| 4286/15000 [27:28<34:13,  5.22it/s, lr=9.88e-6, step_loss=0.0601]07/18/2023 19:30:50 - INFO - __main__ - train loss is 2.411296852864325\n",
      "Steps:  29%|▌ | 4287/15000 [27:28<33:31,  5.33it/s, lr=9.88e-6, step_loss=0.435]07/18/2023 19:30:50 - INFO - __main__ - train loss is 2.537451752461493\n",
      "Steps:  29%|▌ | 4288/15000 [27:28<33:02,  5.40it/s, lr=9.88e-6, step_loss=0.126]07/18/2023 19:30:50 - INFO - __main__ - train loss is 2.8849031412974\n",
      "Steps:  29%|▌ | 4289/15000 [27:28<32:43,  5.45it/s, lr=9.88e-6, step_loss=0.347]07/18/2023 19:30:50 - INFO - __main__ - train loss is 3.317083545960486\n",
      "Steps:  29%|▌ | 4290/15000 [27:28<32:27,  5.50it/s, lr=9.88e-6, step_loss=0.432]07/18/2023 19:30:51 - INFO - __main__ - train loss is 3.945502587594092\n",
      "Steps:  29%|▌ | 4291/15000 [27:29<32:20,  5.52it/s, lr=9.88e-6, step_loss=0.628]07/18/2023 19:30:51 - INFO - __main__ - train loss is 4.002412267960608\n",
      "Steps:  29%|▎| 4292/15000 [27:29<32:10,  5.55it/s, lr=9.87e-6, step_loss=0.0569]07/18/2023 19:30:51 - INFO - __main__ - train loss is 4.249704250134528\n",
      "[2023-07-18 19:30:51,572] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:  29%|▌ | 4293/15000 [27:29<31:50,  5.60it/s, lr=9.87e-6, step_loss=0.247]07/18/2023 19:30:51 - INFO - __main__ - train loss is 4.252025896683335\n",
      "Steps:  29%|▎| 4294/15000 [27:29<31:47,  5.61it/s, lr=9.87e-6, step_loss=0.0023207/18/2023 19:30:51 - INFO - __main__ - train loss is 4.255395737476647\n",
      "Steps:  29%|▎| 4295/15000 [27:29<31:47,  5.61it/s, lr=9.87e-6, step_loss=0.0033707/18/2023 19:30:52 - INFO - __main__ - train loss is 4.2694525280967355\n",
      "Steps:  29%|▎| 4296/15000 [27:29<32:06,  5.56it/s, lr=9.87e-6, step_loss=0.0141]07/18/2023 19:30:52 - INFO - __main__ - train loss is 4.950498298741877\n",
      "Steps:  29%|▌ | 4297/15000 [27:30<32:06,  5.56it/s, lr=9.87e-6, step_loss=0.681]07/18/2023 19:30:52 - INFO - __main__ - train loss is 5.190225140191615\n",
      "Steps:  29%|▊  | 4298/15000 [27:30<32:00,  5.57it/s, lr=9.87e-6, step_loss=0.24]07/18/2023 19:30:52 - INFO - __main__ - train loss is 5.589061097241938\n",
      "Steps:  29%|▌ | 4299/15000 [27:30<31:57,  5.58it/s, lr=9.87e-6, step_loss=0.399]07/18/2023 19:30:52 - INFO - __main__ - train loss is 5.615936770103872\n",
      "Steps:  29%|▎| 4300/15000 [27:30<31:54,  5.59it/s, lr=9.87e-6, step_loss=0.0269]07/18/2023 19:30:52 - INFO - __main__ - train loss is 5.880547954700887\n",
      "Steps:  29%|▌ | 4301/15000 [27:30<31:51,  5.60it/s, lr=9.87e-6, step_loss=0.265]07/18/2023 19:30:53 - INFO - __main__ - train loss is 6.192523523233831\n",
      "Steps:  29%|▌ | 4302/15000 [27:30<31:52,  5.59it/s, lr=9.87e-6, step_loss=0.312]07/18/2023 19:30:53 - INFO - __main__ - train loss is 6.22203600872308\n",
      "Steps:  29%|▎| 4303/15000 [27:31<31:51,  5.60it/s, lr=9.87e-6, step_loss=0.0295]07/18/2023 19:30:53 - INFO - __main__ - train loss is 6.228528772480786\n",
      "Steps:  29%|▎| 4304/15000 [27:31<31:49,  5.60it/s, lr=9.87e-6, step_loss=0.0064907/18/2023 19:30:53 - INFO - __main__ - train loss is 6.263411940075457\n",
      "Steps:  29%|▎| 4305/15000 [27:31<32:46,  5.44it/s, lr=9.87e-6, step_loss=0.0349]07/18/2023 19:30:53 - INFO - __main__ - train loss is 6.395132289268076\n",
      "Steps:  29%|▌ | 4306/15000 [27:31<32:28,  5.49it/s, lr=9.87e-6, step_loss=0.132]07/18/2023 19:30:54 - INFO - __main__ - train loss is 6.573585496284068\n",
      "Steps:  29%|▌ | 4307/15000 [27:31<32:16,  5.52it/s, lr=9.87e-6, step_loss=0.178]07/18/2023 19:30:54 - INFO - __main__ - train loss is 6.621969391591847\n",
      "Steps:  29%|▎| 4308/15000 [27:32<32:07,  5.55it/s, lr=9.87e-6, step_loss=0.0484]07/18/2023 19:30:54 - INFO - __main__ - train loss is 7.06414230633527\n",
      "Steps:  29%|▌ | 4309/15000 [27:32<32:01,  5.56it/s, lr=9.87e-6, step_loss=0.442]07/18/2023 19:30:54 - INFO - __main__ - train loss is 7.088343980722129\n",
      "Steps:  29%|▎| 4310/15000 [27:32<31:56,  5.58it/s, lr=9.87e-6, step_loss=0.0242]07/18/2023 19:30:54 - INFO - __main__ - train loss is 7.260327520780265\n",
      "Steps:  29%|▌ | 4311/15000 [27:32<31:53,  5.59it/s, lr=9.87e-6, step_loss=0.172]07/18/2023 19:30:54 - INFO - __main__ - train loss is 7.269310315139592\n",
      "Steps:  29%|▎| 4312/15000 [27:32<31:51,  5.59it/s, lr=9.87e-6, step_loss=0.0089807/18/2023 19:30:55 - INFO - __main__ - train loss is 7.569438894279301\n",
      "Steps:  29%|█▏  | 4313/15000 [27:32<31:49,  5.60it/s, lr=9.87e-6, step_loss=0.3]07/18/2023 19:30:55 - INFO - __main__ - train loss is 8.021673251874745\n",
      "Steps:  29%|▌ | 4314/15000 [27:33<31:47,  5.60it/s, lr=9.87e-6, step_loss=0.452]07/18/2023 19:30:55 - INFO - __main__ - train loss is 8.03678775858134\n",
      "Steps:  29%|▎| 4315/15000 [27:33<31:48,  5.60it/s, lr=9.87e-6, step_loss=0.0151]07/18/2023 19:30:55 - INFO - __main__ - train loss is 8.234826038591564\n",
      "Steps:  29%|▌ | 4316/15000 [27:33<32:05,  5.55it/s, lr=9.87e-6, step_loss=0.198]07/18/2023 19:30:55 - INFO - __main__ - train loss is 8.24221116444096\n",
      "Steps:  29%|▎| 4317/15000 [27:33<32:12,  5.53it/s, lr=9.87e-6, step_loss=0.0073907/18/2023 19:30:55 - INFO - __main__ - train loss is 8.261780527886003\n",
      "Steps:  29%|▎| 4318/15000 [27:33<32:04,  5.55it/s, lr=9.87e-6, step_loss=0.0196]07/18/2023 19:30:56 - INFO - __main__ - train loss is 8.536967483814806\n",
      "Steps:  29%|▌ | 4319/15000 [27:34<31:58,  5.57it/s, lr=9.87e-6, step_loss=0.275]07/18/2023 19:30:56 - INFO - __main__ - train loss is 8.540497006382793\n",
      "Steps:  29%|▎| 4320/15000 [27:34<31:55,  5.58it/s, lr=9.87e-6, step_loss=0.0035307/18/2023 19:30:56 - INFO - __main__ - train loss is 8.552003372926265\n",
      "Steps:  29%|▎| 4321/15000 [27:34<31:53,  5.58it/s, lr=9.87e-6, step_loss=0.0115]07/18/2023 19:30:56 - INFO - __main__ - train loss is 8.59206583024934\n",
      "Steps:  29%|▎| 4322/15000 [27:34<31:51,  5.59it/s, lr=9.87e-6, step_loss=0.0401]07/18/2023 19:30:56 - INFO - __main__ - train loss is 8.614190727937967\n",
      "Steps:  29%|▎| 4323/15000 [27:34<31:49,  5.59it/s, lr=9.87e-6, step_loss=0.0221]07/18/2023 19:30:57 - INFO - __main__ - train loss is 8.780770749319345\n",
      "Steps:  29%|▌ | 4324/15000 [27:34<31:49,  5.59it/s, lr=9.87e-6, step_loss=0.167]07/18/2023 19:30:57 - INFO - __main__ - train loss is 9.232230216730386\n",
      "Steps:  29%|▌ | 4325/15000 [27:35<31:52,  5.58it/s, lr=9.87e-6, step_loss=0.451]07/18/2023 19:30:57 - INFO - __main__ - train loss is 9.285277352202684\n",
      "Steps:  29%|▌ | 4326/15000 [27:35<31:49,  5.59it/s, lr=9.87e-6, step_loss=0.053]07/18/2023 19:30:57 - INFO - __main__ - train loss is 9.290208651684225\n",
      "Steps:  29%|▎| 4327/15000 [27:35<31:48,  5.59it/s, lr=9.87e-6, step_loss=0.0049307/18/2023 19:30:57 - INFO - __main__ - train loss is 9.345249018631876\n",
      "Steps:  29%|▌ | 4328/15000 [27:35<31:45,  5.60it/s, lr=9.87e-6, step_loss=0.055]07/18/2023 19:30:57 - INFO - __main__ - train loss is 9.606146058999002\n",
      "Steps:  29%|▌ | 4329/15000 [27:35<31:44,  5.60it/s, lr=9.87e-6, step_loss=0.261]07/18/2023 19:30:58 - INFO - __main__ - train loss is 9.734981319867074\n",
      "Steps:  29%|▌ | 4330/15000 [27:36<31:45,  5.60it/s, lr=9.87e-6, step_loss=0.129]07/18/2023 19:30:58 - INFO - __main__ - train loss is 9.76074060704559\n",
      "Steps:  29%|▎| 4331/15000 [27:36<31:43,  5.60it/s, lr=9.87e-6, step_loss=0.0258]07/18/2023 19:30:58 - INFO - __main__ - train loss is 9.766087284311652\n",
      "Steps:  29%|▎| 4332/15000 [27:36<31:42,  5.61it/s, lr=9.87e-6, step_loss=0.0053507/18/2023 19:30:58 - INFO - __main__ - train loss is 9.849790370091796\n",
      "Steps:  29%|▎| 4333/15000 [27:36<31:42,  5.61it/s, lr=9.87e-6, step_loss=0.0837]07/18/2023 19:30:58 - INFO - __main__ - train loss is 9.851537292823195\n",
      "Steps:  29%|▎| 4334/15000 [27:36<31:42,  5.61it/s, lr=9.87e-6, step_loss=0.0017507/18/2023 19:30:59 - INFO - __main__ - train loss is 10.191416447982192\n",
      "Steps:  29%|▊  | 4335/15000 [27:36<31:41,  5.61it/s, lr=9.87e-6, step_loss=0.34]07/18/2023 19:30:59 - INFO - __main__ - train loss is 10.33187929354608\n",
      "Steps:  29%|▊  | 4336/15000 [27:37<31:58,  5.56it/s, lr=9.87e-6, step_loss=0.14]07/18/2023 19:30:59 - INFO - __main__ - train loss is 10.356696547940373\n",
      "Steps:  29%|▎| 4337/15000 [27:37<32:08,  5.53it/s, lr=9.87e-6, step_loss=0.0248]07/18/2023 19:30:59 - INFO - __main__ - train loss is 10.40784807689488\n",
      "Steps:  29%|▎| 4338/15000 [27:37<31:59,  5.55it/s, lr=9.87e-6, step_loss=0.0512]07/18/2023 19:30:59 - INFO - __main__ - train loss is 10.411545599345118\n",
      "Steps:  29%|▎| 4339/15000 [27:37<31:53,  5.57it/s, lr=9.87e-6, step_loss=0.0037]07/18/2023 19:30:59 - INFO - __main__ - train loss is 10.431745375040919\n",
      "Steps:  29%|▎| 4340/15000 [27:37<31:50,  5.58it/s, lr=9.87e-6, step_loss=0.0202]07/18/2023 19:31:00 - INFO - __main__ - train loss is 10.560267145279795\n",
      "Steps:  29%|▌ | 4341/15000 [27:37<31:47,  5.59it/s, lr=9.87e-6, step_loss=0.129]07/18/2023 19:31:00 - INFO - __main__ - train loss is 10.57638829620555\n",
      "Steps:  29%|▎| 4342/15000 [27:38<31:43,  5.60it/s, lr=9.87e-6, step_loss=0.0161]07/18/2023 19:31:00 - INFO - __main__ - train loss is 10.992954638320953\n",
      "Steps:  29%|▌ | 4343/15000 [27:38<31:42,  5.60it/s, lr=9.87e-6, step_loss=0.417]07/18/2023 19:31:00 - INFO - __main__ - train loss is 11.331380244810134\n",
      "Steps:  29%|▌ | 4344/15000 [27:38<31:43,  5.60it/s, lr=9.87e-6, step_loss=0.338]07/18/2023 19:31:00 - INFO - __main__ - train loss is 11.436427917797118\n",
      "Steps:  29%|▌ | 4345/15000 [27:38<31:41,  5.60it/s, lr=9.87e-6, step_loss=0.105]07/18/2023 19:31:00 - INFO - __main__ - train loss is 11.797683027107269\n",
      "Steps:  29%|▌ | 4346/15000 [27:38<31:41,  5.60it/s, lr=9.87e-6, step_loss=0.361]07/18/2023 19:31:01 - INFO - __main__ - train loss is 11.970407154876739\n",
      "Steps:  29%|▌ | 4347/15000 [27:39<31:46,  5.59it/s, lr=9.87e-6, step_loss=0.173]07/18/2023 19:31:01 - INFO - __main__ - train loss is 12.54369690688327\n",
      "Steps:  29%|▌ | 4348/15000 [27:39<32:03,  5.54it/s, lr=9.87e-6, step_loss=0.573]07/18/2023 19:31:01 - INFO - __main__ - train loss is 12.564022578764707\n",
      "Steps:  29%|▎| 4349/15000 [27:39<32:16,  5.50it/s, lr=9.87e-6, step_loss=0.0203]07/18/2023 19:31:01 - INFO - __main__ - train loss is 12.569669059012085\n",
      "Steps:  29%|▎| 4350/15000 [27:39<32:18,  5.49it/s, lr=9.87e-6, step_loss=0.0056507/18/2023 19:31:01 - INFO - __main__ - train loss is 12.741363993380219\n",
      "Steps:  29%|▌ | 4351/15000 [27:39<32:06,  5.53it/s, lr=9.87e-6, step_loss=0.172]07/18/2023 19:31:02 - INFO - __main__ - train loss is 12.828962756786495\n",
      "Steps:  29%|▎| 4352/15000 [27:39<32:08,  5.52it/s, lr=9.87e-6, step_loss=0.0876]07/18/2023 19:31:02 - INFO - __main__ - train loss is 13.046627892646939\n",
      "Steps:  29%|▌ | 4353/15000 [27:40<32:16,  5.50it/s, lr=9.87e-6, step_loss=0.218]07/18/2023 19:31:02 - INFO - __main__ - train loss is 13.178359283600003\n",
      "Steps:  29%|▌ | 4354/15000 [27:40<32:04,  5.53it/s, lr=9.87e-6, step_loss=0.132]07/18/2023 19:31:02 - INFO - __main__ - train loss is 13.231701704207808\n",
      "Steps:  29%|▎| 4355/15000 [27:40<31:56,  5.55it/s, lr=9.87e-6, step_loss=0.0533]07/18/2023 19:31:02 - INFO - __main__ - train loss is 13.29430621350184\n",
      "Steps:  29%|▎| 4356/15000 [27:40<31:51,  5.57it/s, lr=9.87e-6, step_loss=0.0626]07/18/2023 19:31:02 - INFO - __main__ - train loss is 13.31507263192907\n",
      "Steps:  29%|▎| 4357/15000 [27:40<31:48,  5.58it/s, lr=9.87e-6, step_loss=0.0208]07/18/2023 19:31:03 - INFO - __main__ - train loss is 13.317572268191725\n",
      "Steps:  29%|▎| 4358/15000 [27:41<31:46,  5.58it/s, lr=9.87e-6, step_loss=0.0025]07/18/2023 19:31:03 - INFO - __main__ - train loss is 13.511809142772108\n",
      "Steps:  29%|▌ | 4359/15000 [27:41<31:45,  5.58it/s, lr=9.87e-6, step_loss=0.194]07/18/2023 19:31:03 - INFO - __main__ - train loss is 13.55046837264672\n",
      "Steps:  29%|▎| 4360/15000 [27:41<31:44,  5.59it/s, lr=9.87e-6, step_loss=0.0387]07/18/2023 19:31:03 - INFO - __main__ - train loss is 13.556734154932201\n",
      "Steps:  29%|▎| 4361/15000 [27:41<31:43,  5.59it/s, lr=9.87e-6, step_loss=0.0062707/18/2023 19:31:03 - INFO - __main__ - train loss is 13.940131495706737\n",
      "Steps:  29%|▌ | 4362/15000 [27:41<31:41,  5.59it/s, lr=9.87e-6, step_loss=0.383]07/18/2023 19:31:04 - INFO - __main__ - train loss is 14.354974816553295\n",
      "Steps:  29%|▌ | 4363/15000 [27:41<31:41,  5.59it/s, lr=9.87e-6, step_loss=0.415]07/18/2023 19:31:04 - INFO - __main__ - train loss is 15.293345938436687\n",
      "Steps:  29%|▌ | 4364/15000 [27:42<31:39,  5.60it/s, lr=9.87e-6, step_loss=0.938]07/18/2023 19:31:04 - INFO - __main__ - train loss is 15.692653427831829\n",
      "Steps:  29%|▌ | 4365/15000 [27:42<42:31,  4.17it/s, lr=9.87e-6, step_loss=0.399]07/18/2023 19:31:05 - INFO - __main__ - Per validation step average loss is 0.002579527208581567\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Cumulative validation average loss is 0.002579527208581567\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Per validation step average loss is 0.02146952413022518\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Cumulative validation average loss is 0.02404905133880675\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Per validation step average loss is 0.2458445131778717\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Cumulative validation average loss is 0.26989356451667845\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Per validation step average loss is 0.31794339418411255\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Cumulative validation average loss is 0.587836958700791\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Per validation step average loss is 0.10234904289245605\n",
      "07/18/2023 19:31:05 - INFO - __main__ - Cumulative validation average loss is 0.6901860015932471\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Per validation step average loss is 0.5286725163459778\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Cumulative validation average loss is 1.2188585179392248\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Per validation step average loss is 0.49454861879348755\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Cumulative validation average loss is 1.7134071367327124\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Per validation step average loss is 0.007462196052074432\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Cumulative validation average loss is 1.7208693327847868\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Per validation step average loss is 0.11469030380249023\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Cumulative validation average loss is 1.835559636587277\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Per validation step average loss is 0.01410721242427826\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Cumulative validation average loss is 1.8496668490115553\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Per validation step average loss is 0.13261765241622925\n",
      "07/18/2023 19:31:06 - INFO - __main__ - Cumulative validation average loss is 1.9822845014277846\n",
      "07/18/2023 19:31:07 - INFO - __main__ - Per validation step average loss is 0.3908251225948334\n",
      "07/18/2023 19:31:07 - INFO - __main__ - Cumulative validation average loss is 2.373109624022618\n",
      "07/18/2023 19:31:07 - INFO - __main__ - Average validation loss for Epoch 44 is 0.19775913533521816\n",
      "07/18/2023 19:31:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:31:19 - INFO - __main__ - Starting epoch 45\n",
      "07/18/2023 19:31:20 - INFO - __main__ - train loss is 0.0059925043024122715\n",
      "Steps:  29%|▎| 4366/15000 [27:58<14:36:14,  4.94s/it, lr=9.87e-6, step_loss=0.0007/18/2023 19:31:20 - INFO - __main__ - train loss is 0.008884311886504292\n",
      "Steps:  29%|▎| 4367/15000 [27:58<10:23:04,  3.52s/it, lr=9.87e-6, step_loss=0.0007/18/2023 19:31:20 - INFO - __main__ - train loss is 0.09311843034811318\n",
      "Steps:  29%|▎| 4368/15000 [27:58<7:25:51,  2.52s/it, lr=9.87e-6, step_loss=0.08407/18/2023 19:31:21 - INFO - __main__ - train loss is 0.612818778725341\n",
      "Steps:  29%|▎| 4369/15000 [27:58<5:21:37,  1.82s/it, lr=9.87e-6, step_loss=0.52]07/18/2023 19:31:21 - INFO - __main__ - train loss is 1.0046975624281913\n",
      "Steps:  29%|▎| 4370/15000 [27:59<3:54:38,  1.32s/it, lr=9.87e-6, step_loss=0.39207/18/2023 19:31:21 - INFO - __main__ - train loss is 1.0102840822655708\n",
      "Steps:  29%|▎| 4371/15000 [27:59<2:54:02,  1.02it/s, lr=9.87e-6, step_loss=0.00507/18/2023 19:31:21 - INFO - __main__ - train loss is 1.0554011550266296\n",
      "Steps:  29%|▎| 4372/15000 [27:59<2:11:23,  1.35it/s, lr=9.87e-6, step_loss=0.04507/18/2023 19:31:21 - INFO - __main__ - train loss is 1.1621213641483337\n",
      "Steps:  29%|▎| 4373/15000 [27:59<1:41:43,  1.74it/s, lr=9.87e-6, step_loss=0.10707/18/2023 19:31:21 - INFO - __main__ - train loss is 1.222028498770669\n",
      "Steps:  29%|▎| 4374/15000 [27:59<1:20:38,  2.20it/s, lr=9.87e-6, step_loss=0.05907/18/2023 19:31:22 - INFO - __main__ - train loss is 1.4230115313548595\n",
      "Steps:  29%|▎| 4375/15000 [28:00<1:05:53,  2.69it/s, lr=9.87e-6, step_loss=0.20107/18/2023 19:31:22 - INFO - __main__ - train loss is 2.3779234786052257\n",
      "Steps:  29%|▌ | 4376/15000 [28:00<55:34,  3.19it/s, lr=9.87e-6, step_loss=0.955]07/18/2023 19:31:22 - INFO - __main__ - train loss is 2.4358592603821307\n",
      "Steps:  29%|▎| 4377/15000 [28:00<48:20,  3.66it/s, lr=9.87e-6, step_loss=0.0579]07/18/2023 19:31:22 - INFO - __main__ - train loss is 2.882754144491628\n",
      "Steps:  29%|▌ | 4378/15000 [28:00<43:15,  4.09it/s, lr=9.87e-6, step_loss=0.447]07/18/2023 19:31:22 - INFO - __main__ - train loss is 2.9085487176198512\n",
      "Steps:  29%|▎| 4379/15000 [28:00<39:44,  4.45it/s, lr=9.87e-6, step_loss=0.0258]07/18/2023 19:31:23 - INFO - __main__ - train loss is 3.0652440686244518\n",
      "Steps:  29%|▌ | 4380/15000 [28:00<37:16,  4.75it/s, lr=9.87e-6, step_loss=0.157]07/18/2023 19:31:23 - INFO - __main__ - train loss is 3.152208437444642\n",
      "Steps:  29%|▌ | 4381/15000 [28:01<35:30,  4.98it/s, lr=9.87e-6, step_loss=0.087]07/18/2023 19:31:23 - INFO - __main__ - train loss is 3.17504379642196\n",
      "Steps:  29%|▎| 4382/15000 [28:01<34:17,  5.16it/s, lr=9.87e-6, step_loss=0.0228]07/18/2023 19:31:23 - INFO - __main__ - train loss is 3.302120452048257\n",
      "Steps:  29%|▌ | 4383/15000 [28:01<33:29,  5.28it/s, lr=9.87e-6, step_loss=0.127]07/18/2023 19:31:23 - INFO - __main__ - train loss is 3.374029678525403\n",
      "Steps:  29%|▎| 4384/15000 [28:01<33:09,  5.34it/s, lr=9.87e-6, step_loss=0.0719]07/18/2023 19:31:23 - INFO - __main__ - train loss is 3.3819845702964813\n",
      "Steps:  29%|▎| 4385/15000 [28:01<32:41,  5.41it/s, lr=9.87e-6, step_loss=0.0079507/18/2023 19:31:24 - INFO - __main__ - train loss is 3.5083866205532104\n",
      "Steps:  29%|▌ | 4386/15000 [28:02<32:19,  5.47it/s, lr=9.87e-6, step_loss=0.126]07/18/2023 19:31:24 - INFO - __main__ - train loss is 3.5111861010082066\n",
      "Steps:  29%|▎| 4387/15000 [28:02<32:04,  5.51it/s, lr=9.87e-6, step_loss=0.0028]07/18/2023 19:31:24 - INFO - __main__ - train loss is 3.5358998184092343\n",
      "Steps:  29%|▎| 4388/15000 [28:02<31:53,  5.54it/s, lr=9.87e-6, step_loss=0.0247]07/18/2023 19:31:24 - INFO - __main__ - train loss is 3.5596491103060544\n",
      "Steps:  29%|▎| 4389/15000 [28:02<31:46,  5.56it/s, lr=9.87e-6, step_loss=0.0237]07/18/2023 19:31:24 - INFO - __main__ - train loss is 3.6747154747135937\n",
      "Steps:  29%|▌ | 4390/15000 [28:02<31:47,  5.56it/s, lr=9.87e-6, step_loss=0.115]07/18/2023 19:31:25 - INFO - __main__ - train loss is 3.680302742868662\n",
      "Steps:  29%|▎| 4391/15000 [28:02<31:42,  5.58it/s, lr=9.87e-6, step_loss=0.0055907/18/2023 19:31:25 - INFO - __main__ - train loss is 3.6951714605093002\n",
      "Steps:  29%|▎| 4392/15000 [28:03<31:39,  5.59it/s, lr=9.87e-6, step_loss=0.0149]07/18/2023 19:31:25 - INFO - __main__ - train loss is 3.696728273993358\n",
      "Steps:  29%|▎| 4393/15000 [28:03<31:36,  5.59it/s, lr=9.87e-6, step_loss=0.0015607/18/2023 19:31:25 - INFO - __main__ - train loss is 3.7935657200869173\n",
      "Steps:  29%|▎| 4394/15000 [28:03<31:33,  5.60it/s, lr=9.87e-6, step_loss=0.0968]07/18/2023 19:31:25 - INFO - __main__ - train loss is 4.337160557275638\n",
      "Steps:  29%|▌ | 4395/15000 [28:03<31:32,  5.60it/s, lr=9.87e-6, step_loss=0.544]07/18/2023 19:31:25 - INFO - __main__ - train loss is 4.699361651903018\n",
      "Steps:  29%|▌ | 4396/15000 [28:03<31:32,  5.60it/s, lr=9.87e-6, step_loss=0.362]07/18/2023 19:31:26 - INFO - __main__ - train loss is 4.71594931348227\n",
      "Steps:  29%|▎| 4397/15000 [28:03<31:32,  5.60it/s, lr=9.87e-6, step_loss=0.0166]07/18/2023 19:31:26 - INFO - __main__ - train loss is 4.7200592185836285\n",
      "Steps:  29%|▎| 4398/15000 [28:04<31:32,  5.60it/s, lr=9.87e-6, step_loss=0.0041107/18/2023 19:31:26 - INFO - __main__ - train loss is 4.723754117963836\n",
      "Steps:  29%|▎| 4399/15000 [28:04<31:32,  5.60it/s, lr=9.87e-6, step_loss=0.0036907/18/2023 19:31:26 - INFO - __main__ - train loss is 4.750059897778556\n",
      "Steps:  29%|▎| 4400/15000 [28:04<31:31,  5.60it/s, lr=9.87e-6, step_loss=0.0263]07/18/2023 19:31:26 - INFO - __main__ - train loss is 4.7552082042675465\n",
      "Steps:  29%|▎| 4401/15000 [28:04<31:31,  5.60it/s, lr=9.87e-6, step_loss=0.0051507/18/2023 19:31:26 - INFO - __main__ - train loss is 4.758609430165961\n",
      "Steps:  29%|▎| 4402/15000 [28:04<31:32,  5.60it/s, lr=9.87e-6, step_loss=0.0034]07/18/2023 19:31:27 - INFO - __main__ - train loss is 5.014984504552558\n",
      "Steps:  29%|▌ | 4403/15000 [28:05<31:33,  5.60it/s, lr=9.87e-6, step_loss=0.256]07/18/2023 19:31:27 - INFO - __main__ - train loss is 5.096300603123382\n",
      "Steps:  29%|▎| 4404/15000 [28:05<31:33,  5.60it/s, lr=9.87e-6, step_loss=0.0813]07/18/2023 19:31:27 - INFO - __main__ - train loss is 5.1471594732720405\n",
      "Steps:  29%|▎| 4405/15000 [28:05<31:34,  5.59it/s, lr=9.87e-6, step_loss=0.0509]07/18/2023 19:31:27 - INFO - __main__ - train loss is 5.188374319346622\n",
      "Steps:  29%|▎| 4406/15000 [28:05<31:32,  5.60it/s, lr=9.87e-6, step_loss=0.0412]07/18/2023 19:31:27 - INFO - __main__ - train loss is 5.199637121753767\n",
      "Steps:  29%|▎| 4407/15000 [28:05<31:31,  5.60it/s, lr=9.87e-6, step_loss=0.0113]07/18/2023 19:31:28 - INFO - __main__ - train loss is 5.841087407665327\n",
      "Steps:  29%|▌ | 4408/15000 [28:05<31:49,  5.55it/s, lr=9.87e-6, step_loss=0.641]07/18/2023 19:31:28 - INFO - __main__ - train loss is 6.423875338630751\n",
      "Steps:  29%|▌ | 4409/15000 [28:06<31:49,  5.55it/s, lr=9.87e-6, step_loss=0.583]07/18/2023 19:31:28 - INFO - __main__ - train loss is 6.427034902852029\n",
      "Steps:  29%|▎| 4410/15000 [28:06<31:54,  5.53it/s, lr=9.87e-6, step_loss=0.0031607/18/2023 19:31:28 - INFO - __main__ - train loss is 6.637914496939629\n",
      "Steps:  29%|▌ | 4411/15000 [28:06<32:04,  5.50it/s, lr=9.87e-6, step_loss=0.211]07/18/2023 19:31:28 - INFO - __main__ - train loss is 6.791690859477967\n",
      "Steps:  29%|▌ | 4412/15000 [28:06<32:17,  5.46it/s, lr=9.87e-6, step_loss=0.154]07/18/2023 19:31:28 - INFO - __main__ - train loss is 6.837446216028184\n",
      "Steps:  29%|▎| 4413/15000 [28:06<32:09,  5.49it/s, lr=9.87e-6, step_loss=0.0458]07/18/2023 19:31:29 - INFO - __main__ - train loss is 6.840746539412066\n",
      "Steps:  29%|▎| 4414/15000 [28:07<31:56,  5.52it/s, lr=9.87e-6, step_loss=0.0033]07/18/2023 19:31:29 - INFO - __main__ - train loss is 6.849874085513875\n",
      "Steps:  29%|▎| 4415/15000 [28:07<31:48,  5.54it/s, lr=9.87e-6, step_loss=0.0091307/18/2023 19:31:29 - INFO - __main__ - train loss is 7.180067783920094\n",
      "Steps:  29%|▉  | 4416/15000 [28:07<31:41,  5.57it/s, lr=9.87e-6, step_loss=0.33]07/18/2023 19:31:29 - INFO - __main__ - train loss is 7.181806032313034\n",
      "Steps:  29%|▎| 4417/15000 [28:07<31:37,  5.58it/s, lr=9.87e-6, step_loss=0.0017407/18/2023 19:31:29 - INFO - __main__ - train loss is 7.289991442812607\n",
      "Steps:  29%|▌ | 4418/15000 [28:07<31:34,  5.59it/s, lr=9.87e-6, step_loss=0.108]07/18/2023 19:31:30 - INFO - __main__ - train loss is 7.294301742454991\n",
      "Steps:  29%|▎| 4419/15000 [28:07<31:47,  5.55it/s, lr=9.87e-6, step_loss=0.0043107/18/2023 19:31:30 - INFO - __main__ - train loss is 7.30079669947736\n",
      "Steps:  29%|▎| 4420/15000 [28:08<31:40,  5.57it/s, lr=9.87e-6, step_loss=0.0064907/18/2023 19:31:30 - INFO - __main__ - train loss is 7.322096661431715\n",
      "Steps:  29%|▎| 4421/15000 [28:08<31:35,  5.58it/s, lr=9.87e-6, step_loss=0.0213]07/18/2023 19:31:30 - INFO - __main__ - train loss is 7.366681185318157\n",
      "Steps:  29%|▎| 4422/15000 [28:08<31:30,  5.59it/s, lr=9.87e-6, step_loss=0.0446]07/18/2023 19:31:30 - INFO - __main__ - train loss is 7.392568562878296\n",
      "Steps:  29%|▎| 4423/15000 [28:08<31:29,  5.60it/s, lr=9.87e-6, step_loss=0.0259]07/18/2023 19:31:30 - INFO - __main__ - train loss is 7.395137866260484\n",
      "Steps:  29%|▎| 4424/15000 [28:08<31:27,  5.60it/s, lr=9.87e-6, step_loss=0.0025707/18/2023 19:31:31 - INFO - __main__ - train loss is 7.477788378717378\n",
      "Steps:  30%|▎| 4425/15000 [28:08<31:25,  5.61it/s, lr=9.87e-6, step_loss=0.0827]07/18/2023 19:31:31 - INFO - __main__ - train loss is 7.496444103540853\n",
      "Steps:  30%|▎| 4426/15000 [28:09<31:24,  5.61it/s, lr=9.87e-6, step_loss=0.0187]07/18/2023 19:31:31 - INFO - __main__ - train loss is 7.499423814704642\n",
      "Steps:  30%|▎| 4427/15000 [28:09<31:25,  5.61it/s, lr=9.87e-6, step_loss=0.0029807/18/2023 19:31:31 - INFO - __main__ - train loss is 7.849684310844168\n",
      "Steps:  30%|▉  | 4428/15000 [28:09<31:24,  5.61it/s, lr=9.87e-6, step_loss=0.35]07/18/2023 19:31:31 - INFO - __main__ - train loss is 7.870147878071293\n",
      "Steps:  30%|▎| 4429/15000 [28:09<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.0205]07/18/2023 19:31:32 - INFO - __main__ - train loss is 8.076679790159687\n",
      "Steps:  30%|▌ | 4430/15000 [28:09<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.207]07/18/2023 19:31:32 - INFO - __main__ - train loss is 8.118327101459727\n",
      "Steps:  30%|▎| 4431/15000 [28:10<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.0416]07/18/2023 19:31:32 - INFO - __main__ - train loss is 8.153505762806162\n",
      "Steps:  30%|▎| 4432/15000 [28:10<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.0352]07/18/2023 19:31:32 - INFO - __main__ - train loss is 8.312253465643153\n",
      "Steps:  30%|▌ | 4433/15000 [28:10<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.159]07/18/2023 19:31:32 - INFO - __main__ - train loss is 8.802840461721644\n",
      "Steps:  30%|▌ | 4434/15000 [28:10<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.491]07/18/2023 19:31:32 - INFO - __main__ - train loss is 8.951381524791941\n",
      "Steps:  30%|▌ | 4435/15000 [28:10<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.149]07/18/2023 19:31:33 - INFO - __main__ - train loss is 9.080948820104823\n",
      "Steps:  30%|▉  | 4436/15000 [28:10<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.13]07/18/2023 19:31:33 - INFO - __main__ - train loss is 9.463328202953562\n",
      "Steps:  30%|▌ | 4437/15000 [28:11<31:23,  5.61it/s, lr=9.87e-6, step_loss=0.382]07/18/2023 19:31:33 - INFO - __main__ - train loss is 9.63894878863357\n",
      "Steps:  30%|▌ | 4438/15000 [28:11<31:22,  5.61it/s, lr=9.87e-6, step_loss=0.176]07/18/2023 19:31:33 - INFO - __main__ - train loss is 9.918139090528712\n",
      "Steps:  30%|▌ | 4439/15000 [28:11<31:22,  5.61it/s, lr=9.87e-6, step_loss=0.279]07/18/2023 19:31:33 - INFO - __main__ - train loss is 9.924272004747763\n",
      "Steps:  30%|▎| 4440/15000 [28:11<31:22,  5.61it/s, lr=9.87e-6, step_loss=0.0061307/18/2023 19:31:33 - INFO - __main__ - train loss is 9.940158616984263\n",
      "Steps:  30%|▎| 4441/15000 [28:11<31:22,  5.61it/s, lr=9.87e-6, step_loss=0.0159]07/18/2023 19:31:34 - INFO - __main__ - train loss is 10.174702864373103\n",
      "Steps:  30%|▌ | 4442/15000 [28:12<31:20,  5.61it/s, lr=9.87e-6, step_loss=0.235]07/18/2023 19:31:34 - INFO - __main__ - train loss is 10.2154617162887\n",
      "Steps:  30%|▎| 4443/15000 [28:12<31:21,  5.61it/s, lr=9.87e-6, step_loss=0.0408]07/18/2023 19:31:34 - INFO - __main__ - train loss is 10.303019017213956\n",
      "Steps:  30%|▎| 4444/15000 [28:12<31:20,  5.61it/s, lr=9.87e-6, step_loss=0.0876]07/18/2023 19:31:34 - INFO - __main__ - train loss is 10.348107010358945\n",
      "Steps:  30%|▎| 4445/15000 [28:12<31:20,  5.61it/s, lr=9.87e-6, step_loss=0.0451]07/18/2023 19:31:34 - INFO - __main__ - train loss is 10.814887464279309\n",
      "Steps:  30%|▌ | 4446/15000 [28:12<31:19,  5.61it/s, lr=9.87e-6, step_loss=0.467]07/18/2023 19:31:35 - INFO - __main__ - train loss is 10.891152411932126\n",
      "Steps:  30%|▎| 4447/15000 [28:12<31:18,  5.62it/s, lr=9.87e-6, step_loss=0.0763]07/18/2023 19:31:35 - INFO - __main__ - train loss is 10.907022454077378\n",
      "Steps:  30%|▎| 4448/15000 [28:13<31:18,  5.62it/s, lr=9.87e-6, step_loss=0.0159]07/18/2023 19:31:35 - INFO - __main__ - train loss is 10.934823885792866\n",
      "Steps:  30%|▎| 4449/15000 [28:13<31:18,  5.62it/s, lr=9.87e-6, step_loss=0.0278]07/18/2023 19:31:35 - INFO - __main__ - train loss is 11.21044971072115\n",
      "Steps:  30%|▌ | 4450/15000 [28:13<31:17,  5.62it/s, lr=9.87e-6, step_loss=0.276]07/18/2023 19:31:35 - INFO - __main__ - train loss is 11.498293981188908\n",
      "Steps:  30%|▌ | 4451/15000 [28:13<31:16,  5.62it/s, lr=9.87e-6, step_loss=0.288]07/18/2023 19:31:35 - INFO - __main__ - train loss is 11.517581388587132\n",
      "Steps:  30%|▎| 4452/15000 [28:13<31:15,  5.62it/s, lr=9.87e-6, step_loss=0.0193]07/18/2023 19:31:36 - INFO - __main__ - train loss is 11.644883319968358\n",
      "Steps:  30%|▌ | 4453/15000 [28:13<31:15,  5.62it/s, lr=9.87e-6, step_loss=0.127]07/18/2023 19:31:36 - INFO - __main__ - train loss is 11.673098501050845\n",
      "Steps:  30%|▎| 4454/15000 [28:14<31:15,  5.62it/s, lr=9.87e-6, step_loss=0.0282]07/18/2023 19:31:36 - INFO - __main__ - train loss is 11.828515824163333\n",
      "Steps:  30%|▌ | 4455/15000 [28:14<31:15,  5.62it/s, lr=9.87e-6, step_loss=0.155]07/18/2023 19:31:36 - INFO - __main__ - train loss is 11.930141050601378\n",
      "Steps:  30%|▌ | 4456/15000 [28:14<31:14,  5.62it/s, lr=9.87e-6, step_loss=0.102]07/18/2023 19:31:36 - INFO - __main__ - train loss is 11.933725235285237\n",
      "Steps:  30%|▎| 4457/15000 [28:14<31:14,  5.62it/s, lr=9.87e-6, step_loss=0.0035807/18/2023 19:31:36 - INFO - __main__ - train loss is 11.958420197712258\n",
      "Steps:  30%|▎| 4458/15000 [28:14<31:13,  5.63it/s, lr=9.87e-6, step_loss=0.0247]07/18/2023 19:31:37 - INFO - __main__ - train loss is 11.994196742074564\n",
      "Steps:  30%|▎| 4459/15000 [28:15<31:13,  5.63it/s, lr=9.87e-6, step_loss=0.0358]07/18/2023 19:31:37 - INFO - __main__ - train loss is 12.014382700668648\n",
      "Steps:  30%|▎| 4460/15000 [28:15<31:13,  5.63it/s, lr=9.87e-6, step_loss=0.0202]07/18/2023 19:31:37 - INFO - __main__ - train loss is 12.422118644462898\n",
      "Steps:  30%|▌ | 4461/15000 [28:15<31:13,  5.63it/s, lr=9.87e-6, step_loss=0.408]07/18/2023 19:31:37 - INFO - __main__ - train loss is 12.523407633649185\n",
      "Steps:  30%|▌ | 4462/15000 [28:15<41:42,  4.21it/s, lr=9.86e-6, step_loss=0.101]07/18/2023 19:31:38 - INFO - __main__ - Per validation step average loss is 0.4376883804798126\n",
      "07/18/2023 19:31:38 - INFO - __main__ - Cumulative validation average loss is 0.4376883804798126\n",
      "07/18/2023 19:31:38 - INFO - __main__ - Per validation step average loss is 0.003668430494144559\n",
      "07/18/2023 19:31:38 - INFO - __main__ - Cumulative validation average loss is 0.4413568109739572\n",
      "07/18/2023 19:31:38 - INFO - __main__ - Per validation step average loss is 0.9411939382553101\n",
      "07/18/2023 19:31:38 - INFO - __main__ - Cumulative validation average loss is 1.3825507492292672\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Per validation step average loss is 0.5324882864952087\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Cumulative validation average loss is 1.915039035724476\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Per validation step average loss is 0.32891783118247986\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Cumulative validation average loss is 2.243956866906956\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Per validation step average loss is 0.01220426894724369\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Cumulative validation average loss is 2.2561611358541995\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Per validation step average loss is 0.001566715887747705\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Cumulative validation average loss is 2.2577278517419472\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Per validation step average loss is 0.40823793411254883\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Cumulative validation average loss is 2.665965785854496\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Per validation step average loss is 0.18975786864757538\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Cumulative validation average loss is 2.8557236545020714\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Per validation step average loss is 0.18710173666477203\n",
      "07/18/2023 19:31:39 - INFO - __main__ - Cumulative validation average loss is 3.0428253911668435\n",
      "07/18/2023 19:31:40 - INFO - __main__ - Per validation step average loss is 0.0028648003935813904\n",
      "07/18/2023 19:31:40 - INFO - __main__ - Cumulative validation average loss is 3.045690191560425\n",
      "07/18/2023 19:31:40 - INFO - __main__ - Per validation step average loss is 0.027728654444217682\n",
      "07/18/2023 19:31:40 - INFO - __main__ - Cumulative validation average loss is 3.0734188460046425\n",
      "07/18/2023 19:31:40 - INFO - __main__ - Average validation loss for Epoch 45 is 0.25611823716705356\n",
      "07/18/2023 19:31:40 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:31:53 - INFO - __main__ - Starting epoch 46\n",
      "07/18/2023 19:31:53 - INFO - __main__ - train loss is 0.003428046591579914\n",
      "Steps:  30%|▎| 4463/15000 [28:31<14:24:06,  4.92s/it, lr=9.86e-6, step_loss=0.0007/18/2023 19:31:53 - INFO - __main__ - train loss is 0.060986888594925404\n",
      "Steps:  30%|▎| 4464/15000 [28:31<10:14:14,  3.50s/it, lr=9.86e-6, step_loss=0.0507/18/2023 19:31:54 - INFO - __main__ - train loss is 0.17918020207434893\n",
      "Steps:  30%|▎| 4465/15000 [28:31<7:19:18,  2.50s/it, lr=9.86e-6, step_loss=0.11807/18/2023 19:31:54 - INFO - __main__ - train loss is 0.29205977637320757\n",
      "Steps:  30%|▎| 4466/15000 [28:32<5:16:51,  1.80s/it, lr=9.86e-6, step_loss=0.11307/18/2023 19:31:54 - INFO - __main__ - train loss is 0.3600210892036557\n",
      "Steps:  30%|▎| 4467/15000 [28:32<3:51:11,  1.32s/it, lr=9.86e-6, step_loss=0.06807/18/2023 19:31:54 - INFO - __main__ - train loss is 0.3980418862774968\n",
      "Steps:  30%|▎| 4468/15000 [28:32<2:51:48,  1.02it/s, lr=9.86e-6, step_loss=0.03807/18/2023 19:31:54 - INFO - __main__ - train loss is 0.4252463346347213\n",
      "Steps:  30%|▎| 4469/15000 [28:32<2:10:27,  1.35it/s, lr=9.86e-6, step_loss=0.02707/18/2023 19:31:55 - INFO - __main__ - train loss is 0.43370550964027643\n",
      "Steps:  30%|▎| 4470/15000 [28:32<1:40:57,  1.74it/s, lr=9.86e-6, step_loss=0.00807/18/2023 19:31:55 - INFO - __main__ - train loss is 0.45000502560287714\n",
      "Steps:  30%|▎| 4471/15000 [28:33<1:20:01,  2.19it/s, lr=9.86e-6, step_loss=0.01607/18/2023 19:31:55 - INFO - __main__ - train loss is 0.7948984215036035\n",
      "Steps:  30%|▎| 4472/15000 [28:33<1:05:20,  2.69it/s, lr=9.86e-6, step_loss=0.34507/18/2023 19:31:55 - INFO - __main__ - train loss is 0.9456320414319634\n",
      "Steps:  30%|▌ | 4473/15000 [28:33<55:04,  3.19it/s, lr=9.86e-6, step_loss=0.151]07/18/2023 19:31:55 - INFO - __main__ - train loss is 1.0140684405341744\n",
      "Steps:  30%|▎| 4474/15000 [28:33<47:52,  3.66it/s, lr=9.86e-6, step_loss=0.0684]07/18/2023 19:31:55 - INFO - __main__ - train loss is 1.3723036209121346\n",
      "Steps:  30%|▌ | 4475/15000 [28:33<42:50,  4.10it/s, lr=9.86e-6, step_loss=0.358]07/18/2023 19:31:56 - INFO - __main__ - train loss is 1.4012638637796044\n",
      "Steps:  30%|▌ | 4476/15000 [28:33<39:19,  4.46it/s, lr=9.86e-6, step_loss=0.029]07/18/2023 19:31:56 - INFO - __main__ - train loss is 1.710506827570498\n",
      "Steps:  30%|▌ | 4477/15000 [28:34<36:53,  4.75it/s, lr=9.86e-6, step_loss=0.309]07/18/2023 19:31:56 - INFO - __main__ - train loss is 2.1372198769822717\n",
      "Steps:  30%|▌ | 4478/15000 [28:34<35:09,  4.99it/s, lr=9.86e-6, step_loss=0.427]07/18/2023 19:31:56 - INFO - __main__ - train loss is 2.287646026350558\n",
      "Steps:  30%|▉  | 4479/15000 [28:34<33:56,  5.17it/s, lr=9.86e-6, step_loss=0.15]07/18/2023 19:31:56 - INFO - __main__ - train loss is 2.2910125465132296\n",
      "Steps:  30%|▎| 4480/15000 [28:34<33:06,  5.29it/s, lr=9.86e-6, step_loss=0.0033707/18/2023 19:31:56 - INFO - __main__ - train loss is 2.619359901640564\n",
      "Steps:  30%|▌ | 4481/15000 [28:34<32:33,  5.38it/s, lr=9.86e-6, step_loss=0.328]07/18/2023 19:31:57 - INFO - __main__ - train loss is 2.6773502440191805\n",
      "Steps:  30%|▌ | 4482/15000 [28:35<32:08,  5.45it/s, lr=9.86e-6, step_loss=0.058]07/18/2023 19:31:57 - INFO - __main__ - train loss is 2.7194907725788653\n",
      "Steps:  30%|▎| 4483/15000 [28:35<31:52,  5.50it/s, lr=9.86e-6, step_loss=0.0421]07/18/2023 19:31:57 - INFO - __main__ - train loss is 2.8517883480526507\n",
      "Steps:  30%|▌ | 4484/15000 [28:35<31:39,  5.54it/s, lr=9.86e-6, step_loss=0.132]07/18/2023 19:31:57 - INFO - __main__ - train loss is 2.857179554644972\n",
      "Steps:  30%|▎| 4485/15000 [28:35<31:31,  5.56it/s, lr=9.86e-6, step_loss=0.0053907/18/2023 19:31:57 - INFO - __main__ - train loss is 3.0250504934228957\n",
      "Steps:  30%|▌ | 4486/15000 [28:35<31:25,  5.58it/s, lr=9.86e-6, step_loss=0.168]07/18/2023 19:31:58 - INFO - __main__ - train loss is 3.3567456626333296\n",
      "Steps:  30%|▌ | 4487/15000 [28:35<31:21,  5.59it/s, lr=9.86e-6, step_loss=0.332]07/18/2023 19:31:58 - INFO - __main__ - train loss is 3.6649165474809706\n",
      "Steps:  30%|▌ | 4488/15000 [28:36<31:18,  5.60it/s, lr=9.86e-6, step_loss=0.308]07/18/2023 19:31:58 - INFO - __main__ - train loss is 3.6982137435115874\n",
      "Steps:  30%|▎| 4489/15000 [28:36<31:17,  5.60it/s, lr=9.86e-6, step_loss=0.0333]07/18/2023 19:31:58 - INFO - __main__ - train loss is 3.7618081220425665\n",
      "Steps:  30%|▎| 4490/15000 [28:36<31:15,  5.60it/s, lr=9.86e-6, step_loss=0.0636]07/18/2023 19:31:58 - INFO - __main__ - train loss is 4.3590361722745\n",
      "Steps:  30%|▌ | 4491/15000 [28:36<31:14,  5.61it/s, lr=9.86e-6, step_loss=0.597]07/18/2023 19:31:58 - INFO - __main__ - train loss is 4.639276827219874\n",
      "Steps:  30%|▉  | 4492/15000 [28:36<31:13,  5.61it/s, lr=9.86e-6, step_loss=0.28]07/18/2023 19:31:59 - INFO - __main__ - train loss is 4.721349129918963\n",
      "Steps:  30%|▎| 4493/15000 [28:37<31:12,  5.61it/s, lr=9.86e-6, step_loss=0.0821]07/18/2023 19:31:59 - INFO - __main__ - train loss is 4.959307963494211\n",
      "Steps:  30%|▌ | 4494/15000 [28:37<31:10,  5.62it/s, lr=9.86e-6, step_loss=0.238]07/18/2023 19:31:59 - INFO - __main__ - train loss is 4.99467376479879\n",
      "Steps:  30%|▎| 4495/15000 [28:37<31:10,  5.62it/s, lr=9.86e-6, step_loss=0.0354]07/18/2023 19:31:59 - INFO - __main__ - train loss is 5.03072956064716\n",
      "Steps:  30%|▎| 4496/15000 [28:37<31:10,  5.62it/s, lr=9.86e-6, step_loss=0.0361]07/18/2023 19:31:59 - INFO - __main__ - train loss is 5.067401728127152\n",
      "Steps:  30%|▎| 4497/15000 [28:37<31:09,  5.62it/s, lr=9.86e-6, step_loss=0.0367]07/18/2023 19:32:00 - INFO - __main__ - train loss is 5.167466370854527\n",
      "Steps:  30%|█▏  | 4498/15000 [28:37<31:11,  5.61it/s, lr=9.86e-6, step_loss=0.1]07/18/2023 19:32:00 - INFO - __main__ - train loss is 5.243174953851849\n",
      "Steps:  30%|▎| 4499/15000 [28:38<31:12,  5.61it/s, lr=9.86e-6, step_loss=0.0757]07/18/2023 19:32:00 - INFO - __main__ - train loss is 5.322439132723957\n",
      "Steps:  30%|▎| 4500/15000 [28:38<31:11,  5.61it/s, lr=9.86e-6, step_loss=0.0757]07/18/2023 19:32:00 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-4500\n",
      "07/18/2023 19:32:00 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:32:00,450] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:32:00,454] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-4500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:32:00,454] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-4500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:32:00,462] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-4500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:32:00,462] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-4500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:32:00,483] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-4500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:32:00,484] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-4500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:32:00,484] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:32:00 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-4500/pytorch_model\n",
      "07/18/2023 19:32:00 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-4500/scheduler.bin\n",
      "07/18/2023 19:32:00 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-4500/random_states_0.pkl\n",
      "07/18/2023 19:32:00 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-4500\n",
      "Steps:  30%|▎| 4500/15000 [28:38<31:11,  5.61it/s, lr=9.86e-6, step_loss=0.0793]07/18/2023 19:32:00 - INFO - __main__ - train loss is 5.358409835491329\n",
      "Steps:  30%|▌ | 4501/15000 [28:38<33:03,  5.29it/s, lr=9.86e-6, step_loss=0.036]07/18/2023 19:32:00 - INFO - __main__ - train loss is 5.582647128496319\n",
      "Steps:  30%|▌ | 4502/15000 [28:38<32:28,  5.39it/s, lr=9.86e-6, step_loss=0.224]07/18/2023 19:32:00 - INFO - __main__ - train loss is 5.591073291841894\n",
      "Steps:  30%|▎| 4503/15000 [28:38<32:05,  5.45it/s, lr=9.86e-6, step_loss=0.0084307/18/2023 19:32:01 - INFO - __main__ - train loss is 5.822008239571005\n",
      "Steps:  30%|▌ | 4504/15000 [28:38<31:49,  5.50it/s, lr=9.86e-6, step_loss=0.231]07/18/2023 19:32:01 - INFO - __main__ - train loss is 5.8541435287334025\n",
      "Steps:  30%|▎| 4505/15000 [28:39<31:38,  5.53it/s, lr=9.86e-6, step_loss=0.0321]07/18/2023 19:32:01 - INFO - __main__ - train loss is 6.040492831263691\n",
      "Steps:  30%|▌ | 4506/15000 [28:39<31:29,  5.55it/s, lr=9.86e-6, step_loss=0.186]07/18/2023 19:32:01 - INFO - __main__ - train loss is 6.214791415724903\n",
      "Steps:  30%|▌ | 4507/15000 [28:39<31:22,  5.57it/s, lr=9.86e-6, step_loss=0.174]07/18/2023 19:32:01 - INFO - __main__ - train loss is 6.3032896355725825\n",
      "Steps:  30%|▎| 4508/15000 [28:39<31:18,  5.58it/s, lr=9.86e-6, step_loss=0.0885]07/18/2023 19:32:02 - INFO - __main__ - train loss is 6.447757421527058\n",
      "Steps:  30%|▌ | 4509/15000 [28:39<31:16,  5.59it/s, lr=9.86e-6, step_loss=0.144]07/18/2023 19:32:02 - INFO - __main__ - train loss is 6.452078524976969\n",
      "Steps:  30%|▎| 4510/15000 [28:40<31:15,  5.59it/s, lr=9.86e-6, step_loss=0.0043207/18/2023 19:32:02 - INFO - __main__ - train loss is 6.467273282818496\n",
      "Steps:  30%|▎| 4511/15000 [28:40<31:12,  5.60it/s, lr=9.86e-6, step_loss=0.0152]07/18/2023 19:32:02 - INFO - __main__ - train loss is 6.632650556974113\n",
      "Steps:  30%|▌ | 4512/15000 [28:40<31:11,  5.61it/s, lr=9.86e-6, step_loss=0.165]07/18/2023 19:32:02 - INFO - __main__ - train loss is 6.885337057523429\n",
      "Steps:  30%|▌ | 4513/15000 [28:40<31:10,  5.61it/s, lr=9.86e-6, step_loss=0.253]07/18/2023 19:32:02 - INFO - __main__ - train loss is 6.95433923881501\n",
      "Steps:  30%|▌ | 4514/15000 [28:40<31:08,  5.61it/s, lr=9.86e-6, step_loss=0.069]07/18/2023 19:32:03 - INFO - __main__ - train loss is 6.959493433125317\n",
      "Steps:  30%|▎| 4515/15000 [28:40<31:08,  5.61it/s, lr=9.86e-6, step_loss=0.0051507/18/2023 19:32:03 - INFO - __main__ - train loss is 7.009862479753792\n",
      "Steps:  30%|▎| 4516/15000 [28:41<31:07,  5.61it/s, lr=9.86e-6, step_loss=0.0504]07/18/2023 19:32:03 - INFO - __main__ - train loss is 7.025874485261738\n",
      "Steps:  30%|▌ | 4517/15000 [28:41<31:07,  5.61it/s, lr=9.86e-6, step_loss=0.016]07/18/2023 19:32:03 - INFO - __main__ - train loss is 7.130925943143666\n",
      "Steps:  30%|▌ | 4518/15000 [28:41<31:05,  5.62it/s, lr=9.86e-6, step_loss=0.105]07/18/2023 19:32:03 - INFO - __main__ - train loss is 7.134109199978411\n",
      "Steps:  30%|▎| 4519/15000 [28:41<31:05,  5.62it/s, lr=9.86e-6, step_loss=0.0031807/18/2023 19:32:03 - INFO - __main__ - train loss is 7.14892200846225\n",
      "Steps:  30%|▎| 4520/15000 [28:41<31:05,  5.62it/s, lr=9.86e-6, step_loss=0.0148]07/18/2023 19:32:04 - INFO - __main__ - train loss is 7.152395606972277\n",
      "Steps:  30%|▎| 4521/15000 [28:42<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.0034707/18/2023 19:32:04 - INFO - __main__ - train loss is 7.154969003051519\n",
      "Steps:  30%|▎| 4522/15000 [28:42<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.0025707/18/2023 19:32:04 - INFO - __main__ - train loss is 7.272930201143026\n",
      "Steps:  30%|▌ | 4523/15000 [28:42<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.118]07/18/2023 19:32:04 - INFO - __main__ - train loss is 7.61821761354804\n",
      "Steps:  30%|▌ | 4524/15000 [28:42<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.345]07/18/2023 19:32:04 - INFO - __main__ - train loss is 7.645751604810357\n",
      "Steps:  30%|▎| 4525/15000 [28:42<31:03,  5.62it/s, lr=9.86e-6, step_loss=0.0275]07/18/2023 19:32:05 - INFO - __main__ - train loss is 7.894530365243554\n",
      "Steps:  30%|▌ | 4526/15000 [28:42<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.249]07/18/2023 19:32:05 - INFO - __main__ - train loss is 8.221102962270379\n",
      "Steps:  30%|▌ | 4527/15000 [28:43<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.327]07/18/2023 19:32:05 - INFO - __main__ - train loss is 8.372066447511315\n",
      "Steps:  30%|▌ | 4528/15000 [28:43<31:03,  5.62it/s, lr=9.86e-6, step_loss=0.151]07/18/2023 19:32:05 - INFO - __main__ - train loss is 8.521861234679818\n",
      "Steps:  30%|▉  | 4529/15000 [28:43<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.15]07/18/2023 19:32:05 - INFO - __main__ - train loss is 8.530420042574406\n",
      "Steps:  30%|▎| 4530/15000 [28:43<31:04,  5.62it/s, lr=9.86e-6, step_loss=0.0085607/18/2023 19:32:05 - INFO - __main__ - train loss is 8.789299465715885\n",
      "Steps:  30%|▌ | 4531/15000 [28:43<31:05,  5.61it/s, lr=9.86e-6, step_loss=0.259]07/18/2023 19:32:06 - INFO - __main__ - train loss is 8.811256766319275\n",
      "Steps:  30%|▌ | 4532/15000 [28:43<31:04,  5.61it/s, lr=9.86e-6, step_loss=0.022]07/18/2023 19:32:06 - INFO - __main__ - train loss is 9.392293632030487\n",
      "Steps:  30%|▌ | 4533/15000 [28:44<31:03,  5.62it/s, lr=9.86e-6, step_loss=0.581]07/18/2023 19:32:06 - INFO - __main__ - train loss is 9.437761571258307\n",
      "Steps:  30%|▎| 4534/15000 [28:44<31:03,  5.62it/s, lr=9.86e-6, step_loss=0.0455]07/18/2023 19:32:06 - INFO - __main__ - train loss is 9.439821147825569\n",
      "Steps:  30%|▎| 4535/15000 [28:44<31:02,  5.62it/s, lr=9.86e-6, step_loss=0.0020607/18/2023 19:32:06 - INFO - __main__ - train loss is 9.513531201984733\n",
      "Steps:  30%|▎| 4536/15000 [28:44<31:01,  5.62it/s, lr=9.86e-6, step_loss=0.0737]07/18/2023 19:32:06 - INFO - __main__ - train loss is 9.715738677885383\n",
      "Steps:  30%|▌ | 4537/15000 [28:44<31:01,  5.62it/s, lr=9.86e-6, step_loss=0.202]07/18/2023 19:32:07 - INFO - __main__ - train loss is 9.820055605378002\n",
      "Steps:  30%|▌ | 4538/15000 [28:45<31:01,  5.62it/s, lr=9.86e-6, step_loss=0.104]07/18/2023 19:32:07 - INFO - __main__ - train loss is 9.83071239804849\n",
      "Steps:  30%|▎| 4539/15000 [28:45<31:01,  5.62it/s, lr=9.86e-6, step_loss=0.0107]07/18/2023 19:32:07 - INFO - __main__ - train loss is 10.008987387176603\n",
      "Steps:  30%|▌ | 4540/15000 [28:45<31:02,  5.62it/s, lr=9.86e-6, step_loss=0.178]07/18/2023 19:32:07 - INFO - __main__ - train loss is 10.218010430689901\n",
      "Steps:  30%|▌ | 4541/15000 [28:45<31:02,  5.61it/s, lr=9.86e-6, step_loss=0.209]07/18/2023 19:32:07 - INFO - __main__ - train loss is 10.284943473991007\n",
      "Steps:  30%|▎| 4542/15000 [28:45<31:04,  5.61it/s, lr=9.86e-6, step_loss=0.0669]07/18/2023 19:32:08 - INFO - __main__ - train loss is 10.29925806587562\n",
      "Steps:  30%|▎| 4543/15000 [28:45<31:21,  5.56it/s, lr=9.86e-6, step_loss=0.0143]07/18/2023 19:32:08 - INFO - __main__ - train loss is 10.304448075126857\n",
      "Steps:  30%|▎| 4544/15000 [28:46<31:27,  5.54it/s, lr=9.86e-6, step_loss=0.0051907/18/2023 19:32:08 - INFO - __main__ - train loss is 10.364101092796773\n",
      "Steps:  30%|▎| 4545/15000 [28:46<31:19,  5.56it/s, lr=9.86e-6, step_loss=0.0597]07/18/2023 19:32:08 - INFO - __main__ - train loss is 10.3680290854536\n",
      "Steps:  30%|▎| 4546/15000 [28:46<31:12,  5.58it/s, lr=9.86e-6, step_loss=0.0039307/18/2023 19:32:08 - INFO - __main__ - train loss is 10.42775992071256\n",
      "Steps:  30%|▎| 4547/15000 [28:46<31:07,  5.60it/s, lr=9.86e-6, step_loss=0.0597]07/18/2023 19:32:08 - INFO - __main__ - train loss is 10.436355017591268\n",
      "Steps:  30%|▎| 4548/15000 [28:46<31:03,  5.61it/s, lr=9.86e-6, step_loss=0.0086]07/18/2023 19:32:09 - INFO - __main__ - train loss is 10.480604269076139\n",
      "Steps:  30%|▎| 4549/15000 [28:47<31:04,  5.61it/s, lr=9.86e-6, step_loss=0.0442]07/18/2023 19:32:09 - INFO - __main__ - train loss is 10.536942013073713\n",
      "Steps:  30%|▎| 4550/15000 [28:47<31:02,  5.61it/s, lr=9.86e-6, step_loss=0.0563]07/18/2023 19:32:09 - INFO - __main__ - train loss is 10.538550692144781\n",
      "Steps:  30%|▎| 4551/15000 [28:47<31:01,  5.61it/s, lr=9.86e-6, step_loss=0.0016107/18/2023 19:32:09 - INFO - __main__ - train loss is 10.734622823540121\n",
      "Steps:  30%|▌ | 4552/15000 [28:47<31:01,  5.61it/s, lr=9.86e-6, step_loss=0.196]07/18/2023 19:32:09 - INFO - __main__ - train loss is 10.939206796232611\n",
      "Steps:  30%|▌ | 4553/15000 [28:47<31:11,  5.58it/s, lr=9.86e-6, step_loss=0.205]07/18/2023 19:32:10 - INFO - __main__ - train loss is 10.945313701406121\n",
      "Steps:  30%|▎| 4554/15000 [28:47<31:09,  5.59it/s, lr=9.86e-6, step_loss=0.0061107/18/2023 19:32:10 - INFO - __main__ - train loss is 11.587670097127557\n",
      "Steps:  30%|▌ | 4555/15000 [28:48<31:20,  5.55it/s, lr=9.86e-6, step_loss=0.642]07/18/2023 19:32:10 - INFO - __main__ - train loss is 11.715008536353707\n",
      "Steps:  30%|▌ | 4556/15000 [28:48<31:29,  5.53it/s, lr=9.86e-6, step_loss=0.127]07/18/2023 19:32:10 - INFO - __main__ - train loss is 11.74323969334364\n",
      "Steps:  30%|▎| 4557/15000 [28:48<31:37,  5.50it/s, lr=9.86e-6, step_loss=0.0282]07/18/2023 19:32:10 - INFO - __main__ - train loss is 12.46029119938612\n",
      "Steps:  30%|▌ | 4558/15000 [28:48<31:41,  5.49it/s, lr=9.86e-6, step_loss=0.717]07/18/2023 19:32:11 - INFO - __main__ - train loss is 12.553041495382786\n",
      "Steps:  30%|▎| 4559/15000 [28:49<42:30,  4.09it/s, lr=9.86e-6, step_loss=0.0928]07/18/2023 19:32:11 - INFO - __main__ - Per validation step average loss is 0.3100970983505249\n",
      "07/18/2023 19:32:11 - INFO - __main__ - Cumulative validation average loss is 0.3100970983505249\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.005663858726620674\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 0.3157609570771456\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.4344003200531006\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 0.7501612771302462\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.17691460251808167\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 0.9270758796483278\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.37935611605644226\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 1.30643199570477\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.1309530884027481\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 1.4373850841075182\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.09581949561834335\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 1.5332045797258615\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Per validation step average loss is 0.3956965506076813\n",
      "07/18/2023 19:32:12 - INFO - __main__ - Cumulative validation average loss is 1.9289011303335428\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Per validation step average loss is 0.00437255809083581\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Cumulative validation average loss is 1.9332736884243786\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Per validation step average loss is 0.20201435685157776\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Cumulative validation average loss is 2.1352880452759564\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Per validation step average loss is 0.00338387512601912\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Cumulative validation average loss is 2.1386719204019755\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Per validation step average loss is 0.4651598334312439\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Cumulative validation average loss is 2.6038317538332194\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Average validation loss for Epoch 46 is 0.21698597948610163\n",
      "07/18/2023 19:32:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:32:26 - INFO - __main__ - Starting epoch 47\n",
      "07/18/2023 19:32:26 - INFO - __main__ - train loss is 0.11075419187545776\n",
      "Steps:  30%|▎| 4560/15000 [29:04<14:10:44,  4.89s/it, lr=9.86e-6, step_loss=0.1107/18/2023 19:32:27 - INFO - __main__ - train loss is 0.11552724475041032\n",
      "Steps:  30%|▎| 4561/15000 [29:04<10:05:17,  3.48s/it, lr=9.86e-6, step_loss=0.0007/18/2023 19:32:27 - INFO - __main__ - train loss is 0.28461152547970414\n",
      "Steps:  30%|▎| 4562/15000 [29:05<7:14:03,  2.50s/it, lr=9.86e-6, step_loss=0.16907/18/2023 19:32:27 - INFO - __main__ - train loss is 0.4121412062086165\n",
      "Steps:  30%|▎| 4563/15000 [29:05<5:14:17,  1.81s/it, lr=9.86e-6, step_loss=0.12807/18/2023 19:32:27 - INFO - __main__ - train loss is 0.9387574219144881\n",
      "Steps:  30%|▎| 4564/15000 [29:05<3:51:02,  1.33s/it, lr=9.86e-6, step_loss=0.52707/18/2023 19:32:27 - INFO - __main__ - train loss is 0.9555782289244235\n",
      "Steps:  30%|▎| 4565/15000 [29:05<2:53:17,  1.00it/s, lr=9.86e-6, step_loss=0.01607/18/2023 19:32:28 - INFO - __main__ - train loss is 1.2583195776678622\n",
      "Steps:  30%|▎| 4566/15000 [29:06<2:12:41,  1.31it/s, lr=9.86e-6, step_loss=0.30307/18/2023 19:32:28 - INFO - __main__ - train loss is 1.5184406847693026\n",
      "Steps:  30%|▎| 4567/15000 [29:06<1:44:01,  1.67it/s, lr=9.86e-6, step_loss=0.26]07/18/2023 19:32:28 - INFO - __main__ - train loss is 1.5257552941329777\n",
      "Steps:  30%|▎| 4568/15000 [29:06<1:23:39,  2.08it/s, lr=9.86e-6, step_loss=0.00707/18/2023 19:32:28 - INFO - __main__ - train loss is 1.5400255643762648\n",
      "Steps:  30%|▎| 4569/15000 [29:06<1:08:10,  2.55it/s, lr=9.86e-6, step_loss=0.01407/18/2023 19:32:28 - INFO - __main__ - train loss is 1.5459041660651565\n",
      "Steps:  30%|▎| 4570/15000 [29:06<57:30,  3.02it/s, lr=9.86e-6, step_loss=0.0058807/18/2023 19:32:29 - INFO - __main__ - train loss is 1.5907002007588744\n",
      "Steps:  30%|▎| 4571/15000 [29:06<49:49,  3.49it/s, lr=9.86e-6, step_loss=0.0448]07/18/2023 19:32:29 - INFO - __main__ - train loss is 1.7029910599812865\n",
      "Steps:  30%|▌ | 4572/15000 [29:07<44:22,  3.92it/s, lr=9.86e-6, step_loss=0.112]07/18/2023 19:32:29 - INFO - __main__ - train loss is 2.4539633309468627\n",
      "Steps:  30%|▌ | 4573/15000 [29:07<40:27,  4.29it/s, lr=9.86e-6, step_loss=0.751]07/18/2023 19:32:29 - INFO - __main__ - train loss is 2.548018059693277\n",
      "Steps:  30%|▎| 4574/15000 [29:07<37:45,  4.60it/s, lr=9.86e-6, step_loss=0.0941]07/18/2023 19:32:29 - INFO - __main__ - train loss is 2.5509297936223447\n",
      "Steps:  30%|▎| 4575/15000 [29:07<35:50,  4.85it/s, lr=9.86e-6, step_loss=0.0029107/18/2023 19:32:29 - INFO - __main__ - train loss is 2.578093984629959\n",
      "Steps:  31%|▎| 4576/15000 [29:07<34:28,  5.04it/s, lr=9.86e-6, step_loss=0.0272]07/18/2023 19:32:30 - INFO - __main__ - train loss is 2.5795416177716106\n",
      "Steps:  31%|▎| 4577/15000 [29:08<33:36,  5.17it/s, lr=9.86e-6, step_loss=0.0014507/18/2023 19:32:30 - INFO - __main__ - train loss is 2.8055548758711666\n",
      "Steps:  31%|▌ | 4578/15000 [29:08<32:57,  5.27it/s, lr=9.86e-6, step_loss=0.226]07/18/2023 19:32:30 - INFO - __main__ - train loss is 2.808697377331555\n",
      "Steps:  31%|▎| 4579/15000 [29:08<32:28,  5.35it/s, lr=9.86e-6, step_loss=0.0031407/18/2023 19:32:30 - INFO - __main__ - train loss is 2.8108004522509873\n",
      "Steps:  31%|▎| 4580/15000 [29:08<32:08,  5.40it/s, lr=9.86e-6, step_loss=0.0021]07/18/2023 19:32:30 - INFO - __main__ - train loss is 2.9411777150817215\n",
      "Steps:  31%|▉  | 4581/15000 [29:08<31:54,  5.44it/s, lr=9.86e-6, step_loss=0.13]07/18/2023 19:32:31 - INFO - __main__ - train loss is 2.9440060516353697\n",
      "Steps:  31%|▎| 4582/15000 [29:08<31:45,  5.47it/s, lr=9.86e-6, step_loss=0.0028307/18/2023 19:32:31 - INFO - __main__ - train loss is 2.9764622000511736\n",
      "Steps:  31%|▎| 4583/15000 [29:09<31:38,  5.49it/s, lr=9.86e-6, step_loss=0.0325]07/18/2023 19:32:31 - INFO - __main__ - train loss is 3.1745065001305193\n",
      "Steps:  31%|▌ | 4584/15000 [29:09<31:35,  5.50it/s, lr=9.86e-6, step_loss=0.198]07/18/2023 19:32:31 - INFO - __main__ - train loss is 3.1786759512033314\n",
      "Steps:  31%|▎| 4585/15000 [29:09<31:43,  5.47it/s, lr=9.86e-6, step_loss=0.0041707/18/2023 19:32:31 - INFO - __main__ - train loss is 3.8723778740968555\n",
      "Steps:  31%|▌ | 4586/15000 [29:09<31:37,  5.49it/s, lr=9.86e-6, step_loss=0.694]07/18/2023 19:32:31 - INFO - __main__ - train loss is 3.945478500565514\n",
      "Steps:  31%|▎| 4587/15000 [29:09<31:33,  5.50it/s, lr=9.86e-6, step_loss=0.0731]07/18/2023 19:32:32 - INFO - __main__ - train loss is 4.096524299820885\n",
      "Steps:  31%|▌ | 4588/15000 [29:10<31:29,  5.51it/s, lr=9.86e-6, step_loss=0.151]07/18/2023 19:32:32 - INFO - __main__ - train loss is 4.126883482327685\n",
      "Steps:  31%|▎| 4589/15000 [29:10<31:27,  5.52it/s, lr=9.86e-6, step_loss=0.0304]07/18/2023 19:32:32 - INFO - __main__ - train loss is 4.335914691677317\n",
      "Steps:  31%|▌ | 4590/15000 [29:10<31:24,  5.52it/s, lr=9.86e-6, step_loss=0.209]07/18/2023 19:32:32 - INFO - __main__ - train loss is 4.353471683105454\n",
      "Steps:  31%|▎| 4591/15000 [29:10<31:23,  5.53it/s, lr=9.86e-6, step_loss=0.0176]07/18/2023 19:32:32 - INFO - __main__ - train loss is 4.357661854242906\n",
      "Steps:  31%|▎| 4592/15000 [29:10<31:21,  5.53it/s, lr=9.86e-6, step_loss=0.0041907/18/2023 19:32:33 - INFO - __main__ - train loss is 4.402777734911069\n",
      "Steps:  31%|▎| 4593/15000 [29:10<31:39,  5.48it/s, lr=9.86e-6, step_loss=0.0451]07/18/2023 19:32:33 - INFO - __main__ - train loss is 4.720881286775693\n",
      "Steps:  31%|▌ | 4594/15000 [29:11<32:03,  5.41it/s, lr=9.86e-6, step_loss=0.318]07/18/2023 19:32:33 - INFO - __main__ - train loss is 5.010657015955076\n",
      "Steps:  31%|▉  | 4595/15000 [29:11<31:50,  5.45it/s, lr=9.86e-6, step_loss=0.29]07/18/2023 19:32:33 - INFO - __main__ - train loss is 5.084911469137296\n",
      "Steps:  31%|▎| 4596/15000 [29:11<31:33,  5.50it/s, lr=9.86e-6, step_loss=0.0743]07/18/2023 19:32:33 - INFO - __main__ - train loss is 5.14374579093419\n",
      "Steps:  31%|▎| 4597/15000 [29:11<31:19,  5.53it/s, lr=9.86e-6, step_loss=0.0588]07/18/2023 19:32:33 - INFO - __main__ - train loss is 5.1586342414375395\n",
      "Steps:  31%|▎| 4598/15000 [29:11<31:11,  5.56it/s, lr=9.86e-6, step_loss=0.0149]07/18/2023 19:32:34 - INFO - __main__ - train loss is 5.3186340590473264\n",
      "Steps:  31%|▉  | 4599/15000 [29:12<31:06,  5.57it/s, lr=9.86e-6, step_loss=0.16]07/18/2023 19:32:34 - INFO - __main__ - train loss is 5.419309805845842\n",
      "Steps:  31%|▌ | 4600/15000 [29:12<31:02,  5.59it/s, lr=9.86e-6, step_loss=0.101]07/18/2023 19:32:34 - INFO - __main__ - train loss is 5.493895891821012\n",
      "Steps:  31%|▎| 4601/15000 [29:12<31:00,  5.59it/s, lr=9.86e-6, step_loss=0.0746]07/18/2023 19:32:34 - INFO - __main__ - train loss is 5.74134387425147\n",
      "Steps:  31%|▌ | 4602/15000 [29:12<30:57,  5.60it/s, lr=9.86e-6, step_loss=0.247]07/18/2023 19:32:34 - INFO - __main__ - train loss is 5.7559724857565016\n",
      "Steps:  31%|▎| 4603/15000 [29:12<30:57,  5.60it/s, lr=9.86e-6, step_loss=0.0146]07/18/2023 19:32:35 - INFO - __main__ - train loss is 6.097387294983491\n",
      "Steps:  31%|▌ | 4604/15000 [29:12<30:54,  5.61it/s, lr=9.86e-6, step_loss=0.341]07/18/2023 19:32:35 - INFO - __main__ - train loss is 6.102783196372911\n",
      "Steps:  31%|▎| 4605/15000 [29:13<30:54,  5.60it/s, lr=9.86e-6, step_loss=0.0054]07/18/2023 19:32:35 - INFO - __main__ - train loss is 6.104268052149564\n",
      "Steps:  31%|▎| 4606/15000 [29:13<30:53,  5.61it/s, lr=9.86e-6, step_loss=0.0014807/18/2023 19:32:35 - INFO - __main__ - train loss is 6.122692995239049\n",
      "Steps:  31%|▎| 4607/15000 [29:13<30:54,  5.61it/s, lr=9.86e-6, step_loss=0.0184]07/18/2023 19:32:35 - INFO - __main__ - train loss is 6.27436137991026\n",
      "Steps:  31%|▌ | 4608/15000 [29:13<30:54,  5.60it/s, lr=9.86e-6, step_loss=0.152]07/18/2023 19:32:35 - INFO - __main__ - train loss is 6.305087881628424\n",
      "Steps:  31%|▎| 4609/15000 [29:13<30:52,  5.61it/s, lr=9.86e-6, step_loss=0.0307]07/18/2023 19:32:36 - INFO - __main__ - train loss is 6.450680228415877\n",
      "Steps:  31%|▌ | 4610/15000 [29:14<30:51,  5.61it/s, lr=9.86e-6, step_loss=0.146]07/18/2023 19:32:36 - INFO - __main__ - train loss is 6.5614151381887496\n",
      "Steps:  31%|▌ | 4611/15000 [29:14<30:52,  5.61it/s, lr=9.86e-6, step_loss=0.111]07/18/2023 19:32:36 - INFO - __main__ - train loss is 6.586241135839373\n",
      "Steps:  31%|▎| 4612/15000 [29:14<30:51,  5.61it/s, lr=9.86e-6, step_loss=0.0248]07/18/2023 19:32:36 - INFO - __main__ - train loss is 7.074155578855425\n",
      "Steps:  31%|▌ | 4613/15000 [29:14<30:50,  5.61it/s, lr=9.86e-6, step_loss=0.488]07/18/2023 19:32:36 - INFO - __main__ - train loss is 7.194304163102061\n",
      "Steps:  31%|▉  | 4614/15000 [29:14<30:50,  5.61it/s, lr=9.86e-6, step_loss=0.12]07/18/2023 19:32:37 - INFO - __main__ - train loss is 7.203488113824278\n",
      "Steps:  31%|▎| 4615/15000 [29:14<31:05,  5.57it/s, lr=9.86e-6, step_loss=0.0091807/18/2023 19:32:37 - INFO - __main__ - train loss is 7.300528178457171\n",
      "Steps:  31%|▌ | 4616/15000 [29:15<31:18,  5.53it/s, lr=9.86e-6, step_loss=0.097]07/18/2023 19:32:37 - INFO - __main__ - train loss is 7.673340598586947\n",
      "Steps:  31%|▌ | 4617/15000 [29:15<31:15,  5.54it/s, lr=9.86e-6, step_loss=0.373]07/18/2023 19:32:37 - INFO - __main__ - train loss is 7.683082485105842\n",
      "Steps:  31%|▎| 4618/15000 [29:15<31:07,  5.56it/s, lr=9.86e-6, step_loss=0.0097407/18/2023 19:32:37 - INFO - __main__ - train loss is 7.712991611566395\n",
      "Steps:  31%|▎| 4619/15000 [29:15<31:03,  5.57it/s, lr=9.86e-6, step_loss=0.0299]07/18/2023 19:32:37 - INFO - __main__ - train loss is 8.098711179103702\n",
      "Steps:  31%|▌ | 4620/15000 [29:15<30:57,  5.59it/s, lr=9.86e-6, step_loss=0.386]07/18/2023 19:32:38 - INFO - __main__ - train loss is 8.14152586972341\n",
      "Steps:  31%|▎| 4621/15000 [29:15<30:54,  5.60it/s, lr=9.86e-6, step_loss=0.0428]07/18/2023 19:32:38 - INFO - __main__ - train loss is 8.145548953209072\n",
      "Steps:  31%|▎| 4622/15000 [29:16<30:53,  5.60it/s, lr=9.86e-6, step_loss=0.0040207/18/2023 19:32:38 - INFO - __main__ - train loss is 8.515153928194195\n",
      "Steps:  31%|▉  | 4623/15000 [29:16<30:50,  5.61it/s, lr=9.86e-6, step_loss=0.37]07/18/2023 19:32:38 - INFO - __main__ - train loss is 8.61369294533506\n",
      "Steps:  31%|▎| 4624/15000 [29:16<30:50,  5.61it/s, lr=9.85e-6, step_loss=0.0985]07/18/2023 19:32:38 - INFO - __main__ - train loss is 8.627655398566276\n",
      "Steps:  31%|▌ | 4625/15000 [29:16<30:49,  5.61it/s, lr=9.85e-6, step_loss=0.014]07/18/2023 19:32:38 - INFO - __main__ - train loss is 8.630182437133044\n",
      "Steps:  31%|▎| 4626/15000 [29:16<30:50,  5.61it/s, lr=9.85e-6, step_loss=0.0025307/18/2023 19:32:39 - INFO - __main__ - train loss is 9.092415444087237\n",
      "Steps:  31%|▌ | 4627/15000 [29:17<30:49,  5.61it/s, lr=9.85e-6, step_loss=0.462]07/18/2023 19:32:39 - INFO - __main__ - train loss is 9.112392849754542\n",
      "Steps:  31%|▉  | 4628/15000 [29:17<30:48,  5.61it/s, lr=9.85e-6, step_loss=0.02]07/18/2023 19:32:39 - INFO - __main__ - train loss is 9.213464594911784\n",
      "Steps:  31%|▌ | 4629/15000 [29:17<30:48,  5.61it/s, lr=9.85e-6, step_loss=0.101]07/18/2023 19:32:39 - INFO - __main__ - train loss is 9.244297064375132\n",
      "Steps:  31%|▎| 4630/15000 [29:17<30:48,  5.61it/s, lr=9.85e-6, step_loss=0.0308]07/18/2023 19:32:39 - INFO - __main__ - train loss is 9.424050218891352\n",
      "Steps:  31%|▉  | 4631/15000 [29:17<30:47,  5.61it/s, lr=9.85e-6, step_loss=0.18]07/18/2023 19:32:40 - INFO - __main__ - train loss is 9.427690933924168\n",
      "Steps:  31%|▎| 4632/15000 [29:17<30:46,  5.61it/s, lr=9.85e-6, step_loss=0.0036407/18/2023 19:32:40 - INFO - __main__ - train loss is 9.450212396215647\n",
      "Steps:  31%|▎| 4633/15000 [29:18<30:46,  5.61it/s, lr=9.85e-6, step_loss=0.0225]07/18/2023 19:32:40 - INFO - __main__ - train loss is 9.480327985715121\n",
      "Steps:  31%|▎| 4634/15000 [29:18<30:45,  5.62it/s, lr=9.85e-6, step_loss=0.0301]07/18/2023 19:32:40 - INFO - __main__ - train loss is 9.663652337621897\n",
      "Steps:  31%|▌ | 4635/15000 [29:18<30:45,  5.62it/s, lr=9.85e-6, step_loss=0.183]07/18/2023 19:32:40 - INFO - __main__ - train loss is 9.686989103909582\n",
      "Steps:  31%|▎| 4636/15000 [29:18<30:45,  5.62it/s, lr=9.85e-6, step_loss=0.0233]07/18/2023 19:32:40 - INFO - __main__ - train loss is 9.69488239986822\n",
      "Steps:  31%|▎| 4637/15000 [29:18<30:47,  5.61it/s, lr=9.85e-6, step_loss=0.0078907/18/2023 19:32:41 - INFO - __main__ - train loss is 9.78819005889818\n",
      "Steps:  31%|▎| 4638/15000 [29:19<31:05,  5.55it/s, lr=9.85e-6, step_loss=0.0933]07/18/2023 19:32:41 - INFO - __main__ - train loss is 9.970744393300265\n",
      "Steps:  31%|▌ | 4639/15000 [29:19<31:30,  5.48it/s, lr=9.85e-6, step_loss=0.183]07/18/2023 19:32:41 - INFO - __main__ - train loss is 10.011042311321944\n",
      "Steps:  31%|▎| 4640/15000 [29:19<31:16,  5.52it/s, lr=9.85e-6, step_loss=0.0403]07/18/2023 19:32:41 - INFO - __main__ - train loss is 10.057455397676677\n",
      "Steps:  31%|▎| 4641/15000 [29:19<31:05,  5.55it/s, lr=9.85e-6, step_loss=0.0464]07/18/2023 19:32:41 - INFO - __main__ - train loss is 10.797495461534709\n",
      "Steps:  31%|▉  | 4642/15000 [29:19<31:00,  5.57it/s, lr=9.85e-6, step_loss=0.74]07/18/2023 19:32:42 - INFO - __main__ - train loss is 10.875405646394938\n",
      "Steps:  31%|▎| 4643/15000 [29:19<31:19,  5.51it/s, lr=9.85e-6, step_loss=0.0779]07/18/2023 19:32:42 - INFO - __main__ - train loss is 11.348928041290492\n",
      "Steps:  31%|▌ | 4644/15000 [29:20<31:59,  5.40it/s, lr=9.85e-6, step_loss=0.474]07/18/2023 19:32:42 - INFO - __main__ - train loss is 11.64613140327856\n",
      "Steps:  31%|▌ | 4645/15000 [29:20<32:33,  5.30it/s, lr=9.85e-6, step_loss=0.297]07/18/2023 19:32:42 - INFO - __main__ - train loss is 11.97752622468397\n",
      "Steps:  31%|▌ | 4646/15000 [29:20<32:49,  5.26it/s, lr=9.85e-6, step_loss=0.331]07/18/2023 19:32:42 - INFO - __main__ - train loss is 12.077989056240767\n",
      "Steps:  31%|█▏  | 4647/15000 [29:20<33:00,  5.23it/s, lr=9.85e-6, step_loss=0.1]07/18/2023 19:32:43 - INFO - __main__ - train loss is 12.46804816974327\n",
      "Steps:  31%|▉  | 4648/15000 [29:20<33:08,  5.21it/s, lr=9.85e-6, step_loss=0.39]07/18/2023 19:32:43 - INFO - __main__ - train loss is 12.989639356266707\n",
      "Steps:  31%|▌ | 4649/15000 [29:21<33:13,  5.19it/s, lr=9.85e-6, step_loss=0.522]07/18/2023 19:32:43 - INFO - __main__ - train loss is 13.067340626846999\n",
      "Steps:  31%|▎| 4650/15000 [29:21<33:16,  5.18it/s, lr=9.85e-6, step_loss=0.0777]07/18/2023 19:32:43 - INFO - __main__ - train loss is 13.501480772625655\n",
      "Steps:  31%|▌ | 4651/15000 [29:21<33:32,  5.14it/s, lr=9.85e-6, step_loss=0.434]07/18/2023 19:32:43 - INFO - __main__ - train loss is 13.519993913825601\n",
      "Steps:  31%|▎| 4652/15000 [29:21<33:27,  5.16it/s, lr=9.85e-6, step_loss=0.0185]07/18/2023 19:32:43 - INFO - __main__ - train loss is 13.731598851736635\n",
      "Steps:  31%|▌ | 4653/15000 [29:21<33:24,  5.16it/s, lr=9.85e-6, step_loss=0.212]07/18/2023 19:32:44 - INFO - __main__ - train loss is 14.24112313752994\n",
      "Steps:  31%|▉  | 4654/15000 [29:22<33:24,  5.16it/s, lr=9.85e-6, step_loss=0.51]07/18/2023 19:32:44 - INFO - __main__ - train loss is 15.07814067369327\n",
      "Steps:  31%|▌ | 4655/15000 [29:22<33:24,  5.16it/s, lr=9.85e-6, step_loss=0.837]07/18/2023 19:32:44 - INFO - __main__ - train loss is 15.26712462073192\n",
      "Steps:  31%|▌ | 4656/15000 [29:22<45:41,  3.77it/s, lr=9.85e-6, step_loss=0.189]07/18/2023 19:32:45 - INFO - __main__ - Per validation step average loss is 0.1193854957818985\n",
      "07/18/2023 19:32:45 - INFO - __main__ - Cumulative validation average loss is 0.1193854957818985\n",
      "07/18/2023 19:32:45 - INFO - __main__ - Per validation step average loss is 0.0015626258682459593\n",
      "07/18/2023 19:32:45 - INFO - __main__ - Cumulative validation average loss is 0.12094812165014446\n",
      "07/18/2023 19:32:45 - INFO - __main__ - Per validation step average loss is 0.23726269602775574\n",
      "07/18/2023 19:32:45 - INFO - __main__ - Cumulative validation average loss is 0.3582108176779002\n",
      "07/18/2023 19:32:45 - INFO - __main__ - Per validation step average loss is 0.03842011094093323\n",
      "07/18/2023 19:32:45 - INFO - __main__ - Cumulative validation average loss is 0.3966309286188334\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Per validation step average loss is 0.04868851229548454\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Cumulative validation average loss is 0.44531944091431797\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Per validation step average loss is 0.13677000999450684\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Cumulative validation average loss is 0.5820894509088248\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Per validation step average loss is 0.014546101912856102\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Cumulative validation average loss is 0.5966355528216809\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Per validation step average loss is 0.6093384027481079\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Cumulative validation average loss is 1.2059739555697888\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Per validation step average loss is 0.12496062368154526\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Cumulative validation average loss is 1.330934579251334\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Per validation step average loss is 0.5495982766151428\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Cumulative validation average loss is 1.880532855866477\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Per validation step average loss is 0.11791155487298965\n",
      "07/18/2023 19:32:46 - INFO - __main__ - Cumulative validation average loss is 1.9984444107394665\n",
      "07/18/2023 19:32:47 - INFO - __main__ - Per validation step average loss is 0.027108557522296906\n",
      "07/18/2023 19:32:47 - INFO - __main__ - Cumulative validation average loss is 2.0255529682617635\n",
      "07/18/2023 19:32:47 - INFO - __main__ - Average validation loss for Epoch 47 is 0.1687960806884803\n",
      "07/18/2023 19:32:47 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:32:59 - INFO - __main__ - Starting epoch 48\n",
      "07/18/2023 19:33:00 - INFO - __main__ - train loss is 0.009329925291240215\n",
      "Steps:  31%|▎| 4657/15000 [29:38<14:08:33,  4.92s/it, lr=9.85e-6, step_loss=0.0007/18/2023 19:33:00 - INFO - __main__ - train loss is 0.2650713426992297\n",
      "Steps:  31%|▎| 4658/15000 [29:38<10:03:15,  3.50s/it, lr=9.85e-6, step_loss=0.2507/18/2023 19:33:00 - INFO - __main__ - train loss is 0.3699207929894328\n",
      "Steps:  31%|▎| 4659/15000 [29:38<7:11:26,  2.50s/it, lr=9.85e-6, step_loss=0.10507/18/2023 19:33:01 - INFO - __main__ - train loss is 0.37239788798615336\n",
      "Steps:  31%|▎| 4660/15000 [29:39<5:11:10,  1.81s/it, lr=9.85e-6, step_loss=0.00207/18/2023 19:33:01 - INFO - __main__ - train loss is 0.807515490334481\n",
      "Steps:  31%|▎| 4661/15000 [29:39<3:47:00,  1.32s/it, lr=9.85e-6, step_loss=0.43507/18/2023 19:33:01 - INFO - __main__ - train loss is 1.0392848285846412\n",
      "Steps:  31%|▎| 4662/15000 [29:39<2:48:10,  1.02it/s, lr=9.85e-6, step_loss=0.23207/18/2023 19:33:01 - INFO - __main__ - train loss is 1.0935436333529651\n",
      "Steps:  31%|▎| 4663/15000 [29:39<2:07:01,  1.36it/s, lr=9.85e-6, step_loss=0.05407/18/2023 19:33:01 - INFO - __main__ - train loss is 1.4164447630755603\n",
      "Steps:  31%|▎| 4664/15000 [29:39<1:38:07,  1.76it/s, lr=9.85e-6, step_loss=0.32307/18/2023 19:33:02 - INFO - __main__ - train loss is 1.6970774377696216\n",
      "Steps:  31%|▎| 4665/15000 [29:39<1:17:53,  2.21it/s, lr=9.85e-6, step_loss=0.28107/18/2023 19:33:02 - INFO - __main__ - train loss is 1.7283782134763896\n",
      "Steps:  31%|▎| 4666/15000 [29:40<1:03:43,  2.70it/s, lr=9.85e-6, step_loss=0.03107/18/2023 19:33:02 - INFO - __main__ - train loss is 1.9952022801153362\n",
      "Steps:  31%|▌ | 4667/15000 [29:40<53:48,  3.20it/s, lr=9.85e-6, step_loss=0.267]07/18/2023 19:33:02 - INFO - __main__ - train loss is 2.024609405081719\n",
      "Steps:  31%|▎| 4668/15000 [29:40<46:50,  3.68it/s, lr=9.85e-6, step_loss=0.0294]07/18/2023 19:33:02 - INFO - __main__ - train loss is 2.0381620316766202\n",
      "Steps:  31%|▎| 4669/15000 [29:40<41:58,  4.10it/s, lr=9.85e-6, step_loss=0.0136]07/18/2023 19:33:02 - INFO - __main__ - train loss is 2.8556946902535856\n",
      "Steps:  31%|▌ | 4670/15000 [29:40<38:33,  4.46it/s, lr=9.85e-6, step_loss=0.818]07/18/2023 19:33:03 - INFO - __main__ - train loss is 3.2083053975366056\n",
      "Steps:  31%|▌ | 4671/15000 [29:40<36:10,  4.76it/s, lr=9.85e-6, step_loss=0.353]07/18/2023 19:33:03 - INFO - __main__ - train loss is 3.7053568749688566\n",
      "Steps:  31%|▌ | 4672/15000 [29:41<34:31,  4.99it/s, lr=9.85e-6, step_loss=0.497]07/18/2023 19:33:03 - INFO - __main__ - train loss is 4.057529696729034\n",
      "Steps:  31%|▌ | 4673/15000 [29:41<33:21,  5.16it/s, lr=9.85e-6, step_loss=0.352]07/18/2023 19:33:03 - INFO - __main__ - train loss is 4.0611690995283425\n",
      "Steps:  31%|▎| 4674/15000 [29:41<32:32,  5.29it/s, lr=9.85e-6, step_loss=0.0036407/18/2023 19:33:03 - INFO - __main__ - train loss is 4.124762688297778\n",
      "Steps:  31%|▎| 4675/15000 [29:41<32:03,  5.37it/s, lr=9.85e-6, step_loss=0.0636]07/18/2023 19:33:03 - INFO - __main__ - train loss is 4.303717259783298\n",
      "Steps:  31%|▌ | 4676/15000 [29:41<31:38,  5.44it/s, lr=9.85e-6, step_loss=0.179]07/18/2023 19:33:04 - INFO - __main__ - train loss is 4.647017721552402\n",
      "Steps:  31%|▌ | 4677/15000 [29:42<31:20,  5.49it/s, lr=9.85e-6, step_loss=0.343]07/18/2023 19:33:04 - INFO - __main__ - train loss is 5.016902272123843\n",
      "Steps:  31%|▉  | 4678/15000 [29:42<31:08,  5.52it/s, lr=9.85e-6, step_loss=0.37]07/18/2023 19:33:04 - INFO - __main__ - train loss is 5.031538207549602\n",
      "Steps:  31%|▎| 4679/15000 [29:42<31:03,  5.54it/s, lr=9.85e-6, step_loss=0.0146]07/18/2023 19:33:04 - INFO - __main__ - train loss is 5.566747028846294\n",
      "Steps:  31%|▌ | 4680/15000 [29:42<30:55,  5.56it/s, lr=9.85e-6, step_loss=0.535]07/18/2023 19:33:04 - INFO - __main__ - train loss is 6.247354466933757\n",
      "Steps:  31%|▌ | 4681/15000 [29:42<30:51,  5.57it/s, lr=9.85e-6, step_loss=0.681]07/18/2023 19:33:05 - INFO - __main__ - train loss is 6.64234407665208\n",
      "Steps:  31%|▌ | 4682/15000 [29:42<30:48,  5.58it/s, lr=9.85e-6, step_loss=0.395]07/18/2023 19:33:05 - INFO - __main__ - train loss is 6.668833557981998\n",
      "Steps:  31%|▎| 4683/15000 [29:43<30:46,  5.59it/s, lr=9.85e-6, step_loss=0.0265]07/18/2023 19:33:05 - INFO - __main__ - train loss is 6.795024965424091\n",
      "Steps:  31%|▌ | 4684/15000 [29:43<30:44,  5.59it/s, lr=9.85e-6, step_loss=0.126]07/18/2023 19:33:05 - INFO - __main__ - train loss is 7.486011241097003\n",
      "Steps:  31%|▌ | 4685/15000 [29:43<30:42,  5.60it/s, lr=9.85e-6, step_loss=0.691]07/18/2023 19:33:05 - INFO - __main__ - train loss is 7.542095028329641\n",
      "Steps:  31%|▎| 4686/15000 [29:43<30:40,  5.60it/s, lr=9.85e-6, step_loss=0.0561]07/18/2023 19:33:05 - INFO - __main__ - train loss is 7.546431928873062\n",
      "Steps:  31%|▎| 4687/15000 [29:43<30:40,  5.60it/s, lr=9.85e-6, step_loss=0.0043407/18/2023 19:33:06 - INFO - __main__ - train loss is 7.552897458896041\n",
      "Steps:  31%|▎| 4688/15000 [29:44<30:41,  5.60it/s, lr=9.85e-6, step_loss=0.0064707/18/2023 19:33:06 - INFO - __main__ - train loss is 7.6041041892021894\n",
      "Steps:  31%|▎| 4689/15000 [29:44<30:39,  5.60it/s, lr=9.85e-6, step_loss=0.0512]07/18/2023 19:33:06 - INFO - __main__ - train loss is 7.6058987939031795\n",
      "Steps:  31%|▎| 4690/15000 [29:44<30:38,  5.61it/s, lr=9.85e-6, step_loss=0.0017907/18/2023 19:33:06 - INFO - __main__ - train loss is 7.698255326715298\n",
      "Steps:  31%|▎| 4691/15000 [29:44<30:39,  5.60it/s, lr=9.85e-6, step_loss=0.0924]07/18/2023 19:33:06 - INFO - __main__ - train loss is 7.706190747325309\n",
      "Steps:  31%|▎| 4692/15000 [29:44<30:43,  5.59it/s, lr=9.85e-6, step_loss=0.0079407/18/2023 19:33:07 - INFO - __main__ - train loss is 7.92516356438864\n",
      "Steps:  31%|▋ | 4693/15000 [29:44<30:42,  5.59it/s, lr=9.85e-6, step_loss=0.219]07/18/2023 19:33:07 - INFO - __main__ - train loss is 7.956416000728495\n",
      "Steps:  31%|▎| 4694/15000 [29:45<30:41,  5.60it/s, lr=9.85e-6, step_loss=0.0313]07/18/2023 19:33:07 - INFO - __main__ - train loss is 8.19299032271374\n",
      "Steps:  31%|▋ | 4695/15000 [29:45<30:44,  5.59it/s, lr=9.85e-6, step_loss=0.237]07/18/2023 19:33:07 - INFO - __main__ - train loss is 8.196590702864341\n",
      "Steps:  31%|▎| 4696/15000 [29:45<30:45,  5.58it/s, lr=9.85e-6, step_loss=0.0036]07/18/2023 19:33:07 - INFO - __main__ - train loss is 8.404639642569236\n",
      "Steps:  31%|▋ | 4697/15000 [29:45<30:44,  5.59it/s, lr=9.85e-6, step_loss=0.208]07/18/2023 19:33:07 - INFO - __main__ - train loss is 8.740728419157676\n",
      "Steps:  31%|▋ | 4698/15000 [29:45<30:44,  5.59it/s, lr=9.85e-6, step_loss=0.336]07/18/2023 19:33:08 - INFO - __main__ - train loss is 9.111037354799919\n",
      "Steps:  31%|▉  | 4699/15000 [29:45<30:44,  5.59it/s, lr=9.85e-6, step_loss=0.37]07/18/2023 19:33:08 - INFO - __main__ - train loss is 9.129861893015914\n",
      "Steps:  31%|▎| 4700/15000 [29:46<30:42,  5.59it/s, lr=9.85e-6, step_loss=0.0188]07/18/2023 19:33:08 - INFO - __main__ - train loss is 9.231377513962798\n",
      "Steps:  31%|▋ | 4701/15000 [29:46<30:44,  5.59it/s, lr=9.85e-6, step_loss=0.102]07/18/2023 19:33:08 - INFO - __main__ - train loss is 9.236455889302306\n",
      "Steps:  31%|▎| 4702/15000 [29:46<30:42,  5.59it/s, lr=9.85e-6, step_loss=0.0050807/18/2023 19:33:08 - INFO - __main__ - train loss is 9.349544005352072\n",
      "Steps:  31%|▋ | 4703/15000 [29:46<30:42,  5.59it/s, lr=9.85e-6, step_loss=0.113]07/18/2023 19:33:08 - INFO - __main__ - train loss is 9.942013936000876\n",
      "Steps:  31%|▋ | 4704/15000 [29:46<30:40,  5.59it/s, lr=9.85e-6, step_loss=0.592]07/18/2023 19:33:09 - INFO - __main__ - train loss is 9.944410048774444\n",
      "Steps:  31%|▎| 4705/15000 [29:47<30:39,  5.60it/s, lr=9.85e-6, step_loss=0.0024]07/18/2023 19:33:09 - INFO - __main__ - train loss is 9.97256725502666\n",
      "Steps:  31%|▎| 4706/15000 [29:47<30:37,  5.60it/s, lr=9.85e-6, step_loss=0.0282]07/18/2023 19:33:09 - INFO - __main__ - train loss is 10.516826803213917\n",
      "Steps:  31%|▋ | 4707/15000 [29:47<30:36,  5.60it/s, lr=9.85e-6, step_loss=0.544]07/18/2023 19:33:09 - INFO - __main__ - train loss is 10.60398393345531\n",
      "Steps:  31%|▎| 4708/15000 [29:47<30:35,  5.61it/s, lr=9.85e-6, step_loss=0.0872]07/18/2023 19:33:09 - INFO - __main__ - train loss is 10.622373734018765\n",
      "Steps:  31%|▎| 4709/15000 [29:47<30:37,  5.60it/s, lr=9.85e-6, step_loss=0.0184]07/18/2023 19:33:10 - INFO - __main__ - train loss is 10.684672382078134\n",
      "Steps:  31%|▎| 4710/15000 [29:47<30:38,  5.60it/s, lr=9.85e-6, step_loss=0.0623]07/18/2023 19:33:10 - INFO - __main__ - train loss is 10.761653293273412\n",
      "Steps:  31%|▋ | 4711/15000 [29:48<30:36,  5.60it/s, lr=9.85e-6, step_loss=0.077]07/18/2023 19:33:10 - INFO - __main__ - train loss is 11.615232099196874\n",
      "Steps:  31%|▋ | 4712/15000 [29:48<30:36,  5.60it/s, lr=9.85e-6, step_loss=0.854]07/18/2023 19:33:10 - INFO - __main__ - train loss is 11.887612630031072\n",
      "Steps:  31%|▋ | 4713/15000 [29:48<30:37,  5.60it/s, lr=9.85e-6, step_loss=0.272]07/18/2023 19:33:10 - INFO - __main__ - train loss is 11.929859582684003\n",
      "Steps:  31%|▎| 4714/15000 [29:48<30:35,  5.60it/s, lr=9.85e-6, step_loss=0.0422]07/18/2023 19:33:10 - INFO - __main__ - train loss is 12.103893909952603\n",
      "Steps:  31%|▋ | 4715/15000 [29:48<30:35,  5.60it/s, lr=9.85e-6, step_loss=0.174]07/18/2023 19:33:11 - INFO - __main__ - train loss is 12.466790113947354\n",
      "Steps:  31%|▋ | 4716/15000 [29:49<30:34,  5.61it/s, lr=9.85e-6, step_loss=0.363]07/18/2023 19:33:11 - INFO - __main__ - train loss is 12.599801484844647\n",
      "Steps:  31%|▋ | 4717/15000 [29:49<30:35,  5.60it/s, lr=9.85e-6, step_loss=0.133]07/18/2023 19:33:11 - INFO - __main__ - train loss is 12.96979937364813\n",
      "Steps:  31%|▉  | 4718/15000 [29:49<30:35,  5.60it/s, lr=9.85e-6, step_loss=0.37]07/18/2023 19:33:11 - INFO - __main__ - train loss is 13.087143537006341\n",
      "Steps:  31%|▋ | 4719/15000 [29:49<30:34,  5.60it/s, lr=9.85e-6, step_loss=0.117]07/18/2023 19:33:11 - INFO - __main__ - train loss is 13.283738952479325\n",
      "Steps:  31%|▋ | 4720/15000 [29:49<30:33,  5.61it/s, lr=9.85e-6, step_loss=0.197]07/18/2023 19:33:12 - INFO - __main__ - train loss is 13.297831147327088\n",
      "Steps:  31%|▎| 4721/15000 [29:49<30:34,  5.60it/s, lr=9.85e-6, step_loss=0.0141]07/18/2023 19:33:12 - INFO - __main__ - train loss is 13.334162920131348\n",
      "Steps:  31%|▎| 4722/15000 [29:50<30:34,  5.60it/s, lr=9.85e-6, step_loss=0.0363]07/18/2023 19:33:12 - INFO - __main__ - train loss is 13.417914993478917\n",
      "Steps:  31%|▎| 4723/15000 [29:50<30:34,  5.60it/s, lr=9.85e-6, step_loss=0.0838]07/18/2023 19:33:12 - INFO - __main__ - train loss is 13.740481443121098\n",
      "Steps:  31%|▋ | 4724/15000 [29:50<30:36,  5.60it/s, lr=9.85e-6, step_loss=0.323]07/18/2023 19:33:12 - INFO - __main__ - train loss is 14.090072966529988\n",
      "Steps:  32%|▉  | 4725/15000 [29:50<30:35,  5.60it/s, lr=9.85e-6, step_loss=0.35]07/18/2023 19:33:12 - INFO - __main__ - train loss is 14.102946711122058\n",
      "Steps:  32%|▎| 4726/15000 [29:50<30:34,  5.60it/s, lr=9.85e-6, step_loss=0.0129]07/18/2023 19:33:13 - INFO - __main__ - train loss is 14.238573280512355\n",
      "Steps:  32%|▋ | 4727/15000 [29:50<30:33,  5.60it/s, lr=9.85e-6, step_loss=0.136]07/18/2023 19:33:13 - INFO - __main__ - train loss is 14.245703150867485\n",
      "Steps:  32%|▎| 4728/15000 [29:51<30:50,  5.55it/s, lr=9.85e-6, step_loss=0.0071307/18/2023 19:33:13 - INFO - __main__ - train loss is 14.280197416781448\n",
      "Steps:  32%|▎| 4729/15000 [29:51<31:27,  5.44it/s, lr=9.85e-6, step_loss=0.0345]07/18/2023 19:33:13 - INFO - __main__ - train loss is 14.575973158120178\n",
      "Steps:  32%|▋ | 4730/15000 [29:51<31:29,  5.44it/s, lr=9.85e-6, step_loss=0.296]07/18/2023 19:33:13 - INFO - __main__ - train loss is 14.586484901956283\n",
      "Steps:  32%|▎| 4731/15000 [29:51<31:13,  5.48it/s, lr=9.85e-6, step_loss=0.0105]07/18/2023 19:33:14 - INFO - __main__ - train loss is 14.814063839963637\n",
      "Steps:  32%|▋ | 4732/15000 [29:51<31:16,  5.47it/s, lr=9.85e-6, step_loss=0.228]07/18/2023 19:33:14 - INFO - __main__ - train loss is 14.816152041661553\n",
      "Steps:  32%|▎| 4733/15000 [29:52<31:03,  5.51it/s, lr=9.85e-6, step_loss=0.0020907/18/2023 19:33:14 - INFO - __main__ - train loss is 15.388347929227166\n",
      "Steps:  32%|▋ | 4734/15000 [29:52<30:54,  5.54it/s, lr=9.85e-6, step_loss=0.572]07/18/2023 19:33:14 - INFO - __main__ - train loss is 15.71859896730166\n",
      "Steps:  32%|▉  | 4735/15000 [29:52<30:47,  5.56it/s, lr=9.85e-6, step_loss=0.33]07/18/2023 19:33:14 - INFO - __main__ - train loss is 16.482823198544793\n",
      "Steps:  32%|▋ | 4736/15000 [29:52<30:43,  5.57it/s, lr=9.85e-6, step_loss=0.764]07/18/2023 19:33:14 - INFO - __main__ - train loss is 16.683514213073067\n",
      "Steps:  32%|▋ | 4737/15000 [29:52<30:40,  5.58it/s, lr=9.85e-6, step_loss=0.201]07/18/2023 19:33:15 - INFO - __main__ - train loss is 16.808059861767106\n",
      "Steps:  32%|▋ | 4738/15000 [29:52<30:39,  5.58it/s, lr=9.85e-6, step_loss=0.125]07/18/2023 19:33:15 - INFO - __main__ - train loss is 16.882041161763482\n",
      "Steps:  32%|▋ | 4739/15000 [29:53<30:46,  5.56it/s, lr=9.85e-6, step_loss=0.074]07/18/2023 19:33:15 - INFO - __main__ - train loss is 16.948233907925896\n",
      "Steps:  32%|▎| 4740/15000 [29:53<30:40,  5.58it/s, lr=9.85e-6, step_loss=0.0662]07/18/2023 19:33:15 - INFO - __main__ - train loss is 17.174168532597832\n",
      "Steps:  32%|▋ | 4741/15000 [29:53<30:36,  5.59it/s, lr=9.85e-6, step_loss=0.226]07/18/2023 19:33:15 - INFO - __main__ - train loss is 17.199607279035263\n",
      "Steps:  32%|▎| 4742/15000 [29:53<30:34,  5.59it/s, lr=9.85e-6, step_loss=0.0254]07/18/2023 19:33:15 - INFO - __main__ - train loss is 17.221145707997493\n",
      "Steps:  32%|▎| 4743/15000 [29:53<30:48,  5.55it/s, lr=9.85e-6, step_loss=0.0215]07/18/2023 19:33:16 - INFO - __main__ - train loss is 17.355026442441158\n",
      "Steps:  32%|▋ | 4744/15000 [29:54<30:53,  5.53it/s, lr=9.85e-6, step_loss=0.134]07/18/2023 19:33:16 - INFO - __main__ - train loss is 18.017022807034664\n",
      "Steps:  32%|▋ | 4745/15000 [29:54<30:54,  5.53it/s, lr=9.85e-6, step_loss=0.662]07/18/2023 19:33:16 - INFO - __main__ - train loss is 18.062528692069463\n",
      "Steps:  32%|▎| 4746/15000 [29:54<30:54,  5.53it/s, lr=9.85e-6, step_loss=0.0455]07/18/2023 19:33:16 - INFO - __main__ - train loss is 18.236422710004263\n",
      "Steps:  32%|▋ | 4747/15000 [29:54<30:46,  5.55it/s, lr=9.85e-6, step_loss=0.174]07/18/2023 19:33:16 - INFO - __main__ - train loss is 18.24186307413038\n",
      "Steps:  32%|▎| 4748/15000 [29:54<30:40,  5.57it/s, lr=9.85e-6, step_loss=0.0054407/18/2023 19:33:17 - INFO - __main__ - train loss is 18.521309020346962\n",
      "Steps:  32%|▋ | 4749/15000 [29:54<30:44,  5.56it/s, lr=9.85e-6, step_loss=0.279]07/18/2023 19:33:17 - INFO - __main__ - train loss is 18.529915733612143\n",
      "Steps:  32%|▎| 4750/15000 [29:55<30:38,  5.58it/s, lr=9.85e-6, step_loss=0.0086107/18/2023 19:33:17 - INFO - __main__ - train loss is 18.567828728235327\n",
      "Steps:  32%|▎| 4751/15000 [29:55<30:37,  5.58it/s, lr=9.85e-6, step_loss=0.0379]07/18/2023 19:33:17 - INFO - __main__ - train loss is 18.5932328797644\n",
      "Steps:  32%|▎| 4752/15000 [29:55<30:34,  5.59it/s, lr=9.85e-6, step_loss=0.0254]07/18/2023 19:33:17 - INFO - __main__ - train loss is 18.603821190423332\n",
      "Steps:  32%|▎| 4753/15000 [29:55<40:57,  4.17it/s, lr=9.85e-6, step_loss=0.0106]07/18/2023 19:33:18 - INFO - __main__ - Per validation step average loss is 0.0033323001116514206\n",
      "07/18/2023 19:33:18 - INFO - __main__ - Cumulative validation average loss is 0.0033323001116514206\n",
      "07/18/2023 19:33:18 - INFO - __main__ - Per validation step average loss is 0.027272691950201988\n",
      "07/18/2023 19:33:18 - INFO - __main__ - Cumulative validation average loss is 0.03060499206185341\n",
      "07/18/2023 19:33:18 - INFO - __main__ - Per validation step average loss is 0.48235249519348145\n",
      "07/18/2023 19:33:18 - INFO - __main__ - Cumulative validation average loss is 0.5129574872553349\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Per validation step average loss is 0.3284232020378113\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Cumulative validation average loss is 0.8413806892931461\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Per validation step average loss is 0.2100217640399933\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Cumulative validation average loss is 1.0514024533331394\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Per validation step average loss is 0.016459515318274498\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Cumulative validation average loss is 1.067861968651414\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Per validation step average loss is 0.014397528022527695\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Cumulative validation average loss is 1.0822594966739416\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Per validation step average loss is 0.0019815717823803425\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Cumulative validation average loss is 1.084241068456322\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Per validation step average loss is 0.037676721811294556\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Cumulative validation average loss is 1.1219177902676165\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Per validation step average loss is 0.033703893423080444\n",
      "07/18/2023 19:33:19 - INFO - __main__ - Cumulative validation average loss is 1.155621683690697\n",
      "07/18/2023 19:33:20 - INFO - __main__ - Per validation step average loss is 0.060625117272138596\n",
      "07/18/2023 19:33:20 - INFO - __main__ - Cumulative validation average loss is 1.2162468009628356\n",
      "07/18/2023 19:33:20 - INFO - __main__ - Per validation step average loss is 0.016767656430602074\n",
      "07/18/2023 19:33:20 - INFO - __main__ - Cumulative validation average loss is 1.2330144573934376\n",
      "07/18/2023 19:33:20 - INFO - __main__ - Average validation loss for Epoch 48 is 0.10275120478278647\n",
      "07/18/2023 19:33:20 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:33:33 - INFO - __main__ - Starting epoch 49\n",
      "07/18/2023 19:33:33 - INFO - __main__ - train loss is 0.1001727357506752\n",
      "Steps:  32%|▎| 4754/15000 [30:11<13:54:17,  4.89s/it, lr=9.85e-6, step_loss=0.1]07/18/2023 19:33:33 - INFO - __main__ - train loss is 0.3167622610926628\n",
      "Steps:  32%|▎| 4755/15000 [30:11<9:53:03,  3.47s/it, lr=9.85e-6, step_loss=0.21707/18/2023 19:33:34 - INFO - __main__ - train loss is 0.3190338499844074\n",
      "Steps:  32%|▎| 4756/15000 [30:11<7:04:14,  2.48s/it, lr=9.85e-6, step_loss=0.00207/18/2023 19:33:34 - INFO - __main__ - train loss is 0.4551004506647587\n",
      "Steps:  32%|▎| 4757/15000 [30:12<5:06:02,  1.79s/it, lr=9.85e-6, step_loss=0.13607/18/2023 19:33:34 - INFO - __main__ - train loss is 0.6020358689129353\n",
      "Steps:  32%|▎| 4758/15000 [30:12<3:43:35,  1.31s/it, lr=9.85e-6, step_loss=0.14707/18/2023 19:33:34 - INFO - __main__ - train loss is 0.759807113558054\n",
      "[2023-07-18 19:33:34,704] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  32%|▎| 4759/15000 [30:12<2:46:06,  1.03it/s, lr=9.85e-6, step_loss=0.15807/18/2023 19:33:34 - INFO - __main__ - train loss is 0.7698535900563002\n",
      "Steps:  32%|▎| 4760/15000 [30:12<2:05:24,  1.36it/s, lr=9.85e-6, step_loss=0.01]07/18/2023 19:33:34 - INFO - __main__ - train loss is 1.2361809592694044\n",
      "Steps:  32%|▎| 4761/15000 [30:12<1:37:09,  1.76it/s, lr=9.85e-6, step_loss=0.46607/18/2023 19:33:35 - INFO - __main__ - train loss is 1.2617187462747097\n",
      "Steps:  32%|▎| 4762/15000 [30:13<1:17:05,  2.21it/s, lr=9.85e-6, step_loss=0.02507/18/2023 19:33:35 - INFO - __main__ - train loss is 1.6389374695718288\n",
      "Steps:  32%|▎| 4763/15000 [30:13<1:03:05,  2.70it/s, lr=9.85e-6, step_loss=0.37707/18/2023 19:33:35 - INFO - __main__ - train loss is 1.6843971237540245\n",
      "Steps:  32%|▎| 4764/15000 [30:13<53:32,  3.19it/s, lr=9.85e-6, step_loss=0.0455]07/18/2023 19:33:35 - INFO - __main__ - train loss is 1.8050714880228043\n",
      "Steps:  32%|▋ | 4765/15000 [30:13<46:50,  3.64it/s, lr=9.85e-6, step_loss=0.121]07/18/2023 19:33:35 - INFO - __main__ - train loss is 1.9816821217536926\n",
      "Steps:  32%|▋ | 4766/15000 [30:13<41:54,  4.07it/s, lr=9.85e-6, step_loss=0.177]07/18/2023 19:33:36 - INFO - __main__ - train loss is 2.0257544964551926\n",
      "Steps:  32%|▎| 4767/15000 [30:13<38:27,  4.44it/s, lr=9.85e-6, step_loss=0.0441]07/18/2023 19:33:36 - INFO - __main__ - train loss is 2.1812887638807297\n",
      "Steps:  32%|▋ | 4768/15000 [30:14<36:04,  4.73it/s, lr=9.85e-6, step_loss=0.156]07/18/2023 19:33:36 - INFO - __main__ - train loss is 2.3494822829961777\n",
      "Steps:  32%|▋ | 4769/15000 [30:14<34:19,  4.97it/s, lr=9.85e-6, step_loss=0.168]07/18/2023 19:33:36 - INFO - __main__ - train loss is 2.37790210545063\n",
      "Steps:  32%|▎| 4770/15000 [30:14<33:09,  5.14it/s, lr=9.85e-6, step_loss=0.0284]07/18/2023 19:33:36 - INFO - __main__ - train loss is 2.5682347118854523\n",
      "Steps:  32%|▉  | 4771/15000 [30:14<32:19,  5.27it/s, lr=9.85e-6, step_loss=0.19]07/18/2023 19:33:36 - INFO - __main__ - train loss is 2.581770640797913\n",
      "Steps:  32%|▎| 4772/15000 [30:14<31:47,  5.36it/s, lr=9.85e-6, step_loss=0.0135]07/18/2023 19:33:37 - INFO - __main__ - train loss is 2.6460867868736386\n",
      "Steps:  32%|▎| 4773/15000 [30:15<31:20,  5.44it/s, lr=9.85e-6, step_loss=0.0643]07/18/2023 19:33:37 - INFO - __main__ - train loss is 2.7836436377838254\n",
      "Steps:  32%|▋ | 4774/15000 [30:15<31:01,  5.49it/s, lr=9.85e-6, step_loss=0.138]07/18/2023 19:33:37 - INFO - __main__ - train loss is 2.8054674761369824\n",
      "Steps:  32%|▎| 4775/15000 [30:15<30:49,  5.53it/s, lr=9.85e-6, step_loss=0.0218]07/18/2023 19:33:37 - INFO - __main__ - train loss is 2.819636113010347\n",
      "Steps:  32%|▎| 4776/15000 [30:15<30:40,  5.55it/s, lr=9.85e-6, step_loss=0.0142]07/18/2023 19:33:37 - INFO - __main__ - train loss is 2.842342942021787\n",
      "Steps:  32%|▎| 4777/15000 [30:15<30:53,  5.52it/s, lr=9.85e-6, step_loss=0.0227]07/18/2023 19:33:38 - INFO - __main__ - train loss is 3.20471456553787\n",
      "Steps:  32%|▋ | 4778/15000 [30:15<30:43,  5.54it/s, lr=9.85e-6, step_loss=0.362]07/18/2023 19:33:38 - INFO - __main__ - train loss is 3.2638438707217574\n",
      "Steps:  32%|▎| 4779/15000 [30:16<30:36,  5.56it/s, lr=9.85e-6, step_loss=0.0591]07/18/2023 19:33:38 - INFO - __main__ - train loss is 3.2893613101914525\n",
      "Steps:  32%|▎| 4780/15000 [30:16<30:33,  5.57it/s, lr=9.85e-6, step_loss=0.0255]07/18/2023 19:33:38 - INFO - __main__ - train loss is 3.729019862599671\n",
      "Steps:  32%|▉  | 4781/15000 [30:16<30:29,  5.58it/s, lr=9.85e-6, step_loss=0.44]07/18/2023 19:33:38 - INFO - __main__ - train loss is 3.9049810441210866\n",
      "Steps:  32%|▋ | 4782/15000 [30:16<30:26,  5.59it/s, lr=9.84e-6, step_loss=0.176]07/18/2023 19:33:38 - INFO - __main__ - train loss is 4.471037772484124\n",
      "Steps:  32%|▋ | 4783/15000 [30:16<30:38,  5.56it/s, lr=9.84e-6, step_loss=0.566]07/18/2023 19:33:39 - INFO - __main__ - train loss is 4.578503069467843\n",
      "Steps:  32%|▋ | 4784/15000 [30:16<30:34,  5.57it/s, lr=9.84e-6, step_loss=0.107]07/18/2023 19:33:39 - INFO - __main__ - train loss is 4.820868936367333\n",
      "Steps:  32%|▋ | 4785/15000 [30:17<30:30,  5.58it/s, lr=9.84e-6, step_loss=0.242]07/18/2023 19:33:39 - INFO - __main__ - train loss is 5.193365273065865\n",
      "Steps:  32%|▋ | 4786/15000 [30:17<30:28,  5.59it/s, lr=9.84e-6, step_loss=0.372]07/18/2023 19:33:39 - INFO - __main__ - train loss is 5.338637215085328\n",
      "Steps:  32%|▋ | 4787/15000 [30:17<30:26,  5.59it/s, lr=9.84e-6, step_loss=0.145]07/18/2023 19:33:39 - INFO - __main__ - train loss is 5.378400628454983\n",
      "Steps:  32%|▎| 4788/15000 [30:17<30:24,  5.60it/s, lr=9.84e-6, step_loss=0.0398]07/18/2023 19:33:39 - INFO - __main__ - train loss is 5.389417263679206\n",
      "Steps:  32%|▋ | 4789/15000 [30:17<30:22,  5.60it/s, lr=9.84e-6, step_loss=0.011]07/18/2023 19:33:40 - INFO - __main__ - train loss is 5.958112630061805\n",
      "Steps:  32%|▋ | 4790/15000 [30:18<30:20,  5.61it/s, lr=9.84e-6, step_loss=0.569]07/18/2023 19:33:40 - INFO - __main__ - train loss is 6.503008815459907\n",
      "Steps:  32%|▋ | 4791/15000 [30:18<30:20,  5.61it/s, lr=9.84e-6, step_loss=0.545]07/18/2023 19:33:40 - INFO - __main__ - train loss is 6.820822807960212\n",
      "Steps:  32%|▋ | 4792/15000 [30:18<30:19,  5.61it/s, lr=9.84e-6, step_loss=0.318]07/18/2023 19:33:40 - INFO - __main__ - train loss is 6.832348906435072\n",
      "Steps:  32%|▎| 4793/15000 [30:18<30:18,  5.61it/s, lr=9.84e-6, step_loss=0.0115]07/18/2023 19:33:40 - INFO - __main__ - train loss is 6.834076625527814\n",
      "Steps:  32%|▎| 4794/15000 [30:18<30:17,  5.62it/s, lr=9.84e-6, step_loss=0.0017307/18/2023 19:33:41 - INFO - __main__ - train loss is 6.864289460005239\n",
      "Steps:  32%|▎| 4795/15000 [30:18<30:17,  5.61it/s, lr=9.84e-6, step_loss=0.0302]07/18/2023 19:33:41 - INFO - __main__ - train loss is 7.02477848273702\n",
      "Steps:  32%|▉  | 4796/15000 [30:19<30:17,  5.61it/s, lr=9.84e-6, step_loss=0.16]07/18/2023 19:33:41 - INFO - __main__ - train loss is 7.034284335793927\n",
      "Steps:  32%|▎| 4797/15000 [30:19<30:18,  5.61it/s, lr=9.84e-6, step_loss=0.0095107/18/2023 19:33:41 - INFO - __main__ - train loss is 7.262561631621793\n",
      "Steps:  32%|▋ | 4798/15000 [30:19<30:17,  5.61it/s, lr=9.84e-6, step_loss=0.228]07/18/2023 19:33:41 - INFO - __main__ - train loss is 7.276224757777527\n",
      "Steps:  32%|▎| 4799/15000 [30:19<30:17,  5.61it/s, lr=9.84e-6, step_loss=0.0137]07/18/2023 19:33:41 - INFO - __main__ - train loss is 7.470970924245194\n",
      "Steps:  32%|▋ | 4800/15000 [30:19<30:25,  5.59it/s, lr=9.84e-6, step_loss=0.195]07/18/2023 19:33:42 - INFO - __main__ - train loss is 7.8230582133401185\n",
      "Steps:  32%|▋ | 4801/15000 [30:20<30:50,  5.51it/s, lr=9.84e-6, step_loss=0.352]07/18/2023 19:33:42 - INFO - __main__ - train loss is 8.265882308827713\n",
      "Steps:  32%|▋ | 4802/15000 [30:20<31:09,  5.46it/s, lr=9.84e-6, step_loss=0.443]07/18/2023 19:33:42 - INFO - __main__ - train loss is 8.2751083758194\n",
      "Steps:  32%|▎| 4803/15000 [30:20<31:45,  5.35it/s, lr=9.84e-6, step_loss=0.0092307/18/2023 19:33:42 - INFO - __main__ - train loss is 8.33964812126942\n",
      "Steps:  32%|▎| 4804/15000 [30:20<32:05,  5.30it/s, lr=9.84e-6, step_loss=0.0645]07/18/2023 19:33:42 - INFO - __main__ - train loss is 8.392074787290767\n",
      "Steps:  32%|▎| 4805/15000 [30:20<32:18,  5.26it/s, lr=9.84e-6, step_loss=0.0524]07/18/2023 19:33:43 - INFO - __main__ - train loss is 8.829199933679774\n",
      "Steps:  32%|▋ | 4806/15000 [30:20<32:30,  5.23it/s, lr=9.84e-6, step_loss=0.437]07/18/2023 19:33:43 - INFO - __main__ - train loss is 8.832355900434777\n",
      "Steps:  32%|▎| 4807/15000 [30:21<32:38,  5.21it/s, lr=9.84e-6, step_loss=0.0031607/18/2023 19:33:43 - INFO - __main__ - train loss is 8.850126060424373\n",
      "Steps:  32%|▎| 4808/15000 [30:21<32:42,  5.19it/s, lr=9.84e-6, step_loss=0.0178]07/18/2023 19:33:43 - INFO - __main__ - train loss is 8.955643499968573\n",
      "Steps:  32%|▋ | 4809/15000 [30:21<32:22,  5.25it/s, lr=9.84e-6, step_loss=0.106]07/18/2023 19:33:43 - INFO - __main__ - train loss is 9.080371151445433\n",
      "Steps:  32%|▋ | 4810/15000 [30:21<32:18,  5.26it/s, lr=9.84e-6, step_loss=0.125]07/18/2023 19:33:44 - INFO - __main__ - train loss is 9.14991612243466\n",
      "Steps:  32%|▎| 4811/15000 [30:21<32:28,  5.23it/s, lr=9.84e-6, step_loss=0.0695]07/18/2023 19:33:44 - INFO - __main__ - train loss is 9.153071904787794\n",
      "Steps:  32%|▎| 4812/15000 [30:22<32:35,  5.21it/s, lr=9.84e-6, step_loss=0.0031607/18/2023 19:33:44 - INFO - __main__ - train loss is 9.387058193096891\n",
      "Steps:  32%|▋ | 4813/15000 [30:22<32:38,  5.20it/s, lr=9.84e-6, step_loss=0.234]07/18/2023 19:33:44 - INFO - __main__ - train loss is 9.409356566378847\n",
      "Steps:  32%|▎| 4814/15000 [30:22<32:38,  5.20it/s, lr=9.84e-6, step_loss=0.0223]07/18/2023 19:33:44 - INFO - __main__ - train loss is 9.44738301099278\n",
      "Steps:  32%|▋ | 4815/15000 [30:22<32:39,  5.20it/s, lr=9.84e-6, step_loss=0.038]07/18/2023 19:33:45 - INFO - __main__ - train loss is 9.474656693870202\n",
      "Steps:  32%|▎| 4816/15000 [30:22<32:39,  5.20it/s, lr=9.84e-6, step_loss=0.0273]07/18/2023 19:33:45 - INFO - __main__ - train loss is 9.476943624438718\n",
      "Steps:  32%|▎| 4817/15000 [30:23<32:39,  5.20it/s, lr=9.84e-6, step_loss=0.0022907/18/2023 19:33:45 - INFO - __main__ - train loss is 9.645697337808087\n",
      "Steps:  32%|▋ | 4818/15000 [30:23<32:39,  5.20it/s, lr=9.84e-6, step_loss=0.169]07/18/2023 19:33:45 - INFO - __main__ - train loss is 9.676875832723454\n",
      "Steps:  32%|▎| 4819/15000 [30:23<32:39,  5.20it/s, lr=9.84e-6, step_loss=0.0312]07/18/2023 19:33:45 - INFO - __main__ - train loss is 9.699463495286182\n",
      "Steps:  32%|▎| 4820/15000 [30:23<32:39,  5.19it/s, lr=9.84e-6, step_loss=0.0226]07/18/2023 19:33:45 - INFO - __main__ - train loss is 9.707795766415074\n",
      "Steps:  32%|▎| 4821/15000 [30:23<32:19,  5.25it/s, lr=9.84e-6, step_loss=0.0083307/18/2023 19:33:46 - INFO - __main__ - train loss is 9.727472690166906\n",
      "Steps:  32%|▎| 4822/15000 [30:24<31:42,  5.35it/s, lr=9.84e-6, step_loss=0.0197]07/18/2023 19:33:46 - INFO - __main__ - train loss is 10.50248017651029\n",
      "Steps:  32%|▋ | 4823/15000 [30:24<31:13,  5.43it/s, lr=9.84e-6, step_loss=0.775]07/18/2023 19:33:46 - INFO - __main__ - train loss is 10.984092233004048\n",
      "Steps:  32%|▋ | 4824/15000 [30:24<30:55,  5.48it/s, lr=9.84e-6, step_loss=0.482]07/18/2023 19:33:46 - INFO - __main__ - train loss is 11.088630792917684\n",
      "Steps:  32%|▋ | 4825/15000 [30:24<30:42,  5.52it/s, lr=9.84e-6, step_loss=0.105]07/18/2023 19:33:46 - INFO - __main__ - train loss is 11.098866594256833\n",
      "Steps:  32%|▎| 4826/15000 [30:24<30:32,  5.55it/s, lr=9.84e-6, step_loss=0.0102]07/18/2023 19:33:47 - INFO - __main__ - train loss is 11.114725074963644\n",
      "Steps:  32%|▎| 4827/15000 [30:24<30:25,  5.57it/s, lr=9.84e-6, step_loss=0.0159]07/18/2023 19:33:47 - INFO - __main__ - train loss is 11.119633108610287\n",
      "Steps:  32%|▎| 4828/15000 [30:25<30:20,  5.59it/s, lr=9.84e-6, step_loss=0.0049107/18/2023 19:33:47 - INFO - __main__ - train loss is 11.13388360501267\n",
      "Steps:  32%|▎| 4829/15000 [30:25<30:38,  5.53it/s, lr=9.84e-6, step_loss=0.0143]07/18/2023 19:33:47 - INFO - __main__ - train loss is 11.139485981082544\n",
      "Steps:  32%|▎| 4830/15000 [30:25<31:01,  5.46it/s, lr=9.84e-6, step_loss=0.0056]07/18/2023 19:33:47 - INFO - __main__ - train loss is 11.143959897337481\n",
      "Steps:  32%|▎| 4831/15000 [30:25<30:46,  5.51it/s, lr=9.84e-6, step_loss=0.0044707/18/2023 19:33:47 - INFO - __main__ - train loss is 11.829007702646777\n",
      "Steps:  32%|▋ | 4832/15000 [30:25<30:35,  5.54it/s, lr=9.84e-6, step_loss=0.685]07/18/2023 19:33:48 - INFO - __main__ - train loss is 12.142084973631427\n",
      "Steps:  32%|▋ | 4833/15000 [30:26<30:28,  5.56it/s, lr=9.84e-6, step_loss=0.313]07/18/2023 19:33:48 - INFO - __main__ - train loss is 12.24590930598788\n",
      "Steps:  32%|▋ | 4834/15000 [30:26<30:24,  5.57it/s, lr=9.84e-6, step_loss=0.104]07/18/2023 19:33:48 - INFO - __main__ - train loss is 12.36010097968392\n",
      "Steps:  32%|▋ | 4835/15000 [30:26<30:19,  5.59it/s, lr=9.84e-6, step_loss=0.114]07/18/2023 19:33:48 - INFO - __main__ - train loss is 12.365602514473721\n",
      "Steps:  32%|▎| 4836/15000 [30:26<30:15,  5.60it/s, lr=9.84e-6, step_loss=0.0055]07/18/2023 19:33:48 - INFO - __main__ - train loss is 12.597406512824818\n",
      "Steps:  32%|▋ | 4837/15000 [30:26<30:13,  5.60it/s, lr=9.84e-6, step_loss=0.232]07/18/2023 19:33:49 - INFO - __main__ - train loss is 12.660042046336457\n",
      "Steps:  32%|▎| 4838/15000 [30:26<30:10,  5.61it/s, lr=9.84e-6, step_loss=0.0626]07/18/2023 19:33:49 - INFO - __main__ - train loss is 12.662918568821624\n",
      "Steps:  32%|▎| 4839/15000 [30:27<30:09,  5.61it/s, lr=9.84e-6, step_loss=0.0028807/18/2023 19:33:49 - INFO - __main__ - train loss is 12.701589801581576\n",
      "Steps:  32%|▎| 4840/15000 [30:27<30:08,  5.62it/s, lr=9.84e-6, step_loss=0.0387]07/18/2023 19:33:49 - INFO - __main__ - train loss is 12.70998942037113\n",
      "Steps:  32%|▎| 4841/15000 [30:27<30:06,  5.62it/s, lr=9.84e-6, step_loss=0.0084]07/18/2023 19:33:49 - INFO - __main__ - train loss is 13.122133395867422\n",
      "Steps:  32%|▋ | 4842/15000 [30:27<30:05,  5.63it/s, lr=9.84e-6, step_loss=0.412]07/18/2023 19:33:49 - INFO - __main__ - train loss is 13.6690645434428\n",
      "Steps:  32%|▋ | 4843/15000 [30:27<30:05,  5.63it/s, lr=9.84e-6, step_loss=0.547]07/18/2023 19:33:50 - INFO - __main__ - train loss is 13.674011643277481\n",
      "Steps:  32%|▎| 4844/15000 [30:27<30:05,  5.62it/s, lr=9.84e-6, step_loss=0.0049507/18/2023 19:33:50 - INFO - __main__ - train loss is 13.827924723969772\n",
      "Steps:  32%|▋ | 4845/15000 [30:28<30:05,  5.63it/s, lr=9.84e-6, step_loss=0.154]07/18/2023 19:33:50 - INFO - __main__ - train loss is 14.192242707358673\n",
      "Steps:  32%|▋ | 4846/15000 [30:28<30:05,  5.63it/s, lr=9.84e-6, step_loss=0.364]07/18/2023 19:33:50 - INFO - __main__ - train loss is 14.515005345689133\n",
      "Steps:  32%|▋ | 4847/15000 [30:28<30:04,  5.63it/s, lr=9.84e-6, step_loss=0.323]07/18/2023 19:33:50 - INFO - __main__ - train loss is 14.55862396885641\n",
      "Steps:  32%|▎| 4848/15000 [30:28<30:04,  5.63it/s, lr=9.84e-6, step_loss=0.0436]07/18/2023 19:33:50 - INFO - __main__ - train loss is 14.649908690946177\n",
      "Steps:  32%|▎| 4849/15000 [30:28<30:03,  5.63it/s, lr=9.84e-6, step_loss=0.0913]07/18/2023 19:33:51 - INFO - __main__ - train loss is 14.745493217604235\n",
      "Steps:  32%|▎| 4850/15000 [30:29<45:04,  3.75it/s, lr=9.84e-6, step_loss=0.0956]07/18/2023 19:33:52 - INFO - __main__ - Per validation step average loss is 0.007687571924179792\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Cumulative validation average loss is 0.007687571924179792\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Per validation step average loss is 0.33981165289878845\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Cumulative validation average loss is 0.34749922482296824\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Per validation step average loss is 0.09464633464813232\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Cumulative validation average loss is 0.44214555947110057\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Per validation step average loss is 0.008322887122631073\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Cumulative validation average loss is 0.45046844659373164\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Per validation step average loss is 0.32121092081069946\n",
      "07/18/2023 19:33:52 - INFO - __main__ - Cumulative validation average loss is 0.7716793674044311\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Per validation step average loss is 0.44933176040649414\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Cumulative validation average loss is 1.2210111278109252\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Per validation step average loss is 0.05080302804708481\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Cumulative validation average loss is 1.27181415585801\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Per validation step average loss is 0.004889736883342266\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Cumulative validation average loss is 1.2767038927413523\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Per validation step average loss is 0.06344029307365417\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Cumulative validation average loss is 1.3401441858150065\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Per validation step average loss is 0.001704520545899868\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Cumulative validation average loss is 1.3418487063609064\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Per validation step average loss is 0.04307445511221886\n",
      "07/18/2023 19:33:53 - INFO - __main__ - Cumulative validation average loss is 1.3849231614731252\n",
      "07/18/2023 19:33:54 - INFO - __main__ - Per validation step average loss is 0.0455176904797554\n",
      "07/18/2023 19:33:54 - INFO - __main__ - Cumulative validation average loss is 1.4304408519528806\n",
      "07/18/2023 19:33:54 - INFO - __main__ - Average validation loss for Epoch 49 is 0.11920340432940672\n",
      "07/18/2023 19:33:54 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:34:07 - INFO - __main__ - Starting epoch 50\n",
      "07/18/2023 19:34:08 - INFO - __main__ - train loss is 0.0126050915569067\n",
      "Steps:  32%|▎| 4851/15000 [30:46<14:39:42,  5.20s/it, lr=9.84e-6, step_loss=0.0107/18/2023 19:34:08 - INFO - __main__ - train loss is 0.044956786558032036\n",
      "Steps:  32%|▎| 4852/15000 [30:46<10:43:21,  3.80s/it, lr=9.84e-6, step_loss=0.0307/18/2023 19:34:09 - INFO - __main__ - train loss is 0.07841294817626476\n",
      "Steps:  32%|▎| 4853/15000 [30:47<7:57:56,  2.83s/it, lr=9.84e-6, step_loss=0.03307/18/2023 19:34:09 - INFO - __main__ - train loss is 0.153992285951972\n",
      "Steps:  32%|▎| 4854/15000 [30:47<6:01:36,  2.14s/it, lr=9.84e-6, step_loss=0.07507/18/2023 19:34:10 - INFO - __main__ - train loss is 0.4448098745197058\n",
      "Steps:  32%|▎| 4855/15000 [30:48<4:40:24,  1.66s/it, lr=9.84e-6, step_loss=0.29107/18/2023 19:34:10 - INFO - __main__ - train loss is 0.4465878966730088\n",
      "Steps:  32%|▎| 4856/15000 [30:48<3:43:29,  1.32s/it, lr=9.84e-6, step_loss=0.00107/18/2023 19:34:11 - INFO - __main__ - train loss is 1.0112067821901292\n",
      "Steps:  32%|▎| 4857/15000 [30:49<3:03:51,  1.09s/it, lr=9.84e-6, step_loss=0.56507/18/2023 19:34:11 - INFO - __main__ - train loss is 1.0142679845448583\n",
      "Steps:  32%|▎| 4858/15000 [30:49<2:36:04,  1.08it/s, lr=9.84e-6, step_loss=0.00307/18/2023 19:34:12 - INFO - __main__ - train loss is 1.1097538804169744\n",
      "Steps:  32%|▎| 4859/15000 [30:50<2:16:19,  1.24it/s, lr=9.84e-6, step_loss=0.09507/18/2023 19:34:13 - INFO - __main__ - train loss is 1.1266894636210054\n",
      "Steps:  32%|▎| 4860/15000 [30:50<2:02:49,  1.38it/s, lr=9.84e-6, step_loss=0.01607/18/2023 19:34:13 - INFO - __main__ - train loss is 1.295177280670032\n",
      "Steps:  32%|▎| 4861/15000 [30:51<1:53:22,  1.49it/s, lr=9.84e-6, step_loss=0.16807/18/2023 19:34:14 - INFO - __main__ - train loss is 1.3018281392287463\n",
      "Steps:  32%|▎| 4862/15000 [30:51<1:46:36,  1.58it/s, lr=9.84e-6, step_loss=0.00607/18/2023 19:34:14 - INFO - __main__ - train loss is 1.335794136626646\n",
      "Steps:  32%|▎| 4863/15000 [30:52<1:41:58,  1.66it/s, lr=9.84e-6, step_loss=0.03407/18/2023 19:34:15 - INFO - __main__ - train loss is 1.385932170553133\n",
      "Steps:  32%|▎| 4864/15000 [30:53<1:38:44,  1.71it/s, lr=9.84e-6, step_loss=0.05007/18/2023 19:34:15 - INFO - __main__ - train loss is 1.3895678098779172\n",
      "Steps:  32%|▎| 4865/15000 [30:53<1:36:29,  1.75it/s, lr=9.84e-6, step_loss=0.00307/18/2023 19:34:16 - INFO - __main__ - train loss is 1.5039046581368893\n",
      "Steps:  32%|▎| 4866/15000 [30:54<1:34:38,  1.78it/s, lr=9.84e-6, step_loss=0.11407/18/2023 19:34:16 - INFO - __main__ - train loss is 1.6332891460042447\n",
      "Steps:  32%|▎| 4867/15000 [30:54<1:33:33,  1.81it/s, lr=9.84e-6, step_loss=0.12907/18/2023 19:34:17 - INFO - __main__ - train loss is 1.7767186786513776\n",
      "Steps:  32%|▎| 4868/15000 [30:55<1:32:44,  1.82it/s, lr=9.84e-6, step_loss=0.14307/18/2023 19:34:17 - INFO - __main__ - train loss is 2.275941255269572\n",
      "Steps:  32%|▎| 4869/15000 [30:55<1:31:58,  1.84it/s, lr=9.84e-6, step_loss=0.49907/18/2023 19:34:18 - INFO - __main__ - train loss is 2.9697903420310467\n",
      "Steps:  32%|▎| 4870/15000 [30:56<1:31:47,  1.84it/s, lr=9.84e-6, step_loss=0.69407/18/2023 19:34:18 - INFO - __main__ - train loss is 3.0445146809797734\n",
      "Steps:  32%|▎| 4871/15000 [30:56<1:31:24,  1.85it/s, lr=9.84e-6, step_loss=0.07407/18/2023 19:34:19 - INFO - __main__ - train loss is 3.331373895285651\n",
      "Steps:  32%|▎| 4872/15000 [30:57<1:31:15,  1.85it/s, lr=9.84e-6, step_loss=0.28707/18/2023 19:34:20 - INFO - __main__ - train loss is 3.484063233016059\n",
      "Steps:  32%|▎| 4873/15000 [30:57<1:31:06,  1.85it/s, lr=9.84e-6, step_loss=0.15307/18/2023 19:34:20 - INFO - __main__ - train loss is 3.4928494959603995\n",
      "Steps:  32%|▎| 4874/15000 [30:58<1:32:04,  1.83it/s, lr=9.84e-6, step_loss=0.00807/18/2023 19:34:21 - INFO - __main__ - train loss is 3.7903197675477713\n",
      "Steps:  32%|▎| 4875/15000 [30:59<1:31:55,  1.84it/s, lr=9.84e-6, step_loss=0.29707/18/2023 19:34:21 - INFO - __main__ - train loss is 3.9145030945073813\n",
      "Steps:  33%|▎| 4876/15000 [30:59<1:31:31,  1.84it/s, lr=9.84e-6, step_loss=0.12407/18/2023 19:34:22 - INFO - __main__ - train loss is 4.11436974699609\n",
      "Steps:  33%|▋ | 4877/15000 [31:00<1:31:10,  1.85it/s, lr=9.84e-6, step_loss=0.2]07/18/2023 19:34:22 - INFO - __main__ - train loss is 4.1335007797461\n",
      "Steps:  33%|▎| 4878/15000 [31:00<1:30:52,  1.86it/s, lr=9.84e-6, step_loss=0.01907/18/2023 19:34:23 - INFO - __main__ - train loss is 4.168747487245128\n",
      "Steps:  33%|▎| 4879/15000 [31:01<1:30:57,  1.85it/s, lr=9.84e-6, step_loss=0.03507/18/2023 19:34:23 - INFO - __main__ - train loss is 4.256826194701716\n",
      "Steps:  33%|▎| 4880/15000 [31:01<1:30:43,  1.86it/s, lr=9.84e-6, step_loss=0.08807/18/2023 19:34:24 - INFO - __main__ - train loss is 4.621715041575953\n",
      "Steps:  33%|▎| 4881/15000 [31:02<1:31:18,  1.85it/s, lr=9.84e-6, step_loss=0.36507/18/2023 19:34:24 - INFO - __main__ - train loss is 4.630963188363239\n",
      "Steps:  33%|▎| 4882/15000 [31:02<1:31:02,  1.85it/s, lr=9.84e-6, step_loss=0.00907/18/2023 19:34:25 - INFO - __main__ - train loss is 5.282607895089313\n",
      "Steps:  33%|▎| 4883/15000 [31:03<1:31:00,  1.85it/s, lr=9.84e-6, step_loss=0.65207/18/2023 19:34:25 - INFO - __main__ - train loss is 5.3318032815586776\n",
      "Steps:  33%|▎| 4884/15000 [31:03<1:31:10,  1.85it/s, lr=9.84e-6, step_loss=0.04907/18/2023 19:34:26 - INFO - __main__ - train loss is 5.900888521922752\n",
      "Steps:  33%|▎| 4885/15000 [31:04<1:31:10,  1.85it/s, lr=9.84e-6, step_loss=0.56907/18/2023 19:34:27 - INFO - __main__ - train loss is 6.3831963434349746\n",
      "Steps:  33%|▎| 4886/15000 [31:04<1:31:12,  1.85it/s, lr=9.84e-6, step_loss=0.48207/18/2023 19:34:27 - INFO - __main__ - train loss is 6.653864939464256\n",
      "Steps:  33%|▎| 4887/15000 [31:05<1:32:22,  1.82it/s, lr=9.84e-6, step_loss=0.27107/18/2023 19:34:28 - INFO - __main__ - train loss is 6.657280657673255\n",
      "Steps:  33%|▎| 4888/15000 [31:06<1:35:20,  1.77it/s, lr=9.84e-6, step_loss=0.00307/18/2023 19:34:28 - INFO - __main__ - train loss is 7.193359706783667\n",
      "Steps:  33%|▎| 4889/15000 [31:06<1:36:50,  1.74it/s, lr=9.84e-6, step_loss=0.53607/18/2023 19:34:29 - INFO - __main__ - train loss is 7.210217759246007\n",
      "Steps:  33%|▎| 4890/15000 [31:07<1:35:23,  1.77it/s, lr=9.84e-6, step_loss=0.01607/18/2023 19:34:29 - INFO - __main__ - train loss is 7.225599974626675\n",
      "Steps:  33%|▎| 4891/15000 [31:07<1:34:16,  1.79it/s, lr=9.84e-6, step_loss=0.01507/18/2023 19:34:30 - INFO - __main__ - train loss is 7.551339060300961\n",
      "Steps:  33%|▎| 4892/15000 [31:08<1:32:59,  1.81it/s, lr=9.84e-6, step_loss=0.32607/18/2023 19:34:30 - INFO - __main__ - train loss is 7.58080161944963\n",
      "Steps:  33%|▎| 4893/15000 [31:08<1:32:10,  1.83it/s, lr=9.84e-6, step_loss=0.02907/18/2023 19:34:31 - INFO - __main__ - train loss is 7.588310125051066\n",
      "Steps:  33%|▎| 4894/15000 [31:09<1:31:49,  1.83it/s, lr=9.84e-6, step_loss=0.00707/18/2023 19:34:32 - INFO - __main__ - train loss is 7.5923948276322335\n",
      "Steps:  33%|▎| 4895/15000 [31:09<1:31:26,  1.84it/s, lr=9.84e-6, step_loss=0.00407/18/2023 19:34:32 - INFO - __main__ - train loss is 7.72259326162748\n",
      "Steps:  33%|▎| 4896/15000 [31:10<1:31:15,  1.85it/s, lr=9.84e-6, step_loss=0.13]07/18/2023 19:34:33 - INFO - __main__ - train loss is 7.731873049167916\n",
      "Steps:  33%|▎| 4897/15000 [31:11<1:31:05,  1.85it/s, lr=9.84e-6, step_loss=0.00907/18/2023 19:34:33 - INFO - __main__ - train loss is 7.797700545517728\n",
      "Steps:  33%|▎| 4898/15000 [31:11<1:31:00,  1.85it/s, lr=9.84e-6, step_loss=0.06507/18/2023 19:34:34 - INFO - __main__ - train loss is 7.874562590150163\n",
      "Steps:  33%|▎| 4899/15000 [31:12<1:30:59,  1.85it/s, lr=9.84e-6, step_loss=0.07607/18/2023 19:34:34 - INFO - __main__ - train loss is 7.959837331203744\n",
      "Steps:  33%|▎| 4900/15000 [31:12<1:30:32,  1.86it/s, lr=9.84e-6, step_loss=0.08507/18/2023 19:34:35 - INFO - __main__ - train loss is 8.05182511988096\n",
      "Steps:  33%|▎| 4901/15000 [31:13<1:30:36,  1.86it/s, lr=9.84e-6, step_loss=0.09207/18/2023 19:34:35 - INFO - __main__ - train loss is 8.142436950234696\n",
      "Steps:  33%|▎| 4902/15000 [31:13<1:31:18,  1.84it/s, lr=9.84e-6, step_loss=0.09007/18/2023 19:34:36 - INFO - __main__ - train loss is 8.433834462193772\n",
      "Steps:  33%|▎| 4903/15000 [31:14<1:31:35,  1.84it/s, lr=9.84e-6, step_loss=0.29107/18/2023 19:34:36 - INFO - __main__ - train loss is 8.466936117736623\n",
      "Steps:  33%|▎| 4904/15000 [31:14<1:31:02,  1.85it/s, lr=9.84e-6, step_loss=0.03307/18/2023 19:34:37 - INFO - __main__ - train loss is 8.468784844502807\n",
      "Steps:  33%|▎| 4905/15000 [31:15<1:30:57,  1.85it/s, lr=9.84e-6, step_loss=0.00107/18/2023 19:34:38 - INFO - __main__ - train loss is 8.708043133839965\n",
      "Steps:  33%|▎| 4906/15000 [31:15<1:30:56,  1.85it/s, lr=9.84e-6, step_loss=0.23907/18/2023 19:34:38 - INFO - __main__ - train loss is 8.886088078841567\n",
      "Steps:  33%|▎| 4907/15000 [31:16<1:30:48,  1.85it/s, lr=9.84e-6, step_loss=0.17807/18/2023 19:34:39 - INFO - __main__ - train loss is 8.905037049204111\n",
      "Steps:  33%|▎| 4908/15000 [31:16<1:30:48,  1.85it/s, lr=9.84e-6, step_loss=0.01807/18/2023 19:34:39 - INFO - __main__ - train loss is 9.126486394554377\n",
      "Steps:  33%|▎| 4909/15000 [31:17<1:30:49,  1.85it/s, lr=9.84e-6, step_loss=0.22107/18/2023 19:34:40 - INFO - __main__ - train loss is 9.771082255989313\n",
      "Steps:  33%|▎| 4910/15000 [31:18<1:30:57,  1.85it/s, lr=9.84e-6, step_loss=0.64507/18/2023 19:34:40 - INFO - __main__ - train loss is 9.918606165796518\n",
      "Steps:  33%|▎| 4911/15000 [31:18<1:30:48,  1.85it/s, lr=9.84e-6, step_loss=0.14807/18/2023 19:34:41 - INFO - __main__ - train loss is 10.000557091087103\n",
      "Steps:  33%|▎| 4912/15000 [31:19<1:30:35,  1.86it/s, lr=9.84e-6, step_loss=0.08207/18/2023 19:34:41 - INFO - __main__ - train loss is 10.743291284888983\n",
      "Steps:  33%|▎| 4913/15000 [31:19<1:30:38,  1.85it/s, lr=9.84e-6, step_loss=0.74307/18/2023 19:34:42 - INFO - __main__ - train loss is 10.75099065573886\n",
      "Steps:  33%|▎| 4914/15000 [31:20<1:30:53,  1.85it/s, lr=9.84e-6, step_loss=0.00707/18/2023 19:34:42 - INFO - __main__ - train loss is 10.769487344194204\n",
      "Steps:  33%|▎| 4915/15000 [31:20<1:32:23,  1.82it/s, lr=9.84e-6, step_loss=0.01807/18/2023 19:34:43 - INFO - __main__ - train loss is 10.970233731437474\n",
      "Steps:  33%|▎| 4916/15000 [31:21<1:32:34,  1.82it/s, lr=9.84e-6, step_loss=0.20107/18/2023 19:34:44 - INFO - __main__ - train loss is 10.973022004123777\n",
      "Steps:  33%|▎| 4917/15000 [31:21<1:33:21,  1.80it/s, lr=9.84e-6, step_loss=0.00207/18/2023 19:34:44 - INFO - __main__ - train loss is 11.129440059419721\n",
      "Steps:  33%|▎| 4918/15000 [31:22<1:33:40,  1.79it/s, lr=9.84e-6, step_loss=0.15607/18/2023 19:34:45 - INFO - __main__ - train loss is 11.132703073555604\n",
      "Steps:  33%|▎| 4919/15000 [31:23<1:33:44,  1.79it/s, lr=9.84e-6, step_loss=0.00307/18/2023 19:34:45 - INFO - __main__ - train loss is 11.139300331706181\n",
      "Steps:  33%|▎| 4920/15000 [31:23<1:33:04,  1.80it/s, lr=9.84e-6, step_loss=0.00607/18/2023 19:34:46 - INFO - __main__ - train loss is 11.512963637942448\n",
      "Steps:  33%|▎| 4921/15000 [31:24<1:32:26,  1.82it/s, lr=9.84e-6, step_loss=0.37407/18/2023 19:34:46 - INFO - __main__ - train loss is 11.644832223886624\n",
      "Steps:  33%|▎| 4922/15000 [31:24<1:32:20,  1.82it/s, lr=9.84e-6, step_loss=0.13207/18/2023 19:34:47 - INFO - __main__ - train loss is 11.664855510229245\n",
      "Steps:  33%|▎| 4923/15000 [31:25<1:32:26,  1.82it/s, lr=9.84e-6, step_loss=0.02]07/18/2023 19:34:47 - INFO - __main__ - train loss is 11.674737829947844\n",
      "Steps:  33%|▎| 4924/15000 [31:25<1:33:40,  1.79it/s, lr=9.84e-6, step_loss=0.00907/18/2023 19:34:48 - INFO - __main__ - train loss is 11.768450167262927\n",
      "Steps:  33%|▎| 4925/15000 [31:26<1:37:13,  1.73it/s, lr=9.84e-6, step_loss=0.09307/18/2023 19:34:49 - INFO - __main__ - train loss is 12.358134772861376\n",
      "Steps:  33%|▎| 4926/15000 [31:27<1:37:43,  1.72it/s, lr=9.84e-6, step_loss=0.59]07/18/2023 19:34:49 - INFO - __main__ - train loss is 12.64653679379262\n",
      "Steps:  33%|▎| 4927/15000 [31:27<1:36:04,  1.75it/s, lr=9.84e-6, step_loss=0.28807/18/2023 19:34:50 - INFO - __main__ - train loss is 12.664668210083619\n",
      "Steps:  33%|▎| 4928/15000 [31:28<1:34:35,  1.77it/s, lr=9.84e-6, step_loss=0.01807/18/2023 19:34:50 - INFO - __main__ - train loss is 12.947329469257966\n",
      "Steps:  33%|▎| 4929/15000 [31:28<1:33:36,  1.79it/s, lr=9.84e-6, step_loss=0.28307/18/2023 19:34:51 - INFO - __main__ - train loss is 12.95690891169943\n",
      "Steps:  33%|▎| 4930/15000 [31:29<1:34:01,  1.79it/s, lr=9.84e-6, step_loss=0.00907/18/2023 19:34:51 - INFO - __main__ - train loss is 13.257221341365948\n",
      "Steps:  33%|▋ | 4931/15000 [31:29<1:33:00,  1.80it/s, lr=9.84e-6, step_loss=0.3]07/18/2023 19:34:52 - INFO - __main__ - train loss is 13.262761483201757\n",
      "Steps:  33%|▎| 4932/15000 [31:30<1:32:22,  1.82it/s, lr=9.84e-6, step_loss=0.00507/18/2023 19:34:52 - INFO - __main__ - train loss is 13.465184325585142\n",
      "Steps:  33%|▎| 4933/15000 [31:30<1:31:57,  1.82it/s, lr=9.84e-6, step_loss=0.20207/18/2023 19:34:53 - INFO - __main__ - train loss is 14.176037485012785\n",
      "Steps:  33%|▎| 4934/15000 [31:31<1:31:41,  1.83it/s, lr=9.84e-6, step_loss=0.71107/18/2023 19:34:54 - INFO - __main__ - train loss is 14.239377299556509\n",
      "Steps:  33%|▎| 4935/15000 [31:31<1:31:23,  1.84it/s, lr=9.83e-6, step_loss=0.06307/18/2023 19:34:54 - INFO - __main__ - train loss is 14.268597444752231\n",
      "Steps:  33%|▎| 4936/15000 [31:32<1:31:35,  1.83it/s, lr=9.83e-6, step_loss=0.02907/18/2023 19:34:55 - INFO - __main__ - train loss is 14.369490703800693\n",
      "Steps:  33%|▎| 4937/15000 [31:32<1:31:11,  1.84it/s, lr=9.83e-6, step_loss=0.10107/18/2023 19:34:55 - INFO - __main__ - train loss is 14.574436178663746\n",
      "Steps:  33%|▎| 4938/15000 [31:33<1:30:55,  1.84it/s, lr=9.83e-6, step_loss=0.20507/18/2023 19:34:56 - INFO - __main__ - train loss is 14.648509090999141\n",
      "Steps:  33%|▎| 4939/15000 [31:34<1:30:52,  1.85it/s, lr=9.83e-6, step_loss=0.07407/18/2023 19:34:56 - INFO - __main__ - train loss is 14.658454871037975\n",
      "Steps:  33%|▎| 4940/15000 [31:34<1:30:47,  1.85it/s, lr=9.83e-6, step_loss=0.00907/18/2023 19:34:57 - INFO - __main__ - train loss is 14.66869479813613\n",
      "Steps:  33%|▎| 4941/15000 [31:35<1:30:33,  1.85it/s, lr=9.83e-6, step_loss=0.01007/18/2023 19:34:57 - INFO - __main__ - train loss is 14.993034903192893\n",
      "Steps:  33%|▎| 4942/15000 [31:35<1:30:40,  1.85it/s, lr=9.83e-6, step_loss=0.32407/18/2023 19:34:58 - INFO - __main__ - train loss is 15.32898623147048\n",
      "Steps:  33%|▎| 4943/15000 [31:36<1:31:08,  1.84it/s, lr=9.83e-6, step_loss=0.33607/18/2023 19:34:58 - INFO - __main__ - train loss is 15.336162020685151\n",
      "Steps:  33%|▎| 4944/15000 [31:36<1:31:58,  1.82it/s, lr=9.83e-6, step_loss=0.00707/18/2023 19:34:59 - INFO - __main__ - train loss is 16.008197834016755\n",
      "Steps:  33%|▎| 4945/15000 [31:37<1:31:29,  1.83it/s, lr=9.83e-6, step_loss=0.67207/18/2023 19:35:00 - INFO - __main__ - train loss is 16.029293761821464\n",
      "Steps:  33%|▎| 4946/15000 [31:37<1:31:09,  1.84it/s, lr=9.83e-6, step_loss=0.02107/18/2023 19:35:00 - INFO - __main__ - train loss is 16.041030533844605\n",
      "Steps:  33%|▎| 4947/15000 [31:38<1:41:22,  1.65it/s, lr=9.83e-6, step_loss=0.01107/18/2023 19:35:01 - INFO - __main__ - Per validation step average loss is 0.015280667692422867\n",
      "07/18/2023 19:35:01 - INFO - __main__ - Cumulative validation average loss is 0.015280667692422867\n",
      "07/18/2023 19:35:01 - INFO - __main__ - Per validation step average loss is 0.031558066606521606\n",
      "07/18/2023 19:35:01 - INFO - __main__ - Cumulative validation average loss is 0.04683873429894447\n",
      "07/18/2023 19:35:01 - INFO - __main__ - Per validation step average loss is 0.1353996992111206\n",
      "07/18/2023 19:35:01 - INFO - __main__ - Cumulative validation average loss is 0.18223843351006508\n",
      "07/18/2023 19:35:01 - INFO - __main__ - Per validation step average loss is 0.30990660190582275\n",
      "07/18/2023 19:35:01 - INFO - __main__ - Cumulative validation average loss is 0.49214503541588783\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Per validation step average loss is 0.04786369949579239\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Cumulative validation average loss is 0.5400087349116802\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Per validation step average loss is 0.00754042761400342\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Cumulative validation average loss is 0.5475491625256836\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Per validation step average loss is 0.0031282147392630577\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Cumulative validation average loss is 0.5506773772649467\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Per validation step average loss is 0.0017359477933496237\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Cumulative validation average loss is 0.5524133250582963\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Per validation step average loss is 0.1558167040348053\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Cumulative validation average loss is 0.7082300290931016\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Per validation step average loss is 0.31440800428390503\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Cumulative validation average loss is 1.0226380333770066\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Per validation step average loss is 0.2040553092956543\n",
      "07/18/2023 19:35:02 - INFO - __main__ - Cumulative validation average loss is 1.226693342672661\n",
      "07/18/2023 19:35:03 - INFO - __main__ - Per validation step average loss is 0.001926972414366901\n",
      "07/18/2023 19:35:03 - INFO - __main__ - Cumulative validation average loss is 1.2286203150870278\n",
      "07/18/2023 19:35:03 - INFO - __main__ - Average validation loss for Epoch 50 is 0.10238502625725232\n",
      "07/18/2023 19:35:03 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:35:15 - INFO - __main__ - Starting epoch 51\n",
      "07/18/2023 19:35:16 - INFO - __main__ - train loss is 0.010743672959506512\n",
      "Steps:  33%|▎| 4948/15000 [31:54<14:19:18,  5.13s/it, lr=9.83e-6, step_loss=0.0107/18/2023 19:35:16 - INFO - __main__ - train loss is 0.8141700578853488\n",
      "Steps:  33%|▎| 4949/15000 [31:54<10:10:37,  3.65s/it, lr=9.83e-6, step_loss=0.8007/18/2023 19:35:16 - INFO - __main__ - train loss is 0.8757468974217772\n",
      "Steps:  33%|▎| 4950/15000 [31:54<7:16:21,  2.61s/it, lr=9.83e-6, step_loss=0.06107/18/2023 19:35:16 - INFO - __main__ - train loss is 0.8774284552782774\n",
      "Steps:  33%|▎| 4951/15000 [31:54<5:14:21,  1.88s/it, lr=9.83e-6, step_loss=0.00107/18/2023 19:35:17 - INFO - __main__ - train loss is 0.9218405205756426\n",
      "Steps:  33%|▎| 4952/15000 [31:55<3:48:59,  1.37s/it, lr=9.83e-6, step_loss=0.04407/18/2023 19:35:17 - INFO - __main__ - train loss is 1.217470170930028\n",
      "Steps:  33%|▎| 4953/15000 [31:55<2:49:20,  1.01s/it, lr=9.83e-6, step_loss=0.29607/18/2023 19:35:17 - INFO - __main__ - train loss is 1.5960332471877337\n",
      "Steps:  33%|▎| 4954/15000 [31:55<2:07:28,  1.31it/s, lr=9.83e-6, step_loss=0.37907/18/2023 19:35:17 - INFO - __main__ - train loss is 1.605501877143979\n",
      "Steps:  33%|▎| 4955/15000 [31:55<1:38:09,  1.71it/s, lr=9.83e-6, step_loss=0.00907/18/2023 19:35:17 - INFO - __main__ - train loss is 1.8222453612834215\n",
      "Steps:  33%|▎| 4956/15000 [31:55<1:18:03,  2.14it/s, lr=9.83e-6, step_loss=0.21707/18/2023 19:35:18 - INFO - __main__ - train loss is 1.8885698784142733\n",
      "Steps:  33%|▎| 4957/15000 [31:55<1:03:39,  2.63it/s, lr=9.83e-6, step_loss=0.06607/18/2023 19:35:18 - INFO - __main__ - train loss is 2.0985921788960695\n",
      "Steps:  33%|▉  | 4958/15000 [31:56<53:29,  3.13it/s, lr=9.83e-6, step_loss=0.21]07/18/2023 19:35:18 - INFO - __main__ - train loss is 2.149676760658622\n",
      "Steps:  33%|▎| 4959/15000 [31:56<46:22,  3.61it/s, lr=9.83e-6, step_loss=0.0511]07/18/2023 19:35:18 - INFO - __main__ - train loss is 2.154979472979903\n",
      "Steps:  33%|▎| 4960/15000 [31:56<41:23,  4.04it/s, lr=9.83e-6, step_loss=0.0053]07/18/2023 19:35:18 - INFO - __main__ - train loss is 2.433556055650115\n",
      "Steps:  33%|▋ | 4961/15000 [31:56<38:11,  4.38it/s, lr=9.83e-6, step_loss=0.279]07/18/2023 19:35:18 - INFO - __main__ - train loss is 3.135455345734954\n",
      "Steps:  33%|▋ | 4962/15000 [31:56<35:56,  4.66it/s, lr=9.83e-6, step_loss=0.702]07/18/2023 19:35:19 - INFO - __main__ - train loss is 3.1474711932241917\n",
      "Steps:  33%|▋ | 4963/15000 [31:57<34:29,  4.85it/s, lr=9.83e-6, step_loss=0.012]07/18/2023 19:35:19 - INFO - __main__ - train loss is 3.171512421220541\n",
      "Steps:  33%|▋ | 4964/15000 [31:57<33:14,  5.03it/s, lr=9.83e-6, step_loss=0.024]07/18/2023 19:35:19 - INFO - __main__ - train loss is 3.2042647935450077\n",
      "Steps:  33%|▎| 4965/15000 [31:57<32:13,  5.19it/s, lr=9.83e-6, step_loss=0.0328]07/18/2023 19:35:19 - INFO - __main__ - train loss is 3.2303444165736437\n",
      "Steps:  33%|▎| 4966/15000 [31:57<31:30,  5.31it/s, lr=9.83e-6, step_loss=0.0261]07/18/2023 19:35:19 - INFO - __main__ - train loss is 3.2590117752552032\n",
      "Steps:  33%|▎| 4967/15000 [31:57<31:00,  5.39it/s, lr=9.83e-6, step_loss=0.0287]07/18/2023 19:35:20 - INFO - __main__ - train loss is 3.374105289578438\n",
      "Steps:  33%|▋ | 4968/15000 [31:57<30:39,  5.45it/s, lr=9.83e-6, step_loss=0.115]07/18/2023 19:35:20 - INFO - __main__ - train loss is 3.5333662629127502\n",
      "Steps:  33%|▋ | 4969/15000 [31:58<30:24,  5.50it/s, lr=9.83e-6, step_loss=0.159]07/18/2023 19:35:20 - INFO - __main__ - train loss is 3.806013435125351\n",
      "Steps:  33%|▋ | 4970/15000 [31:58<30:14,  5.53it/s, lr=9.83e-6, step_loss=0.273]07/18/2023 19:35:20 - INFO - __main__ - train loss is 3.8467554450035095\n",
      "Steps:  33%|▎| 4971/15000 [31:58<30:06,  5.55it/s, lr=9.83e-6, step_loss=0.0407]07/18/2023 19:35:20 - INFO - __main__ - train loss is 3.8488737721927464\n",
      "Steps:  33%|▎| 4972/15000 [31:58<30:00,  5.57it/s, lr=9.83e-6, step_loss=0.0021207/18/2023 19:35:20 - INFO - __main__ - train loss is 3.8680470888502896\n",
      "Steps:  33%|▎| 4973/15000 [31:58<29:57,  5.58it/s, lr=9.83e-6, step_loss=0.0192]07/18/2023 19:35:21 - INFO - __main__ - train loss is 4.385882884729654\n",
      "Steps:  33%|▋ | 4974/15000 [31:58<29:54,  5.59it/s, lr=9.83e-6, step_loss=0.518]07/18/2023 19:35:21 - INFO - __main__ - train loss is 4.393143656197935\n",
      "Steps:  33%|▎| 4975/15000 [31:59<29:52,  5.59it/s, lr=9.83e-6, step_loss=0.0072607/18/2023 19:35:21 - INFO - __main__ - train loss is 4.399755953345448\n",
      "Steps:  33%|▎| 4976/15000 [31:59<29:52,  5.59it/s, lr=9.83e-6, step_loss=0.0066107/18/2023 19:35:21 - INFO - __main__ - train loss is 4.657482384238392\n",
      "Steps:  33%|▋ | 4977/15000 [31:59<30:02,  5.56it/s, lr=9.83e-6, step_loss=0.258]07/18/2023 19:35:21 - INFO - __main__ - train loss is 5.110766022000462\n",
      "Steps:  33%|▋ | 4978/15000 [31:59<29:57,  5.57it/s, lr=9.83e-6, step_loss=0.453]07/18/2023 19:35:22 - INFO - __main__ - train loss is 5.116531556472182\n",
      "Steps:  33%|▎| 4979/15000 [31:59<29:54,  5.58it/s, lr=9.83e-6, step_loss=0.0057707/18/2023 19:35:22 - INFO - __main__ - train loss is 5.333164652809501\n",
      "Steps:  33%|▋ | 4980/15000 [32:00<29:53,  5.59it/s, lr=9.83e-6, step_loss=0.217]07/18/2023 19:35:22 - INFO - __main__ - train loss is 5.336005242541432\n",
      "Steps:  33%|▎| 4981/15000 [32:00<29:51,  5.59it/s, lr=9.83e-6, step_loss=0.0028407/18/2023 19:35:22 - INFO - __main__ - train loss is 6.187277706339955\n",
      "Steps:  33%|▋ | 4982/15000 [32:00<29:49,  5.60it/s, lr=9.83e-6, step_loss=0.851]07/18/2023 19:35:22 - INFO - __main__ - train loss is 6.358556600287557\n",
      "Steps:  33%|▋ | 4983/15000 [32:00<29:49,  5.60it/s, lr=9.83e-6, step_loss=0.171]07/18/2023 19:35:22 - INFO - __main__ - train loss is 6.401335356757045\n",
      "Steps:  33%|▎| 4984/15000 [32:00<29:48,  5.60it/s, lr=9.83e-6, step_loss=0.0428]07/18/2023 19:35:23 - INFO - __main__ - train loss is 6.562851486727595\n",
      "Steps:  33%|▋ | 4985/15000 [32:00<29:48,  5.60it/s, lr=9.83e-6, step_loss=0.162]07/18/2023 19:35:23 - INFO - __main__ - train loss is 6.607466055080295\n",
      "Steps:  33%|▎| 4986/15000 [32:01<29:50,  5.59it/s, lr=9.83e-6, step_loss=0.0446]07/18/2023 19:35:23 - INFO - __main__ - train loss is 6.628910878673196\n",
      "Steps:  33%|▎| 4987/15000 [32:01<29:48,  5.60it/s, lr=9.83e-6, step_loss=0.0214]07/18/2023 19:35:23 - INFO - __main__ - train loss is 6.630825522355735\n",
      "Steps:  33%|▎| 4988/15000 [32:01<30:05,  5.55it/s, lr=9.83e-6, step_loss=0.0019107/18/2023 19:35:23 - INFO - __main__ - train loss is 6.633430499350652\n",
      "Steps:  33%|▎| 4989/15000 [32:01<30:14,  5.52it/s, lr=9.83e-6, step_loss=0.0026]07/18/2023 19:35:23 - INFO - __main__ - train loss is 6.899052578723058\n",
      "Steps:  33%|▋ | 4990/15000 [32:01<30:04,  5.55it/s, lr=9.83e-6, step_loss=0.266]07/18/2023 19:35:24 - INFO - __main__ - train loss is 7.004074942087755\n",
      "Steps:  33%|▋ | 4991/15000 [32:02<29:58,  5.56it/s, lr=9.83e-6, step_loss=0.105]07/18/2023 19:35:24 - INFO - __main__ - train loss is 7.023451411863789\n",
      "Steps:  33%|▎| 4992/15000 [32:02<29:54,  5.58it/s, lr=9.83e-6, step_loss=0.0194]07/18/2023 19:35:24 - INFO - __main__ - train loss is 7.195576095720753\n",
      "Steps:  33%|▋ | 4993/15000 [32:02<29:51,  5.59it/s, lr=9.83e-6, step_loss=0.172]07/18/2023 19:35:24 - INFO - __main__ - train loss is 7.746729517122731\n",
      "Steps:  33%|▋ | 4994/15000 [32:02<29:49,  5.59it/s, lr=9.83e-6, step_loss=0.551]07/18/2023 19:35:24 - INFO - __main__ - train loss is 8.265655541559681\n",
      "Steps:  33%|▋ | 4995/15000 [32:02<30:04,  5.55it/s, lr=9.83e-6, step_loss=0.519]07/18/2023 19:35:25 - INFO - __main__ - train loss is 8.375864455243573\n",
      "Steps:  33%|▉  | 4996/15000 [32:02<30:11,  5.52it/s, lr=9.83e-6, step_loss=0.11]07/18/2023 19:35:25 - INFO - __main__ - train loss is 8.508901485940441\n",
      "Steps:  33%|▋ | 4997/15000 [32:03<30:21,  5.49it/s, lr=9.83e-6, step_loss=0.133]07/18/2023 19:35:25 - INFO - __main__ - train loss is 8.534182866802439\n",
      "Steps:  33%|▎| 4998/15000 [32:03<30:24,  5.48it/s, lr=9.83e-6, step_loss=0.0253]07/18/2023 19:35:25 - INFO - __main__ - train loss is 8.759982665767893\n",
      "Steps:  33%|▋ | 4999/15000 [32:03<30:30,  5.46it/s, lr=9.83e-6, step_loss=0.226]07/18/2023 19:35:25 - INFO - __main__ - train loss is 9.006560152163729\n",
      "Steps:  33%|▋ | 5000/15000 [32:03<30:23,  5.48it/s, lr=9.83e-6, step_loss=0.226]07/18/2023 19:35:25 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-5000\n",
      "07/18/2023 19:35:25 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:35:25,880] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:35:25,884] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-5000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:35:25,884] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-5000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:35:25,892] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-5000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:35:25,892] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-5000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:35:25,914] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-5000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:35:25,914] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-5000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:35:25,914] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:35:25 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-5000/pytorch_model\n",
      "07/18/2023 19:35:25 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-5000/scheduler.bin\n",
      "07/18/2023 19:35:25 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-5000/random_states_0.pkl\n",
      "07/18/2023 19:35:25 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-5000\n",
      "Steps:  33%|▋ | 5000/15000 [32:03<30:23,  5.48it/s, lr=9.83e-6, step_loss=0.247]07/18/2023 19:35:26 - INFO - __main__ - train loss is 9.04022922529839\n",
      "Steps:  33%|▎| 5001/15000 [32:03<32:03,  5.20it/s, lr=9.83e-6, step_loss=0.0337]07/18/2023 19:35:26 - INFO - __main__ - train loss is 9.370501542231068\n",
      "Steps:  33%|█  | 5002/15000 [32:04<31:41,  5.26it/s, lr=9.83e-6, step_loss=0.33]07/18/2023 19:35:26 - INFO - __main__ - train loss is 9.623596573015675\n",
      "Steps:  33%|▋ | 5003/15000 [32:04<31:16,  5.33it/s, lr=9.83e-6, step_loss=0.253]07/18/2023 19:35:26 - INFO - __main__ - train loss is 10.025766188045964\n",
      "Steps:  33%|▋ | 5004/15000 [32:04<30:48,  5.41it/s, lr=9.83e-6, step_loss=0.402]07/18/2023 19:35:26 - INFO - __main__ - train loss is 10.032447304343805\n",
      "Steps:  33%|▎| 5005/15000 [32:04<30:29,  5.46it/s, lr=9.83e-6, step_loss=0.0066807/18/2023 19:35:26 - INFO - __main__ - train loss is 10.990843262290582\n",
      "Steps:  33%|▋ | 5006/15000 [32:04<30:16,  5.50it/s, lr=9.83e-6, step_loss=0.958]07/18/2023 19:35:27 - INFO - __main__ - train loss is 10.995930216973647\n",
      "Steps:  33%|▎| 5007/15000 [32:04<30:07,  5.53it/s, lr=9.83e-6, step_loss=0.0050907/18/2023 19:35:27 - INFO - __main__ - train loss is 10.998811970232055\n",
      "Steps:  33%|▎| 5008/15000 [32:05<30:12,  5.51it/s, lr=9.83e-6, step_loss=0.0028807/18/2023 19:35:27 - INFO - __main__ - train loss is 11.010794793022797\n",
      "Steps:  33%|▋ | 5009/15000 [32:05<30:04,  5.54it/s, lr=9.83e-6, step_loss=0.012]07/18/2023 19:35:27 - INFO - __main__ - train loss is 11.149641220225021\n",
      "Steps:  33%|▋ | 5010/15000 [32:05<29:58,  5.55it/s, lr=9.83e-6, step_loss=0.139]07/18/2023 19:35:27 - INFO - __main__ - train loss is 11.270176996244118\n",
      "Steps:  33%|▋ | 5011/15000 [32:05<29:54,  5.57it/s, lr=9.83e-6, step_loss=0.121]07/18/2023 19:35:27 - INFO - __main__ - train loss is 11.506463487399742\n",
      "Steps:  33%|▋ | 5012/15000 [32:05<29:51,  5.57it/s, lr=9.83e-6, step_loss=0.236]07/18/2023 19:35:28 - INFO - __main__ - train loss is 11.510058970423415\n",
      "Steps:  33%|▎| 5013/15000 [32:06<29:49,  5.58it/s, lr=9.83e-6, step_loss=0.0036]07/18/2023 19:35:28 - INFO - __main__ - train loss is 11.544185140402988\n",
      "Steps:  33%|▎| 5014/15000 [32:06<29:49,  5.58it/s, lr=9.83e-6, step_loss=0.0341]07/18/2023 19:35:28 - INFO - __main__ - train loss is 11.548413906479254\n",
      "Steps:  33%|▎| 5015/15000 [32:06<29:47,  5.59it/s, lr=9.83e-6, step_loss=0.0042307/18/2023 19:35:28 - INFO - __main__ - train loss is 12.043353144312277\n",
      "Steps:  33%|▋ | 5016/15000 [32:06<29:47,  5.59it/s, lr=9.83e-6, step_loss=0.495]07/18/2023 19:35:28 - INFO - __main__ - train loss is 12.257595543051139\n",
      "Steps:  33%|▋ | 5017/15000 [32:06<29:46,  5.59it/s, lr=9.83e-6, step_loss=0.214]07/18/2023 19:35:29 - INFO - __main__ - train loss is 12.959922317648306\n",
      "Steps:  33%|▋ | 5018/15000 [32:06<29:44,  5.59it/s, lr=9.83e-6, step_loss=0.702]07/18/2023 19:35:29 - INFO - __main__ - train loss is 13.070091549539939\n",
      "Steps:  33%|█  | 5019/15000 [32:07<29:42,  5.60it/s, lr=9.83e-6, step_loss=0.11]07/18/2023 19:35:29 - INFO - __main__ - train loss is 13.116477377945557\n",
      "Steps:  33%|▎| 5020/15000 [32:07<29:44,  5.59it/s, lr=9.83e-6, step_loss=0.0464]07/18/2023 19:35:29 - INFO - __main__ - train loss is 13.234868102008477\n",
      "Steps:  33%|▋ | 5021/15000 [32:07<29:43,  5.59it/s, lr=9.83e-6, step_loss=0.118]07/18/2023 19:35:29 - INFO - __main__ - train loss is 13.768513016635552\n",
      "Steps:  33%|▋ | 5022/15000 [32:07<29:43,  5.60it/s, lr=9.83e-6, step_loss=0.534]07/18/2023 19:35:29 - INFO - __main__ - train loss is 13.867069430882111\n",
      "Steps:  33%|▎| 5023/15000 [32:07<29:43,  5.60it/s, lr=9.83e-6, step_loss=0.0986]07/18/2023 19:35:30 - INFO - __main__ - train loss is 14.166640766197816\n",
      "Steps:  33%|█▎  | 5024/15000 [32:08<29:42,  5.60it/s, lr=9.83e-6, step_loss=0.3]07/18/2023 19:35:30 - INFO - __main__ - train loss is 14.603437431389466\n",
      "Steps:  34%|▋ | 5025/15000 [32:08<29:42,  5.60it/s, lr=9.83e-6, step_loss=0.437]07/18/2023 19:35:30 - INFO - __main__ - train loss is 14.64004946523346\n",
      "Steps:  34%|▎| 5026/15000 [32:08<29:43,  5.59it/s, lr=9.83e-6, step_loss=0.0366]07/18/2023 19:35:30 - INFO - __main__ - train loss is 14.702110547805205\n",
      "Steps:  34%|▎| 5027/15000 [32:08<29:41,  5.60it/s, lr=9.83e-6, step_loss=0.0621]07/18/2023 19:35:30 - INFO - __main__ - train loss is 14.712052747840062\n",
      "Steps:  34%|▎| 5028/15000 [32:08<29:39,  5.60it/s, lr=9.83e-6, step_loss=0.0099407/18/2023 19:35:31 - INFO - __main__ - train loss is 14.760040745371953\n",
      "Steps:  34%|▋ | 5029/15000 [32:08<29:38,  5.61it/s, lr=9.83e-6, step_loss=0.048]07/18/2023 19:35:31 - INFO - __main__ - train loss is 14.93561452650465\n",
      "Steps:  34%|▋ | 5030/15000 [32:09<29:37,  5.61it/s, lr=9.83e-6, step_loss=0.176]07/18/2023 19:35:31 - INFO - __main__ - train loss is 15.042051151627675\n",
      "Steps:  34%|▋ | 5031/15000 [32:09<29:36,  5.61it/s, lr=9.83e-6, step_loss=0.106]07/18/2023 19:35:31 - INFO - __main__ - train loss is 15.286114052170888\n",
      "Steps:  34%|▋ | 5032/15000 [32:09<29:50,  5.57it/s, lr=9.83e-6, step_loss=0.244]07/18/2023 19:35:31 - INFO - __main__ - train loss is 15.369903102749959\n",
      "Steps:  34%|▎| 5033/15000 [32:09<29:59,  5.54it/s, lr=9.83e-6, step_loss=0.0838]07/18/2023 19:35:31 - INFO - __main__ - train loss is 15.459467888111249\n",
      "Steps:  34%|▎| 5034/15000 [32:09<29:52,  5.56it/s, lr=9.83e-6, step_loss=0.0896]07/18/2023 19:35:32 - INFO - __main__ - train loss is 15.89513933681883\n",
      "Steps:  34%|▋ | 5035/15000 [32:09<29:46,  5.58it/s, lr=9.83e-6, step_loss=0.436]07/18/2023 19:35:32 - INFO - __main__ - train loss is 16.284556806320325\n",
      "Steps:  34%|▋ | 5036/15000 [32:10<29:41,  5.59it/s, lr=9.83e-6, step_loss=0.389]07/18/2023 19:35:32 - INFO - __main__ - train loss is 16.573596060508862\n",
      "Steps:  34%|▋ | 5037/15000 [32:10<29:37,  5.60it/s, lr=9.83e-6, step_loss=0.289]07/18/2023 19:35:32 - INFO - __main__ - train loss is 16.584245145553723\n",
      "Steps:  34%|▎| 5038/15000 [32:10<29:35,  5.61it/s, lr=9.83e-6, step_loss=0.0106]07/18/2023 19:35:32 - INFO - __main__ - train loss is 16.634157471591607\n",
      "Steps:  34%|▎| 5039/15000 [32:10<29:33,  5.62it/s, lr=9.83e-6, step_loss=0.0499]07/18/2023 19:35:32 - INFO - __main__ - train loss is 16.642025688895956\n",
      "Steps:  34%|▎| 5040/15000 [32:10<29:32,  5.62it/s, lr=9.83e-6, step_loss=0.0078707/18/2023 19:35:33 - INFO - __main__ - train loss is 16.64868029509671\n",
      "Steps:  34%|▎| 5041/15000 [32:11<29:31,  5.62it/s, lr=9.83e-6, step_loss=0.0066507/18/2023 19:35:33 - INFO - __main__ - train loss is 16.771679158555344\n",
      "Steps:  34%|▋ | 5042/15000 [32:11<29:30,  5.62it/s, lr=9.83e-6, step_loss=0.123]07/18/2023 19:35:33 - INFO - __main__ - train loss is 16.834427963243797\n",
      "Steps:  34%|▎| 5043/15000 [32:11<29:29,  5.63it/s, lr=9.83e-6, step_loss=0.0627]07/18/2023 19:35:33 - INFO - __main__ - train loss is 16.839678923832253\n",
      "Steps:  34%|▎| 5044/15000 [32:11<40:46,  4.07it/s, lr=9.83e-6, step_loss=0.0052507/18/2023 19:35:34 - INFO - __main__ - Per validation step average loss is 0.27734649181365967\n",
      "07/18/2023 19:35:34 - INFO - __main__ - Cumulative validation average loss is 0.27734649181365967\n",
      "07/18/2023 19:35:34 - INFO - __main__ - Per validation step average loss is 0.19620665907859802\n",
      "07/18/2023 19:35:34 - INFO - __main__ - Cumulative validation average loss is 0.4735531508922577\n",
      "07/18/2023 19:35:34 - INFO - __main__ - Per validation step average loss is 0.06211360916495323\n",
      "07/18/2023 19:35:34 - INFO - __main__ - Cumulative validation average loss is 0.5356667600572109\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Per validation step average loss is 0.00447362195700407\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Cumulative validation average loss is 0.540140382014215\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Per validation step average loss is 0.3023279011249542\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Cumulative validation average loss is 0.8424682831391692\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Per validation step average loss is 0.03567405790090561\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Cumulative validation average loss is 0.8781423410400748\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Per validation step average loss is 0.047368913888931274\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Cumulative validation average loss is 0.9255112549290061\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Per validation step average loss is 0.15473315119743347\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Cumulative validation average loss is 1.0802444061264396\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Per validation step average loss is 0.03592889755964279\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Cumulative validation average loss is 1.1161733036860824\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Per validation step average loss is 0.08011624217033386\n",
      "07/18/2023 19:35:35 - INFO - __main__ - Cumulative validation average loss is 1.1962895458564162\n",
      "07/18/2023 19:35:36 - INFO - __main__ - Per validation step average loss is 0.004336304031312466\n",
      "07/18/2023 19:35:36 - INFO - __main__ - Cumulative validation average loss is 1.2006258498877287\n",
      "07/18/2023 19:35:36 - INFO - __main__ - Per validation step average loss is 0.02117830142378807\n",
      "07/18/2023 19:35:36 - INFO - __main__ - Cumulative validation average loss is 1.2218041513115168\n",
      "07/18/2023 19:35:36 - INFO - __main__ - Average validation loss for Epoch 51 is 0.10181701260929306\n",
      "07/18/2023 19:35:36 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:35:49 - INFO - __main__ - Starting epoch 52\n",
      "07/18/2023 19:35:49 - INFO - __main__ - train loss is 0.07828410714864731\n",
      "Steps:  34%|▎| 5045/15000 [32:27<13:36:52,  4.92s/it, lr=9.83e-6, step_loss=0.0707/18/2023 19:35:49 - INFO - __main__ - train loss is 0.44968288391828537\n",
      "Steps:  34%|▎| 5046/15000 [32:27<9:40:39,  3.50s/it, lr=9.83e-6, step_loss=0.37107/18/2023 19:35:50 - INFO - __main__ - train loss is 0.5818025395274162\n",
      "Steps:  34%|▎| 5047/15000 [32:28<6:55:34,  2.51s/it, lr=9.83e-6, step_loss=0.13207/18/2023 19:35:50 - INFO - __main__ - train loss is 0.6126448251307011\n",
      "Steps:  34%|▎| 5048/15000 [32:28<5:00:16,  1.81s/it, lr=9.83e-6, step_loss=0.03007/18/2023 19:35:50 - INFO - __main__ - train loss is 0.7211526222527027\n",
      "Steps:  34%|▎| 5049/15000 [32:28<3:39:35,  1.32s/it, lr=9.83e-6, step_loss=0.10907/18/2023 19:35:50 - INFO - __main__ - train loss is 1.0963086672127247\n",
      "Steps:  34%|▎| 5050/15000 [32:28<2:43:11,  1.02it/s, lr=9.83e-6, step_loss=0.37507/18/2023 19:35:50 - INFO - __main__ - train loss is 1.3191196657717228\n",
      "Steps:  34%|▎| 5051/15000 [32:28<2:03:39,  1.34it/s, lr=9.83e-6, step_loss=0.22307/18/2023 19:35:51 - INFO - __main__ - train loss is 1.478314895182848\n",
      "Steps:  34%|▎| 5052/15000 [32:28<1:35:28,  1.74it/s, lr=9.83e-6, step_loss=0.15907/18/2023 19:35:51 - INFO - __main__ - train loss is 1.4929662868380547\n",
      "Steps:  34%|▎| 5053/15000 [32:29<1:15:41,  2.19it/s, lr=9.83e-6, step_loss=0.01407/18/2023 19:35:51 - INFO - __main__ - train loss is 1.5977811440825462\n",
      "Steps:  34%|▎| 5054/15000 [32:29<1:01:56,  2.68it/s, lr=9.83e-6, step_loss=0.10507/18/2023 19:35:51 - INFO - __main__ - train loss is 1.5996133430162445\n",
      "Steps:  34%|▎| 5055/15000 [32:29<52:36,  3.15it/s, lr=9.83e-6, step_loss=0.0018307/18/2023 19:35:51 - INFO - __main__ - train loss is 1.683250461355783\n",
      "Steps:  34%|▎| 5056/15000 [32:29<45:44,  3.62it/s, lr=9.83e-6, step_loss=0.0836]07/18/2023 19:35:51 - INFO - __main__ - train loss is 1.7627067459980026\n",
      "Steps:  34%|▎| 5057/15000 [32:29<40:52,  4.05it/s, lr=9.83e-6, step_loss=0.0795]07/18/2023 19:35:52 - INFO - __main__ - train loss is 1.7696454260731116\n",
      "Steps:  34%|▎| 5058/15000 [32:30<37:44,  4.39it/s, lr=9.83e-6, step_loss=0.0069407/18/2023 19:35:52 - INFO - __main__ - train loss is 2.1263724599266425\n",
      "Steps:  34%|▋ | 5059/15000 [32:30<35:23,  4.68it/s, lr=9.83e-6, step_loss=0.357]07/18/2023 19:35:52 - INFO - __main__ - train loss is 2.1302887002239004\n",
      "Steps:  34%|▎| 5060/15000 [32:30<34:33,  4.79it/s, lr=9.83e-6, step_loss=0.0039207/18/2023 19:35:52 - INFO - __main__ - train loss is 2.2412706637987867\n",
      "Steps:  34%|▋ | 5061/15000 [32:30<33:38,  4.92it/s, lr=9.83e-6, step_loss=0.111]07/18/2023 19:35:52 - INFO - __main__ - train loss is 2.3678694689879194\n",
      "Steps:  34%|▋ | 5062/15000 [32:30<32:51,  5.04it/s, lr=9.83e-6, step_loss=0.127]07/18/2023 19:35:53 - INFO - __main__ - train loss is 2.4887284064898267\n",
      "Steps:  34%|▋ | 5063/15000 [32:30<32:58,  5.02it/s, lr=9.83e-6, step_loss=0.121]07/18/2023 19:35:53 - INFO - __main__ - train loss is 2.4978734623873606\n",
      "Steps:  34%|▎| 5064/15000 [32:31<32:14,  5.14it/s, lr=9.83e-6, step_loss=0.0091507/18/2023 19:35:53 - INFO - __main__ - train loss is 2.768688864656724\n",
      "Steps:  34%|▋ | 5065/15000 [32:31<31:44,  5.22it/s, lr=9.83e-6, step_loss=0.271]07/18/2023 19:35:53 - INFO - __main__ - train loss is 3.1705576848471537\n",
      "Steps:  34%|▋ | 5066/15000 [32:31<31:22,  5.28it/s, lr=9.83e-6, step_loss=0.402]07/18/2023 19:35:53 - INFO - __main__ - train loss is 3.2594091814244166\n",
      "Steps:  34%|▎| 5067/15000 [32:31<30:49,  5.37it/s, lr=9.83e-6, step_loss=0.0889]07/18/2023 19:35:54 - INFO - __main__ - train loss is 3.3758248385274783\n",
      "Steps:  34%|▋ | 5068/15000 [32:31<30:27,  5.43it/s, lr=9.83e-6, step_loss=0.116]07/18/2023 19:35:54 - INFO - __main__ - train loss is 3.46343402529601\n",
      "Steps:  34%|▎| 5069/15000 [32:32<30:12,  5.48it/s, lr=9.83e-6, step_loss=0.0876]07/18/2023 19:35:54 - INFO - __main__ - train loss is 3.5665235962951556\n",
      "Steps:  34%|▋ | 5070/15000 [32:32<30:11,  5.48it/s, lr=9.83e-6, step_loss=0.103]07/18/2023 19:35:54 - INFO - __main__ - train loss is 3.6366993185365573\n",
      "Steps:  34%|▎| 5071/15000 [32:32<30:07,  5.49it/s, lr=9.83e-6, step_loss=0.0702]07/18/2023 19:35:54 - INFO - __main__ - train loss is 3.6562216595048085\n",
      "Steps:  34%|▎| 5072/15000 [32:32<30:09,  5.49it/s, lr=9.83e-6, step_loss=0.0195]07/18/2023 19:35:54 - INFO - __main__ - train loss is 3.754098252975382\n",
      "Steps:  34%|▎| 5073/15000 [32:32<30:18,  5.46it/s, lr=9.83e-6, step_loss=0.0979]07/18/2023 19:35:55 - INFO - __main__ - train loss is 3.815337972366251\n",
      "Steps:  34%|▎| 5074/15000 [32:33<30:25,  5.44it/s, lr=9.83e-6, step_loss=0.0612]07/18/2023 19:35:55 - INFO - __main__ - train loss is 3.8222503709839657\n",
      "Steps:  34%|▎| 5075/15000 [32:33<30:32,  5.42it/s, lr=9.83e-6, step_loss=0.0069107/18/2023 19:35:55 - INFO - __main__ - train loss is 3.825778920087032\n",
      "Steps:  34%|▎| 5076/15000 [32:33<30:21,  5.45it/s, lr=9.83e-6, step_loss=0.0035307/18/2023 19:35:55 - INFO - __main__ - train loss is 3.8605646825162694\n",
      "Steps:  34%|▎| 5077/15000 [32:33<30:14,  5.47it/s, lr=9.83e-6, step_loss=0.0348]07/18/2023 19:35:55 - INFO - __main__ - train loss is 4.005460936459713\n",
      "Steps:  34%|▋ | 5078/15000 [32:33<30:09,  5.48it/s, lr=9.83e-6, step_loss=0.145]07/18/2023 19:35:56 - INFO - __main__ - train loss is 4.245086539420299\n",
      "Steps:  34%|█  | 5079/15000 [32:33<30:06,  5.49it/s, lr=9.83e-6, step_loss=0.24]07/18/2023 19:35:56 - INFO - __main__ - train loss is 5.1758057362167165\n",
      "Steps:  34%|▋ | 5080/15000 [32:34<30:03,  5.50it/s, lr=9.83e-6, step_loss=0.931]07/18/2023 19:35:56 - INFO - __main__ - train loss is 5.195080142351799\n",
      "Steps:  34%|▎| 5081/15000 [32:34<30:10,  5.48it/s, lr=9.83e-6, step_loss=0.0193]07/18/2023 19:35:56 - INFO - __main__ - train loss is 5.218823250266723\n",
      "Steps:  34%|▎| 5082/15000 [32:34<30:05,  5.49it/s, lr=9.82e-6, step_loss=0.0237]07/18/2023 19:35:56 - INFO - __main__ - train loss is 5.232644323143177\n",
      "Steps:  34%|▎| 5083/15000 [32:34<30:02,  5.50it/s, lr=9.82e-6, step_loss=0.0138]07/18/2023 19:35:56 - INFO - __main__ - train loss is 5.7074379659025\n",
      "Steps:  34%|▋ | 5084/15000 [32:34<30:00,  5.51it/s, lr=9.82e-6, step_loss=0.475]07/18/2023 19:35:57 - INFO - __main__ - train loss is 5.711500228266232\n",
      "Steps:  34%|▎| 5085/15000 [32:35<29:58,  5.51it/s, lr=9.82e-6, step_loss=0.0040607/18/2023 19:35:57 - INFO - __main__ - train loss is 5.858315915684216\n",
      "Steps:  34%|▋ | 5086/15000 [32:35<29:57,  5.52it/s, lr=9.82e-6, step_loss=0.147]07/18/2023 19:35:57 - INFO - __main__ - train loss is 6.227420599083416\n",
      "Steps:  34%|▋ | 5087/15000 [32:35<29:57,  5.52it/s, lr=9.82e-6, step_loss=0.369]07/18/2023 19:35:57 - INFO - __main__ - train loss is 6.278986428747885\n",
      "Steps:  34%|▎| 5088/15000 [32:35<29:57,  5.52it/s, lr=9.82e-6, step_loss=0.0516]07/18/2023 19:35:57 - INFO - __main__ - train loss is 6.373253662954085\n",
      "Steps:  34%|▎| 5089/15000 [32:35<29:56,  5.52it/s, lr=9.82e-6, step_loss=0.0943]07/18/2023 19:35:58 - INFO - __main__ - train loss is 6.5419563696486875\n",
      "Steps:  34%|▋ | 5090/15000 [32:35<30:11,  5.47it/s, lr=9.82e-6, step_loss=0.169]07/18/2023 19:35:58 - INFO - __main__ - train loss is 6.903921280871145\n",
      "Steps:  34%|▋ | 5091/15000 [32:36<30:02,  5.50it/s, lr=9.82e-6, step_loss=0.362]07/18/2023 19:35:58 - INFO - __main__ - train loss is 7.337082628975622\n",
      "Steps:  34%|▋ | 5092/15000 [32:36<29:53,  5.53it/s, lr=9.82e-6, step_loss=0.433]07/18/2023 19:35:58 - INFO - __main__ - train loss is 7.551184152136557\n",
      "Steps:  34%|▋ | 5093/15000 [32:36<29:46,  5.55it/s, lr=9.82e-6, step_loss=0.214]07/18/2023 19:35:58 - INFO - __main__ - train loss is 7.565380616928451\n",
      "Steps:  34%|▎| 5094/15000 [32:36<29:40,  5.56it/s, lr=9.82e-6, step_loss=0.0142]07/18/2023 19:35:58 - INFO - __main__ - train loss is 7.602486549760215\n",
      "Steps:  34%|▎| 5095/15000 [32:36<29:36,  5.58it/s, lr=9.82e-6, step_loss=0.0371]07/18/2023 19:35:59 - INFO - __main__ - train loss is 8.078301190282218\n",
      "Steps:  34%|▋ | 5096/15000 [32:36<29:33,  5.58it/s, lr=9.82e-6, step_loss=0.476]07/18/2023 19:35:59 - INFO - __main__ - train loss is 8.219824879313819\n",
      "Steps:  34%|▋ | 5097/15000 [32:37<29:32,  5.59it/s, lr=9.82e-6, step_loss=0.142]07/18/2023 19:35:59 - INFO - __main__ - train loss is 8.234351181308739\n",
      "Steps:  34%|▎| 5098/15000 [32:37<29:32,  5.59it/s, lr=9.82e-6, step_loss=0.0145]07/18/2023 19:35:59 - INFO - __main__ - train loss is 8.52620222500991\n",
      "Steps:  34%|▋ | 5099/15000 [32:37<29:31,  5.59it/s, lr=9.82e-6, step_loss=0.292]07/18/2023 19:35:59 - INFO - __main__ - train loss is 8.532390816952102\n",
      "Steps:  34%|▎| 5100/15000 [32:37<29:40,  5.56it/s, lr=9.82e-6, step_loss=0.0061907/18/2023 19:35:59 - INFO - __main__ - train loss is 8.845372184063308\n",
      "Steps:  34%|▋ | 5101/15000 [32:37<29:37,  5.57it/s, lr=9.82e-6, step_loss=0.313]07/18/2023 19:36:00 - INFO - __main__ - train loss is 8.937175436760299\n",
      "Steps:  34%|▎| 5102/15000 [32:38<29:38,  5.57it/s, lr=9.82e-6, step_loss=0.0918]07/18/2023 19:36:00 - INFO - __main__ - train loss is 8.967511142487638\n",
      "Steps:  34%|▎| 5103/15000 [32:38<29:35,  5.57it/s, lr=9.82e-6, step_loss=0.0303]07/18/2023 19:36:00 - INFO - __main__ - train loss is 9.037945399875753\n",
      "Steps:  34%|▎| 5104/15000 [32:38<29:32,  5.58it/s, lr=9.82e-6, step_loss=0.0704]07/18/2023 19:36:00 - INFO - __main__ - train loss is 9.641972790355794\n",
      "Steps:  34%|▋ | 5105/15000 [32:38<29:31,  5.58it/s, lr=9.82e-6, step_loss=0.604]07/18/2023 19:36:00 - INFO - __main__ - train loss is 9.81158844649326\n",
      "Steps:  34%|█  | 5106/15000 [32:38<29:30,  5.59it/s, lr=9.82e-6, step_loss=0.17]07/18/2023 19:36:01 - INFO - __main__ - train loss is 9.923238540883176\n",
      "Steps:  34%|▋ | 5107/15000 [32:38<29:30,  5.59it/s, lr=9.82e-6, step_loss=0.112]07/18/2023 19:36:01 - INFO - __main__ - train loss is 9.941821939195506\n",
      "Steps:  34%|▎| 5108/15000 [32:39<29:28,  5.59it/s, lr=9.82e-6, step_loss=0.0186]07/18/2023 19:36:01 - INFO - __main__ - train loss is 10.116865641321056\n",
      "Steps:  34%|▋ | 5109/15000 [32:39<29:27,  5.60it/s, lr=9.82e-6, step_loss=0.175]07/18/2023 19:36:01 - INFO - __main__ - train loss is 10.119564215070568\n",
      "Steps:  34%|▎| 5110/15000 [32:39<29:26,  5.60it/s, lr=9.82e-6, step_loss=0.0027]07/18/2023 19:36:01 - INFO - __main__ - train loss is 10.150459666154347\n",
      "Steps:  34%|▎| 5111/15000 [32:39<29:26,  5.60it/s, lr=9.82e-6, step_loss=0.0309]07/18/2023 19:36:01 - INFO - __main__ - train loss is 10.158041565096937\n",
      "Steps:  34%|▎| 5112/15000 [32:39<29:25,  5.60it/s, lr=9.82e-6, step_loss=0.0075807/18/2023 19:36:02 - INFO - __main__ - train loss is 10.27642458525952\n",
      "Steps:  34%|▋ | 5113/15000 [32:40<29:26,  5.60it/s, lr=9.82e-6, step_loss=0.118]07/18/2023 19:36:02 - INFO - __main__ - train loss is 10.393585114157759\n",
      "Steps:  34%|▋ | 5114/15000 [32:40<29:25,  5.60it/s, lr=9.82e-6, step_loss=0.117]07/18/2023 19:36:02 - INFO - __main__ - train loss is 10.478262691176496\n",
      "Steps:  34%|▎| 5115/15000 [32:40<29:24,  5.60it/s, lr=9.82e-6, step_loss=0.0847]07/18/2023 19:36:02 - INFO - __main__ - train loss is 10.511747109121643\n",
      "Steps:  34%|▎| 5116/15000 [32:40<29:25,  5.60it/s, lr=9.82e-6, step_loss=0.0335]07/18/2023 19:36:02 - INFO - __main__ - train loss is 10.95011966151651\n",
      "Steps:  34%|▋ | 5117/15000 [32:40<29:24,  5.60it/s, lr=9.82e-6, step_loss=0.438]07/18/2023 19:36:03 - INFO - __main__ - train loss is 11.217533098882996\n",
      "Steps:  34%|▋ | 5118/15000 [32:40<29:41,  5.55it/s, lr=9.82e-6, step_loss=0.267]07/18/2023 19:36:03 - INFO - __main__ - train loss is 11.924026714987122\n",
      "Steps:  34%|▋ | 5119/15000 [32:41<29:43,  5.54it/s, lr=9.82e-6, step_loss=0.706]07/18/2023 19:36:03 - INFO - __main__ - train loss is 12.082981990999542\n",
      "Steps:  34%|▋ | 5120/15000 [32:41<29:38,  5.55it/s, lr=9.82e-6, step_loss=0.159]07/18/2023 19:36:03 - INFO - __main__ - train loss is 12.36033408564981\n",
      "Steps:  34%|▋ | 5121/15000 [32:41<29:35,  5.56it/s, lr=9.82e-6, step_loss=0.277]07/18/2023 19:36:03 - INFO - __main__ - train loss is 12.684322940534912\n",
      "Steps:  34%|▋ | 5122/15000 [32:41<29:31,  5.58it/s, lr=9.82e-6, step_loss=0.324]07/18/2023 19:36:03 - INFO - __main__ - train loss is 12.68716758058872\n",
      "Steps:  34%|▎| 5123/15000 [32:41<29:29,  5.58it/s, lr=9.82e-6, step_loss=0.0028407/18/2023 19:36:04 - INFO - __main__ - train loss is 12.693051161128096\n",
      "Steps:  34%|▎| 5124/15000 [32:42<29:27,  5.59it/s, lr=9.82e-6, step_loss=0.0058807/18/2023 19:36:04 - INFO - __main__ - train loss is 12.823657663422637\n",
      "Steps:  34%|▋ | 5125/15000 [32:42<29:25,  5.59it/s, lr=9.82e-6, step_loss=0.131]07/18/2023 19:36:04 - INFO - __main__ - train loss is 12.840953789534979\n",
      "Steps:  34%|▎| 5126/15000 [32:42<29:22,  5.60it/s, lr=9.82e-6, step_loss=0.0173]07/18/2023 19:36:04 - INFO - __main__ - train loss is 12.907375804963522\n",
      "Steps:  34%|▎| 5127/15000 [32:42<29:20,  5.61it/s, lr=9.82e-6, step_loss=0.0664]07/18/2023 19:36:04 - INFO - __main__ - train loss is 13.142068616929464\n",
      "Steps:  34%|▋ | 5128/15000 [32:42<29:18,  5.61it/s, lr=9.82e-6, step_loss=0.235]07/18/2023 19:36:05 - INFO - __main__ - train loss is 13.146564412745647\n",
      "Steps:  34%|▎| 5129/15000 [32:42<29:30,  5.58it/s, lr=9.82e-6, step_loss=0.0045]07/18/2023 19:36:05 - INFO - __main__ - train loss is 13.393375117215328\n",
      "Steps:  34%|▋ | 5130/15000 [32:43<29:24,  5.59it/s, lr=9.82e-6, step_loss=0.247]07/18/2023 19:36:05 - INFO - __main__ - train loss is 13.849001306924038\n",
      "Steps:  34%|▋ | 5131/15000 [32:43<29:23,  5.59it/s, lr=9.82e-6, step_loss=0.456]07/18/2023 19:36:05 - INFO - __main__ - train loss is 14.105985123547725\n",
      "Steps:  34%|▋ | 5132/15000 [32:43<29:21,  5.60it/s, lr=9.82e-6, step_loss=0.257]07/18/2023 19:36:05 - INFO - __main__ - train loss is 14.990189153584652\n",
      "Steps:  34%|▋ | 5133/15000 [32:43<29:19,  5.61it/s, lr=9.82e-6, step_loss=0.884]07/18/2023 19:36:05 - INFO - __main__ - train loss is 15.337074119481258\n",
      "Steps:  34%|▋ | 5134/15000 [32:43<29:18,  5.61it/s, lr=9.82e-6, step_loss=0.347]07/18/2023 19:36:06 - INFO - __main__ - train loss is 15.34494693565648\n",
      "Steps:  34%|▎| 5135/15000 [32:43<29:19,  5.61it/s, lr=9.82e-6, step_loss=0.0078707/18/2023 19:36:06 - INFO - __main__ - train loss is 15.347893946687691\n",
      "Steps:  34%|▎| 5136/15000 [32:44<29:18,  5.61it/s, lr=9.82e-6, step_loss=0.0029507/18/2023 19:36:06 - INFO - __main__ - train loss is 15.378670782665722\n",
      "Steps:  34%|▎| 5137/15000 [32:44<29:18,  5.61it/s, lr=9.82e-6, step_loss=0.0308]07/18/2023 19:36:06 - INFO - __main__ - train loss is 15.507347763399594\n",
      "Steps:  34%|▋ | 5138/15000 [32:44<29:18,  5.61it/s, lr=9.82e-6, step_loss=0.129]07/18/2023 19:36:06 - INFO - __main__ - train loss is 15.520329520921223\n",
      "Steps:  34%|▋ | 5139/15000 [32:44<29:16,  5.61it/s, lr=9.82e-6, step_loss=0.013]07/18/2023 19:36:06 - INFO - __main__ - train loss is 15.547555600176565\n",
      "Steps:  34%|▎| 5140/15000 [32:44<29:15,  5.62it/s, lr=9.82e-6, step_loss=0.0272]07/18/2023 19:36:07 - INFO - __main__ - train loss is 15.550406206282787\n",
      "Steps:  34%|▎| 5141/15000 [32:45<38:15,  4.30it/s, lr=9.82e-6, step_loss=0.0028507/18/2023 19:36:08 - INFO - __main__ - Per validation step average loss is 0.04232402890920639\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Cumulative validation average loss is 0.04232402890920639\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Per validation step average loss is 0.0019411616958677769\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Cumulative validation average loss is 0.04426519060507417\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Per validation step average loss is 0.12252897769212723\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Cumulative validation average loss is 0.1667941682972014\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Per validation step average loss is 0.3061071038246155\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Cumulative validation average loss is 0.4729012721218169\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Per validation step average loss is 0.31415247917175293\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Cumulative validation average loss is 0.7870537512935698\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Per validation step average loss is 0.1175006628036499\n",
      "07/18/2023 19:36:08 - INFO - __main__ - Cumulative validation average loss is 0.9045544140972197\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Per validation step average loss is 0.3197327256202698\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Cumulative validation average loss is 1.2242871397174895\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Per validation step average loss is 0.006957090925425291\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Cumulative validation average loss is 1.2312442306429148\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Per validation step average loss is 0.23542450368404388\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Cumulative validation average loss is 1.4666687343269587\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Per validation step average loss is 0.003721330314874649\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Cumulative validation average loss is 1.4703900646418333\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Per validation step average loss is 0.6552934050559998\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Cumulative validation average loss is 2.125683469697833\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Per validation step average loss is 0.1325196921825409\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Cumulative validation average loss is 2.258203161880374\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Average validation loss for Epoch 52 is 0.1881835968233645\n",
      "07/18/2023 19:36:09 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:36:22 - INFO - __main__ - Starting epoch 53\n",
      "07/18/2023 19:36:23 - INFO - __main__ - train loss is 0.002837682608515024\n",
      "Steps:  34%|▎| 5142/15000 [33:01<13:27:02,  4.91s/it, lr=9.82e-6, step_loss=0.0007/18/2023 19:36:23 - INFO - __main__ - train loss is 0.006597772240638733\n",
      "Steps:  34%|▎| 5143/15000 [33:01<9:33:43,  3.49s/it, lr=9.82e-6, step_loss=0.00307/18/2023 19:36:23 - INFO - __main__ - train loss is 0.010483040008693933\n",
      "Steps:  34%|▎| 5144/15000 [33:01<6:50:18,  2.50s/it, lr=9.82e-6, step_loss=0.00307/18/2023 19:36:23 - INFO - __main__ - train loss is 0.2982166544534266\n",
      "Steps:  34%|▎| 5145/15000 [33:01<4:56:04,  1.80s/it, lr=9.82e-6, step_loss=0.28807/18/2023 19:36:23 - INFO - __main__ - train loss is 0.3806378752924502\n",
      "Steps:  34%|▎| 5146/15000 [33:01<3:35:59,  1.32s/it, lr=9.82e-6, step_loss=0.08207/18/2023 19:36:24 - INFO - __main__ - train loss is 0.4085474447347224\n",
      "Steps:  34%|▎| 5147/15000 [33:01<2:40:00,  1.03it/s, lr=9.82e-6, step_loss=0.02707/18/2023 19:36:24 - INFO - __main__ - train loss is 0.5196230546571314\n",
      "Steps:  34%|▎| 5148/15000 [33:02<2:00:46,  1.36it/s, lr=9.82e-6, step_loss=0.11107/18/2023 19:36:24 - INFO - __main__ - train loss is 0.6521695987321436\n",
      "Steps:  34%|▎| 5149/15000 [33:02<1:33:18,  1.76it/s, lr=9.82e-6, step_loss=0.13307/18/2023 19:36:24 - INFO - __main__ - train loss is 1.1002571717835963\n",
      "Steps:  34%|▎| 5150/15000 [33:02<1:14:03,  2.22it/s, lr=9.82e-6, step_loss=0.44807/18/2023 19:36:24 - INFO - __main__ - train loss is 1.3857020870782435\n",
      "Steps:  34%|▎| 5151/15000 [33:02<1:00:33,  2.71it/s, lr=9.82e-6, step_loss=0.28507/18/2023 19:36:24 - INFO - __main__ - train loss is 1.407788383308798\n",
      "Steps:  34%|▎| 5152/15000 [33:02<51:08,  3.21it/s, lr=9.82e-6, step_loss=0.0221]07/18/2023 19:36:25 - INFO - __main__ - train loss is 1.5959543609060347\n",
      "Steps:  34%|▋ | 5153/15000 [33:03<44:32,  3.68it/s, lr=9.82e-6, step_loss=0.188]07/18/2023 19:36:25 - INFO - __main__ - train loss is 1.6051023681648076\n",
      "Steps:  34%|▎| 5154/15000 [33:03<39:55,  4.11it/s, lr=9.82e-6, step_loss=0.0091507/18/2023 19:36:25 - INFO - __main__ - train loss is 1.6124869552440941\n",
      "Steps:  34%|▎| 5155/15000 [33:03<36:48,  4.46it/s, lr=9.82e-6, step_loss=0.0073807/18/2023 19:36:25 - INFO - __main__ - train loss is 1.6612379741854966\n",
      "Steps:  34%|▎| 5156/15000 [33:03<34:30,  4.75it/s, lr=9.82e-6, step_loss=0.0488]07/18/2023 19:36:25 - INFO - __main__ - train loss is 1.8225594949908555\n",
      "Steps:  34%|▋ | 5157/15000 [33:03<32:53,  4.99it/s, lr=9.82e-6, step_loss=0.161]07/18/2023 19:36:26 - INFO - __main__ - train loss is 1.9645070773549378\n",
      "Steps:  34%|▋ | 5158/15000 [33:03<31:45,  5.17it/s, lr=9.82e-6, step_loss=0.142]07/18/2023 19:36:26 - INFO - __main__ - train loss is 2.512120817322284\n",
      "Steps:  34%|▋ | 5159/15000 [33:04<30:59,  5.29it/s, lr=9.82e-6, step_loss=0.548]07/18/2023 19:36:26 - INFO - __main__ - train loss is 2.7993910652585328\n",
      "Steps:  34%|▋ | 5160/15000 [33:04<30:27,  5.38it/s, lr=9.82e-6, step_loss=0.287]07/18/2023 19:36:26 - INFO - __main__ - train loss is 2.837480437476188\n",
      "Steps:  34%|▎| 5161/15000 [33:04<30:04,  5.45it/s, lr=9.82e-6, step_loss=0.0381]07/18/2023 19:36:26 - INFO - __main__ - train loss is 2.8887044903822243\n",
      "Steps:  34%|▎| 5162/15000 [33:04<29:48,  5.50it/s, lr=9.82e-6, step_loss=0.0512]07/18/2023 19:36:26 - INFO - __main__ - train loss is 2.891766461543739\n",
      "Steps:  34%|▎| 5163/15000 [33:04<29:37,  5.53it/s, lr=9.82e-6, step_loss=0.0030607/18/2023 19:36:27 - INFO - __main__ - train loss is 3.1557934312149882\n",
      "Steps:  34%|▋ | 5164/15000 [33:04<29:31,  5.55it/s, lr=9.82e-6, step_loss=0.264]07/18/2023 19:36:27 - INFO - __main__ - train loss is 3.628691735677421\n",
      "Steps:  34%|▋ | 5165/15000 [33:05<29:26,  5.57it/s, lr=9.82e-6, step_loss=0.473]07/18/2023 19:36:27 - INFO - __main__ - train loss is 3.710596370510757\n",
      "Steps:  34%|▎| 5166/15000 [33:05<29:22,  5.58it/s, lr=9.82e-6, step_loss=0.0819]07/18/2023 19:36:27 - INFO - __main__ - train loss is 3.7496610647067428\n",
      "Steps:  34%|▎| 5167/15000 [33:05<29:20,  5.59it/s, lr=9.82e-6, step_loss=0.0391]07/18/2023 19:36:27 - INFO - __main__ - train loss is 3.8771420186385512\n",
      "Steps:  34%|▋ | 5168/15000 [33:05<29:18,  5.59it/s, lr=9.82e-6, step_loss=0.127]07/18/2023 19:36:27 - INFO - __main__ - train loss is 4.523446626029909\n",
      "Steps:  34%|▋ | 5169/15000 [33:05<29:17,  5.59it/s, lr=9.82e-6, step_loss=0.646]07/18/2023 19:36:28 - INFO - __main__ - train loss is 4.905437416397035\n",
      "Steps:  34%|▋ | 5170/15000 [33:06<29:16,  5.60it/s, lr=9.82e-6, step_loss=0.382]07/18/2023 19:36:28 - INFO - __main__ - train loss is 4.914551361463964\n",
      "Steps:  34%|▎| 5171/15000 [33:06<29:15,  5.60it/s, lr=9.82e-6, step_loss=0.0091107/18/2023 19:36:28 - INFO - __main__ - train loss is 4.920983176678419\n",
      "Steps:  34%|▎| 5172/15000 [33:06<29:14,  5.60it/s, lr=9.82e-6, step_loss=0.0064307/18/2023 19:36:28 - INFO - __main__ - train loss is 5.051768254488707\n",
      "Steps:  34%|▋ | 5173/15000 [33:06<29:13,  5.60it/s, lr=9.82e-6, step_loss=0.131]07/18/2023 19:36:28 - INFO - __main__ - train loss is 5.055941367056221\n",
      "Steps:  34%|▎| 5174/15000 [33:06<29:12,  5.61it/s, lr=9.82e-6, step_loss=0.0041707/18/2023 19:36:29 - INFO - __main__ - train loss is 5.059486255282536\n",
      "Steps:  34%|▎| 5175/15000 [33:06<29:11,  5.61it/s, lr=9.82e-6, step_loss=0.0035407/18/2023 19:36:29 - INFO - __main__ - train loss is 5.062359231291339\n",
      "Steps:  35%|▎| 5176/15000 [33:07<29:11,  5.61it/s, lr=9.82e-6, step_loss=0.0028707/18/2023 19:36:29 - INFO - __main__ - train loss is 5.0712409594561905\n",
      "Steps:  35%|▎| 5177/15000 [33:07<29:10,  5.61it/s, lr=9.82e-6, step_loss=0.0088807/18/2023 19:36:29 - INFO - __main__ - train loss is 5.390464154770598\n",
      "Steps:  35%|▋ | 5178/15000 [33:07<29:11,  5.61it/s, lr=9.82e-6, step_loss=0.319]07/18/2023 19:36:29 - INFO - __main__ - train loss is 5.404147584689781\n",
      "Steps:  35%|▎| 5179/15000 [33:07<29:11,  5.61it/s, lr=9.82e-6, step_loss=0.0137]07/18/2023 19:36:29 - INFO - __main__ - train loss is 5.429192478535697\n",
      "Steps:  35%|▋ | 5180/15000 [33:07<29:11,  5.61it/s, lr=9.82e-6, step_loss=0.025]07/18/2023 19:36:30 - INFO - __main__ - train loss is 5.434942811494693\n",
      "Steps:  35%|▎| 5181/15000 [33:07<29:11,  5.61it/s, lr=9.82e-6, step_loss=0.0057507/18/2023 19:36:30 - INFO - __main__ - train loss is 5.451005223905668\n",
      "Steps:  35%|▎| 5182/15000 [33:08<29:10,  5.61it/s, lr=9.82e-6, step_loss=0.0161]07/18/2023 19:36:30 - INFO - __main__ - train loss is 5.5758258884307\n",
      "Steps:  35%|▋ | 5183/15000 [33:08<29:10,  5.61it/s, lr=9.82e-6, step_loss=0.125]07/18/2023 19:36:30 - INFO - __main__ - train loss is 5.807450923835859\n",
      "Steps:  35%|▋ | 5184/15000 [33:08<29:10,  5.61it/s, lr=9.82e-6, step_loss=0.232]07/18/2023 19:36:30 - INFO - __main__ - train loss is 6.245596799766645\n",
      "Steps:  35%|▋ | 5185/15000 [33:08<29:09,  5.61it/s, lr=9.82e-6, step_loss=0.438]07/18/2023 19:36:31 - INFO - __main__ - train loss is 6.769344243919477\n",
      "Steps:  35%|▋ | 5186/15000 [33:08<29:10,  5.61it/s, lr=9.82e-6, step_loss=0.524]07/18/2023 19:36:31 - INFO - __main__ - train loss is 7.1438985203858465\n",
      "Steps:  35%|▋ | 5187/15000 [33:09<29:09,  5.61it/s, lr=9.82e-6, step_loss=0.375]07/18/2023 19:36:31 - INFO - __main__ - train loss is 7.716819319641218\n",
      "Steps:  35%|▋ | 5188/15000 [33:09<29:10,  5.60it/s, lr=9.82e-6, step_loss=0.573]07/18/2023 19:36:31 - INFO - __main__ - train loss is 7.7356160876806825\n",
      "Steps:  35%|▎| 5189/15000 [33:09<29:10,  5.60it/s, lr=9.82e-6, step_loss=0.0188]07/18/2023 19:36:31 - INFO - __main__ - train loss is 7.739373628050089\n",
      "Steps:  35%|▎| 5190/15000 [33:09<29:09,  5.61it/s, lr=9.82e-6, step_loss=0.0037607/18/2023 19:36:31 - INFO - __main__ - train loss is 7.7494694869965315\n",
      "Steps:  35%|▎| 5191/15000 [33:09<29:09,  5.61it/s, lr=9.82e-6, step_loss=0.0101]07/18/2023 19:36:32 - INFO - __main__ - train loss is 7.758441084995866\n",
      "Steps:  35%|▎| 5192/15000 [33:09<29:09,  5.61it/s, lr=9.82e-6, step_loss=0.0089707/18/2023 19:36:32 - INFO - __main__ - train loss is 7.792485581710935\n",
      "Steps:  35%|▋ | 5193/15000 [33:10<29:10,  5.60it/s, lr=9.82e-6, step_loss=0.034]07/18/2023 19:36:32 - INFO - __main__ - train loss is 8.00934642739594\n",
      "Steps:  35%|▋ | 5194/15000 [33:10<29:08,  5.61it/s, lr=9.82e-6, step_loss=0.217]07/18/2023 19:36:32 - INFO - __main__ - train loss is 8.340884389355779\n",
      "Steps:  35%|▋ | 5195/15000 [33:10<29:25,  5.55it/s, lr=9.82e-6, step_loss=0.332]07/18/2023 19:36:32 - INFO - __main__ - train loss is 8.427801655605435\n",
      "Steps:  35%|▎| 5196/15000 [33:10<29:26,  5.55it/s, lr=9.82e-6, step_loss=0.0869]07/18/2023 19:36:32 - INFO - __main__ - train loss is 8.44253265671432\n",
      "Steps:  35%|▎| 5197/15000 [33:10<29:21,  5.56it/s, lr=9.82e-6, step_loss=0.0147]07/18/2023 19:36:33 - INFO - __main__ - train loss is 8.510653799399734\n",
      "Steps:  35%|▎| 5198/15000 [33:11<29:19,  5.57it/s, lr=9.82e-6, step_loss=0.0681]07/18/2023 19:36:33 - INFO - __main__ - train loss is 8.933023458346725\n",
      "Steps:  35%|▋ | 5199/15000 [33:11<29:20,  5.57it/s, lr=9.82e-6, step_loss=0.422]07/18/2023 19:36:33 - INFO - __main__ - train loss is 9.071812784299254\n",
      "Steps:  35%|▋ | 5200/15000 [33:11<29:17,  5.58it/s, lr=9.82e-6, step_loss=0.139]07/18/2023 19:36:33 - INFO - __main__ - train loss is 9.235344296321273\n",
      "Steps:  35%|▋ | 5201/15000 [33:11<29:25,  5.55it/s, lr=9.82e-6, step_loss=0.164]07/18/2023 19:36:33 - INFO - __main__ - train loss is 9.641056841239333\n",
      "Steps:  35%|▋ | 5202/15000 [33:11<29:24,  5.55it/s, lr=9.82e-6, step_loss=0.406]07/18/2023 19:36:34 - INFO - __main__ - train loss is 9.67158323340118\n",
      "Steps:  35%|▎| 5203/15000 [33:11<29:19,  5.57it/s, lr=9.82e-6, step_loss=0.0305]07/18/2023 19:36:34 - INFO - __main__ - train loss is 9.745509875938296\n",
      "Steps:  35%|▎| 5204/15000 [33:12<29:15,  5.58it/s, lr=9.82e-6, step_loss=0.0739]07/18/2023 19:36:34 - INFO - __main__ - train loss is 10.50723816268146\n",
      "Steps:  35%|▋ | 5205/15000 [33:12<29:13,  5.59it/s, lr=9.82e-6, step_loss=0.762]07/18/2023 19:36:34 - INFO - __main__ - train loss is 10.827852381393313\n",
      "Steps:  35%|▋ | 5206/15000 [33:12<29:10,  5.59it/s, lr=9.82e-6, step_loss=0.321]07/18/2023 19:36:34 - INFO - __main__ - train loss is 10.92632800154388\n",
      "Steps:  35%|▎| 5207/15000 [33:12<29:10,  5.60it/s, lr=9.82e-6, step_loss=0.0985]07/18/2023 19:36:34 - INFO - __main__ - train loss is 11.325371561571956\n",
      "Steps:  35%|▋ | 5208/15000 [33:12<29:09,  5.60it/s, lr=9.82e-6, step_loss=0.399]07/18/2023 19:36:35 - INFO - __main__ - train loss is 11.328163411468267\n",
      "Steps:  35%|▎| 5209/15000 [33:13<29:18,  5.57it/s, lr=9.82e-6, step_loss=0.0027907/18/2023 19:36:35 - INFO - __main__ - train loss is 12.09858187660575\n",
      "Steps:  35%|█  | 5210/15000 [33:13<29:14,  5.58it/s, lr=9.82e-6, step_loss=0.77]07/18/2023 19:36:35 - INFO - __main__ - train loss is 12.11011409573257\n",
      "Steps:  35%|▎| 5211/15000 [33:13<29:28,  5.54it/s, lr=9.82e-6, step_loss=0.0115]07/18/2023 19:36:35 - INFO - __main__ - train loss is 12.114560103509575\n",
      "Steps:  35%|▎| 5212/15000 [33:13<29:27,  5.54it/s, lr=9.82e-6, step_loss=0.0044507/18/2023 19:36:35 - INFO - __main__ - train loss is 12.118617041036487\n",
      "Steps:  35%|▎| 5213/15000 [33:13<29:20,  5.56it/s, lr=9.82e-6, step_loss=0.0040607/18/2023 19:36:36 - INFO - __main__ - train loss is 12.246005592867732\n",
      "Steps:  35%|▋ | 5214/15000 [33:13<29:18,  5.57it/s, lr=9.82e-6, step_loss=0.127]07/18/2023 19:36:36 - INFO - __main__ - train loss is 12.901109276339412\n",
      "Steps:  35%|▋ | 5215/15000 [33:14<29:27,  5.54it/s, lr=9.82e-6, step_loss=0.655]07/18/2023 19:36:36 - INFO - __main__ - train loss is 13.574100075289607\n",
      "Steps:  35%|▋ | 5216/15000 [33:14<29:21,  5.55it/s, lr=9.82e-6, step_loss=0.673]07/18/2023 19:36:36 - INFO - __main__ - train loss is 13.65755414776504\n",
      "Steps:  35%|▎| 5217/15000 [33:14<29:16,  5.57it/s, lr=9.82e-6, step_loss=0.0835]07/18/2023 19:36:36 - INFO - __main__ - train loss is 13.660233119037002\n",
      "Steps:  35%|▎| 5218/15000 [33:14<29:27,  5.53it/s, lr=9.82e-6, step_loss=0.0026807/18/2023 19:36:36 - INFO - __main__ - train loss is 13.879472279455513\n",
      "Steps:  35%|▋ | 5219/15000 [33:14<29:36,  5.51it/s, lr=9.82e-6, step_loss=0.219]07/18/2023 19:36:37 - INFO - __main__ - train loss is 13.920935814734548\n",
      "Steps:  35%|▎| 5220/15000 [33:15<29:48,  5.47it/s, lr=9.82e-6, step_loss=0.0415]07/18/2023 19:36:37 - INFO - __main__ - train loss is 14.14396292483434\n",
      "Steps:  35%|▋ | 5221/15000 [33:15<29:53,  5.45it/s, lr=9.82e-6, step_loss=0.223]07/18/2023 19:36:37 - INFO - __main__ - train loss is 14.264288087841123\n",
      "Steps:  35%|█  | 5222/15000 [33:15<29:49,  5.46it/s, lr=9.82e-6, step_loss=0.12]07/18/2023 19:36:37 - INFO - __main__ - train loss is 14.636165698524565\n",
      "Steps:  35%|▋ | 5223/15000 [33:15<29:53,  5.45it/s, lr=9.82e-6, step_loss=0.372]07/18/2023 19:36:37 - INFO - __main__ - train loss is 14.911556710954756\n",
      "Steps:  35%|▋ | 5224/15000 [33:15<29:54,  5.45it/s, lr=9.82e-6, step_loss=0.275]07/18/2023 19:36:38 - INFO - __main__ - train loss is 14.931909953709692\n",
      "Steps:  35%|▎| 5225/15000 [33:15<29:40,  5.49it/s, lr=9.82e-6, step_loss=0.0204]07/18/2023 19:36:38 - INFO - __main__ - train loss is 15.56276992475614\n",
      "Steps:  35%|▋ | 5226/15000 [33:16<29:29,  5.52it/s, lr=9.81e-6, step_loss=0.631]07/18/2023 19:36:38 - INFO - __main__ - train loss is 15.566331752110273\n",
      "Steps:  35%|▎| 5227/15000 [33:16<29:22,  5.55it/s, lr=9.81e-6, step_loss=0.0035607/18/2023 19:36:38 - INFO - __main__ - train loss is 15.567975443555042\n",
      "Steps:  35%|▎| 5228/15000 [33:16<29:16,  5.56it/s, lr=9.81e-6, step_loss=0.0016407/18/2023 19:36:38 - INFO - __main__ - train loss is 15.854920726967975\n",
      "Steps:  35%|▋ | 5229/15000 [33:16<29:11,  5.58it/s, lr=9.81e-6, step_loss=0.287]07/18/2023 19:36:38 - INFO - __main__ - train loss is 15.978965875459835\n",
      "Steps:  35%|▋ | 5230/15000 [33:16<29:07,  5.59it/s, lr=9.81e-6, step_loss=0.124]07/18/2023 19:36:39 - INFO - __main__ - train loss is 16.49116611178033\n",
      "Steps:  35%|▋ | 5231/15000 [33:16<29:05,  5.60it/s, lr=9.81e-6, step_loss=0.512]07/18/2023 19:36:39 - INFO - __main__ - train loss is 16.497993218479678\n",
      "Steps:  35%|▎| 5232/15000 [33:17<29:03,  5.60it/s, lr=9.81e-6, step_loss=0.0068307/18/2023 19:36:39 - INFO - __main__ - train loss is 16.609902220545337\n",
      "Steps:  35%|▋ | 5233/15000 [33:17<29:04,  5.60it/s, lr=9.81e-6, step_loss=0.112]07/18/2023 19:36:39 - INFO - __main__ - train loss is 16.620892809471115\n",
      "Steps:  35%|▋ | 5234/15000 [33:17<29:19,  5.55it/s, lr=9.81e-6, step_loss=0.011]07/18/2023 19:36:39 - INFO - __main__ - train loss is 16.829104186734185\n",
      "Steps:  35%|▋ | 5235/15000 [33:17<29:14,  5.57it/s, lr=9.81e-6, step_loss=0.208]07/18/2023 19:36:39 - INFO - __main__ - train loss is 17.008823128184304\n",
      "Steps:  35%|█  | 5236/15000 [33:17<29:10,  5.58it/s, lr=9.81e-6, step_loss=0.18]07/18/2023 19:36:40 - INFO - __main__ - train loss is 17.042222993215546\n",
      "Steps:  35%|▎| 5237/15000 [33:18<29:06,  5.59it/s, lr=9.81e-6, step_loss=0.0334]07/18/2023 19:36:40 - INFO - __main__ - train loss is 17.084477634867653\n",
      "Steps:  35%|▎| 5238/15000 [33:18<39:41,  4.10it/s, lr=9.81e-6, step_loss=0.0423]07/18/2023 19:36:41 - INFO - __main__ - Per validation step average loss is 0.06328341364860535\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Cumulative validation average loss is 0.06328341364860535\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Per validation step average loss is 0.22447523474693298\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Cumulative validation average loss is 0.28775864839553833\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Per validation step average loss is 0.02226947993040085\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Cumulative validation average loss is 0.3100281283259392\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Per validation step average loss is 0.014965245500206947\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Cumulative validation average loss is 0.3249933738261461\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Per validation step average loss is 0.48538973927497864\n",
      "07/18/2023 19:36:41 - INFO - __main__ - Cumulative validation average loss is 0.8103831131011248\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.021971315145492554\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 0.8323544282466173\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.20222201943397522\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.0345764476805925\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.07721206545829773\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.1117885131388903\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.29263049364089966\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.40441900677979\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.08865344524383545\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.4930724520236254\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Per validation step average loss is 0.02064777910709381\n",
      "07/18/2023 19:36:42 - INFO - __main__ - Cumulative validation average loss is 1.5137202311307192\n",
      "07/18/2023 19:36:43 - INFO - __main__ - Per validation step average loss is 0.4340546429157257\n",
      "07/18/2023 19:36:43 - INFO - __main__ - Cumulative validation average loss is 1.947774874046445\n",
      "07/18/2023 19:36:43 - INFO - __main__ - Average validation loss for Epoch 53 is 0.16231457283720374\n",
      "07/18/2023 19:36:43 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:36:56 - INFO - __main__ - Starting epoch 54\n",
      "07/18/2023 19:36:56 - INFO - __main__ - train loss is 0.22765178978443146\n",
      "Steps:  35%|▎| 5239/15000 [33:34<13:30:51,  4.98s/it, lr=9.81e-6, step_loss=0.2207/18/2023 19:36:56 - INFO - __main__ - train loss is 0.3646215349435806\n",
      "Steps:  35%|▎| 5240/15000 [33:34<9:36:51,  3.55s/it, lr=9.81e-6, step_loss=0.13707/18/2023 19:36:56 - INFO - __main__ - train loss is 0.7134871929883957\n",
      "Steps:  35%|▎| 5241/15000 [33:34<6:52:49,  2.54s/it, lr=9.81e-6, step_loss=0.34907/18/2023 19:36:57 - INFO - __main__ - train loss is 0.7397612817585468\n",
      "Steps:  35%|▎| 5242/15000 [33:35<4:57:46,  1.83s/it, lr=9.81e-6, step_loss=0.02607/18/2023 19:36:57 - INFO - __main__ - train loss is 0.7459098072722554\n",
      "Steps:  35%|▎| 5243/15000 [33:35<3:37:04,  1.33s/it, lr=9.81e-6, step_loss=0.00607/18/2023 19:36:57 - INFO - __main__ - train loss is 1.392245170660317\n",
      "Steps:  35%|▎| 5244/15000 [33:35<2:40:46,  1.01it/s, lr=9.81e-6, step_loss=0.64607/18/2023 19:36:57 - INFO - __main__ - train loss is 1.4325292157009244\n",
      "Steps:  35%|▎| 5245/15000 [33:35<2:01:12,  1.34it/s, lr=9.81e-6, step_loss=0.04007/18/2023 19:36:57 - INFO - __main__ - train loss is 1.4565255781635642\n",
      "Steps:  35%|▎| 5246/15000 [33:35<1:33:30,  1.74it/s, lr=9.81e-6, step_loss=0.02407/18/2023 19:36:58 - INFO - __main__ - train loss is 1.6463930597528815\n",
      "Steps:  35%|▎| 5247/15000 [33:35<1:14:07,  2.19it/s, lr=9.81e-6, step_loss=0.19]07/18/2023 19:36:58 - INFO - __main__ - train loss is 1.6483862248715013\n",
      "Steps:  35%|▎| 5248/15000 [33:36<1:00:32,  2.68it/s, lr=9.81e-6, step_loss=0.00107/18/2023 19:36:58 - INFO - __main__ - train loss is 1.700655616587028\n",
      "Steps:  35%|▎| 5249/15000 [33:36<51:03,  3.18it/s, lr=9.81e-6, step_loss=0.0523]07/18/2023 19:36:58 - INFO - __main__ - train loss is 1.7153385614510626\n",
      "Steps:  35%|▎| 5250/15000 [33:36<44:23,  3.66it/s, lr=9.81e-6, step_loss=0.0147]07/18/2023 19:36:58 - INFO - __main__ - train loss is 1.8495609497185796\n",
      "Steps:  35%|▋ | 5251/15000 [33:36<39:43,  4.09it/s, lr=9.81e-6, step_loss=0.134]07/18/2023 19:36:58 - INFO - __main__ - train loss is 2.028438720619306\n",
      "Steps:  35%|▋ | 5252/15000 [33:36<36:29,  4.45it/s, lr=9.81e-6, step_loss=0.179]07/18/2023 19:36:59 - INFO - __main__ - train loss is 2.0367531755473465\n",
      "Steps:  35%|▎| 5253/15000 [33:37<34:15,  4.74it/s, lr=9.81e-6, step_loss=0.0083107/18/2023 19:36:59 - INFO - __main__ - train loss is 2.0387060190550983\n",
      "Steps:  35%|▎| 5254/15000 [33:37<32:37,  4.98it/s, lr=9.81e-6, step_loss=0.0019507/18/2023 19:36:59 - INFO - __main__ - train loss is 2.2421877230517566\n",
      "Steps:  35%|▋ | 5255/15000 [33:37<31:29,  5.16it/s, lr=9.81e-6, step_loss=0.203]07/18/2023 19:36:59 - INFO - __main__ - train loss is 2.55333612812683\n",
      "Steps:  35%|▋ | 5256/15000 [33:37<30:44,  5.28it/s, lr=9.81e-6, step_loss=0.311]07/18/2023 19:36:59 - INFO - __main__ - train loss is 2.5559024438261986\n",
      "Steps:  35%|▎| 5257/15000 [33:37<30:12,  5.38it/s, lr=9.81e-6, step_loss=0.0025707/18/2023 19:37:00 - INFO - __main__ - train loss is 3.2605807408690453\n",
      "Steps:  35%|▋ | 5258/15000 [33:37<29:51,  5.44it/s, lr=9.81e-6, step_loss=0.705]07/18/2023 19:37:00 - INFO - __main__ - train loss is 3.4672300592064857\n",
      "Steps:  35%|▋ | 5259/15000 [33:38<29:34,  5.49it/s, lr=9.81e-6, step_loss=0.207]07/18/2023 19:37:00 - INFO - __main__ - train loss is 3.488303679972887\n",
      "Steps:  35%|▎| 5260/15000 [33:38<29:23,  5.52it/s, lr=9.81e-6, step_loss=0.0211]07/18/2023 19:37:00 - INFO - __main__ - train loss is 3.512634467333555\n",
      "Steps:  35%|▎| 5261/15000 [33:38<29:22,  5.53it/s, lr=9.81e-6, step_loss=0.0243]07/18/2023 19:37:00 - INFO - __main__ - train loss is 3.886806260794401\n",
      "Steps:  35%|▋ | 5262/15000 [33:38<31:09,  5.21it/s, lr=9.81e-6, step_loss=0.374]07/18/2023 19:37:00 - INFO - __main__ - train loss is 4.538907717913389\n",
      "Steps:  35%|▋ | 5263/15000 [33:38<30:33,  5.31it/s, lr=9.81e-6, step_loss=0.652]07/18/2023 19:37:01 - INFO - __main__ - train loss is 4.543372094631195\n",
      "Steps:  35%|▎| 5264/15000 [33:39<30:33,  5.31it/s, lr=9.81e-6, step_loss=0.0044607/18/2023 19:37:01 - INFO - __main__ - train loss is 4.554418690502644\n",
      "Steps:  35%|▋ | 5265/15000 [33:39<31:44,  5.11it/s, lr=9.81e-6, step_loss=0.011]07/18/2023 19:37:01 - INFO - __main__ - train loss is 5.2669500187039375\n",
      "Steps:  35%|▋ | 5266/15000 [33:39<31:12,  5.20it/s, lr=9.81e-6, step_loss=0.713]07/18/2023 19:37:01 - INFO - __main__ - train loss is 5.653736539185047\n",
      "Steps:  35%|▋ | 5267/15000 [33:39<31:05,  5.22it/s, lr=9.81e-6, step_loss=0.387]07/18/2023 19:37:01 - INFO - __main__ - train loss is 5.882434509694576\n",
      "Steps:  35%|▋ | 5268/15000 [33:39<30:33,  5.31it/s, lr=9.81e-6, step_loss=0.229]07/18/2023 19:37:02 - INFO - __main__ - train loss is 5.920111488550901\n",
      "Steps:  35%|▎| 5269/15000 [33:39<30:21,  5.34it/s, lr=9.81e-6, step_loss=0.0377]07/18/2023 19:37:02 - INFO - __main__ - train loss is 5.934329262003303\n",
      "Steps:  35%|▎| 5270/15000 [33:40<30:01,  5.40it/s, lr=9.81e-6, step_loss=0.0142]07/18/2023 19:37:02 - INFO - __main__ - train loss is 6.1890364196151495\n",
      "Steps:  35%|▋ | 5271/15000 [33:40<29:59,  5.41it/s, lr=9.81e-6, step_loss=0.255]07/18/2023 19:37:02 - INFO - __main__ - train loss is 6.279326615855098\n",
      "Steps:  35%|▎| 5272/15000 [33:40<30:09,  5.38it/s, lr=9.81e-6, step_loss=0.0903]07/18/2023 19:37:02 - INFO - __main__ - train loss is 6.407738892361522\n",
      "Steps:  35%|▋ | 5273/15000 [33:40<29:47,  5.44it/s, lr=9.81e-6, step_loss=0.128]07/18/2023 19:37:03 - INFO - __main__ - train loss is 6.788976458832622\n",
      "Steps:  35%|▋ | 5274/15000 [33:40<29:32,  5.49it/s, lr=9.81e-6, step_loss=0.381]07/18/2023 19:37:03 - INFO - __main__ - train loss is 7.201206175610423\n",
      "Steps:  35%|▋ | 5275/15000 [33:41<29:21,  5.52it/s, lr=9.81e-6, step_loss=0.412]07/18/2023 19:37:03 - INFO - __main__ - train loss is 7.203405963256955\n",
      "Steps:  35%|▎| 5276/15000 [33:41<29:15,  5.54it/s, lr=9.81e-6, step_loss=0.0022]07/18/2023 19:37:03 - INFO - __main__ - train loss is 7.32010112889111\n",
      "Steps:  35%|▋ | 5277/15000 [33:41<29:26,  5.51it/s, lr=9.81e-6, step_loss=0.117]07/18/2023 19:37:03 - INFO - __main__ - train loss is 7.472542630508542\n",
      "Steps:  35%|▋ | 5278/15000 [33:41<29:22,  5.52it/s, lr=9.81e-6, step_loss=0.152]07/18/2023 19:37:03 - INFO - __main__ - train loss is 7.514580009505153\n",
      "Steps:  35%|▋ | 5279/15000 [33:41<29:14,  5.54it/s, lr=9.81e-6, step_loss=0.042]07/18/2023 19:37:04 - INFO - __main__ - train loss is 7.521639136131853\n",
      "Steps:  35%|▎| 5280/15000 [33:41<29:08,  5.56it/s, lr=9.81e-6, step_loss=0.0070607/18/2023 19:37:04 - INFO - __main__ - train loss is 7.537859865929931\n",
      "Steps:  35%|▎| 5281/15000 [33:42<29:05,  5.57it/s, lr=9.81e-6, step_loss=0.0162]07/18/2023 19:37:04 - INFO - __main__ - train loss is 7.5413942146115005\n",
      "Steps:  35%|▎| 5282/15000 [33:42<29:03,  5.57it/s, lr=9.81e-6, step_loss=0.0035307/18/2023 19:37:04 - INFO - __main__ - train loss is 7.63079373864457\n",
      "Steps:  35%|▎| 5283/15000 [33:42<29:03,  5.57it/s, lr=9.81e-6, step_loss=0.0894]07/18/2023 19:37:04 - INFO - __main__ - train loss is 7.786752689164132\n",
      "Steps:  35%|▋ | 5284/15000 [33:42<29:00,  5.58it/s, lr=9.81e-6, step_loss=0.156]07/18/2023 19:37:04 - INFO - __main__ - train loss is 8.321396577637643\n",
      "Steps:  35%|▋ | 5285/15000 [33:42<29:02,  5.58it/s, lr=9.81e-6, step_loss=0.535]07/18/2023 19:37:05 - INFO - __main__ - train loss is 8.48811213998124\n",
      "Steps:  35%|▋ | 5286/15000 [33:43<28:59,  5.58it/s, lr=9.81e-6, step_loss=0.167]07/18/2023 19:37:05 - INFO - __main__ - train loss is 8.49388799443841\n",
      "Steps:  35%|▎| 5287/15000 [33:43<29:02,  5.57it/s, lr=9.81e-6, step_loss=0.0057807/18/2023 19:37:05 - INFO - __main__ - train loss is 8.574868310242891\n",
      "Steps:  35%|▋ | 5288/15000 [33:43<28:59,  5.58it/s, lr=9.81e-6, step_loss=0.081]07/18/2023 19:37:05 - INFO - __main__ - train loss is 8.640382621437311\n",
      "Steps:  35%|▎| 5289/15000 [33:43<28:57,  5.59it/s, lr=9.81e-6, step_loss=0.0655]07/18/2023 19:37:05 - INFO - __main__ - train loss is 8.712896469980478\n",
      "Steps:  35%|▎| 5290/15000 [33:43<28:56,  5.59it/s, lr=9.81e-6, step_loss=0.0725]07/18/2023 19:37:06 - INFO - __main__ - train loss is 9.178640965372324\n",
      "Steps:  35%|▋ | 5291/15000 [33:43<28:56,  5.59it/s, lr=9.81e-6, step_loss=0.466]07/18/2023 19:37:06 - INFO - __main__ - train loss is 9.222886797040701\n",
      "Steps:  35%|▎| 5292/15000 [33:44<28:57,  5.59it/s, lr=9.81e-6, step_loss=0.0442]07/18/2023 19:37:06 - INFO - __main__ - train loss is 9.23853063210845\n",
      "Steps:  35%|▎| 5293/15000 [33:44<28:55,  5.59it/s, lr=9.81e-6, step_loss=0.0156]07/18/2023 19:37:06 - INFO - __main__ - train loss is 9.241075132275\n",
      "Steps:  35%|▎| 5294/15000 [33:44<28:57,  5.59it/s, lr=9.81e-6, step_loss=0.0025407/18/2023 19:37:06 - INFO - __main__ - train loss is 9.247306240955368\n",
      "Steps:  35%|▎| 5295/15000 [33:44<28:56,  5.59it/s, lr=9.81e-6, step_loss=0.0062307/18/2023 19:37:06 - INFO - __main__ - train loss is 9.402886731782928\n",
      "Steps:  35%|▋ | 5296/15000 [33:44<29:05,  5.56it/s, lr=9.81e-6, step_loss=0.156]07/18/2023 19:37:07 - INFO - __main__ - train loss is 9.516734345117584\n",
      "Steps:  35%|▋ | 5297/15000 [33:45<29:11,  5.54it/s, lr=9.81e-6, step_loss=0.114]07/18/2023 19:37:07 - INFO - __main__ - train loss is 9.522340336581692\n",
      "Steps:  35%|▎| 5298/15000 [33:45<29:13,  5.53it/s, lr=9.81e-6, step_loss=0.0056107/18/2023 19:37:07 - INFO - __main__ - train loss is 9.903567353030667\n",
      "Steps:  35%|▋ | 5299/15000 [33:45<29:13,  5.53it/s, lr=9.81e-6, step_loss=0.381]07/18/2023 19:37:07 - INFO - __main__ - train loss is 9.912779538659379\n",
      "Steps:  35%|▎| 5300/15000 [33:45<29:14,  5.53it/s, lr=9.81e-6, step_loss=0.0092107/18/2023 19:37:07 - INFO - __main__ - train loss is 10.073906554607674\n",
      "Steps:  35%|▋ | 5301/15000 [33:45<29:26,  5.49it/s, lr=9.81e-6, step_loss=0.161]07/18/2023 19:37:08 - INFO - __main__ - train loss is 10.082490068627521\n",
      "Steps:  35%|▎| 5302/15000 [33:45<29:22,  5.50it/s, lr=9.81e-6, step_loss=0.0085807/18/2023 19:37:08 - INFO - __main__ - train loss is 10.091960384277627\n",
      "Steps:  35%|▎| 5303/15000 [33:46<29:20,  5.51it/s, lr=9.81e-6, step_loss=0.0094707/18/2023 19:37:08 - INFO - __main__ - train loss is 10.111658700508997\n",
      "Steps:  35%|▎| 5304/15000 [33:46<29:18,  5.51it/s, lr=9.81e-6, step_loss=0.0197]07/18/2023 19:37:08 - INFO - __main__ - train loss is 10.619104870362207\n",
      "Steps:  35%|▋ | 5305/15000 [33:46<29:09,  5.54it/s, lr=9.81e-6, step_loss=0.507]07/18/2023 19:37:08 - INFO - __main__ - train loss is 10.915906675858423\n",
      "Steps:  35%|▋ | 5306/15000 [33:46<29:03,  5.56it/s, lr=9.81e-6, step_loss=0.297]07/18/2023 19:37:08 - INFO - __main__ - train loss is 10.927570341853425\n",
      "Steps:  35%|▎| 5307/15000 [33:46<28:58,  5.57it/s, lr=9.81e-6, step_loss=0.0117]07/18/2023 19:37:09 - INFO - __main__ - train loss is 10.974602601258084\n",
      "Steps:  35%|▋ | 5308/15000 [33:47<28:55,  5.58it/s, lr=9.81e-6, step_loss=0.047]07/18/2023 19:37:09 - INFO - __main__ - train loss is 10.977795630693436\n",
      "Steps:  35%|▎| 5309/15000 [33:47<28:53,  5.59it/s, lr=9.81e-6, step_loss=0.0031907/18/2023 19:37:09 - INFO - __main__ - train loss is 11.010380368679762\n",
      "Steps:  35%|▎| 5310/15000 [33:47<28:51,  5.60it/s, lr=9.81e-6, step_loss=0.0326]07/18/2023 19:37:09 - INFO - __main__ - train loss is 11.160701494663954\n",
      "Steps:  35%|█  | 5311/15000 [33:47<28:50,  5.60it/s, lr=9.81e-6, step_loss=0.15]07/18/2023 19:37:09 - INFO - __main__ - train loss is 11.169688487425447\n",
      "Steps:  35%|▎| 5312/15000 [33:47<28:49,  5.60it/s, lr=9.81e-6, step_loss=0.0089907/18/2023 19:37:10 - INFO - __main__ - train loss is 11.746604586020112\n",
      "Steps:  35%|▋ | 5313/15000 [33:47<28:48,  5.60it/s, lr=9.81e-6, step_loss=0.577]07/18/2023 19:37:10 - INFO - __main__ - train loss is 11.7997379694134\n",
      "Steps:  35%|▎| 5314/15000 [33:48<28:47,  5.61it/s, lr=9.81e-6, step_loss=0.0531]07/18/2023 19:37:10 - INFO - __main__ - train loss is 11.818224618211389\n",
      "Steps:  35%|▎| 5315/15000 [33:48<28:47,  5.61it/s, lr=9.81e-6, step_loss=0.0185]07/18/2023 19:37:10 - INFO - __main__ - train loss is 11.823897738009691\n",
      "Steps:  35%|▎| 5316/15000 [33:48<28:47,  5.61it/s, lr=9.81e-6, step_loss=0.0056707/18/2023 19:37:10 - INFO - __main__ - train loss is 11.830300187692046\n",
      "Steps:  35%|▎| 5317/15000 [33:48<29:00,  5.56it/s, lr=9.81e-6, step_loss=0.0064]07/18/2023 19:37:10 - INFO - __main__ - train loss is 11.995778104290366\n",
      "Steps:  35%|▋ | 5318/15000 [33:48<28:55,  5.58it/s, lr=9.81e-6, step_loss=0.165]07/18/2023 19:37:11 - INFO - __main__ - train loss is 12.003408384509385\n",
      "Steps:  35%|▎| 5319/15000 [33:48<28:52,  5.59it/s, lr=9.81e-6, step_loss=0.0076307/18/2023 19:37:11 - INFO - __main__ - train loss is 12.165260684676468\n",
      "Steps:  35%|▋ | 5320/15000 [33:49<28:50,  5.59it/s, lr=9.81e-6, step_loss=0.162]07/18/2023 19:37:11 - INFO - __main__ - train loss is 12.288938325829804\n",
      "Steps:  35%|▋ | 5321/15000 [33:49<28:48,  5.60it/s, lr=9.81e-6, step_loss=0.124]07/18/2023 19:37:11 - INFO - __main__ - train loss is 12.294627266004682\n",
      "Steps:  35%|▎| 5322/15000 [33:49<28:58,  5.57it/s, lr=9.81e-6, step_loss=0.0056907/18/2023 19:37:11 - INFO - __main__ - train loss is 12.304300570860505\n",
      "Steps:  35%|▎| 5323/15000 [33:49<28:53,  5.58it/s, lr=9.81e-6, step_loss=0.0096707/18/2023 19:37:11 - INFO - __main__ - train loss is 12.315992238000035\n",
      "Steps:  35%|▎| 5324/15000 [33:49<28:49,  5.59it/s, lr=9.81e-6, step_loss=0.0117]07/18/2023 19:37:12 - INFO - __main__ - train loss is 12.400981919839978\n",
      "Steps:  36%|▋ | 5325/15000 [33:50<28:47,  5.60it/s, lr=9.81e-6, step_loss=0.085]07/18/2023 19:37:12 - INFO - __main__ - train loss is 12.44513594917953\n",
      "Steps:  36%|▎| 5326/15000 [33:50<28:43,  5.61it/s, lr=9.81e-6, step_loss=0.0442]07/18/2023 19:37:12 - INFO - __main__ - train loss is 12.491817282512784\n",
      "Steps:  36%|▎| 5327/15000 [33:50<28:42,  5.62it/s, lr=9.81e-6, step_loss=0.0467]07/18/2023 19:37:12 - INFO - __main__ - train loss is 12.516611775383353\n",
      "Steps:  36%|▎| 5328/15000 [33:50<28:42,  5.62it/s, lr=9.81e-6, step_loss=0.0248]07/18/2023 19:37:12 - INFO - __main__ - train loss is 12.51894016796723\n",
      "Steps:  36%|▎| 5329/15000 [33:50<28:41,  5.62it/s, lr=9.81e-6, step_loss=0.0023307/18/2023 19:37:13 - INFO - __main__ - train loss is 12.572177222464234\n",
      "Steps:  36%|▎| 5330/15000 [33:50<28:40,  5.62it/s, lr=9.81e-6, step_loss=0.0532]07/18/2023 19:37:13 - INFO - __main__ - train loss is 12.596056288573891\n",
      "Steps:  36%|▎| 5331/15000 [33:51<28:42,  5.61it/s, lr=9.81e-6, step_loss=0.0239]07/18/2023 19:37:13 - INFO - __main__ - train loss is 12.626910621766001\n",
      "Steps:  36%|▎| 5332/15000 [33:51<28:42,  5.61it/s, lr=9.81e-6, step_loss=0.0309]07/18/2023 19:37:13 - INFO - __main__ - train loss is 12.98547979677096\n",
      "Steps:  36%|▋ | 5333/15000 [33:51<28:41,  5.61it/s, lr=9.81e-6, step_loss=0.359]07/18/2023 19:37:13 - INFO - __main__ - train loss is 13.078757318202406\n",
      "Steps:  36%|▎| 5334/15000 [33:51<28:40,  5.62it/s, lr=9.81e-6, step_loss=0.0933]07/18/2023 19:37:14 - INFO - __main__ - train loss is 13.240674289409071\n",
      "Steps:  36%|▋ | 5335/15000 [33:52<37:37,  4.28it/s, lr=9.81e-6, step_loss=0.162]07/18/2023 19:37:14 - INFO - __main__ - Per validation step average loss is 0.3007751703262329\n",
      "07/18/2023 19:37:14 - INFO - __main__ - Cumulative validation average loss is 0.3007751703262329\n",
      "07/18/2023 19:37:14 - INFO - __main__ - Per validation step average loss is 0.005156613886356354\n",
      "07/18/2023 19:37:14 - INFO - __main__ - Cumulative validation average loss is 0.30593178421258926\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Per validation step average loss is 0.002305910922586918\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Cumulative validation average loss is 0.3082376951351762\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Per validation step average loss is 0.16234584152698517\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Cumulative validation average loss is 0.47058353666216135\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Per validation step average loss is 0.07877983152866364\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Cumulative validation average loss is 0.549363368190825\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Per validation step average loss is 0.0022510692942887545\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Cumulative validation average loss is 0.5516144374851137\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Per validation step average loss is 0.042504120618104935\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Cumulative validation average loss is 0.5941185581032187\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Per validation step average loss is 0.006247428711503744\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Cumulative validation average loss is 0.6003659868147224\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Per validation step average loss is 0.18123173713684082\n",
      "07/18/2023 19:37:15 - INFO - __main__ - Cumulative validation average loss is 0.7815977239515632\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Per validation step average loss is 0.02649812027812004\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Cumulative validation average loss is 0.8080958442296833\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Per validation step average loss is 0.4980202317237854\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Cumulative validation average loss is 1.3061160759534687\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Per validation step average loss is 0.31619757413864136\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Cumulative validation average loss is 1.62231365009211\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Average validation loss for Epoch 54 is 0.1351928041743425\n",
      "07/18/2023 19:37:16 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:37:29 - INFO - __main__ - Starting epoch 55\n",
      "07/18/2023 19:37:29 - INFO - __main__ - train loss is 0.002266538329422474\n",
      "Steps:  36%|▎| 5336/15000 [34:07<13:01:47,  4.85s/it, lr=9.81e-6, step_loss=0.0007/18/2023 19:37:29 - INFO - __main__ - train loss is 0.025608395226299763\n",
      "Steps:  36%|▎| 5337/15000 [34:07<9:16:03,  3.45s/it, lr=9.81e-6, step_loss=0.02307/18/2023 19:37:30 - INFO - __main__ - train loss is 0.06877909321337938\n",
      "Steps:  36%|▎| 5338/15000 [34:08<6:37:45,  2.47s/it, lr=9.81e-6, step_loss=0.04307/18/2023 19:37:30 - INFO - __main__ - train loss is 0.07708270754665136\n",
      "Steps:  36%|▎| 5339/15000 [34:08<4:47:00,  1.78s/it, lr=9.81e-6, step_loss=0.00807/18/2023 19:37:30 - INFO - __main__ - train loss is 0.11450555827468634\n",
      "Steps:  36%|▎| 5340/15000 [34:08<3:29:28,  1.30s/it, lr=9.81e-6, step_loss=0.03707/18/2023 19:37:30 - INFO - __main__ - train loss is 0.22259300854057074\n",
      "Steps:  36%|▎| 5341/15000 [34:08<2:35:22,  1.04it/s, lr=9.81e-6, step_loss=0.10807/18/2023 19:37:30 - INFO - __main__ - train loss is 0.22432950884103775\n",
      "Steps:  36%|▎| 5342/15000 [34:08<1:57:19,  1.37it/s, lr=9.81e-6, step_loss=0.00107/18/2023 19:37:31 - INFO - __main__ - train loss is 0.2509530410170555\n",
      "Steps:  36%|▎| 5343/15000 [34:08<1:30:41,  1.77it/s, lr=9.81e-6, step_loss=0.02607/18/2023 19:37:31 - INFO - __main__ - train loss is 0.3361406847834587\n",
      "Steps:  36%|▎| 5344/15000 [34:09<1:12:03,  2.23it/s, lr=9.81e-6, step_loss=0.08507/18/2023 19:37:31 - INFO - __main__ - train loss is 0.5207090452313423\n",
      "Steps:  36%|▋ | 5345/15000 [34:09<59:17,  2.71it/s, lr=9.81e-6, step_loss=0.185]07/18/2023 19:37:31 - INFO - __main__ - train loss is 0.5601931139826775\n",
      "Steps:  36%|▎| 5346/15000 [34:09<50:30,  3.19it/s, lr=9.81e-6, step_loss=0.0395]07/18/2023 19:37:31 - INFO - __main__ - train loss is 0.7700391337275505\n",
      "Steps:  36%|█  | 5347/15000 [34:09<43:54,  3.66it/s, lr=9.81e-6, step_loss=0.21]07/18/2023 19:37:31 - INFO - __main__ - train loss is 0.8479609861969948\n",
      "Steps:  36%|▎| 5348/15000 [34:09<39:18,  4.09it/s, lr=9.81e-6, step_loss=0.0779]07/18/2023 19:37:32 - INFO - __main__ - train loss is 0.8526804009452462\n",
      "Steps:  36%|▎| 5349/15000 [34:09<36:06,  4.46it/s, lr=9.81e-6, step_loss=0.0047207/18/2023 19:37:32 - INFO - __main__ - train loss is 0.8687790716066957\n",
      "Steps:  36%|▎| 5350/15000 [34:10<33:49,  4.75it/s, lr=9.81e-6, step_loss=0.0161]07/18/2023 19:37:32 - INFO - __main__ - train loss is 0.9135254295542836\n",
      "Steps:  36%|▎| 5351/15000 [34:10<32:15,  4.98it/s, lr=9.81e-6, step_loss=0.0447]07/18/2023 19:37:32 - INFO - __main__ - train loss is 1.3031896026805043\n",
      "Steps:  36%|█  | 5352/15000 [34:10<31:10,  5.16it/s, lr=9.81e-6, step_loss=0.39]07/18/2023 19:37:32 - INFO - __main__ - train loss is 1.328655899502337\n",
      "Steps:  36%|▎| 5353/15000 [34:10<30:25,  5.29it/s, lr=9.81e-6, step_loss=0.0255]07/18/2023 19:37:32 - INFO - __main__ - train loss is 1.5425441274419427\n",
      "Steps:  36%|▋ | 5354/15000 [34:10<29:53,  5.38it/s, lr=9.81e-6, step_loss=0.214]07/18/2023 19:37:33 - INFO - __main__ - train loss is 2.476892531849444\n",
      "Steps:  36%|▋ | 5355/15000 [34:11<29:48,  5.39it/s, lr=9.81e-6, step_loss=0.934]07/18/2023 19:37:33 - INFO - __main__ - train loss is 2.5239415066316724\n",
      "Steps:  36%|▋ | 5356/15000 [34:11<29:32,  5.44it/s, lr=9.81e-6, step_loss=0.047]07/18/2023 19:37:33 - INFO - __main__ - train loss is 2.555914198048413\n",
      "Steps:  36%|▋ | 5357/15000 [34:11<29:18,  5.48it/s, lr=9.81e-6, step_loss=0.032]07/18/2023 19:37:33 - INFO - __main__ - train loss is 2.838229333050549\n",
      "Steps:  36%|▋ | 5358/15000 [34:11<29:06,  5.52it/s, lr=9.81e-6, step_loss=0.282]07/18/2023 19:37:33 - INFO - __main__ - train loss is 3.002780039794743\n",
      "Steps:  36%|▋ | 5359/15000 [34:11<28:59,  5.54it/s, lr=9.81e-6, step_loss=0.165]07/18/2023 19:37:34 - INFO - __main__ - train loss is 3.014848387800157\n",
      "Steps:  36%|▎| 5360/15000 [34:11<28:53,  5.56it/s, lr=9.81e-6, step_loss=0.0121]07/18/2023 19:37:34 - INFO - __main__ - train loss is 3.3086322909221053\n",
      "Steps:  36%|▋ | 5361/15000 [34:12<28:49,  5.57it/s, lr=9.81e-6, step_loss=0.294]07/18/2023 19:37:34 - INFO - __main__ - train loss is 3.469232893548906\n",
      "Steps:  36%|▋ | 5362/15000 [34:12<28:46,  5.58it/s, lr=9.81e-6, step_loss=0.161]07/18/2023 19:37:34 - INFO - __main__ - train loss is 3.6945868646726012\n",
      "Steps:  36%|▋ | 5363/15000 [34:12<28:43,  5.59it/s, lr=9.81e-6, step_loss=0.225]07/18/2023 19:37:34 - INFO - __main__ - train loss is 3.701616761740297\n",
      "Steps:  36%|▎| 5364/15000 [34:12<28:40,  5.60it/s, lr=9.81e-6, step_loss=0.0070307/18/2023 19:37:34 - INFO - __main__ - train loss is 3.847565872129053\n",
      "Steps:  36%|▋ | 5365/15000 [34:12<28:40,  5.60it/s, lr=9.81e-6, step_loss=0.146]07/18/2023 19:37:35 - INFO - __main__ - train loss is 3.894442757125944\n",
      "Steps:  36%|▋ | 5366/15000 [34:13<28:38,  5.61it/s, lr=9.8e-6, step_loss=0.0469]07/18/2023 19:37:35 - INFO - __main__ - train loss is 4.102285688277334\n",
      "Steps:  36%|█  | 5367/15000 [34:13<28:37,  5.61it/s, lr=9.8e-6, step_loss=0.208]07/18/2023 19:37:35 - INFO - __main__ - train loss is 4.173751448746771\n",
      "Steps:  36%|▋ | 5368/15000 [34:13<28:37,  5.61it/s, lr=9.8e-6, step_loss=0.0715]07/18/2023 19:37:35 - INFO - __main__ - train loss is 4.225514059420675\n",
      "Steps:  36%|▋ | 5369/15000 [34:13<28:37,  5.61it/s, lr=9.8e-6, step_loss=0.0518]07/18/2023 19:37:35 - INFO - __main__ - train loss is 4.278330949600786\n",
      "Steps:  36%|▋ | 5370/15000 [34:13<28:37,  5.61it/s, lr=9.8e-6, step_loss=0.0528]07/18/2023 19:37:36 - INFO - __main__ - train loss is 4.38301141327247\n",
      "Steps:  36%|█  | 5371/15000 [34:13<28:35,  5.61it/s, lr=9.8e-6, step_loss=0.105]07/18/2023 19:37:36 - INFO - __main__ - train loss is 4.481115979608148\n",
      "Steps:  36%|▋ | 5372/15000 [34:14<28:35,  5.61it/s, lr=9.8e-6, step_loss=0.0981]07/18/2023 19:37:36 - INFO - __main__ - train loss is 4.875826162751764\n",
      "Steps:  36%|█  | 5373/15000 [34:14<28:34,  5.62it/s, lr=9.8e-6, step_loss=0.395]07/18/2023 19:37:36 - INFO - __main__ - train loss is 5.522548002656549\n",
      "Steps:  36%|█  | 5374/15000 [34:14<28:35,  5.61it/s, lr=9.8e-6, step_loss=0.647]07/18/2023 19:37:36 - INFO - __main__ - train loss is 6.055815381463617\n",
      "Steps:  36%|█  | 5375/15000 [34:14<28:33,  5.62it/s, lr=9.8e-6, step_loss=0.533]07/18/2023 19:37:36 - INFO - __main__ - train loss is 6.057506698183715\n",
      "Steps:  36%|▎| 5376/15000 [34:14<28:33,  5.62it/s, lr=9.8e-6, step_loss=0.00169]07/18/2023 19:37:37 - INFO - __main__ - train loss is 6.345031487755477\n",
      "Steps:  36%|█  | 5377/15000 [34:14<28:33,  5.62it/s, lr=9.8e-6, step_loss=0.288]07/18/2023 19:37:37 - INFO - __main__ - train loss is 6.346866465639323\n",
      "Steps:  36%|▎| 5378/15000 [34:15<28:33,  5.62it/s, lr=9.8e-6, step_loss=0.00183]07/18/2023 19:37:37 - INFO - __main__ - train loss is 6.365712422411889\n",
      "Steps:  36%|▋ | 5379/15000 [34:15<28:32,  5.62it/s, lr=9.8e-6, step_loss=0.0188]07/18/2023 19:37:37 - INFO - __main__ - train loss is 6.380941841285676\n",
      "Steps:  36%|▋ | 5380/15000 [34:15<28:32,  5.62it/s, lr=9.8e-6, step_loss=0.0152]07/18/2023 19:37:37 - INFO - __main__ - train loss is 6.495180118363351\n",
      "Steps:  36%|█  | 5381/15000 [34:15<28:32,  5.62it/s, lr=9.8e-6, step_loss=0.114]07/18/2023 19:37:37 - INFO - __main__ - train loss is 6.5123786623589694\n",
      "Steps:  36%|▋ | 5382/15000 [34:15<28:32,  5.62it/s, lr=9.8e-6, step_loss=0.0172]07/18/2023 19:37:38 - INFO - __main__ - train loss is 6.531262717675418\n",
      "Steps:  36%|▋ | 5383/15000 [34:16<28:32,  5.61it/s, lr=9.8e-6, step_loss=0.0189]07/18/2023 19:37:38 - INFO - __main__ - train loss is 6.61110858572647\n",
      "Steps:  36%|▋ | 5384/15000 [34:16<28:33,  5.61it/s, lr=9.8e-6, step_loss=0.0798]07/18/2023 19:37:38 - INFO - __main__ - train loss is 6.613686544355005\n",
      "Steps:  36%|▎| 5385/15000 [34:16<28:32,  5.62it/s, lr=9.8e-6, step_loss=0.00258]07/18/2023 19:37:38 - INFO - __main__ - train loss is 6.615875966148451\n",
      "Steps:  36%|▎| 5386/15000 [34:16<28:30,  5.62it/s, lr=9.8e-6, step_loss=0.00219]07/18/2023 19:37:38 - INFO - __main__ - train loss is 6.619187757605687\n",
      "Steps:  36%|▎| 5387/15000 [34:16<28:30,  5.62it/s, lr=9.8e-6, step_loss=0.00331]07/18/2023 19:37:39 - INFO - __main__ - train loss is 7.01305077993311\n",
      "Steps:  36%|█  | 5388/15000 [34:16<28:29,  5.62it/s, lr=9.8e-6, step_loss=0.394]07/18/2023 19:37:39 - INFO - __main__ - train loss is 7.015686109894887\n",
      "Steps:  36%|▎| 5389/15000 [34:17<28:31,  5.62it/s, lr=9.8e-6, step_loss=0.00264]07/18/2023 19:37:39 - INFO - __main__ - train loss is 7.054734733188525\n",
      "Steps:  36%|█  | 5390/15000 [34:17<28:32,  5.61it/s, lr=9.8e-6, step_loss=0.039]07/18/2023 19:37:39 - INFO - __main__ - train loss is 7.14936700114049\n",
      "Steps:  36%|▋ | 5391/15000 [34:17<28:31,  5.61it/s, lr=9.8e-6, step_loss=0.0946]07/18/2023 19:37:39 - INFO - __main__ - train loss is 7.216746699297801\n",
      "Steps:  36%|▋ | 5392/15000 [34:17<28:30,  5.62it/s, lr=9.8e-6, step_loss=0.0674]07/18/2023 19:37:39 - INFO - __main__ - train loss is 7.350283649051562\n",
      "Steps:  36%|█  | 5393/15000 [34:17<28:30,  5.62it/s, lr=9.8e-6, step_loss=0.134]07/18/2023 19:37:40 - INFO - __main__ - train loss is 7.446459997678176\n",
      "Steps:  36%|▋ | 5394/15000 [34:18<28:30,  5.62it/s, lr=9.8e-6, step_loss=0.0962]07/18/2023 19:37:40 - INFO - __main__ - train loss is 7.500441830838099\n",
      "Steps:  36%|█  | 5395/15000 [34:18<28:30,  5.62it/s, lr=9.8e-6, step_loss=0.054]07/18/2023 19:37:40 - INFO - __main__ - train loss is 7.674194466555491\n",
      "Steps:  36%|█  | 5396/15000 [34:18<28:43,  5.57it/s, lr=9.8e-6, step_loss=0.174]07/18/2023 19:37:40 - INFO - __main__ - train loss is 7.863105308497325\n",
      "Steps:  36%|█  | 5397/15000 [34:18<28:54,  5.54it/s, lr=9.8e-6, step_loss=0.189]07/18/2023 19:37:40 - INFO - __main__ - train loss is 7.905849058413878\n",
      "Steps:  36%|▋ | 5398/15000 [34:18<28:51,  5.54it/s, lr=9.8e-6, step_loss=0.0427]07/18/2023 19:37:41 - INFO - __main__ - train loss is 8.175622064853087\n",
      "Steps:  36%|█▍  | 5399/15000 [34:18<28:58,  5.52it/s, lr=9.8e-6, step_loss=0.27]07/18/2023 19:37:41 - INFO - __main__ - train loss is 8.252969276392832\n",
      "Steps:  36%|▋ | 5400/15000 [34:19<29:04,  5.50it/s, lr=9.8e-6, step_loss=0.0773]07/18/2023 19:37:41 - INFO - __main__ - train loss is 8.717762422049418\n",
      "Steps:  36%|█  | 5401/15000 [34:19<28:53,  5.54it/s, lr=9.8e-6, step_loss=0.465]07/18/2023 19:37:41 - INFO - __main__ - train loss is 8.828466501319781\n",
      "Steps:  36%|█  | 5402/15000 [34:19<28:57,  5.52it/s, lr=9.8e-6, step_loss=0.111]07/18/2023 19:37:41 - INFO - __main__ - train loss is 8.872641623253003\n",
      "Steps:  36%|▋ | 5403/15000 [34:19<29:03,  5.50it/s, lr=9.8e-6, step_loss=0.0442]07/18/2023 19:37:41 - INFO - __main__ - train loss is 8.880468990886584\n",
      "Steps:  36%|▎| 5404/15000 [34:19<29:18,  5.46it/s, lr=9.8e-6, step_loss=0.00783]07/18/2023 19:37:42 - INFO - __main__ - train loss is 9.190052535617724\n",
      "Steps:  36%|█▍  | 5405/15000 [34:20<29:27,  5.43it/s, lr=9.8e-6, step_loss=0.31]07/18/2023 19:37:42 - INFO - __main__ - train loss is 9.507271614158526\n",
      "Steps:  36%|█  | 5406/15000 [34:20<29:22,  5.44it/s, lr=9.8e-6, step_loss=0.317]07/18/2023 19:37:42 - INFO - __main__ - train loss is 9.578172128880396\n",
      "Steps:  36%|▋ | 5407/15000 [34:20<29:17,  5.46it/s, lr=9.8e-6, step_loss=0.0709]07/18/2023 19:37:42 - INFO - __main__ - train loss is 9.582865194184706\n",
      "Steps:  36%|▎| 5408/15000 [34:20<29:21,  5.45it/s, lr=9.8e-6, step_loss=0.00469]07/18/2023 19:37:42 - INFO - __main__ - train loss is 10.34296651254408\n",
      "Steps:  36%|█▍  | 5409/15000 [34:20<29:33,  5.41it/s, lr=9.8e-6, step_loss=0.76]07/18/2023 19:37:43 - INFO - __main__ - train loss is 10.44222938339226\n",
      "Steps:  36%|▋ | 5410/15000 [34:20<30:00,  5.33it/s, lr=9.8e-6, step_loss=0.0993]07/18/2023 19:37:43 - INFO - __main__ - train loss is 10.452574691502377\n",
      "Steps:  36%|▋ | 5411/15000 [34:21<30:17,  5.27it/s, lr=9.8e-6, step_loss=0.0103]07/18/2023 19:37:43 - INFO - __main__ - train loss is 10.455235552741215\n",
      "Steps:  36%|▎| 5412/15000 [34:21<30:28,  5.24it/s, lr=9.8e-6, step_loss=0.00266]07/18/2023 19:37:43 - INFO - __main__ - train loss is 10.627022546483204\n",
      "Steps:  36%|█  | 5413/15000 [34:21<30:20,  5.27it/s, lr=9.8e-6, step_loss=0.172]07/18/2023 19:37:43 - INFO - __main__ - train loss is 10.631254530744627\n",
      "Steps:  36%|▎| 5414/15000 [34:21<29:57,  5.33it/s, lr=9.8e-6, step_loss=0.00423]07/18/2023 19:37:43 - INFO - __main__ - train loss is 10.653846829431131\n",
      "Steps:  36%|▋ | 5415/15000 [34:21<29:40,  5.38it/s, lr=9.8e-6, step_loss=0.0226]07/18/2023 19:37:44 - INFO - __main__ - train loss is 10.700569807784632\n",
      "Steps:  36%|▋ | 5416/15000 [34:22<29:28,  5.42it/s, lr=9.8e-6, step_loss=0.0467]07/18/2023 19:37:44 - INFO - __main__ - train loss is 10.70495489728637\n",
      "Steps:  36%|▎| 5417/15000 [34:22<29:54,  5.34it/s, lr=9.8e-6, step_loss=0.00439]07/18/2023 19:37:44 - INFO - __main__ - train loss is 10.827111889841035\n",
      "Steps:  36%|█  | 5418/15000 [34:22<30:13,  5.28it/s, lr=9.8e-6, step_loss=0.122]07/18/2023 19:37:44 - INFO - __main__ - train loss is 11.095307727577165\n",
      "Steps:  36%|█  | 5419/15000 [34:22<30:23,  5.25it/s, lr=9.8e-6, step_loss=0.268]07/18/2023 19:37:44 - INFO - __main__ - train loss is 11.139267021091655\n",
      "Steps:  36%|█  | 5420/15000 [34:22<30:35,  5.22it/s, lr=9.8e-6, step_loss=0.044]07/18/2023 19:37:45 - INFO - __main__ - train loss is 11.59930678573437\n",
      "Steps:  36%|█▍  | 5421/15000 [34:23<30:41,  5.20it/s, lr=9.8e-6, step_loss=0.46]07/18/2023 19:37:45 - INFO - __main__ - train loss is 11.871124201687053\n",
      "Steps:  36%|█  | 5422/15000 [34:23<30:44,  5.19it/s, lr=9.8e-6, step_loss=0.272]07/18/2023 19:37:45 - INFO - __main__ - train loss is 12.15782439080067\n",
      "Steps:  36%|█  | 5423/15000 [34:23<31:16,  5.10it/s, lr=9.8e-6, step_loss=0.287]07/18/2023 19:37:45 - INFO - __main__ - train loss is 12.911954515846446\n",
      "Steps:  36%|█  | 5424/15000 [34:23<31:07,  5.13it/s, lr=9.8e-6, step_loss=0.754]07/18/2023 19:37:45 - INFO - __main__ - train loss is 13.38073789444752\n",
      "Steps:  36%|█  | 5425/15000 [34:23<31:02,  5.14it/s, lr=9.8e-6, step_loss=0.469]07/18/2023 19:37:46 - INFO - __main__ - train loss is 13.383547134464607\n",
      "Steps:  36%|▎| 5426/15000 [34:24<31:00,  5.15it/s, lr=9.8e-6, step_loss=0.00281]07/18/2023 19:37:46 - INFO - __main__ - train loss is 13.400795254623517\n",
      "Steps:  36%|▋ | 5427/15000 [34:24<30:59,  5.15it/s, lr=9.8e-6, step_loss=0.0172]07/18/2023 19:37:46 - INFO - __main__ - train loss is 13.416034119902179\n",
      "Steps:  36%|▋ | 5428/15000 [34:24<30:57,  5.15it/s, lr=9.8e-6, step_loss=0.0152]07/18/2023 19:37:46 - INFO - __main__ - train loss is 13.784391837893054\n",
      "Steps:  36%|█  | 5429/15000 [34:24<30:53,  5.16it/s, lr=9.8e-6, step_loss=0.368]07/18/2023 19:37:46 - INFO - __main__ - train loss is 13.795881333528087\n",
      "Steps:  36%|▋ | 5430/15000 [34:24<30:15,  5.27it/s, lr=9.8e-6, step_loss=0.0115]07/18/2023 19:37:47 - INFO - __main__ - train loss is 13.92353621381335\n",
      "Steps:  36%|█  | 5431/15000 [34:24<29:57,  5.32it/s, lr=9.8e-6, step_loss=0.128]07/18/2023 19:37:47 - INFO - __main__ - train loss is 13.92897629016079\n",
      "Steps:  36%|▎| 5432/15000 [34:25<40:41,  3.92it/s, lr=9.8e-6, step_loss=0.00544]07/18/2023 19:37:48 - INFO - __main__ - Per validation step average loss is 0.07621046900749207\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Cumulative validation average loss is 0.07621046900749207\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Per validation step average loss is 0.20960205793380737\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Cumulative validation average loss is 0.28581252694129944\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Per validation step average loss is 0.22959081828594208\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Cumulative validation average loss is 0.5154033452272415\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Per validation step average loss is 0.08661018311977386\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Cumulative validation average loss is 0.6020135283470154\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Per validation step average loss is 0.045024432241916656\n",
      "07/18/2023 19:37:48 - INFO - __main__ - Cumulative validation average loss is 0.647037960588932\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Per validation step average loss is 0.040583450347185135\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Cumulative validation average loss is 0.6876214109361172\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Per validation step average loss is 0.17857342958450317\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Cumulative validation average loss is 0.8661948405206203\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Per validation step average loss is 0.0016374216647818685\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Cumulative validation average loss is 0.8678322621854022\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Per validation step average loss is 0.033992357552051544\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Cumulative validation average loss is 0.9018246197374538\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Per validation step average loss is 0.08287655562162399\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Cumulative validation average loss is 0.9847011753590778\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Per validation step average loss is 0.02215200662612915\n",
      "07/18/2023 19:37:49 - INFO - __main__ - Cumulative validation average loss is 1.006853181985207\n",
      "07/18/2023 19:37:50 - INFO - __main__ - Per validation step average loss is 0.00459434324875474\n",
      "07/18/2023 19:37:50 - INFO - __main__ - Cumulative validation average loss is 1.0114475252339616\n",
      "07/18/2023 19:37:50 - INFO - __main__ - Average validation loss for Epoch 55 is 0.0842872937694968\n",
      "07/18/2023 19:37:50 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:38:02 - INFO - __main__ - Starting epoch 56\n",
      "07/18/2023 19:38:03 - INFO - __main__ - train loss is 0.001995488302782178\n",
      "Steps:  36%|▎| 5433/15000 [34:41<13:12:03,  4.97s/it, lr=9.8e-6, step_loss=0.00207/18/2023 19:38:03 - INFO - __main__ - train loss is 0.029263557167723775\n",
      "Steps:  36%|▎| 5434/15000 [34:41<9:22:59,  3.53s/it, lr=9.8e-6, step_loss=0.027307/18/2023 19:38:03 - INFO - __main__ - train loss is 0.4019298565108329\n",
      "Steps:  36%|▎| 5435/15000 [34:41<6:42:34,  2.53s/it, lr=9.8e-6, step_loss=0.373]07/18/2023 19:38:03 - INFO - __main__ - train loss is 0.7519294035155326\n",
      "Steps:  36%|▋ | 5436/15000 [34:41<4:50:16,  1.82s/it, lr=9.8e-6, step_loss=0.35]07/18/2023 19:38:04 - INFO - __main__ - train loss is 1.293329955311492\n",
      "Steps:  36%|▎| 5437/15000 [34:42<3:31:41,  1.33s/it, lr=9.8e-6, step_loss=0.541]07/18/2023 19:38:04 - INFO - __main__ - train loss is 1.296579774003476\n",
      "Steps:  36%|▎| 5438/15000 [34:42<2:36:48,  1.02it/s, lr=9.8e-6, step_loss=0.003207/18/2023 19:38:04 - INFO - __main__ - train loss is 1.3221925548277795\n",
      "Steps:  36%|▎| 5439/15000 [34:42<1:58:16,  1.35it/s, lr=9.8e-6, step_loss=0.025607/18/2023 19:38:04 - INFO - __main__ - train loss is 1.3448034166358411\n",
      "Steps:  36%|▎| 5440/15000 [34:42<1:31:16,  1.75it/s, lr=9.8e-6, step_loss=0.022607/18/2023 19:38:04 - INFO - __main__ - train loss is 1.3498675916343927\n",
      "Steps:  36%|▎| 5441/15000 [34:42<1:12:37,  2.19it/s, lr=9.8e-6, step_loss=0.005007/18/2023 19:38:05 - INFO - __main__ - train loss is 1.4407260660082102\n",
      "Steps:  36%|▋ | 5442/15000 [34:42<59:34,  2.67it/s, lr=9.8e-6, step_loss=0.0909]07/18/2023 19:38:05 - INFO - __main__ - train loss is 1.6822833064943552\n",
      "Steps:  36%|█  | 5443/15000 [34:43<50:12,  3.17it/s, lr=9.8e-6, step_loss=0.242]07/18/2023 19:38:05 - INFO - __main__ - train loss is 2.1980390790849924\n",
      "Steps:  36%|█  | 5444/15000 [34:43<43:42,  3.64it/s, lr=9.8e-6, step_loss=0.516]07/18/2023 19:38:05 - INFO - __main__ - train loss is 2.199764743912965\n",
      "Steps:  36%|▎| 5445/15000 [34:43<39:06,  4.07it/s, lr=9.8e-6, step_loss=0.00173]07/18/2023 19:38:05 - INFO - __main__ - train loss is 2.2517552305944264\n",
      "Steps:  36%|█  | 5446/15000 [34:43<35:57,  4.43it/s, lr=9.8e-6, step_loss=0.052]07/18/2023 19:38:05 - INFO - __main__ - train loss is 2.3696274613030255\n",
      "Steps:  36%|█  | 5447/15000 [34:43<33:41,  4.73it/s, lr=9.8e-6, step_loss=0.118]07/18/2023 19:38:06 - INFO - __main__ - train loss is 2.7370955203659832\n",
      "Steps:  36%|█  | 5448/15000 [34:44<32:05,  4.96it/s, lr=9.8e-6, step_loss=0.367]07/18/2023 19:38:06 - INFO - __main__ - train loss is 2.759669512975961\n",
      "Steps:  36%|▋ | 5449/15000 [34:44<30:59,  5.14it/s, lr=9.8e-6, step_loss=0.0226]07/18/2023 19:38:06 - INFO - __main__ - train loss is 2.875034995842725\n",
      "Steps:  36%|█  | 5450/15000 [34:44<30:14,  5.26it/s, lr=9.8e-6, step_loss=0.115]07/18/2023 19:38:06 - INFO - __main__ - train loss is 2.880906803999096\n",
      "Steps:  36%|▎| 5451/15000 [34:44<29:43,  5.35it/s, lr=9.8e-6, step_loss=0.00587]07/18/2023 19:38:06 - INFO - __main__ - train loss is 2.8862838591448963\n",
      "Steps:  36%|▎| 5452/15000 [34:44<29:20,  5.42it/s, lr=9.8e-6, step_loss=0.00538]07/18/2023 19:38:07 - INFO - __main__ - train loss is 2.96525815827772\n",
      "Steps:  36%|█  | 5453/15000 [34:44<29:04,  5.47it/s, lr=9.8e-6, step_loss=0.079]07/18/2023 19:38:07 - INFO - __main__ - train loss is 3.5314849982969463\n",
      "Steps:  36%|█  | 5454/15000 [34:45<28:52,  5.51it/s, lr=9.8e-6, step_loss=0.566]07/18/2023 19:38:07 - INFO - __main__ - train loss is 3.5710953320376575\n",
      "Steps:  36%|▋ | 5455/15000 [34:45<28:44,  5.54it/s, lr=9.8e-6, step_loss=0.0396]07/18/2023 19:38:07 - INFO - __main__ - train loss is 3.630716762971133\n",
      "Steps:  36%|▋ | 5456/15000 [34:45<28:35,  5.56it/s, lr=9.8e-6, step_loss=0.0596]07/18/2023 19:38:07 - INFO - __main__ - train loss is 3.6499065342359245\n",
      "Steps:  36%|▋ | 5457/15000 [34:45<28:31,  5.58it/s, lr=9.8e-6, step_loss=0.0192]07/18/2023 19:38:07 - INFO - __main__ - train loss is 3.9061271133832633\n",
      "Steps:  36%|█  | 5458/15000 [34:45<28:30,  5.58it/s, lr=9.8e-6, step_loss=0.256]07/18/2023 19:38:08 - INFO - __main__ - train loss is 4.031111020129174\n",
      "Steps:  36%|█  | 5459/15000 [34:45<28:28,  5.58it/s, lr=9.8e-6, step_loss=0.125]07/18/2023 19:38:08 - INFO - __main__ - train loss is 4.089191302191466\n",
      "Steps:  36%|▋ | 5460/15000 [34:46<28:27,  5.59it/s, lr=9.8e-6, step_loss=0.0581]07/18/2023 19:38:08 - INFO - __main__ - train loss is 4.247300281655043\n",
      "Steps:  36%|█  | 5461/15000 [34:46<28:25,  5.59it/s, lr=9.8e-6, step_loss=0.158]07/18/2023 19:38:08 - INFO - __main__ - train loss is 4.2965828026644886\n",
      "Steps:  36%|▋ | 5462/15000 [34:46<28:24,  5.60it/s, lr=9.8e-6, step_loss=0.0493]07/18/2023 19:38:08 - INFO - __main__ - train loss is 4.315395388286561\n",
      "Steps:  36%|▋ | 5463/15000 [34:46<28:24,  5.60it/s, lr=9.8e-6, step_loss=0.0188]07/18/2023 19:38:08 - INFO - __main__ - train loss is 4.5258107664994895\n",
      "Steps:  36%|█▍  | 5464/15000 [34:46<28:33,  5.57it/s, lr=9.8e-6, step_loss=0.21]07/18/2023 19:38:09 - INFO - __main__ - train loss is 4.952392685692757\n",
      "Steps:  36%|█  | 5465/15000 [34:47<28:28,  5.58it/s, lr=9.8e-6, step_loss=0.427]07/18/2023 19:38:09 - INFO - __main__ - train loss is 4.958621088881046\n",
      "Steps:  36%|▎| 5466/15000 [34:47<28:26,  5.59it/s, lr=9.8e-6, step_loss=0.00623]07/18/2023 19:38:09 - INFO - __main__ - train loss is 4.960969387320802\n",
      "Steps:  36%|▎| 5467/15000 [34:47<28:24,  5.59it/s, lr=9.8e-6, step_loss=0.00235]07/18/2023 19:38:09 - INFO - __main__ - train loss is 4.974821983603761\n",
      "Steps:  36%|▋ | 5468/15000 [34:47<29:40,  5.35it/s, lr=9.8e-6, step_loss=0.0139]07/18/2023 19:38:09 - INFO - __main__ - train loss is 5.097383162705228\n",
      "Steps:  36%|█  | 5469/15000 [34:47<29:34,  5.37it/s, lr=9.8e-6, step_loss=0.123]07/18/2023 19:38:10 - INFO - __main__ - train loss is 5.653457066742703\n",
      "Steps:  36%|█  | 5470/15000 [34:48<31:16,  5.08it/s, lr=9.8e-6, step_loss=0.556]07/18/2023 19:38:10 - INFO - __main__ - train loss is 5.688450581161305\n",
      "Steps:  36%|█  | 5471/15000 [34:48<30:27,  5.21it/s, lr=9.8e-6, step_loss=0.035]07/18/2023 19:38:10 - INFO - __main__ - train loss is 5.735044277040288\n",
      "Steps:  36%|▋ | 5472/15000 [34:48<29:49,  5.33it/s, lr=9.8e-6, step_loss=0.0466]07/18/2023 19:38:10 - INFO - __main__ - train loss is 6.324145114747807\n",
      "Steps:  36%|█  | 5473/15000 [34:48<29:21,  5.41it/s, lr=9.8e-6, step_loss=0.589]07/18/2023 19:38:10 - INFO - __main__ - train loss is 6.3812711823266\n",
      "Steps:  36%|▋ | 5474/15000 [34:48<29:02,  5.47it/s, lr=9.8e-6, step_loss=0.0571]07/18/2023 19:38:11 - INFO - __main__ - train loss is 6.610031961230561\n",
      "Steps:  36%|█  | 5475/15000 [34:48<28:49,  5.51it/s, lr=9.8e-6, step_loss=0.229]07/18/2023 19:38:11 - INFO - __main__ - train loss is 7.0819487858098\n",
      "Steps:  37%|█  | 5476/15000 [34:49<28:38,  5.54it/s, lr=9.8e-6, step_loss=0.472]07/18/2023 19:38:11 - INFO - __main__ - train loss is 7.12756663816981\n",
      "Steps:  37%|▋ | 5477/15000 [34:49<28:33,  5.56it/s, lr=9.8e-6, step_loss=0.0456]07/18/2023 19:38:11 - INFO - __main__ - train loss is 7.275379392085597\n",
      "Steps:  37%|█  | 5478/15000 [34:49<28:27,  5.57it/s, lr=9.8e-6, step_loss=0.148]07/18/2023 19:38:11 - INFO - __main__ - train loss is 7.3863752882461995\n",
      "Steps:  37%|█  | 5479/15000 [34:49<28:24,  5.59it/s, lr=9.8e-6, step_loss=0.111]07/18/2023 19:38:11 - INFO - __main__ - train loss is 7.462133998749778\n",
      "Steps:  37%|▋ | 5480/15000 [34:49<28:21,  5.59it/s, lr=9.8e-6, step_loss=0.0758]07/18/2023 19:38:12 - INFO - __main__ - train loss is 7.464411357417703\n",
      "Steps:  37%|▎| 5481/15000 [34:49<28:22,  5.59it/s, lr=9.8e-6, step_loss=0.00228]07/18/2023 19:38:12 - INFO - __main__ - train loss is 7.466157852904871\n",
      "Steps:  37%|▎| 5482/15000 [34:50<28:20,  5.60it/s, lr=9.8e-6, step_loss=0.00175]07/18/2023 19:38:12 - INFO - __main__ - train loss is 7.638079553144053\n",
      "Steps:  37%|█  | 5483/15000 [34:50<28:34,  5.55it/s, lr=9.8e-6, step_loss=0.172]07/18/2023 19:38:12 - INFO - __main__ - train loss is 7.796851217048243\n",
      "Steps:  37%|█  | 5484/15000 [34:50<28:34,  5.55it/s, lr=9.8e-6, step_loss=0.159]07/18/2023 19:38:12 - INFO - __main__ - train loss is 8.704742490546778\n",
      "Steps:  37%|█  | 5485/15000 [34:50<28:29,  5.56it/s, lr=9.8e-6, step_loss=0.908]07/18/2023 19:38:13 - INFO - __main__ - train loss is 8.71149999764748\n",
      "Steps:  37%|▎| 5486/15000 [34:50<28:26,  5.58it/s, lr=9.8e-6, step_loss=0.00676]07/18/2023 19:38:13 - INFO - __main__ - train loss is 8.725309000583366\n",
      "Steps:  37%|▋ | 5487/15000 [34:51<28:24,  5.58it/s, lr=9.8e-6, step_loss=0.0138]07/18/2023 19:38:13 - INFO - __main__ - train loss is 8.771139891119674\n",
      "Steps:  37%|▋ | 5488/15000 [34:51<28:21,  5.59it/s, lr=9.8e-6, step_loss=0.0458]07/18/2023 19:38:13 - INFO - __main__ - train loss is 9.433544189902022\n",
      "Steps:  37%|█  | 5489/15000 [34:51<28:22,  5.59it/s, lr=9.8e-6, step_loss=0.662]07/18/2023 19:38:13 - INFO - __main__ - train loss is 9.458152097882703\n",
      "Steps:  37%|▋ | 5490/15000 [34:51<28:19,  5.59it/s, lr=9.8e-6, step_loss=0.0246]07/18/2023 19:38:13 - INFO - __main__ - train loss is 9.465177348582074\n",
      "Steps:  37%|▎| 5491/15000 [34:51<28:19,  5.60it/s, lr=9.8e-6, step_loss=0.00703]07/18/2023 19:38:14 - INFO - __main__ - train loss is 9.932051888434216\n",
      "Steps:  37%|█  | 5492/15000 [34:51<28:17,  5.60it/s, lr=9.8e-6, step_loss=0.467]07/18/2023 19:38:14 - INFO - __main__ - train loss is 10.208382538286969\n",
      "Steps:  37%|█  | 5493/15000 [34:52<28:15,  5.61it/s, lr=9.8e-6, step_loss=0.276]07/18/2023 19:38:14 - INFO - __main__ - train loss is 10.765391400782391\n",
      "Steps:  37%|█  | 5494/15000 [34:52<28:14,  5.61it/s, lr=9.8e-6, step_loss=0.557]07/18/2023 19:38:14 - INFO - __main__ - train loss is 10.965065917698666\n",
      "Steps:  37%|█▊   | 5495/15000 [34:52<28:13,  5.61it/s, lr=9.8e-6, step_loss=0.2]07/18/2023 19:38:14 - INFO - __main__ - train loss is 10.999133786885068\n",
      "Steps:  37%|▋ | 5496/15000 [34:52<28:12,  5.61it/s, lr=9.8e-6, step_loss=0.0341]07/18/2023 19:38:14 - INFO - __main__ - train loss is 11.000910616945475\n",
      "Steps:  37%|▎| 5497/15000 [34:52<28:12,  5.62it/s, lr=9.8e-6, step_loss=0.00178]07/18/2023 19:38:15 - INFO - __main__ - train loss is 11.024194251280278\n",
      "Steps:  37%|▋ | 5498/15000 [34:53<28:14,  5.61it/s, lr=9.8e-6, step_loss=0.0233]07/18/2023 19:38:15 - INFO - __main__ - train loss is 11.180724899750203\n",
      "Steps:  37%|█  | 5499/15000 [34:53<28:15,  5.60it/s, lr=9.8e-6, step_loss=0.157]07/18/2023 19:38:15 - INFO - __main__ - train loss is 11.185656934510916\n",
      "Steps:  37%|█  | 5500/15000 [34:53<28:14,  5.61it/s, lr=9.8e-6, step_loss=0.157]07/18/2023 19:38:15 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-5500\n",
      "07/18/2023 19:38:15 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:38:15,592] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:38:15,596] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-5500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:38:15,596] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-5500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:38:15,604] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-5500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:38:15,604] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-5500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:38:15,625] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-5500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:38:15,626] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-5500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:38:15,626] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:38:15 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-5500/pytorch_model\n",
      "07/18/2023 19:38:15 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-5500/scheduler.bin\n",
      "07/18/2023 19:38:15 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-5500/random_states_0.pkl\n",
      "07/18/2023 19:38:15 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-5500\n",
      "Steps:  37%|▎| 5500/15000 [34:53<28:14,  5.61it/s, lr=9.8e-6, step_loss=0.00493]07/18/2023 19:38:15 - INFO - __main__ - train loss is 11.189454158302397\n",
      "Steps:  37%|▋ | 5501/15000 [34:53<29:57,  5.28it/s, lr=9.8e-6, step_loss=0.0038]07/18/2023 19:38:15 - INFO - __main__ - train loss is 11.644824822898954\n",
      "Steps:  37%|▋ | 5502/15000 [34:53<29:26,  5.38it/s, lr=9.79e-6, step_loss=0.455]07/18/2023 19:38:16 - INFO - __main__ - train loss is 11.985376556869596\n",
      "Steps:  37%|▋ | 5503/15000 [34:53<29:03,  5.45it/s, lr=9.79e-6, step_loss=0.341]07/18/2023 19:38:16 - INFO - __main__ - train loss is 12.00304403482005\n",
      "Steps:  37%|▎| 5504/15000 [34:54<28:52,  5.48it/s, lr=9.79e-6, step_loss=0.0177]07/18/2023 19:38:16 - INFO - __main__ - train loss is 12.945472623687238\n",
      "Steps:  37%|▋ | 5505/15000 [34:54<28:41,  5.52it/s, lr=9.79e-6, step_loss=0.942]07/18/2023 19:38:16 - INFO - __main__ - train loss is 13.192646767478436\n",
      "Steps:  37%|▋ | 5506/15000 [34:54<28:33,  5.54it/s, lr=9.79e-6, step_loss=0.247]07/18/2023 19:38:16 - INFO - __main__ - train loss is 13.222826465498656\n",
      "Steps:  37%|▎| 5507/15000 [34:54<28:28,  5.56it/s, lr=9.79e-6, step_loss=0.0302]07/18/2023 19:38:16 - INFO - __main__ - train loss is 13.38508890522644\n",
      "Steps:  37%|▋ | 5508/15000 [34:54<28:23,  5.57it/s, lr=9.79e-6, step_loss=0.162]07/18/2023 19:38:17 - INFO - __main__ - train loss is 13.403959359508008\n",
      "Steps:  37%|▎| 5509/15000 [34:55<28:19,  5.58it/s, lr=9.79e-6, step_loss=0.0189]07/18/2023 19:38:17 - INFO - __main__ - train loss is 13.591169233899564\n",
      "Steps:  37%|▋ | 5510/15000 [34:55<28:16,  5.59it/s, lr=9.79e-6, step_loss=0.187]07/18/2023 19:38:17 - INFO - __main__ - train loss is 13.959423835854977\n",
      "Steps:  37%|▋ | 5511/15000 [34:55<28:14,  5.60it/s, lr=9.79e-6, step_loss=0.368]07/18/2023 19:38:17 - INFO - __main__ - train loss is 14.207738082390279\n",
      "Steps:  37%|▋ | 5512/15000 [34:55<28:13,  5.60it/s, lr=9.79e-6, step_loss=0.248]07/18/2023 19:38:17 - INFO - __main__ - train loss is 14.222645177971572\n",
      "Steps:  37%|▎| 5513/15000 [34:55<28:12,  5.61it/s, lr=9.79e-6, step_loss=0.0149]07/18/2023 19:38:18 - INFO - __main__ - train loss is 14.661942734848708\n",
      "Steps:  37%|▋ | 5514/15000 [34:55<28:11,  5.61it/s, lr=9.79e-6, step_loss=0.439]07/18/2023 19:38:18 - INFO - __main__ - train loss is 14.69368041632697\n",
      "Steps:  37%|▎| 5515/15000 [34:56<28:09,  5.62it/s, lr=9.79e-6, step_loss=0.0317]07/18/2023 19:38:18 - INFO - __main__ - train loss is 14.781125869136304\n",
      "Steps:  37%|▎| 5516/15000 [34:56<28:08,  5.62it/s, lr=9.79e-6, step_loss=0.0874]07/18/2023 19:38:18 - INFO - __main__ - train loss is 15.51386186061427\n",
      "Steps:  37%|▋ | 5517/15000 [34:56<28:07,  5.62it/s, lr=9.79e-6, step_loss=0.733]07/18/2023 19:38:18 - INFO - __main__ - train loss is 15.52440156089142\n",
      "Steps:  37%|▎| 5518/15000 [34:56<28:06,  5.62it/s, lr=9.79e-6, step_loss=0.0105]07/18/2023 19:38:18 - INFO - __main__ - train loss is 15.565717794466764\n",
      "Steps:  37%|▎| 5519/15000 [34:56<28:07,  5.62it/s, lr=9.79e-6, step_loss=0.0413]07/18/2023 19:38:19 - INFO - __main__ - train loss is 15.615701009053737\n",
      "Steps:  37%|█  | 5520/15000 [34:56<28:06,  5.62it/s, lr=9.79e-6, step_loss=0.05]07/18/2023 19:38:19 - INFO - __main__ - train loss is 15.912528295535594\n",
      "Steps:  37%|▋ | 5521/15000 [34:57<28:07,  5.62it/s, lr=9.79e-6, step_loss=0.297]07/18/2023 19:38:19 - INFO - __main__ - train loss is 15.929328788537532\n",
      "Steps:  37%|▎| 5522/15000 [34:57<28:07,  5.62it/s, lr=9.79e-6, step_loss=0.0168]07/18/2023 19:38:19 - INFO - __main__ - train loss is 16.11938162567094\n",
      "Steps:  37%|█  | 5523/15000 [34:57<28:08,  5.61it/s, lr=9.79e-6, step_loss=0.19]07/18/2023 19:38:19 - INFO - __main__ - train loss is 16.473989297170192\n",
      "Steps:  37%|▋ | 5524/15000 [34:57<28:11,  5.60it/s, lr=9.79e-6, step_loss=0.355]07/18/2023 19:38:19 - INFO - __main__ - train loss is 16.48150131292641\n",
      "Steps:  37%|▎| 5525/15000 [34:57<28:10,  5.60it/s, lr=9.79e-6, step_loss=0.0075107/18/2023 19:38:20 - INFO - __main__ - train loss is 16.516378534957767\n",
      "Steps:  37%|▎| 5526/15000 [34:58<28:09,  5.61it/s, lr=9.79e-6, step_loss=0.0349]07/18/2023 19:38:20 - INFO - __main__ - train loss is 16.611367566511035\n",
      "Steps:  37%|▋ | 5527/15000 [34:58<28:07,  5.61it/s, lr=9.79e-6, step_loss=0.095]07/18/2023 19:38:20 - INFO - __main__ - train loss is 16.614035069243982\n",
      "Steps:  37%|▎| 5528/15000 [34:58<28:09,  5.61it/s, lr=9.79e-6, step_loss=0.0026707/18/2023 19:38:20 - INFO - __main__ - train loss is 16.64607527037151\n",
      "Steps:  37%|▋ | 5529/15000 [34:58<38:47,  4.07it/s, lr=9.79e-6, step_loss=0.032]07/18/2023 19:38:21 - INFO - __main__ - Per validation step average loss is 0.0019613225013017654\n",
      "07/18/2023 19:38:21 - INFO - __main__ - Cumulative validation average loss is 0.0019613225013017654\n",
      "07/18/2023 19:38:21 - INFO - __main__ - Per validation step average loss is 0.1988411843776703\n",
      "07/18/2023 19:38:21 - INFO - __main__ - Cumulative validation average loss is 0.20080250687897205\n",
      "07/18/2023 19:38:21 - INFO - __main__ - Per validation step average loss is 0.003203272121027112\n",
      "07/18/2023 19:38:21 - INFO - __main__ - Cumulative validation average loss is 0.20400577899999917\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Per validation step average loss is 0.014961151406168938\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Cumulative validation average loss is 0.2189669304061681\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Per validation step average loss is 0.01758531481027603\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Cumulative validation average loss is 0.23655224521644413\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Per validation step average loss is 0.20906594395637512\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Cumulative validation average loss is 0.44561818917281926\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Per validation step average loss is 0.48535168170928955\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Cumulative validation average loss is 0.9309698708821088\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Per validation step average loss is 0.03379351645708084\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Cumulative validation average loss is 0.9647633873391896\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Per validation step average loss is 0.12883782386779785\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Cumulative validation average loss is 1.0936012112069875\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Per validation step average loss is 0.13932646811008453\n",
      "07/18/2023 19:38:22 - INFO - __main__ - Cumulative validation average loss is 1.232927679317072\n",
      "07/18/2023 19:38:23 - INFO - __main__ - Per validation step average loss is 0.04723397642374039\n",
      "07/18/2023 19:38:23 - INFO - __main__ - Cumulative validation average loss is 1.2801616557408124\n",
      "07/18/2023 19:38:23 - INFO - __main__ - Per validation step average loss is 0.050999801605939865\n",
      "07/18/2023 19:38:23 - INFO - __main__ - Cumulative validation average loss is 1.3311614573467523\n",
      "07/18/2023 19:38:23 - INFO - __main__ - Average validation loss for Epoch 56 is 0.11093012144556269\n",
      "07/18/2023 19:38:23 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:38:36 - INFO - __main__ - Starting epoch 57\n",
      "07/18/2023 19:38:36 - INFO - __main__ - train loss is 0.07933886349201202\n",
      "Steps:  37%|▎| 5530/15000 [35:14<12:51:09,  4.89s/it, lr=9.79e-6, step_loss=0.0707/18/2023 19:38:36 - INFO - __main__ - train loss is 0.09053815715014935\n",
      "Steps:  37%|▎| 5531/15000 [35:14<9:08:11,  3.47s/it, lr=9.79e-6, step_loss=0.01107/18/2023 19:38:37 - INFO - __main__ - train loss is 0.2521584164351225\n",
      "Steps:  37%|▎| 5532/15000 [35:14<6:32:05,  2.48s/it, lr=9.79e-6, step_loss=0.16207/18/2023 19:38:37 - INFO - __main__ - train loss is 0.25424352288246155\n",
      "Steps:  37%|▎| 5533/15000 [35:15<4:42:52,  1.79s/it, lr=9.79e-6, step_loss=0.00207/18/2023 19:38:37 - INFO - __main__ - train loss is 0.2867787033319473\n",
      "Steps:  37%|▎| 5534/15000 [35:15<3:26:24,  1.31s/it, lr=9.79e-6, step_loss=0.03207/18/2023 19:38:37 - INFO - __main__ - train loss is 0.7569452375173569\n",
      "Steps:  37%|▎| 5535/15000 [35:15<2:33:00,  1.03it/s, lr=9.79e-6, step_loss=0.47]07/18/2023 19:38:37 - INFO - __main__ - train loss is 0.9674708545207977\n",
      "Steps:  37%|▎| 5536/15000 [35:15<1:55:33,  1.36it/s, lr=9.79e-6, step_loss=0.21107/18/2023 19:38:37 - INFO - __main__ - train loss is 0.9734641290269792\n",
      "Steps:  37%|▎| 5537/15000 [35:15<1:29:15,  1.77it/s, lr=9.79e-6, step_loss=0.00507/18/2023 19:38:38 - INFO - __main__ - train loss is 1.2109723961912096\n",
      "Steps:  37%|▎| 5538/15000 [35:15<1:11:08,  2.22it/s, lr=9.79e-6, step_loss=0.23807/18/2023 19:38:38 - INFO - __main__ - train loss is 1.2134792525321245\n",
      "Steps:  37%|▎| 5539/15000 [35:16<58:18,  2.70it/s, lr=9.79e-6, step_loss=0.0025107/18/2023 19:38:38 - INFO - __main__ - train loss is 1.5567242819815874\n",
      "Steps:  37%|▋ | 5540/15000 [35:16<49:12,  3.20it/s, lr=9.79e-6, step_loss=0.343]07/18/2023 19:38:38 - INFO - __main__ - train loss is 1.5852417275309563\n",
      "Steps:  37%|▎| 5541/15000 [35:16<42:50,  3.68it/s, lr=9.79e-6, step_loss=0.0285]07/18/2023 19:38:38 - INFO - __main__ - train loss is 1.590712965466082\n",
      "Steps:  37%|▎| 5542/15000 [35:16<38:24,  4.10it/s, lr=9.79e-6, step_loss=0.0054707/18/2023 19:38:38 - INFO - __main__ - train loss is 1.6307489024475217\n",
      "Steps:  37%|█  | 5543/15000 [35:16<35:16,  4.47it/s, lr=9.79e-6, step_loss=0.04]07/18/2023 19:38:39 - INFO - __main__ - train loss is 2.318164144642651\n",
      "Steps:  37%|▋ | 5544/15000 [35:17<33:07,  4.76it/s, lr=9.79e-6, step_loss=0.687]07/18/2023 19:38:39 - INFO - __main__ - train loss is 2.326483796350658\n",
      "Steps:  37%|▎| 5545/15000 [35:17<31:35,  4.99it/s, lr=9.79e-6, step_loss=0.0083207/18/2023 19:38:39 - INFO - __main__ - train loss is 2.375180165283382\n",
      "Steps:  37%|▎| 5546/15000 [35:17<30:31,  5.16it/s, lr=9.79e-6, step_loss=0.0487]07/18/2023 19:38:39 - INFO - __main__ - train loss is 2.378902033669874\n",
      "Steps:  37%|▎| 5547/15000 [35:17<29:46,  5.29it/s, lr=9.79e-6, step_loss=0.0037207/18/2023 19:38:39 - INFO - __main__ - train loss is 2.748596803052351\n",
      "Steps:  37%|█  | 5548/15000 [35:17<29:16,  5.38it/s, lr=9.79e-6, step_loss=0.37]07/18/2023 19:38:40 - INFO - __main__ - train loss is 2.7586852132808417\n",
      "Steps:  37%|▎| 5549/15000 [35:17<28:57,  5.44it/s, lr=9.79e-6, step_loss=0.0101]07/18/2023 19:38:40 - INFO - __main__ - train loss is 3.258289110613987\n",
      "Steps:  37%|█▍  | 5550/15000 [35:18<28:42,  5.49it/s, lr=9.79e-6, step_loss=0.5]07/18/2023 19:38:40 - INFO - __main__ - train loss is 3.951679718447849\n",
      "Steps:  37%|▋ | 5551/15000 [35:18<28:31,  5.52it/s, lr=9.79e-6, step_loss=0.693]07/18/2023 19:38:40 - INFO - __main__ - train loss is 3.9572293942328542\n",
      "Steps:  37%|▎| 5552/15000 [35:18<28:23,  5.55it/s, lr=9.79e-6, step_loss=0.0055507/18/2023 19:38:40 - INFO - __main__ - train loss is 3.9615956030320376\n",
      "Steps:  37%|▎| 5553/15000 [35:18<28:18,  5.56it/s, lr=9.79e-6, step_loss=0.0043707/18/2023 19:38:40 - INFO - __main__ - train loss is 3.963615817716345\n",
      "Steps:  37%|▎| 5554/15000 [35:18<28:14,  5.58it/s, lr=9.79e-6, step_loss=0.0020207/18/2023 19:38:41 - INFO - __main__ - train loss is 4.295603794744238\n",
      "Steps:  37%|▋ | 5555/15000 [35:18<28:12,  5.58it/s, lr=9.79e-6, step_loss=0.332]07/18/2023 19:38:41 - INFO - __main__ - train loss is 4.331081731012091\n",
      "Steps:  37%|▎| 5556/15000 [35:19<28:10,  5.59it/s, lr=9.79e-6, step_loss=0.0355]07/18/2023 19:38:41 - INFO - __main__ - train loss is 4.701255185296759\n",
      "Steps:  37%|█  | 5557/15000 [35:19<28:08,  5.59it/s, lr=9.79e-6, step_loss=0.37]07/18/2023 19:38:41 - INFO - __main__ - train loss is 5.0827039608266205\n",
      "Steps:  37%|▋ | 5558/15000 [35:19<28:06,  5.60it/s, lr=9.79e-6, step_loss=0.381]07/18/2023 19:38:41 - INFO - __main__ - train loss is 5.106518424814567\n",
      "Steps:  37%|▎| 5559/15000 [35:19<28:07,  5.60it/s, lr=9.79e-6, step_loss=0.0238]07/18/2023 19:38:42 - INFO - __main__ - train loss is 5.108548601856455\n",
      "Steps:  37%|▎| 5560/15000 [35:19<28:10,  5.58it/s, lr=9.79e-6, step_loss=0.0020307/18/2023 19:38:42 - INFO - __main__ - train loss is 5.118176664924249\n",
      "Steps:  37%|▎| 5561/15000 [35:20<28:25,  5.54it/s, lr=9.79e-6, step_loss=0.0096307/18/2023 19:38:42 - INFO - __main__ - train loss is 5.189267825102434\n",
      "Steps:  37%|▎| 5562/15000 [35:20<28:34,  5.51it/s, lr=9.79e-6, step_loss=0.0711]07/18/2023 19:38:42 - INFO - __main__ - train loss is 5.280030999099836\n",
      "Steps:  37%|▎| 5563/15000 [35:20<28:58,  5.43it/s, lr=9.79e-6, step_loss=0.0908]07/18/2023 19:38:42 - INFO - __main__ - train loss is 5.473530802642927\n",
      "Steps:  37%|▋ | 5564/15000 [35:20<28:48,  5.46it/s, lr=9.79e-6, step_loss=0.193]07/18/2023 19:38:42 - INFO - __main__ - train loss is 5.485347517533228\n",
      "Steps:  37%|▎| 5565/15000 [35:20<28:52,  5.45it/s, lr=9.79e-6, step_loss=0.0118]07/18/2023 19:38:43 - INFO - __main__ - train loss is 5.713610642356798\n",
      "Steps:  37%|▋ | 5566/15000 [35:20<28:52,  5.45it/s, lr=9.79e-6, step_loss=0.228]07/18/2023 19:38:43 - INFO - __main__ - train loss is 5.761651181383058\n",
      "Steps:  37%|▋ | 5567/15000 [35:21<28:47,  5.46it/s, lr=9.79e-6, step_loss=0.048]07/18/2023 19:38:43 - INFO - __main__ - train loss is 5.767531148856506\n",
      "Steps:  37%|▎| 5568/15000 [35:21<28:44,  5.47it/s, lr=9.79e-6, step_loss=0.0058807/18/2023 19:38:43 - INFO - __main__ - train loss is 5.770249473163858\n",
      "Steps:  37%|▎| 5569/15000 [35:21<29:03,  5.41it/s, lr=9.79e-6, step_loss=0.0027207/18/2023 19:38:43 - INFO - __main__ - train loss is 5.772098363842815\n",
      "Steps:  37%|▎| 5570/15000 [35:21<29:31,  5.32it/s, lr=9.79e-6, step_loss=0.0018507/18/2023 19:38:44 - INFO - __main__ - train loss is 5.783676180522889\n",
      "Steps:  37%|▎| 5571/15000 [35:21<29:47,  5.28it/s, lr=9.79e-6, step_loss=0.0116]07/18/2023 19:38:44 - INFO - __main__ - train loss is 6.522390696685761\n",
      "Steps:  37%|▋ | 5572/15000 [35:22<30:01,  5.23it/s, lr=9.79e-6, step_loss=0.739]07/18/2023 19:38:44 - INFO - __main__ - train loss is 6.620352629106492\n",
      "Steps:  37%|▋ | 5573/15000 [35:22<30:16,  5.19it/s, lr=9.79e-6, step_loss=0.098]07/18/2023 19:38:44 - INFO - __main__ - train loss is 6.686427909415215\n",
      "Steps:  37%|▎| 5574/15000 [35:22<30:22,  5.17it/s, lr=9.79e-6, step_loss=0.0661]07/18/2023 19:38:44 - INFO - __main__ - train loss is 6.750011298339814\n",
      "Steps:  37%|▎| 5575/15000 [35:22<30:00,  5.24it/s, lr=9.79e-6, step_loss=0.0636]07/18/2023 19:38:45 - INFO - __main__ - train loss is 7.273085806053132\n",
      "Steps:  37%|▋ | 5576/15000 [35:22<29:35,  5.31it/s, lr=9.79e-6, step_loss=0.523]07/18/2023 19:38:45 - INFO - __main__ - train loss is 7.415590736549348\n",
      "Steps:  37%|▋ | 5577/15000 [35:23<29:34,  5.31it/s, lr=9.79e-6, step_loss=0.143]07/18/2023 19:38:45 - INFO - __main__ - train loss is 7.568862605374306\n",
      "Steps:  37%|▋ | 5578/15000 [35:23<29:55,  5.25it/s, lr=9.79e-6, step_loss=0.153]07/18/2023 19:38:45 - INFO - __main__ - train loss is 7.844517547171563\n",
      "Steps:  37%|▋ | 5579/15000 [35:23<30:13,  5.20it/s, lr=9.79e-6, step_loss=0.276]07/18/2023 19:38:45 - INFO - __main__ - train loss is 7.9409084427170455\n",
      "Steps:  37%|▎| 5580/15000 [35:23<30:26,  5.16it/s, lr=9.79e-6, step_loss=0.0964]07/18/2023 19:38:45 - INFO - __main__ - train loss is 7.955087548587471\n",
      "Steps:  37%|▎| 5581/15000 [35:23<30:33,  5.14it/s, lr=9.79e-6, step_loss=0.0142]07/18/2023 19:38:46 - INFO - __main__ - train loss is 8.13298753509298\n",
      "Steps:  37%|▋ | 5582/15000 [35:24<30:32,  5.14it/s, lr=9.79e-6, step_loss=0.178]07/18/2023 19:38:46 - INFO - __main__ - train loss is 8.556345021817833\n",
      "Steps:  37%|▋ | 5583/15000 [35:24<30:53,  5.08it/s, lr=9.79e-6, step_loss=0.423]07/18/2023 19:38:46 - INFO - __main__ - train loss is 8.994767403695732\n",
      "Steps:  37%|▋ | 5584/15000 [35:24<30:46,  5.10it/s, lr=9.79e-6, step_loss=0.438]07/18/2023 19:38:46 - INFO - __main__ - train loss is 9.306581354234368\n",
      "Steps:  37%|▋ | 5585/15000 [35:24<30:40,  5.12it/s, lr=9.79e-6, step_loss=0.312]07/18/2023 19:38:46 - INFO - __main__ - train loss is 9.343483379576355\n",
      "Steps:  37%|▎| 5586/15000 [35:24<31:09,  5.03it/s, lr=9.79e-6, step_loss=0.0369]07/18/2023 19:38:47 - INFO - __main__ - train loss is 9.405447325203568\n",
      "Steps:  37%|▋ | 5587/15000 [35:25<30:53,  5.08it/s, lr=9.79e-6, step_loss=0.062]07/18/2023 19:38:47 - INFO - __main__ - train loss is 9.434242064598948\n",
      "Steps:  37%|▎| 5588/15000 [35:25<30:38,  5.12it/s, lr=9.79e-6, step_loss=0.0288]07/18/2023 19:38:47 - INFO - __main__ - train loss is 9.445259605068713\n",
      "Steps:  37%|▋ | 5589/15000 [35:25<29:56,  5.24it/s, lr=9.79e-6, step_loss=0.011]07/18/2023 19:38:47 - INFO - __main__ - train loss is 9.448770621558651\n",
      "Steps:  37%|▎| 5590/15000 [35:25<29:31,  5.31it/s, lr=9.79e-6, step_loss=0.0035107/18/2023 19:38:47 - INFO - __main__ - train loss is 9.58202708675526\n",
      "Steps:  37%|▋ | 5591/15000 [35:25<29:03,  5.40it/s, lr=9.79e-6, step_loss=0.133]07/18/2023 19:38:48 - INFO - __main__ - train loss is 9.651598842581734\n",
      "Steps:  37%|▎| 5592/15000 [35:25<28:44,  5.46it/s, lr=9.79e-6, step_loss=0.0696]07/18/2023 19:38:48 - INFO - __main__ - train loss is 9.671610312303528\n",
      "Steps:  37%|█  | 5593/15000 [35:26<28:31,  5.50it/s, lr=9.79e-6, step_loss=0.02]07/18/2023 19:38:48 - INFO - __main__ - train loss is 10.058205054840073\n",
      "Steps:  37%|▋ | 5594/15000 [35:26<28:21,  5.53it/s, lr=9.79e-6, step_loss=0.387]07/18/2023 19:38:48 - INFO - __main__ - train loss is 10.06089029693976\n",
      "Steps:  37%|▎| 5595/15000 [35:26<28:13,  5.55it/s, lr=9.79e-6, step_loss=0.0026907/18/2023 19:38:48 - INFO - __main__ - train loss is 10.096236715558916\n",
      "Steps:  37%|▎| 5596/15000 [35:26<28:08,  5.57it/s, lr=9.79e-6, step_loss=0.0353]07/18/2023 19:38:48 - INFO - __main__ - train loss is 10.10338778840378\n",
      "Steps:  37%|▎| 5597/15000 [35:26<28:04,  5.58it/s, lr=9.79e-6, step_loss=0.0071507/18/2023 19:38:49 - INFO - __main__ - train loss is 10.123743447009474\n",
      "Steps:  37%|▎| 5598/15000 [35:27<28:02,  5.59it/s, lr=9.79e-6, step_loss=0.0204]07/18/2023 19:38:49 - INFO - __main__ - train loss is 10.440946193877608\n",
      "Steps:  37%|▋ | 5599/15000 [35:27<27:59,  5.60it/s, lr=9.79e-6, step_loss=0.317]07/18/2023 19:38:49 - INFO - __main__ - train loss is 10.531744095031172\n",
      "Steps:  37%|▎| 5600/15000 [35:27<27:57,  5.60it/s, lr=9.79e-6, step_loss=0.0908]07/18/2023 19:38:49 - INFO - __main__ - train loss is 10.61201041424647\n",
      "Steps:  37%|▎| 5601/15000 [35:27<27:57,  5.60it/s, lr=9.79e-6, step_loss=0.0803]07/18/2023 19:38:49 - INFO - __main__ - train loss is 10.942397887352854\n",
      "Steps:  37%|█  | 5602/15000 [35:27<27:56,  5.60it/s, lr=9.79e-6, step_loss=0.33]07/18/2023 19:38:50 - INFO - __main__ - train loss is 10.948362677823752\n",
      "Steps:  37%|▎| 5603/15000 [35:27<27:56,  5.61it/s, lr=9.79e-6, step_loss=0.0059607/18/2023 19:38:50 - INFO - __main__ - train loss is 11.338999658357352\n",
      "Steps:  37%|▋ | 5604/15000 [35:28<27:55,  5.61it/s, lr=9.79e-6, step_loss=0.391]07/18/2023 19:38:50 - INFO - __main__ - train loss is 11.347220494877547\n",
      "Steps:  37%|▎| 5605/15000 [35:28<27:55,  5.61it/s, lr=9.79e-6, step_loss=0.0082207/18/2023 19:38:50 - INFO - __main__ - train loss is 11.391392603050917\n",
      "Steps:  37%|▎| 5606/15000 [35:28<27:55,  5.61it/s, lr=9.79e-6, step_loss=0.0442]07/18/2023 19:38:50 - INFO - __main__ - train loss is 11.790328576695174\n",
      "Steps:  37%|▋ | 5607/15000 [35:28<27:54,  5.61it/s, lr=9.79e-6, step_loss=0.399]07/18/2023 19:38:50 - INFO - __main__ - train loss is 11.80493003455922\n",
      "Steps:  37%|▎| 5608/15000 [35:28<27:54,  5.61it/s, lr=9.79e-6, step_loss=0.0146]07/18/2023 19:38:51 - INFO - __main__ - train loss is 11.8116958248429\n",
      "Steps:  37%|▎| 5609/15000 [35:28<27:54,  5.61it/s, lr=9.79e-6, step_loss=0.0067707/18/2023 19:38:51 - INFO - __main__ - train loss is 11.970315482001752\n",
      "Steps:  37%|▋ | 5610/15000 [35:29<27:53,  5.61it/s, lr=9.79e-6, step_loss=0.159]07/18/2023 19:38:51 - INFO - __main__ - train loss is 12.039318229537457\n",
      "Steps:  37%|▋ | 5611/15000 [35:29<27:53,  5.61it/s, lr=9.79e-6, step_loss=0.069]07/18/2023 19:38:51 - INFO - __main__ - train loss is 12.51090308604762\n",
      "Steps:  37%|▋ | 5612/15000 [35:29<27:51,  5.62it/s, lr=9.79e-6, step_loss=0.472]07/18/2023 19:38:51 - INFO - __main__ - train loss is 12.732062275987118\n",
      "Steps:  37%|▋ | 5613/15000 [35:29<27:50,  5.62it/s, lr=9.79e-6, step_loss=0.221]07/18/2023 19:38:51 - INFO - __main__ - train loss is 13.166737433057278\n",
      "Steps:  37%|▋ | 5614/15000 [35:29<27:50,  5.62it/s, lr=9.79e-6, step_loss=0.435]07/18/2023 19:38:52 - INFO - __main__ - train loss is 13.209998104255646\n",
      "Steps:  37%|▎| 5615/15000 [35:30<27:49,  5.62it/s, lr=9.79e-6, step_loss=0.0433]07/18/2023 19:38:52 - INFO - __main__ - train loss is 13.213755909353495\n",
      "Steps:  37%|▎| 5616/15000 [35:30<27:49,  5.62it/s, lr=9.79e-6, step_loss=0.0037607/18/2023 19:38:52 - INFO - __main__ - train loss is 13.267525620758533\n",
      "Steps:  37%|▎| 5617/15000 [35:30<27:49,  5.62it/s, lr=9.79e-6, step_loss=0.0538]07/18/2023 19:38:52 - INFO - __main__ - train loss is 13.714765794575214\n",
      "Steps:  37%|▋ | 5618/15000 [35:30<27:48,  5.62it/s, lr=9.79e-6, step_loss=0.447]07/18/2023 19:38:52 - INFO - __main__ - train loss is 13.726102194748819\n",
      "Steps:  37%|▎| 5619/15000 [35:30<27:48,  5.62it/s, lr=9.79e-6, step_loss=0.0113]07/18/2023 19:38:53 - INFO - __main__ - train loss is 13.732386058196425\n",
      "Steps:  37%|▎| 5620/15000 [35:30<27:51,  5.61it/s, lr=9.79e-6, step_loss=0.0062807/18/2023 19:38:53 - INFO - __main__ - train loss is 13.735560802510008\n",
      "Steps:  37%|▎| 5621/15000 [35:31<27:49,  5.62it/s, lr=9.79e-6, step_loss=0.0031707/18/2023 19:38:53 - INFO - __main__ - train loss is 14.273027686169371\n",
      "Steps:  37%|▋ | 5622/15000 [35:31<27:51,  5.61it/s, lr=9.79e-6, step_loss=0.537]07/18/2023 19:38:53 - INFO - __main__ - train loss is 14.684958545258269\n",
      "Steps:  37%|▋ | 5623/15000 [35:31<27:50,  5.61it/s, lr=9.79e-6, step_loss=0.412]07/18/2023 19:38:53 - INFO - __main__ - train loss is 14.891904098680243\n",
      "Steps:  37%|▋ | 5624/15000 [35:31<27:49,  5.62it/s, lr=9.79e-6, step_loss=0.207]07/18/2023 19:38:53 - INFO - __main__ - train loss is 15.259172899415717\n",
      "Steps:  38%|▊ | 5625/15000 [35:31<27:48,  5.62it/s, lr=9.79e-6, step_loss=0.367]07/18/2023 19:38:54 - INFO - __main__ - train loss is 15.284635491436347\n",
      "Steps:  38%|▍| 5626/15000 [35:32<36:42,  4.26it/s, lr=9.79e-6, step_loss=0.0255]07/18/2023 19:38:54 - INFO - __main__ - Per validation step average loss is 0.0024082460440695286\n",
      "07/18/2023 19:38:54 - INFO - __main__ - Cumulative validation average loss is 0.0024082460440695286\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Per validation step average loss is 0.10675075650215149\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Cumulative validation average loss is 0.10915900254622102\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Per validation step average loss is 0.001578361145220697\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Cumulative validation average loss is 0.11073736369144171\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Per validation step average loss is 0.11609168350696564\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Cumulative validation average loss is 0.22682904719840735\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Per validation step average loss is 0.27914559841156006\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Cumulative validation average loss is 0.5059746456099674\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Per validation step average loss is 0.011778772808611393\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Cumulative validation average loss is 0.5177534184185788\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Per validation step average loss is 0.16086304187774658\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Cumulative validation average loss is 0.6786164602963254\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Per validation step average loss is 0.3234066963195801\n",
      "07/18/2023 19:38:55 - INFO - __main__ - Cumulative validation average loss is 1.0020231566159055\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Per validation step average loss is 0.004089465830475092\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Cumulative validation average loss is 1.0061126224463806\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Per validation step average loss is 0.0720948651432991\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Cumulative validation average loss is 1.0782074875896797\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Per validation step average loss is 0.04811651632189751\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Cumulative validation average loss is 1.1263240039115772\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Per validation step average loss is 0.002599366009235382\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Cumulative validation average loss is 1.1289233699208125\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Average validation loss for Epoch 57 is 0.09407694749340105\n",
      "07/18/2023 19:38:56 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:39:09 - INFO - __main__ - Starting epoch 58\n",
      "07/18/2023 19:39:09 - INFO - __main__ - train loss is 0.0019614635966718197\n",
      "Steps:  38%|▍| 5627/15000 [35:47<12:40:00,  4.87s/it, lr=9.79e-6, step_loss=0.0007/18/2023 19:39:10 - INFO - __main__ - train loss is 0.005461585707962513\n",
      "Steps:  38%|▍| 5628/15000 [35:48<9:00:33,  3.46s/it, lr=9.79e-6, step_loss=0.00307/18/2023 19:39:10 - INFO - __main__ - train loss is 0.29780365247279406\n",
      "Steps:  38%|▍| 5629/15000 [35:48<6:26:59,  2.48s/it, lr=9.79e-6, step_loss=0.29207/18/2023 19:39:10 - INFO - __main__ - train loss is 0.29994852002710104\n",
      "Steps:  38%|▍| 5630/15000 [35:48<4:39:27,  1.79s/it, lr=9.79e-6, step_loss=0.00207/18/2023 19:39:10 - INFO - __main__ - train loss is 0.3996136402711272\n",
      "Steps:  38%|▍| 5631/15000 [35:48<3:23:59,  1.31s/it, lr=9.79e-6, step_loss=0.09907/18/2023 19:39:10 - INFO - __main__ - train loss is 0.41279240790754557\n",
      "Steps:  38%|▍| 5632/15000 [35:48<2:31:13,  1.03it/s, lr=9.79e-6, step_loss=0.01307/18/2023 19:39:11 - INFO - __main__ - train loss is 0.42149437963962555\n",
      "Steps:  38%|▍| 5633/15000 [35:48<1:54:15,  1.37it/s, lr=9.79e-6, step_loss=0.00807/18/2023 19:39:11 - INFO - __main__ - train loss is 0.5917423367500305\n",
      "Steps:  38%|▍| 5634/15000 [35:49<1:28:19,  1.77it/s, lr=9.79e-6, step_loss=0.17]07/18/2023 19:39:11 - INFO - __main__ - train loss is 1.3267636895179749\n",
      "Steps:  38%|▍| 5635/15000 [35:49<1:10:10,  2.22it/s, lr=9.79e-6, step_loss=0.73507/18/2023 19:39:11 - INFO - __main__ - train loss is 1.5060716569423676\n",
      "Steps:  38%|▊ | 5636/15000 [35:49<57:27,  2.72it/s, lr=9.78e-6, step_loss=0.179]07/18/2023 19:39:11 - INFO - __main__ - train loss is 1.6274529546499252\n",
      "Steps:  38%|▊ | 5637/15000 [35:49<48:33,  3.21it/s, lr=9.78e-6, step_loss=0.121]07/18/2023 19:39:11 - INFO - __main__ - train loss is 1.6294958961661905\n",
      "Steps:  38%|▍| 5638/15000 [35:49<42:19,  3.69it/s, lr=9.78e-6, step_loss=0.0020407/18/2023 19:39:12 - INFO - __main__ - train loss is 1.6351689563598484\n",
      "Steps:  38%|▍| 5639/15000 [35:50<37:58,  4.11it/s, lr=9.78e-6, step_loss=0.0056707/18/2023 19:39:12 - INFO - __main__ - train loss is 1.7655284570064396\n",
      "Steps:  38%|█▏ | 5640/15000 [35:50<34:54,  4.47it/s, lr=9.78e-6, step_loss=0.13]07/18/2023 19:39:12 - INFO - __main__ - train loss is 1.8361078219022602\n",
      "Steps:  38%|▍| 5641/15000 [35:50<32:49,  4.75it/s, lr=9.78e-6, step_loss=0.0706]07/18/2023 19:39:12 - INFO - __main__ - train loss is 2.1043894903268665\n",
      "Steps:  38%|▊ | 5642/15000 [35:50<31:18,  4.98it/s, lr=9.78e-6, step_loss=0.268]07/18/2023 19:39:12 - INFO - __main__ - train loss is 2.115237048594281\n",
      "Steps:  38%|▍| 5643/15000 [35:50<30:13,  5.16it/s, lr=9.78e-6, step_loss=0.0108]07/18/2023 19:39:13 - INFO - __main__ - train loss is 2.118634910089895\n",
      "Steps:  38%|▍| 5644/15000 [35:50<29:31,  5.28it/s, lr=9.78e-6, step_loss=0.0034]07/18/2023 19:39:13 - INFO - __main__ - train loss is 2.196931079728529\n",
      "Steps:  38%|▍| 5645/15000 [35:51<29:02,  5.37it/s, lr=9.78e-6, step_loss=0.0783]07/18/2023 19:39:13 - INFO - __main__ - train loss is 2.2356110743712634\n",
      "Steps:  38%|▍| 5646/15000 [35:51<28:43,  5.43it/s, lr=9.78e-6, step_loss=0.0387]07/18/2023 19:39:13 - INFO - __main__ - train loss is 2.2402363519649953\n",
      "Steps:  38%|▍| 5647/15000 [35:51<28:28,  5.47it/s, lr=9.78e-6, step_loss=0.0046307/18/2023 19:39:13 - INFO - __main__ - train loss is 2.6877248387318105\n",
      "Steps:  38%|▊ | 5648/15000 [35:51<28:17,  5.51it/s, lr=9.78e-6, step_loss=0.447]07/18/2023 19:39:13 - INFO - __main__ - train loss is 2.714022637112066\n",
      "Steps:  38%|▍| 5649/15000 [35:51<28:09,  5.53it/s, lr=9.78e-6, step_loss=0.0263]07/18/2023 19:39:14 - INFO - __main__ - train loss is 2.7233802198898047\n",
      "Steps:  38%|▍| 5650/15000 [35:52<28:03,  5.55it/s, lr=9.78e-6, step_loss=0.0093607/18/2023 19:39:14 - INFO - __main__ - train loss is 2.880190235329792\n",
      "Steps:  38%|▊ | 5651/15000 [35:52<28:15,  5.51it/s, lr=9.78e-6, step_loss=0.157]07/18/2023 19:39:14 - INFO - __main__ - train loss is 2.923932608915493\n",
      "Steps:  38%|▍| 5652/15000 [35:52<28:35,  5.45it/s, lr=9.78e-6, step_loss=0.0437]07/18/2023 19:39:14 - INFO - __main__ - train loss is 3.3202477663289756\n",
      "Steps:  38%|▊ | 5653/15000 [35:52<28:51,  5.40it/s, lr=9.78e-6, step_loss=0.396]07/18/2023 19:39:14 - INFO - __main__ - train loss is 3.753345128847286\n",
      "Steps:  38%|▊ | 5654/15000 [35:52<28:32,  5.46it/s, lr=9.78e-6, step_loss=0.433]07/18/2023 19:39:15 - INFO - __main__ - train loss is 3.990457799984142\n",
      "Steps:  38%|▊ | 5655/15000 [35:52<28:28,  5.47it/s, lr=9.78e-6, step_loss=0.237]07/18/2023 19:39:15 - INFO - __main__ - train loss is 4.3775641589891165\n",
      "Steps:  38%|▊ | 5656/15000 [35:53<28:31,  5.46it/s, lr=9.78e-6, step_loss=0.387]07/18/2023 19:39:15 - INFO - __main__ - train loss is 4.461217050207779\n",
      "Steps:  38%|▍| 5657/15000 [35:53<28:35,  5.45it/s, lr=9.78e-6, step_loss=0.0837]07/18/2023 19:39:15 - INFO - __main__ - train loss is 4.489486803067848\n",
      "Steps:  38%|▍| 5658/15000 [35:53<28:48,  5.41it/s, lr=9.78e-6, step_loss=0.0283]07/18/2023 19:39:15 - INFO - __main__ - train loss is 5.443893243325874\n",
      "Steps:  38%|▊ | 5659/15000 [35:53<28:36,  5.44it/s, lr=9.78e-6, step_loss=0.954]07/18/2023 19:39:15 - INFO - __main__ - train loss is 5.5042706213425845\n",
      "Steps:  38%|▍| 5660/15000 [35:53<28:22,  5.49it/s, lr=9.78e-6, step_loss=0.0604]07/18/2023 19:39:16 - INFO - __main__ - train loss is 5.540771783096716\n",
      "Steps:  38%|▍| 5661/15000 [35:54<28:13,  5.52it/s, lr=9.78e-6, step_loss=0.0365]07/18/2023 19:39:16 - INFO - __main__ - train loss is 5.704519615275785\n",
      "Steps:  38%|▊ | 5662/15000 [35:54<28:06,  5.54it/s, lr=9.78e-6, step_loss=0.164]07/18/2023 19:39:16 - INFO - __main__ - train loss is 5.779584393603727\n",
      "Steps:  38%|▍| 5663/15000 [35:54<28:01,  5.55it/s, lr=9.78e-6, step_loss=0.0751]07/18/2023 19:39:16 - INFO - __main__ - train loss is 5.812583689345047\n",
      "Steps:  38%|▊ | 5664/15000 [35:54<27:58,  5.56it/s, lr=9.78e-6, step_loss=0.033]07/18/2023 19:39:16 - INFO - __main__ - train loss is 5.941053275717422\n",
      "Steps:  38%|▊ | 5665/15000 [35:54<27:55,  5.57it/s, lr=9.78e-6, step_loss=0.128]07/18/2023 19:39:17 - INFO - __main__ - train loss is 6.0747457190882415\n",
      "Steps:  38%|▊ | 5666/15000 [35:54<27:57,  5.56it/s, lr=9.78e-6, step_loss=0.134]07/18/2023 19:39:17 - INFO - __main__ - train loss is 6.087256819708273\n",
      "Steps:  38%|▍| 5667/15000 [35:55<28:05,  5.54it/s, lr=9.78e-6, step_loss=0.0125]07/18/2023 19:39:17 - INFO - __main__ - train loss is 6.33491373131983\n",
      "Steps:  38%|▊ | 5668/15000 [35:55<28:15,  5.51it/s, lr=9.78e-6, step_loss=0.248]07/18/2023 19:39:17 - INFO - __main__ - train loss is 6.338189625646919\n",
      "Steps:  38%|▍| 5669/15000 [35:55<28:10,  5.52it/s, lr=9.78e-6, step_loss=0.0032807/18/2023 19:39:17 - INFO - __main__ - train loss is 6.351737917866558\n",
      "Steps:  38%|▍| 5670/15000 [35:55<28:02,  5.54it/s, lr=9.78e-6, step_loss=0.0135]07/18/2023 19:39:17 - INFO - __main__ - train loss is 6.476056219544262\n",
      "Steps:  38%|▊ | 5671/15000 [35:55<27:58,  5.56it/s, lr=9.78e-6, step_loss=0.124]07/18/2023 19:39:18 - INFO - __main__ - train loss is 6.505611933302134\n",
      "Steps:  38%|▍| 5672/15000 [35:56<28:11,  5.52it/s, lr=9.78e-6, step_loss=0.0296]07/18/2023 19:39:18 - INFO - __main__ - train loss is 6.511806356720626\n",
      "Steps:  38%|▍| 5673/15000 [35:56<28:16,  5.50it/s, lr=9.78e-6, step_loss=0.0061907/18/2023 19:39:18 - INFO - __main__ - train loss is 6.880743789486587\n",
      "Steps:  38%|▊ | 5674/15000 [35:56<28:05,  5.53it/s, lr=9.78e-6, step_loss=0.369]07/18/2023 19:39:18 - INFO - __main__ - train loss is 7.035294848494232\n",
      "Steps:  38%|▊ | 5675/15000 [35:56<27:58,  5.55it/s, lr=9.78e-6, step_loss=0.155]07/18/2023 19:39:18 - INFO - __main__ - train loss is 7.037204264197499\n",
      "Steps:  38%|▍| 5676/15000 [35:56<27:54,  5.57it/s, lr=9.78e-6, step_loss=0.0019107/18/2023 19:39:19 - INFO - __main__ - train loss is 7.191806165967137\n",
      "Steps:  38%|▊ | 5677/15000 [35:56<27:51,  5.58it/s, lr=9.78e-6, step_loss=0.155]07/18/2023 19:39:19 - INFO - __main__ - train loss is 7.201063567306846\n",
      "Steps:  38%|▍| 5678/15000 [35:57<27:48,  5.59it/s, lr=9.78e-6, step_loss=0.0092607/18/2023 19:39:19 - INFO - __main__ - train loss is 7.3654847531579435\n",
      "Steps:  38%|▊ | 5679/15000 [35:57<27:46,  5.59it/s, lr=9.78e-6, step_loss=0.164]07/18/2023 19:39:19 - INFO - __main__ - train loss is 7.61929772188887\n",
      "Steps:  38%|▊ | 5680/15000 [35:57<27:47,  5.59it/s, lr=9.78e-6, step_loss=0.254]07/18/2023 19:39:19 - INFO - __main__ - train loss is 7.711310075130314\n",
      "Steps:  38%|▊ | 5681/15000 [35:57<27:47,  5.59it/s, lr=9.78e-6, step_loss=0.092]07/18/2023 19:39:19 - INFO - __main__ - train loss is 7.824398787226528\n",
      "Steps:  38%|▊ | 5682/15000 [35:57<27:50,  5.58it/s, lr=9.78e-6, step_loss=0.113]07/18/2023 19:39:20 - INFO - __main__ - train loss is 7.864201833959669\n",
      "Steps:  38%|▍| 5683/15000 [35:57<28:09,  5.51it/s, lr=9.78e-6, step_loss=0.0398]07/18/2023 19:39:20 - INFO - __main__ - train loss is 8.440392365213484\n",
      "Steps:  38%|▊ | 5684/15000 [35:58<28:07,  5.52it/s, lr=9.78e-6, step_loss=0.576]07/18/2023 19:39:20 - INFO - __main__ - train loss is 8.452650878112763\n",
      "Steps:  38%|▍| 5685/15000 [35:58<28:00,  5.54it/s, lr=9.78e-6, step_loss=0.0123]07/18/2023 19:39:20 - INFO - __main__ - train loss is 8.608412626665086\n",
      "Steps:  38%|▊ | 5686/15000 [35:58<27:55,  5.56it/s, lr=9.78e-6, step_loss=0.156]07/18/2023 19:39:20 - INFO - __main__ - train loss is 8.626040793489665\n",
      "Steps:  38%|▍| 5687/15000 [35:58<27:51,  5.57it/s, lr=9.78e-6, step_loss=0.0176]07/18/2023 19:39:20 - INFO - __main__ - train loss is 8.9465819071047\n",
      "Steps:  38%|▊ | 5688/15000 [35:58<27:48,  5.58it/s, lr=9.78e-6, step_loss=0.321]07/18/2023 19:39:21 - INFO - __main__ - train loss is 8.989186457823962\n",
      "Steps:  38%|▍| 5689/15000 [35:59<27:46,  5.59it/s, lr=9.78e-6, step_loss=0.0426]07/18/2023 19:39:21 - INFO - __main__ - train loss is 9.21042825980112\n",
      "Steps:  38%|▊ | 5690/15000 [35:59<27:44,  5.59it/s, lr=9.78e-6, step_loss=0.221]07/18/2023 19:39:21 - INFO - __main__ - train loss is 9.217554758768529\n",
      "Steps:  38%|▍| 5691/15000 [35:59<27:44,  5.59it/s, lr=9.78e-6, step_loss=0.0071307/18/2023 19:39:21 - INFO - __main__ - train loss is 9.238902188371867\n",
      "Steps:  38%|▍| 5692/15000 [35:59<27:43,  5.59it/s, lr=9.78e-6, step_loss=0.0213]07/18/2023 19:39:21 - INFO - __main__ - train loss is 9.240453354315832\n",
      "Steps:  38%|▍| 5693/15000 [35:59<27:45,  5.59it/s, lr=9.78e-6, step_loss=0.0015507/18/2023 19:39:22 - INFO - __main__ - train loss is 9.252042076783255\n",
      "Steps:  38%|▍| 5694/15000 [35:59<27:47,  5.58it/s, lr=9.78e-6, step_loss=0.0116]07/18/2023 19:39:22 - INFO - __main__ - train loss is 9.361071831779554\n",
      "Steps:  38%|▊ | 5695/15000 [36:00<27:48,  5.58it/s, lr=9.78e-6, step_loss=0.109]07/18/2023 19:39:22 - INFO - __main__ - train loss is 9.47256352682598\n",
      "Steps:  38%|▊ | 5696/15000 [36:00<27:48,  5.58it/s, lr=9.78e-6, step_loss=0.111]07/18/2023 19:39:22 - INFO - __main__ - train loss is 9.848466656403616\n",
      "Steps:  38%|▊ | 5697/15000 [36:00<27:48,  5.57it/s, lr=9.78e-6, step_loss=0.376]07/18/2023 19:39:22 - INFO - __main__ - train loss is 10.19841282744892\n",
      "Steps:  38%|█▏ | 5698/15000 [36:00<27:49,  5.57it/s, lr=9.78e-6, step_loss=0.35]07/18/2023 19:39:22 - INFO - __main__ - train loss is 10.314209579722956\n",
      "Steps:  38%|▊ | 5699/15000 [36:00<27:46,  5.58it/s, lr=9.78e-6, step_loss=0.116]07/18/2023 19:39:23 - INFO - __main__ - train loss is 10.31941298325546\n",
      "Steps:  38%|▍| 5700/15000 [36:01<27:43,  5.59it/s, lr=9.78e-6, step_loss=0.0052]07/18/2023 19:39:23 - INFO - __main__ - train loss is 10.331952020758763\n",
      "Steps:  38%|▍| 5701/15000 [36:01<27:42,  5.59it/s, lr=9.78e-6, step_loss=0.0125]07/18/2023 19:39:23 - INFO - __main__ - train loss is 10.471349507803097\n",
      "Steps:  38%|▊ | 5702/15000 [36:01<27:41,  5.59it/s, lr=9.78e-6, step_loss=0.139]07/18/2023 19:39:23 - INFO - __main__ - train loss is 10.483003694796935\n",
      "Steps:  38%|▍| 5703/15000 [36:01<27:41,  5.60it/s, lr=9.78e-6, step_loss=0.0117]07/18/2023 19:39:23 - INFO - __main__ - train loss is 10.519275468075648\n",
      "Steps:  38%|▍| 5704/15000 [36:01<27:42,  5.59it/s, lr=9.78e-6, step_loss=0.0363]07/18/2023 19:39:24 - INFO - __main__ - train loss is 11.163809579098597\n",
      "Steps:  38%|▊ | 5705/15000 [36:01<27:42,  5.59it/s, lr=9.78e-6, step_loss=0.645]07/18/2023 19:39:24 - INFO - __main__ - train loss is 11.171074165264145\n",
      "Steps:  38%|▍| 5706/15000 [36:02<27:41,  5.59it/s, lr=9.78e-6, step_loss=0.0072607/18/2023 19:39:24 - INFO - __main__ - train loss is 11.311600772896782\n",
      "Steps:  38%|▊ | 5707/15000 [36:02<27:39,  5.60it/s, lr=9.78e-6, step_loss=0.141]07/18/2023 19:39:24 - INFO - __main__ - train loss is 11.320291216718033\n",
      "Steps:  38%|▍| 5708/15000 [36:02<27:38,  5.60it/s, lr=9.78e-6, step_loss=0.0086907/18/2023 19:39:24 - INFO - __main__ - train loss is 11.575709219323471\n",
      "Steps:  38%|▊ | 5709/15000 [36:02<27:37,  5.61it/s, lr=9.78e-6, step_loss=0.255]07/18/2023 19:39:24 - INFO - __main__ - train loss is 11.849942441331223\n",
      "Steps:  38%|▊ | 5710/15000 [36:02<27:36,  5.61it/s, lr=9.78e-6, step_loss=0.274]07/18/2023 19:39:25 - INFO - __main__ - train loss is 11.854829684598371\n",
      "Steps:  38%|▍| 5711/15000 [36:02<27:36,  5.61it/s, lr=9.78e-6, step_loss=0.0048907/18/2023 19:39:25 - INFO - __main__ - train loss is 11.878066421253607\n",
      "Steps:  38%|▍| 5712/15000 [36:03<27:35,  5.61it/s, lr=9.78e-6, step_loss=0.0232]07/18/2023 19:39:25 - INFO - __main__ - train loss is 11.894615105120465\n",
      "Steps:  38%|▍| 5713/15000 [36:03<27:35,  5.61it/s, lr=9.78e-6, step_loss=0.0165]07/18/2023 19:39:25 - INFO - __main__ - train loss is 11.896848350996152\n",
      "Steps:  38%|▍| 5714/15000 [36:03<27:35,  5.61it/s, lr=9.78e-6, step_loss=0.0022307/18/2023 19:39:25 - INFO - __main__ - train loss is 11.911447292426601\n",
      "Steps:  38%|▍| 5715/15000 [36:03<27:35,  5.61it/s, lr=9.78e-6, step_loss=0.0146]07/18/2023 19:39:25 - INFO - __main__ - train loss is 12.403721845010296\n",
      "Steps:  38%|▊ | 5716/15000 [36:03<27:35,  5.61it/s, lr=9.78e-6, step_loss=0.492]07/18/2023 19:39:26 - INFO - __main__ - train loss is 12.756475126603618\n",
      "Steps:  38%|▊ | 5717/15000 [36:04<27:35,  5.61it/s, lr=9.78e-6, step_loss=0.353]07/18/2023 19:39:26 - INFO - __main__ - train loss is 12.801884500542656\n",
      "Steps:  38%|▍| 5718/15000 [36:04<27:34,  5.61it/s, lr=9.78e-6, step_loss=0.0454]07/18/2023 19:39:26 - INFO - __main__ - train loss is 12.894398091593757\n",
      "Steps:  38%|▍| 5719/15000 [36:04<27:33,  5.61it/s, lr=9.78e-6, step_loss=0.0925]07/18/2023 19:39:26 - INFO - __main__ - train loss is 12.905463042901829\n",
      "Steps:  38%|▍| 5720/15000 [36:04<27:49,  5.56it/s, lr=9.78e-6, step_loss=0.0111]07/18/2023 19:39:26 - INFO - __main__ - train loss is 12.918427484342828\n",
      "Steps:  38%|▊ | 5721/15000 [36:04<27:52,  5.55it/s, lr=9.78e-6, step_loss=0.013]07/18/2023 19:39:27 - INFO - __main__ - train loss is 12.999705182621256\n",
      "Steps:  38%|▍| 5722/15000 [36:04<27:47,  5.56it/s, lr=9.78e-6, step_loss=0.0813]07/18/2023 19:39:27 - INFO - __main__ - train loss is 13.138153927633539\n",
      "Steps:  38%|▊ | 5723/15000 [36:05<36:42,  4.21it/s, lr=9.78e-6, step_loss=0.138]07/18/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.04489586502313614\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 0.04489586502313614\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.04305099695920944\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 0.08794686198234558\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.3001413345336914\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 0.388088196516037\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.03502122685313225\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 0.42310942336916924\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.6848388314247131\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 1.1079482547938824\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Per validation step average loss is 0.07861659675836563\n",
      "07/18/2023 19:39:28 - INFO - __main__ - Cumulative validation average loss is 1.186564851552248\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.10153928399085999\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 1.288104135543108\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.4933655560016632\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 1.7814696915447712\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.26811113953590393\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 2.049580831080675\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.006368323229253292\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 2.0559491543099284\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.018177568912506104\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 2.0741267232224345\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Per validation step average loss is 0.29496049880981445\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Cumulative validation average loss is 2.369087222032249\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Average validation loss for Epoch 58 is 0.19742393516935408\n",
      "07/18/2023 19:39:29 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:39:42 - INFO - __main__ - Starting epoch 59\n",
      "07/18/2023 19:39:43 - INFO - __main__ - train loss is 0.43892329931259155\n",
      "Steps:  38%|▍| 5724/15000 [36:21<12:37:26,  4.90s/it, lr=9.78e-6, step_loss=0.4307/18/2023 19:39:43 - INFO - __main__ - train loss is 0.5503359958529472\n",
      "Steps:  38%|▍| 5725/15000 [36:21<8:58:47,  3.49s/it, lr=9.78e-6, step_loss=0.11107/18/2023 19:39:43 - INFO - __main__ - train loss is 0.619490422308445\n",
      "Steps:  38%|▍| 5726/15000 [36:21<6:25:52,  2.50s/it, lr=9.78e-6, step_loss=0.06907/18/2023 19:39:43 - INFO - __main__ - train loss is 0.689461000263691\n",
      "Steps:  38%|▍| 5727/15000 [36:21<4:39:26,  1.81s/it, lr=9.78e-6, step_loss=0.07]07/18/2023 19:39:43 - INFO - __main__ - train loss is 0.8149460479617119\n",
      "Steps:  38%|▍| 5728/15000 [36:21<3:24:43,  1.32s/it, lr=9.78e-6, step_loss=0.12507/18/2023 19:39:44 - INFO - __main__ - train loss is 1.1115257069468498\n",
      "Steps:  38%|▍| 5729/15000 [36:22<2:32:25,  1.01it/s, lr=9.78e-6, step_loss=0.29707/18/2023 19:39:44 - INFO - __main__ - train loss is 1.1188985276967287\n",
      "Steps:  38%|▍| 5730/15000 [36:22<1:55:10,  1.34it/s, lr=9.78e-6, step_loss=0.00707/18/2023 19:39:44 - INFO - __main__ - train loss is 1.1216626749373972\n",
      "Steps:  38%|▍| 5731/15000 [36:22<1:29:23,  1.73it/s, lr=9.78e-6, step_loss=0.00207/18/2023 19:39:44 - INFO - __main__ - train loss is 1.1406742916442454\n",
      "Steps:  38%|▍| 5732/15000 [36:22<1:11:11,  2.17it/s, lr=9.78e-6, step_loss=0.01907/18/2023 19:39:44 - INFO - __main__ - train loss is 1.3249243781901896\n",
      "Steps:  38%|▊ | 5733/15000 [36:22<58:35,  2.64it/s, lr=9.78e-6, step_loss=0.184]07/18/2023 19:39:45 - INFO - __main__ - train loss is 1.3432310135103762\n",
      "Steps:  38%|▍| 5734/15000 [36:23<50:19,  3.07it/s, lr=9.78e-6, step_loss=0.0183]07/18/2023 19:39:45 - INFO - __main__ - train loss is 1.5545040727593005\n",
      "Steps:  38%|▊ | 5735/15000 [36:23<44:14,  3.49it/s, lr=9.78e-6, step_loss=0.211]07/18/2023 19:39:45 - INFO - __main__ - train loss is 1.6481706486083567\n",
      "Steps:  38%|▍| 5736/15000 [36:23<39:54,  3.87it/s, lr=9.78e-6, step_loss=0.0937]07/18/2023 19:39:45 - INFO - __main__ - train loss is 2.526764451060444\n",
      "Steps:  38%|▊ | 5737/15000 [36:23<36:18,  4.25it/s, lr=9.78e-6, step_loss=0.879]07/18/2023 19:39:45 - INFO - __main__ - train loss is 2.529249945189804\n",
      "Steps:  38%|▍| 5738/15000 [36:23<34:08,  4.52it/s, lr=9.78e-6, step_loss=0.0024907/18/2023 19:39:46 - INFO - __main__ - train loss is 2.6524140327237546\n",
      "Steps:  38%|▊ | 5739/15000 [36:23<32:57,  4.68it/s, lr=9.78e-6, step_loss=0.123]07/18/2023 19:39:46 - INFO - __main__ - train loss is 2.6607608585618436\n",
      "Steps:  38%|▍| 5740/15000 [36:24<32:02,  4.82it/s, lr=9.78e-6, step_loss=0.0083507/18/2023 19:39:46 - INFO - __main__ - train loss is 2.6636205315589905\n",
      "Steps:  38%|▍| 5741/15000 [36:24<31:26,  4.91it/s, lr=9.78e-6, step_loss=0.0028607/18/2023 19:39:46 - INFO - __main__ - train loss is 2.960470139980316\n",
      "Steps:  38%|▊ | 5742/15000 [36:24<31:02,  4.97it/s, lr=9.78e-6, step_loss=0.297]07/18/2023 19:39:46 - INFO - __main__ - train loss is 2.9646780570037663\n",
      "Steps:  38%|▍| 5743/15000 [36:24<30:42,  5.03it/s, lr=9.78e-6, step_loss=0.0042107/18/2023 19:39:47 - INFO - __main__ - train loss is 3.3247644384391606\n",
      "Steps:  38%|█▏ | 5744/15000 [36:24<30:29,  5.06it/s, lr=9.78e-6, step_loss=0.36]07/18/2023 19:39:47 - INFO - __main__ - train loss is 3.3273432729765773\n",
      "Steps:  38%|▍| 5745/15000 [36:25<30:18,  5.09it/s, lr=9.78e-6, step_loss=0.0025807/18/2023 19:39:47 - INFO - __main__ - train loss is 3.778113949112594\n",
      "Steps:  38%|▊ | 5746/15000 [36:25<30:07,  5.12it/s, lr=9.78e-6, step_loss=0.451]07/18/2023 19:39:47 - INFO - __main__ - train loss is 3.7850884329527617\n",
      "Steps:  38%|▍| 5747/15000 [36:25<29:57,  5.15it/s, lr=9.78e-6, step_loss=0.0069707/18/2023 19:39:47 - INFO - __main__ - train loss is 3.789291786029935\n",
      "Steps:  38%|▍| 5748/15000 [36:25<29:56,  5.15it/s, lr=9.78e-6, step_loss=0.0042]07/18/2023 19:39:48 - INFO - __main__ - train loss is 3.8039138857275248\n",
      "Steps:  38%|▍| 5749/15000 [36:25<29:13,  5.28it/s, lr=9.78e-6, step_loss=0.0146]07/18/2023 19:39:48 - INFO - __main__ - train loss is 3.8542301785200834\n",
      "Steps:  38%|▍| 5750/15000 [36:26<28:43,  5.37it/s, lr=9.78e-6, step_loss=0.0503]07/18/2023 19:39:48 - INFO - __main__ - train loss is 3.9237101953476667\n",
      "Steps:  38%|▍| 5751/15000 [36:26<28:22,  5.43it/s, lr=9.78e-6, step_loss=0.0695]07/18/2023 19:39:48 - INFO - __main__ - train loss is 3.9838912319391966\n",
      "Steps:  38%|▍| 5752/15000 [36:26<28:08,  5.48it/s, lr=9.78e-6, step_loss=0.0602]07/18/2023 19:39:48 - INFO - __main__ - train loss is 4.092625690624118\n",
      "Steps:  38%|▊ | 5753/15000 [36:26<27:58,  5.51it/s, lr=9.78e-6, step_loss=0.109]07/18/2023 19:39:48 - INFO - __main__ - train loss is 4.1193325482308865\n",
      "Steps:  38%|▍| 5754/15000 [36:26<27:50,  5.53it/s, lr=9.78e-6, step_loss=0.0267]07/18/2023 19:39:49 - INFO - __main__ - train loss is 4.27384665235877\n",
      "Steps:  38%|▊ | 5755/15000 [36:26<27:45,  5.55it/s, lr=9.78e-6, step_loss=0.155]07/18/2023 19:39:49 - INFO - __main__ - train loss is 4.461080472916365\n",
      "Steps:  38%|▊ | 5756/15000 [36:27<27:39,  5.57it/s, lr=9.78e-6, step_loss=0.187]07/18/2023 19:39:49 - INFO - __main__ - train loss is 4.610248204320669\n",
      "Steps:  38%|▊ | 5757/15000 [36:27<27:38,  5.57it/s, lr=9.78e-6, step_loss=0.149]07/18/2023 19:39:49 - INFO - __main__ - train loss is 4.741701778024435\n",
      "Steps:  38%|▊ | 5758/15000 [36:27<27:36,  5.58it/s, lr=9.78e-6, step_loss=0.131]07/18/2023 19:39:49 - INFO - __main__ - train loss is 5.064833398908377\n",
      "Steps:  38%|▊ | 5759/15000 [36:27<27:35,  5.58it/s, lr=9.78e-6, step_loss=0.323]07/18/2023 19:39:49 - INFO - __main__ - train loss is 5.149728458374739\n",
      "Steps:  38%|▍| 5760/15000 [36:27<27:33,  5.59it/s, lr=9.78e-6, step_loss=0.0849]07/18/2023 19:39:50 - INFO - __main__ - train loss is 5.556639056652784\n",
      "Steps:  38%|▊ | 5761/15000 [36:28<27:32,  5.59it/s, lr=9.78e-6, step_loss=0.407]07/18/2023 19:39:50 - INFO - __main__ - train loss is 5.638099912554026\n",
      "Steps:  38%|▍| 5762/15000 [36:28<27:31,  5.59it/s, lr=9.78e-6, step_loss=0.0815]07/18/2023 19:39:50 - INFO - __main__ - train loss is 6.103988233953714\n",
      "Steps:  38%|▊ | 5763/15000 [36:28<27:30,  5.60it/s, lr=9.78e-6, step_loss=0.466]07/18/2023 19:39:50 - INFO - __main__ - train loss is 6.237087342888117\n",
      "Steps:  38%|▊ | 5764/15000 [36:28<27:45,  5.54it/s, lr=9.78e-6, step_loss=0.133]07/18/2023 19:39:50 - INFO - __main__ - train loss is 6.3698634542524815\n",
      "Steps:  38%|▊ | 5765/15000 [36:28<27:43,  5.55it/s, lr=9.78e-6, step_loss=0.133]07/18/2023 19:39:51 - INFO - __main__ - train loss is 6.665478114038706\n",
      "Steps:  38%|▊ | 5766/15000 [36:28<27:54,  5.52it/s, lr=9.77e-6, step_loss=0.296]07/18/2023 19:39:51 - INFO - __main__ - train loss is 6.6989348493516445\n",
      "Steps:  38%|▍| 5767/15000 [36:29<27:55,  5.51it/s, lr=9.77e-6, step_loss=0.0335]07/18/2023 19:39:51 - INFO - __main__ - train loss is 6.831485133618116\n",
      "Steps:  38%|▊ | 5768/15000 [36:29<28:02,  5.49it/s, lr=9.77e-6, step_loss=0.133]07/18/2023 19:39:51 - INFO - __main__ - train loss is 7.064881917089224\n",
      "Steps:  38%|▊ | 5769/15000 [36:29<28:22,  5.42it/s, lr=9.77e-6, step_loss=0.233]07/18/2023 19:39:51 - INFO - __main__ - train loss is 7.1774031184613705\n",
      "Steps:  38%|▊ | 5770/15000 [36:29<28:13,  5.45it/s, lr=9.77e-6, step_loss=0.113]07/18/2023 19:39:51 - INFO - __main__ - train loss is 7.213346298784018\n",
      "Steps:  38%|▍| 5771/15000 [36:29<28:00,  5.49it/s, lr=9.77e-6, step_loss=0.0359]07/18/2023 19:39:52 - INFO - __main__ - train loss is 7.5824768505990505\n",
      "Steps:  38%|▊ | 5772/15000 [36:30<28:03,  5.48it/s, lr=9.77e-6, step_loss=0.369]07/18/2023 19:39:52 - INFO - __main__ - train loss is 7.737058665603399\n",
      "Steps:  38%|▊ | 5773/15000 [36:30<28:08,  5.47it/s, lr=9.77e-6, step_loss=0.155]07/18/2023 19:39:52 - INFO - __main__ - train loss is 7.956621911376715\n",
      "Steps:  38%|█▏ | 5774/15000 [36:30<28:01,  5.49it/s, lr=9.77e-6, step_loss=0.22]07/18/2023 19:39:52 - INFO - __main__ - train loss is 7.960545878857374\n",
      "Steps:  38%|▍| 5775/15000 [36:30<27:53,  5.51it/s, lr=9.77e-6, step_loss=0.0039207/18/2023 19:39:52 - INFO - __main__ - train loss is 8.034967731684446\n",
      "Steps:  39%|▍| 5776/15000 [36:30<27:48,  5.53it/s, lr=9.77e-6, step_loss=0.0744]07/18/2023 19:39:53 - INFO - __main__ - train loss is 8.038599993102252\n",
      "Steps:  39%|▍| 5777/15000 [36:30<27:41,  5.55it/s, lr=9.77e-6, step_loss=0.0036307/18/2023 19:39:53 - INFO - __main__ - train loss is 8.34450730215758\n",
      "Steps:  39%|▊ | 5778/15000 [36:31<27:50,  5.52it/s, lr=9.77e-6, step_loss=0.306]07/18/2023 19:39:53 - INFO - __main__ - train loss is 8.745364065282047\n",
      "Steps:  39%|▊ | 5779/15000 [36:31<27:42,  5.55it/s, lr=9.77e-6, step_loss=0.401]07/18/2023 19:39:53 - INFO - __main__ - train loss is 8.91891914140433\n",
      "Steps:  39%|▊ | 5780/15000 [36:31<27:50,  5.52it/s, lr=9.77e-6, step_loss=0.174]07/18/2023 19:39:53 - INFO - __main__ - train loss is 8.974685843102634\n",
      "Steps:  39%|▍| 5781/15000 [36:31<27:41,  5.55it/s, lr=9.77e-6, step_loss=0.0558]07/18/2023 19:39:53 - INFO - __main__ - train loss is 8.990602201782167\n",
      "Steps:  39%|▍| 5782/15000 [36:31<27:40,  5.55it/s, lr=9.77e-6, step_loss=0.0159]07/18/2023 19:39:54 - INFO - __main__ - train loss is 9.19367907103151\n",
      "Steps:  39%|▊ | 5783/15000 [36:32<27:51,  5.51it/s, lr=9.77e-6, step_loss=0.203]07/18/2023 19:39:54 - INFO - __main__ - train loss is 9.196406722068787\n",
      "Steps:  39%|▍| 5784/15000 [36:32<27:47,  5.53it/s, lr=9.77e-6, step_loss=0.0027307/18/2023 19:39:54 - INFO - __main__ - train loss is 9.215196872130036\n",
      "Steps:  39%|▍| 5785/15000 [36:32<27:40,  5.55it/s, lr=9.77e-6, step_loss=0.0188]07/18/2023 19:39:54 - INFO - __main__ - train loss is 9.22043443005532\n",
      "Steps:  39%|▍| 5786/15000 [36:32<27:35,  5.57it/s, lr=9.77e-6, step_loss=0.0052407/18/2023 19:39:54 - INFO - __main__ - train loss is 9.277678309939802\n",
      "Steps:  39%|▍| 5787/15000 [36:32<27:31,  5.58it/s, lr=9.77e-6, step_loss=0.0572]07/18/2023 19:39:55 - INFO - __main__ - train loss is 9.331460322253406\n",
      "Steps:  39%|▍| 5788/15000 [36:32<27:28,  5.59it/s, lr=9.77e-6, step_loss=0.0538]07/18/2023 19:39:55 - INFO - __main__ - train loss is 9.354903475381434\n",
      "Steps:  39%|▍| 5789/15000 [36:33<27:27,  5.59it/s, lr=9.77e-6, step_loss=0.0234]07/18/2023 19:39:55 - INFO - __main__ - train loss is 9.371286169625819\n",
      "Steps:  39%|▍| 5790/15000 [36:33<27:25,  5.60it/s, lr=9.77e-6, step_loss=0.0164]07/18/2023 19:39:55 - INFO - __main__ - train loss is 9.379583631642163\n",
      "Steps:  39%|▍| 5791/15000 [36:33<27:25,  5.60it/s, lr=9.77e-6, step_loss=0.0083]07/18/2023 19:39:55 - INFO - __main__ - train loss is 9.5892170118168\n",
      "Steps:  39%|█▏ | 5792/15000 [36:33<27:25,  5.60it/s, lr=9.77e-6, step_loss=0.21]07/18/2023 19:39:55 - INFO - __main__ - train loss is 10.090429251082242\n",
      "Steps:  39%|▊ | 5793/15000 [36:33<27:28,  5.59it/s, lr=9.77e-6, step_loss=0.501]07/18/2023 19:39:56 - INFO - __main__ - train loss is 10.12229970190674\n",
      "Steps:  39%|▍| 5794/15000 [36:34<27:28,  5.58it/s, lr=9.77e-6, step_loss=0.0319]07/18/2023 19:39:56 - INFO - __main__ - train loss is 10.129885036498308\n",
      "Steps:  39%|▍| 5795/15000 [36:34<27:38,  5.55it/s, lr=9.77e-6, step_loss=0.0075907/18/2023 19:39:56 - INFO - __main__ - train loss is 10.370973739773035\n",
      "Steps:  39%|▊ | 5796/15000 [36:34<27:49,  5.51it/s, lr=9.77e-6, step_loss=0.241]07/18/2023 19:39:56 - INFO - __main__ - train loss is 10.373888947069645\n",
      "Steps:  39%|▍| 5797/15000 [36:34<28:03,  5.47it/s, lr=9.77e-6, step_loss=0.0029207/18/2023 19:39:56 - INFO - __main__ - train loss is 10.432798713445663\n",
      "Steps:  39%|▍| 5798/15000 [36:34<28:04,  5.46it/s, lr=9.77e-6, step_loss=0.0589]07/18/2023 19:39:57 - INFO - __main__ - train loss is 10.442323995754123\n",
      "Steps:  39%|▍| 5799/15000 [36:34<27:52,  5.50it/s, lr=9.77e-6, step_loss=0.0095307/18/2023 19:39:57 - INFO - __main__ - train loss is 10.61485636048019\n",
      "Steps:  39%|▊ | 5800/15000 [36:35<27:43,  5.53it/s, lr=9.77e-6, step_loss=0.173]07/18/2023 19:39:57 - INFO - __main__ - train loss is 10.703721364960074\n",
      "Steps:  39%|▍| 5801/15000 [36:35<27:38,  5.55it/s, lr=9.77e-6, step_loss=0.0889]07/18/2023 19:39:57 - INFO - __main__ - train loss is 10.989173343405128\n",
      "Steps:  39%|▊ | 5802/15000 [36:35<27:34,  5.56it/s, lr=9.77e-6, step_loss=0.285]07/18/2023 19:39:57 - INFO - __main__ - train loss is 11.226492514833808\n",
      "Steps:  39%|▊ | 5803/15000 [36:35<27:45,  5.52it/s, lr=9.77e-6, step_loss=0.237]07/18/2023 19:39:57 - INFO - __main__ - train loss is 11.23407102143392\n",
      "Steps:  39%|▍| 5804/15000 [36:35<27:50,  5.51it/s, lr=9.77e-6, step_loss=0.0075807/18/2023 19:39:58 - INFO - __main__ - train loss is 11.253252686467022\n",
      "Steps:  39%|▍| 5805/15000 [36:36<27:39,  5.54it/s, lr=9.77e-6, step_loss=0.0192]07/18/2023 19:39:58 - INFO - __main__ - train loss is 11.554622502531856\n",
      "Steps:  39%|▊ | 5806/15000 [36:36<27:33,  5.56it/s, lr=9.77e-6, step_loss=0.301]07/18/2023 19:39:58 - INFO - __main__ - train loss is 11.628318415489048\n",
      "Steps:  39%|▍| 5807/15000 [36:36<27:28,  5.58it/s, lr=9.77e-6, step_loss=0.0737]07/18/2023 19:39:58 - INFO - __main__ - train loss is 11.637319802772254\n",
      "Steps:  39%|▊ | 5808/15000 [36:36<27:25,  5.58it/s, lr=9.77e-6, step_loss=0.009]07/18/2023 19:39:58 - INFO - __main__ - train loss is 12.192150353919715\n",
      "Steps:  39%|▊ | 5809/15000 [36:36<27:37,  5.54it/s, lr=9.77e-6, step_loss=0.555]07/18/2023 19:39:59 - INFO - __main__ - train loss is 12.20636693900451\n",
      "Steps:  39%|▍| 5810/15000 [36:36<27:46,  5.51it/s, lr=9.77e-6, step_loss=0.0142]07/18/2023 19:39:59 - INFO - __main__ - train loss is 12.487313193734735\n",
      "Steps:  39%|▊ | 5811/15000 [36:37<27:37,  5.54it/s, lr=9.77e-6, step_loss=0.281]07/18/2023 19:39:59 - INFO - __main__ - train loss is 12.518087872769684\n",
      "Steps:  39%|▍| 5812/15000 [36:37<27:30,  5.57it/s, lr=9.77e-6, step_loss=0.0308]07/18/2023 19:39:59 - INFO - __main__ - train loss is 13.222903916146606\n",
      "Steps:  39%|▊ | 5813/15000 [36:37<27:26,  5.58it/s, lr=9.77e-6, step_loss=0.705]07/18/2023 19:39:59 - INFO - __main__ - train loss is 13.468254694249481\n",
      "Steps:  39%|▊ | 5814/15000 [36:37<27:39,  5.54it/s, lr=9.77e-6, step_loss=0.245]07/18/2023 19:39:59 - INFO - __main__ - train loss is 13.485103157814592\n",
      "Steps:  39%|▍| 5815/15000 [36:37<27:43,  5.52it/s, lr=9.77e-6, step_loss=0.0168]07/18/2023 19:40:00 - INFO - __main__ - train loss is 14.282237557228655\n",
      "Steps:  39%|▊ | 5816/15000 [36:37<27:48,  5.50it/s, lr=9.77e-6, step_loss=0.797]07/18/2023 19:40:00 - INFO - __main__ - train loss is 14.284331228584051\n",
      "Steps:  39%|▍| 5817/15000 [36:38<27:52,  5.49it/s, lr=9.77e-6, step_loss=0.0020907/18/2023 19:40:00 - INFO - __main__ - train loss is 14.298275178298354\n",
      "Steps:  39%|▍| 5818/15000 [36:38<27:53,  5.49it/s, lr=9.77e-6, step_loss=0.0139]07/18/2023 19:40:00 - INFO - __main__ - train loss is 14.30393110588193\n",
      "Steps:  39%|▍| 5819/15000 [36:38<27:41,  5.53it/s, lr=9.77e-6, step_loss=0.0056607/18/2023 19:40:01 - INFO - __main__ - train loss is 14.581273186951876\n",
      "Steps:  39%|▊ | 5820/15000 [36:38<40:20,  3.79it/s, lr=9.77e-6, step_loss=0.277]07/18/2023 19:40:01 - INFO - __main__ - Per validation step average loss is 0.013218836858868599\n",
      "07/18/2023 19:40:01 - INFO - __main__ - Cumulative validation average loss is 0.013218836858868599\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Per validation step average loss is 0.007747180759906769\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Cumulative validation average loss is 0.020966017618775368\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Per validation step average loss is 0.28979772329330444\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Cumulative validation average loss is 0.3107637409120798\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Per validation step average loss is 0.028271835297346115\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Cumulative validation average loss is 0.3390355762094259\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Per validation step average loss is 0.3584293723106384\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Cumulative validation average loss is 0.6974649485200644\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Per validation step average loss is 0.40382012724876404\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Cumulative validation average loss is 1.1012850757688284\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Per validation step average loss is 0.4906790852546692\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Cumulative validation average loss is 1.5919641610234976\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Per validation step average loss is 0.4472125768661499\n",
      "07/18/2023 19:40:02 - INFO - __main__ - Cumulative validation average loss is 2.0391767378896475\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Per validation step average loss is 0.030619710683822632\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Cumulative validation average loss is 2.06979644857347\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Per validation step average loss is 0.1540299654006958\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Cumulative validation average loss is 2.223826413974166\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Per validation step average loss is 0.23280498385429382\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Cumulative validation average loss is 2.4566313978284597\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Per validation step average loss is 0.024415355175733566\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Cumulative validation average loss is 2.4810467530041933\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Average validation loss for Epoch 59 is 0.20675389608368278\n",
      "07/18/2023 19:40:03 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:40:16 - INFO - __main__ - Starting epoch 60\n",
      "07/18/2023 19:40:17 - INFO - __main__ - train loss is 0.34214112162590027\n",
      "Steps:  39%|▍| 5821/15000 [36:55<12:54:14,  5.06s/it, lr=9.77e-6, step_loss=0.3407/18/2023 19:40:17 - INFO - __main__ - train loss is 0.6458927094936371\n",
      "Steps:  39%|▍| 5822/15000 [36:55<9:26:42,  3.70s/it, lr=9.77e-6, step_loss=0.30407/18/2023 19:40:18 - INFO - __main__ - train loss is 0.7176144421100616\n",
      "Steps:  39%|▍| 5823/15000 [36:56<7:01:56,  2.76s/it, lr=9.77e-6, step_loss=0.07107/18/2023 19:40:18 - INFO - __main__ - train loss is 0.8525629639625549\n",
      "Steps:  39%|▍| 5824/15000 [36:56<5:20:02,  2.09s/it, lr=9.77e-6, step_loss=0.13507/18/2023 19:40:19 - INFO - __main__ - train loss is 0.8651698837056756\n",
      "Steps:  39%|▍| 5825/15000 [36:57<4:09:06,  1.63s/it, lr=9.77e-6, step_loss=0.01207/18/2023 19:40:20 - INFO - __main__ - train loss is 0.9585483381524682\n",
      "Steps:  39%|▍| 5826/15000 [36:57<3:19:05,  1.30s/it, lr=9.77e-6, step_loss=0.09307/18/2023 19:40:20 - INFO - __main__ - train loss is 1.0608905563130975\n",
      "Steps:  39%|▍| 5827/15000 [36:58<2:44:14,  1.07s/it, lr=9.77e-6, step_loss=0.10207/18/2023 19:40:21 - INFO - __main__ - train loss is 1.1333179781213403\n",
      "Steps:  39%|▍| 5828/15000 [36:59<2:19:48,  1.09it/s, lr=9.77e-6, step_loss=0.07207/18/2023 19:40:21 - INFO - __main__ - train loss is 1.1443613870069385\n",
      "Steps:  39%|▍| 5829/15000 [36:59<2:02:36,  1.25it/s, lr=9.77e-6, step_loss=0.01107/18/2023 19:40:22 - INFO - __main__ - train loss is 1.2067980719730258\n",
      "Steps:  39%|▍| 5830/15000 [37:00<1:50:41,  1.38it/s, lr=9.77e-6, step_loss=0.06207/18/2023 19:40:22 - INFO - __main__ - train loss is 1.2510736165568233\n",
      "Steps:  39%|▍| 5831/15000 [37:00<1:42:05,  1.50it/s, lr=9.77e-6, step_loss=0.04407/18/2023 19:40:23 - INFO - __main__ - train loss is 1.4043661681935191\n",
      "Steps:  39%|▍| 5832/15000 [37:01<1:36:11,  1.59it/s, lr=9.77e-6, step_loss=0.15307/18/2023 19:40:23 - INFO - __main__ - train loss is 1.4479044480249286\n",
      "Steps:  39%|▍| 5833/15000 [37:01<1:32:31,  1.65it/s, lr=9.77e-6, step_loss=0.04307/18/2023 19:40:24 - INFO - __main__ - train loss is 1.4736194079741836\n",
      "Steps:  39%|▍| 5834/15000 [37:02<1:29:47,  1.70it/s, lr=9.77e-6, step_loss=0.02507/18/2023 19:40:24 - INFO - __main__ - train loss is 1.5248150071129203\n",
      "Steps:  39%|▍| 5835/15000 [37:02<1:28:07,  1.73it/s, lr=9.77e-6, step_loss=0.05107/18/2023 19:40:25 - INFO - __main__ - train loss is 1.5574258295819163\n",
      "Steps:  39%|▍| 5836/15000 [37:03<1:26:23,  1.77it/s, lr=9.77e-6, step_loss=0.03207/18/2023 19:40:26 - INFO - __main__ - train loss is 1.6815853295847774\n",
      "Steps:  39%|▍| 5837/15000 [37:03<1:25:21,  1.79it/s, lr=9.77e-6, step_loss=0.12407/18/2023 19:40:26 - INFO - __main__ - train loss is 1.7472242219373584\n",
      "Steps:  39%|▍| 5838/15000 [37:04<1:24:29,  1.81it/s, lr=9.77e-6, step_loss=0.06507/18/2023 19:40:27 - INFO - __main__ - train loss is 1.7739162584766746\n",
      "Steps:  39%|▍| 5839/15000 [37:05<1:23:57,  1.82it/s, lr=9.77e-6, step_loss=0.02607/18/2023 19:40:27 - INFO - __main__ - train loss is 1.8738618483766913\n",
      "Steps:  39%|▍| 5840/15000 [37:05<1:23:32,  1.83it/s, lr=9.77e-6, step_loss=0.09907/18/2023 19:40:28 - INFO - __main__ - train loss is 1.8778406237252057\n",
      "Steps:  39%|▍| 5841/15000 [37:06<1:23:08,  1.84it/s, lr=9.77e-6, step_loss=0.00307/18/2023 19:40:28 - INFO - __main__ - train loss is 2.221761748660356\n",
      "Steps:  39%|▍| 5842/15000 [37:06<1:23:03,  1.84it/s, lr=9.77e-6, step_loss=0.34407/18/2023 19:40:29 - INFO - __main__ - train loss is 2.642363563645631\n",
      "Steps:  39%|▍| 5843/15000 [37:07<1:23:04,  1.84it/s, lr=9.77e-6, step_loss=0.42107/18/2023 19:40:29 - INFO - __main__ - train loss is 2.711926080752164\n",
      "Steps:  39%|▍| 5844/15000 [37:07<1:23:00,  1.84it/s, lr=9.77e-6, step_loss=0.06907/18/2023 19:40:30 - INFO - __main__ - train loss is 2.720543525647372\n",
      "Steps:  39%|▍| 5845/15000 [37:08<1:22:55,  1.84it/s, lr=9.77e-6, step_loss=0.00807/18/2023 19:40:30 - INFO - __main__ - train loss is 2.7279455037787557\n",
      "Steps:  39%|▍| 5846/15000 [37:08<1:22:47,  1.84it/s, lr=9.77e-6, step_loss=0.00707/18/2023 19:40:31 - INFO - __main__ - train loss is 2.7461432265117764\n",
      "Steps:  39%|▍| 5847/15000 [37:09<1:23:06,  1.84it/s, lr=9.77e-6, step_loss=0.01807/18/2023 19:40:32 - INFO - __main__ - train loss is 2.8593168603256345\n",
      "Steps:  39%|▍| 5848/15000 [37:09<1:25:24,  1.79it/s, lr=9.77e-6, step_loss=0.11307/18/2023 19:40:32 - INFO - __main__ - train loss is 2.889982351101935\n",
      "Steps:  39%|▍| 5849/15000 [37:10<1:29:27,  1.70it/s, lr=9.77e-6, step_loss=0.03007/18/2023 19:40:33 - INFO - __main__ - train loss is 3.1405117297545075\n",
      "Steps:  39%|▍| 5850/15000 [37:11<1:31:14,  1.67it/s, lr=9.77e-6, step_loss=0.25107/18/2023 19:40:33 - INFO - __main__ - train loss is 3.649066128768027\n",
      "Steps:  39%|▍| 5851/15000 [37:11<1:28:39,  1.72it/s, lr=9.77e-6, step_loss=0.50907/18/2023 19:40:34 - INFO - __main__ - train loss is 3.7078901724889874\n",
      "Steps:  39%|▍| 5852/15000 [37:12<1:26:59,  1.75it/s, lr=9.77e-6, step_loss=0.05807/18/2023 19:40:34 - INFO - __main__ - train loss is 3.925625224597752\n",
      "Steps:  39%|▍| 5853/15000 [37:12<1:25:56,  1.77it/s, lr=9.77e-6, step_loss=0.21807/18/2023 19:40:35 - INFO - __main__ - train loss is 4.317847569473088\n",
      "Steps:  39%|▍| 5854/15000 [37:13<1:25:07,  1.79it/s, lr=9.77e-6, step_loss=0.39207/18/2023 19:40:36 - INFO - __main__ - train loss is 4.550895621068776\n",
      "Steps:  39%|▍| 5855/15000 [37:13<1:24:21,  1.81it/s, lr=9.77e-6, step_loss=0.23307/18/2023 19:40:36 - INFO - __main__ - train loss is 4.579432344995439\n",
      "Steps:  39%|▍| 5856/15000 [37:14<1:23:55,  1.82it/s, lr=9.77e-6, step_loss=0.02807/18/2023 19:40:37 - INFO - __main__ - train loss is 4.624816334806383\n",
      "Steps:  39%|▍| 5857/15000 [37:15<1:23:35,  1.82it/s, lr=9.77e-6, step_loss=0.04507/18/2023 19:40:37 - INFO - __main__ - train loss is 4.779582074843347\n",
      "Steps:  39%|▍| 5858/15000 [37:15<1:23:01,  1.84it/s, lr=9.77e-6, step_loss=0.15507/18/2023 19:40:38 - INFO - __main__ - train loss is 4.794692919589579\n",
      "Steps:  39%|▍| 5859/15000 [37:16<1:22:50,  1.84it/s, lr=9.77e-6, step_loss=0.01507/18/2023 19:40:38 - INFO - __main__ - train loss is 4.802237508818507\n",
      "Steps:  39%|▍| 5860/15000 [37:16<1:22:42,  1.84it/s, lr=9.77e-6, step_loss=0.00707/18/2023 19:40:39 - INFO - __main__ - train loss is 4.807931962423027\n",
      "Steps:  39%|▍| 5861/15000 [37:17<1:22:55,  1.84it/s, lr=9.77e-6, step_loss=0.00507/18/2023 19:40:39 - INFO - __main__ - train loss is 5.046777966432273\n",
      "Steps:  39%|▍| 5862/15000 [37:17<1:22:47,  1.84it/s, lr=9.77e-6, step_loss=0.23907/18/2023 19:40:40 - INFO - __main__ - train loss is 5.196930783800781\n",
      "Steps:  39%|▍| 5863/15000 [37:18<1:22:53,  1.84it/s, lr=9.77e-6, step_loss=0.15]07/18/2023 19:40:40 - INFO - __main__ - train loss is 5.2845390466973186\n",
      "Steps:  39%|▍| 5864/15000 [37:18<1:22:57,  1.84it/s, lr=9.77e-6, step_loss=0.08707/18/2023 19:40:41 - INFO - __main__ - train loss is 5.2868845500051975\n",
      "Steps:  39%|▍| 5865/15000 [37:19<1:22:43,  1.84it/s, lr=9.77e-6, step_loss=0.00207/18/2023 19:40:42 - INFO - __main__ - train loss is 5.323967598378658\n",
      "Steps:  39%|▍| 5866/15000 [37:19<1:22:54,  1.84it/s, lr=9.77e-6, step_loss=0.03707/18/2023 19:40:42 - INFO - __main__ - train loss is 5.677130334079266\n",
      "Steps:  39%|▍| 5867/15000 [37:20<1:23:44,  1.82it/s, lr=9.77e-6, step_loss=0.35307/18/2023 19:40:43 - INFO - __main__ - train loss is 5.830384843051434\n",
      "Steps:  39%|▍| 5868/15000 [37:21<1:24:29,  1.80it/s, lr=9.77e-6, step_loss=0.15307/18/2023 19:40:43 - INFO - __main__ - train loss is 6.595026187598705\n",
      "Steps:  39%|▍| 5869/15000 [37:21<1:24:40,  1.80it/s, lr=9.77e-6, step_loss=0.76507/18/2023 19:40:44 - INFO - __main__ - train loss is 6.66552946716547\n",
      "Steps:  39%|▍| 5870/15000 [37:22<1:24:42,  1.80it/s, lr=9.77e-6, step_loss=0.07007/18/2023 19:40:44 - INFO - __main__ - train loss is 6.66729830019176\n",
      "Steps:  39%|▍| 5871/15000 [37:22<1:24:54,  1.79it/s, lr=9.77e-6, step_loss=0.00107/18/2023 19:40:45 - INFO - __main__ - train loss is 6.682813711464405\n",
      "Steps:  39%|▍| 5872/15000 [37:23<1:24:50,  1.79it/s, lr=9.77e-6, step_loss=0.01507/18/2023 19:40:45 - INFO - __main__ - train loss is 6.68525986908935\n",
      "Steps:  39%|▍| 5873/15000 [37:23<1:24:49,  1.79it/s, lr=9.77e-6, step_loss=0.00207/18/2023 19:40:46 - INFO - __main__ - train loss is 6.692896151682362\n",
      "Steps:  39%|▍| 5874/15000 [37:24<1:24:26,  1.80it/s, lr=9.77e-6, step_loss=0.00707/18/2023 19:40:47 - INFO - __main__ - train loss is 6.695277563063428\n",
      "Steps:  39%|▍| 5875/15000 [37:24<1:24:09,  1.81it/s, lr=9.77e-6, step_loss=0.00207/18/2023 19:40:47 - INFO - __main__ - train loss is 6.993049732176587\n",
      "Steps:  39%|▍| 5876/15000 [37:25<1:23:56,  1.81it/s, lr=9.77e-6, step_loss=0.29807/18/2023 19:40:48 - INFO - __main__ - train loss is 7.356209835736081\n",
      "Steps:  39%|▍| 5877/15000 [37:26<1:23:07,  1.83it/s, lr=9.77e-6, step_loss=0.36307/18/2023 19:40:48 - INFO - __main__ - train loss is 7.376099738059565\n",
      "Steps:  39%|▍| 5878/15000 [37:26<1:22:36,  1.84it/s, lr=9.77e-6, step_loss=0.01907/18/2023 19:40:49 - INFO - __main__ - train loss is 7.534339519916102\n",
      "Steps:  39%|▍| 5879/15000 [37:27<1:22:23,  1.85it/s, lr=9.77e-6, step_loss=0.15807/18/2023 19:40:49 - INFO - __main__ - train loss is 7.628922926960513\n",
      "Steps:  39%|▍| 5880/15000 [37:27<1:22:16,  1.85it/s, lr=9.77e-6, step_loss=0.09407/18/2023 19:40:50 - INFO - __main__ - train loss is 7.63242390519008\n",
      "Steps:  39%|▍| 5881/15000 [37:28<1:22:37,  1.84it/s, lr=9.77e-6, step_loss=0.00307/18/2023 19:40:50 - INFO - __main__ - train loss is 7.641007417347282\n",
      "Steps:  39%|▍| 5882/15000 [37:28<1:22:38,  1.84it/s, lr=9.77e-6, step_loss=0.00807/18/2023 19:40:51 - INFO - __main__ - train loss is 7.645148595795035\n",
      "Steps:  39%|▍| 5883/15000 [37:29<1:22:53,  1.83it/s, lr=9.77e-6, step_loss=0.00407/18/2023 19:40:51 - INFO - __main__ - train loss is 8.09143971465528\n",
      "Steps:  39%|▍| 5884/15000 [37:29<1:23:28,  1.82it/s, lr=9.77e-6, step_loss=0.44607/18/2023 19:40:52 - INFO - __main__ - train loss is 8.101378755643964\n",
      "Steps:  39%|▍| 5885/15000 [37:30<1:23:28,  1.82it/s, lr=9.77e-6, step_loss=0.00907/18/2023 19:40:53 - INFO - __main__ - train loss is 8.173820013180375\n",
      "Steps:  39%|▍| 5886/15000 [37:30<1:23:07,  1.83it/s, lr=9.77e-6, step_loss=0.07207/18/2023 19:40:53 - INFO - __main__ - train loss is 8.711151057854295\n",
      "Steps:  39%|▍| 5887/15000 [37:31<1:22:44,  1.84it/s, lr=9.77e-6, step_loss=0.53707/18/2023 19:40:54 - INFO - __main__ - train loss is 8.73057371005416\n",
      "Steps:  39%|▍| 5888/15000 [37:32<1:22:21,  1.84it/s, lr=9.77e-6, step_loss=0.01907/18/2023 19:40:54 - INFO - __main__ - train loss is 8.733385752886534\n",
      "Steps:  39%|▍| 5889/15000 [37:32<1:22:28,  1.84it/s, lr=9.77e-6, step_loss=0.00207/18/2023 19:40:55 - INFO - __main__ - train loss is 8.73854451160878\n",
      "Steps:  39%|▍| 5890/15000 [37:33<1:22:48,  1.83it/s, lr=9.77e-6, step_loss=0.00507/18/2023 19:40:55 - INFO - __main__ - train loss is 8.861896905116737\n",
      "Steps:  39%|▍| 5891/15000 [37:33<1:23:24,  1.82it/s, lr=9.77e-6, step_loss=0.12307/18/2023 19:40:56 - INFO - __main__ - train loss is 9.054429444484413\n",
      "Steps:  39%|▍| 5892/15000 [37:34<1:30:35,  1.68it/s, lr=9.77e-6, step_loss=0.19307/18/2023 19:40:57 - INFO - __main__ - train loss is 9.08227467443794\n",
      "Steps:  39%|▍| 5893/15000 [37:35<1:32:52,  1.63it/s, lr=9.76e-6, step_loss=0.02707/18/2023 19:40:57 - INFO - __main__ - train loss is 9.21849715616554\n",
      "Steps:  39%|▍| 5894/15000 [37:35<1:29:59,  1.69it/s, lr=9.76e-6, step_loss=0.13607/18/2023 19:40:58 - INFO - __main__ - train loss is 9.239504336379468\n",
      "Steps:  39%|▍| 5895/15000 [37:36<1:27:43,  1.73it/s, lr=9.76e-6, step_loss=0.02107/18/2023 19:40:58 - INFO - __main__ - train loss is 9.354798241518438\n",
      "Steps:  39%|▍| 5896/15000 [37:36<1:26:08,  1.76it/s, lr=9.76e-6, step_loss=0.11507/18/2023 19:40:59 - INFO - __main__ - train loss is 9.374494520016015\n",
      "Steps:  39%|▍| 5897/15000 [37:37<1:25:03,  1.78it/s, lr=9.76e-6, step_loss=0.01907/18/2023 19:40:59 - INFO - __main__ - train loss is 9.702098962850869\n",
      "Steps:  39%|▍| 5898/15000 [37:37<1:24:25,  1.80it/s, lr=9.76e-6, step_loss=0.32807/18/2023 19:41:00 - INFO - __main__ - train loss is 10.08811026532203\n",
      "Steps:  39%|▍| 5899/15000 [37:38<1:24:06,  1.80it/s, lr=9.76e-6, step_loss=0.38607/18/2023 19:41:00 - INFO - __main__ - train loss is 10.236221906729043\n",
      "Steps:  39%|▍| 5900/15000 [37:38<1:23:32,  1.82it/s, lr=9.76e-6, step_loss=0.14807/18/2023 19:41:01 - INFO - __main__ - train loss is 10.266663462854922\n",
      "Steps:  39%|▍| 5901/15000 [37:39<1:23:00,  1.83it/s, lr=9.76e-6, step_loss=0.03007/18/2023 19:41:02 - INFO - __main__ - train loss is 10.369240806438029\n",
      "Steps:  39%|▍| 5902/15000 [37:39<1:22:58,  1.83it/s, lr=9.76e-6, step_loss=0.10307/18/2023 19:41:02 - INFO - __main__ - train loss is 10.45122663769871\n",
      "Steps:  39%|▍| 5903/15000 [37:40<1:22:43,  1.83it/s, lr=9.76e-6, step_loss=0.08207/18/2023 19:41:03 - INFO - __main__ - train loss is 10.844910816289485\n",
      "Steps:  39%|▍| 5904/15000 [37:41<1:22:33,  1.84it/s, lr=9.76e-6, step_loss=0.39407/18/2023 19:41:03 - INFO - __main__ - train loss is 10.84752602595836\n",
      "Steps:  39%|▍| 5905/15000 [37:41<1:22:22,  1.84it/s, lr=9.76e-6, step_loss=0.00207/18/2023 19:41:04 - INFO - __main__ - train loss is 11.025230792351067\n",
      "Steps:  39%|▍| 5906/15000 [37:42<1:22:23,  1.84it/s, lr=9.76e-6, step_loss=0.17807/18/2023 19:41:04 - INFO - __main__ - train loss is 11.576142576523125\n",
      "Steps:  39%|▍| 5907/15000 [37:42<1:22:20,  1.84it/s, lr=9.76e-6, step_loss=0.55107/18/2023 19:41:05 - INFO - __main__ - train loss is 11.644527991302311\n",
      "Steps:  39%|▍| 5908/15000 [37:43<1:22:18,  1.84it/s, lr=9.76e-6, step_loss=0.06807/18/2023 19:41:05 - INFO - __main__ - train loss is 11.962557156570256\n",
      "Steps:  39%|▍| 5909/15000 [37:43<1:22:25,  1.84it/s, lr=9.76e-6, step_loss=0.31807/18/2023 19:41:06 - INFO - __main__ - train loss is 12.092821796424687\n",
      "Steps:  39%|▍| 5910/15000 [37:44<1:22:10,  1.84it/s, lr=9.76e-6, step_loss=0.13]07/18/2023 19:41:06 - INFO - __main__ - train loss is 12.293133174069226\n",
      "Steps:  39%|▊ | 5911/15000 [37:44<1:22:26,  1.84it/s, lr=9.76e-6, step_loss=0.2]07/18/2023 19:41:07 - INFO - __main__ - train loss is 12.445528377778828\n",
      "Steps:  39%|▍| 5912/15000 [37:45<1:22:30,  1.84it/s, lr=9.76e-6, step_loss=0.15207/18/2023 19:41:08 - INFO - __main__ - train loss is 12.525715132243931\n",
      "Steps:  39%|▍| 5913/15000 [37:45<1:22:15,  1.84it/s, lr=9.76e-6, step_loss=0.08007/18/2023 19:41:08 - INFO - __main__ - train loss is 12.556947489269078\n",
      "Steps:  39%|▍| 5914/15000 [37:46<1:22:22,  1.84it/s, lr=9.76e-6, step_loss=0.03107/18/2023 19:41:09 - INFO - __main__ - train loss is 12.570658064447343\n",
      "Steps:  39%|▍| 5915/15000 [37:46<1:22:08,  1.84it/s, lr=9.76e-6, step_loss=0.01307/18/2023 19:41:09 - INFO - __main__ - train loss is 12.652520245872438\n",
      "Steps:  39%|▍| 5916/15000 [37:47<1:21:59,  1.85it/s, lr=9.76e-6, step_loss=0.08107/18/2023 19:41:10 - INFO - __main__ - train loss is 12.655117645161226\n",
      "Steps:  39%|▍| 5917/15000 [37:48<1:36:12,  1.57it/s, lr=9.76e-6, step_loss=0.00207/18/2023 19:41:11 - INFO - __main__ - Per validation step average loss is 0.08647361397743225\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Cumulative validation average loss is 0.08647361397743225\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Per validation step average loss is 0.4893686771392822\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Cumulative validation average loss is 0.5758422911167145\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Per validation step average loss is 0.3165900707244873\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Cumulative validation average loss is 0.8924323618412018\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Per validation step average loss is 0.5320733785629272\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Cumulative validation average loss is 1.424505740404129\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Per validation step average loss is 0.0023909960873425007\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Cumulative validation average loss is 1.4268967364914715\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Per validation step average loss is 0.19559817016124725\n",
      "07/18/2023 19:41:11 - INFO - __main__ - Cumulative validation average loss is 1.6224949066527188\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Per validation step average loss is 0.2733492851257324\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Cumulative validation average loss is 1.8958441917784512\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Per validation step average loss is 0.6460393667221069\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Cumulative validation average loss is 2.541883558500558\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Per validation step average loss is 0.027227547019720078\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Cumulative validation average loss is 2.569111105520278\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Per validation step average loss is 0.1584157943725586\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Cumulative validation average loss is 2.727526899892837\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Per validation step average loss is 0.13544660806655884\n",
      "07/18/2023 19:41:12 - INFO - __main__ - Cumulative validation average loss is 2.8629735079593956\n",
      "07/18/2023 19:41:13 - INFO - __main__ - Per validation step average loss is 0.5891704559326172\n",
      "07/18/2023 19:41:13 - INFO - __main__ - Cumulative validation average loss is 3.452143963892013\n",
      "07/18/2023 19:41:13 - INFO - __main__ - Average validation loss for Epoch 60 is 0.28767866365766775\n",
      "07/18/2023 19:41:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:41:25 - INFO - __main__ - Starting epoch 61\n",
      "07/18/2023 19:41:26 - INFO - __main__ - train loss is 0.1938551962375641\n",
      "Steps:  39%|▍| 5918/15000 [38:04<13:01:12,  5.16s/it, lr=9.76e-6, step_loss=0.1907/18/2023 19:41:26 - INFO - __main__ - train loss is 0.21533671766519547\n",
      "Steps:  39%|▍| 5919/15000 [38:04<9:15:13,  3.67s/it, lr=9.76e-6, step_loss=0.02107/18/2023 19:41:26 - INFO - __main__ - train loss is 0.22909859381616116\n",
      "Steps:  39%|▍| 5920/15000 [38:04<6:36:44,  2.62s/it, lr=9.76e-6, step_loss=0.01307/18/2023 19:41:26 - INFO - __main__ - train loss is 0.2658908721059561\n",
      "Steps:  39%|▍| 5921/15000 [38:04<4:45:43,  1.89s/it, lr=9.76e-6, step_loss=0.03607/18/2023 19:41:26 - INFO - __main__ - train loss is 0.28576539270579815\n",
      "Steps:  39%|▍| 5922/15000 [38:04<3:28:10,  1.38s/it, lr=9.76e-6, step_loss=0.01907/18/2023 19:41:27 - INFO - __main__ - train loss is 0.28947236272506416\n",
      "Steps:  39%|▍| 5923/15000 [38:05<2:33:49,  1.02s/it, lr=9.76e-6, step_loss=0.00307/18/2023 19:41:27 - INFO - __main__ - train loss is 1.1165203067939728\n",
      "Steps:  39%|▍| 5924/15000 [38:05<1:55:43,  1.31it/s, lr=9.76e-6, step_loss=0.82707/18/2023 19:41:27 - INFO - __main__ - train loss is 1.2101493838708848\n",
      "Steps:  40%|▍| 5925/15000 [38:05<1:29:03,  1.70it/s, lr=9.76e-6, step_loss=0.09307/18/2023 19:41:27 - INFO - __main__ - train loss is 1.2187107808422297\n",
      "Steps:  40%|▍| 5926/15000 [38:05<1:10:21,  2.15it/s, lr=9.76e-6, step_loss=0.00807/18/2023 19:41:27 - INFO - __main__ - train loss is 1.495580793125555\n",
      "Steps:  40%|▊ | 5927/15000 [38:05<57:18,  2.64it/s, lr=9.76e-6, step_loss=0.277]07/18/2023 19:41:28 - INFO - __main__ - train loss is 1.5302646092604846\n",
      "Steps:  40%|▍| 5928/15000 [38:05<48:09,  3.14it/s, lr=9.76e-6, step_loss=0.0347]07/18/2023 19:41:28 - INFO - __main__ - train loss is 1.5339579524006695\n",
      "Steps:  40%|▍| 5929/15000 [38:06<41:44,  3.62it/s, lr=9.76e-6, step_loss=0.0036907/18/2023 19:41:28 - INFO - __main__ - train loss is 1.5353698291582987\n",
      "Steps:  40%|▍| 5930/15000 [38:06<37:18,  4.05it/s, lr=9.76e-6, step_loss=0.0014107/18/2023 19:41:28 - INFO - __main__ - train loss is 1.5480090397177264\n",
      "Steps:  40%|▍| 5931/15000 [38:06<34:12,  4.42it/s, lr=9.76e-6, step_loss=0.0126]07/18/2023 19:41:28 - INFO - __main__ - train loss is 1.5755558776436374\n",
      "Steps:  40%|▍| 5932/15000 [38:06<31:58,  4.73it/s, lr=9.76e-6, step_loss=0.0275]07/18/2023 19:41:28 - INFO - __main__ - train loss is 1.9610852765617892\n",
      "Steps:  40%|▊ | 5933/15000 [38:06<30:25,  4.97it/s, lr=9.76e-6, step_loss=0.386]07/18/2023 19:41:29 - INFO - __main__ - train loss is 1.966286595328711\n",
      "Steps:  40%|▍| 5934/15000 [38:06<29:20,  5.15it/s, lr=9.76e-6, step_loss=0.0052]07/18/2023 19:41:29 - INFO - __main__ - train loss is 1.9840591059764847\n",
      "Steps:  40%|▍| 5935/15000 [38:07<28:36,  5.28it/s, lr=9.76e-6, step_loss=0.0178]07/18/2023 19:41:29 - INFO - __main__ - train loss is 2.227693955763243\n",
      "Steps:  40%|▊ | 5936/15000 [38:07<28:08,  5.37it/s, lr=9.76e-6, step_loss=0.244]07/18/2023 19:41:29 - INFO - __main__ - train loss is 2.245007953955792\n",
      "Steps:  40%|▍| 5937/15000 [38:07<27:58,  5.40it/s, lr=9.76e-6, step_loss=0.0173]07/18/2023 19:41:29 - INFO - __main__ - train loss is 2.3264237412950024\n",
      "Steps:  40%|▍| 5938/15000 [38:07<27:49,  5.43it/s, lr=9.76e-6, step_loss=0.0814]07/18/2023 19:41:29 - INFO - __main__ - train loss is 3.139780736877583\n",
      "Steps:  40%|▊ | 5939/15000 [38:07<27:31,  5.49it/s, lr=9.76e-6, step_loss=0.813]07/18/2023 19:41:30 - INFO - __main__ - train loss is 3.766538001014851\n",
      "Steps:  40%|▊ | 5940/15000 [38:08<27:21,  5.52it/s, lr=9.76e-6, step_loss=0.627]07/18/2023 19:41:30 - INFO - __main__ - train loss is 3.9666428634664044\n",
      "Steps:  40%|█▌  | 5941/15000 [38:08<27:29,  5.49it/s, lr=9.76e-6, step_loss=0.2]07/18/2023 19:41:30 - INFO - __main__ - train loss is 4.007442648871802\n",
      "Steps:  40%|▍| 5942/15000 [38:08<27:22,  5.51it/s, lr=9.76e-6, step_loss=0.0408]07/18/2023 19:41:30 - INFO - __main__ - train loss is 4.378229673369788\n",
      "Steps:  40%|▊ | 5943/15000 [38:08<27:20,  5.52it/s, lr=9.76e-6, step_loss=0.371]07/18/2023 19:41:30 - INFO - __main__ - train loss is 4.543400655849837\n",
      "Steps:  40%|▊ | 5944/15000 [38:08<27:19,  5.52it/s, lr=9.76e-6, step_loss=0.165]07/18/2023 19:41:31 - INFO - __main__ - train loss is 4.991186241968535\n",
      "Steps:  40%|▊ | 5945/15000 [38:08<27:18,  5.53it/s, lr=9.76e-6, step_loss=0.448]07/18/2023 19:41:31 - INFO - __main__ - train loss is 5.034264359041117\n",
      "Steps:  40%|▍| 5946/15000 [38:09<27:15,  5.53it/s, lr=9.76e-6, step_loss=0.0431]07/18/2023 19:41:31 - INFO - __main__ - train loss is 5.059125916450284\n",
      "Steps:  40%|▍| 5947/15000 [38:09<27:14,  5.54it/s, lr=9.76e-6, step_loss=0.0249]07/18/2023 19:41:31 - INFO - __main__ - train loss is 5.314546571462415\n",
      "Steps:  40%|▊ | 5948/15000 [38:09<27:12,  5.55it/s, lr=9.76e-6, step_loss=0.255]07/18/2023 19:41:31 - INFO - __main__ - train loss is 5.763141856878065\n",
      "Steps:  40%|▊ | 5949/15000 [38:09<27:12,  5.54it/s, lr=9.76e-6, step_loss=0.449]07/18/2023 19:41:31 - INFO - __main__ - train loss is 5.76493375771679\n",
      "Steps:  40%|▍| 5950/15000 [38:09<27:14,  5.54it/s, lr=9.76e-6, step_loss=0.0017907/18/2023 19:41:32 - INFO - __main__ - train loss is 5.7898595372680575\n",
      "Steps:  40%|▍| 5951/15000 [38:10<27:29,  5.49it/s, lr=9.76e-6, step_loss=0.0249]07/18/2023 19:41:32 - INFO - __main__ - train loss is 5.8167110125068575\n",
      "Steps:  40%|▍| 5952/15000 [38:10<27:24,  5.50it/s, lr=9.76e-6, step_loss=0.0269]07/18/2023 19:41:32 - INFO - __main__ - train loss is 6.081960771465674\n",
      "Steps:  40%|▊ | 5953/15000 [38:10<27:23,  5.50it/s, lr=9.76e-6, step_loss=0.265]07/18/2023 19:41:32 - INFO - __main__ - train loss is 6.123388212407008\n",
      "Steps:  40%|▍| 5954/15000 [38:10<27:12,  5.54it/s, lr=9.76e-6, step_loss=0.0414]07/18/2023 19:41:32 - INFO - __main__ - train loss is 6.2001474315766245\n",
      "Steps:  40%|▍| 5955/15000 [38:10<27:05,  5.57it/s, lr=9.76e-6, step_loss=0.0768]07/18/2023 19:41:33 - INFO - __main__ - train loss is 6.7154802496079355\n",
      "Steps:  40%|▊ | 5956/15000 [38:10<27:00,  5.58it/s, lr=9.76e-6, step_loss=0.515]07/18/2023 19:41:33 - INFO - __main__ - train loss is 6.756947342539206\n",
      "Steps:  40%|▍| 5957/15000 [38:11<26:56,  5.60it/s, lr=9.76e-6, step_loss=0.0415]07/18/2023 19:41:33 - INFO - __main__ - train loss is 6.785834109643474\n",
      "Steps:  40%|▍| 5958/15000 [38:11<26:53,  5.60it/s, lr=9.76e-6, step_loss=0.0289]07/18/2023 19:41:33 - INFO - __main__ - train loss is 6.8939299716148525\n",
      "Steps:  40%|▊ | 5959/15000 [38:11<26:51,  5.61it/s, lr=9.76e-6, step_loss=0.108]07/18/2023 19:41:33 - INFO - __main__ - train loss is 7.002521267393604\n",
      "Steps:  40%|▊ | 5960/15000 [38:11<26:50,  5.61it/s, lr=9.76e-6, step_loss=0.109]07/18/2023 19:41:33 - INFO - __main__ - train loss is 7.305227866629139\n",
      "Steps:  40%|▊ | 5961/15000 [38:11<26:49,  5.62it/s, lr=9.76e-6, step_loss=0.303]07/18/2023 19:41:34 - INFO - __main__ - train loss is 7.553767716744915\n",
      "Steps:  40%|▊ | 5962/15000 [38:11<26:48,  5.62it/s, lr=9.76e-6, step_loss=0.249]07/18/2023 19:41:34 - INFO - __main__ - train loss is 7.888749217847362\n",
      "Steps:  40%|▊ | 5963/15000 [38:12<26:47,  5.62it/s, lr=9.76e-6, step_loss=0.335]07/18/2023 19:41:34 - INFO - __main__ - train loss is 7.896348760696128\n",
      "Steps:  40%|▍| 5964/15000 [38:12<26:46,  5.62it/s, lr=9.76e-6, step_loss=0.0076]07/18/2023 19:41:34 - INFO - __main__ - train loss is 7.932347686262801\n",
      "Steps:  40%|▊ | 5965/15000 [38:12<26:46,  5.62it/s, lr=9.76e-6, step_loss=0.036]07/18/2023 19:41:34 - INFO - __main__ - train loss is 8.349270166130736\n",
      "Steps:  40%|▊ | 5966/15000 [38:12<26:46,  5.62it/s, lr=9.76e-6, step_loss=0.417]07/18/2023 19:41:34 - INFO - __main__ - train loss is 8.383516275556758\n",
      "Steps:  40%|▍| 5967/15000 [38:12<27:01,  5.57it/s, lr=9.76e-6, step_loss=0.0342]07/18/2023 19:41:35 - INFO - __main__ - train loss is 8.536596023710445\n",
      "Steps:  40%|▊ | 5968/15000 [38:13<27:05,  5.56it/s, lr=9.76e-6, step_loss=0.153]07/18/2023 19:41:35 - INFO - __main__ - train loss is 9.138935291441157\n",
      "Steps:  40%|▊ | 5969/15000 [38:13<26:59,  5.58it/s, lr=9.76e-6, step_loss=0.602]07/18/2023 19:41:35 - INFO - __main__ - train loss is 9.230042600305751\n",
      "Steps:  40%|▍| 5970/15000 [38:13<26:55,  5.59it/s, lr=9.76e-6, step_loss=0.0911]07/18/2023 19:41:35 - INFO - __main__ - train loss is 9.244581380160525\n",
      "Steps:  40%|▍| 5971/15000 [38:13<26:51,  5.60it/s, lr=9.76e-6, step_loss=0.0145]07/18/2023 19:41:35 - INFO - __main__ - train loss is 9.65339691308327\n",
      "Steps:  40%|▊ | 5972/15000 [38:13<26:50,  5.61it/s, lr=9.76e-6, step_loss=0.409]07/18/2023 19:41:36 - INFO - __main__ - train loss is 9.671261632116511\n",
      "Steps:  40%|▍| 5973/15000 [38:13<26:49,  5.61it/s, lr=9.76e-6, step_loss=0.0179]07/18/2023 19:41:36 - INFO - __main__ - train loss is 9.700024415971711\n",
      "Steps:  40%|▍| 5974/15000 [38:14<26:48,  5.61it/s, lr=9.76e-6, step_loss=0.0288]07/18/2023 19:41:36 - INFO - __main__ - train loss is 9.701812725747004\n",
      "Steps:  40%|▍| 5975/15000 [38:14<26:47,  5.61it/s, lr=9.76e-6, step_loss=0.0017907/18/2023 19:41:36 - INFO - __main__ - train loss is 9.713874354260042\n",
      "Steps:  40%|▍| 5976/15000 [38:14<26:45,  5.62it/s, lr=9.76e-6, step_loss=0.0121]07/18/2023 19:41:36 - INFO - __main__ - train loss is 9.781532555120066\n",
      "Steps:  40%|▍| 5977/15000 [38:14<26:44,  5.62it/s, lr=9.76e-6, step_loss=0.0677]07/18/2023 19:41:36 - INFO - __main__ - train loss is 9.785517793381587\n",
      "Steps:  40%|▍| 5978/15000 [38:14<26:47,  5.61it/s, lr=9.76e-6, step_loss=0.0039907/18/2023 19:41:37 - INFO - __main__ - train loss is 9.855156477773562\n",
      "Steps:  40%|▍| 5979/15000 [38:15<26:46,  5.62it/s, lr=9.76e-6, step_loss=0.0696]07/18/2023 19:41:37 - INFO - __main__ - train loss is 9.862547819735482\n",
      "Steps:  40%|▍| 5980/15000 [38:15<26:45,  5.62it/s, lr=9.76e-6, step_loss=0.0073907/18/2023 19:41:37 - INFO - __main__ - train loss is 9.871545609319583\n",
      "Steps:  40%|▊ | 5981/15000 [38:15<26:46,  5.62it/s, lr=9.76e-6, step_loss=0.009]07/18/2023 19:41:37 - INFO - __main__ - train loss is 9.876728860894218\n",
      "Steps:  40%|▍| 5982/15000 [38:15<26:45,  5.62it/s, lr=9.76e-6, step_loss=0.0051807/18/2023 19:41:37 - INFO - __main__ - train loss is 9.884836037876084\n",
      "Steps:  40%|▍| 5983/15000 [38:15<26:45,  5.62it/s, lr=9.76e-6, step_loss=0.0081107/18/2023 19:41:38 - INFO - __main__ - train loss is 10.04326464724727\n",
      "Steps:  40%|▊ | 5984/15000 [38:15<26:45,  5.61it/s, lr=9.76e-6, step_loss=0.158]07/18/2023 19:41:38 - INFO - __main__ - train loss is 10.062965189339593\n",
      "Steps:  40%|▍| 5985/15000 [38:16<26:44,  5.62it/s, lr=9.76e-6, step_loss=0.0197]07/18/2023 19:41:38 - INFO - __main__ - train loss is 10.472027992131189\n",
      "Steps:  40%|▊ | 5986/15000 [38:16<26:44,  5.62it/s, lr=9.76e-6, step_loss=0.409]07/18/2023 19:41:38 - INFO - __main__ - train loss is 10.476494209608063\n",
      "Steps:  40%|▍| 5987/15000 [38:16<26:44,  5.62it/s, lr=9.76e-6, step_loss=0.0044707/18/2023 19:41:38 - INFO - __main__ - train loss is 10.568482981761917\n",
      "Steps:  40%|▊ | 5988/15000 [38:16<26:43,  5.62it/s, lr=9.76e-6, step_loss=0.092]07/18/2023 19:41:38 - INFO - __main__ - train loss is 10.597807382931933\n",
      "Steps:  40%|▍| 5989/15000 [38:16<26:43,  5.62it/s, lr=9.76e-6, step_loss=0.0293]07/18/2023 19:41:39 - INFO - __main__ - train loss is 10.874800299992785\n",
      "Steps:  40%|▊ | 5990/15000 [38:16<26:42,  5.62it/s, lr=9.76e-6, step_loss=0.277]07/18/2023 19:41:39 - INFO - __main__ - train loss is 10.998254818608984\n",
      "Steps:  40%|▊ | 5991/15000 [38:17<26:41,  5.62it/s, lr=9.76e-6, step_loss=0.123]07/18/2023 19:41:39 - INFO - __main__ - train loss is 11.23551976471208\n",
      "Steps:  40%|▊ | 5992/15000 [38:17<26:41,  5.62it/s, lr=9.76e-6, step_loss=0.237]07/18/2023 19:41:39 - INFO - __main__ - train loss is 11.384925929596648\n",
      "Steps:  40%|▊ | 5993/15000 [38:17<26:42,  5.62it/s, lr=9.76e-6, step_loss=0.149]07/18/2023 19:41:39 - INFO - __main__ - train loss is 11.78700971393846\n",
      "Steps:  40%|▊ | 5994/15000 [38:17<26:42,  5.62it/s, lr=9.76e-6, step_loss=0.402]07/18/2023 19:41:39 - INFO - __main__ - train loss is 11.790346218505874\n",
      "Steps:  40%|▍| 5995/15000 [38:17<26:42,  5.62it/s, lr=9.76e-6, step_loss=0.0033407/18/2023 19:41:40 - INFO - __main__ - train loss is 12.33076341287233\n",
      "Steps:  40%|█▏ | 5996/15000 [38:18<26:58,  5.56it/s, lr=9.76e-6, step_loss=0.54]07/18/2023 19:41:40 - INFO - __main__ - train loss is 13.020497394958511\n",
      "Steps:  40%|█▏ | 5997/15000 [38:18<27:02,  5.55it/s, lr=9.76e-6, step_loss=0.69]07/18/2023 19:41:40 - INFO - __main__ - train loss is 13.21844538883306\n",
      "Steps:  40%|▊ | 5998/15000 [38:18<26:55,  5.57it/s, lr=9.76e-6, step_loss=0.198]07/18/2023 19:41:40 - INFO - __main__ - train loss is 13.226220917655155\n",
      "Steps:  40%|▍| 5999/15000 [38:18<27:00,  5.55it/s, lr=9.76e-6, step_loss=0.0077807/18/2023 19:41:40 - INFO - __main__ - train loss is 13.244211946381256\n",
      "Steps:  40%|▍| 6000/15000 [38:18<26:55,  5.57it/s, lr=9.76e-6, step_loss=0.0077807/18/2023 19:41:40 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-6000\n",
      "07/18/2023 19:41:40 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:41:40,979] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:41:40,983] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-6000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:41:40,983] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-6000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:41:40,991] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-6000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:41:40,991] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-6000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:41:41,012] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-6000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:41:41,012] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-6000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:41:41,012] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:41:41 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-6000/pytorch_model\n",
      "07/18/2023 19:41:41 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-6000/scheduler.bin\n",
      "07/18/2023 19:41:41 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-6000/random_states_0.pkl\n",
      "07/18/2023 19:41:41 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-6000\n",
      "Steps:  40%|▊ | 6000/15000 [38:18<26:55,  5.57it/s, lr=9.76e-6, step_loss=0.018]07/18/2023 19:41:41 - INFO - __main__ - train loss is 13.247476010816172\n",
      "Steps:  40%|▍| 6001/15000 [38:18<28:29,  5.26it/s, lr=9.76e-6, step_loss=0.0032607/18/2023 19:41:41 - INFO - __main__ - train loss is 13.297234176890925\n",
      "Steps:  40%|▍| 6002/15000 [38:19<28:02,  5.35it/s, lr=9.76e-6, step_loss=0.0498]07/18/2023 19:41:41 - INFO - __main__ - train loss is 13.333169034915045\n",
      "Steps:  40%|▍| 6003/15000 [38:19<27:35,  5.43it/s, lr=9.76e-6, step_loss=0.0359]07/18/2023 19:41:41 - INFO - __main__ - train loss is 13.468297786312178\n",
      "Steps:  40%|▊ | 6004/15000 [38:19<27:18,  5.49it/s, lr=9.76e-6, step_loss=0.135]07/18/2023 19:41:41 - INFO - __main__ - train loss is 13.521233364241198\n",
      "Steps:  40%|▍| 6005/15000 [38:19<27:06,  5.53it/s, lr=9.76e-6, step_loss=0.0529]07/18/2023 19:41:41 - INFO - __main__ - train loss is 13.873948379652575\n",
      "Steps:  40%|▊ | 6006/15000 [38:19<27:06,  5.53it/s, lr=9.76e-6, step_loss=0.353]07/18/2023 19:41:42 - INFO - __main__ - train loss is 13.883589425357059\n",
      "Steps:  40%|▍| 6007/15000 [38:20<27:19,  5.49it/s, lr=9.76e-6, step_loss=0.0096407/18/2023 19:41:42 - INFO - __main__ - train loss is 13.967150100739673\n",
      "Steps:  40%|▍| 6008/15000 [38:20<27:32,  5.44it/s, lr=9.76e-6, step_loss=0.0836]07/18/2023 19:41:42 - INFO - __main__ - train loss is 13.972007513279095\n",
      "Steps:  40%|▍| 6009/15000 [38:20<27:29,  5.45it/s, lr=9.76e-6, step_loss=0.0048607/18/2023 19:41:42 - INFO - __main__ - train loss is 13.985344084212556\n",
      "Steps:  40%|▍| 6010/15000 [38:20<27:25,  5.46it/s, lr=9.76e-6, step_loss=0.0133]07/18/2023 19:41:42 - INFO - __main__ - train loss is 13.987260823138058\n",
      "Steps:  40%|▍| 6011/15000 [38:20<27:29,  5.45it/s, lr=9.76e-6, step_loss=0.0019207/18/2023 19:41:43 - INFO - __main__ - train loss is 13.991131876828149\n",
      "Steps:  40%|▍| 6012/15000 [38:20<27:28,  5.45it/s, lr=9.76e-6, step_loss=0.0038707/18/2023 19:41:43 - INFO - __main__ - train loss is 14.033070725621656\n",
      "Steps:  40%|▍| 6013/15000 [38:21<27:22,  5.47it/s, lr=9.76e-6, step_loss=0.0419]07/18/2023 19:41:43 - INFO - __main__ - train loss is 14.311571252765134\n",
      "Steps:  40%|▊ | 6014/15000 [38:21<39:18,  3.81it/s, lr=9.76e-6, step_loss=0.279]07/18/2023 19:41:44 - INFO - __main__ - Per validation step average loss is 0.09922920912504196\n",
      "07/18/2023 19:41:44 - INFO - __main__ - Cumulative validation average loss is 0.09922920912504196\n",
      "07/18/2023 19:41:44 - INFO - __main__ - Per validation step average loss is 0.05243176594376564\n",
      "07/18/2023 19:41:44 - INFO - __main__ - Cumulative validation average loss is 0.1516609750688076\n",
      "07/18/2023 19:41:44 - INFO - __main__ - Per validation step average loss is 0.003933695610612631\n",
      "07/18/2023 19:41:44 - INFO - __main__ - Cumulative validation average loss is 0.15559467067942023\n",
      "07/18/2023 19:41:44 - INFO - __main__ - Per validation step average loss is 0.20435422658920288\n",
      "07/18/2023 19:41:44 - INFO - __main__ - Cumulative validation average loss is 0.3599488972686231\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.5157763957977295\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 0.8757252930663526\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.0017961736302822828\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 0.8775214666966349\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.012176627293229103\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 0.889698093989864\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.3642019033432007\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 1.2538999973330647\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.1851787269115448\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 1.4390787242446095\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.027242153882980347\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 1.4663208781275898\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Per validation step average loss is 0.07828226685523987\n",
      "07/18/2023 19:41:45 - INFO - __main__ - Cumulative validation average loss is 1.5446031449828297\n",
      "07/18/2023 19:41:46 - INFO - __main__ - Per validation step average loss is 0.018112242221832275\n",
      "07/18/2023 19:41:46 - INFO - __main__ - Cumulative validation average loss is 1.562715387204662\n",
      "07/18/2023 19:41:46 - INFO - __main__ - Average validation loss for Epoch 61 is 0.13022628226705515\n",
      "07/18/2023 19:41:46 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:41:59 - INFO - __main__ - Starting epoch 62\n",
      "07/18/2023 19:41:59 - INFO - __main__ - train loss is 0.012774933129549026\n",
      "Steps:  40%|▍| 6015/15000 [38:37<12:21:12,  4.95s/it, lr=9.76e-6, step_loss=0.0107/18/2023 19:41:59 - INFO - __main__ - train loss is 0.05842123553156853\n",
      "Steps:  40%|▍| 6016/15000 [38:37<8:46:48,  3.52s/it, lr=9.76e-6, step_loss=0.04507/18/2023 19:41:59 - INFO - __main__ - train loss is 0.08051588945090771\n",
      "Steps:  40%|▍| 6017/15000 [38:37<6:16:47,  2.52s/it, lr=9.76e-6, step_loss=0.02207/18/2023 19:42:00 - INFO - __main__ - train loss is 0.126990532502532\n",
      "Steps:  40%|▍| 6018/15000 [38:38<4:31:42,  1.82s/it, lr=9.75e-6, step_loss=0.04607/18/2023 19:42:00 - INFO - __main__ - train loss is 0.13150059524923563\n",
      "Steps:  40%|▍| 6019/15000 [38:38<3:18:11,  1.32s/it, lr=9.75e-6, step_loss=0.00407/18/2023 19:42:00 - INFO - __main__ - train loss is 0.14250266831368208\n",
      "Steps:  40%|▍| 6020/15000 [38:38<2:26:53,  1.02it/s, lr=9.75e-6, step_loss=0.01107/18/2023 19:42:00 - INFO - __main__ - train loss is 0.1451442048419267\n",
      "Steps:  40%|▍| 6021/15000 [38:38<1:50:49,  1.35it/s, lr=9.75e-6, step_loss=0.00207/18/2023 19:42:00 - INFO - __main__ - train loss is 0.267980593489483\n",
      "Steps:  40%|▍| 6022/15000 [38:38<1:25:33,  1.75it/s, lr=9.75e-6, step_loss=0.12307/18/2023 19:42:01 - INFO - __main__ - train loss is 0.27588490885682404\n",
      "Steps:  40%|▍| 6023/15000 [38:38<1:08:03,  2.20it/s, lr=9.75e-6, step_loss=0.00707/18/2023 19:42:01 - INFO - __main__ - train loss is 0.8185871068853885\n",
      "Steps:  40%|▊ | 6024/15000 [38:39<55:52,  2.68it/s, lr=9.75e-6, step_loss=0.543]07/18/2023 19:42:01 - INFO - __main__ - train loss is 0.8230732295196503\n",
      "Steps:  40%|▍| 6025/15000 [38:39<47:11,  3.17it/s, lr=9.75e-6, step_loss=0.0044907/18/2023 19:42:01 - INFO - __main__ - train loss is 0.8707867327611893\n",
      "Steps:  40%|▍| 6026/15000 [38:39<41:10,  3.63it/s, lr=9.75e-6, step_loss=0.0477]07/18/2023 19:42:01 - INFO - __main__ - train loss is 1.1974512997549027\n",
      "Steps:  40%|▊ | 6027/15000 [38:39<36:48,  4.06it/s, lr=9.75e-6, step_loss=0.327]07/18/2023 19:42:01 - INFO - __main__ - train loss is 1.4632886711042374\n",
      "Steps:  40%|▊ | 6028/15000 [38:39<33:46,  4.43it/s, lr=9.75e-6, step_loss=0.266]07/18/2023 19:42:02 - INFO - __main__ - train loss is 1.5307684305589646\n",
      "Steps:  40%|▍| 6029/15000 [38:40<31:52,  4.69it/s, lr=9.75e-6, step_loss=0.0675]07/18/2023 19:42:02 - INFO - __main__ - train loss is 1.878357148496434\n",
      "Steps:  40%|▊ | 6030/15000 [38:40<30:30,  4.90it/s, lr=9.75e-6, step_loss=0.348]07/18/2023 19:42:02 - INFO - __main__ - train loss is 2.1197438600938767\n",
      "Steps:  40%|▊ | 6031/15000 [38:40<29:19,  5.10it/s, lr=9.75e-6, step_loss=0.241]07/18/2023 19:42:02 - INFO - __main__ - train loss is 2.141953161684796\n",
      "Steps:  40%|▍| 6032/15000 [38:40<28:47,  5.19it/s, lr=9.75e-6, step_loss=0.0222]07/18/2023 19:42:02 - INFO - __main__ - train loss is 2.3928673479240388\n",
      "Steps:  40%|▊ | 6033/15000 [38:40<28:14,  5.29it/s, lr=9.75e-6, step_loss=0.251]07/18/2023 19:42:03 - INFO - __main__ - train loss is 2.758148721186444\n",
      "Steps:  40%|▊ | 6034/15000 [38:40<27:46,  5.38it/s, lr=9.75e-6, step_loss=0.365]07/18/2023 19:42:03 - INFO - __main__ - train loss is 2.760772213106975\n",
      "Steps:  40%|▍| 6035/15000 [38:41<27:27,  5.44it/s, lr=9.75e-6, step_loss=0.0026207/18/2023 19:42:03 - INFO - __main__ - train loss is 2.777459738543257\n",
      "Steps:  40%|▍| 6036/15000 [38:41<27:13,  5.49it/s, lr=9.75e-6, step_loss=0.0167]07/18/2023 19:42:03 - INFO - __main__ - train loss is 2.8233169780578464\n",
      "Steps:  40%|▍| 6037/15000 [38:41<27:02,  5.52it/s, lr=9.75e-6, step_loss=0.0459]07/18/2023 19:42:03 - INFO - __main__ - train loss is 3.0001538859214634\n",
      "Steps:  40%|▊ | 6038/15000 [38:41<26:55,  5.55it/s, lr=9.75e-6, step_loss=0.177]07/18/2023 19:42:03 - INFO - __main__ - train loss is 3.0251223703380674\n",
      "Steps:  40%|▊ | 6039/15000 [38:41<26:50,  5.56it/s, lr=9.75e-6, step_loss=0.025]07/18/2023 19:42:04 - INFO - __main__ - train loss is 3.032956604612991\n",
      "Steps:  40%|▍| 6040/15000 [38:42<26:46,  5.58it/s, lr=9.75e-6, step_loss=0.0078307/18/2023 19:42:04 - INFO - __main__ - train loss is 3.158905182732269\n",
      "Steps:  40%|▊ | 6041/15000 [38:42<26:44,  5.58it/s, lr=9.75e-6, step_loss=0.126]07/18/2023 19:42:04 - INFO - __main__ - train loss is 3.7396707877051085\n",
      "Steps:  40%|▊ | 6042/15000 [38:42<26:43,  5.59it/s, lr=9.75e-6, step_loss=0.581]07/18/2023 19:42:04 - INFO - __main__ - train loss is 3.8257751285564154\n",
      "Steps:  40%|▍| 6043/15000 [38:42<26:42,  5.59it/s, lr=9.75e-6, step_loss=0.0861]07/18/2023 19:42:04 - INFO - __main__ - train loss is 3.8435976549517363\n",
      "Steps:  40%|▍| 6044/15000 [38:42<26:40,  5.59it/s, lr=9.75e-6, step_loss=0.0178]07/18/2023 19:42:05 - INFO - __main__ - train loss is 3.850127122597769\n",
      "Steps:  40%|▍| 6045/15000 [38:42<26:40,  5.60it/s, lr=9.75e-6, step_loss=0.0065307/18/2023 19:42:05 - INFO - __main__ - train loss is 3.85596588277258\n",
      "Steps:  40%|▍| 6046/15000 [38:43<26:38,  5.60it/s, lr=9.75e-6, step_loss=0.0058407/18/2023 19:42:05 - INFO - __main__ - train loss is 3.8777832130435854\n",
      "Steps:  40%|▍| 6047/15000 [38:43<26:38,  5.60it/s, lr=9.75e-6, step_loss=0.0218]07/18/2023 19:42:05 - INFO - __main__ - train loss is 3.8808549938257784\n",
      "Steps:  40%|▍| 6048/15000 [38:43<26:38,  5.60it/s, lr=9.75e-6, step_loss=0.0030707/18/2023 19:42:05 - INFO - __main__ - train loss is 3.8840889239218086\n",
      "Steps:  40%|▍| 6049/15000 [38:43<26:38,  5.60it/s, lr=9.75e-6, step_loss=0.0032307/18/2023 19:42:05 - INFO - __main__ - train loss is 3.886978092137724\n",
      "Steps:  40%|▍| 6050/15000 [38:43<26:39,  5.60it/s, lr=9.75e-6, step_loss=0.0028907/18/2023 19:42:06 - INFO - __main__ - train loss is 3.900304710958153\n",
      "Steps:  40%|▍| 6051/15000 [38:43<26:37,  5.60it/s, lr=9.75e-6, step_loss=0.0133]07/18/2023 19:42:06 - INFO - __main__ - train loss is 3.9351249993778765\n",
      "Steps:  40%|▍| 6052/15000 [38:44<26:37,  5.60it/s, lr=9.75e-6, step_loss=0.0348]07/18/2023 19:42:06 - INFO - __main__ - train loss is 4.0120626599527895\n",
      "Steps:  40%|▍| 6053/15000 [38:44<26:38,  5.60it/s, lr=9.75e-6, step_loss=0.0769]07/18/2023 19:42:06 - INFO - __main__ - train loss is 4.3245476693846285\n",
      "Steps:  40%|▊ | 6054/15000 [38:44<26:38,  5.60it/s, lr=9.75e-6, step_loss=0.312]07/18/2023 19:42:06 - INFO - __main__ - train loss is 4.326390183065087\n",
      "Steps:  40%|▍| 6055/15000 [38:44<26:39,  5.59it/s, lr=9.75e-6, step_loss=0.0018407/18/2023 19:42:06 - INFO - __main__ - train loss is 4.436533025000244\n",
      "Steps:  40%|█▏ | 6056/15000 [38:44<26:39,  5.59it/s, lr=9.75e-6, step_loss=0.11]07/18/2023 19:42:07 - INFO - __main__ - train loss is 4.667321986053139\n",
      "Steps:  40%|▊ | 6057/15000 [38:45<26:39,  5.59it/s, lr=9.75e-6, step_loss=0.231]07/18/2023 19:42:07 - INFO - __main__ - train loss is 4.674667790066451\n",
      "Steps:  40%|▍| 6058/15000 [38:45<26:38,  5.59it/s, lr=9.75e-6, step_loss=0.0073507/18/2023 19:42:07 - INFO - __main__ - train loss is 5.0761749292723835\n",
      "Steps:  40%|▊ | 6059/15000 [38:45<26:37,  5.60it/s, lr=9.75e-6, step_loss=0.402]07/18/2023 19:42:07 - INFO - __main__ - train loss is 5.122376732062548\n",
      "Steps:  40%|▍| 6060/15000 [38:45<26:36,  5.60it/s, lr=9.75e-6, step_loss=0.0462]07/18/2023 19:42:07 - INFO - __main__ - train loss is 5.156499746721238\n",
      "Steps:  40%|▍| 6061/15000 [38:45<26:34,  5.60it/s, lr=9.75e-6, step_loss=0.0341]07/18/2023 19:42:08 - INFO - __main__ - train loss is 5.553377095144242\n",
      "Steps:  40%|▊ | 6062/15000 [38:45<26:34,  5.61it/s, lr=9.75e-6, step_loss=0.397]07/18/2023 19:42:08 - INFO - __main__ - train loss is 5.930573407094926\n",
      "Steps:  40%|▊ | 6063/15000 [38:46<26:35,  5.60it/s, lr=9.75e-6, step_loss=0.377]07/18/2023 19:42:08 - INFO - __main__ - train loss is 6.0699508669786155\n",
      "Steps:  40%|▊ | 6064/15000 [38:46<26:36,  5.60it/s, lr=9.75e-6, step_loss=0.139]07/18/2023 19:42:08 - INFO - __main__ - train loss is 6.116181220393628\n",
      "Steps:  40%|▍| 6065/15000 [38:46<26:35,  5.60it/s, lr=9.75e-6, step_loss=0.0462]07/18/2023 19:42:08 - INFO - __main__ - train loss is 6.248007233720273\n",
      "Steps:  40%|▊ | 6066/15000 [38:46<26:34,  5.60it/s, lr=9.75e-6, step_loss=0.132]07/18/2023 19:42:08 - INFO - __main__ - train loss is 6.27308516157791\n",
      "Steps:  40%|▍| 6067/15000 [38:46<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.0251]07/18/2023 19:42:09 - INFO - __main__ - train loss is 6.514625682961196\n",
      "Steps:  40%|▊ | 6068/15000 [38:47<26:34,  5.60it/s, lr=9.75e-6, step_loss=0.242]07/18/2023 19:42:09 - INFO - __main__ - train loss is 6.534774880390614\n",
      "Steps:  40%|▍| 6069/15000 [38:47<26:34,  5.60it/s, lr=9.75e-6, step_loss=0.0201]07/18/2023 19:42:09 - INFO - __main__ - train loss is 6.536749497288838\n",
      "Steps:  40%|▍| 6070/15000 [38:47<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.0019707/18/2023 19:42:09 - INFO - __main__ - train loss is 6.571120694512501\n",
      "Steps:  40%|▍| 6071/15000 [38:47<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.0344]07/18/2023 19:42:09 - INFO - __main__ - train loss is 6.573457741178572\n",
      "Steps:  40%|▍| 6072/15000 [38:47<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.0023407/18/2023 19:42:10 - INFO - __main__ - train loss is 6.760464199818671\n",
      "Steps:  40%|▊ | 6073/15000 [38:47<26:34,  5.60it/s, lr=9.75e-6, step_loss=0.187]07/18/2023 19:42:10 - INFO - __main__ - train loss is 6.875992619432509\n",
      "Steps:  40%|▊ | 6074/15000 [38:48<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.116]07/18/2023 19:42:10 - INFO - __main__ - train loss is 7.05396727565676\n",
      "Steps:  40%|▊ | 6075/15000 [38:48<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.178]07/18/2023 19:42:10 - INFO - __main__ - train loss is 7.1801770413294435\n",
      "Steps:  41%|▊ | 6076/15000 [38:48<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.126]07/18/2023 19:42:10 - INFO - __main__ - train loss is 7.182944216532633\n",
      "Steps:  41%|▍| 6077/15000 [38:48<26:32,  5.60it/s, lr=9.75e-6, step_loss=0.0027707/18/2023 19:42:10 - INFO - __main__ - train loss is 7.503222145838663\n",
      "Steps:  41%|█▏ | 6078/15000 [38:48<26:34,  5.60it/s, lr=9.75e-6, step_loss=0.32]07/18/2023 19:42:11 - INFO - __main__ - train loss is 7.507667681900784\n",
      "Steps:  41%|▍| 6079/15000 [38:48<26:34,  5.59it/s, lr=9.75e-6, step_loss=0.0044507/18/2023 19:42:11 - INFO - __main__ - train loss is 7.839358350960538\n",
      "Steps:  41%|▊ | 6080/15000 [38:49<26:33,  5.60it/s, lr=9.75e-6, step_loss=0.332]07/18/2023 19:42:11 - INFO - __main__ - train loss is 7.878181210486218\n",
      "Steps:  41%|▍| 6081/15000 [38:49<26:32,  5.60it/s, lr=9.75e-6, step_loss=0.0388]07/18/2023 19:42:11 - INFO - __main__ - train loss is 8.203076175181195\n",
      "Steps:  41%|▊ | 6082/15000 [38:49<26:32,  5.60it/s, lr=9.75e-6, step_loss=0.325]07/18/2023 19:42:11 - INFO - __main__ - train loss is 8.699247292010114\n",
      "Steps:  41%|▊ | 6083/15000 [38:49<26:32,  5.60it/s, lr=9.75e-6, step_loss=0.496]07/18/2023 19:42:11 - INFO - __main__ - train loss is 8.744455746142194\n",
      "Steps:  41%|▍| 6084/15000 [38:49<26:31,  5.60it/s, lr=9.75e-6, step_loss=0.0452]07/18/2023 19:42:12 - INFO - __main__ - train loss is 9.403258732287213\n",
      "Steps:  41%|▊ | 6085/15000 [38:50<26:31,  5.60it/s, lr=9.75e-6, step_loss=0.659]07/18/2023 19:42:12 - INFO - __main__ - train loss is 9.659429899184033\n",
      "Steps:  41%|▊ | 6086/15000 [38:50<26:31,  5.60it/s, lr=9.75e-6, step_loss=0.256]07/18/2023 19:42:12 - INFO - __main__ - train loss is 9.74888443085365\n",
      "Steps:  41%|▍| 6087/15000 [38:50<26:31,  5.60it/s, lr=9.75e-6, step_loss=0.0895]07/18/2023 19:42:12 - INFO - __main__ - train loss is 9.771677278680727\n",
      "Steps:  41%|▍| 6088/15000 [38:50<26:31,  5.60it/s, lr=9.75e-6, step_loss=0.0228]07/18/2023 19:42:12 - INFO - __main__ - train loss is 9.783124787500128\n",
      "Steps:  41%|▍| 6089/15000 [38:50<26:31,  5.60it/s, lr=9.75e-6, step_loss=0.0114]07/18/2023 19:42:13 - INFO - __main__ - train loss is 9.821422969689593\n",
      "Steps:  41%|▍| 6090/15000 [38:50<26:35,  5.58it/s, lr=9.75e-6, step_loss=0.0383]07/18/2023 19:42:13 - INFO - __main__ - train loss is 9.8482958690729\n",
      "Steps:  41%|▍| 6091/15000 [38:51<26:34,  5.59it/s, lr=9.75e-6, step_loss=0.0269]07/18/2023 19:42:13 - INFO - __main__ - train loss is 10.103899242123589\n",
      "Steps:  41%|▊ | 6092/15000 [38:51<26:33,  5.59it/s, lr=9.75e-6, step_loss=0.256]07/18/2023 19:42:13 - INFO - __main__ - train loss is 10.259414778789505\n",
      "Steps:  41%|▊ | 6093/15000 [38:51<26:32,  5.59it/s, lr=9.75e-6, step_loss=0.156]07/18/2023 19:42:13 - INFO - __main__ - train loss is 10.265698169125244\n",
      "Steps:  41%|▍| 6094/15000 [38:51<26:31,  5.60it/s, lr=9.75e-6, step_loss=0.0062807/18/2023 19:42:13 - INFO - __main__ - train loss is 10.270529419882223\n",
      "Steps:  41%|▍| 6095/15000 [38:51<26:31,  5.59it/s, lr=9.75e-6, step_loss=0.0048307/18/2023 19:42:14 - INFO - __main__ - train loss is 10.48213890264742\n",
      "Steps:  41%|▊ | 6096/15000 [38:52<26:28,  5.60it/s, lr=9.75e-6, step_loss=0.212]07/18/2023 19:42:14 - INFO - __main__ - train loss is 10.486177682643756\n",
      "Steps:  41%|▍| 6097/15000 [38:52<26:27,  5.61it/s, lr=9.75e-6, step_loss=0.0040407/18/2023 19:42:14 - INFO - __main__ - train loss is 10.494094188092276\n",
      "Steps:  41%|▍| 6098/15000 [38:52<26:26,  5.61it/s, lr=9.75e-6, step_loss=0.0079207/18/2023 19:42:14 - INFO - __main__ - train loss is 10.526147345779464\n",
      "Steps:  41%|▍| 6099/15000 [38:52<26:25,  5.62it/s, lr=9.75e-6, step_loss=0.0321]07/18/2023 19:42:14 - INFO - __main__ - train loss is 10.734696457860991\n",
      "Steps:  41%|▊ | 6100/15000 [38:52<26:24,  5.62it/s, lr=9.75e-6, step_loss=0.209]07/18/2023 19:42:15 - INFO - __main__ - train loss is 11.357098529813811\n",
      "Steps:  41%|▊ | 6101/15000 [38:52<26:24,  5.62it/s, lr=9.75e-6, step_loss=0.622]07/18/2023 19:42:15 - INFO - __main__ - train loss is 11.681669513462111\n",
      "Steps:  41%|▊ | 6102/15000 [38:53<26:23,  5.62it/s, lr=9.75e-6, step_loss=0.325]07/18/2023 19:42:15 - INFO - __main__ - train loss is 11.882048870204017\n",
      "Steps:  41%|█▋  | 6103/15000 [38:53<26:25,  5.61it/s, lr=9.75e-6, step_loss=0.2]07/18/2023 19:42:15 - INFO - __main__ - train loss is 11.895794306648895\n",
      "Steps:  41%|▍| 6104/15000 [38:53<26:25,  5.61it/s, lr=9.75e-6, step_loss=0.0137]07/18/2023 19:42:15 - INFO - __main__ - train loss is 12.292497460497543\n",
      "Steps:  41%|▊ | 6105/15000 [38:53<26:26,  5.61it/s, lr=9.75e-6, step_loss=0.397]07/18/2023 19:42:15 - INFO - __main__ - train loss is 12.333736297441646\n",
      "Steps:  41%|▍| 6106/15000 [38:53<26:25,  5.61it/s, lr=9.75e-6, step_loss=0.0412]07/18/2023 19:42:16 - INFO - __main__ - train loss is 12.77830168302171\n",
      "Steps:  41%|▊ | 6107/15000 [38:53<26:25,  5.61it/s, lr=9.75e-6, step_loss=0.445]07/18/2023 19:42:16 - INFO - __main__ - train loss is 12.78092679916881\n",
      "Steps:  41%|▍| 6108/15000 [38:54<26:25,  5.61it/s, lr=9.75e-6, step_loss=0.0026307/18/2023 19:42:16 - INFO - __main__ - train loss is 12.788220492890105\n",
      "Steps:  41%|▍| 6109/15000 [38:54<26:25,  5.61it/s, lr=9.75e-6, step_loss=0.0072907/18/2023 19:42:16 - INFO - __main__ - train loss is 12.88886415748857\n",
      "Steps:  41%|▊ | 6110/15000 [38:54<26:26,  5.60it/s, lr=9.75e-6, step_loss=0.101]07/18/2023 19:42:17 - INFO - __main__ - train loss is 12.955144239356741\n",
      "Steps:  41%|▍| 6111/15000 [38:54<37:07,  3.99it/s, lr=9.75e-6, step_loss=0.0663]07/18/2023 19:42:17 - INFO - __main__ - Per validation step average loss is 0.4437607526779175\n",
      "07/18/2023 19:42:17 - INFO - __main__ - Cumulative validation average loss is 0.4437607526779175\n",
      "07/18/2023 19:42:17 - INFO - __main__ - Per validation step average loss is 0.38800907135009766\n",
      "07/18/2023 19:42:17 - INFO - __main__ - Cumulative validation average loss is 0.8317698240280151\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Per validation step average loss is 0.03922282159328461\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Cumulative validation average loss is 0.8709926456212997\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Per validation step average loss is 0.014668930321931839\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Cumulative validation average loss is 0.8856615759432316\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Per validation step average loss is 0.40707725286483765\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Cumulative validation average loss is 1.2927388288080692\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Per validation step average loss is 0.00716808158904314\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Cumulative validation average loss is 1.2999069103971124\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Per validation step average loss is 0.9419068098068237\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Cumulative validation average loss is 2.241813720203936\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Per validation step average loss is 0.0041367788799107075\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Cumulative validation average loss is 2.245950499083847\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Per validation step average loss is 0.005786675028502941\n",
      "07/18/2023 19:42:18 - INFO - __main__ - Cumulative validation average loss is 2.2517371741123497\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Per validation step average loss is 0.06724026799201965\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Cumulative validation average loss is 2.3189774421043694\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Per validation step average loss is 0.17626136541366577\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Cumulative validation average loss is 2.495238807518035\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Per validation step average loss is 0.01468193344771862\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Cumulative validation average loss is 2.509920740965754\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Average validation loss for Epoch 62 is 0.20916006174714616\n",
      "07/18/2023 19:42:19 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:42:32 - INFO - __main__ - Starting epoch 63\n",
      "07/18/2023 19:42:32 - INFO - __main__ - train loss is 0.5623879432678223\n",
      "Steps:  41%|▍| 6112/15000 [39:10<12:04:13,  4.89s/it, lr=9.75e-6, step_loss=0.5607/18/2023 19:42:32 - INFO - __main__ - train loss is 0.5762192476540804\n",
      "Steps:  41%|▍| 6113/15000 [39:10<8:34:54,  3.48s/it, lr=9.75e-6, step_loss=0.01307/18/2023 19:42:33 - INFO - __main__ - train loss is 0.703874783590436\n",
      "Steps:  41%|▍| 6114/15000 [39:10<6:08:24,  2.49s/it, lr=9.75e-6, step_loss=0.12807/18/2023 19:42:33 - INFO - __main__ - train loss is 1.2213981915265322\n",
      "Steps:  41%|▍| 6115/15000 [39:11<4:25:47,  1.79s/it, lr=9.75e-6, step_loss=0.51807/18/2023 19:42:33 - INFO - __main__ - train loss is 1.2917463351041079\n",
      "Steps:  41%|▍| 6116/15000 [39:11<3:13:56,  1.31s/it, lr=9.75e-6, step_loss=0.07007/18/2023 19:42:33 - INFO - __main__ - train loss is 1.2960849637165666\n",
      "Steps:  41%|▍| 6117/15000 [39:11<2:23:42,  1.03it/s, lr=9.75e-6, step_loss=0.00407/18/2023 19:42:33 - INFO - __main__ - train loss is 1.812584781087935\n",
      "Steps:  41%|▍| 6118/15000 [39:11<1:48:37,  1.36it/s, lr=9.75e-6, step_loss=0.51607/18/2023 19:42:33 - INFO - __main__ - train loss is 1.8292378867045045\n",
      "Steps:  41%|▍| 6119/15000 [39:11<1:23:56,  1.76it/s, lr=9.75e-6, step_loss=0.01607/18/2023 19:42:34 - INFO - __main__ - train loss is 1.8324511740356684\n",
      "Steps:  41%|▍| 6120/15000 [39:12<1:06:50,  2.21it/s, lr=9.75e-6, step_loss=0.00307/18/2023 19:42:34 - INFO - __main__ - train loss is 2.42355770803988\n",
      "Steps:  41%|▊ | 6121/15000 [39:12<54:41,  2.71it/s, lr=9.75e-6, step_loss=0.591]07/18/2023 19:42:34 - INFO - __main__ - train loss is 3.0579553339630365\n",
      "Steps:  41%|▊ | 6122/15000 [39:12<46:11,  3.20it/s, lr=9.75e-6, step_loss=0.634]07/18/2023 19:42:34 - INFO - __main__ - train loss is 3.059954313794151\n",
      "Steps:  41%|▊ | 6123/15000 [39:12<40:14,  3.68it/s, lr=9.75e-6, step_loss=0.002]07/18/2023 19:42:34 - INFO - __main__ - train loss is 3.0920626840088516\n",
      "Steps:  41%|▍| 6124/15000 [39:12<36:07,  4.10it/s, lr=9.75e-6, step_loss=0.0321]07/18/2023 19:42:35 - INFO - __main__ - train loss is 3.1365863701794297\n",
      "Steps:  41%|▍| 6125/15000 [39:12<33:11,  4.46it/s, lr=9.75e-6, step_loss=0.0445]07/18/2023 19:42:35 - INFO - __main__ - train loss is 3.312403174350038\n",
      "Steps:  41%|▊ | 6126/15000 [39:13<31:08,  4.75it/s, lr=9.75e-6, step_loss=0.176]07/18/2023 19:42:35 - INFO - __main__ - train loss is 3.7121880969498307\n",
      "Steps:  41%|█▋  | 6127/15000 [39:13<29:41,  4.98it/s, lr=9.75e-6, step_loss=0.4]07/18/2023 19:42:35 - INFO - __main__ - train loss is 3.733100069919601\n",
      "Steps:  41%|▍| 6128/15000 [39:13<28:39,  5.16it/s, lr=9.75e-6, step_loss=0.0209]07/18/2023 19:42:35 - INFO - __main__ - train loss is 4.010379327693954\n",
      "Steps:  41%|▊ | 6129/15000 [39:13<27:57,  5.29it/s, lr=9.75e-6, step_loss=0.277]07/18/2023 19:42:35 - INFO - __main__ - train loss is 4.020159428240731\n",
      "Steps:  41%|▍| 6130/15000 [39:13<27:28,  5.38it/s, lr=9.75e-6, step_loss=0.0097807/18/2023 19:42:36 - INFO - __main__ - train loss is 4.391883705975488\n",
      "Steps:  41%|▊ | 6131/15000 [39:14<27:07,  5.45it/s, lr=9.75e-6, step_loss=0.372]07/18/2023 19:42:36 - INFO - __main__ - train loss is 4.448816915275529\n",
      "Steps:  41%|▍| 6132/15000 [39:14<26:54,  5.49it/s, lr=9.75e-6, step_loss=0.0569]07/18/2023 19:42:36 - INFO - __main__ - train loss is 4.9235341746825725\n",
      "Steps:  41%|▊ | 6133/15000 [39:14<26:43,  5.53it/s, lr=9.75e-6, step_loss=0.475]07/18/2023 19:42:36 - INFO - __main__ - train loss is 4.977773492457345\n",
      "Steps:  41%|▍| 6134/15000 [39:14<26:36,  5.55it/s, lr=9.75e-6, step_loss=0.0542]07/18/2023 19:42:36 - INFO - __main__ - train loss is 5.386405115248635\n",
      "Steps:  41%|▊ | 6135/15000 [39:14<26:32,  5.57it/s, lr=9.75e-6, step_loss=0.409]07/18/2023 19:42:37 - INFO - __main__ - train loss is 6.028452878119424\n",
      "Steps:  41%|▊ | 6136/15000 [39:14<26:28,  5.58it/s, lr=9.75e-6, step_loss=0.642]07/18/2023 19:42:37 - INFO - __main__ - train loss is 6.257372712017968\n",
      "Steps:  41%|▊ | 6137/15000 [39:15<26:26,  5.59it/s, lr=9.75e-6, step_loss=0.229]07/18/2023 19:42:37 - INFO - __main__ - train loss is 6.602012311341241\n",
      "Steps:  41%|▊ | 6138/15000 [39:15<26:25,  5.59it/s, lr=9.75e-6, step_loss=0.345]07/18/2023 19:42:37 - INFO - __main__ - train loss is 6.953476284863427\n",
      "Steps:  41%|▊ | 6139/15000 [39:15<26:23,  5.60it/s, lr=9.75e-6, step_loss=0.351]07/18/2023 19:42:37 - INFO - __main__ - train loss is 7.023484130622819\n",
      "Steps:  41%|█▏ | 6140/15000 [39:15<26:21,  5.60it/s, lr=9.74e-6, step_loss=0.07]07/18/2023 19:42:37 - INFO - __main__ - train loss is 7.039724336238578\n",
      "Steps:  41%|▍| 6141/15000 [39:15<26:21,  5.60it/s, lr=9.74e-6, step_loss=0.0162]07/18/2023 19:42:38 - INFO - __main__ - train loss is 7.13600450870581\n",
      "Steps:  41%|▍| 6142/15000 [39:15<26:23,  5.59it/s, lr=9.74e-6, step_loss=0.0963]07/18/2023 19:42:38 - INFO - __main__ - train loss is 7.1547345102299005\n",
      "Steps:  41%|▍| 6143/15000 [39:16<26:24,  5.59it/s, lr=9.74e-6, step_loss=0.0187]07/18/2023 19:42:38 - INFO - __main__ - train loss is 7.184029906289652\n",
      "Steps:  41%|▍| 6144/15000 [39:16<26:25,  5.58it/s, lr=9.74e-6, step_loss=0.0293]07/18/2023 19:42:38 - INFO - __main__ - train loss is 7.57049450208433\n",
      "Steps:  41%|▊ | 6145/15000 [39:16<26:24,  5.59it/s, lr=9.74e-6, step_loss=0.386]07/18/2023 19:42:38 - INFO - __main__ - train loss is 7.576031174743548\n",
      "Steps:  41%|▍| 6146/15000 [39:16<26:47,  5.51it/s, lr=9.74e-6, step_loss=0.0055407/18/2023 19:42:39 - INFO - __main__ - train loss is 8.22962185391225\n",
      "Steps:  41%|▊ | 6147/15000 [39:16<29:03,  5.08it/s, lr=9.74e-6, step_loss=0.654]07/18/2023 19:42:39 - INFO - __main__ - train loss is 8.37640480347909\n",
      "Steps:  41%|▊ | 6148/15000 [39:17<28:41,  5.14it/s, lr=9.74e-6, step_loss=0.147]07/18/2023 19:42:39 - INFO - __main__ - train loss is 8.383515405235812\n",
      "Steps:  41%|▍| 6149/15000 [39:17<28:34,  5.16it/s, lr=9.74e-6, step_loss=0.0071107/18/2023 19:42:39 - INFO - __main__ - train loss is 8.423981706378981\n",
      "Steps:  41%|▍| 6150/15000 [39:17<27:53,  5.29it/s, lr=9.74e-6, step_loss=0.0405]07/18/2023 19:42:39 - INFO - __main__ - train loss is 8.503016295609996\n",
      "Steps:  41%|▊ | 6151/15000 [39:17<27:25,  5.38it/s, lr=9.74e-6, step_loss=0.079]07/18/2023 19:42:39 - INFO - __main__ - train loss is 8.505509019130841\n",
      "Steps:  41%|▍| 6152/15000 [39:17<27:05,  5.44it/s, lr=9.74e-6, step_loss=0.0024907/18/2023 19:42:40 - INFO - __main__ - train loss is 8.684654534095898\n",
      "Steps:  41%|▊ | 6153/15000 [39:18<26:51,  5.49it/s, lr=9.74e-6, step_loss=0.179]07/18/2023 19:42:40 - INFO - __main__ - train loss is 8.693301961990073\n",
      "Steps:  41%|▍| 6154/15000 [39:18<26:43,  5.52it/s, lr=9.74e-6, step_loss=0.0086507/18/2023 19:42:40 - INFO - __main__ - train loss is 8.696693001547828\n",
      "Steps:  41%|▍| 6155/15000 [39:18<26:36,  5.54it/s, lr=9.74e-6, step_loss=0.0033907/18/2023 19:42:40 - INFO - __main__ - train loss is 8.804797007003799\n",
      "Steps:  41%|▊ | 6156/15000 [39:18<26:31,  5.56it/s, lr=9.74e-6, step_loss=0.108]07/18/2023 19:42:40 - INFO - __main__ - train loss is 8.808359712129459\n",
      "Steps:  41%|▍| 6157/15000 [39:18<26:28,  5.57it/s, lr=9.74e-6, step_loss=0.0035607/18/2023 19:42:41 - INFO - __main__ - train loss is 9.168523043161258\n",
      "Steps:  41%|█▏ | 6158/15000 [39:18<26:25,  5.58it/s, lr=9.74e-6, step_loss=0.36]07/18/2023 19:42:41 - INFO - __main__ - train loss is 9.366603970294818\n",
      "Steps:  41%|▊ | 6159/15000 [39:19<26:25,  5.58it/s, lr=9.74e-6, step_loss=0.198]07/18/2023 19:42:41 - INFO - __main__ - train loss is 9.470642313128337\n",
      "Steps:  41%|▊ | 6160/15000 [39:19<26:22,  5.58it/s, lr=9.74e-6, step_loss=0.104]07/18/2023 19:42:41 - INFO - __main__ - train loss is 9.962479695444927\n",
      "Steps:  41%|▊ | 6161/15000 [39:19<26:23,  5.58it/s, lr=9.74e-6, step_loss=0.492]07/18/2023 19:42:41 - INFO - __main__ - train loss is 9.972157466923818\n",
      "Steps:  41%|▍| 6162/15000 [39:19<26:21,  5.59it/s, lr=9.74e-6, step_loss=0.0096807/18/2023 19:42:41 - INFO - __main__ - train loss is 10.51514433673583\n",
      "Steps:  41%|▊ | 6163/15000 [39:19<26:33,  5.55it/s, lr=9.74e-6, step_loss=0.543]07/18/2023 19:42:42 - INFO - __main__ - train loss is 10.539811137830839\n",
      "Steps:  41%|▍| 6164/15000 [39:20<27:11,  5.42it/s, lr=9.74e-6, step_loss=0.0247]07/18/2023 19:42:42 - INFO - __main__ - train loss is 10.569220332195982\n",
      "Steps:  41%|▍| 6165/15000 [39:20<27:39,  5.32it/s, lr=9.74e-6, step_loss=0.0294]07/18/2023 19:42:42 - INFO - __main__ - train loss is 11.009582308819517\n",
      "Steps:  41%|█▏ | 6166/15000 [39:20<27:58,  5.26it/s, lr=9.74e-6, step_loss=0.44]07/18/2023 19:42:42 - INFO - __main__ - train loss is 11.012579932808876\n",
      "Steps:  41%|▊ | 6167/15000 [39:20<28:33,  5.16it/s, lr=9.74e-6, step_loss=0.003]07/18/2023 19:42:42 - INFO - __main__ - train loss is 11.473055884242058\n",
      "Steps:  41%|█▏ | 6168/15000 [39:20<28:04,  5.24it/s, lr=9.74e-6, step_loss=0.46]07/18/2023 19:42:43 - INFO - __main__ - train loss is 11.718101307749748\n",
      "Steps:  41%|▊ | 6169/15000 [39:21<28:55,  5.09it/s, lr=9.74e-6, step_loss=0.245]07/18/2023 19:42:43 - INFO - __main__ - train loss is 11.721419151872396\n",
      "Steps:  41%|▍| 6170/15000 [39:21<28:50,  5.10it/s, lr=9.74e-6, step_loss=0.0033207/18/2023 19:42:43 - INFO - __main__ - train loss is 11.727840474806726\n",
      "Steps:  41%|▍| 6171/15000 [39:21<28:29,  5.16it/s, lr=9.74e-6, step_loss=0.0064207/18/2023 19:42:43 - INFO - __main__ - train loss is 11.776058736257255\n",
      "Steps:  41%|▍| 6172/15000 [39:21<28:14,  5.21it/s, lr=9.74e-6, step_loss=0.0482]07/18/2023 19:42:43 - INFO - __main__ - train loss is 11.793070769868791\n",
      "Steps:  41%|▊ | 6173/15000 [39:21<28:19,  5.19it/s, lr=9.74e-6, step_loss=0.017]07/18/2023 19:42:44 - INFO - __main__ - train loss is 12.017716891132295\n",
      "Steps:  41%|▊ | 6174/15000 [39:21<28:24,  5.18it/s, lr=9.74e-6, step_loss=0.225]07/18/2023 19:42:44 - INFO - __main__ - train loss is 12.974999672733247\n",
      "Steps:  41%|▊ | 6175/15000 [39:22<28:31,  5.16it/s, lr=9.74e-6, step_loss=0.957]07/18/2023 19:42:44 - INFO - __main__ - train loss is 12.977329711662605\n",
      "Steps:  41%|▍| 6176/15000 [39:22<28:29,  5.16it/s, lr=9.74e-6, step_loss=0.0023307/18/2023 19:42:44 - INFO - __main__ - train loss is 13.422611008631065\n",
      "Steps:  41%|▊ | 6177/15000 [39:22<28:35,  5.14it/s, lr=9.74e-6, step_loss=0.445]07/18/2023 19:42:44 - INFO - __main__ - train loss is 13.425164743093774\n",
      "Steps:  41%|▍| 6178/15000 [39:22<28:37,  5.14it/s, lr=9.74e-6, step_loss=0.0025507/18/2023 19:42:45 - INFO - __main__ - train loss is 13.504946565954015\n",
      "Steps:  41%|▍| 6179/15000 [39:22<28:37,  5.14it/s, lr=9.74e-6, step_loss=0.0798]07/18/2023 19:42:45 - INFO - __main__ - train loss is 13.858887321082875\n",
      "Steps:  41%|▊ | 6180/15000 [39:23<28:40,  5.13it/s, lr=9.74e-6, step_loss=0.354]07/18/2023 19:42:45 - INFO - __main__ - train loss is 14.151515490142629\n",
      "Steps:  41%|▊ | 6181/15000 [39:23<28:41,  5.12it/s, lr=9.74e-6, step_loss=0.293]07/18/2023 19:42:45 - INFO - __main__ - train loss is 14.295552125899121\n",
      "Steps:  41%|▊ | 6182/15000 [39:23<28:42,  5.12it/s, lr=9.74e-6, step_loss=0.144]07/18/2023 19:42:45 - INFO - __main__ - train loss is 14.300177755532786\n",
      "Steps:  41%|▍| 6183/15000 [39:23<28:39,  5.13it/s, lr=9.74e-6, step_loss=0.0046307/18/2023 19:42:46 - INFO - __main__ - train loss is 14.534188630757853\n",
      "Steps:  41%|▊ | 6184/15000 [39:23<28:38,  5.13it/s, lr=9.74e-6, step_loss=0.234]07/18/2023 19:42:46 - INFO - __main__ - train loss is 14.9170835937839\n",
      "Steps:  41%|▊ | 6185/15000 [39:24<28:47,  5.10it/s, lr=9.74e-6, step_loss=0.383]07/18/2023 19:42:46 - INFO - __main__ - train loss is 14.91909782285802\n",
      "Steps:  41%|▍| 6186/15000 [39:24<28:41,  5.12it/s, lr=9.74e-6, step_loss=0.0020107/18/2023 19:42:46 - INFO - __main__ - train loss is 15.104093474103138\n",
      "Steps:  41%|▊ | 6187/15000 [39:24<28:36,  5.13it/s, lr=9.74e-6, step_loss=0.185]07/18/2023 19:42:46 - INFO - __main__ - train loss is 15.109723740024492\n",
      "Steps:  41%|▍| 6188/15000 [39:24<28:35,  5.14it/s, lr=9.74e-6, step_loss=0.0056307/18/2023 19:42:47 - INFO - __main__ - train loss is 15.12297127279453\n",
      "Steps:  41%|▍| 6189/15000 [39:24<28:33,  5.14it/s, lr=9.74e-6, step_loss=0.0132]07/18/2023 19:42:47 - INFO - __main__ - train loss is 15.311125210253522\n",
      "Steps:  41%|▊ | 6190/15000 [39:25<28:32,  5.14it/s, lr=9.74e-6, step_loss=0.188]07/18/2023 19:42:47 - INFO - __main__ - train loss is 15.317218189826235\n",
      "Steps:  41%|▍| 6191/15000 [39:25<28:10,  5.21it/s, lr=9.74e-6, step_loss=0.0060907/18/2023 19:42:47 - INFO - __main__ - train loss is 15.685020392527804\n",
      "Steps:  41%|▊ | 6192/15000 [39:25<27:47,  5.28it/s, lr=9.74e-6, step_loss=0.368]07/18/2023 19:42:47 - INFO - __main__ - train loss is 15.707566020777449\n",
      "Steps:  41%|▍| 6193/15000 [39:25<27:17,  5.38it/s, lr=9.74e-6, step_loss=0.0225]07/18/2023 19:42:47 - INFO - __main__ - train loss is 15.898819563677534\n",
      "Steps:  41%|▊ | 6194/15000 [39:25<27:11,  5.40it/s, lr=9.74e-6, step_loss=0.191]07/18/2023 19:42:48 - INFO - __main__ - train loss is 16.028722492745146\n",
      "Steps:  41%|█▏ | 6195/15000 [39:26<26:57,  5.44it/s, lr=9.74e-6, step_loss=0.13]07/18/2023 19:42:48 - INFO - __main__ - train loss is 16.097598938038573\n",
      "Steps:  41%|▍| 6196/15000 [39:26<26:43,  5.49it/s, lr=9.74e-6, step_loss=0.0689]07/18/2023 19:42:48 - INFO - __main__ - train loss is 16.173492623260245\n",
      "Steps:  41%|▍| 6197/15000 [39:26<26:33,  5.52it/s, lr=9.74e-6, step_loss=0.0759]07/18/2023 19:42:48 - INFO - __main__ - train loss is 16.30767069547437\n",
      "Steps:  41%|▊ | 6198/15000 [39:26<26:25,  5.55it/s, lr=9.74e-6, step_loss=0.134]07/18/2023 19:42:48 - INFO - __main__ - train loss is 16.638348353793845\n",
      "Steps:  41%|▊ | 6199/15000 [39:26<26:19,  5.57it/s, lr=9.74e-6, step_loss=0.331]07/18/2023 19:42:49 - INFO - __main__ - train loss is 16.737708573928103\n",
      "Steps:  41%|▍| 6200/15000 [39:26<26:15,  5.59it/s, lr=9.74e-6, step_loss=0.0994]07/18/2023 19:42:49 - INFO - __main__ - train loss is 16.76297380379401\n",
      "Steps:  41%|▍| 6201/15000 [39:27<26:12,  5.60it/s, lr=9.74e-6, step_loss=0.0253]07/18/2023 19:42:49 - INFO - __main__ - train loss is 17.021449763095006\n",
      "Steps:  41%|▊ | 6202/15000 [39:27<26:09,  5.61it/s, lr=9.74e-6, step_loss=0.258]07/18/2023 19:42:49 - INFO - __main__ - train loss is 17.0962350924965\n",
      "Steps:  41%|▍| 6203/15000 [39:27<26:08,  5.61it/s, lr=9.74e-6, step_loss=0.0748]07/18/2023 19:42:49 - INFO - __main__ - train loss is 17.47048884234391\n",
      "Steps:  41%|▊ | 6204/15000 [39:27<26:07,  5.61it/s, lr=9.74e-6, step_loss=0.374]07/18/2023 19:42:49 - INFO - __main__ - train loss is 17.742669071769342\n",
      "Steps:  41%|▊ | 6205/15000 [39:27<26:06,  5.61it/s, lr=9.74e-6, step_loss=0.272]07/18/2023 19:42:50 - INFO - __main__ - train loss is 17.97766278288327\n",
      "Steps:  41%|▊ | 6206/15000 [39:27<26:06,  5.61it/s, lr=9.74e-6, step_loss=0.235]07/18/2023 19:42:50 - INFO - __main__ - train loss is 17.979234184604138\n",
      "Steps:  41%|▍| 6207/15000 [39:28<26:06,  5.61it/s, lr=9.74e-6, step_loss=0.0015707/18/2023 19:42:50 - INFO - __main__ - train loss is 18.332753862719983\n",
      "Steps:  41%|▊ | 6208/15000 [39:28<37:55,  3.86it/s, lr=9.74e-6, step_loss=0.354]07/18/2023 19:42:51 - INFO - __main__ - Per validation step average loss is 0.011468429118394852\n",
      "07/18/2023 19:42:51 - INFO - __main__ - Cumulative validation average loss is 0.011468429118394852\n",
      "07/18/2023 19:42:51 - INFO - __main__ - Per validation step average loss is 0.1417001187801361\n",
      "07/18/2023 19:42:51 - INFO - __main__ - Cumulative validation average loss is 0.15316854789853096\n",
      "07/18/2023 19:42:51 - INFO - __main__ - Per validation step average loss is 0.6145280003547668\n",
      "07/18/2023 19:42:51 - INFO - __main__ - Cumulative validation average loss is 0.7676965482532978\n",
      "07/18/2023 19:42:51 - INFO - __main__ - Per validation step average loss is 0.46962761878967285\n",
      "07/18/2023 19:42:51 - INFO - __main__ - Cumulative validation average loss is 1.2373241670429707\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Per validation step average loss is 0.0385640412569046\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Cumulative validation average loss is 1.2758882082998753\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Per validation step average loss is 0.2147310972213745\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Cumulative validation average loss is 1.4906193055212498\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Per validation step average loss is 0.16832131147384644\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Cumulative validation average loss is 1.6589406169950962\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Per validation step average loss is 0.14321748912334442\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Cumulative validation average loss is 1.8021581061184406\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Per validation step average loss is 0.5989135503768921\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Cumulative validation average loss is 2.4010716564953327\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Per validation step average loss is 0.2667863368988037\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Cumulative validation average loss is 2.6678579933941364\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Per validation step average loss is 0.04139752313494682\n",
      "07/18/2023 19:42:52 - INFO - __main__ - Cumulative validation average loss is 2.7092555165290833\n",
      "07/18/2023 19:42:53 - INFO - __main__ - Per validation step average loss is 0.2918745279312134\n",
      "07/18/2023 19:42:53 - INFO - __main__ - Cumulative validation average loss is 3.0011300444602966\n",
      "07/18/2023 19:42:53 - INFO - __main__ - Average validation loss for Epoch 63 is 0.2500941703716914\n",
      "07/18/2023 19:42:53 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:43:05 - INFO - __main__ - Starting epoch 64\n",
      "07/18/2023 19:43:06 - INFO - __main__ - train loss is 0.014684987254440784\n",
      "Steps:  41%|▍| 6209/15000 [39:44<12:09:30,  4.98s/it, lr=9.74e-6, step_loss=0.0107/18/2023 19:43:06 - INFO - __main__ - train loss is 0.017783155431970954\n",
      "Steps:  41%|▍| 6210/15000 [39:44<8:38:26,  3.54s/it, lr=9.74e-6, step_loss=0.00307/18/2023 19:43:07 - INFO - __main__ - train loss is 0.027877593180164695\n",
      "Steps:  41%|▍| 6211/15000 [39:44<6:10:42,  2.53s/it, lr=9.74e-6, step_loss=0.01007/18/2023 19:43:07 - INFO - __main__ - train loss is 0.25263073458336294\n",
      "Steps:  41%|▍| 6212/15000 [39:45<4:27:17,  1.82s/it, lr=9.74e-6, step_loss=0.22507/18/2023 19:43:07 - INFO - __main__ - train loss is 0.25824460783042014\n",
      "Steps:  41%|▍| 6213/15000 [39:45<3:14:54,  1.33s/it, lr=9.74e-6, step_loss=0.00507/18/2023 19:43:07 - INFO - __main__ - train loss is 0.41033909120596945\n",
      "Steps:  41%|▍| 6214/15000 [39:45<2:24:35,  1.01it/s, lr=9.74e-6, step_loss=0.15207/18/2023 19:43:07 - INFO - __main__ - train loss is 0.6082680860999972\n",
      "Steps:  41%|▍| 6215/15000 [39:45<1:49:30,  1.34it/s, lr=9.74e-6, step_loss=0.19807/18/2023 19:43:07 - INFO - __main__ - train loss is 1.1024028400424868\n",
      "Steps:  41%|▍| 6216/15000 [39:45<1:24:57,  1.72it/s, lr=9.74e-6, step_loss=0.49407/18/2023 19:43:08 - INFO - __main__ - train loss is 1.2380171457771212\n",
      "Steps:  41%|▍| 6217/15000 [39:46<1:07:42,  2.16it/s, lr=9.74e-6, step_loss=0.13607/18/2023 19:43:08 - INFO - __main__ - train loss is 1.2397823971696198\n",
      "Steps:  41%|▍| 6218/15000 [39:46<55:12,  2.65it/s, lr=9.74e-6, step_loss=0.0017707/18/2023 19:43:08 - INFO - __main__ - train loss is 1.6126152914948761\n",
      "Steps:  41%|▊ | 6219/15000 [39:46<46:27,  3.15it/s, lr=9.74e-6, step_loss=0.373]07/18/2023 19:43:08 - INFO - __main__ - train loss is 1.6229243674315512\n",
      "Steps:  41%|▍| 6220/15000 [39:46<40:19,  3.63it/s, lr=9.74e-6, step_loss=0.0103]07/18/2023 19:43:08 - INFO - __main__ - train loss is 1.6317699500359595\n",
      "Steps:  41%|▍| 6221/15000 [39:46<36:01,  4.06it/s, lr=9.74e-6, step_loss=0.0088507/18/2023 19:43:09 - INFO - __main__ - train loss is 1.649860838893801\n",
      "Steps:  41%|▍| 6222/15000 [39:46<33:02,  4.43it/s, lr=9.74e-6, step_loss=0.0181]07/18/2023 19:43:09 - INFO - __main__ - train loss is 1.6794586726464331\n",
      "Steps:  41%|▍| 6223/15000 [39:47<30:58,  4.72it/s, lr=9.74e-6, step_loss=0.0296]07/18/2023 19:43:09 - INFO - __main__ - train loss is 1.9064578362740576\n",
      "Steps:  41%|▊ | 6224/15000 [39:47<29:39,  4.93it/s, lr=9.74e-6, step_loss=0.227]07/18/2023 19:43:09 - INFO - __main__ - train loss is 1.9878913261927664\n",
      "Steps:  42%|▍| 6225/15000 [39:47<28:33,  5.12it/s, lr=9.74e-6, step_loss=0.0814]07/18/2023 19:43:09 - INFO - __main__ - train loss is 2.1182342865504324\n",
      "Steps:  42%|█▏ | 6226/15000 [39:47<27:48,  5.26it/s, lr=9.74e-6, step_loss=0.13]07/18/2023 19:43:09 - INFO - __main__ - train loss is 2.376702616456896\n",
      "Steps:  42%|▊ | 6227/15000 [39:47<27:17,  5.36it/s, lr=9.74e-6, step_loss=0.258]07/18/2023 19:43:10 - INFO - __main__ - train loss is 2.4212433346547186\n",
      "Steps:  42%|▍| 6228/15000 [39:48<26:55,  5.43it/s, lr=9.74e-6, step_loss=0.0445]07/18/2023 19:43:10 - INFO - __main__ - train loss is 2.5528490194119513\n",
      "Steps:  42%|▊ | 6229/15000 [39:48<26:40,  5.48it/s, lr=9.74e-6, step_loss=0.132]07/18/2023 19:43:10 - INFO - __main__ - train loss is 2.582953891251236\n",
      "Steps:  42%|▍| 6230/15000 [39:48<26:29,  5.52it/s, lr=9.74e-6, step_loss=0.0301]07/18/2023 19:43:10 - INFO - __main__ - train loss is 2.5977735086344182\n",
      "Steps:  42%|▍| 6231/15000 [39:48<26:22,  5.54it/s, lr=9.74e-6, step_loss=0.0148]07/18/2023 19:43:10 - INFO - __main__ - train loss is 3.152302698697895\n",
      "Steps:  42%|▊ | 6232/15000 [39:48<26:17,  5.56it/s, lr=9.74e-6, step_loss=0.555]07/18/2023 19:43:11 - INFO - __main__ - train loss is 3.189594694878906\n",
      "Steps:  42%|▍| 6233/15000 [39:48<26:13,  5.57it/s, lr=9.74e-6, step_loss=0.0373]07/18/2023 19:43:11 - INFO - __main__ - train loss is 3.1936443941667676\n",
      "Steps:  42%|▍| 6234/15000 [39:49<26:11,  5.58it/s, lr=9.74e-6, step_loss=0.0040507/18/2023 19:43:11 - INFO - __main__ - train loss is 3.2472424851730466\n",
      "Steps:  42%|▍| 6235/15000 [39:49<26:09,  5.59it/s, lr=9.74e-6, step_loss=0.0536]07/18/2023 19:43:11 - INFO - __main__ - train loss is 3.3635319070890546\n",
      "Steps:  42%|▊ | 6236/15000 [39:49<26:10,  5.58it/s, lr=9.74e-6, step_loss=0.116]07/18/2023 19:43:11 - INFO - __main__ - train loss is 3.369651440065354\n",
      "Steps:  42%|▍| 6237/15000 [39:49<26:09,  5.58it/s, lr=9.74e-6, step_loss=0.0061207/18/2023 19:43:11 - INFO - __main__ - train loss is 3.373104018624872\n",
      "Steps:  42%|▍| 6238/15000 [39:49<26:11,  5.58it/s, lr=9.74e-6, step_loss=0.0034507/18/2023 19:43:12 - INFO - __main__ - train loss is 3.6409652060829103\n",
      "Steps:  42%|▊ | 6239/15000 [39:49<26:09,  5.58it/s, lr=9.74e-6, step_loss=0.268]07/18/2023 19:43:12 - INFO - __main__ - train loss is 3.683941663708538\n",
      "Steps:  42%|▊ | 6240/15000 [39:50<26:12,  5.57it/s, lr=9.74e-6, step_loss=0.043]07/18/2023 19:43:12 - INFO - __main__ - train loss is 4.111953140702099\n",
      "Steps:  42%|▊ | 6241/15000 [39:50<26:09,  5.58it/s, lr=9.74e-6, step_loss=0.428]07/18/2023 19:43:12 - INFO - __main__ - train loss is 4.211794415023178\n",
      "Steps:  42%|▍| 6242/15000 [39:50<26:07,  5.59it/s, lr=9.74e-6, step_loss=0.0998]07/18/2023 19:43:12 - INFO - __main__ - train loss is 4.224780622404069\n",
      "Steps:  42%|▊ | 6243/15000 [39:50<26:06,  5.59it/s, lr=9.74e-6, step_loss=0.013]07/18/2023 19:43:12 - INFO - __main__ - train loss is 4.235469211358577\n",
      "Steps:  42%|▍| 6244/15000 [39:50<26:05,  5.59it/s, lr=9.74e-6, step_loss=0.0107]07/18/2023 19:43:13 - INFO - __main__ - train loss is 4.611857135314494\n",
      "Steps:  42%|▊ | 6245/15000 [39:51<26:07,  5.59it/s, lr=9.74e-6, step_loss=0.376]07/18/2023 19:43:13 - INFO - __main__ - train loss is 4.643172845710069\n",
      "Steps:  42%|▍| 6246/15000 [39:51<26:05,  5.59it/s, lr=9.74e-6, step_loss=0.0313]07/18/2023 19:43:13 - INFO - __main__ - train loss is 4.837541699875146\n",
      "Steps:  42%|▊ | 6247/15000 [39:51<26:04,  5.60it/s, lr=9.74e-6, step_loss=0.194]07/18/2023 19:43:13 - INFO - __main__ - train loss is 4.929865256417543\n",
      "Steps:  42%|▍| 6248/15000 [39:51<26:03,  5.60it/s, lr=9.74e-6, step_loss=0.0923]07/18/2023 19:43:13 - INFO - __main__ - train loss is 5.065769389737397\n",
      "Steps:  42%|▊ | 6249/15000 [39:51<26:03,  5.60it/s, lr=9.74e-6, step_loss=0.136]07/18/2023 19:43:14 - INFO - __main__ - train loss is 5.067719591432251\n",
      "Steps:  42%|▍| 6250/15000 [39:51<26:03,  5.60it/s, lr=9.74e-6, step_loss=0.0019507/18/2023 19:43:14 - INFO - __main__ - train loss is 5.1575829439098015\n",
      "Steps:  42%|▍| 6251/15000 [39:52<26:02,  5.60it/s, lr=9.74e-6, step_loss=0.0899]07/18/2023 19:43:14 - INFO - __main__ - train loss is 5.532047068350948\n",
      "Steps:  42%|▊ | 6252/15000 [39:52<26:01,  5.60it/s, lr=9.74e-6, step_loss=0.374]07/18/2023 19:43:14 - INFO - __main__ - train loss is 5.533573894412257\n",
      "Steps:  42%|▍| 6253/15000 [39:52<26:01,  5.60it/s, lr=9.74e-6, step_loss=0.0015307/18/2023 19:43:14 - INFO - __main__ - train loss is 5.54594173154328\n",
      "Steps:  42%|▍| 6254/15000 [39:52<26:01,  5.60it/s, lr=9.74e-6, step_loss=0.0124]07/18/2023 19:43:14 - INFO - __main__ - train loss is 5.54801556665916\n",
      "Steps:  42%|▍| 6255/15000 [39:52<26:00,  5.60it/s, lr=9.74e-6, step_loss=0.0020707/18/2023 19:43:15 - INFO - __main__ - train loss is 5.63564208347816\n",
      "Steps:  42%|▍| 6256/15000 [39:53<26:00,  5.60it/s, lr=9.74e-6, step_loss=0.0876]07/18/2023 19:43:15 - INFO - __main__ - train loss is 5.7039076258661225\n",
      "Steps:  42%|▍| 6257/15000 [39:53<26:00,  5.60it/s, lr=9.74e-6, step_loss=0.0683]07/18/2023 19:43:15 - INFO - __main__ - train loss is 5.740654850495048\n",
      "Steps:  42%|▍| 6258/15000 [39:53<25:59,  5.60it/s, lr=9.74e-6, step_loss=0.0367]07/18/2023 19:43:15 - INFO - __main__ - train loss is 6.43349876452703\n",
      "Steps:  42%|▊ | 6259/15000 [39:53<25:59,  5.61it/s, lr=9.74e-6, step_loss=0.693]07/18/2023 19:43:15 - INFO - __main__ - train loss is 6.458117907983251\n",
      "Steps:  42%|▍| 6260/15000 [39:53<25:59,  5.60it/s, lr=9.73e-6, step_loss=0.0246]07/18/2023 19:43:16 - INFO - __main__ - train loss is 6.461284886230715\n",
      "Steps:  42%|▍| 6261/15000 [39:53<25:57,  5.61it/s, lr=9.73e-6, step_loss=0.0031707/18/2023 19:43:16 - INFO - __main__ - train loss is 6.4696097747655585\n",
      "Steps:  42%|▍| 6262/15000 [39:54<25:58,  5.61it/s, lr=9.73e-6, step_loss=0.0083207/18/2023 19:43:16 - INFO - __main__ - train loss is 6.739526488003321\n",
      "Steps:  42%|█▎ | 6263/15000 [39:54<25:58,  5.61it/s, lr=9.73e-6, step_loss=0.27]07/18/2023 19:43:16 - INFO - __main__ - train loss is 6.777242146548815\n",
      "Steps:  42%|▍| 6264/15000 [39:54<25:58,  5.61it/s, lr=9.73e-6, step_loss=0.0377]07/18/2023 19:43:16 - INFO - __main__ - train loss is 6.7828070792602375\n",
      "Steps:  42%|▍| 6265/15000 [39:54<25:58,  5.61it/s, lr=9.73e-6, step_loss=0.0055607/18/2023 19:43:16 - INFO - __main__ - train loss is 6.903018255834468\n",
      "Steps:  42%|█▎ | 6266/15000 [39:54<25:58,  5.61it/s, lr=9.73e-6, step_loss=0.12]07/18/2023 19:43:17 - INFO - __main__ - train loss is 6.908051339094527\n",
      "Steps:  42%|▍| 6267/15000 [39:54<26:01,  5.59it/s, lr=9.73e-6, step_loss=0.0050307/18/2023 19:43:17 - INFO - __main__ - train loss is 7.1065254035638645\n",
      "Steps:  42%|▊ | 6268/15000 [39:55<26:00,  5.59it/s, lr=9.73e-6, step_loss=0.198]07/18/2023 19:43:17 - INFO - __main__ - train loss is 7.136197657440789\n",
      "Steps:  42%|▍| 6269/15000 [39:55<26:03,  5.58it/s, lr=9.73e-6, step_loss=0.0297]07/18/2023 19:43:17 - INFO - __main__ - train loss is 7.24868895218242\n",
      "Steps:  42%|▊ | 6270/15000 [39:55<26:02,  5.59it/s, lr=9.73e-6, step_loss=0.112]07/18/2023 19:43:17 - INFO - __main__ - train loss is 7.273314495687373\n",
      "Steps:  42%|▍| 6271/15000 [39:55<26:00,  5.59it/s, lr=9.73e-6, step_loss=0.0246]07/18/2023 19:43:17 - INFO - __main__ - train loss is 7.410692055826075\n",
      "Steps:  42%|▊ | 6272/15000 [39:55<25:59,  5.60it/s, lr=9.73e-6, step_loss=0.137]07/18/2023 19:43:18 - INFO - __main__ - train loss is 7.420917839859612\n",
      "Steps:  42%|▍| 6273/15000 [39:56<25:58,  5.60it/s, lr=9.73e-6, step_loss=0.0102]07/18/2023 19:43:18 - INFO - __main__ - train loss is 7.431392175261863\n",
      "Steps:  42%|▍| 6274/15000 [39:56<25:57,  5.60it/s, lr=9.73e-6, step_loss=0.0105]07/18/2023 19:43:18 - INFO - __main__ - train loss is 7.516874966328032\n",
      "Steps:  42%|▍| 6275/15000 [39:56<25:57,  5.60it/s, lr=9.73e-6, step_loss=0.0855]07/18/2023 19:43:18 - INFO - __main__ - train loss is 7.533349723671563\n",
      "Steps:  42%|▍| 6276/15000 [39:56<25:55,  5.61it/s, lr=9.73e-6, step_loss=0.0165]07/18/2023 19:43:18 - INFO - __main__ - train loss is 7.767752082203515\n",
      "Steps:  42%|▊ | 6277/15000 [39:56<25:56,  5.60it/s, lr=9.73e-6, step_loss=0.234]07/18/2023 19:43:19 - INFO - __main__ - train loss is 7.82436106831301\n",
      "Steps:  42%|▍| 6278/15000 [39:56<25:57,  5.60it/s, lr=9.73e-6, step_loss=0.0566]07/18/2023 19:43:19 - INFO - __main__ - train loss is 7.950948757235892\n",
      "Steps:  42%|▊ | 6279/15000 [39:57<25:57,  5.60it/s, lr=9.73e-6, step_loss=0.127]07/18/2023 19:43:19 - INFO - __main__ - train loss is 8.01392502814997\n",
      "Steps:  42%|▊ | 6280/15000 [39:57<25:56,  5.60it/s, lr=9.73e-6, step_loss=0.063]07/18/2023 19:43:19 - INFO - __main__ - train loss is 8.381329846684821\n",
      "Steps:  42%|▊ | 6281/15000 [39:57<25:56,  5.60it/s, lr=9.73e-6, step_loss=0.367]07/18/2023 19:43:19 - INFO - __main__ - train loss is 8.384066900820471\n",
      "Steps:  42%|▍| 6282/15000 [39:57<25:56,  5.60it/s, lr=9.73e-6, step_loss=0.0027407/18/2023 19:43:19 - INFO - __main__ - train loss is 8.475518307299353\n",
      "Steps:  42%|▍| 6283/15000 [39:57<25:56,  5.60it/s, lr=9.73e-6, step_loss=0.0915]07/18/2023 19:43:20 - INFO - __main__ - train loss is 8.522574542672373\n",
      "Steps:  42%|▍| 6284/15000 [39:58<26:11,  5.55it/s, lr=9.73e-6, step_loss=0.0471]07/18/2023 19:43:20 - INFO - __main__ - train loss is 8.52498068951536\n",
      "Steps:  42%|▍| 6285/15000 [39:58<26:26,  5.49it/s, lr=9.73e-6, step_loss=0.0024107/18/2023 19:43:20 - INFO - __main__ - train loss is 8.571825563092716\n",
      "Steps:  42%|▍| 6286/15000 [39:58<26:22,  5.51it/s, lr=9.73e-6, step_loss=0.0468]07/18/2023 19:43:20 - INFO - __main__ - train loss is 8.92685425200034\n",
      "Steps:  42%|▊ | 6287/15000 [39:58<26:13,  5.54it/s, lr=9.73e-6, step_loss=0.355]07/18/2023 19:43:20 - INFO - __main__ - train loss is 8.976238298346289\n",
      "Steps:  42%|▍| 6288/15000 [39:58<26:09,  5.55it/s, lr=9.73e-6, step_loss=0.0494]07/18/2023 19:43:21 - INFO - __main__ - train loss is 9.016422088374384\n",
      "Steps:  42%|▍| 6289/15000 [39:58<26:15,  5.53it/s, lr=9.73e-6, step_loss=0.0402]07/18/2023 19:43:21 - INFO - __main__ - train loss is 9.105537663330324\n",
      "Steps:  42%|▍| 6290/15000 [39:59<26:07,  5.56it/s, lr=9.73e-6, step_loss=0.0891]07/18/2023 19:43:21 - INFO - __main__ - train loss is 9.484051774372347\n",
      "Steps:  42%|▊ | 6291/15000 [39:59<26:02,  5.58it/s, lr=9.73e-6, step_loss=0.379]07/18/2023 19:43:21 - INFO - __main__ - train loss is 9.519730213214643\n",
      "Steps:  42%|▍| 6292/15000 [39:59<25:58,  5.59it/s, lr=9.73e-6, step_loss=0.0357]07/18/2023 19:43:21 - INFO - __main__ - train loss is 9.937694910098799\n",
      "Steps:  42%|▊ | 6293/15000 [39:59<25:55,  5.60it/s, lr=9.73e-6, step_loss=0.418]07/18/2023 19:43:21 - INFO - __main__ - train loss is 10.268537136842497\n",
      "Steps:  42%|▊ | 6294/15000 [39:59<25:53,  5.60it/s, lr=9.73e-6, step_loss=0.331]07/18/2023 19:43:22 - INFO - __main__ - train loss is 10.270052441279404\n",
      "Steps:  42%|▍| 6295/15000 [39:59<25:52,  5.61it/s, lr=9.73e-6, step_loss=0.0015207/18/2023 19:43:22 - INFO - __main__ - train loss is 10.458382376353256\n",
      "Steps:  42%|▊ | 6296/15000 [40:00<25:50,  5.61it/s, lr=9.73e-6, step_loss=0.188]07/18/2023 19:43:22 - INFO - __main__ - train loss is 10.469472597236745\n",
      "Steps:  42%|▍| 6297/15000 [40:00<25:51,  5.61it/s, lr=9.73e-6, step_loss=0.0111]07/18/2023 19:43:22 - INFO - __main__ - train loss is 10.900668631191365\n",
      "Steps:  42%|▊ | 6298/15000 [40:00<25:50,  5.61it/s, lr=9.73e-6, step_loss=0.431]07/18/2023 19:43:22 - INFO - __main__ - train loss is 10.963992151315324\n",
      "Steps:  42%|▍| 6299/15000 [40:00<25:50,  5.61it/s, lr=9.73e-6, step_loss=0.0633]07/18/2023 19:43:23 - INFO - __main__ - train loss is 11.127641173894517\n",
      "Steps:  42%|▊ | 6300/15000 [40:00<25:49,  5.62it/s, lr=9.73e-6, step_loss=0.164]07/18/2023 19:43:23 - INFO - __main__ - train loss is 11.384061994845979\n",
      "Steps:  42%|▊ | 6301/15000 [40:01<25:48,  5.62it/s, lr=9.73e-6, step_loss=0.256]07/18/2023 19:43:23 - INFO - __main__ - train loss is 11.452816578443162\n",
      "Steps:  42%|▍| 6302/15000 [40:01<25:49,  5.61it/s, lr=9.73e-6, step_loss=0.0688]07/18/2023 19:43:23 - INFO - __main__ - train loss is 11.54663019895088\n",
      "Steps:  42%|▍| 6303/15000 [40:01<25:49,  5.61it/s, lr=9.73e-6, step_loss=0.0938]07/18/2023 19:43:23 - INFO - __main__ - train loss is 11.548432761221193\n",
      "Steps:  42%|▍| 6304/15000 [40:01<25:48,  5.62it/s, lr=9.73e-6, step_loss=0.0018]07/18/2023 19:43:24 - INFO - __main__ - train loss is 11.703241207986139\n",
      "Steps:  42%|▊ | 6305/15000 [40:02<37:35,  3.85it/s, lr=9.73e-6, step_loss=0.155]07/18/2023 19:43:24 - INFO - __main__ - Per validation step average loss is 0.0069588953629136086\n",
      "07/18/2023 19:43:24 - INFO - __main__ - Cumulative validation average loss is 0.0069588953629136086\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Per validation step average loss is 0.04946409910917282\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Cumulative validation average loss is 0.05642299447208643\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Per validation step average loss is 0.2856452167034149\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Cumulative validation average loss is 0.34206821117550135\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Per validation step average loss is 0.3564622402191162\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Cumulative validation average loss is 0.6985304513946176\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Per validation step average loss is 0.40898793935775757\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Cumulative validation average loss is 1.1075183907523751\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Per validation step average loss is 0.03763666749000549\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Cumulative validation average loss is 1.1451550582423806\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Per validation step average loss is 0.24005426466464996\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Cumulative validation average loss is 1.3852093229070306\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Per validation step average loss is 0.1382075697183609\n",
      "07/18/2023 19:43:25 - INFO - __main__ - Cumulative validation average loss is 1.5234168926253915\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Per validation step average loss is 0.4068237543106079\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Cumulative validation average loss is 1.9302406469359994\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Per validation step average loss is 0.18880204856395721\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Cumulative validation average loss is 2.1190426954999566\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Per validation step average loss is 0.0035617039538919926\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Cumulative validation average loss is 2.1226043994538486\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Per validation step average loss is 0.2915857136249542\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Cumulative validation average loss is 2.414190113078803\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Average validation loss for Epoch 64 is 0.20118250942323357\n",
      "07/18/2023 19:43:26 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:43:39 - INFO - __main__ - Starting epoch 65\n",
      "07/18/2023 19:43:39 - INFO - __main__ - train loss is 0.018029045313596725\n",
      "Steps:  42%|▍| 6306/15000 [40:17<11:53:35,  4.92s/it, lr=9.73e-6, step_loss=0.0107/18/2023 19:43:40 - INFO - __main__ - train loss is 0.5021685175597668\n",
      "Steps:  42%|▍| 6307/15000 [40:18<8:27:14,  3.50s/it, lr=9.73e-6, step_loss=0.48407/18/2023 19:43:40 - INFO - __main__ - train loss is 0.5126345064491034\n",
      "Steps:  42%|▍| 6308/15000 [40:18<6:02:49,  2.50s/it, lr=9.73e-6, step_loss=0.01007/18/2023 19:43:40 - INFO - __main__ - train loss is 0.5162866427563131\n",
      "Steps:  42%|▍| 6309/15000 [40:18<4:21:41,  1.81s/it, lr=9.73e-6, step_loss=0.00307/18/2023 19:43:40 - INFO - __main__ - train loss is 0.7451951219700277\n",
      "Steps:  42%|▍| 6310/15000 [40:18<3:11:04,  1.32s/it, lr=9.73e-6, step_loss=0.22907/18/2023 19:43:40 - INFO - __main__ - train loss is 0.7469607661478221\n",
      "Steps:  42%|▍| 6311/15000 [40:18<2:21:28,  1.02it/s, lr=9.73e-6, step_loss=0.00107/18/2023 19:43:41 - INFO - __main__ - train loss is 0.748587760492228\n",
      "Steps:  42%|▍| 6312/15000 [40:18<1:46:44,  1.36it/s, lr=9.73e-6, step_loss=0.00107/18/2023 19:43:41 - INFO - __main__ - train loss is 1.2963126631220803\n",
      "Steps:  42%|▍| 6313/15000 [40:19<1:22:26,  1.76it/s, lr=9.73e-6, step_loss=0.54807/18/2023 19:43:41 - INFO - __main__ - train loss is 1.4485968382796273\n",
      "Steps:  42%|▍| 6314/15000 [40:19<1:05:41,  2.20it/s, lr=9.73e-6, step_loss=0.15207/18/2023 19:43:41 - INFO - __main__ - train loss is 1.5972716392716393\n",
      "Steps:  42%|▊ | 6315/15000 [40:19<53:46,  2.69it/s, lr=9.73e-6, step_loss=0.149]07/18/2023 19:43:41 - INFO - __main__ - train loss is 1.6064208255847916\n",
      "Steps:  42%|▍| 6316/15000 [40:19<45:21,  3.19it/s, lr=9.73e-6, step_loss=0.0091507/18/2023 19:43:41 - INFO - __main__ - train loss is 1.631466825841926\n",
      "Steps:  42%|▊ | 6317/15000 [40:19<39:51,  3.63it/s, lr=9.73e-6, step_loss=0.025]07/18/2023 19:43:42 - INFO - __main__ - train loss is 1.6330368098570034\n",
      "Steps:  42%|▍| 6318/15000 [40:20<36:14,  3.99it/s, lr=9.73e-6, step_loss=0.0015707/18/2023 19:43:42 - INFO - __main__ - train loss is 2.0379525598837063\n",
      "Steps:  42%|▊ | 6319/15000 [40:20<33:45,  4.28it/s, lr=9.73e-6, step_loss=0.405]07/18/2023 19:43:42 - INFO - __main__ - train loss is 2.0423052528640255\n",
      "Steps:  42%|▍| 6320/15000 [40:20<32:04,  4.51it/s, lr=9.73e-6, step_loss=0.0043507/18/2023 19:43:42 - INFO - __main__ - train loss is 2.851490400149487\n",
      "Steps:  42%|▊ | 6321/15000 [40:20<30:23,  4.76it/s, lr=9.73e-6, step_loss=0.809]07/18/2023 19:43:42 - INFO - __main__ - train loss is 2.8831081533571705\n",
      "Steps:  42%|▍| 6322/15000 [40:20<29:28,  4.91it/s, lr=9.73e-6, step_loss=0.0316]07/18/2023 19:43:43 - INFO - __main__ - train loss is 3.071665167226456\n",
      "Steps:  42%|▊ | 6323/15000 [40:20<29:27,  4.91it/s, lr=9.73e-6, step_loss=0.189]07/18/2023 19:43:43 - INFO - __main__ - train loss is 3.234349905862473\n",
      "Steps:  42%|▊ | 6324/15000 [40:21<29:03,  4.98it/s, lr=9.73e-6, step_loss=0.163]07/18/2023 19:43:43 - INFO - __main__ - train loss is 3.2414369381731376\n",
      "Steps:  42%|▍| 6325/15000 [40:21<28:39,  5.04it/s, lr=9.73e-6, step_loss=0.0070907/18/2023 19:43:43 - INFO - __main__ - train loss is 3.2651580203091726\n",
      "Steps:  42%|▍| 6326/15000 [40:21<28:05,  5.15it/s, lr=9.73e-6, step_loss=0.0237]07/18/2023 19:43:43 - INFO - __main__ - train loss is 3.3196510303532705\n",
      "Steps:  42%|▍| 6327/15000 [40:21<27:37,  5.23it/s, lr=9.73e-6, step_loss=0.0545]07/18/2023 19:43:44 - INFO - __main__ - train loss is 3.5241859335219488\n",
      "Steps:  42%|▊ | 6328/15000 [40:21<27:32,  5.25it/s, lr=9.73e-6, step_loss=0.205]07/18/2023 19:43:44 - INFO - __main__ - train loss is 3.545921564451419\n",
      "Steps:  42%|▍| 6329/15000 [40:22<27:47,  5.20it/s, lr=9.73e-6, step_loss=0.0217]07/18/2023 19:43:44 - INFO - __main__ - train loss is 3.8759918216383085\n",
      "Steps:  42%|█▎ | 6330/15000 [40:22<27:58,  5.17it/s, lr=9.73e-6, step_loss=0.33]07/18/2023 19:43:44 - INFO - __main__ - train loss is 4.492520332685672\n",
      "Steps:  42%|▊ | 6331/15000 [40:22<28:00,  5.16it/s, lr=9.73e-6, step_loss=0.617]07/18/2023 19:43:44 - INFO - __main__ - train loss is 4.607092552236281\n",
      "Steps:  42%|▊ | 6332/15000 [40:22<27:43,  5.21it/s, lr=9.73e-6, step_loss=0.115]07/18/2023 19:43:45 - INFO - __main__ - train loss is 5.1286418962990865\n",
      "Steps:  42%|▊ | 6333/15000 [40:22<27:57,  5.17it/s, lr=9.73e-6, step_loss=0.522]07/18/2023 19:43:45 - INFO - __main__ - train loss is 5.761511676362716\n",
      "Steps:  42%|▊ | 6334/15000 [40:23<28:05,  5.14it/s, lr=9.73e-6, step_loss=0.633]07/18/2023 19:43:45 - INFO - __main__ - train loss is 5.9089172560488805\n",
      "Steps:  42%|▊ | 6335/15000 [40:23<28:12,  5.12it/s, lr=9.73e-6, step_loss=0.147]07/18/2023 19:43:45 - INFO - __main__ - train loss is 5.974817507318221\n",
      "Steps:  42%|▍| 6336/15000 [40:23<28:12,  5.12it/s, lr=9.73e-6, step_loss=0.0659]07/18/2023 19:43:45 - INFO - __main__ - train loss is 6.577787749818526\n",
      "Steps:  42%|▊ | 6337/15000 [40:23<28:16,  5.11it/s, lr=9.73e-6, step_loss=0.603]07/18/2023 19:43:46 - INFO - __main__ - train loss is 7.337510936311446\n",
      "Steps:  42%|█▎ | 6338/15000 [40:23<28:12,  5.12it/s, lr=9.73e-6, step_loss=0.76]07/18/2023 19:43:46 - INFO - __main__ - train loss is 8.092704169801436\n",
      "Steps:  42%|▊ | 6339/15000 [40:24<28:10,  5.12it/s, lr=9.73e-6, step_loss=0.755]07/18/2023 19:43:46 - INFO - __main__ - train loss is 8.123666612780653\n",
      "Steps:  42%|▊ | 6340/15000 [40:24<27:52,  5.18it/s, lr=9.73e-6, step_loss=0.031]07/18/2023 19:43:46 - INFO - __main__ - train loss is 8.240262089646421\n",
      "Steps:  42%|▊ | 6341/15000 [40:24<27:28,  5.25it/s, lr=9.73e-6, step_loss=0.117]07/18/2023 19:43:46 - INFO - __main__ - train loss is 8.676599262631498\n",
      "Steps:  42%|▊ | 6342/15000 [40:24<27:05,  5.33it/s, lr=9.73e-6, step_loss=0.436]07/18/2023 19:43:46 - INFO - __main__ - train loss is 8.791015019989572\n",
      "Steps:  42%|▊ | 6343/15000 [40:24<27:13,  5.30it/s, lr=9.73e-6, step_loss=0.114]07/18/2023 19:43:47 - INFO - __main__ - train loss is 8.794822929543443\n",
      "Steps:  42%|▍| 6344/15000 [40:25<27:24,  5.26it/s, lr=9.73e-6, step_loss=0.0038107/18/2023 19:43:47 - INFO - __main__ - train loss is 8.823890682426281\n",
      "Steps:  42%|▍| 6345/15000 [40:25<27:36,  5.23it/s, lr=9.73e-6, step_loss=0.0291]07/18/2023 19:43:47 - INFO - __main__ - train loss is 9.039852168527432\n",
      "Steps:  42%|▊ | 6346/15000 [40:25<27:43,  5.20it/s, lr=9.73e-6, step_loss=0.216]07/18/2023 19:43:47 - INFO - __main__ - train loss is 9.541652288404293\n",
      "Steps:  42%|▊ | 6347/15000 [40:25<27:48,  5.19it/s, lr=9.73e-6, step_loss=0.502]07/18/2023 19:43:47 - INFO - __main__ - train loss is 9.883145179715939\n",
      "Steps:  42%|▊ | 6348/15000 [40:25<27:51,  5.18it/s, lr=9.73e-6, step_loss=0.341]07/18/2023 19:43:48 - INFO - __main__ - train loss is 9.996703188982792\n",
      "Steps:  42%|▊ | 6349/15000 [40:25<27:47,  5.19it/s, lr=9.73e-6, step_loss=0.114]07/18/2023 19:43:48 - INFO - __main__ - train loss is 10.848210197058506\n",
      "Steps:  42%|▊ | 6350/15000 [40:26<27:20,  5.27it/s, lr=9.73e-6, step_loss=0.852]07/18/2023 19:43:48 - INFO - __main__ - train loss is 11.316598337260075\n",
      "Steps:  42%|▊ | 6351/15000 [40:26<26:51,  5.37it/s, lr=9.73e-6, step_loss=0.468]07/18/2023 19:43:48 - INFO - __main__ - train loss is 11.58300862845499\n",
      "Steps:  42%|▊ | 6352/15000 [40:26<26:33,  5.43it/s, lr=9.73e-6, step_loss=0.266]07/18/2023 19:43:48 - INFO - __main__ - train loss is 11.588458581012674\n",
      "Steps:  42%|▍| 6353/15000 [40:26<26:18,  5.48it/s, lr=9.73e-6, step_loss=0.0054507/18/2023 19:43:49 - INFO - __main__ - train loss is 12.102323694271035\n",
      "Steps:  42%|▊ | 6354/15000 [40:26<26:07,  5.51it/s, lr=9.73e-6, step_loss=0.514]07/18/2023 19:43:49 - INFO - __main__ - train loss is 12.13316385273356\n",
      "Steps:  42%|▍| 6355/15000 [40:27<26:00,  5.54it/s, lr=9.73e-6, step_loss=0.0308]07/18/2023 19:43:49 - INFO - __main__ - train loss is 12.13534277875442\n",
      "Steps:  42%|▍| 6356/15000 [40:27<25:55,  5.56it/s, lr=9.73e-6, step_loss=0.0021807/18/2023 19:43:49 - INFO - __main__ - train loss is 12.199253538739868\n",
      "Steps:  42%|▍| 6357/15000 [40:27<25:52,  5.57it/s, lr=9.73e-6, step_loss=0.0639]07/18/2023 19:43:49 - INFO - __main__ - train loss is 12.212980986689217\n",
      "Steps:  42%|▍| 6358/15000 [40:27<26:04,  5.52it/s, lr=9.73e-6, step_loss=0.0137]07/18/2023 19:43:49 - INFO - __main__ - train loss is 12.417052955483086\n",
      "Steps:  42%|▊ | 6359/15000 [40:27<26:02,  5.53it/s, lr=9.73e-6, step_loss=0.204]07/18/2023 19:43:50 - INFO - __main__ - train loss is 12.490908713196404\n",
      "Steps:  42%|▍| 6360/15000 [40:27<25:55,  5.55it/s, lr=9.73e-6, step_loss=0.0739]07/18/2023 19:43:50 - INFO - __main__ - train loss is 13.420036883209832\n",
      "Steps:  42%|▊ | 6361/15000 [40:28<25:52,  5.56it/s, lr=9.73e-6, step_loss=0.929]07/18/2023 19:43:50 - INFO - __main__ - train loss is 13.423144059372135\n",
      "Steps:  42%|▍| 6362/15000 [40:28<25:49,  5.57it/s, lr=9.73e-6, step_loss=0.0031107/18/2023 19:43:50 - INFO - __main__ - train loss is 13.468448778730817\n",
      "Steps:  42%|▍| 6363/15000 [40:28<25:47,  5.58it/s, lr=9.73e-6, step_loss=0.0453]07/18/2023 19:43:50 - INFO - __main__ - train loss is 13.537251493078656\n",
      "Steps:  42%|▍| 6364/15000 [40:28<25:56,  5.55it/s, lr=9.73e-6, step_loss=0.0688]07/18/2023 19:43:50 - INFO - __main__ - train loss is 13.590397326392122\n",
      "Steps:  42%|▍| 6365/15000 [40:28<26:05,  5.52it/s, lr=9.73e-6, step_loss=0.0531]07/18/2023 19:43:51 - INFO - __main__ - train loss is 13.623755490523763\n",
      "Steps:  42%|▍| 6366/15000 [40:29<26:08,  5.51it/s, lr=9.73e-6, step_loss=0.0334]07/18/2023 19:43:51 - INFO - __main__ - train loss is 13.737337147933431\n",
      "Steps:  42%|▊ | 6367/15000 [40:29<26:01,  5.53it/s, lr=9.73e-6, step_loss=0.114]07/18/2023 19:43:51 - INFO - __main__ - train loss is 13.742600456462242\n",
      "Steps:  42%|▍| 6368/15000 [40:29<26:10,  5.50it/s, lr=9.73e-6, step_loss=0.0052607/18/2023 19:43:51 - INFO - __main__ - train loss is 13.75153117312584\n",
      "Steps:  42%|▍| 6369/15000 [40:29<26:16,  5.48it/s, lr=9.73e-6, step_loss=0.0089307/18/2023 19:43:51 - INFO - __main__ - train loss is 13.753698098589666\n",
      "Steps:  42%|▍| 6370/15000 [40:29<26:06,  5.51it/s, lr=9.73e-6, step_loss=0.0021707/18/2023 19:43:52 - INFO - __main__ - train loss is 13.882153543760069\n",
      "Steps:  42%|▊ | 6371/15000 [40:29<26:14,  5.48it/s, lr=9.73e-6, step_loss=0.128]07/18/2023 19:43:52 - INFO - __main__ - train loss is 14.419986578752287\n",
      "Steps:  42%|▊ | 6372/15000 [40:30<26:19,  5.46it/s, lr=9.73e-6, step_loss=0.538]07/18/2023 19:43:52 - INFO - __main__ - train loss is 14.425543151446618\n",
      "Steps:  42%|▍| 6373/15000 [40:30<26:23,  5.45it/s, lr=9.73e-6, step_loss=0.0055607/18/2023 19:43:52 - INFO - __main__ - train loss is 14.4588842127705\n",
      "Steps:  42%|▍| 6374/15000 [40:30<26:15,  5.48it/s, lr=9.73e-6, step_loss=0.0333]07/18/2023 19:43:52 - INFO - __main__ - train loss is 14.522527586319484\n",
      "Steps:  42%|▍| 6375/15000 [40:30<26:05,  5.51it/s, lr=9.73e-6, step_loss=0.0636]07/18/2023 19:43:52 - INFO - __main__ - train loss is 14.527152914204635\n",
      "Steps:  43%|▍| 6376/15000 [40:30<26:05,  5.51it/s, lr=9.73e-6, step_loss=0.0046307/18/2023 19:43:53 - INFO - __main__ - train loss is 14.582275140681304\n",
      "Steps:  43%|▍| 6377/15000 [40:31<25:57,  5.54it/s, lr=9.73e-6, step_loss=0.0551]07/18/2023 19:43:53 - INFO - __main__ - train loss is 15.13779674808029\n",
      "Steps:  43%|▊ | 6378/15000 [40:31<26:06,  5.50it/s, lr=9.72e-6, step_loss=0.556]07/18/2023 19:43:53 - INFO - __main__ - train loss is 15.577754962840118\n",
      "Steps:  43%|█▎ | 6379/15000 [40:31<26:03,  5.51it/s, lr=9.72e-6, step_loss=0.44]07/18/2023 19:43:53 - INFO - __main__ - train loss is 15.594395845779218\n",
      "Steps:  43%|▍| 6380/15000 [40:31<26:09,  5.49it/s, lr=9.72e-6, step_loss=0.0166]07/18/2023 19:43:53 - INFO - __main__ - train loss is 15.812196179875173\n",
      "Steps:  43%|▊ | 6381/15000 [40:31<26:01,  5.52it/s, lr=9.72e-6, step_loss=0.218]07/18/2023 19:43:54 - INFO - __main__ - train loss is 16.062853201874532\n",
      "Steps:  43%|▊ | 6382/15000 [40:31<25:54,  5.54it/s, lr=9.72e-6, step_loss=0.251]07/18/2023 19:43:54 - INFO - __main__ - train loss is 16.08666156756226\n",
      "Steps:  43%|▍| 6383/15000 [40:32<25:49,  5.56it/s, lr=9.72e-6, step_loss=0.0238]07/18/2023 19:43:54 - INFO - __main__ - train loss is 16.166449656360783\n",
      "Steps:  43%|▍| 6384/15000 [40:32<25:45,  5.58it/s, lr=9.72e-6, step_loss=0.0798]07/18/2023 19:43:54 - INFO - __main__ - train loss is 16.189525255584158\n",
      "Steps:  43%|▍| 6385/15000 [40:32<25:42,  5.58it/s, lr=9.72e-6, step_loss=0.0231]07/18/2023 19:43:54 - INFO - __main__ - train loss is 16.294059121632017\n",
      "Steps:  43%|▊ | 6386/15000 [40:32<25:40,  5.59it/s, lr=9.72e-6, step_loss=0.105]07/18/2023 19:43:54 - INFO - __main__ - train loss is 16.588913822197355\n",
      "Steps:  43%|▊ | 6387/15000 [40:32<25:38,  5.60it/s, lr=9.72e-6, step_loss=0.295]07/18/2023 19:43:55 - INFO - __main__ - train loss is 16.867597991251387\n",
      "Steps:  43%|▊ | 6388/15000 [40:33<25:37,  5.60it/s, lr=9.72e-6, step_loss=0.279]07/18/2023 19:43:55 - INFO - __main__ - train loss is 16.89349479752127\n",
      "Steps:  43%|▍| 6389/15000 [40:33<25:35,  5.61it/s, lr=9.72e-6, step_loss=0.0259]07/18/2023 19:43:55 - INFO - __main__ - train loss is 17.111948696547188\n",
      "Steps:  43%|▊ | 6390/15000 [40:33<25:34,  5.61it/s, lr=9.72e-6, step_loss=0.218]07/18/2023 19:43:55 - INFO - __main__ - train loss is 17.12392889673356\n",
      "Steps:  43%|▊ | 6391/15000 [40:33<25:34,  5.61it/s, lr=9.72e-6, step_loss=0.012]07/18/2023 19:43:55 - INFO - __main__ - train loss is 17.130904637859203\n",
      "Steps:  43%|▍| 6392/15000 [40:33<25:33,  5.61it/s, lr=9.72e-6, step_loss=0.0069807/18/2023 19:43:56 - INFO - __main__ - train loss is 17.161498724133708\n",
      "Steps:  43%|▍| 6393/15000 [40:33<25:45,  5.57it/s, lr=9.72e-6, step_loss=0.0306]07/18/2023 19:43:56 - INFO - __main__ - train loss is 17.295806481153704\n",
      "Steps:  43%|▊ | 6394/15000 [40:34<25:58,  5.52it/s, lr=9.72e-6, step_loss=0.134]07/18/2023 19:43:56 - INFO - __main__ - train loss is 17.297152089420706\n",
      "Steps:  43%|▍| 6395/15000 [40:34<25:53,  5.54it/s, lr=9.72e-6, step_loss=0.0013507/18/2023 19:43:56 - INFO - __main__ - train loss is 17.321859712246805\n",
      "Steps:  43%|▍| 6396/15000 [40:34<25:46,  5.56it/s, lr=9.72e-6, step_loss=0.0247]07/18/2023 19:43:56 - INFO - __main__ - train loss is 17.32500973972492\n",
      "Steps:  43%|▍| 6397/15000 [40:34<25:48,  5.55it/s, lr=9.72e-6, step_loss=0.0031507/18/2023 19:43:56 - INFO - __main__ - train loss is 17.665732300607488\n",
      "Steps:  43%|▊ | 6398/15000 [40:34<25:57,  5.52it/s, lr=9.72e-6, step_loss=0.341]07/18/2023 19:43:57 - INFO - __main__ - train loss is 17.721085401950404\n",
      "Steps:  43%|▍| 6399/15000 [40:35<25:54,  5.53it/s, lr=9.72e-6, step_loss=0.0554]07/18/2023 19:43:57 - INFO - __main__ - train loss is 17.73332482459955\n",
      "Steps:  43%|▍| 6400/15000 [40:35<25:47,  5.56it/s, lr=9.72e-6, step_loss=0.0122]07/18/2023 19:43:57 - INFO - __main__ - train loss is 17.80972947063856\n",
      "Steps:  43%|▍| 6401/15000 [40:35<25:48,  5.55it/s, lr=9.72e-6, step_loss=0.0764]07/18/2023 19:43:57 - INFO - __main__ - train loss is 17.84625024232082\n",
      "Steps:  43%|▍| 6402/15000 [40:35<35:29,  4.04it/s, lr=9.72e-6, step_loss=0.0365]07/18/2023 19:43:58 - INFO - __main__ - Per validation step average loss is 0.09800645709037781\n",
      "07/18/2023 19:43:58 - INFO - __main__ - Cumulative validation average loss is 0.09800645709037781\n",
      "07/18/2023 19:43:58 - INFO - __main__ - Per validation step average loss is 0.004459678195416927\n",
      "07/18/2023 19:43:58 - INFO - __main__ - Cumulative validation average loss is 0.10246613528579473\n",
      "07/18/2023 19:43:58 - INFO - __main__ - Per validation step average loss is 0.002937009558081627\n",
      "07/18/2023 19:43:58 - INFO - __main__ - Cumulative validation average loss is 0.10540314484387636\n",
      "07/18/2023 19:43:58 - INFO - __main__ - Per validation step average loss is 0.1498481184244156\n",
      "07/18/2023 19:43:58 - INFO - __main__ - Cumulative validation average loss is 0.25525126326829195\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Per validation step average loss is 0.05716995522379875\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Cumulative validation average loss is 0.3124212184920907\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Per validation step average loss is 0.002441906137391925\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Cumulative validation average loss is 0.3148631246294826\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Per validation step average loss is 0.0022376878187060356\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Cumulative validation average loss is 0.31710081244818866\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Per validation step average loss is 0.020644234493374825\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Cumulative validation average loss is 0.3377450469415635\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Per validation step average loss is 0.06028158217668533\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Cumulative validation average loss is 0.3980266291182488\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Per validation step average loss is 0.016919858753681183\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Cumulative validation average loss is 0.41494648787193\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Per validation step average loss is 0.02542860060930252\n",
      "07/18/2023 19:43:59 - INFO - __main__ - Cumulative validation average loss is 0.4403750884812325\n",
      "07/18/2023 19:44:00 - INFO - __main__ - Per validation step average loss is 0.0630948543548584\n",
      "07/18/2023 19:44:00 - INFO - __main__ - Cumulative validation average loss is 0.5034699428360909\n",
      "07/18/2023 19:44:00 - INFO - __main__ - Average validation loss for Epoch 65 is 0.041955828569674246\n",
      "07/18/2023 19:44:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:44:13 - INFO - __main__ - Starting epoch 66\n",
      "07/18/2023 19:44:13 - INFO - __main__ - train loss is 0.0030688608530908823\n",
      "Steps:  43%|▍| 6403/15000 [40:51<11:41:43,  4.90s/it, lr=9.72e-6, step_loss=0.0007/18/2023 19:44:13 - INFO - __main__ - train loss is 0.019017398590222\n",
      "Steps:  43%|▍| 6404/15000 [40:51<8:18:50,  3.48s/it, lr=9.72e-6, step_loss=0.01507/18/2023 19:44:13 - INFO - __main__ - train loss is 0.13280259096063673\n",
      "Steps:  43%|▍| 6405/15000 [40:51<5:56:50,  2.49s/it, lr=9.72e-6, step_loss=0.11407/18/2023 19:44:14 - INFO - __main__ - train loss is 0.13536453247070312\n",
      "Steps:  43%|▍| 6406/15000 [40:52<4:17:24,  1.80s/it, lr=9.72e-6, step_loss=0.00207/18/2023 19:44:14 - INFO - __main__ - train loss is 0.6203727126121521\n",
      "Steps:  43%|▍| 6407/15000 [40:52<3:07:56,  1.31s/it, lr=9.72e-6, step_loss=0.48507/18/2023 19:44:14 - INFO - __main__ - train loss is 0.6743570193648338\n",
      "Steps:  43%|▍| 6408/15000 [40:52<2:19:16,  1.03it/s, lr=9.72e-6, step_loss=0.05407/18/2023 19:44:14 - INFO - __main__ - train loss is 0.7306559756398201\n",
      "Steps:  43%|▍| 6409/15000 [40:52<1:45:08,  1.36it/s, lr=9.72e-6, step_loss=0.05607/18/2023 19:44:14 - INFO - __main__ - train loss is 0.732498362660408\n",
      "Steps:  43%|▍| 6410/15000 [40:52<1:21:14,  1.76it/s, lr=9.72e-6, step_loss=0.00107/18/2023 19:44:15 - INFO - __main__ - train loss is 0.7342101028189063\n",
      "Steps:  43%|▍| 6411/15000 [40:52<1:04:30,  2.22it/s, lr=9.72e-6, step_loss=0.00107/18/2023 19:44:15 - INFO - __main__ - train loss is 1.1347590377554297\n",
      "Steps:  43%|▊ | 6412/15000 [40:53<53:00,  2.70it/s, lr=9.72e-6, step_loss=0.401]07/18/2023 19:44:15 - INFO - __main__ - train loss is 1.5499590327963233\n",
      "Steps:  43%|▊ | 6413/15000 [40:53<44:44,  3.20it/s, lr=9.72e-6, step_loss=0.415]07/18/2023 19:44:15 - INFO - __main__ - train loss is 1.7629141202196479\n",
      "Steps:  43%|▊ | 6414/15000 [40:53<38:57,  3.67it/s, lr=9.72e-6, step_loss=0.213]07/18/2023 19:44:15 - INFO - __main__ - train loss is 1.765094282105565\n",
      "Steps:  43%|▍| 6415/15000 [40:53<34:55,  4.10it/s, lr=9.72e-6, step_loss=0.0021807/18/2023 19:44:15 - INFO - __main__ - train loss is 1.9246715176850557\n",
      "Steps:  43%|█▎ | 6416/15000 [40:53<32:08,  4.45it/s, lr=9.72e-6, step_loss=0.16]07/18/2023 19:44:16 - INFO - __main__ - train loss is 1.9736854899674654\n",
      "Steps:  43%|▊ | 6417/15000 [40:54<30:19,  4.72it/s, lr=9.72e-6, step_loss=0.049]07/18/2023 19:44:16 - INFO - __main__ - train loss is 1.9761161785572767\n",
      "Steps:  43%|▍| 6418/15000 [40:54<28:52,  4.95it/s, lr=9.72e-6, step_loss=0.0024307/18/2023 19:44:16 - INFO - __main__ - train loss is 2.209567306563258\n",
      "Steps:  43%|▊ | 6419/15000 [40:54<27:55,  5.12it/s, lr=9.72e-6, step_loss=0.233]07/18/2023 19:44:16 - INFO - __main__ - train loss is 2.401101289317012\n",
      "Steps:  43%|▊ | 6420/15000 [40:54<27:25,  5.21it/s, lr=9.72e-6, step_loss=0.192]07/18/2023 19:44:16 - INFO - __main__ - train loss is 2.940261660143733\n",
      "Steps:  43%|▊ | 6421/15000 [40:54<26:51,  5.32it/s, lr=9.72e-6, step_loss=0.539]07/18/2023 19:44:17 - INFO - __main__ - train loss is 3.382714269682765\n",
      "Steps:  43%|▊ | 6422/15000 [40:54<26:38,  5.37it/s, lr=9.72e-6, step_loss=0.442]07/18/2023 19:44:17 - INFO - __main__ - train loss is 3.3990956004709005\n",
      "Steps:  43%|▍| 6423/15000 [40:55<26:18,  5.43it/s, lr=9.72e-6, step_loss=0.0164]07/18/2023 19:44:17 - INFO - __main__ - train loss is 3.629377907142043\n",
      "Steps:  43%|█▎ | 6424/15000 [40:55<26:19,  5.43it/s, lr=9.72e-6, step_loss=0.23]07/18/2023 19:44:17 - INFO - __main__ - train loss is 3.7569823917001486\n",
      "Steps:  43%|▊ | 6425/15000 [40:55<26:19,  5.43it/s, lr=9.72e-6, step_loss=0.128]07/18/2023 19:44:17 - INFO - __main__ - train loss is 4.536583429202437\n",
      "Steps:  43%|█▎ | 6426/15000 [40:55<26:17,  5.44it/s, lr=9.72e-6, step_loss=0.78]07/18/2023 19:44:17 - INFO - __main__ - train loss is 4.83657712303102\n",
      "Steps:  43%|█▋  | 6427/15000 [40:55<26:17,  5.44it/s, lr=9.72e-6, step_loss=0.3]07/18/2023 19:44:18 - INFO - __main__ - train loss is 5.268084650859237\n",
      "Steps:  43%|▊ | 6428/15000 [40:56<26:03,  5.48it/s, lr=9.72e-6, step_loss=0.432]07/18/2023 19:44:18 - INFO - __main__ - train loss is 5.580635851249099\n",
      "Steps:  43%|▊ | 6429/15000 [40:56<25:54,  5.51it/s, lr=9.72e-6, step_loss=0.313]07/18/2023 19:44:18 - INFO - __main__ - train loss is 6.058216040953994\n",
      "Steps:  43%|▊ | 6430/15000 [40:56<25:58,  5.50it/s, lr=9.72e-6, step_loss=0.478]07/18/2023 19:44:18 - INFO - __main__ - train loss is 6.202312206849456\n",
      "Steps:  43%|▊ | 6431/15000 [40:56<25:58,  5.50it/s, lr=9.72e-6, step_loss=0.144]07/18/2023 19:44:18 - INFO - __main__ - train loss is 6.206407127901912\n",
      "Steps:  43%|▍| 6432/15000 [40:56<25:51,  5.52it/s, lr=9.72e-6, step_loss=0.0040907/18/2023 19:44:19 - INFO - __main__ - train loss is 6.25818089954555\n",
      "Steps:  43%|▍| 6433/15000 [40:56<25:45,  5.54it/s, lr=9.72e-6, step_loss=0.0518]07/18/2023 19:44:19 - INFO - __main__ - train loss is 6.26024409243837\n",
      "Steps:  43%|▍| 6434/15000 [40:57<25:41,  5.56it/s, lr=9.72e-6, step_loss=0.0020607/18/2023 19:44:19 - INFO - __main__ - train loss is 6.327785155270249\n",
      "Steps:  43%|▍| 6435/15000 [40:57<25:39,  5.57it/s, lr=9.72e-6, step_loss=0.0675]07/18/2023 19:44:19 - INFO - __main__ - train loss is 6.393049283418804\n",
      "Steps:  43%|▍| 6436/15000 [40:57<25:36,  5.57it/s, lr=9.72e-6, step_loss=0.0653]07/18/2023 19:44:19 - INFO - __main__ - train loss is 6.517362585756928\n",
      "Steps:  43%|▊ | 6437/15000 [40:57<25:35,  5.58it/s, lr=9.72e-6, step_loss=0.124]07/18/2023 19:44:19 - INFO - __main__ - train loss is 6.720051458571106\n",
      "Steps:  43%|▊ | 6438/15000 [40:57<25:33,  5.58it/s, lr=9.72e-6, step_loss=0.203]07/18/2023 19:44:20 - INFO - __main__ - train loss is 6.811388379428536\n",
      "Steps:  43%|▍| 6439/15000 [40:58<25:43,  5.55it/s, lr=9.72e-6, step_loss=0.0913]07/18/2023 19:44:20 - INFO - __main__ - train loss is 6.941019183490425\n",
      "Steps:  43%|█▎ | 6440/15000 [40:58<25:53,  5.51it/s, lr=9.72e-6, step_loss=0.13]07/18/2023 19:44:20 - INFO - __main__ - train loss is 7.466822928283364\n",
      "Steps:  43%|▊ | 6441/15000 [40:58<26:14,  5.44it/s, lr=9.72e-6, step_loss=0.526]07/18/2023 19:44:20 - INFO - __main__ - train loss is 7.7748468280769885\n",
      "Steps:  43%|▊ | 6442/15000 [40:58<26:27,  5.39it/s, lr=9.72e-6, step_loss=0.308]07/18/2023 19:44:20 - INFO - __main__ - train loss is 7.777602969668806\n",
      "Steps:  43%|▍| 6443/15000 [40:58<26:37,  5.36it/s, lr=9.72e-6, step_loss=0.0027607/18/2023 19:44:21 - INFO - __main__ - train loss is 7.780797038692981\n",
      "Steps:  43%|▍| 6444/15000 [40:58<26:36,  5.36it/s, lr=9.72e-6, step_loss=0.0031907/18/2023 19:44:21 - INFO - __main__ - train loss is 8.208650563377887\n",
      "Steps:  43%|▊ | 6445/15000 [40:59<26:29,  5.38it/s, lr=9.72e-6, step_loss=0.428]07/18/2023 19:44:21 - INFO - __main__ - train loss is 8.212323990883306\n",
      "Steps:  43%|▍| 6446/15000 [40:59<26:17,  5.42it/s, lr=9.72e-6, step_loss=0.0036707/18/2023 19:44:21 - INFO - __main__ - train loss is 8.214970325818285\n",
      "Steps:  43%|▍| 6447/15000 [40:59<26:15,  5.43it/s, lr=9.72e-6, step_loss=0.0026507/18/2023 19:44:21 - INFO - __main__ - train loss is 8.261385889491066\n",
      "Steps:  43%|▍| 6448/15000 [40:59<26:01,  5.48it/s, lr=9.72e-6, step_loss=0.0464]07/18/2023 19:44:21 - INFO - __main__ - train loss is 8.266010271152481\n",
      "Steps:  43%|▍| 6449/15000 [40:59<25:51,  5.51it/s, lr=9.72e-6, step_loss=0.0046207/18/2023 19:44:22 - INFO - __main__ - train loss is 8.281937192892656\n",
      "Steps:  43%|▍| 6450/15000 [41:00<25:43,  5.54it/s, lr=9.72e-6, step_loss=0.0159]07/18/2023 19:44:22 - INFO - __main__ - train loss is 8.410306732868776\n",
      "Steps:  43%|▊ | 6451/15000 [41:00<25:38,  5.56it/s, lr=9.72e-6, step_loss=0.128]07/18/2023 19:44:22 - INFO - __main__ - train loss is 8.607451509451494\n",
      "Steps:  43%|▊ | 6452/15000 [41:00<25:33,  5.57it/s, lr=9.72e-6, step_loss=0.197]07/18/2023 19:44:22 - INFO - __main__ - train loss is 8.61019674059935\n",
      "Steps:  43%|▍| 6453/15000 [41:00<25:31,  5.58it/s, lr=9.72e-6, step_loss=0.0027507/18/2023 19:44:22 - INFO - __main__ - train loss is 9.030073912115768\n",
      "Steps:  43%|█▎ | 6454/15000 [41:00<25:28,  5.59it/s, lr=9.72e-6, step_loss=0.42]07/18/2023 19:44:23 - INFO - __main__ - train loss is 9.071895976783708\n",
      "Steps:  43%|▍| 6455/15000 [41:00<25:28,  5.59it/s, lr=9.72e-6, step_loss=0.0418]07/18/2023 19:44:23 - INFO - __main__ - train loss is 9.582997937919572\n",
      "Steps:  43%|▊ | 6456/15000 [41:01<25:27,  5.59it/s, lr=9.72e-6, step_loss=0.511]07/18/2023 19:44:23 - INFO - __main__ - train loss is 9.625254550250247\n",
      "Steps:  43%|▍| 6457/15000 [41:01<25:27,  5.59it/s, lr=9.72e-6, step_loss=0.0423]07/18/2023 19:44:23 - INFO - __main__ - train loss is 9.806448334129527\n",
      "Steps:  43%|▊ | 6458/15000 [41:01<25:27,  5.59it/s, lr=9.72e-6, step_loss=0.181]07/18/2023 19:44:23 - INFO - __main__ - train loss is 9.852969681145623\n",
      "Steps:  43%|▍| 6459/15000 [41:01<25:27,  5.59it/s, lr=9.72e-6, step_loss=0.0465]07/18/2023 19:44:23 - INFO - __main__ - train loss is 9.880138849141076\n",
      "Steps:  43%|▍| 6460/15000 [41:01<25:26,  5.59it/s, lr=9.72e-6, step_loss=0.0272]07/18/2023 19:44:24 - INFO - __main__ - train loss is 9.953040425898507\n",
      "Steps:  43%|▍| 6461/15000 [41:02<25:25,  5.60it/s, lr=9.72e-6, step_loss=0.0729]07/18/2023 19:44:24 - INFO - __main__ - train loss is 10.170228903414682\n",
      "Steps:  43%|▊ | 6462/15000 [41:02<25:24,  5.60it/s, lr=9.72e-6, step_loss=0.217]07/18/2023 19:44:24 - INFO - __main__ - train loss is 10.234565538587049\n",
      "Steps:  43%|▍| 6463/15000 [41:02<25:25,  5.60it/s, lr=9.72e-6, step_loss=0.0643]07/18/2023 19:44:24 - INFO - __main__ - train loss is 10.299052019836381\n",
      "Steps:  43%|▍| 6464/15000 [41:02<25:25,  5.60it/s, lr=9.72e-6, step_loss=0.0645]07/18/2023 19:44:24 - INFO - __main__ - train loss is 10.526718293549493\n",
      "Steps:  43%|▊ | 6465/15000 [41:02<25:25,  5.60it/s, lr=9.72e-6, step_loss=0.228]07/18/2023 19:44:25 - INFO - __main__ - train loss is 10.568413150729612\n",
      "Steps:  43%|▍| 6466/15000 [41:02<25:24,  5.60it/s, lr=9.72e-6, step_loss=0.0417]07/18/2023 19:44:25 - INFO - __main__ - train loss is 10.597010518657044\n",
      "Steps:  43%|▍| 6467/15000 [41:03<25:24,  5.60it/s, lr=9.72e-6, step_loss=0.0286]07/18/2023 19:44:25 - INFO - __main__ - train loss is 10.645076829241589\n",
      "Steps:  43%|▍| 6468/15000 [41:03<25:24,  5.60it/s, lr=9.72e-6, step_loss=0.0481]07/18/2023 19:44:25 - INFO - __main__ - train loss is 10.904453235911205\n",
      "Steps:  43%|▊ | 6469/15000 [41:03<25:23,  5.60it/s, lr=9.72e-6, step_loss=0.259]07/18/2023 19:44:25 - INFO - __main__ - train loss is 10.968582469271496\n",
      "Steps:  43%|▍| 6470/15000 [41:03<25:22,  5.60it/s, lr=9.72e-6, step_loss=0.0641]07/18/2023 19:44:25 - INFO - __main__ - train loss is 10.991464236052707\n",
      "Steps:  43%|▍| 6471/15000 [41:03<25:23,  5.60it/s, lr=9.72e-6, step_loss=0.0229]07/18/2023 19:44:26 - INFO - __main__ - train loss is 10.994245789712295\n",
      "Steps:  43%|▍| 6472/15000 [41:03<25:23,  5.60it/s, lr=9.72e-6, step_loss=0.0027807/18/2023 19:44:26 - INFO - __main__ - train loss is 11.056209556525573\n",
      "Steps:  43%|▊ | 6473/15000 [41:04<25:23,  5.60it/s, lr=9.72e-6, step_loss=0.062]07/18/2023 19:44:26 - INFO - __main__ - train loss is 11.571619383757934\n",
      "Steps:  43%|▊ | 6474/15000 [41:04<25:23,  5.60it/s, lr=9.72e-6, step_loss=0.515]07/18/2023 19:44:26 - INFO - __main__ - train loss is 11.573033571592532\n",
      "Steps:  43%|▍| 6475/15000 [41:04<25:24,  5.59it/s, lr=9.72e-6, step_loss=0.0014107/18/2023 19:44:26 - INFO - __main__ - train loss is 11.790207803598605\n",
      "Steps:  43%|▊ | 6476/15000 [41:04<25:22,  5.60it/s, lr=9.72e-6, step_loss=0.217]07/18/2023 19:44:26 - INFO - __main__ - train loss is 12.102203339687549\n",
      "Steps:  43%|▊ | 6477/15000 [41:04<25:24,  5.59it/s, lr=9.72e-6, step_loss=0.312]07/18/2023 19:44:27 - INFO - __main__ - train loss is 12.182040632120334\n",
      "Steps:  43%|▍| 6478/15000 [41:05<25:23,  5.59it/s, lr=9.72e-6, step_loss=0.0798]07/18/2023 19:44:27 - INFO - __main__ - train loss is 12.581521869054995\n",
      "Steps:  43%|▊ | 6479/15000 [41:05<25:25,  5.59it/s, lr=9.72e-6, step_loss=0.399]07/18/2023 19:44:27 - INFO - __main__ - train loss is 12.586624749819748\n",
      "Steps:  43%|▍| 6480/15000 [41:05<25:24,  5.59it/s, lr=9.72e-6, step_loss=0.0051]07/18/2023 19:44:27 - INFO - __main__ - train loss is 12.705016896943562\n",
      "Steps:  43%|▊ | 6481/15000 [41:05<25:23,  5.59it/s, lr=9.72e-6, step_loss=0.118]07/18/2023 19:44:27 - INFO - __main__ - train loss is 12.86555893800687\n",
      "Steps:  43%|▊ | 6482/15000 [41:05<25:22,  5.59it/s, lr=9.72e-6, step_loss=0.161]07/18/2023 19:44:28 - INFO - __main__ - train loss is 12.91377583972644\n",
      "Steps:  43%|▍| 6483/15000 [41:05<25:22,  5.60it/s, lr=9.72e-6, step_loss=0.0482]07/18/2023 19:44:28 - INFO - __main__ - train loss is 12.971311473171227\n",
      "Steps:  43%|▍| 6484/15000 [41:06<25:30,  5.57it/s, lr=9.72e-6, step_loss=0.0575]07/18/2023 19:44:28 - INFO - __main__ - train loss is 13.11321438185405\n",
      "Steps:  43%|▊ | 6485/15000 [41:06<25:25,  5.58it/s, lr=9.72e-6, step_loss=0.142]07/18/2023 19:44:28 - INFO - __main__ - train loss is 13.115501101012342\n",
      "Steps:  43%|▍| 6486/15000 [41:06<25:23,  5.59it/s, lr=9.72e-6, step_loss=0.0022907/18/2023 19:44:28 - INFO - __main__ - train loss is 13.325096498127095\n",
      "Steps:  43%|█▎ | 6487/15000 [41:06<25:22,  5.59it/s, lr=9.72e-6, step_loss=0.21]07/18/2023 19:44:28 - INFO - __main__ - train loss is 13.381402435596101\n",
      "Steps:  43%|▍| 6488/15000 [41:06<25:20,  5.60it/s, lr=9.72e-6, step_loss=0.0563]07/18/2023 19:44:29 - INFO - __main__ - train loss is 13.543985697324388\n",
      "Steps:  43%|▊ | 6489/15000 [41:07<25:19,  5.60it/s, lr=9.72e-6, step_loss=0.163]07/18/2023 19:44:29 - INFO - __main__ - train loss is 13.559662374551408\n",
      "Steps:  43%|▍| 6490/15000 [41:07<25:19,  5.60it/s, lr=9.72e-6, step_loss=0.0157]07/18/2023 19:44:29 - INFO - __main__ - train loss is 13.683171543176286\n",
      "Steps:  43%|▊ | 6491/15000 [41:07<25:19,  5.60it/s, lr=9.72e-6, step_loss=0.124]07/18/2023 19:44:29 - INFO - __main__ - train loss is 13.686318816966377\n",
      "Steps:  43%|▍| 6492/15000 [41:07<25:18,  5.60it/s, lr=9.72e-6, step_loss=0.0031507/18/2023 19:44:29 - INFO - __main__ - train loss is 13.71824560908135\n",
      "Steps:  43%|▍| 6493/15000 [41:07<25:18,  5.60it/s, lr=9.72e-6, step_loss=0.0319]07/18/2023 19:44:30 - INFO - __main__ - train loss is 13.788862271583639\n",
      "Steps:  43%|▍| 6494/15000 [41:07<25:18,  5.60it/s, lr=9.71e-6, step_loss=0.0706]07/18/2023 19:44:30 - INFO - __main__ - train loss is 13.80187199858483\n",
      "Steps:  43%|▊ | 6495/15000 [41:08<25:17,  5.61it/s, lr=9.71e-6, step_loss=0.013]07/18/2023 19:44:30 - INFO - __main__ - train loss is 14.04977983084973\n",
      "Steps:  43%|▊ | 6496/15000 [41:08<25:16,  5.61it/s, lr=9.71e-6, step_loss=0.248]07/18/2023 19:44:30 - INFO - __main__ - train loss is 14.070108900195919\n",
      "Steps:  43%|▍| 6497/15000 [41:08<25:15,  5.61it/s, lr=9.71e-6, step_loss=0.0203]07/18/2023 19:44:30 - INFO - __main__ - train loss is 14.073269179905765\n",
      "Steps:  43%|▍| 6498/15000 [41:08<25:14,  5.61it/s, lr=9.71e-6, step_loss=0.0031607/18/2023 19:44:31 - INFO - __main__ - train loss is 14.089413382927887\n",
      "Steps:  43%|▍| 6499/15000 [41:08<33:26,  4.24it/s, lr=9.71e-6, step_loss=0.0161]07/18/2023 19:44:31 - INFO - __main__ - Per validation step average loss is 0.006339709740132093\n",
      "07/18/2023 19:44:31 - INFO - __main__ - Cumulative validation average loss is 0.006339709740132093\n",
      "07/18/2023 19:44:31 - INFO - __main__ - Per validation step average loss is 0.04659856855869293\n",
      "07/18/2023 19:44:31 - INFO - __main__ - Cumulative validation average loss is 0.052938278298825026\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.3578174114227295\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 0.4107556897215545\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.014870643615722656\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 0.4256263333372772\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.10814609378576279\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 0.53377242712304\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.04301255941390991\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 0.5767849865369499\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.007222268730401993\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 0.5840072552673519\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.17280954122543335\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 0.7568167964927852\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Per validation step average loss is 0.0030781584791839123\n",
      "07/18/2023 19:44:32 - INFO - __main__ - Cumulative validation average loss is 0.7598949549719691\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Per validation step average loss is 0.005668167024850845\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Cumulative validation average loss is 0.76556312199682\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Per validation step average loss is 0.0017965645529329777\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Cumulative validation average loss is 0.767359686549753\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Per validation step average loss is 0.14628966152668\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Cumulative validation average loss is 0.9136493480764329\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Average validation loss for Epoch 66 is 0.07613744567303608\n",
      "07/18/2023 19:44:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:44:46 - INFO - __main__ - Starting epoch 67\n",
      "07/18/2023 19:44:46 - INFO - __main__ - train loss is 0.001969594042748213\n",
      "Steps:  43%|▍| 6500/15000 [41:24<11:39:36,  4.94s/it, lr=9.71e-6, step_loss=0.0107/18/2023 19:44:47 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-6500\n",
      "07/18/2023 19:44:47 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:44:47,095] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:44:47,106] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-6500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:44:47,106] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-6500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:44:47,118] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-6500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:44:47,119] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-6500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:44:47,144] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-6500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:44:47,144] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-6500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:44:47,145] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:44:47 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-6500/pytorch_model\n",
      "07/18/2023 19:44:47 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-6500/scheduler.bin\n",
      "07/18/2023 19:44:47 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-6500/random_states_0.pkl\n",
      "07/18/2023 19:44:47 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-6500\n",
      "Steps:  43%|▍| 6500/15000 [41:24<11:39:36,  4.94s/it, lr=9.71e-6, step_loss=0.0007/18/2023 19:44:47 - INFO - __main__ - train loss is 0.0886872443370521\n",
      "Steps:  43%|▍| 6501/15000 [41:25<8:19:54,  3.53s/it, lr=9.71e-6, step_loss=0.08607/18/2023 19:44:47 - INFO - __main__ - train loss is 0.41497987834736705\n",
      "Steps:  43%|▍| 6502/15000 [41:25<5:58:05,  2.53s/it, lr=9.71e-6, step_loss=0.32607/18/2023 19:44:47 - INFO - __main__ - train loss is 0.837104085367173\n",
      "Steps:  43%|▍| 6503/15000 [41:25<4:18:54,  1.83s/it, lr=9.71e-6, step_loss=0.42207/18/2023 19:44:47 - INFO - __main__ - train loss is 0.8794719721190631\n",
      "Steps:  43%|▍| 6504/15000 [41:25<3:09:32,  1.34s/it, lr=9.71e-6, step_loss=0.04207/18/2023 19:44:48 - INFO - __main__ - train loss is 0.925658471416682\n",
      "Steps:  43%|▍| 6505/15000 [41:25<2:20:55,  1.00it/s, lr=9.71e-6, step_loss=0.04607/18/2023 19:44:48 - INFO - __main__ - train loss is 0.9435265804640949\n",
      "Steps:  43%|▍| 6506/15000 [41:26<1:46:15,  1.33it/s, lr=9.71e-6, step_loss=0.01707/18/2023 19:44:48 - INFO - __main__ - train loss is 1.1685264254920185\n",
      "Steps:  43%|▍| 6507/15000 [41:26<1:21:55,  1.73it/s, lr=9.71e-6, step_loss=0.22507/18/2023 19:44:48 - INFO - __main__ - train loss is 1.8682342912070453\n",
      "Steps:  43%|▊ | 6508/15000 [41:26<1:04:52,  2.18it/s, lr=9.71e-6, step_loss=0.7]07/18/2023 19:44:48 - INFO - __main__ - train loss is 2.1627710605971515\n",
      "Steps:  43%|▊ | 6509/15000 [41:26<52:57,  2.67it/s, lr=9.71e-6, step_loss=0.295]07/18/2023 19:44:48 - INFO - __main__ - train loss is 2.2459616134874523\n",
      "Steps:  43%|▍| 6510/15000 [41:26<44:38,  3.17it/s, lr=9.71e-6, step_loss=0.0832]07/18/2023 19:44:49 - INFO - __main__ - train loss is 2.2482843534089625\n",
      "Steps:  43%|▍| 6511/15000 [41:26<38:46,  3.65it/s, lr=9.71e-6, step_loss=0.0023207/18/2023 19:44:49 - INFO - __main__ - train loss is 2.2841282174922526\n",
      "Steps:  43%|▍| 6512/15000 [41:27<34:42,  4.08it/s, lr=9.71e-6, step_loss=0.0358]07/18/2023 19:44:49 - INFO - __main__ - train loss is 2.4056624681688845\n",
      "Steps:  43%|▊ | 6513/15000 [41:27<31:51,  4.44it/s, lr=9.71e-6, step_loss=0.122]07/18/2023 19:44:49 - INFO - __main__ - train loss is 2.410043349955231\n",
      "Steps:  43%|▍| 6514/15000 [41:27<29:55,  4.73it/s, lr=9.71e-6, step_loss=0.0043807/18/2023 19:44:49 - INFO - __main__ - train loss is 2.4124383409507573\n",
      "Steps:  43%|▍| 6515/15000 [41:27<28:28,  4.97it/s, lr=9.71e-6, step_loss=0.0023907/18/2023 19:44:49 - INFO - __main__ - train loss is 2.718733735848218\n",
      "Steps:  43%|▊ | 6516/15000 [41:27<27:28,  5.15it/s, lr=9.71e-6, step_loss=0.306]07/18/2023 19:44:50 - INFO - __main__ - train loss is 2.9052054514177144\n",
      "Steps:  43%|▊ | 6517/15000 [41:28<26:47,  5.28it/s, lr=9.71e-6, step_loss=0.186]07/18/2023 19:44:50 - INFO - __main__ - train loss is 2.9168832101859152\n",
      "Steps:  43%|▍| 6518/15000 [41:28<26:18,  5.37it/s, lr=9.71e-6, step_loss=0.0117]07/18/2023 19:44:50 - INFO - __main__ - train loss is 3.0136059024371207\n",
      "Steps:  43%|▍| 6519/15000 [41:28<25:59,  5.44it/s, lr=9.71e-6, step_loss=0.0967]07/18/2023 19:44:50 - INFO - __main__ - train loss is 3.026921888347715\n",
      "Steps:  43%|▍| 6520/15000 [41:28<25:45,  5.49it/s, lr=9.71e-6, step_loss=0.0133]07/18/2023 19:44:50 - INFO - __main__ - train loss is 3.1231772056780756\n",
      "Steps:  43%|▍| 6521/15000 [41:28<25:35,  5.52it/s, lr=9.71e-6, step_loss=0.0963]07/18/2023 19:44:51 - INFO - __main__ - train loss is 3.1617524824105203\n",
      "Steps:  43%|▍| 6522/15000 [41:28<25:28,  5.55it/s, lr=9.71e-6, step_loss=0.0386]07/18/2023 19:44:51 - INFO - __main__ - train loss is 3.164906089892611\n",
      "Steps:  43%|▍| 6523/15000 [41:29<25:23,  5.56it/s, lr=9.71e-6, step_loss=0.0031507/18/2023 19:44:51 - INFO - __main__ - train loss is 3.166396030690521\n",
      "Steps:  43%|▍| 6524/15000 [41:29<25:18,  5.58it/s, lr=9.71e-6, step_loss=0.0014907/18/2023 19:44:51 - INFO - __main__ - train loss is 3.509912261273712\n",
      "Steps:  44%|▊ | 6525/15000 [41:29<25:16,  5.59it/s, lr=9.71e-6, step_loss=0.344]07/18/2023 19:44:51 - INFO - __main__ - train loss is 3.819121429231018\n",
      "Steps:  44%|▊ | 6526/15000 [41:29<25:15,  5.59it/s, lr=9.71e-6, step_loss=0.309]07/18/2023 19:44:51 - INFO - __main__ - train loss is 3.8242009873501956\n",
      "Steps:  44%|▍| 6527/15000 [41:29<25:14,  5.60it/s, lr=9.71e-6, step_loss=0.0050807/18/2023 19:44:52 - INFO - __main__ - train loss is 3.826584856957197\n",
      "Steps:  44%|▍| 6528/15000 [41:30<25:12,  5.60it/s, lr=9.71e-6, step_loss=0.0023807/18/2023 19:44:52 - INFO - __main__ - train loss is 4.397791367024183\n",
      "Steps:  44%|▊ | 6529/15000 [41:30<25:23,  5.56it/s, lr=9.71e-6, step_loss=0.571]07/18/2023 19:44:52 - INFO - __main__ - train loss is 4.4918950535357\n",
      "Steps:  44%|▍| 6530/15000 [41:30<25:19,  5.57it/s, lr=9.71e-6, step_loss=0.0941]07/18/2023 19:44:52 - INFO - __main__ - train loss is 4.522114224731922\n",
      "Steps:  44%|▍| 6531/15000 [41:30<25:16,  5.58it/s, lr=9.71e-6, step_loss=0.0302]07/18/2023 19:44:52 - INFO - __main__ - train loss is 4.754053987562656\n",
      "Steps:  44%|▊ | 6532/15000 [41:30<25:14,  5.59it/s, lr=9.71e-6, step_loss=0.232]07/18/2023 19:44:53 - INFO - __main__ - train loss is 4.858080558478832\n",
      "Steps:  44%|▊ | 6533/15000 [41:30<25:13,  5.60it/s, lr=9.71e-6, step_loss=0.104]07/18/2023 19:44:53 - INFO - __main__ - train loss is 4.91088280081749\n",
      "Steps:  44%|▍| 6534/15000 [41:31<25:12,  5.60it/s, lr=9.71e-6, step_loss=0.0528]07/18/2023 19:44:53 - INFO - __main__ - train loss is 5.348083883523941\n",
      "Steps:  44%|▊ | 6535/15000 [41:31<25:23,  5.55it/s, lr=9.71e-6, step_loss=0.437]07/18/2023 19:44:53 - INFO - __main__ - train loss is 5.44575834274292\n",
      "Steps:  44%|▍| 6536/15000 [41:31<25:19,  5.57it/s, lr=9.71e-6, step_loss=0.0977]07/18/2023 19:44:53 - INFO - __main__ - train loss is 5.846506953239441\n",
      "Steps:  44%|▊ | 6537/15000 [41:31<25:15,  5.58it/s, lr=9.71e-6, step_loss=0.401]07/18/2023 19:44:53 - INFO - __main__ - train loss is 6.006342843174934\n",
      "Steps:  44%|█▎ | 6538/15000 [41:31<25:36,  5.51it/s, lr=9.71e-6, step_loss=0.16]07/18/2023 19:44:54 - INFO - __main__ - train loss is 6.016422023996711\n",
      "Steps:  44%|▍| 6539/15000 [41:32<27:38,  5.10it/s, lr=9.71e-6, step_loss=0.0101]07/18/2023 19:44:54 - INFO - __main__ - train loss is 6.472207417711616\n",
      "Steps:  44%|▊ | 6540/15000 [41:32<27:37,  5.10it/s, lr=9.71e-6, step_loss=0.456]07/18/2023 19:44:54 - INFO - __main__ - train loss is 7.226912250742316\n",
      "Steps:  44%|▊ | 6541/15000 [41:32<26:54,  5.24it/s, lr=9.71e-6, step_loss=0.755]07/18/2023 19:44:54 - INFO - __main__ - train loss is 7.26296522282064\n",
      "Steps:  44%|▍| 6542/15000 [41:32<26:25,  5.33it/s, lr=9.71e-6, step_loss=0.0361]07/18/2023 19:44:54 - INFO - __main__ - train loss is 7.265068519860506\n",
      "Steps:  44%|▍| 6543/15000 [41:32<26:05,  5.40it/s, lr=9.71e-6, step_loss=0.0021]07/18/2023 19:44:55 - INFO - __main__ - train loss is 7.369949195533991\n",
      "Steps:  44%|▊ | 6544/15000 [41:32<25:50,  5.45it/s, lr=9.71e-6, step_loss=0.105]07/18/2023 19:44:55 - INFO - __main__ - train loss is 7.627076301723719\n",
      "Steps:  44%|▊ | 6545/15000 [41:33<25:38,  5.50it/s, lr=9.71e-6, step_loss=0.257]07/18/2023 19:44:55 - INFO - __main__ - train loss is 7.860916916280985\n",
      "Steps:  44%|▊ | 6546/15000 [41:33<25:30,  5.53it/s, lr=9.71e-6, step_loss=0.234]07/18/2023 19:44:55 - INFO - __main__ - train loss is 7.869152718223631\n",
      "Steps:  44%|▍| 6547/15000 [41:33<25:23,  5.55it/s, lr=9.71e-6, step_loss=0.0082407/18/2023 19:44:55 - INFO - __main__ - train loss is 8.038340442813933\n",
      "Steps:  44%|▊ | 6548/15000 [41:33<25:18,  5.57it/s, lr=9.71e-6, step_loss=0.169]07/18/2023 19:44:55 - INFO - __main__ - train loss is 8.067744360305369\n",
      "Steps:  44%|▍| 6549/15000 [41:33<25:14,  5.58it/s, lr=9.71e-6, step_loss=0.0294]07/18/2023 19:44:56 - INFO - __main__ - train loss is 8.409431830979884\n",
      "Steps:  44%|▊ | 6550/15000 [41:34<25:16,  5.57it/s, lr=9.71e-6, step_loss=0.342]07/18/2023 19:44:56 - INFO - __main__ - train loss is 8.461142835207283\n",
      "Steps:  44%|▍| 6551/15000 [41:34<25:14,  5.58it/s, lr=9.71e-6, step_loss=0.0517]07/18/2023 19:44:56 - INFO - __main__ - train loss is 8.610091728158295\n",
      "Steps:  44%|▊ | 6552/15000 [41:34<25:48,  5.46it/s, lr=9.71e-6, step_loss=0.149]07/18/2023 19:44:56 - INFO - __main__ - train loss is 8.986197245307267\n",
      "Steps:  44%|▊ | 6553/15000 [41:34<27:37,  5.10it/s, lr=9.71e-6, step_loss=0.376]07/18/2023 19:44:56 - INFO - __main__ - train loss is 9.05015289504081\n",
      "Steps:  44%|▊ | 6554/15000 [41:34<28:43,  4.90it/s, lr=9.71e-6, step_loss=0.064]07/18/2023 19:44:57 - INFO - __main__ - train loss is 9.052682060748339\n",
      "Steps:  44%|▍| 6555/15000 [41:35<29:28,  4.78it/s, lr=9.71e-6, step_loss=0.0025307/18/2023 19:44:57 - INFO - __main__ - train loss is 9.112643279135227\n",
      "Steps:  44%|█▎ | 6556/15000 [41:35<29:52,  4.71it/s, lr=9.71e-6, step_loss=0.06]07/18/2023 19:44:57 - INFO - __main__ - train loss is 9.119123183190823\n",
      "Steps:  44%|▍| 6557/15000 [41:35<30:07,  4.67it/s, lr=9.71e-6, step_loss=0.0064807/18/2023 19:44:57 - INFO - __main__ - train loss is 9.159601245075464\n",
      "Steps:  44%|▍| 6558/15000 [41:35<29:47,  4.72it/s, lr=9.71e-6, step_loss=0.0405]07/18/2023 19:44:58 - INFO - __main__ - train loss is 9.172876144759357\n",
      "Steps:  44%|▍| 6559/15000 [41:35<28:29,  4.94it/s, lr=9.71e-6, step_loss=0.0133]07/18/2023 19:44:58 - INFO - __main__ - train loss is 9.18050009245053\n",
      "Steps:  44%|▍| 6560/15000 [41:36<27:26,  5.13it/s, lr=9.71e-6, step_loss=0.0076207/18/2023 19:44:58 - INFO - __main__ - train loss is 9.20523194829002\n",
      "Steps:  44%|▍| 6561/15000 [41:36<26:43,  5.26it/s, lr=9.71e-6, step_loss=0.0247]07/18/2023 19:44:58 - INFO - __main__ - train loss is 9.362262709531933\n",
      "Steps:  44%|▊ | 6562/15000 [41:36<26:12,  5.37it/s, lr=9.71e-6, step_loss=0.157]07/18/2023 19:44:58 - INFO - __main__ - train loss is 9.364980580285192\n",
      "Steps:  44%|▍| 6563/15000 [41:36<25:50,  5.44it/s, lr=9.71e-6, step_loss=0.0027207/18/2023 19:44:58 - INFO - __main__ - train loss is 9.366978607140481\n",
      "Steps:  44%|▉ | 6564/15000 [41:36<25:34,  5.50it/s, lr=9.71e-6, step_loss=0.002]07/18/2023 19:44:59 - INFO - __main__ - train loss is 9.371859122999012\n",
      "Steps:  44%|▍| 6565/15000 [41:36<25:23,  5.54it/s, lr=9.71e-6, step_loss=0.0048807/18/2023 19:44:59 - INFO - __main__ - train loss is 9.421644196845591\n",
      "Steps:  44%|▍| 6566/15000 [41:37<25:16,  5.56it/s, lr=9.71e-6, step_loss=0.0498]07/18/2023 19:44:59 - INFO - __main__ - train loss is 9.456792772747576\n",
      "Steps:  44%|▍| 6567/15000 [41:37<25:10,  5.58it/s, lr=9.71e-6, step_loss=0.0351]07/18/2023 19:44:59 - INFO - __main__ - train loss is 9.461639743298292\n",
      "Steps:  44%|▍| 6568/15000 [41:37<25:06,  5.60it/s, lr=9.71e-6, step_loss=0.0048507/18/2023 19:44:59 - INFO - __main__ - train loss is 9.463565005455166\n",
      "Steps:  44%|▍| 6569/15000 [41:37<25:04,  5.60it/s, lr=9.71e-6, step_loss=0.0019307/18/2023 19:44:59 - INFO - __main__ - train loss is 9.639426423702389\n",
      "Steps:  44%|▉ | 6570/15000 [41:37<25:04,  5.60it/s, lr=9.71e-6, step_loss=0.176]07/18/2023 19:45:00 - INFO - __main__ - train loss is 9.968728913459927\n",
      "Steps:  44%|▉ | 6571/15000 [41:38<25:02,  5.61it/s, lr=9.71e-6, step_loss=0.329]07/18/2023 19:45:00 - INFO - __main__ - train loss is 10.10755209485069\n",
      "Steps:  44%|▉ | 6572/15000 [41:38<25:01,  5.61it/s, lr=9.71e-6, step_loss=0.139]07/18/2023 19:45:00 - INFO - __main__ - train loss is 10.111926967278123\n",
      "Steps:  44%|▍| 6573/15000 [41:38<25:03,  5.61it/s, lr=9.71e-6, step_loss=0.0043707/18/2023 19:45:00 - INFO - __main__ - train loss is 10.320894772186875\n",
      "Steps:  44%|▉ | 6574/15000 [41:38<25:03,  5.61it/s, lr=9.71e-6, step_loss=0.209]07/18/2023 19:45:00 - INFO - __main__ - train loss is 10.693759614601731\n",
      "Steps:  44%|▉ | 6575/15000 [41:38<25:04,  5.60it/s, lr=9.71e-6, step_loss=0.373]07/18/2023 19:45:01 - INFO - __main__ - train loss is 10.698446016293019\n",
      "Steps:  44%|▍| 6576/15000 [41:38<25:03,  5.60it/s, lr=9.71e-6, step_loss=0.0046907/18/2023 19:45:01 - INFO - __main__ - train loss is 10.701382556464523\n",
      "Steps:  44%|▍| 6577/15000 [41:39<25:04,  5.60it/s, lr=9.71e-6, step_loss=0.0029407/18/2023 19:45:01 - INFO - __main__ - train loss is 11.617633023764938\n",
      "Steps:  44%|▉ | 6578/15000 [41:39<25:03,  5.60it/s, lr=9.71e-6, step_loss=0.916]07/18/2023 19:45:01 - INFO - __main__ - train loss is 12.071140506770462\n",
      "Steps:  44%|▉ | 6579/15000 [41:39<25:01,  5.61it/s, lr=9.71e-6, step_loss=0.454]07/18/2023 19:45:01 - INFO - __main__ - train loss is 12.090026296209544\n",
      "Steps:  44%|▍| 6580/15000 [41:39<24:58,  5.62it/s, lr=9.71e-6, step_loss=0.0189]07/18/2023 19:45:01 - INFO - __main__ - train loss is 12.538070089649409\n",
      "Steps:  44%|▉ | 6581/15000 [41:39<24:57,  5.62it/s, lr=9.71e-6, step_loss=0.448]07/18/2023 19:45:02 - INFO - __main__ - train loss is 12.53981833846774\n",
      "Steps:  44%|▍| 6582/15000 [41:39<24:56,  5.63it/s, lr=9.71e-6, step_loss=0.0017507/18/2023 19:45:02 - INFO - __main__ - train loss is 12.680398456170224\n",
      "Steps:  44%|▉ | 6583/15000 [41:40<24:55,  5.63it/s, lr=9.71e-6, step_loss=0.141]07/18/2023 19:45:02 - INFO - __main__ - train loss is 12.686300139757805\n",
      "Steps:  44%|▍| 6584/15000 [41:40<24:54,  5.63it/s, lr=9.71e-6, step_loss=0.0059]07/18/2023 19:45:02 - INFO - __main__ - train loss is 13.135106664034538\n",
      "Steps:  44%|▉ | 6585/15000 [41:40<24:53,  5.63it/s, lr=9.71e-6, step_loss=0.449]07/18/2023 19:45:02 - INFO - __main__ - train loss is 13.299690779182129\n",
      "Steps:  44%|▉ | 6586/15000 [41:40<24:53,  5.63it/s, lr=9.71e-6, step_loss=0.165]07/18/2023 19:45:02 - INFO - __main__ - train loss is 13.303989904350601\n",
      "Steps:  44%|▍| 6587/15000 [41:40<25:02,  5.60it/s, lr=9.71e-6, step_loss=0.0043]07/18/2023 19:45:03 - INFO - __main__ - train loss is 13.328271421021782\n",
      "Steps:  44%|▍| 6588/15000 [41:41<24:59,  5.61it/s, lr=9.71e-6, step_loss=0.0243]07/18/2023 19:45:03 - INFO - __main__ - train loss is 13.331414843327366\n",
      "Steps:  44%|▍| 6589/15000 [41:41<24:57,  5.62it/s, lr=9.71e-6, step_loss=0.0031407/18/2023 19:45:03 - INFO - __main__ - train loss is 13.67233505321201\n",
      "Steps:  44%|▉ | 6590/15000 [41:41<24:55,  5.62it/s, lr=9.71e-6, step_loss=0.341]07/18/2023 19:45:03 - INFO - __main__ - train loss is 13.772710899240337\n",
      "Steps:  44%|█▊  | 6591/15000 [41:41<24:55,  5.62it/s, lr=9.71e-6, step_loss=0.1]07/18/2023 19:45:03 - INFO - __main__ - train loss is 13.812175626284443\n",
      "Steps:  44%|▍| 6592/15000 [41:41<24:54,  5.63it/s, lr=9.71e-6, step_loss=0.0395]07/18/2023 19:45:04 - INFO - __main__ - train loss is 14.355169887072407\n",
      "Steps:  44%|▉ | 6593/15000 [41:41<24:53,  5.63it/s, lr=9.71e-6, step_loss=0.543]07/18/2023 19:45:04 - INFO - __main__ - train loss is 14.423320593661629\n",
      "Steps:  44%|▍| 6594/15000 [41:42<24:52,  5.63it/s, lr=9.71e-6, step_loss=0.0682]07/18/2023 19:45:04 - INFO - __main__ - train loss is 14.425758508383296\n",
      "Steps:  44%|▍| 6595/15000 [41:42<24:52,  5.63it/s, lr=9.71e-6, step_loss=0.0024407/18/2023 19:45:04 - INFO - __main__ - train loss is 14.429167966241948\n",
      "Steps:  44%|▍| 6596/15000 [41:42<33:18,  4.21it/s, lr=9.71e-6, step_loss=0.0034107/18/2023 19:45:05 - INFO - __main__ - Per validation step average loss is 0.22083213925361633\n",
      "07/18/2023 19:45:05 - INFO - __main__ - Cumulative validation average loss is 0.22083213925361633\n",
      "07/18/2023 19:45:05 - INFO - __main__ - Per validation step average loss is 0.2550816535949707\n",
      "07/18/2023 19:45:05 - INFO - __main__ - Cumulative validation average loss is 0.47591379284858704\n",
      "07/18/2023 19:45:05 - INFO - __main__ - Per validation step average loss is 0.47812268137931824\n",
      "07/18/2023 19:45:05 - INFO - __main__ - Cumulative validation average loss is 0.9540364742279053\n",
      "07/18/2023 19:45:05 - INFO - __main__ - Per validation step average loss is 0.02748088352382183\n",
      "07/18/2023 19:45:05 - INFO - __main__ - Cumulative validation average loss is 0.9815173577517271\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Per validation step average loss is 0.15037839114665985\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Cumulative validation average loss is 1.131895748898387\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Per validation step average loss is 0.2306067943572998\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Cumulative validation average loss is 1.3625025432556868\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Per validation step average loss is 0.21159033477306366\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Cumulative validation average loss is 1.5740928780287504\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Per validation step average loss is 0.06294450163841248\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Cumulative validation average loss is 1.637037379667163\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Per validation step average loss is 0.010668054223060608\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Cumulative validation average loss is 1.6477054338902235\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Per validation step average loss is 0.004071138333529234\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Cumulative validation average loss is 1.6517765722237527\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Per validation step average loss is 0.03592380881309509\n",
      "07/18/2023 19:45:06 - INFO - __main__ - Cumulative validation average loss is 1.6877003810368478\n",
      "07/18/2023 19:45:07 - INFO - __main__ - Per validation step average loss is 0.02613115683197975\n",
      "07/18/2023 19:45:07 - INFO - __main__ - Cumulative validation average loss is 1.7138315378688276\n",
      "07/18/2023 19:45:07 - INFO - __main__ - Average validation loss for Epoch 67 is 0.1428192948224023\n",
      "07/18/2023 19:45:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:45:19 - INFO - __main__ - Starting epoch 68\n",
      "07/18/2023 19:45:20 - INFO - __main__ - train loss is 0.6241411566734314\n",
      "Steps:  44%|▍| 6597/15000 [41:58<11:24:14,  4.89s/it, lr=9.71e-6, step_loss=0.6207/18/2023 19:45:20 - INFO - __main__ - train loss is 0.6707810238003731\n",
      "Steps:  44%|▍| 6598/15000 [41:58<8:06:25,  3.47s/it, lr=9.71e-6, step_loss=0.04607/18/2023 19:45:20 - INFO - __main__ - train loss is 0.8321074470877647\n",
      "Steps:  44%|▍| 6599/15000 [41:58<5:48:00,  2.49s/it, lr=9.71e-6, step_loss=0.16107/18/2023 19:45:21 - INFO - __main__ - train loss is 1.0008508935570717\n",
      "Steps:  44%|▍| 6600/15000 [41:58<4:12:00,  1.80s/it, lr=9.71e-6, step_loss=0.16907/18/2023 19:45:21 - INFO - __main__ - train loss is 1.1650345250964165\n",
      "Steps:  44%|▍| 6601/15000 [41:59<3:04:20,  1.32s/it, lr=9.71e-6, step_loss=0.16407/18/2023 19:45:21 - INFO - __main__ - train loss is 1.167530020000413\n",
      "Steps:  44%|▍| 6602/15000 [41:59<2:17:46,  1.02it/s, lr=9.71e-6, step_loss=0.00207/18/2023 19:45:21 - INFO - __main__ - train loss is 1.188318581553176\n",
      "Steps:  44%|▍| 6603/15000 [41:59<1:44:13,  1.34it/s, lr=9.71e-6, step_loss=0.02007/18/2023 19:45:21 - INFO - __main__ - train loss is 1.4711189579684287\n",
      "Steps:  44%|▍| 6604/15000 [41:59<1:20:29,  1.74it/s, lr=9.71e-6, step_loss=0.28307/18/2023 19:45:22 - INFO - __main__ - train loss is 1.6189835381228477\n",
      "Steps:  44%|▍| 6605/15000 [41:59<1:04:03,  2.18it/s, lr=9.71e-6, step_loss=0.14807/18/2023 19:45:22 - INFO - __main__ - train loss is 1.626730118645355\n",
      "Steps:  44%|▍| 6606/15000 [42:00<52:21,  2.67it/s, lr=9.71e-6, step_loss=0.0077507/18/2023 19:45:22 - INFO - __main__ - train loss is 1.6562581181060523\n",
      "Steps:  44%|▍| 6607/15000 [42:00<44:21,  3.15it/s, lr=9.71e-6, step_loss=0.0295]07/18/2023 19:45:22 - INFO - __main__ - train loss is 1.7850715040694922\n",
      "Steps:  44%|█▎ | 6608/15000 [42:00<38:34,  3.63it/s, lr=9.7e-6, step_loss=0.129]07/18/2023 19:45:22 - INFO - __main__ - train loss is 1.9551675736438483\n",
      "Steps:  44%|█▊  | 6609/15000 [42:00<34:28,  4.06it/s, lr=9.7e-6, step_loss=0.17]07/18/2023 19:45:22 - INFO - __main__ - train loss is 2.291369628859684\n",
      "Steps:  44%|█▎ | 6610/15000 [42:00<31:35,  4.43it/s, lr=9.7e-6, step_loss=0.336]07/18/2023 19:45:23 - INFO - __main__ - train loss is 2.325227726949379\n",
      "Steps:  44%|▉ | 6611/15000 [42:00<29:38,  4.72it/s, lr=9.7e-6, step_loss=0.0339]07/18/2023 19:45:23 - INFO - __main__ - train loss is 2.6962795450817794\n",
      "Steps:  44%|█▎ | 6612/15000 [42:01<28:12,  4.96it/s, lr=9.7e-6, step_loss=0.371]07/18/2023 19:45:23 - INFO - __main__ - train loss is 3.0875313475262374\n",
      "Steps:  44%|█▎ | 6613/15000 [42:01<27:12,  5.14it/s, lr=9.7e-6, step_loss=0.391]07/18/2023 19:45:23 - INFO - __main__ - train loss is 3.107089702738449\n",
      "Steps:  44%|▉ | 6614/15000 [42:01<26:30,  5.27it/s, lr=9.7e-6, step_loss=0.0196]07/18/2023 19:45:23 - INFO - __main__ - train loss is 3.745826844824478\n",
      "Steps:  44%|█▎ | 6615/15000 [42:01<26:04,  5.36it/s, lr=9.7e-6, step_loss=0.639]07/18/2023 19:45:23 - INFO - __main__ - train loss is 3.7785160213243216\n",
      "Steps:  44%|▉ | 6616/15000 [42:01<25:44,  5.43it/s, lr=9.7e-6, step_loss=0.0327]07/18/2023 19:45:24 - INFO - __main__ - train loss is 3.808764402521774\n",
      "Steps:  44%|▉ | 6617/15000 [42:02<25:29,  5.48it/s, lr=9.7e-6, step_loss=0.0302]07/18/2023 19:45:24 - INFO - __main__ - train loss is 3.84299908275716\n",
      "Steps:  44%|▉ | 6618/15000 [42:02<25:18,  5.52it/s, lr=9.7e-6, step_loss=0.0342]07/18/2023 19:45:24 - INFO - __main__ - train loss is 3.8725827380549163\n",
      "Steps:  44%|▉ | 6619/15000 [42:02<25:11,  5.54it/s, lr=9.7e-6, step_loss=0.0296]07/18/2023 19:45:24 - INFO - __main__ - train loss is 4.050350372446701\n",
      "Steps:  44%|█▎ | 6620/15000 [42:02<25:05,  5.57it/s, lr=9.7e-6, step_loss=0.178]07/18/2023 19:45:24 - INFO - __main__ - train loss is 4.095172029687092\n",
      "Steps:  44%|▉ | 6621/15000 [42:02<25:03,  5.57it/s, lr=9.7e-6, step_loss=0.0448]07/18/2023 19:45:25 - INFO - __main__ - train loss is 4.135508035076782\n",
      "Steps:  44%|▉ | 6622/15000 [42:02<25:00,  5.58it/s, lr=9.7e-6, step_loss=0.0403]07/18/2023 19:45:25 - INFO - __main__ - train loss is 4.195972029818222\n",
      "Steps:  44%|▉ | 6623/15000 [42:03<24:58,  5.59it/s, lr=9.7e-6, step_loss=0.0605]07/18/2023 19:45:25 - INFO - __main__ - train loss is 4.245968402130529\n",
      "Steps:  44%|█▊  | 6624/15000 [42:03<24:56,  5.60it/s, lr=9.7e-6, step_loss=0.05]07/18/2023 19:45:25 - INFO - __main__ - train loss is 4.307825137628242\n",
      "Steps:  44%|▉ | 6625/15000 [42:03<24:55,  5.60it/s, lr=9.7e-6, step_loss=0.0619]07/18/2023 19:45:25 - INFO - __main__ - train loss is 4.337361554382369\n",
      "Steps:  44%|▉ | 6626/15000 [42:03<24:55,  5.60it/s, lr=9.7e-6, step_loss=0.0295]07/18/2023 19:45:25 - INFO - __main__ - train loss is 4.378698910353705\n",
      "Steps:  44%|▉ | 6627/15000 [42:03<24:57,  5.59it/s, lr=9.7e-6, step_loss=0.0413]07/18/2023 19:45:26 - INFO - __main__ - train loss is 4.720719541190192\n",
      "Steps:  44%|█▎ | 6628/15000 [42:04<24:54,  5.60it/s, lr=9.7e-6, step_loss=0.342]07/18/2023 19:45:26 - INFO - __main__ - train loss is 4.790836955187842\n",
      "Steps:  44%|▉ | 6629/15000 [42:04<24:54,  5.60it/s, lr=9.7e-6, step_loss=0.0701]07/18/2023 19:45:26 - INFO - __main__ - train loss is 4.884087922750041\n",
      "Steps:  44%|▉ | 6630/15000 [42:04<24:53,  5.60it/s, lr=9.7e-6, step_loss=0.0933]07/18/2023 19:45:26 - INFO - __main__ - train loss is 5.432435932336375\n",
      "Steps:  44%|█▎ | 6631/15000 [42:04<24:52,  5.61it/s, lr=9.7e-6, step_loss=0.548]07/18/2023 19:45:26 - INFO - __main__ - train loss is 5.57332635181956\n",
      "Steps:  44%|█▎ | 6632/15000 [42:04<24:52,  5.61it/s, lr=9.7e-6, step_loss=0.141]07/18/2023 19:45:27 - INFO - __main__ - train loss is 5.590300499228761\n",
      "Steps:  44%|█▎ | 6633/15000 [42:04<24:52,  5.61it/s, lr=9.7e-6, step_loss=0.017]07/18/2023 19:45:27 - INFO - __main__ - train loss is 5.592817514901981\n",
      "Steps:  44%|▍| 6634/15000 [42:05<24:51,  5.61it/s, lr=9.7e-6, step_loss=0.00252]07/18/2023 19:45:27 - INFO - __main__ - train loss is 5.68110005534254\n",
      "Steps:  44%|▉ | 6635/15000 [42:05<24:51,  5.61it/s, lr=9.7e-6, step_loss=0.0883]07/18/2023 19:45:27 - INFO - __main__ - train loss is 5.718834120547399\n",
      "Steps:  44%|▉ | 6636/15000 [42:05<24:50,  5.61it/s, lr=9.7e-6, step_loss=0.0377]07/18/2023 19:45:27 - INFO - __main__ - train loss is 5.7852873837109655\n",
      "Steps:  44%|▉ | 6637/15000 [42:05<24:51,  5.61it/s, lr=9.7e-6, step_loss=0.0665]07/18/2023 19:45:27 - INFO - __main__ - train loss is 5.787622629897669\n",
      "Steps:  44%|▍| 6638/15000 [42:05<24:50,  5.61it/s, lr=9.7e-6, step_loss=0.00234]07/18/2023 19:45:28 - INFO - __main__ - train loss is 5.8719952024985105\n",
      "Steps:  44%|▉ | 6639/15000 [42:05<24:50,  5.61it/s, lr=9.7e-6, step_loss=0.0844]07/18/2023 19:45:28 - INFO - __main__ - train loss is 5.8795775540638715\n",
      "Steps:  44%|▍| 6640/15000 [42:06<24:49,  5.61it/s, lr=9.7e-6, step_loss=0.00758]07/18/2023 19:45:28 - INFO - __main__ - train loss is 6.396867967443541\n",
      "Steps:  44%|█▎ | 6641/15000 [42:06<24:50,  5.61it/s, lr=9.7e-6, step_loss=0.517]07/18/2023 19:45:28 - INFO - __main__ - train loss is 6.746840930776671\n",
      "Steps:  44%|█▊  | 6642/15000 [42:06<24:50,  5.61it/s, lr=9.7e-6, step_loss=0.35]07/18/2023 19:45:28 - INFO - __main__ - train loss is 7.185746378498152\n",
      "Steps:  44%|█▎ | 6643/15000 [42:06<24:51,  5.60it/s, lr=9.7e-6, step_loss=0.439]07/18/2023 19:45:28 - INFO - __main__ - train loss is 7.192799911135808\n",
      "Steps:  44%|▍| 6644/15000 [42:06<24:50,  5.61it/s, lr=9.7e-6, step_loss=0.00705]07/18/2023 19:45:29 - INFO - __main__ - train loss is 7.2000572823453695\n",
      "Steps:  44%|▍| 6645/15000 [42:07<24:49,  5.61it/s, lr=9.7e-6, step_loss=0.00726]07/18/2023 19:45:29 - INFO - __main__ - train loss is 7.674118890659884\n",
      "Steps:  44%|█▎ | 6646/15000 [42:07<24:49,  5.61it/s, lr=9.7e-6, step_loss=0.474]07/18/2023 19:45:29 - INFO - __main__ - train loss is 7.678073363611475\n",
      "Steps:  44%|▍| 6647/15000 [42:07<24:49,  5.61it/s, lr=9.7e-6, step_loss=0.00395]07/18/2023 19:45:29 - INFO - __main__ - train loss is 7.741084890672937\n",
      "Steps:  44%|█▎ | 6648/15000 [42:07<24:48,  5.61it/s, lr=9.7e-6, step_loss=0.063]07/18/2023 19:45:29 - INFO - __main__ - train loss is 7.767908718669787\n",
      "Steps:  44%|▉ | 6649/15000 [42:07<24:48,  5.61it/s, lr=9.7e-6, step_loss=0.0268]07/18/2023 19:45:30 - INFO - __main__ - train loss is 7.81908879824914\n",
      "Steps:  44%|▉ | 6650/15000 [42:07<24:48,  5.61it/s, lr=9.7e-6, step_loss=0.0512]07/18/2023 19:45:30 - INFO - __main__ - train loss is 7.822268963558599\n",
      "Steps:  44%|▍| 6651/15000 [42:08<24:47,  5.61it/s, lr=9.7e-6, step_loss=0.00318]07/18/2023 19:45:30 - INFO - __main__ - train loss is 8.283556104404852\n",
      "Steps:  44%|█▎ | 6652/15000 [42:08<24:46,  5.61it/s, lr=9.7e-6, step_loss=0.461]07/18/2023 19:45:30 - INFO - __main__ - train loss is 8.357532874448225\n",
      "Steps:  44%|█▎ | 6653/15000 [42:08<24:48,  5.61it/s, lr=9.7e-6, step_loss=0.074]07/18/2023 19:45:30 - INFO - __main__ - train loss is 8.360707175452262\n",
      "Steps:  44%|▍| 6654/15000 [42:08<24:48,  5.61it/s, lr=9.7e-6, step_loss=0.00317]07/18/2023 19:45:30 - INFO - __main__ - train loss is 9.1182882306166\n",
      "Steps:  44%|█▎ | 6655/15000 [42:08<24:48,  5.61it/s, lr=9.7e-6, step_loss=0.758]07/18/2023 19:45:31 - INFO - __main__ - train loss is 9.331082296092063\n",
      "Steps:  44%|█▎ | 6656/15000 [42:09<24:47,  5.61it/s, lr=9.7e-6, step_loss=0.213]07/18/2023 19:45:31 - INFO - __main__ - train loss is 9.576902848202735\n",
      "Steps:  44%|█▎ | 6657/15000 [42:09<24:47,  5.61it/s, lr=9.7e-6, step_loss=0.246]07/18/2023 19:45:31 - INFO - __main__ - train loss is 9.74632964702323\n",
      "Steps:  44%|█▎ | 6658/15000 [42:09<24:46,  5.61it/s, lr=9.7e-6, step_loss=0.169]07/18/2023 19:45:31 - INFO - __main__ - train loss is 9.749815761577338\n",
      "Steps:  44%|▍| 6659/15000 [42:09<24:46,  5.61it/s, lr=9.7e-6, step_loss=0.00349]07/18/2023 19:45:31 - INFO - __main__ - train loss is 9.994412675034255\n",
      "Steps:  44%|█▎ | 6660/15000 [42:09<24:45,  5.62it/s, lr=9.7e-6, step_loss=0.245]07/18/2023 19:45:32 - INFO - __main__ - train loss is 10.060230440925807\n",
      "Steps:  44%|▉ | 6661/15000 [42:09<24:45,  5.61it/s, lr=9.7e-6, step_loss=0.0658]07/18/2023 19:45:32 - INFO - __main__ - train loss is 10.341494686435908\n",
      "Steps:  44%|█▎ | 6662/15000 [42:10<24:45,  5.61it/s, lr=9.7e-6, step_loss=0.281]07/18/2023 19:45:32 - INFO - __main__ - train loss is 10.37566267279908\n",
      "Steps:  44%|▉ | 6663/15000 [42:10<24:46,  5.61it/s, lr=9.7e-6, step_loss=0.0342]07/18/2023 19:45:32 - INFO - __main__ - train loss is 10.579387831967324\n",
      "Steps:  44%|█▎ | 6664/15000 [42:10<24:45,  5.61it/s, lr=9.7e-6, step_loss=0.204]07/18/2023 19:45:32 - INFO - __main__ - train loss is 10.582418003352359\n",
      "Steps:  44%|▍| 6665/15000 [42:10<24:47,  5.60it/s, lr=9.7e-6, step_loss=0.00303]07/18/2023 19:45:32 - INFO - __main__ - train loss is 10.691797175677493\n",
      "Steps:  44%|█▎ | 6666/15000 [42:10<24:48,  5.60it/s, lr=9.7e-6, step_loss=0.109]07/18/2023 19:45:33 - INFO - __main__ - train loss is 10.991117635043338\n",
      "Steps:  44%|█▎ | 6667/15000 [42:10<24:48,  5.60it/s, lr=9.7e-6, step_loss=0.299]07/18/2023 19:45:33 - INFO - __main__ - train loss is 11.089116425486282\n",
      "Steps:  44%|█▎ | 6668/15000 [42:11<24:48,  5.60it/s, lr=9.7e-6, step_loss=0.098]07/18/2023 19:45:33 - INFO - __main__ - train loss is 11.099062942201272\n",
      "Steps:  44%|▍| 6669/15000 [42:11<24:48,  5.60it/s, lr=9.7e-6, step_loss=0.00995]07/18/2023 19:45:33 - INFO - __main__ - train loss is 11.103712036972865\n",
      "Steps:  44%|▍| 6670/15000 [42:11<24:48,  5.60it/s, lr=9.7e-6, step_loss=0.00465]07/18/2023 19:45:33 - INFO - __main__ - train loss is 11.109537807060406\n",
      "Steps:  44%|▍| 6671/15000 [42:11<24:47,  5.60it/s, lr=9.7e-6, step_loss=0.00583]07/18/2023 19:45:33 - INFO - __main__ - train loss is 11.124932104488835\n",
      "Steps:  44%|▉ | 6672/15000 [42:11<24:47,  5.60it/s, lr=9.7e-6, step_loss=0.0154]07/18/2023 19:45:34 - INFO - __main__ - train loss is 11.131326018599793\n",
      "Steps:  44%|▍| 6673/15000 [42:12<24:47,  5.60it/s, lr=9.7e-6, step_loss=0.00639]07/18/2023 19:45:34 - INFO - __main__ - train loss is 11.17902638646774\n",
      "Steps:  44%|▉ | 6674/15000 [42:12<24:47,  5.60it/s, lr=9.7e-6, step_loss=0.0477]07/18/2023 19:45:34 - INFO - __main__ - train loss is 11.220707989064977\n",
      "Steps:  44%|▉ | 6675/15000 [42:12<25:01,  5.55it/s, lr=9.7e-6, step_loss=0.0417]07/18/2023 19:45:34 - INFO - __main__ - train loss is 11.44346899422817\n",
      "Steps:  45%|█▎ | 6676/15000 [42:12<25:01,  5.54it/s, lr=9.7e-6, step_loss=0.223]07/18/2023 19:45:34 - INFO - __main__ - train loss is 11.54095774027519\n",
      "Steps:  45%|▉ | 6677/15000 [42:12<25:08,  5.52it/s, lr=9.7e-6, step_loss=0.0975]07/18/2023 19:45:35 - INFO - __main__ - train loss is 11.566025747684762\n",
      "Steps:  45%|▉ | 6678/15000 [42:12<25:11,  5.50it/s, lr=9.7e-6, step_loss=0.0251]07/18/2023 19:45:35 - INFO - __main__ - train loss is 11.574753616703674\n",
      "Steps:  45%|▍| 6679/15000 [42:13<25:17,  5.48it/s, lr=9.7e-6, step_loss=0.00873]07/18/2023 19:45:35 - INFO - __main__ - train loss is 11.724815730703995\n",
      "Steps:  45%|█▊  | 6680/15000 [42:13<25:22,  5.46it/s, lr=9.7e-6, step_loss=0.15]07/18/2023 19:45:35 - INFO - __main__ - train loss is 11.80222560907714\n",
      "Steps:  45%|▉ | 6681/15000 [42:13<25:12,  5.50it/s, lr=9.7e-6, step_loss=0.0774]07/18/2023 19:45:35 - INFO - __main__ - train loss is 11.917319630039856\n",
      "Steps:  45%|█▎ | 6682/15000 [42:13<25:04,  5.53it/s, lr=9.7e-6, step_loss=0.115]07/18/2023 19:45:35 - INFO - __main__ - train loss is 12.065954570425674\n",
      "Steps:  45%|█▎ | 6683/15000 [42:13<24:57,  5.55it/s, lr=9.7e-6, step_loss=0.149]07/18/2023 19:45:36 - INFO - __main__ - train loss is 12.260747437132522\n",
      "Steps:  45%|█▎ | 6684/15000 [42:14<24:57,  5.55it/s, lr=9.7e-6, step_loss=0.195]07/18/2023 19:45:36 - INFO - __main__ - train loss is 12.274487569695339\n",
      "Steps:  45%|▉ | 6685/15000 [42:14<25:04,  5.53it/s, lr=9.7e-6, step_loss=0.0137]07/18/2023 19:45:36 - INFO - __main__ - train loss is 12.322274796431884\n",
      "Steps:  45%|▉ | 6686/15000 [42:14<25:11,  5.50it/s, lr=9.7e-6, step_loss=0.0478]07/18/2023 19:45:36 - INFO - __main__ - train loss is 12.331882319180295\n",
      "Steps:  45%|▍| 6687/15000 [42:14<25:06,  5.52it/s, lr=9.7e-6, step_loss=0.00961]07/18/2023 19:45:36 - INFO - __main__ - train loss is 12.344385207397863\n",
      "Steps:  45%|▉ | 6688/15000 [42:14<24:59,  5.54it/s, lr=9.7e-6, step_loss=0.0125]07/18/2023 19:45:37 - INFO - __main__ - train loss is 12.481876224977896\n",
      "Steps:  45%|█▎ | 6689/15000 [42:14<25:05,  5.52it/s, lr=9.7e-6, step_loss=0.137]07/18/2023 19:45:37 - INFO - __main__ - train loss is 12.508278782246634\n",
      "Steps:  45%|▉ | 6690/15000 [42:15<24:58,  5.55it/s, lr=9.7e-6, step_loss=0.0264]07/18/2023 19:45:37 - INFO - __main__ - train loss is 12.642551923869178\n",
      "Steps:  45%|█▎ | 6691/15000 [42:15<24:53,  5.56it/s, lr=9.7e-6, step_loss=0.134]07/18/2023 19:45:37 - INFO - __main__ - train loss is 12.647351767634973\n",
      "Steps:  45%|▉ | 6692/15000 [42:15<24:49,  5.58it/s, lr=9.7e-6, step_loss=0.0048]07/18/2023 19:45:37 - INFO - __main__ - train loss is 12.656749350717291\n",
      "Steps:  45%|▉ | 6693/15000 [42:15<32:57,  4.20it/s, lr=9.7e-6, step_loss=0.0094]07/18/2023 19:45:38 - INFO - __main__ - Per validation step average loss is 0.13206613063812256\n",
      "07/18/2023 19:45:38 - INFO - __main__ - Cumulative validation average loss is 0.13206613063812256\n",
      "07/18/2023 19:45:38 - INFO - __main__ - Per validation step average loss is 0.0033180832397192717\n",
      "07/18/2023 19:45:38 - INFO - __main__ - Cumulative validation average loss is 0.13538421387784183\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Per validation step average loss is 0.13612200319766998\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Cumulative validation average loss is 0.2715062170755118\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Per validation step average loss is 0.1470140814781189\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Cumulative validation average loss is 0.4185202985536307\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Per validation step average loss is 0.21591416001319885\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Cumulative validation average loss is 0.6344344585668296\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Per validation step average loss is 0.04235563427209854\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Cumulative validation average loss is 0.6767900928389281\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Per validation step average loss is 0.27281421422958374\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Cumulative validation average loss is 0.9496043070685118\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Per validation step average loss is 0.05075979232788086\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Cumulative validation average loss is 1.0003640993963927\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Per validation step average loss is 0.4044852554798126\n",
      "07/18/2023 19:45:39 - INFO - __main__ - Cumulative validation average loss is 1.4048493548762053\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Per validation step average loss is 0.03087804466485977\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Cumulative validation average loss is 1.435727399541065\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Per validation step average loss is 0.011963315308094025\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Cumulative validation average loss is 1.4476907148491591\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Per validation step average loss is 0.12102679908275604\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Cumulative validation average loss is 1.5687175139319152\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Average validation loss for Epoch 68 is 0.13072645949432626\n",
      "07/18/2023 19:45:40 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:45:53 - INFO - __main__ - Starting epoch 69\n",
      "07/18/2023 19:45:53 - INFO - __main__ - train loss is 0.0013014536816626787\n",
      "Steps:  45%|▍| 6694/15000 [42:31<11:26:42,  4.96s/it, lr=9.7e-6, step_loss=0.00107/18/2023 19:45:54 - INFO - __main__ - train loss is 0.005862864898517728\n",
      "Steps:  45%|▍| 6695/15000 [42:32<8:08:03,  3.53s/it, lr=9.7e-6, step_loss=0.004507/18/2023 19:45:54 - INFO - __main__ - train loss is 0.05157870729453862\n",
      "Steps:  45%|▍| 6696/15000 [42:32<5:49:00,  2.52s/it, lr=9.7e-6, step_loss=0.045707/18/2023 19:45:54 - INFO - __main__ - train loss is 0.3801499076653272\n",
      "Steps:  45%|▍| 6697/15000 [42:32<4:11:41,  1.82s/it, lr=9.7e-6, step_loss=0.329]07/18/2023 19:45:54 - INFO - __main__ - train loss is 0.8541928001213819\n",
      "Steps:  45%|▍| 6698/15000 [42:32<3:03:33,  1.33s/it, lr=9.7e-6, step_loss=0.474]07/18/2023 19:45:54 - INFO - __main__ - train loss is 1.0251813002396375\n",
      "Steps:  45%|▍| 6699/15000 [42:32<2:15:58,  1.02it/s, lr=9.7e-6, step_loss=0.171]07/18/2023 19:45:55 - INFO - __main__ - train loss is 1.0760235965717584\n",
      "Steps:  45%|▍| 6700/15000 [42:32<1:42:34,  1.35it/s, lr=9.7e-6, step_loss=0.050807/18/2023 19:45:55 - INFO - __main__ - train loss is 1.432383018778637\n",
      "Steps:  45%|▍| 6701/15000 [42:33<1:19:11,  1.75it/s, lr=9.7e-6, step_loss=0.356]07/18/2023 19:45:55 - INFO - __main__ - train loss is 1.8574592352379113\n",
      "Steps:  45%|▍| 6702/15000 [42:33<1:02:48,  2.20it/s, lr=9.7e-6, step_loss=0.425]07/18/2023 19:45:55 - INFO - __main__ - train loss is 1.8856026374269277\n",
      "Steps:  45%|▉ | 6703/15000 [42:33<51:20,  2.69it/s, lr=9.7e-6, step_loss=0.0281]07/18/2023 19:45:55 - INFO - __main__ - train loss is 1.9340920962858945\n",
      "Steps:  45%|▉ | 6704/15000 [42:33<43:33,  3.17it/s, lr=9.7e-6, step_loss=0.0485]07/18/2023 19:45:55 - INFO - __main__ - train loss is 2.0812099792528898\n",
      "Steps:  45%|█▎ | 6705/15000 [42:33<38:14,  3.61it/s, lr=9.7e-6, step_loss=0.147]07/18/2023 19:45:56 - INFO - __main__ - train loss is 2.0829486910952255\n",
      "Steps:  45%|▍| 6706/15000 [42:34<34:15,  4.03it/s, lr=9.7e-6, step_loss=0.00174]07/18/2023 19:45:56 - INFO - __main__ - train loss is 2.104049048270099\n",
      "Steps:  45%|▉ | 6707/15000 [42:34<31:20,  4.41it/s, lr=9.7e-6, step_loss=0.0211]07/18/2023 19:45:56 - INFO - __main__ - train loss is 2.3104006563080475\n",
      "Steps:  45%|█▎ | 6708/15000 [42:34<29:20,  4.71it/s, lr=9.7e-6, step_loss=0.206]07/18/2023 19:45:56 - INFO - __main__ - train loss is 3.0340743575943634\n",
      "Steps:  45%|█▎ | 6709/15000 [42:34<27:57,  4.94it/s, lr=9.7e-6, step_loss=0.724]07/18/2023 19:45:56 - INFO - __main__ - train loss is 3.0364248187979683\n",
      "Steps:  45%|▍| 6710/15000 [42:34<27:10,  5.08it/s, lr=9.7e-6, step_loss=0.00235]07/18/2023 19:45:57 - INFO - __main__ - train loss is 3.134227159782313\n",
      "Steps:  45%|▉ | 6711/15000 [42:34<26:36,  5.19it/s, lr=9.7e-6, step_loss=0.0978]07/18/2023 19:45:57 - INFO - __main__ - train loss is 3.4215248258551583\n",
      "Steps:  45%|█▎ | 6712/15000 [42:35<26:02,  5.31it/s, lr=9.7e-6, step_loss=0.287]07/18/2023 19:45:57 - INFO - __main__ - train loss is 3.5215922774514183\n",
      "Steps:  45%|██▏  | 6713/15000 [42:35<25:36,  5.39it/s, lr=9.7e-6, step_loss=0.1]07/18/2023 19:45:57 - INFO - __main__ - train loss is 3.5711731308838353\n",
      "Steps:  45%|▉ | 6714/15000 [42:35<25:20,  5.45it/s, lr=9.7e-6, step_loss=0.0496]07/18/2023 19:45:57 - INFO - __main__ - train loss is 3.608479327871464\n",
      "Steps:  45%|▉ | 6715/15000 [42:35<25:07,  5.50it/s, lr=9.7e-6, step_loss=0.0373]07/18/2023 19:45:57 - INFO - __main__ - train loss is 3.649998098029755\n",
      "Steps:  45%|▉ | 6716/15000 [42:35<24:58,  5.53it/s, lr=9.7e-6, step_loss=0.0415]07/18/2023 19:45:58 - INFO - __main__ - train loss is 3.667171358480118\n",
      "Steps:  45%|▉ | 6717/15000 [42:35<24:51,  5.55it/s, lr=9.7e-6, step_loss=0.0172]07/18/2023 19:45:58 - INFO - __main__ - train loss is 3.80282682122197\n",
      "Steps:  45%|█▎ | 6718/15000 [42:36<24:47,  5.57it/s, lr=9.7e-6, step_loss=0.136]07/18/2023 19:45:58 - INFO - __main__ - train loss is 3.814043069607578\n",
      "Steps:  45%|▉ | 6719/15000 [42:36<24:44,  5.58it/s, lr=9.7e-6, step_loss=0.0112]07/18/2023 19:45:58 - INFO - __main__ - train loss is 4.1199482925003394\n",
      "Steps:  45%|▉ | 6720/15000 [42:36<24:42,  5.59it/s, lr=9.69e-6, step_loss=0.306]07/18/2023 19:45:58 - INFO - __main__ - train loss is 4.9486942536896095\n",
      "Steps:  45%|▉ | 6721/15000 [42:36<24:40,  5.59it/s, lr=9.69e-6, step_loss=0.829]07/18/2023 19:45:58 - INFO - __main__ - train loss is 5.409515286213718\n",
      "Steps:  45%|▉ | 6722/15000 [42:36<24:40,  5.59it/s, lr=9.69e-6, step_loss=0.461]07/18/2023 19:45:59 - INFO - __main__ - train loss is 5.415553801110946\n",
      "Steps:  45%|▍| 6723/15000 [42:37<24:39,  5.59it/s, lr=9.69e-6, step_loss=0.0060407/18/2023 19:45:59 - INFO - __main__ - train loss is 5.587764881900512\n",
      "Steps:  45%|▉ | 6724/15000 [42:37<24:38,  5.60it/s, lr=9.69e-6, step_loss=0.172]07/18/2023 19:45:59 - INFO - __main__ - train loss is 5.8919776905095205\n",
      "Steps:  45%|▉ | 6725/15000 [42:37<24:37,  5.60it/s, lr=9.69e-6, step_loss=0.304]07/18/2023 19:45:59 - INFO - __main__ - train loss is 6.329740248969756\n",
      "Steps:  45%|▉ | 6726/15000 [42:37<24:37,  5.60it/s, lr=9.69e-6, step_loss=0.438]07/18/2023 19:45:59 - INFO - __main__ - train loss is 6.47390284424182\n",
      "Steps:  45%|▉ | 6727/15000 [42:37<24:35,  5.61it/s, lr=9.69e-6, step_loss=0.144]07/18/2023 19:46:00 - INFO - __main__ - train loss is 6.4895277976756915\n",
      "Steps:  45%|▍| 6728/15000 [42:37<24:37,  5.60it/s, lr=9.69e-6, step_loss=0.0156]07/18/2023 19:46:00 - INFO - __main__ - train loss is 6.549933506525122\n",
      "Steps:  45%|▍| 6729/15000 [42:38<24:36,  5.60it/s, lr=9.69e-6, step_loss=0.0604]07/18/2023 19:46:00 - INFO - __main__ - train loss is 6.567583101219498\n",
      "Steps:  45%|▍| 6730/15000 [42:38<24:48,  5.56it/s, lr=9.69e-6, step_loss=0.0176]07/18/2023 19:46:00 - INFO - __main__ - train loss is 6.658617744571529\n",
      "Steps:  45%|▉ | 6731/15000 [42:38<24:57,  5.52it/s, lr=9.69e-6, step_loss=0.091]07/18/2023 19:46:00 - INFO - __main__ - train loss is 6.734145487076603\n",
      "Steps:  45%|▍| 6732/15000 [42:38<25:03,  5.50it/s, lr=9.69e-6, step_loss=0.0755]07/18/2023 19:46:00 - INFO - __main__ - train loss is 6.735625323257409\n",
      "Steps:  45%|▍| 6733/15000 [42:38<24:56,  5.52it/s, lr=9.69e-6, step_loss=0.0014807/18/2023 19:46:01 - INFO - __main__ - train loss is 6.76137755101081\n",
      "Steps:  45%|▍| 6734/15000 [42:39<24:58,  5.52it/s, lr=9.69e-6, step_loss=0.0258]07/18/2023 19:46:01 - INFO - __main__ - train loss is 6.769372329465114\n",
      "Steps:  45%|▍| 6735/15000 [42:39<25:06,  5.49it/s, lr=9.69e-6, step_loss=0.0079907/18/2023 19:46:01 - INFO - __main__ - train loss is 7.249670252553187\n",
      "Steps:  45%|█▎ | 6736/15000 [42:39<25:02,  5.50it/s, lr=9.69e-6, step_loss=0.48]07/18/2023 19:46:01 - INFO - __main__ - train loss is 7.289644521079026\n",
      "Steps:  45%|█▎ | 6737/15000 [42:39<24:54,  5.53it/s, lr=9.69e-6, step_loss=0.04]07/18/2023 19:46:01 - INFO - __main__ - train loss is 7.460616689524613\n",
      "Steps:  45%|▉ | 6738/15000 [42:39<24:52,  5.53it/s, lr=9.69e-6, step_loss=0.171]07/18/2023 19:46:02 - INFO - __main__ - train loss is 7.768495511612855\n",
      "Steps:  45%|▉ | 6739/15000 [42:39<24:59,  5.51it/s, lr=9.69e-6, step_loss=0.308]07/18/2023 19:46:02 - INFO - __main__ - train loss is 7.824260879657231\n",
      "Steps:  45%|▍| 6740/15000 [42:40<25:03,  5.49it/s, lr=9.69e-6, step_loss=0.0558]07/18/2023 19:46:02 - INFO - __main__ - train loss is 7.827254851232283\n",
      "Steps:  45%|▍| 6741/15000 [42:40<25:05,  5.48it/s, lr=9.69e-6, step_loss=0.0029907/18/2023 19:46:02 - INFO - __main__ - train loss is 8.41629787243437\n",
      "Steps:  45%|▉ | 6742/15000 [42:40<25:10,  5.47it/s, lr=9.69e-6, step_loss=0.589]07/18/2023 19:46:02 - INFO - __main__ - train loss is 8.453254018793814\n",
      "Steps:  45%|▉ | 6743/15000 [42:40<25:12,  5.46it/s, lr=9.69e-6, step_loss=0.037]07/18/2023 19:46:02 - INFO - __main__ - train loss is 8.612076495657675\n",
      "Steps:  45%|▉ | 6744/15000 [42:40<25:09,  5.47it/s, lr=9.69e-6, step_loss=0.159]07/18/2023 19:46:03 - INFO - __main__ - train loss is 8.618789939559065\n",
      "Steps:  45%|▍| 6745/15000 [42:41<24:59,  5.50it/s, lr=9.69e-6, step_loss=0.0067107/18/2023 19:46:03 - INFO - __main__ - train loss is 8.926174758351408\n",
      "Steps:  45%|▉ | 6746/15000 [42:41<25:06,  5.48it/s, lr=9.69e-6, step_loss=0.307]07/18/2023 19:46:03 - INFO - __main__ - train loss is 9.053954867995344\n",
      "Steps:  45%|▉ | 6747/15000 [42:41<24:59,  5.50it/s, lr=9.69e-6, step_loss=0.128]07/18/2023 19:46:03 - INFO - __main__ - train loss is 9.447857348597609\n",
      "Steps:  45%|▉ | 6748/15000 [42:41<24:53,  5.53it/s, lr=9.69e-6, step_loss=0.394]07/18/2023 19:46:03 - INFO - __main__ - train loss is 9.463144120178185\n",
      "Steps:  45%|▍| 6749/15000 [42:41<24:47,  5.55it/s, lr=9.69e-6, step_loss=0.0153]07/18/2023 19:46:04 - INFO - __main__ - train loss is 9.467494061565958\n",
      "Steps:  45%|▍| 6750/15000 [42:41<24:43,  5.56it/s, lr=9.69e-6, step_loss=0.0043507/18/2023 19:46:04 - INFO - __main__ - train loss is 9.831596782780252\n",
      "Steps:  45%|▉ | 6751/15000 [42:42<24:39,  5.58it/s, lr=9.69e-6, step_loss=0.364]07/18/2023 19:46:04 - INFO - __main__ - train loss is 9.844032030901872\n",
      "Steps:  45%|▍| 6752/15000 [42:42<24:37,  5.58it/s, lr=9.69e-6, step_loss=0.0124]07/18/2023 19:46:04 - INFO - __main__ - train loss is 9.877697013667785\n",
      "Steps:  45%|▍| 6753/15000 [42:42<24:35,  5.59it/s, lr=9.69e-6, step_loss=0.0337]07/18/2023 19:46:04 - INFO - __main__ - train loss is 9.885513336746953\n",
      "Steps:  45%|▍| 6754/15000 [42:42<24:35,  5.59it/s, lr=9.69e-6, step_loss=0.0078207/18/2023 19:46:04 - INFO - __main__ - train loss is 9.979930729954503\n",
      "Steps:  45%|▍| 6755/15000 [42:42<24:35,  5.59it/s, lr=9.69e-6, step_loss=0.0944]07/18/2023 19:46:05 - INFO - __main__ - train loss is 10.690971584408544\n",
      "Steps:  45%|▉ | 6756/15000 [42:43<24:33,  5.59it/s, lr=9.69e-6, step_loss=0.711]07/18/2023 19:46:05 - INFO - __main__ - train loss is 10.692534811329097\n",
      "Steps:  45%|▍| 6757/15000 [42:43<24:33,  5.60it/s, lr=9.69e-6, step_loss=0.0015607/18/2023 19:46:05 - INFO - __main__ - train loss is 11.03961644275114\n",
      "Steps:  45%|▉ | 6758/15000 [42:43<24:32,  5.60it/s, lr=9.69e-6, step_loss=0.347]07/18/2023 19:46:05 - INFO - __main__ - train loss is 11.290920800995082\n",
      "Steps:  45%|▉ | 6759/15000 [42:43<24:31,  5.60it/s, lr=9.69e-6, step_loss=0.251]07/18/2023 19:46:05 - INFO - __main__ - train loss is 11.320428188424557\n",
      "Steps:  45%|▍| 6760/15000 [42:43<24:31,  5.60it/s, lr=9.69e-6, step_loss=0.0295]07/18/2023 19:46:06 - INFO - __main__ - train loss is 11.434328402858227\n",
      "Steps:  45%|▉ | 6761/15000 [42:43<24:35,  5.58it/s, lr=9.69e-6, step_loss=0.114]07/18/2023 19:46:06 - INFO - __main__ - train loss is 11.871463384013623\n",
      "Steps:  45%|▉ | 6762/15000 [42:44<24:34,  5.59it/s, lr=9.69e-6, step_loss=0.437]07/18/2023 19:46:06 - INFO - __main__ - train loss is 11.872953090118244\n",
      "Steps:  45%|▍| 6763/15000 [42:44<24:34,  5.59it/s, lr=9.69e-6, step_loss=0.0014907/18/2023 19:46:06 - INFO - __main__ - train loss is 11.950078117894009\n",
      "Steps:  45%|▍| 6764/15000 [42:44<24:32,  5.59it/s, lr=9.69e-6, step_loss=0.0771]07/18/2023 19:46:06 - INFO - __main__ - train loss is 12.040915104793385\n",
      "Steps:  45%|▍| 6765/15000 [42:44<24:32,  5.59it/s, lr=9.69e-6, step_loss=0.0908]07/18/2023 19:46:06 - INFO - __main__ - train loss is 12.051709400722757\n",
      "Steps:  45%|▍| 6766/15000 [42:44<24:31,  5.59it/s, lr=9.69e-6, step_loss=0.0108]07/18/2023 19:46:07 - INFO - __main__ - train loss is 12.237963633844629\n",
      "Steps:  45%|▉ | 6767/15000 [42:44<24:33,  5.59it/s, lr=9.69e-6, step_loss=0.186]07/18/2023 19:46:07 - INFO - __main__ - train loss is 12.429380046436563\n",
      "Steps:  45%|▉ | 6768/15000 [42:45<24:32,  5.59it/s, lr=9.69e-6, step_loss=0.191]07/18/2023 19:46:07 - INFO - __main__ - train loss is 12.484364027390257\n",
      "Steps:  45%|▉ | 6769/15000 [42:45<24:32,  5.59it/s, lr=9.69e-6, step_loss=0.055]07/18/2023 19:46:07 - INFO - __main__ - train loss is 12.568444745847955\n",
      "Steps:  45%|▍| 6770/15000 [42:45<24:31,  5.59it/s, lr=9.69e-6, step_loss=0.0841]07/18/2023 19:46:07 - INFO - __main__ - train loss is 12.642497511813417\n",
      "Steps:  45%|▍| 6771/15000 [42:45<24:35,  5.58it/s, lr=9.69e-6, step_loss=0.0741]07/18/2023 19:46:07 - INFO - __main__ - train loss is 12.751931736478582\n",
      "Steps:  45%|▉ | 6772/15000 [42:45<24:43,  5.55it/s, lr=9.69e-6, step_loss=0.109]07/18/2023 19:46:08 - INFO - __main__ - train loss is 12.775378305697814\n",
      "Steps:  45%|▍| 6773/15000 [42:46<24:57,  5.49it/s, lr=9.69e-6, step_loss=0.0234]07/18/2023 19:46:08 - INFO - __main__ - train loss is 12.794727862114087\n",
      "Steps:  45%|▍| 6774/15000 [42:46<25:08,  5.45it/s, lr=9.69e-6, step_loss=0.0193]07/18/2023 19:46:08 - INFO - __main__ - train loss is 12.83528570854105\n",
      "Steps:  45%|▍| 6775/15000 [42:46<25:00,  5.48it/s, lr=9.69e-6, step_loss=0.0406]07/18/2023 19:46:08 - INFO - __main__ - train loss is 12.837734293658286\n",
      "Steps:  45%|▍| 6776/15000 [42:46<24:57,  5.49it/s, lr=9.69e-6, step_loss=0.0024507/18/2023 19:46:08 - INFO - __main__ - train loss is 12.945498671848327\n",
      "Steps:  45%|▉ | 6777/15000 [42:46<24:47,  5.53it/s, lr=9.69e-6, step_loss=0.108]07/18/2023 19:46:09 - INFO - __main__ - train loss is 12.961169505957514\n",
      "Steps:  45%|▍| 6778/15000 [42:46<24:41,  5.55it/s, lr=9.69e-6, step_loss=0.0157]07/18/2023 19:46:09 - INFO - __main__ - train loss is 12.96805917751044\n",
      "Steps:  45%|▍| 6779/15000 [42:47<24:36,  5.57it/s, lr=9.69e-6, step_loss=0.0068907/18/2023 19:46:09 - INFO - __main__ - train loss is 13.044807421974838\n",
      "Steps:  45%|▍| 6780/15000 [42:47<24:31,  5.59it/s, lr=9.69e-6, step_loss=0.0767]07/18/2023 19:46:09 - INFO - __main__ - train loss is 13.155470396392047\n",
      "Steps:  45%|▉ | 6781/15000 [42:47<24:28,  5.60it/s, lr=9.69e-6, step_loss=0.111]07/18/2023 19:46:09 - INFO - __main__ - train loss is 13.228104333393276\n",
      "Steps:  45%|▍| 6782/15000 [42:47<24:26,  5.60it/s, lr=9.69e-6, step_loss=0.0726]07/18/2023 19:46:09 - INFO - __main__ - train loss is 13.648182849399745\n",
      "Steps:  45%|█▎ | 6783/15000 [42:47<24:26,  5.60it/s, lr=9.69e-6, step_loss=0.42]07/18/2023 19:46:10 - INFO - __main__ - train loss is 13.792865852825344\n",
      "Steps:  45%|▉ | 6784/15000 [42:48<24:24,  5.61it/s, lr=9.69e-6, step_loss=0.145]07/18/2023 19:46:10 - INFO - __main__ - train loss is 14.240221004001796\n",
      "Steps:  45%|▉ | 6785/15000 [42:48<24:23,  5.61it/s, lr=9.69e-6, step_loss=0.447]07/18/2023 19:46:10 - INFO - __main__ - train loss is 14.742471675388515\n",
      "Steps:  45%|▉ | 6786/15000 [42:48<24:22,  5.62it/s, lr=9.69e-6, step_loss=0.502]07/18/2023 19:46:10 - INFO - __main__ - train loss is 15.322288434021175\n",
      "[2023-07-18 19:46:10,761] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:  45%|█▎ | 6787/15000 [42:48<24:11,  5.66it/s, lr=9.69e-6, step_loss=0.58]07/18/2023 19:46:10 - INFO - __main__ - train loss is 15.889792065136135\n",
      "Steps:  45%|▉ | 6788/15000 [42:48<24:12,  5.65it/s, lr=9.69e-6, step_loss=0.568]07/18/2023 19:46:11 - INFO - __main__ - train loss is 16.465430716983974\n",
      "Steps:  45%|▉ | 6789/15000 [42:48<24:17,  5.63it/s, lr=9.69e-6, step_loss=0.576]07/18/2023 19:46:11 - INFO - __main__ - train loss is 17.160735229961574\n",
      "Steps:  45%|▉ | 6790/15000 [42:49<32:23,  4.22it/s, lr=9.69e-6, step_loss=0.695]07/18/2023 19:46:12 - INFO - __main__ - Per validation step average loss is 0.018385909497737885\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Cumulative validation average loss is 0.018385909497737885\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Per validation step average loss is 0.033969778567552567\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Cumulative validation average loss is 0.05235568806529045\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Per validation step average loss is 0.10500045120716095\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Cumulative validation average loss is 0.1573561392724514\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Per validation step average loss is 0.33350178599357605\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Cumulative validation average loss is 0.49085792526602745\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Per validation step average loss is 0.5497703552246094\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Cumulative validation average loss is 1.0406282804906368\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Per validation step average loss is 0.04267657920718193\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Cumulative validation average loss is 1.0833048596978188\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Per validation step average loss is 0.048443492501974106\n",
      "07/18/2023 19:46:12 - INFO - __main__ - Cumulative validation average loss is 1.1317483521997929\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Per validation step average loss is 0.13988803327083588\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Cumulative validation average loss is 1.2716363854706287\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Per validation step average loss is 0.05093429982662201\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Cumulative validation average loss is 1.3225706852972507\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Per validation step average loss is 0.008540995419025421\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Cumulative validation average loss is 1.3311116807162762\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Per validation step average loss is 0.005523097235709429\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Cumulative validation average loss is 1.3366347779519856\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Per validation step average loss is 0.06279139220714569\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Cumulative validation average loss is 1.3994261701591313\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Average validation loss for Epoch 69 is 0.11661884751326095\n",
      "07/18/2023 19:46:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:46:26 - INFO - __main__ - Starting epoch 70\n",
      "07/18/2023 19:46:27 - INFO - __main__ - train loss is 0.0811396986246109\n",
      "Steps:  45%|▍| 6791/15000 [43:05<11:26:02,  5.01s/it, lr=9.69e-6, step_loss=0.0807/18/2023 19:46:28 - INFO - __main__ - train loss is 0.14822428673505783\n",
      "Steps:  45%|▍| 6792/15000 [43:06<8:23:00,  3.68s/it, lr=9.69e-6, step_loss=0.06707/18/2023 19:46:28 - INFO - __main__ - train loss is 0.2857350930571556\n",
      "Steps:  45%|▍| 6793/15000 [43:06<6:14:21,  2.74s/it, lr=9.69e-6, step_loss=0.13807/18/2023 19:46:29 - INFO - __main__ - train loss is 0.3234728053212166\n",
      "Steps:  45%|▍| 6794/15000 [43:07<4:44:26,  2.08s/it, lr=9.69e-6, step_loss=0.03707/18/2023 19:46:29 - INFO - __main__ - train loss is 0.6443056240677834\n",
      "Steps:  45%|▍| 6795/15000 [43:07<3:41:20,  1.62s/it, lr=9.69e-6, step_loss=0.32107/18/2023 19:46:30 - INFO - __main__ - train loss is 0.8111563995480537\n",
      "Steps:  45%|▍| 6796/15000 [43:08<2:57:06,  1.30s/it, lr=9.69e-6, step_loss=0.16707/18/2023 19:46:30 - INFO - __main__ - train loss is 1.0703751519322395\n",
      "Steps:  45%|▍| 6797/15000 [43:08<2:26:17,  1.07s/it, lr=9.69e-6, step_loss=0.25907/18/2023 19:46:31 - INFO - __main__ - train loss is 1.6149929240345955\n",
      "Steps:  45%|▍| 6798/15000 [43:09<2:04:32,  1.10it/s, lr=9.69e-6, step_loss=0.54507/18/2023 19:46:31 - INFO - __main__ - train loss is 1.6760514453053474\n",
      "Steps:  45%|▍| 6799/15000 [43:09<1:50:01,  1.24it/s, lr=9.69e-6, step_loss=0.06107/18/2023 19:46:32 - INFO - __main__ - train loss is 1.6777359377592802\n",
      "Steps:  45%|▍| 6800/15000 [43:10<1:39:17,  1.38it/s, lr=9.69e-6, step_loss=0.00107/18/2023 19:46:33 - INFO - __main__ - train loss is 1.7351007293909788\n",
      "Steps:  45%|▍| 6801/15000 [43:10<1:31:56,  1.49it/s, lr=9.69e-6, step_loss=0.05707/18/2023 19:46:33 - INFO - __main__ - train loss is 2.6025003623217344\n",
      "Steps:  45%|▍| 6802/15000 [43:11<1:26:53,  1.57it/s, lr=9.69e-6, step_loss=0.86707/18/2023 19:46:34 - INFO - __main__ - train loss is 2.7186728548258543\n",
      "Steps:  45%|▍| 6803/15000 [43:12<1:23:11,  1.64it/s, lr=9.69e-6, step_loss=0.11607/18/2023 19:46:34 - INFO - __main__ - train loss is 2.764160728082061\n",
      "Steps:  45%|▍| 6804/15000 [43:12<1:20:31,  1.70it/s, lr=9.69e-6, step_loss=0.04507/18/2023 19:46:35 - INFO - __main__ - train loss is 2.9709531124681234\n",
      "Steps:  45%|▍| 6805/15000 [43:13<1:18:42,  1.74it/s, lr=9.69e-6, step_loss=0.20707/18/2023 19:46:35 - INFO - __main__ - train loss is 2.9724570041289553\n",
      "Steps:  45%|▍| 6806/15000 [43:13<1:17:12,  1.77it/s, lr=9.69e-6, step_loss=0.00107/18/2023 19:46:36 - INFO - __main__ - train loss is 3.220397618948482\n",
      "Steps:  45%|▍| 6807/15000 [43:14<1:16:28,  1.79it/s, lr=9.69e-6, step_loss=0.24807/18/2023 19:46:36 - INFO - __main__ - train loss is 3.2320580933010206\n",
      "Steps:  45%|▍| 6808/15000 [43:14<1:15:47,  1.80it/s, lr=9.69e-6, step_loss=0.01107/18/2023 19:46:37 - INFO - __main__ - train loss is 3.2359632117440924\n",
      "Steps:  45%|▍| 6809/15000 [43:15<1:15:13,  1.81it/s, lr=9.69e-6, step_loss=0.00307/18/2023 19:46:37 - INFO - __main__ - train loss is 3.2638197311898693\n",
      "Steps:  45%|▍| 6810/15000 [43:15<1:15:03,  1.82it/s, lr=9.69e-6, step_loss=0.02707/18/2023 19:46:38 - INFO - __main__ - train loss is 3.42733205051627\n",
      "Steps:  45%|▍| 6811/15000 [43:16<1:14:52,  1.82it/s, lr=9.69e-6, step_loss=0.16407/18/2023 19:46:39 - INFO - __main__ - train loss is 3.505433223559521\n",
      "Steps:  45%|▍| 6812/15000 [43:16<1:14:49,  1.82it/s, lr=9.69e-6, step_loss=0.07807/18/2023 19:46:39 - INFO - __main__ - train loss is 3.50844900298398\n",
      "Steps:  45%|▍| 6813/15000 [43:17<1:14:41,  1.83it/s, lr=9.69e-6, step_loss=0.00307/18/2023 19:46:40 - INFO - __main__ - train loss is 3.595351621392183\n",
      "Steps:  45%|▍| 6814/15000 [43:18<1:14:25,  1.83it/s, lr=9.69e-6, step_loss=0.08607/18/2023 19:46:40 - INFO - __main__ - train loss is 3.600082794087939\n",
      "Steps:  45%|▍| 6815/15000 [43:18<1:14:09,  1.84it/s, lr=9.69e-6, step_loss=0.00407/18/2023 19:46:41 - INFO - __main__ - train loss is 4.317274907487445\n",
      "Steps:  45%|▍| 6816/15000 [43:19<1:14:07,  1.84it/s, lr=9.69e-6, step_loss=0.71707/18/2023 19:46:41 - INFO - __main__ - train loss is 4.4545780214248225\n",
      "Steps:  45%|▍| 6817/15000 [43:19<1:13:58,  1.84it/s, lr=9.69e-6, step_loss=0.13707/18/2023 19:46:42 - INFO - __main__ - train loss is 4.461192236631177\n",
      "Steps:  45%|▍| 6818/15000 [43:20<1:14:13,  1.84it/s, lr=9.69e-6, step_loss=0.00607/18/2023 19:46:42 - INFO - __main__ - train loss is 4.697710351436399\n",
      "Steps:  45%|▍| 6819/15000 [43:20<1:15:05,  1.82it/s, lr=9.69e-6, step_loss=0.23707/18/2023 19:46:43 - INFO - __main__ - train loss is 4.919598535983823\n",
      "Steps:  45%|▍| 6820/15000 [43:21<1:15:18,  1.81it/s, lr=9.69e-6, step_loss=0.22207/18/2023 19:46:43 - INFO - __main__ - train loss is 5.228189544170164\n",
      "Steps:  45%|▍| 6821/15000 [43:21<1:15:27,  1.81it/s, lr=9.69e-6, step_loss=0.30907/18/2023 19:46:44 - INFO - __main__ - train loss is 5.23972833098378\n",
      "Steps:  45%|▍| 6822/15000 [43:22<1:15:53,  1.80it/s, lr=9.69e-6, step_loss=0.01107/18/2023 19:46:45 - INFO - __main__ - train loss is 5.411750822677277\n",
      "Steps:  45%|▍| 6823/15000 [43:23<1:17:42,  1.75it/s, lr=9.69e-6, step_loss=0.17207/18/2023 19:46:45 - INFO - __main__ - train loss is 5.4139591994462535\n",
      "Steps:  45%|▍| 6824/15000 [43:23<1:19:30,  1.71it/s, lr=9.69e-6, step_loss=0.00207/18/2023 19:46:46 - INFO - __main__ - train loss is 5.611840272205882\n",
      "Steps:  46%|▍| 6825/15000 [43:24<1:20:20,  1.70it/s, lr=9.69e-6, step_loss=0.19807/18/2023 19:46:46 - INFO - __main__ - train loss is 5.631945893052034\n",
      "Steps:  46%|▍| 6826/15000 [43:24<1:20:10,  1.70it/s, lr=9.69e-6, step_loss=0.02007/18/2023 19:46:47 - INFO - __main__ - train loss is 5.636721395771019\n",
      "Steps:  46%|▍| 6827/15000 [43:25<1:18:46,  1.73it/s, lr=9.69e-6, step_loss=0.00407/18/2023 19:46:48 - INFO - __main__ - train loss is 5.638740059104748\n",
      "Steps:  46%|▍| 6828/15000 [43:25<1:17:17,  1.76it/s, lr=9.69e-6, step_loss=0.00207/18/2023 19:46:48 - INFO - __main__ - train loss is 5.794526469078846\n",
      "Steps:  46%|▍| 6829/15000 [43:26<1:15:58,  1.79it/s, lr=9.69e-6, step_loss=0.15607/18/2023 19:46:49 - INFO - __main__ - train loss is 5.966519232955761\n",
      "Steps:  46%|▍| 6830/15000 [43:26<1:15:19,  1.81it/s, lr=9.69e-6, step_loss=0.17207/18/2023 19:46:49 - INFO - __main__ - train loss is 5.9825751521857455\n",
      "Steps:  46%|▍| 6831/15000 [43:27<1:14:50,  1.82it/s, lr=9.68e-6, step_loss=0.01607/18/2023 19:46:50 - INFO - __main__ - train loss is 5.987419775803573\n",
      "Steps:  46%|▍| 6832/15000 [43:28<1:14:23,  1.83it/s, lr=9.68e-6, step_loss=0.00407/18/2023 19:46:50 - INFO - __main__ - train loss is 6.1906570858554915\n",
      "Steps:  46%|▍| 6833/15000 [43:28<1:14:23,  1.83it/s, lr=9.68e-6, step_loss=0.20307/18/2023 19:46:51 - INFO - __main__ - train loss is 6.278634867747314\n",
      "Steps:  46%|▍| 6834/15000 [43:29<1:14:20,  1.83it/s, lr=9.68e-6, step_loss=0.08807/18/2023 19:46:51 - INFO - __main__ - train loss is 6.282457008608617\n",
      "Steps:  46%|▍| 6835/15000 [43:29<1:14:16,  1.83it/s, lr=9.68e-6, step_loss=0.00307/18/2023 19:46:52 - INFO - __main__ - train loss is 6.342601157375611\n",
      "Steps:  46%|▍| 6836/15000 [43:30<1:14:30,  1.83it/s, lr=9.68e-6, step_loss=0.06007/18/2023 19:46:52 - INFO - __main__ - train loss is 6.702166951843537\n",
      "Steps:  46%|▍| 6837/15000 [43:30<1:14:22,  1.83it/s, lr=9.68e-6, step_loss=0.36]07/18/2023 19:46:53 - INFO - __main__ - train loss is 6.911081500002183\n",
      "Steps:  46%|▍| 6838/15000 [43:31<1:13:58,  1.84it/s, lr=9.68e-6, step_loss=0.20907/18/2023 19:46:54 - INFO - __main__ - train loss is 6.954705580719747\n",
      "Steps:  46%|▍| 6839/15000 [43:31<1:14:09,  1.83it/s, lr=9.68e-6, step_loss=0.04307/18/2023 19:46:54 - INFO - __main__ - train loss is 7.112892135628499\n",
      "Steps:  46%|▍| 6840/15000 [43:32<1:14:05,  1.84it/s, lr=9.68e-6, step_loss=0.15807/18/2023 19:46:55 - INFO - __main__ - train loss is 7.14266239257995\n",
      "Steps:  46%|▍| 6841/15000 [43:32<1:14:24,  1.83it/s, lr=9.68e-6, step_loss=0.02907/18/2023 19:46:55 - INFO - __main__ - train loss is 7.403882162296213\n",
      "Steps:  46%|▍| 6842/15000 [43:33<1:14:29,  1.83it/s, lr=9.68e-6, step_loss=0.26107/18/2023 19:46:56 - INFO - __main__ - train loss is 7.558311598026194\n",
      "Steps:  46%|▍| 6843/15000 [43:34<1:14:26,  1.83it/s, lr=9.68e-6, step_loss=0.15407/18/2023 19:46:56 - INFO - __main__ - train loss is 7.714595960103907\n",
      "Steps:  46%|▍| 6844/15000 [43:34<1:14:24,  1.83it/s, lr=9.68e-6, step_loss=0.15607/18/2023 19:46:57 - INFO - __main__ - train loss is 7.766208173357882\n",
      "Steps:  46%|▍| 6845/15000 [43:35<1:14:26,  1.83it/s, lr=9.68e-6, step_loss=0.05107/18/2023 19:46:57 - INFO - __main__ - train loss is 7.775844203890301\n",
      "Steps:  46%|▍| 6846/15000 [43:35<1:14:24,  1.83it/s, lr=9.68e-6, step_loss=0.00907/18/2023 19:46:58 - INFO - __main__ - train loss is 8.036231952370144\n",
      "Steps:  46%|▍| 6847/15000 [43:36<1:14:14,  1.83it/s, lr=9.68e-6, step_loss=0.26]07/18/2023 19:46:58 - INFO - __main__ - train loss is 8.101538913906552\n",
      "Steps:  46%|▍| 6848/15000 [43:36<1:14:25,  1.83it/s, lr=9.68e-6, step_loss=0.06507/18/2023 19:46:59 - INFO - __main__ - train loss is 8.253023179830052\n",
      "Steps:  46%|▍| 6849/15000 [43:37<1:14:23,  1.83it/s, lr=9.68e-6, step_loss=0.15107/18/2023 19:47:00 - INFO - __main__ - train loss is 8.499346854747273\n",
      "Steps:  46%|▍| 6850/15000 [43:37<1:14:20,  1.83it/s, lr=9.68e-6, step_loss=0.24607/18/2023 19:47:00 - INFO - __main__ - train loss is 8.839179250062443\n",
      "Steps:  46%|▍| 6851/15000 [43:38<1:14:22,  1.83it/s, lr=9.68e-6, step_loss=0.34]07/18/2023 19:47:01 - INFO - __main__ - train loss is 8.851746686385013\n",
      "Steps:  46%|▍| 6852/15000 [43:39<1:14:25,  1.82it/s, lr=9.68e-6, step_loss=0.01207/18/2023 19:47:01 - INFO - __main__ - train loss is 9.089648686931469\n",
      "Steps:  46%|▍| 6853/15000 [43:39<1:14:31,  1.82it/s, lr=9.68e-6, step_loss=0.23807/18/2023 19:47:02 - INFO - __main__ - train loss is 9.656728230998851\n",
      "Steps:  46%|▍| 6854/15000 [43:40<1:14:14,  1.83it/s, lr=9.68e-6, step_loss=0.56707/18/2023 19:47:02 - INFO - __main__ - train loss is 10.054374717758037\n",
      "Steps:  46%|▍| 6855/15000 [43:40<1:14:31,  1.82it/s, lr=9.68e-6, step_loss=0.39807/18/2023 19:47:03 - INFO - __main__ - train loss is 10.29379757551942\n",
      "Steps:  46%|▍| 6856/15000 [43:41<1:14:23,  1.82it/s, lr=9.68e-6, step_loss=0.23907/18/2023 19:47:03 - INFO - __main__ - train loss is 10.389205866144039\n",
      "Steps:  46%|▍| 6857/15000 [43:41<1:14:25,  1.82it/s, lr=9.68e-6, step_loss=0.09507/18/2023 19:47:04 - INFO - __main__ - train loss is 10.423465412692167\n",
      "Steps:  46%|▍| 6858/15000 [43:42<1:14:14,  1.83it/s, lr=9.68e-6, step_loss=0.03407/18/2023 19:47:04 - INFO - __main__ - train loss is 10.792463701800443\n",
      "Steps:  46%|▍| 6859/15000 [43:42<1:14:05,  1.83it/s, lr=9.68e-6, step_loss=0.36907/18/2023 19:47:05 - INFO - __main__ - train loss is 10.804911650368012\n",
      "Steps:  46%|▍| 6860/15000 [43:43<1:14:13,  1.83it/s, lr=9.68e-6, step_loss=0.01207/18/2023 19:47:06 - INFO - __main__ - train loss is 10.833128563710488\n",
      "Steps:  46%|▍| 6861/15000 [43:43<1:14:06,  1.83it/s, lr=9.68e-6, step_loss=0.02807/18/2023 19:47:06 - INFO - __main__ - train loss is 10.838367304881103\n",
      "Steps:  46%|▍| 6862/15000 [43:44<1:14:09,  1.83it/s, lr=9.68e-6, step_loss=0.00507/18/2023 19:47:07 - INFO - __main__ - train loss is 10.859854607959278\n",
      "Steps:  46%|▍| 6863/15000 [43:45<1:14:13,  1.83it/s, lr=9.68e-6, step_loss=0.02107/18/2023 19:47:07 - INFO - __main__ - train loss is 10.865377574344166\n",
      "Steps:  46%|▍| 6864/15000 [43:45<1:14:13,  1.83it/s, lr=9.68e-6, step_loss=0.00507/18/2023 19:47:08 - INFO - __main__ - train loss is 10.883134576608427\n",
      "Steps:  46%|▍| 6865/15000 [43:46<1:14:16,  1.83it/s, lr=9.68e-6, step_loss=0.01707/18/2023 19:47:08 - INFO - __main__ - train loss is 11.399425658513792\n",
      "Steps:  46%|▍| 6866/15000 [43:46<1:14:07,  1.83it/s, lr=9.68e-6, step_loss=0.51607/18/2023 19:47:09 - INFO - __main__ - train loss is 11.527192863752134\n",
      "Steps:  46%|▍| 6867/15000 [43:47<1:14:09,  1.83it/s, lr=9.68e-6, step_loss=0.12807/18/2023 19:47:09 - INFO - __main__ - train loss is 11.9118681877153\n",
      "Steps:  46%|▍| 6868/15000 [43:47<1:14:11,  1.83it/s, lr=9.68e-6, step_loss=0.38507/18/2023 19:47:10 - INFO - __main__ - train loss is 12.393298181821592\n",
      "Steps:  46%|▍| 6869/15000 [43:48<1:13:54,  1.83it/s, lr=9.68e-6, step_loss=0.48107/18/2023 19:47:10 - INFO - __main__ - train loss is 12.443556941230781\n",
      "Steps:  46%|▍| 6870/15000 [43:48<1:13:50,  1.83it/s, lr=9.68e-6, step_loss=0.05007/18/2023 19:47:11 - INFO - __main__ - train loss is 12.656561902840622\n",
      "Steps:  46%|▍| 6871/15000 [43:49<1:14:18,  1.82it/s, lr=9.68e-6, step_loss=0.21307/18/2023 19:47:12 - INFO - __main__ - train loss is 12.665491019492038\n",
      "Steps:  46%|▍| 6872/15000 [43:49<1:14:07,  1.83it/s, lr=9.68e-6, step_loss=0.00807/18/2023 19:47:12 - INFO - __main__ - train loss is 12.996360038523562\n",
      "Steps:  46%|▍| 6873/15000 [43:50<1:14:13,  1.82it/s, lr=9.68e-6, step_loss=0.33107/18/2023 19:47:13 - INFO - __main__ - train loss is 13.091463600401767\n",
      "Steps:  46%|▍| 6874/15000 [43:51<1:15:23,  1.80it/s, lr=9.68e-6, step_loss=0.09507/18/2023 19:47:13 - INFO - __main__ - train loss is 13.112596939434297\n",
      "Steps:  46%|▍| 6875/15000 [43:51<1:17:53,  1.74it/s, lr=9.68e-6, step_loss=0.02107/18/2023 19:47:14 - INFO - __main__ - train loss is 13.144231799175031\n",
      "Steps:  46%|▍| 6876/15000 [43:52<1:19:35,  1.70it/s, lr=9.68e-6, step_loss=0.03107/18/2023 19:47:14 - INFO - __main__ - train loss is 13.417114648153074\n",
      "Steps:  46%|▍| 6877/15000 [43:52<1:19:22,  1.71it/s, lr=9.68e-6, step_loss=0.27307/18/2023 19:47:15 - INFO - __main__ - train loss is 14.157520922948606\n",
      "Steps:  46%|▍| 6878/15000 [43:53<1:19:16,  1.71it/s, lr=9.68e-6, step_loss=0.74]07/18/2023 19:47:16 - INFO - __main__ - train loss is 14.373980703880079\n",
      "Steps:  46%|▍| 6879/15000 [43:54<1:17:42,  1.74it/s, lr=9.68e-6, step_loss=0.21607/18/2023 19:47:16 - INFO - __main__ - train loss is 14.376853514346294\n",
      "Steps:  46%|▍| 6880/15000 [43:54<1:16:24,  1.77it/s, lr=9.68e-6, step_loss=0.00207/18/2023 19:47:17 - INFO - __main__ - train loss is 14.785915005835705\n",
      "Steps:  46%|▍| 6881/15000 [43:55<1:15:14,  1.80it/s, lr=9.68e-6, step_loss=0.40907/18/2023 19:47:17 - INFO - __main__ - train loss is 14.788385665160604\n",
      "Steps:  46%|▍| 6882/15000 [43:55<1:14:36,  1.81it/s, lr=9.68e-6, step_loss=0.00207/18/2023 19:47:18 - INFO - __main__ - train loss is 15.471227442962117\n",
      "Steps:  46%|▍| 6883/15000 [43:56<1:14:18,  1.82it/s, lr=9.68e-6, step_loss=0.68307/18/2023 19:47:18 - INFO - __main__ - train loss is 15.563408976537175\n",
      "Steps:  46%|▍| 6884/15000 [43:56<1:14:13,  1.82it/s, lr=9.68e-6, step_loss=0.09207/18/2023 19:47:19 - INFO - __main__ - train loss is 15.693113690358587\n",
      "Steps:  46%|▍| 6885/15000 [43:57<1:13:51,  1.83it/s, lr=9.68e-6, step_loss=0.13]07/18/2023 19:47:19 - INFO - __main__ - train loss is 15.958825415116735\n",
      "Steps:  46%|▍| 6886/15000 [43:57<1:13:28,  1.84it/s, lr=9.68e-6, step_loss=0.26607/18/2023 19:47:20 - INFO - __main__ - train loss is 15.974953647819348\n",
      "Steps:  46%|▍| 6887/15000 [43:58<1:22:50,  1.63it/s, lr=9.68e-6, step_loss=0.01607/18/2023 19:47:21 - INFO - __main__ - Per validation step average loss is 0.5203900337219238\n",
      "07/18/2023 19:47:21 - INFO - __main__ - Cumulative validation average loss is 0.5203900337219238\n",
      "07/18/2023 19:47:21 - INFO - __main__ - Per validation step average loss is 0.6917049884796143\n",
      "07/18/2023 19:47:21 - INFO - __main__ - Cumulative validation average loss is 1.212095022201538\n",
      "07/18/2023 19:47:21 - INFO - __main__ - Per validation step average loss is 0.007610311731696129\n",
      "07/18/2023 19:47:21 - INFO - __main__ - Cumulative validation average loss is 1.2197053339332342\n",
      "07/18/2023 19:47:21 - INFO - __main__ - Per validation step average loss is 0.3568912446498871\n",
      "07/18/2023 19:47:21 - INFO - __main__ - Cumulative validation average loss is 1.5765965785831213\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Per validation step average loss is 0.0019819599110633135\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Cumulative validation average loss is 1.5785785384941846\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Per validation step average loss is 0.3435117304325104\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Cumulative validation average loss is 1.922090268926695\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Per validation step average loss is 0.05625598877668381\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Cumulative validation average loss is 1.9783462577033788\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Per validation step average loss is 0.006213930435478687\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Cumulative validation average loss is 1.9845601881388575\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Per validation step average loss is 0.008249353617429733\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Cumulative validation average loss is 1.9928095417562872\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Per validation step average loss is 0.0886642336845398\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Cumulative validation average loss is 2.081473775440827\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Per validation step average loss is 0.020644359290599823\n",
      "07/18/2023 19:47:22 - INFO - __main__ - Cumulative validation average loss is 2.102118134731427\n",
      "07/18/2023 19:47:23 - INFO - __main__ - Per validation step average loss is 0.21969449520111084\n",
      "07/18/2023 19:47:23 - INFO - __main__ - Cumulative validation average loss is 2.3218126299325377\n",
      "07/18/2023 19:47:23 - INFO - __main__ - Average validation loss for Epoch 70 is 0.19348438582771146\n",
      "07/18/2023 19:47:23 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:47:35 - INFO - __main__ - Starting epoch 71\n",
      "07/18/2023 19:47:36 - INFO - __main__ - train loss is 0.006305268034338951\n",
      "Steps:  46%|▍| 6888/15000 [44:14<11:40:04,  5.18s/it, lr=9.68e-6, step_loss=0.0007/18/2023 19:47:36 - INFO - __main__ - train loss is 0.06777351535856724\n",
      "Steps:  46%|▍| 6889/15000 [44:14<8:17:32,  3.68s/it, lr=9.68e-6, step_loss=0.06107/18/2023 19:47:36 - INFO - __main__ - train loss is 0.07427307963371277\n",
      "Steps:  46%|▍| 6890/15000 [44:14<5:55:53,  2.63s/it, lr=9.68e-6, step_loss=0.00607/18/2023 19:47:37 - INFO - __main__ - train loss is 0.17661763727664948\n",
      "Steps:  46%|▍| 6891/15000 [44:14<4:16:51,  1.90s/it, lr=9.68e-6, step_loss=0.10207/18/2023 19:47:37 - INFO - __main__ - train loss is 0.313273549079895\n",
      "Steps:  46%|▍| 6892/15000 [44:15<3:07:26,  1.39s/it, lr=9.68e-6, step_loss=0.13707/18/2023 19:47:37 - INFO - __main__ - train loss is 0.9150925874710083\n",
      "Steps:  46%|▍| 6893/15000 [44:15<2:19:00,  1.03s/it, lr=9.68e-6, step_loss=0.60207/18/2023 19:47:37 - INFO - __main__ - train loss is 1.3261797428131104\n",
      "Steps:  46%|▍| 6894/15000 [44:15<1:45:05,  1.29it/s, lr=9.68e-6, step_loss=0.41107/18/2023 19:47:37 - INFO - __main__ - train loss is 1.5935677289962769\n",
      "Steps:  46%|▍| 6895/15000 [44:15<1:21:06,  1.67it/s, lr=9.68e-6, step_loss=0.26707/18/2023 19:47:38 - INFO - __main__ - train loss is 1.6456143036484718\n",
      "Steps:  46%|▍| 6896/15000 [44:15<1:03:58,  2.11it/s, lr=9.68e-6, step_loss=0.05207/18/2023 19:47:38 - INFO - __main__ - train loss is 2.052661783993244\n",
      "Steps:  46%|▉ | 6897/15000 [44:16<51:58,  2.60it/s, lr=9.68e-6, step_loss=0.407]07/18/2023 19:47:38 - INFO - __main__ - train loss is 2.300866700708866\n",
      "Steps:  46%|▉ | 6898/15000 [44:16<43:34,  3.10it/s, lr=9.68e-6, step_loss=0.248]07/18/2023 19:47:38 - INFO - __main__ - train loss is 2.4719293192029\n",
      "Steps:  46%|▉ | 6899/15000 [44:16<37:41,  3.58it/s, lr=9.68e-6, step_loss=0.171]07/18/2023 19:47:38 - INFO - __main__ - train loss is 2.7486508563160896\n",
      "Steps:  46%|▉ | 6900/15000 [44:16<33:34,  4.02it/s, lr=9.68e-6, step_loss=0.277]07/18/2023 19:47:38 - INFO - __main__ - train loss is 2.994520850479603\n",
      "Steps:  46%|▉ | 6901/15000 [44:16<30:40,  4.40it/s, lr=9.68e-6, step_loss=0.246]07/18/2023 19:47:39 - INFO - __main__ - train loss is 3.285978801548481\n",
      "Steps:  46%|▉ | 6902/15000 [44:16<28:40,  4.71it/s, lr=9.68e-6, step_loss=0.291]07/18/2023 19:47:39 - INFO - __main__ - train loss is 3.358186937868595\n",
      "Steps:  46%|▍| 6903/15000 [44:17<27:14,  4.95it/s, lr=9.68e-6, step_loss=0.0722]07/18/2023 19:47:39 - INFO - __main__ - train loss is 4.035492993891239\n",
      "Steps:  46%|▉ | 6904/15000 [44:17<26:14,  5.14it/s, lr=9.68e-6, step_loss=0.677]07/18/2023 19:47:39 - INFO - __main__ - train loss is 4.477666772902012\n",
      "Steps:  46%|▉ | 6905/15000 [44:17<25:35,  5.27it/s, lr=9.68e-6, step_loss=0.442]07/18/2023 19:47:39 - INFO - __main__ - train loss is 4.578932128846645\n",
      "Steps:  46%|▉ | 6906/15000 [44:17<25:07,  5.37it/s, lr=9.68e-6, step_loss=0.101]07/18/2023 19:47:40 - INFO - __main__ - train loss is 4.590434273704886\n",
      "Steps:  46%|▍| 6907/15000 [44:17<24:48,  5.44it/s, lr=9.68e-6, step_loss=0.0115]07/18/2023 19:47:40 - INFO - __main__ - train loss is 4.743100648745894\n",
      "[2023-07-18 19:47:40,262] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  46%|▉ | 6908/15000 [44:18<24:23,  5.53it/s, lr=9.68e-6, step_loss=0.153]07/18/2023 19:47:40 - INFO - __main__ - train loss is 4.938945835456252\n",
      "Steps:  46%|▉ | 6909/15000 [44:18<24:16,  5.55it/s, lr=9.68e-6, step_loss=0.196]07/18/2023 19:47:40 - INFO - __main__ - train loss is 5.397851889953017\n",
      "Steps:  46%|▉ | 6910/15000 [44:18<24:12,  5.57it/s, lr=9.68e-6, step_loss=0.459]07/18/2023 19:47:40 - INFO - __main__ - train loss is 5.4018146293237805\n",
      "Steps:  46%|▍| 6911/15000 [44:18<24:07,  5.59it/s, lr=9.68e-6, step_loss=0.0039607/18/2023 19:47:40 - INFO - __main__ - train loss is 5.461972494609654\n",
      "Steps:  46%|▍| 6912/15000 [44:18<24:05,  5.60it/s, lr=9.68e-6, step_loss=0.0602]07/18/2023 19:47:41 - INFO - __main__ - train loss is 5.477590415626764\n",
      "Steps:  46%|▍| 6913/15000 [44:18<24:02,  5.61it/s, lr=9.68e-6, step_loss=0.0156]07/18/2023 19:47:41 - INFO - __main__ - train loss is 5.888444159179926\n",
      "Steps:  46%|▉ | 6914/15000 [44:19<24:12,  5.57it/s, lr=9.68e-6, step_loss=0.411]07/18/2023 19:47:41 - INFO - __main__ - train loss is 5.889940021559596\n",
      "Steps:  46%|▍| 6915/15000 [44:19<24:21,  5.53it/s, lr=9.68e-6, step_loss=0.0015]07/18/2023 19:47:41 - INFO - __main__ - train loss is 5.904023407027125\n",
      "Steps:  46%|▍| 6916/15000 [44:19<24:25,  5.52it/s, lr=9.68e-6, step_loss=0.0141]07/18/2023 19:47:41 - INFO - __main__ - train loss is 5.960844362154603\n",
      "Steps:  46%|▍| 6917/15000 [44:19<24:31,  5.49it/s, lr=9.68e-6, step_loss=0.0568]07/18/2023 19:47:41 - INFO - __main__ - train loss is 6.686388337984681\n",
      "Steps:  46%|▉ | 6918/15000 [44:19<24:45,  5.44it/s, lr=9.68e-6, step_loss=0.726]07/18/2023 19:47:42 - INFO - __main__ - train loss is 6.823790499940515\n",
      "Steps:  46%|▉ | 6919/15000 [44:20<26:25,  5.10it/s, lr=9.68e-6, step_loss=0.137]07/18/2023 19:47:42 - INFO - __main__ - train loss is 7.047637039795518\n",
      "Steps:  46%|▉ | 6920/15000 [44:20<28:42,  4.69it/s, lr=9.68e-6, step_loss=0.224]07/18/2023 19:47:42 - INFO - __main__ - train loss is 7.07042339630425\n",
      "Steps:  46%|▍| 6921/15000 [44:20<30:14,  4.45it/s, lr=9.68e-6, step_loss=0.0228]07/18/2023 19:47:42 - INFO - __main__ - train loss is 7.675217540934682\n",
      "Steps:  46%|▉ | 6922/15000 [44:20<29:07,  4.62it/s, lr=9.68e-6, step_loss=0.605]07/18/2023 19:47:43 - INFO - __main__ - train loss is 7.6843212973326445\n",
      "Steps:  46%|▍| 6923/15000 [44:20<28:11,  4.77it/s, lr=9.68e-6, step_loss=0.0091]07/18/2023 19:47:43 - INFO - __main__ - train loss is 7.689163236878812\n",
      "Steps:  46%|▍| 6924/15000 [44:21<27:21,  4.92it/s, lr=9.68e-6, step_loss=0.0048407/18/2023 19:47:43 - INFO - __main__ - train loss is 8.478035836480558\n",
      "Steps:  46%|▉ | 6925/15000 [44:21<26:35,  5.06it/s, lr=9.68e-6, step_loss=0.789]07/18/2023 19:47:43 - INFO - __main__ - train loss is 8.485469782724977\n",
      "Steps:  46%|▍| 6926/15000 [44:21<26:25,  5.09it/s, lr=9.68e-6, step_loss=0.0074307/18/2023 19:47:43 - INFO - __main__ - train loss is 8.487598983105272\n",
      "Steps:  46%|▍| 6927/15000 [44:21<26:20,  5.11it/s, lr=9.68e-6, step_loss=0.0021307/18/2023 19:47:44 - INFO - __main__ - train loss is 8.547903919126838\n",
      "Steps:  46%|▍| 6928/15000 [44:21<26:18,  5.12it/s, lr=9.68e-6, step_loss=0.0603]07/18/2023 19:47:44 - INFO - __main__ - train loss is 8.705517643596977\n",
      "Steps:  46%|▉ | 6929/15000 [44:22<25:54,  5.19it/s, lr=9.68e-6, step_loss=0.158]07/18/2023 19:47:44 - INFO - __main__ - train loss is 8.776676231529564\n",
      "Steps:  46%|▍| 6930/15000 [44:22<25:29,  5.27it/s, lr=9.68e-6, step_loss=0.0712]07/18/2023 19:47:44 - INFO - __main__ - train loss is 9.196613961365074\n",
      "Steps:  46%|█▍ | 6931/15000 [44:22<25:15,  5.32it/s, lr=9.68e-6, step_loss=0.42]07/18/2023 19:47:44 - INFO - __main__ - train loss is 9.224927788134664\n",
      "Steps:  46%|▍| 6932/15000 [44:22<25:16,  5.32it/s, lr=9.68e-6, step_loss=0.0283]07/18/2023 19:47:44 - INFO - __main__ - train loss is 9.725844567175955\n",
      "Steps:  46%|▉ | 6933/15000 [44:22<25:04,  5.36it/s, lr=9.68e-6, step_loss=0.501]07/18/2023 19:47:45 - INFO - __main__ - train loss is 9.7330408138223\n",
      "Steps:  46%|▍| 6934/15000 [44:23<25:10,  5.34it/s, lr=9.68e-6, step_loss=0.0072]07/18/2023 19:47:45 - INFO - __main__ - train loss is 9.787208881694824\n",
      "Steps:  46%|▍| 6935/15000 [44:23<25:29,  5.27it/s, lr=9.68e-6, step_loss=0.0542]07/18/2023 19:47:45 - INFO - __main__ - train loss is 9.795842164661735\n",
      "Steps:  46%|▍| 6936/15000 [44:23<25:43,  5.22it/s, lr=9.68e-6, step_loss=0.0086307/18/2023 19:47:45 - INFO - __main__ - train loss is 10.420082980301231\n",
      "Steps:  46%|▉ | 6937/15000 [44:23<26:15,  5.12it/s, lr=9.68e-6, step_loss=0.624]07/18/2023 19:47:45 - INFO - __main__ - train loss is 10.529015266802162\n",
      "Steps:  46%|▉ | 6938/15000 [44:23<26:11,  5.13it/s, lr=9.68e-6, step_loss=0.109]07/18/2023 19:47:46 - INFO - __main__ - train loss is 10.656474733259529\n",
      "Steps:  46%|▉ | 6939/15000 [44:24<25:37,  5.24it/s, lr=9.68e-6, step_loss=0.127]07/18/2023 19:47:46 - INFO - __main__ - train loss is 11.11623361101374\n",
      "Steps:  46%|█▍ | 6940/15000 [44:24<25:21,  5.30it/s, lr=9.67e-6, step_loss=0.46]07/18/2023 19:47:46 - INFO - __main__ - train loss is 11.262410604860634\n",
      "Steps:  46%|▉ | 6941/15000 [44:24<24:59,  5.37it/s, lr=9.67e-6, step_loss=0.146]07/18/2023 19:47:46 - INFO - __main__ - train loss is 11.296394058968872\n",
      "Steps:  46%|▉ | 6942/15000 [44:24<24:46,  5.42it/s, lr=9.67e-6, step_loss=0.034]07/18/2023 19:47:46 - INFO - __main__ - train loss is 11.298787084408104\n",
      "Steps:  46%|▍| 6943/15000 [44:24<24:37,  5.45it/s, lr=9.67e-6, step_loss=0.0023907/18/2023 19:47:47 - INFO - __main__ - train loss is 11.300780529156327\n",
      "Steps:  46%|▍| 6944/15000 [44:24<24:45,  5.42it/s, lr=9.67e-6, step_loss=0.0019907/18/2023 19:47:47 - INFO - __main__ - train loss is 11.302800653968006\n",
      "Steps:  46%|▍| 6945/15000 [44:25<24:42,  5.44it/s, lr=9.67e-6, step_loss=0.0020207/18/2023 19:47:47 - INFO - __main__ - train loss is 11.311530645471066\n",
      "Steps:  46%|▍| 6946/15000 [44:25<24:34,  5.46it/s, lr=9.67e-6, step_loss=0.0087307/18/2023 19:47:47 - INFO - __main__ - train loss is 11.724200184922665\n",
      "Steps:  46%|▉ | 6947/15000 [44:25<24:28,  5.48it/s, lr=9.67e-6, step_loss=0.413]07/18/2023 19:47:47 - INFO - __main__ - train loss is 11.742574709933251\n",
      "Steps:  46%|▍| 6948/15000 [44:25<24:24,  5.50it/s, lr=9.67e-6, step_loss=0.0184]07/18/2023 19:47:47 - INFO - __main__ - train loss is 11.868358317296952\n",
      "Steps:  46%|▉ | 6949/15000 [44:25<24:25,  5.50it/s, lr=9.67e-6, step_loss=0.126]07/18/2023 19:47:48 - INFO - __main__ - train loss is 12.001283976715058\n",
      "Steps:  46%|▉ | 6950/15000 [44:26<24:22,  5.51it/s, lr=9.67e-6, step_loss=0.133]07/18/2023 19:47:48 - INFO - __main__ - train loss is 12.308548036497086\n",
      "Steps:  46%|▉ | 6951/15000 [44:26<24:20,  5.51it/s, lr=9.67e-6, step_loss=0.307]07/18/2023 19:47:48 - INFO - __main__ - train loss is 12.333797059487551\n",
      "Steps:  46%|▍| 6952/15000 [44:26<24:19,  5.51it/s, lr=9.67e-6, step_loss=0.0252]07/18/2023 19:47:48 - INFO - __main__ - train loss is 12.33613138878718\n",
      "Steps:  46%|▍| 6953/15000 [44:26<24:19,  5.51it/s, lr=9.67e-6, step_loss=0.0023307/18/2023 19:47:48 - INFO - __main__ - train loss is 12.8171241232194\n",
      "Steps:  46%|▉ | 6954/15000 [44:26<24:20,  5.51it/s, lr=9.67e-6, step_loss=0.481]07/18/2023 19:47:49 - INFO - __main__ - train loss is 12.829657254274935\n",
      "Steps:  46%|▍| 6955/15000 [44:26<24:18,  5.52it/s, lr=9.67e-6, step_loss=0.0125]07/18/2023 19:47:49 - INFO - __main__ - train loss is 12.847161283250898\n",
      "Steps:  46%|▍| 6956/15000 [44:27<24:18,  5.51it/s, lr=9.67e-6, step_loss=0.0175]07/18/2023 19:47:49 - INFO - __main__ - train loss is 12.871141945477575\n",
      "Steps:  46%|▉ | 6957/15000 [44:27<24:17,  5.52it/s, lr=9.67e-6, step_loss=0.024]07/18/2023 19:47:49 - INFO - __main__ - train loss is 12.931639505084604\n",
      "Steps:  46%|▍| 6958/15000 [44:27<24:16,  5.52it/s, lr=9.67e-6, step_loss=0.0605]07/18/2023 19:47:49 - INFO - __main__ - train loss is 12.985256729181856\n",
      "Steps:  46%|▍| 6959/15000 [44:27<24:15,  5.52it/s, lr=9.67e-6, step_loss=0.0536]07/18/2023 19:47:49 - INFO - __main__ - train loss is 13.063373146113008\n",
      "Steps:  46%|▍| 6960/15000 [44:27<24:15,  5.52it/s, lr=9.67e-6, step_loss=0.0781]07/18/2023 19:47:50 - INFO - __main__ - train loss is 13.614340958651155\n",
      "Steps:  46%|▉ | 6961/15000 [44:28<24:15,  5.52it/s, lr=9.67e-6, step_loss=0.551]07/18/2023 19:47:50 - INFO - __main__ - train loss is 14.171944437082857\n",
      "Steps:  46%|▉ | 6962/15000 [44:28<24:14,  5.53it/s, lr=9.67e-6, step_loss=0.558]07/18/2023 19:47:50 - INFO - __main__ - train loss is 14.245919396635145\n",
      "Steps:  46%|▉ | 6963/15000 [44:28<24:14,  5.52it/s, lr=9.67e-6, step_loss=0.074]07/18/2023 19:47:50 - INFO - __main__ - train loss is 14.302903769072145\n",
      "Steps:  46%|▉ | 6964/15000 [44:28<24:14,  5.53it/s, lr=9.67e-6, step_loss=0.057]07/18/2023 19:47:50 - INFO - __main__ - train loss is 14.865273532923311\n",
      "Steps:  46%|▉ | 6965/15000 [44:28<24:28,  5.47it/s, lr=9.67e-6, step_loss=0.562]07/18/2023 19:47:51 - INFO - __main__ - train loss is 14.902381678577513\n",
      "Steps:  46%|▍| 6966/15000 [44:28<24:22,  5.49it/s, lr=9.67e-6, step_loss=0.0371]07/18/2023 19:47:51 - INFO - __main__ - train loss is 14.935008329804987\n",
      "Steps:  46%|▍| 6967/15000 [44:29<24:12,  5.53it/s, lr=9.67e-6, step_loss=0.0326]07/18/2023 19:47:51 - INFO - __main__ - train loss is 14.94106610165909\n",
      "Steps:  46%|▍| 6968/15000 [44:29<24:06,  5.55it/s, lr=9.67e-6, step_loss=0.0060607/18/2023 19:47:51 - INFO - __main__ - train loss is 15.165091902483255\n",
      "Steps:  46%|▉ | 6969/15000 [44:29<24:02,  5.57it/s, lr=9.67e-6, step_loss=0.224]07/18/2023 19:47:51 - INFO - __main__ - train loss is 15.170467679854482\n",
      "Steps:  46%|▍| 6970/15000 [44:29<24:08,  5.54it/s, lr=9.67e-6, step_loss=0.0053807/18/2023 19:47:51 - INFO - __main__ - train loss is 15.52430618321523\n",
      "Steps:  46%|▉ | 6971/15000 [44:29<24:02,  5.57it/s, lr=9.67e-6, step_loss=0.354]07/18/2023 19:47:52 - INFO - __main__ - train loss is 15.544323646929115\n",
      "Steps:  46%|█▍ | 6972/15000 [44:30<23:58,  5.58it/s, lr=9.67e-6, step_loss=0.02]07/18/2023 19:47:52 - INFO - __main__ - train loss is 15.55541227152571\n",
      "Steps:  46%|▍| 6973/15000 [44:30<23:55,  5.59it/s, lr=9.67e-6, step_loss=0.0111]07/18/2023 19:47:52 - INFO - __main__ - train loss is 15.726334580685943\n",
      "Steps:  46%|▉ | 6974/15000 [44:30<23:53,  5.60it/s, lr=9.67e-6, step_loss=0.171]07/18/2023 19:47:52 - INFO - __main__ - train loss is 15.791457825805992\n",
      "Steps:  46%|▍| 6975/15000 [44:30<23:51,  5.61it/s, lr=9.67e-6, step_loss=0.0651]07/18/2023 19:47:52 - INFO - __main__ - train loss is 15.794941923115402\n",
      "Steps:  47%|▍| 6976/15000 [44:30<23:50,  5.61it/s, lr=9.67e-6, step_loss=0.0034807/18/2023 19:47:53 - INFO - __main__ - train loss is 15.873647181782871\n",
      "Steps:  47%|▍| 6977/15000 [44:30<23:51,  5.60it/s, lr=9.67e-6, step_loss=0.0787]07/18/2023 19:47:53 - INFO - __main__ - train loss is 16.247948168311268\n",
      "Steps:  47%|▉ | 6978/15000 [44:31<23:56,  5.58it/s, lr=9.67e-6, step_loss=0.374]07/18/2023 19:47:53 - INFO - __main__ - train loss is 16.269793244544417\n",
      "Steps:  47%|▍| 6979/15000 [44:31<23:54,  5.59it/s, lr=9.67e-6, step_loss=0.0218]07/18/2023 19:47:53 - INFO - __main__ - train loss is 16.334985765162855\n",
      "Steps:  47%|▍| 6980/15000 [44:31<23:52,  5.60it/s, lr=9.67e-6, step_loss=0.0652]07/18/2023 19:47:53 - INFO - __main__ - train loss is 16.523597466293722\n",
      "Steps:  47%|▉ | 6981/15000 [44:31<23:51,  5.60it/s, lr=9.67e-6, step_loss=0.189]07/18/2023 19:47:53 - INFO - __main__ - train loss is 16.819038855377585\n",
      "Steps:  47%|▉ | 6982/15000 [44:31<23:49,  5.61it/s, lr=9.67e-6, step_loss=0.295]07/18/2023 19:47:54 - INFO - __main__ - train loss is 16.842292743269354\n",
      "Steps:  47%|▍| 6983/15000 [44:31<23:48,  5.61it/s, lr=9.67e-6, step_loss=0.0233]07/18/2023 19:47:54 - INFO - __main__ - train loss is 16.86022365698591\n",
      "Steps:  47%|▍| 6984/15000 [44:32<32:45,  4.08it/s, lr=9.67e-6, step_loss=0.0179]07/18/2023 19:47:55 - INFO - __main__ - Per validation step average loss is 0.20002257823944092\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Cumulative validation average loss is 0.20002257823944092\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Per validation step average loss is 0.1791415959596634\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Cumulative validation average loss is 0.3791641741991043\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Per validation step average loss is 0.06777556240558624\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Cumulative validation average loss is 0.44693973660469055\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Per validation step average loss is 0.24288161098957062\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Cumulative validation average loss is 0.6898213475942612\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Per validation step average loss is 0.14217683672904968\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Cumulative validation average loss is 0.8319981843233109\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Per validation step average loss is 0.002629700116813183\n",
      "07/18/2023 19:47:55 - INFO - __main__ - Cumulative validation average loss is 0.834627884440124\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Per validation step average loss is 0.03745490312576294\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Cumulative validation average loss is 0.872082787565887\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Per validation step average loss is 0.15490314364433289\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Cumulative validation average loss is 1.0269859312102199\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Per validation step average loss is 0.08727367222309113\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Cumulative validation average loss is 1.114259603433311\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Per validation step average loss is 0.021084416657686234\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Cumulative validation average loss is 1.1353440200909972\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Per validation step average loss is 0.14425480365753174\n",
      "07/18/2023 19:47:56 - INFO - __main__ - Cumulative validation average loss is 1.279598823748529\n",
      "07/18/2023 19:47:57 - INFO - __main__ - Per validation step average loss is 0.061420705169439316\n",
      "07/18/2023 19:47:57 - INFO - __main__ - Cumulative validation average loss is 1.3410195289179683\n",
      "07/18/2023 19:47:57 - INFO - __main__ - Average validation loss for Epoch 71 is 0.11175162740983069\n",
      "07/18/2023 19:47:57 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:48:09 - INFO - __main__ - Starting epoch 72\n",
      "07/18/2023 19:48:10 - INFO - __main__ - train loss is 0.008094236254692078\n",
      "Steps:  47%|▍| 6985/15000 [44:48<10:57:07,  4.92s/it, lr=9.67e-6, step_loss=0.0007/18/2023 19:48:10 - INFO - __main__ - train loss is 0.2182377725839615\n",
      "Steps:  47%|▍| 6986/15000 [44:48<7:47:04,  3.50s/it, lr=9.67e-6, step_loss=0.21]07/18/2023 19:48:10 - INFO - __main__ - train loss is 0.22336946427822113\n",
      "Steps:  47%|▍| 6987/15000 [44:48<5:34:02,  2.50s/it, lr=9.67e-6, step_loss=0.00507/18/2023 19:48:10 - INFO - __main__ - train loss is 0.4651630371809006\n",
      "Steps:  47%|▍| 6988/15000 [44:48<4:01:12,  1.81s/it, lr=9.67e-6, step_loss=0.24207/18/2023 19:48:11 - INFO - __main__ - train loss is 0.4674161244183779\n",
      "Steps:  47%|▍| 6989/15000 [44:48<2:55:57,  1.32s/it, lr=9.67e-6, step_loss=0.00207/18/2023 19:48:11 - INFO - __main__ - train loss is 0.4731999896466732\n",
      "Steps:  47%|▍| 6990/15000 [44:49<2:10:21,  1.02it/s, lr=9.67e-6, step_loss=0.00507/18/2023 19:48:11 - INFO - __main__ - train loss is 0.503713633865118\n",
      "Steps:  47%|▍| 6991/15000 [44:49<1:38:27,  1.36it/s, lr=9.67e-6, step_loss=0.03007/18/2023 19:48:11 - INFO - __main__ - train loss is 0.5055997463641688\n",
      "Steps:  47%|▍| 6992/15000 [44:49<1:16:01,  1.76it/s, lr=9.67e-6, step_loss=0.00107/18/2023 19:48:11 - INFO - __main__ - train loss is 0.6800301166949794\n",
      "Steps:  47%|▍| 6993/15000 [44:49<1:00:20,  2.21it/s, lr=9.67e-6, step_loss=0.17407/18/2023 19:48:11 - INFO - __main__ - train loss is 0.988859603065066\n",
      "Steps:  47%|▉ | 6994/15000 [44:49<49:21,  2.70it/s, lr=9.67e-6, step_loss=0.309]07/18/2023 19:48:12 - INFO - __main__ - train loss is 1.1009653526125476\n",
      "Steps:  47%|▉ | 6995/15000 [44:50<42:22,  3.15it/s, lr=9.67e-6, step_loss=0.112]07/18/2023 19:48:12 - INFO - __main__ - train loss is 1.1181271428940818\n",
      "Steps:  47%|▍| 6996/15000 [44:50<38:18,  3.48it/s, lr=9.67e-6, step_loss=0.0172]07/18/2023 19:48:12 - INFO - __main__ - train loss is 1.4258946533082053\n",
      "Steps:  47%|▉ | 6997/15000 [44:50<35:19,  3.78it/s, lr=9.67e-6, step_loss=0.308]07/18/2023 19:48:12 - INFO - __main__ - train loss is 1.789162581670098\n",
      "Steps:  47%|▉ | 6998/15000 [44:50<33:13,  4.01it/s, lr=9.67e-6, step_loss=0.363]07/18/2023 19:48:12 - INFO - __main__ - train loss is 1.7919681611238047\n",
      "Steps:  47%|▍| 6999/15000 [44:50<32:03,  4.16it/s, lr=9.67e-6, step_loss=0.0028107/18/2023 19:48:13 - INFO - __main__ - train loss is 1.797630711342208\n",
      "Steps:  47%|▍| 7000/15000 [44:51<31:08,  4.28it/s, lr=9.67e-6, step_loss=0.0028107/18/2023 19:48:13 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-7000\n",
      "07/18/2023 19:48:13 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:48:13,284] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:48:13,292] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-7000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:48:13,292] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-7000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:48:13,305] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-7000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:48:13,305] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-7000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:48:13,329] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-7000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:48:13,329] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-7000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:48:13,329] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:48:13 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-7000/pytorch_model\n",
      "07/18/2023 19:48:13 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-7000/scheduler.bin\n",
      "07/18/2023 19:48:13 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-7000/random_states_0.pkl\n",
      "07/18/2023 19:48:13 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-7000\n",
      "Steps:  47%|▍| 7000/15000 [44:51<31:08,  4.28it/s, lr=9.67e-6, step_loss=0.0056607/18/2023 19:48:13 - INFO - __main__ - train loss is 2.1245174248469993\n",
      "Steps:  47%|▉ | 7001/15000 [44:51<32:04,  4.16it/s, lr=9.67e-6, step_loss=0.327]07/18/2023 19:48:13 - INFO - __main__ - train loss is 2.1364929348928854\n",
      "Steps:  47%|▉ | 7002/15000 [44:51<29:58,  4.45it/s, lr=9.67e-6, step_loss=0.012]07/18/2023 19:48:13 - INFO - __main__ - train loss is 2.220126536558382\n",
      "Steps:  47%|▍| 7003/15000 [44:51<28:16,  4.71it/s, lr=9.67e-6, step_loss=0.0836]07/18/2023 19:48:14 - INFO - __main__ - train loss is 2.428139236639254\n",
      "Steps:  47%|▉ | 7004/15000 [44:51<26:56,  4.95it/s, lr=9.67e-6, step_loss=0.208]07/18/2023 19:48:14 - INFO - __main__ - train loss is 2.4583485805196688\n",
      "Steps:  47%|▍| 7005/15000 [44:52<25:59,  5.13it/s, lr=9.67e-6, step_loss=0.0302]07/18/2023 19:48:14 - INFO - __main__ - train loss is 2.5014636971754953\n",
      "Steps:  47%|▍| 7006/15000 [44:52<25:28,  5.23it/s, lr=9.67e-6, step_loss=0.0431]07/18/2023 19:48:14 - INFO - __main__ - train loss is 2.536884055356495\n",
      "Steps:  47%|▍| 7007/15000 [44:52<24:58,  5.34it/s, lr=9.67e-6, step_loss=0.0354]07/18/2023 19:48:14 - INFO - __main__ - train loss is 2.650317654828541\n",
      "Steps:  47%|▉ | 7008/15000 [44:52<24:50,  5.36it/s, lr=9.67e-6, step_loss=0.113]07/18/2023 19:48:14 - INFO - __main__ - train loss is 2.6745622371090576\n",
      "Steps:  47%|▍| 7009/15000 [44:52<24:35,  5.42it/s, lr=9.67e-6, step_loss=0.0242]07/18/2023 19:48:15 - INFO - __main__ - train loss is 2.798065758193843\n",
      "Steps:  47%|▉ | 7010/15000 [44:52<24:20,  5.47it/s, lr=9.67e-6, step_loss=0.124]07/18/2023 19:48:15 - INFO - __main__ - train loss is 2.825411680038087\n",
      "Steps:  47%|▍| 7011/15000 [44:53<24:10,  5.51it/s, lr=9.67e-6, step_loss=0.0273]07/18/2023 19:48:15 - INFO - __main__ - train loss is 2.8277258434100077\n",
      "Steps:  47%|▍| 7012/15000 [44:53<24:03,  5.53it/s, lr=9.67e-6, step_loss=0.0023107/18/2023 19:48:15 - INFO - __main__ - train loss is 3.076528296689503\n",
      "Steps:  47%|▉ | 7013/15000 [44:53<24:05,  5.53it/s, lr=9.67e-6, step_loss=0.249]07/18/2023 19:48:15 - INFO - __main__ - train loss is 3.0923347630305216\n",
      "Steps:  47%|▍| 7014/15000 [44:53<24:00,  5.54it/s, lr=9.67e-6, step_loss=0.0158]07/18/2023 19:48:15 - INFO - __main__ - train loss is 3.10220171965193\n",
      "Steps:  47%|▍| 7015/15000 [44:53<23:56,  5.56it/s, lr=9.67e-6, step_loss=0.0098707/18/2023 19:48:16 - INFO - __main__ - train loss is 3.11044857732486\n",
      "Steps:  47%|▍| 7016/15000 [44:54<23:53,  5.57it/s, lr=9.67e-6, step_loss=0.0082507/18/2023 19:48:16 - INFO - __main__ - train loss is 3.1214530783472583\n",
      "Steps:  47%|▉ | 7017/15000 [44:54<23:50,  5.58it/s, lr=9.67e-6, step_loss=0.011]07/18/2023 19:48:16 - INFO - __main__ - train loss is 3.2273717167554423\n",
      "Steps:  47%|▉ | 7018/15000 [44:54<23:49,  5.58it/s, lr=9.67e-6, step_loss=0.106]07/18/2023 19:48:16 - INFO - __main__ - train loss is 3.230500021367334\n",
      "Steps:  47%|▍| 7019/15000 [44:54<23:58,  5.55it/s, lr=9.67e-6, step_loss=0.0031307/18/2023 19:48:16 - INFO - __main__ - train loss is 3.404955187230371\n",
      "Steps:  47%|▉ | 7020/15000 [44:54<23:58,  5.55it/s, lr=9.67e-6, step_loss=0.174]07/18/2023 19:48:17 - INFO - __main__ - train loss is 3.598482438712381\n",
      "Steps:  47%|▉ | 7021/15000 [44:54<23:53,  5.57it/s, lr=9.67e-6, step_loss=0.194]07/18/2023 19:48:17 - INFO - __main__ - train loss is 3.6967458812287077\n",
      "Steps:  47%|▍| 7022/15000 [44:55<23:49,  5.58it/s, lr=9.67e-6, step_loss=0.0983]07/18/2023 19:48:17 - INFO - __main__ - train loss is 4.359855600981973\n",
      "Steps:  47%|▉ | 7023/15000 [44:55<23:47,  5.59it/s, lr=9.67e-6, step_loss=0.663]07/18/2023 19:48:17 - INFO - __main__ - train loss is 4.363088988815434\n",
      "Steps:  47%|▍| 7024/15000 [44:55<23:45,  5.59it/s, lr=9.67e-6, step_loss=0.0032307/18/2023 19:48:17 - INFO - __main__ - train loss is 4.412482739542611\n",
      "Steps:  47%|▍| 7025/15000 [44:55<23:44,  5.60it/s, lr=9.67e-6, step_loss=0.0494]07/18/2023 19:48:17 - INFO - __main__ - train loss is 4.424750542384572\n",
      "Steps:  47%|▍| 7026/15000 [44:55<23:43,  5.60it/s, lr=9.67e-6, step_loss=0.0123]07/18/2023 19:48:18 - INFO - __main__ - train loss is 4.451115332660265\n",
      "Steps:  47%|▍| 7027/15000 [44:56<23:43,  5.60it/s, lr=9.67e-6, step_loss=0.0264]07/18/2023 19:48:18 - INFO - __main__ - train loss is 4.553027205285616\n",
      "Steps:  47%|▉ | 7028/15000 [44:56<23:42,  5.60it/s, lr=9.67e-6, step_loss=0.102]07/18/2023 19:48:18 - INFO - __main__ - train loss is 4.662104360875674\n",
      "Steps:  47%|▉ | 7029/15000 [44:56<23:42,  5.60it/s, lr=9.67e-6, step_loss=0.109]07/18/2023 19:48:18 - INFO - __main__ - train loss is 5.161861501750536\n",
      "Steps:  47%|█▊  | 7030/15000 [44:56<23:41,  5.61it/s, lr=9.67e-6, step_loss=0.5]07/18/2023 19:48:18 - INFO - __main__ - train loss is 5.164575724978931\n",
      "Steps:  47%|▍| 7031/15000 [44:56<23:44,  5.60it/s, lr=9.67e-6, step_loss=0.0027107/18/2023 19:48:19 - INFO - __main__ - train loss is 5.575871854205616\n",
      "Steps:  47%|▉ | 7032/15000 [44:56<23:43,  5.60it/s, lr=9.67e-6, step_loss=0.411]07/18/2023 19:48:19 - INFO - __main__ - train loss is 6.256331115146168\n",
      "Steps:  47%|█▍ | 7033/15000 [44:57<23:43,  5.60it/s, lr=9.67e-6, step_loss=0.68]07/18/2023 19:48:19 - INFO - __main__ - train loss is 6.282938025076874\n",
      "Steps:  47%|▍| 7034/15000 [44:57<23:43,  5.60it/s, lr=9.67e-6, step_loss=0.0266]07/18/2023 19:48:19 - INFO - __main__ - train loss is 6.38396114774514\n",
      "Steps:  47%|▉ | 7035/15000 [44:57<23:41,  5.60it/s, lr=9.67e-6, step_loss=0.101]07/18/2023 19:48:19 - INFO - __main__ - train loss is 6.4317411101656035\n",
      "Steps:  47%|▍| 7036/15000 [44:57<23:42,  5.60it/s, lr=9.67e-6, step_loss=0.0478]07/18/2023 19:48:19 - INFO - __main__ - train loss is 6.686439803917892\n",
      "Steps:  47%|▉ | 7037/15000 [44:57<23:41,  5.60it/s, lr=9.67e-6, step_loss=0.255]07/18/2023 19:48:20 - INFO - __main__ - train loss is 6.691510721691884\n",
      "Steps:  47%|▍| 7038/15000 [44:57<23:55,  5.55it/s, lr=9.67e-6, step_loss=0.0050707/18/2023 19:48:20 - INFO - __main__ - train loss is 6.7273776304209605\n",
      "Steps:  47%|▍| 7039/15000 [44:58<24:04,  5.51it/s, lr=9.67e-6, step_loss=0.0359]07/18/2023 19:48:20 - INFO - __main__ - train loss is 6.9154161881888285\n",
      "Steps:  47%|▉ | 7040/15000 [44:58<24:10,  5.49it/s, lr=9.67e-6, step_loss=0.188]07/18/2023 19:48:20 - INFO - __main__ - train loss is 6.929810750880279\n",
      "Steps:  47%|▍| 7041/15000 [44:58<24:06,  5.50it/s, lr=9.67e-6, step_loss=0.0144]07/18/2023 19:48:20 - INFO - __main__ - train loss is 7.267461884417571\n",
      "Steps:  47%|▉ | 7042/15000 [44:58<23:58,  5.53it/s, lr=9.67e-6, step_loss=0.338]07/18/2023 19:48:21 - INFO - __main__ - train loss is 7.727981257834472\n",
      "Steps:  47%|▉ | 7043/15000 [44:58<23:52,  5.55it/s, lr=9.67e-6, step_loss=0.461]07/18/2023 19:48:21 - INFO - __main__ - train loss is 8.097374844946899\n",
      "Steps:  47%|▉ | 7044/15000 [44:59<23:48,  5.57it/s, lr=9.67e-6, step_loss=0.369]07/18/2023 19:48:21 - INFO - __main__ - train loss is 8.135707702138461\n",
      "Steps:  47%|▍| 7045/15000 [44:59<23:44,  5.58it/s, lr=9.67e-6, step_loss=0.0383]07/18/2023 19:48:21 - INFO - __main__ - train loss is 8.892862762906589\n",
      "Steps:  47%|▉ | 7046/15000 [44:59<23:43,  5.59it/s, lr=9.67e-6, step_loss=0.757]07/18/2023 19:48:21 - INFO - __main__ - train loss is 8.907013874151744\n",
      "Steps:  47%|▍| 7047/15000 [44:59<23:40,  5.60it/s, lr=9.66e-6, step_loss=0.0142]07/18/2023 19:48:21 - INFO - __main__ - train loss is 9.552198152639903\n",
      "Steps:  47%|▉ | 7048/15000 [44:59<23:39,  5.60it/s, lr=9.66e-6, step_loss=0.645]07/18/2023 19:48:22 - INFO - __main__ - train loss is 9.61951976607088\n",
      "Steps:  47%|▍| 7049/15000 [44:59<23:40,  5.60it/s, lr=9.66e-6, step_loss=0.0673]07/18/2023 19:48:22 - INFO - __main__ - train loss is 9.646637040772475\n",
      "Steps:  47%|▍| 7050/15000 [45:00<23:53,  5.55it/s, lr=9.66e-6, step_loss=0.0271]07/18/2023 19:48:22 - INFO - __main__ - train loss is 9.917926150956191\n",
      "Steps:  47%|▉ | 7051/15000 [45:00<23:54,  5.54it/s, lr=9.66e-6, step_loss=0.271]07/18/2023 19:48:22 - INFO - __main__ - train loss is 10.203091162838973\n",
      "Steps:  47%|▉ | 7052/15000 [45:00<23:48,  5.56it/s, lr=9.66e-6, step_loss=0.285]07/18/2023 19:48:22 - INFO - __main__ - train loss is 10.251475557335652\n",
      "Steps:  47%|▍| 7053/15000 [45:00<23:44,  5.58it/s, lr=9.66e-6, step_loss=0.0484]07/18/2023 19:48:22 - INFO - __main__ - train loss is 10.67057387495879\n",
      "Steps:  47%|▉ | 7054/15000 [45:00<23:45,  5.57it/s, lr=9.66e-6, step_loss=0.419]07/18/2023 19:48:23 - INFO - __main__ - train loss is 10.914249255903997\n",
      "Steps:  47%|▉ | 7055/15000 [45:01<23:43,  5.58it/s, lr=9.66e-6, step_loss=0.244]07/18/2023 19:48:23 - INFO - __main__ - train loss is 10.941732052364387\n",
      "Steps:  47%|▍| 7056/15000 [45:01<23:40,  5.59it/s, lr=9.66e-6, step_loss=0.0275]07/18/2023 19:48:23 - INFO - __main__ - train loss is 10.984723452129401\n",
      "Steps:  47%|▉ | 7057/15000 [45:01<23:52,  5.54it/s, lr=9.66e-6, step_loss=0.043]07/18/2023 19:48:23 - INFO - __main__ - train loss is 11.174751389422454\n",
      "Steps:  47%|█▍ | 7058/15000 [45:01<23:47,  5.56it/s, lr=9.66e-6, step_loss=0.19]07/18/2023 19:48:23 - INFO - __main__ - train loss is 11.402205172576942\n",
      "Steps:  47%|▉ | 7059/15000 [45:01<23:44,  5.58it/s, lr=9.66e-6, step_loss=0.227]07/18/2023 19:48:24 - INFO - __main__ - train loss is 11.902077261009254\n",
      "Steps:  47%|█▉  | 7060/15000 [45:01<23:54,  5.53it/s, lr=9.66e-6, step_loss=0.5]07/18/2023 19:48:24 - INFO - __main__ - train loss is 11.903769822558388\n",
      "Steps:  47%|▍| 7061/15000 [45:02<23:58,  5.52it/s, lr=9.66e-6, step_loss=0.0016907/18/2023 19:48:24 - INFO - __main__ - train loss is 12.008611829718575\n",
      "Steps:  47%|▉ | 7062/15000 [45:02<24:04,  5.50it/s, lr=9.66e-6, step_loss=0.105]07/18/2023 19:48:24 - INFO - __main__ - train loss is 12.054571592947468\n",
      "Steps:  47%|▉ | 7063/15000 [45:02<24:09,  5.47it/s, lr=9.66e-6, step_loss=0.046]07/18/2023 19:48:24 - INFO - __main__ - train loss is 12.236409688135609\n",
      "Steps:  47%|▉ | 7064/15000 [45:02<24:04,  5.49it/s, lr=9.66e-6, step_loss=0.182]07/18/2023 19:48:24 - INFO - __main__ - train loss is 12.526026690145954\n",
      "Steps:  47%|█▍ | 7065/15000 [45:02<23:56,  5.52it/s, lr=9.66e-6, step_loss=0.29]07/18/2023 19:48:25 - INFO - __main__ - train loss is 12.550661919405684\n",
      "Steps:  47%|▍| 7066/15000 [45:03<23:50,  5.54it/s, lr=9.66e-6, step_loss=0.0246]07/18/2023 19:48:25 - INFO - __main__ - train loss is 12.562696760287508\n",
      "Steps:  47%|▉ | 7067/15000 [45:03<23:59,  5.51it/s, lr=9.66e-6, step_loss=0.012]07/18/2023 19:48:25 - INFO - __main__ - train loss is 12.569514198461547\n",
      "Steps:  47%|▍| 7068/15000 [45:03<24:15,  5.45it/s, lr=9.66e-6, step_loss=0.0068207/18/2023 19:48:25 - INFO - __main__ - train loss is 12.626330903032795\n",
      "Steps:  47%|▍| 7069/15000 [45:03<24:11,  5.46it/s, lr=9.66e-6, step_loss=0.0568]07/18/2023 19:48:25 - INFO - __main__ - train loss is 12.96867965743877\n",
      "Steps:  47%|▉ | 7070/15000 [45:03<23:59,  5.51it/s, lr=9.66e-6, step_loss=0.342]07/18/2023 19:48:26 - INFO - __main__ - train loss is 13.057242131093517\n",
      "Steps:  47%|▍| 7071/15000 [45:03<23:51,  5.54it/s, lr=9.66e-6, step_loss=0.0886]07/18/2023 19:48:26 - INFO - __main__ - train loss is 13.171577258268371\n",
      "Steps:  47%|▉ | 7072/15000 [45:04<23:46,  5.56it/s, lr=9.66e-6, step_loss=0.114]07/18/2023 19:48:26 - INFO - __main__ - train loss is 13.78618554607965\n",
      "Steps:  47%|▉ | 7073/15000 [45:04<23:41,  5.58it/s, lr=9.66e-6, step_loss=0.615]07/18/2023 19:48:26 - INFO - __main__ - train loss is 13.789111942052841\n",
      "Steps:  47%|▍| 7074/15000 [45:04<23:38,  5.59it/s, lr=9.66e-6, step_loss=0.0029307/18/2023 19:48:26 - INFO - __main__ - train loss is 13.799472481943667\n",
      "Steps:  47%|▍| 7075/15000 [45:04<23:36,  5.59it/s, lr=9.66e-6, step_loss=0.0104]07/18/2023 19:48:26 - INFO - __main__ - train loss is 14.08296284172684\n",
      "Steps:  47%|▉ | 7076/15000 [45:04<23:36,  5.60it/s, lr=9.66e-6, step_loss=0.283]07/18/2023 19:48:27 - INFO - __main__ - train loss is 14.086572458967566\n",
      "Steps:  47%|▍| 7077/15000 [45:05<23:34,  5.60it/s, lr=9.66e-6, step_loss=0.0036107/18/2023 19:48:27 - INFO - __main__ - train loss is 14.1164476480335\n",
      "Steps:  47%|▍| 7078/15000 [45:05<23:34,  5.60it/s, lr=9.66e-6, step_loss=0.0299]07/18/2023 19:48:27 - INFO - __main__ - train loss is 14.165513386949897\n",
      "Steps:  47%|▍| 7079/15000 [45:05<23:32,  5.61it/s, lr=9.66e-6, step_loss=0.0491]07/18/2023 19:48:27 - INFO - __main__ - train loss is 14.234462289139628\n",
      "Steps:  47%|▍| 7080/15000 [45:05<23:32,  5.61it/s, lr=9.66e-6, step_loss=0.0689]07/18/2023 19:48:28 - INFO - __main__ - train loss is 14.237216213718057\n",
      "Steps:  47%|▍| 7081/15000 [45:05<32:12,  4.10it/s, lr=9.66e-6, step_loss=0.0027507/18/2023 19:48:28 - INFO - __main__ - Per validation step average loss is 0.027155790477991104\n",
      "07/18/2023 19:48:28 - INFO - __main__ - Cumulative validation average loss is 0.027155790477991104\n",
      "07/18/2023 19:48:28 - INFO - __main__ - Per validation step average loss is 0.3642647862434387\n",
      "07/18/2023 19:48:28 - INFO - __main__ - Cumulative validation average loss is 0.3914205767214298\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Per validation step average loss is 0.0053633409552276134\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Cumulative validation average loss is 0.39678391767665744\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Per validation step average loss is 0.48640307784080505\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Cumulative validation average loss is 0.8831869955174625\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Per validation step average loss is 0.09476296603679657\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Cumulative validation average loss is 0.9779499615542591\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Per validation step average loss is 0.004174845293164253\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Cumulative validation average loss is 0.9821248068474233\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Per validation step average loss is 0.22272679209709167\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Cumulative validation average loss is 1.204851598944515\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Per validation step average loss is 0.24367889761924744\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Cumulative validation average loss is 1.4485304965637624\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Per validation step average loss is 0.3867341876029968\n",
      "07/18/2023 19:48:29 - INFO - __main__ - Cumulative validation average loss is 1.8352646841667593\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Per validation step average loss is 0.36408472061157227\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Cumulative validation average loss is 2.1993494047783315\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Per validation step average loss is 0.20386843383312225\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Cumulative validation average loss is 2.4032178386114538\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Per validation step average loss is 0.08201674371957779\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Cumulative validation average loss is 2.4852345823310316\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Average validation loss for Epoch 72 is 0.2071028818609193\n",
      "07/18/2023 19:48:30 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:48:43 - INFO - __main__ - Starting epoch 73\n",
      "07/18/2023 19:48:43 - INFO - __main__ - train loss is 0.004451890010386705\n",
      "Steps:  47%|▍| 7082/15000 [45:21<10:48:40,  4.92s/it, lr=9.66e-6, step_loss=0.0007/18/2023 19:48:44 - INFO - __main__ - train loss is 0.2636730563826859\n",
      "Steps:  47%|▍| 7083/15000 [45:21<7:41:16,  3.50s/it, lr=9.66e-6, step_loss=0.25907/18/2023 19:48:44 - INFO - __main__ - train loss is 0.3350701299495995\n",
      "Steps:  47%|▍| 7084/15000 [45:22<5:30:03,  2.50s/it, lr=9.66e-6, step_loss=0.07107/18/2023 19:48:44 - INFO - __main__ - train loss is 0.3390862592495978\n",
      "Steps:  47%|▍| 7085/15000 [45:22<3:58:30,  1.81s/it, lr=9.66e-6, step_loss=0.00407/18/2023 19:48:44 - INFO - __main__ - train loss is 0.5749670215882361\n",
      "Steps:  47%|▍| 7086/15000 [45:22<2:54:45,  1.32s/it, lr=9.66e-6, step_loss=0.23607/18/2023 19:48:44 - INFO - __main__ - train loss is 1.1753116794861853\n",
      "Steps:  47%|▉ | 7087/15000 [45:22<2:09:58,  1.01it/s, lr=9.66e-6, step_loss=0.6]07/18/2023 19:48:45 - INFO - __main__ - train loss is 1.208639191929251\n",
      "Steps:  47%|▍| 7088/15000 [45:22<1:38:40,  1.34it/s, lr=9.66e-6, step_loss=0.03307/18/2023 19:48:45 - INFO - __main__ - train loss is 1.2327626240439713\n",
      "Steps:  47%|▍| 7089/15000 [45:23<1:16:43,  1.72it/s, lr=9.66e-6, step_loss=0.02407/18/2023 19:48:45 - INFO - __main__ - train loss is 1.3400437724776566\n",
      "Steps:  47%|▍| 7090/15000 [45:23<1:01:16,  2.15it/s, lr=9.66e-6, step_loss=0.10707/18/2023 19:48:45 - INFO - __main__ - train loss is 1.4098153379745781\n",
      "Steps:  47%|▍| 7091/15000 [45:23<50:11,  2.63it/s, lr=9.66e-6, step_loss=0.0698]07/18/2023 19:48:45 - INFO - __main__ - train loss is 1.6083956477232277\n",
      "Steps:  47%|▉ | 7092/15000 [45:23<42:17,  3.12it/s, lr=9.66e-6, step_loss=0.199]07/18/2023 19:48:45 - INFO - __main__ - train loss is 1.753490385133773\n",
      "Steps:  47%|▉ | 7093/15000 [45:23<36:50,  3.58it/s, lr=9.66e-6, step_loss=0.145]07/18/2023 19:48:46 - INFO - __main__ - train loss is 1.7558532080147415\n",
      "Steps:  47%|▍| 7094/15000 [45:24<33:16,  3.96it/s, lr=9.66e-6, step_loss=0.0023607/18/2023 19:48:46 - INFO - __main__ - train loss is 2.0051853677723557\n",
      "Steps:  47%|▉ | 7095/15000 [45:24<30:53,  4.26it/s, lr=9.66e-6, step_loss=0.249]07/18/2023 19:48:46 - INFO - __main__ - train loss is 2.3703494688961655\n",
      "Steps:  47%|▉ | 7096/15000 [45:24<29:16,  4.50it/s, lr=9.66e-6, step_loss=0.365]07/18/2023 19:48:46 - INFO - __main__ - train loss is 2.4147644399199635\n",
      "Steps:  47%|▍| 7097/15000 [45:24<28:06,  4.69it/s, lr=9.66e-6, step_loss=0.0444]07/18/2023 19:48:46 - INFO - __main__ - train loss is 2.4163838044041768\n",
      "Steps:  47%|▍| 7098/15000 [45:24<27:19,  4.82it/s, lr=9.66e-6, step_loss=0.0016207/18/2023 19:48:47 - INFO - __main__ - train loss is 2.432574772858061\n",
      "Steps:  47%|▍| 7099/15000 [45:24<26:48,  4.91it/s, lr=9.66e-6, step_loss=0.0162]07/18/2023 19:48:47 - INFO - __main__ - train loss is 2.5986450255149975\n",
      "Steps:  47%|▉ | 7100/15000 [45:25<26:24,  4.98it/s, lr=9.66e-6, step_loss=0.166]07/18/2023 19:48:47 - INFO - __main__ - train loss is 2.6792450562352315\n",
      "Steps:  47%|▍| 7101/15000 [45:25<26:09,  5.03it/s, lr=9.66e-6, step_loss=0.0806]07/18/2023 19:48:47 - INFO - __main__ - train loss is 3.2281490579480305\n",
      "Steps:  47%|▉ | 7102/15000 [45:25<26:00,  5.06it/s, lr=9.66e-6, step_loss=0.549]07/18/2023 19:48:47 - INFO - __main__ - train loss is 3.237436961964704\n",
      "Steps:  47%|▍| 7103/15000 [45:25<25:51,  5.09it/s, lr=9.66e-6, step_loss=0.0092907/18/2023 19:48:48 - INFO - __main__ - train loss is 3.2526630960637704\n",
      "Steps:  47%|▍| 7104/15000 [45:25<25:44,  5.11it/s, lr=9.66e-6, step_loss=0.0152]07/18/2023 19:48:48 - INFO - __main__ - train loss is 3.668361207121052\n",
      "Steps:  47%|▉ | 7105/15000 [45:26<25:39,  5.13it/s, lr=9.66e-6, step_loss=0.416]07/18/2023 19:48:48 - INFO - __main__ - train loss is 3.7873174377018586\n",
      "Steps:  47%|▉ | 7106/15000 [45:26<25:36,  5.14it/s, lr=9.66e-6, step_loss=0.119]07/18/2023 19:48:48 - INFO - __main__ - train loss is 3.9381930954987183\n",
      "Steps:  47%|▉ | 7107/15000 [45:26<25:36,  5.14it/s, lr=9.66e-6, step_loss=0.151]07/18/2023 19:48:48 - INFO - __main__ - train loss is 4.034321194165386\n",
      "Steps:  47%|▍| 7108/15000 [45:26<25:22,  5.18it/s, lr=9.66e-6, step_loss=0.0961]07/18/2023 19:48:49 - INFO - __main__ - train loss is 4.073440378182568\n",
      "Steps:  47%|▍| 7109/15000 [45:26<24:54,  5.28it/s, lr=9.66e-6, step_loss=0.0391]07/18/2023 19:48:49 - INFO - __main__ - train loss is 4.251309131854214\n",
      "Steps:  47%|▉ | 7110/15000 [45:27<24:33,  5.35it/s, lr=9.66e-6, step_loss=0.178]07/18/2023 19:48:49 - INFO - __main__ - train loss is 4.410815765731968\n",
      "Steps:  47%|█▍ | 7111/15000 [45:27<24:31,  5.36it/s, lr=9.66e-6, step_loss=0.16]07/18/2023 19:48:49 - INFO - __main__ - train loss is 4.435442639165558\n",
      "Steps:  47%|▍| 7112/15000 [45:27<24:18,  5.41it/s, lr=9.66e-6, step_loss=0.0246]07/18/2023 19:48:49 - INFO - __main__ - train loss is 4.457335577928461\n",
      "Steps:  47%|▍| 7113/15000 [45:27<24:08,  5.44it/s, lr=9.66e-6, step_loss=0.0219]07/18/2023 19:48:49 - INFO - __main__ - train loss is 5.159261094057001\n",
      "Steps:  47%|▉ | 7114/15000 [45:27<24:16,  5.42it/s, lr=9.66e-6, step_loss=0.702]07/18/2023 19:48:50 - INFO - __main__ - train loss is 5.206292407237925\n",
      "Steps:  47%|▉ | 7115/15000 [45:28<24:05,  5.46it/s, lr=9.66e-6, step_loss=0.047]07/18/2023 19:48:50 - INFO - __main__ - train loss is 5.2945515379542485\n",
      "Steps:  47%|▍| 7116/15000 [45:28<23:53,  5.50it/s, lr=9.66e-6, step_loss=0.0883]07/18/2023 19:48:50 - INFO - __main__ - train loss is 5.296132802730426\n",
      "Steps:  47%|▍| 7117/15000 [45:28<23:44,  5.53it/s, lr=9.66e-6, step_loss=0.0015807/18/2023 19:48:50 - INFO - __main__ - train loss is 5.300420336192474\n",
      "Steps:  47%|▍| 7118/15000 [45:28<23:40,  5.55it/s, lr=9.66e-6, step_loss=0.0042907/18/2023 19:48:50 - INFO - __main__ - train loss is 5.302911397069693\n",
      "Steps:  47%|▍| 7119/15000 [45:28<23:36,  5.56it/s, lr=9.66e-6, step_loss=0.0024907/18/2023 19:48:51 - INFO - __main__ - train loss is 5.738584395498037\n",
      "Steps:  47%|▉ | 7120/15000 [45:28<23:44,  5.53it/s, lr=9.66e-6, step_loss=0.436]07/18/2023 19:48:51 - INFO - __main__ - train loss is 5.762111922726035\n",
      "Steps:  47%|▍| 7121/15000 [45:29<23:42,  5.54it/s, lr=9.66e-6, step_loss=0.0235]07/18/2023 19:48:51 - INFO - __main__ - train loss is 5.890773912891746\n",
      "Steps:  47%|▉ | 7122/15000 [45:29<23:36,  5.56it/s, lr=9.66e-6, step_loss=0.129]07/18/2023 19:48:51 - INFO - __main__ - train loss is 6.109505971893668\n",
      "Steps:  47%|▉ | 7123/15000 [45:29<23:32,  5.58it/s, lr=9.66e-6, step_loss=0.219]07/18/2023 19:48:51 - INFO - __main__ - train loss is 6.285381576046348\n",
      "Steps:  47%|▉ | 7124/15000 [45:29<23:29,  5.59it/s, lr=9.66e-6, step_loss=0.176]07/18/2023 19:48:51 - INFO - __main__ - train loss is 6.806238790974021\n",
      "Steps:  48%|▉ | 7125/15000 [45:29<23:26,  5.60it/s, lr=9.66e-6, step_loss=0.521]07/18/2023 19:48:52 - INFO - __main__ - train loss is 7.082527598366141\n",
      "Steps:  48%|▉ | 7126/15000 [45:29<23:25,  5.60it/s, lr=9.66e-6, step_loss=0.276]07/18/2023 19:48:52 - INFO - __main__ - train loss is 7.093483902513981\n",
      "Steps:  48%|▉ | 7127/15000 [45:30<23:24,  5.61it/s, lr=9.66e-6, step_loss=0.011]07/18/2023 19:48:52 - INFO - __main__ - train loss is 7.347862996160984\n",
      "Steps:  48%|▉ | 7128/15000 [45:30<23:23,  5.61it/s, lr=9.66e-6, step_loss=0.254]07/18/2023 19:48:52 - INFO - __main__ - train loss is 7.819315887987614\n",
      "Steps:  48%|▉ | 7129/15000 [45:30<23:22,  5.61it/s, lr=9.66e-6, step_loss=0.471]07/18/2023 19:48:52 - INFO - __main__ - train loss is 8.150579787790775\n",
      "Steps:  48%|▉ | 7130/15000 [45:30<23:22,  5.61it/s, lr=9.66e-6, step_loss=0.331]07/18/2023 19:48:52 - INFO - __main__ - train loss is 8.155347652733326\n",
      "Steps:  48%|▍| 7131/15000 [45:30<23:21,  5.62it/s, lr=9.66e-6, step_loss=0.0047707/18/2023 19:48:53 - INFO - __main__ - train loss is 8.370160423219204\n",
      "Steps:  48%|▉ | 7132/15000 [45:31<23:29,  5.58it/s, lr=9.66e-6, step_loss=0.215]07/18/2023 19:48:53 - INFO - __main__ - train loss is 8.653023801743984\n",
      "Steps:  48%|▉ | 7133/15000 [45:31<23:47,  5.51it/s, lr=9.66e-6, step_loss=0.283]07/18/2023 19:48:53 - INFO - __main__ - train loss is 9.513226352632046\n",
      "Steps:  48%|█▍ | 7134/15000 [45:31<23:43,  5.52it/s, lr=9.66e-6, step_loss=0.86]07/18/2023 19:48:53 - INFO - __main__ - train loss is 9.68324937671423\n",
      "Steps:  48%|█▍ | 7135/15000 [45:31<23:36,  5.55it/s, lr=9.66e-6, step_loss=0.17]07/18/2023 19:48:53 - INFO - __main__ - train loss is 9.851624943315983\n",
      "Steps:  48%|▉ | 7136/15000 [45:31<23:31,  5.57it/s, lr=9.66e-6, step_loss=0.168]07/18/2023 19:48:54 - INFO - __main__ - train loss is 10.098554573953152\n",
      "Steps:  48%|▉ | 7137/15000 [45:31<23:28,  5.58it/s, lr=9.66e-6, step_loss=0.247]07/18/2023 19:48:54 - INFO - __main__ - train loss is 10.122868791222572\n",
      "Steps:  48%|▍| 7138/15000 [45:32<23:25,  5.59it/s, lr=9.66e-6, step_loss=0.0243]07/18/2023 19:48:54 - INFO - __main__ - train loss is 10.283711925148964\n",
      "Steps:  48%|▉ | 7139/15000 [45:32<23:24,  5.60it/s, lr=9.66e-6, step_loss=0.161]07/18/2023 19:48:54 - INFO - __main__ - train loss is 10.540351435542107\n",
      "Steps:  48%|▉ | 7140/15000 [45:32<23:22,  5.60it/s, lr=9.66e-6, step_loss=0.257]07/18/2023 19:48:54 - INFO - __main__ - train loss is 10.555660955607891\n",
      "Steps:  48%|▍| 7141/15000 [45:32<23:21,  5.61it/s, lr=9.66e-6, step_loss=0.0153]07/18/2023 19:48:54 - INFO - __main__ - train loss is 10.886555068194866\n",
      "Steps:  48%|▉ | 7142/15000 [45:32<23:20,  5.61it/s, lr=9.66e-6, step_loss=0.331]07/18/2023 19:48:55 - INFO - __main__ - train loss is 10.893900602124631\n",
      "Steps:  48%|▍| 7143/15000 [45:33<23:19,  5.61it/s, lr=9.66e-6, step_loss=0.0073507/18/2023 19:48:55 - INFO - __main__ - train loss is 10.956777705810964\n",
      "Steps:  48%|▍| 7144/15000 [45:33<23:19,  5.61it/s, lr=9.66e-6, step_loss=0.0629]07/18/2023 19:48:55 - INFO - __main__ - train loss is 11.110026164911687\n",
      "Steps:  48%|▉ | 7145/15000 [45:33<23:20,  5.61it/s, lr=9.66e-6, step_loss=0.153]07/18/2023 19:48:55 - INFO - __main__ - train loss is 11.233643761835992\n",
      "Steps:  48%|▉ | 7146/15000 [45:33<23:19,  5.61it/s, lr=9.66e-6, step_loss=0.124]07/18/2023 19:48:55 - INFO - __main__ - train loss is 11.622314623557031\n",
      "Steps:  48%|▉ | 7147/15000 [45:33<23:19,  5.61it/s, lr=9.66e-6, step_loss=0.389]07/18/2023 19:48:56 - INFO - __main__ - train loss is 11.628964399918914\n",
      "Steps:  48%|▍| 7148/15000 [45:33<23:19,  5.61it/s, lr=9.66e-6, step_loss=0.0066507/18/2023 19:48:56 - INFO - __main__ - train loss is 11.634062801487744\n",
      "Steps:  48%|▍| 7149/15000 [45:34<23:18,  5.61it/s, lr=9.66e-6, step_loss=0.0051]07/18/2023 19:48:56 - INFO - __main__ - train loss is 11.662617550231516\n",
      "Steps:  48%|▍| 7150/15000 [45:34<23:18,  5.62it/s, lr=9.66e-6, step_loss=0.0286]07/18/2023 19:48:56 - INFO - __main__ - train loss is 12.114033923484385\n",
      "Steps:  48%|▉ | 7151/15000 [45:34<23:17,  5.62it/s, lr=9.66e-6, step_loss=0.451]07/18/2023 19:48:56 - INFO - __main__ - train loss is 12.131817637942731\n",
      "Steps:  48%|▍| 7152/15000 [45:34<23:18,  5.61it/s, lr=9.66e-6, step_loss=0.0178]07/18/2023 19:48:56 - INFO - __main__ - train loss is 12.14762061368674\n",
      "Steps:  48%|▍| 7153/15000 [45:34<23:25,  5.58it/s, lr=9.65e-6, step_loss=0.0158]07/18/2023 19:48:57 - INFO - __main__ - train loss is 12.15883437730372\n",
      "Steps:  48%|▍| 7154/15000 [45:34<23:23,  5.59it/s, lr=9.65e-6, step_loss=0.0112]07/18/2023 19:48:57 - INFO - __main__ - train loss is 12.187822604551911\n",
      "Steps:  48%|▉ | 7155/15000 [45:35<23:21,  5.60it/s, lr=9.65e-6, step_loss=0.029]07/18/2023 19:48:57 - INFO - __main__ - train loss is 12.503614330664277\n",
      "Steps:  48%|▉ | 7156/15000 [45:35<23:20,  5.60it/s, lr=9.65e-6, step_loss=0.316]07/18/2023 19:48:57 - INFO - __main__ - train loss is 12.566967809572816\n",
      "Steps:  48%|▍| 7157/15000 [45:35<23:20,  5.60it/s, lr=9.65e-6, step_loss=0.0634]07/18/2023 19:48:57 - INFO - __main__ - train loss is 12.744300657883286\n",
      "Steps:  48%|▉ | 7158/15000 [45:35<23:20,  5.60it/s, lr=9.65e-6, step_loss=0.177]07/18/2023 19:48:57 - INFO - __main__ - train loss is 13.14559649862349\n",
      "Steps:  48%|▉ | 7159/15000 [45:35<23:20,  5.60it/s, lr=9.65e-6, step_loss=0.401]07/18/2023 19:48:58 - INFO - __main__ - train loss is 13.14759783493355\n",
      "Steps:  48%|▉ | 7160/15000 [45:36<23:20,  5.60it/s, lr=9.65e-6, step_loss=0.002]07/18/2023 19:48:58 - INFO - __main__ - train loss is 13.150129414629191\n",
      "Steps:  48%|▍| 7161/15000 [45:36<23:19,  5.60it/s, lr=9.65e-6, step_loss=0.0025307/18/2023 19:48:58 - INFO - __main__ - train loss is 13.192144821863621\n",
      "Steps:  48%|▉ | 7162/15000 [45:36<23:31,  5.55it/s, lr=9.65e-6, step_loss=0.042]07/18/2023 19:48:58 - INFO - __main__ - train loss is 13.274140137713403\n",
      "Steps:  48%|▉ | 7163/15000 [45:36<23:31,  5.55it/s, lr=9.65e-6, step_loss=0.082]07/18/2023 19:48:58 - INFO - __main__ - train loss is 13.279533583205193\n",
      "Steps:  48%|▍| 7164/15000 [45:36<23:26,  5.57it/s, lr=9.65e-6, step_loss=0.0053907/18/2023 19:48:59 - INFO - __main__ - train loss is 13.706099230330437\n",
      "Steps:  48%|▉ | 7165/15000 [45:36<23:23,  5.58it/s, lr=9.65e-6, step_loss=0.427]07/18/2023 19:48:59 - INFO - __main__ - train loss is 13.740911606233567\n",
      "Steps:  48%|▍| 7166/15000 [45:37<23:20,  5.59it/s, lr=9.65e-6, step_loss=0.0348]07/18/2023 19:48:59 - INFO - __main__ - train loss is 13.762786713894457\n",
      "Steps:  48%|▍| 7167/15000 [45:37<23:19,  5.60it/s, lr=9.65e-6, step_loss=0.0219]07/18/2023 19:48:59 - INFO - __main__ - train loss is 13.799100009258837\n",
      "Steps:  48%|▍| 7168/15000 [45:37<23:19,  5.60it/s, lr=9.65e-6, step_loss=0.0363]07/18/2023 19:48:59 - INFO - __main__ - train loss is 14.170802799519151\n",
      "Steps:  48%|▉ | 7169/15000 [45:37<23:17,  5.60it/s, lr=9.65e-6, step_loss=0.372]07/18/2023 19:48:59 - INFO - __main__ - train loss is 14.381914628203958\n",
      "Steps:  48%|▉ | 7170/15000 [45:37<23:17,  5.60it/s, lr=9.65e-6, step_loss=0.211]07/18/2023 19:49:00 - INFO - __main__ - train loss is 14.385050633689389\n",
      "Steps:  48%|▍| 7171/15000 [45:38<23:17,  5.60it/s, lr=9.65e-6, step_loss=0.0031407/18/2023 19:49:00 - INFO - __main__ - train loss is 14.387050462886691\n",
      "Steps:  48%|▉ | 7172/15000 [45:38<23:15,  5.61it/s, lr=9.65e-6, step_loss=0.002]07/18/2023 19:49:00 - INFO - __main__ - train loss is 14.842321766540408\n",
      "Steps:  48%|▉ | 7173/15000 [45:38<23:14,  5.61it/s, lr=9.65e-6, step_loss=0.455]07/18/2023 19:49:00 - INFO - __main__ - train loss is 15.208843542262912\n",
      "Steps:  48%|▉ | 7174/15000 [45:38<23:14,  5.61it/s, lr=9.65e-6, step_loss=0.367]07/18/2023 19:49:00 - INFO - __main__ - train loss is 15.43091475777328\n",
      "Steps:  48%|▉ | 7175/15000 [45:38<23:14,  5.61it/s, lr=9.65e-6, step_loss=0.222]07/18/2023 19:49:01 - INFO - __main__ - train loss is 16.10040813498199\n",
      "Steps:  48%|▉ | 7176/15000 [45:38<23:14,  5.61it/s, lr=9.65e-6, step_loss=0.669]07/18/2023 19:49:01 - INFO - __main__ - train loss is 16.126346431672573\n",
      "Steps:  48%|▍| 7177/15000 [45:39<23:15,  5.61it/s, lr=9.65e-6, step_loss=0.0259]07/18/2023 19:49:01 - INFO - __main__ - train loss is 16.265400283038616\n",
      "Steps:  48%|▉ | 7178/15000 [45:39<32:02,  4.07it/s, lr=9.65e-6, step_loss=0.139]07/18/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.2863571047782898\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 0.2863571047782898\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.10783509910106659\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 0.3941922038793564\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.04574939236044884\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 0.4399415962398052\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.3653630018234253\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 0.8053045980632305\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.030537351965904236\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 0.8358419500291348\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Per validation step average loss is 0.4669288694858551\n",
      "07/18/2023 19:49:02 - INFO - __main__ - Cumulative validation average loss is 1.3027708195149899\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.008804041892290115\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 1.31157486140728\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.011850988492369652\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 1.3234258498996496\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.28302890062332153\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 1.6064547505229712\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.430081844329834\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 2.036536594852805\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Per validation step average loss is 0.001654070452786982\n",
      "07/18/2023 19:49:03 - INFO - __main__ - Cumulative validation average loss is 2.038190665305592\n",
      "07/18/2023 19:49:04 - INFO - __main__ - Per validation step average loss is 0.040101852267980576\n",
      "07/18/2023 19:49:04 - INFO - __main__ - Cumulative validation average loss is 2.0782925175735727\n",
      "07/18/2023 19:49:04 - INFO - __main__ - Average validation loss for Epoch 73 is 0.17319104313113107\n",
      "07/18/2023 19:49:04 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:49:16 - INFO - __main__ - Starting epoch 74\n",
      "07/18/2023 19:49:17 - INFO - __main__ - train loss is 0.1955610066652298\n",
      "Steps:  48%|▍| 7179/15000 [45:55<10:30:56,  4.84s/it, lr=9.65e-6, step_loss=0.1907/18/2023 19:49:17 - INFO - __main__ - train loss is 0.2075352631509304\n",
      "Steps:  48%|▍| 7180/15000 [45:55<7:28:36,  3.44s/it, lr=9.65e-6, step_loss=0.01207/18/2023 19:49:17 - INFO - __main__ - train loss is 0.21478263102471828\n",
      "Steps:  48%|▍| 7181/15000 [45:55<5:20:58,  2.46s/it, lr=9.65e-6, step_loss=0.00707/18/2023 19:49:17 - INFO - __main__ - train loss is 0.25315829552710056\n",
      "Steps:  48%|▍| 7182/15000 [45:55<3:51:37,  1.78s/it, lr=9.65e-6, step_loss=0.03807/18/2023 19:49:17 - INFO - __main__ - train loss is 0.3130930308252573\n",
      "Steps:  48%|▍| 7183/15000 [45:55<2:49:04,  1.30s/it, lr=9.65e-6, step_loss=0.05907/18/2023 19:49:18 - INFO - __main__ - train loss is 0.3313767686486244\n",
      "Steps:  48%|▍| 7184/15000 [45:55<2:05:27,  1.04it/s, lr=9.65e-6, step_loss=0.01807/18/2023 19:49:18 - INFO - __main__ - train loss is 0.6469774022698402\n",
      "Steps:  48%|▍| 7185/15000 [45:56<1:34:45,  1.37it/s, lr=9.65e-6, step_loss=0.31607/18/2023 19:49:18 - INFO - __main__ - train loss is 0.6927350535988808\n",
      "Steps:  48%|▍| 7186/15000 [45:56<1:13:15,  1.78it/s, lr=9.65e-6, step_loss=0.04507/18/2023 19:49:18 - INFO - __main__ - train loss is 0.7170893251895905\n",
      "Steps:  48%|▍| 7187/15000 [45:56<58:12,  2.24it/s, lr=9.65e-6, step_loss=0.0244]07/18/2023 19:49:18 - INFO - __main__ - train loss is 0.7248343895189464\n",
      "Steps:  48%|▍| 7188/15000 [45:56<47:40,  2.73it/s, lr=9.65e-6, step_loss=0.0077507/18/2023 19:49:18 - INFO - __main__ - train loss is 1.1258747349493206\n",
      "Steps:  48%|▉ | 7189/15000 [45:56<40:18,  3.23it/s, lr=9.65e-6, step_loss=0.401]07/18/2023 19:49:19 - INFO - __main__ - train loss is 1.37107866210863\n",
      "Steps:  48%|▉ | 7190/15000 [45:57<35:08,  3.70it/s, lr=9.65e-6, step_loss=0.245]07/18/2023 19:49:19 - INFO - __main__ - train loss is 1.6013265768997371\n",
      "Steps:  48%|█▍ | 7191/15000 [45:57<31:33,  4.12it/s, lr=9.65e-6, step_loss=0.23]07/18/2023 19:49:19 - INFO - __main__ - train loss is 2.0055477540008724\n",
      "Steps:  48%|▉ | 7192/15000 [45:57<29:17,  4.44it/s, lr=9.65e-6, step_loss=0.404]07/18/2023 19:49:19 - INFO - __main__ - train loss is 2.9505783240310848\n",
      "Steps:  48%|▉ | 7193/15000 [45:57<27:49,  4.68it/s, lr=9.65e-6, step_loss=0.945]07/18/2023 19:49:19 - INFO - __main__ - train loss is 3.361586473416537\n",
      "Steps:  48%|▉ | 7194/15000 [45:57<26:32,  4.90it/s, lr=9.65e-6, step_loss=0.411]07/18/2023 19:49:20 - INFO - __main__ - train loss is 3.3706253240816295\n",
      "Steps:  48%|▍| 7195/15000 [45:57<25:31,  5.10it/s, lr=9.65e-6, step_loss=0.0090407/18/2023 19:49:20 - INFO - __main__ - train loss is 3.5384883205406368\n",
      "Steps:  48%|▉ | 7196/15000 [45:58<24:50,  5.24it/s, lr=9.65e-6, step_loss=0.168]07/18/2023 19:49:20 - INFO - __main__ - train loss is 3.5769337597303092\n",
      "Steps:  48%|▍| 7197/15000 [45:58<24:21,  5.34it/s, lr=9.65e-6, step_loss=0.0384]07/18/2023 19:49:20 - INFO - __main__ - train loss is 3.858742523472756\n",
      "Steps:  48%|▉ | 7198/15000 [45:58<24:01,  5.41it/s, lr=9.65e-6, step_loss=0.282]07/18/2023 19:49:20 - INFO - __main__ - train loss is 3.863526040688157\n",
      "Steps:  48%|▍| 7199/15000 [45:58<23:46,  5.47it/s, lr=9.65e-6, step_loss=0.0047807/18/2023 19:49:20 - INFO - __main__ - train loss is 4.087601596489549\n",
      "Steps:  48%|▉ | 7200/15000 [45:58<23:36,  5.51it/s, lr=9.65e-6, step_loss=0.224]07/18/2023 19:49:21 - INFO - __main__ - train loss is 4.310108283534646\n",
      "Steps:  48%|▉ | 7201/15000 [45:58<23:29,  5.53it/s, lr=9.65e-6, step_loss=0.223]07/18/2023 19:49:21 - INFO - __main__ - train loss is 4.3201651787385345\n",
      "Steps:  48%|▍| 7202/15000 [45:59<23:37,  5.50it/s, lr=9.65e-6, step_loss=0.0101]07/18/2023 19:49:21 - INFO - __main__ - train loss is 4.371544457040727\n",
      "Steps:  48%|▍| 7203/15000 [45:59<23:35,  5.51it/s, lr=9.65e-6, step_loss=0.0514]07/18/2023 19:49:21 - INFO - __main__ - train loss is 4.433934859000146\n",
      "Steps:  48%|▍| 7204/15000 [45:59<23:29,  5.53it/s, lr=9.65e-6, step_loss=0.0624]07/18/2023 19:49:21 - INFO - __main__ - train loss is 4.44056636095047\n",
      "Steps:  48%|▍| 7205/15000 [45:59<23:26,  5.54it/s, lr=9.65e-6, step_loss=0.0066307/18/2023 19:49:22 - INFO - __main__ - train loss is 4.5396969467401505\n",
      "Steps:  48%|▍| 7206/15000 [45:59<23:35,  5.51it/s, lr=9.65e-6, step_loss=0.0991]07/18/2023 19:49:22 - INFO - __main__ - train loss is 4.725973501801491\n",
      "Steps:  48%|▉ | 7207/15000 [46:00<23:35,  5.50it/s, lr=9.65e-6, step_loss=0.186]07/18/2023 19:49:22 - INFO - __main__ - train loss is 4.7280342823360115\n",
      "Steps:  48%|▍| 7208/15000 [46:00<23:28,  5.53it/s, lr=9.65e-6, step_loss=0.0020607/18/2023 19:49:22 - INFO - __main__ - train loss is 5.134273374686018\n",
      "Steps:  48%|▉ | 7209/15000 [46:00<23:23,  5.55it/s, lr=9.65e-6, step_loss=0.406]07/18/2023 19:49:22 - INFO - __main__ - train loss is 5.538594776997343\n",
      "Steps:  48%|▉ | 7210/15000 [46:00<23:18,  5.57it/s, lr=9.65e-6, step_loss=0.404]07/18/2023 19:49:22 - INFO - __main__ - train loss is 6.2170557922217995\n",
      "Steps:  48%|▉ | 7211/15000 [46:00<23:26,  5.54it/s, lr=9.65e-6, step_loss=0.678]07/18/2023 19:49:23 - INFO - __main__ - train loss is 6.243815411115065\n",
      "Steps:  48%|▍| 7212/15000 [46:00<23:34,  5.50it/s, lr=9.65e-6, step_loss=0.0268]07/18/2023 19:49:23 - INFO - __main__ - train loss is 6.250122437952086\n",
      "Steps:  48%|▍| 7213/15000 [46:01<23:44,  5.47it/s, lr=9.65e-6, step_loss=0.0063107/18/2023 19:49:23 - INFO - __main__ - train loss is 6.567085186718032\n",
      "Steps:  48%|▉ | 7214/15000 [46:01<23:35,  5.50it/s, lr=9.65e-6, step_loss=0.317]07/18/2023 19:49:23 - INFO - __main__ - train loss is 7.117442528484389\n",
      "Steps:  48%|█▍ | 7215/15000 [46:01<23:27,  5.53it/s, lr=9.65e-6, step_loss=0.55]07/18/2023 19:49:23 - INFO - __main__ - train loss is 7.2110067184548825\n",
      "Steps:  48%|▍| 7216/15000 [46:01<23:22,  5.55it/s, lr=9.65e-6, step_loss=0.0936]07/18/2023 19:49:24 - INFO - __main__ - train loss is 7.960688966093585\n",
      "Steps:  48%|█▍ | 7217/15000 [46:01<23:17,  5.57it/s, lr=9.65e-6, step_loss=0.75]07/18/2023 19:49:24 - INFO - __main__ - train loss is 7.993249642429873\n",
      "Steps:  48%|▍| 7218/15000 [46:02<23:13,  5.59it/s, lr=9.65e-6, step_loss=0.0326]07/18/2023 19:49:24 - INFO - __main__ - train loss is 7.995497890282422\n",
      "Steps:  48%|▍| 7219/15000 [46:02<23:11,  5.59it/s, lr=9.65e-6, step_loss=0.0022507/18/2023 19:49:24 - INFO - __main__ - train loss is 8.143002011347562\n",
      "Steps:  48%|▉ | 7220/15000 [46:02<23:10,  5.60it/s, lr=9.65e-6, step_loss=0.148]07/18/2023 19:49:24 - INFO - __main__ - train loss is 8.250317693222314\n",
      "Steps:  48%|▉ | 7221/15000 [46:02<23:09,  5.60it/s, lr=9.65e-6, step_loss=0.107]07/18/2023 19:49:24 - INFO - __main__ - train loss is 8.730252981651574\n",
      "Steps:  48%|█▍ | 7222/15000 [46:02<23:08,  5.60it/s, lr=9.65e-6, step_loss=0.48]07/18/2023 19:49:25 - INFO - __main__ - train loss is 8.914610758889467\n",
      "Steps:  48%|▉ | 7223/15000 [46:02<23:08,  5.60it/s, lr=9.65e-6, step_loss=0.184]07/18/2023 19:49:25 - INFO - __main__ - train loss is 9.705085412133485\n",
      "Steps:  48%|█▍ | 7224/15000 [46:03<23:07,  5.60it/s, lr=9.65e-6, step_loss=0.79]07/18/2023 19:49:25 - INFO - __main__ - train loss is 10.213348642457277\n",
      "Steps:  48%|▉ | 7225/15000 [46:03<23:09,  5.60it/s, lr=9.65e-6, step_loss=0.508]07/18/2023 19:49:25 - INFO - __main__ - train loss is 10.236224135849625\n",
      "Steps:  48%|▍| 7226/15000 [46:03<23:07,  5.60it/s, lr=9.65e-6, step_loss=0.0229]07/18/2023 19:49:25 - INFO - __main__ - train loss is 10.4541433067061\n",
      "Steps:  48%|▉ | 7227/15000 [46:03<23:06,  5.60it/s, lr=9.65e-6, step_loss=0.218]07/18/2023 19:49:25 - INFO - __main__ - train loss is 10.456577133852988\n",
      "Steps:  48%|▍| 7228/15000 [46:03<23:07,  5.60it/s, lr=9.65e-6, step_loss=0.0024307/18/2023 19:49:26 - INFO - __main__ - train loss is 10.458527846145444\n",
      "Steps:  48%|▍| 7229/15000 [46:04<23:06,  5.60it/s, lr=9.65e-6, step_loss=0.0019507/18/2023 19:49:26 - INFO - __main__ - train loss is 10.584562865900807\n",
      "Steps:  48%|▉ | 7230/15000 [46:04<23:05,  5.61it/s, lr=9.65e-6, step_loss=0.126]07/18/2023 19:49:26 - INFO - __main__ - train loss is 10.611133133876137\n",
      "Steps:  48%|▍| 7231/15000 [46:04<23:05,  5.61it/s, lr=9.65e-6, step_loss=0.0266]07/18/2023 19:49:26 - INFO - __main__ - train loss is 10.613122042850591\n",
      "Steps:  48%|▍| 7232/15000 [46:04<23:05,  5.60it/s, lr=9.65e-6, step_loss=0.0019907/18/2023 19:49:26 - INFO - __main__ - train loss is 10.616534436237998\n",
      "Steps:  48%|▍| 7233/15000 [46:04<23:06,  5.60it/s, lr=9.65e-6, step_loss=0.0034107/18/2023 19:49:27 - INFO - __main__ - train loss is 10.619293688680045\n",
      "Steps:  48%|▍| 7234/15000 [46:04<23:06,  5.60it/s, lr=9.65e-6, step_loss=0.0027607/18/2023 19:49:27 - INFO - __main__ - train loss is 10.688649347866885\n",
      "Steps:  48%|▍| 7235/15000 [46:05<23:18,  5.55it/s, lr=9.65e-6, step_loss=0.0694]07/18/2023 19:49:27 - INFO - __main__ - train loss is 10.906756243552081\n",
      "Steps:  48%|▉ | 7236/15000 [46:05<23:14,  5.57it/s, lr=9.65e-6, step_loss=0.218]07/18/2023 19:49:27 - INFO - __main__ - train loss is 10.909772149170749\n",
      "Steps:  48%|▍| 7237/15000 [46:05<23:11,  5.58it/s, lr=9.65e-6, step_loss=0.0030207/18/2023 19:49:27 - INFO - __main__ - train loss is 10.94343361153733\n",
      "Steps:  48%|▍| 7238/15000 [46:05<23:09,  5.59it/s, lr=9.65e-6, step_loss=0.0337]07/18/2023 19:49:27 - INFO - __main__ - train loss is 10.979727453435771\n",
      "Steps:  48%|▍| 7239/15000 [46:05<23:07,  5.59it/s, lr=9.65e-6, step_loss=0.0363]07/18/2023 19:49:28 - INFO - __main__ - train loss is 11.059322214568965\n",
      "Steps:  48%|▍| 7240/15000 [46:05<23:06,  5.60it/s, lr=9.65e-6, step_loss=0.0796]07/18/2023 19:49:28 - INFO - __main__ - train loss is 11.126366070355289\n",
      "Steps:  48%|▉ | 7241/15000 [46:06<23:05,  5.60it/s, lr=9.65e-6, step_loss=0.067]07/18/2023 19:49:28 - INFO - __main__ - train loss is 11.192368707503192\n",
      "Steps:  48%|▉ | 7242/15000 [46:06<23:04,  5.60it/s, lr=9.65e-6, step_loss=0.066]07/18/2023 19:49:28 - INFO - __main__ - train loss is 11.193958844756708\n",
      "Steps:  48%|▍| 7243/15000 [46:06<23:17,  5.55it/s, lr=9.65e-6, step_loss=0.0015907/18/2023 19:49:28 - INFO - __main__ - train loss is 11.352645631646737\n",
      "Steps:  48%|▉ | 7244/15000 [46:06<23:12,  5.57it/s, lr=9.65e-6, step_loss=0.159]07/18/2023 19:49:29 - INFO - __main__ - train loss is 11.562442611670122\n",
      "Steps:  48%|█▍ | 7245/15000 [46:06<23:09,  5.58it/s, lr=9.65e-6, step_loss=0.21]07/18/2023 19:49:29 - INFO - __main__ - train loss is 11.81144344410859\n",
      "Steps:  48%|▉ | 7246/15000 [46:07<23:07,  5.59it/s, lr=9.65e-6, step_loss=0.249]07/18/2023 19:49:29 - INFO - __main__ - train loss is 11.930058609461412\n",
      "Steps:  48%|▉ | 7247/15000 [46:07<23:05,  5.60it/s, lr=9.65e-6, step_loss=0.119]07/18/2023 19:49:29 - INFO - __main__ - train loss is 12.366679202532396\n",
      "Steps:  48%|▉ | 7248/15000 [46:07<23:04,  5.60it/s, lr=9.65e-6, step_loss=0.437]07/18/2023 19:49:29 - INFO - __main__ - train loss is 12.368264855234884\n",
      "Steps:  48%|▍| 7249/15000 [46:07<23:04,  5.60it/s, lr=9.65e-6, step_loss=0.0015907/18/2023 19:49:29 - INFO - __main__ - train loss is 12.54018986353185\n",
      "Steps:  48%|▉ | 7250/15000 [46:07<23:04,  5.60it/s, lr=9.65e-6, step_loss=0.172]07/18/2023 19:49:30 - INFO - __main__ - train loss is 12.583507069735788\n",
      "Steps:  48%|▍| 7251/15000 [46:07<23:02,  5.61it/s, lr=9.65e-6, step_loss=0.0433]07/18/2023 19:49:30 - INFO - __main__ - train loss is 12.633073971956037\n",
      "Steps:  48%|▍| 7252/15000 [46:08<23:01,  5.61it/s, lr=9.65e-6, step_loss=0.0496]07/18/2023 19:49:30 - INFO - __main__ - train loss is 12.653903729631566\n",
      "Steps:  48%|▍| 7253/15000 [46:08<23:01,  5.61it/s, lr=9.65e-6, step_loss=0.0208]07/18/2023 19:49:30 - INFO - __main__ - train loss is 12.659277491620742\n",
      "Steps:  48%|▍| 7254/15000 [46:08<23:01,  5.61it/s, lr=9.65e-6, step_loss=0.0053707/18/2023 19:49:30 - INFO - __main__ - train loss is 12.866098307422362\n",
      "Steps:  48%|▉ | 7255/15000 [46:08<23:01,  5.61it/s, lr=9.65e-6, step_loss=0.207]07/18/2023 19:49:30 - INFO - __main__ - train loss is 13.37615909462329\n",
      "Steps:  48%|█▍ | 7256/15000 [46:08<23:01,  5.61it/s, lr=9.65e-6, step_loss=0.51]07/18/2023 19:49:31 - INFO - __main__ - train loss is 13.693556093028747\n",
      "Steps:  48%|▉ | 7257/15000 [46:09<23:00,  5.61it/s, lr=9.64e-6, step_loss=0.317]07/18/2023 19:49:31 - INFO - __main__ - train loss is 13.880822189501487\n",
      "Steps:  48%|▉ | 7258/15000 [46:09<23:00,  5.61it/s, lr=9.64e-6, step_loss=0.187]07/18/2023 19:49:31 - INFO - __main__ - train loss is 14.03780477528926\n",
      "Steps:  48%|▉ | 7259/15000 [46:09<22:59,  5.61it/s, lr=9.64e-6, step_loss=0.157]07/18/2023 19:49:31 - INFO - __main__ - train loss is 14.593209438375197\n",
      "Steps:  48%|▉ | 7260/15000 [46:09<22:57,  5.62it/s, lr=9.64e-6, step_loss=0.555]07/18/2023 19:49:31 - INFO - __main__ - train loss is 14.907175593427382\n",
      "Steps:  48%|▉ | 7261/15000 [46:09<22:57,  5.62it/s, lr=9.64e-6, step_loss=0.314]07/18/2023 19:49:32 - INFO - __main__ - train loss is 15.059680112055503\n",
      "Steps:  48%|▉ | 7262/15000 [46:09<22:56,  5.62it/s, lr=9.64e-6, step_loss=0.153]07/18/2023 19:49:32 - INFO - __main__ - train loss is 15.066806229646318\n",
      "Steps:  48%|▍| 7263/15000 [46:10<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.0071307/18/2023 19:49:32 - INFO - __main__ - train loss is 15.093850172008388\n",
      "Steps:  48%|▉ | 7264/15000 [46:10<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.027]07/18/2023 19:49:32 - INFO - __main__ - train loss is 15.803018665756099\n",
      "Steps:  48%|▉ | 7265/15000 [46:10<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.709]07/18/2023 19:49:32 - INFO - __main__ - train loss is 15.940542823518626\n",
      "Steps:  48%|▉ | 7266/15000 [46:10<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.138]07/18/2023 19:49:32 - INFO - __main__ - train loss is 16.074745139922015\n",
      "Steps:  48%|▉ | 7267/15000 [46:10<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.134]07/18/2023 19:49:33 - INFO - __main__ - train loss is 16.08850469707977\n",
      "Steps:  48%|▍| 7268/15000 [46:10<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.0138]07/18/2023 19:49:33 - INFO - __main__ - train loss is 16.214616517419927\n",
      "Steps:  48%|▉ | 7269/15000 [46:11<22:54,  5.62it/s, lr=9.64e-6, step_loss=0.126]07/18/2023 19:49:33 - INFO - __main__ - train loss is 16.22134307480883\n",
      "Steps:  48%|▍| 7270/15000 [46:11<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.0067307/18/2023 19:49:33 - INFO - __main__ - train loss is 16.292105902801268\n",
      "Steps:  48%|▍| 7271/15000 [46:11<22:55,  5.62it/s, lr=9.64e-6, step_loss=0.0708]07/18/2023 19:49:33 - INFO - __main__ - train loss is 16.34139115072321\n",
      "Steps:  48%|▍| 7272/15000 [46:11<22:54,  5.62it/s, lr=9.64e-6, step_loss=0.0493]07/18/2023 19:49:33 - INFO - __main__ - train loss is 16.362876471946947\n",
      "Steps:  48%|▍| 7273/15000 [46:11<22:54,  5.62it/s, lr=9.64e-6, step_loss=0.0215]07/18/2023 19:49:34 - INFO - __main__ - train loss is 17.063412365387194\n",
      "Steps:  48%|▉ | 7274/15000 [46:12<22:54,  5.62it/s, lr=9.64e-6, step_loss=0.701]07/18/2023 19:49:34 - INFO - __main__ - train loss is 17.354172912309878\n",
      "Steps:  48%|▉ | 7275/15000 [46:12<30:34,  4.21it/s, lr=9.64e-6, step_loss=0.291]07/18/2023 19:49:35 - INFO - __main__ - Per validation step average loss is 0.06075180321931839\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Cumulative validation average loss is 0.06075180321931839\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Per validation step average loss is 0.16822969913482666\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Cumulative validation average loss is 0.22898150235414505\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Per validation step average loss is 0.3901856541633606\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Cumulative validation average loss is 0.6191671565175056\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Per validation step average loss is 0.06468445062637329\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Cumulative validation average loss is 0.6838516071438789\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Per validation step average loss is 0.30099940299987793\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Cumulative validation average loss is 0.9848510101437569\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Per validation step average loss is 0.25372108817100525\n",
      "07/18/2023 19:49:35 - INFO - __main__ - Cumulative validation average loss is 1.2385720983147621\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Per validation step average loss is 0.0064613791182637215\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Cumulative validation average loss is 1.2450334774330258\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Per validation step average loss is 0.06748469918966293\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Cumulative validation average loss is 1.3125181766226888\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Per validation step average loss is 0.011207954958081245\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Cumulative validation average loss is 1.32372613158077\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Per validation step average loss is 0.04149056598544121\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Cumulative validation average loss is 1.3652166975662112\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Per validation step average loss is 0.004522510804235935\n",
      "07/18/2023 19:49:36 - INFO - __main__ - Cumulative validation average loss is 1.3697392083704472\n",
      "07/18/2023 19:49:37 - INFO - __main__ - Per validation step average loss is 0.2616608738899231\n",
      "07/18/2023 19:49:37 - INFO - __main__ - Cumulative validation average loss is 1.6314000822603703\n",
      "07/18/2023 19:49:37 - INFO - __main__ - Average validation loss for Epoch 74 is 0.13595000685503086\n",
      "07/18/2023 19:49:37 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:49:49 - INFO - __main__ - Starting epoch 75\n",
      "07/18/2023 19:49:50 - INFO - __main__ - train loss is 0.015139726921916008\n",
      "Steps:  49%|▍| 7276/15000 [46:28<10:38:06,  4.96s/it, lr=9.64e-6, step_loss=0.0107/18/2023 19:49:50 - INFO - __main__ - train loss is 0.04459538497030735\n",
      "Steps:  49%|▍| 7277/15000 [46:28<7:33:39,  3.52s/it, lr=9.64e-6, step_loss=0.02907/18/2023 19:49:50 - INFO - __main__ - train loss is 0.04620990587864071\n",
      "Steps:  49%|▍| 7278/15000 [46:28<5:24:31,  2.52s/it, lr=9.64e-6, step_loss=0.00107/18/2023 19:49:51 - INFO - __main__ - train loss is 0.09746604843530804\n",
      "Steps:  49%|▍| 7279/15000 [46:28<3:54:01,  1.82s/it, lr=9.64e-6, step_loss=0.05107/18/2023 19:49:51 - INFO - __main__ - train loss is 0.1511986224213615\n",
      "Steps:  49%|▍| 7280/15000 [46:29<2:50:40,  1.33s/it, lr=9.64e-6, step_loss=0.05307/18/2023 19:49:51 - INFO - __main__ - train loss is 0.15348561585415155\n",
      "Steps:  49%|▍| 7281/15000 [46:29<2:06:24,  1.02it/s, lr=9.64e-6, step_loss=0.00207/18/2023 19:49:51 - INFO - __main__ - train loss is 0.26075004518497735\n",
      "Steps:  49%|▍| 7282/15000 [46:29<1:35:24,  1.35it/s, lr=9.64e-6, step_loss=0.10707/18/2023 19:49:51 - INFO - __main__ - train loss is 0.2626274038339034\n",
      "Steps:  49%|▍| 7283/15000 [46:29<1:13:39,  1.75it/s, lr=9.64e-6, step_loss=0.00107/18/2023 19:49:51 - INFO - __main__ - train loss is 0.32404574344400316\n",
      "Steps:  49%|▍| 7284/15000 [46:29<58:25,  2.20it/s, lr=9.64e-6, step_loss=0.0614]07/18/2023 19:49:52 - INFO - __main__ - train loss is 0.3961191658163443\n",
      "Steps:  49%|▍| 7285/15000 [46:30<47:44,  2.69it/s, lr=9.64e-6, step_loss=0.0721]07/18/2023 19:49:52 - INFO - __main__ - train loss is 0.4694139693165198\n",
      "Steps:  49%|▍| 7286/15000 [46:30<40:20,  3.19it/s, lr=9.64e-6, step_loss=0.0733]07/18/2023 19:49:52 - INFO - __main__ - train loss is 0.5759644467616454\n",
      "Steps:  49%|▉ | 7287/15000 [46:30<35:06,  3.66it/s, lr=9.64e-6, step_loss=0.107]07/18/2023 19:49:52 - INFO - __main__ - train loss is 0.767572220065631\n",
      "Steps:  49%|▉ | 7288/15000 [46:30<31:28,  4.08it/s, lr=9.64e-6, step_loss=0.192]07/18/2023 19:49:52 - INFO - __main__ - train loss is 0.7854371365392581\n",
      "Steps:  49%|▍| 7289/15000 [46:30<29:07,  4.41it/s, lr=9.64e-6, step_loss=0.0179]07/18/2023 19:49:53 - INFO - __main__ - train loss is 1.1015565391862765\n",
      "Steps:  49%|▉ | 7290/15000 [46:30<27:24,  4.69it/s, lr=9.64e-6, step_loss=0.316]07/18/2023 19:49:53 - INFO - __main__ - train loss is 1.1724738624179736\n",
      "Steps:  49%|▍| 7291/15000 [46:31<26:02,  4.93it/s, lr=9.64e-6, step_loss=0.0709]07/18/2023 19:49:53 - INFO - __main__ - train loss is 1.1757118419045582\n",
      "Steps:  49%|▍| 7292/15000 [46:31<25:15,  5.09it/s, lr=9.64e-6, step_loss=0.0032407/18/2023 19:49:53 - INFO - __main__ - train loss is 1.3373498633736745\n",
      "Steps:  49%|▉ | 7293/15000 [46:31<24:34,  5.23it/s, lr=9.64e-6, step_loss=0.162]07/18/2023 19:49:53 - INFO - __main__ - train loss is 1.609257610165514\n",
      "Steps:  49%|▉ | 7294/15000 [46:31<24:04,  5.34it/s, lr=9.64e-6, step_loss=0.272]07/18/2023 19:49:53 - INFO - __main__ - train loss is 1.7194700107211247\n",
      "Steps:  49%|█▍ | 7295/15000 [46:31<23:42,  5.41it/s, lr=9.64e-6, step_loss=0.11]07/18/2023 19:49:54 - INFO - __main__ - train loss is 2.1138546630972996\n",
      "Steps:  49%|▉ | 7296/15000 [46:31<23:29,  5.46it/s, lr=9.64e-6, step_loss=0.394]07/18/2023 19:49:54 - INFO - __main__ - train loss is 2.4747795030707493\n",
      "Steps:  49%|▉ | 7297/15000 [46:32<23:20,  5.50it/s, lr=9.64e-6, step_loss=0.361]07/18/2023 19:49:54 - INFO - __main__ - train loss is 2.498741978430189\n",
      "Steps:  49%|▉ | 7298/15000 [46:32<23:14,  5.52it/s, lr=9.64e-6, step_loss=0.024]07/18/2023 19:49:54 - INFO - __main__ - train loss is 3.3463745057815686\n",
      "Steps:  49%|▉ | 7299/15000 [46:32<23:22,  5.49it/s, lr=9.64e-6, step_loss=0.848]07/18/2023 19:49:54 - INFO - __main__ - train loss is 3.358525035553612\n",
      "Steps:  49%|▍| 7300/15000 [46:32<23:26,  5.47it/s, lr=9.64e-6, step_loss=0.0122]07/18/2023 19:49:55 - INFO - __main__ - train loss is 3.5990502663189545\n",
      "Steps:  49%|▉ | 7301/15000 [46:32<23:30,  5.46it/s, lr=9.64e-6, step_loss=0.241]07/18/2023 19:49:55 - INFO - __main__ - train loss is 3.6456760592991486\n",
      "Steps:  49%|▍| 7302/15000 [46:33<23:19,  5.50it/s, lr=9.64e-6, step_loss=0.0466]07/18/2023 19:49:55 - INFO - __main__ - train loss is 4.147533042007126\n",
      "Steps:  49%|▉ | 7303/15000 [46:33<23:13,  5.53it/s, lr=9.64e-6, step_loss=0.502]07/18/2023 19:49:55 - INFO - __main__ - train loss is 4.178656631731428\n",
      "Steps:  49%|▍| 7304/15000 [46:33<23:08,  5.54it/s, lr=9.64e-6, step_loss=0.0311]07/18/2023 19:49:55 - INFO - __main__ - train loss is 4.470506036304869\n",
      "Steps:  49%|▉ | 7305/15000 [46:33<23:17,  5.51it/s, lr=9.64e-6, step_loss=0.292]07/18/2023 19:49:55 - INFO - __main__ - train loss is 4.517958374344744\n",
      "Steps:  49%|▍| 7306/15000 [46:33<23:22,  5.49it/s, lr=9.64e-6, step_loss=0.0475]07/18/2023 19:49:56 - INFO - __main__ - train loss is 4.519523853319697\n",
      "Steps:  49%|▍| 7307/15000 [46:33<23:22,  5.48it/s, lr=9.64e-6, step_loss=0.0015707/18/2023 19:49:56 - INFO - __main__ - train loss is 4.6575239094672725\n",
      "Steps:  49%|▉ | 7308/15000 [46:34<23:15,  5.51it/s, lr=9.64e-6, step_loss=0.138]07/18/2023 19:49:56 - INFO - __main__ - train loss is 5.371809402364306\n",
      "Steps:  49%|▉ | 7309/15000 [46:34<23:21,  5.49it/s, lr=9.64e-6, step_loss=0.714]07/18/2023 19:49:56 - INFO - __main__ - train loss is 5.501528778928332\n",
      "Steps:  49%|█▍ | 7310/15000 [46:34<23:19,  5.49it/s, lr=9.64e-6, step_loss=0.13]07/18/2023 19:49:56 - INFO - __main__ - train loss is 5.544639898347668\n",
      "Steps:  49%|▍| 7311/15000 [46:34<23:20,  5.49it/s, lr=9.64e-6, step_loss=0.0431]07/18/2023 19:49:57 - INFO - __main__ - train loss is 5.92884711723309\n",
      "Steps:  49%|▉ | 7312/15000 [46:34<23:12,  5.52it/s, lr=9.64e-6, step_loss=0.384]07/18/2023 19:49:57 - INFO - __main__ - train loss is 5.9307835444342345\n",
      "Steps:  49%|▍| 7313/15000 [46:35<23:12,  5.52it/s, lr=9.64e-6, step_loss=0.0019407/18/2023 19:49:57 - INFO - __main__ - train loss is 6.439769063843414\n",
      "Steps:  49%|▉ | 7314/15000 [46:35<23:07,  5.54it/s, lr=9.64e-6, step_loss=0.509]07/18/2023 19:49:57 - INFO - __main__ - train loss is 6.558912624372169\n",
      "Steps:  49%|▉ | 7315/15000 [46:35<23:03,  5.56it/s, lr=9.64e-6, step_loss=0.119]07/18/2023 19:49:57 - INFO - __main__ - train loss is 6.963894535554573\n",
      "Steps:  49%|▉ | 7316/15000 [46:35<22:59,  5.57it/s, lr=9.64e-6, step_loss=0.405]07/18/2023 19:49:57 - INFO - __main__ - train loss is 7.342964221490547\n",
      "Steps:  49%|▉ | 7317/15000 [46:35<22:57,  5.58it/s, lr=9.64e-6, step_loss=0.379]07/18/2023 19:49:58 - INFO - __main__ - train loss is 7.562288154615089\n",
      "Steps:  49%|▉ | 7318/15000 [46:35<22:54,  5.59it/s, lr=9.64e-6, step_loss=0.219]07/18/2023 19:49:58 - INFO - __main__ - train loss is 7.571562640136108\n",
      "Steps:  49%|▍| 7319/15000 [46:36<22:54,  5.59it/s, lr=9.64e-6, step_loss=0.0092707/18/2023 19:49:58 - INFO - __main__ - train loss is 7.615260477876291\n",
      "Steps:  49%|▍| 7320/15000 [46:36<23:05,  5.54it/s, lr=9.64e-6, step_loss=0.0437]07/18/2023 19:49:58 - INFO - __main__ - train loss is 7.6490578015800565\n",
      "Steps:  49%|▍| 7321/15000 [46:36<23:00,  5.56it/s, lr=9.64e-6, step_loss=0.0338]07/18/2023 19:49:58 - INFO - __main__ - train loss is 7.68947934708558\n",
      "Steps:  49%|▍| 7322/15000 [46:36<22:57,  5.57it/s, lr=9.64e-6, step_loss=0.0404]07/18/2023 19:49:58 - INFO - __main__ - train loss is 8.065465833758935\n",
      "Steps:  49%|▉ | 7323/15000 [46:36<22:57,  5.57it/s, lr=9.64e-6, step_loss=0.376]07/18/2023 19:49:59 - INFO - __main__ - train loss is 8.06867878115736\n",
      "Steps:  49%|▍| 7324/15000 [46:37<22:55,  5.58it/s, lr=9.64e-6, step_loss=0.0032107/18/2023 19:49:59 - INFO - __main__ - train loss is 8.262296974426135\n",
      "Steps:  49%|▉ | 7325/15000 [46:37<22:54,  5.58it/s, lr=9.64e-6, step_loss=0.194]07/18/2023 19:49:59 - INFO - __main__ - train loss is 8.554015338188037\n",
      "Steps:  49%|▉ | 7326/15000 [46:37<22:53,  5.59it/s, lr=9.64e-6, step_loss=0.292]07/18/2023 19:49:59 - INFO - __main__ - train loss is 8.566996458685026\n",
      "Steps:  49%|▉ | 7327/15000 [46:37<22:53,  5.59it/s, lr=9.64e-6, step_loss=0.013]07/18/2023 19:49:59 - INFO - __main__ - train loss is 8.56884787499439\n",
      "Steps:  49%|▍| 7328/15000 [46:37<22:53,  5.59it/s, lr=9.64e-6, step_loss=0.0018507/18/2023 19:50:00 - INFO - __main__ - train loss is 8.605328115518205\n",
      "Steps:  49%|▍| 7329/15000 [46:37<22:53,  5.58it/s, lr=9.64e-6, step_loss=0.0365]07/18/2023 19:50:00 - INFO - __main__ - train loss is 8.617666157777421\n",
      "Steps:  49%|▍| 7330/15000 [46:38<22:53,  5.59it/s, lr=9.64e-6, step_loss=0.0123]07/18/2023 19:50:00 - INFO - __main__ - train loss is 8.628987126867287\n",
      "Steps:  49%|▍| 7331/15000 [46:38<23:05,  5.53it/s, lr=9.64e-6, step_loss=0.0113]07/18/2023 19:50:00 - INFO - __main__ - train loss is 8.634760604123585\n",
      "Steps:  49%|▍| 7332/15000 [46:38<23:05,  5.53it/s, lr=9.64e-6, step_loss=0.0057707/18/2023 19:50:00 - INFO - __main__ - train loss is 8.637792740832083\n",
      "Steps:  49%|▍| 7333/15000 [46:38<23:10,  5.51it/s, lr=9.64e-6, step_loss=0.0030307/18/2023 19:50:00 - INFO - __main__ - train loss is 8.740869511733763\n",
      "Steps:  49%|▉ | 7334/15000 [46:38<23:04,  5.54it/s, lr=9.64e-6, step_loss=0.103]07/18/2023 19:50:01 - INFO - __main__ - train loss is 8.747667728806846\n",
      "Steps:  49%|▍| 7335/15000 [46:39<23:13,  5.50it/s, lr=9.64e-6, step_loss=0.0068]07/18/2023 19:50:01 - INFO - __main__ - train loss is 8.8979060043348\n",
      "Steps:  49%|█▍ | 7336/15000 [46:39<23:23,  5.46it/s, lr=9.64e-6, step_loss=0.15]07/18/2023 19:50:01 - INFO - __main__ - train loss is 8.954073882545345\n",
      "Steps:  49%|▍| 7337/15000 [46:39<23:30,  5.43it/s, lr=9.64e-6, step_loss=0.0562]07/18/2023 19:50:01 - INFO - __main__ - train loss is 9.149758851970546\n",
      "Steps:  49%|▉ | 7338/15000 [46:39<23:35,  5.41it/s, lr=9.64e-6, step_loss=0.196]07/18/2023 19:50:01 - INFO - __main__ - train loss is 9.365140086854808\n",
      "Steps:  49%|▉ | 7339/15000 [46:39<23:35,  5.41it/s, lr=9.64e-6, step_loss=0.215]07/18/2023 19:50:02 - INFO - __main__ - train loss is 9.449452786589973\n",
      "Steps:  49%|▍| 7340/15000 [46:39<23:24,  5.46it/s, lr=9.64e-6, step_loss=0.0843]07/18/2023 19:50:02 - INFO - __main__ - train loss is 9.754736809874885\n",
      "Steps:  49%|▉ | 7341/15000 [46:40<23:26,  5.45it/s, lr=9.64e-6, step_loss=0.305]07/18/2023 19:50:02 - INFO - __main__ - train loss is 9.76479244127404\n",
      "Steps:  49%|▍| 7342/15000 [46:40<23:18,  5.47it/s, lr=9.64e-6, step_loss=0.0101]07/18/2023 19:50:02 - INFO - __main__ - train loss is 9.837377144838683\n",
      "Steps:  49%|▍| 7343/15000 [46:40<23:10,  5.51it/s, lr=9.64e-6, step_loss=0.0726]07/18/2023 19:50:02 - INFO - __main__ - train loss is 9.910420982982032\n",
      "Steps:  49%|▉ | 7344/15000 [46:40<23:03,  5.53it/s, lr=9.64e-6, step_loss=0.073]07/18/2023 19:50:02 - INFO - __main__ - train loss is 10.292898713494651\n",
      "Steps:  49%|▉ | 7345/15000 [46:40<23:10,  5.50it/s, lr=9.64e-6, step_loss=0.382]07/18/2023 19:50:03 - INFO - __main__ - train loss is 10.312685011769645\n",
      "Steps:  49%|▍| 7346/15000 [46:41<23:03,  5.53it/s, lr=9.64e-6, step_loss=0.0198]07/18/2023 19:50:03 - INFO - __main__ - train loss is 10.366516127134673\n",
      "Steps:  49%|▍| 7347/15000 [46:41<22:58,  5.55it/s, lr=9.64e-6, step_loss=0.0538]07/18/2023 19:50:03 - INFO - __main__ - train loss is 10.406869168276899\n",
      "Steps:  49%|▍| 7348/15000 [46:41<23:10,  5.50it/s, lr=9.64e-6, step_loss=0.0404]07/18/2023 19:50:03 - INFO - __main__ - train loss is 10.72645288228523\n",
      "Steps:  49%|█▍ | 7349/15000 [46:41<23:12,  5.49it/s, lr=9.64e-6, step_loss=0.32]07/18/2023 19:50:03 - INFO - __main__ - train loss is 10.782410166109912\n",
      "Steps:  49%|▉ | 7350/15000 [46:41<23:18,  5.47it/s, lr=9.64e-6, step_loss=0.056]07/18/2023 19:50:04 - INFO - __main__ - train loss is 10.795120411436073\n",
      "Steps:  49%|▍| 7351/15000 [46:41<23:15,  5.48it/s, lr=9.64e-6, step_loss=0.0127]07/18/2023 19:50:04 - INFO - __main__ - train loss is 10.886319168726914\n",
      "Steps:  49%|▍| 7352/15000 [46:42<23:11,  5.49it/s, lr=9.64e-6, step_loss=0.0912]07/18/2023 19:50:04 - INFO - __main__ - train loss is 11.323858984629624\n",
      "Steps:  49%|▉ | 7353/15000 [46:42<23:10,  5.50it/s, lr=9.64e-6, step_loss=0.438]07/18/2023 19:50:04 - INFO - __main__ - train loss is 11.638467498938553\n",
      "Steps:  49%|▉ | 7354/15000 [46:42<23:12,  5.49it/s, lr=9.64e-6, step_loss=0.315]07/18/2023 19:50:04 - INFO - __main__ - train loss is 12.023688026587479\n",
      "Steps:  49%|▉ | 7355/15000 [46:42<23:11,  5.50it/s, lr=9.64e-6, step_loss=0.385]07/18/2023 19:50:04 - INFO - __main__ - train loss is 12.027190422057174\n",
      "Steps:  49%|▍| 7356/15000 [46:42<23:02,  5.53it/s, lr=9.64e-6, step_loss=0.0035]07/18/2023 19:50:05 - INFO - __main__ - train loss is 12.029042148613371\n",
      "Steps:  49%|▍| 7357/15000 [46:43<23:09,  5.50it/s, lr=9.64e-6, step_loss=0.0018507/18/2023 19:50:05 - INFO - __main__ - train loss is 12.085055494331755\n",
      "Steps:  49%|▉ | 7358/15000 [46:43<23:01,  5.53it/s, lr=9.64e-6, step_loss=0.056]07/18/2023 19:50:05 - INFO - __main__ - train loss is 12.151826584362425\n",
      "Steps:  49%|▍| 7359/15000 [46:43<23:00,  5.54it/s, lr=9.63e-6, step_loss=0.0668]07/18/2023 19:50:05 - INFO - __main__ - train loss is 12.572371119284071\n",
      "Steps:  49%|▉ | 7360/15000 [46:43<22:55,  5.55it/s, lr=9.63e-6, step_loss=0.421]07/18/2023 19:50:05 - INFO - __main__ - train loss is 12.607823026948608\n",
      "Steps:  49%|▍| 7361/15000 [46:43<22:51,  5.57it/s, lr=9.63e-6, step_loss=0.0355]07/18/2023 19:50:06 - INFO - __main__ - train loss is 12.836862725787796\n",
      "Steps:  49%|▉ | 7362/15000 [46:43<23:02,  5.53it/s, lr=9.63e-6, step_loss=0.229]07/18/2023 19:50:06 - INFO - __main__ - train loss is 12.903406424098648\n",
      "Steps:  49%|▍| 7363/15000 [46:44<23:18,  5.46it/s, lr=9.63e-6, step_loss=0.0665]07/18/2023 19:50:06 - INFO - __main__ - train loss is 12.945809563272633\n",
      "Steps:  49%|▍| 7364/15000 [46:44<23:17,  5.46it/s, lr=9.63e-6, step_loss=0.0424]07/18/2023 19:50:06 - INFO - __main__ - train loss is 13.14965783583466\n",
      "Steps:  49%|▉ | 7365/15000 [46:44<23:06,  5.51it/s, lr=9.63e-6, step_loss=0.204]07/18/2023 19:50:06 - INFO - __main__ - train loss is 13.151295853080228\n",
      "Steps:  49%|▍| 7366/15000 [46:44<22:57,  5.54it/s, lr=9.63e-6, step_loss=0.0016407/18/2023 19:50:06 - INFO - __main__ - train loss is 13.221858781995252\n",
      "Steps:  49%|▍| 7367/15000 [46:44<22:51,  5.57it/s, lr=9.63e-6, step_loss=0.0706]07/18/2023 19:50:07 - INFO - __main__ - train loss is 13.393796813907102\n",
      "Steps:  49%|▉ | 7368/15000 [46:45<22:48,  5.58it/s, lr=9.63e-6, step_loss=0.172]07/18/2023 19:50:07 - INFO - __main__ - train loss is 13.519455460133031\n",
      "Steps:  49%|▉ | 7369/15000 [46:45<22:45,  5.59it/s, lr=9.63e-6, step_loss=0.126]07/18/2023 19:50:07 - INFO - __main__ - train loss is 13.582511571468785\n",
      "Steps:  49%|▍| 7370/15000 [46:45<22:43,  5.59it/s, lr=9.63e-6, step_loss=0.0631]07/18/2023 19:50:07 - INFO - __main__ - train loss is 13.61898369831033\n",
      "Steps:  49%|▍| 7371/15000 [46:45<22:42,  5.60it/s, lr=9.63e-6, step_loss=0.0365]07/18/2023 19:50:08 - INFO - __main__ - train loss is 14.210903478087857\n",
      "Steps:  49%|▉ | 7372/15000 [46:45<30:10,  4.21it/s, lr=9.63e-6, step_loss=0.592]07/18/2023 19:50:08 - INFO - __main__ - Per validation step average loss is 0.0024939884897321463\n",
      "07/18/2023 19:50:08 - INFO - __main__ - Cumulative validation average loss is 0.0024939884897321463\n",
      "07/18/2023 19:50:08 - INFO - __main__ - Per validation step average loss is 0.07926813513040543\n",
      "07/18/2023 19:50:08 - INFO - __main__ - Cumulative validation average loss is 0.08176212362013757\n",
      "07/18/2023 19:50:08 - INFO - __main__ - Per validation step average loss is 0.04146261513233185\n",
      "07/18/2023 19:50:08 - INFO - __main__ - Cumulative validation average loss is 0.12322473875246942\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Per validation step average loss is 0.10301028192043304\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Cumulative validation average loss is 0.22623502067290246\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Per validation step average loss is 0.0034092143177986145\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Cumulative validation average loss is 0.22964423499070108\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Per validation step average loss is 0.05288396030664444\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Cumulative validation average loss is 0.2825281952973455\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Per validation step average loss is 0.07195238769054413\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Cumulative validation average loss is 0.35448058298788965\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Per validation step average loss is 0.2526399493217468\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Cumulative validation average loss is 0.6071205323096365\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Per validation step average loss is 0.30200839042663574\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Cumulative validation average loss is 0.9091289227362722\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Per validation step average loss is 0.007120649330317974\n",
      "07/18/2023 19:50:09 - INFO - __main__ - Cumulative validation average loss is 0.9162495720665902\n",
      "07/18/2023 19:50:10 - INFO - __main__ - Per validation step average loss is 0.2322579026222229\n",
      "07/18/2023 19:50:10 - INFO - __main__ - Cumulative validation average loss is 1.148507474688813\n",
      "07/18/2023 19:50:10 - INFO - __main__ - Per validation step average loss is 0.021014615893363953\n",
      "07/18/2023 19:50:10 - INFO - __main__ - Cumulative validation average loss is 1.169522090582177\n",
      "07/18/2023 19:50:10 - INFO - __main__ - Average validation loss for Epoch 75 is 0.09746017421518142\n",
      "07/18/2023 19:50:10 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:50:23 - INFO - __main__ - Starting epoch 76\n",
      "07/18/2023 19:50:23 - INFO - __main__ - train loss is 0.06273825466632843\n",
      "Steps:  49%|▍| 7373/15000 [47:01<10:22:00,  4.89s/it, lr=9.63e-6, step_loss=0.0607/18/2023 19:50:23 - INFO - __main__ - train loss is 0.07052838336676359\n",
      "Steps:  49%|▍| 7374/15000 [47:01<7:22:09,  3.48s/it, lr=9.63e-6, step_loss=0.00707/18/2023 19:50:24 - INFO - __main__ - train loss is 0.07363459747284651\n",
      "Steps:  49%|▍| 7375/15000 [47:02<5:16:19,  2.49s/it, lr=9.63e-6, step_loss=0.00307/18/2023 19:50:24 - INFO - __main__ - train loss is 0.4795815674588084\n",
      "Steps:  49%|▍| 7376/15000 [47:02<3:48:11,  1.80s/it, lr=9.63e-6, step_loss=0.40607/18/2023 19:50:24 - INFO - __main__ - train loss is 0.5820691762492061\n",
      "Steps:  49%|▍| 7377/15000 [47:02<2:46:29,  1.31s/it, lr=9.63e-6, step_loss=0.10207/18/2023 19:50:24 - INFO - __main__ - train loss is 0.5907356115058064\n",
      "Steps:  49%|▍| 7378/15000 [47:02<2:03:24,  1.03it/s, lr=9.63e-6, step_loss=0.00807/18/2023 19:50:24 - INFO - __main__ - train loss is 0.9368981989100575\n",
      "Steps:  49%|▍| 7379/15000 [47:02<1:33:10,  1.36it/s, lr=9.63e-6, step_loss=0.34607/18/2023 19:50:25 - INFO - __main__ - train loss is 1.5246234210208058\n",
      "Steps:  49%|▍| 7380/15000 [47:02<1:11:59,  1.76it/s, lr=9.63e-6, step_loss=0.58807/18/2023 19:50:25 - INFO - __main__ - train loss is 1.8664127262309194\n",
      "Steps:  49%|▉ | 7381/15000 [47:03<57:10,  2.22it/s, lr=9.63e-6, step_loss=0.342]07/18/2023 19:50:25 - INFO - __main__ - train loss is 1.8718881327658892\n",
      "Steps:  49%|▍| 7382/15000 [47:03<46:47,  2.71it/s, lr=9.63e-6, step_loss=0.0054807/18/2023 19:50:25 - INFO - __main__ - train loss is 2.1819146890193224\n",
      "Steps:  49%|█▍ | 7383/15000 [47:03<39:32,  3.21it/s, lr=9.63e-6, step_loss=0.31]07/18/2023 19:50:25 - INFO - __main__ - train loss is 2.1968742422759533\n",
      "Steps:  49%|▉ | 7384/15000 [47:03<34:26,  3.68it/s, lr=9.63e-6, step_loss=0.015]07/18/2023 19:50:25 - INFO - __main__ - train loss is 2.202015340793878\n",
      "Steps:  49%|▍| 7385/15000 [47:03<30:52,  4.11it/s, lr=9.63e-6, step_loss=0.0051407/18/2023 19:50:26 - INFO - __main__ - train loss is 2.9239259962923825\n",
      "Steps:  49%|▉ | 7386/15000 [47:04<28:24,  4.47it/s, lr=9.63e-6, step_loss=0.722]07/18/2023 19:50:26 - INFO - __main__ - train loss is 3.1897538607008755\n",
      "Steps:  49%|▉ | 7387/15000 [47:04<26:39,  4.76it/s, lr=9.63e-6, step_loss=0.266]07/18/2023 19:50:26 - INFO - __main__ - train loss is 3.193528039380908\n",
      "Steps:  49%|▍| 7388/15000 [47:04<25:25,  4.99it/s, lr=9.63e-6, step_loss=0.0037707/18/2023 19:50:26 - INFO - __main__ - train loss is 3.1951085564214736\n",
      "Steps:  49%|▍| 7389/15000 [47:04<24:34,  5.16it/s, lr=9.63e-6, step_loss=0.0015807/18/2023 19:50:26 - INFO - __main__ - train loss is 3.198859974509105\n",
      "Steps:  49%|▍| 7390/15000 [47:04<23:59,  5.29it/s, lr=9.63e-6, step_loss=0.0037507/18/2023 19:50:27 - INFO - __main__ - train loss is 3.2404112776275724\n",
      "Steps:  49%|▍| 7391/15000 [47:04<23:34,  5.38it/s, lr=9.63e-6, step_loss=0.0416]07/18/2023 19:50:27 - INFO - __main__ - train loss is 3.244161785580218\n",
      "Steps:  49%|▍| 7392/15000 [47:05<23:16,  5.45it/s, lr=9.63e-6, step_loss=0.0037507/18/2023 19:50:27 - INFO - __main__ - train loss is 3.2959590265527368\n",
      "Steps:  49%|▍| 7393/15000 [47:05<23:05,  5.49it/s, lr=9.63e-6, step_loss=0.0518]07/18/2023 19:50:27 - INFO - __main__ - train loss is 3.3056842954829335\n",
      "Steps:  49%|▍| 7394/15000 [47:05<22:56,  5.52it/s, lr=9.63e-6, step_loss=0.0097307/18/2023 19:50:27 - INFO - __main__ - train loss is 3.3707746164873242\n",
      "Steps:  49%|▍| 7395/15000 [47:05<22:51,  5.55it/s, lr=9.63e-6, step_loss=0.0651]07/18/2023 19:50:27 - INFO - __main__ - train loss is 4.296995271928608\n",
      "Steps:  49%|▉ | 7396/15000 [47:05<22:55,  5.53it/s, lr=9.63e-6, step_loss=0.926]07/18/2023 19:50:28 - INFO - __main__ - train loss is 4.322610796429217\n",
      "Steps:  49%|▍| 7397/15000 [47:05<22:50,  5.55it/s, lr=9.63e-6, step_loss=0.0256]07/18/2023 19:50:28 - INFO - __main__ - train loss is 4.328845185227692\n",
      "Steps:  49%|▍| 7398/15000 [47:06<22:47,  5.56it/s, lr=9.63e-6, step_loss=0.0062307/18/2023 19:50:28 - INFO - __main__ - train loss is 4.38664132822305\n",
      "Steps:  49%|▍| 7399/15000 [47:06<22:44,  5.57it/s, lr=9.63e-6, step_loss=0.0578]07/18/2023 19:50:28 - INFO - __main__ - train loss is 4.472585600800812\n",
      "Steps:  49%|▍| 7400/15000 [47:06<22:41,  5.58it/s, lr=9.63e-6, step_loss=0.0859]07/18/2023 19:50:28 - INFO - __main__ - train loss is 4.724407655186951\n",
      "Steps:  49%|▉ | 7401/15000 [47:06<22:40,  5.59it/s, lr=9.63e-6, step_loss=0.252]07/18/2023 19:50:28 - INFO - __main__ - train loss is 4.874749434180558\n",
      "Steps:  49%|█▍ | 7402/15000 [47:06<22:39,  5.59it/s, lr=9.63e-6, step_loss=0.15]07/18/2023 19:50:29 - INFO - __main__ - train loss is 4.879682024475187\n",
      "Steps:  49%|▍| 7403/15000 [47:07<22:40,  5.59it/s, lr=9.63e-6, step_loss=0.0049307/18/2023 19:50:29 - INFO - __main__ - train loss is 4.882082650437951\n",
      "Steps:  49%|▍| 7404/15000 [47:07<22:38,  5.59it/s, lr=9.63e-6, step_loss=0.0024]07/18/2023 19:50:29 - INFO - __main__ - train loss is 4.884195655817166\n",
      "Steps:  49%|▍| 7405/15000 [47:07<22:40,  5.58it/s, lr=9.63e-6, step_loss=0.0021107/18/2023 19:50:29 - INFO - __main__ - train loss is 4.968576193088666\n",
      "Steps:  49%|▍| 7406/15000 [47:07<22:39,  5.59it/s, lr=9.63e-6, step_loss=0.0844]07/18/2023 19:50:29 - INFO - __main__ - train loss is 5.375505209201947\n",
      "Steps:  49%|▉ | 7407/15000 [47:07<22:37,  5.59it/s, lr=9.63e-6, step_loss=0.407]07/18/2023 19:50:30 - INFO - __main__ - train loss is 5.47547459625639\n",
      "Steps:  49%|█▉  | 7408/15000 [47:07<22:36,  5.60it/s, lr=9.63e-6, step_loss=0.1]07/18/2023 19:50:30 - INFO - __main__ - train loss is 5.756281584734097\n",
      "Steps:  49%|▉ | 7409/15000 [47:08<22:35,  5.60it/s, lr=9.63e-6, step_loss=0.281]07/18/2023 19:50:30 - INFO - __main__ - train loss is 5.766996087739244\n",
      "Steps:  49%|▍| 7410/15000 [47:08<22:34,  5.60it/s, lr=9.63e-6, step_loss=0.0107]07/18/2023 19:50:30 - INFO - __main__ - train loss is 5.924118088791147\n",
      "Steps:  49%|▉ | 7411/15000 [47:08<22:33,  5.61it/s, lr=9.63e-6, step_loss=0.157]07/18/2023 19:50:30 - INFO - __main__ - train loss is 5.950285576516762\n",
      "Steps:  49%|▍| 7412/15000 [47:08<22:33,  5.61it/s, lr=9.63e-6, step_loss=0.0262]07/18/2023 19:50:30 - INFO - __main__ - train loss is 5.970961340004578\n",
      "Steps:  49%|▍| 7413/15000 [47:08<22:33,  5.61it/s, lr=9.63e-6, step_loss=0.0207]07/18/2023 19:50:31 - INFO - __main__ - train loss is 6.174778364831582\n",
      "Steps:  49%|▉ | 7414/15000 [47:09<22:32,  5.61it/s, lr=9.63e-6, step_loss=0.204]07/18/2023 19:50:31 - INFO - __main__ - train loss is 6.204334117705002\n",
      "Steps:  49%|▍| 7415/15000 [47:09<22:32,  5.61it/s, lr=9.63e-6, step_loss=0.0296]07/18/2023 19:50:31 - INFO - __main__ - train loss is 6.3913053350988775\n",
      "Steps:  49%|▉ | 7416/15000 [47:09<22:34,  5.60it/s, lr=9.63e-6, step_loss=0.187]07/18/2023 19:50:31 - INFO - __main__ - train loss is 6.457368560368195\n",
      "Steps:  49%|▍| 7417/15000 [47:09<22:33,  5.60it/s, lr=9.63e-6, step_loss=0.0661]07/18/2023 19:50:31 - INFO - __main__ - train loss is 6.490029603475705\n",
      "Steps:  49%|▍| 7418/15000 [47:09<22:33,  5.60it/s, lr=9.63e-6, step_loss=0.0327]07/18/2023 19:50:32 - INFO - __main__ - train loss is 6.809513837331906\n",
      "Steps:  49%|▉ | 7419/15000 [47:09<22:33,  5.60it/s, lr=9.63e-6, step_loss=0.319]07/18/2023 19:50:32 - INFO - __main__ - train loss is 7.3997549714986235\n",
      "Steps:  49%|█▍ | 7420/15000 [47:10<22:32,  5.60it/s, lr=9.63e-6, step_loss=0.59]07/18/2023 19:50:32 - INFO - __main__ - train loss is 7.547751754755154\n",
      "Steps:  49%|▉ | 7421/15000 [47:10<22:32,  5.60it/s, lr=9.63e-6, step_loss=0.148]07/18/2023 19:50:32 - INFO - __main__ - train loss is 7.635598920518532\n",
      "Steps:  49%|▍| 7422/15000 [47:10<22:31,  5.61it/s, lr=9.63e-6, step_loss=0.0878]07/18/2023 19:50:32 - INFO - __main__ - train loss is 7.638111605076119\n",
      "Steps:  49%|▍| 7423/15000 [47:10<22:31,  5.61it/s, lr=9.63e-6, step_loss=0.0025107/18/2023 19:50:32 - INFO - __main__ - train loss is 7.6601671043317765\n",
      "Steps:  49%|▍| 7424/15000 [47:10<22:41,  5.57it/s, lr=9.63e-6, step_loss=0.0221]07/18/2023 19:50:33 - INFO - __main__ - train loss is 7.805845535127446\n",
      "Steps:  50%|▉ | 7425/15000 [47:10<22:44,  5.55it/s, lr=9.63e-6, step_loss=0.146]07/18/2023 19:50:33 - INFO - __main__ - train loss is 8.13305506738834\n",
      "Steps:  50%|▉ | 7426/15000 [47:11<22:45,  5.55it/s, lr=9.63e-6, step_loss=0.327]07/18/2023 19:50:33 - INFO - __main__ - train loss is 8.179585120407864\n",
      "Steps:  50%|▍| 7427/15000 [47:11<22:55,  5.50it/s, lr=9.63e-6, step_loss=0.0465]07/18/2023 19:50:33 - INFO - __main__ - train loss is 8.361419892637059\n",
      "Steps:  50%|▉ | 7428/15000 [47:11<22:53,  5.51it/s, lr=9.63e-6, step_loss=0.182]07/18/2023 19:50:33 - INFO - __main__ - train loss is 8.502041867701337\n",
      "Steps:  50%|▉ | 7429/15000 [47:11<22:52,  5.52it/s, lr=9.63e-6, step_loss=0.141]07/18/2023 19:50:34 - INFO - __main__ - train loss is 8.570739119080827\n",
      "Steps:  50%|▍| 7430/15000 [47:11<22:51,  5.52it/s, lr=9.63e-6, step_loss=0.0687]07/18/2023 19:50:34 - INFO - __main__ - train loss is 8.821597217349336\n",
      "Steps:  50%|▉ | 7431/15000 [47:12<22:50,  5.52it/s, lr=9.63e-6, step_loss=0.251]07/18/2023 19:50:34 - INFO - __main__ - train loss is 9.688621042994782\n",
      "Steps:  50%|▉ | 7432/15000 [47:12<22:50,  5.52it/s, lr=9.63e-6, step_loss=0.867]07/18/2023 19:50:34 - INFO - __main__ - train loss is 10.282557843951508\n",
      "Steps:  50%|▉ | 7433/15000 [47:12<22:51,  5.52it/s, lr=9.63e-6, step_loss=0.594]07/18/2023 19:50:34 - INFO - __main__ - train loss is 10.31696396204643\n",
      "Steps:  50%|▍| 7434/15000 [47:12<22:49,  5.52it/s, lr=9.63e-6, step_loss=0.0344]07/18/2023 19:50:34 - INFO - __main__ - train loss is 10.31931599485688\n",
      "Steps:  50%|▍| 7435/15000 [47:12<22:49,  5.52it/s, lr=9.63e-6, step_loss=0.0023507/18/2023 19:50:35 - INFO - __main__ - train loss is 10.514976526377723\n",
      "Steps:  50%|▉ | 7436/15000 [47:12<22:48,  5.53it/s, lr=9.63e-6, step_loss=0.196]07/18/2023 19:50:35 - INFO - __main__ - train loss is 10.614077153382823\n",
      "Steps:  50%|▍| 7437/15000 [47:13<22:47,  5.53it/s, lr=9.63e-6, step_loss=0.0991]07/18/2023 19:50:35 - INFO - __main__ - train loss is 10.649716566083953\n",
      "Steps:  50%|▍| 7438/15000 [47:13<23:00,  5.48it/s, lr=9.63e-6, step_loss=0.0356]07/18/2023 19:50:35 - INFO - __main__ - train loss is 10.656709135277197\n",
      "Steps:  50%|▍| 7439/15000 [47:13<23:05,  5.46it/s, lr=9.63e-6, step_loss=0.0069907/18/2023 19:50:35 - INFO - __main__ - train loss is 10.999946594936773\n",
      "Steps:  50%|▉ | 7440/15000 [47:13<22:57,  5.49it/s, lr=9.63e-6, step_loss=0.343]07/18/2023 19:50:36 - INFO - __main__ - train loss is 11.345752478344366\n",
      "Steps:  50%|▉ | 7441/15000 [47:13<23:00,  5.47it/s, lr=9.63e-6, step_loss=0.346]07/18/2023 19:50:36 - INFO - __main__ - train loss is 11.517490313155577\n",
      "Steps:  50%|▉ | 7442/15000 [47:14<23:02,  5.47it/s, lr=9.63e-6, step_loss=0.172]07/18/2023 19:50:36 - INFO - __main__ - train loss is 11.76132968137972\n",
      "Steps:  50%|▉ | 7443/15000 [47:14<22:53,  5.50it/s, lr=9.63e-6, step_loss=0.244]07/18/2023 19:50:36 - INFO - __main__ - train loss is 11.762886534794234\n",
      "Steps:  50%|▍| 7444/15000 [47:14<22:46,  5.53it/s, lr=9.63e-6, step_loss=0.0015607/18/2023 19:50:36 - INFO - __main__ - train loss is 11.766881116083823\n",
      "Steps:  50%|▍| 7445/15000 [47:14<22:53,  5.50it/s, lr=9.63e-6, step_loss=0.0039907/18/2023 19:50:36 - INFO - __main__ - train loss is 12.410340674570762\n",
      "Steps:  50%|▉ | 7446/15000 [47:14<22:49,  5.52it/s, lr=9.63e-6, step_loss=0.643]07/18/2023 19:50:37 - INFO - __main__ - train loss is 12.431223444989882\n",
      "Steps:  50%|▍| 7447/15000 [47:14<22:53,  5.50it/s, lr=9.63e-6, step_loss=0.0209]07/18/2023 19:50:37 - INFO - __main__ - train loss is 12.943626873544417\n",
      "Steps:  50%|▉ | 7448/15000 [47:15<22:59,  5.47it/s, lr=9.63e-6, step_loss=0.512]07/18/2023 19:50:37 - INFO - __main__ - train loss is 13.204348080209456\n",
      "Steps:  50%|▉ | 7449/15000 [47:15<23:06,  5.45it/s, lr=9.63e-6, step_loss=0.261]07/18/2023 19:50:37 - INFO - __main__ - train loss is 13.223111421219073\n",
      "Steps:  50%|▍| 7450/15000 [47:15<23:01,  5.46it/s, lr=9.63e-6, step_loss=0.0188]07/18/2023 19:50:37 - INFO - __main__ - train loss is 13.331028700224124\n",
      "Steps:  50%|▉ | 7451/15000 [47:15<22:57,  5.48it/s, lr=9.63e-6, step_loss=0.108]07/18/2023 19:50:38 - INFO - __main__ - train loss is 13.720347643247806\n",
      "Steps:  50%|▉ | 7452/15000 [47:15<23:01,  5.46it/s, lr=9.63e-6, step_loss=0.389]07/18/2023 19:50:38 - INFO - __main__ - train loss is 13.973918736330234\n",
      "Steps:  50%|▉ | 7453/15000 [47:16<22:54,  5.49it/s, lr=9.63e-6, step_loss=0.254]07/18/2023 19:50:38 - INFO - __main__ - train loss is 14.000235665938817\n",
      "Steps:  50%|▍| 7454/15000 [47:16<22:57,  5.48it/s, lr=9.63e-6, step_loss=0.0263]07/18/2023 19:50:38 - INFO - __main__ - train loss is 14.261141080758534\n",
      "Steps:  50%|▉ | 7455/15000 [47:16<22:47,  5.52it/s, lr=9.63e-6, step_loss=0.261]07/18/2023 19:50:38 - INFO - __main__ - train loss is 14.79830207338091\n",
      "Steps:  50%|▉ | 7456/15000 [47:16<22:50,  5.50it/s, lr=9.63e-6, step_loss=0.537]07/18/2023 19:50:38 - INFO - __main__ - train loss is 14.946086217067204\n",
      "Steps:  50%|▉ | 7457/15000 [47:16<22:41,  5.54it/s, lr=9.63e-6, step_loss=0.148]07/18/2023 19:50:39 - INFO - __main__ - train loss is 15.399851668975316\n",
      "Steps:  50%|▉ | 7458/15000 [47:16<22:35,  5.56it/s, lr=9.63e-6, step_loss=0.454]07/18/2023 19:50:39 - INFO - __main__ - train loss is 15.461618740460835\n",
      "Steps:  50%|▍| 7459/15000 [47:17<22:29,  5.59it/s, lr=9.63e-6, step_loss=0.0618]07/18/2023 19:50:39 - INFO - __main__ - train loss is 16.110350806615315\n",
      "Steps:  50%|▉ | 7460/15000 [47:17<22:28,  5.59it/s, lr=9.62e-6, step_loss=0.649]07/18/2023 19:50:39 - INFO - __main__ - train loss is 16.134823980159126\n",
      "Steps:  50%|▍| 7461/15000 [47:17<22:27,  5.60it/s, lr=9.62e-6, step_loss=0.0245]07/18/2023 19:50:39 - INFO - __main__ - train loss is 16.20325876993593\n",
      "Steps:  50%|▍| 7462/15000 [47:17<22:29,  5.59it/s, lr=9.62e-6, step_loss=0.0684]07/18/2023 19:50:39 - INFO - __main__ - train loss is 16.26269643229898\n",
      "Steps:  50%|▍| 7463/15000 [47:17<22:27,  5.59it/s, lr=9.62e-6, step_loss=0.0594]07/18/2023 19:50:40 - INFO - __main__ - train loss is 16.26465375011321\n",
      "Steps:  50%|▍| 7464/15000 [47:18<22:26,  5.60it/s, lr=9.62e-6, step_loss=0.0019607/18/2023 19:50:40 - INFO - __main__ - train loss is 16.47124361281749\n",
      "Steps:  50%|▉ | 7465/15000 [47:18<22:23,  5.61it/s, lr=9.62e-6, step_loss=0.207]07/18/2023 19:50:40 - INFO - __main__ - train loss is 16.489259982830845\n",
      "Steps:  50%|▉ | 7466/15000 [47:18<22:23,  5.61it/s, lr=9.62e-6, step_loss=0.018]07/18/2023 19:50:40 - INFO - __main__ - train loss is 16.71056678367313\n",
      "Steps:  50%|▉ | 7467/15000 [47:18<22:23,  5.61it/s, lr=9.62e-6, step_loss=0.221]07/18/2023 19:50:40 - INFO - __main__ - train loss is 16.784810202545486\n",
      "Steps:  50%|▍| 7468/15000 [47:18<22:23,  5.61it/s, lr=9.62e-6, step_loss=0.0742]07/18/2023 19:50:41 - INFO - __main__ - train loss is 17.189580636448227\n",
      "Steps:  50%|▉ | 7469/15000 [47:19<30:40,  4.09it/s, lr=9.62e-6, step_loss=0.405]07/18/2023 19:50:42 - INFO - __main__ - Per validation step average loss is 0.008989985100924969\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Cumulative validation average loss is 0.008989985100924969\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Per validation step average loss is 0.006829807534813881\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Cumulative validation average loss is 0.01581979263573885\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Per validation step average loss is 0.017561741173267365\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Cumulative validation average loss is 0.033381533809006214\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Per validation step average loss is 0.37089309096336365\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Cumulative validation average loss is 0.40427462477236986\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Per validation step average loss is 0.21586796641349792\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Cumulative validation average loss is 0.6201425911858678\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Per validation step average loss is 0.0044020116329193115\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Cumulative validation average loss is 0.6245446028187871\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Per validation step average loss is 0.011279175989329815\n",
      "07/18/2023 19:50:42 - INFO - __main__ - Cumulative validation average loss is 0.6358237788081169\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Per validation step average loss is 0.031925641000270844\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Cumulative validation average loss is 0.6677494198083878\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Per validation step average loss is 0.006003866903483868\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Cumulative validation average loss is 0.6737532867118716\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Per validation step average loss is 0.276067316532135\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Cumulative validation average loss is 0.9498206032440066\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Per validation step average loss is 0.10506635159254074\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Cumulative validation average loss is 1.0548869548365474\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Per validation step average loss is 0.2526640295982361\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Cumulative validation average loss is 1.3075509844347835\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Average validation loss for Epoch 76 is 0.10896258203623195\n",
      "07/18/2023 19:50:43 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:50:56 - INFO - __main__ - Starting epoch 77\n",
      "07/18/2023 19:50:57 - INFO - __main__ - train loss is 0.018333259969949722\n",
      "Steps:  50%|▍| 7470/15000 [47:35<10:27:16,  5.00s/it, lr=9.62e-6, step_loss=0.0107/18/2023 19:50:57 - INFO - __main__ - train loss is 0.02765338495373726\n",
      "Steps:  50%|▍| 7471/15000 [47:35<7:25:59,  3.55s/it, lr=9.62e-6, step_loss=0.00907/18/2023 19:50:57 - INFO - __main__ - train loss is 0.04868067242205143\n",
      "Steps:  50%|▍| 7472/15000 [47:35<5:19:16,  2.54s/it, lr=9.62e-6, step_loss=0.02107/18/2023 19:50:57 - INFO - __main__ - train loss is 0.06318698823451996\n",
      "Steps:  50%|▍| 7473/15000 [47:35<3:50:39,  1.84s/it, lr=9.62e-6, step_loss=0.01407/18/2023 19:50:58 - INFO - __main__ - train loss is 0.06619663327001035\n",
      "Steps:  50%|▍| 7474/15000 [47:36<2:48:08,  1.34s/it, lr=9.62e-6, step_loss=0.00307/18/2023 19:50:58 - INFO - __main__ - train loss is 0.0914241501595825\n",
      "Steps:  50%|▍| 7475/15000 [47:36<2:04:23,  1.01it/s, lr=9.62e-6, step_loss=0.02507/18/2023 19:50:58 - INFO - __main__ - train loss is 0.3786741921212524\n",
      "Steps:  50%|▍| 7476/15000 [47:36<1:33:49,  1.34it/s, lr=9.62e-6, step_loss=0.28707/18/2023 19:50:58 - INFO - __main__ - train loss is 0.40186558454297483\n",
      "Steps:  50%|▍| 7477/15000 [47:36<1:12:20,  1.73it/s, lr=9.62e-6, step_loss=0.02307/18/2023 19:50:58 - INFO - __main__ - train loss is 0.4034418975934386\n",
      "Steps:  50%|▍| 7478/15000 [47:36<57:19,  2.19it/s, lr=9.62e-6, step_loss=0.0015807/18/2023 19:50:59 - INFO - __main__ - train loss is 0.4659071443602443\n",
      "Steps:  50%|▍| 7479/15000 [47:36<46:48,  2.68it/s, lr=9.62e-6, step_loss=0.0625]07/18/2023 19:50:59 - INFO - __main__ - train loss is 0.5357231898233294\n",
      "Steps:  50%|▍| 7480/15000 [47:37<39:27,  3.18it/s, lr=9.62e-6, step_loss=0.0698]07/18/2023 19:50:59 - INFO - __main__ - train loss is 0.6254132939502597\n",
      "Steps:  50%|▍| 7481/15000 [47:37<34:31,  3.63it/s, lr=9.62e-6, step_loss=0.0897]07/18/2023 19:50:59 - INFO - __main__ - train loss is 0.6304885921999812\n",
      "Steps:  50%|▍| 7482/15000 [47:37<31:16,  4.01it/s, lr=9.62e-6, step_loss=0.0050807/18/2023 19:50:59 - INFO - __main__ - train loss is 0.6385975619778037\n",
      "Steps:  50%|▍| 7483/15000 [47:37<28:59,  4.32it/s, lr=9.62e-6, step_loss=0.0081107/18/2023 19:50:59 - INFO - __main__ - train loss is 0.6888250773772597\n",
      "Steps:  50%|▍| 7484/15000 [47:37<27:18,  4.59it/s, lr=9.62e-6, step_loss=0.0502]07/18/2023 19:51:00 - INFO - __main__ - train loss is 1.0723281567916274\n",
      "Steps:  50%|▉ | 7485/15000 [47:38<26:02,  4.81it/s, lr=9.62e-6, step_loss=0.384]07/18/2023 19:51:00 - INFO - __main__ - train loss is 1.0784890595823526\n",
      "Steps:  50%|▍| 7486/15000 [47:38<24:57,  5.02it/s, lr=9.62e-6, step_loss=0.0061607/18/2023 19:51:00 - INFO - __main__ - train loss is 1.6592974606901407\n",
      "Steps:  50%|▉ | 7487/15000 [47:38<24:11,  5.18it/s, lr=9.62e-6, step_loss=0.581]07/18/2023 19:51:00 - INFO - __main__ - train loss is 1.7266775537282228\n",
      "Steps:  50%|▍| 7488/15000 [47:38<23:52,  5.24it/s, lr=9.62e-6, step_loss=0.0674]07/18/2023 19:51:00 - INFO - __main__ - train loss is 1.7304061227478087\n",
      "Steps:  50%|▍| 7489/15000 [47:38<23:28,  5.33it/s, lr=9.62e-6, step_loss=0.0037307/18/2023 19:51:01 - INFO - __main__ - train loss is 1.9884752803482115\n",
      "Steps:  50%|▉ | 7490/15000 [47:38<23:10,  5.40it/s, lr=9.62e-6, step_loss=0.258]07/18/2023 19:51:01 - INFO - __main__ - train loss is 2.099820422474295\n",
      "Steps:  50%|▉ | 7491/15000 [47:39<22:54,  5.46it/s, lr=9.62e-6, step_loss=0.111]07/18/2023 19:51:01 - INFO - __main__ - train loss is 2.2819650643505156\n",
      "Steps:  50%|▉ | 7492/15000 [47:39<22:43,  5.50it/s, lr=9.62e-6, step_loss=0.182]07/18/2023 19:51:01 - INFO - __main__ - train loss is 2.5879105501808226\n",
      "Steps:  50%|▉ | 7493/15000 [47:39<22:36,  5.53it/s, lr=9.62e-6, step_loss=0.306]07/18/2023 19:51:01 - INFO - __main__ - train loss is 2.9484701924957335\n",
      "Steps:  50%|▉ | 7494/15000 [47:39<22:31,  5.55it/s, lr=9.62e-6, step_loss=0.361]07/18/2023 19:51:01 - INFO - __main__ - train loss is 3.0583387040533125\n",
      "Steps:  50%|█▍ | 7495/15000 [47:39<22:28,  5.57it/s, lr=9.62e-6, step_loss=0.11]07/18/2023 19:51:02 - INFO - __main__ - train loss is 3.060428926255554\n",
      "Steps:  50%|▍| 7496/15000 [47:39<22:26,  5.57it/s, lr=9.62e-6, step_loss=0.0020907/18/2023 19:51:02 - INFO - __main__ - train loss is 3.0754127562977374\n",
      "Steps:  50%|▉ | 7497/15000 [47:40<22:23,  5.58it/s, lr=9.62e-6, step_loss=0.015]07/18/2023 19:51:02 - INFO - __main__ - train loss is 3.0792140138801187\n",
      "Steps:  50%|▍| 7498/15000 [47:40<22:22,  5.59it/s, lr=9.62e-6, step_loss=0.0038]07/18/2023 19:51:02 - INFO - __main__ - train loss is 3.1622938287910074\n",
      "Steps:  50%|▍| 7499/15000 [47:40<22:21,  5.59it/s, lr=9.62e-6, step_loss=0.0831]07/18/2023 19:51:02 - INFO - __main__ - train loss is 3.223933838075027\n",
      "Steps:  50%|▌| 7500/15000 [47:40<22:20,  5.59it/s, lr=9.62e-6, step_loss=0.0831]07/18/2023 19:51:02 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-7500\n",
      "07/18/2023 19:51:02 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:51:02,894] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:51:02,899] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-7500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:51:02,899] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-7500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:51:02,906] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-7500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:51:02,907] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-7500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:51:02,926] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-7500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:51:02,926] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-7500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:51:02,926] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:51:02 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-7500/pytorch_model\n",
      "07/18/2023 19:51:02 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-7500/scheduler.bin\n",
      "07/18/2023 19:51:02 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-7500/random_states_0.pkl\n",
      "07/18/2023 19:51:02 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-7500\n",
      "Steps:  50%|▌| 7500/15000 [47:40<22:20,  5.59it/s, lr=9.62e-6, step_loss=0.0616]07/18/2023 19:51:03 - INFO - __main__ - train loss is 3.227124902885407\n",
      "Steps:  50%|▌| 7501/15000 [47:40<23:46,  5.26it/s, lr=9.62e-6, step_loss=0.0031907/18/2023 19:51:03 - INFO - __main__ - train loss is 3.5292606386356056\n",
      "Steps:  50%|█ | 7502/15000 [47:41<23:19,  5.36it/s, lr=9.62e-6, step_loss=0.302]07/18/2023 19:51:03 - INFO - __main__ - train loss is 3.5625590714626014\n",
      "Steps:  50%|▌| 7503/15000 [47:41<23:01,  5.43it/s, lr=9.62e-6, step_loss=0.0333]07/18/2023 19:51:03 - INFO - __main__ - train loss is 3.6431289496831596\n",
      "Steps:  50%|▌| 7504/15000 [47:41<22:48,  5.48it/s, lr=9.62e-6, step_loss=0.0806]07/18/2023 19:51:03 - INFO - __main__ - train loss is 4.2154553714208305\n",
      "Steps:  50%|█ | 7505/15000 [47:41<22:39,  5.51it/s, lr=9.62e-6, step_loss=0.572]07/18/2023 19:51:03 - INFO - __main__ - train loss is 4.376345861237496\n",
      "Steps:  50%|█ | 7506/15000 [47:41<22:45,  5.49it/s, lr=9.62e-6, step_loss=0.161]07/18/2023 19:51:04 - INFO - __main__ - train loss is 4.463893804233521\n",
      "Steps:  50%|▌| 7507/15000 [47:41<22:43,  5.50it/s, lr=9.62e-6, step_loss=0.0875]07/18/2023 19:51:04 - INFO - __main__ - train loss is 4.53684964356944\n",
      "Steps:  50%|█ | 7508/15000 [47:42<22:35,  5.53it/s, lr=9.62e-6, step_loss=0.073]07/18/2023 19:51:04 - INFO - __main__ - train loss is 4.5393631521146744\n",
      "Steps:  50%|▌| 7509/15000 [47:42<22:29,  5.55it/s, lr=9.62e-6, step_loss=0.0025107/18/2023 19:51:04 - INFO - __main__ - train loss is 4.704189306823537\n",
      "Steps:  50%|█ | 7510/15000 [47:42<22:25,  5.57it/s, lr=9.62e-6, step_loss=0.165]07/18/2023 19:51:04 - INFO - __main__ - train loss is 4.890086478320882\n",
      "Steps:  50%|█ | 7511/15000 [47:42<22:22,  5.58it/s, lr=9.62e-6, step_loss=0.186]07/18/2023 19:51:04 - INFO - __main__ - train loss is 5.081792956916615\n",
      "Steps:  50%|█ | 7512/15000 [47:42<22:20,  5.59it/s, lr=9.62e-6, step_loss=0.192]07/18/2023 19:51:05 - INFO - __main__ - train loss is 5.1099120925646275\n",
      "Steps:  50%|▌| 7513/15000 [47:43<22:19,  5.59it/s, lr=9.62e-6, step_loss=0.0281]07/18/2023 19:51:05 - INFO - __main__ - train loss is 5.125259621767327\n",
      "Steps:  50%|▌| 7514/15000 [47:43<22:18,  5.59it/s, lr=9.62e-6, step_loss=0.0153]07/18/2023 19:51:05 - INFO - __main__ - train loss is 5.319405167130753\n",
      "Steps:  50%|█ | 7515/15000 [47:43<22:18,  5.59it/s, lr=9.62e-6, step_loss=0.194]07/18/2023 19:51:05 - INFO - __main__ - train loss is 5.667544304160401\n",
      "Steps:  50%|█ | 7516/15000 [47:43<22:16,  5.60it/s, lr=9.62e-6, step_loss=0.348]07/18/2023 19:51:05 - INFO - __main__ - train loss is 5.898181735305116\n",
      "Steps:  50%|█ | 7517/15000 [47:43<22:20,  5.58it/s, lr=9.62e-6, step_loss=0.231]07/18/2023 19:51:06 - INFO - __main__ - train loss is 6.050419269828126\n",
      "Steps:  50%|█ | 7518/15000 [47:43<22:26,  5.56it/s, lr=9.62e-6, step_loss=0.152]07/18/2023 19:51:06 - INFO - __main__ - train loss is 6.187225877074525\n",
      "Steps:  50%|█ | 7519/15000 [47:44<22:22,  5.57it/s, lr=9.62e-6, step_loss=0.137]07/18/2023 19:51:06 - INFO - __main__ - train loss is 6.338525621918961\n",
      "Steps:  50%|█ | 7520/15000 [47:44<22:20,  5.58it/s, lr=9.62e-6, step_loss=0.151]07/18/2023 19:51:06 - INFO - __main__ - train loss is 6.668098925380036\n",
      "Steps:  50%|█▌ | 7521/15000 [47:44<22:18,  5.59it/s, lr=9.62e-6, step_loss=0.33]07/18/2023 19:51:06 - INFO - __main__ - train loss is 6.810069768456742\n",
      "Steps:  50%|█ | 7522/15000 [47:44<22:17,  5.59it/s, lr=9.62e-6, step_loss=0.142]07/18/2023 19:51:06 - INFO - __main__ - train loss is 6.817810612497851\n",
      "Steps:  50%|▌| 7523/15000 [47:44<22:16,  5.59it/s, lr=9.62e-6, step_loss=0.0077407/18/2023 19:51:07 - INFO - __main__ - train loss is 6.851329448400065\n",
      "Steps:  50%|▌| 7524/15000 [47:45<22:16,  5.59it/s, lr=9.62e-6, step_loss=0.0335]07/18/2023 19:51:07 - INFO - __main__ - train loss is 6.907849135575816\n",
      "Steps:  50%|▌| 7525/15000 [47:45<22:15,  5.60it/s, lr=9.62e-6, step_loss=0.0565]07/18/2023 19:51:07 - INFO - __main__ - train loss is 6.917143599828705\n",
      "Steps:  50%|▌| 7526/15000 [47:45<22:14,  5.60it/s, lr=9.62e-6, step_loss=0.0092907/18/2023 19:51:07 - INFO - __main__ - train loss is 6.920327901141718\n",
      "Steps:  50%|▌| 7527/15000 [47:45<22:14,  5.60it/s, lr=9.62e-6, step_loss=0.0031807/18/2023 19:51:07 - INFO - __main__ - train loss is 7.221036731498316\n",
      "Steps:  50%|█ | 7528/15000 [47:45<22:14,  5.60it/s, lr=9.62e-6, step_loss=0.301]07/18/2023 19:51:08 - INFO - __main__ - train loss is 7.59319358994253\n",
      "Steps:  50%|█ | 7529/15000 [47:45<22:15,  5.60it/s, lr=9.62e-6, step_loss=0.372]07/18/2023 19:51:08 - INFO - __main__ - train loss is 7.655631407396868\n",
      "Steps:  50%|▌| 7530/15000 [47:46<22:15,  5.59it/s, lr=9.62e-6, step_loss=0.0624]07/18/2023 19:51:08 - INFO - __main__ - train loss is 7.7153697677422315\n",
      "Steps:  50%|▌| 7531/15000 [47:46<22:14,  5.59it/s, lr=9.62e-6, step_loss=0.0597]07/18/2023 19:51:08 - INFO - __main__ - train loss is 7.719627434620634\n",
      "Steps:  50%|▌| 7532/15000 [47:46<22:14,  5.60it/s, lr=9.62e-6, step_loss=0.0042607/18/2023 19:51:08 - INFO - __main__ - train loss is 7.744941832730547\n",
      "Steps:  50%|▌| 7533/15000 [47:46<22:13,  5.60it/s, lr=9.62e-6, step_loss=0.0253]07/18/2023 19:51:08 - INFO - __main__ - train loss is 7.824571514734998\n",
      "Steps:  50%|▌| 7534/15000 [47:46<22:13,  5.60it/s, lr=9.62e-6, step_loss=0.0796]07/18/2023 19:51:09 - INFO - __main__ - train loss is 7.892274441430345\n",
      "Steps:  50%|▌| 7535/15000 [47:46<22:13,  5.60it/s, lr=9.62e-6, step_loss=0.0677]07/18/2023 19:51:09 - INFO - __main__ - train loss is 7.898550364887342\n",
      "Steps:  50%|▌| 7536/15000 [47:47<22:14,  5.59it/s, lr=9.62e-6, step_loss=0.0062807/18/2023 19:51:09 - INFO - __main__ - train loss is 8.136412922060117\n",
      "Steps:  50%|█ | 7537/15000 [47:47<22:13,  5.60it/s, lr=9.62e-6, step_loss=0.238]07/18/2023 19:51:09 - INFO - __main__ - train loss is 8.375714260851964\n",
      "Steps:  50%|█ | 7538/15000 [47:47<22:13,  5.60it/s, lr=9.62e-6, step_loss=0.239]07/18/2023 19:51:09 - INFO - __main__ - train loss is 8.547842267667875\n",
      "Steps:  50%|█ | 7539/15000 [47:47<22:12,  5.60it/s, lr=9.62e-6, step_loss=0.172]07/18/2023 19:51:10 - INFO - __main__ - train loss is 8.864471558248624\n",
      "Steps:  50%|█ | 7540/15000 [47:47<22:12,  5.60it/s, lr=9.62e-6, step_loss=0.317]07/18/2023 19:51:10 - INFO - __main__ - train loss is 8.876602882286534\n",
      "Steps:  50%|▌| 7541/15000 [47:48<22:11,  5.60it/s, lr=9.62e-6, step_loss=0.0121]07/18/2023 19:51:10 - INFO - __main__ - train loss is 9.103675225516781\n",
      "Steps:  50%|█ | 7542/15000 [47:48<22:11,  5.60it/s, lr=9.62e-6, step_loss=0.227]07/18/2023 19:51:10 - INFO - __main__ - train loss is 9.118087634211406\n",
      "Steps:  50%|▌| 7543/15000 [47:48<22:11,  5.60it/s, lr=9.62e-6, step_loss=0.0144]07/18/2023 19:51:10 - INFO - __main__ - train loss is 9.50230024731718\n",
      "Steps:  50%|█ | 7544/15000 [47:48<22:10,  5.60it/s, lr=9.62e-6, step_loss=0.384]07/18/2023 19:51:10 - INFO - __main__ - train loss is 9.505653731059283\n",
      "Steps:  50%|▌| 7545/15000 [47:48<22:10,  5.60it/s, lr=9.62e-6, step_loss=0.0033507/18/2023 19:51:11 - INFO - __main__ - train loss is 9.546423360239714\n",
      "Steps:  50%|▌| 7546/15000 [47:48<22:10,  5.60it/s, lr=9.62e-6, step_loss=0.0408]07/18/2023 19:51:11 - INFO - __main__ - train loss is 9.64839532924816\n",
      "Steps:  50%|█ | 7547/15000 [47:49<22:12,  5.59it/s, lr=9.62e-6, step_loss=0.102]07/18/2023 19:51:11 - INFO - __main__ - train loss is 10.602020412217826\n",
      "Steps:  50%|█ | 7548/15000 [47:49<22:11,  5.60it/s, lr=9.62e-6, step_loss=0.954]07/18/2023 19:51:11 - INFO - __main__ - train loss is 10.855352162849158\n",
      "Steps:  50%|█ | 7549/15000 [47:49<22:10,  5.60it/s, lr=9.62e-6, step_loss=0.253]07/18/2023 19:51:11 - INFO - __main__ - train loss is 10.85686042997986\n",
      "Steps:  50%|▌| 7550/15000 [47:49<22:09,  5.60it/s, lr=9.62e-6, step_loss=0.0015107/18/2023 19:51:11 - INFO - __main__ - train loss is 10.866772937588394\n",
      "Steps:  50%|▌| 7551/15000 [47:49<22:11,  5.59it/s, lr=9.62e-6, step_loss=0.0099107/18/2023 19:51:12 - INFO - __main__ - train loss is 11.074389102868736\n",
      "Steps:  50%|█ | 7552/15000 [47:50<22:10,  5.60it/s, lr=9.62e-6, step_loss=0.208]07/18/2023 19:51:12 - INFO - __main__ - train loss is 11.279453906230628\n",
      "Steps:  50%|█ | 7553/15000 [47:50<22:09,  5.60it/s, lr=9.62e-6, step_loss=0.205]07/18/2023 19:51:12 - INFO - __main__ - train loss is 11.293959482572973\n",
      "Steps:  50%|▌| 7554/15000 [47:50<22:07,  5.61it/s, lr=9.62e-6, step_loss=0.0145]07/18/2023 19:51:12 - INFO - __main__ - train loss is 11.538374959491193\n",
      "Steps:  50%|█ | 7555/15000 [47:50<22:06,  5.61it/s, lr=9.62e-6, step_loss=0.244]07/18/2023 19:51:12 - INFO - __main__ - train loss is 11.764921247027814\n",
      "Steps:  50%|█ | 7556/15000 [47:50<22:06,  5.61it/s, lr=9.62e-6, step_loss=0.227]07/18/2023 19:51:13 - INFO - __main__ - train loss is 11.787540423683822\n",
      "Steps:  50%|▌| 7557/15000 [47:50<22:05,  5.61it/s, lr=9.62e-6, step_loss=0.0226]07/18/2023 19:51:13 - INFO - __main__ - train loss is 11.866366948001087\n",
      "Steps:  50%|▌| 7558/15000 [47:51<22:06,  5.61it/s, lr=9.62e-6, step_loss=0.0788]07/18/2023 19:51:13 - INFO - __main__ - train loss is 12.125337745063007\n",
      "Steps:  50%|█ | 7559/15000 [47:51<22:06,  5.61it/s, lr=9.62e-6, step_loss=0.259]07/18/2023 19:51:13 - INFO - __main__ - train loss is 12.944157208316028\n",
      "Steps:  50%|█ | 7560/15000 [47:51<22:06,  5.61it/s, lr=9.61e-6, step_loss=0.819]07/18/2023 19:51:13 - INFO - __main__ - train loss is 13.015962260775268\n",
      "Steps:  50%|▌| 7561/15000 [47:51<22:05,  5.61it/s, lr=9.61e-6, step_loss=0.0718]07/18/2023 19:51:13 - INFO - __main__ - train loss is 13.08867162745446\n",
      "Steps:  50%|▌| 7562/15000 [47:51<22:05,  5.61it/s, lr=9.61e-6, step_loss=0.0727]07/18/2023 19:51:14 - INFO - __main__ - train loss is 13.107970046810806\n",
      "Steps:  50%|▌| 7563/15000 [47:51<22:05,  5.61it/s, lr=9.61e-6, step_loss=0.0193]07/18/2023 19:51:14 - INFO - __main__ - train loss is 13.314645948819816\n",
      "Steps:  50%|█ | 7564/15000 [47:52<22:04,  5.62it/s, lr=9.61e-6, step_loss=0.207]07/18/2023 19:51:14 - INFO - __main__ - train loss is 13.354008345864713\n",
      "Steps:  50%|▌| 7565/15000 [47:52<22:04,  5.62it/s, lr=9.61e-6, step_loss=0.0394]07/18/2023 19:51:14 - INFO - __main__ - train loss is 13.368412973359227\n",
      "Steps:  50%|▌| 7566/15000 [47:52<29:23,  4.21it/s, lr=9.61e-6, step_loss=0.0144]07/18/2023 19:51:15 - INFO - __main__ - Per validation step average loss is 0.05747973546385765\n",
      "07/18/2023 19:51:15 - INFO - __main__ - Cumulative validation average loss is 0.05747973546385765\n",
      "07/18/2023 19:51:15 - INFO - __main__ - Per validation step average loss is 0.2602452039718628\n",
      "07/18/2023 19:51:15 - INFO - __main__ - Cumulative validation average loss is 0.31772493943572044\n",
      "07/18/2023 19:51:15 - INFO - __main__ - Per validation step average loss is 0.018098417669534683\n",
      "07/18/2023 19:51:15 - INFO - __main__ - Cumulative validation average loss is 0.3358233571052551\n",
      "07/18/2023 19:51:15 - INFO - __main__ - Per validation step average loss is 0.0642910823225975\n",
      "07/18/2023 19:51:15 - INFO - __main__ - Cumulative validation average loss is 0.40011443942785263\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Per validation step average loss is 0.007803704123944044\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Cumulative validation average loss is 0.4079181435517967\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Per validation step average loss is 0.029713548719882965\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Cumulative validation average loss is 0.43763169227167964\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Per validation step average loss is 0.5543071031570435\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Cumulative validation average loss is 0.9919387954287231\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Per validation step average loss is 0.06940645724534988\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Cumulative validation average loss is 1.061345252674073\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Per validation step average loss is 0.27362683415412903\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Cumulative validation average loss is 1.334972086828202\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Per validation step average loss is 0.012618417851626873\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Cumulative validation average loss is 1.3475905046798289\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Per validation step average loss is 0.052048489451408386\n",
      "07/18/2023 19:51:16 - INFO - __main__ - Cumulative validation average loss is 1.3996389941312373\n",
      "07/18/2023 19:51:17 - INFO - __main__ - Per validation step average loss is 0.03826889395713806\n",
      "07/18/2023 19:51:17 - INFO - __main__ - Cumulative validation average loss is 1.4379078880883753\n",
      "07/18/2023 19:51:17 - INFO - __main__ - Average validation loss for Epoch 77 is 0.11982565734069794\n",
      "07/18/2023 19:51:17 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:51:30 - INFO - __main__ - Starting epoch 78\n",
      "07/18/2023 19:51:30 - INFO - __main__ - train loss is 0.08370600640773773\n",
      "Steps:  50%|▌| 7567/15000 [48:08<10:05:26,  4.89s/it, lr=9.61e-6, step_loss=0.0807/18/2023 19:51:30 - INFO - __main__ - train loss is 0.18923580646514893\n",
      "Steps:  50%|▌| 7568/15000 [48:08<7:10:48,  3.48s/it, lr=9.61e-6, step_loss=0.10607/18/2023 19:51:30 - INFO - __main__ - train loss is 0.2078564576804638\n",
      "Steps:  50%|▌| 7569/15000 [48:08<5:08:09,  2.49s/it, lr=9.61e-6, step_loss=0.01807/18/2023 19:51:31 - INFO - __main__ - train loss is 0.2204769216477871\n",
      "Steps:  50%|▌| 7570/15000 [48:09<3:42:26,  1.80s/it, lr=9.61e-6, step_loss=0.01207/18/2023 19:51:31 - INFO - __main__ - train loss is 0.649724718183279\n",
      "Steps:  50%|▌| 7571/15000 [48:09<2:42:18,  1.31s/it, lr=9.61e-6, step_loss=0.42907/18/2023 19:51:31 - INFO - __main__ - train loss is 0.8578915260732174\n",
      "Steps:  50%|▌| 7572/15000 [48:09<2:00:28,  1.03it/s, lr=9.61e-6, step_loss=0.20807/18/2023 19:51:31 - INFO - __main__ - train loss is 0.862279218621552\n",
      "Steps:  50%|▌| 7573/15000 [48:09<1:31:00,  1.36it/s, lr=9.61e-6, step_loss=0.00407/18/2023 19:51:31 - INFO - __main__ - train loss is 1.0800404818728566\n",
      "Steps:  50%|▌| 7574/15000 [48:09<1:10:20,  1.76it/s, lr=9.61e-6, step_loss=0.21807/18/2023 19:51:32 - INFO - __main__ - train loss is 1.6198176415637136\n",
      "Steps:  50%|█▌ | 7575/15000 [48:09<55:50,  2.22it/s, lr=9.61e-6, step_loss=0.54]07/18/2023 19:51:32 - INFO - __main__ - train loss is 1.634868437424302\n",
      "Steps:  51%|▌| 7576/15000 [48:10<45:40,  2.71it/s, lr=9.61e-6, step_loss=0.0151]07/18/2023 19:51:32 - INFO - __main__ - train loss is 1.8800758067518473\n",
      "Steps:  51%|█ | 7577/15000 [48:10<38:35,  3.21it/s, lr=9.61e-6, step_loss=0.245]07/18/2023 19:51:32 - INFO - __main__ - train loss is 1.8906991118565202\n",
      "Steps:  51%|▌| 7578/15000 [48:10<33:46,  3.66it/s, lr=9.61e-6, step_loss=0.0106]07/18/2023 19:51:32 - INFO - __main__ - train loss is 2.460956477560103\n",
      "Steps:  51%|█▌ | 7579/15000 [48:10<30:21,  4.07it/s, lr=9.61e-6, step_loss=0.57]07/18/2023 19:51:32 - INFO - __main__ - train loss is 2.463401655200869\n",
      "Steps:  51%|▌| 7580/15000 [48:10<27:50,  4.44it/s, lr=9.61e-6, step_loss=0.0024507/18/2023 19:51:33 - INFO - __main__ - train loss is 2.47643317328766\n",
      "Steps:  51%|█ | 7581/15000 [48:10<26:05,  4.74it/s, lr=9.61e-6, step_loss=0.013]07/18/2023 19:51:33 - INFO - __main__ - train loss is 2.5247477968223393\n",
      "Steps:  51%|▌| 7582/15000 [48:11<24:51,  4.97it/s, lr=9.61e-6, step_loss=0.0483]07/18/2023 19:51:33 - INFO - __main__ - train loss is 2.528454827843234\n",
      "Steps:  51%|▌| 7583/15000 [48:11<23:58,  5.15it/s, lr=9.61e-6, step_loss=0.0037107/18/2023 19:51:33 - INFO - __main__ - train loss is 2.5805331121664494\n",
      "Steps:  51%|▌| 7584/15000 [48:11<23:23,  5.28it/s, lr=9.61e-6, step_loss=0.0521]07/18/2023 19:51:33 - INFO - __main__ - train loss is 2.6092374201398343\n",
      "Steps:  51%|▌| 7585/15000 [48:11<22:58,  5.38it/s, lr=9.61e-6, step_loss=0.0287]07/18/2023 19:51:33 - INFO - __main__ - train loss is 2.649584936676547\n",
      "Steps:  51%|▌| 7586/15000 [48:11<22:41,  5.44it/s, lr=9.61e-6, step_loss=0.0403]07/18/2023 19:51:34 - INFO - __main__ - train loss is 2.734139936743304\n",
      "Steps:  51%|▌| 7587/15000 [48:12<22:30,  5.49it/s, lr=9.61e-6, step_loss=0.0846]07/18/2023 19:51:34 - INFO - __main__ - train loss is 2.85945754009299\n",
      "Steps:  51%|█ | 7588/15000 [48:12<22:22,  5.52it/s, lr=9.61e-6, step_loss=0.125]07/18/2023 19:51:34 - INFO - __main__ - train loss is 2.8689294781070203\n",
      "Steps:  51%|▌| 7589/15000 [48:12<22:16,  5.55it/s, lr=9.61e-6, step_loss=0.0094707/18/2023 19:51:34 - INFO - __main__ - train loss is 2.899166154442355\n",
      "Steps:  51%|▌| 7590/15000 [48:12<22:11,  5.57it/s, lr=9.61e-6, step_loss=0.0302]07/18/2023 19:51:34 - INFO - __main__ - train loss is 2.931689901975915\n",
      "Steps:  51%|▌| 7591/15000 [48:12<22:07,  5.58it/s, lr=9.61e-6, step_loss=0.0325]07/18/2023 19:51:35 - INFO - __main__ - train loss is 2.9337066032458097\n",
      "Steps:  51%|▌| 7592/15000 [48:12<22:06,  5.58it/s, lr=9.61e-6, step_loss=0.0020207/18/2023 19:51:35 - INFO - __main__ - train loss is 3.0125362046528608\n",
      "Steps:  51%|▌| 7593/15000 [48:13<22:05,  5.59it/s, lr=9.61e-6, step_loss=0.0788]07/18/2023 19:51:35 - INFO - __main__ - train loss is 3.390105939703062\n",
      "Steps:  51%|█ | 7594/15000 [48:13<22:04,  5.59it/s, lr=9.61e-6, step_loss=0.378]07/18/2023 19:51:35 - INFO - __main__ - train loss is 3.4731068529654294\n",
      "Steps:  51%|█ | 7595/15000 [48:13<22:02,  5.60it/s, lr=9.61e-6, step_loss=0.083]07/18/2023 19:51:35 - INFO - __main__ - train loss is 3.476631391327828\n",
      "Steps:  51%|▌| 7596/15000 [48:13<22:01,  5.60it/s, lr=9.61e-6, step_loss=0.0035207/18/2023 19:51:35 - INFO - __main__ - train loss is 3.546958628576249\n",
      "Steps:  51%|▌| 7597/15000 [48:13<22:01,  5.60it/s, lr=9.61e-6, step_loss=0.0703]07/18/2023 19:51:36 - INFO - __main__ - train loss is 3.9657114180736244\n",
      "Steps:  51%|█ | 7598/15000 [48:14<22:00,  5.61it/s, lr=9.61e-6, step_loss=0.419]07/18/2023 19:51:36 - INFO - __main__ - train loss is 3.981505251955241\n",
      "Steps:  51%|▌| 7599/15000 [48:14<21:59,  5.61it/s, lr=9.61e-6, step_loss=0.0158]07/18/2023 19:51:36 - INFO - __main__ - train loss is 3.9831367949955165\n",
      "Steps:  51%|▌| 7600/15000 [48:14<21:58,  5.61it/s, lr=9.61e-6, step_loss=0.0016307/18/2023 19:51:36 - INFO - __main__ - train loss is 4.169900260400027\n",
      "Steps:  51%|█ | 7601/15000 [48:14<21:59,  5.61it/s, lr=9.61e-6, step_loss=0.187]07/18/2023 19:51:36 - INFO - __main__ - train loss is 4.191512938123196\n",
      "Steps:  51%|▌| 7602/15000 [48:14<21:59,  5.61it/s, lr=9.61e-6, step_loss=0.0216]07/18/2023 19:51:37 - INFO - __main__ - train loss is 4.458359505515546\n",
      "Steps:  51%|█ | 7603/15000 [48:14<21:58,  5.61it/s, lr=9.61e-6, step_loss=0.267]07/18/2023 19:51:37 - INFO - __main__ - train loss is 4.481594632845372\n",
      "Steps:  51%|▌| 7604/15000 [48:15<21:59,  5.60it/s, lr=9.61e-6, step_loss=0.0232]07/18/2023 19:51:37 - INFO - __main__ - train loss is 4.616384859662503\n",
      "Steps:  51%|█ | 7605/15000 [48:15<21:59,  5.60it/s, lr=9.61e-6, step_loss=0.135]07/18/2023 19:51:37 - INFO - __main__ - train loss is 4.623633743729442\n",
      "Steps:  51%|▌| 7606/15000 [48:15<22:00,  5.60it/s, lr=9.61e-6, step_loss=0.0072507/18/2023 19:51:37 - INFO - __main__ - train loss is 4.634766583796591\n",
      "Steps:  51%|▌| 7607/15000 [48:15<21:59,  5.60it/s, lr=9.61e-6, step_loss=0.0111]07/18/2023 19:51:37 - INFO - __main__ - train loss is 5.287116473075002\n",
      "Steps:  51%|█ | 7608/15000 [48:15<22:08,  5.57it/s, lr=9.61e-6, step_loss=0.652]07/18/2023 19:51:38 - INFO - __main__ - train loss is 5.332228404935449\n",
      "Steps:  51%|▌| 7609/15000 [48:15<22:06,  5.57it/s, lr=9.61e-6, step_loss=0.0451]07/18/2023 19:51:38 - INFO - __main__ - train loss is 5.546060604508966\n",
      "Steps:  51%|█ | 7610/15000 [48:16<22:03,  5.58it/s, lr=9.61e-6, step_loss=0.214]07/18/2023 19:51:38 - INFO - __main__ - train loss is 5.6814597374759614\n",
      "Steps:  51%|█ | 7611/15000 [48:16<22:13,  5.54it/s, lr=9.61e-6, step_loss=0.135]07/18/2023 19:51:38 - INFO - __main__ - train loss is 5.691010268870741\n",
      "Steps:  51%|▌| 7612/15000 [48:16<22:20,  5.51it/s, lr=9.61e-6, step_loss=0.0095507/18/2023 19:51:38 - INFO - __main__ - train loss is 5.99882552260533\n",
      "Steps:  51%|█ | 7613/15000 [48:16<22:13,  5.54it/s, lr=9.61e-6, step_loss=0.308]07/18/2023 19:51:38 - INFO - __main__ - train loss is 6.349875720683485\n",
      "Steps:  51%|█ | 7614/15000 [48:16<22:09,  5.56it/s, lr=9.61e-6, step_loss=0.351]07/18/2023 19:51:39 - INFO - __main__ - train loss is 6.364847146440297\n",
      "Steps:  51%|█ | 7615/15000 [48:17<22:18,  5.52it/s, lr=9.61e-6, step_loss=0.015]07/18/2023 19:51:39 - INFO - __main__ - train loss is 6.367227370617911\n",
      "Steps:  51%|▌| 7616/15000 [48:17<22:16,  5.53it/s, lr=9.61e-6, step_loss=0.0023807/18/2023 19:51:39 - INFO - __main__ - train loss is 6.463555390713736\n",
      "Steps:  51%|▌| 7617/15000 [48:17<22:11,  5.55it/s, lr=9.61e-6, step_loss=0.0963]07/18/2023 19:51:39 - INFO - __main__ - train loss is 6.537189538357779\n",
      "Steps:  51%|▌| 7618/15000 [48:17<22:07,  5.56it/s, lr=9.61e-6, step_loss=0.0736]07/18/2023 19:51:39 - INFO - __main__ - train loss is 6.612058396218345\n",
      "Steps:  51%|▌| 7619/15000 [48:17<22:04,  5.57it/s, lr=9.61e-6, step_loss=0.0749]07/18/2023 19:51:40 - INFO - __main__ - train loss is 6.83469473826699\n",
      "Steps:  51%|█ | 7620/15000 [48:17<22:02,  5.58it/s, lr=9.61e-6, step_loss=0.223]07/18/2023 19:51:40 - INFO - __main__ - train loss is 6.856900482205674\n",
      "Steps:  51%|▌| 7621/15000 [48:18<22:01,  5.58it/s, lr=9.61e-6, step_loss=0.0222]07/18/2023 19:51:40 - INFO - __main__ - train loss is 6.948969914345071\n",
      "Steps:  51%|▌| 7622/15000 [48:18<22:00,  5.59it/s, lr=9.61e-6, step_loss=0.0921]07/18/2023 19:51:40 - INFO - __main__ - train loss is 6.98841384681873\n",
      "Steps:  51%|▌| 7623/15000 [48:18<21:59,  5.59it/s, lr=9.61e-6, step_loss=0.0394]07/18/2023 19:51:40 - INFO - __main__ - train loss is 6.9955795460846275\n",
      "Steps:  51%|▌| 7624/15000 [48:18<21:58,  5.60it/s, lr=9.61e-6, step_loss=0.0071707/18/2023 19:51:40 - INFO - __main__ - train loss is 7.071893920889124\n",
      "Steps:  51%|▌| 7625/15000 [48:18<21:57,  5.60it/s, lr=9.61e-6, step_loss=0.0763]07/18/2023 19:51:41 - INFO - __main__ - train loss is 7.07698141480796\n",
      "Steps:  51%|▌| 7626/15000 [48:19<21:56,  5.60it/s, lr=9.61e-6, step_loss=0.0050907/18/2023 19:51:41 - INFO - __main__ - train loss is 7.352302004350349\n",
      "Steps:  51%|█ | 7627/15000 [48:19<22:08,  5.55it/s, lr=9.61e-6, step_loss=0.275]07/18/2023 19:51:41 - INFO - __main__ - train loss is 7.489542801631615\n",
      "Steps:  51%|█ | 7628/15000 [48:19<22:18,  5.51it/s, lr=9.61e-6, step_loss=0.137]07/18/2023 19:51:41 - INFO - __main__ - train loss is 7.6210543408524245\n",
      "Steps:  51%|█ | 7629/15000 [48:19<22:12,  5.53it/s, lr=9.61e-6, step_loss=0.132]07/18/2023 19:51:41 - INFO - __main__ - train loss is 7.739874613238499\n",
      "Steps:  51%|█ | 7630/15000 [48:19<22:08,  5.55it/s, lr=9.61e-6, step_loss=0.119]07/18/2023 19:51:42 - INFO - __main__ - train loss is 7.7509174204897135\n",
      "Steps:  51%|█ | 7631/15000 [48:19<22:12,  5.53it/s, lr=9.61e-6, step_loss=0.011]07/18/2023 19:51:42 - INFO - __main__ - train loss is 7.76552250678651\n",
      "Steps:  51%|▌| 7632/15000 [48:20<22:19,  5.50it/s, lr=9.61e-6, step_loss=0.0146]07/18/2023 19:51:42 - INFO - __main__ - train loss is 7.813106805784628\n",
      "Steps:  51%|▌| 7633/15000 [48:20<22:21,  5.49it/s, lr=9.61e-6, step_loss=0.0476]07/18/2023 19:51:42 - INFO - __main__ - train loss is 8.096435935003683\n",
      "Steps:  51%|█ | 7634/15000 [48:20<22:25,  5.47it/s, lr=9.61e-6, step_loss=0.283]07/18/2023 19:51:42 - INFO - __main__ - train loss is 8.588016361696646\n",
      "Steps:  51%|█ | 7635/15000 [48:20<22:24,  5.48it/s, lr=9.61e-6, step_loss=0.492]07/18/2023 19:51:42 - INFO - __main__ - train loss is 8.703526586992666\n",
      "Steps:  51%|█ | 7636/15000 [48:20<22:22,  5.49it/s, lr=9.61e-6, step_loss=0.116]07/18/2023 19:51:43 - INFO - __main__ - train loss is 8.70794890425168\n",
      "Steps:  51%|▌| 7637/15000 [48:21<22:21,  5.49it/s, lr=9.61e-6, step_loss=0.0044207/18/2023 19:51:43 - INFO - __main__ - train loss is 9.11542422673665\n",
      "Steps:  51%|█ | 7638/15000 [48:21<22:21,  5.49it/s, lr=9.61e-6, step_loss=0.407]07/18/2023 19:51:43 - INFO - __main__ - train loss is 9.505541275953874\n",
      "Steps:  51%|█▌ | 7639/15000 [48:21<22:22,  5.48it/s, lr=9.61e-6, step_loss=0.39]07/18/2023 19:51:43 - INFO - __main__ - train loss is 9.50978846498765\n",
      "Steps:  51%|▌| 7640/15000 [48:21<22:22,  5.48it/s, lr=9.61e-6, step_loss=0.0042507/18/2023 19:51:43 - INFO - __main__ - train loss is 9.97155148931779\n",
      "Steps:  51%|█ | 7641/15000 [48:21<22:46,  5.39it/s, lr=9.61e-6, step_loss=0.462]07/18/2023 19:51:44 - INFO - __main__ - train loss is 10.246149491751567\n",
      "Steps:  51%|█ | 7642/15000 [48:21<23:04,  5.32it/s, lr=9.61e-6, step_loss=0.275]07/18/2023 19:51:44 - INFO - __main__ - train loss is 10.457553681218997\n",
      "Steps:  51%|█ | 7643/15000 [48:22<23:19,  5.26it/s, lr=9.61e-6, step_loss=0.211]07/18/2023 19:51:44 - INFO - __main__ - train loss is 10.467787992442027\n",
      "Steps:  51%|▌| 7644/15000 [48:22<23:37,  5.19it/s, lr=9.61e-6, step_loss=0.0102]07/18/2023 19:51:44 - INFO - __main__ - train loss is 10.473237564554438\n",
      "Steps:  51%|▌| 7645/15000 [48:22<23:48,  5.15it/s, lr=9.61e-6, step_loss=0.0054507/18/2023 19:51:44 - INFO - __main__ - train loss is 10.485468670492992\n",
      "Steps:  51%|▌| 7646/15000 [48:22<23:54,  5.13it/s, lr=9.61e-6, step_loss=0.0122]07/18/2023 19:51:45 - INFO - __main__ - train loss is 10.59414067841135\n",
      "Steps:  51%|█ | 7647/15000 [48:22<23:49,  5.15it/s, lr=9.61e-6, step_loss=0.109]07/18/2023 19:51:45 - INFO - __main__ - train loss is 10.603544015204534\n",
      "Steps:  51%|▌| 7648/15000 [48:23<23:46,  5.15it/s, lr=9.61e-6, step_loss=0.0094]07/18/2023 19:51:45 - INFO - __main__ - train loss is 10.607017568079755\n",
      "Steps:  51%|▌| 7649/15000 [48:23<23:23,  5.24it/s, lr=9.61e-6, step_loss=0.0034707/18/2023 19:51:45 - INFO - __main__ - train loss is 10.617866388289258\n",
      "Steps:  51%|▌| 7650/15000 [48:23<23:05,  5.30it/s, lr=9.61e-6, step_loss=0.0108]07/18/2023 19:51:45 - INFO - __main__ - train loss is 10.652476544259116\n",
      "Steps:  51%|▌| 7651/15000 [48:23<22:51,  5.36it/s, lr=9.61e-6, step_loss=0.0346]07/18/2023 19:51:45 - INFO - __main__ - train loss is 10.664372383384034\n",
      "Steps:  51%|▌| 7652/15000 [48:23<22:42,  5.39it/s, lr=9.61e-6, step_loss=0.0119]07/18/2023 19:51:46 - INFO - __main__ - train loss is 10.979466615943238\n",
      "Steps:  51%|█ | 7653/15000 [48:24<22:40,  5.40it/s, lr=9.61e-6, step_loss=0.315]07/18/2023 19:51:46 - INFO - __main__ - train loss is 11.00765620614402\n",
      "Steps:  51%|▌| 7654/15000 [48:24<22:49,  5.36it/s, lr=9.61e-6, step_loss=0.0282]07/18/2023 19:51:46 - INFO - __main__ - train loss is 11.010662851156667\n",
      "Steps:  51%|▌| 7655/15000 [48:24<23:12,  5.27it/s, lr=9.61e-6, step_loss=0.0030107/18/2023 19:51:46 - INFO - __main__ - train loss is 11.01947959070094\n",
      "Steps:  51%|▌| 7656/15000 [48:24<23:25,  5.22it/s, lr=9.61e-6, step_loss=0.0088207/18/2023 19:51:46 - INFO - __main__ - train loss is 11.021461316850036\n",
      "Steps:  51%|▌| 7657/15000 [48:24<23:20,  5.24it/s, lr=9.61e-6, step_loss=0.0019807/18/2023 19:51:47 - INFO - __main__ - train loss is 11.442444392945617\n",
      "Steps:  51%|█ | 7658/15000 [48:25<23:17,  5.26it/s, lr=9.61e-6, step_loss=0.421]07/18/2023 19:51:47 - INFO - __main__ - train loss is 11.483359621372074\n",
      "Steps:  51%|█ | 7659/15000 [48:25<23:39,  5.17it/s, lr=9.6e-6, step_loss=0.0409]07/18/2023 19:51:47 - INFO - __main__ - train loss is 11.489732883870602\n",
      "Steps:  51%|▌| 7660/15000 [48:25<23:47,  5.14it/s, lr=9.6e-6, step_loss=0.00637]07/18/2023 19:51:47 - INFO - __main__ - train loss is 11.758990906178951\n",
      "Steps:  51%|█▌ | 7661/15000 [48:25<23:20,  5.24it/s, lr=9.6e-6, step_loss=0.269]07/18/2023 19:51:47 - INFO - __main__ - train loss is 11.760687930043787\n",
      "Steps:  51%|█ | 7662/15000 [48:25<23:17,  5.25it/s, lr=9.6e-6, step_loss=0.0017]07/18/2023 19:51:48 - INFO - __main__ - train loss is 11.786260155495256\n",
      "Steps:  51%|█ | 7663/15000 [48:26<34:26,  3.55it/s, lr=9.6e-6, step_loss=0.0256]07/18/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.0699428915977478\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 0.0699428915977478\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.12621909379959106\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 0.19616198539733887\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.2975741922855377\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 0.4937361776828766\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.505457878112793\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 0.9991940557956696\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Per validation step average loss is 0.004835096187889576\n",
      "07/18/2023 19:51:49 - INFO - __main__ - Cumulative validation average loss is 1.0040291519835591\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.271895170211792\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 1.2759243221953511\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.030087940394878387\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 1.3060122625902295\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.01649314910173416\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 1.3225054116919637\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.04699082672595978\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 1.3694962384179235\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.17937728762626648\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 1.54887352604419\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Per validation step average loss is 0.15253467857837677\n",
      "07/18/2023 19:51:50 - INFO - __main__ - Cumulative validation average loss is 1.7014082046225667\n",
      "07/18/2023 19:51:51 - INFO - __main__ - Per validation step average loss is 0.002674889750778675\n",
      "07/18/2023 19:51:51 - INFO - __main__ - Cumulative validation average loss is 1.7040830943733454\n",
      "07/18/2023 19:51:51 - INFO - __main__ - Average validation loss for Epoch 78 is 0.1420069245311121\n",
      "07/18/2023 19:51:51 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:52:03 - INFO - __main__ - Starting epoch 79\n",
      "07/18/2023 19:52:04 - INFO - __main__ - train loss is 0.0033469274640083313\n",
      "Steps:  51%|▌| 7664/15000 [48:42<10:11:36,  5.00s/it, lr=9.6e-6, step_loss=0.00307/18/2023 19:52:04 - INFO - __main__ - train loss is 0.0875888541340828\n",
      "Steps:  51%|▌| 7665/15000 [48:42<7:15:06,  3.56s/it, lr=9.6e-6, step_loss=0.084207/18/2023 19:52:04 - INFO - __main__ - train loss is 0.1371593400835991\n",
      "Steps:  51%|▌| 7666/15000 [48:42<5:11:18,  2.55s/it, lr=9.6e-6, step_loss=0.049607/18/2023 19:52:04 - INFO - __main__ - train loss is 0.2960083410143852\n",
      "Steps:  51%|▌| 7667/15000 [48:42<3:44:25,  1.84s/it, lr=9.6e-6, step_loss=0.159]07/18/2023 19:52:05 - INFO - __main__ - train loss is 0.30213877744972706\n",
      "Steps:  51%|▌| 7668/15000 [48:43<2:43:44,  1.34s/it, lr=9.6e-6, step_loss=0.006107/18/2023 19:52:05 - INFO - __main__ - train loss is 0.3052472728304565\n",
      "Steps:  51%|▌| 7669/15000 [48:43<2:01:12,  1.01it/s, lr=9.6e-6, step_loss=0.003107/18/2023 19:52:05 - INFO - __main__ - train loss is 0.31159153999760747\n",
      "Steps:  51%|▌| 7670/15000 [48:43<1:31:23,  1.34it/s, lr=9.6e-6, step_loss=0.006307/18/2023 19:52:05 - INFO - __main__ - train loss is 0.4736792934127152\n",
      "Steps:  51%|▌| 7671/15000 [48:43<1:10:29,  1.73it/s, lr=9.6e-6, step_loss=0.162]07/18/2023 19:52:05 - INFO - __main__ - train loss is 1.2603520643897355\n",
      "Steps:  51%|█▌ | 7672/15000 [48:43<55:54,  2.18it/s, lr=9.6e-6, step_loss=0.787]07/18/2023 19:52:06 - INFO - __main__ - train loss is 1.4741605413146317\n",
      "Steps:  51%|█▌ | 7673/15000 [48:43<45:40,  2.67it/s, lr=9.6e-6, step_loss=0.214]07/18/2023 19:52:06 - INFO - __main__ - train loss is 1.7136327070184052\n",
      "Steps:  51%|█▌ | 7674/15000 [48:44<38:30,  3.17it/s, lr=9.6e-6, step_loss=0.239]07/18/2023 19:52:06 - INFO - __main__ - train loss is 2.0527738970704377\n",
      "Steps:  51%|█▌ | 7675/15000 [48:44<33:27,  3.65it/s, lr=9.6e-6, step_loss=0.339]07/18/2023 19:52:06 - INFO - __main__ - train loss is 2.1553936791606247\n",
      "Steps:  51%|█▌ | 7676/15000 [48:44<29:56,  4.08it/s, lr=9.6e-6, step_loss=0.103]07/18/2023 19:52:06 - INFO - __main__ - train loss is 2.189669203478843\n",
      "Steps:  51%|█ | 7677/15000 [48:44<27:30,  4.44it/s, lr=9.6e-6, step_loss=0.0343]07/18/2023 19:52:06 - INFO - __main__ - train loss is 2.4284614440985024\n",
      "Steps:  51%|█▌ | 7678/15000 [48:44<25:48,  4.73it/s, lr=9.6e-6, step_loss=0.239]07/18/2023 19:52:07 - INFO - __main__ - train loss is 2.4732233327813447\n",
      "Steps:  51%|█ | 7679/15000 [48:45<24:35,  4.96it/s, lr=9.6e-6, step_loss=0.0448]07/18/2023 19:52:07 - INFO - __main__ - train loss is 2.5789924231357872\n",
      "Steps:  51%|█▌ | 7680/15000 [48:45<23:55,  5.10it/s, lr=9.6e-6, step_loss=0.106]07/18/2023 19:52:07 - INFO - __main__ - train loss is 2.580581874004565\n",
      "Steps:  51%|▌| 7681/15000 [48:45<23:16,  5.24it/s, lr=9.6e-6, step_loss=0.00159]07/18/2023 19:52:07 - INFO - __main__ - train loss is 3.003794104210101\n",
      "Steps:  51%|█▌ | 7682/15000 [48:45<22:49,  5.34it/s, lr=9.6e-6, step_loss=0.423]07/18/2023 19:52:07 - INFO - __main__ - train loss is 3.044339556596242\n",
      "Steps:  51%|█ | 7683/15000 [48:45<22:29,  5.42it/s, lr=9.6e-6, step_loss=0.0405]07/18/2023 19:52:08 - INFO - __main__ - train loss is 3.0677493069088086\n",
      "Steps:  51%|█ | 7684/15000 [48:45<22:18,  5.47it/s, lr=9.6e-6, step_loss=0.0234]07/18/2023 19:52:08 - INFO - __main__ - train loss is 3.2462804469978437\n",
      "Steps:  51%|█▌ | 7685/15000 [48:46<22:13,  5.48it/s, lr=9.6e-6, step_loss=0.179]07/18/2023 19:52:08 - INFO - __main__ - train loss is 3.5075704607879743\n",
      "Steps:  51%|█▌ | 7686/15000 [48:46<22:09,  5.50it/s, lr=9.6e-6, step_loss=0.261]07/18/2023 19:52:08 - INFO - __main__ - train loss is 3.5103744691004977\n",
      "Steps:  51%|█ | 7687/15000 [48:46<22:02,  5.53it/s, lr=9.6e-6, step_loss=0.0028]07/18/2023 19:52:08 - INFO - __main__ - train loss is 3.6445345705142245\n",
      "Steps:  51%|█▌ | 7688/15000 [48:46<22:09,  5.50it/s, lr=9.6e-6, step_loss=0.134]07/18/2023 19:52:08 - INFO - __main__ - train loss is 3.652715841657482\n",
      "Steps:  51%|▌| 7689/15000 [48:46<22:13,  5.48it/s, lr=9.6e-6, step_loss=0.00818]07/18/2023 19:52:09 - INFO - __main__ - train loss is 3.8001547552412376\n",
      "Steps:  51%|█▌ | 7690/15000 [48:46<22:17,  5.47it/s, lr=9.6e-6, step_loss=0.147]07/18/2023 19:52:09 - INFO - __main__ - train loss is 3.908490451402031\n",
      "Steps:  51%|█▌ | 7691/15000 [48:47<22:12,  5.48it/s, lr=9.6e-6, step_loss=0.108]07/18/2023 19:52:09 - INFO - __main__ - train loss is 4.025086896843277\n",
      "Steps:  51%|█▌ | 7692/15000 [48:47<22:04,  5.52it/s, lr=9.6e-6, step_loss=0.117]07/18/2023 19:52:09 - INFO - __main__ - train loss is 4.0280770707177\n",
      "Steps:  51%|▌| 7693/15000 [48:47<21:59,  5.54it/s, lr=9.6e-6, step_loss=0.00299]07/18/2023 19:52:09 - INFO - __main__ - train loss is 4.036838268046267\n",
      "Steps:  51%|▌| 7694/15000 [48:47<21:56,  5.55it/s, lr=9.6e-6, step_loss=0.00876]07/18/2023 19:52:10 - INFO - __main__ - train loss is 4.104772959952243\n",
      "Steps:  51%|█ | 7695/15000 [48:47<21:53,  5.56it/s, lr=9.6e-6, step_loss=0.0679]07/18/2023 19:52:10 - INFO - __main__ - train loss is 4.126402613823302\n",
      "Steps:  51%|█ | 7696/15000 [48:48<21:51,  5.57it/s, lr=9.6e-6, step_loss=0.0216]07/18/2023 19:52:10 - INFO - __main__ - train loss is 4.81153332919348\n",
      "Steps:  51%|█▌ | 7697/15000 [48:48<21:51,  5.57it/s, lr=9.6e-6, step_loss=0.685]07/18/2023 19:52:10 - INFO - __main__ - train loss is 4.953985524480231\n",
      "Steps:  51%|█▌ | 7698/15000 [48:48<21:49,  5.58it/s, lr=9.6e-6, step_loss=0.142]07/18/2023 19:52:10 - INFO - __main__ - train loss is 5.075316776637919\n",
      "Steps:  51%|█▌ | 7699/15000 [48:48<21:48,  5.58it/s, lr=9.6e-6, step_loss=0.121]07/18/2023 19:52:10 - INFO - __main__ - train loss is 5.120725487475283\n",
      "Steps:  51%|█ | 7700/15000 [48:48<21:59,  5.53it/s, lr=9.6e-6, step_loss=0.0454]07/18/2023 19:52:11 - INFO - __main__ - train loss is 5.458943073754199\n",
      "Steps:  51%|█▌ | 7701/15000 [48:48<21:58,  5.54it/s, lr=9.6e-6, step_loss=0.338]07/18/2023 19:52:11 - INFO - __main__ - train loss is 5.842102562193759\n",
      "Steps:  51%|█▌ | 7702/15000 [48:49<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.383]07/18/2023 19:52:11 - INFO - __main__ - train loss is 6.118462954764254\n",
      "Steps:  51%|█▌ | 7703/15000 [48:49<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.276]07/18/2023 19:52:11 - INFO - __main__ - train loss is 6.209308211808093\n",
      "Steps:  51%|█ | 7704/15000 [48:49<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.0908]07/18/2023 19:52:11 - INFO - __main__ - train loss is 6.420767878298648\n",
      "Steps:  51%|█▌ | 7705/15000 [48:49<21:59,  5.53it/s, lr=9.6e-6, step_loss=0.211]07/18/2023 19:52:11 - INFO - __main__ - train loss is 6.5113461065338925\n",
      "Steps:  51%|█ | 7706/15000 [48:49<21:59,  5.53it/s, lr=9.6e-6, step_loss=0.0906]07/18/2023 19:52:12 - INFO - __main__ - train loss is 6.519522551563568\n",
      "Steps:  51%|▌| 7707/15000 [48:50<21:59,  5.53it/s, lr=9.6e-6, step_loss=0.00818]07/18/2023 19:52:12 - INFO - __main__ - train loss is 6.802796874311753\n",
      "Steps:  51%|█▌ | 7708/15000 [48:50<21:59,  5.53it/s, lr=9.6e-6, step_loss=0.283]07/18/2023 19:52:12 - INFO - __main__ - train loss is 6.804701991728507\n",
      "Steps:  51%|▌| 7709/15000 [48:50<21:59,  5.53it/s, lr=9.6e-6, step_loss=0.00191]07/18/2023 19:52:12 - INFO - __main__ - train loss is 6.808763754903339\n",
      "Steps:  51%|▌| 7710/15000 [48:50<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.00406]07/18/2023 19:52:12 - INFO - __main__ - train loss is 6.814930723863654\n",
      "Steps:  51%|▌| 7711/15000 [48:50<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.00617]07/18/2023 19:52:13 - INFO - __main__ - train loss is 6.816335215233266\n",
      "Steps:  51%|█ | 7712/15000 [48:50<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.0014]07/18/2023 19:52:13 - INFO - __main__ - train loss is 6.818510972429067\n",
      "Steps:  51%|▌| 7713/15000 [48:51<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.00218]07/18/2023 19:52:13 - INFO - __main__ - train loss is 7.427773975301534\n",
      "Steps:  51%|█▌ | 7714/15000 [48:51<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.609]07/18/2023 19:52:13 - INFO - __main__ - train loss is 7.6296356548555195\n",
      "Steps:  51%|█▌ | 7715/15000 [48:51<21:58,  5.53it/s, lr=9.6e-6, step_loss=0.202]07/18/2023 19:52:13 - INFO - __main__ - train loss is 7.700197220314294\n",
      "Steps:  51%|█ | 7716/15000 [48:51<21:58,  5.52it/s, lr=9.6e-6, step_loss=0.0706]07/18/2023 19:52:13 - INFO - __main__ - train loss is 7.7256455780006945\n",
      "Steps:  51%|█ | 7717/15000 [48:51<21:58,  5.52it/s, lr=9.6e-6, step_loss=0.0254]07/18/2023 19:52:14 - INFO - __main__ - train loss is 7.986871844623238\n",
      "Steps:  51%|█▌ | 7718/15000 [48:52<21:58,  5.52it/s, lr=9.6e-6, step_loss=0.261]07/18/2023 19:52:14 - INFO - __main__ - train loss is 8.401714927051216\n",
      "Steps:  51%|█▌ | 7719/15000 [48:52<21:58,  5.52it/s, lr=9.6e-6, step_loss=0.415]07/18/2023 19:52:14 - INFO - __main__ - train loss is 8.40936765121296\n",
      "Steps:  51%|▌| 7720/15000 [48:52<21:58,  5.52it/s, lr=9.6e-6, step_loss=0.00765]07/18/2023 19:52:14 - INFO - __main__ - train loss is 8.600827515590936\n",
      "Steps:  51%|█▌ | 7721/15000 [48:52<22:01,  5.51it/s, lr=9.6e-6, step_loss=0.191]07/18/2023 19:52:14 - INFO - __main__ - train loss is 8.621302620042115\n",
      "Steps:  51%|█ | 7722/15000 [48:52<21:59,  5.52it/s, lr=9.6e-6, step_loss=0.0205]07/18/2023 19:52:15 - INFO - __main__ - train loss is 8.705462739337236\n",
      "Steps:  51%|█ | 7723/15000 [48:52<21:59,  5.52it/s, lr=9.6e-6, step_loss=0.0842]07/18/2023 19:52:15 - INFO - __main__ - train loss is 8.731834803242236\n",
      "Steps:  51%|█ | 7724/15000 [48:53<22:06,  5.48it/s, lr=9.6e-6, step_loss=0.0264]07/18/2023 19:52:15 - INFO - __main__ - train loss is 9.580401931423694\n",
      "Steps:  52%|█▌ | 7725/15000 [48:53<22:04,  5.49it/s, lr=9.6e-6, step_loss=0.849]07/18/2023 19:52:15 - INFO - __main__ - train loss is 9.620625187177211\n",
      "Steps:  52%|█ | 7726/15000 [48:53<22:11,  5.46it/s, lr=9.6e-6, step_loss=0.0402]07/18/2023 19:52:15 - INFO - __main__ - train loss is 9.62688905140385\n",
      "Steps:  52%|▌| 7727/15000 [48:53<22:01,  5.50it/s, lr=9.6e-6, step_loss=0.00626]07/18/2023 19:52:15 - INFO - __main__ - train loss is 10.498188199009746\n",
      "Steps:  52%|█▌ | 7728/15000 [48:53<21:54,  5.53it/s, lr=9.6e-6, step_loss=0.871]07/18/2023 19:52:16 - INFO - __main__ - train loss is 10.504441401455551\n",
      "Steps:  52%|▌| 7729/15000 [48:54<21:49,  5.55it/s, lr=9.6e-6, step_loss=0.00625]07/18/2023 19:52:16 - INFO - __main__ - train loss is 10.837057253811508\n",
      "Steps:  52%|█▌ | 7730/15000 [48:54<21:45,  5.57it/s, lr=9.6e-6, step_loss=0.333]07/18/2023 19:52:16 - INFO - __main__ - train loss is 10.992935529444367\n",
      "Steps:  52%|█▌ | 7731/15000 [48:54<21:42,  5.58it/s, lr=9.6e-6, step_loss=0.156]07/18/2023 19:52:16 - INFO - __main__ - train loss is 10.995426698587835\n",
      "Steps:  52%|▌| 7732/15000 [48:54<21:40,  5.59it/s, lr=9.6e-6, step_loss=0.00249]07/18/2023 19:52:16 - INFO - __main__ - train loss is 11.141067235730588\n",
      "Steps:  52%|█▌ | 7733/15000 [48:54<21:38,  5.59it/s, lr=9.6e-6, step_loss=0.146]07/18/2023 19:52:17 - INFO - __main__ - train loss is 11.489965914748609\n",
      "Steps:  52%|█▌ | 7734/15000 [48:54<21:37,  5.60it/s, lr=9.6e-6, step_loss=0.349]07/18/2023 19:52:17 - INFO - __main__ - train loss is 11.499265956692398\n",
      "Steps:  52%|█ | 7735/15000 [48:55<21:36,  5.60it/s, lr=9.6e-6, step_loss=0.0093]07/18/2023 19:52:17 - INFO - __main__ - train loss is 11.8104416904971\n",
      "Steps:  52%|█▌ | 7736/15000 [48:55<21:36,  5.60it/s, lr=9.6e-6, step_loss=0.311]07/18/2023 19:52:17 - INFO - __main__ - train loss is 11.81511598918587\n",
      "Steps:  52%|▌| 7737/15000 [48:55<21:36,  5.60it/s, lr=9.6e-6, step_loss=0.00467]07/18/2023 19:52:17 - INFO - __main__ - train loss is 11.95940385852009\n",
      "Steps:  52%|█▌ | 7738/15000 [48:55<21:35,  5.60it/s, lr=9.6e-6, step_loss=0.144]07/18/2023 19:52:17 - INFO - __main__ - train loss is 12.295941905118525\n",
      "Steps:  52%|█▌ | 7739/15000 [48:55<21:34,  5.61it/s, lr=9.6e-6, step_loss=0.337]07/18/2023 19:52:18 - INFO - __main__ - train loss is 12.303146084304899\n",
      "Steps:  52%|█ | 7740/15000 [48:56<21:34,  5.61it/s, lr=9.6e-6, step_loss=0.0072]07/18/2023 19:52:18 - INFO - __main__ - train loss is 12.310431138146669\n",
      "Steps:  52%|▌| 7741/15000 [48:56<21:34,  5.61it/s, lr=9.6e-6, step_loss=0.00729]07/18/2023 19:52:18 - INFO - __main__ - train loss is 12.535279021132737\n",
      "Steps:  52%|█▌ | 7742/15000 [48:56<21:34,  5.61it/s, lr=9.6e-6, step_loss=0.225]07/18/2023 19:52:18 - INFO - __main__ - train loss is 12.641256988514215\n",
      "Steps:  52%|█▌ | 7743/15000 [48:56<21:33,  5.61it/s, lr=9.6e-6, step_loss=0.106]07/18/2023 19:52:18 - INFO - __main__ - train loss is 12.87711300002411\n",
      "Steps:  52%|█▌ | 7744/15000 [48:56<21:33,  5.61it/s, lr=9.6e-6, step_loss=0.236]07/18/2023 19:52:19 - INFO - __main__ - train loss is 12.881580065470189\n",
      "Steps:  52%|▌| 7745/15000 [48:56<21:32,  5.61it/s, lr=9.6e-6, step_loss=0.00447]07/18/2023 19:52:19 - INFO - __main__ - train loss is 12.909041020553559\n",
      "Steps:  52%|█ | 7746/15000 [48:57<21:32,  5.61it/s, lr=9.6e-6, step_loss=0.0275]07/18/2023 19:52:19 - INFO - __main__ - train loss is 13.198375734966248\n",
      "Steps:  52%|█▌ | 7747/15000 [48:57<23:15,  5.20it/s, lr=9.6e-6, step_loss=0.289]07/18/2023 19:52:19 - INFO - __main__ - train loss is 13.338287148158997\n",
      "Steps:  52%|██  | 7748/15000 [48:57<22:44,  5.32it/s, lr=9.6e-6, step_loss=0.14]07/18/2023 19:52:19 - INFO - __main__ - train loss is 14.108162257354707\n",
      "Steps:  52%|██  | 7749/15000 [48:57<22:45,  5.31it/s, lr=9.6e-6, step_loss=0.77]07/18/2023 19:52:19 - INFO - __main__ - train loss is 14.126130759250373\n",
      "Steps:  52%|█▌ | 7750/15000 [48:57<22:22,  5.40it/s, lr=9.6e-6, step_loss=0.018]07/18/2023 19:52:20 - INFO - __main__ - train loss is 14.20510372472927\n",
      "Steps:  52%|█▌ | 7751/15000 [48:58<22:06,  5.46it/s, lr=9.6e-6, step_loss=0.079]07/18/2023 19:52:20 - INFO - __main__ - train loss is 14.569814651738852\n",
      "Steps:  52%|█▌ | 7752/15000 [48:58<22:08,  5.45it/s, lr=9.6e-6, step_loss=0.365]07/18/2023 19:52:20 - INFO - __main__ - train loss is 15.494566291105002\n",
      "Steps:  52%|█▌ | 7753/15000 [48:58<22:04,  5.47it/s, lr=9.6e-6, step_loss=0.925]07/18/2023 19:52:20 - INFO - __main__ - train loss is 15.968868731986731\n",
      "Steps:  52%|█▌ | 7754/15000 [48:58<21:54,  5.51it/s, lr=9.6e-6, step_loss=0.474]07/18/2023 19:52:20 - INFO - __main__ - train loss is 16.173768773209304\n",
      "Steps:  52%|█▌ | 7755/15000 [48:58<21:55,  5.51it/s, lr=9.6e-6, step_loss=0.205]07/18/2023 19:52:21 - INFO - __main__ - train loss is 16.191236400511116\n",
      "Steps:  52%|▌| 7756/15000 [48:58<21:47,  5.54it/s, lr=9.59e-6, step_loss=0.0175]07/18/2023 19:52:21 - INFO - __main__ - train loss is 16.23219527443871\n",
      "Steps:  52%|█ | 7757/15000 [48:59<21:43,  5.56it/s, lr=9.59e-6, step_loss=0.041]07/18/2023 19:52:21 - INFO - __main__ - train loss is 16.395473258104175\n",
      "Steps:  52%|█ | 7758/15000 [48:59<21:39,  5.57it/s, lr=9.59e-6, step_loss=0.163]07/18/2023 19:52:21 - INFO - __main__ - train loss is 16.406717028003186\n",
      "Steps:  52%|▌| 7759/15000 [48:59<21:36,  5.58it/s, lr=9.59e-6, step_loss=0.0112]07/18/2023 19:52:21 - INFO - __main__ - train loss is 16.465123198460788\n",
      "Steps:  52%|▌| 7760/15000 [48:59<28:45,  4.20it/s, lr=9.59e-6, step_loss=0.0584]07/18/2023 19:52:22 - INFO - __main__ - Per validation step average loss is 0.017089981585741043\n",
      "07/18/2023 19:52:22 - INFO - __main__ - Cumulative validation average loss is 0.017089981585741043\n",
      "07/18/2023 19:52:22 - INFO - __main__ - Per validation step average loss is 0.20582042634487152\n",
      "07/18/2023 19:52:22 - INFO - __main__ - Cumulative validation average loss is 0.22291040793061256\n",
      "07/18/2023 19:52:22 - INFO - __main__ - Per validation step average loss is 0.012957265600562096\n",
      "07/18/2023 19:52:22 - INFO - __main__ - Cumulative validation average loss is 0.23586767353117466\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Per validation step average loss is 0.005801037885248661\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Cumulative validation average loss is 0.24166871141642332\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Per validation step average loss is 0.04039168357849121\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Cumulative validation average loss is 0.28206039499491453\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Per validation step average loss is 0.11283840239048004\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Cumulative validation average loss is 0.3948987973853946\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Per validation step average loss is 0.02049407549202442\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Cumulative validation average loss is 0.415392872877419\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Per validation step average loss is 0.5124635100364685\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Cumulative validation average loss is 0.9278563829138875\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Per validation step average loss is 0.003253591014072299\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Cumulative validation average loss is 0.9311099739279598\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Per validation step average loss is 0.32715266942977905\n",
      "07/18/2023 19:52:23 - INFO - __main__ - Cumulative validation average loss is 1.2582626433577389\n",
      "07/18/2023 19:52:24 - INFO - __main__ - Per validation step average loss is 0.016006849706172943\n",
      "07/18/2023 19:52:24 - INFO - __main__ - Cumulative validation average loss is 1.2742694930639118\n",
      "07/18/2023 19:52:24 - INFO - __main__ - Per validation step average loss is 0.3237141966819763\n",
      "07/18/2023 19:52:24 - INFO - __main__ - Cumulative validation average loss is 1.5979836897458881\n",
      "07/18/2023 19:52:24 - INFO - __main__ - Average validation loss for Epoch 79 is 0.13316530747882402\n",
      "07/18/2023 19:52:24 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:52:37 - INFO - __main__ - Starting epoch 80\n",
      "07/18/2023 19:52:38 - INFO - __main__ - train loss is 0.06201501190662384\n",
      "Steps:  52%|▌| 7761/15000 [49:15<10:02:22,  4.99s/it, lr=9.59e-6, step_loss=0.0607/18/2023 19:52:38 - INFO - __main__ - train loss is 0.1285797655582428\n",
      "Steps:  52%|▌| 7762/15000 [49:16<7:21:23,  3.66s/it, lr=9.59e-6, step_loss=0.06607/18/2023 19:52:39 - INFO - __main__ - train loss is 0.2507949322462082\n",
      "Steps:  52%|▌| 7763/15000 [49:17<5:29:07,  2.73s/it, lr=9.59e-6, step_loss=0.12207/18/2023 19:52:39 - INFO - __main__ - train loss is 0.2830823101103306\n",
      "Steps:  52%|▌| 7764/15000 [49:17<4:09:52,  2.07s/it, lr=9.59e-6, step_loss=0.03207/18/2023 19:52:40 - INFO - __main__ - train loss is 0.34185362234711647\n",
      "Steps:  52%|▌| 7765/15000 [49:18<3:14:34,  1.61s/it, lr=9.59e-6, step_loss=0.05807/18/2023 19:52:40 - INFO - __main__ - train loss is 0.5472339726984501\n",
      "Steps:  52%|▌| 7766/15000 [49:18<2:35:50,  1.29s/it, lr=9.59e-6, step_loss=0.20507/18/2023 19:52:41 - INFO - __main__ - train loss is 0.6480881534516811\n",
      "Steps:  52%|▌| 7767/15000 [49:19<2:08:39,  1.07s/it, lr=9.59e-6, step_loss=0.10107/18/2023 19:52:41 - INFO - __main__ - train loss is 0.9578881524503231\n",
      "Steps:  52%|▌| 7768/15000 [49:19<1:49:45,  1.10it/s, lr=9.59e-6, step_loss=0.31]07/18/2023 19:52:42 - INFO - __main__ - train loss is 1.0995008312165737\n",
      "Steps:  52%|▌| 7769/15000 [49:20<1:36:50,  1.24it/s, lr=9.59e-6, step_loss=0.14207/18/2023 19:52:42 - INFO - __main__ - train loss is 1.2856965027749538\n",
      "Steps:  52%|▌| 7770/15000 [49:20<1:28:06,  1.37it/s, lr=9.59e-6, step_loss=0.18607/18/2023 19:52:43 - INFO - __main__ - train loss is 1.2934185503982008\n",
      "Steps:  52%|▌| 7771/15000 [49:21<1:21:53,  1.47it/s, lr=9.59e-6, step_loss=0.00707/18/2023 19:52:44 - INFO - __main__ - train loss is 1.317951453384012\n",
      "Steps:  52%|▌| 7772/15000 [49:21<1:17:46,  1.55it/s, lr=9.59e-6, step_loss=0.02407/18/2023 19:52:44 - INFO - __main__ - train loss is 1.7084124810062349\n",
      "Steps:  52%|▌| 7773/15000 [49:22<1:14:58,  1.61it/s, lr=9.59e-6, step_loss=0.39]07/18/2023 19:52:45 - INFO - __main__ - train loss is 1.7217454346828163\n",
      "Steps:  52%|▌| 7774/15000 [49:23<1:13:13,  1.64it/s, lr=9.59e-6, step_loss=0.01307/18/2023 19:52:45 - INFO - __main__ - train loss is 1.7250880824867636\n",
      "Steps:  52%|▌| 7775/15000 [49:23<1:11:39,  1.68it/s, lr=9.59e-6, step_loss=0.00307/18/2023 19:52:46 - INFO - __main__ - train loss is 1.7332188340369612\n",
      "Steps:  52%|▌| 7776/15000 [49:24<1:10:29,  1.71it/s, lr=9.59e-6, step_loss=0.00807/18/2023 19:52:46 - INFO - __main__ - train loss is 1.7349278095643967\n",
      "Steps:  52%|▌| 7777/15000 [49:24<1:09:40,  1.73it/s, lr=9.59e-6, step_loss=0.00107/18/2023 19:52:47 - INFO - __main__ - train loss is 2.011598116485402\n",
      "Steps:  52%|▌| 7778/15000 [49:25<1:08:47,  1.75it/s, lr=9.59e-6, step_loss=0.27707/18/2023 19:52:48 - INFO - __main__ - train loss is 2.014621088281274\n",
      "Steps:  52%|▌| 7779/15000 [49:25<1:08:45,  1.75it/s, lr=9.59e-6, step_loss=0.00307/18/2023 19:52:48 - INFO - __main__ - train loss is 2.0375647004693747\n",
      "Steps:  52%|▌| 7780/15000 [49:26<1:08:23,  1.76it/s, lr=9.59e-6, step_loss=0.02207/18/2023 19:52:49 - INFO - __main__ - train loss is 2.058242941275239\n",
      "Steps:  52%|▌| 7781/15000 [49:27<1:07:19,  1.79it/s, lr=9.59e-6, step_loss=0.02007/18/2023 19:52:49 - INFO - __main__ - train loss is 2.1949077788740396\n",
      "Steps:  52%|▌| 7782/15000 [49:27<1:06:44,  1.80it/s, lr=9.59e-6, step_loss=0.13707/18/2023 19:52:50 - INFO - __main__ - train loss is 2.2005588496103883\n",
      "Steps:  52%|▌| 7783/15000 [49:28<1:06:13,  1.82it/s, lr=9.59e-6, step_loss=0.00507/18/2023 19:52:50 - INFO - __main__ - train loss is 2.3020551213994622\n",
      "Steps:  52%|▌| 7784/15000 [49:28<1:05:42,  1.83it/s, lr=9.59e-6, step_loss=0.10107/18/2023 19:52:51 - INFO - __main__ - train loss is 2.668719203211367\n",
      "Steps:  52%|▌| 7785/15000 [49:29<1:05:53,  1.82it/s, lr=9.59e-6, step_loss=0.36707/18/2023 19:52:51 - INFO - __main__ - train loss is 2.952812642790377\n",
      "Steps:  52%|▌| 7786/15000 [49:29<1:07:46,  1.77it/s, lr=9.59e-6, step_loss=0.28407/18/2023 19:52:52 - INFO - __main__ - train loss is 3.3544792840257287\n",
      "Steps:  52%|▌| 7787/15000 [49:30<1:09:24,  1.73it/s, lr=9.59e-6, step_loss=0.40207/18/2023 19:52:53 - INFO - __main__ - train loss is 3.697557062841952\n",
      "Steps:  52%|▌| 7788/15000 [49:30<1:08:28,  1.76it/s, lr=9.59e-6, step_loss=0.34307/18/2023 19:52:53 - INFO - __main__ - train loss is 3.8873621532693505\n",
      "Steps:  52%|▌| 7789/15000 [49:31<1:07:37,  1.78it/s, lr=9.59e-6, step_loss=0.19]07/18/2023 19:52:54 - INFO - __main__ - train loss is 4.034801051951945\n",
      "Steps:  52%|▌| 7790/15000 [49:32<1:06:53,  1.80it/s, lr=9.59e-6, step_loss=0.14707/18/2023 19:52:54 - INFO - __main__ - train loss is 4.095488571561873\n",
      "Steps:  52%|▌| 7791/15000 [49:32<1:06:22,  1.81it/s, lr=9.59e-6, step_loss=0.06007/18/2023 19:52:55 - INFO - __main__ - train loss is 4.637308859266341\n",
      "Steps:  52%|▌| 7792/15000 [49:33<1:06:07,  1.82it/s, lr=9.59e-6, step_loss=0.54207/18/2023 19:52:55 - INFO - __main__ - train loss is 4.725886055268347\n",
      "Steps:  52%|▌| 7793/15000 [49:33<1:05:49,  1.82it/s, lr=9.59e-6, step_loss=0.08807/18/2023 19:52:56 - INFO - __main__ - train loss is 5.228991159237921\n",
      "Steps:  52%|▌| 7794/15000 [49:34<1:05:54,  1.82it/s, lr=9.59e-6, step_loss=0.50307/18/2023 19:52:56 - INFO - __main__ - train loss is 5.548054822720587\n",
      "Steps:  52%|▌| 7795/15000 [49:34<1:06:15,  1.81it/s, lr=9.59e-6, step_loss=0.31907/18/2023 19:52:57 - INFO - __main__ - train loss is 5.592166521586478\n",
      "Steps:  52%|▌| 7796/15000 [49:35<1:05:50,  1.82it/s, lr=9.59e-6, step_loss=0.04407/18/2023 19:52:58 - INFO - __main__ - train loss is 5.690996863879263\n",
      "Steps:  52%|▌| 7797/15000 [49:35<1:05:39,  1.83it/s, lr=9.59e-6, step_loss=0.09807/18/2023 19:52:58 - INFO - __main__ - train loss is 5.709264741279185\n",
      "Steps:  52%|▌| 7798/15000 [49:36<1:05:40,  1.83it/s, lr=9.59e-6, step_loss=0.01807/18/2023 19:52:59 - INFO - __main__ - train loss is 5.801322386600077\n",
      "Steps:  52%|▌| 7799/15000 [49:36<1:05:51,  1.82it/s, lr=9.59e-6, step_loss=0.09207/18/2023 19:52:59 - INFO - __main__ - train loss is 6.067445502616465\n",
      "Steps:  52%|▌| 7800/15000 [49:37<1:05:38,  1.83it/s, lr=9.59e-6, step_loss=0.26607/18/2023 19:53:00 - INFO - __main__ - train loss is 6.418376610614359\n",
      "Steps:  52%|▌| 7801/15000 [49:38<1:05:31,  1.83it/s, lr=9.59e-6, step_loss=0.35107/18/2023 19:53:00 - INFO - __main__ - train loss is 6.6673294166103005\n",
      "Steps:  52%|▌| 7802/15000 [49:38<1:05:12,  1.84it/s, lr=9.59e-6, step_loss=0.24907/18/2023 19:53:01 - INFO - __main__ - train loss is 6.955978558398783\n",
      "Steps:  52%|▌| 7803/15000 [49:39<1:05:09,  1.84it/s, lr=9.59e-6, step_loss=0.28907/18/2023 19:53:01 - INFO - __main__ - train loss is 6.9594264545012265\n",
      "Steps:  52%|▌| 7804/15000 [49:39<1:05:21,  1.84it/s, lr=9.59e-6, step_loss=0.00307/18/2023 19:53:02 - INFO - __main__ - train loss is 6.979532047407702\n",
      "Steps:  52%|▌| 7805/15000 [49:40<1:05:16,  1.84it/s, lr=9.59e-6, step_loss=0.02007/18/2023 19:53:02 - INFO - __main__ - train loss is 7.165291040437296\n",
      "Steps:  52%|▌| 7806/15000 [49:40<1:05:21,  1.83it/s, lr=9.59e-6, step_loss=0.18607/18/2023 19:53:03 - INFO - __main__ - train loss is 7.233230634825304\n",
      "Steps:  52%|▌| 7807/15000 [49:41<1:05:00,  1.84it/s, lr=9.59e-6, step_loss=0.06707/18/2023 19:53:03 - INFO - __main__ - train loss is 7.256502914475277\n",
      "Steps:  52%|▌| 7808/15000 [49:41<1:05:01,  1.84it/s, lr=9.59e-6, step_loss=0.02307/18/2023 19:53:04 - INFO - __main__ - train loss is 7.4326629370916635\n",
      "Steps:  52%|▌| 7809/15000 [49:42<1:05:00,  1.84it/s, lr=9.59e-6, step_loss=0.17607/18/2023 19:53:05 - INFO - __main__ - train loss is 7.718535277293995\n",
      "Steps:  52%|▌| 7810/15000 [49:42<1:05:02,  1.84it/s, lr=9.59e-6, step_loss=0.28607/18/2023 19:53:05 - INFO - __main__ - train loss is 7.88702482287772\n",
      "Steps:  52%|▌| 7811/15000 [49:43<1:05:08,  1.84it/s, lr=9.59e-6, step_loss=0.16807/18/2023 19:53:06 - INFO - __main__ - train loss is 8.165906462119892\n",
      "Steps:  52%|▌| 7812/15000 [49:44<1:05:15,  1.84it/s, lr=9.59e-6, step_loss=0.27907/18/2023 19:53:06 - INFO - __main__ - train loss is 8.20152550493367\n",
      "Steps:  52%|▌| 7813/15000 [49:44<1:05:12,  1.84it/s, lr=9.59e-6, step_loss=0.03507/18/2023 19:53:07 - INFO - __main__ - train loss is 8.209996404359117\n",
      "Steps:  52%|▌| 7814/15000 [49:45<1:05:12,  1.84it/s, lr=9.59e-6, step_loss=0.00807/18/2023 19:53:07 - INFO - __main__ - train loss is 8.211998457321897\n",
      "Steps:  52%|▌| 7815/15000 [49:45<1:04:51,  1.85it/s, lr=9.59e-6, step_loss=0.00207/18/2023 19:53:08 - INFO - __main__ - train loss is 8.36952262581326\n",
      "Steps:  52%|▌| 7816/15000 [49:46<1:05:00,  1.84it/s, lr=9.59e-6, step_loss=0.15807/18/2023 19:53:08 - INFO - __main__ - train loss is 8.696943456539884\n",
      "Steps:  52%|▌| 7817/15000 [49:46<1:04:59,  1.84it/s, lr=9.59e-6, step_loss=0.32707/18/2023 19:53:09 - INFO - __main__ - train loss is 8.700428001349792\n",
      "Steps:  52%|▌| 7818/15000 [49:47<1:05:14,  1.83it/s, lr=9.59e-6, step_loss=0.00307/18/2023 19:53:09 - INFO - __main__ - train loss is 8.720278817927465\n",
      "Steps:  52%|▌| 7819/15000 [49:47<1:05:20,  1.83it/s, lr=9.59e-6, step_loss=0.01907/18/2023 19:53:10 - INFO - __main__ - train loss is 8.759360451018438\n",
      "Steps:  52%|▌| 7820/15000 [49:48<1:05:12,  1.84it/s, lr=9.59e-6, step_loss=0.03907/18/2023 19:53:11 - INFO - __main__ - train loss is 8.9533943568822\n",
      "Steps:  52%|▌| 7821/15000 [49:48<1:04:53,  1.84it/s, lr=9.59e-6, step_loss=0.19407/18/2023 19:53:11 - INFO - __main__ - train loss is 9.68430483690463\n",
      "Steps:  52%|▌| 7822/15000 [49:49<1:04:55,  1.84it/s, lr=9.59e-6, step_loss=0.73107/18/2023 19:53:12 - INFO - __main__ - train loss is 9.843487459933385\n",
      "Steps:  52%|▌| 7823/15000 [49:50<1:04:48,  1.85it/s, lr=9.59e-6, step_loss=0.15907/18/2023 19:53:12 - INFO - __main__ - train loss is 9.8740764351096\n",
      "Steps:  52%|▌| 7824/15000 [49:50<1:04:44,  1.85it/s, lr=9.59e-6, step_loss=0.03007/18/2023 19:53:13 - INFO - __main__ - train loss is 9.876568320207298\n",
      "Steps:  52%|▌| 7825/15000 [49:51<1:04:56,  1.84it/s, lr=9.59e-6, step_loss=0.00207/18/2023 19:53:13 - INFO - __main__ - train loss is 9.881860668770969\n",
      "Steps:  52%|▌| 7826/15000 [49:51<1:04:36,  1.85it/s, lr=9.59e-6, step_loss=0.00507/18/2023 19:53:14 - INFO - __main__ - train loss is 10.23167663346976\n",
      "Steps:  52%|▌| 7827/15000 [49:52<1:04:42,  1.85it/s, lr=9.59e-6, step_loss=0.35]07/18/2023 19:53:14 - INFO - __main__ - train loss is 10.23486974206753\n",
      "Steps:  52%|▌| 7828/15000 [49:52<1:04:52,  1.84it/s, lr=9.59e-6, step_loss=0.00307/18/2023 19:53:15 - INFO - __main__ - train loss is 10.446933024795726\n",
      "Steps:  52%|▌| 7829/15000 [49:53<1:04:46,  1.85it/s, lr=9.59e-6, step_loss=0.21207/18/2023 19:53:15 - INFO - __main__ - train loss is 10.60342358914204\n",
      "Steps:  52%|▌| 7830/15000 [49:53<1:04:50,  1.84it/s, lr=9.59e-6, step_loss=0.15607/18/2023 19:53:16 - INFO - __main__ - train loss is 10.850131177576259\n",
      "Steps:  52%|▌| 7831/15000 [49:54<1:04:53,  1.84it/s, lr=9.59e-6, step_loss=0.24707/18/2023 19:53:17 - INFO - __main__ - train loss is 11.269750678213313\n",
      "Steps:  52%|▌| 7832/15000 [49:54<1:04:54,  1.84it/s, lr=9.59e-6, step_loss=0.42]07/18/2023 19:53:17 - INFO - __main__ - train loss is 11.271351954201236\n",
      "Steps:  52%|▌| 7833/15000 [49:55<1:04:56,  1.84it/s, lr=9.59e-6, step_loss=0.00107/18/2023 19:53:18 - INFO - __main__ - train loss is 11.683583459118381\n",
      "Steps:  52%|▌| 7834/15000 [49:56<1:05:14,  1.83it/s, lr=9.59e-6, step_loss=0.41207/18/2023 19:53:18 - INFO - __main__ - train loss is 11.922795122722164\n",
      "Steps:  52%|▌| 7835/15000 [49:56<1:04:59,  1.84it/s, lr=9.59e-6, step_loss=0.23907/18/2023 19:53:19 - INFO - __main__ - train loss is 11.930571652250364\n",
      "Steps:  52%|▌| 7836/15000 [49:57<1:05:10,  1.83it/s, lr=9.59e-6, step_loss=0.00707/18/2023 19:53:19 - INFO - __main__ - train loss is 12.172475866274908\n",
      "Steps:  52%|▌| 7837/15000 [49:57<1:05:08,  1.83it/s, lr=9.59e-6, step_loss=0.24207/18/2023 19:53:20 - INFO - __main__ - train loss is 12.226259573595598\n",
      "Steps:  52%|▌| 7838/15000 [49:58<1:04:54,  1.84it/s, lr=9.59e-6, step_loss=0.05307/18/2023 19:53:20 - INFO - __main__ - train loss is 12.228316724766046\n",
      "Steps:  52%|▌| 7839/15000 [49:58<1:04:33,  1.85it/s, lr=9.59e-6, step_loss=0.00207/18/2023 19:53:21 - INFO - __main__ - train loss is 12.243408088106662\n",
      "Steps:  52%|▌| 7840/15000 [49:59<1:04:46,  1.84it/s, lr=9.59e-6, step_loss=0.01507/18/2023 19:53:21 - INFO - __main__ - train loss is 12.445139904040843\n",
      "Steps:  52%|▌| 7841/15000 [49:59<1:04:54,  1.84it/s, lr=9.59e-6, step_loss=0.20207/18/2023 19:53:22 - INFO - __main__ - train loss is 12.560760844964534\n",
      "Steps:  52%|▌| 7842/15000 [50:00<1:04:42,  1.84it/s, lr=9.59e-6, step_loss=0.11607/18/2023 19:53:23 - INFO - __main__ - train loss is 12.568487754557282\n",
      "Steps:  52%|▌| 7843/15000 [50:00<1:04:40,  1.84it/s, lr=9.59e-6, step_loss=0.00707/18/2023 19:53:23 - INFO - __main__ - train loss is 12.607520794961601\n",
      "Steps:  52%|▌| 7844/15000 [50:01<1:05:44,  1.81it/s, lr=9.59e-6, step_loss=0.03907/18/2023 19:53:24 - INFO - __main__ - train loss is 12.638496473897249\n",
      "Steps:  52%|▌| 7845/15000 [50:02<1:08:09,  1.75it/s, lr=9.59e-6, step_loss=0.03107/18/2023 19:53:24 - INFO - __main__ - train loss is 12.64395878976211\n",
      "Steps:  52%|▌| 7846/15000 [50:02<1:09:06,  1.73it/s, lr=9.59e-6, step_loss=0.00507/18/2023 19:53:25 - INFO - __main__ - train loss is 12.696805050130934\n",
      "Steps:  52%|▌| 7847/15000 [50:03<1:08:13,  1.75it/s, lr=9.59e-6, step_loss=0.05207/18/2023 19:53:25 - INFO - __main__ - train loss is 12.713494048919529\n",
      "Steps:  52%|▌| 7848/15000 [50:03<1:09:04,  1.73it/s, lr=9.59e-6, step_loss=0.01607/18/2023 19:53:26 - INFO - __main__ - train loss is 12.936614559497684\n",
      "Steps:  52%|▌| 7849/15000 [50:04<1:07:39,  1.76it/s, lr=9.59e-6, step_loss=0.22307/18/2023 19:53:27 - INFO - __main__ - train loss is 12.975775571074337\n",
      "Steps:  52%|▌| 7850/15000 [50:04<1:06:37,  1.79it/s, lr=9.59e-6, step_loss=0.03907/18/2023 19:53:27 - INFO - __main__ - train loss is 13.277123482432216\n",
      "Steps:  52%|▌| 7851/15000 [50:05<1:06:08,  1.80it/s, lr=9.59e-6, step_loss=0.30107/18/2023 19:53:28 - INFO - __main__ - train loss is 13.326997281517833\n",
      "Steps:  52%|▌| 7852/15000 [50:06<1:05:42,  1.81it/s, lr=9.59e-6, step_loss=0.04907/18/2023 19:53:28 - INFO - __main__ - train loss is 13.395582938101143\n",
      "Steps:  52%|▌| 7853/15000 [50:06<1:05:40,  1.81it/s, lr=9.58e-6, step_loss=0.06807/18/2023 19:53:29 - INFO - __main__ - train loss is 13.412839881610125\n",
      "Steps:  52%|▌| 7854/15000 [50:07<1:05:24,  1.82it/s, lr=9.58e-6, step_loss=0.01707/18/2023 19:53:29 - INFO - __main__ - train loss is 13.42431741161272\n",
      "Steps:  52%|▌| 7855/15000 [50:07<1:04:55,  1.83it/s, lr=9.58e-6, step_loss=0.01107/18/2023 19:53:30 - INFO - __main__ - train loss is 13.813088230323046\n",
      "Steps:  52%|▌| 7856/15000 [50:08<1:04:52,  1.84it/s, lr=9.58e-6, step_loss=0.38907/18/2023 19:53:31 - INFO - __main__ - train loss is 13.824031447526067\n",
      "Steps:  52%|▌| 7857/15000 [50:08<1:11:29,  1.67it/s, lr=9.58e-6, step_loss=0.01007/18/2023 19:53:31 - INFO - __main__ - Per validation step average loss is 0.14425694942474365\n",
      "07/18/2023 19:53:31 - INFO - __main__ - Cumulative validation average loss is 0.14425694942474365\n",
      "07/18/2023 19:53:31 - INFO - __main__ - Per validation step average loss is 0.009174646809697151\n",
      "07/18/2023 19:53:31 - INFO - __main__ - Cumulative validation average loss is 0.1534315962344408\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Per validation step average loss is 0.008966797962784767\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Cumulative validation average loss is 0.16239839419722557\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Per validation step average loss is 0.08680705726146698\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Cumulative validation average loss is 0.24920545145869255\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Per validation step average loss is 0.010619203560054302\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Cumulative validation average loss is 0.25982465501874685\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Per validation step average loss is 0.02935742400586605\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Cumulative validation average loss is 0.2891820790246129\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Per validation step average loss is 0.012027285061776638\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Cumulative validation average loss is 0.30120936408638954\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Per validation step average loss is 0.13899478316307068\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Cumulative validation average loss is 0.4402041472494602\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Per validation step average loss is 0.06317855417728424\n",
      "07/18/2023 19:53:32 - INFO - __main__ - Cumulative validation average loss is 0.5033827014267445\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Per validation step average loss is 0.0013945967657491565\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Cumulative validation average loss is 0.5047772981924936\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Per validation step average loss is 0.11966554820537567\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Cumulative validation average loss is 0.6244428463978693\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Per validation step average loss is 0.15904518961906433\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Cumulative validation average loss is 0.7834880360169336\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Average validation loss for Epoch 80 is 0.0652906696680778\n",
      "07/18/2023 19:53:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:53:46 - INFO - __main__ - Starting epoch 81\n",
      "07/18/2023 19:53:47 - INFO - __main__ - train loss is 0.0872785672545433\n",
      "Steps:  52%|▌| 7858/15000 [50:25<10:26:35,  5.26s/it, lr=9.58e-6, step_loss=0.0807/18/2023 19:53:47 - INFO - __main__ - train loss is 0.08909917902201414\n",
      "Steps:  52%|▌| 7859/15000 [50:25<7:24:56,  3.74s/it, lr=9.58e-6, step_loss=0.00107/18/2023 19:53:47 - INFO - __main__ - train loss is 0.09192476840689778\n",
      "Steps:  52%|▌| 7860/15000 [50:25<5:17:44,  2.67s/it, lr=9.58e-6, step_loss=0.00207/18/2023 19:53:47 - INFO - __main__ - train loss is 0.11717371689155698\n",
      "Steps:  52%|▌| 7861/15000 [50:25<3:48:50,  1.92s/it, lr=9.58e-6, step_loss=0.02507/18/2023 19:53:47 - INFO - __main__ - train loss is 0.13365754345431924\n",
      "Steps:  52%|▌| 7862/15000 [50:25<2:46:31,  1.40s/it, lr=9.58e-6, step_loss=0.01607/18/2023 19:53:48 - INFO - __main__ - train loss is 0.485417811665684\n",
      "Steps:  52%|▌| 7863/15000 [50:25<2:02:59,  1.03s/it, lr=9.58e-6, step_loss=0.35207/18/2023 19:53:48 - INFO - __main__ - train loss is 0.4886301099322736\n",
      "Steps:  52%|▌| 7864/15000 [50:26<1:32:29,  1.29it/s, lr=9.58e-6, step_loss=0.00307/18/2023 19:53:48 - INFO - __main__ - train loss is 0.4920675603207201\n",
      "Steps:  52%|▌| 7865/15000 [50:26<1:11:05,  1.67it/s, lr=9.58e-6, step_loss=0.00307/18/2023 19:53:48 - INFO - __main__ - train loss is 0.4989700724836439\n",
      "Steps:  52%|▌| 7866/15000 [50:26<56:09,  2.12it/s, lr=9.58e-6, step_loss=0.0069]07/18/2023 19:53:48 - INFO - __main__ - train loss is 0.6321931590791792\n",
      "Steps:  52%|█ | 7867/15000 [50:26<45:39,  2.60it/s, lr=9.58e-6, step_loss=0.133]07/18/2023 19:53:48 - INFO - __main__ - train loss is 0.9108308067079633\n",
      "Steps:  52%|█ | 7868/15000 [50:26<38:17,  3.10it/s, lr=9.58e-6, step_loss=0.279]07/18/2023 19:53:49 - INFO - __main__ - train loss is 0.9150173559319228\n",
      "Steps:  52%|▌| 7869/15000 [50:27<33:20,  3.57it/s, lr=9.58e-6, step_loss=0.0041907/18/2023 19:53:49 - INFO - __main__ - train loss is 0.9377787455450743\n",
      "Steps:  52%|▌| 7870/15000 [50:27<29:53,  3.98it/s, lr=9.58e-6, step_loss=0.0228]07/18/2023 19:53:49 - INFO - __main__ - train loss is 0.9416533391922712\n",
      "Steps:  52%|▌| 7871/15000 [50:27<27:19,  4.35it/s, lr=9.58e-6, step_loss=0.0038707/18/2023 19:53:49 - INFO - __main__ - train loss is 0.9432753543369472\n",
      "Steps:  52%|▌| 7872/15000 [50:27<25:29,  4.66it/s, lr=9.58e-6, step_loss=0.0016207/18/2023 19:53:49 - INFO - __main__ - train loss is 1.3064506868831813\n",
      "Steps:  52%|█ | 7873/15000 [50:27<24:11,  4.91it/s, lr=9.58e-6, step_loss=0.363]07/18/2023 19:53:50 - INFO - __main__ - train loss is 1.6183035890571773\n",
      "Steps:  52%|█ | 7874/15000 [50:27<23:16,  5.10it/s, lr=9.58e-6, step_loss=0.312]07/18/2023 19:53:50 - INFO - __main__ - train loss is 1.925955645274371\n",
      "Steps:  52%|█ | 7875/15000 [50:28<22:47,  5.21it/s, lr=9.58e-6, step_loss=0.308]07/18/2023 19:53:50 - INFO - __main__ - train loss is 2.334924570750445\n",
      "Steps:  53%|█ | 7876/15000 [50:28<22:20,  5.31it/s, lr=9.58e-6, step_loss=0.409]07/18/2023 19:53:50 - INFO - __main__ - train loss is 2.3371490775607526\n",
      "Steps:  53%|▌| 7877/15000 [50:28<22:01,  5.39it/s, lr=9.58e-6, step_loss=0.0022207/18/2023 19:53:50 - INFO - __main__ - train loss is 2.3410845971666276\n",
      "Steps:  53%|▌| 7878/15000 [50:28<21:55,  5.41it/s, lr=9.58e-6, step_loss=0.0039407/18/2023 19:53:50 - INFO - __main__ - train loss is 2.4706799662671983\n",
      "Steps:  53%|█▌ | 7879/15000 [50:28<21:56,  5.41it/s, lr=9.58e-6, step_loss=0.13]07/18/2023 19:53:51 - INFO - __main__ - train loss is 2.7385247624479234\n",
      "Steps:  53%|█ | 7880/15000 [50:29<21:46,  5.45it/s, lr=9.58e-6, step_loss=0.268]07/18/2023 19:53:51 - INFO - __main__ - train loss is 2.7433032183907926\n",
      "Steps:  53%|▌| 7881/15000 [50:29<21:47,  5.45it/s, lr=9.58e-6, step_loss=0.0047807/18/2023 19:53:51 - INFO - __main__ - train loss is 2.7449713418027386\n",
      "Steps:  53%|▌| 7882/15000 [50:29<21:39,  5.48it/s, lr=9.58e-6, step_loss=0.0016707/18/2023 19:53:51 - INFO - __main__ - train loss is 3.3819267818471417\n",
      "Steps:  53%|█ | 7883/15000 [50:29<21:29,  5.52it/s, lr=9.58e-6, step_loss=0.637]07/18/2023 19:53:51 - INFO - __main__ - train loss is 3.601099214865826\n",
      "Steps:  53%|█ | 7884/15000 [50:29<21:22,  5.55it/s, lr=9.58e-6, step_loss=0.219]07/18/2023 19:53:52 - INFO - __main__ - train loss is 3.7128153213998303\n",
      "Steps:  53%|█ | 7885/15000 [50:29<21:20,  5.56it/s, lr=9.58e-6, step_loss=0.112]07/18/2023 19:53:52 - INFO - __main__ - train loss is 3.719547339132987\n",
      "Steps:  53%|▌| 7886/15000 [50:30<21:17,  5.57it/s, lr=9.58e-6, step_loss=0.0067307/18/2023 19:53:52 - INFO - __main__ - train loss is 4.002874054363929\n",
      "Steps:  53%|█ | 7887/15000 [50:30<21:14,  5.58it/s, lr=9.58e-6, step_loss=0.283]07/18/2023 19:53:52 - INFO - __main__ - train loss is 4.201266713789664\n",
      "Steps:  53%|█ | 7888/15000 [50:30<21:12,  5.59it/s, lr=9.58e-6, step_loss=0.198]07/18/2023 19:53:52 - INFO - __main__ - train loss is 4.257143847993575\n",
      "Steps:  53%|▌| 7889/15000 [50:30<21:10,  5.60it/s, lr=9.58e-6, step_loss=0.0559]07/18/2023 19:53:52 - INFO - __main__ - train loss is 4.345953785232268\n",
      "Steps:  53%|▌| 7890/15000 [50:30<21:09,  5.60it/s, lr=9.58e-6, step_loss=0.0888]07/18/2023 19:53:53 - INFO - __main__ - train loss is 4.731824718764983\n",
      "Steps:  53%|█ | 7891/15000 [50:30<21:08,  5.60it/s, lr=9.58e-6, step_loss=0.386]07/18/2023 19:53:53 - INFO - __main__ - train loss is 4.747587744495831\n",
      "Steps:  53%|▌| 7892/15000 [50:31<21:07,  5.61it/s, lr=9.58e-6, step_loss=0.0158]07/18/2023 19:53:53 - INFO - __main__ - train loss is 4.756244512624107\n",
      "Steps:  53%|▌| 7893/15000 [50:31<21:07,  5.61it/s, lr=9.58e-6, step_loss=0.0086607/18/2023 19:53:53 - INFO - __main__ - train loss is 5.022042306489311\n",
      "Steps:  53%|█ | 7894/15000 [50:31<21:19,  5.56it/s, lr=9.58e-6, step_loss=0.266]07/18/2023 19:53:53 - INFO - __main__ - train loss is 5.204602303332649\n",
      "Steps:  53%|█ | 7895/15000 [50:31<21:15,  5.57it/s, lr=9.58e-6, step_loss=0.183]07/18/2023 19:53:53 - INFO - __main__ - train loss is 5.2093260324327275\n",
      "Steps:  53%|▌| 7896/15000 [50:31<21:12,  5.58it/s, lr=9.58e-6, step_loss=0.0047207/18/2023 19:53:54 - INFO - __main__ - train loss is 5.286996412905864\n",
      "Steps:  53%|▌| 7897/15000 [50:32<21:11,  5.59it/s, lr=9.58e-6, step_loss=0.0777]07/18/2023 19:53:54 - INFO - __main__ - train loss is 5.5655093676177785\n",
      "Steps:  53%|█ | 7898/15000 [50:32<21:09,  5.59it/s, lr=9.58e-6, step_loss=0.279]07/18/2023 19:53:54 - INFO - __main__ - train loss is 5.567978476523422\n",
      "Steps:  53%|▌| 7899/15000 [50:32<21:07,  5.60it/s, lr=9.58e-6, step_loss=0.0024707/18/2023 19:53:54 - INFO - __main__ - train loss is 5.913847183226608\n",
      "Steps:  53%|█ | 7900/15000 [50:32<21:06,  5.61it/s, lr=9.58e-6, step_loss=0.346]07/18/2023 19:53:54 - INFO - __main__ - train loss is 5.915878831059672\n",
      "Steps:  53%|▌| 7901/15000 [50:32<21:05,  5.61it/s, lr=9.58e-6, step_loss=0.0020307/18/2023 19:53:55 - INFO - __main__ - train loss is 6.544691382558085\n",
      "Steps:  53%|█ | 7902/15000 [50:32<21:05,  5.61it/s, lr=9.58e-6, step_loss=0.629]07/18/2023 19:53:55 - INFO - __main__ - train loss is 6.571381835849024\n",
      "Steps:  53%|▌| 7903/15000 [50:33<21:04,  5.61it/s, lr=9.58e-6, step_loss=0.0267]07/18/2023 19:53:55 - INFO - __main__ - train loss is 6.584651612327434\n",
      "Steps:  53%|▌| 7904/15000 [50:33<21:04,  5.61it/s, lr=9.58e-6, step_loss=0.0133]07/18/2023 19:53:55 - INFO - __main__ - train loss is 6.871197336004116\n",
      "Steps:  53%|█ | 7905/15000 [50:33<21:04,  5.61it/s, lr=9.58e-6, step_loss=0.287]07/18/2023 19:53:55 - INFO - __main__ - train loss is 6.947186314151622\n",
      "Steps:  53%|█ | 7906/15000 [50:33<21:03,  5.61it/s, lr=9.58e-6, step_loss=0.076]07/18/2023 19:53:55 - INFO - __main__ - train loss is 6.983318795100786\n",
      "Steps:  53%|▌| 7907/15000 [50:33<21:03,  5.61it/s, lr=9.58e-6, step_loss=0.0361]07/18/2023 19:53:56 - INFO - __main__ - train loss is 6.987470646039583\n",
      "Steps:  53%|▌| 7908/15000 [50:34<21:05,  5.61it/s, lr=9.58e-6, step_loss=0.0041507/18/2023 19:53:56 - INFO - __main__ - train loss is 7.02343953831587\n",
      "Steps:  53%|█ | 7909/15000 [50:34<21:24,  5.52it/s, lr=9.58e-6, step_loss=0.036]07/18/2023 19:53:56 - INFO - __main__ - train loss is 7.2952431259909645\n",
      "Steps:  53%|█ | 7910/15000 [50:34<24:08,  4.89it/s, lr=9.58e-6, step_loss=0.272]07/18/2023 19:53:56 - INFO - __main__ - train loss is 7.3689072547713295\n",
      "Steps:  53%|▌| 7911/15000 [50:34<24:42,  4.78it/s, lr=9.58e-6, step_loss=0.0737]07/18/2023 19:53:56 - INFO - __main__ - train loss is 7.527642679051496\n",
      "Steps:  53%|█ | 7912/15000 [50:34<24:48,  4.76it/s, lr=9.58e-6, step_loss=0.159]07/18/2023 19:53:57 - INFO - __main__ - train loss is 7.713763472274877\n",
      "Steps:  53%|█ | 7913/15000 [50:35<24:34,  4.81it/s, lr=9.58e-6, step_loss=0.186]07/18/2023 19:53:57 - INFO - __main__ - train loss is 8.00070425553713\n",
      "Steps:  53%|█ | 7914/15000 [50:35<23:44,  4.97it/s, lr=9.58e-6, step_loss=0.287]07/18/2023 19:53:57 - INFO - __main__ - train loss is 8.450231638387777\n",
      "Steps:  53%|█▌ | 7915/15000 [50:35<22:56,  5.15it/s, lr=9.58e-6, step_loss=0.45]07/18/2023 19:53:57 - INFO - __main__ - train loss is 8.800533589557745\n",
      "Steps:  53%|█▌ | 7916/15000 [50:35<22:22,  5.28it/s, lr=9.58e-6, step_loss=0.35]07/18/2023 19:53:57 - INFO - __main__ - train loss is 9.246397372917272\n",
      "Steps:  53%|█ | 7917/15000 [50:35<22:01,  5.36it/s, lr=9.58e-6, step_loss=0.446]07/18/2023 19:53:58 - INFO - __main__ - train loss is 9.266871512518264\n",
      "Steps:  53%|▌| 7918/15000 [50:36<21:45,  5.43it/s, lr=9.58e-6, step_loss=0.0205]07/18/2023 19:53:58 - INFO - __main__ - train loss is 9.507770211086608\n",
      "Steps:  53%|█ | 7919/15000 [50:36<21:32,  5.48it/s, lr=9.58e-6, step_loss=0.241]07/18/2023 19:53:58 - INFO - __main__ - train loss is 10.021313876495697\n",
      "Steps:  53%|█ | 7920/15000 [50:36<21:24,  5.51it/s, lr=9.58e-6, step_loss=0.514]07/18/2023 19:53:58 - INFO - __main__ - train loss is 10.024863187340088\n",
      "Steps:  53%|▌| 7921/15000 [50:36<21:17,  5.54it/s, lr=9.58e-6, step_loss=0.0035507/18/2023 19:53:58 - INFO - __main__ - train loss is 10.288110856083222\n",
      "Steps:  53%|█ | 7922/15000 [50:36<21:14,  5.55it/s, lr=9.58e-6, step_loss=0.263]07/18/2023 19:53:59 - INFO - __main__ - train loss is 10.316608697292395\n",
      "Steps:  53%|▌| 7923/15000 [50:36<21:11,  5.57it/s, lr=9.58e-6, step_loss=0.0285]07/18/2023 19:53:59 - INFO - __main__ - train loss is 10.345657296595164\n",
      "Steps:  53%|█ | 7924/15000 [50:37<21:07,  5.58it/s, lr=9.58e-6, step_loss=0.029]07/18/2023 19:53:59 - INFO - __main__ - train loss is 10.540794246015139\n",
      "Steps:  53%|█ | 7925/15000 [50:37<21:06,  5.59it/s, lr=9.58e-6, step_loss=0.195]07/18/2023 19:53:59 - INFO - __main__ - train loss is 10.895823471364565\n",
      "Steps:  53%|█ | 7926/15000 [50:37<21:05,  5.59it/s, lr=9.58e-6, step_loss=0.355]07/18/2023 19:53:59 - INFO - __main__ - train loss is 11.091707132873125\n",
      "Steps:  53%|█ | 7927/15000 [50:37<21:04,  5.59it/s, lr=9.58e-6, step_loss=0.196]07/18/2023 19:53:59 - INFO - __main__ - train loss is 11.232492156443186\n",
      "Steps:  53%|█ | 7928/15000 [50:37<21:05,  5.59it/s, lr=9.58e-6, step_loss=0.141]07/18/2023 19:54:00 - INFO - __main__ - train loss is 11.271518617984839\n",
      "Steps:  53%|█ | 7929/15000 [50:37<21:06,  5.59it/s, lr=9.58e-6, step_loss=0.039]07/18/2023 19:54:00 - INFO - __main__ - train loss is 11.282513503101654\n",
      "Steps:  53%|█ | 7930/15000 [50:38<21:03,  5.59it/s, lr=9.58e-6, step_loss=0.011]07/18/2023 19:54:00 - INFO - __main__ - train loss is 11.489630017546006\n",
      "Steps:  53%|█ | 7931/15000 [50:38<21:01,  5.60it/s, lr=9.58e-6, step_loss=0.207]07/18/2023 19:54:00 - INFO - __main__ - train loss is 11.68166652705986\n",
      "Steps:  53%|█ | 7932/15000 [50:38<21:00,  5.61it/s, lr=9.58e-6, step_loss=0.192]07/18/2023 19:54:00 - INFO - __main__ - train loss is 12.042476926115341\n",
      "Steps:  53%|█ | 7933/15000 [50:38<20:59,  5.61it/s, lr=9.58e-6, step_loss=0.361]07/18/2023 19:54:00 - INFO - __main__ - train loss is 12.06661894370336\n",
      "Steps:  53%|▌| 7934/15000 [50:38<21:09,  5.56it/s, lr=9.58e-6, step_loss=0.0241]07/18/2023 19:54:01 - INFO - __main__ - train loss is 12.32949622918386\n",
      "Steps:  53%|█ | 7935/15000 [50:39<21:06,  5.58it/s, lr=9.58e-6, step_loss=0.263]07/18/2023 19:54:01 - INFO - __main__ - train loss is 12.336576879140921\n",
      "Steps:  53%|▌| 7936/15000 [50:39<21:03,  5.59it/s, lr=9.58e-6, step_loss=0.0070807/18/2023 19:54:01 - INFO - __main__ - train loss is 12.411967203137465\n",
      "Steps:  53%|▌| 7937/15000 [50:39<21:02,  5.59it/s, lr=9.58e-6, step_loss=0.0754]07/18/2023 19:54:01 - INFO - __main__ - train loss is 12.418608835083432\n",
      "Steps:  53%|▌| 7938/15000 [50:39<21:01,  5.60it/s, lr=9.58e-6, step_loss=0.0066407/18/2023 19:54:01 - INFO - __main__ - train loss is 12.42732248280663\n",
      "Steps:  53%|▌| 7939/15000 [50:39<20:59,  5.61it/s, lr=9.58e-6, step_loss=0.0087107/18/2023 19:54:02 - INFO - __main__ - train loss is 12.445662554469891\n",
      "Steps:  53%|▌| 7940/15000 [50:39<20:58,  5.61it/s, lr=9.58e-6, step_loss=0.0183]07/18/2023 19:54:02 - INFO - __main__ - train loss is 12.496879447367974\n",
      "Steps:  53%|▌| 7941/15000 [50:40<20:57,  5.61it/s, lr=9.58e-6, step_loss=0.0512]07/18/2023 19:54:02 - INFO - __main__ - train loss is 12.623912353185005\n",
      "Steps:  53%|█ | 7942/15000 [50:40<20:57,  5.61it/s, lr=9.58e-6, step_loss=0.127]07/18/2023 19:54:02 - INFO - __main__ - train loss is 13.101182777551003\n",
      "Steps:  53%|█ | 7943/15000 [50:40<20:55,  5.62it/s, lr=9.58e-6, step_loss=0.477]07/18/2023 19:54:02 - INFO - __main__ - train loss is 13.333786238101311\n",
      "Steps:  53%|█ | 7944/15000 [50:40<20:55,  5.62it/s, lr=9.58e-6, step_loss=0.233]07/18/2023 19:54:02 - INFO - __main__ - train loss is 13.576742906239815\n",
      "Steps:  53%|█ | 7945/15000 [50:40<20:53,  5.63it/s, lr=9.58e-6, step_loss=0.243]07/18/2023 19:54:03 - INFO - __main__ - train loss is 13.586361082387157\n",
      "Steps:  53%|▌| 7946/15000 [50:40<20:53,  5.63it/s, lr=9.58e-6, step_loss=0.0096207/18/2023 19:54:03 - INFO - __main__ - train loss is 13.58925037982408\n",
      "Steps:  53%|▌| 7947/15000 [50:41<20:53,  5.62it/s, lr=9.58e-6, step_loss=0.0028907/18/2023 19:54:03 - INFO - __main__ - train loss is 13.813595289015211\n",
      "Steps:  53%|█ | 7948/15000 [50:41<20:53,  5.63it/s, lr=9.57e-6, step_loss=0.224]07/18/2023 19:54:03 - INFO - __main__ - train loss is 13.866784760379232\n",
      "Steps:  53%|▌| 7949/15000 [50:41<20:54,  5.62it/s, lr=9.57e-6, step_loss=0.0532]07/18/2023 19:54:03 - INFO - __main__ - train loss is 13.922789146774448\n",
      "Steps:  53%|█ | 7950/15000 [50:41<20:53,  5.62it/s, lr=9.57e-6, step_loss=0.056]07/18/2023 19:54:03 - INFO - __main__ - train loss is 13.928930244990624\n",
      "Steps:  53%|▌| 7951/15000 [50:41<20:52,  5.63it/s, lr=9.57e-6, step_loss=0.0061407/18/2023 19:54:04 - INFO - __main__ - train loss is 14.029437131830491\n",
      "Steps:  53%|█ | 7952/15000 [50:42<20:52,  5.63it/s, lr=9.57e-6, step_loss=0.101]07/18/2023 19:54:04 - INFO - __main__ - train loss is 14.046550156199373\n",
      "Steps:  53%|▌| 7953/15000 [50:42<20:52,  5.63it/s, lr=9.57e-6, step_loss=0.0171]07/18/2023 19:54:04 - INFO - __main__ - train loss is 14.334699036204256\n",
      "Steps:  53%|█ | 7954/15000 [50:42<28:19,  4.15it/s, lr=9.57e-6, step_loss=0.288]07/18/2023 19:54:05 - INFO - __main__ - Per validation step average loss is 0.0973796620965004\n",
      "07/18/2023 19:54:05 - INFO - __main__ - Cumulative validation average loss is 0.0973796620965004\n",
      "07/18/2023 19:54:05 - INFO - __main__ - Per validation step average loss is 0.29672467708587646\n",
      "07/18/2023 19:54:05 - INFO - __main__ - Cumulative validation average loss is 0.39410433918237686\n",
      "07/18/2023 19:54:05 - INFO - __main__ - Per validation step average loss is 0.13072150945663452\n",
      "07/18/2023 19:54:05 - INFO - __main__ - Cumulative validation average loss is 0.5248258486390114\n",
      "07/18/2023 19:54:05 - INFO - __main__ - Per validation step average loss is 0.4027576446533203\n",
      "07/18/2023 19:54:05 - INFO - __main__ - Cumulative validation average loss is 0.9275834932923317\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.006167850457131863\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 0.9337513437494636\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.004018280655145645\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 0.9377696244046092\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.11896675825119019\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 1.0567363826557994\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.5310249924659729\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 1.5877613751217723\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.1919761598110199\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 1.7797375349327922\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.3491542339324951\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 2.1288917688652873\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Per validation step average loss is 0.0014456257922574878\n",
      "07/18/2023 19:54:06 - INFO - __main__ - Cumulative validation average loss is 2.130337394657545\n",
      "07/18/2023 19:54:07 - INFO - __main__ - Per validation step average loss is 0.0020606722682714462\n",
      "07/18/2023 19:54:07 - INFO - __main__ - Cumulative validation average loss is 2.1323980669258162\n",
      "07/18/2023 19:54:07 - INFO - __main__ - Average validation loss for Epoch 81 is 0.1776998389104847\n",
      "07/18/2023 19:54:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:54:19 - INFO - __main__ - Starting epoch 82\n",
      "07/18/2023 19:54:20 - INFO - __main__ - train loss is 0.023229237645864487\n",
      "Steps:  53%|▌| 7955/15000 [50:58<9:36:36,  4.91s/it, lr=9.57e-6, step_loss=0.02307/18/2023 19:54:20 - INFO - __main__ - train loss is 0.1690572015941143\n",
      "Steps:  53%|▌| 7956/15000 [50:58<6:49:51,  3.49s/it, lr=9.57e-6, step_loss=0.14607/18/2023 19:54:20 - INFO - __main__ - train loss is 0.24596751853823662\n",
      "Steps:  53%|▌| 7957/15000 [50:58<4:53:06,  2.50s/it, lr=9.57e-6, step_loss=0.07607/18/2023 19:54:21 - INFO - __main__ - train loss is 0.25064518209546804\n",
      "Steps:  53%|▌| 7958/15000 [50:58<3:31:24,  1.80s/it, lr=9.57e-6, step_loss=0.00407/18/2023 19:54:21 - INFO - __main__ - train loss is 0.6794541692361236\n",
      "Steps:  53%|▌| 7959/15000 [50:59<2:34:18,  1.31s/it, lr=9.57e-6, step_loss=0.42907/18/2023 19:54:21 - INFO - __main__ - train loss is 0.6865726942196488\n",
      "Steps:  53%|▌| 7960/15000 [50:59<1:54:19,  1.03it/s, lr=9.57e-6, step_loss=0.00707/18/2023 19:54:21 - INFO - __main__ - train loss is 1.1188637847080827\n",
      "Steps:  53%|▌| 7961/15000 [50:59<1:26:21,  1.36it/s, lr=9.57e-6, step_loss=0.43207/18/2023 19:54:21 - INFO - __main__ - train loss is 1.121525171212852\n",
      "Steps:  53%|▌| 7962/15000 [50:59<1:06:42,  1.76it/s, lr=9.57e-6, step_loss=0.00207/18/2023 19:54:21 - INFO - __main__ - train loss is 1.5032316474243999\n",
      "Steps:  53%|█ | 7963/15000 [50:59<53:05,  2.21it/s, lr=9.57e-6, step_loss=0.382]07/18/2023 19:54:22 - INFO - __main__ - train loss is 1.591909828595817\n",
      "Steps:  53%|▌| 7964/15000 [51:00<43:24,  2.70it/s, lr=9.57e-6, step_loss=0.0887]07/18/2023 19:54:22 - INFO - __main__ - train loss is 1.620098521001637\n",
      "Steps:  53%|▌| 7965/15000 [51:00<36:37,  3.20it/s, lr=9.57e-6, step_loss=0.0282]07/18/2023 19:54:22 - INFO - __main__ - train loss is 1.8201603339985013\n",
      "Steps:  53%|██  | 7966/15000 [51:00<31:52,  3.68it/s, lr=9.57e-6, step_loss=0.2]07/18/2023 19:54:22 - INFO - __main__ - train loss is 1.930256818421185\n",
      "Steps:  53%|█▌ | 7967/15000 [51:00<28:33,  4.10it/s, lr=9.57e-6, step_loss=0.11]07/18/2023 19:54:22 - INFO - __main__ - train loss is 1.9366839649155736\n",
      "Steps:  53%|▌| 7968/15000 [51:00<26:14,  4.47it/s, lr=9.57e-6, step_loss=0.0064307/18/2023 19:54:23 - INFO - __main__ - train loss is 1.9524278054013848\n",
      "Steps:  53%|▌| 7969/15000 [51:00<24:38,  4.76it/s, lr=9.57e-6, step_loss=0.0157]07/18/2023 19:54:23 - INFO - __main__ - train loss is 1.959287085570395\n",
      "Steps:  53%|▌| 7970/15000 [51:01<23:36,  4.96it/s, lr=9.57e-6, step_loss=0.0068607/18/2023 19:54:23 - INFO - __main__ - train loss is 1.975888534449041\n",
      "Steps:  53%|▌| 7971/15000 [51:01<23:02,  5.09it/s, lr=9.57e-6, step_loss=0.0166]07/18/2023 19:54:23 - INFO - __main__ - train loss is 1.9922621240839362\n",
      "Steps:  53%|▌| 7972/15000 [51:01<22:27,  5.21it/s, lr=9.57e-6, step_loss=0.0164]07/18/2023 19:54:23 - INFO - __main__ - train loss is 2.001726506277919\n",
      "Steps:  53%|▌| 7973/15000 [51:01<22:11,  5.28it/s, lr=9.57e-6, step_loss=0.0094607/18/2023 19:54:23 - INFO - __main__ - train loss is 2.011577134951949\n",
      "Steps:  53%|▌| 7974/15000 [51:01<21:52,  5.35it/s, lr=9.57e-6, step_loss=0.0098507/18/2023 19:54:24 - INFO - __main__ - train loss is 2.057278508320451\n",
      "Steps:  53%|▌| 7975/15000 [51:02<21:35,  5.42it/s, lr=9.57e-6, step_loss=0.0457]07/18/2023 19:54:24 - INFO - __main__ - train loss is 2.096473215147853\n",
      "Steps:  53%|▌| 7976/15000 [51:02<21:22,  5.48it/s, lr=9.57e-6, step_loss=0.0392]07/18/2023 19:54:24 - INFO - __main__ - train loss is 2.10176905291155\n",
      "Steps:  53%|▌| 7977/15000 [51:02<21:13,  5.52it/s, lr=9.57e-6, step_loss=0.0053]07/18/2023 19:54:24 - INFO - __main__ - train loss is 2.294536017347127\n",
      "Steps:  53%|█ | 7978/15000 [51:02<21:08,  5.54it/s, lr=9.57e-6, step_loss=0.193]07/18/2023 19:54:24 - INFO - __main__ - train loss is 3.1490069259889424\n",
      "Steps:  53%|█ | 7979/15000 [51:02<21:04,  5.55it/s, lr=9.57e-6, step_loss=0.854]07/18/2023 19:54:25 - INFO - __main__ - train loss is 3.164885595906526\n",
      "Steps:  53%|▌| 7980/15000 [51:02<21:01,  5.57it/s, lr=9.57e-6, step_loss=0.0159]07/18/2023 19:54:25 - INFO - __main__ - train loss is 3.2749143098481\n",
      "Steps:  53%|█▌ | 7981/15000 [51:03<20:58,  5.58it/s, lr=9.57e-6, step_loss=0.11]07/18/2023 19:54:25 - INFO - __main__ - train loss is 3.5568735455162823\n",
      "Steps:  53%|█ | 7982/15000 [51:03<20:57,  5.58it/s, lr=9.57e-6, step_loss=0.282]07/18/2023 19:54:25 - INFO - __main__ - train loss is 3.5993743469007313\n",
      "Steps:  53%|▌| 7983/15000 [51:03<20:56,  5.59it/s, lr=9.57e-6, step_loss=0.0425]07/18/2023 19:54:25 - INFO - __main__ - train loss is 3.6039141002111137\n",
      "Steps:  53%|▌| 7984/15000 [51:03<20:53,  5.59it/s, lr=9.57e-6, step_loss=0.0045407/18/2023 19:54:25 - INFO - __main__ - train loss is 3.6153158373199403\n",
      "Steps:  53%|▌| 7985/15000 [51:03<20:54,  5.59it/s, lr=9.57e-6, step_loss=0.0114]07/18/2023 19:54:26 - INFO - __main__ - train loss is 3.9092598981224\n",
      "Steps:  53%|█ | 7986/15000 [51:03<20:53,  5.59it/s, lr=9.57e-6, step_loss=0.294]07/18/2023 19:54:26 - INFO - __main__ - train loss is 3.9571416466496885\n",
      "Steps:  53%|▌| 7987/15000 [51:04<20:52,  5.60it/s, lr=9.57e-6, step_loss=0.0479]07/18/2023 19:54:26 - INFO - __main__ - train loss is 3.9637232711538672\n",
      "Steps:  53%|▌| 7988/15000 [51:04<20:53,  5.59it/s, lr=9.57e-6, step_loss=0.0065807/18/2023 19:54:26 - INFO - __main__ - train loss is 4.1080722799524665\n",
      "Steps:  53%|█ | 7989/15000 [51:04<20:53,  5.59it/s, lr=9.57e-6, step_loss=0.144]07/18/2023 19:54:26 - INFO - __main__ - train loss is 4.124049703590572\n",
      "Steps:  53%|█ | 7990/15000 [51:04<20:53,  5.59it/s, lr=9.57e-6, step_loss=0.016]07/18/2023 19:54:27 - INFO - __main__ - train loss is 4.132730522193015\n",
      "Steps:  53%|▌| 7991/15000 [51:04<20:54,  5.59it/s, lr=9.57e-6, step_loss=0.0086807/18/2023 19:54:27 - INFO - __main__ - train loss is 4.144741341471672\n",
      "Steps:  53%|█ | 7992/15000 [51:05<20:53,  5.59it/s, lr=9.57e-6, step_loss=0.012]07/18/2023 19:54:27 - INFO - __main__ - train loss is 4.352484002709389\n",
      "Steps:  53%|█ | 7993/15000 [51:05<20:52,  5.59it/s, lr=9.57e-6, step_loss=0.208]07/18/2023 19:54:27 - INFO - __main__ - train loss is 4.38411320745945\n",
      "Steps:  53%|▌| 7994/15000 [51:05<20:52,  5.60it/s, lr=9.57e-6, step_loss=0.0316]07/18/2023 19:54:27 - INFO - __main__ - train loss is 4.386109294369817\n",
      "Steps:  53%|█ | 7995/15000 [51:05<20:51,  5.60it/s, lr=9.57e-6, step_loss=0.002]07/18/2023 19:54:27 - INFO - __main__ - train loss is 4.527304144576192\n",
      "Steps:  53%|█ | 7996/15000 [51:05<20:50,  5.60it/s, lr=9.57e-6, step_loss=0.141]07/18/2023 19:54:28 - INFO - __main__ - train loss is 4.573855379596353\n",
      "Steps:  53%|▌| 7997/15000 [51:05<20:49,  5.60it/s, lr=9.57e-6, step_loss=0.0466]07/18/2023 19:54:28 - INFO - __main__ - train loss is 4.721397975459695\n",
      "Steps:  53%|█ | 7998/15000 [51:06<20:49,  5.61it/s, lr=9.57e-6, step_loss=0.148]07/18/2023 19:54:28 - INFO - __main__ - train loss is 4.749886339530349\n",
      "Steps:  53%|▌| 7999/15000 [51:06<20:49,  5.61it/s, lr=9.57e-6, step_loss=0.0285]07/18/2023 19:54:28 - INFO - __main__ - train loss is 5.352681642398238\n",
      "Steps:  53%|▌| 8000/15000 [51:06<20:48,  5.61it/s, lr=9.57e-6, step_loss=0.0285]07/18/2023 19:54:28 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-8000\n",
      "07/18/2023 19:54:28 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:54:28,695] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:54:28,699] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-8000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:54:28,699] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-8000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:54:28,708] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-8000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:54:28,708] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-8000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:54:28,732] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-8000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:54:28,732] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-8000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:54:28,732] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:54:28 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-8000/pytorch_model\n",
      "07/18/2023 19:54:28 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-8000/scheduler.bin\n",
      "07/18/2023 19:54:28 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-8000/random_states_0.pkl\n",
      "07/18/2023 19:54:28 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-8000\n",
      "Steps:  53%|█ | 8000/15000 [51:06<20:48,  5.61it/s, lr=9.57e-6, step_loss=0.603]07/18/2023 19:54:28 - INFO - __main__ - train loss is 5.366733831353486\n",
      "Steps:  53%|▌| 8001/15000 [51:06<22:10,  5.26it/s, lr=9.57e-6, step_loss=0.0141]07/18/2023 19:54:29 - INFO - __main__ - train loss is 5.3793303314596415\n",
      "Steps:  53%|▌| 8002/15000 [51:06<21:45,  5.36it/s, lr=9.57e-6, step_loss=0.0126]07/18/2023 19:54:29 - INFO - __main__ - train loss is 5.382535641314462\n",
      "Steps:  53%|▌| 8003/15000 [51:07<21:28,  5.43it/s, lr=9.57e-6, step_loss=0.0032107/18/2023 19:54:29 - INFO - __main__ - train loss is 5.439881813945249\n",
      "Steps:  53%|▌| 8004/15000 [51:07<21:16,  5.48it/s, lr=9.57e-6, step_loss=0.0573]07/18/2023 19:54:29 - INFO - __main__ - train loss is 5.603788283886388\n",
      "Steps:  53%|█ | 8005/15000 [51:07<21:08,  5.52it/s, lr=9.57e-6, step_loss=0.164]07/18/2023 19:54:29 - INFO - __main__ - train loss is 5.608039852930233\n",
      "Steps:  53%|▌| 8006/15000 [51:07<21:01,  5.54it/s, lr=9.57e-6, step_loss=0.0042507/18/2023 19:54:29 - INFO - __main__ - train loss is 5.6165495223831385\n",
      "Steps:  53%|▌| 8007/15000 [51:07<20:57,  5.56it/s, lr=9.57e-6, step_loss=0.0085107/18/2023 19:54:30 - INFO - __main__ - train loss is 5.8562733985017985\n",
      "Steps:  53%|█▌ | 8008/15000 [51:07<20:54,  5.57it/s, lr=9.57e-6, step_loss=0.24]07/18/2023 19:54:30 - INFO - __main__ - train loss is 5.927952245576307\n",
      "Steps:  53%|▌| 8009/15000 [51:08<20:53,  5.58it/s, lr=9.57e-6, step_loss=0.0717]07/18/2023 19:54:30 - INFO - __main__ - train loss is 5.933697137748823\n",
      "Steps:  53%|▌| 8010/15000 [51:08<21:46,  5.35it/s, lr=9.57e-6, step_loss=0.0057407/18/2023 19:54:30 - INFO - __main__ - train loss is 5.935295903356746\n",
      "Steps:  53%|▌| 8011/15000 [51:08<21:30,  5.41it/s, lr=9.57e-6, step_loss=0.0016]07/18/2023 19:54:30 - INFO - __main__ - train loss is 6.003400624962524\n",
      "Steps:  53%|▌| 8012/15000 [51:08<21:19,  5.46it/s, lr=9.57e-6, step_loss=0.0681]07/18/2023 19:54:30 - INFO - __main__ - train loss is 6.64513707277365\n",
      "Steps:  53%|█ | 8013/15000 [51:08<21:10,  5.50it/s, lr=9.57e-6, step_loss=0.642]07/18/2023 19:54:31 - INFO - __main__ - train loss is 6.892701567383483\n",
      "Steps:  53%|█ | 8014/15000 [51:09<21:04,  5.53it/s, lr=9.57e-6, step_loss=0.248]07/18/2023 19:54:31 - INFO - __main__ - train loss is 6.9283245888073\n",
      "Steps:  53%|▌| 8015/15000 [51:09<20:59,  5.54it/s, lr=9.57e-6, step_loss=0.0356]07/18/2023 19:54:31 - INFO - __main__ - train loss is 7.2679819848854095\n",
      "Steps:  53%|█▌ | 8016/15000 [51:09<20:56,  5.56it/s, lr=9.57e-6, step_loss=0.34]07/18/2023 19:54:31 - INFO - __main__ - train loss is 7.329051443608478\n",
      "Steps:  53%|▌| 8017/15000 [51:09<20:53,  5.57it/s, lr=9.57e-6, step_loss=0.0611]07/18/2023 19:54:31 - INFO - __main__ - train loss is 7.566756957443431\n",
      "Steps:  53%|█ | 8018/15000 [51:09<20:51,  5.58it/s, lr=9.57e-6, step_loss=0.238]07/18/2023 19:54:32 - INFO - __main__ - train loss is 7.679619358154014\n",
      "Steps:  53%|█ | 8019/15000 [51:09<20:51,  5.58it/s, lr=9.57e-6, step_loss=0.113]07/18/2023 19:54:32 - INFO - __main__ - train loss is 8.057681665988639\n",
      "Steps:  53%|█ | 8020/15000 [51:10<20:50,  5.58it/s, lr=9.57e-6, step_loss=0.378]07/18/2023 19:54:32 - INFO - __main__ - train loss is 8.175526113482192\n",
      "Steps:  53%|█ | 8021/15000 [51:10<20:49,  5.59it/s, lr=9.57e-6, step_loss=0.118]07/18/2023 19:54:32 - INFO - __main__ - train loss is 8.181169997202232\n",
      "Steps:  53%|▌| 8022/15000 [51:10<20:48,  5.59it/s, lr=9.57e-6, step_loss=0.0056407/18/2023 19:54:32 - INFO - __main__ - train loss is 8.194121681386605\n",
      "Steps:  53%|█ | 8023/15000 [51:10<20:49,  5.59it/s, lr=9.57e-6, step_loss=0.013]07/18/2023 19:54:32 - INFO - __main__ - train loss is 8.22225552634336\n",
      "Steps:  53%|▌| 8024/15000 [51:10<21:00,  5.54it/s, lr=9.57e-6, step_loss=0.0281]07/18/2023 19:54:33 - INFO - __main__ - train loss is 8.28033926920034\n",
      "Steps:  54%|▌| 8025/15000 [51:11<21:00,  5.53it/s, lr=9.57e-6, step_loss=0.0581]07/18/2023 19:54:33 - INFO - __main__ - train loss is 8.285278469091281\n",
      "Steps:  54%|▌| 8026/15000 [51:11<20:58,  5.54it/s, lr=9.57e-6, step_loss=0.0049407/18/2023 19:54:33 - INFO - __main__ - train loss is 8.39557021833025\n",
      "Steps:  54%|█▌ | 8027/15000 [51:11<20:54,  5.56it/s, lr=9.57e-6, step_loss=0.11]07/18/2023 19:54:33 - INFO - __main__ - train loss is 8.905486941104755\n",
      "Steps:  54%|█▌ | 8028/15000 [51:11<20:52,  5.57it/s, lr=9.57e-6, step_loss=0.51]07/18/2023 19:54:33 - INFO - __main__ - train loss is 9.10516458726488\n",
      "Steps:  54%|██▏ | 8029/15000 [51:11<20:50,  5.57it/s, lr=9.57e-6, step_loss=0.2]07/18/2023 19:54:34 - INFO - __main__ - train loss is 9.18947910494171\n",
      "Steps:  54%|▌| 8030/15000 [51:11<20:49,  5.58it/s, lr=9.57e-6, step_loss=0.0843]07/18/2023 19:54:34 - INFO - __main__ - train loss is 9.5867040080484\n",
      "Steps:  54%|█ | 8031/15000 [51:12<20:47,  5.59it/s, lr=9.57e-6, step_loss=0.397]07/18/2023 19:54:34 - INFO - __main__ - train loss is 9.621796577936038\n",
      "Steps:  54%|▌| 8032/15000 [51:12<20:59,  5.53it/s, lr=9.57e-6, step_loss=0.0351]07/18/2023 19:54:34 - INFO - __main__ - train loss is 9.824149220949039\n",
      "Steps:  54%|█ | 8033/15000 [51:12<21:17,  5.45it/s, lr=9.57e-6, step_loss=0.202]07/18/2023 19:54:34 - INFO - __main__ - train loss is 9.831075072987005\n",
      "Steps:  54%|▌| 8034/15000 [51:12<21:07,  5.50it/s, lr=9.57e-6, step_loss=0.0069307/18/2023 19:54:34 - INFO - __main__ - train loss is 9.84398381668143\n",
      "Steps:  54%|▌| 8035/15000 [51:12<21:11,  5.48it/s, lr=9.57e-6, step_loss=0.0129]07/18/2023 19:54:35 - INFO - __main__ - train loss is 9.887829365907237\n",
      "Steps:  54%|▌| 8036/15000 [51:13<21:24,  5.42it/s, lr=9.57e-6, step_loss=0.0438]07/18/2023 19:54:35 - INFO - __main__ - train loss is 10.453086080728099\n",
      "Steps:  54%|█ | 8037/15000 [51:13<21:16,  5.46it/s, lr=9.57e-6, step_loss=0.565]07/18/2023 19:54:35 - INFO - __main__ - train loss is 10.461733313975856\n",
      "Steps:  54%|▌| 8038/15000 [51:13<21:19,  5.44it/s, lr=9.57e-6, step_loss=0.0086507/18/2023 19:54:35 - INFO - __main__ - train loss is 10.575285243568942\n",
      "Steps:  54%|█ | 8039/15000 [51:13<21:16,  5.45it/s, lr=9.57e-6, step_loss=0.114]07/18/2023 19:54:35 - INFO - __main__ - train loss is 10.70058752852492\n",
      "Steps:  54%|█ | 8040/15000 [51:13<21:05,  5.50it/s, lr=9.57e-6, step_loss=0.125]07/18/2023 19:54:36 - INFO - __main__ - train loss is 10.764643410919234\n",
      "Steps:  54%|▌| 8041/15000 [51:13<20:57,  5.54it/s, lr=9.57e-6, step_loss=0.0641]07/18/2023 19:54:36 - INFO - __main__ - train loss is 10.838658268330619\n",
      "Steps:  54%|█ | 8042/15000 [51:14<20:52,  5.56it/s, lr=9.56e-6, step_loss=0.074]07/18/2023 19:54:36 - INFO - __main__ - train loss is 10.84043716499582\n",
      "Steps:  54%|▌| 8043/15000 [51:14<20:49,  5.57it/s, lr=9.56e-6, step_loss=0.0017807/18/2023 19:54:36 - INFO - __main__ - train loss is 10.881760502699763\n",
      "Steps:  54%|▌| 8044/15000 [51:14<20:46,  5.58it/s, lr=9.56e-6, step_loss=0.0413]07/18/2023 19:54:36 - INFO - __main__ - train loss is 10.926892856601626\n",
      "Steps:  54%|▌| 8045/15000 [51:14<20:44,  5.59it/s, lr=9.56e-6, step_loss=0.0451]07/18/2023 19:54:36 - INFO - __main__ - train loss is 11.296879450324923\n",
      "Steps:  54%|█▌ | 8046/15000 [51:14<20:43,  5.59it/s, lr=9.56e-6, step_loss=0.37]07/18/2023 19:54:37 - INFO - __main__ - train loss is 11.485153193119913\n",
      "Steps:  54%|█ | 8047/15000 [51:15<20:50,  5.56it/s, lr=9.56e-6, step_loss=0.188]07/18/2023 19:54:37 - INFO - __main__ - train loss is 11.682599613908678\n",
      "Steps:  54%|█ | 8048/15000 [51:15<20:46,  5.58it/s, lr=9.56e-6, step_loss=0.197]07/18/2023 19:54:37 - INFO - __main__ - train loss is 11.742453815881163\n",
      "Steps:  54%|▌| 8049/15000 [51:15<20:43,  5.59it/s, lr=9.56e-6, step_loss=0.0599]07/18/2023 19:54:37 - INFO - __main__ - train loss is 11.808026450220495\n",
      "Steps:  54%|▌| 8050/15000 [51:15<20:53,  5.54it/s, lr=9.56e-6, step_loss=0.0656]07/18/2023 19:54:38 - INFO - __main__ - train loss is 11.892696353141218\n",
      "Steps:  54%|▌| 8051/15000 [51:15<28:10,  4.11it/s, lr=9.56e-6, step_loss=0.0847]07/18/2023 19:54:38 - INFO - __main__ - Per validation step average loss is 0.0014184785541146994\n",
      "07/18/2023 19:54:38 - INFO - __main__ - Cumulative validation average loss is 0.0014184785541146994\n",
      "07/18/2023 19:54:38 - INFO - __main__ - Per validation step average loss is 0.13142597675323486\n",
      "07/18/2023 19:54:38 - INFO - __main__ - Cumulative validation average loss is 0.13284445530734956\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Per validation step average loss is 0.14265179634094238\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Cumulative validation average loss is 0.27549625164829195\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Per validation step average loss is 0.04283132031559944\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Cumulative validation average loss is 0.3183275719638914\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Per validation step average loss is 0.2633722424507141\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Cumulative validation average loss is 0.5816998144146055\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Per validation step average loss is 0.3450177311897278\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Cumulative validation average loss is 0.9267175456043333\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Per validation step average loss is 0.009665376506745815\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Cumulative validation average loss is 0.9363829221110791\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Per validation step average loss is 0.19953781366348267\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Cumulative validation average loss is 1.1359207357745618\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Per validation step average loss is 0.2840868830680847\n",
      "07/18/2023 19:54:39 - INFO - __main__ - Cumulative validation average loss is 1.4200076188426465\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Per validation step average loss is 0.10272956639528275\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Cumulative validation average loss is 1.5227371852379292\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Per validation step average loss is 0.1976587474346161\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Cumulative validation average loss is 1.7203959326725453\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Per validation step average loss is 0.020091067999601364\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Cumulative validation average loss is 1.7404870006721467\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Average validation loss for Epoch 82 is 0.14504058338934556\n",
      "07/18/2023 19:54:40 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:54:53 - INFO - __main__ - Starting epoch 83\n",
      "07/18/2023 19:54:53 - INFO - __main__ - train loss is 0.18993225693702698\n",
      "Steps:  54%|▌| 8052/15000 [51:31<9:29:07,  4.91s/it, lr=9.56e-6, step_loss=0.19]07/18/2023 19:54:54 - INFO - __main__ - train loss is 0.520270586013794\n",
      "Steps:  54%|▌| 8053/15000 [51:31<6:44:36,  3.49s/it, lr=9.56e-6, step_loss=0.33]07/18/2023 19:54:54 - INFO - __main__ - train loss is 0.5390832480043173\n",
      "Steps:  54%|▌| 8054/15000 [51:32<4:49:22,  2.50s/it, lr=9.56e-6, step_loss=0.01807/18/2023 19:54:54 - INFO - __main__ - train loss is 0.82433564029634\n",
      "Steps:  54%|▌| 8055/15000 [51:32<3:28:42,  1.80s/it, lr=9.56e-6, step_loss=0.28507/18/2023 19:54:54 - INFO - __main__ - train loss is 1.386377876624465\n",
      "Steps:  54%|▌| 8056/15000 [51:32<2:32:20,  1.32s/it, lr=9.56e-6, step_loss=0.56207/18/2023 19:54:54 - INFO - __main__ - train loss is 1.9810169395059347\n",
      "Steps:  54%|▌| 8057/15000 [51:32<1:52:49,  1.03it/s, lr=9.56e-6, step_loss=0.59507/18/2023 19:54:54 - INFO - __main__ - train loss is 2.0297448206692934\n",
      "Steps:  54%|▌| 8058/15000 [51:32<1:25:09,  1.36it/s, lr=9.56e-6, step_loss=0.04807/18/2023 19:54:55 - INFO - __main__ - train loss is 2.0440815780311823\n",
      "Steps:  54%|▌| 8059/15000 [51:33<1:05:46,  1.76it/s, lr=9.56e-6, step_loss=0.01407/18/2023 19:54:55 - INFO - __main__ - train loss is 2.045667211874388\n",
      "Steps:  54%|▌| 8060/15000 [51:33<52:11,  2.22it/s, lr=9.56e-6, step_loss=0.0015907/18/2023 19:54:55 - INFO - __main__ - train loss is 2.048373043886386\n",
      "Steps:  54%|▌| 8061/15000 [51:33<42:44,  2.71it/s, lr=9.56e-6, step_loss=0.0027107/18/2023 19:54:55 - INFO - __main__ - train loss is 2.0501192420488223\n",
      "Steps:  54%|▌| 8062/15000 [51:33<36:05,  3.20it/s, lr=9.56e-6, step_loss=0.0017507/18/2023 19:54:55 - INFO - __main__ - train loss is 2.0695648848777637\n",
      "Steps:  54%|▌| 8063/15000 [51:33<31:24,  3.68it/s, lr=9.56e-6, step_loss=0.0194]07/18/2023 19:54:56 - INFO - __main__ - train loss is 2.0720946242799982\n",
      "Steps:  54%|▌| 8064/15000 [51:33<28:10,  4.10it/s, lr=9.56e-6, step_loss=0.0025307/18/2023 19:54:56 - INFO - __main__ - train loss is 2.081184563576244\n",
      "Steps:  54%|▌| 8065/15000 [51:34<26:01,  4.44it/s, lr=9.56e-6, step_loss=0.0090907/18/2023 19:54:56 - INFO - __main__ - train loss is 2.092074999003671\n",
      "Steps:  54%|▌| 8066/15000 [51:34<24:24,  4.73it/s, lr=9.56e-6, step_loss=0.0109]07/18/2023 19:54:56 - INFO - __main__ - train loss is 2.3850338546326384\n",
      "Steps:  54%|█ | 8067/15000 [51:34<23:15,  4.97it/s, lr=9.56e-6, step_loss=0.293]07/18/2023 19:54:56 - INFO - __main__ - train loss is 2.647688933997415\n",
      "Steps:  54%|█ | 8068/15000 [51:34<22:26,  5.15it/s, lr=9.56e-6, step_loss=0.263]07/18/2023 19:54:56 - INFO - __main__ - train loss is 2.7715365228941664\n",
      "Steps:  54%|█ | 8069/15000 [51:34<21:53,  5.28it/s, lr=9.56e-6, step_loss=0.124]07/18/2023 19:54:57 - INFO - __main__ - train loss is 2.824472193955444\n",
      "Steps:  54%|▌| 8070/15000 [51:34<21:30,  5.37it/s, lr=9.56e-6, step_loss=0.0529]07/18/2023 19:54:57 - INFO - __main__ - train loss is 2.8262621453031898\n",
      "Steps:  54%|▌| 8071/15000 [51:35<21:14,  5.44it/s, lr=9.56e-6, step_loss=0.0017907/18/2023 19:54:57 - INFO - __main__ - train loss is 2.830067675327882\n",
      "Steps:  54%|▌| 8072/15000 [51:35<21:03,  5.49it/s, lr=9.56e-6, step_loss=0.0038107/18/2023 19:54:57 - INFO - __main__ - train loss is 2.8672635739203542\n",
      "Steps:  54%|▌| 8073/15000 [51:35<20:55,  5.52it/s, lr=9.56e-6, step_loss=0.0372]07/18/2023 19:54:57 - INFO - __main__ - train loss is 2.88271870999597\n",
      "Steps:  54%|▌| 8074/15000 [51:35<21:00,  5.49it/s, lr=9.56e-6, step_loss=0.0155]07/18/2023 19:54:57 - INFO - __main__ - train loss is 3.04553204565309\n",
      "Steps:  54%|█ | 8075/15000 [51:35<21:05,  5.47it/s, lr=9.56e-6, step_loss=0.163]07/18/2023 19:54:58 - INFO - __main__ - train loss is 3.0535037161316723\n",
      "Steps:  54%|▌| 8076/15000 [51:36<21:07,  5.46it/s, lr=9.56e-6, step_loss=0.0079707/18/2023 19:54:58 - INFO - __main__ - train loss is 3.056655831867829\n",
      "Steps:  54%|▌| 8077/15000 [51:36<21:13,  5.44it/s, lr=9.56e-6, step_loss=0.0031507/18/2023 19:54:58 - INFO - __main__ - train loss is 3.1548883395735174\n",
      "Steps:  54%|▌| 8078/15000 [51:36<21:06,  5.47it/s, lr=9.56e-6, step_loss=0.0982]07/18/2023 19:54:58 - INFO - __main__ - train loss is 3.216273125493899\n",
      "Steps:  54%|▌| 8079/15000 [51:36<21:05,  5.47it/s, lr=9.56e-6, step_loss=0.0614]07/18/2023 19:54:58 - INFO - __main__ - train loss is 3.2345225086901337\n",
      "Steps:  54%|▌| 8080/15000 [51:36<21:07,  5.46it/s, lr=9.56e-6, step_loss=0.0182]07/18/2023 19:54:59 - INFO - __main__ - train loss is 3.52598493010737\n",
      "Steps:  54%|█ | 8081/15000 [51:36<21:10,  5.45it/s, lr=9.56e-6, step_loss=0.291]07/18/2023 19:54:59 - INFO - __main__ - train loss is 3.529553438303992\n",
      "Steps:  54%|▌| 8082/15000 [51:37<21:11,  5.44it/s, lr=9.56e-6, step_loss=0.0035707/18/2023 19:54:59 - INFO - __main__ - train loss is 3.544683239189908\n",
      "Steps:  54%|▌| 8083/15000 [51:37<21:04,  5.47it/s, lr=9.56e-6, step_loss=0.0151]07/18/2023 19:54:59 - INFO - __main__ - train loss is 3.616037345258519\n",
      "Steps:  54%|▌| 8084/15000 [51:37<20:55,  5.51it/s, lr=9.56e-6, step_loss=0.0714]07/18/2023 19:54:59 - INFO - __main__ - train loss is 4.301876998273656\n",
      "Steps:  54%|█ | 8085/15000 [51:37<20:49,  5.53it/s, lr=9.56e-6, step_loss=0.686]07/18/2023 19:54:59 - INFO - __main__ - train loss is 4.382085582939908\n",
      "Steps:  54%|▌| 8086/15000 [51:37<20:57,  5.50it/s, lr=9.56e-6, step_loss=0.0802]07/18/2023 19:55:00 - INFO - __main__ - train loss is 4.384158297907561\n",
      "Steps:  54%|▌| 8087/15000 [51:38<21:05,  5.46it/s, lr=9.56e-6, step_loss=0.0020707/18/2023 19:55:00 - INFO - __main__ - train loss is 4.390443246811628\n",
      "Steps:  54%|▌| 8088/15000 [51:38<21:15,  5.42it/s, lr=9.56e-6, step_loss=0.0062807/18/2023 19:55:00 - INFO - __main__ - train loss is 4.447166848927736\n",
      "Steps:  54%|▌| 8089/15000 [51:38<21:09,  5.44it/s, lr=9.56e-6, step_loss=0.0567]07/18/2023 19:55:00 - INFO - __main__ - train loss is 4.449087353888899\n",
      "Steps:  54%|▌| 8090/15000 [51:38<20:59,  5.49it/s, lr=9.56e-6, step_loss=0.0019207/18/2023 19:55:00 - INFO - __main__ - train loss is 4.649010690394789\n",
      "Steps:  54%|██▏ | 8091/15000 [51:38<20:52,  5.52it/s, lr=9.56e-6, step_loss=0.2]07/18/2023 19:55:01 - INFO - __main__ - train loss is 4.759977834764868\n",
      "Steps:  54%|█ | 8092/15000 [51:38<20:57,  5.50it/s, lr=9.56e-6, step_loss=0.111]07/18/2023 19:55:01 - INFO - __main__ - train loss is 5.145659821573645\n",
      "Steps:  54%|█ | 8093/15000 [51:39<20:49,  5.53it/s, lr=9.56e-6, step_loss=0.386]07/18/2023 19:55:01 - INFO - __main__ - train loss is 5.484704928938299\n",
      "Steps:  54%|█ | 8094/15000 [51:39<20:43,  5.55it/s, lr=9.56e-6, step_loss=0.339]07/18/2023 19:55:01 - INFO - __main__ - train loss is 5.493949428666383\n",
      "Steps:  54%|▌| 8095/15000 [51:39<20:40,  5.57it/s, lr=9.56e-6, step_loss=0.0092407/18/2023 19:55:01 - INFO - __main__ - train loss is 5.5151665979065\n",
      "Steps:  54%|▌| 8096/15000 [51:39<20:39,  5.57it/s, lr=9.56e-6, step_loss=0.0212]07/18/2023 19:55:01 - INFO - __main__ - train loss is 5.86521257692948\n",
      "Steps:  54%|█▌ | 8097/15000 [51:39<20:38,  5.57it/s, lr=9.56e-6, step_loss=0.35]07/18/2023 19:55:02 - INFO - __main__ - train loss is 5.967349948827177\n",
      "Steps:  54%|█ | 8098/15000 [51:40<20:49,  5.52it/s, lr=9.56e-6, step_loss=0.102]07/18/2023 19:55:02 - INFO - __main__ - train loss is 6.3391204797662795\n",
      "Steps:  54%|█ | 8099/15000 [51:40<20:59,  5.48it/s, lr=9.56e-6, step_loss=0.372]07/18/2023 19:55:02 - INFO - __main__ - train loss is 6.341141167562455\n",
      "Steps:  54%|▌| 8100/15000 [51:40<20:51,  5.51it/s, lr=9.56e-6, step_loss=0.0020207/18/2023 19:55:02 - INFO - __main__ - train loss is 6.529223594348878\n",
      "Steps:  54%|█ | 8101/15000 [51:40<20:45,  5.54it/s, lr=9.56e-6, step_loss=0.188]07/18/2023 19:55:02 - INFO - __main__ - train loss is 6.813763919752091\n",
      "Steps:  54%|█ | 8102/15000 [51:40<20:44,  5.54it/s, lr=9.56e-6, step_loss=0.285]07/18/2023 19:55:03 - INFO - __main__ - train loss is 6.816568217473105\n",
      "Steps:  54%|▌| 8103/15000 [51:40<20:41,  5.56it/s, lr=9.56e-6, step_loss=0.0028]07/18/2023 19:55:03 - INFO - __main__ - train loss is 6.817979603889398\n",
      "Steps:  54%|▌| 8104/15000 [51:41<20:40,  5.56it/s, lr=9.56e-6, step_loss=0.0014107/18/2023 19:55:03 - INFO - __main__ - train loss is 7.4282002745894715\n",
      "Steps:  54%|█▌ | 8105/15000 [51:41<20:37,  5.57it/s, lr=9.56e-6, step_loss=0.61]07/18/2023 19:55:03 - INFO - __main__ - train loss is 7.431973719620146\n",
      "Steps:  54%|▌| 8106/15000 [51:41<20:38,  5.57it/s, lr=9.56e-6, step_loss=0.0037707/18/2023 19:55:03 - INFO - __main__ - train loss is 7.464184658252634\n",
      "Steps:  54%|▌| 8107/15000 [51:41<20:35,  5.58it/s, lr=9.56e-6, step_loss=0.0322]07/18/2023 19:55:03 - INFO - __main__ - train loss is 7.466220875154249\n",
      "Steps:  54%|▌| 8108/15000 [51:41<20:32,  5.59it/s, lr=9.56e-6, step_loss=0.0020407/18/2023 19:55:04 - INFO - __main__ - train loss is 7.498553966055624\n",
      "Steps:  54%|▌| 8109/15000 [51:42<20:31,  5.59it/s, lr=9.56e-6, step_loss=0.0323]07/18/2023 19:55:04 - INFO - __main__ - train loss is 7.502106771687977\n",
      "Steps:  54%|▌| 8110/15000 [51:42<20:39,  5.56it/s, lr=9.56e-6, step_loss=0.0035507/18/2023 19:55:04 - INFO - __main__ - train loss is 7.513091586413793\n",
      "Steps:  54%|█ | 8111/15000 [51:42<21:03,  5.45it/s, lr=9.56e-6, step_loss=0.011]07/18/2023 19:55:04 - INFO - __main__ - train loss is 7.5577367468504235\n",
      "Steps:  54%|▌| 8112/15000 [51:42<20:53,  5.50it/s, lr=9.56e-6, step_loss=0.0446]07/18/2023 19:55:04 - INFO - __main__ - train loss is 7.806486181798391\n",
      "Steps:  54%|█ | 8113/15000 [51:42<20:48,  5.52it/s, lr=9.56e-6, step_loss=0.249]07/18/2023 19:55:05 - INFO - __main__ - train loss is 8.265899233403616\n",
      "Steps:  54%|█ | 8114/15000 [51:42<20:42,  5.54it/s, lr=9.56e-6, step_loss=0.459]07/18/2023 19:55:05 - INFO - __main__ - train loss is 8.278188619646244\n",
      "Steps:  54%|▌| 8115/15000 [51:43<20:37,  5.57it/s, lr=9.56e-6, step_loss=0.0123]07/18/2023 19:55:05 - INFO - __main__ - train loss is 8.374146584304981\n",
      "Steps:  54%|█ | 8116/15000 [51:43<20:34,  5.58it/s, lr=9.56e-6, step_loss=0.096]07/18/2023 19:55:05 - INFO - __main__ - train loss is 8.394576437654905\n",
      "Steps:  54%|▌| 8117/15000 [51:43<20:32,  5.59it/s, lr=9.56e-6, step_loss=0.0204]07/18/2023 19:55:05 - INFO - __main__ - train loss is 8.425444412860088\n",
      "Steps:  54%|▌| 8118/15000 [51:43<20:31,  5.59it/s, lr=9.56e-6, step_loss=0.0309]07/18/2023 19:55:05 - INFO - __main__ - train loss is 8.642573479446582\n",
      "Steps:  54%|█ | 8119/15000 [51:43<20:29,  5.59it/s, lr=9.56e-6, step_loss=0.217]07/18/2023 19:55:06 - INFO - __main__ - train loss is 8.655016578617506\n",
      "Steps:  54%|▌| 8120/15000 [51:44<20:29,  5.60it/s, lr=9.56e-6, step_loss=0.0124]07/18/2023 19:55:06 - INFO - __main__ - train loss is 8.943433560314588\n",
      "Steps:  54%|█ | 8121/15000 [51:44<20:41,  5.54it/s, lr=9.56e-6, step_loss=0.288]07/18/2023 19:55:06 - INFO - __main__ - train loss is 9.044371820869856\n",
      "Steps:  54%|█ | 8122/15000 [51:44<21:00,  5.46it/s, lr=9.56e-6, step_loss=0.101]07/18/2023 19:55:06 - INFO - __main__ - train loss is 9.750483251991682\n",
      "Steps:  54%|█ | 8123/15000 [51:44<20:53,  5.48it/s, lr=9.56e-6, step_loss=0.706]07/18/2023 19:55:06 - INFO - __main__ - train loss is 9.75255757512059\n",
      "Steps:  54%|▌| 8124/15000 [51:44<20:46,  5.52it/s, lr=9.56e-6, step_loss=0.0020707/18/2023 19:55:07 - INFO - __main__ - train loss is 10.369549154653214\n",
      "Steps:  54%|█ | 8125/15000 [51:44<20:43,  5.53it/s, lr=9.56e-6, step_loss=0.617]07/18/2023 19:55:07 - INFO - __main__ - train loss is 10.385438205092214\n",
      "Steps:  54%|▌| 8126/15000 [51:45<20:38,  5.55it/s, lr=9.56e-6, step_loss=0.0159]07/18/2023 19:55:07 - INFO - __main__ - train loss is 10.641870946972631\n",
      "Steps:  54%|█ | 8127/15000 [51:45<20:36,  5.56it/s, lr=9.56e-6, step_loss=0.256]07/18/2023 19:55:07 - INFO - __main__ - train loss is 10.656684852554463\n",
      "Steps:  54%|▌| 8128/15000 [51:45<20:34,  5.57it/s, lr=9.56e-6, step_loss=0.0148]07/18/2023 19:55:07 - INFO - __main__ - train loss is 11.223427988006733\n",
      "Steps:  54%|█ | 8129/15000 [51:45<20:41,  5.53it/s, lr=9.56e-6, step_loss=0.567]07/18/2023 19:55:07 - INFO - __main__ - train loss is 11.384485683753155\n",
      "Steps:  54%|█ | 8130/15000 [51:45<20:37,  5.55it/s, lr=9.56e-6, step_loss=0.161]07/18/2023 19:55:08 - INFO - __main__ - train loss is 12.013855777098797\n",
      "Steps:  54%|█ | 8131/15000 [51:46<20:34,  5.56it/s, lr=9.56e-6, step_loss=0.629]07/18/2023 19:55:08 - INFO - __main__ - train loss is 12.441201678826474\n",
      "Steps:  54%|█ | 8132/15000 [51:46<20:43,  5.52it/s, lr=9.56e-6, step_loss=0.427]07/18/2023 19:55:08 - INFO - __main__ - train loss is 12.568921349360608\n",
      "Steps:  54%|█ | 8133/15000 [51:46<20:40,  5.54it/s, lr=9.56e-6, step_loss=0.128]07/18/2023 19:55:08 - INFO - __main__ - train loss is 12.632227859809063\n",
      "Steps:  54%|▌| 8134/15000 [51:46<20:34,  5.56it/s, lr=9.56e-6, step_loss=0.0633]07/18/2023 19:55:08 - INFO - __main__ - train loss is 13.167975626303814\n",
      "Steps:  54%|█ | 8135/15000 [51:46<20:33,  5.57it/s, lr=9.55e-6, step_loss=0.536]07/18/2023 19:55:09 - INFO - __main__ - train loss is 13.17608057835605\n",
      "Steps:  54%|▌| 8136/15000 [51:46<20:30,  5.58it/s, lr=9.55e-6, step_loss=0.0081]07/18/2023 19:55:09 - INFO - __main__ - train loss is 13.199376150383614\n",
      "Steps:  54%|▌| 8137/15000 [51:47<20:28,  5.59it/s, lr=9.55e-6, step_loss=0.0233]07/18/2023 19:55:09 - INFO - __main__ - train loss is 13.589608355774544\n",
      "Steps:  54%|█▋ | 8138/15000 [51:47<20:26,  5.59it/s, lr=9.55e-6, step_loss=0.39]07/18/2023 19:55:09 - INFO - __main__ - train loss is 13.868206723942421\n",
      "Steps:  54%|█ | 8139/15000 [51:47<20:25,  5.60it/s, lr=9.55e-6, step_loss=0.279]07/18/2023 19:55:09 - INFO - __main__ - train loss is 13.935732170357369\n",
      "Steps:  54%|▌| 8140/15000 [51:47<20:24,  5.60it/s, lr=9.55e-6, step_loss=0.0675]07/18/2023 19:55:09 - INFO - __main__ - train loss is 14.44325761438813\n",
      "Steps:  54%|█ | 8141/15000 [51:47<20:28,  5.59it/s, lr=9.55e-6, step_loss=0.508]07/18/2023 19:55:10 - INFO - __main__ - train loss is 14.530762656941079\n",
      "Steps:  54%|▌| 8142/15000 [51:47<20:26,  5.59it/s, lr=9.55e-6, step_loss=0.0875]07/18/2023 19:55:10 - INFO - __main__ - train loss is 14.739091321243905\n",
      "Steps:  54%|█ | 8143/15000 [51:48<20:24,  5.60it/s, lr=9.55e-6, step_loss=0.208]07/18/2023 19:55:10 - INFO - __main__ - train loss is 15.127820118679665\n",
      "Steps:  54%|█ | 8144/15000 [51:48<20:24,  5.60it/s, lr=9.55e-6, step_loss=0.389]07/18/2023 19:55:10 - INFO - __main__ - train loss is 15.133350273012184\n",
      "Steps:  54%|▌| 8145/15000 [51:48<20:23,  5.60it/s, lr=9.55e-6, step_loss=0.0055307/18/2023 19:55:10 - INFO - __main__ - train loss is 15.155738124041818\n",
      "Steps:  54%|▌| 8146/15000 [51:48<20:31,  5.57it/s, lr=9.55e-6, step_loss=0.0224]07/18/2023 19:55:10 - INFO - __main__ - train loss is 15.301913687377237\n",
      "Steps:  54%|█ | 8147/15000 [51:48<20:39,  5.53it/s, lr=9.55e-6, step_loss=0.146]07/18/2023 19:55:11 - INFO - __main__ - train loss is 15.337733195512556\n",
      "Steps:  54%|▌| 8148/15000 [51:49<28:21,  4.03it/s, lr=9.55e-6, step_loss=0.0358]07/18/2023 19:55:12 - INFO - __main__ - Per validation step average loss is 0.02673259563744068\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Cumulative validation average loss is 0.02673259563744068\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Per validation step average loss is 0.002039763145148754\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Cumulative validation average loss is 0.028772358782589436\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Per validation step average loss is 0.24718807637691498\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Cumulative validation average loss is 0.2759604351595044\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Per validation step average loss is 0.008816799148917198\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Cumulative validation average loss is 0.2847772343084216\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Per validation step average loss is 0.03082006424665451\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Cumulative validation average loss is 0.3155972985550761\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Per validation step average loss is 0.11717069894075394\n",
      "07/18/2023 19:55:12 - INFO - __main__ - Cumulative validation average loss is 0.43276799749583006\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Per validation step average loss is 0.5358471870422363\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Cumulative validation average loss is 0.9686151845380664\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Per validation step average loss is 0.1984902322292328\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Cumulative validation average loss is 1.1671054167672992\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Per validation step average loss is 0.020811347290873528\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Cumulative validation average loss is 1.1879167640581727\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Per validation step average loss is 0.1873256415128708\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Cumulative validation average loss is 1.3752424055710435\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Per validation step average loss is 0.01679006963968277\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Cumulative validation average loss is 1.3920324752107263\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Per validation step average loss is 0.5185421705245972\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Cumulative validation average loss is 1.9105746457353234\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Average validation loss for Epoch 83 is 0.15921455381127694\n",
      "07/18/2023 19:55:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:55:26 - INFO - __main__ - Starting epoch 84\n",
      "07/18/2023 19:55:27 - INFO - __main__ - train loss is 0.003541481215506792\n",
      "Steps:  54%|▌| 8149/15000 [52:05<9:19:34,  4.90s/it, lr=9.55e-6, step_loss=0.00307/18/2023 19:55:27 - INFO - __main__ - train loss is 0.44817514391615987\n",
      "Steps:  54%|▌| 8150/15000 [52:05<6:37:47,  3.48s/it, lr=9.55e-6, step_loss=0.44507/18/2023 19:55:27 - INFO - __main__ - train loss is 0.510081083048135\n",
      "Steps:  54%|▌| 8151/15000 [52:05<4:44:33,  2.49s/it, lr=9.55e-6, step_loss=0.06107/18/2023 19:55:27 - INFO - __main__ - train loss is 0.6665344540961087\n",
      "Steps:  54%|▌| 8152/15000 [52:05<3:25:15,  1.80s/it, lr=9.55e-6, step_loss=0.15607/18/2023 19:55:27 - INFO - __main__ - train loss is 0.6691958829760551\n",
      "Steps:  54%|▌| 8153/15000 [52:05<2:29:59,  1.31s/it, lr=9.55e-6, step_loss=0.00207/18/2023 19:55:28 - INFO - __main__ - train loss is 0.6804268304258585\n",
      "Steps:  54%|▌| 8154/15000 [52:05<1:51:06,  1.03it/s, lr=9.55e-6, step_loss=0.01107/18/2023 19:55:28 - INFO - __main__ - train loss is 1.0479561928659678\n",
      "Steps:  54%|▌| 8155/15000 [52:06<1:23:54,  1.36it/s, lr=9.55e-6, step_loss=0.36807/18/2023 19:55:28 - INFO - __main__ - train loss is 1.0511471112258732\n",
      "Steps:  54%|▌| 8156/15000 [52:06<1:04:50,  1.76it/s, lr=9.55e-6, step_loss=0.00307/18/2023 19:55:28 - INFO - __main__ - train loss is 1.151632719207555\n",
      "Steps:  54%|██▏ | 8157/15000 [52:06<51:28,  2.22it/s, lr=9.55e-6, step_loss=0.1]07/18/2023 19:55:28 - INFO - __main__ - train loss is 1.2133208331651986\n",
      "Steps:  54%|▌| 8158/15000 [52:06<42:08,  2.71it/s, lr=9.55e-6, step_loss=0.0617]07/18/2023 19:55:28 - INFO - __main__ - train loss is 1.2261150074191391\n",
      "Steps:  54%|▌| 8159/15000 [52:06<35:34,  3.21it/s, lr=9.55e-6, step_loss=0.0128]07/18/2023 19:55:29 - INFO - __main__ - train loss is 1.3987551522441208\n",
      "Steps:  54%|█ | 8160/15000 [52:07<31:11,  3.66it/s, lr=9.55e-6, step_loss=0.173]07/18/2023 19:55:29 - INFO - __main__ - train loss is 1.4272733950056136\n",
      "Steps:  54%|▌| 8161/15000 [52:07<28:17,  4.03it/s, lr=9.55e-6, step_loss=0.0285]07/18/2023 19:55:29 - INFO - __main__ - train loss is 1.8020166181959212\n",
      "Steps:  54%|█ | 8162/15000 [52:07<26:11,  4.35it/s, lr=9.55e-6, step_loss=0.375]07/18/2023 19:55:29 - INFO - __main__ - train loss is 1.849961640778929\n",
      "Steps:  54%|▌| 8163/15000 [52:07<24:26,  4.66it/s, lr=9.55e-6, step_loss=0.0479]07/18/2023 19:55:29 - INFO - __main__ - train loss is 1.8752652262337506\n",
      "Steps:  54%|▌| 8164/15000 [52:07<23:10,  4.91it/s, lr=9.55e-6, step_loss=0.0253]07/18/2023 19:55:30 - INFO - __main__ - train loss is 2.2807282959111035\n",
      "Steps:  54%|█ | 8165/15000 [52:07<22:17,  5.11it/s, lr=9.55e-6, step_loss=0.405]07/18/2023 19:55:30 - INFO - __main__ - train loss is 2.286823948379606\n",
      "Steps:  54%|▌| 8166/15000 [52:08<21:42,  5.25it/s, lr=9.55e-6, step_loss=0.0061]07/18/2023 19:55:30 - INFO - __main__ - train loss is 2.3142467285506427\n",
      "Steps:  54%|▌| 8167/15000 [52:08<21:17,  5.35it/s, lr=9.55e-6, step_loss=0.0274]07/18/2023 19:55:30 - INFO - __main__ - train loss is 2.316265355795622\n",
      "Steps:  54%|▌| 8168/15000 [52:08<20:59,  5.42it/s, lr=9.55e-6, step_loss=0.0020207/18/2023 19:55:30 - INFO - __main__ - train loss is 2.745613854378462\n",
      "Steps:  54%|█ | 8169/15000 [52:08<20:47,  5.48it/s, lr=9.55e-6, step_loss=0.429]07/18/2023 19:55:30 - INFO - __main__ - train loss is 3.1663650684058666\n",
      "Steps:  54%|█ | 8170/15000 [52:08<20:38,  5.51it/s, lr=9.55e-6, step_loss=0.421]07/18/2023 19:55:31 - INFO - __main__ - train loss is 3.356433104723692\n",
      "Steps:  54%|█▋ | 8171/15000 [52:09<20:32,  5.54it/s, lr=9.55e-6, step_loss=0.19]07/18/2023 19:55:31 - INFO - __main__ - train loss is 3.3928700014948845\n",
      "Steps:  54%|▌| 8172/15000 [52:09<20:28,  5.56it/s, lr=9.55e-6, step_loss=0.0364]07/18/2023 19:55:31 - INFO - __main__ - train loss is 3.3969059735536575\n",
      "Steps:  54%|▌| 8173/15000 [52:09<20:27,  5.56it/s, lr=9.55e-6, step_loss=0.0040407/18/2023 19:55:31 - INFO - __main__ - train loss is 3.77667997777462\n",
      "Steps:  54%|█▋ | 8174/15000 [52:09<20:25,  5.57it/s, lr=9.55e-6, step_loss=0.38]07/18/2023 19:55:31 - INFO - __main__ - train loss is 3.7820048700086772\n",
      "Steps:  55%|▌| 8175/15000 [52:09<20:34,  5.53it/s, lr=9.55e-6, step_loss=0.0053207/18/2023 19:55:32 - INFO - __main__ - train loss is 3.7846808105241507\n",
      "Steps:  55%|▌| 8176/15000 [52:09<20:28,  5.55it/s, lr=9.55e-6, step_loss=0.0026807/18/2023 19:55:32 - INFO - __main__ - train loss is 3.935919862939045\n",
      "Steps:  55%|█ | 8177/15000 [52:10<20:25,  5.57it/s, lr=9.55e-6, step_loss=0.151]07/18/2023 19:55:32 - INFO - __main__ - train loss is 3.9374772410374135\n",
      "Steps:  55%|▌| 8178/15000 [52:10<20:25,  5.57it/s, lr=9.55e-6, step_loss=0.0015607/18/2023 19:55:32 - INFO - __main__ - train loss is 3.9445687185507268\n",
      "Steps:  55%|▌| 8179/15000 [52:10<20:41,  5.49it/s, lr=9.55e-6, step_loss=0.0070907/18/2023 19:55:32 - INFO - __main__ - train loss is 4.401244724867865\n",
      "Steps:  55%|█ | 8180/15000 [52:10<20:34,  5.53it/s, lr=9.55e-6, step_loss=0.457]07/18/2023 19:55:32 - INFO - __main__ - train loss is 4.42989541660063\n",
      "Steps:  55%|▌| 8181/15000 [52:10<20:28,  5.55it/s, lr=9.55e-6, step_loss=0.0287]07/18/2023 19:55:33 - INFO - __main__ - train loss is 4.468362823827192\n",
      "Steps:  55%|▌| 8182/15000 [52:10<20:25,  5.56it/s, lr=9.55e-6, step_loss=0.0385]07/18/2023 19:55:33 - INFO - __main__ - train loss is 4.480839266208932\n",
      "Steps:  55%|▌| 8183/15000 [52:11<20:27,  5.55it/s, lr=9.55e-6, step_loss=0.0125]07/18/2023 19:55:33 - INFO - __main__ - train loss is 4.622048674849793\n",
      "Steps:  55%|█ | 8184/15000 [52:11<20:28,  5.55it/s, lr=9.55e-6, step_loss=0.141]07/18/2023 19:55:33 - INFO - __main__ - train loss is 4.831989093450829\n",
      "Steps:  55%|█▋ | 8185/15000 [52:11<20:29,  5.54it/s, lr=9.55e-6, step_loss=0.21]07/18/2023 19:55:33 - INFO - __main__ - train loss is 5.010050891665742\n",
      "Steps:  55%|█ | 8186/15000 [52:11<20:31,  5.54it/s, lr=9.55e-6, step_loss=0.178]07/18/2023 19:55:33 - INFO - __main__ - train loss is 5.206412105588242\n",
      "Steps:  55%|█ | 8187/15000 [52:11<20:31,  5.53it/s, lr=9.55e-6, step_loss=0.196]07/18/2023 19:55:34 - INFO - __main__ - train loss is 5.413316159276292\n",
      "Steps:  55%|█ | 8188/15000 [52:12<20:32,  5.53it/s, lr=9.55e-6, step_loss=0.207]07/18/2023 19:55:34 - INFO - __main__ - train loss is 5.445127724437043\n",
      "Steps:  55%|▌| 8189/15000 [52:12<20:32,  5.53it/s, lr=9.55e-6, step_loss=0.0318]07/18/2023 19:55:34 - INFO - __main__ - train loss is 5.50963910552673\n",
      "Steps:  55%|▌| 8190/15000 [52:12<20:32,  5.53it/s, lr=9.55e-6, step_loss=0.0645]07/18/2023 19:55:34 - INFO - __main__ - train loss is 5.725969976512715\n",
      "Steps:  55%|█ | 8191/15000 [52:12<20:31,  5.53it/s, lr=9.55e-6, step_loss=0.216]07/18/2023 19:55:34 - INFO - __main__ - train loss is 5.768812916008756\n",
      "Steps:  55%|▌| 8192/15000 [52:12<20:31,  5.53it/s, lr=9.55e-6, step_loss=0.0428]07/18/2023 19:55:35 - INFO - __main__ - train loss is 5.787520649610087\n",
      "Steps:  55%|▌| 8193/15000 [52:12<20:31,  5.53it/s, lr=9.55e-6, step_loss=0.0187]07/18/2023 19:55:35 - INFO - __main__ - train loss is 5.835510614095256\n",
      "Steps:  55%|█ | 8194/15000 [52:13<20:32,  5.52it/s, lr=9.55e-6, step_loss=0.048]07/18/2023 19:55:35 - INFO - __main__ - train loss is 5.882255038945004\n",
      "Steps:  55%|▌| 8195/15000 [52:13<20:32,  5.52it/s, lr=9.55e-6, step_loss=0.0467]07/18/2023 19:55:35 - INFO - __main__ - train loss is 6.060994765488431\n",
      "Steps:  55%|█ | 8196/15000 [52:13<20:32,  5.52it/s, lr=9.55e-6, step_loss=0.179]07/18/2023 19:55:35 - INFO - __main__ - train loss is 6.09624586510472\n",
      "Steps:  55%|▌| 8197/15000 [52:13<20:32,  5.52it/s, lr=9.55e-6, step_loss=0.0353]07/18/2023 19:55:35 - INFO - __main__ - train loss is 6.196855964837596\n",
      "Steps:  55%|█ | 8198/15000 [52:13<20:32,  5.52it/s, lr=9.55e-6, step_loss=0.101]07/18/2023 19:55:36 - INFO - __main__ - train loss is 6.259348674444482\n",
      "Steps:  55%|▌| 8199/15000 [52:14<20:27,  5.54it/s, lr=9.55e-6, step_loss=0.0625]07/18/2023 19:55:36 - INFO - __main__ - train loss is 6.524784727720544\n",
      "Steps:  55%|█ | 8200/15000 [52:14<20:23,  5.56it/s, lr=9.55e-6, step_loss=0.265]07/18/2023 19:55:36 - INFO - __main__ - train loss is 6.727943434147164\n",
      "Steps:  55%|█ | 8201/15000 [52:14<20:19,  5.57it/s, lr=9.55e-6, step_loss=0.203]07/18/2023 19:55:36 - INFO - __main__ - train loss is 6.829776628641412\n",
      "Steps:  55%|█ | 8202/15000 [52:14<20:18,  5.58it/s, lr=9.55e-6, step_loss=0.102]07/18/2023 19:55:36 - INFO - __main__ - train loss is 6.991096629528329\n",
      "Steps:  55%|█ | 8203/15000 [52:14<20:17,  5.58it/s, lr=9.55e-6, step_loss=0.161]07/18/2023 19:55:37 - INFO - __main__ - train loss is 7.152051656274125\n",
      "Steps:  55%|█ | 8204/15000 [52:14<20:16,  5.59it/s, lr=9.55e-6, step_loss=0.161]07/18/2023 19:55:37 - INFO - __main__ - train loss is 7.242067320970818\n",
      "Steps:  55%|█▋ | 8205/15000 [52:15<20:15,  5.59it/s, lr=9.55e-6, step_loss=0.09]07/18/2023 19:55:37 - INFO - __main__ - train loss is 7.384586005238816\n",
      "Steps:  55%|█ | 8206/15000 [52:15<20:14,  5.59it/s, lr=9.55e-6, step_loss=0.143]07/18/2023 19:55:37 - INFO - __main__ - train loss is 7.511254309443757\n",
      "Steps:  55%|█ | 8207/15000 [52:15<20:15,  5.59it/s, lr=9.55e-6, step_loss=0.127]07/18/2023 19:55:37 - INFO - __main__ - train loss is 7.512847365345806\n",
      "Steps:  55%|▌| 8208/15000 [52:15<20:14,  5.59it/s, lr=9.55e-6, step_loss=0.0015907/18/2023 19:55:37 - INFO - __main__ - train loss is 7.822961212601513\n",
      "Steps:  55%|█▋ | 8209/15000 [52:15<20:14,  5.59it/s, lr=9.55e-6, step_loss=0.31]07/18/2023 19:55:38 - INFO - __main__ - train loss is 7.912911327090114\n",
      "Steps:  55%|█▋ | 8210/15000 [52:16<20:14,  5.59it/s, lr=9.55e-6, step_loss=0.09]07/18/2023 19:55:38 - INFO - __main__ - train loss is 7.978820265736431\n",
      "Steps:  55%|▌| 8211/15000 [52:16<20:26,  5.54it/s, lr=9.55e-6, step_loss=0.0659]07/18/2023 19:55:38 - INFO - __main__ - train loss is 7.990915178786963\n",
      "Steps:  55%|▌| 8212/15000 [52:16<22:04,  5.13it/s, lr=9.55e-6, step_loss=0.0121]07/18/2023 19:55:38 - INFO - __main__ - train loss is 8.30013734055683\n",
      "Steps:  55%|█ | 8213/15000 [52:16<22:23,  5.05it/s, lr=9.55e-6, step_loss=0.309]07/18/2023 19:55:38 - INFO - __main__ - train loss is 8.331543840002269\n",
      "Steps:  55%|▌| 8214/15000 [52:16<23:06,  4.89it/s, lr=9.55e-6, step_loss=0.0314]07/18/2023 19:55:39 - INFO - __main__ - train loss is 8.371462210547179\n",
      "Steps:  55%|▌| 8215/15000 [52:17<22:25,  5.04it/s, lr=9.55e-6, step_loss=0.0399]07/18/2023 19:55:39 - INFO - __main__ - train loss is 8.398572327103466\n",
      "Steps:  55%|▌| 8216/15000 [52:17<21:45,  5.20it/s, lr=9.55e-6, step_loss=0.0271]07/18/2023 19:55:39 - INFO - __main__ - train loss is 8.43586086621508\n",
      "Steps:  55%|▌| 8217/15000 [52:17<21:18,  5.30it/s, lr=9.55e-6, step_loss=0.0373]07/18/2023 19:55:39 - INFO - __main__ - train loss is 8.532955506350845\n",
      "Steps:  55%|▌| 8218/15000 [52:17<20:58,  5.39it/s, lr=9.55e-6, step_loss=0.0971]07/18/2023 19:55:39 - INFO - __main__ - train loss is 8.574679823126644\n",
      "Steps:  55%|▌| 8219/15000 [52:17<20:52,  5.41it/s, lr=9.55e-6, step_loss=0.0417]07/18/2023 19:55:40 - INFO - __main__ - train loss is 9.2778629376553\n",
      "Steps:  55%|█ | 8220/15000 [52:17<20:40,  5.46it/s, lr=9.55e-6, step_loss=0.703]07/18/2023 19:55:40 - INFO - __main__ - train loss is 9.469671504106373\n",
      "Steps:  55%|█ | 8221/15000 [52:18<20:32,  5.50it/s, lr=9.55e-6, step_loss=0.192]07/18/2023 19:55:40 - INFO - __main__ - train loss is 9.477932977955788\n",
      "Steps:  55%|▌| 8222/15000 [52:18<20:26,  5.53it/s, lr=9.55e-6, step_loss=0.0082607/18/2023 19:55:40 - INFO - __main__ - train loss is 10.005896497052163\n",
      "Steps:  55%|█ | 8223/15000 [52:18<20:21,  5.55it/s, lr=9.55e-6, step_loss=0.528]07/18/2023 19:55:40 - INFO - __main__ - train loss is 10.013856661971658\n",
      "Steps:  55%|▌| 8224/15000 [52:18<20:18,  5.56it/s, lr=9.55e-6, step_loss=0.0079607/18/2023 19:55:40 - INFO - __main__ - train loss is 10.116981086786836\n",
      "Steps:  55%|█ | 8225/15000 [52:18<20:25,  5.53it/s, lr=9.55e-6, step_loss=0.103]07/18/2023 19:55:41 - INFO - __main__ - train loss is 10.14638983597979\n",
      "Steps:  55%|▌| 8226/15000 [52:19<20:27,  5.52it/s, lr=9.55e-6, step_loss=0.0294]07/18/2023 19:55:41 - INFO - __main__ - train loss is 10.186126114334911\n",
      "Steps:  55%|▌| 8227/15000 [52:19<20:23,  5.54it/s, lr=9.54e-6, step_loss=0.0397]07/18/2023 19:55:41 - INFO - __main__ - train loss is 10.53044077893719\n",
      "Steps:  55%|█ | 8228/15000 [52:19<20:19,  5.55it/s, lr=9.54e-6, step_loss=0.344]07/18/2023 19:55:41 - INFO - __main__ - train loss is 10.597669513430446\n",
      "Steps:  55%|▌| 8229/15000 [52:19<20:23,  5.54it/s, lr=9.54e-6, step_loss=0.0672]07/18/2023 19:55:41 - INFO - __main__ - train loss is 10.774945320095867\n",
      "Steps:  55%|█ | 8230/15000 [52:19<20:29,  5.51it/s, lr=9.54e-6, step_loss=0.177]07/18/2023 19:55:42 - INFO - __main__ - train loss is 11.108773888554424\n",
      "Steps:  55%|█ | 8231/15000 [52:19<20:46,  5.43it/s, lr=9.54e-6, step_loss=0.334]07/18/2023 19:55:42 - INFO - __main__ - train loss is 11.447721005883068\n",
      "Steps:  55%|█ | 8232/15000 [52:20<21:10,  5.33it/s, lr=9.54e-6, step_loss=0.339]07/18/2023 19:55:42 - INFO - __main__ - train loss is 11.484160204883665\n",
      "Steps:  55%|▌| 8233/15000 [52:20<21:23,  5.27it/s, lr=9.54e-6, step_loss=0.0364]07/18/2023 19:55:42 - INFO - __main__ - train loss is 11.497836815658957\n",
      "Steps:  55%|▌| 8234/15000 [52:20<21:33,  5.23it/s, lr=9.54e-6, step_loss=0.0137]07/18/2023 19:55:42 - INFO - __main__ - train loss is 11.924464034382254\n",
      "Steps:  55%|█ | 8235/15000 [52:20<21:42,  5.19it/s, lr=9.54e-6, step_loss=0.427]07/18/2023 19:55:43 - INFO - __main__ - train loss is 11.927046725759283\n",
      "Steps:  55%|▌| 8236/15000 [52:20<21:45,  5.18it/s, lr=9.54e-6, step_loss=0.0025807/18/2023 19:55:43 - INFO - __main__ - train loss is 12.26835278631188\n",
      "Steps:  55%|█ | 8237/15000 [52:21<21:50,  5.16it/s, lr=9.54e-6, step_loss=0.341]07/18/2023 19:55:43 - INFO - __main__ - train loss is 12.525413492927328\n",
      "Steps:  55%|█ | 8238/15000 [52:21<21:52,  5.15it/s, lr=9.54e-6, step_loss=0.257]07/18/2023 19:55:43 - INFO - __main__ - train loss is 12.580886414507404\n",
      "Steps:  55%|▌| 8239/15000 [52:21<21:42,  5.19it/s, lr=9.54e-6, step_loss=0.0555]07/18/2023 19:55:43 - INFO - __main__ - train loss is 12.960737815359607\n",
      "Steps:  55%|█▋ | 8240/15000 [52:21<21:20,  5.28it/s, lr=9.54e-6, step_loss=0.38]07/18/2023 19:55:43 - INFO - __main__ - train loss is 13.150328507879749\n",
      "Steps:  55%|█▋ | 8241/15000 [52:21<21:21,  5.28it/s, lr=9.54e-6, step_loss=0.19]07/18/2023 19:55:44 - INFO - __main__ - train loss is 13.228097340324894\n",
      "Steps:  55%|▌| 8242/15000 [52:22<21:33,  5.23it/s, lr=9.54e-6, step_loss=0.0778]07/18/2023 19:55:44 - INFO - __main__ - train loss is 13.312700106063858\n",
      "Steps:  55%|▌| 8243/15000 [52:22<21:39,  5.20it/s, lr=9.54e-6, step_loss=0.0846]07/18/2023 19:55:44 - INFO - __main__ - train loss is 13.314824388129637\n",
      "Steps:  55%|▌| 8244/15000 [52:22<21:41,  5.19it/s, lr=9.54e-6, step_loss=0.0021207/18/2023 19:55:45 - INFO - __main__ - train loss is 13.328940679086372\n",
      "Steps:  55%|▌| 8245/15000 [52:22<30:48,  3.65it/s, lr=9.54e-6, step_loss=0.0141]07/18/2023 19:55:45 - INFO - __main__ - Per validation step average loss is 0.12980051338672638\n",
      "07/18/2023 19:55:45 - INFO - __main__ - Cumulative validation average loss is 0.12980051338672638\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Per validation step average loss is 0.0353599414229393\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Cumulative validation average loss is 0.16516045480966568\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Per validation step average loss is 0.226619690656662\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Cumulative validation average loss is 0.39178014546632767\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Per validation step average loss is 0.006511214654892683\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Cumulative validation average loss is 0.39829136012122035\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Per validation step average loss is 0.001979328691959381\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Cumulative validation average loss is 0.40027068881317973\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Per validation step average loss is 0.2900877296924591\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Cumulative validation average loss is 0.6903584185056388\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Per validation step average loss is 0.012710310518741608\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Cumulative validation average loss is 0.7030687290243804\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Per validation step average loss is 0.42898234724998474\n",
      "07/18/2023 19:55:46 - INFO - __main__ - Cumulative validation average loss is 1.1320510762743652\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Per validation step average loss is 0.172145813703537\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Cumulative validation average loss is 1.3041968899779022\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Per validation step average loss is 0.06589771807193756\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Cumulative validation average loss is 1.3700946080498397\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Per validation step average loss is 0.18636417388916016\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Cumulative validation average loss is 1.556458781939\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Per validation step average loss is 0.12851707637310028\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Cumulative validation average loss is 1.6849758583121002\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Average validation loss for Epoch 84 is 0.14041465485934168\n",
      "07/18/2023 19:55:47 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:56:00 - INFO - __main__ - Starting epoch 85\n",
      "07/18/2023 19:56:01 - INFO - __main__ - train loss is 0.1754753738641739\n",
      "Steps:  55%|▌| 8246/15000 [52:39<9:31:01,  5.07s/it, lr=9.54e-6, step_loss=0.17507/18/2023 19:56:01 - INFO - __main__ - train loss is 0.21090444922447205\n",
      "Steps:  55%|▌| 8247/15000 [52:39<6:45:50,  3.61s/it, lr=9.54e-6, step_loss=0.03507/18/2023 19:56:01 - INFO - __main__ - train loss is 0.222389105707407\n",
      "Steps:  55%|▌| 8248/15000 [52:39<4:50:15,  2.58s/it, lr=9.54e-6, step_loss=0.01107/18/2023 19:56:01 - INFO - __main__ - train loss is 0.22770653199404478\n",
      "Steps:  55%|▌| 8249/15000 [52:39<3:29:22,  1.86s/it, lr=9.54e-6, step_loss=0.00507/18/2023 19:56:02 - INFO - __main__ - train loss is 0.23113001068122685\n",
      "Steps:  55%|▌| 8250/15000 [52:39<2:32:48,  1.36s/it, lr=9.54e-6, step_loss=0.00307/18/2023 19:56:02 - INFO - __main__ - train loss is 0.23352160467766225\n",
      "Steps:  55%|▌| 8251/15000 [52:40<1:53:22,  1.01s/it, lr=9.54e-6, step_loss=0.00207/18/2023 19:56:02 - INFO - __main__ - train loss is 0.7814384938683361\n",
      "Steps:  55%|▌| 8252/15000 [52:40<1:25:29,  1.32it/s, lr=9.54e-6, step_loss=0.54807/18/2023 19:56:02 - INFO - __main__ - train loss is 0.7969146899413317\n",
      "Steps:  55%|▌| 8253/15000 [52:40<1:05:49,  1.71it/s, lr=9.54e-6, step_loss=0.01507/18/2023 19:56:02 - INFO - __main__ - train loss is 0.953505017561838\n",
      "Steps:  55%|█ | 8254/15000 [52:40<52:04,  2.16it/s, lr=9.54e-6, step_loss=0.157]07/18/2023 19:56:02 - INFO - __main__ - train loss is 0.958043536869809\n",
      "Steps:  55%|▌| 8255/15000 [52:40<42:27,  2.65it/s, lr=9.54e-6, step_loss=0.0045407/18/2023 19:56:03 - INFO - __main__ - train loss is 0.9681706640403718\n",
      "Steps:  55%|▌| 8256/15000 [52:41<35:43,  3.15it/s, lr=9.54e-6, step_loss=0.0101]07/18/2023 19:56:03 - INFO - __main__ - train loss is 0.9878043744247407\n",
      "Steps:  55%|▌| 8257/15000 [52:41<31:01,  3.62it/s, lr=9.54e-6, step_loss=0.0196]07/18/2023 19:56:03 - INFO - __main__ - train loss is 0.9942518442403525\n",
      "Steps:  55%|▌| 8258/15000 [52:41<27:42,  4.05it/s, lr=9.54e-6, step_loss=0.0064507/18/2023 19:56:03 - INFO - __main__ - train loss is 1.0138217888306826\n",
      "Steps:  55%|▌| 8259/15000 [52:41<25:25,  4.42it/s, lr=9.54e-6, step_loss=0.0196]07/18/2023 19:56:03 - INFO - __main__ - train loss is 1.2293669066857547\n",
      "Steps:  55%|█ | 8260/15000 [52:41<23:59,  4.68it/s, lr=9.54e-6, step_loss=0.216]07/18/2023 19:56:04 - INFO - __main__ - train loss is 1.3845782957505435\n",
      "Steps:  55%|█ | 8261/15000 [52:41<22:50,  4.92it/s, lr=9.54e-6, step_loss=0.155]07/18/2023 19:56:04 - INFO - __main__ - train loss is 1.4262254617642611\n",
      "Steps:  55%|▌| 8262/15000 [52:42<22:09,  5.07it/s, lr=9.54e-6, step_loss=0.0416]07/18/2023 19:56:04 - INFO - __main__ - train loss is 1.4605773619841784\n",
      "Steps:  55%|▌| 8263/15000 [52:42<21:46,  5.16it/s, lr=9.54e-6, step_loss=0.0344]07/18/2023 19:56:04 - INFO - __main__ - train loss is 1.7691271237563342\n",
      "Steps:  55%|█ | 8264/15000 [52:42<21:18,  5.27it/s, lr=9.54e-6, step_loss=0.309]07/18/2023 19:56:04 - INFO - __main__ - train loss is 1.8695807463955134\n",
      "Steps:  55%|██▏ | 8265/15000 [52:42<21:04,  5.32it/s, lr=9.54e-6, step_loss=0.1]07/18/2023 19:56:04 - INFO - __main__ - train loss is 2.139076770050451\n",
      "Steps:  55%|█ | 8266/15000 [52:42<20:45,  5.41it/s, lr=9.54e-6, step_loss=0.269]07/18/2023 19:56:05 - INFO - __main__ - train loss is 2.235289045376703\n",
      "Steps:  55%|▌| 8267/15000 [52:42<20:34,  5.46it/s, lr=9.54e-6, step_loss=0.0962]07/18/2023 19:56:05 - INFO - __main__ - train loss is 2.825260766549036\n",
      "Steps:  55%|█▋ | 8268/15000 [52:43<20:24,  5.50it/s, lr=9.54e-6, step_loss=0.59]07/18/2023 19:56:05 - INFO - __main__ - train loss is 2.9053306139539927\n",
      "Steps:  55%|▌| 8269/15000 [52:43<20:18,  5.52it/s, lr=9.54e-6, step_loss=0.0801]07/18/2023 19:56:05 - INFO - __main__ - train loss is 2.964097388787195\n",
      "Steps:  55%|▌| 8270/15000 [52:43<20:24,  5.50it/s, lr=9.54e-6, step_loss=0.0588]07/18/2023 19:56:05 - INFO - __main__ - train loss is 3.291303612990305\n",
      "Steps:  55%|█ | 8271/15000 [52:43<20:22,  5.51it/s, lr=9.54e-6, step_loss=0.327]07/18/2023 19:56:06 - INFO - __main__ - train loss is 3.434760519070551\n",
      "Steps:  55%|█ | 8272/15000 [52:43<20:16,  5.53it/s, lr=9.54e-6, step_loss=0.143]07/18/2023 19:56:06 - INFO - __main__ - train loss is 3.9518214545678347\n",
      "Steps:  55%|█ | 8273/15000 [52:44<20:23,  5.50it/s, lr=9.54e-6, step_loss=0.517]07/18/2023 19:56:06 - INFO - __main__ - train loss is 4.112398140830919\n",
      "Steps:  55%|█ | 8274/15000 [52:44<20:20,  5.51it/s, lr=9.54e-6, step_loss=0.161]07/18/2023 19:56:06 - INFO - __main__ - train loss is 4.1157719634938985\n",
      "Steps:  55%|▌| 8275/15000 [52:44<20:14,  5.54it/s, lr=9.54e-6, step_loss=0.0033707/18/2023 19:56:06 - INFO - __main__ - train loss is 4.118161344900727\n",
      "Steps:  55%|▌| 8276/15000 [52:44<20:11,  5.55it/s, lr=9.54e-6, step_loss=0.0023907/18/2023 19:56:06 - INFO - __main__ - train loss is 4.2218150440603495\n",
      "Steps:  55%|█ | 8277/15000 [52:44<20:08,  5.56it/s, lr=9.54e-6, step_loss=0.104]07/18/2023 19:56:07 - INFO - __main__ - train loss is 4.234135890379548\n",
      "Steps:  55%|▌| 8278/15000 [52:44<20:05,  5.57it/s, lr=9.54e-6, step_loss=0.0123]07/18/2023 19:56:07 - INFO - __main__ - train loss is 4.394058430567384\n",
      "Steps:  55%|█▋ | 8279/15000 [52:45<20:03,  5.58it/s, lr=9.54e-6, step_loss=0.16]07/18/2023 19:56:07 - INFO - __main__ - train loss is 4.698852265253663\n",
      "Steps:  55%|█ | 8280/15000 [52:45<20:01,  5.59it/s, lr=9.54e-6, step_loss=0.305]07/18/2023 19:56:07 - INFO - __main__ - train loss is 4.7192175686359406\n",
      "Steps:  55%|▌| 8281/15000 [52:45<20:01,  5.59it/s, lr=9.54e-6, step_loss=0.0204]07/18/2023 19:56:07 - INFO - __main__ - train loss is 4.729798503220081\n",
      "Steps:  55%|▌| 8282/15000 [52:45<20:03,  5.58it/s, lr=9.54e-6, step_loss=0.0106]07/18/2023 19:56:07 - INFO - __main__ - train loss is 4.745556162670255\n",
      "Steps:  55%|▌| 8283/15000 [52:45<20:09,  5.55it/s, lr=9.54e-6, step_loss=0.0158]07/18/2023 19:56:08 - INFO - __main__ - train loss is 4.945901678875089\n",
      "Steps:  55%|██▏ | 8284/15000 [52:46<20:10,  5.55it/s, lr=9.54e-6, step_loss=0.2]07/18/2023 19:56:08 - INFO - __main__ - train loss is 5.00579577870667\n",
      "Steps:  55%|▌| 8285/15000 [52:46<20:23,  5.49it/s, lr=9.54e-6, step_loss=0.0599]07/18/2023 19:56:08 - INFO - __main__ - train loss is 5.146678240969777\n",
      "Steps:  55%|█ | 8286/15000 [52:46<20:19,  5.50it/s, lr=9.54e-6, step_loss=0.141]07/18/2023 19:56:08 - INFO - __main__ - train loss is 5.1837555561214685\n",
      "Steps:  55%|▌| 8287/15000 [52:46<20:24,  5.48it/s, lr=9.54e-6, step_loss=0.0371]07/18/2023 19:56:08 - INFO - __main__ - train loss is 5.67390857078135\n",
      "Steps:  55%|█▋ | 8288/15000 [52:46<20:18,  5.51it/s, lr=9.54e-6, step_loss=0.49]07/18/2023 19:56:09 - INFO - __main__ - train loss is 5.687755296006799\n",
      "Steps:  55%|▌| 8289/15000 [52:46<20:12,  5.54it/s, lr=9.54e-6, step_loss=0.0138]07/18/2023 19:56:09 - INFO - __main__ - train loss is 5.724323516711593\n",
      "Steps:  55%|▌| 8290/15000 [52:47<20:06,  5.56it/s, lr=9.54e-6, step_loss=0.0366]07/18/2023 19:56:09 - INFO - __main__ - train loss is 5.925308471545577\n",
      "Steps:  55%|█ | 8291/15000 [52:47<20:03,  5.58it/s, lr=9.54e-6, step_loss=0.201]07/18/2023 19:56:09 - INFO - __main__ - train loss is 5.931326238438487\n",
      "Steps:  55%|▌| 8292/15000 [52:47<20:00,  5.59it/s, lr=9.54e-6, step_loss=0.0060207/18/2023 19:56:09 - INFO - __main__ - train loss is 6.314081249758601\n",
      "Steps:  55%|█ | 8293/15000 [52:47<20:02,  5.58it/s, lr=9.54e-6, step_loss=0.383]07/18/2023 19:56:09 - INFO - __main__ - train loss is 6.332715978845954\n",
      "Steps:  55%|▌| 8294/15000 [52:47<20:02,  5.58it/s, lr=9.54e-6, step_loss=0.0186]07/18/2023 19:56:10 - INFO - __main__ - train loss is 6.7937256302684546\n",
      "Steps:  55%|█ | 8295/15000 [52:48<20:02,  5.58it/s, lr=9.54e-6, step_loss=0.461]07/18/2023 19:56:10 - INFO - __main__ - train loss is 6.851605320349336\n",
      "Steps:  55%|▌| 8296/15000 [52:48<19:59,  5.59it/s, lr=9.54e-6, step_loss=0.0579]07/18/2023 19:56:10 - INFO - __main__ - train loss is 6.911565193906426\n",
      "Steps:  55%|█▋ | 8297/15000 [52:48<19:58,  5.59it/s, lr=9.54e-6, step_loss=0.06]07/18/2023 19:56:10 - INFO - __main__ - train loss is 7.571154782548547\n",
      "Steps:  55%|█▋ | 8298/15000 [52:48<19:57,  5.60it/s, lr=9.54e-6, step_loss=0.66]07/18/2023 19:56:10 - INFO - __main__ - train loss is 7.694501304998994\n",
      "Steps:  55%|█ | 8299/15000 [52:48<19:56,  5.60it/s, lr=9.54e-6, step_loss=0.123]07/18/2023 19:56:11 - INFO - __main__ - train loss is 7.812658483162522\n",
      "Steps:  55%|█ | 8300/15000 [52:48<19:55,  5.60it/s, lr=9.54e-6, step_loss=0.118]07/18/2023 19:56:11 - INFO - __main__ - train loss is 7.81812739931047\n",
      "Steps:  55%|▌| 8301/15000 [52:49<19:55,  5.61it/s, lr=9.54e-6, step_loss=0.0054707/18/2023 19:56:11 - INFO - __main__ - train loss is 7.982326811179519\n",
      "Steps:  55%|█ | 8302/15000 [52:49<19:55,  5.60it/s, lr=9.54e-6, step_loss=0.164]07/18/2023 19:56:11 - INFO - __main__ - train loss is 8.047786450013518\n",
      "Steps:  55%|▌| 8303/15000 [52:49<19:55,  5.60it/s, lr=9.54e-6, step_loss=0.0655]07/18/2023 19:56:11 - INFO - __main__ - train loss is 8.049458497436717\n",
      "Steps:  55%|▌| 8304/15000 [52:49<19:55,  5.60it/s, lr=9.54e-6, step_loss=0.0016707/18/2023 19:56:11 - INFO - __main__ - train loss is 8.060725005576387\n",
      "Steps:  55%|▌| 8305/15000 [52:49<19:55,  5.60it/s, lr=9.54e-6, step_loss=0.0113]07/18/2023 19:56:12 - INFO - __main__ - train loss is 8.102368960389867\n",
      "Steps:  55%|▌| 8306/15000 [52:49<19:54,  5.60it/s, lr=9.54e-6, step_loss=0.0416]07/18/2023 19:56:12 - INFO - __main__ - train loss is 8.39406574727036\n",
      "Steps:  55%|█ | 8307/15000 [52:50<19:54,  5.60it/s, lr=9.54e-6, step_loss=0.292]07/18/2023 19:56:12 - INFO - __main__ - train loss is 8.741597960004583\n",
      "Steps:  55%|█ | 8308/15000 [52:50<19:54,  5.60it/s, lr=9.54e-6, step_loss=0.348]07/18/2023 19:56:12 - INFO - __main__ - train loss is 8.75984369055368\n",
      "Steps:  55%|▌| 8309/15000 [52:50<19:55,  5.60it/s, lr=9.54e-6, step_loss=0.0182]07/18/2023 19:56:12 - INFO - __main__ - train loss is 9.513252837816253\n",
      "Steps:  55%|█ | 8310/15000 [52:50<19:54,  5.60it/s, lr=9.54e-6, step_loss=0.753]07/18/2023 19:56:13 - INFO - __main__ - train loss is 9.54394873813726\n",
      "Steps:  55%|▌| 8311/15000 [52:50<19:54,  5.60it/s, lr=9.54e-6, step_loss=0.0307]07/18/2023 19:56:13 - INFO - __main__ - train loss is 10.115873662987724\n",
      "Steps:  55%|█ | 8312/15000 [52:51<19:54,  5.60it/s, lr=9.54e-6, step_loss=0.572]07/18/2023 19:56:13 - INFO - __main__ - train loss is 10.244842736283317\n",
      "Steps:  55%|█ | 8313/15000 [52:51<20:02,  5.56it/s, lr=9.54e-6, step_loss=0.129]07/18/2023 19:56:13 - INFO - __main__ - train loss is 10.249107861658558\n",
      "Steps:  55%|▌| 8314/15000 [52:51<20:54,  5.33it/s, lr=9.54e-6, step_loss=0.0042707/18/2023 19:56:13 - INFO - __main__ - train loss is 10.622586810728535\n",
      "Steps:  55%|█ | 8315/15000 [52:51<20:53,  5.33it/s, lr=9.54e-6, step_loss=0.373]07/18/2023 19:56:13 - INFO - __main__ - train loss is 10.624224753817543\n",
      "Steps:  55%|▌| 8316/15000 [52:51<21:00,  5.30it/s, lr=9.54e-6, step_loss=0.0016407/18/2023 19:56:14 - INFO - __main__ - train loss is 10.695768357953057\n",
      "Steps:  55%|▌| 8317/15000 [52:52<20:41,  5.38it/s, lr=9.54e-6, step_loss=0.0715]07/18/2023 19:56:14 - INFO - __main__ - train loss is 11.00548887415789\n",
      "Steps:  55%|█▋ | 8318/15000 [52:52<20:26,  5.45it/s, lr=9.53e-6, step_loss=0.31]07/18/2023 19:56:14 - INFO - __main__ - train loss is 11.23041826649569\n",
      "Steps:  55%|█ | 8319/15000 [52:52<20:15,  5.50it/s, lr=9.53e-6, step_loss=0.225]07/18/2023 19:56:14 - INFO - __main__ - train loss is 11.281117820879444\n",
      "Steps:  55%|▌| 8320/15000 [52:52<20:08,  5.53it/s, lr=9.53e-6, step_loss=0.0507]07/18/2023 19:56:14 - INFO - __main__ - train loss is 11.283711712574586\n",
      "Steps:  55%|▌| 8321/15000 [52:52<20:04,  5.55it/s, lr=9.53e-6, step_loss=0.0025907/18/2023 19:56:15 - INFO - __main__ - train loss is 11.386863846099004\n",
      "Steps:  55%|█ | 8322/15000 [52:52<20:01,  5.56it/s, lr=9.53e-6, step_loss=0.103]07/18/2023 19:56:15 - INFO - __main__ - train loss is 11.595083433901891\n",
      "Steps:  55%|█ | 8323/15000 [52:53<19:58,  5.57it/s, lr=9.53e-6, step_loss=0.208]07/18/2023 19:56:15 - INFO - __main__ - train loss is 11.631158482050523\n",
      "Steps:  55%|▌| 8324/15000 [52:53<19:56,  5.58it/s, lr=9.53e-6, step_loss=0.0361]07/18/2023 19:56:15 - INFO - __main__ - train loss is 11.636673467932269\n",
      "Steps:  56%|▌| 8325/15000 [52:53<20:08,  5.52it/s, lr=9.53e-6, step_loss=0.0055107/18/2023 19:56:15 - INFO - __main__ - train loss is 12.07186661916785\n",
      "Steps:  56%|█ | 8326/15000 [52:53<20:18,  5.48it/s, lr=9.53e-6, step_loss=0.435]07/18/2023 19:56:15 - INFO - __main__ - train loss is 12.104227795032784\n",
      "Steps:  56%|▌| 8327/15000 [52:53<20:10,  5.51it/s, lr=9.53e-6, step_loss=0.0324]07/18/2023 19:56:16 - INFO - __main__ - train loss is 12.168307556537911\n",
      "Steps:  56%|▌| 8328/15000 [52:53<20:04,  5.54it/s, lr=9.53e-6, step_loss=0.0641]07/18/2023 19:56:16 - INFO - __main__ - train loss is 12.17496994533576\n",
      "Steps:  56%|▌| 8329/15000 [52:54<19:59,  5.56it/s, lr=9.53e-6, step_loss=0.0066607/18/2023 19:56:16 - INFO - __main__ - train loss is 12.184756621019915\n",
      "Steps:  56%|▌| 8330/15000 [52:54<19:57,  5.57it/s, lr=9.53e-6, step_loss=0.0097907/18/2023 19:56:16 - INFO - __main__ - train loss is 12.641601070063189\n",
      "Steps:  56%|█ | 8331/15000 [52:54<19:55,  5.58it/s, lr=9.53e-6, step_loss=0.457]07/18/2023 19:56:16 - INFO - __main__ - train loss is 13.216040416853502\n",
      "Steps:  56%|█ | 8332/15000 [52:54<20:04,  5.54it/s, lr=9.53e-6, step_loss=0.574]07/18/2023 19:56:17 - INFO - __main__ - train loss is 13.458314775722101\n",
      "Steps:  56%|█ | 8333/15000 [52:54<20:10,  5.51it/s, lr=9.53e-6, step_loss=0.242]07/18/2023 19:56:17 - INFO - __main__ - train loss is 13.48352470737882\n",
      "Steps:  56%|▌| 8334/15000 [52:55<20:13,  5.49it/s, lr=9.53e-6, step_loss=0.0252]07/18/2023 19:56:17 - INFO - __main__ - train loss is 13.574589980067685\n",
      "Steps:  56%|▌| 8335/15000 [52:55<20:05,  5.53it/s, lr=9.53e-6, step_loss=0.0911]07/18/2023 19:56:17 - INFO - __main__ - train loss is 13.581334450514987\n",
      "Steps:  56%|▌| 8336/15000 [52:55<20:00,  5.55it/s, lr=9.53e-6, step_loss=0.0067407/18/2023 19:56:17 - INFO - __main__ - train loss is 13.768472113879398\n",
      "Steps:  56%|█ | 8337/15000 [52:55<19:56,  5.57it/s, lr=9.53e-6, step_loss=0.187]07/18/2023 19:56:17 - INFO - __main__ - train loss is 13.771619741804898\n",
      "Steps:  56%|▌| 8338/15000 [52:55<19:53,  5.58it/s, lr=9.53e-6, step_loss=0.0031507/18/2023 19:56:18 - INFO - __main__ - train loss is 13.793762314133346\n",
      "Steps:  56%|▌| 8339/15000 [52:55<19:55,  5.57it/s, lr=9.53e-6, step_loss=0.0221]07/18/2023 19:56:18 - INFO - __main__ - train loss is 13.80585299897939\n",
      "Steps:  56%|▌| 8340/15000 [52:56<19:53,  5.58it/s, lr=9.53e-6, step_loss=0.0121]07/18/2023 19:56:18 - INFO - __main__ - train loss is 13.808347333222628\n",
      "Steps:  56%|▌| 8341/15000 [52:56<19:51,  5.59it/s, lr=9.53e-6, step_loss=0.0024907/18/2023 19:56:18 - INFO - __main__ - train loss is 14.054236490279436\n",
      "Steps:  56%|█ | 8342/15000 [52:56<27:01,  4.11it/s, lr=9.53e-6, step_loss=0.246]07/18/2023 19:56:19 - INFO - __main__ - Per validation step average loss is 0.20230212807655334\n",
      "07/18/2023 19:56:19 - INFO - __main__ - Cumulative validation average loss is 0.20230212807655334\n",
      "07/18/2023 19:56:19 - INFO - __main__ - Per validation step average loss is 0.018548982217907906\n",
      "07/18/2023 19:56:19 - INFO - __main__ - Cumulative validation average loss is 0.22085111029446125\n",
      "07/18/2023 19:56:19 - INFO - __main__ - Per validation step average loss is 0.016150828450918198\n",
      "07/18/2023 19:56:19 - INFO - __main__ - Cumulative validation average loss is 0.23700193874537945\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Per validation step average loss is 0.28705793619155884\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Cumulative validation average loss is 0.5240598749369383\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Per validation step average loss is 0.35842424631118774\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Cumulative validation average loss is 0.882484121248126\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Per validation step average loss is 0.02097424305975437\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Cumulative validation average loss is 0.9034583643078804\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Per validation step average loss is 0.09266743063926697\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Cumulative validation average loss is 0.9961257949471474\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Per validation step average loss is 0.024207517504692078\n",
      "07/18/2023 19:56:20 - INFO - __main__ - Cumulative validation average loss is 1.0203333124518394\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Per validation step average loss is 0.17699018120765686\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Cumulative validation average loss is 1.1973234936594963\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Per validation step average loss is 0.22325104475021362\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Cumulative validation average loss is 1.42057453840971\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Per validation step average loss is 0.04145326837897301\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Cumulative validation average loss is 1.462027806788683\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Per validation step average loss is 0.11623385548591614\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Cumulative validation average loss is 1.578261662274599\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Average validation loss for Epoch 85 is 0.13152180518954992\n",
      "07/18/2023 19:56:21 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:56:34 - INFO - __main__ - Starting epoch 86\n",
      "07/18/2023 19:56:34 - INFO - __main__ - train loss is 0.042118433862924576\n",
      "Steps:  56%|▌| 8343/15000 [53:12<9:16:23,  5.01s/it, lr=9.53e-6, step_loss=0.04207/18/2023 19:56:35 - INFO - __main__ - train loss is 0.170473862439394\n",
      "Steps:  56%|▌| 8344/15000 [53:13<6:35:25,  3.56s/it, lr=9.53e-6, step_loss=0.12807/18/2023 19:56:35 - INFO - __main__ - train loss is 0.23916229233145714\n",
      "Steps:  56%|▌| 8345/15000 [53:13<4:42:53,  2.55s/it, lr=9.53e-6, step_loss=0.06807/18/2023 19:56:35 - INFO - __main__ - train loss is 0.5135019682347775\n",
      "Steps:  56%|▌| 8346/15000 [53:13<3:23:59,  1.84s/it, lr=9.53e-6, step_loss=0.27407/18/2023 19:56:35 - INFO - __main__ - train loss is 0.5163073446601629\n",
      "Steps:  56%|▌| 8347/15000 [53:13<2:28:52,  1.34s/it, lr=9.53e-6, step_loss=0.00207/18/2023 19:56:35 - INFO - __main__ - train loss is 0.6038793977349997\n",
      "Steps:  56%|▌| 8348/15000 [53:13<1:50:23,  1.00it/s, lr=9.53e-6, step_loss=0.08707/18/2023 19:56:36 - INFO - __main__ - train loss is 0.6287188474088907\n",
      "Steps:  56%|▌| 8349/15000 [53:13<1:23:17,  1.33it/s, lr=9.53e-6, step_loss=0.02407/18/2023 19:56:36 - INFO - __main__ - train loss is 0.9371145311743021\n",
      "Steps:  56%|▌| 8350/15000 [53:14<1:04:13,  1.73it/s, lr=9.53e-6, step_loss=0.30807/18/2023 19:56:36 - INFO - __main__ - train loss is 0.9399209669791162\n",
      "Steps:  56%|▌| 8351/15000 [53:14<50:51,  2.18it/s, lr=9.53e-6, step_loss=0.0028107/18/2023 19:56:36 - INFO - __main__ - train loss is 1.1766167185269296\n",
      "Steps:  56%|█ | 8352/15000 [53:14<41:29,  2.67it/s, lr=9.53e-6, step_loss=0.237]07/18/2023 19:56:36 - INFO - __main__ - train loss is 1.1968836239539087\n",
      "Steps:  56%|▌| 8353/15000 [53:14<34:56,  3.17it/s, lr=9.53e-6, step_loss=0.0203]07/18/2023 19:56:36 - INFO - __main__ - train loss is 1.2044664579443634\n",
      "Steps:  56%|▌| 8354/15000 [53:14<30:22,  3.65it/s, lr=9.53e-6, step_loss=0.0075807/18/2023 19:56:37 - INFO - __main__ - train loss is 1.3742731171660125\n",
      "Steps:  56%|█▋ | 8355/15000 [53:15<27:10,  4.08it/s, lr=9.53e-6, step_loss=0.17]07/18/2023 19:56:37 - INFO - __main__ - train loss is 1.3789051631465554\n",
      "Steps:  56%|▌| 8356/15000 [53:15<24:56,  4.44it/s, lr=9.53e-6, step_loss=0.0046307/18/2023 19:56:37 - INFO - __main__ - train loss is 1.380901311058551\n",
      "Steps:  56%|█ | 8357/15000 [53:15<23:33,  4.70it/s, lr=9.53e-6, step_loss=0.002]07/18/2023 19:56:37 - INFO - __main__ - train loss is 1.3865960943512619\n",
      "Steps:  56%|▌| 8358/15000 [53:15<22:33,  4.91it/s, lr=9.53e-6, step_loss=0.0056907/18/2023 19:56:37 - INFO - __main__ - train loss is 1.3920896421186626\n",
      "Steps:  56%|▌| 8359/15000 [53:15<21:42,  5.10it/s, lr=9.53e-6, step_loss=0.0054907/18/2023 19:56:38 - INFO - __main__ - train loss is 1.3951260631438345\n",
      "Steps:  56%|▌| 8360/15000 [53:15<21:07,  5.24it/s, lr=9.53e-6, step_loss=0.0030407/18/2023 19:56:38 - INFO - __main__ - train loss is 1.5030694936867803\n",
      "Steps:  56%|█ | 8361/15000 [53:16<20:42,  5.34it/s, lr=9.53e-6, step_loss=0.108]07/18/2023 19:56:38 - INFO - __main__ - train loss is 1.8833555912133306\n",
      "Steps:  56%|█▋ | 8362/15000 [53:16<20:26,  5.41it/s, lr=9.53e-6, step_loss=0.38]07/18/2023 19:56:38 - INFO - __main__ - train loss is 2.41291007748805\n",
      "Steps:  56%|█▋ | 8363/15000 [53:16<20:21,  5.43it/s, lr=9.53e-6, step_loss=0.53]07/18/2023 19:56:38 - INFO - __main__ - train loss is 2.4143797480501235\n",
      "Steps:  56%|▌| 8364/15000 [53:16<20:20,  5.44it/s, lr=9.53e-6, step_loss=0.0014707/18/2023 19:56:38 - INFO - __main__ - train loss is 2.5541739487089217\n",
      "Steps:  56%|█▋ | 8365/15000 [53:16<20:09,  5.49it/s, lr=9.53e-6, step_loss=0.14]07/18/2023 19:56:39 - INFO - __main__ - train loss is 2.558158340398222\n",
      "Steps:  56%|▌| 8366/15000 [53:17<20:02,  5.52it/s, lr=9.53e-6, step_loss=0.0039807/18/2023 19:56:39 - INFO - __main__ - train loss is 2.5988518283702433\n",
      "Steps:  56%|▌| 8367/15000 [53:17<19:57,  5.54it/s, lr=9.53e-6, step_loss=0.0407]07/18/2023 19:56:39 - INFO - __main__ - train loss is 2.7578814611770213\n",
      "Steps:  56%|█ | 8368/15000 [53:17<19:54,  5.55it/s, lr=9.53e-6, step_loss=0.159]07/18/2023 19:56:39 - INFO - __main__ - train loss is 2.811403459403664\n",
      "Steps:  56%|▌| 8369/15000 [53:17<19:59,  5.53it/s, lr=9.53e-6, step_loss=0.0535]07/18/2023 19:56:39 - INFO - __main__ - train loss is 3.0142534584738314\n",
      "Steps:  56%|█ | 8370/15000 [53:17<20:05,  5.50it/s, lr=9.53e-6, step_loss=0.203]07/18/2023 19:56:40 - INFO - __main__ - train loss is 3.570262393448502\n",
      "Steps:  56%|█ | 8371/15000 [53:17<20:13,  5.46it/s, lr=9.53e-6, step_loss=0.556]07/18/2023 19:56:40 - INFO - __main__ - train loss is 3.6707627312280238\n",
      "Steps:  56%|█ | 8372/15000 [53:18<20:07,  5.49it/s, lr=9.53e-6, step_loss=0.101]07/18/2023 19:56:40 - INFO - __main__ - train loss is 4.565655185375363\n",
      "Steps:  56%|█ | 8373/15000 [53:18<20:01,  5.52it/s, lr=9.53e-6, step_loss=0.895]07/18/2023 19:56:40 - INFO - __main__ - train loss is 4.567577400943264\n",
      "Steps:  56%|▌| 8374/15000 [53:18<19:56,  5.54it/s, lr=9.53e-6, step_loss=0.0019207/18/2023 19:56:40 - INFO - __main__ - train loss is 5.099869409343228\n",
      "Steps:  56%|█ | 8375/15000 [53:18<19:52,  5.56it/s, lr=9.53e-6, step_loss=0.532]07/18/2023 19:56:40 - INFO - __main__ - train loss is 5.137664338340983\n",
      "Steps:  56%|▌| 8376/15000 [53:18<19:50,  5.57it/s, lr=9.53e-6, step_loss=0.0378]07/18/2023 19:56:41 - INFO - __main__ - train loss is 5.241333408048376\n",
      "Steps:  56%|█ | 8377/15000 [53:19<19:49,  5.57it/s, lr=9.53e-6, step_loss=0.104]07/18/2023 19:56:41 - INFO - __main__ - train loss is 5.628158254316077\n",
      "Steps:  56%|█ | 8378/15000 [53:19<20:08,  5.48it/s, lr=9.53e-6, step_loss=0.387]07/18/2023 19:56:41 - INFO - __main__ - train loss is 5.8860092589166015\n",
      "Steps:  56%|█ | 8379/15000 [53:19<20:01,  5.51it/s, lr=9.53e-6, step_loss=0.258]07/18/2023 19:56:41 - INFO - __main__ - train loss is 6.127956418087706\n",
      "Steps:  56%|█ | 8380/15000 [53:19<20:06,  5.49it/s, lr=9.53e-6, step_loss=0.242]07/18/2023 19:56:41 - INFO - __main__ - train loss is 6.430309263756499\n",
      "Steps:  56%|█ | 8381/15000 [53:19<20:03,  5.50it/s, lr=9.53e-6, step_loss=0.302]07/18/2023 19:56:42 - INFO - __main__ - train loss is 6.434918331680819\n",
      "Steps:  56%|▌| 8382/15000 [53:19<20:13,  5.45it/s, lr=9.53e-6, step_loss=0.0046107/18/2023 19:56:42 - INFO - __main__ - train loss is 6.996129500446841\n",
      "Steps:  56%|█ | 8383/15000 [53:20<20:25,  5.40it/s, lr=9.53e-6, step_loss=0.561]07/18/2023 19:56:42 - INFO - __main__ - train loss is 7.191716375527903\n",
      "Steps:  56%|█ | 8384/15000 [53:20<20:42,  5.33it/s, lr=9.53e-6, step_loss=0.196]07/18/2023 19:56:42 - INFO - __main__ - train loss is 7.698815407929942\n",
      "Steps:  56%|█ | 8385/15000 [53:20<20:54,  5.27it/s, lr=9.53e-6, step_loss=0.507]07/18/2023 19:56:42 - INFO - __main__ - train loss is 7.9820290233474225\n",
      "Steps:  56%|█ | 8386/15000 [53:20<21:04,  5.23it/s, lr=9.53e-6, step_loss=0.283]07/18/2023 19:56:43 - INFO - __main__ - train loss is 8.085993672488257\n",
      "Steps:  56%|█ | 8387/15000 [53:20<21:19,  5.17it/s, lr=9.53e-6, step_loss=0.104]07/18/2023 19:56:43 - INFO - __main__ - train loss is 8.093549879034981\n",
      "Steps:  56%|▌| 8388/15000 [53:21<21:20,  5.16it/s, lr=9.53e-6, step_loss=0.0075607/18/2023 19:56:43 - INFO - __main__ - train loss is 8.273738832911476\n",
      "Steps:  56%|█▋ | 8389/15000 [53:21<21:20,  5.16it/s, lr=9.53e-6, step_loss=0.18]07/18/2023 19:56:43 - INFO - __main__ - train loss is 8.367302210768685\n",
      "Steps:  56%|▌| 8390/15000 [53:21<21:20,  5.16it/s, lr=9.53e-6, step_loss=0.0936]07/18/2023 19:56:43 - INFO - __main__ - train loss is 8.39230559929274\n",
      "Steps:  56%|█ | 8391/15000 [53:21<21:21,  5.16it/s, lr=9.53e-6, step_loss=0.025]07/18/2023 19:56:43 - INFO - __main__ - train loss is 8.442424962064251\n",
      "Steps:  56%|▌| 8392/15000 [53:21<21:19,  5.16it/s, lr=9.53e-6, step_loss=0.0501]07/18/2023 19:56:44 - INFO - __main__ - train loss is 8.584185817977414\n",
      "Steps:  56%|█ | 8393/15000 [53:22<21:09,  5.20it/s, lr=9.53e-6, step_loss=0.142]07/18/2023 19:56:44 - INFO - __main__ - train loss is 8.618465503444895\n",
      "Steps:  56%|▌| 8394/15000 [53:22<20:55,  5.26it/s, lr=9.53e-6, step_loss=0.0343]07/18/2023 19:56:44 - INFO - __main__ - train loss is 8.644324676832184\n",
      "Steps:  56%|▌| 8395/15000 [53:22<20:53,  5.27it/s, lr=9.53e-6, step_loss=0.0259]07/18/2023 19:56:44 - INFO - __main__ - train loss is 8.960004465421662\n",
      "Steps:  56%|█ | 8396/15000 [53:22<21:04,  5.22it/s, lr=9.53e-6, step_loss=0.316]07/18/2023 19:56:44 - INFO - __main__ - train loss is 9.14995721145533\n",
      "Steps:  56%|█▋ | 8397/15000 [53:22<21:10,  5.20it/s, lr=9.53e-6, step_loss=0.19]07/18/2023 19:56:45 - INFO - __main__ - train loss is 9.500932963332161\n",
      "Steps:  56%|█ | 8398/15000 [53:23<21:16,  5.17it/s, lr=9.53e-6, step_loss=0.351]07/18/2023 19:56:45 - INFO - __main__ - train loss is 9.643677921732888\n",
      "Steps:  56%|█ | 8399/15000 [53:23<21:22,  5.15it/s, lr=9.53e-6, step_loss=0.143]07/18/2023 19:56:45 - INFO - __main__ - train loss is 9.88501446112059\n",
      "Steps:  56%|█ | 8400/15000 [53:23<21:21,  5.15it/s, lr=9.53e-6, step_loss=0.241]07/18/2023 19:56:45 - INFO - __main__ - train loss is 10.183878944953904\n",
      "Steps:  56%|█ | 8401/15000 [53:23<21:22,  5.15it/s, lr=9.53e-6, step_loss=0.299]07/18/2023 19:56:45 - INFO - __main__ - train loss is 10.19196803192608\n",
      "Steps:  56%|▌| 8402/15000 [53:23<21:22,  5.14it/s, lr=9.53e-6, step_loss=0.0080907/18/2023 19:56:46 - INFO - __main__ - train loss is 10.592436709208414\n",
      "Steps:  56%|██▏ | 8403/15000 [53:23<21:23,  5.14it/s, lr=9.53e-6, step_loss=0.4]07/18/2023 19:56:46 - INFO - __main__ - train loss is 10.596978723304346\n",
      "Steps:  56%|▌| 8404/15000 [53:24<21:22,  5.15it/s, lr=9.53e-6, step_loss=0.0045407/18/2023 19:56:46 - INFO - __main__ - train loss is 10.608114789472893\n",
      "Steps:  56%|▌| 8405/15000 [53:24<21:20,  5.15it/s, lr=9.53e-6, step_loss=0.0111]07/18/2023 19:56:46 - INFO - __main__ - train loss is 10.616359844105318\n",
      "Steps:  56%|▌| 8406/15000 [53:24<21:19,  5.15it/s, lr=9.53e-6, step_loss=0.0082507/18/2023 19:56:46 - INFO - __main__ - train loss is 10.654585681157187\n",
      "Steps:  56%|▌| 8407/15000 [53:24<21:26,  5.12it/s, lr=9.53e-6, step_loss=0.0382]07/18/2023 19:56:47 - INFO - __main__ - train loss is 10.655883186263964\n",
      "Steps:  56%|▌| 8408/15000 [53:24<21:32,  5.10it/s, lr=9.53e-6, step_loss=0.0013]07/18/2023 19:56:47 - INFO - __main__ - train loss is 11.187774413032457\n",
      "Steps:  56%|█ | 8409/15000 [53:25<21:16,  5.16it/s, lr=9.52e-6, step_loss=0.532]07/18/2023 19:56:47 - INFO - __main__ - train loss is 11.255634994013235\n",
      "Steps:  56%|▌| 8410/15000 [53:25<20:56,  5.25it/s, lr=9.52e-6, step_loss=0.0679]07/18/2023 19:56:47 - INFO - __main__ - train loss is 11.261808644747362\n",
      "Steps:  56%|▌| 8411/15000 [53:25<20:51,  5.27it/s, lr=9.52e-6, step_loss=0.0061707/18/2023 19:56:47 - INFO - __main__ - train loss is 11.317414007848129\n",
      "Steps:  56%|▌| 8412/15000 [53:25<20:58,  5.23it/s, lr=9.52e-6, step_loss=0.0556]07/18/2023 19:56:48 - INFO - __main__ - train loss is 11.44456972903572\n",
      "Steps:  56%|█ | 8413/15000 [53:25<20:53,  5.25it/s, lr=9.52e-6, step_loss=0.127]07/18/2023 19:56:48 - INFO - __main__ - train loss is 11.488094970351085\n",
      "Steps:  56%|▌| 8414/15000 [53:26<21:02,  5.22it/s, lr=9.52e-6, step_loss=0.0435]07/18/2023 19:56:48 - INFO - __main__ - train loss is 11.490247601410374\n",
      "Steps:  56%|▌| 8415/15000 [53:26<21:00,  5.23it/s, lr=9.52e-6, step_loss=0.0021507/18/2023 19:56:48 - INFO - __main__ - train loss is 11.519190640887246\n",
      "Steps:  56%|▌| 8416/15000 [53:26<22:10,  4.95it/s, lr=9.52e-6, step_loss=0.0289]07/18/2023 19:56:48 - INFO - __main__ - train loss is 11.562177577754483\n",
      "Steps:  56%|█ | 8417/15000 [53:26<22:47,  4.81it/s, lr=9.52e-6, step_loss=0.043]07/18/2023 19:56:49 - INFO - __main__ - train loss is 11.571730369469151\n",
      "Steps:  56%|▌| 8418/15000 [53:26<22:03,  4.97it/s, lr=9.52e-6, step_loss=0.0095507/18/2023 19:56:49 - INFO - __main__ - train loss is 11.80649417056702\n",
      "Steps:  56%|█ | 8419/15000 [53:27<21:39,  5.07it/s, lr=9.52e-6, step_loss=0.235]07/18/2023 19:56:49 - INFO - __main__ - train loss is 11.809856810374185\n",
      "Steps:  56%|▌| 8420/15000 [53:27<21:10,  5.18it/s, lr=9.52e-6, step_loss=0.0033607/18/2023 19:56:49 - INFO - __main__ - train loss is 11.812170988414437\n",
      "Steps:  56%|▌| 8421/15000 [53:27<20:47,  5.27it/s, lr=9.52e-6, step_loss=0.0023107/18/2023 19:56:49 - INFO - __main__ - train loss is 11.83570700744167\n",
      "Steps:  56%|▌| 8422/15000 [53:27<20:30,  5.34it/s, lr=9.52e-6, step_loss=0.0235]07/18/2023 19:56:49 - INFO - __main__ - train loss is 12.127997933421284\n",
      "Steps:  56%|█ | 8423/15000 [53:27<20:12,  5.42it/s, lr=9.52e-6, step_loss=0.292]07/18/2023 19:56:50 - INFO - __main__ - train loss is 12.380043594632298\n",
      "Steps:  56%|█ | 8424/15000 [53:28<20:01,  5.47it/s, lr=9.52e-6, step_loss=0.252]07/18/2023 19:56:50 - INFO - __main__ - train loss is 12.382325091864914\n",
      "Steps:  56%|▌| 8425/15000 [53:28<19:52,  5.51it/s, lr=9.52e-6, step_loss=0.0022807/18/2023 19:56:50 - INFO - __main__ - train loss is 12.792109230067581\n",
      "Steps:  56%|█▋ | 8426/15000 [53:28<19:54,  5.50it/s, lr=9.52e-6, step_loss=0.41]07/18/2023 19:56:50 - INFO - __main__ - train loss is 12.867237971629947\n",
      "Steps:  56%|▌| 8427/15000 [53:28<19:58,  5.48it/s, lr=9.52e-6, step_loss=0.0751]07/18/2023 19:56:50 - INFO - __main__ - train loss is 13.36918263277039\n",
      "Steps:  56%|█ | 8428/15000 [53:28<19:58,  5.49it/s, lr=9.52e-6, step_loss=0.502]07/18/2023 19:56:51 - INFO - __main__ - train loss is 13.643189446534961\n",
      "Steps:  56%|█ | 8429/15000 [53:28<19:59,  5.48it/s, lr=9.52e-6, step_loss=0.274]07/18/2023 19:56:51 - INFO - __main__ - train loss is 13.891490326728672\n",
      "Steps:  56%|█ | 8430/15000 [53:29<19:56,  5.49it/s, lr=9.52e-6, step_loss=0.248]07/18/2023 19:56:51 - INFO - __main__ - train loss is 13.904883371200413\n",
      "Steps:  56%|▌| 8431/15000 [53:29<20:00,  5.47it/s, lr=9.52e-6, step_loss=0.0134]07/18/2023 19:56:51 - INFO - __main__ - train loss is 13.917698926758021\n",
      "Steps:  56%|▌| 8432/15000 [53:29<19:55,  5.49it/s, lr=9.52e-6, step_loss=0.0128]07/18/2023 19:56:51 - INFO - __main__ - train loss is 13.919880804605782\n",
      "Steps:  56%|▌| 8433/15000 [53:29<19:48,  5.53it/s, lr=9.52e-6, step_loss=0.0021807/18/2023 19:56:51 - INFO - __main__ - train loss is 13.92630551662296\n",
      "Steps:  56%|▌| 8434/15000 [53:29<19:42,  5.55it/s, lr=9.52e-6, step_loss=0.0064207/18/2023 19:56:52 - INFO - __main__ - train loss is 14.16134689655155\n",
      "Steps:  56%|█ | 8435/15000 [53:30<19:39,  5.57it/s, lr=9.52e-6, step_loss=0.235]07/18/2023 19:56:52 - INFO - __main__ - train loss is 14.472463919781148\n",
      "Steps:  56%|█ | 8436/15000 [53:30<19:49,  5.52it/s, lr=9.52e-6, step_loss=0.311]07/18/2023 19:56:52 - INFO - __main__ - train loss is 14.474127278896049\n",
      "Steps:  56%|▌| 8437/15000 [53:30<19:48,  5.52it/s, lr=9.52e-6, step_loss=0.0016607/18/2023 19:56:52 - INFO - __main__ - train loss is 14.498227794887498\n",
      "Steps:  56%|▌| 8438/15000 [53:30<19:41,  5.55it/s, lr=9.52e-6, step_loss=0.0241]07/18/2023 19:56:53 - INFO - __main__ - train loss is 14.77599432063289\n",
      "Steps:  56%|█▏| 8439/15000 [53:30<26:23,  4.14it/s, lr=9.52e-6, step_loss=0.278]07/18/2023 19:56:53 - INFO - __main__ - Per validation step average loss is 0.010641630738973618\n",
      "07/18/2023 19:56:53 - INFO - __main__ - Cumulative validation average loss is 0.010641630738973618\n",
      "07/18/2023 19:56:53 - INFO - __main__ - Per validation step average loss is 0.4874817728996277\n",
      "07/18/2023 19:56:53 - INFO - __main__ - Cumulative validation average loss is 0.4981234036386013\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Per validation step average loss is 0.11229740083217621\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Cumulative validation average loss is 0.6104208044707775\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Per validation step average loss is 0.6448119282722473\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Cumulative validation average loss is 1.2552327327430248\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Per validation step average loss is 0.022713832557201385\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Cumulative validation average loss is 1.2779465653002262\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Per validation step average loss is 0.1814587414264679\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Cumulative validation average loss is 1.459405306726694\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Per validation step average loss is 0.03203962743282318\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Cumulative validation average loss is 1.4914449341595173\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Per validation step average loss is 0.0024543653707951307\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Cumulative validation average loss is 1.4938992995303124\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Per validation step average loss is 0.3444446921348572\n",
      "07/18/2023 19:56:54 - INFO - __main__ - Cumulative validation average loss is 1.8383439916651696\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Per validation step average loss is 0.5438085794448853\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Cumulative validation average loss is 2.382152571110055\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Per validation step average loss is 0.20081759989261627\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Cumulative validation average loss is 2.582970171002671\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Per validation step average loss is 0.05763516575098038\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Cumulative validation average loss is 2.6406053367536515\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Average validation loss for Epoch 86 is 0.22005044472947097\n",
      "07/18/2023 19:56:55 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:57:08 - INFO - __main__ - Starting epoch 87\n",
      "07/18/2023 19:57:08 - INFO - __main__ - train loss is 0.5349833369255066\n",
      "Steps:  56%|▌| 8440/15000 [53:46<8:54:58,  4.89s/it, lr=9.52e-6, step_loss=0.53507/18/2023 19:57:08 - INFO - __main__ - train loss is 0.5481285117566586\n",
      "Steps:  56%|▌| 8441/15000 [53:46<6:20:36,  3.48s/it, lr=9.52e-6, step_loss=0.01307/18/2023 19:57:09 - INFO - __main__ - train loss is 0.5603897273540497\n",
      "Steps:  56%|▌| 8442/15000 [53:47<4:32:26,  2.49s/it, lr=9.52e-6, step_loss=0.01207/18/2023 19:57:09 - INFO - __main__ - train loss is 0.5704764658585191\n",
      "Steps:  56%|▌| 8443/15000 [53:47<3:16:30,  1.80s/it, lr=9.52e-6, step_loss=0.01007/18/2023 19:57:09 - INFO - __main__ - train loss is 0.8646134370937943\n",
      "Steps:  56%|▌| 8444/15000 [53:47<2:23:22,  1.31s/it, lr=9.52e-6, step_loss=0.29407/18/2023 19:57:09 - INFO - __main__ - train loss is 0.9879714557901025\n",
      "Steps:  56%|▌| 8445/15000 [53:47<1:46:30,  1.03it/s, lr=9.52e-6, step_loss=0.12307/18/2023 19:57:09 - INFO - __main__ - train loss is 1.3047815868631005\n",
      "Steps:  56%|▌| 8446/15000 [53:47<1:20:26,  1.36it/s, lr=9.52e-6, step_loss=0.31707/18/2023 19:57:10 - INFO - __main__ - train loss is 1.7061675200238824\n",
      "Steps:  56%|▌| 8447/15000 [53:47<1:02:07,  1.76it/s, lr=9.52e-6, step_loss=0.40107/18/2023 19:57:10 - INFO - __main__ - train loss is 1.798351333476603\n",
      "Steps:  56%|▌| 8448/15000 [53:48<49:18,  2.21it/s, lr=9.52e-6, step_loss=0.0922]07/18/2023 19:57:10 - INFO - __main__ - train loss is 1.809675776399672\n",
      "Steps:  56%|▌| 8449/15000 [53:48<40:18,  2.71it/s, lr=9.52e-6, step_loss=0.0113]07/18/2023 19:57:10 - INFO - __main__ - train loss is 1.9360328996554017\n",
      "Steps:  56%|█▏| 8450/15000 [53:48<34:01,  3.21it/s, lr=9.52e-6, step_loss=0.126]07/18/2023 19:57:10 - INFO - __main__ - train loss is 2.16099173668772\n",
      "Steps:  56%|█▏| 8451/15000 [53:48<29:37,  3.68it/s, lr=9.52e-6, step_loss=0.225]07/18/2023 19:57:10 - INFO - __main__ - train loss is 2.675340005196631\n",
      "Steps:  56%|█▏| 8452/15000 [53:48<26:33,  4.11it/s, lr=9.52e-6, step_loss=0.514]07/18/2023 19:57:11 - INFO - __main__ - train loss is 3.3632912123575807\n",
      "Steps:  56%|█▏| 8453/15000 [53:49<24:24,  4.47it/s, lr=9.52e-6, step_loss=0.688]07/18/2023 19:57:11 - INFO - __main__ - train loss is 3.625747092999518\n",
      "Steps:  56%|█▏| 8454/15000 [53:49<22:55,  4.76it/s, lr=9.52e-6, step_loss=0.262]07/18/2023 19:57:11 - INFO - __main__ - train loss is 3.7183777624741197\n",
      "Steps:  56%|▌| 8455/15000 [53:49<21:51,  4.99it/s, lr=9.52e-6, step_loss=0.0926]07/18/2023 19:57:11 - INFO - __main__ - train loss is 4.01971357408911\n",
      "Steps:  56%|█▏| 8456/15000 [53:49<21:05,  5.17it/s, lr=9.52e-6, step_loss=0.301]07/18/2023 19:57:11 - INFO - __main__ - train loss is 4.240001016296446\n",
      "Steps:  56%|█▋ | 8457/15000 [53:49<20:35,  5.29it/s, lr=9.52e-6, step_loss=0.22]07/18/2023 19:57:12 - INFO - __main__ - train loss is 4.401715033687651\n",
      "Steps:  56%|█▏| 8458/15000 [53:49<20:14,  5.38it/s, lr=9.52e-6, step_loss=0.162]07/18/2023 19:57:12 - INFO - __main__ - train loss is 4.705082350410521\n",
      "Steps:  56%|█▏| 8459/15000 [53:50<20:00,  5.45it/s, lr=9.52e-6, step_loss=0.303]07/18/2023 19:57:12 - INFO - __main__ - train loss is 4.9410485262051225\n",
      "Steps:  56%|█▏| 8460/15000 [53:50<19:49,  5.50it/s, lr=9.52e-6, step_loss=0.236]07/18/2023 19:57:12 - INFO - __main__ - train loss is 5.337494962848723\n",
      "Steps:  56%|█▏| 8461/15000 [53:50<19:43,  5.53it/s, lr=9.52e-6, step_loss=0.396]07/18/2023 19:57:12 - INFO - __main__ - train loss is 5.42084198538214\n",
      "Steps:  56%|▌| 8462/15000 [53:50<19:37,  5.55it/s, lr=9.52e-6, step_loss=0.0833]07/18/2023 19:57:12 - INFO - __main__ - train loss is 5.427381397224963\n",
      "Steps:  56%|▌| 8463/15000 [53:50<19:33,  5.57it/s, lr=9.52e-6, step_loss=0.0065407/18/2023 19:57:13 - INFO - __main__ - train loss is 5.43414392741397\n",
      "Steps:  56%|▌| 8464/15000 [53:50<19:30,  5.58it/s, lr=9.52e-6, step_loss=0.0067607/18/2023 19:57:13 - INFO - __main__ - train loss is 5.523637269157916\n",
      "Steps:  56%|▌| 8465/15000 [53:51<19:28,  5.59it/s, lr=9.52e-6, step_loss=0.0895]07/18/2023 19:57:13 - INFO - __main__ - train loss is 5.543090645689517\n",
      "Steps:  56%|▌| 8466/15000 [53:51<19:26,  5.60it/s, lr=9.52e-6, step_loss=0.0195]07/18/2023 19:57:13 - INFO - __main__ - train loss is 5.559436552692205\n",
      "Steps:  56%|▌| 8467/15000 [53:51<19:25,  5.61it/s, lr=9.52e-6, step_loss=0.0163]07/18/2023 19:57:13 - INFO - __main__ - train loss is 5.597687237430364\n",
      "Steps:  56%|▌| 8468/15000 [53:51<19:24,  5.61it/s, lr=9.52e-6, step_loss=0.0383]07/18/2023 19:57:13 - INFO - __main__ - train loss is 5.606575754005462\n",
      "Steps:  56%|▌| 8469/15000 [53:51<19:24,  5.61it/s, lr=9.52e-6, step_loss=0.0088907/18/2023 19:57:14 - INFO - __main__ - train loss is 5.641572420019656\n",
      "Steps:  56%|█▏| 8470/15000 [53:52<19:23,  5.61it/s, lr=9.52e-6, step_loss=0.035]07/18/2023 19:57:14 - INFO - __main__ - train loss is 5.730039153713733\n",
      "Steps:  56%|▌| 8471/15000 [53:52<19:22,  5.61it/s, lr=9.52e-6, step_loss=0.0885]07/18/2023 19:57:14 - INFO - __main__ - train loss is 5.761064209509641\n",
      "Steps:  56%|█▏| 8472/15000 [53:52<19:22,  5.61it/s, lr=9.52e-6, step_loss=0.031]07/18/2023 19:57:14 - INFO - __main__ - train loss is 5.8014596668072045\n",
      "Steps:  56%|▌| 8473/15000 [53:52<19:22,  5.61it/s, lr=9.52e-6, step_loss=0.0404]07/18/2023 19:57:14 - INFO - __main__ - train loss is 5.8925318834371865\n",
      "Steps:  56%|▌| 8474/15000 [53:52<19:29,  5.58it/s, lr=9.52e-6, step_loss=0.0911]07/18/2023 19:57:15 - INFO - __main__ - train loss is 6.1276305434294045\n",
      "Steps:  56%|█▏| 8475/15000 [53:52<19:39,  5.53it/s, lr=9.52e-6, step_loss=0.235]07/18/2023 19:57:15 - INFO - __main__ - train loss is 6.1575294774957\n",
      "Steps:  57%|▌| 8476/15000 [53:53<19:38,  5.54it/s, lr=9.52e-6, step_loss=0.0299]07/18/2023 19:57:15 - INFO - __main__ - train loss is 6.237949502188712\n",
      "Steps:  57%|▌| 8477/15000 [53:53<19:42,  5.52it/s, lr=9.52e-6, step_loss=0.0804]07/18/2023 19:57:15 - INFO - __main__ - train loss is 6.246974420268089\n",
      "Steps:  57%|▌| 8478/15000 [53:53<19:47,  5.49it/s, lr=9.52e-6, step_loss=0.0090207/18/2023 19:57:15 - INFO - __main__ - train loss is 6.250955576077104\n",
      "Steps:  57%|▌| 8479/15000 [53:53<19:50,  5.48it/s, lr=9.52e-6, step_loss=0.0039807/18/2023 19:57:15 - INFO - __main__ - train loss is 6.293143788352609\n",
      "Steps:  57%|▌| 8480/15000 [53:53<19:42,  5.52it/s, lr=9.52e-6, step_loss=0.0422]07/18/2023 19:57:16 - INFO - __main__ - train loss is 6.464418077841401\n",
      "Steps:  57%|█▏| 8481/15000 [53:54<19:36,  5.54it/s, lr=9.52e-6, step_loss=0.171]07/18/2023 19:57:16 - INFO - __main__ - train loss is 6.494758879765868\n",
      "Steps:  57%|▌| 8482/15000 [53:54<19:32,  5.56it/s, lr=9.52e-6, step_loss=0.0303]07/18/2023 19:57:16 - INFO - __main__ - train loss is 6.497624900657684\n",
      "Steps:  57%|▌| 8483/15000 [53:54<19:29,  5.57it/s, lr=9.52e-6, step_loss=0.0028707/18/2023 19:57:16 - INFO - __main__ - train loss is 6.508892681915313\n",
      "Steps:  57%|▌| 8484/15000 [53:54<19:35,  5.54it/s, lr=9.52e-6, step_loss=0.0113]07/18/2023 19:57:16 - INFO - __main__ - train loss is 6.519585399422795\n",
      "Steps:  57%|▌| 8485/15000 [53:54<19:31,  5.56it/s, lr=9.52e-6, step_loss=0.0107]07/18/2023 19:57:17 - INFO - __main__ - train loss is 6.5233521142508835\n",
      "Steps:  57%|▌| 8486/15000 [53:54<19:28,  5.57it/s, lr=9.52e-6, step_loss=0.0037707/18/2023 19:57:17 - INFO - __main__ - train loss is 6.528136227047071\n",
      "Steps:  57%|▌| 8487/15000 [53:55<19:38,  5.53it/s, lr=9.52e-6, step_loss=0.0047807/18/2023 19:57:17 - INFO - __main__ - train loss is 7.123781118309125\n",
      "Steps:  57%|█▏| 8488/15000 [53:55<19:39,  5.52it/s, lr=9.52e-6, step_loss=0.596]07/18/2023 19:57:17 - INFO - __main__ - train loss is 7.144655652111396\n",
      "Steps:  57%|▌| 8489/15000 [53:55<19:33,  5.55it/s, lr=9.52e-6, step_loss=0.0209]07/18/2023 19:57:17 - INFO - __main__ - train loss is 7.186016723280773\n",
      "Steps:  57%|▌| 8490/15000 [53:55<19:30,  5.56it/s, lr=9.52e-6, step_loss=0.0414]07/18/2023 19:57:17 - INFO - __main__ - train loss is 7.208870686357841\n",
      "Steps:  57%|▌| 8491/15000 [53:55<19:27,  5.58it/s, lr=9.52e-6, step_loss=0.0229]07/18/2023 19:57:18 - INFO - __main__ - train loss is 7.674768663709983\n",
      "Steps:  57%|█▏| 8492/15000 [53:56<19:36,  5.53it/s, lr=9.52e-6, step_loss=0.466]07/18/2023 19:57:18 - INFO - __main__ - train loss is 7.706685773795471\n",
      "Steps:  57%|▌| 8493/15000 [53:56<19:38,  5.52it/s, lr=9.52e-6, step_loss=0.0319]07/18/2023 19:57:18 - INFO - __main__ - train loss is 7.929001502459869\n",
      "Steps:  57%|█▏| 8494/15000 [53:56<19:33,  5.54it/s, lr=9.52e-6, step_loss=0.222]07/18/2023 19:57:18 - INFO - __main__ - train loss is 7.953514732187614\n",
      "Steps:  57%|▌| 8495/15000 [53:56<19:29,  5.56it/s, lr=9.52e-6, step_loss=0.0245]07/18/2023 19:57:18 - INFO - __main__ - train loss is 7.9564836726058275\n",
      "Steps:  57%|▌| 8496/15000 [53:56<19:38,  5.52it/s, lr=9.52e-6, step_loss=0.0029707/18/2023 19:57:19 - INFO - __main__ - train loss is 7.978167700814083\n",
      "Steps:  57%|▌| 8497/15000 [53:56<19:47,  5.48it/s, lr=9.52e-6, step_loss=0.0217]07/18/2023 19:57:19 - INFO - __main__ - train loss is 8.491683113621548\n",
      "Steps:  57%|█▏| 8498/15000 [53:57<19:43,  5.50it/s, lr=9.51e-6, step_loss=0.514]07/18/2023 19:57:19 - INFO - __main__ - train loss is 8.53808334027417\n",
      "Steps:  57%|▌| 8499/15000 [53:57<19:36,  5.53it/s, lr=9.51e-6, step_loss=0.0464]07/18/2023 19:57:19 - INFO - __main__ - train loss is 8.639066579984501\n",
      "Steps:  57%|▌| 8500/15000 [53:57<19:30,  5.55it/s, lr=9.51e-6, step_loss=0.0464]07/18/2023 19:57:19 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-8500\n",
      "07/18/2023 19:57:19 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 19:57:19,670] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 19:57:19,674] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-8500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 19:57:19,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-8500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 19:57:19,682] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-8500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 19:57:19,682] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-8500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 19:57:19,704] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-8500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 19:57:19,704] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-8500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 19:57:19,704] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 19:57:19 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-8500/pytorch_model\n",
      "07/18/2023 19:57:19 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-8500/scheduler.bin\n",
      "07/18/2023 19:57:19 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-8500/random_states_0.pkl\n",
      "07/18/2023 19:57:19 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-8500\n",
      "Steps:  57%|█▏| 8500/15000 [53:57<19:30,  5.55it/s, lr=9.51e-6, step_loss=0.101]07/18/2023 19:57:19 - INFO - __main__ - train loss is 9.049191060708836\n",
      "Steps:  57%|█▋ | 8501/15000 [53:57<20:38,  5.25it/s, lr=9.51e-6, step_loss=0.41]07/18/2023 19:57:19 - INFO - __main__ - train loss is 9.08932141517289\n",
      "Steps:  57%|▌| 8502/15000 [53:57<20:25,  5.30it/s, lr=9.51e-6, step_loss=0.0401]07/18/2023 19:57:20 - INFO - __main__ - train loss is 9.103199612582102\n",
      "Steps:  57%|▌| 8503/15000 [53:58<20:17,  5.34it/s, lr=9.51e-6, step_loss=0.0139]07/18/2023 19:57:20 - INFO - __main__ - train loss is 9.122341813752428\n",
      "Steps:  57%|▌| 8504/15000 [53:58<20:21,  5.32it/s, lr=9.51e-6, step_loss=0.0191]07/18/2023 19:57:20 - INFO - __main__ - train loss is 9.154977819183841\n",
      "Steps:  57%|▌| 8505/15000 [53:58<20:13,  5.35it/s, lr=9.51e-6, step_loss=0.0326]07/18/2023 19:57:20 - INFO - __main__ - train loss is 9.45719631598331\n",
      "Steps:  57%|█▏| 8506/15000 [53:58<20:00,  5.41it/s, lr=9.51e-6, step_loss=0.302]07/18/2023 19:57:20 - INFO - __main__ - train loss is 9.458802111679688\n",
      "Steps:  57%|▌| 8507/15000 [53:58<19:59,  5.41it/s, lr=9.51e-6, step_loss=0.0016107/18/2023 19:57:21 - INFO - __main__ - train loss is 9.555251009995118\n",
      "Steps:  57%|▌| 8508/15000 [53:58<19:50,  5.46it/s, lr=9.51e-6, step_loss=0.0964]07/18/2023 19:57:21 - INFO - __main__ - train loss is 9.560952329309657\n",
      "Steps:  57%|▌| 8509/15000 [53:59<19:41,  5.49it/s, lr=9.51e-6, step_loss=0.0057]07/18/2023 19:57:21 - INFO - __main__ - train loss is 9.562415413442068\n",
      "Steps:  57%|▌| 8510/15000 [53:59<19:45,  5.47it/s, lr=9.51e-6, step_loss=0.0014607/18/2023 19:57:21 - INFO - __main__ - train loss is 9.81048790353816\n",
      "Steps:  57%|█▏| 8511/15000 [53:59<19:41,  5.49it/s, lr=9.51e-6, step_loss=0.248]07/18/2023 19:57:21 - INFO - __main__ - train loss is 9.947384662809782\n",
      "Steps:  57%|█▏| 8512/15000 [53:59<19:33,  5.53it/s, lr=9.51e-6, step_loss=0.137]07/18/2023 19:57:21 - INFO - __main__ - train loss is 10.348456449690275\n",
      "Steps:  57%|█▏| 8513/15000 [53:59<19:28,  5.55it/s, lr=9.51e-6, step_loss=0.401]07/18/2023 19:57:22 - INFO - __main__ - train loss is 10.379746347549371\n",
      "Steps:  57%|▌| 8514/15000 [54:00<19:24,  5.57it/s, lr=9.51e-6, step_loss=0.0313]07/18/2023 19:57:22 - INFO - __main__ - train loss is 10.566062807920389\n",
      "Steps:  57%|█▏| 8515/15000 [54:00<19:22,  5.58it/s, lr=9.51e-6, step_loss=0.186]07/18/2023 19:57:22 - INFO - __main__ - train loss is 11.013364314916544\n",
      "Steps:  57%|█▏| 8516/15000 [54:00<19:21,  5.58it/s, lr=9.51e-6, step_loss=0.447]07/18/2023 19:57:22 - INFO - __main__ - train loss is 11.022717079962604\n",
      "Steps:  57%|▌| 8517/15000 [54:00<19:30,  5.54it/s, lr=9.51e-6, step_loss=0.0093507/18/2023 19:57:22 - INFO - __main__ - train loss is 11.129378794576041\n",
      "Steps:  57%|█▏| 8518/15000 [54:00<19:30,  5.54it/s, lr=9.51e-6, step_loss=0.107]07/18/2023 19:57:23 - INFO - __main__ - train loss is 11.164276475901715\n",
      "Steps:  57%|▌| 8519/15000 [54:00<19:36,  5.51it/s, lr=9.51e-6, step_loss=0.0349]07/18/2023 19:57:23 - INFO - __main__ - train loss is 11.415287489886396\n",
      "Steps:  57%|█▏| 8520/15000 [54:01<19:43,  5.48it/s, lr=9.51e-6, step_loss=0.251]07/18/2023 19:57:23 - INFO - __main__ - train loss is 11.44707051932346\n",
      "Steps:  57%|▌| 8521/15000 [54:01<19:50,  5.44it/s, lr=9.51e-6, step_loss=0.0318]07/18/2023 19:57:23 - INFO - __main__ - train loss is 11.457583275507204\n",
      "Steps:  57%|▌| 8522/15000 [54:01<21:36,  5.00it/s, lr=9.51e-6, step_loss=0.0105]07/18/2023 19:57:23 - INFO - __main__ - train loss is 11.802659538458101\n",
      "Steps:  57%|█▏| 8523/15000 [54:01<21:14,  5.08it/s, lr=9.51e-6, step_loss=0.345]07/18/2023 19:57:24 - INFO - __main__ - train loss is 11.98287872679066\n",
      "Steps:  57%|█▋ | 8524/15000 [54:01<20:40,  5.22it/s, lr=9.51e-6, step_loss=0.18]07/18/2023 19:57:24 - INFO - __main__ - train loss is 12.149797958205454\n",
      "Steps:  57%|█▏| 8525/15000 [54:02<20:23,  5.29it/s, lr=9.51e-6, step_loss=0.167]07/18/2023 19:57:24 - INFO - __main__ - train loss is 12.41412083513569\n",
      "Steps:  57%|█▏| 8526/15000 [54:02<20:03,  5.38it/s, lr=9.51e-6, step_loss=0.264]07/18/2023 19:57:24 - INFO - __main__ - train loss is 12.709536236594431\n",
      "Steps:  57%|█▏| 8527/15000 [54:02<19:54,  5.42it/s, lr=9.51e-6, step_loss=0.295]07/18/2023 19:57:24 - INFO - __main__ - train loss is 12.710885632433929\n",
      "Steps:  57%|▌| 8528/15000 [54:02<19:41,  5.48it/s, lr=9.51e-6, step_loss=0.0013507/18/2023 19:57:24 - INFO - __main__ - train loss is 12.77034100482706\n",
      "Steps:  57%|▌| 8529/15000 [54:02<19:32,  5.52it/s, lr=9.51e-6, step_loss=0.0595]07/18/2023 19:57:25 - INFO - __main__ - train loss is 12.776324967038818\n",
      "Steps:  57%|▌| 8530/15000 [54:03<19:27,  5.54it/s, lr=9.51e-6, step_loss=0.0059807/18/2023 19:57:25 - INFO - __main__ - train loss is 12.778364922502078\n",
      "Steps:  57%|▌| 8531/15000 [54:03<19:22,  5.57it/s, lr=9.51e-6, step_loss=0.0020407/18/2023 19:57:25 - INFO - __main__ - train loss is 13.099225368001498\n",
      "Steps:  57%|█▏| 8532/15000 [54:03<19:20,  5.57it/s, lr=9.51e-6, step_loss=0.321]07/18/2023 19:57:25 - INFO - __main__ - train loss is 13.106541928951629\n",
      "Steps:  57%|▌| 8533/15000 [54:03<19:17,  5.59it/s, lr=9.51e-6, step_loss=0.0073207/18/2023 19:57:25 - INFO - __main__ - train loss is 13.325326037709601\n",
      "Steps:  57%|█▏| 8534/15000 [54:03<19:15,  5.60it/s, lr=9.51e-6, step_loss=0.219]07/18/2023 19:57:26 - INFO - __main__ - train loss is 13.544252944295295\n",
      "Steps:  57%|█▏| 8535/15000 [54:03<19:15,  5.59it/s, lr=9.51e-6, step_loss=0.219]07/18/2023 19:57:26 - INFO - __main__ - train loss is 13.555488986079581\n",
      "Steps:  57%|▌| 8536/15000 [54:04<25:55,  4.16it/s, lr=9.51e-6, step_loss=0.0112]07/18/2023 19:57:27 - INFO - __main__ - Per validation step average loss is 0.27851197123527527\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Cumulative validation average loss is 0.27851197123527527\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Per validation step average loss is 0.041662536561489105\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Cumulative validation average loss is 0.3201745077967644\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Per validation step average loss is 0.09636686742305756\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Cumulative validation average loss is 0.41654137521982193\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Per validation step average loss is 0.004328330047428608\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Cumulative validation average loss is 0.42086970526725054\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Per validation step average loss is 0.4209302067756653\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Cumulative validation average loss is 0.8417999120429158\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Per validation step average loss is 0.04495672509074211\n",
      "07/18/2023 19:57:27 - INFO - __main__ - Cumulative validation average loss is 0.8867566371336579\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Per validation step average loss is 0.003155364654958248\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Cumulative validation average loss is 0.8899120017886162\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Per validation step average loss is 0.28295132517814636\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Cumulative validation average loss is 1.1728633269667625\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Per validation step average loss is 0.3056577444076538\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Cumulative validation average loss is 1.4785210713744164\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Per validation step average loss is 0.04949447140097618\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Cumulative validation average loss is 1.5280155427753925\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Per validation step average loss is 0.010257144458591938\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Cumulative validation average loss is 1.5382726872339845\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Per validation step average loss is 0.014553263783454895\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Cumulative validation average loss is 1.5528259510174394\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Average validation loss for Epoch 87 is 0.12940216258478662\n",
      "07/18/2023 19:57:28 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:57:41 - INFO - __main__ - Starting epoch 88\n",
      "07/18/2023 19:57:42 - INFO - __main__ - train loss is 0.0022913352586328983\n",
      "Steps:  57%|▌| 8537/15000 [54:20<8:47:07,  4.89s/it, lr=9.51e-6, step_loss=0.00207/18/2023 19:57:42 - INFO - __main__ - train loss is 0.593454493675381\n",
      "Steps:  57%|▌| 8538/15000 [54:20<6:14:55,  3.48s/it, lr=9.51e-6, step_loss=0.59107/18/2023 19:57:42 - INFO - __main__ - train loss is 0.6376544148661196\n",
      "Steps:  57%|▌| 8539/15000 [54:20<4:28:15,  2.49s/it, lr=9.51e-6, step_loss=0.04407/18/2023 19:57:42 - INFO - __main__ - train loss is 0.6395583602134138\n",
      "Steps:  57%|▌| 8540/15000 [54:20<3:13:35,  1.80s/it, lr=9.51e-6, step_loss=0.00107/18/2023 19:57:42 - INFO - __main__ - train loss is 0.6437838429119438\n",
      "Steps:  57%|▌| 8541/15000 [54:20<2:21:41,  1.32s/it, lr=9.51e-6, step_loss=0.00407/18/2023 19:57:43 - INFO - __main__ - train loss is 0.6907421702053398\n",
      "Steps:  57%|▌| 8542/15000 [54:20<1:45:25,  1.02it/s, lr=9.51e-6, step_loss=0.04707/18/2023 19:57:43 - INFO - __main__ - train loss is 0.7743141853716224\n",
      "Steps:  57%|▌| 8543/15000 [54:21<1:20:02,  1.34it/s, lr=9.51e-6, step_loss=0.08307/18/2023 19:57:43 - INFO - __main__ - train loss is 0.7810121008660644\n",
      "Steps:  57%|▌| 8544/15000 [54:21<1:02:13,  1.73it/s, lr=9.51e-6, step_loss=0.00607/18/2023 19:57:43 - INFO - __main__ - train loss is 0.8601390176918358\n",
      "Steps:  57%|▌| 8545/15000 [54:21<49:33,  2.17it/s, lr=9.51e-6, step_loss=0.0791]07/18/2023 19:57:43 - INFO - __main__ - train loss is 0.8707364646252245\n",
      "Steps:  57%|▌| 8546/15000 [54:21<40:30,  2.66it/s, lr=9.51e-6, step_loss=0.0106]07/18/2023 19:57:44 - INFO - __main__ - train loss is 1.2980198708828539\n",
      "Steps:  57%|█▏| 8547/15000 [54:21<34:32,  3.11it/s, lr=9.51e-6, step_loss=0.427]07/18/2023 19:57:44 - INFO - __main__ - train loss is 1.3029972387012094\n",
      "Steps:  57%|▌| 8548/15000 [54:22<30:15,  3.55it/s, lr=9.51e-6, step_loss=0.0049807/18/2023 19:57:44 - INFO - __main__ - train loss is 1.904757030075416\n",
      "Steps:  57%|█▏| 8549/15000 [54:22<27:24,  3.92it/s, lr=9.51e-6, step_loss=0.602]07/18/2023 19:57:44 - INFO - __main__ - train loss is 1.9161960144992918\n",
      "Steps:  57%|▌| 8550/15000 [54:22<25:27,  4.22it/s, lr=9.51e-6, step_loss=0.0114]07/18/2023 19:57:44 - INFO - __main__ - train loss is 2.187027301406488\n",
      "Steps:  57%|█▏| 8551/15000 [54:22<24:02,  4.47it/s, lr=9.51e-6, step_loss=0.271]07/18/2023 19:57:44 - INFO - __main__ - train loss is 2.2310237211640924\n",
      "Steps:  57%|█▏| 8552/15000 [54:22<23:05,  4.65it/s, lr=9.51e-6, step_loss=0.044]07/18/2023 19:57:45 - INFO - __main__ - train loss is 2.3631003422196954\n",
      "Steps:  57%|█▏| 8553/15000 [54:23<22:03,  4.87it/s, lr=9.51e-6, step_loss=0.132]07/18/2023 19:57:45 - INFO - __main__ - train loss is 2.5096062642987818\n",
      "Steps:  57%|█▏| 8554/15000 [54:23<21:33,  4.98it/s, lr=9.51e-6, step_loss=0.147]07/18/2023 19:57:45 - INFO - __main__ - train loss is 2.6393037212546915\n",
      "Steps:  57%|█▋ | 8555/15000 [54:23<21:22,  5.03it/s, lr=9.51e-6, step_loss=0.13]07/18/2023 19:57:45 - INFO - __main__ - train loss is 2.7331430760677904\n",
      "Steps:  57%|▌| 8556/15000 [54:23<21:12,  5.06it/s, lr=9.51e-6, step_loss=0.0938]07/18/2023 19:57:45 - INFO - __main__ - train loss is 2.788337252801284\n",
      "Steps:  57%|▌| 8557/15000 [54:23<21:05,  5.09it/s, lr=9.51e-6, step_loss=0.0552]07/18/2023 19:57:46 - INFO - __main__ - train loss is 2.7936880828347057\n",
      "Steps:  57%|▌| 8558/15000 [54:24<20:41,  5.19it/s, lr=9.51e-6, step_loss=0.0053507/18/2023 19:57:46 - INFO - __main__ - train loss is 2.8129637555684894\n",
      "Steps:  57%|▌| 8559/15000 [54:24<20:34,  5.22it/s, lr=9.51e-6, step_loss=0.0193]07/18/2023 19:57:46 - INFO - __main__ - train loss is 2.816696437774226\n",
      "Steps:  57%|▌| 8560/15000 [54:24<20:37,  5.20it/s, lr=9.51e-6, step_loss=0.0037307/18/2023 19:57:46 - INFO - __main__ - train loss is 2.9159308474045247\n",
      "Steps:  57%|▌| 8561/15000 [54:24<20:40,  5.19it/s, lr=9.51e-6, step_loss=0.0992]07/18/2023 19:57:46 - INFO - __main__ - train loss is 3.21586416172795\n",
      "Steps:  57%|██▎ | 8562/15000 [54:24<20:46,  5.16it/s, lr=9.51e-6, step_loss=0.3]07/18/2023 19:57:47 - INFO - __main__ - train loss is 3.302397708175704\n",
      "Steps:  57%|▌| 8563/15000 [54:24<20:48,  5.16it/s, lr=9.51e-6, step_loss=0.0865]07/18/2023 19:57:47 - INFO - __main__ - train loss is 3.3251406874042004\n",
      "Steps:  57%|▌| 8564/15000 [54:25<20:49,  5.15it/s, lr=9.51e-6, step_loss=0.0227]07/18/2023 19:57:47 - INFO - __main__ - train loss is 3.32733899098821\n",
      "Steps:  57%|▌| 8565/15000 [54:25<20:50,  5.15it/s, lr=9.51e-6, step_loss=0.0022]07/18/2023 19:57:47 - INFO - __main__ - train loss is 3.4443511341232806\n",
      "Steps:  57%|█▏| 8566/15000 [54:25<20:54,  5.13it/s, lr=9.51e-6, step_loss=0.117]07/18/2023 19:57:47 - INFO - __main__ - train loss is 3.881465730490163\n",
      "Steps:  57%|█▏| 8567/15000 [54:25<20:51,  5.14it/s, lr=9.51e-6, step_loss=0.437]07/18/2023 19:57:48 - INFO - __main__ - train loss is 3.8981629305053502\n",
      "Steps:  57%|▌| 8568/15000 [54:25<20:56,  5.12it/s, lr=9.51e-6, step_loss=0.0167]07/18/2023 19:57:48 - INFO - __main__ - train loss is 4.226562231080607\n",
      "Steps:  57%|█▏| 8569/15000 [54:26<20:55,  5.12it/s, lr=9.51e-6, step_loss=0.328]07/18/2023 19:57:48 - INFO - __main__ - train loss is 4.6227720968890935\n",
      "Steps:  57%|█▏| 8570/15000 [54:26<20:53,  5.13it/s, lr=9.51e-6, step_loss=0.396]07/18/2023 19:57:48 - INFO - __main__ - train loss is 4.721113129751757\n",
      "Steps:  57%|▌| 8571/15000 [54:26<20:53,  5.13it/s, lr=9.51e-6, step_loss=0.0983]07/18/2023 19:57:48 - INFO - __main__ - train loss is 4.724533890374005\n",
      "Steps:  57%|▌| 8572/15000 [54:26<20:52,  5.13it/s, lr=9.51e-6, step_loss=0.0034207/18/2023 19:57:49 - INFO - __main__ - train loss is 4.7514135940000415\n",
      "Steps:  57%|▌| 8573/15000 [54:26<20:50,  5.14it/s, lr=9.51e-6, step_loss=0.0269]07/18/2023 19:57:49 - INFO - __main__ - train loss is 5.326523850671947\n",
      "Steps:  57%|█▏| 8574/15000 [54:27<20:50,  5.14it/s, lr=9.51e-6, step_loss=0.575]07/18/2023 19:57:49 - INFO - __main__ - train loss is 5.336168031208217\n",
      "Steps:  57%|▌| 8575/15000 [54:27<20:52,  5.13it/s, lr=9.51e-6, step_loss=0.0096407/18/2023 19:57:49 - INFO - __main__ - train loss is 5.38502314966172\n",
      "Steps:  57%|▌| 8576/15000 [54:27<20:38,  5.18it/s, lr=9.51e-6, step_loss=0.0489]07/18/2023 19:57:49 - INFO - __main__ - train loss is 5.412356457673013\n",
      "Steps:  57%|▌| 8577/15000 [54:27<20:14,  5.29it/s, lr=9.51e-6, step_loss=0.0273]07/18/2023 19:57:49 - INFO - __main__ - train loss is 5.438186961226165\n",
      "Steps:  57%|▌| 8578/15000 [54:27<19:55,  5.37it/s, lr=9.51e-6, step_loss=0.0258]07/18/2023 19:57:50 - INFO - __main__ - train loss is 5.640652435831726\n",
      "Steps:  57%|█▏| 8579/15000 [54:28<19:41,  5.44it/s, lr=9.51e-6, step_loss=0.202]07/18/2023 19:57:50 - INFO - __main__ - train loss is 5.7745415745303035\n",
      "Steps:  57%|█▏| 8580/15000 [54:28<19:31,  5.48it/s, lr=9.51e-6, step_loss=0.134]07/18/2023 19:57:50 - INFO - __main__ - train loss is 5.777660418767482\n",
      "Steps:  57%|▌| 8581/15000 [54:28<19:25,  5.51it/s, lr=9.51e-6, step_loss=0.0031207/18/2023 19:57:50 - INFO - __main__ - train loss is 6.20971154095605\n",
      "Steps:  57%|█▏| 8582/15000 [54:28<19:20,  5.53it/s, lr=9.51e-6, step_loss=0.432]07/18/2023 19:57:50 - INFO - __main__ - train loss is 6.2623756979592144\n",
      "Steps:  57%|▌| 8583/15000 [54:28<19:16,  5.55it/s, lr=9.51e-6, step_loss=0.0527]07/18/2023 19:57:51 - INFO - __main__ - train loss is 6.268568412866443\n",
      "Steps:  57%|▌| 8584/15000 [54:28<19:12,  5.57it/s, lr=9.51e-6, step_loss=0.0061907/18/2023 19:57:51 - INFO - __main__ - train loss is 6.43174591800198\n",
      "Steps:  57%|█▏| 8585/15000 [54:29<19:10,  5.57it/s, lr=9.51e-6, step_loss=0.163]07/18/2023 19:57:51 - INFO - __main__ - train loss is 6.545527273323387\n",
      "Steps:  57%|█▏| 8586/15000 [54:29<19:11,  5.57it/s, lr=9.51e-6, step_loss=0.114]07/18/2023 19:57:51 - INFO - __main__ - train loss is 6.920742565300316\n",
      "Steps:  57%|█▋ | 8587/15000 [54:29<19:09,  5.58it/s, lr=9.5e-6, step_loss=0.375]07/18/2023 19:57:51 - INFO - __main__ - train loss is 7.06265997281298\n",
      "Steps:  57%|█▋ | 8588/15000 [54:29<19:17,  5.54it/s, lr=9.5e-6, step_loss=0.142]07/18/2023 19:57:51 - INFO - __main__ - train loss is 7.38827141514048\n",
      "Steps:  57%|█▋ | 8589/15000 [54:29<19:17,  5.54it/s, lr=9.5e-6, step_loss=0.326]07/18/2023 19:57:52 - INFO - __main__ - train loss is 7.421534982975572\n",
      "Steps:  57%|█▏| 8590/15000 [54:30<19:18,  5.53it/s, lr=9.5e-6, step_loss=0.0333]07/18/2023 19:57:52 - INFO - __main__ - train loss is 7.444845674093813\n",
      "Steps:  57%|█▏| 8591/15000 [54:30<19:18,  5.53it/s, lr=9.5e-6, step_loss=0.0233]07/18/2023 19:57:52 - INFO - __main__ - train loss is 7.4781974158249795\n",
      "Steps:  57%|█▏| 8592/15000 [54:30<19:17,  5.53it/s, lr=9.5e-6, step_loss=0.0334]07/18/2023 19:57:52 - INFO - __main__ - train loss is 7.480765989050269\n",
      "Steps:  57%|▌| 8593/15000 [54:30<19:17,  5.53it/s, lr=9.5e-6, step_loss=0.00257]07/18/2023 19:57:52 - INFO - __main__ - train loss is 7.488331023603678\n",
      "Steps:  57%|▌| 8594/15000 [54:30<19:17,  5.53it/s, lr=9.5e-6, step_loss=0.00757]07/18/2023 19:57:53 - INFO - __main__ - train loss is 7.490643998607993\n",
      "Steps:  57%|▌| 8595/15000 [54:30<19:17,  5.54it/s, lr=9.5e-6, step_loss=0.00231]07/18/2023 19:57:53 - INFO - __main__ - train loss is 7.67121391557157\n",
      "Steps:  57%|█▋ | 8596/15000 [54:31<19:17,  5.53it/s, lr=9.5e-6, step_loss=0.181]07/18/2023 19:57:53 - INFO - __main__ - train loss is 7.694769160822034\n",
      "Steps:  57%|█▏| 8597/15000 [54:31<19:17,  5.53it/s, lr=9.5e-6, step_loss=0.0236]07/18/2023 19:57:53 - INFO - __main__ - train loss is 7.928623141720891\n",
      "Steps:  57%|█▋ | 8598/15000 [54:31<19:17,  5.53it/s, lr=9.5e-6, step_loss=0.234]07/18/2023 19:57:53 - INFO - __main__ - train loss is 7.930443116580136\n",
      "Steps:  57%|▌| 8599/15000 [54:31<19:12,  5.56it/s, lr=9.5e-6, step_loss=0.00182]07/18/2023 19:57:53 - INFO - __main__ - train loss is 7.972356529091485\n",
      "Steps:  57%|█▏| 8600/15000 [54:31<19:07,  5.58it/s, lr=9.5e-6, step_loss=0.0419]07/18/2023 19:57:54 - INFO - __main__ - train loss is 8.011516907368787\n",
      "Steps:  57%|█▏| 8601/15000 [54:32<19:08,  5.57it/s, lr=9.5e-6, step_loss=0.0392]07/18/2023 19:57:54 - INFO - __main__ - train loss is 8.116793536697514\n",
      "Steps:  57%|█▋ | 8602/15000 [54:32<19:05,  5.58it/s, lr=9.5e-6, step_loss=0.105]07/18/2023 19:57:54 - INFO - __main__ - train loss is 8.161832754616626\n",
      "Steps:  57%|█▋ | 8603/15000 [54:32<19:04,  5.59it/s, lr=9.5e-6, step_loss=0.045]07/18/2023 19:57:54 - INFO - __main__ - train loss is 8.163940846570767\n",
      "Steps:  57%|▌| 8604/15000 [54:32<19:03,  5.60it/s, lr=9.5e-6, step_loss=0.00211]07/18/2023 19:57:54 - INFO - __main__ - train loss is 8.168826899142005\n",
      "Steps:  57%|▌| 8605/15000 [54:32<19:01,  5.60it/s, lr=9.5e-6, step_loss=0.00489]07/18/2023 19:57:55 - INFO - __main__ - train loss is 8.225493400008418\n",
      "Steps:  57%|█▏| 8606/15000 [54:32<19:00,  5.60it/s, lr=9.5e-6, step_loss=0.0567]07/18/2023 19:57:55 - INFO - __main__ - train loss is 8.675192205817439\n",
      "Steps:  57%|██▎ | 8607/15000 [54:33<19:00,  5.60it/s, lr=9.5e-6, step_loss=0.45]07/18/2023 19:57:55 - INFO - __main__ - train loss is 8.677967400872149\n",
      "Steps:  57%|▌| 8608/15000 [54:33<18:59,  5.61it/s, lr=9.5e-6, step_loss=0.00278]07/18/2023 19:57:55 - INFO - __main__ - train loss is 8.684162091114558\n",
      "Steps:  57%|▌| 8609/15000 [54:33<18:59,  5.61it/s, lr=9.5e-6, step_loss=0.00619]07/18/2023 19:57:55 - INFO - __main__ - train loss is 8.780021216371097\n",
      "Steps:  57%|█▏| 8610/15000 [54:33<18:58,  5.61it/s, lr=9.5e-6, step_loss=0.0959]07/18/2023 19:57:55 - INFO - __main__ - train loss is 8.89912406692747\n",
      "Steps:  57%|█▋ | 8611/15000 [54:33<18:58,  5.61it/s, lr=9.5e-6, step_loss=0.119]07/18/2023 19:57:56 - INFO - __main__ - train loss is 9.097401123144664\n",
      "Steps:  57%|█▋ | 8612/15000 [54:33<19:07,  5.57it/s, lr=9.5e-6, step_loss=0.198]07/18/2023 19:57:56 - INFO - __main__ - train loss is 9.131106387474574\n",
      "Steps:  57%|█▏| 8613/15000 [54:34<19:04,  5.58it/s, lr=9.5e-6, step_loss=0.0337]07/18/2023 19:57:56 - INFO - __main__ - train loss is 9.605585883953609\n",
      "Steps:  57%|█▋ | 8614/15000 [54:34<19:02,  5.59it/s, lr=9.5e-6, step_loss=0.474]07/18/2023 19:57:56 - INFO - __main__ - train loss is 9.884089361527003\n",
      "Steps:  57%|█▋ | 8615/15000 [54:34<19:00,  5.60it/s, lr=9.5e-6, step_loss=0.279]07/18/2023 19:57:56 - INFO - __main__ - train loss is 9.938736024894752\n",
      "Steps:  57%|█▏| 8616/15000 [54:34<18:59,  5.60it/s, lr=9.5e-6, step_loss=0.0546]07/18/2023 19:57:56 - INFO - __main__ - train loss is 10.479759398498572\n",
      "Steps:  57%|█▋ | 8617/15000 [54:34<18:59,  5.60it/s, lr=9.5e-6, step_loss=0.541]07/18/2023 19:57:57 - INFO - __main__ - train loss is 10.48184881603811\n",
      "Steps:  57%|▌| 8618/15000 [54:35<18:57,  5.61it/s, lr=9.5e-6, step_loss=0.00209]07/18/2023 19:57:57 - INFO - __main__ - train loss is 11.069447855115868\n",
      "Steps:  57%|█▋ | 8619/15000 [54:35<18:56,  5.61it/s, lr=9.5e-6, step_loss=0.588]07/18/2023 19:57:57 - INFO - __main__ - train loss is 11.234740371466614\n",
      "Steps:  57%|█▋ | 8620/15000 [54:35<18:56,  5.61it/s, lr=9.5e-6, step_loss=0.165]07/18/2023 19:57:57 - INFO - __main__ - train loss is 11.621654088259675\n",
      "Steps:  57%|█▋ | 8621/15000 [54:35<19:03,  5.58it/s, lr=9.5e-6, step_loss=0.387]07/18/2023 19:57:57 - INFO - __main__ - train loss is 12.245903367758729\n",
      "Steps:  57%|█▋ | 8622/15000 [54:35<19:01,  5.59it/s, lr=9.5e-6, step_loss=0.624]07/18/2023 19:57:58 - INFO - __main__ - train loss is 13.14976453280542\n",
      "Steps:  57%|█▋ | 8623/15000 [54:35<18:59,  5.60it/s, lr=9.5e-6, step_loss=0.904]07/18/2023 19:57:58 - INFO - __main__ - train loss is 13.213409552932717\n",
      "Steps:  57%|█▏| 8624/15000 [54:36<18:57,  5.61it/s, lr=9.5e-6, step_loss=0.0636]07/18/2023 19:57:58 - INFO - __main__ - train loss is 13.221274873823859\n",
      "Steps:  57%|▌| 8625/15000 [54:36<18:56,  5.61it/s, lr=9.5e-6, step_loss=0.00787]07/18/2023 19:57:58 - INFO - __main__ - train loss is 13.22448943706695\n",
      "Steps:  58%|▌| 8626/15000 [54:36<20:17,  5.24it/s, lr=9.5e-6, step_loss=0.00321]07/18/2023 19:57:58 - INFO - __main__ - train loss is 13.296417990350164\n",
      "Steps:  58%|█▏| 8627/15000 [54:36<20:08,  5.28it/s, lr=9.5e-6, step_loss=0.0719]07/18/2023 19:57:59 - INFO - __main__ - train loss is 13.843362131738104\n",
      "Steps:  58%|█▋ | 8628/15000 [54:36<20:21,  5.22it/s, lr=9.5e-6, step_loss=0.547]07/18/2023 19:57:59 - INFO - __main__ - train loss is 13.91873251798097\n",
      "Steps:  58%|█▏| 8629/15000 [54:37<20:14,  5.25it/s, lr=9.5e-6, step_loss=0.0754]07/18/2023 19:57:59 - INFO - __main__ - train loss is 13.969781668507494\n",
      "Steps:  58%|█▋ | 8630/15000 [54:37<20:00,  5.31it/s, lr=9.5e-6, step_loss=0.051]07/18/2023 19:57:59 - INFO - __main__ - train loss is 13.985421785735525\n",
      "Steps:  58%|█▏| 8631/15000 [54:37<19:40,  5.40it/s, lr=9.5e-6, step_loss=0.0156]07/18/2023 19:57:59 - INFO - __main__ - train loss is 14.175928482436575\n",
      "Steps:  58%|█▋ | 8632/15000 [54:37<19:26,  5.46it/s, lr=9.5e-6, step_loss=0.191]07/18/2023 19:58:00 - INFO - __main__ - train loss is 14.179295034031384\n",
      "Steps:  58%|▌| 8633/15000 [54:38<25:50,  4.11it/s, lr=9.5e-6, step_loss=0.00337]07/18/2023 19:58:00 - INFO - __main__ - Per validation step average loss is 0.22766050696372986\n",
      "07/18/2023 19:58:00 - INFO - __main__ - Cumulative validation average loss is 0.22766050696372986\n",
      "07/18/2023 19:58:00 - INFO - __main__ - Per validation step average loss is 0.48496943712234497\n",
      "07/18/2023 19:58:00 - INFO - __main__ - Cumulative validation average loss is 0.7126299440860748\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Per validation step average loss is 0.14677077531814575\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Cumulative validation average loss is 0.8594007194042206\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Per validation step average loss is 0.29876628518104553\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Cumulative validation average loss is 1.1581670045852661\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Per validation step average loss is 0.27408459782600403\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Cumulative validation average loss is 1.4322516024112701\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Per validation step average loss is 0.0630006194114685\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Cumulative validation average loss is 1.4952522218227386\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Per validation step average loss is 0.07490826398134232\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Cumulative validation average loss is 1.570160485804081\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Per validation step average loss is 0.336281955242157\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Cumulative validation average loss is 1.906442441046238\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Per validation step average loss is 0.09474510699510574\n",
      "07/18/2023 19:58:01 - INFO - __main__ - Cumulative validation average loss is 2.0011875480413437\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Per validation step average loss is 0.024290040135383606\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Cumulative validation average loss is 2.0254775881767273\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Per validation step average loss is 0.03724570572376251\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Cumulative validation average loss is 2.06272329390049\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Per validation step average loss is 0.007460035849362612\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Cumulative validation average loss is 2.0701833297498524\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Average validation loss for Epoch 88 is 0.17251527747915438\n",
      "07/18/2023 19:58:02 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:58:15 - INFO - __main__ - Starting epoch 89\n",
      "07/18/2023 19:58:16 - INFO - __main__ - train loss is 0.07881361246109009\n",
      "Steps:  58%|▌| 8634/15000 [54:53<8:44:40,  4.95s/it, lr=9.5e-6, step_loss=0.078807/18/2023 19:58:16 - INFO - __main__ - train loss is 0.21280184388160706\n",
      "Steps:  58%|▌| 8635/15000 [54:54<6:13:14,  3.52s/it, lr=9.5e-6, step_loss=0.134]07/18/2023 19:58:16 - INFO - __main__ - train loss is 0.21431627869606018\n",
      "Steps:  58%|▌| 8636/15000 [54:54<4:27:03,  2.52s/it, lr=9.5e-6, step_loss=0.001507/18/2023 19:58:16 - INFO - __main__ - train loss is 0.2886277213692665\n",
      "Steps:  58%|▌| 8637/15000 [54:54<3:12:41,  1.82s/it, lr=9.5e-6, step_loss=0.074307/18/2023 19:58:16 - INFO - __main__ - train loss is 0.3077489733695984\n",
      "Steps:  58%|▌| 8638/15000 [54:54<2:20:35,  1.33s/it, lr=9.5e-6, step_loss=0.019107/18/2023 19:58:16 - INFO - __main__ - train loss is 0.3125847475603223\n",
      "Steps:  58%|▌| 8639/15000 [54:54<1:44:11,  1.02it/s, lr=9.5e-6, step_loss=0.004807/18/2023 19:58:17 - INFO - __main__ - train loss is 0.7461109654977918\n",
      "Steps:  58%|▌| 8640/15000 [54:55<1:18:52,  1.34it/s, lr=9.5e-6, step_loss=0.434]07/18/2023 19:58:17 - INFO - __main__ - train loss is 0.7575384769588709\n",
      "Steps:  58%|▌| 8641/15000 [54:55<1:01:13,  1.73it/s, lr=9.5e-6, step_loss=0.011407/18/2023 19:58:17 - INFO - __main__ - train loss is 1.6437231097370386\n",
      "Steps:  58%|█▋ | 8642/15000 [54:55<48:49,  2.17it/s, lr=9.5e-6, step_loss=0.886]07/18/2023 19:58:17 - INFO - __main__ - train loss is 1.6478223977610469\n",
      "Steps:  58%|█▏| 8643/15000 [54:55<39:50,  2.66it/s, lr=9.5e-6, step_loss=0.0041]07/18/2023 19:58:17 - INFO - __main__ - train loss is 1.6547770034521818\n",
      "Steps:  58%|▌| 8644/15000 [54:55<33:32,  3.16it/s, lr=9.5e-6, step_loss=0.00695]07/18/2023 19:58:18 - INFO - __main__ - train loss is 1.9713359009474516\n",
      "Steps:  58%|█▋ | 8645/15000 [54:55<29:09,  3.63it/s, lr=9.5e-6, step_loss=0.317]07/18/2023 19:58:18 - INFO - __main__ - train loss is 2.1028443705290556\n",
      "Steps:  58%|█▋ | 8646/15000 [54:56<26:12,  4.04it/s, lr=9.5e-6, step_loss=0.132]07/18/2023 19:58:18 - INFO - __main__ - train loss is 2.44406626932323\n",
      "Steps:  58%|█▋ | 8647/15000 [54:56<24:13,  4.37it/s, lr=9.5e-6, step_loss=0.341]07/18/2023 19:58:18 - INFO - __main__ - train loss is 3.0083204340189695\n",
      "Steps:  58%|█▋ | 8648/15000 [54:56<22:38,  4.68it/s, lr=9.5e-6, step_loss=0.564]07/18/2023 19:58:18 - INFO - __main__ - train loss is 3.21021599881351\n",
      "Steps:  58%|█▋ | 8649/15000 [54:56<21:34,  4.91it/s, lr=9.5e-6, step_loss=0.202]07/18/2023 19:58:18 - INFO - __main__ - train loss is 3.2191920951008797\n",
      "Steps:  58%|▌| 8650/15000 [54:56<20:49,  5.08it/s, lr=9.5e-6, step_loss=0.00898]07/18/2023 19:58:19 - INFO - __main__ - train loss is 3.292665086686611\n",
      "Steps:  58%|█▏| 8651/15000 [54:57<20:19,  5.21it/s, lr=9.5e-6, step_loss=0.0735]07/18/2023 19:58:19 - INFO - __main__ - train loss is 3.5369652435183525\n",
      "Steps:  58%|█▋ | 8652/15000 [54:57<19:58,  5.30it/s, lr=9.5e-6, step_loss=0.244]07/18/2023 19:58:19 - INFO - __main__ - train loss is 3.5389332082122564\n",
      "Steps:  58%|▌| 8653/15000 [54:57<19:43,  5.36it/s, lr=9.5e-6, step_loss=0.00197]07/18/2023 19:58:19 - INFO - __main__ - train loss is 3.7119669523090124\n",
      "Steps:  58%|█▋ | 8654/15000 [54:57<19:32,  5.41it/s, lr=9.5e-6, step_loss=0.173]07/18/2023 19:58:19 - INFO - __main__ - train loss is 4.555664738640189\n",
      "Steps:  58%|█▋ | 8655/15000 [54:57<19:26,  5.44it/s, lr=9.5e-6, step_loss=0.844]07/18/2023 19:58:20 - INFO - __main__ - train loss is 4.873964985832572\n",
      "Steps:  58%|█▋ | 8656/15000 [54:57<19:20,  5.47it/s, lr=9.5e-6, step_loss=0.318]07/18/2023 19:58:20 - INFO - __main__ - train loss is 5.000268077477813\n",
      "Steps:  58%|█▋ | 8657/15000 [54:58<19:16,  5.48it/s, lr=9.5e-6, step_loss=0.126]07/18/2023 19:58:20 - INFO - __main__ - train loss is 5.289003586396575\n",
      "Steps:  58%|█▋ | 8658/15000 [54:58<19:13,  5.50it/s, lr=9.5e-6, step_loss=0.289]07/18/2023 19:58:20 - INFO - __main__ - train loss is 5.291408889228478\n",
      "Steps:  58%|▌| 8659/15000 [54:58<19:11,  5.51it/s, lr=9.5e-6, step_loss=0.00241]07/18/2023 19:58:20 - INFO - __main__ - train loss is 5.293336674338207\n",
      "Steps:  58%|▌| 8660/15000 [54:58<19:10,  5.51it/s, lr=9.5e-6, step_loss=0.00193]07/18/2023 19:58:20 - INFO - __main__ - train loss is 5.625992282992229\n",
      "Steps:  58%|█▋ | 8661/15000 [54:58<19:10,  5.51it/s, lr=9.5e-6, step_loss=0.333]07/18/2023 19:58:21 - INFO - __main__ - train loss is 5.647928558057174\n",
      "Steps:  58%|█▏| 8662/15000 [54:59<19:08,  5.52it/s, lr=9.5e-6, step_loss=0.0219]07/18/2023 19:58:21 - INFO - __main__ - train loss is 5.651461957255378\n",
      "Steps:  58%|▌| 8663/15000 [54:59<19:08,  5.52it/s, lr=9.5e-6, step_loss=0.00353]07/18/2023 19:58:21 - INFO - __main__ - train loss is 6.015165118733421\n",
      "Steps:  58%|█▋ | 8664/15000 [54:59<19:07,  5.52it/s, lr=9.5e-6, step_loss=0.364]07/18/2023 19:58:21 - INFO - __main__ - train loss is 6.020232427632436\n",
      "Steps:  58%|▌| 8665/15000 [54:59<19:06,  5.52it/s, lr=9.5e-6, step_loss=0.00507]07/18/2023 19:58:21 - INFO - __main__ - train loss is 6.025771205546334\n",
      "Steps:  58%|▌| 8666/15000 [54:59<19:08,  5.51it/s, lr=9.5e-6, step_loss=0.00554]07/18/2023 19:58:22 - INFO - __main__ - train loss is 6.349221174838021\n",
      "Steps:  58%|█▋ | 8667/15000 [54:59<19:08,  5.52it/s, lr=9.5e-6, step_loss=0.323]07/18/2023 19:58:22 - INFO - __main__ - train loss is 6.355249944375828\n",
      "Steps:  58%|▌| 8668/15000 [55:00<19:08,  5.51it/s, lr=9.5e-6, step_loss=0.00603]07/18/2023 19:58:22 - INFO - __main__ - train loss is 6.70523816649802\n",
      "Steps:  58%|██▎ | 8669/15000 [55:00<19:07,  5.52it/s, lr=9.5e-6, step_loss=0.35]07/18/2023 19:58:22 - INFO - __main__ - train loss is 6.886105033801869\n",
      "Steps:  58%|█▋ | 8670/15000 [55:00<19:07,  5.52it/s, lr=9.5e-6, step_loss=0.181]07/18/2023 19:58:22 - INFO - __main__ - train loss is 7.152966293739155\n",
      "Steps:  58%|█▋ | 8671/15000 [55:00<19:06,  5.52it/s, lr=9.5e-6, step_loss=0.267]07/18/2023 19:58:22 - INFO - __main__ - train loss is 7.154563153162599\n",
      "Steps:  58%|█▏| 8672/15000 [55:00<19:06,  5.52it/s, lr=9.5e-6, step_loss=0.0016]07/18/2023 19:58:23 - INFO - __main__ - train loss is 7.156545858364552\n",
      "Steps:  58%|▌| 8673/15000 [55:01<19:07,  5.52it/s, lr=9.5e-6, step_loss=0.00198]07/18/2023 19:58:23 - INFO - __main__ - train loss is 7.159372937632725\n",
      "Steps:  58%|▌| 8674/15000 [55:01<19:06,  5.52it/s, lr=9.49e-6, step_loss=0.0028307/18/2023 19:58:23 - INFO - __main__ - train loss is 7.521691513014957\n",
      "Steps:  58%|█▏| 8675/15000 [55:01<19:18,  5.46it/s, lr=9.49e-6, step_loss=0.362]07/18/2023 19:58:23 - INFO - __main__ - train loss is 7.668153938604519\n",
      "Steps:  58%|█▏| 8676/15000 [55:01<19:24,  5.43it/s, lr=9.49e-6, step_loss=0.146]07/18/2023 19:58:23 - INFO - __main__ - train loss is 7.680870263604447\n",
      "Steps:  58%|▌| 8677/15000 [55:01<19:19,  5.45it/s, lr=9.49e-6, step_loss=0.0127]07/18/2023 19:58:24 - INFO - __main__ - train loss is 7.855159728555009\n",
      "Steps:  58%|█▏| 8678/15000 [55:01<19:25,  5.42it/s, lr=9.49e-6, step_loss=0.174]07/18/2023 19:58:24 - INFO - __main__ - train loss is 8.272822349099442\n",
      "Steps:  58%|█▏| 8679/15000 [55:02<19:19,  5.45it/s, lr=9.49e-6, step_loss=0.418]07/18/2023 19:58:24 - INFO - __main__ - train loss is 8.409247859148309\n",
      "Steps:  58%|█▏| 8680/15000 [55:02<19:14,  5.48it/s, lr=9.49e-6, step_loss=0.136]07/18/2023 19:58:24 - INFO - __main__ - train loss is 8.758638723520562\n",
      "Steps:  58%|█▏| 8681/15000 [55:02<19:10,  5.49it/s, lr=9.49e-6, step_loss=0.349]07/18/2023 19:58:24 - INFO - __main__ - train loss is 9.121633215574548\n",
      "Steps:  58%|█▏| 8682/15000 [55:02<19:07,  5.50it/s, lr=9.49e-6, step_loss=0.363]07/18/2023 19:58:24 - INFO - __main__ - train loss is 9.132858302211389\n",
      "Steps:  58%|▌| 8683/15000 [55:02<19:06,  5.51it/s, lr=9.49e-6, step_loss=0.0112]07/18/2023 19:58:25 - INFO - __main__ - train loss is 9.174258179729804\n",
      "Steps:  58%|▌| 8684/15000 [55:03<19:05,  5.51it/s, lr=9.49e-6, step_loss=0.0414]07/18/2023 19:58:25 - INFO - __main__ - train loss is 9.556199498241767\n",
      "Steps:  58%|█▏| 8685/15000 [55:03<19:04,  5.52it/s, lr=9.49e-6, step_loss=0.382]07/18/2023 19:58:25 - INFO - __main__ - train loss is 9.62456963188015\n",
      "Steps:  58%|▌| 8686/15000 [55:03<19:03,  5.52it/s, lr=9.49e-6, step_loss=0.0684]07/18/2023 19:58:25 - INFO - __main__ - train loss is 10.003076709574088\n",
      "Steps:  58%|█▏| 8687/15000 [55:03<19:03,  5.52it/s, lr=9.49e-6, step_loss=0.379]07/18/2023 19:58:25 - INFO - __main__ - train loss is 10.023984309053048\n",
      "Steps:  58%|▌| 8688/15000 [55:03<19:02,  5.52it/s, lr=9.49e-6, step_loss=0.0209]07/18/2023 19:58:26 - INFO - __main__ - train loss is 10.025761935277842\n",
      "Steps:  58%|▌| 8689/15000 [55:03<19:02,  5.52it/s, lr=9.49e-6, step_loss=0.0017807/18/2023 19:58:26 - INFO - __main__ - train loss is 10.033942285343073\n",
      "Steps:  58%|▌| 8690/15000 [55:04<18:57,  5.55it/s, lr=9.49e-6, step_loss=0.0081807/18/2023 19:58:26 - INFO - __main__ - train loss is 10.07646327780094\n",
      "Steps:  58%|▌| 8691/15000 [55:04<18:54,  5.56it/s, lr=9.49e-6, step_loss=0.0425]07/18/2023 19:58:26 - INFO - __main__ - train loss is 10.128513443632983\n",
      "Steps:  58%|▌| 8692/15000 [55:04<18:51,  5.58it/s, lr=9.49e-6, step_loss=0.0521]07/18/2023 19:58:26 - INFO - __main__ - train loss is 10.85000150220003\n",
      "Steps:  58%|█▏| 8693/15000 [55:04<18:49,  5.58it/s, lr=9.49e-6, step_loss=0.721]07/18/2023 19:58:26 - INFO - __main__ - train loss is 10.852501373621635\n",
      "Steps:  58%|▌| 8694/15000 [55:04<18:48,  5.59it/s, lr=9.49e-6, step_loss=0.0025]07/18/2023 19:58:27 - INFO - __main__ - train loss is 10.958364616963081\n",
      "Steps:  58%|█▏| 8695/15000 [55:05<18:58,  5.54it/s, lr=9.49e-6, step_loss=0.106]07/18/2023 19:58:27 - INFO - __main__ - train loss is 11.307010751101188\n",
      "Steps:  58%|█▏| 8696/15000 [55:05<19:03,  5.51it/s, lr=9.49e-6, step_loss=0.349]07/18/2023 19:58:27 - INFO - __main__ - train loss is 11.330586982774548\n",
      "Steps:  58%|▌| 8697/15000 [55:05<18:58,  5.54it/s, lr=9.49e-6, step_loss=0.0236]07/18/2023 19:58:27 - INFO - __main__ - train loss is 11.775727910804562\n",
      "Steps:  58%|█▏| 8698/15000 [55:05<18:53,  5.56it/s, lr=9.49e-6, step_loss=0.445]07/18/2023 19:58:27 - INFO - __main__ - train loss is 11.80013014364522\n",
      "Steps:  58%|▌| 8699/15000 [55:05<18:52,  5.56it/s, lr=9.49e-6, step_loss=0.0244]07/18/2023 19:58:28 - INFO - __main__ - train loss is 11.966709717991762\n",
      "Steps:  58%|█▏| 8700/15000 [55:05<18:50,  5.57it/s, lr=9.49e-6, step_loss=0.167]07/18/2023 19:58:28 - INFO - __main__ - train loss is 12.126873329165392\n",
      "Steps:  58%|█▋ | 8701/15000 [55:06<19:00,  5.52it/s, lr=9.49e-6, step_loss=0.16]07/18/2023 19:58:28 - INFO - __main__ - train loss is 12.152806712198071\n",
      "Steps:  58%|▌| 8702/15000 [55:06<19:03,  5.51it/s, lr=9.49e-6, step_loss=0.0259]07/18/2023 19:58:28 - INFO - __main__ - train loss is 12.154588684556074\n",
      "Steps:  58%|▌| 8703/15000 [55:06<18:57,  5.54it/s, lr=9.49e-6, step_loss=0.0017807/18/2023 19:58:28 - INFO - __main__ - train loss is 12.16002487402875\n",
      "Steps:  58%|▌| 8704/15000 [55:06<18:53,  5.56it/s, lr=9.49e-6, step_loss=0.0054407/18/2023 19:58:28 - INFO - __main__ - train loss is 12.208726383862086\n",
      "Steps:  58%|▌| 8705/15000 [55:06<18:50,  5.57it/s, lr=9.49e-6, step_loss=0.0487]07/18/2023 19:58:29 - INFO - __main__ - train loss is 12.466371275600977\n",
      "Steps:  58%|█▏| 8706/15000 [55:06<18:47,  5.58it/s, lr=9.49e-6, step_loss=0.258]07/18/2023 19:58:29 - INFO - __main__ - train loss is 12.472594126709737\n",
      "Steps:  58%|▌| 8707/15000 [55:07<18:46,  5.59it/s, lr=9.49e-6, step_loss=0.0062207/18/2023 19:58:29 - INFO - __main__ - train loss is 12.808761521824636\n",
      "Steps:  58%|█▏| 8708/15000 [55:07<18:45,  5.59it/s, lr=9.49e-6, step_loss=0.336]07/18/2023 19:58:29 - INFO - __main__ - train loss is 12.868731766589917\n",
      "Steps:  58%|█▋ | 8709/15000 [55:07<18:45,  5.59it/s, lr=9.49e-6, step_loss=0.06]07/18/2023 19:58:29 - INFO - __main__ - train loss is 13.15403333271388\n",
      "Steps:  58%|█▏| 8710/15000 [55:07<18:44,  5.59it/s, lr=9.49e-6, step_loss=0.285]07/18/2023 19:58:29 - INFO - __main__ - train loss is 13.39074377680663\n",
      "Steps:  58%|█▏| 8711/15000 [55:07<18:44,  5.59it/s, lr=9.49e-6, step_loss=0.237]07/18/2023 19:58:30 - INFO - __main__ - train loss is 13.40232326707337\n",
      "Steps:  58%|▌| 8712/15000 [55:08<18:44,  5.59it/s, lr=9.49e-6, step_loss=0.0116]07/18/2023 19:58:30 - INFO - __main__ - train loss is 13.511688700527884\n",
      "Steps:  58%|█▏| 8713/15000 [55:08<18:44,  5.59it/s, lr=9.49e-6, step_loss=0.109]07/18/2023 19:58:30 - INFO - __main__ - train loss is 13.518786772736348\n",
      "Steps:  58%|▌| 8714/15000 [55:08<18:42,  5.60it/s, lr=9.49e-6, step_loss=0.0071]07/18/2023 19:58:30 - INFO - __main__ - train loss is 13.687013134011067\n",
      "Steps:  58%|█▏| 8715/15000 [55:08<18:40,  5.61it/s, lr=9.49e-6, step_loss=0.168]07/18/2023 19:58:30 - INFO - __main__ - train loss is 13.916979387053289\n",
      "Steps:  58%|█▋ | 8716/15000 [55:08<18:39,  5.61it/s, lr=9.49e-6, step_loss=0.23]07/18/2023 19:58:31 - INFO - __main__ - train loss is 13.950399115332402\n",
      "Steps:  58%|▌| 8717/15000 [55:08<18:39,  5.61it/s, lr=9.49e-6, step_loss=0.0334]07/18/2023 19:58:31 - INFO - __main__ - train loss is 13.97793131286744\n",
      "Steps:  58%|▌| 8718/15000 [55:09<18:39,  5.61it/s, lr=9.49e-6, step_loss=0.0275]07/18/2023 19:58:31 - INFO - __main__ - train loss is 14.06934151018504\n",
      "Steps:  58%|▌| 8719/15000 [55:09<18:39,  5.61it/s, lr=9.49e-6, step_loss=0.0914]07/18/2023 19:58:31 - INFO - __main__ - train loss is 14.11114372278098\n",
      "Steps:  58%|▌| 8720/15000 [55:09<18:38,  5.62it/s, lr=9.49e-6, step_loss=0.0418]07/18/2023 19:58:31 - INFO - __main__ - train loss is 14.130222107865848\n",
      "Steps:  58%|▌| 8721/15000 [55:09<18:37,  5.62it/s, lr=9.49e-6, step_loss=0.0191]07/18/2023 19:58:31 - INFO - __main__ - train loss is 14.359175588586368\n",
      "Steps:  58%|█▏| 8722/15000 [55:09<18:37,  5.62it/s, lr=9.49e-6, step_loss=0.229]07/18/2023 19:58:32 - INFO - __main__ - train loss is 14.418699323781766\n",
      "Steps:  58%|▌| 8723/15000 [55:10<18:37,  5.62it/s, lr=9.49e-6, step_loss=0.0595]07/18/2023 19:58:32 - INFO - __main__ - train loss is 14.432003290974535\n",
      "Steps:  58%|▌| 8724/15000 [55:10<18:37,  5.62it/s, lr=9.49e-6, step_loss=0.0133]07/18/2023 19:58:32 - INFO - __main__ - train loss is 14.448739936226048\n",
      "Steps:  58%|▌| 8725/15000 [55:10<18:36,  5.62it/s, lr=9.49e-6, step_loss=0.0167]07/18/2023 19:58:32 - INFO - __main__ - train loss is 14.58973505126778\n",
      "Steps:  58%|█▏| 8726/15000 [55:10<18:37,  5.62it/s, lr=9.49e-6, step_loss=0.141]07/18/2023 19:58:32 - INFO - __main__ - train loss is 14.614253887557425\n",
      "Steps:  58%|▌| 8727/15000 [55:10<18:36,  5.62it/s, lr=9.49e-6, step_loss=0.0245]07/18/2023 19:58:33 - INFO - __main__ - train loss is 14.691096888505854\n",
      "Steps:  58%|▌| 8728/15000 [55:10<18:36,  5.62it/s, lr=9.49e-6, step_loss=0.0768]07/18/2023 19:58:33 - INFO - __main__ - train loss is 14.749258422874846\n",
      "Steps:  58%|▌| 8729/15000 [55:11<18:36,  5.62it/s, lr=9.49e-6, step_loss=0.0582]07/18/2023 19:58:33 - INFO - __main__ - train loss is 14.81202683749143\n",
      "Steps:  58%|▌| 8730/15000 [55:11<26:02,  4.01it/s, lr=9.49e-6, step_loss=0.0628]07/18/2023 19:58:34 - INFO - __main__ - Per validation step average loss is 0.035743776708841324\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Cumulative validation average loss is 0.035743776708841324\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Per validation step average loss is 0.014249205589294434\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Cumulative validation average loss is 0.04999298229813576\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Per validation step average loss is 0.21285486221313477\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Cumulative validation average loss is 0.2628478445112705\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Per validation step average loss is 0.8882632851600647\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Cumulative validation average loss is 1.1511111296713352\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Per validation step average loss is 0.04151631519198418\n",
      "07/18/2023 19:58:34 - INFO - __main__ - Cumulative validation average loss is 1.1926274448633194\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Per validation step average loss is 0.013348137959837914\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Cumulative validation average loss is 1.2059755828231573\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Per validation step average loss is 0.14008812606334686\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Cumulative validation average loss is 1.3460637088865042\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Per validation step average loss is 0.07893133163452148\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Cumulative validation average loss is 1.4249950405210257\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Per validation step average loss is 0.19561602175235748\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Cumulative validation average loss is 1.6206110622733831\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Per validation step average loss is 0.03457288816571236\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Cumulative validation average loss is 1.6551839504390955\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Per validation step average loss is 0.19145354628562927\n",
      "07/18/2023 19:58:35 - INFO - __main__ - Cumulative validation average loss is 1.8466374967247248\n",
      "07/18/2023 19:58:36 - INFO - __main__ - Per validation step average loss is 0.2786881923675537\n",
      "07/18/2023 19:58:36 - INFO - __main__ - Cumulative validation average loss is 2.1253256890922785\n",
      "07/18/2023 19:58:36 - INFO - __main__ - Average validation loss for Epoch 89 is 0.1771104740910232\n",
      "07/18/2023 19:58:36 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:58:49 - INFO - __main__ - Starting epoch 90\n",
      "07/18/2023 19:58:50 - INFO - __main__ - train loss is 0.090235635638237\n",
      "Steps:  58%|▌| 8731/15000 [55:28<8:57:53,  5.15s/it, lr=9.49e-6, step_loss=0.09007/18/2023 19:58:50 - INFO - __main__ - train loss is 0.5296870321035385\n",
      "Steps:  58%|▌| 8732/15000 [55:28<6:35:05,  3.78s/it, lr=9.49e-6, step_loss=0.43907/18/2023 19:58:51 - INFO - __main__ - train loss is 0.9094132035970688\n",
      "Steps:  58%|▌| 8733/15000 [55:29<4:55:44,  2.83s/it, lr=9.49e-6, step_loss=0.38]07/18/2023 19:58:51 - INFO - __main__ - train loss is 0.9653247594833374\n",
      "Steps:  58%|▌| 8734/15000 [55:29<3:44:55,  2.15s/it, lr=9.49e-6, step_loss=0.05507/18/2023 19:58:52 - INFO - __main__ - train loss is 0.9789347117766738\n",
      "Steps:  58%|▌| 8735/15000 [55:30<2:54:23,  1.67s/it, lr=9.49e-6, step_loss=0.01307/18/2023 19:58:53 - INFO - __main__ - train loss is 0.9806549740023911\n",
      "Steps:  58%|▌| 8736/15000 [55:30<2:19:19,  1.33s/it, lr=9.49e-6, step_loss=0.00107/18/2023 19:58:53 - INFO - __main__ - train loss is 1.7775124502368271\n",
      "Steps:  58%|▌| 8737/15000 [55:31<1:54:29,  1.10s/it, lr=9.49e-6, step_loss=0.79707/18/2023 19:58:54 - INFO - __main__ - train loss is 1.7950633284635842\n",
      "Steps:  58%|▌| 8738/15000 [55:32<1:36:55,  1.08it/s, lr=9.49e-6, step_loss=0.01707/18/2023 19:58:54 - INFO - __main__ - train loss is 1.8126504239626229\n",
      "Steps:  58%|▌| 8739/15000 [55:32<1:25:01,  1.23it/s, lr=9.49e-6, step_loss=0.01707/18/2023 19:58:55 - INFO - __main__ - train loss is 2.046900984365493\n",
      "Steps:  58%|▌| 8740/15000 [55:33<1:16:39,  1.36it/s, lr=9.49e-6, step_loss=0.23407/18/2023 19:58:55 - INFO - __main__ - train loss is 2.274998900014907\n",
      "Steps:  58%|▌| 8741/15000 [55:33<1:10:54,  1.47it/s, lr=9.49e-6, step_loss=0.22807/18/2023 19:58:56 - INFO - __main__ - train loss is 3.0130773154087365\n",
      "Steps:  58%|▌| 8742/15000 [55:34<1:06:27,  1.57it/s, lr=9.49e-6, step_loss=0.73807/18/2023 19:58:56 - INFO - __main__ - train loss is 3.4732182291336358\n",
      "Steps:  58%|▌| 8743/15000 [55:34<1:03:23,  1.65it/s, lr=9.49e-6, step_loss=0.46]07/18/2023 19:58:57 - INFO - __main__ - train loss is 3.523787305224687\n",
      "Steps:  58%|▌| 8744/15000 [55:35<1:01:14,  1.70it/s, lr=9.49e-6, step_loss=0.05007/18/2023 19:58:57 - INFO - __main__ - train loss is 3.9481737171299756\n",
      "Steps:  58%|█▏| 8745/15000 [55:35<59:54,  1.74it/s, lr=9.49e-6, step_loss=0.424]07/18/2023 19:58:58 - INFO - __main__ - train loss is 4.107690826524049\n",
      "Steps:  58%|█▋ | 8746/15000 [55:36<58:53,  1.77it/s, lr=9.49e-6, step_loss=0.16]07/18/2023 19:58:59 - INFO - __main__ - train loss is 4.474403515923768\n",
      "Steps:  58%|█▏| 8747/15000 [55:36<58:09,  1.79it/s, lr=9.49e-6, step_loss=0.367]07/18/2023 19:58:59 - INFO - __main__ - train loss is 4.86897023068741\n",
      "Steps:  58%|█▏| 8748/15000 [55:37<57:28,  1.81it/s, lr=9.49e-6, step_loss=0.395]07/18/2023 19:59:00 - INFO - __main__ - train loss is 5.1336577092297375\n",
      "Steps:  58%|█▏| 8749/15000 [55:38<57:09,  1.82it/s, lr=9.49e-6, step_loss=0.265]07/18/2023 19:59:00 - INFO - __main__ - train loss is 5.144949306268245\n",
      "Steps:  58%|▌| 8750/15000 [55:38<56:53,  1.83it/s, lr=9.49e-6, step_loss=0.0113]07/18/2023 19:59:01 - INFO - __main__ - train loss is 5.318626750726253\n",
      "Steps:  58%|█▏| 8751/15000 [55:39<56:41,  1.84it/s, lr=9.49e-6, step_loss=0.174]07/18/2023 19:59:01 - INFO - __main__ - train loss is 5.334701966959983\n",
      "Steps:  58%|▌| 8752/15000 [55:39<56:39,  1.84it/s, lr=9.49e-6, step_loss=0.0161]07/18/2023 19:59:02 - INFO - __main__ - train loss is 5.6527852532453835\n",
      "Steps:  58%|█▏| 8753/15000 [55:40<56:27,  1.84it/s, lr=9.49e-6, step_loss=0.318]07/18/2023 19:59:02 - INFO - __main__ - train loss is 5.6873024185188115\n",
      "Steps:  58%|▌| 8754/15000 [55:40<56:18,  1.85it/s, lr=9.49e-6, step_loss=0.0345]07/18/2023 19:59:03 - INFO - __main__ - train loss is 5.702995453495532\n",
      "Steps:  58%|▌| 8755/15000 [55:41<56:04,  1.86it/s, lr=9.49e-6, step_loss=0.0157]07/18/2023 19:59:03 - INFO - __main__ - train loss is 5.715550140012056\n",
      "Steps:  58%|▌| 8756/15000 [55:41<56:07,  1.85it/s, lr=9.49e-6, step_loss=0.0126]07/18/2023 19:59:04 - INFO - __main__ - train loss is 5.768354334402829\n",
      "Steps:  58%|▌| 8757/15000 [55:42<56:13,  1.85it/s, lr=9.49e-6, step_loss=0.0528]07/18/2023 19:59:04 - INFO - __main__ - train loss is 5.829214577097446\n",
      "Steps:  58%|▌| 8758/15000 [55:42<56:18,  1.85it/s, lr=9.49e-6, step_loss=0.0609]07/18/2023 19:59:05 - INFO - __main__ - train loss is 5.87830799492076\n",
      "Steps:  58%|▌| 8759/15000 [55:43<56:21,  1.85it/s, lr=9.49e-6, step_loss=0.0491]07/18/2023 19:59:06 - INFO - __main__ - train loss is 6.058216523844749\n",
      "Steps:  58%|█▊ | 8760/15000 [55:43<56:09,  1.85it/s, lr=9.49e-6, step_loss=0.18]07/18/2023 19:59:06 - INFO - __main__ - train loss is 6.077886630315334\n",
      "Steps:  58%|▌| 8761/15000 [55:44<56:11,  1.85it/s, lr=9.48e-6, step_loss=0.0197]07/18/2023 19:59:07 - INFO - __main__ - train loss is 6.256665397901088\n",
      "Steps:  58%|█▏| 8762/15000 [55:45<56:21,  1.84it/s, lr=9.48e-6, step_loss=0.179]07/18/2023 19:59:07 - INFO - __main__ - train loss is 6.531480540055782\n",
      "Steps:  58%|█▏| 8763/15000 [55:45<56:22,  1.84it/s, lr=9.48e-6, step_loss=0.275]07/18/2023 19:59:08 - INFO - __main__ - train loss is 6.791911174077541\n",
      "Steps:  58%|█▊ | 8764/15000 [55:46<56:18,  1.85it/s, lr=9.48e-6, step_loss=0.26]07/18/2023 19:59:08 - INFO - __main__ - train loss is 6.9822112512774765\n",
      "Steps:  58%|█▊ | 8765/15000 [55:46<56:22,  1.84it/s, lr=9.48e-6, step_loss=0.19]07/18/2023 19:59:09 - INFO - __main__ - train loss is 7.245838869828731\n",
      "Steps:  58%|█▏| 8766/15000 [55:47<56:29,  1.84it/s, lr=9.48e-6, step_loss=0.264]07/18/2023 19:59:09 - INFO - __main__ - train loss is 7.247664801310748\n",
      "Steps:  58%|▌| 8767/15000 [55:47<1:00:25,  1.72it/s, lr=9.48e-6, step_loss=0.00107/18/2023 19:59:10 - INFO - __main__ - train loss is 7.254270595032722\n",
      "Steps:  58%|▌| 8768/15000 [55:48<1:08:21,  1.52it/s, lr=9.48e-6, step_loss=0.00607/18/2023 19:59:11 - INFO - __main__ - train loss is 7.331346702296287\n",
      "Steps:  58%|▌| 8769/15000 [55:49<1:07:07,  1.55it/s, lr=9.48e-6, step_loss=0.07707/18/2023 19:59:11 - INFO - __main__ - train loss is 7.625673782546073\n",
      "Steps:  58%|▌| 8770/15000 [55:49<1:04:11,  1.62it/s, lr=9.48e-6, step_loss=0.29407/18/2023 19:59:12 - INFO - __main__ - train loss is 7.6307767713442445\n",
      "Steps:  58%|▌| 8771/15000 [55:50<1:01:56,  1.68it/s, lr=9.48e-6, step_loss=0.00507/18/2023 19:59:13 - INFO - __main__ - train loss is 7.632757868384942\n",
      "Steps:  58%|▌| 8772/15000 [55:50<1:00:21,  1.72it/s, lr=9.48e-6, step_loss=0.00107/18/2023 19:59:13 - INFO - __main__ - train loss is 7.6697314938064665\n",
      "Steps:  58%|█▏| 8773/15000 [55:51<59:28,  1.75it/s, lr=9.48e-6, step_loss=0.037]07/18/2023 19:59:14 - INFO - __main__ - train loss is 7.671585840405896\n",
      "Steps:  58%|▌| 8774/15000 [55:52<58:30,  1.77it/s, lr=9.48e-6, step_loss=0.0018507/18/2023 19:59:14 - INFO - __main__ - train loss is 7.903879088582471\n",
      "Steps:  58%|█▏| 8775/15000 [55:52<57:41,  1.80it/s, lr=9.48e-6, step_loss=0.232]07/18/2023 19:59:15 - INFO - __main__ - train loss is 8.084089768351987\n",
      "Steps:  59%|█▊ | 8776/15000 [55:53<57:32,  1.80it/s, lr=9.48e-6, step_loss=0.18]07/18/2023 19:59:15 - INFO - __main__ - train loss is 8.337053013266996\n",
      "Steps:  59%|█▏| 8777/15000 [55:53<56:58,  1.82it/s, lr=9.48e-6, step_loss=0.253]07/18/2023 19:59:16 - INFO - __main__ - train loss is 8.534283441724256\n",
      "Steps:  59%|█▏| 8778/15000 [55:54<56:40,  1.83it/s, lr=9.48e-6, step_loss=0.197]07/18/2023 19:59:16 - INFO - __main__ - train loss is 8.563822911353782\n",
      "Steps:  59%|▌| 8779/15000 [55:54<56:21,  1.84it/s, lr=9.48e-6, step_loss=0.0295]07/18/2023 19:59:17 - INFO - __main__ - train loss is 8.596031953813508\n",
      "Steps:  59%|▌| 8780/15000 [55:55<56:05,  1.85it/s, lr=9.48e-6, step_loss=0.0322]07/18/2023 19:59:17 - INFO - __main__ - train loss is 8.746901993872598\n",
      "Steps:  59%|█▏| 8781/15000 [55:55<56:05,  1.85it/s, lr=9.48e-6, step_loss=0.151]07/18/2023 19:59:18 - INFO - __main__ - train loss is 8.76405326765962\n",
      "Steps:  59%|▌| 8782/15000 [55:56<56:01,  1.85it/s, lr=9.48e-6, step_loss=0.0172]07/18/2023 19:59:19 - INFO - __main__ - train loss is 8.989084077300504\n",
      "Steps:  59%|█▏| 8783/15000 [55:56<56:03,  1.85it/s, lr=9.48e-6, step_loss=0.225]07/18/2023 19:59:19 - INFO - __main__ - train loss is 9.263383102836087\n",
      "Steps:  59%|█▏| 8784/15000 [55:57<55:58,  1.85it/s, lr=9.48e-6, step_loss=0.274]07/18/2023 19:59:20 - INFO - __main__ - train loss is 9.399548885645345\n",
      "Steps:  59%|█▏| 8785/15000 [55:58<55:55,  1.85it/s, lr=9.48e-6, step_loss=0.136]07/18/2023 19:59:20 - INFO - __main__ - train loss is 9.413521777139977\n",
      "Steps:  59%|█▏| 8786/15000 [55:58<56:01,  1.85it/s, lr=9.48e-6, step_loss=0.014]07/18/2023 19:59:21 - INFO - __main__ - train loss is 9.475655461894348\n",
      "Steps:  59%|▌| 8787/15000 [55:59<55:45,  1.86it/s, lr=9.48e-6, step_loss=0.0621]07/18/2023 19:59:21 - INFO - __main__ - train loss is 9.879942025290802\n",
      "Steps:  59%|█▏| 8788/15000 [55:59<55:42,  1.86it/s, lr=9.48e-6, step_loss=0.404]07/18/2023 19:59:22 - INFO - __main__ - train loss is 9.897826810600236\n",
      "Steps:  59%|▌| 8789/15000 [56:00<55:33,  1.86it/s, lr=9.48e-6, step_loss=0.0179]07/18/2023 19:59:22 - INFO - __main__ - train loss is 10.46468832087703\n",
      "Steps:  59%|█▏| 8790/15000 [56:00<55:43,  1.86it/s, lr=9.48e-6, step_loss=0.567]07/18/2023 19:59:23 - INFO - __main__ - train loss is 10.614778463961557\n",
      "Steps:  59%|█▊ | 8791/15000 [56:01<55:42,  1.86it/s, lr=9.48e-6, step_loss=0.15]07/18/2023 19:59:23 - INFO - __main__ - train loss is 11.07653755438514\n",
      "Steps:  59%|█▏| 8792/15000 [56:01<55:35,  1.86it/s, lr=9.48e-6, step_loss=0.462]07/18/2023 19:59:24 - INFO - __main__ - train loss is 11.086012081475928\n",
      "Steps:  59%|▌| 8793/15000 [56:02<55:41,  1.86it/s, lr=9.48e-6, step_loss=0.0094707/18/2023 19:59:24 - INFO - __main__ - train loss is 11.198982262285426\n",
      "Steps:  59%|█▏| 8794/15000 [56:02<55:35,  1.86it/s, lr=9.48e-6, step_loss=0.113]07/18/2023 19:59:25 - INFO - __main__ - train loss is 11.363134914310649\n",
      "Steps:  59%|█▏| 8795/15000 [56:03<55:43,  1.86it/s, lr=9.48e-6, step_loss=0.164]07/18/2023 19:59:26 - INFO - __main__ - train loss is 11.740772509248927\n",
      "Steps:  59%|█▏| 8796/15000 [56:03<55:39,  1.86it/s, lr=9.48e-6, step_loss=0.378]07/18/2023 19:59:26 - INFO - __main__ - train loss is 11.74561862158589\n",
      "Steps:  59%|▌| 8797/15000 [56:04<55:24,  1.87it/s, lr=9.48e-6, step_loss=0.0048507/18/2023 19:59:27 - INFO - __main__ - train loss is 11.752748955739662\n",
      "Steps:  59%|▌| 8798/15000 [56:04<55:33,  1.86it/s, lr=9.48e-6, step_loss=0.0071307/18/2023 19:59:27 - INFO - __main__ - train loss is 11.774632685584947\n",
      "Steps:  59%|▌| 8799/15000 [56:05<55:36,  1.86it/s, lr=9.48e-6, step_loss=0.0219]07/18/2023 19:59:28 - INFO - __main__ - train loss is 12.366110258502886\n",
      "Steps:  59%|█▏| 8800/15000 [56:06<55:47,  1.85it/s, lr=9.48e-6, step_loss=0.591]07/18/2023 19:59:28 - INFO - __main__ - train loss is 12.467527472181246\n",
      "Steps:  59%|█▏| 8801/15000 [56:06<56:08,  1.84it/s, lr=9.48e-6, step_loss=0.101]07/18/2023 19:59:29 - INFO - __main__ - train loss is 12.510663450462744\n",
      "Steps:  59%|▌| 8802/15000 [56:07<56:04,  1.84it/s, lr=9.48e-6, step_loss=0.0431]07/18/2023 19:59:29 - INFO - __main__ - train loss is 12.557221331400797\n",
      "Steps:  59%|▌| 8803/15000 [56:07<55:56,  1.85it/s, lr=9.48e-6, step_loss=0.0466]07/18/2023 19:59:30 - INFO - __main__ - train loss is 12.602657683892176\n",
      "Steps:  59%|▌| 8804/15000 [56:08<55:55,  1.85it/s, lr=9.48e-6, step_loss=0.0454]07/18/2023 19:59:30 - INFO - __main__ - train loss is 12.628127352101728\n",
      "Steps:  59%|▌| 8805/15000 [56:08<55:54,  1.85it/s, lr=9.48e-6, step_loss=0.0255]07/18/2023 19:59:31 - INFO - __main__ - train loss is 12.64725334267132\n",
      "Steps:  59%|▌| 8806/15000 [56:09<55:39,  1.85it/s, lr=9.48e-6, step_loss=0.0191]07/18/2023 19:59:31 - INFO - __main__ - train loss is 12.867626257939264\n",
      "Steps:  59%|█▊ | 8807/15000 [56:09<55:30,  1.86it/s, lr=9.48e-6, step_loss=0.22]07/18/2023 19:59:32 - INFO - __main__ - train loss is 12.87075668736361\n",
      "Steps:  59%|▌| 8808/15000 [56:10<55:35,  1.86it/s, lr=9.48e-6, step_loss=0.0031307/18/2023 19:59:33 - INFO - __main__ - train loss is 12.878983909031376\n",
      "Steps:  59%|▌| 8809/15000 [56:10<55:24,  1.86it/s, lr=9.48e-6, step_loss=0.0082307/18/2023 19:59:33 - INFO - __main__ - train loss is 13.145028436323628\n",
      "Steps:  59%|█▏| 8810/15000 [56:11<55:34,  1.86it/s, lr=9.48e-6, step_loss=0.266]07/18/2023 19:59:34 - INFO - __main__ - train loss is 13.150770926149562\n",
      "Steps:  59%|▌| 8811/15000 [56:12<55:40,  1.85it/s, lr=9.48e-6, step_loss=0.0057407/18/2023 19:59:34 - INFO - __main__ - train loss is 13.365434193285182\n",
      "Steps:  59%|█▏| 8812/15000 [56:12<55:43,  1.85it/s, lr=9.48e-6, step_loss=0.215]07/18/2023 19:59:35 - INFO - __main__ - train loss is 13.376025339821354\n",
      "Steps:  59%|▌| 8813/15000 [56:13<55:45,  1.85it/s, lr=9.48e-6, step_loss=0.0106]07/18/2023 19:59:35 - INFO - __main__ - train loss is 13.389454348245636\n",
      "Steps:  59%|▌| 8814/15000 [56:13<55:47,  1.85it/s, lr=9.48e-6, step_loss=0.0134]07/18/2023 19:59:36 - INFO - __main__ - train loss is 13.420967476675287\n",
      "Steps:  59%|▌| 8815/15000 [56:14<55:44,  1.85it/s, lr=9.48e-6, step_loss=0.0315]07/18/2023 19:59:36 - INFO - __main__ - train loss is 13.475197477499023\n",
      "Steps:  59%|▌| 8816/15000 [56:14<55:36,  1.85it/s, lr=9.48e-6, step_loss=0.0542]07/18/2023 19:59:37 - INFO - __main__ - train loss is 13.711204273859039\n",
      "Steps:  59%|█▏| 8817/15000 [56:15<55:29,  1.86it/s, lr=9.48e-6, step_loss=0.236]07/18/2023 19:59:37 - INFO - __main__ - train loss is 13.966944111743942\n",
      "Steps:  59%|█▏| 8818/15000 [56:15<55:21,  1.86it/s, lr=9.48e-6, step_loss=0.256]07/18/2023 19:59:38 - INFO - __main__ - train loss is 13.98018780280836\n",
      "Steps:  59%|▌| 8819/15000 [56:16<55:21,  1.86it/s, lr=9.48e-6, step_loss=0.0132]07/18/2023 19:59:38 - INFO - __main__ - train loss is 14.339702039258555\n",
      "Steps:  59%|█▊ | 8820/15000 [56:16<55:25,  1.86it/s, lr=9.48e-6, step_loss=0.36]07/18/2023 19:59:39 - INFO - __main__ - train loss is 14.344567335443571\n",
      "Steps:  59%|▌| 8821/15000 [56:17<55:29,  1.86it/s, lr=9.48e-6, step_loss=0.0048707/18/2023 19:59:40 - INFO - __main__ - train loss is 14.360529463039711\n",
      "Steps:  59%|█▏| 8822/15000 [56:17<55:34,  1.85it/s, lr=9.48e-6, step_loss=0.016]07/18/2023 19:59:40 - INFO - __main__ - train loss is 14.509458641754463\n",
      "Steps:  59%|█▏| 8823/15000 [56:18<55:37,  1.85it/s, lr=9.48e-6, step_loss=0.149]07/18/2023 19:59:41 - INFO - __main__ - train loss is 14.607761482940987\n",
      "Steps:  59%|▌| 8824/15000 [56:19<55:52,  1.84it/s, lr=9.48e-6, step_loss=0.0983]07/18/2023 19:59:41 - INFO - __main__ - train loss is 14.879168789135292\n",
      "Steps:  59%|█▏| 8825/15000 [56:19<56:07,  1.83it/s, lr=9.48e-6, step_loss=0.271]07/18/2023 19:59:42 - INFO - __main__ - train loss is 15.092024634825066\n",
      "Steps:  59%|█▏| 8826/15000 [56:20<56:13,  1.83it/s, lr=9.48e-6, step_loss=0.213]07/18/2023 19:59:43 - INFO - __main__ - train loss is 15.232174943434075\n",
      "Steps:  59%|▌| 8827/15000 [56:20<1:05:10,  1.58it/s, lr=9.48e-6, step_loss=0.14]07/18/2023 19:59:43 - INFO - __main__ - Per validation step average loss is 0.27003300189971924\n",
      "07/18/2023 19:59:43 - INFO - __main__ - Cumulative validation average loss is 0.27003300189971924\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Per validation step average loss is 0.15919229388237\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Cumulative validation average loss is 0.42922529578208923\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Per validation step average loss is 0.23957672715187073\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Cumulative validation average loss is 0.66880202293396\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Per validation step average loss is 0.03307048976421356\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Cumulative validation average loss is 0.7018725126981735\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Per validation step average loss is 0.046963319182395935\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Cumulative validation average loss is 0.7488358318805695\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Per validation step average loss is 0.2683788537979126\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Cumulative validation average loss is 1.017214685678482\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Per validation step average loss is 0.011314162984490395\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Cumulative validation average loss is 1.0285288486629725\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Per validation step average loss is 0.2972251772880554\n",
      "07/18/2023 19:59:44 - INFO - __main__ - Cumulative validation average loss is 1.3257540259510279\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Per validation step average loss is 0.010929429903626442\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Cumulative validation average loss is 1.3366834558546543\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Per validation step average loss is 0.5477535724639893\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Cumulative validation average loss is 1.8844370283186436\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Per validation step average loss is 0.19987666606903076\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Cumulative validation average loss is 2.0843136943876743\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Per validation step average loss is 0.07291653007268906\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Cumulative validation average loss is 2.1572302244603634\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Average validation loss for Epoch 90 is 0.17976918537169695\n",
      "07/18/2023 19:59:45 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 19:59:59 - INFO - __main__ - Starting epoch 91\n",
      "07/18/2023 19:59:59 - INFO - __main__ - train loss is 0.26020801067352295\n",
      "Steps:  59%|▌| 8828/15000 [56:37<9:14:50,  5.39s/it, lr=9.48e-6, step_loss=0.26]07/18/2023 19:59:59 - INFO - __main__ - train loss is 0.5865838825702667\n",
      "Steps:  59%|▌| 8829/15000 [56:37<6:33:50,  3.83s/it, lr=9.48e-6, step_loss=0.32607/18/2023 19:59:59 - INFO - __main__ - train loss is 0.5881647177739069\n",
      "Steps:  59%|▌| 8830/15000 [56:37<4:41:08,  2.73s/it, lr=9.48e-6, step_loss=0.00107/18/2023 20:00:00 - INFO - __main__ - train loss is 0.5931825934676453\n",
      "Steps:  59%|▌| 8831/15000 [56:38<3:22:23,  1.97s/it, lr=9.48e-6, step_loss=0.00507/18/2023 20:00:00 - INFO - __main__ - train loss is 0.6000260448781773\n",
      "Steps:  59%|▌| 8832/15000 [56:38<2:27:26,  1.43s/it, lr=9.48e-6, step_loss=0.00607/18/2023 20:00:00 - INFO - __main__ - train loss is 0.6102157215354964\n",
      "Steps:  59%|▌| 8833/15000 [56:38<1:48:54,  1.06s/it, lr=9.48e-6, step_loss=0.01007/18/2023 20:00:00 - INFO - __main__ - train loss is 0.615002844366245\n",
      "Steps:  59%|▌| 8834/15000 [56:38<1:21:55,  1.25it/s, lr=9.48e-6, step_loss=0.00407/18/2023 20:00:00 - INFO - __main__ - train loss is 0.6320597081212327\n",
      "Steps:  59%|▌| 8835/15000 [56:38<1:02:52,  1.63it/s, lr=9.48e-6, step_loss=0.01707/18/2023 20:00:01 - INFO - __main__ - train loss is 0.7181700690416619\n",
      "Steps:  59%|▌| 8836/15000 [56:38<49:29,  2.08it/s, lr=9.48e-6, step_loss=0.0861]07/18/2023 20:00:01 - INFO - __main__ - train loss is 1.0268797798780724\n",
      "Steps:  59%|█▏| 8837/15000 [56:39<40:06,  2.56it/s, lr=9.48e-6, step_loss=0.309]07/18/2023 20:00:01 - INFO - __main__ - train loss is 1.1928737087873742\n",
      "Steps:  59%|█▏| 8838/15000 [56:39<33:33,  3.06it/s, lr=9.48e-6, step_loss=0.166]07/18/2023 20:00:01 - INFO - __main__ - train loss is 1.2233879676787183\n",
      "Steps:  59%|▌| 8839/15000 [56:39<28:57,  3.55it/s, lr=9.48e-6, step_loss=0.0305]07/18/2023 20:00:01 - INFO - __main__ - train loss is 1.394799347850494\n",
      "Steps:  59%|█▏| 8840/15000 [56:39<25:45,  3.99it/s, lr=9.48e-6, step_loss=0.171]07/18/2023 20:00:01 - INFO - __main__ - train loss is 1.7447317800251767\n",
      "Steps:  59%|█▊ | 8841/15000 [56:39<23:29,  4.37it/s, lr=9.48e-6, step_loss=0.35]07/18/2023 20:00:02 - INFO - __main__ - train loss is 1.7474422956584021\n",
      "Steps:  59%|▌| 8842/15000 [56:40<22:04,  4.65it/s, lr=9.48e-6, step_loss=0.0027107/18/2023 20:00:02 - INFO - __main__ - train loss is 1.7663512135623023\n",
      "Steps:  59%|▌| 8843/15000 [56:40<20:59,  4.89it/s, lr=9.48e-6, step_loss=0.0189]07/18/2023 20:00:02 - INFO - __main__ - train loss is 2.002267977106385\n",
      "Steps:  59%|█▏| 8844/15000 [56:40<20:14,  5.07it/s, lr=9.48e-6, step_loss=0.236]07/18/2023 20:00:02 - INFO - __main__ - train loss is 2.355987330782227\n",
      "Steps:  59%|█▏| 8845/15000 [56:40<19:42,  5.20it/s, lr=9.48e-6, step_loss=0.354]07/18/2023 20:00:02 - INFO - __main__ - train loss is 2.3955701569793746\n",
      "Steps:  59%|▌| 8846/15000 [56:40<19:21,  5.30it/s, lr=9.48e-6, step_loss=0.0396]07/18/2023 20:00:03 - INFO - __main__ - train loss is 2.8293357769725844\n",
      "Steps:  59%|█▏| 8847/15000 [56:40<19:13,  5.33it/s, lr=9.47e-6, step_loss=0.434]07/18/2023 20:00:03 - INFO - __main__ - train loss is 3.0628887395141646\n",
      "Steps:  59%|█▏| 8848/15000 [56:41<19:01,  5.39it/s, lr=9.47e-6, step_loss=0.234]07/18/2023 20:00:03 - INFO - __main__ - train loss is 3.0841062179533765\n",
      "Steps:  59%|▌| 8849/15000 [56:41<18:52,  5.43it/s, lr=9.47e-6, step_loss=0.0212]07/18/2023 20:00:03 - INFO - __main__ - train loss is 3.0892248534364626\n",
      "Steps:  59%|▌| 8850/15000 [56:41<18:45,  5.46it/s, lr=9.47e-6, step_loss=0.0051207/18/2023 20:00:03 - INFO - __main__ - train loss is 3.616060593049042\n",
      "Steps:  59%|█▏| 8851/15000 [56:41<18:40,  5.49it/s, lr=9.47e-6, step_loss=0.527]07/18/2023 20:00:03 - INFO - __main__ - train loss is 3.6193472881568596\n",
      "Steps:  59%|▌| 8852/15000 [56:41<18:47,  5.45it/s, lr=9.47e-6, step_loss=0.0032907/18/2023 20:00:04 - INFO - __main__ - train loss is 3.621260630316101\n",
      "Steps:  59%|▌| 8853/15000 [56:42<18:53,  5.42it/s, lr=9.47e-6, step_loss=0.0019107/18/2023 20:00:04 - INFO - __main__ - train loss is 3.7301404870813712\n",
      "Steps:  59%|█▏| 8854/15000 [56:42<18:41,  5.48it/s, lr=9.47e-6, step_loss=0.109]07/18/2023 20:00:04 - INFO - __main__ - train loss is 3.7333808360854164\n",
      "Steps:  59%|▌| 8855/15000 [56:42<18:32,  5.52it/s, lr=9.47e-6, step_loss=0.0032407/18/2023 20:00:04 - INFO - __main__ - train loss is 3.751405388698913\n",
      "Steps:  59%|█▏| 8856/15000 [56:42<18:26,  5.55it/s, lr=9.47e-6, step_loss=0.018]07/18/2023 20:00:04 - INFO - __main__ - train loss is 3.760299284593202\n",
      "Steps:  59%|▌| 8857/15000 [56:42<18:22,  5.57it/s, lr=9.47e-6, step_loss=0.0088907/18/2023 20:00:05 - INFO - __main__ - train loss is 4.263344605104066\n",
      "Steps:  59%|█▏| 8858/15000 [56:42<18:19,  5.58it/s, lr=9.47e-6, step_loss=0.503]07/18/2023 20:00:05 - INFO - __main__ - train loss is 4.274558588513173\n",
      "Steps:  59%|▌| 8859/15000 [56:43<18:17,  5.59it/s, lr=9.47e-6, step_loss=0.0112]07/18/2023 20:00:05 - INFO - __main__ - train loss is 4.27659871627111\n",
      "Steps:  59%|▌| 8860/15000 [56:43<18:16,  5.60it/s, lr=9.47e-6, step_loss=0.0020407/18/2023 20:00:05 - INFO - __main__ - train loss is 4.5129862372996286\n",
      "Steps:  59%|█▏| 8861/15000 [56:43<18:14,  5.61it/s, lr=9.47e-6, step_loss=0.236]07/18/2023 20:00:05 - INFO - __main__ - train loss is 4.520149576594122\n",
      "Steps:  59%|▌| 8862/15000 [56:43<18:13,  5.61it/s, lr=9.47e-6, step_loss=0.0071607/18/2023 20:00:05 - INFO - __main__ - train loss is 4.551500002969988\n",
      "Steps:  59%|▌| 8863/15000 [56:43<18:13,  5.61it/s, lr=9.47e-6, step_loss=0.0314]07/18/2023 20:00:06 - INFO - __main__ - train loss is 4.603987562586553\n",
      "Steps:  59%|▌| 8864/15000 [56:43<18:13,  5.61it/s, lr=9.47e-6, step_loss=0.0525]07/18/2023 20:00:06 - INFO - __main__ - train loss is 4.793393063475378\n",
      "Steps:  59%|█▏| 8865/15000 [56:44<18:12,  5.61it/s, lr=9.47e-6, step_loss=0.189]07/18/2023 20:00:06 - INFO - __main__ - train loss is 4.80148695607204\n",
      "Steps:  59%|▌| 8866/15000 [56:44<18:12,  5.61it/s, lr=9.47e-6, step_loss=0.0080907/18/2023 20:00:06 - INFO - __main__ - train loss is 4.818798063439317\n",
      "Steps:  59%|▌| 8867/15000 [56:44<18:13,  5.61it/s, lr=9.47e-6, step_loss=0.0173]07/18/2023 20:00:06 - INFO - __main__ - train loss is 4.822961304453202\n",
      "Steps:  59%|▌| 8868/15000 [56:44<18:13,  5.61it/s, lr=9.47e-6, step_loss=0.0041607/18/2023 20:00:06 - INFO - __main__ - train loss is 4.842643577721901\n",
      "Steps:  59%|▌| 8869/15000 [56:44<18:13,  5.61it/s, lr=9.47e-6, step_loss=0.0197]07/18/2023 20:00:07 - INFO - __main__ - train loss is 4.893367815879174\n",
      "Steps:  59%|▌| 8870/15000 [56:45<18:14,  5.60it/s, lr=9.47e-6, step_loss=0.0507]07/18/2023 20:00:07 - INFO - __main__ - train loss is 5.415859151748009\n",
      "Steps:  59%|█▏| 8871/15000 [56:45<18:14,  5.60it/s, lr=9.47e-6, step_loss=0.522]07/18/2023 20:00:07 - INFO - __main__ - train loss is 5.521496009198017\n",
      "Steps:  59%|█▏| 8872/15000 [56:45<18:14,  5.60it/s, lr=9.47e-6, step_loss=0.106]07/18/2023 20:00:07 - INFO - __main__ - train loss is 5.526269650203176\n",
      "Steps:  59%|▌| 8873/15000 [56:45<18:15,  5.59it/s, lr=9.47e-6, step_loss=0.0047707/18/2023 20:00:07 - INFO - __main__ - train loss is 5.534718751092441\n",
      "Steps:  59%|▌| 8874/15000 [56:45<18:14,  5.60it/s, lr=9.47e-6, step_loss=0.0084507/18/2023 20:00:08 - INFO - __main__ - train loss is 5.600537500460632\n",
      "Steps:  59%|▌| 8875/15000 [56:45<18:14,  5.60it/s, lr=9.47e-6, step_loss=0.0658]07/18/2023 20:00:08 - INFO - __main__ - train loss is 5.615774627891369\n",
      "Steps:  59%|▌| 8876/15000 [56:46<18:14,  5.60it/s, lr=9.47e-6, step_loss=0.0152]07/18/2023 20:00:08 - INFO - __main__ - train loss is 6.05010854837019\n",
      "Steps:  59%|█▏| 8877/15000 [56:46<18:20,  5.57it/s, lr=9.47e-6, step_loss=0.434]07/18/2023 20:00:08 - INFO - __main__ - train loss is 6.063691979390569\n",
      "Steps:  59%|▌| 8878/15000 [56:46<18:22,  5.55it/s, lr=9.47e-6, step_loss=0.0136]07/18/2023 20:00:08 - INFO - __main__ - train loss is 6.229607051354833\n",
      "Steps:  59%|█▏| 8879/15000 [56:46<18:25,  5.54it/s, lr=9.47e-6, step_loss=0.166]07/18/2023 20:00:08 - INFO - __main__ - train loss is 6.244126659003086\n",
      "Steps:  59%|▌| 8880/15000 [56:46<18:22,  5.55it/s, lr=9.47e-6, step_loss=0.0145]07/18/2023 20:00:09 - INFO - __main__ - train loss is 6.263926748302765\n",
      "Steps:  59%|▌| 8881/15000 [56:47<18:19,  5.56it/s, lr=9.47e-6, step_loss=0.0198]07/18/2023 20:00:09 - INFO - __main__ - train loss is 6.267913859453984\n",
      "Steps:  59%|▌| 8882/15000 [56:47<18:19,  5.56it/s, lr=9.47e-6, step_loss=0.0039907/18/2023 20:00:09 - INFO - __main__ - train loss is 6.539680432644673\n",
      "Steps:  59%|█▏| 8883/15000 [56:47<18:27,  5.52it/s, lr=9.47e-6, step_loss=0.272]07/18/2023 20:00:09 - INFO - __main__ - train loss is 6.543702328694053\n",
      "Steps:  59%|▌| 8884/15000 [56:47<18:22,  5.55it/s, lr=9.47e-6, step_loss=0.0040207/18/2023 20:00:09 - INFO - __main__ - train loss is 6.555537318927236\n",
      "Steps:  59%|▌| 8885/15000 [56:47<18:19,  5.56it/s, lr=9.47e-6, step_loss=0.0118]07/18/2023 20:00:10 - INFO - __main__ - train loss is 6.57412756246049\n",
      "Steps:  59%|▌| 8886/15000 [56:47<18:17,  5.57it/s, lr=9.47e-6, step_loss=0.0186]07/18/2023 20:00:10 - INFO - __main__ - train loss is 6.584462899831124\n",
      "Steps:  59%|▌| 8887/15000 [56:48<18:15,  5.58it/s, lr=9.47e-6, step_loss=0.0103]07/18/2023 20:00:10 - INFO - __main__ - train loss is 6.594835655880161\n",
      "Steps:  59%|▌| 8888/15000 [56:48<18:14,  5.58it/s, lr=9.47e-6, step_loss=0.0104]07/18/2023 20:00:10 - INFO - __main__ - train loss is 6.611268671345897\n",
      "Steps:  59%|▌| 8889/15000 [56:48<18:25,  5.53it/s, lr=9.47e-6, step_loss=0.0164]07/18/2023 20:00:10 - INFO - __main__ - train loss is 6.708890052628703\n",
      "Steps:  59%|▌| 8890/15000 [56:48<18:29,  5.51it/s, lr=9.47e-6, step_loss=0.0976]07/18/2023 20:00:10 - INFO - __main__ - train loss is 6.733588552218862\n",
      "Steps:  59%|▌| 8891/15000 [56:48<18:23,  5.53it/s, lr=9.47e-6, step_loss=0.0247]07/18/2023 20:00:11 - INFO - __main__ - train loss is 6.755844153580256\n",
      "Steps:  59%|▌| 8892/15000 [56:48<18:20,  5.55it/s, lr=9.47e-6, step_loss=0.0223]07/18/2023 20:00:11 - INFO - __main__ - train loss is 6.864479310926981\n",
      "Steps:  59%|█▏| 8893/15000 [56:49<18:17,  5.57it/s, lr=9.47e-6, step_loss=0.109]07/18/2023 20:00:11 - INFO - __main__ - train loss is 6.885177224990912\n",
      "Steps:  59%|▌| 8894/15000 [56:49<18:18,  5.56it/s, lr=9.47e-6, step_loss=0.0207]07/18/2023 20:00:11 - INFO - __main__ - train loss is 6.893299892661162\n",
      "Steps:  59%|▌| 8895/15000 [56:49<18:16,  5.57it/s, lr=9.47e-6, step_loss=0.0081207/18/2023 20:00:11 - INFO - __main__ - train loss is 6.895330752595328\n",
      "Steps:  59%|▌| 8896/15000 [56:49<18:14,  5.58it/s, lr=9.47e-6, step_loss=0.0020307/18/2023 20:00:12 - INFO - __main__ - train loss is 6.907359850942157\n",
      "Steps:  59%|█▏| 8897/15000 [56:49<18:12,  5.58it/s, lr=9.47e-6, step_loss=0.012]07/18/2023 20:00:12 - INFO - __main__ - train loss is 7.040292186080478\n",
      "Steps:  59%|█▏| 8898/15000 [56:50<18:11,  5.59it/s, lr=9.47e-6, step_loss=0.133]07/18/2023 20:00:12 - INFO - __main__ - train loss is 7.07936169707682\n",
      "Steps:  59%|▌| 8899/15000 [56:50<18:19,  5.55it/s, lr=9.47e-6, step_loss=0.0391]07/18/2023 20:00:12 - INFO - __main__ - train loss is 7.643068452714942\n",
      "Steps:  59%|█▏| 8900/15000 [56:50<18:24,  5.52it/s, lr=9.47e-6, step_loss=0.564]07/18/2023 20:00:12 - INFO - __main__ - train loss is 7.876676102518104\n",
      "Steps:  59%|█▏| 8901/15000 [56:50<18:28,  5.50it/s, lr=9.47e-6, step_loss=0.234]07/18/2023 20:00:12 - INFO - __main__ - train loss is 8.02771710359957\n",
      "Steps:  59%|█▏| 8902/15000 [56:50<18:31,  5.49it/s, lr=9.47e-6, step_loss=0.151]07/18/2023 20:00:13 - INFO - __main__ - train loss is 8.10715304815676\n",
      "Steps:  59%|▌| 8903/15000 [56:50<18:33,  5.47it/s, lr=9.47e-6, step_loss=0.0794]07/18/2023 20:00:13 - INFO - __main__ - train loss is 8.158888277946971\n",
      "Steps:  59%|▌| 8904/15000 [56:51<18:35,  5.46it/s, lr=9.47e-6, step_loss=0.0517]07/18/2023 20:00:13 - INFO - __main__ - train loss is 8.333203730522655\n",
      "Steps:  59%|█▏| 8905/15000 [56:51<18:35,  5.46it/s, lr=9.47e-6, step_loss=0.174]07/18/2023 20:00:13 - INFO - __main__ - train loss is 8.38346132019069\n",
      "Steps:  59%|▌| 8906/15000 [56:51<18:35,  5.46it/s, lr=9.47e-6, step_loss=0.0503]07/18/2023 20:00:13 - INFO - __main__ - train loss is 8.39107377117034\n",
      "Steps:  59%|▌| 8907/15000 [56:51<18:34,  5.47it/s, lr=9.47e-6, step_loss=0.0076107/18/2023 20:00:14 - INFO - __main__ - train loss is 8.520921357325278\n",
      "Steps:  59%|█▊ | 8908/15000 [56:51<18:25,  5.51it/s, lr=9.47e-6, step_loss=0.13]07/18/2023 20:00:14 - INFO - __main__ - train loss is 8.761372097185813\n",
      "Steps:  59%|█▊ | 8909/15000 [56:52<18:26,  5.51it/s, lr=9.47e-6, step_loss=0.24]07/18/2023 20:00:14 - INFO - __main__ - train loss is 9.185785480192862\n",
      "Steps:  59%|█▏| 8910/15000 [56:52<18:19,  5.54it/s, lr=9.47e-6, step_loss=0.424]07/18/2023 20:00:14 - INFO - __main__ - train loss is 9.281050928286277\n",
      "Steps:  59%|▌| 8911/15000 [56:52<18:16,  5.56it/s, lr=9.47e-6, step_loss=0.0953]07/18/2023 20:00:14 - INFO - __main__ - train loss is 9.722515620640479\n",
      "Steps:  59%|█▏| 8912/15000 [56:52<18:13,  5.57it/s, lr=9.47e-6, step_loss=0.441]07/18/2023 20:00:14 - INFO - __main__ - train loss is 9.797126584104262\n",
      "Steps:  59%|▌| 8913/15000 [56:52<18:10,  5.58it/s, lr=9.47e-6, step_loss=0.0746]07/18/2023 20:00:15 - INFO - __main__ - train loss is 9.801323309889995\n",
      "Steps:  59%|▌| 8914/15000 [56:52<18:09,  5.59it/s, lr=9.47e-6, step_loss=0.0042]07/18/2023 20:00:15 - INFO - __main__ - train loss is 9.885851525119506\n",
      "Steps:  59%|▌| 8915/15000 [56:53<18:08,  5.59it/s, lr=9.47e-6, step_loss=0.0845]07/18/2023 20:00:15 - INFO - __main__ - train loss is 10.057556026033126\n",
      "Steps:  59%|█▏| 8916/15000 [56:53<18:06,  5.60it/s, lr=9.47e-6, step_loss=0.172]07/18/2023 20:00:15 - INFO - __main__ - train loss is 10.07084973284509\n",
      "Steps:  59%|▌| 8917/15000 [56:53<18:09,  5.58it/s, lr=9.47e-6, step_loss=0.0133]07/18/2023 20:00:15 - INFO - __main__ - train loss is 10.0786568535259\n",
      "Steps:  59%|▌| 8918/15000 [56:53<18:07,  5.59it/s, lr=9.47e-6, step_loss=0.0078107/18/2023 20:00:15 - INFO - __main__ - train loss is 10.156936467974447\n",
      "Steps:  59%|▌| 8919/15000 [56:53<18:05,  5.60it/s, lr=9.47e-6, step_loss=0.0783]07/18/2023 20:00:16 - INFO - __main__ - train loss is 10.474731983034872\n",
      "Steps:  59%|█▏| 8920/15000 [56:54<18:04,  5.61it/s, lr=9.47e-6, step_loss=0.318]07/18/2023 20:00:16 - INFO - __main__ - train loss is 10.486990434466861\n",
      "Steps:  59%|▌| 8921/15000 [56:54<18:03,  5.61it/s, lr=9.47e-6, step_loss=0.0123]07/18/2023 20:00:16 - INFO - __main__ - train loss is 10.784714323817752\n",
      "Steps:  59%|█▏| 8922/15000 [56:54<18:03,  5.61it/s, lr=9.47e-6, step_loss=0.298]07/18/2023 20:00:16 - INFO - __main__ - train loss is 10.928589177667163\n",
      "Steps:  59%|█▏| 8923/15000 [56:54<18:03,  5.61it/s, lr=9.47e-6, step_loss=0.144]07/18/2023 20:00:17 - INFO - __main__ - train loss is 10.946002022712491\n",
      "Steps:  59%|▌| 8924/15000 [56:54<24:52,  4.07it/s, lr=9.47e-6, step_loss=0.0174]07/18/2023 20:00:17 - INFO - __main__ - Per validation step average loss is 0.4838331341743469\n",
      "07/18/2023 20:00:17 - INFO - __main__ - Cumulative validation average loss is 0.4838331341743469\n",
      "07/18/2023 20:00:17 - INFO - __main__ - Per validation step average loss is 0.19503101706504822\n",
      "07/18/2023 20:00:17 - INFO - __main__ - Cumulative validation average loss is 0.6788641512393951\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Per validation step average loss is 0.021746525540947914\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Cumulative validation average loss is 0.7006106767803431\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Per validation step average loss is 0.06647393107414246\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Cumulative validation average loss is 0.7670846078544855\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Per validation step average loss is 0.3037264049053192\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Cumulative validation average loss is 1.0708110127598047\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Per validation step average loss is 0.0027155219577252865\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Cumulative validation average loss is 1.07352653471753\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Per validation step average loss is 0.0029589817859232426\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Cumulative validation average loss is 1.0764855165034533\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Per validation step average loss is 0.2178344875574112\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Cumulative validation average loss is 1.2943200040608644\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Per validation step average loss is 0.002971585374325514\n",
      "07/18/2023 20:00:18 - INFO - __main__ - Cumulative validation average loss is 1.29729158943519\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Per validation step average loss is 0.08690628409385681\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Cumulative validation average loss is 1.3841978735290468\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Per validation step average loss is 0.009498614817857742\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Cumulative validation average loss is 1.3936964883469045\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Per validation step average loss is 0.041358593851327896\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Cumulative validation average loss is 1.4350550821982324\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Average validation loss for Epoch 91 is 0.11958792351651937\n",
      "07/18/2023 20:00:19 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:00:32 - INFO - __main__ - Starting epoch 92\n",
      "07/18/2023 20:00:32 - INFO - __main__ - train loss is 0.007978705689311028\n",
      "Steps:  60%|▌| 8925/15000 [57:10<8:16:13,  4.90s/it, lr=9.47e-6, step_loss=0.00707/18/2023 20:00:33 - INFO - __main__ - train loss is 0.016892927698791027\n",
      "Steps:  60%|▌| 8926/15000 [57:10<5:52:45,  3.48s/it, lr=9.47e-6, step_loss=0.00807/18/2023 20:00:33 - INFO - __main__ - train loss is 0.30520500522106886\n",
      "Steps:  60%|▌| 8927/15000 [57:11<4:12:19,  2.49s/it, lr=9.47e-6, step_loss=0.28807/18/2023 20:00:33 - INFO - __main__ - train loss is 0.30858613178133965\n",
      "Steps:  60%|▌| 8928/15000 [57:11<3:02:07,  1.80s/it, lr=9.47e-6, step_loss=0.00307/18/2023 20:00:33 - INFO - __main__ - train loss is 0.8222699873149395\n",
      "Steps:  60%|▌| 8929/15000 [57:11<2:13:03,  1.31s/it, lr=9.47e-6, step_loss=0.51407/18/2023 20:00:33 - INFO - __main__ - train loss is 1.3598564378917217\n",
      "Steps:  60%|▌| 8930/15000 [57:11<1:38:36,  1.03it/s, lr=9.47e-6, step_loss=0.53807/18/2023 20:00:33 - INFO - __main__ - train loss is 1.3895439952611923\n",
      "Steps:  60%|▌| 8931/15000 [57:11<1:14:29,  1.36it/s, lr=9.47e-6, step_loss=0.02907/18/2023 20:00:34 - INFO - __main__ - train loss is 1.514107346534729\n",
      "Steps:  60%|█▏| 8932/15000 [57:12<57:36,  1.76it/s, lr=9.46e-6, step_loss=0.125]07/18/2023 20:00:34 - INFO - __main__ - train loss is 1.6086266040802002\n",
      "Steps:  60%|▌| 8933/15000 [57:12<45:48,  2.21it/s, lr=9.46e-6, step_loss=0.0945]07/18/2023 20:00:34 - INFO - __main__ - train loss is 1.846110761165619\n",
      "Steps:  60%|█▏| 8934/15000 [57:12<37:33,  2.69it/s, lr=9.46e-6, step_loss=0.237]07/18/2023 20:00:34 - INFO - __main__ - train loss is 1.8477765278657898\n",
      "Steps:  60%|▌| 8935/15000 [57:12<31:45,  3.18it/s, lr=9.46e-6, step_loss=0.0016707/18/2023 20:00:34 - INFO - __main__ - train loss is 1.8500915862387046\n",
      "Steps:  60%|▌| 8936/15000 [57:12<27:52,  3.63it/s, lr=9.46e-6, step_loss=0.0023207/18/2023 20:00:35 - INFO - __main__ - train loss is 1.9116258159046993\n",
      "Steps:  60%|▌| 8937/15000 [57:12<24:56,  4.05it/s, lr=9.46e-6, step_loss=0.0615]07/18/2023 20:00:35 - INFO - __main__ - train loss is 1.9369051161920652\n",
      "Steps:  60%|▌| 8938/15000 [57:13<22:49,  4.42it/s, lr=9.46e-6, step_loss=0.0253]07/18/2023 20:00:35 - INFO - __main__ - train loss is 1.984386634430848\n",
      "Steps:  60%|▌| 8939/15000 [57:13<21:22,  4.73it/s, lr=9.46e-6, step_loss=0.0475]07/18/2023 20:00:35 - INFO - __main__ - train loss is 2.007860243669711\n",
      "Steps:  60%|▌| 8940/15000 [57:13<20:20,  4.97it/s, lr=9.46e-6, step_loss=0.0235]07/18/2023 20:00:35 - INFO - __main__ - train loss is 2.0183057341491804\n",
      "Steps:  60%|▌| 8941/15000 [57:13<19:37,  5.14it/s, lr=9.46e-6, step_loss=0.0104]07/18/2023 20:00:35 - INFO - __main__ - train loss is 2.075676691136323\n",
      "Steps:  60%|▌| 8942/15000 [57:13<19:21,  5.22it/s, lr=9.46e-6, step_loss=0.0574]07/18/2023 20:00:36 - INFO - __main__ - train loss is 2.0823380382498726\n",
      "Steps:  60%|▌| 8943/15000 [57:14<19:15,  5.24it/s, lr=9.46e-6, step_loss=0.0066607/18/2023 20:00:36 - INFO - __main__ - train loss is 2.086965138441883\n",
      "Steps:  60%|▌| 8944/15000 [57:14<19:00,  5.31it/s, lr=9.46e-6, step_loss=0.0046307/18/2023 20:00:36 - INFO - __main__ - train loss is 2.4521638102596626\n",
      "Steps:  60%|█▏| 8945/15000 [57:14<18:52,  5.35it/s, lr=9.46e-6, step_loss=0.365]07/18/2023 20:00:36 - INFO - __main__ - train loss is 2.5644863940542564\n",
      "Steps:  60%|█▏| 8946/15000 [57:14<18:57,  5.32it/s, lr=9.46e-6, step_loss=0.112]07/18/2023 20:00:36 - INFO - __main__ - train loss is 2.630557658500038\n",
      "Steps:  60%|▌| 8947/15000 [57:14<19:00,  5.31it/s, lr=9.46e-6, step_loss=0.0661]07/18/2023 20:00:37 - INFO - __main__ - train loss is 2.741602035588585\n",
      "Steps:  60%|█▏| 8948/15000 [57:14<19:03,  5.29it/s, lr=9.46e-6, step_loss=0.111]07/18/2023 20:00:37 - INFO - __main__ - train loss is 2.7445128896506503\n",
      "Steps:  60%|▌| 8949/15000 [57:15<18:54,  5.33it/s, lr=9.46e-6, step_loss=0.0029107/18/2023 20:00:37 - INFO - __main__ - train loss is 2.860814292100258\n",
      "Steps:  60%|█▏| 8950/15000 [57:15<18:37,  5.41it/s, lr=9.46e-6, step_loss=0.116]07/18/2023 20:00:37 - INFO - __main__ - train loss is 2.8982221261831\n",
      "Steps:  60%|▌| 8951/15000 [57:15<18:26,  5.47it/s, lr=9.46e-6, step_loss=0.0374]07/18/2023 20:00:37 - INFO - __main__ - train loss is 3.4084955827565864\n",
      "Steps:  60%|█▊ | 8952/15000 [57:15<18:18,  5.51it/s, lr=9.46e-6, step_loss=0.51]07/18/2023 20:00:37 - INFO - __main__ - train loss is 3.423523184028454\n",
      "Steps:  60%|█▏| 8953/15000 [57:15<18:13,  5.53it/s, lr=9.46e-6, step_loss=0.015]07/18/2023 20:00:38 - INFO - __main__ - train loss is 3.561873968807049\n",
      "[2023-07-18 20:00:38,218] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:  60%|█▏| 8954/15000 [57:16<18:05,  5.57it/s, lr=9.46e-6, step_loss=0.138]07/18/2023 20:00:38 - INFO - __main__ - train loss is 3.615049358573742\n",
      "Steps:  60%|▌| 8955/15000 [57:16<18:06,  5.56it/s, lr=9.46e-6, step_loss=0.0532]07/18/2023 20:00:38 - INFO - __main__ - train loss is 3.6602736675413325\n",
      "Steps:  60%|▌| 8956/15000 [57:16<18:08,  5.55it/s, lr=9.46e-6, step_loss=0.0452]07/18/2023 20:00:38 - INFO - __main__ - train loss is 3.764884051051922\n",
      "Steps:  60%|█▏| 8957/15000 [57:16<18:08,  5.55it/s, lr=9.46e-6, step_loss=0.105]07/18/2023 20:00:38 - INFO - __main__ - train loss is 3.788171295193024\n",
      "Steps:  60%|▌| 8958/15000 [57:16<18:09,  5.55it/s, lr=9.46e-6, step_loss=0.0233]07/18/2023 20:00:39 - INFO - __main__ - train loss is 3.9749187567504123\n",
      "Steps:  60%|█▏| 8959/15000 [57:16<18:10,  5.54it/s, lr=9.46e-6, step_loss=0.187]07/18/2023 20:00:39 - INFO - __main__ - train loss is 3.995080214110203\n",
      "Steps:  60%|▌| 8960/15000 [57:17<18:10,  5.54it/s, lr=9.46e-6, step_loss=0.0202]07/18/2023 20:00:39 - INFO - __main__ - train loss is 4.091219510999508\n",
      "Steps:  60%|▌| 8961/15000 [57:17<18:11,  5.53it/s, lr=9.46e-6, step_loss=0.0961]07/18/2023 20:00:39 - INFO - __main__ - train loss is 4.548062261310406\n",
      "Steps:  60%|█▏| 8962/15000 [57:17<18:11,  5.53it/s, lr=9.46e-6, step_loss=0.457]07/18/2023 20:00:39 - INFO - __main__ - train loss is 4.580952726420946\n",
      "Steps:  60%|▌| 8963/15000 [57:17<18:11,  5.53it/s, lr=9.46e-6, step_loss=0.0329]07/18/2023 20:00:39 - INFO - __main__ - train loss is 4.67414846282918\n",
      "Steps:  60%|▌| 8964/15000 [57:17<18:11,  5.53it/s, lr=9.46e-6, step_loss=0.0932]07/18/2023 20:00:40 - INFO - __main__ - train loss is 4.707637261715718\n",
      "Steps:  60%|▌| 8965/15000 [57:18<18:11,  5.53it/s, lr=9.46e-6, step_loss=0.0335]07/18/2023 20:00:40 - INFO - __main__ - train loss is 4.8415061050327495\n",
      "Steps:  60%|█▏| 8966/15000 [57:18<18:05,  5.56it/s, lr=9.46e-6, step_loss=0.134]07/18/2023 20:00:40 - INFO - __main__ - train loss is 4.885846901801415\n",
      "Steps:  60%|▌| 8967/15000 [57:18<18:02,  5.58it/s, lr=9.46e-6, step_loss=0.0443]07/18/2023 20:00:40 - INFO - __main__ - train loss is 5.047487128642388\n",
      "Steps:  60%|█▏| 8968/15000 [57:18<17:59,  5.59it/s, lr=9.46e-6, step_loss=0.162]07/18/2023 20:00:40 - INFO - __main__ - train loss is 5.049725271412171\n",
      "Steps:  60%|▌| 8969/15000 [57:18<18:09,  5.54it/s, lr=9.46e-6, step_loss=0.0022407/18/2023 20:00:41 - INFO - __main__ - train loss is 5.062099836417474\n",
      "Steps:  60%|▌| 8970/15000 [57:18<18:16,  5.50it/s, lr=9.46e-6, step_loss=0.0124]07/18/2023 20:00:41 - INFO - __main__ - train loss is 5.118383161374368\n",
      "Steps:  60%|▌| 8971/15000 [57:19<18:10,  5.53it/s, lr=9.46e-6, step_loss=0.0563]07/18/2023 20:00:41 - INFO - __main__ - train loss is 5.121025123517029\n",
      "Steps:  60%|▌| 8972/15000 [57:19<18:07,  5.54it/s, lr=9.46e-6, step_loss=0.0026407/18/2023 20:00:41 - INFO - __main__ - train loss is 5.207044982234947\n",
      "Steps:  60%|█▏| 8973/15000 [57:19<18:05,  5.55it/s, lr=9.46e-6, step_loss=0.086]07/18/2023 20:00:41 - INFO - __main__ - train loss is 5.901992940227501\n",
      "Steps:  60%|█▏| 8974/15000 [57:19<18:02,  5.57it/s, lr=9.46e-6, step_loss=0.695]07/18/2023 20:00:41 - INFO - __main__ - train loss is 5.969355978886597\n",
      "Steps:  60%|▌| 8975/15000 [57:19<18:01,  5.57it/s, lr=9.46e-6, step_loss=0.0674]07/18/2023 20:00:42 - INFO - __main__ - train loss is 6.098975979606621\n",
      "Steps:  60%|█▊ | 8976/15000 [57:19<18:13,  5.51it/s, lr=9.46e-6, step_loss=0.13]07/18/2023 20:00:42 - INFO - __main__ - train loss is 6.569248163024895\n",
      "Steps:  60%|█▊ | 8977/15000 [57:20<19:06,  5.25it/s, lr=9.46e-6, step_loss=0.47]07/18/2023 20:00:42 - INFO - __main__ - train loss is 6.634171069483273\n",
      "Steps:  60%|▌| 8978/15000 [57:20<19:13,  5.22it/s, lr=9.46e-6, step_loss=0.0649]07/18/2023 20:00:42 - INFO - __main__ - train loss is 7.09401002607774\n",
      "Steps:  60%|█▊ | 8979/15000 [57:20<19:17,  5.20it/s, lr=9.46e-6, step_loss=0.46]07/18/2023 20:00:42 - INFO - __main__ - train loss is 7.197630331735127\n",
      "Steps:  60%|█▏| 8980/15000 [57:20<19:14,  5.21it/s, lr=9.46e-6, step_loss=0.104]07/18/2023 20:00:43 - INFO - __main__ - train loss is 7.3146196835441515\n",
      "Steps:  60%|█▏| 8981/15000 [57:20<18:55,  5.30it/s, lr=9.46e-6, step_loss=0.117]07/18/2023 20:00:43 - INFO - __main__ - train loss is 7.558722265879624\n",
      "Steps:  60%|█▏| 8982/15000 [57:21<18:42,  5.36it/s, lr=9.46e-6, step_loss=0.244]07/18/2023 20:00:43 - INFO - __main__ - train loss is 8.136510261218064\n",
      "Steps:  60%|█▏| 8983/15000 [57:21<18:33,  5.40it/s, lr=9.46e-6, step_loss=0.578]07/18/2023 20:00:43 - INFO - __main__ - train loss is 8.370598965208046\n",
      "Steps:  60%|█▏| 8984/15000 [57:21<18:29,  5.42it/s, lr=9.46e-6, step_loss=0.234]07/18/2023 20:00:43 - INFO - __main__ - train loss is 8.689783983747475\n",
      "Steps:  60%|█▏| 8985/15000 [57:21<18:33,  5.40it/s, lr=9.46e-6, step_loss=0.319]07/18/2023 20:00:43 - INFO - __main__ - train loss is 8.718708178843372\n",
      "Steps:  60%|▌| 8986/15000 [57:21<18:27,  5.43it/s, lr=9.46e-6, step_loss=0.0289]07/18/2023 20:00:44 - INFO - __main__ - train loss is 8.834394707228057\n",
      "Steps:  60%|█▏| 8987/15000 [57:22<18:29,  5.42it/s, lr=9.46e-6, step_loss=0.116]07/18/2023 20:00:44 - INFO - __main__ - train loss is 9.147865070845\n",
      "Steps:  60%|█▏| 8988/15000 [57:22<18:25,  5.44it/s, lr=9.46e-6, step_loss=0.313]07/18/2023 20:00:44 - INFO - __main__ - train loss is 9.276868357206695\n",
      "Steps:  60%|█▏| 8989/15000 [57:22<18:20,  5.46it/s, lr=9.46e-6, step_loss=0.129]07/18/2023 20:00:44 - INFO - __main__ - train loss is 9.28127980499994\n",
      "Steps:  60%|▌| 8990/15000 [57:22<18:16,  5.48it/s, lr=9.46e-6, step_loss=0.0044107/18/2023 20:00:44 - INFO - __main__ - train loss is 9.29274710721802\n",
      "Steps:  60%|▌| 8991/15000 [57:22<18:15,  5.49it/s, lr=9.46e-6, step_loss=0.0115]07/18/2023 20:00:45 - INFO - __main__ - train loss is 9.373760093818419\n",
      "Steps:  60%|█▏| 8992/15000 [57:22<18:13,  5.49it/s, lr=9.46e-6, step_loss=0.081]07/18/2023 20:00:45 - INFO - __main__ - train loss is 9.704869736800902\n",
      "Steps:  60%|█▏| 8993/15000 [57:23<18:51,  5.31it/s, lr=9.46e-6, step_loss=0.331]07/18/2023 20:00:45 - INFO - __main__ - train loss is 9.837895710836165\n",
      "Steps:  60%|█▏| 8994/15000 [57:23<19:02,  5.26it/s, lr=9.46e-6, step_loss=0.133]07/18/2023 20:00:45 - INFO - __main__ - train loss is 9.842891623149626\n",
      "Steps:  60%|█▏| 8995/15000 [57:23<19:11,  5.21it/s, lr=9.46e-6, step_loss=0.005]07/18/2023 20:00:45 - INFO - __main__ - train loss is 10.019294832716696\n",
      "Steps:  60%|█▏| 8996/15000 [57:23<19:20,  5.17it/s, lr=9.46e-6, step_loss=0.176]07/18/2023 20:00:46 - INFO - __main__ - train loss is 10.224965651403181\n",
      "Steps:  60%|█▏| 8997/15000 [57:23<19:23,  5.16it/s, lr=9.46e-6, step_loss=0.206]07/18/2023 20:00:46 - INFO - __main__ - train loss is 10.260742143611424\n",
      "Steps:  60%|▌| 8998/15000 [57:24<19:29,  5.13it/s, lr=9.46e-6, step_loss=0.0358]07/18/2023 20:00:46 - INFO - __main__ - train loss is 10.262517183669843\n",
      "Steps:  60%|▌| 8999/15000 [57:24<19:24,  5.16it/s, lr=9.46e-6, step_loss=0.0017807/18/2023 20:00:46 - INFO - __main__ - train loss is 10.26646091195289\n",
      "Steps:  60%|▌| 9000/15000 [57:24<19:26,  5.15it/s, lr=9.46e-6, step_loss=0.0017807/18/2023 20:00:46 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-9000\n",
      "07/18/2023 20:00:46 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:00:46,741] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:00:46,747] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-9000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:00:46,747] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-9000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:00:46,758] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-9000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:00:46,758] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-9000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:00:46,783] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-9000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:00:46,783] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-9000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:00:46,783] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:00:46 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-9000/pytorch_model\n",
      "07/18/2023 20:00:46 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-9000/scheduler.bin\n",
      "07/18/2023 20:00:46 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-9000/random_states_0.pkl\n",
      "07/18/2023 20:00:46 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-9000\n",
      "Steps:  60%|▌| 9000/15000 [57:24<19:26,  5.15it/s, lr=9.46e-6, step_loss=0.0039407/18/2023 20:00:46 - INFO - __main__ - train loss is 10.336040587746538\n",
      "Steps:  60%|▌| 9001/15000 [57:24<20:40,  4.84it/s, lr=9.46e-6, step_loss=0.0696]07/18/2023 20:00:47 - INFO - __main__ - train loss is 10.460464143776335\n",
      "Steps:  60%|█▏| 9002/15000 [57:24<20:19,  4.92it/s, lr=9.46e-6, step_loss=0.124]07/18/2023 20:00:47 - INFO - __main__ - train loss is 10.67430269124452\n",
      "Steps:  60%|█▏| 9003/15000 [57:25<19:57,  5.01it/s, lr=9.46e-6, step_loss=0.214]07/18/2023 20:00:47 - INFO - __main__ - train loss is 11.234941357397474\n",
      "Steps:  60%|█▏| 9004/15000 [57:25<19:49,  5.04it/s, lr=9.46e-6, step_loss=0.561]07/18/2023 20:00:47 - INFO - __main__ - train loss is 11.343242430710234\n",
      "Steps:  60%|█▏| 9005/15000 [57:25<19:44,  5.06it/s, lr=9.46e-6, step_loss=0.108]07/18/2023 20:00:47 - INFO - __main__ - train loss is 11.345304390997626\n",
      "Steps:  60%|▌| 9006/15000 [57:25<19:36,  5.09it/s, lr=9.46e-6, step_loss=0.0020607/18/2023 20:00:48 - INFO - __main__ - train loss is 11.455737492651679\n",
      "Steps:  60%|█▊ | 9007/15000 [57:25<19:32,  5.11it/s, lr=9.46e-6, step_loss=0.11]07/18/2023 20:00:48 - INFO - __main__ - train loss is 11.470535141066648\n",
      "Steps:  60%|▌| 9008/15000 [57:26<19:30,  5.12it/s, lr=9.46e-6, step_loss=0.0148]07/18/2023 20:00:48 - INFO - __main__ - train loss is 11.61092102213297\n",
      "Steps:  60%|█▊ | 9009/15000 [57:26<19:28,  5.12it/s, lr=9.46e-6, step_loss=0.14]07/18/2023 20:00:48 - INFO - __main__ - train loss is 11.678817537263967\n",
      "Steps:  60%|▌| 9010/15000 [57:26<19:27,  5.13it/s, lr=9.46e-6, step_loss=0.0679]07/18/2023 20:00:48 - INFO - __main__ - train loss is 11.68434265034739\n",
      "Steps:  60%|▌| 9011/15000 [57:26<19:27,  5.13it/s, lr=9.46e-6, step_loss=0.0055307/18/2023 20:00:49 - INFO - __main__ - train loss is 11.706320691504516\n",
      "Steps:  60%|█▏| 9012/15000 [57:26<19:27,  5.13it/s, lr=9.46e-6, step_loss=0.022]07/18/2023 20:00:49 - INFO - __main__ - train loss is 11.762423626729287\n",
      "Steps:  60%|▌| 9013/15000 [57:27<19:27,  5.13it/s, lr=9.46e-6, step_loss=0.0561]07/18/2023 20:00:49 - INFO - __main__ - train loss is 12.03091382200364\n",
      "Steps:  60%|█▏| 9014/15000 [57:27<19:26,  5.13it/s, lr=9.46e-6, step_loss=0.268]07/18/2023 20:00:49 - INFO - __main__ - train loss is 12.450170449563302\n",
      "Steps:  60%|█▏| 9015/15000 [57:27<19:24,  5.14it/s, lr=9.46e-6, step_loss=0.419]07/18/2023 20:00:49 - INFO - __main__ - train loss is 12.509469084092416\n",
      "Steps:  60%|▌| 9016/15000 [57:27<19:13,  5.19it/s, lr=9.46e-6, step_loss=0.0593]07/18/2023 20:00:49 - INFO - __main__ - train loss is 12.526410013088025\n",
      "Steps:  60%|▌| 9017/15000 [57:27<18:47,  5.31it/s, lr=9.46e-6, step_loss=0.0169]07/18/2023 20:00:50 - INFO - __main__ - train loss is 12.530318081495352\n",
      "Steps:  60%|▌| 9018/15000 [57:28<18:36,  5.36it/s, lr=9.45e-6, step_loss=0.0039107/18/2023 20:00:50 - INFO - __main__ - train loss is 12.690714657423086\n",
      "Steps:  60%|█▊ | 9019/15000 [57:28<18:31,  5.38it/s, lr=9.45e-6, step_loss=0.16]07/18/2023 20:00:50 - INFO - __main__ - train loss is 12.695702354540117\n",
      "Steps:  60%|▌| 9020/15000 [57:28<18:27,  5.40it/s, lr=9.45e-6, step_loss=0.0049907/18/2023 20:00:50 - INFO - __main__ - train loss is 12.828744481434114\n",
      "Steps:  60%|█▏| 9021/15000 [57:28<24:23,  4.08it/s, lr=9.45e-6, step_loss=0.133]07/18/2023 20:00:51 - INFO - __main__ - Per validation step average loss is 0.013510433956980705\n",
      "07/18/2023 20:00:51 - INFO - __main__ - Cumulative validation average loss is 0.013510433956980705\n",
      "07/18/2023 20:00:51 - INFO - __main__ - Per validation step average loss is 0.055816467851400375\n",
      "07/18/2023 20:00:51 - INFO - __main__ - Cumulative validation average loss is 0.06932690180838108\n",
      "07/18/2023 20:00:51 - INFO - __main__ - Per validation step average loss is 0.2472074180841446\n",
      "07/18/2023 20:00:51 - INFO - __main__ - Cumulative validation average loss is 0.3165343198925257\n",
      "07/18/2023 20:00:51 - INFO - __main__ - Per validation step average loss is 0.011131761595606804\n",
      "07/18/2023 20:00:51 - INFO - __main__ - Cumulative validation average loss is 0.3276660814881325\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Per validation step average loss is 0.2081776112318039\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Cumulative validation average loss is 0.5358436927199364\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Per validation step average loss is 0.1222599446773529\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Cumulative validation average loss is 0.6581036373972893\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Per validation step average loss is 0.11387715488672256\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Cumulative validation average loss is 0.7719807922840118\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Per validation step average loss is 0.04819972813129425\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Cumulative validation average loss is 0.8201805204153061\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Per validation step average loss is 0.007157293614000082\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Cumulative validation average loss is 0.8273378140293062\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Per validation step average loss is 0.011315640062093735\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Cumulative validation average loss is 0.8386534540913999\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Per validation step average loss is 0.06234755367040634\n",
      "07/18/2023 20:00:52 - INFO - __main__ - Cumulative validation average loss is 0.9010010077618062\n",
      "07/18/2023 20:00:53 - INFO - __main__ - Per validation step average loss is 0.264143168926239\n",
      "07/18/2023 20:00:53 - INFO - __main__ - Cumulative validation average loss is 1.1651441766880453\n",
      "07/18/2023 20:00:53 - INFO - __main__ - Average validation loss for Epoch 92 is 0.0970953480573371\n",
      "07/18/2023 20:00:53 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:01:06 - INFO - __main__ - Starting epoch 93\n",
      "07/18/2023 20:01:06 - INFO - __main__ - train loss is 0.029162026941776276\n",
      "Steps:  60%|▌| 9022/15000 [57:44<8:06:27,  4.88s/it, lr=9.45e-6, step_loss=0.02907/18/2023 20:01:06 - INFO - __main__ - train loss is 0.42516908794641495\n",
      "Steps:  60%|▌| 9023/15000 [57:44<5:45:57,  3.47s/it, lr=9.45e-6, step_loss=0.39607/18/2023 20:01:06 - INFO - __main__ - train loss is 0.4719727784395218\n",
      "Steps:  60%|▌| 9024/15000 [57:44<4:07:44,  2.49s/it, lr=9.45e-6, step_loss=0.04607/18/2023 20:01:07 - INFO - __main__ - train loss is 0.6553655415773392\n",
      "Steps:  60%|▌| 9025/15000 [57:45<2:59:04,  1.80s/it, lr=9.45e-6, step_loss=0.18307/18/2023 20:01:07 - INFO - __main__ - train loss is 0.7031518667936325\n",
      "Steps:  60%|▌| 9026/15000 [57:45<2:10:51,  1.31s/it, lr=9.45e-6, step_loss=0.04707/18/2023 20:01:07 - INFO - __main__ - train loss is 0.7081564753316343\n",
      "Steps:  60%|▌| 9027/15000 [57:45<1:37:06,  1.03it/s, lr=9.45e-6, step_loss=0.00507/18/2023 20:01:07 - INFO - __main__ - train loss is 0.7272661863826215\n",
      "Steps:  60%|▌| 9028/15000 [57:45<1:13:30,  1.35it/s, lr=9.45e-6, step_loss=0.01907/18/2023 20:01:07 - INFO - __main__ - train loss is 0.7414600369520485\n",
      "Steps:  60%|▌| 9029/15000 [57:45<56:45,  1.75it/s, lr=9.45e-6, step_loss=0.0142]07/18/2023 20:01:08 - INFO - __main__ - train loss is 0.7682904885150492\n",
      "Steps:  60%|▌| 9030/15000 [57:45<45:02,  2.21it/s, lr=9.45e-6, step_loss=0.0268]07/18/2023 20:01:08 - INFO - __main__ - train loss is 0.7773153414018452\n",
      "Steps:  60%|▌| 9031/15000 [57:46<36:50,  2.70it/s, lr=9.45e-6, step_loss=0.0090207/18/2023 20:01:08 - INFO - __main__ - train loss is 0.7865020199678838\n",
      "Steps:  60%|▌| 9032/15000 [57:46<31:06,  3.20it/s, lr=9.45e-6, step_loss=0.0091907/18/2023 20:01:08 - INFO - __main__ - train loss is 0.8227349310182035\n",
      "Steps:  60%|▌| 9033/15000 [57:46<27:04,  3.67it/s, lr=9.45e-6, step_loss=0.0362]07/18/2023 20:01:08 - INFO - __main__ - train loss is 0.828185751568526\n",
      "Steps:  60%|▌| 9034/15000 [57:46<24:19,  4.09it/s, lr=9.45e-6, step_loss=0.0054507/18/2023 20:01:08 - INFO - __main__ - train loss is 0.8310931432060897\n",
      "Steps:  60%|▌| 9035/15000 [57:46<22:20,  4.45it/s, lr=9.45e-6, step_loss=0.0029107/18/2023 20:01:09 - INFO - __main__ - train loss is 0.8450859454460442\n",
      "Steps:  60%|█▏| 9036/15000 [57:47<20:57,  4.74it/s, lr=9.45e-6, step_loss=0.014]07/18/2023 20:01:09 - INFO - __main__ - train loss is 0.8476899771485478\n",
      "Steps:  60%|▌| 9037/15000 [57:47<19:58,  4.98it/s, lr=9.45e-6, step_loss=0.0026]07/18/2023 20:01:09 - INFO - __main__ - train loss is 0.9810756950173527\n",
      "Steps:  60%|█▏| 9038/15000 [57:47<19:17,  5.15it/s, lr=9.45e-6, step_loss=0.133]07/18/2023 20:01:09 - INFO - __main__ - train loss is 1.3279977946076542\n",
      "Steps:  60%|█▏| 9039/15000 [57:47<18:49,  5.28it/s, lr=9.45e-6, step_loss=0.347]07/18/2023 20:01:09 - INFO - __main__ - train loss is 1.6165696291718632\n",
      "Steps:  60%|█▏| 9040/15000 [57:47<18:29,  5.37it/s, lr=9.45e-6, step_loss=0.289]07/18/2023 20:01:10 - INFO - __main__ - train loss is 1.6397961175534874\n",
      "Steps:  60%|▌| 9041/15000 [57:47<18:16,  5.44it/s, lr=9.45e-6, step_loss=0.0232]07/18/2023 20:01:10 - INFO - __main__ - train loss is 2.1405046975705773\n",
      "Steps:  60%|█▏| 9042/15000 [57:48<18:06,  5.48it/s, lr=9.45e-6, step_loss=0.501]07/18/2023 20:01:10 - INFO - __main__ - train loss is 2.2218286565039307\n",
      "Steps:  60%|▌| 9043/15000 [57:48<17:59,  5.52it/s, lr=9.45e-6, step_loss=0.0813]07/18/2023 20:01:10 - INFO - __main__ - train loss is 3.073867397615686\n",
      "Steps:  60%|█▏| 9044/15000 [57:48<17:54,  5.54it/s, lr=9.45e-6, step_loss=0.852]07/18/2023 20:01:10 - INFO - __main__ - train loss is 3.0908124207053334\n",
      "Steps:  60%|▌| 9045/15000 [57:48<17:52,  5.55it/s, lr=9.45e-6, step_loss=0.0169]07/18/2023 20:01:10 - INFO - __main__ - train loss is 3.4676209448371083\n",
      "Steps:  60%|█▏| 9046/15000 [57:48<17:49,  5.56it/s, lr=9.45e-6, step_loss=0.377]07/18/2023 20:01:11 - INFO - __main__ - train loss is 3.502080718288198\n",
      "Steps:  60%|▌| 9047/15000 [57:49<17:49,  5.57it/s, lr=9.45e-6, step_loss=0.0345]07/18/2023 20:01:11 - INFO - __main__ - train loss is 3.5877863040659577\n",
      "Steps:  60%|▌| 9048/15000 [57:49<17:47,  5.58it/s, lr=9.45e-6, step_loss=0.0857]07/18/2023 20:01:11 - INFO - __main__ - train loss is 3.659592109033838\n",
      "Steps:  60%|▌| 9049/15000 [57:49<17:46,  5.58it/s, lr=9.45e-6, step_loss=0.0718]07/18/2023 20:01:11 - INFO - __main__ - train loss is 3.8289371153805405\n",
      "Steps:  60%|█▏| 9050/15000 [57:49<17:55,  5.53it/s, lr=9.45e-6, step_loss=0.169]07/18/2023 20:01:11 - INFO - __main__ - train loss is 3.831139227608219\n",
      "Steps:  60%|▌| 9051/15000 [57:49<18:01,  5.50it/s, lr=9.45e-6, step_loss=0.0022]07/18/2023 20:01:12 - INFO - __main__ - train loss is 3.8337669742759317\n",
      "Steps:  60%|▌| 9052/15000 [57:49<18:09,  5.46it/s, lr=9.45e-6, step_loss=0.0026307/18/2023 20:01:12 - INFO - __main__ - train loss is 3.8676677939947695\n",
      "Steps:  60%|▌| 9053/15000 [57:50<18:19,  5.41it/s, lr=9.45e-6, step_loss=0.0339]07/18/2023 20:01:12 - INFO - __main__ - train loss is 4.153583764797077\n",
      "Steps:  60%|█▏| 9054/15000 [57:50<18:16,  5.42it/s, lr=9.45e-6, step_loss=0.286]07/18/2023 20:01:12 - INFO - __main__ - train loss is 4.1648246922995895\n",
      "Steps:  60%|▌| 9055/15000 [57:50<18:05,  5.47it/s, lr=9.45e-6, step_loss=0.0112]07/18/2023 20:01:12 - INFO - __main__ - train loss is 4.1664141761139035\n",
      "Steps:  60%|▌| 9056/15000 [57:50<18:08,  5.46it/s, lr=9.45e-6, step_loss=0.0015907/18/2023 20:01:12 - INFO - __main__ - train loss is 4.167875176295638\n",
      "Steps:  60%|▌| 9057/15000 [57:50<18:03,  5.48it/s, lr=9.45e-6, step_loss=0.0014607/18/2023 20:01:13 - INFO - __main__ - train loss is 4.173314977437258\n",
      "Steps:  60%|▌| 9058/15000 [57:51<17:56,  5.52it/s, lr=9.45e-6, step_loss=0.0054407/18/2023 20:01:13 - INFO - __main__ - train loss is 4.342463944107294\n",
      "Steps:  60%|█▏| 9059/15000 [57:51<17:51,  5.54it/s, lr=9.45e-6, step_loss=0.169]07/18/2023 20:01:13 - INFO - __main__ - train loss is 4.395573068410158\n",
      "Steps:  60%|▌| 9060/15000 [57:51<17:47,  5.56it/s, lr=9.45e-6, step_loss=0.0531]07/18/2023 20:01:13 - INFO - __main__ - train loss is 4.669772434979677\n",
      "Steps:  60%|█▏| 9061/15000 [57:51<17:45,  5.57it/s, lr=9.45e-6, step_loss=0.274]07/18/2023 20:01:13 - INFO - __main__ - train loss is 4.836334232240915\n",
      "Steps:  60%|█▏| 9062/15000 [57:51<17:43,  5.58it/s, lr=9.45e-6, step_loss=0.167]07/18/2023 20:01:14 - INFO - __main__ - train loss is 5.269186142832041\n",
      "Steps:  60%|█▏| 9063/15000 [57:51<17:42,  5.59it/s, lr=9.45e-6, step_loss=0.433]07/18/2023 20:01:14 - INFO - __main__ - train loss is 5.666883949190378\n",
      "Steps:  60%|█▏| 9064/15000 [57:52<17:41,  5.59it/s, lr=9.45e-6, step_loss=0.398]07/18/2023 20:01:14 - INFO - __main__ - train loss is 5.685552570968866\n",
      "Steps:  60%|▌| 9065/15000 [57:52<17:40,  5.59it/s, lr=9.45e-6, step_loss=0.0187]07/18/2023 20:01:14 - INFO - __main__ - train loss is 5.770808178931475\n",
      "Steps:  60%|▌| 9066/15000 [57:52<17:40,  5.60it/s, lr=9.45e-6, step_loss=0.0853]07/18/2023 20:01:14 - INFO - __main__ - train loss is 5.98769049718976\n",
      "Steps:  60%|█▏| 9067/15000 [57:52<17:40,  5.60it/s, lr=9.45e-6, step_loss=0.217]07/18/2023 20:01:14 - INFO - __main__ - train loss is 6.012165084481239\n",
      "Steps:  60%|▌| 9068/15000 [57:52<17:40,  5.60it/s, lr=9.45e-6, step_loss=0.0245]07/18/2023 20:01:15 - INFO - __main__ - train loss is 6.034695969894528\n",
      "Steps:  60%|▌| 9069/15000 [57:52<17:39,  5.60it/s, lr=9.45e-6, step_loss=0.0225]07/18/2023 20:01:15 - INFO - __main__ - train loss is 6.179563777521253\n",
      "Steps:  60%|█▏| 9070/15000 [57:53<17:38,  5.60it/s, lr=9.45e-6, step_loss=0.145]07/18/2023 20:01:15 - INFO - __main__ - train loss is 6.273005457594991\n",
      "Steps:  60%|▌| 9071/15000 [57:53<17:38,  5.60it/s, lr=9.45e-6, step_loss=0.0934]07/18/2023 20:01:15 - INFO - __main__ - train loss is 6.367430130019784\n",
      "Steps:  60%|▌| 9072/15000 [57:53<17:38,  5.60it/s, lr=9.45e-6, step_loss=0.0944]07/18/2023 20:01:15 - INFO - __main__ - train loss is 6.517807165160775\n",
      "Steps:  60%|█▊ | 9073/15000 [57:53<17:38,  5.60it/s, lr=9.45e-6, step_loss=0.15]07/18/2023 20:01:15 - INFO - __main__ - train loss is 7.217703202739358\n",
      "Steps:  60%|██▍ | 9074/15000 [57:53<17:37,  5.60it/s, lr=9.45e-6, step_loss=0.7]07/18/2023 20:01:16 - INFO - __main__ - train loss is 7.226084721274674\n",
      "Steps:  60%|▌| 9075/15000 [57:54<17:39,  5.59it/s, lr=9.45e-6, step_loss=0.0083807/18/2023 20:01:16 - INFO - __main__ - train loss is 7.229945611208677\n",
      "Steps:  61%|▌| 9076/15000 [57:54<17:38,  5.59it/s, lr=9.45e-6, step_loss=0.0038607/18/2023 20:01:16 - INFO - __main__ - train loss is 7.250746671110392\n",
      "Steps:  61%|▌| 9077/15000 [57:54<17:38,  5.60it/s, lr=9.45e-6, step_loss=0.0208]07/18/2023 20:01:16 - INFO - __main__ - train loss is 7.416151080280542\n",
      "Steps:  61%|█▏| 9078/15000 [57:54<17:37,  5.60it/s, lr=9.45e-6, step_loss=0.165]07/18/2023 20:01:16 - INFO - __main__ - train loss is 7.695184502750635\n",
      "Steps:  61%|█▏| 9079/15000 [57:54<17:38,  5.59it/s, lr=9.45e-6, step_loss=0.279]07/18/2023 20:01:17 - INFO - __main__ - train loss is 7.696976898354478\n",
      "Steps:  61%|▌| 9080/15000 [57:54<17:39,  5.59it/s, lr=9.45e-6, step_loss=0.0017907/18/2023 20:01:17 - INFO - __main__ - train loss is 7.733785761636682\n",
      "Steps:  61%|▌| 9081/15000 [57:55<17:38,  5.59it/s, lr=9.45e-6, step_loss=0.0368]07/18/2023 20:01:17 - INFO - __main__ - train loss is 7.761292962473817\n",
      "Steps:  61%|▌| 9082/15000 [57:55<17:38,  5.59it/s, lr=9.45e-6, step_loss=0.0275]07/18/2023 20:01:17 - INFO - __main__ - train loss is 7.768287378014065\n",
      "Steps:  61%|▌| 9083/15000 [57:55<17:48,  5.54it/s, lr=9.45e-6, step_loss=0.0069907/18/2023 20:01:17 - INFO - __main__ - train loss is 7.7838756466517225\n",
      "Steps:  61%|▌| 9084/15000 [57:55<17:58,  5.49it/s, lr=9.45e-6, step_loss=0.0156]07/18/2023 20:01:17 - INFO - __main__ - train loss is 7.786037229816429\n",
      "Steps:  61%|▌| 9085/15000 [57:55<17:55,  5.50it/s, lr=9.45e-6, step_loss=0.0021607/18/2023 20:01:18 - INFO - __main__ - train loss is 7.86059723875951\n",
      "Steps:  61%|▌| 9086/15000 [57:56<17:50,  5.53it/s, lr=9.45e-6, step_loss=0.0746]07/18/2023 20:01:18 - INFO - __main__ - train loss is 7.972434417228214\n",
      "Steps:  61%|█▏| 9087/15000 [57:56<17:47,  5.54it/s, lr=9.45e-6, step_loss=0.112]07/18/2023 20:01:18 - INFO - __main__ - train loss is 8.26163990877103\n",
      "Steps:  61%|█▏| 9088/15000 [57:56<17:44,  5.55it/s, lr=9.45e-6, step_loss=0.289]07/18/2023 20:01:18 - INFO - __main__ - train loss is 8.268041413160972\n",
      "Steps:  61%|▌| 9089/15000 [57:56<17:52,  5.51it/s, lr=9.45e-6, step_loss=0.0064]07/18/2023 20:01:18 - INFO - __main__ - train loss is 8.690957825514488\n",
      "Steps:  61%|█▏| 9090/15000 [57:56<17:49,  5.53it/s, lr=9.45e-6, step_loss=0.423]07/18/2023 20:01:19 - INFO - __main__ - train loss is 8.693097866955213\n",
      "Steps:  61%|▌| 9091/15000 [57:56<17:45,  5.54it/s, lr=9.45e-6, step_loss=0.0021407/18/2023 20:01:19 - INFO - __main__ - train loss is 8.743210025015287\n",
      "Steps:  61%|▌| 9092/15000 [57:57<17:42,  5.56it/s, lr=9.45e-6, step_loss=0.0501]07/18/2023 20:01:19 - INFO - __main__ - train loss is 8.749262926052324\n",
      "Steps:  61%|▌| 9093/15000 [57:57<17:40,  5.57it/s, lr=9.45e-6, step_loss=0.0060507/18/2023 20:01:19 - INFO - __main__ - train loss is 9.090661880443804\n",
      "Steps:  61%|█▏| 9094/15000 [57:57<17:39,  5.58it/s, lr=9.45e-6, step_loss=0.341]07/18/2023 20:01:19 - INFO - __main__ - train loss is 9.297991839121096\n",
      "Steps:  61%|█▏| 9095/15000 [57:57<17:37,  5.58it/s, lr=9.45e-6, step_loss=0.207]07/18/2023 20:01:19 - INFO - __main__ - train loss is 9.430211600731127\n",
      "Steps:  61%|█▏| 9096/15000 [57:57<17:36,  5.59it/s, lr=9.45e-6, step_loss=0.132]07/18/2023 20:01:20 - INFO - __main__ - train loss is 9.433457487612031\n",
      "Steps:  61%|▌| 9097/15000 [57:58<17:36,  5.59it/s, lr=9.45e-6, step_loss=0.0032507/18/2023 20:01:20 - INFO - __main__ - train loss is 9.438896978623234\n",
      "Steps:  61%|▌| 9098/15000 [57:58<17:35,  5.59it/s, lr=9.45e-6, step_loss=0.0054407/18/2023 20:01:20 - INFO - __main__ - train loss is 9.605818460113369\n",
      "Steps:  61%|█▏| 9099/15000 [57:58<17:37,  5.58it/s, lr=9.45e-6, step_loss=0.167]07/18/2023 20:01:20 - INFO - __main__ - train loss is 9.782837609178387\n",
      "Steps:  61%|█▏| 9100/15000 [57:58<17:36,  5.58it/s, lr=9.45e-6, step_loss=0.177]07/18/2023 20:01:20 - INFO - __main__ - train loss is 9.809511961764656\n",
      "Steps:  61%|▌| 9101/15000 [57:58<17:41,  5.56it/s, lr=9.45e-6, step_loss=0.0267]07/18/2023 20:01:21 - INFO - __main__ - train loss is 9.814554834156297\n",
      "Steps:  61%|▌| 9102/15000 [57:58<17:45,  5.53it/s, lr=9.44e-6, step_loss=0.0050407/18/2023 20:01:21 - INFO - __main__ - train loss is 9.838934331550263\n",
      "Steps:  61%|▌| 9103/15000 [57:59<17:41,  5.56it/s, lr=9.44e-6, step_loss=0.0244]07/18/2023 20:01:21 - INFO - __main__ - train loss is 9.865784737630747\n",
      "Steps:  61%|▌| 9104/15000 [57:59<17:37,  5.57it/s, lr=9.44e-6, step_loss=0.0269]07/18/2023 20:01:21 - INFO - __main__ - train loss is 10.575104805990122\n",
      "Steps:  61%|█▏| 9105/15000 [57:59<17:36,  5.58it/s, lr=9.44e-6, step_loss=0.709]07/18/2023 20:01:21 - INFO - __main__ - train loss is 10.582850848673843\n",
      "Steps:  61%|▌| 9106/15000 [57:59<17:35,  5.58it/s, lr=9.44e-6, step_loss=0.0077507/18/2023 20:01:21 - INFO - __main__ - train loss is 10.616996703087352\n",
      "Steps:  61%|▌| 9107/15000 [57:59<17:34,  5.59it/s, lr=9.44e-6, step_loss=0.0341]07/18/2023 20:01:22 - INFO - __main__ - train loss is 10.788826582371257\n",
      "Steps:  61%|█▏| 9108/15000 [57:59<17:43,  5.54it/s, lr=9.44e-6, step_loss=0.172]07/18/2023 20:01:22 - INFO - __main__ - train loss is 10.830409751622938\n",
      "Steps:  61%|▌| 9109/15000 [58:00<17:49,  5.51it/s, lr=9.44e-6, step_loss=0.0416]07/18/2023 20:01:22 - INFO - __main__ - train loss is 10.864400097518228\n",
      "Steps:  61%|█▏| 9110/15000 [58:00<17:43,  5.54it/s, lr=9.44e-6, step_loss=0.034]07/18/2023 20:01:22 - INFO - __main__ - train loss is 10.878692563041113\n",
      "Steps:  61%|▌| 9111/15000 [58:00<17:49,  5.51it/s, lr=9.44e-6, step_loss=0.0143]07/18/2023 20:01:22 - INFO - __main__ - train loss is 10.881773489410989\n",
      "Steps:  61%|▌| 9112/15000 [58:00<17:51,  5.50it/s, lr=9.44e-6, step_loss=0.0030807/18/2023 20:01:23 - INFO - __main__ - train loss is 10.928611445124261\n",
      "Steps:  61%|▌| 9113/15000 [58:00<17:44,  5.53it/s, lr=9.44e-6, step_loss=0.0468]07/18/2023 20:01:23 - INFO - __main__ - train loss is 11.507509636576287\n",
      "Steps:  61%|█▏| 9114/15000 [58:01<17:40,  5.55it/s, lr=9.44e-6, step_loss=0.579]07/18/2023 20:01:23 - INFO - __main__ - train loss is 11.995392548735254\n",
      "Steps:  61%|█▏| 9115/15000 [58:01<17:36,  5.57it/s, lr=9.44e-6, step_loss=0.488]07/18/2023 20:01:23 - INFO - __main__ - train loss is 12.299743222887628\n",
      "Steps:  61%|█▏| 9116/15000 [58:01<17:34,  5.58it/s, lr=9.44e-6, step_loss=0.304]07/18/2023 20:01:23 - INFO - __main__ - train loss is 12.371490876073949\n",
      "Steps:  61%|▌| 9117/15000 [58:01<17:32,  5.59it/s, lr=9.44e-6, step_loss=0.0717]07/18/2023 20:01:24 - INFO - __main__ - train loss is 12.388182037393562\n",
      "Steps:  61%|▌| 9118/15000 [58:02<24:09,  4.06it/s, lr=9.44e-6, step_loss=0.0167]07/18/2023 20:01:24 - INFO - __main__ - Per validation step average loss is 0.0543748214840889\n",
      "07/18/2023 20:01:24 - INFO - __main__ - Cumulative validation average loss is 0.0543748214840889\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Per validation step average loss is 0.8044049739837646\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Cumulative validation average loss is 0.8587797954678535\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Per validation step average loss is 0.025906652212142944\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Cumulative validation average loss is 0.8846864476799965\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Per validation step average loss is 0.2693685293197632\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Cumulative validation average loss is 1.1540549769997597\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Per validation step average loss is 0.08680686354637146\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Cumulative validation average loss is 1.2408618405461311\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Per validation step average loss is 0.023986823856830597\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Cumulative validation average loss is 1.2648486644029617\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Per validation step average loss is 0.05020943284034729\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Cumulative validation average loss is 1.315058097243309\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Per validation step average loss is 0.28618407249450684\n",
      "07/18/2023 20:01:25 - INFO - __main__ - Cumulative validation average loss is 1.6012421697378159\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Per validation step average loss is 0.3033917546272278\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Cumulative validation average loss is 1.9046339243650436\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Per validation step average loss is 0.19996479153633118\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Cumulative validation average loss is 2.104598715901375\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Per validation step average loss is 0.0030605471692979336\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Cumulative validation average loss is 2.1076592630706728\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Per validation step average loss is 0.11647696048021317\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Cumulative validation average loss is 2.224136223550886\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Average validation loss for Epoch 93 is 0.18534468529590717\n",
      "07/18/2023 20:01:26 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:01:39 - INFO - __main__ - Starting epoch 94\n",
      "07/18/2023 20:01:39 - INFO - __main__ - train loss is 0.01881127990782261\n",
      "Steps:  61%|▌| 9119/15000 [58:17<8:02:33,  4.92s/it, lr=9.44e-6, step_loss=0.01807/18/2023 20:01:40 - INFO - __main__ - train loss is 0.15341308154165745\n",
      "Steps:  61%|▌| 9120/15000 [58:18<5:43:02,  3.50s/it, lr=9.44e-6, step_loss=0.13507/18/2023 20:01:40 - INFO - __main__ - train loss is 0.45946975983679295\n",
      "Steps:  61%|▌| 9121/15000 [58:18<4:05:29,  2.51s/it, lr=9.44e-6, step_loss=0.30607/18/2023 20:01:40 - INFO - __main__ - train loss is 0.46171894343569875\n",
      "Steps:  61%|▌| 9122/15000 [58:18<2:57:20,  1.81s/it, lr=9.44e-6, step_loss=0.00207/18/2023 20:01:40 - INFO - __main__ - train loss is 0.4643473783507943\n",
      "Steps:  61%|▌| 9123/15000 [58:18<2:09:33,  1.32s/it, lr=9.44e-6, step_loss=0.00207/18/2023 20:01:40 - INFO - __main__ - train loss is 0.5291499877348542\n",
      "Steps:  61%|▌| 9124/15000 [58:18<1:35:59,  1.02it/s, lr=9.44e-6, step_loss=0.06407/18/2023 20:01:41 - INFO - __main__ - train loss is 0.5939519936218858\n",
      "Steps:  61%|▌| 9125/15000 [58:18<1:12:24,  1.35it/s, lr=9.44e-6, step_loss=0.06407/18/2023 20:01:41 - INFO - __main__ - train loss is 0.6052670041099191\n",
      "Steps:  61%|▌| 9126/15000 [58:19<56:04,  1.75it/s, lr=9.44e-6, step_loss=0.0113]07/18/2023 20:01:41 - INFO - __main__ - train loss is 0.6504206517711282\n",
      "Steps:  61%|▌| 9127/15000 [58:19<44:28,  2.20it/s, lr=9.44e-6, step_loss=0.0452]07/18/2023 20:01:41 - INFO - __main__ - train loss is 0.7034874418750405\n",
      "Steps:  61%|▌| 9128/15000 [58:19<36:21,  2.69it/s, lr=9.44e-6, step_loss=0.0531]07/18/2023 20:01:41 - INFO - __main__ - train loss is 1.1979473689571023\n",
      "Steps:  61%|█▏| 9129/15000 [58:19<30:47,  3.18it/s, lr=9.44e-6, step_loss=0.494]07/18/2023 20:01:41 - INFO - __main__ - train loss is 1.2123410664498806\n",
      "Steps:  61%|▌| 9130/15000 [58:19<26:58,  3.63it/s, lr=9.44e-6, step_loss=0.0144]07/18/2023 20:01:42 - INFO - __main__ - train loss is 1.280542228370905\n",
      "Steps:  61%|▌| 9131/15000 [58:20<24:25,  4.01it/s, lr=9.44e-6, step_loss=0.0682]07/18/2023 20:01:42 - INFO - __main__ - train loss is 1.3046586699783802\n",
      "Steps:  61%|▌| 9132/15000 [58:20<22:47,  4.29it/s, lr=9.44e-6, step_loss=0.0241]07/18/2023 20:01:42 - INFO - __main__ - train loss is 1.4773126281797886\n",
      "Steps:  61%|█▏| 9133/15000 [58:20<21:38,  4.52it/s, lr=9.44e-6, step_loss=0.173]07/18/2023 20:01:42 - INFO - __main__ - train loss is 1.9658955372869968\n",
      "Steps:  61%|█▏| 9134/15000 [58:20<20:49,  4.69it/s, lr=9.44e-6, step_loss=0.489]07/18/2023 20:01:42 - INFO - __main__ - train loss is 2.1633703745901585\n",
      "Steps:  61%|█▏| 9135/15000 [58:20<20:14,  4.83it/s, lr=9.44e-6, step_loss=0.197]07/18/2023 20:01:43 - INFO - __main__ - train loss is 2.1661037537269294\n",
      "Steps:  61%|▌| 9136/15000 [58:21<19:53,  4.92it/s, lr=9.44e-6, step_loss=0.0027307/18/2023 20:01:43 - INFO - __main__ - train loss is 2.2266130852513015\n",
      "Steps:  61%|▌| 9137/15000 [58:21<19:35,  4.99it/s, lr=9.44e-6, step_loss=0.0605]07/18/2023 20:01:43 - INFO - __main__ - train loss is 2.279626216273755\n",
      "Steps:  61%|█▏| 9138/15000 [58:21<19:21,  5.05it/s, lr=9.44e-6, step_loss=0.053]07/18/2023 20:01:43 - INFO - __main__ - train loss is 2.2868786584585905\n",
      "Steps:  61%|▌| 9139/15000 [58:21<19:13,  5.08it/s, lr=9.44e-6, step_loss=0.0072507/18/2023 20:01:43 - INFO - __main__ - train loss is 2.3055296950042248\n",
      "Steps:  61%|▌| 9140/15000 [58:21<19:07,  5.11it/s, lr=9.44e-6, step_loss=0.0187]07/18/2023 20:01:44 - INFO - __main__ - train loss is 2.8157021813094616\n",
      "Steps:  61%|█▊ | 9141/15000 [58:21<19:07,  5.10it/s, lr=9.44e-6, step_loss=0.51]07/18/2023 20:01:44 - INFO - __main__ - train loss is 2.8558926060795784\n",
      "Steps:  61%|▌| 9142/15000 [58:22<19:08,  5.10it/s, lr=9.44e-6, step_loss=0.0402]07/18/2023 20:01:44 - INFO - __main__ - train loss is 3.071603484451771\n",
      "Steps:  61%|█▏| 9143/15000 [58:22<19:04,  5.12it/s, lr=9.44e-6, step_loss=0.216]07/18/2023 20:01:44 - INFO - __main__ - train loss is 3.253186784684658\n",
      "Steps:  61%|█▏| 9144/15000 [58:22<19:01,  5.13it/s, lr=9.44e-6, step_loss=0.182]07/18/2023 20:01:44 - INFO - __main__ - train loss is 3.3453796952962875\n",
      "Steps:  61%|▌| 9145/15000 [58:22<19:01,  5.13it/s, lr=9.44e-6, step_loss=0.0922]07/18/2023 20:01:45 - INFO - __main__ - train loss is 3.348208841169253\n",
      "Steps:  61%|▌| 9146/15000 [58:22<18:57,  5.15it/s, lr=9.44e-6, step_loss=0.0028307/18/2023 20:01:45 - INFO - __main__ - train loss is 4.00546270259656\n",
      "Steps:  61%|█▏| 9147/15000 [58:23<18:56,  5.15it/s, lr=9.44e-6, step_loss=0.657]07/18/2023 20:01:45 - INFO - __main__ - train loss is 4.647933300817385\n",
      "Steps:  61%|█▏| 9148/15000 [58:23<18:56,  5.15it/s, lr=9.44e-6, step_loss=0.642]07/18/2023 20:01:45 - INFO - __main__ - train loss is 4.80195364006795\n",
      "Steps:  61%|█▏| 9149/15000 [58:23<18:47,  5.19it/s, lr=9.44e-6, step_loss=0.154]07/18/2023 20:01:45 - INFO - __main__ - train loss is 4.80378311208915\n",
      "Steps:  61%|▌| 9150/15000 [58:23<19:06,  5.10it/s, lr=9.44e-6, step_loss=0.0018307/18/2023 20:01:46 - INFO - __main__ - train loss is 4.963482552091591\n",
      "Steps:  61%|█▊ | 9151/15000 [58:23<19:03,  5.11it/s, lr=9.44e-6, step_loss=0.16]07/18/2023 20:01:46 - INFO - __main__ - train loss is 5.011149910162203\n",
      "Steps:  61%|▌| 9152/15000 [58:24<19:02,  5.12it/s, lr=9.44e-6, step_loss=0.0477]07/18/2023 20:01:46 - INFO - __main__ - train loss is 5.125354905496351\n",
      "Steps:  61%|█▏| 9153/15000 [58:24<19:00,  5.13it/s, lr=9.44e-6, step_loss=0.114]07/18/2023 20:01:46 - INFO - __main__ - train loss is 5.379764904151671\n",
      "Steps:  61%|█▏| 9154/15000 [58:24<18:59,  5.13it/s, lr=9.44e-6, step_loss=0.254]07/18/2023 20:01:46 - INFO - __main__ - train loss is 5.38145597698167\n",
      "Steps:  61%|▌| 9155/15000 [58:24<18:57,  5.14it/s, lr=9.44e-6, step_loss=0.0016907/18/2023 20:01:47 - INFO - __main__ - train loss is 5.386385375633836\n",
      "Steps:  61%|▌| 9156/15000 [58:24<18:59,  5.13it/s, lr=9.44e-6, step_loss=0.0049307/18/2023 20:01:47 - INFO - __main__ - train loss is 5.406486138701439\n",
      "Steps:  61%|▌| 9157/15000 [58:25<18:59,  5.13it/s, lr=9.44e-6, step_loss=0.0201]07/18/2023 20:01:47 - INFO - __main__ - train loss is 5.6173611879348755\n",
      "Steps:  61%|█▏| 9158/15000 [58:25<18:56,  5.14it/s, lr=9.44e-6, step_loss=0.211]07/18/2023 20:01:47 - INFO - __main__ - train loss is 6.449533820152283\n",
      "Steps:  61%|█▏| 9159/15000 [58:25<18:57,  5.13it/s, lr=9.44e-6, step_loss=0.832]07/18/2023 20:01:47 - INFO - __main__ - train loss is 6.4522063778713346\n",
      "Steps:  61%|▌| 9160/15000 [58:25<18:56,  5.14it/s, lr=9.44e-6, step_loss=0.0026707/18/2023 20:01:47 - INFO - __main__ - train loss is 6.736164127476513\n",
      "Steps:  61%|█▏| 9161/15000 [58:25<18:56,  5.14it/s, lr=9.44e-6, step_loss=0.284]07/18/2023 20:01:48 - INFO - __main__ - train loss is 6.751234441064298\n",
      "Steps:  61%|▌| 9162/15000 [58:26<18:53,  5.15it/s, lr=9.44e-6, step_loss=0.0151]07/18/2023 20:01:48 - INFO - __main__ - train loss is 6.752939169644378\n",
      "Steps:  61%|▌| 9163/15000 [58:26<18:53,  5.15it/s, lr=9.44e-6, step_loss=0.0017]07/18/2023 20:01:48 - INFO - __main__ - train loss is 7.081382994889282\n",
      "Steps:  61%|█▏| 9164/15000 [58:26<18:53,  5.15it/s, lr=9.44e-6, step_loss=0.328]07/18/2023 20:01:48 - INFO - __main__ - train loss is 7.131633763550781\n",
      "Steps:  61%|▌| 9165/15000 [58:26<18:52,  5.15it/s, lr=9.44e-6, step_loss=0.0503]07/18/2023 20:01:48 - INFO - __main__ - train loss is 8.060891156434081\n",
      "Steps:  61%|█▏| 9166/15000 [58:26<18:54,  5.14it/s, lr=9.44e-6, step_loss=0.929]07/18/2023 20:01:49 - INFO - __main__ - train loss is 8.219626461504959\n",
      "Steps:  61%|█▏| 9167/15000 [58:27<18:54,  5.14it/s, lr=9.44e-6, step_loss=0.159]07/18/2023 20:01:49 - INFO - __main__ - train loss is 8.22594257898163\n",
      "Steps:  61%|▌| 9168/15000 [58:27<18:57,  5.13it/s, lr=9.44e-6, step_loss=0.0063207/18/2023 20:01:49 - INFO - __main__ - train loss is 8.470355001161806\n",
      "Steps:  61%|█▏| 9169/15000 [58:27<18:47,  5.17it/s, lr=9.44e-6, step_loss=0.244]07/18/2023 20:01:49 - INFO - __main__ - train loss is 8.477116047288291\n",
      "Steps:  61%|▌| 9170/15000 [58:27<18:22,  5.29it/s, lr=9.44e-6, step_loss=0.0067607/18/2023 20:01:49 - INFO - __main__ - train loss is 8.58062617375981\n",
      "Steps:  61%|█▏| 9171/15000 [58:27<18:03,  5.38it/s, lr=9.44e-6, step_loss=0.104]07/18/2023 20:01:50 - INFO - __main__ - train loss is 8.583590709953569\n",
      "Steps:  61%|▌| 9172/15000 [58:27<17:50,  5.44it/s, lr=9.44e-6, step_loss=0.0029607/18/2023 20:01:50 - INFO - __main__ - train loss is 8.79876274743583\n",
      "Steps:  61%|█▏| 9173/15000 [58:28<17:40,  5.49it/s, lr=9.44e-6, step_loss=0.215]07/18/2023 20:01:50 - INFO - __main__ - train loss is 9.246881702332757\n",
      "Steps:  61%|█▏| 9174/15000 [58:28<17:34,  5.53it/s, lr=9.44e-6, step_loss=0.448]07/18/2023 20:01:50 - INFO - __main__ - train loss is 9.709670105366968\n",
      "Steps:  61%|█▏| 9175/15000 [58:28<17:30,  5.54it/s, lr=9.44e-6, step_loss=0.463]07/18/2023 20:01:50 - INFO - __main__ - train loss is 9.914005169062875\n",
      "Steps:  61%|█▏| 9176/15000 [58:28<17:27,  5.56it/s, lr=9.44e-6, step_loss=0.204]07/18/2023 20:01:50 - INFO - __main__ - train loss is 10.27178646007087\n",
      "Steps:  61%|█▏| 9177/15000 [58:28<17:26,  5.57it/s, lr=9.44e-6, step_loss=0.358]07/18/2023 20:01:51 - INFO - __main__ - train loss is 10.347872504382394\n",
      "Steps:  61%|▌| 9178/15000 [58:29<17:24,  5.58it/s, lr=9.44e-6, step_loss=0.0761]07/18/2023 20:01:51 - INFO - __main__ - train loss is 10.581949436455034\n",
      "Steps:  61%|█▏| 9179/15000 [58:29<17:22,  5.58it/s, lr=9.44e-6, step_loss=0.234]07/18/2023 20:01:51 - INFO - __main__ - train loss is 10.659024709253572\n",
      "Steps:  61%|▌| 9180/15000 [58:29<17:21,  5.59it/s, lr=9.44e-6, step_loss=0.0771]07/18/2023 20:01:51 - INFO - __main__ - train loss is 10.882615098147653\n",
      "Steps:  61%|█▏| 9181/15000 [58:29<17:20,  5.59it/s, lr=9.44e-6, step_loss=0.224]07/18/2023 20:01:51 - INFO - __main__ - train loss is 10.942208187072538\n",
      "Steps:  61%|▌| 9182/15000 [58:29<17:19,  5.60it/s, lr=9.44e-6, step_loss=0.0596]07/18/2023 20:01:52 - INFO - __main__ - train loss is 11.14524971076753\n",
      "Steps:  61%|█▏| 9183/15000 [58:29<17:18,  5.60it/s, lr=9.44e-6, step_loss=0.203]07/18/2023 20:01:52 - INFO - __main__ - train loss is 11.157968958257698\n",
      "Steps:  61%|▌| 9184/15000 [58:30<17:18,  5.60it/s, lr=9.44e-6, step_loss=0.0127]07/18/2023 20:01:52 - INFO - __main__ - train loss is 11.164043834782206\n",
      "Steps:  61%|▌| 9185/15000 [58:30<17:17,  5.60it/s, lr=9.43e-6, step_loss=0.0060707/18/2023 20:01:52 - INFO - __main__ - train loss is 11.170814343146048\n",
      "Steps:  61%|▌| 9186/15000 [58:30<17:16,  5.61it/s, lr=9.43e-6, step_loss=0.0067707/18/2023 20:01:52 - INFO - __main__ - train loss is 11.76222593372222\n",
      "Steps:  61%|█▏| 9187/15000 [58:30<17:16,  5.61it/s, lr=9.43e-6, step_loss=0.591]07/18/2023 20:01:52 - INFO - __main__ - train loss is 11.772575837909244\n",
      "Steps:  61%|▌| 9188/15000 [58:30<17:16,  5.61it/s, lr=9.43e-6, step_loss=0.0103]07/18/2023 20:01:53 - INFO - __main__ - train loss is 11.780642631812952\n",
      "Steps:  61%|▌| 9189/15000 [58:30<17:21,  5.58it/s, lr=9.43e-6, step_loss=0.0080707/18/2023 20:01:53 - INFO - __main__ - train loss is 12.319586101337336\n",
      "Steps:  61%|█▏| 9190/15000 [58:31<17:29,  5.54it/s, lr=9.43e-6, step_loss=0.539]07/18/2023 20:01:53 - INFO - __main__ - train loss is 12.375998075469397\n",
      "Steps:  61%|▌| 9191/15000 [58:31<17:34,  5.51it/s, lr=9.43e-6, step_loss=0.0564]07/18/2023 20:01:53 - INFO - __main__ - train loss is 12.48724598006811\n",
      "Steps:  61%|█▏| 9192/15000 [58:31<17:32,  5.52it/s, lr=9.43e-6, step_loss=0.111]07/18/2023 20:01:53 - INFO - __main__ - train loss is 12.548019758774899\n",
      "Steps:  61%|▌| 9193/15000 [58:31<17:28,  5.54it/s, lr=9.43e-6, step_loss=0.0608]07/18/2023 20:01:54 - INFO - __main__ - train loss is 12.936742148711346\n",
      "Steps:  61%|█▏| 9194/15000 [58:31<17:34,  5.51it/s, lr=9.43e-6, step_loss=0.389]07/18/2023 20:01:54 - INFO - __main__ - train loss is 13.009577310993336\n",
      "Steps:  61%|▌| 9195/15000 [58:32<17:28,  5.53it/s, lr=9.43e-6, step_loss=0.0728]07/18/2023 20:01:54 - INFO - __main__ - train loss is 13.091293267323636\n",
      "Steps:  61%|▌| 9196/15000 [58:32<17:25,  5.55it/s, lr=9.43e-6, step_loss=0.0817]07/18/2023 20:01:54 - INFO - __main__ - train loss is 13.1804308736464\n",
      "Steps:  61%|▌| 9197/15000 [58:32<17:23,  5.56it/s, lr=9.43e-6, step_loss=0.0891]07/18/2023 20:01:54 - INFO - __main__ - train loss is 13.200116551830433\n",
      "Steps:  61%|▌| 9198/15000 [58:32<17:20,  5.58it/s, lr=9.43e-6, step_loss=0.0197]07/18/2023 20:01:54 - INFO - __main__ - train loss is 13.489810443832539\n",
      "Steps:  61%|█▊ | 9199/15000 [58:32<17:18,  5.59it/s, lr=9.43e-6, step_loss=0.29]07/18/2023 20:01:55 - INFO - __main__ - train loss is 13.491602827678435\n",
      "Steps:  61%|▌| 9200/15000 [58:32<17:15,  5.60it/s, lr=9.43e-6, step_loss=0.0017907/18/2023 20:01:55 - INFO - __main__ - train loss is 13.599772018264048\n",
      "Steps:  61%|█▏| 9201/15000 [58:33<17:14,  5.61it/s, lr=9.43e-6, step_loss=0.108]07/18/2023 20:01:55 - INFO - __main__ - train loss is 13.835825216840021\n",
      "Steps:  61%|█▏| 9202/15000 [58:33<17:13,  5.61it/s, lr=9.43e-6, step_loss=0.236]07/18/2023 20:01:55 - INFO - __main__ - train loss is 14.131394934724085\n",
      "Steps:  61%|█▏| 9203/15000 [58:33<17:14,  5.61it/s, lr=9.43e-6, step_loss=0.296]07/18/2023 20:01:55 - INFO - __main__ - train loss is 14.17874666757416\n",
      "Steps:  61%|▌| 9204/15000 [58:33<17:13,  5.61it/s, lr=9.43e-6, step_loss=0.0474]07/18/2023 20:01:55 - INFO - __main__ - train loss is 14.32945832319092\n",
      "Steps:  61%|█▏| 9205/15000 [58:33<17:13,  5.61it/s, lr=9.43e-6, step_loss=0.151]07/18/2023 20:01:56 - INFO - __main__ - train loss is 14.373502139816992\n",
      "Steps:  61%|█▏| 9206/15000 [58:34<17:22,  5.56it/s, lr=9.43e-6, step_loss=0.044]07/18/2023 20:01:56 - INFO - __main__ - train loss is 14.382932470995001\n",
      "Steps:  61%|▌| 9207/15000 [58:34<17:25,  5.54it/s, lr=9.43e-6, step_loss=0.0094307/18/2023 20:01:56 - INFO - __main__ - train loss is 14.386713732848875\n",
      "Steps:  61%|▌| 9208/15000 [58:34<17:29,  5.52it/s, lr=9.43e-6, step_loss=0.0037807/18/2023 20:01:56 - INFO - __main__ - train loss is 15.320640374789946\n",
      "Steps:  61%|█▏| 9209/15000 [58:34<17:30,  5.51it/s, lr=9.43e-6, step_loss=0.934]07/18/2023 20:01:56 - INFO - __main__ - train loss is 15.366527595440857\n",
      "Steps:  61%|▌| 9210/15000 [58:34<17:24,  5.54it/s, lr=9.43e-6, step_loss=0.0459]07/18/2023 20:01:57 - INFO - __main__ - train loss is 15.753455259720795\n",
      "Steps:  61%|█▏| 9211/15000 [58:34<17:20,  5.56it/s, lr=9.43e-6, step_loss=0.387]07/18/2023 20:01:57 - INFO - __main__ - train loss is 15.817821190576069\n",
      "Steps:  61%|▌| 9212/15000 [58:35<17:17,  5.58it/s, lr=9.43e-6, step_loss=0.0644]07/18/2023 20:01:57 - INFO - __main__ - train loss is 15.845516332308762\n",
      "Steps:  61%|▌| 9213/15000 [58:35<17:15,  5.59it/s, lr=9.43e-6, step_loss=0.0277]07/18/2023 20:01:57 - INFO - __main__ - train loss is 15.847509602899663\n",
      "Steps:  61%|▌| 9214/15000 [58:35<17:16,  5.58it/s, lr=9.43e-6, step_loss=0.0019907/18/2023 20:01:58 - INFO - __main__ - train loss is 16.214783768053167\n",
      "Steps:  61%|█▏| 9215/15000 [58:35<23:59,  4.02it/s, lr=9.43e-6, step_loss=0.367]07/18/2023 20:01:58 - INFO - __main__ - Per validation step average loss is 0.13518257439136505\n",
      "07/18/2023 20:01:58 - INFO - __main__ - Cumulative validation average loss is 0.13518257439136505\n",
      "07/18/2023 20:01:58 - INFO - __main__ - Per validation step average loss is 0.0034043597988784313\n",
      "07/18/2023 20:01:58 - INFO - __main__ - Cumulative validation average loss is 0.13858693419024348\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Per validation step average loss is 0.27945536375045776\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Cumulative validation average loss is 0.41804229794070125\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Per validation step average loss is 0.0026006484404206276\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Cumulative validation average loss is 0.4206429463811219\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Per validation step average loss is 0.006608105730265379\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Cumulative validation average loss is 0.42725105211138725\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Per validation step average loss is 0.0018009210471063852\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Cumulative validation average loss is 0.42905197315849364\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Per validation step average loss is 0.031498391181230545\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Cumulative validation average loss is 0.4605503643397242\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Per validation step average loss is 0.8429590463638306\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Cumulative validation average loss is 1.3035094107035547\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Per validation step average loss is 0.0825219452381134\n",
      "07/18/2023 20:01:59 - INFO - __main__ - Cumulative validation average loss is 1.3860313559416682\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Per validation step average loss is 0.002792993327602744\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Cumulative validation average loss is 1.388824349269271\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Per validation step average loss is 0.241637721657753\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Cumulative validation average loss is 1.6304620709270239\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Per validation step average loss is 0.33421748876571655\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Cumulative validation average loss is 1.9646795596927404\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Average validation loss for Epoch 94 is 0.1637232966410617\n",
      "07/18/2023 20:02:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:02:13 - INFO - __main__ - Starting epoch 95\n",
      "07/18/2023 20:02:13 - INFO - __main__ - train loss is 0.644284725189209\n",
      "Steps:  61%|▌| 9216/15000 [58:51<7:58:11,  4.96s/it, lr=9.43e-6, step_loss=0.64407/18/2023 20:02:14 - INFO - __main__ - train loss is 0.8922462463378906\n",
      "Steps:  61%|▌| 9217/15000 [58:52<5:39:55,  3.53s/it, lr=9.43e-6, step_loss=0.24807/18/2023 20:02:14 - INFO - __main__ - train loss is 0.893987022107467\n",
      "Steps:  61%|▌| 9218/15000 [58:52<4:03:06,  2.52s/it, lr=9.43e-6, step_loss=0.00107/18/2023 20:02:14 - INFO - __main__ - train loss is 0.9805726183112711\n",
      "Steps:  61%|▌| 9219/15000 [58:52<2:55:16,  1.82s/it, lr=9.43e-6, step_loss=0.08607/18/2023 20:02:14 - INFO - __main__ - train loss is 1.0117596311029047\n",
      "Steps:  61%|▌| 9220/15000 [58:52<2:07:48,  1.33s/it, lr=9.43e-6, step_loss=0.03107/18/2023 20:02:14 - INFO - __main__ - train loss is 1.0133812081767246\n",
      "Steps:  61%|▌| 9221/15000 [58:52<1:34:39,  1.02it/s, lr=9.43e-6, step_loss=0.00107/18/2023 20:02:15 - INFO - __main__ - train loss is 1.5330353629542515\n",
      "Steps:  61%|▌| 9222/15000 [58:52<1:11:22,  1.35it/s, lr=9.43e-6, step_loss=0.52]07/18/2023 20:02:15 - INFO - __main__ - train loss is 1.6046287071658298\n",
      "Steps:  61%|▌| 9223/15000 [58:53<55:04,  1.75it/s, lr=9.43e-6, step_loss=0.0716]07/18/2023 20:02:15 - INFO - __main__ - train loss is 1.6065937088569626\n",
      "Steps:  61%|▌| 9224/15000 [58:53<43:40,  2.20it/s, lr=9.43e-6, step_loss=0.0019707/18/2023 20:02:15 - INFO - __main__ - train loss is 2.139981131418608\n",
      "Steps:  62%|█▏| 9225/15000 [58:53<35:42,  2.70it/s, lr=9.43e-6, step_loss=0.533]07/18/2023 20:02:15 - INFO - __main__ - train loss is 2.205639730556868\n",
      "Steps:  62%|▌| 9226/15000 [58:53<30:06,  3.20it/s, lr=9.43e-6, step_loss=0.0657]07/18/2023 20:02:15 - INFO - __main__ - train loss is 2.356736700399779\n",
      "Steps:  62%|█▏| 9227/15000 [58:53<26:12,  3.67it/s, lr=9.43e-6, step_loss=0.151]07/18/2023 20:02:16 - INFO - __main__ - train loss is 2.4415832416852936\n",
      "Steps:  62%|▌| 9228/15000 [58:53<23:27,  4.10it/s, lr=9.43e-6, step_loss=0.0848]07/18/2023 20:02:16 - INFO - __main__ - train loss is 3.3933604614576325\n",
      "Steps:  62%|█▏| 9229/15000 [58:54<21:33,  4.46it/s, lr=9.43e-6, step_loss=0.952]07/18/2023 20:02:16 - INFO - __main__ - train loss is 3.566843475564383\n",
      "Steps:  62%|█▏| 9230/15000 [58:54<20:13,  4.76it/s, lr=9.43e-6, step_loss=0.173]07/18/2023 20:02:16 - INFO - __main__ - train loss is 3.6478805573424324\n",
      "Steps:  62%|█▏| 9231/15000 [58:54<19:19,  4.97it/s, lr=9.43e-6, step_loss=0.081]07/18/2023 20:02:16 - INFO - __main__ - train loss is 4.035630110069178\n",
      "Steps:  62%|█▏| 9232/15000 [58:54<19:34,  4.91it/s, lr=9.43e-6, step_loss=0.388]07/18/2023 20:02:17 - INFO - __main__ - train loss is 4.074541020556353\n",
      "Steps:  62%|▌| 9233/15000 [58:54<19:42,  4.88it/s, lr=9.43e-6, step_loss=0.0389]07/18/2023 20:02:17 - INFO - __main__ - train loss is 4.412690031691454\n",
      "Steps:  62%|█▏| 9234/15000 [58:55<19:27,  4.94it/s, lr=9.43e-6, step_loss=0.338]07/18/2023 20:02:17 - INFO - __main__ - train loss is 4.443859366117977\n",
      "Steps:  62%|▌| 9235/15000 [58:55<18:58,  5.06it/s, lr=9.43e-6, step_loss=0.0312]07/18/2023 20:02:17 - INFO - __main__ - train loss is 4.446599628892727\n",
      "Steps:  62%|▌| 9236/15000 [58:55<18:26,  5.21it/s, lr=9.43e-6, step_loss=0.0027407/18/2023 20:02:17 - INFO - __main__ - train loss is 4.461152719450183\n",
      "Steps:  62%|▌| 9237/15000 [58:55<18:04,  5.31it/s, lr=9.43e-6, step_loss=0.0146]07/18/2023 20:02:17 - INFO - __main__ - train loss is 4.830158161115833\n",
      "Steps:  62%|█▏| 9238/15000 [58:55<17:48,  5.39it/s, lr=9.43e-6, step_loss=0.369]07/18/2023 20:02:18 - INFO - __main__ - train loss is 4.967149214935489\n",
      "Steps:  62%|█▏| 9239/15000 [58:56<17:36,  5.45it/s, lr=9.43e-6, step_loss=0.137]07/18/2023 20:02:18 - INFO - __main__ - train loss is 4.973761159577407\n",
      "Steps:  62%|▌| 9240/15000 [58:56<17:28,  5.49it/s, lr=9.43e-6, step_loss=0.0066107/18/2023 20:02:18 - INFO - __main__ - train loss is 5.305747646489181\n",
      "Steps:  62%|█▏| 9241/15000 [58:56<17:21,  5.53it/s, lr=9.43e-6, step_loss=0.332]07/18/2023 20:02:18 - INFO - __main__ - train loss is 5.397889744141139\n",
      "Steps:  62%|▌| 9242/15000 [58:56<17:16,  5.55it/s, lr=9.43e-6, step_loss=0.0921]07/18/2023 20:02:18 - INFO - __main__ - train loss is 5.419756829389371\n",
      "Steps:  62%|▌| 9243/15000 [58:56<17:13,  5.57it/s, lr=9.43e-6, step_loss=0.0219]07/18/2023 20:02:19 - INFO - __main__ - train loss is 5.510098196216859\n",
      "Steps:  62%|▌| 9244/15000 [58:56<17:11,  5.58it/s, lr=9.43e-6, step_loss=0.0903]07/18/2023 20:02:19 - INFO - __main__ - train loss is 5.51699575514067\n",
      "Steps:  62%|▌| 9245/15000 [58:57<17:10,  5.58it/s, lr=9.43e-6, step_loss=0.0069]07/18/2023 20:02:19 - INFO - __main__ - train loss is 5.542595858802088\n",
      "Steps:  62%|▌| 9246/15000 [58:57<17:09,  5.59it/s, lr=9.43e-6, step_loss=0.0256]07/18/2023 20:02:19 - INFO - __main__ - train loss is 5.550429028575309\n",
      "Steps:  62%|▌| 9247/15000 [58:57<17:08,  5.60it/s, lr=9.43e-6, step_loss=0.0078307/18/2023 20:02:19 - INFO - __main__ - train loss is 5.5521674799965695\n",
      "Steps:  62%|▌| 9248/15000 [58:57<17:07,  5.60it/s, lr=9.43e-6, step_loss=0.0017407/18/2023 20:02:19 - INFO - __main__ - train loss is 5.935500805382617\n",
      "Steps:  62%|█▏| 9249/15000 [58:57<17:06,  5.60it/s, lr=9.43e-6, step_loss=0.383]07/18/2023 20:02:20 - INFO - __main__ - train loss is 6.014339317684062\n",
      "Steps:  62%|▌| 9250/15000 [58:58<17:06,  5.60it/s, lr=9.43e-6, step_loss=0.0788]07/18/2023 20:02:20 - INFO - __main__ - train loss is 6.126122010056861\n",
      "Steps:  62%|█▏| 9251/15000 [58:58<17:05,  5.61it/s, lr=9.43e-6, step_loss=0.112]07/18/2023 20:02:20 - INFO - __main__ - train loss is 6.144693770562299\n",
      "Steps:  62%|▌| 9252/15000 [58:58<17:05,  5.61it/s, lr=9.43e-6, step_loss=0.0186]07/18/2023 20:02:20 - INFO - __main__ - train loss is 6.171521297772415\n",
      "Steps:  62%|▌| 9253/15000 [58:58<17:06,  5.60it/s, lr=9.43e-6, step_loss=0.0268]07/18/2023 20:02:20 - INFO - __main__ - train loss is 6.22229050018359\n",
      "Steps:  62%|▌| 9254/15000 [58:58<17:05,  5.60it/s, lr=9.43e-6, step_loss=0.0508]07/18/2023 20:02:21 - INFO - __main__ - train loss is 6.304998471518047\n",
      "Steps:  62%|▌| 9255/15000 [58:58<17:04,  5.61it/s, lr=9.43e-6, step_loss=0.0827]07/18/2023 20:02:21 - INFO - __main__ - train loss is 6.410578950424679\n",
      "Steps:  62%|█▏| 9256/15000 [58:59<17:04,  5.61it/s, lr=9.43e-6, step_loss=0.106]07/18/2023 20:02:21 - INFO - __main__ - train loss is 6.41622768540401\n",
      "Steps:  62%|▌| 9257/15000 [58:59<17:04,  5.61it/s, lr=9.43e-6, step_loss=0.0056507/18/2023 20:02:21 - INFO - __main__ - train loss is 6.434960529324599\n",
      "Steps:  62%|▌| 9258/15000 [58:59<17:03,  5.61it/s, lr=9.43e-6, step_loss=0.0187]07/18/2023 20:02:21 - INFO - __main__ - train loss is 6.679671347257681\n",
      "Steps:  62%|█▏| 9259/15000 [58:59<17:03,  5.61it/s, lr=9.43e-6, step_loss=0.245]07/18/2023 20:02:21 - INFO - __main__ - train loss is 6.761034891125746\n",
      "Steps:  62%|▌| 9260/15000 [58:59<17:03,  5.61it/s, lr=9.43e-6, step_loss=0.0814]07/18/2023 20:02:22 - INFO - __main__ - train loss is 6.784951914218254\n",
      "Steps:  62%|▌| 9261/15000 [58:59<17:04,  5.60it/s, lr=9.43e-6, step_loss=0.0239]07/18/2023 20:02:22 - INFO - __main__ - train loss is 7.067438591388054\n",
      "Steps:  62%|█▏| 9262/15000 [59:00<17:04,  5.60it/s, lr=9.43e-6, step_loss=0.282]07/18/2023 20:02:22 - INFO - __main__ - train loss is 7.091289330390282\n",
      "Steps:  62%|▌| 9263/15000 [59:00<17:04,  5.60it/s, lr=9.43e-6, step_loss=0.0239]07/18/2023 20:02:22 - INFO - __main__ - train loss is 7.3056222387822345\n",
      "Steps:  62%|█▏| 9264/15000 [59:00<17:05,  5.59it/s, lr=9.43e-6, step_loss=0.214]07/18/2023 20:02:22 - INFO - __main__ - train loss is 7.368417438236065\n",
      "Steps:  62%|▌| 9265/15000 [59:00<17:05,  5.59it/s, lr=9.43e-6, step_loss=0.0628]07/18/2023 20:02:22 - INFO - __main__ - train loss is 7.455841776099987\n",
      "Steps:  62%|▌| 9266/15000 [59:00<17:05,  5.59it/s, lr=9.43e-6, step_loss=0.0874]07/18/2023 20:02:23 - INFO - __main__ - train loss is 7.477300614234991\n",
      "Steps:  62%|▌| 9267/15000 [59:01<17:05,  5.59it/s, lr=9.42e-6, step_loss=0.0215]07/18/2023 20:02:23 - INFO - __main__ - train loss is 7.616428643581457\n",
      "Steps:  62%|█▏| 9268/15000 [59:01<17:05,  5.59it/s, lr=9.42e-6, step_loss=0.139]07/18/2023 20:02:23 - INFO - __main__ - train loss is 8.000024587032385\n",
      "Steps:  62%|█▏| 9269/15000 [59:01<17:03,  5.60it/s, lr=9.42e-6, step_loss=0.384]07/18/2023 20:02:23 - INFO - __main__ - train loss is 8.40200755011756\n",
      "Steps:  62%|█▏| 9270/15000 [59:01<17:03,  5.60it/s, lr=9.42e-6, step_loss=0.402]07/18/2023 20:02:23 - INFO - __main__ - train loss is 8.406336561893113\n",
      "Steps:  62%|▌| 9271/15000 [59:01<17:03,  5.60it/s, lr=9.42e-6, step_loss=0.0043307/18/2023 20:02:24 - INFO - __main__ - train loss is 8.414186312933452\n",
      "Steps:  62%|▌| 9272/15000 [59:01<17:03,  5.60it/s, lr=9.42e-6, step_loss=0.0078507/18/2023 20:02:24 - INFO - __main__ - train loss is 8.41754718462471\n",
      "Steps:  62%|▌| 9273/15000 [59:02<17:03,  5.59it/s, lr=9.42e-6, step_loss=0.0033607/18/2023 20:02:24 - INFO - __main__ - train loss is 8.427646976546384\n",
      "Steps:  62%|▌| 9274/15000 [59:02<17:03,  5.60it/s, lr=9.42e-6, step_loss=0.0101]07/18/2023 20:02:24 - INFO - __main__ - train loss is 8.46406218840275\n",
      "Steps:  62%|▌| 9275/15000 [59:02<17:03,  5.60it/s, lr=9.42e-6, step_loss=0.0364]07/18/2023 20:02:24 - INFO - __main__ - train loss is 8.566940960125066\n",
      "Steps:  62%|█▏| 9276/15000 [59:02<17:02,  5.60it/s, lr=9.42e-6, step_loss=0.103]07/18/2023 20:02:24 - INFO - __main__ - train loss is 8.849798378185369\n",
      "Steps:  62%|█▏| 9277/15000 [59:02<17:12,  5.55it/s, lr=9.42e-6, step_loss=0.283]07/18/2023 20:02:25 - INFO - __main__ - train loss is 9.168306109146215\n",
      "Steps:  62%|█▏| 9278/15000 [59:03<17:08,  5.56it/s, lr=9.42e-6, step_loss=0.319]07/18/2023 20:02:25 - INFO - __main__ - train loss is 9.170807371963747\n",
      "Steps:  62%|▌| 9279/15000 [59:03<17:05,  5.58it/s, lr=9.42e-6, step_loss=0.0025]07/18/2023 20:02:25 - INFO - __main__ - train loss is 9.226004681666382\n",
      "Steps:  62%|▌| 9280/15000 [59:03<17:03,  5.59it/s, lr=9.42e-6, step_loss=0.0552]07/18/2023 20:02:25 - INFO - __main__ - train loss is 9.272608849336393\n",
      "Steps:  62%|▌| 9281/15000 [59:03<17:08,  5.56it/s, lr=9.42e-6, step_loss=0.0466]07/18/2023 20:02:25 - INFO - __main__ - train loss is 9.301040775259025\n",
      "Steps:  62%|▌| 9282/15000 [59:03<17:07,  5.56it/s, lr=9.42e-6, step_loss=0.0284]07/18/2023 20:02:26 - INFO - __main__ - train loss is 9.692192203481682\n",
      "Steps:  62%|█▏| 9283/15000 [59:03<17:13,  5.53it/s, lr=9.42e-6, step_loss=0.391]07/18/2023 20:02:26 - INFO - __main__ - train loss is 9.777868746896274\n",
      "Steps:  62%|▌| 9284/15000 [59:04<17:19,  5.50it/s, lr=9.42e-6, step_loss=0.0857]07/18/2023 20:02:26 - INFO - __main__ - train loss is 10.397401808877476\n",
      "Steps:  62%|█▊ | 9285/15000 [59:04<17:17,  5.51it/s, lr=9.42e-6, step_loss=0.62]07/18/2023 20:02:26 - INFO - __main__ - train loss is 10.412055575405248\n",
      "Steps:  62%|▌| 9286/15000 [59:04<17:17,  5.51it/s, lr=9.42e-6, step_loss=0.0147]07/18/2023 20:02:26 - INFO - __main__ - train loss is 10.632560693775304\n",
      "Steps:  62%|█▏| 9287/15000 [59:04<17:21,  5.48it/s, lr=9.42e-6, step_loss=0.221]07/18/2023 20:02:26 - INFO - __main__ - train loss is 10.861078881775029\n",
      "Steps:  62%|█▏| 9288/15000 [59:04<17:19,  5.49it/s, lr=9.42e-6, step_loss=0.229]07/18/2023 20:02:27 - INFO - __main__ - train loss is 11.226283722673543\n",
      "Steps:  62%|█▏| 9289/15000 [59:05<17:23,  5.47it/s, lr=9.42e-6, step_loss=0.365]07/18/2023 20:02:27 - INFO - __main__ - train loss is 11.473927998100407\n",
      "Steps:  62%|█▏| 9290/15000 [59:05<17:22,  5.48it/s, lr=9.42e-6, step_loss=0.248]07/18/2023 20:02:27 - INFO - __main__ - train loss is 11.974351191078313\n",
      "Steps:  62%|██▍ | 9291/15000 [59:05<17:17,  5.51it/s, lr=9.42e-6, step_loss=0.5]07/18/2023 20:02:27 - INFO - __main__ - train loss is 11.983174004708417\n",
      "Steps:  62%|▌| 9292/15000 [59:05<17:18,  5.49it/s, lr=9.42e-6, step_loss=0.0088207/18/2023 20:02:27 - INFO - __main__ - train loss is 12.069465004955418\n",
      "Steps:  62%|▌| 9293/15000 [59:05<17:18,  5.50it/s, lr=9.42e-6, step_loss=0.0863]07/18/2023 20:02:28 - INFO - __main__ - train loss is 12.220994615112431\n",
      "Steps:  62%|█▏| 9294/15000 [59:05<17:19,  5.49it/s, lr=9.42e-6, step_loss=0.152]07/18/2023 20:02:28 - INFO - __main__ - train loss is 12.307151937042363\n",
      "Steps:  62%|▌| 9295/15000 [59:06<17:22,  5.47it/s, lr=9.42e-6, step_loss=0.0862]07/18/2023 20:02:28 - INFO - __main__ - train loss is 12.784298204933293\n",
      "Steps:  62%|█▏| 9296/15000 [59:06<17:21,  5.48it/s, lr=9.42e-6, step_loss=0.477]07/18/2023 20:02:28 - INFO - __main__ - train loss is 12.819467329536565\n",
      "Steps:  62%|▌| 9297/15000 [59:06<17:13,  5.52it/s, lr=9.42e-6, step_loss=0.0352]07/18/2023 20:02:28 - INFO - __main__ - train loss is 12.823293297202326\n",
      "Steps:  62%|▌| 9298/15000 [59:06<17:08,  5.55it/s, lr=9.42e-6, step_loss=0.0038307/18/2023 20:02:28 - INFO - __main__ - train loss is 12.973384140641429\n",
      "Steps:  62%|█▊ | 9299/15000 [59:06<17:14,  5.51it/s, lr=9.42e-6, step_loss=0.15]07/18/2023 20:02:29 - INFO - __main__ - train loss is 12.987831350998022\n",
      "Steps:  62%|▌| 9300/15000 [59:07<17:21,  5.47it/s, lr=9.42e-6, step_loss=0.0144]07/18/2023 20:02:29 - INFO - __main__ - train loss is 12.993042667978443\n",
      "Steps:  62%|▌| 9301/15000 [59:07<17:17,  5.49it/s, lr=9.42e-6, step_loss=0.0052107/18/2023 20:02:29 - INFO - __main__ - train loss is 13.103800912969746\n",
      "Steps:  62%|█▏| 9302/15000 [59:07<17:20,  5.48it/s, lr=9.42e-6, step_loss=0.111]07/18/2023 20:02:29 - INFO - __main__ - train loss is 13.129520667367615\n",
      "Steps:  62%|▌| 9303/15000 [59:07<17:19,  5.48it/s, lr=9.42e-6, step_loss=0.0257]07/18/2023 20:02:29 - INFO - __main__ - train loss is 13.135901558795013\n",
      "Steps:  62%|▌| 9304/15000 [59:07<17:12,  5.52it/s, lr=9.42e-6, step_loss=0.0063807/18/2023 20:02:30 - INFO - __main__ - train loss is 13.161770665668882\n",
      "Steps:  62%|▌| 9305/15000 [59:07<17:06,  5.55it/s, lr=9.42e-6, step_loss=0.0259]07/18/2023 20:02:30 - INFO - __main__ - train loss is 13.431373202824034\n",
      "Steps:  62%|█▊ | 9306/15000 [59:08<17:12,  5.52it/s, lr=9.42e-6, step_loss=0.27]07/18/2023 20:02:30 - INFO - __main__ - train loss is 13.435225845430978\n",
      "Steps:  62%|▌| 9307/15000 [59:08<17:14,  5.50it/s, lr=9.42e-6, step_loss=0.0038507/18/2023 20:02:30 - INFO - __main__ - train loss is 13.69826829538215\n",
      "Steps:  62%|█▏| 9308/15000 [59:08<17:17,  5.49it/s, lr=9.42e-6, step_loss=0.263]07/18/2023 20:02:30 - INFO - __main__ - train loss is 13.69956681469921\n",
      "Steps:  62%|▌| 9309/15000 [59:08<17:14,  5.50it/s, lr=9.42e-6, step_loss=0.0013]07/18/2023 20:02:30 - INFO - __main__ - train loss is 13.83565111795906\n",
      "Steps:  62%|█▏| 9310/15000 [59:08<17:08,  5.53it/s, lr=9.42e-6, step_loss=0.136]07/18/2023 20:02:31 - INFO - __main__ - train loss is 14.27670650521759\n",
      "Steps:  62%|█▏| 9311/15000 [59:09<17:03,  5.56it/s, lr=9.42e-6, step_loss=0.441]07/18/2023 20:02:31 - INFO - __main__ - train loss is 14.280374533613212\n",
      "Steps:  62%|▌| 9312/15000 [59:09<23:24,  4.05it/s, lr=9.42e-6, step_loss=0.0036707/18/2023 20:02:32 - INFO - __main__ - Per validation step average loss is 0.3305256962776184\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Cumulative validation average loss is 0.3305256962776184\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Per validation step average loss is 0.39041370153427124\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Cumulative validation average loss is 0.7209393978118896\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Per validation step average loss is 0.03605274856090546\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Cumulative validation average loss is 0.7569921463727951\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Per validation step average loss is 0.010599169880151749\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Cumulative validation average loss is 0.7675913162529469\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Per validation step average loss is 0.3559356927871704\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Cumulative validation average loss is 1.1235270090401173\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Per validation step average loss is 0.05483419448137283\n",
      "07/18/2023 20:02:32 - INFO - __main__ - Cumulative validation average loss is 1.17836120352149\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Per validation step average loss is 0.27652400732040405\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Cumulative validation average loss is 1.4548852108418941\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Per validation step average loss is 0.5030155777931213\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Cumulative validation average loss is 1.9579007886350155\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Per validation step average loss is 0.9591611623764038\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Cumulative validation average loss is 2.9170619510114193\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Per validation step average loss is 0.0649854987859726\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Cumulative validation average loss is 2.982047449797392\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Per validation step average loss is 0.12399476766586304\n",
      "07/18/2023 20:02:33 - INFO - __main__ - Cumulative validation average loss is 3.106042217463255\n",
      "07/18/2023 20:02:34 - INFO - __main__ - Per validation step average loss is 0.05559398978948593\n",
      "07/18/2023 20:02:34 - INFO - __main__ - Cumulative validation average loss is 3.161636207252741\n",
      "07/18/2023 20:02:34 - INFO - __main__ - Average validation loss for Epoch 95 is 0.2634696839377284\n",
      "07/18/2023 20:02:34 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:02:46 - INFO - __main__ - Starting epoch 96\n",
      "07/18/2023 20:02:47 - INFO - __main__ - train loss is 0.05044994130730629\n",
      "Steps:  62%|▌| 9313/15000 [59:25<7:52:06,  4.98s/it, lr=9.42e-6, step_loss=0.05007/18/2023 20:02:47 - INFO - __main__ - train loss is 0.07901643589138985\n",
      "Steps:  62%|▌| 9314/15000 [59:25<5:35:56,  3.54s/it, lr=9.42e-6, step_loss=0.02807/18/2023 20:02:47 - INFO - __main__ - train loss is 0.41292162612080574\n",
      "Steps:  62%|▌| 9315/15000 [59:25<4:00:30,  2.54s/it, lr=9.42e-6, step_loss=0.33407/18/2023 20:02:48 - INFO - __main__ - train loss is 0.4161755545064807\n",
      "Steps:  62%|▌| 9316/15000 [59:26<2:53:49,  1.83s/it, lr=9.42e-6, step_loss=0.00307/18/2023 20:02:48 - INFO - __main__ - train loss is 0.4186850329861045\n",
      "Steps:  62%|▌| 9317/15000 [59:26<2:07:15,  1.34s/it, lr=9.42e-6, step_loss=0.00207/18/2023 20:02:48 - INFO - __main__ - train loss is 0.429565304890275\n",
      "Steps:  62%|▌| 9318/15000 [59:26<1:34:15,  1.00it/s, lr=9.42e-6, step_loss=0.01007/18/2023 20:02:48 - INFO - __main__ - train loss is 0.4411831684410572\n",
      "Steps:  62%|▌| 9319/15000 [59:26<1:11:07,  1.33it/s, lr=9.42e-6, step_loss=0.01107/18/2023 20:02:48 - INFO - __main__ - train loss is 0.45443973038345575\n",
      "Steps:  62%|▌| 9320/15000 [59:26<55:07,  1.72it/s, lr=9.42e-6, step_loss=0.0133]07/18/2023 20:02:49 - INFO - __main__ - train loss is 0.46102877566590905\n",
      "Steps:  62%|▌| 9321/15000 [59:26<44:04,  2.15it/s, lr=9.42e-6, step_loss=0.0065907/18/2023 20:02:49 - INFO - __main__ - train loss is 0.4705082937143743\n",
      "Steps:  62%|▌| 9322/15000 [59:27<36:20,  2.60it/s, lr=9.42e-6, step_loss=0.0094807/18/2023 20:02:49 - INFO - __main__ - train loss is 0.6656553312204778\n",
      "Steps:  62%|█▏| 9323/15000 [59:27<30:57,  3.06it/s, lr=9.42e-6, step_loss=0.195]07/18/2023 20:02:49 - INFO - __main__ - train loss is 0.6704030060209334\n",
      "Steps:  62%|▌| 9324/15000 [59:27<27:10,  3.48it/s, lr=9.42e-6, step_loss=0.0047507/18/2023 20:02:49 - INFO - __main__ - train loss is 1.5164141678251326\n",
      "Steps:  62%|█▏| 9325/15000 [59:27<24:31,  3.86it/s, lr=9.42e-6, step_loss=0.846]07/18/2023 20:02:50 - INFO - __main__ - train loss is 1.5205049575306475\n",
      "Steps:  62%|▌| 9326/15000 [59:27<22:42,  4.16it/s, lr=9.42e-6, step_loss=0.0040907/18/2023 20:02:50 - INFO - __main__ - train loss is 1.6281637162901461\n",
      "Steps:  62%|█▏| 9327/15000 [59:28<21:23,  4.42it/s, lr=9.42e-6, step_loss=0.108]07/18/2023 20:02:50 - INFO - __main__ - train loss is 1.6394741968251765\n",
      "Steps:  62%|▌| 9328/15000 [59:28<20:29,  4.61it/s, lr=9.42e-6, step_loss=0.0113]07/18/2023 20:02:50 - INFO - __main__ - train loss is 1.6416456480510533\n",
      "Steps:  62%|▌| 9329/15000 [59:28<19:55,  4.74it/s, lr=9.42e-6, step_loss=0.0021707/18/2023 20:02:50 - INFO - __main__ - train loss is 2.012250103522092\n",
      "Steps:  62%|█▏| 9330/15000 [59:28<19:26,  4.86it/s, lr=9.42e-6, step_loss=0.371]07/18/2023 20:02:51 - INFO - __main__ - train loss is 2.0147076318971813\n",
      "Steps:  62%|▌| 9331/15000 [59:28<18:44,  5.04it/s, lr=9.42e-6, step_loss=0.0024607/18/2023 20:02:51 - INFO - __main__ - train loss is 2.154616318177432\n",
      "Steps:  62%|█▊ | 9332/15000 [59:29<18:17,  5.16it/s, lr=9.42e-6, step_loss=0.14]07/18/2023 20:02:51 - INFO - __main__ - train loss is 2.1573099070228636\n",
      "Steps:  62%|▌| 9333/15000 [59:29<17:52,  5.29it/s, lr=9.42e-6, step_loss=0.0026907/18/2023 20:02:51 - INFO - __main__ - train loss is 2.1805334188975394\n",
      "Steps:  62%|▌| 9334/15000 [59:29<17:43,  5.33it/s, lr=9.42e-6, step_loss=0.0232]07/18/2023 20:02:51 - INFO - __main__ - train loss is 2.2678552218712866\n",
      "Steps:  62%|▌| 9335/15000 [59:29<17:28,  5.40it/s, lr=9.42e-6, step_loss=0.0873]07/18/2023 20:02:51 - INFO - __main__ - train loss is 2.3874993273057044\n",
      "Steps:  62%|█▊ | 9336/15000 [59:29<17:17,  5.46it/s, lr=9.42e-6, step_loss=0.12]07/18/2023 20:02:52 - INFO - __main__ - train loss is 2.986953551415354\n",
      "Steps:  62%|█▏| 9337/15000 [59:29<17:10,  5.50it/s, lr=9.42e-6, step_loss=0.599]07/18/2023 20:02:52 - INFO - __main__ - train loss is 2.9931012582965195\n",
      "Steps:  62%|▌| 9338/15000 [59:30<17:04,  5.52it/s, lr=9.42e-6, step_loss=0.0061507/18/2023 20:02:52 - INFO - __main__ - train loss is 3.3046046984381974\n",
      "Steps:  62%|█▏| 9339/15000 [59:30<17:01,  5.54it/s, lr=9.42e-6, step_loss=0.312]07/18/2023 20:02:52 - INFO - __main__ - train loss is 3.7416422558017075\n",
      "Steps:  62%|█▏| 9340/15000 [59:30<16:58,  5.56it/s, lr=9.42e-6, step_loss=0.437]07/18/2023 20:02:52 - INFO - __main__ - train loss is 3.8768694144673645\n",
      "Steps:  62%|█▏| 9341/15000 [59:30<16:55,  5.57it/s, lr=9.42e-6, step_loss=0.135]07/18/2023 20:02:52 - INFO - __main__ - train loss is 3.9283212241716683\n",
      "Steps:  62%|▌| 9342/15000 [59:30<16:53,  5.58it/s, lr=9.42e-6, step_loss=0.0515]07/18/2023 20:02:53 - INFO - __main__ - train loss is 4.136906873900443\n",
      "Steps:  62%|█▏| 9343/15000 [59:31<16:53,  5.58it/s, lr=9.42e-6, step_loss=0.209]07/18/2023 20:02:53 - INFO - __main__ - train loss is 4.2908703801222146\n",
      "Steps:  62%|█▏| 9344/15000 [59:31<16:54,  5.58it/s, lr=9.42e-6, step_loss=0.154]07/18/2023 20:02:53 - INFO - __main__ - train loss is 4.519371670205146\n",
      "Steps:  62%|█▏| 9345/15000 [59:31<16:52,  5.59it/s, lr=9.42e-6, step_loss=0.229]07/18/2023 20:02:53 - INFO - __main__ - train loss is 4.786450069863349\n",
      "Steps:  62%|█▏| 9346/15000 [59:31<16:51,  5.59it/s, lr=9.42e-6, step_loss=0.267]07/18/2023 20:02:53 - INFO - __main__ - train loss is 5.099683922249824\n",
      "Steps:  62%|█▏| 9347/15000 [59:31<16:50,  5.59it/s, lr=9.42e-6, step_loss=0.313]07/18/2023 20:02:54 - INFO - __main__ - train loss is 5.3363605556078255\n",
      "Steps:  62%|█▏| 9348/15000 [59:31<16:50,  5.59it/s, lr=9.42e-6, step_loss=0.237]07/18/2023 20:02:54 - INFO - __main__ - train loss is 5.348699901718646\n",
      "Steps:  62%|▌| 9349/15000 [59:32<16:50,  5.59it/s, lr=9.41e-6, step_loss=0.0123]07/18/2023 20:02:54 - INFO - __main__ - train loss is 5.4728420791216195\n",
      "Steps:  62%|█▏| 9350/15000 [59:32<16:49,  5.60it/s, lr=9.41e-6, step_loss=0.124]07/18/2023 20:02:54 - INFO - __main__ - train loss is 5.716010671574622\n",
      "Steps:  62%|█▏| 9351/15000 [59:32<16:49,  5.59it/s, lr=9.41e-6, step_loss=0.243]07/18/2023 20:02:54 - INFO - __main__ - train loss is 5.729146304074675\n",
      "Steps:  62%|▌| 9352/15000 [59:32<16:49,  5.60it/s, lr=9.41e-6, step_loss=0.0131]07/18/2023 20:02:54 - INFO - __main__ - train loss is 5.734108489472419\n",
      "Steps:  62%|▌| 9353/15000 [59:32<16:49,  5.59it/s, lr=9.41e-6, step_loss=0.0049607/18/2023 20:02:55 - INFO - __main__ - train loss is 6.356969636399299\n",
      "Steps:  62%|█▏| 9354/15000 [59:33<16:49,  5.59it/s, lr=9.41e-6, step_loss=0.623]07/18/2023 20:02:55 - INFO - __main__ - train loss is 6.383512992877513\n",
      "Steps:  62%|▌| 9355/15000 [59:33<16:49,  5.59it/s, lr=9.41e-6, step_loss=0.0265]07/18/2023 20:02:55 - INFO - __main__ - train loss is 6.387776916380972\n",
      "Steps:  62%|▌| 9356/15000 [59:33<16:49,  5.59it/s, lr=9.41e-6, step_loss=0.0042607/18/2023 20:02:55 - INFO - __main__ - train loss is 6.597521340008825\n",
      "Steps:  62%|█▊ | 9357/15000 [59:33<16:50,  5.59it/s, lr=9.41e-6, step_loss=0.21]07/18/2023 20:02:55 - INFO - __main__ - train loss is 6.668390905018896\n",
      "Steps:  62%|▌| 9358/15000 [59:33<17:59,  5.23it/s, lr=9.41e-6, step_loss=0.0709]07/18/2023 20:02:56 - INFO - __main__ - train loss is 6.688481607940048\n",
      "Steps:  62%|▌| 9359/15000 [59:33<18:31,  5.08it/s, lr=9.41e-6, step_loss=0.0201]07/18/2023 20:02:56 - INFO - __main__ - train loss is 6.708281976636499\n",
      "Steps:  62%|▌| 9360/15000 [59:34<18:46,  5.01it/s, lr=9.41e-6, step_loss=0.0198]07/18/2023 20:02:56 - INFO - __main__ - train loss is 6.823100214358419\n",
      "Steps:  62%|█▏| 9361/15000 [59:34<18:28,  5.09it/s, lr=9.41e-6, step_loss=0.115]07/18/2023 20:02:56 - INFO - __main__ - train loss is 6.8975632465444505\n",
      "Steps:  62%|▌| 9362/15000 [59:34<18:06,  5.19it/s, lr=9.41e-6, step_loss=0.0745]07/18/2023 20:02:56 - INFO - __main__ - train loss is 6.906910237390548\n",
      "Steps:  62%|▌| 9363/15000 [59:34<17:50,  5.26it/s, lr=9.41e-6, step_loss=0.0093507/18/2023 20:02:57 - INFO - __main__ - train loss is 7.0070680496282876\n",
      "Steps:  62%|██▍ | 9364/15000 [59:34<17:42,  5.30it/s, lr=9.41e-6, step_loss=0.1]07/18/2023 20:02:57 - INFO - __main__ - train loss is 7.5809686300344765\n",
      "Steps:  62%|█▏| 9365/15000 [59:35<17:37,  5.33it/s, lr=9.41e-6, step_loss=0.574]07/18/2023 20:02:57 - INFO - __main__ - train loss is 7.6791748446412385\n",
      "Steps:  62%|▌| 9366/15000 [59:35<17:21,  5.41it/s, lr=9.41e-6, step_loss=0.0982]07/18/2023 20:02:57 - INFO - __main__ - train loss is 7.942920450586826\n",
      "Steps:  62%|█▏| 9367/15000 [59:35<17:12,  5.46it/s, lr=9.41e-6, step_loss=0.264]07/18/2023 20:02:57 - INFO - __main__ - train loss is 8.015578482765704\n",
      "Steps:  62%|▌| 9368/15000 [59:35<17:05,  5.49it/s, lr=9.41e-6, step_loss=0.0727]07/18/2023 20:02:57 - INFO - __main__ - train loss is 8.811667416710407\n",
      "Steps:  62%|█▏| 9369/15000 [59:35<17:00,  5.52it/s, lr=9.41e-6, step_loss=0.796]07/18/2023 20:02:58 - INFO - __main__ - train loss is 8.914389361161739\n",
      "Steps:  62%|█▏| 9370/15000 [59:36<16:56,  5.54it/s, lr=9.41e-6, step_loss=0.103]07/18/2023 20:02:58 - INFO - __main__ - train loss is 9.344810355920345\n",
      "Steps:  62%|█▊ | 9371/15000 [59:36<17:02,  5.50it/s, lr=9.41e-6, step_loss=0.43]07/18/2023 20:02:58 - INFO - __main__ - train loss is 9.821937878150493\n",
      "Steps:  62%|█▏| 9372/15000 [59:36<17:07,  5.48it/s, lr=9.41e-6, step_loss=0.477]07/18/2023 20:02:58 - INFO - __main__ - train loss is 10.056432683486491\n",
      "Steps:  62%|█▏| 9373/15000 [59:36<17:08,  5.47it/s, lr=9.41e-6, step_loss=0.234]07/18/2023 20:02:58 - INFO - __main__ - train loss is 10.189931709785014\n",
      "Steps:  62%|█▏| 9374/15000 [59:36<17:11,  5.45it/s, lr=9.41e-6, step_loss=0.133]07/18/2023 20:02:59 - INFO - __main__ - train loss is 10.549232442397624\n",
      "Steps:  62%|█▎| 9375/15000 [59:36<17:13,  5.44it/s, lr=9.41e-6, step_loss=0.359]07/18/2023 20:02:59 - INFO - __main__ - train loss is 11.065449793357402\n",
      "Steps:  63%|█▎| 9376/15000 [59:37<17:10,  5.46it/s, lr=9.41e-6, step_loss=0.516]07/18/2023 20:02:59 - INFO - __main__ - train loss is 11.128364343661815\n",
      "Steps:  63%|▋| 9377/15000 [59:37<17:03,  5.49it/s, lr=9.41e-6, step_loss=0.0629]07/18/2023 20:02:59 - INFO - __main__ - train loss is 11.208546299953014\n",
      "Steps:  63%|▋| 9378/15000 [59:37<17:06,  5.48it/s, lr=9.41e-6, step_loss=0.0802]07/18/2023 20:02:59 - INFO - __main__ - train loss is 11.21027269831393\n",
      "Steps:  63%|▋| 9379/15000 [59:37<17:00,  5.51it/s, lr=9.41e-6, step_loss=0.0017307/18/2023 20:02:59 - INFO - __main__ - train loss is 11.260294298292138\n",
      "Steps:  63%|█▉ | 9380/15000 [59:37<16:56,  5.53it/s, lr=9.41e-6, step_loss=0.05]07/18/2023 20:03:00 - INFO - __main__ - train loss is 11.262140035396442\n",
      "Steps:  63%|▋| 9381/15000 [59:38<17:02,  5.49it/s, lr=9.41e-6, step_loss=0.0018507/18/2023 20:03:00 - INFO - __main__ - train loss is 11.273224567761645\n",
      "Steps:  63%|▋| 9382/15000 [59:38<17:00,  5.51it/s, lr=9.41e-6, step_loss=0.0111]07/18/2023 20:03:00 - INFO - __main__ - train loss is 11.385318612447008\n",
      "Steps:  63%|█▎| 9383/15000 [59:38<17:04,  5.48it/s, lr=9.41e-6, step_loss=0.112]07/18/2023 20:03:00 - INFO - __main__ - train loss is 11.402275239815935\n",
      "Steps:  63%|█▎| 9384/15000 [59:38<17:02,  5.49it/s, lr=9.41e-6, step_loss=0.017]07/18/2023 20:03:00 - INFO - __main__ - train loss is 11.666233395924792\n",
      "Steps:  63%|█▎| 9385/15000 [59:38<17:06,  5.47it/s, lr=9.41e-6, step_loss=0.264]07/18/2023 20:03:01 - INFO - __main__ - train loss is 11.718299774220213\n",
      "Steps:  63%|▋| 9386/15000 [59:38<17:12,  5.44it/s, lr=9.41e-6, step_loss=0.0521]07/18/2023 20:03:01 - INFO - __main__ - train loss is 12.251762954285368\n",
      "Steps:  63%|█▎| 9387/15000 [59:39<17:04,  5.48it/s, lr=9.41e-6, step_loss=0.533]07/18/2023 20:03:01 - INFO - __main__ - train loss is 12.516668705036864\n",
      "Steps:  63%|█▎| 9388/15000 [59:39<16:58,  5.51it/s, lr=9.41e-6, step_loss=0.265]07/18/2023 20:03:01 - INFO - __main__ - train loss is 12.519793531158939\n",
      "Steps:  63%|▋| 9389/15000 [59:39<17:04,  5.48it/s, lr=9.41e-6, step_loss=0.0031207/18/2023 20:03:01 - INFO - __main__ - train loss is 12.54499819711782\n",
      "Steps:  63%|▋| 9390/15000 [59:39<17:07,  5.46it/s, lr=9.41e-6, step_loss=0.0252]07/18/2023 20:03:01 - INFO - __main__ - train loss is 12.633994831005111\n",
      "Steps:  63%|█▎| 9391/15000 [59:39<17:07,  5.46it/s, lr=9.41e-6, step_loss=0.089]07/18/2023 20:03:02 - INFO - __main__ - train loss is 12.642605982953683\n",
      "Steps:  63%|▋| 9392/15000 [59:40<17:05,  5.47it/s, lr=9.41e-6, step_loss=0.0086107/18/2023 20:03:02 - INFO - __main__ - train loss is 12.96047716611065\n",
      "Steps:  63%|█▎| 9393/15000 [59:40<17:08,  5.45it/s, lr=9.41e-6, step_loss=0.318]07/18/2023 20:03:02 - INFO - __main__ - train loss is 13.005586125189438\n",
      "Steps:  63%|▋| 9394/15000 [59:40<17:02,  5.48it/s, lr=9.41e-6, step_loss=0.0451]07/18/2023 20:03:02 - INFO - __main__ - train loss is 13.316597678000107\n",
      "Steps:  63%|█▎| 9395/15000 [59:40<17:04,  5.47it/s, lr=9.41e-6, step_loss=0.311]07/18/2023 20:03:02 - INFO - __main__ - train loss is 13.718516804510728\n",
      "Steps:  63%|█▎| 9396/15000 [59:40<17:04,  5.47it/s, lr=9.41e-6, step_loss=0.402]07/18/2023 20:03:03 - INFO - __main__ - train loss is 13.932705976301804\n",
      "Steps:  63%|█▎| 9397/15000 [59:40<17:06,  5.46it/s, lr=9.41e-6, step_loss=0.214]07/18/2023 20:03:03 - INFO - __main__ - train loss is 14.242723293835297\n",
      "Steps:  63%|█▉ | 9398/15000 [59:41<17:06,  5.46it/s, lr=9.41e-6, step_loss=0.31]07/18/2023 20:03:03 - INFO - __main__ - train loss is 14.249566467711702\n",
      "Steps:  63%|▋| 9399/15000 [59:41<16:57,  5.50it/s, lr=9.41e-6, step_loss=0.0068407/18/2023 20:03:03 - INFO - __main__ - train loss is 14.251792337279767\n",
      "Steps:  63%|▋| 9400/15000 [59:41<16:51,  5.54it/s, lr=9.41e-6, step_loss=0.0022307/18/2023 20:03:03 - INFO - __main__ - train loss is 14.618834252934903\n",
      "Steps:  63%|█▎| 9401/15000 [59:41<16:47,  5.56it/s, lr=9.41e-6, step_loss=0.367]07/18/2023 20:03:03 - INFO - __main__ - train loss is 14.723392132204026\n",
      "Steps:  63%|█▎| 9402/15000 [59:41<16:44,  5.57it/s, lr=9.41e-6, step_loss=0.105]07/18/2023 20:03:04 - INFO - __main__ - train loss is 14.959943804424256\n",
      "Steps:  63%|█▎| 9403/15000 [59:42<16:41,  5.59it/s, lr=9.41e-6, step_loss=0.237]07/18/2023 20:03:04 - INFO - __main__ - train loss is 15.346743914764374\n",
      "Steps:  63%|█▎| 9404/15000 [59:42<16:39,  5.60it/s, lr=9.41e-6, step_loss=0.387]07/18/2023 20:03:04 - INFO - __main__ - train loss is 15.366032182704657\n",
      "Steps:  63%|▋| 9405/15000 [59:42<16:38,  5.60it/s, lr=9.41e-6, step_loss=0.0193]07/18/2023 20:03:04 - INFO - __main__ - train loss is 15.989031314384192\n",
      "Steps:  63%|█▎| 9406/15000 [59:42<16:38,  5.60it/s, lr=9.41e-6, step_loss=0.623]07/18/2023 20:03:04 - INFO - __main__ - train loss is 16.108120142947882\n",
      "Steps:  63%|█▎| 9407/15000 [59:42<16:37,  5.60it/s, lr=9.41e-6, step_loss=0.119]07/18/2023 20:03:05 - INFO - __main__ - train loss is 16.455192923080176\n",
      "Steps:  63%|█▎| 9408/15000 [59:42<16:45,  5.56it/s, lr=9.41e-6, step_loss=0.347]07/18/2023 20:03:05 - INFO - __main__ - train loss is 16.494867667090148\n",
      "Steps:  63%|▋| 9409/15000 [59:43<22:34,  4.13it/s, lr=9.41e-6, step_loss=0.0397]07/18/2023 20:03:06 - INFO - __main__ - Per validation step average loss is 0.15570947527885437\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Cumulative validation average loss is 0.15570947527885437\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Per validation step average loss is 0.6744668483734131\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Cumulative validation average loss is 0.8301763236522675\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Per validation step average loss is 0.47321829199790955\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Cumulative validation average loss is 1.303394615650177\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Per validation step average loss is 0.3562840223312378\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Cumulative validation average loss is 1.6596786379814148\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Per validation step average loss is 0.047634173184633255\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Cumulative validation average loss is 1.707312811166048\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Per validation step average loss is 0.13124290108680725\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Cumulative validation average loss is 1.8385557122528553\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Per validation step average loss is 0.3651728630065918\n",
      "07/18/2023 20:03:06 - INFO - __main__ - Cumulative validation average loss is 2.203728575259447\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Per validation step average loss is 0.04940613731741905\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Cumulative validation average loss is 2.253134712576866\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Per validation step average loss is 0.027334608137607574\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Cumulative validation average loss is 2.2804693207144737\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Per validation step average loss is 0.5270708799362183\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Cumulative validation average loss is 2.807540200650692\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Per validation step average loss is 0.16903924942016602\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Cumulative validation average loss is 2.976579450070858\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Per validation step average loss is 0.01627914234995842\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Cumulative validation average loss is 2.9928585924208164\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Average validation loss for Epoch 96 is 0.2494048827017347\n",
      "07/18/2023 20:03:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:03:20 - INFO - __main__ - Starting epoch 97\n",
      "07/18/2023 20:03:21 - INFO - __main__ - train loss is 0.010601191781461239\n",
      "Steps:  63%|▋| 9410/15000 [59:59<7:39:34,  4.93s/it, lr=9.41e-6, step_loss=0.01007/18/2023 20:03:21 - INFO - __main__ - train loss is 0.05823318939656019\n",
      "Steps:  63%|▋| 9411/15000 [59:59<5:26:50,  3.51s/it, lr=9.41e-6, step_loss=0.04707/18/2023 20:03:21 - INFO - __main__ - train loss is 0.3740249751135707\n",
      "Steps:  63%|▋| 9412/15000 [59:59<3:53:53,  2.51s/it, lr=9.41e-6, step_loss=0.31607/18/2023 20:03:21 - INFO - __main__ - train loss is 1.0297464011237025\n",
      "Steps:  63%|▋| 9413/15000 [59:59<2:48:40,  1.81s/it, lr=9.41e-6, step_loss=0.65607/18/2023 20:03:22 - INFO - __main__ - train loss is 1.0431684693321586\n",
      "Steps:  63%|▋| 9414/15000 [59:59<2:03:02,  1.32s/it, lr=9.41e-6, step_loss=0.01307/18/2023 20:03:22 - INFO - __main__ - train loss is 1.2152819177135825\n",
      "Steps:  63%|▋| 9415/15000 [1:00:00<1:31:06,  1.02it/s, lr=9.41e-6, step_loss=0.107/18/2023 20:03:22 - INFO - __main__ - train loss is 1.9759454866871238\n",
      "Steps:  63%|▋| 9416/15000 [1:00:00<1:08:45,  1.35it/s, lr=9.41e-6, step_loss=0.707/18/2023 20:03:22 - INFO - __main__ - train loss is 1.992760638706386\n",
      "Steps:  63%|▋| 9417/15000 [1:00:00<53:05,  1.75it/s, lr=9.41e-6, step_loss=0.01607/18/2023 20:03:22 - INFO - __main__ - train loss is 2.4653667910024524\n",
      "Steps:  63%|▋| 9418/15000 [1:00:00<42:07,  2.21it/s, lr=9.41e-6, step_loss=0.47307/18/2023 20:03:22 - INFO - __main__ - train loss is 2.468769872561097\n",
      "Steps:  63%|▋| 9419/15000 [1:00:00<34:26,  2.70it/s, lr=9.41e-6, step_loss=0.00307/18/2023 20:03:23 - INFO - __main__ - train loss is 2.561634698882699\n",
      "Steps:  63%|▋| 9420/15000 [1:00:00<29:05,  3.20it/s, lr=9.41e-6, step_loss=0.09207/18/2023 20:03:23 - INFO - __main__ - train loss is 2.722514847293496\n",
      "Steps:  63%|▋| 9421/15000 [1:00:01<25:19,  3.67it/s, lr=9.41e-6, step_loss=0.16107/18/2023 20:03:23 - INFO - __main__ - train loss is 2.759902300313115\n",
      "Steps:  63%|▋| 9422/15000 [1:00:01<22:49,  4.07it/s, lr=9.41e-6, step_loss=0.03707/18/2023 20:03:23 - INFO - __main__ - train loss is 2.76193627435714\n",
      "Steps:  63%|▋| 9423/15000 [1:00:01<20:56,  4.44it/s, lr=9.41e-6, step_loss=0.00207/18/2023 20:03:23 - INFO - __main__ - train loss is 2.887725052423775\n",
      "Steps:  63%|▋| 9424/15000 [1:00:01<19:38,  4.73it/s, lr=9.41e-6, step_loss=0.12607/18/2023 20:03:23 - INFO - __main__ - train loss is 3.256998714990914\n",
      "Steps:  63%|▋| 9425/15000 [1:00:01<18:42,  4.97it/s, lr=9.41e-6, step_loss=0.36907/18/2023 20:03:24 - INFO - __main__ - train loss is 3.380918067879975\n",
      "Steps:  63%|▋| 9426/15000 [1:00:02<18:03,  5.15it/s, lr=9.41e-6, step_loss=0.12407/18/2023 20:03:24 - INFO - __main__ - train loss is 3.38404072355479\n",
      "Steps:  63%|▋| 9427/15000 [1:00:02<17:36,  5.27it/s, lr=9.41e-6, step_loss=0.00307/18/2023 20:03:24 - INFO - __main__ - train loss is 3.402512819506228\n",
      "Steps:  63%|▋| 9428/15000 [1:00:02<17:18,  5.37it/s, lr=9.41e-6, step_loss=0.01807/18/2023 20:03:24 - INFO - __main__ - train loss is 3.5628003934398293\n",
      "Steps:  63%|▋| 9429/15000 [1:00:02<17:04,  5.44it/s, lr=9.41e-6, step_loss=0.16]07/18/2023 20:03:24 - INFO - __main__ - train loss is 3.575881057418883\n",
      "Steps:  63%|▋| 9430/15000 [1:00:02<16:56,  5.48it/s, lr=9.4e-6, step_loss=0.013107/18/2023 20:03:25 - INFO - __main__ - train loss is 3.604782276786864\n",
      "Steps:  63%|▋| 9431/15000 [1:00:02<16:49,  5.51it/s, lr=9.4e-6, step_loss=0.028907/18/2023 20:03:25 - INFO - __main__ - train loss is 3.666287154890597\n",
      "Steps:  63%|▋| 9432/15000 [1:00:03<16:45,  5.54it/s, lr=9.4e-6, step_loss=0.061507/18/2023 20:03:25 - INFO - __main__ - train loss is 3.8372465381398797\n",
      "Steps:  63%|▋| 9433/15000 [1:00:03<16:42,  5.56it/s, lr=9.4e-6, step_loss=0.171]07/18/2023 20:03:25 - INFO - __main__ - train loss is 4.16810751054436\n",
      "Steps:  63%|▋| 9434/15000 [1:00:03<16:39,  5.57it/s, lr=9.4e-6, step_loss=0.331]07/18/2023 20:03:25 - INFO - __main__ - train loss is 4.334933043457568\n",
      "Steps:  63%|▋| 9435/15000 [1:00:03<16:37,  5.58it/s, lr=9.4e-6, step_loss=0.167]07/18/2023 20:03:25 - INFO - __main__ - train loss is 4.522639946080744\n",
      "Steps:  63%|▋| 9436/15000 [1:00:03<16:36,  5.58it/s, lr=9.4e-6, step_loss=0.188]07/18/2023 20:03:26 - INFO - __main__ - train loss is 4.9096444407477975\n",
      "Steps:  63%|▋| 9437/15000 [1:00:04<16:36,  5.58it/s, lr=9.4e-6, step_loss=0.387]07/18/2023 20:03:26 - INFO - __main__ - train loss is 4.9422319093719125\n",
      "Steps:  63%|▋| 9438/15000 [1:00:04<16:35,  5.59it/s, lr=9.4e-6, step_loss=0.032607/18/2023 20:03:26 - INFO - __main__ - train loss is 5.113644883967936\n",
      "Steps:  63%|▋| 9439/15000 [1:00:04<16:34,  5.59it/s, lr=9.4e-6, step_loss=0.171]07/18/2023 20:03:26 - INFO - __main__ - train loss is 5.235439375974238\n",
      "Steps:  63%|▋| 9440/15000 [1:00:04<16:34,  5.59it/s, lr=9.4e-6, step_loss=0.122]07/18/2023 20:03:26 - INFO - __main__ - train loss is 5.338149950839579\n",
      "Steps:  63%|▋| 9441/15000 [1:00:04<16:42,  5.54it/s, lr=9.4e-6, step_loss=0.103]07/18/2023 20:03:27 - INFO - __main__ - train loss is 5.621531681157649\n",
      "Steps:  63%|▋| 9442/15000 [1:00:04<16:39,  5.56it/s, lr=9.4e-6, step_loss=0.283]07/18/2023 20:03:27 - INFO - __main__ - train loss is 5.665986814536154\n",
      "Steps:  63%|▋| 9443/15000 [1:00:05<16:37,  5.57it/s, lr=9.4e-6, step_loss=0.044507/18/2023 20:03:27 - INFO - __main__ - train loss is 5.748623066581786\n",
      "Steps:  63%|▋| 9444/15000 [1:00:05<16:36,  5.58it/s, lr=9.4e-6, step_loss=0.082607/18/2023 20:03:27 - INFO - __main__ - train loss is 5.788986721076071\n",
      "Steps:  63%|▋| 9445/15000 [1:00:05<16:35,  5.58it/s, lr=9.4e-6, step_loss=0.040407/18/2023 20:03:27 - INFO - __main__ - train loss is 5.893499516882002\n",
      "Steps:  63%|▋| 9446/15000 [1:00:05<16:33,  5.59it/s, lr=9.4e-6, step_loss=0.105]07/18/2023 20:03:27 - INFO - __main__ - train loss is 5.895406837342307\n",
      "Steps:  63%|▋| 9447/15000 [1:00:05<16:33,  5.59it/s, lr=9.4e-6, step_loss=0.001907/18/2023 20:03:28 - INFO - __main__ - train loss is 6.088136027334258\n",
      "Steps:  63%|▋| 9448/15000 [1:00:05<16:32,  5.60it/s, lr=9.4e-6, step_loss=0.193]07/18/2023 20:03:28 - INFO - __main__ - train loss is 6.259512345073745\n",
      "Steps:  63%|▋| 9449/15000 [1:00:06<16:31,  5.60it/s, lr=9.4e-6, step_loss=0.171]07/18/2023 20:03:28 - INFO - __main__ - train loss is 6.260844190022908\n",
      "Steps:  63%|▋| 9450/15000 [1:00:06<16:31,  5.60it/s, lr=9.4e-6, step_loss=0.001307/18/2023 20:03:28 - INFO - __main__ - train loss is 6.703699726960622\n",
      "Steps:  63%|▋| 9451/15000 [1:00:06<16:31,  5.60it/s, lr=9.4e-6, step_loss=0.443]07/18/2023 20:03:28 - INFO - __main__ - train loss is 6.73069134389516\n",
      "Steps:  63%|▋| 9452/15000 [1:00:06<16:30,  5.60it/s, lr=9.4e-6, step_loss=0.027]07/18/2023 20:03:28 - INFO - __main__ - train loss is 6.773466393700801\n",
      "Steps:  63%|▋| 9453/15000 [1:00:06<16:30,  5.60it/s, lr=9.4e-6, step_loss=0.042807/18/2023 20:03:29 - INFO - __main__ - train loss is 6.811991386464797\n",
      "Steps:  63%|▋| 9454/15000 [1:00:07<16:30,  5.60it/s, lr=9.4e-6, step_loss=0.038507/18/2023 20:03:29 - INFO - __main__ - train loss is 6.929428421310149\n",
      "Steps:  63%|▋| 9455/15000 [1:00:07<16:30,  5.60it/s, lr=9.4e-6, step_loss=0.117]07/18/2023 20:03:29 - INFO - __main__ - train loss is 7.074296303442679\n",
      "Steps:  63%|▋| 9456/15000 [1:00:07<16:29,  5.60it/s, lr=9.4e-6, step_loss=0.145]07/18/2023 20:03:29 - INFO - __main__ - train loss is 7.380611308268271\n",
      "Steps:  63%|▋| 9457/15000 [1:00:07<16:30,  5.60it/s, lr=9.4e-6, step_loss=0.306]07/18/2023 20:03:29 - INFO - __main__ - train loss is 7.4852438274538144\n",
      "Steps:  63%|▋| 9458/15000 [1:00:07<16:30,  5.60it/s, lr=9.4e-6, step_loss=0.105]07/18/2023 20:03:30 - INFO - __main__ - train loss is 7.839296788326465\n",
      "Steps:  63%|▋| 9459/15000 [1:00:07<16:30,  5.59it/s, lr=9.4e-6, step_loss=0.354]07/18/2023 20:03:30 - INFO - __main__ - train loss is 7.949316673330031\n",
      "Steps:  63%|█▎| 9460/15000 [1:00:08<16:40,  5.54it/s, lr=9.4e-6, step_loss=0.11]07/18/2023 20:03:30 - INFO - __main__ - train loss is 7.951076632016338\n",
      "Steps:  63%|▋| 9461/15000 [1:00:08<16:49,  5.49it/s, lr=9.4e-6, step_loss=0.001707/18/2023 20:03:30 - INFO - __main__ - train loss is 8.332994674914517\n",
      "Steps:  63%|▋| 9462/15000 [1:00:08<16:47,  5.49it/s, lr=9.4e-6, step_loss=0.382]07/18/2023 20:03:30 - INFO - __main__ - train loss is 8.341982571058907\n",
      "Steps:  63%|▋| 9463/15000 [1:00:08<16:42,  5.52it/s, lr=9.4e-6, step_loss=0.008907/18/2023 20:03:30 - INFO - __main__ - train loss is 8.346133677870966\n",
      "Steps:  63%|▋| 9464/15000 [1:00:08<16:39,  5.54it/s, lr=9.4e-6, step_loss=0.004107/18/2023 20:03:31 - INFO - __main__ - train loss is 8.576922325999476\n",
      "Steps:  63%|▋| 9465/15000 [1:00:09<16:36,  5.55it/s, lr=9.4e-6, step_loss=0.231]07/18/2023 20:03:31 - INFO - __main__ - train loss is 8.796844123513438\n",
      "Steps:  63%|█▎| 9466/15000 [1:00:09<16:34,  5.57it/s, lr=9.4e-6, step_loss=0.22]07/18/2023 20:03:31 - INFO - __main__ - train loss is 8.79871266160626\n",
      "Steps:  63%|▋| 9467/15000 [1:00:09<16:33,  5.57it/s, lr=9.4e-6, step_loss=0.001807/18/2023 20:03:31 - INFO - __main__ - train loss is 8.819489007932134\n",
      "Steps:  63%|▋| 9468/15000 [1:00:09<16:32,  5.58it/s, lr=9.4e-6, step_loss=0.020807/18/2023 20:03:31 - INFO - __main__ - train loss is 8.904972141725011\n",
      "Steps:  63%|▋| 9469/15000 [1:00:09<16:30,  5.58it/s, lr=9.4e-6, step_loss=0.085507/18/2023 20:03:32 - INFO - __main__ - train loss is 9.035036509972997\n",
      "Steps:  63%|█▎| 9470/15000 [1:00:09<16:29,  5.59it/s, lr=9.4e-6, step_loss=0.13]07/18/2023 20:03:32 - INFO - __main__ - train loss is 9.22721329901833\n",
      "Steps:  63%|▋| 9471/15000 [1:00:10<16:29,  5.59it/s, lr=9.4e-6, step_loss=0.192]07/18/2023 20:03:32 - INFO - __main__ - train loss is 9.23056233173702\n",
      "Steps:  63%|▋| 9472/15000 [1:00:10<16:30,  5.58it/s, lr=9.4e-6, step_loss=0.003307/18/2023 20:03:32 - INFO - __main__ - train loss is 9.400213199318387\n",
      "Steps:  63%|█▎| 9473/15000 [1:00:10<16:29,  5.58it/s, lr=9.4e-6, step_loss=0.17]07/18/2023 20:03:32 - INFO - __main__ - train loss is 9.751195448101498\n",
      "Steps:  63%|▋| 9474/15000 [1:00:10<16:29,  5.59it/s, lr=9.4e-6, step_loss=0.351]07/18/2023 20:03:32 - INFO - __main__ - train loss is 10.147528486908413\n",
      "Steps:  63%|▋| 9475/15000 [1:00:10<16:28,  5.59it/s, lr=9.4e-6, step_loss=0.396]07/18/2023 20:03:33 - INFO - __main__ - train loss is 10.280557277263142\n",
      "Steps:  63%|▋| 9476/15000 [1:00:11<16:28,  5.59it/s, lr=9.4e-6, step_loss=0.133]07/18/2023 20:03:33 - INFO - __main__ - train loss is 10.315524111152627\n",
      "Steps:  63%|▋| 9477/15000 [1:00:11<16:27,  5.59it/s, lr=9.4e-6, step_loss=0.035]07/18/2023 20:03:33 - INFO - __main__ - train loss is 10.41169659292791\n",
      "Steps:  63%|▋| 9478/15000 [1:00:11<16:37,  5.54it/s, lr=9.4e-6, step_loss=0.096207/18/2023 20:03:33 - INFO - __main__ - train loss is 10.467187515110709\n",
      "Steps:  63%|▋| 9479/15000 [1:00:11<16:44,  5.50it/s, lr=9.4e-6, step_loss=0.055507/18/2023 20:03:33 - INFO - __main__ - train loss is 10.478406493202783\n",
      "Steps:  63%|▋| 9480/15000 [1:00:11<16:42,  5.50it/s, lr=9.4e-6, step_loss=0.011207/18/2023 20:03:34 - INFO - __main__ - train loss is 10.698925320641138\n",
      "Steps:  63%|▋| 9481/15000 [1:00:11<16:48,  5.48it/s, lr=9.4e-6, step_loss=0.221]07/18/2023 20:03:34 - INFO - __main__ - train loss is 10.835673276917078\n",
      "Steps:  63%|▋| 9482/15000 [1:00:12<16:48,  5.47it/s, lr=9.4e-6, step_loss=0.137]07/18/2023 20:03:34 - INFO - __main__ - train loss is 11.154690150753595\n",
      "Steps:  63%|▋| 9483/15000 [1:00:12<16:50,  5.46it/s, lr=9.4e-6, step_loss=0.319]07/18/2023 20:03:34 - INFO - __main__ - train loss is 11.431621377007104\n",
      "Steps:  63%|▋| 9484/15000 [1:00:12<16:42,  5.50it/s, lr=9.4e-6, step_loss=0.277]07/18/2023 20:03:34 - INFO - __main__ - train loss is 11.784150455729105\n",
      "Steps:  63%|▋| 9485/15000 [1:00:12<16:49,  5.46it/s, lr=9.4e-6, step_loss=0.353]07/18/2023 20:03:34 - INFO - __main__ - train loss is 11.792395335272886\n",
      "Steps:  63%|▋| 9486/15000 [1:00:12<18:01,  5.10it/s, lr=9.4e-6, step_loss=0.008207/18/2023 20:03:35 - INFO - __main__ - train loss is 11.833708629594184\n",
      "Steps:  63%|▋| 9487/15000 [1:00:13<17:33,  5.23it/s, lr=9.4e-6, step_loss=0.041307/18/2023 20:03:35 - INFO - __main__ - train loss is 11.924355596886016\n",
      "Steps:  63%|▋| 9488/15000 [1:00:13<17:12,  5.34it/s, lr=9.4e-6, step_loss=0.090607/18/2023 20:03:35 - INFO - __main__ - train loss is 12.193611831055023\n",
      "Steps:  63%|▋| 9489/15000 [1:00:13<16:58,  5.41it/s, lr=9.4e-6, step_loss=0.269]07/18/2023 20:03:35 - INFO - __main__ - train loss is 12.677795172319748\n",
      "Steps:  63%|▋| 9490/15000 [1:00:13<16:48,  5.47it/s, lr=9.4e-6, step_loss=0.484]07/18/2023 20:03:35 - INFO - __main__ - train loss is 12.681220554630272\n",
      "Steps:  63%|▋| 9491/15000 [1:00:13<16:48,  5.46it/s, lr=9.4e-6, step_loss=0.003407/18/2023 20:03:36 - INFO - __main__ - train loss is 12.688220617244951\n",
      "Steps:  63%|▋| 9492/15000 [1:00:13<16:40,  5.50it/s, lr=9.4e-6, step_loss=0.007]07/18/2023 20:03:36 - INFO - __main__ - train loss is 12.699862959678285\n",
      "Steps:  63%|▋| 9493/15000 [1:00:14<16:34,  5.54it/s, lr=9.4e-6, step_loss=0.011607/18/2023 20:03:36 - INFO - __main__ - train loss is 12.703013293328695\n",
      "Steps:  63%|▋| 9494/15000 [1:00:14<16:30,  5.56it/s, lr=9.4e-6, step_loss=0.003107/18/2023 20:03:36 - INFO - __main__ - train loss is 13.160591386142187\n",
      "Steps:  63%|▋| 9495/15000 [1:00:14<16:27,  5.57it/s, lr=9.4e-6, step_loss=0.458]07/18/2023 20:03:36 - INFO - __main__ - train loss is 13.233027063193731\n",
      "Steps:  63%|▋| 9496/15000 [1:00:14<16:25,  5.58it/s, lr=9.4e-6, step_loss=0.072407/18/2023 20:03:36 - INFO - __main__ - train loss is 13.283349648001604\n",
      "Steps:  63%|▋| 9497/15000 [1:00:14<16:24,  5.59it/s, lr=9.4e-6, step_loss=0.050307/18/2023 20:03:37 - INFO - __main__ - train loss is 13.38330670434516\n",
      "Steps:  63%|█▉ | 9498/15000 [1:00:15<16:22,  5.60it/s, lr=9.4e-6, step_loss=0.1]07/18/2023 20:03:37 - INFO - __main__ - train loss is 13.555897243204527\n",
      "Steps:  63%|▋| 9499/15000 [1:00:15<16:31,  5.55it/s, lr=9.4e-6, step_loss=0.173]07/18/2023 20:03:37 - INFO - __main__ - train loss is 13.565450536902063\n",
      "Steps:  63%|▋| 9500/15000 [1:00:15<16:29,  5.56it/s, lr=9.4e-6, step_loss=0.173]07/18/2023 20:03:37 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-9500\n",
      "07/18/2023 20:03:37 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:03:37,595] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:03:37,600] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-9500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:03:37,600] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-9500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:03:37,608] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-9500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:03:37,608] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-9500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:03:37,627] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-9500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:03:37,633] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-9500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:03:37,633] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:03:37 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-9500/pytorch_model\n",
      "07/18/2023 20:03:37 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-9500/scheduler.bin\n",
      "07/18/2023 20:03:37 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-9500/random_states_0.pkl\n",
      "07/18/2023 20:03:37 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-9500\n",
      "Steps:  63%|▋| 9500/15000 [1:00:15<16:29,  5.56it/s, lr=9.4e-6, step_loss=0.009507/18/2023 20:03:37 - INFO - __main__ - train loss is 13.579024986247532\n",
      "Steps:  63%|▋| 9501/15000 [1:00:15<17:31,  5.23it/s, lr=9.4e-6, step_loss=0.013607/18/2023 20:03:37 - INFO - __main__ - train loss is 13.633117192308418\n",
      "Steps:  63%|▋| 9502/15000 [1:00:15<17:10,  5.33it/s, lr=9.4e-6, step_loss=0.054107/18/2023 20:03:38 - INFO - __main__ - train loss is 13.969483517925255\n",
      "Steps:  63%|▋| 9503/15000 [1:00:15<17:04,  5.36it/s, lr=9.4e-6, step_loss=0.336]07/18/2023 20:03:38 - INFO - __main__ - train loss is 14.090162665466778\n",
      "Steps:  63%|▋| 9504/15000 [1:00:16<16:59,  5.39it/s, lr=9.4e-6, step_loss=0.121]07/18/2023 20:03:38 - INFO - __main__ - train loss is 14.137640387634747\n",
      "Steps:  63%|▋| 9505/15000 [1:00:16<16:47,  5.46it/s, lr=9.4e-6, step_loss=0.047507/18/2023 20:03:38 - INFO - __main__ - train loss is 14.771899253944866\n",
      "Steps:  63%|▋| 9506/15000 [1:00:16<22:22,  4.09it/s, lr=9.4e-6, step_loss=0.634]07/18/2023 20:03:39 - INFO - __main__ - Per validation step average loss is 0.011016873642802238\n",
      "07/18/2023 20:03:39 - INFO - __main__ - Cumulative validation average loss is 0.011016873642802238\n",
      "07/18/2023 20:03:39 - INFO - __main__ - Per validation step average loss is 0.04177325963973999\n",
      "07/18/2023 20:03:39 - INFO - __main__ - Cumulative validation average loss is 0.05279013328254223\n",
      "07/18/2023 20:03:39 - INFO - __main__ - Per validation step average loss is 0.029597867280244827\n",
      "07/18/2023 20:03:39 - INFO - __main__ - Cumulative validation average loss is 0.08238800056278706\n",
      "07/18/2023 20:03:39 - INFO - __main__ - Per validation step average loss is 0.1076742559671402\n",
      "07/18/2023 20:03:39 - INFO - __main__ - Cumulative validation average loss is 0.19006225652992725\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Per validation step average loss is 0.3495486080646515\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Cumulative validation average loss is 0.5396108645945787\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Per validation step average loss is 0.0022693658247590065\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Cumulative validation average loss is 0.5418802304193377\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Per validation step average loss is 0.005106218159198761\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Cumulative validation average loss is 0.5469864485785365\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Per validation step average loss is 0.0026241932064294815\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Cumulative validation average loss is 0.549610641784966\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Per validation step average loss is 0.02271723374724388\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Cumulative validation average loss is 0.5723278755322099\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Per validation step average loss is 0.01827372796833515\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Cumulative validation average loss is 0.590601603500545\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Per validation step average loss is 0.06766068190336227\n",
      "07/18/2023 20:03:40 - INFO - __main__ - Cumulative validation average loss is 0.6582622854039073\n",
      "07/18/2023 20:03:41 - INFO - __main__ - Per validation step average loss is 0.07925034314393997\n",
      "07/18/2023 20:03:41 - INFO - __main__ - Cumulative validation average loss is 0.7375126285478473\n",
      "07/18/2023 20:03:41 - INFO - __main__ - Average validation loss for Epoch 97 is 0.061459385712320604\n",
      "07/18/2023 20:03:41 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:03:54 - INFO - __main__ - Starting epoch 98\n",
      "07/18/2023 20:03:55 - INFO - __main__ - train loss is 0.003429461270570755\n",
      "Steps:  63%|▋| 9507/15000 [1:00:33<7:43:00,  5.06s/it, lr=9.4e-6, step_loss=0.0007/18/2023 20:03:55 - INFO - __main__ - train loss is 0.017219265922904015\n",
      "Steps:  63%|▋| 9508/15000 [1:00:33<5:28:56,  3.59s/it, lr=9.4e-6, step_loss=0.0107/18/2023 20:03:55 - INFO - __main__ - train loss is 0.6618299093097448\n",
      "Steps:  63%|▋| 9509/15000 [1:00:33<3:55:17,  2.57s/it, lr=9.4e-6, step_loss=0.6407/18/2023 20:03:55 - INFO - __main__ - train loss is 0.782918905839324\n",
      "Steps:  63%|▋| 9510/15000 [1:00:33<2:49:37,  1.85s/it, lr=9.39e-6, step_loss=0.107/18/2023 20:03:55 - INFO - __main__ - train loss is 0.8575945477932692\n",
      "Steps:  63%|▋| 9511/15000 [1:00:33<2:03:40,  1.35s/it, lr=9.39e-6, step_loss=0.007/18/2023 20:03:56 - INFO - __main__ - train loss is 0.9322061594575644\n",
      "Steps:  63%|▋| 9512/15000 [1:00:33<1:31:35,  1.00s/it, lr=9.39e-6, step_loss=0.007/18/2023 20:03:56 - INFO - __main__ - train loss is 1.3214507158845663\n",
      "Steps:  63%|▋| 9513/15000 [1:00:34<1:09:11,  1.32it/s, lr=9.39e-6, step_loss=0.307/18/2023 20:03:56 - INFO - __main__ - train loss is 1.3591829407960176\n",
      "Steps:  63%|▋| 9514/15000 [1:00:34<53:22,  1.71it/s, lr=9.39e-6, step_loss=0.03707/18/2023 20:03:56 - INFO - __main__ - train loss is 1.4298972729593515\n",
      "Steps:  63%|▋| 9515/15000 [1:00:34<42:18,  2.16it/s, lr=9.39e-6, step_loss=0.07007/18/2023 20:03:56 - INFO - __main__ - train loss is 1.4358335798606277\n",
      "Steps:  63%|▋| 9516/15000 [1:00:34<34:33,  2.65it/s, lr=9.39e-6, step_loss=0.00507/18/2023 20:03:56 - INFO - __main__ - train loss is 1.6137203490361571\n",
      "Steps:  63%|▋| 9517/15000 [1:00:34<29:07,  3.14it/s, lr=9.39e-6, step_loss=0.17807/18/2023 20:03:57 - INFO - __main__ - train loss is 1.616281274240464\n",
      "Steps:  63%|▋| 9518/15000 [1:00:35<25:19,  3.61it/s, lr=9.39e-6, step_loss=0.00207/18/2023 20:03:57 - INFO - __main__ - train loss is 1.9700933727435768\n",
      "Steps:  63%|▋| 9519/15000 [1:00:35<22:39,  4.03it/s, lr=9.39e-6, step_loss=0.35407/18/2023 20:03:57 - INFO - __main__ - train loss is 2.018982383888215\n",
      "Steps:  63%|▋| 9520/15000 [1:00:35<20:58,  4.36it/s, lr=9.39e-6, step_loss=0.04807/18/2023 20:03:57 - INFO - __main__ - train loss is 2.020725010195747\n",
      "Steps:  63%|▋| 9521/15000 [1:00:35<19:52,  4.60it/s, lr=9.39e-6, step_loss=0.00107/18/2023 20:03:57 - INFO - __main__ - train loss is 2.350301085272804\n",
      "Steps:  63%|▋| 9522/15000 [1:00:35<19:11,  4.76it/s, lr=9.39e-6, step_loss=0.33]07/18/2023 20:03:58 - INFO - __main__ - train loss is 2.606802044669166\n",
      "Steps:  63%|▋| 9523/15000 [1:00:35<18:19,  4.98it/s, lr=9.39e-6, step_loss=0.25707/18/2023 20:03:58 - INFO - __main__ - train loss is 2.7420227511320263\n",
      "Steps:  63%|▋| 9524/15000 [1:00:36<17:43,  5.15it/s, lr=9.39e-6, step_loss=0.13507/18/2023 20:03:58 - INFO - __main__ - train loss is 2.8864846213255078\n",
      "Steps:  64%|▋| 9525/15000 [1:00:36<17:17,  5.28it/s, lr=9.39e-6, step_loss=0.14407/18/2023 20:03:58 - INFO - __main__ - train loss is 2.9385757653508335\n",
      "Steps:  64%|▋| 9526/15000 [1:00:36<16:59,  5.37it/s, lr=9.39e-6, step_loss=0.05207/18/2023 20:03:58 - INFO - __main__ - train loss is 3.348684778669849\n",
      "Steps:  64%|▋| 9527/15000 [1:00:36<16:58,  5.37it/s, lr=9.39e-6, step_loss=0.41]07/18/2023 20:03:58 - INFO - __main__ - train loss is 3.5025029985699803\n",
      "Steps:  64%|▋| 9528/15000 [1:00:36<17:14,  5.29it/s, lr=9.39e-6, step_loss=0.15407/18/2023 20:03:59 - INFO - __main__ - train loss is 3.5839568285737187\n",
      "Steps:  64%|▋| 9529/15000 [1:00:37<18:08,  5.03it/s, lr=9.39e-6, step_loss=0.08107/18/2023 20:03:59 - INFO - __main__ - train loss is 3.8981076686177403\n",
      "Steps:  64%|▋| 9530/15000 [1:00:37<18:52,  4.83it/s, lr=9.39e-6, step_loss=0.31407/18/2023 20:03:59 - INFO - __main__ - train loss is 3.9225220868829638\n",
      "Steps:  64%|▋| 9531/15000 [1:00:37<19:17,  4.73it/s, lr=9.39e-6, step_loss=0.02407/18/2023 20:03:59 - INFO - __main__ - train loss is 4.729373712325469\n",
      "Steps:  64%|▋| 9532/15000 [1:00:37<19:34,  4.66it/s, lr=9.39e-6, step_loss=0.80707/18/2023 20:04:00 - INFO - __main__ - train loss is 4.87749769189395\n",
      "Steps:  64%|▋| 9533/15000 [1:00:37<19:48,  4.60it/s, lr=9.39e-6, step_loss=0.14807/18/2023 20:04:00 - INFO - __main__ - train loss is 4.889113895827904\n",
      "Steps:  64%|▋| 9534/15000 [1:00:38<19:56,  4.57it/s, lr=9.39e-6, step_loss=0.01107/18/2023 20:04:00 - INFO - __main__ - train loss is 4.894664391176775\n",
      "Steps:  64%|▋| 9535/15000 [1:00:38<19:56,  4.57it/s, lr=9.39e-6, step_loss=0.00507/18/2023 20:04:00 - INFO - __main__ - train loss is 4.905850988114253\n",
      "Steps:  64%|▋| 9536/15000 [1:00:38<19:40,  4.63it/s, lr=9.39e-6, step_loss=0.01107/18/2023 20:04:00 - INFO - __main__ - train loss is 5.036091666901484\n",
      "Steps:  64%|▋| 9537/15000 [1:00:38<18:42,  4.87it/s, lr=9.39e-6, step_loss=0.13]07/18/2023 20:04:01 - INFO - __main__ - train loss is 5.268829982960597\n",
      "Steps:  64%|▋| 9538/15000 [1:00:38<17:58,  5.07it/s, lr=9.39e-6, step_loss=0.23307/18/2023 20:04:01 - INFO - __main__ - train loss is 5.271987225161865\n",
      "Steps:  64%|▋| 9539/15000 [1:00:39<17:34,  5.18it/s, lr=9.39e-6, step_loss=0.00307/18/2023 20:04:01 - INFO - __main__ - train loss is 5.323671295540407\n",
      "Steps:  64%|▋| 9540/15000 [1:00:39<17:11,  5.29it/s, lr=9.39e-6, step_loss=0.05107/18/2023 20:04:01 - INFO - __main__ - train loss is 5.712151660816744\n",
      "Steps:  64%|▋| 9541/15000 [1:00:39<16:55,  5.38it/s, lr=9.39e-6, step_loss=0.38807/18/2023 20:04:01 - INFO - __main__ - train loss is 5.744620549725369\n",
      "Steps:  64%|▋| 9542/15000 [1:00:39<16:43,  5.44it/s, lr=9.39e-6, step_loss=0.03207/18/2023 20:04:01 - INFO - __main__ - train loss is 5.798709876136854\n",
      "Steps:  64%|▋| 9543/15000 [1:00:39<16:41,  5.45it/s, lr=9.39e-6, step_loss=0.05407/18/2023 20:04:02 - INFO - __main__ - train loss is 5.801292795455083\n",
      "Steps:  64%|▋| 9544/15000 [1:00:40<16:42,  5.45it/s, lr=9.39e-6, step_loss=0.00207/18/2023 20:04:02 - INFO - __main__ - train loss is 6.33441724232398\n",
      "Steps:  64%|▋| 9545/15000 [1:00:40<16:35,  5.48it/s, lr=9.39e-6, step_loss=0.53307/18/2023 20:04:02 - INFO - __main__ - train loss is 6.340670857811347\n",
      "Steps:  64%|▋| 9546/15000 [1:00:40<16:28,  5.52it/s, lr=9.39e-6, step_loss=0.00607/18/2023 20:04:02 - INFO - __main__ - train loss is 6.410808969521895\n",
      "Steps:  64%|▋| 9547/15000 [1:00:40<16:23,  5.54it/s, lr=9.39e-6, step_loss=0.07007/18/2023 20:04:02 - INFO - __main__ - train loss is 6.414439701242372\n",
      "Steps:  64%|▋| 9548/15000 [1:00:40<16:20,  5.56it/s, lr=9.39e-6, step_loss=0.00307/18/2023 20:04:03 - INFO - __main__ - train loss is 6.41654173610732\n",
      "Steps:  64%|▋| 9549/15000 [1:00:40<16:17,  5.57it/s, lr=9.39e-6, step_loss=0.00207/18/2023 20:04:03 - INFO - __main__ - train loss is 6.423913258127868\n",
      "Steps:  64%|▋| 9550/15000 [1:00:41<16:16,  5.58it/s, lr=9.39e-6, step_loss=0.00707/18/2023 20:04:03 - INFO - __main__ - train loss is 6.510266560129821\n",
      "Steps:  64%|▋| 9551/15000 [1:00:41<16:15,  5.59it/s, lr=9.39e-6, step_loss=0.08607/18/2023 20:04:03 - INFO - __main__ - train loss is 6.5765624372288585\n",
      "Steps:  64%|▋| 9552/15000 [1:00:41<16:13,  5.60it/s, lr=9.39e-6, step_loss=0.06607/18/2023 20:04:03 - INFO - __main__ - train loss is 7.285194429568946\n",
      "Steps:  64%|▋| 9553/15000 [1:00:41<16:13,  5.60it/s, lr=9.39e-6, step_loss=0.70907/18/2023 20:04:03 - INFO - __main__ - train loss is 7.334132923744619\n",
      "Steps:  64%|▋| 9554/15000 [1:00:41<16:12,  5.60it/s, lr=9.39e-6, step_loss=0.04807/18/2023 20:04:04 - INFO - __main__ - train loss is 7.342825036495924\n",
      "Steps:  64%|▋| 9555/15000 [1:00:42<16:21,  5.55it/s, lr=9.39e-6, step_loss=0.00807/18/2023 20:04:04 - INFO - __main__ - train loss is 7.380993220955133\n",
      "Steps:  64%|▋| 9556/15000 [1:00:42<16:25,  5.53it/s, lr=9.39e-6, step_loss=0.03807/18/2023 20:04:04 - INFO - __main__ - train loss is 7.456791270524263\n",
      "Steps:  64%|▋| 9557/15000 [1:00:42<16:20,  5.55it/s, lr=9.39e-6, step_loss=0.07507/18/2023 20:04:04 - INFO - __main__ - train loss is 7.699614156037569\n",
      "Steps:  64%|▋| 9558/15000 [1:00:42<16:17,  5.56it/s, lr=9.39e-6, step_loss=0.24307/18/2023 20:04:04 - INFO - __main__ - train loss is 7.809174302965403\n",
      "Steps:  64%|▋| 9559/15000 [1:00:42<16:15,  5.58it/s, lr=9.39e-6, step_loss=0.11]07/18/2023 20:04:05 - INFO - __main__ - train loss is 7.984942022711039\n",
      "Steps:  64%|▋| 9560/15000 [1:00:42<16:13,  5.59it/s, lr=9.39e-6, step_loss=0.17607/18/2023 20:04:05 - INFO - __main__ - train loss is 8.17751819267869\n",
      "Steps:  64%|▋| 9561/15000 [1:00:43<16:11,  5.60it/s, lr=9.39e-6, step_loss=0.19307/18/2023 20:04:05 - INFO - __main__ - train loss is 8.395203489810228\n",
      "Steps:  64%|▋| 9562/15000 [1:00:43<16:10,  5.60it/s, lr=9.39e-6, step_loss=0.21807/18/2023 20:04:05 - INFO - __main__ - train loss is 8.480336342006922\n",
      "Steps:  64%|▋| 9563/15000 [1:00:43<16:09,  5.61it/s, lr=9.39e-6, step_loss=0.08507/18/2023 20:04:05 - INFO - __main__ - train loss is 8.500340070575476\n",
      "Steps:  64%|▋| 9564/15000 [1:00:43<16:19,  5.55it/s, lr=9.39e-6, step_loss=0.02]07/18/2023 20:04:05 - INFO - __main__ - train loss is 8.557427577674389\n",
      "Steps:  64%|▋| 9565/15000 [1:00:43<16:16,  5.56it/s, lr=9.39e-6, step_loss=0.05707/18/2023 20:04:06 - INFO - __main__ - train loss is 8.830595158040524\n",
      "Steps:  64%|▋| 9566/15000 [1:00:44<16:14,  5.58it/s, lr=9.39e-6, step_loss=0.27307/18/2023 20:04:06 - INFO - __main__ - train loss is 9.00998704880476\n",
      "Steps:  64%|▋| 9567/15000 [1:00:44<16:13,  5.58it/s, lr=9.39e-6, step_loss=0.17907/18/2023 20:04:06 - INFO - __main__ - train loss is 9.018193794414401\n",
      "Steps:  64%|▋| 9568/15000 [1:00:44<16:18,  5.55it/s, lr=9.39e-6, step_loss=0.00807/18/2023 20:04:06 - INFO - __main__ - train loss is 9.053075080737472\n",
      "Steps:  64%|▋| 9569/15000 [1:00:44<16:15,  5.56it/s, lr=9.39e-6, step_loss=0.03407/18/2023 20:04:06 - INFO - __main__ - train loss is 9.18892071209848\n",
      "Steps:  64%|▋| 9570/15000 [1:00:44<16:13,  5.58it/s, lr=9.39e-6, step_loss=0.13607/18/2023 20:04:07 - INFO - __main__ - train loss is 9.394202833995223\n",
      "Steps:  64%|▋| 9571/15000 [1:00:44<16:12,  5.58it/s, lr=9.39e-6, step_loss=0.20507/18/2023 20:04:07 - INFO - __main__ - train loss is 9.550072779878974\n",
      "Steps:  64%|▋| 9572/15000 [1:00:45<16:11,  5.59it/s, lr=9.39e-6, step_loss=0.15607/18/2023 20:04:07 - INFO - __main__ - train loss is 9.690950697287917\n",
      "Steps:  64%|▋| 9573/15000 [1:00:45<16:09,  5.60it/s, lr=9.39e-6, step_loss=0.14107/18/2023 20:04:07 - INFO - __main__ - train loss is 9.839263221248984\n",
      "Steps:  64%|▋| 9574/15000 [1:00:45<16:08,  5.60it/s, lr=9.39e-6, step_loss=0.14807/18/2023 20:04:07 - INFO - __main__ - train loss is 9.848705114796758\n",
      "Steps:  64%|▋| 9575/15000 [1:00:45<16:15,  5.56it/s, lr=9.39e-6, step_loss=0.00907/18/2023 20:04:07 - INFO - __main__ - train loss is 9.969902018085122\n",
      "Steps:  64%|▋| 9576/15000 [1:00:45<16:21,  5.53it/s, lr=9.39e-6, step_loss=0.12107/18/2023 20:04:08 - INFO - __main__ - train loss is 9.98801557905972\n",
      "Steps:  64%|▋| 9577/15000 [1:00:45<16:23,  5.51it/s, lr=9.39e-6, step_loss=0.01807/18/2023 20:04:08 - INFO - __main__ - train loss is 9.994437546469271\n",
      "Steps:  64%|▋| 9578/15000 [1:00:46<16:28,  5.49it/s, lr=9.39e-6, step_loss=0.00607/18/2023 20:04:08 - INFO - __main__ - train loss is 10.004395511932671\n",
      "Steps:  64%|▋| 9579/15000 [1:00:46<16:26,  5.49it/s, lr=9.39e-6, step_loss=0.00907/18/2023 20:04:08 - INFO - __main__ - train loss is 10.074742865748703\n",
      "Steps:  64%|▋| 9580/15000 [1:00:46<16:20,  5.53it/s, lr=9.39e-6, step_loss=0.07007/18/2023 20:04:08 - INFO - __main__ - train loss is 10.312821221537888\n",
      "Steps:  64%|▋| 9581/15000 [1:00:46<16:19,  5.53it/s, lr=9.39e-6, step_loss=0.23807/18/2023 20:04:09 - INFO - __main__ - train loss is 10.344343026168644\n",
      "Steps:  64%|▋| 9582/15000 [1:00:46<16:15,  5.55it/s, lr=9.39e-6, step_loss=0.03107/18/2023 20:04:09 - INFO - __main__ - train loss is 10.346816416829824\n",
      "Steps:  64%|▋| 9583/15000 [1:00:47<16:16,  5.55it/s, lr=9.39e-6, step_loss=0.00207/18/2023 20:04:09 - INFO - __main__ - train loss is 10.562462639063597\n",
      "Steps:  64%|▋| 9584/15000 [1:00:47<16:17,  5.54it/s, lr=9.39e-6, step_loss=0.21607/18/2023 20:04:09 - INFO - __main__ - train loss is 10.825211685150862\n",
      "Steps:  64%|▋| 9585/15000 [1:00:47<16:13,  5.56it/s, lr=9.39e-6, step_loss=0.26307/18/2023 20:04:09 - INFO - __main__ - train loss is 10.838331243023276\n",
      "Steps:  64%|▋| 9586/15000 [1:00:47<16:10,  5.58it/s, lr=9.39e-6, step_loss=0.01307/18/2023 20:04:09 - INFO - __main__ - train loss is 11.298561414703727\n",
      "Steps:  64%|▋| 9587/15000 [1:00:47<16:08,  5.59it/s, lr=9.39e-6, step_loss=0.46]07/18/2023 20:04:10 - INFO - __main__ - train loss is 11.301386850886047\n",
      "Steps:  64%|▋| 9588/15000 [1:00:47<16:06,  5.60it/s, lr=9.39e-6, step_loss=0.00207/18/2023 20:04:10 - INFO - __main__ - train loss is 11.461521971039474\n",
      "Steps:  64%|▋| 9589/15000 [1:00:48<16:05,  5.60it/s, lr=9.39e-6, step_loss=0.16]07/18/2023 20:04:10 - INFO - __main__ - train loss is 11.481622611172497\n",
      "Steps:  64%|▋| 9590/15000 [1:00:48<16:04,  5.61it/s, lr=9.38e-6, step_loss=0.02007/18/2023 20:04:10 - INFO - __main__ - train loss is 11.655568127520382\n",
      "Steps:  64%|▋| 9591/15000 [1:00:48<16:03,  5.61it/s, lr=9.38e-6, step_loss=0.17407/18/2023 20:04:10 - INFO - __main__ - train loss is 11.689214115031064\n",
      "Steps:  64%|▋| 9592/15000 [1:00:48<16:02,  5.62it/s, lr=9.38e-6, step_loss=0.03307/18/2023 20:04:10 - INFO - __main__ - train loss is 11.96838838327676\n",
      "Steps:  64%|▋| 9593/15000 [1:00:48<16:03,  5.61it/s, lr=9.38e-6, step_loss=0.27907/18/2023 20:04:11 - INFO - __main__ - train loss is 12.241720502264798\n",
      "Steps:  64%|▋| 9594/15000 [1:00:49<16:04,  5.60it/s, lr=9.38e-6, step_loss=0.27307/18/2023 20:04:11 - INFO - __main__ - train loss is 12.837772076018155\n",
      "Steps:  64%|▋| 9595/15000 [1:00:49<16:04,  5.60it/s, lr=9.38e-6, step_loss=0.59607/18/2023 20:04:11 - INFO - __main__ - train loss is 12.855993137694895\n",
      "Steps:  64%|▋| 9596/15000 [1:00:49<16:03,  5.61it/s, lr=9.38e-6, step_loss=0.01807/18/2023 20:04:11 - INFO - __main__ - train loss is 12.914302830584347\n",
      "Steps:  64%|▋| 9597/15000 [1:00:49<16:03,  5.61it/s, lr=9.38e-6, step_loss=0.05807/18/2023 20:04:11 - INFO - __main__ - train loss is 12.930919201113284\n",
      "Steps:  64%|▋| 9598/15000 [1:00:49<16:01,  5.62it/s, lr=9.38e-6, step_loss=0.01607/18/2023 20:04:12 - INFO - __main__ - train loss is 13.352323860861361\n",
      "Steps:  64%|▋| 9599/15000 [1:00:49<16:02,  5.61it/s, lr=9.38e-6, step_loss=0.42107/18/2023 20:04:12 - INFO - __main__ - train loss is 13.384346568025649\n",
      "Steps:  64%|▋| 9600/15000 [1:00:50<16:02,  5.61it/s, lr=9.38e-6, step_loss=0.03207/18/2023 20:04:12 - INFO - __main__ - train loss is 13.498446159996092\n",
      "Steps:  64%|▋| 9601/15000 [1:00:50<16:02,  5.61it/s, lr=9.38e-6, step_loss=0.11407/18/2023 20:04:12 - INFO - __main__ - train loss is 13.599357173778117\n",
      "Steps:  64%|▋| 9602/15000 [1:00:50<16:02,  5.61it/s, lr=9.38e-6, step_loss=0.10107/18/2023 20:04:12 - INFO - __main__ - train loss is 13.603613566607237\n",
      "Steps:  64%|▋| 9603/15000 [1:00:50<22:07,  4.07it/s, lr=9.38e-6, step_loss=0.00407/18/2023 20:04:13 - INFO - __main__ - Per validation step average loss is 0.002526788040995598\n",
      "07/18/2023 20:04:13 - INFO - __main__ - Cumulative validation average loss is 0.002526788040995598\n",
      "07/18/2023 20:04:13 - INFO - __main__ - Per validation step average loss is 0.6974838972091675\n",
      "07/18/2023 20:04:13 - INFO - __main__ - Cumulative validation average loss is 0.7000106852501631\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Per validation step average loss is 0.033937156200408936\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Cumulative validation average loss is 0.733947841450572\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Per validation step average loss is 0.2268334925174713\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Cumulative validation average loss is 0.9607813339680433\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Per validation step average loss is 0.28727492690086365\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Cumulative validation average loss is 1.248056260868907\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Per validation step average loss is 0.20244251191616058\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Cumulative validation average loss is 1.4504987727850676\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Per validation step average loss is 0.057472798973321915\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Cumulative validation average loss is 1.5079715717583895\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Per validation step average loss is 0.2918856739997864\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Cumulative validation average loss is 1.7998572457581758\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Per validation step average loss is 0.09210476279258728\n",
      "07/18/2023 20:04:14 - INFO - __main__ - Cumulative validation average loss is 1.8919620085507631\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Per validation step average loss is 0.05611713230609894\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Cumulative validation average loss is 1.948079140856862\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Per validation step average loss is 0.09944944828748703\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Cumulative validation average loss is 2.047528589144349\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Per validation step average loss is 0.0019001452019438148\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Cumulative validation average loss is 2.049428734346293\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Average validation loss for Epoch 98 is 0.17078572786219107\n",
      "07/18/2023 20:04:15 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:04:28 - INFO - __main__ - Starting epoch 99\n",
      "07/18/2023 20:04:29 - INFO - __main__ - train loss is 0.01837872713804245\n",
      "Steps:  64%|▋| 9604/15000 [1:01:07<7:32:19,  5.03s/it, lr=9.38e-6, step_loss=0.007/18/2023 20:04:29 - INFO - __main__ - train loss is 0.05941642448306084\n",
      "Steps:  64%|▋| 9605/15000 [1:01:07<5:21:32,  3.58s/it, lr=9.38e-6, step_loss=0.007/18/2023 20:04:29 - INFO - __main__ - train loss is 0.45288578793406487\n",
      "Steps:  64%|▋| 9606/15000 [1:01:07<3:50:05,  2.56s/it, lr=9.38e-6, step_loss=0.307/18/2023 20:04:29 - INFO - __main__ - train loss is 0.4588561006821692\n",
      "Steps:  64%|▋| 9607/15000 [1:01:07<2:45:52,  1.85s/it, lr=9.38e-6, step_loss=0.007/18/2023 20:04:29 - INFO - __main__ - train loss is 0.49114984134212136\n",
      "Steps:  64%|▋| 9608/15000 [1:01:07<2:00:55,  1.35s/it, lr=9.38e-6, step_loss=0.007/18/2023 20:04:30 - INFO - __main__ - train loss is 0.576193465385586\n",
      "Steps:  64%|▋| 9609/15000 [1:01:07<1:29:29,  1.00it/s, lr=9.38e-6, step_loss=0.007/18/2023 20:04:30 - INFO - __main__ - train loss is 0.6114692003466189\n",
      "Steps:  64%|▋| 9610/15000 [1:01:08<1:07:35,  1.33it/s, lr=9.38e-6, step_loss=0.007/18/2023 20:04:30 - INFO - __main__ - train loss is 0.6553323552943766\n",
      "Steps:  64%|▋| 9611/15000 [1:01:08<52:14,  1.72it/s, lr=9.38e-6, step_loss=0.04307/18/2023 20:04:30 - INFO - __main__ - train loss is 0.6577709247358143\n",
      "Steps:  64%|▋| 9612/15000 [1:01:08<41:26,  2.17it/s, lr=9.38e-6, step_loss=0.00207/18/2023 20:04:30 - INFO - __main__ - train loss is 0.9693131973035634\n",
      "Steps:  64%|▋| 9613/15000 [1:01:08<33:47,  2.66it/s, lr=9.38e-6, step_loss=0.31207/18/2023 20:04:30 - INFO - __main__ - train loss is 1.1301233400590718\n",
      "Steps:  64%|▋| 9614/15000 [1:01:08<28:35,  3.14it/s, lr=9.38e-6, step_loss=0.16107/18/2023 20:04:31 - INFO - __main__ - train loss is 1.378206752706319\n",
      "Steps:  64%|▋| 9615/15000 [1:01:09<24:52,  3.61it/s, lr=9.38e-6, step_loss=0.24807/18/2023 20:04:31 - INFO - __main__ - train loss is 1.3923845519311726\n",
      "Steps:  64%|▋| 9616/15000 [1:01:09<22:12,  4.04it/s, lr=9.38e-6, step_loss=0.01407/18/2023 20:04:31 - INFO - __main__ - train loss is 1.4045317242853343\n",
      "Steps:  64%|▋| 9617/15000 [1:01:09<20:20,  4.41it/s, lr=9.38e-6, step_loss=0.01207/18/2023 20:04:31 - INFO - __main__ - train loss is 1.407406706130132\n",
      "Steps:  64%|▋| 9618/15000 [1:01:09<19:02,  4.71it/s, lr=9.38e-6, step_loss=0.00207/18/2023 20:04:31 - INFO - __main__ - train loss is 1.4132075251545757\n",
      "Steps:  64%|▋| 9619/15000 [1:01:09<18:07,  4.95it/s, lr=9.38e-6, step_loss=0.00507/18/2023 20:04:32 - INFO - __main__ - train loss is 2.1200382651295513\n",
      "Steps:  64%|▋| 9620/15000 [1:01:09<17:28,  5.13it/s, lr=9.38e-6, step_loss=0.70707/18/2023 20:04:32 - INFO - __main__ - train loss is 2.14857705286704\n",
      "Steps:  64%|▋| 9621/15000 [1:01:10<17:02,  5.26it/s, lr=9.38e-6, step_loss=0.02807/18/2023 20:04:32 - INFO - __main__ - train loss is 2.3719313924666494\n",
      "Steps:  64%|▋| 9622/15000 [1:01:10<16:43,  5.36it/s, lr=9.38e-6, step_loss=0.22307/18/2023 20:04:32 - INFO - __main__ - train loss is 2.377305845497176\n",
      "Steps:  64%|▋| 9623/15000 [1:01:10<16:30,  5.43it/s, lr=9.38e-6, step_loss=0.00507/18/2023 20:04:32 - INFO - __main__ - train loss is 2.396981618134305\n",
      "Steps:  64%|▋| 9624/15000 [1:01:10<16:21,  5.48it/s, lr=9.38e-6, step_loss=0.01907/18/2023 20:04:32 - INFO - __main__ - train loss is 2.3999535648617893\n",
      "Steps:  64%|▋| 9625/15000 [1:01:10<16:15,  5.51it/s, lr=9.38e-6, step_loss=0.00207/18/2023 20:04:33 - INFO - __main__ - train loss is 2.439698828617111\n",
      "Steps:  64%|▋| 9626/15000 [1:01:11<16:17,  5.50it/s, lr=9.38e-6, step_loss=0.03907/18/2023 20:04:33 - INFO - __main__ - train loss is 2.5278357400093228\n",
      "Steps:  64%|▋| 9627/15000 [1:01:11<16:11,  5.53it/s, lr=9.38e-6, step_loss=0.08807/18/2023 20:04:33 - INFO - __main__ - train loss is 3.2565031780395657\n",
      "Steps:  64%|▋| 9628/15000 [1:01:11<16:07,  5.55it/s, lr=9.38e-6, step_loss=0.72907/18/2023 20:04:33 - INFO - __main__ - train loss is 3.3881018592510372\n",
      "Steps:  64%|▋| 9629/15000 [1:01:11<16:04,  5.57it/s, lr=9.38e-6, step_loss=0.13207/18/2023 20:04:33 - INFO - __main__ - train loss is 3.4800418673548847\n",
      "Steps:  64%|▋| 9630/15000 [1:01:11<16:02,  5.58it/s, lr=9.38e-6, step_loss=0.09107/18/2023 20:04:34 - INFO - __main__ - train loss is 3.531813735375181\n",
      "Steps:  64%|▋| 9631/15000 [1:01:11<16:01,  5.58it/s, lr=9.38e-6, step_loss=0.05107/18/2023 20:04:34 - INFO - __main__ - train loss is 3.854453260311857\n",
      "Steps:  64%|▋| 9632/15000 [1:01:12<16:02,  5.58it/s, lr=9.38e-6, step_loss=0.32307/18/2023 20:04:34 - INFO - __main__ - train loss is 4.062444249400869\n",
      "Steps:  64%|▋| 9633/15000 [1:01:12<16:02,  5.58it/s, lr=9.38e-6, step_loss=0.20807/18/2023 20:04:34 - INFO - __main__ - train loss is 4.582803825149313\n",
      "Steps:  64%|▋| 9634/15000 [1:01:12<16:01,  5.58it/s, lr=9.38e-6, step_loss=0.52]07/18/2023 20:04:34 - INFO - __main__ - train loss is 4.866251955041662\n",
      "Steps:  64%|▋| 9635/15000 [1:01:12<16:02,  5.57it/s, lr=9.38e-6, step_loss=0.28307/18/2023 20:04:34 - INFO - __main__ - train loss is 4.887297116452828\n",
      "Steps:  64%|▋| 9636/15000 [1:01:12<16:02,  5.58it/s, lr=9.38e-6, step_loss=0.02107/18/2023 20:04:35 - INFO - __main__ - train loss is 4.925721016013995\n",
      "Steps:  64%|▋| 9637/15000 [1:01:12<16:02,  5.57it/s, lr=9.38e-6, step_loss=0.03807/18/2023 20:04:35 - INFO - __main__ - train loss is 5.429414656246081\n",
      "Steps:  64%|▋| 9638/15000 [1:01:13<16:00,  5.58it/s, lr=9.38e-6, step_loss=0.50407/18/2023 20:04:35 - INFO - __main__ - train loss is 5.44006009423174\n",
      "Steps:  64%|▋| 9639/15000 [1:01:13<16:01,  5.57it/s, lr=9.38e-6, step_loss=0.01007/18/2023 20:04:35 - INFO - __main__ - train loss is 5.449960273923352\n",
      "Steps:  64%|▋| 9640/15000 [1:01:13<16:00,  5.58it/s, lr=9.38e-6, step_loss=0.00907/18/2023 20:04:35 - INFO - __main__ - train loss is 5.664917153539136\n",
      "Steps:  64%|▋| 9641/15000 [1:01:13<16:02,  5.57it/s, lr=9.38e-6, step_loss=0.21507/18/2023 20:04:36 - INFO - __main__ - train loss is 5.819717359961942\n",
      "Steps:  64%|▋| 9642/15000 [1:01:13<16:00,  5.58it/s, lr=9.38e-6, step_loss=0.15507/18/2023 20:04:36 - INFO - __main__ - train loss is 5.824720510514453\n",
      "Steps:  64%|▋| 9643/15000 [1:01:14<16:00,  5.58it/s, lr=9.38e-6, step_loss=0.00507/18/2023 20:04:36 - INFO - __main__ - train loss is 5.837686559418216\n",
      "Steps:  64%|▋| 9644/15000 [1:01:14<16:00,  5.58it/s, lr=9.38e-6, step_loss=0.01307/18/2023 20:04:36 - INFO - __main__ - train loss is 5.841020944295451\n",
      "Steps:  64%|▋| 9645/15000 [1:01:14<15:59,  5.58it/s, lr=9.38e-6, step_loss=0.00307/18/2023 20:04:36 - INFO - __main__ - train loss is 5.8606306973379105\n",
      "Steps:  64%|▋| 9646/15000 [1:01:14<15:59,  5.58it/s, lr=9.38e-6, step_loss=0.01907/18/2023 20:04:36 - INFO - __main__ - train loss is 5.861982397036627\n",
      "Steps:  64%|▋| 9647/15000 [1:01:14<15:58,  5.58it/s, lr=9.38e-6, step_loss=0.00107/18/2023 20:04:37 - INFO - __main__ - train loss is 5.866918649757281\n",
      "Steps:  64%|▋| 9648/15000 [1:01:14<15:58,  5.59it/s, lr=9.38e-6, step_loss=0.00407/18/2023 20:04:37 - INFO - __main__ - train loss is 6.086719181621447\n",
      "Steps:  64%|▋| 9649/15000 [1:01:15<15:57,  5.59it/s, lr=9.38e-6, step_loss=0.22]07/18/2023 20:04:37 - INFO - __main__ - train loss is 6.1226095671299845\n",
      "Steps:  64%|▋| 9650/15000 [1:01:15<15:56,  5.59it/s, lr=9.38e-6, step_loss=0.03507/18/2023 20:04:37 - INFO - __main__ - train loss is 6.125153199536726\n",
      "Steps:  64%|▋| 9651/15000 [1:01:15<15:56,  5.59it/s, lr=9.38e-6, step_loss=0.00207/18/2023 20:04:37 - INFO - __main__ - train loss is 6.138911830028519\n",
      "Steps:  64%|▋| 9652/15000 [1:01:15<15:56,  5.59it/s, lr=9.38e-6, step_loss=0.01307/18/2023 20:04:37 - INFO - __main__ - train loss is 6.311791436513886\n",
      "Steps:  64%|▋| 9653/15000 [1:01:15<15:55,  5.59it/s, lr=9.38e-6, step_loss=0.17307/18/2023 20:04:38 - INFO - __main__ - train loss is 6.456052871188149\n",
      "Steps:  64%|▋| 9654/15000 [1:01:16<15:55,  5.59it/s, lr=9.38e-6, step_loss=0.14407/18/2023 20:04:38 - INFO - __main__ - train loss is 6.478821219643578\n",
      "Steps:  64%|▋| 9655/15000 [1:01:16<15:56,  5.59it/s, lr=9.38e-6, step_loss=0.02207/18/2023 20:04:38 - INFO - __main__ - train loss is 6.787471653660759\n",
      "Steps:  64%|▋| 9656/15000 [1:01:16<15:56,  5.59it/s, lr=9.38e-6, step_loss=0.30907/18/2023 20:04:38 - INFO - __main__ - train loss is 7.116585852345452\n",
      "Steps:  64%|▋| 9657/15000 [1:01:16<15:55,  5.59it/s, lr=9.38e-6, step_loss=0.32907/18/2023 20:04:38 - INFO - __main__ - train loss is 7.180117474636063\n",
      "Steps:  64%|▋| 9658/15000 [1:01:16<15:55,  5.59it/s, lr=9.38e-6, step_loss=0.06307/18/2023 20:04:39 - INFO - __main__ - train loss is 7.182545857038349\n",
      "Steps:  64%|▋| 9659/15000 [1:01:16<15:55,  5.59it/s, lr=9.38e-6, step_loss=0.00207/18/2023 20:04:39 - INFO - __main__ - train loss is 7.277231500949711\n",
      "Steps:  64%|▋| 9660/15000 [1:01:17<15:54,  5.59it/s, lr=9.38e-6, step_loss=0.09407/18/2023 20:04:39 - INFO - __main__ - train loss is 7.365830750670284\n",
      "Steps:  64%|▋| 9661/15000 [1:01:17<16:00,  5.56it/s, lr=9.38e-6, step_loss=0.08807/18/2023 20:04:39 - INFO - __main__ - train loss is 7.643336893524975\n",
      "Steps:  64%|▋| 9662/15000 [1:01:17<16:07,  5.52it/s, lr=9.38e-6, step_loss=0.27807/18/2023 20:04:39 - INFO - __main__ - train loss is 7.646092508453876\n",
      "Steps:  64%|▋| 9663/15000 [1:01:17<16:05,  5.53it/s, lr=9.38e-6, step_loss=0.00207/18/2023 20:04:39 - INFO - __main__ - train loss is 7.693731766659766\n",
      "Steps:  64%|▋| 9664/15000 [1:01:17<16:01,  5.55it/s, lr=9.38e-6, step_loss=0.04707/18/2023 20:04:40 - INFO - __main__ - train loss is 7.7195861344225705\n",
      "Steps:  64%|▋| 9665/15000 [1:01:18<15:59,  5.56it/s, lr=9.38e-6, step_loss=0.02507/18/2023 20:04:40 - INFO - __main__ - train loss is 8.223478436935693\n",
      "Steps:  64%|▋| 9666/15000 [1:01:18<15:57,  5.57it/s, lr=9.38e-6, step_loss=0.50407/18/2023 20:04:40 - INFO - __main__ - train loss is 8.479287058580667\n",
      "Steps:  64%|▋| 9667/15000 [1:01:18<15:58,  5.56it/s, lr=9.38e-6, step_loss=0.25607/18/2023 20:04:40 - INFO - __main__ - train loss is 8.66363062011078\n",
      "Steps:  64%|▋| 9668/15000 [1:01:18<16:06,  5.52it/s, lr=9.38e-6, step_loss=0.18407/18/2023 20:04:40 - INFO - __main__ - train loss is 9.179952458012849\n",
      "Steps:  64%|▋| 9669/15000 [1:01:18<16:04,  5.53it/s, lr=9.37e-6, step_loss=0.51607/18/2023 20:04:41 - INFO - __main__ - train loss is 9.233513296116143\n",
      "Steps:  64%|▋| 9670/15000 [1:01:18<16:01,  5.54it/s, lr=9.37e-6, step_loss=0.05307/18/2023 20:04:41 - INFO - __main__ - train loss is 9.279028982389718\n",
      "Steps:  64%|▋| 9671/15000 [1:01:19<16:00,  5.55it/s, lr=9.37e-6, step_loss=0.04507/18/2023 20:04:41 - INFO - __main__ - train loss is 9.599043548572809\n",
      "Steps:  64%|▋| 9672/15000 [1:01:19<15:57,  5.57it/s, lr=9.37e-6, step_loss=0.32]07/18/2023 20:04:41 - INFO - __main__ - train loss is 9.811992332804948\n",
      "Steps:  64%|▋| 9673/15000 [1:01:19<15:56,  5.57it/s, lr=9.37e-6, step_loss=0.21307/18/2023 20:04:41 - INFO - __main__ - train loss is 10.100506112445146\n",
      "Steps:  64%|▋| 9674/15000 [1:01:19<15:56,  5.57it/s, lr=9.37e-6, step_loss=0.28907/18/2023 20:04:41 - INFO - __main__ - train loss is 10.16742553608492\n",
      "Steps:  64%|▋| 9675/15000 [1:01:19<15:59,  5.55it/s, lr=9.37e-6, step_loss=0.06607/18/2023 20:04:42 - INFO - __main__ - train loss is 10.626042418647557\n",
      "Steps:  65%|▋| 9676/15000 [1:01:20<16:43,  5.31it/s, lr=9.37e-6, step_loss=0.45907/18/2023 20:04:42 - INFO - __main__ - train loss is 10.697045855689794\n",
      "Steps:  65%|▋| 9677/15000 [1:01:20<16:46,  5.29it/s, lr=9.37e-6, step_loss=0.07107/18/2023 20:04:42 - INFO - __main__ - train loss is 10.705066123511642\n",
      "Steps:  65%|▋| 9678/15000 [1:01:20<16:56,  5.23it/s, lr=9.37e-6, step_loss=0.00807/18/2023 20:04:42 - INFO - __main__ - train loss is 11.017821052577347\n",
      "Steps:  65%|▋| 9679/15000 [1:01:20<17:01,  5.21it/s, lr=9.37e-6, step_loss=0.31307/18/2023 20:04:42 - INFO - __main__ - train loss is 11.019832605030388\n",
      "Steps:  65%|▋| 9680/15000 [1:01:20<17:04,  5.19it/s, lr=9.37e-6, step_loss=0.00207/18/2023 20:04:43 - INFO - __main__ - train loss is 11.208250099327415\n",
      "Steps:  65%|▋| 9681/15000 [1:01:20<17:06,  5.18it/s, lr=9.37e-6, step_loss=0.18807/18/2023 20:04:43 - INFO - __main__ - train loss is 11.228218970354646\n",
      "Steps:  65%|▋| 9682/15000 [1:01:21<17:08,  5.17it/s, lr=9.37e-6, step_loss=0.02]07/18/2023 20:04:43 - INFO - __main__ - train loss is 11.282584452535957\n",
      "Steps:  65%|▋| 9683/15000 [1:01:21<17:08,  5.17it/s, lr=9.37e-6, step_loss=0.05407/18/2023 20:04:43 - INFO - __main__ - train loss is 11.323087276425213\n",
      "Steps:  65%|▋| 9684/15000 [1:01:21<17:09,  5.17it/s, lr=9.37e-6, step_loss=0.04007/18/2023 20:04:43 - INFO - __main__ - train loss is 11.327196908649057\n",
      "Steps:  65%|▋| 9685/15000 [1:01:21<17:10,  5.16it/s, lr=9.37e-6, step_loss=0.00407/18/2023 20:04:44 - INFO - __main__ - train loss is 11.630547178443521\n",
      "Steps:  65%|▋| 9686/15000 [1:01:21<17:09,  5.16it/s, lr=9.37e-6, step_loss=0.30307/18/2023 20:04:44 - INFO - __main__ - train loss is 11.639093483332545\n",
      "Steps:  65%|▋| 9687/15000 [1:01:22<17:11,  5.15it/s, lr=9.37e-6, step_loss=0.00807/18/2023 20:04:44 - INFO - __main__ - train loss is 11.792277360800654\n",
      "Steps:  65%|▋| 9688/15000 [1:01:22<17:12,  5.14it/s, lr=9.37e-6, step_loss=0.15307/18/2023 20:04:44 - INFO - __main__ - train loss is 11.803258328232914\n",
      "Steps:  65%|▋| 9689/15000 [1:01:22<17:12,  5.15it/s, lr=9.37e-6, step_loss=0.01107/18/2023 20:04:44 - INFO - __main__ - train loss is 11.834018646273762\n",
      "Steps:  65%|▋| 9690/15000 [1:01:22<17:11,  5.15it/s, lr=9.37e-6, step_loss=0.03007/18/2023 20:04:45 - INFO - __main__ - train loss is 12.325297175440937\n",
      "Steps:  65%|▋| 9691/15000 [1:01:22<17:10,  5.15it/s, lr=9.37e-6, step_loss=0.49107/18/2023 20:04:45 - INFO - __main__ - train loss is 12.361058468464762\n",
      "Steps:  65%|▋| 9692/15000 [1:01:23<17:10,  5.15it/s, lr=9.37e-6, step_loss=0.03507/18/2023 20:04:45 - INFO - __main__ - train loss is 12.38459066906944\n",
      "Steps:  65%|▋| 9693/15000 [1:01:23<17:13,  5.14it/s, lr=9.37e-6, step_loss=0.02307/18/2023 20:04:45 - INFO - __main__ - train loss is 12.696729107294232\n",
      "Steps:  65%|▋| 9694/15000 [1:01:23<17:14,  5.13it/s, lr=9.37e-6, step_loss=0.31207/18/2023 20:04:45 - INFO - __main__ - train loss is 12.698935547145084\n",
      "Steps:  65%|▋| 9695/15000 [1:01:23<17:14,  5.13it/s, lr=9.37e-6, step_loss=0.00207/18/2023 20:04:46 - INFO - __main__ - train loss is 12.703705775318667\n",
      "Steps:  65%|▋| 9696/15000 [1:01:23<17:20,  5.10it/s, lr=9.37e-6, step_loss=0.00407/18/2023 20:04:46 - INFO - __main__ - train loss is 12.763060020981357\n",
      "Steps:  65%|▋| 9697/15000 [1:01:24<17:18,  5.10it/s, lr=9.37e-6, step_loss=0.05907/18/2023 20:04:46 - INFO - __main__ - train loss is 13.005460398970172\n",
      "Steps:  65%|▋| 9698/15000 [1:01:24<17:15,  5.12it/s, lr=9.37e-6, step_loss=0.24207/18/2023 20:04:46 - INFO - __main__ - train loss is 13.074920455692336\n",
      "Steps:  65%|▋| 9699/15000 [1:01:24<17:13,  5.13it/s, lr=9.37e-6, step_loss=0.06907/18/2023 20:04:47 - INFO - __main__ - train loss is 13.119052449939772\n",
      "Steps:  65%|▋| 9700/15000 [1:01:24<23:54,  3.70it/s, lr=9.37e-6, step_loss=0.04407/18/2023 20:04:47 - INFO - __main__ - Per validation step average loss is 0.2918545603752136\n",
      "07/18/2023 20:04:47 - INFO - __main__ - Cumulative validation average loss is 0.2918545603752136\n",
      "07/18/2023 20:04:47 - INFO - __main__ - Per validation step average loss is 0.062393952161073685\n",
      "07/18/2023 20:04:47 - INFO - __main__ - Cumulative validation average loss is 0.3542485125362873\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Per validation step average loss is 0.410208523273468\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Cumulative validation average loss is 0.7644570358097553\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Per validation step average loss is 0.10301629453897476\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Cumulative validation average loss is 0.8674733303487301\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Per validation step average loss is 0.047145143151283264\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Cumulative validation average loss is 0.9146184735000134\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Per validation step average loss is 0.13861492276191711\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Cumulative validation average loss is 1.0532333962619305\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Per validation step average loss is 0.147294282913208\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Cumulative validation average loss is 1.2005276791751385\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Per validation step average loss is 0.0020430549047887325\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Cumulative validation average loss is 1.2025707340799272\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Per validation step average loss is 0.03557480126619339\n",
      "07/18/2023 20:04:48 - INFO - __main__ - Cumulative validation average loss is 1.2381455353461206\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Per validation step average loss is 0.4095648527145386\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Cumulative validation average loss is 1.6477103880606592\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Per validation step average loss is 0.25783273577690125\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Cumulative validation average loss is 1.9055431238375604\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Per validation step average loss is 0.0064730215817689896\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Cumulative validation average loss is 1.9120161454193294\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Average validation loss for Epoch 99 is 0.15933467878494412\n",
      "07/18/2023 20:04:49 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:05:02 - INFO - __main__ - Starting epoch 100\n",
      "07/18/2023 20:05:03 - INFO - __main__ - train loss is 0.0219707228243351\n",
      "Steps:  65%|▋| 9701/15000 [1:01:41<7:34:12,  5.14s/it, lr=9.37e-6, step_loss=0.007/18/2023 20:05:04 - INFO - __main__ - train loss is 0.11003254726529121\n",
      "Steps:  65%|▋| 9702/15000 [1:01:41<5:32:13,  3.76s/it, lr=9.37e-6, step_loss=0.007/18/2023 20:05:04 - INFO - __main__ - train loss is 0.12464636005461216\n",
      "Steps:  65%|▋| 9703/15000 [1:01:42<4:06:52,  2.80s/it, lr=9.37e-6, step_loss=0.007/18/2023 20:05:05 - INFO - __main__ - train loss is 0.13111447310075164\n",
      "Steps:  65%|▋| 9704/15000 [1:01:43<3:07:11,  2.12s/it, lr=9.37e-6, step_loss=0.007/18/2023 20:05:05 - INFO - __main__ - train loss is 0.26705788588151336\n",
      "Steps:  65%|▋| 9705/15000 [1:01:43<2:26:07,  1.66s/it, lr=9.37e-6, step_loss=0.107/18/2023 20:05:06 - INFO - __main__ - train loss is 0.2985263145528734\n",
      "Steps:  65%|▋| 9706/15000 [1:01:44<1:56:37,  1.32s/it, lr=9.37e-6, step_loss=0.007/18/2023 20:05:06 - INFO - __main__ - train loss is 0.5739790475927293\n",
      "Steps:  65%|▋| 9707/15000 [1:01:44<1:35:59,  1.09s/it, lr=9.37e-6, step_loss=0.207/18/2023 20:05:07 - INFO - __main__ - train loss is 0.899708119686693\n",
      "Steps:  65%|▋| 9708/15000 [1:01:45<1:21:32,  1.08it/s, lr=9.37e-6, step_loss=0.307/18/2023 20:05:07 - INFO - __main__ - train loss is 1.0719935870729387\n",
      "Steps:  65%|▋| 9709/15000 [1:01:45<1:11:20,  1.24it/s, lr=9.37e-6, step_loss=0.107/18/2023 20:05:08 - INFO - __main__ - train loss is 1.1411582282744348\n",
      "Steps:  65%|▋| 9710/15000 [1:01:46<1:04:20,  1.37it/s, lr=9.37e-6, step_loss=0.007/18/2023 20:05:09 - INFO - __main__ - train loss is 1.1465029302053154\n",
      "Steps:  65%|▋| 9711/15000 [1:01:46<59:22,  1.48it/s, lr=9.37e-6, step_loss=0.00507/18/2023 20:05:09 - INFO - __main__ - train loss is 1.4285254660062492\n",
      "Steps:  65%|▋| 9712/15000 [1:01:47<55:56,  1.58it/s, lr=9.37e-6, step_loss=0.28207/18/2023 20:05:10 - INFO - __main__ - train loss is 1.4318527136929333\n",
      "Steps:  65%|▋| 9713/15000 [1:01:47<53:21,  1.65it/s, lr=9.37e-6, step_loss=0.00307/18/2023 20:05:10 - INFO - __main__ - train loss is 1.6436799024231732\n",
      "Steps:  65%|▋| 9714/15000 [1:01:48<51:41,  1.70it/s, lr=9.37e-6, step_loss=0.21207/18/2023 20:05:11 - INFO - __main__ - train loss is 1.7374813039787114\n",
      "Steps:  65%|▋| 9715/15000 [1:01:49<50:57,  1.73it/s, lr=9.37e-6, step_loss=0.09307/18/2023 20:05:11 - INFO - __main__ - train loss is 1.7648433377034962\n",
      "Steps:  65%|▋| 9716/15000 [1:01:49<49:56,  1.76it/s, lr=9.37e-6, step_loss=0.02707/18/2023 20:05:12 - INFO - __main__ - train loss is 1.76897305669263\n",
      "Steps:  65%|▋| 9717/15000 [1:01:50<49:14,  1.79it/s, lr=9.37e-6, step_loss=0.00407/18/2023 20:05:12 - INFO - __main__ - train loss is 1.7729237847961485\n",
      "Steps:  65%|▋| 9718/15000 [1:01:50<48:41,  1.81it/s, lr=9.37e-6, step_loss=0.00307/18/2023 20:05:13 - INFO - __main__ - train loss is 2.123942690435797\n",
      "Steps:  65%|▋| 9719/15000 [1:01:51<48:29,  1.81it/s, lr=9.37e-6, step_loss=0.35107/18/2023 20:05:13 - INFO - __main__ - train loss is 2.130363490432501\n",
      "Steps:  65%|▋| 9720/15000 [1:01:51<48:11,  1.83it/s, lr=9.37e-6, step_loss=0.00607/18/2023 20:05:14 - INFO - __main__ - train loss is 2.2407917343080044\n",
      "Steps:  65%|▋| 9721/15000 [1:01:52<47:59,  1.83it/s, lr=9.37e-6, step_loss=0.11]07/18/2023 20:05:14 - INFO - __main__ - train loss is 2.3376111947000027\n",
      "Steps:  65%|▋| 9722/15000 [1:01:52<47:56,  1.83it/s, lr=9.37e-6, step_loss=0.09607/18/2023 20:05:15 - INFO - __main__ - train loss is 2.340736699756235\n",
      "Steps:  65%|▋| 9723/15000 [1:01:53<47:48,  1.84it/s, lr=9.37e-6, step_loss=0.00307/18/2023 20:05:16 - INFO - __main__ - train loss is 2.5241148001514375\n",
      "Steps:  65%|▋| 9724/15000 [1:01:53<47:48,  1.84it/s, lr=9.37e-6, step_loss=0.18307/18/2023 20:05:16 - INFO - __main__ - train loss is 2.5322608961723745\n",
      "Steps:  65%|▋| 9725/15000 [1:01:54<47:50,  1.84it/s, lr=9.37e-6, step_loss=0.00807/18/2023 20:05:17 - INFO - __main__ - train loss is 2.7654364272020757\n",
      "Steps:  65%|▋| 9726/15000 [1:01:55<47:43,  1.84it/s, lr=9.37e-6, step_loss=0.23307/18/2023 20:05:17 - INFO - __main__ - train loss is 2.8477524309419096\n",
      "Steps:  65%|▋| 9727/15000 [1:01:55<47:40,  1.84it/s, lr=9.37e-6, step_loss=0.08207/18/2023 20:05:18 - INFO - __main__ - train loss is 3.20481795957312\n",
      "Steps:  65%|▋| 9728/15000 [1:01:56<47:37,  1.84it/s, lr=9.37e-6, step_loss=0.35707/18/2023 20:05:18 - INFO - __main__ - train loss is 3.2241795151494443\n",
      "Steps:  65%|▋| 9729/15000 [1:01:56<47:31,  1.85it/s, lr=9.37e-6, step_loss=0.01907/18/2023 20:05:19 - INFO - __main__ - train loss is 3.44014493515715\n",
      "Steps:  65%|▋| 9730/15000 [1:01:57<47:32,  1.85it/s, lr=9.37e-6, step_loss=0.21607/18/2023 20:05:19 - INFO - __main__ - train loss is 3.4436616064049304\n",
      "Steps:  65%|▋| 9731/15000 [1:01:57<47:34,  1.85it/s, lr=9.37e-6, step_loss=0.00307/18/2023 20:05:20 - INFO - __main__ - train loss is 3.944815850351006\n",
      "Steps:  65%|▋| 9732/15000 [1:01:58<47:41,  1.84it/s, lr=9.37e-6, step_loss=0.50107/18/2023 20:05:20 - INFO - __main__ - train loss is 4.256800448987633\n",
      "Steps:  65%|▋| 9733/15000 [1:01:58<47:54,  1.83it/s, lr=9.37e-6, step_loss=0.31207/18/2023 20:05:21 - INFO - __main__ - train loss is 4.265075689647347\n",
      "Steps:  65%|▋| 9734/15000 [1:01:59<47:45,  1.84it/s, lr=9.37e-6, step_loss=0.00807/18/2023 20:05:22 - INFO - __main__ - train loss is 4.287464960012585\n",
      "Steps:  65%|▋| 9735/15000 [1:01:59<47:43,  1.84it/s, lr=9.37e-6, step_loss=0.02207/18/2023 20:05:22 - INFO - __main__ - train loss is 4.384403063450009\n",
      "Steps:  65%|▋| 9736/15000 [1:02:00<47:36,  1.84it/s, lr=9.37e-6, step_loss=0.09607/18/2023 20:05:23 - INFO - __main__ - train loss is 4.893664671573788\n",
      "Steps:  65%|▋| 9737/15000 [1:02:01<47:38,  1.84it/s, lr=9.37e-6, step_loss=0.50907/18/2023 20:05:23 - INFO - __main__ - train loss is 5.129838599357754\n",
      "Steps:  65%|▋| 9738/15000 [1:02:01<47:34,  1.84it/s, lr=9.37e-6, step_loss=0.23607/18/2023 20:05:24 - INFO - __main__ - train loss is 5.654860510025173\n",
      "Steps:  65%|▋| 9739/15000 [1:02:02<49:07,  1.78it/s, lr=9.37e-6, step_loss=0.52507/18/2023 20:05:24 - INFO - __main__ - train loss is 5.713323003146797\n",
      "Steps:  65%|▋| 9740/15000 [1:02:02<50:45,  1.73it/s, lr=9.37e-6, step_loss=0.05807/18/2023 20:05:25 - INFO - __main__ - train loss is 6.262112504336983\n",
      "Steps:  65%|▋| 9741/15000 [1:02:03<51:48,  1.69it/s, lr=9.37e-6, step_loss=0.54907/18/2023 20:05:26 - INFO - __main__ - train loss is 6.457889741752297\n",
      "Steps:  65%|▋| 9742/15000 [1:02:03<50:47,  1.73it/s, lr=9.37e-6, step_loss=0.19607/18/2023 20:05:26 - INFO - __main__ - train loss is 6.460210226010531\n",
      "Steps:  65%|▋| 9743/15000 [1:02:04<49:52,  1.76it/s, lr=9.37e-6, step_loss=0.00207/18/2023 20:05:27 - INFO - __main__ - train loss is 6.461892404011451\n",
      "Steps:  65%|▋| 9744/15000 [1:02:05<49:13,  1.78it/s, lr=9.37e-6, step_loss=0.00107/18/2023 20:05:27 - INFO - __main__ - train loss is 6.747766323736869\n",
      "Steps:  65%|▋| 9745/15000 [1:02:05<48:44,  1.80it/s, lr=9.37e-6, step_loss=0.28607/18/2023 20:05:28 - INFO - __main__ - train loss is 6.989551894715987\n",
      "Steps:  65%|▋| 9746/15000 [1:02:06<48:33,  1.80it/s, lr=9.37e-6, step_loss=0.24207/18/2023 20:05:28 - INFO - __main__ - train loss is 7.276916884235106\n",
      "Steps:  65%|▋| 9747/15000 [1:02:06<48:20,  1.81it/s, lr=9.37e-6, step_loss=0.28707/18/2023 20:05:29 - INFO - __main__ - train loss is 7.4133405316388234\n",
      "Steps:  65%|▋| 9748/15000 [1:02:07<48:03,  1.82it/s, lr=9.36e-6, step_loss=0.13607/18/2023 20:05:29 - INFO - __main__ - train loss is 7.625912390998565\n",
      "Steps:  65%|▋| 9749/15000 [1:02:07<47:53,  1.83it/s, lr=9.36e-6, step_loss=0.21307/18/2023 20:05:30 - INFO - __main__ - train loss is 7.634975807159208\n",
      "Steps:  65%|▋| 9750/15000 [1:02:08<47:54,  1.83it/s, lr=9.36e-6, step_loss=0.00907/18/2023 20:05:30 - INFO - __main__ - train loss is 7.869245157926343\n",
      "Steps:  65%|▋| 9751/15000 [1:02:08<48:00,  1.82it/s, lr=9.36e-6, step_loss=0.23407/18/2023 20:05:31 - INFO - __main__ - train loss is 7.9840845031430945\n",
      "Steps:  65%|▋| 9752/15000 [1:02:09<48:00,  1.82it/s, lr=9.36e-6, step_loss=0.11507/18/2023 20:05:32 - INFO - __main__ - train loss is 7.98729613085743\n",
      "Steps:  65%|▋| 9753/15000 [1:02:09<47:54,  1.83it/s, lr=9.36e-6, step_loss=0.00307/18/2023 20:05:32 - INFO - __main__ - train loss is 8.052728619775735\n",
      "Steps:  65%|▋| 9754/15000 [1:02:10<47:46,  1.83it/s, lr=9.36e-6, step_loss=0.06507/18/2023 20:05:33 - INFO - __main__ - train loss is 8.10480501910206\n",
      "Steps:  65%|▋| 9755/15000 [1:02:11<48:42,  1.79it/s, lr=9.36e-6, step_loss=0.05207/18/2023 20:05:33 - INFO - __main__ - train loss is 8.107643993920647\n",
      "Steps:  65%|▋| 9756/15000 [1:02:11<52:27,  1.67it/s, lr=9.36e-6, step_loss=0.00207/18/2023 20:05:34 - INFO - __main__ - train loss is 8.273869322962128\n",
      "Steps:  65%|▋| 9757/15000 [1:02:12<52:11,  1.67it/s, lr=9.36e-6, step_loss=0.16607/18/2023 20:05:35 - INFO - __main__ - train loss is 8.288090696907602\n",
      "Steps:  65%|▋| 9758/15000 [1:02:12<51:14,  1.70it/s, lr=9.36e-6, step_loss=0.01407/18/2023 20:05:35 - INFO - __main__ - train loss is 8.305924894637428\n",
      "Steps:  65%|▋| 9759/15000 [1:02:13<50:28,  1.73it/s, lr=9.36e-6, step_loss=0.01707/18/2023 20:05:36 - INFO - __main__ - train loss is 8.489784585661255\n",
      "Steps:  65%|▋| 9760/15000 [1:02:14<49:36,  1.76it/s, lr=9.36e-6, step_loss=0.18407/18/2023 20:05:36 - INFO - __main__ - train loss is 8.558197649545036\n",
      "Steps:  65%|▋| 9761/15000 [1:02:14<48:56,  1.78it/s, lr=9.36e-6, step_loss=0.06807/18/2023 20:05:37 - INFO - __main__ - train loss is 8.776807638234459\n",
      "Steps:  65%|▋| 9762/15000 [1:02:15<48:24,  1.80it/s, lr=9.36e-6, step_loss=0.21907/18/2023 20:05:37 - INFO - __main__ - train loss is 9.23652857763227\n",
      "Steps:  65%|▋| 9763/15000 [1:02:15<48:04,  1.82it/s, lr=9.36e-6, step_loss=0.46]07/18/2023 20:05:38 - INFO - __main__ - train loss is 9.253934791660868\n",
      "Steps:  65%|▋| 9764/15000 [1:02:16<47:38,  1.83it/s, lr=9.36e-6, step_loss=0.01707/18/2023 20:05:38 - INFO - __main__ - train loss is 9.37863562849816\n",
      "Steps:  65%|▋| 9765/15000 [1:02:16<47:23,  1.84it/s, lr=9.36e-6, step_loss=0.12507/18/2023 20:05:39 - INFO - __main__ - train loss is 9.789082629955374\n",
      "Steps:  65%|▋| 9766/15000 [1:02:17<47:21,  1.84it/s, lr=9.36e-6, step_loss=0.41]07/18/2023 20:05:39 - INFO - __main__ - train loss is 9.877155496156774\n",
      "Steps:  65%|▋| 9767/15000 [1:02:17<47:36,  1.83it/s, lr=9.36e-6, step_loss=0.08807/18/2023 20:05:40 - INFO - __main__ - train loss is 9.910070548183285\n",
      "Steps:  65%|▋| 9768/15000 [1:02:18<47:35,  1.83it/s, lr=9.36e-6, step_loss=0.03207/18/2023 20:05:41 - INFO - __main__ - train loss is 10.044212842709385\n",
      "Steps:  65%|▋| 9769/15000 [1:02:18<47:32,  1.83it/s, lr=9.36e-6, step_loss=0.13407/18/2023 20:05:41 - INFO - __main__ - train loss is 10.12105753493961\n",
      "Steps:  65%|▋| 9770/15000 [1:02:19<47:40,  1.83it/s, lr=9.36e-6, step_loss=0.07607/18/2023 20:05:42 - INFO - __main__ - train loss is 10.124096887069754\n",
      "Steps:  65%|▋| 9771/15000 [1:02:20<47:38,  1.83it/s, lr=9.36e-6, step_loss=0.00307/18/2023 20:05:42 - INFO - __main__ - train loss is 10.19503265793901\n",
      "Steps:  65%|▋| 9772/15000 [1:02:20<48:04,  1.81it/s, lr=9.36e-6, step_loss=0.07007/18/2023 20:05:43 - INFO - __main__ - train loss is 10.246870824950747\n",
      "Steps:  65%|▋| 9773/15000 [1:02:21<48:07,  1.81it/s, lr=9.36e-6, step_loss=0.05107/18/2023 20:05:43 - INFO - __main__ - train loss is 10.252273700083606\n",
      "Steps:  65%|▋| 9774/15000 [1:02:21<48:13,  1.81it/s, lr=9.36e-6, step_loss=0.00507/18/2023 20:05:44 - INFO - __main__ - train loss is 10.267169783706777\n",
      "Steps:  65%|▋| 9775/15000 [1:02:22<48:23,  1.80it/s, lr=9.36e-6, step_loss=0.01407/18/2023 20:05:44 - INFO - __main__ - train loss is 10.907547782058828\n",
      "Steps:  65%|▋| 9776/15000 [1:02:22<48:30,  1.79it/s, lr=9.36e-6, step_loss=0.64]07/18/2023 20:05:45 - INFO - __main__ - train loss is 11.00119310140144\n",
      "Steps:  65%|▋| 9777/15000 [1:02:23<48:40,  1.79it/s, lr=9.36e-6, step_loss=0.09307/18/2023 20:05:46 - INFO - __main__ - train loss is 11.009858279372565\n",
      "Steps:  65%|▋| 9778/15000 [1:02:23<48:41,  1.79it/s, lr=9.36e-6, step_loss=0.00807/18/2023 20:05:46 - INFO - __main__ - train loss is 11.133739172364585\n",
      "Steps:  65%|▋| 9779/15000 [1:02:24<48:27,  1.80it/s, lr=9.36e-6, step_loss=0.12407/18/2023 20:05:47 - INFO - __main__ - train loss is 11.374464570428245\n",
      "Steps:  65%|▋| 9780/15000 [1:02:25<48:21,  1.80it/s, lr=9.36e-6, step_loss=0.24107/18/2023 20:05:47 - INFO - __main__ - train loss is 11.377042551874183\n",
      "Steps:  65%|▋| 9781/15000 [1:02:25<48:01,  1.81it/s, lr=9.36e-6, step_loss=0.00207/18/2023 20:05:48 - INFO - __main__ - train loss is 11.394541641115211\n",
      "Steps:  65%|▋| 9782/15000 [1:02:26<47:49,  1.82it/s, lr=9.36e-6, step_loss=0.01707/18/2023 20:05:48 - INFO - __main__ - train loss is 11.880936463712715\n",
      "Steps:  65%|▋| 9783/15000 [1:02:26<47:33,  1.83it/s, lr=9.36e-6, step_loss=0.48607/18/2023 20:05:49 - INFO - __main__ - train loss is 12.048225065111183\n",
      "Steps:  65%|▋| 9784/15000 [1:02:27<47:25,  1.83it/s, lr=9.36e-6, step_loss=0.16707/18/2023 20:05:49 - INFO - __main__ - train loss is 12.547954102396034\n",
      "Steps:  65%|█▎| 9785/15000 [1:02:27<47:11,  1.84it/s, lr=9.36e-6, step_loss=0.5]07/18/2023 20:05:50 - INFO - __main__ - train loss is 12.604083904414438\n",
      "Steps:  65%|▋| 9786/15000 [1:02:28<47:04,  1.85it/s, lr=9.36e-6, step_loss=0.05607/18/2023 20:05:50 - INFO - __main__ - train loss is 12.606523939291947\n",
      "Steps:  65%|▋| 9787/15000 [1:02:28<47:11,  1.84it/s, lr=9.36e-6, step_loss=0.00207/18/2023 20:05:51 - INFO - __main__ - train loss is 12.681982816080563\n",
      "Steps:  65%|▋| 9788/15000 [1:02:29<47:07,  1.84it/s, lr=9.36e-6, step_loss=0.07507/18/2023 20:05:52 - INFO - __main__ - train loss is 12.68985563784372\n",
      "Steps:  65%|▋| 9789/15000 [1:02:29<47:04,  1.84it/s, lr=9.36e-6, step_loss=0.00707/18/2023 20:05:52 - INFO - __main__ - train loss is 12.766727941925637\n",
      "Steps:  65%|▋| 9790/15000 [1:02:30<46:56,  1.85it/s, lr=9.36e-6, step_loss=0.07607/18/2023 20:05:53 - INFO - __main__ - train loss is 12.773022479261272\n",
      "Steps:  65%|▋| 9791/15000 [1:02:31<46:58,  1.85it/s, lr=9.36e-6, step_loss=0.00607/18/2023 20:05:53 - INFO - __main__ - train loss is 13.7166610424174\n",
      "Steps:  65%|▋| 9792/15000 [1:02:31<46:57,  1.85it/s, lr=9.36e-6, step_loss=0.94407/18/2023 20:05:54 - INFO - __main__ - train loss is 13.758508871193044\n",
      "Steps:  65%|▋| 9793/15000 [1:02:32<46:55,  1.85it/s, lr=9.36e-6, step_loss=0.04107/18/2023 20:05:54 - INFO - __main__ - train loss is 13.771289110998623\n",
      "Steps:  65%|▋| 9794/15000 [1:02:32<47:20,  1.83it/s, lr=9.36e-6, step_loss=0.01207/18/2023 20:05:55 - INFO - __main__ - train loss is 13.810343370656483\n",
      "Steps:  65%|▋| 9795/15000 [1:02:33<47:09,  1.84it/s, lr=9.36e-6, step_loss=0.03907/18/2023 20:05:55 - INFO - __main__ - train loss is 13.924444393138401\n",
      "Steps:  65%|▋| 9796/15000 [1:02:33<47:06,  1.84it/s, lr=9.36e-6, step_loss=0.11407/18/2023 20:05:56 - INFO - __main__ - train loss is 14.095333845238201\n",
      "Steps:  65%|▋| 9797/15000 [1:02:34<55:37,  1.56it/s, lr=9.36e-6, step_loss=0.17107/18/2023 20:05:57 - INFO - __main__ - Per validation step average loss is 0.0041323695331811905\n",
      "07/18/2023 20:05:57 - INFO - __main__ - Cumulative validation average loss is 0.0041323695331811905\n",
      "07/18/2023 20:05:57 - INFO - __main__ - Per validation step average loss is 0.15395045280456543\n",
      "07/18/2023 20:05:57 - INFO - __main__ - Cumulative validation average loss is 0.15808282233774662\n",
      "07/18/2023 20:05:57 - INFO - __main__ - Per validation step average loss is 0.0792156308889389\n",
      "07/18/2023 20:05:57 - INFO - __main__ - Cumulative validation average loss is 0.23729845322668552\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Per validation step average loss is 0.029172129929065704\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Cumulative validation average loss is 0.26647058315575123\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Per validation step average loss is 0.0319744311273098\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Cumulative validation average loss is 0.298445014283061\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Per validation step average loss is 0.2706710994243622\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Cumulative validation average loss is 0.5691161137074232\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Per validation step average loss is 0.4960653483867645\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Cumulative validation average loss is 1.0651814620941877\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Per validation step average loss is 0.01229589618742466\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Cumulative validation average loss is 1.0774773582816124\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Per validation step average loss is 0.6748296022415161\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Cumulative validation average loss is 1.7523069605231285\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Per validation step average loss is 0.48940685391426086\n",
      "07/18/2023 20:05:58 - INFO - __main__ - Cumulative validation average loss is 2.2417138144373894\n",
      "07/18/2023 20:05:59 - INFO - __main__ - Per validation step average loss is 0.16459548473358154\n",
      "07/18/2023 20:05:59 - INFO - __main__ - Cumulative validation average loss is 2.406309299170971\n",
      "07/18/2023 20:05:59 - INFO - __main__ - Per validation step average loss is 0.0037706056609749794\n",
      "07/18/2023 20:05:59 - INFO - __main__ - Cumulative validation average loss is 2.410079904831946\n",
      "07/18/2023 20:05:59 - INFO - __main__ - Average validation loss for Epoch 100 is 0.20083999206932882\n",
      "07/18/2023 20:05:59 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:06:12 - INFO - __main__ - Starting epoch 101\n",
      "07/18/2023 20:06:12 - INFO - __main__ - train loss is 0.21696704626083374\n",
      "Steps:  65%|▋| 9798/15000 [1:02:50<7:34:56,  5.25s/it, lr=9.36e-6, step_loss=0.207/18/2023 20:06:12 - INFO - __main__ - train loss is 0.24743911437690258\n",
      "Steps:  65%|▋| 9799/15000 [1:02:50<5:23:15,  3.73s/it, lr=9.36e-6, step_loss=0.007/18/2023 20:06:13 - INFO - __main__ - train loss is 0.3727093022316694\n",
      "Steps:  65%|▋| 9800/15000 [1:02:51<3:53:59,  2.70s/it, lr=9.36e-6, step_loss=0.107/18/2023 20:06:13 - INFO - __main__ - train loss is 0.38620354514569044\n",
      "Steps:  65%|▋| 9801/15000 [1:02:51<2:50:06,  1.96s/it, lr=9.36e-6, step_loss=0.007/18/2023 20:06:13 - INFO - __main__ - train loss is 0.5774896321818233\n",
      "Steps:  65%|▋| 9802/15000 [1:02:51<2:05:05,  1.44s/it, lr=9.36e-6, step_loss=0.107/18/2023 20:06:13 - INFO - __main__ - train loss is 0.662523346953094\n",
      "Steps:  65%|▋| 9803/15000 [1:02:51<1:33:12,  1.08s/it, lr=9.36e-6, step_loss=0.007/18/2023 20:06:14 - INFO - __main__ - train loss is 0.7171233100816607\n",
      "Steps:  65%|▋| 9804/15000 [1:02:51<1:10:36,  1.23it/s, lr=9.36e-6, step_loss=0.007/18/2023 20:06:14 - INFO - __main__ - train loss is 0.9113164348527789\n",
      "Steps:  65%|▋| 9805/15000 [1:02:52<54:10,  1.60it/s, lr=9.36e-6, step_loss=0.19407/18/2023 20:06:14 - INFO - __main__ - train loss is 0.9164165104739368\n",
      "Steps:  65%|▋| 9806/15000 [1:02:52<42:39,  2.03it/s, lr=9.36e-6, step_loss=0.00507/18/2023 20:06:14 - INFO - __main__ - train loss is 0.9278442193754017\n",
      "Steps:  65%|▋| 9807/15000 [1:02:52<34:46,  2.49it/s, lr=9.36e-6, step_loss=0.01107/18/2023 20:06:14 - INFO - __main__ - train loss is 1.2393433679826558\n",
      "Steps:  65%|▋| 9808/15000 [1:02:52<29:31,  2.93it/s, lr=9.36e-6, step_loss=0.31107/18/2023 20:06:15 - INFO - __main__ - train loss is 1.2478698487393558\n",
      "Steps:  65%|▋| 9809/15000 [1:02:52<25:38,  3.37it/s, lr=9.36e-6, step_loss=0.00807/18/2023 20:06:15 - INFO - __main__ - train loss is 1.2924293535761535\n",
      "Steps:  65%|▋| 9810/15000 [1:02:53<22:43,  3.81it/s, lr=9.36e-6, step_loss=0.04407/18/2023 20:06:15 - INFO - __main__ - train loss is 1.3122378825210035\n",
      "Steps:  65%|▋| 9811/15000 [1:02:53<20:34,  4.20it/s, lr=9.36e-6, step_loss=0.01907/18/2023 20:06:15 - INFO - __main__ - train loss is 1.434701883699745\n",
      "Steps:  65%|▋| 9812/15000 [1:02:53<19:04,  4.53it/s, lr=9.36e-6, step_loss=0.12207/18/2023 20:06:15 - INFO - __main__ - train loss is 1.441862196661532\n",
      "Steps:  65%|▋| 9813/15000 [1:02:53<17:59,  4.81it/s, lr=9.36e-6, step_loss=0.00707/18/2023 20:06:15 - INFO - __main__ - train loss is 1.634070129133761\n",
      "Steps:  65%|▋| 9814/15000 [1:02:53<17:13,  5.02it/s, lr=9.36e-6, step_loss=0.19207/18/2023 20:06:16 - INFO - __main__ - train loss is 1.7858008602634072\n",
      "Steps:  65%|▋| 9815/15000 [1:02:54<16:43,  5.17it/s, lr=9.36e-6, step_loss=0.15207/18/2023 20:06:16 - INFO - __main__ - train loss is 1.9138085404410958\n",
      "Steps:  65%|▋| 9816/15000 [1:02:54<16:19,  5.29it/s, lr=9.36e-6, step_loss=0.12807/18/2023 20:06:16 - INFO - __main__ - train loss is 1.934584149159491\n",
      "Steps:  65%|▋| 9817/15000 [1:02:54<16:02,  5.38it/s, lr=9.36e-6, step_loss=0.02007/18/2023 20:06:16 - INFO - __main__ - train loss is 1.9929715441539884\n",
      "Steps:  65%|▋| 9818/15000 [1:02:54<15:51,  5.44it/s, lr=9.36e-6, step_loss=0.05807/18/2023 20:06:16 - INFO - __main__ - train loss is 1.99740816000849\n",
      "Steps:  65%|▋| 9819/15000 [1:02:54<15:43,  5.49it/s, lr=9.36e-6, step_loss=0.00407/18/2023 20:06:17 - INFO - __main__ - train loss is 2.2011280739679933\n",
      "Steps:  65%|▋| 9820/15000 [1:02:54<15:38,  5.52it/s, lr=9.36e-6, step_loss=0.20407/18/2023 20:06:17 - INFO - __main__ - train loss is 2.4629139387980103\n",
      "Steps:  65%|▋| 9821/15000 [1:02:55<15:34,  5.54it/s, lr=9.36e-6, step_loss=0.26207/18/2023 20:06:17 - INFO - __main__ - train loss is 2.464313415228389\n",
      "Steps:  65%|▋| 9822/15000 [1:02:55<15:40,  5.51it/s, lr=9.36e-6, step_loss=0.00107/18/2023 20:06:17 - INFO - __main__ - train loss is 2.547016662894748\n",
      "Steps:  65%|▋| 9823/15000 [1:02:55<15:47,  5.46it/s, lr=9.36e-6, step_loss=0.08207/18/2023 20:06:17 - INFO - __main__ - train loss is 2.5694851906737313\n",
      "Steps:  65%|▋| 9824/15000 [1:02:55<15:58,  5.40it/s, lr=9.36e-6, step_loss=0.02207/18/2023 20:06:17 - INFO - __main__ - train loss is 2.606987423612736\n",
      "Steps:  66%|▋| 9825/15000 [1:02:55<15:48,  5.46it/s, lr=9.36e-6, step_loss=0.03707/18/2023 20:06:18 - INFO - __main__ - train loss is 2.6136934807291254\n",
      "Steps:  66%|▋| 9826/15000 [1:02:55<15:41,  5.49it/s, lr=9.35e-6, step_loss=0.00607/18/2023 20:06:18 - INFO - __main__ - train loss is 2.615517392172478\n",
      "Steps:  66%|▋| 9827/15000 [1:02:56<15:36,  5.52it/s, lr=9.35e-6, step_loss=0.00107/18/2023 20:06:18 - INFO - __main__ - train loss is 2.839263423695229\n",
      "Steps:  66%|▋| 9828/15000 [1:02:56<15:33,  5.54it/s, lr=9.35e-6, step_loss=0.22407/18/2023 20:06:18 - INFO - __main__ - train loss is 3.051897748722695\n",
      "Steps:  66%|▋| 9829/15000 [1:02:56<15:30,  5.55it/s, lr=9.35e-6, step_loss=0.21307/18/2023 20:06:18 - INFO - __main__ - train loss is 3.0772370224585757\n",
      "Steps:  66%|▋| 9830/15000 [1:02:56<15:31,  5.55it/s, lr=9.35e-6, step_loss=0.02507/18/2023 20:06:19 - INFO - __main__ - train loss is 3.1062607964267954\n",
      "Steps:  66%|▋| 9831/15000 [1:02:56<15:38,  5.51it/s, lr=9.35e-6, step_loss=0.02907/18/2023 20:06:19 - INFO - __main__ - train loss is 3.1081687696278095\n",
      "Steps:  66%|▋| 9832/15000 [1:02:57<15:51,  5.43it/s, lr=9.35e-6, step_loss=0.00107/18/2023 20:06:19 - INFO - __main__ - train loss is 3.122478775680065\n",
      "Steps:  66%|▋| 9833/15000 [1:02:57<15:51,  5.43it/s, lr=9.35e-6, step_loss=0.01407/18/2023 20:06:19 - INFO - __main__ - train loss is 3.29459061473608\n",
      "Steps:  66%|▋| 9834/15000 [1:02:57<15:50,  5.44it/s, lr=9.35e-6, step_loss=0.17207/18/2023 20:06:19 - INFO - __main__ - train loss is 3.5009379014372826\n",
      "Steps:  66%|▋| 9835/15000 [1:02:57<15:49,  5.44it/s, lr=9.35e-6, step_loss=0.20607/18/2023 20:06:19 - INFO - __main__ - train loss is 3.577997274696827\n",
      "Steps:  66%|▋| 9836/15000 [1:02:57<15:44,  5.47it/s, lr=9.35e-6, step_loss=0.07707/18/2023 20:06:20 - INFO - __main__ - train loss is 3.7054249718785286\n",
      "Steps:  66%|▋| 9837/15000 [1:02:58<15:47,  5.45it/s, lr=9.35e-6, step_loss=0.12707/18/2023 20:06:20 - INFO - __main__ - train loss is 3.873543359339237\n",
      "Steps:  66%|▋| 9838/15000 [1:02:58<15:48,  5.44it/s, lr=9.35e-6, step_loss=0.16807/18/2023 20:06:20 - INFO - __main__ - train loss is 4.492685176432133\n",
      "Steps:  66%|▋| 9839/15000 [1:02:58<15:46,  5.45it/s, lr=9.35e-6, step_loss=0.61907/18/2023 20:06:20 - INFO - __main__ - train loss is 4.715346165001392\n",
      "Steps:  66%|▋| 9840/15000 [1:02:58<15:39,  5.49it/s, lr=9.35e-6, step_loss=0.22307/18/2023 20:06:20 - INFO - __main__ - train loss is 4.718859834130853\n",
      "Steps:  66%|▋| 9841/15000 [1:02:58<15:33,  5.53it/s, lr=9.35e-6, step_loss=0.00307/18/2023 20:06:21 - INFO - __main__ - train loss is 4.814258327241987\n",
      "Steps:  66%|▋| 9842/15000 [1:02:58<15:29,  5.55it/s, lr=9.35e-6, step_loss=0.09507/18/2023 20:06:21 - INFO - __main__ - train loss is 5.32849728083238\n",
      "Steps:  66%|▋| 9843/15000 [1:02:59<15:26,  5.56it/s, lr=9.35e-6, step_loss=0.51407/18/2023 20:06:21 - INFO - __main__ - train loss is 5.566441228147596\n",
      "Steps:  66%|▋| 9844/15000 [1:02:59<15:32,  5.53it/s, lr=9.35e-6, step_loss=0.23807/18/2023 20:06:21 - INFO - __main__ - train loss is 5.58007327793166\n",
      "Steps:  66%|▋| 9845/15000 [1:02:59<15:28,  5.55it/s, lr=9.35e-6, step_loss=0.01307/18/2023 20:06:21 - INFO - __main__ - train loss is 5.8762336182408035\n",
      "Steps:  66%|▋| 9846/15000 [1:02:59<15:26,  5.56it/s, lr=9.35e-6, step_loss=0.29607/18/2023 20:06:21 - INFO - __main__ - train loss is 5.8789443138521165\n",
      "Steps:  66%|▋| 9847/15000 [1:02:59<15:25,  5.57it/s, lr=9.35e-6, step_loss=0.00207/18/2023 20:06:22 - INFO - __main__ - train loss is 5.890255479840562\n",
      "Steps:  66%|▋| 9848/15000 [1:02:59<15:23,  5.58it/s, lr=9.35e-6, step_loss=0.01107/18/2023 20:06:22 - INFO - __main__ - train loss is 6.338629840640351\n",
      "Steps:  66%|▋| 9849/15000 [1:03:00<15:22,  5.58it/s, lr=9.35e-6, step_loss=0.44807/18/2023 20:06:22 - INFO - __main__ - train loss is 6.547992198495194\n",
      "Steps:  66%|▋| 9850/15000 [1:03:00<15:21,  5.59it/s, lr=9.35e-6, step_loss=0.20907/18/2023 20:06:22 - INFO - __main__ - train loss is 6.646378262666985\n",
      "Steps:  66%|▋| 9851/15000 [1:03:00<15:21,  5.59it/s, lr=9.35e-6, step_loss=0.09807/18/2023 20:06:22 - INFO - __main__ - train loss is 6.652438322780654\n",
      "Steps:  66%|▋| 9852/15000 [1:03:00<15:20,  5.59it/s, lr=9.35e-6, step_loss=0.00607/18/2023 20:06:22 - INFO - __main__ - train loss is 6.653877930250019\n",
      "Steps:  66%|▋| 9853/15000 [1:03:00<15:19,  5.60it/s, lr=9.35e-6, step_loss=0.00107/18/2023 20:06:23 - INFO - __main__ - train loss is 6.911566989030689\n",
      "Steps:  66%|▋| 9854/15000 [1:03:01<15:19,  5.60it/s, lr=9.35e-6, step_loss=0.25807/18/2023 20:06:23 - INFO - __main__ - train loss is 7.439950482454151\n",
      "Steps:  66%|▋| 9855/15000 [1:03:01<15:20,  5.59it/s, lr=9.35e-6, step_loss=0.52807/18/2023 20:06:23 - INFO - __main__ - train loss is 8.043644444551319\n",
      "Steps:  66%|▋| 9856/15000 [1:03:01<15:20,  5.59it/s, lr=9.35e-6, step_loss=0.60407/18/2023 20:06:23 - INFO - __main__ - train loss is 8.079402522649616\n",
      "Steps:  66%|▋| 9857/15000 [1:03:01<15:19,  5.59it/s, lr=9.35e-6, step_loss=0.03507/18/2023 20:06:23 - INFO - __main__ - train loss is 8.456651405896991\n",
      "Steps:  66%|▋| 9858/15000 [1:03:01<15:19,  5.59it/s, lr=9.35e-6, step_loss=0.37707/18/2023 20:06:24 - INFO - __main__ - train loss is 8.473717502783984\n",
      "Steps:  66%|▋| 9859/15000 [1:03:01<15:21,  5.58it/s, lr=9.35e-6, step_loss=0.01707/18/2023 20:06:24 - INFO - __main__ - train loss is 8.513024501036853\n",
      "Steps:  66%|▋| 9860/15000 [1:03:02<15:21,  5.58it/s, lr=9.35e-6, step_loss=0.03907/18/2023 20:06:24 - INFO - __main__ - train loss is 8.52488468727097\n",
      "Steps:  66%|▋| 9861/15000 [1:03:02<15:20,  5.58it/s, lr=9.35e-6, step_loss=0.01107/18/2023 20:06:24 - INFO - __main__ - train loss is 8.527070481330156\n",
      "Steps:  66%|▋| 9862/15000 [1:03:02<15:20,  5.58it/s, lr=9.35e-6, step_loss=0.00207/18/2023 20:06:24 - INFO - __main__ - train loss is 8.535805203020573\n",
      "Steps:  66%|▋| 9863/15000 [1:03:02<15:19,  5.58it/s, lr=9.35e-6, step_loss=0.00807/18/2023 20:06:24 - INFO - __main__ - train loss is 9.011522985994816\n",
      "Steps:  66%|▋| 9864/15000 [1:03:02<15:19,  5.58it/s, lr=9.35e-6, step_loss=0.47607/18/2023 20:06:25 - INFO - __main__ - train loss is 9.01446376228705\n",
      "Steps:  66%|▋| 9865/15000 [1:03:03<15:19,  5.58it/s, lr=9.35e-6, step_loss=0.00207/18/2023 20:06:25 - INFO - __main__ - train loss is 9.09078616881743\n",
      "Steps:  66%|▋| 9866/15000 [1:03:03<15:19,  5.59it/s, lr=9.35e-6, step_loss=0.07607/18/2023 20:06:25 - INFO - __main__ - train loss is 9.115061605814844\n",
      "Steps:  66%|▋| 9867/15000 [1:03:03<15:18,  5.59it/s, lr=9.35e-6, step_loss=0.02407/18/2023 20:06:25 - INFO - __main__ - train loss is 9.374764467123896\n",
      "Steps:  66%|▋| 9868/15000 [1:03:03<15:17,  5.59it/s, lr=9.35e-6, step_loss=0.26]07/18/2023 20:06:25 - INFO - __main__ - train loss is 9.46294996375218\n",
      "Steps:  66%|▋| 9869/15000 [1:03:03<15:18,  5.59it/s, lr=9.35e-6, step_loss=0.08807/18/2023 20:06:26 - INFO - __main__ - train loss is 9.53364265197888\n",
      "Steps:  66%|▋| 9870/15000 [1:03:03<15:17,  5.59it/s, lr=9.35e-6, step_loss=0.07007/18/2023 20:06:26 - INFO - __main__ - train loss is 9.557752881664783\n",
      "Steps:  66%|▋| 9871/15000 [1:03:04<15:16,  5.59it/s, lr=9.35e-6, step_loss=0.02407/18/2023 20:06:26 - INFO - __main__ - train loss is 10.213063154835254\n",
      "Steps:  66%|▋| 9872/15000 [1:03:04<15:16,  5.59it/s, lr=9.35e-6, step_loss=0.65507/18/2023 20:06:26 - INFO - __main__ - train loss is 10.48903873981908\n",
      "Steps:  66%|▋| 9873/15000 [1:03:04<15:16,  5.59it/s, lr=9.35e-6, step_loss=0.27607/18/2023 20:06:26 - INFO - __main__ - train loss is 10.739547584671527\n",
      "Steps:  66%|▋| 9874/15000 [1:03:04<15:16,  5.59it/s, lr=9.35e-6, step_loss=0.25107/18/2023 20:06:26 - INFO - __main__ - train loss is 10.774070568848401\n",
      "Steps:  66%|▋| 9875/15000 [1:03:04<15:17,  5.58it/s, lr=9.35e-6, step_loss=0.03407/18/2023 20:06:27 - INFO - __main__ - train loss is 11.053015657234937\n",
      "Steps:  66%|▋| 9876/15000 [1:03:04<15:17,  5.59it/s, lr=9.35e-6, step_loss=0.27907/18/2023 20:06:27 - INFO - __main__ - train loss is 11.735439189244062\n",
      "Steps:  66%|▋| 9877/15000 [1:03:05<15:16,  5.59it/s, lr=9.35e-6, step_loss=0.68207/18/2023 20:06:27 - INFO - __main__ - train loss is 11.786322448868304\n",
      "Steps:  66%|▋| 9878/15000 [1:03:05<15:16,  5.59it/s, lr=9.35e-6, step_loss=0.05007/18/2023 20:06:27 - INFO - __main__ - train loss is 11.941607390064746\n",
      "Steps:  66%|▋| 9879/15000 [1:03:05<15:15,  5.60it/s, lr=9.35e-6, step_loss=0.15507/18/2023 20:06:27 - INFO - __main__ - train loss is 12.248315606731921\n",
      "Steps:  66%|▋| 9880/15000 [1:03:05<15:16,  5.59it/s, lr=9.35e-6, step_loss=0.30707/18/2023 20:06:28 - INFO - __main__ - train loss is 12.382810298819095\n",
      "Steps:  66%|▋| 9881/15000 [1:03:05<15:15,  5.59it/s, lr=9.35e-6, step_loss=0.13407/18/2023 20:06:28 - INFO - __main__ - train loss is 12.451393943745643\n",
      "Steps:  66%|▋| 9882/15000 [1:03:06<15:15,  5.59it/s, lr=9.35e-6, step_loss=0.06807/18/2023 20:06:28 - INFO - __main__ - train loss is 12.685591441113502\n",
      "Steps:  66%|▋| 9883/15000 [1:03:06<15:14,  5.59it/s, lr=9.35e-6, step_loss=0.23407/18/2023 20:06:28 - INFO - __main__ - train loss is 13.08677450986579\n",
      "Steps:  66%|▋| 9884/15000 [1:03:06<15:14,  5.59it/s, lr=9.35e-6, step_loss=0.40107/18/2023 20:06:28 - INFO - __main__ - train loss is 13.139887746889144\n",
      "Steps:  66%|▋| 9885/15000 [1:03:06<15:14,  5.59it/s, lr=9.35e-6, step_loss=0.05307/18/2023 20:06:28 - INFO - __main__ - train loss is 13.244940650183707\n",
      "Steps:  66%|▋| 9886/15000 [1:03:06<15:14,  5.59it/s, lr=9.35e-6, step_loss=0.10507/18/2023 20:06:29 - INFO - __main__ - train loss is 13.248708063270897\n",
      "Steps:  66%|▋| 9887/15000 [1:03:06<15:13,  5.59it/s, lr=9.35e-6, step_loss=0.00307/18/2023 20:06:29 - INFO - __main__ - train loss is 13.743316942360252\n",
      "Steps:  66%|▋| 9888/15000 [1:03:07<15:13,  5.60it/s, lr=9.35e-6, step_loss=0.49507/18/2023 20:06:29 - INFO - __main__ - train loss is 13.84086681297049\n",
      "Steps:  66%|▋| 9889/15000 [1:03:07<15:12,  5.60it/s, lr=9.35e-6, step_loss=0.09707/18/2023 20:06:29 - INFO - __main__ - train loss is 13.90425676247105\n",
      "Steps:  66%|▋| 9890/15000 [1:03:07<15:11,  5.60it/s, lr=9.35e-6, step_loss=0.06307/18/2023 20:06:29 - INFO - __main__ - train loss is 13.910834548529238\n",
      "Steps:  66%|▋| 9891/15000 [1:03:07<15:11,  5.60it/s, lr=9.35e-6, step_loss=0.00607/18/2023 20:06:29 - INFO - __main__ - train loss is 14.057760534342378\n",
      "Steps:  66%|▋| 9892/15000 [1:03:07<15:11,  5.60it/s, lr=9.35e-6, step_loss=0.14707/18/2023 20:06:30 - INFO - __main__ - train loss is 14.12069915002212\n",
      "Steps:  66%|▋| 9893/15000 [1:03:08<15:11,  5.60it/s, lr=9.35e-6, step_loss=0.06207/18/2023 20:06:30 - INFO - __main__ - train loss is 14.31990466779098\n",
      "Steps:  66%|▋| 9894/15000 [1:03:08<20:14,  4.21it/s, lr=9.35e-6, step_loss=0.19907/18/2023 20:06:31 - INFO - __main__ - Per validation step average loss is 0.3428143262863159\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Cumulative validation average loss is 0.3428143262863159\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Per validation step average loss is 0.18331871926784515\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Cumulative validation average loss is 0.5261330455541611\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Per validation step average loss is 0.017600685358047485\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Cumulative validation average loss is 0.5437337309122086\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Per validation step average loss is 0.022699128836393356\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Cumulative validation average loss is 0.5664328597486019\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Per validation step average loss is 0.3840412497520447\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Cumulative validation average loss is 0.9504741095006466\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Per validation step average loss is 0.010598371736705303\n",
      "07/18/2023 20:06:31 - INFO - __main__ - Cumulative validation average loss is 0.9610724812373519\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Per validation step average loss is 0.6382371187210083\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Cumulative validation average loss is 1.5993095999583602\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Per validation step average loss is 0.2037668526172638\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Cumulative validation average loss is 1.803076452575624\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Per validation step average loss is 0.024255696684122086\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Cumulative validation average loss is 1.827332149259746\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Per validation step average loss is 0.0037402301095426083\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Cumulative validation average loss is 1.8310723793692887\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Per validation step average loss is 0.005383249372243881\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Cumulative validation average loss is 1.8364556287415326\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Per validation step average loss is 0.2458585500717163\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Cumulative validation average loss is 2.082314178813249\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Average validation loss for Epoch 101 is 0.17352618156777075\n",
      "07/18/2023 20:06:32 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:10.596374, resuming normal operation.\n",
      "07/18/2023 20:06:45 - INFO - __main__ - Starting epoch 102\n",
      "07/18/2023 20:06:46 - INFO - __main__ - train loss is 0.02296638861298561\n",
      "Steps:  66%|▋| 9895/15000 [1:03:24<7:00:30,  4.94s/it, lr=9.35e-6, step_loss=0.007/18/2023 20:06:46 - INFO - __main__ - train loss is 0.40191787853837013\n",
      "Steps:  66%|▋| 9896/15000 [1:03:24<4:59:00,  3.51s/it, lr=9.35e-6, step_loss=0.307/18/2023 20:06:46 - INFO - __main__ - train loss is 0.4297259449958801\n",
      "Steps:  66%|▋| 9897/15000 [1:03:24<3:33:55,  2.52s/it, lr=9.35e-6, step_loss=0.007/18/2023 20:06:46 - INFO - __main__ - train loss is 0.4438626803457737\n",
      "Steps:  66%|▋| 9898/15000 [1:03:24<2:34:21,  1.82s/it, lr=9.35e-6, step_loss=0.007/18/2023 20:06:47 - INFO - __main__ - train loss is 0.4722484350204468\n",
      "Steps:  66%|▋| 9899/15000 [1:03:25<1:52:46,  1.33s/it, lr=9.35e-6, step_loss=0.007/18/2023 20:06:47 - INFO - __main__ - train loss is 0.49672235921025276\n",
      "Steps:  66%|▋| 9900/15000 [1:03:25<1:24:03,  1.01it/s, lr=9.35e-6, step_loss=0.007/18/2023 20:06:47 - INFO - __main__ - train loss is 0.7835959978401661\n",
      "Steps:  66%|▋| 9901/15000 [1:03:25<1:03:30,  1.34it/s, lr=9.35e-6, step_loss=0.207/18/2023 20:06:47 - INFO - __main__ - train loss is 0.8918815441429615\n",
      "Steps:  66%|▋| 9902/15000 [1:03:25<49:10,  1.73it/s, lr=9.35e-6, step_loss=0.10807/18/2023 20:06:47 - INFO - __main__ - train loss is 0.9114077556878328\n",
      "Steps:  66%|▋| 9903/15000 [1:03:25<39:15,  2.16it/s, lr=9.34e-6, step_loss=0.01907/18/2023 20:06:48 - INFO - __main__ - train loss is 1.062845217064023\n",
      "Steps:  66%|▋| 9904/15000 [1:03:26<32:26,  2.62it/s, lr=9.34e-6, step_loss=0.15107/18/2023 20:06:48 - INFO - __main__ - train loss is 1.2395406235009432\n",
      "Steps:  66%|▋| 9905/15000 [1:03:26<27:37,  3.07it/s, lr=9.34e-6, step_loss=0.17707/18/2023 20:06:48 - INFO - __main__ - train loss is 1.708349334076047\n",
      "Steps:  66%|▋| 9906/15000 [1:03:26<24:04,  3.53it/s, lr=9.34e-6, step_loss=0.46907/18/2023 20:06:48 - INFO - __main__ - train loss is 1.7114414351526648\n",
      "Steps:  66%|▋| 9907/15000 [1:03:26<21:33,  3.94it/s, lr=9.34e-6, step_loss=0.00307/18/2023 20:06:48 - INFO - __main__ - train loss is 1.7459436582867056\n",
      "Steps:  66%|▋| 9908/15000 [1:03:26<19:39,  4.32it/s, lr=9.34e-6, step_loss=0.03407/18/2023 20:06:49 - INFO - __main__ - train loss is 2.111981503898278\n",
      "Steps:  66%|▋| 9909/15000 [1:03:26<18:17,  4.64it/s, lr=9.34e-6, step_loss=0.36607/18/2023 20:06:49 - INFO - __main__ - train loss is 2.1186063198838383\n",
      "Steps:  66%|▋| 9910/15000 [1:03:27<17:19,  4.90it/s, lr=9.34e-6, step_loss=0.00607/18/2023 20:06:49 - INFO - __main__ - train loss is 2.2434335111174732\n",
      "Steps:  66%|▋| 9911/15000 [1:03:27<16:39,  5.09it/s, lr=9.34e-6, step_loss=0.12507/18/2023 20:06:49 - INFO - __main__ - train loss is 2.2577802466694266\n",
      "Steps:  66%|▋| 9912/15000 [1:03:27<16:11,  5.24it/s, lr=9.34e-6, step_loss=0.01407/18/2023 20:06:49 - INFO - __main__ - train loss is 2.3429735379759222\n",
      "Steps:  66%|▋| 9913/15000 [1:03:27<15:51,  5.35it/s, lr=9.34e-6, step_loss=0.08507/18/2023 20:06:49 - INFO - __main__ - train loss is 2.3727176452521235\n",
      "Steps:  66%|▋| 9914/15000 [1:03:27<15:46,  5.37it/s, lr=9.34e-6, step_loss=0.02907/18/2023 20:06:50 - INFO - __main__ - train loss is 2.73545714863576\n",
      "Steps:  66%|▋| 9915/15000 [1:03:28<15:41,  5.40it/s, lr=9.34e-6, step_loss=0.36307/18/2023 20:06:50 - INFO - __main__ - train loss is 2.7988464946392924\n",
      "Steps:  66%|▋| 9916/15000 [1:03:28<15:31,  5.46it/s, lr=9.34e-6, step_loss=0.06307/18/2023 20:06:50 - INFO - __main__ - train loss is 2.812539644772187\n",
      "Steps:  66%|▋| 9917/15000 [1:03:28<15:23,  5.50it/s, lr=9.34e-6, step_loss=0.01307/18/2023 20:06:50 - INFO - __main__ - train loss is 3.1617650168482214\n",
      "Steps:  66%|▋| 9918/15000 [1:03:28<15:19,  5.53it/s, lr=9.34e-6, step_loss=0.34907/18/2023 20:06:50 - INFO - __main__ - train loss is 3.167625440051779\n",
      "Steps:  66%|▋| 9919/15000 [1:03:28<15:15,  5.55it/s, lr=9.34e-6, step_loss=0.00507/18/2023 20:06:51 - INFO - __main__ - train loss is 3.2677373418118805\n",
      "Steps:  66%|█▎| 9920/15000 [1:03:28<15:12,  5.57it/s, lr=9.34e-6, step_loss=0.1]07/18/2023 20:06:51 - INFO - __main__ - train loss is 3.7404821345116943\n",
      "Steps:  66%|▋| 9921/15000 [1:03:29<15:11,  5.57it/s, lr=9.34e-6, step_loss=0.47307/18/2023 20:06:51 - INFO - __main__ - train loss is 3.8954034128692\n",
      "Steps:  66%|▋| 9922/15000 [1:03:29<15:10,  5.58it/s, lr=9.34e-6, step_loss=0.15507/18/2023 20:06:51 - INFO - __main__ - train loss is 4.011379493167624\n",
      "Steps:  66%|▋| 9923/15000 [1:03:29<15:09,  5.58it/s, lr=9.34e-6, step_loss=0.11607/18/2023 20:06:51 - INFO - __main__ - train loss is 4.014496192103252\n",
      "Steps:  66%|▋| 9924/15000 [1:03:29<15:17,  5.53it/s, lr=9.34e-6, step_loss=0.00307/18/2023 20:06:51 - INFO - __main__ - train loss is 4.281315073138103\n",
      "Steps:  66%|▋| 9925/15000 [1:03:29<15:23,  5.49it/s, lr=9.34e-6, step_loss=0.26707/18/2023 20:06:52 - INFO - __main__ - train loss is 4.362310237949714\n",
      "Steps:  66%|▋| 9926/15000 [1:03:30<15:27,  5.47it/s, lr=9.34e-6, step_loss=0.08107/18/2023 20:06:52 - INFO - __main__ - train loss is 4.364104334730655\n",
      "Steps:  66%|▋| 9927/15000 [1:03:30<15:29,  5.45it/s, lr=9.34e-6, step_loss=0.00107/18/2023 20:06:52 - INFO - __main__ - train loss is 4.396966230589896\n",
      "Steps:  66%|▋| 9928/15000 [1:03:30<15:22,  5.50it/s, lr=9.34e-6, step_loss=0.03207/18/2023 20:06:52 - INFO - __main__ - train loss is 5.112067472655326\n",
      "Steps:  66%|▋| 9929/15000 [1:03:30<15:23,  5.49it/s, lr=9.34e-6, step_loss=0.71507/18/2023 20:06:52 - INFO - __main__ - train loss is 5.345122617203742\n",
      "Steps:  66%|▋| 9930/15000 [1:03:30<15:17,  5.53it/s, lr=9.34e-6, step_loss=0.23307/18/2023 20:06:53 - INFO - __main__ - train loss is 5.540597361046821\n",
      "Steps:  66%|▋| 9931/15000 [1:03:30<15:13,  5.55it/s, lr=9.34e-6, step_loss=0.19507/18/2023 20:06:53 - INFO - __main__ - train loss is 5.662877317983657\n",
      "Steps:  66%|▋| 9932/15000 [1:03:31<15:10,  5.56it/s, lr=9.34e-6, step_loss=0.12207/18/2023 20:06:53 - INFO - __main__ - train loss is 5.6909134616144\n",
      "Steps:  66%|▋| 9933/15000 [1:03:31<15:10,  5.57it/s, lr=9.34e-6, step_loss=0.02807/18/2023 20:06:53 - INFO - __main__ - train loss is 5.70569105213508\n",
      "Steps:  66%|▋| 9934/15000 [1:03:31<15:08,  5.58it/s, lr=9.34e-6, step_loss=0.01407/18/2023 20:06:53 - INFO - __main__ - train loss is 5.893738282378763\n",
      "Steps:  66%|▋| 9935/15000 [1:03:31<15:06,  5.59it/s, lr=9.34e-6, step_loss=0.18807/18/2023 20:06:53 - INFO - __main__ - train loss is 5.910806044470519\n",
      "Steps:  66%|▋| 9936/15000 [1:03:31<15:16,  5.52it/s, lr=9.34e-6, step_loss=0.01707/18/2023 20:06:54 - INFO - __main__ - train loss is 6.061543091665953\n",
      "Steps:  66%|▋| 9937/15000 [1:03:32<16:58,  4.97it/s, lr=9.34e-6, step_loss=0.15107/18/2023 20:06:54 - INFO - __main__ - train loss is 6.081108573358506\n",
      "Steps:  66%|▋| 9938/15000 [1:03:32<16:42,  5.05it/s, lr=9.34e-6, step_loss=0.01907/18/2023 20:06:54 - INFO - __main__ - train loss is 6.166642177384347\n",
      "Steps:  66%|▋| 9939/15000 [1:03:32<16:19,  5.17it/s, lr=9.34e-6, step_loss=0.08507/18/2023 20:06:54 - INFO - __main__ - train loss is 6.170193392317742\n",
      "Steps:  66%|▋| 9940/15000 [1:03:32<16:04,  5.25it/s, lr=9.34e-6, step_loss=0.00307/18/2023 20:06:54 - INFO - __main__ - train loss is 6.316752451937646\n",
      "[2023-07-18 20:06:54,991] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  66%|▋| 9941/15000 [1:03:32<15:46,  5.34it/s, lr=9.34e-6, step_loss=0.14707/18/2023 20:06:55 - INFO - __main__ - train loss is 6.3481987859122455\n",
      "Steps:  66%|▋| 9942/15000 [1:03:32<15:32,  5.42it/s, lr=9.34e-6, step_loss=0.03107/18/2023 20:06:55 - INFO - __main__ - train loss is 6.789442553650588\n",
      "Steps:  66%|▋| 9943/15000 [1:03:33<15:24,  5.47it/s, lr=9.34e-6, step_loss=0.44107/18/2023 20:06:55 - INFO - __main__ - train loss is 6.799660850781947\n",
      "Steps:  66%|▋| 9944/15000 [1:03:33<15:18,  5.51it/s, lr=9.34e-6, step_loss=0.01007/18/2023 20:06:55 - INFO - __main__ - train loss is 6.806125819217414\n",
      "Steps:  66%|▋| 9945/15000 [1:03:33<15:13,  5.53it/s, lr=9.34e-6, step_loss=0.00607/18/2023 20:06:55 - INFO - __main__ - train loss is 6.880662545096129\n",
      "Steps:  66%|▋| 9946/15000 [1:03:33<15:09,  5.56it/s, lr=9.34e-6, step_loss=0.07407/18/2023 20:06:55 - INFO - __main__ - train loss is 6.952640965115279\n",
      "Steps:  66%|▋| 9947/15000 [1:03:33<15:06,  5.57it/s, lr=9.34e-6, step_loss=0.07207/18/2023 20:06:56 - INFO - __main__ - train loss is 7.045255541335791\n",
      "Steps:  66%|▋| 9948/15000 [1:03:34<15:05,  5.58it/s, lr=9.34e-6, step_loss=0.09207/18/2023 20:06:56 - INFO - __main__ - train loss is 7.143977432977408\n",
      "Steps:  66%|▋| 9949/15000 [1:03:34<15:04,  5.59it/s, lr=9.34e-6, step_loss=0.09807/18/2023 20:06:56 - INFO - __main__ - train loss is 7.234741031657904\n",
      "Steps:  66%|▋| 9950/15000 [1:03:34<15:06,  5.57it/s, lr=9.34e-6, step_loss=0.09007/18/2023 20:06:56 - INFO - __main__ - train loss is 7.439674257766455\n",
      "Steps:  66%|▋| 9951/15000 [1:03:34<15:05,  5.58it/s, lr=9.34e-6, step_loss=0.20507/18/2023 20:06:56 - INFO - __main__ - train loss is 7.568277298938483\n",
      "Steps:  66%|▋| 9952/15000 [1:03:34<15:03,  5.59it/s, lr=9.34e-6, step_loss=0.12907/18/2023 20:06:57 - INFO - __main__ - train loss is 8.322104691993445\n",
      "Steps:  66%|▋| 9953/15000 [1:03:34<15:09,  5.55it/s, lr=9.34e-6, step_loss=0.75407/18/2023 20:06:57 - INFO - __main__ - train loss is 8.439296289812773\n",
      "Steps:  66%|▋| 9954/15000 [1:03:35<15:12,  5.53it/s, lr=9.34e-6, step_loss=0.11707/18/2023 20:06:57 - INFO - __main__ - train loss is 8.536957598756999\n",
      "Steps:  66%|▋| 9955/15000 [1:03:35<15:08,  5.55it/s, lr=9.34e-6, step_loss=0.09707/18/2023 20:06:57 - INFO - __main__ - train loss is 8.729907772969455\n",
      "Steps:  66%|▋| 9956/15000 [1:03:35<15:06,  5.57it/s, lr=9.34e-6, step_loss=0.19307/18/2023 20:06:57 - INFO - __main__ - train loss is 9.236089728306979\n",
      "Steps:  66%|▋| 9957/15000 [1:03:35<15:12,  5.52it/s, lr=9.34e-6, step_loss=0.50607/18/2023 20:06:57 - INFO - __main__ - train loss is 9.237606850336306\n",
      "Steps:  66%|▋| 9958/15000 [1:03:35<15:11,  5.53it/s, lr=9.34e-6, step_loss=0.00107/18/2023 20:06:58 - INFO - __main__ - train loss is 9.239544617244974\n",
      "Steps:  66%|▋| 9959/15000 [1:03:36<15:08,  5.55it/s, lr=9.34e-6, step_loss=0.00107/18/2023 20:06:58 - INFO - __main__ - train loss is 9.415565299103037\n",
      "Steps:  66%|▋| 9960/15000 [1:03:36<15:05,  5.56it/s, lr=9.34e-6, step_loss=0.17607/18/2023 20:06:58 - INFO - __main__ - train loss is 9.458760651061311\n",
      "Steps:  66%|▋| 9961/15000 [1:03:36<15:11,  5.53it/s, lr=9.34e-6, step_loss=0.04307/18/2023 20:06:58 - INFO - __main__ - train loss is 10.04741338104941\n",
      "Steps:  66%|▋| 9962/15000 [1:03:36<15:13,  5.52it/s, lr=9.34e-6, step_loss=0.58907/18/2023 20:06:58 - INFO - __main__ - train loss is 10.060678673209623\n",
      "Steps:  66%|▋| 9963/15000 [1:03:36<15:09,  5.54it/s, lr=9.34e-6, step_loss=0.01307/18/2023 20:06:59 - INFO - __main__ - train loss is 10.315940034808591\n",
      "Steps:  66%|▋| 9964/15000 [1:03:36<15:12,  5.52it/s, lr=9.34e-6, step_loss=0.25507/18/2023 20:06:59 - INFO - __main__ - train loss is 10.335191359044984\n",
      "Steps:  66%|▋| 9965/15000 [1:03:37<15:16,  5.49it/s, lr=9.34e-6, step_loss=0.01907/18/2023 20:06:59 - INFO - __main__ - train loss is 10.350431352155283\n",
      "Steps:  66%|▋| 9966/15000 [1:03:37<15:12,  5.52it/s, lr=9.34e-6, step_loss=0.01507/18/2023 20:06:59 - INFO - __main__ - train loss is 10.988903074758127\n",
      "Steps:  66%|▋| 9967/15000 [1:03:37<15:08,  5.54it/s, lr=9.34e-6, step_loss=0.63807/18/2023 20:06:59 - INFO - __main__ - train loss is 11.052719331579283\n",
      "Steps:  66%|▋| 9968/15000 [1:03:37<15:05,  5.56it/s, lr=9.34e-6, step_loss=0.06307/18/2023 20:06:59 - INFO - __main__ - train loss is 11.059487645281479\n",
      "Steps:  66%|▋| 9969/15000 [1:03:37<15:12,  5.51it/s, lr=9.34e-6, step_loss=0.00607/18/2023 20:07:00 - INFO - __main__ - train loss is 11.113926728023216\n",
      "Steps:  66%|▋| 9970/15000 [1:03:38<15:19,  5.47it/s, lr=9.34e-6, step_loss=0.05407/18/2023 20:07:00 - INFO - __main__ - train loss is 11.479675431502983\n",
      "Steps:  66%|▋| 9971/15000 [1:03:38<15:14,  5.50it/s, lr=9.34e-6, step_loss=0.36607/18/2023 20:07:00 - INFO - __main__ - train loss is 11.557617713464424\n",
      "Steps:  66%|▋| 9972/15000 [1:03:38<15:10,  5.52it/s, lr=9.34e-6, step_loss=0.07707/18/2023 20:07:00 - INFO - __main__ - train loss is 11.699906428111717\n",
      "Steps:  66%|▋| 9973/15000 [1:03:38<15:16,  5.48it/s, lr=9.34e-6, step_loss=0.14207/18/2023 20:07:00 - INFO - __main__ - train loss is 11.719661240233108\n",
      "Steps:  66%|▋| 9974/15000 [1:03:38<15:14,  5.50it/s, lr=9.34e-6, step_loss=0.01907/18/2023 20:07:01 - INFO - __main__ - train loss is 11.896250475896522\n",
      "Steps:  66%|▋| 9975/15000 [1:03:38<15:09,  5.53it/s, lr=9.34e-6, step_loss=0.17707/18/2023 20:07:01 - INFO - __main__ - train loss is 12.087318335426971\n",
      "Steps:  67%|▋| 9976/15000 [1:03:39<15:04,  5.55it/s, lr=9.34e-6, step_loss=0.19107/18/2023 20:07:01 - INFO - __main__ - train loss is 12.546194766415283\n",
      "Steps:  67%|▋| 9977/15000 [1:03:39<15:01,  5.57it/s, lr=9.34e-6, step_loss=0.45907/18/2023 20:07:01 - INFO - __main__ - train loss is 12.632864360464737\n",
      "Steps:  67%|▋| 9978/15000 [1:03:39<15:01,  5.57it/s, lr=9.34e-6, step_loss=0.08607/18/2023 20:07:01 - INFO - __main__ - train loss is 12.692957122577354\n",
      "Steps:  67%|▋| 9979/15000 [1:03:39<14:59,  5.58it/s, lr=9.34e-6, step_loss=0.06007/18/2023 20:07:01 - INFO - __main__ - train loss is 12.712009413866326\n",
      "Steps:  67%|▋| 9980/15000 [1:03:39<14:58,  5.59it/s, lr=9.34e-6, step_loss=0.01907/18/2023 20:07:02 - INFO - __main__ - train loss is 12.871401651529595\n",
      "Steps:  67%|▋| 9981/15000 [1:03:39<14:57,  5.59it/s, lr=9.33e-6, step_loss=0.15907/18/2023 20:07:02 - INFO - __main__ - train loss is 12.961078538326547\n",
      "Steps:  67%|▋| 9982/15000 [1:03:40<14:55,  5.60it/s, lr=9.33e-6, step_loss=0.08907/18/2023 20:07:02 - INFO - __main__ - train loss is 13.128440900472924\n",
      "Steps:  67%|▋| 9983/15000 [1:03:40<14:55,  5.60it/s, lr=9.33e-6, step_loss=0.16707/18/2023 20:07:02 - INFO - __main__ - train loss is 13.369726448087022\n",
      "Steps:  67%|▋| 9984/15000 [1:03:40<14:54,  5.61it/s, lr=9.33e-6, step_loss=0.24107/18/2023 20:07:02 - INFO - __main__ - train loss is 13.464956088690087\n",
      "Steps:  67%|▋| 9985/15000 [1:03:40<14:54,  5.61it/s, lr=9.33e-6, step_loss=0.09507/18/2023 20:07:02 - INFO - __main__ - train loss is 13.514471254078671\n",
      "Steps:  67%|▋| 9986/15000 [1:03:40<14:54,  5.60it/s, lr=9.33e-6, step_loss=0.04907/18/2023 20:07:03 - INFO - __main__ - train loss is 13.747012219158933\n",
      "Steps:  67%|▋| 9987/15000 [1:03:41<15:03,  5.55it/s, lr=9.33e-6, step_loss=0.23307/18/2023 20:07:03 - INFO - __main__ - train loss is 14.059583148686215\n",
      "Steps:  67%|▋| 9988/15000 [1:03:41<15:11,  5.50it/s, lr=9.33e-6, step_loss=0.31307/18/2023 20:07:03 - INFO - __main__ - train loss is 14.061695273732767\n",
      "Steps:  67%|▋| 9989/15000 [1:03:41<15:14,  5.48it/s, lr=9.33e-6, step_loss=0.00207/18/2023 20:07:03 - INFO - __main__ - train loss is 14.139770347392187\n",
      "Steps:  67%|▋| 9990/15000 [1:03:41<15:16,  5.47it/s, lr=9.33e-6, step_loss=0.07807/18/2023 20:07:04 - INFO - __main__ - train loss is 14.361294019734487\n",
      "Steps:  67%|▋| 9991/15000 [1:03:41<19:52,  4.20it/s, lr=9.33e-6, step_loss=0.22207/18/2023 20:07:04 - INFO - __main__ - Per validation step average loss is 0.014290674589574337\n",
      "07/18/2023 20:07:04 - INFO - __main__ - Cumulative validation average loss is 0.014290674589574337\n",
      "07/18/2023 20:07:04 - INFO - __main__ - Per validation step average loss is 0.008874384686350822\n",
      "07/18/2023 20:07:04 - INFO - __main__ - Cumulative validation average loss is 0.02316505927592516\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.23791715502738953\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 0.2610822143033147\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.005969290155917406\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 0.2670515044592321\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.008552180603146553\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 0.27560368506237864\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.06201663613319397\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 0.3376203211955726\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.1988222897052765\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 0.5364426109008491\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.031142042949795723\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 0.5675846538506448\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Per validation step average loss is 0.002044031396508217\n",
      "07/18/2023 20:07:05 - INFO - __main__ - Cumulative validation average loss is 0.569628685247153\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Per validation step average loss is 0.00864869263023138\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Cumulative validation average loss is 0.5782773778773844\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Per validation step average loss is 0.14975202083587646\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Cumulative validation average loss is 0.7280293987132609\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Per validation step average loss is 0.06261879950761795\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Cumulative validation average loss is 0.7906481982208788\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Average validation loss for Epoch 102 is 0.0658873498517399\n",
      "07/18/2023 20:07:06 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:07:19 - INFO - __main__ - Starting epoch 103\n",
      "07/18/2023 20:07:19 - INFO - __main__ - train loss is 0.16606363654136658\n",
      "Steps:  67%|▋| 9992/15000 [1:03:57<6:48:24,  4.89s/it, lr=9.33e-6, step_loss=0.107/18/2023 20:07:20 - INFO - __main__ - train loss is 0.17180831544101238\n",
      "Steps:  67%|▋| 9993/15000 [1:03:57<4:50:17,  3.48s/it, lr=9.33e-6, step_loss=0.007/18/2023 20:07:20 - INFO - __main__ - train loss is 0.7215363513678312\n",
      "Steps:  67%|▋| 9994/15000 [1:03:58<3:27:37,  2.49s/it, lr=9.33e-6, step_loss=0.507/18/2023 20:07:20 - INFO - __main__ - train loss is 0.7254397235810757\n",
      "Steps:  67%|▋| 9995/15000 [1:03:58<2:29:45,  1.80s/it, lr=9.33e-6, step_loss=0.007/18/2023 20:07:20 - INFO - __main__ - train loss is 0.8681719712913036\n",
      "Steps:  67%|▋| 9996/15000 [1:03:58<1:49:22,  1.31s/it, lr=9.33e-6, step_loss=0.107/18/2023 20:07:20 - INFO - __main__ - train loss is 1.29225180670619\n",
      "Steps:  67%|▋| 9997/15000 [1:03:58<1:20:59,  1.03it/s, lr=9.33e-6, step_loss=0.407/18/2023 20:07:20 - INFO - __main__ - train loss is 1.5859407596290112\n",
      "Steps:  67%|▋| 9998/15000 [1:03:58<1:01:08,  1.36it/s, lr=9.33e-6, step_loss=0.207/18/2023 20:07:21 - INFO - __main__ - train loss is 1.590188049711287\n",
      "Steps:  67%|▋| 9999/15000 [1:03:58<47:14,  1.76it/s, lr=9.33e-6, step_loss=0.00407/18/2023 20:07:21 - INFO - __main__ - train loss is 1.6164317363873124\n",
      "Steps:  67%|▋| 10000/15000 [1:03:59<37:30,  2.22it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:21 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-10000\n",
      "07/18/2023 20:07:21 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:07:21,375] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:07:21,380] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-10000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:07:21,380] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-10000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:07:21,387] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-10000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:07:21,388] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-10000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:07:21,406] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-10000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:07:21,407] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-10000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:07:21,407] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:07:21 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-10000/pytorch_model\n",
      "07/18/2023 20:07:21 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-10000/scheduler.bin\n",
      "07/18/2023 20:07:21 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-10000/random_states_0.pkl\n",
      "07/18/2023 20:07:21 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-10000\n",
      "Steps:  67%|▋| 10000/15000 [1:03:59<37:30,  2.22it/s, lr=9.33e-6, step_loss=0.0207/18/2023 20:07:21 - INFO - __main__ - train loss is 2.0958811873570085\n",
      "Steps:  67%|▋| 10001/15000 [1:03:59<31:39,  2.63it/s, lr=9.33e-6, step_loss=0.4707/18/2023 20:07:21 - INFO - __main__ - train loss is 2.1020167814567685\n",
      "Steps:  67%|▋| 10002/15000 [1:03:59<26:37,  3.13it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:21 - INFO - __main__ - train loss is 2.2557141380384564\n",
      "Steps:  67%|▋| 10003/15000 [1:03:59<23:04,  3.61it/s, lr=9.33e-6, step_loss=0.1507/18/2023 20:07:22 - INFO - __main__ - train loss is 2.3185961665585637\n",
      "Steps:  67%|▋| 10004/15000 [1:03:59<20:38,  4.03it/s, lr=9.33e-6, step_loss=0.0607/18/2023 20:07:22 - INFO - __main__ - train loss is 2.470992756076157\n",
      "Steps:  67%|▋| 10005/15000 [1:04:00<18:54,  4.40it/s, lr=9.33e-6, step_loss=0.1507/18/2023 20:07:22 - INFO - __main__ - train loss is 2.728463483043015\n",
      "Steps:  67%|▋| 10006/15000 [1:04:00<17:41,  4.71it/s, lr=9.33e-6, step_loss=0.2507/18/2023 20:07:22 - INFO - __main__ - train loss is 2.9269293965771794\n",
      "Steps:  67%|▋| 10007/15000 [1:04:00<16:49,  4.95it/s, lr=9.33e-6, step_loss=0.1907/18/2023 20:07:22 - INFO - __main__ - train loss is 3.3163028778508306\n",
      "Steps:  67%|▋| 10008/15000 [1:04:00<16:15,  5.12it/s, lr=9.33e-6, step_loss=0.3807/18/2023 20:07:22 - INFO - __main__ - train loss is 3.4385447399690747\n",
      "Steps:  67%|▋| 10009/15000 [1:04:00<15:50,  5.25it/s, lr=9.33e-6, step_loss=0.1207/18/2023 20:07:23 - INFO - __main__ - train loss is 3.4415810592472553\n",
      "Steps:  67%|▋| 10010/15000 [1:04:00<15:32,  5.35it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:23 - INFO - __main__ - train loss is 3.564900916069746\n",
      "Steps:  67%|▋| 10011/15000 [1:04:01<15:28,  5.37it/s, lr=9.33e-6, step_loss=0.1207/18/2023 20:07:23 - INFO - __main__ - train loss is 3.899044793099165\n",
      "Steps:  67%|▋| 10012/15000 [1:04:01<15:28,  5.37it/s, lr=9.33e-6, step_loss=0.3307/18/2023 20:07:23 - INFO - __main__ - train loss is 3.903956025838852\n",
      "Steps:  67%|▋| 10013/15000 [1:04:01<15:17,  5.43it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:23 - INFO - __main__ - train loss is 3.9085136386565864\n",
      "Steps:  67%|▋| 10014/15000 [1:04:01<15:09,  5.48it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:24 - INFO - __main__ - train loss is 3.909930498804897\n",
      "Steps:  67%|▋| 10015/15000 [1:04:01<15:05,  5.51it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:24 - INFO - __main__ - train loss is 3.9495645030401647\n",
      "Steps:  67%|▋| 10016/15000 [1:04:02<15:01,  5.53it/s, lr=9.33e-6, step_loss=0.0307/18/2023 20:07:24 - INFO - __main__ - train loss is 3.962217995431274\n",
      "Steps:  67%|▋| 10017/15000 [1:04:02<14:58,  5.54it/s, lr=9.33e-6, step_loss=0.0107/18/2023 20:07:24 - INFO - __main__ - train loss is 3.968268760945648\n",
      "Steps:  67%|▋| 10018/15000 [1:04:02<14:56,  5.56it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:24 - INFO - __main__ - train loss is 4.156154879834503\n",
      "Steps:  67%|▋| 10019/15000 [1:04:02<14:53,  5.57it/s, lr=9.33e-6, step_loss=0.1807/18/2023 20:07:24 - INFO - __main__ - train loss is 4.167224088218063\n",
      "Steps:  67%|▋| 10020/15000 [1:04:02<14:51,  5.58it/s, lr=9.33e-6, step_loss=0.0107/18/2023 20:07:25 - INFO - __main__ - train loss is 4.439480522181839\n",
      "Steps:  67%|▋| 10021/15000 [1:04:02<14:51,  5.59it/s, lr=9.33e-6, step_loss=0.2707/18/2023 20:07:25 - INFO - __main__ - train loss is 4.576901668217033\n",
      "Steps:  67%|▋| 10022/15000 [1:04:03<14:50,  5.59it/s, lr=9.33e-6, step_loss=0.1307/18/2023 20:07:25 - INFO - __main__ - train loss is 4.602952239569277\n",
      "Steps:  67%|▋| 10023/15000 [1:04:03<14:49,  5.59it/s, lr=9.33e-6, step_loss=0.0207/18/2023 20:07:25 - INFO - __main__ - train loss is 4.703000565525144\n",
      "Steps:  67%|▋| 10024/15000 [1:04:03<14:49,  5.59it/s, lr=9.33e-6, step_loss=0.1]07/18/2023 20:07:25 - INFO - __main__ - train loss is 4.794539508875459\n",
      "Steps:  67%|▋| 10025/15000 [1:04:03<14:48,  5.60it/s, lr=9.33e-6, step_loss=0.0907/18/2023 20:07:25 - INFO - __main__ - train loss is 5.45644694333896\n",
      "Steps:  67%|▋| 10026/15000 [1:04:03<14:48,  5.60it/s, lr=9.33e-6, step_loss=0.6607/18/2023 20:07:26 - INFO - __main__ - train loss is 5.47198984073475\n",
      "Steps:  67%|▋| 10027/15000 [1:04:04<14:48,  5.60it/s, lr=9.33e-6, step_loss=0.0107/18/2023 20:07:26 - INFO - __main__ - train loss is 5.474165757652372\n",
      "Steps:  67%|▋| 10028/15000 [1:04:04<14:47,  5.60it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:26 - INFO - __main__ - train loss is 5.551722576376051\n",
      "Steps:  67%|▋| 10029/15000 [1:04:04<14:47,  5.60it/s, lr=9.33e-6, step_loss=0.0707/18/2023 20:07:26 - INFO - __main__ - train loss is 6.049753477331251\n",
      "Steps:  67%|▋| 10030/15000 [1:04:04<14:47,  5.60it/s, lr=9.33e-6, step_loss=0.4907/18/2023 20:07:26 - INFO - __main__ - train loss is 6.136194964405149\n",
      "Steps:  67%|▋| 10031/15000 [1:04:04<14:49,  5.58it/s, lr=9.33e-6, step_loss=0.0807/18/2023 20:07:27 - INFO - __main__ - train loss is 6.212487762328237\n",
      "Steps:  67%|▋| 10032/15000 [1:04:04<14:48,  5.59it/s, lr=9.33e-6, step_loss=0.0707/18/2023 20:07:27 - INFO - __main__ - train loss is 6.238426880445331\n",
      "Steps:  67%|▋| 10033/15000 [1:04:05<14:47,  5.59it/s, lr=9.33e-6, step_loss=0.0207/18/2023 20:07:27 - INFO - __main__ - train loss is 6.513000087346882\n",
      "Steps:  67%|▋| 10034/15000 [1:04:05<14:47,  5.59it/s, lr=9.33e-6, step_loss=0.2707/18/2023 20:07:27 - INFO - __main__ - train loss is 6.60099890222773\n",
      "Steps:  67%|▋| 10035/15000 [1:04:05<14:46,  5.60it/s, lr=9.33e-6, step_loss=0.0807/18/2023 20:07:27 - INFO - __main__ - train loss is 7.066676878836006\n",
      "Steps:  67%|▋| 10036/15000 [1:04:05<14:46,  5.60it/s, lr=9.33e-6, step_loss=0.4607/18/2023 20:07:27 - INFO - __main__ - train loss is 7.070907003711909\n",
      "Steps:  67%|▋| 10037/15000 [1:04:05<14:46,  5.60it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:28 - INFO - __main__ - train loss is 7.264946914743632\n",
      "Steps:  67%|▋| 10038/15000 [1:04:06<14:46,  5.60it/s, lr=9.33e-6, step_loss=0.1907/18/2023 20:07:28 - INFO - __main__ - train loss is 7.377237319480628\n",
      "Steps:  67%|▋| 10039/15000 [1:04:06<14:45,  5.60it/s, lr=9.33e-6, step_loss=0.1107/18/2023 20:07:28 - INFO - __main__ - train loss is 7.60490846587345\n",
      "Steps:  67%|▋| 10040/15000 [1:04:06<14:45,  5.60it/s, lr=9.33e-6, step_loss=0.2207/18/2023 20:07:28 - INFO - __main__ - train loss is 7.705561413895339\n",
      "Steps:  67%|▋| 10041/15000 [1:04:06<14:45,  5.60it/s, lr=9.33e-6, step_loss=0.1007/18/2023 20:07:28 - INFO - __main__ - train loss is 8.105386986862868\n",
      "Steps:  67%|▋| 10042/15000 [1:04:06<14:45,  5.60it/s, lr=9.33e-6, step_loss=0.4]07/18/2023 20:07:29 - INFO - __main__ - train loss is 8.131511782761663\n",
      "Steps:  67%|▋| 10043/15000 [1:04:06<14:45,  5.60it/s, lr=9.33e-6, step_loss=0.0207/18/2023 20:07:29 - INFO - __main__ - train loss is 8.367108901496977\n",
      "Steps:  67%|▋| 10044/15000 [1:04:07<14:45,  5.60it/s, lr=9.33e-6, step_loss=0.2307/18/2023 20:07:29 - INFO - __main__ - train loss is 8.401100707706064\n",
      "Steps:  67%|▋| 10045/15000 [1:04:07<14:44,  5.60it/s, lr=9.33e-6, step_loss=0.0307/18/2023 20:07:29 - INFO - __main__ - train loss is 8.407529282849282\n",
      "Steps:  67%|▋| 10046/15000 [1:04:07<14:44,  5.60it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:29 - INFO - __main__ - train loss is 8.422005570027977\n",
      "Steps:  67%|▋| 10047/15000 [1:04:07<14:44,  5.60it/s, lr=9.33e-6, step_loss=0.0107/18/2023 20:07:29 - INFO - __main__ - train loss is 8.474460190627724\n",
      "Steps:  67%|▋| 10048/15000 [1:04:07<14:44,  5.60it/s, lr=9.33e-6, step_loss=0.0507/18/2023 20:07:30 - INFO - __main__ - train loss is 8.907494878862053\n",
      "Steps:  67%|▋| 10049/15000 [1:04:07<14:44,  5.60it/s, lr=9.33e-6, step_loss=0.4307/18/2023 20:07:30 - INFO - __main__ - train loss is 8.922384409699589\n",
      "Steps:  67%|▋| 10050/15000 [1:04:08<14:43,  5.60it/s, lr=9.33e-6, step_loss=0.0107/18/2023 20:07:30 - INFO - __main__ - train loss is 9.192364661488682\n",
      "Steps:  67%|▋| 10051/15000 [1:04:08<14:43,  5.60it/s, lr=9.33e-6, step_loss=0.2707/18/2023 20:07:30 - INFO - __main__ - train loss is 9.468130318913609\n",
      "Steps:  67%|▋| 10052/15000 [1:04:08<14:43,  5.60it/s, lr=9.33e-6, step_loss=0.2707/18/2023 20:07:30 - INFO - __main__ - train loss is 9.50480309734121\n",
      "Steps:  67%|▋| 10053/15000 [1:04:08<14:43,  5.60it/s, lr=9.33e-6, step_loss=0.0307/18/2023 20:07:30 - INFO - __main__ - train loss is 10.172956800553948\n",
      "Steps:  67%|▋| 10054/15000 [1:04:08<14:43,  5.60it/s, lr=9.33e-6, step_loss=0.6607/18/2023 20:07:31 - INFO - __main__ - train loss is 10.175964473979548\n",
      "Steps:  67%|▋| 10055/15000 [1:04:09<14:42,  5.60it/s, lr=9.33e-6, step_loss=0.0007/18/2023 20:07:31 - INFO - __main__ - train loss is 10.299360766308382\n",
      "Steps:  67%|▋| 10056/15000 [1:04:09<14:42,  5.60it/s, lr=9.33e-6, step_loss=0.1207/18/2023 20:07:31 - INFO - __main__ - train loss is 10.342003314988688\n",
      "Steps:  67%|▋| 10057/15000 [1:04:09<14:42,  5.60it/s, lr=9.33e-6, step_loss=0.0407/18/2023 20:07:31 - INFO - __main__ - train loss is 10.352531763957813\n",
      "Steps:  67%|▋| 10058/15000 [1:04:09<14:42,  5.60it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:31 - INFO - __main__ - train loss is 10.358819771790877\n",
      "Steps:  67%|▋| 10059/15000 [1:04:09<14:42,  5.60it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:32 - INFO - __main__ - train loss is 10.410371534759179\n",
      "Steps:  67%|▋| 10060/15000 [1:04:09<14:42,  5.60it/s, lr=9.32e-6, step_loss=0.0507/18/2023 20:07:32 - INFO - __main__ - train loss is 10.429127231473103\n",
      "Steps:  67%|▋| 10061/15000 [1:04:10<14:42,  5.59it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:32 - INFO - __main__ - train loss is 10.605619311565533\n",
      "Steps:  67%|▋| 10062/15000 [1:04:10<14:43,  5.59it/s, lr=9.32e-6, step_loss=0.1707/18/2023 20:07:32 - INFO - __main__ - train loss is 10.884573161834851\n",
      "Steps:  67%|▋| 10063/15000 [1:04:10<14:42,  5.59it/s, lr=9.32e-6, step_loss=0.2707/18/2023 20:07:32 - INFO - __main__ - train loss is 11.083136454457417\n",
      "Steps:  67%|▋| 10064/15000 [1:04:10<14:44,  5.58it/s, lr=9.32e-6, step_loss=0.1907/18/2023 20:07:32 - INFO - __main__ - train loss is 11.109238106990233\n",
      "Steps:  67%|▋| 10065/15000 [1:04:10<14:44,  5.58it/s, lr=9.32e-6, step_loss=0.0207/18/2023 20:07:33 - INFO - __main__ - train loss is 11.150112759554759\n",
      "Steps:  67%|▋| 10066/15000 [1:04:11<14:45,  5.57it/s, lr=9.32e-6, step_loss=0.0407/18/2023 20:07:33 - INFO - __main__ - train loss is 11.2154238934163\n",
      "Steps:  67%|▋| 10067/15000 [1:04:11<14:44,  5.58it/s, lr=9.32e-6, step_loss=0.0607/18/2023 20:07:33 - INFO - __main__ - train loss is 11.233628604793921\n",
      "Steps:  67%|▋| 10068/15000 [1:04:11<14:42,  5.59it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:33 - INFO - __main__ - train loss is 11.724410329246894\n",
      "Steps:  67%|▋| 10069/15000 [1:04:11<14:43,  5.58it/s, lr=9.32e-6, step_loss=0.4907/18/2023 20:07:33 - INFO - __main__ - train loss is 11.72716633649543\n",
      "Steps:  67%|▋| 10070/15000 [1:04:11<14:42,  5.58it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:34 - INFO - __main__ - train loss is 11.897304814774543\n",
      "Steps:  67%|▋| 10071/15000 [1:04:11<14:43,  5.58it/s, lr=9.32e-6, step_loss=0.1707/18/2023 20:07:34 - INFO - __main__ - train loss is 12.129149269778281\n",
      "Steps:  67%|▋| 10072/15000 [1:04:12<14:42,  5.59it/s, lr=9.32e-6, step_loss=0.2307/18/2023 20:07:34 - INFO - __main__ - train loss is 12.477905404288322\n",
      "Steps:  67%|▋| 10073/15000 [1:04:12<14:43,  5.58it/s, lr=9.32e-6, step_loss=0.3407/18/2023 20:07:34 - INFO - __main__ - train loss is 12.517771535087377\n",
      "Steps:  67%|▋| 10074/15000 [1:04:12<14:41,  5.59it/s, lr=9.32e-6, step_loss=0.0307/18/2023 20:07:34 - INFO - __main__ - train loss is 12.577768818009645\n",
      "Steps:  67%|▋| 10075/15000 [1:04:12<14:42,  5.58it/s, lr=9.32e-6, step_loss=0.0607/18/2023 20:07:34 - INFO - __main__ - train loss is 12.591673507820815\n",
      "Steps:  67%|▋| 10076/15000 [1:04:12<14:49,  5.54it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:35 - INFO - __main__ - train loss is 12.599533242639154\n",
      "Steps:  67%|▋| 10077/15000 [1:04:12<14:47,  5.55it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:35 - INFO - __main__ - train loss is 12.664983404334635\n",
      "Steps:  67%|▋| 10078/15000 [1:04:13<14:46,  5.55it/s, lr=9.32e-6, step_loss=0.0607/18/2023 20:07:35 - INFO - __main__ - train loss is 12.856208396609873\n",
      "Steps:  67%|▋| 10079/15000 [1:04:13<14:43,  5.57it/s, lr=9.32e-6, step_loss=0.1907/18/2023 20:07:35 - INFO - __main__ - train loss is 12.8579288253095\n",
      "Steps:  67%|▋| 10080/15000 [1:04:13<14:41,  5.58it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:35 - INFO - __main__ - train loss is 13.013554883887991\n",
      "Steps:  67%|▋| 10081/15000 [1:04:13<14:39,  5.59it/s, lr=9.32e-6, step_loss=0.1507/18/2023 20:07:36 - INFO - __main__ - train loss is 13.022371826460585\n",
      "Steps:  67%|▋| 10082/15000 [1:04:13<15:38,  5.24it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:36 - INFO - __main__ - train loss is 13.18495793431066\n",
      "Steps:  67%|▋| 10083/15000 [1:04:14<15:39,  5.23it/s, lr=9.32e-6, step_loss=0.1607/18/2023 20:07:36 - INFO - __main__ - train loss is 13.187791528413072\n",
      "Steps:  67%|▋| 10084/15000 [1:04:14<15:36,  5.25it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:36 - INFO - __main__ - train loss is 13.436068998882547\n",
      "Steps:  67%|▋| 10085/15000 [1:04:14<15:21,  5.34it/s, lr=9.32e-6, step_loss=0.2407/18/2023 20:07:36 - INFO - __main__ - train loss is 13.471176004270092\n",
      "Steps:  67%|▋| 10086/15000 [1:04:14<15:14,  5.37it/s, lr=9.32e-6, step_loss=0.0307/18/2023 20:07:36 - INFO - __main__ - train loss is 13.49394366168417\n",
      "Steps:  67%|▋| 10087/15000 [1:04:14<15:04,  5.43it/s, lr=9.32e-6, step_loss=0.0207/18/2023 20:07:37 - INFO - __main__ - train loss is 13.96230110549368\n",
      "Steps:  67%|▋| 10088/15000 [1:04:15<19:35,  4.18it/s, lr=9.32e-6, step_loss=0.4607/18/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.04006735235452652\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 0.04006735235452652\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.20512303709983826\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 0.24519038945436478\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.0074933432042598724\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 0.25268373265862465\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.4798218011856079\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 0.7325055338442326\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.6581681966781616\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 1.3906737305223942\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.16551697254180908\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 1.5561907030642033\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Per validation step average loss is 0.056657418608665466\n",
      "07/18/2023 20:07:38 - INFO - __main__ - Cumulative validation average loss is 1.6128481216728687\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Per validation step average loss is 0.10316765308380127\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Cumulative validation average loss is 1.71601577475667\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Per validation step average loss is 0.04568981006741524\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Cumulative validation average loss is 1.7617055848240852\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Per validation step average loss is 0.040926650166511536\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Cumulative validation average loss is 1.8026322349905968\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Per validation step average loss is 0.03499562665820122\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Cumulative validation average loss is 1.837627861648798\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Per validation step average loss is 0.003804378444328904\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Cumulative validation average loss is 1.841432240093127\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Average validation loss for Epoch 103 is 0.15345268667442724\n",
      "07/18/2023 20:07:39 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:07:52 - INFO - __main__ - Starting epoch 104\n",
      "07/18/2023 20:07:53 - INFO - __main__ - train loss is 0.10708300769329071\n",
      "Steps:  67%|▋| 10089/15000 [1:04:31<6:43:32,  4.93s/it, lr=9.32e-6, step_loss=0.07/18/2023 20:07:53 - INFO - __main__ - train loss is 0.37425561249256134\n",
      "Steps:  67%|▋| 10090/15000 [1:04:31<4:46:56,  3.51s/it, lr=9.32e-6, step_loss=0.07/18/2023 20:07:53 - INFO - __main__ - train loss is 0.6904293447732925\n",
      "Steps:  67%|▋| 10091/15000 [1:04:31<3:25:28,  2.51s/it, lr=9.32e-6, step_loss=0.07/18/2023 20:07:53 - INFO - __main__ - train loss is 0.6926311291754246\n",
      "Steps:  67%|▋| 10092/15000 [1:04:31<2:28:23,  1.81s/it, lr=9.32e-6, step_loss=0.07/18/2023 20:07:53 - INFO - __main__ - train loss is 1.0660145319998264\n",
      "Steps:  67%|▋| 10093/15000 [1:04:31<1:48:25,  1.33s/it, lr=9.32e-6, step_loss=0.07/18/2023 20:07:54 - INFO - __main__ - train loss is 1.0898959022015333\n",
      "Steps:  67%|▋| 10094/15000 [1:04:32<1:20:24,  1.02it/s, lr=9.32e-6, step_loss=0.07/18/2023 20:07:54 - INFO - __main__ - train loss is 1.4351342301815748\n",
      "Steps:  67%|▋| 10095/15000 [1:04:32<1:00:38,  1.35it/s, lr=9.32e-6, step_loss=0.07/18/2023 20:07:54 - INFO - __main__ - train loss is 1.666199116036296\n",
      "Steps:  67%|▋| 10096/15000 [1:04:32<46:48,  1.75it/s, lr=9.32e-6, step_loss=0.2307/18/2023 20:07:54 - INFO - __main__ - train loss is 2.1086094956845045\n",
      "Steps:  67%|▋| 10097/15000 [1:04:32<37:06,  2.20it/s, lr=9.32e-6, step_loss=0.4407/18/2023 20:07:54 - INFO - __main__ - train loss is 2.1154616377316415\n",
      "Steps:  67%|▋| 10098/15000 [1:04:32<30:19,  2.69it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:55 - INFO - __main__ - train loss is 2.120934426318854\n",
      "Steps:  67%|▋| 10099/15000 [1:04:32<25:34,  3.19it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:55 - INFO - __main__ - train loss is 2.270423441659659\n",
      "Steps:  67%|▋| 10100/15000 [1:04:33<22:15,  3.67it/s, lr=9.32e-6, step_loss=0.1407/18/2023 20:07:55 - INFO - __main__ - train loss is 2.3827339480631053\n",
      "Steps:  67%|▋| 10101/15000 [1:04:33<19:56,  4.10it/s, lr=9.32e-6, step_loss=0.1107/18/2023 20:07:55 - INFO - __main__ - train loss is 2.6434494624845684\n",
      "Steps:  67%|▋| 10102/15000 [1:04:33<18:21,  4.45it/s, lr=9.32e-6, step_loss=0.2607/18/2023 20:07:55 - INFO - __main__ - train loss is 2.6595869618467987\n",
      "Steps:  67%|▋| 10103/15000 [1:04:33<17:19,  4.71it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:55 - INFO - __main__ - train loss is 2.661549351643771\n",
      "Steps:  67%|▋| 10104/15000 [1:04:33<16:37,  4.91it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:56 - INFO - __main__ - train loss is 2.6783899045549333\n",
      "Steps:  67%|▋| 10105/15000 [1:04:34<16:11,  5.04it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:56 - INFO - __main__ - train loss is 2.687019435223192\n",
      "Steps:  67%|▋| 10106/15000 [1:04:34<15:41,  5.20it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:56 - INFO - __main__ - train loss is 2.9732613838277757\n",
      "Steps:  67%|▋| 10107/15000 [1:04:34<15:21,  5.31it/s, lr=9.32e-6, step_loss=0.2807/18/2023 20:07:56 - INFO - __main__ - train loss is 3.0091359145008028\n",
      "Steps:  67%|▋| 10108/15000 [1:04:34<15:06,  5.40it/s, lr=9.32e-6, step_loss=0.0307/18/2023 20:07:56 - INFO - __main__ - train loss is 3.048433770891279\n",
      "Steps:  67%|▋| 10109/15000 [1:04:34<14:55,  5.46it/s, lr=9.32e-6, step_loss=0.0307/18/2023 20:07:57 - INFO - __main__ - train loss is 3.0572822797112167\n",
      "Steps:  67%|▋| 10110/15000 [1:04:34<14:48,  5.50it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:57 - INFO - __main__ - train loss is 3.0590136357350275\n",
      "Steps:  67%|▋| 10111/15000 [1:04:35<14:43,  5.53it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:57 - INFO - __main__ - train loss is 3.3281277128262445\n",
      "Steps:  67%|▋| 10112/15000 [1:04:35<14:40,  5.55it/s, lr=9.32e-6, step_loss=0.2607/18/2023 20:07:57 - INFO - __main__ - train loss is 3.564016253571026\n",
      "Steps:  67%|▋| 10113/15000 [1:04:35<14:37,  5.57it/s, lr=9.32e-6, step_loss=0.2307/18/2023 20:07:57 - INFO - __main__ - train loss is 3.7587141998810694\n",
      "Steps:  67%|▋| 10114/15000 [1:04:35<14:35,  5.58it/s, lr=9.32e-6, step_loss=0.1907/18/2023 20:07:57 - INFO - __main__ - train loss is 3.8554032378597185\n",
      "Steps:  67%|▋| 10115/15000 [1:04:35<14:42,  5.53it/s, lr=9.32e-6, step_loss=0.0907/18/2023 20:07:58 - INFO - __main__ - train loss is 4.220115178148262\n",
      "Steps:  67%|▋| 10116/15000 [1:04:35<14:44,  5.52it/s, lr=9.32e-6, step_loss=0.3607/18/2023 20:07:58 - INFO - __main__ - train loss is 4.227403941447847\n",
      "Steps:  67%|▋| 10117/15000 [1:04:36<14:40,  5.55it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:58 - INFO - __main__ - train loss is 4.2912656989647076\n",
      "Steps:  67%|▋| 10118/15000 [1:04:36<14:37,  5.56it/s, lr=9.32e-6, step_loss=0.0607/18/2023 20:07:58 - INFO - __main__ - train loss is 4.468308973009698\n",
      "Steps:  67%|▋| 10119/15000 [1:04:36<14:36,  5.57it/s, lr=9.32e-6, step_loss=0.1707/18/2023 20:07:58 - INFO - __main__ - train loss is 4.478057245607488\n",
      "Steps:  67%|▋| 10120/15000 [1:04:36<14:40,  5.54it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:58 - INFO - __main__ - train loss is 5.175854842062108\n",
      "Steps:  67%|▋| 10121/15000 [1:04:36<14:39,  5.55it/s, lr=9.32e-6, step_loss=0.6907/18/2023 20:07:59 - INFO - __main__ - train loss is 5.183176242629997\n",
      "Steps:  67%|▋| 10122/15000 [1:04:37<14:38,  5.56it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:59 - INFO - __main__ - train loss is 5.194191556307487\n",
      "Steps:  67%|▋| 10123/15000 [1:04:37<14:37,  5.56it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:59 - INFO - __main__ - train loss is 5.207380786421709\n",
      "Steps:  67%|▋| 10124/15000 [1:04:37<14:37,  5.55it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:07:59 - INFO - __main__ - train loss is 5.209580686758272\n",
      "Steps:  68%|▋| 10125/15000 [1:04:37<14:40,  5.54it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:07:59 - INFO - __main__ - train loss is 5.225844644824974\n",
      "Steps:  68%|▋| 10126/15000 [1:04:37<14:37,  5.56it/s, lr=9.32e-6, step_loss=0.0107/18/2023 20:08:00 - INFO - __main__ - train loss is 5.499550306121819\n",
      "Steps:  68%|▋| 10127/15000 [1:04:37<14:39,  5.54it/s, lr=9.32e-6, step_loss=0.2707/18/2023 20:08:00 - INFO - __main__ - train loss is 5.501829345826991\n",
      "Steps:  68%|▋| 10128/15000 [1:04:38<14:39,  5.54it/s, lr=9.32e-6, step_loss=0.0007/18/2023 20:08:00 - INFO - __main__ - train loss is 5.557852675323375\n",
      "Steps:  68%|▋| 10129/15000 [1:04:38<14:37,  5.55it/s, lr=9.32e-6, step_loss=0.0507/18/2023 20:08:00 - INFO - __main__ - train loss is 5.645064604585059\n",
      "Steps:  68%|▋| 10130/15000 [1:04:38<14:37,  5.55it/s, lr=9.32e-6, step_loss=0.0807/18/2023 20:08:00 - INFO - __main__ - train loss is 5.8098955425666645\n",
      "Steps:  68%|▋| 10131/15000 [1:04:38<14:35,  5.56it/s, lr=9.32e-6, step_loss=0.1607/18/2023 20:08:00 - INFO - __main__ - train loss is 5.95288488001097\n",
      "Steps:  68%|▋| 10132/15000 [1:04:38<14:33,  5.57it/s, lr=9.32e-6, step_loss=0.1407/18/2023 20:08:01 - INFO - __main__ - train loss is 5.9552264522062615\n",
      "Steps:  68%|▋| 10133/15000 [1:04:39<14:32,  5.58it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:01 - INFO - __main__ - train loss is 6.358351797913201\n",
      "Steps:  68%|▋| 10134/15000 [1:04:39<14:31,  5.58it/s, lr=9.31e-6, step_loss=0.4007/18/2023 20:08:01 - INFO - __main__ - train loss is 6.3612797387177125\n",
      "Steps:  68%|▋| 10135/15000 [1:04:39<14:30,  5.59it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:01 - INFO - __main__ - train loss is 6.547235918813385\n",
      "Steps:  68%|▋| 10136/15000 [1:04:39<14:29,  5.59it/s, lr=9.31e-6, step_loss=0.1807/18/2023 20:08:01 - INFO - __main__ - train loss is 6.594112550490536\n",
      "Steps:  68%|▋| 10137/15000 [1:04:39<14:30,  5.59it/s, lr=9.31e-6, step_loss=0.0407/18/2023 20:08:02 - INFO - __main__ - train loss is 6.612232289859094\n",
      "Steps:  68%|▋| 10138/15000 [1:04:39<14:29,  5.59it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:02 - INFO - __main__ - train loss is 6.962562046595849\n",
      "Steps:  68%|▋| 10139/15000 [1:04:40<14:29,  5.59it/s, lr=9.31e-6, step_loss=0.3507/18/2023 20:08:02 - INFO - __main__ - train loss is 6.9911291130119935\n",
      "Steps:  68%|▋| 10140/15000 [1:04:40<14:29,  5.59it/s, lr=9.31e-6, step_loss=0.0207/18/2023 20:08:02 - INFO - __main__ - train loss is 6.992932413355447\n",
      "Steps:  68%|▋| 10141/15000 [1:04:40<14:29,  5.59it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:02 - INFO - __main__ - train loss is 6.994472416583449\n",
      "Steps:  68%|▋| 10142/15000 [1:04:40<14:28,  5.59it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:02 - INFO - __main__ - train loss is 7.262985142413527\n",
      "Steps:  68%|▋| 10143/15000 [1:04:40<14:27,  5.60it/s, lr=9.31e-6, step_loss=0.2607/18/2023 20:08:03 - INFO - __main__ - train loss is 7.519374045077711\n",
      "Steps:  68%|▋| 10144/15000 [1:04:40<14:26,  5.60it/s, lr=9.31e-6, step_loss=0.2507/18/2023 20:08:03 - INFO - __main__ - train loss is 7.657687115017325\n",
      "Steps:  68%|▋| 10145/15000 [1:04:41<14:27,  5.60it/s, lr=9.31e-6, step_loss=0.1307/18/2023 20:08:03 - INFO - __main__ - train loss is 7.677442843560129\n",
      "Steps:  68%|▋| 10146/15000 [1:04:41<14:27,  5.60it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:03 - INFO - __main__ - train loss is 7.738450086209923\n",
      "Steps:  68%|▋| 10147/15000 [1:04:41<14:27,  5.60it/s, lr=9.31e-6, step_loss=0.0607/18/2023 20:08:03 - INFO - __main__ - train loss is 8.100256627891213\n",
      "Steps:  68%|▋| 10148/15000 [1:04:41<14:27,  5.59it/s, lr=9.31e-6, step_loss=0.3607/18/2023 20:08:04 - INFO - __main__ - train loss is 8.140262185130268\n",
      "Steps:  68%|▋| 10149/15000 [1:04:41<14:27,  5.59it/s, lr=9.31e-6, step_loss=0.0407/18/2023 20:08:04 - INFO - __main__ - train loss is 8.151055053342134\n",
      "Steps:  68%|▋| 10150/15000 [1:04:42<14:26,  5.59it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:04 - INFO - __main__ - train loss is 8.245506808627397\n",
      "Steps:  68%|▋| 10151/15000 [1:04:42<14:26,  5.59it/s, lr=9.31e-6, step_loss=0.0907/18/2023 20:08:04 - INFO - __main__ - train loss is 8.2963375155814\n",
      "Steps:  68%|▋| 10152/15000 [1:04:42<14:26,  5.60it/s, lr=9.31e-6, step_loss=0.0507/18/2023 20:08:04 - INFO - __main__ - train loss is 8.347030692268163\n",
      "Steps:  68%|▋| 10153/15000 [1:04:42<14:25,  5.60it/s, lr=9.31e-6, step_loss=0.0507/18/2023 20:08:04 - INFO - __main__ - train loss is 8.44025243120268\n",
      "Steps:  68%|▋| 10154/15000 [1:04:42<14:25,  5.60it/s, lr=9.31e-6, step_loss=0.0907/18/2023 20:08:05 - INFO - __main__ - train loss is 8.442629925906658\n",
      "Steps:  68%|▋| 10155/15000 [1:04:42<14:27,  5.59it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:05 - INFO - __main__ - train loss is 8.629555158317089\n",
      "Steps:  68%|▋| 10156/15000 [1:04:43<14:26,  5.59it/s, lr=9.31e-6, step_loss=0.1807/18/2023 20:08:05 - INFO - __main__ - train loss is 8.698063179850578\n",
      "Steps:  68%|▋| 10157/15000 [1:04:43<14:26,  5.59it/s, lr=9.31e-6, step_loss=0.0607/18/2023 20:08:05 - INFO - __main__ - train loss is 8.7364062666893\n",
      "Steps:  68%|▋| 10158/15000 [1:04:43<14:25,  5.60it/s, lr=9.31e-6, step_loss=0.0307/18/2023 20:08:05 - INFO - __main__ - train loss is 8.738273866823874\n",
      "Steps:  68%|▋| 10159/15000 [1:04:43<14:24,  5.60it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:05 - INFO - __main__ - train loss is 8.74104537430685\n",
      "Steps:  68%|▋| 10160/15000 [1:04:43<14:24,  5.60it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:06 - INFO - __main__ - train loss is 8.903679299983196\n",
      "Steps:  68%|▋| 10161/15000 [1:04:44<14:24,  5.60it/s, lr=9.31e-6, step_loss=0.1607/18/2023 20:08:06 - INFO - __main__ - train loss is 9.125155541929416\n",
      "Steps:  68%|▋| 10162/15000 [1:04:44<14:24,  5.60it/s, lr=9.31e-6, step_loss=0.2207/18/2023 20:08:06 - INFO - __main__ - train loss is 9.593294206890278\n",
      "Steps:  68%|▋| 10163/15000 [1:04:44<14:23,  5.60it/s, lr=9.31e-6, step_loss=0.4607/18/2023 20:08:06 - INFO - __main__ - train loss is 9.690740410122089\n",
      "Steps:  68%|▋| 10164/15000 [1:04:44<14:23,  5.60it/s, lr=9.31e-6, step_loss=0.0907/18/2023 20:08:06 - INFO - __main__ - train loss is 9.710278415936045\n",
      "Steps:  68%|▋| 10165/15000 [1:04:44<14:23,  5.60it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:07 - INFO - __main__ - train loss is 9.735459331306629\n",
      "Steps:  68%|▋| 10166/15000 [1:04:44<14:23,  5.60it/s, lr=9.31e-6, step_loss=0.0207/18/2023 20:08:07 - INFO - __main__ - train loss is 9.828621391090564\n",
      "Steps:  68%|▋| 10167/15000 [1:04:45<14:23,  5.60it/s, lr=9.31e-6, step_loss=0.0907/18/2023 20:08:07 - INFO - __main__ - train loss is 9.854417335125618\n",
      "Steps:  68%|▋| 10168/15000 [1:04:45<14:22,  5.60it/s, lr=9.31e-6, step_loss=0.0207/18/2023 20:08:07 - INFO - __main__ - train loss is 9.993595715495758\n",
      "Steps:  68%|▋| 10169/15000 [1:04:45<14:21,  5.61it/s, lr=9.31e-6, step_loss=0.1307/18/2023 20:08:07 - INFO - __main__ - train loss is 10.001873586210422\n",
      "Steps:  68%|▋| 10170/15000 [1:04:45<14:21,  5.61it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:07 - INFO - __main__ - train loss is 10.008176958072\n",
      "Steps:  68%|▋| 10171/15000 [1:04:45<14:20,  5.61it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:08 - INFO - __main__ - train loss is 10.199539592373185\n",
      "Steps:  68%|▋| 10172/15000 [1:04:46<14:26,  5.57it/s, lr=9.31e-6, step_loss=0.1907/18/2023 20:08:08 - INFO - __main__ - train loss is 10.412767341244034\n",
      "Steps:  68%|▋| 10173/15000 [1:04:46<14:33,  5.53it/s, lr=9.31e-6, step_loss=0.2107/18/2023 20:08:08 - INFO - __main__ - train loss is 10.428231410565786\n",
      "Steps:  68%|▋| 10174/15000 [1:04:46<14:31,  5.54it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:08 - INFO - __main__ - train loss is 10.448952836799435\n",
      "Steps:  68%|▋| 10175/15000 [1:04:46<14:28,  5.56it/s, lr=9.31e-6, step_loss=0.0207/18/2023 20:08:08 - INFO - __main__ - train loss is 10.513830369221978\n",
      "Steps:  68%|▋| 10176/15000 [1:04:46<14:25,  5.57it/s, lr=9.31e-6, step_loss=0.0607/18/2023 20:08:09 - INFO - __main__ - train loss is 10.709592020022683\n",
      "Steps:  68%|▋| 10177/15000 [1:04:46<14:23,  5.59it/s, lr=9.31e-6, step_loss=0.1907/18/2023 20:08:09 - INFO - __main__ - train loss is 10.724771547946148\n",
      "Steps:  68%|▋| 10178/15000 [1:04:47<14:21,  5.60it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:09 - INFO - __main__ - train loss is 10.736502437735908\n",
      "Steps:  68%|▋| 10179/15000 [1:04:47<14:20,  5.60it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:09 - INFO - __main__ - train loss is 11.01531305804383\n",
      "Steps:  68%|▋| 10180/15000 [1:04:47<14:19,  5.61it/s, lr=9.31e-6, step_loss=0.2707/18/2023 20:08:09 - INFO - __main__ - train loss is 11.02431795920711\n",
      "Steps:  68%|▋| 10181/15000 [1:04:47<14:18,  5.62it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:09 - INFO - __main__ - train loss is 11.03409218590241\n",
      "Steps:  68%|▋| 10182/15000 [1:04:47<14:17,  5.62it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:10 - INFO - __main__ - train loss is 11.167434928822331\n",
      "Steps:  68%|▋| 10183/15000 [1:04:47<14:17,  5.61it/s, lr=9.31e-6, step_loss=0.1307/18/2023 20:08:10 - INFO - __main__ - train loss is 11.87012368242722\n",
      "Steps:  68%|▋| 10184/15000 [1:04:48<14:17,  5.61it/s, lr=9.31e-6, step_loss=0.7007/18/2023 20:08:10 - INFO - __main__ - train loss is 11.873583480133675\n",
      "Steps:  68%|▋| 10185/15000 [1:04:48<18:59,  4.23it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:11 - INFO - __main__ - Per validation step average loss is 0.06744950264692307\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Cumulative validation average loss is 0.06744950264692307\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Per validation step average loss is 0.0019122813828289509\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Cumulative validation average loss is 0.06936178402975202\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Per validation step average loss is 0.1543528139591217\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Cumulative validation average loss is 0.22371459798887372\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Per validation step average loss is 0.10131263732910156\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Cumulative validation average loss is 0.3250272353179753\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Per validation step average loss is 0.031043732538819313\n",
      "07/18/2023 20:08:11 - INFO - __main__ - Cumulative validation average loss is 0.3560709678567946\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Per validation step average loss is 0.020743343979120255\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Cumulative validation average loss is 0.37681431183591485\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Per validation step average loss is 0.2146637886762619\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Cumulative validation average loss is 0.5914781005121768\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Per validation step average loss is 0.15967297554016113\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Cumulative validation average loss is 0.7511510760523379\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Per validation step average loss is 0.34656834602355957\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Cumulative validation average loss is 1.0977194220758975\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Per validation step average loss is 0.12855640053749084\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Cumulative validation average loss is 1.2262758226133883\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Per validation step average loss is 0.004601563327014446\n",
      "07/18/2023 20:08:12 - INFO - __main__ - Cumulative validation average loss is 1.2308773859404027\n",
      "07/18/2023 20:08:13 - INFO - __main__ - Per validation step average loss is 0.28997111320495605\n",
      "07/18/2023 20:08:13 - INFO - __main__ - Cumulative validation average loss is 1.5208484991453588\n",
      "07/18/2023 20:08:13 - INFO - __main__ - Average validation loss for Epoch 104 is 0.1267373749287799\n",
      "07/18/2023 20:08:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:08:26 - INFO - __main__ - Starting epoch 105\n",
      "07/18/2023 20:08:26 - INFO - __main__ - train loss is 0.005252450704574585\n",
      "Steps:  68%|▋| 10186/15000 [1:05:04<6:38:14,  4.96s/it, lr=9.31e-6, step_loss=0.07/18/2023 20:08:26 - INFO - __main__ - train loss is 0.08102680742740631\n",
      "Steps:  68%|▋| 10187/15000 [1:05:04<4:43:08,  3.53s/it, lr=9.31e-6, step_loss=0.07/18/2023 20:08:26 - INFO - __main__ - train loss is 0.19971752166748047\n",
      "Steps:  68%|▋| 10188/15000 [1:05:04<3:22:26,  2.52s/it, lr=9.31e-6, step_loss=0.07/18/2023 20:08:27 - INFO - __main__ - train loss is 0.2165258452296257\n",
      "Steps:  68%|▋| 10189/15000 [1:05:05<2:25:57,  1.82s/it, lr=9.31e-6, step_loss=0.07/18/2023 20:08:27 - INFO - __main__ - train loss is 0.7041267678141594\n",
      "Steps:  68%|▋| 10190/15000 [1:05:05<1:46:27,  1.33s/it, lr=9.31e-6, step_loss=0.07/18/2023 20:08:27 - INFO - __main__ - train loss is 1.1963713392615318\n",
      "Steps:  68%|▋| 10191/15000 [1:05:05<1:18:51,  1.02it/s, lr=9.31e-6, step_loss=0.07/18/2023 20:08:27 - INFO - __main__ - train loss is 1.1990570600610226\n",
      "Steps:  68%|▋| 10192/15000 [1:05:05<59:27,  1.35it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:27 - INFO - __main__ - train loss is 1.2092359538655728\n",
      "Steps:  68%|▋| 10193/15000 [1:05:05<45:52,  1.75it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:28 - INFO - __main__ - train loss is 1.2871233995538205\n",
      "Steps:  68%|▋| 10194/15000 [1:05:05<36:22,  2.20it/s, lr=9.31e-6, step_loss=0.0707/18/2023 20:08:28 - INFO - __main__ - train loss is 1.2955925080459565\n",
      "Steps:  68%|▋| 10195/15000 [1:05:06<29:43,  2.69it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:28 - INFO - __main__ - train loss is 1.2995363904628903\n",
      "Steps:  68%|▋| 10196/15000 [1:05:06<25:04,  3.19it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:28 - INFO - __main__ - train loss is 1.3668417467270046\n",
      "Steps:  68%|▋| 10197/15000 [1:05:06<21:48,  3.67it/s, lr=9.31e-6, step_loss=0.0607/18/2023 20:08:28 - INFO - __main__ - train loss is 1.37679372751154\n",
      "Steps:  68%|▋| 10198/15000 [1:05:06<19:32,  4.09it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:28 - INFO - __main__ - train loss is 1.7928039284888655\n",
      "Steps:  68%|▋| 10199/15000 [1:05:06<17:58,  4.45it/s, lr=9.31e-6, step_loss=0.4107/18/2023 20:08:29 - INFO - __main__ - train loss is 1.8096912244800478\n",
      "Steps:  68%|▋| 10200/15000 [1:05:07<16:50,  4.75it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:29 - INFO - __main__ - train loss is 1.8572712989989668\n",
      "Steps:  68%|▋| 10201/15000 [1:05:07<16:03,  4.98it/s, lr=9.31e-6, step_loss=0.0407/18/2023 20:08:29 - INFO - __main__ - train loss is 1.8668391855899245\n",
      "Steps:  68%|▋| 10202/15000 [1:05:07<15:30,  5.15it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:29 - INFO - __main__ - train loss is 1.8691425488796085\n",
      "Steps:  68%|▋| 10203/15000 [1:05:07<15:10,  5.27it/s, lr=9.31e-6, step_loss=0.0007/18/2023 20:08:29 - INFO - __main__ - train loss is 1.9309270994272083\n",
      "Steps:  68%|▋| 10204/15000 [1:05:07<14:53,  5.37it/s, lr=9.31e-6, step_loss=0.0607/18/2023 20:08:30 - INFO - __main__ - train loss is 1.9432609293144196\n",
      "Steps:  68%|▋| 10205/15000 [1:05:07<14:42,  5.43it/s, lr=9.31e-6, step_loss=0.0107/18/2023 20:08:30 - INFO - __main__ - train loss is 2.2610697362106293\n",
      "Steps:  68%|▋| 10206/15000 [1:05:08<14:35,  5.48it/s, lr=9.31e-6, step_loss=0.3107/18/2023 20:08:30 - INFO - __main__ - train loss is 2.3940577420871705\n",
      "Steps:  68%|▋| 10207/15000 [1:05:08<14:29,  5.52it/s, lr=9.31e-6, step_loss=0.1307/18/2023 20:08:30 - INFO - __main__ - train loss is 2.428127175895497\n",
      "Steps:  68%|▋| 10208/15000 [1:05:08<14:24,  5.55it/s, lr=9.31e-6, step_loss=0.0307/18/2023 20:08:30 - INFO - __main__ - train loss is 2.4361624016892165\n",
      "Steps:  68%|▋| 10209/15000 [1:05:08<14:21,  5.56it/s, lr=9.3e-6, step_loss=0.00807/18/2023 20:08:30 - INFO - __main__ - train loss is 2.838285882724449\n",
      "Steps:  68%|▋| 10210/15000 [1:05:08<14:19,  5.57it/s, lr=9.3e-6, step_loss=0.40207/18/2023 20:08:31 - INFO - __main__ - train loss is 2.8404618420172483\n",
      "Steps:  68%|▋| 10211/15000 [1:05:08<14:17,  5.58it/s, lr=9.3e-6, step_loss=0.00207/18/2023 20:08:31 - INFO - __main__ - train loss is 2.971432975726202\n",
      "Steps:  68%|▋| 10212/15000 [1:05:09<14:16,  5.59it/s, lr=9.3e-6, step_loss=0.13107/18/2023 20:08:31 - INFO - __main__ - train loss is 3.002780131297186\n",
      "Steps:  68%|▋| 10213/15000 [1:05:09<14:15,  5.59it/s, lr=9.3e-6, step_loss=0.03107/18/2023 20:08:31 - INFO - __main__ - train loss is 3.041247419314459\n",
      "Steps:  68%|▋| 10214/15000 [1:05:09<14:15,  5.60it/s, lr=9.3e-6, step_loss=0.03807/18/2023 20:08:31 - INFO - __main__ - train loss is 3.0624794096220285\n",
      "Steps:  68%|▋| 10215/15000 [1:05:09<14:14,  5.60it/s, lr=9.3e-6, step_loss=0.02107/18/2023 20:08:31 - INFO - __main__ - train loss is 3.421291741775349\n",
      "Steps:  68%|▋| 10216/15000 [1:05:09<14:14,  5.60it/s, lr=9.3e-6, step_loss=0.35907/18/2023 20:08:32 - INFO - __main__ - train loss is 3.4239825138356537\n",
      "Steps:  68%|▋| 10217/15000 [1:05:10<14:14,  5.60it/s, lr=9.3e-6, step_loss=0.00207/18/2023 20:08:32 - INFO - __main__ - train loss is 3.5349310317542404\n",
      "Steps:  68%|▋| 10218/15000 [1:05:10<14:14,  5.60it/s, lr=9.3e-6, step_loss=0.11107/18/2023 20:08:32 - INFO - __main__ - train loss is 3.703723488142714\n",
      "Steps:  68%|▋| 10219/15000 [1:05:10<14:13,  5.60it/s, lr=9.3e-6, step_loss=0.16907/18/2023 20:08:32 - INFO - __main__ - train loss is 3.70612459233962\n",
      "Steps:  68%|▋| 10220/15000 [1:05:10<14:14,  5.60it/s, lr=9.3e-6, step_loss=0.00207/18/2023 20:08:32 - INFO - __main__ - train loss is 3.781501602148637\n",
      "Steps:  68%|▋| 10221/15000 [1:05:10<14:13,  5.60it/s, lr=9.3e-6, step_loss=0.07507/18/2023 20:08:33 - INFO - __main__ - train loss is 3.9168462564703077\n",
      "Steps:  68%|▋| 10222/15000 [1:05:10<14:13,  5.60it/s, lr=9.3e-6, step_loss=0.13507/18/2023 20:08:33 - INFO - __main__ - train loss is 4.061290021752939\n",
      "Steps:  68%|▋| 10223/15000 [1:05:11<14:12,  5.60it/s, lr=9.3e-6, step_loss=0.14407/18/2023 20:08:33 - INFO - __main__ - train loss is 4.435390945291147\n",
      "Steps:  68%|▋| 10224/15000 [1:05:11<14:12,  5.60it/s, lr=9.3e-6, step_loss=0.37407/18/2023 20:08:33 - INFO - __main__ - train loss is 4.437793943332508\n",
      "Steps:  68%|▋| 10225/15000 [1:05:11<14:12,  5.60it/s, lr=9.3e-6, step_loss=0.00207/18/2023 20:08:33 - INFO - __main__ - train loss is 4.521176579641178\n",
      "Steps:  68%|▋| 10226/15000 [1:05:11<14:11,  5.60it/s, lr=9.3e-6, step_loss=0.08307/18/2023 20:08:33 - INFO - __main__ - train loss is 4.782436284469441\n",
      "Steps:  68%|▋| 10227/15000 [1:05:11<14:12,  5.60it/s, lr=9.3e-6, step_loss=0.26107/18/2023 20:08:34 - INFO - __main__ - train loss is 4.972153756069019\n",
      "Steps:  68%|▋| 10228/15000 [1:05:12<14:12,  5.60it/s, lr=9.3e-6, step_loss=0.19]07/18/2023 20:08:34 - INFO - __main__ - train loss is 5.019153430359438\n",
      "Steps:  68%|▋| 10229/15000 [1:05:12<14:12,  5.60it/s, lr=9.3e-6, step_loss=0.04707/18/2023 20:08:34 - INFO - __main__ - train loss is 5.034292581724003\n",
      "Steps:  68%|▋| 10230/15000 [1:05:12<14:12,  5.60it/s, lr=9.3e-6, step_loss=0.01507/18/2023 20:08:34 - INFO - __main__ - train loss is 5.260945397661999\n",
      "Steps:  68%|▋| 10231/15000 [1:05:12<14:11,  5.60it/s, lr=9.3e-6, step_loss=0.22707/18/2023 20:08:34 - INFO - __main__ - train loss is 5.279850733699277\n",
      "Steps:  68%|▋| 10232/15000 [1:05:12<14:11,  5.60it/s, lr=9.3e-6, step_loss=0.01807/18/2023 20:08:35 - INFO - __main__ - train loss is 5.372061212779954\n",
      "Steps:  68%|▋| 10233/15000 [1:05:12<14:11,  5.60it/s, lr=9.3e-6, step_loss=0.09207/18/2023 20:08:35 - INFO - __main__ - train loss is 5.874619563343003\n",
      "Steps:  68%|▋| 10234/15000 [1:05:13<14:11,  5.60it/s, lr=9.3e-6, step_loss=0.50307/18/2023 20:08:35 - INFO - __main__ - train loss is 5.93928994727321\n",
      "Steps:  68%|▋| 10235/15000 [1:05:13<14:10,  5.60it/s, lr=9.3e-6, step_loss=0.06407/18/2023 20:08:35 - INFO - __main__ - train loss is 6.080784847261384\n",
      "Steps:  68%|▋| 10236/15000 [1:05:13<14:10,  5.60it/s, lr=9.3e-6, step_loss=0.14107/18/2023 20:08:35 - INFO - __main__ - train loss is 6.1329918403644115\n",
      "Steps:  68%|▋| 10237/15000 [1:05:13<14:26,  5.50it/s, lr=9.3e-6, step_loss=0.05207/18/2023 20:08:35 - INFO - __main__ - train loss is 6.136069676605985\n",
      "Steps:  68%|▋| 10238/15000 [1:05:13<14:21,  5.53it/s, lr=9.3e-6, step_loss=0.00307/18/2023 20:08:36 - INFO - __main__ - train loss is 6.330251983134076\n",
      "Steps:  68%|▋| 10239/15000 [1:05:13<14:18,  5.55it/s, lr=9.3e-6, step_loss=0.19407/18/2023 20:08:36 - INFO - __main__ - train loss is 6.6149269852321595\n",
      "Steps:  68%|▋| 10240/15000 [1:05:14<14:15,  5.56it/s, lr=9.3e-6, step_loss=0.28507/18/2023 20:08:36 - INFO - __main__ - train loss is 6.638752829981968\n",
      "Steps:  68%|▋| 10241/15000 [1:05:14<14:14,  5.57it/s, lr=9.3e-6, step_loss=0.02307/18/2023 20:08:36 - INFO - __main__ - train loss is 7.090680283261463\n",
      "Steps:  68%|▋| 10242/15000 [1:05:14<14:12,  5.58it/s, lr=9.3e-6, step_loss=0.45207/18/2023 20:08:36 - INFO - __main__ - train loss is 7.54509372706525\n",
      "Steps:  68%|▋| 10243/15000 [1:05:14<14:10,  5.59it/s, lr=9.3e-6, step_loss=0.45407/18/2023 20:08:36 - INFO - __main__ - train loss is 7.613425736082718\n",
      "Steps:  68%|▋| 10244/15000 [1:05:14<14:09,  5.60it/s, lr=9.3e-6, step_loss=0.06807/18/2023 20:08:37 - INFO - __main__ - train loss is 8.14003658737056\n",
      "Steps:  68%|▋| 10245/15000 [1:05:15<14:08,  5.60it/s, lr=9.3e-6, step_loss=0.52707/18/2023 20:08:37 - INFO - __main__ - train loss is 8.176949714077637\n",
      "Steps:  68%|▋| 10246/15000 [1:05:15<14:08,  5.61it/s, lr=9.3e-6, step_loss=0.03607/18/2023 20:08:37 - INFO - __main__ - train loss is 8.191824906272814\n",
      "Steps:  68%|▋| 10247/15000 [1:05:15<14:07,  5.61it/s, lr=9.3e-6, step_loss=0.01407/18/2023 20:08:37 - INFO - __main__ - train loss is 8.199611262185499\n",
      "Steps:  68%|▋| 10248/15000 [1:05:15<14:08,  5.60it/s, lr=9.3e-6, step_loss=0.00707/18/2023 20:08:37 - INFO - __main__ - train loss is 8.529640153748915\n",
      "Steps:  68%|▋| 10249/15000 [1:05:15<14:07,  5.60it/s, lr=9.3e-6, step_loss=0.33]07/18/2023 20:08:38 - INFO - __main__ - train loss is 8.614006147487089\n",
      "Steps:  68%|▋| 10250/15000 [1:05:15<14:07,  5.60it/s, lr=9.3e-6, step_loss=0.08407/18/2023 20:08:38 - INFO - __main__ - train loss is 8.69622112880461\n",
      "Steps:  68%|▋| 10251/15000 [1:05:16<14:06,  5.61it/s, lr=9.3e-6, step_loss=0.08207/18/2023 20:08:38 - INFO - __main__ - train loss is 9.011690334184095\n",
      "Steps:  68%|▋| 10252/15000 [1:05:16<14:06,  5.61it/s, lr=9.3e-6, step_loss=0.31507/18/2023 20:08:38 - INFO - __main__ - train loss is 9.519537881715223\n",
      "Steps:  68%|▋| 10253/15000 [1:05:16<14:11,  5.57it/s, lr=9.3e-6, step_loss=0.50807/18/2023 20:08:38 - INFO - __main__ - train loss is 9.615719453198835\n",
      "Steps:  68%|▋| 10254/15000 [1:05:16<14:13,  5.56it/s, lr=9.3e-6, step_loss=0.09607/18/2023 20:08:38 - INFO - __main__ - train loss is 9.61720607127063\n",
      "Steps:  68%|▋| 10255/15000 [1:05:16<14:11,  5.57it/s, lr=9.3e-6, step_loss=0.00107/18/2023 20:08:39 - INFO - __main__ - train loss is 10.454934214008972\n",
      "Steps:  68%|▋| 10256/15000 [1:05:17<14:10,  5.58it/s, lr=9.3e-6, step_loss=0.83807/18/2023 20:08:39 - INFO - __main__ - train loss is 10.744159732712433\n",
      "Steps:  68%|▋| 10257/15000 [1:05:17<14:10,  5.57it/s, lr=9.3e-6, step_loss=0.28907/18/2023 20:08:39 - INFO - __main__ - train loss is 10.76009598816745\n",
      "Steps:  68%|▋| 10258/15000 [1:05:17<14:09,  5.58it/s, lr=9.3e-6, step_loss=0.01507/18/2023 20:08:39 - INFO - __main__ - train loss is 10.776520774466917\n",
      "Steps:  68%|▋| 10259/15000 [1:05:17<14:08,  5.59it/s, lr=9.3e-6, step_loss=0.01607/18/2023 20:08:39 - INFO - __main__ - train loss is 10.828876160783693\n",
      "Steps:  68%|▋| 10260/15000 [1:05:17<14:07,  5.59it/s, lr=9.3e-6, step_loss=0.05207/18/2023 20:08:40 - INFO - __main__ - train loss is 11.11470612208359\n",
      "Steps:  68%|▋| 10261/15000 [1:05:17<14:07,  5.59it/s, lr=9.3e-6, step_loss=0.28607/18/2023 20:08:40 - INFO - __main__ - train loss is 11.123842033324763\n",
      "Steps:  68%|▋| 10262/15000 [1:05:18<14:06,  5.59it/s, lr=9.3e-6, step_loss=0.00907/18/2023 20:08:40 - INFO - __main__ - train loss is 11.421821090159938\n",
      "Steps:  68%|▋| 10263/15000 [1:05:18<14:09,  5.58it/s, lr=9.3e-6, step_loss=0.29807/18/2023 20:08:40 - INFO - __main__ - train loss is 11.468553236452863\n",
      "Steps:  68%|▋| 10264/15000 [1:05:18<14:15,  5.53it/s, lr=9.3e-6, step_loss=0.04607/18/2023 20:08:40 - INFO - __main__ - train loss is 11.470826001605019\n",
      "Steps:  68%|▋| 10265/15000 [1:05:18<14:18,  5.52it/s, lr=9.3e-6, step_loss=0.00207/18/2023 20:08:40 - INFO - __main__ - train loss is 11.516001248499379\n",
      "Steps:  68%|▋| 10266/15000 [1:05:18<14:21,  5.49it/s, lr=9.3e-6, step_loss=0.04507/18/2023 20:08:41 - INFO - __main__ - train loss is 11.534376775613055\n",
      "Steps:  68%|▋| 10267/15000 [1:05:19<14:27,  5.46it/s, lr=9.3e-6, step_loss=0.01807/18/2023 20:08:41 - INFO - __main__ - train loss is 11.537989885313436\n",
      "Steps:  68%|▋| 10268/15000 [1:05:19<14:26,  5.46it/s, lr=9.3e-6, step_loss=0.00307/18/2023 20:08:41 - INFO - __main__ - train loss is 12.032388151390478\n",
      "Steps:  68%|▋| 10269/15000 [1:05:19<14:20,  5.50it/s, lr=9.3e-6, step_loss=0.49407/18/2023 20:08:41 - INFO - __main__ - train loss is 12.316988230450079\n",
      "Steps:  68%|▋| 10270/15000 [1:05:19<14:15,  5.53it/s, lr=9.3e-6, step_loss=0.28507/18/2023 20:08:41 - INFO - __main__ - train loss is 12.522708848817274\n",
      "Steps:  68%|▋| 10271/15000 [1:05:19<14:18,  5.51it/s, lr=9.3e-6, step_loss=0.20607/18/2023 20:08:42 - INFO - __main__ - train loss is 12.54671209375374\n",
      "Steps:  68%|▋| 10272/15000 [1:05:19<14:22,  5.48it/s, lr=9.3e-6, step_loss=0.02407/18/2023 20:08:42 - INFO - __main__ - train loss is 12.950727664632723\n",
      "Steps:  68%|▋| 10273/15000 [1:05:20<14:26,  5.45it/s, lr=9.3e-6, step_loss=0.40407/18/2023 20:08:42 - INFO - __main__ - train loss is 13.007945821387693\n",
      "Steps:  68%|▋| 10274/15000 [1:05:20<14:29,  5.44it/s, lr=9.3e-6, step_loss=0.05707/18/2023 20:08:42 - INFO - __main__ - train loss is 13.073875405592844\n",
      "Steps:  68%|▋| 10275/15000 [1:05:20<14:36,  5.39it/s, lr=9.3e-6, step_loss=0.06507/18/2023 20:08:42 - INFO - __main__ - train loss is 13.076144203078002\n",
      "Steps:  69%|▋| 10276/15000 [1:05:20<14:34,  5.40it/s, lr=9.3e-6, step_loss=0.00207/18/2023 20:08:42 - INFO - __main__ - train loss is 13.139833598863333\n",
      "Steps:  69%|▋| 10277/15000 [1:05:20<14:30,  5.42it/s, lr=9.3e-6, step_loss=0.06307/18/2023 20:08:43 - INFO - __main__ - train loss is 13.201574034523219\n",
      "Steps:  69%|▋| 10278/15000 [1:05:21<14:28,  5.44it/s, lr=9.3e-6, step_loss=0.06107/18/2023 20:08:43 - INFO - __main__ - train loss is 13.274424246978015\n",
      "Steps:  69%|▋| 10279/15000 [1:05:21<14:30,  5.42it/s, lr=9.3e-6, step_loss=0.07207/18/2023 20:08:43 - INFO - __main__ - train loss is 13.525463751982898\n",
      "Steps:  69%|▋| 10280/15000 [1:05:21<14:35,  5.39it/s, lr=9.3e-6, step_loss=0.25107/18/2023 20:08:43 - INFO - __main__ - train loss is 13.890566639136523\n",
      "Steps:  69%|▋| 10281/15000 [1:05:21<14:36,  5.39it/s, lr=9.3e-6, step_loss=0.36507/18/2023 20:08:44 - INFO - __main__ - train loss is 14.037285305093974\n",
      "Steps:  69%|▋| 10282/15000 [1:05:22<20:22,  3.86it/s, lr=9.3e-6, step_loss=0.14707/18/2023 20:08:44 - INFO - __main__ - Per validation step average loss is 0.0027839280664920807\n",
      "07/18/2023 20:08:44 - INFO - __main__ - Cumulative validation average loss is 0.0027839280664920807\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Per validation step average loss is 0.0751076266169548\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Cumulative validation average loss is 0.07789155468344688\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Per validation step average loss is 0.20383939146995544\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Cumulative validation average loss is 0.28173094615340233\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Per validation step average loss is 0.12383463233709335\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Cumulative validation average loss is 0.4055655784904957\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Per validation step average loss is 0.15379953384399414\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Cumulative validation average loss is 0.5593651123344898\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Per validation step average loss is 0.024495244026184082\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Cumulative validation average loss is 0.5838603563606739\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Per validation step average loss is 0.1655326783657074\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Cumulative validation average loss is 0.7493930347263813\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Per validation step average loss is 0.41320884227752686\n",
      "07/18/2023 20:08:45 - INFO - __main__ - Cumulative validation average loss is 1.1626018770039082\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Per validation step average loss is 0.09400593489408493\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Cumulative validation average loss is 1.256607811897993\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Per validation step average loss is 0.005677357781678438\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Cumulative validation average loss is 1.2622851696796715\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Per validation step average loss is 0.015298858284950256\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Cumulative validation average loss is 1.2775840279646218\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Per validation step average loss is 0.2495315670967102\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Cumulative validation average loss is 1.527115595061332\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Average validation loss for Epoch 105 is 0.12725963292177767\n",
      "07/18/2023 20:08:46 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:09:00 - INFO - __main__ - Starting epoch 106\n",
      "07/18/2023 20:09:00 - INFO - __main__ - train loss is 0.016667958348989487\n",
      "Steps:  69%|▋| 10283/15000 [1:05:38<6:46:37,  5.17s/it, lr=9.3e-6, step_loss=0.007/18/2023 20:09:00 - INFO - __main__ - train loss is 0.02069071913138032\n",
      "Steps:  69%|▋| 10284/15000 [1:05:38<4:48:48,  3.67s/it, lr=9.29e-6, step_loss=0.07/18/2023 20:09:01 - INFO - __main__ - train loss is 0.16837955499067903\n",
      "Steps:  69%|▋| 10285/15000 [1:05:39<3:26:20,  2.63s/it, lr=9.29e-6, step_loss=0.07/18/2023 20:09:01 - INFO - __main__ - train loss is 0.21063547069206834\n",
      "Steps:  69%|▋| 10286/15000 [1:05:39<2:28:36,  1.89s/it, lr=9.29e-6, step_loss=0.07/18/2023 20:09:01 - INFO - __main__ - train loss is 0.5688168876804411\n",
      "Steps:  69%|▋| 10287/15000 [1:05:39<1:48:16,  1.38s/it, lr=9.29e-6, step_loss=0.07/18/2023 20:09:01 - INFO - __main__ - train loss is 0.8312078290618956\n",
      "Steps:  69%|▋| 10288/15000 [1:05:39<1:19:58,  1.02s/it, lr=9.29e-6, step_loss=0.07/18/2023 20:09:01 - INFO - __main__ - train loss is 0.8407395803369582\n",
      "Steps:  69%|▋| 10289/15000 [1:05:39<1:00:13,  1.30it/s, lr=9.29e-6, step_loss=0.07/18/2023 20:09:02 - INFO - __main__ - train loss is 1.223924817983061\n",
      "Steps:  69%|▋| 10290/15000 [1:05:39<46:20,  1.69it/s, lr=9.29e-6, step_loss=0.3807/18/2023 20:09:02 - INFO - __main__ - train loss is 1.4902428411878645\n",
      "Steps:  69%|▋| 10291/15000 [1:05:40<36:37,  2.14it/s, lr=9.29e-6, step_loss=0.2607/18/2023 20:09:02 - INFO - __main__ - train loss is 1.5025080111809075\n",
      "Steps:  69%|▋| 10292/15000 [1:05:40<29:49,  2.63it/s, lr=9.29e-6, step_loss=0.0107/18/2023 20:09:02 - INFO - __main__ - train loss is 1.5651991558261216\n",
      "Steps:  69%|▋| 10293/15000 [1:05:40<25:04,  3.13it/s, lr=9.29e-6, step_loss=0.0607/18/2023 20:09:02 - INFO - __main__ - train loss is 2.2951724720187485\n",
      "Steps:  69%|▋| 10294/15000 [1:05:40<21:44,  3.61it/s, lr=9.29e-6, step_loss=0.7307/18/2023 20:09:02 - INFO - __main__ - train loss is 2.6196422171778977\n",
      "Steps:  69%|▋| 10295/15000 [1:05:40<19:23,  4.04it/s, lr=9.29e-6, step_loss=0.3207/18/2023 20:09:03 - INFO - __main__ - train loss is 2.6221469612792134\n",
      "Steps:  69%|▋| 10296/15000 [1:05:40<17:45,  4.41it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:03 - INFO - __main__ - train loss is 2.6555261658504605\n",
      "Steps:  69%|▋| 10297/15000 [1:05:41<16:38,  4.71it/s, lr=9.29e-6, step_loss=0.0307/18/2023 20:09:03 - INFO - __main__ - train loss is 3.1917837308719754\n",
      "Steps:  69%|▋| 10298/15000 [1:05:41<15:49,  4.95it/s, lr=9.29e-6, step_loss=0.5307/18/2023 20:09:03 - INFO - __main__ - train loss is 3.1998559860512614\n",
      "Steps:  69%|▋| 10299/15000 [1:05:41<15:15,  5.13it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:03 - INFO - __main__ - train loss is 3.2021404593251646\n",
      "Steps:  69%|▋| 10300/15000 [1:05:41<14:58,  5.23it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:03 - INFO - __main__ - train loss is 3.512573370244354\n",
      "Steps:  69%|▋| 10301/15000 [1:05:41<14:45,  5.30it/s, lr=9.29e-6, step_loss=0.3107/18/2023 20:09:04 - INFO - __main__ - train loss is 3.5215596384368837\n",
      "Steps:  69%|▋| 10302/15000 [1:05:42<14:40,  5.34it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:04 - INFO - __main__ - train loss is 3.6062093577347696\n",
      "Steps:  69%|▋| 10303/15000 [1:05:42<14:37,  5.35it/s, lr=9.29e-6, step_loss=0.0807/18/2023 20:09:04 - INFO - __main__ - train loss is 3.612306013237685\n",
      "Steps:  69%|▋| 10304/15000 [1:05:42<14:34,  5.37it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:04 - INFO - __main__ - train loss is 3.684860661160201\n",
      "Steps:  69%|▋| 10305/15000 [1:05:42<14:26,  5.42it/s, lr=9.29e-6, step_loss=0.0707/18/2023 20:09:04 - INFO - __main__ - train loss is 3.737787145655602\n",
      "Steps:  69%|▋| 10306/15000 [1:05:42<14:18,  5.47it/s, lr=9.29e-6, step_loss=0.0507/18/2023 20:09:05 - INFO - __main__ - train loss is 3.7401378268841654\n",
      "Steps:  69%|▋| 10307/15000 [1:05:42<14:13,  5.50it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:05 - INFO - __main__ - train loss is 3.7422669760417193\n",
      "Steps:  69%|▋| 10308/15000 [1:05:43<14:08,  5.53it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:05 - INFO - __main__ - train loss is 4.5731002918910235\n",
      "Steps:  69%|▋| 10309/15000 [1:05:43<14:06,  5.54it/s, lr=9.29e-6, step_loss=0.8307/18/2023 20:09:05 - INFO - __main__ - train loss is 4.83376767556183\n",
      "Steps:  69%|▋| 10310/15000 [1:05:43<14:03,  5.56it/s, lr=9.29e-6, step_loss=0.2607/18/2023 20:09:05 - INFO - __main__ - train loss is 4.855353259248659\n",
      "Steps:  69%|▋| 10311/15000 [1:05:43<14:01,  5.57it/s, lr=9.29e-6, step_loss=0.0207/18/2023 20:09:05 - INFO - __main__ - train loss is 4.920481414301321\n",
      "Steps:  69%|▋| 10312/15000 [1:05:43<14:00,  5.58it/s, lr=9.29e-6, step_loss=0.0607/18/2023 20:09:06 - INFO - __main__ - train loss is 4.928180413553491\n",
      "Steps:  69%|▋| 10313/15000 [1:05:44<13:59,  5.59it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:06 - INFO - __main__ - train loss is 4.967732785502449\n",
      "Steps:  69%|▋| 10314/15000 [1:05:44<13:58,  5.59it/s, lr=9.29e-6, step_loss=0.0307/18/2023 20:09:06 - INFO - __main__ - train loss is 5.207489995518699\n",
      "Steps:  69%|▋| 10315/15000 [1:05:44<13:57,  5.60it/s, lr=9.29e-6, step_loss=0.2407/18/2023 20:09:06 - INFO - __main__ - train loss is 5.321693754056469\n",
      "Steps:  69%|▋| 10316/15000 [1:05:44<13:56,  5.60it/s, lr=9.29e-6, step_loss=0.1107/18/2023 20:09:06 - INFO - __main__ - train loss is 5.328563053859398\n",
      "Steps:  69%|▋| 10317/15000 [1:05:44<13:56,  5.60it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:07 - INFO - __main__ - train loss is 5.329934487817809\n",
      "Steps:  69%|▋| 10318/15000 [1:05:44<14:01,  5.56it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:07 - INFO - __main__ - train loss is 5.3857063229661435\n",
      "Steps:  69%|▋| 10319/15000 [1:05:45<13:59,  5.57it/s, lr=9.29e-6, step_loss=0.0507/18/2023 20:09:07 - INFO - __main__ - train loss is 5.401336374459788\n",
      "Steps:  69%|▋| 10320/15000 [1:05:45<13:59,  5.58it/s, lr=9.29e-6, step_loss=0.0107/18/2023 20:09:07 - INFO - __main__ - train loss is 5.710351350484416\n",
      "Steps:  69%|▋| 10321/15000 [1:05:45<13:58,  5.58it/s, lr=9.29e-6, step_loss=0.3007/18/2023 20:09:07 - INFO - __main__ - train loss is 5.752326479880139\n",
      "Steps:  69%|▋| 10322/15000 [1:05:45<13:57,  5.59it/s, lr=9.29e-6, step_loss=0.0407/18/2023 20:09:07 - INFO - __main__ - train loss is 5.972878954140469\n",
      "Steps:  69%|▋| 10323/15000 [1:05:45<13:57,  5.59it/s, lr=9.29e-6, step_loss=0.2207/18/2023 20:09:08 - INFO - __main__ - train loss is 6.455086639849469\n",
      "Steps:  69%|▋| 10324/15000 [1:05:46<13:56,  5.59it/s, lr=9.29e-6, step_loss=0.4807/18/2023 20:09:08 - INFO - __main__ - train loss is 6.491312837926671\n",
      "Steps:  69%|▋| 10325/15000 [1:05:46<13:55,  5.59it/s, lr=9.29e-6, step_loss=0.0307/18/2023 20:09:08 - INFO - __main__ - train loss is 6.507452280027792\n",
      "Steps:  69%|▋| 10326/15000 [1:05:46<13:55,  5.60it/s, lr=9.29e-6, step_loss=0.0107/18/2023 20:09:08 - INFO - __main__ - train loss is 6.518145986599848\n",
      "Steps:  69%|▋| 10327/15000 [1:05:46<13:54,  5.60it/s, lr=9.29e-6, step_loss=0.0107/18/2023 20:09:08 - INFO - __main__ - train loss is 6.520220400299877\n",
      "Steps:  69%|▋| 10328/15000 [1:05:46<13:54,  5.60it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:09 - INFO - __main__ - train loss is 7.251663149800152\n",
      "Steps:  69%|▋| 10329/15000 [1:05:46<13:54,  5.60it/s, lr=9.29e-6, step_loss=0.7307/18/2023 20:09:09 - INFO - __main__ - train loss is 7.443022490944713\n",
      "Steps:  69%|▋| 10330/15000 [1:05:47<13:53,  5.60it/s, lr=9.29e-6, step_loss=0.1907/18/2023 20:09:09 - INFO - __main__ - train loss is 7.853129388298839\n",
      "Steps:  69%|▋| 10331/15000 [1:05:47<13:53,  5.60it/s, lr=9.29e-6, step_loss=0.4107/18/2023 20:09:09 - INFO - __main__ - train loss is 7.86061191232875\n",
      "Steps:  69%|▋| 10332/15000 [1:05:47<13:52,  5.61it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:09 - INFO - __main__ - train loss is 8.03852653177455\n",
      "Steps:  69%|▋| 10333/15000 [1:05:47<14:00,  5.55it/s, lr=9.29e-6, step_loss=0.1707/18/2023 20:09:09 - INFO - __main__ - train loss is 8.063287696335465\n",
      "Steps:  69%|▋| 10334/15000 [1:05:47<14:13,  5.47it/s, lr=9.29e-6, step_loss=0.0207/18/2023 20:09:10 - INFO - __main__ - train loss is 8.347913107369095\n",
      "Steps:  69%|▋| 10335/15000 [1:05:48<14:09,  5.49it/s, lr=9.29e-6, step_loss=0.2807/18/2023 20:09:10 - INFO - __main__ - train loss is 8.356140674557537\n",
      "Steps:  69%|▋| 10336/15000 [1:05:48<14:04,  5.52it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:10 - INFO - __main__ - train loss is 8.359506940469146\n",
      "Steps:  69%|▋| 10337/15000 [1:05:48<14:01,  5.54it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:10 - INFO - __main__ - train loss is 8.443200593814254\n",
      "Steps:  69%|▋| 10338/15000 [1:05:48<13:58,  5.56it/s, lr=9.29e-6, step_loss=0.0807/18/2023 20:09:10 - INFO - __main__ - train loss is 8.445085928426124\n",
      "Steps:  69%|▋| 10339/15000 [1:05:48<13:57,  5.57it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:11 - INFO - __main__ - train loss is 8.66442664025817\n",
      "Steps:  69%|▋| 10340/15000 [1:05:48<13:56,  5.57it/s, lr=9.29e-6, step_loss=0.2107/18/2023 20:09:11 - INFO - __main__ - train loss is 8.667695344774984\n",
      "Steps:  69%|▋| 10341/15000 [1:05:49<13:55,  5.58it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:11 - INFO - __main__ - train loss is 8.679949543788098\n",
      "Steps:  69%|▋| 10342/15000 [1:05:49<13:54,  5.58it/s, lr=9.29e-6, step_loss=0.0107/18/2023 20:09:11 - INFO - __main__ - train loss is 8.686193765490316\n",
      "Steps:  69%|▋| 10343/15000 [1:05:49<13:52,  5.59it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:11 - INFO - __main__ - train loss is 9.107621015398763\n",
      "Steps:  69%|▋| 10344/15000 [1:05:49<13:52,  5.59it/s, lr=9.29e-6, step_loss=0.4207/18/2023 20:09:11 - INFO - __main__ - train loss is 9.260247038095258\n",
      "Steps:  69%|▋| 10345/15000 [1:05:49<13:56,  5.57it/s, lr=9.29e-6, step_loss=0.1507/18/2023 20:09:12 - INFO - __main__ - train loss is 9.59689064451959\n",
      "Steps:  69%|▋| 10346/15000 [1:05:49<13:54,  5.58it/s, lr=9.29e-6, step_loss=0.3307/18/2023 20:09:12 - INFO - __main__ - train loss is 10.220441417186521\n",
      "Steps:  69%|▋| 10347/15000 [1:05:50<14:01,  5.53it/s, lr=9.29e-6, step_loss=0.6207/18/2023 20:09:12 - INFO - __main__ - train loss is 10.251293433248065\n",
      "Steps:  69%|▋| 10348/15000 [1:05:50<14:00,  5.53it/s, lr=9.29e-6, step_loss=0.0307/18/2023 20:09:12 - INFO - __main__ - train loss is 10.253911986830644\n",
      "Steps:  69%|▋| 10349/15000 [1:05:50<13:57,  5.56it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:12 - INFO - __main__ - train loss is 10.274885114165954\n",
      "Steps:  69%|▋| 10350/15000 [1:05:50<13:54,  5.57it/s, lr=9.29e-6, step_loss=0.0207/18/2023 20:09:12 - INFO - __main__ - train loss is 10.279424253269099\n",
      "Steps:  69%|▋| 10351/15000 [1:05:50<13:53,  5.58it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:13 - INFO - __main__ - train loss is 10.655999007984065\n",
      "Steps:  69%|▋| 10352/15000 [1:05:51<14:00,  5.53it/s, lr=9.29e-6, step_loss=0.3707/18/2023 20:09:13 - INFO - __main__ - train loss is 11.086638453765772\n",
      "Steps:  69%|▋| 10353/15000 [1:05:51<13:59,  5.53it/s, lr=9.29e-6, step_loss=0.4307/18/2023 20:09:13 - INFO - __main__ - train loss is 11.089216691325419\n",
      "Steps:  69%|▋| 10354/15000 [1:05:51<14:03,  5.51it/s, lr=9.29e-6, step_loss=0.0007/18/2023 20:09:13 - INFO - __main__ - train loss is 11.327721145818941\n",
      "Steps:  69%|▋| 10355/15000 [1:05:51<13:59,  5.53it/s, lr=9.29e-6, step_loss=0.2307/18/2023 20:09:13 - INFO - __main__ - train loss is 11.536493343184702\n",
      "Steps:  69%|▋| 10356/15000 [1:05:51<13:56,  5.55it/s, lr=9.29e-6, step_loss=0.2007/18/2023 20:09:14 - INFO - __main__ - train loss is 11.606408473919146\n",
      "Steps:  69%|▋| 10357/15000 [1:05:51<13:54,  5.56it/s, lr=9.29e-6, step_loss=0.0607/18/2023 20:09:14 - INFO - __main__ - train loss is 11.629879531334154\n",
      "Steps:  69%|▋| 10358/15000 [1:05:52<13:53,  5.57it/s, lr=9.28e-6, step_loss=0.0207/18/2023 20:09:14 - INFO - __main__ - train loss is 12.198585924576037\n",
      "Steps:  69%|▋| 10359/15000 [1:05:52<13:52,  5.57it/s, lr=9.28e-6, step_loss=0.5607/18/2023 20:09:14 - INFO - __main__ - train loss is 12.326618117163889\n",
      "Steps:  69%|▋| 10360/15000 [1:05:52<13:51,  5.58it/s, lr=9.28e-6, step_loss=0.1207/18/2023 20:09:14 - INFO - __main__ - train loss is 12.329118447029032\n",
      "Steps:  69%|▋| 10361/15000 [1:05:52<13:50,  5.58it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:14 - INFO - __main__ - train loss is 12.34542817028705\n",
      "Steps:  69%|▋| 10362/15000 [1:05:52<13:51,  5.58it/s, lr=9.28e-6, step_loss=0.0107/18/2023 20:09:15 - INFO - __main__ - train loss is 12.438157485448755\n",
      "Steps:  69%|▋| 10363/15000 [1:05:53<13:50,  5.58it/s, lr=9.28e-6, step_loss=0.0907/18/2023 20:09:15 - INFO - __main__ - train loss is 12.458766482421197\n",
      "Steps:  69%|▋| 10364/15000 [1:05:53<13:49,  5.59it/s, lr=9.28e-6, step_loss=0.0207/18/2023 20:09:15 - INFO - __main__ - train loss is 12.460179721121676\n",
      "Steps:  69%|▋| 10365/15000 [1:05:53<13:48,  5.59it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:15 - INFO - __main__ - train loss is 12.462669827160425\n",
      "Steps:  69%|▋| 10366/15000 [1:05:53<13:47,  5.60it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:15 - INFO - __main__ - train loss is 12.57971970748622\n",
      "Steps:  69%|▋| 10367/15000 [1:05:53<13:46,  5.60it/s, lr=9.28e-6, step_loss=0.1107/18/2023 20:09:16 - INFO - __main__ - train loss is 12.582881714799441\n",
      "Steps:  69%|▋| 10368/15000 [1:05:53<13:46,  5.61it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:16 - INFO - __main__ - train loss is 12.8421914834762\n",
      "Steps:  69%|▋| 10369/15000 [1:05:54<13:46,  5.61it/s, lr=9.28e-6, step_loss=0.2507/18/2023 20:09:16 - INFO - __main__ - train loss is 12.85900005477015\n",
      "Steps:  69%|▋| 10370/15000 [1:05:54<13:45,  5.61it/s, lr=9.28e-6, step_loss=0.0107/18/2023 20:09:16 - INFO - __main__ - train loss is 12.86397694668267\n",
      "Steps:  69%|▋| 10371/15000 [1:05:54<13:45,  5.61it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:16 - INFO - __main__ - train loss is 12.86994556861464\n",
      "Steps:  69%|▋| 10372/15000 [1:05:54<13:44,  5.61it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:16 - INFO - __main__ - train loss is 13.11882285552565\n",
      "Steps:  69%|▋| 10373/15000 [1:05:54<13:45,  5.61it/s, lr=9.28e-6, step_loss=0.2407/18/2023 20:09:17 - INFO - __main__ - train loss is 13.121988037251867\n",
      "Steps:  69%|▋| 10374/15000 [1:05:54<13:45,  5.60it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:17 - INFO - __main__ - train loss is 13.5076380163664\n",
      "Steps:  69%|▋| 10375/15000 [1:05:55<13:45,  5.60it/s, lr=9.28e-6, step_loss=0.3807/18/2023 20:09:17 - INFO - __main__ - train loss is 13.562624772661366\n",
      "Steps:  69%|▋| 10376/15000 [1:05:55<13:45,  5.60it/s, lr=9.28e-6, step_loss=0.0507/18/2023 20:09:17 - INFO - __main__ - train loss is 13.576246170909144\n",
      "Steps:  69%|▋| 10377/15000 [1:05:55<13:45,  5.60it/s, lr=9.28e-6, step_loss=0.0107/18/2023 20:09:17 - INFO - __main__ - train loss is 13.624505377025343\n",
      "Steps:  69%|▋| 10378/15000 [1:05:55<13:45,  5.60it/s, lr=9.28e-6, step_loss=0.0407/18/2023 20:09:18 - INFO - __main__ - train loss is 13.858192658633925\n",
      "Steps:  69%|▋| 10379/15000 [1:05:56<19:15,  4.00it/s, lr=9.28e-6, step_loss=0.2307/18/2023 20:09:18 - INFO - __main__ - Per validation step average loss is 0.2659236192703247\n",
      "07/18/2023 20:09:18 - INFO - __main__ - Cumulative validation average loss is 0.2659236192703247\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Per validation step average loss is 0.0014977853279560804\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Cumulative validation average loss is 0.2674214045982808\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Per validation step average loss is 0.18302220106124878\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Cumulative validation average loss is 0.45044360565952957\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Per validation step average loss is 0.2041650414466858\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Cumulative validation average loss is 0.6546086471062154\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Per validation step average loss is 0.00343060540035367\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Cumulative validation average loss is 0.658039252506569\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Per validation step average loss is 0.18642476201057434\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Cumulative validation average loss is 0.8444640145171434\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Per validation step average loss is 0.232105553150177\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Cumulative validation average loss is 1.0765695676673204\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Per validation step average loss is 0.012072831392288208\n",
      "07/18/2023 20:09:19 - INFO - __main__ - Cumulative validation average loss is 1.0886423990596086\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Per validation step average loss is 0.3633108139038086\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Cumulative validation average loss is 1.4519532129634172\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Per validation step average loss is 0.134240984916687\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Cumulative validation average loss is 1.5861941978801042\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Per validation step average loss is 0.001929798279888928\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Cumulative validation average loss is 1.5881239961599931\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Per validation step average loss is 0.4396042823791504\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Cumulative validation average loss is 2.0277282785391435\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Average validation loss for Epoch 106 is 0.16897735654492863\n",
      "07/18/2023 20:09:20 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:09:33 - INFO - __main__ - Starting epoch 107\n",
      "07/18/2023 20:09:34 - INFO - __main__ - train loss is 0.0024935761466622353\n",
      "Steps:  69%|▋| 10380/15000 [1:06:12<6:20:50,  4.95s/it, lr=9.28e-6, step_loss=0.07/18/2023 20:09:34 - INFO - __main__ - train loss is 0.01852572802454233\n",
      "Steps:  69%|▋| 10381/15000 [1:06:12<4:30:54,  3.52s/it, lr=9.28e-6, step_loss=0.07/18/2023 20:09:34 - INFO - __main__ - train loss is 0.3019607150927186\n",
      "Steps:  69%|▋| 10382/15000 [1:06:12<3:13:50,  2.52s/it, lr=9.28e-6, step_loss=0.07/18/2023 20:09:34 - INFO - __main__ - train loss is 0.3673245096579194\n",
      "Steps:  69%|▋| 10383/15000 [1:06:12<2:19:46,  1.82s/it, lr=9.28e-6, step_loss=0.07/18/2023 20:09:34 - INFO - __main__ - train loss is 0.36952492548152804\n",
      "Steps:  69%|▋| 10384/15000 [1:06:12<1:41:58,  1.33s/it, lr=9.28e-6, step_loss=0.07/18/2023 20:09:35 - INFO - __main__ - train loss is 0.5845300401560962\n",
      "Steps:  69%|▋| 10385/15000 [1:06:12<1:15:30,  1.02it/s, lr=9.28e-6, step_loss=0.07/18/2023 20:09:35 - INFO - __main__ - train loss is 0.6233013081364334\n",
      "Steps:  69%|▋| 10386/15000 [1:06:13<56:59,  1.35it/s, lr=9.28e-6, step_loss=0.0307/18/2023 20:09:35 - INFO - __main__ - train loss is 1.1980363535694778\n",
      "Steps:  69%|▋| 10387/15000 [1:06:13<44:07,  1.74it/s, lr=9.28e-6, step_loss=0.5707/18/2023 20:09:35 - INFO - __main__ - train loss is 1.3269643592648208\n",
      "Steps:  69%|▋| 10388/15000 [1:06:13<35:12,  2.18it/s, lr=9.28e-6, step_loss=0.1207/18/2023 20:09:35 - INFO - __main__ - train loss is 1.4143913718871772\n",
      "Steps:  69%|▋| 10389/15000 [1:06:13<28:44,  2.67it/s, lr=9.28e-6, step_loss=0.0807/18/2023 20:09:35 - INFO - __main__ - train loss is 1.4309260691516101\n",
      "Steps:  69%|▋| 10390/15000 [1:06:13<24:13,  3.17it/s, lr=9.28e-6, step_loss=0.0107/18/2023 20:09:36 - INFO - __main__ - train loss is 1.6319299484603107\n",
      "Steps:  69%|▋| 10391/15000 [1:06:14<21:11,  3.62it/s, lr=9.28e-6, step_loss=0.2007/18/2023 20:09:36 - INFO - __main__ - train loss is 2.3936248566024005\n",
      "Steps:  69%|▋| 10392/15000 [1:06:14<18:58,  4.05it/s, lr=9.28e-6, step_loss=0.7607/18/2023 20:09:36 - INFO - __main__ - train loss is 2.407985605765134\n",
      "Steps:  69%|▋| 10393/15000 [1:06:14<17:23,  4.41it/s, lr=9.28e-6, step_loss=0.0107/18/2023 20:09:36 - INFO - __main__ - train loss is 2.5300367777235806\n",
      "Steps:  69%|▋| 10394/15000 [1:06:14<16:22,  4.69it/s, lr=9.28e-6, step_loss=0.1207/18/2023 20:09:36 - INFO - __main__ - train loss is 2.80476275132969\n",
      "Steps:  69%|▋| 10395/15000 [1:06:14<15:33,  4.93it/s, lr=9.28e-6, step_loss=0.2707/18/2023 20:09:37 - INFO - __main__ - train loss is 3.0731770102865994\n",
      "Steps:  69%|▋| 10396/15000 [1:06:14<15:00,  5.11it/s, lr=9.28e-6, step_loss=0.2607/18/2023 20:09:37 - INFO - __main__ - train loss is 3.132240314502269\n",
      "Steps:  69%|▋| 10397/15000 [1:06:15<14:44,  5.20it/s, lr=9.28e-6, step_loss=0.0507/18/2023 20:09:37 - INFO - __main__ - train loss is 3.739298958797008\n",
      "Steps:  69%|▋| 10398/15000 [1:06:15<14:25,  5.32it/s, lr=9.28e-6, step_loss=0.6007/18/2023 20:09:37 - INFO - __main__ - train loss is 3.7414748216979206\n",
      "Steps:  69%|▋| 10399/15000 [1:06:15<14:12,  5.40it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:37 - INFO - __main__ - train loss is 3.7453476493246853\n",
      "Steps:  69%|▋| 10400/15000 [1:06:15<14:02,  5.46it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:37 - INFO - __main__ - train loss is 3.7601851387880743\n",
      "Steps:  69%|▋| 10401/15000 [1:06:15<13:58,  5.49it/s, lr=9.28e-6, step_loss=0.0107/18/2023 20:09:38 - INFO - __main__ - train loss is 3.7986304252408445\n",
      "Steps:  69%|▋| 10402/15000 [1:06:16<13:52,  5.52it/s, lr=9.28e-6, step_loss=0.0307/18/2023 20:09:38 - INFO - __main__ - train loss is 4.167376765515655\n",
      "Steps:  69%|▋| 10403/15000 [1:06:16<13:49,  5.55it/s, lr=9.28e-6, step_loss=0.3607/18/2023 20:09:38 - INFO - __main__ - train loss is 4.493027368094772\n",
      "Steps:  69%|▋| 10404/15000 [1:06:16<13:46,  5.56it/s, lr=9.28e-6, step_loss=0.3207/18/2023 20:09:38 - INFO - __main__ - train loss is 4.57333937427029\n",
      "Steps:  69%|▋| 10405/15000 [1:06:16<13:44,  5.57it/s, lr=9.28e-6, step_loss=0.0807/18/2023 20:09:38 - INFO - __main__ - train loss is 4.617505887057632\n",
      "Steps:  69%|▋| 10406/15000 [1:06:16<13:43,  5.58it/s, lr=9.28e-6, step_loss=0.0407/18/2023 20:09:39 - INFO - __main__ - train loss is 4.624475688207895\n",
      "Steps:  69%|▋| 10407/15000 [1:06:16<13:45,  5.56it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:39 - INFO - __main__ - train loss is 4.802885652054101\n",
      "Steps:  69%|▋| 10408/15000 [1:06:17<13:43,  5.57it/s, lr=9.28e-6, step_loss=0.1707/18/2023 20:09:39 - INFO - __main__ - train loss is 4.936159000266343\n",
      "Steps:  69%|▋| 10409/15000 [1:06:17<13:42,  5.58it/s, lr=9.28e-6, step_loss=0.1307/18/2023 20:09:39 - INFO - __main__ - train loss is 5.001816899050027\n",
      "Steps:  69%|▋| 10410/15000 [1:06:17<13:40,  5.59it/s, lr=9.28e-6, step_loss=0.0607/18/2023 20:09:39 - INFO - __main__ - train loss is 5.270252198446542\n",
      "Steps:  69%|▋| 10411/15000 [1:06:17<13:50,  5.53it/s, lr=9.28e-6, step_loss=0.2607/18/2023 20:09:39 - INFO - __main__ - train loss is 5.300017774570733\n",
      "Steps:  69%|▋| 10412/15000 [1:06:17<13:54,  5.50it/s, lr=9.28e-6, step_loss=0.0207/18/2023 20:09:40 - INFO - __main__ - train loss is 5.391962171066552\n",
      "Steps:  69%|▋| 10413/15000 [1:06:17<13:50,  5.53it/s, lr=9.28e-6, step_loss=0.0907/18/2023 20:09:40 - INFO - __main__ - train loss is 5.457991078961641\n",
      "Steps:  69%|▋| 10414/15000 [1:06:18<13:47,  5.55it/s, lr=9.28e-6, step_loss=0.0607/18/2023 20:09:40 - INFO - __main__ - train loss is 5.465762591455132\n",
      "Steps:  69%|▋| 10415/15000 [1:06:18<13:52,  5.51it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:40 - INFO - __main__ - train loss is 5.888374543283135\n",
      "Steps:  69%|▋| 10416/15000 [1:06:18<13:50,  5.52it/s, lr=9.28e-6, step_loss=0.4207/18/2023 20:09:40 - INFO - __main__ - train loss is 6.3641222775913775\n",
      "Steps:  69%|▋| 10417/15000 [1:06:18<13:47,  5.54it/s, lr=9.28e-6, step_loss=0.4707/18/2023 20:09:40 - INFO - __main__ - train loss is 6.481206683907658\n",
      "Steps:  69%|▋| 10418/15000 [1:06:18<13:45,  5.55it/s, lr=9.28e-6, step_loss=0.1107/18/2023 20:09:41 - INFO - __main__ - train loss is 6.485936560668051\n",
      "Steps:  69%|▋| 10419/15000 [1:06:19<13:43,  5.56it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:41 - INFO - __main__ - train loss is 6.554276519455016\n",
      "Steps:  69%|▋| 10420/15000 [1:06:19<13:49,  5.52it/s, lr=9.28e-6, step_loss=0.0607/18/2023 20:09:41 - INFO - __main__ - train loss is 6.796027177013457\n",
      "Steps:  69%|▋| 10421/15000 [1:06:19<13:45,  5.55it/s, lr=9.28e-6, step_loss=0.2407/18/2023 20:09:41 - INFO - __main__ - train loss is 6.798531372565776\n",
      "Steps:  69%|▋| 10422/15000 [1:06:19<13:42,  5.56it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:41 - INFO - __main__ - train loss is 6.836018145550042\n",
      "Steps:  69%|▋| 10423/15000 [1:06:19<13:41,  5.57it/s, lr=9.28e-6, step_loss=0.0307/18/2023 20:09:42 - INFO - __main__ - train loss is 6.8443465693853796\n",
      "Steps:  69%|▋| 10424/15000 [1:06:19<13:49,  5.52it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:42 - INFO - __main__ - train loss is 6.848464290611446\n",
      "Steps:  70%|▋| 10425/15000 [1:06:20<13:50,  5.51it/s, lr=9.28e-6, step_loss=0.0007/18/2023 20:09:42 - INFO - __main__ - train loss is 7.170386920683086\n",
      "Steps:  70%|▋| 10426/15000 [1:06:20<14:00,  5.44it/s, lr=9.28e-6, step_loss=0.3207/18/2023 20:09:42 - INFO - __main__ - train loss is 7.182877293787897\n",
      "Steps:  70%|▋| 10427/15000 [1:06:20<14:16,  5.34it/s, lr=9.28e-6, step_loss=0.0107/18/2023 20:09:42 - INFO - __main__ - train loss is 7.252538374625146\n",
      "Steps:  70%|▋| 10428/15000 [1:06:20<14:29,  5.26it/s, lr=9.28e-6, step_loss=0.0607/18/2023 20:09:43 - INFO - __main__ - train loss is 8.004319122992456\n",
      "Steps:  70%|▋| 10429/15000 [1:06:20<15:01,  5.07it/s, lr=9.28e-6, step_loss=0.7507/18/2023 20:09:43 - INFO - __main__ - train loss is 8.09548909123987\n",
      "Steps:  70%|▋| 10430/15000 [1:06:21<15:11,  5.01it/s, lr=9.28e-6, step_loss=0.0907/18/2023 20:09:43 - INFO - __main__ - train loss is 8.121186506934464\n",
      "Steps:  70%|▋| 10431/15000 [1:06:21<15:14,  4.99it/s, lr=9.28e-6, step_loss=0.0207/18/2023 20:09:43 - INFO - __main__ - train loss is 8.999497187323868\n",
      "Steps:  70%|▋| 10432/15000 [1:06:21<15:13,  5.00it/s, lr=9.27e-6, step_loss=0.8707/18/2023 20:09:43 - INFO - __main__ - train loss is 9.144932103343308\n",
      "Steps:  70%|▋| 10433/15000 [1:06:21<15:08,  5.03it/s, lr=9.27e-6, step_loss=0.1407/18/2023 20:09:44 - INFO - __main__ - train loss is 9.297296327538788\n",
      "Steps:  70%|▋| 10434/15000 [1:06:21<15:03,  5.06it/s, lr=9.27e-6, step_loss=0.1507/18/2023 20:09:44 - INFO - __main__ - train loss is 9.299437757115811\n",
      "Steps:  70%|▋| 10435/15000 [1:06:22<14:58,  5.08it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:09:44 - INFO - __main__ - train loss is 10.081041510682553\n",
      "Steps:  70%|▋| 10436/15000 [1:06:22<14:54,  5.10it/s, lr=9.27e-6, step_loss=0.7807/18/2023 20:09:44 - INFO - __main__ - train loss is 10.095212706830353\n",
      "Steps:  70%|▋| 10437/15000 [1:06:22<14:56,  5.09it/s, lr=9.27e-6, step_loss=0.0107/18/2023 20:09:44 - INFO - __main__ - train loss is 10.709368058945984\n",
      "Steps:  70%|▋| 10438/15000 [1:06:22<15:02,  5.05it/s, lr=9.27e-6, step_loss=0.6107/18/2023 20:09:45 - INFO - __main__ - train loss is 10.765623418148607\n",
      "Steps:  70%|▋| 10439/15000 [1:06:22<14:58,  5.08it/s, lr=9.27e-6, step_loss=0.0507/18/2023 20:09:45 - INFO - __main__ - train loss is 10.766877720598131\n",
      "Steps:  70%|▋| 10440/15000 [1:06:23<14:54,  5.10it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:09:45 - INFO - __main__ - train loss is 10.80866818735376\n",
      "Steps:  70%|▋| 10441/15000 [1:06:23<15:04,  5.04it/s, lr=9.27e-6, step_loss=0.0407/18/2023 20:09:45 - INFO - __main__ - train loss is 10.952723732683808\n",
      "Steps:  70%|▋| 10442/15000 [1:06:23<14:58,  5.07it/s, lr=9.27e-6, step_loss=0.1407/18/2023 20:09:45 - INFO - __main__ - train loss is 10.991475871298462\n",
      "Steps:  70%|▋| 10443/15000 [1:06:23<14:57,  5.08it/s, lr=9.27e-6, step_loss=0.0307/18/2023 20:09:46 - INFO - __main__ - train loss is 11.005858466494828\n",
      "Steps:  70%|▋| 10444/15000 [1:06:23<14:53,  5.10it/s, lr=9.27e-6, step_loss=0.0107/18/2023 20:09:46 - INFO - __main__ - train loss is 11.178084910381585\n",
      "Steps:  70%|▋| 10445/15000 [1:06:24<14:52,  5.10it/s, lr=9.27e-6, step_loss=0.1707/18/2023 20:09:46 - INFO - __main__ - train loss is 11.19339824700728\n",
      "Steps:  70%|▋| 10446/15000 [1:06:24<14:51,  5.11it/s, lr=9.27e-6, step_loss=0.0107/18/2023 20:09:46 - INFO - __main__ - train loss is 11.521118382457644\n",
      "Steps:  70%|▋| 10447/15000 [1:06:24<14:50,  5.11it/s, lr=9.27e-6, step_loss=0.3207/18/2023 20:09:46 - INFO - __main__ - train loss is 11.526515889447182\n",
      "Steps:  70%|▋| 10448/15000 [1:06:24<14:48,  5.12it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:09:46 - INFO - __main__ - train loss is 11.951952564995736\n",
      "Steps:  70%|▋| 10449/15000 [1:06:24<14:48,  5.12it/s, lr=9.27e-6, step_loss=0.4207/18/2023 20:09:47 - INFO - __main__ - train loss is 11.990086152683944\n",
      "Steps:  70%|▋| 10450/15000 [1:06:25<14:54,  5.08it/s, lr=9.27e-6, step_loss=0.0307/18/2023 20:09:47 - INFO - __main__ - train loss is 12.068782098125666\n",
      "Steps:  70%|▋| 10451/15000 [1:06:25<14:50,  5.11it/s, lr=9.27e-6, step_loss=0.0707/18/2023 20:09:47 - INFO - __main__ - train loss is 12.101558558177203\n",
      "Steps:  70%|▋| 10452/15000 [1:06:25<14:37,  5.18it/s, lr=9.27e-6, step_loss=0.0307/18/2023 20:09:47 - INFO - __main__ - train loss is 12.181639872025698\n",
      "Steps:  70%|▋| 10453/15000 [1:06:25<14:27,  5.24it/s, lr=9.27e-6, step_loss=0.0807/18/2023 20:09:47 - INFO - __main__ - train loss is 12.343140549492091\n",
      "Steps:  70%|▋| 10454/15000 [1:06:25<14:21,  5.28it/s, lr=9.27e-6, step_loss=0.1607/18/2023 20:09:48 - INFO - __main__ - train loss is 12.418589189182967\n",
      "Steps:  70%|▋| 10455/15000 [1:06:26<14:22,  5.27it/s, lr=9.27e-6, step_loss=0.0707/18/2023 20:09:48 - INFO - __main__ - train loss is 12.8115534032695\n",
      "Steps:  70%|▋| 10456/15000 [1:06:26<14:22,  5.27it/s, lr=9.27e-6, step_loss=0.3907/18/2023 20:09:48 - INFO - __main__ - train loss is 12.891658171545714\n",
      "Steps:  70%|▋| 10457/15000 [1:06:26<14:29,  5.22it/s, lr=9.27e-6, step_loss=0.0807/18/2023 20:09:48 - INFO - __main__ - train loss is 12.92394036008045\n",
      "Steps:  70%|▋| 10458/15000 [1:06:26<14:34,  5.19it/s, lr=9.27e-6, step_loss=0.0307/18/2023 20:09:48 - INFO - __main__ - train loss is 12.974654003512114\n",
      "Steps:  70%|▋| 10459/15000 [1:06:26<14:37,  5.17it/s, lr=9.27e-6, step_loss=0.0507/18/2023 20:09:49 - INFO - __main__ - train loss is 13.227311834227294\n",
      "Steps:  70%|▋| 10460/15000 [1:06:26<14:24,  5.25it/s, lr=9.27e-6, step_loss=0.2507/18/2023 20:09:49 - INFO - __main__ - train loss is 13.501843496691436\n",
      "Steps:  70%|▋| 10461/15000 [1:06:27<14:14,  5.31it/s, lr=9.27e-6, step_loss=0.2707/18/2023 20:09:49 - INFO - __main__ - train loss is 13.547302536200732\n",
      "Steps:  70%|▋| 10462/15000 [1:06:27<14:08,  5.35it/s, lr=9.27e-6, step_loss=0.0407/18/2023 20:09:49 - INFO - __main__ - train loss is 13.908016137313098\n",
      "Steps:  70%|▋| 10463/15000 [1:06:27<14:04,  5.37it/s, lr=9.27e-6, step_loss=0.3607/18/2023 20:09:49 - INFO - __main__ - train loss is 14.041210628580302\n",
      "Steps:  70%|▋| 10464/15000 [1:06:27<14:06,  5.36it/s, lr=9.27e-6, step_loss=0.1307/18/2023 20:09:50 - INFO - __main__ - train loss is 14.128304190468043\n",
      "Steps:  70%|▋| 10465/15000 [1:06:27<14:02,  5.38it/s, lr=9.27e-6, step_loss=0.0807/18/2023 20:09:50 - INFO - __main__ - train loss is 14.603912211488932\n",
      "Steps:  70%|▋| 10466/15000 [1:06:28<14:04,  5.37it/s, lr=9.27e-6, step_loss=0.4707/18/2023 20:09:50 - INFO - __main__ - train loss is 14.945671177934855\n",
      "Steps:  70%|▋| 10467/15000 [1:06:28<14:10,  5.33it/s, lr=9.27e-6, step_loss=0.3407/18/2023 20:09:50 - INFO - __main__ - train loss is 14.947348637273535\n",
      "Steps:  70%|▋| 10468/15000 [1:06:28<13:59,  5.40it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:09:50 - INFO - __main__ - train loss is 14.948959022760391\n",
      "Steps:  70%|▋| 10469/15000 [1:06:28<13:50,  5.46it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:09:50 - INFO - __main__ - train loss is 14.960984846577048\n",
      "Steps:  70%|▋| 10470/15000 [1:06:28<13:43,  5.50it/s, lr=9.27e-6, step_loss=0.0107/18/2023 20:09:51 - INFO - __main__ - train loss is 14.967766410205513\n",
      "Steps:  70%|▋| 10471/15000 [1:06:29<13:38,  5.53it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:09:51 - INFO - __main__ - train loss is 15.359349554870278\n",
      "Steps:  70%|▋| 10472/15000 [1:06:29<13:34,  5.56it/s, lr=9.27e-6, step_loss=0.3907/18/2023 20:09:51 - INFO - __main__ - train loss is 15.379909137729555\n",
      "Steps:  70%|▋| 10473/15000 [1:06:29<13:32,  5.57it/s, lr=9.27e-6, step_loss=0.0207/18/2023 20:09:51 - INFO - __main__ - train loss is 15.383031599456444\n",
      "Steps:  70%|▋| 10474/15000 [1:06:29<13:30,  5.58it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:09:51 - INFO - __main__ - train loss is 15.40434579574503\n",
      "Steps:  70%|▋| 10475/15000 [1:06:29<13:29,  5.59it/s, lr=9.27e-6, step_loss=0.0207/18/2023 20:09:52 - INFO - __main__ - train loss is 15.828250274294987\n",
      "Steps:  70%|▋| 10476/15000 [1:06:30<18:26,  4.09it/s, lr=9.27e-6, step_loss=0.4207/18/2023 20:09:52 - INFO - __main__ - Per validation step average loss is 0.002650064881891012\n",
      "07/18/2023 20:09:52 - INFO - __main__ - Cumulative validation average loss is 0.002650064881891012\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Per validation step average loss is 0.06893936544656754\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Cumulative validation average loss is 0.07158943032845855\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Per validation step average loss is 0.26699304580688477\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Cumulative validation average loss is 0.3385824761353433\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Per validation step average loss is 0.2378850281238556\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Cumulative validation average loss is 0.5764675042591989\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Per validation step average loss is 0.002748381346464157\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Cumulative validation average loss is 0.5792158856056631\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Per validation step average loss is 0.0492030568420887\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Cumulative validation average loss is 0.6284189424477518\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Per validation step average loss is 0.3995532989501953\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Cumulative validation average loss is 1.027972241397947\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Per validation step average loss is 0.13966357707977295\n",
      "07/18/2023 20:09:53 - INFO - __main__ - Cumulative validation average loss is 1.16763581847772\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Per validation step average loss is 0.11487260460853577\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Cumulative validation average loss is 1.2825084230862558\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Per validation step average loss is 0.4010409414768219\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Cumulative validation average loss is 1.6835493645630777\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Per validation step average loss is 0.002177150920033455\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Cumulative validation average loss is 1.6857265154831111\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Per validation step average loss is 0.26692095398902893\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Cumulative validation average loss is 1.95264746947214\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Average validation loss for Epoch 107 is 0.16272062245601168\n",
      "07/18/2023 20:09:54 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:10:07 - INFO - __main__ - Starting epoch 108\n",
      "07/18/2023 20:10:07 - INFO - __main__ - train loss is 0.11162065714597702\n",
      "Steps:  70%|▋| 10477/15000 [1:06:45<6:07:30,  4.88s/it, lr=9.27e-6, step_loss=0.07/18/2023 20:10:08 - INFO - __main__ - train loss is 0.461238257586956\n",
      "Steps:  70%|▋| 10478/15000 [1:06:45<4:21:16,  3.47s/it, lr=9.27e-6, step_loss=0.07/18/2023 20:10:08 - INFO - __main__ - train loss is 0.4807138256728649\n",
      "Steps:  70%|▋| 10479/15000 [1:06:46<3:06:59,  2.48s/it, lr=9.27e-6, step_loss=0.07/18/2023 20:10:08 - INFO - __main__ - train loss is 0.48930833023041487\n",
      "Steps:  70%|▋| 10480/15000 [1:06:46<2:14:53,  1.79s/it, lr=9.27e-6, step_loss=0.07/18/2023 20:10:08 - INFO - __main__ - train loss is 0.5106545547023416\n",
      "Steps:  70%|▋| 10481/15000 [1:06:46<1:38:29,  1.31s/it, lr=9.27e-6, step_loss=0.07/18/2023 20:10:08 - INFO - __main__ - train loss is 0.8873656848445535\n",
      "Steps:  70%|▋| 10482/15000 [1:06:46<1:13:04,  1.03it/s, lr=9.27e-6, step_loss=0.07/18/2023 20:10:08 - INFO - __main__ - train loss is 1.1692387023940682\n",
      "Steps:  70%|▋| 10483/15000 [1:06:46<55:16,  1.36it/s, lr=9.27e-6, step_loss=0.2807/18/2023 20:10:09 - INFO - __main__ - train loss is 1.6418988266959786\n",
      "Steps:  70%|▋| 10484/15000 [1:06:47<42:43,  1.76it/s, lr=9.27e-6, step_loss=0.4707/18/2023 20:10:09 - INFO - __main__ - train loss is 1.9348752656951547\n",
      "Steps:  70%|▋| 10485/15000 [1:06:47<33:55,  2.22it/s, lr=9.27e-6, step_loss=0.2907/18/2023 20:10:09 - INFO - __main__ - train loss is 2.080779538489878\n",
      "Steps:  70%|▋| 10486/15000 [1:06:47<27:46,  2.71it/s, lr=9.27e-6, step_loss=0.1407/18/2023 20:10:09 - INFO - __main__ - train loss is 2.4064584532752633\n",
      "Steps:  70%|▋| 10487/15000 [1:06:47<23:27,  3.21it/s, lr=9.27e-6, step_loss=0.3207/18/2023 20:10:09 - INFO - __main__ - train loss is 2.4334797048941255\n",
      "Steps:  70%|▋| 10488/15000 [1:06:47<20:26,  3.68it/s, lr=9.27e-6, step_loss=0.0207/18/2023 20:10:10 - INFO - __main__ - train loss is 2.4653012389317155\n",
      "Steps:  70%|▋| 10489/15000 [1:06:47<18:20,  4.10it/s, lr=9.27e-6, step_loss=0.0307/18/2023 20:10:10 - INFO - __main__ - train loss is 2.5002145329490304\n",
      "Steps:  70%|▋| 10490/15000 [1:06:48<16:50,  4.46it/s, lr=9.27e-6, step_loss=0.0307/18/2023 20:10:10 - INFO - __main__ - train loss is 2.6239469656720757\n",
      "Steps:  70%|▋| 10491/15000 [1:06:48<15:49,  4.75it/s, lr=9.27e-6, step_loss=0.1207/18/2023 20:10:10 - INFO - __main__ - train loss is 3.5564047703519464\n",
      "Steps:  70%|▋| 10492/15000 [1:06:48<15:05,  4.98it/s, lr=9.27e-6, step_loss=0.9307/18/2023 20:10:10 - INFO - __main__ - train loss is 3.5625128289684653\n",
      "Steps:  70%|▋| 10493/15000 [1:06:48<14:34,  5.16it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:10:10 - INFO - __main__ - train loss is 3.5648228076752275\n",
      "Steps:  70%|▋| 10494/15000 [1:06:48<14:13,  5.28it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:10:11 - INFO - __main__ - train loss is 4.297874822979793\n",
      "Steps:  70%|▋| 10495/15000 [1:06:49<14:00,  5.36it/s, lr=9.27e-6, step_loss=0.7307/18/2023 20:10:11 - INFO - __main__ - train loss is 4.3402004388626665\n",
      "Steps:  70%|▋| 10496/15000 [1:06:49<13:49,  5.43it/s, lr=9.27e-6, step_loss=0.0407/18/2023 20:10:11 - INFO - __main__ - train loss is 4.347221927484497\n",
      "Steps:  70%|▋| 10497/15000 [1:06:49<13:44,  5.46it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:10:11 - INFO - __main__ - train loss is 4.35293944994919\n",
      "Steps:  70%|▋| 10498/15000 [1:06:49<13:39,  5.50it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:10:11 - INFO - __main__ - train loss is 4.36109737562947\n",
      "Steps:  70%|▋| 10499/15000 [1:06:49<13:35,  5.52it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:10:12 - INFO - __main__ - train loss is 4.373181693023071\n",
      "Steps:  70%|▋| 10500/15000 [1:06:49<13:39,  5.49it/s, lr=9.27e-6, step_loss=0.0007/18/2023 20:10:12 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-10500\n",
      "07/18/2023 20:10:12 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:10:12,132] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:10:12,136] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-10500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:10:12,136] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-10500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:10:12,144] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-10500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:10:12,144] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-10500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:10:12,163] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-10500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:10:12,163] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-10500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:10:12,163] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:10:12 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-10500/pytorch_model\n",
      "07/18/2023 20:10:12 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-10500/scheduler.bin\n",
      "07/18/2023 20:10:12 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-10500/random_states_0.pkl\n",
      "07/18/2023 20:10:12 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-10500\n",
      "Steps:  70%|▋| 10500/15000 [1:06:49<13:39,  5.49it/s, lr=9.27e-6, step_loss=0.0107/18/2023 20:10:12 - INFO - __main__ - train loss is 4.543138928478584\n",
      "Steps:  70%|▋| 10501/15000 [1:06:50<14:26,  5.20it/s, lr=9.27e-6, step_loss=0.1707/18/2023 20:10:12 - INFO - __main__ - train loss is 4.605493511771783\n",
      "Steps:  70%|▋| 10502/15000 [1:06:50<14:07,  5.31it/s, lr=9.27e-6, step_loss=0.0607/18/2023 20:10:12 - INFO - __main__ - train loss is 4.637488852953538\n",
      "Steps:  70%|▋| 10503/15000 [1:06:50<13:54,  5.39it/s, lr=9.27e-6, step_loss=0.0307/18/2023 20:10:12 - INFO - __main__ - train loss is 5.305088888620958\n",
      "Steps:  70%|▋| 10504/15000 [1:06:50<13:45,  5.45it/s, lr=9.27e-6, step_loss=0.6607/18/2023 20:10:12 - INFO - __main__ - train loss is 5.662566970800981\n",
      "Steps:  70%|▋| 10505/15000 [1:06:50<13:46,  5.44it/s, lr=9.26e-6, step_loss=0.3507/18/2023 20:10:13 - INFO - __main__ - train loss is 5.664814806776121\n",
      "Steps:  70%|▋| 10506/15000 [1:06:51<13:41,  5.47it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:13 - INFO - __main__ - train loss is 6.004000163869932\n",
      "Steps:  70%|▋| 10507/15000 [1:06:51<13:35,  5.51it/s, lr=9.26e-6, step_loss=0.3307/18/2023 20:10:13 - INFO - __main__ - train loss is 6.212325013475493\n",
      "Steps:  70%|▋| 10508/15000 [1:06:51<13:30,  5.54it/s, lr=9.26e-6, step_loss=0.2007/18/2023 20:10:13 - INFO - __main__ - train loss is 6.247064686613157\n",
      "Steps:  70%|▋| 10509/15000 [1:06:51<13:35,  5.51it/s, lr=9.26e-6, step_loss=0.0307/18/2023 20:10:13 - INFO - __main__ - train loss is 6.251180731924251\n",
      "Steps:  70%|▋| 10510/15000 [1:06:51<13:31,  5.54it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:14 - INFO - __main__ - train loss is 6.274166605668142\n",
      "Steps:  70%|▋| 10511/15000 [1:06:51<13:27,  5.56it/s, lr=9.26e-6, step_loss=0.0207/18/2023 20:10:14 - INFO - __main__ - train loss is 6.4409207322169095\n",
      "Steps:  70%|▋| 10512/15000 [1:06:52<13:25,  5.57it/s, lr=9.26e-6, step_loss=0.1607/18/2023 20:10:14 - INFO - __main__ - train loss is 6.678012094693258\n",
      "Steps:  70%|▋| 10513/15000 [1:06:52<13:24,  5.57it/s, lr=9.26e-6, step_loss=0.2307/18/2023 20:10:14 - INFO - __main__ - train loss is 6.739357921527699\n",
      "Steps:  70%|▋| 10514/15000 [1:06:52<13:24,  5.58it/s, lr=9.26e-6, step_loss=0.0607/18/2023 20:10:14 - INFO - __main__ - train loss is 6.801860037492588\n",
      "Steps:  70%|▋| 10515/15000 [1:06:52<13:23,  5.58it/s, lr=9.26e-6, step_loss=0.0607/18/2023 20:10:14 - INFO - __main__ - train loss is 6.821114114718512\n",
      "Steps:  70%|▋| 10516/15000 [1:06:52<13:22,  5.59it/s, lr=9.26e-6, step_loss=0.0107/18/2023 20:10:15 - INFO - __main__ - train loss is 7.173151902155951\n",
      "Steps:  70%|▋| 10517/15000 [1:06:53<13:28,  5.54it/s, lr=9.26e-6, step_loss=0.3507/18/2023 20:10:15 - INFO - __main__ - train loss is 7.341421178774908\n",
      "Steps:  70%|▋| 10518/15000 [1:06:53<13:26,  5.56it/s, lr=9.26e-6, step_loss=0.1607/18/2023 20:10:15 - INFO - __main__ - train loss is 7.345416902797297\n",
      "Steps:  70%|▋| 10519/15000 [1:06:53<13:24,  5.57it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:15 - INFO - __main__ - train loss is 7.374680732609704\n",
      "Steps:  70%|▋| 10520/15000 [1:06:53<13:23,  5.58it/s, lr=9.26e-6, step_loss=0.0207/18/2023 20:10:15 - INFO - __main__ - train loss is 7.417299592169002\n",
      "Steps:  70%|▋| 10521/15000 [1:06:53<13:22,  5.58it/s, lr=9.26e-6, step_loss=0.0407/18/2023 20:10:16 - INFO - __main__ - train loss is 7.421770693501458\n",
      "Steps:  70%|▋| 10522/15000 [1:06:53<13:21,  5.59it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:16 - INFO - __main__ - train loss is 7.423826021375135\n",
      "Steps:  70%|▋| 10523/15000 [1:06:54<13:20,  5.59it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:16 - INFO - __main__ - train loss is 7.8864179973024875\n",
      "Steps:  70%|▋| 10524/15000 [1:06:54<13:19,  5.60it/s, lr=9.26e-6, step_loss=0.4607/18/2023 20:10:16 - INFO - __main__ - train loss is 7.973693614127114\n",
      "Steps:  70%|▋| 10525/15000 [1:06:54<13:28,  5.54it/s, lr=9.26e-6, step_loss=0.0807/18/2023 20:10:16 - INFO - __main__ - train loss is 8.132909153820947\n",
      "Steps:  70%|▋| 10526/15000 [1:06:54<13:25,  5.55it/s, lr=9.26e-6, step_loss=0.1507/18/2023 20:10:16 - INFO - __main__ - train loss is 8.151084979297593\n",
      "Steps:  70%|▋| 10527/15000 [1:06:54<13:23,  5.57it/s, lr=9.26e-6, step_loss=0.0107/18/2023 20:10:17 - INFO - __main__ - train loss is 8.373582561733201\n",
      "Steps:  70%|▋| 10528/15000 [1:06:54<13:22,  5.57it/s, lr=9.26e-6, step_loss=0.2207/18/2023 20:10:17 - INFO - __main__ - train loss is 8.407528841169551\n",
      "Steps:  70%|▋| 10529/15000 [1:06:55<13:21,  5.58it/s, lr=9.26e-6, step_loss=0.0307/18/2023 20:10:17 - INFO - __main__ - train loss is 8.86142893997021\n",
      "Steps:  70%|▋| 10530/15000 [1:06:55<13:20,  5.58it/s, lr=9.26e-6, step_loss=0.4507/18/2023 20:10:17 - INFO - __main__ - train loss is 9.002793112071231\n",
      "Steps:  70%|▋| 10531/15000 [1:06:55<13:21,  5.58it/s, lr=9.26e-6, step_loss=0.1407/18/2023 20:10:17 - INFO - __main__ - train loss is 9.125131347449496\n",
      "Steps:  70%|▋| 10532/15000 [1:06:55<13:20,  5.58it/s, lr=9.26e-6, step_loss=0.1207/18/2023 20:10:18 - INFO - __main__ - train loss is 9.140365325147286\n",
      "Steps:  70%|▋| 10533/15000 [1:06:55<13:22,  5.57it/s, lr=9.26e-6, step_loss=0.0107/18/2023 20:10:18 - INFO - __main__ - train loss is 9.218413330847397\n",
      "Steps:  70%|▋| 10534/15000 [1:06:56<13:21,  5.57it/s, lr=9.26e-6, step_loss=0.0707/18/2023 20:10:18 - INFO - __main__ - train loss is 9.400555528933182\n",
      "Steps:  70%|▋| 10535/15000 [1:06:56<13:28,  5.52it/s, lr=9.26e-6, step_loss=0.1807/18/2023 20:10:18 - INFO - __main__ - train loss is 9.452422343427315\n",
      "Steps:  70%|▋| 10536/15000 [1:06:56<13:27,  5.53it/s, lr=9.26e-6, step_loss=0.0507/18/2023 20:10:18 - INFO - __main__ - train loss is 9.748972647124901\n",
      "Steps:  70%|▋| 10537/15000 [1:06:56<13:32,  5.49it/s, lr=9.26e-6, step_loss=0.2907/18/2023 20:10:18 - INFO - __main__ - train loss is 10.53283714526333\n",
      "Steps:  70%|▋| 10538/15000 [1:06:56<13:42,  5.43it/s, lr=9.26e-6, step_loss=0.7807/18/2023 20:10:19 - INFO - __main__ - train loss is 10.534817600389943\n",
      "Steps:  70%|▋| 10539/15000 [1:06:56<13:37,  5.46it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:19 - INFO - __main__ - train loss is 10.536891980329528\n",
      "Steps:  70%|▋| 10540/15000 [1:06:57<13:31,  5.50it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:19 - INFO - __main__ - train loss is 11.057981057325378\n",
      "Steps:  70%|▋| 10541/15000 [1:06:57<13:27,  5.52it/s, lr=9.26e-6, step_loss=0.5207/18/2023 20:10:19 - INFO - __main__ - train loss is 11.134709460893646\n",
      "Steps:  70%|▋| 10542/15000 [1:06:57<13:31,  5.49it/s, lr=9.26e-6, step_loss=0.0707/18/2023 20:10:19 - INFO - __main__ - train loss is 11.293701244750991\n",
      "Steps:  70%|▋| 10543/15000 [1:06:57<13:27,  5.52it/s, lr=9.26e-6, step_loss=0.1507/18/2023 20:10:20 - INFO - __main__ - train loss is 11.414360797265545\n",
      "Steps:  70%|▋| 10544/15000 [1:06:57<13:31,  5.49it/s, lr=9.26e-6, step_loss=0.1207/18/2023 20:10:20 - INFO - __main__ - train loss is 11.434646548936144\n",
      "Steps:  70%|▋| 10545/15000 [1:06:58<13:37,  5.45it/s, lr=9.26e-6, step_loss=0.0207/18/2023 20:10:20 - INFO - __main__ - train loss is 11.492724867770448\n",
      "Steps:  70%|▋| 10546/15000 [1:06:58<13:32,  5.48it/s, lr=9.26e-6, step_loss=0.0507/18/2023 20:10:20 - INFO - __main__ - train loss is 11.570764677831903\n",
      "Steps:  70%|▋| 10547/15000 [1:06:58<13:28,  5.51it/s, lr=9.26e-6, step_loss=0.0707/18/2023 20:10:20 - INFO - __main__ - train loss is 11.813648598501459\n",
      "Steps:  70%|▋| 10548/15000 [1:06:58<13:24,  5.53it/s, lr=9.26e-6, step_loss=0.2407/18/2023 20:10:20 - INFO - __main__ - train loss is 12.080923753092065\n",
      "Steps:  70%|▋| 10549/15000 [1:06:58<13:27,  5.51it/s, lr=9.26e-6, step_loss=0.2607/18/2023 20:10:21 - INFO - __main__ - train loss is 12.344728576252237\n",
      "Steps:  70%|▋| 10550/15000 [1:06:58<13:27,  5.51it/s, lr=9.26e-6, step_loss=0.2607/18/2023 20:10:21 - INFO - __main__ - train loss is 12.369035190204158\n",
      "Steps:  70%|▋| 10551/15000 [1:06:59<13:27,  5.51it/s, lr=9.26e-6, step_loss=0.0207/18/2023 20:10:21 - INFO - __main__ - train loss is 12.374596905661747\n",
      "Steps:  70%|▋| 10552/15000 [1:06:59<13:27,  5.51it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:21 - INFO - __main__ - train loss is 12.907951009226963\n",
      "Steps:  70%|▋| 10553/15000 [1:06:59<13:27,  5.51it/s, lr=9.26e-6, step_loss=0.5307/18/2023 20:10:21 - INFO - __main__ - train loss is 12.911605007946491\n",
      "Steps:  70%|▋| 10554/15000 [1:06:59<13:26,  5.51it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:22 - INFO - __main__ - train loss is 12.919587726704776\n",
      "Steps:  70%|▋| 10555/15000 [1:06:59<13:34,  5.46it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:22 - INFO - __main__ - train loss is 13.044923464767635\n",
      "Steps:  70%|▋| 10556/15000 [1:07:00<13:32,  5.47it/s, lr=9.26e-6, step_loss=0.1207/18/2023 20:10:22 - INFO - __main__ - train loss is 13.050259195268154\n",
      "Steps:  70%|▋| 10557/15000 [1:07:00<13:33,  5.46it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:22 - INFO - __main__ - train loss is 13.072400331497192\n",
      "Steps:  70%|▋| 10558/15000 [1:07:00<13:29,  5.48it/s, lr=9.26e-6, step_loss=0.0207/18/2023 20:10:22 - INFO - __main__ - train loss is 13.11174027621746\n",
      "Steps:  70%|▋| 10559/15000 [1:07:00<13:24,  5.52it/s, lr=9.26e-6, step_loss=0.0307/18/2023 20:10:22 - INFO - __main__ - train loss is 13.155837140977383\n",
      "Steps:  70%|▋| 10560/15000 [1:07:00<13:20,  5.55it/s, lr=9.26e-6, step_loss=0.0407/18/2023 20:10:23 - INFO - __main__ - train loss is 13.21287539601326\n",
      "Steps:  70%|▋| 10561/15000 [1:07:00<13:17,  5.56it/s, lr=9.26e-6, step_loss=0.0507/18/2023 20:10:23 - INFO - __main__ - train loss is 13.267062287777662\n",
      "Steps:  70%|▋| 10562/15000 [1:07:01<13:15,  5.58it/s, lr=9.26e-6, step_loss=0.0507/18/2023 20:10:23 - INFO - __main__ - train loss is 13.726945471018553\n",
      "Steps:  70%|▋| 10563/15000 [1:07:01<13:14,  5.58it/s, lr=9.26e-6, step_loss=0.4607/18/2023 20:10:23 - INFO - __main__ - train loss is 13.748109973967075\n",
      "Steps:  70%|▋| 10564/15000 [1:07:01<13:13,  5.59it/s, lr=9.26e-6, step_loss=0.0207/18/2023 20:10:23 - INFO - __main__ - train loss is 13.751305205281824\n",
      "Steps:  70%|▋| 10565/15000 [1:07:01<13:13,  5.59it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:23 - INFO - __main__ - train loss is 13.8412976837717\n",
      "Steps:  70%|▋| 10566/15000 [1:07:01<13:12,  5.59it/s, lr=9.26e-6, step_loss=0.0907/18/2023 20:10:24 - INFO - __main__ - train loss is 13.84334447234869\n",
      "Steps:  70%|▋| 10567/15000 [1:07:02<13:17,  5.56it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:24 - INFO - __main__ - train loss is 14.142383597791195\n",
      "Steps:  70%|▋| 10568/15000 [1:07:02<13:14,  5.58it/s, lr=9.26e-6, step_loss=0.2907/18/2023 20:10:24 - INFO - __main__ - train loss is 14.151488144882023\n",
      "Steps:  70%|▋| 10569/15000 [1:07:02<13:14,  5.58it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:24 - INFO - __main__ - train loss is 14.348928441293538\n",
      "Steps:  70%|▋| 10570/15000 [1:07:02<13:12,  5.59it/s, lr=9.26e-6, step_loss=0.1907/18/2023 20:10:24 - INFO - __main__ - train loss is 14.492265124805272\n",
      "Steps:  70%|▋| 10571/15000 [1:07:02<13:11,  5.60it/s, lr=9.26e-6, step_loss=0.1407/18/2023 20:10:25 - INFO - __main__ - train loss is 14.497938876971602\n",
      "Steps:  70%|▋| 10572/15000 [1:07:02<13:10,  5.60it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:25 - INFO - __main__ - train loss is 14.500426635146141\n",
      "Steps:  70%|▋| 10573/15000 [1:07:03<17:42,  4.17it/s, lr=9.26e-6, step_loss=0.0007/18/2023 20:10:26 - INFO - __main__ - Per validation step average loss is 0.00603023124858737\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Cumulative validation average loss is 0.00603023124858737\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Per validation step average loss is 0.14823240041732788\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Cumulative validation average loss is 0.15426263166591525\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Per validation step average loss is 0.34138885140419006\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Cumulative validation average loss is 0.4956514830701053\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Per validation step average loss is 0.07392080128192902\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Cumulative validation average loss is 0.5695722843520343\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Per validation step average loss is 0.006692389026284218\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Cumulative validation average loss is 0.5762646733783185\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Per validation step average loss is 0.21486085653305054\n",
      "07/18/2023 20:10:26 - INFO - __main__ - Cumulative validation average loss is 0.7911255299113691\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Per validation step average loss is 0.12025709450244904\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Cumulative validation average loss is 0.9113826244138181\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Per validation step average loss is 0.08112824708223343\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Cumulative validation average loss is 0.9925108714960515\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Per validation step average loss is 0.003158089704811573\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Cumulative validation average loss is 0.9956689612008631\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Per validation step average loss is 0.0036190254613757133\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Cumulative validation average loss is 0.9992879866622388\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Per validation step average loss is 0.0013440323527902365\n",
      "07/18/2023 20:10:27 - INFO - __main__ - Cumulative validation average loss is 1.000632019015029\n",
      "07/18/2023 20:10:28 - INFO - __main__ - Per validation step average loss is 0.0035392462741583586\n",
      "07/18/2023 20:10:28 - INFO - __main__ - Cumulative validation average loss is 1.0041712652891874\n",
      "07/18/2023 20:10:28 - INFO - __main__ - Average validation loss for Epoch 108 is 0.08368093877409895\n",
      "07/18/2023 20:10:28 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:10:40 - INFO - __main__ - Starting epoch 109\n",
      "07/18/2023 20:10:41 - INFO - __main__ - train loss is 0.002426188439130783\n",
      "Steps:  70%|▋| 10574/15000 [1:07:19<6:06:00,  4.96s/it, lr=9.26e-6, step_loss=0.07/18/2023 20:10:41 - INFO - __main__ - train loss is 0.017439795657992363\n",
      "Steps:  70%|▋| 10575/15000 [1:07:19<4:20:15,  3.53s/it, lr=9.26e-6, step_loss=0.07/18/2023 20:10:41 - INFO - __main__ - train loss is 0.043743010610342026\n",
      "Steps:  71%|▋| 10576/15000 [1:07:19<3:06:17,  2.53s/it, lr=9.26e-6, step_loss=0.07/18/2023 20:10:41 - INFO - __main__ - train loss is 0.045482803136110306\n",
      "Steps:  71%|▋| 10577/15000 [1:07:19<2:14:26,  1.82s/it, lr=9.26e-6, step_loss=0.07/18/2023 20:10:42 - INFO - __main__ - train loss is 0.07366210967302322\n",
      "Steps:  71%|▋| 10578/15000 [1:07:20<1:38:21,  1.33s/it, lr=9.25e-6, step_loss=0.07/18/2023 20:10:42 - INFO - __main__ - train loss is 0.10901810601353645\n",
      "Steps:  71%|▋| 10579/15000 [1:07:20<1:13:11,  1.01it/s, lr=9.25e-6, step_loss=0.07/18/2023 20:10:42 - INFO - __main__ - train loss is 0.5907219536602497\n",
      "Steps:  71%|▋| 10580/15000 [1:07:20<55:29,  1.33it/s, lr=9.25e-6, step_loss=0.4807/18/2023 20:10:42 - INFO - __main__ - train loss is 0.6001737983897328\n",
      "Steps:  71%|▋| 10581/15000 [1:07:20<43:06,  1.71it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:42 - INFO - __main__ - train loss is 0.6571367690339684\n",
      "Steps:  71%|▋| 10582/15000 [1:07:20<34:26,  2.14it/s, lr=9.25e-6, step_loss=0.0507/18/2023 20:10:43 - INFO - __main__ - train loss is 0.662551139947027\n",
      "Steps:  71%|▋| 10583/15000 [1:07:21<28:22,  2.59it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:43 - INFO - __main__ - train loss is 0.6640327437780797\n",
      "Steps:  71%|▋| 10584/15000 [1:07:21<24:07,  3.05it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:43 - INFO - __main__ - train loss is 0.9689220055006444\n",
      "Steps:  71%|▋| 10585/15000 [1:07:21<21:10,  3.48it/s, lr=9.25e-6, step_loss=0.3007/18/2023 20:10:43 - INFO - __main__ - train loss is 1.212929294910282\n",
      "Steps:  71%|▋| 10586/15000 [1:07:21<19:04,  3.86it/s, lr=9.25e-6, step_loss=0.2407/18/2023 20:10:43 - INFO - __main__ - train loss is 1.2728747627697885\n",
      "Steps:  71%|▋| 10587/15000 [1:07:21<17:37,  4.17it/s, lr=9.25e-6, step_loss=0.0507/18/2023 20:10:44 - INFO - __main__ - train loss is 1.8257499835453928\n",
      "Steps:  71%|▋| 10588/15000 [1:07:21<16:31,  4.45it/s, lr=9.25e-6, step_loss=0.5507/18/2023 20:10:44 - INFO - __main__ - train loss is 1.8810695162974298\n",
      "Steps:  71%|▋| 10589/15000 [1:07:22<15:33,  4.72it/s, lr=9.25e-6, step_loss=0.0507/18/2023 20:10:44 - INFO - __main__ - train loss is 2.0642524412833154\n",
      "Steps:  71%|▋| 10590/15000 [1:07:22<15:03,  4.88it/s, lr=9.25e-6, step_loss=0.1807/18/2023 20:10:44 - INFO - __main__ - train loss is 2.109223825391382\n",
      "Steps:  71%|▋| 10591/15000 [1:07:22<14:50,  4.95it/s, lr=9.25e-6, step_loss=0.0407/18/2023 20:10:44 - INFO - __main__ - train loss is 2.258470696862787\n",
      "Steps:  71%|▋| 10592/15000 [1:07:22<14:39,  5.01it/s, lr=9.25e-6, step_loss=0.1407/18/2023 20:10:45 - INFO - __main__ - train loss is 2.4508459246717393\n",
      "Steps:  71%|▋| 10593/15000 [1:07:22<14:27,  5.08it/s, lr=9.25e-6, step_loss=0.1907/18/2023 20:10:45 - INFO - __main__ - train loss is 2.463525492232293\n",
      "Steps:  71%|▋| 10594/15000 [1:07:23<14:19,  5.13it/s, lr=9.25e-6, step_loss=0.0107/18/2023 20:10:45 - INFO - __main__ - train loss is 2.8122160914354026\n",
      "Steps:  71%|▋| 10595/15000 [1:07:23<14:11,  5.17it/s, lr=9.25e-6, step_loss=0.3407/18/2023 20:10:45 - INFO - __main__ - train loss is 2.886565166991204\n",
      "Steps:  71%|▋| 10596/15000 [1:07:23<14:12,  5.16it/s, lr=9.25e-6, step_loss=0.0707/18/2023 20:10:45 - INFO - __main__ - train loss is 2.8936864766292274\n",
      "Steps:  71%|▋| 10597/15000 [1:07:23<14:14,  5.15it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:46 - INFO - __main__ - train loss is 3.030202630441636\n",
      "Steps:  71%|▋| 10598/15000 [1:07:23<14:15,  5.15it/s, lr=9.25e-6, step_loss=0.1307/18/2023 20:10:46 - INFO - __main__ - train loss is 3.2490417691878974\n",
      "Steps:  71%|▋| 10599/15000 [1:07:24<14:15,  5.15it/s, lr=9.25e-6, step_loss=0.2107/18/2023 20:10:46 - INFO - __main__ - train loss is 3.2764794803224504\n",
      "Steps:  71%|▋| 10600/15000 [1:07:24<14:21,  5.11it/s, lr=9.25e-6, step_loss=0.0207/18/2023 20:10:46 - INFO - __main__ - train loss is 3.286986344959587\n",
      "Steps:  71%|▋| 10601/15000 [1:07:24<14:20,  5.11it/s, lr=9.25e-6, step_loss=0.0107/18/2023 20:10:46 - INFO - __main__ - train loss is 3.3086008015088737\n",
      "Steps:  71%|▋| 10602/15000 [1:07:24<14:21,  5.10it/s, lr=9.25e-6, step_loss=0.0207/18/2023 20:10:46 - INFO - __main__ - train loss is 3.3216449986211956\n",
      "Steps:  71%|▋| 10603/15000 [1:07:24<14:19,  5.12it/s, lr=9.25e-6, step_loss=0.0107/18/2023 20:10:47 - INFO - __main__ - train loss is 3.627507127355784\n",
      "Steps:  71%|▋| 10604/15000 [1:07:25<14:18,  5.12it/s, lr=9.25e-6, step_loss=0.3007/18/2023 20:10:47 - INFO - __main__ - train loss is 3.6498225214891136\n",
      "Steps:  71%|▋| 10605/15000 [1:07:25<14:16,  5.13it/s, lr=9.25e-6, step_loss=0.0207/18/2023 20:10:47 - INFO - __main__ - train loss is 3.7404286745004356\n",
      "Steps:  71%|▋| 10606/15000 [1:07:25<14:17,  5.13it/s, lr=9.25e-6, step_loss=0.0907/18/2023 20:10:47 - INFO - __main__ - train loss is 3.8190696421079338\n",
      "Steps:  71%|▋| 10607/15000 [1:07:25<14:18,  5.12it/s, lr=9.25e-6, step_loss=0.0707/18/2023 20:10:47 - INFO - __main__ - train loss is 3.831741569098085\n",
      "Steps:  71%|▋| 10608/15000 [1:07:25<14:13,  5.15it/s, lr=9.25e-6, step_loss=0.0107/18/2023 20:10:48 - INFO - __main__ - train loss is 3.8384351818822324\n",
      "Steps:  71%|▋| 10609/15000 [1:07:26<14:19,  5.11it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:48 - INFO - __main__ - train loss is 3.8409184322226793\n",
      "Steps:  71%|▋| 10610/15000 [1:07:26<14:21,  5.10it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:48 - INFO - __main__ - train loss is 3.8632028542924672\n",
      "Steps:  71%|▋| 10611/15000 [1:07:26<14:23,  5.08it/s, lr=9.25e-6, step_loss=0.0207/18/2023 20:10:48 - INFO - __main__ - train loss is 3.8732597671914846\n",
      "Steps:  71%|▋| 10612/15000 [1:07:26<14:25,  5.07it/s, lr=9.25e-6, step_loss=0.0107/18/2023 20:10:48 - INFO - __main__ - train loss is 4.798707231180742\n",
      "Steps:  71%|▋| 10613/15000 [1:07:26<14:40,  4.98it/s, lr=9.25e-6, step_loss=0.9207/18/2023 20:10:49 - INFO - __main__ - train loss is 4.869706890778616\n",
      "Steps:  71%|▋| 10614/15000 [1:07:27<14:25,  5.07it/s, lr=9.25e-6, step_loss=0.0707/18/2023 20:10:49 - INFO - __main__ - train loss is 4.998962364392355\n",
      "Steps:  71%|▋| 10615/15000 [1:07:27<14:18,  5.11it/s, lr=9.25e-6, step_loss=0.1207/18/2023 20:10:49 - INFO - __main__ - train loss is 5.398143819766119\n",
      "Steps:  71%|▋| 10616/15000 [1:07:27<14:15,  5.12it/s, lr=9.25e-6, step_loss=0.3907/18/2023 20:10:49 - INFO - __main__ - train loss is 5.5174306847620755\n",
      "Steps:  71%|▋| 10617/15000 [1:07:27<14:16,  5.11it/s, lr=9.25e-6, step_loss=0.1107/18/2023 20:10:49 - INFO - __main__ - train loss is 5.520609817234799\n",
      "Steps:  71%|▋| 10618/15000 [1:07:27<14:14,  5.13it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:50 - INFO - __main__ - train loss is 5.811838648049161\n",
      "Steps:  71%|▋| 10619/15000 [1:07:28<14:05,  5.18it/s, lr=9.25e-6, step_loss=0.2907/18/2023 20:10:50 - INFO - __main__ - train loss is 6.108560821739957\n",
      "Steps:  71%|▋| 10620/15000 [1:07:28<14:07,  5.17it/s, lr=9.25e-6, step_loss=0.2907/18/2023 20:10:50 - INFO - __main__ - train loss is 6.112881012028083\n",
      "Steps:  71%|▋| 10621/15000 [1:07:28<14:09,  5.16it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:50 - INFO - __main__ - train loss is 6.191995799308643\n",
      "Steps:  71%|▋| 10622/15000 [1:07:28<14:08,  5.16it/s, lr=9.25e-6, step_loss=0.0707/18/2023 20:10:50 - INFO - __main__ - train loss is 6.214832722907886\n",
      "Steps:  71%|▋| 10623/15000 [1:07:28<14:11,  5.14it/s, lr=9.25e-6, step_loss=0.0207/18/2023 20:10:51 - INFO - __main__ - train loss is 6.40601335442625\n",
      "Steps:  71%|▋| 10624/15000 [1:07:28<14:11,  5.14it/s, lr=9.25e-6, step_loss=0.1907/18/2023 20:10:51 - INFO - __main__ - train loss is 6.965730413561687\n",
      "Steps:  71%|▋| 10625/15000 [1:07:29<14:06,  5.17it/s, lr=9.25e-6, step_loss=0.5607/18/2023 20:10:51 - INFO - __main__ - train loss is 7.039718232816085\n",
      "Steps:  71%|▋| 10626/15000 [1:07:29<13:49,  5.27it/s, lr=9.25e-6, step_loss=0.0707/18/2023 20:10:51 - INFO - __main__ - train loss is 7.129541523521766\n",
      "Steps:  71%|▋| 10627/15000 [1:07:29<13:43,  5.31it/s, lr=9.25e-6, step_loss=0.0807/18/2023 20:10:51 - INFO - __main__ - train loss is 7.1310116169042885\n",
      "Steps:  71%|▋| 10628/15000 [1:07:29<13:30,  5.40it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:52 - INFO - __main__ - train loss is 7.334889453370124\n",
      "Steps:  71%|▋| 10629/15000 [1:07:29<13:21,  5.45it/s, lr=9.25e-6, step_loss=0.2007/18/2023 20:10:52 - INFO - __main__ - train loss is 7.387579080183059\n",
      "Steps:  71%|▋| 10630/15000 [1:07:30<13:22,  5.44it/s, lr=9.25e-6, step_loss=0.0507/18/2023 20:10:52 - INFO - __main__ - train loss is 7.6045635608024895\n",
      "Steps:  71%|▋| 10631/15000 [1:07:30<13:18,  5.47it/s, lr=9.25e-6, step_loss=0.2107/18/2023 20:10:52 - INFO - __main__ - train loss is 7.963088717777282\n",
      "Steps:  71%|▋| 10632/15000 [1:07:30<13:13,  5.51it/s, lr=9.25e-6, step_loss=0.3507/18/2023 20:10:52 - INFO - __main__ - train loss is 8.147896465379745\n",
      "Steps:  71%|▋| 10633/15000 [1:07:30<13:16,  5.48it/s, lr=9.25e-6, step_loss=0.1807/18/2023 20:10:52 - INFO - __main__ - train loss is 8.149348452920094\n",
      "Steps:  71%|▋| 10634/15000 [1:07:30<13:11,  5.52it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:53 - INFO - __main__ - train loss is 8.243091896409169\n",
      "Steps:  71%|▋| 10635/15000 [1:07:30<13:15,  5.49it/s, lr=9.25e-6, step_loss=0.0907/18/2023 20:10:53 - INFO - __main__ - train loss is 8.316857718164101\n",
      "Steps:  71%|▋| 10636/15000 [1:07:31<13:20,  5.45it/s, lr=9.25e-6, step_loss=0.0707/18/2023 20:10:53 - INFO - __main__ - train loss is 8.382972225779667\n",
      "Steps:  71%|▋| 10637/15000 [1:07:31<13:16,  5.48it/s, lr=9.25e-6, step_loss=0.0607/18/2023 20:10:53 - INFO - __main__ - train loss is 8.403684608871117\n",
      "Steps:  71%|▋| 10638/15000 [1:07:31<13:11,  5.51it/s, lr=9.25e-6, step_loss=0.0207/18/2023 20:10:53 - INFO - __main__ - train loss is 8.405333610717207\n",
      "Steps:  71%|▋| 10639/15000 [1:07:31<13:08,  5.53it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:54 - INFO - __main__ - train loss is 8.44678650284186\n",
      "Steps:  71%|▋| 10640/15000 [1:07:31<13:06,  5.55it/s, lr=9.25e-6, step_loss=0.0407/18/2023 20:10:54 - INFO - __main__ - train loss is 8.458716957364231\n",
      "Steps:  71%|▋| 10641/15000 [1:07:32<13:04,  5.56it/s, lr=9.25e-6, step_loss=0.0107/18/2023 20:10:54 - INFO - __main__ - train loss is 8.465387375093997\n",
      "Steps:  71%|▋| 10642/15000 [1:07:32<13:10,  5.51it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:54 - INFO - __main__ - train loss is 8.730758936144412\n",
      "Steps:  71%|▋| 10643/15000 [1:07:32<13:13,  5.49it/s, lr=9.25e-6, step_loss=0.2607/18/2023 20:10:54 - INFO - __main__ - train loss is 8.73756586574018\n",
      "Steps:  71%|▋| 10644/15000 [1:07:32<13:08,  5.52it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:54 - INFO - __main__ - train loss is 8.781157972291112\n",
      "Steps:  71%|▋| 10645/15000 [1:07:32<13:05,  5.55it/s, lr=9.25e-6, step_loss=0.0407/18/2023 20:10:55 - INFO - __main__ - train loss is 9.46569407172501\n",
      "Steps:  71%|▋| 10646/15000 [1:07:32<13:02,  5.57it/s, lr=9.25e-6, step_loss=0.6807/18/2023 20:10:55 - INFO - __main__ - train loss is 9.473066586069763\n",
      "Steps:  71%|▋| 10647/15000 [1:07:33<13:01,  5.57it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:55 - INFO - __main__ - train loss is 9.478612754493952\n",
      "Steps:  71%|▋| 10648/15000 [1:07:33<13:00,  5.58it/s, lr=9.25e-6, step_loss=0.0007/18/2023 20:10:55 - INFO - __main__ - train loss is 9.830179069191217\n",
      "Steps:  71%|▋| 10649/15000 [1:07:33<12:59,  5.58it/s, lr=9.25e-6, step_loss=0.3507/18/2023 20:10:55 - INFO - __main__ - train loss is 9.857470855116844\n",
      "Steps:  71%|▋| 10650/15000 [1:07:33<12:58,  5.59it/s, lr=9.25e-6, step_loss=0.0207/18/2023 20:10:55 - INFO - __main__ - train loss is 9.890091724693775\n",
      "Steps:  71%|▋| 10651/15000 [1:07:33<12:57,  5.59it/s, lr=9.24e-6, step_loss=0.0307/18/2023 20:10:56 - INFO - __main__ - train loss is 10.094369120895863\n",
      "Steps:  71%|▋| 10652/15000 [1:07:34<12:57,  5.59it/s, lr=9.24e-6, step_loss=0.2007/18/2023 20:10:56 - INFO - __main__ - train loss is 10.314728580415249\n",
      "Steps:  71%|▋| 10653/15000 [1:07:34<12:56,  5.60it/s, lr=9.24e-6, step_loss=0.2207/18/2023 20:10:56 - INFO - __main__ - train loss is 10.330378137528896\n",
      "Steps:  71%|▋| 10654/15000 [1:07:34<12:56,  5.60it/s, lr=9.24e-6, step_loss=0.0107/18/2023 20:10:56 - INFO - __main__ - train loss is 10.697871051728725\n",
      "Steps:  71%|▋| 10655/15000 [1:07:34<12:55,  5.60it/s, lr=9.24e-6, step_loss=0.3607/18/2023 20:10:56 - INFO - __main__ - train loss is 10.710089437663555\n",
      "Steps:  71%|▋| 10656/15000 [1:07:34<12:55,  5.60it/s, lr=9.24e-6, step_loss=0.0107/18/2023 20:10:57 - INFO - __main__ - train loss is 10.803906723856926\n",
      "Steps:  71%|▋| 10657/15000 [1:07:34<12:55,  5.60it/s, lr=9.24e-6, step_loss=0.0907/18/2023 20:10:57 - INFO - __main__ - train loss is 10.805902487365529\n",
      "Steps:  71%|▋| 10658/15000 [1:07:35<12:54,  5.61it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:10:57 - INFO - __main__ - train loss is 10.951472899643704\n",
      "Steps:  71%|▋| 10659/15000 [1:07:35<12:53,  5.61it/s, lr=9.24e-6, step_loss=0.1407/18/2023 20:10:57 - INFO - __main__ - train loss is 11.030320263234898\n",
      "Steps:  71%|▋| 10660/15000 [1:07:35<12:53,  5.61it/s, lr=9.24e-6, step_loss=0.0707/18/2023 20:10:57 - INFO - __main__ - train loss is 11.22270596656017\n",
      "Steps:  71%|▋| 10661/15000 [1:07:35<12:53,  5.61it/s, lr=9.24e-6, step_loss=0.1907/18/2023 20:10:57 - INFO - __main__ - train loss is 11.23043649061583\n",
      "Steps:  71%|▋| 10662/15000 [1:07:35<12:52,  5.61it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:10:58 - INFO - __main__ - train loss is 11.321309992810711\n",
      "Steps:  71%|▋| 10663/15000 [1:07:36<12:52,  5.61it/s, lr=9.24e-6, step_loss=0.0907/18/2023 20:10:58 - INFO - __main__ - train loss is 11.425767013570294\n",
      "Steps:  71%|▋| 10664/15000 [1:07:36<12:52,  5.61it/s, lr=9.24e-6, step_loss=0.1007/18/2023 20:10:58 - INFO - __main__ - train loss is 11.687675902387127\n",
      "Steps:  71%|▋| 10665/15000 [1:07:36<12:52,  5.61it/s, lr=9.24e-6, step_loss=0.2607/18/2023 20:10:58 - INFO - __main__ - train loss is 11.693839360726997\n",
      "Steps:  71%|▋| 10666/15000 [1:07:36<12:52,  5.61it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:10:58 - INFO - __main__ - train loss is 11.70113931200467\n",
      "Steps:  71%|▋| 10667/15000 [1:07:36<12:59,  5.56it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:10:59 - INFO - __main__ - train loss is 11.825989167904481\n",
      "Steps:  71%|▋| 10668/15000 [1:07:36<13:05,  5.52it/s, lr=9.24e-6, step_loss=0.1207/18/2023 20:10:59 - INFO - __main__ - train loss is 12.349887650227174\n",
      "Steps:  71%|▋| 10669/15000 [1:07:37<13:09,  5.49it/s, lr=9.24e-6, step_loss=0.5207/18/2023 20:10:59 - INFO - __main__ - train loss is 12.371255689999089\n",
      "Steps:  71%|▋| 10670/15000 [1:07:37<17:42,  4.07it/s, lr=9.24e-6, step_loss=0.0207/18/2023 20:11:00 - INFO - __main__ - Per validation step average loss is 0.016014065593481064\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Cumulative validation average loss is 0.016014065593481064\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Per validation step average loss is 0.0016620398964732885\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Cumulative validation average loss is 0.017676105489954352\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Per validation step average loss is 0.0077541284263134\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Cumulative validation average loss is 0.025430233916267753\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Per validation step average loss is 0.12588195502758026\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Cumulative validation average loss is 0.15131218894384801\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Per validation step average loss is 0.0027396264486014843\n",
      "07/18/2023 20:11:00 - INFO - __main__ - Cumulative validation average loss is 0.1540518153924495\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Per validation step average loss is 0.5519900918006897\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Cumulative validation average loss is 0.7060419071931392\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Per validation step average loss is 0.029769644141197205\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Cumulative validation average loss is 0.7358115513343364\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Per validation step average loss is 0.03428559750318527\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Cumulative validation average loss is 0.7700971488375217\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Per validation step average loss is 0.005329438950866461\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Cumulative validation average loss is 0.7754265877883881\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Per validation step average loss is 0.17518725991249084\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Cumulative validation average loss is 0.950613847700879\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Per validation step average loss is 0.21272122859954834\n",
      "07/18/2023 20:11:01 - INFO - __main__ - Cumulative validation average loss is 1.1633350763004273\n",
      "07/18/2023 20:11:02 - INFO - __main__ - Per validation step average loss is 0.47596603631973267\n",
      "07/18/2023 20:11:02 - INFO - __main__ - Cumulative validation average loss is 1.63930111262016\n",
      "07/18/2023 20:11:02 - INFO - __main__ - Average validation loss for Epoch 109 is 0.13660842605168\n",
      "07/18/2023 20:11:02 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:11:14 - INFO - __main__ - Starting epoch 110\n",
      "07/18/2023 20:11:15 - INFO - __main__ - train loss is 0.0036364567931741476\n",
      "Steps:  71%|▋| 10671/15000 [1:07:53<6:03:48,  5.04s/it, lr=9.24e-6, step_loss=0.07/18/2023 20:11:16 - INFO - __main__ - train loss is 0.4976689589675516\n",
      "Steps:  71%|▋| 10672/15000 [1:07:54<4:26:29,  3.69s/it, lr=9.24e-6, step_loss=0.07/18/2023 20:11:16 - INFO - __main__ - train loss is 0.7368438316043466\n",
      "Steps:  71%|▋| 10673/15000 [1:07:54<3:18:23,  2.75s/it, lr=9.24e-6, step_loss=0.07/18/2023 20:11:17 - INFO - __main__ - train loss is 0.7475536696147174\n",
      "Steps:  71%|▋| 10674/15000 [1:07:55<2:30:44,  2.09s/it, lr=9.24e-6, step_loss=0.07/18/2023 20:11:18 - INFO - __main__ - train loss is 1.0454972020816058\n",
      "Steps:  71%|▋| 10675/15000 [1:07:55<1:57:24,  1.63s/it, lr=9.24e-6, step_loss=0.07/18/2023 20:11:18 - INFO - __main__ - train loss is 1.078887530369684\n",
      "Steps:  71%|▋| 10676/15000 [1:07:56<1:33:57,  1.30s/it, lr=9.24e-6, step_loss=0.07/18/2023 20:11:19 - INFO - __main__ - train loss is 1.0805459644179791\n",
      "Steps:  71%|▋| 10677/15000 [1:07:57<1:17:37,  1.08s/it, lr=9.24e-6, step_loss=0.07/18/2023 20:11:19 - INFO - __main__ - train loss is 1.4261798288207501\n",
      "Steps:  71%|▋| 10678/15000 [1:07:57<1:05:59,  1.09it/s, lr=9.24e-6, step_loss=0.07/18/2023 20:11:20 - INFO - __main__ - train loss is 1.9874211575370282\n",
      "Steps:  71%|▋| 10679/15000 [1:07:58<58:00,  1.24it/s, lr=9.24e-6, step_loss=0.5607/18/2023 20:11:20 - INFO - __main__ - train loss is 2.195239561377093\n",
      "Steps:  71%|▋| 10680/15000 [1:07:58<52:26,  1.37it/s, lr=9.24e-6, step_loss=0.2007/18/2023 20:11:21 - INFO - __main__ - train loss is 2.2279651935677975\n",
      "Steps:  71%|▋| 10681/15000 [1:07:59<48:29,  1.48it/s, lr=9.24e-6, step_loss=0.0307/18/2023 20:11:21 - INFO - __main__ - train loss is 3.12202741461806\n",
      "Steps:  71%|▋| 10682/15000 [1:07:59<45:39,  1.58it/s, lr=9.24e-6, step_loss=0.8907/18/2023 20:11:22 - INFO - __main__ - train loss is 3.184390666661784\n",
      "Steps:  71%|▋| 10683/15000 [1:08:00<44:00,  1.63it/s, lr=9.24e-6, step_loss=0.0607/18/2023 20:11:22 - INFO - __main__ - train loss is 3.537981780944392\n",
      "Steps:  71%|▋| 10684/15000 [1:08:00<42:27,  1.69it/s, lr=9.24e-6, step_loss=0.3507/18/2023 20:11:23 - INFO - __main__ - train loss is 3.722886028466746\n",
      "Steps:  71%|▋| 10685/15000 [1:08:01<41:46,  1.72it/s, lr=9.24e-6, step_loss=0.1807/18/2023 20:11:24 - INFO - __main__ - train loss is 3.850368770537898\n",
      "Steps:  71%|▋| 10686/15000 [1:08:01<40:59,  1.75it/s, lr=9.24e-6, step_loss=0.1207/18/2023 20:11:24 - INFO - __main__ - train loss is 3.851830965373665\n",
      "Steps:  71%|▋| 10687/15000 [1:08:02<40:17,  1.78it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:11:25 - INFO - __main__ - train loss is 4.081168970558792\n",
      "Steps:  71%|▋| 10688/15000 [1:08:03<39:49,  1.80it/s, lr=9.24e-6, step_loss=0.2207/18/2023 20:11:25 - INFO - __main__ - train loss is 4.178673243615776\n",
      "Steps:  71%|▋| 10689/15000 [1:08:03<39:31,  1.82it/s, lr=9.24e-6, step_loss=0.0907/18/2023 20:11:26 - INFO - __main__ - train loss is 4.299305236432701\n",
      "Steps:  71%|▋| 10690/15000 [1:08:04<39:23,  1.82it/s, lr=9.24e-6, step_loss=0.1207/18/2023 20:11:26 - INFO - __main__ - train loss is 4.305960882920772\n",
      "Steps:  71%|▋| 10691/15000 [1:08:04<39:15,  1.83it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:11:27 - INFO - __main__ - train loss is 4.563324559945613\n",
      "Steps:  71%|▋| 10692/15000 [1:08:05<39:19,  1.83it/s, lr=9.24e-6, step_loss=0.2507/18/2023 20:11:27 - INFO - __main__ - train loss is 4.565336605301127\n",
      "Steps:  71%|▋| 10693/15000 [1:08:05<39:13,  1.83it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:11:28 - INFO - __main__ - train loss is 4.5705547330435365\n",
      "Steps:  71%|▋| 10694/15000 [1:08:06<39:04,  1.84it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:11:28 - INFO - __main__ - train loss is 4.575012219836935\n",
      "Steps:  71%|▋| 10695/15000 [1:08:06<39:04,  1.84it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:11:29 - INFO - __main__ - train loss is 4.772926969220862\n",
      "Steps:  71%|▋| 10696/15000 [1:08:07<39:04,  1.84it/s, lr=9.24e-6, step_loss=0.1907/18/2023 20:11:30 - INFO - __main__ - train loss is 4.775223023723811\n",
      "Steps:  71%|▋| 10697/15000 [1:08:07<39:11,  1.83it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:11:30 - INFO - __main__ - train loss is 4.826304230373353\n",
      "Steps:  71%|▋| 10698/15000 [1:08:08<39:12,  1.83it/s, lr=9.24e-6, step_loss=0.0507/18/2023 20:11:31 - INFO - __main__ - train loss is 4.852613668423146\n",
      "Steps:  71%|▋| 10699/15000 [1:08:09<39:04,  1.83it/s, lr=9.24e-6, step_loss=0.0207/18/2023 20:11:31 - INFO - __main__ - train loss is 5.004296671133488\n",
      "Steps:  71%|▋| 10700/15000 [1:08:09<39:00,  1.84it/s, lr=9.24e-6, step_loss=0.1507/18/2023 20:11:32 - INFO - __main__ - train loss is 5.31019852636382\n",
      "Steps:  71%|▋| 10701/15000 [1:08:10<39:06,  1.83it/s, lr=9.24e-6, step_loss=0.3007/18/2023 20:11:32 - INFO - __main__ - train loss is 5.407949242275208\n",
      "Steps:  71%|▋| 10702/15000 [1:08:10<39:12,  1.83it/s, lr=9.24e-6, step_loss=0.0907/18/2023 20:11:33 - INFO - __main__ - train loss is 5.5506391557864845\n",
      "Steps:  71%|▋| 10703/15000 [1:08:11<39:17,  1.82it/s, lr=9.24e-6, step_loss=0.1407/18/2023 20:11:33 - INFO - __main__ - train loss is 5.696274760644883\n",
      "Steps:  71%|▋| 10704/15000 [1:08:11<39:16,  1.82it/s, lr=9.24e-6, step_loss=0.1407/18/2023 20:11:34 - INFO - __main__ - train loss is 6.247976306360215\n",
      "Steps:  71%|▋| 10705/15000 [1:08:12<39:13,  1.82it/s, lr=9.24e-6, step_loss=0.5507/18/2023 20:11:34 - INFO - __main__ - train loss is 6.953890088479966\n",
      "Steps:  71%|▋| 10706/15000 [1:08:12<39:08,  1.83it/s, lr=9.24e-6, step_loss=0.7007/18/2023 20:11:35 - INFO - __main__ - train loss is 7.214193108957261\n",
      "Steps:  71%|▋| 10707/15000 [1:08:13<39:08,  1.83it/s, lr=9.24e-6, step_loss=0.2607/18/2023 20:11:36 - INFO - __main__ - train loss is 7.22364855138585\n",
      "Steps:  71%|▋| 10708/15000 [1:08:13<39:11,  1.83it/s, lr=9.24e-6, step_loss=0.0007/18/2023 20:11:36 - INFO - __main__ - train loss is 7.309490087907761\n",
      "Steps:  71%|▋| 10709/15000 [1:08:14<39:13,  1.82it/s, lr=9.24e-6, step_loss=0.0807/18/2023 20:11:37 - INFO - __main__ - train loss is 7.32388824922964\n",
      "Steps:  71%|▋| 10710/15000 [1:08:15<39:05,  1.83it/s, lr=9.24e-6, step_loss=0.0107/18/2023 20:11:37 - INFO - __main__ - train loss is 7.450287021230906\n",
      "Steps:  71%|▋| 10711/15000 [1:08:15<39:06,  1.83it/s, lr=9.24e-6, step_loss=0.1207/18/2023 20:11:38 - INFO - __main__ - train loss is 7.505840055178851\n",
      "Steps:  71%|▋| 10712/15000 [1:08:16<39:01,  1.83it/s, lr=9.24e-6, step_loss=0.0507/18/2023 20:11:38 - INFO - __main__ - train loss is 7.533054634463042\n",
      "Steps:  71%|▋| 10713/15000 [1:08:16<39:03,  1.83it/s, lr=9.24e-6, step_loss=0.0207/18/2023 20:11:39 - INFO - __main__ - train loss is 8.167584642302245\n",
      "Steps:  71%|▋| 10714/15000 [1:08:17<39:03,  1.83it/s, lr=9.24e-6, step_loss=0.6307/18/2023 20:11:39 - INFO - __main__ - train loss is 8.187251921277493\n",
      "Steps:  71%|▋| 10715/15000 [1:08:17<38:57,  1.83it/s, lr=9.24e-6, step_loss=0.0107/18/2023 20:11:40 - INFO - __main__ - train loss is 8.379262890201062\n",
      "Steps:  71%|▋| 10716/15000 [1:08:18<38:52,  1.84it/s, lr=9.24e-6, step_loss=0.1907/18/2023 20:11:40 - INFO - __main__ - train loss is 8.424673161935061\n",
      "Steps:  71%|▋| 10717/15000 [1:08:18<39:08,  1.82it/s, lr=9.24e-6, step_loss=0.0407/18/2023 20:11:41 - INFO - __main__ - train loss is 8.435994351748377\n",
      "Steps:  71%|▋| 10718/15000 [1:08:19<39:00,  1.83it/s, lr=9.24e-6, step_loss=0.0107/18/2023 20:11:42 - INFO - __main__ - train loss is 9.038224423769861\n",
      "Steps:  71%|▋| 10719/15000 [1:08:19<39:25,  1.81it/s, lr=9.24e-6, step_loss=0.6007/18/2023 20:11:42 - INFO - __main__ - train loss is 9.050331837963313\n",
      "Steps:  71%|▋| 10720/15000 [1:08:20<39:51,  1.79it/s, lr=9.24e-6, step_loss=0.0107/18/2023 20:11:43 - INFO - __main__ - train loss is 9.321733571123332\n",
      "Steps:  71%|▋| 10721/15000 [1:08:21<40:02,  1.78it/s, lr=9.24e-6, step_loss=0.2707/18/2023 20:11:43 - INFO - __main__ - train loss is 9.711301780771464\n",
      "Steps:  71%|▋| 10722/15000 [1:08:21<40:03,  1.78it/s, lr=9.24e-6, step_loss=0.3907/18/2023 20:11:44 - INFO - __main__ - train loss is 9.770247749518603\n",
      "Steps:  71%|▋| 10723/15000 [1:08:22<40:12,  1.77it/s, lr=9.23e-6, step_loss=0.0507/18/2023 20:11:44 - INFO - __main__ - train loss is 9.782957143615931\n",
      "Steps:  71%|▋| 10724/15000 [1:08:22<39:58,  1.78it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:11:45 - INFO - __main__ - train loss is 9.915191895794123\n",
      "Steps:  72%|▋| 10725/15000 [1:08:23<39:54,  1.79it/s, lr=9.23e-6, step_loss=0.1307/18/2023 20:11:46 - INFO - __main__ - train loss is 9.954680650960654\n",
      "Steps:  72%|▋| 10726/15000 [1:08:23<40:05,  1.78it/s, lr=9.23e-6, step_loss=0.0307/18/2023 20:11:46 - INFO - __main__ - train loss is 9.957937573082745\n",
      "Steps:  72%|▋| 10727/15000 [1:08:24<39:48,  1.79it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:11:47 - INFO - __main__ - train loss is 10.365562175400555\n",
      "Steps:  72%|▋| 10728/15000 [1:08:25<40:16,  1.77it/s, lr=9.23e-6, step_loss=0.4007/18/2023 20:11:47 - INFO - __main__ - train loss is 10.380055323243141\n",
      "Steps:  72%|▋| 10729/15000 [1:08:25<40:11,  1.77it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:11:48 - INFO - __main__ - train loss is 10.395042884163558\n",
      "Steps:  72%|▋| 10730/15000 [1:08:26<40:04,  1.78it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:11:48 - INFO - __main__ - train loss is 10.410961701534688\n",
      "Steps:  72%|▋| 10731/15000 [1:08:26<39:55,  1.78it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:11:49 - INFO - __main__ - train loss is 10.51349317934364\n",
      "Steps:  72%|▋| 10732/15000 [1:08:27<40:02,  1.78it/s, lr=9.23e-6, step_loss=0.1007/18/2023 20:11:49 - INFO - __main__ - train loss is 11.112347005866468\n",
      "Steps:  72%|▋| 10733/15000 [1:08:27<40:03,  1.78it/s, lr=9.23e-6, step_loss=0.5907/18/2023 20:11:50 - INFO - __main__ - train loss is 11.115483184345067\n",
      "Steps:  72%|▋| 10734/15000 [1:08:28<39:37,  1.79it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:11:51 - INFO - __main__ - train loss is 11.468461294658482\n",
      "Steps:  72%|▋| 10735/15000 [1:08:28<39:25,  1.80it/s, lr=9.23e-6, step_loss=0.3507/18/2023 20:11:51 - INFO - __main__ - train loss is 11.470619544619694\n",
      "Steps:  72%|▋| 10736/15000 [1:08:29<39:11,  1.81it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:11:52 - INFO - __main__ - train loss is 11.628125056857243\n",
      "Steps:  72%|▋| 10737/15000 [1:08:30<39:27,  1.80it/s, lr=9.23e-6, step_loss=0.1507/18/2023 20:11:52 - INFO - __main__ - train loss is 11.722861416870728\n",
      "Steps:  72%|▋| 10738/15000 [1:08:30<41:23,  1.72it/s, lr=9.23e-6, step_loss=0.0907/18/2023 20:11:53 - INFO - __main__ - train loss is 11.729839445324615\n",
      "Steps:  72%|▋| 10739/15000 [1:08:31<41:30,  1.71it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:11:54 - INFO - __main__ - train loss is 11.880444289417937\n",
      "Steps:  72%|▋| 10740/15000 [1:08:31<41:58,  1.69it/s, lr=9.23e-6, step_loss=0.1507/18/2023 20:11:54 - INFO - __main__ - train loss is 11.900395232485607\n",
      "Steps:  72%|▋| 10741/15000 [1:08:32<41:00,  1.73it/s, lr=9.23e-6, step_loss=0.0207/18/2023 20:11:55 - INFO - __main__ - train loss is 12.696404355810955\n",
      "Steps:  72%|▋| 10742/15000 [1:08:33<40:18,  1.76it/s, lr=9.23e-6, step_loss=0.7907/18/2023 20:11:55 - INFO - __main__ - train loss is 12.738556298660114\n",
      "Steps:  72%|▋| 10743/15000 [1:08:33<39:49,  1.78it/s, lr=9.23e-6, step_loss=0.0407/18/2023 20:11:56 - INFO - __main__ - train loss is 12.750536820152774\n",
      "Steps:  72%|▋| 10744/15000 [1:08:34<39:20,  1.80it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:11:56 - INFO - __main__ - train loss is 12.753808330977336\n",
      "Steps:  72%|▋| 10745/15000 [1:08:34<39:10,  1.81it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:11:57 - INFO - __main__ - train loss is 12.757258618948981\n",
      "Steps:  72%|▋| 10746/15000 [1:08:35<38:59,  1.82it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:11:57 - INFO - __main__ - train loss is 13.360173786757514\n",
      "Steps:  72%|▋| 10747/15000 [1:08:35<38:52,  1.82it/s, lr=9.23e-6, step_loss=0.6007/18/2023 20:11:58 - INFO - __main__ - train loss is 13.953539694426581\n",
      "Steps:  72%|▋| 10748/15000 [1:08:36<38:40,  1.83it/s, lr=9.23e-6, step_loss=0.5907/18/2023 20:11:58 - INFO - __main__ - train loss is 13.996772448299453\n",
      "Steps:  72%|▋| 10749/15000 [1:08:36<38:49,  1.83it/s, lr=9.23e-6, step_loss=0.0407/18/2023 20:11:59 - INFO - __main__ - train loss is 14.009679023874924\n",
      "Steps:  72%|▋| 10750/15000 [1:08:37<38:44,  1.83it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:12:00 - INFO - __main__ - train loss is 14.460127596510574\n",
      "Steps:  72%|▋| 10751/15000 [1:08:37<38:39,  1.83it/s, lr=9.23e-6, step_loss=0.4507/18/2023 20:12:00 - INFO - __main__ - train loss is 14.468596000922844\n",
      "Steps:  72%|▋| 10752/15000 [1:08:38<38:35,  1.83it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:01 - INFO - __main__ - train loss is 14.828141172183678\n",
      "Steps:  72%|▋| 10753/15000 [1:08:38<38:28,  1.84it/s, lr=9.23e-6, step_loss=0.3607/18/2023 20:12:01 - INFO - __main__ - train loss is 14.832525994395837\n",
      "Steps:  72%|▋| 10754/15000 [1:08:39<38:20,  1.85it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:02 - INFO - __main__ - train loss is 14.833938956726342\n",
      "Steps:  72%|▋| 10755/15000 [1:08:40<38:19,  1.85it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:02 - INFO - __main__ - train loss is 14.860532332677394\n",
      "Steps:  72%|▋| 10756/15000 [1:08:40<38:14,  1.85it/s, lr=9.23e-6, step_loss=0.0207/18/2023 20:12:03 - INFO - __main__ - train loss is 14.92938955547288\n",
      "Steps:  72%|▋| 10757/15000 [1:08:41<38:16,  1.85it/s, lr=9.23e-6, step_loss=0.0607/18/2023 20:12:03 - INFO - __main__ - train loss is 14.963562768418342\n",
      "Steps:  72%|▋| 10758/15000 [1:08:41<38:17,  1.85it/s, lr=9.23e-6, step_loss=0.0307/18/2023 20:12:04 - INFO - __main__ - train loss is 14.9756876709871\n",
      "Steps:  72%|▋| 10759/15000 [1:08:42<38:16,  1.85it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:12:04 - INFO - __main__ - train loss is 14.987756268586963\n",
      "Steps:  72%|▋| 10760/15000 [1:08:42<38:24,  1.84it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:12:05 - INFO - __main__ - train loss is 15.124837891664356\n",
      "Steps:  72%|▋| 10761/15000 [1:08:43<38:22,  1.84it/s, lr=9.23e-6, step_loss=0.1307/18/2023 20:12:05 - INFO - __main__ - train loss is 15.187840403523296\n",
      "Steps:  72%|▋| 10762/15000 [1:08:43<38:20,  1.84it/s, lr=9.23e-6, step_loss=0.0607/18/2023 20:12:06 - INFO - __main__ - train loss is 15.250156702008098\n",
      "Steps:  72%|▋| 10763/15000 [1:08:44<38:19,  1.84it/s, lr=9.23e-6, step_loss=0.0607/18/2023 20:12:07 - INFO - __main__ - train loss is 15.252323514781892\n",
      "Steps:  72%|▋| 10764/15000 [1:08:44<38:19,  1.84it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:07 - INFO - __main__ - train loss is 15.402504823170602\n",
      "Steps:  72%|▋| 10765/15000 [1:08:45<38:14,  1.85it/s, lr=9.23e-6, step_loss=0.1507/18/2023 20:12:08 - INFO - __main__ - train loss is 15.41234851628542\n",
      "Steps:  72%|▋| 10766/15000 [1:08:46<38:27,  1.83it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:08 - INFO - __main__ - train loss is 15.710698015987873\n",
      "Steps:  72%|▋| 10767/15000 [1:08:46<43:21,  1.63it/s, lr=9.23e-6, step_loss=0.2907/18/2023 20:12:09 - INFO - __main__ - Per validation step average loss is 0.011205360293388367\n",
      "07/18/2023 20:12:09 - INFO - __main__ - Cumulative validation average loss is 0.011205360293388367\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Per validation step average loss is 0.0015799346147105098\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Cumulative validation average loss is 0.012785294908098876\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Per validation step average loss is 0.19736602902412415\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Cumulative validation average loss is 0.21015132393222302\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Per validation step average loss is 0.16635632514953613\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Cumulative validation average loss is 0.37650764908175915\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Per validation step average loss is 0.22180971503257751\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Cumulative validation average loss is 0.5983173641143367\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Per validation step average loss is 0.961519718170166\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Cumulative validation average loss is 1.5598370822845027\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Per validation step average loss is 0.1854819655418396\n",
      "07/18/2023 20:12:10 - INFO - __main__ - Cumulative validation average loss is 1.7453190478263423\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Per validation step average loss is 0.11458826065063477\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Cumulative validation average loss is 1.859907308476977\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Per validation step average loss is 0.030788717791438103\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Cumulative validation average loss is 1.8906960262684152\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Per validation step average loss is 0.14085054397583008\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Cumulative validation average loss is 2.0315465702442452\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Per validation step average loss is 0.08477284014225006\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Cumulative validation average loss is 2.1163194103864953\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Per validation step average loss is 0.0018085921183228493\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Cumulative validation average loss is 2.118128002504818\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Average validation loss for Epoch 110 is 0.1765106668754015\n",
      "07/18/2023 20:12:11 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:12:24 - INFO - __main__ - Starting epoch 111\n",
      "07/18/2023 20:12:25 - INFO - __main__ - train loss is 0.01326710730791092\n",
      "Steps:  72%|▋| 10768/15000 [1:09:02<6:12:15,  5.28s/it, lr=9.23e-6, step_loss=0.07/18/2023 20:12:25 - INFO - __main__ - train loss is 0.07953480631113052\n",
      "Steps:  72%|▋| 10769/15000 [1:09:03<4:24:19,  3.75s/it, lr=9.23e-6, step_loss=0.07/18/2023 20:12:25 - INFO - __main__ - train loss is 0.08137273788452148\n",
      "Steps:  72%|▋| 10770/15000 [1:09:03<3:08:43,  2.68s/it, lr=9.23e-6, step_loss=0.07/18/2023 20:12:25 - INFO - __main__ - train loss is 0.5443338751792908\n",
      "Steps:  72%|▋| 10771/15000 [1:09:03<2:15:49,  1.93s/it, lr=9.23e-6, step_loss=0.07/18/2023 20:12:25 - INFO - __main__ - train loss is 0.6343884021043777\n",
      "Steps:  72%|▋| 10772/15000 [1:09:03<1:38:47,  1.40s/it, lr=9.23e-6, step_loss=0.07/18/2023 20:12:25 - INFO - __main__ - train loss is 0.7360246181488037\n",
      "Steps:  72%|▋| 10773/15000 [1:09:03<1:12:58,  1.04s/it, lr=9.23e-6, step_loss=0.07/18/2023 20:12:26 - INFO - __main__ - train loss is 1.024940699338913\n",
      "Steps:  72%|▋| 10774/15000 [1:09:04<54:48,  1.28it/s, lr=9.23e-6, step_loss=0.2807/18/2023 20:12:26 - INFO - __main__ - train loss is 1.1030130982398987\n",
      "Steps:  72%|▋| 10775/15000 [1:09:04<42:17,  1.67it/s, lr=9.23e-6, step_loss=0.0707/18/2023 20:12:26 - INFO - __main__ - train loss is 1.2641663551330566\n",
      "Steps:  72%|▋| 10776/15000 [1:09:04<33:20,  2.11it/s, lr=9.23e-6, step_loss=0.1607/18/2023 20:12:26 - INFO - __main__ - train loss is 1.636429637670517\n",
      "Steps:  72%|▋| 10777/15000 [1:09:04<27:04,  2.60it/s, lr=9.23e-6, step_loss=0.3707/18/2023 20:12:26 - INFO - __main__ - train loss is 1.737169660627842\n",
      "Steps:  72%|▋| 10778/15000 [1:09:04<22:41,  3.10it/s, lr=9.23e-6, step_loss=0.1007/18/2023 20:12:27 - INFO - __main__ - train loss is 1.7565745189785957\n",
      "Steps:  72%|▋| 10779/15000 [1:09:04<19:37,  3.59it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:12:27 - INFO - __main__ - train loss is 2.0521781221032143\n",
      "Steps:  72%|▋| 10780/15000 [1:09:05<17:29,  4.02it/s, lr=9.23e-6, step_loss=0.2907/18/2023 20:12:27 - INFO - __main__ - train loss is 2.5833593979477882\n",
      "Steps:  72%|▋| 10781/15000 [1:09:05<16:00,  4.39it/s, lr=9.23e-6, step_loss=0.5307/18/2023 20:12:27 - INFO - __main__ - train loss is 2.592082330957055\n",
      "Steps:  72%|▋| 10782/15000 [1:09:05<14:56,  4.71it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:27 - INFO - __main__ - train loss is 2.639469662681222\n",
      "Steps:  72%|▋| 10783/15000 [1:09:05<14:11,  4.95it/s, lr=9.23e-6, step_loss=0.0407/18/2023 20:12:27 - INFO - __main__ - train loss is 2.6445573987439275\n",
      "Steps:  72%|▋| 10784/15000 [1:09:05<13:39,  5.14it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:28 - INFO - __main__ - train loss is 2.6462693291250616\n",
      "Steps:  72%|▋| 10785/15000 [1:09:06<13:18,  5.28it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:28 - INFO - __main__ - train loss is 2.768925570184365\n",
      "Steps:  72%|▋| 10786/15000 [1:09:06<13:11,  5.33it/s, lr=9.23e-6, step_loss=0.1207/18/2023 20:12:28 - INFO - __main__ - train loss is 3.1378839241806418\n",
      "Steps:  72%|▋| 10787/15000 [1:09:06<13:00,  5.40it/s, lr=9.23e-6, step_loss=0.3607/18/2023 20:12:28 - INFO - __main__ - train loss is 3.176231041783467\n",
      "Steps:  72%|▋| 10788/15000 [1:09:06<12:50,  5.47it/s, lr=9.23e-6, step_loss=0.0307/18/2023 20:12:28 - INFO - __main__ - train loss is 3.1834831240121275\n",
      "Steps:  72%|▋| 10789/15000 [1:09:06<12:44,  5.51it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:29 - INFO - __main__ - train loss is 3.1854271366028115\n",
      "Steps:  72%|▋| 10790/15000 [1:09:06<12:39,  5.54it/s, lr=9.23e-6, step_loss=0.0007/18/2023 20:12:29 - INFO - __main__ - train loss is 3.373877309146337\n",
      "Steps:  72%|▋| 10791/15000 [1:09:07<12:36,  5.56it/s, lr=9.23e-6, step_loss=0.1807/18/2023 20:12:29 - INFO - __main__ - train loss is 3.4386036245850846\n",
      "Steps:  72%|▋| 10792/15000 [1:09:07<12:35,  5.57it/s, lr=9.23e-6, step_loss=0.0607/18/2023 20:12:29 - INFO - __main__ - train loss is 3.4552641882328317\n",
      "Steps:  72%|▋| 10793/15000 [1:09:07<12:33,  5.58it/s, lr=9.23e-6, step_loss=0.0107/18/2023 20:12:29 - INFO - __main__ - train loss is 3.5746717526344582\n",
      "Steps:  72%|▋| 10794/15000 [1:09:07<12:32,  5.59it/s, lr=9.23e-6, step_loss=0.1107/18/2023 20:12:29 - INFO - __main__ - train loss is 3.941318280878477\n",
      "Steps:  72%|▋| 10795/15000 [1:09:07<12:33,  5.58it/s, lr=9.22e-6, step_loss=0.3607/18/2023 20:12:30 - INFO - __main__ - train loss is 4.27216643828433\n",
      "Steps:  72%|▋| 10796/15000 [1:09:07<12:32,  5.59it/s, lr=9.22e-6, step_loss=0.3307/18/2023 20:12:30 - INFO - __main__ - train loss is 4.275026339222677\n",
      "Steps:  72%|▋| 10797/15000 [1:09:08<12:37,  5.55it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:30 - INFO - __main__ - train loss is 4.300115133752115\n",
      "Steps:  72%|▋| 10798/15000 [1:09:08<12:42,  5.51it/s, lr=9.22e-6, step_loss=0.0207/18/2023 20:12:30 - INFO - __main__ - train loss is 4.427085156668909\n",
      "Steps:  72%|▋| 10799/15000 [1:09:08<12:49,  5.46it/s, lr=9.22e-6, step_loss=0.1207/18/2023 20:12:30 - INFO - __main__ - train loss is 4.476508761872537\n",
      "Steps:  72%|▋| 10800/15000 [1:09:08<12:43,  5.50it/s, lr=9.22e-6, step_loss=0.0407/18/2023 20:12:31 - INFO - __main__ - train loss is 4.482072922051884\n",
      "Steps:  72%|▋| 10801/15000 [1:09:08<12:39,  5.53it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:31 - INFO - __main__ - train loss is 4.585864263237454\n",
      "Steps:  72%|▋| 10802/15000 [1:09:09<12:36,  5.55it/s, lr=9.22e-6, step_loss=0.1007/18/2023 20:12:31 - INFO - __main__ - train loss is 4.5896285373019055\n",
      "Steps:  72%|▋| 10803/15000 [1:09:09<12:34,  5.56it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:31 - INFO - __main__ - train loss is 4.803646464948542\n",
      "Steps:  72%|▋| 10804/15000 [1:09:09<12:46,  5.48it/s, lr=9.22e-6, step_loss=0.2107/18/2023 20:12:31 - INFO - __main__ - train loss is 5.024713312392123\n",
      "Steps:  72%|▋| 10805/15000 [1:09:09<12:44,  5.49it/s, lr=9.22e-6, step_loss=0.2207/18/2023 20:12:31 - INFO - __main__ - train loss is 5.130112064187415\n",
      "Steps:  72%|▋| 10806/15000 [1:09:09<12:40,  5.52it/s, lr=9.22e-6, step_loss=0.1007/18/2023 20:12:32 - INFO - __main__ - train loss is 5.224425134365447\n",
      "Steps:  72%|▋| 10807/15000 [1:09:09<12:42,  5.50it/s, lr=9.22e-6, step_loss=0.0907/18/2023 20:12:32 - INFO - __main__ - train loss is 5.234877132927068\n",
      "Steps:  72%|▋| 10808/15000 [1:09:10<12:45,  5.48it/s, lr=9.22e-6, step_loss=0.0107/18/2023 20:12:32 - INFO - __main__ - train loss is 5.355459348415025\n",
      "Steps:  72%|▋| 10809/15000 [1:09:10<12:40,  5.51it/s, lr=9.22e-6, step_loss=0.1207/18/2023 20:12:32 - INFO - __main__ - train loss is 5.372212332789786\n",
      "Steps:  72%|▋| 10810/15000 [1:09:10<12:38,  5.52it/s, lr=9.22e-6, step_loss=0.0107/18/2023 20:12:32 - INFO - __main__ - train loss is 5.400605884497054\n",
      "Steps:  72%|▋| 10811/15000 [1:09:10<12:35,  5.54it/s, lr=9.22e-6, step_loss=0.0207/18/2023 20:12:33 - INFO - __main__ - train loss is 5.634961602394469\n",
      "Steps:  72%|▋| 10812/15000 [1:09:10<12:34,  5.55it/s, lr=9.22e-6, step_loss=0.2307/18/2023 20:12:33 - INFO - __main__ - train loss is 5.642573260818608\n",
      "Steps:  72%|▋| 10813/15000 [1:09:11<12:32,  5.56it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:33 - INFO - __main__ - train loss is 5.644920801394619\n",
      "Steps:  72%|▋| 10814/15000 [1:09:11<12:31,  5.57it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:33 - INFO - __main__ - train loss is 5.915852581732906\n",
      "Steps:  72%|▋| 10815/15000 [1:09:11<12:29,  5.58it/s, lr=9.22e-6, step_loss=0.2707/18/2023 20:12:33 - INFO - __main__ - train loss is 6.011889462941326\n",
      "Steps:  72%|▋| 10816/15000 [1:09:11<12:28,  5.59it/s, lr=9.22e-6, step_loss=0.0907/18/2023 20:12:33 - INFO - __main__ - train loss is 6.126389791839756\n",
      "Steps:  72%|▋| 10817/15000 [1:09:11<12:28,  5.59it/s, lr=9.22e-6, step_loss=0.1107/18/2023 20:12:34 - INFO - __main__ - train loss is 6.299544354551472\n",
      "Steps:  72%|▋| 10818/15000 [1:09:11<12:27,  5.59it/s, lr=9.22e-6, step_loss=0.1707/18/2023 20:12:34 - INFO - __main__ - train loss is 6.650417944067158\n",
      "Steps:  72%|▋| 10819/15000 [1:09:12<12:27,  5.59it/s, lr=9.22e-6, step_loss=0.3507/18/2023 20:12:34 - INFO - __main__ - train loss is 6.7906687908107415\n",
      "Steps:  72%|▋| 10820/15000 [1:09:12<12:27,  5.59it/s, lr=9.22e-6, step_loss=0.1407/18/2023 20:12:34 - INFO - __main__ - train loss is 7.294946794980206\n",
      "Steps:  72%|▋| 10821/15000 [1:09:12<12:27,  5.59it/s, lr=9.22e-6, step_loss=0.5007/18/2023 20:12:34 - INFO - __main__ - train loss is 7.5858145110541955\n",
      "Steps:  72%|▋| 10822/15000 [1:09:12<12:26,  5.59it/s, lr=9.22e-6, step_loss=0.2907/18/2023 20:12:34 - INFO - __main__ - train loss is 7.745846783393063\n",
      "Steps:  72%|▋| 10823/15000 [1:09:12<12:26,  5.60it/s, lr=9.22e-6, step_loss=0.1607/18/2023 20:12:35 - INFO - __main__ - train loss is 7.748730172519572\n",
      "Steps:  72%|▋| 10824/15000 [1:09:13<12:25,  5.60it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:35 - INFO - __main__ - train loss is 8.374770631198771\n",
      "Steps:  72%|▋| 10825/15000 [1:09:13<12:25,  5.60it/s, lr=9.22e-6, step_loss=0.6207/18/2023 20:12:35 - INFO - __main__ - train loss is 8.442394894664176\n",
      "Steps:  72%|▋| 10826/15000 [1:09:13<12:25,  5.60it/s, lr=9.22e-6, step_loss=0.0607/18/2023 20:12:35 - INFO - __main__ - train loss is 8.598408264224418\n",
      "Steps:  72%|▋| 10827/15000 [1:09:13<12:25,  5.60it/s, lr=9.22e-6, step_loss=0.1507/18/2023 20:12:35 - INFO - __main__ - train loss is 8.738888931577094\n",
      "Steps:  72%|▋| 10828/15000 [1:09:13<12:24,  5.60it/s, lr=9.22e-6, step_loss=0.1407/18/2023 20:12:36 - INFO - __main__ - train loss is 8.741739735123701\n",
      "Steps:  72%|▋| 10829/15000 [1:09:13<12:24,  5.60it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:36 - INFO - __main__ - train loss is 9.363748893258162\n",
      "Steps:  72%|▋| 10830/15000 [1:09:14<13:18,  5.22it/s, lr=9.22e-6, step_loss=0.6207/18/2023 20:12:36 - INFO - __main__ - train loss is 9.507812366005965\n",
      "Steps:  72%|▋| 10831/15000 [1:09:14<14:55,  4.66it/s, lr=9.22e-6, step_loss=0.1407/18/2023 20:12:36 - INFO - __main__ - train loss is 9.796448990819044\n",
      "Steps:  72%|▋| 10832/15000 [1:09:14<15:06,  4.60it/s, lr=9.22e-6, step_loss=0.2807/18/2023 20:12:36 - INFO - __main__ - train loss is 9.97291992616374\n",
      "Steps:  72%|▋| 10833/15000 [1:09:14<16:19,  4.26it/s, lr=9.22e-6, step_loss=0.1707/18/2023 20:12:37 - INFO - __main__ - train loss is 9.980393765610643\n",
      "Steps:  72%|▋| 10834/15000 [1:09:15<17:00,  4.08it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:37 - INFO - __main__ - train loss is 9.98961562581826\n",
      "Steps:  72%|▋| 10835/15000 [1:09:15<16:08,  4.30it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:37 - INFO - __main__ - train loss is 10.198133594472893\n",
      "Steps:  72%|▋| 10836/15000 [1:09:15<15:06,  4.60it/s, lr=9.22e-6, step_loss=0.2007/18/2023 20:12:37 - INFO - __main__ - train loss is 10.235724992235191\n",
      "Steps:  72%|▋| 10837/15000 [1:09:15<14:22,  4.83it/s, lr=9.22e-6, step_loss=0.0307/18/2023 20:12:38 - INFO - __main__ - train loss is 10.242925463826396\n",
      "Steps:  72%|▋| 10838/15000 [1:09:15<13:52,  5.00it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:38 - INFO - __main__ - train loss is 10.244499709806405\n",
      "Steps:  72%|▋| 10839/15000 [1:09:16<13:29,  5.14it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:38 - INFO - __main__ - train loss is 10.4388128783321\n",
      "Steps:  72%|▋| 10840/15000 [1:09:16<13:13,  5.24it/s, lr=9.22e-6, step_loss=0.1907/18/2023 20:12:38 - INFO - __main__ - train loss is 10.636608895263635\n",
      "Steps:  72%|▋| 10841/15000 [1:09:16<13:06,  5.28it/s, lr=9.22e-6, step_loss=0.1907/18/2023 20:12:38 - INFO - __main__ - train loss is 10.747688491246663\n",
      "Steps:  72%|▋| 10842/15000 [1:09:16<12:56,  5.35it/s, lr=9.22e-6, step_loss=0.1107/18/2023 20:12:38 - INFO - __main__ - train loss is 10.860060636303388\n",
      "Steps:  72%|▋| 10843/15000 [1:09:16<12:49,  5.40it/s, lr=9.22e-6, step_loss=0.1107/18/2023 20:12:39 - INFO - __main__ - train loss is 10.861433650017716\n",
      "Steps:  72%|▋| 10844/15000 [1:09:17<12:44,  5.44it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:39 - INFO - __main__ - train loss is 10.958705353201367\n",
      "Steps:  72%|▋| 10845/15000 [1:09:17<12:40,  5.46it/s, lr=9.22e-6, step_loss=0.0907/18/2023 20:12:39 - INFO - __main__ - train loss is 10.962629753281362\n",
      "Steps:  72%|▋| 10846/15000 [1:09:17<12:37,  5.48it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:39 - INFO - __main__ - train loss is 11.123278441955335\n",
      "Steps:  72%|▋| 10847/15000 [1:09:17<12:35,  5.49it/s, lr=9.22e-6, step_loss=0.1607/18/2023 20:12:39 - INFO - __main__ - train loss is 11.502442094613798\n",
      "Steps:  72%|▋| 10848/15000 [1:09:17<12:30,  5.53it/s, lr=9.22e-6, step_loss=0.3707/18/2023 20:12:40 - INFO - __main__ - train loss is 11.507299542543478\n",
      "Steps:  72%|▋| 10849/15000 [1:09:17<12:27,  5.56it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:40 - INFO - __main__ - train loss is 11.774936765548773\n",
      "Steps:  72%|▋| 10850/15000 [1:09:18<12:26,  5.56it/s, lr=9.22e-6, step_loss=0.2607/18/2023 20:12:40 - INFO - __main__ - train loss is 11.779239001800306\n",
      "Steps:  72%|▋| 10851/15000 [1:09:18<12:23,  5.58it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:40 - INFO - __main__ - train loss is 11.799031945993192\n",
      "Steps:  72%|▋| 10852/15000 [1:09:18<12:22,  5.59it/s, lr=9.22e-6, step_loss=0.0107/18/2023 20:12:40 - INFO - __main__ - train loss is 11.809932260890491\n",
      "Steps:  72%|▋| 10853/15000 [1:09:18<12:20,  5.60it/s, lr=9.22e-6, step_loss=0.0107/18/2023 20:12:40 - INFO - __main__ - train loss is 11.987983374972828\n",
      "Steps:  72%|▋| 10854/15000 [1:09:18<12:19,  5.60it/s, lr=9.22e-6, step_loss=0.1707/18/2023 20:12:41 - INFO - __main__ - train loss is 12.073073051054962\n",
      "Steps:  72%|▋| 10855/15000 [1:09:18<12:18,  5.61it/s, lr=9.22e-6, step_loss=0.0807/18/2023 20:12:41 - INFO - __main__ - train loss is 12.25294301577378\n",
      "Steps:  72%|▋| 10856/15000 [1:09:19<12:18,  5.61it/s, lr=9.22e-6, step_loss=0.1807/18/2023 20:12:41 - INFO - __main__ - train loss is 12.355257510324009\n",
      "Steps:  72%|▋| 10857/15000 [1:09:19<12:17,  5.61it/s, lr=9.22e-6, step_loss=0.1007/18/2023 20:12:41 - INFO - __main__ - train loss is 12.617343573947437\n",
      "Steps:  72%|▋| 10858/15000 [1:09:19<12:17,  5.61it/s, lr=9.22e-6, step_loss=0.2607/18/2023 20:12:41 - INFO - __main__ - train loss is 12.754867463489063\n",
      "Steps:  72%|▋| 10859/15000 [1:09:19<12:17,  5.61it/s, lr=9.22e-6, step_loss=0.1307/18/2023 20:12:42 - INFO - __main__ - train loss is 13.277507155318744\n",
      "Steps:  72%|▋| 10860/15000 [1:09:19<12:22,  5.58it/s, lr=9.22e-6, step_loss=0.5207/18/2023 20:12:42 - INFO - __main__ - train loss is 13.462329863687046\n",
      "Steps:  72%|▋| 10861/15000 [1:09:20<12:37,  5.47it/s, lr=9.22e-6, step_loss=0.1807/18/2023 20:12:42 - INFO - __main__ - train loss is 13.487617029924877\n",
      "Steps:  72%|▋| 10862/15000 [1:09:20<12:37,  5.46it/s, lr=9.22e-6, step_loss=0.0207/18/2023 20:12:42 - INFO - __main__ - train loss is 13.49101492727641\n",
      "Steps:  72%|▋| 10863/15000 [1:09:20<12:34,  5.48it/s, lr=9.22e-6, step_loss=0.0007/18/2023 20:12:42 - INFO - __main__ - train loss is 13.571407317765988\n",
      "Steps:  72%|▋| 10864/15000 [1:09:20<17:50,  3.86it/s, lr=9.22e-6, step_loss=0.0807/18/2023 20:12:43 - INFO - __main__ - Per validation step average loss is 0.011082706972956657\n",
      "07/18/2023 20:12:43 - INFO - __main__ - Cumulative validation average loss is 0.011082706972956657\n",
      "07/18/2023 20:12:43 - INFO - __main__ - Per validation step average loss is 0.07527633011341095\n",
      "07/18/2023 20:12:43 - INFO - __main__ - Cumulative validation average loss is 0.08635903708636761\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Per validation step average loss is 0.03250684589147568\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Cumulative validation average loss is 0.11886588297784328\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Per validation step average loss is 0.06373575329780579\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Cumulative validation average loss is 0.18260163627564907\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Per validation step average loss is 0.0015114574925974011\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Cumulative validation average loss is 0.18411309376824647\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Per validation step average loss is 0.02644084393978119\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Cumulative validation average loss is 0.21055393770802766\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Per validation step average loss is 0.5268735289573669\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Cumulative validation average loss is 0.7374274666653946\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Per validation step average loss is 0.5444542169570923\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Cumulative validation average loss is 1.281881683622487\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Per validation step average loss is 0.49602216482162476\n",
      "07/18/2023 20:12:44 - INFO - __main__ - Cumulative validation average loss is 1.7779038484441116\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Per validation step average loss is 0.011807836592197418\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Cumulative validation average loss is 1.789711685036309\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Per validation step average loss is 0.02603384479880333\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Cumulative validation average loss is 1.8157455298351124\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Per validation step average loss is 0.48458272218704224\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Cumulative validation average loss is 2.3003282520221546\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Average validation loss for Epoch 111 is 0.1916940210018462\n",
      "07/18/2023 20:12:45 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:12:58 - INFO - __main__ - Starting epoch 112\n",
      "07/18/2023 20:12:59 - INFO - __main__ - train loss is 0.4526921510696411\n",
      "Steps:  72%|▋| 10865/15000 [1:09:37<5:45:42,  5.02s/it, lr=9.22e-6, step_loss=0.07/18/2023 20:12:59 - INFO - __main__ - train loss is 0.4893234148621559\n",
      "Steps:  72%|▋| 10866/15000 [1:09:37<4:05:50,  3.57s/it, lr=9.21e-6, step_loss=0.07/18/2023 20:12:59 - INFO - __main__ - train loss is 0.4912436273880303\n",
      "Steps:  72%|▋| 10867/15000 [1:09:37<2:55:56,  2.55s/it, lr=9.21e-6, step_loss=0.07/18/2023 20:12:59 - INFO - __main__ - train loss is 0.5033402075059712\n",
      "Steps:  72%|▋| 10868/15000 [1:09:37<2:06:55,  1.84s/it, lr=9.21e-6, step_loss=0.07/18/2023 20:12:59 - INFO - __main__ - train loss is 0.5748027940280735\n",
      "Steps:  72%|▋| 10869/15000 [1:09:37<1:32:29,  1.34s/it, lr=9.21e-6, step_loss=0.07/18/2023 20:13:00 - INFO - __main__ - train loss is 0.6099681151099503\n",
      "Steps:  72%|▋| 10870/15000 [1:09:37<1:08:29,  1.01it/s, lr=9.21e-6, step_loss=0.07/18/2023 20:13:00 - INFO - __main__ - train loss is 0.7188521665520966\n",
      "Steps:  72%|▋| 10871/15000 [1:09:38<51:36,  1.33it/s, lr=9.21e-6, step_loss=0.1007/18/2023 20:13:00 - INFO - __main__ - train loss is 0.7394871939904988\n",
      "Steps:  72%|▋| 10872/15000 [1:09:38<39:47,  1.73it/s, lr=9.21e-6, step_loss=0.0207/18/2023 20:13:00 - INFO - __main__ - train loss is 1.083281182218343\n",
      "Steps:  72%|▋| 10873/15000 [1:09:38<31:31,  2.18it/s, lr=9.21e-6, step_loss=0.3407/18/2023 20:13:00 - INFO - __main__ - train loss is 1.499331556726247\n",
      "Steps:  72%|▋| 10874/15000 [1:09:38<25:44,  2.67it/s, lr=9.21e-6, step_loss=0.4107/18/2023 20:13:00 - INFO - __main__ - train loss is 1.7967459787614644\n",
      "Steps:  72%|▋| 10875/15000 [1:09:38<21:40,  3.17it/s, lr=9.21e-6, step_loss=0.2907/18/2023 20:13:01 - INFO - __main__ - train loss is 1.7993688359856606\n",
      "Steps:  73%|▋| 10876/15000 [1:09:38<18:49,  3.65it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:01 - INFO - __main__ - train loss is 2.086499609053135\n",
      "Steps:  73%|▋| 10877/15000 [1:09:39<16:51,  4.08it/s, lr=9.21e-6, step_loss=0.2807/18/2023 20:13:01 - INFO - __main__ - train loss is 2.5837992802262306\n",
      "Steps:  73%|▋| 10878/15000 [1:09:39<15:28,  4.44it/s, lr=9.21e-6, step_loss=0.4907/18/2023 20:13:01 - INFO - __main__ - train loss is 2.5889025069773197\n",
      "Steps:  73%|▋| 10879/15000 [1:09:39<14:29,  4.74it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:01 - INFO - __main__ - train loss is 3.0231692530214787\n",
      "Steps:  73%|▋| 10880/15000 [1:09:39<13:48,  4.97it/s, lr=9.21e-6, step_loss=0.4307/18/2023 20:13:01 - INFO - __main__ - train loss is 3.066434532403946\n",
      "Steps:  73%|▋| 10881/15000 [1:09:39<13:20,  5.14it/s, lr=9.21e-6, step_loss=0.0407/18/2023 20:13:02 - INFO - __main__ - train loss is 3.0721268970519304\n",
      "Steps:  73%|▋| 10882/15000 [1:09:40<13:01,  5.27it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:02 - INFO - __main__ - train loss is 3.436031909659505\n",
      "Steps:  73%|▋| 10883/15000 [1:09:40<12:48,  5.36it/s, lr=9.21e-6, step_loss=0.3607/18/2023 20:13:02 - INFO - __main__ - train loss is 3.702523620799184\n",
      "Steps:  73%|▋| 10884/15000 [1:09:40<12:45,  5.38it/s, lr=9.21e-6, step_loss=0.2607/18/2023 20:13:02 - INFO - __main__ - train loss is 3.92385539598763\n",
      "Steps:  73%|▋| 10885/15000 [1:09:40<12:36,  5.44it/s, lr=9.21e-6, step_loss=0.2207/18/2023 20:13:02 - INFO - __main__ - train loss is 4.053342746570706\n",
      "Steps:  73%|▋| 10886/15000 [1:09:40<12:37,  5.43it/s, lr=9.21e-6, step_loss=0.1207/18/2023 20:13:03 - INFO - __main__ - train loss is 4.31518535502255\n",
      "Steps:  73%|▋| 10887/15000 [1:09:40<12:33,  5.46it/s, lr=9.21e-6, step_loss=0.2607/18/2023 20:13:03 - INFO - __main__ - train loss is 4.317481067497283\n",
      "Steps:  73%|▋| 10888/15000 [1:09:41<12:28,  5.50it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:03 - INFO - __main__ - train loss is 4.397293303627521\n",
      "Steps:  73%|▋| 10889/15000 [1:09:41<12:24,  5.52it/s, lr=9.21e-6, step_loss=0.0707/18/2023 20:13:03 - INFO - __main__ - train loss is 4.704887960571796\n",
      "Steps:  73%|▋| 10890/15000 [1:09:41<12:21,  5.54it/s, lr=9.21e-6, step_loss=0.3007/18/2023 20:13:03 - INFO - __main__ - train loss is 4.963060085196048\n",
      "Steps:  73%|▋| 10891/15000 [1:09:41<12:19,  5.55it/s, lr=9.21e-6, step_loss=0.2507/18/2023 20:13:03 - INFO - __main__ - train loss is 5.291704182047397\n",
      "Steps:  73%|▋| 10892/15000 [1:09:41<12:18,  5.57it/s, lr=9.21e-6, step_loss=0.3207/18/2023 20:13:04 - INFO - __main__ - train loss is 5.45429800869897\n",
      "Steps:  73%|▋| 10893/15000 [1:09:42<12:16,  5.57it/s, lr=9.21e-6, step_loss=0.1607/18/2023 20:13:04 - INFO - __main__ - train loss is 5.8405274343676865\n",
      "Steps:  73%|▋| 10894/15000 [1:09:42<12:15,  5.58it/s, lr=9.21e-6, step_loss=0.3807/18/2023 20:13:04 - INFO - __main__ - train loss is 6.505231995601207\n",
      "Steps:  73%|▋| 10895/15000 [1:09:42<12:15,  5.58it/s, lr=9.21e-6, step_loss=0.6607/18/2023 20:13:04 - INFO - __main__ - train loss is 6.512565842363983\n",
      "Steps:  73%|▋| 10896/15000 [1:09:42<12:14,  5.59it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:04 - INFO - __main__ - train loss is 6.651344201061875\n",
      "Steps:  73%|▋| 10897/15000 [1:09:42<12:18,  5.56it/s, lr=9.21e-6, step_loss=0.1307/18/2023 20:13:05 - INFO - __main__ - train loss is 6.87674697348848\n",
      "Steps:  73%|▋| 10898/15000 [1:09:42<12:16,  5.57it/s, lr=9.21e-6, step_loss=0.2207/18/2023 20:13:05 - INFO - __main__ - train loss is 7.107703676912934\n",
      "Steps:  73%|▋| 10899/15000 [1:09:43<12:15,  5.57it/s, lr=9.21e-6, step_loss=0.2307/18/2023 20:13:05 - INFO - __main__ - train loss is 7.32240184256807\n",
      "Steps:  73%|▋| 10900/15000 [1:09:43<12:14,  5.58it/s, lr=9.21e-6, step_loss=0.2107/18/2023 20:13:05 - INFO - __main__ - train loss is 7.342830883804709\n",
      "Steps:  73%|▋| 10901/15000 [1:09:43<12:13,  5.59it/s, lr=9.21e-6, step_loss=0.0207/18/2023 20:13:05 - INFO - __main__ - train loss is 7.454196477774531\n",
      "Steps:  73%|▋| 10902/15000 [1:09:43<12:13,  5.59it/s, lr=9.21e-6, step_loss=0.1107/18/2023 20:13:05 - INFO - __main__ - train loss is 7.644924233201891\n",
      "Steps:  73%|▋| 10903/15000 [1:09:43<12:13,  5.59it/s, lr=9.21e-6, step_loss=0.1907/18/2023 20:13:06 - INFO - __main__ - train loss is 7.666152019519359\n",
      "Steps:  73%|▋| 10904/15000 [1:09:44<12:12,  5.59it/s, lr=9.21e-6, step_loss=0.0207/18/2023 20:13:06 - INFO - __main__ - train loss is 7.759416651446372\n",
      "Steps:  73%|▋| 10905/15000 [1:09:44<12:12,  5.59it/s, lr=9.21e-6, step_loss=0.0907/18/2023 20:13:06 - INFO - __main__ - train loss is 8.019394409377128\n",
      "Steps:  73%|▋| 10906/15000 [1:09:44<12:11,  5.59it/s, lr=9.21e-6, step_loss=0.2607/18/2023 20:13:06 - INFO - __main__ - train loss is 8.035803877282888\n",
      "Steps:  73%|▋| 10907/15000 [1:09:44<12:11,  5.60it/s, lr=9.21e-6, step_loss=0.0107/18/2023 20:13:06 - INFO - __main__ - train loss is 8.084925316739827\n",
      "Steps:  73%|▋| 10908/15000 [1:09:44<12:10,  5.60it/s, lr=9.21e-6, step_loss=0.0407/18/2023 20:13:07 - INFO - __main__ - train loss is 8.213518821168691\n",
      "Steps:  73%|▋| 10909/15000 [1:09:44<12:10,  5.60it/s, lr=9.21e-6, step_loss=0.1207/18/2023 20:13:07 - INFO - __main__ - train loss is 8.499663286376745\n",
      "Steps:  73%|▋| 10910/15000 [1:09:45<12:10,  5.60it/s, lr=9.21e-6, step_loss=0.2807/18/2023 20:13:07 - INFO - __main__ - train loss is 8.858738594222814\n",
      "Steps:  73%|▋| 10911/15000 [1:09:45<12:10,  5.60it/s, lr=9.21e-6, step_loss=0.3507/18/2023 20:13:07 - INFO - __main__ - train loss is 9.275198929477483\n",
      "Steps:  73%|▋| 10912/15000 [1:09:45<12:11,  5.59it/s, lr=9.21e-6, step_loss=0.4107/18/2023 20:13:07 - INFO - __main__ - train loss is 9.299294198397547\n",
      "Steps:  73%|▋| 10913/15000 [1:09:45<12:10,  5.59it/s, lr=9.21e-6, step_loss=0.0207/18/2023 20:13:07 - INFO - __main__ - train loss is 9.51503142202273\n",
      "Steps:  73%|▋| 10914/15000 [1:09:45<12:10,  5.59it/s, lr=9.21e-6, step_loss=0.2107/18/2023 20:13:08 - INFO - __main__ - train loss is 9.981850171927363\n",
      "Steps:  73%|▋| 10915/15000 [1:09:45<12:10,  5.60it/s, lr=9.21e-6, step_loss=0.4607/18/2023 20:13:08 - INFO - __main__ - train loss is 9.987712242174894\n",
      "Steps:  73%|▋| 10916/15000 [1:09:46<12:10,  5.59it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:08 - INFO - __main__ - train loss is 10.27214238839224\n",
      "Steps:  73%|▋| 10917/15000 [1:09:46<12:09,  5.59it/s, lr=9.21e-6, step_loss=0.2807/18/2023 20:13:08 - INFO - __main__ - train loss is 10.470449068117887\n",
      "Steps:  73%|▋| 10918/15000 [1:09:46<12:09,  5.60it/s, lr=9.21e-6, step_loss=0.1907/18/2023 20:13:08 - INFO - __main__ - train loss is 11.083382584620267\n",
      "Steps:  73%|▋| 10919/15000 [1:09:46<12:09,  5.60it/s, lr=9.21e-6, step_loss=0.6107/18/2023 20:13:08 - INFO - __main__ - train loss is 11.11403430858627\n",
      "Steps:  73%|▋| 10920/15000 [1:09:46<12:08,  5.60it/s, lr=9.21e-6, step_loss=0.0307/18/2023 20:13:09 - INFO - __main__ - train loss is 11.845029963646084\n",
      "Steps:  73%|▋| 10921/15000 [1:09:47<12:08,  5.60it/s, lr=9.21e-6, step_loss=0.7307/18/2023 20:13:09 - INFO - __main__ - train loss is 12.101563884411007\n",
      "Steps:  73%|▋| 10922/15000 [1:09:47<12:08,  5.60it/s, lr=9.21e-6, step_loss=0.2507/18/2023 20:13:09 - INFO - __main__ - train loss is 12.210494934115559\n",
      "Steps:  73%|▋| 10923/15000 [1:09:47<12:07,  5.60it/s, lr=9.21e-6, step_loss=0.1007/18/2023 20:13:09 - INFO - __main__ - train loss is 12.667735038790852\n",
      "Steps:  73%|▋| 10924/15000 [1:09:47<12:07,  5.60it/s, lr=9.21e-6, step_loss=0.4507/18/2023 20:13:09 - INFO - __main__ - train loss is 12.829200802836567\n",
      "Steps:  73%|▋| 10925/15000 [1:09:47<12:08,  5.60it/s, lr=9.21e-6, step_loss=0.1607/18/2023 20:13:10 - INFO - __main__ - train loss is 13.135319916997105\n",
      "Steps:  73%|▋| 10926/15000 [1:09:47<12:08,  5.60it/s, lr=9.21e-6, step_loss=0.3007/18/2023 20:13:10 - INFO - __main__ - train loss is 13.152949376497418\n",
      "Steps:  73%|▋| 10927/15000 [1:09:48<12:08,  5.59it/s, lr=9.21e-6, step_loss=0.0107/18/2023 20:13:10 - INFO - __main__ - train loss is 13.154804007150233\n",
      "Steps:  73%|▋| 10928/15000 [1:09:48<12:07,  5.60it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:10 - INFO - __main__ - train loss is 13.174466828815639\n",
      "Steps:  73%|▋| 10929/15000 [1:09:48<12:07,  5.60it/s, lr=9.21e-6, step_loss=0.0107/18/2023 20:13:10 - INFO - __main__ - train loss is 13.554462532512844\n",
      "Steps:  73%|▋| 10930/15000 [1:09:48<12:07,  5.59it/s, lr=9.21e-6, step_loss=0.3807/18/2023 20:13:10 - INFO - __main__ - train loss is 13.759317512623966\n",
      "Steps:  73%|▋| 10931/15000 [1:09:48<12:07,  5.59it/s, lr=9.21e-6, step_loss=0.2007/18/2023 20:13:11 - INFO - __main__ - train loss is 13.767589679919183\n",
      "Steps:  73%|▋| 10932/15000 [1:09:49<12:07,  5.60it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:11 - INFO - __main__ - train loss is 13.826224303804338\n",
      "Steps:  73%|▋| 10933/15000 [1:09:49<12:06,  5.60it/s, lr=9.21e-6, step_loss=0.0507/18/2023 20:13:11 - INFO - __main__ - train loss is 14.12798551376909\n",
      "Steps:  73%|▋| 10934/15000 [1:09:49<12:06,  5.60it/s, lr=9.21e-6, step_loss=0.3007/18/2023 20:13:11 - INFO - __main__ - train loss is 14.274975529871881\n",
      "Steps:  73%|▋| 10935/15000 [1:09:49<12:06,  5.60it/s, lr=9.21e-6, step_loss=0.1407/18/2023 20:13:11 - INFO - __main__ - train loss is 14.277628098847345\n",
      "Steps:  73%|▋| 10936/15000 [1:09:49<12:06,  5.60it/s, lr=9.21e-6, step_loss=0.0007/18/2023 20:13:12 - INFO - __main__ - train loss is 14.316607230575755\n",
      "Steps:  73%|▋| 10937/15000 [1:09:49<12:06,  5.60it/s, lr=9.2e-6, step_loss=0.03907/18/2023 20:13:12 - INFO - __main__ - train loss is 14.360655785771087\n",
      "Steps:  73%|▋| 10938/15000 [1:09:50<12:05,  5.60it/s, lr=9.2e-6, step_loss=0.04407/18/2023 20:13:12 - INFO - __main__ - train loss is 14.420421988936141\n",
      "Steps:  73%|▋| 10939/15000 [1:09:50<12:05,  5.60it/s, lr=9.2e-6, step_loss=0.05907/18/2023 20:13:12 - INFO - __main__ - train loss is 14.605714322300628\n",
      "Steps:  73%|▋| 10940/15000 [1:09:50<12:05,  5.60it/s, lr=9.2e-6, step_loss=0.18507/18/2023 20:13:12 - INFO - __main__ - train loss is 14.613096510758623\n",
      "Steps:  73%|▋| 10941/15000 [1:09:50<12:05,  5.60it/s, lr=9.2e-6, step_loss=0.00707/18/2023 20:13:12 - INFO - __main__ - train loss is 14.706469004740939\n",
      "Steps:  73%|▋| 10942/15000 [1:09:50<12:05,  5.59it/s, lr=9.2e-6, step_loss=0.09307/18/2023 20:13:13 - INFO - __main__ - train loss is 14.777700228383765\n",
      "Steps:  73%|▋| 10943/15000 [1:09:50<12:05,  5.59it/s, lr=9.2e-6, step_loss=0.07107/18/2023 20:13:13 - INFO - __main__ - train loss is 14.788981169229373\n",
      "Steps:  73%|▋| 10944/15000 [1:09:51<12:05,  5.59it/s, lr=9.2e-6, step_loss=0.01107/18/2023 20:13:13 - INFO - __main__ - train loss is 15.320181220537052\n",
      "Steps:  73%|▋| 10945/15000 [1:09:51<12:04,  5.60it/s, lr=9.2e-6, step_loss=0.53107/18/2023 20:13:13 - INFO - __main__ - train loss is 15.764569103484973\n",
      "Steps:  73%|▋| 10946/15000 [1:09:51<12:03,  5.60it/s, lr=9.2e-6, step_loss=0.44407/18/2023 20:13:13 - INFO - __main__ - train loss is 15.797128975158557\n",
      "Steps:  73%|▋| 10947/15000 [1:09:51<12:03,  5.60it/s, lr=9.2e-6, step_loss=0.03207/18/2023 20:13:13 - INFO - __main__ - train loss is 16.499479591613635\n",
      "Steps:  73%|▋| 10948/15000 [1:09:51<12:02,  5.60it/s, lr=9.2e-6, step_loss=0.70207/18/2023 20:13:14 - INFO - __main__ - train loss is 16.50783065124415\n",
      "Steps:  73%|▋| 10949/15000 [1:09:52<12:02,  5.60it/s, lr=9.2e-6, step_loss=0.00807/18/2023 20:13:14 - INFO - __main__ - train loss is 16.63543160422705\n",
      "Steps:  73%|▋| 10950/15000 [1:09:52<12:02,  5.61it/s, lr=9.2e-6, step_loss=0.12807/18/2023 20:13:14 - INFO - __main__ - train loss is 17.263540344079956\n",
      "Steps:  73%|▋| 10951/15000 [1:09:52<12:02,  5.60it/s, lr=9.2e-6, step_loss=0.62807/18/2023 20:13:14 - INFO - __main__ - train loss is 17.27063485304825\n",
      "Steps:  73%|▋| 10952/15000 [1:09:52<12:02,  5.60it/s, lr=9.2e-6, step_loss=0.00707/18/2023 20:13:14 - INFO - __main__ - train loss is 17.438711040420458\n",
      "Steps:  73%|▋| 10953/15000 [1:09:52<12:01,  5.61it/s, lr=9.2e-6, step_loss=0.16807/18/2023 20:13:15 - INFO - __main__ - train loss is 17.81439929525368\n",
      "Steps:  73%|▋| 10954/15000 [1:09:52<12:01,  5.60it/s, lr=9.2e-6, step_loss=0.37607/18/2023 20:13:15 - INFO - __main__ - train loss is 17.816179712535813\n",
      "Steps:  73%|▋| 10955/15000 [1:09:53<12:02,  5.60it/s, lr=9.2e-6, step_loss=0.00107/18/2023 20:13:15 - INFO - __main__ - train loss is 18.064930041553453\n",
      "Steps:  73%|▋| 10956/15000 [1:09:53<12:01,  5.60it/s, lr=9.2e-6, step_loss=0.24907/18/2023 20:13:15 - INFO - __main__ - train loss is 18.099410941125825\n",
      "Steps:  73%|▋| 10957/15000 [1:09:53<12:01,  5.60it/s, lr=9.2e-6, step_loss=0.03407/18/2023 20:13:15 - INFO - __main__ - train loss is 18.16810751450248\n",
      "Steps:  73%|▋| 10958/15000 [1:09:53<12:01,  5.61it/s, lr=9.2e-6, step_loss=0.06807/18/2023 20:13:15 - INFO - __main__ - train loss is 18.18462682259269\n",
      "Steps:  73%|▋| 10959/15000 [1:09:53<12:00,  5.61it/s, lr=9.2e-6, step_loss=0.01607/18/2023 20:13:16 - INFO - __main__ - train loss is 18.187196367187425\n",
      "Steps:  73%|▋| 10960/15000 [1:09:54<12:00,  5.61it/s, lr=9.2e-6, step_loss=0.00207/18/2023 20:13:16 - INFO - __main__ - train loss is 18.262122095329687\n",
      "Steps:  73%|▋| 10961/15000 [1:09:54<16:17,  4.13it/s, lr=9.2e-6, step_loss=0.07407/18/2023 20:13:17 - INFO - __main__ - Per validation step average loss is 0.22361069917678833\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Cumulative validation average loss is 0.22361069917678833\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Per validation step average loss is 0.03701947629451752\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Cumulative validation average loss is 0.26063017547130585\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Per validation step average loss is 0.0023530214093625546\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Cumulative validation average loss is 0.2629831968806684\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Per validation step average loss is 0.05927655100822449\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Cumulative validation average loss is 0.3222597478888929\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Per validation step average loss is 0.046592168509960175\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Cumulative validation average loss is 0.36885191639885306\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Per validation step average loss is 0.0048035429790616035\n",
      "07/18/2023 20:13:17 - INFO - __main__ - Cumulative validation average loss is 0.37365545937791467\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Per validation step average loss is 0.11961377412080765\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Cumulative validation average loss is 0.4932692334987223\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Per validation step average loss is 0.004958444740623236\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Cumulative validation average loss is 0.49822767823934555\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Per validation step average loss is 0.29638826847076416\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Cumulative validation average loss is 0.7946159467101097\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Per validation step average loss is 0.02714643068611622\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Cumulative validation average loss is 0.8217623773962259\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Per validation step average loss is 0.03164243698120117\n",
      "07/18/2023 20:13:18 - INFO - __main__ - Cumulative validation average loss is 0.8534048143774271\n",
      "07/18/2023 20:13:19 - INFO - __main__ - Per validation step average loss is 0.002297488274052739\n",
      "07/18/2023 20:13:19 - INFO - __main__ - Cumulative validation average loss is 0.8557023026514798\n",
      "07/18/2023 20:13:19 - INFO - __main__ - Average validation loss for Epoch 112 is 0.07130852522095665\n",
      "07/18/2023 20:13:19 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:13:31 - INFO - __main__ - Starting epoch 113\n",
      "07/18/2023 20:13:32 - INFO - __main__ - train loss is 0.4483199417591095\n",
      "Steps:  73%|▋| 10962/15000 [1:10:10<5:29:46,  4.90s/it, lr=9.2e-6, step_loss=0.407/18/2023 20:13:32 - INFO - __main__ - train loss is 0.7118391692638397\n",
      "Steps:  73%|▋| 10963/15000 [1:10:10<3:54:24,  3.48s/it, lr=9.2e-6, step_loss=0.207/18/2023 20:13:32 - INFO - __main__ - train loss is 0.7179959854111075\n",
      "Steps:  73%|▋| 10964/15000 [1:10:10<2:47:39,  2.49s/it, lr=9.2e-6, step_loss=0.007/18/2023 20:13:32 - INFO - __main__ - train loss is 1.2483286699280143\n",
      "Steps:  73%|▋| 10965/15000 [1:10:10<2:00:55,  1.80s/it, lr=9.2e-6, step_loss=0.507/18/2023 20:13:33 - INFO - __main__ - train loss is 1.2633857233449817\n",
      "Steps:  73%|▋| 10966/15000 [1:10:10<1:28:13,  1.31s/it, lr=9.2e-6, step_loss=0.007/18/2023 20:13:33 - INFO - __main__ - train loss is 1.3381604803726077\n",
      "Steps:  73%|▋| 10967/15000 [1:10:11<1:05:31,  1.03it/s, lr=9.2e-6, step_loss=0.007/18/2023 20:13:33 - INFO - __main__ - train loss is 1.527374799363315\n",
      "Steps:  73%|▋| 10968/15000 [1:10:11<49:26,  1.36it/s, lr=9.2e-6, step_loss=0.18907/18/2023 20:13:33 - INFO - __main__ - train loss is 2.016150767914951\n",
      "Steps:  73%|▋| 10969/15000 [1:10:11<38:11,  1.76it/s, lr=9.2e-6, step_loss=0.48907/18/2023 20:13:33 - INFO - __main__ - train loss is 2.1625205678865314\n",
      "Steps:  73%|▋| 10970/15000 [1:10:11<30:18,  2.22it/s, lr=9.2e-6, step_loss=0.14607/18/2023 20:13:33 - INFO - __main__ - train loss is 2.4138324363157153\n",
      "Steps:  73%|▋| 10971/15000 [1:10:11<24:48,  2.71it/s, lr=9.2e-6, step_loss=0.25107/18/2023 20:13:34 - INFO - __main__ - train loss is 3.3377250535413623\n",
      "Steps:  73%|▋| 10972/15000 [1:10:11<20:57,  3.20it/s, lr=9.2e-6, step_loss=0.92407/18/2023 20:13:34 - INFO - __main__ - train loss is 3.486613313667476\n",
      "Steps:  73%|▋| 10973/15000 [1:10:12<18:14,  3.68it/s, lr=9.2e-6, step_loss=0.14907/18/2023 20:13:34 - INFO - __main__ - train loss is 3.4911509808152914\n",
      "Steps:  73%|▋| 10974/15000 [1:10:12<16:27,  4.07it/s, lr=9.2e-6, step_loss=0.00407/18/2023 20:13:34 - INFO - __main__ - train loss is 3.579061044380069\n",
      "Steps:  73%|▋| 10975/15000 [1:10:12<15:12,  4.41it/s, lr=9.2e-6, step_loss=0.08707/18/2023 20:13:34 - INFO - __main__ - train loss is 3.581778898369521\n",
      "Steps:  73%|▋| 10976/15000 [1:10:12<14:19,  4.68it/s, lr=9.2e-6, step_loss=0.00207/18/2023 20:13:34 - INFO - __main__ - train loss is 3.7406999017111957\n",
      "Steps:  73%|▋| 10977/15000 [1:10:12<13:42,  4.89it/s, lr=9.2e-6, step_loss=0.15907/18/2023 20:13:35 - INFO - __main__ - train loss is 4.126863851677626\n",
      "Steps:  73%|▋| 10978/15000 [1:10:13<13:10,  5.09it/s, lr=9.2e-6, step_loss=0.38607/18/2023 20:13:35 - INFO - __main__ - train loss is 4.183828029315919\n",
      "Steps:  73%|▋| 10979/15000 [1:10:13<12:48,  5.23it/s, lr=9.2e-6, step_loss=0.05707/18/2023 20:13:35 - INFO - __main__ - train loss is 4.193697650451213\n",
      "Steps:  73%|▋| 10980/15000 [1:10:13<12:33,  5.33it/s, lr=9.2e-6, step_loss=0.00907/18/2023 20:13:35 - INFO - __main__ - train loss is 4.384760965127498\n",
      "Steps:  73%|▋| 10981/15000 [1:10:13<12:35,  5.32it/s, lr=9.2e-6, step_loss=0.19107/18/2023 20:13:35 - INFO - __main__ - train loss is 4.38873717142269\n",
      "Steps:  73%|▋| 10982/15000 [1:10:13<12:26,  5.38it/s, lr=9.2e-6, step_loss=0.00307/18/2023 20:13:36 - INFO - __main__ - train loss is 4.631914704572409\n",
      "Steps:  73%|▋| 10983/15000 [1:10:13<12:24,  5.39it/s, lr=9.2e-6, step_loss=0.24307/18/2023 20:13:36 - INFO - __main__ - train loss is 4.8523195828311145\n",
      "Steps:  73%|▋| 10984/15000 [1:10:14<12:17,  5.44it/s, lr=9.2e-6, step_loss=0.22]07/18/2023 20:13:36 - INFO - __main__ - train loss is 5.054011225234717\n",
      "Steps:  73%|▋| 10985/15000 [1:10:14<12:11,  5.49it/s, lr=9.2e-6, step_loss=0.20207/18/2023 20:13:36 - INFO - __main__ - train loss is 5.05740781314671\n",
      "Steps:  73%|▋| 10986/15000 [1:10:14<12:07,  5.52it/s, lr=9.2e-6, step_loss=0.00307/18/2023 20:13:36 - INFO - __main__ - train loss is 5.1018547136336565\n",
      "Steps:  73%|▋| 10987/15000 [1:10:14<12:04,  5.54it/s, lr=9.2e-6, step_loss=0.04407/18/2023 20:13:36 - INFO - __main__ - train loss is 5.107616882771254\n",
      "Steps:  73%|▋| 10988/15000 [1:10:14<12:06,  5.52it/s, lr=9.2e-6, step_loss=0.00507/18/2023 20:13:37 - INFO - __main__ - train loss is 5.241787742823362\n",
      "Steps:  73%|▋| 10989/15000 [1:10:15<12:03,  5.54it/s, lr=9.2e-6, step_loss=0.13407/18/2023 20:13:37 - INFO - __main__ - train loss is 5.2434672840172425\n",
      "Steps:  73%|▋| 10990/15000 [1:10:15<12:01,  5.56it/s, lr=9.2e-6, step_loss=0.00107/18/2023 20:13:37 - INFO - __main__ - train loss is 5.488610265427269\n",
      "Steps:  73%|▋| 10991/15000 [1:10:15<11:59,  5.57it/s, lr=9.2e-6, step_loss=0.24507/18/2023 20:13:37 - INFO - __main__ - train loss is 5.492494360660203\n",
      "Steps:  73%|▋| 10992/15000 [1:10:15<11:58,  5.58it/s, lr=9.2e-6, step_loss=0.00307/18/2023 20:13:37 - INFO - __main__ - train loss is 5.4986812939168885\n",
      "Steps:  73%|▋| 10993/15000 [1:10:15<11:57,  5.59it/s, lr=9.2e-6, step_loss=0.00607/18/2023 20:13:38 - INFO - __main__ - train loss is 5.504258005996235\n",
      "Steps:  73%|▋| 10994/15000 [1:10:15<11:56,  5.59it/s, lr=9.2e-6, step_loss=0.00507/18/2023 20:13:38 - INFO - __main__ - train loss is 5.512235853006132\n",
      "Steps:  73%|▋| 10995/15000 [1:10:16<11:55,  5.60it/s, lr=9.2e-6, step_loss=0.00707/18/2023 20:13:38 - INFO - __main__ - train loss is 5.7633550494210795\n",
      "Steps:  73%|▋| 10996/15000 [1:10:16<11:55,  5.60it/s, lr=9.2e-6, step_loss=0.25107/18/2023 20:13:38 - INFO - __main__ - train loss is 5.971948149730451\n",
      "Steps:  73%|▋| 10997/15000 [1:10:16<11:55,  5.59it/s, lr=9.2e-6, step_loss=0.20907/18/2023 20:13:38 - INFO - __main__ - train loss is 6.171683955122717\n",
      "Steps:  73%|█▍| 10998/15000 [1:10:16<11:56,  5.59it/s, lr=9.2e-6, step_loss=0.2]07/18/2023 20:13:38 - INFO - __main__ - train loss is 6.175589345977642\n",
      "Steps:  73%|▋| 10999/15000 [1:10:16<11:55,  5.59it/s, lr=9.2e-6, step_loss=0.00307/18/2023 20:13:39 - INFO - __main__ - train loss is 6.181110339821316\n",
      "Steps:  73%|▋| 11000/15000 [1:10:17<11:54,  5.60it/s, lr=9.2e-6, step_loss=0.00307/18/2023 20:13:39 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-11000\n",
      "07/18/2023 20:13:39 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:13:39,213] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:13:39,218] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-11000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:13:39,218] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-11000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:13:39,225] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-11000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:13:39,226] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-11000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:13:39,245] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-11000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:13:39,245] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-11000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:13:39,245] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:13:39 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-11000/pytorch_model\n",
      "07/18/2023 20:13:39 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-11000/scheduler.bin\n",
      "07/18/2023 20:13:39 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-11000/random_states_0.pkl\n",
      "07/18/2023 20:13:39 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-11000\n",
      "Steps:  73%|▋| 11000/15000 [1:10:17<11:54,  5.60it/s, lr=9.2e-6, step_loss=0.00507/18/2023 20:13:39 - INFO - __main__ - train loss is 6.546347426832654\n",
      "Steps:  73%|▋| 11001/15000 [1:10:17<12:39,  5.27it/s, lr=9.2e-6, step_loss=0.36507/18/2023 20:13:39 - INFO - __main__ - train loss is 6.560858410433866\n",
      "Steps:  73%|▋| 11002/15000 [1:10:17<12:25,  5.37it/s, lr=9.2e-6, step_loss=0.01407/18/2023 20:13:39 - INFO - __main__ - train loss is 6.563499162555672\n",
      "Steps:  73%|▋| 11003/15000 [1:10:17<12:21,  5.39it/s, lr=9.2e-6, step_loss=0.00207/18/2023 20:13:39 - INFO - __main__ - train loss is 6.5653805455658585\n",
      "Steps:  73%|▋| 11004/15000 [1:10:17<12:13,  5.45it/s, lr=9.2e-6, step_loss=0.00107/18/2023 20:13:40 - INFO - __main__ - train loss is 6.625080989906564\n",
      "Steps:  73%|▋| 11005/15000 [1:10:17<12:06,  5.50it/s, lr=9.2e-6, step_loss=0.05907/18/2023 20:13:40 - INFO - __main__ - train loss is 6.7718402615282685\n",
      "Steps:  73%|▋| 11006/15000 [1:10:18<12:02,  5.53it/s, lr=9.2e-6, step_loss=0.14707/18/2023 20:13:40 - INFO - __main__ - train loss is 7.101866947719827\n",
      "Steps:  73%|▋| 11007/15000 [1:10:18<11:59,  5.55it/s, lr=9.19e-6, step_loss=0.3307/18/2023 20:13:40 - INFO - __main__ - train loss is 7.142059641191736\n",
      "Steps:  73%|▋| 11008/15000 [1:10:18<11:57,  5.56it/s, lr=9.19e-6, step_loss=0.0407/18/2023 20:13:40 - INFO - __main__ - train loss is 7.17868503392674\n",
      "Steps:  73%|▋| 11009/15000 [1:10:18<11:56,  5.57it/s, lr=9.19e-6, step_loss=0.0307/18/2023 20:13:40 - INFO - __main__ - train loss is 7.1818373838905245\n",
      "Steps:  73%|▋| 11010/15000 [1:10:18<11:55,  5.58it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:41 - INFO - __main__ - train loss is 7.186051630182192\n",
      "Steps:  73%|▋| 11011/15000 [1:10:19<11:54,  5.58it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:41 - INFO - __main__ - train loss is 7.740662478609011\n",
      "Steps:  73%|▋| 11012/15000 [1:10:19<11:59,  5.54it/s, lr=9.19e-6, step_loss=0.5507/18/2023 20:13:41 - INFO - __main__ - train loss is 7.9734579406213015\n",
      "Steps:  73%|▋| 11013/15000 [1:10:19<11:57,  5.56it/s, lr=9.19e-6, step_loss=0.2307/18/2023 20:13:41 - INFO - __main__ - train loss is 8.16573388199322\n",
      "Steps:  73%|▋| 11014/15000 [1:10:19<11:55,  5.57it/s, lr=9.19e-6, step_loss=0.1907/18/2023 20:13:41 - INFO - __main__ - train loss is 8.22715186025016\n",
      "Steps:  73%|▋| 11015/15000 [1:10:19<11:54,  5.58it/s, lr=9.19e-6, step_loss=0.0607/18/2023 20:13:42 - INFO - __main__ - train loss is 8.235264787217602\n",
      "Steps:  73%|▋| 11016/15000 [1:10:19<12:11,  5.45it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:42 - INFO - __main__ - train loss is 8.262218503048643\n",
      "Steps:  73%|▋| 11017/15000 [1:10:20<12:17,  5.40it/s, lr=9.19e-6, step_loss=0.0207/18/2023 20:13:42 - INFO - __main__ - train loss is 8.269755617016926\n",
      "Steps:  73%|▋| 11018/15000 [1:10:20<12:14,  5.42it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:42 - INFO - __main__ - train loss is 8.320960462326184\n",
      "Steps:  73%|▋| 11019/15000 [1:10:20<12:12,  5.44it/s, lr=9.19e-6, step_loss=0.0507/18/2023 20:13:42 - INFO - __main__ - train loss is 8.343412393936887\n",
      "Steps:  73%|▋| 11020/15000 [1:10:20<12:22,  5.36it/s, lr=9.19e-6, step_loss=0.0207/18/2023 20:13:42 - INFO - __main__ - train loss is 8.477044815430418\n",
      "Steps:  73%|▋| 11021/15000 [1:10:20<12:32,  5.29it/s, lr=9.19e-6, step_loss=0.1307/18/2023 20:13:43 - INFO - __main__ - train loss is 8.480977708240971\n",
      "Steps:  73%|▋| 11022/15000 [1:10:21<12:35,  5.27it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:43 - INFO - __main__ - train loss is 8.496062175137922\n",
      "Steps:  73%|▋| 11023/15000 [1:10:21<12:31,  5.29it/s, lr=9.19e-6, step_loss=0.0107/18/2023 20:13:43 - INFO - __main__ - train loss is 8.50966302654706\n",
      "Steps:  73%|▋| 11024/15000 [1:10:21<12:23,  5.35it/s, lr=9.19e-6, step_loss=0.0107/18/2023 20:13:43 - INFO - __main__ - train loss is 8.578347366070375\n",
      "Steps:  74%|▋| 11025/15000 [1:10:21<12:29,  5.31it/s, lr=9.19e-6, step_loss=0.0607/18/2023 20:13:43 - INFO - __main__ - train loss is 8.67024527094327\n",
      "Steps:  74%|▋| 11026/15000 [1:10:21<12:35,  5.26it/s, lr=9.19e-6, step_loss=0.0907/18/2023 20:13:44 - INFO - __main__ - train loss is 8.830781187629327\n",
      "Steps:  74%|▋| 11027/15000 [1:10:22<12:40,  5.22it/s, lr=9.19e-6, step_loss=0.1607/18/2023 20:13:44 - INFO - __main__ - train loss is 9.034888814901933\n",
      "Steps:  74%|▋| 11028/15000 [1:10:22<12:43,  5.20it/s, lr=9.19e-6, step_loss=0.2007/18/2023 20:13:44 - INFO - __main__ - train loss is 9.04736022069119\n",
      "Steps:  74%|▋| 11029/15000 [1:10:22<12:46,  5.18it/s, lr=9.19e-6, step_loss=0.0107/18/2023 20:13:44 - INFO - __main__ - train loss is 9.100692922016606\n",
      "Steps:  74%|▋| 11030/15000 [1:10:22<12:48,  5.17it/s, lr=9.19e-6, step_loss=0.0507/18/2023 20:13:44 - INFO - __main__ - train loss is 9.143599854549393\n",
      "Steps:  74%|▋| 11031/15000 [1:10:22<12:48,  5.16it/s, lr=9.19e-6, step_loss=0.0407/18/2023 20:13:45 - INFO - __main__ - train loss is 9.145988779840991\n",
      "Steps:  74%|▋| 11032/15000 [1:10:22<12:42,  5.20it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:45 - INFO - __main__ - train loss is 9.168372749118134\n",
      "Steps:  74%|▋| 11033/15000 [1:10:23<12:41,  5.21it/s, lr=9.19e-6, step_loss=0.0207/18/2023 20:13:45 - INFO - __main__ - train loss is 9.720374940661713\n",
      "Steps:  74%|▋| 11034/15000 [1:10:23<12:33,  5.26it/s, lr=9.19e-6, step_loss=0.5507/18/2023 20:13:45 - INFO - __main__ - train loss is 9.833354516653344\n",
      "Steps:  74%|▋| 11035/15000 [1:10:23<12:32,  5.27it/s, lr=9.19e-6, step_loss=0.1107/18/2023 20:13:45 - INFO - __main__ - train loss is 10.140691979555413\n",
      "Steps:  74%|▋| 11036/15000 [1:10:23<12:30,  5.28it/s, lr=9.19e-6, step_loss=0.3007/18/2023 20:13:46 - INFO - __main__ - train loss is 10.144267464289442\n",
      "Steps:  74%|▋| 11037/15000 [1:10:23<12:36,  5.24it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:46 - INFO - __main__ - train loss is 10.224691072711721\n",
      "Steps:  74%|▋| 11038/15000 [1:10:24<12:41,  5.21it/s, lr=9.19e-6, step_loss=0.0807/18/2023 20:13:46 - INFO - __main__ - train loss is 10.227419583359733\n",
      "Steps:  74%|▋| 11039/15000 [1:10:24<12:43,  5.19it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:46 - INFO - __main__ - train loss is 10.240876101190224\n",
      "Steps:  74%|▋| 11040/15000 [1:10:24<12:46,  5.17it/s, lr=9.19e-6, step_loss=0.0107/18/2023 20:13:46 - INFO - __main__ - train loss is 10.2441149817314\n",
      "Steps:  74%|▋| 11041/15000 [1:10:24<12:47,  5.16it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:47 - INFO - __main__ - train loss is 10.44608692987822\n",
      "Steps:  74%|▋| 11042/15000 [1:10:24<12:48,  5.15it/s, lr=9.19e-6, step_loss=0.2007/18/2023 20:13:47 - INFO - __main__ - train loss is 10.480005198856816\n",
      "Steps:  74%|▋| 11043/15000 [1:10:25<12:47,  5.15it/s, lr=9.19e-6, step_loss=0.0307/18/2023 20:13:47 - INFO - __main__ - train loss is 10.485174488043413\n",
      "Steps:  74%|▋| 11044/15000 [1:10:25<12:47,  5.15it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:47 - INFO - __main__ - train loss is 10.70231495401822\n",
      "Steps:  74%|▋| 11045/15000 [1:10:25<12:48,  5.15it/s, lr=9.19e-6, step_loss=0.2107/18/2023 20:13:47 - INFO - __main__ - train loss is 10.715608650585636\n",
      "Steps:  74%|▋| 11046/15000 [1:10:25<12:48,  5.15it/s, lr=9.19e-6, step_loss=0.0107/18/2023 20:13:47 - INFO - __main__ - train loss is 10.717089477693662\n",
      "Steps:  74%|▋| 11047/15000 [1:10:25<12:51,  5.13it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:48 - INFO - __main__ - train loss is 10.764471120899543\n",
      "Steps:  74%|▋| 11048/15000 [1:10:26<12:52,  5.12it/s, lr=9.19e-6, step_loss=0.0407/18/2023 20:13:48 - INFO - __main__ - train loss is 10.843667410081252\n",
      "Steps:  74%|▋| 11049/15000 [1:10:26<12:52,  5.12it/s, lr=9.19e-6, step_loss=0.0707/18/2023 20:13:48 - INFO - __main__ - train loss is 11.160080276196823\n",
      "Steps:  74%|▋| 11050/15000 [1:10:26<12:51,  5.12it/s, lr=9.19e-6, step_loss=0.3107/18/2023 20:13:48 - INFO - __main__ - train loss is 11.167538632405922\n",
      "Steps:  74%|▋| 11051/15000 [1:10:26<12:50,  5.12it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:13:48 - INFO - __main__ - train loss is 11.380302567733452\n",
      "Steps:  74%|▋| 11052/15000 [1:10:26<12:48,  5.13it/s, lr=9.19e-6, step_loss=0.2107/18/2023 20:13:49 - INFO - __main__ - train loss is 11.436504428042099\n",
      "Steps:  74%|▋| 11053/15000 [1:10:27<12:48,  5.14it/s, lr=9.19e-6, step_loss=0.0507/18/2023 20:13:49 - INFO - __main__ - train loss is 12.324531976832077\n",
      "Steps:  74%|▋| 11054/15000 [1:10:27<12:47,  5.14it/s, lr=9.19e-6, step_loss=0.8807/18/2023 20:13:49 - INFO - __main__ - train loss is 12.496640627039596\n",
      "Steps:  74%|▋| 11055/15000 [1:10:27<12:47,  5.14it/s, lr=9.19e-6, step_loss=0.1707/18/2023 20:13:49 - INFO - __main__ - train loss is 12.6159700199496\n",
      "Steps:  74%|▋| 11056/15000 [1:10:27<12:47,  5.14it/s, lr=9.19e-6, step_loss=0.1107/18/2023 20:13:49 - INFO - __main__ - train loss is 12.6484515897464\n",
      "Steps:  74%|▋| 11057/15000 [1:10:27<12:47,  5.14it/s, lr=9.19e-6, step_loss=0.0307/18/2023 20:13:50 - INFO - __main__ - train loss is 12.735087820095941\n",
      "Steps:  74%|▋| 11058/15000 [1:10:28<17:52,  3.68it/s, lr=9.19e-6, step_loss=0.0807/18/2023 20:13:51 - INFO - __main__ - Per validation step average loss is 0.012839315459132195\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Cumulative validation average loss is 0.012839315459132195\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Per validation step average loss is 0.026097241789102554\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Cumulative validation average loss is 0.03893655724823475\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Per validation step average loss is 0.7586631774902344\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Cumulative validation average loss is 0.7975997347384691\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Per validation step average loss is 0.0038485755212605\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Cumulative validation average loss is 0.8014483102597296\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Per validation step average loss is 0.34818488359451294\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Cumulative validation average loss is 1.1496331938542426\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Per validation step average loss is 0.10138633847236633\n",
      "07/18/2023 20:13:51 - INFO - __main__ - Cumulative validation average loss is 1.251019532326609\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Per validation step average loss is 0.4361620843410492\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Cumulative validation average loss is 1.687181616667658\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Per validation step average loss is 0.2642657458782196\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Cumulative validation average loss is 1.9514473625458777\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Per validation step average loss is 0.010056639090180397\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Cumulative validation average loss is 1.961504001636058\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Per validation step average loss is 0.004798767622560263\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Cumulative validation average loss is 1.9663027692586184\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Per validation step average loss is 0.02819334715604782\n",
      "07/18/2023 20:13:52 - INFO - __main__ - Cumulative validation average loss is 1.9944961164146662\n",
      "07/18/2023 20:13:53 - INFO - __main__ - Per validation step average loss is 0.14655810594558716\n",
      "07/18/2023 20:13:53 - INFO - __main__ - Cumulative validation average loss is 2.1410542223602533\n",
      "07/18/2023 20:13:53 - INFO - __main__ - Average validation loss for Epoch 113 is 0.1784211851966878\n",
      "07/18/2023 20:13:53 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:14:05 - INFO - __main__ - Starting epoch 114\n",
      "07/18/2023 20:14:06 - INFO - __main__ - train loss is 0.24350868165493011\n",
      "Steps:  74%|▋| 11059/15000 [1:10:44<5:26:10,  4.97s/it, lr=9.19e-6, step_loss=0.07/18/2023 20:14:06 - INFO - __main__ - train loss is 0.38219045102596283\n",
      "Steps:  74%|▋| 11060/15000 [1:10:44<3:51:53,  3.53s/it, lr=9.19e-6, step_loss=0.07/18/2023 20:14:06 - INFO - __main__ - train loss is 0.4705202654004097\n",
      "Steps:  74%|▋| 11061/15000 [1:10:44<2:45:47,  2.53s/it, lr=9.19e-6, step_loss=0.07/18/2023 20:14:06 - INFO - __main__ - train loss is 0.5510067492723465\n",
      "Steps:  74%|▋| 11062/15000 [1:10:44<1:59:32,  1.82s/it, lr=9.19e-6, step_loss=0.07/18/2023 20:14:07 - INFO - __main__ - train loss is 0.8495469242334366\n",
      "Steps:  74%|▋| 11063/15000 [1:10:44<1:27:09,  1.33s/it, lr=9.19e-6, step_loss=0.07/18/2023 20:14:07 - INFO - __main__ - train loss is 1.1813866049051285\n",
      "Steps:  74%|▋| 11064/15000 [1:10:45<1:04:56,  1.01it/s, lr=9.19e-6, step_loss=0.07/18/2023 20:14:07 - INFO - __main__ - train loss is 1.3190767616033554\n",
      "Steps:  74%|▋| 11065/15000 [1:10:45<52:41,  1.24it/s, lr=9.19e-6, step_loss=0.1307/18/2023 20:14:07 - INFO - __main__ - train loss is 1.6116371601819992\n",
      "Steps:  74%|▋| 11066/15000 [1:10:45<40:44,  1.61it/s, lr=9.19e-6, step_loss=0.2907/18/2023 20:14:07 - INFO - __main__ - train loss is 1.6432683132588863\n",
      "Steps:  74%|▋| 11067/15000 [1:10:45<32:06,  2.04it/s, lr=9.19e-6, step_loss=0.0307/18/2023 20:14:08 - INFO - __main__ - train loss is 1.785336371511221\n",
      "Steps:  74%|▋| 11068/15000 [1:10:46<25:58,  2.52it/s, lr=9.19e-6, step_loss=0.1407/18/2023 20:14:08 - INFO - __main__ - train loss is 2.057521875947714\n",
      "Steps:  74%|▋| 11069/15000 [1:10:46<21:40,  3.02it/s, lr=9.19e-6, step_loss=0.2707/18/2023 20:14:08 - INFO - __main__ - train loss is 2.1545046977698803\n",
      "Steps:  74%|▋| 11070/15000 [1:10:46<18:47,  3.49it/s, lr=9.19e-6, step_loss=0.0907/18/2023 20:14:08 - INFO - __main__ - train loss is 2.160975370090455\n",
      "Steps:  74%|▋| 11071/15000 [1:10:46<16:46,  3.90it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:14:08 - INFO - __main__ - train loss is 2.6398638817481697\n",
      "Steps:  74%|▋| 11072/15000 [1:10:46<15:20,  4.27it/s, lr=9.19e-6, step_loss=0.4707/18/2023 20:14:09 - INFO - __main__ - train loss is 2.6443393509835005\n",
      "Steps:  74%|▋| 11073/15000 [1:10:46<14:20,  4.56it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:14:09 - INFO - __main__ - train loss is 2.645933178020641\n",
      "Steps:  74%|▋| 11074/15000 [1:10:47<13:38,  4.80it/s, lr=9.19e-6, step_loss=0.0007/18/2023 20:14:09 - INFO - __main__ - train loss is 2.693242222769186\n",
      "Steps:  74%|▋| 11075/15000 [1:10:47<13:03,  5.01it/s, lr=9.19e-6, step_loss=0.0407/18/2023 20:14:09 - INFO - __main__ - train loss is 3.0558750338386744\n",
      "Steps:  74%|▋| 11076/15000 [1:10:47<12:38,  5.17it/s, lr=9.19e-6, step_loss=0.3607/18/2023 20:14:09 - INFO - __main__ - train loss is 3.3541247851680964\n",
      "Steps:  74%|▋| 11077/15000 [1:10:47<12:21,  5.29it/s, lr=9.18e-6, step_loss=0.2907/18/2023 20:14:09 - INFO - __main__ - train loss is 3.3810007355641574\n",
      "Steps:  74%|▋| 11078/15000 [1:10:47<12:09,  5.38it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:10 - INFO - __main__ - train loss is 3.4112694177310914\n",
      "Steps:  74%|▋| 11079/15000 [1:10:48<12:00,  5.44it/s, lr=9.18e-6, step_loss=0.0307/18/2023 20:14:10 - INFO - __main__ - train loss is 3.429703053785488\n",
      "Steps:  74%|▋| 11080/15000 [1:10:48<11:55,  5.48it/s, lr=9.18e-6, step_loss=0.0107/18/2023 20:14:10 - INFO - __main__ - train loss is 3.7132587402593344\n",
      "Steps:  74%|▋| 11081/15000 [1:10:48<11:50,  5.52it/s, lr=9.18e-6, step_loss=0.2807/18/2023 20:14:10 - INFO - __main__ - train loss is 3.792865601135418\n",
      "Steps:  74%|▋| 11082/15000 [1:10:48<11:46,  5.54it/s, lr=9.18e-6, step_loss=0.0707/18/2023 20:14:10 - INFO - __main__ - train loss is 3.902975496603176\n",
      "Steps:  74%|▋| 11083/15000 [1:10:48<11:44,  5.56it/s, lr=9.18e-6, step_loss=0.1107/18/2023 20:14:11 - INFO - __main__ - train loss is 3.907565093366429\n",
      "Steps:  74%|▋| 11084/15000 [1:10:48<11:42,  5.58it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:11 - INFO - __main__ - train loss is 3.9366369012277573\n",
      "Steps:  74%|▋| 11085/15000 [1:10:49<11:41,  5.58it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:11 - INFO - __main__ - train loss is 4.178148320643231\n",
      "Steps:  74%|▋| 11086/15000 [1:10:49<11:40,  5.58it/s, lr=9.18e-6, step_loss=0.2407/18/2023 20:14:11 - INFO - __main__ - train loss is 4.391184947220609\n",
      "Steps:  74%|▋| 11087/15000 [1:10:49<11:40,  5.59it/s, lr=9.18e-6, step_loss=0.2107/18/2023 20:14:11 - INFO - __main__ - train loss is 4.394187631784007\n",
      "Steps:  74%|▋| 11088/15000 [1:10:49<11:39,  5.59it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:11 - INFO - __main__ - train loss is 4.597026395378634\n",
      "Steps:  74%|▋| 11089/15000 [1:10:49<11:39,  5.59it/s, lr=9.18e-6, step_loss=0.2007/18/2023 20:14:12 - INFO - __main__ - train loss is 4.601714355638251\n",
      "Steps:  74%|▋| 11090/15000 [1:10:49<11:38,  5.60it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:12 - INFO - __main__ - train loss is 4.735319686820731\n",
      "Steps:  74%|▋| 11091/15000 [1:10:50<11:38,  5.60it/s, lr=9.18e-6, step_loss=0.1307/18/2023 20:14:12 - INFO - __main__ - train loss is 4.757058543851599\n",
      "Steps:  74%|▋| 11092/15000 [1:10:50<11:38,  5.60it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:12 - INFO - __main__ - train loss is 5.046735388925299\n",
      "Steps:  74%|▋| 11093/15000 [1:10:50<11:38,  5.60it/s, lr=9.18e-6, step_loss=0.2907/18/2023 20:14:12 - INFO - __main__ - train loss is 5.059233060805127\n",
      "Steps:  74%|▋| 11094/15000 [1:10:50<11:38,  5.59it/s, lr=9.18e-6, step_loss=0.0107/18/2023 20:14:13 - INFO - __main__ - train loss is 5.230389482108876\n",
      "Steps:  74%|▋| 11095/15000 [1:10:50<11:37,  5.60it/s, lr=9.18e-6, step_loss=0.1707/18/2023 20:14:13 - INFO - __main__ - train loss is 5.279548651305959\n",
      "Steps:  74%|▋| 11096/15000 [1:10:51<11:37,  5.60it/s, lr=9.18e-6, step_loss=0.0407/18/2023 20:14:13 - INFO - __main__ - train loss is 5.355374402133748\n",
      "Steps:  74%|▋| 11097/15000 [1:10:51<11:37,  5.60it/s, lr=9.18e-6, step_loss=0.0707/18/2023 20:14:13 - INFO - __main__ - train loss is 5.474724075524136\n",
      "Steps:  74%|▋| 11098/15000 [1:10:51<11:36,  5.60it/s, lr=9.18e-6, step_loss=0.1107/18/2023 20:14:13 - INFO - __main__ - train loss is 5.4968009672593325\n",
      "Steps:  74%|▋| 11099/15000 [1:10:51<11:36,  5.60it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:13 - INFO - __main__ - train loss is 5.537655931664631\n",
      "Steps:  74%|▋| 11100/15000 [1:10:51<11:36,  5.60it/s, lr=9.18e-6, step_loss=0.0407/18/2023 20:14:14 - INFO - __main__ - train loss is 5.6871878921519965\n",
      "Steps:  74%|▋| 11101/15000 [1:10:51<11:36,  5.60it/s, lr=9.18e-6, step_loss=0.1507/18/2023 20:14:14 - INFO - __main__ - train loss is 5.912563037825748\n",
      "Steps:  74%|▋| 11102/15000 [1:10:52<11:36,  5.59it/s, lr=9.18e-6, step_loss=0.2207/18/2023 20:14:14 - INFO - __main__ - train loss is 5.956140641821548\n",
      "Steps:  74%|▋| 11103/15000 [1:10:52<11:36,  5.60it/s, lr=9.18e-6, step_loss=0.0407/18/2023 20:14:14 - INFO - __main__ - train loss is 5.963911338942125\n",
      "Steps:  74%|▋| 11104/15000 [1:10:52<11:36,  5.60it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:14 - INFO - __main__ - train loss is 5.977821049513295\n",
      "Steps:  74%|▋| 11105/15000 [1:10:52<11:38,  5.57it/s, lr=9.18e-6, step_loss=0.0107/18/2023 20:14:14 - INFO - __main__ - train loss is 6.01814113301225\n",
      "Steps:  74%|▋| 11106/15000 [1:10:52<11:43,  5.53it/s, lr=9.18e-6, step_loss=0.0407/18/2023 20:14:15 - INFO - __main__ - train loss is 6.0420274150092155\n",
      "Steps:  74%|▋| 11107/15000 [1:10:53<11:50,  5.48it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:15 - INFO - __main__ - train loss is 6.048015475040302\n",
      "Steps:  74%|▋| 11108/15000 [1:10:53<11:57,  5.42it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:15 - INFO - __main__ - train loss is 6.067657999461517\n",
      "Steps:  74%|▋| 11109/15000 [1:10:53<12:02,  5.38it/s, lr=9.18e-6, step_loss=0.0107/18/2023 20:14:15 - INFO - __main__ - train loss is 6.085258839419112\n",
      "Steps:  74%|▋| 11110/15000 [1:10:53<11:56,  5.43it/s, lr=9.18e-6, step_loss=0.0107/18/2023 20:14:15 - INFO - __main__ - train loss is 6.4308265128638595\n",
      "Steps:  74%|▋| 11111/15000 [1:10:53<11:49,  5.48it/s, lr=9.18e-6, step_loss=0.3407/18/2023 20:14:16 - INFO - __main__ - train loss is 6.5176873037125915\n",
      "Steps:  74%|▋| 11112/15000 [1:10:53<11:48,  5.49it/s, lr=9.18e-6, step_loss=0.0807/18/2023 20:14:16 - INFO - __main__ - train loss is 6.542984718224034\n",
      "Steps:  74%|▋| 11113/15000 [1:10:54<11:47,  5.50it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:16 - INFO - __main__ - train loss is 6.558583326404914\n",
      "Steps:  74%|▋| 11114/15000 [1:10:54<11:47,  5.49it/s, lr=9.18e-6, step_loss=0.0107/18/2023 20:14:16 - INFO - __main__ - train loss is 6.576699878787622\n",
      "Steps:  74%|▋| 11115/15000 [1:10:54<11:46,  5.50it/s, lr=9.18e-6, step_loss=0.0107/18/2023 20:14:16 - INFO - __main__ - train loss is 6.585953134810552\n",
      "Steps:  74%|▋| 11116/15000 [1:10:54<11:45,  5.51it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:16 - INFO - __main__ - train loss is 6.674945954000577\n",
      "Steps:  74%|▋| 11117/15000 [1:10:54<11:44,  5.51it/s, lr=9.18e-6, step_loss=0.0807/18/2023 20:14:17 - INFO - __main__ - train loss is 6.749247792875394\n",
      "Steps:  74%|▋| 11118/15000 [1:10:55<11:43,  5.52it/s, lr=9.18e-6, step_loss=0.0707/18/2023 20:14:17 - INFO - __main__ - train loss is 6.90333080640994\n",
      "Steps:  74%|▋| 11119/15000 [1:10:55<11:43,  5.52it/s, lr=9.18e-6, step_loss=0.1507/18/2023 20:14:17 - INFO - __main__ - train loss is 7.056474689161405\n",
      "Steps:  74%|▋| 11120/15000 [1:10:55<11:43,  5.52it/s, lr=9.18e-6, step_loss=0.1507/18/2023 20:14:17 - INFO - __main__ - train loss is 7.127983685350046\n",
      "Steps:  74%|▋| 11121/15000 [1:10:55<11:42,  5.52it/s, lr=9.18e-6, step_loss=0.0707/18/2023 20:14:17 - INFO - __main__ - train loss is 7.571554895257577\n",
      "Steps:  74%|▋| 11122/15000 [1:10:55<11:42,  5.52it/s, lr=9.18e-6, step_loss=0.4407/18/2023 20:14:18 - INFO - __main__ - train loss is 7.606949154054746\n",
      "Steps:  74%|▋| 11123/15000 [1:10:55<11:42,  5.52it/s, lr=9.18e-6, step_loss=0.0307/18/2023 20:14:18 - INFO - __main__ - train loss is 8.122669163858518\n",
      "Steps:  74%|▋| 11124/15000 [1:10:56<11:42,  5.52it/s, lr=9.18e-6, step_loss=0.5107/18/2023 20:14:18 - INFO - __main__ - train loss is 8.147348334779963\n",
      "Steps:  74%|▋| 11125/15000 [1:10:56<11:41,  5.52it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:18 - INFO - __main__ - train loss is 8.834826996317133\n",
      "Steps:  74%|▋| 11126/15000 [1:10:56<11:40,  5.53it/s, lr=9.18e-6, step_loss=0.6807/18/2023 20:14:18 - INFO - __main__ - train loss is 9.364003946771845\n",
      "Steps:  74%|▋| 11127/15000 [1:10:56<11:40,  5.53it/s, lr=9.18e-6, step_loss=0.5207/18/2023 20:14:18 - INFO - __main__ - train loss is 9.403659416129813\n",
      "Steps:  74%|▋| 11128/15000 [1:10:56<11:40,  5.53it/s, lr=9.18e-6, step_loss=0.0307/18/2023 20:14:19 - INFO - __main__ - train loss is 9.462237888714299\n",
      "Steps:  74%|▋| 11129/15000 [1:10:57<11:46,  5.48it/s, lr=9.18e-6, step_loss=0.0507/18/2023 20:14:19 - INFO - __main__ - train loss is 9.764605516334996\n",
      "Steps:  74%|▋| 11130/15000 [1:10:57<11:50,  5.45it/s, lr=9.18e-6, step_loss=0.3007/18/2023 20:14:19 - INFO - __main__ - train loss is 9.84235573722981\n",
      "Steps:  74%|▋| 11131/15000 [1:10:57<11:48,  5.46it/s, lr=9.18e-6, step_loss=0.0707/18/2023 20:14:19 - INFO - __main__ - train loss is 10.31213162257336\n",
      "Steps:  74%|▋| 11132/15000 [1:10:57<11:52,  5.43it/s, lr=9.18e-6, step_loss=0.4707/18/2023 20:14:19 - INFO - __main__ - train loss is 10.416346559068188\n",
      "Steps:  74%|▋| 11133/15000 [1:10:57<11:49,  5.45it/s, lr=9.18e-6, step_loss=0.1007/18/2023 20:14:20 - INFO - __main__ - train loss is 10.461279535433277\n",
      "Steps:  74%|▋| 11134/15000 [1:10:57<11:51,  5.43it/s, lr=9.18e-6, step_loss=0.0407/18/2023 20:14:20 - INFO - __main__ - train loss is 11.241370046278462\n",
      "Steps:  74%|▋| 11135/15000 [1:10:58<11:48,  5.46it/s, lr=9.18e-6, step_loss=0.7807/18/2023 20:14:20 - INFO - __main__ - train loss is 11.472651907941326\n",
      "Steps:  74%|▋| 11136/15000 [1:10:58<11:52,  5.42it/s, lr=9.18e-6, step_loss=0.2307/18/2023 20:14:20 - INFO - __main__ - train loss is 11.49395297258161\n",
      "Steps:  74%|▋| 11137/15000 [1:10:58<11:51,  5.43it/s, lr=9.18e-6, step_loss=0.0207/18/2023 20:14:20 - INFO - __main__ - train loss is 11.499001266201958\n",
      "Steps:  74%|▋| 11138/15000 [1:10:58<11:44,  5.48it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:20 - INFO - __main__ - train loss is 11.561373645206913\n",
      "Steps:  74%|▋| 11139/15000 [1:10:58<11:39,  5.52it/s, lr=9.18e-6, step_loss=0.0607/18/2023 20:14:21 - INFO - __main__ - train loss is 11.563969563925639\n",
      "Steps:  74%|▋| 11140/15000 [1:10:59<11:35,  5.55it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:21 - INFO - __main__ - train loss is 11.568344439612702\n",
      "Steps:  74%|▋| 11141/15000 [1:10:59<11:33,  5.57it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:21 - INFO - __main__ - train loss is 11.760693500982597\n",
      "Steps:  74%|▋| 11142/15000 [1:10:59<11:31,  5.58it/s, lr=9.18e-6, step_loss=0.1907/18/2023 20:14:21 - INFO - __main__ - train loss is 11.767675083363429\n",
      "Steps:  74%|▋| 11143/15000 [1:10:59<11:29,  5.59it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:21 - INFO - __main__ - train loss is 11.838538583600894\n",
      "Steps:  74%|▋| 11144/15000 [1:10:59<11:28,  5.60it/s, lr=9.18e-6, step_loss=0.0707/18/2023 20:14:22 - INFO - __main__ - train loss is 12.04173843213357\n",
      "Steps:  74%|▋| 11145/15000 [1:10:59<11:28,  5.60it/s, lr=9.18e-6, step_loss=0.2007/18/2023 20:14:22 - INFO - __main__ - train loss is 12.04442265140824\n",
      "Steps:  74%|▋| 11146/15000 [1:11:00<11:27,  5.61it/s, lr=9.18e-6, step_loss=0.0007/18/2023 20:14:22 - INFO - __main__ - train loss is 12.055223500123248\n",
      "Steps:  74%|▋| 11147/15000 [1:11:00<11:32,  5.56it/s, lr=9.17e-6, step_loss=0.0107/18/2023 20:14:22 - INFO - __main__ - train loss is 12.225948324194178\n",
      "Steps:  74%|▋| 11148/15000 [1:11:00<11:30,  5.58it/s, lr=9.17e-6, step_loss=0.1707/18/2023 20:14:22 - INFO - __main__ - train loss is 12.342137580504641\n",
      "Steps:  74%|▋| 11149/15000 [1:11:00<11:29,  5.59it/s, lr=9.17e-6, step_loss=0.1107/18/2023 20:14:22 - INFO - __main__ - train loss is 12.44201792567037\n",
      "Steps:  74%|▋| 11150/15000 [1:11:00<11:28,  5.60it/s, lr=9.17e-6, step_loss=0.0907/18/2023 20:14:23 - INFO - __main__ - train loss is 12.600759966066107\n",
      "Steps:  74%|▋| 11151/15000 [1:11:01<11:27,  5.60it/s, lr=9.17e-6, step_loss=0.1507/18/2023 20:14:23 - INFO - __main__ - train loss is 12.61279248050414\n",
      "Steps:  74%|▋| 11152/15000 [1:11:01<11:26,  5.60it/s, lr=9.17e-6, step_loss=0.0107/18/2023 20:14:23 - INFO - __main__ - train loss is 12.790280241286382\n",
      "Steps:  74%|▋| 11153/15000 [1:11:01<11:25,  5.61it/s, lr=9.17e-6, step_loss=0.1707/18/2023 20:14:23 - INFO - __main__ - train loss is 12.825765643035993\n",
      "Steps:  74%|▋| 11154/15000 [1:11:01<11:25,  5.61it/s, lr=9.17e-6, step_loss=0.0307/18/2023 20:14:24 - INFO - __main__ - train loss is 12.999439153587446\n",
      "Steps:  74%|▋| 11155/15000 [1:11:01<15:21,  4.17it/s, lr=9.17e-6, step_loss=0.1707/18/2023 20:14:24 - INFO - __main__ - Per validation step average loss is 0.10540491342544556\n",
      "07/18/2023 20:14:24 - INFO - __main__ - Cumulative validation average loss is 0.10540491342544556\n",
      "07/18/2023 20:14:24 - INFO - __main__ - Per validation step average loss is 0.06530442088842392\n",
      "07/18/2023 20:14:24 - INFO - __main__ - Cumulative validation average loss is 0.17070933431386948\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Per validation step average loss is 0.008395103737711906\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Cumulative validation average loss is 0.17910443805158138\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Per validation step average loss is 0.18681442737579346\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Cumulative validation average loss is 0.36591886542737484\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Per validation step average loss is 0.0014997849939391017\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Cumulative validation average loss is 0.36741865042131394\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Per validation step average loss is 0.2662509083747864\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Cumulative validation average loss is 0.6336695587961003\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Per validation step average loss is 0.1600629985332489\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Cumulative validation average loss is 0.7937325573293492\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Per validation step average loss is 0.1256641447544098\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Cumulative validation average loss is 0.919396702083759\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Per validation step average loss is 0.020758915692567825\n",
      "07/18/2023 20:14:25 - INFO - __main__ - Cumulative validation average loss is 0.9401556177763268\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Per validation step average loss is 0.20090067386627197\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Cumulative validation average loss is 1.1410562916425988\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Per validation step average loss is 0.023837510496377945\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Cumulative validation average loss is 1.1648938021389768\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Per validation step average loss is 0.23710572719573975\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Cumulative validation average loss is 1.4019995293347165\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Average validation loss for Epoch 114 is 0.11683329411122638\n",
      "07/18/2023 20:14:26 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:14:39 - INFO - __main__ - Starting epoch 115\n",
      "07/18/2023 20:14:39 - INFO - __main__ - train loss is 0.008663571439683437\n",
      "Steps:  74%|▋| 11156/15000 [1:11:17<5:14:27,  4.91s/it, lr=9.17e-6, step_loss=0.07/18/2023 20:14:40 - INFO - __main__ - train loss is 0.012168692890554667\n",
      "Steps:  74%|▋| 11157/15000 [1:11:17<3:43:30,  3.49s/it, lr=9.17e-6, step_loss=0.07/18/2023 20:14:40 - INFO - __main__ - train loss is 0.014926752774044871\n",
      "Steps:  74%|▋| 11158/15000 [1:11:18<2:39:50,  2.50s/it, lr=9.17e-6, step_loss=0.07/18/2023 20:14:40 - INFO - __main__ - train loss is 0.03701404365710914\n",
      "Steps:  74%|▋| 11159/15000 [1:11:18<1:55:17,  1.80s/it, lr=9.17e-6, step_loss=0.07/18/2023 20:14:40 - INFO - __main__ - train loss is 0.060517924604937434\n",
      "Steps:  74%|▋| 11160/15000 [1:11:18<1:24:09,  1.32s/it, lr=9.17e-6, step_loss=0.07/18/2023 20:14:40 - INFO - __main__ - train loss is 0.09453608351759613\n",
      "Steps:  74%|▋| 11161/15000 [1:11:18<1:02:19,  1.03it/s, lr=9.17e-6, step_loss=0.07/18/2023 20:14:40 - INFO - __main__ - train loss is 0.4930070515256375\n",
      "Steps:  74%|▋| 11162/15000 [1:11:18<47:03,  1.36it/s, lr=9.17e-6, step_loss=0.3907/18/2023 20:14:41 - INFO - __main__ - train loss is 0.9315073366742581\n",
      "Steps:  74%|▋| 11163/15000 [1:11:18<36:21,  1.76it/s, lr=9.17e-6, step_loss=0.4307/18/2023 20:14:41 - INFO - __main__ - train loss is 1.0796955998521298\n",
      "Steps:  74%|▋| 11164/15000 [1:11:19<28:51,  2.21it/s, lr=9.17e-6, step_loss=0.1407/18/2023 20:14:41 - INFO - __main__ - train loss is 1.083406925899908\n",
      "Steps:  74%|▋| 11165/15000 [1:11:19<23:37,  2.71it/s, lr=9.17e-6, step_loss=0.0007/18/2023 20:14:41 - INFO - __main__ - train loss is 1.0849287984892726\n",
      "Steps:  74%|▋| 11166/15000 [1:11:19<19:57,  3.20it/s, lr=9.17e-6, step_loss=0.0007/18/2023 20:14:41 - INFO - __main__ - train loss is 1.4774244306609035\n",
      "Steps:  74%|▋| 11167/15000 [1:11:19<17:23,  3.67it/s, lr=9.17e-6, step_loss=0.3907/18/2023 20:14:42 - INFO - __main__ - train loss is 1.4795251463074237\n",
      "Steps:  74%|▋| 11168/15000 [1:11:19<15:44,  4.06it/s, lr=9.17e-6, step_loss=0.0007/18/2023 20:14:42 - INFO - __main__ - train loss is 1.526461036177352\n",
      "Steps:  74%|▋| 11169/15000 [1:11:20<14:46,  4.32it/s, lr=9.17e-6, step_loss=0.0407/18/2023 20:14:42 - INFO - __main__ - train loss is 1.5520403508562595\n",
      "Steps:  74%|▋| 11170/15000 [1:11:20<13:56,  4.58it/s, lr=9.17e-6, step_loss=0.0207/18/2023 20:14:42 - INFO - __main__ - train loss is 1.8532917324919254\n",
      "Steps:  74%|▋| 11171/15000 [1:11:20<13:27,  4.74it/s, lr=9.17e-6, step_loss=0.3007/18/2023 20:14:42 - INFO - __main__ - train loss is 1.8972451176960021\n",
      "Steps:  74%|▋| 11172/15000 [1:11:20<13:08,  4.85it/s, lr=9.17e-6, step_loss=0.0407/18/2023 20:14:42 - INFO - __main__ - train loss is 1.9280557178426534\n",
      "Steps:  74%|▋| 11173/15000 [1:11:20<12:55,  4.94it/s, lr=9.17e-6, step_loss=0.0307/18/2023 20:14:43 - INFO - __main__ - train loss is 2.069451465504244\n",
      "Steps:  74%|▋| 11174/15000 [1:11:21<12:46,  4.99it/s, lr=9.17e-6, step_loss=0.1407/18/2023 20:14:43 - INFO - __main__ - train loss is 2.093683968530968\n",
      "Steps:  74%|▋| 11175/15000 [1:11:21<12:38,  5.04it/s, lr=9.17e-6, step_loss=0.0207/18/2023 20:14:43 - INFO - __main__ - train loss is 2.159287388669327\n",
      "Steps:  75%|▋| 11176/15000 [1:11:21<12:34,  5.07it/s, lr=9.17e-6, step_loss=0.0607/18/2023 20:14:43 - INFO - __main__ - train loss is 2.1648537206929177\n",
      "Steps:  75%|▋| 11177/15000 [1:11:21<12:31,  5.09it/s, lr=9.17e-6, step_loss=0.0007/18/2023 20:14:43 - INFO - __main__ - train loss is 2.531765340594575\n",
      "Steps:  75%|▋| 11178/15000 [1:11:21<12:28,  5.10it/s, lr=9.17e-6, step_loss=0.3607/18/2023 20:14:44 - INFO - __main__ - train loss is 2.684260143665597\n",
      "Steps:  75%|▋| 11179/15000 [1:11:22<12:28,  5.10it/s, lr=9.17e-6, step_loss=0.1507/18/2023 20:14:44 - INFO - __main__ - train loss is 2.7153870936017483\n",
      "Steps:  75%|▋| 11180/15000 [1:11:22<12:27,  5.11it/s, lr=9.17e-6, step_loss=0.0307/18/2023 20:14:44 - INFO - __main__ - train loss is 2.7360754671972245\n",
      "Steps:  75%|▋| 11181/15000 [1:11:22<12:25,  5.12it/s, lr=9.17e-6, step_loss=0.0207/18/2023 20:14:44 - INFO - __main__ - train loss is 3.0210682216566056\n",
      "Steps:  75%|▋| 11182/15000 [1:11:22<12:25,  5.12it/s, lr=9.17e-6, step_loss=0.2807/18/2023 20:14:44 - INFO - __main__ - train loss is 3.0425921890418977\n",
      "Steps:  75%|▋| 11183/15000 [1:11:22<12:24,  5.12it/s, lr=9.17e-6, step_loss=0.0207/18/2023 20:14:45 - INFO - __main__ - train loss is 3.0608944471459836\n",
      "Steps:  75%|▋| 11184/15000 [1:11:23<12:23,  5.13it/s, lr=9.17e-6, step_loss=0.0107/18/2023 20:14:45 - INFO - __main__ - train loss is 3.0783535304944962\n",
      "Steps:  75%|▋| 11185/15000 [1:11:23<12:22,  5.13it/s, lr=9.17e-6, step_loss=0.0107/18/2023 20:14:45 - INFO - __main__ - train loss is 3.1387406166177243\n",
      "Steps:  75%|▋| 11186/15000 [1:11:23<12:22,  5.14it/s, lr=9.17e-6, step_loss=0.0607/18/2023 20:14:45 - INFO - __main__ - train loss is 3.2540529693942517\n",
      "Steps:  75%|▋| 11187/15000 [1:11:23<12:22,  5.13it/s, lr=9.17e-6, step_loss=0.1107/18/2023 20:14:45 - INFO - __main__ - train loss is 3.292509476421401\n",
      "Steps:  75%|▋| 11188/15000 [1:11:23<12:22,  5.13it/s, lr=9.17e-6, step_loss=0.0307/18/2023 20:14:46 - INFO - __main__ - train loss is 3.3062259207945317\n",
      "Steps:  75%|▋| 11189/15000 [1:11:23<12:21,  5.14it/s, lr=9.17e-6, step_loss=0.0107/18/2023 20:14:46 - INFO - __main__ - train loss is 3.3701123993378133\n",
      "Steps:  75%|▋| 11190/15000 [1:11:24<12:21,  5.14it/s, lr=9.17e-6, step_loss=0.0607/18/2023 20:14:46 - INFO - __main__ - train loss is 3.4057562972884625\n",
      "Steps:  75%|▋| 11191/15000 [1:11:24<12:22,  5.13it/s, lr=9.17e-6, step_loss=0.0307/18/2023 20:14:46 - INFO - __main__ - train loss is 3.4234605121891946\n",
      "Steps:  75%|▋| 11192/15000 [1:11:24<12:22,  5.13it/s, lr=9.17e-6, step_loss=0.0107/18/2023 20:14:46 - INFO - __main__ - train loss is 3.7486306715290993\n",
      "Steps:  75%|▋| 11193/15000 [1:11:24<12:22,  5.13it/s, lr=9.17e-6, step_loss=0.3207/18/2023 20:14:47 - INFO - __main__ - train loss is 4.048342912225053\n",
      "Steps:  75%|▋| 11194/15000 [1:11:24<12:25,  5.10it/s, lr=9.17e-6, step_loss=0.3]07/18/2023 20:14:47 - INFO - __main__ - train loss is 4.051337990676984\n",
      "Steps:  75%|▋| 11195/15000 [1:11:25<12:24,  5.11it/s, lr=9.17e-6, step_loss=0.0007/18/2023 20:14:47 - INFO - __main__ - train loss is 4.1073037011083215\n",
      "Steps:  75%|▋| 11196/15000 [1:11:25<12:26,  5.09it/s, lr=9.17e-6, step_loss=0.0507/18/2023 20:14:47 - INFO - __main__ - train loss is 4.630914650624618\n",
      "Steps:  75%|▋| 11197/15000 [1:11:25<12:24,  5.10it/s, lr=9.17e-6, step_loss=0.5207/18/2023 20:14:47 - INFO - __main__ - train loss is 4.985214493935928\n",
      "Steps:  75%|▋| 11198/15000 [1:11:25<12:23,  5.11it/s, lr=9.17e-6, step_loss=0.3507/18/2023 20:14:48 - INFO - __main__ - train loss is 5.248431764310226\n",
      "Steps:  75%|▋| 11199/15000 [1:11:25<12:22,  5.12it/s, lr=9.17e-6, step_loss=0.2607/18/2023 20:14:48 - INFO - __main__ - train loss is 5.32985284156166\n",
      "Steps:  75%|▋| 11200/15000 [1:11:26<12:14,  5.17it/s, lr=9.17e-6, step_loss=0.0807/18/2023 20:14:48 - INFO - __main__ - train loss is 5.353112362092361\n",
      "Steps:  75%|▋| 11201/15000 [1:11:26<12:07,  5.22it/s, lr=9.17e-6, step_loss=0.0207/18/2023 20:14:48 - INFO - __main__ - train loss is 5.5871081573423\n",
      "Steps:  75%|▋| 11202/15000 [1:11:26<12:10,  5.20it/s, lr=9.17e-6, step_loss=0.2307/18/2023 20:14:48 - INFO - __main__ - train loss is 5.7965787870343775\n",
      "Steps:  75%|▋| 11203/15000 [1:11:26<12:14,  5.17it/s, lr=9.17e-6, step_loss=0.2007/18/2023 20:14:49 - INFO - __main__ - train loss is 5.803139930823818\n",
      "Steps:  75%|▋| 11204/15000 [1:11:26<12:16,  5.15it/s, lr=9.17e-6, step_loss=0.0007/18/2023 20:14:49 - INFO - __main__ - train loss is 6.5556204377207905\n",
      "Steps:  75%|▋| 11205/15000 [1:11:27<12:17,  5.14it/s, lr=9.17e-6, step_loss=0.7507/18/2023 20:14:49 - INFO - __main__ - train loss is 6.6102189442608505\n",
      "Steps:  75%|▋| 11206/15000 [1:11:27<12:17,  5.15it/s, lr=9.17e-6, step_loss=0.0507/18/2023 20:14:49 - INFO - __main__ - train loss is 6.795306714484468\n",
      "Steps:  75%|▋| 11207/15000 [1:11:27<12:17,  5.14it/s, lr=9.17e-6, step_loss=0.1807/18/2023 20:14:49 - INFO - __main__ - train loss is 6.962248297641054\n",
      "Steps:  75%|▋| 11208/15000 [1:11:27<12:16,  5.15it/s, lr=9.17e-6, step_loss=0.1607/18/2023 20:14:49 - INFO - __main__ - train loss is 7.264828594634309\n",
      "Steps:  75%|▋| 11209/15000 [1:11:27<12:16,  5.15it/s, lr=9.17e-6, step_loss=0.3007/18/2023 20:14:50 - INFO - __main__ - train loss is 7.270069073187187\n",
      "Steps:  75%|▋| 11210/15000 [1:11:28<12:17,  5.14it/s, lr=9.17e-6, step_loss=0.0007/18/2023 20:14:50 - INFO - __main__ - train loss is 7.820456217275932\n",
      "Steps:  75%|▋| 11211/15000 [1:11:28<12:19,  5.12it/s, lr=9.17e-6, step_loss=0.5507/18/2023 20:14:50 - INFO - __main__ - train loss is 7.953373487340286\n",
      "Steps:  75%|▋| 11212/15000 [1:11:28<12:19,  5.12it/s, lr=9.17e-6, step_loss=0.1307/18/2023 20:14:50 - INFO - __main__ - train loss is 8.317939157830551\n",
      "Steps:  75%|▋| 11213/15000 [1:11:28<12:19,  5.12it/s, lr=9.17e-6, step_loss=0.3607/18/2023 20:14:50 - INFO - __main__ - train loss is 8.35454025794752\n",
      "Steps:  75%|▋| 11214/15000 [1:11:28<12:08,  5.20it/s, lr=9.17e-6, step_loss=0.0307/18/2023 20:14:51 - INFO - __main__ - train loss is 8.527731224196032\n",
      "Steps:  75%|▋| 11215/15000 [1:11:29<11:57,  5.28it/s, lr=9.17e-6, step_loss=0.1707/18/2023 20:14:51 - INFO - __main__ - train loss is 8.671387418406084\n",
      "Steps:  75%|▋| 11216/15000 [1:11:29<11:45,  5.37it/s, lr=9.16e-6, step_loss=0.1407/18/2023 20:14:51 - INFO - __main__ - train loss is 8.709149762289599\n",
      "Steps:  75%|▋| 11217/15000 [1:11:29<11:36,  5.43it/s, lr=9.16e-6, step_loss=0.0307/18/2023 20:14:51 - INFO - __main__ - train loss is 8.849667473929003\n",
      "Steps:  75%|▋| 11218/15000 [1:11:29<11:30,  5.48it/s, lr=9.16e-6, step_loss=0.1407/18/2023 20:14:51 - INFO - __main__ - train loss is 9.167362108128145\n",
      "Steps:  75%|▋| 11219/15000 [1:11:29<11:26,  5.51it/s, lr=9.16e-6, step_loss=0.3107/18/2023 20:14:52 - INFO - __main__ - train loss is 9.178627736167982\n",
      "Steps:  75%|▋| 11220/15000 [1:11:29<11:23,  5.53it/s, lr=9.16e-6, step_loss=0.0107/18/2023 20:14:52 - INFO - __main__ - train loss is 9.22246267576702\n",
      "Steps:  75%|▋| 11221/15000 [1:11:30<11:20,  5.55it/s, lr=9.16e-6, step_loss=0.0407/18/2023 20:14:52 - INFO - __main__ - train loss is 9.651496968464926\n",
      "Steps:  75%|▋| 11222/15000 [1:11:30<11:18,  5.57it/s, lr=9.16e-6, step_loss=0.4207/18/2023 20:14:52 - INFO - __main__ - train loss is 9.752789824502543\n",
      "Steps:  75%|▋| 11223/15000 [1:11:30<11:17,  5.57it/s, lr=9.16e-6, step_loss=0.1007/18/2023 20:14:52 - INFO - __main__ - train loss is 9.756330845644698\n",
      "Steps:  75%|▋| 11224/15000 [1:11:30<11:16,  5.58it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:52 - INFO - __main__ - train loss is 9.813773972680792\n",
      "Steps:  75%|▋| 11225/15000 [1:11:30<11:16,  5.58it/s, lr=9.16e-6, step_loss=0.0507/18/2023 20:14:53 - INFO - __main__ - train loss is 9.828552016755566\n",
      "Steps:  75%|▋| 11226/15000 [1:11:30<11:15,  5.58it/s, lr=9.16e-6, step_loss=0.0107/18/2023 20:14:53 - INFO - __main__ - train loss is 9.834468624321744\n",
      "Steps:  75%|▋| 11227/15000 [1:11:31<12:00,  5.24it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:53 - INFO - __main__ - train loss is 9.907294294564053\n",
      "Steps:  75%|▋| 11228/15000 [1:11:31<12:29,  5.03it/s, lr=9.16e-6, step_loss=0.0707/18/2023 20:14:53 - INFO - __main__ - train loss is 10.229494294850156\n",
      "Steps:  75%|▋| 11229/15000 [1:11:31<12:20,  5.09it/s, lr=9.16e-6, step_loss=0.3207/18/2023 20:14:53 - INFO - __main__ - train loss is 10.262935812352225\n",
      "Steps:  75%|▋| 11230/15000 [1:11:31<12:09,  5.16it/s, lr=9.16e-6, step_loss=0.0307/18/2023 20:14:54 - INFO - __main__ - train loss is 10.411830420373008\n",
      "Steps:  75%|▋| 11231/15000 [1:11:31<11:59,  5.24it/s, lr=9.16e-6, step_loss=0.1407/18/2023 20:14:54 - INFO - __main__ - train loss is 10.414362951880321\n",
      "Steps:  75%|▋| 11232/15000 [1:11:32<11:52,  5.29it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:54 - INFO - __main__ - train loss is 10.542401805287227\n",
      "Steps:  75%|▋| 11233/15000 [1:11:32<11:44,  5.35it/s, lr=9.16e-6, step_loss=0.1207/18/2023 20:14:54 - INFO - __main__ - train loss is 10.637016601627693\n",
      "Steps:  75%|▋| 11234/15000 [1:11:32<11:38,  5.39it/s, lr=9.16e-6, step_loss=0.0907/18/2023 20:14:54 - INFO - __main__ - train loss is 10.651190170785412\n",
      "Steps:  75%|▋| 11235/15000 [1:11:32<11:33,  5.43it/s, lr=9.16e-6, step_loss=0.0107/18/2023 20:14:55 - INFO - __main__ - train loss is 10.7841086180415\n",
      "Steps:  75%|▋| 11236/15000 [1:11:32<11:33,  5.43it/s, lr=9.16e-6, step_loss=0.1307/18/2023 20:14:55 - INFO - __main__ - train loss is 10.818801501533017\n",
      "Steps:  75%|▋| 11237/15000 [1:11:33<11:31,  5.44it/s, lr=9.16e-6, step_loss=0.0307/18/2023 20:14:55 - INFO - __main__ - train loss is 10.821713659679517\n",
      "Steps:  75%|▋| 11238/15000 [1:11:33<11:25,  5.49it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:55 - INFO - __main__ - train loss is 11.02004187158309\n",
      "Steps:  75%|▋| 11239/15000 [1:11:33<11:21,  5.52it/s, lr=9.16e-6, step_loss=0.1907/18/2023 20:14:55 - INFO - __main__ - train loss is 11.067383143818006\n",
      "Steps:  75%|▋| 11240/15000 [1:11:33<11:17,  5.55it/s, lr=9.16e-6, step_loss=0.0407/18/2023 20:14:55 - INFO - __main__ - train loss is 11.09031076892279\n",
      "Steps:  75%|▋| 11241/15000 [1:11:33<11:15,  5.56it/s, lr=9.16e-6, step_loss=0.0207/18/2023 20:14:56 - INFO - __main__ - train loss is 11.091893682954833\n",
      "Steps:  75%|▋| 11242/15000 [1:11:33<11:15,  5.56it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:56 - INFO - __main__ - train loss is 11.10529340035282\n",
      "Steps:  75%|▋| 11243/15000 [1:11:34<11:14,  5.57it/s, lr=9.16e-6, step_loss=0.0107/18/2023 20:14:56 - INFO - __main__ - train loss is 11.106731217121705\n",
      "Steps:  75%|▋| 11244/15000 [1:11:34<11:14,  5.57it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:56 - INFO - __main__ - train loss is 11.363244335865602\n",
      "Steps:  75%|▋| 11245/15000 [1:11:34<11:13,  5.58it/s, lr=9.16e-6, step_loss=0.2507/18/2023 20:14:56 - INFO - __main__ - train loss is 11.722217421745881\n",
      "Steps:  75%|▋| 11246/15000 [1:11:34<11:12,  5.58it/s, lr=9.16e-6, step_loss=0.3507/18/2023 20:14:56 - INFO - __main__ - train loss is 11.730016007786617\n",
      "Steps:  75%|▋| 11247/15000 [1:11:34<11:11,  5.58it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:57 - INFO - __main__ - train loss is 11.743649679934606\n",
      "Steps:  75%|▋| 11248/15000 [1:11:35<11:11,  5.59it/s, lr=9.16e-6, step_loss=0.0107/18/2023 20:14:57 - INFO - __main__ - train loss is 11.82955340645276\n",
      "Steps:  75%|▋| 11249/15000 [1:11:35<11:16,  5.54it/s, lr=9.16e-6, step_loss=0.0807/18/2023 20:14:57 - INFO - __main__ - train loss is 11.833217990817502\n",
      "Steps:  75%|▊| 11250/15000 [1:11:35<11:21,  5.50it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:14:57 - INFO - __main__ - train loss is 11.850507139461115\n",
      "Steps:  75%|▊| 11251/15000 [1:11:35<11:20,  5.51it/s, lr=9.16e-6, step_loss=0.0107/18/2023 20:14:58 - INFO - __main__ - train loss is 12.560871242778376\n",
      "Steps:  75%|▊| 11252/15000 [1:11:35<15:13,  4.10it/s, lr=9.16e-6, step_loss=0.7107/18/2023 20:14:58 - INFO - __main__ - Per validation step average loss is 0.08208124339580536\n",
      "07/18/2023 20:14:58 - INFO - __main__ - Cumulative validation average loss is 0.08208124339580536\n",
      "07/18/2023 20:14:58 - INFO - __main__ - Per validation step average loss is 0.03265833854675293\n",
      "07/18/2023 20:14:58 - INFO - __main__ - Cumulative validation average loss is 0.11473958194255829\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Per validation step average loss is 0.161863774061203\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Cumulative validation average loss is 0.2766033560037613\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Per validation step average loss is 0.003134564496576786\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Cumulative validation average loss is 0.2797379205003381\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Per validation step average loss is 0.3419261872768402\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Cumulative validation average loss is 0.6216641077771783\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Per validation step average loss is 0.43472403287887573\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Cumulative validation average loss is 1.056388140656054\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Per validation step average loss is 0.14882203936576843\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Cumulative validation average loss is 1.2052101800218225\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Per validation step average loss is 0.1775934398174286\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Cumulative validation average loss is 1.382803619839251\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Per validation step average loss is 0.08866555988788605\n",
      "07/18/2023 20:14:59 - INFO - __main__ - Cumulative validation average loss is 1.471469179727137\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Per validation step average loss is 0.03019854798913002\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Cumulative validation average loss is 1.501667727716267\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Per validation step average loss is 0.04445040598511696\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Cumulative validation average loss is 1.546118133701384\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Per validation step average loss is 0.17603963613510132\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Cumulative validation average loss is 1.7221577698364854\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Average validation loss for Epoch 115 is 0.14351314748637378\n",
      "07/18/2023 20:15:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:15:13 - INFO - __main__ - Starting epoch 116\n",
      "07/18/2023 20:15:13 - INFO - __main__ - train loss is 0.11096455156803131\n",
      "Steps:  75%|▊| 11253/15000 [1:11:51<5:06:34,  4.91s/it, lr=9.16e-6, step_loss=0.07/18/2023 20:15:14 - INFO - __main__ - train loss is 0.22786271572113037\n",
      "Steps:  75%|▊| 11254/15000 [1:11:51<3:37:53,  3.49s/it, lr=9.16e-6, step_loss=0.07/18/2023 20:15:14 - INFO - __main__ - train loss is 0.4215441197156906\n",
      "Steps:  75%|▊| 11255/15000 [1:11:52<2:35:51,  2.50s/it, lr=9.16e-6, step_loss=0.07/18/2023 20:15:14 - INFO - __main__ - train loss is 0.4237593363504857\n",
      "Steps:  75%|▊| 11256/15000 [1:11:52<1:52:24,  1.80s/it, lr=9.16e-6, step_loss=0.07/18/2023 20:15:14 - INFO - __main__ - train loss is 0.9866721581202\n",
      "Steps:  75%|▊| 11257/15000 [1:11:52<1:22:04,  1.32s/it, lr=9.16e-6, step_loss=0.07/18/2023 20:15:14 - INFO - __main__ - train loss is 1.0536077942233533\n",
      "Steps:  75%|▊| 11258/15000 [1:11:52<1:00:53,  1.02it/s, lr=9.16e-6, step_loss=0.07/18/2023 20:15:14 - INFO - __main__ - train loss is 1.0632183279376477\n",
      "Steps:  75%|▊| 11259/15000 [1:11:52<45:59,  1.36it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:15:15 - INFO - __main__ - train loss is 1.1892199243884534\n",
      "Steps:  75%|▊| 11260/15000 [1:11:53<35:31,  1.75it/s, lr=9.16e-6, step_loss=0.1207/18/2023 20:15:15 - INFO - __main__ - train loss is 1.7150283779483289\n",
      "Steps:  75%|▊| 11261/15000 [1:11:53<28:11,  2.21it/s, lr=9.16e-6, step_loss=0.5207/18/2023 20:15:15 - INFO - __main__ - train loss is 1.8717200483661145\n",
      "Steps:  75%|▊| 11262/15000 [1:11:53<23:03,  2.70it/s, lr=9.16e-6, step_loss=0.1507/18/2023 20:15:15 - INFO - __main__ - train loss is 2.128545793471858\n",
      "Steps:  75%|▊| 11263/15000 [1:11:53<19:28,  3.20it/s, lr=9.16e-6, step_loss=0.2507/18/2023 20:15:15 - INFO - __main__ - train loss is 2.1815908278804272\n",
      "Steps:  75%|▊| 11264/15000 [1:11:53<16:58,  3.67it/s, lr=9.16e-6, step_loss=0.0507/18/2023 20:15:16 - INFO - __main__ - train loss is 2.3640898193698376\n",
      "Steps:  75%|▊| 11265/15000 [1:11:53<15:11,  4.10it/s, lr=9.16e-6, step_loss=0.1807/18/2023 20:15:16 - INFO - __main__ - train loss is 2.5629298116546124\n",
      "Steps:  75%|▊| 11266/15000 [1:11:54<13:58,  4.45it/s, lr=9.16e-6, step_loss=0.1907/18/2023 20:15:16 - INFO - __main__ - train loss is 2.6942835475783795\n",
      "Steps:  75%|▊| 11267/15000 [1:11:54<13:06,  4.75it/s, lr=9.16e-6, step_loss=0.1307/18/2023 20:15:16 - INFO - __main__ - train loss is 2.8815224941354245\n",
      "Steps:  75%|▊| 11268/15000 [1:11:54<12:30,  4.97it/s, lr=9.16e-6, step_loss=0.1807/18/2023 20:15:16 - INFO - __main__ - train loss is 3.1585247989278287\n",
      "Steps:  75%|▊| 11269/15000 [1:11:54<12:04,  5.15it/s, lr=9.16e-6, step_loss=0.2707/18/2023 20:15:16 - INFO - __main__ - train loss is 3.3731578912120312\n",
      "Steps:  75%|▊| 11270/15000 [1:11:54<11:47,  5.27it/s, lr=9.16e-6, step_loss=0.2107/18/2023 20:15:17 - INFO - __main__ - train loss is 3.422986204503104\n",
      "Steps:  75%|▊| 11271/15000 [1:11:55<11:35,  5.36it/s, lr=9.16e-6, step_loss=0.0407/18/2023 20:15:17 - INFO - __main__ - train loss is 3.493890682933852\n",
      "Steps:  75%|▊| 11272/15000 [1:11:55<11:26,  5.43it/s, lr=9.16e-6, step_loss=0.0707/18/2023 20:15:17 - INFO - __main__ - train loss is 3.5362420852761716\n",
      "Steps:  75%|▊| 11273/15000 [1:11:55<11:27,  5.42it/s, lr=9.16e-6, step_loss=0.0407/18/2023 20:15:17 - INFO - __main__ - train loss is 4.125560122309253\n",
      "Steps:  75%|▊| 11274/15000 [1:11:55<11:32,  5.38it/s, lr=9.16e-6, step_loss=0.5807/18/2023 20:15:17 - INFO - __main__ - train loss is 4.526267069159076\n",
      "Steps:  75%|▊| 11275/15000 [1:11:55<11:30,  5.39it/s, lr=9.16e-6, step_loss=0.4007/18/2023 20:15:18 - INFO - __main__ - train loss is 4.70275359111838\n",
      "Steps:  75%|▊| 11276/15000 [1:11:55<11:29,  5.40it/s, lr=9.16e-6, step_loss=0.1707/18/2023 20:15:18 - INFO - __main__ - train loss is 5.367833602009341\n",
      "Steps:  75%|▊| 11277/15000 [1:11:56<11:28,  5.41it/s, lr=9.16e-6, step_loss=0.6607/18/2023 20:15:18 - INFO - __main__ - train loss is 5.369332676986232\n",
      "Steps:  75%|▊| 11278/15000 [1:11:56<11:23,  5.45it/s, lr=9.16e-6, step_loss=0.0007/18/2023 20:15:18 - INFO - __main__ - train loss is 5.520587077597156\n",
      "Steps:  75%|▊| 11279/15000 [1:11:56<11:17,  5.49it/s, lr=9.16e-6, step_loss=0.1507/18/2023 20:15:18 - INFO - __main__ - train loss is 5.706386050442234\n",
      "Steps:  75%|▊| 11280/15000 [1:11:56<11:13,  5.52it/s, lr=9.16e-6, step_loss=0.1807/18/2023 20:15:18 - INFO - __main__ - train loss is 5.728880297625437\n",
      "Steps:  75%|▊| 11281/15000 [1:11:56<11:11,  5.54it/s, lr=9.16e-6, step_loss=0.0207/18/2023 20:15:19 - INFO - __main__ - train loss is 5.750415589893237\n",
      "Steps:  75%|▊| 11282/15000 [1:11:57<11:09,  5.55it/s, lr=9.16e-6, step_loss=0.0207/18/2023 20:15:19 - INFO - __main__ - train loss is 5.94105139025487\n",
      "Steps:  75%|▊| 11283/15000 [1:11:57<11:07,  5.57it/s, lr=9.16e-6, step_loss=0.1907/18/2023 20:15:19 - INFO - __main__ - train loss is 6.391399886691943\n",
      "Steps:  75%|▊| 11284/15000 [1:11:57<11:06,  5.57it/s, lr=9.16e-6, step_loss=0.4507/18/2023 20:15:19 - INFO - __main__ - train loss is 7.057930376613513\n",
      "Steps:  75%|▊| 11285/15000 [1:11:57<11:06,  5.57it/s, lr=9.15e-6, step_loss=0.6607/18/2023 20:15:19 - INFO - __main__ - train loss is 7.06117812753655\n",
      "Steps:  75%|▊| 11286/15000 [1:11:57<11:05,  5.58it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:20 - INFO - __main__ - train loss is 7.092221971834078\n",
      "Steps:  75%|▊| 11287/15000 [1:11:57<11:04,  5.58it/s, lr=9.15e-6, step_loss=0.0307/18/2023 20:15:20 - INFO - __main__ - train loss is 7.108101029181853\n",
      "Steps:  75%|▊| 11288/15000 [1:11:58<11:04,  5.58it/s, lr=9.15e-6, step_loss=0.0107/18/2023 20:15:20 - INFO - __main__ - train loss is 7.111989119788632\n",
      "Steps:  75%|▊| 11289/15000 [1:11:58<11:04,  5.59it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:20 - INFO - __main__ - train loss is 7.444637635489926\n",
      "Steps:  75%|▊| 11290/15000 [1:11:58<11:03,  5.59it/s, lr=9.15e-6, step_loss=0.3307/18/2023 20:15:20 - INFO - __main__ - train loss is 7.7370435984339565\n",
      "Steps:  75%|▊| 11291/15000 [1:11:58<11:03,  5.59it/s, lr=9.15e-6, step_loss=0.2907/18/2023 20:15:20 - INFO - __main__ - train loss is 7.844069385668263\n",
      "Steps:  75%|▊| 11292/15000 [1:11:58<11:07,  5.55it/s, lr=9.15e-6, step_loss=0.1007/18/2023 20:15:21 - INFO - __main__ - train loss is 8.077823186060414\n",
      "Steps:  75%|▊| 11293/15000 [1:11:58<11:05,  5.57it/s, lr=9.15e-6, step_loss=0.2307/18/2023 20:15:21 - INFO - __main__ - train loss is 8.498577499529347\n",
      "Steps:  75%|▊| 11294/15000 [1:11:59<11:04,  5.58it/s, lr=9.15e-6, step_loss=0.4207/18/2023 20:15:21 - INFO - __main__ - train loss is 8.571549387415871\n",
      "Steps:  75%|▊| 11295/15000 [1:11:59<11:03,  5.59it/s, lr=9.15e-6, step_loss=0.0707/18/2023 20:15:21 - INFO - __main__ - train loss is 8.735874207457528\n",
      "Steps:  75%|▊| 11296/15000 [1:11:59<11:02,  5.59it/s, lr=9.15e-6, step_loss=0.1607/18/2023 20:15:21 - INFO - __main__ - train loss is 8.799129733582959\n",
      "Steps:  75%|▊| 11297/15000 [1:11:59<11:01,  5.59it/s, lr=9.15e-6, step_loss=0.0607/18/2023 20:15:21 - INFO - __main__ - train loss is 8.815683105727658\n",
      "Steps:  75%|▊| 11298/15000 [1:11:59<11:01,  5.60it/s, lr=9.15e-6, step_loss=0.0107/18/2023 20:15:22 - INFO - __main__ - train loss is 8.926883617183194\n",
      "Steps:  75%|▊| 11299/15000 [1:12:00<11:01,  5.60it/s, lr=9.15e-6, step_loss=0.1107/18/2023 20:15:22 - INFO - __main__ - train loss is 8.96246618940495\n",
      "Steps:  75%|▊| 11300/15000 [1:12:00<11:00,  5.60it/s, lr=9.15e-6, step_loss=0.0307/18/2023 20:15:22 - INFO - __main__ - train loss is 8.966235408326611\n",
      "Steps:  75%|▊| 11301/15000 [1:12:00<11:00,  5.60it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:22 - INFO - __main__ - train loss is 9.010156055679545\n",
      "Steps:  75%|▊| 11302/15000 [1:12:00<11:00,  5.60it/s, lr=9.15e-6, step_loss=0.0407/18/2023 20:15:22 - INFO - __main__ - train loss is 9.075168205192313\n",
      "Steps:  75%|▊| 11303/15000 [1:12:00<10:59,  5.60it/s, lr=9.15e-6, step_loss=0.0607/18/2023 20:15:23 - INFO - __main__ - train loss is 9.357348872115836\n",
      "Steps:  75%|▊| 11304/15000 [1:12:00<10:59,  5.60it/s, lr=9.15e-6, step_loss=0.2807/18/2023 20:15:23 - INFO - __main__ - train loss is 9.655153197934851\n",
      "Steps:  75%|▊| 11305/15000 [1:12:01<10:59,  5.60it/s, lr=9.15e-6, step_loss=0.2907/18/2023 20:15:23 - INFO - __main__ - train loss is 10.071160269668326\n",
      "Steps:  75%|▊| 11306/15000 [1:12:01<10:59,  5.60it/s, lr=9.15e-6, step_loss=0.4107/18/2023 20:15:23 - INFO - __main__ - train loss is 10.358755154302344\n",
      "Steps:  75%|▊| 11307/15000 [1:12:01<10:58,  5.61it/s, lr=9.15e-6, step_loss=0.2807/18/2023 20:15:23 - INFO - __main__ - train loss is 10.614540172507986\n",
      "Steps:  75%|▊| 11308/15000 [1:12:01<10:58,  5.60it/s, lr=9.15e-6, step_loss=0.2507/18/2023 20:15:23 - INFO - __main__ - train loss is 10.772881282260641\n",
      "Steps:  75%|▊| 11309/15000 [1:12:01<10:58,  5.60it/s, lr=9.15e-6, step_loss=0.1507/18/2023 20:15:24 - INFO - __main__ - train loss is 10.826307831099257\n",
      "Steps:  75%|▊| 11310/15000 [1:12:02<10:58,  5.60it/s, lr=9.15e-6, step_loss=0.0507/18/2023 20:15:24 - INFO - __main__ - train loss is 11.118895945837721\n",
      "Steps:  75%|▊| 11311/15000 [1:12:02<10:58,  5.61it/s, lr=9.15e-6, step_loss=0.2907/18/2023 20:15:24 - INFO - __main__ - train loss is 11.128719854867086\n",
      "Steps:  75%|▊| 11312/15000 [1:12:02<10:58,  5.60it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:24 - INFO - __main__ - train loss is 11.303691584384069\n",
      "Steps:  75%|▊| 11313/15000 [1:12:02<10:57,  5.60it/s, lr=9.15e-6, step_loss=0.1707/18/2023 20:15:24 - INFO - __main__ - train loss is 11.327597575029358\n",
      "Steps:  75%|▊| 11314/15000 [1:12:02<10:57,  5.60it/s, lr=9.15e-6, step_loss=0.0207/18/2023 20:15:25 - INFO - __main__ - train loss is 11.734962360700592\n",
      "Steps:  75%|▊| 11315/15000 [1:12:02<10:58,  5.60it/s, lr=9.15e-6, step_loss=0.4007/18/2023 20:15:25 - INFO - __main__ - train loss is 11.737158361123875\n",
      "Steps:  75%|▊| 11316/15000 [1:12:03<10:58,  5.60it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:25 - INFO - __main__ - train loss is 11.91512209479697\n",
      "Steps:  75%|▊| 11317/15000 [1:12:03<10:58,  5.60it/s, lr=9.15e-6, step_loss=0.1707/18/2023 20:15:25 - INFO - __main__ - train loss is 11.918722150148824\n",
      "Steps:  75%|▊| 11318/15000 [1:12:03<11:04,  5.54it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:25 - INFO - __main__ - train loss is 12.060310227097943\n",
      "Steps:  75%|▊| 11319/15000 [1:12:03<11:08,  5.51it/s, lr=9.15e-6, step_loss=0.1407/18/2023 20:15:25 - INFO - __main__ - train loss is 12.41483394545503\n",
      "Steps:  75%|▊| 11320/15000 [1:12:03<11:05,  5.53it/s, lr=9.15e-6, step_loss=0.3507/18/2023 20:15:26 - INFO - __main__ - train loss is 12.418785336660221\n",
      "Steps:  75%|▊| 11321/15000 [1:12:03<11:02,  5.55it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:26 - INFO - __main__ - train loss is 12.766147974180058\n",
      "Steps:  75%|▊| 11322/15000 [1:12:04<11:00,  5.56it/s, lr=9.15e-6, step_loss=0.3407/18/2023 20:15:26 - INFO - __main__ - train loss is 12.767502416973002\n",
      "Steps:  75%|▊| 11323/15000 [1:12:04<10:59,  5.58it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:26 - INFO - __main__ - train loss is 12.771140530821867\n",
      "Steps:  75%|▊| 11324/15000 [1:12:04<10:58,  5.58it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:26 - INFO - __main__ - train loss is 12.77478425821755\n",
      "Steps:  76%|▊| 11325/15000 [1:12:04<10:57,  5.59it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:27 - INFO - __main__ - train loss is 12.778821004205383\n",
      "Steps:  76%|▊| 11326/15000 [1:12:04<10:56,  5.59it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:27 - INFO - __main__ - train loss is 12.852489201002754\n",
      "Steps:  76%|▊| 11327/15000 [1:12:05<10:56,  5.59it/s, lr=9.15e-6, step_loss=0.0707/18/2023 20:15:27 - INFO - __main__ - train loss is 12.882122734212317\n",
      "Steps:  76%|▊| 11328/15000 [1:12:05<10:56,  5.59it/s, lr=9.15e-6, step_loss=0.0207/18/2023 20:15:27 - INFO - __main__ - train loss is 12.959595704101957\n",
      "Steps:  76%|▊| 11329/15000 [1:12:05<10:56,  5.59it/s, lr=9.15e-6, step_loss=0.0707/18/2023 20:15:27 - INFO - __main__ - train loss is 13.043264621519484\n",
      "Steps:  76%|▊| 11330/15000 [1:12:05<11:09,  5.48it/s, lr=9.15e-6, step_loss=0.0807/18/2023 20:15:27 - INFO - __main__ - train loss is 13.204469049000181\n",
      "Steps:  76%|▊| 11331/15000 [1:12:05<11:06,  5.50it/s, lr=9.15e-6, step_loss=0.1607/18/2023 20:15:28 - INFO - __main__ - train loss is 13.222822842770256\n",
      "Steps:  76%|▊| 11332/15000 [1:12:05<11:03,  5.53it/s, lr=9.15e-6, step_loss=0.0107/18/2023 20:15:28 - INFO - __main__ - train loss is 13.25481480511371\n",
      "Steps:  76%|▊| 11333/15000 [1:12:06<11:00,  5.55it/s, lr=9.15e-6, step_loss=0.0307/18/2023 20:15:28 - INFO - __main__ - train loss is 13.259877118864097\n",
      "Steps:  76%|▊| 11334/15000 [1:12:06<10:58,  5.57it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:28 - INFO - __main__ - train loss is 13.329777124919929\n",
      "Steps:  76%|▊| 11335/15000 [1:12:06<10:56,  5.58it/s, lr=9.15e-6, step_loss=0.0607/18/2023 20:15:28 - INFO - __main__ - train loss is 13.54206815699581\n",
      "Steps:  76%|▊| 11336/15000 [1:12:06<10:55,  5.59it/s, lr=9.15e-6, step_loss=0.2107/18/2023 20:15:28 - INFO - __main__ - train loss is 13.555118626565672\n",
      "Steps:  76%|▊| 11337/15000 [1:12:06<10:54,  5.60it/s, lr=9.15e-6, step_loss=0.0107/18/2023 20:15:29 - INFO - __main__ - train loss is 14.1153041186044\n",
      "Steps:  76%|▊| 11338/15000 [1:12:07<10:53,  5.60it/s, lr=9.15e-6, step_loss=0.5607/18/2023 20:15:29 - INFO - __main__ - train loss is 14.12285090482328\n",
      "Steps:  76%|▊| 11339/15000 [1:12:07<10:53,  5.60it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:29 - INFO - __main__ - train loss is 14.908990631462075\n",
      "Steps:  76%|▊| 11340/15000 [1:12:07<10:52,  5.61it/s, lr=9.15e-6, step_loss=0.7807/18/2023 20:15:29 - INFO - __main__ - train loss is 14.92705303488765\n",
      "Steps:  76%|▊| 11341/15000 [1:12:07<10:52,  5.61it/s, lr=9.15e-6, step_loss=0.0107/18/2023 20:15:29 - INFO - __main__ - train loss is 15.321557224378921\n",
      "Steps:  76%|▊| 11342/15000 [1:12:07<10:52,  5.60it/s, lr=9.15e-6, step_loss=0.3907/18/2023 20:15:30 - INFO - __main__ - train loss is 15.519282967434265\n",
      "Steps:  76%|▊| 11343/15000 [1:12:07<10:52,  5.61it/s, lr=9.15e-6, step_loss=0.1907/18/2023 20:15:30 - INFO - __main__ - train loss is 15.676710993633606\n",
      "Steps:  76%|▊| 11344/15000 [1:12:08<10:51,  5.61it/s, lr=9.15e-6, step_loss=0.1507/18/2023 20:15:30 - INFO - __main__ - train loss is 16.108429343090393\n",
      "Steps:  76%|▊| 11345/15000 [1:12:08<10:51,  5.61it/s, lr=9.15e-6, step_loss=0.4307/18/2023 20:15:30 - INFO - __main__ - train loss is 16.16501652880106\n",
      "Steps:  76%|▊| 11346/15000 [1:12:08<10:51,  5.61it/s, lr=9.15e-6, step_loss=0.0507/18/2023 20:15:30 - INFO - __main__ - train loss is 16.167037642444484\n",
      "Steps:  76%|▊| 11347/15000 [1:12:08<10:51,  5.61it/s, lr=9.15e-6, step_loss=0.0007/18/2023 20:15:30 - INFO - __main__ - train loss is 16.2893635322107\n",
      "Steps:  76%|▊| 11348/15000 [1:12:08<10:50,  5.61it/s, lr=9.15e-6, step_loss=0.1207/18/2023 20:15:31 - INFO - __main__ - train loss is 16.58633923425805\n",
      "Steps:  76%|▊| 11349/15000 [1:12:09<14:48,  4.11it/s, lr=9.15e-6, step_loss=0.2907/18/2023 20:15:32 - INFO - __main__ - Per validation step average loss is 0.4029162526130676\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Cumulative validation average loss is 0.4029162526130676\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Per validation step average loss is 0.181759774684906\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Cumulative validation average loss is 0.5846760272979736\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Per validation step average loss is 0.0942375510931015\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Cumulative validation average loss is 0.6789135783910751\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Per validation step average loss is 0.4481544494628906\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Cumulative validation average loss is 1.1270680278539658\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Per validation step average loss is 0.00495729548856616\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Cumulative validation average loss is 1.132025323342532\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Per validation step average loss is 0.16514962911605835\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Cumulative validation average loss is 1.2971749524585903\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Per validation step average loss is 0.18721462786197662\n",
      "07/18/2023 20:15:32 - INFO - __main__ - Cumulative validation average loss is 1.484389580320567\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Per validation step average loss is 0.2730340361595154\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Cumulative validation average loss is 1.7574236164800823\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Per validation step average loss is 0.13033567368984222\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Cumulative validation average loss is 1.8877592901699245\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Per validation step average loss is 0.1057838574051857\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Cumulative validation average loss is 1.9935431475751102\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Per validation step average loss is 0.01695350930094719\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Cumulative validation average loss is 2.0104966568760574\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Per validation step average loss is 0.4233217239379883\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Cumulative validation average loss is 2.4338183808140457\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Average validation loss for Epoch 116 is 0.20281819840117046\n",
      "07/18/2023 20:15:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:15:46 - INFO - __main__ - Starting epoch 117\n",
      "07/18/2023 20:15:47 - INFO - __main__ - train loss is 0.0625232681632042\n",
      "Steps:  76%|▊| 11350/15000 [1:12:25<5:07:18,  5.05s/it, lr=9.15e-6, step_loss=0.07/18/2023 20:15:47 - INFO - __main__ - train loss is 0.1268567517399788\n",
      "Steps:  76%|▊| 11351/15000 [1:12:25<3:38:24,  3.59s/it, lr=9.15e-6, step_loss=0.07/18/2023 20:15:47 - INFO - __main__ - train loss is 0.35117221623659134\n",
      "Steps:  76%|▊| 11352/15000 [1:12:25<2:36:11,  2.57s/it, lr=9.15e-6, step_loss=0.07/18/2023 20:15:48 - INFO - __main__ - train loss is 0.37586650997400284\n",
      "Steps:  76%|▊| 11353/15000 [1:12:26<1:52:41,  1.85s/it, lr=9.14e-6, step_loss=0.07/18/2023 20:15:48 - INFO - __main__ - train loss is 0.41937142610549927\n",
      "Steps:  76%|▊| 11354/15000 [1:12:26<1:22:19,  1.35s/it, lr=9.14e-6, step_loss=0.07/18/2023 20:15:48 - INFO - __main__ - train loss is 0.4281385522335768\n",
      "Steps:  76%|▊| 11355/15000 [1:12:26<1:01:12,  1.01s/it, lr=9.14e-6, step_loss=0.07/18/2023 20:15:48 - INFO - __main__ - train loss is 0.49062071554362774\n",
      "Steps:  76%|▊| 11356/15000 [1:12:26<46:22,  1.31it/s, lr=9.14e-6, step_loss=0.0607/18/2023 20:15:48 - INFO - __main__ - train loss is 0.5111983697861433\n",
      "Steps:  76%|▊| 11357/15000 [1:12:26<36:00,  1.69it/s, lr=9.14e-6, step_loss=0.0207/18/2023 20:15:49 - INFO - __main__ - train loss is 0.8989866059273481\n",
      "Steps:  76%|▊| 11358/15000 [1:12:27<28:45,  2.11it/s, lr=9.14e-6, step_loss=0.3807/18/2023 20:15:49 - INFO - __main__ - train loss is 1.1664598565548658\n",
      "Steps:  76%|▊| 11359/15000 [1:12:27<23:41,  2.56it/s, lr=9.14e-6, step_loss=0.2607/18/2023 20:15:49 - INFO - __main__ - train loss is 1.1691237078048289\n",
      "Steps:  76%|▊| 11360/15000 [1:12:27<20:07,  3.01it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:49 - INFO - __main__ - train loss is 1.2107924283482134\n",
      "Steps:  76%|▊| 11361/15000 [1:12:27<17:38,  3.44it/s, lr=9.14e-6, step_loss=0.0407/18/2023 20:15:49 - INFO - __main__ - train loss is 1.258223565761\n",
      "Steps:  76%|▊| 11362/15000 [1:12:27<15:53,  3.82it/s, lr=9.14e-6, step_loss=0.0407/18/2023 20:15:50 - INFO - __main__ - train loss is 1.371892670635134\n",
      "Steps:  76%|▊| 11363/15000 [1:12:27<14:40,  4.13it/s, lr=9.14e-6, step_loss=0.1107/18/2023 20:15:50 - INFO - __main__ - train loss is 1.3742195549421012\n",
      "Steps:  76%|▊| 11364/15000 [1:12:28<13:49,  4.38it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:50 - INFO - __main__ - train loss is 1.6980372848920524\n",
      "Steps:  76%|▊| 11365/15000 [1:12:28<13:12,  4.58it/s, lr=9.14e-6, step_loss=0.3207/18/2023 20:15:50 - INFO - __main__ - train loss is 1.7994770291261375\n",
      "Steps:  76%|▊| 11366/15000 [1:12:28<12:46,  4.74it/s, lr=9.14e-6, step_loss=0.1007/18/2023 20:15:50 - INFO - __main__ - train loss is 2.5854281070642173\n",
      "Steps:  76%|▊| 11367/15000 [1:12:28<12:29,  4.85it/s, lr=9.14e-6, step_loss=0.7807/18/2023 20:15:51 - INFO - __main__ - train loss is 2.7659761193208396\n",
      "Steps:  76%|▊| 11368/15000 [1:12:28<12:10,  4.97it/s, lr=9.14e-6, step_loss=0.1807/18/2023 20:15:51 - INFO - __main__ - train loss is 2.8619614127092063\n",
      "Steps:  76%|▊| 11369/15000 [1:12:29<11:51,  5.10it/s, lr=9.14e-6, step_loss=0.0907/18/2023 20:15:51 - INFO - __main__ - train loss is 2.874285902362317\n",
      "Steps:  76%|▊| 11370/15000 [1:12:29<11:47,  5.13it/s, lr=9.14e-6, step_loss=0.0107/18/2023 20:15:51 - INFO - __main__ - train loss is 2.877424784237519\n",
      "Steps:  76%|▊| 11371/15000 [1:12:29<11:44,  5.15it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:51 - INFO - __main__ - train loss is 3.0229927378240973\n",
      "Steps:  76%|▊| 11372/15000 [1:12:29<11:28,  5.27it/s, lr=9.14e-6, step_loss=0.1407/18/2023 20:15:52 - INFO - __main__ - train loss is 3.028381986776367\n",
      "Steps:  76%|▊| 11373/15000 [1:12:29<11:17,  5.36it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:52 - INFO - __main__ - train loss is 3.074093638220802\n",
      "Steps:  76%|▊| 11374/15000 [1:12:30<11:08,  5.43it/s, lr=9.14e-6, step_loss=0.0407/18/2023 20:15:52 - INFO - __main__ - train loss is 3.086581733310595\n",
      "Steps:  76%|▊| 11375/15000 [1:12:30<11:01,  5.48it/s, lr=9.14e-6, step_loss=0.0107/18/2023 20:15:52 - INFO - __main__ - train loss is 3.1730997303966433\n",
      "Steps:  76%|▊| 11376/15000 [1:12:30<10:57,  5.51it/s, lr=9.14e-6, step_loss=0.0807/18/2023 20:15:52 - INFO - __main__ - train loss is 3.175908971345052\n",
      "Steps:  76%|▊| 11377/15000 [1:12:30<10:54,  5.53it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:52 - INFO - __main__ - train loss is 3.2565428947564214\n",
      "Steps:  76%|▊| 11378/15000 [1:12:30<10:52,  5.55it/s, lr=9.14e-6, step_loss=0.0807/18/2023 20:15:53 - INFO - __main__ - train loss is 3.2642299372237176\n",
      "Steps:  76%|▊| 11379/15000 [1:12:30<10:51,  5.56it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:53 - INFO - __main__ - train loss is 3.283597110537812\n",
      "Steps:  76%|▊| 11380/15000 [1:12:31<10:50,  5.56it/s, lr=9.14e-6, step_loss=0.0107/18/2023 20:15:53 - INFO - __main__ - train loss is 3.9671809661667794\n",
      "Steps:  76%|▊| 11381/15000 [1:12:31<10:49,  5.57it/s, lr=9.14e-6, step_loss=0.6807/18/2023 20:15:53 - INFO - __main__ - train loss is 4.381600348977372\n",
      "Steps:  76%|▊| 11382/15000 [1:12:31<10:49,  5.57it/s, lr=9.14e-6, step_loss=0.4107/18/2023 20:15:53 - INFO - __main__ - train loss is 4.444650201825425\n",
      "Steps:  76%|▊| 11383/15000 [1:12:31<10:48,  5.58it/s, lr=9.14e-6, step_loss=0.0607/18/2023 20:15:53 - INFO - __main__ - train loss is 4.819949774770066\n",
      "Steps:  76%|▊| 11384/15000 [1:12:31<10:47,  5.59it/s, lr=9.14e-6, step_loss=0.3707/18/2023 20:15:54 - INFO - __main__ - train loss is 5.035571216372773\n",
      "Steps:  76%|▊| 11385/15000 [1:12:32<10:46,  5.59it/s, lr=9.14e-6, step_loss=0.2107/18/2023 20:15:54 - INFO - __main__ - train loss is 5.119877747027203\n",
      "Steps:  76%|▊| 11386/15000 [1:12:32<10:46,  5.59it/s, lr=9.14e-6, step_loss=0.0807/18/2023 20:15:54 - INFO - __main__ - train loss is 5.174177727429196\n",
      "Steps:  76%|▊| 11387/15000 [1:12:32<10:46,  5.59it/s, lr=9.14e-6, step_loss=0.0507/18/2023 20:15:54 - INFO - __main__ - train loss is 5.308896294562146\n",
      "Steps:  76%|▊| 11388/15000 [1:12:32<10:46,  5.59it/s, lr=9.14e-6, step_loss=0.1307/18/2023 20:15:54 - INFO - __main__ - train loss is 5.313752849353477\n",
      "Steps:  76%|▊| 11389/15000 [1:12:32<10:45,  5.59it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:55 - INFO - __main__ - train loss is 5.700849790824577\n",
      "Steps:  76%|▊| 11390/15000 [1:12:32<10:46,  5.59it/s, lr=9.14e-6, step_loss=0.3807/18/2023 20:15:55 - INFO - __main__ - train loss is 6.096366305602714\n",
      "Steps:  76%|▊| 11391/15000 [1:12:33<10:45,  5.59it/s, lr=9.14e-6, step_loss=0.3907/18/2023 20:15:55 - INFO - __main__ - train loss is 6.646898765815422\n",
      "Steps:  76%|▊| 11392/15000 [1:12:33<10:45,  5.59it/s, lr=9.14e-6, step_loss=0.5507/18/2023 20:15:55 - INFO - __main__ - train loss is 7.23677744413726\n",
      "Steps:  76%|▊| 11393/15000 [1:12:33<10:45,  5.59it/s, lr=9.14e-6, step_loss=0.5907/18/2023 20:15:55 - INFO - __main__ - train loss is 7.242592103080824\n",
      "Steps:  76%|▊| 11394/15000 [1:12:33<10:45,  5.59it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:55 - INFO - __main__ - train loss is 7.316694877343252\n",
      "Steps:  76%|▊| 11395/15000 [1:12:33<10:48,  5.56it/s, lr=9.14e-6, step_loss=0.0707/18/2023 20:15:56 - INFO - __main__ - train loss is 7.319467587163672\n",
      "Steps:  76%|▊| 11396/15000 [1:12:34<10:47,  5.57it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:56 - INFO - __main__ - train loss is 7.32176184724085\n",
      "Steps:  76%|▊| 11397/15000 [1:12:34<10:51,  5.53it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:56 - INFO - __main__ - train loss is 7.593698353273794\n",
      "Steps:  76%|▊| 11398/15000 [1:12:34<10:49,  5.54it/s, lr=9.14e-6, step_loss=0.2707/18/2023 20:15:56 - INFO - __main__ - train loss is 8.060281724436209\n",
      "Steps:  76%|▊| 11399/15000 [1:12:34<10:47,  5.56it/s, lr=9.14e-6, step_loss=0.4607/18/2023 20:15:56 - INFO - __main__ - train loss is 8.122245882404968\n",
      "Steps:  76%|▊| 11400/15000 [1:12:34<10:47,  5.56it/s, lr=9.14e-6, step_loss=0.0607/18/2023 20:15:57 - INFO - __main__ - train loss is 8.361497406614944\n",
      "Steps:  76%|▊| 11401/15000 [1:12:34<10:46,  5.57it/s, lr=9.14e-6, step_loss=0.2307/18/2023 20:15:57 - INFO - __main__ - train loss is 8.365028988337144\n",
      "Steps:  76%|▊| 11402/15000 [1:12:35<10:45,  5.57it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:57 - INFO - __main__ - train loss is 8.415848079835996\n",
      "Steps:  76%|▊| 11403/15000 [1:12:35<10:44,  5.58it/s, lr=9.14e-6, step_loss=0.0507/18/2023 20:15:57 - INFO - __main__ - train loss is 8.905274335062131\n",
      "Steps:  76%|▊| 11404/15000 [1:12:35<10:44,  5.58it/s, lr=9.14e-6, step_loss=0.4807/18/2023 20:15:57 - INFO - __main__ - train loss is 9.47684246650897\n",
      "Steps:  76%|▊| 11405/15000 [1:12:35<10:44,  5.58it/s, lr=9.14e-6, step_loss=0.5707/18/2023 20:15:57 - INFO - __main__ - train loss is 9.775464538251981\n",
      "Steps:  76%|▊| 11406/15000 [1:12:35<10:43,  5.58it/s, lr=9.14e-6, step_loss=0.2907/18/2023 20:15:58 - INFO - __main__ - train loss is 10.338356558000669\n",
      "Steps:  76%|▊| 11407/15000 [1:12:35<10:43,  5.58it/s, lr=9.14e-6, step_loss=0.5607/18/2023 20:15:58 - INFO - __main__ - train loss is 10.71040153852664\n",
      "Steps:  76%|▊| 11408/15000 [1:12:36<10:43,  5.58it/s, lr=9.14e-6, step_loss=0.3707/18/2023 20:15:58 - INFO - __main__ - train loss is 10.86745947948657\n",
      "Steps:  76%|▊| 11409/15000 [1:12:36<10:43,  5.58it/s, lr=9.14e-6, step_loss=0.1507/18/2023 20:15:58 - INFO - __main__ - train loss is 11.160089377081022\n",
      "Steps:  76%|▊| 11410/15000 [1:12:36<10:42,  5.58it/s, lr=9.14e-6, step_loss=0.2907/18/2023 20:15:58 - INFO - __main__ - train loss is 11.16290007927455\n",
      "Steps:  76%|▊| 11411/15000 [1:12:36<10:42,  5.58it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:15:58 - INFO - __main__ - train loss is 11.186137270415202\n",
      "Steps:  76%|▊| 11412/15000 [1:12:36<10:42,  5.59it/s, lr=9.14e-6, step_loss=0.0207/18/2023 20:15:59 - INFO - __main__ - train loss is 11.261661362135783\n",
      "Steps:  76%|▊| 11413/15000 [1:12:37<10:41,  5.59it/s, lr=9.14e-6, step_loss=0.0707/18/2023 20:15:59 - INFO - __main__ - train loss is 11.39899904676713\n",
      "Steps:  76%|▊| 11414/15000 [1:12:37<10:41,  5.59it/s, lr=9.14e-6, step_loss=0.1307/18/2023 20:15:59 - INFO - __main__ - train loss is 11.580230694497004\n",
      "Steps:  76%|▊| 11415/15000 [1:12:37<10:41,  5.59it/s, lr=9.14e-6, step_loss=0.1807/18/2023 20:15:59 - INFO - __main__ - train loss is 11.595205309102312\n",
      "Steps:  76%|▊| 11416/15000 [1:12:37<10:40,  5.59it/s, lr=9.14e-6, step_loss=0.0107/18/2023 20:15:59 - INFO - __main__ - train loss is 11.597176879178733\n",
      "Steps:  76%|▊| 11417/15000 [1:12:37<10:40,  5.59it/s, lr=9.14e-6, step_loss=0.0007/18/2023 20:16:00 - INFO - __main__ - train loss is 11.616754587274045\n",
      "Steps:  76%|▊| 11418/15000 [1:12:37<10:40,  5.59it/s, lr=9.14e-6, step_loss=0.0107/18/2023 20:16:00 - INFO - __main__ - train loss is 11.672640580218285\n",
      "Steps:  76%|▊| 11419/15000 [1:12:38<10:40,  5.59it/s, lr=9.14e-6, step_loss=0.0507/18/2023 20:16:00 - INFO - __main__ - train loss is 11.872560906689614\n",
      "Steps:  76%|▊| 11420/15000 [1:12:38<10:46,  5.54it/s, lr=9.14e-6, step_loss=0.2]07/18/2023 20:16:00 - INFO - __main__ - train loss is 11.874968569958583\n",
      "Steps:  76%|▊| 11421/15000 [1:12:38<10:50,  5.50it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:00 - INFO - __main__ - train loss is 11.972228940809146\n",
      "Steps:  76%|▊| 11422/15000 [1:12:38<10:51,  5.49it/s, lr=9.13e-6, step_loss=0.0907/18/2023 20:16:00 - INFO - __main__ - train loss is 12.056093361461535\n",
      "Steps:  76%|▊| 11423/15000 [1:12:38<10:54,  5.47it/s, lr=9.13e-6, step_loss=0.0807/18/2023 20:16:01 - INFO - __main__ - train loss is 12.495736088836566\n",
      "Steps:  76%|▊| 11424/15000 [1:12:39<10:51,  5.49it/s, lr=9.13e-6, step_loss=0.4407/18/2023 20:16:01 - INFO - __main__ - train loss is 12.536412980640307\n",
      "Steps:  76%|▊| 11425/15000 [1:12:39<10:48,  5.52it/s, lr=9.13e-6, step_loss=0.0407/18/2023 20:16:01 - INFO - __main__ - train loss is 12.538862990448251\n",
      "Steps:  76%|▊| 11426/15000 [1:12:39<10:45,  5.54it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:01 - INFO - __main__ - train loss is 13.047274159500375\n",
      "Steps:  76%|▊| 11427/15000 [1:12:39<10:48,  5.51it/s, lr=9.13e-6, step_loss=0.5007/18/2023 20:16:01 - INFO - __main__ - train loss is 13.052208190085366\n",
      "Steps:  76%|▊| 11428/15000 [1:12:39<10:50,  5.49it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:02 - INFO - __main__ - train loss is 13.123444442870095\n",
      "Steps:  76%|▊| 11429/15000 [1:12:39<10:47,  5.52it/s, lr=9.13e-6, step_loss=0.0707/18/2023 20:16:02 - INFO - __main__ - train loss is 13.558752511860803\n",
      "Steps:  76%|▊| 11430/15000 [1:12:40<10:44,  5.54it/s, lr=9.13e-6, step_loss=0.4307/18/2023 20:16:02 - INFO - __main__ - train loss is 13.746930380584672\n",
      "Steps:  76%|▊| 11431/15000 [1:12:40<10:41,  5.57it/s, lr=9.13e-6, step_loss=0.1807/18/2023 20:16:02 - INFO - __main__ - train loss is 14.212877293350175\n",
      "Steps:  76%|▊| 11432/15000 [1:12:40<10:39,  5.58it/s, lr=9.13e-6, step_loss=0.4607/18/2023 20:16:02 - INFO - __main__ - train loss is 14.234492867486551\n",
      "Steps:  76%|▊| 11433/15000 [1:12:40<10:39,  5.58it/s, lr=9.13e-6, step_loss=0.0207/18/2023 20:16:02 - INFO - __main__ - train loss is 14.604288547532633\n",
      "Steps:  76%|▊| 11434/15000 [1:12:40<10:38,  5.59it/s, lr=9.13e-6, step_loss=0.3707/18/2023 20:16:03 - INFO - __main__ - train loss is 14.60679119033739\n",
      "Steps:  76%|▊| 11435/15000 [1:12:41<10:37,  5.60it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:03 - INFO - __main__ - train loss is 14.751542098354548\n",
      "Steps:  76%|▊| 11436/15000 [1:12:41<10:36,  5.60it/s, lr=9.13e-6, step_loss=0.1407/18/2023 20:16:03 - INFO - __main__ - train loss is 14.759432909544557\n",
      "Steps:  76%|▊| 11437/15000 [1:12:41<10:35,  5.60it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:03 - INFO - __main__ - train loss is 14.837804561015218\n",
      "Steps:  76%|▊| 11438/15000 [1:12:41<10:35,  5.60it/s, lr=9.13e-6, step_loss=0.0707/18/2023 20:16:03 - INFO - __main__ - train loss is 14.871150413062423\n",
      "Steps:  76%|▊| 11439/15000 [1:12:41<10:35,  5.61it/s, lr=9.13e-6, step_loss=0.0307/18/2023 20:16:04 - INFO - __main__ - train loss is 15.054490306880325\n",
      "Steps:  76%|▊| 11440/15000 [1:12:41<10:34,  5.61it/s, lr=9.13e-6, step_loss=0.1807/18/2023 20:16:04 - INFO - __main__ - train loss is 15.059249492827803\n",
      "Steps:  76%|▊| 11441/15000 [1:12:42<10:34,  5.61it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:04 - INFO - __main__ - train loss is 15.664558740798384\n",
      "Steps:  76%|▊| 11442/15000 [1:12:42<10:34,  5.61it/s, lr=9.13e-6, step_loss=0.6007/18/2023 20:16:04 - INFO - __main__ - train loss is 16.019407900515944\n",
      "Steps:  76%|▊| 11443/15000 [1:12:42<10:41,  5.55it/s, lr=9.13e-6, step_loss=0.3507/18/2023 20:16:04 - INFO - __main__ - train loss is 16.08943078154698\n",
      "Steps:  76%|▊| 11444/15000 [1:12:42<10:38,  5.57it/s, lr=9.13e-6, step_loss=0.0707/18/2023 20:16:04 - INFO - __main__ - train loss is 16.09218345815316\n",
      "Steps:  76%|▊| 11445/15000 [1:12:42<10:37,  5.58it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:05 - INFO - __main__ - train loss is 16.299831660930067\n",
      "Steps:  76%|▊| 11446/15000 [1:12:43<14:49,  3.99it/s, lr=9.13e-6, step_loss=0.2007/18/2023 20:16:06 - INFO - __main__ - Per validation step average loss is 0.005735000595450401\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Cumulative validation average loss is 0.005735000595450401\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Per validation step average loss is 0.026385344564914703\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Cumulative validation average loss is 0.032120345160365105\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Per validation step average loss is 0.11164547502994537\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Cumulative validation average loss is 0.14376582019031048\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Per validation step average loss is 0.11888207495212555\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Cumulative validation average loss is 0.262647895142436\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Per validation step average loss is 0.43265217542648315\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Cumulative validation average loss is 0.6953000705689192\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Per validation step average loss is 0.0015980445314198732\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Cumulative validation average loss is 0.696898115100339\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Per validation step average loss is 0.016565963625907898\n",
      "07/18/2023 20:16:06 - INFO - __main__ - Cumulative validation average loss is 0.713464078726247\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Per validation step average loss is 0.5981699228286743\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Cumulative validation average loss is 1.3116340015549213\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Per validation step average loss is 0.0038255215622484684\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Cumulative validation average loss is 1.3154595231171697\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Per validation step average loss is 0.15106770396232605\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Cumulative validation average loss is 1.4665272270794958\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Per validation step average loss is 0.05724819749593735\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Cumulative validation average loss is 1.5237754245754331\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Per validation step average loss is 0.1414300501346588\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Cumulative validation average loss is 1.665205474710092\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Average validation loss for Epoch 117 is 0.13876712289250767\n",
      "07/18/2023 20:16:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:16:20 - INFO - __main__ - Starting epoch 118\n",
      "07/18/2023 20:16:21 - INFO - __main__ - train loss is 0.004493126180022955\n",
      "Steps:  76%|▊| 11447/15000 [1:12:59<4:53:06,  4.95s/it, lr=9.13e-6, step_loss=0.07/18/2023 20:16:21 - INFO - __main__ - train loss is 0.18315661838278174\n",
      "Steps:  76%|▊| 11448/15000 [1:12:59<3:28:17,  3.52s/it, lr=9.13e-6, step_loss=0.07/18/2023 20:16:21 - INFO - __main__ - train loss is 0.3621822386048734\n",
      "Steps:  76%|▊| 11449/15000 [1:12:59<2:28:57,  2.52s/it, lr=9.13e-6, step_loss=0.07/18/2023 20:16:21 - INFO - __main__ - train loss is 0.510763758327812\n",
      "Steps:  76%|▊| 11450/15000 [1:12:59<1:47:25,  1.82s/it, lr=9.13e-6, step_loss=0.07/18/2023 20:16:21 - INFO - __main__ - train loss is 0.5785029171966016\n",
      "Steps:  76%|▊| 11451/15000 [1:12:59<1:18:22,  1.33s/it, lr=9.13e-6, step_loss=0.07/18/2023 20:16:22 - INFO - __main__ - train loss is 0.6368189244531095\n",
      "Steps:  76%|▊| 11452/15000 [1:13:00<58:03,  1.02it/s, lr=9.13e-6, step_loss=0.0507/18/2023 20:16:22 - INFO - __main__ - train loss is 0.9355962066911161\n",
      "Steps:  76%|▊| 11453/15000 [1:13:00<43:47,  1.35it/s, lr=9.13e-6, step_loss=0.2907/18/2023 20:16:22 - INFO - __main__ - train loss is 1.5531066446565092\n",
      "Steps:  76%|▊| 11454/15000 [1:13:00<33:47,  1.75it/s, lr=9.13e-6, step_loss=0.6107/18/2023 20:16:22 - INFO - __main__ - train loss is 1.5619770078919828\n",
      "Steps:  76%|▊| 11455/15000 [1:13:00<26:48,  2.20it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:22 - INFO - __main__ - train loss is 1.568001430016011\n",
      "Steps:  76%|▊| 11456/15000 [1:13:00<21:54,  2.70it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:23 - INFO - __main__ - train loss is 1.792586367111653\n",
      "Steps:  76%|▊| 11457/15000 [1:13:00<18:28,  3.20it/s, lr=9.13e-6, step_loss=0.2207/18/2023 20:16:23 - INFO - __main__ - train loss is 1.7996860705316067\n",
      "Steps:  76%|▊| 11458/15000 [1:13:01<16:04,  3.67it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:23 - INFO - __main__ - train loss is 1.8057933207601309\n",
      "Steps:  76%|▊| 11459/15000 [1:13:01<14:25,  4.09it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:23 - INFO - __main__ - train loss is 1.9495177324861288\n",
      "Steps:  76%|▊| 11460/15000 [1:13:01<13:15,  4.45it/s, lr=9.13e-6, step_loss=0.1407/18/2023 20:16:23 - INFO - __main__ - train loss is 2.717261618003249\n",
      "Steps:  76%|▊| 11461/15000 [1:13:01<12:25,  4.75it/s, lr=9.13e-6, step_loss=0.7607/18/2023 20:16:23 - INFO - __main__ - train loss is 3.0899767335504293\n",
      "Steps:  76%|▊| 11462/15000 [1:13:01<11:51,  4.98it/s, lr=9.13e-6, step_loss=0.3707/18/2023 20:16:24 - INFO - __main__ - train loss is 3.5088129695504904\n",
      "Steps:  76%|▊| 11463/15000 [1:13:02<11:26,  5.15it/s, lr=9.13e-6, step_loss=0.4107/18/2023 20:16:24 - INFO - __main__ - train loss is 3.5745571982115507\n",
      "Steps:  76%|▊| 11464/15000 [1:13:02<11:10,  5.28it/s, lr=9.13e-6, step_loss=0.0607/18/2023 20:16:24 - INFO - __main__ - train loss is 3.7263826709240675\n",
      "Steps:  76%|▊| 11465/15000 [1:13:02<10:58,  5.36it/s, lr=9.13e-6, step_loss=0.1507/18/2023 20:16:24 - INFO - __main__ - train loss is 3.8037219252437353\n",
      "Steps:  76%|▊| 11466/15000 [1:13:02<10:51,  5.43it/s, lr=9.13e-6, step_loss=0.0707/18/2023 20:16:24 - INFO - __main__ - train loss is 4.0110738929361105\n",
      "Steps:  76%|▊| 11467/15000 [1:13:02<10:46,  5.47it/s, lr=9.13e-6, step_loss=0.2007/18/2023 20:16:25 - INFO - __main__ - train loss is 4.162766670808196\n",
      "Steps:  76%|▊| 11468/15000 [1:13:02<10:41,  5.51it/s, lr=9.13e-6, step_loss=0.1507/18/2023 20:16:25 - INFO - __main__ - train loss is 4.28093727491796\n",
      "Steps:  76%|▊| 11469/15000 [1:13:03<10:42,  5.50it/s, lr=9.13e-6, step_loss=0.1107/18/2023 20:16:25 - INFO - __main__ - train loss is 4.319947360083461\n",
      "Steps:  76%|▊| 11470/15000 [1:13:03<10:38,  5.53it/s, lr=9.13e-6, step_loss=0.0307/18/2023 20:16:25 - INFO - __main__ - train loss is 4.769079921767116\n",
      "Steps:  76%|▊| 11471/15000 [1:13:03<10:37,  5.53it/s, lr=9.13e-6, step_loss=0.4407/18/2023 20:16:25 - INFO - __main__ - train loss is 4.774246027693152\n",
      "Steps:  76%|▊| 11472/15000 [1:13:03<10:35,  5.55it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:25 - INFO - __main__ - train loss is 4.8012208715081215\n",
      "Steps:  76%|▊| 11473/15000 [1:13:03<10:33,  5.56it/s, lr=9.13e-6, step_loss=0.0207/18/2023 20:16:26 - INFO - __main__ - train loss is 5.076407499611378\n",
      "Steps:  76%|▊| 11474/15000 [1:13:03<10:38,  5.52it/s, lr=9.13e-6, step_loss=0.2707/18/2023 20:16:26 - INFO - __main__ - train loss is 5.660110957920551\n",
      "Steps:  76%|▊| 11475/15000 [1:13:04<10:37,  5.53it/s, lr=9.13e-6, step_loss=0.5807/18/2023 20:16:26 - INFO - __main__ - train loss is 5.674909378401935\n",
      "Steps:  77%|▊| 11476/15000 [1:13:04<10:36,  5.54it/s, lr=9.13e-6, step_loss=0.0107/18/2023 20:16:26 - INFO - __main__ - train loss is 5.687565938569605\n",
      "Steps:  77%|▊| 11477/15000 [1:13:04<10:34,  5.55it/s, lr=9.13e-6, step_loss=0.0107/18/2023 20:16:26 - INFO - __main__ - train loss is 5.82532209251076\n",
      "Steps:  77%|▊| 11478/15000 [1:13:04<10:34,  5.56it/s, lr=9.13e-6, step_loss=0.1307/18/2023 20:16:26 - INFO - __main__ - train loss is 5.843050331808627\n",
      "Steps:  77%|▊| 11479/15000 [1:13:04<10:36,  5.53it/s, lr=9.13e-6, step_loss=0.0107/18/2023 20:16:27 - INFO - __main__ - train loss is 5.854069735854864\n",
      "Steps:  77%|▊| 11480/15000 [1:13:05<10:34,  5.55it/s, lr=9.13e-6, step_loss=0.0107/18/2023 20:16:27 - INFO - __main__ - train loss is 5.965571951121092\n",
      "Steps:  77%|▊| 11481/15000 [1:13:05<11:15,  5.21it/s, lr=9.13e-6, step_loss=0.1107/18/2023 20:16:27 - INFO - __main__ - train loss is 6.346495222300291\n",
      "Steps:  77%|▊| 11482/15000 [1:13:05<11:14,  5.21it/s, lr=9.13e-6, step_loss=0.3807/18/2023 20:16:27 - INFO - __main__ - train loss is 6.348415147862397\n",
      "Steps:  77%|▊| 11483/15000 [1:13:05<11:16,  5.20it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:27 - INFO - __main__ - train loss is 6.351930911769159\n",
      "Steps:  77%|▊| 11484/15000 [1:13:05<11:13,  5.22it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:28 - INFO - __main__ - train loss is 6.416514570941217\n",
      "Steps:  77%|▊| 11485/15000 [1:13:06<11:00,  5.32it/s, lr=9.13e-6, step_loss=0.0607/18/2023 20:16:28 - INFO - __main__ - train loss is 6.696734692086466\n",
      "Steps:  77%|▊| 11486/15000 [1:13:06<10:50,  5.41it/s, lr=9.13e-6, step_loss=0.2807/18/2023 20:16:28 - INFO - __main__ - train loss is 7.078009571065195\n",
      "Steps:  77%|▊| 11487/15000 [1:13:06<10:43,  5.46it/s, lr=9.13e-6, step_loss=0.3807/18/2023 20:16:28 - INFO - __main__ - train loss is 7.0836193362483755\n",
      "Steps:  77%|▊| 11488/15000 [1:13:06<10:38,  5.50it/s, lr=9.13e-6, step_loss=0.0007/18/2023 20:16:28 - INFO - __main__ - train loss is 7.2204595456132665\n",
      "Steps:  77%|▊| 11489/15000 [1:13:06<10:35,  5.53it/s, lr=9.12e-6, step_loss=0.1307/18/2023 20:16:29 - INFO - __main__ - train loss is 7.22353965009097\n",
      "Steps:  77%|▊| 11490/15000 [1:13:06<10:32,  5.55it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:29 - INFO - __main__ - train loss is 7.706822096952237\n",
      "Steps:  77%|▊| 11491/15000 [1:13:07<10:30,  5.56it/s, lr=9.12e-6, step_loss=0.4807/18/2023 20:16:29 - INFO - __main__ - train loss is 8.369231879361905\n",
      "Steps:  77%|▊| 11492/15000 [1:13:07<10:29,  5.58it/s, lr=9.12e-6, step_loss=0.6607/18/2023 20:16:29 - INFO - __main__ - train loss is 8.380442746565677\n",
      "Steps:  77%|▊| 11493/15000 [1:13:07<10:28,  5.58it/s, lr=9.12e-6, step_loss=0.0107/18/2023 20:16:29 - INFO - __main__ - train loss is 8.388298706733622\n",
      "Steps:  77%|▊| 11494/15000 [1:13:07<10:27,  5.59it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:29 - INFO - __main__ - train loss is 8.395664432202466\n",
      "Steps:  77%|▊| 11495/15000 [1:13:07<10:33,  5.54it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:30 - INFO - __main__ - train loss is 8.402591280755587\n",
      "Steps:  77%|▊| 11496/15000 [1:13:08<10:36,  5.50it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:30 - INFO - __main__ - train loss is 9.04995077115018\n",
      "Steps:  77%|▊| 11497/15000 [1:13:08<10:33,  5.53it/s, lr=9.12e-6, step_loss=0.6407/18/2023 20:16:30 - INFO - __main__ - train loss is 9.129594907280989\n",
      "Steps:  77%|▊| 11498/15000 [1:13:08<10:31,  5.54it/s, lr=9.12e-6, step_loss=0.0707/18/2023 20:16:30 - INFO - __main__ - train loss is 9.273321539280005\n",
      "Steps:  77%|▊| 11499/15000 [1:13:08<10:29,  5.56it/s, lr=9.12e-6, step_loss=0.1407/18/2023 20:16:30 - INFO - __main__ - train loss is 9.287975188461132\n",
      "Steps:  77%|▊| 11500/15000 [1:13:08<10:29,  5.56it/s, lr=9.12e-6, step_loss=0.1407/18/2023 20:16:30 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-11500\n",
      "07/18/2023 20:16:30 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:16:30,932] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:16:30,937] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-11500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:16:30,937] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-11500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:16:30,945] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-11500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:16:30,945] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-11500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:16:30,968] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-11500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:16:30,968] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-11500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:16:30,968] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:16:30 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-11500/pytorch_model\n",
      "07/18/2023 20:16:30 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-11500/scheduler.bin\n",
      "07/18/2023 20:16:30 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-11500/random_states_0.pkl\n",
      "07/18/2023 20:16:30 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-11500\n",
      "Steps:  77%|▊| 11500/15000 [1:13:08<10:29,  5.56it/s, lr=9.12e-6, step_loss=0.0107/18/2023 20:16:31 - INFO - __main__ - train loss is 9.361263793078251\n",
      "Steps:  77%|▊| 11501/15000 [1:13:08<11:08,  5.23it/s, lr=9.12e-6, step_loss=0.0707/18/2023 20:16:31 - INFO - __main__ - train loss is 9.56154496606905\n",
      "Steps:  77%|▊| 11502/15000 [1:13:09<11:00,  5.29it/s, lr=9.12e-6, step_loss=0.2]07/18/2023 20:16:31 - INFO - __main__ - train loss is 9.567677202750929\n",
      "Steps:  77%|▊| 11503/15000 [1:13:09<10:50,  5.38it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:31 - INFO - __main__ - train loss is 9.574755184934475\n",
      "Steps:  77%|▊| 11504/15000 [1:13:09<10:48,  5.39it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:31 - INFO - __main__ - train loss is 9.606156986788847\n",
      "Steps:  77%|▊| 11505/15000 [1:13:09<10:51,  5.36it/s, lr=9.12e-6, step_loss=0.0307/18/2023 20:16:31 - INFO - __main__ - train loss is 9.622965634451248\n",
      "Steps:  77%|▊| 11506/15000 [1:13:09<10:48,  5.39it/s, lr=9.12e-6, step_loss=0.0107/18/2023 20:16:32 - INFO - __main__ - train loss is 9.963906527147628\n",
      "Steps:  77%|▊| 11507/15000 [1:13:10<10:52,  5.35it/s, lr=9.12e-6, step_loss=0.3407/18/2023 20:16:32 - INFO - __main__ - train loss is 10.180617035017349\n",
      "Steps:  77%|▊| 11508/15000 [1:13:10<10:49,  5.37it/s, lr=9.12e-6, step_loss=0.2107/18/2023 20:16:32 - INFO - __main__ - train loss is 10.247283749864437\n",
      "Steps:  77%|▊| 11509/15000 [1:13:10<10:41,  5.44it/s, lr=9.12e-6, step_loss=0.0607/18/2023 20:16:32 - INFO - __main__ - train loss is 10.285111621604301\n",
      "Steps:  77%|▊| 11510/15000 [1:13:10<10:36,  5.49it/s, lr=9.12e-6, step_loss=0.0307/18/2023 20:16:32 - INFO - __main__ - train loss is 10.302863997058012\n",
      "Steps:  77%|▊| 11511/15000 [1:13:10<10:32,  5.52it/s, lr=9.12e-6, step_loss=0.0107/18/2023 20:16:33 - INFO - __main__ - train loss is 10.329384703771211\n",
      "Steps:  77%|▊| 11512/15000 [1:13:10<10:28,  5.55it/s, lr=9.12e-6, step_loss=0.0207/18/2023 20:16:33 - INFO - __main__ - train loss is 10.74383224977646\n",
      "Steps:  77%|▊| 11513/15000 [1:13:11<10:26,  5.56it/s, lr=9.12e-6, step_loss=0.4107/18/2023 20:16:33 - INFO - __main__ - train loss is 10.92306977941189\n",
      "Steps:  77%|▊| 11514/15000 [1:13:11<10:25,  5.58it/s, lr=9.12e-6, step_loss=0.1707/18/2023 20:16:33 - INFO - __main__ - train loss is 11.190912310616113\n",
      "Steps:  77%|▊| 11515/15000 [1:13:11<10:24,  5.58it/s, lr=9.12e-6, step_loss=0.2607/18/2023 20:16:33 - INFO - __main__ - train loss is 11.198193627060391\n",
      "Steps:  77%|▊| 11516/15000 [1:13:11<10:23,  5.59it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:33 - INFO - __main__ - train loss is 11.200185404275544\n",
      "Steps:  77%|▊| 11517/15000 [1:13:11<10:23,  5.59it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:34 - INFO - __main__ - train loss is 11.234595381771214\n",
      "Steps:  77%|▊| 11518/15000 [1:13:12<10:22,  5.59it/s, lr=9.12e-6, step_loss=0.0307/18/2023 20:16:34 - INFO - __main__ - train loss is 11.27204321429599\n",
      "Steps:  77%|▊| 11519/15000 [1:13:12<10:22,  5.60it/s, lr=9.12e-6, step_loss=0.0307/18/2023 20:16:34 - INFO - __main__ - train loss is 11.30807665840257\n",
      "Steps:  77%|▊| 11520/15000 [1:13:12<10:21,  5.60it/s, lr=9.12e-6, step_loss=0.0307/18/2023 20:16:34 - INFO - __main__ - train loss is 11.35215691209305\n",
      "Steps:  77%|▊| 11521/15000 [1:13:12<10:21,  5.60it/s, lr=9.12e-6, step_loss=0.0407/18/2023 20:16:34 - INFO - __main__ - train loss is 11.356429498293437\n",
      "Steps:  77%|▊| 11522/15000 [1:13:12<10:20,  5.60it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:35 - INFO - __main__ - train loss is 11.641142826178111\n",
      "Steps:  77%|▊| 11523/15000 [1:13:12<10:20,  5.60it/s, lr=9.12e-6, step_loss=0.2807/18/2023 20:16:35 - INFO - __main__ - train loss is 12.02902559528593\n",
      "Steps:  77%|▊| 11524/15000 [1:13:13<10:20,  5.60it/s, lr=9.12e-6, step_loss=0.3807/18/2023 20:16:35 - INFO - __main__ - train loss is 12.034329866641201\n",
      "Steps:  77%|▊| 11525/15000 [1:13:13<10:20,  5.60it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:35 - INFO - __main__ - train loss is 12.036624454543926\n",
      "Steps:  77%|▊| 11526/15000 [1:13:13<10:20,  5.60it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:35 - INFO - __main__ - train loss is 12.236628197715618\n",
      "Steps:  77%|▊| 11527/15000 [1:13:13<10:19,  5.61it/s, lr=9.12e-6, step_loss=0.2]07/18/2023 20:16:35 - INFO - __main__ - train loss is 12.658712648437358\n",
      "Steps:  77%|▊| 11528/15000 [1:13:13<10:25,  5.55it/s, lr=9.12e-6, step_loss=0.4207/18/2023 20:16:36 - INFO - __main__ - train loss is 13.115708701894619\n",
      "Steps:  77%|▊| 11529/15000 [1:13:14<10:29,  5.51it/s, lr=9.12e-6, step_loss=0.4507/18/2023 20:16:36 - INFO - __main__ - train loss is 13.429664545343257\n",
      "Steps:  77%|▊| 11530/15000 [1:13:14<10:26,  5.54it/s, lr=9.12e-6, step_loss=0.3107/18/2023 20:16:36 - INFO - __main__ - train loss is 13.437746104435064\n",
      "Steps:  77%|▊| 11531/15000 [1:13:14<10:24,  5.56it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:36 - INFO - __main__ - train loss is 13.592496093944646\n",
      "Steps:  77%|▊| 11532/15000 [1:13:14<10:22,  5.57it/s, lr=9.12e-6, step_loss=0.1507/18/2023 20:16:36 - INFO - __main__ - train loss is 13.612879181862809\n",
      "Steps:  77%|▊| 11533/15000 [1:13:14<10:21,  5.58it/s, lr=9.12e-6, step_loss=0.0207/18/2023 20:16:37 - INFO - __main__ - train loss is 13.758748496533372\n",
      "Steps:  77%|▊| 11534/15000 [1:13:14<10:19,  5.59it/s, lr=9.12e-6, step_loss=0.1407/18/2023 20:16:37 - INFO - __main__ - train loss is 13.865674155415036\n",
      "Steps:  77%|▊| 11535/15000 [1:13:15<10:19,  5.60it/s, lr=9.12e-6, step_loss=0.1007/18/2023 20:16:37 - INFO - __main__ - train loss is 13.984865801990964\n",
      "Steps:  77%|▊| 11536/15000 [1:13:15<10:18,  5.60it/s, lr=9.12e-6, step_loss=0.1107/18/2023 20:16:37 - INFO - __main__ - train loss is 14.180469262064435\n",
      "Steps:  77%|▊| 11537/15000 [1:13:15<10:17,  5.61it/s, lr=9.12e-6, step_loss=0.1907/18/2023 20:16:37 - INFO - __main__ - train loss is 14.216616461635567\n",
      "Steps:  77%|▊| 11538/15000 [1:13:15<10:16,  5.61it/s, lr=9.12e-6, step_loss=0.0307/18/2023 20:16:37 - INFO - __main__ - train loss is 14.223708165925927\n",
      "Steps:  77%|▊| 11539/15000 [1:13:15<10:17,  5.61it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:38 - INFO - __main__ - train loss is 14.729819430154748\n",
      "Steps:  77%|▊| 11540/15000 [1:13:15<10:17,  5.61it/s, lr=9.12e-6, step_loss=0.5007/18/2023 20:16:38 - INFO - __main__ - train loss is 14.773512238753028\n",
      "Steps:  77%|▊| 11541/15000 [1:13:16<10:16,  5.61it/s, lr=9.12e-6, step_loss=0.0407/18/2023 20:16:38 - INFO - __main__ - train loss is 14.783517220173962\n",
      "Steps:  77%|▊| 11542/15000 [1:13:16<10:16,  5.61it/s, lr=9.12e-6, step_loss=0.0107/18/2023 20:16:38 - INFO - __main__ - train loss is 15.150157609139569\n",
      "Steps:  77%|▊| 11543/15000 [1:13:16<13:48,  4.17it/s, lr=9.12e-6, step_loss=0.3607/18/2023 20:16:39 - INFO - __main__ - Per validation step average loss is 0.012074079364538193\n",
      "07/18/2023 20:16:39 - INFO - __main__ - Cumulative validation average loss is 0.012074079364538193\n",
      "07/18/2023 20:16:39 - INFO - __main__ - Per validation step average loss is 0.004009939264506102\n",
      "07/18/2023 20:16:39 - INFO - __main__ - Cumulative validation average loss is 0.016084018629044294\n",
      "07/18/2023 20:16:39 - INFO - __main__ - Per validation step average loss is 0.10276683419942856\n",
      "07/18/2023 20:16:39 - INFO - __main__ - Cumulative validation average loss is 0.11885085282847285\n",
      "07/18/2023 20:16:39 - INFO - __main__ - Per validation step average loss is 0.07506676018238068\n",
      "07/18/2023 20:16:39 - INFO - __main__ - Cumulative validation average loss is 0.19391761301085353\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Per validation step average loss is 0.009102178737521172\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Cumulative validation average loss is 0.2030197917483747\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Per validation step average loss is 0.023511355742812157\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Cumulative validation average loss is 0.22653114749118686\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Per validation step average loss is 0.06672824919223785\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Cumulative validation average loss is 0.2932593966834247\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Per validation step average loss is 0.05380164459347725\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Cumulative validation average loss is 0.34706104127690196\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Per validation step average loss is 0.012679754756391048\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Cumulative validation average loss is 0.359740796033293\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Per validation step average loss is 0.006340715568512678\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Cumulative validation average loss is 0.3660815116018057\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Per validation step average loss is 0.0527886338531971\n",
      "07/18/2023 20:16:40 - INFO - __main__ - Cumulative validation average loss is 0.4188701454550028\n",
      "07/18/2023 20:16:41 - INFO - __main__ - Per validation step average loss is 0.0014769883127883077\n",
      "07/18/2023 20:16:41 - INFO - __main__ - Cumulative validation average loss is 0.4203471337677911\n",
      "07/18/2023 20:16:41 - INFO - __main__ - Average validation loss for Epoch 118 is 0.03502892781398259\n",
      "07/18/2023 20:16:41 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:16:54 - INFO - __main__ - Starting epoch 119\n",
      "07/18/2023 20:16:55 - INFO - __main__ - train loss is 0.002131871646270156\n",
      "Steps:  77%|▊| 11544/15000 [1:13:32<4:50:38,  5.05s/it, lr=9.12e-6, step_loss=0.07/18/2023 20:16:55 - INFO - __main__ - train loss is 0.5677878779824823\n",
      "Steps:  77%|▊| 11545/15000 [1:13:33<3:26:30,  3.59s/it, lr=9.12e-6, step_loss=0.07/18/2023 20:16:55 - INFO - __main__ - train loss is 0.5761369473766536\n",
      "Steps:  77%|▊| 11546/15000 [1:13:33<2:27:35,  2.56s/it, lr=9.12e-6, step_loss=0.07/18/2023 20:16:55 - INFO - __main__ - train loss is 0.585984944133088\n",
      "Steps:  77%|▊| 11547/15000 [1:13:33<1:46:23,  1.85s/it, lr=9.12e-6, step_loss=0.07/18/2023 20:16:55 - INFO - __main__ - train loss is 0.6416955355089158\n",
      "Steps:  77%|▊| 11548/15000 [1:13:33<1:17:34,  1.35s/it, lr=9.12e-6, step_loss=0.07/18/2023 20:16:55 - INFO - __main__ - train loss is 0.7953606608789414\n",
      "Steps:  77%|▊| 11549/15000 [1:13:33<57:29,  1.00it/s, lr=9.12e-6, step_loss=0.1507/18/2023 20:16:56 - INFO - __main__ - train loss is 1.305291748372838\n",
      "Steps:  77%|▊| 11550/15000 [1:13:34<43:24,  1.32it/s, lr=9.12e-6, step_loss=0.5107/18/2023 20:16:56 - INFO - __main__ - train loss is 1.8458589080255479\n",
      "Steps:  77%|▊| 11551/15000 [1:13:34<33:27,  1.72it/s, lr=9.12e-6, step_loss=0.5407/18/2023 20:16:56 - INFO - __main__ - train loss is 2.08710145088844\n",
      "Steps:  77%|▊| 11552/15000 [1:13:34<26:28,  2.17it/s, lr=9.12e-6, step_loss=0.2407/18/2023 20:16:56 - INFO - __main__ - train loss is 2.091356318211183\n",
      "Steps:  77%|▊| 11553/15000 [1:13:34<21:36,  2.66it/s, lr=9.12e-6, step_loss=0.0007/18/2023 20:16:56 - INFO - __main__ - train loss is 2.4930010547395796\n",
      "Steps:  77%|▊| 11554/15000 [1:13:34<18:11,  3.16it/s, lr=9.12e-6, step_loss=0.4007/18/2023 20:16:57 - INFO - __main__ - train loss is 2.862477015471086\n",
      "Steps:  77%|▊| 11555/15000 [1:13:34<15:53,  3.61it/s, lr=9.12e-6, step_loss=0.3607/18/2023 20:16:57 - INFO - __main__ - train loss is 2.8829601739998907\n",
      "Steps:  77%|▊| 11556/15000 [1:13:35<14:22,  3.99it/s, lr=9.11e-6, step_loss=0.0207/18/2023 20:16:57 - INFO - __main__ - train loss is 3.1010407840367407\n",
      "Steps:  77%|▊| 11557/15000 [1:13:35<13:16,  4.32it/s, lr=9.11e-6, step_loss=0.2107/18/2023 20:16:57 - INFO - __main__ - train loss is 3.400576058542356\n",
      "Steps:  77%|▊| 11558/15000 [1:13:35<12:23,  4.63it/s, lr=9.11e-6, step_loss=0.3]07/18/2023 20:16:57 - INFO - __main__ - train loss is 3.655629221117124\n",
      "Steps:  77%|▊| 11559/15000 [1:13:35<11:50,  4.85it/s, lr=9.11e-6, step_loss=0.2507/18/2023 20:16:57 - INFO - __main__ - train loss is 3.7085358460899442\n",
      "Steps:  77%|▊| 11560/15000 [1:13:35<11:23,  5.04it/s, lr=9.11e-6, step_loss=0.0507/18/2023 20:16:58 - INFO - __main__ - train loss is 4.479126032209024\n",
      "Steps:  77%|▊| 11561/15000 [1:13:36<11:02,  5.19it/s, lr=9.11e-6, step_loss=0.7707/18/2023 20:16:58 - INFO - __main__ - train loss is 4.547103348886594\n",
      "Steps:  77%|▊| 11562/15000 [1:13:36<10:47,  5.31it/s, lr=9.11e-6, step_loss=0.0607/18/2023 20:16:58 - INFO - __main__ - train loss is 4.8011236225720495\n",
      "Steps:  77%|▊| 11563/15000 [1:13:36<10:37,  5.39it/s, lr=9.11e-6, step_loss=0.2507/18/2023 20:16:58 - INFO - __main__ - train loss is 4.820769607787952\n",
      "Steps:  77%|▊| 11564/15000 [1:13:36<10:30,  5.45it/s, lr=9.11e-6, step_loss=0.0107/18/2023 20:16:58 - INFO - __main__ - train loss is 4.865006178384647\n",
      "Steps:  77%|▊| 11565/15000 [1:13:36<10:25,  5.49it/s, lr=9.11e-6, step_loss=0.0407/18/2023 20:16:59 - INFO - __main__ - train loss is 5.056994139915332\n",
      "Steps:  77%|▊| 11566/15000 [1:13:36<10:21,  5.52it/s, lr=9.11e-6, step_loss=0.1907/18/2023 20:16:59 - INFO - __main__ - train loss is 5.15664829290472\n",
      "Steps:  77%|▊| 11567/15000 [1:13:37<10:24,  5.49it/s, lr=9.11e-6, step_loss=0.0907/18/2023 20:16:59 - INFO - __main__ - train loss is 5.210839304840192\n",
      "Steps:  77%|▊| 11568/15000 [1:13:37<10:21,  5.52it/s, lr=9.11e-6, step_loss=0.0507/18/2023 20:16:59 - INFO - __main__ - train loss is 5.52965847006999\n",
      "Steps:  77%|▊| 11569/15000 [1:13:37<10:18,  5.55it/s, lr=9.11e-6, step_loss=0.3107/18/2023 20:16:59 - INFO - __main__ - train loss is 5.593478414928541\n",
      "Steps:  77%|▊| 11570/15000 [1:13:37<10:16,  5.56it/s, lr=9.11e-6, step_loss=0.0607/18/2023 20:16:59 - INFO - __main__ - train loss is 5.635777558898553\n",
      "Steps:  77%|▊| 11571/15000 [1:13:37<10:15,  5.57it/s, lr=9.11e-6, step_loss=0.0407/18/2023 20:17:00 - INFO - __main__ - train loss is 6.069278117036447\n",
      "Steps:  77%|▊| 11572/15000 [1:13:38<10:15,  5.57it/s, lr=9.11e-6, step_loss=0.4307/18/2023 20:17:00 - INFO - __main__ - train loss is 6.333719130372629\n",
      "Steps:  77%|▊| 11573/15000 [1:13:38<10:15,  5.57it/s, lr=9.11e-6, step_loss=0.2607/18/2023 20:17:00 - INFO - __main__ - train loss is 6.344315318157896\n",
      "Steps:  77%|▊| 11574/15000 [1:13:38<10:14,  5.58it/s, lr=9.11e-6, step_loss=0.0107/18/2023 20:17:00 - INFO - __main__ - train loss is 6.435393629362807\n",
      "Steps:  77%|▊| 11575/15000 [1:13:38<10:13,  5.58it/s, lr=9.11e-6, step_loss=0.0907/18/2023 20:17:00 - INFO - __main__ - train loss is 6.581224856665358\n",
      "Steps:  77%|▊| 11576/15000 [1:13:38<10:15,  5.56it/s, lr=9.11e-6, step_loss=0.1407/18/2023 20:17:01 - INFO - __main__ - train loss is 6.771323872497305\n",
      "Steps:  77%|▊| 11577/15000 [1:13:38<10:14,  5.57it/s, lr=9.11e-6, step_loss=0.1907/18/2023 20:17:01 - INFO - __main__ - train loss is 6.780087887076661\n",
      "Steps:  77%|▊| 11578/15000 [1:13:39<10:13,  5.58it/s, lr=9.11e-6, step_loss=0.0007/18/2023 20:17:01 - INFO - __main__ - train loss is 6.806600994197652\n",
      "Steps:  77%|▊| 11579/15000 [1:13:39<10:12,  5.58it/s, lr=9.11e-6, step_loss=0.0207/18/2023 20:17:01 - INFO - __main__ - train loss is 6.877345389453694\n",
      "Steps:  77%|▊| 11580/15000 [1:13:39<10:12,  5.59it/s, lr=9.11e-6, step_loss=0.0707/18/2023 20:17:01 - INFO - __main__ - train loss is 6.9520319912116975\n",
      "Steps:  77%|▊| 11581/15000 [1:13:39<10:11,  5.59it/s, lr=9.11e-6, step_loss=0.0707/18/2023 20:17:01 - INFO - __main__ - train loss is 7.2046734902542084\n",
      "Steps:  77%|▊| 11582/15000 [1:13:39<10:11,  5.59it/s, lr=9.11e-6, step_loss=0.2507/18/2023 20:17:02 - INFO - __main__ - train loss is 7.257206081179902\n",
      "Steps:  77%|▊| 11583/15000 [1:13:39<10:11,  5.59it/s, lr=9.11e-6, step_loss=0.0507/18/2023 20:17:02 - INFO - __main__ - train loss is 7.350132106570527\n",
      "Steps:  77%|▊| 11584/15000 [1:13:40<10:11,  5.59it/s, lr=9.11e-6, step_loss=0.0907/18/2023 20:17:02 - INFO - __main__ - train loss is 7.477431206731126\n",
      "Steps:  77%|▊| 11585/15000 [1:13:40<10:10,  5.59it/s, lr=9.11e-6, step_loss=0.1207/18/2023 20:17:02 - INFO - __main__ - train loss is 7.524496908066794\n",
      "Steps:  77%|▊| 11586/15000 [1:13:40<10:10,  5.60it/s, lr=9.11e-6, step_loss=0.0407/18/2023 20:17:02 - INFO - __main__ - train loss is 8.020599062321708\n",
      "Steps:  77%|▊| 11587/15000 [1:13:40<10:09,  5.60it/s, lr=9.11e-6, step_loss=0.4907/18/2023 20:17:02 - INFO - __main__ - train loss is 8.055096472380683\n",
      "Steps:  77%|▊| 11588/15000 [1:13:40<10:09,  5.60it/s, lr=9.11e-6, step_loss=0.0307/18/2023 20:17:03 - INFO - __main__ - train loss is 8.092736351070926\n",
      "Steps:  77%|▊| 11589/15000 [1:13:41<10:09,  5.60it/s, lr=9.11e-6, step_loss=0.0307/18/2023 20:17:03 - INFO - __main__ - train loss is 9.013014304218814\n",
      "Steps:  77%|▊| 11590/15000 [1:13:41<10:09,  5.60it/s, lr=9.11e-6, step_loss=0.9207/18/2023 20:17:03 - INFO - __main__ - train loss is 9.030001365346834\n",
      "Steps:  77%|▊| 11591/15000 [1:13:41<10:09,  5.60it/s, lr=9.11e-6, step_loss=0.0107/18/2023 20:17:03 - INFO - __main__ - train loss is 9.256079056067392\n",
      "Steps:  77%|▊| 11592/15000 [1:13:41<10:08,  5.60it/s, lr=9.11e-6, step_loss=0.2207/18/2023 20:17:03 - INFO - __main__ - train loss is 9.343941845698282\n",
      "Steps:  77%|▊| 11593/15000 [1:13:41<10:08,  5.60it/s, lr=9.11e-6, step_loss=0.0807/18/2023 20:17:04 - INFO - __main__ - train loss is 9.355495269177482\n",
      "Steps:  77%|▊| 11594/15000 [1:13:41<10:08,  5.60it/s, lr=9.11e-6, step_loss=0.0107/18/2023 20:17:04 - INFO - __main__ - train loss is 10.079260642407462\n",
      "Steps:  77%|▊| 11595/15000 [1:13:42<10:08,  5.59it/s, lr=9.11e-6, step_loss=0.7207/18/2023 20:17:04 - INFO - __main__ - train loss is 10.81813400494866\n",
      "Steps:  77%|▊| 11596/15000 [1:13:42<10:07,  5.60it/s, lr=9.11e-6, step_loss=0.7307/18/2023 20:17:04 - INFO - __main__ - train loss is 10.865076551912352\n",
      "Steps:  77%|▊| 11597/15000 [1:13:42<10:07,  5.60it/s, lr=9.11e-6, step_loss=0.0407/18/2023 20:17:04 - INFO - __main__ - train loss is 11.61136997747235\n",
      "Steps:  77%|▊| 11598/15000 [1:13:42<10:07,  5.60it/s, lr=9.11e-6, step_loss=0.7407/18/2023 20:17:04 - INFO - __main__ - train loss is 12.157114038942382\n",
      "Steps:  77%|▊| 11599/15000 [1:13:42<10:08,  5.59it/s, lr=9.11e-6, step_loss=0.5407/18/2023 20:17:05 - INFO - __main__ - train loss is 12.247609595535323\n",
      "Steps:  77%|▊| 11600/15000 [1:13:43<10:10,  5.57it/s, lr=9.11e-6, step_loss=0.0907/18/2023 20:17:05 - INFO - __main__ - train loss is 12.287808800814673\n",
      "Steps:  77%|▊| 11601/15000 [1:13:43<10:09,  5.57it/s, lr=9.11e-6, step_loss=0.0407/18/2023 20:17:05 - INFO - __main__ - train loss is 12.39044106262736\n",
      "Steps:  77%|▊| 11602/15000 [1:13:43<10:09,  5.58it/s, lr=9.11e-6, step_loss=0.1007/18/2023 20:17:05 - INFO - __main__ - train loss is 12.428903723834082\n",
      "Steps:  77%|▊| 11603/15000 [1:13:43<10:08,  5.58it/s, lr=9.11e-6, step_loss=0.0307/18/2023 20:17:05 - INFO - __main__ - train loss is 12.455821693642065\n",
      "Steps:  77%|▊| 11604/15000 [1:13:43<10:07,  5.59it/s, lr=9.11e-6, step_loss=0.0207/18/2023 20:17:06 - INFO - __main__ - train loss is 12.458931543165818\n",
      "Steps:  77%|▊| 11605/15000 [1:13:43<10:07,  5.59it/s, lr=9.11e-6, step_loss=0.0007/18/2023 20:17:06 - INFO - __main__ - train loss is 13.138473607832566\n",
      "Steps:  77%|▊| 11606/15000 [1:13:44<10:06,  5.59it/s, lr=9.11e-6, step_loss=0.6807/18/2023 20:17:06 - INFO - __main__ - train loss is 13.721169509226456\n",
      "Steps:  77%|▊| 11607/15000 [1:13:44<10:12,  5.54it/s, lr=9.11e-6, step_loss=0.5807/18/2023 20:17:06 - INFO - __main__ - train loss is 14.155035563046113\n",
      "Steps:  77%|▊| 11608/15000 [1:13:44<10:10,  5.55it/s, lr=9.11e-6, step_loss=0.4307/18/2023 20:17:06 - INFO - __main__ - train loss is 14.708005853230134\n",
      "Steps:  77%|▊| 11609/15000 [1:13:44<10:09,  5.56it/s, lr=9.11e-6, step_loss=0.5507/18/2023 20:17:06 - INFO - __main__ - train loss is 14.78963052504696\n",
      "Steps:  77%|▊| 11610/15000 [1:13:44<10:08,  5.57it/s, lr=9.11e-6, step_loss=0.0807/18/2023 20:17:07 - INFO - __main__ - train loss is 15.203318290645257\n",
      "Steps:  77%|▊| 11611/15000 [1:13:45<10:11,  5.54it/s, lr=9.11e-6, step_loss=0.4107/18/2023 20:17:07 - INFO - __main__ - train loss is 15.231774103129283\n",
      "Steps:  77%|▊| 11612/15000 [1:13:45<10:09,  5.56it/s, lr=9.11e-6, step_loss=0.0207/18/2023 20:17:07 - INFO - __main__ - train loss is 15.42328516789712\n",
      "Steps:  77%|▊| 11613/15000 [1:13:45<10:13,  5.52it/s, lr=9.11e-6, step_loss=0.1907/18/2023 20:17:07 - INFO - __main__ - train loss is 15.429311594227329\n",
      "Steps:  77%|▊| 11614/15000 [1:13:45<10:15,  5.50it/s, lr=9.11e-6, step_loss=0.0007/18/2023 20:17:07 - INFO - __main__ - train loss is 15.442146057495847\n",
      "Steps:  77%|▊| 11615/15000 [1:13:45<10:17,  5.48it/s, lr=9.11e-6, step_loss=0.0107/18/2023 20:17:08 - INFO - __main__ - train loss is 15.44598611118272\n",
      "Steps:  77%|▊| 11616/15000 [1:13:45<10:13,  5.51it/s, lr=9.11e-6, step_loss=0.0007/18/2023 20:17:08 - INFO - __main__ - train loss is 15.76917912485078\n",
      "Steps:  77%|▊| 11617/15000 [1:13:46<10:11,  5.54it/s, lr=9.11e-6, step_loss=0.3207/18/2023 20:17:08 - INFO - __main__ - train loss is 15.818648547399789\n",
      "Steps:  77%|▊| 11618/15000 [1:13:46<10:09,  5.55it/s, lr=9.11e-6, step_loss=0.0407/18/2023 20:17:08 - INFO - __main__ - train loss is 15.82939212815836\n",
      "Steps:  77%|▊| 11619/15000 [1:13:46<10:07,  5.57it/s, lr=9.11e-6, step_loss=0.0107/18/2023 20:17:08 - INFO - __main__ - train loss is 16.058769159484655\n",
      "Steps:  77%|▊| 11620/15000 [1:13:46<10:05,  5.58it/s, lr=9.11e-6, step_loss=0.2207/18/2023 20:17:08 - INFO - __main__ - train loss is 16.066473425831646\n",
      "Steps:  77%|▊| 11621/15000 [1:13:46<10:05,  5.58it/s, lr=9.11e-6, step_loss=0.0007/18/2023 20:17:09 - INFO - __main__ - train loss is 16.219868631567806\n",
      "Steps:  77%|▊| 11622/15000 [1:13:46<10:04,  5.59it/s, lr=9.11e-6, step_loss=0.1507/18/2023 20:17:09 - INFO - __main__ - train loss is 16.501772017683834\n",
      "Steps:  77%|▊| 11623/15000 [1:13:47<10:10,  5.53it/s, lr=9.1e-6, step_loss=0.28207/18/2023 20:17:09 - INFO - __main__ - train loss is 17.085674138274044\n",
      "Steps:  77%|▊| 11624/15000 [1:13:47<10:12,  5.51it/s, lr=9.1e-6, step_loss=0.58407/18/2023 20:17:09 - INFO - __main__ - train loss is 17.27030879398808\n",
      "Steps:  78%|▊| 11625/15000 [1:13:47<10:12,  5.51it/s, lr=9.1e-6, step_loss=0.18507/18/2023 20:17:09 - INFO - __main__ - train loss is 17.434809864964336\n",
      "Steps:  78%|▊| 11626/15000 [1:13:47<10:08,  5.54it/s, lr=9.1e-6, step_loss=0.16507/18/2023 20:17:10 - INFO - __main__ - train loss is 17.972840250935405\n",
      "Steps:  78%|▊| 11627/15000 [1:13:47<10:06,  5.56it/s, lr=9.1e-6, step_loss=0.53807/18/2023 20:17:10 - INFO - __main__ - train loss is 18.03633821150288\n",
      "Steps:  78%|▊| 11628/15000 [1:13:48<10:05,  5.57it/s, lr=9.1e-6, step_loss=0.06307/18/2023 20:17:10 - INFO - __main__ - train loss is 18.069143989589065\n",
      "Steps:  78%|▊| 11629/15000 [1:13:48<10:04,  5.58it/s, lr=9.1e-6, step_loss=0.03207/18/2023 20:17:10 - INFO - __main__ - train loss is 18.155405902769417\n",
      "Steps:  78%|▊| 11630/15000 [1:13:48<10:03,  5.59it/s, lr=9.1e-6, step_loss=0.08607/18/2023 20:17:10 - INFO - __main__ - train loss is 18.169407084118575\n",
      "Steps:  78%|▊| 11631/15000 [1:13:48<10:02,  5.60it/s, lr=9.1e-6, step_loss=0.01407/18/2023 20:17:10 - INFO - __main__ - train loss is 18.57223917497322\n",
      "Steps:  78%|▊| 11632/15000 [1:13:48<10:01,  5.60it/s, lr=9.1e-6, step_loss=0.40307/18/2023 20:17:11 - INFO - __main__ - train loss is 18.58625309402123\n",
      "Steps:  78%|▊| 11633/15000 [1:13:48<10:01,  5.60it/s, lr=9.1e-6, step_loss=0.01407/18/2023 20:17:11 - INFO - __main__ - train loss is 18.647018978837878\n",
      "Steps:  78%|▊| 11634/15000 [1:13:49<10:00,  5.60it/s, lr=9.1e-6, step_loss=0.06007/18/2023 20:17:11 - INFO - __main__ - train loss is 19.008072207216173\n",
      "Steps:  78%|▊| 11635/15000 [1:13:49<10:00,  5.61it/s, lr=9.1e-6, step_loss=0.36107/18/2023 20:17:11 - INFO - __main__ - train loss is 19.05431820685044\n",
      "Steps:  78%|▊| 11636/15000 [1:13:49<09:59,  5.61it/s, lr=9.1e-6, step_loss=0.04607/18/2023 20:17:11 - INFO - __main__ - train loss is 19.456297325436026\n",
      "Steps:  78%|▊| 11637/15000 [1:13:49<09:59,  5.61it/s, lr=9.1e-6, step_loss=0.40207/18/2023 20:17:11 - INFO - __main__ - train loss is 19.469716558698565\n",
      "Steps:  78%|▊| 11638/15000 [1:13:49<09:59,  5.61it/s, lr=9.1e-6, step_loss=0.01307/18/2023 20:17:12 - INFO - __main__ - train loss is 19.767347047571093\n",
      "Steps:  78%|▊| 11639/15000 [1:13:50<09:58,  5.61it/s, lr=9.1e-6, step_loss=0.29807/18/2023 20:17:12 - INFO - __main__ - train loss is 19.79910140717402\n",
      "Steps:  78%|▊| 11640/15000 [1:13:50<13:20,  4.20it/s, lr=9.1e-6, step_loss=0.03107/18/2023 20:17:13 - INFO - __main__ - Per validation step average loss is 0.15072494745254517\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Cumulative validation average loss is 0.15072494745254517\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Per validation step average loss is 0.04942212998867035\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Cumulative validation average loss is 0.20014707744121552\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Per validation step average loss is 0.7347389459609985\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Cumulative validation average loss is 0.934886023402214\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Per validation step average loss is 0.007517354097217321\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Cumulative validation average loss is 0.9424033774994314\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Per validation step average loss is 0.05129123479127884\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Cumulative validation average loss is 0.9936946122907102\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Per validation step average loss is 0.024149201810359955\n",
      "07/18/2023 20:17:13 - INFO - __main__ - Cumulative validation average loss is 1.0178438141010702\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Per validation step average loss is 0.006832260638475418\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Cumulative validation average loss is 1.0246760747395456\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Per validation step average loss is 0.005844064988195896\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Cumulative validation average loss is 1.0305201397277415\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Per validation step average loss is 0.03419060632586479\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Cumulative validation average loss is 1.0647107460536063\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Per validation step average loss is 0.0023223860189318657\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Cumulative validation average loss is 1.0670331320725381\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Per validation step average loss is 0.03209485858678818\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Cumulative validation average loss is 1.0991279906593263\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Per validation step average loss is 0.014164591208100319\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Cumulative validation average loss is 1.1132925818674266\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Average validation loss for Epoch 119 is 0.09277438182228555\n",
      "07/18/2023 20:17:14 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:17:27 - INFO - __main__ - Starting epoch 120\n",
      "07/18/2023 20:17:28 - INFO - __main__ - train loss is 0.08666544407606125\n",
      "Steps:  78%|▊| 11641/15000 [1:14:06<4:39:30,  4.99s/it, lr=9.1e-6, step_loss=0.007/18/2023 20:17:29 - INFO - __main__ - train loss is 0.42534302920103073\n",
      "Steps:  78%|▊| 11642/15000 [1:14:07<3:24:38,  3.66s/it, lr=9.1e-6, step_loss=0.307/18/2023 20:17:29 - INFO - __main__ - train loss is 0.5901498720049858\n",
      "Steps:  78%|▊| 11643/15000 [1:14:07<2:32:20,  2.72s/it, lr=9.1e-6, step_loss=0.107/18/2023 20:17:30 - INFO - __main__ - train loss is 0.5926187578588724\n",
      "Steps:  78%|▊| 11644/15000 [1:14:08<1:55:41,  2.07s/it, lr=9.1e-6, step_loss=0.007/18/2023 20:17:30 - INFO - __main__ - train loss is 0.5991338333114982\n",
      "Steps:  78%|▊| 11645/15000 [1:14:08<1:30:08,  1.61s/it, lr=9.1e-6, step_loss=0.007/18/2023 20:17:31 - INFO - __main__ - train loss is 0.6957068582996726\n",
      "Steps:  78%|▊| 11646/15000 [1:14:09<1:12:11,  1.29s/it, lr=9.1e-6, step_loss=0.007/18/2023 20:17:31 - INFO - __main__ - train loss is 0.7011731341481209\n",
      "Steps:  78%|▊| 11647/15000 [1:14:09<59:34,  1.07s/it, lr=9.1e-6, step_loss=0.00507/18/2023 20:17:32 - INFO - __main__ - train loss is 1.1573906317353249\n",
      "Steps:  78%|▊| 11648/15000 [1:14:10<50:39,  1.10it/s, lr=9.1e-6, step_loss=0.45607/18/2023 20:17:32 - INFO - __main__ - train loss is 1.3007483407855034\n",
      "Steps:  78%|▊| 11649/15000 [1:14:10<44:32,  1.25it/s, lr=9.1e-6, step_loss=0.14307/18/2023 20:17:33 - INFO - __main__ - train loss is 1.3058423036709428\n",
      "Steps:  78%|▊| 11650/15000 [1:14:11<40:15,  1.39it/s, lr=9.1e-6, step_loss=0.00507/18/2023 20:17:34 - INFO - __main__ - train loss is 1.6219765776768327\n",
      "Steps:  78%|▊| 11651/15000 [1:14:11<37:12,  1.50it/s, lr=9.1e-6, step_loss=0.31607/18/2023 20:17:34 - INFO - __main__ - train loss is 1.9109679693356156\n",
      "Steps:  78%|▊| 11652/15000 [1:14:12<35:15,  1.58it/s, lr=9.1e-6, step_loss=0.28907/18/2023 20:17:35 - INFO - __main__ - train loss is 2.111807801760733\n",
      "Steps:  78%|▊| 11653/15000 [1:14:13<33:44,  1.65it/s, lr=9.1e-6, step_loss=0.20107/18/2023 20:17:35 - INFO - __main__ - train loss is 2.1163397450000048\n",
      "Steps:  78%|▊| 11654/15000 [1:14:13<32:34,  1.71it/s, lr=9.1e-6, step_loss=0.00407/18/2023 20:17:36 - INFO - __main__ - train loss is 2.1732462886720896\n",
      "Steps:  78%|▊| 11655/15000 [1:14:14<31:46,  1.75it/s, lr=9.1e-6, step_loss=0.05607/18/2023 20:17:36 - INFO - __main__ - train loss is 2.4731288198381662\n",
      "Steps:  78%|█▌| 11656/15000 [1:14:14<31:15,  1.78it/s, lr=9.1e-6, step_loss=0.3]07/18/2023 20:17:37 - INFO - __main__ - train loss is 2.5178438555449247\n",
      "Steps:  78%|▊| 11657/15000 [1:14:15<30:54,  1.80it/s, lr=9.1e-6, step_loss=0.04407/18/2023 20:17:37 - INFO - __main__ - train loss is 2.7442133259028196\n",
      "Steps:  78%|▊| 11658/15000 [1:14:15<30:35,  1.82it/s, lr=9.1e-6, step_loss=0.22607/18/2023 20:17:38 - INFO - __main__ - train loss is 2.746989171486348\n",
      "Steps:  78%|▊| 11659/15000 [1:14:16<30:41,  1.81it/s, lr=9.1e-6, step_loss=0.00207/18/2023 20:17:38 - INFO - __main__ - train loss is 2.8292954522185028\n",
      "Steps:  78%|▊| 11660/15000 [1:14:16<30:38,  1.82it/s, lr=9.1e-6, step_loss=0.08207/18/2023 20:17:39 - INFO - __main__ - train loss is 3.132952149491757\n",
      "Steps:  78%|▊| 11661/15000 [1:14:17<30:27,  1.83it/s, lr=9.1e-6, step_loss=0.30407/18/2023 20:17:40 - INFO - __main__ - train loss is 3.1430796063505113\n",
      "Steps:  78%|▊| 11662/15000 [1:14:17<30:27,  1.83it/s, lr=9.1e-6, step_loss=0.01007/18/2023 20:17:40 - INFO - __main__ - train loss is 3.330378574784845\n",
      "Steps:  78%|▊| 11663/15000 [1:14:18<30:22,  1.83it/s, lr=9.1e-6, step_loss=0.18707/18/2023 20:17:41 - INFO - __main__ - train loss is 3.5690914816223085\n",
      "Steps:  78%|▊| 11664/15000 [1:14:18<30:19,  1.83it/s, lr=9.1e-6, step_loss=0.23907/18/2023 20:17:41 - INFO - __main__ - train loss is 3.6749764955602586\n",
      "Steps:  78%|▊| 11665/15000 [1:14:19<30:25,  1.83it/s, lr=9.1e-6, step_loss=0.10607/18/2023 20:17:42 - INFO - __main__ - train loss is 3.67640337953344\n",
      "Steps:  78%|▊| 11666/15000 [1:14:20<30:26,  1.83it/s, lr=9.1e-6, step_loss=0.00107/18/2023 20:17:42 - INFO - __main__ - train loss is 3.6925448761321604\n",
      "Steps:  78%|▊| 11667/15000 [1:14:20<30:31,  1.82it/s, lr=9.1e-6, step_loss=0.01607/18/2023 20:17:43 - INFO - __main__ - train loss is 3.6988256140612066\n",
      "Steps:  78%|▊| 11668/15000 [1:14:21<30:39,  1.81it/s, lr=9.1e-6, step_loss=0.00607/18/2023 20:17:43 - INFO - __main__ - train loss is 3.7186115621589124\n",
      "Steps:  78%|▊| 11669/15000 [1:14:21<30:54,  1.80it/s, lr=9.1e-6, step_loss=0.01907/18/2023 20:17:44 - INFO - __main__ - train loss is 3.7560221306048334\n",
      "Steps:  78%|▊| 11670/15000 [1:14:22<31:02,  1.79it/s, lr=9.1e-6, step_loss=0.03707/18/2023 20:17:44 - INFO - __main__ - train loss is 3.762387383263558\n",
      "Steps:  78%|▊| 11671/15000 [1:14:22<31:02,  1.79it/s, lr=9.1e-6, step_loss=0.00607/18/2023 20:17:45 - INFO - __main__ - train loss is 4.046467769425362\n",
      "Steps:  78%|▊| 11672/15000 [1:14:23<30:59,  1.79it/s, lr=9.1e-6, step_loss=0.28407/18/2023 20:17:46 - INFO - __main__ - train loss is 4.094191427808255\n",
      "Steps:  78%|▊| 11673/15000 [1:14:23<30:56,  1.79it/s, lr=9.1e-6, step_loss=0.04707/18/2023 20:17:46 - INFO - __main__ - train loss is 4.1011349386535585\n",
      "Steps:  78%|▊| 11674/15000 [1:14:24<31:12,  1.78it/s, lr=9.1e-6, step_loss=0.00607/18/2023 20:17:47 - INFO - __main__ - train loss is 4.23340575164184\n",
      "Steps:  78%|▊| 11675/15000 [1:14:25<31:11,  1.78it/s, lr=9.1e-6, step_loss=0.13207/18/2023 20:17:47 - INFO - __main__ - train loss is 4.2376986760646105\n",
      "Steps:  78%|▊| 11676/15000 [1:14:25<31:11,  1.78it/s, lr=9.1e-6, step_loss=0.00407/18/2023 20:17:48 - INFO - __main__ - train loss is 4.516793938353658\n",
      "Steps:  78%|▊| 11677/15000 [1:14:26<31:12,  1.77it/s, lr=9.1e-6, step_loss=0.27907/18/2023 20:17:48 - INFO - __main__ - train loss is 4.786242516711354\n",
      "Steps:  78%|▊| 11678/15000 [1:14:26<31:02,  1.78it/s, lr=9.1e-6, step_loss=0.26907/18/2023 20:17:49 - INFO - __main__ - train loss is 4.794461479410529\n",
      "Steps:  78%|▊| 11679/15000 [1:14:27<31:00,  1.78it/s, lr=9.1e-6, step_loss=0.00807/18/2023 20:17:50 - INFO - __main__ - train loss is 4.872370099648833\n",
      "Steps:  78%|▊| 11680/15000 [1:14:27<30:51,  1.79it/s, lr=9.1e-6, step_loss=0.07707/18/2023 20:17:50 - INFO - __main__ - train loss is 5.4899126049131155\n",
      "Steps:  78%|▊| 11681/15000 [1:14:28<30:43,  1.80it/s, lr=9.1e-6, step_loss=0.61807/18/2023 20:17:51 - INFO - __main__ - train loss is 5.497978603467345\n",
      "Steps:  78%|▊| 11682/15000 [1:14:29<30:33,  1.81it/s, lr=9.1e-6, step_loss=0.00807/18/2023 20:17:51 - INFO - __main__ - train loss is 5.5458937380462885\n",
      "Steps:  78%|▊| 11683/15000 [1:14:29<30:19,  1.82it/s, lr=9.1e-6, step_loss=0.04707/18/2023 20:17:52 - INFO - __main__ - train loss is 5.664334440603852\n",
      "Steps:  78%|▊| 11684/15000 [1:14:30<30:21,  1.82it/s, lr=9.1e-6, step_loss=0.11807/18/2023 20:17:52 - INFO - __main__ - train loss is 5.673220269382\n",
      "Steps:  78%|▊| 11685/15000 [1:14:30<30:16,  1.82it/s, lr=9.1e-6, step_loss=0.00807/18/2023 20:17:53 - INFO - __main__ - train loss is 5.678424104116857\n",
      "Steps:  78%|▊| 11686/15000 [1:14:31<30:16,  1.82it/s, lr=9.1e-6, step_loss=0.00507/18/2023 20:17:53 - INFO - __main__ - train loss is 5.744574247859418\n",
      "Steps:  78%|▊| 11687/15000 [1:14:31<30:09,  1.83it/s, lr=9.1e-6, step_loss=0.06607/18/2023 20:17:54 - INFO - __main__ - train loss is 5.826885967515409\n",
      "Steps:  78%|▊| 11688/15000 [1:14:32<30:00,  1.84it/s, lr=9.1e-6, step_loss=0.08207/18/2023 20:17:54 - INFO - __main__ - train loss is 5.830502484925091\n",
      "Steps:  78%|▊| 11689/15000 [1:14:32<29:57,  1.84it/s, lr=9.1e-6, step_loss=0.00307/18/2023 20:17:55 - INFO - __main__ - train loss is 5.8749457793310285\n",
      "Steps:  78%|▊| 11690/15000 [1:14:33<29:55,  1.84it/s, lr=9.09e-6, step_loss=0.0407/18/2023 20:17:56 - INFO - __main__ - train loss is 6.119516585953534\n",
      "Steps:  78%|▊| 11691/15000 [1:14:33<29:56,  1.84it/s, lr=9.09e-6, step_loss=0.2407/18/2023 20:17:56 - INFO - __main__ - train loss is 6.717643295414746\n",
      "Steps:  78%|▊| 11692/15000 [1:14:34<29:51,  1.85it/s, lr=9.09e-6, step_loss=0.5907/18/2023 20:17:57 - INFO - __main__ - train loss is 6.7633105562999845\n",
      "Steps:  78%|▊| 11693/15000 [1:14:34<29:43,  1.85it/s, lr=9.09e-6, step_loss=0.0407/18/2023 20:17:57 - INFO - __main__ - train loss is 6.815695879049599\n",
      "Steps:  78%|▊| 11694/15000 [1:14:35<29:43,  1.85it/s, lr=9.09e-6, step_loss=0.0507/18/2023 20:17:58 - INFO - __main__ - train loss is 6.817584902513772\n",
      "Steps:  78%|▊| 11695/15000 [1:14:36<29:44,  1.85it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:17:58 - INFO - __main__ - train loss is 6.858841240871698\n",
      "Steps:  78%|▊| 11696/15000 [1:14:36<30:02,  1.83it/s, lr=9.09e-6, step_loss=0.0407/18/2023 20:17:59 - INFO - __main__ - train loss is 6.8936731037683785\n",
      "Steps:  78%|▊| 11697/15000 [1:14:37<30:02,  1.83it/s, lr=9.09e-6, step_loss=0.0307/18/2023 20:17:59 - INFO - __main__ - train loss is 7.14845920773223\n",
      "Steps:  78%|▊| 11698/15000 [1:14:37<29:57,  1.84it/s, lr=9.09e-6, step_loss=0.2507/18/2023 20:18:00 - INFO - __main__ - train loss is 7.155567075591534\n",
      "Steps:  78%|▊| 11699/15000 [1:14:38<29:52,  1.84it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:00 - INFO - __main__ - train loss is 7.1884344588033855\n",
      "Steps:  78%|▊| 11700/15000 [1:14:38<29:49,  1.84it/s, lr=9.09e-6, step_loss=0.0307/18/2023 20:18:01 - INFO - __main__ - train loss is 7.217045407276601\n",
      "Steps:  78%|▊| 11701/15000 [1:14:39<29:58,  1.83it/s, lr=9.09e-6, step_loss=0.0207/18/2023 20:18:02 - INFO - __main__ - train loss is 7.260661106090993\n",
      "Steps:  78%|▊| 11702/15000 [1:14:39<31:30,  1.74it/s, lr=9.09e-6, step_loss=0.0407/18/2023 20:18:02 - INFO - __main__ - train loss is 7.280007503461093\n",
      "Steps:  78%|▊| 11703/15000 [1:14:40<33:35,  1.64it/s, lr=9.09e-6, step_loss=0.0107/18/2023 20:18:03 - INFO - __main__ - train loss is 7.595820508431643\n",
      "Steps:  78%|▊| 11704/15000 [1:14:41<32:42,  1.68it/s, lr=9.09e-6, step_loss=0.3107/18/2023 20:18:03 - INFO - __main__ - train loss is 7.611168035771698\n",
      "Steps:  78%|▊| 11705/15000 [1:14:41<31:58,  1.72it/s, lr=9.09e-6, step_loss=0.0107/18/2023 20:18:04 - INFO - __main__ - train loss is 7.690462553407997\n",
      "Steps:  78%|▊| 11706/15000 [1:14:42<31:24,  1.75it/s, lr=9.09e-6, step_loss=0.0707/18/2023 20:18:05 - INFO - __main__ - train loss is 7.862657913472503\n",
      "Steps:  78%|▊| 11707/15000 [1:14:42<31:05,  1.77it/s, lr=9.09e-6, step_loss=0.1707/18/2023 20:18:05 - INFO - __main__ - train loss is 7.926017442252487\n",
      "Steps:  78%|▊| 11708/15000 [1:14:43<30:38,  1.79it/s, lr=9.09e-6, step_loss=0.0607/18/2023 20:18:06 - INFO - __main__ - train loss is 8.314903744962066\n",
      "Steps:  78%|▊| 11709/15000 [1:14:43<30:20,  1.81it/s, lr=9.09e-6, step_loss=0.3807/18/2023 20:18:06 - INFO - __main__ - train loss is 8.492736080195755\n",
      "Steps:  78%|▊| 11710/15000 [1:14:44<30:11,  1.82it/s, lr=9.09e-6, step_loss=0.1707/18/2023 20:18:07 - INFO - __main__ - train loss is 8.58259024610743\n",
      "Steps:  78%|▊| 11711/15000 [1:14:45<30:02,  1.83it/s, lr=9.09e-6, step_loss=0.0807/18/2023 20:18:07 - INFO - __main__ - train loss is 8.74710246315226\n",
      "Steps:  78%|▊| 11712/15000 [1:14:45<29:51,  1.84it/s, lr=9.09e-6, step_loss=0.1607/18/2023 20:18:08 - INFO - __main__ - train loss is 8.76093946537003\n",
      "Steps:  78%|▊| 11713/15000 [1:14:46<29:43,  1.84it/s, lr=9.09e-6, step_loss=0.0107/18/2023 20:18:08 - INFO - __main__ - train loss is 9.530889795627445\n",
      "Steps:  78%|▊| 11714/15000 [1:14:46<29:48,  1.84it/s, lr=9.09e-6, step_loss=0.7707/18/2023 20:18:09 - INFO - __main__ - train loss is 9.537518739700317\n",
      "Steps:  78%|▊| 11715/15000 [1:14:47<29:48,  1.84it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:09 - INFO - __main__ - train loss is 9.553403034806252\n",
      "Steps:  78%|▊| 11716/15000 [1:14:47<29:41,  1.84it/s, lr=9.09e-6, step_loss=0.0107/18/2023 20:18:10 - INFO - __main__ - train loss is 9.556559856515378\n",
      "Steps:  78%|▊| 11717/15000 [1:14:48<29:46,  1.84it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:10 - INFO - __main__ - train loss is 10.115588660817593\n",
      "Steps:  78%|▊| 11718/15000 [1:14:48<29:47,  1.84it/s, lr=9.09e-6, step_loss=0.5507/18/2023 20:18:11 - INFO - __main__ - train loss is 10.463721181731671\n",
      "Steps:  78%|▊| 11719/15000 [1:14:49<29:49,  1.83it/s, lr=9.09e-6, step_loss=0.3407/18/2023 20:18:12 - INFO - __main__ - train loss is 10.50789515255019\n",
      "Steps:  78%|▊| 11720/15000 [1:14:49<29:49,  1.83it/s, lr=9.09e-6, step_loss=0.0407/18/2023 20:18:12 - INFO - __main__ - train loss is 10.550701830070466\n",
      "Steps:  78%|▊| 11721/15000 [1:14:50<29:41,  1.84it/s, lr=9.09e-6, step_loss=0.0407/18/2023 20:18:13 - INFO - __main__ - train loss is 11.112269315402955\n",
      "Steps:  78%|▊| 11722/15000 [1:14:51<29:38,  1.84it/s, lr=9.09e-6, step_loss=0.5607/18/2023 20:18:13 - INFO - __main__ - train loss is 11.2326559307985\n",
      "Steps:  78%|▊| 11723/15000 [1:14:51<29:32,  1.85it/s, lr=9.09e-6, step_loss=0.1207/18/2023 20:18:14 - INFO - __main__ - train loss is 11.634758371394128\n",
      "Steps:  78%|▊| 11724/15000 [1:14:52<29:31,  1.85it/s, lr=9.09e-6, step_loss=0.4007/18/2023 20:18:14 - INFO - __main__ - train loss is 11.968795973341912\n",
      "Steps:  78%|▊| 11725/15000 [1:14:52<29:27,  1.85it/s, lr=9.09e-6, step_loss=0.3307/18/2023 20:18:15 - INFO - __main__ - train loss is 11.973063868004829\n",
      "Steps:  78%|▊| 11726/15000 [1:14:53<29:29,  1.85it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:15 - INFO - __main__ - train loss is 11.97445318440441\n",
      "Steps:  78%|▊| 11727/15000 [1:14:53<29:31,  1.85it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:16 - INFO - __main__ - train loss is 12.029413628973998\n",
      "Steps:  78%|▊| 11728/15000 [1:14:54<29:34,  1.84it/s, lr=9.09e-6, step_loss=0.0507/18/2023 20:18:16 - INFO - __main__ - train loss is 12.151258784928359\n",
      "Steps:  78%|▊| 11729/15000 [1:14:54<29:34,  1.84it/s, lr=9.09e-6, step_loss=0.1207/18/2023 20:18:17 - INFO - __main__ - train loss is 12.3995211009169\n",
      "Steps:  78%|▊| 11730/15000 [1:14:55<29:32,  1.85it/s, lr=9.09e-6, step_loss=0.2407/18/2023 20:18:18 - INFO - __main__ - train loss is 12.403895676718093\n",
      "Steps:  78%|▊| 11731/15000 [1:14:55<29:34,  1.84it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:18 - INFO - __main__ - train loss is 13.02987319289241\n",
      "Steps:  78%|▊| 11732/15000 [1:14:56<29:34,  1.84it/s, lr=9.09e-6, step_loss=0.6207/18/2023 20:18:19 - INFO - __main__ - train loss is 13.411295176134445\n",
      "Steps:  78%|▊| 11733/15000 [1:14:56<29:32,  1.84it/s, lr=9.09e-6, step_loss=0.3807/18/2023 20:18:19 - INFO - __main__ - train loss is 13.579702020273544\n",
      "Steps:  78%|▊| 11734/15000 [1:14:57<29:33,  1.84it/s, lr=9.09e-6, step_loss=0.1607/18/2023 20:18:20 - INFO - __main__ - train loss is 14.20762330351863\n",
      "Steps:  78%|▊| 11735/15000 [1:14:58<29:28,  1.85it/s, lr=9.09e-6, step_loss=0.6207/18/2023 20:18:20 - INFO - __main__ - train loss is 14.307228632853366\n",
      "Steps:  78%|▊| 11736/15000 [1:14:58<29:28,  1.85it/s, lr=9.09e-6, step_loss=0.0907/18/2023 20:18:21 - INFO - __main__ - train loss is 14.358850263641216\n",
      "Steps:  78%|▊| 11737/15000 [1:14:59<35:39,  1.53it/s, lr=9.09e-6, step_loss=0.0507/18/2023 20:18:22 - INFO - __main__ - Per validation step average loss is 0.26552557945251465\n",
      "07/18/2023 20:18:22 - INFO - __main__ - Cumulative validation average loss is 0.26552557945251465\n",
      "07/18/2023 20:18:22 - INFO - __main__ - Per validation step average loss is 0.12517184019088745\n",
      "07/18/2023 20:18:22 - INFO - __main__ - Cumulative validation average loss is 0.3906974196434021\n",
      "07/18/2023 20:18:22 - INFO - __main__ - Per validation step average loss is 0.13028690218925476\n",
      "07/18/2023 20:18:22 - INFO - __main__ - Cumulative validation average loss is 0.5209843218326569\n",
      "07/18/2023 20:18:22 - INFO - __main__ - Per validation step average loss is 0.04460504651069641\n",
      "07/18/2023 20:18:22 - INFO - __main__ - Cumulative validation average loss is 0.5655893683433533\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Per validation step average loss is 0.059159472584724426\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Cumulative validation average loss is 0.6247488409280777\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Per validation step average loss is 0.010826380923390388\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Cumulative validation average loss is 0.6355752218514681\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Per validation step average loss is 0.003068068064749241\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Cumulative validation average loss is 0.6386432899162173\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Per validation step average loss is 0.001994970254600048\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Cumulative validation average loss is 0.6406382601708174\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Per validation step average loss is 0.052235186100006104\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Cumulative validation average loss is 0.6928734462708235\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Per validation step average loss is 0.0026167272590100765\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Cumulative validation average loss is 0.6954901735298336\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Per validation step average loss is 0.007298355922102928\n",
      "07/18/2023 20:18:23 - INFO - __main__ - Cumulative validation average loss is 0.7027885294519365\n",
      "07/18/2023 20:18:24 - INFO - __main__ - Per validation step average loss is 0.05822288617491722\n",
      "07/18/2023 20:18:24 - INFO - __main__ - Cumulative validation average loss is 0.7610114156268537\n",
      "07/18/2023 20:18:24 - INFO - __main__ - Average validation loss for Epoch 120 is 0.06341761796890448\n",
      "07/18/2023 20:18:24 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:18:37 - INFO - __main__ - Starting epoch 121\n",
      "07/18/2023 20:18:37 - INFO - __main__ - train loss is 0.2559072971343994\n",
      "Steps:  78%|▊| 11738/15000 [1:15:15<4:50:10,  5.34s/it, lr=9.09e-6, step_loss=0.07/18/2023 20:18:38 - INFO - __main__ - train loss is 0.26328146643936634\n",
      "Steps:  78%|▊| 11739/15000 [1:15:15<3:26:03,  3.79s/it, lr=9.09e-6, step_loss=0.07/18/2023 20:18:38 - INFO - __main__ - train loss is 0.2651606402359903\n",
      "Steps:  78%|▊| 11740/15000 [1:15:16<2:27:08,  2.71s/it, lr=9.09e-6, step_loss=0.07/18/2023 20:18:38 - INFO - __main__ - train loss is 0.29952639853581786\n",
      "Steps:  78%|▊| 11741/15000 [1:15:16<1:45:52,  1.95s/it, lr=9.09e-6, step_loss=0.07/18/2023 20:18:38 - INFO - __main__ - train loss is 0.3700510016642511\n",
      "Steps:  78%|▊| 11742/15000 [1:15:16<1:17:00,  1.42s/it, lr=9.09e-6, step_loss=0.07/18/2023 20:18:38 - INFO - __main__ - train loss is 0.38685583462938666\n",
      "Steps:  78%|▊| 11743/15000 [1:15:16<56:48,  1.05s/it, lr=9.09e-6, step_loss=0.0107/18/2023 20:18:38 - INFO - __main__ - train loss is 0.38892043894156814\n",
      "Steps:  78%|▊| 11744/15000 [1:15:16<42:38,  1.27it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:39 - INFO - __main__ - train loss is 0.4807491726242006\n",
      "Steps:  78%|▊| 11745/15000 [1:15:17<32:43,  1.66it/s, lr=9.09e-6, step_loss=0.0907/18/2023 20:18:39 - INFO - __main__ - train loss is 0.610259426292032\n",
      "Steps:  78%|▊| 11746/15000 [1:15:17<25:47,  2.10it/s, lr=9.09e-6, step_loss=0.1307/18/2023 20:18:39 - INFO - __main__ - train loss is 0.8762635118328035\n",
      "Steps:  78%|▊| 11747/15000 [1:15:17<20:56,  2.59it/s, lr=9.09e-6, step_loss=0.2607/18/2023 20:18:39 - INFO - __main__ - train loss is 1.2897679931484163\n",
      "Steps:  78%|▊| 11748/15000 [1:15:17<17:38,  3.07it/s, lr=9.09e-6, step_loss=0.4107/18/2023 20:18:39 - INFO - __main__ - train loss is 1.6238970286212862\n",
      "Steps:  78%|▊| 11749/15000 [1:15:17<15:21,  3.53it/s, lr=9.09e-6, step_loss=0.3307/18/2023 20:18:40 - INFO - __main__ - train loss is 1.6303740958683193\n",
      "Steps:  78%|▊| 11750/15000 [1:15:17<13:39,  3.97it/s, lr=9.09e-6, step_loss=0.0007/18/2023 20:18:40 - INFO - __main__ - train loss is 1.9839071850292385\n",
      "Steps:  78%|▊| 11751/15000 [1:15:18<12:26,  4.35it/s, lr=9.09e-6, step_loss=0.3507/18/2023 20:18:40 - INFO - __main__ - train loss is 2.2224953989498317\n",
      "Steps:  78%|▊| 11752/15000 [1:15:18<11:35,  4.67it/s, lr=9.09e-6, step_loss=0.2307/18/2023 20:18:40 - INFO - __main__ - train loss is 2.6403641323558986\n",
      "Steps:  78%|▊| 11753/15000 [1:15:18<10:59,  4.93it/s, lr=9.09e-6, step_loss=0.4107/18/2023 20:18:40 - INFO - __main__ - train loss is 3.283838353585452\n",
      "Steps:  78%|▊| 11754/15000 [1:15:18<10:34,  5.12it/s, lr=9.09e-6, step_loss=0.6407/18/2023 20:18:40 - INFO - __main__ - train loss is 3.3236417989246547\n",
      "Steps:  78%|▊| 11755/15000 [1:15:18<10:17,  5.26it/s, lr=9.09e-6, step_loss=0.0307/18/2023 20:18:41 - INFO - __main__ - train loss is 3.369601174723357\n",
      "Steps:  78%|▊| 11756/15000 [1:15:19<10:04,  5.36it/s, lr=9.09e-6, step_loss=0.0407/18/2023 20:18:41 - INFO - __main__ - train loss is 3.603771075140685\n",
      "Steps:  78%|▊| 11757/15000 [1:15:19<09:56,  5.44it/s, lr=9.08e-6, step_loss=0.2307/18/2023 20:18:41 - INFO - __main__ - train loss is 3.7538326526992023\n",
      "Steps:  78%|▊| 11758/15000 [1:15:19<09:51,  5.48it/s, lr=9.08e-6, step_loss=0.1507/18/2023 20:18:41 - INFO - __main__ - train loss is 3.9923303867690265\n",
      "Steps:  78%|▊| 11759/15000 [1:15:19<09:47,  5.52it/s, lr=9.08e-6, step_loss=0.2307/18/2023 20:18:41 - INFO - __main__ - train loss is 4.1007399703375995\n",
      "Steps:  78%|▊| 11760/15000 [1:15:19<09:43,  5.55it/s, lr=9.08e-6, step_loss=0.1007/18/2023 20:18:42 - INFO - __main__ - train loss is 4.142704940866679\n",
      "Steps:  78%|▊| 11761/15000 [1:15:19<09:44,  5.54it/s, lr=9.08e-6, step_loss=0.0407/18/2023 20:18:42 - INFO - __main__ - train loss is 4.627753950189799\n",
      "Steps:  78%|▊| 11762/15000 [1:15:20<09:47,  5.51it/s, lr=9.08e-6, step_loss=0.4807/18/2023 20:18:42 - INFO - __main__ - train loss is 4.796779922675341\n",
      "Steps:  78%|▊| 11763/15000 [1:15:20<09:57,  5.42it/s, lr=9.08e-6, step_loss=0.1607/18/2023 20:18:42 - INFO - __main__ - train loss is 4.917460277210921\n",
      "Steps:  78%|▊| 11764/15000 [1:15:20<10:08,  5.32it/s, lr=9.08e-6, step_loss=0.1207/18/2023 20:18:42 - INFO - __main__ - train loss is 4.939829550217837\n",
      "Steps:  78%|▊| 11765/15000 [1:15:20<10:14,  5.27it/s, lr=9.08e-6, step_loss=0.0207/18/2023 20:18:42 - INFO - __main__ - train loss is 5.043605044018477\n",
      "Steps:  78%|▊| 11766/15000 [1:15:20<10:18,  5.23it/s, lr=9.08e-6, step_loss=0.1007/18/2023 20:18:43 - INFO - __main__ - train loss is 5.313972338568419\n",
      "Steps:  78%|▊| 11767/15000 [1:15:21<10:21,  5.20it/s, lr=9.08e-6, step_loss=0.2707/18/2023 20:18:43 - INFO - __main__ - train loss is 5.31593082845211\n",
      "Steps:  78%|▊| 11768/15000 [1:15:21<10:23,  5.18it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:43 - INFO - __main__ - train loss is 5.341502690687776\n",
      "Steps:  78%|▊| 11769/15000 [1:15:21<10:25,  5.16it/s, lr=9.08e-6, step_loss=0.0207/18/2023 20:18:43 - INFO - __main__ - train loss is 5.4592760521918535\n",
      "Steps:  78%|▊| 11770/15000 [1:15:21<10:28,  5.14it/s, lr=9.08e-6, step_loss=0.1107/18/2023 20:18:43 - INFO - __main__ - train loss is 5.741106541827321\n",
      "Steps:  78%|▊| 11771/15000 [1:15:21<10:24,  5.17it/s, lr=9.08e-6, step_loss=0.2807/18/2023 20:18:44 - INFO - __main__ - train loss is 5.797832762822509\n",
      "Steps:  78%|▊| 11772/15000 [1:15:22<10:25,  5.16it/s, lr=9.08e-6, step_loss=0.0507/18/2023 20:18:44 - INFO - __main__ - train loss is 5.823915472254157\n",
      "Steps:  78%|▊| 11773/15000 [1:15:22<10:26,  5.15it/s, lr=9.08e-6, step_loss=0.0207/18/2023 20:18:44 - INFO - __main__ - train loss is 6.034126153215766\n",
      "Steps:  78%|▊| 11774/15000 [1:15:22<10:27,  5.14it/s, lr=9.08e-6, step_loss=0.2107/18/2023 20:18:44 - INFO - __main__ - train loss is 6.037346433848143\n",
      "Steps:  78%|▊| 11775/15000 [1:15:22<10:27,  5.14it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:44 - INFO - __main__ - train loss is 6.056675447151065\n",
      "Steps:  79%|▊| 11776/15000 [1:15:22<10:23,  5.17it/s, lr=9.08e-6, step_loss=0.0107/18/2023 20:18:45 - INFO - __main__ - train loss is 6.122660068795085\n",
      "Steps:  79%|▊| 11777/15000 [1:15:23<10:15,  5.24it/s, lr=9.08e-6, step_loss=0.0607/18/2023 20:18:45 - INFO - __main__ - train loss is 6.319805948063731\n",
      "Steps:  79%|▊| 11778/15000 [1:15:23<10:15,  5.23it/s, lr=9.08e-6, step_loss=0.1907/18/2023 20:18:45 - INFO - __main__ - train loss is 6.54243297688663\n",
      "Steps:  79%|▊| 11779/15000 [1:15:23<10:18,  5.20it/s, lr=9.08e-6, step_loss=0.2207/18/2023 20:18:45 - INFO - __main__ - train loss is 6.54686828609556\n",
      "Steps:  79%|▊| 11780/15000 [1:15:23<10:12,  5.26it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:45 - INFO - __main__ - train loss is 6.843342355452478\n",
      "Steps:  79%|▊| 11781/15000 [1:15:23<10:16,  5.22it/s, lr=9.08e-6, step_loss=0.2907/18/2023 20:18:46 - INFO - __main__ - train loss is 6.8809512024745345\n",
      "Steps:  79%|▊| 11782/15000 [1:15:23<10:18,  5.20it/s, lr=9.08e-6, step_loss=0.0307/18/2023 20:18:46 - INFO - __main__ - train loss is 7.108577466569841\n",
      "Steps:  79%|▊| 11783/15000 [1:15:24<10:23,  5.16it/s, lr=9.08e-6, step_loss=0.2207/18/2023 20:18:46 - INFO - __main__ - train loss is 7.112968584522605\n",
      "Steps:  79%|▊| 11784/15000 [1:15:24<10:27,  5.13it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:46 - INFO - __main__ - train loss is 7.158944947645068\n",
      "Steps:  79%|▊| 11785/15000 [1:15:24<10:27,  5.12it/s, lr=9.08e-6, step_loss=0.0407/18/2023 20:18:46 - INFO - __main__ - train loss is 7.724264187738299\n",
      "Steps:  79%|▊| 11786/15000 [1:15:24<10:17,  5.20it/s, lr=9.08e-6, step_loss=0.5607/18/2023 20:18:47 - INFO - __main__ - train loss is 8.393449587747455\n",
      "Steps:  79%|▊| 11787/15000 [1:15:24<10:07,  5.29it/s, lr=9.08e-6, step_loss=0.6607/18/2023 20:18:47 - INFO - __main__ - train loss is 8.711156828328967\n",
      "Steps:  79%|▊| 11788/15000 [1:15:25<10:06,  5.29it/s, lr=9.08e-6, step_loss=0.3107/18/2023 20:18:47 - INFO - __main__ - train loss is 8.754109112545848\n",
      "Steps:  79%|▊| 11789/15000 [1:15:25<10:04,  5.31it/s, lr=9.08e-6, step_loss=0.0407/18/2023 20:18:47 - INFO - __main__ - train loss is 8.763110604137182\n",
      "Steps:  79%|▊| 11790/15000 [1:15:25<10:03,  5.32it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:47 - INFO - __main__ - train loss is 8.861649882048368\n",
      "Steps:  79%|▊| 11791/15000 [1:15:25<10:05,  5.30it/s, lr=9.08e-6, step_loss=0.0907/18/2023 20:18:47 - INFO - __main__ - train loss is 8.873368700034916\n",
      "Steps:  79%|▊| 11792/15000 [1:15:25<10:05,  5.29it/s, lr=9.08e-6, step_loss=0.0107/18/2023 20:18:48 - INFO - __main__ - train loss is 9.813459952361882\n",
      "Steps:  79%|▊| 11793/15000 [1:15:26<09:58,  5.36it/s, lr=9.08e-6, step_loss=0.9407/18/2023 20:18:48 - INFO - __main__ - train loss is 9.982814003713429\n",
      "Steps:  79%|▊| 11794/15000 [1:15:26<09:57,  5.37it/s, lr=9.08e-6, step_loss=0.1607/18/2023 20:18:48 - INFO - __main__ - train loss is 10.14925238955766\n",
      "Steps:  79%|▊| 11795/15000 [1:15:26<09:57,  5.36it/s, lr=9.08e-6, step_loss=0.1607/18/2023 20:18:48 - INFO - __main__ - train loss is 10.17433654051274\n",
      "Steps:  79%|▊| 11796/15000 [1:15:26<09:52,  5.41it/s, lr=9.08e-6, step_loss=0.0207/18/2023 20:18:48 - INFO - __main__ - train loss is 10.182495756074786\n",
      "Steps:  79%|▊| 11797/15000 [1:15:26<09:45,  5.47it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:49 - INFO - __main__ - train loss is 10.534630520269275\n",
      "Steps:  79%|▊| 11798/15000 [1:15:26<09:41,  5.51it/s, lr=9.08e-6, step_loss=0.3507/18/2023 20:18:49 - INFO - __main__ - train loss is 10.577684698626399\n",
      "Steps:  79%|▊| 11799/15000 [1:15:27<09:38,  5.53it/s, lr=9.08e-6, step_loss=0.0407/18/2023 20:18:49 - INFO - __main__ - train loss is 10.71351826004684\n",
      "Steps:  79%|▊| 11800/15000 [1:15:27<09:43,  5.49it/s, lr=9.08e-6, step_loss=0.1307/18/2023 20:18:49 - INFO - __main__ - train loss is 10.805079659447074\n",
      "Steps:  79%|▊| 11801/15000 [1:15:27<10:59,  4.85it/s, lr=9.08e-6, step_loss=0.0907/18/2023 20:18:49 - INFO - __main__ - train loss is 10.812087857164443\n",
      "Steps:  79%|▊| 11802/15000 [1:15:27<12:13,  4.36it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:50 - INFO - __main__ - train loss is 11.191174292005599\n",
      "Steps:  79%|▊| 11803/15000 [1:15:28<13:20,  3.99it/s, lr=9.08e-6, step_loss=0.3707/18/2023 20:18:50 - INFO - __main__ - train loss is 11.20371785108\n",
      "Steps:  79%|▊| 11804/15000 [1:15:28<13:37,  3.91it/s, lr=9.08e-6, step_loss=0.0107/18/2023 20:18:50 - INFO - __main__ - train loss is 11.24659384880215\n",
      "Steps:  79%|▊| 11805/15000 [1:15:28<13:35,  3.92it/s, lr=9.08e-6, step_loss=0.0407/18/2023 20:18:50 - INFO - __main__ - train loss is 11.901701585389674\n",
      "Steps:  79%|▊| 11806/15000 [1:15:28<12:31,  4.25it/s, lr=9.08e-6, step_loss=0.6507/18/2023 20:18:51 - INFO - __main__ - train loss is 12.048022166825831\n",
      "Steps:  79%|▊| 11807/15000 [1:15:29<11:54,  4.47it/s, lr=9.08e-6, step_loss=0.1407/18/2023 20:18:51 - INFO - __main__ - train loss is 12.088746176101267\n",
      "Steps:  79%|▊| 11808/15000 [1:15:29<11:14,  4.73it/s, lr=9.08e-6, step_loss=0.0407/18/2023 20:18:51 - INFO - __main__ - train loss is 12.230065048672259\n",
      "Steps:  79%|▊| 11809/15000 [1:15:29<10:43,  4.96it/s, lr=9.08e-6, step_loss=0.1407/18/2023 20:18:51 - INFO - __main__ - train loss is 12.535882175900042\n",
      "Steps:  79%|▊| 11810/15000 [1:15:29<10:24,  5.11it/s, lr=9.08e-6, step_loss=0.3007/18/2023 20:18:51 - INFO - __main__ - train loss is 13.004762888886034\n",
      "Steps:  79%|▊| 11811/15000 [1:15:29<10:10,  5.23it/s, lr=9.08e-6, step_loss=0.4607/18/2023 20:18:52 - INFO - __main__ - train loss is 13.33207652065903\n",
      "Steps:  79%|▊| 11812/15000 [1:15:29<10:00,  5.31it/s, lr=9.08e-6, step_loss=0.3207/18/2023 20:18:52 - INFO - __main__ - train loss is 14.049590201117098\n",
      "Steps:  79%|▊| 11813/15000 [1:15:30<09:57,  5.34it/s, lr=9.08e-6, step_loss=0.7107/18/2023 20:18:52 - INFO - __main__ - train loss is 14.940144867636263\n",
      "Steps:  79%|▊| 11814/15000 [1:15:30<09:48,  5.41it/s, lr=9.08e-6, step_loss=0.8907/18/2023 20:18:52 - INFO - __main__ - train loss is 14.9433249165304\n",
      "Steps:  79%|▊| 11815/15000 [1:15:30<09:42,  5.47it/s, lr=9.08e-6, step_loss=0.0007/18/2023 20:18:52 - INFO - __main__ - train loss is 14.97011733846739\n",
      "Steps:  79%|▊| 11816/15000 [1:15:30<09:37,  5.51it/s, lr=9.08e-6, step_loss=0.0207/18/2023 20:18:52 - INFO - __main__ - train loss is 14.990446053911\n",
      "Steps:  79%|▊| 11817/15000 [1:15:30<09:39,  5.49it/s, lr=9.08e-6, step_loss=0.0207/18/2023 20:18:53 - INFO - __main__ - train loss is 15.158707164693624\n",
      "Steps:  79%|▊| 11818/15000 [1:15:31<09:35,  5.53it/s, lr=9.08e-6, step_loss=0.1607/18/2023 20:18:53 - INFO - __main__ - train loss is 15.622163080144674\n",
      "Steps:  79%|▊| 11819/15000 [1:15:31<09:32,  5.56it/s, lr=9.08e-6, step_loss=0.4607/18/2023 20:18:53 - INFO - __main__ - train loss is 15.926309101749212\n",
      "Steps:  79%|▊| 11820/15000 [1:15:31<09:30,  5.58it/s, lr=9.08e-6, step_loss=0.3007/18/2023 20:18:53 - INFO - __main__ - train loss is 15.950926870573312\n",
      "Steps:  79%|▊| 11821/15000 [1:15:31<09:29,  5.58it/s, lr=9.08e-6, step_loss=0.0207/18/2023 20:18:53 - INFO - __main__ - train loss is 15.996875789482147\n",
      "Steps:  79%|▊| 11822/15000 [1:15:31<09:28,  5.59it/s, lr=9.08e-6, step_loss=0.0407/18/2023 20:18:54 - INFO - __main__ - train loss is 16.316206958610564\n",
      "Steps:  79%|▊| 11823/15000 [1:15:31<09:27,  5.59it/s, lr=9.07e-6, step_loss=0.3107/18/2023 20:18:54 - INFO - __main__ - train loss is 16.53836974175647\n",
      "Steps:  79%|▊| 11824/15000 [1:15:32<09:32,  5.54it/s, lr=9.07e-6, step_loss=0.2207/18/2023 20:18:54 - INFO - __main__ - train loss is 16.56263384828344\n",
      "Steps:  79%|▊| 11825/15000 [1:15:32<09:32,  5.55it/s, lr=9.07e-6, step_loss=0.0207/18/2023 20:18:54 - INFO - __main__ - train loss is 16.71768674859777\n",
      "Steps:  79%|▊| 11826/15000 [1:15:32<09:30,  5.57it/s, lr=9.07e-6, step_loss=0.1507/18/2023 20:18:54 - INFO - __main__ - train loss is 17.362626051995903\n",
      "Steps:  79%|▊| 11827/15000 [1:15:32<09:34,  5.52it/s, lr=9.07e-6, step_loss=0.6407/18/2023 20:18:54 - INFO - __main__ - train loss is 17.574681928846985\n",
      "Steps:  79%|▊| 11828/15000 [1:15:32<09:33,  5.53it/s, lr=9.07e-6, step_loss=0.2107/18/2023 20:18:55 - INFO - __main__ - train loss is 17.64671497652307\n",
      "Steps:  79%|▊| 11829/15000 [1:15:33<09:30,  5.56it/s, lr=9.07e-6, step_loss=0.0707/18/2023 20:18:55 - INFO - __main__ - train loss is 17.67148804338649\n",
      "Steps:  79%|▊| 11830/15000 [1:15:33<09:28,  5.57it/s, lr=9.07e-6, step_loss=0.0207/18/2023 20:18:55 - INFO - __main__ - train loss is 17.676465660799295\n",
      "Steps:  79%|▊| 11831/15000 [1:15:33<09:27,  5.58it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:18:55 - INFO - __main__ - train loss is 17.985959738958627\n",
      "Steps:  79%|▊| 11832/15000 [1:15:33<09:26,  5.59it/s, lr=9.07e-6, step_loss=0.3007/18/2023 20:18:55 - INFO - __main__ - train loss is 17.99279735563323\n",
      "Steps:  79%|▊| 11833/15000 [1:15:33<09:25,  5.60it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:18:56 - INFO - __main__ - train loss is 18.092183541040868\n",
      "Steps:  79%|▊| 11834/15000 [1:15:34<13:15,  3.98it/s, lr=9.07e-6, step_loss=0.0907/18/2023 20:18:57 - INFO - __main__ - Per validation step average loss is 0.012188676744699478\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Cumulative validation average loss is 0.012188676744699478\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Per validation step average loss is 0.03344816341996193\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Cumulative validation average loss is 0.04563684016466141\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Per validation step average loss is 0.4356560707092285\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Cumulative validation average loss is 0.4812929108738899\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Per validation step average loss is 0.022127453237771988\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Cumulative validation average loss is 0.5034203641116619\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Per validation step average loss is 0.6276906728744507\n",
      "07/18/2023 20:18:57 - INFO - __main__ - Cumulative validation average loss is 1.1311110369861126\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Per validation step average loss is 0.03705422207713127\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Cumulative validation average loss is 1.1681652590632439\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Per validation step average loss is 0.24550896883010864\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Cumulative validation average loss is 1.4136742278933525\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Per validation step average loss is 0.18900863826274872\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Cumulative validation average loss is 1.6026828661561012\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Per validation step average loss is 0.07046820968389511\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Cumulative validation average loss is 1.6731510758399963\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Per validation step average loss is 0.003545970655977726\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Cumulative validation average loss is 1.676697046495974\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Per validation step average loss is 0.0130393635481596\n",
      "07/18/2023 20:18:58 - INFO - __main__ - Cumulative validation average loss is 1.6897364100441337\n",
      "07/18/2023 20:18:59 - INFO - __main__ - Per validation step average loss is 0.034306637942790985\n",
      "07/18/2023 20:18:59 - INFO - __main__ - Cumulative validation average loss is 1.7240430479869246\n",
      "07/18/2023 20:18:59 - INFO - __main__ - Average validation loss for Epoch 121 is 0.1436702539989104\n",
      "07/18/2023 20:18:59 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:19:11 - INFO - __main__ - Starting epoch 122\n",
      "07/18/2023 20:19:12 - INFO - __main__ - train loss is 0.0759599506855011\n",
      "Steps:  79%|▊| 11835/15000 [1:15:50<4:25:31,  5.03s/it, lr=9.07e-6, step_loss=0.07/18/2023 20:19:12 - INFO - __main__ - train loss is 0.12553773820400238\n",
      "Steps:  79%|▊| 11836/15000 [1:15:50<3:08:43,  3.58s/it, lr=9.07e-6, step_loss=0.07/18/2023 20:19:12 - INFO - __main__ - train loss is 0.13198820129036903\n",
      "Steps:  79%|▊| 11837/15000 [1:15:50<2:15:00,  2.56s/it, lr=9.07e-6, step_loss=0.07/18/2023 20:19:13 - INFO - __main__ - train loss is 0.23061152175068855\n",
      "Steps:  79%|▊| 11838/15000 [1:15:50<1:37:18,  1.85s/it, lr=9.07e-6, step_loss=0.07/18/2023 20:19:13 - INFO - __main__ - train loss is 0.24366856552660465\n",
      "Steps:  79%|▊| 11839/15000 [1:15:51<1:10:54,  1.35s/it, lr=9.07e-6, step_loss=0.07/18/2023 20:19:13 - INFO - __main__ - train loss is 0.4929360840469599\n",
      "Steps:  79%|▊| 11840/15000 [1:15:51<52:30,  1.00it/s, lr=9.07e-6, step_loss=0.2407/18/2023 20:19:13 - INFO - __main__ - train loss is 0.5067991279065609\n",
      "Steps:  79%|▊| 11841/15000 [1:15:51<39:35,  1.33it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:13 - INFO - __main__ - train loss is 1.0117235444486141\n",
      "Steps:  79%|▊| 11842/15000 [1:15:51<30:30,  1.73it/s, lr=9.07e-6, step_loss=0.5007/18/2023 20:19:13 - INFO - __main__ - train loss is 1.0420157294720411\n",
      "Steps:  79%|▊| 11843/15000 [1:15:51<24:09,  2.18it/s, lr=9.07e-6, step_loss=0.0307/18/2023 20:19:14 - INFO - __main__ - train loss is 1.351133344694972\n",
      "Steps:  79%|▊| 11844/15000 [1:15:51<19:42,  2.67it/s, lr=9.07e-6, step_loss=0.3007/18/2023 20:19:14 - INFO - __main__ - train loss is 1.7579166572540998\n",
      "Steps:  79%|▊| 11845/15000 [1:15:52<16:36,  3.17it/s, lr=9.07e-6, step_loss=0.4007/18/2023 20:19:14 - INFO - __main__ - train loss is 1.7903884705156088\n",
      "Steps:  79%|▊| 11846/15000 [1:15:52<14:25,  3.64it/s, lr=9.07e-6, step_loss=0.0307/18/2023 20:19:14 - INFO - __main__ - train loss is 2.23367259465158\n",
      "Steps:  79%|▊| 11847/15000 [1:15:52<12:54,  4.07it/s, lr=9.07e-6, step_loss=0.4407/18/2023 20:19:14 - INFO - __main__ - train loss is 2.2517327815294266\n",
      "Steps:  79%|▊| 11848/15000 [1:15:52<11:50,  4.44it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:14 - INFO - __main__ - train loss is 2.2848695889115334\n",
      "Steps:  79%|▊| 11849/15000 [1:15:52<11:06,  4.73it/s, lr=9.07e-6, step_loss=0.0307/18/2023 20:19:15 - INFO - __main__ - train loss is 2.298485642299056\n",
      "Steps:  79%|▊| 11850/15000 [1:15:53<10:34,  4.97it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:15 - INFO - __main__ - train loss is 2.3271018248051405\n",
      "Steps:  79%|▊| 11851/15000 [1:15:53<10:11,  5.15it/s, lr=9.07e-6, step_loss=0.0207/18/2023 20:19:15 - INFO - __main__ - train loss is 2.4675048422068357\n",
      "Steps:  79%|▊| 11852/15000 [1:15:53<09:56,  5.27it/s, lr=9.07e-6, step_loss=0.1407/18/2023 20:19:15 - INFO - __main__ - train loss is 2.4783210791647434\n",
      "Steps:  79%|▊| 11853/15000 [1:15:53<09:46,  5.37it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:15 - INFO - __main__ - train loss is 2.7259943522512913\n",
      "Steps:  79%|▊| 11854/15000 [1:15:53<09:38,  5.44it/s, lr=9.07e-6, step_loss=0.2407/18/2023 20:19:16 - INFO - __main__ - train loss is 2.902044866234064\n",
      "Steps:  79%|▊| 11855/15000 [1:15:53<09:33,  5.49it/s, lr=9.07e-6, step_loss=0.1707/18/2023 20:19:16 - INFO - __main__ - train loss is 2.9413837529718876\n",
      "Steps:  79%|▊| 11856/15000 [1:15:54<09:29,  5.52it/s, lr=9.07e-6, step_loss=0.0307/18/2023 20:19:16 - INFO - __main__ - train loss is 3.0857699252665043\n",
      "Steps:  79%|▊| 11857/15000 [1:15:54<09:27,  5.54it/s, lr=9.07e-6, step_loss=0.1407/18/2023 20:19:16 - INFO - __main__ - train loss is 3.7643602825701237\n",
      "Steps:  79%|▊| 11858/15000 [1:15:54<09:29,  5.52it/s, lr=9.07e-6, step_loss=0.6707/18/2023 20:19:16 - INFO - __main__ - train loss is 3.8395306952297688\n",
      "Steps:  79%|▊| 11859/15000 [1:15:54<09:26,  5.54it/s, lr=9.07e-6, step_loss=0.0707/18/2023 20:19:16 - INFO - __main__ - train loss is 3.8832063637673855\n",
      "Steps:  79%|▊| 11860/15000 [1:15:54<09:30,  5.50it/s, lr=9.07e-6, step_loss=0.0407/18/2023 20:19:17 - INFO - __main__ - train loss is 4.1642756424844265\n",
      "Steps:  79%|▊| 11861/15000 [1:15:55<09:33,  5.47it/s, lr=9.07e-6, step_loss=0.2807/18/2023 20:19:17 - INFO - __main__ - train loss is 4.621233101934195\n",
      "Steps:  79%|▊| 11862/15000 [1:15:55<09:29,  5.51it/s, lr=9.07e-6, step_loss=0.4507/18/2023 20:19:17 - INFO - __main__ - train loss is 4.907504137605429\n",
      "Steps:  79%|▊| 11863/15000 [1:15:55<09:27,  5.53it/s, lr=9.07e-6, step_loss=0.2807/18/2023 20:19:17 - INFO - __main__ - train loss is 4.993185501545668\n",
      "Steps:  79%|▊| 11864/15000 [1:15:55<09:29,  5.51it/s, lr=9.07e-6, step_loss=0.0807/18/2023 20:19:17 - INFO - __main__ - train loss is 5.23091871663928\n",
      "Steps:  79%|▊| 11865/15000 [1:15:55<09:32,  5.48it/s, lr=9.07e-6, step_loss=0.2307/18/2023 20:19:18 - INFO - __main__ - train loss is 5.513999115675688\n",
      "Steps:  79%|▊| 11866/15000 [1:15:55<09:29,  5.50it/s, lr=9.07e-6, step_loss=0.2807/18/2023 20:19:18 - INFO - __main__ - train loss is 5.5275395112112164\n",
      "Steps:  79%|▊| 11867/15000 [1:15:56<09:26,  5.53it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:18 - INFO - __main__ - train loss is 5.696761731989682\n",
      "Steps:  79%|▊| 11868/15000 [1:15:56<09:24,  5.55it/s, lr=9.07e-6, step_loss=0.1607/18/2023 20:19:18 - INFO - __main__ - train loss is 5.706636428833008\n",
      "Steps:  79%|▊| 11869/15000 [1:15:56<09:22,  5.56it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:19:18 - INFO - __main__ - train loss is 5.855761826038361\n",
      "Steps:  79%|▊| 11870/15000 [1:15:56<09:21,  5.58it/s, lr=9.07e-6, step_loss=0.1407/18/2023 20:19:18 - INFO - __main__ - train loss is 5.864924255758524\n",
      "Steps:  79%|▊| 11871/15000 [1:15:56<09:20,  5.58it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:19:19 - INFO - __main__ - train loss is 5.872756687924266\n",
      "Steps:  79%|▊| 11872/15000 [1:15:57<09:20,  5.58it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:19:19 - INFO - __main__ - train loss is 5.880743739195168\n",
      "Steps:  79%|▊| 11873/15000 [1:15:57<09:19,  5.59it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:19:19 - INFO - __main__ - train loss is 5.935436573810875\n",
      "Steps:  79%|▊| 11874/15000 [1:15:57<09:19,  5.59it/s, lr=9.07e-6, step_loss=0.0507/18/2023 20:19:19 - INFO - __main__ - train loss is 5.973701980896294\n",
      "Steps:  79%|▊| 11875/15000 [1:15:57<09:18,  5.59it/s, lr=9.07e-6, step_loss=0.0307/18/2023 20:19:19 - INFO - __main__ - train loss is 5.978998814709485\n",
      "Steps:  79%|▊| 11876/15000 [1:15:57<09:18,  5.59it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:19:20 - INFO - __main__ - train loss is 5.990060831420124\n",
      "Steps:  79%|▊| 11877/15000 [1:15:57<09:17,  5.60it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:20 - INFO - __main__ - train loss is 6.006505641154945\n",
      "Steps:  79%|▊| 11878/15000 [1:15:58<09:17,  5.60it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:20 - INFO - __main__ - train loss is 6.043498034588993\n",
      "Steps:  79%|▊| 11879/15000 [1:15:58<09:17,  5.60it/s, lr=9.07e-6, step_loss=0.0307/18/2023 20:19:20 - INFO - __main__ - train loss is 6.058843286707997\n",
      "Steps:  79%|▊| 11880/15000 [1:15:58<09:17,  5.60it/s, lr=9.07e-6, step_loss=0.0107/18/2023 20:19:20 - INFO - __main__ - train loss is 6.061850379919633\n",
      "Steps:  79%|▊| 11881/15000 [1:15:58<09:17,  5.60it/s, lr=9.07e-6, step_loss=0.0007/18/2023 20:19:20 - INFO - __main__ - train loss is 6.110667675500736\n",
      "Steps:  79%|▊| 11882/15000 [1:15:58<09:16,  5.60it/s, lr=9.07e-6, step_loss=0.0407/18/2023 20:19:21 - INFO - __main__ - train loss is 6.405369907384738\n",
      "Steps:  79%|▊| 11883/15000 [1:15:58<09:16,  5.60it/s, lr=9.07e-6, step_loss=0.2907/18/2023 20:19:21 - INFO - __main__ - train loss is 6.474169485038146\n",
      "Steps:  79%|▊| 11884/15000 [1:15:59<09:16,  5.60it/s, lr=9.07e-6, step_loss=0.0607/18/2023 20:19:21 - INFO - __main__ - train loss is 6.759332410758361\n",
      "Steps:  79%|▊| 11885/15000 [1:15:59<09:16,  5.60it/s, lr=9.07e-6, step_loss=0.2807/18/2023 20:19:21 - INFO - __main__ - train loss is 6.889171860879287\n",
      "Steps:  79%|▊| 11886/15000 [1:15:59<09:16,  5.60it/s, lr=9.07e-6, step_loss=0.1307/18/2023 20:19:21 - INFO - __main__ - train loss is 7.062986977165565\n",
      "Steps:  79%|▊| 11887/15000 [1:15:59<09:16,  5.60it/s, lr=9.07e-6, step_loss=0.1707/18/2023 20:19:21 - INFO - __main__ - train loss is 7.873268730705604\n",
      "Steps:  79%|▊| 11888/15000 [1:15:59<09:15,  5.60it/s, lr=9.06e-6, step_loss=0.8107/18/2023 20:19:22 - INFO - __main__ - train loss is 7.899323120480403\n",
      "Steps:  79%|▊| 11889/15000 [1:16:00<09:15,  5.60it/s, lr=9.06e-6, step_loss=0.0207/18/2023 20:19:22 - INFO - __main__ - train loss is 8.035172670846805\n",
      "Steps:  79%|▊| 11890/15000 [1:16:00<09:15,  5.60it/s, lr=9.06e-6, step_loss=0.1307/18/2023 20:19:22 - INFO - __main__ - train loss is 8.141855992143974\n",
      "Steps:  79%|▊| 11891/15000 [1:16:00<09:14,  5.60it/s, lr=9.06e-6, step_loss=0.1007/18/2023 20:19:22 - INFO - __main__ - train loss is 8.191961124306545\n",
      "Steps:  79%|▊| 11892/15000 [1:16:00<09:14,  5.60it/s, lr=9.06e-6, step_loss=0.0507/18/2023 20:19:22 - INFO - __main__ - train loss is 8.230801801895723\n",
      "Steps:  79%|▊| 11893/15000 [1:16:00<09:14,  5.60it/s, lr=9.06e-6, step_loss=0.0307/18/2023 20:19:23 - INFO - __main__ - train loss is 8.48161856434308\n",
      "Steps:  79%|▊| 11894/15000 [1:16:00<09:14,  5.60it/s, lr=9.06e-6, step_loss=0.2507/18/2023 20:19:23 - INFO - __main__ - train loss is 8.597779165720567\n",
      "Steps:  79%|▊| 11895/15000 [1:16:01<09:14,  5.60it/s, lr=9.06e-6, step_loss=0.1107/18/2023 20:19:23 - INFO - __main__ - train loss is 9.104329537367448\n",
      "Steps:  79%|▊| 11896/15000 [1:16:01<09:14,  5.60it/s, lr=9.06e-6, step_loss=0.5007/18/2023 20:19:23 - INFO - __main__ - train loss is 9.120934013044462\n",
      "Steps:  79%|▊| 11897/15000 [1:16:01<09:13,  5.60it/s, lr=9.06e-6, step_loss=0.0107/18/2023 20:19:23 - INFO - __main__ - train loss is 9.174466963624582\n",
      "Steps:  79%|▊| 11898/15000 [1:16:01<09:13,  5.60it/s, lr=9.06e-6, step_loss=0.0507/18/2023 20:19:23 - INFO - __main__ - train loss is 9.51918065152131\n",
      "Steps:  79%|▊| 11899/15000 [1:16:01<09:13,  5.60it/s, lr=9.06e-6, step_loss=0.3407/18/2023 20:19:24 - INFO - __main__ - train loss is 9.52526064706035\n",
      "Steps:  79%|▊| 11900/15000 [1:16:02<09:18,  5.55it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:24 - INFO - __main__ - train loss is 9.611784016015008\n",
      "Steps:  79%|▊| 11901/15000 [1:16:02<09:24,  5.49it/s, lr=9.06e-6, step_loss=0.0807/18/2023 20:19:24 - INFO - __main__ - train loss is 9.716956516029313\n",
      "Steps:  79%|▊| 11902/15000 [1:16:02<09:22,  5.51it/s, lr=9.06e-6, step_loss=0.1007/18/2023 20:19:24 - INFO - __main__ - train loss is 9.922924195649102\n",
      "Steps:  79%|▊| 11903/15000 [1:16:02<09:19,  5.54it/s, lr=9.06e-6, step_loss=0.2007/18/2023 20:19:24 - INFO - __main__ - train loss is 9.92558868136257\n",
      "Steps:  79%|▊| 11904/15000 [1:16:02<09:17,  5.56it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:25 - INFO - __main__ - train loss is 10.030144228599966\n",
      "Steps:  79%|▊| 11905/15000 [1:16:02<09:15,  5.57it/s, lr=9.06e-6, step_loss=0.1007/18/2023 20:19:25 - INFO - __main__ - train loss is 10.052163199521601\n",
      "Steps:  79%|▊| 11906/15000 [1:16:03<09:14,  5.58it/s, lr=9.06e-6, step_loss=0.0207/18/2023 20:19:25 - INFO - __main__ - train loss is 10.180845172144473\n",
      "Steps:  79%|▊| 11907/15000 [1:16:03<09:13,  5.59it/s, lr=9.06e-6, step_loss=0.1207/18/2023 20:19:25 - INFO - __main__ - train loss is 10.60011097881943\n",
      "Steps:  79%|▊| 11908/15000 [1:16:03<09:12,  5.59it/s, lr=9.06e-6, step_loss=0.4107/18/2023 20:19:25 - INFO - __main__ - train loss is 10.614394983276725\n",
      "Steps:  79%|▊| 11909/15000 [1:16:03<09:12,  5.59it/s, lr=9.06e-6, step_loss=0.0107/18/2023 20:19:25 - INFO - __main__ - train loss is 10.627285538241267\n",
      "Steps:  79%|▊| 11910/15000 [1:16:03<09:12,  5.60it/s, lr=9.06e-6, step_loss=0.0107/18/2023 20:19:26 - INFO - __main__ - train loss is 10.650334825739264\n",
      "Steps:  79%|▊| 11911/15000 [1:16:03<09:11,  5.60it/s, lr=9.06e-6, step_loss=0.0207/18/2023 20:19:26 - INFO - __main__ - train loss is 10.843701964244246\n",
      "Steps:  79%|▊| 11912/15000 [1:16:04<09:11,  5.60it/s, lr=9.06e-6, step_loss=0.1907/18/2023 20:19:26 - INFO - __main__ - train loss is 10.899544017389417\n",
      "Steps:  79%|▊| 11913/15000 [1:16:04<09:10,  5.60it/s, lr=9.06e-6, step_loss=0.0507/18/2023 20:19:26 - INFO - __main__ - train loss is 11.198469238355756\n",
      "Steps:  79%|▊| 11914/15000 [1:16:04<09:11,  5.60it/s, lr=9.06e-6, step_loss=0.2907/18/2023 20:19:26 - INFO - __main__ - train loss is 11.536687510088086\n",
      "Steps:  79%|▊| 11915/15000 [1:16:04<09:10,  5.60it/s, lr=9.06e-6, step_loss=0.3307/18/2023 20:19:26 - INFO - __main__ - train loss is 11.539104699157178\n",
      "Steps:  79%|▊| 11916/15000 [1:16:04<09:09,  5.61it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:27 - INFO - __main__ - train loss is 11.565584533847868\n",
      "Steps:  79%|▊| 11917/15000 [1:16:05<09:09,  5.61it/s, lr=9.06e-6, step_loss=0.0207/18/2023 20:19:27 - INFO - __main__ - train loss is 11.570844969712198\n",
      "Steps:  79%|▊| 11918/15000 [1:16:05<09:09,  5.61it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:27 - INFO - __main__ - train loss is 11.575878137722611\n",
      "Steps:  79%|▊| 11919/15000 [1:16:05<09:14,  5.56it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:27 - INFO - __main__ - train loss is 11.622128026559949\n",
      "Steps:  79%|▊| 11920/15000 [1:16:05<09:21,  5.48it/s, lr=9.06e-6, step_loss=0.0407/18/2023 20:19:27 - INFO - __main__ - train loss is 11.632114662788808\n",
      "Steps:  79%|▊| 11921/15000 [1:16:05<09:24,  5.45it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:28 - INFO - __main__ - train loss is 12.368114127777517\n",
      "Steps:  79%|▊| 11922/15000 [1:16:05<09:19,  5.50it/s, lr=9.06e-6, step_loss=0.7307/18/2023 20:19:28 - INFO - __main__ - train loss is 12.392579997889698\n",
      "Steps:  79%|▊| 11923/15000 [1:16:06<09:19,  5.50it/s, lr=9.06e-6, step_loss=0.0207/18/2023 20:19:28 - INFO - __main__ - train loss is 12.664018238894641\n",
      "Steps:  79%|▊| 11924/15000 [1:16:06<09:16,  5.53it/s, lr=9.06e-6, step_loss=0.2707/18/2023 20:19:28 - INFO - __main__ - train loss is 12.917534018866718\n",
      "Steps:  80%|▊| 11925/15000 [1:16:06<09:14,  5.55it/s, lr=9.06e-6, step_loss=0.2507/18/2023 20:19:28 - INFO - __main__ - train loss is 12.919785283505917\n",
      "Steps:  80%|▊| 11926/15000 [1:16:06<09:12,  5.57it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:28 - INFO - __main__ - train loss is 13.621798776090145\n",
      "Steps:  80%|▊| 11927/15000 [1:16:06<09:10,  5.58it/s, lr=9.06e-6, step_loss=0.7007/18/2023 20:19:29 - INFO - __main__ - train loss is 13.638373240828514\n",
      "Steps:  80%|▊| 11928/15000 [1:16:07<09:09,  5.59it/s, lr=9.06e-6, step_loss=0.0107/18/2023 20:19:29 - INFO - __main__ - train loss is 13.776467815041542\n",
      "Steps:  80%|▊| 11929/15000 [1:16:07<09:14,  5.54it/s, lr=9.06e-6, step_loss=0.1307/18/2023 20:19:29 - INFO - __main__ - train loss is 13.797837633639574\n",
      "Steps:  80%|▊| 11930/15000 [1:16:07<09:13,  5.55it/s, lr=9.06e-6, step_loss=0.0207/18/2023 20:19:29 - INFO - __main__ - train loss is 13.82096615433693\n",
      "Steps:  80%|▊| 11931/15000 [1:16:07<12:21,  4.14it/s, lr=9.06e-6, step_loss=0.0207/18/2023 20:19:30 - INFO - __main__ - Per validation step average loss is 0.0013470664853230119\n",
      "07/18/2023 20:19:30 - INFO - __main__ - Cumulative validation average loss is 0.0013470664853230119\n",
      "07/18/2023 20:19:30 - INFO - __main__ - Per validation step average loss is 0.03877119719982147\n",
      "07/18/2023 20:19:30 - INFO - __main__ - Cumulative validation average loss is 0.040118263685144484\n",
      "07/18/2023 20:19:30 - INFO - __main__ - Per validation step average loss is 0.0015191008569672704\n",
      "07/18/2023 20:19:30 - INFO - __main__ - Cumulative validation average loss is 0.041637364542111754\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Per validation step average loss is 0.10121220350265503\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Cumulative validation average loss is 0.14284956804476678\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Per validation step average loss is 0.48575085401535034\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Cumulative validation average loss is 0.6286004220601171\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Per validation step average loss is 0.005229679401963949\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Cumulative validation average loss is 0.6338301014620811\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Per validation step average loss is 0.011696716770529747\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Cumulative validation average loss is 0.6455268182326108\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Per validation step average loss is 0.48243552446365356\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Cumulative validation average loss is 1.1279623426962644\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Per validation step average loss is 0.019372403621673584\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Cumulative validation average loss is 1.147334746317938\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Per validation step average loss is 0.07471217960119247\n",
      "07/18/2023 20:19:31 - INFO - __main__ - Cumulative validation average loss is 1.2220469259191304\n",
      "07/18/2023 20:19:32 - INFO - __main__ - Per validation step average loss is 0.03548140078783035\n",
      "07/18/2023 20:19:32 - INFO - __main__ - Cumulative validation average loss is 1.2575283267069608\n",
      "07/18/2023 20:19:32 - INFO - __main__ - Per validation step average loss is 0.001215695170685649\n",
      "07/18/2023 20:19:32 - INFO - __main__ - Cumulative validation average loss is 1.2587440218776464\n",
      "07/18/2023 20:19:32 - INFO - __main__ - Average validation loss for Epoch 122 is 0.10489533515647054\n",
      "07/18/2023 20:19:32 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:19:45 - INFO - __main__ - Starting epoch 123\n",
      "07/18/2023 20:19:45 - INFO - __main__ - train loss is 0.12490648031234741\n",
      "Steps:  80%|▊| 11932/15000 [1:16:23<4:13:21,  4.95s/it, lr=9.06e-6, step_loss=0.07/18/2023 20:19:46 - INFO - __main__ - train loss is 0.24887000024318695\n",
      "Steps:  80%|▊| 11933/15000 [1:16:23<3:00:17,  3.53s/it, lr=9.06e-6, step_loss=0.07/18/2023 20:19:46 - INFO - __main__ - train loss is 0.34191128611564636\n",
      "Steps:  80%|▊| 11934/15000 [1:16:24<2:09:09,  2.53s/it, lr=9.06e-6, step_loss=0.07/18/2023 20:19:46 - INFO - __main__ - train loss is 0.5362724959850311\n",
      "Steps:  80%|▊| 11935/15000 [1:16:24<1:33:21,  1.83s/it, lr=9.06e-6, step_loss=0.07/18/2023 20:19:46 - INFO - __main__ - train loss is 0.5496891010552645\n",
      "Steps:  80%|▊| 11936/15000 [1:16:24<1:08:18,  1.34s/it, lr=9.06e-6, step_loss=0.07/18/2023 20:19:46 - INFO - __main__ - train loss is 0.6966444570571184\n",
      "Steps:  80%|▊| 11937/15000 [1:16:24<50:44,  1.01it/s, lr=9.06e-6, step_loss=0.1407/18/2023 20:19:47 - INFO - __main__ - train loss is 0.764576205983758\n",
      "Steps:  80%|▊| 11938/15000 [1:16:24<38:28,  1.33it/s, lr=9.06e-6, step_loss=0.0607/18/2023 20:19:47 - INFO - __main__ - train loss is 1.4238690230995417\n",
      "Steps:  80%|▊| 11939/15000 [1:16:25<29:47,  1.71it/s, lr=9.06e-6, step_loss=0.6507/18/2023 20:19:47 - INFO - __main__ - train loss is 1.4644084703177214\n",
      "Steps:  80%|▊| 11940/15000 [1:16:25<23:48,  2.14it/s, lr=9.06e-6, step_loss=0.0407/18/2023 20:19:47 - INFO - __main__ - train loss is 1.466913782991469\n",
      "Steps:  80%|▊| 11941/15000 [1:16:25<19:36,  2.60it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:47 - INFO - __main__ - train loss is 1.5785821313038468\n",
      "Steps:  80%|▊| 11942/15000 [1:16:25<16:43,  3.05it/s, lr=9.06e-6, step_loss=0.1107/18/2023 20:19:47 - INFO - __main__ - train loss is 1.5808152658864856\n",
      "Steps:  80%|▊| 11943/15000 [1:16:25<14:39,  3.47it/s, lr=9.06e-6, step_loss=0.0007/18/2023 20:19:48 - INFO - __main__ - train loss is 1.9582469267770648\n",
      "Steps:  80%|▊| 11944/15000 [1:16:26<13:13,  3.85it/s, lr=9.06e-6, step_loss=0.3707/18/2023 20:19:48 - INFO - __main__ - train loss is 2.11683742236346\n",
      "Steps:  80%|▊| 11945/15000 [1:16:26<12:13,  4.16it/s, lr=9.06e-6, step_loss=0.1507/18/2023 20:19:48 - INFO - __main__ - train loss is 2.3447907073423266\n",
      "Steps:  80%|▊| 11946/15000 [1:16:26<11:32,  4.41it/s, lr=9.06e-6, step_loss=0.2207/18/2023 20:19:48 - INFO - __main__ - train loss is 2.6936487955972552\n",
      "Steps:  80%|▊| 11947/15000 [1:16:26<11:01,  4.61it/s, lr=9.06e-6, step_loss=0.3407/18/2023 20:19:48 - INFO - __main__ - train loss is 2.8510858668014407\n",
      "Steps:  80%|▊| 11948/15000 [1:16:26<10:41,  4.76it/s, lr=9.06e-6, step_loss=0.1507/18/2023 20:19:49 - INFO - __main__ - train loss is 2.898716668598354\n",
      "Steps:  80%|▊| 11949/15000 [1:16:27<10:29,  4.85it/s, lr=9.06e-6, step_loss=0.0407/18/2023 20:19:49 - INFO - __main__ - train loss is 3.0936342580243945\n",
      "Steps:  80%|▊| 11950/15000 [1:16:27<10:19,  4.93it/s, lr=9.06e-6, step_loss=0.1907/18/2023 20:19:49 - INFO - __main__ - train loss is 3.332187573425472\n",
      "Steps:  80%|▊| 11951/15000 [1:16:27<10:12,  4.98it/s, lr=9.06e-6, step_loss=0.2307/18/2023 20:19:49 - INFO - __main__ - train loss is 3.8423744840547442\n",
      "Steps:  80%|▊| 11952/15000 [1:16:27<10:07,  5.02it/s, lr=9.06e-6, step_loss=0.5107/18/2023 20:19:49 - INFO - __main__ - train loss is 4.073169778101146\n",
      "Steps:  80%|▊| 11953/15000 [1:16:27<10:04,  5.04it/s, lr=9.06e-6, step_loss=0.2307/18/2023 20:19:50 - INFO - __main__ - train loss is 4.281737725250423\n",
      "Steps:  80%|▊| 11954/15000 [1:16:28<09:50,  5.16it/s, lr=9.05e-6, step_loss=0.2007/18/2023 20:19:50 - INFO - __main__ - train loss is 4.361615243367851\n",
      "Steps:  80%|▊| 11955/15000 [1:16:28<09:39,  5.25it/s, lr=9.05e-6, step_loss=0.0707/18/2023 20:19:50 - INFO - __main__ - train loss is 4.375276919454336\n",
      "Steps:  80%|▊| 11956/15000 [1:16:28<09:40,  5.24it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:19:50 - INFO - __main__ - train loss is 4.807841833680868\n",
      "Steps:  80%|▊| 11957/15000 [1:16:28<09:43,  5.21it/s, lr=9.05e-6, step_loss=0.4307/18/2023 20:19:50 - INFO - __main__ - train loss is 5.58035671338439\n",
      "Steps:  80%|▊| 11958/15000 [1:16:28<09:45,  5.19it/s, lr=9.05e-6, step_loss=0.7707/18/2023 20:19:51 - INFO - __main__ - train loss is 5.645157139748335\n",
      "Steps:  80%|▊| 11959/15000 [1:16:28<09:46,  5.18it/s, lr=9.05e-6, step_loss=0.0607/18/2023 20:19:51 - INFO - __main__ - train loss is 5.753675263375044\n",
      "Steps:  80%|▊| 11960/15000 [1:16:29<09:48,  5.17it/s, lr=9.05e-6, step_loss=0.1007/18/2023 20:19:51 - INFO - __main__ - train loss is 6.700212698429823\n",
      "Steps:  80%|▊| 11961/15000 [1:16:29<09:48,  5.16it/s, lr=9.05e-6, step_loss=0.9407/18/2023 20:19:51 - INFO - __main__ - train loss is 7.356841128319502\n",
      "Steps:  80%|▊| 11962/15000 [1:16:29<09:49,  5.15it/s, lr=9.05e-6, step_loss=0.6507/18/2023 20:19:51 - INFO - __main__ - train loss is 7.360683880513534\n",
      "Steps:  80%|▊| 11963/15000 [1:16:29<10:03,  5.03it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:52 - INFO - __main__ - train loss is 7.613983951276168\n",
      "[2023-07-18 20:19:52,155] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:  80%|▊| 11964/15000 [1:16:29<09:54,  5.11it/s, lr=9.05e-6, step_loss=0.2507/18/2023 20:19:52 - INFO - __main__ - train loss is 7.910027585690841\n",
      "Steps:  80%|▊| 11965/15000 [1:16:30<09:43,  5.20it/s, lr=9.05e-6, step_loss=0.2907/18/2023 20:19:52 - INFO - __main__ - train loss is 7.986095748608932\n",
      "Steps:  80%|▊| 11966/15000 [1:16:30<09:38,  5.24it/s, lr=9.05e-6, step_loss=0.0707/18/2023 20:19:52 - INFO - __main__ - train loss is 7.999592343112454\n",
      "Steps:  80%|▊| 11967/15000 [1:16:30<09:41,  5.21it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:19:52 - INFO - __main__ - train loss is 8.001326621859334\n",
      "Steps:  80%|▊| 11968/15000 [1:16:30<09:30,  5.32it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:52 - INFO - __main__ - train loss is 8.012517057708465\n",
      "Steps:  80%|▊| 11969/15000 [1:16:30<09:21,  5.40it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:19:53 - INFO - __main__ - train loss is 8.059396699420176\n",
      "Steps:  80%|▊| 11970/15000 [1:16:31<09:15,  5.46it/s, lr=9.05e-6, step_loss=0.0407/18/2023 20:19:53 - INFO - __main__ - train loss is 8.096086912206374\n",
      "Steps:  80%|▊| 11971/15000 [1:16:31<09:11,  5.49it/s, lr=9.05e-6, step_loss=0.0307/18/2023 20:19:53 - INFO - __main__ - train loss is 8.106806474155746\n",
      "Steps:  80%|▊| 11972/15000 [1:16:31<09:13,  5.47it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:19:53 - INFO - __main__ - train loss is 8.470021086162888\n",
      "Steps:  80%|▊| 11973/15000 [1:16:31<09:11,  5.49it/s, lr=9.05e-6, step_loss=0.3607/18/2023 20:19:53 - INFO - __main__ - train loss is 8.51014192623552\n",
      "Steps:  80%|▊| 11974/15000 [1:16:31<09:09,  5.50it/s, lr=9.05e-6, step_loss=0.0407/18/2023 20:19:54 - INFO - __main__ - train loss is 8.943885760731064\n",
      "Steps:  80%|▊| 11975/15000 [1:16:31<09:12,  5.48it/s, lr=9.05e-6, step_loss=0.4307/18/2023 20:19:54 - INFO - __main__ - train loss is 8.989979701465927\n",
      "Steps:  80%|▊| 11976/15000 [1:16:32<09:13,  5.47it/s, lr=9.05e-6, step_loss=0.0407/18/2023 20:19:54 - INFO - __main__ - train loss is 8.993450351408683\n",
      "Steps:  80%|▊| 11977/15000 [1:16:32<09:13,  5.46it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:54 - INFO - __main__ - train loss is 9.128495239070617\n",
      "Steps:  80%|▊| 11978/15000 [1:16:32<09:16,  5.43it/s, lr=9.05e-6, step_loss=0.1307/18/2023 20:19:54 - INFO - __main__ - train loss is 9.525851689628325\n",
      "Steps:  80%|▊| 11979/15000 [1:16:32<09:13,  5.46it/s, lr=9.05e-6, step_loss=0.3907/18/2023 20:19:54 - INFO - __main__ - train loss is 9.698297106078826\n",
      "Steps:  80%|▊| 11980/15000 [1:16:32<09:11,  5.47it/s, lr=9.05e-6, step_loss=0.1707/18/2023 20:19:55 - INFO - __main__ - train loss is 9.714518763474189\n",
      "Steps:  80%|▊| 11981/15000 [1:16:33<09:10,  5.49it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:19:55 - INFO - __main__ - train loss is 9.791342534474097\n",
      "Steps:  80%|▊| 11982/15000 [1:16:33<09:08,  5.50it/s, lr=9.05e-6, step_loss=0.0707/18/2023 20:19:55 - INFO - __main__ - train loss is 9.852305271080695\n",
      "Steps:  80%|▊| 11983/15000 [1:16:33<09:12,  5.46it/s, lr=9.05e-6, step_loss=0.0607/18/2023 20:19:55 - INFO - __main__ - train loss is 9.906659234664403\n",
      "Steps:  80%|▊| 11984/15000 [1:16:33<09:10,  5.48it/s, lr=9.05e-6, step_loss=0.0507/18/2023 20:19:55 - INFO - __main__ - train loss is 10.284991819760762\n",
      "Steps:  80%|▊| 11985/15000 [1:16:33<09:09,  5.48it/s, lr=9.05e-6, step_loss=0.3707/18/2023 20:19:56 - INFO - __main__ - train loss is 10.434330363175832\n",
      "Steps:  80%|▊| 11986/15000 [1:16:33<09:08,  5.49it/s, lr=9.05e-6, step_loss=0.1407/18/2023 20:19:56 - INFO - __main__ - train loss is 10.444158836617135\n",
      "Steps:  80%|▊| 11987/15000 [1:16:34<09:12,  5.45it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:56 - INFO - __main__ - train loss is 10.60220351757016\n",
      "Steps:  80%|▊| 11988/15000 [1:16:34<09:10,  5.47it/s, lr=9.05e-6, step_loss=0.1507/18/2023 20:19:56 - INFO - __main__ - train loss is 10.674597992911004\n",
      "Steps:  80%|▊| 11989/15000 [1:16:34<09:08,  5.49it/s, lr=9.05e-6, step_loss=0.0707/18/2023 20:19:56 - INFO - __main__ - train loss is 10.849681749357842\n",
      "Steps:  80%|▊| 11990/15000 [1:16:34<09:07,  5.50it/s, lr=9.05e-6, step_loss=0.1707/18/2023 20:19:56 - INFO - __main__ - train loss is 11.273306980147026\n",
      "Steps:  80%|▊| 11991/15000 [1:16:34<09:06,  5.50it/s, lr=9.05e-6, step_loss=0.4207/18/2023 20:19:57 - INFO - __main__ - train loss is 11.303212060942315\n",
      "Steps:  80%|▊| 11992/15000 [1:16:35<09:06,  5.51it/s, lr=9.05e-6, step_loss=0.0207/18/2023 20:19:57 - INFO - __main__ - train loss is 11.33300327451434\n",
      "Steps:  80%|▊| 11993/15000 [1:16:35<09:10,  5.46it/s, lr=9.05e-6, step_loss=0.0207/18/2023 20:19:57 - INFO - __main__ - train loss is 11.808615378453396\n",
      "Steps:  80%|▊| 11994/15000 [1:16:35<09:08,  5.48it/s, lr=9.05e-6, step_loss=0.4707/18/2023 20:19:57 - INFO - __main__ - train loss is 12.006725452258252\n",
      "Steps:  80%|▊| 11995/15000 [1:16:35<09:05,  5.51it/s, lr=9.05e-6, step_loss=0.1907/18/2023 20:19:57 - INFO - __main__ - train loss is 12.01188181701582\n",
      "Steps:  80%|▊| 11996/15000 [1:16:35<09:02,  5.53it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:58 - INFO - __main__ - train loss is 12.08522823813837\n",
      "Steps:  80%|▊| 11997/15000 [1:16:35<09:01,  5.55it/s, lr=9.05e-6, step_loss=0.0707/18/2023 20:19:58 - INFO - __main__ - train loss is 12.093790752696805\n",
      "Steps:  80%|▊| 11998/15000 [1:16:36<09:00,  5.56it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:58 - INFO - __main__ - train loss is 12.128177909064107\n",
      "Steps:  80%|▊| 11999/15000 [1:16:36<09:04,  5.51it/s, lr=9.05e-6, step_loss=0.0307/18/2023 20:19:58 - INFO - __main__ - train loss is 12.161529557663016\n",
      "Steps:  80%|▊| 12000/15000 [1:16:36<09:06,  5.49it/s, lr=9.05e-6, step_loss=0.0307/18/2023 20:19:58 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-12000\n",
      "07/18/2023 20:19:58 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:19:58,722] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:19:58,727] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-12000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:19:58,727] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-12000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:19:58,734] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-12000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:19:58,735] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-12000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:19:58,754] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-12000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:19:58,754] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-12000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:19:58,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:19:58 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-12000/pytorch_model\n",
      "07/18/2023 20:19:58 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-12000/scheduler.bin\n",
      "07/18/2023 20:19:58 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-12000/random_states_0.pkl\n",
      "07/18/2023 20:19:58 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-12000\n",
      "Steps:  80%|▊| 12000/15000 [1:16:36<09:06,  5.49it/s, lr=9.05e-6, step_loss=0.0307/18/2023 20:19:58 - INFO - __main__ - train loss is 12.18032669450622\n",
      "Steps:  80%|▊| 12001/15000 [1:16:36<09:37,  5.19it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:19:59 - INFO - __main__ - train loss is 12.27432745124679\n",
      "Steps:  80%|▊| 12002/15000 [1:16:36<09:25,  5.30it/s, lr=9.05e-6, step_loss=0.0907/18/2023 20:19:59 - INFO - __main__ - train loss is 12.696907812613063\n",
      "Steps:  80%|▊| 12003/15000 [1:16:37<09:15,  5.39it/s, lr=9.05e-6, step_loss=0.4207/18/2023 20:19:59 - INFO - __main__ - train loss is 12.700369348167442\n",
      "Steps:  80%|▊| 12004/15000 [1:16:37<09:09,  5.45it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:59 - INFO - __main__ - train loss is 13.000267555355094\n",
      "Steps:  80%|▊| 12005/15000 [1:16:37<09:05,  5.49it/s, lr=9.05e-6, step_loss=0.3]07/18/2023 20:19:59 - INFO - __main__ - train loss is 13.00839138997253\n",
      "Steps:  80%|▊| 12006/15000 [1:16:37<09:02,  5.52it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:19:59 - INFO - __main__ - train loss is 13.13012980890926\n",
      "Steps:  80%|▊| 12007/15000 [1:16:37<09:01,  5.53it/s, lr=9.05e-6, step_loss=0.1207/18/2023 20:20:00 - INFO - __main__ - train loss is 13.146079184836708\n",
      "Steps:  80%|▊| 12008/15000 [1:16:37<08:59,  5.55it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:20:00 - INFO - __main__ - train loss is 13.148129580891691\n",
      "Steps:  80%|▊| 12009/15000 [1:16:38<08:57,  5.57it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:20:00 - INFO - __main__ - train loss is 13.438498555100523\n",
      "Steps:  80%|▊| 12010/15000 [1:16:38<08:56,  5.58it/s, lr=9.05e-6, step_loss=0.2907/18/2023 20:20:00 - INFO - __main__ - train loss is 13.459527535713278\n",
      "Steps:  80%|▊| 12011/15000 [1:16:38<08:55,  5.58it/s, lr=9.05e-6, step_loss=0.0207/18/2023 20:20:00 - INFO - __main__ - train loss is 13.844397647655569\n",
      "Steps:  80%|▊| 12012/15000 [1:16:38<08:54,  5.59it/s, lr=9.05e-6, step_loss=0.3807/18/2023 20:20:00 - INFO - __main__ - train loss is 14.11988426593598\n",
      "Steps:  80%|▊| 12013/15000 [1:16:38<08:54,  5.58it/s, lr=9.05e-6, step_loss=0.2707/18/2023 20:20:01 - INFO - __main__ - train loss is 14.34466725436505\n",
      "Steps:  80%|▊| 12014/15000 [1:16:39<08:54,  5.59it/s, lr=9.05e-6, step_loss=0.2207/18/2023 20:20:01 - INFO - __main__ - train loss is 14.357869180268608\n",
      "Steps:  80%|▊| 12015/15000 [1:16:39<08:54,  5.58it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:20:01 - INFO - __main__ - train loss is 14.360240035341121\n",
      "Steps:  80%|▊| 12016/15000 [1:16:39<08:55,  5.57it/s, lr=9.05e-6, step_loss=0.0007/18/2023 20:20:01 - INFO - __main__ - train loss is 14.372364762821235\n",
      "Steps:  80%|▊| 12017/15000 [1:16:39<08:58,  5.54it/s, lr=9.05e-6, step_loss=0.0107/18/2023 20:20:01 - INFO - __main__ - train loss is 14.825042251148261\n",
      "Steps:  80%|▊| 12018/15000 [1:16:39<08:57,  5.55it/s, lr=9.05e-6, step_loss=0.4507/18/2023 20:20:02 - INFO - __main__ - train loss is 14.855017386027612\n",
      "Steps:  80%|▊| 12019/15000 [1:16:39<08:56,  5.55it/s, lr=9.05e-6, step_loss=0.0307/18/2023 20:20:02 - INFO - __main__ - train loss is 14.862127954722382\n",
      "Steps:  80%|▊| 12020/15000 [1:16:40<08:55,  5.57it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:02 - INFO - __main__ - train loss is 15.264310146332718\n",
      "Steps:  80%|▊| 12021/15000 [1:16:40<08:53,  5.58it/s, lr=9.04e-6, step_loss=0.4007/18/2023 20:20:02 - INFO - __main__ - train loss is 15.315652648569085\n",
      "Steps:  80%|▊| 12022/15000 [1:16:40<08:52,  5.59it/s, lr=9.04e-6, step_loss=0.0507/18/2023 20:20:02 - INFO - __main__ - train loss is 15.397563333273865\n",
      "Steps:  80%|▊| 12023/15000 [1:16:40<08:52,  5.59it/s, lr=9.04e-6, step_loss=0.0807/18/2023 20:20:02 - INFO - __main__ - train loss is 15.453703338862397\n",
      "Steps:  80%|▊| 12024/15000 [1:16:40<08:51,  5.60it/s, lr=9.04e-6, step_loss=0.0507/18/2023 20:20:03 - INFO - __main__ - train loss is 15.458635128685273\n",
      "Steps:  80%|▊| 12025/15000 [1:16:41<08:51,  5.60it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:03 - INFO - __main__ - train loss is 15.461429759976454\n",
      "Steps:  80%|▊| 12026/15000 [1:16:41<08:50,  5.60it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:03 - INFO - __main__ - train loss is 15.475091612082906\n",
      "Steps:  80%|▊| 12027/15000 [1:16:41<08:50,  5.60it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:03 - INFO - __main__ - train loss is 15.687908535939641\n",
      "Steps:  80%|▊| 12028/15000 [1:16:41<12:13,  4.05it/s, lr=9.04e-6, step_loss=0.2107/18/2023 20:20:04 - INFO - __main__ - Per validation step average loss is 0.03083057329058647\n",
      "07/18/2023 20:20:04 - INFO - __main__ - Cumulative validation average loss is 0.03083057329058647\n",
      "07/18/2023 20:20:04 - INFO - __main__ - Per validation step average loss is 0.0984245240688324\n",
      "07/18/2023 20:20:04 - INFO - __main__ - Cumulative validation average loss is 0.12925509735941887\n",
      "07/18/2023 20:20:04 - INFO - __main__ - Per validation step average loss is 0.2841351330280304\n",
      "07/18/2023 20:20:04 - INFO - __main__ - Cumulative validation average loss is 0.41339023038744926\n",
      "07/18/2023 20:20:04 - INFO - __main__ - Per validation step average loss is 0.0022364596370607615\n",
      "07/18/2023 20:20:04 - INFO - __main__ - Cumulative validation average loss is 0.41562669002451\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Per validation step average loss is 0.05485803633928299\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Cumulative validation average loss is 0.470484726363793\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Per validation step average loss is 0.0014788575936108828\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Cumulative validation average loss is 0.4719635839574039\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Per validation step average loss is 0.05797019973397255\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Cumulative validation average loss is 0.5299337836913764\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Per validation step average loss is 0.09197988361120224\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Cumulative validation average loss is 0.6219136673025787\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Per validation step average loss is 0.05196583271026611\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Cumulative validation average loss is 0.6738795000128448\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Per validation step average loss is 0.006705327425152063\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Cumulative validation average loss is 0.6805848274379969\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Per validation step average loss is 0.009112379513680935\n",
      "07/18/2023 20:20:05 - INFO - __main__ - Cumulative validation average loss is 0.6896972069516778\n",
      "07/18/2023 20:20:06 - INFO - __main__ - Per validation step average loss is 0.4873724579811096\n",
      "07/18/2023 20:20:06 - INFO - __main__ - Cumulative validation average loss is 1.1770696649327874\n",
      "07/18/2023 20:20:06 - INFO - __main__ - Average validation loss for Epoch 123 is 0.09808913874439895\n",
      "07/18/2023 20:20:06 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:20:19 - INFO - __main__ - Starting epoch 124\n",
      "07/18/2023 20:20:19 - INFO - __main__ - train loss is 0.005981081165373325\n",
      "Steps:  80%|▊| 12029/15000 [1:16:57<4:01:26,  4.88s/it, lr=9.04e-6, step_loss=0.07/18/2023 20:20:19 - INFO - __main__ - train loss is 0.10442170593887568\n",
      "Steps:  80%|▊| 12030/15000 [1:16:57<2:51:36,  3.47s/it, lr=9.04e-6, step_loss=0.07/18/2023 20:20:19 - INFO - __main__ - train loss is 0.8762548277154565\n",
      "Steps:  80%|▊| 12031/15000 [1:16:57<2:02:44,  2.48s/it, lr=9.04e-6, step_loss=0.07/18/2023 20:20:20 - INFO - __main__ - train loss is 0.8889111848548055\n",
      "Steps:  80%|▊| 12032/15000 [1:16:58<1:28:36,  1.79s/it, lr=9.04e-6, step_loss=0.07/18/2023 20:20:20 - INFO - __main__ - train loss is 0.9029614217579365\n",
      "Steps:  80%|▊| 12033/15000 [1:16:58<1:04:50,  1.31s/it, lr=9.04e-6, step_loss=0.07/18/2023 20:20:20 - INFO - __main__ - train loss is 0.9048606945434585\n",
      "Steps:  80%|▊| 12034/15000 [1:16:58<48:11,  1.03it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:20 - INFO - __main__ - train loss is 0.9871037347475067\n",
      "Steps:  80%|▊| 12035/15000 [1:16:58<36:23,  1.36it/s, lr=9.04e-6, step_loss=0.0807/18/2023 20:20:20 - INFO - __main__ - train loss is 1.0403776509920135\n",
      "Steps:  80%|▊| 12036/15000 [1:16:58<28:05,  1.76it/s, lr=9.04e-6, step_loss=0.0507/18/2023 20:20:21 - INFO - __main__ - train loss is 1.041850478737615\n",
      "Steps:  80%|▊| 12037/15000 [1:16:58<22:18,  2.21it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:21 - INFO - __main__ - train loss is 1.2407910985639319\n",
      "Steps:  80%|▊| 12038/15000 [1:16:59<18:14,  2.71it/s, lr=9.04e-6, step_loss=0.1907/18/2023 20:20:21 - INFO - __main__ - train loss is 1.4426383835962042\n",
      "Steps:  80%|▊| 12039/15000 [1:16:59<15:24,  3.20it/s, lr=9.04e-6, step_loss=0.2007/18/2023 20:20:21 - INFO - __main__ - train loss is 1.4470675386255607\n",
      "Steps:  80%|▊| 12040/15000 [1:16:59<13:24,  3.68it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:21 - INFO - __main__ - train loss is 1.832652548677288\n",
      "Steps:  80%|▊| 12041/15000 [1:16:59<12:01,  4.10it/s, lr=9.04e-6, step_loss=0.3807/18/2023 20:20:21 - INFO - __main__ - train loss is 2.0952214397257194\n",
      "Steps:  80%|▊| 12042/15000 [1:16:59<11:02,  4.46it/s, lr=9.04e-6, step_loss=0.2607/18/2023 20:20:22 - INFO - __main__ - train loss is 2.1913843922084197\n",
      "Steps:  80%|▊| 12043/15000 [1:17:00<10:27,  4.71it/s, lr=9.04e-6, step_loss=0.0907/18/2023 20:20:22 - INFO - __main__ - train loss is 2.201948147616349\n",
      "Steps:  80%|▊| 12044/15000 [1:17:00<10:01,  4.92it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:22 - INFO - __main__ - train loss is 2.316157382330857\n",
      "Steps:  80%|▊| 12045/15000 [1:17:00<09:38,  5.11it/s, lr=9.04e-6, step_loss=0.1107/18/2023 20:20:22 - INFO - __main__ - train loss is 2.454414140782319\n",
      "Steps:  80%|▊| 12046/15000 [1:17:00<09:27,  5.21it/s, lr=9.04e-6, step_loss=0.1307/18/2023 20:20:22 - INFO - __main__ - train loss is 2.4650604681810364\n",
      "Steps:  80%|▊| 12047/15000 [1:17:00<09:15,  5.32it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:23 - INFO - __main__ - train loss is 2.6252247350057587\n",
      "Steps:  80%|▊| 12048/15000 [1:17:00<09:07,  5.39it/s, lr=9.04e-6, step_loss=0.1607/18/2023 20:20:23 - INFO - __main__ - train loss is 2.6270725819049403\n",
      "Steps:  80%|▊| 12049/15000 [1:17:01<09:01,  5.45it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:23 - INFO - __main__ - train loss is 2.7254438194213435\n",
      "Steps:  80%|▊| 12050/15000 [1:17:01<08:56,  5.50it/s, lr=9.04e-6, step_loss=0.0907/18/2023 20:20:23 - INFO - __main__ - train loss is 2.9257086011348292\n",
      "Steps:  80%|▊| 12051/15000 [1:17:01<08:53,  5.53it/s, lr=9.04e-6, step_loss=0.2]07/18/2023 20:20:23 - INFO - __main__ - train loss is 2.958704056101851\n",
      "Steps:  80%|▊| 12052/15000 [1:17:01<08:51,  5.55it/s, lr=9.04e-6, step_loss=0.0307/18/2023 20:20:23 - INFO - __main__ - train loss is 3.3244906085310504\n",
      "Steps:  80%|▊| 12053/15000 [1:17:01<08:55,  5.51it/s, lr=9.04e-6, step_loss=0.3607/18/2023 20:20:24 - INFO - __main__ - train loss is 3.4475338774500415\n",
      "Steps:  80%|▊| 12054/15000 [1:17:01<08:58,  5.47it/s, lr=9.04e-6, step_loss=0.1207/18/2023 20:20:24 - INFO - __main__ - train loss is 3.4798971879063174\n",
      "Steps:  80%|▊| 12055/15000 [1:17:02<08:58,  5.47it/s, lr=9.04e-6, step_loss=0.0307/18/2023 20:20:24 - INFO - __main__ - train loss is 3.682239444809966\n",
      "Steps:  80%|▊| 12056/15000 [1:17:02<08:59,  5.46it/s, lr=9.04e-6, step_loss=0.2007/18/2023 20:20:24 - INFO - __main__ - train loss is 3.6991892064688727\n",
      "Steps:  80%|▊| 12057/15000 [1:17:02<08:56,  5.48it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:24 - INFO - __main__ - train loss is 3.8448825086234137\n",
      "Steps:  80%|▊| 12058/15000 [1:17:02<08:52,  5.52it/s, lr=9.04e-6, step_loss=0.1407/18/2023 20:20:25 - INFO - __main__ - train loss is 3.8466260795248672\n",
      "Steps:  80%|▊| 12059/15000 [1:17:02<08:50,  5.54it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:25 - INFO - __main__ - train loss is 4.074171102489345\n",
      "Steps:  80%|▊| 12060/15000 [1:17:03<08:48,  5.56it/s, lr=9.04e-6, step_loss=0.2207/18/2023 20:20:25 - INFO - __main__ - train loss is 4.076428075670265\n",
      "Steps:  80%|▊| 12061/15000 [1:17:03<08:47,  5.57it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:25 - INFO - __main__ - train loss is 4.120543764322065\n",
      "Steps:  80%|▊| 12062/15000 [1:17:03<08:46,  5.58it/s, lr=9.04e-6, step_loss=0.0407/18/2023 20:20:25 - INFO - __main__ - train loss is 4.152738296776079\n",
      "Steps:  80%|▊| 12063/15000 [1:17:03<08:45,  5.59it/s, lr=9.04e-6, step_loss=0.0307/18/2023 20:20:25 - INFO - __main__ - train loss is 4.17010562622454\n",
      "Steps:  80%|▊| 12064/15000 [1:17:03<08:45,  5.59it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:26 - INFO - __main__ - train loss is 4.248999019502662\n",
      "Steps:  80%|▊| 12065/15000 [1:17:03<08:49,  5.55it/s, lr=9.04e-6, step_loss=0.0707/18/2023 20:20:26 - INFO - __main__ - train loss is 4.253062459989451\n",
      "Steps:  80%|▊| 12066/15000 [1:17:04<08:51,  5.52it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:26 - INFO - __main__ - train loss is 4.272334550856613\n",
      "Steps:  80%|▊| 12067/15000 [1:17:04<08:48,  5.55it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:26 - INFO - __main__ - train loss is 4.299535175203346\n",
      "Steps:  80%|▊| 12068/15000 [1:17:04<08:53,  5.49it/s, lr=9.04e-6, step_loss=0.0207/18/2023 20:20:26 - INFO - __main__ - train loss is 4.317749592824839\n",
      "Steps:  80%|▊| 12069/15000 [1:17:04<08:57,  5.45it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:27 - INFO - __main__ - train loss is 4.324739210656844\n",
      "Steps:  80%|▊| 12070/15000 [1:17:04<08:59,  5.43it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:27 - INFO - __main__ - train loss is 4.5215790051734075\n",
      "Steps:  80%|▊| 12071/15000 [1:17:05<08:54,  5.48it/s, lr=9.04e-6, step_loss=0.1907/18/2023 20:20:27 - INFO - __main__ - train loss is 4.5473162945127115\n",
      "Steps:  80%|▊| 12072/15000 [1:17:05<08:51,  5.51it/s, lr=9.04e-6, step_loss=0.0207/18/2023 20:20:27 - INFO - __main__ - train loss is 4.563986730179749\n",
      "Steps:  80%|▊| 12073/15000 [1:17:05<08:49,  5.53it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:27 - INFO - __main__ - train loss is 4.583975550136529\n",
      "Steps:  80%|▊| 12074/15000 [1:17:05<08:52,  5.50it/s, lr=9.04e-6, step_loss=0.0207/18/2023 20:20:27 - INFO - __main__ - train loss is 4.607206262997352\n",
      "Steps:  80%|▊| 12075/15000 [1:17:05<08:51,  5.51it/s, lr=9.04e-6, step_loss=0.0207/18/2023 20:20:28 - INFO - __main__ - train loss is 4.613882879144512\n",
      "Steps:  81%|▊| 12076/15000 [1:17:05<08:48,  5.53it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:28 - INFO - __main__ - train loss is 4.905816534883343\n",
      "Steps:  81%|▊| 12077/15000 [1:17:06<08:46,  5.55it/s, lr=9.04e-6, step_loss=0.2907/18/2023 20:20:28 - INFO - __main__ - train loss is 4.916878223768435\n",
      "Steps:  81%|▊| 12078/15000 [1:17:06<08:46,  5.55it/s, lr=9.04e-6, step_loss=0.0107/18/2023 20:20:28 - INFO - __main__ - train loss is 5.437314868322574\n",
      "Steps:  81%|▊| 12079/15000 [1:17:06<09:17,  5.24it/s, lr=9.04e-6, step_loss=0.5207/18/2023 20:20:28 - INFO - __main__ - train loss is 5.446762734442018\n",
      "Steps:  81%|▊| 12080/15000 [1:17:06<09:49,  4.96it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:29 - INFO - __main__ - train loss is 5.627451175241731\n",
      "Steps:  81%|▊| 12081/15000 [1:17:06<09:59,  4.87it/s, lr=9.04e-6, step_loss=0.1807/18/2023 20:20:29 - INFO - __main__ - train loss is 5.629776894929819\n",
      "Steps:  81%|▊| 12082/15000 [1:17:07<09:38,  5.04it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:29 - INFO - __main__ - train loss is 5.633316190331243\n",
      "Steps:  81%|▊| 12083/15000 [1:17:07<09:21,  5.20it/s, lr=9.04e-6, step_loss=0.0007/18/2023 20:20:29 - INFO - __main__ - train loss is 5.841641486971639\n",
      "Steps:  81%|▊| 12084/15000 [1:17:07<09:09,  5.31it/s, lr=9.04e-6, step_loss=0.2007/18/2023 20:20:29 - INFO - __main__ - train loss is 5.854102832614444\n",
      "Steps:  81%|▊| 12085/15000 [1:17:07<09:01,  5.39it/s, lr=9.03e-6, step_loss=0.0107/18/2023 20:20:30 - INFO - __main__ - train loss is 5.858226120355539\n",
      "Steps:  81%|▊| 12086/15000 [1:17:07<08:58,  5.41it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:30 - INFO - __main__ - train loss is 6.354813933256082\n",
      "Steps:  81%|▊| 12087/15000 [1:17:08<08:53,  5.46it/s, lr=9.03e-6, step_loss=0.4907/18/2023 20:20:30 - INFO - __main__ - train loss is 6.39922215777915\n",
      "Steps:  81%|▊| 12088/15000 [1:17:08<08:52,  5.47it/s, lr=9.03e-6, step_loss=0.0407/18/2023 20:20:30 - INFO - __main__ - train loss is 6.608152083936147\n",
      "Steps:  81%|▊| 12089/15000 [1:17:08<08:48,  5.50it/s, lr=9.03e-6, step_loss=0.2007/18/2023 20:20:30 - INFO - __main__ - train loss is 6.610840267618187\n",
      "Steps:  81%|▊| 12090/15000 [1:17:08<08:46,  5.53it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:30 - INFO - __main__ - train loss is 6.7489405936794356\n",
      "Steps:  81%|▊| 12091/15000 [1:17:08<08:44,  5.55it/s, lr=9.03e-6, step_loss=0.1307/18/2023 20:20:31 - INFO - __main__ - train loss is 6.750339356600307\n",
      "Steps:  81%|▊| 12092/15000 [1:17:08<08:47,  5.52it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:31 - INFO - __main__ - train loss is 6.84547085815575\n",
      "Steps:  81%|▊| 12093/15000 [1:17:09<08:44,  5.54it/s, lr=9.03e-6, step_loss=0.0907/18/2023 20:20:31 - INFO - __main__ - train loss is 6.896754694520496\n",
      "Steps:  81%|▊| 12094/15000 [1:17:09<08:46,  5.52it/s, lr=9.03e-6, step_loss=0.0507/18/2023 20:20:31 - INFO - __main__ - train loss is 7.179069650708698\n",
      "Steps:  81%|▊| 12095/15000 [1:17:09<08:49,  5.49it/s, lr=9.03e-6, step_loss=0.2807/18/2023 20:20:31 - INFO - __main__ - train loss is 7.181155379512347\n",
      "Steps:  81%|▊| 12096/15000 [1:17:09<08:51,  5.47it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:31 - INFO - __main__ - train loss is 7.2442899976158515\n",
      "Steps:  81%|▊| 12097/15000 [1:17:09<08:52,  5.45it/s, lr=9.03e-6, step_loss=0.0607/18/2023 20:20:32 - INFO - __main__ - train loss is 7.544700208702125\n",
      "Steps:  81%|▊| 12098/15000 [1:17:10<08:48,  5.49it/s, lr=9.03e-6, step_loss=0.3]07/18/2023 20:20:32 - INFO - __main__ - train loss is 7.878241631784476\n",
      "Steps:  81%|▊| 12099/15000 [1:17:10<08:46,  5.51it/s, lr=9.03e-6, step_loss=0.3307/18/2023 20:20:32 - INFO - __main__ - train loss is 8.219748321571387\n",
      "Steps:  81%|▊| 12100/15000 [1:17:10<08:43,  5.54it/s, lr=9.03e-6, step_loss=0.3407/18/2023 20:20:32 - INFO - __main__ - train loss is 8.343865420320071\n",
      "Steps:  81%|▊| 12101/15000 [1:17:10<08:46,  5.50it/s, lr=9.03e-6, step_loss=0.1207/18/2023 20:20:32 - INFO - __main__ - train loss is 8.393455419340171\n",
      "Steps:  81%|▊| 12102/15000 [1:17:10<08:45,  5.51it/s, lr=9.03e-6, step_loss=0.0407/18/2023 20:20:33 - INFO - __main__ - train loss is 8.406525328406133\n",
      "Steps:  81%|▊| 12103/15000 [1:17:10<08:43,  5.54it/s, lr=9.03e-6, step_loss=0.0107/18/2023 20:20:33 - INFO - __main__ - train loss is 8.412322926451452\n",
      "Steps:  81%|▊| 12104/15000 [1:17:11<08:41,  5.55it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:33 - INFO - __main__ - train loss is 8.414184513734654\n",
      "Steps:  81%|▊| 12105/15000 [1:17:11<08:39,  5.57it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:33 - INFO - __main__ - train loss is 8.505830775247887\n",
      "Steps:  81%|▊| 12106/15000 [1:17:11<08:38,  5.58it/s, lr=9.03e-6, step_loss=0.0907/18/2023 20:20:33 - INFO - __main__ - train loss is 8.528874906944111\n",
      "Steps:  81%|▊| 12107/15000 [1:17:11<08:38,  5.58it/s, lr=9.03e-6, step_loss=0.0207/18/2023 20:20:33 - INFO - __main__ - train loss is 8.53575008478947\n",
      "Steps:  81%|▊| 12108/15000 [1:17:11<08:38,  5.58it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:34 - INFO - __main__ - train loss is 8.677174338372424\n",
      "Steps:  81%|▊| 12109/15000 [1:17:12<08:36,  5.59it/s, lr=9.03e-6, step_loss=0.1407/18/2023 20:20:34 - INFO - __main__ - train loss is 8.680661374470219\n",
      "Steps:  81%|▊| 12110/15000 [1:17:12<08:36,  5.60it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:34 - INFO - __main__ - train loss is 8.769525112351403\n",
      "Steps:  81%|▊| 12111/15000 [1:17:12<08:35,  5.60it/s, lr=9.03e-6, step_loss=0.0807/18/2023 20:20:34 - INFO - __main__ - train loss is 8.919699551304802\n",
      "Steps:  81%|▊| 12112/15000 [1:17:12<08:35,  5.60it/s, lr=9.03e-6, step_loss=0.1507/18/2023 20:20:34 - INFO - __main__ - train loss is 9.009212197503075\n",
      "Steps:  81%|▊| 12113/15000 [1:17:12<08:34,  5.61it/s, lr=9.03e-6, step_loss=0.0807/18/2023 20:20:35 - INFO - __main__ - train loss is 9.454072119435295\n",
      "Steps:  81%|▊| 12114/15000 [1:17:12<08:34,  5.61it/s, lr=9.03e-6, step_loss=0.4407/18/2023 20:20:35 - INFO - __main__ - train loss is 9.650104658445343\n",
      "Steps:  81%|▊| 12115/15000 [1:17:13<08:37,  5.57it/s, lr=9.03e-6, step_loss=0.1907/18/2023 20:20:35 - INFO - __main__ - train loss is 9.86577002867125\n",
      "Steps:  81%|▊| 12116/15000 [1:17:13<08:41,  5.53it/s, lr=9.03e-6, step_loss=0.2107/18/2023 20:20:35 - INFO - __main__ - train loss is 9.9240895526018\n",
      "Steps:  81%|▊| 12117/15000 [1:17:13<08:40,  5.54it/s, lr=9.03e-6, step_loss=0.0507/18/2023 20:20:35 - INFO - __main__ - train loss is 9.929748881375417\n",
      "Steps:  81%|▊| 12118/15000 [1:17:13<08:38,  5.55it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:35 - INFO - __main__ - train loss is 10.071446824586019\n",
      "Steps:  81%|▊| 12119/15000 [1:17:13<08:37,  5.57it/s, lr=9.03e-6, step_loss=0.1407/18/2023 20:20:36 - INFO - __main__ - train loss is 10.479862827574834\n",
      "Steps:  81%|▊| 12120/15000 [1:17:14<08:35,  5.59it/s, lr=9.03e-6, step_loss=0.4007/18/2023 20:20:36 - INFO - __main__ - train loss is 10.482140768552199\n",
      "Steps:  81%|▊| 12121/15000 [1:17:14<08:34,  5.60it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:36 - INFO - __main__ - train loss is 10.521713253343478\n",
      "Steps:  81%|▊| 12122/15000 [1:17:14<08:33,  5.60it/s, lr=9.03e-6, step_loss=0.0307/18/2023 20:20:36 - INFO - __main__ - train loss is 10.529757097596303\n",
      "Steps:  81%|▊| 12123/15000 [1:17:14<08:33,  5.60it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:36 - INFO - __main__ - train loss is 10.893724218243733\n",
      "Steps:  81%|▊| 12124/15000 [1:17:14<08:32,  5.61it/s, lr=9.03e-6, step_loss=0.3607/18/2023 20:20:37 - INFO - __main__ - train loss is 11.184598580235615\n",
      "Steps:  81%|▊| 12125/15000 [1:17:15<12:07,  3.95it/s, lr=9.03e-6, step_loss=0.2907/18/2023 20:20:38 - INFO - __main__ - Per validation step average loss is 0.0017195951659232378\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Cumulative validation average loss is 0.0017195951659232378\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Per validation step average loss is 0.007452845573425293\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Cumulative validation average loss is 0.00917244073934853\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Per validation step average loss is 0.0016464244108647108\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Cumulative validation average loss is 0.010818865150213242\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Per validation step average loss is 0.06109912320971489\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Cumulative validation average loss is 0.07191798835992813\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Per validation step average loss is 0.011865371838212013\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Cumulative validation average loss is 0.08378336019814014\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Per validation step average loss is 0.08102916181087494\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Cumulative validation average loss is 0.16481252200901508\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Per validation step average loss is 0.23275379836559296\n",
      "07/18/2023 20:20:38 - INFO - __main__ - Cumulative validation average loss is 0.39756632037460804\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Per validation step average loss is 0.058512620627880096\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Cumulative validation average loss is 0.45607894100248814\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Per validation step average loss is 0.048729922622442245\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Cumulative validation average loss is 0.5048088636249304\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Per validation step average loss is 0.20581789314746857\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Cumulative validation average loss is 0.710626756772399\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Per validation step average loss is 0.02962164580821991\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Cumulative validation average loss is 0.7402484025806189\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Per validation step average loss is 0.3275778293609619\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Cumulative validation average loss is 1.0678262319415808\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Average validation loss for Epoch 124 is 0.08898551932846506\n",
      "07/18/2023 20:20:39 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:20:52 - INFO - __main__ - Starting epoch 125\n",
      "07/18/2023 20:20:53 - INFO - __main__ - train loss is 0.06732350587844849\n",
      "Steps:  81%|▊| 12126/15000 [1:17:31<4:02:03,  5.05s/it, lr=9.03e-6, step_loss=0.07/18/2023 20:20:53 - INFO - __main__ - train loss is 0.4945228099822998\n",
      "Steps:  81%|▊| 12127/15000 [1:17:31<2:51:57,  3.59s/it, lr=9.03e-6, step_loss=0.07/18/2023 20:20:53 - INFO - __main__ - train loss is 0.5311072245240211\n",
      "Steps:  81%|▊| 12128/15000 [1:17:31<2:02:55,  2.57s/it, lr=9.03e-6, step_loss=0.07/18/2023 20:20:54 - INFO - __main__ - train loss is 0.5337873979005963\n",
      "Steps:  81%|▊| 12129/15000 [1:17:31<1:28:34,  1.85s/it, lr=9.03e-6, step_loss=0.07/18/2023 20:20:54 - INFO - __main__ - train loss is 0.7241511030588299\n",
      "Steps:  81%|▊| 12130/15000 [1:17:32<1:04:31,  1.35s/it, lr=9.03e-6, step_loss=0.07/18/2023 20:20:54 - INFO - __main__ - train loss is 0.7785993202123791\n",
      "Steps:  81%|▊| 12131/15000 [1:17:32<47:45,  1.00it/s, lr=9.03e-6, step_loss=0.0507/18/2023 20:20:54 - INFO - __main__ - train loss is 1.1313483400736004\n",
      "Steps:  81%|▊| 12132/15000 [1:17:32<35:58,  1.33it/s, lr=9.03e-6, step_loss=0.3507/18/2023 20:20:54 - INFO - __main__ - train loss is 1.3201201541814953\n",
      "Steps:  81%|▊| 12133/15000 [1:17:32<27:43,  1.72it/s, lr=9.03e-6, step_loss=0.1807/18/2023 20:20:54 - INFO - __main__ - train loss is 1.3222520726267248\n",
      "Steps:  81%|▊| 12134/15000 [1:17:32<21:56,  2.18it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:55 - INFO - __main__ - train loss is 1.3573454620782286\n",
      "Steps:  81%|▊| 12135/15000 [1:17:33<17:53,  2.67it/s, lr=9.03e-6, step_loss=0.0307/18/2023 20:20:55 - INFO - __main__ - train loss is 1.480368837947026\n",
      "Steps:  81%|▊| 12136/15000 [1:17:33<15:03,  3.17it/s, lr=9.03e-6, step_loss=0.1207/18/2023 20:20:55 - INFO - __main__ - train loss is 1.527629722142592\n",
      "Steps:  81%|▊| 12137/15000 [1:17:33<13:05,  3.65it/s, lr=9.03e-6, step_loss=0.0407/18/2023 20:20:55 - INFO - __main__ - train loss is 1.6179198215249926\n",
      "Steps:  81%|▊| 12138/15000 [1:17:33<11:41,  4.08it/s, lr=9.03e-6, step_loss=0.0907/18/2023 20:20:55 - INFO - __main__ - train loss is 1.8680092284921557\n",
      "Steps:  81%|▊| 12139/15000 [1:17:33<10:44,  4.44it/s, lr=9.03e-6, step_loss=0.2507/18/2023 20:20:56 - INFO - __main__ - train loss is 1.938494365895167\n",
      "Steps:  81%|▊| 12140/15000 [1:17:33<10:03,  4.74it/s, lr=9.03e-6, step_loss=0.0707/18/2023 20:20:56 - INFO - __main__ - train loss is 1.993929591262713\n",
      "Steps:  81%|▊| 12141/15000 [1:17:34<09:34,  4.97it/s, lr=9.03e-6, step_loss=0.0507/18/2023 20:20:56 - INFO - __main__ - train loss is 1.9965667130891234\n",
      "Steps:  81%|▊| 12142/15000 [1:17:34<09:14,  5.15it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:56 - INFO - __main__ - train loss is 2.002732902066782\n",
      "Steps:  81%|▊| 12143/15000 [1:17:34<09:00,  5.28it/s, lr=9.03e-6, step_loss=0.0007/18/2023 20:20:56 - INFO - __main__ - train loss is 2.1877011947799474\n",
      "Steps:  81%|▊| 12144/15000 [1:17:34<08:51,  5.37it/s, lr=9.03e-6, step_loss=0.1807/18/2023 20:20:56 - INFO - __main__ - train loss is 2.833782880799845\n",
      "Steps:  81%|▊| 12145/15000 [1:17:34<08:45,  5.44it/s, lr=9.03e-6, step_loss=0.6407/18/2023 20:20:57 - INFO - __main__ - train loss is 3.080620809691027\n",
      "Steps:  81%|▊| 12146/15000 [1:17:34<08:40,  5.49it/s, lr=9.03e-6, step_loss=0.2407/18/2023 20:20:57 - INFO - __main__ - train loss is 3.2305799566674978\n",
      "Steps:  81%|▊| 12147/15000 [1:17:35<08:36,  5.52it/s, lr=9.03e-6, step_loss=0.1507/18/2023 20:20:57 - INFO - __main__ - train loss is 3.2761100113857538\n",
      "Steps:  81%|▊| 12148/15000 [1:17:35<08:34,  5.54it/s, lr=9.03e-6, step_loss=0.0407/18/2023 20:20:57 - INFO - __main__ - train loss is 3.342565330909565\n",
      "Steps:  81%|▊| 12149/15000 [1:17:35<08:32,  5.56it/s, lr=9.02e-6, step_loss=0.0607/18/2023 20:20:57 - INFO - __main__ - train loss is 3.346611560555175\n",
      "Steps:  81%|▊| 12150/15000 [1:17:35<08:31,  5.57it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:20:57 - INFO - __main__ - train loss is 3.4011758503038436\n",
      "Steps:  81%|▊| 12151/15000 [1:17:35<08:30,  5.58it/s, lr=9.02e-6, step_loss=0.0507/18/2023 20:20:58 - INFO - __main__ - train loss is 3.5750683930236846\n",
      "Steps:  81%|▊| 12152/15000 [1:17:36<08:29,  5.59it/s, lr=9.02e-6, step_loss=0.1707/18/2023 20:20:58 - INFO - __main__ - train loss is 3.8026842859108\n",
      "Steps:  81%|▊| 12153/15000 [1:17:36<08:29,  5.59it/s, lr=9.02e-6, step_loss=0.2207/18/2023 20:20:58 - INFO - __main__ - train loss is 3.8046064478112385\n",
      "Steps:  81%|▊| 12154/15000 [1:17:36<08:28,  5.59it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:20:58 - INFO - __main__ - train loss is 3.807858476997353\n",
      "Steps:  81%|▊| 12155/15000 [1:17:36<08:44,  5.42it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:20:58 - INFO - __main__ - train loss is 3.842224324704148\n",
      "Steps:  81%|▊| 12156/15000 [1:17:36<08:39,  5.47it/s, lr=9.02e-6, step_loss=0.0307/18/2023 20:20:59 - INFO - __main__ - train loss is 3.917939836741425\n",
      "Steps:  81%|▊| 12157/15000 [1:17:36<08:35,  5.51it/s, lr=9.02e-6, step_loss=0.0707/18/2023 20:20:59 - INFO - __main__ - train loss is 3.950877948314883\n",
      "Steps:  81%|▊| 12158/15000 [1:17:37<08:33,  5.54it/s, lr=9.02e-6, step_loss=0.0307/18/2023 20:20:59 - INFO - __main__ - train loss is 4.081948800594546\n",
      "Steps:  81%|▊| 12159/15000 [1:17:37<08:31,  5.56it/s, lr=9.02e-6, step_loss=0.1307/18/2023 20:20:59 - INFO - __main__ - train loss is 4.362667961628176\n",
      "Steps:  81%|▊| 12160/15000 [1:17:37<08:29,  5.57it/s, lr=9.02e-6, step_loss=0.2807/18/2023 20:20:59 - INFO - __main__ - train loss is 4.3738298347452655\n",
      "Steps:  81%|▊| 12161/15000 [1:17:37<08:28,  5.58it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:20:59 - INFO - __main__ - train loss is 4.382399478578009\n",
      "Steps:  81%|▊| 12162/15000 [1:17:37<08:28,  5.58it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:00 - INFO - __main__ - train loss is 4.38494919531513\n",
      "Steps:  81%|▊| 12163/15000 [1:17:38<08:27,  5.59it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:00 - INFO - __main__ - train loss is 4.997303175856359\n",
      "Steps:  81%|▊| 12164/15000 [1:17:38<08:31,  5.55it/s, lr=9.02e-6, step_loss=0.6107/18/2023 20:21:00 - INFO - __main__ - train loss is 5.0242346982704476\n",
      "Steps:  81%|▊| 12165/15000 [1:17:38<08:29,  5.56it/s, lr=9.02e-6, step_loss=0.0207/18/2023 20:21:00 - INFO - __main__ - train loss is 5.0385125550674275\n",
      "Steps:  81%|▊| 12166/15000 [1:17:38<08:28,  5.57it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:00 - INFO - __main__ - train loss is 5.13705515593756\n",
      "Steps:  81%|▊| 12167/15000 [1:17:38<08:27,  5.58it/s, lr=9.02e-6, step_loss=0.0907/18/2023 20:21:01 - INFO - __main__ - train loss is 5.409448919002898\n",
      "Steps:  81%|▊| 12168/15000 [1:17:38<08:29,  5.56it/s, lr=9.02e-6, step_loss=0.2707/18/2023 20:21:01 - INFO - __main__ - train loss is 5.668604550068267\n",
      "Steps:  81%|▊| 12169/15000 [1:17:39<08:28,  5.57it/s, lr=9.02e-6, step_loss=0.2507/18/2023 20:21:01 - INFO - __main__ - train loss is 6.040839073364623\n",
      "Steps:  81%|▊| 12170/15000 [1:17:39<08:27,  5.57it/s, lr=9.02e-6, step_loss=0.3707/18/2023 20:21:01 - INFO - __main__ - train loss is 6.0449087877059355\n",
      "Steps:  81%|▊| 12171/15000 [1:17:39<08:26,  5.58it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:01 - INFO - __main__ - train loss is 6.0860185358906165\n",
      "Steps:  81%|▊| 12172/15000 [1:17:39<08:28,  5.57it/s, lr=9.02e-6, step_loss=0.0407/18/2023 20:21:01 - INFO - __main__ - train loss is 6.111601305776276\n",
      "Steps:  81%|▊| 12173/15000 [1:17:39<08:26,  5.58it/s, lr=9.02e-6, step_loss=0.0207/18/2023 20:21:02 - INFO - __main__ - train loss is 6.243429777794518\n",
      "Steps:  81%|▊| 12174/15000 [1:17:40<08:26,  5.58it/s, lr=9.02e-6, step_loss=0.1307/18/2023 20:21:02 - INFO - __main__ - train loss is 6.863447187119164\n",
      "Steps:  81%|▊| 12175/15000 [1:17:40<08:25,  5.59it/s, lr=9.02e-6, step_loss=0.6207/18/2023 20:21:02 - INFO - __main__ - train loss is 7.3207212664419785\n",
      "Steps:  81%|▊| 12176/15000 [1:17:40<08:24,  5.60it/s, lr=9.02e-6, step_loss=0.4507/18/2023 20:21:02 - INFO - __main__ - train loss is 7.429519442492165\n",
      "Steps:  81%|▊| 12177/15000 [1:17:40<08:24,  5.60it/s, lr=9.02e-6, step_loss=0.1007/18/2023 20:21:02 - INFO - __main__ - train loss is 8.110469726496376\n",
      "Steps:  81%|▊| 12178/15000 [1:17:40<08:23,  5.60it/s, lr=9.02e-6, step_loss=0.6807/18/2023 20:21:03 - INFO - __main__ - train loss is 8.122399791725911\n",
      "Steps:  81%|▊| 12179/15000 [1:17:40<08:23,  5.60it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:03 - INFO - __main__ - train loss is 8.427170380600728\n",
      "Steps:  81%|▊| 12180/15000 [1:17:41<08:23,  5.60it/s, lr=9.02e-6, step_loss=0.3007/18/2023 20:21:03 - INFO - __main__ - train loss is 8.733299120911397\n",
      "Steps:  81%|▊| 12181/15000 [1:17:41<08:23,  5.60it/s, lr=9.02e-6, step_loss=0.3007/18/2023 20:21:03 - INFO - __main__ - train loss is 8.744739846908487\n",
      "Steps:  81%|▊| 12182/15000 [1:17:41<08:22,  5.60it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:03 - INFO - __main__ - train loss is 8.755896534421481\n",
      "Steps:  81%|▊| 12183/15000 [1:17:41<08:22,  5.60it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:03 - INFO - __main__ - train loss is 9.259049977757968\n",
      "Steps:  81%|▊| 12184/15000 [1:17:41<08:22,  5.60it/s, lr=9.02e-6, step_loss=0.5007/18/2023 20:21:04 - INFO - __main__ - train loss is 9.27319978887681\n",
      "Steps:  81%|▊| 12185/15000 [1:17:41<08:22,  5.60it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:04 - INFO - __main__ - train loss is 9.284500649780966\n",
      "Steps:  81%|▊| 12186/15000 [1:17:42<08:22,  5.60it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:04 - INFO - __main__ - train loss is 9.361718817264773\n",
      "Steps:  81%|▊| 12187/15000 [1:17:42<08:22,  5.60it/s, lr=9.02e-6, step_loss=0.0707/18/2023 20:21:04 - INFO - __main__ - train loss is 9.489345504553057\n",
      "Steps:  81%|▊| 12188/15000 [1:17:42<08:21,  5.60it/s, lr=9.02e-6, step_loss=0.1207/18/2023 20:21:04 - INFO - __main__ - train loss is 9.498408455052413\n",
      "Steps:  81%|▊| 12189/15000 [1:17:42<08:21,  5.60it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:04 - INFO - __main__ - train loss is 9.504999042139389\n",
      "Steps:  81%|▊| 12190/15000 [1:17:42<08:21,  5.60it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:05 - INFO - __main__ - train loss is 9.510306860902347\n",
      "Steps:  81%|▊| 12191/15000 [1:17:43<08:22,  5.59it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:05 - INFO - __main__ - train loss is 9.524264779523946\n",
      "Steps:  81%|▊| 12192/15000 [1:17:43<08:21,  5.59it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:05 - INFO - __main__ - train loss is 9.545223700464703\n",
      "Steps:  81%|▊| 12193/15000 [1:17:43<08:21,  5.60it/s, lr=9.02e-6, step_loss=0.0207/18/2023 20:21:05 - INFO - __main__ - train loss is 9.577180212945677\n",
      "Steps:  81%|▊| 12194/15000 [1:17:43<08:21,  5.60it/s, lr=9.02e-6, step_loss=0.0307/18/2023 20:21:05 - INFO - __main__ - train loss is 9.86866081377957\n",
      "Steps:  81%|▊| 12195/15000 [1:17:43<08:21,  5.60it/s, lr=9.02e-6, step_loss=0.2907/18/2023 20:21:06 - INFO - __main__ - train loss is 9.90758576488588\n",
      "Steps:  81%|▊| 12196/15000 [1:17:43<08:24,  5.56it/s, lr=9.02e-6, step_loss=0.0307/18/2023 20:21:06 - INFO - __main__ - train loss is 9.922328517423011\n",
      "Steps:  81%|▊| 12197/15000 [1:17:44<08:22,  5.57it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:06 - INFO - __main__ - train loss is 10.265761122689582\n",
      "Steps:  81%|▊| 12198/15000 [1:17:44<08:21,  5.58it/s, lr=9.02e-6, step_loss=0.3407/18/2023 20:21:06 - INFO - __main__ - train loss is 10.296203092322685\n",
      "Steps:  81%|▊| 12199/15000 [1:17:44<08:20,  5.59it/s, lr=9.02e-6, step_loss=0.0307/18/2023 20:21:06 - INFO - __main__ - train loss is 10.412467554793693\n",
      "Steps:  81%|▊| 12200/15000 [1:17:44<08:20,  5.60it/s, lr=9.02e-6, step_loss=0.1107/18/2023 20:21:06 - INFO - __main__ - train loss is 10.55529178737197\n",
      "Steps:  81%|▊| 12201/15000 [1:17:44<08:20,  5.60it/s, lr=9.02e-6, step_loss=0.1407/18/2023 20:21:07 - INFO - __main__ - train loss is 10.57767570449505\n",
      "Steps:  81%|▊| 12202/15000 [1:17:45<08:19,  5.60it/s, lr=9.02e-6, step_loss=0.0207/18/2023 20:21:07 - INFO - __main__ - train loss is 10.824093137518503\n",
      "Steps:  81%|▊| 12203/15000 [1:17:45<08:24,  5.55it/s, lr=9.02e-6, step_loss=0.2407/18/2023 20:21:07 - INFO - __main__ - train loss is 10.833932225243188\n",
      "Steps:  81%|▊| 12204/15000 [1:17:45<08:26,  5.52it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:07 - INFO - __main__ - train loss is 11.453535918728448\n",
      "Steps:  81%|▊| 12205/15000 [1:17:45<08:26,  5.52it/s, lr=9.02e-6, step_loss=0.6207/18/2023 20:21:07 - INFO - __main__ - train loss is 11.59858930541668\n",
      "Steps:  81%|▊| 12206/15000 [1:17:45<08:24,  5.54it/s, lr=9.02e-6, step_loss=0.1407/18/2023 20:21:08 - INFO - __main__ - train loss is 11.60073172452394\n",
      "Steps:  81%|▊| 12207/15000 [1:17:45<08:26,  5.51it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:08 - INFO - __main__ - train loss is 11.618790480890311\n",
      "Steps:  81%|▊| 12208/15000 [1:17:46<08:28,  5.49it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:08 - INFO - __main__ - train loss is 11.829956058063544\n",
      "Steps:  81%|▊| 12209/15000 [1:17:46<08:25,  5.52it/s, lr=9.02e-6, step_loss=0.2107/18/2023 20:21:08 - INFO - __main__ - train loss is 11.838414374389686\n",
      "Steps:  81%|▊| 12210/15000 [1:17:46<08:22,  5.55it/s, lr=9.02e-6, step_loss=0.0007/18/2023 20:21:08 - INFO - __main__ - train loss is 12.244510683813132\n",
      "Steps:  81%|▊| 12211/15000 [1:17:46<08:21,  5.56it/s, lr=9.02e-6, step_loss=0.4007/18/2023 20:21:08 - INFO - __main__ - train loss is 12.263271312811412\n",
      "Steps:  81%|▊| 12212/15000 [1:17:46<08:23,  5.54it/s, lr=9.02e-6, step_loss=0.0107/18/2023 20:21:09 - INFO - __main__ - train loss is 12.302142668166198\n",
      "Steps:  81%|▊| 12213/15000 [1:17:46<08:21,  5.56it/s, lr=9.02e-6, step_loss=0.0307/18/2023 20:21:09 - INFO - __main__ - train loss is 12.486069503822364\n",
      "Steps:  81%|▊| 12214/15000 [1:17:47<08:19,  5.58it/s, lr=9.01e-6, step_loss=0.1807/18/2023 20:21:09 - INFO - __main__ - train loss is 12.756270948448218\n",
      "Steps:  81%|▊| 12215/15000 [1:17:47<08:18,  5.58it/s, lr=9.01e-6, step_loss=0.2707/18/2023 20:21:09 - INFO - __main__ - train loss is 13.085833135643043\n",
      "Steps:  81%|▊| 12216/15000 [1:17:47<08:17,  5.59it/s, lr=9.01e-6, step_loss=0.3307/18/2023 20:21:09 - INFO - __main__ - train loss is 13.112487349309959\n",
      "Steps:  81%|▊| 12217/15000 [1:17:47<08:21,  5.54it/s, lr=9.01e-6, step_loss=0.0207/18/2023 20:21:10 - INFO - __main__ - train loss is 13.21446076373104\n",
      "Steps:  81%|▊| 12218/15000 [1:17:47<08:21,  5.55it/s, lr=9.01e-6, step_loss=0.1007/18/2023 20:21:10 - INFO - __main__ - train loss is 13.22236631589476\n",
      "Steps:  81%|▊| 12219/15000 [1:17:48<08:19,  5.56it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:10 - INFO - __main__ - train loss is 13.23880898731295\n",
      "Steps:  81%|▊| 12220/15000 [1:17:48<08:18,  5.58it/s, lr=9.01e-6, step_loss=0.0107/18/2023 20:21:10 - INFO - __main__ - train loss is 13.291110960417427\n",
      "Steps:  81%|▊| 12221/15000 [1:17:48<08:17,  5.58it/s, lr=9.01e-6, step_loss=0.0507/18/2023 20:21:10 - INFO - __main__ - train loss is 13.469947544508614\n",
      "Steps:  81%|▊| 12222/15000 [1:17:48<11:29,  4.03it/s, lr=9.01e-6, step_loss=0.1707/18/2023 20:21:11 - INFO - __main__ - Per validation step average loss is 0.32668036222457886\n",
      "07/18/2023 20:21:11 - INFO - __main__ - Cumulative validation average loss is 0.32668036222457886\n",
      "07/18/2023 20:21:11 - INFO - __main__ - Per validation step average loss is 0.01187057700008154\n",
      "07/18/2023 20:21:11 - INFO - __main__ - Cumulative validation average loss is 0.3385509392246604\n",
      "07/18/2023 20:21:11 - INFO - __main__ - Per validation step average loss is 0.19447973370552063\n",
      "07/18/2023 20:21:11 - INFO - __main__ - Cumulative validation average loss is 0.533030672930181\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Per validation step average loss is 0.159861221909523\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Cumulative validation average loss is 0.692891894839704\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Per validation step average loss is 0.4407685399055481\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Cumulative validation average loss is 1.1336604347452521\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Per validation step average loss is 0.37558239698410034\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Cumulative validation average loss is 1.5092428317293525\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Per validation step average loss is 0.07285996526479721\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Cumulative validation average loss is 1.5821027969941497\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Per validation step average loss is 0.023956026881933212\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Cumulative validation average loss is 1.606058823876083\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Per validation step average loss is 0.2578752636909485\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Cumulative validation average loss is 1.8639340875670314\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Per validation step average loss is 0.0023993393406271935\n",
      "07/18/2023 20:21:12 - INFO - __main__ - Cumulative validation average loss is 1.8663334269076586\n",
      "07/18/2023 20:21:13 - INFO - __main__ - Per validation step average loss is 0.1151677668094635\n",
      "07/18/2023 20:21:13 - INFO - __main__ - Cumulative validation average loss is 1.981501193717122\n",
      "07/18/2023 20:21:13 - INFO - __main__ - Per validation step average loss is 0.017322756350040436\n",
      "07/18/2023 20:21:13 - INFO - __main__ - Cumulative validation average loss is 1.9988239500671625\n",
      "07/18/2023 20:21:13 - INFO - __main__ - Average validation loss for Epoch 125 is 0.16656866250559688\n",
      "07/18/2023 20:21:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:21:26 - INFO - __main__ - Starting epoch 126\n",
      "07/18/2023 20:21:26 - INFO - __main__ - train loss is 0.00319121778011322\n",
      "Steps:  81%|▊| 12223/15000 [1:18:04<3:48:17,  4.93s/it, lr=9.01e-6, step_loss=0.07/18/2023 20:21:26 - INFO - __main__ - train loss is 0.006158699980005622\n",
      "Steps:  81%|▊| 12224/15000 [1:18:04<2:42:13,  3.51s/it, lr=9.01e-6, step_loss=0.07/18/2023 20:21:27 - INFO - __main__ - train loss is 0.1268434131052345\n",
      "Steps:  82%|▊| 12225/15000 [1:18:05<1:55:59,  2.51s/it, lr=9.01e-6, step_loss=0.07/18/2023 20:21:27 - INFO - __main__ - train loss is 0.13088512583635747\n",
      "Steps:  82%|▊| 12226/15000 [1:18:05<1:23:37,  1.81s/it, lr=9.01e-6, step_loss=0.07/18/2023 20:21:27 - INFO - __main__ - train loss is 0.1933235616888851\n",
      "Steps:  82%|▊| 12227/15000 [1:18:05<1:01:02,  1.32s/it, lr=9.01e-6, step_loss=0.07/18/2023 20:21:27 - INFO - __main__ - train loss is 0.27559320046566427\n",
      "Steps:  82%|▊| 12228/15000 [1:18:05<45:10,  1.02it/s, lr=9.01e-6, step_loss=0.0807/18/2023 20:21:27 - INFO - __main__ - train loss is 0.2789501380175352\n",
      "Steps:  82%|▊| 12229/15000 [1:18:05<34:10,  1.35it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:28 - INFO - __main__ - train loss is 0.7960396241396666\n",
      "Steps:  82%|▊| 12230/15000 [1:18:05<26:32,  1.74it/s, lr=9.01e-6, step_loss=0.5107/18/2023 20:21:28 - INFO - __main__ - train loss is 0.8154833000153303\n",
      "Steps:  82%|▊| 12231/15000 [1:18:06<21:03,  2.19it/s, lr=9.01e-6, step_loss=0.0107/18/2023 20:21:28 - INFO - __main__ - train loss is 1.0703565161675215\n",
      "Steps:  82%|▊| 12232/15000 [1:18:06<17:12,  2.68it/s, lr=9.01e-6, step_loss=0.2507/18/2023 20:21:28 - INFO - __main__ - train loss is 1.0724717774428427\n",
      "Steps:  82%|▊| 12233/15000 [1:18:06<14:30,  3.18it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:28 - INFO - __main__ - train loss is 1.0753725594840944\n",
      "Steps:  82%|▊| 12234/15000 [1:18:06<12:37,  3.65it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:28 - INFO - __main__ - train loss is 1.088110585231334\n",
      "Steps:  82%|▊| 12235/15000 [1:18:06<11:19,  4.07it/s, lr=9.01e-6, step_loss=0.0107/18/2023 20:21:29 - INFO - __main__ - train loss is 1.675287385005504\n",
      "Steps:  82%|▊| 12236/15000 [1:18:07<10:27,  4.40it/s, lr=9.01e-6, step_loss=0.5807/18/2023 20:21:29 - INFO - __main__ - train loss is 2.232195992488414\n",
      "Steps:  82%|▊| 12237/15000 [1:18:07<09:55,  4.64it/s, lr=9.01e-6, step_loss=0.5507/18/2023 20:21:29 - INFO - __main__ - train loss is 2.2350516305305064\n",
      "Steps:  82%|▊| 12238/15000 [1:18:07<09:25,  4.89it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:29 - INFO - __main__ - train loss is 2.2363956512417644\n",
      "Steps:  82%|▊| 12239/15000 [1:18:07<09:02,  5.09it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:29 - INFO - __main__ - train loss is 2.279400532832369\n",
      "Steps:  82%|▊| 12240/15000 [1:18:07<08:47,  5.23it/s, lr=9.01e-6, step_loss=0.0407/18/2023 20:21:30 - INFO - __main__ - train loss is 2.697343980660662\n",
      "Steps:  82%|▊| 12241/15000 [1:18:07<08:36,  5.34it/s, lr=9.01e-6, step_loss=0.4107/18/2023 20:21:30 - INFO - __main__ - train loss is 2.6998109875712544\n",
      "Steps:  82%|▊| 12242/15000 [1:18:08<08:29,  5.41it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:30 - INFO - __main__ - train loss is 2.826635321835056\n",
      "Steps:  82%|▊| 12243/15000 [1:18:08<08:24,  5.47it/s, lr=9.01e-6, step_loss=0.1207/18/2023 20:21:30 - INFO - __main__ - train loss is 2.8278388106264174\n",
      "Steps:  82%|▊| 12244/15000 [1:18:08<08:20,  5.51it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:30 - INFO - __main__ - train loss is 2.871899473015219\n",
      "Steps:  82%|▊| 12245/15000 [1:18:08<08:17,  5.54it/s, lr=9.01e-6, step_loss=0.0407/18/2023 20:21:30 - INFO - __main__ - train loss is 3.0189547413028777\n",
      "Steps:  82%|▊| 12246/15000 [1:18:08<08:15,  5.56it/s, lr=9.01e-6, step_loss=0.1407/18/2023 20:21:31 - INFO - __main__ - train loss is 3.0405832924880087\n",
      "Steps:  82%|▊| 12247/15000 [1:18:09<08:15,  5.56it/s, lr=9.01e-6, step_loss=0.0207/18/2023 20:21:31 - INFO - __main__ - train loss is 3.074132198933512\n",
      "Steps:  82%|▊| 12248/15000 [1:18:09<08:13,  5.57it/s, lr=9.01e-6, step_loss=0.0307/18/2023 20:21:31 - INFO - __main__ - train loss is 3.185387718025595\n",
      "Steps:  82%|▊| 12249/15000 [1:18:09<08:12,  5.58it/s, lr=9.01e-6, step_loss=0.1107/18/2023 20:21:31 - INFO - __main__ - train loss is 3.192126356996596\n",
      "Steps:  82%|▊| 12250/15000 [1:18:09<08:12,  5.59it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:31 - INFO - __main__ - train loss is 3.246252597309649\n",
      "Steps:  82%|▊| 12251/15000 [1:18:09<08:11,  5.59it/s, lr=9.01e-6, step_loss=0.0507/18/2023 20:21:32 - INFO - __main__ - train loss is 3.4917475739493966\n",
      "Steps:  82%|▊| 12252/15000 [1:18:09<08:11,  5.59it/s, lr=9.01e-6, step_loss=0.2407/18/2023 20:21:32 - INFO - __main__ - train loss is 3.865575418807566\n",
      "Steps:  82%|▊| 12253/15000 [1:18:10<08:10,  5.60it/s, lr=9.01e-6, step_loss=0.3707/18/2023 20:21:32 - INFO - __main__ - train loss is 3.893443771637976\n",
      "Steps:  82%|▊| 12254/15000 [1:18:10<08:10,  5.60it/s, lr=9.01e-6, step_loss=0.0207/18/2023 20:21:32 - INFO - __main__ - train loss is 3.9578719595447183\n",
      "Steps:  82%|▊| 12255/15000 [1:18:10<08:10,  5.60it/s, lr=9.01e-6, step_loss=0.0607/18/2023 20:21:32 - INFO - __main__ - train loss is 4.1420867601409554\n",
      "Steps:  82%|▊| 12256/15000 [1:18:10<08:10,  5.60it/s, lr=9.01e-6, step_loss=0.1807/18/2023 20:21:32 - INFO - __main__ - train loss is 4.1446954475250095\n",
      "Steps:  82%|▊| 12257/15000 [1:18:10<08:10,  5.59it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:33 - INFO - __main__ - train loss is 4.273550065001473\n",
      "Steps:  82%|▊| 12258/15000 [1:18:10<08:10,  5.59it/s, lr=9.01e-6, step_loss=0.1207/18/2023 20:21:33 - INFO - __main__ - train loss is 4.497193174203858\n",
      "Steps:  82%|▊| 12259/15000 [1:18:11<08:09,  5.59it/s, lr=9.01e-6, step_loss=0.2207/18/2023 20:21:33 - INFO - __main__ - train loss is 4.499739854363725\n",
      "Steps:  82%|▊| 12260/15000 [1:18:11<08:09,  5.60it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:33 - INFO - __main__ - train loss is 4.505453609628603\n",
      "Steps:  82%|▊| 12261/15000 [1:18:11<08:09,  5.60it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:33 - INFO - __main__ - train loss is 4.882746183080599\n",
      "Steps:  82%|▊| 12262/15000 [1:18:11<08:09,  5.60it/s, lr=9.01e-6, step_loss=0.3707/18/2023 20:21:33 - INFO - __main__ - train loss is 4.893630067585036\n",
      "Steps:  82%|▊| 12263/15000 [1:18:11<08:09,  5.59it/s, lr=9.01e-6, step_loss=0.0107/18/2023 20:21:34 - INFO - __main__ - train loss is 5.036629567621276\n",
      "Steps:  82%|▊| 12264/15000 [1:18:12<08:08,  5.60it/s, lr=9.01e-6, step_loss=0.1407/18/2023 20:21:34 - INFO - __main__ - train loss is 5.040544992079958\n",
      "Steps:  82%|▊| 12265/15000 [1:18:12<08:08,  5.60it/s, lr=9.01e-6, step_loss=0.0007/18/2023 20:21:34 - INFO - __main__ - train loss is 5.078016938408837\n",
      "Steps:  82%|▊| 12266/15000 [1:18:12<08:08,  5.60it/s, lr=9.01e-6, step_loss=0.0307/18/2023 20:21:34 - INFO - __main__ - train loss is 5.165385158499703\n",
      "Steps:  82%|▊| 12267/15000 [1:18:12<08:08,  5.60it/s, lr=9.01e-6, step_loss=0.0807/18/2023 20:21:34 - INFO - __main__ - train loss is 5.387151868781075\n",
      "Steps:  82%|▊| 12268/15000 [1:18:12<08:07,  5.60it/s, lr=9.01e-6, step_loss=0.2207/18/2023 20:21:35 - INFO - __main__ - train loss is 5.414286628132686\n",
      "Steps:  82%|▊| 12269/15000 [1:18:12<08:07,  5.60it/s, lr=9.01e-6, step_loss=0.0207/18/2023 20:21:35 - INFO - __main__ - train loss is 5.6283395735081285\n",
      "Steps:  82%|▊| 12270/15000 [1:18:13<08:07,  5.60it/s, lr=9.01e-6, step_loss=0.2107/18/2023 20:21:35 - INFO - __main__ - train loss is 6.088989719515666\n",
      "Steps:  82%|▊| 12271/15000 [1:18:13<08:06,  5.60it/s, lr=9.01e-6, step_loss=0.4607/18/2023 20:21:35 - INFO - __main__ - train loss is 6.994832500582561\n",
      "Steps:  82%|▊| 12272/15000 [1:18:13<08:06,  5.61it/s, lr=9.01e-6, step_loss=0.9007/18/2023 20:21:35 - INFO - __main__ - train loss is 7.191731914645061\n",
      "Steps:  82%|▊| 12273/15000 [1:18:13<08:06,  5.61it/s, lr=9.01e-6, step_loss=0.1907/18/2023 20:21:35 - INFO - __main__ - train loss is 7.279199436074123\n",
      "Steps:  82%|▊| 12274/15000 [1:18:13<08:06,  5.61it/s, lr=9.01e-6, step_loss=0.0807/18/2023 20:21:36 - INFO - __main__ - train loss is 7.294843829935417\n",
      "Steps:  82%|▊| 12275/15000 [1:18:14<08:06,  5.60it/s, lr=9.01e-6, step_loss=0.0107/18/2023 20:21:36 - INFO - __main__ - train loss is 7.440714664524421\n",
      "Steps:  82%|▊| 12276/15000 [1:18:14<08:05,  5.61it/s, lr=9.01e-6, step_loss=0.1407/18/2023 20:21:36 - INFO - __main__ - train loss is 7.739272333448753\n",
      "Steps:  82%|▊| 12277/15000 [1:18:14<08:05,  5.61it/s, lr=9.01e-6, step_loss=0.2907/18/2023 20:21:36 - INFO - __main__ - train loss is 7.79287002957426\n",
      "Steps:  82%|▊| 12278/15000 [1:18:14<08:05,  5.61it/s, lr=9e-6, step_loss=0.0536]07/18/2023 20:21:36 - INFO - __main__ - train loss is 7.7955548672471195\n",
      "Steps:  82%|▊| 12279/15000 [1:18:14<08:05,  5.61it/s, lr=9e-6, step_loss=0.0026807/18/2023 20:21:37 - INFO - __main__ - train loss is 8.400096645811573\n",
      "Steps:  82%|█▋| 12280/15000 [1:18:14<08:05,  5.61it/s, lr=9e-6, step_loss=0.605]07/18/2023 20:21:37 - INFO - __main__ - train loss is 8.473114861408249\n",
      "Steps:  82%|█▋| 12281/15000 [1:18:15<08:05,  5.60it/s, lr=9e-6, step_loss=0.073]07/18/2023 20:21:37 - INFO - __main__ - train loss is 8.967512591043487\n",
      "Steps:  82%|█▋| 12282/15000 [1:18:15<08:04,  5.61it/s, lr=9e-6, step_loss=0.494]07/18/2023 20:21:37 - INFO - __main__ - train loss is 9.045897474745288\n",
      "Steps:  82%|▊| 12283/15000 [1:18:15<08:05,  5.60it/s, lr=9e-6, step_loss=0.0784]07/18/2023 20:21:37 - INFO - __main__ - train loss is 9.058827491709962\n",
      "Steps:  82%|▊| 12284/15000 [1:18:15<08:04,  5.60it/s, lr=9e-6, step_loss=0.0129]07/18/2023 20:21:37 - INFO - __main__ - train loss is 9.07832052768208\n",
      "Steps:  82%|▊| 12285/15000 [1:18:15<08:04,  5.60it/s, lr=9e-6, step_loss=0.0195]07/18/2023 20:21:38 - INFO - __main__ - train loss is 9.14028605655767\n",
      "Steps:  82%|█▋| 12286/15000 [1:18:15<08:09,  5.55it/s, lr=9e-6, step_loss=0.062]07/18/2023 20:21:38 - INFO - __main__ - train loss is 9.142504737712443\n",
      "Steps:  82%|▊| 12287/15000 [1:18:16<08:07,  5.56it/s, lr=9e-6, step_loss=0.0022207/18/2023 20:21:38 - INFO - __main__ - train loss is 9.246786684729159\n",
      "Steps:  82%|█▋| 12288/15000 [1:18:16<08:08,  5.56it/s, lr=9e-6, step_loss=0.104]07/18/2023 20:21:38 - INFO - __main__ - train loss is 9.786331624723971\n",
      "Steps:  82%|██▍| 12289/15000 [1:18:16<08:06,  5.57it/s, lr=9e-6, step_loss=0.54]07/18/2023 20:21:38 - INFO - __main__ - train loss is 10.141016752459109\n",
      "Steps:  82%|█▋| 12290/15000 [1:18:16<08:06,  5.57it/s, lr=9e-6, step_loss=0.355]07/18/2023 20:21:39 - INFO - __main__ - train loss is 10.166288268752396\n",
      "Steps:  82%|▊| 12291/15000 [1:18:16<08:05,  5.58it/s, lr=9e-6, step_loss=0.0253]07/18/2023 20:21:39 - INFO - __main__ - train loss is 10.622877609916031\n",
      "Steps:  82%|█▋| 12292/15000 [1:18:17<08:04,  5.59it/s, lr=9e-6, step_loss=0.457]07/18/2023 20:21:39 - INFO - __main__ - train loss is 10.624846189282835\n",
      "Steps:  82%|▊| 12293/15000 [1:18:17<08:05,  5.58it/s, lr=9e-6, step_loss=0.0019707/18/2023 20:21:39 - INFO - __main__ - train loss is 10.631857628934085\n",
      "Steps:  82%|▊| 12294/15000 [1:18:17<08:04,  5.59it/s, lr=9e-6, step_loss=0.0070107/18/2023 20:21:39 - INFO - __main__ - train loss is 11.159524674527347\n",
      "Steps:  82%|█▋| 12295/15000 [1:18:17<08:03,  5.59it/s, lr=9e-6, step_loss=0.528]07/18/2023 20:21:39 - INFO - __main__ - train loss is 11.502020413987339\n",
      "Steps:  82%|█▋| 12296/15000 [1:18:17<08:03,  5.60it/s, lr=9e-6, step_loss=0.342]07/18/2023 20:21:40 - INFO - __main__ - train loss is 11.506331418640912\n",
      "Steps:  82%|▊| 12297/15000 [1:18:17<08:03,  5.59it/s, lr=9e-6, step_loss=0.0043107/18/2023 20:21:40 - INFO - __main__ - train loss is 11.515523963607848\n",
      "Steps:  82%|▊| 12298/15000 [1:18:18<08:02,  5.60it/s, lr=9e-6, step_loss=0.0091907/18/2023 20:21:40 - INFO - __main__ - train loss is 11.61870724055916\n",
      "Steps:  82%|█▋| 12299/15000 [1:18:18<08:02,  5.60it/s, lr=9e-6, step_loss=0.103]07/18/2023 20:21:40 - INFO - __main__ - train loss is 12.36511164996773\n",
      "Steps:  82%|█▋| 12300/15000 [1:18:18<08:02,  5.60it/s, lr=9e-6, step_loss=0.746]07/18/2023 20:21:40 - INFO - __main__ - train loss is 12.68564221356064\n",
      "Steps:  82%|█▋| 12301/15000 [1:18:18<08:02,  5.60it/s, lr=9e-6, step_loss=0.321]07/18/2023 20:21:40 - INFO - __main__ - train loss is 12.687267989385873\n",
      "Steps:  82%|▊| 12302/15000 [1:18:18<08:01,  5.60it/s, lr=9e-6, step_loss=0.0016307/18/2023 20:21:41 - INFO - __main__ - train loss is 12.892350614536554\n",
      "Steps:  82%|█▋| 12303/15000 [1:18:19<08:01,  5.60it/s, lr=9e-6, step_loss=0.205]07/18/2023 20:21:41 - INFO - __main__ - train loss is 12.931384474504739\n",
      "Steps:  82%|█▋| 12304/15000 [1:18:19<08:01,  5.59it/s, lr=9e-6, step_loss=0.039]07/18/2023 20:21:41 - INFO - __main__ - train loss is 12.935270996298641\n",
      "Steps:  82%|▊| 12305/15000 [1:18:19<08:01,  5.60it/s, lr=9e-6, step_loss=0.0038907/18/2023 20:21:41 - INFO - __main__ - train loss is 13.016203330364078\n",
      "Steps:  82%|▊| 12306/15000 [1:18:19<08:01,  5.60it/s, lr=9e-6, step_loss=0.0809]07/18/2023 20:21:41 - INFO - __main__ - train loss is 13.020534698385745\n",
      "Steps:  82%|▊| 12307/15000 [1:18:19<08:01,  5.60it/s, lr=9e-6, step_loss=0.0043307/18/2023 20:21:42 - INFO - __main__ - train loss is 13.343814168591052\n",
      "Steps:  82%|█▋| 12308/15000 [1:18:19<08:01,  5.59it/s, lr=9e-6, step_loss=0.323]07/18/2023 20:21:42 - INFO - __main__ - train loss is 13.35474992217496\n",
      "Steps:  82%|▊| 12309/15000 [1:18:20<08:10,  5.48it/s, lr=9e-6, step_loss=0.0109]07/18/2023 20:21:42 - INFO - __main__ - train loss is 13.394777767825872\n",
      "Steps:  82%|██▍| 12310/15000 [1:18:20<08:14,  5.44it/s, lr=9e-6, step_loss=0.04]07/18/2023 20:21:42 - INFO - __main__ - train loss is 13.706173651386052\n",
      "Steps:  82%|█▋| 12311/15000 [1:18:20<08:15,  5.43it/s, lr=9e-6, step_loss=0.311]07/18/2023 20:21:42 - INFO - __main__ - train loss is 13.794634737540036\n",
      "Steps:  82%|▊| 12312/15000 [1:18:20<08:16,  5.41it/s, lr=9e-6, step_loss=0.0885]07/18/2023 20:21:42 - INFO - __main__ - train loss is 13.796421272214502\n",
      "Steps:  82%|▊| 12313/15000 [1:18:20<08:14,  5.43it/s, lr=9e-6, step_loss=0.0017907/18/2023 20:21:43 - INFO - __main__ - train loss is 13.899250050541013\n",
      "Steps:  82%|█▋| 12314/15000 [1:18:21<08:32,  5.25it/s, lr=9e-6, step_loss=0.103]07/18/2023 20:21:43 - INFO - __main__ - train loss is 13.954190825577825\n",
      "Steps:  82%|▊| 12315/15000 [1:18:21<08:34,  5.22it/s, lr=9e-6, step_loss=0.0549]07/18/2023 20:21:43 - INFO - __main__ - train loss is 13.982312092091888\n",
      "Steps:  82%|▊| 12316/15000 [1:18:21<08:35,  5.21it/s, lr=9e-6, step_loss=0.0281]07/18/2023 20:21:43 - INFO - __main__ - train loss is 14.363856890704483\n",
      "Steps:  82%|█▋| 12317/15000 [1:18:21<08:36,  5.20it/s, lr=9e-6, step_loss=0.382]07/18/2023 20:21:43 - INFO - __main__ - train loss is 14.378594044130296\n",
      "Steps:  82%|▊| 12318/15000 [1:18:21<08:37,  5.19it/s, lr=9e-6, step_loss=0.0147]07/18/2023 20:21:44 - INFO - __main__ - train loss is 14.398627466987818\n",
      "Steps:  82%|██▍| 12319/15000 [1:18:22<12:28,  3.58it/s, lr=9e-6, step_loss=0.02]07/18/2023 20:21:45 - INFO - __main__ - Per validation step average loss is 0.05174718797206879\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Cumulative validation average loss is 0.05174718797206879\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Per validation step average loss is 0.005089831072837114\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Cumulative validation average loss is 0.0568370190449059\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Per validation step average loss is 0.02159779705107212\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Cumulative validation average loss is 0.07843481609597802\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Per validation step average loss is 0.17307426035404205\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Cumulative validation average loss is 0.2515090764500201\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Per validation step average loss is 0.11437182128429413\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Cumulative validation average loss is 0.3658808977343142\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Per validation step average loss is 0.10467466711997986\n",
      "07/18/2023 20:21:45 - INFO - __main__ - Cumulative validation average loss is 0.47055556485429406\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Per validation step average loss is 0.21790306270122528\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Cumulative validation average loss is 0.6884586275555193\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Per validation step average loss is 0.13675251603126526\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Cumulative validation average loss is 0.8252111435867846\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Per validation step average loss is 0.15720239281654358\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Cumulative validation average loss is 0.9824135364033282\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Per validation step average loss is 0.002716617425903678\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Cumulative validation average loss is 0.9851301538292319\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Per validation step average loss is 0.05672522261738777\n",
      "07/18/2023 20:21:46 - INFO - __main__ - Cumulative validation average loss is 1.0418553764466196\n",
      "07/18/2023 20:21:47 - INFO - __main__ - Per validation step average loss is 0.009626133367419243\n",
      "07/18/2023 20:21:47 - INFO - __main__ - Cumulative validation average loss is 1.0514815098140389\n",
      "07/18/2023 20:21:47 - INFO - __main__ - Average validation loss for Epoch 126 is 0.08762345915116991\n",
      "07/18/2023 20:21:47 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:22:00 - INFO - __main__ - Starting epoch 127\n",
      "07/18/2023 20:22:00 - INFO - __main__ - train loss is 0.011256646364927292\n",
      "Steps:  82%|▊| 12320/15000 [1:18:38<3:46:02,  5.06s/it, lr=9e-6, step_loss=0.01107/18/2023 20:22:00 - INFO - __main__ - train loss is 0.0542595311999321\n",
      "Steps:  82%|▊| 12321/15000 [1:18:38<2:40:33,  3.60s/it, lr=9e-6, step_loss=0.04307/18/2023 20:22:01 - INFO - __main__ - train loss is 0.11040982976555824\n",
      "Steps:  82%|▊| 12322/15000 [1:18:38<1:54:48,  2.57s/it, lr=9e-6, step_loss=0.05607/18/2023 20:22:01 - INFO - __main__ - train loss is 0.12383032403886318\n",
      "Steps:  82%|▊| 12323/15000 [1:18:39<1:22:46,  1.86s/it, lr=9e-6, step_loss=0.01307/18/2023 20:22:01 - INFO - __main__ - train loss is 0.16369549371302128\n",
      "Steps:  82%|▊| 12324/15000 [1:18:39<1:00:19,  1.35s/it, lr=9e-6, step_loss=0.03907/18/2023 20:22:01 - INFO - __main__ - train loss is 0.7131629977375269\n",
      "Steps:  82%|█▋| 12325/15000 [1:18:39<44:42,  1.00s/it, lr=9e-6, step_loss=0.549]07/18/2023 20:22:01 - INFO - __main__ - train loss is 0.8903055880218744\n",
      "Steps:  82%|█▋| 12326/15000 [1:18:39<33:40,  1.32it/s, lr=9e-6, step_loss=0.177]07/18/2023 20:22:01 - INFO - __main__ - train loss is 1.2606463823467493\n",
      "Steps:  82%|██▍| 12327/15000 [1:18:39<25:56,  1.72it/s, lr=9e-6, step_loss=0.37]07/18/2023 20:22:02 - INFO - __main__ - train loss is 1.8519548568874598\n",
      "Steps:  82%|█▋| 12328/15000 [1:18:39<20:32,  2.17it/s, lr=9e-6, step_loss=0.591]07/18/2023 20:22:02 - INFO - __main__ - train loss is 1.860287363640964\n",
      "Steps:  82%|▊| 12329/15000 [1:18:40<16:44,  2.66it/s, lr=9e-6, step_loss=0.0083307/18/2023 20:22:02 - INFO - __main__ - train loss is 1.9493523938581347\n",
      "Steps:  82%|▊| 12330/15000 [1:18:40<14:05,  3.16it/s, lr=9e-6, step_loss=0.0891]07/18/2023 20:22:02 - INFO - __main__ - train loss is 2.1580606503412127\n",
      "Steps:  82%|█▋| 12331/15000 [1:18:40<12:13,  3.64it/s, lr=9e-6, step_loss=0.209]07/18/2023 20:22:02 - INFO - __main__ - train loss is 2.1801986983045936\n",
      "Steps:  82%|▊| 12332/15000 [1:18:40<10:55,  4.07it/s, lr=9e-6, step_loss=0.0221]07/18/2023 20:22:02 - INFO - __main__ - train loss is 2.3298153271898627\n",
      "Steps:  82%|██▍| 12333/15000 [1:18:40<10:01,  4.43it/s, lr=9e-6, step_loss=0.15]07/18/2023 20:22:03 - INFO - __main__ - train loss is 2.4349974310025573\n",
      "Steps:  82%|█▋| 12334/15000 [1:18:41<09:23,  4.73it/s, lr=9e-6, step_loss=0.105]07/18/2023 20:22:03 - INFO - __main__ - train loss is 2.6562300538644195\n",
      "Steps:  82%|█▋| 12335/15000 [1:18:41<08:56,  4.96it/s, lr=9e-6, step_loss=0.221]07/18/2023 20:22:03 - INFO - __main__ - train loss is 2.737021422944963\n",
      "Steps:  82%|▊| 12336/15000 [1:18:41<08:38,  5.14it/s, lr=9e-6, step_loss=0.0808]07/18/2023 20:22:03 - INFO - __main__ - train loss is 2.9854482477530837\n",
      "Steps:  82%|█▋| 12337/15000 [1:18:41<08:25,  5.27it/s, lr=9e-6, step_loss=0.248]07/18/2023 20:22:03 - INFO - __main__ - train loss is 3.0875961845740676\n",
      "Steps:  82%|█▋| 12338/15000 [1:18:41<08:16,  5.37it/s, lr=9e-6, step_loss=0.102]07/18/2023 20:22:04 - INFO - __main__ - train loss is 3.091194260166958\n",
      "Steps:  82%|▊| 12339/15000 [1:18:41<08:09,  5.43it/s, lr=9e-6, step_loss=0.0036]07/18/2023 20:22:04 - INFO - __main__ - train loss is 3.100033485563472\n",
      "Steps:  82%|▊| 12340/15000 [1:18:42<08:05,  5.48it/s, lr=9e-6, step_loss=0.0088407/18/2023 20:22:04 - INFO - __main__ - train loss is 3.1019456456415355\n",
      "Steps:  82%|▊| 12341/15000 [1:18:42<08:01,  5.52it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:04 - INFO - __main__ - train loss is 3.858298189472407\n",
      "Steps:  82%|▊| 12342/15000 [1:18:42<07:59,  5.54it/s, lr=8.99e-6, step_loss=0.7507/18/2023 20:22:04 - INFO - __main__ - train loss is 3.893280442338437\n",
      "Steps:  82%|▊| 12343/15000 [1:18:42<07:59,  5.54it/s, lr=8.99e-6, step_loss=0.0307/18/2023 20:22:04 - INFO - __main__ - train loss is 3.9696403327398\n",
      "Steps:  82%|▊| 12344/15000 [1:18:42<07:57,  5.56it/s, lr=8.99e-6, step_loss=0.0707/18/2023 20:22:05 - INFO - __main__ - train loss is 3.995456030126661\n",
      "Steps:  82%|▊| 12345/15000 [1:18:43<07:56,  5.57it/s, lr=8.99e-6, step_loss=0.0207/18/2023 20:22:05 - INFO - __main__ - train loss is 4.2002012631855905\n",
      "Steps:  82%|▊| 12346/15000 [1:18:43<07:55,  5.58it/s, lr=8.99e-6, step_loss=0.2007/18/2023 20:22:05 - INFO - __main__ - train loss is 4.268389803823084\n",
      "Steps:  82%|▊| 12347/15000 [1:18:43<07:54,  5.59it/s, lr=8.99e-6, step_loss=0.0607/18/2023 20:22:05 - INFO - __main__ - train loss is 4.367097420152277\n",
      "Steps:  82%|▊| 12348/15000 [1:18:43<07:54,  5.59it/s, lr=8.99e-6, step_loss=0.0907/18/2023 20:22:05 - INFO - __main__ - train loss is 4.379293525125831\n",
      "Steps:  82%|▊| 12349/15000 [1:18:43<07:53,  5.59it/s, lr=8.99e-6, step_loss=0.0107/18/2023 20:22:06 - INFO - __main__ - train loss is 4.709581339266151\n",
      "Steps:  82%|▊| 12350/15000 [1:18:43<07:53,  5.59it/s, lr=8.99e-6, step_loss=0.3307/18/2023 20:22:06 - INFO - __main__ - train loss is 4.756294840481132\n",
      "Steps:  82%|▊| 12351/15000 [1:18:44<07:53,  5.59it/s, lr=8.99e-6, step_loss=0.0407/18/2023 20:22:06 - INFO - __main__ - train loss is 4.758539751637727\n",
      "Steps:  82%|▊| 12352/15000 [1:18:44<07:53,  5.59it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:06 - INFO - __main__ - train loss is 4.821423620451242\n",
      "Steps:  82%|▊| 12353/15000 [1:18:44<07:53,  5.59it/s, lr=8.99e-6, step_loss=0.0607/18/2023 20:22:06 - INFO - __main__ - train loss is 5.0450442736037076\n",
      "Steps:  82%|▊| 12354/15000 [1:18:44<07:53,  5.59it/s, lr=8.99e-6, step_loss=0.2207/18/2023 20:22:06 - INFO - __main__ - train loss is 5.076420408207923\n",
      "Steps:  82%|▊| 12355/15000 [1:18:44<07:57,  5.54it/s, lr=8.99e-6, step_loss=0.0307/18/2023 20:22:07 - INFO - __main__ - train loss is 5.372368138749152\n",
      "Steps:  82%|▊| 12356/15000 [1:18:44<07:58,  5.52it/s, lr=8.99e-6, step_loss=0.2907/18/2023 20:22:07 - INFO - __main__ - train loss is 5.37718197517097\n",
      "Steps:  82%|▊| 12357/15000 [1:18:45<07:56,  5.54it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:07 - INFO - __main__ - train loss is 5.655612854287028\n",
      "Steps:  82%|▊| 12358/15000 [1:18:45<07:55,  5.55it/s, lr=8.99e-6, step_loss=0.2707/18/2023 20:22:07 - INFO - __main__ - train loss is 5.6577424462884665\n",
      "Steps:  82%|▊| 12359/15000 [1:18:45<07:54,  5.56it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:07 - INFO - __main__ - train loss is 5.679215056821704\n",
      "Steps:  82%|▊| 12360/15000 [1:18:45<07:53,  5.57it/s, lr=8.99e-6, step_loss=0.0207/18/2023 20:22:08 - INFO - __main__ - train loss is 5.769866554066539\n",
      "Steps:  82%|▊| 12361/15000 [1:18:45<07:52,  5.58it/s, lr=8.99e-6, step_loss=0.0907/18/2023 20:22:08 - INFO - __main__ - train loss is 5.818318387493491\n",
      "Steps:  82%|▊| 12362/15000 [1:18:46<07:52,  5.59it/s, lr=8.99e-6, step_loss=0.0407/18/2023 20:22:08 - INFO - __main__ - train loss is 5.848350351676345\n",
      "Steps:  82%|▊| 12363/15000 [1:18:46<07:51,  5.59it/s, lr=8.99e-6, step_loss=0.0307/18/2023 20:22:08 - INFO - __main__ - train loss is 6.165956085547805\n",
      "Steps:  82%|▊| 12364/15000 [1:18:46<07:51,  5.59it/s, lr=8.99e-6, step_loss=0.3107/18/2023 20:22:08 - INFO - __main__ - train loss is 6.237189149484038\n",
      "Steps:  82%|▊| 12365/15000 [1:18:46<07:51,  5.59it/s, lr=8.99e-6, step_loss=0.0707/18/2023 20:22:08 - INFO - __main__ - train loss is 6.355226254090667\n",
      "Steps:  82%|▊| 12366/15000 [1:18:46<07:51,  5.59it/s, lr=8.99e-6, step_loss=0.1107/18/2023 20:22:09 - INFO - __main__ - train loss is 6.467447971925139\n",
      "Steps:  82%|▊| 12367/15000 [1:18:46<07:51,  5.59it/s, lr=8.99e-6, step_loss=0.1107/18/2023 20:22:09 - INFO - __main__ - train loss is 6.468791405321099\n",
      "Steps:  82%|▊| 12368/15000 [1:18:47<07:51,  5.58it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:09 - INFO - __main__ - train loss is 6.9358343878993765\n",
      "Steps:  82%|▊| 12369/15000 [1:18:47<07:51,  5.58it/s, lr=8.99e-6, step_loss=0.4607/18/2023 20:22:09 - INFO - __main__ - train loss is 6.968229385674931\n",
      "Steps:  82%|▊| 12370/15000 [1:18:47<07:57,  5.51it/s, lr=8.99e-6, step_loss=0.0307/18/2023 20:22:09 - INFO - __main__ - train loss is 7.187399151385762\n",
      "Steps:  82%|▊| 12371/15000 [1:18:47<08:39,  5.06it/s, lr=8.99e-6, step_loss=0.2107/18/2023 20:22:10 - INFO - __main__ - train loss is 7.190575357875787\n",
      "Steps:  82%|▊| 12372/15000 [1:18:47<08:49,  4.96it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:10 - INFO - __main__ - train loss is 7.238193218014203\n",
      "Steps:  82%|▊| 12373/15000 [1:18:48<08:39,  5.06it/s, lr=8.99e-6, step_loss=0.0407/18/2023 20:22:10 - INFO - __main__ - train loss is 7.243256179965101\n",
      "Steps:  82%|▊| 12374/15000 [1:18:48<08:26,  5.18it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:10 - INFO - __main__ - train loss is 7.527049986994825\n",
      "Steps:  82%|▊| 12375/15000 [1:18:48<08:17,  5.28it/s, lr=8.99e-6, step_loss=0.2807/18/2023 20:22:10 - INFO - __main__ - train loss is 7.608887007809244\n",
      "Steps:  83%|▊| 12376/15000 [1:18:48<08:10,  5.35it/s, lr=8.99e-6, step_loss=0.0807/18/2023 20:22:10 - INFO - __main__ - train loss is 7.611213555675931\n",
      "Steps:  83%|▊| 12377/15000 [1:18:48<08:10,  5.35it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:11 - INFO - __main__ - train loss is 7.675834437948652\n",
      "Steps:  83%|▊| 12378/15000 [1:18:49<08:09,  5.35it/s, lr=8.99e-6, step_loss=0.0607/18/2023 20:22:11 - INFO - __main__ - train loss is 7.684264768031426\n",
      "Steps:  83%|▊| 12379/15000 [1:18:49<08:05,  5.40it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:11 - INFO - __main__ - train loss is 7.823899794486351\n",
      "Steps:  83%|▊| 12380/15000 [1:18:49<08:01,  5.44it/s, lr=8.99e-6, step_loss=0.1407/18/2023 20:22:11 - INFO - __main__ - train loss is 8.089879740145989\n",
      "Steps:  83%|▊| 12381/15000 [1:18:49<08:00,  5.45it/s, lr=8.99e-6, step_loss=0.2607/18/2023 20:22:11 - INFO - __main__ - train loss is 8.141180899110623\n",
      "Steps:  83%|▊| 12382/15000 [1:18:49<07:58,  5.48it/s, lr=8.99e-6, step_loss=0.0507/18/2023 20:22:12 - INFO - __main__ - train loss is 8.224936466780491\n",
      "Steps:  83%|▊| 12383/15000 [1:18:49<07:56,  5.49it/s, lr=8.99e-6, step_loss=0.0807/18/2023 20:22:12 - INFO - __main__ - train loss is 8.2425426581176\n",
      "Steps:  83%|▊| 12384/15000 [1:18:50<07:55,  5.50it/s, lr=8.99e-6, step_loss=0.0107/18/2023 20:22:12 - INFO - __main__ - train loss is 8.330915626254864\n",
      "Steps:  83%|▊| 12385/15000 [1:18:50<07:55,  5.50it/s, lr=8.99e-6, step_loss=0.0807/18/2023 20:22:12 - INFO - __main__ - train loss is 8.420739766326733\n",
      "Steps:  83%|▊| 12386/15000 [1:18:50<07:54,  5.51it/s, lr=8.99e-6, step_loss=0.0807/18/2023 20:22:12 - INFO - __main__ - train loss is 9.276650902000256\n",
      "Steps:  83%|▊| 12387/15000 [1:18:50<07:54,  5.51it/s, lr=8.99e-6, step_loss=0.8507/18/2023 20:22:12 - INFO - __main__ - train loss is 9.305196160566993\n",
      "Steps:  83%|▊| 12388/15000 [1:18:50<07:58,  5.46it/s, lr=8.99e-6, step_loss=0.0207/18/2023 20:22:13 - INFO - __main__ - train loss is 9.41409483004827\n",
      "Steps:  83%|▊| 12389/15000 [1:18:51<07:58,  5.46it/s, lr=8.99e-6, step_loss=0.1007/18/2023 20:22:13 - INFO - __main__ - train loss is 9.435139538836665\n",
      "Steps:  83%|▊| 12390/15000 [1:18:51<07:57,  5.47it/s, lr=8.99e-6, step_loss=0.0207/18/2023 20:22:13 - INFO - __main__ - train loss is 10.090845348429866\n",
      "Steps:  83%|▊| 12391/15000 [1:18:51<07:54,  5.50it/s, lr=8.99e-6, step_loss=0.6507/18/2023 20:22:13 - INFO - __main__ - train loss is 10.093079137033783\n",
      "Steps:  83%|▊| 12392/15000 [1:18:51<07:51,  5.53it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:13 - INFO - __main__ - train loss is 10.140971178538166\n",
      "Steps:  83%|▊| 12393/15000 [1:18:51<07:50,  5.54it/s, lr=8.99e-6, step_loss=0.0407/18/2023 20:22:14 - INFO - __main__ - train loss is 10.309797326452099\n",
      "Steps:  83%|▊| 12394/15000 [1:18:51<07:49,  5.55it/s, lr=8.99e-6, step_loss=0.1607/18/2023 20:22:14 - INFO - __main__ - train loss is 10.393032381660305\n",
      "Steps:  83%|▊| 12395/15000 [1:18:52<07:48,  5.56it/s, lr=8.99e-6, step_loss=0.0807/18/2023 20:22:14 - INFO - __main__ - train loss is 10.51691021991428\n",
      "Steps:  83%|▊| 12396/15000 [1:18:52<07:47,  5.56it/s, lr=8.99e-6, step_loss=0.1207/18/2023 20:22:14 - INFO - __main__ - train loss is 10.529028283781372\n",
      "Steps:  83%|▊| 12397/15000 [1:18:52<07:47,  5.57it/s, lr=8.99e-6, step_loss=0.0107/18/2023 20:22:14 - INFO - __main__ - train loss is 10.590310948318802\n",
      "Steps:  83%|▊| 12398/15000 [1:18:52<07:47,  5.57it/s, lr=8.99e-6, step_loss=0.0607/18/2023 20:22:14 - INFO - __main__ - train loss is 10.689997027046047\n",
      "Steps:  83%|▊| 12399/15000 [1:18:52<07:46,  5.57it/s, lr=8.99e-6, step_loss=0.0907/18/2023 20:22:15 - INFO - __main__ - train loss is 11.289782712585293\n",
      "Steps:  83%|▊| 12400/15000 [1:18:53<07:45,  5.58it/s, lr=8.99e-6, step_loss=0.6]07/18/2023 20:22:15 - INFO - __main__ - train loss is 11.43426075053867\n",
      "Steps:  83%|▊| 12401/15000 [1:18:53<07:44,  5.59it/s, lr=8.99e-6, step_loss=0.1407/18/2023 20:22:15 - INFO - __main__ - train loss is 11.781563366181217\n",
      "Steps:  83%|▊| 12402/15000 [1:18:53<07:44,  5.60it/s, lr=8.99e-6, step_loss=0.3407/18/2023 20:22:15 - INFO - __main__ - train loss is 11.844374219304882\n",
      "Steps:  83%|▊| 12403/15000 [1:18:53<07:43,  5.60it/s, lr=8.99e-6, step_loss=0.0607/18/2023 20:22:15 - INFO - __main__ - train loss is 11.849564371979795\n",
      "Steps:  83%|▊| 12404/15000 [1:18:53<07:43,  5.60it/s, lr=8.99e-6, step_loss=0.0007/18/2023 20:22:16 - INFO - __main__ - train loss is 11.881434945738874\n",
      "Steps:  83%|▊| 12405/15000 [1:18:53<07:43,  5.60it/s, lr=8.98e-6, step_loss=0.0307/18/2023 20:22:16 - INFO - __main__ - train loss is 11.957456646836363\n",
      "Steps:  83%|▊| 12406/15000 [1:18:54<07:43,  5.60it/s, lr=8.98e-6, step_loss=0.0707/18/2023 20:22:16 - INFO - __main__ - train loss is 12.21239709702786\n",
      "Steps:  83%|▊| 12407/15000 [1:18:54<07:42,  5.60it/s, lr=8.98e-6, step_loss=0.2507/18/2023 20:22:16 - INFO - __main__ - train loss is 12.217597240000032\n",
      "Steps:  83%|▊| 12408/15000 [1:18:54<07:42,  5.60it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:16 - INFO - __main__ - train loss is 12.279770118533634\n",
      "Steps:  83%|▊| 12409/15000 [1:18:54<07:42,  5.60it/s, lr=8.98e-6, step_loss=0.0607/18/2023 20:22:16 - INFO - __main__ - train loss is 12.66857088857796\n",
      "Steps:  83%|▊| 12410/15000 [1:18:54<07:46,  5.55it/s, lr=8.98e-6, step_loss=0.3807/18/2023 20:22:17 - INFO - __main__ - train loss is 12.671358587569557\n",
      "Steps:  83%|▊| 12411/15000 [1:18:55<07:50,  5.50it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:17 - INFO - __main__ - train loss is 12.80973068100866\n",
      "Steps:  83%|▊| 12412/15000 [1:18:55<07:47,  5.53it/s, lr=8.98e-6, step_loss=0.1307/18/2023 20:22:17 - INFO - __main__ - train loss is 12.995376872248016\n",
      "Steps:  83%|▊| 12413/15000 [1:18:55<07:46,  5.55it/s, lr=8.98e-6, step_loss=0.1807/18/2023 20:22:17 - INFO - __main__ - train loss is 13.027599549270235\n",
      "Steps:  83%|▊| 12414/15000 [1:18:55<07:44,  5.56it/s, lr=8.98e-6, step_loss=0.0307/18/2023 20:22:17 - INFO - __main__ - train loss is 13.83235738275107\n",
      "Steps:  83%|▊| 12415/15000 [1:18:55<07:43,  5.58it/s, lr=8.98e-6, step_loss=0.8007/18/2023 20:22:18 - INFO - __main__ - train loss is 13.850041142082773\n",
      "Steps:  83%|▊| 12416/15000 [1:18:56<10:18,  4.17it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:18 - INFO - __main__ - Per validation step average loss is 0.01215983834117651\n",
      "07/18/2023 20:22:18 - INFO - __main__ - Cumulative validation average loss is 0.01215983834117651\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Per validation step average loss is 0.2511677145957947\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Cumulative validation average loss is 0.2633275529369712\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Per validation step average loss is 0.0615769624710083\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Cumulative validation average loss is 0.3249045154079795\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Per validation step average loss is 0.2732432782649994\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Cumulative validation average loss is 0.5981477936729789\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Per validation step average loss is 0.22626103460788727\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Cumulative validation average loss is 0.8244088282808661\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Per validation step average loss is 0.22134298086166382\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Cumulative validation average loss is 1.04575180914253\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Per validation step average loss is 0.00799003429710865\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Cumulative validation average loss is 1.0537418434396386\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Per validation step average loss is 0.006920919753611088\n",
      "07/18/2023 20:22:19 - INFO - __main__ - Cumulative validation average loss is 1.0606627631932497\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Per validation step average loss is 0.007571991533041\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Cumulative validation average loss is 1.0682347547262907\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Per validation step average loss is 0.09224967658519745\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Cumulative validation average loss is 1.1604844313114882\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Per validation step average loss is 0.10319401323795319\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Cumulative validation average loss is 1.2636784445494413\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Per validation step average loss is 0.6109341979026794\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Cumulative validation average loss is 1.8746126424521208\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Average validation loss for Epoch 127 is 0.1562177202043434\n",
      "07/18/2023 20:22:20 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:22:33 - INFO - __main__ - Starting epoch 128\n",
      "07/18/2023 20:22:34 - INFO - __main__ - train loss is 0.051464103162288666\n",
      "Steps:  83%|▊| 12417/15000 [1:19:11<3:31:21,  4.91s/it, lr=8.98e-6, step_loss=0.07/18/2023 20:22:34 - INFO - __main__ - train loss is 0.056875708512961864\n",
      "Steps:  83%|▊| 12418/15000 [1:19:12<2:30:11,  3.49s/it, lr=8.98e-6, step_loss=0.07/18/2023 20:22:34 - INFO - __main__ - train loss is 0.29567289631813765\n",
      "Steps:  83%|▊| 12419/15000 [1:19:12<1:47:24,  2.50s/it, lr=8.98e-6, step_loss=0.07/18/2023 20:22:34 - INFO - __main__ - train loss is 0.3109318511560559\n",
      "Steps:  83%|▊| 12420/15000 [1:19:12<1:17:27,  1.80s/it, lr=8.98e-6, step_loss=0.07/18/2023 20:22:34 - INFO - __main__ - train loss is 0.43871279526501894\n",
      "Steps:  83%|▊| 12421/15000 [1:19:12<56:30,  1.31s/it, lr=8.98e-6, step_loss=0.1207/18/2023 20:22:34 - INFO - __main__ - train loss is 1.1463958220556378\n",
      "Steps:  83%|▊| 12422/15000 [1:19:12<41:51,  1.03it/s, lr=8.98e-6, step_loss=0.7007/18/2023 20:22:35 - INFO - __main__ - train loss is 1.1642735293135047\n",
      "Steps:  83%|▊| 12423/15000 [1:19:12<31:37,  1.36it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:35 - INFO - __main__ - train loss is 1.235560624860227\n",
      "Steps:  83%|▊| 12424/15000 [1:19:13<24:25,  1.76it/s, lr=8.98e-6, step_loss=0.0707/18/2023 20:22:35 - INFO - __main__ - train loss is 1.241713103838265\n",
      "Steps:  83%|▊| 12425/15000 [1:19:13<19:22,  2.21it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:35 - INFO - __main__ - train loss is 1.265716270543635\n",
      "Steps:  83%|▊| 12426/15000 [1:19:13<15:55,  2.69it/s, lr=8.98e-6, step_loss=0.0207/18/2023 20:22:35 - INFO - __main__ - train loss is 1.2784791197627783\n",
      "Steps:  83%|▊| 12427/15000 [1:19:13<13:28,  3.18it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:36 - INFO - __main__ - train loss is 1.3110603969544172\n",
      "Steps:  83%|▊| 12428/15000 [1:19:13<11:44,  3.65it/s, lr=8.98e-6, step_loss=0.0307/18/2023 20:22:36 - INFO - __main__ - train loss is 2.082484332844615\n",
      "Steps:  83%|▊| 12429/15000 [1:19:14<10:36,  4.04it/s, lr=8.98e-6, step_loss=0.7707/18/2023 20:22:36 - INFO - __main__ - train loss is 2.2223179768770933\n",
      "Steps:  83%|▊| 12430/15000 [1:19:14<09:44,  4.39it/s, lr=8.98e-6, step_loss=0.1407/18/2023 20:22:36 - INFO - __main__ - train loss is 2.3211418371647596\n",
      "Steps:  83%|▊| 12431/15000 [1:19:14<09:08,  4.68it/s, lr=8.98e-6, step_loss=0.0907/18/2023 20:22:36 - INFO - __main__ - train loss is 2.3247276451438665\n",
      "Steps:  83%|▊| 12432/15000 [1:19:14<08:43,  4.91it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:36 - INFO - __main__ - train loss is 3.1828260328620672\n",
      "Steps:  83%|▊| 12433/15000 [1:19:14<08:24,  5.08it/s, lr=8.98e-6, step_loss=0.8507/18/2023 20:22:37 - INFO - __main__ - train loss is 3.2015805896371603\n",
      "Steps:  83%|▊| 12434/15000 [1:19:14<08:12,  5.21it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:37 - INFO - __main__ - train loss is 3.7810071166604757\n",
      "Steps:  83%|▊| 12435/15000 [1:19:15<08:03,  5.30it/s, lr=8.98e-6, step_loss=0.5707/18/2023 20:22:37 - INFO - __main__ - train loss is 3.7838561749085784\n",
      "Steps:  83%|▊| 12436/15000 [1:19:15<07:58,  5.36it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:37 - INFO - __main__ - train loss is 3.868927246890962\n",
      "Steps:  83%|▊| 12437/15000 [1:19:15<07:58,  5.36it/s, lr=8.98e-6, step_loss=0.0807/18/2023 20:22:37 - INFO - __main__ - train loss is 4.03265096899122\n",
      "Steps:  83%|▊| 12438/15000 [1:19:15<07:53,  5.41it/s, lr=8.98e-6, step_loss=0.1607/18/2023 20:22:38 - INFO - __main__ - train loss is 4.037321167998016\n",
      "Steps:  83%|▊| 12439/15000 [1:19:15<07:50,  5.44it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:38 - INFO - __main__ - train loss is 4.076083670370281\n",
      "Steps:  83%|▊| 12440/15000 [1:19:16<07:48,  5.46it/s, lr=8.98e-6, step_loss=0.0307/18/2023 20:22:38 - INFO - __main__ - train loss is 4.284716288559139\n",
      "Steps:  83%|▊| 12441/15000 [1:19:16<07:47,  5.48it/s, lr=8.98e-6, step_loss=0.2007/18/2023 20:22:38 - INFO - __main__ - train loss is 4.28819839283824\n",
      "Steps:  83%|▊| 12442/15000 [1:19:16<07:45,  5.49it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:38 - INFO - __main__ - train loss is 4.347401484847069\n",
      "Steps:  83%|▊| 12443/15000 [1:19:16<07:44,  5.50it/s, lr=8.98e-6, step_loss=0.0507/18/2023 20:22:38 - INFO - __main__ - train loss is 4.5464752316474915\n",
      "Steps:  83%|▊| 12444/15000 [1:19:16<07:44,  5.50it/s, lr=8.98e-6, step_loss=0.1907/18/2023 20:22:39 - INFO - __main__ - train loss is 4.595556236803532\n",
      "Steps:  83%|▊| 12445/15000 [1:19:16<07:44,  5.51it/s, lr=8.98e-6, step_loss=0.0407/18/2023 20:22:39 - INFO - __main__ - train loss is 4.622422210872173\n",
      "Steps:  83%|▊| 12446/15000 [1:19:17<07:43,  5.51it/s, lr=8.98e-6, step_loss=0.0207/18/2023 20:22:39 - INFO - __main__ - train loss is 4.816173620522022\n",
      "Steps:  83%|▊| 12447/15000 [1:19:17<07:42,  5.52it/s, lr=8.98e-6, step_loss=0.1907/18/2023 20:22:39 - INFO - __main__ - train loss is 4.974935777485371\n",
      "Steps:  83%|▊| 12448/15000 [1:19:17<07:42,  5.51it/s, lr=8.98e-6, step_loss=0.1507/18/2023 20:22:39 - INFO - __main__ - train loss is 5.031649351119995\n",
      "Steps:  83%|▊| 12449/15000 [1:19:17<07:42,  5.51it/s, lr=8.98e-6, step_loss=0.0507/18/2023 20:22:39 - INFO - __main__ - train loss is 5.042106214910746\n",
      "Steps:  83%|▊| 12450/15000 [1:19:17<07:41,  5.52it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:40 - INFO - __main__ - train loss is 5.052530269138515\n",
      "Steps:  83%|▊| 12451/15000 [1:19:18<07:41,  5.52it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:40 - INFO - __main__ - train loss is 5.309946517460048\n",
      "Steps:  83%|▊| 12452/15000 [1:19:18<07:41,  5.52it/s, lr=8.98e-6, step_loss=0.2507/18/2023 20:22:40 - INFO - __main__ - train loss is 5.31730455160141\n",
      "Steps:  83%|▊| 12453/15000 [1:19:18<07:41,  5.52it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:40 - INFO - __main__ - train loss is 5.51026414334774\n",
      "Steps:  83%|▊| 12454/15000 [1:19:18<07:41,  5.52it/s, lr=8.98e-6, step_loss=0.1907/18/2023 20:22:40 - INFO - __main__ - train loss is 5.90472324192524\n",
      "Steps:  83%|▊| 12455/15000 [1:19:18<07:41,  5.51it/s, lr=8.98e-6, step_loss=0.3907/18/2023 20:22:41 - INFO - __main__ - train loss is 6.283715859055519\n",
      "Steps:  83%|▊| 12456/15000 [1:19:18<07:41,  5.51it/s, lr=8.98e-6, step_loss=0.3707/18/2023 20:22:41 - INFO - __main__ - train loss is 6.295393988490105\n",
      "Steps:  83%|▊| 12457/15000 [1:19:19<07:41,  5.51it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:41 - INFO - __main__ - train loss is 6.444607451558113\n",
      "Steps:  83%|▊| 12458/15000 [1:19:19<07:40,  5.52it/s, lr=8.98e-6, step_loss=0.1407/18/2023 20:22:41 - INFO - __main__ - train loss is 6.448487281799316\n",
      "Steps:  83%|▊| 12459/15000 [1:19:19<07:44,  5.47it/s, lr=8.98e-6, step_loss=0.0007/18/2023 20:22:41 - INFO - __main__ - train loss is 6.467132339254022\n",
      "Steps:  83%|▊| 12460/15000 [1:19:19<07:43,  5.48it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:41 - INFO - __main__ - train loss is 6.498341152444482\n",
      "Steps:  83%|▊| 12461/15000 [1:19:19<07:40,  5.51it/s, lr=8.98e-6, step_loss=0.0307/18/2023 20:22:42 - INFO - __main__ - train loss is 6.745376313105226\n",
      "Steps:  83%|▊| 12462/15000 [1:19:20<07:49,  5.40it/s, lr=8.98e-6, step_loss=0.2407/18/2023 20:22:42 - INFO - __main__ - train loss is 6.760202085599303\n",
      "Steps:  83%|▊| 12463/15000 [1:19:20<07:49,  5.40it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:42 - INFO - __main__ - train loss is 6.770327741280198\n",
      "Steps:  83%|▊| 12464/15000 [1:19:20<07:48,  5.41it/s, lr=8.98e-6, step_loss=0.0107/18/2023 20:22:42 - INFO - __main__ - train loss is 6.9252562168985605\n",
      "Steps:  83%|▊| 12465/15000 [1:19:20<07:56,  5.32it/s, lr=8.98e-6, step_loss=0.1507/18/2023 20:22:42 - INFO - __main__ - train loss is 6.945845941081643\n",
      "Steps:  83%|▊| 12466/15000 [1:19:20<08:02,  5.25it/s, lr=8.98e-6, step_loss=0.0207/18/2023 20:22:43 - INFO - __main__ - train loss is 7.095566252246499\n",
      "Steps:  83%|▊| 12467/15000 [1:19:21<08:07,  5.20it/s, lr=8.98e-6, step_loss=0.1507/18/2023 20:22:43 - INFO - __main__ - train loss is 7.617755392566323\n",
      "Steps:  83%|▊| 12468/15000 [1:19:21<08:09,  5.17it/s, lr=8.97e-6, step_loss=0.5207/18/2023 20:22:43 - INFO - __main__ - train loss is 7.86696750856936\n",
      "Steps:  83%|▊| 12469/15000 [1:19:21<08:09,  5.17it/s, lr=8.97e-6, step_loss=0.2407/18/2023 20:22:43 - INFO - __main__ - train loss is 7.947876976802945\n",
      "Steps:  83%|▊| 12470/15000 [1:19:21<08:10,  5.16it/s, lr=8.97e-6, step_loss=0.0807/18/2023 20:22:43 - INFO - __main__ - train loss is 8.32128624804318\n",
      "Steps:  83%|▊| 12471/15000 [1:19:21<08:10,  5.15it/s, lr=8.97e-6, step_loss=0.3707/18/2023 20:22:44 - INFO - __main__ - train loss is 8.606387184932828\n",
      "Steps:  83%|▊| 12472/15000 [1:19:22<08:11,  5.14it/s, lr=8.97e-6, step_loss=0.2807/18/2023 20:22:44 - INFO - __main__ - train loss is 9.105431335046887\n",
      "Steps:  83%|▊| 12473/15000 [1:19:22<08:11,  5.14it/s, lr=8.97e-6, step_loss=0.4907/18/2023 20:22:44 - INFO - __main__ - train loss is 9.155690224841237\n",
      "Steps:  83%|▊| 12474/15000 [1:19:22<08:11,  5.14it/s, lr=8.97e-6, step_loss=0.0507/18/2023 20:22:44 - INFO - __main__ - train loss is 9.539021225646138\n",
      "Steps:  83%|▊| 12475/15000 [1:19:22<08:12,  5.13it/s, lr=8.97e-6, step_loss=0.3807/18/2023 20:22:44 - INFO - __main__ - train loss is 9.586464995518327\n",
      "Steps:  83%|▊| 12476/15000 [1:19:22<08:11,  5.13it/s, lr=8.97e-6, step_loss=0.0407/18/2023 20:22:45 - INFO - __main__ - train loss is 9.587726592551917\n",
      "Steps:  83%|▊| 12477/15000 [1:19:22<08:11,  5.14it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:45 - INFO - __main__ - train loss is 9.600245479028672\n",
      "Steps:  83%|▊| 12478/15000 [1:19:23<08:10,  5.14it/s, lr=8.97e-6, step_loss=0.0107/18/2023 20:22:45 - INFO - __main__ - train loss is 9.676879729609936\n",
      "Steps:  83%|▊| 12479/15000 [1:19:23<08:10,  5.14it/s, lr=8.97e-6, step_loss=0.0707/18/2023 20:22:45 - INFO - __main__ - train loss is 9.67865162587259\n",
      "Steps:  83%|▊| 12480/15000 [1:19:23<08:10,  5.13it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:45 - INFO - __main__ - train loss is 9.779677818180062\n",
      "Steps:  83%|▊| 12481/15000 [1:19:23<08:13,  5.11it/s, lr=8.97e-6, step_loss=0.1007/18/2023 20:22:46 - INFO - __main__ - train loss is 9.808899922878481\n",
      "Steps:  83%|▊| 12482/15000 [1:19:23<08:13,  5.10it/s, lr=8.97e-6, step_loss=0.0207/18/2023 20:22:46 - INFO - __main__ - train loss is 10.283441616804339\n",
      "Steps:  83%|▊| 12483/15000 [1:19:24<08:12,  5.11it/s, lr=8.97e-6, step_loss=0.4707/18/2023 20:22:46 - INFO - __main__ - train loss is 10.316171652288176\n",
      "Steps:  83%|▊| 12484/15000 [1:19:24<08:11,  5.12it/s, lr=8.97e-6, step_loss=0.0307/18/2023 20:22:46 - INFO - __main__ - train loss is 10.844138390035369\n",
      "Steps:  83%|▊| 12485/15000 [1:19:24<08:14,  5.08it/s, lr=8.97e-6, step_loss=0.5207/18/2023 20:22:46 - INFO - __main__ - train loss is 11.211360401124693\n",
      "Steps:  83%|▊| 12486/15000 [1:19:24<08:12,  5.10it/s, lr=8.97e-6, step_loss=0.3607/18/2023 20:22:47 - INFO - __main__ - train loss is 11.43823838850949\n",
      "Steps:  83%|▊| 12487/15000 [1:19:24<08:12,  5.10it/s, lr=8.97e-6, step_loss=0.2207/18/2023 20:22:47 - INFO - __main__ - train loss is 11.73816353699658\n",
      "Steps:  83%|▊| 12488/15000 [1:19:25<08:10,  5.12it/s, lr=8.97e-6, step_loss=0.3]07/18/2023 20:22:47 - INFO - __main__ - train loss is 12.110011494369246\n",
      "Steps:  83%|▊| 12489/15000 [1:19:25<08:02,  5.20it/s, lr=8.97e-6, step_loss=0.3707/18/2023 20:22:47 - INFO - __main__ - train loss is 12.202505296678282\n",
      "Steps:  83%|▊| 12490/15000 [1:19:25<07:56,  5.26it/s, lr=8.97e-6, step_loss=0.0907/18/2023 20:22:47 - INFO - __main__ - train loss is 12.206500345491804\n",
      "Steps:  83%|▊| 12491/15000 [1:19:25<07:52,  5.31it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:47 - INFO - __main__ - train loss is 12.213517794036306\n",
      "Steps:  83%|▊| 12492/15000 [1:19:25<07:54,  5.28it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:48 - INFO - __main__ - train loss is 12.244674058281817\n",
      "Steps:  83%|▊| 12493/15000 [1:19:26<07:58,  5.24it/s, lr=8.97e-6, step_loss=0.0307/18/2023 20:22:48 - INFO - __main__ - train loss is 12.24647098465357\n",
      "Steps:  83%|▊| 12494/15000 [1:19:26<08:00,  5.22it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:48 - INFO - __main__ - train loss is 12.252623495762236\n",
      "Steps:  83%|▊| 12495/15000 [1:19:26<08:02,  5.19it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:48 - INFO - __main__ - train loss is 12.311107182060368\n",
      "Steps:  83%|▊| 12496/15000 [1:19:26<08:04,  5.17it/s, lr=8.97e-6, step_loss=0.0507/18/2023 20:22:48 - INFO - __main__ - train loss is 12.362120703910477\n",
      "Steps:  83%|▊| 12497/15000 [1:19:26<08:06,  5.14it/s, lr=8.97e-6, step_loss=0.0507/18/2023 20:22:49 - INFO - __main__ - train loss is 12.53695325658191\n",
      "Steps:  83%|▊| 12498/15000 [1:19:27<08:08,  5.13it/s, lr=8.97e-6, step_loss=0.1707/18/2023 20:22:49 - INFO - __main__ - train loss is 12.825864330981858\n",
      "Steps:  83%|▊| 12499/15000 [1:19:27<08:08,  5.12it/s, lr=8.97e-6, step_loss=0.2807/18/2023 20:22:49 - INFO - __main__ - train loss is 12.862201714073308\n",
      "Steps:  83%|▊| 12500/15000 [1:19:27<08:08,  5.11it/s, lr=8.97e-6, step_loss=0.2807/18/2023 20:22:49 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-12500\n",
      "07/18/2023 20:22:49 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:22:49,643] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:22:49,649] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-12500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:22:49,649] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-12500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:22:49,660] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-12500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:22:49,660] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-12500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:22:49,683] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-12500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:22:49,683] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-12500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:22:49,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:22:49 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-12500/pytorch_model\n",
      "07/18/2023 20:22:49 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-12500/scheduler.bin\n",
      "07/18/2023 20:22:49 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-12500/random_states_0.pkl\n",
      "07/18/2023 20:22:49 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-12500\n",
      "Steps:  83%|▊| 12500/15000 [1:19:27<08:08,  5.11it/s, lr=8.97e-6, step_loss=0.0307/18/2023 20:22:49 - INFO - __main__ - train loss is 13.625036739860661\n",
      "Steps:  83%|▊| 12501/15000 [1:19:27<08:39,  4.81it/s, lr=8.97e-6, step_loss=0.7607/18/2023 20:22:49 - INFO - __main__ - train loss is 13.638227190938778\n",
      "Steps:  83%|▊| 12502/15000 [1:19:27<08:29,  4.91it/s, lr=8.97e-6, step_loss=0.0107/18/2023 20:22:50 - INFO - __main__ - train loss is 13.653997533139773\n",
      "Steps:  83%|▊| 12503/15000 [1:19:28<08:22,  4.97it/s, lr=8.97e-6, step_loss=0.0107/18/2023 20:22:50 - INFO - __main__ - train loss is 13.682417923700996\n",
      "Steps:  83%|▊| 12504/15000 [1:19:28<08:16,  5.03it/s, lr=8.97e-6, step_loss=0.0207/18/2023 20:22:50 - INFO - __main__ - train loss is 13.684584445436485\n",
      "Steps:  83%|▊| 12505/15000 [1:19:28<08:12,  5.06it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:50 - INFO - __main__ - train loss is 13.688034647260793\n",
      "Steps:  83%|▊| 12506/15000 [1:19:28<08:10,  5.09it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:50 - INFO - __main__ - train loss is 14.193677120958455\n",
      "Steps:  83%|▊| 12507/15000 [1:19:28<08:08,  5.11it/s, lr=8.97e-6, step_loss=0.5007/18/2023 20:22:51 - INFO - __main__ - train loss is 14.196496723336168\n",
      "Steps:  83%|▊| 12508/15000 [1:19:29<08:06,  5.12it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:22:51 - INFO - __main__ - train loss is 14.242283759755082\n",
      "Steps:  83%|▊| 12509/15000 [1:19:29<08:05,  5.13it/s, lr=8.97e-6, step_loss=0.0407/18/2023 20:22:51 - INFO - __main__ - train loss is 14.67346578661818\n",
      "Steps:  83%|▊| 12510/15000 [1:19:29<08:05,  5.13it/s, lr=8.97e-6, step_loss=0.4307/18/2023 20:22:51 - INFO - __main__ - train loss is 15.235149083775468\n",
      "Steps:  83%|▊| 12511/15000 [1:19:29<08:05,  5.13it/s, lr=8.97e-6, step_loss=0.5607/18/2023 20:22:51 - INFO - __main__ - train loss is 15.362202046555467\n",
      "Steps:  83%|▊| 12512/15000 [1:19:29<08:04,  5.13it/s, lr=8.97e-6, step_loss=0.1207/18/2023 20:22:52 - INFO - __main__ - train loss is 15.379899339866824\n",
      "Steps:  83%|▊| 12513/15000 [1:19:30<10:30,  3.95it/s, lr=8.97e-6, step_loss=0.0107/18/2023 20:22:53 - INFO - __main__ - Per validation step average loss is 0.45404911041259766\n",
      "07/18/2023 20:22:53 - INFO - __main__ - Cumulative validation average loss is 0.45404911041259766\n",
      "07/18/2023 20:22:53 - INFO - __main__ - Per validation step average loss is 0.2858451008796692\n",
      "07/18/2023 20:22:53 - INFO - __main__ - Cumulative validation average loss is 0.7398942112922668\n",
      "07/18/2023 20:22:53 - INFO - __main__ - Per validation step average loss is 0.052955832332372665\n",
      "07/18/2023 20:22:53 - INFO - __main__ - Cumulative validation average loss is 0.7928500436246395\n",
      "07/18/2023 20:22:53 - INFO - __main__ - Per validation step average loss is 0.052988842129707336\n",
      "07/18/2023 20:22:53 - INFO - __main__ - Cumulative validation average loss is 0.8458388857543468\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Per validation step average loss is 0.020064465701580048\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Cumulative validation average loss is 0.8659033514559269\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Per validation step average loss is 0.03605310991406441\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Cumulative validation average loss is 0.9019564613699913\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Per validation step average loss is 0.0036144570913165808\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Cumulative validation average loss is 0.9055709184613079\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Per validation step average loss is 0.41234999895095825\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Cumulative validation average loss is 1.3179209174122661\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Per validation step average loss is 0.569563627243042\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Cumulative validation average loss is 1.8874845446553081\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Per validation step average loss is 0.3446676731109619\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Cumulative validation average loss is 2.23215221776627\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Per validation step average loss is 0.3631567358970642\n",
      "07/18/2023 20:22:54 - INFO - __main__ - Cumulative validation average loss is 2.5953089536633343\n",
      "07/18/2023 20:22:55 - INFO - __main__ - Per validation step average loss is 0.010778918862342834\n",
      "07/18/2023 20:22:55 - INFO - __main__ - Cumulative validation average loss is 2.606087872525677\n",
      "07/18/2023 20:22:55 - INFO - __main__ - Average validation loss for Epoch 128 is 0.21717398937713975\n",
      "07/18/2023 20:22:55 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:23:08 - INFO - __main__ - Starting epoch 129\n",
      "07/18/2023 20:23:08 - INFO - __main__ - train loss is 0.04706025868654251\n",
      "Steps:  83%|▊| 12514/15000 [1:19:46<3:34:30,  5.18s/it, lr=8.97e-6, step_loss=0.07/18/2023 20:23:09 - INFO - __main__ - train loss is 0.755216009914875\n",
      "Steps:  83%|▊| 12515/15000 [1:19:47<2:32:19,  3.68s/it, lr=8.97e-6, step_loss=0.07/18/2023 20:23:09 - INFO - __main__ - train loss is 1.248389907181263\n",
      "Steps:  83%|▊| 12516/15000 [1:19:47<1:48:47,  2.63s/it, lr=8.97e-6, step_loss=0.07/18/2023 20:23:09 - INFO - __main__ - train loss is 1.5998360589146614\n",
      "Steps:  83%|▊| 12517/15000 [1:19:47<1:18:19,  1.89s/it, lr=8.97e-6, step_loss=0.07/18/2023 20:23:09 - INFO - __main__ - train loss is 1.897715575993061\n",
      "Steps:  83%|▊| 12518/15000 [1:19:47<57:02,  1.38s/it, lr=8.97e-6, step_loss=0.2907/18/2023 20:23:09 - INFO - __main__ - train loss is 2.722781963646412\n",
      "Steps:  83%|▊| 12519/15000 [1:19:47<42:08,  1.02s/it, lr=8.97e-6, step_loss=0.8207/18/2023 20:23:10 - INFO - __main__ - train loss is 3.011864222586155\n",
      "Steps:  83%|▊| 12520/15000 [1:19:47<31:42,  1.30it/s, lr=8.97e-6, step_loss=0.2807/18/2023 20:23:10 - INFO - __main__ - train loss is 3.1846713200211525\n",
      "Steps:  83%|▊| 12521/15000 [1:19:48<24:23,  1.69it/s, lr=8.97e-6, step_loss=0.1707/18/2023 20:23:10 - INFO - __main__ - train loss is 3.1873527872376144\n",
      "Steps:  83%|▊| 12522/15000 [1:19:48<19:16,  2.14it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:23:10 - INFO - __main__ - train loss is 3.5753654944710433\n",
      "Steps:  83%|▊| 12523/15000 [1:19:48<15:41,  2.63it/s, lr=8.97e-6, step_loss=0.3807/18/2023 20:23:10 - INFO - __main__ - train loss is 3.661627824883908\n",
      "Steps:  83%|▊| 12524/15000 [1:19:48<13:10,  3.13it/s, lr=8.97e-6, step_loss=0.0807/18/2023 20:23:10 - INFO - __main__ - train loss is 3.7456023055128753\n",
      "Steps:  84%|▊| 12525/15000 [1:19:48<11:25,  3.61it/s, lr=8.97e-6, step_loss=0.0807/18/2023 20:23:11 - INFO - __main__ - train loss is 4.166785116773099\n",
      "Steps:  84%|▊| 12526/15000 [1:19:49<10:12,  4.04it/s, lr=8.97e-6, step_loss=0.4207/18/2023 20:23:11 - INFO - __main__ - train loss is 4.178650989662856\n",
      "Steps:  84%|▊| 12527/15000 [1:19:49<09:24,  4.38it/s, lr=8.97e-6, step_loss=0.0107/18/2023 20:23:11 - INFO - __main__ - train loss is 4.185523617547005\n",
      "Steps:  84%|▊| 12528/15000 [1:19:49<08:47,  4.69it/s, lr=8.97e-6, step_loss=0.0007/18/2023 20:23:11 - INFO - __main__ - train loss is 4.214450858067721\n",
      "Steps:  84%|▊| 12529/15000 [1:19:49<08:21,  4.93it/s, lr=8.97e-6, step_loss=0.0207/18/2023 20:23:11 - INFO - __main__ - train loss is 4.3340482781641185\n",
      "Steps:  84%|▊| 12530/15000 [1:19:49<08:02,  5.12it/s, lr=8.97e-6, step_loss=0.1207/18/2023 20:23:12 - INFO - __main__ - train loss is 4.336402440909296\n",
      "Steps:  84%|▊| 12531/15000 [1:19:49<07:50,  5.25it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:12 - INFO - __main__ - train loss is 4.340026154648513\n",
      "Steps:  84%|▊| 12532/15000 [1:19:50<07:45,  5.30it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:12 - INFO - __main__ - train loss is 4.3783938880078495\n",
      "Steps:  84%|▊| 12533/15000 [1:19:50<07:39,  5.37it/s, lr=8.96e-6, step_loss=0.0307/18/2023 20:23:12 - INFO - __main__ - train loss is 4.40356521261856\n",
      "Steps:  84%|▊| 12534/15000 [1:19:50<07:37,  5.39it/s, lr=8.96e-6, step_loss=0.0207/18/2023 20:23:12 - INFO - __main__ - train loss is 4.4115286390297115\n",
      "Steps:  84%|▊| 12535/15000 [1:19:50<07:40,  5.35it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:12 - INFO - __main__ - train loss is 4.485820285510272\n",
      "Steps:  84%|▊| 12536/15000 [1:19:50<07:34,  5.42it/s, lr=8.96e-6, step_loss=0.0707/18/2023 20:23:13 - INFO - __main__ - train loss is 4.4916459186933935\n",
      "Steps:  84%|▊| 12537/15000 [1:19:51<07:30,  5.47it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:13 - INFO - __main__ - train loss is 4.4956687754020095\n",
      "Steps:  84%|▊| 12538/15000 [1:19:51<07:31,  5.46it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:13 - INFO - __main__ - train loss is 5.028204686008394\n",
      "Steps:  84%|▊| 12539/15000 [1:19:51<07:35,  5.41it/s, lr=8.96e-6, step_loss=0.5307/18/2023 20:23:13 - INFO - __main__ - train loss is 5.0336364903487265\n",
      "Steps:  84%|▊| 12540/15000 [1:19:51<07:31,  5.45it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:13 - INFO - __main__ - train loss is 5.1984091945923865\n",
      "Steps:  84%|▊| 12541/15000 [1:19:51<07:27,  5.49it/s, lr=8.96e-6, step_loss=0.1607/18/2023 20:23:14 - INFO - __main__ - train loss is 5.201533896615729\n",
      "Steps:  84%|▊| 12542/15000 [1:19:51<07:25,  5.52it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:14 - INFO - __main__ - train loss is 6.157929284265265\n",
      "Steps:  84%|▊| 12543/15000 [1:19:52<07:23,  5.54it/s, lr=8.96e-6, step_loss=0.9507/18/2023 20:23:14 - INFO - __main__ - train loss is 6.2408284523990005\n",
      "Steps:  84%|▊| 12544/15000 [1:19:52<07:21,  5.56it/s, lr=8.96e-6, step_loss=0.0807/18/2023 20:23:14 - INFO - __main__ - train loss is 6.249929785495624\n",
      "Steps:  84%|▊| 12545/15000 [1:19:52<07:20,  5.57it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:14 - INFO - __main__ - train loss is 6.676708876853809\n",
      "Steps:  84%|▊| 12546/15000 [1:19:52<07:19,  5.58it/s, lr=8.96e-6, step_loss=0.4207/18/2023 20:23:14 - INFO - __main__ - train loss is 7.2776387927588075\n",
      "Steps:  84%|▊| 12547/15000 [1:19:52<07:19,  5.58it/s, lr=8.96e-6, step_loss=0.6007/18/2023 20:23:15 - INFO - __main__ - train loss is 7.402426987653598\n",
      "Steps:  84%|▊| 12548/15000 [1:19:52<07:21,  5.56it/s, lr=8.96e-6, step_loss=0.1207/18/2023 20:23:15 - INFO - __main__ - train loss is 7.581778019433841\n",
      "Steps:  84%|▊| 12549/15000 [1:19:53<07:19,  5.57it/s, lr=8.96e-6, step_loss=0.1707/18/2023 20:23:15 - INFO - __main__ - train loss is 7.71383224404417\n",
      "Steps:  84%|▊| 12550/15000 [1:19:53<07:18,  5.58it/s, lr=8.96e-6, step_loss=0.1307/18/2023 20:23:15 - INFO - __main__ - train loss is 7.716219001915306\n",
      "Steps:  84%|▊| 12551/15000 [1:19:53<07:18,  5.59it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:15 - INFO - __main__ - train loss is 8.144620412494987\n",
      "Steps:  84%|▊| 12552/15000 [1:19:53<07:17,  5.59it/s, lr=8.96e-6, step_loss=0.4207/18/2023 20:23:15 - INFO - __main__ - train loss is 8.258130440022796\n",
      "Steps:  84%|▊| 12553/15000 [1:19:53<07:17,  5.59it/s, lr=8.96e-6, step_loss=0.1107/18/2023 20:23:16 - INFO - __main__ - train loss is 8.262787870131433\n",
      "Steps:  84%|▊| 12554/15000 [1:19:54<07:17,  5.60it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:16 - INFO - __main__ - train loss is 8.546797118149698\n",
      "Steps:  84%|▊| 12555/15000 [1:19:54<07:16,  5.60it/s, lr=8.96e-6, step_loss=0.2807/18/2023 20:23:16 - INFO - __main__ - train loss is 8.550477354088798\n",
      "Steps:  84%|▊| 12556/15000 [1:19:54<07:16,  5.60it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:16 - INFO - __main__ - train loss is 8.651156163075939\n",
      "Steps:  84%|▊| 12557/15000 [1:19:54<07:16,  5.60it/s, lr=8.96e-6, step_loss=0.1007/18/2023 20:23:16 - INFO - __main__ - train loss is 8.656936953542754\n",
      "Steps:  84%|▊| 12558/15000 [1:19:54<07:15,  5.60it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:17 - INFO - __main__ - train loss is 9.116551558254287\n",
      "Steps:  84%|▊| 12559/15000 [1:19:54<07:16,  5.60it/s, lr=8.96e-6, step_loss=0.4607/18/2023 20:23:17 - INFO - __main__ - train loss is 9.119601190788671\n",
      "Steps:  84%|▊| 12560/15000 [1:19:55<07:15,  5.60it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:17 - INFO - __main__ - train loss is 9.37254571984522\n",
      "Steps:  84%|▊| 12561/15000 [1:19:55<07:15,  5.60it/s, lr=8.96e-6, step_loss=0.2507/18/2023 20:23:17 - INFO - __main__ - train loss is 9.695000529987738\n",
      "Steps:  84%|▊| 12562/15000 [1:19:55<07:15,  5.60it/s, lr=8.96e-6, step_loss=0.3207/18/2023 20:23:17 - INFO - __main__ - train loss is 9.731337391538545\n",
      "Steps:  84%|▊| 12563/15000 [1:19:55<07:15,  5.60it/s, lr=8.96e-6, step_loss=0.0307/18/2023 20:23:17 - INFO - __main__ - train loss is 10.057980769081041\n",
      "Steps:  84%|▊| 12564/15000 [1:19:55<07:15,  5.60it/s, lr=8.96e-6, step_loss=0.3207/18/2023 20:23:18 - INFO - __main__ - train loss is 10.060140386456624\n",
      "Steps:  84%|▊| 12565/15000 [1:19:56<07:14,  5.60it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:18 - INFO - __main__ - train loss is 10.114252604776993\n",
      "Steps:  84%|▊| 12566/15000 [1:19:56<07:14,  5.60it/s, lr=8.96e-6, step_loss=0.0507/18/2023 20:23:18 - INFO - __main__ - train loss is 10.43947944813408\n",
      "Steps:  84%|▊| 12567/15000 [1:19:56<07:17,  5.56it/s, lr=8.96e-6, step_loss=0.3207/18/2023 20:23:18 - INFO - __main__ - train loss is 10.74521891050972\n",
      "Steps:  84%|▊| 12568/15000 [1:19:56<07:16,  5.57it/s, lr=8.96e-6, step_loss=0.3007/18/2023 20:23:18 - INFO - __main__ - train loss is 10.776108732679859\n",
      "Steps:  84%|▊| 12569/15000 [1:19:56<07:17,  5.55it/s, lr=8.96e-6, step_loss=0.0307/18/2023 20:23:19 - INFO - __main__ - train loss is 10.78422301565297\n",
      "Steps:  84%|▊| 12570/15000 [1:19:56<07:16,  5.57it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:19 - INFO - __main__ - train loss is 10.789620741037652\n",
      "Steps:  84%|▊| 12571/15000 [1:19:57<07:15,  5.58it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:19 - INFO - __main__ - train loss is 11.282415612367913\n",
      "Steps:  84%|▊| 12572/15000 [1:19:57<07:14,  5.58it/s, lr=8.96e-6, step_loss=0.4907/18/2023 20:23:19 - INFO - __main__ - train loss is 11.422011508373544\n",
      "Steps:  84%|▊| 12573/15000 [1:19:57<07:14,  5.59it/s, lr=8.96e-6, step_loss=0.1407/18/2023 20:23:19 - INFO - __main__ - train loss is 11.4327504101675\n",
      "Steps:  84%|▊| 12574/15000 [1:19:57<07:14,  5.59it/s, lr=8.96e-6, step_loss=0.0107/18/2023 20:23:19 - INFO - __main__ - train loss is 11.836004025069997\n",
      "Steps:  84%|▊| 12575/15000 [1:19:57<07:13,  5.59it/s, lr=8.96e-6, step_loss=0.4007/18/2023 20:23:20 - INFO - __main__ - train loss is 12.033884099451825\n",
      "Steps:  84%|▊| 12576/15000 [1:19:58<07:13,  5.60it/s, lr=8.96e-6, step_loss=0.1907/18/2023 20:23:20 - INFO - __main__ - train loss is 12.096784508554265\n",
      "Steps:  84%|▊| 12577/15000 [1:19:58<07:13,  5.60it/s, lr=8.96e-6, step_loss=0.0607/18/2023 20:23:20 - INFO - __main__ - train loss is 12.79359511169605\n",
      "Steps:  84%|▊| 12578/15000 [1:19:58<07:12,  5.60it/s, lr=8.96e-6, step_loss=0.6907/18/2023 20:23:20 - INFO - __main__ - train loss is 12.808442347450182\n",
      "Steps:  84%|▊| 12579/15000 [1:19:58<07:12,  5.60it/s, lr=8.96e-6, step_loss=0.0107/18/2023 20:23:20 - INFO - __main__ - train loss is 12.978009083075449\n",
      "Steps:  84%|▊| 12580/15000 [1:19:58<07:12,  5.60it/s, lr=8.96e-6, step_loss=0.1707/18/2023 20:23:21 - INFO - __main__ - train loss is 13.014463742030784\n",
      "Steps:  84%|▊| 12581/15000 [1:19:58<07:12,  5.59it/s, lr=8.96e-6, step_loss=0.0307/18/2023 20:23:21 - INFO - __main__ - train loss is 13.272620160831138\n",
      "Steps:  84%|▊| 12582/15000 [1:19:59<07:16,  5.54it/s, lr=8.96e-6, step_loss=0.2507/18/2023 20:23:21 - INFO - __main__ - train loss is 13.680426736129448\n",
      "Steps:  84%|▊| 12583/15000 [1:19:59<07:16,  5.54it/s, lr=8.96e-6, step_loss=0.4007/18/2023 20:23:21 - INFO - __main__ - train loss is 13.943356533301994\n",
      "Steps:  84%|▊| 12584/15000 [1:19:59<07:20,  5.48it/s, lr=8.96e-6, step_loss=0.2607/18/2023 20:23:21 - INFO - __main__ - train loss is 14.595745225204155\n",
      "Steps:  84%|▊| 12585/15000 [1:19:59<07:19,  5.50it/s, lr=8.96e-6, step_loss=0.6507/18/2023 20:23:21 - INFO - __main__ - train loss is 14.634943616343662\n",
      "Steps:  84%|▊| 12586/15000 [1:19:59<07:16,  5.53it/s, lr=8.96e-6, step_loss=0.0307/18/2023 20:23:22 - INFO - __main__ - train loss is 14.643251775531098\n",
      "Steps:  84%|▊| 12587/15000 [1:19:59<07:15,  5.55it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:22 - INFO - __main__ - train loss is 14.654613399645314\n",
      "Steps:  84%|▊| 12588/15000 [1:20:00<07:13,  5.56it/s, lr=8.96e-6, step_loss=0.0107/18/2023 20:23:22 - INFO - __main__ - train loss is 14.668666284298524\n",
      "Steps:  84%|▊| 12589/15000 [1:20:00<07:12,  5.57it/s, lr=8.96e-6, step_loss=0.0107/18/2023 20:23:22 - INFO - __main__ - train loss is 14.672651761909947\n",
      "Steps:  84%|▊| 12590/15000 [1:20:00<07:11,  5.58it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:22 - INFO - __main__ - train loss is 14.67480057477951\n",
      "Steps:  84%|▊| 12591/15000 [1:20:00<07:11,  5.58it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:22 - INFO - __main__ - train loss is 14.677659205161035\n",
      "Steps:  84%|▊| 12592/15000 [1:20:00<07:10,  5.59it/s, lr=8.96e-6, step_loss=0.0007/18/2023 20:23:23 - INFO - __main__ - train loss is 14.685074254870415\n",
      "Steps:  84%|▊| 12593/15000 [1:20:01<07:10,  5.59it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:23:23 - INFO - __main__ - train loss is 14.698857491835952\n",
      "Steps:  84%|▊| 12594/15000 [1:20:01<07:13,  5.56it/s, lr=8.95e-6, step_loss=0.0107/18/2023 20:23:23 - INFO - __main__ - train loss is 14.745272321626544\n",
      "Steps:  84%|▊| 12595/15000 [1:20:01<07:16,  5.51it/s, lr=8.95e-6, step_loss=0.0407/18/2023 20:23:23 - INFO - __main__ - train loss is 15.06275991909206\n",
      "Steps:  84%|▊| 12596/15000 [1:20:01<07:17,  5.50it/s, lr=8.95e-6, step_loss=0.3107/18/2023 20:23:23 - INFO - __main__ - train loss is 15.172698160633445\n",
      "Steps:  84%|▊| 12597/15000 [1:20:01<07:18,  5.48it/s, lr=8.95e-6, step_loss=0.1107/18/2023 20:23:24 - INFO - __main__ - train loss is 15.200217552483082\n",
      "Steps:  84%|▊| 12598/15000 [1:20:01<07:16,  5.50it/s, lr=8.95e-6, step_loss=0.0207/18/2023 20:23:24 - INFO - __main__ - train loss is 15.294206097722054\n",
      "Steps:  84%|▊| 12599/15000 [1:20:02<07:13,  5.53it/s, lr=8.95e-6, step_loss=0.0907/18/2023 20:23:24 - INFO - __main__ - train loss is 15.529187425971031\n",
      "Steps:  84%|▊| 12600/15000 [1:20:02<07:15,  5.51it/s, lr=8.95e-6, step_loss=0.2307/18/2023 20:23:24 - INFO - __main__ - train loss is 15.658824607729912\n",
      "Steps:  84%|▊| 12601/15000 [1:20:02<07:16,  5.49it/s, lr=8.95e-6, step_loss=0.1307/18/2023 20:23:24 - INFO - __main__ - train loss is 15.907192304730415\n",
      "Steps:  84%|▊| 12602/15000 [1:20:02<07:13,  5.53it/s, lr=8.95e-6, step_loss=0.2407/18/2023 20:23:24 - INFO - __main__ - train loss is 15.938186278566718\n",
      "Steps:  84%|▊| 12603/15000 [1:20:02<07:12,  5.55it/s, lr=8.95e-6, step_loss=0.0307/18/2023 20:23:25 - INFO - __main__ - train loss is 16.092971524223685\n",
      "Steps:  84%|▊| 12604/15000 [1:20:03<07:14,  5.52it/s, lr=8.95e-6, step_loss=0.1507/18/2023 20:23:25 - INFO - __main__ - train loss is 16.096105783246458\n",
      "Steps:  84%|▊| 12605/15000 [1:20:03<07:16,  5.49it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:23:25 - INFO - __main__ - train loss is 16.697599141858518\n",
      "Steps:  84%|▊| 12606/15000 [1:20:03<07:17,  5.47it/s, lr=8.95e-6, step_loss=0.6007/18/2023 20:23:25 - INFO - __main__ - train loss is 16.793098240159452\n",
      "Steps:  84%|▊| 12607/15000 [1:20:03<07:15,  5.49it/s, lr=8.95e-6, step_loss=0.0907/18/2023 20:23:25 - INFO - __main__ - train loss is 16.98203959967941\n",
      "Steps:  84%|▊| 12608/15000 [1:20:03<07:13,  5.52it/s, lr=8.95e-6, step_loss=0.1807/18/2023 20:23:26 - INFO - __main__ - train loss is 17.210746376775205\n",
      "Steps:  84%|▊| 12609/15000 [1:20:03<07:14,  5.51it/s, lr=8.95e-6, step_loss=0.2207/18/2023 20:23:26 - INFO - __main__ - train loss is 17.585414498113096\n",
      "Steps:  84%|▊| 12610/15000 [1:20:04<09:52,  4.04it/s, lr=8.95e-6, step_loss=0.3707/18/2023 20:23:27 - INFO - __main__ - Per validation step average loss is 0.31837064027786255\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Cumulative validation average loss is 0.31837064027786255\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Per validation step average loss is 0.04623762518167496\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Cumulative validation average loss is 0.3646082654595375\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Per validation step average loss is 0.20295853912830353\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Cumulative validation average loss is 0.567566804587841\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Per validation step average loss is 0.004377967678010464\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Cumulative validation average loss is 0.5719447722658515\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Per validation step average loss is 0.21645334362983704\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Cumulative validation average loss is 0.7883981158956885\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Per validation step average loss is 0.009271404705941677\n",
      "07/18/2023 20:23:27 - INFO - __main__ - Cumulative validation average loss is 0.7976695206016302\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Per validation step average loss is 0.33570170402526855\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Cumulative validation average loss is 1.1333712246268988\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Per validation step average loss is 0.026259645819664\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Cumulative validation average loss is 1.1596308704465628\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Per validation step average loss is 0.10490868985652924\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Cumulative validation average loss is 1.264539560303092\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Per validation step average loss is 0.040928810834884644\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Cumulative validation average loss is 1.3054683711379766\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Per validation step average loss is 0.003962079994380474\n",
      "07/18/2023 20:23:28 - INFO - __main__ - Cumulative validation average loss is 1.3094304511323571\n",
      "07/18/2023 20:23:29 - INFO - __main__ - Per validation step average loss is 0.028165485709905624\n",
      "07/18/2023 20:23:29 - INFO - __main__ - Cumulative validation average loss is 1.3375959368422627\n",
      "07/18/2023 20:23:29 - INFO - __main__ - Average validation loss for Epoch 129 is 0.11146632807018857\n",
      "07/18/2023 20:23:29 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:23:41 - INFO - __main__ - Starting epoch 130\n",
      "07/18/2023 20:23:42 - INFO - __main__ - train loss is 0.3524787724018097\n",
      "Steps:  84%|▊| 12611/15000 [1:20:20<3:21:26,  5.06s/it, lr=8.95e-6, step_loss=0.07/18/2023 20:23:43 - INFO - __main__ - train loss is 0.6151958703994751\n",
      "Steps:  84%|▊| 12612/15000 [1:20:21<2:27:41,  3.71s/it, lr=8.95e-6, step_loss=0.07/18/2023 20:23:43 - INFO - __main__ - train loss is 0.7074178904294968\n",
      "Steps:  84%|▊| 12613/15000 [1:20:21<1:50:05,  2.77s/it, lr=8.95e-6, step_loss=0.07/18/2023 20:23:44 - INFO - __main__ - train loss is 0.7378232702612877\n",
      "Steps:  84%|▊| 12614/15000 [1:20:22<1:23:34,  2.10s/it, lr=8.95e-6, step_loss=0.07/18/2023 20:23:45 - INFO - __main__ - train loss is 1.1592460498213768\n",
      "Steps:  84%|▊| 12615/15000 [1:20:22<1:05:06,  1.64s/it, lr=8.95e-6, step_loss=0.07/18/2023 20:23:45 - INFO - __main__ - train loss is 1.321486346423626\n",
      "Steps:  84%|▊| 12616/15000 [1:20:23<52:08,  1.31s/it, lr=8.95e-6, step_loss=0.1607/18/2023 20:23:46 - INFO - __main__ - train loss is 1.4137515649199486\n",
      "Steps:  84%|▊| 12617/15000 [1:20:24<43:12,  1.09s/it, lr=8.95e-6, step_loss=0.0907/18/2023 20:23:46 - INFO - __main__ - train loss is 1.8202919587492943\n",
      "Steps:  84%|▊| 12618/15000 [1:20:24<36:50,  1.08it/s, lr=8.95e-6, step_loss=0.4007/18/2023 20:23:47 - INFO - __main__ - train loss is 1.8534168489277363\n",
      "Steps:  84%|▊| 12619/15000 [1:20:25<32:18,  1.23it/s, lr=8.95e-6, step_loss=0.0307/18/2023 20:23:47 - INFO - __main__ - train loss is 2.4358275420963764\n",
      "Steps:  84%|▊| 12620/15000 [1:20:25<29:20,  1.35it/s, lr=8.95e-6, step_loss=0.5807/18/2023 20:23:48 - INFO - __main__ - train loss is 2.82136644795537\n",
      "Steps:  84%|▊| 12621/15000 [1:20:26<27:07,  1.46it/s, lr=8.95e-6, step_loss=0.3807/18/2023 20:23:48 - INFO - __main__ - train loss is 3.113285083323717\n",
      "Steps:  84%|▊| 12622/15000 [1:20:26<25:30,  1.55it/s, lr=8.95e-6, step_loss=0.2907/18/2023 20:23:49 - INFO - __main__ - train loss is 3.169293984770775\n",
      "Steps:  84%|▊| 12623/15000 [1:20:27<24:26,  1.62it/s, lr=8.95e-6, step_loss=0.0507/18/2023 20:23:50 - INFO - __main__ - train loss is 3.1876465789973736\n",
      "Steps:  84%|▊| 12624/15000 [1:20:27<23:46,  1.67it/s, lr=8.95e-6, step_loss=0.0107/18/2023 20:23:50 - INFO - __main__ - train loss is 3.272311981767416\n",
      "Steps:  84%|▊| 12625/15000 [1:20:28<23:19,  1.70it/s, lr=8.95e-6, step_loss=0.0807/18/2023 20:23:51 - INFO - __main__ - train loss is 3.2786204190924764\n",
      "Steps:  84%|▊| 12626/15000 [1:20:29<23:01,  1.72it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:23:51 - INFO - __main__ - train loss is 3.4846264394000173\n",
      "Steps:  84%|▊| 12627/15000 [1:20:29<22:43,  1.74it/s, lr=8.95e-6, step_loss=0.2007/18/2023 20:23:52 - INFO - __main__ - train loss is 3.498773586936295\n",
      "Steps:  84%|▊| 12628/15000 [1:20:30<24:11,  1.63it/s, lr=8.95e-6, step_loss=0.0107/18/2023 20:23:53 - INFO - __main__ - train loss is 3.920904708094895\n",
      "Steps:  84%|▊| 12629/15000 [1:20:30<24:14,  1.63it/s, lr=8.95e-6, step_loss=0.4207/18/2023 20:23:53 - INFO - __main__ - train loss is 3.933804809115827\n",
      "Steps:  84%|▊| 12630/15000 [1:20:31<23:27,  1.68it/s, lr=8.95e-6, step_loss=0.0107/18/2023 20:23:54 - INFO - __main__ - train loss is 4.261619894765317\n",
      "Steps:  84%|▊| 12631/15000 [1:20:31<22:53,  1.73it/s, lr=8.95e-6, step_loss=0.3207/18/2023 20:23:54 - INFO - __main__ - train loss is 4.543478815816343\n",
      "Steps:  84%|▊| 12632/15000 [1:20:32<22:24,  1.76it/s, lr=8.95e-6, step_loss=0.2807/18/2023 20:23:55 - INFO - __main__ - train loss is 4.545328699517995\n",
      "Steps:  84%|▊| 12633/15000 [1:20:33<22:03,  1.79it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:23:55 - INFO - __main__ - train loss is 4.575430402997881\n",
      "Steps:  84%|▊| 12634/15000 [1:20:33<22:01,  1.79it/s, lr=8.95e-6, step_loss=0.0307/18/2023 20:23:56 - INFO - __main__ - train loss is 4.846418092492968\n",
      "Steps:  84%|▊| 12635/15000 [1:20:34<21:49,  1.81it/s, lr=8.95e-6, step_loss=0.2707/18/2023 20:23:56 - INFO - __main__ - train loss is 4.851451960857958\n",
      "Steps:  84%|▊| 12636/15000 [1:20:34<21:39,  1.82it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:23:57 - INFO - __main__ - train loss is 5.055975717958063\n",
      "Steps:  84%|▊| 12637/15000 [1:20:35<21:37,  1.82it/s, lr=8.95e-6, step_loss=0.2007/18/2023 20:23:57 - INFO - __main__ - train loss is 5.2379942811094224\n",
      "Steps:  84%|▊| 12638/15000 [1:20:35<21:38,  1.82it/s, lr=8.95e-6, step_loss=0.1807/18/2023 20:23:58 - INFO - __main__ - train loss is 5.348134291823953\n",
      "Steps:  84%|▊| 12639/15000 [1:20:36<21:34,  1.82it/s, lr=8.95e-6, step_loss=0.1107/18/2023 20:23:59 - INFO - __main__ - train loss is 5.586153281386942\n",
      "Steps:  84%|▊| 12640/15000 [1:20:36<21:27,  1.83it/s, lr=8.95e-6, step_loss=0.2307/18/2023 20:23:59 - INFO - __main__ - train loss is 5.615445464383811\n",
      "Steps:  84%|▊| 12641/15000 [1:20:37<21:29,  1.83it/s, lr=8.95e-6, step_loss=0.0207/18/2023 20:24:00 - INFO - __main__ - train loss is 5.710872202645987\n",
      "Steps:  84%|▊| 12642/15000 [1:20:37<21:33,  1.82it/s, lr=8.95e-6, step_loss=0.0907/18/2023 20:24:00 - INFO - __main__ - train loss is 5.714893058408052\n",
      "Steps:  84%|▊| 12643/15000 [1:20:38<21:35,  1.82it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:24:01 - INFO - __main__ - train loss is 6.61222715722397\n",
      "Steps:  84%|▊| 12644/15000 [1:20:39<21:43,  1.81it/s, lr=8.95e-6, step_loss=0.8907/18/2023 20:24:01 - INFO - __main__ - train loss is 6.696279839146882\n",
      "Steps:  84%|▊| 12645/15000 [1:20:39<21:43,  1.81it/s, lr=8.95e-6, step_loss=0.0807/18/2023 20:24:02 - INFO - __main__ - train loss is 7.1215626751072705\n",
      "Steps:  84%|▊| 12646/15000 [1:20:40<21:42,  1.81it/s, lr=8.95e-6, step_loss=0.4207/18/2023 20:24:02 - INFO - __main__ - train loss is 7.125132476678118\n",
      "Steps:  84%|▊| 12647/15000 [1:20:40<21:35,  1.82it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:24:03 - INFO - __main__ - train loss is 7.236023841192946\n",
      "Steps:  84%|▊| 12648/15000 [1:20:41<21:29,  1.82it/s, lr=8.95e-6, step_loss=0.1107/18/2023 20:24:03 - INFO - __main__ - train loss is 7.237977349432185\n",
      "Steps:  84%|▊| 12649/15000 [1:20:41<21:22,  1.83it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:24:04 - INFO - __main__ - train loss is 7.246107734972611\n",
      "Steps:  84%|▊| 12650/15000 [1:20:42<21:13,  1.84it/s, lr=8.95e-6, step_loss=0.0007/18/2023 20:24:05 - INFO - __main__ - train loss is 7.3035524191800505\n",
      "Steps:  84%|▊| 12651/15000 [1:20:42<21:13,  1.84it/s, lr=8.95e-6, step_loss=0.0507/18/2023 20:24:05 - INFO - __main__ - train loss is 7.362695779884234\n",
      "Steps:  84%|▊| 12652/15000 [1:20:43<21:10,  1.85it/s, lr=8.95e-6, step_loss=0.0507/18/2023 20:24:06 - INFO - __main__ - train loss is 7.383204335579649\n",
      "Steps:  84%|▊| 12653/15000 [1:20:43<21:06,  1.85it/s, lr=8.95e-6, step_loss=0.0207/18/2023 20:24:06 - INFO - __main__ - train loss is 7.397451453143731\n",
      "Steps:  84%|▊| 12654/15000 [1:20:44<21:08,  1.85it/s, lr=8.95e-6, step_loss=0.0107/18/2023 20:24:07 - INFO - __main__ - train loss is 7.40854779467918\n",
      "Steps:  84%|▊| 12655/15000 [1:20:45<21:08,  1.85it/s, lr=8.94e-6, step_loss=0.0107/18/2023 20:24:07 - INFO - __main__ - train loss is 7.536441570380703\n",
      "Steps:  84%|▊| 12656/15000 [1:20:45<21:09,  1.85it/s, lr=8.94e-6, step_loss=0.1207/18/2023 20:24:08 - INFO - __main__ - train loss is 7.580046667018905\n",
      "Steps:  84%|▊| 12657/15000 [1:20:46<21:01,  1.86it/s, lr=8.94e-6, step_loss=0.0407/18/2023 20:24:08 - INFO - __main__ - train loss is 7.939833356300369\n",
      "Steps:  84%|▊| 12658/15000 [1:20:46<21:04,  1.85it/s, lr=8.94e-6, step_loss=0.3607/18/2023 20:24:09 - INFO - __main__ - train loss is 7.94145877356641\n",
      "Steps:  84%|▊| 12659/15000 [1:20:47<21:02,  1.85it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:09 - INFO - __main__ - train loss is 8.011518803192303\n",
      "Steps:  84%|▊| 12660/15000 [1:20:47<21:04,  1.85it/s, lr=8.94e-6, step_loss=0.0707/18/2023 20:24:10 - INFO - __main__ - train loss is 8.27670141751878\n",
      "Steps:  84%|▊| 12661/15000 [1:20:48<21:06,  1.85it/s, lr=8.94e-6, step_loss=0.2607/18/2023 20:24:10 - INFO - __main__ - train loss is 8.494393315864727\n",
      "Steps:  84%|▊| 12662/15000 [1:20:48<21:04,  1.85it/s, lr=8.94e-6, step_loss=0.2107/18/2023 20:24:11 - INFO - __main__ - train loss is 8.537748747272417\n",
      "Steps:  84%|▊| 12663/15000 [1:20:49<21:03,  1.85it/s, lr=8.94e-6, step_loss=0.0407/18/2023 20:24:12 - INFO - __main__ - train loss is 8.539161444292404\n",
      "Steps:  84%|▊| 12664/15000 [1:20:49<20:59,  1.86it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:12 - INFO - __main__ - train loss is 8.686891675577499\n",
      "Steps:  84%|▊| 12665/15000 [1:20:50<21:00,  1.85it/s, lr=8.94e-6, step_loss=0.1407/18/2023 20:24:13 - INFO - __main__ - train loss is 8.693280861363746\n",
      "Steps:  84%|▊| 12666/15000 [1:20:51<21:03,  1.85it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:13 - INFO - __main__ - train loss is 8.815590017125942\n",
      "Steps:  84%|▊| 12667/15000 [1:20:51<21:00,  1.85it/s, lr=8.94e-6, step_loss=0.1207/18/2023 20:24:14 - INFO - __main__ - train loss is 9.177664988324977\n",
      "Steps:  84%|▊| 12668/15000 [1:20:52<21:00,  1.85it/s, lr=8.94e-6, step_loss=0.3607/18/2023 20:24:14 - INFO - __main__ - train loss is 9.236201547668315\n",
      "Steps:  84%|▊| 12669/15000 [1:20:52<20:57,  1.85it/s, lr=8.94e-6, step_loss=0.0507/18/2023 20:24:15 - INFO - __main__ - train loss is 9.239316012593918\n",
      "Steps:  84%|▊| 12670/15000 [1:20:53<20:59,  1.85it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:15 - INFO - __main__ - train loss is 9.35239921126049\n",
      "Steps:  84%|▊| 12671/15000 [1:20:53<21:00,  1.85it/s, lr=8.94e-6, step_loss=0.1107/18/2023 20:24:16 - INFO - __main__ - train loss is 9.410562254372053\n",
      "Steps:  84%|▊| 12672/15000 [1:20:54<21:09,  1.83it/s, lr=8.94e-6, step_loss=0.0507/18/2023 20:24:16 - INFO - __main__ - train loss is 9.412354763946496\n",
      "Steps:  84%|▊| 12673/15000 [1:20:54<21:04,  1.84it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:17 - INFO - __main__ - train loss is 9.416841486818157\n",
      "Steps:  84%|▊| 12674/15000 [1:20:55<21:06,  1.84it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:18 - INFO - __main__ - train loss is 9.902149597532116\n",
      "Steps:  84%|▊| 12675/15000 [1:20:55<21:13,  1.83it/s, lr=8.94e-6, step_loss=0.4807/18/2023 20:24:18 - INFO - __main__ - train loss is 10.199515084153973\n",
      "Steps:  85%|▊| 12676/15000 [1:20:56<21:07,  1.83it/s, lr=8.94e-6, step_loss=0.2907/18/2023 20:24:19 - INFO - __main__ - train loss is 10.462554881698452\n",
      "Steps:  85%|▊| 12677/15000 [1:20:57<21:06,  1.83it/s, lr=8.94e-6, step_loss=0.2607/18/2023 20:24:19 - INFO - __main__ - train loss is 10.68814216030296\n",
      "Steps:  85%|▊| 12678/15000 [1:20:57<21:03,  1.84it/s, lr=8.94e-6, step_loss=0.2207/18/2023 20:24:20 - INFO - __main__ - train loss is 10.78240528178867\n",
      "Steps:  85%|▊| 12679/15000 [1:20:58<20:59,  1.84it/s, lr=8.94e-6, step_loss=0.0907/18/2023 20:24:20 - INFO - __main__ - train loss is 10.942153925425373\n",
      "Steps:  85%|▊| 12680/15000 [1:20:58<21:07,  1.83it/s, lr=8.94e-6, step_loss=0.1607/18/2023 20:24:21 - INFO - __main__ - train loss is 10.946434912621044\n",
      "Steps:  85%|▊| 12681/15000 [1:20:59<21:03,  1.84it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:21 - INFO - __main__ - train loss is 11.031782714067958\n",
      "Steps:  85%|▊| 12682/15000 [1:20:59<21:01,  1.84it/s, lr=8.94e-6, step_loss=0.0807/18/2023 20:24:22 - INFO - __main__ - train loss is 11.257634816109203\n",
      "Steps:  85%|▊| 12683/15000 [1:21:00<21:00,  1.84it/s, lr=8.94e-6, step_loss=0.2207/18/2023 20:24:22 - INFO - __main__ - train loss is 11.267102697282098\n",
      "Steps:  85%|▊| 12684/15000 [1:21:00<20:58,  1.84it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:23 - INFO - __main__ - train loss is 11.494253316312097\n",
      "Steps:  85%|▊| 12685/15000 [1:21:01<20:58,  1.84it/s, lr=8.94e-6, step_loss=0.2207/18/2023 20:24:24 - INFO - __main__ - train loss is 11.521983747719787\n",
      "Steps:  85%|▊| 12686/15000 [1:21:01<20:56,  1.84it/s, lr=8.94e-6, step_loss=0.0207/18/2023 20:24:24 - INFO - __main__ - train loss is 11.636758287786506\n",
      "Steps:  85%|▊| 12687/15000 [1:21:02<20:56,  1.84it/s, lr=8.94e-6, step_loss=0.1107/18/2023 20:24:25 - INFO - __main__ - train loss is 11.668286004452966\n",
      "Steps:  85%|▊| 12688/15000 [1:21:02<20:55,  1.84it/s, lr=8.94e-6, step_loss=0.0307/18/2023 20:24:25 - INFO - __main__ - train loss is 11.675786965410225\n",
      "Steps:  85%|▊| 12689/15000 [1:21:03<21:02,  1.83it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:26 - INFO - __main__ - train loss is 11.812048875610344\n",
      "Steps:  85%|▊| 12690/15000 [1:21:04<20:58,  1.84it/s, lr=8.94e-6, step_loss=0.1307/18/2023 20:24:26 - INFO - __main__ - train loss is 11.814589676330797\n",
      "Steps:  85%|▊| 12691/15000 [1:21:04<21:02,  1.83it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:27 - INFO - __main__ - train loss is 12.076477643917315\n",
      "Steps:  85%|▊| 12692/15000 [1:21:05<21:15,  1.81it/s, lr=8.94e-6, step_loss=0.2607/18/2023 20:24:27 - INFO - __main__ - train loss is 12.267137241433375\n",
      "Steps:  85%|▊| 12693/15000 [1:21:05<21:09,  1.82it/s, lr=8.94e-6, step_loss=0.1907/18/2023 20:24:28 - INFO - __main__ - train loss is 12.311362740467303\n",
      "Steps:  85%|▊| 12694/15000 [1:21:06<21:03,  1.83it/s, lr=8.94e-6, step_loss=0.0407/18/2023 20:24:28 - INFO - __main__ - train loss is 12.575798627804033\n",
      "Steps:  85%|▊| 12695/15000 [1:21:06<20:51,  1.84it/s, lr=8.94e-6, step_loss=0.2607/18/2023 20:24:29 - INFO - __main__ - train loss is 12.81504279084038\n",
      "Steps:  85%|▊| 12696/15000 [1:21:07<20:51,  1.84it/s, lr=8.94e-6, step_loss=0.2307/18/2023 20:24:30 - INFO - __main__ - train loss is 12.897260603378527\n",
      "Steps:  85%|▊| 12697/15000 [1:21:07<20:47,  1.85it/s, lr=8.94e-6, step_loss=0.0807/18/2023 20:24:30 - INFO - __main__ - train loss is 12.898918970837258\n",
      "Steps:  85%|▊| 12698/15000 [1:21:08<20:49,  1.84it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:31 - INFO - __main__ - train loss is 13.06895284296479\n",
      "Steps:  85%|▊| 12699/15000 [1:21:08<20:51,  1.84it/s, lr=8.94e-6, step_loss=0.1707/18/2023 20:24:31 - INFO - __main__ - train loss is 13.287635728134774\n",
      "Steps:  85%|▊| 12700/15000 [1:21:09<20:50,  1.84it/s, lr=8.94e-6, step_loss=0.2107/18/2023 20:24:32 - INFO - __main__ - train loss is 13.297760650864802\n",
      "Steps:  85%|▊| 12701/15000 [1:21:10<20:48,  1.84it/s, lr=8.94e-6, step_loss=0.0107/18/2023 20:24:32 - INFO - __main__ - train loss is 13.831179067841731\n",
      "Steps:  85%|▊| 12702/15000 [1:21:10<20:46,  1.84it/s, lr=8.94e-6, step_loss=0.5307/18/2023 20:24:33 - INFO - __main__ - train loss is 13.848541753715836\n",
      "Steps:  85%|▊| 12703/15000 [1:21:11<20:42,  1.85it/s, lr=8.94e-6, step_loss=0.0107/18/2023 20:24:33 - INFO - __main__ - train loss is 14.346561627811752\n",
      "Steps:  85%|▊| 12704/15000 [1:21:11<20:39,  1.85it/s, lr=8.94e-6, step_loss=0.4907/18/2023 20:24:34 - INFO - __main__ - train loss is 14.679621981806122\n",
      "Steps:  85%|▊| 12705/15000 [1:21:12<20:38,  1.85it/s, lr=8.94e-6, step_loss=0.3307/18/2023 20:24:34 - INFO - __main__ - train loss is 14.77154452574905\n",
      "Steps:  85%|▊| 12706/15000 [1:21:12<20:33,  1.86it/s, lr=8.94e-6, step_loss=0.0907/18/2023 20:24:35 - INFO - __main__ - train loss is 14.786606310284697\n",
      "Steps:  85%|▊| 12707/15000 [1:21:13<24:07,  1.58it/s, lr=8.94e-6, step_loss=0.0107/18/2023 20:24:36 - INFO - __main__ - Per validation step average loss is 0.002999718766659498\n",
      "07/18/2023 20:24:36 - INFO - __main__ - Cumulative validation average loss is 0.002999718766659498\n",
      "07/18/2023 20:24:36 - INFO - __main__ - Per validation step average loss is 0.0035625414457172155\n",
      "07/18/2023 20:24:36 - INFO - __main__ - Cumulative validation average loss is 0.006562260212376714\n",
      "07/18/2023 20:24:36 - INFO - __main__ - Per validation step average loss is 0.003916659392416477\n",
      "07/18/2023 20:24:36 - INFO - __main__ - Cumulative validation average loss is 0.010478919604793191\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Per validation step average loss is 0.04004389047622681\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Cumulative validation average loss is 0.05052281008102\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Per validation step average loss is 0.0020360955968499184\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Cumulative validation average loss is 0.052558905677869916\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Per validation step average loss is 0.007970411330461502\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Cumulative validation average loss is 0.06052931700833142\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Per validation step average loss is 0.026243599131703377\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Cumulative validation average loss is 0.0867729161400348\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Per validation step average loss is 0.05152387171983719\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Cumulative validation average loss is 0.13829678785987198\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Per validation step average loss is 0.07661565393209457\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Cumulative validation average loss is 0.21491244179196656\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Per validation step average loss is 0.00840002577751875\n",
      "07/18/2023 20:24:37 - INFO - __main__ - Cumulative validation average loss is 0.2233124675694853\n",
      "07/18/2023 20:24:38 - INFO - __main__ - Per validation step average loss is 0.3826442360877991\n",
      "07/18/2023 20:24:38 - INFO - __main__ - Cumulative validation average loss is 0.6059567036572844\n",
      "07/18/2023 20:24:38 - INFO - __main__ - Per validation step average loss is 0.6604011058807373\n",
      "07/18/2023 20:24:38 - INFO - __main__ - Cumulative validation average loss is 1.2663578095380217\n",
      "07/18/2023 20:24:38 - INFO - __main__ - Average validation loss for Epoch 130 is 0.10552981746150181\n",
      "07/18/2023 20:24:38 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:24:51 - INFO - __main__ - Starting epoch 131\n",
      "07/18/2023 20:24:52 - INFO - __main__ - train loss is 0.4668271541595459\n",
      "Steps:  85%|▊| 12708/15000 [1:21:29<3:24:34,  5.36s/it, lr=8.94e-6, step_loss=0.07/18/2023 20:24:52 - INFO - __main__ - train loss is 0.5637459307909012\n",
      "Steps:  85%|▊| 12709/15000 [1:21:30<2:25:14,  3.80s/it, lr=8.94e-6, step_loss=0.07/18/2023 20:24:52 - INFO - __main__ - train loss is 0.6081860437989235\n",
      "Steps:  85%|▊| 12710/15000 [1:21:30<1:43:47,  2.72s/it, lr=8.94e-6, step_loss=0.07/18/2023 20:24:52 - INFO - __main__ - train loss is 0.8419746682047844\n",
      "Steps:  85%|▊| 12711/15000 [1:21:30<1:14:42,  1.96s/it, lr=8.94e-6, step_loss=0.07/18/2023 20:24:52 - INFO - __main__ - train loss is 0.8445547269657254\n",
      "Steps:  85%|▊| 12712/15000 [1:21:30<54:20,  1.43s/it, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:53 - INFO - __main__ - train loss is 1.0234845774248242\n",
      "Steps:  85%|▊| 12713/15000 [1:21:30<40:07,  1.05s/it, lr=8.94e-6, step_loss=0.1707/18/2023 20:24:53 - INFO - __main__ - train loss is 1.0509334532544017\n",
      "Steps:  85%|▊| 12714/15000 [1:21:31<30:11,  1.26it/s, lr=8.94e-6, step_loss=0.0207/18/2023 20:24:53 - INFO - __main__ - train loss is 1.0564496368169785\n",
      "Steps:  85%|▊| 12715/15000 [1:21:31<23:08,  1.65it/s, lr=8.94e-6, step_loss=0.0007/18/2023 20:24:53 - INFO - __main__ - train loss is 1.2829120606184006\n",
      "Steps:  85%|▊| 12716/15000 [1:21:31<18:13,  2.09it/s, lr=8.94e-6, step_loss=0.2207/18/2023 20:24:53 - INFO - __main__ - train loss is 1.388087972998619\n",
      "Steps:  85%|▊| 12717/15000 [1:21:31<14:47,  2.57it/s, lr=8.93e-6, step_loss=0.1007/18/2023 20:24:53 - INFO - __main__ - train loss is 1.4254307486116886\n",
      "Steps:  85%|▊| 12718/15000 [1:21:31<12:23,  3.07it/s, lr=8.93e-6, step_loss=0.0307/18/2023 20:24:54 - INFO - __main__ - train loss is 1.5540664233267307\n",
      "Steps:  85%|▊| 12719/15000 [1:21:31<10:42,  3.55it/s, lr=8.93e-6, step_loss=0.1207/18/2023 20:24:54 - INFO - __main__ - train loss is 1.5667280051857233\n",
      "Steps:  85%|▊| 12720/15000 [1:21:32<09:30,  3.99it/s, lr=8.93e-6, step_loss=0.0107/18/2023 20:24:54 - INFO - __main__ - train loss is 1.651191109791398\n",
      "Steps:  85%|▊| 12721/15000 [1:21:32<08:40,  4.37it/s, lr=8.93e-6, step_loss=0.0807/18/2023 20:24:54 - INFO - __main__ - train loss is 2.0443356577306986\n",
      "Steps:  85%|▊| 12722/15000 [1:21:32<08:06,  4.69it/s, lr=8.93e-6, step_loss=0.3907/18/2023 20:24:54 - INFO - __main__ - train loss is 2.0958051923662424\n",
      "Steps:  85%|▊| 12723/15000 [1:21:32<07:42,  4.92it/s, lr=8.93e-6, step_loss=0.0507/18/2023 20:24:54 - INFO - __main__ - train loss is 2.382974022999406\n",
      "Steps:  85%|▊| 12724/15000 [1:21:32<07:25,  5.11it/s, lr=8.93e-6, step_loss=0.2807/18/2023 20:24:55 - INFO - __main__ - train loss is 2.545730883255601\n",
      "Steps:  85%|▊| 12725/15000 [1:21:33<07:13,  5.25it/s, lr=8.93e-6, step_loss=0.1607/18/2023 20:24:55 - INFO - __main__ - train loss is 2.5489692431874573\n",
      "Steps:  85%|▊| 12726/15000 [1:21:33<07:09,  5.30it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:24:55 - INFO - __main__ - train loss is 2.737514976877719\n",
      "Steps:  85%|▊| 12727/15000 [1:21:33<07:01,  5.39it/s, lr=8.93e-6, step_loss=0.1807/18/2023 20:24:55 - INFO - __main__ - train loss is 3.014723662752658\n",
      "Steps:  85%|▊| 12728/15000 [1:21:33<06:56,  5.45it/s, lr=8.93e-6, step_loss=0.2707/18/2023 20:24:55 - INFO - __main__ - train loss is 3.0923186135478318\n",
      "Steps:  85%|▊| 12729/15000 [1:21:33<06:53,  5.49it/s, lr=8.93e-6, step_loss=0.0707/18/2023 20:24:56 - INFO - __main__ - train loss is 3.184560213703662\n",
      "Steps:  85%|▊| 12730/15000 [1:21:33<06:50,  5.52it/s, lr=8.93e-6, step_loss=0.0907/18/2023 20:24:56 - INFO - __main__ - train loss is 3.1998536200262606\n",
      "Steps:  85%|▊| 12731/15000 [1:21:34<06:49,  5.55it/s, lr=8.93e-6, step_loss=0.0107/18/2023 20:24:56 - INFO - __main__ - train loss is 3.2589214951731265\n",
      "Steps:  85%|▊| 12732/15000 [1:21:34<06:47,  5.56it/s, lr=8.93e-6, step_loss=0.0507/18/2023 20:24:56 - INFO - __main__ - train loss is 3.447904428932816\n",
      "Steps:  85%|▊| 12733/15000 [1:21:34<06:46,  5.58it/s, lr=8.93e-6, step_loss=0.1807/18/2023 20:24:56 - INFO - __main__ - train loss is 3.453442313708365\n",
      "Steps:  85%|▊| 12734/15000 [1:21:34<06:45,  5.58it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:24:56 - INFO - __main__ - train loss is 3.458138843998313\n",
      "Steps:  85%|▊| 12735/15000 [1:21:34<06:45,  5.59it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:24:57 - INFO - __main__ - train loss is 3.5219778027385473\n",
      "Steps:  85%|▊| 12736/15000 [1:21:35<06:44,  5.60it/s, lr=8.93e-6, step_loss=0.0607/18/2023 20:24:57 - INFO - __main__ - train loss is 3.635181238874793\n",
      "Steps:  85%|▊| 12737/15000 [1:21:35<06:44,  5.60it/s, lr=8.93e-6, step_loss=0.1107/18/2023 20:24:57 - INFO - __main__ - train loss is 4.065999677404761\n",
      "Steps:  85%|▊| 12738/15000 [1:21:35<06:43,  5.60it/s, lr=8.93e-6, step_loss=0.4307/18/2023 20:24:57 - INFO - __main__ - train loss is 4.127324579283595\n",
      "Steps:  85%|▊| 12739/15000 [1:21:35<06:43,  5.60it/s, lr=8.93e-6, step_loss=0.0607/18/2023 20:24:57 - INFO - __main__ - train loss is 4.635604677721858\n",
      "Steps:  85%|▊| 12740/15000 [1:21:35<06:43,  5.61it/s, lr=8.93e-6, step_loss=0.5007/18/2023 20:24:58 - INFO - __main__ - train loss is 4.714574275538325\n",
      "Steps:  85%|▊| 12741/15000 [1:21:35<06:42,  5.61it/s, lr=8.93e-6, step_loss=0.0707/18/2023 20:24:58 - INFO - __main__ - train loss is 4.882024912163615\n",
      "Steps:  85%|▊| 12742/15000 [1:21:36<06:42,  5.60it/s, lr=8.93e-6, step_loss=0.1607/18/2023 20:24:58 - INFO - __main__ - train loss is 4.970481118187308\n",
      "Steps:  85%|▊| 12743/15000 [1:21:36<06:47,  5.54it/s, lr=8.93e-6, step_loss=0.0807/18/2023 20:24:58 - INFO - __main__ - train loss is 4.973724493291229\n",
      "Steps:  85%|▊| 12744/15000 [1:21:36<06:46,  5.55it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:24:58 - INFO - __main__ - train loss is 5.030928479041904\n",
      "Steps:  85%|▊| 12745/15000 [1:21:36<06:44,  5.57it/s, lr=8.93e-6, step_loss=0.0507/18/2023 20:24:58 - INFO - __main__ - train loss is 5.1790687455795705\n",
      "Steps:  85%|▊| 12746/15000 [1:21:36<06:43,  5.58it/s, lr=8.93e-6, step_loss=0.1407/18/2023 20:24:59 - INFO - __main__ - train loss is 5.320590631570667\n",
      "Steps:  85%|▊| 12747/15000 [1:21:36<06:43,  5.58it/s, lr=8.93e-6, step_loss=0.1407/18/2023 20:24:59 - INFO - __main__ - train loss is 5.360306741204113\n",
      "Steps:  85%|▊| 12748/15000 [1:21:37<06:43,  5.58it/s, lr=8.93e-6, step_loss=0.0307/18/2023 20:24:59 - INFO - __main__ - train loss is 5.773322643246502\n",
      "Steps:  85%|▊| 12749/15000 [1:21:37<06:42,  5.59it/s, lr=8.93e-6, step_loss=0.4107/18/2023 20:24:59 - INFO - __main__ - train loss is 6.124205709900707\n",
      "Steps:  85%|▊| 12750/15000 [1:21:37<06:42,  5.59it/s, lr=8.93e-6, step_loss=0.3507/18/2023 20:24:59 - INFO - __main__ - train loss is 6.144403488840908\n",
      "Steps:  85%|▊| 12751/15000 [1:21:37<06:41,  5.59it/s, lr=8.93e-6, step_loss=0.0207/18/2023 20:25:00 - INFO - __main__ - train loss is 6.1963473609648645\n",
      "Steps:  85%|▊| 12752/15000 [1:21:37<06:41,  5.60it/s, lr=8.93e-6, step_loss=0.0507/18/2023 20:25:00 - INFO - __main__ - train loss is 6.230597054120153\n",
      "Steps:  85%|▊| 12753/15000 [1:21:38<06:41,  5.60it/s, lr=8.93e-6, step_loss=0.0307/18/2023 20:25:00 - INFO - __main__ - train loss is 6.366642808075994\n",
      "Steps:  85%|▊| 12754/15000 [1:21:38<06:41,  5.60it/s, lr=8.93e-6, step_loss=0.1307/18/2023 20:25:00 - INFO - __main__ - train loss is 6.372327257413417\n",
      "Steps:  85%|▊| 12755/15000 [1:21:38<06:40,  5.60it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:25:00 - INFO - __main__ - train loss is 6.594249178189784\n",
      "Steps:  85%|▊| 12756/15000 [1:21:38<06:40,  5.60it/s, lr=8.93e-6, step_loss=0.2207/18/2023 20:25:00 - INFO - __main__ - train loss is 6.760022897738963\n",
      "Steps:  85%|▊| 12757/15000 [1:21:38<06:40,  5.60it/s, lr=8.93e-6, step_loss=0.1607/18/2023 20:25:01 - INFO - __main__ - train loss is 6.977398474235088\n",
      "Steps:  85%|▊| 12758/15000 [1:21:38<06:40,  5.60it/s, lr=8.93e-6, step_loss=0.2107/18/2023 20:25:01 - INFO - __main__ - train loss is 7.053208027500659\n",
      "Steps:  85%|▊| 12759/15000 [1:21:39<06:40,  5.60it/s, lr=8.93e-6, step_loss=0.0707/18/2023 20:25:01 - INFO - __main__ - train loss is 7.580118690151721\n",
      "Steps:  85%|▊| 12760/15000 [1:21:39<06:39,  5.60it/s, lr=8.93e-6, step_loss=0.5207/18/2023 20:25:01 - INFO - __main__ - train loss is 7.630180411506444\n",
      "Steps:  85%|▊| 12761/15000 [1:21:39<06:39,  5.60it/s, lr=8.93e-6, step_loss=0.0507/18/2023 20:25:01 - INFO - __main__ - train loss is 7.637305311858654\n",
      "Steps:  85%|▊| 12762/15000 [1:21:39<06:39,  5.60it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:25:01 - INFO - __main__ - train loss is 7.647531465627253\n",
      "Steps:  85%|▊| 12763/15000 [1:21:39<06:39,  5.60it/s, lr=8.93e-6, step_loss=0.0107/18/2023 20:25:02 - INFO - __main__ - train loss is 7.758095414377749\n",
      "Steps:  85%|▊| 12764/15000 [1:21:40<06:39,  5.59it/s, lr=8.93e-6, step_loss=0.1107/18/2023 20:25:02 - INFO - __main__ - train loss is 7.801357646472752\n",
      "Steps:  85%|▊| 12765/15000 [1:21:40<06:39,  5.60it/s, lr=8.93e-6, step_loss=0.0407/18/2023 20:25:02 - INFO - __main__ - train loss is 8.262545605190098\n",
      "Steps:  85%|▊| 12766/15000 [1:21:40<06:39,  5.60it/s, lr=8.93e-6, step_loss=0.4607/18/2023 20:25:02 - INFO - __main__ - train loss is 8.288435433991253\n",
      "Steps:  85%|▊| 12767/15000 [1:21:40<06:38,  5.60it/s, lr=8.93e-6, step_loss=0.0207/18/2023 20:25:02 - INFO - __main__ - train loss is 8.399463404901326\n",
      "Steps:  85%|▊| 12768/15000 [1:21:40<06:38,  5.60it/s, lr=8.93e-6, step_loss=0.1107/18/2023 20:25:03 - INFO - __main__ - train loss is 8.415690639056265\n",
      "Steps:  85%|▊| 12769/15000 [1:21:40<06:41,  5.55it/s, lr=8.93e-6, step_loss=0.0107/18/2023 20:25:03 - INFO - __main__ - train loss is 8.62964501325041\n",
      "Steps:  85%|▊| 12770/15000 [1:21:41<06:40,  5.57it/s, lr=8.93e-6, step_loss=0.2107/18/2023 20:25:03 - INFO - __main__ - train loss is 8.638146051205695\n",
      "Steps:  85%|▊| 12771/15000 [1:21:41<06:39,  5.58it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:25:03 - INFO - __main__ - train loss is 8.975819208659232\n",
      "Steps:  85%|▊| 12772/15000 [1:21:41<06:38,  5.59it/s, lr=8.93e-6, step_loss=0.3307/18/2023 20:25:03 - INFO - __main__ - train loss is 9.059293226338923\n",
      "Steps:  85%|▊| 12773/15000 [1:21:41<06:38,  5.59it/s, lr=8.93e-6, step_loss=0.0807/18/2023 20:25:03 - INFO - __main__ - train loss is 9.263871879316866\n",
      "Steps:  85%|▊| 12774/15000 [1:21:41<06:37,  5.60it/s, lr=8.93e-6, step_loss=0.2007/18/2023 20:25:04 - INFO - __main__ - train loss is 9.602354736067355\n",
      "Steps:  85%|▊| 12775/15000 [1:21:41<06:37,  5.60it/s, lr=8.93e-6, step_loss=0.3307/18/2023 20:25:04 - INFO - __main__ - train loss is 9.702230387367308\n",
      "Steps:  85%|▊| 12776/15000 [1:21:42<06:37,  5.60it/s, lr=8.93e-6, step_loss=0.0907/18/2023 20:25:04 - INFO - __main__ - train loss is 9.856703215278685\n",
      "Steps:  85%|▊| 12777/15000 [1:21:42<06:36,  5.60it/s, lr=8.93e-6, step_loss=0.1507/18/2023 20:25:04 - INFO - __main__ - train loss is 9.861007250845432\n",
      "Steps:  85%|▊| 12778/15000 [1:21:42<06:36,  5.61it/s, lr=8.93e-6, step_loss=0.0007/18/2023 20:25:04 - INFO - __main__ - train loss is 9.940943613648415\n",
      "Steps:  85%|▊| 12779/15000 [1:21:42<06:36,  5.60it/s, lr=8.92e-6, step_loss=0.0707/18/2023 20:25:05 - INFO - __main__ - train loss is 9.954285757616162\n",
      "Steps:  85%|▊| 12780/15000 [1:21:42<06:36,  5.60it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:05 - INFO - __main__ - train loss is 10.709690587595105\n",
      "Steps:  85%|▊| 12781/15000 [1:21:43<06:36,  5.60it/s, lr=8.92e-6, step_loss=0.7507/18/2023 20:25:05 - INFO - __main__ - train loss is 11.053385036066175\n",
      "Steps:  85%|▊| 12782/15000 [1:21:43<06:35,  5.60it/s, lr=8.92e-6, step_loss=0.3407/18/2023 20:25:05 - INFO - __main__ - train loss is 11.30817793495953\n",
      "Steps:  85%|▊| 12783/15000 [1:21:43<06:35,  5.60it/s, lr=8.92e-6, step_loss=0.2507/18/2023 20:25:05 - INFO - __main__ - train loss is 11.464355932548642\n",
      "Steps:  85%|▊| 12784/15000 [1:21:43<06:35,  5.60it/s, lr=8.92e-6, step_loss=0.1507/18/2023 20:25:05 - INFO - __main__ - train loss is 11.482747413218021\n",
      "Steps:  85%|▊| 12785/15000 [1:21:43<06:35,  5.60it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:06 - INFO - __main__ - train loss is 11.657488517463207\n",
      "Steps:  85%|▊| 12786/15000 [1:21:43<06:35,  5.60it/s, lr=8.92e-6, step_loss=0.1707/18/2023 20:25:06 - INFO - __main__ - train loss is 11.672742012888193\n",
      "Steps:  85%|▊| 12787/15000 [1:21:44<06:35,  5.60it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:06 - INFO - __main__ - train loss is 11.69077792018652\n",
      "Steps:  85%|▊| 12788/15000 [1:21:44<06:34,  5.60it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:06 - INFO - __main__ - train loss is 11.693812713725492\n",
      "Steps:  85%|▊| 12789/15000 [1:21:44<06:34,  5.61it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:06 - INFO - __main__ - train loss is 11.701241825474426\n",
      "Steps:  85%|▊| 12790/15000 [1:21:44<06:33,  5.61it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:06 - INFO - __main__ - train loss is 11.704628861276433\n",
      "Steps:  85%|▊| 12791/15000 [1:21:44<06:33,  5.61it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:07 - INFO - __main__ - train loss is 12.09453201922588\n",
      "Steps:  85%|▊| 12792/15000 [1:21:45<06:33,  5.61it/s, lr=8.92e-6, step_loss=0.3907/18/2023 20:25:07 - INFO - __main__ - train loss is 12.602400964824483\n",
      "Steps:  85%|▊| 12793/15000 [1:21:45<06:33,  5.61it/s, lr=8.92e-6, step_loss=0.5007/18/2023 20:25:07 - INFO - __main__ - train loss is 12.980944431154057\n",
      "Steps:  85%|▊| 12794/15000 [1:21:45<06:32,  5.62it/s, lr=8.92e-6, step_loss=0.3707/18/2023 20:25:07 - INFO - __main__ - train loss is 13.11923577520065\n",
      "Steps:  85%|▊| 12795/15000 [1:21:45<06:32,  5.61it/s, lr=8.92e-6, step_loss=0.1307/18/2023 20:25:07 - INFO - __main__ - train loss is 13.13964573922567\n",
      "Steps:  85%|▊| 12796/15000 [1:21:45<06:33,  5.60it/s, lr=8.92e-6, step_loss=0.0207/18/2023 20:25:08 - INFO - __main__ - train loss is 13.395042522577569\n",
      "Steps:  85%|▊| 12797/15000 [1:21:45<06:32,  5.61it/s, lr=8.92e-6, step_loss=0.2507/18/2023 20:25:08 - INFO - __main__ - train loss is 13.435937977163121\n",
      "Steps:  85%|▊| 12798/15000 [1:21:46<06:32,  5.61it/s, lr=8.92e-6, step_loss=0.0407/18/2023 20:25:08 - INFO - __main__ - train loss is 13.443478941218928\n",
      "Steps:  85%|▊| 12799/15000 [1:21:46<06:32,  5.61it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:08 - INFO - __main__ - train loss is 13.539263463811949\n",
      "Steps:  85%|▊| 12800/15000 [1:21:46<06:32,  5.61it/s, lr=8.92e-6, step_loss=0.0907/18/2023 20:25:08 - INFO - __main__ - train loss is 13.550953298108652\n",
      "Steps:  85%|▊| 12801/15000 [1:21:46<06:31,  5.61it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:08 - INFO - __main__ - train loss is 13.89534482290037\n",
      "Steps:  85%|▊| 12802/15000 [1:21:46<06:31,  5.61it/s, lr=8.92e-6, step_loss=0.3407/18/2023 20:25:09 - INFO - __main__ - train loss is 13.899465650552884\n",
      "Steps:  85%|▊| 12803/15000 [1:21:46<06:32,  5.60it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:09 - INFO - __main__ - train loss is 13.912963275099173\n",
      "Steps:  85%|▊| 12804/15000 [1:21:47<08:59,  4.07it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:10 - INFO - __main__ - Per validation step average loss is 0.11126990616321564\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Cumulative validation average loss is 0.11126990616321564\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Per validation step average loss is 0.011628605425357819\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Cumulative validation average loss is 0.12289851158857346\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Per validation step average loss is 0.01719658449292183\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Cumulative validation average loss is 0.14009509608149529\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Per validation step average loss is 0.0028227795846760273\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Cumulative validation average loss is 0.1429178756661713\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Per validation step average loss is 0.2707333564758301\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Cumulative validation average loss is 0.4136512321420014\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Per validation step average loss is 0.012299209833145142\n",
      "07/18/2023 20:25:10 - INFO - __main__ - Cumulative validation average loss is 0.42595044197514653\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Per validation step average loss is 0.003757780184969306\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Cumulative validation average loss is 0.42970822216011584\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Per validation step average loss is 0.011545399203896523\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Cumulative validation average loss is 0.44125362136401236\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Per validation step average loss is 0.023528315126895905\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Cumulative validation average loss is 0.46478193649090827\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Per validation step average loss is 0.18412484228610992\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Cumulative validation average loss is 0.6489067787770182\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Per validation step average loss is 0.06919923424720764\n",
      "07/18/2023 20:25:11 - INFO - __main__ - Cumulative validation average loss is 0.7181060130242258\n",
      "07/18/2023 20:25:12 - INFO - __main__ - Per validation step average loss is 0.03362468630075455\n",
      "07/18/2023 20:25:12 - INFO - __main__ - Cumulative validation average loss is 0.7517306993249804\n",
      "07/18/2023 20:25:12 - INFO - __main__ - Average validation loss for Epoch 131 is 0.06264422494374837\n",
      "07/18/2023 20:25:12 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:25:24 - INFO - __main__ - Starting epoch 132\n",
      "07/18/2023 20:25:25 - INFO - __main__ - train loss is 0.4864504933357239\n",
      "Steps:  85%|▊| 12805/15000 [1:22:03<2:59:18,  4.90s/it, lr=8.92e-6, step_loss=0.07/18/2023 20:25:25 - INFO - __main__ - train loss is 1.0407828092575073\n",
      "Steps:  85%|▊| 12806/15000 [1:22:03<2:07:25,  3.48s/it, lr=8.92e-6, step_loss=0.07/18/2023 20:25:25 - INFO - __main__ - train loss is 1.278663694858551\n",
      "Steps:  85%|▊| 12807/15000 [1:22:03<1:31:06,  2.49s/it, lr=8.92e-6, step_loss=0.07/18/2023 20:25:25 - INFO - __main__ - train loss is 1.3690488710999489\n",
      "Steps:  85%|▊| 12808/15000 [1:22:03<1:05:47,  1.80s/it, lr=8.92e-6, step_loss=0.07/18/2023 20:25:25 - INFO - __main__ - train loss is 1.5157847180962563\n",
      "Steps:  85%|▊| 12809/15000 [1:22:03<47:58,  1.31s/it, lr=8.92e-6, step_loss=0.1407/18/2023 20:25:26 - INFO - __main__ - train loss is 1.5185988522134721\n",
      "Steps:  85%|▊| 12810/15000 [1:22:04<35:30,  1.03it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:26 - INFO - __main__ - train loss is 1.5922459340654314\n",
      "Steps:  85%|▊| 12811/15000 [1:22:04<26:48,  1.36it/s, lr=8.92e-6, step_loss=0.0707/18/2023 20:25:26 - INFO - __main__ - train loss is 1.5956575274467468\n",
      "Steps:  85%|▊| 12812/15000 [1:22:04<20:42,  1.76it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:26 - INFO - __main__ - train loss is 1.9220725893974304\n",
      "Steps:  85%|▊| 12813/15000 [1:22:04<16:25,  2.22it/s, lr=8.92e-6, step_loss=0.3207/18/2023 20:25:26 - INFO - __main__ - train loss is 2.068815380334854\n",
      "Steps:  85%|▊| 12814/15000 [1:22:04<13:25,  2.71it/s, lr=8.92e-6, step_loss=0.1407/18/2023 20:25:27 - INFO - __main__ - train loss is 2.0789543576538563\n",
      "Steps:  85%|▊| 12815/15000 [1:22:04<11:20,  3.21it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:27 - INFO - __main__ - train loss is 2.223720569163561\n",
      "Steps:  85%|▊| 12816/15000 [1:22:05<09:52,  3.69it/s, lr=8.92e-6, step_loss=0.1407/18/2023 20:25:27 - INFO - __main__ - train loss is 2.2767081409692764\n",
      "Steps:  85%|▊| 12817/15000 [1:22:05<08:51,  4.11it/s, lr=8.92e-6, step_loss=0.0507/18/2023 20:25:27 - INFO - __main__ - train loss is 2.514402002096176\n",
      "Steps:  85%|▊| 12818/15000 [1:22:05<08:09,  4.46it/s, lr=8.92e-6, step_loss=0.2307/18/2023 20:25:27 - INFO - __main__ - train loss is 2.614148296415806\n",
      "Steps:  85%|▊| 12819/15000 [1:22:05<07:42,  4.71it/s, lr=8.92e-6, step_loss=0.0907/18/2023 20:25:27 - INFO - __main__ - train loss is 2.623935862444341\n",
      "Steps:  85%|▊| 12820/15000 [1:22:05<07:26,  4.88it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:28 - INFO - __main__ - train loss is 2.6267451329622418\n",
      "Steps:  85%|▊| 12821/15000 [1:22:06<07:09,  5.08it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:28 - INFO - __main__ - train loss is 2.6430319047067314\n",
      "Steps:  85%|▊| 12822/15000 [1:22:06<06:56,  5.23it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:28 - INFO - __main__ - train loss is 2.733676234493032\n",
      "Steps:  85%|▊| 12823/15000 [1:22:06<06:47,  5.34it/s, lr=8.92e-6, step_loss=0.0907/18/2023 20:25:28 - INFO - __main__ - train loss is 3.076931575546041\n",
      "Steps:  85%|▊| 12824/15000 [1:22:06<06:41,  5.42it/s, lr=8.92e-6, step_loss=0.3407/18/2023 20:25:28 - INFO - __main__ - train loss is 3.1024823079351336\n",
      "Steps:  86%|▊| 12825/15000 [1:22:06<06:41,  5.42it/s, lr=8.92e-6, step_loss=0.0207/18/2023 20:25:29 - INFO - __main__ - train loss is 3.111320551717654\n",
      "Steps:  86%|▊| 12826/15000 [1:22:06<06:38,  5.45it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:29 - INFO - __main__ - train loss is 3.115868314867839\n",
      "Steps:  86%|▊| 12827/15000 [1:22:07<06:35,  5.50it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:29 - INFO - __main__ - train loss is 3.7267433253582567\n",
      "Steps:  86%|▊| 12828/15000 [1:22:07<06:33,  5.53it/s, lr=8.92e-6, step_loss=0.6107/18/2023 20:25:29 - INFO - __main__ - train loss is 3.7405492605175823\n",
      "Steps:  86%|▊| 12829/15000 [1:22:07<06:31,  5.55it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:29 - INFO - __main__ - train loss is 3.7559977814089507\n",
      "Steps:  86%|▊| 12830/15000 [1:22:07<06:30,  5.55it/s, lr=8.92e-6, step_loss=0.0107/18/2023 20:25:29 - INFO - __main__ - train loss is 4.130800430430099\n",
      "Steps:  86%|▊| 12831/15000 [1:22:07<06:29,  5.57it/s, lr=8.92e-6, step_loss=0.3707/18/2023 20:25:30 - INFO - __main__ - train loss is 4.244122278643772\n",
      "Steps:  86%|▊| 12832/15000 [1:22:08<06:29,  5.57it/s, lr=8.92e-6, step_loss=0.1107/18/2023 20:25:30 - INFO - __main__ - train loss is 4.6289408325683326\n",
      "Steps:  86%|▊| 12833/15000 [1:22:08<06:30,  5.55it/s, lr=8.92e-6, step_loss=0.3807/18/2023 20:25:30 - INFO - __main__ - train loss is 4.874181044055149\n",
      "Steps:  86%|▊| 12834/15000 [1:22:08<06:29,  5.57it/s, lr=8.92e-6, step_loss=0.2407/18/2023 20:25:30 - INFO - __main__ - train loss is 5.051557970000431\n",
      "Steps:  86%|▊| 12835/15000 [1:22:08<06:30,  5.54it/s, lr=8.92e-6, step_loss=0.1707/18/2023 20:25:30 - INFO - __main__ - train loss is 5.059067725902423\n",
      "Steps:  86%|▊| 12836/15000 [1:22:08<06:32,  5.51it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:31 - INFO - __main__ - train loss is 5.142786785727367\n",
      "Steps:  86%|▊| 12837/15000 [1:22:08<06:35,  5.46it/s, lr=8.92e-6, step_loss=0.0807/18/2023 20:25:31 - INFO - __main__ - train loss is 5.145152457756922\n",
      "Steps:  86%|▊| 12838/15000 [1:22:09<06:36,  5.45it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:31 - INFO - __main__ - train loss is 5.36978552560322\n",
      "Steps:  86%|▊| 12839/15000 [1:22:09<06:33,  5.49it/s, lr=8.92e-6, step_loss=0.2207/18/2023 20:25:31 - INFO - __main__ - train loss is 5.372164011001587\n",
      "Steps:  86%|▊| 12840/15000 [1:22:09<06:31,  5.52it/s, lr=8.92e-6, step_loss=0.0007/18/2023 20:25:31 - INFO - __main__ - train loss is 5.447831757366657\n",
      "Steps:  86%|▊| 12841/15000 [1:22:09<06:29,  5.54it/s, lr=8.91e-6, step_loss=0.0707/18/2023 20:25:31 - INFO - __main__ - train loss is 6.032356388866901\n",
      "Steps:  86%|▊| 12842/15000 [1:22:09<06:28,  5.55it/s, lr=8.91e-6, step_loss=0.5807/18/2023 20:25:32 - INFO - __main__ - train loss is 6.464306779205799\n",
      "Steps:  86%|▊| 12843/15000 [1:22:09<06:27,  5.56it/s, lr=8.91e-6, step_loss=0.4307/18/2023 20:25:32 - INFO - __main__ - train loss is 6.62822438031435\n",
      "Steps:  86%|▊| 12844/15000 [1:22:10<06:26,  5.58it/s, lr=8.91e-6, step_loss=0.1607/18/2023 20:25:32 - INFO - __main__ - train loss is 6.696680538356304\n",
      "Steps:  86%|▊| 12845/15000 [1:22:10<06:25,  5.58it/s, lr=8.91e-6, step_loss=0.0607/18/2023 20:25:32 - INFO - __main__ - train loss is 6.698558916337788\n",
      "Steps:  86%|▊| 12846/15000 [1:22:10<06:28,  5.54it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:32 - INFO - __main__ - train loss is 6.938377027399838\n",
      "Steps:  86%|▊| 12847/15000 [1:22:10<06:27,  5.56it/s, lr=8.91e-6, step_loss=0.2407/18/2023 20:25:33 - INFO - __main__ - train loss is 6.9517810409888625\n",
      "Steps:  86%|▊| 12848/15000 [1:22:10<06:27,  5.56it/s, lr=8.91e-6, step_loss=0.0107/18/2023 20:25:33 - INFO - __main__ - train loss is 7.21944139059633\n",
      "Steps:  86%|▊| 12849/15000 [1:22:11<06:29,  5.52it/s, lr=8.91e-6, step_loss=0.2607/18/2023 20:25:33 - INFO - __main__ - train loss is 7.56508809980005\n",
      "Steps:  86%|▊| 12850/15000 [1:22:11<06:31,  5.50it/s, lr=8.91e-6, step_loss=0.3407/18/2023 20:25:33 - INFO - __main__ - train loss is 7.714006788097322\n",
      "Steps:  86%|▊| 12851/15000 [1:22:11<06:32,  5.48it/s, lr=8.91e-6, step_loss=0.1407/18/2023 20:25:33 - INFO - __main__ - train loss is 7.785400494001806\n",
      "Steps:  86%|▊| 12852/15000 [1:22:11<06:29,  5.52it/s, lr=8.91e-6, step_loss=0.0707/18/2023 20:25:33 - INFO - __main__ - train loss is 7.816896396689117\n",
      "Steps:  86%|▊| 12853/15000 [1:22:11<06:27,  5.55it/s, lr=8.91e-6, step_loss=0.0307/18/2023 20:25:34 - INFO - __main__ - train loss is 7.82316098222509\n",
      "Steps:  86%|▊| 12854/15000 [1:22:11<06:25,  5.56it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:34 - INFO - __main__ - train loss is 8.45802483567968\n",
      "Steps:  86%|▊| 12855/15000 [1:22:12<06:24,  5.57it/s, lr=8.91e-6, step_loss=0.6307/18/2023 20:25:34 - INFO - __main__ - train loss is 8.65574104199186\n",
      "Steps:  86%|▊| 12856/15000 [1:22:12<06:24,  5.58it/s, lr=8.91e-6, step_loss=0.1907/18/2023 20:25:34 - INFO - __main__ - train loss is 8.88453138479963\n",
      "Steps:  86%|▊| 12857/15000 [1:22:12<06:23,  5.59it/s, lr=8.91e-6, step_loss=0.2207/18/2023 20:25:34 - INFO - __main__ - train loss is 8.90794829512015\n",
      "Steps:  86%|▊| 12858/15000 [1:22:12<06:26,  5.54it/s, lr=8.91e-6, step_loss=0.0207/18/2023 20:25:35 - INFO - __main__ - train loss is 8.97454814100638\n",
      "Steps:  86%|▊| 12859/15000 [1:22:12<07:13,  4.94it/s, lr=8.91e-6, step_loss=0.0607/18/2023 20:25:35 - INFO - __main__ - train loss is 9.150148371700197\n",
      "Steps:  86%|▊| 12860/15000 [1:22:13<07:11,  4.96it/s, lr=8.91e-6, step_loss=0.1707/18/2023 20:25:35 - INFO - __main__ - train loss is 9.209217990282923\n",
      "Steps:  86%|▊| 12861/15000 [1:22:13<07:29,  4.76it/s, lr=8.91e-6, step_loss=0.0507/18/2023 20:25:35 - INFO - __main__ - train loss is 9.456037605646998\n",
      "Steps:  86%|▊| 12862/15000 [1:22:13<07:08,  4.99it/s, lr=8.91e-6, step_loss=0.2407/18/2023 20:25:35 - INFO - __main__ - train loss is 9.461169892922044\n",
      "Steps:  86%|▊| 12863/15000 [1:22:13<06:54,  5.16it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:36 - INFO - __main__ - train loss is 9.469403812661767\n",
      "Steps:  86%|▊| 12864/15000 [1:22:13<06:44,  5.28it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:36 - INFO - __main__ - train loss is 9.485544515773654\n",
      "Steps:  86%|▊| 12865/15000 [1:22:14<06:38,  5.36it/s, lr=8.91e-6, step_loss=0.0107/18/2023 20:25:36 - INFO - __main__ - train loss is 9.77289135567844\n",
      "Steps:  86%|▊| 12866/15000 [1:22:14<06:33,  5.43it/s, lr=8.91e-6, step_loss=0.2807/18/2023 20:25:36 - INFO - __main__ - train loss is 9.774686948163435\n",
      "Steps:  86%|▊| 12867/15000 [1:22:14<06:29,  5.48it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:36 - INFO - __main__ - train loss is 9.932685450417921\n",
      "Steps:  86%|▊| 12868/15000 [1:22:14<06:26,  5.52it/s, lr=8.91e-6, step_loss=0.1507/18/2023 20:25:36 - INFO - __main__ - train loss is 10.30732496152632\n",
      "Steps:  86%|▊| 12869/15000 [1:22:14<06:24,  5.54it/s, lr=8.91e-6, step_loss=0.3707/18/2023 20:25:37 - INFO - __main__ - train loss is 10.313348027644679\n",
      "Steps:  86%|▊| 12870/15000 [1:22:14<06:23,  5.56it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:37 - INFO - __main__ - train loss is 10.383288549957797\n",
      "Steps:  86%|▊| 12871/15000 [1:22:15<06:22,  5.57it/s, lr=8.91e-6, step_loss=0.0607/18/2023 20:25:37 - INFO - __main__ - train loss is 10.395079307025298\n",
      "Steps:  86%|▊| 12872/15000 [1:22:15<06:21,  5.58it/s, lr=8.91e-6, step_loss=0.0107/18/2023 20:25:37 - INFO - __main__ - train loss is 10.59936249977909\n",
      "Steps:  86%|▊| 12873/15000 [1:22:15<06:21,  5.58it/s, lr=8.91e-6, step_loss=0.2007/18/2023 20:25:37 - INFO - __main__ - train loss is 10.604450461221859\n",
      "Steps:  86%|▊| 12874/15000 [1:22:15<06:21,  5.57it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:38 - INFO - __main__ - train loss is 10.99248379166238\n",
      "Steps:  86%|▊| 12875/15000 [1:22:15<06:20,  5.58it/s, lr=8.91e-6, step_loss=0.3807/18/2023 20:25:38 - INFO - __main__ - train loss is 10.994315872434527\n",
      "Steps:  86%|▊| 12876/15000 [1:22:16<06:20,  5.58it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:38 - INFO - __main__ - train loss is 11.218939105514437\n",
      "Steps:  86%|▊| 12877/15000 [1:22:16<06:20,  5.58it/s, lr=8.91e-6, step_loss=0.2207/18/2023 20:25:38 - INFO - __main__ - train loss is 11.226597553584725\n",
      "Steps:  86%|▊| 12878/15000 [1:22:16<06:19,  5.59it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:38 - INFO - __main__ - train loss is 11.280537317041308\n",
      "Steps:  86%|▊| 12879/15000 [1:22:16<06:20,  5.58it/s, lr=8.91e-6, step_loss=0.0507/18/2023 20:25:38 - INFO - __main__ - train loss is 11.46579227829352\n",
      "Steps:  86%|▊| 12880/15000 [1:22:16<06:19,  5.59it/s, lr=8.91e-6, step_loss=0.1807/18/2023 20:25:39 - INFO - __main__ - train loss is 11.546945171896368\n",
      "Steps:  86%|▊| 12881/15000 [1:22:16<06:22,  5.54it/s, lr=8.91e-6, step_loss=0.0807/18/2023 20:25:39 - INFO - __main__ - train loss is 11.57198977144435\n",
      "Steps:  86%|▊| 12882/15000 [1:22:17<06:22,  5.53it/s, lr=8.91e-6, step_loss=0.0207/18/2023 20:25:39 - INFO - __main__ - train loss is 11.768108409363776\n",
      "Steps:  86%|▊| 12883/15000 [1:22:17<06:25,  5.49it/s, lr=8.91e-6, step_loss=0.1907/18/2023 20:25:39 - INFO - __main__ - train loss is 11.902239274699241\n",
      "Steps:  86%|▊| 12884/15000 [1:22:17<06:27,  5.47it/s, lr=8.91e-6, step_loss=0.1307/18/2023 20:25:39 - INFO - __main__ - train loss is 11.9099792689085\n",
      "Steps:  86%|▊| 12885/15000 [1:22:17<06:27,  5.46it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:40 - INFO - __main__ - train loss is 12.280256643891335\n",
      "Steps:  86%|▊| 12886/15000 [1:22:17<06:27,  5.46it/s, lr=8.91e-6, step_loss=0.3707/18/2023 20:25:40 - INFO - __main__ - train loss is 12.293698972091079\n",
      "Steps:  86%|▊| 12887/15000 [1:22:18<06:23,  5.50it/s, lr=8.91e-6, step_loss=0.0107/18/2023 20:25:40 - INFO - __main__ - train loss is 12.298710085451603\n",
      "Steps:  86%|▊| 12888/15000 [1:22:18<06:25,  5.48it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:40 - INFO - __main__ - train loss is 12.32016247138381\n",
      "Steps:  86%|▊| 12889/15000 [1:22:18<06:25,  5.47it/s, lr=8.91e-6, step_loss=0.0207/18/2023 20:25:40 - INFO - __main__ - train loss is 12.328380507417023\n",
      "Steps:  86%|▊| 12890/15000 [1:22:18<06:23,  5.50it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:40 - INFO - __main__ - train loss is 12.400474389083683\n",
      "Steps:  86%|▊| 12891/15000 [1:22:18<06:23,  5.49it/s, lr=8.91e-6, step_loss=0.0707/18/2023 20:25:41 - INFO - __main__ - train loss is 12.402686843648553\n",
      "Steps:  86%|▊| 12892/15000 [1:22:18<06:23,  5.50it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:41 - INFO - __main__ - train loss is 12.448477005586028\n",
      "Steps:  86%|▊| 12893/15000 [1:22:19<06:21,  5.53it/s, lr=8.91e-6, step_loss=0.0407/18/2023 20:25:41 - INFO - __main__ - train loss is 12.482424488291144\n",
      "Steps:  86%|▊| 12894/15000 [1:22:19<06:19,  5.55it/s, lr=8.91e-6, step_loss=0.0307/18/2023 20:25:41 - INFO - __main__ - train loss is 12.621146013960242\n",
      "Steps:  86%|▊| 12895/15000 [1:22:19<06:18,  5.57it/s, lr=8.91e-6, step_loss=0.1307/18/2023 20:25:41 - INFO - __main__ - train loss is 13.111022224649787\n",
      "Steps:  86%|▊| 12896/15000 [1:22:19<06:16,  5.58it/s, lr=8.91e-6, step_loss=0.4907/18/2023 20:25:41 - INFO - __main__ - train loss is 13.204374914988875\n",
      "Steps:  86%|▊| 12897/15000 [1:22:19<06:16,  5.59it/s, lr=8.91e-6, step_loss=0.0907/18/2023 20:25:42 - INFO - __main__ - train loss is 13.225590301677585\n",
      "Steps:  86%|▊| 12898/15000 [1:22:20<06:20,  5.53it/s, lr=8.91e-6, step_loss=0.0207/18/2023 20:25:42 - INFO - __main__ - train loss is 13.245257379487157\n",
      "Steps:  86%|▊| 12899/15000 [1:22:20<06:24,  5.47it/s, lr=8.91e-6, step_loss=0.0107/18/2023 20:25:42 - INFO - __main__ - train loss is 13.250093736685812\n",
      "Steps:  86%|▊| 12900/15000 [1:22:20<06:27,  5.43it/s, lr=8.91e-6, step_loss=0.0007/18/2023 20:25:42 - INFO - __main__ - train loss is 13.294336029328406\n",
      "Steps:  86%|▊| 12901/15000 [1:22:20<08:50,  3.96it/s, lr=8.91e-6, step_loss=0.0407/18/2023 20:25:43 - INFO - __main__ - Per validation step average loss is 0.0024540526792407036\n",
      "07/18/2023 20:25:43 - INFO - __main__ - Cumulative validation average loss is 0.0024540526792407036\n",
      "07/18/2023 20:25:43 - INFO - __main__ - Per validation step average loss is 0.0035839229822158813\n",
      "07/18/2023 20:25:43 - INFO - __main__ - Cumulative validation average loss is 0.006037975661456585\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Per validation step average loss is 0.07212049514055252\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Cumulative validation average loss is 0.0781584708020091\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Per validation step average loss is 0.04571237415075302\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Cumulative validation average loss is 0.12387084495276213\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Per validation step average loss is 0.0032468545250594616\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Cumulative validation average loss is 0.1271176994778216\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Per validation step average loss is 0.15253789722919464\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Cumulative validation average loss is 0.27965559670701623\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Per validation step average loss is 0.007466117385774851\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Cumulative validation average loss is 0.2871217140927911\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Per validation step average loss is 0.23076164722442627\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Cumulative validation average loss is 0.5178833613172174\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Per validation step average loss is 0.004709518514573574\n",
      "07/18/2023 20:25:44 - INFO - __main__ - Cumulative validation average loss is 0.5225928798317909\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Per validation step average loss is 0.43049490451812744\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Cumulative validation average loss is 0.9530877843499184\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Per validation step average loss is 0.008522311225533485\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Cumulative validation average loss is 0.9616100955754519\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Per validation step average loss is 0.39616698026657104\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Cumulative validation average loss is 1.357777075842023\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Average validation loss for Epoch 132 is 0.11314808965350191\n",
      "07/18/2023 20:25:45 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:25:58 - INFO - __main__ - Starting epoch 133\n",
      "07/18/2023 20:25:59 - INFO - __main__ - train loss is 0.07970848679542542\n",
      "Steps:  86%|▊| 12902/15000 [1:22:37<2:55:44,  5.03s/it, lr=8.9e-6, step_loss=0.007/18/2023 20:25:59 - INFO - __main__ - train loss is 0.10222603194415569\n",
      "Steps:  86%|▊| 12903/15000 [1:22:37<2:04:54,  3.57s/it, lr=8.9e-6, step_loss=0.007/18/2023 20:25:59 - INFO - __main__ - train loss is 0.44568864814937115\n",
      "Steps:  86%|▊| 12904/15000 [1:22:37<1:29:19,  2.56s/it, lr=8.9e-6, step_loss=0.307/18/2023 20:25:59 - INFO - __main__ - train loss is 1.0280619096010923\n",
      "Steps:  86%|▊| 12905/15000 [1:22:37<1:04:24,  1.84s/it, lr=8.9e-6, step_loss=0.507/18/2023 20:25:59 - INFO - __main__ - train loss is 1.1373027544468641\n",
      "Steps:  86%|▊| 12906/15000 [1:22:37<47:01,  1.35s/it, lr=8.9e-6, step_loss=0.10907/18/2023 20:26:00 - INFO - __main__ - train loss is 1.1392861269414425\n",
      "Steps:  86%|▊| 12907/15000 [1:22:37<34:51,  1.00it/s, lr=8.9e-6, step_loss=0.00107/18/2023 20:26:00 - INFO - __main__ - train loss is 1.1484932424500585\n",
      "Steps:  86%|▊| 12908/15000 [1:22:38<26:16,  1.33it/s, lr=8.9e-6, step_loss=0.00907/18/2023 20:26:00 - INFO - __main__ - train loss is 1.4443678380921483\n",
      "Steps:  86%|▊| 12909/15000 [1:22:38<20:14,  1.72it/s, lr=8.9e-6, step_loss=0.29607/18/2023 20:26:00 - INFO - __main__ - train loss is 1.4495882950723171\n",
      "Steps:  86%|▊| 12910/15000 [1:22:38<16:01,  2.17it/s, lr=8.9e-6, step_loss=0.00507/18/2023 20:26:00 - INFO - __main__ - train loss is 1.869445826858282\n",
      "Steps:  86%|▊| 12911/15000 [1:22:38<13:04,  2.66it/s, lr=8.9e-6, step_loss=0.42]07/18/2023 20:26:00 - INFO - __main__ - train loss is 1.8768630037084222\n",
      "Steps:  86%|▊| 12912/15000 [1:22:38<11:04,  3.14it/s, lr=8.9e-6, step_loss=0.00707/18/2023 20:26:01 - INFO - __main__ - train loss is 1.9555434295907617\n",
      "Steps:  86%|▊| 12913/15000 [1:22:39<09:37,  3.62it/s, lr=8.9e-6, step_loss=0.07807/18/2023 20:26:01 - INFO - __main__ - train loss is 2.2136231968179345\n",
      "Steps:  86%|▊| 12914/15000 [1:22:39<08:35,  4.04it/s, lr=8.9e-6, step_loss=0.25807/18/2023 20:26:01 - INFO - __main__ - train loss is 2.234894805587828\n",
      "Steps:  86%|▊| 12915/15000 [1:22:39<07:55,  4.38it/s, lr=8.9e-6, step_loss=0.02107/18/2023 20:26:01 - INFO - __main__ - train loss is 2.2878514723852277\n",
      "Steps:  86%|▊| 12916/15000 [1:22:39<07:24,  4.69it/s, lr=8.9e-6, step_loss=0.05307/18/2023 20:26:01 - INFO - __main__ - train loss is 2.3412311458960176\n",
      "Steps:  86%|▊| 12917/15000 [1:22:39<07:01,  4.94it/s, lr=8.9e-6, step_loss=0.05307/18/2023 20:26:02 - INFO - __main__ - train loss is 2.657825925387442\n",
      "Steps:  86%|▊| 12918/15000 [1:22:39<06:48,  5.10it/s, lr=8.9e-6, step_loss=0.31707/18/2023 20:26:02 - INFO - __main__ - train loss is 2.662097948603332\n",
      "Steps:  86%|▊| 12919/15000 [1:22:40<06:37,  5.24it/s, lr=8.9e-6, step_loss=0.00407/18/2023 20:26:02 - INFO - __main__ - train loss is 3.06564639788121\n",
      "Steps:  86%|▊| 12920/15000 [1:22:40<06:29,  5.34it/s, lr=8.9e-6, step_loss=0.40407/18/2023 20:26:02 - INFO - __main__ - train loss is 3.0731051778420806\n",
      "Steps:  86%|▊| 12921/15000 [1:22:40<06:26,  5.38it/s, lr=8.9e-6, step_loss=0.00707/18/2023 20:26:02 - INFO - __main__ - train loss is 3.5682248985394835\n",
      "Steps:  86%|▊| 12922/15000 [1:22:40<06:25,  5.39it/s, lr=8.9e-6, step_loss=0.49507/18/2023 20:26:02 - INFO - __main__ - train loss is 3.5772931780666113\n",
      "Steps:  86%|▊| 12923/15000 [1:22:40<06:23,  5.42it/s, lr=8.9e-6, step_loss=0.00907/18/2023 20:26:03 - INFO - __main__ - train loss is 3.5808135042898357\n",
      "Steps:  86%|▊| 12924/15000 [1:22:41<06:23,  5.42it/s, lr=8.9e-6, step_loss=0.00307/18/2023 20:26:03 - INFO - __main__ - train loss is 3.6601147721521556\n",
      "Steps:  86%|▊| 12925/15000 [1:22:41<06:23,  5.40it/s, lr=8.9e-6, step_loss=0.07907/18/2023 20:26:03 - INFO - __main__ - train loss is 3.666803432162851\n",
      "Steps:  86%|▊| 12926/15000 [1:22:41<06:19,  5.46it/s, lr=8.9e-6, step_loss=0.00607/18/2023 20:26:03 - INFO - __main__ - train loss is 3.7139253220520914\n",
      "Steps:  86%|▊| 12927/15000 [1:22:41<06:16,  5.50it/s, lr=8.9e-6, step_loss=0.04707/18/2023 20:26:03 - INFO - __main__ - train loss is 4.241746386047453\n",
      "Steps:  86%|▊| 12928/15000 [1:22:41<06:15,  5.52it/s, lr=8.9e-6, step_loss=0.52807/18/2023 20:26:04 - INFO - __main__ - train loss is 4.245898671448231\n",
      "Steps:  86%|▊| 12929/15000 [1:22:41<06:13,  5.55it/s, lr=8.9e-6, step_loss=0.00407/18/2023 20:26:04 - INFO - __main__ - train loss is 4.25075319968164\n",
      "Steps:  86%|▊| 12930/15000 [1:22:42<06:12,  5.56it/s, lr=8.9e-6, step_loss=0.00407/18/2023 20:26:04 - INFO - __main__ - train loss is 4.513092374429107\n",
      "Steps:  86%|▊| 12931/15000 [1:22:42<06:11,  5.57it/s, lr=8.9e-6, step_loss=0.26207/18/2023 20:26:04 - INFO - __main__ - train loss is 4.534982422366738\n",
      "Steps:  86%|▊| 12932/15000 [1:22:42<06:11,  5.57it/s, lr=8.9e-6, step_loss=0.02107/18/2023 20:26:04 - INFO - __main__ - train loss is 4.540147489402443\n",
      "Steps:  86%|▊| 12933/15000 [1:22:42<06:10,  5.58it/s, lr=8.9e-6, step_loss=0.00507/18/2023 20:26:04 - INFO - __main__ - train loss is 4.567468030843884\n",
      "Steps:  86%|▊| 12934/15000 [1:22:42<06:13,  5.53it/s, lr=8.9e-6, step_loss=0.02707/18/2023 20:26:05 - INFO - __main__ - train loss is 4.596627587918192\n",
      "Steps:  86%|▊| 12935/15000 [1:22:42<06:13,  5.53it/s, lr=8.9e-6, step_loss=0.02907/18/2023 20:26:05 - INFO - __main__ - train loss is 4.606410542968661\n",
      "Steps:  86%|▊| 12936/15000 [1:22:43<06:11,  5.55it/s, lr=8.9e-6, step_loss=0.00907/18/2023 20:26:05 - INFO - __main__ - train loss is 5.111514011863619\n",
      "Steps:  86%|▊| 12937/15000 [1:22:43<06:10,  5.56it/s, lr=8.9e-6, step_loss=0.50507/18/2023 20:26:05 - INFO - __main__ - train loss is 5.512794027570635\n",
      "Steps:  86%|▊| 12938/15000 [1:22:43<06:09,  5.58it/s, lr=8.9e-6, step_loss=0.40107/18/2023 20:26:05 - INFO - __main__ - train loss is 6.073349485639483\n",
      "Steps:  86%|▊| 12939/15000 [1:22:43<06:09,  5.58it/s, lr=8.9e-6, step_loss=0.56107/18/2023 20:26:05 - INFO - __main__ - train loss is 6.26545629883185\n",
      "Steps:  86%|▊| 12940/15000 [1:22:43<06:12,  5.53it/s, lr=8.9e-6, step_loss=0.19207/18/2023 20:26:06 - INFO - __main__ - train loss is 6.318806397262961\n",
      "Steps:  86%|▊| 12941/15000 [1:22:44<06:10,  5.55it/s, lr=8.9e-6, step_loss=0.05307/18/2023 20:26:06 - INFO - __main__ - train loss is 6.361700239125639\n",
      "Steps:  86%|▊| 12942/15000 [1:22:44<06:09,  5.57it/s, lr=8.9e-6, step_loss=0.04207/18/2023 20:26:06 - INFO - __main__ - train loss is 6.633865448180586\n",
      "Steps:  86%|▊| 12943/15000 [1:22:44<06:11,  5.53it/s, lr=8.9e-6, step_loss=0.27207/18/2023 20:26:06 - INFO - __main__ - train loss is 7.00727746123448\n",
      "Steps:  86%|▊| 12944/15000 [1:22:44<06:10,  5.55it/s, lr=8.9e-6, step_loss=0.37307/18/2023 20:26:06 - INFO - __main__ - train loss is 7.320309730712324\n",
      "Steps:  86%|▊| 12945/15000 [1:22:44<06:12,  5.52it/s, lr=8.9e-6, step_loss=0.31307/18/2023 20:26:07 - INFO - __main__ - train loss is 7.557646396104246\n",
      "Steps:  86%|▊| 12946/15000 [1:22:44<06:11,  5.52it/s, lr=8.9e-6, step_loss=0.23707/18/2023 20:26:07 - INFO - __main__ - train loss is 7.725431235972792\n",
      "Steps:  86%|▊| 12947/15000 [1:22:45<06:13,  5.49it/s, lr=8.9e-6, step_loss=0.16807/18/2023 20:26:07 - INFO - __main__ - train loss is 8.229474040213972\n",
      "Steps:  86%|▊| 12948/15000 [1:22:45<06:11,  5.52it/s, lr=8.9e-6, step_loss=0.50407/18/2023 20:26:07 - INFO - __main__ - train loss is 8.390721323434263\n",
      "[2023-07-18 20:26:07,704] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:  86%|▊| 12949/15000 [1:22:45<06:07,  5.58it/s, lr=8.9e-6, step_loss=0.16107/18/2023 20:26:07 - INFO - __main__ - train loss is 8.393755236640573\n",
      "Steps:  86%|▊| 12950/15000 [1:22:45<06:06,  5.59it/s, lr=8.9e-6, step_loss=0.00307/18/2023 20:26:07 - INFO - __main__ - train loss is 8.480962315574288\n",
      "Steps:  86%|▊| 12951/15000 [1:22:45<06:06,  5.59it/s, lr=8.9e-6, step_loss=0.08707/18/2023 20:26:08 - INFO - __main__ - train loss is 8.482564327307045\n",
      "Steps:  86%|▊| 12952/15000 [1:22:46<06:06,  5.59it/s, lr=8.9e-6, step_loss=0.00107/18/2023 20:26:08 - INFO - __main__ - train loss is 9.019887146539986\n",
      "Steps:  86%|▊| 12953/15000 [1:22:46<06:06,  5.59it/s, lr=8.9e-6, step_loss=0.53707/18/2023 20:26:08 - INFO - __main__ - train loss is 9.198084232397377\n",
      "Steps:  86%|▊| 12954/15000 [1:22:46<06:06,  5.59it/s, lr=8.9e-6, step_loss=0.17807/18/2023 20:26:08 - INFO - __main__ - train loss is 9.311339509673417\n",
      "Steps:  86%|▊| 12955/15000 [1:22:46<06:06,  5.59it/s, lr=8.9e-6, step_loss=0.11307/18/2023 20:26:08 - INFO - __main__ - train loss is 9.319384143687785\n",
      "Steps:  86%|▊| 12956/15000 [1:22:46<06:05,  5.59it/s, lr=8.9e-6, step_loss=0.00807/18/2023 20:26:09 - INFO - __main__ - train loss is 9.494301528669894\n",
      "Steps:  86%|▊| 12957/15000 [1:22:46<06:05,  5.59it/s, lr=8.9e-6, step_loss=0.17507/18/2023 20:26:09 - INFO - __main__ - train loss is 9.517761797644198\n",
      "Steps:  86%|▊| 12958/15000 [1:22:47<06:05,  5.59it/s, lr=8.9e-6, step_loss=0.02307/18/2023 20:26:09 - INFO - __main__ - train loss is 9.535505692474544\n",
      "Steps:  86%|▊| 12959/15000 [1:22:47<06:06,  5.57it/s, lr=8.9e-6, step_loss=0.01707/18/2023 20:26:09 - INFO - __main__ - train loss is 9.656591976992786\n",
      "Steps:  86%|▊| 12960/15000 [1:22:47<06:05,  5.58it/s, lr=8.9e-6, step_loss=0.12107/18/2023 20:26:09 - INFO - __main__ - train loss is 9.738613019697368\n",
      "Steps:  86%|▊| 12961/15000 [1:22:47<06:04,  5.59it/s, lr=8.9e-6, step_loss=0.08207/18/2023 20:26:09 - INFO - __main__ - train loss is 9.923085953108966\n",
      "Steps:  86%|▊| 12962/15000 [1:22:47<06:04,  5.59it/s, lr=8.9e-6, step_loss=0.18407/18/2023 20:26:10 - INFO - __main__ - train loss is 10.881749178282917\n",
      "Steps:  86%|▊| 12963/15000 [1:22:48<06:04,  5.59it/s, lr=8.9e-6, step_loss=0.95907/18/2023 20:26:10 - INFO - __main__ - train loss is 10.91150342207402\n",
      "Steps:  86%|▊| 12964/15000 [1:22:48<06:03,  5.60it/s, lr=8.89e-6, step_loss=0.0207/18/2023 20:26:10 - INFO - __main__ - train loss is 11.25972135644406\n",
      "Steps:  86%|▊| 12965/15000 [1:22:48<06:03,  5.60it/s, lr=8.89e-6, step_loss=0.3407/18/2023 20:26:10 - INFO - __main__ - train loss is 11.61813663225621\n",
      "Steps:  86%|▊| 12966/15000 [1:22:48<06:03,  5.60it/s, lr=8.89e-6, step_loss=0.3507/18/2023 20:26:10 - INFO - __main__ - train loss is 11.883474159054458\n",
      "Steps:  86%|▊| 12967/15000 [1:22:48<06:02,  5.60it/s, lr=8.89e-6, step_loss=0.2607/18/2023 20:26:11 - INFO - __main__ - train loss is 12.005084204487503\n",
      "Steps:  86%|▊| 12968/15000 [1:22:48<06:02,  5.61it/s, lr=8.89e-6, step_loss=0.1207/18/2023 20:26:11 - INFO - __main__ - train loss is 12.025118852965534\n",
      "Steps:  86%|▊| 12969/15000 [1:22:49<06:02,  5.61it/s, lr=8.89e-6, step_loss=0.0207/18/2023 20:26:11 - INFO - __main__ - train loss is 12.21761331986636\n",
      "Steps:  86%|▊| 12970/15000 [1:22:49<06:02,  5.60it/s, lr=8.89e-6, step_loss=0.1907/18/2023 20:26:11 - INFO - __main__ - train loss is 12.44926034938544\n",
      "Steps:  86%|▊| 12971/15000 [1:22:49<06:02,  5.60it/s, lr=8.89e-6, step_loss=0.2307/18/2023 20:26:11 - INFO - __main__ - train loss is 12.505426331423223\n",
      "Steps:  86%|▊| 12972/15000 [1:22:49<06:01,  5.60it/s, lr=8.89e-6, step_loss=0.0507/18/2023 20:26:11 - INFO - __main__ - train loss is 12.568051218055189\n",
      "Steps:  86%|▊| 12973/15000 [1:22:49<06:01,  5.60it/s, lr=8.89e-6, step_loss=0.0607/18/2023 20:26:12 - INFO - __main__ - train loss is 12.590896463952959\n",
      "Steps:  86%|▊| 12974/15000 [1:22:49<06:01,  5.60it/s, lr=8.89e-6, step_loss=0.0207/18/2023 20:26:12 - INFO - __main__ - train loss is 12.881811297498643\n",
      "Steps:  86%|▊| 12975/15000 [1:22:50<06:01,  5.60it/s, lr=8.89e-6, step_loss=0.2907/18/2023 20:26:12 - INFO - __main__ - train loss is 13.039211384020746\n",
      "Steps:  87%|▊| 12976/15000 [1:22:50<06:01,  5.60it/s, lr=8.89e-6, step_loss=0.1507/18/2023 20:26:12 - INFO - __main__ - train loss is 13.050486501306295\n",
      "Steps:  87%|▊| 12977/15000 [1:22:50<06:01,  5.60it/s, lr=8.89e-6, step_loss=0.0107/18/2023 20:26:12 - INFO - __main__ - train loss is 13.098193604499102\n",
      "Steps:  87%|▊| 12978/15000 [1:22:50<06:00,  5.60it/s, lr=8.89e-6, step_loss=0.0407/18/2023 20:26:12 - INFO - __main__ - train loss is 13.118564264848828\n",
      "Steps:  87%|▊| 12979/15000 [1:22:50<06:00,  5.60it/s, lr=8.89e-6, step_loss=0.0207/18/2023 20:26:13 - INFO - __main__ - train loss is 13.125723381526768\n",
      "Steps:  87%|▊| 12980/15000 [1:22:51<06:00,  5.60it/s, lr=8.89e-6, step_loss=0.0007/18/2023 20:26:13 - INFO - __main__ - train loss is 13.285043452866375\n",
      "Steps:  87%|▊| 12981/15000 [1:22:51<06:00,  5.60it/s, lr=8.89e-6, step_loss=0.1507/18/2023 20:26:13 - INFO - __main__ - train loss is 13.302648005075753\n",
      "Steps:  87%|▊| 12982/15000 [1:22:51<06:00,  5.60it/s, lr=8.89e-6, step_loss=0.0107/18/2023 20:26:13 - INFO - __main__ - train loss is 13.317785751074553\n",
      "Steps:  87%|▊| 12983/15000 [1:22:51<05:59,  5.61it/s, lr=8.89e-6, step_loss=0.0107/18/2023 20:26:13 - INFO - __main__ - train loss is 13.45793953165412\n",
      "Steps:  87%|▊| 12984/15000 [1:22:51<05:59,  5.61it/s, lr=8.89e-6, step_loss=0.1407/18/2023 20:26:14 - INFO - __main__ - train loss is 13.495657444000244\n",
      "Steps:  87%|▊| 12985/15000 [1:22:51<05:59,  5.61it/s, lr=8.89e-6, step_loss=0.0307/18/2023 20:26:14 - INFO - __main__ - train loss is 13.695109575986862\n",
      "Steps:  87%|▊| 12986/15000 [1:22:52<05:59,  5.61it/s, lr=8.89e-6, step_loss=0.1907/18/2023 20:26:14 - INFO - __main__ - train loss is 13.986021608114243\n",
      "Steps:  87%|▊| 12987/15000 [1:22:52<05:58,  5.61it/s, lr=8.89e-6, step_loss=0.2907/18/2023 20:26:14 - INFO - __main__ - train loss is 14.652864247560501\n",
      "Steps:  87%|▊| 12988/15000 [1:22:52<05:58,  5.61it/s, lr=8.89e-6, step_loss=0.6607/18/2023 20:26:14 - INFO - __main__ - train loss is 15.08542314171791\n",
      "Steps:  87%|▊| 12989/15000 [1:22:52<05:58,  5.61it/s, lr=8.89e-6, step_loss=0.4307/18/2023 20:26:14 - INFO - __main__ - train loss is 15.101688234135509\n",
      "Steps:  87%|▊| 12990/15000 [1:22:52<05:58,  5.61it/s, lr=8.89e-6, step_loss=0.0107/18/2023 20:26:15 - INFO - __main__ - train loss is 15.105049665318802\n",
      "Steps:  87%|▊| 12991/15000 [1:22:53<05:57,  5.61it/s, lr=8.89e-6, step_loss=0.0007/18/2023 20:26:15 - INFO - __main__ - train loss is 15.376411910401657\n",
      "Steps:  87%|▊| 12992/15000 [1:22:53<05:57,  5.61it/s, lr=8.89e-6, step_loss=0.2707/18/2023 20:26:15 - INFO - __main__ - train loss is 15.632801558123901\n",
      "Steps:  87%|▊| 12993/15000 [1:22:53<05:57,  5.62it/s, lr=8.89e-6, step_loss=0.2507/18/2023 20:26:15 - INFO - __main__ - train loss is 15.63486366532743\n",
      "Steps:  87%|▊| 12994/15000 [1:22:53<05:57,  5.62it/s, lr=8.89e-6, step_loss=0.0007/18/2023 20:26:15 - INFO - __main__ - train loss is 15.9925223197788\n",
      "Steps:  87%|▊| 12995/15000 [1:22:53<05:57,  5.62it/s, lr=8.89e-6, step_loss=0.3507/18/2023 20:26:16 - INFO - __main__ - train loss is 16.0575555767864\n",
      "Steps:  87%|▊| 12996/15000 [1:22:53<05:57,  5.61it/s, lr=8.89e-6, step_loss=0.0607/18/2023 20:26:16 - INFO - __main__ - train loss is 16.140308996662498\n",
      "Steps:  87%|▊| 12997/15000 [1:22:54<05:57,  5.61it/s, lr=8.89e-6, step_loss=0.0807/18/2023 20:26:16 - INFO - __main__ - train loss is 16.74362870119512\n",
      "Steps:  87%|▊| 12998/15000 [1:22:54<08:02,  4.15it/s, lr=8.89e-6, step_loss=0.6007/18/2023 20:26:17 - INFO - __main__ - Per validation step average loss is 0.11287841200828552\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Cumulative validation average loss is 0.11287841200828552\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Per validation step average loss is 0.003050676081329584\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Cumulative validation average loss is 0.1159290880896151\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Per validation step average loss is 0.14563891291618347\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Cumulative validation average loss is 0.2615680010057986\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Per validation step average loss is 0.05614887550473213\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Cumulative validation average loss is 0.3177168765105307\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Per validation step average loss is 0.007269729860126972\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Cumulative validation average loss is 0.3249866063706577\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Per validation step average loss is 0.01624426618218422\n",
      "07/18/2023 20:26:17 - INFO - __main__ - Cumulative validation average loss is 0.3412308725528419\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Per validation step average loss is 0.008593057282269001\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Cumulative validation average loss is 0.3498239298351109\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Per validation step average loss is 0.029858091846108437\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Cumulative validation average loss is 0.37968202168121934\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Per validation step average loss is 0.22619996964931488\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Cumulative validation average loss is 0.6058819913305342\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Per validation step average loss is 0.009828077629208565\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Cumulative validation average loss is 0.6157100689597428\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Per validation step average loss is 0.008777525275945663\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Cumulative validation average loss is 0.6244875942356884\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Per validation step average loss is 0.008361444808542728\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Cumulative validation average loss is 0.6328490390442312\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Average validation loss for Epoch 133 is 0.0527374199203526\n",
      "07/18/2023 20:26:18 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:26:31 - INFO - __main__ - Starting epoch 134\n",
      "07/18/2023 20:26:32 - INFO - __main__ - train loss is 0.16298553347587585\n",
      "Steps:  87%|▊| 12999/15000 [1:23:10<2:42:45,  4.88s/it, lr=8.89e-6, step_loss=0.07/18/2023 20:26:32 - INFO - __main__ - train loss is 0.6718440353870392\n",
      "Steps:  87%|▊| 13000/15000 [1:23:10<1:55:39,  3.47s/it, lr=8.89e-6, step_loss=0.07/18/2023 20:26:32 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-13000\n",
      "07/18/2023 20:26:32 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:26:32,545] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:26:32,549] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:26:32,549] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:26:32,557] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:26:32,557] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-13000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:26:32,578] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-13000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:26:32,579] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-13000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:26:32,579] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:26:32 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-13000/pytorch_model\n",
      "07/18/2023 20:26:32 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-13000/scheduler.bin\n",
      "07/18/2023 20:26:32 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-13000/random_states_0.pkl\n",
      "07/18/2023 20:26:32 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-13000\n",
      "Steps:  87%|▊| 13000/15000 [1:23:10<1:55:39,  3.47s/it, lr=8.89e-6, step_loss=0.07/18/2023 20:26:32 - INFO - __main__ - train loss is 0.7796823233366013\n",
      "Steps:  87%|▊| 13001/15000 [1:23:10<1:23:06,  2.49s/it, lr=8.89e-6, step_loss=0.07/18/2023 20:26:32 - INFO - __main__ - train loss is 0.9731332957744598\n",
      "Steps:  87%|▊| 13002/15000 [1:23:10<59:57,  1.80s/it, lr=8.89e-6, step_loss=0.1907/18/2023 20:26:33 - INFO - __main__ - train loss is 0.9799701850861311\n",
      "Steps:  87%|▊| 13003/15000 [1:23:10<43:43,  1.31s/it, lr=8.89e-6, step_loss=0.0007/18/2023 20:26:33 - INFO - __main__ - train loss is 0.9994188528507948\n",
      "Steps:  87%|▊| 13004/15000 [1:23:11<32:21,  1.03it/s, lr=8.89e-6, step_loss=0.0107/18/2023 20:26:33 - INFO - __main__ - train loss is 1.0715545173734426\n",
      "Steps:  87%|▊| 13005/15000 [1:23:11<24:26,  1.36it/s, lr=8.89e-6, step_loss=0.0707/18/2023 20:26:33 - INFO - __main__ - train loss is 1.1562995221465826\n",
      "Steps:  87%|▊| 13006/15000 [1:23:11<18:52,  1.76it/s, lr=8.89e-6, step_loss=0.0807/18/2023 20:26:33 - INFO - __main__ - train loss is 1.179950326681137\n",
      "Steps:  87%|▊| 13007/15000 [1:23:11<14:58,  2.22it/s, lr=8.89e-6, step_loss=0.0207/18/2023 20:26:33 - INFO - __main__ - train loss is 1.1819211887195706\n",
      "Steps:  87%|▊| 13008/15000 [1:23:11<12:15,  2.71it/s, lr=8.89e-6, step_loss=0.0007/18/2023 20:26:34 - INFO - __main__ - train loss is 1.2620810540392995\n",
      "Steps:  87%|▊| 13009/15000 [1:23:11<10:20,  3.21it/s, lr=8.89e-6, step_loss=0.0807/18/2023 20:26:34 - INFO - __main__ - train loss is 1.520619479008019\n",
      "Steps:  87%|▊| 13010/15000 [1:23:12<09:00,  3.68it/s, lr=8.89e-6, step_loss=0.2507/18/2023 20:26:34 - INFO - __main__ - train loss is 1.5788243906572461\n",
      "Steps:  87%|▊| 13011/15000 [1:23:12<08:04,  4.11it/s, lr=8.89e-6, step_loss=0.0507/18/2023 20:26:34 - INFO - __main__ - train loss is 1.5904684299603105\n",
      "Steps:  87%|▊| 13012/15000 [1:23:12<07:24,  4.47it/s, lr=8.89e-6, step_loss=0.0107/18/2023 20:26:34 - INFO - __main__ - train loss is 1.6320445919409394\n",
      "Steps:  87%|▊| 13013/15000 [1:23:12<06:57,  4.76it/s, lr=8.89e-6, step_loss=0.0407/18/2023 20:26:34 - INFO - __main__ - train loss is 1.6521436618641019\n",
      "Steps:  87%|▊| 13014/15000 [1:23:12<06:38,  4.99it/s, lr=8.89e-6, step_loss=0.0207/18/2023 20:26:35 - INFO - __main__ - train loss is 1.672482413239777\n",
      "Steps:  87%|▊| 13015/15000 [1:23:13<06:24,  5.16it/s, lr=8.89e-6, step_loss=0.0207/18/2023 20:26:35 - INFO - __main__ - train loss is 1.6747143424581736\n",
      "Steps:  87%|▊| 13016/15000 [1:23:13<06:15,  5.29it/s, lr=8.89e-6, step_loss=0.0007/18/2023 20:26:35 - INFO - __main__ - train loss is 1.7914980358909816\n",
      "Steps:  87%|▊| 13017/15000 [1:23:13<06:08,  5.38it/s, lr=8.89e-6, step_loss=0.1107/18/2023 20:26:35 - INFO - __main__ - train loss is 2.0847977108787745\n",
      "Steps:  87%|▊| 13018/15000 [1:23:13<06:04,  5.44it/s, lr=8.89e-6, step_loss=0.2907/18/2023 20:26:35 - INFO - __main__ - train loss is 2.161502108676359\n",
      "Steps:  87%|▊| 13019/15000 [1:23:13<06:00,  5.49it/s, lr=8.89e-6, step_loss=0.0707/18/2023 20:26:36 - INFO - __main__ - train loss is 2.2779309458564967\n",
      "Steps:  87%|▊| 13020/15000 [1:23:13<05:58,  5.52it/s, lr=8.89e-6, step_loss=0.1107/18/2023 20:26:36 - INFO - __main__ - train loss is 2.542986959917471\n",
      "Steps:  87%|▊| 13021/15000 [1:23:14<05:56,  5.54it/s, lr=8.89e-6, step_loss=0.2607/18/2023 20:26:36 - INFO - __main__ - train loss is 2.5981627113651484\n",
      "Steps:  87%|▊| 13022/15000 [1:23:14<05:55,  5.56it/s, lr=8.89e-6, step_loss=0.0507/18/2023 20:26:36 - INFO - __main__ - train loss is 3.4244451529812068\n",
      "Steps:  87%|▊| 13023/15000 [1:23:14<05:54,  5.57it/s, lr=8.89e-6, step_loss=0.8207/18/2023 20:26:36 - INFO - __main__ - train loss is 3.4336982432287186\n",
      "Steps:  87%|▊| 13024/15000 [1:23:14<05:53,  5.59it/s, lr=8.89e-6, step_loss=0.0007/18/2023 20:26:36 - INFO - __main__ - train loss is 3.6027620050590485\n",
      "Steps:  87%|▊| 13025/15000 [1:23:14<05:53,  5.59it/s, lr=8.88e-6, step_loss=0.1607/18/2023 20:26:37 - INFO - __main__ - train loss is 3.6419011156540364\n",
      "Steps:  87%|▊| 13026/15000 [1:23:15<05:56,  5.54it/s, lr=8.88e-6, step_loss=0.0307/18/2023 20:26:37 - INFO - __main__ - train loss is 3.64431559946388\n",
      "Steps:  87%|▊| 13027/15000 [1:23:15<06:01,  5.46it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:37 - INFO - __main__ - train loss is 3.645769282593392\n",
      "Steps:  87%|▊| 13028/15000 [1:23:15<06:04,  5.40it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:37 - INFO - __main__ - train loss is 3.6960462325951084\n",
      "Steps:  87%|▊| 13029/15000 [1:23:15<06:06,  5.38it/s, lr=8.88e-6, step_loss=0.0507/18/2023 20:26:37 - INFO - __main__ - train loss is 3.8262898916145787\n",
      "Steps:  87%|▊| 13030/15000 [1:23:15<06:02,  5.44it/s, lr=8.88e-6, step_loss=0.1307/18/2023 20:26:38 - INFO - __main__ - train loss is 3.8696098135551438\n",
      "Steps:  87%|▊| 13031/15000 [1:23:15<06:01,  5.45it/s, lr=8.88e-6, step_loss=0.0407/18/2023 20:26:38 - INFO - __main__ - train loss is 3.948458525701426\n",
      "Steps:  87%|▊| 13032/15000 [1:23:16<05:59,  5.47it/s, lr=8.88e-6, step_loss=0.0707/18/2023 20:26:38 - INFO - __main__ - train loss is 3.9528797728708014\n",
      "Steps:  87%|▊| 13033/15000 [1:23:16<05:58,  5.48it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:38 - INFO - __main__ - train loss is 4.005141661851667\n",
      "Steps:  87%|▊| 13034/15000 [1:23:16<05:57,  5.50it/s, lr=8.88e-6, step_loss=0.0507/18/2023 20:26:38 - INFO - __main__ - train loss is 4.018759428872727\n",
      "Steps:  87%|▊| 13035/15000 [1:23:16<06:00,  5.45it/s, lr=8.88e-6, step_loss=0.0107/18/2023 20:26:38 - INFO - __main__ - train loss is 4.365789651288651\n",
      "Steps:  87%|▊| 13036/15000 [1:23:16<06:01,  5.43it/s, lr=8.88e-6, step_loss=0.3407/18/2023 20:26:39 - INFO - __main__ - train loss is 4.9048029178520665\n",
      "Steps:  87%|▊| 13037/15000 [1:23:17<06:01,  5.43it/s, lr=8.88e-6, step_loss=0.5307/18/2023 20:26:39 - INFO - __main__ - train loss is 5.0169223541161045\n",
      "Steps:  87%|▊| 13038/15000 [1:23:17<05:57,  5.48it/s, lr=8.88e-6, step_loss=0.1107/18/2023 20:26:39 - INFO - __main__ - train loss is 5.508138059987687\n",
      "Steps:  87%|▊| 13039/15000 [1:23:17<05:55,  5.52it/s, lr=8.88e-6, step_loss=0.4907/18/2023 20:26:39 - INFO - __main__ - train loss is 5.6093971425434574\n",
      "Steps:  87%|▊| 13040/15000 [1:23:17<05:53,  5.54it/s, lr=8.88e-6, step_loss=0.1007/18/2023 20:26:39 - INFO - __main__ - train loss is 5.6157824558904395\n",
      "Steps:  87%|▊| 13041/15000 [1:23:17<05:52,  5.56it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:40 - INFO - __main__ - train loss is 5.795488045900129\n",
      "Steps:  87%|▊| 13042/15000 [1:23:17<05:51,  5.57it/s, lr=8.88e-6, step_loss=0.1807/18/2023 20:26:40 - INFO - __main__ - train loss is 5.975865022628568\n",
      "Steps:  87%|▊| 13043/15000 [1:23:18<05:50,  5.58it/s, lr=8.88e-6, step_loss=0.1807/18/2023 20:26:40 - INFO - __main__ - train loss is 6.180458174436353\n",
      "Steps:  87%|▊| 13044/15000 [1:23:18<05:49,  5.59it/s, lr=8.88e-6, step_loss=0.2007/18/2023 20:26:40 - INFO - __main__ - train loss is 6.212400802760385\n",
      "Steps:  87%|▊| 13045/15000 [1:23:18<05:49,  5.60it/s, lr=8.88e-6, step_loss=0.0307/18/2023 20:26:40 - INFO - __main__ - train loss is 6.243834575056098\n",
      "Steps:  87%|▊| 13046/15000 [1:23:18<05:48,  5.60it/s, lr=8.88e-6, step_loss=0.0307/18/2023 20:26:40 - INFO - __main__ - train loss is 6.4035140027990565\n",
      "Steps:  87%|▊| 13047/15000 [1:23:18<05:48,  5.60it/s, lr=8.88e-6, step_loss=0.1607/18/2023 20:26:41 - INFO - __main__ - train loss is 6.420924955396913\n",
      "Steps:  87%|▊| 13048/15000 [1:23:19<05:48,  5.60it/s, lr=8.88e-6, step_loss=0.0107/18/2023 20:26:41 - INFO - __main__ - train loss is 6.4471199897816405\n",
      "Steps:  87%|▊| 13049/15000 [1:23:19<05:48,  5.60it/s, lr=8.88e-6, step_loss=0.0207/18/2023 20:26:41 - INFO - __main__ - train loss is 6.677816638140939\n",
      "Steps:  87%|▊| 13050/15000 [1:23:19<05:48,  5.60it/s, lr=8.88e-6, step_loss=0.2307/18/2023 20:26:41 - INFO - __main__ - train loss is 6.780397632508539\n",
      "Steps:  87%|▊| 13051/15000 [1:23:19<05:48,  5.60it/s, lr=8.88e-6, step_loss=0.1007/18/2023 20:26:41 - INFO - __main__ - train loss is 6.793776256381534\n",
      "Steps:  87%|▊| 13052/15000 [1:23:19<05:48,  5.60it/s, lr=8.88e-6, step_loss=0.0107/18/2023 20:26:42 - INFO - __main__ - train loss is 6.805727242841385\n",
      "Steps:  87%|▊| 13053/15000 [1:23:19<05:48,  5.59it/s, lr=8.88e-6, step_loss=0.0107/18/2023 20:26:42 - INFO - __main__ - train loss is 6.9950757616898045\n",
      "Steps:  87%|▊| 13054/15000 [1:23:20<05:51,  5.53it/s, lr=8.88e-6, step_loss=0.1807/18/2023 20:26:42 - INFO - __main__ - train loss is 7.0019997785566375\n",
      "Steps:  87%|▊| 13055/15000 [1:23:20<05:55,  5.47it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:42 - INFO - __main__ - train loss is 7.033119276049547\n",
      "Steps:  87%|▊| 13056/15000 [1:23:20<06:00,  5.40it/s, lr=8.88e-6, step_loss=0.0307/18/2023 20:26:42 - INFO - __main__ - train loss is 7.094371113809757\n",
      "Steps:  87%|▊| 13057/15000 [1:23:20<05:59,  5.41it/s, lr=8.88e-6, step_loss=0.0607/18/2023 20:26:42 - INFO - __main__ - train loss is 7.097580036264844\n",
      "Steps:  87%|▊| 13058/15000 [1:23:20<06:02,  5.35it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:43 - INFO - __main__ - train loss is 7.111907662008889\n",
      "Steps:  87%|▊| 13059/15000 [1:23:21<06:04,  5.33it/s, lr=8.88e-6, step_loss=0.0107/18/2023 20:26:43 - INFO - __main__ - train loss is 7.115409519174136\n",
      "Steps:  87%|▊| 13060/15000 [1:23:21<06:02,  5.35it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:43 - INFO - __main__ - train loss is 7.21858869085554\n",
      "Steps:  87%|▊| 13061/15000 [1:23:21<06:07,  5.27it/s, lr=8.88e-6, step_loss=0.1007/18/2023 20:26:43 - INFO - __main__ - train loss is 7.227731466875412\n",
      "Steps:  87%|▊| 13062/15000 [1:23:21<06:10,  5.23it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:43 - INFO - __main__ - train loss is 7.2460175981977955\n",
      "Steps:  87%|▊| 13063/15000 [1:23:21<06:13,  5.19it/s, lr=8.88e-6, step_loss=0.0107/18/2023 20:26:44 - INFO - __main__ - train loss is 7.24802613875363\n",
      "Steps:  87%|▊| 13064/15000 [1:23:22<06:15,  5.16it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:44 - INFO - __main__ - train loss is 7.3163112761685625\n",
      "Steps:  87%|▊| 13065/15000 [1:23:22<06:16,  5.14it/s, lr=8.88e-6, step_loss=0.0607/18/2023 20:26:44 - INFO - __main__ - train loss is 7.681974834413268\n",
      "Steps:  87%|▊| 13066/15000 [1:23:22<06:19,  5.10it/s, lr=8.88e-6, step_loss=0.3607/18/2023 20:26:44 - INFO - __main__ - train loss is 8.109108573407866\n",
      "Steps:  87%|▊| 13067/15000 [1:23:22<06:19,  5.09it/s, lr=8.88e-6, step_loss=0.4207/18/2023 20:26:44 - INFO - __main__ - train loss is 8.113355319597758\n",
      "Steps:  87%|▊| 13068/15000 [1:23:22<06:19,  5.09it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:45 - INFO - __main__ - train loss is 8.571795325377025\n",
      "Steps:  87%|▊| 13069/15000 [1:23:22<06:19,  5.09it/s, lr=8.88e-6, step_loss=0.4507/18/2023 20:26:45 - INFO - __main__ - train loss is 8.57892322272528\n",
      "Steps:  87%|▊| 13070/15000 [1:23:23<06:18,  5.10it/s, lr=8.88e-6, step_loss=0.0007/18/2023 20:26:45 - INFO - __main__ - train loss is 8.830733534996398\n",
      "Steps:  87%|▊| 13071/15000 [1:23:23<06:17,  5.11it/s, lr=8.88e-6, step_loss=0.2507/18/2023 20:26:45 - INFO - __main__ - train loss is 8.845246237819083\n",
      "Steps:  87%|▊| 13072/15000 [1:23:23<06:16,  5.12it/s, lr=8.88e-6, step_loss=0.0107/18/2023 20:26:45 - INFO - __main__ - train loss is 8.938819927279837\n",
      "Steps:  87%|▊| 13073/15000 [1:23:23<06:16,  5.12it/s, lr=8.88e-6, step_loss=0.0907/18/2023 20:26:46 - INFO - __main__ - train loss is 9.062854197924025\n",
      "Steps:  87%|▊| 13074/15000 [1:23:23<06:12,  5.17it/s, lr=8.88e-6, step_loss=0.1207/18/2023 20:26:46 - INFO - __main__ - train loss is 9.172351849381812\n",
      "Steps:  87%|▊| 13075/15000 [1:23:24<06:06,  5.26it/s, lr=8.88e-6, step_loss=0.1007/18/2023 20:26:46 - INFO - __main__ - train loss is 9.228052173857577\n",
      "Steps:  87%|▊| 13076/15000 [1:23:24<06:04,  5.27it/s, lr=8.88e-6, step_loss=0.0507/18/2023 20:26:46 - INFO - __main__ - train loss is 9.271094617550261\n",
      "Steps:  87%|▊| 13077/15000 [1:23:24<06:09,  5.20it/s, lr=8.88e-6, step_loss=0.0407/18/2023 20:26:46 - INFO - __main__ - train loss is 9.33861746371258\n",
      "Steps:  87%|▊| 13078/15000 [1:23:24<06:11,  5.17it/s, lr=8.88e-6, step_loss=0.0607/18/2023 20:26:47 - INFO - __main__ - train loss is 9.361052361433394\n",
      "Steps:  87%|▊| 13079/15000 [1:23:24<06:13,  5.14it/s, lr=8.88e-6, step_loss=0.0207/18/2023 20:26:47 - INFO - __main__ - train loss is 9.587126207654364\n",
      "Steps:  87%|▊| 13080/15000 [1:23:25<06:17,  5.08it/s, lr=8.88e-6, step_loss=0.2207/18/2023 20:26:47 - INFO - __main__ - train loss is 9.694865045254119\n",
      "Steps:  87%|▊| 13081/15000 [1:23:25<06:17,  5.08it/s, lr=8.88e-6, step_loss=0.1007/18/2023 20:26:47 - INFO - __main__ - train loss is 9.807630119030364\n",
      "Steps:  87%|▊| 13082/15000 [1:23:25<06:16,  5.09it/s, lr=8.88e-6, step_loss=0.1107/18/2023 20:26:47 - INFO - __main__ - train loss is 9.942510006134398\n",
      "Steps:  87%|▊| 13083/15000 [1:23:25<06:15,  5.10it/s, lr=8.88e-6, step_loss=0.1307/18/2023 20:26:48 - INFO - __main__ - train loss is 10.321012851898558\n",
      "Steps:  87%|▊| 13084/15000 [1:23:25<06:14,  5.12it/s, lr=8.88e-6, step_loss=0.3707/18/2023 20:26:48 - INFO - __main__ - train loss is 10.36561857641209\n",
      "Steps:  87%|▊| 13085/15000 [1:23:26<06:13,  5.12it/s, lr=8.87e-6, step_loss=0.0407/18/2023 20:26:48 - INFO - __main__ - train loss is 10.427359421853907\n",
      "Steps:  87%|▊| 13086/15000 [1:23:26<06:14,  5.12it/s, lr=8.87e-6, step_loss=0.0607/18/2023 20:26:48 - INFO - __main__ - train loss is 10.42939912120346\n",
      "Steps:  87%|▊| 13087/15000 [1:23:26<06:14,  5.11it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:26:48 - INFO - __main__ - train loss is 10.687032777466811\n",
      "Steps:  87%|▊| 13088/15000 [1:23:26<06:10,  5.17it/s, lr=8.87e-6, step_loss=0.2507/18/2023 20:26:49 - INFO - __main__ - train loss is 10.991692859330215\n",
      "Steps:  87%|▊| 13089/15000 [1:23:26<06:17,  5.06it/s, lr=8.87e-6, step_loss=0.3007/18/2023 20:26:49 - INFO - __main__ - train loss is 11.026099972077645\n",
      "Steps:  87%|▊| 13090/15000 [1:23:27<06:15,  5.09it/s, lr=8.87e-6, step_loss=0.0307/18/2023 20:26:49 - INFO - __main__ - train loss is 11.02925855095964\n",
      "Steps:  87%|▊| 13091/15000 [1:23:27<06:14,  5.10it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:26:49 - INFO - __main__ - train loss is 11.492480041342787\n",
      "Steps:  87%|▊| 13092/15000 [1:23:27<06:13,  5.11it/s, lr=8.87e-6, step_loss=0.4607/18/2023 20:26:49 - INFO - __main__ - train loss is 11.514548580977134\n",
      "Steps:  87%|▊| 13093/15000 [1:23:27<06:11,  5.13it/s, lr=8.87e-6, step_loss=0.0207/18/2023 20:26:49 - INFO - __main__ - train loss is 11.516676238621585\n",
      "Steps:  87%|▊| 13094/15000 [1:23:27<06:12,  5.12it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:26:50 - INFO - __main__ - train loss is 11.521126376348548\n",
      "Steps:  87%|▊| 13095/15000 [1:23:28<08:40,  3.66it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:26:51 - INFO - __main__ - Per validation step average loss is 0.03170548006892204\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Cumulative validation average loss is 0.03170548006892204\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Per validation step average loss is 0.7617756128311157\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Cumulative validation average loss is 0.7934810929000378\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Per validation step average loss is 0.2050982117652893\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Cumulative validation average loss is 0.9985793046653271\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Per validation step average loss is 0.17154952883720398\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Cumulative validation average loss is 1.170128833502531\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Per validation step average loss is 0.0028113066218793392\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Cumulative validation average loss is 1.1729401401244104\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Per validation step average loss is 0.5091950297355652\n",
      "07/18/2023 20:26:51 - INFO - __main__ - Cumulative validation average loss is 1.6821351698599756\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Per validation step average loss is 0.025312652811408043\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Cumulative validation average loss is 1.7074478226713836\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Per validation step average loss is 0.0603308342397213\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Cumulative validation average loss is 1.767778656911105\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Per validation step average loss is 0.1748499870300293\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Cumulative validation average loss is 1.9426286439411342\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Per validation step average loss is 0.0032211311627179384\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Cumulative validation average loss is 1.9458497751038522\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Per validation step average loss is 0.08178242295980453\n",
      "07/18/2023 20:26:52 - INFO - __main__ - Cumulative validation average loss is 2.0276321980636567\n",
      "07/18/2023 20:26:53 - INFO - __main__ - Per validation step average loss is 0.08180665969848633\n",
      "07/18/2023 20:26:53 - INFO - __main__ - Cumulative validation average loss is 2.109438857762143\n",
      "07/18/2023 20:26:53 - INFO - __main__ - Average validation loss for Epoch 134 is 0.1757865714801786\n",
      "07/18/2023 20:26:53 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:27:05 - INFO - __main__ - Starting epoch 135\n",
      "07/18/2023 20:27:06 - INFO - __main__ - train loss is 0.008443672209978104\n",
      "Steps:  87%|▊| 13096/15000 [1:23:44<2:39:10,  5.02s/it, lr=8.87e-6, step_loss=0.07/18/2023 20:27:06 - INFO - __main__ - train loss is 0.03615577518939972\n",
      "Steps:  87%|▊| 13097/15000 [1:23:44<1:53:04,  3.57s/it, lr=8.87e-6, step_loss=0.07/18/2023 20:27:06 - INFO - __main__ - train loss is 0.4671967476606369\n",
      "Steps:  87%|▊| 13098/15000 [1:23:44<1:20:48,  2.55s/it, lr=8.87e-6, step_loss=0.07/18/2023 20:27:07 - INFO - __main__ - train loss is 0.589314304292202\n",
      "Steps:  87%|▊| 13099/15000 [1:23:44<58:14,  1.84s/it, lr=8.87e-6, step_loss=0.1207/18/2023 20:27:07 - INFO - __main__ - train loss is 0.6141909807920456\n",
      "Steps:  87%|▊| 13100/15000 [1:23:45<42:26,  1.34s/it, lr=8.87e-6, step_loss=0.0207/18/2023 20:27:07 - INFO - __main__ - train loss is 1.0975233763456345\n",
      "Steps:  87%|▊| 13101/15000 [1:23:45<31:23,  1.01it/s, lr=8.87e-6, step_loss=0.4807/18/2023 20:27:07 - INFO - __main__ - train loss is 1.179407723248005\n",
      "Steps:  87%|▊| 13102/15000 [1:23:45<23:39,  1.34it/s, lr=8.87e-6, step_loss=0.0807/18/2023 20:27:07 - INFO - __main__ - train loss is 1.3409909829497337\n",
      "Steps:  87%|▊| 13103/15000 [1:23:45<18:14,  1.73it/s, lr=8.87e-6, step_loss=0.1607/18/2023 20:27:07 - INFO - __main__ - train loss is 1.7870389744639397\n",
      "Steps:  87%|▊| 13104/15000 [1:23:45<14:26,  2.19it/s, lr=8.87e-6, step_loss=0.4407/18/2023 20:27:08 - INFO - __main__ - train loss is 1.7997746523469687\n",
      "Steps:  87%|▊| 13105/15000 [1:23:46<11:47,  2.68it/s, lr=8.87e-6, step_loss=0.0107/18/2023 20:27:08 - INFO - __main__ - train loss is 2.1843657549470663\n",
      "Steps:  87%|▊| 13106/15000 [1:23:46<09:55,  3.18it/s, lr=8.87e-6, step_loss=0.3807/18/2023 20:27:08 - INFO - __main__ - train loss is 2.290806455537677\n",
      "Steps:  87%|▊| 13107/15000 [1:23:46<08:37,  3.66it/s, lr=8.87e-6, step_loss=0.1007/18/2023 20:27:08 - INFO - __main__ - train loss is 2.3119951765984297\n",
      "Steps:  87%|▊| 13108/15000 [1:23:46<07:42,  4.09it/s, lr=8.87e-6, step_loss=0.0207/18/2023 20:27:08 - INFO - __main__ - train loss is 2.5157690476626158\n",
      "Steps:  87%|▊| 13109/15000 [1:23:46<07:04,  4.45it/s, lr=8.87e-6, step_loss=0.2007/18/2023 20:27:09 - INFO - __main__ - train loss is 2.5287040900439024\n",
      "Steps:  87%|▊| 13110/15000 [1:23:46<06:37,  4.75it/s, lr=8.87e-6, step_loss=0.0107/18/2023 20:27:09 - INFO - __main__ - train loss is 2.7921708654612303\n",
      "Steps:  87%|▊| 13111/15000 [1:23:47<06:19,  4.98it/s, lr=8.87e-6, step_loss=0.2607/18/2023 20:27:09 - INFO - __main__ - train loss is 3.1613843869417906\n",
      "Steps:  87%|▊| 13112/15000 [1:23:47<06:05,  5.16it/s, lr=8.87e-6, step_loss=0.3607/18/2023 20:27:09 - INFO - __main__ - train loss is 3.7253571581095457\n",
      "Steps:  87%|▊| 13113/15000 [1:23:47<05:56,  5.29it/s, lr=8.87e-6, step_loss=0.5607/18/2023 20:27:09 - INFO - __main__ - train loss is 3.72711355809588\n",
      "Steps:  87%|▊| 13114/15000 [1:23:47<05:54,  5.33it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:09 - INFO - __main__ - train loss is 3.7322709538275376\n",
      "Steps:  87%|▊| 13115/15000 [1:23:47<05:49,  5.39it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:10 - INFO - __main__ - train loss is 4.077870664768852\n",
      "Steps:  87%|▊| 13116/15000 [1:23:47<05:47,  5.42it/s, lr=8.87e-6, step_loss=0.3407/18/2023 20:27:10 - INFO - __main__ - train loss is 4.168849451118149\n",
      "Steps:  87%|▊| 13117/15000 [1:23:48<05:43,  5.47it/s, lr=8.87e-6, step_loss=0.0907/18/2023 20:27:10 - INFO - __main__ - train loss is 4.8265500493580475\n",
      "Steps:  87%|▊| 13118/15000 [1:23:48<05:44,  5.46it/s, lr=8.87e-6, step_loss=0.6507/18/2023 20:27:10 - INFO - __main__ - train loss is 5.3820203967625275\n",
      "Steps:  87%|▊| 13119/15000 [1:23:48<05:47,  5.41it/s, lr=8.87e-6, step_loss=0.5507/18/2023 20:27:10 - INFO - __main__ - train loss is 5.444855076842941\n",
      "Steps:  87%|▊| 13120/15000 [1:23:48<05:44,  5.45it/s, lr=8.87e-6, step_loss=0.0607/18/2023 20:27:11 - INFO - __main__ - train loss is 5.446327541489154\n",
      "Steps:  87%|▊| 13121/15000 [1:23:48<05:43,  5.47it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:11 - INFO - __main__ - train loss is 5.449611113406718\n",
      "Steps:  87%|▊| 13122/15000 [1:23:49<05:40,  5.51it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:11 - INFO - __main__ - train loss is 5.709304259158671\n",
      "Steps:  87%|▊| 13123/15000 [1:23:49<05:38,  5.54it/s, lr=8.87e-6, step_loss=0.2607/18/2023 20:27:11 - INFO - __main__ - train loss is 6.4331486681476235\n",
      "Steps:  87%|▊| 13124/15000 [1:23:49<05:37,  5.56it/s, lr=8.87e-6, step_loss=0.7207/18/2023 20:27:11 - INFO - __main__ - train loss is 6.437371478881687\n",
      "Steps:  88%|▉| 13125/15000 [1:23:49<05:36,  5.58it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:11 - INFO - __main__ - train loss is 6.439302808837965\n",
      "Steps:  88%|▉| 13126/15000 [1:23:49<05:35,  5.59it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:12 - INFO - __main__ - train loss is 6.510955742793158\n",
      "Steps:  88%|▉| 13127/15000 [1:23:49<05:34,  5.59it/s, lr=8.87e-6, step_loss=0.0707/18/2023 20:27:12 - INFO - __main__ - train loss is 6.709222219185904\n",
      "Steps:  88%|▉| 13128/15000 [1:23:50<05:34,  5.59it/s, lr=8.87e-6, step_loss=0.1907/18/2023 20:27:12 - INFO - __main__ - train loss is 7.1283045031595975\n",
      "Steps:  88%|▉| 13129/15000 [1:23:50<05:36,  5.56it/s, lr=8.87e-6, step_loss=0.4107/18/2023 20:27:12 - INFO - __main__ - train loss is 7.133312732214108\n",
      "Steps:  88%|▉| 13130/15000 [1:23:50<05:38,  5.52it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:12 - INFO - __main__ - train loss is 7.2578762921039015\n",
      "Steps:  88%|▉| 13131/15000 [1:23:50<05:40,  5.49it/s, lr=8.87e-6, step_loss=0.1207/18/2023 20:27:12 - INFO - __main__ - train loss is 7.273735415423289\n",
      "Steps:  88%|▉| 13132/15000 [1:23:50<05:40,  5.49it/s, lr=8.87e-6, step_loss=0.0107/18/2023 20:27:13 - INFO - __main__ - train loss is 7.282419067109004\n",
      "Steps:  88%|▉| 13133/15000 [1:23:51<05:38,  5.52it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:13 - INFO - __main__ - train loss is 7.289866345236078\n",
      "Steps:  88%|▉| 13134/15000 [1:23:51<05:39,  5.49it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:13 - INFO - __main__ - train loss is 7.430385919520631\n",
      "Steps:  88%|▉| 13135/15000 [1:23:51<05:40,  5.47it/s, lr=8.87e-6, step_loss=0.1407/18/2023 20:27:13 - INFO - __main__ - train loss is 7.437580447411165\n",
      "Steps:  88%|▉| 13136/15000 [1:23:51<05:41,  5.47it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:13 - INFO - __main__ - train loss is 7.439599428791553\n",
      "Steps:  88%|▉| 13137/15000 [1:23:51<05:41,  5.45it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:14 - INFO - __main__ - train loss is 7.609811667818576\n",
      "Steps:  88%|▉| 13138/15000 [1:23:51<05:42,  5.44it/s, lr=8.87e-6, step_loss=0.1707/18/2023 20:27:14 - INFO - __main__ - train loss is 7.749365497846156\n",
      "Steps:  88%|▉| 13139/15000 [1:23:52<05:42,  5.44it/s, lr=8.87e-6, step_loss=0.1407/18/2023 20:27:14 - INFO - __main__ - train loss is 7.80400423752144\n",
      "Steps:  88%|▉| 13140/15000 [1:23:52<05:39,  5.49it/s, lr=8.87e-6, step_loss=0.0507/18/2023 20:27:14 - INFO - __main__ - train loss is 7.807573466328904\n",
      "Steps:  88%|▉| 13141/15000 [1:23:52<05:37,  5.52it/s, lr=8.87e-6, step_loss=0.0007/18/2023 20:27:14 - INFO - __main__ - train loss is 8.082684724358842\n",
      "Steps:  88%|▉| 13142/15000 [1:23:52<05:35,  5.54it/s, lr=8.87e-6, step_loss=0.2707/18/2023 20:27:14 - INFO - __main__ - train loss is 8.126522599486634\n",
      "Steps:  88%|▉| 13143/15000 [1:23:52<05:35,  5.53it/s, lr=8.87e-6, step_loss=0.0407/18/2023 20:27:15 - INFO - __main__ - train loss is 8.380881695775315\n",
      "Steps:  88%|▉| 13144/15000 [1:23:53<05:37,  5.50it/s, lr=8.87e-6, step_loss=0.2507/18/2023 20:27:15 - INFO - __main__ - train loss is 8.395771139999852\n",
      "Steps:  88%|▉| 13145/15000 [1:23:53<05:35,  5.53it/s, lr=8.87e-6, step_loss=0.0107/18/2023 20:27:15 - INFO - __main__ - train loss is 8.484455967089161\n",
      "Steps:  88%|▉| 13146/15000 [1:23:53<05:34,  5.55it/s, lr=8.86e-6, step_loss=0.0807/18/2023 20:27:15 - INFO - __main__ - train loss is 8.541694974293932\n",
      "Steps:  88%|▉| 13147/15000 [1:23:53<05:33,  5.56it/s, lr=8.86e-6, step_loss=0.0507/18/2023 20:27:15 - INFO - __main__ - train loss is 8.612280493369326\n",
      "Steps:  88%|▉| 13148/15000 [1:23:53<05:32,  5.56it/s, lr=8.86e-6, step_loss=0.0707/18/2023 20:27:16 - INFO - __main__ - train loss is 8.6932994031813\n",
      "Steps:  88%|▉| 13149/15000 [1:23:53<05:32,  5.57it/s, lr=8.86e-6, step_loss=0.0807/18/2023 20:27:16 - INFO - __main__ - train loss is 8.779827935388312\n",
      "Steps:  88%|▉| 13150/15000 [1:23:54<05:31,  5.59it/s, lr=8.86e-6, step_loss=0.0807/18/2023 20:27:16 - INFO - __main__ - train loss is 8.781536211026832\n",
      "Steps:  88%|▉| 13151/15000 [1:23:54<05:30,  5.59it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:16 - INFO - __main__ - train loss is 8.783650116063654\n",
      "Steps:  88%|▉| 13152/15000 [1:23:54<05:30,  5.60it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:16 - INFO - __main__ - train loss is 8.964103505946696\n",
      "Steps:  88%|▉| 13153/15000 [1:23:54<05:29,  5.60it/s, lr=8.86e-6, step_loss=0.1807/18/2023 20:27:16 - INFO - __main__ - train loss is 9.041502074338496\n",
      "Steps:  88%|▉| 13154/15000 [1:23:54<05:29,  5.60it/s, lr=8.86e-6, step_loss=0.0707/18/2023 20:27:17 - INFO - __main__ - train loss is 9.048644232098013\n",
      "Steps:  88%|▉| 13155/15000 [1:23:55<05:29,  5.60it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:17 - INFO - __main__ - train loss is 9.442635404411703\n",
      "Steps:  88%|▉| 13156/15000 [1:23:55<05:32,  5.55it/s, lr=8.86e-6, step_loss=0.3907/18/2023 20:27:17 - INFO - __main__ - train loss is 9.4463364854455\n",
      "Steps:  88%|▉| 13157/15000 [1:23:55<05:36,  5.47it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:17 - INFO - __main__ - train loss is 9.467892050743103\n",
      "Steps:  88%|▉| 13158/15000 [1:23:55<05:34,  5.51it/s, lr=8.86e-6, step_loss=0.0207/18/2023 20:27:17 - INFO - __main__ - train loss is 9.724560558795929\n",
      "Steps:  88%|▉| 13159/15000 [1:23:55<05:32,  5.53it/s, lr=8.86e-6, step_loss=0.2507/18/2023 20:27:18 - INFO - __main__ - train loss is 10.37636536359787\n",
      "Steps:  88%|▉| 13160/15000 [1:23:55<05:31,  5.55it/s, lr=8.86e-6, step_loss=0.6507/18/2023 20:27:18 - INFO - __main__ - train loss is 10.606035932898521\n",
      "Steps:  88%|▉| 13161/15000 [1:23:56<05:30,  5.57it/s, lr=8.86e-6, step_loss=0.2307/18/2023 20:27:18 - INFO - __main__ - train loss is 10.73884679377079\n",
      "Steps:  88%|▉| 13162/15000 [1:23:56<05:29,  5.58it/s, lr=8.86e-6, step_loss=0.1307/18/2023 20:27:18 - INFO - __main__ - train loss is 11.111580237746239\n",
      "Steps:  88%|▉| 13163/15000 [1:23:56<05:31,  5.55it/s, lr=8.86e-6, step_loss=0.3707/18/2023 20:27:18 - INFO - __main__ - train loss is 11.29231046140194\n",
      "Steps:  88%|▉| 13164/15000 [1:23:56<05:31,  5.54it/s, lr=8.86e-6, step_loss=0.1807/18/2023 20:27:18 - INFO - __main__ - train loss is 11.751139089465141\n",
      "Steps:  88%|▉| 13165/15000 [1:23:56<05:32,  5.52it/s, lr=8.86e-6, step_loss=0.4507/18/2023 20:27:19 - INFO - __main__ - train loss is 11.830421328544617\n",
      "Steps:  88%|▉| 13166/15000 [1:23:57<05:30,  5.55it/s, lr=8.86e-6, step_loss=0.0707/18/2023 20:27:19 - INFO - __main__ - train loss is 11.947648271918297\n",
      "Steps:  88%|▉| 13167/15000 [1:23:57<05:29,  5.56it/s, lr=8.86e-6, step_loss=0.1107/18/2023 20:27:19 - INFO - __main__ - train loss is 11.950715469196439\n",
      "Steps:  88%|▉| 13168/15000 [1:23:57<05:28,  5.58it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:19 - INFO - __main__ - train loss is 11.990789974108338\n",
      "Steps:  88%|▉| 13169/15000 [1:23:57<05:28,  5.58it/s, lr=8.86e-6, step_loss=0.0407/18/2023 20:27:19 - INFO - __main__ - train loss is 11.996311011258513\n",
      "Steps:  88%|▉| 13170/15000 [1:23:57<05:27,  5.59it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:20 - INFO - __main__ - train loss is 11.999647337943316\n",
      "Steps:  88%|▉| 13171/15000 [1:23:57<05:27,  5.58it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:20 - INFO - __main__ - train loss is 12.022422153502703\n",
      "Steps:  88%|▉| 13172/15000 [1:23:58<05:28,  5.56it/s, lr=8.86e-6, step_loss=0.0207/18/2023 20:27:20 - INFO - __main__ - train loss is 12.262993071228266\n",
      "Steps:  88%|▉| 13173/15000 [1:23:58<05:27,  5.58it/s, lr=8.86e-6, step_loss=0.2407/18/2023 20:27:20 - INFO - __main__ - train loss is 12.283915311098099\n",
      "Steps:  88%|▉| 13174/15000 [1:23:58<05:26,  5.59it/s, lr=8.86e-6, step_loss=0.0207/18/2023 20:27:20 - INFO - __main__ - train loss is 12.295974221080542\n",
      "Steps:  88%|▉| 13175/15000 [1:23:58<05:26,  5.59it/s, lr=8.86e-6, step_loss=0.0107/18/2023 20:27:20 - INFO - __main__ - train loss is 12.305778477340937\n",
      "Steps:  88%|▉| 13176/15000 [1:23:58<05:25,  5.60it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:21 - INFO - __main__ - train loss is 12.330405361950397\n",
      "Steps:  88%|▉| 13177/15000 [1:23:58<05:24,  5.61it/s, lr=8.86e-6, step_loss=0.0207/18/2023 20:27:21 - INFO - __main__ - train loss is 12.3329699463211\n",
      "Steps:  88%|▉| 13178/15000 [1:23:59<05:24,  5.62it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:21 - INFO - __main__ - train loss is 12.33730955189094\n",
      "Steps:  88%|▉| 13179/15000 [1:23:59<05:23,  5.62it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:21 - INFO - __main__ - train loss is 12.645925951655954\n",
      "Steps:  88%|▉| 13180/15000 [1:23:59<05:23,  5.62it/s, lr=8.86e-6, step_loss=0.3007/18/2023 20:27:21 - INFO - __main__ - train loss is 12.662545756902546\n",
      "Steps:  88%|▉| 13181/15000 [1:23:59<05:26,  5.57it/s, lr=8.86e-6, step_loss=0.0107/18/2023 20:27:21 - INFO - __main__ - train loss is 12.853296966757625\n",
      "Steps:  88%|▉| 13182/15000 [1:23:59<05:26,  5.57it/s, lr=8.86e-6, step_loss=0.1907/18/2023 20:27:22 - INFO - __main__ - train loss is 13.199424357619137\n",
      "Steps:  88%|▉| 13183/15000 [1:24:00<05:25,  5.58it/s, lr=8.86e-6, step_loss=0.3407/18/2023 20:27:22 - INFO - __main__ - train loss is 13.203039547428489\n",
      "Steps:  88%|▉| 13184/15000 [1:24:00<05:24,  5.59it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:22 - INFO - __main__ - train loss is 13.586896261200309\n",
      "Steps:  88%|▉| 13185/15000 [1:24:00<05:23,  5.61it/s, lr=8.86e-6, step_loss=0.3807/18/2023 20:27:22 - INFO - __main__ - train loss is 13.659316098317504\n",
      "Steps:  88%|▉| 13186/15000 [1:24:00<05:23,  5.61it/s, lr=8.86e-6, step_loss=0.0707/18/2023 20:27:22 - INFO - __main__ - train loss is 13.736880673095584\n",
      "Steps:  88%|▉| 13187/15000 [1:24:00<05:26,  5.55it/s, lr=8.86e-6, step_loss=0.0707/18/2023 20:27:23 - INFO - __main__ - train loss is 13.884229553863406\n",
      "Steps:  88%|▉| 13188/15000 [1:24:01<06:05,  4.96it/s, lr=8.86e-6, step_loss=0.1407/18/2023 20:27:23 - INFO - __main__ - train loss is 14.161872489377856\n",
      "Steps:  88%|▉| 13189/15000 [1:24:01<06:02,  5.00it/s, lr=8.86e-6, step_loss=0.2707/18/2023 20:27:23 - INFO - __main__ - train loss is 14.318936271592975\n",
      "Steps:  88%|▉| 13190/15000 [1:24:01<06:30,  4.64it/s, lr=8.86e-6, step_loss=0.1507/18/2023 20:27:23 - INFO - __main__ - train loss is 14.870250625535846\n",
      "Steps:  88%|▉| 13191/15000 [1:24:01<06:12,  4.86it/s, lr=8.86e-6, step_loss=0.5507/18/2023 20:27:24 - INFO - __main__ - train loss is 15.82124380581081\n",
      "Steps:  88%|▉| 13192/15000 [1:24:02<07:36,  3.96it/s, lr=8.86e-6, step_loss=0.9507/18/2023 20:27:24 - INFO - __main__ - Per validation step average loss is 0.02992628514766693\n",
      "07/18/2023 20:27:24 - INFO - __main__ - Cumulative validation average loss is 0.02992628514766693\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Per validation step average loss is 0.010572614148259163\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Cumulative validation average loss is 0.040498899295926094\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Per validation step average loss is 0.001327254343777895\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Cumulative validation average loss is 0.04182615363970399\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Per validation step average loss is 0.485843300819397\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Cumulative validation average loss is 0.527669454459101\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Per validation step average loss is 0.402488112449646\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Cumulative validation average loss is 0.930157566908747\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Per validation step average loss is 0.13937917351722717\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Cumulative validation average loss is 1.0695367404259741\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Per validation step average loss is 0.0068976241163909435\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Cumulative validation average loss is 1.076434364542365\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Per validation step average loss is 0.01051095500588417\n",
      "07/18/2023 20:27:25 - INFO - __main__ - Cumulative validation average loss is 1.0869453195482492\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Per validation step average loss is 0.4194526970386505\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Cumulative validation average loss is 1.5063980165868998\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Per validation step average loss is 0.09469282627105713\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Cumulative validation average loss is 1.6010908428579569\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Per validation step average loss is 0.025053836405277252\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Cumulative validation average loss is 1.6261446792632341\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Per validation step average loss is 0.02901609241962433\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Cumulative validation average loss is 1.6551607716828585\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Average validation loss for Epoch 135 is 0.13793006430690488\n",
      "07/18/2023 20:27:26 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:27:39 - INFO - __main__ - Starting epoch 136\n",
      "07/18/2023 20:27:39 - INFO - __main__ - train loss is 0.1939222812652588\n",
      "Steps:  88%|▉| 13193/15000 [1:24:17<2:27:57,  4.91s/it, lr=8.86e-6, step_loss=0.07/18/2023 20:27:40 - INFO - __main__ - train loss is 0.21542604267597198\n",
      "Steps:  88%|▉| 13194/15000 [1:24:17<1:45:09,  3.49s/it, lr=8.86e-6, step_loss=0.07/18/2023 20:27:40 - INFO - __main__ - train loss is 0.27681727334856987\n",
      "Steps:  88%|▉| 13195/15000 [1:24:18<1:15:11,  2.50s/it, lr=8.86e-6, step_loss=0.07/18/2023 20:27:40 - INFO - __main__ - train loss is 0.6412577740848064\n",
      "Steps:  88%|▉| 13196/15000 [1:24:18<54:12,  1.80s/it, lr=8.86e-6, step_loss=0.3607/18/2023 20:27:40 - INFO - __main__ - train loss is 0.7495040856301785\n",
      "Steps:  88%|▉| 13197/15000 [1:24:18<39:32,  1.32s/it, lr=8.86e-6, step_loss=0.1007/18/2023 20:27:40 - INFO - __main__ - train loss is 0.7774145249277353\n",
      "Steps:  88%|▉| 13198/15000 [1:24:18<29:17,  1.03it/s, lr=8.86e-6, step_loss=0.0207/18/2023 20:27:40 - INFO - __main__ - train loss is 0.7937882747501135\n",
      "Steps:  88%|▉| 13199/15000 [1:24:18<22:06,  1.36it/s, lr=8.86e-6, step_loss=0.0107/18/2023 20:27:41 - INFO - __main__ - train loss is 0.9672009255737066\n",
      "Steps:  88%|▉| 13200/15000 [1:24:19<17:07,  1.75it/s, lr=8.86e-6, step_loss=0.1707/18/2023 20:27:41 - INFO - __main__ - train loss is 1.0721482392400503\n",
      "Steps:  88%|▉| 13201/15000 [1:24:19<13:35,  2.21it/s, lr=8.86e-6, step_loss=0.1007/18/2023 20:27:41 - INFO - __main__ - train loss is 1.0739953762385994\n",
      "Steps:  88%|▉| 13202/15000 [1:24:19<11:06,  2.70it/s, lr=8.86e-6, step_loss=0.0007/18/2023 20:27:41 - INFO - __main__ - train loss is 1.091202393407002\n",
      "Steps:  88%|▉| 13203/15000 [1:24:19<09:22,  3.20it/s, lr=8.86e-6, step_loss=0.0107/18/2023 20:27:41 - INFO - __main__ - train loss is 1.105381240369752\n",
      "Steps:  88%|▉| 13204/15000 [1:24:19<08:09,  3.67it/s, lr=8.86e-6, step_loss=0.0107/18/2023 20:27:42 - INFO - __main__ - train loss is 1.3023852307815105\n",
      "Steps:  88%|▉| 13205/15000 [1:24:19<07:24,  4.04it/s, lr=8.86e-6, step_loss=0.1907/18/2023 20:27:42 - INFO - __main__ - train loss is 1.3976576526183635\n",
      "Steps:  88%|▉| 13206/15000 [1:24:20<06:53,  4.34it/s, lr=8.85e-6, step_loss=0.0907/18/2023 20:27:42 - INFO - __main__ - train loss is 1.5131544072646648\n",
      "Steps:  88%|▉| 13207/15000 [1:24:20<06:33,  4.55it/s, lr=8.85e-6, step_loss=0.1107/18/2023 20:27:42 - INFO - __main__ - train loss is 1.6283781577367336\n",
      "Steps:  88%|▉| 13208/15000 [1:24:20<06:19,  4.73it/s, lr=8.85e-6, step_loss=0.1107/18/2023 20:27:42 - INFO - __main__ - train loss is 1.7149829615373164\n",
      "Steps:  88%|▉| 13209/15000 [1:24:20<06:09,  4.85it/s, lr=8.85e-6, step_loss=0.0807/18/2023 20:27:43 - INFO - __main__ - train loss is 1.7186684429179877\n",
      "Steps:  88%|▉| 13210/15000 [1:24:20<06:02,  4.93it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:43 - INFO - __main__ - train loss is 2.4823735177051276\n",
      "Steps:  88%|▉| 13211/15000 [1:24:21<05:58,  5.00it/s, lr=8.85e-6, step_loss=0.7607/18/2023 20:27:43 - INFO - __main__ - train loss is 2.5639788776170462\n",
      "Steps:  88%|▉| 13212/15000 [1:24:21<05:55,  5.04it/s, lr=8.85e-6, step_loss=0.0807/18/2023 20:27:43 - INFO - __main__ - train loss is 2.6172522872220725\n",
      "Steps:  88%|▉| 13213/15000 [1:24:21<05:53,  5.06it/s, lr=8.85e-6, step_loss=0.0507/18/2023 20:27:43 - INFO - __main__ - train loss is 2.6218110027257353\n",
      "Steps:  88%|▉| 13214/15000 [1:24:21<05:51,  5.08it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:44 - INFO - __main__ - train loss is 2.6699739100877196\n",
      "Steps:  88%|▉| 13215/15000 [1:24:21<05:50,  5.09it/s, lr=8.85e-6, step_loss=0.0407/18/2023 20:27:44 - INFO - __main__ - train loss is 2.8466902973596007\n",
      "Steps:  88%|▉| 13216/15000 [1:24:22<05:50,  5.10it/s, lr=8.85e-6, step_loss=0.1707/18/2023 20:27:44 - INFO - __main__ - train loss is 3.0384773465339094\n",
      "Steps:  88%|▉| 13217/15000 [1:24:22<05:49,  5.10it/s, lr=8.85e-6, step_loss=0.1907/18/2023 20:27:44 - INFO - __main__ - train loss is 3.0826296547893435\n",
      "Steps:  88%|▉| 13218/15000 [1:24:22<05:49,  5.09it/s, lr=8.85e-6, step_loss=0.0407/18/2023 20:27:44 - INFO - __main__ - train loss is 3.0880949415732175\n",
      "Steps:  88%|▉| 13219/15000 [1:24:22<05:49,  5.09it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:44 - INFO - __main__ - train loss is 3.1463434987235814\n",
      "Steps:  88%|▉| 13220/15000 [1:24:22<05:50,  5.08it/s, lr=8.85e-6, step_loss=0.0507/18/2023 20:27:45 - INFO - __main__ - train loss is 3.705784707562998\n",
      "Steps:  88%|▉| 13221/15000 [1:24:23<05:51,  5.06it/s, lr=8.85e-6, step_loss=0.5507/18/2023 20:27:45 - INFO - __main__ - train loss is 3.888625442283228\n",
      "Steps:  88%|▉| 13222/15000 [1:24:23<05:50,  5.08it/s, lr=8.85e-6, step_loss=0.1807/18/2023 20:27:45 - INFO - __main__ - train loss is 4.119863494532183\n",
      "Steps:  88%|▉| 13223/15000 [1:24:23<05:48,  5.10it/s, lr=8.85e-6, step_loss=0.2307/18/2023 20:27:45 - INFO - __main__ - train loss is 4.132880170131102\n",
      "Steps:  88%|▉| 13224/15000 [1:24:23<05:47,  5.11it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:45 - INFO - __main__ - train loss is 4.745023209834471\n",
      "Steps:  88%|▉| 13225/15000 [1:24:23<05:46,  5.12it/s, lr=8.85e-6, step_loss=0.6107/18/2023 20:27:46 - INFO - __main__ - train loss is 4.7466180104529485\n",
      "Steps:  88%|▉| 13226/15000 [1:24:24<05:45,  5.14it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:46 - INFO - __main__ - train loss is 4.758037019870244\n",
      "Steps:  88%|▉| 13227/15000 [1:24:24<05:44,  5.14it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:46 - INFO - __main__ - train loss is 4.82493973930832\n",
      "Steps:  88%|▉| 13228/15000 [1:24:24<05:44,  5.14it/s, lr=8.85e-6, step_loss=0.0607/18/2023 20:27:46 - INFO - __main__ - train loss is 4.961053055129014\n",
      "Steps:  88%|▉| 13229/15000 [1:24:24<05:47,  5.10it/s, lr=8.85e-6, step_loss=0.1307/18/2023 20:27:46 - INFO - __main__ - train loss is 4.9700779024278745\n",
      "Steps:  88%|▉| 13230/15000 [1:24:24<05:46,  5.12it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:47 - INFO - __main__ - train loss is 5.3976902071153745\n",
      "Steps:  88%|▉| 13231/15000 [1:24:25<05:44,  5.13it/s, lr=8.85e-6, step_loss=0.4207/18/2023 20:27:47 - INFO - __main__ - train loss is 5.431476366124116\n",
      "Steps:  88%|▉| 13232/15000 [1:24:25<05:44,  5.14it/s, lr=8.85e-6, step_loss=0.0307/18/2023 20:27:47 - INFO - __main__ - train loss is 5.438803909695707\n",
      "Steps:  88%|▉| 13233/15000 [1:24:25<05:44,  5.12it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:47 - INFO - __main__ - train loss is 5.457799705094658\n",
      "Steps:  88%|▉| 13234/15000 [1:24:25<05:44,  5.13it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:47 - INFO - __main__ - train loss is 5.471897904179059\n",
      "Steps:  88%|▉| 13235/15000 [1:24:25<05:52,  5.00it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:48 - INFO - __main__ - train loss is 5.582630064687692\n",
      "Steps:  88%|▉| 13236/15000 [1:24:26<05:49,  5.05it/s, lr=8.85e-6, step_loss=0.1107/18/2023 20:27:48 - INFO - __main__ - train loss is 5.756454881629907\n",
      "[2023-07-18 20:27:48,419] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576\n",
      "Steps:  88%|▉| 13237/15000 [1:24:26<05:44,  5.12it/s, lr=8.85e-6, step_loss=0.1707/18/2023 20:27:48 - INFO - __main__ - train loss is 5.767648056498729\n",
      "Steps:  88%|▉| 13238/15000 [1:24:26<05:39,  5.19it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:48 - INFO - __main__ - train loss is 5.771376695367508\n",
      "Steps:  88%|▉| 13239/15000 [1:24:26<05:36,  5.23it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:48 - INFO - __main__ - train loss is 6.102925743791275\n",
      "Steps:  88%|▉| 13240/15000 [1:24:26<05:38,  5.20it/s, lr=8.85e-6, step_loss=0.3307/18/2023 20:27:49 - INFO - __main__ - train loss is 6.482140716048889\n",
      "Steps:  88%|▉| 13241/15000 [1:24:26<05:40,  5.17it/s, lr=8.85e-6, step_loss=0.3707/18/2023 20:27:49 - INFO - __main__ - train loss is 6.583566348883323\n",
      "Steps:  88%|▉| 13242/15000 [1:24:27<05:40,  5.16it/s, lr=8.85e-6, step_loss=0.1007/18/2023 20:27:49 - INFO - __main__ - train loss is 6.702031489345245\n",
      "Steps:  88%|▉| 13243/15000 [1:24:27<05:40,  5.16it/s, lr=8.85e-6, step_loss=0.1107/18/2023 20:27:49 - INFO - __main__ - train loss is 6.711490603978746\n",
      "Steps:  88%|▉| 13244/15000 [1:24:27<05:40,  5.15it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:49 - INFO - __main__ - train loss is 6.719913139822893\n",
      "Steps:  88%|▉| 13245/15000 [1:24:27<05:41,  5.14it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:50 - INFO - __main__ - train loss is 6.736260879668407\n",
      "Steps:  88%|▉| 13246/15000 [1:24:27<05:41,  5.13it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:50 - INFO - __main__ - train loss is 6.741336972336285\n",
      "Steps:  88%|▉| 13247/15000 [1:24:28<05:40,  5.14it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:50 - INFO - __main__ - train loss is 6.783402130822651\n",
      "Steps:  88%|▉| 13248/15000 [1:24:28<05:40,  5.14it/s, lr=8.85e-6, step_loss=0.0407/18/2023 20:27:50 - INFO - __main__ - train loss is 6.897381276707165\n",
      "Steps:  88%|▉| 13249/15000 [1:24:28<05:40,  5.14it/s, lr=8.85e-6, step_loss=0.1107/18/2023 20:27:50 - INFO - __main__ - train loss is 6.9869659402174875\n",
      "Steps:  88%|▉| 13250/15000 [1:24:28<05:40,  5.14it/s, lr=8.85e-6, step_loss=0.0807/18/2023 20:27:51 - INFO - __main__ - train loss is 6.996890476788394\n",
      "Steps:  88%|▉| 13251/15000 [1:24:28<05:41,  5.12it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:51 - INFO - __main__ - train loss is 7.259185067261569\n",
      "Steps:  88%|▉| 13252/15000 [1:24:29<05:39,  5.14it/s, lr=8.85e-6, step_loss=0.2607/18/2023 20:27:51 - INFO - __main__ - train loss is 7.270977171021514\n",
      "Steps:  88%|▉| 13253/15000 [1:24:29<05:40,  5.12it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:51 - INFO - __main__ - train loss is 7.620315940934233\n",
      "Steps:  88%|▉| 13254/15000 [1:24:29<05:40,  5.12it/s, lr=8.85e-6, step_loss=0.3407/18/2023 20:27:51 - INFO - __main__ - train loss is 7.879789413767867\n",
      "Steps:  88%|▉| 13255/15000 [1:24:29<05:40,  5.13it/s, lr=8.85e-6, step_loss=0.2507/18/2023 20:27:52 - INFO - __main__ - train loss is 7.882454615202732\n",
      "Steps:  88%|▉| 13256/15000 [1:24:29<05:39,  5.14it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:52 - INFO - __main__ - train loss is 7.898589259129949\n",
      "Steps:  88%|▉| 13257/15000 [1:24:30<05:36,  5.17it/s, lr=8.85e-6, step_loss=0.0107/18/2023 20:27:52 - INFO - __main__ - train loss is 8.241346186143346\n",
      "Steps:  88%|▉| 13258/15000 [1:24:30<05:29,  5.29it/s, lr=8.85e-6, step_loss=0.3407/18/2023 20:27:52 - INFO - __main__ - train loss is 8.783958917600103\n",
      "Steps:  88%|▉| 13259/15000 [1:24:30<05:23,  5.38it/s, lr=8.85e-6, step_loss=0.5407/18/2023 20:27:52 - INFO - __main__ - train loss is 8.875697886687703\n",
      "Steps:  88%|▉| 13260/15000 [1:24:30<05:19,  5.44it/s, lr=8.85e-6, step_loss=0.0907/18/2023 20:27:52 - INFO - __main__ - train loss is 8.877045222907327\n",
      "Steps:  88%|▉| 13261/15000 [1:24:30<05:17,  5.49it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:53 - INFO - __main__ - train loss is 8.87848587858025\n",
      "Steps:  88%|▉| 13262/15000 [1:24:30<05:14,  5.52it/s, lr=8.85e-6, step_loss=0.0007/18/2023 20:27:53 - INFO - __main__ - train loss is 8.957873707287945\n",
      "Steps:  88%|▉| 13263/15000 [1:24:31<05:13,  5.54it/s, lr=8.85e-6, step_loss=0.0707/18/2023 20:27:53 - INFO - __main__ - train loss is 9.038462964468636\n",
      "Steps:  88%|▉| 13264/15000 [1:24:31<05:12,  5.56it/s, lr=8.85e-6, step_loss=0.0807/18/2023 20:27:53 - INFO - __main__ - train loss is 9.223575187497772\n",
      "Steps:  88%|▉| 13265/15000 [1:24:31<05:11,  5.57it/s, lr=8.85e-6, step_loss=0.1807/18/2023 20:27:53 - INFO - __main__ - train loss is 9.274996017687954\n",
      "Steps:  88%|▉| 13266/15000 [1:24:31<05:11,  5.57it/s, lr=8.85e-6, step_loss=0.0507/18/2023 20:27:53 - INFO - __main__ - train loss is 9.561329250806011\n",
      "Steps:  88%|▉| 13267/15000 [1:24:31<05:10,  5.58it/s, lr=8.84e-6, step_loss=0.2807/18/2023 20:27:54 - INFO - __main__ - train loss is 9.680832137935795\n",
      "Steps:  88%|▉| 13268/15000 [1:24:32<05:10,  5.58it/s, lr=8.84e-6, step_loss=0.1207/18/2023 20:27:54 - INFO - __main__ - train loss is 9.703338529565372\n",
      "Steps:  88%|▉| 13269/15000 [1:24:32<05:09,  5.58it/s, lr=8.84e-6, step_loss=0.0207/18/2023 20:27:54 - INFO - __main__ - train loss is 9.77380004117731\n",
      "Steps:  88%|▉| 13270/15000 [1:24:32<05:12,  5.53it/s, lr=8.84e-6, step_loss=0.0707/18/2023 20:27:54 - INFO - __main__ - train loss is 10.412606026628055\n",
      "Steps:  88%|▉| 13271/15000 [1:24:32<05:12,  5.53it/s, lr=8.84e-6, step_loss=0.6307/18/2023 20:27:54 - INFO - __main__ - train loss is 10.570559184649028\n",
      "Steps:  88%|▉| 13272/15000 [1:24:32<05:11,  5.55it/s, lr=8.84e-6, step_loss=0.1507/18/2023 20:27:55 - INFO - __main__ - train loss is 10.671579982736148\n",
      "Steps:  88%|▉| 13273/15000 [1:24:32<05:10,  5.56it/s, lr=8.84e-6, step_loss=0.1007/18/2023 20:27:55 - INFO - __main__ - train loss is 10.685221396037377\n",
      "Steps:  88%|▉| 13274/15000 [1:24:33<05:09,  5.57it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:27:55 - INFO - __main__ - train loss is 10.86426813120488\n",
      "Steps:  88%|▉| 13275/15000 [1:24:33<05:09,  5.57it/s, lr=8.84e-6, step_loss=0.1707/18/2023 20:27:55 - INFO - __main__ - train loss is 10.88808586599771\n",
      "Steps:  89%|▉| 13276/15000 [1:24:33<05:10,  5.55it/s, lr=8.84e-6, step_loss=0.0207/18/2023 20:27:55 - INFO - __main__ - train loss is 11.13129275443498\n",
      "Steps:  89%|▉| 13277/15000 [1:24:33<05:10,  5.55it/s, lr=8.84e-6, step_loss=0.2407/18/2023 20:27:55 - INFO - __main__ - train loss is 11.13435895612929\n",
      "Steps:  89%|▉| 13278/15000 [1:24:33<05:09,  5.56it/s, lr=8.84e-6, step_loss=0.0007/18/2023 20:27:56 - INFO - __main__ - train loss is 11.523812575847842\n",
      "Steps:  89%|▉| 13279/15000 [1:24:34<05:08,  5.57it/s, lr=8.84e-6, step_loss=0.3807/18/2023 20:27:56 - INFO - __main__ - train loss is 11.528118234244175\n",
      "Steps:  89%|▉| 13280/15000 [1:24:34<05:08,  5.58it/s, lr=8.84e-6, step_loss=0.0007/18/2023 20:27:56 - INFO - __main__ - train loss is 11.998622309532948\n",
      "Steps:  89%|▉| 13281/15000 [1:24:34<05:07,  5.59it/s, lr=8.84e-6, step_loss=0.4707/18/2023 20:27:56 - INFO - __main__ - train loss is 12.230658244458027\n",
      "Steps:  89%|▉| 13282/15000 [1:24:34<05:07,  5.59it/s, lr=8.84e-6, step_loss=0.2307/18/2023 20:27:56 - INFO - __main__ - train loss is 12.291476111975498\n",
      "Steps:  89%|▉| 13283/15000 [1:24:34<05:06,  5.60it/s, lr=8.84e-6, step_loss=0.0607/18/2023 20:27:57 - INFO - __main__ - train loss is 12.310163756948896\n",
      "Steps:  89%|▉| 13284/15000 [1:24:34<05:06,  5.59it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:27:57 - INFO - __main__ - train loss is 12.416926747304387\n",
      "Steps:  89%|▉| 13285/15000 [1:24:35<05:06,  5.59it/s, lr=8.84e-6, step_loss=0.1007/18/2023 20:27:57 - INFO - __main__ - train loss is 12.43416508298833\n",
      "Steps:  89%|▉| 13286/15000 [1:24:35<05:07,  5.58it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:27:57 - INFO - __main__ - train loss is 12.438196931150742\n",
      "Steps:  89%|▉| 13287/15000 [1:24:35<05:06,  5.59it/s, lr=8.84e-6, step_loss=0.0007/18/2023 20:27:57 - INFO - __main__ - train loss is 12.56790173437912\n",
      "Steps:  89%|▉| 13288/15000 [1:24:35<05:06,  5.58it/s, lr=8.84e-6, step_loss=0.1307/18/2023 20:27:58 - INFO - __main__ - train loss is 12.868231836822815\n",
      "Steps:  89%|▉| 13289/15000 [1:24:36<07:06,  4.01it/s, lr=8.84e-6, step_loss=0.3]07/18/2023 20:27:58 - INFO - __main__ - Per validation step average loss is 0.013910430483520031\n",
      "07/18/2023 20:27:58 - INFO - __main__ - Cumulative validation average loss is 0.013910430483520031\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Per validation step average loss is 0.28431618213653564\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Cumulative validation average loss is 0.2982266126200557\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Per validation step average loss is 0.09813693165779114\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Cumulative validation average loss is 0.3963635442778468\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Per validation step average loss is 0.0058409059420228004\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Cumulative validation average loss is 0.4022044502198696\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Per validation step average loss is 0.2920199930667877\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Cumulative validation average loss is 0.6942244432866573\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Per validation step average loss is 0.6905163526535034\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Cumulative validation average loss is 1.3847407959401608\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Per validation step average loss is 0.0023164977319538593\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Cumulative validation average loss is 1.3870572936721146\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Per validation step average loss is 0.15376845002174377\n",
      "07/18/2023 20:27:59 - INFO - __main__ - Cumulative validation average loss is 1.5408257436938584\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Per validation step average loss is 0.39069491624832153\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Cumulative validation average loss is 1.93152065994218\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Per validation step average loss is 0.27343013882637024\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Cumulative validation average loss is 2.20495079876855\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Per validation step average loss is 0.009405850432813168\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Cumulative validation average loss is 2.2143566492013633\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Per validation step average loss is 0.09929145872592926\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Cumulative validation average loss is 2.3136481079272926\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Average validation loss for Epoch 136 is 0.19280400899394104\n",
      "07/18/2023 20:28:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:28:13 - INFO - __main__ - Starting epoch 137\n",
      "07/18/2023 20:28:14 - INFO - __main__ - train loss is 0.6463759541511536\n",
      "Steps:  89%|▉| 13290/15000 [1:24:51<2:20:49,  4.94s/it, lr=8.84e-6, step_loss=0.07/18/2023 20:28:14 - INFO - __main__ - train loss is 0.9223357439041138\n",
      "Steps:  89%|▉| 13291/15000 [1:24:52<1:40:02,  3.51s/it, lr=8.84e-6, step_loss=0.07/18/2023 20:28:14 - INFO - __main__ - train loss is 0.9244226515293121\n",
      "Steps:  89%|▉| 13292/15000 [1:24:52<1:11:32,  2.51s/it, lr=8.84e-6, step_loss=0.07/18/2023 20:28:14 - INFO - __main__ - train loss is 0.9296118714846671\n",
      "Steps:  89%|▉| 13293/15000 [1:24:52<51:33,  1.81s/it, lr=8.84e-6, step_loss=0.0007/18/2023 20:28:14 - INFO - __main__ - train loss is 1.6786156394518912\n",
      "Steps:  89%|▉| 13294/15000 [1:24:52<37:35,  1.32s/it, lr=8.84e-6, step_loss=0.7407/18/2023 20:28:14 - INFO - __main__ - train loss is 1.6915333294309676\n",
      "Steps:  89%|▉| 13295/15000 [1:24:52<27:53,  1.02it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:28:15 - INFO - __main__ - train loss is 1.929645808879286\n",
      "Steps:  89%|▉| 13296/15000 [1:24:53<21:02,  1.35it/s, lr=8.84e-6, step_loss=0.2307/18/2023 20:28:15 - INFO - __main__ - train loss is 1.9763885349966586\n",
      "Steps:  89%|▉| 13297/15000 [1:24:53<16:13,  1.75it/s, lr=8.84e-6, step_loss=0.0407/18/2023 20:28:15 - INFO - __main__ - train loss is 2.277498117182404\n",
      "Steps:  89%|▉| 13298/15000 [1:24:53<12:53,  2.20it/s, lr=8.84e-6, step_loss=0.3007/18/2023 20:28:15 - INFO - __main__ - train loss is 2.811728468630463\n",
      "Steps:  89%|▉| 13299/15000 [1:24:53<10:31,  2.69it/s, lr=8.84e-6, step_loss=0.5307/18/2023 20:28:15 - INFO - __main__ - train loss is 2.8440090366639197\n",
      "Steps:  89%|▉| 13300/15000 [1:24:53<08:52,  3.19it/s, lr=8.84e-6, step_loss=0.0307/18/2023 20:28:16 - INFO - __main__ - train loss is 3.114676470402628\n",
      "Steps:  89%|▉| 13301/15000 [1:24:53<07:43,  3.67it/s, lr=8.84e-6, step_loss=0.2707/18/2023 20:28:16 - INFO - __main__ - train loss is 3.4210118600167334\n",
      "Steps:  89%|▉| 13302/15000 [1:24:54<06:54,  4.10it/s, lr=8.84e-6, step_loss=0.3007/18/2023 20:28:16 - INFO - __main__ - train loss is 3.4224321888759732\n",
      "Steps:  89%|▉| 13303/15000 [1:24:54<06:21,  4.45it/s, lr=8.84e-6, step_loss=0.0007/18/2023 20:28:16 - INFO - __main__ - train loss is 3.722766970284283\n",
      "Steps:  89%|▉| 13304/15000 [1:24:54<05:56,  4.75it/s, lr=8.84e-6, step_loss=0.3]07/18/2023 20:28:16 - INFO - __main__ - train loss is 4.031255100853741\n",
      "Steps:  89%|▉| 13305/15000 [1:24:54<05:40,  4.98it/s, lr=8.84e-6, step_loss=0.3007/18/2023 20:28:16 - INFO - __main__ - train loss is 4.667075132019818\n",
      "Steps:  89%|▉| 13306/15000 [1:24:54<05:33,  5.08it/s, lr=8.84e-6, step_loss=0.6307/18/2023 20:28:17 - INFO - __main__ - train loss is 4.672971833497286\n",
      "Steps:  89%|▉| 13307/15000 [1:24:55<06:19,  4.46it/s, lr=8.84e-6, step_loss=0.0007/18/2023 20:28:17 - INFO - __main__ - train loss is 4.7085345685482025\n",
      "Steps:  89%|▉| 13308/15000 [1:24:55<06:02,  4.66it/s, lr=8.84e-6, step_loss=0.0307/18/2023 20:28:17 - INFO - __main__ - train loss is 4.726763561367989\n",
      "Steps:  89%|▉| 13309/15000 [1:24:55<05:55,  4.76it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:28:17 - INFO - __main__ - train loss is 4.739645610563457\n",
      "Steps:  89%|▉| 13310/15000 [1:24:55<05:46,  4.87it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:28:17 - INFO - __main__ - train loss is 4.758298146538436\n",
      "Steps:  89%|▉| 13311/15000 [1:24:55<05:33,  5.06it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:28:18 - INFO - __main__ - train loss is 4.888798671774566\n",
      "Steps:  89%|▉| 13312/15000 [1:24:56<05:23,  5.21it/s, lr=8.84e-6, step_loss=0.1307/18/2023 20:28:18 - INFO - __main__ - train loss is 5.229592460207641\n",
      "Steps:  89%|▉| 13313/15000 [1:24:56<05:17,  5.32it/s, lr=8.84e-6, step_loss=0.3407/18/2023 20:28:18 - INFO - __main__ - train loss is 5.234321461059153\n",
      "Steps:  89%|▉| 13314/15000 [1:24:56<05:12,  5.40it/s, lr=8.84e-6, step_loss=0.0007/18/2023 20:28:18 - INFO - __main__ - train loss is 5.717044965364039\n",
      "Steps:  89%|▉| 13315/15000 [1:24:56<05:08,  5.46it/s, lr=8.84e-6, step_loss=0.4807/18/2023 20:28:18 - INFO - __main__ - train loss is 5.931448892690241\n",
      "Steps:  89%|▉| 13316/15000 [1:24:56<05:05,  5.50it/s, lr=8.84e-6, step_loss=0.2107/18/2023 20:28:19 - INFO - __main__ - train loss is 6.162190840579569\n",
      "Steps:  89%|▉| 13317/15000 [1:24:56<05:03,  5.54it/s, lr=8.84e-6, step_loss=0.2307/18/2023 20:28:19 - INFO - __main__ - train loss is 6.329768584109843\n",
      "Steps:  89%|▉| 13318/15000 [1:24:57<05:02,  5.56it/s, lr=8.84e-6, step_loss=0.1607/18/2023 20:28:19 - INFO - __main__ - train loss is 6.4668896505609155\n",
      "Steps:  89%|▉| 13319/15000 [1:24:57<05:01,  5.57it/s, lr=8.84e-6, step_loss=0.1307/18/2023 20:28:19 - INFO - __main__ - train loss is 7.118434698320925\n",
      "Steps:  89%|▉| 13320/15000 [1:24:57<05:04,  5.53it/s, lr=8.84e-6, step_loss=0.6507/18/2023 20:28:19 - INFO - __main__ - train loss is 7.326210648752749\n",
      "Steps:  89%|▉| 13321/15000 [1:24:57<05:03,  5.54it/s, lr=8.84e-6, step_loss=0.2007/18/2023 20:28:19 - INFO - __main__ - train loss is 7.34151126910001\n",
      "Steps:  89%|▉| 13322/15000 [1:24:57<05:01,  5.56it/s, lr=8.84e-6, step_loss=0.0107/18/2023 20:28:20 - INFO - __main__ - train loss is 7.674975831992924\n",
      "Steps:  89%|▉| 13323/15000 [1:24:58<05:01,  5.57it/s, lr=8.84e-6, step_loss=0.3307/18/2023 20:28:20 - INFO - __main__ - train loss is 7.822313477285206\n",
      "Steps:  89%|▉| 13324/15000 [1:24:58<05:00,  5.58it/s, lr=8.84e-6, step_loss=0.1407/18/2023 20:28:20 - INFO - __main__ - train loss is 8.026689981110394\n",
      "Steps:  89%|▉| 13325/15000 [1:24:58<05:00,  5.58it/s, lr=8.84e-6, step_loss=0.2007/18/2023 20:28:20 - INFO - __main__ - train loss is 8.28574535716325\n",
      "Steps:  89%|▉| 13326/15000 [1:24:58<05:01,  5.56it/s, lr=8.83e-6, step_loss=0.2507/18/2023 20:28:20 - INFO - __main__ - train loss is 8.356119354255497\n",
      "Steps:  89%|▉| 13327/15000 [1:24:58<05:00,  5.56it/s, lr=8.83e-6, step_loss=0.0707/18/2023 20:28:21 - INFO - __main__ - train loss is 8.359443880151957\n",
      "Steps:  89%|▉| 13328/15000 [1:24:58<04:59,  5.58it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:21 - INFO - __main__ - train loss is 8.433044097851962\n",
      "Steps:  89%|▉| 13329/15000 [1:24:59<04:59,  5.58it/s, lr=8.83e-6, step_loss=0.0707/18/2023 20:28:21 - INFO - __main__ - train loss is 8.600067771505564\n",
      "Steps:  89%|▉| 13330/15000 [1:24:59<04:58,  5.59it/s, lr=8.83e-6, step_loss=0.1607/18/2023 20:28:21 - INFO - __main__ - train loss is 8.62994998274371\n",
      "Steps:  89%|▉| 13331/15000 [1:24:59<04:59,  5.58it/s, lr=8.83e-6, step_loss=0.0207/18/2023 20:28:21 - INFO - __main__ - train loss is 8.636659000534564\n",
      "Steps:  89%|▉| 13332/15000 [1:24:59<04:58,  5.59it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:21 - INFO - __main__ - train loss is 8.645093739498407\n",
      "Steps:  89%|▉| 13333/15000 [1:24:59<04:58,  5.59it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:22 - INFO - __main__ - train loss is 8.688321162480861\n",
      "Steps:  89%|▉| 13334/15000 [1:24:59<04:57,  5.60it/s, lr=8.83e-6, step_loss=0.0407/18/2023 20:28:22 - INFO - __main__ - train loss is 8.702136900741607\n",
      "Steps:  89%|▉| 13335/15000 [1:25:00<04:57,  5.60it/s, lr=8.83e-6, step_loss=0.0107/18/2023 20:28:22 - INFO - __main__ - train loss is 8.704863952007145\n",
      "Steps:  89%|▉| 13336/15000 [1:25:00<04:57,  5.60it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:22 - INFO - __main__ - train loss is 8.707828366197646\n",
      "Steps:  89%|▉| 13337/15000 [1:25:00<04:56,  5.60it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:22 - INFO - __main__ - train loss is 8.938091748394072\n",
      "Steps:  89%|▉| 13338/15000 [1:25:00<04:57,  5.59it/s, lr=8.83e-6, step_loss=0.2307/18/2023 20:28:23 - INFO - __main__ - train loss is 9.03961790446192\n",
      "Steps:  89%|▉| 13339/15000 [1:25:00<04:56,  5.59it/s, lr=8.83e-6, step_loss=0.1007/18/2023 20:28:23 - INFO - __main__ - train loss is 9.257049017585814\n",
      "Steps:  89%|▉| 13340/15000 [1:25:01<04:56,  5.60it/s, lr=8.83e-6, step_loss=0.2107/18/2023 20:28:23 - INFO - __main__ - train loss is 9.763092094101012\n",
      "Steps:  89%|▉| 13341/15000 [1:25:01<04:56,  5.60it/s, lr=8.83e-6, step_loss=0.5007/18/2023 20:28:23 - INFO - __main__ - train loss is 9.768282012082636\n",
      "Steps:  89%|▉| 13342/15000 [1:25:01<04:56,  5.59it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:23 - INFO - __main__ - train loss is 9.783677977509797\n",
      "Steps:  89%|▉| 13343/15000 [1:25:01<04:59,  5.54it/s, lr=8.83e-6, step_loss=0.0107/18/2023 20:28:23 - INFO - __main__ - train loss is 10.229535234160721\n",
      "Steps:  89%|▉| 13344/15000 [1:25:01<04:59,  5.53it/s, lr=8.83e-6, step_loss=0.4407/18/2023 20:28:24 - INFO - __main__ - train loss is 10.23995294701308\n",
      "Steps:  89%|▉| 13345/15000 [1:25:01<04:58,  5.54it/s, lr=8.83e-6, step_loss=0.0107/18/2023 20:28:24 - INFO - __main__ - train loss is 10.52093496453017\n",
      "Steps:  89%|▉| 13346/15000 [1:25:02<04:57,  5.55it/s, lr=8.83e-6, step_loss=0.2807/18/2023 20:28:24 - INFO - __main__ - train loss is 10.56086904834956\n",
      "Steps:  89%|▉| 13347/15000 [1:25:02<04:57,  5.55it/s, lr=8.83e-6, step_loss=0.0307/18/2023 20:28:24 - INFO - __main__ - train loss is 10.907417277805507\n",
      "Steps:  89%|▉| 13348/15000 [1:25:02<05:00,  5.51it/s, lr=8.83e-6, step_loss=0.3407/18/2023 20:28:24 - INFO - __main__ - train loss is 11.273984949104488\n",
      "Steps:  89%|▉| 13349/15000 [1:25:02<05:01,  5.47it/s, lr=8.83e-6, step_loss=0.3607/18/2023 20:28:24 - INFO - __main__ - train loss is 11.27727795066312\n",
      "Steps:  89%|▉| 13350/15000 [1:25:02<05:02,  5.45it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:25 - INFO - __main__ - train loss is 11.465135220903903\n",
      "Steps:  89%|▉| 13351/15000 [1:25:03<05:03,  5.43it/s, lr=8.83e-6, step_loss=0.1807/18/2023 20:28:25 - INFO - __main__ - train loss is 11.533599008340389\n",
      "Steps:  89%|▉| 13352/15000 [1:25:03<05:02,  5.46it/s, lr=8.83e-6, step_loss=0.0607/18/2023 20:28:25 - INFO - __main__ - train loss is 11.535521007608622\n",
      "Steps:  89%|▉| 13353/15000 [1:25:03<04:59,  5.49it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:25 - INFO - __main__ - train loss is 11.727293408941478\n",
      "Steps:  89%|▉| 13354/15000 [1:25:03<04:58,  5.52it/s, lr=8.83e-6, step_loss=0.1907/18/2023 20:28:25 - INFO - __main__ - train loss is 12.136086262296885\n",
      "Steps:  89%|▉| 13355/15000 [1:25:03<04:56,  5.54it/s, lr=8.83e-6, step_loss=0.4007/18/2023 20:28:26 - INFO - __main__ - train loss is 12.486101813148707\n",
      "Steps:  89%|▉| 13356/15000 [1:25:03<04:55,  5.56it/s, lr=8.83e-6, step_loss=0.3507/18/2023 20:28:26 - INFO - __main__ - train loss is 12.781670845579356\n",
      "Steps:  89%|▉| 13357/15000 [1:25:04<04:54,  5.57it/s, lr=8.83e-6, step_loss=0.2907/18/2023 20:28:26 - INFO - __main__ - train loss is 12.783417876111344\n",
      "Steps:  89%|▉| 13358/15000 [1:25:04<04:54,  5.58it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:26 - INFO - __main__ - train loss is 12.886529411422089\n",
      "Steps:  89%|▉| 13359/15000 [1:25:04<04:53,  5.59it/s, lr=8.83e-6, step_loss=0.1007/18/2023 20:28:26 - INFO - __main__ - train loss is 12.926958522992209\n",
      "Steps:  89%|▉| 13360/15000 [1:25:04<04:53,  5.59it/s, lr=8.83e-6, step_loss=0.0407/18/2023 20:28:26 - INFO - __main__ - train loss is 13.782141349511221\n",
      "Steps:  89%|▉| 13361/15000 [1:25:04<04:52,  5.59it/s, lr=8.83e-6, step_loss=0.8507/18/2023 20:28:27 - INFO - __main__ - train loss is 13.783907302422449\n",
      "Steps:  89%|▉| 13362/15000 [1:25:05<04:52,  5.60it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:27 - INFO - __main__ - train loss is 13.788428770145401\n",
      "Steps:  89%|▉| 13363/15000 [1:25:05<04:52,  5.59it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:27 - INFO - __main__ - train loss is 13.818842734908685\n",
      "Steps:  89%|▉| 13364/15000 [1:25:05<04:52,  5.59it/s, lr=8.83e-6, step_loss=0.0307/18/2023 20:28:27 - INFO - __main__ - train loss is 13.82519478467293\n",
      "Steps:  89%|▉| 13365/15000 [1:25:05<04:52,  5.59it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:27 - INFO - __main__ - train loss is 13.889263862045482\n",
      "Steps:  89%|▉| 13366/15000 [1:25:05<04:52,  5.59it/s, lr=8.83e-6, step_loss=0.0607/18/2023 20:28:28 - INFO - __main__ - train loss is 14.380464309128001\n",
      "Steps:  89%|▉| 13367/15000 [1:25:05<04:52,  5.59it/s, lr=8.83e-6, step_loss=0.4907/18/2023 20:28:28 - INFO - __main__ - train loss is 14.430937976809219\n",
      "Steps:  89%|▉| 13368/15000 [1:25:06<04:51,  5.60it/s, lr=8.83e-6, step_loss=0.0507/18/2023 20:28:28 - INFO - __main__ - train loss is 14.439095535548404\n",
      "Steps:  89%|▉| 13369/15000 [1:25:06<04:51,  5.60it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:28 - INFO - __main__ - train loss is 14.813106634886935\n",
      "Steps:  89%|▉| 13370/15000 [1:25:06<04:53,  5.55it/s, lr=8.83e-6, step_loss=0.3707/18/2023 20:28:28 - INFO - __main__ - train loss is 15.103831270011142\n",
      "Steps:  89%|▉| 13371/15000 [1:25:06<04:55,  5.52it/s, lr=8.83e-6, step_loss=0.2907/18/2023 20:28:28 - INFO - __main__ - train loss is 15.105893750675023\n",
      "Steps:  89%|▉| 13372/15000 [1:25:06<04:53,  5.55it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:29 - INFO - __main__ - train loss is 15.158415340818465\n",
      "Steps:  89%|▉| 13373/15000 [1:25:07<04:52,  5.57it/s, lr=8.83e-6, step_loss=0.0507/18/2023 20:28:29 - INFO - __main__ - train loss is 15.269568839110434\n",
      "Steps:  89%|▉| 13374/15000 [1:25:07<04:51,  5.58it/s, lr=8.83e-6, step_loss=0.1107/18/2023 20:28:29 - INFO - __main__ - train loss is 15.709543474949896\n",
      "Steps:  89%|▉| 13375/15000 [1:25:07<04:50,  5.59it/s, lr=8.83e-6, step_loss=0.4407/18/2023 20:28:29 - INFO - __main__ - train loss is 15.744457666762173\n",
      "Steps:  89%|▉| 13376/15000 [1:25:07<04:50,  5.59it/s, lr=8.83e-6, step_loss=0.0307/18/2023 20:28:29 - INFO - __main__ - train loss is 15.813420434482396\n",
      "Steps:  89%|▉| 13377/15000 [1:25:07<04:50,  5.59it/s, lr=8.83e-6, step_loss=0.0607/18/2023 20:28:30 - INFO - __main__ - train loss is 15.859631818719208\n",
      "Steps:  89%|▉| 13378/15000 [1:25:07<04:49,  5.60it/s, lr=8.83e-6, step_loss=0.0407/18/2023 20:28:30 - INFO - __main__ - train loss is 15.8731630994007\n",
      "Steps:  89%|▉| 13379/15000 [1:25:08<04:49,  5.61it/s, lr=8.83e-6, step_loss=0.0107/18/2023 20:28:30 - INFO - __main__ - train loss is 16.248367483727634\n",
      "Steps:  89%|▉| 13380/15000 [1:25:08<04:51,  5.55it/s, lr=8.83e-6, step_loss=0.3707/18/2023 20:28:30 - INFO - __main__ - train loss is 16.252867293544114\n",
      "Steps:  89%|▉| 13381/15000 [1:25:08<04:51,  5.55it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:30 - INFO - __main__ - train loss is 16.25812413590029\n",
      "Steps:  89%|▉| 13382/15000 [1:25:08<04:51,  5.56it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:30 - INFO - __main__ - train loss is 16.33636348741129\n",
      "Steps:  89%|▉| 13383/15000 [1:25:08<04:53,  5.52it/s, lr=8.83e-6, step_loss=0.0707/18/2023 20:28:31 - INFO - __main__ - train loss is 16.62211009161547\n",
      "Steps:  89%|▉| 13384/15000 [1:25:08<04:53,  5.50it/s, lr=8.83e-6, step_loss=0.2807/18/2023 20:28:31 - INFO - __main__ - train loss is 16.628730416297913\n",
      "Steps:  89%|▉| 13385/15000 [1:25:09<04:51,  5.54it/s, lr=8.83e-6, step_loss=0.0007/18/2023 20:28:31 - INFO - __main__ - train loss is 16.63362548034638\n",
      "Steps:  89%|▉| 13386/15000 [1:25:09<06:28,  4.16it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:32 - INFO - __main__ - Per validation step average loss is 0.22822922468185425\n",
      "07/18/2023 20:28:32 - INFO - __main__ - Cumulative validation average loss is 0.22822922468185425\n",
      "07/18/2023 20:28:32 - INFO - __main__ - Per validation step average loss is 0.3259196877479553\n",
      "07/18/2023 20:28:32 - INFO - __main__ - Cumulative validation average loss is 0.5541489124298096\n",
      "07/18/2023 20:28:32 - INFO - __main__ - Per validation step average loss is 0.6606218814849854\n",
      "07/18/2023 20:28:32 - INFO - __main__ - Cumulative validation average loss is 1.214770793914795\n",
      "07/18/2023 20:28:32 - INFO - __main__ - Per validation step average loss is 0.026112515479326248\n",
      "07/18/2023 20:28:32 - INFO - __main__ - Cumulative validation average loss is 1.2408833093941212\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Per validation step average loss is 0.4346016049385071\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Cumulative validation average loss is 1.6754849143326283\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Per validation step average loss is 0.020148659124970436\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Cumulative validation average loss is 1.6956335734575987\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Per validation step average loss is 0.5545156002044678\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Cumulative validation average loss is 2.2501491736620665\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Per validation step average loss is 0.24029335379600525\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Cumulative validation average loss is 2.4904425274580717\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Per validation step average loss is 0.3078768253326416\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Cumulative validation average loss is 2.7983193527907133\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Per validation step average loss is 0.33076339960098267\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Cumulative validation average loss is 3.129082752391696\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Per validation step average loss is 0.19032025337219238\n",
      "07/18/2023 20:28:33 - INFO - __main__ - Cumulative validation average loss is 3.3194030057638884\n",
      "07/18/2023 20:28:34 - INFO - __main__ - Per validation step average loss is 0.002231393475085497\n",
      "07/18/2023 20:28:34 - INFO - __main__ - Cumulative validation average loss is 3.321634399238974\n",
      "07/18/2023 20:28:34 - INFO - __main__ - Average validation loss for Epoch 137 is 0.2768028666032478\n",
      "07/18/2023 20:28:34 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:28:46 - INFO - __main__ - Starting epoch 138\n",
      "07/18/2023 20:28:47 - INFO - __main__ - train loss is 0.10923776775598526\n",
      "Steps:  89%|▉| 13387/15000 [1:25:25<2:15:49,  5.05s/it, lr=8.82e-6, step_loss=0.07/18/2023 20:28:48 - INFO - __main__ - train loss is 1.068232037127018\n",
      "Steps:  89%|▉| 13388/15000 [1:25:26<1:36:31,  3.59s/it, lr=8.82e-6, step_loss=0.07/18/2023 20:28:48 - INFO - __main__ - train loss is 1.1381564810872078\n",
      "Steps:  89%|▉| 13389/15000 [1:25:26<1:09:07,  2.57s/it, lr=8.82e-6, step_loss=0.07/18/2023 20:28:48 - INFO - __main__ - train loss is 1.4322764948010445\n",
      "Steps:  89%|▉| 13390/15000 [1:25:26<49:55,  1.86s/it, lr=8.82e-6, step_loss=0.2907/18/2023 20:28:48 - INFO - __main__ - train loss is 1.7550299540162086\n",
      "Steps:  89%|▉| 13391/15000 [1:25:26<36:30,  1.36s/it, lr=8.82e-6, step_loss=0.3207/18/2023 20:28:48 - INFO - __main__ - train loss is 2.0392095521092415\n",
      "Steps:  89%|▉| 13392/15000 [1:25:26<27:03,  1.01s/it, lr=8.82e-6, step_loss=0.2807/18/2023 20:28:49 - INFO - __main__ - train loss is 2.8327698782086372\n",
      "Steps:  89%|▉| 13393/15000 [1:25:26<20:27,  1.31it/s, lr=8.82e-6, step_loss=0.7907/18/2023 20:28:49 - INFO - __main__ - train loss is 2.8436699267476797\n",
      "Steps:  89%|▉| 13394/15000 [1:25:27<15:52,  1.69it/s, lr=8.82e-6, step_loss=0.0107/18/2023 20:28:49 - INFO - __main__ - train loss is 2.8895884063094854\n",
      "Steps:  89%|▉| 13395/15000 [1:25:27<12:39,  2.11it/s, lr=8.82e-6, step_loss=0.0407/18/2023 20:28:49 - INFO - __main__ - train loss is 2.89093708852306\n",
      "Steps:  89%|▉| 13396/15000 [1:25:27<10:24,  2.57it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:49 - INFO - __main__ - train loss is 2.9295802214182913\n",
      "Steps:  89%|▉| 13397/15000 [1:25:27<08:49,  3.03it/s, lr=8.82e-6, step_loss=0.0307/18/2023 20:28:50 - INFO - __main__ - train loss is 3.3136869170702994\n",
      "Steps:  89%|▉| 13398/15000 [1:25:27<07:43,  3.46it/s, lr=8.82e-6, step_loss=0.3807/18/2023 20:28:50 - INFO - __main__ - train loss is 3.323163508903235\n",
      "Steps:  89%|▉| 13399/15000 [1:25:28<06:56,  3.84it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:50 - INFO - __main__ - train loss is 3.8147278423421085\n",
      "Steps:  89%|▉| 13400/15000 [1:25:28<06:24,  4.16it/s, lr=8.82e-6, step_loss=0.4907/18/2023 20:28:50 - INFO - __main__ - train loss is 3.817071382422\n",
      "Steps:  89%|▉| 13401/15000 [1:25:28<05:59,  4.44it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:50 - INFO - __main__ - train loss is 4.289522473234683\n",
      "Steps:  89%|▉| 13402/15000 [1:25:28<05:40,  4.69it/s, lr=8.82e-6, step_loss=0.4707/18/2023 20:28:51 - INFO - __main__ - train loss is 5.079093043226749\n",
      "Steps:  89%|▉| 13403/15000 [1:25:28<05:26,  4.89it/s, lr=8.82e-6, step_loss=0.7907/18/2023 20:28:51 - INFO - __main__ - train loss is 5.0871117995120585\n",
      "Steps:  89%|▉| 13404/15000 [1:25:29<05:19,  5.00it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:51 - INFO - __main__ - train loss is 5.13734087580815\n",
      "Steps:  89%|▉| 13405/15000 [1:25:29<05:12,  5.11it/s, lr=8.82e-6, step_loss=0.0507/18/2023 20:28:51 - INFO - __main__ - train loss is 5.153911689762026\n",
      "Steps:  89%|▉| 13406/15000 [1:25:29<05:09,  5.14it/s, lr=8.82e-6, step_loss=0.0107/18/2023 20:28:51 - INFO - __main__ - train loss is 5.372127214912325\n",
      "Steps:  89%|▉| 13407/15000 [1:25:29<05:09,  5.14it/s, lr=8.82e-6, step_loss=0.2107/18/2023 20:28:51 - INFO - __main__ - train loss is 5.377959388773888\n",
      "Steps:  89%|▉| 13408/15000 [1:25:29<05:08,  5.15it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:52 - INFO - __main__ - train loss is 5.5189619096927345\n",
      "Steps:  89%|▉| 13409/15000 [1:25:30<05:09,  5.15it/s, lr=8.82e-6, step_loss=0.1407/18/2023 20:28:52 - INFO - __main__ - train loss is 5.909064296167344\n",
      "Steps:  89%|▉| 13410/15000 [1:25:30<05:08,  5.15it/s, lr=8.82e-6, step_loss=0.3907/18/2023 20:28:52 - INFO - __main__ - train loss is 5.982718813698739\n",
      "Steps:  89%|▉| 13411/15000 [1:25:30<05:08,  5.14it/s, lr=8.82e-6, step_loss=0.0707/18/2023 20:28:52 - INFO - __main__ - train loss is 6.002270811703056\n",
      "Steps:  89%|▉| 13412/15000 [1:25:30<05:08,  5.15it/s, lr=8.82e-6, step_loss=0.0107/18/2023 20:28:52 - INFO - __main__ - train loss is 6.440415435936302\n",
      "Steps:  89%|▉| 13413/15000 [1:25:30<05:08,  5.14it/s, lr=8.82e-6, step_loss=0.4307/18/2023 20:28:53 - INFO - __main__ - train loss is 6.460231350269169\n",
      "Steps:  89%|▉| 13414/15000 [1:25:31<05:08,  5.14it/s, lr=8.82e-6, step_loss=0.0107/18/2023 20:28:53 - INFO - __main__ - train loss is 6.490211328025907\n",
      "Steps:  89%|▉| 13415/15000 [1:25:31<05:03,  5.22it/s, lr=8.82e-6, step_loss=0.0307/18/2023 20:28:53 - INFO - __main__ - train loss is 6.533939850982279\n",
      "Steps:  89%|▉| 13416/15000 [1:25:31<05:00,  5.26it/s, lr=8.82e-6, step_loss=0.0407/18/2023 20:28:53 - INFO - __main__ - train loss is 6.539577990304679\n",
      "Steps:  89%|▉| 13417/15000 [1:25:31<04:58,  5.30it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:53 - INFO - __main__ - train loss is 6.658683821093291\n",
      "Steps:  89%|▉| 13418/15000 [1:25:31<05:03,  5.21it/s, lr=8.82e-6, step_loss=0.1107/18/2023 20:28:54 - INFO - __main__ - train loss is 6.696278627496213\n",
      "Steps:  89%|▉| 13419/15000 [1:25:31<05:03,  5.21it/s, lr=8.82e-6, step_loss=0.0307/18/2023 20:28:54 - INFO - __main__ - train loss is 6.985715176444501\n",
      "Steps:  89%|▉| 13420/15000 [1:25:32<05:00,  5.26it/s, lr=8.82e-6, step_loss=0.2807/18/2023 20:28:54 - INFO - __main__ - train loss is 6.991165746934712\n",
      "Steps:  89%|▉| 13421/15000 [1:25:32<04:57,  5.31it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:54 - INFO - __main__ - train loss is 6.997699945233762\n",
      "Steps:  89%|▉| 13422/15000 [1:25:32<04:56,  5.32it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:54 - INFO - __main__ - train loss is 7.242605238221586\n",
      "Steps:  89%|▉| 13423/15000 [1:25:32<04:54,  5.35it/s, lr=8.82e-6, step_loss=0.2407/18/2023 20:28:55 - INFO - __main__ - train loss is 7.24501756997779\n",
      "Steps:  89%|▉| 13424/15000 [1:25:32<04:52,  5.40it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:55 - INFO - __main__ - train loss is 7.251269352156669\n",
      "Steps:  90%|▉| 13425/15000 [1:25:33<04:49,  5.43it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:55 - INFO - __main__ - train loss is 7.56291325064376\n",
      "Steps:  90%|▉| 13426/15000 [1:25:33<04:48,  5.46it/s, lr=8.82e-6, step_loss=0.3107/18/2023 20:28:55 - INFO - __main__ - train loss is 7.675771188456565\n",
      "Steps:  90%|▉| 13427/15000 [1:25:33<04:47,  5.48it/s, lr=8.82e-6, step_loss=0.1107/18/2023 20:28:55 - INFO - __main__ - train loss is 8.08040798874572\n",
      "Steps:  90%|▉| 13428/15000 [1:25:33<04:46,  5.49it/s, lr=8.82e-6, step_loss=0.4007/18/2023 20:28:55 - INFO - __main__ - train loss is 8.089910958427936\n",
      "Steps:  90%|▉| 13429/15000 [1:25:33<04:45,  5.50it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:56 - INFO - __main__ - train loss is 8.162277270574123\n",
      "Steps:  90%|▉| 13430/15000 [1:25:33<04:45,  5.51it/s, lr=8.82e-6, step_loss=0.0707/18/2023 20:28:56 - INFO - __main__ - train loss is 8.49346049549058\n",
      "Steps:  90%|▉| 13431/15000 [1:25:34<04:44,  5.51it/s, lr=8.82e-6, step_loss=0.3307/18/2023 20:28:56 - INFO - __main__ - train loss is 8.495986809954047\n",
      "Steps:  90%|▉| 13432/15000 [1:25:34<04:44,  5.51it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:56 - INFO - __main__ - train loss is 8.666056966409087\n",
      "Steps:  90%|▉| 13433/15000 [1:25:34<04:46,  5.46it/s, lr=8.82e-6, step_loss=0.1707/18/2023 20:28:56 - INFO - __main__ - train loss is 8.70957168750465\n",
      "Steps:  90%|▉| 13434/15000 [1:25:34<04:46,  5.47it/s, lr=8.82e-6, step_loss=0.0407/18/2023 20:28:57 - INFO - __main__ - train loss is 8.711440034909174\n",
      "Steps:  90%|▉| 13435/15000 [1:25:34<04:44,  5.51it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:57 - INFO - __main__ - train loss is 8.730492234928533\n",
      "Steps:  90%|▉| 13436/15000 [1:25:35<04:42,  5.54it/s, lr=8.82e-6, step_loss=0.0107/18/2023 20:28:57 - INFO - __main__ - train loss is 8.94386123190634\n",
      "Steps:  90%|▉| 13437/15000 [1:25:35<04:41,  5.55it/s, lr=8.82e-6, step_loss=0.2107/18/2023 20:28:57 - INFO - __main__ - train loss is 8.948452692711726\n",
      "Steps:  90%|▉| 13438/15000 [1:25:35<04:40,  5.57it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:57 - INFO - __main__ - train loss is 8.950319992145523\n",
      "Steps:  90%|▉| 13439/15000 [1:25:35<04:39,  5.58it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:57 - INFO - __main__ - train loss is 9.21287308796309\n",
      "Steps:  90%|▉| 13440/15000 [1:25:35<04:39,  5.58it/s, lr=8.82e-6, step_loss=0.2607/18/2023 20:28:58 - INFO - __main__ - train loss is 9.33456957503222\n",
      "Steps:  90%|▉| 13441/15000 [1:25:35<04:39,  5.59it/s, lr=8.82e-6, step_loss=0.1207/18/2023 20:28:58 - INFO - __main__ - train loss is 9.341418687487021\n",
      "Steps:  90%|▉| 13442/15000 [1:25:36<04:38,  5.59it/s, lr=8.82e-6, step_loss=0.0007/18/2023 20:28:58 - INFO - __main__ - train loss is 9.468972821021453\n",
      "Steps:  90%|▉| 13443/15000 [1:25:36<04:38,  5.59it/s, lr=8.82e-6, step_loss=0.1207/18/2023 20:28:58 - INFO - __main__ - train loss is 9.485007848823443\n",
      "Steps:  90%|▉| 13444/15000 [1:25:36<04:38,  5.59it/s, lr=8.82e-6, step_loss=0.0107/18/2023 20:28:58 - INFO - __main__ - train loss is 9.495621976675466\n",
      "Steps:  90%|▉| 13445/15000 [1:25:36<04:37,  5.60it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:28:58 - INFO - __main__ - train loss is 9.509560077684\n",
      "Steps:  90%|▉| 13446/15000 [1:25:36<04:37,  5.59it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:28:59 - INFO - __main__ - train loss is 9.541142556117848\n",
      "Steps:  90%|▉| 13447/15000 [1:25:37<04:37,  5.59it/s, lr=8.81e-6, step_loss=0.0307/18/2023 20:28:59 - INFO - __main__ - train loss is 9.553501474903896\n",
      "Steps:  90%|▉| 13448/15000 [1:25:37<04:37,  5.59it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:28:59 - INFO - __main__ - train loss is 9.740668433951214\n",
      "Steps:  90%|▉| 13449/15000 [1:25:37<04:37,  5.60it/s, lr=8.81e-6, step_loss=0.1807/18/2023 20:28:59 - INFO - __main__ - train loss is 9.790639232145622\n",
      "Steps:  90%|▉| 13450/15000 [1:25:37<04:36,  5.60it/s, lr=8.81e-6, step_loss=0.0507/18/2023 20:28:59 - INFO - __main__ - train loss is 9.815601111622527\n",
      "Steps:  90%|▉| 13451/15000 [1:25:37<04:36,  5.59it/s, lr=8.81e-6, step_loss=0.0207/18/2023 20:29:00 - INFO - __main__ - train loss is 9.819172279909253\n",
      "Steps:  90%|▉| 13452/15000 [1:25:37<04:36,  5.59it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:00 - INFO - __main__ - train loss is 9.977866576984525\n",
      "Steps:  90%|▉| 13453/15000 [1:25:38<04:36,  5.59it/s, lr=8.81e-6, step_loss=0.1507/18/2023 20:29:00 - INFO - __main__ - train loss is 9.97990533313714\n",
      "Steps:  90%|▉| 13454/15000 [1:25:38<04:36,  5.59it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:00 - INFO - __main__ - train loss is 9.982835990609601\n",
      "Steps:  90%|▉| 13455/15000 [1:25:38<04:36,  5.60it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:00 - INFO - __main__ - train loss is 10.115143371047452\n",
      "Steps:  90%|▉| 13456/15000 [1:25:38<04:35,  5.60it/s, lr=8.81e-6, step_loss=0.1307/18/2023 20:29:00 - INFO - __main__ - train loss is 10.116862811380997\n",
      "Steps:  90%|▉| 13457/15000 [1:25:38<04:36,  5.58it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:01 - INFO - __main__ - train loss is 10.265142016345635\n",
      "Steps:  90%|▉| 13458/15000 [1:25:39<04:36,  5.59it/s, lr=8.81e-6, step_loss=0.1407/18/2023 20:29:01 - INFO - __main__ - train loss is 10.289946928853169\n",
      "Steps:  90%|▉| 13459/15000 [1:25:39<04:35,  5.59it/s, lr=8.81e-6, step_loss=0.0207/18/2023 20:29:01 - INFO - __main__ - train loss is 10.679661348694935\n",
      "Steps:  90%|▉| 13460/15000 [1:25:39<04:35,  5.59it/s, lr=8.81e-6, step_loss=0.3907/18/2023 20:29:01 - INFO - __main__ - train loss is 11.012792304391041\n",
      "Steps:  90%|▉| 13461/15000 [1:25:39<04:34,  5.60it/s, lr=8.81e-6, step_loss=0.3307/18/2023 20:29:01 - INFO - __main__ - train loss is 11.03457921021618\n",
      "Steps:  90%|▉| 13462/15000 [1:25:39<04:35,  5.59it/s, lr=8.81e-6, step_loss=0.0207/18/2023 20:29:02 - INFO - __main__ - train loss is 11.089462649310008\n",
      "Steps:  90%|▉| 13463/15000 [1:25:39<04:34,  5.60it/s, lr=8.81e-6, step_loss=0.0507/18/2023 20:29:02 - INFO - __main__ - train loss is 11.186650570714846\n",
      "Steps:  90%|▉| 13464/15000 [1:25:40<04:34,  5.60it/s, lr=8.81e-6, step_loss=0.0907/18/2023 20:29:02 - INFO - __main__ - train loss is 11.472169723594561\n",
      "Steps:  90%|▉| 13465/15000 [1:25:40<04:34,  5.60it/s, lr=8.81e-6, step_loss=0.2807/18/2023 20:29:02 - INFO - __main__ - train loss is 11.486825594911352\n",
      "Steps:  90%|▉| 13466/15000 [1:25:40<04:33,  5.60it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:29:02 - INFO - __main__ - train loss is 11.742791125783697\n",
      "Steps:  90%|▉| 13467/15000 [1:25:40<04:33,  5.61it/s, lr=8.81e-6, step_loss=0.2507/18/2023 20:29:02 - INFO - __main__ - train loss is 11.758419947931543\n",
      "Steps:  90%|▉| 13468/15000 [1:25:40<04:34,  5.58it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:29:03 - INFO - __main__ - train loss is 11.760271079139784\n",
      "Steps:  90%|▉| 13469/15000 [1:25:40<04:34,  5.59it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:03 - INFO - __main__ - train loss is 11.794760435121134\n",
      "Steps:  90%|▉| 13470/15000 [1:25:41<04:33,  5.59it/s, lr=8.81e-6, step_loss=0.0307/18/2023 20:29:03 - INFO - __main__ - train loss is 11.800028155790642\n",
      "Steps:  90%|▉| 13471/15000 [1:25:41<04:33,  5.60it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:03 - INFO - __main__ - train loss is 11.84834913839586\n",
      "Steps:  90%|▉| 13472/15000 [1:25:41<04:33,  5.59it/s, lr=8.81e-6, step_loss=0.0407/18/2023 20:29:03 - INFO - __main__ - train loss is 11.85880962968804\n",
      "Steps:  90%|▉| 13473/15000 [1:25:41<04:32,  5.60it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:29:03 - INFO - __main__ - train loss is 12.077590773114935\n",
      "Steps:  90%|▉| 13474/15000 [1:25:41<04:32,  5.60it/s, lr=8.81e-6, step_loss=0.2107/18/2023 20:29:04 - INFO - __main__ - train loss is 12.565479407319799\n",
      "Steps:  90%|▉| 13475/15000 [1:25:42<04:31,  5.61it/s, lr=8.81e-6, step_loss=0.4807/18/2023 20:29:04 - INFO - __main__ - train loss is 12.57143670716323\n",
      "Steps:  90%|▉| 13476/15000 [1:25:42<04:31,  5.61it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:04 - INFO - __main__ - train loss is 12.58901259698905\n",
      "Steps:  90%|▉| 13477/15000 [1:25:42<04:31,  5.61it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:29:04 - INFO - __main__ - train loss is 12.613815549993888\n",
      "Steps:  90%|▉| 13478/15000 [1:25:42<04:31,  5.61it/s, lr=8.81e-6, step_loss=0.0207/18/2023 20:29:04 - INFO - __main__ - train loss is 12.774212811375037\n",
      "Steps:  90%|▉| 13479/15000 [1:25:42<04:30,  5.61it/s, lr=8.81e-6, step_loss=0.1607/18/2023 20:29:05 - INFO - __main__ - train loss is 12.813239686423913\n",
      "Steps:  90%|▉| 13480/15000 [1:25:42<04:30,  5.61it/s, lr=8.81e-6, step_loss=0.0307/18/2023 20:29:05 - INFO - __main__ - train loss is 12.995876454049721\n",
      "Steps:  90%|▉| 13481/15000 [1:25:43<04:30,  5.61it/s, lr=8.81e-6, step_loss=0.1807/18/2023 20:29:05 - INFO - __main__ - train loss is 13.001957649597898\n",
      "Steps:  90%|▉| 13482/15000 [1:25:43<04:30,  5.61it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:05 - INFO - __main__ - train loss is 13.21788183809258\n",
      "Steps:  90%|▉| 13483/15000 [1:25:43<06:03,  4.17it/s, lr=8.81e-6, step_loss=0.2107/18/2023 20:29:06 - INFO - __main__ - Per validation step average loss is 0.2117367833852768\n",
      "07/18/2023 20:29:06 - INFO - __main__ - Cumulative validation average loss is 0.2117367833852768\n",
      "07/18/2023 20:29:06 - INFO - __main__ - Per validation step average loss is 0.0029697504360228777\n",
      "07/18/2023 20:29:06 - INFO - __main__ - Cumulative validation average loss is 0.21470653382129967\n",
      "07/18/2023 20:29:06 - INFO - __main__ - Per validation step average loss is 0.2435293197631836\n",
      "07/18/2023 20:29:06 - INFO - __main__ - Cumulative validation average loss is 0.45823585358448327\n",
      "07/18/2023 20:29:06 - INFO - __main__ - Per validation step average loss is 0.038688745349645615\n",
      "07/18/2023 20:29:06 - INFO - __main__ - Cumulative validation average loss is 0.4969245989341289\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Per validation step average loss is 0.015532799065113068\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Cumulative validation average loss is 0.512457397999242\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Per validation step average loss is 0.015497558750212193\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Cumulative validation average loss is 0.5279549567494541\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Per validation step average loss is 0.3443033695220947\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Cumulative validation average loss is 0.8722583262715489\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Per validation step average loss is 0.28191980719566345\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Cumulative validation average loss is 1.1541781334672123\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Per validation step average loss is 0.25663769245147705\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Cumulative validation average loss is 1.4108158259186894\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Per validation step average loss is 0.3986765444278717\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Cumulative validation average loss is 1.809492370346561\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Per validation step average loss is 0.29761096835136414\n",
      "07/18/2023 20:29:07 - INFO - __main__ - Cumulative validation average loss is 2.107103338697925\n",
      "07/18/2023 20:29:08 - INFO - __main__ - Per validation step average loss is 0.1804681122303009\n",
      "07/18/2023 20:29:08 - INFO - __main__ - Cumulative validation average loss is 2.287571450928226\n",
      "07/18/2023 20:29:08 - INFO - __main__ - Average validation loss for Epoch 138 is 0.19063095424401885\n",
      "07/18/2023 20:29:08 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:29:21 - INFO - __main__ - Starting epoch 139\n",
      "07/18/2023 20:29:21 - INFO - __main__ - train loss is 0.2512347996234894\n",
      "Steps:  90%|▉| 13484/15000 [1:25:59<2:05:02,  4.95s/it, lr=8.81e-6, step_loss=0.07/18/2023 20:29:21 - INFO - __main__ - train loss is 0.40731698274612427\n",
      "Steps:  90%|▉| 13485/15000 [1:25:59<1:29:02,  3.53s/it, lr=8.81e-6, step_loss=0.07/18/2023 20:29:22 - INFO - __main__ - train loss is 0.9767904877662659\n",
      "Steps:  90%|▉| 13486/15000 [1:26:00<1:03:59,  2.54s/it, lr=8.81e-6, step_loss=0.07/18/2023 20:29:22 - INFO - __main__ - train loss is 1.0159596391022205\n",
      "Steps:  90%|▉| 13487/15000 [1:26:00<46:17,  1.84s/it, lr=8.81e-6, step_loss=0.0307/18/2023 20:29:22 - INFO - __main__ - train loss is 1.2113322503864765\n",
      "Steps:  90%|▉| 13488/15000 [1:26:00<33:57,  1.35s/it, lr=8.81e-6, step_loss=0.1907/18/2023 20:29:22 - INFO - __main__ - train loss is 1.256441693753004\n",
      "Steps:  90%|▉| 13489/15000 [1:26:00<25:27,  1.01s/it, lr=8.81e-6, step_loss=0.0407/18/2023 20:29:22 - INFO - __main__ - train loss is 1.3012927696108818\n",
      "Steps:  90%|▉| 13490/15000 [1:26:00<19:29,  1.29it/s, lr=8.81e-6, step_loss=0.0407/18/2023 20:29:23 - INFO - __main__ - train loss is 1.3060780577361584\n",
      "Steps:  90%|▉| 13491/15000 [1:26:01<15:19,  1.64it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:23 - INFO - __main__ - train loss is 1.343025516718626\n",
      "Steps:  90%|▉| 13492/15000 [1:26:01<12:23,  2.03it/s, lr=8.81e-6, step_loss=0.0307/18/2023 20:29:23 - INFO - __main__ - train loss is 1.7155932895839214\n",
      "Steps:  90%|▉| 13493/15000 [1:26:01<10:20,  2.43it/s, lr=8.81e-6, step_loss=0.3707/18/2023 20:29:23 - INFO - __main__ - train loss is 2.311104368418455\n",
      "Steps:  90%|▉| 13494/15000 [1:26:01<08:54,  2.82it/s, lr=8.81e-6, step_loss=0.5907/18/2023 20:29:24 - INFO - __main__ - train loss is 2.749514799565077\n",
      "Steps:  90%|▉| 13495/15000 [1:26:02<07:54,  3.17it/s, lr=8.81e-6, step_loss=0.4307/18/2023 20:29:24 - INFO - __main__ - train loss is 2.753012230154127\n",
      "Steps:  90%|▉| 13496/15000 [1:26:02<07:12,  3.47it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:24 - INFO - __main__ - train loss is 2.7662075865082443\n",
      "Steps:  90%|▉| 13497/15000 [1:26:02<06:41,  3.75it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:29:24 - INFO - __main__ - train loss is 3.0350196468643844\n",
      "Steps:  90%|▉| 13498/15000 [1:26:02<06:17,  3.98it/s, lr=8.81e-6, step_loss=0.2607/18/2023 20:29:24 - INFO - __main__ - train loss is 3.0370056312531233\n",
      "Steps:  90%|▉| 13499/15000 [1:26:02<05:54,  4.23it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:25 - INFO - __main__ - train loss is 3.7417429368942976\n",
      "Steps:  90%|▉| 13500/15000 [1:26:03<05:29,  4.55it/s, lr=8.81e-6, step_loss=0.0007/18/2023 20:29:25 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-13500\n",
      "07/18/2023 20:29:25 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:29:25,256] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:29:25,261] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-13500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:29:25,261] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-13500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:29:25,268] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-13500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:29:25,269] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-13500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:29:25,288] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-13500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:29:25,294] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-13500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:29:25,294] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:29:25 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-13500/pytorch_model\n",
      "07/18/2023 20:29:25 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-13500/scheduler.bin\n",
      "07/18/2023 20:29:25 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-13500/random_states_0.pkl\n",
      "07/18/2023 20:29:25 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-13500\n",
      "Steps:  90%|▉| 13500/15000 [1:26:03<05:29,  4.55it/s, lr=8.81e-6, step_loss=0.7007/18/2023 20:29:25 - INFO - __main__ - train loss is 3.862652374431491\n",
      "Steps:  90%|▉| 13501/15000 [1:26:03<05:28,  4.56it/s, lr=8.81e-6, step_loss=0.1207/18/2023 20:29:25 - INFO - __main__ - train loss is 4.589437557384372\n",
      "Steps:  90%|▉| 13502/15000 [1:26:03<05:10,  4.83it/s, lr=8.81e-6, step_loss=0.7207/18/2023 20:29:25 - INFO - __main__ - train loss is 4.606814870610833\n",
      "Steps:  90%|▉| 13503/15000 [1:26:03<04:57,  5.04it/s, lr=8.81e-6, step_loss=0.0107/18/2023 20:29:25 - INFO - __main__ - train loss is 4.880233505740762\n",
      "Steps:  90%|▉| 13504/15000 [1:26:03<04:48,  5.19it/s, lr=8.8e-6, step_loss=0.27307/18/2023 20:29:26 - INFO - __main__ - train loss is 5.052188390865922\n",
      "Steps:  90%|▉| 13505/15000 [1:26:03<04:41,  5.31it/s, lr=8.8e-6, step_loss=0.17207/18/2023 20:29:26 - INFO - __main__ - train loss is 5.122197667136788\n",
      "Steps:  90%|▉| 13506/15000 [1:26:04<04:37,  5.39it/s, lr=8.8e-6, step_loss=0.07]07/18/2023 20:29:26 - INFO - __main__ - train loss is 5.152948398143053\n",
      "Steps:  90%|▉| 13507/15000 [1:26:04<04:34,  5.45it/s, lr=8.8e-6, step_loss=0.03007/18/2023 20:29:26 - INFO - __main__ - train loss is 5.736393112689257\n",
      "Steps:  90%|▉| 13508/15000 [1:26:04<04:34,  5.44it/s, lr=8.8e-6, step_loss=0.58307/18/2023 20:29:26 - INFO - __main__ - train loss is 5.763757839798927\n",
      "Steps:  90%|▉| 13509/15000 [1:26:04<04:32,  5.48it/s, lr=8.8e-6, step_loss=0.02707/18/2023 20:29:27 - INFO - __main__ - train loss is 6.316856995224953\n",
      "Steps:  90%|▉| 13510/15000 [1:26:04<04:32,  5.47it/s, lr=8.8e-6, step_loss=0.55307/18/2023 20:29:27 - INFO - __main__ - train loss is 6.41824109852314\n",
      "Steps:  90%|▉| 13511/15000 [1:26:05<04:32,  5.46it/s, lr=8.8e-6, step_loss=0.10107/18/2023 20:29:27 - INFO - __main__ - train loss is 6.518403962254524\n",
      "Steps:  90%|█▊| 13512/15000 [1:26:05<04:34,  5.43it/s, lr=8.8e-6, step_loss=0.1]07/18/2023 20:29:27 - INFO - __main__ - train loss is 6.522930139675736\n",
      "Steps:  90%|▉| 13513/15000 [1:26:05<04:32,  5.46it/s, lr=8.8e-6, step_loss=0.00407/18/2023 20:29:27 - INFO - __main__ - train loss is 6.524763310677372\n",
      "Steps:  90%|▉| 13514/15000 [1:26:05<04:30,  5.50it/s, lr=8.8e-6, step_loss=0.00107/18/2023 20:29:27 - INFO - __main__ - train loss is 6.556657309061848\n",
      "Steps:  90%|▉| 13515/15000 [1:26:05<04:30,  5.49it/s, lr=8.8e-6, step_loss=0.03107/18/2023 20:29:28 - INFO - __main__ - train loss is 6.712156871682964\n",
      "Steps:  90%|▉| 13516/15000 [1:26:05<04:31,  5.47it/s, lr=8.8e-6, step_loss=0.15507/18/2023 20:29:28 - INFO - __main__ - train loss is 6.733236151165329\n",
      "Steps:  90%|▉| 13517/15000 [1:26:06<04:34,  5.41it/s, lr=8.8e-6, step_loss=0.02107/18/2023 20:29:28 - INFO - __main__ - train loss is 6.889322044677101\n",
      "Steps:  90%|▉| 13518/15000 [1:26:06<04:31,  5.46it/s, lr=8.8e-6, step_loss=0.15607/18/2023 20:29:28 - INFO - __main__ - train loss is 6.893267628620379\n",
      "Steps:  90%|▉| 13519/15000 [1:26:06<04:29,  5.50it/s, lr=8.8e-6, step_loss=0.00307/18/2023 20:29:28 - INFO - __main__ - train loss is 6.897108981036581\n",
      "Steps:  90%|▉| 13520/15000 [1:26:06<04:29,  5.50it/s, lr=8.8e-6, step_loss=0.00307/18/2023 20:29:29 - INFO - __main__ - train loss is 6.901239849277772\n",
      "Steps:  90%|▉| 13521/15000 [1:26:06<04:30,  5.47it/s, lr=8.8e-6, step_loss=0.00407/18/2023 20:29:29 - INFO - __main__ - train loss is 6.918185291462578\n",
      "Steps:  90%|▉| 13522/15000 [1:26:07<04:29,  5.49it/s, lr=8.8e-6, step_loss=0.01607/18/2023 20:29:29 - INFO - __main__ - train loss is 6.9437884237850085\n",
      "Steps:  90%|▉| 13523/15000 [1:26:07<04:27,  5.52it/s, lr=8.8e-6, step_loss=0.02507/18/2023 20:29:29 - INFO - __main__ - train loss is 6.946843821904622\n",
      "Steps:  90%|▉| 13524/15000 [1:26:07<04:25,  5.55it/s, lr=8.8e-6, step_loss=0.00307/18/2023 20:29:29 - INFO - __main__ - train loss is 7.163244892260991\n",
      "Steps:  90%|▉| 13525/15000 [1:26:07<04:26,  5.53it/s, lr=8.8e-6, step_loss=0.21607/18/2023 20:29:29 - INFO - __main__ - train loss is 7.222152840695344\n",
      "Steps:  90%|▉| 13526/15000 [1:26:07<04:28,  5.49it/s, lr=8.8e-6, step_loss=0.05807/18/2023 20:29:30 - INFO - __main__ - train loss is 7.275867071351968\n",
      "Steps:  90%|▉| 13527/15000 [1:26:07<04:26,  5.52it/s, lr=8.8e-6, step_loss=0.05307/18/2023 20:29:30 - INFO - __main__ - train loss is 7.7876057889079675\n",
      "Steps:  90%|▉| 13528/15000 [1:26:08<04:25,  5.54it/s, lr=8.8e-6, step_loss=0.51207/18/2023 20:29:30 - INFO - __main__ - train loss is 7.912828933796845\n",
      "Steps:  90%|▉| 13529/15000 [1:26:08<04:24,  5.55it/s, lr=8.8e-6, step_loss=0.12507/18/2023 20:29:30 - INFO - __main__ - train loss is 7.956796225509606\n",
      "Steps:  90%|▉| 13530/15000 [1:26:08<04:24,  5.57it/s, lr=8.8e-6, step_loss=0.04407/18/2023 20:29:30 - INFO - __main__ - train loss is 8.024148527882062\n",
      "Steps:  90%|▉| 13531/15000 [1:26:08<04:23,  5.58it/s, lr=8.8e-6, step_loss=0.06707/18/2023 20:29:30 - INFO - __main__ - train loss is 8.035188766545616\n",
      "Steps:  90%|▉| 13532/15000 [1:26:08<04:22,  5.58it/s, lr=8.8e-6, step_loss=0.01107/18/2023 20:29:31 - INFO - __main__ - train loss is 8.119960086769424\n",
      "Steps:  90%|▉| 13533/15000 [1:26:09<04:23,  5.57it/s, lr=8.8e-6, step_loss=0.08407/18/2023 20:29:31 - INFO - __main__ - train loss is 8.140020067221485\n",
      "Steps:  90%|▉| 13534/15000 [1:26:09<04:22,  5.58it/s, lr=8.8e-6, step_loss=0.02007/18/2023 20:29:31 - INFO - __main__ - train loss is 8.286743680364452\n",
      "Steps:  90%|▉| 13535/15000 [1:26:09<04:22,  5.59it/s, lr=8.8e-6, step_loss=0.14707/18/2023 20:29:31 - INFO - __main__ - train loss is 8.761002699262463\n",
      "Steps:  90%|▉| 13536/15000 [1:26:09<04:21,  5.59it/s, lr=8.8e-6, step_loss=0.47407/18/2023 20:29:31 - INFO - __main__ - train loss is 8.83035371673759\n",
      "Steps:  90%|▉| 13537/15000 [1:26:09<04:24,  5.53it/s, lr=8.8e-6, step_loss=0.06907/18/2023 20:29:32 - INFO - __main__ - train loss is 8.926965045160614\n",
      "Steps:  90%|▉| 13538/15000 [1:26:09<04:24,  5.53it/s, lr=8.8e-6, step_loss=0.09607/18/2023 20:29:32 - INFO - __main__ - train loss is 9.090849699801765\n",
      "Steps:  90%|▉| 13539/15000 [1:26:10<04:23,  5.55it/s, lr=8.8e-6, step_loss=0.16407/18/2023 20:29:32 - INFO - __main__ - train loss is 9.19809851271566\n",
      "Steps:  90%|▉| 13540/15000 [1:26:10<04:22,  5.57it/s, lr=8.8e-6, step_loss=0.10707/18/2023 20:29:32 - INFO - __main__ - train loss is 9.204300529207103\n",
      "Steps:  90%|▉| 13541/15000 [1:26:10<04:21,  5.58it/s, lr=8.8e-6, step_loss=0.00607/18/2023 20:29:32 - INFO - __main__ - train loss is 9.217240904341452\n",
      "Steps:  90%|▉| 13542/15000 [1:26:10<04:21,  5.58it/s, lr=8.8e-6, step_loss=0.01207/18/2023 20:29:32 - INFO - __main__ - train loss is 9.357279454241507\n",
      "Steps:  90%|▉| 13543/15000 [1:26:10<04:23,  5.53it/s, lr=8.8e-6, step_loss=0.14]07/18/2023 20:29:33 - INFO - __main__ - train loss is 9.440096025238745\n",
      "Steps:  90%|▉| 13544/15000 [1:26:11<04:26,  5.46it/s, lr=8.8e-6, step_loss=0.08207/18/2023 20:29:33 - INFO - __main__ - train loss is 9.457411412964575\n",
      "Steps:  90%|▉| 13545/15000 [1:26:11<04:28,  5.41it/s, lr=8.8e-6, step_loss=0.01707/18/2023 20:29:33 - INFO - __main__ - train loss is 9.829072062741034\n",
      "Steps:  90%|▉| 13546/15000 [1:26:11<04:30,  5.38it/s, lr=8.8e-6, step_loss=0.37207/18/2023 20:29:33 - INFO - __main__ - train loss is 9.889823668519966\n",
      "Steps:  90%|▉| 13547/15000 [1:26:11<04:27,  5.43it/s, lr=8.8e-6, step_loss=0.06007/18/2023 20:29:33 - INFO - __main__ - train loss is 10.03341098956298\n",
      "Steps:  90%|▉| 13548/15000 [1:26:11<04:24,  5.48it/s, lr=8.8e-6, step_loss=0.14407/18/2023 20:29:34 - INFO - __main__ - train loss is 10.347265296499245\n",
      "Steps:  90%|▉| 13549/15000 [1:26:11<04:23,  5.52it/s, lr=8.8e-6, step_loss=0.31407/18/2023 20:29:34 - INFO - __main__ - train loss is 10.698033564607613\n",
      "Steps:  90%|▉| 13550/15000 [1:26:12<04:21,  5.54it/s, lr=8.8e-6, step_loss=0.35107/18/2023 20:29:34 - INFO - __main__ - train loss is 10.703354203957133\n",
      "Steps:  90%|▉| 13551/15000 [1:26:12<04:23,  5.51it/s, lr=8.8e-6, step_loss=0.00507/18/2023 20:29:34 - INFO - __main__ - train loss is 10.723735218751244\n",
      "Steps:  90%|▉| 13552/15000 [1:26:12<04:25,  5.44it/s, lr=8.8e-6, step_loss=0.02007/18/2023 20:29:34 - INFO - __main__ - train loss is 10.731144852819853\n",
      "Steps:  90%|▉| 13553/15000 [1:26:12<04:25,  5.46it/s, lr=8.8e-6, step_loss=0.00707/18/2023 20:29:34 - INFO - __main__ - train loss is 10.739414861309342\n",
      "Steps:  90%|▉| 13554/15000 [1:26:12<04:22,  5.50it/s, lr=8.8e-6, step_loss=0.00807/18/2023 20:29:35 - INFO - __main__ - train loss is 10.758049467462115\n",
      "Steps:  90%|▉| 13555/15000 [1:26:13<04:21,  5.53it/s, lr=8.8e-6, step_loss=0.01807/18/2023 20:29:35 - INFO - __main__ - train loss is 10.79122706677299\n",
      "Steps:  90%|▉| 13556/15000 [1:26:13<04:20,  5.55it/s, lr=8.8e-6, step_loss=0.03307/18/2023 20:29:35 - INFO - __main__ - train loss is 11.216506982105784\n",
      "Steps:  90%|▉| 13557/15000 [1:26:13<04:19,  5.57it/s, lr=8.8e-6, step_loss=0.42507/18/2023 20:29:35 - INFO - __main__ - train loss is 11.23589906457346\n",
      "Steps:  90%|▉| 13558/15000 [1:26:13<04:18,  5.58it/s, lr=8.8e-6, step_loss=0.01907/18/2023 20:29:35 - INFO - __main__ - train loss is 11.357332873973064\n",
      "Steps:  90%|▉| 13559/15000 [1:26:13<04:18,  5.58it/s, lr=8.8e-6, step_loss=0.12107/18/2023 20:29:36 - INFO - __main__ - train loss is 11.366907706367783\n",
      "Steps:  90%|▉| 13560/15000 [1:26:13<04:17,  5.59it/s, lr=8.8e-6, step_loss=0.00907/18/2023 20:29:36 - INFO - __main__ - train loss is 11.37527503434103\n",
      "Steps:  90%|▉| 13561/15000 [1:26:14<04:17,  5.59it/s, lr=8.8e-6, step_loss=0.00807/18/2023 20:29:36 - INFO - __main__ - train loss is 11.396982680889778\n",
      "Steps:  90%|▉| 13562/15000 [1:26:14<04:16,  5.60it/s, lr=8.8e-6, step_loss=0.02107/18/2023 20:29:36 - INFO - __main__ - train loss is 11.405914749833755\n",
      "Steps:  90%|▉| 13563/15000 [1:26:14<04:16,  5.60it/s, lr=8.79e-6, step_loss=0.0007/18/2023 20:29:36 - INFO - __main__ - train loss is 11.528635363909416\n",
      "Steps:  90%|▉| 13564/15000 [1:26:14<04:16,  5.60it/s, lr=8.79e-6, step_loss=0.1207/18/2023 20:29:36 - INFO - __main__ - train loss is 12.370678584906273\n",
      "Steps:  90%|▉| 13565/15000 [1:26:14<04:16,  5.61it/s, lr=8.79e-6, step_loss=0.8407/18/2023 20:29:37 - INFO - __main__ - train loss is 12.519018869730644\n",
      "Steps:  90%|▉| 13566/15000 [1:26:15<04:17,  5.56it/s, lr=8.79e-6, step_loss=0.1407/18/2023 20:29:37 - INFO - __main__ - train loss is 12.5840333661763\n",
      "Steps:  90%|▉| 13567/15000 [1:26:15<04:16,  5.58it/s, lr=8.79e-6, step_loss=0.0607/18/2023 20:29:37 - INFO - __main__ - train loss is 12.650315318140201\n",
      "Steps:  90%|▉| 13568/15000 [1:26:15<04:16,  5.59it/s, lr=8.79e-6, step_loss=0.0607/18/2023 20:29:37 - INFO - __main__ - train loss is 12.718351948889904\n",
      "Steps:  90%|▉| 13569/15000 [1:26:15<04:15,  5.60it/s, lr=8.79e-6, step_loss=0.0607/18/2023 20:29:37 - INFO - __main__ - train loss is 12.863040465745144\n",
      "Steps:  90%|▉| 13570/15000 [1:26:15<04:15,  5.61it/s, lr=8.79e-6, step_loss=0.1407/18/2023 20:29:38 - INFO - __main__ - train loss is 13.067569274338894\n",
      "Steps:  90%|▉| 13571/15000 [1:26:15<04:14,  5.61it/s, lr=8.79e-6, step_loss=0.2007/18/2023 20:29:38 - INFO - __main__ - train loss is 13.286429140600376\n",
      "Steps:  90%|▉| 13572/15000 [1:26:16<04:14,  5.61it/s, lr=8.79e-6, step_loss=0.2107/18/2023 20:29:38 - INFO - __main__ - train loss is 13.28938664298039\n",
      "Steps:  90%|▉| 13573/15000 [1:26:16<04:14,  5.61it/s, lr=8.79e-6, step_loss=0.0007/18/2023 20:29:38 - INFO - __main__ - train loss is 13.439897788572125\n",
      "Steps:  90%|▉| 13574/15000 [1:26:16<04:14,  5.61it/s, lr=8.79e-6, step_loss=0.1507/18/2023 20:29:38 - INFO - __main__ - train loss is 13.570204002666287\n",
      "Steps:  90%|▉| 13575/15000 [1:26:16<04:13,  5.62it/s, lr=8.79e-6, step_loss=0.1307/18/2023 20:29:38 - INFO - __main__ - train loss is 13.66598093311768\n",
      "Steps:  91%|▉| 13576/15000 [1:26:16<04:13,  5.62it/s, lr=8.79e-6, step_loss=0.0907/18/2023 20:29:39 - INFO - __main__ - train loss is 13.782556502032094\n",
      "Steps:  91%|▉| 13577/15000 [1:26:16<04:13,  5.61it/s, lr=8.79e-6, step_loss=0.1107/18/2023 20:29:39 - INFO - __main__ - train loss is 13.80784948344808\n",
      "Steps:  91%|▉| 13578/15000 [1:26:17<04:16,  5.55it/s, lr=8.79e-6, step_loss=0.0207/18/2023 20:29:39 - INFO - __main__ - train loss is 13.813678906182759\n",
      "Steps:  91%|▉| 13579/15000 [1:26:17<04:16,  5.54it/s, lr=8.79e-6, step_loss=0.0007/18/2023 20:29:39 - INFO - __main__ - train loss is 14.029562816838734\n",
      "Steps:  91%|▉| 13580/15000 [1:26:17<05:46,  4.10it/s, lr=8.79e-6, step_loss=0.2107/18/2023 20:29:40 - INFO - __main__ - Per validation step average loss is 0.014269380830228329\n",
      "07/18/2023 20:29:40 - INFO - __main__ - Cumulative validation average loss is 0.014269380830228329\n",
      "07/18/2023 20:29:40 - INFO - __main__ - Per validation step average loss is 0.0045242831110954285\n",
      "07/18/2023 20:29:40 - INFO - __main__ - Cumulative validation average loss is 0.018793663941323757\n",
      "07/18/2023 20:29:40 - INFO - __main__ - Per validation step average loss is 0.12694373726844788\n",
      "07/18/2023 20:29:40 - INFO - __main__ - Cumulative validation average loss is 0.14573740120977163\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Per validation step average loss is 0.003988579846918583\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Cumulative validation average loss is 0.14972598105669022\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Per validation step average loss is 0.0812004953622818\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Cumulative validation average loss is 0.23092647641897202\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Per validation step average loss is 0.23906826972961426\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Cumulative validation average loss is 0.4699947461485863\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Per validation step average loss is 0.042877040803432465\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Cumulative validation average loss is 0.5128717869520187\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Per validation step average loss is 0.0017983142752200365\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Cumulative validation average loss is 0.5146701012272388\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Per validation step average loss is 0.11918002367019653\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Cumulative validation average loss is 0.6338501248974353\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Per validation step average loss is 0.014296479523181915\n",
      "07/18/2023 20:29:41 - INFO - __main__ - Cumulative validation average loss is 0.6481466044206172\n",
      "07/18/2023 20:29:42 - INFO - __main__ - Per validation step average loss is 0.30191874504089355\n",
      "07/18/2023 20:29:42 - INFO - __main__ - Cumulative validation average loss is 0.9500653494615108\n",
      "07/18/2023 20:29:42 - INFO - __main__ - Per validation step average loss is 0.04456787928938866\n",
      "07/18/2023 20:29:42 - INFO - __main__ - Cumulative validation average loss is 0.9946332287508994\n",
      "07/18/2023 20:29:42 - INFO - __main__ - Average validation loss for Epoch 139 is 0.08288610239590828\n",
      "07/18/2023 20:29:42 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:29:55 - INFO - __main__ - Starting epoch 140\n",
      "07/18/2023 20:29:56 - INFO - __main__ - train loss is 0.04299170523881912\n",
      "Steps:  91%|▉| 13581/15000 [1:26:34<2:00:35,  5.10s/it, lr=8.79e-6, step_loss=0.07/18/2023 20:29:56 - INFO - __main__ - train loss is 0.04516694648191333\n",
      "Steps:  91%|▉| 13582/15000 [1:26:34<1:28:11,  3.73s/it, lr=8.79e-6, step_loss=0.07/18/2023 20:29:57 - INFO - __main__ - train loss is 0.5549735794775188\n",
      "Steps:  91%|▉| 13583/15000 [1:26:35<1:05:34,  2.78s/it, lr=8.79e-6, step_loss=0.07/18/2023 20:29:57 - INFO - __main__ - train loss is 0.6124626244418323\n",
      "Steps:  91%|▉| 13584/15000 [1:26:35<49:42,  2.11s/it, lr=8.79e-6, step_loss=0.0507/18/2023 20:29:58 - INFO - __main__ - train loss is 0.679384886752814\n",
      "Steps:  91%|▉| 13585/15000 [1:26:36<38:44,  1.64s/it, lr=8.79e-6, step_loss=0.0607/18/2023 20:29:59 - INFO - __main__ - train loss is 0.6840860364027321\n",
      "Steps:  91%|▉| 13586/15000 [1:26:36<30:56,  1.31s/it, lr=8.79e-6, step_loss=0.0007/18/2023 20:29:59 - INFO - __main__ - train loss is 0.878847983200103\n",
      "Steps:  91%|▉| 13587/15000 [1:26:37<25:25,  1.08s/it, lr=8.79e-6, step_loss=0.1907/18/2023 20:30:00 - INFO - __main__ - train loss is 1.159464415628463\n",
      "Steps:  91%|▉| 13588/15000 [1:26:37<21:36,  1.09it/s, lr=8.79e-6, step_loss=0.2807/18/2023 20:30:00 - INFO - __main__ - train loss is 1.1878629853017628\n",
      "Steps:  91%|▉| 13589/15000 [1:26:38<19:01,  1.24it/s, lr=8.79e-6, step_loss=0.0207/18/2023 20:30:01 - INFO - __main__ - train loss is 1.5450256993062794\n",
      "Steps:  91%|▉| 13590/15000 [1:26:39<17:10,  1.37it/s, lr=8.79e-6, step_loss=0.3507/18/2023 20:30:01 - INFO - __main__ - train loss is 1.5662905392237008\n",
      "Steps:  91%|▉| 13591/15000 [1:26:39<15:48,  1.49it/s, lr=8.79e-6, step_loss=0.0207/18/2023 20:30:02 - INFO - __main__ - train loss is 1.7337256637401879\n",
      "Steps:  91%|▉| 13592/15000 [1:26:40<14:53,  1.58it/s, lr=8.79e-6, step_loss=0.1607/18/2023 20:30:02 - INFO - __main__ - train loss is 1.7853623894043267\n",
      "Steps:  91%|▉| 13593/15000 [1:26:40<14:15,  1.64it/s, lr=8.79e-6, step_loss=0.0507/18/2023 20:30:03 - INFO - __main__ - train loss is 1.7952889637090266\n",
      "Steps:  91%|▉| 13594/15000 [1:26:41<13:49,  1.70it/s, lr=8.79e-6, step_loss=0.0007/18/2023 20:30:03 - INFO - __main__ - train loss is 2.0387614951469004\n",
      "Steps:  91%|▉| 13595/15000 [1:26:41<13:28,  1.74it/s, lr=8.79e-6, step_loss=0.2407/18/2023 20:30:04 - INFO - __main__ - train loss is 2.0511007071472704\n",
      "Steps:  91%|▉| 13596/15000 [1:26:42<13:13,  1.77it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:05 - INFO - __main__ - train loss is 2.0625786618329585\n",
      "Steps:  91%|▉| 13597/15000 [1:26:42<13:05,  1.79it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:05 - INFO - __main__ - train loss is 2.153960464987904\n",
      "Steps:  91%|▉| 13598/15000 [1:26:43<12:59,  1.80it/s, lr=8.79e-6, step_loss=0.0907/18/2023 20:30:06 - INFO - __main__ - train loss is 2.1717453193850815\n",
      "Steps:  91%|▉| 13599/15000 [1:26:43<12:51,  1.82it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:06 - INFO - __main__ - train loss is 2.2377126407809556\n",
      "Steps:  91%|▉| 13600/15000 [1:26:44<12:47,  1.83it/s, lr=8.79e-6, step_loss=0.0607/18/2023 20:30:07 - INFO - __main__ - train loss is 2.2499266215600073\n",
      "Steps:  91%|▉| 13601/15000 [1:26:45<13:03,  1.79it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:07 - INFO - __main__ - train loss is 2.253028782783076\n",
      "Steps:  91%|▉| 13602/15000 [1:26:45<13:36,  1.71it/s, lr=8.79e-6, step_loss=0.0007/18/2023 20:30:08 - INFO - __main__ - train loss is 2.2662589240353554\n",
      "Steps:  91%|▉| 13603/15000 [1:26:46<13:17,  1.75it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:08 - INFO - __main__ - train loss is 2.278750462224707\n",
      "Steps:  91%|▉| 13604/15000 [1:26:46<13:03,  1.78it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:09 - INFO - __main__ - train loss is 2.5315950044896454\n",
      "Steps:  91%|▉| 13605/15000 [1:26:47<12:54,  1.80it/s, lr=8.79e-6, step_loss=0.2507/18/2023 20:30:10 - INFO - __main__ - train loss is 2.5410269869025797\n",
      "Steps:  91%|▉| 13606/15000 [1:26:47<12:53,  1.80it/s, lr=8.79e-6, step_loss=0.0007/18/2023 20:30:10 - INFO - __main__ - train loss is 2.5765707043465227\n",
      "Steps:  91%|▉| 13607/15000 [1:26:48<12:48,  1.81it/s, lr=8.79e-6, step_loss=0.0307/18/2023 20:30:11 - INFO - __main__ - train loss is 2.7878222016151994\n",
      "Steps:  91%|▉| 13608/15000 [1:26:49<12:44,  1.82it/s, lr=8.79e-6, step_loss=0.2107/18/2023 20:30:11 - INFO - __main__ - train loss is 2.8141470884438604\n",
      "Steps:  91%|▉| 13609/15000 [1:26:49<12:40,  1.83it/s, lr=8.79e-6, step_loss=0.0207/18/2023 20:30:12 - INFO - __main__ - train loss is 2.851905215298757\n",
      "Steps:  91%|▉| 13610/15000 [1:26:50<12:35,  1.84it/s, lr=8.79e-6, step_loss=0.0307/18/2023 20:30:12 - INFO - __main__ - train loss is 3.071435514604673\n",
      "Steps:  91%|▉| 13611/15000 [1:26:50<12:34,  1.84it/s, lr=8.79e-6, step_loss=0.2207/18/2023 20:30:13 - INFO - __main__ - train loss is 3.6991248761769384\n",
      "Steps:  91%|▉| 13612/15000 [1:26:51<12:34,  1.84it/s, lr=8.79e-6, step_loss=0.6207/18/2023 20:30:13 - INFO - __main__ - train loss is 3.71116155362688\n",
      "Steps:  91%|▉| 13613/15000 [1:26:51<12:31,  1.85it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:14 - INFO - __main__ - train loss is 3.9076179263647646\n",
      "Steps:  91%|▉| 13614/15000 [1:26:52<12:32,  1.84it/s, lr=8.79e-6, step_loss=0.1907/18/2023 20:30:14 - INFO - __main__ - train loss is 3.9099020997527987\n",
      "Steps:  91%|▉| 13615/15000 [1:26:52<12:31,  1.84it/s, lr=8.79e-6, step_loss=0.0007/18/2023 20:30:15 - INFO - __main__ - train loss is 4.323929194593802\n",
      "Steps:  91%|▉| 13616/15000 [1:26:53<12:31,  1.84it/s, lr=8.79e-6, step_loss=0.4107/18/2023 20:30:15 - INFO - __main__ - train loss is 4.380551889771596\n",
      "Steps:  91%|▉| 13617/15000 [1:26:53<12:30,  1.84it/s, lr=8.79e-6, step_loss=0.0507/18/2023 20:30:16 - INFO - __main__ - train loss is 4.450512573355809\n",
      "Steps:  91%|▉| 13618/15000 [1:26:54<12:30,  1.84it/s, lr=8.79e-6, step_loss=0.0707/18/2023 20:30:17 - INFO - __main__ - train loss is 4.463520847493783\n",
      "Steps:  91%|▉| 13619/15000 [1:26:54<12:30,  1.84it/s, lr=8.79e-6, step_loss=0.0107/18/2023 20:30:17 - INFO - __main__ - train loss is 4.51418162160553\n",
      "Steps:  91%|▉| 13620/15000 [1:26:55<12:28,  1.84it/s, lr=8.79e-6, step_loss=0.0507/18/2023 20:30:18 - INFO - __main__ - train loss is 4.537105884635821\n",
      "Steps:  91%|▉| 13621/15000 [1:26:56<12:29,  1.84it/s, lr=8.78e-6, step_loss=0.0207/18/2023 20:30:18 - INFO - __main__ - train loss is 4.7374641264323145\n",
      "Steps:  91%|▉| 13622/15000 [1:26:56<12:33,  1.83it/s, lr=8.78e-6, step_loss=0.2]07/18/2023 20:30:19 - INFO - __main__ - train loss is 4.744856264209375\n",
      "Steps:  91%|▉| 13623/15000 [1:26:57<13:34,  1.69it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:20 - INFO - __main__ - train loss is 5.0793658753391355\n",
      "Steps:  91%|▉| 13624/15000 [1:26:57<13:46,  1.67it/s, lr=8.78e-6, step_loss=0.3307/18/2023 20:30:20 - INFO - __main__ - train loss is 5.116125773405656\n",
      "Steps:  91%|▉| 13625/15000 [1:26:58<13:56,  1.64it/s, lr=8.78e-6, step_loss=0.0307/18/2023 20:30:21 - INFO - __main__ - train loss is 5.125059373443946\n",
      "Steps:  91%|▉| 13626/15000 [1:26:59<13:33,  1.69it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:21 - INFO - __main__ - train loss is 5.13871968886815\n",
      "Steps:  91%|▉| 13627/15000 [1:26:59<13:10,  1.74it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:22 - INFO - __main__ - train loss is 5.173764589941129\n",
      "Steps:  91%|▉| 13628/15000 [1:27:00<13:01,  1.76it/s, lr=8.78e-6, step_loss=0.0307/18/2023 20:30:22 - INFO - __main__ - train loss is 5.188977763755247\n",
      "Steps:  91%|▉| 13629/15000 [1:27:00<12:49,  1.78it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:23 - INFO - __main__ - train loss is 5.19163804105483\n",
      "Steps:  91%|▉| 13630/15000 [1:27:01<12:39,  1.80it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:23 - INFO - __main__ - train loss is 5.5487552469130605\n",
      "Steps:  91%|▉| 13631/15000 [1:27:01<12:34,  1.81it/s, lr=8.78e-6, step_loss=0.3507/18/2023 20:30:24 - INFO - __main__ - train loss is 5.834160405909643\n",
      "Steps:  91%|▉| 13632/15000 [1:27:02<12:31,  1.82it/s, lr=8.78e-6, step_loss=0.2807/18/2023 20:30:25 - INFO - __main__ - train loss is 6.3131441657897085\n",
      "Steps:  91%|▉| 13633/15000 [1:27:02<12:29,  1.82it/s, lr=8.78e-6, step_loss=0.4707/18/2023 20:30:25 - INFO - __main__ - train loss is 6.474426585948095\n",
      "Steps:  91%|▉| 13634/15000 [1:27:03<12:23,  1.84it/s, lr=8.78e-6, step_loss=0.1607/18/2023 20:30:26 - INFO - __main__ - train loss is 6.481703992700204\n",
      "Steps:  91%|▉| 13635/15000 [1:27:04<12:25,  1.83it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:26 - INFO - __main__ - train loss is 6.722920801257715\n",
      "Steps:  91%|▉| 13636/15000 [1:27:04<12:26,  1.83it/s, lr=8.78e-6, step_loss=0.2407/18/2023 20:30:27 - INFO - __main__ - train loss is 6.774514365708455\n",
      "Steps:  91%|▉| 13637/15000 [1:27:05<12:24,  1.83it/s, lr=8.78e-6, step_loss=0.0507/18/2023 20:30:27 - INFO - __main__ - train loss is 6.841292079305276\n",
      "Steps:  91%|▉| 13638/15000 [1:27:05<12:25,  1.83it/s, lr=8.78e-6, step_loss=0.0607/18/2023 20:30:28 - INFO - __main__ - train loss is 6.976749818539247\n",
      "Steps:  91%|▉| 13639/15000 [1:27:06<12:23,  1.83it/s, lr=8.78e-6, step_loss=0.1307/18/2023 20:30:28 - INFO - __main__ - train loss is 7.009734466439113\n",
      "Steps:  91%|▉| 13640/15000 [1:27:06<12:22,  1.83it/s, lr=8.78e-6, step_loss=0.0307/18/2023 20:30:29 - INFO - __main__ - train loss is 7.028109302511439\n",
      "Steps:  91%|▉| 13641/15000 [1:27:07<12:19,  1.84it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:29 - INFO - __main__ - train loss is 7.4756695532705635\n",
      "Steps:  91%|▉| 13642/15000 [1:27:07<12:17,  1.84it/s, lr=8.78e-6, step_loss=0.4407/18/2023 20:30:30 - INFO - __main__ - train loss is 7.94145887135528\n",
      "Steps:  91%|▉| 13643/15000 [1:27:08<12:16,  1.84it/s, lr=8.78e-6, step_loss=0.4607/18/2023 20:30:31 - INFO - __main__ - train loss is 8.069354539504275\n",
      "Steps:  91%|▉| 13644/15000 [1:27:08<12:13,  1.85it/s, lr=8.78e-6, step_loss=0.1207/18/2023 20:30:31 - INFO - __main__ - train loss is 8.095042219152674\n",
      "Steps:  91%|▉| 13645/15000 [1:27:09<12:15,  1.84it/s, lr=8.78e-6, step_loss=0.0207/18/2023 20:30:32 - INFO - __main__ - train loss is 8.100431241793558\n",
      "Steps:  91%|▉| 13646/15000 [1:27:09<12:14,  1.84it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:32 - INFO - __main__ - train loss is 8.432535447878763\n",
      "Steps:  91%|▉| 13647/15000 [1:27:10<12:10,  1.85it/s, lr=8.78e-6, step_loss=0.3307/18/2023 20:30:33 - INFO - __main__ - train loss is 8.4431394233834\n",
      "Steps:  91%|▉| 13648/15000 [1:27:11<12:11,  1.85it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:33 - INFO - __main__ - train loss is 8.665182043565437\n",
      "Steps:  91%|▉| 13649/15000 [1:27:11<12:13,  1.84it/s, lr=8.78e-6, step_loss=0.2207/18/2023 20:30:34 - INFO - __main__ - train loss is 8.695148148341104\n",
      "Steps:  91%|▉| 13650/15000 [1:27:12<12:13,  1.84it/s, lr=8.78e-6, step_loss=0.0307/18/2023 20:30:34 - INFO - __main__ - train loss is 8.939129658741876\n",
      "Steps:  91%|▉| 13651/15000 [1:27:12<12:16,  1.83it/s, lr=8.78e-6, step_loss=0.2407/18/2023 20:30:35 - INFO - __main__ - train loss is 9.04026121716015\n",
      "Steps:  91%|▉| 13652/15000 [1:27:13<12:16,  1.83it/s, lr=8.78e-6, step_loss=0.1007/18/2023 20:30:35 - INFO - __main__ - train loss is 9.163248964352533\n",
      "Steps:  91%|▉| 13653/15000 [1:27:13<12:32,  1.79it/s, lr=8.78e-6, step_loss=0.1207/18/2023 20:30:36 - INFO - __main__ - train loss is 9.201470573199913\n",
      "Steps:  91%|▉| 13654/15000 [1:27:14<12:44,  1.76it/s, lr=8.78e-6, step_loss=0.0307/18/2023 20:30:37 - INFO - __main__ - train loss is 9.477323432220146\n",
      "Steps:  91%|▉| 13655/15000 [1:27:14<12:37,  1.77it/s, lr=8.78e-6, step_loss=0.2707/18/2023 20:30:37 - INFO - __main__ - train loss is 9.559729967964813\n",
      "Steps:  91%|▉| 13656/15000 [1:27:15<12:37,  1.77it/s, lr=8.78e-6, step_loss=0.0807/18/2023 20:30:38 - INFO - __main__ - train loss is 9.576399233890697\n",
      "Steps:  91%|▉| 13657/15000 [1:27:16<12:41,  1.76it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:38 - INFO - __main__ - train loss is 9.589840817032382\n",
      "Steps:  91%|▉| 13658/15000 [1:27:16<12:33,  1.78it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:39 - INFO - __main__ - train loss is 9.897021191893145\n",
      "Steps:  91%|▉| 13659/15000 [1:27:17<12:30,  1.79it/s, lr=8.78e-6, step_loss=0.3007/18/2023 20:30:39 - INFO - __main__ - train loss is 10.103118526516482\n",
      "Steps:  91%|▉| 13660/15000 [1:27:17<12:26,  1.80it/s, lr=8.78e-6, step_loss=0.2007/18/2023 20:30:40 - INFO - __main__ - train loss is 10.11234669177793\n",
      "Steps:  91%|▉| 13661/15000 [1:27:18<12:18,  1.81it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:40 - INFO - __main__ - train loss is 10.121150627499446\n",
      "Steps:  91%|▉| 13662/15000 [1:27:18<12:15,  1.82it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:41 - INFO - __main__ - train loss is 10.33408872759901\n",
      "Steps:  91%|▉| 13663/15000 [1:27:19<12:10,  1.83it/s, lr=8.78e-6, step_loss=0.2107/18/2023 20:30:42 - INFO - __main__ - train loss is 10.519367903238162\n",
      "Steps:  91%|▉| 13664/15000 [1:27:19<12:02,  1.85it/s, lr=8.78e-6, step_loss=0.1807/18/2023 20:30:42 - INFO - __main__ - train loss is 10.668233334785327\n",
      "Steps:  91%|▉| 13665/15000 [1:27:20<12:02,  1.85it/s, lr=8.78e-6, step_loss=0.1407/18/2023 20:30:43 - INFO - __main__ - train loss is 10.835978924995288\n",
      "Steps:  91%|▉| 13666/15000 [1:27:21<12:07,  1.83it/s, lr=8.78e-6, step_loss=0.1607/18/2023 20:30:43 - INFO - __main__ - train loss is 10.934955432778224\n",
      "Steps:  91%|▉| 13667/15000 [1:27:21<12:17,  1.81it/s, lr=8.78e-6, step_loss=0.0907/18/2023 20:30:44 - INFO - __main__ - train loss is 10.94765771436505\n",
      "Steps:  91%|▉| 13668/15000 [1:27:22<12:27,  1.78it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:44 - INFO - __main__ - train loss is 11.029377604601905\n",
      "Steps:  91%|▉| 13669/15000 [1:27:22<12:29,  1.78it/s, lr=8.78e-6, step_loss=0.0807/18/2023 20:30:45 - INFO - __main__ - train loss is 11.445389742730185\n",
      "Steps:  91%|▉| 13670/15000 [1:27:23<12:31,  1.77it/s, lr=8.78e-6, step_loss=0.4107/18/2023 20:30:45 - INFO - __main__ - train loss is 11.505848663626239\n",
      "Steps:  91%|▉| 13671/15000 [1:27:23<12:30,  1.77it/s, lr=8.78e-6, step_loss=0.0607/18/2023 20:30:46 - INFO - __main__ - train loss is 12.171956198988482\n",
      "Steps:  91%|▉| 13672/15000 [1:27:24<12:25,  1.78it/s, lr=8.78e-6, step_loss=0.6607/18/2023 20:30:47 - INFO - __main__ - train loss is 12.174249651376158\n",
      "Steps:  91%|▉| 13673/15000 [1:27:24<12:28,  1.77it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:47 - INFO - __main__ - train loss is 12.210263880435377\n",
      "Steps:  91%|▉| 13674/15000 [1:27:25<12:23,  1.78it/s, lr=8.78e-6, step_loss=0.0307/18/2023 20:30:48 - INFO - __main__ - train loss is 12.213023957330734\n",
      "Steps:  91%|▉| 13675/15000 [1:27:26<12:28,  1.77it/s, lr=8.78e-6, step_loss=0.0007/18/2023 20:30:48 - INFO - __main__ - train loss is 12.556705710012466\n",
      "Steps:  91%|▉| 13676/15000 [1:27:26<12:46,  1.73it/s, lr=8.78e-6, step_loss=0.3407/18/2023 20:30:49 - INFO - __main__ - train loss is 12.568602955434471\n",
      "Steps:  91%|▉| 13677/15000 [1:27:27<14:27,  1.53it/s, lr=8.78e-6, step_loss=0.0107/18/2023 20:30:50 - INFO - __main__ - Per validation step average loss is 0.14360731840133667\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Cumulative validation average loss is 0.14360731840133667\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Per validation step average loss is 0.20918315649032593\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Cumulative validation average loss is 0.3527904748916626\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Per validation step average loss is 0.11529836058616638\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Cumulative validation average loss is 0.468088835477829\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Per validation step average loss is 0.42340803146362305\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Cumulative validation average loss is 0.891496866941452\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Per validation step average loss is 0.12027342617511749\n",
      "07/18/2023 20:30:50 - INFO - __main__ - Cumulative validation average loss is 1.0117702931165695\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Per validation step average loss is 0.0022644540295004845\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Cumulative validation average loss is 1.01403474714607\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Per validation step average loss is 0.04155056178569794\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Cumulative validation average loss is 1.055585308931768\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Per validation step average loss is 0.08022921532392502\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Cumulative validation average loss is 1.135814524255693\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Per validation step average loss is 0.5531511902809143\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Cumulative validation average loss is 1.6889657145366073\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Per validation step average loss is 0.20374682545661926\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Cumulative validation average loss is 1.8927125399932265\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Per validation step average loss is 0.0025453204289078712\n",
      "07/18/2023 20:30:51 - INFO - __main__ - Cumulative validation average loss is 1.8952578604221344\n",
      "07/18/2023 20:30:52 - INFO - __main__ - Per validation step average loss is 0.45377564430236816\n",
      "07/18/2023 20:30:52 - INFO - __main__ - Cumulative validation average loss is 2.3490335047245026\n",
      "07/18/2023 20:30:52 - INFO - __main__ - Average validation loss for Epoch 140 is 0.1957527920603752\n",
      "07/18/2023 20:30:52 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:31:05 - INFO - __main__ - Starting epoch 141\n",
      "07/18/2023 20:31:05 - INFO - __main__ - train loss is 0.31118619441986084\n",
      "Steps:  91%|▉| 13678/15000 [1:27:43<1:55:25,  5.24s/it, lr=8.78e-6, step_loss=0.07/18/2023 20:31:05 - INFO - __main__ - train loss is 0.38589926064014435\n",
      "Steps:  91%|▉| 13679/15000 [1:27:43<1:21:55,  3.72s/it, lr=8.78e-6, step_loss=0.07/18/2023 20:31:05 - INFO - __main__ - train loss is 0.4719868451356888\n",
      "Steps:  91%|▉| 13680/15000 [1:27:43<58:30,  2.66s/it, lr=8.77e-6, step_loss=0.0807/18/2023 20:31:06 - INFO - __main__ - train loss is 0.4766572988592088\n",
      "Steps:  91%|▉| 13681/15000 [1:27:44<42:06,  1.92s/it, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:06 - INFO - __main__ - train loss is 0.5718374825082719\n",
      "Steps:  91%|▉| 13682/15000 [1:27:44<30:39,  1.40s/it, lr=8.77e-6, step_loss=0.0907/18/2023 20:31:06 - INFO - __main__ - train loss is 0.7560985810123384\n",
      "Steps:  91%|▉| 13683/15000 [1:27:44<22:37,  1.03s/it, lr=8.77e-6, step_loss=0.1807/18/2023 20:31:06 - INFO - __main__ - train loss is 0.8364818221889436\n",
      "Steps:  91%|▉| 13684/15000 [1:27:44<16:59,  1.29it/s, lr=8.77e-6, step_loss=0.0807/18/2023 20:31:06 - INFO - __main__ - train loss is 0.8385018985718489\n",
      "Steps:  91%|▉| 13685/15000 [1:27:44<13:03,  1.68it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:07 - INFO - __main__ - train loss is 1.4739060085266829\n",
      "Steps:  91%|▉| 13686/15000 [1:27:44<10:18,  2.13it/s, lr=8.77e-6, step_loss=0.6307/18/2023 20:31:07 - INFO - __main__ - train loss is 1.6521988045424223\n",
      "Steps:  91%|▉| 13687/15000 [1:27:45<08:22,  2.61it/s, lr=8.77e-6, step_loss=0.1707/18/2023 20:31:07 - INFO - __main__ - train loss is 1.7267766576260328\n",
      "Steps:  91%|▉| 13688/15000 [1:27:45<07:01,  3.11it/s, lr=8.77e-6, step_loss=0.0707/18/2023 20:31:07 - INFO - __main__ - train loss is 1.8316104095429182\n",
      "Steps:  91%|▉| 13689/15000 [1:27:45<06:04,  3.59it/s, lr=8.77e-6, step_loss=0.1007/18/2023 20:31:07 - INFO - __main__ - train loss is 1.971775246784091\n",
      "Steps:  91%|▉| 13690/15000 [1:27:45<05:25,  4.03it/s, lr=8.77e-6, step_loss=0.1407/18/2023 20:31:07 - INFO - __main__ - train loss is 2.0938612651079893\n",
      "Steps:  91%|▉| 13691/15000 [1:27:45<04:57,  4.40it/s, lr=8.77e-6, step_loss=0.1207/18/2023 20:31:08 - INFO - __main__ - train loss is 2.20053300075233\n",
      "Steps:  91%|▉| 13692/15000 [1:27:46<04:38,  4.70it/s, lr=8.77e-6, step_loss=0.1007/18/2023 20:31:08 - INFO - __main__ - train loss is 2.5151374619454145\n",
      "Steps:  91%|▉| 13693/15000 [1:27:46<04:24,  4.94it/s, lr=8.77e-6, step_loss=0.3107/18/2023 20:31:08 - INFO - __main__ - train loss is 2.524745136499405\n",
      "Steps:  91%|▉| 13694/15000 [1:27:46<04:14,  5.13it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:08 - INFO - __main__ - train loss is 2.5298884897492826\n",
      "Steps:  91%|▉| 13695/15000 [1:27:46<04:08,  5.26it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:08 - INFO - __main__ - train loss is 2.5529906689189374\n",
      "Steps:  91%|▉| 13696/15000 [1:27:46<04:03,  5.36it/s, lr=8.77e-6, step_loss=0.0207/18/2023 20:31:09 - INFO - __main__ - train loss is 2.8387377499602735\n",
      "Steps:  91%|▉| 13697/15000 [1:27:46<03:59,  5.43it/s, lr=8.77e-6, step_loss=0.2807/18/2023 20:31:09 - INFO - __main__ - train loss is 2.873821401502937\n",
      "Steps:  91%|▉| 13698/15000 [1:27:47<03:57,  5.48it/s, lr=8.77e-6, step_loss=0.0307/18/2023 20:31:09 - INFO - __main__ - train loss is 2.9936928837560117\n",
      "Steps:  91%|▉| 13699/15000 [1:27:47<03:56,  5.51it/s, lr=8.77e-6, step_loss=0.1207/18/2023 20:31:09 - INFO - __main__ - train loss is 3.47928107669577\n",
      "Steps:  91%|▉| 13700/15000 [1:27:47<03:54,  5.54it/s, lr=8.77e-6, step_loss=0.4807/18/2023 20:31:09 - INFO - __main__ - train loss is 3.7165066092275083\n",
      "Steps:  91%|▉| 13701/15000 [1:27:47<03:54,  5.53it/s, lr=8.77e-6, step_loss=0.2307/18/2023 20:31:09 - INFO - __main__ - train loss is 4.083138295914978\n",
      "Steps:  91%|▉| 13702/15000 [1:27:47<03:53,  5.55it/s, lr=8.77e-6, step_loss=0.3607/18/2023 20:31:10 - INFO - __main__ - train loss is 4.425942549016327\n",
      "Steps:  91%|▉| 13703/15000 [1:27:47<03:53,  5.56it/s, lr=8.77e-6, step_loss=0.3407/18/2023 20:31:10 - INFO - __main__ - train loss is 4.758764901664108\n",
      "Steps:  91%|▉| 13704/15000 [1:27:48<03:52,  5.57it/s, lr=8.77e-6, step_loss=0.3307/18/2023 20:31:10 - INFO - __main__ - train loss is 4.83128018071875\n",
      "Steps:  91%|▉| 13705/15000 [1:27:48<03:52,  5.58it/s, lr=8.77e-6, step_loss=0.0707/18/2023 20:31:10 - INFO - __main__ - train loss is 4.922861882951111\n",
      "Steps:  91%|▉| 13706/15000 [1:27:48<03:51,  5.59it/s, lr=8.77e-6, step_loss=0.0907/18/2023 20:31:10 - INFO - __main__ - train loss is 5.862260290887207\n",
      "Steps:  91%|▉| 13707/15000 [1:27:48<03:51,  5.59it/s, lr=8.77e-6, step_loss=0.9307/18/2023 20:31:10 - INFO - __main__ - train loss is 6.020437443163246\n",
      "Steps:  91%|▉| 13708/15000 [1:27:48<03:50,  5.59it/s, lr=8.77e-6, step_loss=0.1507/18/2023 20:31:11 - INFO - __main__ - train loss is 6.081319031771272\n",
      "Steps:  91%|▉| 13709/15000 [1:27:49<03:50,  5.59it/s, lr=8.77e-6, step_loss=0.0607/18/2023 20:31:11 - INFO - __main__ - train loss is 6.151298803742975\n",
      "Steps:  91%|▉| 13710/15000 [1:27:49<03:50,  5.59it/s, lr=8.77e-6, step_loss=0.0707/18/2023 20:31:11 - INFO - __main__ - train loss is 6.152918063569814\n",
      "Steps:  91%|▉| 13711/15000 [1:27:49<03:50,  5.58it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:11 - INFO - __main__ - train loss is 6.160892662126571\n",
      "Steps:  91%|▉| 13712/15000 [1:27:49<03:50,  5.58it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:11 - INFO - __main__ - train loss is 6.355443578679115\n",
      "Steps:  91%|▉| 13713/15000 [1:27:49<03:50,  5.58it/s, lr=8.77e-6, step_loss=0.1907/18/2023 20:31:12 - INFO - __main__ - train loss is 6.358047667425126\n",
      "Steps:  91%|▉| 13714/15000 [1:27:49<03:50,  5.58it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:12 - INFO - __main__ - train loss is 6.542443621437997\n",
      "Steps:  91%|▉| 13715/15000 [1:27:50<03:50,  5.58it/s, lr=8.77e-6, step_loss=0.1807/18/2023 20:31:12 - INFO - __main__ - train loss is 6.546836983412504\n",
      "Steps:  91%|▉| 13716/15000 [1:27:50<03:49,  5.59it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:12 - INFO - __main__ - train loss is 6.555771387182176\n",
      "Steps:  91%|▉| 13717/15000 [1:27:50<03:49,  5.59it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:12 - INFO - __main__ - train loss is 6.57698034029454\n",
      "Steps:  91%|▉| 13718/15000 [1:27:50<03:49,  5.58it/s, lr=8.77e-6, step_loss=0.0207/18/2023 20:31:12 - INFO - __main__ - train loss is 6.946541923098266\n",
      "Steps:  91%|▉| 13719/15000 [1:27:50<03:49,  5.59it/s, lr=8.77e-6, step_loss=0.3707/18/2023 20:31:13 - INFO - __main__ - train loss is 7.1784353433176875\n",
      "Steps:  91%|▉| 13720/15000 [1:27:51<03:49,  5.59it/s, lr=8.77e-6, step_loss=0.2307/18/2023 20:31:13 - INFO - __main__ - train loss is 7.2350090546533465\n",
      "Steps:  91%|▉| 13721/15000 [1:27:51<03:48,  5.59it/s, lr=8.77e-6, step_loss=0.0507/18/2023 20:31:13 - INFO - __main__ - train loss is 7.240483932197094\n",
      "Steps:  91%|▉| 13722/15000 [1:27:51<03:48,  5.59it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:13 - INFO - __main__ - train loss is 7.4915298745036125\n",
      "Steps:  91%|▉| 13723/15000 [1:27:51<03:48,  5.59it/s, lr=8.77e-6, step_loss=0.2507/18/2023 20:31:13 - INFO - __main__ - train loss is 7.66391970962286\n",
      "Steps:  91%|▉| 13724/15000 [1:27:51<03:48,  5.59it/s, lr=8.77e-6, step_loss=0.1707/18/2023 20:31:14 - INFO - __main__ - train loss is 7.843811683356762\n",
      "Steps:  92%|▉| 13725/15000 [1:27:51<03:48,  5.59it/s, lr=8.77e-6, step_loss=0.1807/18/2023 20:31:14 - INFO - __main__ - train loss is 7.863158788532019\n",
      "Steps:  92%|▉| 13726/15000 [1:27:52<03:47,  5.59it/s, lr=8.77e-6, step_loss=0.0107/18/2023 20:31:14 - INFO - __main__ - train loss is 7.974396016448736\n",
      "Steps:  92%|▉| 13727/15000 [1:27:52<03:47,  5.59it/s, lr=8.77e-6, step_loss=0.1107/18/2023 20:31:14 - INFO - __main__ - train loss is 8.216732110828161\n",
      "Steps:  92%|▉| 13728/15000 [1:27:52<03:47,  5.59it/s, lr=8.77e-6, step_loss=0.2407/18/2023 20:31:14 - INFO - __main__ - train loss is 8.218230449128896\n",
      "Steps:  92%|▉| 13729/15000 [1:27:52<03:47,  5.59it/s, lr=8.77e-6, step_loss=0.0007/18/2023 20:31:14 - INFO - __main__ - train loss is 8.24816893832758\n",
      "Steps:  92%|▉| 13730/15000 [1:27:52<03:47,  5.59it/s, lr=8.77e-6, step_loss=0.0207/18/2023 20:31:15 - INFO - __main__ - train loss is 8.25999573012814\n",
      "Steps:  92%|▉| 13731/15000 [1:27:52<03:46,  5.59it/s, lr=8.77e-6, step_loss=0.0107/18/2023 20:31:15 - INFO - __main__ - train loss is 8.276670280378312\n",
      "Steps:  92%|▉| 13732/15000 [1:27:53<03:46,  5.59it/s, lr=8.77e-6, step_loss=0.0107/18/2023 20:31:15 - INFO - __main__ - train loss is 8.419627908151597\n",
      "Steps:  92%|▉| 13733/15000 [1:27:53<03:46,  5.59it/s, lr=8.77e-6, step_loss=0.1407/18/2023 20:31:15 - INFO - __main__ - train loss is 8.61753176478669\n",
      "Steps:  92%|▉| 13734/15000 [1:27:53<03:46,  5.59it/s, lr=8.77e-6, step_loss=0.1907/18/2023 20:31:15 - INFO - __main__ - train loss is 8.862765240948647\n",
      "Steps:  92%|▉| 13735/15000 [1:27:53<03:46,  5.59it/s, lr=8.77e-6, step_loss=0.2407/18/2023 20:31:15 - INFO - __main__ - train loss is 8.921206905972213\n",
      "Steps:  92%|▉| 13736/15000 [1:27:53<03:45,  5.59it/s, lr=8.77e-6, step_loss=0.0507/18/2023 20:31:16 - INFO - __main__ - train loss is 8.982722397428006\n",
      "Steps:  92%|▉| 13737/15000 [1:27:54<03:45,  5.59it/s, lr=8.77e-6, step_loss=0.0607/18/2023 20:31:16 - INFO - __main__ - train loss is 9.047259639482945\n",
      "Steps:  92%|▉| 13738/15000 [1:27:54<03:45,  5.59it/s, lr=8.76e-6, step_loss=0.0607/18/2023 20:31:16 - INFO - __main__ - train loss is 9.064700729679316\n",
      "Steps:  92%|▉| 13739/15000 [1:27:54<03:45,  5.60it/s, lr=8.76e-6, step_loss=0.0107/18/2023 20:31:16 - INFO - __main__ - train loss is 9.070011628326029\n",
      "Steps:  92%|▉| 13740/15000 [1:27:54<03:45,  5.60it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:16 - INFO - __main__ - train loss is 9.140620072837919\n",
      "Steps:  92%|▉| 13741/15000 [1:27:54<03:45,  5.60it/s, lr=8.76e-6, step_loss=0.0707/18/2023 20:31:17 - INFO - __main__ - train loss is 9.188814488705248\n",
      "Steps:  92%|▉| 13742/15000 [1:27:54<03:44,  5.60it/s, lr=8.76e-6, step_loss=0.0407/18/2023 20:31:17 - INFO - __main__ - train loss is 9.19509743200615\n",
      "Steps:  92%|▉| 13743/15000 [1:27:55<03:44,  5.59it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:17 - INFO - __main__ - train loss is 9.799914822448045\n",
      "Steps:  92%|▉| 13744/15000 [1:27:55<03:44,  5.60it/s, lr=8.76e-6, step_loss=0.6007/18/2023 20:31:17 - INFO - __main__ - train loss is 9.80376193439588\n",
      "Steps:  92%|▉| 13745/15000 [1:27:55<03:44,  5.60it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:17 - INFO - __main__ - train loss is 9.967528556939214\n",
      "Steps:  92%|▉| 13746/15000 [1:27:55<03:43,  5.60it/s, lr=8.76e-6, step_loss=0.1607/18/2023 20:31:17 - INFO - __main__ - train loss is 10.192084168549627\n",
      "Steps:  92%|▉| 13747/15000 [1:27:55<03:44,  5.57it/s, lr=8.76e-6, step_loss=0.2207/18/2023 20:31:18 - INFO - __main__ - train loss is 10.685943757649511\n",
      "Steps:  92%|▉| 13748/15000 [1:27:56<03:44,  5.58it/s, lr=8.76e-6, step_loss=0.4907/18/2023 20:31:18 - INFO - __main__ - train loss is 10.883745064493269\n",
      "Steps:  92%|▉| 13749/15000 [1:27:56<03:44,  5.58it/s, lr=8.76e-6, step_loss=0.1907/18/2023 20:31:18 - INFO - __main__ - train loss is 10.885875589912757\n",
      "Steps:  92%|▉| 13750/15000 [1:27:56<03:43,  5.58it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:18 - INFO - __main__ - train loss is 11.015296511119232\n",
      "Steps:  92%|▉| 13751/15000 [1:27:56<03:43,  5.58it/s, lr=8.76e-6, step_loss=0.1207/18/2023 20:31:18 - INFO - __main__ - train loss is 11.298381440108642\n",
      "Steps:  92%|▉| 13752/15000 [1:27:56<03:43,  5.59it/s, lr=8.76e-6, step_loss=0.2807/18/2023 20:31:19 - INFO - __main__ - train loss is 11.331867351895198\n",
      "Steps:  92%|▉| 13753/15000 [1:27:56<03:43,  5.59it/s, lr=8.76e-6, step_loss=0.0307/18/2023 20:31:19 - INFO - __main__ - train loss is 11.423954427009448\n",
      "Steps:  92%|▉| 13754/15000 [1:27:57<03:42,  5.59it/s, lr=8.76e-6, step_loss=0.0907/18/2023 20:31:19 - INFO - __main__ - train loss is 11.425648435484618\n",
      "Steps:  92%|▉| 13755/15000 [1:27:57<03:42,  5.59it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:19 - INFO - __main__ - train loss is 11.646111830603331\n",
      "Steps:  92%|▉| 13756/15000 [1:27:57<03:42,  5.59it/s, lr=8.76e-6, step_loss=0.2207/18/2023 20:31:19 - INFO - __main__ - train loss is 11.824937298428267\n",
      "Steps:  92%|▉| 13757/15000 [1:27:57<03:42,  5.59it/s, lr=8.76e-6, step_loss=0.1707/18/2023 20:31:19 - INFO - __main__ - train loss is 12.458822324406356\n",
      "Steps:  92%|▉| 13758/15000 [1:27:57<03:41,  5.59it/s, lr=8.76e-6, step_loss=0.6307/18/2023 20:31:20 - INFO - __main__ - train loss is 12.702515646349639\n",
      "Steps:  92%|▉| 13759/15000 [1:27:57<03:41,  5.60it/s, lr=8.76e-6, step_loss=0.2407/18/2023 20:31:20 - INFO - __main__ - train loss is 12.74502870393917\n",
      "Steps:  92%|▉| 13760/15000 [1:27:58<03:41,  5.60it/s, lr=8.76e-6, step_loss=0.0407/18/2023 20:31:20 - INFO - __main__ - train loss is 12.770595585461706\n",
      "Steps:  92%|▉| 13761/15000 [1:27:58<03:41,  5.60it/s, lr=8.76e-6, step_loss=0.0207/18/2023 20:31:20 - INFO - __main__ - train loss is 13.03874767338857\n",
      "Steps:  92%|▉| 13762/15000 [1:27:58<03:41,  5.60it/s, lr=8.76e-6, step_loss=0.2607/18/2023 20:31:20 - INFO - __main__ - train loss is 13.040612296317704\n",
      "Steps:  92%|▉| 13763/15000 [1:27:58<03:40,  5.60it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:20 - INFO - __main__ - train loss is 13.313919917796738\n",
      "Steps:  92%|▉| 13764/15000 [1:27:58<03:40,  5.60it/s, lr=8.76e-6, step_loss=0.2707/18/2023 20:31:21 - INFO - __main__ - train loss is 13.324381987680681\n",
      "Steps:  92%|▉| 13765/15000 [1:27:59<03:40,  5.60it/s, lr=8.76e-6, step_loss=0.0107/18/2023 20:31:21 - INFO - __main__ - train loss is 13.32831737876404\n",
      "Steps:  92%|▉| 13766/15000 [1:27:59<03:40,  5.60it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:21 - INFO - __main__ - train loss is 13.688561950926669\n",
      "Steps:  92%|▉| 13767/15000 [1:27:59<03:42,  5.53it/s, lr=8.76e-6, step_loss=0.3607/18/2023 20:31:21 - INFO - __main__ - train loss is 13.864758257870562\n",
      "Steps:  92%|▉| 13768/15000 [1:27:59<03:43,  5.52it/s, lr=8.76e-6, step_loss=0.1707/18/2023 20:31:21 - INFO - __main__ - train loss is 14.010379423503764\n",
      "Steps:  92%|▉| 13769/15000 [1:27:59<03:41,  5.55it/s, lr=8.76e-6, step_loss=0.1407/18/2023 20:31:22 - INFO - __main__ - train loss is 14.273600568179972\n",
      "Steps:  92%|▉| 13770/15000 [1:27:59<03:40,  5.57it/s, lr=8.76e-6, step_loss=0.2607/18/2023 20:31:22 - INFO - __main__ - train loss is 14.62147920310963\n",
      "Steps:  92%|▉| 13771/15000 [1:28:00<03:40,  5.58it/s, lr=8.76e-6, step_loss=0.3407/18/2023 20:31:22 - INFO - __main__ - train loss is 14.624876382644288\n",
      "Steps:  92%|▉| 13772/15000 [1:28:00<03:39,  5.59it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:22 - INFO - __main__ - train loss is 14.637635025079362\n",
      "Steps:  92%|▉| 13773/15000 [1:28:00<03:39,  5.59it/s, lr=8.76e-6, step_loss=0.0107/18/2023 20:31:23 - INFO - __main__ - train loss is 14.93085450201761\n",
      "Steps:  92%|▉| 13774/15000 [1:28:00<05:01,  4.06it/s, lr=8.76e-6, step_loss=0.2907/18/2023 20:31:23 - INFO - __main__ - Per validation step average loss is 0.05968465656042099\n",
      "07/18/2023 20:31:23 - INFO - __main__ - Cumulative validation average loss is 0.05968465656042099\n",
      "07/18/2023 20:31:23 - INFO - __main__ - Per validation step average loss is 0.005100416950881481\n",
      "07/18/2023 20:31:23 - INFO - __main__ - Cumulative validation average loss is 0.06478507351130247\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Per validation step average loss is 0.30819928646087646\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Cumulative validation average loss is 0.37298435997217894\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Per validation step average loss is 0.04108436033129692\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Cumulative validation average loss is 0.41406872030347586\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Per validation step average loss is 0.020533986389636993\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Cumulative validation average loss is 0.43460270669311285\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Per validation step average loss is 0.05572324991226196\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Cumulative validation average loss is 0.4903259566053748\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Per validation step average loss is 0.4687519073486328\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Cumulative validation average loss is 0.9590778639540076\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Per validation step average loss is 0.44670408964157104\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Cumulative validation average loss is 1.4057819535955787\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Per validation step average loss is 0.15328922867774963\n",
      "07/18/2023 20:31:24 - INFO - __main__ - Cumulative validation average loss is 1.5590711822733283\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Per validation step average loss is 0.22700226306915283\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Cumulative validation average loss is 1.7860734453424811\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Per validation step average loss is 0.007261295337229967\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Cumulative validation average loss is 1.793334740679711\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Per validation step average loss is 0.5450695753097534\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Cumulative validation average loss is 2.3384043159894645\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Average validation loss for Epoch 141 is 0.19486702633245537\n",
      "07/18/2023 20:31:25 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:31:38 - INFO - __main__ - Starting epoch 142\n",
      "07/18/2023 20:31:39 - INFO - __main__ - train loss is 0.6069244146347046\n",
      "Steps:  92%|▉| 13775/15000 [1:28:17<1:44:01,  5.09s/it, lr=8.76e-6, step_loss=0.07/18/2023 20:31:39 - INFO - __main__ - train loss is 0.6270422469824553\n",
      "Steps:  92%|▉| 13776/15000 [1:28:17<1:13:53,  3.62s/it, lr=8.76e-6, step_loss=0.07/18/2023 20:31:39 - INFO - __main__ - train loss is 0.6511382777243853\n",
      "Steps:  92%|▉| 13777/15000 [1:28:17<52:46,  2.59s/it, lr=8.76e-6, step_loss=0.0207/18/2023 20:31:39 - INFO - __main__ - train loss is 0.6813734471797943\n",
      "Steps:  92%|▉| 13778/15000 [1:28:17<38:00,  1.87s/it, lr=8.76e-6, step_loss=0.0307/18/2023 20:31:40 - INFO - __main__ - train loss is 0.6849362221546471\n",
      "Steps:  92%|▉| 13779/15000 [1:28:18<27:41,  1.36s/it, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:40 - INFO - __main__ - train loss is 0.687343942001462\n",
      "Steps:  92%|▉| 13780/15000 [1:28:18<20:27,  1.01s/it, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:40 - INFO - __main__ - train loss is 0.6904400794301182\n",
      "Steps:  92%|▉| 13781/15000 [1:28:18<15:24,  1.32it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:40 - INFO - __main__ - train loss is 0.6968542167451233\n",
      "Steps:  92%|▉| 13782/15000 [1:28:18<11:51,  1.71it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:40 - INFO - __main__ - train loss is 0.7157484123017639\n",
      "Steps:  92%|▉| 13783/15000 [1:28:18<09:22,  2.16it/s, lr=8.76e-6, step_loss=0.0107/18/2023 20:31:41 - INFO - __main__ - train loss is 0.775496614864096\n",
      "Steps:  92%|▉| 13784/15000 [1:28:18<07:38,  2.65it/s, lr=8.76e-6, step_loss=0.0507/18/2023 20:31:41 - INFO - __main__ - train loss is 0.8348069170024246\n",
      "Steps:  92%|▉| 13785/15000 [1:28:19<06:26,  3.15it/s, lr=8.76e-6, step_loss=0.0507/18/2023 20:31:41 - INFO - __main__ - train loss is 1.0459545531775802\n",
      "Steps:  92%|▉| 13786/15000 [1:28:19<05:35,  3.62it/s, lr=8.76e-6, step_loss=0.2107/18/2023 20:31:41 - INFO - __main__ - train loss is 1.4164142289664596\n",
      "Steps:  92%|▉| 13787/15000 [1:28:19<04:59,  4.05it/s, lr=8.76e-6, step_loss=0.3707/18/2023 20:31:41 - INFO - __main__ - train loss is 1.5614315995480865\n",
      "Steps:  92%|▉| 13788/15000 [1:28:19<04:34,  4.42it/s, lr=8.76e-6, step_loss=0.1407/18/2023 20:31:41 - INFO - __main__ - train loss is 1.665790376951918\n",
      "Steps:  92%|▉| 13789/15000 [1:28:19<04:16,  4.72it/s, lr=8.76e-6, step_loss=0.1007/18/2023 20:31:42 - INFO - __main__ - train loss is 1.668817502213642\n",
      "Steps:  92%|▉| 13790/15000 [1:28:20<04:06,  4.91it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:42 - INFO - __main__ - train loss is 1.7330354421865195\n",
      "Steps:  92%|▉| 13791/15000 [1:28:20<04:00,  5.03it/s, lr=8.76e-6, step_loss=0.0607/18/2023 20:31:42 - INFO - __main__ - train loss is 1.734864964382723\n",
      "Steps:  92%|▉| 13792/15000 [1:28:20<03:57,  5.10it/s, lr=8.76e-6, step_loss=0.0007/18/2023 20:31:42 - INFO - __main__ - train loss is 2.686832919018343\n",
      "Steps:  92%|▉| 13793/15000 [1:28:20<03:52,  5.18it/s, lr=8.76e-6, step_loss=0.9507/18/2023 20:31:42 - INFO - __main__ - train loss is 2.7142658524680883\n",
      "Steps:  92%|▉| 13794/15000 [1:28:20<03:49,  5.25it/s, lr=8.76e-6, step_loss=0.0207/18/2023 20:31:43 - INFO - __main__ - train loss is 2.9777988486457616\n",
      "Steps:  92%|▉| 13795/15000 [1:28:20<03:49,  5.26it/s, lr=8.76e-6, step_loss=0.2607/18/2023 20:31:43 - INFO - __main__ - train loss is 2.9928240899462253\n",
      "Steps:  92%|▉| 13796/15000 [1:28:21<03:49,  5.24it/s, lr=8.75e-6, step_loss=0.0107/18/2023 20:31:43 - INFO - __main__ - train loss is 2.9987819569651037\n",
      "Steps:  92%|▉| 13797/15000 [1:28:21<03:46,  5.31it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:43 - INFO - __main__ - train loss is 3.370570935541764\n",
      "Steps:  92%|▉| 13798/15000 [1:28:21<03:45,  5.34it/s, lr=8.75e-6, step_loss=0.3707/18/2023 20:31:43 - INFO - __main__ - train loss is 3.410181902581826\n",
      "Steps:  92%|▉| 13799/15000 [1:28:21<03:45,  5.33it/s, lr=8.75e-6, step_loss=0.0307/18/2023 20:31:43 - INFO - __main__ - train loss is 3.427954504499212\n",
      "Steps:  92%|▉| 13800/15000 [1:28:21<03:45,  5.32it/s, lr=8.75e-6, step_loss=0.0107/18/2023 20:31:44 - INFO - __main__ - train loss is 3.430132217472419\n",
      "Steps:  92%|▉| 13801/15000 [1:28:22<03:47,  5.27it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:44 - INFO - __main__ - train loss is 3.440448444103822\n",
      "Steps:  92%|▉| 13802/15000 [1:28:22<03:49,  5.23it/s, lr=8.75e-6, step_loss=0.0107/18/2023 20:31:44 - INFO - __main__ - train loss is 3.4469549369532615\n",
      "Steps:  92%|▉| 13803/15000 [1:28:22<03:48,  5.24it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:44 - INFO - __main__ - train loss is 3.732418627711013\n",
      "Steps:  92%|▉| 13804/15000 [1:28:22<03:46,  5.28it/s, lr=8.75e-6, step_loss=0.2807/18/2023 20:31:44 - INFO - __main__ - train loss is 3.7901459496933967\n",
      "Steps:  92%|▉| 13805/15000 [1:28:22<03:43,  5.34it/s, lr=8.75e-6, step_loss=0.0507/18/2023 20:31:45 - INFO - __main__ - train loss is 4.128615991445258\n",
      "Steps:  92%|▉| 13806/15000 [1:28:23<03:46,  5.28it/s, lr=8.75e-6, step_loss=0.3307/18/2023 20:31:45 - INFO - __main__ - train loss is 4.130247465800494\n",
      "Steps:  92%|▉| 13807/15000 [1:28:23<03:48,  5.22it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:45 - INFO - __main__ - train loss is 4.192421983461827\n",
      "Steps:  92%|▉| 13808/15000 [1:28:23<03:49,  5.20it/s, lr=8.75e-6, step_loss=0.0607/18/2023 20:31:45 - INFO - __main__ - train loss is 4.203073320444673\n",
      "Steps:  92%|▉| 13809/15000 [1:28:23<03:50,  5.18it/s, lr=8.75e-6, step_loss=0.0107/18/2023 20:31:45 - INFO - __main__ - train loss is 4.301852201577276\n",
      "Steps:  92%|▉| 13810/15000 [1:28:23<03:51,  5.15it/s, lr=8.75e-6, step_loss=0.0907/18/2023 20:31:46 - INFO - __main__ - train loss is 4.30654163332656\n",
      "Steps:  92%|▉| 13811/15000 [1:28:23<03:48,  5.20it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:46 - INFO - __main__ - train loss is 4.310118844965473\n",
      "Steps:  92%|▉| 13812/15000 [1:28:24<03:47,  5.23it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:46 - INFO - __main__ - train loss is 4.314564558910206\n",
      "Steps:  92%|▉| 13813/15000 [1:28:24<03:48,  5.18it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:46 - INFO - __main__ - train loss is 4.657002303050831\n",
      "Steps:  92%|▉| 13814/15000 [1:28:24<03:50,  5.15it/s, lr=8.75e-6, step_loss=0.3407/18/2023 20:31:46 - INFO - __main__ - train loss is 4.857225510524586\n",
      "Steps:  92%|▉| 13815/15000 [1:28:24<03:49,  5.16it/s, lr=8.75e-6, step_loss=0.2]07/18/2023 20:31:47 - INFO - __main__ - train loss is 4.8774942711461335\n",
      "Steps:  92%|▉| 13816/15000 [1:28:24<03:49,  5.16it/s, lr=8.75e-6, step_loss=0.0207/18/2023 20:31:47 - INFO - __main__ - train loss is 4.897225658642128\n",
      "Steps:  92%|▉| 13817/15000 [1:28:25<03:46,  5.22it/s, lr=8.75e-6, step_loss=0.0107/18/2023 20:31:47 - INFO - __main__ - train loss is 4.915238515706733\n",
      "Steps:  92%|▉| 13818/15000 [1:28:25<03:47,  5.20it/s, lr=8.75e-6, step_loss=0.0107/18/2023 20:31:47 - INFO - __main__ - train loss is 4.940102084772661\n",
      "Steps:  92%|▉| 13819/15000 [1:28:25<03:48,  5.16it/s, lr=8.75e-6, step_loss=0.0207/18/2023 20:31:47 - INFO - __main__ - train loss is 5.399770899908617\n",
      "Steps:  92%|▉| 13820/15000 [1:28:25<03:49,  5.13it/s, lr=8.75e-6, step_loss=0.4607/18/2023 20:31:48 - INFO - __main__ - train loss is 5.455679483013228\n",
      "Steps:  92%|▉| 13821/15000 [1:28:25<03:50,  5.11it/s, lr=8.75e-6, step_loss=0.0507/18/2023 20:31:48 - INFO - __main__ - train loss is 5.902363515691832\n",
      "Steps:  92%|▉| 13822/15000 [1:28:26<03:50,  5.12it/s, lr=8.75e-6, step_loss=0.4407/18/2023 20:31:48 - INFO - __main__ - train loss is 6.175374157028273\n",
      "Steps:  92%|▉| 13823/15000 [1:28:26<03:50,  5.10it/s, lr=8.75e-6, step_loss=0.2707/18/2023 20:31:48 - INFO - __main__ - train loss is 6.624915487365797\n",
      "Steps:  92%|▉| 13824/15000 [1:28:26<03:50,  5.10it/s, lr=8.75e-6, step_loss=0.4507/18/2023 20:31:48 - INFO - __main__ - train loss is 6.692165575223044\n",
      "Steps:  92%|▉| 13825/15000 [1:28:26<03:50,  5.10it/s, lr=8.75e-6, step_loss=0.0607/18/2023 20:31:49 - INFO - __main__ - train loss is 6.72725263168104\n",
      "Steps:  92%|▉| 13826/15000 [1:28:26<03:50,  5.10it/s, lr=8.75e-6, step_loss=0.0307/18/2023 20:31:49 - INFO - __main__ - train loss is 6.87501737405546\n",
      "Steps:  92%|▉| 13827/15000 [1:28:27<03:47,  5.15it/s, lr=8.75e-6, step_loss=0.1407/18/2023 20:31:49 - INFO - __main__ - train loss is 6.878179579274729\n",
      "Steps:  92%|▉| 13828/15000 [1:28:27<03:45,  5.21it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:49 - INFO - __main__ - train loss is 7.185532002942637\n",
      "Steps:  92%|▉| 13829/15000 [1:28:27<03:41,  5.28it/s, lr=8.75e-6, step_loss=0.3007/18/2023 20:31:49 - INFO - __main__ - train loss is 7.501865505473688\n",
      "Steps:  92%|▉| 13830/15000 [1:28:27<03:42,  5.26it/s, lr=8.75e-6, step_loss=0.3107/18/2023 20:31:49 - INFO - __main__ - train loss is 7.564067869680002\n",
      "Steps:  92%|▉| 13831/15000 [1:28:27<03:43,  5.23it/s, lr=8.75e-6, step_loss=0.0607/18/2023 20:31:50 - INFO - __main__ - train loss is 7.890081047313288\n",
      "Steps:  92%|▉| 13832/15000 [1:28:28<03:44,  5.20it/s, lr=8.75e-6, step_loss=0.3207/18/2023 20:31:50 - INFO - __main__ - train loss is 8.003564073937014\n",
      "Steps:  92%|▉| 13833/15000 [1:28:28<03:45,  5.18it/s, lr=8.75e-6, step_loss=0.1107/18/2023 20:31:50 - INFO - __main__ - train loss is 8.056507124798372\n",
      "Steps:  92%|▉| 13834/15000 [1:28:28<03:46,  5.16it/s, lr=8.75e-6, step_loss=0.0507/18/2023 20:31:50 - INFO - __main__ - train loss is 8.188615902559832\n",
      "Steps:  92%|▉| 13835/15000 [1:28:28<03:46,  5.15it/s, lr=8.75e-6, step_loss=0.1307/18/2023 20:31:50 - INFO - __main__ - train loss is 8.39700388838537\n",
      "Steps:  92%|▉| 13836/15000 [1:28:28<03:47,  5.12it/s, lr=8.75e-6, step_loss=0.2007/18/2023 20:31:51 - INFO - __main__ - train loss is 8.492262526648119\n",
      "Steps:  92%|▉| 13837/15000 [1:28:29<03:47,  5.11it/s, lr=8.75e-6, step_loss=0.0907/18/2023 20:31:51 - INFO - __main__ - train loss is 8.536009057657793\n",
      "Steps:  92%|▉| 13838/15000 [1:28:29<03:45,  5.15it/s, lr=8.75e-6, step_loss=0.0407/18/2023 20:31:51 - INFO - __main__ - train loss is 9.079425915377215\n",
      "Steps:  92%|▉| 13839/15000 [1:28:29<03:45,  5.14it/s, lr=8.75e-6, step_loss=0.5407/18/2023 20:31:51 - INFO - __main__ - train loss is 9.11858197604306\n",
      "Steps:  92%|▉| 13840/15000 [1:28:29<03:45,  5.14it/s, lr=8.75e-6, step_loss=0.0307/18/2023 20:31:51 - INFO - __main__ - train loss is 9.128232000628486\n",
      "Steps:  92%|▉| 13841/15000 [1:28:29<03:45,  5.15it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:52 - INFO - __main__ - train loss is 9.145124137634411\n",
      "Steps:  92%|▉| 13842/15000 [1:28:30<03:44,  5.16it/s, lr=8.75e-6, step_loss=0.0107/18/2023 20:31:52 - INFO - __main__ - train loss is 9.147324432851747\n",
      "Steps:  92%|▉| 13843/15000 [1:28:30<03:42,  5.21it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:52 - INFO - __main__ - train loss is 9.17923924815841\n",
      "Steps:  92%|▉| 13844/15000 [1:28:30<03:39,  5.28it/s, lr=8.75e-6, step_loss=0.0307/18/2023 20:31:52 - INFO - __main__ - train loss is 9.438119326950982\n",
      "Steps:  92%|▉| 13845/15000 [1:28:30<03:35,  5.37it/s, lr=8.75e-6, step_loss=0.2507/18/2023 20:31:52 - INFO - __main__ - train loss is 9.439753282931633\n",
      "Steps:  92%|▉| 13846/15000 [1:28:30<03:32,  5.43it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:53 - INFO - __main__ - train loss is 9.605598632362671\n",
      "Steps:  92%|▉| 13847/15000 [1:28:30<03:30,  5.47it/s, lr=8.75e-6, step_loss=0.1607/18/2023 20:31:53 - INFO - __main__ - train loss is 9.697486754623242\n",
      "Steps:  92%|▉| 13848/15000 [1:28:31<03:29,  5.50it/s, lr=8.75e-6, step_loss=0.0907/18/2023 20:31:53 - INFO - __main__ - train loss is 10.08588462707121\n",
      "Steps:  92%|▉| 13849/15000 [1:28:31<03:28,  5.53it/s, lr=8.75e-6, step_loss=0.3807/18/2023 20:31:53 - INFO - __main__ - train loss is 10.208309229579754\n",
      "Steps:  92%|▉| 13850/15000 [1:28:31<03:29,  5.49it/s, lr=8.75e-6, step_loss=0.1207/18/2023 20:31:53 - INFO - __main__ - train loss is 10.418860312667675\n",
      "Steps:  92%|▉| 13851/15000 [1:28:31<03:28,  5.51it/s, lr=8.75e-6, step_loss=0.2107/18/2023 20:31:53 - INFO - __main__ - train loss is 10.657290216651745\n",
      "Steps:  92%|▉| 13852/15000 [1:28:31<03:27,  5.53it/s, lr=8.75e-6, step_loss=0.2307/18/2023 20:31:54 - INFO - __main__ - train loss is 10.663194006425329\n",
      "Steps:  92%|▉| 13853/15000 [1:28:31<03:28,  5.50it/s, lr=8.75e-6, step_loss=0.0007/18/2023 20:31:54 - INFO - __main__ - train loss is 10.665205195429735\n",
      "Steps:  92%|▉| 13854/15000 [1:28:32<03:28,  5.49it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:31:54 - INFO - __main__ - train loss is 10.684493318083696\n",
      "Steps:  92%|▉| 13855/15000 [1:28:32<03:29,  5.48it/s, lr=8.74e-6, step_loss=0.0107/18/2023 20:31:54 - INFO - __main__ - train loss is 10.709783777478151\n",
      "Steps:  92%|▉| 13856/15000 [1:28:32<03:28,  5.50it/s, lr=8.74e-6, step_loss=0.0207/18/2023 20:31:54 - INFO - __main__ - train loss is 11.04793651390355\n",
      "Steps:  92%|▉| 13857/15000 [1:28:32<03:26,  5.53it/s, lr=8.74e-6, step_loss=0.3307/18/2023 20:31:55 - INFO - __main__ - train loss is 11.078530855360441\n",
      "Steps:  92%|▉| 13858/15000 [1:28:32<03:25,  5.55it/s, lr=8.74e-6, step_loss=0.0307/18/2023 20:31:55 - INFO - __main__ - train loss is 11.080190421431325\n",
      "Steps:  92%|▉| 13859/15000 [1:28:33<03:24,  5.57it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:31:55 - INFO - __main__ - train loss is 11.11615529784467\n",
      "Steps:  92%|▉| 13860/15000 [1:28:33<03:26,  5.53it/s, lr=8.74e-6, step_loss=0.0307/18/2023 20:31:55 - INFO - __main__ - train loss is 11.979279191582464\n",
      "Steps:  92%|▉| 13861/15000 [1:28:33<03:25,  5.54it/s, lr=8.74e-6, step_loss=0.8607/18/2023 20:31:55 - INFO - __main__ - train loss is 11.991036520688795\n",
      "Steps:  92%|▉| 13862/15000 [1:28:33<03:24,  5.56it/s, lr=8.74e-6, step_loss=0.0107/18/2023 20:31:55 - INFO - __main__ - train loss is 11.996113494387828\n",
      "Steps:  92%|▉| 13863/15000 [1:28:33<03:23,  5.58it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:31:56 - INFO - __main__ - train loss is 12.063891455880366\n",
      "Steps:  92%|▉| 13864/15000 [1:28:33<03:23,  5.59it/s, lr=8.74e-6, step_loss=0.0607/18/2023 20:31:56 - INFO - __main__ - train loss is 12.132142253569327\n",
      "Steps:  92%|▉| 13865/15000 [1:28:34<03:22,  5.59it/s, lr=8.74e-6, step_loss=0.0607/18/2023 20:31:56 - INFO - __main__ - train loss is 12.159959514043294\n",
      "Steps:  92%|▉| 13866/15000 [1:28:34<03:22,  5.60it/s, lr=8.74e-6, step_loss=0.0207/18/2023 20:31:56 - INFO - __main__ - train loss is 12.168029817170464\n",
      "Steps:  92%|▉| 13867/15000 [1:28:34<03:22,  5.60it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:31:56 - INFO - __main__ - train loss is 12.416170986718498\n",
      "Steps:  92%|▉| 13868/15000 [1:28:34<03:21,  5.61it/s, lr=8.74e-6, step_loss=0.2407/18/2023 20:31:56 - INFO - __main__ - train loss is 12.422212534933351\n",
      "Steps:  92%|▉| 13869/15000 [1:28:34<03:23,  5.55it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:31:57 - INFO - __main__ - train loss is 12.452823774307035\n",
      "Steps:  92%|▉| 13870/15000 [1:28:35<03:23,  5.55it/s, lr=8.74e-6, step_loss=0.0307/18/2023 20:31:57 - INFO - __main__ - train loss is 12.456847316003405\n",
      "Steps:  92%|▉| 13871/15000 [1:28:35<04:32,  4.15it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:31:58 - INFO - __main__ - Per validation step average loss is 0.9025915265083313\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Cumulative validation average loss is 0.9025915265083313\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Per validation step average loss is 0.05013871192932129\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Cumulative validation average loss is 0.9527302384376526\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Per validation step average loss is 0.4752817451953888\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Cumulative validation average loss is 1.4280119836330414\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Per validation step average loss is 0.05828530713915825\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Cumulative validation average loss is 1.4862972907721996\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Per validation step average loss is 0.020646803081035614\n",
      "07/18/2023 20:31:58 - INFO - __main__ - Cumulative validation average loss is 1.5069440938532352\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Per validation step average loss is 0.08573274314403534\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Cumulative validation average loss is 1.5926768369972706\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Per validation step average loss is 0.32222995162010193\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Cumulative validation average loss is 1.9149067886173725\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Per validation step average loss is 0.330039918422699\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Cumulative validation average loss is 2.2449467070400715\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Per validation step average loss is 0.006104390136897564\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Cumulative validation average loss is 2.251051097176969\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Per validation step average loss is 0.0033411767799407244\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Cumulative validation average loss is 2.2543922739569098\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Per validation step average loss is 0.24962075054645538\n",
      "07/18/2023 20:31:59 - INFO - __main__ - Cumulative validation average loss is 2.504013024503365\n",
      "07/18/2023 20:32:00 - INFO - __main__ - Per validation step average loss is 0.04972720518708229\n",
      "07/18/2023 20:32:00 - INFO - __main__ - Cumulative validation average loss is 2.5537402296904474\n",
      "07/18/2023 20:32:00 - INFO - __main__ - Average validation loss for Epoch 142 is 0.2128116858075373\n",
      "07/18/2023 20:32:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:32:13 - INFO - __main__ - Starting epoch 143\n",
      "07/18/2023 20:32:13 - INFO - __main__ - train loss is 0.015613822266459465\n",
      "Steps:  92%|▉| 13872/15000 [1:28:51<1:33:40,  4.98s/it, lr=8.74e-6, step_loss=0.07/18/2023 20:32:13 - INFO - __main__ - train loss is 0.22036477737128735\n",
      "Steps:  92%|▉| 13873/15000 [1:28:51<1:06:32,  3.54s/it, lr=8.74e-6, step_loss=0.07/18/2023 20:32:13 - INFO - __main__ - train loss is 0.47877237014472485\n",
      "Steps:  92%|▉| 13874/15000 [1:28:51<47:33,  2.53s/it, lr=8.74e-6, step_loss=0.2507/18/2023 20:32:14 - INFO - __main__ - train loss is 0.6972761731594801\n",
      "Steps:  92%|▉| 13875/15000 [1:28:52<34:15,  1.83s/it, lr=8.74e-6, step_loss=0.2107/18/2023 20:32:14 - INFO - __main__ - train loss is 0.7656249534338713\n",
      "Steps:  93%|▉| 13876/15000 [1:28:52<24:58,  1.33s/it, lr=8.74e-6, step_loss=0.0607/18/2023 20:32:14 - INFO - __main__ - train loss is 0.7829151134938002\n",
      "Steps:  93%|▉| 13877/15000 [1:28:52<18:27,  1.01it/s, lr=8.74e-6, step_loss=0.0107/18/2023 20:32:14 - INFO - __main__ - train loss is 0.7851396421901882\n",
      "Steps:  93%|▉| 13878/15000 [1:28:52<13:55,  1.34it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:14 - INFO - __main__ - train loss is 0.7937316498719156\n",
      "Steps:  93%|▉| 13879/15000 [1:28:52<10:43,  1.74it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:15 - INFO - __main__ - train loss is 0.8652863926254213\n",
      "Steps:  93%|▉| 13880/15000 [1:28:52<08:30,  2.20it/s, lr=8.74e-6, step_loss=0.0707/18/2023 20:32:15 - INFO - __main__ - train loss is 1.1538034207187593\n",
      "Steps:  93%|▉| 13881/15000 [1:28:53<06:56,  2.69it/s, lr=8.74e-6, step_loss=0.2807/18/2023 20:32:15 - INFO - __main__ - train loss is 1.179219267796725\n",
      "Steps:  93%|▉| 13882/15000 [1:28:53<05:50,  3.19it/s, lr=8.74e-6, step_loss=0.0207/18/2023 20:32:15 - INFO - __main__ - train loss is 1.511867247056216\n",
      "Steps:  93%|▉| 13883/15000 [1:28:53<05:04,  3.66it/s, lr=8.74e-6, step_loss=0.3307/18/2023 20:32:15 - INFO - __main__ - train loss is 1.5178090264089406\n",
      "Steps:  93%|▉| 13884/15000 [1:28:53<04:32,  4.09it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:15 - INFO - __main__ - train loss is 1.6814469029195607\n",
      "Steps:  93%|▉| 13885/15000 [1:28:53<04:10,  4.46it/s, lr=8.74e-6, step_loss=0.1607/18/2023 20:32:16 - INFO - __main__ - train loss is 1.8972552348859608\n",
      "Steps:  93%|▉| 13886/15000 [1:28:53<03:54,  4.75it/s, lr=8.74e-6, step_loss=0.2107/18/2023 20:32:16 - INFO - __main__ - train loss is 2.0127327968366444\n",
      "Steps:  93%|▉| 13887/15000 [1:28:54<03:43,  4.98it/s, lr=8.74e-6, step_loss=0.1107/18/2023 20:32:16 - INFO - __main__ - train loss is 2.595710449386388\n",
      "Steps:  93%|▉| 13888/15000 [1:28:54<03:35,  5.16it/s, lr=8.74e-6, step_loss=0.5807/18/2023 20:32:16 - INFO - __main__ - train loss is 2.6032270812429488\n",
      "Steps:  93%|▉| 13889/15000 [1:28:54<03:30,  5.29it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:16 - INFO - __main__ - train loss is 2.634420726913959\n",
      "Steps:  93%|▉| 13890/15000 [1:28:54<03:26,  5.38it/s, lr=8.74e-6, step_loss=0.0307/18/2023 20:32:16 - INFO - __main__ - train loss is 2.6439873655326664\n",
      "Steps:  93%|▉| 13891/15000 [1:28:54<03:23,  5.44it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:17 - INFO - __main__ - train loss is 2.7444384996779263\n",
      "Steps:  93%|▉| 13892/15000 [1:28:55<03:21,  5.49it/s, lr=8.74e-6, step_loss=0.1]07/18/2023 20:32:17 - INFO - __main__ - train loss is 2.784184001851827\n",
      "Steps:  93%|▉| 13893/15000 [1:28:55<03:20,  5.52it/s, lr=8.74e-6, step_loss=0.0307/18/2023 20:32:17 - INFO - __main__ - train loss is 2.7879180849995464\n",
      "Steps:  93%|▉| 13894/15000 [1:28:55<03:19,  5.55it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:17 - INFO - __main__ - train loss is 2.8331990295555443\n",
      "Steps:  93%|▉| 13895/15000 [1:28:55<03:18,  5.57it/s, lr=8.74e-6, step_loss=0.0407/18/2023 20:32:17 - INFO - __main__ - train loss is 3.019050126662478\n",
      "Steps:  93%|▉| 13896/15000 [1:28:55<03:17,  5.58it/s, lr=8.74e-6, step_loss=0.1807/18/2023 20:32:18 - INFO - __main__ - train loss is 3.407143806805834\n",
      "Steps:  93%|▉| 13897/15000 [1:28:55<03:17,  5.58it/s, lr=8.74e-6, step_loss=0.3807/18/2023 20:32:18 - INFO - __main__ - train loss is 3.414055517176166\n",
      "Steps:  93%|▉| 13898/15000 [1:28:56<03:19,  5.53it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:18 - INFO - __main__ - train loss is 3.4385116996709257\n",
      "Steps:  93%|▉| 13899/15000 [1:28:56<03:18,  5.55it/s, lr=8.74e-6, step_loss=0.0207/18/2023 20:32:18 - INFO - __main__ - train loss is 3.4718062358442694\n",
      "Steps:  93%|▉| 13900/15000 [1:28:56<03:17,  5.56it/s, lr=8.74e-6, step_loss=0.0307/18/2023 20:32:18 - INFO - __main__ - train loss is 3.5071809517685324\n",
      "Steps:  93%|▉| 13901/15000 [1:28:56<03:17,  5.57it/s, lr=8.74e-6, step_loss=0.0307/18/2023 20:32:18 - INFO - __main__ - train loss is 3.5496437998954207\n",
      "Steps:  93%|▉| 13902/15000 [1:28:56<03:16,  5.58it/s, lr=8.74e-6, step_loss=0.0407/18/2023 20:32:19 - INFO - __main__ - train loss is 3.5545090220402926\n",
      "Steps:  93%|▉| 13903/15000 [1:28:57<03:16,  5.59it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:19 - INFO - __main__ - train loss is 4.113531925482675\n",
      "Steps:  93%|▉| 13904/15000 [1:28:57<03:16,  5.59it/s, lr=8.74e-6, step_loss=0.5507/18/2023 20:32:19 - INFO - __main__ - train loss is 4.267844595713541\n",
      "Steps:  93%|▉| 13905/15000 [1:28:57<03:15,  5.59it/s, lr=8.74e-6, step_loss=0.1507/18/2023 20:32:19 - INFO - __main__ - train loss is 5.012479998869821\n",
      "Steps:  93%|▉| 13906/15000 [1:28:57<03:15,  5.60it/s, lr=8.74e-6, step_loss=0.7407/18/2023 20:32:19 - INFO - __main__ - train loss is 5.411188044352457\n",
      "Steps:  93%|▉| 13907/15000 [1:28:57<03:15,  5.60it/s, lr=8.74e-6, step_loss=0.3907/18/2023 20:32:20 - INFO - __main__ - train loss is 5.412941614165902\n",
      "Steps:  93%|▉| 13908/15000 [1:28:57<03:15,  5.59it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:20 - INFO - __main__ - train loss is 5.4291028175503016\n",
      "Steps:  93%|▉| 13909/15000 [1:28:58<03:16,  5.56it/s, lr=8.74e-6, step_loss=0.0107/18/2023 20:32:20 - INFO - __main__ - train loss is 5.4329159506596625\n",
      "Steps:  93%|▉| 13910/15000 [1:28:58<03:17,  5.53it/s, lr=8.74e-6, step_loss=0.0007/18/2023 20:32:20 - INFO - __main__ - train loss is 5.551533492747694\n",
      "Steps:  93%|▉| 13911/15000 [1:28:58<03:16,  5.55it/s, lr=8.73e-6, step_loss=0.1107/18/2023 20:32:20 - INFO - __main__ - train loss is 5.583358435425907\n",
      "Steps:  93%|▉| 13912/15000 [1:28:58<03:15,  5.56it/s, lr=8.73e-6, step_loss=0.0307/18/2023 20:32:20 - INFO - __main__ - train loss is 5.652182607445866\n",
      "Steps:  93%|▉| 13913/15000 [1:28:58<03:16,  5.53it/s, lr=8.73e-6, step_loss=0.0607/18/2023 20:32:21 - INFO - __main__ - train loss is 6.081240265164524\n",
      "Steps:  93%|▉| 13914/15000 [1:28:59<03:15,  5.55it/s, lr=8.73e-6, step_loss=0.4207/18/2023 20:32:21 - INFO - __main__ - train loss is 6.177710531745106\n",
      "Steps:  93%|▉| 13915/15000 [1:28:59<03:15,  5.56it/s, lr=8.73e-6, step_loss=0.0907/18/2023 20:32:21 - INFO - __main__ - train loss is 6.322219459805638\n",
      "Steps:  93%|▉| 13916/15000 [1:28:59<03:14,  5.57it/s, lr=8.73e-6, step_loss=0.1407/18/2023 20:32:21 - INFO - __main__ - train loss is 6.337936753872782\n",
      "Steps:  93%|▉| 13917/15000 [1:28:59<03:15,  5.53it/s, lr=8.73e-6, step_loss=0.0107/18/2023 20:32:21 - INFO - __main__ - train loss is 6.3680220493115485\n",
      "Steps:  93%|▉| 13918/15000 [1:28:59<03:16,  5.52it/s, lr=8.73e-6, step_loss=0.0307/18/2023 20:32:22 - INFO - __main__ - train loss is 6.372565058525652\n",
      "Steps:  93%|▉| 13919/15000 [1:28:59<03:16,  5.49it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:22 - INFO - __main__ - train loss is 6.563277599867433\n",
      "Steps:  93%|▉| 13920/15000 [1:29:00<03:16,  5.50it/s, lr=8.73e-6, step_loss=0.1907/18/2023 20:32:22 - INFO - __main__ - train loss is 6.60281897475943\n",
      "Steps:  93%|▉| 13921/15000 [1:29:00<03:14,  5.53it/s, lr=8.73e-6, step_loss=0.0307/18/2023 20:32:22 - INFO - __main__ - train loss is 6.886266270186752\n",
      "Steps:  93%|▉| 13922/15000 [1:29:00<03:14,  5.55it/s, lr=8.73e-6, step_loss=0.2807/18/2023 20:32:22 - INFO - __main__ - train loss is 6.900398002471775\n",
      "Steps:  93%|▉| 13923/15000 [1:29:00<03:13,  5.56it/s, lr=8.73e-6, step_loss=0.0107/18/2023 20:32:22 - INFO - __main__ - train loss is 6.964528576936573\n",
      "Steps:  93%|▉| 13924/15000 [1:29:00<03:12,  5.58it/s, lr=8.73e-6, step_loss=0.0607/18/2023 20:32:23 - INFO - __main__ - train loss is 6.967688832432032\n",
      "Steps:  93%|▉| 13925/15000 [1:29:00<03:12,  5.58it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:23 - INFO - __main__ - train loss is 7.381232384592295\n",
      "Steps:  93%|▉| 13926/15000 [1:29:01<03:12,  5.59it/s, lr=8.73e-6, step_loss=0.4107/18/2023 20:32:23 - INFO - __main__ - train loss is 7.390421072021127\n",
      "Steps:  93%|▉| 13927/15000 [1:29:01<03:11,  5.60it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:23 - INFO - __main__ - train loss is 7.399608017876744\n",
      "Steps:  93%|▉| 13928/15000 [1:29:01<03:13,  5.55it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:23 - INFO - __main__ - train loss is 7.412746138870716\n",
      "Steps:  93%|▉| 13929/15000 [1:29:01<03:13,  5.53it/s, lr=8.73e-6, step_loss=0.0107/18/2023 20:32:24 - INFO - __main__ - train loss is 7.512611605226994\n",
      "Steps:  93%|▉| 13930/15000 [1:29:01<03:12,  5.55it/s, lr=8.73e-6, step_loss=0.0907/18/2023 20:32:24 - INFO - __main__ - train loss is 7.51549427350983\n",
      "Steps:  93%|▉| 13931/15000 [1:29:02<03:13,  5.52it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:24 - INFO - __main__ - train loss is 7.557056398596615\n",
      "Steps:  93%|▉| 13932/15000 [1:29:02<03:14,  5.49it/s, lr=8.73e-6, step_loss=0.0407/18/2023 20:32:24 - INFO - __main__ - train loss is 7.638864108826965\n",
      "Steps:  93%|▉| 13933/15000 [1:29:02<03:13,  5.51it/s, lr=8.73e-6, step_loss=0.0807/18/2023 20:32:24 - INFO - __main__ - train loss is 7.762517140712589\n",
      "Steps:  93%|▉| 13934/15000 [1:29:02<03:12,  5.53it/s, lr=8.73e-6, step_loss=0.1207/18/2023 20:32:24 - INFO - __main__ - train loss is 7.9877565815113485\n",
      "Steps:  93%|▉| 13935/15000 [1:29:02<03:11,  5.55it/s, lr=8.73e-6, step_loss=0.2207/18/2023 20:32:25 - INFO - __main__ - train loss is 8.162423761095852\n",
      "Steps:  93%|▉| 13936/15000 [1:29:02<03:11,  5.56it/s, lr=8.73e-6, step_loss=0.1707/18/2023 20:32:25 - INFO - __main__ - train loss is 8.180938520934433\n",
      "Steps:  93%|▉| 13937/15000 [1:29:03<03:12,  5.52it/s, lr=8.73e-6, step_loss=0.0107/18/2023 20:32:25 - INFO - __main__ - train loss is 8.208858800586313\n",
      "Steps:  93%|▉| 13938/15000 [1:29:03<03:12,  5.52it/s, lr=8.73e-6, step_loss=0.0207/18/2023 20:32:25 - INFO - __main__ - train loss is 8.365562153514475\n",
      "Steps:  93%|▉| 13939/15000 [1:29:03<03:13,  5.49it/s, lr=8.73e-6, step_loss=0.1507/18/2023 20:32:25 - INFO - __main__ - train loss is 8.61360111599788\n",
      "Steps:  93%|▉| 13940/15000 [1:29:03<03:12,  5.51it/s, lr=8.73e-6, step_loss=0.2407/18/2023 20:32:25 - INFO - __main__ - train loss is 8.705050197895616\n",
      "Steps:  93%|▉| 13941/15000 [1:29:03<03:12,  5.50it/s, lr=8.73e-6, step_loss=0.0907/18/2023 20:32:26 - INFO - __main__ - train loss is 8.742137213703245\n",
      "Steps:  93%|▉| 13942/15000 [1:29:04<03:11,  5.53it/s, lr=8.73e-6, step_loss=0.0307/18/2023 20:32:26 - INFO - __main__ - train loss is 8.81667231535539\n",
      "Steps:  93%|▉| 13943/15000 [1:29:04<03:11,  5.52it/s, lr=8.73e-6, step_loss=0.0707/18/2023 20:32:26 - INFO - __main__ - train loss is 8.820872138254344\n",
      "Steps:  93%|▉| 13944/15000 [1:29:04<03:10,  5.54it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:26 - INFO - __main__ - train loss is 8.9963263226673\n",
      "Steps:  93%|▉| 13945/15000 [1:29:04<03:09,  5.56it/s, lr=8.73e-6, step_loss=0.1707/18/2023 20:32:26 - INFO - __main__ - train loss is 9.012586361728609\n",
      "Steps:  93%|▉| 13946/15000 [1:29:04<03:09,  5.57it/s, lr=8.73e-6, step_loss=0.0107/18/2023 20:32:27 - INFO - __main__ - train loss is 9.215469098649919\n",
      "Steps:  93%|▉| 13947/15000 [1:29:04<03:09,  5.55it/s, lr=8.73e-6, step_loss=0.2007/18/2023 20:32:27 - INFO - __main__ - train loss is 9.359012371860445\n",
      "Steps:  93%|▉| 13948/15000 [1:29:05<03:09,  5.56it/s, lr=8.73e-6, step_loss=0.1407/18/2023 20:32:27 - INFO - __main__ - train loss is 9.361297628609464\n",
      "Steps:  93%|▉| 13949/15000 [1:29:05<03:08,  5.56it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:27 - INFO - __main__ - train loss is 9.425145021406934\n",
      "Steps:  93%|▉| 13950/15000 [1:29:05<03:08,  5.57it/s, lr=8.73e-6, step_loss=0.0607/18/2023 20:32:27 - INFO - __main__ - train loss is 9.638690671650693\n",
      "Steps:  93%|▉| 13951/15000 [1:29:05<03:07,  5.58it/s, lr=8.73e-6, step_loss=0.2107/18/2023 20:32:27 - INFO - __main__ - train loss is 9.64285809523426\n",
      "Steps:  93%|▉| 13952/15000 [1:29:05<03:07,  5.59it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:28 - INFO - __main__ - train loss is 9.7457431552466\n",
      "Steps:  93%|▉| 13953/15000 [1:29:06<03:07,  5.60it/s, lr=8.73e-6, step_loss=0.1007/18/2023 20:32:28 - INFO - __main__ - train loss is 9.794228009646758\n",
      "Steps:  93%|▉| 13954/15000 [1:29:06<03:07,  5.59it/s, lr=8.73e-6, step_loss=0.0407/18/2023 20:32:28 - INFO - __main__ - train loss is 9.93424243456684\n",
      "Steps:  93%|▉| 13955/15000 [1:29:06<03:06,  5.59it/s, lr=8.73e-6, step_loss=0.1407/18/2023 20:32:28 - INFO - __main__ - train loss is 9.939127794234082\n",
      "Steps:  93%|▉| 13956/15000 [1:29:06<03:06,  5.60it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:28 - INFO - __main__ - train loss is 9.947481349809095\n",
      "Steps:  93%|▉| 13957/15000 [1:29:06<03:06,  5.60it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:29 - INFO - __main__ - train loss is 9.995579370064661\n",
      "Steps:  93%|▉| 13958/15000 [1:29:06<03:05,  5.60it/s, lr=8.73e-6, step_loss=0.0407/18/2023 20:32:29 - INFO - __main__ - train loss is 10.372898646397516\n",
      "Steps:  93%|▉| 13959/15000 [1:29:07<03:05,  5.60it/s, lr=8.73e-6, step_loss=0.3707/18/2023 20:32:29 - INFO - __main__ - train loss is 10.383202434284613\n",
      "Steps:  93%|▉| 13960/15000 [1:29:07<03:05,  5.60it/s, lr=8.73e-6, step_loss=0.0107/18/2023 20:32:29 - INFO - __main__ - train loss is 10.743922234280035\n",
      "Steps:  93%|▉| 13961/15000 [1:29:07<03:05,  5.61it/s, lr=8.73e-6, step_loss=0.3607/18/2023 20:32:29 - INFO - __main__ - train loss is 10.75134493666701\n",
      "Steps:  93%|▉| 13962/15000 [1:29:07<03:05,  5.61it/s, lr=8.73e-6, step_loss=0.0007/18/2023 20:32:29 - INFO - __main__ - train loss is 10.840792703209445\n",
      "Steps:  93%|▉| 13963/15000 [1:29:07<03:04,  5.61it/s, lr=8.73e-6, step_loss=0.0807/18/2023 20:32:30 - INFO - __main__ - train loss is 10.866358530474827\n",
      "Steps:  93%|▉| 13964/15000 [1:29:07<03:04,  5.61it/s, lr=8.73e-6, step_loss=0.0207/18/2023 20:32:30 - INFO - __main__ - train loss is 11.045880866004154\n",
      "Steps:  93%|▉| 13965/15000 [1:29:08<03:04,  5.61it/s, lr=8.73e-6, step_loss=0.1807/18/2023 20:32:30 - INFO - __main__ - train loss is 11.223542717052624\n",
      "Steps:  93%|▉| 13966/15000 [1:29:08<03:07,  5.52it/s, lr=8.73e-6, step_loss=0.1707/18/2023 20:32:30 - INFO - __main__ - train loss is 11.33992898161523\n",
      "Steps:  93%|▉| 13967/15000 [1:29:08<03:08,  5.49it/s, lr=8.73e-6, step_loss=0.1107/18/2023 20:32:31 - INFO - __main__ - train loss is 11.893675324274227\n",
      "Steps:  93%|▉| 13968/15000 [1:29:08<04:06,  4.18it/s, lr=8.72e-6, step_loss=0.5507/18/2023 20:32:31 - INFO - __main__ - Per validation step average loss is 0.22001205384731293\n",
      "07/18/2023 20:32:31 - INFO - __main__ - Cumulative validation average loss is 0.22001205384731293\n",
      "07/18/2023 20:32:31 - INFO - __main__ - Per validation step average loss is 0.0664740577340126\n",
      "07/18/2023 20:32:31 - INFO - __main__ - Cumulative validation average loss is 0.28648611158132553\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Per validation step average loss is 0.4084920883178711\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Cumulative validation average loss is 0.6949781998991966\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Per validation step average loss is 0.007750188931822777\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Cumulative validation average loss is 0.7027283888310194\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Per validation step average loss is 0.11520569771528244\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Cumulative validation average loss is 0.8179340865463018\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Per validation step average loss is 0.20343148708343506\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Cumulative validation average loss is 1.021365573629737\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Per validation step average loss is 0.002280893735587597\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Cumulative validation average loss is 1.0236464673653245\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Per validation step average loss is 0.12352333217859268\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Cumulative validation average loss is 1.1471697995439172\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Per validation step average loss is 0.0025148368440568447\n",
      "07/18/2023 20:32:32 - INFO - __main__ - Cumulative validation average loss is 1.149684636387974\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Per validation step average loss is 0.022483624517917633\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Cumulative validation average loss is 1.1721682609058917\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Per validation step average loss is 0.5492586493492126\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Cumulative validation average loss is 1.7214269102551043\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Per validation step average loss is 0.01763906516134739\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Cumulative validation average loss is 1.7390659754164517\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Average validation loss for Epoch 143 is 0.14492216461803764\n",
      "07/18/2023 20:32:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:32:46 - INFO - __main__ - Starting epoch 144\n",
      "07/18/2023 20:32:47 - INFO - __main__ - train loss is 0.0014299021568149328\n",
      "Steps:  93%|▉| 13969/15000 [1:29:25<1:26:24,  5.03s/it, lr=8.72e-6, step_loss=0.07/18/2023 20:32:47 - INFO - __main__ - train loss is 0.07557685836218297\n",
      "Steps:  93%|▉| 13970/15000 [1:29:25<1:01:24,  3.58s/it, lr=8.72e-6, step_loss=0.07/18/2023 20:32:47 - INFO - __main__ - train loss is 0.09066893509589136\n",
      "Steps:  93%|▉| 13971/15000 [1:29:25<43:57,  2.56s/it, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:47 - INFO - __main__ - train loss is 0.7321257775183767\n",
      "Steps:  93%|▉| 13972/15000 [1:29:25<31:44,  1.85s/it, lr=8.72e-6, step_loss=0.6407/18/2023 20:32:48 - INFO - __main__ - train loss is 0.7667306659277529\n",
      "Steps:  93%|▉| 13973/15000 [1:29:25<23:11,  1.35s/it, lr=8.72e-6, step_loss=0.0307/18/2023 20:32:48 - INFO - __main__ - train loss is 0.7800535026472062\n",
      "Steps:  93%|▉| 13974/15000 [1:29:26<17:13,  1.01s/it, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:48 - INFO - __main__ - train loss is 0.8001751664560288\n",
      "Steps:  93%|▉| 13975/15000 [1:29:26<13:00,  1.31it/s, lr=8.72e-6, step_loss=0.0207/18/2023 20:32:48 - INFO - __main__ - train loss is 0.9522845360916108\n",
      "Steps:  93%|▉| 13976/15000 [1:29:26<10:02,  1.70it/s, lr=8.72e-6, step_loss=0.1507/18/2023 20:32:48 - INFO - __main__ - train loss is 1.0060772958677262\n",
      "Steps:  93%|▉| 13977/15000 [1:29:26<07:56,  2.14it/s, lr=8.72e-6, step_loss=0.0507/18/2023 20:32:48 - INFO - __main__ - train loss is 1.0079935914836824\n",
      "Steps:  93%|▉| 13978/15000 [1:29:26<06:29,  2.62it/s, lr=8.72e-6, step_loss=0.0007/18/2023 20:32:49 - INFO - __main__ - train loss is 1.0546331941150129\n",
      "Steps:  93%|▉| 13979/15000 [1:29:27<05:29,  3.09it/s, lr=8.72e-6, step_loss=0.0407/18/2023 20:32:49 - INFO - __main__ - train loss is 1.0876975185237825\n",
      "Steps:  93%|▉| 13980/15000 [1:29:27<04:50,  3.52it/s, lr=8.72e-6, step_loss=0.0307/18/2023 20:32:49 - INFO - __main__ - train loss is 1.1013149204663932\n",
      "Steps:  93%|▉| 13981/15000 [1:29:27<04:22,  3.88it/s, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:49 - INFO - __main__ - train loss is 1.1159887542016804\n",
      "Steps:  93%|▉| 13982/15000 [1:29:27<04:03,  4.18it/s, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:49 - INFO - __main__ - train loss is 1.1287981835193932\n",
      "Steps:  93%|▉| 13983/15000 [1:29:27<03:50,  4.42it/s, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:50 - INFO - __main__ - train loss is 1.5300705400295556\n",
      "Steps:  93%|▉| 13984/15000 [1:29:27<03:40,  4.61it/s, lr=8.72e-6, step_loss=0.4007/18/2023 20:32:50 - INFO - __main__ - train loss is 1.7150404271669686\n",
      "Steps:  93%|▉| 13985/15000 [1:29:28<03:33,  4.76it/s, lr=8.72e-6, step_loss=0.1807/18/2023 20:32:50 - INFO - __main__ - train loss is 1.7297158199362457\n",
      "Steps:  93%|▉| 13986/15000 [1:29:28<03:28,  4.87it/s, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:50 - INFO - __main__ - train loss is 1.8148308652453125\n",
      "Steps:  93%|▉| 13987/15000 [1:29:28<03:24,  4.96it/s, lr=8.72e-6, step_loss=0.0807/18/2023 20:32:50 - INFO - __main__ - train loss is 1.8429429749958217\n",
      "Steps:  93%|▉| 13988/15000 [1:29:28<03:21,  5.02it/s, lr=8.72e-6, step_loss=0.0207/18/2023 20:32:51 - INFO - __main__ - train loss is 1.9394595618359745\n",
      "Steps:  93%|▉| 13989/15000 [1:29:28<03:20,  5.05it/s, lr=8.72e-6, step_loss=0.0907/18/2023 20:32:51 - INFO - __main__ - train loss is 2.0463606636039913\n",
      "Steps:  93%|▉| 13990/15000 [1:29:29<03:19,  5.05it/s, lr=8.72e-6, step_loss=0.1007/18/2023 20:32:51 - INFO - __main__ - train loss is 2.0507452907040715\n",
      "Steps:  93%|▉| 13991/15000 [1:29:29<03:19,  5.07it/s, lr=8.72e-6, step_loss=0.0007/18/2023 20:32:51 - INFO - __main__ - train loss is 2.212322157807648\n",
      "Steps:  93%|▉| 13992/15000 [1:29:29<03:18,  5.09it/s, lr=8.72e-6, step_loss=0.1607/18/2023 20:32:51 - INFO - __main__ - train loss is 2.213774249656126\n",
      "Steps:  93%|▉| 13993/15000 [1:29:29<03:17,  5.10it/s, lr=8.72e-6, step_loss=0.0007/18/2023 20:32:52 - INFO - __main__ - train loss is 2.218999012140557\n",
      "Steps:  93%|▉| 13994/15000 [1:29:29<03:16,  5.12it/s, lr=8.72e-6, step_loss=0.0007/18/2023 20:32:52 - INFO - __main__ - train loss is 2.2315052456688136\n",
      "Steps:  93%|▉| 13995/15000 [1:29:30<03:16,  5.12it/s, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:52 - INFO - __main__ - train loss is 3.107462019426748\n",
      "Steps:  93%|▉| 13996/15000 [1:29:30<03:15,  5.13it/s, lr=8.72e-6, step_loss=0.8707/18/2023 20:32:52 - INFO - __main__ - train loss is 3.162587047321722\n",
      "Steps:  93%|▉| 13997/15000 [1:29:30<03:15,  5.13it/s, lr=8.72e-6, step_loss=0.0507/18/2023 20:32:52 - INFO - __main__ - train loss is 3.1892245679628104\n",
      "Steps:  93%|▉| 13998/15000 [1:29:30<03:15,  5.12it/s, lr=8.72e-6, step_loss=0.0207/18/2023 20:32:53 - INFO - __main__ - train loss is 3.191118910908699\n",
      "Steps:  93%|▉| 13999/15000 [1:29:30<03:15,  5.12it/s, lr=8.72e-6, step_loss=0.0007/18/2023 20:32:53 - INFO - __main__ - train loss is 3.8326144367456436\n",
      "Steps:  93%|▉| 14000/15000 [1:29:31<03:14,  5.13it/s, lr=8.72e-6, step_loss=0.0007/18/2023 20:32:53 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-14000\n",
      "07/18/2023 20:32:53 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:32:53,317] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:32:53,323] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:32:53,323] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:32:53,333] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:32:53,334] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-14000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:32:53,358] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-14000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:32:53,359] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-14000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:32:53,359] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:32:53 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-14000/pytorch_model\n",
      "07/18/2023 20:32:53 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-14000/scheduler.bin\n",
      "07/18/2023 20:32:53 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-14000/random_states_0.pkl\n",
      "07/18/2023 20:32:53 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-14000\n",
      "Steps:  93%|▉| 14000/15000 [1:29:31<03:14,  5.13it/s, lr=8.72e-6, step_loss=0.6407/18/2023 20:32:53 - INFO - __main__ - train loss is 3.8594757318496704\n",
      "Steps:  93%|▉| 14001/15000 [1:29:31<03:26,  4.83it/s, lr=8.72e-6, step_loss=0.0207/18/2023 20:32:53 - INFO - __main__ - train loss is 4.5337677001953125\n",
      "Steps:  93%|▉| 14002/15000 [1:29:31<03:22,  4.93it/s, lr=8.72e-6, step_loss=0.6707/18/2023 20:32:53 - INFO - __main__ - train loss is 4.558472894132137\n",
      "Steps:  93%|▉| 14003/15000 [1:29:31<03:19,  4.99it/s, lr=8.72e-6, step_loss=0.0207/18/2023 20:32:54 - INFO - __main__ - train loss is 4.88002198189497\n",
      "Steps:  93%|▉| 14004/15000 [1:29:31<03:17,  5.04it/s, lr=8.72e-6, step_loss=0.3207/18/2023 20:32:54 - INFO - __main__ - train loss is 4.893623890355229\n",
      "Steps:  93%|▉| 14005/15000 [1:29:32<03:16,  5.07it/s, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:54 - INFO - __main__ - train loss is 4.91807534173131\n",
      "Steps:  93%|▉| 14006/15000 [1:29:32<03:15,  5.09it/s, lr=8.72e-6, step_loss=0.0207/18/2023 20:32:54 - INFO - __main__ - train loss is 5.116484437137842\n",
      "Steps:  93%|▉| 14007/15000 [1:29:32<03:14,  5.10it/s, lr=8.72e-6, step_loss=0.1907/18/2023 20:32:54 - INFO - __main__ - train loss is 5.148968692868948\n",
      "Steps:  93%|▉| 14008/15000 [1:29:32<03:16,  5.04it/s, lr=8.72e-6, step_loss=0.0307/18/2023 20:32:55 - INFO - __main__ - train loss is 5.204366911202669\n",
      "Steps:  93%|▉| 14009/15000 [1:29:32<03:16,  5.04it/s, lr=8.72e-6, step_loss=0.0507/18/2023 20:32:55 - INFO - __main__ - train loss is 5.930229652673006\n",
      "Steps:  93%|▉| 14010/15000 [1:29:33<03:12,  5.15it/s, lr=8.72e-6, step_loss=0.7207/18/2023 20:32:55 - INFO - __main__ - train loss is 6.1056634075939655\n",
      "Steps:  93%|▉| 14011/15000 [1:29:33<03:07,  5.27it/s, lr=8.72e-6, step_loss=0.1707/18/2023 20:32:55 - INFO - __main__ - train loss is 6.113172604702413\n",
      "Steps:  93%|▉| 14012/15000 [1:29:33<03:04,  5.36it/s, lr=8.72e-6, step_loss=0.0007/18/2023 20:32:55 - INFO - __main__ - train loss is 6.213987312279642\n",
      "Steps:  93%|▉| 14013/15000 [1:29:33<03:01,  5.43it/s, lr=8.72e-6, step_loss=0.1007/18/2023 20:32:55 - INFO - __main__ - train loss is 6.307974866591394\n",
      "Steps:  93%|▉| 14014/15000 [1:29:33<03:00,  5.47it/s, lr=8.72e-6, step_loss=0.0907/18/2023 20:32:56 - INFO - __main__ - train loss is 6.6996483420953155\n",
      "Steps:  93%|▉| 14015/15000 [1:29:34<03:08,  5.21it/s, lr=8.72e-6, step_loss=0.3907/18/2023 20:32:56 - INFO - __main__ - train loss is 6.954895935021341\n",
      "Steps:  93%|▉| 14016/15000 [1:29:34<03:39,  4.48it/s, lr=8.72e-6, step_loss=0.2507/18/2023 20:32:56 - INFO - __main__ - train loss is 7.028615645132959\n",
      "Steps:  93%|▉| 14017/15000 [1:29:34<03:43,  4.41it/s, lr=8.72e-6, step_loss=0.0707/18/2023 20:32:56 - INFO - __main__ - train loss is 7.040245075710118\n",
      "Steps:  93%|▉| 14018/15000 [1:29:34<03:36,  4.54it/s, lr=8.72e-6, step_loss=0.0107/18/2023 20:32:57 - INFO - __main__ - train loss is 7.110603836365044\n",
      "Steps:  93%|▉| 14019/15000 [1:29:34<03:26,  4.76it/s, lr=8.72e-6, step_loss=0.0707/18/2023 20:32:57 - INFO - __main__ - train loss is 7.147712671197951\n",
      "Steps:  93%|▉| 14020/15000 [1:29:35<03:16,  4.98it/s, lr=8.72e-6, step_loss=0.0307/18/2023 20:32:57 - INFO - __main__ - train loss is 7.423083239234984\n",
      "Steps:  93%|▉| 14021/15000 [1:29:35<03:10,  5.15it/s, lr=8.72e-6, step_loss=0.2707/18/2023 20:32:57 - INFO - __main__ - train loss is 7.638577365316451\n",
      "Steps:  93%|▉| 14022/15000 [1:29:35<03:05,  5.27it/s, lr=8.72e-6, step_loss=0.2107/18/2023 20:32:57 - INFO - __main__ - train loss is 7.692802377976477\n",
      "Steps:  93%|▉| 14023/15000 [1:29:35<03:02,  5.36it/s, lr=8.72e-6, step_loss=0.0507/18/2023 20:32:57 - INFO - __main__ - train loss is 8.245491155423224\n",
      "Steps:  93%|▉| 14024/15000 [1:29:35<02:59,  5.43it/s, lr=8.72e-6, step_loss=0.5507/18/2023 20:32:58 - INFO - __main__ - train loss is 8.560323365963995\n",
      "Steps:  94%|▉| 14025/15000 [1:29:36<02:57,  5.48it/s, lr=8.72e-6, step_loss=0.3107/18/2023 20:32:58 - INFO - __main__ - train loss is 9.313666054047644\n",
      "Steps:  94%|▉| 14026/15000 [1:29:36<02:56,  5.52it/s, lr=8.71e-6, step_loss=0.7507/18/2023 20:32:58 - INFO - __main__ - train loss is 9.330053796060383\n",
      "Steps:  94%|▉| 14027/15000 [1:29:36<02:55,  5.54it/s, lr=8.71e-6, step_loss=0.0107/18/2023 20:32:58 - INFO - __main__ - train loss is 9.433449973352253\n",
      "Steps:  94%|▉| 14028/15000 [1:29:36<02:54,  5.56it/s, lr=8.71e-6, step_loss=0.1007/18/2023 20:32:58 - INFO - __main__ - train loss is 9.641909112222493\n",
      "Steps:  94%|▉| 14029/15000 [1:29:36<02:54,  5.57it/s, lr=8.71e-6, step_loss=0.2007/18/2023 20:32:59 - INFO - __main__ - train loss is 9.662641019560397\n",
      "Steps:  94%|▉| 14030/15000 [1:29:36<02:53,  5.58it/s, lr=8.71e-6, step_loss=0.0207/18/2023 20:32:59 - INFO - __main__ - train loss is 9.939805896021426\n",
      "Steps:  94%|▉| 14031/15000 [1:29:37<02:53,  5.58it/s, lr=8.71e-6, step_loss=0.2707/18/2023 20:32:59 - INFO - __main__ - train loss is 9.95960367936641\n",
      "Steps:  94%|▉| 14032/15000 [1:29:37<02:53,  5.58it/s, lr=8.71e-6, step_loss=0.0107/18/2023 20:32:59 - INFO - __main__ - train loss is 10.37364084739238\n",
      "Steps:  94%|▉| 14033/15000 [1:29:37<02:53,  5.58it/s, lr=8.71e-6, step_loss=0.4107/18/2023 20:32:59 - INFO - __main__ - train loss is 10.492830489762127\n",
      "Steps:  94%|▉| 14034/15000 [1:29:37<02:52,  5.58it/s, lr=8.71e-6, step_loss=0.1107/18/2023 20:32:59 - INFO - __main__ - train loss is 10.543380067683756\n",
      "Steps:  94%|▉| 14035/15000 [1:29:37<02:52,  5.59it/s, lr=8.71e-6, step_loss=0.0507/18/2023 20:33:00 - INFO - __main__ - train loss is 10.966162190772593\n",
      "Steps:  94%|▉| 14036/15000 [1:29:37<02:52,  5.59it/s, lr=8.71e-6, step_loss=0.4207/18/2023 20:33:00 - INFO - __main__ - train loss is 11.075108447112143\n",
      "Steps:  94%|▉| 14037/15000 [1:29:38<02:52,  5.59it/s, lr=8.71e-6, step_loss=0.1007/18/2023 20:33:00 - INFO - __main__ - train loss is 11.078425290295854\n",
      "Steps:  94%|▉| 14038/15000 [1:29:38<02:51,  5.59it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:00 - INFO - __main__ - train loss is 11.081634996226057\n",
      "Steps:  94%|▉| 14039/15000 [1:29:38<02:51,  5.59it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:00 - INFO - __main__ - train loss is 11.20624172477983\n",
      "Steps:  94%|▉| 14040/15000 [1:29:38<02:51,  5.59it/s, lr=8.71e-6, step_loss=0.1207/18/2023 20:33:01 - INFO - __main__ - train loss is 11.389151392271742\n",
      "Steps:  94%|▉| 14041/15000 [1:29:38<02:51,  5.60it/s, lr=8.71e-6, step_loss=0.1807/18/2023 20:33:01 - INFO - __main__ - train loss is 11.407217059051618\n",
      "Steps:  94%|▉| 14042/15000 [1:29:39<02:51,  5.60it/s, lr=8.71e-6, step_loss=0.0107/18/2023 20:33:01 - INFO - __main__ - train loss is 11.411441108444706\n",
      "Steps:  94%|▉| 14043/15000 [1:29:39<02:50,  5.60it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:01 - INFO - __main__ - train loss is 11.911337336758152\n",
      "Steps:  94%|▉| 14044/15000 [1:29:39<02:50,  5.60it/s, lr=8.71e-6, step_loss=0.5]07/18/2023 20:33:01 - INFO - __main__ - train loss is 11.916404736461118\n",
      "Steps:  94%|▉| 14045/15000 [1:29:39<02:50,  5.59it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:01 - INFO - __main__ - train loss is 12.015981880249456\n",
      "Steps:  94%|▉| 14046/15000 [1:29:39<02:50,  5.60it/s, lr=8.71e-6, step_loss=0.0907/18/2023 20:33:02 - INFO - __main__ - train loss is 12.064358999254182\n",
      "Steps:  94%|▉| 14047/15000 [1:29:39<02:50,  5.60it/s, lr=8.71e-6, step_loss=0.0407/18/2023 20:33:02 - INFO - __main__ - train loss is 12.4208235044498\n",
      "Steps:  94%|▉| 14048/15000 [1:29:40<02:50,  5.60it/s, lr=8.71e-6, step_loss=0.3507/18/2023 20:33:02 - INFO - __main__ - train loss is 12.477284197928384\n",
      "Steps:  94%|▉| 14049/15000 [1:29:40<02:49,  5.60it/s, lr=8.71e-6, step_loss=0.0507/18/2023 20:33:02 - INFO - __main__ - train loss is 12.483447362901643\n",
      "Steps:  94%|▉| 14050/15000 [1:29:40<02:49,  5.60it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:02 - INFO - __main__ - train loss is 12.486263379920274\n",
      "Steps:  94%|▉| 14051/15000 [1:29:40<02:50,  5.55it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:02 - INFO - __main__ - train loss is 12.488740468863398\n",
      "Steps:  94%|▉| 14052/15000 [1:29:40<02:50,  5.57it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:03 - INFO - __main__ - train loss is 12.889996702317148\n",
      "Steps:  94%|▉| 14053/15000 [1:29:41<02:50,  5.55it/s, lr=8.71e-6, step_loss=0.4007/18/2023 20:33:03 - INFO - __main__ - train loss is 12.90466743009165\n",
      "Steps:  94%|▉| 14054/15000 [1:29:41<02:51,  5.51it/s, lr=8.71e-6, step_loss=0.0107/18/2023 20:33:03 - INFO - __main__ - train loss is 13.003965244162828\n",
      "Steps:  94%|▉| 14055/15000 [1:29:41<02:51,  5.52it/s, lr=8.71e-6, step_loss=0.0907/18/2023 20:33:03 - INFO - __main__ - train loss is 13.00572900287807\n",
      "Steps:  94%|▉| 14056/15000 [1:29:41<02:50,  5.54it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:03 - INFO - __main__ - train loss is 13.084662033244967\n",
      "Steps:  94%|▉| 14057/15000 [1:29:41<02:50,  5.54it/s, lr=8.71e-6, step_loss=0.0707/18/2023 20:33:04 - INFO - __main__ - train loss is 13.092127325478941\n",
      "Steps:  94%|▉| 14058/15000 [1:29:41<02:49,  5.56it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:04 - INFO - __main__ - train loss is 13.097099115140736\n",
      "Steps:  94%|▉| 14059/15000 [1:29:42<02:49,  5.56it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:04 - INFO - __main__ - train loss is 13.104773451574147\n",
      "Steps:  94%|▉| 14060/15000 [1:29:42<02:48,  5.58it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:04 - INFO - __main__ - train loss is 13.109519149176776\n",
      "Steps:  94%|▉| 14061/15000 [1:29:42<02:47,  5.59it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:04 - INFO - __main__ - train loss is 13.142521719448268\n",
      "Steps:  94%|▉| 14062/15000 [1:29:42<02:47,  5.60it/s, lr=8.71e-6, step_loss=0.0307/18/2023 20:33:04 - INFO - __main__ - train loss is 13.327360863797367\n",
      "Steps:  94%|▉| 14063/15000 [1:29:42<02:47,  5.60it/s, lr=8.71e-6, step_loss=0.1807/18/2023 20:33:05 - INFO - __main__ - train loss is 13.432603145949543\n",
      "Steps:  94%|▉| 14064/15000 [1:29:43<02:47,  5.60it/s, lr=8.71e-6, step_loss=0.1007/18/2023 20:33:05 - INFO - __main__ - train loss is 13.446609403006732\n",
      "Steps:  94%|▉| 14065/15000 [1:29:43<03:47,  4.10it/s, lr=8.71e-6, step_loss=0.0107/18/2023 20:33:06 - INFO - __main__ - Per validation step average loss is 0.13322287797927856\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Cumulative validation average loss is 0.13322287797927856\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Per validation step average loss is 0.015601349994540215\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Cumulative validation average loss is 0.14882422797381878\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Per validation step average loss is 0.0016449019312858582\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Cumulative validation average loss is 0.15046912990510464\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Per validation step average loss is 0.018843401223421097\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Cumulative validation average loss is 0.16931253112852573\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Per validation step average loss is 0.3569336533546448\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Cumulative validation average loss is 0.5262461844831705\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Per validation step average loss is 0.012019813060760498\n",
      "07/18/2023 20:33:06 - INFO - __main__ - Cumulative validation average loss is 0.538265997543931\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Per validation step average loss is 0.00817151926457882\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Cumulative validation average loss is 0.5464375168085098\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Per validation step average loss is 0.07990249991416931\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Cumulative validation average loss is 0.6263400167226791\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Per validation step average loss is 0.004692183807492256\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Cumulative validation average loss is 0.6310322005301714\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Per validation step average loss is 0.0013742554001510143\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Cumulative validation average loss is 0.6324064559303224\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Per validation step average loss is 0.057288721203804016\n",
      "07/18/2023 20:33:07 - INFO - __main__ - Cumulative validation average loss is 0.6896951771341264\n",
      "07/18/2023 20:33:08 - INFO - __main__ - Per validation step average loss is 0.16391855478286743\n",
      "07/18/2023 20:33:08 - INFO - __main__ - Cumulative validation average loss is 0.8536137319169939\n",
      "07/18/2023 20:33:08 - INFO - __main__ - Average validation loss for Epoch 144 is 0.07113447765974949\n",
      "07/18/2023 20:33:08 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:33:20 - INFO - __main__ - Starting epoch 145\n",
      "07/18/2023 20:33:21 - INFO - __main__ - train loss is 0.024146419018507004\n",
      "Steps:  94%|▉| 14066/15000 [1:29:59<1:16:27,  4.91s/it, lr=8.71e-6, step_loss=0.07/18/2023 20:33:21 - INFO - __main__ - train loss is 0.08159180730581284\n",
      "Steps:  94%|▉| 14067/15000 [1:29:59<54:18,  3.49s/it, lr=8.71e-6, step_loss=0.0507/18/2023 20:33:21 - INFO - __main__ - train loss is 0.7912463769316673\n",
      "Steps:  94%|▉| 14068/15000 [1:29:59<38:48,  2.50s/it, lr=8.71e-6, step_loss=0.7107/18/2023 20:33:21 - INFO - __main__ - train loss is 0.8194584511220455\n",
      "Steps:  94%|▉| 14069/15000 [1:29:59<27:57,  1.80s/it, lr=8.71e-6, step_loss=0.0207/18/2023 20:33:22 - INFO - __main__ - train loss is 0.9225199036300182\n",
      "Steps:  94%|▉| 14070/15000 [1:29:59<20:22,  1.31s/it, lr=8.71e-6, step_loss=0.1007/18/2023 20:33:22 - INFO - __main__ - train loss is 1.1836609356105328\n",
      "Steps:  94%|▉| 14071/15000 [1:30:00<15:05,  1.03it/s, lr=8.71e-6, step_loss=0.2607/18/2023 20:33:22 - INFO - __main__ - train loss is 1.6234991066157818\n",
      "Steps:  94%|▉| 14072/15000 [1:30:00<11:22,  1.36it/s, lr=8.71e-6, step_loss=0.4407/18/2023 20:33:22 - INFO - __main__ - train loss is 2.0310610942542553\n",
      "Steps:  94%|▉| 14073/15000 [1:30:00<08:46,  1.76it/s, lr=8.71e-6, step_loss=0.4007/18/2023 20:33:22 - INFO - __main__ - train loss is 2.1654175482690334\n",
      "Steps:  94%|▉| 14074/15000 [1:30:00<06:57,  2.22it/s, lr=8.71e-6, step_loss=0.1307/18/2023 20:33:22 - INFO - __main__ - train loss is 2.1839488707482815\n",
      "Steps:  94%|▉| 14075/15000 [1:30:00<05:41,  2.71it/s, lr=8.71e-6, step_loss=0.0107/18/2023 20:33:23 - INFO - __main__ - train loss is 2.304666217416525\n",
      "Steps:  94%|▉| 14076/15000 [1:30:00<04:47,  3.21it/s, lr=8.71e-6, step_loss=0.1207/18/2023 20:33:23 - INFO - __main__ - train loss is 2.309320969507098\n",
      "Steps:  94%|▉| 14077/15000 [1:30:01<04:10,  3.68it/s, lr=8.71e-6, step_loss=0.0007/18/2023 20:33:23 - INFO - __main__ - train loss is 2.3634013440459967\n",
      "Steps:  94%|▉| 14078/15000 [1:30:01<03:44,  4.11it/s, lr=8.71e-6, step_loss=0.0507/18/2023 20:33:23 - INFO - __main__ - train loss is 2.4210242312401533\n",
      "Steps:  94%|▉| 14079/15000 [1:30:01<03:26,  4.47it/s, lr=8.71e-6, step_loss=0.0507/18/2023 20:33:23 - INFO - __main__ - train loss is 2.651301307603717\n",
      "Steps:  94%|▉| 14080/15000 [1:30:01<03:13,  4.76it/s, lr=8.71e-6, step_loss=0.2307/18/2023 20:33:23 - INFO - __main__ - train loss is 2.6933781150728464\n",
      "Steps:  94%|▉| 14081/15000 [1:30:01<03:03,  5.00it/s, lr=8.71e-6, step_loss=0.0407/18/2023 20:33:24 - INFO - __main__ - train loss is 2.886992270126939\n",
      "Steps:  94%|▉| 14082/15000 [1:30:02<02:57,  5.17it/s, lr=8.71e-6, step_loss=0.1907/18/2023 20:33:24 - INFO - __main__ - train loss is 3.1294235829263926\n",
      "Steps:  94%|▉| 14083/15000 [1:30:02<02:53,  5.30it/s, lr=8.7e-6, step_loss=0.24207/18/2023 20:33:24 - INFO - __main__ - train loss is 3.6698387507349253\n",
      "Steps:  94%|▉| 14084/15000 [1:30:02<02:50,  5.38it/s, lr=8.7e-6, step_loss=0.54]07/18/2023 20:33:24 - INFO - __main__ - train loss is 4.087178969755769\n",
      "Steps:  94%|▉| 14085/15000 [1:30:02<02:47,  5.45it/s, lr=8.7e-6, step_loss=0.41707/18/2023 20:33:24 - INFO - __main__ - train loss is 4.089618676574901\n",
      "Steps:  94%|▉| 14086/15000 [1:30:02<02:46,  5.50it/s, lr=8.7e-6, step_loss=0.00207/18/2023 20:33:25 - INFO - __main__ - train loss is 4.091204791213386\n",
      "Steps:  94%|▉| 14087/15000 [1:30:02<02:45,  5.53it/s, lr=8.7e-6, step_loss=0.00107/18/2023 20:33:25 - INFO - __main__ - train loss is 4.100297418306582\n",
      "Steps:  94%|▉| 14088/15000 [1:30:03<02:44,  5.55it/s, lr=8.7e-6, step_loss=0.00907/18/2023 20:33:25 - INFO - __main__ - train loss is 4.138485037605278\n",
      "Steps:  94%|▉| 14089/15000 [1:30:03<02:43,  5.57it/s, lr=8.7e-6, step_loss=0.03807/18/2023 20:33:25 - INFO - __main__ - train loss is 4.251240410725586\n",
      "Steps:  94%|▉| 14090/15000 [1:30:03<02:42,  5.58it/s, lr=8.7e-6, step_loss=0.11307/18/2023 20:33:25 - INFO - __main__ - train loss is 4.255401241942309\n",
      "Steps:  94%|▉| 14091/15000 [1:30:03<02:42,  5.59it/s, lr=8.7e-6, step_loss=0.00407/18/2023 20:33:25 - INFO - __main__ - train loss is 4.315427105291747\n",
      "Steps:  94%|▉| 14092/15000 [1:30:03<02:42,  5.60it/s, lr=8.7e-6, step_loss=0.06]07/18/2023 20:33:26 - INFO - __main__ - train loss is 4.3229517847066745\n",
      "Steps:  94%|▉| 14093/15000 [1:30:04<02:41,  5.60it/s, lr=8.7e-6, step_loss=0.00707/18/2023 20:33:26 - INFO - __main__ - train loss is 4.336272662854753\n",
      "Steps:  94%|▉| 14094/15000 [1:30:04<02:41,  5.60it/s, lr=8.7e-6, step_loss=0.01307/18/2023 20:33:26 - INFO - __main__ - train loss is 5.096658652997576\n",
      "Steps:  94%|▉| 14095/15000 [1:30:04<02:43,  5.55it/s, lr=8.7e-6, step_loss=0.76]07/18/2023 20:33:26 - INFO - __main__ - train loss is 5.145618459559046\n",
      "Steps:  94%|▉| 14096/15000 [1:30:04<02:45,  5.47it/s, lr=8.7e-6, step_loss=0.04907/18/2023 20:33:26 - INFO - __main__ - train loss is 5.158570981002413\n",
      "Steps:  94%|▉| 14097/15000 [1:30:04<02:46,  5.43it/s, lr=8.7e-6, step_loss=0.01307/18/2023 20:33:27 - INFO - __main__ - train loss is 5.160070731653832\n",
      "Steps:  94%|▉| 14098/15000 [1:30:04<02:46,  5.43it/s, lr=8.7e-6, step_loss=0.00107/18/2023 20:33:27 - INFO - __main__ - train loss is 5.464774384512566\n",
      "Steps:  94%|▉| 14099/15000 [1:30:05<02:45,  5.44it/s, lr=8.7e-6, step_loss=0.30507/18/2023 20:33:27 - INFO - __main__ - train loss is 5.473890965222381\n",
      "Steps:  94%|▉| 14100/15000 [1:30:05<02:44,  5.48it/s, lr=8.7e-6, step_loss=0.00907/18/2023 20:33:27 - INFO - __main__ - train loss is 5.5440150102367625\n",
      "Steps:  94%|▉| 14101/15000 [1:30:05<02:43,  5.52it/s, lr=8.7e-6, step_loss=0.07007/18/2023 20:33:27 - INFO - __main__ - train loss is 5.817848434089683\n",
      "Steps:  94%|▉| 14102/15000 [1:30:05<02:43,  5.49it/s, lr=8.7e-6, step_loss=0.27407/18/2023 20:33:27 - INFO - __main__ - train loss is 5.843209081678651\n",
      "Steps:  94%|▉| 14103/15000 [1:30:05<02:43,  5.48it/s, lr=8.7e-6, step_loss=0.02507/18/2023 20:33:28 - INFO - __main__ - train loss is 5.846192936995067\n",
      "Steps:  94%|▉| 14104/15000 [1:30:06<02:42,  5.52it/s, lr=8.7e-6, step_loss=0.00207/18/2023 20:33:28 - INFO - __main__ - train loss is 6.504289727308787\n",
      "Steps:  94%|▉| 14105/15000 [1:30:06<02:41,  5.54it/s, lr=8.7e-6, step_loss=0.65807/18/2023 20:33:28 - INFO - __main__ - train loss is 6.58411214093212\n",
      "Steps:  94%|▉| 14106/15000 [1:30:06<02:40,  5.56it/s, lr=8.7e-6, step_loss=0.07907/18/2023 20:33:28 - INFO - __main__ - train loss is 6.846359166898765\n",
      "Steps:  94%|▉| 14107/15000 [1:30:06<02:40,  5.57it/s, lr=8.7e-6, step_loss=0.26207/18/2023 20:33:28 - INFO - __main__ - train loss is 6.849548327620141\n",
      "Steps:  94%|▉| 14108/15000 [1:30:06<02:39,  5.58it/s, lr=8.7e-6, step_loss=0.00307/18/2023 20:33:29 - INFO - __main__ - train loss is 6.915019991691224\n",
      "Steps:  94%|▉| 14109/15000 [1:30:06<02:39,  5.59it/s, lr=8.7e-6, step_loss=0.06507/18/2023 20:33:29 - INFO - __main__ - train loss is 7.054181280429475\n",
      "Steps:  94%|▉| 14110/15000 [1:30:07<02:39,  5.59it/s, lr=8.7e-6, step_loss=0.13907/18/2023 20:33:29 - INFO - __main__ - train loss is 7.058639786555432\n",
      "Steps:  94%|▉| 14111/15000 [1:30:07<02:38,  5.60it/s, lr=8.7e-6, step_loss=0.00407/18/2023 20:33:29 - INFO - __main__ - train loss is 7.177132792188786\n",
      "Steps:  94%|▉| 14112/15000 [1:30:07<02:38,  5.60it/s, lr=8.7e-6, step_loss=0.11807/18/2023 20:33:29 - INFO - __main__ - train loss is 7.210476796492003\n",
      "Steps:  94%|▉| 14113/15000 [1:30:07<02:38,  5.60it/s, lr=8.7e-6, step_loss=0.03307/18/2023 20:33:29 - INFO - __main__ - train loss is 7.225943793891929\n",
      "Steps:  94%|▉| 14114/15000 [1:30:07<02:38,  5.60it/s, lr=8.7e-6, step_loss=0.01507/18/2023 20:33:30 - INFO - __main__ - train loss is 7.571954419254325\n",
      "Steps:  94%|▉| 14115/15000 [1:30:08<02:39,  5.54it/s, lr=8.7e-6, step_loss=0.34607/18/2023 20:33:30 - INFO - __main__ - train loss is 7.578910666401498\n",
      "Steps:  94%|▉| 14116/15000 [1:30:08<02:41,  5.46it/s, lr=8.7e-6, step_loss=0.00607/18/2023 20:33:30 - INFO - __main__ - train loss is 7.895151871140115\n",
      "Steps:  94%|▉| 14117/15000 [1:30:08<02:43,  5.41it/s, lr=8.7e-6, step_loss=0.31607/18/2023 20:33:30 - INFO - __main__ - train loss is 7.941383535857312\n",
      "Steps:  94%|▉| 14118/15000 [1:30:08<02:42,  5.42it/s, lr=8.7e-6, step_loss=0.04607/18/2023 20:33:30 - INFO - __main__ - train loss is 8.076981599326245\n",
      "Steps:  94%|▉| 14119/15000 [1:30:08<02:41,  5.47it/s, lr=8.7e-6, step_loss=0.13607/18/2023 20:33:31 - INFO - __main__ - train loss is 8.086637214641087\n",
      "Steps:  94%|▉| 14120/15000 [1:30:08<02:39,  5.51it/s, lr=8.7e-6, step_loss=0.00907/18/2023 20:33:31 - INFO - __main__ - train loss is 8.110639159451239\n",
      "Steps:  94%|▉| 14121/15000 [1:30:09<02:38,  5.54it/s, lr=8.7e-6, step_loss=0.02407/18/2023 20:33:31 - INFO - __main__ - train loss is 8.114944246015511\n",
      "Steps:  94%|▉| 14122/15000 [1:30:09<02:38,  5.56it/s, lr=8.7e-6, step_loss=0.00407/18/2023 20:33:31 - INFO - __main__ - train loss is 8.125085439882241\n",
      "Steps:  94%|▉| 14123/15000 [1:30:09<02:37,  5.57it/s, lr=8.7e-6, step_loss=0.01007/18/2023 20:33:31 - INFO - __main__ - train loss is 8.128821844118647\n",
      "Steps:  94%|▉| 14124/15000 [1:30:09<02:36,  5.58it/s, lr=8.7e-6, step_loss=0.00307/18/2023 20:33:31 - INFO - __main__ - train loss is 8.219953792053275\n",
      "Steps:  94%|▉| 14125/15000 [1:30:09<02:36,  5.58it/s, lr=8.7e-6, step_loss=0.09107/18/2023 20:33:32 - INFO - __main__ - train loss is 8.368542121606879\n",
      "Steps:  94%|▉| 14126/15000 [1:30:09<02:36,  5.59it/s, lr=8.7e-6, step_loss=0.14907/18/2023 20:33:32 - INFO - __main__ - train loss is 8.386762983980589\n",
      "Steps:  94%|▉| 14127/15000 [1:30:10<02:36,  5.59it/s, lr=8.7e-6, step_loss=0.01807/18/2023 20:33:32 - INFO - __main__ - train loss is 8.424458540859632\n",
      "Steps:  94%|▉| 14128/15000 [1:30:10<02:37,  5.54it/s, lr=8.7e-6, step_loss=0.03707/18/2023 20:33:32 - INFO - __main__ - train loss is 8.908191777649336\n",
      "Steps:  94%|▉| 14129/15000 [1:30:10<02:37,  5.54it/s, lr=8.7e-6, step_loss=0.48407/18/2023 20:33:32 - INFO - __main__ - train loss is 9.099719978752546\n",
      "Steps:  94%|▉| 14130/15000 [1:30:10<02:36,  5.56it/s, lr=8.7e-6, step_loss=0.19207/18/2023 20:33:33 - INFO - __main__ - train loss is 9.107699252548628\n",
      "Steps:  94%|▉| 14131/15000 [1:30:10<02:37,  5.53it/s, lr=8.7e-6, step_loss=0.00707/18/2023 20:33:33 - INFO - __main__ - train loss is 9.109240457531996\n",
      "Steps:  94%|▉| 14132/15000 [1:30:11<02:37,  5.51it/s, lr=8.7e-6, step_loss=0.00107/18/2023 20:33:33 - INFO - __main__ - train loss is 9.365697488305159\n",
      "Steps:  94%|▉| 14133/15000 [1:30:11<02:36,  5.53it/s, lr=8.7e-6, step_loss=0.25607/18/2023 20:33:33 - INFO - __main__ - train loss is 9.90865515184123\n",
      "Steps:  94%|▉| 14134/15000 [1:30:11<02:35,  5.55it/s, lr=8.7e-6, step_loss=0.54307/18/2023 20:33:33 - INFO - __main__ - train loss is 9.914211035356857\n",
      "Steps:  94%|▉| 14135/15000 [1:30:11<02:36,  5.53it/s, lr=8.7e-6, step_loss=0.00507/18/2023 20:33:33 - INFO - __main__ - train loss is 9.988226280198433\n",
      "Steps:  94%|▉| 14136/15000 [1:30:11<02:35,  5.56it/s, lr=8.7e-6, step_loss=0.07407/18/2023 20:33:34 - INFO - __main__ - train loss is 10.002258508116938\n",
      "Steps:  94%|▉| 14137/15000 [1:30:11<02:34,  5.57it/s, lr=8.7e-6, step_loss=0.01407/18/2023 20:33:34 - INFO - __main__ - train loss is 10.889636604697444\n",
      "Steps:  94%|▉| 14138/15000 [1:30:12<02:34,  5.58it/s, lr=8.7e-6, step_loss=0.88707/18/2023 20:33:34 - INFO - __main__ - train loss is 10.90160457661841\n",
      "Steps:  94%|▉| 14139/15000 [1:30:12<02:34,  5.59it/s, lr=8.69e-6, step_loss=0.0107/18/2023 20:33:34 - INFO - __main__ - train loss is 10.943664951832034\n",
      "Steps:  94%|▉| 14140/15000 [1:30:12<02:33,  5.59it/s, lr=8.69e-6, step_loss=0.0407/18/2023 20:33:34 - INFO - __main__ - train loss is 11.48287419846747\n",
      "Steps:  94%|▉| 14141/15000 [1:30:12<02:34,  5.56it/s, lr=8.69e-6, step_loss=0.5307/18/2023 20:33:34 - INFO - __main__ - train loss is 11.54872524610255\n",
      "Steps:  94%|▉| 14142/15000 [1:30:12<02:35,  5.52it/s, lr=8.69e-6, step_loss=0.0607/18/2023 20:33:35 - INFO - __main__ - train loss is 11.589102982194163\n",
      "Steps:  94%|▉| 14143/15000 [1:30:13<02:35,  5.52it/s, lr=8.69e-6, step_loss=0.0407/18/2023 20:33:35 - INFO - __main__ - train loss is 11.648470601649024\n",
      "Steps:  94%|▉| 14144/15000 [1:30:13<02:34,  5.55it/s, lr=8.69e-6, step_loss=0.0507/18/2023 20:33:35 - INFO - __main__ - train loss is 11.650293695973232\n",
      "Steps:  94%|▉| 14145/15000 [1:30:13<02:33,  5.56it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:33:35 - INFO - __main__ - train loss is 11.81149213318713\n",
      "Steps:  94%|▉| 14146/15000 [1:30:13<02:33,  5.57it/s, lr=8.69e-6, step_loss=0.1607/18/2023 20:33:35 - INFO - __main__ - train loss is 12.07092087273486\n",
      "Steps:  94%|▉| 14147/15000 [1:30:13<02:32,  5.59it/s, lr=8.69e-6, step_loss=0.2507/18/2023 20:33:36 - INFO - __main__ - train loss is 12.188147376524284\n",
      "Steps:  94%|▉| 14148/15000 [1:30:13<02:32,  5.60it/s, lr=8.69e-6, step_loss=0.1107/18/2023 20:33:36 - INFO - __main__ - train loss is 12.192362444708124\n",
      "Steps:  94%|▉| 14149/15000 [1:30:14<02:31,  5.60it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:33:36 - INFO - __main__ - train loss is 12.200987026328221\n",
      "Steps:  94%|▉| 14150/15000 [1:30:14<02:31,  5.60it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:33:36 - INFO - __main__ - train loss is 12.222497146809474\n",
      "Steps:  94%|▉| 14151/15000 [1:30:14<02:31,  5.61it/s, lr=8.69e-6, step_loss=0.0207/18/2023 20:33:36 - INFO - __main__ - train loss is 12.497408133232966\n",
      "Steps:  94%|▉| 14152/15000 [1:30:14<02:31,  5.61it/s, lr=8.69e-6, step_loss=0.2707/18/2023 20:33:36 - INFO - __main__ - train loss is 12.504353187279776\n",
      "Steps:  94%|▉| 14153/15000 [1:30:14<02:31,  5.61it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:33:37 - INFO - __main__ - train loss is 12.602310396032408\n",
      "Steps:  94%|▉| 14154/15000 [1:30:15<02:30,  5.61it/s, lr=8.69e-6, step_loss=0.0907/18/2023 20:33:37 - INFO - __main__ - train loss is 12.81436266680248\n",
      "Steps:  94%|▉| 14155/15000 [1:30:15<02:32,  5.56it/s, lr=8.69e-6, step_loss=0.2107/18/2023 20:33:37 - INFO - __main__ - train loss is 12.83592297253199\n",
      "Steps:  94%|▉| 14156/15000 [1:30:15<02:31,  5.57it/s, lr=8.69e-6, step_loss=0.0207/18/2023 20:33:37 - INFO - __main__ - train loss is 13.762544648023322\n",
      "Steps:  94%|▉| 14157/15000 [1:30:15<02:31,  5.58it/s, lr=8.69e-6, step_loss=0.9207/18/2023 20:33:37 - INFO - __main__ - train loss is 14.22348062810488\n",
      "Steps:  94%|▉| 14158/15000 [1:30:15<02:30,  5.59it/s, lr=8.69e-6, step_loss=0.4607/18/2023 20:33:38 - INFO - __main__ - train loss is 14.351083488436416\n",
      "Steps:  94%|▉| 14159/15000 [1:30:15<02:30,  5.60it/s, lr=8.69e-6, step_loss=0.1207/18/2023 20:33:38 - INFO - __main__ - train loss is 14.768637986155227\n",
      "Steps:  94%|▉| 14160/15000 [1:30:16<02:30,  5.60it/s, lr=8.69e-6, step_loss=0.4107/18/2023 20:33:38 - INFO - __main__ - train loss is 15.046483815880492\n",
      "Steps:  94%|▉| 14161/15000 [1:30:16<02:29,  5.60it/s, lr=8.69e-6, step_loss=0.2707/18/2023 20:33:38 - INFO - __main__ - train loss is 15.147103631170467\n",
      "Steps:  94%|▉| 14162/15000 [1:30:16<03:37,  3.85it/s, lr=8.69e-6, step_loss=0.1007/18/2023 20:33:39 - INFO - __main__ - Per validation step average loss is 0.08869180083274841\n",
      "07/18/2023 20:33:39 - INFO - __main__ - Cumulative validation average loss is 0.08869180083274841\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Per validation step average loss is 0.018394894897937775\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Cumulative validation average loss is 0.10708669573068619\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Per validation step average loss is 0.11608242243528366\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Cumulative validation average loss is 0.22316911816596985\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Per validation step average loss is 0.00798079464584589\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Cumulative validation average loss is 0.23114991281181574\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Per validation step average loss is 0.3431951403617859\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Cumulative validation average loss is 0.5743450531736016\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Per validation step average loss is 0.004120794124901295\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Cumulative validation average loss is 0.5784658472985029\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Per validation step average loss is 0.5698651075363159\n",
      "07/18/2023 20:33:40 - INFO - __main__ - Cumulative validation average loss is 1.1483309548348188\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Per validation step average loss is 0.015254260040819645\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Cumulative validation average loss is 1.1635852148756385\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Per validation step average loss is 0.07926014065742493\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Cumulative validation average loss is 1.2428453555330634\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Per validation step average loss is 0.09412684291601181\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Cumulative validation average loss is 1.3369721984490752\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Per validation step average loss is 0.29391682147979736\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Cumulative validation average loss is 1.6308890199288726\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Per validation step average loss is 0.31910979747772217\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Cumulative validation average loss is 1.9499988174065948\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Average validation loss for Epoch 145 is 0.16249990145054957\n",
      "07/18/2023 20:33:41 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:33:54 - INFO - __main__ - Starting epoch 146\n",
      "07/18/2023 20:33:55 - INFO - __main__ - train loss is 0.008950775489211082\n",
      "Steps:  94%|▉| 14163/15000 [1:30:33<1:12:23,  5.19s/it, lr=8.69e-6, step_loss=0.07/18/2023 20:33:55 - INFO - __main__ - train loss is 0.35583636723458767\n",
      "Steps:  94%|▉| 14164/15000 [1:30:33<51:21,  3.69s/it, lr=8.69e-6, step_loss=0.3407/18/2023 20:33:55 - INFO - __main__ - train loss is 0.5637391414493322\n",
      "Steps:  94%|▉| 14165/15000 [1:30:33<36:39,  2.63s/it, lr=8.69e-6, step_loss=0.2007/18/2023 20:33:56 - INFO - __main__ - train loss is 0.5924802348017693\n",
      "Steps:  94%|▉| 14166/15000 [1:30:33<26:21,  1.90s/it, lr=8.69e-6, step_loss=0.0207/18/2023 20:33:56 - INFO - __main__ - train loss is 0.6033642292022705\n",
      "Steps:  94%|▉| 14167/15000 [1:30:34<19:10,  1.38s/it, lr=8.69e-6, step_loss=0.0107/18/2023 20:33:56 - INFO - __main__ - train loss is 0.8137634247541428\n",
      "Steps:  94%|▉| 14168/15000 [1:30:34<14:09,  1.02s/it, lr=8.69e-6, step_loss=0.2107/18/2023 20:33:56 - INFO - __main__ - train loss is 0.8268284760415554\n",
      "Steps:  94%|▉| 14169/15000 [1:30:34<10:38,  1.30it/s, lr=8.69e-6, step_loss=0.0107/18/2023 20:33:56 - INFO - __main__ - train loss is 1.5142902694642544\n",
      "Steps:  94%|▉| 14170/15000 [1:30:34<08:10,  1.69it/s, lr=8.69e-6, step_loss=0.6807/18/2023 20:33:56 - INFO - __main__ - train loss is 1.5199613445438445\n",
      "Steps:  94%|▉| 14171/15000 [1:30:34<06:27,  2.14it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:33:57 - INFO - __main__ - train loss is 1.5316605265252292\n",
      "Steps:  94%|▉| 14172/15000 [1:30:35<05:14,  2.63it/s, lr=8.69e-6, step_loss=0.0107/18/2023 20:33:57 - INFO - __main__ - train loss is 1.600515156518668\n",
      "Steps:  94%|▉| 14173/15000 [1:30:35<04:24,  3.13it/s, lr=8.69e-6, step_loss=0.0607/18/2023 20:33:57 - INFO - __main__ - train loss is 1.6844063247554004\n",
      "Steps:  94%|▉| 14174/15000 [1:30:35<03:48,  3.61it/s, lr=8.69e-6, step_loss=0.0807/18/2023 20:33:57 - INFO - __main__ - train loss is 1.7163335676304996\n",
      "Steps:  94%|▉| 14175/15000 [1:30:35<03:23,  4.05it/s, lr=8.69e-6, step_loss=0.0307/18/2023 20:33:57 - INFO - __main__ - train loss is 1.7570523913018405\n",
      "Steps:  95%|▉| 14176/15000 [1:30:35<03:06,  4.42it/s, lr=8.69e-6, step_loss=0.0407/18/2023 20:33:58 - INFO - __main__ - train loss is 1.8791327173821628\n",
      "Steps:  95%|▉| 14177/15000 [1:30:35<02:54,  4.72it/s, lr=8.69e-6, step_loss=0.1207/18/2023 20:33:58 - INFO - __main__ - train loss is 2.1691307122819126\n",
      "Steps:  95%|▉| 14178/15000 [1:30:36<02:45,  4.96it/s, lr=8.69e-6, step_loss=0.2907/18/2023 20:33:58 - INFO - __main__ - train loss is 2.2809343333356082\n",
      "Steps:  95%|▉| 14179/15000 [1:30:36<02:39,  5.14it/s, lr=8.69e-6, step_loss=0.1107/18/2023 20:33:58 - INFO - __main__ - train loss is 2.3250635894946754\n",
      "Steps:  95%|▉| 14180/15000 [1:30:36<02:35,  5.27it/s, lr=8.69e-6, step_loss=0.0407/18/2023 20:33:58 - INFO - __main__ - train loss is 2.645004156511277\n",
      "Steps:  95%|▉| 14181/15000 [1:30:36<02:32,  5.36it/s, lr=8.69e-6, step_loss=0.3207/18/2023 20:33:58 - INFO - __main__ - train loss is 2.6464718133211136\n",
      "Steps:  95%|▉| 14182/15000 [1:30:36<02:30,  5.44it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:33:59 - INFO - __main__ - train loss is 2.648044747300446\n",
      "Steps:  95%|▉| 14183/15000 [1:30:36<02:28,  5.49it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:33:59 - INFO - __main__ - train loss is 2.678073582239449\n",
      "Steps:  95%|▉| 14184/15000 [1:30:37<02:27,  5.52it/s, lr=8.69e-6, step_loss=0.0307/18/2023 20:33:59 - INFO - __main__ - train loss is 2.7758312122896314\n",
      "Steps:  95%|▉| 14185/15000 [1:30:37<02:27,  5.54it/s, lr=8.69e-6, step_loss=0.0907/18/2023 20:33:59 - INFO - __main__ - train loss is 2.965671648271382\n",
      "Steps:  95%|▉| 14186/15000 [1:30:37<02:26,  5.56it/s, lr=8.69e-6, step_loss=0.1907/18/2023 20:33:59 - INFO - __main__ - train loss is 2.9929044088348746\n",
      "Steps:  95%|▉| 14187/15000 [1:30:37<02:25,  5.57it/s, lr=8.69e-6, step_loss=0.0207/18/2023 20:33:59 - INFO - __main__ - train loss is 3.3413045248016715\n",
      "Steps:  95%|▉| 14188/15000 [1:30:37<02:25,  5.58it/s, lr=8.69e-6, step_loss=0.3407/18/2023 20:34:00 - INFO - __main__ - train loss is 3.355289790779352\n",
      "Steps:  95%|▉| 14189/15000 [1:30:38<02:25,  5.58it/s, lr=8.69e-6, step_loss=0.0107/18/2023 20:34:00 - INFO - __main__ - train loss is 3.3629978140816092\n",
      "Steps:  95%|▉| 14190/15000 [1:30:38<02:24,  5.59it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:34:00 - INFO - __main__ - train loss is 3.563639803789556\n",
      "Steps:  95%|▉| 14191/15000 [1:30:38<02:24,  5.60it/s, lr=8.69e-6, step_loss=0.2007/18/2023 20:34:00 - INFO - __main__ - train loss is 4.490328355692327\n",
      "Steps:  95%|▉| 14192/15000 [1:30:38<02:26,  5.51it/s, lr=8.69e-6, step_loss=0.9207/18/2023 20:34:00 - INFO - __main__ - train loss is 4.493451874703169\n",
      "Steps:  95%|▉| 14193/15000 [1:30:38<02:25,  5.54it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:34:01 - INFO - __main__ - train loss is 4.49814434396103\n",
      "Steps:  95%|▉| 14194/15000 [1:30:38<02:25,  5.56it/s, lr=8.69e-6, step_loss=0.0007/18/2023 20:34:01 - INFO - __main__ - train loss is 4.766950235236436\n",
      "Steps:  95%|▉| 14195/15000 [1:30:39<02:24,  5.57it/s, lr=8.69e-6, step_loss=0.2607/18/2023 20:34:01 - INFO - __main__ - train loss is 5.07122139679268\n",
      "Steps:  95%|▉| 14196/15000 [1:30:39<02:24,  5.58it/s, lr=8.68e-6, step_loss=0.3007/18/2023 20:34:01 - INFO - __main__ - train loss is 5.2755756680853665\n",
      "Steps:  95%|▉| 14197/15000 [1:30:39<02:23,  5.59it/s, lr=8.68e-6, step_loss=0.2007/18/2023 20:34:01 - INFO - __main__ - train loss is 5.325396463740617\n",
      "Steps:  95%|▉| 14198/15000 [1:30:39<02:23,  5.59it/s, lr=8.68e-6, step_loss=0.0407/18/2023 20:34:01 - INFO - __main__ - train loss is 5.837174997199327\n",
      "Steps:  95%|▉| 14199/15000 [1:30:39<02:23,  5.60it/s, lr=8.68e-6, step_loss=0.5107/18/2023 20:34:02 - INFO - __main__ - train loss is 6.1568360780365765\n",
      "Steps:  95%|▉| 14200/15000 [1:30:40<02:23,  5.59it/s, lr=8.68e-6, step_loss=0.3207/18/2023 20:34:02 - INFO - __main__ - train loss is 6.388115689624101\n",
      "Steps:  95%|▉| 14201/15000 [1:30:40<02:22,  5.59it/s, lr=8.68e-6, step_loss=0.2307/18/2023 20:34:02 - INFO - __main__ - train loss is 6.482912376988679\n",
      "Steps:  95%|▉| 14202/15000 [1:30:40<02:22,  5.60it/s, lr=8.68e-6, step_loss=0.0907/18/2023 20:34:02 - INFO - __main__ - train loss is 6.529082220513374\n",
      "Steps:  95%|▉| 14203/15000 [1:30:40<02:22,  5.60it/s, lr=8.68e-6, step_loss=0.0407/18/2023 20:34:02 - INFO - __main__ - train loss is 6.93891040654853\n",
      "Steps:  95%|▉| 14204/15000 [1:30:40<02:22,  5.60it/s, lr=8.68e-6, step_loss=0.4107/18/2023 20:34:03 - INFO - __main__ - train loss is 6.999408048111945\n",
      "Steps:  95%|▉| 14205/15000 [1:30:40<02:23,  5.55it/s, lr=8.68e-6, step_loss=0.0607/18/2023 20:34:03 - INFO - __main__ - train loss is 7.009951975662261\n",
      "Steps:  95%|▉| 14206/15000 [1:30:41<02:25,  5.46it/s, lr=8.68e-6, step_loss=0.0107/18/2023 20:34:03 - INFO - __main__ - train loss is 7.031403597909957\n",
      "Steps:  95%|▉| 14207/15000 [1:30:41<02:24,  5.50it/s, lr=8.68e-6, step_loss=0.0207/18/2023 20:34:03 - INFO - __main__ - train loss is 7.203160834033042\n",
      "Steps:  95%|▉| 14208/15000 [1:30:41<02:24,  5.48it/s, lr=8.68e-6, step_loss=0.1707/18/2023 20:34:03 - INFO - __main__ - train loss is 7.2111117844469845\n",
      "Steps:  95%|▉| 14209/15000 [1:30:41<02:23,  5.52it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:03 - INFO - __main__ - train loss is 7.222150205168873\n",
      "Steps:  95%|▉| 14210/15000 [1:30:41<02:22,  5.54it/s, lr=8.68e-6, step_loss=0.0107/18/2023 20:34:04 - INFO - __main__ - train loss is 7.27215855801478\n",
      "Steps:  95%|▉| 14211/15000 [1:30:42<02:21,  5.56it/s, lr=8.68e-6, step_loss=0.0507/18/2023 20:34:04 - INFO - __main__ - train loss is 7.277222773525864\n",
      "Steps:  95%|▉| 14212/15000 [1:30:42<02:21,  5.57it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:04 - INFO - __main__ - train loss is 7.317740058992058\n",
      "Steps:  95%|▉| 14213/15000 [1:30:42<02:22,  5.52it/s, lr=8.68e-6, step_loss=0.0407/18/2023 20:34:04 - INFO - __main__ - train loss is 7.387304580304772\n",
      "Steps:  95%|▉| 14214/15000 [1:30:42<02:22,  5.51it/s, lr=8.68e-6, step_loss=0.0607/18/2023 20:34:04 - INFO - __main__ - train loss is 7.392349167261273\n",
      "Steps:  95%|▉| 14215/15000 [1:30:42<02:21,  5.53it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:05 - INFO - __main__ - train loss is 7.423025930766016\n",
      "Steps:  95%|▉| 14216/15000 [1:30:42<02:21,  5.55it/s, lr=8.68e-6, step_loss=0.0307/18/2023 20:34:05 - INFO - __main__ - train loss is 7.441690611187369\n",
      "Steps:  95%|▉| 14217/15000 [1:30:43<02:20,  5.57it/s, lr=8.68e-6, step_loss=0.0107/18/2023 20:34:05 - INFO - __main__ - train loss is 7.783055710140616\n",
      "Steps:  95%|▉| 14218/15000 [1:30:43<02:20,  5.58it/s, lr=8.68e-6, step_loss=0.3407/18/2023 20:34:05 - INFO - __main__ - train loss is 7.808887390885502\n",
      "Steps:  95%|▉| 14219/15000 [1:30:43<02:19,  5.59it/s, lr=8.68e-6, step_loss=0.0207/18/2023 20:34:05 - INFO - __main__ - train loss is 7.886170400772244\n",
      "Steps:  95%|▉| 14220/15000 [1:30:43<02:19,  5.59it/s, lr=8.68e-6, step_loss=0.0707/18/2023 20:34:05 - INFO - __main__ - train loss is 8.014310403261334\n",
      "Steps:  95%|▉| 14221/15000 [1:30:43<02:19,  5.60it/s, lr=8.68e-6, step_loss=0.1207/18/2023 20:34:06 - INFO - __main__ - train loss is 8.016722348053008\n",
      "Steps:  95%|▉| 14222/15000 [1:30:43<02:18,  5.61it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:06 - INFO - __main__ - train loss is 8.062276367563754\n",
      "Steps:  95%|▉| 14223/15000 [1:30:44<02:18,  5.60it/s, lr=8.68e-6, step_loss=0.0407/18/2023 20:34:06 - INFO - __main__ - train loss is 8.066066408064216\n",
      "Steps:  95%|▉| 14224/15000 [1:30:44<02:18,  5.60it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:06 - INFO - __main__ - train loss is 8.580659055616707\n",
      "Steps:  95%|▉| 14225/15000 [1:30:44<02:18,  5.60it/s, lr=8.68e-6, step_loss=0.5107/18/2023 20:34:06 - INFO - __main__ - train loss is 8.862333738710731\n",
      "Steps:  95%|▉| 14226/15000 [1:30:44<02:18,  5.60it/s, lr=8.68e-6, step_loss=0.2807/18/2023 20:34:06 - INFO - __main__ - train loss is 9.063533419277519\n",
      "Steps:  95%|▉| 14227/15000 [1:30:44<02:18,  5.60it/s, lr=8.68e-6, step_loss=0.2007/18/2023 20:34:07 - INFO - __main__ - train loss is 9.06548791565001\n",
      "Steps:  95%|▉| 14228/15000 [1:30:45<02:18,  5.59it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:07 - INFO - __main__ - train loss is 9.087004944682121\n",
      "Steps:  95%|▉| 14229/15000 [1:30:45<02:17,  5.59it/s, lr=8.68e-6, step_loss=0.0207/18/2023 20:34:07 - INFO - __main__ - train loss is 9.191102981567383\n",
      "Steps:  95%|▉| 14230/15000 [1:30:45<02:17,  5.59it/s, lr=8.68e-6, step_loss=0.1007/18/2023 20:34:07 - INFO - __main__ - train loss is 9.19565992616117\n",
      "Steps:  95%|▉| 14231/15000 [1:30:45<02:17,  5.59it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:07 - INFO - __main__ - train loss is 9.305910652503371\n",
      "Steps:  95%|▉| 14232/15000 [1:30:45<02:17,  5.60it/s, lr=8.68e-6, step_loss=0.1107/18/2023 20:34:08 - INFO - __main__ - train loss is 9.320501188747585\n",
      "Steps:  95%|▉| 14233/15000 [1:30:45<02:17,  5.60it/s, lr=8.68e-6, step_loss=0.0107/18/2023 20:34:08 - INFO - __main__ - train loss is 9.970679621212184\n",
      "Steps:  95%|▉| 14234/15000 [1:30:46<02:16,  5.60it/s, lr=8.68e-6, step_loss=0.6507/18/2023 20:34:08 - INFO - __main__ - train loss is 10.060179869644344\n",
      "Steps:  95%|▉| 14235/15000 [1:30:46<02:16,  5.60it/s, lr=8.68e-6, step_loss=0.0807/18/2023 20:34:08 - INFO - __main__ - train loss is 10.064439619891346\n",
      "Steps:  95%|▉| 14236/15000 [1:30:46<02:16,  5.60it/s, lr=8.68e-6, step_loss=0.0007/18/2023 20:34:08 - INFO - __main__ - train loss is 10.079683938995004\n",
      "Steps:  95%|▉| 14237/15000 [1:30:46<02:16,  5.59it/s, lr=8.68e-6, step_loss=0.0107/18/2023 20:34:08 - INFO - __main__ - train loss is 10.335704991593957\n",
      "Steps:  95%|▉| 14238/15000 [1:30:46<02:16,  5.58it/s, lr=8.68e-6, step_loss=0.2507/18/2023 20:34:09 - INFO - __main__ - train loss is 10.346751127392054\n",
      "Steps:  95%|▉| 14239/15000 [1:30:47<02:16,  5.58it/s, lr=8.68e-6, step_loss=0.0107/18/2023 20:34:09 - INFO - __main__ - train loss is 10.563424486666918\n",
      "Steps:  95%|▉| 14240/15000 [1:30:47<02:16,  5.58it/s, lr=8.68e-6, step_loss=0.2107/18/2023 20:34:09 - INFO - __main__ - train loss is 11.071563381701708\n",
      "Steps:  95%|▉| 14241/15000 [1:30:47<02:15,  5.58it/s, lr=8.68e-6, step_loss=0.5007/18/2023 20:34:09 - INFO - __main__ - train loss is 11.43264015391469\n",
      "Steps:  95%|▉| 14242/15000 [1:30:47<02:15,  5.59it/s, lr=8.68e-6, step_loss=0.3607/18/2023 20:34:09 - INFO - __main__ - train loss is 11.770563054829836\n",
      "Steps:  95%|▉| 14243/15000 [1:30:47<02:15,  5.60it/s, lr=8.68e-6, step_loss=0.3307/18/2023 20:34:10 - INFO - __main__ - train loss is 11.830221127718687\n",
      "Steps:  95%|▉| 14244/15000 [1:30:47<02:14,  5.60it/s, lr=8.68e-6, step_loss=0.0507/18/2023 20:34:10 - INFO - __main__ - train loss is 12.250977586954832\n",
      "Steps:  95%|▉| 14245/15000 [1:30:48<02:14,  5.60it/s, lr=8.68e-6, step_loss=0.4207/18/2023 20:34:10 - INFO - __main__ - train loss is 12.262920105829835\n",
      "Steps:  95%|▉| 14246/15000 [1:30:48<02:14,  5.60it/s, lr=8.68e-6, step_loss=0.0107/18/2023 20:34:10 - INFO - __main__ - train loss is 12.32936362363398\n",
      "Steps:  95%|▉| 14247/15000 [1:30:48<02:14,  5.60it/s, lr=8.68e-6, step_loss=0.0607/18/2023 20:34:10 - INFO - __main__ - train loss is 12.47589666582644\n",
      "Steps:  95%|▉| 14248/15000 [1:30:48<02:14,  5.61it/s, lr=8.68e-6, step_loss=0.1407/18/2023 20:34:10 - INFO - __main__ - train loss is 12.593706959858537\n",
      "Steps:  95%|▉| 14249/15000 [1:30:48<02:13,  5.61it/s, lr=8.68e-6, step_loss=0.1107/18/2023 20:34:11 - INFO - __main__ - train loss is 12.62890158034861\n",
      "Steps:  95%|▉| 14250/15000 [1:30:48<02:13,  5.61it/s, lr=8.68e-6, step_loss=0.0307/18/2023 20:34:11 - INFO - __main__ - train loss is 13.225283304229379\n",
      "Steps:  95%|▉| 14251/15000 [1:30:49<02:13,  5.61it/s, lr=8.68e-6, step_loss=0.5907/18/2023 20:34:11 - INFO - __main__ - train loss is 13.299716273322701\n",
      "Steps:  95%|▉| 14252/15000 [1:30:49<02:13,  5.60it/s, lr=8.67e-6, step_loss=0.0707/18/2023 20:34:11 - INFO - __main__ - train loss is 13.351247439160943\n",
      "Steps:  95%|▉| 14253/15000 [1:30:49<02:14,  5.55it/s, lr=8.67e-6, step_loss=0.0507/18/2023 20:34:11 - INFO - __main__ - train loss is 13.414254883304238\n",
      "Steps:  95%|▉| 14254/15000 [1:30:49<02:13,  5.57it/s, lr=8.67e-6, step_loss=0.0607/18/2023 20:34:11 - INFO - __main__ - train loss is 13.423303874209523\n",
      "Steps:  95%|▉| 14255/15000 [1:30:49<02:13,  5.58it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:12 - INFO - __main__ - train loss is 13.431947390548885\n",
      "Steps:  95%|▉| 14256/15000 [1:30:50<02:14,  5.54it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:12 - INFO - __main__ - train loss is 13.68095778953284\n",
      "Steps:  95%|▉| 14257/15000 [1:30:50<02:13,  5.56it/s, lr=8.67e-6, step_loss=0.2407/18/2023 20:34:12 - INFO - __main__ - train loss is 13.815526659600437\n",
      "Steps:  95%|▉| 14258/15000 [1:30:50<02:13,  5.58it/s, lr=8.67e-6, step_loss=0.1307/18/2023 20:34:12 - INFO - __main__ - train loss is 13.934905062429607\n",
      "Steps:  95%|▉| 14259/15000 [1:30:50<03:03,  4.03it/s, lr=8.67e-6, step_loss=0.1107/18/2023 20:34:13 - INFO - __main__ - Per validation step average loss is 0.002286883071064949\n",
      "07/18/2023 20:34:13 - INFO - __main__ - Cumulative validation average loss is 0.002286883071064949\n",
      "07/18/2023 20:34:13 - INFO - __main__ - Per validation step average loss is 0.20197635889053345\n",
      "07/18/2023 20:34:13 - INFO - __main__ - Cumulative validation average loss is 0.2042632419615984\n",
      "07/18/2023 20:34:13 - INFO - __main__ - Per validation step average loss is 0.6479488611221313\n",
      "07/18/2023 20:34:13 - INFO - __main__ - Cumulative validation average loss is 0.8522121030837297\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Per validation step average loss is 0.034925203770399094\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Cumulative validation average loss is 0.8871373068541288\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Per validation step average loss is 0.42843639850616455\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Cumulative validation average loss is 1.3155737053602934\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Per validation step average loss is 0.045649994164705276\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Cumulative validation average loss is 1.3612236995249987\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Per validation step average loss is 0.05492742359638214\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Cumulative validation average loss is 1.4161511231213808\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Per validation step average loss is 0.07092195004224777\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Cumulative validation average loss is 1.4870730731636286\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Per validation step average loss is 0.003505328204482794\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Cumulative validation average loss is 1.4905784013681114\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Per validation step average loss is 0.002642479259520769\n",
      "07/18/2023 20:34:14 - INFO - __main__ - Cumulative validation average loss is 1.4932208806276321\n",
      "07/18/2023 20:34:15 - INFO - __main__ - Per validation step average loss is 0.10771308094263077\n",
      "07/18/2023 20:34:15 - INFO - __main__ - Cumulative validation average loss is 1.600933961570263\n",
      "07/18/2023 20:34:15 - INFO - __main__ - Per validation step average loss is 0.0735633373260498\n",
      "07/18/2023 20:34:15 - INFO - __main__ - Cumulative validation average loss is 1.6744972988963127\n",
      "07/18/2023 20:34:15 - INFO - __main__ - Average validation loss for Epoch 146 is 0.13954144157469273\n",
      "07/18/2023 20:34:15 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:34:28 - INFO - __main__ - Starting epoch 147\n",
      "07/18/2023 20:34:28 - INFO - __main__ - train loss is 0.33095526695251465\n",
      "Steps:  95%|▉| 14260/15000 [1:31:06<1:01:03,  4.95s/it, lr=8.67e-6, step_loss=0.07/18/2023 20:34:29 - INFO - __main__ - train loss is 0.3462892286479473\n",
      "Steps:  95%|▉| 14261/15000 [1:31:06<43:21,  3.52s/it, lr=8.67e-6, step_loss=0.0107/18/2023 20:34:29 - INFO - __main__ - train loss is 0.6653006188571453\n",
      "Steps:  95%|▉| 14262/15000 [1:31:07<30:57,  2.52s/it, lr=8.67e-6, step_loss=0.3107/18/2023 20:34:29 - INFO - __main__ - train loss is 0.8438216261565685\n",
      "Steps:  95%|▉| 14263/15000 [1:31:07<22:18,  1.82s/it, lr=8.67e-6, step_loss=0.1707/18/2023 20:34:29 - INFO - __main__ - train loss is 0.8502791179344058\n",
      "Steps:  95%|▉| 14264/15000 [1:31:07<16:14,  1.32s/it, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:29 - INFO - __main__ - train loss is 0.9698215378448367\n",
      "Steps:  95%|▉| 14265/15000 [1:31:07<12:01,  1.02it/s, lr=8.67e-6, step_loss=0.1207/18/2023 20:34:29 - INFO - __main__ - train loss is 1.272186036221683\n",
      "Steps:  95%|▉| 14266/15000 [1:31:07<09:03,  1.35it/s, lr=8.67e-6, step_loss=0.3007/18/2023 20:34:30 - INFO - __main__ - train loss is 1.320462535135448\n",
      "Steps:  95%|▉| 14267/15000 [1:31:08<06:59,  1.75it/s, lr=8.67e-6, step_loss=0.0407/18/2023 20:34:30 - INFO - __main__ - train loss is 1.6041051847860217\n",
      "Steps:  95%|▉| 14268/15000 [1:31:08<05:32,  2.20it/s, lr=8.67e-6, step_loss=0.2807/18/2023 20:34:30 - INFO - __main__ - train loss is 1.6244000820443034\n",
      "Steps:  95%|▉| 14269/15000 [1:31:08<04:31,  2.69it/s, lr=8.67e-6, step_loss=0.0207/18/2023 20:34:30 - INFO - __main__ - train loss is 1.6874305633828044\n",
      "Steps:  95%|▉| 14270/15000 [1:31:08<03:48,  3.19it/s, lr=8.67e-6, step_loss=0.0607/18/2023 20:34:30 - INFO - __main__ - train loss is 1.7020081905648112\n",
      "Steps:  95%|▉| 14271/15000 [1:31:08<03:18,  3.67it/s, lr=8.67e-6, step_loss=0.0107/18/2023 20:34:31 - INFO - __main__ - train loss is 1.7454006997868419\n",
      "Steps:  95%|▉| 14272/15000 [1:31:08<02:57,  4.09it/s, lr=8.67e-6, step_loss=0.0407/18/2023 20:34:31 - INFO - __main__ - train loss is 2.3885675398632884\n",
      "Steps:  95%|▉| 14273/15000 [1:31:09<02:43,  4.45it/s, lr=8.67e-6, step_loss=0.6407/18/2023 20:34:31 - INFO - __main__ - train loss is 2.827833536081016\n",
      "Steps:  95%|▉| 14274/15000 [1:31:09<02:33,  4.74it/s, lr=8.67e-6, step_loss=0.4307/18/2023 20:34:31 - INFO - __main__ - train loss is 3.0346206007525325\n",
      "Steps:  95%|▉| 14275/15000 [1:31:09<02:25,  4.97it/s, lr=8.67e-6, step_loss=0.2007/18/2023 20:34:31 - INFO - __main__ - train loss is 3.039821598213166\n",
      "Steps:  95%|▉| 14276/15000 [1:31:09<02:20,  5.15it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:31 - INFO - __main__ - train loss is 3.0418704841285944\n",
      "Steps:  95%|▉| 14277/15000 [1:31:09<02:17,  5.28it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:32 - INFO - __main__ - train loss is 3.0809622947126627\n",
      "Steps:  95%|▉| 14278/15000 [1:31:09<02:14,  5.36it/s, lr=8.67e-6, step_loss=0.0307/18/2023 20:34:32 - INFO - __main__ - train loss is 3.0851408317685127\n",
      "Steps:  95%|▉| 14279/15000 [1:31:10<02:12,  5.43it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:32 - INFO - __main__ - train loss is 3.095425818115473\n",
      "Steps:  95%|▉| 14280/15000 [1:31:10<02:11,  5.47it/s, lr=8.67e-6, step_loss=0.0107/18/2023 20:34:32 - INFO - __main__ - train loss is 3.231405708938837\n",
      "Steps:  95%|▉| 14281/15000 [1:31:10<02:10,  5.51it/s, lr=8.67e-6, step_loss=0.1307/18/2023 20:34:32 - INFO - __main__ - train loss is 3.7559457160532475\n",
      "Steps:  95%|▉| 14282/15000 [1:31:10<02:09,  5.53it/s, lr=8.67e-6, step_loss=0.5207/18/2023 20:34:32 - INFO - __main__ - train loss is 3.7585673227440566\n",
      "Steps:  95%|▉| 14283/15000 [1:31:10<02:09,  5.55it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:33 - INFO - __main__ - train loss is 3.8538859530817717\n",
      "Steps:  95%|▉| 14284/15000 [1:31:11<02:08,  5.57it/s, lr=8.67e-6, step_loss=0.0907/18/2023 20:34:33 - INFO - __main__ - train loss is 3.8621200292836875\n",
      "Steps:  95%|▉| 14285/15000 [1:31:11<02:08,  5.57it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:33 - INFO - __main__ - train loss is 3.8849178615491837\n",
      "Steps:  95%|▉| 14286/15000 [1:31:11<02:07,  5.58it/s, lr=8.67e-6, step_loss=0.0207/18/2023 20:34:33 - INFO - __main__ - train loss is 4.395048624603078\n",
      "Steps:  95%|▉| 14287/15000 [1:31:11<02:07,  5.58it/s, lr=8.67e-6, step_loss=0.5107/18/2023 20:34:33 - INFO - __main__ - train loss is 4.476543596712872\n",
      "Steps:  95%|▉| 14288/15000 [1:31:11<02:07,  5.59it/s, lr=8.67e-6, step_loss=0.0807/18/2023 20:34:34 - INFO - __main__ - train loss is 4.641992262331769\n",
      "Steps:  95%|▉| 14289/15000 [1:31:11<02:07,  5.59it/s, lr=8.67e-6, step_loss=0.1607/18/2023 20:34:34 - INFO - __main__ - train loss is 5.137625536648557\n",
      "Steps:  95%|▉| 14290/15000 [1:31:12<02:07,  5.59it/s, lr=8.67e-6, step_loss=0.4907/18/2023 20:34:34 - INFO - __main__ - train loss is 5.139390376396477\n",
      "Steps:  95%|▉| 14291/15000 [1:31:12<02:07,  5.57it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:34 - INFO - __main__ - train loss is 5.185152587480843\n",
      "Steps:  95%|▉| 14292/15000 [1:31:12<02:07,  5.57it/s, lr=8.67e-6, step_loss=0.0407/18/2023 20:34:34 - INFO - __main__ - train loss is 5.22567739803344\n",
      "Steps:  95%|▉| 14293/15000 [1:31:12<02:07,  5.53it/s, lr=8.67e-6, step_loss=0.0407/18/2023 20:34:34 - INFO - __main__ - train loss is 5.2615302028134465\n",
      "Steps:  95%|▉| 14294/15000 [1:31:12<02:07,  5.53it/s, lr=8.67e-6, step_loss=0.0307/18/2023 20:34:35 - INFO - __main__ - train loss is 5.637448054738343\n",
      "Steps:  95%|▉| 14295/15000 [1:31:13<02:07,  5.54it/s, lr=8.67e-6, step_loss=0.3707/18/2023 20:34:35 - INFO - __main__ - train loss is 5.6416693944483995\n",
      "Steps:  95%|▉| 14296/15000 [1:31:13<02:06,  5.55it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:35 - INFO - __main__ - train loss is 5.736874612048268\n",
      "Steps:  95%|▉| 14297/15000 [1:31:13<02:06,  5.56it/s, lr=8.67e-6, step_loss=0.0907/18/2023 20:34:35 - INFO - __main__ - train loss is 6.031916173174977\n",
      "Steps:  95%|▉| 14298/15000 [1:31:13<02:06,  5.57it/s, lr=8.67e-6, step_loss=0.2907/18/2023 20:34:35 - INFO - __main__ - train loss is 6.03387751034461\n",
      "Steps:  95%|▉| 14299/15000 [1:31:13<02:05,  5.57it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:36 - INFO - __main__ - train loss is 6.117889005457982\n",
      "Steps:  95%|▉| 14300/15000 [1:31:13<02:06,  5.52it/s, lr=8.67e-6, step_loss=0.0807/18/2023 20:34:36 - INFO - __main__ - train loss is 6.167738836025819\n",
      "Steps:  95%|▉| 14301/15000 [1:31:14<02:06,  5.54it/s, lr=8.67e-6, step_loss=0.0407/18/2023 20:34:36 - INFO - __main__ - train loss is 6.206020790850744\n",
      "Steps:  95%|▉| 14302/15000 [1:31:14<02:05,  5.55it/s, lr=8.67e-6, step_loss=0.0307/18/2023 20:34:36 - INFO - __main__ - train loss is 6.627113837515935\n",
      "Steps:  95%|▉| 14303/15000 [1:31:14<02:05,  5.56it/s, lr=8.67e-6, step_loss=0.4207/18/2023 20:34:36 - INFO - __main__ - train loss is 6.668658666079864\n",
      "Steps:  95%|▉| 14304/15000 [1:31:14<02:05,  5.57it/s, lr=8.67e-6, step_loss=0.0407/18/2023 20:34:36 - INFO - __main__ - train loss is 7.066955677932128\n",
      "Steps:  95%|▉| 14305/15000 [1:31:14<02:05,  5.54it/s, lr=8.67e-6, step_loss=0.3907/18/2023 20:34:37 - INFO - __main__ - train loss is 7.075062146177515\n",
      "Steps:  95%|▉| 14306/15000 [1:31:15<02:05,  5.55it/s, lr=8.67e-6, step_loss=0.0007/18/2023 20:34:37 - INFO - __main__ - train loss is 7.312199910869822\n",
      "Steps:  95%|▉| 14307/15000 [1:31:15<02:04,  5.56it/s, lr=8.67e-6, step_loss=0.2307/18/2023 20:34:37 - INFO - __main__ - train loss is 7.386231889715418\n",
      "Steps:  95%|▉| 14308/15000 [1:31:15<02:05,  5.52it/s, lr=8.67e-6, step_loss=0.0707/18/2023 20:34:37 - INFO - __main__ - train loss is 7.388429609127343\n",
      "Steps:  95%|▉| 14309/15000 [1:31:15<02:05,  5.52it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:34:37 - INFO - __main__ - train loss is 7.4248447166755795\n",
      "Steps:  95%|▉| 14310/15000 [1:31:15<02:04,  5.54it/s, lr=8.66e-6, step_loss=0.0307/18/2023 20:34:38 - INFO - __main__ - train loss is 7.469573390670121\n",
      "Steps:  95%|▉| 14311/15000 [1:31:15<02:03,  5.56it/s, lr=8.66e-6, step_loss=0.0407/18/2023 20:34:38 - INFO - __main__ - train loss is 8.051202905364335\n",
      "Steps:  95%|▉| 14312/15000 [1:31:16<02:03,  5.56it/s, lr=8.66e-6, step_loss=0.5807/18/2023 20:34:38 - INFO - __main__ - train loss is 8.068924170918763\n",
      "Steps:  95%|▉| 14313/15000 [1:31:16<02:03,  5.57it/s, lr=8.66e-6, step_loss=0.0107/18/2023 20:34:38 - INFO - __main__ - train loss is 8.072498370194808\n",
      "Steps:  95%|▉| 14314/15000 [1:31:16<02:03,  5.57it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:34:38 - INFO - __main__ - train loss is 8.08154868078418\n",
      "Steps:  95%|▉| 14315/15000 [1:31:16<02:03,  5.57it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:34:38 - INFO - __main__ - train loss is 8.453518738271669\n",
      "Steps:  95%|▉| 14316/15000 [1:31:16<02:02,  5.57it/s, lr=8.66e-6, step_loss=0.3707/18/2023 20:34:39 - INFO - __main__ - train loss is 8.463310793275014\n",
      "Steps:  95%|▉| 14317/15000 [1:31:16<02:02,  5.57it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:34:39 - INFO - __main__ - train loss is 8.649234831565991\n",
      "Steps:  95%|▉| 14318/15000 [1:31:17<02:02,  5.57it/s, lr=8.66e-6, step_loss=0.1807/18/2023 20:34:39 - INFO - __main__ - train loss is 9.437008202308789\n",
      "Steps:  95%|▉| 14319/15000 [1:31:17<02:02,  5.58it/s, lr=8.66e-6, step_loss=0.7807/18/2023 20:34:39 - INFO - __main__ - train loss is 9.448291246080771\n",
      "Steps:  95%|▉| 14320/15000 [1:31:17<02:01,  5.58it/s, lr=8.66e-6, step_loss=0.0107/18/2023 20:34:39 - INFO - __main__ - train loss is 9.989426914835349\n",
      "Steps:  95%|▉| 14321/15000 [1:31:17<02:01,  5.58it/s, lr=8.66e-6, step_loss=0.5407/18/2023 20:34:39 - INFO - __main__ - train loss is 10.750669542932883\n",
      "Steps:  95%|▉| 14322/15000 [1:31:17<02:01,  5.58it/s, lr=8.66e-6, step_loss=0.7607/18/2023 20:34:40 - INFO - __main__ - train loss is 10.921055261278525\n",
      "Steps:  95%|▉| 14323/15000 [1:31:18<02:01,  5.59it/s, lr=8.66e-6, step_loss=0.1707/18/2023 20:34:40 - INFO - __main__ - train loss is 10.9725479001645\n",
      "Steps:  95%|▉| 14324/15000 [1:31:18<02:00,  5.59it/s, lr=8.66e-6, step_loss=0.0507/18/2023 20:34:40 - INFO - __main__ - train loss is 11.276904475176707\n",
      "Steps:  96%|▉| 14325/15000 [1:31:18<02:00,  5.59it/s, lr=8.66e-6, step_loss=0.3007/18/2023 20:34:40 - INFO - __main__ - train loss is 11.890554797137156\n",
      "Steps:  96%|▉| 14326/15000 [1:31:18<02:00,  5.59it/s, lr=8.66e-6, step_loss=0.6107/18/2023 20:34:40 - INFO - __main__ - train loss is 12.127640586579219\n",
      "Steps:  96%|▉| 14327/15000 [1:31:18<02:00,  5.59it/s, lr=8.66e-6, step_loss=0.2307/18/2023 20:34:41 - INFO - __main__ - train loss is 12.144940650323406\n",
      "Steps:  96%|▉| 14328/15000 [1:31:18<02:00,  5.59it/s, lr=8.66e-6, step_loss=0.0107/18/2023 20:34:41 - INFO - __main__ - train loss is 12.146826104493812\n",
      "Steps:  96%|▉| 14329/15000 [1:31:19<02:00,  5.59it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:34:41 - INFO - __main__ - train loss is 12.177114873426035\n",
      "Steps:  96%|▉| 14330/15000 [1:31:19<01:59,  5.59it/s, lr=8.66e-6, step_loss=0.0307/18/2023 20:34:41 - INFO - __main__ - train loss is 12.296549841063097\n",
      "Steps:  96%|▉| 14331/15000 [1:31:19<01:59,  5.59it/s, lr=8.66e-6, step_loss=0.1107/18/2023 20:34:41 - INFO - __main__ - train loss is 12.698824062244967\n",
      "Steps:  96%|▉| 14332/15000 [1:31:19<01:59,  5.60it/s, lr=8.66e-6, step_loss=0.4007/18/2023 20:34:41 - INFO - __main__ - train loss is 12.878892152803019\n",
      "Steps:  96%|▉| 14333/15000 [1:31:19<01:59,  5.59it/s, lr=8.66e-6, step_loss=0.1807/18/2023 20:34:42 - INFO - __main__ - train loss is 12.9521478258539\n",
      "Steps:  96%|▉| 14334/15000 [1:31:20<02:01,  5.49it/s, lr=8.66e-6, step_loss=0.0707/18/2023 20:34:42 - INFO - __main__ - train loss is 13.032452672021464\n",
      "Steps:  96%|▉| 14335/15000 [1:31:20<02:01,  5.46it/s, lr=8.66e-6, step_loss=0.0807/18/2023 20:34:42 - INFO - __main__ - train loss is 13.042562724323943\n",
      "Steps:  96%|▉| 14336/15000 [1:31:20<02:02,  5.42it/s, lr=8.66e-6, step_loss=0.0107/18/2023 20:34:42 - INFO - __main__ - train loss is 13.359051824780181\n",
      "Steps:  96%|▉| 14337/15000 [1:31:20<02:04,  5.34it/s, lr=8.66e-6, step_loss=0.3107/18/2023 20:34:42 - INFO - __main__ - train loss is 13.374623277457431\n",
      "Steps:  96%|▉| 14338/15000 [1:31:20<02:03,  5.35it/s, lr=8.66e-6, step_loss=0.0107/18/2023 20:34:43 - INFO - __main__ - train loss is 13.497850560816005\n",
      "Steps:  96%|▉| 14339/15000 [1:31:20<02:02,  5.38it/s, lr=8.66e-6, step_loss=0.1207/18/2023 20:34:43 - INFO - __main__ - train loss is 13.502373503288254\n",
      "Steps:  96%|▉| 14340/15000 [1:31:21<02:02,  5.37it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:34:43 - INFO - __main__ - train loss is 13.924478130182251\n",
      "Steps:  96%|▉| 14341/15000 [1:31:21<02:01,  5.41it/s, lr=8.66e-6, step_loss=0.4207/18/2023 20:34:43 - INFO - __main__ - train loss is 14.083420263370499\n",
      "Steps:  96%|▉| 14342/15000 [1:31:21<02:01,  5.42it/s, lr=8.66e-6, step_loss=0.1507/18/2023 20:34:43 - INFO - __main__ - train loss is 14.088739400496706\n",
      "Steps:  96%|▉| 14343/15000 [1:31:21<02:01,  5.41it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:34:44 - INFO - __main__ - train loss is 14.327506815781817\n",
      "Steps:  96%|▉| 14344/15000 [1:31:21<02:00,  5.43it/s, lr=8.66e-6, step_loss=0.2307/18/2023 20:34:44 - INFO - __main__ - train loss is 14.554979732027277\n",
      "Steps:  96%|▉| 14345/15000 [1:31:22<02:00,  5.44it/s, lr=8.66e-6, step_loss=0.2207/18/2023 20:34:44 - INFO - __main__ - train loss is 14.691998397698626\n",
      "Steps:  96%|▉| 14346/15000 [1:31:22<02:00,  5.45it/s, lr=8.66e-6, step_loss=0.1307/18/2023 20:34:44 - INFO - __main__ - train loss is 15.365111207356676\n",
      "Steps:  96%|▉| 14347/15000 [1:31:22<01:59,  5.45it/s, lr=8.66e-6, step_loss=0.6707/18/2023 20:34:44 - INFO - __main__ - train loss is 15.483877604594454\n",
      "Steps:  96%|▉| 14348/15000 [1:31:22<02:00,  5.42it/s, lr=8.66e-6, step_loss=0.1107/18/2023 20:34:44 - INFO - __main__ - train loss is 16.02354729711078\n",
      "Steps:  96%|▉| 14349/15000 [1:31:22<01:59,  5.44it/s, lr=8.66e-6, step_loss=0.5407/18/2023 20:34:45 - INFO - __main__ - train loss is 16.250123446574435\n",
      "Steps:  96%|▉| 14350/15000 [1:31:22<01:59,  5.45it/s, lr=8.66e-6, step_loss=0.2207/18/2023 20:34:45 - INFO - __main__ - train loss is 16.26837204559706\n",
      "Steps:  96%|▉| 14351/15000 [1:31:23<01:59,  5.42it/s, lr=8.66e-6, step_loss=0.0107/18/2023 20:34:45 - INFO - __main__ - train loss is 16.289851911133155\n",
      "Steps:  96%|▉| 14352/15000 [1:31:23<02:00,  5.37it/s, lr=8.66e-6, step_loss=0.0207/18/2023 20:34:45 - INFO - __main__ - train loss is 16.554106570547447\n",
      "Steps:  96%|▉| 14353/15000 [1:31:23<01:59,  5.40it/s, lr=8.66e-6, step_loss=0.2607/18/2023 20:34:45 - INFO - __main__ - train loss is 16.918072826927528\n",
      "Steps:  96%|▉| 14354/15000 [1:31:23<01:58,  5.43it/s, lr=8.66e-6, step_loss=0.3607/18/2023 20:34:46 - INFO - __main__ - train loss is 17.52188492543064\n",
      "Steps:  96%|▉| 14355/15000 [1:31:23<01:58,  5.44it/s, lr=8.66e-6, step_loss=0.6007/18/2023 20:34:46 - INFO - __main__ - train loss is 17.56621453887783\n",
      "Steps:  96%|▉| 14356/15000 [1:31:24<02:51,  3.75it/s, lr=8.66e-6, step_loss=0.0407/18/2023 20:34:47 - INFO - __main__ - Per validation step average loss is 0.1375475525856018\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Cumulative validation average loss is 0.1375475525856018\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Per validation step average loss is 0.004002716392278671\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Cumulative validation average loss is 0.14155026897788048\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Per validation step average loss is 0.05736203491687775\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Cumulative validation average loss is 0.19891230389475822\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Per validation step average loss is 0.009034471586346626\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Cumulative validation average loss is 0.20794677548110485\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Per validation step average loss is 0.04079342633485794\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Cumulative validation average loss is 0.2487402018159628\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Per validation step average loss is 0.018139280378818512\n",
      "07/18/2023 20:34:47 - INFO - __main__ - Cumulative validation average loss is 0.2668794821947813\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Per validation step average loss is 0.07377279549837112\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Cumulative validation average loss is 0.3406522776931524\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Per validation step average loss is 0.30208390951156616\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Cumulative validation average loss is 0.6427361872047186\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Per validation step average loss is 0.0015417221002280712\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Cumulative validation average loss is 0.6442779093049467\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Per validation step average loss is 0.002624734304845333\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Cumulative validation average loss is 0.646902643609792\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Per validation step average loss is 0.21668601036071777\n",
      "07/18/2023 20:34:48 - INFO - __main__ - Cumulative validation average loss is 0.8635886539705098\n",
      "07/18/2023 20:34:49 - INFO - __main__ - Per validation step average loss is 0.017576877027750015\n",
      "07/18/2023 20:34:49 - INFO - __main__ - Cumulative validation average loss is 0.8811655309982598\n",
      "07/18/2023 20:34:49 - INFO - __main__ - Average validation loss for Epoch 147 is 0.07343046091652165\n",
      "07/18/2023 20:34:49 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:35:02 - INFO - __main__ - Starting epoch 148\n",
      "07/18/2023 20:35:02 - INFO - __main__ - train loss is 0.41933467984199524\n",
      "Steps:  96%|▉| 14357/15000 [1:31:40<54:31,  5.09s/it, lr=8.66e-6, step_loss=0.4107/18/2023 20:35:03 - INFO - __main__ - train loss is 0.4217636436223984\n",
      "Steps:  96%|▉| 14358/15000 [1:31:40<38:41,  3.62s/it, lr=8.66e-6, step_loss=0.0007/18/2023 20:35:03 - INFO - __main__ - train loss is 0.4237972330302\n",
      "Steps:  96%|▉| 14359/15000 [1:31:41<27:36,  2.58s/it, lr=8.66e-6, step_loss=0.0007/18/2023 20:35:03 - INFO - __main__ - train loss is 1.2581720184534788\n",
      "Steps:  96%|▉| 14360/15000 [1:31:41<19:52,  1.86s/it, lr=8.66e-6, step_loss=0.8307/18/2023 20:35:03 - INFO - __main__ - train loss is 1.2629064708016813\n",
      "Steps:  96%|▉| 14361/15000 [1:31:41<14:28,  1.36s/it, lr=8.66e-6, step_loss=0.0007/18/2023 20:35:03 - INFO - __main__ - train loss is 1.2964636809192598\n",
      "Steps:  96%|▉| 14362/15000 [1:31:41<10:40,  1.00s/it, lr=8.66e-6, step_loss=0.0307/18/2023 20:35:03 - INFO - __main__ - train loss is 1.5011287457309663\n",
      "Steps:  96%|▉| 14363/15000 [1:31:41<08:02,  1.32it/s, lr=8.66e-6, step_loss=0.2007/18/2023 20:35:04 - INFO - __main__ - train loss is 1.506421041674912\n",
      "Steps:  96%|▉| 14364/15000 [1:31:41<06:11,  1.71it/s, lr=8.66e-6, step_loss=0.0007/18/2023 20:35:04 - INFO - __main__ - train loss is 1.6554147126153111\n",
      "Steps:  96%|▉| 14365/15000 [1:31:42<04:53,  2.16it/s, lr=8.65e-6, step_loss=0.1407/18/2023 20:35:04 - INFO - __main__ - train loss is 2.448289883323014\n",
      "Steps:  96%|▉| 14366/15000 [1:31:42<03:59,  2.65it/s, lr=8.65e-6, step_loss=0.7907/18/2023 20:35:04 - INFO - __main__ - train loss is 2.4870057003572583\n",
      "Steps:  96%|▉| 14367/15000 [1:31:42<03:21,  3.14it/s, lr=8.65e-6, step_loss=0.0307/18/2023 20:35:04 - INFO - __main__ - train loss is 2.5082730995491147\n",
      "Steps:  96%|▉| 14368/15000 [1:31:42<02:54,  3.62it/s, lr=8.65e-6, step_loss=0.0207/18/2023 20:35:04 - INFO - __main__ - train loss is 2.73946485389024\n",
      "Steps:  96%|▉| 14369/15000 [1:31:42<02:35,  4.05it/s, lr=8.65e-6, step_loss=0.2307/18/2023 20:35:05 - INFO - __main__ - train loss is 3.0035512195900083\n",
      "Steps:  96%|▉| 14370/15000 [1:31:43<02:22,  4.41it/s, lr=8.65e-6, step_loss=0.2607/18/2023 20:35:05 - INFO - __main__ - train loss is 3.4907150315120816\n",
      "Steps:  96%|▉| 14371/15000 [1:31:43<02:13,  4.71it/s, lr=8.65e-6, step_loss=0.4807/18/2023 20:35:05 - INFO - __main__ - train loss is 3.515011706389487\n",
      "Steps:  96%|▉| 14372/15000 [1:31:43<02:06,  4.95it/s, lr=8.65e-6, step_loss=0.0207/18/2023 20:35:05 - INFO - __main__ - train loss is 3.517935612704605\n",
      "Steps:  96%|▉| 14373/15000 [1:31:43<02:02,  5.13it/s, lr=8.65e-6, step_loss=0.0007/18/2023 20:35:05 - INFO - __main__ - train loss is 3.560003762599081\n",
      "Steps:  96%|▉| 14374/15000 [1:31:43<01:58,  5.26it/s, lr=8.65e-6, step_loss=0.0407/18/2023 20:35:06 - INFO - __main__ - train loss is 4.016266023274511\n",
      "Steps:  96%|▉| 14375/15000 [1:31:43<01:56,  5.36it/s, lr=8.65e-6, step_loss=0.4507/18/2023 20:35:06 - INFO - __main__ - train loss is 4.162890215869993\n",
      "Steps:  96%|▉| 14376/15000 [1:31:44<01:54,  5.43it/s, lr=8.65e-6, step_loss=0.1407/18/2023 20:35:06 - INFO - __main__ - train loss is 4.187833250965923\n",
      "Steps:  96%|▉| 14377/15000 [1:31:44<01:53,  5.48it/s, lr=8.65e-6, step_loss=0.0207/18/2023 20:35:06 - INFO - __main__ - train loss is 4.311921575572342\n",
      "Steps:  96%|▉| 14378/15000 [1:31:44<01:52,  5.51it/s, lr=8.65e-6, step_loss=0.1207/18/2023 20:35:06 - INFO - __main__ - train loss is 4.679813542868942\n",
      "Steps:  96%|▉| 14379/15000 [1:31:44<01:52,  5.54it/s, lr=8.65e-6, step_loss=0.3607/18/2023 20:35:06 - INFO - __main__ - train loss is 4.755925790872425\n",
      "Steps:  96%|▉| 14380/15000 [1:31:44<01:51,  5.56it/s, lr=8.65e-6, step_loss=0.0707/18/2023 20:35:07 - INFO - __main__ - train loss is 4.833178864326328\n",
      "Steps:  96%|▉| 14381/15000 [1:31:45<01:51,  5.56it/s, lr=8.65e-6, step_loss=0.0707/18/2023 20:35:07 - INFO - __main__ - train loss is 4.9228097214363515\n",
      "Steps:  96%|▉| 14382/15000 [1:31:45<01:50,  5.57it/s, lr=8.65e-6, step_loss=0.0807/18/2023 20:35:07 - INFO - __main__ - train loss is 4.937368064653128\n",
      "Steps:  96%|▉| 14383/15000 [1:31:45<01:50,  5.57it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:07 - INFO - __main__ - train loss is 5.000269039999694\n",
      "Steps:  96%|▉| 14384/15000 [1:31:45<01:51,  5.52it/s, lr=8.65e-6, step_loss=0.0607/18/2023 20:35:07 - INFO - __main__ - train loss is 5.0658749039284885\n",
      "Steps:  96%|▉| 14385/15000 [1:31:45<01:52,  5.44it/s, lr=8.65e-6, step_loss=0.0607/18/2023 20:35:08 - INFO - __main__ - train loss is 5.172153666149825\n",
      "Steps:  96%|▉| 14386/15000 [1:31:45<01:52,  5.46it/s, lr=8.65e-6, step_loss=0.1007/18/2023 20:35:08 - INFO - __main__ - train loss is 5.19208264304325\n",
      "Steps:  96%|▉| 14387/15000 [1:31:46<01:51,  5.50it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:08 - INFO - __main__ - train loss is 5.42111937655136\n",
      "Steps:  96%|▉| 14388/15000 [1:31:46<01:50,  5.53it/s, lr=8.65e-6, step_loss=0.2207/18/2023 20:35:08 - INFO - __main__ - train loss is 5.464773833286017\n",
      "Steps:  96%|▉| 14389/15000 [1:31:46<01:50,  5.54it/s, lr=8.65e-6, step_loss=0.0407/18/2023 20:35:08 - INFO - __main__ - train loss is 5.546249076258391\n",
      "Steps:  96%|▉| 14390/15000 [1:31:46<01:49,  5.56it/s, lr=8.65e-6, step_loss=0.0807/18/2023 20:35:08 - INFO - __main__ - train loss is 5.97739978088066\n",
      "Steps:  96%|▉| 14391/15000 [1:31:46<01:49,  5.57it/s, lr=8.65e-6, step_loss=0.4307/18/2023 20:35:09 - INFO - __main__ - train loss is 6.163829549681395\n",
      "Steps:  96%|▉| 14392/15000 [1:31:47<01:49,  5.54it/s, lr=8.65e-6, step_loss=0.1807/18/2023 20:35:09 - INFO - __main__ - train loss is 6.231161511968821\n",
      "Steps:  96%|▉| 14393/15000 [1:31:47<01:49,  5.53it/s, lr=8.65e-6, step_loss=0.0607/18/2023 20:35:09 - INFO - __main__ - train loss is 6.239434091839939\n",
      "Steps:  96%|▉| 14394/15000 [1:31:47<01:49,  5.51it/s, lr=8.65e-6, step_loss=0.0007/18/2023 20:35:09 - INFO - __main__ - train loss is 6.6326261148788035\n",
      "Steps:  96%|▉| 14395/15000 [1:31:47<01:50,  5.48it/s, lr=8.65e-6, step_loss=0.3907/18/2023 20:35:09 - INFO - __main__ - train loss is 6.636255591874942\n",
      "Steps:  96%|▉| 14396/15000 [1:31:47<01:50,  5.48it/s, lr=8.65e-6, step_loss=0.0007/18/2023 20:35:10 - INFO - __main__ - train loss is 6.743144422536716\n",
      "Steps:  96%|▉| 14397/15000 [1:31:47<01:49,  5.51it/s, lr=8.65e-6, step_loss=0.1007/18/2023 20:35:10 - INFO - __main__ - train loss is 6.856723971432075\n",
      "Steps:  96%|▉| 14398/15000 [1:31:48<01:48,  5.54it/s, lr=8.65e-6, step_loss=0.1107/18/2023 20:35:10 - INFO - __main__ - train loss is 6.875828126212582\n",
      "Steps:  96%|▉| 14399/15000 [1:31:48<01:48,  5.55it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:10 - INFO - __main__ - train loss is 7.135215380927548\n",
      "Steps:  96%|▉| 14400/15000 [1:31:48<01:47,  5.57it/s, lr=8.65e-6, step_loss=0.2507/18/2023 20:35:10 - INFO - __main__ - train loss is 7.180394457420334\n",
      "Steps:  96%|▉| 14401/15000 [1:31:48<01:47,  5.58it/s, lr=8.65e-6, step_loss=0.0407/18/2023 20:35:10 - INFO - __main__ - train loss is 7.197009933879599\n",
      "Steps:  96%|▉| 14402/15000 [1:31:48<01:47,  5.58it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:11 - INFO - __main__ - train loss is 7.850913060596213\n",
      "Steps:  96%|▉| 14403/15000 [1:31:48<01:46,  5.58it/s, lr=8.65e-6, step_loss=0.6507/18/2023 20:35:11 - INFO - __main__ - train loss is 8.456298483302817\n",
      "Steps:  96%|▉| 14404/15000 [1:31:49<01:46,  5.59it/s, lr=8.65e-6, step_loss=0.6007/18/2023 20:35:11 - INFO - __main__ - train loss is 8.467409198870882\n",
      "Steps:  96%|▉| 14405/15000 [1:31:49<01:46,  5.59it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:11 - INFO - __main__ - train loss is 8.573554878821597\n",
      "Steps:  96%|▉| 14406/15000 [1:31:49<01:46,  5.59it/s, lr=8.65e-6, step_loss=0.1007/18/2023 20:35:11 - INFO - __main__ - train loss is 8.617895545205101\n",
      "Steps:  96%|▉| 14407/15000 [1:31:49<01:46,  5.59it/s, lr=8.65e-6, step_loss=0.0407/18/2023 20:35:11 - INFO - __main__ - train loss is 8.974047722062096\n",
      "Steps:  96%|▉| 14408/15000 [1:31:49<01:46,  5.54it/s, lr=8.65e-6, step_loss=0.3507/18/2023 20:35:12 - INFO - __main__ - train loss is 9.181851492961869\n",
      "Steps:  96%|▉| 14409/15000 [1:31:50<01:46,  5.56it/s, lr=8.65e-6, step_loss=0.2007/18/2023 20:35:12 - INFO - __main__ - train loss is 9.302316503366455\n",
      "Steps:  96%|▉| 14410/15000 [1:31:50<01:45,  5.57it/s, lr=8.65e-6, step_loss=0.1207/18/2023 20:35:12 - INFO - __main__ - train loss is 9.404463538667187\n",
      "Steps:  96%|▉| 14411/15000 [1:31:50<01:45,  5.58it/s, lr=8.65e-6, step_loss=0.1007/18/2023 20:35:12 - INFO - __main__ - train loss is 9.41971019259654\n",
      "Steps:  96%|▉| 14412/15000 [1:31:50<01:45,  5.58it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:12 - INFO - __main__ - train loss is 9.50636513880454\n",
      "Steps:  96%|▉| 14413/15000 [1:31:50<01:46,  5.54it/s, lr=8.65e-6, step_loss=0.0807/18/2023 20:35:13 - INFO - __main__ - train loss is 9.510492491768673\n",
      "Steps:  96%|▉| 14414/15000 [1:31:50<01:45,  5.55it/s, lr=8.65e-6, step_loss=0.0007/18/2023 20:35:13 - INFO - __main__ - train loss is 9.61495906417258\n",
      "Steps:  96%|▉| 14415/15000 [1:31:51<01:45,  5.56it/s, lr=8.65e-6, step_loss=0.1007/18/2023 20:35:13 - INFO - __main__ - train loss is 9.705771769629791\n",
      "Steps:  96%|▉| 14416/15000 [1:31:51<01:44,  5.57it/s, lr=8.65e-6, step_loss=0.0907/18/2023 20:35:13 - INFO - __main__ - train loss is 9.716894903453067\n",
      "Steps:  96%|▉| 14417/15000 [1:31:51<01:44,  5.58it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:13 - INFO - __main__ - train loss is 10.670932450564578\n",
      "Steps:  96%|▉| 14418/15000 [1:31:51<01:45,  5.53it/s, lr=8.65e-6, step_loss=0.9507/18/2023 20:35:13 - INFO - __main__ - train loss is 10.687415608437732\n",
      "Steps:  96%|▉| 14419/15000 [1:31:51<01:44,  5.55it/s, lr=8.65e-6, step_loss=0.0107/18/2023 20:35:14 - INFO - __main__ - train loss is 10.718908199341968\n",
      "Steps:  96%|▉| 14420/15000 [1:31:52<01:44,  5.57it/s, lr=8.65e-6, step_loss=0.0307/18/2023 20:35:14 - INFO - __main__ - train loss is 10.777678382815793\n",
      "Steps:  96%|▉| 14421/15000 [1:31:52<01:43,  5.57it/s, lr=8.64e-6, step_loss=0.0507/18/2023 20:35:14 - INFO - __main__ - train loss is 10.79168357909657\n",
      "Steps:  96%|▉| 14422/15000 [1:31:52<01:43,  5.58it/s, lr=8.64e-6, step_loss=0.0107/18/2023 20:35:14 - INFO - __main__ - train loss is 11.018060112604871\n",
      "Steps:  96%|▉| 14423/15000 [1:31:52<01:43,  5.59it/s, lr=8.64e-6, step_loss=0.2207/18/2023 20:35:14 - INFO - __main__ - train loss is 11.023689992027357\n",
      "Steps:  96%|▉| 14424/15000 [1:31:52<01:43,  5.59it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:15 - INFO - __main__ - train loss is 11.275932318763807\n",
      "Steps:  96%|▉| 14425/15000 [1:31:52<01:42,  5.59it/s, lr=8.64e-6, step_loss=0.2507/18/2023 20:35:15 - INFO - __main__ - train loss is 11.427255816059187\n",
      "Steps:  96%|▉| 14426/15000 [1:31:53<01:42,  5.60it/s, lr=8.64e-6, step_loss=0.1507/18/2023 20:35:15 - INFO - __main__ - train loss is 11.93636233289726\n",
      "Steps:  96%|▉| 14427/15000 [1:31:53<01:42,  5.60it/s, lr=8.64e-6, step_loss=0.5007/18/2023 20:35:15 - INFO - __main__ - train loss is 12.13188325543888\n",
      "Steps:  96%|▉| 14428/15000 [1:31:53<01:42,  5.59it/s, lr=8.64e-6, step_loss=0.1907/18/2023 20:35:15 - INFO - __main__ - train loss is 12.578512600855902\n",
      "Steps:  96%|▉| 14429/15000 [1:31:53<01:42,  5.59it/s, lr=8.64e-6, step_loss=0.4407/18/2023 20:35:15 - INFO - __main__ - train loss is 12.678398019867018\n",
      "Steps:  96%|▉| 14430/15000 [1:31:53<01:42,  5.57it/s, lr=8.64e-6, step_loss=0.0907/18/2023 20:35:16 - INFO - __main__ - train loss is 12.689700382994488\n",
      "Steps:  96%|▉| 14431/15000 [1:31:54<01:42,  5.55it/s, lr=8.64e-6, step_loss=0.0107/18/2023 20:35:16 - INFO - __main__ - train loss is 13.003688114928082\n",
      "Steps:  96%|▉| 14432/15000 [1:31:54<01:42,  5.54it/s, lr=8.64e-6, step_loss=0.3107/18/2023 20:35:16 - INFO - __main__ - train loss is 13.00533740548417\n",
      "Steps:  96%|▉| 14433/15000 [1:31:54<01:42,  5.53it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:16 - INFO - __main__ - train loss is 13.006864354247227\n",
      "Steps:  96%|▉| 14434/15000 [1:31:54<01:42,  5.53it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:16 - INFO - __main__ - train loss is 13.14284484111704\n",
      "Steps:  96%|▉| 14435/15000 [1:31:54<01:42,  5.51it/s, lr=8.64e-6, step_loss=0.1307/18/2023 20:35:17 - INFO - __main__ - train loss is 13.462769136065617\n",
      "Steps:  96%|▉| 14436/15000 [1:31:54<01:43,  5.47it/s, lr=8.64e-6, step_loss=0.3207/18/2023 20:35:17 - INFO - __main__ - train loss is 13.867055401438847\n",
      "Steps:  96%|▉| 14437/15000 [1:31:55<01:42,  5.49it/s, lr=8.64e-6, step_loss=0.4007/18/2023 20:35:17 - INFO - __main__ - train loss is 14.102086648577824\n",
      "Steps:  96%|▉| 14438/15000 [1:31:55<01:42,  5.48it/s, lr=8.64e-6, step_loss=0.2307/18/2023 20:35:17 - INFO - __main__ - train loss is 14.139558132970706\n",
      "Steps:  96%|▉| 14439/15000 [1:31:55<01:41,  5.52it/s, lr=8.64e-6, step_loss=0.0307/18/2023 20:35:17 - INFO - __main__ - train loss is 14.508531447732821\n",
      "Steps:  96%|▉| 14440/15000 [1:31:55<01:41,  5.54it/s, lr=8.64e-6, step_loss=0.3607/18/2023 20:35:17 - INFO - __main__ - train loss is 14.6468143875245\n",
      "Steps:  96%|▉| 14441/15000 [1:31:55<01:40,  5.56it/s, lr=8.64e-6, step_loss=0.1307/18/2023 20:35:18 - INFO - __main__ - train loss is 14.873133164132014\n",
      "Steps:  96%|▉| 14442/15000 [1:31:56<01:40,  5.57it/s, lr=8.64e-6, step_loss=0.2207/18/2023 20:35:18 - INFO - __main__ - train loss is 14.943761322880164\n",
      "Steps:  96%|▉| 14443/15000 [1:31:56<01:39,  5.59it/s, lr=8.64e-6, step_loss=0.0707/18/2023 20:35:18 - INFO - __main__ - train loss is 14.949226469034329\n",
      "Steps:  96%|▉| 14444/15000 [1:31:56<01:39,  5.59it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:18 - INFO - __main__ - train loss is 14.953475964954123\n",
      "Steps:  96%|▉| 14445/15000 [1:31:56<01:39,  5.60it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:18 - INFO - __main__ - train loss is 15.19347353070043\n",
      "Steps:  96%|▉| 14446/15000 [1:31:56<01:38,  5.60it/s, lr=8.64e-6, step_loss=0.2407/18/2023 20:35:19 - INFO - __main__ - train loss is 15.300493729999289\n",
      "Steps:  96%|▉| 14447/15000 [1:31:56<01:38,  5.60it/s, lr=8.64e-6, step_loss=0.1007/18/2023 20:35:19 - INFO - __main__ - train loss is 15.301870720461011\n",
      "Steps:  96%|▉| 14448/15000 [1:31:57<01:38,  5.60it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:19 - INFO - __main__ - train loss is 15.30561734829098\n",
      "Steps:  96%|▉| 14449/15000 [1:31:57<01:38,  5.60it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:19 - INFO - __main__ - train loss is 15.446871192194521\n",
      "Steps:  96%|▉| 14450/15000 [1:31:57<01:38,  5.61it/s, lr=8.64e-6, step_loss=0.1407/18/2023 20:35:19 - INFO - __main__ - train loss is 16.19337168429047\n",
      "Steps:  96%|▉| 14451/15000 [1:31:57<01:37,  5.61it/s, lr=8.64e-6, step_loss=0.7407/18/2023 20:35:19 - INFO - __main__ - train loss is 16.472778589464724\n",
      "Steps:  96%|▉| 14452/15000 [1:31:57<01:37,  5.61it/s, lr=8.64e-6, step_loss=0.2707/18/2023 20:35:20 - INFO - __main__ - train loss is 16.801111281849444\n",
      "Steps:  96%|▉| 14453/15000 [1:31:58<02:14,  4.07it/s, lr=8.64e-6, step_loss=0.3207/18/2023 20:35:21 - INFO - __main__ - Per validation step average loss is 0.0016555450856685638\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Cumulative validation average loss is 0.0016555450856685638\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Per validation step average loss is 0.17854371666908264\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Cumulative validation average loss is 0.1801992617547512\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Per validation step average loss is 0.08116112649440765\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Cumulative validation average loss is 0.26136038824915886\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Per validation step average loss is 0.0698763057589531\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Cumulative validation average loss is 0.33123669400811195\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Per validation step average loss is 0.0814436599612236\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Cumulative validation average loss is 0.41268035396933556\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Per validation step average loss is 0.002741984324529767\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Cumulative validation average loss is 0.4154223382938653\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Per validation step average loss is 0.3054277300834656\n",
      "07/18/2023 20:35:21 - INFO - __main__ - Cumulative validation average loss is 0.7208500683773309\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Per validation step average loss is 0.006532730534672737\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Cumulative validation average loss is 0.7273827989120036\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Per validation step average loss is 0.03852580115199089\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Cumulative validation average loss is 0.7659086000639945\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Per validation step average loss is 0.3173583149909973\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Cumulative validation average loss is 1.0832669150549918\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Per validation step average loss is 0.2881181538105011\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Cumulative validation average loss is 1.371385068865493\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Per validation step average loss is 0.09817782044410706\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Cumulative validation average loss is 1.4695628893096\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Average validation loss for Epoch 148 is 0.12246357410913333\n",
      "07/18/2023 20:35:22 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:35:35 - INFO - __main__ - Starting epoch 149\n",
      "07/18/2023 20:35:36 - INFO - __main__ - train loss is 0.040882136672735214\n",
      "Steps:  96%|▉| 14454/15000 [1:32:14<44:59,  4.94s/it, lr=8.64e-6, step_loss=0.0407/18/2023 20:35:36 - INFO - __main__ - train loss is 0.16944312676787376\n",
      "Steps:  96%|▉| 14455/15000 [1:32:14<31:56,  3.52s/it, lr=8.64e-6, step_loss=0.1207/18/2023 20:35:36 - INFO - __main__ - train loss is 0.5533014498651028\n",
      "Steps:  96%|▉| 14456/15000 [1:32:14<22:47,  2.51s/it, lr=8.64e-6, step_loss=0.3807/18/2023 20:35:36 - INFO - __main__ - train loss is 0.6642672829329967\n",
      "Steps:  96%|▉| 14457/15000 [1:32:14<16:25,  1.81s/it, lr=8.64e-6, step_loss=0.1107/18/2023 20:35:36 - INFO - __main__ - train loss is 1.1875748448073864\n",
      "Steps:  96%|▉| 14458/15000 [1:32:14<11:58,  1.33s/it, lr=8.64e-6, step_loss=0.5207/18/2023 20:35:37 - INFO - __main__ - train loss is 1.2140282727777958\n",
      "Steps:  96%|▉| 14459/15000 [1:32:15<08:50,  1.02it/s, lr=8.64e-6, step_loss=0.0207/18/2023 20:35:37 - INFO - __main__ - train loss is 1.4712465144693851\n",
      "Steps:  96%|▉| 14460/15000 [1:32:15<06:39,  1.35it/s, lr=8.64e-6, step_loss=0.2507/18/2023 20:35:37 - INFO - __main__ - train loss is 1.5496703870594501\n",
      "Steps:  96%|▉| 14461/15000 [1:32:15<05:08,  1.75it/s, lr=8.64e-6, step_loss=0.0707/18/2023 20:35:37 - INFO - __main__ - train loss is 1.7586280591785908\n",
      "Steps:  96%|▉| 14462/15000 [1:32:15<04:03,  2.21it/s, lr=8.64e-6, step_loss=0.2007/18/2023 20:35:37 - INFO - __main__ - train loss is 1.9569316990673542\n",
      "Steps:  96%|▉| 14463/15000 [1:32:15<03:19,  2.70it/s, lr=8.64e-6, step_loss=0.1907/18/2023 20:35:38 - INFO - __main__ - train loss is 2.042215544730425\n",
      "Steps:  96%|▉| 14464/15000 [1:32:15<02:47,  3.20it/s, lr=8.64e-6, step_loss=0.0807/18/2023 20:35:38 - INFO - __main__ - train loss is 2.05378201790154\n",
      "Steps:  96%|▉| 14465/15000 [1:32:16<02:25,  3.67it/s, lr=8.64e-6, step_loss=0.0107/18/2023 20:35:38 - INFO - __main__ - train loss is 2.1833376605063677\n",
      "Steps:  96%|▉| 14466/15000 [1:32:16<02:10,  4.10it/s, lr=8.64e-6, step_loss=0.1307/18/2023 20:35:38 - INFO - __main__ - train loss is 2.3563386518508196\n",
      "Steps:  96%|▉| 14467/15000 [1:32:16<01:59,  4.46it/s, lr=8.64e-6, step_loss=0.1707/18/2023 20:35:38 - INFO - __main__ - train loss is 2.463245453312993\n",
      "Steps:  96%|▉| 14468/15000 [1:32:16<01:51,  4.75it/s, lr=8.64e-6, step_loss=0.1007/18/2023 20:35:38 - INFO - __main__ - train loss is 2.573489623144269\n",
      "Steps:  96%|▉| 14469/15000 [1:32:16<01:46,  4.99it/s, lr=8.64e-6, step_loss=0.1107/18/2023 20:35:39 - INFO - __main__ - train loss is 2.577744202222675\n",
      "Steps:  96%|▉| 14470/15000 [1:32:16<01:42,  5.16it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:39 - INFO - __main__ - train loss is 2.993256227578968\n",
      "Steps:  96%|▉| 14471/15000 [1:32:17<01:40,  5.28it/s, lr=8.64e-6, step_loss=0.4107/18/2023 20:35:39 - INFO - __main__ - train loss is 3.0545417717657983\n",
      "Steps:  96%|▉| 14472/15000 [1:32:17<01:38,  5.37it/s, lr=8.64e-6, step_loss=0.0607/18/2023 20:35:39 - INFO - __main__ - train loss is 3.0856125722639263\n",
      "Steps:  96%|▉| 14473/15000 [1:32:17<01:36,  5.44it/s, lr=8.64e-6, step_loss=0.0307/18/2023 20:35:39 - INFO - __main__ - train loss is 3.0900998800061643\n",
      "Steps:  96%|▉| 14474/15000 [1:32:17<01:36,  5.45it/s, lr=8.64e-6, step_loss=0.0007/18/2023 20:35:39 - INFO - __main__ - train loss is 3.308192142751068\n",
      "Steps:  96%|▉| 14475/15000 [1:32:17<01:36,  5.44it/s, lr=8.64e-6, step_loss=0.2107/18/2023 20:35:40 - INFO - __main__ - train loss is 3.445087858941406\n",
      "Steps:  97%|▉| 14476/15000 [1:32:18<01:35,  5.47it/s, lr=8.63e-6, step_loss=0.1307/18/2023 20:35:40 - INFO - __main__ - train loss is 3.5261477171443403\n",
      "Steps:  97%|▉| 14477/15000 [1:32:18<01:35,  5.47it/s, lr=8.63e-6, step_loss=0.0807/18/2023 20:35:40 - INFO - __main__ - train loss is 3.5996843962930143\n",
      "Steps:  97%|▉| 14478/15000 [1:32:18<01:35,  5.45it/s, lr=8.63e-6, step_loss=0.0707/18/2023 20:35:40 - INFO - __main__ - train loss is 3.815893122460693\n",
      "Steps:  97%|▉| 14479/15000 [1:32:18<01:35,  5.48it/s, lr=8.63e-6, step_loss=0.2107/18/2023 20:35:40 - INFO - __main__ - train loss is 3.8341283588670194\n",
      "Steps:  97%|▉| 14480/15000 [1:32:18<01:34,  5.48it/s, lr=8.63e-6, step_loss=0.0107/18/2023 20:35:41 - INFO - __main__ - train loss is 3.83622689335607\n",
      "Steps:  97%|▉| 14481/15000 [1:32:18<01:34,  5.52it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:41 - INFO - __main__ - train loss is 3.8392490297555923\n",
      "Steps:  97%|▉| 14482/15000 [1:32:19<01:33,  5.54it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:41 - INFO - __main__ - train loss is 3.978715717792511\n",
      "Steps:  97%|▉| 14483/15000 [1:32:19<01:32,  5.56it/s, lr=8.63e-6, step_loss=0.1307/18/2023 20:35:41 - INFO - __main__ - train loss is 3.982119187247008\n",
      "Steps:  97%|▉| 14484/15000 [1:32:19<01:32,  5.57it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:41 - INFO - __main__ - train loss is 4.483052595984191\n",
      "Steps:  97%|▉| 14485/15000 [1:32:19<01:32,  5.58it/s, lr=8.63e-6, step_loss=0.5007/18/2023 20:35:41 - INFO - __main__ - train loss is 4.913152619730681\n",
      "Steps:  97%|▉| 14486/15000 [1:32:19<01:32,  5.59it/s, lr=8.63e-6, step_loss=0.4307/18/2023 20:35:42 - INFO - __main__ - train loss is 5.35499034775421\n",
      "Steps:  97%|▉| 14487/15000 [1:32:20<01:32,  5.52it/s, lr=8.63e-6, step_loss=0.4407/18/2023 20:35:42 - INFO - __main__ - train loss is 5.400709647219628\n",
      "Steps:  97%|▉| 14488/15000 [1:32:20<01:33,  5.50it/s, lr=8.63e-6, step_loss=0.0407/18/2023 20:35:42 - INFO - __main__ - train loss is 5.529795858543366\n",
      "Steps:  97%|▉| 14489/15000 [1:32:20<01:33,  5.45it/s, lr=8.63e-6, step_loss=0.1207/18/2023 20:35:42 - INFO - __main__ - train loss is 5.573763388674706\n",
      "Steps:  97%|▉| 14490/15000 [1:32:20<01:34,  5.39it/s, lr=8.63e-6, step_loss=0.0407/18/2023 20:35:42 - INFO - __main__ - train loss is 6.089845675509423\n",
      "Steps:  97%|▉| 14491/15000 [1:32:20<01:36,  5.30it/s, lr=8.63e-6, step_loss=0.5107/18/2023 20:35:43 - INFO - __main__ - train loss is 6.091979222372174\n",
      "Steps:  97%|▉| 14492/15000 [1:32:20<01:37,  5.23it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:43 - INFO - __main__ - train loss is 6.106970779597759\n",
      "Steps:  97%|▉| 14493/15000 [1:32:21<01:37,  5.19it/s, lr=8.63e-6, step_loss=0.0107/18/2023 20:35:43 - INFO - __main__ - train loss is 6.3328928872942924\n",
      "Steps:  97%|▉| 14494/15000 [1:32:21<01:37,  5.18it/s, lr=8.63e-6, step_loss=0.2207/18/2023 20:35:43 - INFO - __main__ - train loss is 6.3353522655088454\n",
      "Steps:  97%|▉| 14495/15000 [1:32:21<01:37,  5.16it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:43 - INFO - __main__ - train loss is 6.590566360624507\n",
      "Steps:  97%|▉| 14496/15000 [1:32:21<01:37,  5.16it/s, lr=8.63e-6, step_loss=0.2507/18/2023 20:35:44 - INFO - __main__ - train loss is 6.883353137644008\n",
      "Steps:  97%|▉| 14497/15000 [1:32:21<01:37,  5.14it/s, lr=8.63e-6, step_loss=0.2907/18/2023 20:35:44 - INFO - __main__ - train loss is 7.346791410120204\n",
      "Steps:  97%|▉| 14498/15000 [1:32:22<01:37,  5.14it/s, lr=8.63e-6, step_loss=0.4607/18/2023 20:35:44 - INFO - __main__ - train loss is 7.653605425031856\n",
      "Steps:  97%|▉| 14499/15000 [1:32:22<01:37,  5.13it/s, lr=8.63e-6, step_loss=0.3007/18/2023 20:35:44 - INFO - __main__ - train loss is 8.4976755019743\n",
      "Steps:  97%|▉| 14500/15000 [1:32:22<01:37,  5.13it/s, lr=8.63e-6, step_loss=0.3007/18/2023 20:35:44 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-14500\n",
      "07/18/2023 20:35:44 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:35:44,747] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:35:44,754] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-14500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:35:44,755] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-14500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:35:44,766] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-14500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:35:44,767] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-14500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:35:44,792] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-14500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:35:44,795] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-14500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:35:44,796] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:35:44 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-14500/pytorch_model\n",
      "07/18/2023 20:35:44 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-14500/scheduler.bin\n",
      "07/18/2023 20:35:44 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-14500/random_states_0.pkl\n",
      "07/18/2023 20:35:44 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-14500\n",
      "Steps:  97%|▉| 14500/15000 [1:32:22<01:37,  5.13it/s, lr=8.63e-6, step_loss=0.8407/18/2023 20:35:44 - INFO - __main__ - train loss is 9.04697343078442\n",
      "Steps:  97%|▉| 14501/15000 [1:32:22<01:45,  4.75it/s, lr=8.63e-6, step_loss=0.5407/18/2023 20:35:45 - INFO - __main__ - train loss is 9.245718979509547\n",
      "Steps:  97%|▉| 14502/15000 [1:32:22<01:41,  4.92it/s, lr=8.63e-6, step_loss=0.1907/18/2023 20:35:45 - INFO - __main__ - train loss is 9.396101870806888\n",
      "Steps:  97%|▉| 14503/15000 [1:32:23<01:39,  5.01it/s, lr=8.63e-6, step_loss=0.1507/18/2023 20:35:45 - INFO - __main__ - train loss is 9.526677527697757\n",
      "Steps:  97%|▉| 14504/15000 [1:32:23<01:38,  5.03it/s, lr=8.63e-6, step_loss=0.1307/18/2023 20:35:45 - INFO - __main__ - train loss is 9.594619364710525\n",
      "Steps:  97%|▉| 14505/15000 [1:32:23<01:37,  5.06it/s, lr=8.63e-6, step_loss=0.0607/18/2023 20:35:45 - INFO - __main__ - train loss is 9.714634345145896\n",
      "Steps:  97%|▉| 14506/15000 [1:32:23<01:37,  5.08it/s, lr=8.63e-6, step_loss=0.1207/18/2023 20:35:46 - INFO - __main__ - train loss is 9.786987410159782\n",
      "Steps:  97%|▉| 14507/15000 [1:32:23<01:36,  5.09it/s, lr=8.63e-6, step_loss=0.0707/18/2023 20:35:46 - INFO - __main__ - train loss is 10.083623097511008\n",
      "Steps:  97%|▉| 14508/15000 [1:32:24<01:36,  5.09it/s, lr=8.63e-6, step_loss=0.2907/18/2023 20:35:46 - INFO - __main__ - train loss is 10.198928714962676\n",
      "Steps:  97%|▉| 14509/15000 [1:32:24<01:36,  5.08it/s, lr=8.63e-6, step_loss=0.1107/18/2023 20:35:46 - INFO - __main__ - train loss is 10.208611220354214\n",
      "Steps:  97%|▉| 14510/15000 [1:32:24<01:36,  5.09it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:46 - INFO - __main__ - train loss is 10.30167293571867\n",
      "Steps:  97%|▉| 14511/15000 [1:32:24<01:35,  5.11it/s, lr=8.63e-6, step_loss=0.0907/18/2023 20:35:47 - INFO - __main__ - train loss is 10.328390380600467\n",
      "Steps:  97%|▉| 14512/15000 [1:32:24<01:35,  5.11it/s, lr=8.63e-6, step_loss=0.0207/18/2023 20:35:47 - INFO - __main__ - train loss is 10.36344692693092\n",
      "Steps:  97%|▉| 14513/15000 [1:32:25<01:35,  5.11it/s, lr=8.63e-6, step_loss=0.0307/18/2023 20:35:47 - INFO - __main__ - train loss is 10.36808195640333\n",
      "Steps:  97%|▉| 14514/15000 [1:32:25<01:35,  5.10it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:47 - INFO - __main__ - train loss is 10.618198453681543\n",
      "Steps:  97%|▉| 14515/15000 [1:32:25<01:34,  5.11it/s, lr=8.63e-6, step_loss=0.2507/18/2023 20:35:47 - INFO - __main__ - train loss is 10.8070354454685\n",
      "Steps:  97%|▉| 14516/15000 [1:32:25<01:34,  5.12it/s, lr=8.63e-6, step_loss=0.1807/18/2023 20:35:48 - INFO - __main__ - train loss is 11.047005503671244\n",
      "Steps:  97%|▉| 14517/15000 [1:32:25<01:34,  5.10it/s, lr=8.63e-6, step_loss=0.2407/18/2023 20:35:48 - INFO - __main__ - train loss is 11.136425121920183\n",
      "Steps:  97%|▉| 14518/15000 [1:32:26<01:34,  5.10it/s, lr=8.63e-6, step_loss=0.0807/18/2023 20:35:48 - INFO - __main__ - train loss is 11.345519080059603\n",
      "Steps:  97%|▉| 14519/15000 [1:32:26<01:34,  5.09it/s, lr=8.63e-6, step_loss=0.2007/18/2023 20:35:48 - INFO - __main__ - train loss is 11.355628052027896\n",
      "Steps:  97%|▉| 14520/15000 [1:32:26<01:34,  5.08it/s, lr=8.63e-6, step_loss=0.0107/18/2023 20:35:48 - INFO - __main__ - train loss is 11.476896413834766\n",
      "Steps:  97%|▉| 14521/15000 [1:32:26<01:34,  5.08it/s, lr=8.63e-6, step_loss=0.1207/18/2023 20:35:49 - INFO - __main__ - train loss is 12.099583157571033\n",
      "Steps:  97%|▉| 14522/15000 [1:32:26<01:33,  5.09it/s, lr=8.63e-6, step_loss=0.6207/18/2023 20:35:49 - INFO - __main__ - train loss is 12.119048052700236\n",
      "Steps:  97%|▉| 14523/15000 [1:32:27<01:33,  5.09it/s, lr=8.63e-6, step_loss=0.0107/18/2023 20:35:49 - INFO - __main__ - train loss is 12.207363584311679\n",
      "Steps:  97%|▉| 14524/15000 [1:32:27<01:32,  5.16it/s, lr=8.63e-6, step_loss=0.0807/18/2023 20:35:49 - INFO - __main__ - train loss is 12.209704466862604\n",
      "Steps:  97%|▉| 14525/15000 [1:32:27<01:32,  5.15it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:49 - INFO - __main__ - train loss is 12.860100575489923\n",
      "Steps:  97%|▉| 14526/15000 [1:32:27<01:31,  5.18it/s, lr=8.63e-6, step_loss=0.6507/18/2023 20:35:49 - INFO - __main__ - train loss is 13.217496790690348\n",
      "Steps:  97%|▉| 14527/15000 [1:32:27<01:30,  5.24it/s, lr=8.63e-6, step_loss=0.3507/18/2023 20:35:50 - INFO - __main__ - train loss is 13.21937936951872\n",
      "Steps:  97%|▉| 14528/15000 [1:32:28<01:29,  5.29it/s, lr=8.63e-6, step_loss=0.0007/18/2023 20:35:50 - INFO - __main__ - train loss is 13.363186676404439\n",
      "Steps:  97%|▉| 14529/15000 [1:32:28<01:28,  5.34it/s, lr=8.63e-6, step_loss=0.1407/18/2023 20:35:50 - INFO - __main__ - train loss is 13.467940878472291\n",
      "Steps:  97%|▉| 14530/15000 [1:32:28<01:27,  5.37it/s, lr=8.63e-6, step_loss=0.1007/18/2023 20:35:50 - INFO - __main__ - train loss is 13.494470529607497\n",
      "Steps:  97%|▉| 14531/15000 [1:32:28<01:27,  5.35it/s, lr=8.63e-6, step_loss=0.0207/18/2023 20:35:50 - INFO - __main__ - train loss is 13.531386927119456\n",
      "Steps:  97%|▉| 14532/15000 [1:32:28<01:27,  5.36it/s, lr=8.62e-6, step_loss=0.0307/18/2023 20:35:51 - INFO - __main__ - train loss is 13.917007699958049\n",
      "Steps:  97%|▉| 14533/15000 [1:32:28<01:27,  5.31it/s, lr=8.62e-6, step_loss=0.3807/18/2023 20:35:51 - INFO - __main__ - train loss is 14.248120382777415\n",
      "Steps:  97%|▉| 14534/15000 [1:32:29<01:29,  5.22it/s, lr=8.62e-6, step_loss=0.3307/18/2023 20:35:51 - INFO - __main__ - train loss is 14.258954881108366\n",
      "Steps:  97%|▉| 14535/15000 [1:32:29<01:35,  4.88it/s, lr=8.62e-6, step_loss=0.0107/18/2023 20:35:51 - INFO - __main__ - train loss is 14.676671086228453\n",
      "Steps:  97%|▉| 14536/15000 [1:32:29<01:36,  4.80it/s, lr=8.62e-6, step_loss=0.4107/18/2023 20:35:51 - INFO - __main__ - train loss is 14.719595788395964\n",
      "Steps:  97%|▉| 14537/15000 [1:32:29<01:33,  4.94it/s, lr=8.62e-6, step_loss=0.0407/18/2023 20:35:52 - INFO - __main__ - train loss is 14.826011045253836\n",
      "Steps:  97%|▉| 14538/15000 [1:32:29<01:31,  5.04it/s, lr=8.62e-6, step_loss=0.1007/18/2023 20:35:52 - INFO - __main__ - train loss is 14.887538055307232\n",
      "Steps:  97%|▉| 14539/15000 [1:32:30<01:30,  5.11it/s, lr=8.62e-6, step_loss=0.0607/18/2023 20:35:52 - INFO - __main__ - train loss is 15.34999329817947\n",
      "Steps:  97%|▉| 14540/15000 [1:32:30<01:29,  5.12it/s, lr=8.62e-6, step_loss=0.4607/18/2023 20:35:52 - INFO - __main__ - train loss is 15.354521942674182\n",
      "Steps:  97%|▉| 14541/15000 [1:32:30<01:29,  5.13it/s, lr=8.62e-6, step_loss=0.0007/18/2023 20:35:52 - INFO - __main__ - train loss is 15.531258178292774\n",
      "Steps:  97%|▉| 14542/15000 [1:32:30<01:29,  5.13it/s, lr=8.62e-6, step_loss=0.1707/18/2023 20:35:53 - INFO - __main__ - train loss is 15.553509240387939\n",
      "Steps:  97%|▉| 14543/15000 [1:32:30<01:29,  5.11it/s, lr=8.62e-6, step_loss=0.0207/18/2023 20:35:53 - INFO - __main__ - train loss is 16.440276389359497\n",
      "Steps:  97%|▉| 14544/15000 [1:32:31<01:29,  5.12it/s, lr=8.62e-6, step_loss=0.8807/18/2023 20:35:53 - INFO - __main__ - train loss is 16.947537784813903\n",
      "Steps:  97%|▉| 14545/15000 [1:32:31<01:28,  5.13it/s, lr=8.62e-6, step_loss=0.5007/18/2023 20:35:53 - INFO - __main__ - train loss is 16.96156866417732\n",
      "Steps:  97%|▉| 14546/15000 [1:32:31<01:28,  5.14it/s, lr=8.62e-6, step_loss=0.0107/18/2023 20:35:53 - INFO - __main__ - train loss is 17.064217205508612\n",
      "Steps:  97%|▉| 14547/15000 [1:32:31<01:28,  5.14it/s, lr=8.62e-6, step_loss=0.1007/18/2023 20:35:54 - INFO - __main__ - train loss is 17.068408726132475\n",
      "Steps:  97%|▉| 14548/15000 [1:32:31<01:26,  5.21it/s, lr=8.62e-6, step_loss=0.0007/18/2023 20:35:54 - INFO - __main__ - train loss is 17.151473818696104\n",
      "Steps:  97%|▉| 14549/15000 [1:32:32<01:27,  5.18it/s, lr=8.62e-6, step_loss=0.0807/18/2023 20:35:54 - INFO - __main__ - train loss is 17.40950059739407\n",
      "Steps:  97%|▉| 14550/15000 [1:32:32<02:10,  3.44it/s, lr=8.62e-6, step_loss=0.2507/18/2023 20:35:55 - INFO - __main__ - Per validation step average loss is 0.19660720229148865\n",
      "07/18/2023 20:35:55 - INFO - __main__ - Cumulative validation average loss is 0.19660720229148865\n",
      "07/18/2023 20:35:55 - INFO - __main__ - Per validation step average loss is 0.019146669656038284\n",
      "07/18/2023 20:35:55 - INFO - __main__ - Cumulative validation average loss is 0.21575387194752693\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Per validation step average loss is 0.2557888329029083\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Cumulative validation average loss is 0.47154270485043526\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Per validation step average loss is 0.8082948923110962\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Cumulative validation average loss is 1.2798375971615314\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Per validation step average loss is 0.06041483208537102\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Cumulative validation average loss is 1.3402524292469025\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Per validation step average loss is 0.07623040676116943\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Cumulative validation average loss is 1.416482836008072\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Per validation step average loss is 0.004068494774401188\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Cumulative validation average loss is 1.420551330782473\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Per validation step average loss is 0.0023298943415284157\n",
      "07/18/2023 20:35:56 - INFO - __main__ - Cumulative validation average loss is 1.4228812251240015\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Per validation step average loss is 0.029341785237193108\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Cumulative validation average loss is 1.4522230103611946\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Per validation step average loss is 0.007309462875127792\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Cumulative validation average loss is 1.4595324732363224\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Per validation step average loss is 0.04323754087090492\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Cumulative validation average loss is 1.5027700141072273\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Per validation step average loss is 0.17366069555282593\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Cumulative validation average loss is 1.6764307096600533\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Average validation loss for Epoch 149 is 0.13970255913833776\n",
      "07/18/2023 20:35:57 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:36:10 - INFO - __main__ - Starting epoch 150\n",
      "07/18/2023 20:36:11 - INFO - __main__ - train loss is 0.25805550813674927\n",
      "Steps:  97%|▉| 14551/15000 [1:32:49<39:54,  5.33s/it, lr=8.62e-6, step_loss=0.2507/18/2023 20:36:12 - INFO - __main__ - train loss is 0.26401684805750847\n",
      "Steps:  97%|▉| 14552/15000 [1:32:50<29:05,  3.90s/it, lr=8.62e-6, step_loss=0.0007/18/2023 20:36:12 - INFO - __main__ - train loss is 0.5391816310584545\n",
      "Steps:  97%|▉| 14553/15000 [1:32:50<21:33,  2.89s/it, lr=8.62e-6, step_loss=0.2707/18/2023 20:36:13 - INFO - __main__ - train loss is 0.6793085597455502\n",
      "Steps:  97%|▉| 14554/15000 [1:32:51<16:15,  2.19s/it, lr=8.62e-6, step_loss=0.1407/18/2023 20:36:14 - INFO - __main__ - train loss is 0.7693282477557659\n",
      "Steps:  97%|▉| 14555/15000 [1:32:51<12:34,  1.70s/it, lr=8.62e-6, step_loss=0.0907/18/2023 20:36:14 - INFO - __main__ - train loss is 0.8043909333646297\n",
      "Steps:  97%|▉| 14556/15000 [1:32:52<10:01,  1.36s/it, lr=8.62e-6, step_loss=0.0307/18/2023 20:36:15 - INFO - __main__ - train loss is 0.8412657827138901\n",
      "Steps:  97%|▉| 14557/15000 [1:32:53<08:13,  1.11s/it, lr=8.62e-6, step_loss=0.0307/18/2023 20:36:15 - INFO - __main__ - train loss is 0.8481112234294415\n",
      "Steps:  97%|▉| 14558/15000 [1:32:53<06:56,  1.06it/s, lr=8.62e-6, step_loss=0.0007/18/2023 20:36:16 - INFO - __main__ - train loss is 0.8496656351489946\n",
      "Steps:  97%|▉| 14559/15000 [1:32:54<06:04,  1.21it/s, lr=8.62e-6, step_loss=0.0007/18/2023 20:36:16 - INFO - __main__ - train loss is 1.52092885307502\n",
      "Steps:  97%|▉| 14560/15000 [1:32:54<05:26,  1.35it/s, lr=8.62e-6, step_loss=0.6707/18/2023 20:36:17 - INFO - __main__ - train loss is 1.541710075805895\n",
      "Steps:  97%|▉| 14561/15000 [1:32:55<04:59,  1.47it/s, lr=8.62e-6, step_loss=0.0207/18/2023 20:36:17 - INFO - __main__ - train loss is 1.6968561232788488\n",
      "Steps:  97%|▉| 14562/15000 [1:32:55<04:40,  1.56it/s, lr=8.62e-6, step_loss=0.1507/18/2023 20:36:18 - INFO - __main__ - train loss is 1.8366185844643041\n",
      "Steps:  97%|▉| 14563/15000 [1:32:56<04:26,  1.64it/s, lr=8.62e-6, step_loss=0.1407/18/2023 20:36:18 - INFO - __main__ - train loss is 1.9071916163666174\n",
      "Steps:  97%|▉| 14564/15000 [1:32:56<04:18,  1.69it/s, lr=8.62e-6, step_loss=0.0707/18/2023 20:36:19 - INFO - __main__ - train loss is 1.9431211919290945\n",
      "Steps:  97%|▉| 14565/15000 [1:32:57<04:11,  1.73it/s, lr=8.62e-6, step_loss=0.0307/18/2023 20:36:20 - INFO - __main__ - train loss is 2.4072823495371267\n",
      "Steps:  97%|▉| 14566/15000 [1:32:57<04:07,  1.75it/s, lr=8.62e-6, step_loss=0.4607/18/2023 20:36:20 - INFO - __main__ - train loss is 3.0826892823679373\n",
      "Steps:  97%|▉| 14567/15000 [1:32:58<04:03,  1.78it/s, lr=8.62e-6, step_loss=0.6707/18/2023 20:36:21 - INFO - __main__ - train loss is 3.1750719369156286\n",
      "Steps:  97%|▉| 14568/15000 [1:32:59<04:02,  1.78it/s, lr=8.62e-6, step_loss=0.0907/18/2023 20:36:21 - INFO - __main__ - train loss is 3.4408296764595434\n",
      "Steps:  97%|▉| 14569/15000 [1:32:59<03:59,  1.80it/s, lr=8.62e-6, step_loss=0.26\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "07/18/2023 20:36:22 - INFO - __main__ - train loss is 3.8166447997791693\n",
      "Steps:  97%|▉| 14570/15000 [1:33:00<03:57,  1.81it/s, lr=8.62e-6, step_loss=0.3707/18/2023 20:36:22 - INFO - __main__ - train loss is 4.085062933037989\n",
      "Steps:  97%|▉| 14571/15000 [1:33:00<03:54,  1.83it/s, lr=8.62e-6, step_loss=0.2607/18/2023 20:36:23 - INFO - __main__ - train loss is 4.274799612234347\n",
      "Steps:  97%|▉| 14572/15000 [1:33:01<03:55,  1.82it/s, lr=8.62e-6, step_loss=0.1907/18/2023 20:36:23 - INFO - __main__ - train loss is 4.3301196553511545\n",
      "Steps:  97%|▉| 14573/15000 [1:33:01<03:53,  1.83it/s, lr=8.62e-6, step_loss=0.0507/18/2023 20:36:24 - INFO - __main__ - train loss is 4.343938845093362\n",
      "Steps:  97%|▉| 14574/15000 [1:33:02<03:53,  1.83it/s, lr=8.62e-6, step_loss=0.0107/18/2023 20:36:24 - INFO - __main__ - train loss is 4.373461070354097\n",
      "Steps:  97%|▉| 14575/15000 [1:33:02<03:52,  1.82it/s, lr=8.62e-6, step_loss=0.0207/18/2023 20:36:25 - INFO - __main__ - train loss is 4.685820641811006\n",
      "Steps:  97%|▉| 14576/15000 [1:33:03<03:51,  1.83it/s, lr=8.62e-6, step_loss=0.3107/18/2023 20:36:26 - INFO - __main__ - train loss is 4.7261646267725155\n",
      "Steps:  97%|▉| 14577/15000 [1:33:03<03:51,  1.83it/s, lr=8.62e-6, step_loss=0.0407/18/2023 20:36:26 - INFO - __main__ - train loss is 4.789090382750146\n",
      "Steps:  97%|▉| 14578/15000 [1:33:04<03:51,  1.82it/s, lr=8.62e-6, step_loss=0.06\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "07/18/2023 20:36:27 - INFO - __main__ - train loss is 4.807161933626048\n",
      "Steps:  97%|▉| 14579/15000 [1:33:05<03:50,  1.83it/s, lr=8.62e-6, step_loss=0.01\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "07/18/2023 20:36:27 - INFO - __main__ - train loss is 5.175045407260768\n",
      "Steps:  97%|▉| 14580/15000 [1:33:05<03:49,  1.83it/s, lr=8.62e-6, step_loss=0.3607/18/2023 20:36:28 - INFO - __main__ - train loss is 5.181304690777324\n",
      "Steps:  97%|▉| 14581/15000 [1:33:06<03:49,  1.83it/s, lr=8.62e-6, step_loss=0.0007/18/2023 20:36:28 - INFO - __main__ - train loss is 5.208729162230156\n",
      "Steps:  97%|▉| 14582/15000 [1:33:06<03:48,  1.83it/s, lr=8.62e-6, step_loss=0.0207/18/2023 20:36:29 - INFO - __main__ - train loss is 5.526188149466179\n",
      "Steps:  97%|▉| 14583/15000 [1:33:07<03:48,  1.82it/s, lr=8.62e-6, step_loss=0.3107/18/2023 20:36:29 - INFO - __main__ - train loss is 5.537177218473516\n",
      "Steps:  97%|▉| 14584/15000 [1:33:07<03:47,  1.83it/s, lr=8.62e-6, step_loss=0.0107/18/2023 20:36:30 - INFO - __main__ - train loss is 5.663344620144926\n",
      "Steps:  97%|▉| 14585/15000 [1:33:08<03:46,  1.84it/s, lr=8.62e-6, step_loss=0.1207/18/2023 20:36:31 - INFO - __main__ - train loss is 6.190187989152037\n",
      "Steps:  97%|▉| 14586/15000 [1:33:08<03:47,  1.82it/s, lr=8.62e-6, step_loss=0.52\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "07/18/2023 20:36:31 - INFO - __main__ - train loss is 6.232188640511595\n",
      "Steps:  97%|▉| 14587/15000 [1:33:09<03:46,  1.82it/s, lr=8.61e-6, step_loss=0.0407/18/2023 20:36:32 - INFO - __main__ - train loss is 6.2823432221775874\n",
      "Steps:  97%|▉| 14588/15000 [1:33:09<03:45,  1.83it/s, lr=8.61e-6, step_loss=0.0507/18/2023 20:36:32 - INFO - __main__ - train loss is 6.3602002173429355\n",
      "Steps:  97%|▉| 14589/15000 [1:33:10<03:44,  1.83it/s, lr=8.61e-6, step_loss=0.0707/18/2023 20:36:33 - INFO - __main__ - train loss is 6.361661688075401\n",
      "Steps:  97%|▉| 14590/15000 [1:33:11<03:44,  1.83it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:33 - INFO - __main__ - train loss is 6.490461275563575\n",
      "Steps:  97%|▉| 14591/15000 [1:33:11<03:43,  1.83it/s, lr=8.61e-6, step_loss=0.1207/18/2023 20:36:34 - INFO - __main__ - train loss is 6.600400359020568\n",
      "Steps:  97%|▉| 14592/15000 [1:33:12<03:43,  1.83it/s, lr=8.61e-6, step_loss=0.1107/18/2023 20:36:34 - INFO - __main__ - train loss is 6.646532707498409\n",
      "Steps:  97%|▉| 14593/15000 [1:33:12<03:41,  1.83it/s, lr=8.61e-6, step_loss=0.0407/18/2023 20:36:35 - INFO - __main__ - train loss is 7.0353898933390155\n",
      "Steps:  97%|▉| 14594/15000 [1:33:13<03:41,  1.83it/s, lr=8.61e-6, step_loss=0.3807/18/2023 20:36:35 - INFO - __main__ - train loss is 7.334749930188991\n",
      "Steps:  97%|▉| 14595/15000 [1:33:13<03:42,  1.82it/s, lr=8.61e-6, step_loss=0.2907/18/2023 20:36:36 - INFO - __main__ - train loss is 7.7500967314699665\n",
      "Steps:  97%|▉| 14596/15000 [1:33:14<03:43,  1.81it/s, lr=8.61e-6, step_loss=0.4107/18/2023 20:36:37 - INFO - __main__ - train loss is 8.244248591945507\n",
      "Steps:  97%|▉| 14597/15000 [1:33:14<03:42,  1.81it/s, lr=8.61e-6, step_loss=0.4907/18/2023 20:36:37 - INFO - __main__ - train loss is 8.265362082631327\n",
      "Steps:  97%|▉| 14598/15000 [1:33:15<03:41,  1.81it/s, lr=8.61e-6, step_loss=0.0207/18/2023 20:36:38 - INFO - __main__ - train loss is 8.279162899241783\n",
      "Steps:  97%|▉| 14599/15000 [1:33:16<03:41,  1.81it/s, lr=8.61e-6, step_loss=0.0107/18/2023 20:36:38 - INFO - __main__ - train loss is 8.766024426207878\n",
      "Steps:  97%|▉| 14600/15000 [1:33:16<03:39,  1.82it/s, lr=8.61e-6, step_loss=0.4807/18/2023 20:36:39 - INFO - __main__ - train loss is 8.786985010490753\n",
      "Steps:  97%|▉| 14601/15000 [1:33:17<03:39,  1.82it/s, lr=8.61e-6, step_loss=0.0207/18/2023 20:36:39 - INFO - __main__ - train loss is 8.79496953508351\n",
      "Steps:  97%|▉| 14602/15000 [1:33:17<03:38,  1.83it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:40 - INFO - __main__ - train loss is 8.916698834509589\n",
      "Steps:  97%|▉| 14603/15000 [1:33:18<03:37,  1.82it/s, lr=8.61e-6, step_loss=0.1207/18/2023 20:36:40 - INFO - __main__ - train loss is 8.925849248305894\n",
      "Steps:  97%|▉| 14604/15000 [1:33:18<03:36,  1.83it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:41 - INFO - __main__ - train loss is 8.934760339208879\n",
      "Steps:  97%|▉| 14605/15000 [1:33:19<03:35,  1.83it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:41 - INFO - __main__ - train loss is 9.229117758222856\n",
      "Steps:  97%|▉| 14606/15000 [1:33:19<03:35,  1.83it/s, lr=8.61e-6, step_loss=0.2907/18/2023 20:36:42 - INFO - __main__ - train loss is 9.355170704075135\n",
      "Steps:  97%|▉| 14607/15000 [1:33:20<03:34,  1.83it/s, lr=8.61e-6, step_loss=0.1207/18/2023 20:36:43 - INFO - __main__ - train loss is 9.64373723382596\n",
      "Steps:  97%|▉| 14608/15000 [1:33:20<03:33,  1.84it/s, lr=8.61e-6, step_loss=0.2807/18/2023 20:36:43 - INFO - __main__ - train loss is 9.646602162509225\n",
      "Steps:  97%|▉| 14609/15000 [1:33:21<03:33,  1.83it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:44 - INFO - __main__ - train loss is 9.776083478122018\n",
      "Steps:  97%|▉| 14610/15000 [1:33:22<03:33,  1.83it/s, lr=8.61e-6, step_loss=0.1207/18/2023 20:36:44 - INFO - __main__ - train loss is 9.809621849446557\n",
      "Steps:  97%|▉| 14611/15000 [1:33:22<03:32,  1.83it/s, lr=8.61e-6, step_loss=0.0307/18/2023 20:36:45 - INFO - __main__ - train loss is 9.879114316194318\n",
      "Steps:  97%|▉| 14612/15000 [1:33:23<03:31,  1.84it/s, lr=8.61e-6, step_loss=0.0607/18/2023 20:36:45 - INFO - __main__ - train loss is 9.888760138652287\n",
      "Steps:  97%|▉| 14613/15000 [1:33:23<03:30,  1.84it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:46 - INFO - __main__ - train loss is 9.994567599496804\n",
      "Steps:  97%|▉| 14614/15000 [1:33:24<03:30,  1.83it/s, lr=8.61e-6, step_loss=0.1007/18/2023 20:36:46 - INFO - __main__ - train loss is 10.03269705211278\n",
      "Steps:  97%|▉| 14615/15000 [1:33:24<03:29,  1.83it/s, lr=8.61e-6, step_loss=0.0307/18/2023 20:36:47 - INFO - __main__ - train loss is 10.03809419402387\n",
      "Steps:  97%|▉| 14616/15000 [1:33:25<03:29,  1.84it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:47 - INFO - __main__ - train loss is 10.369639427750371\n",
      "Steps:  97%|▉| 14617/15000 [1:33:25<03:28,  1.84it/s, lr=8.61e-6, step_loss=0.3307/18/2023 20:36:48 - INFO - __main__ - train loss is 10.371423581033014\n",
      "Steps:  97%|▉| 14618/15000 [1:33:26<03:27,  1.84it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:49 - INFO - __main__ - train loss is 10.73551110306289\n",
      "Steps:  97%|▉| 14619/15000 [1:33:26<03:26,  1.85it/s, lr=8.61e-6, step_loss=0.3607/18/2023 20:36:49 - INFO - __main__ - train loss is 10.916311511187814\n",
      "Steps:  97%|▉| 14620/15000 [1:33:27<03:26,  1.84it/s, lr=8.61e-6, step_loss=0.1807/18/2023 20:36:50 - INFO - __main__ - train loss is 11.174324878840707\n",
      "Steps:  97%|▉| 14621/15000 [1:33:28<03:26,  1.84it/s, lr=8.61e-6, step_loss=0.2507/18/2023 20:36:50 - INFO - __main__ - train loss is 11.420295515446924\n",
      "Steps:  97%|▉| 14622/15000 [1:33:28<03:28,  1.81it/s, lr=8.61e-6, step_loss=0.2407/18/2023 20:36:51 - INFO - __main__ - train loss is 11.617535152821802\n",
      "Steps:  97%|▉| 14623/15000 [1:33:29<03:38,  1.72it/s, lr=8.61e-6, step_loss=0.1907/18/2023 20:36:52 - INFO - __main__ - train loss is 11.67886198067572\n",
      "Steps:  97%|▉| 14624/15000 [1:33:29<03:47,  1.65it/s, lr=8.61e-6, step_loss=0.0607/18/2023 20:36:52 - INFO - __main__ - train loss is 11.682575019891374\n",
      "Steps:  98%|▉| 14625/15000 [1:33:30<03:42,  1.68it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:53 - INFO - __main__ - train loss is 11.731185632641427\n",
      "Steps:  98%|▉| 14626/15000 [1:33:31<03:37,  1.72it/s, lr=8.61e-6, step_loss=0.0407/18/2023 20:36:53 - INFO - __main__ - train loss is 11.756400338257663\n",
      "Steps:  98%|▉| 14627/15000 [1:33:31<03:33,  1.75it/s, lr=8.61e-6, step_loss=0.0207/18/2023 20:36:54 - INFO - __main__ - train loss is 11.799300703103654\n",
      "Steps:  98%|▉| 14628/15000 [1:33:32<03:30,  1.77it/s, lr=8.61e-6, step_loss=0.0407/18/2023 20:36:54 - INFO - __main__ - train loss is 11.811910615186207\n",
      "Steps:  98%|▉| 14629/15000 [1:33:32<03:27,  1.79it/s, lr=8.61e-6, step_loss=0.0107/18/2023 20:36:55 - INFO - __main__ - train loss is 11.85089764453005\n",
      "Steps:  98%|▉| 14630/15000 [1:33:33<03:25,  1.80it/s, lr=8.61e-6, step_loss=0.0307/18/2023 20:36:55 - INFO - __main__ - train loss is 12.180552040110342\n",
      "Steps:  98%|▉| 14631/15000 [1:33:33<03:24,  1.80it/s, lr=8.61e-6, step_loss=0.3307/18/2023 20:36:56 - INFO - __main__ - train loss is 12.185071886400692\n",
      "Steps:  98%|▉| 14632/15000 [1:33:34<03:23,  1.81it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:56 - INFO - __main__ - train loss is 12.565496087889187\n",
      "Steps:  98%|▉| 14633/15000 [1:33:34<03:21,  1.82it/s, lr=8.61e-6, step_loss=0.3807/18/2023 20:36:57 - INFO - __main__ - train loss is 12.92363968573045\n",
      "Steps:  98%|▉| 14634/15000 [1:33:35<03:20,  1.82it/s, lr=8.61e-6, step_loss=0.3507/18/2023 20:36:58 - INFO - __main__ - train loss is 12.97138004458975\n",
      "Steps:  98%|▉| 14635/15000 [1:33:35<03:19,  1.83it/s, lr=8.61e-6, step_loss=0.0407/18/2023 20:36:58 - INFO - __main__ - train loss is 12.972699762671255\n",
      "Steps:  98%|▉| 14636/15000 [1:33:36<03:17,  1.84it/s, lr=8.61e-6, step_loss=0.0007/18/2023 20:36:59 - INFO - __main__ - train loss is 13.035588042228483\n",
      "Steps:  98%|▉| 14637/15000 [1:33:37<03:16,  1.84it/s, lr=8.61e-6, step_loss=0.0607/18/2023 20:36:59 - INFO - __main__ - train loss is 13.081132189719938\n",
      "Steps:  98%|▉| 14638/15000 [1:33:37<03:16,  1.85it/s, lr=8.61e-6, step_loss=0.0407/18/2023 20:37:00 - INFO - __main__ - train loss is 13.152823114185594\n",
      "Steps:  98%|▉| 14639/15000 [1:33:38<03:15,  1.85it/s, lr=8.61e-6, step_loss=0.0707/18/2023 20:37:00 - INFO - __main__ - train loss is 13.677416527061723\n",
      "Steps:  98%|▉| 14640/15000 [1:33:38<03:14,  1.85it/s, lr=8.61e-6, step_loss=0.5207/18/2023 20:37:01 - INFO - __main__ - train loss is 13.712411896674894\n",
      "Steps:  98%|▉| 14641/15000 [1:33:39<03:13,  1.86it/s, lr=8.61e-6, step_loss=0.0307/18/2023 20:37:01 - INFO - __main__ - train loss is 13.878450543968938\n",
      "Steps:  98%|▉| 14642/15000 [1:33:39<03:12,  1.86it/s, lr=8.6e-6, step_loss=0.16607/18/2023 20:37:02 - INFO - __main__ - train loss is 14.180015505640768\n",
      "Steps:  98%|▉| 14643/15000 [1:33:40<03:11,  1.86it/s, lr=8.6e-6, step_loss=0.30207/18/2023 20:37:02 - INFO - __main__ - train loss is 14.18302532506641\n",
      "Steps:  98%|▉| 14644/15000 [1:33:40<03:11,  1.86it/s, lr=8.6e-6, step_loss=0.00307/18/2023 20:37:03 - INFO - __main__ - train loss is 14.259151192731224\n",
      "Steps:  98%|▉| 14645/15000 [1:33:41<03:10,  1.86it/s, lr=8.6e-6, step_loss=0.07607/18/2023 20:37:03 - INFO - __main__ - train loss is 14.28778774139937\n",
      "Steps:  98%|▉| 14646/15000 [1:33:41<03:10,  1.86it/s, lr=8.6e-6, step_loss=0.02807/18/2023 20:37:04 - INFO - __main__ - train loss is 14.296203131205402\n",
      "Steps:  98%|▉| 14647/15000 [1:33:42<03:37,  1.62it/s, lr=8.6e-6, step_loss=0.00807/18/2023 20:37:05 - INFO - __main__ - Per validation step average loss is 0.25167185068130493\n",
      "07/18/2023 20:37:05 - INFO - __main__ - Cumulative validation average loss is 0.25167185068130493\n",
      "07/18/2023 20:37:05 - INFO - __main__ - Per validation step average loss is 0.1273091733455658\n",
      "07/18/2023 20:37:05 - INFO - __main__ - Cumulative validation average loss is 0.3789810240268707\n",
      "07/18/2023 20:37:05 - INFO - __main__ - Per validation step average loss is 0.2918790578842163\n",
      "07/18/2023 20:37:05 - INFO - __main__ - Cumulative validation average loss is 0.670860081911087\n",
      "07/18/2023 20:37:05 - INFO - __main__ - Per validation step average loss is 0.4048178195953369\n",
      "07/18/2023 20:37:05 - INFO - __main__ - Cumulative validation average loss is 1.075677901506424\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Per validation step average loss is 0.0016392474062740803\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Cumulative validation average loss is 1.077317148912698\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Per validation step average loss is 0.36750635504722595\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Cumulative validation average loss is 1.444823503959924\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Per validation step average loss is 0.2920393645763397\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Cumulative validation average loss is 1.7368628685362637\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Per validation step average loss is 0.44412559270858765\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Cumulative validation average loss is 2.1809884612448514\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Per validation step average loss is 0.003145637921988964\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Cumulative validation average loss is 2.1841340991668403\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Per validation step average loss is 0.3780050277709961\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Cumulative validation average loss is 2.5621391269378364\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Per validation step average loss is 0.006191526539623737\n",
      "07/18/2023 20:37:06 - INFO - __main__ - Cumulative validation average loss is 2.56833065347746\n",
      "07/18/2023 20:37:07 - INFO - __main__ - Per validation step average loss is 0.026851460337638855\n",
      "07/18/2023 20:37:07 - INFO - __main__ - Cumulative validation average loss is 2.595182113815099\n",
      "07/18/2023 20:37:07 - INFO - __main__ - Average validation loss for Epoch 150 is 0.21626517615125826\n",
      "07/18/2023 20:37:07 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:37:19 - INFO - __main__ - Starting epoch 151\n",
      "07/18/2023 20:37:20 - INFO - __main__ - train loss is 0.09541992843151093\n",
      "Steps:  98%|▉| 14648/15000 [1:33:58<30:25,  5.19s/it, lr=8.6e-6, step_loss=0.09507/18/2023 20:37:20 - INFO - __main__ - train loss is 0.3199085146188736\n",
      "Steps:  98%|▉| 14649/15000 [1:33:58<21:33,  3.68s/it, lr=8.6e-6, step_loss=0.22407/18/2023 20:37:20 - INFO - __main__ - train loss is 0.4909260720014572\n",
      "Steps:  98%|▉| 14650/15000 [1:33:58<15:22,  2.63s/it, lr=8.6e-6, step_loss=0.17107/18/2023 20:37:21 - INFO - __main__ - train loss is 0.5415342338383198\n",
      "Steps:  98%|▉| 14651/15000 [1:33:59<11:02,  1.90s/it, lr=8.6e-6, step_loss=0.05007/18/2023 20:37:21 - INFO - __main__ - train loss is 1.1115390546619892\n",
      "Steps:  98%|▉| 14652/15000 [1:33:59<08:01,  1.38s/it, lr=8.6e-6, step_loss=0.57]07/18/2023 20:37:21 - INFO - __main__ - train loss is 1.1831157989799976\n",
      "Steps:  98%|▉| 14653/15000 [1:33:59<05:55,  1.02s/it, lr=8.6e-6, step_loss=0.07107/18/2023 20:37:21 - INFO - __main__ - train loss is 1.1879540611989796\n",
      "Steps:  98%|▉| 14654/15000 [1:33:59<04:26,  1.30it/s, lr=8.6e-6, step_loss=0.00407/18/2023 20:37:21 - INFO - __main__ - train loss is 1.2117299032397568\n",
      "Steps:  98%|▉| 14655/15000 [1:33:59<03:24,  1.68it/s, lr=8.6e-6, step_loss=0.02307/18/2023 20:37:22 - INFO - __main__ - train loss is 1.2142067588865757\n",
      "Steps:  98%|▉| 14656/15000 [1:33:59<02:41,  2.13it/s, lr=8.6e-6, step_loss=0.00207/18/2023 20:37:22 - INFO - __main__ - train loss is 1.435317788273096\n",
      "Steps:  98%|▉| 14657/15000 [1:34:00<02:11,  2.61it/s, lr=8.6e-6, step_loss=0.22107/18/2023 20:37:22 - INFO - __main__ - train loss is 1.4446194171905518\n",
      "Steps:  98%|▉| 14658/15000 [1:34:00<01:50,  3.10it/s, lr=8.6e-6, step_loss=0.00907/18/2023 20:37:22 - INFO - __main__ - train loss is 1.4990017302334309\n",
      "Steps:  98%|▉| 14659/15000 [1:34:00<01:35,  3.58it/s, lr=8.6e-6, step_loss=0.05407/18/2023 20:37:22 - INFO - __main__ - train loss is 1.569878701120615\n",
      "Steps:  98%|▉| 14660/15000 [1:34:00<01:24,  4.00it/s, lr=8.6e-6, step_loss=0.07007/18/2023 20:37:22 - INFO - __main__ - train loss is 1.6472881026566029\n",
      "Steps:  98%|▉| 14661/15000 [1:34:00<01:17,  4.37it/s, lr=8.6e-6, step_loss=0.07707/18/2023 20:37:23 - INFO - __main__ - train loss is 1.6503923027776182\n",
      "Steps:  98%|▉| 14662/15000 [1:34:01<01:12,  4.65it/s, lr=8.6e-6, step_loss=0.00307/18/2023 20:37:23 - INFO - __main__ - train loss is 1.748872162308544\n",
      "Steps:  98%|▉| 14663/15000 [1:34:01<01:08,  4.89it/s, lr=8.6e-6, step_loss=0.09807/18/2023 20:37:23 - INFO - __main__ - train loss is 1.8188439547084272\n",
      "Steps:  98%|▉| 14664/15000 [1:34:01<01:06,  5.07it/s, lr=8.6e-6, step_loss=0.07]07/18/2023 20:37:23 - INFO - __main__ - train loss is 1.8209284106269479\n",
      "Steps:  98%|▉| 14665/15000 [1:34:01<01:04,  5.20it/s, lr=8.6e-6, step_loss=0.00207/18/2023 20:37:23 - INFO - __main__ - train loss is 1.854914308525622\n",
      "Steps:  98%|▉| 14666/15000 [1:34:01<01:03,  5.29it/s, lr=8.6e-6, step_loss=0.03407/18/2023 20:37:24 - INFO - __main__ - train loss is 1.8882456431165338\n",
      "Steps:  98%|▉| 14667/15000 [1:34:01<01:02,  5.36it/s, lr=8.6e-6, step_loss=0.03307/18/2023 20:37:24 - INFO - __main__ - train loss is 2.2461626240983605\n",
      "Steps:  98%|▉| 14668/15000 [1:34:02<01:01,  5.41it/s, lr=8.6e-6, step_loss=0.35807/18/2023 20:37:24 - INFO - __main__ - train loss is 2.2493623516056687\n",
      "Steps:  98%|▉| 14669/15000 [1:34:02<01:00,  5.44it/s, lr=8.6e-6, step_loss=0.00307/18/2023 20:37:24 - INFO - __main__ - train loss is 2.27409027912654\n",
      "Steps:  98%|▉| 14670/15000 [1:34:02<01:00,  5.47it/s, lr=8.6e-6, step_loss=0.02407/18/2023 20:37:24 - INFO - __main__ - train loss is 2.293685510987416\n",
      "Steps:  98%|▉| 14671/15000 [1:34:02<00:59,  5.48it/s, lr=8.6e-6, step_loss=0.01907/18/2023 20:37:24 - INFO - __main__ - train loss is 2.3043558525387198\n",
      "Steps:  98%|▉| 14672/15000 [1:34:02<00:59,  5.50it/s, lr=8.6e-6, step_loss=0.01007/18/2023 20:37:25 - INFO - __main__ - train loss is 2.497168682748452\n",
      "Steps:  98%|▉| 14673/15000 [1:34:03<00:59,  5.51it/s, lr=8.6e-6, step_loss=0.19307/18/2023 20:37:25 - INFO - __main__ - train loss is 2.635312639409676\n",
      "Steps:  98%|▉| 14674/15000 [1:34:03<00:59,  5.51it/s, lr=8.6e-6, step_loss=0.13807/18/2023 20:37:25 - INFO - __main__ - train loss is 2.6369133479893208\n",
      "Steps:  98%|▉| 14675/15000 [1:34:03<00:58,  5.52it/s, lr=8.6e-6, step_loss=0.00107/18/2023 20:37:25 - INFO - __main__ - train loss is 3.4434672482311726\n",
      "Steps:  98%|▉| 14676/15000 [1:34:03<00:58,  5.52it/s, lr=8.6e-6, step_loss=0.80707/18/2023 20:37:25 - INFO - __main__ - train loss is 3.4578761253505945\n",
      "Steps:  98%|▉| 14677/15000 [1:34:03<00:58,  5.52it/s, lr=8.6e-6, step_loss=0.01407/18/2023 20:37:26 - INFO - __main__ - train loss is 3.654217967763543\n",
      "Steps:  98%|▉| 14678/15000 [1:34:03<00:58,  5.52it/s, lr=8.6e-6, step_loss=0.19607/18/2023 20:37:26 - INFO - __main__ - train loss is 3.6582614672370255\n",
      "Steps:  98%|▉| 14679/15000 [1:34:04<00:58,  5.52it/s, lr=8.6e-6, step_loss=0.00407/18/2023 20:37:26 - INFO - __main__ - train loss is 3.665374899748713\n",
      "Steps:  98%|▉| 14680/15000 [1:34:04<00:57,  5.52it/s, lr=8.6e-6, step_loss=0.00707/18/2023 20:37:26 - INFO - __main__ - train loss is 3.9813366481103003\n",
      "Steps:  98%|▉| 14681/15000 [1:34:04<00:57,  5.52it/s, lr=8.6e-6, step_loss=0.31607/18/2023 20:37:26 - INFO - __main__ - train loss is 3.9982767277397215\n",
      "Steps:  98%|▉| 14682/15000 [1:34:04<00:58,  5.48it/s, lr=8.6e-6, step_loss=0.01607/18/2023 20:37:26 - INFO - __main__ - train loss is 4.002197608817369\n",
      "Steps:  98%|▉| 14683/15000 [1:34:04<00:57,  5.49it/s, lr=8.6e-6, step_loss=0.00307/18/2023 20:37:27 - INFO - __main__ - train loss is 4.082317710388452\n",
      "Steps:  98%|▉| 14684/15000 [1:34:05<00:57,  5.50it/s, lr=8.6e-6, step_loss=0.08007/18/2023 20:37:27 - INFO - __main__ - train loss is 4.085072978865355\n",
      "Steps:  98%|▉| 14685/15000 [1:34:05<00:57,  5.51it/s, lr=8.6e-6, step_loss=0.00207/18/2023 20:37:27 - INFO - __main__ - train loss is 4.124729439150542\n",
      "Steps:  98%|▉| 14686/15000 [1:34:05<00:56,  5.51it/s, lr=8.6e-6, step_loss=0.03907/18/2023 20:37:27 - INFO - __main__ - train loss is 4.524392768274993\n",
      "Steps:  98%|█▉| 14687/15000 [1:34:05<00:56,  5.52it/s, lr=8.6e-6, step_loss=0.4]07/18/2023 20:37:27 - INFO - __main__ - train loss is 4.530698856338859\n",
      "Steps:  98%|▉| 14688/15000 [1:34:05<00:56,  5.52it/s, lr=8.6e-6, step_loss=0.00607/18/2023 20:37:28 - INFO - __main__ - train loss is 4.5972495805472136\n",
      "Steps:  98%|▉| 14689/15000 [1:34:05<00:56,  5.53it/s, lr=8.6e-6, step_loss=0.06607/18/2023 20:37:28 - INFO - __main__ - train loss is 4.757707042619586\n",
      "Steps:  98%|▉| 14690/15000 [1:34:06<00:56,  5.53it/s, lr=8.6e-6, step_loss=0.16]07/18/2023 20:37:28 - INFO - __main__ - train loss is 4.967805711552501\n",
      "Steps:  98%|▉| 14691/15000 [1:34:06<00:55,  5.53it/s, lr=8.6e-6, step_loss=0.21]07/18/2023 20:37:28 - INFO - __main__ - train loss is 4.997870028018951\n",
      "Steps:  98%|▉| 14692/15000 [1:34:06<00:55,  5.53it/s, lr=8.6e-6, step_loss=0.03007/18/2023 20:37:28 - INFO - __main__ - train loss is 5.191631779074669\n",
      "Steps:  98%|▉| 14693/15000 [1:34:06<00:55,  5.53it/s, lr=8.6e-6, step_loss=0.19407/18/2023 20:37:28 - INFO - __main__ - train loss is 5.40448534488678\n",
      "Steps:  98%|▉| 14694/15000 [1:34:06<00:55,  5.53it/s, lr=8.6e-6, step_loss=0.21307/18/2023 20:37:29 - INFO - __main__ - train loss is 5.6506242752075195\n",
      "Steps:  98%|▉| 14695/15000 [1:34:07<00:55,  5.53it/s, lr=8.6e-6, step_loss=0.24607/18/2023 20:37:29 - INFO - __main__ - train loss is 5.737593151628971\n",
      "Steps:  98%|▉| 14696/15000 [1:34:07<00:54,  5.53it/s, lr=8.6e-6, step_loss=0.08707/18/2023 20:37:29 - INFO - __main__ - train loss is 5.788475647568703\n",
      "Steps:  98%|▉| 14697/15000 [1:34:07<00:54,  5.53it/s, lr=8.6e-6, step_loss=0.05007/18/2023 20:37:29 - INFO - __main__ - train loss is 5.8040160946547985\n",
      "Steps:  98%|▉| 14698/15000 [1:34:07<00:54,  5.53it/s, lr=8.59e-6, step_loss=0.0107/18/2023 20:37:29 - INFO - __main__ - train loss is 6.217611771076918\n",
      "Steps:  98%|▉| 14699/15000 [1:34:07<00:54,  5.53it/s, lr=8.59e-6, step_loss=0.4107/18/2023 20:37:30 - INFO - __main__ - train loss is 6.241169478744268\n",
      "Steps:  98%|▉| 14700/15000 [1:34:07<00:54,  5.53it/s, lr=8.59e-6, step_loss=0.0207/18/2023 20:37:30 - INFO - __main__ - train loss is 6.249126019887626\n",
      "Steps:  98%|▉| 14701/15000 [1:34:08<00:54,  5.53it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:30 - INFO - __main__ - train loss is 6.267332232557237\n",
      "Steps:  98%|▉| 14702/15000 [1:34:08<00:53,  5.53it/s, lr=8.59e-6, step_loss=0.0107/18/2023 20:37:30 - INFO - __main__ - train loss is 6.282896037213504\n",
      "Steps:  98%|▉| 14703/15000 [1:34:08<00:53,  5.53it/s, lr=8.59e-6, step_loss=0.0107/18/2023 20:37:30 - INFO - __main__ - train loss is 6.641468013636768\n",
      "Steps:  98%|▉| 14704/15000 [1:34:08<00:53,  5.53it/s, lr=8.59e-6, step_loss=0.3507/18/2023 20:37:30 - INFO - __main__ - train loss is 6.720657381229103\n",
      "Steps:  98%|▉| 14705/15000 [1:34:08<00:53,  5.51it/s, lr=8.59e-6, step_loss=0.0707/18/2023 20:37:31 - INFO - __main__ - train loss is 6.764982747845352\n",
      "Steps:  98%|▉| 14706/15000 [1:34:09<00:53,  5.46it/s, lr=8.59e-6, step_loss=0.0407/18/2023 20:37:31 - INFO - __main__ - train loss is 6.767092779278755\n",
      "Steps:  98%|▉| 14707/15000 [1:34:09<00:53,  5.47it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:31 - INFO - __main__ - train loss is 6.772391289938241\n",
      "Steps:  98%|▉| 14708/15000 [1:34:09<00:53,  5.49it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:31 - INFO - __main__ - train loss is 6.852564871776849\n",
      "Steps:  98%|▉| 14709/15000 [1:34:09<00:52,  5.50it/s, lr=8.59e-6, step_loss=0.0807/18/2023 20:37:31 - INFO - __main__ - train loss is 6.962330297101289\n",
      "Steps:  98%|▉| 14710/15000 [1:34:09<00:52,  5.50it/s, lr=8.59e-6, step_loss=0.1107/18/2023 20:37:32 - INFO - __main__ - train loss is 6.968291487079114\n",
      "Steps:  98%|▉| 14711/15000 [1:34:09<00:52,  5.47it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:32 - INFO - __main__ - train loss is 7.404967125039548\n",
      "Steps:  98%|▉| 14712/15000 [1:34:10<00:52,  5.48it/s, lr=8.59e-6, step_loss=0.4307/18/2023 20:37:32 - INFO - __main__ - train loss is 7.606074656825513\n",
      "Steps:  98%|▉| 14713/15000 [1:34:10<00:52,  5.46it/s, lr=8.59e-6, step_loss=0.2007/18/2023 20:37:32 - INFO - __main__ - train loss is 7.961565281730145\n",
      "Steps:  98%|▉| 14714/15000 [1:34:10<00:52,  5.48it/s, lr=8.59e-6, step_loss=0.3507/18/2023 20:37:32 - INFO - __main__ - train loss is 7.9780616867356\n",
      "Steps:  98%|▉| 14715/15000 [1:34:10<00:51,  5.49it/s, lr=8.59e-6, step_loss=0.0107/18/2023 20:37:32 - INFO - __main__ - train loss is 8.12298586545512\n",
      "Steps:  98%|▉| 14716/15000 [1:34:10<00:52,  5.45it/s, lr=8.59e-6, step_loss=0.1407/18/2023 20:37:33 - INFO - __main__ - train loss is 8.692635621409863\n",
      "Steps:  98%|▉| 14717/15000 [1:34:11<00:51,  5.48it/s, lr=8.59e-6, step_loss=0.5707/18/2023 20:37:33 - INFO - __main__ - train loss is 9.32624890981242\n",
      "Steps:  98%|▉| 14718/15000 [1:34:11<00:51,  5.51it/s, lr=8.59e-6, step_loss=0.6307/18/2023 20:37:33 - INFO - __main__ - train loss is 9.838587190490216\n",
      "Steps:  98%|▉| 14719/15000 [1:34:11<00:50,  5.54it/s, lr=8.59e-6, step_loss=0.5107/18/2023 20:37:33 - INFO - __main__ - train loss is 9.869943793397397\n",
      "Steps:  98%|▉| 14720/15000 [1:34:11<00:50,  5.56it/s, lr=8.59e-6, step_loss=0.0307/18/2023 20:37:33 - INFO - __main__ - train loss is 9.878974155988544\n",
      "Steps:  98%|▉| 14721/15000 [1:34:11<00:50,  5.57it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:34 - INFO - __main__ - train loss is 10.368070678319782\n",
      "Steps:  98%|▉| 14722/15000 [1:34:11<00:49,  5.58it/s, lr=8.59e-6, step_loss=0.4807/18/2023 20:37:34 - INFO - __main__ - train loss is 10.45739703765139\n",
      "Steps:  98%|▉| 14723/15000 [1:34:12<00:49,  5.58it/s, lr=8.59e-6, step_loss=0.0807/18/2023 20:37:34 - INFO - __main__ - train loss is 10.46877155220136\n",
      "Steps:  98%|▉| 14724/15000 [1:34:12<00:49,  5.59it/s, lr=8.59e-6, step_loss=0.0107/18/2023 20:37:34 - INFO - __main__ - train loss is 10.58517618989572\n",
      "Steps:  98%|▉| 14725/15000 [1:34:12<00:49,  5.60it/s, lr=8.59e-6, step_loss=0.1107/18/2023 20:37:34 - INFO - __main__ - train loss is 10.85682620620355\n",
      "Steps:  98%|▉| 14726/15000 [1:34:12<00:48,  5.60it/s, lr=8.59e-6, step_loss=0.2707/18/2023 20:37:34 - INFO - __main__ - train loss is 11.449308057781309\n",
      "Steps:  98%|▉| 14727/15000 [1:34:12<00:49,  5.54it/s, lr=8.59e-6, step_loss=0.5907/18/2023 20:37:35 - INFO - __main__ - train loss is 11.479796709027141\n",
      "Steps:  98%|▉| 14728/15000 [1:34:12<00:49,  5.54it/s, lr=8.59e-6, step_loss=0.0307/18/2023 20:37:35 - INFO - __main__ - train loss is 11.507546415086836\n",
      "Steps:  98%|▉| 14729/15000 [1:34:13<00:48,  5.56it/s, lr=8.59e-6, step_loss=0.0207/18/2023 20:37:35 - INFO - __main__ - train loss is 11.763921668287367\n",
      "Steps:  98%|▉| 14730/15000 [1:34:13<00:48,  5.58it/s, lr=8.59e-6, step_loss=0.2507/18/2023 20:37:35 - INFO - __main__ - train loss is 11.868640956934541\n",
      "Steps:  98%|▉| 14731/15000 [1:34:13<00:48,  5.59it/s, lr=8.59e-6, step_loss=0.1007/18/2023 20:37:35 - INFO - __main__ - train loss is 11.995096636470407\n",
      "Steps:  98%|▉| 14732/15000 [1:34:13<00:47,  5.60it/s, lr=8.59e-6, step_loss=0.1207/18/2023 20:37:35 - INFO - __main__ - train loss is 12.018629969563335\n",
      "Steps:  98%|▉| 14733/15000 [1:34:13<00:47,  5.60it/s, lr=8.59e-6, step_loss=0.0207/18/2023 20:37:36 - INFO - __main__ - train loss is 12.021243082825094\n",
      "Steps:  98%|▉| 14734/15000 [1:34:14<00:47,  5.60it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:36 - INFO - __main__ - train loss is 12.0989759885706\n",
      "Steps:  98%|▉| 14735/15000 [1:34:14<00:47,  5.61it/s, lr=8.59e-6, step_loss=0.0707/18/2023 20:37:36 - INFO - __main__ - train loss is 12.102635638788342\n",
      "Steps:  98%|▉| 14736/15000 [1:34:14<00:47,  5.60it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:36 - INFO - __main__ - train loss is 12.105941290268674\n",
      "Steps:  98%|▉| 14737/15000 [1:34:14<00:46,  5.61it/s, lr=8.59e-6, step_loss=0.0007/18/2023 20:37:36 - INFO - __main__ - train loss is 12.256402472266927\n",
      "Steps:  98%|▉| 14738/15000 [1:34:14<00:47,  5.56it/s, lr=8.59e-6, step_loss=0.1507/18/2023 20:37:37 - INFO - __main__ - train loss is 12.457241961965337\n",
      "Steps:  98%|▉| 14739/15000 [1:34:14<00:47,  5.54it/s, lr=8.59e-6, step_loss=0.2007/18/2023 20:37:37 - INFO - __main__ - train loss is 12.484014159301296\n",
      "Steps:  98%|▉| 14740/15000 [1:34:15<00:46,  5.55it/s, lr=8.59e-6, step_loss=0.0207/18/2023 20:37:37 - INFO - __main__ - train loss is 12.90868971333839\n",
      "Steps:  98%|▉| 14741/15000 [1:34:15<00:46,  5.56it/s, lr=8.59e-6, step_loss=0.4207/18/2023 20:37:37 - INFO - __main__ - train loss is 12.961507944623008\n",
      "Steps:  98%|▉| 14742/15000 [1:34:15<00:46,  5.57it/s, lr=8.59e-6, step_loss=0.0507/18/2023 20:37:37 - INFO - __main__ - train loss is 13.332244901219383\n",
      "Steps:  98%|▉| 14743/15000 [1:34:15<00:46,  5.58it/s, lr=8.59e-6, step_loss=0.3707/18/2023 20:37:38 - INFO - __main__ - train loss is 13.867313413182274\n",
      "Steps:  98%|▉| 14744/15000 [1:34:16<01:01,  4.14it/s, lr=8.59e-6, step_loss=0.5307/18/2023 20:37:38 - INFO - __main__ - Per validation step average loss is 0.014956758357584476\n",
      "07/18/2023 20:37:38 - INFO - __main__ - Cumulative validation average loss is 0.014956758357584476\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Per validation step average loss is 0.5409268140792847\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Cumulative validation average loss is 0.5558835724368691\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Per validation step average loss is 0.03674515336751938\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Cumulative validation average loss is 0.5926287258043885\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Per validation step average loss is 0.00751367025077343\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Cumulative validation average loss is 0.600142396055162\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Per validation step average loss is 0.21505478024482727\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Cumulative validation average loss is 0.8151971762999892\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Per validation step average loss is 0.07403126358985901\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Cumulative validation average loss is 0.8892284398898482\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Per validation step average loss is 0.016477007418870926\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Cumulative validation average loss is 0.9057054473087192\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Per validation step average loss is 0.02871784381568432\n",
      "07/18/2023 20:37:39 - INFO - __main__ - Cumulative validation average loss is 0.9344232911244035\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Per validation step average loss is 0.002864395035430789\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Cumulative validation average loss is 0.9372876861598343\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Per validation step average loss is 0.05731361731886864\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Cumulative validation average loss is 0.9946013034787029\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Per validation step average loss is 0.10657784342765808\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Cumulative validation average loss is 1.101179146906361\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Per validation step average loss is 0.0020353489089757204\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Cumulative validation average loss is 1.1032144958153367\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Average validation loss for Epoch 151 is 0.09193454131794472\n",
      "07/18/2023 20:37:40 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:37:53 - INFO - __main__ - Starting epoch 152\n",
      "07/18/2023 20:37:54 - INFO - __main__ - train loss is 0.7897905111312866\n",
      "Steps:  98%|▉| 14745/15000 [1:34:32<21:27,  5.05s/it, lr=8.59e-6, step_loss=0.7907/18/2023 20:37:54 - INFO - __main__ - train loss is 0.8608468323945999\n",
      "Steps:  98%|▉| 14746/15000 [1:34:32<15:11,  3.59s/it, lr=8.59e-6, step_loss=0.0707/18/2023 20:37:54 - INFO - __main__ - train loss is 0.9280013218522072\n",
      "Steps:  98%|▉| 14747/15000 [1:34:32<10:49,  2.57s/it, lr=8.59e-6, step_loss=0.0607/18/2023 20:37:54 - INFO - __main__ - train loss is 1.5288024321198463\n",
      "Steps:  98%|▉| 14748/15000 [1:34:32<07:46,  1.85s/it, lr=8.59e-6, step_loss=0.6007/18/2023 20:37:55 - INFO - __main__ - train loss is 1.600511021912098\n",
      "Steps:  98%|▉| 14749/15000 [1:34:33<05:38,  1.35s/it, lr=8.59e-6, step_loss=0.0707/18/2023 20:37:55 - INFO - __main__ - train loss is 1.6549335643649101\n",
      "Steps:  98%|▉| 14750/15000 [1:34:33<04:09,  1.00it/s, lr=8.59e-6, step_loss=0.0507/18/2023 20:37:55 - INFO - __main__ - train loss is 1.8363272324204445\n",
      "Steps:  98%|▉| 14751/15000 [1:34:33<03:07,  1.32it/s, lr=8.59e-6, step_loss=0.1807/18/2023 20:37:55 - INFO - __main__ - train loss is 2.492458738386631\n",
      "Steps:  98%|▉| 14752/15000 [1:34:33<02:24,  1.72it/s, lr=8.58e-6, step_loss=0.6507/18/2023 20:37:55 - INFO - __main__ - train loss is 2.8685372844338417\n",
      "Steps:  98%|▉| 14753/15000 [1:34:33<01:53,  2.17it/s, lr=8.58e-6, step_loss=0.3707/18/2023 20:37:56 - INFO - __main__ - train loss is 3.144189693033695\n",
      "Steps:  98%|▉| 14754/15000 [1:34:33<01:32,  2.66it/s, lr=8.58e-6, step_loss=0.2707/18/2023 20:37:56 - INFO - __main__ - train loss is 3.646600939333439\n",
      "Steps:  98%|▉| 14755/15000 [1:34:34<01:17,  3.16it/s, lr=8.58e-6, step_loss=0.5007/18/2023 20:37:56 - INFO - __main__ - train loss is 3.7079010754823685\n",
      "Steps:  98%|▉| 14756/15000 [1:34:34<01:07,  3.64it/s, lr=8.58e-6, step_loss=0.0607/18/2023 20:37:56 - INFO - __main__ - train loss is 3.873243510723114\n",
      "Steps:  98%|▉| 14757/15000 [1:34:34<00:59,  4.07it/s, lr=8.58e-6, step_loss=0.1607/18/2023 20:37:56 - INFO - __main__ - train loss is 3.9738202914595604\n",
      "Steps:  98%|▉| 14758/15000 [1:34:34<00:54,  4.44it/s, lr=8.58e-6, step_loss=0.1007/18/2023 20:37:56 - INFO - __main__ - train loss is 4.016776252537966\n",
      "Steps:  98%|▉| 14759/15000 [1:34:34<00:50,  4.73it/s, lr=8.58e-6, step_loss=0.0407/18/2023 20:37:57 - INFO - __main__ - train loss is 4.34328405931592\n",
      "Steps:  98%|▉| 14760/15000 [1:34:35<00:48,  4.97it/s, lr=8.58e-6, step_loss=0.3207/18/2023 20:37:57 - INFO - __main__ - train loss is 4.421322401612997\n",
      "Steps:  98%|▉| 14761/15000 [1:34:35<00:46,  5.15it/s, lr=8.58e-6, step_loss=0.0707/18/2023 20:37:57 - INFO - __main__ - train loss is 4.42320703715086\n",
      "Steps:  98%|▉| 14762/15000 [1:34:35<00:45,  5.27it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:37:57 - INFO - __main__ - train loss is 4.429576050490141\n",
      "Steps:  98%|▉| 14763/15000 [1:34:35<00:44,  5.36it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:37:57 - INFO - __main__ - train loss is 4.602081324905157\n",
      "Steps:  98%|▉| 14764/15000 [1:34:35<00:43,  5.43it/s, lr=8.58e-6, step_loss=0.1707/18/2023 20:37:58 - INFO - __main__ - train loss is 4.719982881098986\n",
      "Steps:  98%|▉| 14765/15000 [1:34:35<00:42,  5.48it/s, lr=8.58e-6, step_loss=0.1107/18/2023 20:37:58 - INFO - __main__ - train loss is 4.738131755962968\n",
      "Steps:  98%|▉| 14766/15000 [1:34:36<00:42,  5.52it/s, lr=8.58e-6, step_loss=0.0107/18/2023 20:37:58 - INFO - __main__ - train loss is 4.747197048738599\n",
      "Steps:  98%|▉| 14767/15000 [1:34:36<00:42,  5.54it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:37:58 - INFO - __main__ - train loss is 5.314204232767224\n",
      "Steps:  98%|▉| 14768/15000 [1:34:36<00:41,  5.56it/s, lr=8.58e-6, step_loss=0.5607/18/2023 20:37:58 - INFO - __main__ - train loss is 5.793205814436078\n",
      "Steps:  98%|▉| 14769/15000 [1:34:36<00:41,  5.57it/s, lr=8.58e-6, step_loss=0.4707/18/2023 20:37:58 - INFO - __main__ - train loss is 5.889873513951898\n",
      "Steps:  98%|▉| 14770/15000 [1:34:36<00:41,  5.58it/s, lr=8.58e-6, step_loss=0.0907/18/2023 20:37:59 - INFO - __main__ - train loss is 6.044459590688348\n",
      "Steps:  98%|▉| 14771/15000 [1:34:36<00:41,  5.55it/s, lr=8.58e-6, step_loss=0.1507/18/2023 20:37:59 - INFO - __main__ - train loss is 6.210267970338464\n",
      "Steps:  98%|▉| 14772/15000 [1:34:37<00:40,  5.57it/s, lr=8.58e-6, step_loss=0.1607/18/2023 20:37:59 - INFO - __main__ - train loss is 6.685428002849221\n",
      "Steps:  98%|▉| 14773/15000 [1:34:37<00:40,  5.58it/s, lr=8.58e-6, step_loss=0.4707/18/2023 20:37:59 - INFO - __main__ - train loss is 6.691113766748458\n",
      "Steps:  98%|▉| 14774/15000 [1:34:37<00:40,  5.58it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:37:59 - INFO - __main__ - train loss is 6.795978878159076\n",
      "Steps:  98%|▉| 14775/15000 [1:34:37<00:40,  5.59it/s, lr=8.58e-6, step_loss=0.1007/18/2023 20:38:00 - INFO - __main__ - train loss is 6.814136427361518\n",
      "Steps:  99%|▉| 14776/15000 [1:34:37<00:40,  5.56it/s, lr=8.58e-6, step_loss=0.0107/18/2023 20:38:00 - INFO - __main__ - train loss is 6.941026222426444\n",
      "Steps:  99%|▉| 14777/15000 [1:34:38<00:40,  5.57it/s, lr=8.58e-6, step_loss=0.1207/18/2023 20:38:00 - INFO - __main__ - train loss is 6.996305432636291\n",
      "Steps:  99%|▉| 14778/15000 [1:34:38<00:39,  5.58it/s, lr=8.58e-6, step_loss=0.0507/18/2023 20:38:00 - INFO - __main__ - train loss is 7.002290619071573\n",
      "Steps:  99%|▉| 14779/15000 [1:34:38<00:39,  5.58it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:00 - INFO - __main__ - train loss is 7.42667077248916\n",
      "Steps:  99%|▉| 14780/15000 [1:34:38<00:39,  5.54it/s, lr=8.58e-6, step_loss=0.4207/18/2023 20:38:00 - INFO - __main__ - train loss is 7.5989109254442155\n",
      "Steps:  99%|▉| 14781/15000 [1:34:38<00:39,  5.55it/s, lr=8.58e-6, step_loss=0.1707/18/2023 20:38:01 - INFO - __main__ - train loss is 7.764336196240038\n",
      "Steps:  99%|▉| 14782/15000 [1:34:38<00:39,  5.57it/s, lr=8.58e-6, step_loss=0.1607/18/2023 20:38:01 - INFO - __main__ - train loss is 7.835352954920381\n",
      "Steps:  99%|▉| 14783/15000 [1:34:39<00:38,  5.57it/s, lr=8.58e-6, step_loss=0.0707/18/2023 20:38:01 - INFO - __main__ - train loss is 7.934679803904146\n",
      "Steps:  99%|▉| 14784/15000 [1:34:39<00:38,  5.58it/s, lr=8.58e-6, step_loss=0.0907/18/2023 20:38:01 - INFO - __main__ - train loss is 7.939036451745778\n",
      "Steps:  99%|▉| 14785/15000 [1:34:39<00:38,  5.59it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:01 - INFO - __main__ - train loss is 7.943519428372383\n",
      "Steps:  99%|▉| 14786/15000 [1:34:39<00:38,  5.59it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:01 - INFO - __main__ - train loss is 7.949155570007861\n",
      "Steps:  99%|▉| 14787/15000 [1:34:39<00:38,  5.59it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:02 - INFO - __main__ - train loss is 8.021497786976397\n",
      "Steps:  99%|▉| 14788/15000 [1:34:40<00:37,  5.60it/s, lr=8.58e-6, step_loss=0.0707/18/2023 20:38:02 - INFO - __main__ - train loss is 8.342349202372134\n",
      "Steps:  99%|▉| 14789/15000 [1:34:40<00:37,  5.60it/s, lr=8.58e-6, step_loss=0.3207/18/2023 20:38:02 - INFO - __main__ - train loss is 8.369839620776474\n",
      "Steps:  99%|▉| 14790/15000 [1:34:40<00:37,  5.60it/s, lr=8.58e-6, step_loss=0.0207/18/2023 20:38:02 - INFO - __main__ - train loss is 8.372299626469612\n",
      "Steps:  99%|▉| 14791/15000 [1:34:40<00:37,  5.60it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:02 - INFO - __main__ - train loss is 8.661664918065071\n",
      "Steps:  99%|▉| 14792/15000 [1:34:40<00:37,  5.60it/s, lr=8.58e-6, step_loss=0.2807/18/2023 20:38:03 - INFO - __main__ - train loss is 8.707505475729704\n",
      "Steps:  99%|▉| 14793/15000 [1:34:40<00:36,  5.60it/s, lr=8.58e-6, step_loss=0.0407/18/2023 20:38:03 - INFO - __main__ - train loss is 8.70970355742611\n",
      "Steps:  99%|▉| 14794/15000 [1:34:41<00:36,  5.60it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:03 - INFO - __main__ - train loss is 8.750249698990956\n",
      "Steps:  99%|▉| 14795/15000 [1:34:41<00:36,  5.60it/s, lr=8.58e-6, step_loss=0.0407/18/2023 20:38:03 - INFO - __main__ - train loss is 8.892157510155812\n",
      "Steps:  99%|▉| 14796/15000 [1:34:41<00:36,  5.60it/s, lr=8.58e-6, step_loss=0.1407/18/2023 20:38:03 - INFO - __main__ - train loss is 9.071228444809094\n",
      "Steps:  99%|▉| 14797/15000 [1:34:41<00:36,  5.60it/s, lr=8.58e-6, step_loss=0.1707/18/2023 20:38:03 - INFO - __main__ - train loss is 9.389200419420376\n",
      "Steps:  99%|▉| 14798/15000 [1:34:41<00:36,  5.60it/s, lr=8.58e-6, step_loss=0.3107/18/2023 20:38:04 - INFO - __main__ - train loss is 9.392374970484525\n",
      "Steps:  99%|▉| 14799/15000 [1:34:42<00:35,  5.60it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:04 - INFO - __main__ - train loss is 9.634850271511823\n",
      "Steps:  99%|▉| 14800/15000 [1:34:42<00:35,  5.60it/s, lr=8.58e-6, step_loss=0.2407/18/2023 20:38:04 - INFO - __main__ - train loss is 9.638154014246538\n",
      "Steps:  99%|▉| 14801/15000 [1:34:42<00:35,  5.60it/s, lr=8.58e-6, step_loss=0.0007/18/2023 20:38:04 - INFO - __main__ - train loss is 9.726558267371729\n",
      "Steps:  99%|▉| 14802/15000 [1:34:42<00:35,  5.60it/s, lr=8.58e-6, step_loss=0.0807/18/2023 20:38:04 - INFO - __main__ - train loss is 9.95275607635267\n",
      "Steps:  99%|▉| 14803/15000 [1:34:42<00:35,  5.59it/s, lr=8.58e-6, step_loss=0.2207/18/2023 20:38:05 - INFO - __main__ - train loss is 10.894740014569834\n",
      "Steps:  99%|▉| 14804/15000 [1:34:42<00:35,  5.59it/s, lr=8.58e-6, step_loss=0.9407/18/2023 20:38:05 - INFO - __main__ - train loss is 11.518495350377634\n",
      "Steps:  99%|▉| 14805/15000 [1:34:43<00:34,  5.58it/s, lr=8.58e-6, step_loss=0.6207/18/2023 20:38:05 - INFO - __main__ - train loss is 11.53316741460003\n",
      "Steps:  99%|▉| 14806/15000 [1:34:43<00:34,  5.58it/s, lr=8.58e-6, step_loss=0.0107/18/2023 20:38:05 - INFO - __main__ - train loss is 11.626519836718217\n",
      "Steps:  99%|▉| 14807/15000 [1:34:43<00:34,  5.57it/s, lr=8.57e-6, step_loss=0.0907/18/2023 20:38:05 - INFO - __main__ - train loss is 11.717253424460068\n",
      "Steps:  99%|▉| 14808/15000 [1:34:43<00:34,  5.57it/s, lr=8.57e-6, step_loss=0.0907/18/2023 20:38:05 - INFO - __main__ - train loss is 11.763229854637757\n",
      "Steps:  99%|▉| 14809/15000 [1:34:43<00:34,  5.56it/s, lr=8.57e-6, step_loss=0.0407/18/2023 20:38:06 - INFO - __main__ - train loss is 12.22513658576645\n",
      "Steps:  99%|▉| 14810/15000 [1:34:43<00:34,  5.57it/s, lr=8.57e-6, step_loss=0.4607/18/2023 20:38:06 - INFO - __main__ - train loss is 12.23635924817063\n",
      "Steps:  99%|▉| 14811/15000 [1:34:44<00:33,  5.57it/s, lr=8.57e-6, step_loss=0.0107/18/2023 20:38:06 - INFO - __main__ - train loss is 12.296481946716085\n",
      "Steps:  99%|▉| 14812/15000 [1:34:44<00:33,  5.57it/s, lr=8.57e-6, step_loss=0.0607/18/2023 20:38:06 - INFO - __main__ - train loss is 12.676206985721365\n",
      "Steps:  99%|▉| 14813/15000 [1:34:44<00:33,  5.58it/s, lr=8.57e-6, step_loss=0.3807/18/2023 20:38:06 - INFO - __main__ - train loss is 12.950398126849905\n",
      "Steps:  99%|▉| 14814/15000 [1:34:44<00:33,  5.59it/s, lr=8.57e-6, step_loss=0.2707/18/2023 20:38:06 - INFO - __main__ - train loss is 12.973748380551115\n",
      "Steps:  99%|▉| 14815/15000 [1:34:44<00:33,  5.58it/s, lr=8.57e-6, step_loss=0.0207/18/2023 20:38:07 - INFO - __main__ - train loss is 13.513617092976347\n",
      "Steps:  99%|▉| 14816/15000 [1:34:45<00:32,  5.59it/s, lr=8.57e-6, step_loss=0.5407/18/2023 20:38:07 - INFO - __main__ - train loss is 13.662584776291624\n",
      "Steps:  99%|▉| 14817/15000 [1:34:45<00:32,  5.59it/s, lr=8.57e-6, step_loss=0.1407/18/2023 20:38:07 - INFO - __main__ - train loss is 13.849058801541105\n",
      "Steps:  99%|▉| 14818/15000 [1:34:45<00:32,  5.60it/s, lr=8.57e-6, step_loss=0.1807/18/2023 20:38:07 - INFO - __main__ - train loss is 13.8792722618673\n",
      "Steps:  99%|▉| 14819/15000 [1:34:45<00:32,  5.60it/s, lr=8.57e-6, step_loss=0.0307/18/2023 20:38:07 - INFO - __main__ - train loss is 14.249666074523702\n",
      "Steps:  99%|▉| 14820/15000 [1:34:45<00:32,  5.60it/s, lr=8.57e-6, step_loss=0.3707/18/2023 20:38:08 - INFO - __main__ - train loss is 14.330273667583242\n",
      "Steps:  99%|▉| 14821/15000 [1:34:45<00:31,  5.60it/s, lr=8.57e-6, step_loss=0.0807/18/2023 20:38:08 - INFO - __main__ - train loss is 14.93599776388146\n",
      "Steps:  99%|▉| 14822/15000 [1:34:46<00:31,  5.60it/s, lr=8.57e-6, step_loss=0.6007/18/2023 20:38:08 - INFO - __main__ - train loss is 14.943276423728094\n",
      "Steps:  99%|▉| 14823/15000 [1:34:46<00:31,  5.60it/s, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:08 - INFO - __main__ - train loss is 14.945300058694556\n",
      "Steps:  99%|▉| 14824/15000 [1:34:46<00:31,  5.60it/s, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:08 - INFO - __main__ - train loss is 15.00576647859998\n",
      "Steps:  99%|▉| 14825/15000 [1:34:46<00:31,  5.60it/s, lr=8.57e-6, step_loss=0.0607/18/2023 20:38:08 - INFO - __main__ - train loss is 15.06440815073438\n",
      "Steps:  99%|▉| 14826/15000 [1:34:46<00:31,  5.61it/s, lr=8.57e-6, step_loss=0.0507/18/2023 20:38:09 - INFO - __main__ - train loss is 15.096259297104552\n",
      "Steps:  99%|▉| 14827/15000 [1:34:47<00:30,  5.61it/s, lr=8.57e-6, step_loss=0.0307/18/2023 20:38:09 - INFO - __main__ - train loss is 15.108625481138006\n",
      "Steps:  99%|▉| 14828/15000 [1:34:47<00:30,  5.61it/s, lr=8.57e-6, step_loss=0.0107/18/2023 20:38:09 - INFO - __main__ - train loss is 15.3606334424112\n",
      "Steps:  99%|▉| 14829/15000 [1:34:47<00:30,  5.61it/s, lr=8.57e-6, step_loss=0.2507/18/2023 20:38:09 - INFO - __main__ - train loss is 16.0024374818895\n",
      "Steps:  99%|▉| 14830/15000 [1:34:47<00:30,  5.61it/s, lr=8.57e-6, step_loss=0.6407/18/2023 20:38:09 - INFO - __main__ - train loss is 16.041722668567672\n",
      "Steps:  99%|▉| 14831/15000 [1:34:47<00:30,  5.61it/s, lr=8.57e-6, step_loss=0.0307/18/2023 20:38:10 - INFO - __main__ - train loss is 16.07982593611814\n",
      "Steps:  99%|▉| 14832/15000 [1:34:47<00:29,  5.61it/s, lr=8.57e-6, step_loss=0.0307/18/2023 20:38:10 - INFO - __main__ - train loss is 16.214777348795906\n",
      "Steps:  99%|▉| 14833/15000 [1:34:48<00:29,  5.61it/s, lr=8.57e-6, step_loss=0.1307/18/2023 20:38:10 - INFO - __main__ - train loss is 16.217511378461495\n",
      "Steps:  99%|▉| 14834/15000 [1:34:48<00:29,  5.61it/s, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:10 - INFO - __main__ - train loss is 16.25488655664958\n",
      "Steps:  99%|▉| 14835/15000 [1:34:48<00:29,  5.61it/s, lr=8.57e-6, step_loss=0.0307/18/2023 20:38:10 - INFO - __main__ - train loss is 16.28586557903327\n",
      "Steps:  99%|▉| 14836/15000 [1:34:48<00:29,  5.61it/s, lr=8.57e-6, step_loss=0.0307/18/2023 20:38:10 - INFO - __main__ - train loss is 16.28963641729206\n",
      "Steps:  99%|▉| 14837/15000 [1:34:48<00:29,  5.61it/s, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:11 - INFO - __main__ - train loss is 16.309199090115726\n",
      "Steps:  99%|▉| 14838/15000 [1:34:48<00:28,  5.61it/s, lr=8.57e-6, step_loss=0.0107/18/2023 20:38:11 - INFO - __main__ - train loss is 16.33125789742917\n",
      "Steps:  99%|▉| 14839/15000 [1:34:49<00:28,  5.61it/s, lr=8.57e-6, step_loss=0.0207/18/2023 20:38:11 - INFO - __main__ - train loss is 16.400469708256423\n",
      "Steps:  99%|▉| 14840/15000 [1:34:49<00:28,  5.61it/s, lr=8.57e-6, step_loss=0.0607/18/2023 20:38:11 - INFO - __main__ - train loss is 16.688342112116516\n",
      "Steps:  99%|▉| 14841/15000 [1:34:49<00:39,  4.04it/s, lr=8.57e-6, step_loss=0.2807/18/2023 20:38:12 - INFO - __main__ - Per validation step average loss is 0.010565685108304024\n",
      "07/18/2023 20:38:12 - INFO - __main__ - Cumulative validation average loss is 0.010565685108304024\n",
      "07/18/2023 20:38:12 - INFO - __main__ - Per validation step average loss is 0.1116238459944725\n",
      "07/18/2023 20:38:12 - INFO - __main__ - Cumulative validation average loss is 0.12218953110277653\n",
      "07/18/2023 20:38:12 - INFO - __main__ - Per validation step average loss is 0.004517874214798212\n",
      "07/18/2023 20:38:12 - INFO - __main__ - Cumulative validation average loss is 0.12670740531757474\n",
      "07/18/2023 20:38:12 - INFO - __main__ - Per validation step average loss is 0.2510128617286682\n",
      "07/18/2023 20:38:12 - INFO - __main__ - Cumulative validation average loss is 0.37772026704624295\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Per validation step average loss is 0.021189594641327858\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Cumulative validation average loss is 0.3989098616875708\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Per validation step average loss is 0.026674732565879822\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Cumulative validation average loss is 0.42558459425345063\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Per validation step average loss is 0.00759324012324214\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Cumulative validation average loss is 0.43317783437669277\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Per validation step average loss is 0.18376336991786957\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Cumulative validation average loss is 0.6169412042945623\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Per validation step average loss is 0.10126101225614548\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Cumulative validation average loss is 0.7182022165507078\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Per validation step average loss is 0.26588064432144165\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Cumulative validation average loss is 0.9840828608721495\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Per validation step average loss is 0.05546549707651138\n",
      "07/18/2023 20:38:13 - INFO - __main__ - Cumulative validation average loss is 1.0395483579486609\n",
      "07/18/2023 20:38:14 - INFO - __main__ - Per validation step average loss is 0.44139763712882996\n",
      "07/18/2023 20:38:14 - INFO - __main__ - Cumulative validation average loss is 1.4809459950774908\n",
      "07/18/2023 20:38:14 - INFO - __main__ - Average validation loss for Epoch 152 is 0.12341216625645757\n",
      "07/18/2023 20:38:14 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:38:27 - INFO - __main__ - Starting epoch 153\n",
      "07/18/2023 20:38:27 - INFO - __main__ - train loss is 0.002224407624453306\n",
      "Steps:  99%|▉| 14842/15000 [1:35:05<12:56,  4.91s/it, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:27 - INFO - __main__ - train loss is 0.024039748590439558\n",
      "Steps:  99%|▉| 14843/15000 [1:35:05<09:08,  3.49s/it, lr=8.57e-6, step_loss=0.0207/18/2023 20:38:28 - INFO - __main__ - train loss is 0.7760167750529945\n",
      "Steps:  99%|▉| 14844/15000 [1:35:05<06:29,  2.50s/it, lr=8.57e-6, step_loss=0.7507/18/2023 20:38:28 - INFO - __main__ - train loss is 1.1892859968356788\n",
      "Steps:  99%|▉| 14845/15000 [1:35:06<04:39,  1.80s/it, lr=8.57e-6, step_loss=0.4107/18/2023 20:38:28 - INFO - __main__ - train loss is 1.2715459796600044\n",
      "Steps:  99%|▉| 14846/15000 [1:35:06<03:22,  1.32s/it, lr=8.57e-6, step_loss=0.0807/18/2023 20:38:28 - INFO - __main__ - train loss is 1.3215668122284114\n",
      "Steps:  99%|▉| 14847/15000 [1:35:06<02:29,  1.03it/s, lr=8.57e-6, step_loss=0.0507/18/2023 20:38:28 - INFO - __main__ - train loss is 1.3458946119062603\n",
      "Steps:  99%|▉| 14848/15000 [1:35:06<01:51,  1.36it/s, lr=8.57e-6, step_loss=0.0207/18/2023 20:38:28 - INFO - __main__ - train loss is 1.347679303959012\n",
      "Steps:  99%|▉| 14849/15000 [1:35:06<01:25,  1.76it/s, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:29 - INFO - __main__ - train loss is 1.3564314041286707\n",
      "Steps:  99%|▉| 14850/15000 [1:35:06<01:07,  2.21it/s, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:29 - INFO - __main__ - train loss is 1.3858273457735777\n",
      "Steps:  99%|▉| 14851/15000 [1:35:07<00:55,  2.70it/s, lr=8.57e-6, step_loss=0.0207/18/2023 20:38:29 - INFO - __main__ - train loss is 1.3919414007104933\n",
      "Steps:  99%|▉| 14852/15000 [1:35:07<00:46,  3.18it/s, lr=8.57e-6, step_loss=0.0007/18/2023 20:38:29 - INFO - __main__ - train loss is 1.4717549704946578\n",
      "Steps:  99%|▉| 14853/15000 [1:35:07<00:40,  3.65it/s, lr=8.57e-6, step_loss=0.0707/18/2023 20:38:29 - INFO - __main__ - train loss is 1.5105276205576956\n",
      "Steps:  99%|▉| 14854/15000 [1:35:07<00:35,  4.08it/s, lr=8.57e-6, step_loss=0.0307/18/2023 20:38:29 - INFO - __main__ - train loss is 1.891408781055361\n",
      "Steps:  99%|▉| 14855/15000 [1:35:07<00:32,  4.41it/s, lr=8.57e-6, step_loss=0.3807/18/2023 20:38:30 - INFO - __main__ - train loss is 2.0028562643565238\n",
      "Steps:  99%|▉| 14856/15000 [1:35:08<00:30,  4.65it/s, lr=8.57e-6, step_loss=0.1107/18/2023 20:38:30 - INFO - __main__ - train loss is 2.090200746897608\n",
      "Steps:  99%|▉| 14857/15000 [1:35:08<00:29,  4.88it/s, lr=8.57e-6, step_loss=0.0807/18/2023 20:38:30 - INFO - __main__ - train loss is 2.3645909377373755\n",
      "Steps:  99%|▉| 14858/15000 [1:35:08<00:28,  5.05it/s, lr=8.57e-6, step_loss=0.2707/18/2023 20:38:30 - INFO - __main__ - train loss is 2.4107229658402503\n",
      "Steps:  99%|▉| 14859/15000 [1:35:08<00:27,  5.18it/s, lr=8.57e-6, step_loss=0.0407/18/2023 20:38:30 - INFO - __main__ - train loss is 2.476856427732855\n",
      "Steps:  99%|▉| 14860/15000 [1:35:08<00:26,  5.26it/s, lr=8.57e-6, step_loss=0.0607/18/2023 20:38:31 - INFO - __main__ - train loss is 2.542259978596121\n",
      "Steps:  99%|▉| 14861/15000 [1:35:08<00:26,  5.31it/s, lr=8.57e-6, step_loss=0.0607/18/2023 20:38:31 - INFO - __main__ - train loss is 2.864322977606207\n",
      "Steps:  99%|▉| 14862/15000 [1:35:09<00:25,  5.37it/s, lr=8.56e-6, step_loss=0.3207/18/2023 20:38:31 - INFO - __main__ - train loss is 3.0217763655819\n",
      "Steps:  99%|▉| 14863/15000 [1:35:09<00:25,  5.43it/s, lr=8.56e-6, step_loss=0.1507/18/2023 20:38:31 - INFO - __main__ - train loss is 3.082878774497658\n",
      "Steps:  99%|▉| 14864/15000 [1:35:09<00:24,  5.48it/s, lr=8.56e-6, step_loss=0.0607/18/2023 20:38:31 - INFO - __main__ - train loss is 3.1326823220588267\n",
      "Steps:  99%|▉| 14865/15000 [1:35:09<00:24,  5.51it/s, lr=8.56e-6, step_loss=0.0407/18/2023 20:38:31 - INFO - __main__ - train loss is 3.472447066102177\n",
      "Steps:  99%|▉| 14866/15000 [1:35:09<00:24,  5.49it/s, lr=8.56e-6, step_loss=0.3407/18/2023 20:38:32 - INFO - __main__ - train loss is 3.612845851574093\n",
      "Steps:  99%|▉| 14867/15000 [1:35:10<00:24,  5.49it/s, lr=8.56e-6, step_loss=0.1407/18/2023 20:38:32 - INFO - __main__ - train loss is 3.640447518322617\n",
      "Steps:  99%|▉| 14868/15000 [1:35:10<00:24,  5.50it/s, lr=8.56e-6, step_loss=0.0207/18/2023 20:38:32 - INFO - __main__ - train loss is 3.9387068361975253\n",
      "Steps:  99%|▉| 14869/15000 [1:35:10<00:23,  5.49it/s, lr=8.56e-6, step_loss=0.2907/18/2023 20:38:32 - INFO - __main__ - train loss is 3.953669039066881\n",
      "Steps:  99%|▉| 14870/15000 [1:35:10<00:23,  5.50it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:32 - INFO - __main__ - train loss is 3.956146019510925\n",
      "Steps:  99%|▉| 14871/15000 [1:35:10<00:23,  5.49it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:33 - INFO - __main__ - train loss is 4.0822942731902\n",
      "Steps:  99%|▉| 14872/15000 [1:35:10<00:23,  5.49it/s, lr=8.56e-6, step_loss=0.1207/18/2023 20:38:33 - INFO - __main__ - train loss is 4.095128540880978\n",
      "Steps:  99%|▉| 14873/15000 [1:35:11<00:23,  5.50it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:33 - INFO - __main__ - train loss is 4.14567565638572\n",
      "Steps:  99%|▉| 14874/15000 [1:35:11<00:22,  5.51it/s, lr=8.56e-6, step_loss=0.0507/18/2023 20:38:33 - INFO - __main__ - train loss is 4.489028808660805\n",
      "Steps:  99%|▉| 14875/15000 [1:35:11<00:22,  5.53it/s, lr=8.56e-6, step_loss=0.3407/18/2023 20:38:33 - INFO - __main__ - train loss is 4.510126515291631\n",
      "Steps:  99%|▉| 14876/15000 [1:35:11<00:22,  5.55it/s, lr=8.56e-6, step_loss=0.0207/18/2023 20:38:33 - INFO - __main__ - train loss is 4.576285093091428\n",
      "Steps:  99%|▉| 14877/15000 [1:35:11<00:22,  5.53it/s, lr=8.56e-6, step_loss=0.0607/18/2023 20:38:34 - INFO - __main__ - train loss is 5.205042391084135\n",
      "Steps:  99%|▉| 14878/15000 [1:35:12<00:21,  5.55it/s, lr=8.56e-6, step_loss=0.6207/18/2023 20:38:34 - INFO - __main__ - train loss is 5.270982406102121\n",
      "Steps:  99%|▉| 14879/15000 [1:35:12<00:21,  5.56it/s, lr=8.56e-6, step_loss=0.0607/18/2023 20:38:34 - INFO - __main__ - train loss is 5.343754938803613\n",
      "Steps:  99%|▉| 14880/15000 [1:35:12<00:21,  5.57it/s, lr=8.56e-6, step_loss=0.0707/18/2023 20:38:34 - INFO - __main__ - train loss is 5.542633048258722\n",
      "Steps:  99%|▉| 14881/15000 [1:35:12<00:21,  5.57it/s, lr=8.56e-6, step_loss=0.1907/18/2023 20:38:34 - INFO - __main__ - train loss is 5.659008166752756\n",
      "Steps:  99%|▉| 14882/15000 [1:35:12<00:21,  5.58it/s, lr=8.56e-6, step_loss=0.1107/18/2023 20:38:35 - INFO - __main__ - train loss is 5.674407138489187\n",
      "Steps:  99%|▉| 14883/15000 [1:35:12<00:20,  5.58it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:35 - INFO - __main__ - train loss is 6.482618703506887\n",
      "Steps:  99%|▉| 14884/15000 [1:35:13<00:20,  5.58it/s, lr=8.56e-6, step_loss=0.8007/18/2023 20:38:35 - INFO - __main__ - train loss is 6.4890005104243755\n",
      "Steps:  99%|▉| 14885/15000 [1:35:13<00:20,  5.54it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:35 - INFO - __main__ - train loss is 6.497899158857763\n",
      "Steps:  99%|▉| 14886/15000 [1:35:13<00:20,  5.52it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:35 - INFO - __main__ - train loss is 6.668516202829778\n",
      "Steps:  99%|▉| 14887/15000 [1:35:13<00:20,  5.49it/s, lr=8.56e-6, step_loss=0.1707/18/2023 20:38:35 - INFO - __main__ - train loss is 6.720301031135023\n",
      "Steps:  99%|▉| 14888/15000 [1:35:13<00:20,  5.49it/s, lr=8.56e-6, step_loss=0.0507/18/2023 20:38:36 - INFO - __main__ - train loss is 6.924719481728971\n",
      "Steps:  99%|▉| 14889/15000 [1:35:14<00:20,  5.47it/s, lr=8.56e-6, step_loss=0.2007/18/2023 20:38:36 - INFO - __main__ - train loss is 7.0807203790172935\n",
      "Steps:  99%|▉| 14890/15000 [1:35:14<00:20,  5.46it/s, lr=8.56e-6, step_loss=0.1507/18/2023 20:38:36 - INFO - __main__ - train loss is 7.227424337528646\n",
      "Steps:  99%|▉| 14891/15000 [1:35:14<00:19,  5.47it/s, lr=8.56e-6, step_loss=0.1407/18/2023 20:38:36 - INFO - __main__ - train loss is 7.240137876011431\n",
      "Steps:  99%|▉| 14892/15000 [1:35:14<00:19,  5.51it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:36 - INFO - __main__ - train loss is 7.346214608289301\n",
      "Steps:  99%|▉| 14893/15000 [1:35:14<00:19,  5.53it/s, lr=8.56e-6, step_loss=0.1007/18/2023 20:38:37 - INFO - __main__ - train loss is 7.424326696433127\n",
      "Steps:  99%|▉| 14894/15000 [1:35:14<00:19,  5.51it/s, lr=8.56e-6, step_loss=0.0707/18/2023 20:38:37 - INFO - __main__ - train loss is 7.443837041966617\n",
      "Steps:  99%|▉| 14895/15000 [1:35:15<00:19,  5.48it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:37 - INFO - __main__ - train loss is 7.735761250369251\n",
      "Steps:  99%|▉| 14896/15000 [1:35:15<00:18,  5.50it/s, lr=8.56e-6, step_loss=0.2907/18/2023 20:38:37 - INFO - __main__ - train loss is 7.755183753557503\n",
      "Steps:  99%|▉| 14897/15000 [1:35:15<00:18,  5.53it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:37 - INFO - __main__ - train loss is 8.100422230549157\n",
      "Steps:  99%|▉| 14898/15000 [1:35:15<00:18,  5.55it/s, lr=8.56e-6, step_loss=0.3407/18/2023 20:38:37 - INFO - __main__ - train loss is 8.113728460855782\n",
      "Steps:  99%|▉| 14899/15000 [1:35:15<00:18,  5.56it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:38 - INFO - __main__ - train loss is 8.147556689567864\n",
      "Steps:  99%|▉| 14900/15000 [1:35:16<00:17,  5.58it/s, lr=8.56e-6, step_loss=0.0307/18/2023 20:38:38 - INFO - __main__ - train loss is 8.149985248688608\n",
      "Steps:  99%|▉| 14901/15000 [1:35:16<00:17,  5.58it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:38 - INFO - __main__ - train loss is 8.573016966227442\n",
      "Steps:  99%|▉| 14902/15000 [1:35:16<00:17,  5.58it/s, lr=8.56e-6, step_loss=0.4207/18/2023 20:38:38 - INFO - __main__ - train loss is 8.644455457571894\n",
      "Steps:  99%|▉| 14903/15000 [1:35:16<00:17,  5.58it/s, lr=8.56e-6, step_loss=0.0707/18/2023 20:38:38 - INFO - __main__ - train loss is 8.648270695004612\n",
      "Steps:  99%|▉| 14904/15000 [1:35:16<00:17,  5.59it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:39 - INFO - __main__ - train loss is 8.824125824961811\n",
      "Steps:  99%|▉| 14905/15000 [1:35:16<00:16,  5.59it/s, lr=8.56e-6, step_loss=0.1707/18/2023 20:38:39 - INFO - __main__ - train loss is 8.833540525753051\n",
      "Steps:  99%|▉| 14906/15000 [1:35:17<00:16,  5.59it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:39 - INFO - __main__ - train loss is 8.83580076158978\n",
      "Steps:  99%|▉| 14907/15000 [1:35:17<00:16,  5.60it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:39 - INFO - __main__ - train loss is 8.839669281151146\n",
      "Steps:  99%|▉| 14908/15000 [1:35:17<00:16,  5.59it/s, lr=8.56e-6, step_loss=0.0007/18/2023 20:38:39 - INFO - __main__ - train loss is 9.20206713071093\n",
      "Steps:  99%|▉| 14909/15000 [1:35:17<00:16,  5.59it/s, lr=8.56e-6, step_loss=0.3607/18/2023 20:38:39 - INFO - __main__ - train loss is 9.732851856853813\n",
      "Steps:  99%|▉| 14910/15000 [1:35:17<00:16,  5.59it/s, lr=8.56e-6, step_loss=0.5307/18/2023 20:38:40 - INFO - __main__ - train loss is 9.74394803820178\n",
      "Steps:  99%|▉| 14911/15000 [1:35:17<00:15,  5.59it/s, lr=8.56e-6, step_loss=0.0107/18/2023 20:38:40 - INFO - __main__ - train loss is 9.78023338643834\n",
      "Steps:  99%|▉| 14912/15000 [1:35:18<00:15,  5.59it/s, lr=8.56e-6, step_loss=0.0307/18/2023 20:38:40 - INFO - __main__ - train loss is 9.872891272883862\n",
      "Steps:  99%|▉| 14913/15000 [1:35:18<00:15,  5.59it/s, lr=8.56e-6, step_loss=0.0907/18/2023 20:38:40 - INFO - __main__ - train loss is 10.254125382285565\n",
      "Steps:  99%|▉| 14914/15000 [1:35:18<00:15,  5.59it/s, lr=8.56e-6, step_loss=0.3807/18/2023 20:38:40 - INFO - __main__ - train loss is 10.99813624797389\n",
      "Steps:  99%|▉| 14915/15000 [1:35:18<00:15,  5.58it/s, lr=8.56e-6, step_loss=0.7407/18/2023 20:38:41 - INFO - __main__ - train loss is 11.446947779040784\n",
      "Steps:  99%|▉| 14916/15000 [1:35:18<00:15,  5.58it/s, lr=8.55e-6, step_loss=0.4407/18/2023 20:38:41 - INFO - __main__ - train loss is 11.451818104833364\n",
      "Steps:  99%|▉| 14917/15000 [1:35:19<00:15,  5.53it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:38:41 - INFO - __main__ - train loss is 11.45546954846941\n",
      "Steps:  99%|▉| 14918/15000 [1:35:19<00:14,  5.53it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:38:41 - INFO - __main__ - train loss is 11.600417583948001\n",
      "Steps:  99%|▉| 14919/15000 [1:35:19<00:14,  5.55it/s, lr=8.55e-6, step_loss=0.1407/18/2023 20:38:41 - INFO - __main__ - train loss is 11.950958549743518\n",
      "Steps:  99%|▉| 14920/15000 [1:35:19<00:14,  5.56it/s, lr=8.55e-6, step_loss=0.3507/18/2023 20:38:41 - INFO - __main__ - train loss is 12.28299045539461\n",
      "Steps:  99%|▉| 14921/15000 [1:35:19<00:14,  5.57it/s, lr=8.55e-6, step_loss=0.3307/18/2023 20:38:42 - INFO - __main__ - train loss is 12.35816954053007\n",
      "Steps:  99%|▉| 14922/15000 [1:35:19<00:13,  5.58it/s, lr=8.55e-6, step_loss=0.0707/18/2023 20:38:42 - INFO - __main__ - train loss is 12.360226553399116\n",
      "Steps:  99%|▉| 14923/15000 [1:35:20<00:13,  5.55it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:38:42 - INFO - __main__ - train loss is 12.370587101671845\n",
      "Steps:  99%|▉| 14924/15000 [1:35:20<00:13,  5.54it/s, lr=8.55e-6, step_loss=0.0107/18/2023 20:38:42 - INFO - __main__ - train loss is 12.449632948730141\n",
      "Steps: 100%|▉| 14925/15000 [1:35:20<00:13,  5.48it/s, lr=8.55e-6, step_loss=0.0707/18/2023 20:38:42 - INFO - __main__ - train loss is 12.54636279353872\n",
      "Steps: 100%|▉| 14926/15000 [1:35:20<00:13,  5.46it/s, lr=8.55e-6, step_loss=0.0907/18/2023 20:38:43 - INFO - __main__ - train loss is 13.09587267646566\n",
      "Steps: 100%|▉| 14927/15000 [1:35:20<00:13,  5.41it/s, lr=8.55e-6, step_loss=0.5507/18/2023 20:38:43 - INFO - __main__ - train loss is 13.101084395311773\n",
      "Steps: 100%|▉| 14928/15000 [1:35:21<00:13,  5.31it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:38:43 - INFO - __main__ - train loss is 13.113115891814232\n",
      "Steps: 100%|▉| 14929/15000 [1:35:21<00:13,  5.24it/s, lr=8.55e-6, step_loss=0.0107/18/2023 20:38:43 - INFO - __main__ - train loss is 13.139916229993105\n",
      "Steps: 100%|▉| 14930/15000 [1:35:21<00:13,  5.20it/s, lr=8.55e-6, step_loss=0.0207/18/2023 20:38:43 - INFO - __main__ - train loss is 13.14192428579554\n",
      "Steps: 100%|▉| 14931/15000 [1:35:21<00:13,  5.16it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:38:43 - INFO - __main__ - train loss is 13.167958562728018\n",
      "Steps: 100%|▉| 14932/15000 [1:35:21<00:13,  5.15it/s, lr=8.55e-6, step_loss=0.0207/18/2023 20:38:44 - INFO - __main__ - train loss is 13.17097158334218\n",
      "Steps: 100%|▉| 14933/15000 [1:35:22<00:13,  5.14it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:38:44 - INFO - __main__ - train loss is 13.26334836683236\n",
      "Steps: 100%|▉| 14934/15000 [1:35:22<00:12,  5.15it/s, lr=8.55e-6, step_loss=0.0907/18/2023 20:38:44 - INFO - __main__ - train loss is 13.326171960448846\n",
      "Steps: 100%|▉| 14935/15000 [1:35:22<00:12,  5.15it/s, lr=8.55e-6, step_loss=0.0607/18/2023 20:38:44 - INFO - __main__ - train loss is 13.329040392069146\n",
      "Steps: 100%|▉| 14936/15000 [1:35:22<00:12,  5.15it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:38:44 - INFO - __main__ - train loss is 13.637204869417474\n",
      "Steps: 100%|▉| 14937/15000 [1:35:22<00:12,  5.15it/s, lr=8.55e-6, step_loss=0.3007/18/2023 20:38:45 - INFO - __main__ - train loss is 13.684519982663915\n",
      "Steps: 100%|▉| 14938/15000 [1:35:23<00:16,  3.73it/s, lr=8.55e-6, step_loss=0.0407/18/2023 20:38:46 - INFO - __main__ - Per validation step average loss is 0.4710620641708374\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Cumulative validation average loss is 0.4710620641708374\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Per validation step average loss is 0.12072864174842834\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Cumulative validation average loss is 0.5917907059192657\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Per validation step average loss is 0.08986809849739075\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Cumulative validation average loss is 0.6816588044166565\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Per validation step average loss is 0.007188425865024328\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Cumulative validation average loss is 0.6888472302816808\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Per validation step average loss is 0.12264754623174667\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Cumulative validation average loss is 0.8114947765134275\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Per validation step average loss is 0.10693971812725067\n",
      "07/18/2023 20:38:46 - INFO - __main__ - Cumulative validation average loss is 0.9184344946406782\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Per validation step average loss is 0.033513084053993225\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Cumulative validation average loss is 0.9519475786946714\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Per validation step average loss is 0.14511363208293915\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Cumulative validation average loss is 1.0970612107776105\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Per validation step average loss is 0.8255954384803772\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Cumulative validation average loss is 1.9226566492579877\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Per validation step average loss is 0.023905649781227112\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Cumulative validation average loss is 1.9465622990392148\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Per validation step average loss is 0.03730250895023346\n",
      "07/18/2023 20:38:47 - INFO - __main__ - Cumulative validation average loss is 1.9838648079894483\n",
      "07/18/2023 20:38:48 - INFO - __main__ - Per validation step average loss is 0.04825276881456375\n",
      "07/18/2023 20:38:48 - INFO - __main__ - Cumulative validation average loss is 2.032117576804012\n",
      "07/18/2023 20:38:48 - INFO - __main__ - Average validation loss for Epoch 153 is 0.16934313140033433\n",
      "07/18/2023 20:38:48 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/18/2023 20:39:00 - INFO - __main__ - Starting epoch 154\n",
      "07/18/2023 20:39:01 - INFO - __main__ - train loss is 0.05456791818141937\n",
      "Steps: 100%|▉| 14939/15000 [1:35:39<05:06,  5.02s/it, lr=8.55e-6, step_loss=0.0507/18/2023 20:39:01 - INFO - __main__ - train loss is 0.11233465373516083\n",
      "Steps: 100%|▉| 14940/15000 [1:35:39<03:34,  3.57s/it, lr=8.55e-6, step_loss=0.0507/18/2023 20:39:01 - INFO - __main__ - train loss is 0.28679490089416504\n",
      "Steps: 100%|▉| 14941/15000 [1:35:39<02:30,  2.55s/it, lr=8.55e-6, step_loss=0.1707/18/2023 20:39:02 - INFO - __main__ - train loss is 0.30220902897417545\n",
      "Steps: 100%|▉| 14942/15000 [1:35:39<01:46,  1.84s/it, lr=8.55e-6, step_loss=0.0107/18/2023 20:39:02 - INFO - __main__ - train loss is 0.47937258519232273\n",
      "Steps: 100%|▉| 14943/15000 [1:35:40<01:16,  1.34s/it, lr=8.55e-6, step_loss=0.1707/18/2023 20:39:02 - INFO - __main__ - train loss is 0.4857338257133961\n",
      "Steps: 100%|▉| 14944/15000 [1:35:40<00:55,  1.01it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:02 - INFO - __main__ - train loss is 0.8652544505894184\n",
      "Steps: 100%|▉| 14945/15000 [1:35:40<00:41,  1.33it/s, lr=8.55e-6, step_loss=0.3807/18/2023 20:39:02 - INFO - __main__ - train loss is 0.9320368431508541\n",
      "Steps: 100%|▉| 14946/15000 [1:35:40<00:31,  1.73it/s, lr=8.55e-6, step_loss=0.0607/18/2023 20:39:02 - INFO - __main__ - train loss is 1.3189572654664516\n",
      "Steps: 100%|▉| 14947/15000 [1:35:40<00:24,  2.18it/s, lr=8.55e-6, step_loss=0.3807/18/2023 20:39:03 - INFO - __main__ - train loss is 1.3231890453025699\n",
      "Steps: 100%|▉| 14948/15000 [1:35:41<00:19,  2.67it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:03 - INFO - __main__ - train loss is 1.7357923639938235\n",
      "Steps: 100%|▉| 14949/15000 [1:35:41<00:16,  3.16it/s, lr=8.55e-6, step_loss=0.4107/18/2023 20:39:03 - INFO - __main__ - train loss is 1.8900855286046863\n",
      "Steps: 100%|▉| 14950/15000 [1:35:41<00:13,  3.64it/s, lr=8.55e-6, step_loss=0.1507/18/2023 20:39:03 - INFO - __main__ - train loss is 1.8985667461529374\n",
      "Steps: 100%|▉| 14951/15000 [1:35:41<00:12,  4.07it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:03 - INFO - __main__ - train loss is 2.2564673060551286\n",
      "Steps: 100%|▉| 14952/15000 [1:35:41<00:10,  4.44it/s, lr=8.55e-6, step_loss=0.3507/18/2023 20:39:04 - INFO - __main__ - train loss is 2.534644448198378\n",
      "Steps: 100%|▉| 14953/15000 [1:35:41<00:09,  4.73it/s, lr=8.55e-6, step_loss=0.2707/18/2023 20:39:04 - INFO - __main__ - train loss is 2.541772712022066\n",
      "Steps: 100%|▉| 14954/15000 [1:35:42<00:09,  4.97it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:04 - INFO - __main__ - train loss is 3.0117576010525227\n",
      "Steps: 100%|▉| 14955/15000 [1:35:42<00:08,  5.15it/s, lr=8.55e-6, step_loss=0.4707/18/2023 20:39:04 - INFO - __main__ - train loss is 3.02936589717865\n",
      "Steps: 100%|▉| 14956/15000 [1:35:42<00:08,  5.27it/s, lr=8.55e-6, step_loss=0.0107/18/2023 20:39:04 - INFO - __main__ - train loss is 3.0778737999498844\n",
      "Steps: 100%|▉| 14957/15000 [1:35:42<00:08,  5.37it/s, lr=8.55e-6, step_loss=0.0407/18/2023 20:39:04 - INFO - __main__ - train loss is 3.081044882303104\n",
      "Steps: 100%|▉| 14958/15000 [1:35:42<00:07,  5.44it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:05 - INFO - __main__ - train loss is 3.08918394590728\n",
      "Steps: 100%|▉| 14959/15000 [1:35:42<00:07,  5.49it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:05 - INFO - __main__ - train loss is 3.2267679020296782\n",
      "Steps: 100%|▉| 14960/15000 [1:35:43<00:07,  5.52it/s, lr=8.55e-6, step_loss=0.1307/18/2023 20:39:05 - INFO - __main__ - train loss is 3.232673899969086\n",
      "Steps: 100%|▉| 14961/15000 [1:35:43<00:07,  5.54it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:05 - INFO - __main__ - train loss is 3.848360793432221\n",
      "Steps: 100%|▉| 14962/15000 [1:35:43<00:06,  5.56it/s, lr=8.55e-6, step_loss=0.6107/18/2023 20:39:05 - INFO - __main__ - train loss is 3.853915665531531\n",
      "Steps: 100%|▉| 14963/15000 [1:35:43<00:06,  5.57it/s, lr=8.55e-6, step_loss=0.0007/18/2023 20:39:05 - INFO - __main__ - train loss is 3.9597582335118204\n",
      "Steps: 100%|▉| 14964/15000 [1:35:43<00:06,  5.58it/s, lr=8.55e-6, step_loss=0.1007/18/2023 20:39:06 - INFO - __main__ - train loss is 4.338576864684001\n",
      "Steps: 100%|▉| 14965/15000 [1:35:44<00:06,  5.59it/s, lr=8.55e-6, step_loss=0.3707/18/2023 20:39:06 - INFO - __main__ - train loss is 4.400354247773066\n",
      "Steps: 100%|▉| 14966/15000 [1:35:44<00:06,  5.59it/s, lr=8.55e-6, step_loss=0.0607/18/2023 20:39:06 - INFO - __main__ - train loss is 4.641379293287173\n",
      "Steps: 100%|▉| 14967/15000 [1:35:44<00:05,  5.59it/s, lr=8.55e-6, step_loss=0.2407/18/2023 20:39:06 - INFO - __main__ - train loss is 5.146194037282839\n",
      "Steps: 100%|▉| 14968/15000 [1:35:44<00:05,  5.59it/s, lr=8.55e-6, step_loss=0.5007/18/2023 20:39:06 - INFO - __main__ - train loss is 5.332346212351695\n",
      "Steps: 100%|▉| 14969/15000 [1:35:44<00:05,  5.60it/s, lr=8.55e-6, step_loss=0.1807/18/2023 20:39:07 - INFO - __main__ - train loss is 5.346105087781325\n",
      "Steps: 100%|▉| 14970/15000 [1:35:44<00:05,  5.60it/s, lr=8.54e-6, step_loss=0.0107/18/2023 20:39:07 - INFO - __main__ - train loss is 5.353176818462089\n",
      "Steps: 100%|▉| 14971/15000 [1:35:45<00:05,  5.60it/s, lr=8.54e-6, step_loss=0.0007/18/2023 20:39:07 - INFO - __main__ - train loss is 5.556379691930488\n",
      "Steps: 100%|▉| 14972/15000 [1:35:45<00:05,  5.60it/s, lr=8.54e-6, step_loss=0.2007/18/2023 20:39:07 - INFO - __main__ - train loss is 5.5633783338125795\n",
      "Steps: 100%|▉| 14973/15000 [1:35:45<00:04,  5.60it/s, lr=8.54e-6, step_loss=0.0007/18/2023 20:39:07 - INFO - __main__ - train loss is 6.177915394073352\n",
      "Steps: 100%|▉| 14974/15000 [1:35:45<00:04,  5.59it/s, lr=8.54e-6, step_loss=0.6107/18/2023 20:39:07 - INFO - __main__ - train loss is 6.305510461097583\n",
      "Steps: 100%|▉| 14975/15000 [1:35:45<00:04,  5.59it/s, lr=8.54e-6, step_loss=0.1207/18/2023 20:39:08 - INFO - __main__ - train loss is 6.357205342268571\n",
      "Steps: 100%|▉| 14976/15000 [1:35:46<00:04,  5.59it/s, lr=8.54e-6, step_loss=0.0507/18/2023 20:39:08 - INFO - __main__ - train loss is 6.447822335874662\n",
      "Steps: 100%|▉| 14977/15000 [1:35:46<00:04,  5.59it/s, lr=8.54e-6, step_loss=0.0907/18/2023 20:39:08 - INFO - __main__ - train loss is 6.596176881110296\n",
      "Steps: 100%|▉| 14978/15000 [1:35:46<00:03,  5.59it/s, lr=8.54e-6, step_loss=0.1407/18/2023 20:39:08 - INFO - __main__ - train loss is 6.606110345339403\n",
      "Steps: 100%|▉| 14979/15000 [1:35:46<00:03,  5.59it/s, lr=8.54e-6, step_loss=0.0007/18/2023 20:39:08 - INFO - __main__ - train loss is 6.615084221353754\n",
      "Steps: 100%|▉| 14980/15000 [1:35:46<00:03,  5.59it/s, lr=8.54e-6, step_loss=0.0007/18/2023 20:39:09 - INFO - __main__ - train loss is 6.617253224598244\n",
      "Steps: 100%|▉| 14981/15000 [1:35:46<00:03,  5.59it/s, lr=8.54e-6, step_loss=0.0007/18/2023 20:39:09 - INFO - __main__ - train loss is 6.741309414850548\n",
      "Steps: 100%|▉| 14982/15000 [1:35:47<00:03,  5.60it/s, lr=8.54e-6, step_loss=0.1207/18/2023 20:39:09 - INFO - __main__ - train loss is 7.106738309608772\n",
      "Steps: 100%|▉| 14983/15000 [1:35:47<00:03,  5.60it/s, lr=8.54e-6, step_loss=0.3607/18/2023 20:39:09 - INFO - __main__ - train loss is 7.485827188240364\n",
      "Steps: 100%|▉| 14984/15000 [1:35:47<00:02,  5.60it/s, lr=8.54e-6, step_loss=0.3707/18/2023 20:39:09 - INFO - __main__ - train loss is 7.796288113342598\n",
      "Steps: 100%|▉| 14985/15000 [1:35:47<00:02,  5.59it/s, lr=8.54e-6, step_loss=0.3107/18/2023 20:39:09 - INFO - __main__ - train loss is 7.864925707923248\n",
      "Steps: 100%|▉| 14986/15000 [1:35:47<00:02,  5.59it/s, lr=8.54e-6, step_loss=0.0607/18/2023 20:39:10 - INFO - __main__ - train loss is 8.083314622985199\n",
      "Steps: 100%|▉| 14987/15000 [1:35:47<00:02,  5.59it/s, lr=8.54e-6, step_loss=0.2107/18/2023 20:39:10 - INFO - __main__ - train loss is 8.205111804651096\n",
      "Steps: 100%|▉| 14988/15000 [1:35:48<00:02,  5.59it/s, lr=8.54e-6, step_loss=0.1207/18/2023 20:39:10 - INFO - __main__ - train loss is 8.218623736174777\n",
      "Steps: 100%|▉| 14989/15000 [1:35:48<00:01,  5.59it/s, lr=8.54e-6, step_loss=0.0107/18/2023 20:39:10 - INFO - __main__ - train loss is 8.406048366101459\n",
      "Steps: 100%|▉| 14990/15000 [1:35:48<00:01,  5.56it/s, lr=8.54e-6, step_loss=0.1807/18/2023 20:39:10 - INFO - __main__ - train loss is 8.515148633392528\n",
      "Steps: 100%|▉| 14991/15000 [1:35:48<00:01,  5.52it/s, lr=8.54e-6, step_loss=0.1007/18/2023 20:39:11 - INFO - __main__ - train loss is 8.600640260847285\n",
      "Steps: 100%|▉| 14992/15000 [1:35:48<00:01,  5.55it/s, lr=8.54e-6, step_loss=0.0807/18/2023 20:39:11 - INFO - __main__ - train loss is 9.158622049959376\n",
      "Steps: 100%|▉| 14993/15000 [1:35:49<00:01,  5.56it/s, lr=8.54e-6, step_loss=0.5507/18/2023 20:39:11 - INFO - __main__ - train loss is 9.272772246273234\n",
      "Steps: 100%|▉| 14994/15000 [1:35:49<00:01,  5.57it/s, lr=8.54e-6, step_loss=0.1107/18/2023 20:39:11 - INFO - __main__ - train loss is 9.279216511407867\n",
      "Steps: 100%|▉| 14995/15000 [1:35:49<00:00,  5.50it/s, lr=8.54e-6, step_loss=0.0007/18/2023 20:39:11 - INFO - __main__ - train loss is 9.651401086011901\n",
      "Steps: 100%|▉| 14996/15000 [1:35:49<00:00,  5.48it/s, lr=8.54e-6, step_loss=0.3707/18/2023 20:39:11 - INFO - __main__ - train loss is 9.705437587806955\n",
      "Steps: 100%|▉| 14997/15000 [1:35:49<00:00,  5.45it/s, lr=8.54e-6, step_loss=0.0507/18/2023 20:39:12 - INFO - __main__ - train loss is 9.722138105193153\n",
      "Steps: 100%|▉| 14998/15000 [1:35:49<00:00,  5.47it/s, lr=8.54e-6, step_loss=0.0107/18/2023 20:39:12 - INFO - __main__ - train loss is 9.753743728855625\n",
      "Steps: 100%|▉| 14999/15000 [1:35:50<00:00,  5.48it/s, lr=8.54e-6, step_loss=0.0307/18/2023 20:39:12 - INFO - __main__ - train loss is 9.8290745227132\n",
      "Steps: 100%|█| 15000/15000 [1:35:50<00:00,  5.49it/s, lr=8.54e-6, step_loss=0.0307/18/2023 20:39:12 - INFO - accelerate.accelerator - Saving current state to ./out/17-07/checkpoint-15000\n",
      "07/18/2023 20:39:12 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-07-18 20:39:12,549] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "[2023-07-18 20:39:12,553] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./out/17-07/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-07-18 20:39:12,553] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-07-18 20:39:12,561] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-07-18 20:39:12,561] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./out/17-07/checkpoint-15000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-07-18 20:39:12,581] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./out/17-07/checkpoint-15000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-07-18 20:39:12,586] [INFO] [engine.py:3245:_save_zero_checkpoint] zero checkpoint saved ./out/17-07/checkpoint-15000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-07-18 20:39:12,586] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "07/18/2023 20:39:12 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./out/17-07/checkpoint-15000/pytorch_model\n",
      "07/18/2023 20:39:12 - INFO - accelerate.checkpointing - Scheduler state saved in ./out/17-07/checkpoint-15000/scheduler.bin\n",
      "07/18/2023 20:39:12 - INFO - accelerate.checkpointing - Random states saved in ./out/17-07/checkpoint-15000/random_states_0.pkl\n",
      "07/18/2023 20:39:12 - INFO - __main__ - Saved state to ./out/17-07/checkpoint-15000\n",
      "Steps: 100%|█| 15000/15000 [1:35:50<00:00,  5.49it/s, lr=8.54e-6, step_loss=0.0707/18/2023 20:39:12 - INFO - __main__ - train loss is 9.890555562684312\n",
      "Steps: : 15001it [1:35:50,  5.16it/s, lr=8.54e-6, step_loss=0.0615]             07/18/2023 20:39:12 - INFO - __main__ - train loss is 9.892232105368748\n",
      "Steps: : 15002it [1:35:50,  5.27it/s, lr=8.54e-6, step_loss=0.00168]07/18/2023 20:39:13 - INFO - __main__ - train loss is 10.077777967089787\n",
      "Steps: : 15003it [1:35:50,  5.31it/s, lr=8.54e-6, step_loss=0.186]  07/18/2023 20:39:13 - INFO - __main__ - train loss is 10.096443105721846\n",
      "Steps: : 15004it [1:35:51,  5.37it/s, lr=8.54e-6, step_loss=0.0187]07/18/2023 20:39:13 - INFO - __main__ - train loss is 10.228569645667449\n",
      "Steps: : 15005it [1:35:51,  5.41it/s, lr=8.54e-6, step_loss=0.132] 07/18/2023 20:39:13 - INFO - __main__ - train loss is 10.285577010596171\n",
      "Steps: : 15006it [1:35:51,  5.43it/s, lr=8.54e-6, step_loss=0.057]07/18/2023 20:39:13 - INFO - __main__ - train loss is 10.294786812970415\n",
      "Steps: : 15007it [1:35:51,  5.46it/s, lr=8.54e-6, step_loss=0.00921]07/18/2023 20:39:13 - INFO - __main__ - train loss is 10.37155262590386\n",
      "Steps: : 15008it [1:35:51,  5.43it/s, lr=8.54e-6, step_loss=0.0768] 07/18/2023 20:39:14 - INFO - __main__ - train loss is 10.451039055595174\n",
      "Steps: : 15009it [1:35:52,  5.44it/s, lr=8.54e-6, step_loss=0.0795]07/18/2023 20:39:14 - INFO - __main__ - train loss is 10.478205656865612\n",
      "Steps: : 15010it [1:35:52,  5.43it/s, lr=8.54e-6, step_loss=0.0272]07/18/2023 20:39:14 - INFO - __main__ - train loss is 10.538485123077407\n",
      "Steps: : 15011it [1:35:52,  5.40it/s, lr=8.54e-6, step_loss=0.0603]07/18/2023 20:39:14 - INFO - __main__ - train loss is 10.792947722831741\n",
      "Steps: : 15012it [1:35:52,  5.42it/s, lr=8.54e-6, step_loss=0.254] 07/18/2023 20:39:14 - INFO - __main__ - train loss is 10.962670443812385\n",
      "Steps: : 15013it [1:35:52,  5.45it/s, lr=8.54e-6, step_loss=0.17] 07/18/2023 20:39:15 - INFO - __main__ - train loss is 11.215777991572395\n",
      "Steps: : 15014it [1:35:52,  5.42it/s, lr=8.54e-6, step_loss=0.253]07/18/2023 20:39:15 - INFO - __main__ - train loss is 11.442155657568946\n",
      "Steps: : 15015it [1:35:53,  5.43it/s, lr=8.54e-6, step_loss=0.226]07/18/2023 20:39:15 - INFO - __main__ - train loss is 11.46113138482906\n",
      "Steps: : 15016it [1:35:53,  5.46it/s, lr=8.54e-6, step_loss=0.019]07/18/2023 20:39:15 - INFO - __main__ - train loss is 11.517069956520572\n",
      "Steps: : 15017it [1:35:53,  5.48it/s, lr=8.54e-6, step_loss=0.0559]07/18/2023 20:39:15 - INFO - __main__ - train loss is 11.592685429612175\n",
      "Steps: : 15018it [1:35:53,  5.51it/s, lr=8.54e-6, step_loss=0.0756]07/18/2023 20:39:15 - INFO - __main__ - train loss is 11.63199650705792\n",
      "Steps: : 15019it [1:35:53,  5.54it/s, lr=8.54e-6, step_loss=0.0393]07/18/2023 20:39:16 - INFO - __main__ - train loss is 11.745247485348955\n",
      "Steps: : 15020it [1:35:54,  5.56it/s, lr=8.54e-6, step_loss=0.113] 07/18/2023 20:39:16 - INFO - __main__ - train loss is 11.850754330167547\n",
      "Steps: : 15021it [1:35:54,  5.58it/s, lr=8.54e-6, step_loss=0.106]07/18/2023 20:39:16 - INFO - __main__ - train loss is 11.870579214999452\n",
      "Steps: : 15022it [1:35:54,  5.58it/s, lr=8.54e-6, step_loss=0.0198]07/18/2023 20:39:16 - INFO - __main__ - train loss is 12.03152677626349\n",
      "Steps: : 15023it [1:35:54,  5.54it/s, lr=8.54e-6, step_loss=0.161] 07/18/2023 20:39:16 - INFO - __main__ - train loss is 12.097585441777483\n",
      "Steps: : 15024it [1:35:54,  5.52it/s, lr=8.53e-6, step_loss=0.0661]07/18/2023 20:39:17 - INFO - __main__ - train loss is 12.62377274245955\n",
      "Steps: : 15025it [1:35:54,  5.54it/s, lr=8.53e-6, step_loss=0.526] 07/18/2023 20:39:17 - INFO - __main__ - train loss is 12.633008142234758\n",
      "Steps: : 15026it [1:35:55,  5.56it/s, lr=8.53e-6, step_loss=0.00924]07/18/2023 20:39:17 - INFO - __main__ - train loss is 12.96422000718303\n",
      "Steps: : 15027it [1:35:55,  5.57it/s, lr=8.53e-6, step_loss=0.331]  07/18/2023 20:39:17 - INFO - __main__ - train loss is 13.056065206648782\n",
      "Steps: : 15028it [1:35:55,  5.53it/s, lr=8.53e-6, step_loss=0.0918]07/18/2023 20:39:17 - INFO - __main__ - train loss is 13.215698649408296\n",
      "Steps: : 15029it [1:35:55,  5.54it/s, lr=8.53e-6, step_loss=0.16]  07/18/2023 20:39:17 - INFO - __main__ - train loss is 13.219137876527384\n",
      "Steps: : 15030it [1:35:55,  5.56it/s, lr=8.53e-6, step_loss=0.00344]07/18/2023 20:39:18 - INFO - __main__ - train loss is 13.234995170729235\n",
      "Steps: : 15031it [1:35:56,  5.57it/s, lr=8.53e-6, step_loss=0.0159] 07/18/2023 20:39:18 - INFO - __main__ - train loss is 13.420406728284433\n",
      "Steps: : 15032it [1:35:56,  5.58it/s, lr=8.53e-6, step_loss=0.185] 07/18/2023 20:39:18 - INFO - __main__ - train loss is 13.442314840154722\n",
      "Steps: : 15033it [1:35:56,  5.59it/s, lr=8.53e-6, step_loss=0.0219]07/18/2023 20:39:18 - INFO - __main__ - train loss is 13.444254736881703\n",
      "Steps: : 15034it [1:35:56,  5.59it/s, lr=8.53e-6, step_loss=0.00194]07/18/2023 20:39:19 - INFO - __main__ - train loss is 13.494192111771554\n",
      "Steps: : 15035it [1:35:56,  3.98it/s, lr=8.53e-6, step_loss=0.0499] 07/18/2023 20:39:19 - INFO - __main__ - Per validation step average loss is 0.3554973602294922\n",
      "07/18/2023 20:39:19 - INFO - __main__ - Cumulative validation average loss is 0.3554973602294922\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Per validation step average loss is 0.44873422384262085\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Cumulative validation average loss is 0.804231584072113\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Per validation step average loss is 0.38426247239112854\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Cumulative validation average loss is 1.1884940564632416\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Per validation step average loss is 0.06703177094459534\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Cumulative validation average loss is 1.255525827407837\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Per validation step average loss is 0.0766836553812027\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Cumulative validation average loss is 1.3322094827890396\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Per validation step average loss is 0.016465675085783005\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Cumulative validation average loss is 1.3486751578748226\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Per validation step average loss is 0.004880988970398903\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Cumulative validation average loss is 1.3535561468452215\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Per validation step average loss is 0.009681257419288158\n",
      "07/18/2023 20:39:20 - INFO - __main__ - Cumulative validation average loss is 1.3632374042645097\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Per validation step average loss is 0.3440188765525818\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Cumulative validation average loss is 1.7072562808170915\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Per validation step average loss is 0.04764651507139206\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Cumulative validation average loss is 1.7549027958884835\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Per validation step average loss is 0.02627592906355858\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Cumulative validation average loss is 1.781178724952042\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Per validation step average loss is 0.00141218863427639\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Cumulative validation average loss is 1.7825909135863185\n",
      "07/18/2023 20:39:21 - INFO - __main__ - Average validation loss for Epoch 154 is 0.14854924279885987\n",
      "Model weights saved in ./out/17-07/pytorch_lora_weights.bin\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'conv_in_kernel', 'resnet_skip_time_act', 'num_class_embeds', 'encoder_hid_dim_type', 'encoder_hid_dim', 'mid_block_type', 'only_cross_attention', 'time_embedding_dim', 'cross_attention_norm', 'addition_embed_type', 'class_embeddings_concat', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'timestep_post_act', 'dual_cross_attention', 'conv_out_kernel', 'upcast_attention', 'class_embed_type', 'use_linear_projection', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim', 'resnet_time_scale_shift', 'mid_block_only_cross_attention', 'addition_embed_type_num_heads', 'time_embedding_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1127, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1097, in main\n",
      "    images.append(pipeline(args.validation_prompt, num_inference_steps=30, generator=generator).images[0])\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 728, in __call__\n",
      "    noise_pred = self.unet(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py\", line 848, in forward\n",
      "    sample = upsample_block(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py\", line 2017, in forward\n",
      "    hidden_states = attn(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/transformer_2d.py\", line 296, in forward\n",
      "    hidden_states = block(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention.py\", line 174, in forward\n",
      "    ff_output = self.ff(norm_hidden_states)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention.py\", line 232, in forward\n",
      "    hidden_states = module(hidden_states)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention.py\", line 279, in forward\n",
      "    return hidden_states * self.gelu(gate)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 9.76 GiB total capacity; 6.33 GiB already allocated; 20.88 MiB free; 6.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1127\u001b[0m in \u001b[92m<module>\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1124 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1125 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1126 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1127 \u001b[2m│   \u001b[0mmain()                                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1097\u001b[0m in \u001b[92mmain\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1094 \u001b[0m\u001b[2m│   │   \u001b[0mgenerator = generator.manual_seed(args.seed)                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1095 \u001b[0m\u001b[2m│   \u001b[0mimages = []                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1096 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m _ \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(args.num_validation_images):                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1097 \u001b[2m│   │   \u001b[0mimages.append(pipeline(args.validation_prompt, num_inference_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1098 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1099 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m accelerator.is_main_process:                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1100 \u001b[0m\u001b[2m│   │   \u001b[0mwandb.log(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/p\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mipelines/stable_diffusion/\u001b[0m\u001b[1;33mpipeline_stable_diffusion.py\u001b[0m:\u001b[94m728\u001b[0m in \u001b[92m__call__\u001b[0m       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m725 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlatent_model_input = \u001b[96mself\u001b[0m.scheduler.scale_model_input( \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m726 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m727 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# predict the noise residual\u001b[0m                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m728 \u001b[2m│   │   │   │   \u001b[0mnoise_pred = \u001b[96mself\u001b[0m.unet(                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m729 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlatent_model_input,                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m730 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mt,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m731 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_hidden_states=prompt_embeds,               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/mo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mdules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/m\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33models/\u001b[0m\u001b[1;33munet_2d_condition.py\u001b[0m:\u001b[94m848\u001b[0m in \u001b[92mforward\u001b[0m                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m845 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mupsample_size = down_block_res_samples[-\u001b[94m1\u001b[0m].shape[\u001b[94m2\u001b[0m:]   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m846 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m847 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(upsample_block, \u001b[33m\"\u001b[0m\u001b[33mhas_cross_attention\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m upsa \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m848 \u001b[2m│   │   │   │   \u001b[0msample = upsample_block(                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m849 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states=sample,                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m850 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtemb=emb,                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m851 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mres_hidden_states_tuple=res_samples,               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/mo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mdules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/m\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33models/\u001b[0m\u001b[1;33munet_2d_blocks.py\u001b[0m:\u001b[94m2017\u001b[0m in \u001b[92mforward\u001b[0m                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2014 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)[\u001b[94m0\u001b[0m]                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2015 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2016 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhidden_states = resnet(hidden_states, temb)           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2017 \u001b[2m│   │   │   │   \u001b[0mhidden_states = attn(                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2018 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2019 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_hidden_states=encoder_hidden_states,      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2020 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcross_attention_kwargs=cross_attention_kwargs,    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/mo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mdules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/m\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33models/\u001b[0m\u001b[1;33mtransformer_2d.py\u001b[0m:\u001b[94m296\u001b[0m in \u001b[92mforward\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 2. Blocks\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m block \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.transformer_blocks:                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m296 \u001b[2m│   │   │   \u001b[0mhidden_states = block(                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhidden_states,                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattention_mask=attention_mask,                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mencoder_hidden_states=encoder_hidden_states,           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/mo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mdules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/m\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33models/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m174\u001b[0m in \u001b[92mforward\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.use_ada_layer_norm_zero:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   │   │   \u001b[0mnorm_hidden_states = norm_hidden_states * (\u001b[94m1\u001b[0m + scale_mlp[: \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m174 \u001b[2m│   │   \u001b[0mff_output = \u001b[96mself\u001b[0m.ff(norm_hidden_states)                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.use_ada_layer_norm_zero:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   │   \u001b[0mff_output = gate_mlp.unsqueeze(\u001b[94m1\u001b[0m) * ff_output              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/mo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mdules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/m\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33models/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m232\u001b[0m in \u001b[92mforward\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, hidden_states):                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.net:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m232 \u001b[2m│   │   │   \u001b[0mhidden_states = module(hidden_states)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m hidden_states                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m235 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/mo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mdules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/m\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33models/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m279\u001b[0m in \u001b[92mforward\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, hidden_states):                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states, gate = \u001b[96mself\u001b[0m.proj(hidden_states).chunk(\u001b[94m2\u001b[0m, dim=-\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m279 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m hidden_states * \u001b[96mself\u001b[0m.gelu(gate)                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mApproximateGELU\u001b[0m(nn.Module):                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m20.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m9.76\u001b[0m \n",
      "GiB total capacity; \u001b[1;36m6.33\u001b[0m GiB already allocated; \u001b[1;36m20.88\u001b[0m MiB free; \u001b[1;36m6.36\u001b[0m GiB \n",
      "reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
      "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
      "Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 2804.570 MB of 2804.570 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_train_loss_per_epoch ▆▆▄▂▃▂█▅▆▅▁▂▅▇▄▄█▄▇▄▃▄▄▅▂▄▄▄▂▂▆█▃▇▆▆▅▅▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_valid_loss_per_epoch ▅▃▄▇▁▃▄▄▃▅▄▆▅▃▂▆▇▄▃▃▃▅▄▅▅▂▅▃▄▅▄▄▅▃▁█▆▅▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       training_step_loss ▃▃▁▁▃▁▁▅▂▁▁▂▃▁▁▂▁▁▂▅▂▁▂▁█▁▄▁▁▄▁▁▂▂▁▄▆▃▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_train_loss_per_epoch 0.13912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_valid_loss_per_epoch 0.14855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       training_step_loss 0.04994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtrue-frog-103\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/uqudwn7j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 6196 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230718_190316-uqudwn7j/logs\u001b[0m\n",
      "\u001b[2;36m[20:39:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m104569\u001b[0m\u001b[1m)\u001b[0m  \u001b]8;id=148656;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=231316;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#672\u001b\\\u001b[2m672\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         of binary:                                        \u001b[2m          \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[35m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[95mpython\u001b[0m    \u001b[2m          \u001b[0m\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m926\u001b[0m in \u001b[92mlaunch_command\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m923 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m924 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m925 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m926 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m927 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m928 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m929 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m671\u001b[0m in \u001b[92mdeepspeed_launcher\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m668 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m669 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m670 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m671 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m672 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m673 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m674 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m785\u001b[0m in \u001b[92mrun\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m782 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m783 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m784 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m785 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92m__call__\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mChildFailedError: \u001b[0m\n",
      "============================================================\n",
      "train_text_to_image_lora.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  \u001b[1m<\u001b[0m\u001b[1;95mNO_OTHER_FAILURES\u001b[0m\u001b[39m>\u001b[0m\n",
      "\u001b[39m------------------------------------------------------------\u001b[0m\n",
      "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m07\u001b[0m\u001b[39m-18_\u001b[0m\u001b[1;92m20:39:49\u001b[0m\n",
      "\u001b[39m  host      : honeybone.lan\u001b[0m\n",
      "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m104569\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
      "  traceback : To enable traceback see: \n",
      "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --validation_epochs=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/19-07\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/13-07/2\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
