{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline from downloaded files, to complete huggingface dataset with metadata\n",
    "# Normalisation of sound to [-1, 1]\n",
    "# Construction of full dataset with metadata\n",
    "# Train/Test/Val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from utils.spectrogram_image_converter import SpectrogramImageConverter\n",
    "from utils.spectrogram_params import SpectrogramParams\n",
    "import pydub\n",
    "import typing as T\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class WavPreprocessor:\n",
    "    \n",
    "    def __init__(self, spectrogram_params):\n",
    "        self._params = spectrogram_params\n",
    "        self._converter = SpectrogramImageConverter(parms=spectrogram_params, device=\"cuda\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def resample(self, audio, target_sr):\n",
    "        y, sr = librosa.load(audio, sr=None)\n",
    "        \n",
    "        y_resampled = librosa.resample(y, sr, target_sr)\n",
    "        \n",
    "        return y_resampled, target_sr\n",
    "\n",
    "    def resample_folder(self, input_path, target_sr):\n",
    "        for filename in os.listdir(input_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                path = os.path.join(input_path, filename)\n",
    "                y_resampled, sr = self.resample(path, target_sr)\n",
    "                \n",
    "                save_path = os.path.join(input_path, filename) # Overwrite the original file\n",
    "                sf.write(save_path, y_resampled, sr)\n",
    "\n",
    "    def min_max_normalise(self, audio):\n",
    "        y, sr = librosa.load(audio, sr=None)\n",
    "        \n",
    "        normalised_y = y / np.max(np.abs(y))\n",
    "        \n",
    "        return normalised_y, sr\n",
    "\n",
    "    def min_max_normalise_folder(self, input_path):\n",
    "        for filename in os.listdir(input_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                path = os.path.join(input_path, filename)\n",
    "                norm_wav, sr = self.min_max_normalise(path)\n",
    "                \n",
    "                save_path = os.path.join(input_path, filename) # Overwrite the original file\n",
    "                sf.write(save_path, norm_wav, sr)\n",
    "\n",
    "    def wav_to_spec(self, wav_path, output_path):\n",
    "        # Convert wav to audiosegment\n",
    "        segment = pydub.AudioSegment.from_wav(wav_path)\n",
    "\n",
    "        # Convert to mono\n",
    "        segment = segment.set_channels(1)\n",
    "\n",
    "        # Define named sets of parameters\n",
    "        param_sets: T.Dict[str, self._params] = {}\n",
    "\n",
    "        images: T.Dict[str, Image.Image] = {}\n",
    "\n",
    "        for name, params in param_sets.items():\n",
    "            images[name] = self._converter.spectrogram_image_from_audio(segment)\n",
    "\n",
    "        # Save images to disk\n",
    "        for name, image in images.items():\n",
    "            image_out = output_path + \"/\" + os.fsdecode(wav_path)[:-4] + \".png\"\n",
    "            image.save(image_out, exif=image.getexif(), format=\"PNG\")\n",
    "            print(f\"Saved {image_out}\")\n",
    "\n",
    "    def wav_to_spec_folder(self, input_path):\n",
    "        for wav_file in os.listdir(input_path):\n",
    "            if wav_file.endswith('.wav'): # Ensure we're only working on wav files\n",
    "                wav_path = os.path.join(input_path, wav_file)\n",
    "                self.wav_to_spec(wav_path, input_path) # Output to the same folder\n",
    "\n",
    "\n",
    "            \n",
    "    # def spec_to_wav(self, spec):\n",
    "    # def spec_to_wav_folder(self, input_path, output_path): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Select chosen classes and copy across into data folder\n",
    "class DatasetPipeline:    \n",
    "    _classes = []\n",
    "    _dataset_path = \"\" # Where dataset will be constructed\n",
    "    _class_path = \"\" # Where raw data is saved\n",
    "    _preprocessor = WavPreprocessor\n",
    "    \n",
    "    \n",
    "    def __init__(self, dataset_path, class_path, preprocessor, *classes):\n",
    "        self._dataset_path = dataset_path\n",
    "        self._class_path = class_path\n",
    "        self._classes = [c for c in classes]\n",
    "        self._preprocessor = preprocessor\n",
    "    \n",
    "    \n",
    "    # Creates corresponding folders for chosen classes\n",
    "    def folder_setup(self):\n",
    "        for folder in os.listdir(self._class_path):\n",
    "            if folder in self._classes and os.path.isdir(os.path.join(self._class_path, folder)):\n",
    "                dest_folder = os.path.join(self._dataset_path, folder)\n",
    "\n",
    "                if not os.path.exists(dest_folder):\n",
    "                    os.makedirs(dest_folder)\n",
    "\n",
    "\n",
    "    # Copies files excluding those tagged with REMOVE\n",
    "    def copy_files(self):\n",
    "        for folder in os.listdir(self._class_path):  \n",
    "            if os.path.isdir(os.path.join(self._class_path, folder)):\n",
    "                for file in os.listdir(os.path.join(self._class_path, folder)):\n",
    "                    if 'REMOVE' in file:\n",
    "                        continue\n",
    "\n",
    "                    # Add the folder name (class name) as prefix to each file\n",
    "                    new_file_name = f\"{folder}_{file}\"\n",
    "                    \n",
    "                    src_file = os.path.join(self._class_path, folder, file)\n",
    "                    dest_file = os.path.join(self._dataset_path, folder, new_file_name)\n",
    "                    \n",
    "                    shutil.copy(src_file, dest_file)\n",
    "\n",
    "        \n",
    "    # Generates a metadata.csv with headings [image, prompt, audiofile]\n",
    "    def generate_metadata(self, prompt=None):\n",
    "        for folder in os.listdir(self._dataset_path):\n",
    "            # Define the output path for the CSV file\n",
    "            csv_path = os.path.join(folder, 'metadata.csv')\n",
    "            src_folder = os.path.join(self._class_path, folder)\n",
    "\n",
    "            # Create the CSV file and write the header\n",
    "            with open(csv_path, 'w', newline='') as csv_file:\n",
    "                writer = csv.writer(csv_file)\n",
    "                writer.writerow(['file_name', 'text', 'audiofile'])\n",
    "\n",
    "                # Get the list of PNG files in the source folder\n",
    "                png_files = [f for f in os.listdir(src_folder) if f.endswith('.png')]\n",
    "\n",
    "                # Iterate over each PNG file\n",
    "                for png_file in png_files:\n",
    "                    # Extract the filename without the extension\n",
    "                    file_name = os.path.splitext(png_file)[0]\n",
    "\n",
    "                    # Construct the corresponding WAV file path\n",
    "                    audio_file = os.path.join(folder, file_name)\n",
    "\n",
    "                    # Get the absolute path of the audio file\n",
    "                    abs_audio_file = os.path.abspath(audio_file)\n",
    "\n",
    "                    # Write the row to the CSV file\n",
    "                    if prompt is None:\n",
    "                        prompt = f\"A spectrogram of {(folder.lower())}\"\n",
    "                        \n",
    "                    writer.writerow([png_file, prompt, abs_audio_file])\n",
    "        \n",
    "        \n",
    "    # Combines all classes into a single dataset folder, combining the metadata\n",
    "    def combine_data(self):\n",
    "        combined_folder = os.path.join(self._dataset_path, \"dataset\", \"unsplit\")\n",
    "        os.makedirs(combined_folder, exist_ok=True)\n",
    "\n",
    "        combined_metadata_path = os.path.join(combined_folder, 'metadata.csv')\n",
    "        with open(combined_metadata_path, 'w', newline='') as combined_metadata:\n",
    "            writer = csv.writer(combined_metadata)\n",
    "            writer.writerow(['file_name', 'text', 'audiofile'])  # Write header to the combined metadata\n",
    "\n",
    "            for folder in self._classes:\n",
    "                class_folder = os.path.join(self._dataset_path, folder)\n",
    "\n",
    "                # Copy files\n",
    "                for file in os.listdir(class_folder):\n",
    "                    if file.endswith(\".wav\") or file.endswith(\".png\"):\n",
    "                        src_file = os.path.join(class_folder, file)\n",
    "                        dest_file = os.path.join(combined_folder, file)\n",
    "                        shutil.copy(src_file, dest_file)\n",
    "\n",
    "                # Append metadata\n",
    "                metadata_path = os.path.join(class_folder, 'metadata.csv')\n",
    "                with open(metadata_path, 'r') as metadata:\n",
    "                    reader = csv.reader(metadata)\n",
    "                    next(reader)  # Skip header\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)  # Write each row to the combined metadata\n",
    "            \n",
    "            \n",
    "    # Splits data into train, test and var folders    \n",
    "    def split_data(self, train_ratio=0.8, val_ratio=0.1):\n",
    "        # Create the new directories\n",
    "        base_path = os.path.join(self._dataset_path, \"dataset\")\n",
    "        unsplit_folder = os.path.join(base_path, \"unsplit\")\n",
    "        train_folder = os.path.join(base_path, \"train\")\n",
    "        val_folder = os.path.join(base_path, \"val\")\n",
    "        test_folder = os.path.join(base_path, \"test\")\n",
    "        \n",
    "        os.makedirs(train_folder, exist_ok=True)\n",
    "        os.makedirs(val_folder, exist_ok=True)\n",
    "        os.makedirs(test_folder, exist_ok=True)\n",
    "        \n",
    "        # Collect all unique file prefixes in the unsplit_folder\n",
    "        file_prefixes = {filename.split('.')[0] for filename in os.listdir(unsplit_folder) if filename.endswith(('.wav', '.png'))}\n",
    "        file_prefixes = list(file_prefixes)\n",
    "        \n",
    "        # Shuffle the list for randomness\n",
    "        random.shuffle(file_prefixes)\n",
    "        \n",
    "        # Calculate the indices to split at\n",
    "        total_files = len(file_prefixes)\n",
    "        train_split = math.floor(total_files * train_ratio)\n",
    "        val_split = train_split + math.floor(total_files * val_ratio)\n",
    "        \n",
    "        # Split the list\n",
    "        train_files = file_prefixes[:train_split]\n",
    "        val_files = file_prefixes[train_split:val_split]\n",
    "        test_files = file_prefixes[val_split:]\n",
    "        \n",
    "        # Define a helper function to move files and update metadata\n",
    "        def move_files_and_update_metadata(files, destination_folder, metadata_writer):\n",
    "            for file_prefix in files:\n",
    "                for extension in ['.wav', '.png']:\n",
    "                    file_name = file_prefix + extension\n",
    "                    src_path = os.path.join(unsplit_folder, file_name)\n",
    "                    dest_path = os.path.join(destination_folder, file_name)\n",
    "                    shutil.move(src_path, dest_path)\n",
    "                    \n",
    "                    # Update the metadata\n",
    "                    if extension == '.wav':  # We only need to do this once per pair, so let's do it for '.wav' files\n",
    "                        abs_audio_file = os.path.abspath(dest_path)\n",
    "                        prompt = f\"A spectrogram of {(file_prefix.lower())}\"\n",
    "                        metadata_writer.writerow([file_name, prompt, abs_audio_file])\n",
    "                    \n",
    "        # Move the files and update metadata\n",
    "        for folder, files in zip([train_folder, val_folder, test_folder], [train_files, val_files, test_files]):\n",
    "            metadata_path = os.path.join(folder, 'metadata.csv')\n",
    "            with open(metadata_path, 'w', newline='') as metadata_file:\n",
    "                writer = csv.writer(metadata_file)\n",
    "                writer.writerow(['file_name', 'text', 'audiofile'])  # Write the header\n",
    "                move_files_and_update_metadata(files, folder, writer)\n",
    "                \n",
    "    def preprocess(self, target_sr):\n",
    "        for folder in os.listdir(self._dataset_path):\n",
    "            folder_path = os.path.join(self._dataset_path, folder)  # Full path to the folder\n",
    "            self._preprocessor.resample_folder(folder_path, target_sr)\n",
    "            self._preprocessor.min_max_normalise_folder(folder_path)\n",
    "            self._preprocessor.wav_to_spec_folder(folder_path)\n",
    "\n",
    "    def create_dataset(self, target_sr, train_split, var_split):\n",
    "        assert train_split + var_split <= 1, \"Train and validation split must be less than 1\"\n",
    "        \n",
    "        # 1. Create folders for each class\n",
    "        self.folder_setup()\n",
    "\n",
    "        # 2. Copy files for each class\n",
    "        self.copy_files()\n",
    "        \n",
    "        # 3. Apply preprocessing (resampling and min_max_norm) for each class and create spectrograms\n",
    "        self.preprocess(target_sr)\n",
    "\n",
    "        # 4. Generate metadata for each class\n",
    "        self.generate_metadata()\n",
    "\n",
    "        # 5. Combine all classes into a single dataset folder\n",
    "        self.combine_data()\n",
    "\n",
    "        # 6. Split data into train, test and validation sets\n",
    "        self.split_data(train_ratio=train_split, val_ratio=var_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of target classes\n",
    "\n",
    "# Create objects\n",
    "\n",
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "msc_diss"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
