{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19 12:32:19,537] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87822ed83f464169b722ef8107b923f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5782384a014eb4ad9eea06c1f6c6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789d2d98f3864f90810f1005daca42dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40a78d6f8664576bf83ab1c93d9cc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbeec814ab1473a928b797f8b14154c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" , split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=501x512>,\n",
       " 'prompt': 'a spectrogram of bird song',\n",
       " 'audiofile': './data/Bird vocalization-bird call-bird song/train/-aC8TJIZrtE.wav'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-20 16:17:14,998] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-20 16:17:17,312] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-20 16:17:18,579] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-20 16:17:18,579] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-20 16:17:18,579] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/20/2023 16:17:18 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'variance_type', 'prediction_type', 'clip_sample_range', 'sample_max_value', 'dynamic_thresholding_ratio', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'time_cond_proj_dim', 'mid_block_only_cross_attention', 'cross_attention_norm', 'resnet_time_scale_shift', 'conv_in_kernel', 'upcast_attention', 'num_class_embeds', 'resnet_skip_time_act', 'time_embedding_dim', 'use_linear_projection', 'addition_embed_type_num_heads', 'dual_cross_attention', 'time_embedding_act_fn', 'class_embed_type', 'encoder_hid_dim_type', 'mid_block_type', 'conv_out_kernel', 'class_embeddings_concat', 'timestep_post_act', 'addition_embed_type', 'only_cross_attention', 'resnet_out_scale_factor', 'projection_class_embeddings_input_dim', 'time_embedding_type', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 195/195 [00:00<00:00, 603163.19it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 474468.78it/s]\n",
      "07/20/2023 16:17:25 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-a82c8940ed1ca823/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1106.24it/s]\n",
      "07/20/2023 16:17:27 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (1).\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.2074103355407715 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-20 16:17:31,442] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/20/2023 16:17:31 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/20/2023 16:17:31 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-20 16:17:31,477] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-20 16:17:31,477] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-20 16:17:31,477] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-20 16:17:31,483] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-20 16:17:31,483] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-20 16:17:31,483] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-20 16:17:31,483] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-20 16:17:31,483] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-20 16:17:31,483] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-20 16:17:31,483] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07828235626220703 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-20 16:17:31,677] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-20 16:17:31,678] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-20 16:17:31,678] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.1 GB, percent = 52.1%\n",
      "[2023-07-20 16:17:31,780] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-20 16:17:31,780] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-20 16:17:31,780] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.1 GB, percent = 52.1%\n",
      "[2023-07-20 16:17:31,781] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-20 16:17:31,874] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-20 16:17:31,874] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-20 16:17:31,874] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.1 GB, percent = 52.1%\n",
      "[2023-07-20 16:17:31,878] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-20 16:17:31,879] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-20 16:17:31,879] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-20 16:17:31,879] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
      "[2023-07-20 16:17:31,879] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-20 16:17:31,879] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-20 16:17:31,879] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-20 16:17:31,879] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-20 16:17:31,879] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-20 16:17:31,879] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc614205360>\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-20 16:17:31,880] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-20 16:17:31,881] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-20 16:17:31,881] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-20 16:17:31,881] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00019359588623046875 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230720_161732-owt61hah\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msummer-salad-132\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/owt61hah\u001b[0m\n",
      "07/20/2023 16:17:38 - INFO - __main__ - ***** Running training *****\n",
      "07/20/2023 16:17:38 - INFO - __main__ -   Num examples = 97\n",
      "07/20/2023 16:17:38 - INFO - __main__ -   Num Epochs = 600\n",
      "07/20/2023 16:17:38 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/20/2023 16:17:38 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/20/2023 16:17:38 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/20/2023 16:17:38 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]07/20/2023 16:17:38 - INFO - __main__ - Starting epoch 0\n",
      "07/20/2023 16:17:39 - INFO - __main__ - train loss is 0.2497926950454712\n",
      "[2023-07-20 16:17:40,038] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|          | 1/15000 [00:01<8:17:52,  1.99s/it, lr=0, step_loss=0.25]07/20/2023 16:17:40 - INFO - __main__ - train loss is 0.35711024701595306\n",
      "[2023-07-20 16:17:40,565] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|         | 2/15000 [00:02<4:42:26,  1.13s/it, lr=0, step_loss=0.107]07/20/2023 16:17:41 - INFO - __main__ - train loss is 0.7553751617670059\n",
      "[2023-07-20 16:17:41,101] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|         | 3/15000 [00:03<3:34:41,  1.16it/s, lr=0, step_loss=0.398]07/20/2023 16:17:41 - INFO - __main__ - train loss is 0.8121097832918167\n",
      "[2023-07-20 16:17:41,676] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|        | 4/15000 [00:03<3:06:47,  1.34it/s, lr=0, step_loss=0.0567]07/20/2023 16:17:42 - INFO - __main__ - train loss is 0.9457347989082336\n",
      "[2023-07-20 16:17:42,218] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|         | 5/15000 [00:04<2:48:06,  1.49it/s, lr=0, step_loss=0.134]07/20/2023 16:17:42 - INFO - __main__ - train loss is 1.075062334537506\n",
      "[2023-07-20 16:17:42,751] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|         | 6/15000 [00:04<2:36:17,  1.60it/s, lr=0, step_loss=0.129]07/20/2023 16:17:43 - INFO - __main__ - train loss is 1.2583049833774567\n",
      "[2023-07-20 16:17:43,283] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|         | 7/15000 [00:05<2:28:38,  1.68it/s, lr=0, step_loss=0.183]07/20/2023 16:17:43 - INFO - __main__ - train loss is 1.502046823501587\n",
      "[2023-07-20 16:17:43,813] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|         | 8/15000 [00:05<2:23:24,  1.74it/s, lr=0, step_loss=0.244]07/20/2023 16:17:44 - INFO - __main__ - train loss is 1.5059437050949782\n",
      "Steps:   0%|   | 9/15000 [00:06<2:20:39,  1.78it/s, lr=2.5e-9, step_loss=0.0039]07/20/2023 16:17:44 - INFO - __main__ - train loss is 1.7130002870690078\n",
      "[2023-07-20 16:17:44,876] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%|   | 10/15000 [00:06<2:17:42,  1.81it/s, lr=2.5e-9, step_loss=0.207]07/20/2023 16:17:45 - INFO - __main__ - train loss is 1.7309234298299998\n",
      "Steps:   0%|    | 11/15000 [00:07<2:16:31,  1.83it/s, lr=5e-9, step_loss=0.0179]07/20/2023 16:17:45 - INFO - __main__ - train loss is 1.8375186033081263\n",
      "Steps:   0%|   | 12/15000 [00:07<2:15:13,  1.85it/s, lr=7.5e-9, step_loss=0.107]07/20/2023 16:17:46 - INFO - __main__ - train loss is 1.8409371131565422\n",
      "Steps:   0%|   | 13/15000 [00:08<2:14:54,  1.85it/s, lr=1e-8, step_loss=0.00342]07/20/2023 16:17:46 - INFO - __main__ - train loss is 1.9185615533497185\n",
      "Steps:   0%| | 14/15000 [00:08<2:13:55,  1.87it/s, lr=1.25e-8, step_loss=0.0776]07/20/2023 16:17:47 - INFO - __main__ - train loss is 1.9828102046158165\n",
      "Steps:   0%|  | 15/15000 [00:09<2:13:12,  1.87it/s, lr=1.5e-8, step_loss=0.0642]07/20/2023 16:17:47 - INFO - __main__ - train loss is 2.0244558544363827\n",
      "Steps:   0%| | 16/15000 [00:10<2:12:44,  1.88it/s, lr=1.75e-8, step_loss=0.0416]07/20/2023 16:17:48 - INFO - __main__ - train loss is 2.237043240806088\n",
      "Steps:   0%|     | 17/15000 [00:10<2:12:23,  1.89it/s, lr=2e-8, step_loss=0.213]07/20/2023 16:17:49 - INFO - __main__ - train loss is 2.6352723033633083\n",
      "Steps:   0%|  | 18/15000 [00:11<2:12:32,  1.88it/s, lr=2.25e-8, step_loss=0.398]07/20/2023 16:17:49 - INFO - __main__ - train loss is 2.6889158652629703\n",
      "Steps:   0%|  | 19/15000 [00:11<2:12:18,  1.89it/s, lr=2.5e-8, step_loss=0.0536]07/20/2023 16:17:50 - INFO - __main__ - train loss is 2.7288708069827408\n",
      "Steps:   0%|   | 20/15000 [00:12<2:12:25,  1.89it/s, lr=2.75e-8, step_loss=0.04]07/20/2023 16:17:50 - INFO - __main__ - train loss is 2.740486887982115\n",
      "Steps:   0%|    | 21/15000 [00:12<2:13:08,  1.87it/s, lr=3e-8, step_loss=0.0116]07/20/2023 16:17:51 - INFO - __main__ - train loss is 2.757479384308681\n",
      "Steps:   0%|  | 22/15000 [00:13<2:12:50,  1.88it/s, lr=3.25e-8, step_loss=0.017]07/20/2023 16:17:51 - INFO - __main__ - train loss is 2.7839604874607176\n",
      "Steps:   0%|  | 23/15000 [00:13<2:12:54,  1.88it/s, lr=3.5e-8, step_loss=0.0265]07/20/2023 16:17:52 - INFO - __main__ - train loss is 2.9498439689632505\n",
      "Steps:   0%|  | 24/15000 [00:14<2:13:21,  1.87it/s, lr=3.75e-8, step_loss=0.166]07/20/2023 16:17:52 - INFO - __main__ - train loss is 2.976250730222091\n",
      "Steps:   0%|    | 25/15000 [00:14<2:14:12,  1.86it/s, lr=4e-8, step_loss=0.0264]07/20/2023 16:17:53 - INFO - __main__ - train loss is 3.018855653470382\n",
      "Steps:   0%| | 26/15000 [00:15<2:13:41,  1.87it/s, lr=4.25e-8, step_loss=0.0426]07/20/2023 16:17:53 - INFO - __main__ - train loss is 3.119013421004638\n",
      "[2023-07-20 16:17:53,924] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   0%|    | 27/15000 [00:15<2:13:04,  1.88it/s, lr=4.25e-8, step_loss=0.1]07/20/2023 16:17:54 - INFO - __main__ - train loss is 3.170152492588386\n",
      "Steps:   0%|  | 28/15000 [00:16<2:13:18,  1.87it/s, lr=4.5e-8, step_loss=0.0511]07/20/2023 16:17:54 - INFO - __main__ - train loss is 3.17520398250781\n",
      "Steps:   0%| | 29/15000 [00:16<2:13:45,  1.87it/s, lr=4.75e-8, step_loss=0.0050507/20/2023 16:17:55 - INFO - __main__ - train loss is 3.1860732359346002\n",
      "Steps:   0%|    | 30/15000 [00:17<2:13:30,  1.87it/s, lr=5e-8, step_loss=0.0109]07/20/2023 16:17:55 - INFO - __main__ - train loss is 3.2569586855825037\n",
      "Steps:   0%| | 31/15000 [00:18<2:13:22,  1.87it/s, lr=5.25e-8, step_loss=0.0709]07/20/2023 16:17:56 - INFO - __main__ - train loss is 3.262996267294511\n",
      "Steps:   0%| | 32/15000 [00:18<2:13:14,  1.87it/s, lr=5.5e-8, step_loss=0.00604]07/20/2023 16:17:57 - INFO - __main__ - train loss is 3.26550672785379\n",
      "Steps:   0%| | 33/15000 [00:19<2:12:53,  1.88it/s, lr=5.75e-8, step_loss=0.0025107/20/2023 16:17:57 - INFO - __main__ - train loss is 3.274449102813378\n",
      "Steps:   0%|   | 34/15000 [00:19<2:12:37,  1.88it/s, lr=6e-8, step_loss=0.00894]07/20/2023 16:17:58 - INFO - __main__ - train loss is 3.3647116052452475\n",
      "Steps:   0%| | 35/15000 [00:20<2:12:07,  1.89it/s, lr=6.25e-8, step_loss=0.0903]07/20/2023 16:17:58 - INFO - __main__ - train loss is 3.7533112394157797\n",
      "Steps:   0%|   | 36/15000 [00:20<2:12:42,  1.88it/s, lr=6.5e-8, step_loss=0.389]07/20/2023 16:17:59 - INFO - __main__ - train loss is 4.147809408837929\n",
      "Steps:   0%|  | 37/15000 [00:21<2:12:59,  1.88it/s, lr=6.75e-8, step_loss=0.394]07/20/2023 16:17:59 - INFO - __main__ - train loss is 4.160678646760061\n",
      "Steps:   0%|    | 38/15000 [00:21<2:12:25,  1.88it/s, lr=7e-8, step_loss=0.0129]07/20/2023 16:18:00 - INFO - __main__ - train loss is 4.354435510234907\n",
      "Steps:   0%|  | 39/15000 [00:22<2:12:35,  1.88it/s, lr=7.25e-8, step_loss=0.194]07/20/2023 16:18:00 - INFO - __main__ - train loss is 4.564189858036116\n",
      "Steps:   0%|    | 40/15000 [00:22<2:12:54,  1.88it/s, lr=7.5e-8, step_loss=0.21]07/20/2023 16:18:01 - INFO - __main__ - train loss is 4.75594714959152\n",
      "Steps:   0%|  | 41/15000 [00:23<2:12:40,  1.88it/s, lr=7.75e-8, step_loss=0.192]07/20/2023 16:18:01 - INFO - __main__ - train loss is 4.759734705789015\n",
      "Steps:   0%|   | 42/15000 [00:23<2:12:34,  1.88it/s, lr=8e-8, step_loss=0.00379]07/20/2023 16:18:02 - INFO - __main__ - train loss is 4.805020087165758\n",
      "Steps:   0%| | 43/15000 [00:24<2:12:54,  1.88it/s, lr=8.25e-8, step_loss=0.0453]07/20/2023 16:18:02 - INFO - __main__ - train loss is 4.8577822267543525\n",
      "Steps:   0%|  | 44/15000 [00:24<2:13:02,  1.87it/s, lr=8.5e-8, step_loss=0.0528]07/20/2023 16:18:03 - INFO - __main__ - train loss is 4.863434206461534\n",
      "Steps:   0%| | 45/15000 [00:25<2:12:32,  1.88it/s, lr=8.75e-8, step_loss=0.0056507/20/2023 16:18:03 - INFO - __main__ - train loss is 5.030865352367982\n",
      "Steps:   0%|     | 46/15000 [00:26<2:12:54,  1.88it/s, lr=9e-8, step_loss=0.167]07/20/2023 16:18:04 - INFO - __main__ - train loss is 5.146825518226251\n",
      "Steps:   0%|  | 47/15000 [00:26<2:13:57,  1.86it/s, lr=9.25e-8, step_loss=0.116]07/20/2023 16:18:05 - INFO - __main__ - train loss is 5.271261106943712\n",
      "Steps:   0%|   | 48/15000 [00:27<2:13:18,  1.87it/s, lr=9.5e-8, step_loss=0.124]07/20/2023 16:18:05 - INFO - __main__ - train loss is 5.3790431132074445\n",
      "Steps:   0%|  | 49/15000 [00:27<2:12:55,  1.87it/s, lr=9.75e-8, step_loss=0.108]07/20/2023 16:18:06 - INFO - __main__ - train loss is 5.61680419347249\n",
      "Steps:   0%|     | 50/15000 [00:28<2:12:33,  1.88it/s, lr=1e-7, step_loss=0.238]07/20/2023 16:18:06 - INFO - __main__ - train loss is 5.989642571425065\n",
      "Steps:   0%|  | 51/15000 [00:28<2:12:58,  1.87it/s, lr=1.03e-7, step_loss=0.373]07/20/2023 16:18:07 - INFO - __main__ - train loss is 5.997758160112426\n",
      "Steps:   0%| | 52/15000 [00:29<2:13:04,  1.87it/s, lr=1.05e-7, step_loss=0.0081207/20/2023 16:18:07 - INFO - __main__ - train loss is 6.320805857656524\n",
      "Steps:   0%|  | 53/15000 [00:29<2:12:44,  1.88it/s, lr=1.08e-7, step_loss=0.323]07/20/2023 16:18:08 - INFO - __main__ - train loss is 6.32456963066943\n",
      "Steps:   0%| | 54/15000 [00:30<2:13:16,  1.87it/s, lr=1.1e-7, step_loss=0.00376]07/20/2023 16:18:08 - INFO - __main__ - train loss is 6.3301596159581095\n",
      "Steps:   0%| | 55/15000 [00:30<2:13:31,  1.87it/s, lr=1.13e-7, step_loss=0.0055907/20/2023 16:18:09 - INFO - __main__ - train loss is 6.784984093392268\n",
      "Steps:   0%|  | 56/15000 [00:31<2:13:20,  1.87it/s, lr=1.15e-7, step_loss=0.455]07/20/2023 16:18:09 - INFO - __main__ - train loss is 6.849903974914923\n",
      "Steps:   0%| | 57/15000 [00:31<2:12:41,  1.88it/s, lr=1.18e-7, step_loss=0.0649]07/20/2023 16:18:10 - INFO - __main__ - train loss is 6.938219253206626\n",
      "Steps:   0%|  | 58/15000 [00:32<2:13:13,  1.87it/s, lr=1.2e-7, step_loss=0.0883]07/20/2023 16:18:10 - INFO - __main__ - train loss is 7.658367101335898\n",
      "Steps:   0%|   | 59/15000 [00:32<2:12:56,  1.87it/s, lr=1.23e-7, step_loss=0.72]07/20/2023 16:18:11 - INFO - __main__ - train loss is 7.663024399196729\n",
      "Steps:   0%| | 60/15000 [00:33<2:12:40,  1.88it/s, lr=1.25e-7, step_loss=0.0046607/20/2023 16:18:11 - INFO - __main__ - train loss is 8.004429969703779\n",
      "Steps:   0%|  | 61/15000 [00:34<2:12:36,  1.88it/s, lr=1.27e-7, step_loss=0.341]07/20/2023 16:18:12 - INFO - __main__ - train loss is 8.013669674051926\n",
      "Steps:   0%| | 62/15000 [00:34<2:12:59,  1.87it/s, lr=1.3e-7, step_loss=0.00924]07/20/2023 16:18:13 - INFO - __main__ - train loss is 8.344722811831161\n",
      "Steps:   0%|  | 63/15000 [00:35<2:12:49,  1.87it/s, lr=1.33e-7, step_loss=0.331]07/20/2023 16:18:13 - INFO - __main__ - train loss is 9.002932135714218\n",
      "Steps:   0%|  | 64/15000 [00:35<2:13:32,  1.86it/s, lr=1.35e-7, step_loss=0.658]07/20/2023 16:18:14 - INFO - __main__ - train loss is 9.008566132513806\n",
      "Steps:   0%| | 65/15000 [00:36<2:13:13,  1.87it/s, lr=1.38e-7, step_loss=0.0056307/20/2023 16:18:14 - INFO - __main__ - train loss is 9.694959989516065\n",
      "Steps:   0%|   | 66/15000 [00:36<2:13:59,  1.86it/s, lr=1.4e-7, step_loss=0.686]07/20/2023 16:18:15 - INFO - __main__ - train loss is 9.705156148178503\n",
      "Steps:   0%| | 67/15000 [00:37<2:13:17,  1.87it/s, lr=1.43e-7, step_loss=0.0102]07/20/2023 16:18:15 - INFO - __main__ - train loss is 9.735822471557185\n",
      "Steps:   0%| | 68/15000 [00:37<2:13:47,  1.86it/s, lr=1.45e-7, step_loss=0.0307]07/20/2023 16:18:16 - INFO - __main__ - train loss is 9.745610327227041\n",
      "Steps:   0%| | 69/15000 [00:38<2:13:19,  1.87it/s, lr=1.48e-7, step_loss=0.0097907/20/2023 16:18:16 - INFO - __main__ - train loss is 10.05000212858431\n",
      "Steps:   0%|   | 70/15000 [00:38<2:13:04,  1.87it/s, lr=1.5e-7, step_loss=0.304]07/20/2023 16:18:17 - INFO - __main__ - train loss is 10.40907794306986\n",
      "Steps:   0%|  | 71/15000 [00:39<2:13:22,  1.87it/s, lr=1.53e-7, step_loss=0.359]07/20/2023 16:18:17 - INFO - __main__ - train loss is 10.418338617077097\n",
      "Steps:   0%| | 72/15000 [00:39<2:13:06,  1.87it/s, lr=1.55e-7, step_loss=0.0092607/20/2023 16:18:18 - INFO - __main__ - train loss is 10.427196306874976\n",
      "Steps:   0%| | 73/15000 [00:40<2:13:09,  1.87it/s, lr=1.58e-7, step_loss=0.0088607/20/2023 16:18:18 - INFO - __main__ - train loss is 10.431537722470239\n",
      "Steps:   0%| | 74/15000 [00:40<2:13:13,  1.87it/s, lr=1.6e-7, step_loss=0.00434]07/20/2023 16:18:19 - INFO - __main__ - train loss is 10.463800293626264\n",
      "Steps:   0%| | 75/15000 [00:41<2:13:58,  1.86it/s, lr=1.63e-7, step_loss=0.0323]07/20/2023 16:18:20 - INFO - __main__ - train loss is 10.469310890184715\n",
      "Steps:   1%| | 76/15000 [00:42<2:13:51,  1.86it/s, lr=1.65e-7, step_loss=0.0055107/20/2023 16:18:20 - INFO - __main__ - train loss is 10.68576906179078\n",
      "Steps:   1%|  | 77/15000 [00:42<2:14:44,  1.85it/s, lr=1.68e-7, step_loss=0.216]07/20/2023 16:18:21 - INFO - __main__ - train loss is 11.101437221514061\n",
      "Steps:   1%|   | 78/15000 [00:43<2:14:31,  1.85it/s, lr=1.7e-7, step_loss=0.416]07/20/2023 16:18:21 - INFO - __main__ - train loss is 11.354274044977501\n",
      "Steps:   1%|  | 79/15000 [00:43<2:14:47,  1.85it/s, lr=1.73e-7, step_loss=0.253]07/20/2023 16:18:22 - INFO - __main__ - train loss is 11.404543242650107\n",
      "Steps:   1%| | 80/15000 [00:44<2:14:59,  1.84it/s, lr=1.75e-7, step_loss=0.0503]07/20/2023 16:18:22 - INFO - __main__ - train loss is 11.866512201027945\n",
      "Steps:   1%|  | 81/15000 [00:44<2:14:57,  1.84it/s, lr=1.77e-7, step_loss=0.462]07/20/2023 16:18:23 - INFO - __main__ - train loss is 11.960475526051596\n",
      "Steps:   1%|   | 82/15000 [00:45<2:14:42,  1.85it/s, lr=1.8e-7, step_loss=0.094]07/20/2023 16:18:23 - INFO - __main__ - train loss is 12.482522092061117\n",
      "Steps:   1%|  | 83/15000 [00:45<2:14:27,  1.85it/s, lr=1.82e-7, step_loss=0.522]07/20/2023 16:18:24 - INFO - __main__ - train loss is 12.496324469568208\n",
      "Steps:   1%| | 84/15000 [00:46<2:14:15,  1.85it/s, lr=1.85e-7, step_loss=0.0138]07/20/2023 16:18:24 - INFO - __main__ - train loss is 12.741820489289239\n",
      "Steps:   1%|  | 85/15000 [00:46<2:14:00,  1.85it/s, lr=1.88e-7, step_loss=0.245]07/20/2023 16:18:25 - INFO - __main__ - train loss is 12.780306142987683\n",
      "Steps:   1%|  | 86/15000 [00:47<2:13:12,  1.87it/s, lr=1.9e-7, step_loss=0.0385]07/20/2023 16:18:25 - INFO - __main__ - train loss is 12.866597798885778\n",
      "Steps:   1%| | 87/15000 [00:47<2:12:27,  1.88it/s, lr=1.93e-7, step_loss=0.0863]07/20/2023 16:18:26 - INFO - __main__ - train loss is 13.116246995748952\n",
      "Steps:   1%|   | 88/15000 [00:48<2:12:27,  1.88it/s, lr=1.95e-7, step_loss=0.25]07/20/2023 16:18:27 - INFO - __main__ - train loss is 13.340011281194165\n",
      "Steps:   1%|  | 89/15000 [00:49<2:12:29,  1.88it/s, lr=1.98e-7, step_loss=0.224]07/20/2023 16:18:27 - INFO - __main__ - train loss is 13.365306136431172\n",
      "Steps:   1%|    | 90/15000 [00:49<2:12:45,  1.87it/s, lr=2e-7, step_loss=0.0253]07/20/2023 16:18:28 - INFO - __main__ - train loss is 13.546460879268125\n",
      "Steps:   1%|  | 91/15000 [00:50<2:12:55,  1.87it/s, lr=2.03e-7, step_loss=0.181]07/20/2023 16:18:28 - INFO - __main__ - train loss is 13.687394184293225\n",
      "Steps:   1%|  | 92/15000 [00:50<2:15:07,  1.84it/s, lr=2.05e-7, step_loss=0.141]07/20/2023 16:18:29 - INFO - __main__ - train loss is 13.77500527841039\n",
      "Steps:   1%| | 93/15000 [00:51<2:14:06,  1.85it/s, lr=2.08e-7, step_loss=0.0876]07/20/2023 16:18:29 - INFO - __main__ - train loss is 13.865347263636068\n",
      "Steps:   1%|  | 94/15000 [00:51<2:13:52,  1.86it/s, lr=2.1e-7, step_loss=0.0903]07/20/2023 16:18:30 - INFO - __main__ - train loss is 14.314358827890828\n",
      "Steps:   1%|  | 95/15000 [00:52<2:13:19,  1.86it/s, lr=2.13e-7, step_loss=0.449]07/20/2023 16:18:30 - INFO - __main__ - train loss is 14.790324387373403\n",
      "Steps:   1%|  | 96/15000 [00:52<2:13:28,  1.86it/s, lr=2.15e-7, step_loss=0.476]07/20/2023 16:18:31 - INFO - __main__ - train loss is 15.176308599533513\n",
      "Steps:   1%|  | 97/15000 [00:53<2:29:59,  1.66it/s, lr=2.18e-7, step_loss=0.386]07/20/2023 16:18:32 - INFO - __main__ - Per validation step average loss is 0.1073264479637146\n",
      "07/20/2023 16:18:32 - INFO - __main__ - Cumulative validation average loss is 0.1073264479637146\n",
      "07/20/2023 16:18:33 - INFO - __main__ - Per validation step average loss is 0.2173178344964981\n",
      "07/20/2023 16:18:33 - INFO - __main__ - Cumulative validation average loss is 0.3246442824602127\n",
      "07/20/2023 16:18:33 - INFO - __main__ - Per validation step average loss is 0.0018631205894052982\n",
      "07/20/2023 16:18:33 - INFO - __main__ - Cumulative validation average loss is 0.326507403049618\n",
      "07/20/2023 16:18:34 - INFO - __main__ - Per validation step average loss is 0.06568172574043274\n",
      "07/20/2023 16:18:34 - INFO - __main__ - Cumulative validation average loss is 0.39218912879005075\n",
      "07/20/2023 16:18:34 - INFO - __main__ - Per validation step average loss is 0.025664882734417915\n",
      "07/20/2023 16:18:34 - INFO - __main__ - Cumulative validation average loss is 0.41785401152446866\n",
      "07/20/2023 16:18:34 - INFO - __main__ - Per validation step average loss is 0.1680409014225006\n",
      "07/20/2023 16:18:34 - INFO - __main__ - Cumulative validation average loss is 0.5858949129469693\n",
      "07/20/2023 16:18:35 - INFO - __main__ - Per validation step average loss is 0.002870237920433283\n",
      "07/20/2023 16:18:35 - INFO - __main__ - Cumulative validation average loss is 0.5887651508674026\n",
      "07/20/2023 16:18:35 - INFO - __main__ - Per validation step average loss is 0.48324644565582275\n",
      "07/20/2023 16:18:35 - INFO - __main__ - Cumulative validation average loss is 1.0720115965232253\n",
      "07/20/2023 16:18:36 - INFO - __main__ - Per validation step average loss is 0.007974998094141483\n",
      "07/20/2023 16:18:36 - INFO - __main__ - Cumulative validation average loss is 1.0799865946173668\n",
      "07/20/2023 16:18:36 - INFO - __main__ - Per validation step average loss is 0.5823249816894531\n",
      "07/20/2023 16:18:36 - INFO - __main__ - Cumulative validation average loss is 1.66231157630682\n",
      "07/20/2023 16:18:37 - INFO - __main__ - Per validation step average loss is 0.002587338909506798\n",
      "07/20/2023 16:18:37 - INFO - __main__ - Cumulative validation average loss is 1.6648989152163267\n",
      "07/20/2023 16:18:37 - INFO - __main__ - Per validation step average loss is 0.0015767342410981655\n",
      "07/20/2023 16:18:37 - INFO - __main__ - Cumulative validation average loss is 1.6664756494574249\n",
      "07/20/2023 16:18:37 - INFO - __main__ - Average validation loss for Epoch 0 is 0.13887297078811875\n",
      "07/20/2023 16:18:37 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/20/2023 16:18:50 - INFO - __main__ - Starting epoch 1\n",
      "07/20/2023 16:18:51 - INFO - __main__ - train loss is 0.07227408140897751\n",
      "Steps:   1%| | 98/15000 [01:13<26:35:02,  6.42s/it, lr=2.2e-7, step_loss=0.0723]07/20/2023 16:18:51 - INFO - __main__ - train loss is 0.16284336894750595\n",
      "Steps:   1%| | 99/15000 [01:13<18:50:04,  4.55s/it, lr=2.23e-7, step_loss=0.090607/20/2023 16:18:51 - INFO - __main__ - train loss is 0.22647162526845932\n",
      "Steps:   1%| | 100/15000 [01:13<13:25:00,  3.24s/it, lr=2.25e-7, step_loss=0.06307/20/2023 16:18:52 - INFO - __main__ - train loss is 0.9164844378829002\n",
      "Steps:   1%|  | 101/15000 [01:14<9:37:07,  2.32s/it, lr=2.28e-7, step_loss=0.69]07/20/2023 16:18:52 - INFO - __main__ - train loss is 1.1527695879340172\n",
      "Steps:   1%|  | 102/15000 [01:14<6:58:37,  1.69s/it, lr=2.3e-7, step_loss=0.236]07/20/2023 16:18:52 - INFO - __main__ - train loss is 1.157507578842342\n",
      "Steps:   1%| | 103/15000 [01:14<5:08:52,  1.24s/it, lr=2.33e-7, step_loss=0.004707/20/2023 16:18:52 - INFO - __main__ - train loss is 1.394717345945537\n",
      "Steps:   1%| | 104/15000 [01:14<3:51:20,  1.07it/s, lr=2.35e-7, step_loss=0.237]07/20/2023 16:18:52 - INFO - __main__ - train loss is 1.5765910102054477\n",
      "Steps:   1%| | 105/15000 [01:14<2:57:01,  1.40it/s, lr=2.38e-7, step_loss=0.182]07/20/2023 16:18:53 - INFO - __main__ - train loss is 1.5821330528706312\n",
      "Steps:   1%| | 106/15000 [01:15<2:19:16,  1.78it/s, lr=2.4e-7, step_loss=0.0055407/20/2023 16:18:53 - INFO - __main__ - train loss is 1.9544365983456373\n",
      "Steps:   1%| | 107/15000 [01:15<1:53:05,  2.19it/s, lr=2.43e-7, step_loss=0.372]07/20/2023 16:18:53 - INFO - __main__ - train loss is 1.967676498927176\n",
      "Steps:   1%| | 108/15000 [01:15<1:33:37,  2.65it/s, lr=2.45e-7, step_loss=0.013207/20/2023 16:18:53 - INFO - __main__ - train loss is 2.326981225050986\n",
      "Steps:   1%| | 109/15000 [01:15<1:20:52,  3.07it/s, lr=2.48e-7, step_loss=0.359]07/20/2023 16:18:53 - INFO - __main__ - train loss is 2.343717268668115\n",
      "Steps:   1%| | 110/15000 [01:15<1:11:54,  3.45it/s, lr=2.5e-7, step_loss=0.0167]07/20/2023 16:18:54 - INFO - __main__ - train loss is 2.3989699548110366\n",
      "Steps:   1%| | 111/15000 [01:16<1:05:50,  3.77it/s, lr=2.53e-7, step_loss=0.055307/20/2023 16:18:54 - INFO - __main__ - train loss is 3.0384170478209853\n",
      "Steps:   1%| | 112/15000 [01:16<1:00:23,  4.11it/s, lr=2.55e-7, step_loss=0.639]07/20/2023 16:18:54 - INFO - __main__ - train loss is 3.2332262312993407\n",
      "Steps:   1%|   | 113/15000 [01:16<56:22,  4.40it/s, lr=2.58e-7, step_loss=0.195]07/20/2023 16:18:54 - INFO - __main__ - train loss is 3.4215032970532775\n",
      "Steps:   1%|    | 114/15000 [01:16<53:37,  4.63it/s, lr=2.6e-7, step_loss=0.188]07/20/2023 16:18:54 - INFO - __main__ - train loss is 3.783788732253015\n",
      "Steps:   1%|   | 115/15000 [01:16<51:46,  4.79it/s, lr=2.63e-7, step_loss=0.362]07/20/2023 16:18:55 - INFO - __main__ - train loss is 3.9705505883321166\n",
      "Steps:   1%|   | 116/15000 [01:17<50:26,  4.92it/s, lr=2.65e-7, step_loss=0.187]07/20/2023 16:18:55 - INFO - __main__ - train loss is 3.9895753329619765\n",
      "Steps:   1%|   | 117/15000 [01:17<49:08,  5.05it/s, lr=2.68e-7, step_loss=0.019]07/20/2023 16:18:55 - INFO - __main__ - train loss is 4.179261944256723\n",
      "Steps:   1%|     | 118/15000 [01:17<47:48,  5.19it/s, lr=2.7e-7, step_loss=0.19]07/20/2023 16:18:55 - INFO - __main__ - train loss is 4.4568937337026\n",
      "Steps:   1%|   | 119/15000 [01:17<46:50,  5.29it/s, lr=2.73e-7, step_loss=0.278]07/20/2023 16:18:55 - INFO - __main__ - train loss is 4.477199914865196\n",
      "Steps:   1%|  | 120/15000 [01:17<47:07,  5.26it/s, lr=2.75e-7, step_loss=0.0203]07/20/2023 16:18:56 - INFO - __main__ - train loss is 4.482609401457012\n",
      "Steps:   1%| | 121/15000 [01:18<47:12,  5.25it/s, lr=2.78e-7, step_loss=0.00541]07/20/2023 16:18:56 - INFO - __main__ - train loss is 4.723203445784748\n",
      "Steps:   1%|    | 122/15000 [01:18<47:16,  5.24it/s, lr=2.8e-7, step_loss=0.241]07/20/2023 16:18:56 - INFO - __main__ - train loss is 4.898015166632831\n",
      "Steps:   1%|   | 123/15000 [01:18<47:20,  5.24it/s, lr=2.83e-7, step_loss=0.175]07/20/2023 16:18:56 - INFO - __main__ - train loss is 5.756630088202655\n",
      "Steps:   1%|   | 124/15000 [01:18<47:22,  5.23it/s, lr=2.85e-7, step_loss=0.859]07/20/2023 16:18:56 - INFO - __main__ - train loss is 6.504771496169269\n",
      "Steps:   1%|   | 125/15000 [01:18<47:23,  5.23it/s, lr=2.88e-7, step_loss=0.748]07/20/2023 16:18:56 - INFO - __main__ - train loss is 6.50726362131536\n",
      "Steps:   1%|  | 126/15000 [01:19<47:21,  5.23it/s, lr=2.9e-7, step_loss=0.00249]07/20/2023 16:18:57 - INFO - __main__ - train loss is 6.512385792098939\n",
      "Steps:   1%| | 127/15000 [01:19<47:25,  5.23it/s, lr=2.93e-7, step_loss=0.00512]07/20/2023 16:18:57 - INFO - __main__ - train loss is 7.1093286937102675\n",
      "Steps:   1%|   | 128/15000 [01:19<47:27,  5.22it/s, lr=2.95e-7, step_loss=0.597]07/20/2023 16:18:57 - INFO - __main__ - train loss is 7.67278069909662\n",
      "Steps:   1%|   | 129/15000 [01:19<46:41,  5.31it/s, lr=2.98e-7, step_loss=0.563]07/20/2023 16:18:57 - INFO - __main__ - train loss is 7.6825445694848895\n",
      "Steps:   1%|    | 130/15000 [01:19<46:01,  5.39it/s, lr=3e-7, step_loss=0.00976]07/20/2023 16:18:57 - INFO - __main__ - train loss is 7.7346839075908065\n",
      "Steps:   1%|  | 131/15000 [01:19<45:35,  5.44it/s, lr=3.03e-7, step_loss=0.0521]07/20/2023 16:18:58 - INFO - __main__ - train loss is 8.066396570764482\n",
      "Steps:   1%|   | 132/15000 [01:20<45:17,  5.47it/s, lr=3.05e-7, step_loss=0.332]07/20/2023 16:18:58 - INFO - __main__ - train loss is 8.072134383022785\n",
      "Steps:   1%| | 133/15000 [01:20<45:08,  5.49it/s, lr=3.08e-7, step_loss=0.00574]07/20/2023 16:18:58 - INFO - __main__ - train loss is 8.763131745159626\n",
      "Steps:   1%|    | 134/15000 [01:20<44:58,  5.51it/s, lr=3.1e-7, step_loss=0.691]07/20/2023 16:18:58 - INFO - __main__ - train loss is 8.814098812639713\n",
      "Steps:   1%|   | 135/15000 [01:20<44:51,  5.52it/s, lr=3.13e-7, step_loss=0.051]07/20/2023 16:18:58 - INFO - __main__ - train loss is 8.932366281747818\n",
      "Steps:   1%|   | 136/15000 [01:20<44:43,  5.54it/s, lr=3.15e-7, step_loss=0.118]07/20/2023 16:18:59 - INFO - __main__ - train loss is 9.126403629779816\n",
      "Steps:   1%|   | 137/15000 [01:21<44:39,  5.55it/s, lr=3.18e-7, step_loss=0.194]07/20/2023 16:18:59 - INFO - __main__ - train loss is 9.407424122095108\n",
      "Steps:   1%|    | 138/15000 [01:21<44:38,  5.55it/s, lr=3.2e-7, step_loss=0.281]07/20/2023 16:18:59 - INFO - __main__ - train loss is 9.43723713979125\n",
      "Steps:   1%|  | 139/15000 [01:21<44:36,  5.55it/s, lr=3.23e-7, step_loss=0.0298]07/20/2023 16:18:59 - INFO - __main__ - train loss is 9.448951415717602\n",
      "Steps:   1%|  | 140/15000 [01:21<44:35,  5.55it/s, lr=3.25e-7, step_loss=0.0117]07/20/2023 16:18:59 - INFO - __main__ - train loss is 9.642512194812298\n",
      "Steps:   1%|   | 141/15000 [01:21<44:35,  5.55it/s, lr=3.28e-7, step_loss=0.194]07/20/2023 16:18:59 - INFO - __main__ - train loss is 10.092045836150646\n",
      "Steps:   1%|     | 142/15000 [01:21<44:34,  5.56it/s, lr=3.3e-7, step_loss=0.45]07/20/2023 16:19:00 - INFO - __main__ - train loss is 10.181070275604725\n",
      "Steps:   1%|   | 143/15000 [01:22<44:36,  5.55it/s, lr=3.33e-7, step_loss=0.089]07/20/2023 16:19:00 - INFO - __main__ - train loss is 10.235118925571442\n",
      "Steps:   1%|   | 144/15000 [01:22<44:34,  5.55it/s, lr=3.35e-7, step_loss=0.054]07/20/2023 16:19:00 - INFO - __main__ - train loss is 10.273112270981073\n",
      "Steps:   1%|   | 145/15000 [01:22<44:35,  5.55it/s, lr=3.38e-7, step_loss=0.038]07/20/2023 16:19:00 - INFO - __main__ - train loss is 10.459960389882326\n",
      "Steps:   1%|    | 146/15000 [01:22<44:35,  5.55it/s, lr=3.4e-7, step_loss=0.187]07/20/2023 16:19:00 - INFO - __main__ - train loss is 10.466020916588604\n",
      "Steps:   1%| | 147/15000 [01:22<44:36,  5.55it/s, lr=3.43e-7, step_loss=0.00606]07/20/2023 16:19:00 - INFO - __main__ - train loss is 10.825864111073315\n",
      "Steps:   1%|    | 148/15000 [01:23<44:34,  5.55it/s, lr=3.45e-7, step_loss=0.36]07/20/2023 16:19:01 - INFO - __main__ - train loss is 11.196706865914166\n",
      "Steps:   1%|   | 149/15000 [01:23<44:35,  5.55it/s, lr=3.48e-7, step_loss=0.371]07/20/2023 16:19:01 - INFO - __main__ - train loss is 11.654865269549191\n",
      "Steps:   1%|    | 150/15000 [01:23<44:35,  5.55it/s, lr=3.5e-7, step_loss=0.458]07/20/2023 16:19:01 - INFO - __main__ - train loss is 11.93604997266084\n",
      "Steps:   1%|   | 151/15000 [01:23<44:36,  5.55it/s, lr=3.53e-7, step_loss=0.281]07/20/2023 16:19:01 - INFO - __main__ - train loss is 12.071915511973202\n",
      "Steps:   1%|   | 152/15000 [01:23<44:35,  5.55it/s, lr=3.55e-7, step_loss=0.136]07/20/2023 16:19:01 - INFO - __main__ - train loss is 12.075182673987001\n",
      "Steps:   1%| | 153/15000 [01:23<44:34,  5.55it/s, lr=3.58e-7, step_loss=0.00327]07/20/2023 16:19:02 - INFO - __main__ - train loss is 12.27440827852115\n",
      "Steps:   1%|    | 154/15000 [01:24<44:34,  5.55it/s, lr=3.6e-7, step_loss=0.199]07/20/2023 16:19:02 - INFO - __main__ - train loss is 12.59541886812076\n",
      "Steps:   1%|   | 155/15000 [01:24<44:33,  5.55it/s, lr=3.63e-7, step_loss=0.321]07/20/2023 16:19:02 - INFO - __main__ - train loss is 12.847234485205263\n",
      "Steps:   1%|   | 156/15000 [01:24<44:32,  5.55it/s, lr=3.65e-7, step_loss=0.252]07/20/2023 16:19:02 - INFO - __main__ - train loss is 12.887034398969263\n",
      "Steps:   1%|  | 157/15000 [01:24<44:33,  5.55it/s, lr=3.68e-7, step_loss=0.0398]07/20/2023 16:19:02 - INFO - __main__ - train loss is 12.935489760246128\n",
      "Steps:   1%|   | 158/15000 [01:24<44:33,  5.55it/s, lr=3.7e-7, step_loss=0.0485]07/20/2023 16:19:02 - INFO - __main__ - train loss is 12.976592467632145\n",
      "Steps:   1%|  | 159/15000 [01:25<44:30,  5.56it/s, lr=3.73e-7, step_loss=0.0411]07/20/2023 16:19:03 - INFO - __main__ - train loss is 12.998728610109538\n",
      "Steps:   1%|  | 160/15000 [01:25<44:31,  5.55it/s, lr=3.75e-7, step_loss=0.0221]07/20/2023 16:19:03 - INFO - __main__ - train loss is 13.414813674520701\n",
      "Steps:   1%|   | 161/15000 [01:25<45:40,  5.42it/s, lr=3.78e-7, step_loss=0.416]07/20/2023 16:19:03 - INFO - __main__ - train loss is 13.450504187028855\n",
      "Steps:   1%|   | 162/15000 [01:25<45:18,  5.46it/s, lr=3.8e-7, step_loss=0.0357]07/20/2023 16:19:03 - INFO - __main__ - train loss is 13.45522633381188\n",
      "Steps:   1%| | 163/15000 [01:25<45:04,  5.49it/s, lr=3.83e-7, step_loss=0.00472]07/20/2023 16:19:03 - INFO - __main__ - train loss is 13.46100293006748\n",
      "Steps:   1%| | 164/15000 [01:25<44:51,  5.51it/s, lr=3.85e-7, step_loss=0.00578]07/20/2023 16:19:04 - INFO - __main__ - train loss is 13.463337707333267\n",
      "Steps:   1%| | 165/15000 [01:26<44:44,  5.53it/s, lr=3.88e-7, step_loss=0.00233]07/20/2023 16:19:04 - INFO - __main__ - train loss is 13.465536802075803\n",
      "Steps:   1%|   | 166/15000 [01:26<44:41,  5.53it/s, lr=3.9e-7, step_loss=0.0022]07/20/2023 16:19:04 - INFO - __main__ - train loss is 13.470549639314413\n",
      "Steps:   1%| | 167/15000 [01:26<44:37,  5.54it/s, lr=3.93e-7, step_loss=0.00501]07/20/2023 16:19:04 - INFO - __main__ - train loss is 14.022148605436087\n",
      "Steps:   1%|   | 168/15000 [01:26<44:35,  5.54it/s, lr=3.95e-7, step_loss=0.552]07/20/2023 16:19:04 - INFO - __main__ - train loss is 14.175420012325048\n",
      "Steps:   1%|   | 169/15000 [01:26<44:32,  5.55it/s, lr=3.98e-7, step_loss=0.153]07/20/2023 16:19:04 - INFO - __main__ - train loss is 14.477143432945013\n",
      "Steps:   1%|      | 170/15000 [01:26<44:29,  5.56it/s, lr=4e-7, step_loss=0.302]07/20/2023 16:19:05 - INFO - __main__ - train loss is 14.4887088034302\n",
      "Steps:   1%|  | 171/15000 [01:27<44:31,  5.55it/s, lr=4.03e-7, step_loss=0.0116]07/20/2023 16:19:05 - INFO - __main__ - train loss is 14.550312781706452\n",
      "Steps:   1%|  | 172/15000 [01:27<44:31,  5.55it/s, lr=4.05e-7, step_loss=0.0616]07/20/2023 16:19:05 - INFO - __main__ - train loss is 14.814814085140824\n",
      "Steps:   1%|   | 173/15000 [01:27<44:30,  5.55it/s, lr=4.08e-7, step_loss=0.265]07/20/2023 16:19:05 - INFO - __main__ - train loss is 15.084300810471177\n",
      "Steps:   1%|    | 174/15000 [01:27<44:30,  5.55it/s, lr=4.1e-7, step_loss=0.269]07/20/2023 16:19:05 - INFO - __main__ - train loss is 15.091043046209961\n",
      "Steps:   1%| | 175/15000 [01:27<44:29,  5.55it/s, lr=4.13e-7, step_loss=0.00674]07/20/2023 16:19:06 - INFO - __main__ - train loss is 15.167944370303303\n",
      "Steps:   1%|  | 176/15000 [01:28<44:26,  5.56it/s, lr=4.15e-7, step_loss=0.0769]07/20/2023 16:19:06 - INFO - __main__ - train loss is 15.703493355307728\n",
      "Steps:   1%|   | 177/15000 [01:28<44:24,  5.56it/s, lr=4.18e-7, step_loss=0.536]07/20/2023 16:19:06 - INFO - __main__ - train loss is 15.897231160197407\n",
      "Steps:   1%|    | 178/15000 [01:28<44:10,  5.59it/s, lr=4.2e-7, step_loss=0.194]07/20/2023 16:19:06 - INFO - __main__ - train loss is 16.306213526520878\n",
      "Steps:   1%|   | 179/15000 [01:28<44:02,  5.61it/s, lr=4.23e-7, step_loss=0.409]07/20/2023 16:19:06 - INFO - __main__ - train loss is 16.313781574834138\n",
      "Steps:   1%| | 180/15000 [01:28<43:55,  5.62it/s, lr=4.25e-7, step_loss=0.00757]07/20/2023 16:19:06 - INFO - __main__ - train loss is 16.348440882284194\n",
      "Steps:   1%|  | 181/15000 [01:28<43:52,  5.63it/s, lr=4.28e-7, step_loss=0.0347]07/20/2023 16:19:07 - INFO - __main__ - train loss is 16.575757172424346\n",
      "Steps:   1%|    | 182/15000 [01:29<43:48,  5.64it/s, lr=4.3e-7, step_loss=0.227]07/20/2023 16:19:07 - INFO - __main__ - train loss is 16.58801705436781\n",
      "Steps:   1%|  | 183/15000 [01:29<43:47,  5.64it/s, lr=4.32e-7, step_loss=0.0123]07/20/2023 16:19:07 - INFO - __main__ - train loss is 16.605506092775613\n",
      "Steps:   1%|  | 184/15000 [01:29<43:44,  5.65it/s, lr=4.35e-7, step_loss=0.0175]07/20/2023 16:19:07 - INFO - __main__ - train loss is 16.630361753050238\n",
      "Steps:   1%|  | 185/15000 [01:29<43:42,  5.65it/s, lr=4.37e-7, step_loss=0.0249]07/20/2023 16:19:07 - INFO - __main__ - train loss is 16.66689525777474\n",
      "Steps:   1%|   | 186/15000 [01:29<43:41,  5.65it/s, lr=4.4e-7, step_loss=0.0365]07/20/2023 16:19:07 - INFO - __main__ - train loss is 16.669770060339943\n",
      "Steps:   1%| | 187/15000 [01:30<43:40,  5.65it/s, lr=4.42e-7, step_loss=0.00287]07/20/2023 16:19:08 - INFO - __main__ - train loss is 16.71048424229957\n",
      "Steps:   1%|  | 188/15000 [01:30<43:40,  5.65it/s, lr=4.45e-7, step_loss=0.0407]07/20/2023 16:19:08 - INFO - __main__ - train loss is 16.72632041038014\n",
      "Steps:   1%|  | 189/15000 [01:30<43:40,  5.65it/s, lr=4.48e-7, step_loss=0.0158]07/20/2023 16:19:08 - INFO - __main__ - train loss is 16.729224843671545\n",
      "Steps:   1%|   | 190/15000 [01:30<43:39,  5.65it/s, lr=4.5e-7, step_loss=0.0029]07/20/2023 16:19:08 - INFO - __main__ - train loss is 16.86943401186727\n",
      "Steps:   1%|    | 191/15000 [01:30<43:39,  5.65it/s, lr=4.53e-7, step_loss=0.14]07/20/2023 16:19:08 - INFO - __main__ - train loss is 17.023014230420813\n",
      "Steps:   1%|   | 192/15000 [01:30<43:36,  5.66it/s, lr=4.55e-7, step_loss=0.154]07/20/2023 16:19:09 - INFO - __main__ - train loss is 17.10011642961763\n",
      "Steps:   1%|  | 193/15000 [01:31<43:36,  5.66it/s, lr=4.58e-7, step_loss=0.0771]07/20/2023 16:19:09 - INFO - __main__ - train loss is 17.46392315416597\n",
      "Steps:   1%|    | 194/15000 [01:31<58:42,  4.20it/s, lr=4.6e-7, step_loss=0.364]07/20/2023 16:19:10 - INFO - __main__ - Per validation step average loss is 0.13315339386463165\n",
      "07/20/2023 16:19:10 - INFO - __main__ - Cumulative validation average loss is 0.13315339386463165\n",
      "07/20/2023 16:19:11 - INFO - __main__ - Per validation step average loss is 0.4887844920158386\n",
      "07/20/2023 16:19:11 - INFO - __main__ - Cumulative validation average loss is 0.6219378858804703\n",
      "07/20/2023 16:19:11 - INFO - __main__ - Per validation step average loss is 0.04262934625148773\n",
      "07/20/2023 16:19:11 - INFO - __main__ - Cumulative validation average loss is 0.664567232131958\n",
      "07/20/2023 16:19:11 - INFO - __main__ - Per validation step average loss is 0.7245981693267822\n",
      "07/20/2023 16:19:11 - INFO - __main__ - Cumulative validation average loss is 1.3891654014587402\n",
      "07/20/2023 16:19:12 - INFO - __main__ - Per validation step average loss is 0.08172588050365448\n",
      "07/20/2023 16:19:12 - INFO - __main__ - Cumulative validation average loss is 1.4708912819623947\n",
      "07/20/2023 16:19:12 - INFO - __main__ - Per validation step average loss is 0.36865487694740295\n",
      "07/20/2023 16:19:12 - INFO - __main__ - Cumulative validation average loss is 1.8395461589097977\n",
      "07/20/2023 16:19:13 - INFO - __main__ - Per validation step average loss is 0.01282312348484993\n",
      "07/20/2023 16:19:13 - INFO - __main__ - Cumulative validation average loss is 1.8523692823946476\n",
      "07/20/2023 16:19:13 - INFO - __main__ - Per validation step average loss is 0.6073144674301147\n",
      "07/20/2023 16:19:13 - INFO - __main__ - Cumulative validation average loss is 2.4596837498247623\n",
      "07/20/2023 16:19:14 - INFO - __main__ - Per validation step average loss is 0.010268609039485455\n",
      "07/20/2023 16:19:14 - INFO - __main__ - Cumulative validation average loss is 2.469952358864248\n",
      "07/20/2023 16:19:14 - INFO - __main__ - Per validation step average loss is 0.036561090499162674\n",
      "07/20/2023 16:19:14 - INFO - __main__ - Cumulative validation average loss is 2.5065134493634105\n",
      "07/20/2023 16:19:14 - INFO - __main__ - Per validation step average loss is 0.007793747819960117\n",
      "07/20/2023 16:19:14 - INFO - __main__ - Cumulative validation average loss is 2.5143071971833706\n",
      "07/20/2023 16:19:15 - INFO - __main__ - Per validation step average loss is 0.004540756344795227\n",
      "07/20/2023 16:19:15 - INFO - __main__ - Cumulative validation average loss is 2.518847953528166\n",
      "07/20/2023 16:19:15 - INFO - __main__ - Average validation loss for Epoch 1 is 0.20990399612734714\n",
      "07/20/2023 16:19:15 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/20/2023 16:19:28 - INFO - __main__ - Starting epoch 2\n",
      "07/20/2023 16:19:28 - INFO - __main__ - train loss is 0.09089647233486176\n",
      "Steps:   1%| | 195/15000 [01:50<24:34:29,  5.98s/it, lr=4.63e-7, step_loss=0.09007/20/2023 16:19:28 - INFO - __main__ - train loss is 0.22092828154563904\n",
      "Steps:   1%| | 196/15000 [01:51<17:26:04,  4.24s/it, lr=4.65e-7, step_loss=0.13]07/20/2023 16:19:29 - INFO - __main__ - train loss is 0.24052719399333\n",
      "Steps:   1%| | 197/15000 [01:51<12:26:30,  3.03s/it, lr=4.68e-7, step_loss=0.01907/20/2023 16:19:29 - INFO - __main__ - train loss is 0.2883717976510525\n",
      "Steps:   1%| | 198/15000 [01:51<8:56:59,  2.18s/it, lr=4.7e-7, step_loss=0.0478]07/20/2023 16:19:29 - INFO - __main__ - train loss is 0.8235673271119595\n",
      "Steps:   1%| | 199/15000 [01:51<6:30:22,  1.58s/it, lr=4.73e-7, step_loss=0.535]07/20/2023 16:19:29 - INFO - __main__ - train loss is 1.0893151722848415\n",
      "Steps:   1%| | 200/15000 [01:51<4:51:30,  1.18s/it, lr=4.75e-7, step_loss=0.266]07/20/2023 16:19:29 - INFO - __main__ - train loss is 1.137398425489664\n",
      "Steps:   1%| | 201/15000 [01:52<3:39:35,  1.12it/s, lr=4.78e-7, step_loss=0.048107/20/2023 16:19:30 - INFO - __main__ - train loss is 1.27300139144063\n",
      "Steps:   1%|  | 202/15000 [01:52<2:50:20,  1.45it/s, lr=4.8e-7, step_loss=0.136]07/20/2023 16:19:30 - INFO - __main__ - train loss is 1.598244447261095\n",
      "Steps:   1%| | 203/15000 [01:52<2:15:54,  1.81it/s, lr=4.83e-7, step_loss=0.325]07/20/2023 16:19:30 - INFO - __main__ - train loss is 1.6400908306241035\n",
      "Steps:   1%| | 204/15000 [01:52<1:51:43,  2.21it/s, lr=4.85e-7, step_loss=0.041807/20/2023 16:19:30 - INFO - __main__ - train loss is 1.6462014145217836\n",
      "Steps:   1%| | 205/15000 [01:52<1:34:43,  2.60it/s, lr=4.88e-7, step_loss=0.006107/20/2023 16:19:31 - INFO - __main__ - train loss is 1.6490645909216255\n",
      "Steps:   1%| | 206/15000 [01:53<1:22:49,  2.98it/s, lr=4.9e-7, step_loss=0.0028607/20/2023 16:19:31 - INFO - __main__ - train loss is 1.6690425330307335\n",
      "Steps:   1%|  | 207/15000 [01:53<1:13:41,  3.35it/s, lr=4.93e-7, step_loss=0.02]07/20/2023 16:19:31 - INFO - __main__ - train loss is 2.1223428898956627\n",
      "Steps:   1%| | 208/15000 [01:53<1:06:36,  3.70it/s, lr=4.95e-7, step_loss=0.453]07/20/2023 16:19:31 - INFO - __main__ - train loss is 2.7416867667343467\n",
      "Steps:   1%| | 209/15000 [01:53<1:01:13,  4.03it/s, lr=4.98e-7, step_loss=0.619]07/20/2023 16:19:31 - INFO - __main__ - train loss is 2.8532766753342003\n",
      "Steps:   1%|      | 210/15000 [01:54<58:27,  4.22it/s, lr=5e-7, step_loss=0.112]07/20/2023 16:19:32 - INFO - __main__ - train loss is 2.87128011113964\n",
      "Steps:   1%|   | 211/15000 [01:54<55:10,  4.47it/s, lr=5.03e-7, step_loss=0.018]07/20/2023 16:19:32 - INFO - __main__ - train loss is 3.0814268661197275\n",
      "Steps:   1%|    | 212/15000 [01:54<52:45,  4.67it/s, lr=5.05e-7, step_loss=0.21]07/20/2023 16:19:32 - INFO - __main__ - train loss is 3.1128937189932913\n",
      "Steps:   1%|  | 213/15000 [01:54<50:26,  4.89it/s, lr=5.08e-7, step_loss=0.0315]07/20/2023 16:19:32 - INFO - __main__ - train loss is 3.338452655589208\n",
      "Steps:   1%|    | 214/15000 [01:54<48:37,  5.07it/s, lr=5.1e-7, step_loss=0.226]07/20/2023 16:19:32 - INFO - __main__ - train loss is 3.451711702859029\n",
      "Steps:   1%|   | 215/15000 [01:54<47:07,  5.23it/s, lr=5.12e-7, step_loss=0.113]07/20/2023 16:19:33 - INFO - __main__ - train loss is 3.493570107733831\n",
      "Steps:   1%|  | 216/15000 [01:55<46:30,  5.30it/s, lr=5.15e-7, step_loss=0.0419]07/20/2023 16:19:33 - INFO - __main__ - train loss is 3.509413387393579\n",
      "Steps:   1%|  | 217/15000 [01:55<45:56,  5.36it/s, lr=5.18e-7, step_loss=0.0158]07/20/2023 16:19:33 - INFO - __main__ - train loss is 3.7262925615068525\n",
      "Steps:   1%|    | 218/15000 [01:55<45:17,  5.44it/s, lr=5.2e-7, step_loss=0.217]07/20/2023 16:19:33 - INFO - __main__ - train loss is 3.729714296059683\n",
      "Steps:   1%| | 219/15000 [01:55<45:10,  5.45it/s, lr=5.22e-7, step_loss=0.00342]07/20/2023 16:19:33 - INFO - __main__ - train loss is 3.792974717216566\n",
      "Steps:   1%|  | 220/15000 [01:55<44:54,  5.49it/s, lr=5.25e-7, step_loss=0.0633]07/20/2023 16:19:33 - INFO - __main__ - train loss is 3.7966904325876385\n",
      "Steps:   1%| | 221/15000 [01:56<44:33,  5.53it/s, lr=5.28e-7, step_loss=0.00372]07/20/2023 16:19:34 - INFO - __main__ - train loss is 4.09820762113668\n",
      "Steps:   1%|    | 222/15000 [01:56<44:16,  5.56it/s, lr=5.3e-7, step_loss=0.302]07/20/2023 16:19:34 - INFO - __main__ - train loss is 4.364816962042823\n",
      "Steps:   1%|   | 223/15000 [01:56<44:04,  5.59it/s, lr=5.32e-7, step_loss=0.267]07/20/2023 16:19:34 - INFO - __main__ - train loss is 4.374944545561448\n",
      "Steps:   1%|  | 224/15000 [01:56<43:56,  5.60it/s, lr=5.35e-7, step_loss=0.0101]07/20/2023 16:19:34 - INFO - __main__ - train loss is 5.296098448568955\n",
      "Steps:   2%|   | 225/15000 [01:56<43:53,  5.61it/s, lr=5.38e-7, step_loss=0.921]07/20/2023 16:19:34 - INFO - __main__ - train loss is 5.309521652990952\n",
      "Steps:   2%|   | 226/15000 [01:56<43:50,  5.62it/s, lr=5.4e-7, step_loss=0.0134]07/20/2023 16:19:35 - INFO - __main__ - train loss is 5.954188086325303\n",
      "Steps:   2%|   | 227/15000 [01:57<43:48,  5.62it/s, lr=5.42e-7, step_loss=0.645]07/20/2023 16:19:35 - INFO - __main__ - train loss is 6.233511217171326\n",
      "Steps:   2%|   | 228/15000 [01:57<43:45,  5.63it/s, lr=5.45e-7, step_loss=0.279]07/20/2023 16:19:35 - INFO - __main__ - train loss is 6.317911394173279\n",
      "Steps:   2%|  | 229/15000 [01:57<43:44,  5.63it/s, lr=5.48e-7, step_loss=0.0844]07/20/2023 16:19:35 - INFO - __main__ - train loss is 6.423391096526757\n",
      "Steps:   2%|    | 230/15000 [01:57<43:41,  5.63it/s, lr=5.5e-7, step_loss=0.105]07/20/2023 16:19:35 - INFO - __main__ - train loss is 6.926276855403557\n",
      "Steps:   2%|   | 231/15000 [01:57<43:40,  5.64it/s, lr=5.53e-7, step_loss=0.503]07/20/2023 16:19:35 - INFO - __main__ - train loss is 7.014967866474763\n",
      "Steps:   2%|  | 232/15000 [01:57<43:38,  5.64it/s, lr=5.55e-7, step_loss=0.0887]07/20/2023 16:19:36 - INFO - __main__ - train loss is 7.1233699100557715\n",
      "Steps:   2%|   | 233/15000 [01:58<43:40,  5.64it/s, lr=5.58e-7, step_loss=0.108]07/20/2023 16:19:36 - INFO - __main__ - train loss is 7.244876094395295\n",
      "Steps:   2%|    | 234/15000 [01:58<43:40,  5.63it/s, lr=5.6e-7, step_loss=0.122]07/20/2023 16:19:36 - INFO - __main__ - train loss is 7.617160119349137\n",
      "Steps:   2%|   | 235/15000 [01:58<43:40,  5.63it/s, lr=5.63e-7, step_loss=0.372]07/20/2023 16:19:36 - INFO - __main__ - train loss is 7.6791566463653\n",
      "Steps:   2%|   | 236/15000 [01:58<43:47,  5.62it/s, lr=5.65e-7, step_loss=0.062]07/20/2023 16:19:36 - INFO - __main__ - train loss is 7.881058439845219\n",
      "Steps:   2%|   | 237/15000 [01:58<43:46,  5.62it/s, lr=5.68e-7, step_loss=0.202]07/20/2023 16:19:36 - INFO - __main__ - train loss is 8.23644344531931\n",
      "Steps:   2%|    | 238/15000 [01:59<43:51,  5.61it/s, lr=5.7e-7, step_loss=0.355]07/20/2023 16:19:37 - INFO - __main__ - train loss is 8.510843560332432\n",
      "Steps:   2%|   | 239/15000 [01:59<44:23,  5.54it/s, lr=5.73e-7, step_loss=0.274]07/20/2023 16:19:37 - INFO - __main__ - train loss is 8.676175609463826\n",
      "Steps:   2%|   | 240/15000 [01:59<44:11,  5.57it/s, lr=5.75e-7, step_loss=0.165]07/20/2023 16:19:37 - INFO - __main__ - train loss is 9.208311096066609\n",
      "Steps:   2%|   | 241/15000 [01:59<44:17,  5.55it/s, lr=5.78e-7, step_loss=0.532]07/20/2023 16:19:37 - INFO - __main__ - train loss is 9.237515930319205\n",
      "Steps:   2%|   | 242/15000 [01:59<44:05,  5.58it/s, lr=5.8e-7, step_loss=0.0292]07/20/2023 16:19:37 - INFO - __main__ - train loss is 9.370156023884192\n",
      "Steps:   2%|   | 243/15000 [01:59<44:01,  5.59it/s, lr=5.83e-7, step_loss=0.133]07/20/2023 16:19:38 - INFO - __main__ - train loss is 9.970969889545813\n",
      "Steps:   2%|   | 244/15000 [02:00<44:12,  5.56it/s, lr=5.85e-7, step_loss=0.601]07/20/2023 16:19:38 - INFO - __main__ - train loss is 10.013434391701594\n",
      "Steps:   2%|  | 245/15000 [02:00<44:10,  5.57it/s, lr=5.87e-7, step_loss=0.0425]07/20/2023 16:19:38 - INFO - __main__ - train loss is 10.187447604024783\n",
      "Steps:   2%|    | 246/15000 [02:00<44:00,  5.59it/s, lr=5.9e-7, step_loss=0.174]07/20/2023 16:19:38 - INFO - __main__ - train loss is 10.189226786606014\n",
      "Steps:   2%| | 247/15000 [02:00<43:55,  5.60it/s, lr=5.93e-7, step_loss=0.00178]07/20/2023 16:19:38 - INFO - __main__ - train loss is 10.371366093866527\n",
      "Steps:   2%|   | 248/15000 [02:00<43:53,  5.60it/s, lr=5.95e-7, step_loss=0.182]07/20/2023 16:19:38 - INFO - __main__ - train loss is 10.52447276841849\n",
      "Steps:   2%|   | 249/15000 [02:01<43:52,  5.60it/s, lr=5.97e-7, step_loss=0.153]07/20/2023 16:19:39 - INFO - __main__ - train loss is 10.587687621824443\n",
      "Steps:   2%|     | 250/15000 [02:01<43:50,  5.61it/s, lr=6e-7, step_loss=0.0632]07/20/2023 16:19:39 - INFO - __main__ - train loss is 10.835882435552776\n",
      "Steps:   2%|   | 251/15000 [02:01<43:48,  5.61it/s, lr=6.03e-7, step_loss=0.248]07/20/2023 16:19:39 - INFO - __main__ - train loss is 10.977645586244762\n",
      "Steps:   2%|   | 252/15000 [02:01<44:09,  5.57it/s, lr=6.05e-7, step_loss=0.142]07/20/2023 16:19:39 - INFO - __main__ - train loss is 10.993730907328427\n",
      "Steps:   2%|  | 253/15000 [02:01<44:26,  5.53it/s, lr=6.08e-7, step_loss=0.0161]07/20/2023 16:19:39 - INFO - __main__ - train loss is 11.033542864955962\n",
      "Steps:   2%|   | 254/15000 [02:01<44:24,  5.53it/s, lr=6.1e-7, step_loss=0.0398]07/20/2023 16:19:40 - INFO - __main__ - train loss is 11.035516761709005\n",
      "Steps:   2%| | 255/15000 [02:02<44:33,  5.51it/s, lr=6.13e-7, step_loss=0.00197]07/20/2023 16:19:40 - INFO - __main__ - train loss is 11.24273418681696\n",
      "Steps:   2%|   | 256/15000 [02:02<44:23,  5.54it/s, lr=6.15e-7, step_loss=0.207]07/20/2023 16:19:40 - INFO - __main__ - train loss is 11.711540393996984\n",
      "Steps:   2%|   | 257/15000 [02:02<44:07,  5.57it/s, lr=6.18e-7, step_loss=0.469]07/20/2023 16:19:40 - INFO - __main__ - train loss is 11.759700928349048\n",
      "Steps:   2%|   | 258/15000 [02:02<44:03,  5.58it/s, lr=6.2e-7, step_loss=0.0482]07/20/2023 16:19:40 - INFO - __main__ - train loss is 11.834527347702533\n",
      "Steps:   2%|  | 259/15000 [02:02<43:52,  5.60it/s, lr=6.23e-7, step_loss=0.0748]07/20/2023 16:19:40 - INFO - __main__ - train loss is 12.056737307924777\n",
      "Steps:   2%|   | 260/15000 [02:02<43:46,  5.61it/s, lr=6.25e-7, step_loss=0.222]07/20/2023 16:19:41 - INFO - __main__ - train loss is 12.132422332186252\n",
      "Steps:   2%|  | 261/15000 [02:03<43:43,  5.62it/s, lr=6.28e-7, step_loss=0.0757]07/20/2023 16:19:41 - INFO - __main__ - train loss is 12.288347471971065\n",
      "Steps:   2%|    | 262/15000 [02:03<43:39,  5.63it/s, lr=6.3e-7, step_loss=0.156]07/20/2023 16:19:41 - INFO - __main__ - train loss is 12.304318849463016\n",
      "Steps:   2%|   | 263/15000 [02:03<43:40,  5.62it/s, lr=6.33e-7, step_loss=0.016]07/20/2023 16:19:41 - INFO - __main__ - train loss is 12.746278170961887\n",
      "Steps:   2%|   | 264/15000 [02:03<43:38,  5.63it/s, lr=6.35e-7, step_loss=0.442]07/20/2023 16:19:41 - INFO - __main__ - train loss is 13.079340015072376\n",
      "Steps:   2%|   | 265/15000 [02:03<43:36,  5.63it/s, lr=6.38e-7, step_loss=0.333]07/20/2023 16:19:42 - INFO - __main__ - train loss is 13.156236727256328\n",
      "Steps:   2%|   | 266/15000 [02:04<43:34,  5.64it/s, lr=6.4e-7, step_loss=0.0769]07/20/2023 16:19:42 - INFO - __main__ - train loss is 13.162114330101758\n",
      "Steps:   2%| | 267/15000 [02:04<43:32,  5.64it/s, lr=6.43e-7, step_loss=0.00588]07/20/2023 16:19:42 - INFO - __main__ - train loss is 13.337084956932813\n",
      "Steps:   2%|   | 268/15000 [02:04<43:31,  5.64it/s, lr=6.45e-7, step_loss=0.175]07/20/2023 16:19:42 - INFO - __main__ - train loss is 13.599093981552869\n",
      "Steps:   2%|   | 269/15000 [02:04<43:33,  5.64it/s, lr=6.48e-7, step_loss=0.262]07/20/2023 16:19:42 - INFO - __main__ - train loss is 13.612696823198348\n",
      "Steps:   2%|   | 270/15000 [02:04<43:31,  5.64it/s, lr=6.5e-7, step_loss=0.0136]07/20/2023 16:19:42 - INFO - __main__ - train loss is 13.926426496822387\n",
      "Steps:   2%|   | 271/15000 [02:04<43:30,  5.64it/s, lr=6.53e-7, step_loss=0.314]07/20/2023 16:19:43 - INFO - __main__ - train loss is 14.107385945040733\n",
      "Steps:   2%|   | 272/15000 [02:05<43:31,  5.64it/s, lr=6.55e-7, step_loss=0.181]07/20/2023 16:19:43 - INFO - __main__ - train loss is 14.150985572952777\n",
      "Steps:   2%|  | 273/15000 [02:05<43:32,  5.64it/s, lr=6.58e-7, step_loss=0.0436]07/20/2023 16:19:43 - INFO - __main__ - train loss is 14.33183178724721\n",
      "Steps:   2%|    | 274/15000 [02:05<43:30,  5.64it/s, lr=6.6e-7, step_loss=0.181]07/20/2023 16:19:43 - INFO - __main__ - train loss is 14.334077258361503\n",
      "Steps:   2%| | 275/15000 [02:05<43:30,  5.64it/s, lr=6.63e-7, step_loss=0.00225]07/20/2023 16:19:43 - INFO - __main__ - train loss is 14.407856595469639\n",
      "Steps:   2%|  | 276/15000 [02:05<43:29,  5.64it/s, lr=6.65e-7, step_loss=0.0738]07/20/2023 16:19:43 - INFO - __main__ - train loss is 15.02243794198148\n",
      "Steps:   2%|   | 277/15000 [02:05<43:27,  5.65it/s, lr=6.68e-7, step_loss=0.615]07/20/2023 16:19:44 - INFO - __main__ - train loss is 15.07792102987878\n",
      "Steps:   2%|   | 278/15000 [02:06<43:27,  5.65it/s, lr=6.7e-7, step_loss=0.0555]07/20/2023 16:19:44 - INFO - __main__ - train loss is 15.417455789400265\n",
      "Steps:   2%|    | 279/15000 [02:06<43:23,  5.65it/s, lr=6.73e-7, step_loss=0.34]07/20/2023 16:19:44 - INFO - __main__ - train loss is 15.465733279241249\n",
      "Steps:   2%|  | 280/15000 [02:06<43:25,  5.65it/s, lr=6.75e-7, step_loss=0.0483]07/20/2023 16:19:44 - INFO - __main__ - train loss is 15.623192851198837\n",
      "Steps:   2%|   | 281/15000 [02:06<43:24,  5.65it/s, lr=6.78e-7, step_loss=0.157]07/20/2023 16:19:44 - INFO - __main__ - train loss is 15.635963460197672\n",
      "Steps:   2%|   | 282/15000 [02:06<43:23,  5.65it/s, lr=6.8e-7, step_loss=0.0128]07/20/2023 16:19:45 - INFO - __main__ - train loss is 15.642401440767571\n",
      "Steps:   2%| | 283/15000 [02:07<43:44,  5.61it/s, lr=6.83e-7, step_loss=0.00644]07/20/2023 16:19:45 - INFO - __main__ - train loss is 15.64848207286559\n",
      "Steps:   2%| | 284/15000 [02:07<43:39,  5.62it/s, lr=6.85e-7, step_loss=0.00608]07/20/2023 16:19:45 - INFO - __main__ - train loss is 15.65555338258855\n",
      "Steps:   2%| | 285/15000 [02:07<43:35,  5.63it/s, lr=6.88e-7, step_loss=0.00707]07/20/2023 16:19:45 - INFO - __main__ - train loss is 15.986243826104328\n",
      "Steps:   2%|    | 286/15000 [02:07<43:49,  5.60it/s, lr=6.9e-7, step_loss=0.331]07/20/2023 16:19:45 - INFO - __main__ - train loss is 15.989000253845006\n",
      "Steps:   2%| | 287/15000 [02:07<43:45,  5.60it/s, lr=6.93e-7, step_loss=0.00276]07/20/2023 16:19:45 - INFO - __main__ - train loss is 15.998126996215433\n",
      "Steps:   2%| | 288/15000 [02:07<43:40,  5.61it/s, lr=6.95e-7, step_loss=0.00913]07/20/2023 16:19:46 - INFO - __main__ - train loss is 16.018457063939422\n",
      "Steps:   2%|  | 289/15000 [02:08<43:54,  5.58it/s, lr=6.98e-7, step_loss=0.0203]07/20/2023 16:19:46 - INFO - __main__ - train loss is 16.157575914170593\n",
      "Steps:   2%|      | 290/15000 [02:08<43:48,  5.60it/s, lr=7e-7, step_loss=0.139]07/20/2023 16:19:46 - INFO - __main__ - train loss is 16.165588466916233\n",
      "Steps:   2%| | 291/15000 [02:08<58:40,  4.18it/s, lr=7.03e-7, step_loss=0.00801]07/20/2023 16:19:47 - INFO - __main__ - Per validation step average loss is 0.015403805300593376\n",
      "07/20/2023 16:19:47 - INFO - __main__ - Cumulative validation average loss is 0.015403805300593376\n",
      "07/20/2023 16:19:48 - INFO - __main__ - Per validation step average loss is 0.002126630861312151\n",
      "07/20/2023 16:19:48 - INFO - __main__ - Cumulative validation average loss is 0.017530436161905527\n",
      "07/20/2023 16:19:48 - INFO - __main__ - Per validation step average loss is 0.08306875824928284\n",
      "07/20/2023 16:19:48 - INFO - __main__ - Cumulative validation average loss is 0.10059919441118836\n",
      "07/20/2023 16:19:48 - INFO - __main__ - Per validation step average loss is 0.3178172707557678\n",
      "07/20/2023 16:19:48 - INFO - __main__ - Cumulative validation average loss is 0.4184164651669562\n",
      "07/20/2023 16:19:49 - INFO - __main__ - Per validation step average loss is 0.14660920202732086\n",
      "07/20/2023 16:19:49 - INFO - __main__ - Cumulative validation average loss is 0.565025667194277\n",
      "07/20/2023 16:19:49 - INFO - __main__ - Per validation step average loss is 0.0019226539880037308\n",
      "07/20/2023 16:19:49 - INFO - __main__ - Cumulative validation average loss is 0.5669483211822808\n",
      "07/20/2023 16:19:50 - INFO - __main__ - Per validation step average loss is 0.20793454349040985\n",
      "07/20/2023 16:19:50 - INFO - __main__ - Cumulative validation average loss is 0.7748828646726906\n",
      "07/20/2023 16:19:50 - INFO - __main__ - Per validation step average loss is 0.4666273295879364\n",
      "07/20/2023 16:19:50 - INFO - __main__ - Cumulative validation average loss is 1.241510194260627\n",
      "07/20/2023 16:19:51 - INFO - __main__ - Per validation step average loss is 0.08905747532844543\n",
      "07/20/2023 16:19:51 - INFO - __main__ - Cumulative validation average loss is 1.3305676695890725\n",
      "07/20/2023 16:19:51 - INFO - __main__ - Per validation step average loss is 0.007145795971155167\n",
      "07/20/2023 16:19:51 - INFO - __main__ - Cumulative validation average loss is 1.3377134655602276\n",
      "07/20/2023 16:19:52 - INFO - __main__ - Per validation step average loss is 0.07087083160877228\n",
      "07/20/2023 16:19:52 - INFO - __main__ - Cumulative validation average loss is 1.408584297169\n",
      "07/20/2023 16:19:52 - INFO - __main__ - Per validation step average loss is 0.0034706227015703917\n",
      "07/20/2023 16:19:52 - INFO - __main__ - Cumulative validation average loss is 1.4120549198705703\n",
      "07/20/2023 16:19:52 - INFO - __main__ - Average validation loss for Epoch 2 is 0.11767124332254753\n",
      "07/20/2023 16:19:52 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "07/20/2023 16:20:05 - INFO - __main__ - Starting epoch 3\n",
      "07/20/2023 16:20:05 - INFO - __main__ - train loss is 0.24799680709838867\n",
      "Steps:   2%| | 292/15000 [02:27<24:13:25,  5.93s/it, lr=7.05e-7, step_loss=0.24807/20/2023 16:20:06 - INFO - __main__ - train loss is 0.28515952080488205\n",
      "Steps:   2%| | 293/15000 [02:28<17:10:27,  4.20s/it, lr=7.08e-7, step_loss=0.03707/20/2023 16:20:06 - INFO - __main__ - train loss is 0.5268717035651207\n",
      "Steps:   2%| | 294/15000 [02:28<12:14:51,  3.00s/it, lr=7.1e-7, step_loss=0.242]07/20/2023 16:20:06 - INFO - __main__ - train loss is 0.5969209969043732\n",
      "Steps:   2%|  | 295/15000 [02:28<8:47:23,  2.15s/it, lr=7.12e-7, step_loss=0.07]07/20/2023 16:20:06 - INFO - __main__ - train loss is 0.598982063587755\n",
      "Steps:   2%| | 296/15000 [02:28<6:22:27,  1.56s/it, lr=7.15e-7, step_loss=0.002007/20/2023 16:20:06 - INFO - __main__ - train loss is 0.6008838566485792\n",
      "Steps:   2%| | 297/15000 [02:28<4:40:43,  1.15s/it, lr=7.18e-7, step_loss=0.001907/20/2023 16:20:06 - INFO - __main__ - train loss is 0.6030436840374023\n",
      "Steps:   2%| | 298/15000 [02:28<3:29:55,  1.17it/s, lr=7.2e-7, step_loss=0.0021607/20/2023 16:20:07 - INFO - __main__ - train loss is 0.9047543492633849\n",
      "Steps:   2%| | 299/15000 [02:29<2:40:03,  1.53it/s, lr=7.22e-7, step_loss=0.302]07/20/2023 16:20:07 - INFO - __main__ - train loss is 0.9229683999437839\n",
      "Steps:   2%| | 300/15000 [02:29<2:05:03,  1.96it/s, lr=7.25e-7, step_loss=0.018207/20/2023 16:20:07 - INFO - __main__ - train loss is 0.9312988494057208\n",
      "Steps:   2%| | 301/15000 [02:29<1:40:34,  2.44it/s, lr=7.28e-7, step_loss=0.008307/20/2023 16:20:07 - INFO - __main__ - train loss is 1.0050035242456943\n",
      "Steps:   2%| | 302/15000 [02:29<1:23:36,  2.93it/s, lr=7.3e-7, step_loss=0.0737]07/20/2023 16:20:07 - INFO - __main__ - train loss is 1.0831620816607028\n",
      "Steps:   2%| | 303/15000 [02:29<1:11:30,  3.43it/s, lr=7.32e-7, step_loss=0.078207/20/2023 16:20:08 - INFO - __main__ - train loss is 1.191907447995618\n",
      "Steps:   2%| | 304/15000 [02:30<1:03:09,  3.88it/s, lr=7.35e-7, step_loss=0.109]07/20/2023 16:20:08 - INFO - __main__ - train loss is 1.3751444343943149\n",
      "Steps:   2%|   | 305/15000 [02:30<57:44,  4.24it/s, lr=7.38e-7, step_loss=0.183]07/20/2023 16:20:08 - INFO - __main__ - train loss is 1.3842931578401476\n",
      "Steps:   2%|  | 306/15000 [02:30<54:03,  4.53it/s, lr=7.4e-7, step_loss=0.00915]07/20/2023 16:20:08 - INFO - __main__ - train loss is 1.560102347517386\n",
      "Steps:   2%|   | 307/15000 [02:30<50:52,  4.81it/s, lr=7.42e-7, step_loss=0.176]07/20/2023 16:20:08 - INFO - __main__ - train loss is 1.9994181136135012\n",
      "Steps:   2%|   | 308/15000 [02:30<48:40,  5.03it/s, lr=7.45e-7, step_loss=0.439]^C\n",
      "\u001b[2;36m[16:20:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Received \u001b[1;36m2\u001b[0m death signal, shutting down workers    \u001b]8;id=92741;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=885863;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py#729\u001b\\\u001b[2m729\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Sending process \u001b[1;36m62858\u001b[0m closing signal SIGINT       \u001b]8;id=905389;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=78857;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#698\u001b\\\u001b[2m698\u001b[0m\u001b]8;;\u001b\\\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc71cb584c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1197, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 894, in main\n",
      "    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py\", line 797, in forward\n",
      "    sample, res_samples = downsample_block(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py\", line 924, in forward\n",
      "    hidden_states = attn(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/transformer_2d.py\", line 296, in forward\n",
      "    hidden_states = block(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention.py\", line 144, in forward\n",
      "    attn_output = self.attn1(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention_processor.py\", line 320, in forward\n",
      "    return self.processor(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention_processor.py\", line 602, in __call__\n",
      "    hidden_states = attn.batch_to_head_dim(hidden_states)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/models/attention_processor.py\", line 332, in batch_to_head_dim\n",
      "    tensor = tensor.permute(0, 2, 1, 3).reshape(batch_size // head_size, seq_len, dim * head_size)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --validation_epochs=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=1000 \\\n",
    "  --output_dir=$\"./out/20-07/02\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/13-07/2\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
