{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19 12:32:19,537] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87822ed83f464169b722ef8107b923f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5782384a014eb4ad9eea06c1f6c6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789d2d98f3864f90810f1005daca42dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40a78d6f8664576bf83ab1c93d9cc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbeec814ab1473a928b797f8b14154c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" , split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=501x512>,\n",
       " 'prompt': 'a spectrogram of bird song',\n",
       " 'audiofile': './data/Bird vocalization-bird call-bird song/train/-aC8TJIZrtE.wav'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-20 12:28:11,989] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-20 12:28:14,129] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-20 12:28:15,295] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-20 12:28:15,295] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-20 12:28:15,295] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/20/2023 12:28:15 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'variance_type', 'dynamic_thresholding_ratio', 'sample_max_value', 'clip_sample_range', 'prediction_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'use_linear_projection', 'time_cond_proj_dim', 'cross_attention_norm', 'only_cross_attention', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'addition_embed_type', 'time_embedding_dim', 'mid_block_type', 'encoder_hid_dim_type', 'time_embedding_type', 'resnet_time_scale_shift', 'upcast_attention', 'conv_in_kernel', 'dual_cross_attention', 'encoder_hid_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'conv_out_kernel', 'time_embedding_act_fn', 'class_embed_type', 'timestep_post_act'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 195/195 [00:00<00:00, 727659.50it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 442437.13it/s]\n",
      "07/20/2023 12:28:18 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-1814cee2f26d59b8/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1110.93it/s]\n",
      "07/20/2023 12:28:20 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (1).\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.1962151527404785 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-20 12:28:24,314] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/20/2023 12:28:24 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/20/2023 12:28:24 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-20 12:28:24,349] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-20 12:28:24,349] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-20 12:28:24,350] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-20 12:28:24,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-20 12:28:24,355] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-20 12:28:24,355] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-20 12:28:24,355] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-20 12:28:24,355] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-20 12:28:24,355] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-20 12:28:24,355] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07313299179077148 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-20 12:28:24,551] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-20 12:28:24,552] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-20 12:28:24,552] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 7.64 GB, percent = 49.2%\n",
      "[2023-07-20 12:28:24,654] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-20 12:28:24,654] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-20 12:28:24,654] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 7.65 GB, percent = 49.2%\n",
      "[2023-07-20 12:28:24,654] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-20 12:28:24,748] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-20 12:28:24,748] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-20 12:28:24,748] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 7.65 GB, percent = 49.2%\n",
      "[2023-07-20 12:28:24,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-20 12:28:24,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-20 12:28:24,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-20 12:28:24,753] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]\n",
      "[2023-07-20 12:28:24,753] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-20 12:28:24,753] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f665069f4f0>\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-20 12:28:24,754] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-20 12:28:24,755] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002086162567138672 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230720_122825-n4xzqtb5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwinter-flower-123\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/n4xzqtb5\u001b[0m\n",
      "07/20/2023 12:28:31 - INFO - __main__ - ***** Running training *****\n",
      "07/20/2023 12:28:31 - INFO - __main__ -   Num examples = 97\n",
      "07/20/2023 12:28:31 - INFO - __main__ -   Num Epochs = 600\n",
      "07/20/2023 12:28:31 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/20/2023 12:28:31 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/20/2023 12:28:31 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/20/2023 12:28:31 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]07/20/2023 12:28:31 - INFO - __main__ - Starting epoch 0\n",
      "07/20/2023 12:28:33 - INFO - __main__ - train loss is 0.24979567527770996\n",
      "[2023-07-20 12:28:33,925] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|       | 1/15000 [00:01<8:18:42,  1.99s/it, lr=1e-5, step_loss=0.25]07/20/2023 12:28:34 - INFO - __main__ - train loss is 0.35711006820201874\n",
      "[2023-07-20 12:28:34,602] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|      | 2/15000 [00:02<5:04:54,  1.22s/it, lr=1e-5, step_loss=0.107]07/20/2023 12:28:35 - INFO - __main__ - train loss is 0.7553700059652328\n",
      "[2023-07-20 12:28:35,145] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|      | 3/15000 [00:03<3:47:40,  1.10it/s, lr=1e-5, step_loss=0.398]07/20/2023 12:28:35 - INFO - __main__ - train loss is 0.8121070712804794\n",
      "[2023-07-20 12:28:35,692] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|     | 4/15000 [00:03<3:11:44,  1.30it/s, lr=1e-5, step_loss=0.0567]07/20/2023 12:28:36 - INFO - __main__ - train loss is 0.9457262605428696\n",
      "[2023-07-20 12:28:36,232] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|      | 5/15000 [00:04<2:51:16,  1.46it/s, lr=1e-5, step_loss=0.134]07/20/2023 12:28:36 - INFO - __main__ - train loss is 1.0750528424978256\n",
      "[2023-07-20 12:28:36,774] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|      | 6/15000 [00:04<2:39:05,  1.57it/s, lr=1e-5, step_loss=0.129]07/20/2023 12:28:37 - INFO - __main__ - train loss is 1.2582967579364777\n",
      "[2023-07-20 12:28:37,318] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|      | 7/15000 [00:05<2:31:30,  1.65it/s, lr=1e-5, step_loss=0.183]07/20/2023 12:28:37 - INFO - __main__ - train loss is 1.5020387321710587\n",
      "[2023-07-20 12:28:37,859] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|      | 8/15000 [00:05<2:26:16,  1.71it/s, lr=1e-5, step_loss=0.244]07/20/2023 12:28:38 - INFO - __main__ - train loss is 1.5059351166710258\n",
      "Steps:   0%|     | 9/15000 [00:06<2:23:30,  1.74it/s, lr=1e-5, step_loss=0.0039]07/20/2023 12:28:38 - INFO - __main__ - train loss is 1.7129988512024283\n",
      "[2023-07-20 12:28:38,968] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%|     | 10/15000 [00:07<2:22:18,  1.76it/s, lr=1e-5, step_loss=0.207]07/20/2023 12:28:39 - INFO - __main__ - train loss is 1.7309221653267741\n",
      "Steps:   0%|    | 11/15000 [00:07<2:20:17,  1.78it/s, lr=1e-5, step_loss=0.0179]07/20/2023 12:28:40 - INFO - __main__ - train loss is 1.8375177411362529\n",
      "Steps:   0%|     | 12/15000 [00:08<2:22:18,  1.76it/s, lr=1e-5, step_loss=0.107]07/20/2023 12:28:40 - INFO - __main__ - train loss is 1.8409322942607105\n",
      "Steps:   0%|   | 13/15000 [00:08<2:21:06,  1.77it/s, lr=1e-5, step_loss=0.00341]07/20/2023 12:28:41 - INFO - __main__ - train loss is 1.918553068768233\n",
      "Steps:   0%|    | 14/15000 [00:09<2:19:57,  1.78it/s, lr=1e-5, step_loss=0.0776]07/20/2023 12:28:41 - INFO - __main__ - train loss is 1.982796787749976\n",
      "Steps:   0%|    | 15/15000 [00:09<2:19:03,  1.80it/s, lr=1e-5, step_loss=0.0642]07/20/2023 12:28:42 - INFO - __main__ - train loss is 2.024429767858237\n",
      "Steps:   0%|    | 16/15000 [00:10<2:17:57,  1.81it/s, lr=1e-5, step_loss=0.0416]07/20/2023 12:28:42 - INFO - __main__ - train loss is 2.23700714064762\n",
      "Steps:   0%|     | 17/15000 [00:10<2:17:32,  1.82it/s, lr=1e-5, step_loss=0.213]07/20/2023 12:28:43 - INFO - __main__ - train loss is 2.6352138514630497\n",
      "Steps:   0%|     | 18/15000 [00:11<2:17:22,  1.82it/s, lr=1e-5, step_loss=0.398]07/20/2023 12:28:43 - INFO - __main__ - train loss is 2.6888582068495452\n",
      "Steps:   0%|    | 19/15000 [00:12<2:17:51,  1.81it/s, lr=1e-5, step_loss=0.0536]07/20/2023 12:28:44 - INFO - __main__ - train loss is 2.728792260866612\n",
      "Steps:   0%|    | 20/15000 [00:12<2:17:11,  1.82it/s, lr=1e-5, step_loss=0.0399]07/20/2023 12:28:44 - INFO - __main__ - train loss is 2.7404057341627777\n",
      "Steps:   0%|    | 21/15000 [00:13<2:17:59,  1.81it/s, lr=1e-5, step_loss=0.0116]07/20/2023 12:28:45 - INFO - __main__ - train loss is 2.7573845288716257\n",
      "Steps:   0%|     | 22/15000 [00:13<2:17:14,  1.82it/s, lr=1e-5, step_loss=0.017]07/20/2023 12:28:46 - INFO - __main__ - train loss is 2.7838149121962488\n",
      "Steps:   0%|    | 23/15000 [00:14<2:17:00,  1.82it/s, lr=1e-5, step_loss=0.0264]07/20/2023 12:28:46 - INFO - __main__ - train loss is 2.9496336630545557\n",
      "Steps:   0%|     | 24/15000 [00:14<2:16:46,  1.82it/s, lr=1e-5, step_loss=0.166]07/20/2023 12:28:47 - INFO - __main__ - train loss is 2.9760023090057075\n",
      "Steps:   0%|    | 25/15000 [00:15<2:16:49,  1.82it/s, lr=1e-5, step_loss=0.0264]07/20/2023 12:28:47 - INFO - __main__ - train loss is 3.0185900065116584\n",
      "Steps:   0%|    | 26/15000 [00:15<2:16:45,  1.82it/s, lr=1e-5, step_loss=0.0426]07/20/2023 12:28:48 - INFO - __main__ - train loss is 3.1186500820331275\n",
      "[2023-07-20 12:28:48,329] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   0%|       | 27/15000 [00:16<2:16:41,  1.83it/s, lr=1e-5, step_loss=0.1]07/20/2023 12:28:48 - INFO - __main__ - train loss is 3.1697298320941627\n",
      "Steps:   0%|    | 28/15000 [00:16<2:16:29,  1.83it/s, lr=1e-5, step_loss=0.0511]07/20/2023 12:28:49 - INFO - __main__ - train loss is 3.1747669954784214\n",
      "Steps:   0%|   | 29/15000 [00:17<2:17:05,  1.82it/s, lr=1e-5, step_loss=0.00504]07/20/2023 12:28:49 - INFO - __main__ - train loss is 3.1856239796616137\n",
      "Steps:   0%|    | 30/15000 [00:18<2:16:49,  1.82it/s, lr=1e-5, step_loss=0.0109]07/20/2023 12:28:50 - INFO - __main__ - train loss is 3.256427919957787\n",
      "Steps:   0%|    | 31/15000 [00:18<2:16:41,  1.83it/s, lr=1e-5, step_loss=0.0708]07/20/2023 12:28:50 - INFO - __main__ - train loss is 3.26246036356315\n",
      "Steps:   0%|   | 32/15000 [00:19<2:16:29,  1.83it/s, lr=1e-5, step_loss=0.00603]07/20/2023 12:28:51 - INFO - __main__ - train loss is 3.2649686434306204\n",
      "Steps:   0%|   | 33/15000 [00:19<2:16:34,  1.83it/s, lr=1e-5, step_loss=0.00251]07/20/2023 12:28:52 - INFO - __main__ - train loss is 3.273895634803921\n",
      "Steps:   0%|   | 34/15000 [00:20<2:16:32,  1.83it/s, lr=1e-5, step_loss=0.00893]07/20/2023 12:28:52 - INFO - __main__ - train loss is 3.364148257765919\n",
      "Steps:   0%|    | 35/15000 [00:20<2:16:58,  1.82it/s, lr=1e-5, step_loss=0.0903]07/20/2023 12:28:53 - INFO - __main__ - train loss is 3.752617029938847\n",
      "Steps:   0%|     | 36/15000 [00:21<2:16:53,  1.82it/s, lr=1e-5, step_loss=0.388]07/20/2023 12:28:53 - INFO - __main__ - train loss is 4.146975486073643\n",
      "Steps:   0%|     | 37/15000 [00:21<2:17:40,  1.81it/s, lr=1e-5, step_loss=0.394]07/20/2023 12:28:54 - INFO - __main__ - train loss is 4.159748127218336\n",
      "Steps:   0%|    | 38/15000 [00:22<2:18:51,  1.80it/s, lr=1e-5, step_loss=0.0128]07/20/2023 12:28:54 - INFO - __main__ - train loss is 4.353418683167547\n",
      "Steps:   0%|     | 39/15000 [00:23<2:18:33,  1.80it/s, lr=1e-5, step_loss=0.194]07/20/2023 12:28:55 - INFO - __main__ - train loss is 4.563079362269491\n",
      "Steps:   0%|      | 40/15000 [00:23<2:18:10,  1.80it/s, lr=1e-5, step_loss=0.21]07/20/2023 12:28:55 - INFO - __main__ - train loss is 4.754746889229864\n",
      "Steps:   0%|     | 41/15000 [00:24<2:17:12,  1.82it/s, lr=1e-5, step_loss=0.192]07/20/2023 12:28:56 - INFO - __main__ - train loss is 4.758529958315194\n",
      "Steps:   0%|   | 42/15000 [00:24<2:17:16,  1.82it/s, lr=1e-5, step_loss=0.00378]07/20/2023 12:28:57 - INFO - __main__ - train loss is 4.803676285780966\n",
      "Steps:   0%|    | 43/15000 [00:25<2:16:53,  1.82it/s, lr=1e-5, step_loss=0.0451]07/20/2023 12:28:57 - INFO - __main__ - train loss is 4.856384486891329\n",
      "Steps:   0%|    | 44/15000 [00:25<2:15:52,  1.83it/s, lr=1e-5, step_loss=0.0527]07/20/2023 12:28:58 - INFO - __main__ - train loss is 4.862046516500413\n",
      "Steps:   0%|   | 45/15000 [00:26<2:15:43,  1.84it/s, lr=1e-5, step_loss=0.00566]07/20/2023 12:28:58 - INFO - __main__ - train loss is 5.029340929351747\n",
      "Steps:   0%|     | 46/15000 [00:26<2:16:13,  1.83it/s, lr=1e-5, step_loss=0.167]07/20/2023 12:28:59 - INFO - __main__ - train loss is 5.145255527459085\n",
      "Steps:   0%|     | 47/15000 [00:27<2:16:12,  1.83it/s, lr=1e-5, step_loss=0.116]07/20/2023 12:28:59 - INFO - __main__ - train loss is 5.2696009343490005\n",
      "Steps:   0%|     | 48/15000 [00:27<2:17:22,  1.81it/s, lr=1e-5, step_loss=0.124]07/20/2023 12:29:00 - INFO - __main__ - train loss is 5.37722250726074\n",
      "Steps:   0%|     | 49/15000 [00:28<2:18:20,  1.80it/s, lr=1e-5, step_loss=0.108]07/20/2023 12:29:00 - INFO - __main__ - train loss is 5.614800303243101\n",
      "Steps:   0%|     | 50/15000 [00:29<2:17:49,  1.81it/s, lr=1e-5, step_loss=0.238]07/20/2023 12:29:01 - INFO - __main__ - train loss is 5.987656622193754\n",
      "Steps:   0%|     | 51/15000 [00:29<2:17:37,  1.81it/s, lr=1e-5, step_loss=0.373]07/20/2023 12:29:01 - INFO - __main__ - train loss is 5.995761609636247\n",
      "Steps:   0%|    | 52/15000 [00:30<2:16:55,  1.82it/s, lr=1e-5, step_loss=0.0081]07/20/2023 12:29:02 - INFO - __main__ - train loss is 6.318871534429491\n",
      "Steps:   0%|     | 53/15000 [00:30<2:18:26,  1.80it/s, lr=1e-5, step_loss=0.323]07/20/2023 12:29:03 - INFO - __main__ - train loss is 6.322627485031262\n",
      "Steps:   0%|   | 54/15000 [00:31<2:18:40,  1.80it/s, lr=1e-5, step_loss=0.00376]07/20/2023 12:29:03 - INFO - __main__ - train loss is 6.328184078680351\n",
      "Steps:   0%|   | 55/15000 [00:31<2:18:41,  1.80it/s, lr=1e-5, step_loss=0.00556]07/20/2023 12:29:04 - INFO - __main__ - train loss is 6.782520841108635\n",
      "Steps:   0%|     | 56/15000 [00:32<2:17:09,  1.82it/s, lr=1e-5, step_loss=0.454]07/20/2023 12:29:04 - INFO - __main__ - train loss is 6.8473623127210885\n",
      "Steps:   0%|    | 57/15000 [00:32<2:16:40,  1.82it/s, lr=1e-5, step_loss=0.0648]07/20/2023 12:29:05 - INFO - __main__ - train loss is 6.935596178518608\n",
      "Steps:   0%|    | 58/15000 [00:33<2:16:59,  1.82it/s, lr=1e-5, step_loss=0.0882]07/20/2023 12:29:05 - INFO - __main__ - train loss is 7.655646632658318\n",
      "Steps:   0%|      | 59/15000 [00:34<2:16:51,  1.82it/s, lr=1e-5, step_loss=0.72]07/20/2023 12:29:06 - INFO - __main__ - train loss is 7.660288140410557\n",
      "Steps:   0%|   | 60/15000 [00:34<2:16:40,  1.82it/s, lr=1e-5, step_loss=0.00464]07/20/2023 12:29:06 - INFO - __main__ - train loss is 8.00143538438715\n",
      "Steps:   0%|     | 61/15000 [00:35<2:17:02,  1.82it/s, lr=1e-5, step_loss=0.341]07/20/2023 12:29:07 - INFO - __main__ - train loss is 8.010642666602507\n",
      "Steps:   0%|   | 62/15000 [00:35<2:17:16,  1.81it/s, lr=1e-5, step_loss=0.00921]07/20/2023 12:29:08 - INFO - __main__ - train loss is 8.34140693047084\n",
      "Steps:   0%|     | 63/15000 [00:36<2:16:56,  1.82it/s, lr=1e-5, step_loss=0.331]07/20/2023 12:29:08 - INFO - __main__ - train loss is 8.999452997231856\n",
      "Steps:   0%|     | 64/15000 [00:36<2:16:08,  1.83it/s, lr=1e-5, step_loss=0.658]07/20/2023 12:29:09 - INFO - __main__ - train loss is 9.005075580207631\n",
      "Steps:   0%|   | 65/15000 [00:37<2:15:27,  1.84it/s, lr=1e-5, step_loss=0.00562]07/20/2023 12:29:09 - INFO - __main__ - train loss is 9.691183632938191\n",
      "Steps:   0%|     | 66/15000 [00:37<2:15:35,  1.84it/s, lr=1e-5, step_loss=0.686]07/20/2023 12:29:10 - INFO - __main__ - train loss is 9.701345328940079\n",
      "Steps:   0%|    | 67/15000 [00:38<2:16:08,  1.83it/s, lr=1e-5, step_loss=0.0102]07/20/2023 12:29:10 - INFO - __main__ - train loss is 9.731871553463861\n",
      "Steps:   0%|    | 68/15000 [00:38<2:16:04,  1.83it/s, lr=1e-5, step_loss=0.0305]07/20/2023 12:29:11 - INFO - __main__ - train loss is 9.741641371278092\n",
      "Steps:   0%|   | 69/15000 [00:39<2:15:53,  1.83it/s, lr=1e-5, step_loss=0.00977]07/20/2023 12:29:11 - INFO - __main__ - train loss is 10.045821248320863\n",
      "Steps:   0%|     | 70/15000 [00:40<2:15:06,  1.84it/s, lr=1e-5, step_loss=0.304]07/20/2023 12:29:12 - INFO - __main__ - train loss is 10.404541282681748\n",
      "Steps:   0%|     | 71/15000 [00:40<2:15:47,  1.83it/s, lr=1e-5, step_loss=0.359]07/20/2023 12:29:12 - INFO - __main__ - train loss is 10.413752821041271\n",
      "Steps:   0%|   | 72/15000 [00:41<2:15:54,  1.83it/s, lr=1e-5, step_loss=0.00921]07/20/2023 12:29:13 - INFO - __main__ - train loss is 10.422566612018272\n",
      "Steps:   0%|   | 73/15000 [00:41<2:16:17,  1.83it/s, lr=1e-5, step_loss=0.00881]07/20/2023 12:29:14 - INFO - __main__ - train loss is 10.426877110963687\n",
      "Steps:   0%|   | 74/15000 [00:42<2:15:54,  1.83it/s, lr=1e-5, step_loss=0.00431]07/20/2023 12:29:14 - INFO - __main__ - train loss is 10.459051970159635\n",
      "Steps:   0%|    | 75/15000 [00:42<2:15:53,  1.83it/s, lr=1e-5, step_loss=0.0322]07/20/2023 12:29:15 - INFO - __main__ - train loss is 10.46452083135955\n",
      "Steps:   1%|   | 76/15000 [00:43<2:15:47,  1.83it/s, lr=1e-5, step_loss=0.00547]07/20/2023 12:29:15 - INFO - __main__ - train loss is 10.68079884792678\n",
      "Steps:   1%|     | 77/15000 [00:43<2:16:17,  1.82it/s, lr=1e-5, step_loss=0.216]07/20/2023 12:29:16 - INFO - __main__ - train loss is 11.096308608306572\n",
      "Steps:   1%|     | 78/15000 [00:44<2:17:58,  1.80it/s, lr=1e-5, step_loss=0.416]07/20/2023 12:29:16 - INFO - __main__ - train loss is 11.348643471254036\n",
      "Steps:   1%|     | 79/15000 [00:45<2:19:05,  1.79it/s, lr=1e-5, step_loss=0.252]07/20/2023 12:29:17 - INFO - __main__ - train loss is 11.398723614169285\n",
      "Steps:   1%|    | 80/15000 [00:45<2:17:54,  1.80it/s, lr=1e-5, step_loss=0.0501]07/20/2023 12:29:17 - INFO - __main__ - train loss is 11.860125017119572\n",
      "Steps:   1%|     | 81/15000 [00:46<2:17:54,  1.80it/s, lr=1e-5, step_loss=0.461]07/20/2023 12:29:18 - INFO - __main__ - train loss is 11.953910496784374\n",
      "Steps:   1%|    | 82/15000 [00:46<2:17:49,  1.80it/s, lr=1e-5, step_loss=0.0938]07/20/2023 12:29:19 - INFO - __main__ - train loss is 12.475569036556408\n",
      "Steps:   1%|     | 83/15000 [00:47<2:18:15,  1.80it/s, lr=1e-5, step_loss=0.522]07/20/2023 12:29:19 - INFO - __main__ - train loss is 12.48931776615791\n",
      "Steps:   1%|    | 84/15000 [00:47<2:18:24,  1.80it/s, lr=1e-5, step_loss=0.0137]07/20/2023 12:29:20 - INFO - __main__ - train loss is 12.734456947771832\n",
      "Steps:   1%|     | 85/15000 [00:48<2:18:08,  1.80it/s, lr=1e-5, step_loss=0.245]07/20/2023 12:29:20 - INFO - __main__ - train loss is 12.772781229345128\n",
      "Steps:   1%|    | 86/15000 [00:48<2:17:27,  1.81it/s, lr=1e-5, step_loss=0.0383]07/20/2023 12:29:21 - INFO - __main__ - train loss is 12.858681722311303\n",
      "Steps:   1%|    | 87/15000 [00:49<2:17:37,  1.81it/s, lr=1e-5, step_loss=0.0859]07/20/2023 12:29:21 - INFO - __main__ - train loss is 13.107717140344903\n",
      "Steps:   1%|     | 88/15000 [00:49<2:17:26,  1.81it/s, lr=1e-5, step_loss=0.249]07/20/2023 12:29:22 - INFO - __main__ - train loss is 13.331070049433038\n",
      "Steps:   1%|     | 89/15000 [00:50<2:17:19,  1.81it/s, lr=1e-5, step_loss=0.223]07/20/2023 12:29:22 - INFO - __main__ - train loss is 13.356231434969231\n",
      "Steps:   1%|    | 90/15000 [00:51<2:16:37,  1.82it/s, lr=1e-5, step_loss=0.0252]07/20/2023 12:29:23 - INFO - __main__ - train loss is 13.537082641152665\n",
      "Steps:   1%|     | 91/15000 [00:51<2:17:28,  1.81it/s, lr=1e-5, step_loss=0.181]07/20/2023 12:29:24 - INFO - __main__ - train loss is 13.67776724579744\n",
      "Steps:   1%|     | 92/15000 [00:52<2:18:07,  1.80it/s, lr=1e-5, step_loss=0.141]07/20/2023 12:29:24 - INFO - __main__ - train loss is 13.765259339241311\n",
      "Steps:   1%|    | 93/15000 [00:52<2:18:03,  1.80it/s, lr=1e-5, step_loss=0.0875]07/20/2023 12:29:25 - INFO - __main__ - train loss is 13.85543395462446\n",
      "Steps:   1%|    | 94/15000 [00:53<2:17:53,  1.80it/s, lr=1e-5, step_loss=0.0902]07/20/2023 12:29:25 - INFO - __main__ - train loss is 14.304154886631295\n",
      "Steps:   1%|     | 95/15000 [00:53<2:17:29,  1.81it/s, lr=1e-5, step_loss=0.449]07/20/2023 12:29:26 - INFO - __main__ - train loss is 14.779652281431481\n",
      "Steps:   1%|     | 96/15000 [00:54<2:17:04,  1.81it/s, lr=1e-5, step_loss=0.475]07/20/2023 12:29:26 - INFO - __main__ - train loss is 15.164683832554147\n",
      "Steps:   1%|     | 97/15000 [00:55<2:29:31,  1.66it/s, lr=1e-5, step_loss=0.385]07/20/2023 12:29:27 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:27 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:27 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:27 - INFO - __main__ - Per validation step average loss is 0.10704697668552399\n",
      "07/20/2023 12:29:27 - INFO - __main__ - Cumulative validation average loss is 0.10704697668552399\n",
      "07/20/2023 12:29:27 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:27 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:27 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Per validation step average loss is 0.21689572930335999\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Cumulative validation average loss is 0.32394270598888397\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441043])\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Post-squeeze shape torch.Size([441043])\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Post-avg shape torch.Size([441043])\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Per validation step average loss is 0.0018468108028173447\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Cumulative validation average loss is 0.3257895167917013\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:28 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Per validation step average loss is 0.06556088477373123\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Cumulative validation average loss is 0.39135040156543255\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Per validation step average loss is 0.025578249245882034\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Cumulative validation average loss is 0.4169286508113146\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:29 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Per validation step average loss is 0.1678755283355713\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Cumulative validation average loss is 0.5848041791468859\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Per validation step average loss is 0.0028727035969495773\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Cumulative validation average loss is 0.5876768827438354\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:29:30 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Per validation step average loss is 0.4823782444000244\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Cumulative validation average loss is 1.0700551271438599\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Per validation step average loss is 0.007947079837322235\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Cumulative validation average loss is 1.078002206981182\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:31 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Per validation step average loss is 0.5813367366790771\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Cumulative validation average loss is 1.6593389436602592\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Per validation step average loss is 0.0025737578980624676\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Cumulative validation average loss is 1.6619127015583217\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:29:32 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:29:33 - INFO - __main__ - Per validation step average loss is 0.001572547247633338\n",
      "07/20/2023 12:29:33 - INFO - __main__ - Cumulative validation average loss is 1.663485248805955\n",
      "07/20/2023 12:29:33 - INFO - __main__ - Average validation loss for Epoch 0 is 0.1386237707338296\n",
      "07/20/2023 12:29:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/20/2023 12:29:49 - INFO - __main__ - Starting epoch 1\n",
      "07/20/2023 12:29:49 - INFO - __main__ - train loss is 0.07040134072303772\n",
      "Steps:   1%|   | 98/15000 [01:17<30:09:05,  7.28s/it, lr=1e-5, step_loss=0.0704]07/20/2023 12:29:50 - INFO - __main__ - train loss is 0.16708609461784363\n",
      "Steps:   1%|   | 99/15000 [01:18<21:19:29,  5.15s/it, lr=1e-5, step_loss=0.0967]07/20/2023 12:29:50 - INFO - __main__ - train loss is 0.2334962636232376\n",
      "Steps:   1%|  | 100/15000 [01:18<15:08:45,  3.66s/it, lr=1e-5, step_loss=0.0664]07/20/2023 12:29:50 - INFO - __main__ - train loss is 0.827037051320076\n",
      "Steps:   1%|   | 101/15000 [01:18<10:49:33,  2.62s/it, lr=1e-5, step_loss=0.594]07/20/2023 12:29:50 - INFO - __main__ - train loss is 1.0750639885663986\n",
      "Steps:   1%|    | 102/15000 [01:18<7:47:48,  1.88s/it, lr=1e-5, step_loss=0.248]07/20/2023 12:29:50 - INFO - __main__ - train loss is 1.079053589142859\n",
      "Steps:   1%|  | 103/15000 [01:18<5:40:42,  1.37s/it, lr=1e-5, step_loss=0.00399]07/20/2023 12:29:50 - INFO - __main__ - train loss is 1.2722380543127656\n",
      "Steps:   1%|    | 104/15000 [01:19<4:11:37,  1.01s/it, lr=1e-5, step_loss=0.193]07/20/2023 12:29:51 - INFO - __main__ - train loss is 1.474575170315802\n",
      "Steps:   1%|    | 105/15000 [01:19<3:09:16,  1.31it/s, lr=1e-5, step_loss=0.202]07/20/2023 12:29:51 - INFO - __main__ - train loss is 1.4808002170175314\n",
      "Steps:   1%|  | 106/15000 [01:19<2:25:35,  1.71it/s, lr=1e-5, step_loss=0.00623]07/20/2023 12:29:51 - INFO - __main__ - train loss is 1.850599205121398\n",
      "Steps:   1%|     | 107/15000 [01:19<1:55:07,  2.16it/s, lr=1e-5, step_loss=0.37]07/20/2023 12:29:51 - INFO - __main__ - train loss is 1.862316919490695\n",
      "Steps:   1%|   | 108/15000 [01:19<1:33:43,  2.65it/s, lr=1e-5, step_loss=0.0117]07/20/2023 12:29:51 - INFO - __main__ - train loss is 2.3001867961138487\n",
      "Steps:   1%|    | 109/15000 [01:19<1:18:44,  3.15it/s, lr=1e-5, step_loss=0.438]07/20/2023 12:29:51 - INFO - __main__ - train loss is 2.32013401016593\n",
      "Steps:   1%|   | 110/15000 [01:20<1:08:19,  3.63it/s, lr=1e-5, step_loss=0.0199]07/20/2023 12:29:52 - INFO - __main__ - train loss is 2.362613171339035\n",
      "Steps:   1%|   | 111/15000 [01:20<1:01:04,  4.06it/s, lr=1e-5, step_loss=0.0425]07/20/2023 12:29:52 - INFO - __main__ - train loss is 3.0086215436458588\n",
      "Steps:   1%|      | 112/15000 [01:20<55:56,  4.44it/s, lr=1e-5, step_loss=0.646]07/20/2023 12:29:52 - INFO - __main__ - train loss is 3.2099840939044952\n",
      "Steps:   1%|      | 113/15000 [01:20<52:15,  4.75it/s, lr=1e-5, step_loss=0.201]07/20/2023 12:29:52 - INFO - __main__ - train loss is 3.4092255532741547\n",
      "Steps:   1%|      | 114/15000 [01:20<49:43,  4.99it/s, lr=1e-5, step_loss=0.199]07/20/2023 12:29:52 - INFO - __main__ - train loss is 3.772625356912613\n",
      "Steps:   1%|      | 115/15000 [01:21<48:00,  5.17it/s, lr=1e-5, step_loss=0.363]07/20/2023 12:29:53 - INFO - __main__ - train loss is 3.970648556947708\n",
      "Steps:   1%|      | 116/15000 [01:21<46:46,  5.30it/s, lr=1e-5, step_loss=0.198]07/20/2023 12:29:53 - INFO - __main__ - train loss is 3.9908954836428165\n",
      "Steps:   1%|     | 117/15000 [01:21<46:01,  5.39it/s, lr=1e-5, step_loss=0.0202]07/20/2023 12:29:53 - INFO - __main__ - train loss is 4.173622105270624\n",
      "Steps:   1%|      | 118/15000 [01:21<45:29,  5.45it/s, lr=1e-5, step_loss=0.183]07/20/2023 12:29:53 - INFO - __main__ - train loss is 4.466870222240686\n",
      "Steps:   1%|      | 119/15000 [01:21<45:01,  5.51it/s, lr=1e-5, step_loss=0.293]07/20/2023 12:29:53 - INFO - __main__ - train loss is 4.484960535541177\n",
      "Steps:   1%|     | 120/15000 [01:21<44:41,  5.55it/s, lr=1e-5, step_loss=0.0181]07/20/2023 12:29:53 - INFO - __main__ - train loss is 4.491335305385292\n",
      "Steps:   1%|    | 121/15000 [01:22<44:29,  5.57it/s, lr=1e-5, step_loss=0.00637]07/20/2023 12:29:54 - INFO - __main__ - train loss is 4.729514959268272\n",
      "Steps:   1%|      | 122/15000 [01:22<44:25,  5.58it/s, lr=1e-5, step_loss=0.238]07/20/2023 12:29:54 - INFO - __main__ - train loss is 4.891283261589706\n",
      "Steps:   1%|      | 123/15000 [01:22<44:21,  5.59it/s, lr=1e-5, step_loss=0.162]07/20/2023 12:29:54 - INFO - __main__ - train loss is 5.744253384880722\n",
      "Steps:   1%|      | 124/15000 [01:22<44:13,  5.61it/s, lr=1e-5, step_loss=0.853]07/20/2023 12:29:54 - INFO - __main__ - train loss is 6.490150916390121\n",
      "Steps:   1%|      | 125/15000 [01:22<44:10,  5.61it/s, lr=1e-5, step_loss=0.746]07/20/2023 12:29:54 - INFO - __main__ - train loss is 6.493145710555837\n",
      "Steps:   1%|    | 126/15000 [01:22<44:06,  5.62it/s, lr=1e-5, step_loss=0.00299]07/20/2023 12:29:54 - INFO - __main__ - train loss is 6.49693026044406\n",
      "Steps:   1%|    | 127/15000 [01:23<44:05,  5.62it/s, lr=1e-5, step_loss=0.00378]07/20/2023 12:29:55 - INFO - __main__ - train loss is 7.123288113856688\n",
      "Steps:   1%|      | 128/15000 [01:23<44:16,  5.60it/s, lr=1e-5, step_loss=0.626]07/20/2023 12:29:55 - INFO - __main__ - train loss is 7.6676908324006945\n",
      "Steps:   1%|      | 129/15000 [01:23<44:09,  5.61it/s, lr=1e-5, step_loss=0.544]07/20/2023 12:29:55 - INFO - __main__ - train loss is 7.678176656598225\n",
      "Steps:   1%|     | 130/15000 [01:23<44:07,  5.62it/s, lr=1e-5, step_loss=0.0105]07/20/2023 12:29:55 - INFO - __main__ - train loss is 7.731058411533013\n",
      "Steps:   1%|     | 131/15000 [01:23<44:03,  5.63it/s, lr=1e-5, step_loss=0.0529]07/20/2023 12:29:55 - INFO - __main__ - train loss is 8.041637115413323\n",
      "Steps:   1%|      | 132/15000 [01:24<44:12,  5.60it/s, lr=1e-5, step_loss=0.311]07/20/2023 12:29:56 - INFO - __main__ - train loss is 8.047580437967554\n",
      "Steps:   1%|    | 133/15000 [01:24<44:05,  5.62it/s, lr=1e-5, step_loss=0.00594]07/20/2023 12:29:56 - INFO - __main__ - train loss is 8.703430431196466\n",
      "Steps:   1%|      | 134/15000 [01:24<44:01,  5.63it/s, lr=1e-5, step_loss=0.656]07/20/2023 12:29:56 - INFO - __main__ - train loss is 8.748970037559047\n",
      "Steps:   1%|     | 135/15000 [01:24<43:57,  5.64it/s, lr=1e-5, step_loss=0.0455]07/20/2023 12:29:56 - INFO - __main__ - train loss is 8.856629392364994\n",
      "Steps:   1%|      | 136/15000 [01:24<43:54,  5.64it/s, lr=1e-5, step_loss=0.108]07/20/2023 12:29:56 - INFO - __main__ - train loss is 8.999587318161502\n",
      "Steps:   1%|      | 137/15000 [01:24<43:53,  5.64it/s, lr=1e-5, step_loss=0.143]07/20/2023 12:29:56 - INFO - __main__ - train loss is 9.301622858503833\n",
      "Steps:   1%|      | 138/15000 [01:25<43:53,  5.64it/s, lr=1e-5, step_loss=0.302]07/20/2023 12:29:57 - INFO - __main__ - train loss is 9.331556106219068\n",
      "Steps:   1%|     | 139/15000 [01:25<43:53,  5.64it/s, lr=1e-5, step_loss=0.0299]07/20/2023 12:29:57 - INFO - __main__ - train loss is 9.342568177962676\n",
      "Steps:   1%|      | 140/15000 [01:25<43:53,  5.64it/s, lr=1e-5, step_loss=0.011]07/20/2023 12:29:57 - INFO - __main__ - train loss is 9.542869169497862\n",
      "Steps:   1%|        | 141/15000 [01:25<43:54,  5.64it/s, lr=1e-5, step_loss=0.2]07/20/2023 12:29:57 - INFO - __main__ - train loss is 9.978954483056441\n",
      "Steps:   1%|      | 142/15000 [01:25<43:54,  5.64it/s, lr=1e-5, step_loss=0.436]07/20/2023 12:29:57 - INFO - __main__ - train loss is 10.068983610952273\n",
      "Steps:   1%|       | 143/15000 [01:25<43:54,  5.64it/s, lr=1e-5, step_loss=0.09]07/20/2023 12:29:58 - INFO - __main__ - train loss is 10.127221543574706\n",
      "Steps:   1%|     | 144/15000 [01:26<43:54,  5.64it/s, lr=1e-5, step_loss=0.0582]07/20/2023 12:29:58 - INFO - __main__ - train loss is 10.164313048357144\n",
      "Steps:   1%|     | 145/15000 [01:26<43:53,  5.64it/s, lr=1e-5, step_loss=0.0371]07/20/2023 12:29:58 - INFO - __main__ - train loss is 10.380240127677098\n",
      "Steps:   1%|      | 146/15000 [01:26<43:53,  5.64it/s, lr=1e-5, step_loss=0.216]07/20/2023 12:29:58 - INFO - __main__ - train loss is 10.38528103590943\n",
      "Steps:   1%|    | 147/15000 [01:26<43:54,  5.64it/s, lr=1e-5, step_loss=0.00504]07/20/2023 12:29:58 - INFO - __main__ - train loss is 10.733451495179906\n",
      "Steps:   1%|      | 148/15000 [01:26<43:55,  5.64it/s, lr=1e-5, step_loss=0.348]07/20/2023 12:29:58 - INFO - __main__ - train loss is 11.114672789582983\n",
      "Steps:   1%|      | 149/15000 [01:27<43:58,  5.63it/s, lr=1e-5, step_loss=0.381]07/20/2023 12:29:59 - INFO - __main__ - train loss is 11.54135243059136\n",
      "Steps:   1%|      | 150/15000 [01:27<43:56,  5.63it/s, lr=1e-5, step_loss=0.427]07/20/2023 12:29:59 - INFO - __main__ - train loss is 11.800257722148672\n",
      "Steps:   1%|      | 151/15000 [01:27<43:54,  5.64it/s, lr=1e-5, step_loss=0.259]07/20/2023 12:29:59 - INFO - __main__ - train loss is 11.923654603073373\n",
      "Steps:   1%|      | 152/15000 [01:27<43:52,  5.64it/s, lr=1e-5, step_loss=0.123]07/20/2023 12:29:59 - INFO - __main__ - train loss is 11.926926960004494\n",
      "Steps:   1%|    | 153/15000 [01:27<43:52,  5.64it/s, lr=1e-5, step_loss=0.00327]07/20/2023 12:29:59 - INFO - __main__ - train loss is 12.127600212348625\n",
      "Steps:   1%|      | 154/15000 [01:27<43:52,  5.64it/s, lr=1e-5, step_loss=0.201]07/20/2023 12:29:59 - INFO - __main__ - train loss is 12.396391530288383\n",
      "[2023-07-20 12:30:00,037] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:   1%|      | 155/15000 [01:28<43:34,  5.68it/s, lr=1e-5, step_loss=0.269]07/20/2023 12:30:00 - INFO - __main__ - train loss is 12.713320423616096\n",
      "Steps:   1%|      | 156/15000 [01:28<43:36,  5.67it/s, lr=1e-5, step_loss=0.317]07/20/2023 12:30:00 - INFO - __main__ - train loss is 12.750020046485588\n",
      "Steps:   1%|     | 157/15000 [01:28<43:39,  5.67it/s, lr=1e-5, step_loss=0.0367]07/20/2023 12:30:00 - INFO - __main__ - train loss is 12.797695831162855\n",
      "Steps:   1%|     | 158/15000 [01:28<43:39,  5.67it/s, lr=1e-5, step_loss=0.0477]07/20/2023 12:30:00 - INFO - __main__ - train loss is 12.835851960582659\n",
      "Steps:   1%|     | 159/15000 [01:28<43:41,  5.66it/s, lr=1e-5, step_loss=0.0382]07/20/2023 12:30:00 - INFO - __main__ - train loss is 12.85544052044861\n",
      "Steps:   1%|     | 160/15000 [01:28<43:45,  5.65it/s, lr=1e-5, step_loss=0.0196]07/20/2023 12:30:01 - INFO - __main__ - train loss is 13.275064908666536\n",
      "Steps:   1%|       | 161/15000 [01:29<43:46,  5.65it/s, lr=1e-5, step_loss=0.42]07/20/2023 12:30:01 - INFO - __main__ - train loss is 13.308959551854059\n",
      "Steps:   1%|     | 162/15000 [01:29<43:48,  5.65it/s, lr=1e-5, step_loss=0.0339]07/20/2023 12:30:01 - INFO - __main__ - train loss is 13.313953527016565\n",
      "Steps:   1%|    | 163/15000 [01:29<43:48,  5.64it/s, lr=1e-5, step_loss=0.00499]07/20/2023 12:30:01 - INFO - __main__ - train loss is 13.320202324306592\n",
      "Steps:   1%|    | 164/15000 [01:29<43:51,  5.64it/s, lr=1e-5, step_loss=0.00625]07/20/2023 12:30:01 - INFO - __main__ - train loss is 13.32261444721371\n",
      "Steps:   1%|    | 165/15000 [01:29<43:49,  5.64it/s, lr=1e-5, step_loss=0.00241]07/20/2023 12:30:01 - INFO - __main__ - train loss is 13.324406878789887\n",
      "Steps:   1%|    | 166/15000 [01:30<44:09,  5.60it/s, lr=1e-5, step_loss=0.00179]07/20/2023 12:30:02 - INFO - __main__ - train loss is 13.331846909364685\n",
      "Steps:   1%|    | 167/15000 [01:30<44:15,  5.59it/s, lr=1e-5, step_loss=0.00744]07/20/2023 12:30:02 - INFO - __main__ - train loss is 13.915755467256531\n",
      "Steps:   1%|      | 168/15000 [01:30<44:13,  5.59it/s, lr=1e-5, step_loss=0.584]07/20/2023 12:30:02 - INFO - __main__ - train loss is 14.06871403916739\n",
      "Steps:   1%|      | 169/15000 [01:30<44:08,  5.60it/s, lr=1e-5, step_loss=0.153]07/20/2023 12:30:02 - INFO - __main__ - train loss is 14.39108614786528\n",
      "Steps:   1%|      | 170/15000 [01:30<44:05,  5.61it/s, lr=1e-5, step_loss=0.322]07/20/2023 12:30:02 - INFO - __main__ - train loss is 14.403541018953547\n",
      "Steps:   1%|     | 171/15000 [01:30<43:59,  5.62it/s, lr=1e-5, step_loss=0.0125]07/20/2023 12:30:02 - INFO - __main__ - train loss is 14.469146465649828\n",
      "Steps:   1%|     | 172/15000 [01:31<43:57,  5.62it/s, lr=1e-5, step_loss=0.0656]07/20/2023 12:30:03 - INFO - __main__ - train loss is 14.702751135220751\n",
      "Steps:   1%|      | 173/15000 [01:31<43:54,  5.63it/s, lr=1e-5, step_loss=0.234]07/20/2023 12:30:03 - INFO - __main__ - train loss is 14.910656666150317\n",
      "Steps:   1%|      | 174/15000 [01:31<43:53,  5.63it/s, lr=1e-5, step_loss=0.208]07/20/2023 12:30:03 - INFO - __main__ - train loss is 14.917124730767682\n",
      "Steps:   1%|    | 175/15000 [01:31<43:49,  5.64it/s, lr=1e-5, step_loss=0.00647]07/20/2023 12:30:03 - INFO - __main__ - train loss is 14.992729743244126\n",
      "Steps:   1%|     | 176/15000 [01:31<43:48,  5.64it/s, lr=1e-5, step_loss=0.0756]07/20/2023 12:30:03 - INFO - __main__ - train loss is 15.546797593357041\n",
      "Steps:   1%|      | 177/15000 [01:32<43:46,  5.64it/s, lr=1e-5, step_loss=0.554]07/20/2023 12:30:04 - INFO - __main__ - train loss is 15.720605959417298\n",
      "Steps:   1%|      | 178/15000 [01:32<43:43,  5.65it/s, lr=1e-5, step_loss=0.174]07/20/2023 12:30:04 - INFO - __main__ - train loss is 16.068239410640672\n",
      "Steps:   1%|      | 179/15000 [01:32<43:39,  5.66it/s, lr=1e-5, step_loss=0.348]07/20/2023 12:30:04 - INFO - __main__ - train loss is 16.077081555733457\n",
      "Steps:   1%|    | 180/15000 [01:32<43:38,  5.66it/s, lr=1e-5, step_loss=0.00884]07/20/2023 12:30:04 - INFO - __main__ - train loss is 16.117083767661825\n",
      "Steps:   1%|       | 181/15000 [01:32<43:37,  5.66it/s, lr=1e-5, step_loss=0.04]07/20/2023 12:30:04 - INFO - __main__ - train loss is 16.357613960513845\n",
      "Steps:   1%|      | 182/15000 [01:32<43:35,  5.66it/s, lr=1e-5, step_loss=0.241]07/20/2023 12:30:04 - INFO - __main__ - train loss is 16.371286141918972\n",
      "Steps:   1%|     | 183/15000 [01:33<43:46,  5.64it/s, lr=1e-5, step_loss=0.0137]07/20/2023 12:30:05 - INFO - __main__ - train loss is 16.387365666450933\n",
      "Steps:   1%|     | 184/15000 [01:33<43:53,  5.63it/s, lr=1e-5, step_loss=0.0161]07/20/2023 12:30:05 - INFO - __main__ - train loss is 16.41129142907448\n",
      "Steps:   1%|     | 185/15000 [01:33<43:48,  5.64it/s, lr=1e-5, step_loss=0.0239]07/20/2023 12:30:05 - INFO - __main__ - train loss is 16.448564735474065\n",
      "Steps:   1%|     | 186/15000 [01:33<44:29,  5.55it/s, lr=1e-5, step_loss=0.0373]07/20/2023 12:30:05 - INFO - __main__ - train loss is 16.451478318078443\n",
      "Steps:   1%|    | 187/15000 [01:33<44:14,  5.58it/s, lr=1e-5, step_loss=0.00291]07/20/2023 12:30:05 - INFO - __main__ - train loss is 16.494063616497442\n",
      "Steps:   1%|     | 188/15000 [01:33<44:02,  5.60it/s, lr=1e-5, step_loss=0.0426]07/20/2023 12:30:05 - INFO - __main__ - train loss is 16.51151741738431\n",
      "Steps:   1%|     | 189/15000 [01:34<43:55,  5.62it/s, lr=1e-5, step_loss=0.0175]07/20/2023 12:30:06 - INFO - __main__ - train loss is 16.514458541525528\n",
      "Steps:   1%|    | 190/15000 [01:34<43:51,  5.63it/s, lr=1e-5, step_loss=0.00294]07/20/2023 12:30:06 - INFO - __main__ - train loss is 16.649447326315567\n",
      "Steps:   1%|      | 191/15000 [01:34<43:47,  5.64it/s, lr=1e-5, step_loss=0.135]07/20/2023 12:30:06 - INFO - __main__ - train loss is 16.81385124172084\n",
      "Steps:   1%|      | 192/15000 [01:34<43:43,  5.64it/s, lr=1e-5, step_loss=0.164]07/20/2023 12:30:06 - INFO - __main__ - train loss is 16.902325962437317\n",
      "Steps:   1%|     | 193/15000 [01:34<43:39,  5.65it/s, lr=1e-5, step_loss=0.0885]07/20/2023 12:30:07 - INFO - __main__ - train loss is 17.23602718557231\n",
      "Steps:   1%|    | 194/15000 [01:35<1:03:50,  3.87it/s, lr=1e-5, step_loss=0.334]07/20/2023 12:30:07 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:07 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:07 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Per validation step average loss is 0.13631586730480194\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Cumulative validation average loss is 0.13631586730480194\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Per validation step average loss is 0.48776406049728394\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Cumulative validation average loss is 0.6240799278020859\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441043])\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Post-squeeze shape torch.Size([441043])\n",
      "07/20/2023 12:30:08 - INFO - __main__ - Post-avg shape torch.Size([441043])\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Per validation step average loss is 0.04169473797082901\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Cumulative validation average loss is 0.6657746657729149\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Per validation step average loss is 0.7181880474090576\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Cumulative validation average loss is 1.3839627131819725\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:09 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Per validation step average loss is 0.08151862025260925\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Cumulative validation average loss is 1.4654813334345818\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Per validation step average loss is 0.37661972641944885\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Cumulative validation average loss is 1.8421010598540306\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Per validation step average loss is 0.012799377553164959\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Cumulative validation average loss is 1.8549004374071956\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:30:10 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Per validation step average loss is 0.6057040691375732\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Cumulative validation average loss is 2.460604506544769\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Per validation step average loss is 0.010390717536211014\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Cumulative validation average loss is 2.47099522408098\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:11 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Per validation step average loss is 0.035444475710392\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Cumulative validation average loss is 2.506439699791372\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Per validation step average loss is 0.007608478888869286\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Cumulative validation average loss is 2.514048178680241\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:12 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:13 - INFO - __main__ - Per validation step average loss is 0.004530438221991062\n",
      "07/20/2023 12:30:13 - INFO - __main__ - Cumulative validation average loss is 2.518578616902232\n",
      "07/20/2023 12:30:13 - INFO - __main__ - Average validation loss for Epoch 1 is 0.20988155140851936\n",
      "07/20/2023 12:30:13 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/20/2023 12:30:26 - INFO - __main__ - Starting epoch 2\n",
      "07/20/2023 12:30:26 - INFO - __main__ - train loss is 0.10210886597633362\n",
      "Steps:   1%|   | 195/15000 [01:55<25:10:05,  6.12s/it, lr=1e-5, step_loss=0.102]07/20/2023 12:30:27 - INFO - __main__ - train loss is 0.21975713968276978\n",
      "Steps:   1%|   | 196/15000 [01:55<17:50:13,  4.34s/it, lr=1e-5, step_loss=0.118]07/20/2023 12:30:27 - INFO - __main__ - train loss is 0.23938010819256306\n",
      "Steps:   1%|  | 197/15000 [01:55<12:42:19,  3.09s/it, lr=1e-5, step_loss=0.0196]07/20/2023 12:30:27 - INFO - __main__ - train loss is 0.27277526445686817\n",
      "Steps:   1%|   | 198/15000 [01:55<9:06:46,  2.22s/it, lr=1e-5, step_loss=0.0334]07/20/2023 12:30:27 - INFO - __main__ - train loss is 0.7229895908385515\n",
      "Steps:   1%|     | 199/15000 [01:55<6:36:06,  1.61s/it, lr=1e-5, step_loss=0.45]07/20/2023 12:30:27 - INFO - __main__ - train loss is 0.9946861583739519\n",
      "Steps:   1%|    | 200/15000 [01:55<4:50:19,  1.18s/it, lr=1e-5, step_loss=0.272]07/20/2023 12:30:28 - INFO - __main__ - train loss is 1.033029044046998\n",
      "Steps:   1%|   | 201/15000 [01:56<3:36:17,  1.14it/s, lr=1e-5, step_loss=0.0383]07/20/2023 12:30:28 - INFO - __main__ - train loss is 1.1706706527620554\n",
      "Steps:   1%|    | 202/15000 [01:56<2:44:30,  1.50it/s, lr=1e-5, step_loss=0.138]07/20/2023 12:30:28 - INFO - __main__ - train loss is 1.5277616623789072\n",
      "Steps:   1%|    | 203/15000 [01:56<2:08:13,  1.92it/s, lr=1e-5, step_loss=0.357]07/20/2023 12:30:28 - INFO - __main__ - train loss is 1.5690516587346792\n",
      "Steps:   1%|   | 204/15000 [01:56<1:42:52,  2.40it/s, lr=1e-5, step_loss=0.0413]07/20/2023 12:30:28 - INFO - __main__ - train loss is 1.5736003750935197\n",
      "Steps:   1%|  | 205/15000 [01:56<1:25:04,  2.90it/s, lr=1e-5, step_loss=0.00455]07/20/2023 12:30:28 - INFO - __main__ - train loss is 1.5760032124817371\n",
      "Steps:   1%|   | 206/15000 [01:57<1:12:34,  3.40it/s, lr=1e-5, step_loss=0.0024]07/20/2023 12:30:29 - INFO - __main__ - train loss is 1.6003996338695288\n",
      "Steps:   1%|   | 207/15000 [01:57<1:03:59,  3.85it/s, lr=1e-5, step_loss=0.0244]07/20/2023 12:30:29 - INFO - __main__ - train loss is 2.0384355690330267\n",
      "Steps:   1%|      | 208/15000 [01:57<58:41,  4.20it/s, lr=1e-5, step_loss=0.438]07/20/2023 12:30:29 - INFO - __main__ - train loss is 2.674879064783454\n",
      "Steps:   1%|      | 209/15000 [01:57<54:46,  4.50it/s, lr=1e-5, step_loss=0.636]07/20/2023 12:30:29 - INFO - __main__ - train loss is 2.806184967979789\n",
      "Steps:   1%|      | 210/15000 [01:57<51:23,  4.80it/s, lr=1e-5, step_loss=0.131]07/20/2023 12:30:29 - INFO - __main__ - train loss is 2.823851376771927\n",
      "Steps:   1%|     | 211/15000 [01:57<49:01,  5.03it/s, lr=1e-5, step_loss=0.0177]07/20/2023 12:30:29 - INFO - __main__ - train loss is 3.0311090648174286\n",
      "Steps:   1%|      | 212/15000 [01:58<47:28,  5.19it/s, lr=1e-5, step_loss=0.207]07/20/2023 12:30:30 - INFO - __main__ - train loss is 3.0614266488701105\n",
      "Steps:   1%|     | 213/15000 [01:58<46:30,  5.30it/s, lr=1e-5, step_loss=0.0303]07/20/2023 12:30:30 - INFO - __main__ - train loss is 3.2760217282921076\n",
      "Steps:   1%|      | 214/15000 [01:58<45:39,  5.40it/s, lr=1e-5, step_loss=0.215]07/20/2023 12:30:30 - INFO - __main__ - train loss is 3.3814538959413767\n",
      "Steps:   1%|      | 215/15000 [01:58<45:03,  5.47it/s, lr=1e-5, step_loss=0.105]07/20/2023 12:30:30 - INFO - __main__ - train loss is 3.430847814306617\n",
      "Steps:   1%|     | 216/15000 [01:58<44:39,  5.52it/s, lr=1e-5, step_loss=0.0494]07/20/2023 12:30:30 - INFO - __main__ - train loss is 3.444397209212184\n",
      "Steps:   1%|     | 217/15000 [01:59<44:20,  5.56it/s, lr=1e-5, step_loss=0.0135]07/20/2023 12:30:31 - INFO - __main__ - train loss is 3.6543218325823545\n",
      "Steps:   1%|       | 218/15000 [01:59<44:09,  5.58it/s, lr=1e-5, step_loss=0.21]07/20/2023 12:30:31 - INFO - __main__ - train loss is 3.658353229984641\n",
      "Steps:   1%|    | 219/15000 [01:59<44:00,  5.60it/s, lr=1e-5, step_loss=0.00403]07/20/2023 12:30:31 - INFO - __main__ - train loss is 3.7277531158179045\n",
      "Steps:   1%|     | 220/15000 [01:59<43:55,  5.61it/s, lr=1e-5, step_loss=0.0694]07/20/2023 12:30:31 - INFO - __main__ - train loss is 3.731323206797242\n",
      "Steps:   1%|    | 221/15000 [01:59<43:50,  5.62it/s, lr=1e-5, step_loss=0.00357]07/20/2023 12:30:31 - INFO - __main__ - train loss is 4.0539130214601755\n",
      "Steps:   1%|      | 222/15000 [01:59<43:47,  5.62it/s, lr=1e-5, step_loss=0.323]07/20/2023 12:30:31 - INFO - __main__ - train loss is 4.305952275171876\n",
      "Steps:   1%|      | 223/15000 [02:00<43:47,  5.62it/s, lr=1e-5, step_loss=0.252]07/20/2023 12:30:32 - INFO - __main__ - train loss is 4.316914841532707\n",
      "Steps:   1%|      | 224/15000 [02:00<43:49,  5.62it/s, lr=1e-5, step_loss=0.011]07/20/2023 12:30:32 - INFO - __main__ - train loss is 5.2236417979002\n",
      "Steps:   2%|      | 225/15000 [02:00<44:10,  5.57it/s, lr=1e-5, step_loss=0.907]07/20/2023 12:30:32 - INFO - __main__ - train loss is 5.237316537648439\n",
      "Steps:   2%|     | 226/15000 [02:00<44:18,  5.56it/s, lr=1e-5, step_loss=0.0137]07/20/2023 12:30:32 - INFO - __main__ - train loss is 5.8878716714680195\n",
      "Steps:   2%|      | 227/15000 [02:00<44:09,  5.58it/s, lr=1e-5, step_loss=0.651]07/20/2023 12:30:32 - INFO - __main__ - train loss is 6.138133484870195\n",
      "Steps:   2%|       | 228/15000 [02:00<44:00,  5.59it/s, lr=1e-5, step_loss=0.25]07/20/2023 12:30:33 - INFO - __main__ - train loss is 6.228538852185011\n",
      "Steps:   2%|     | 229/15000 [02:01<43:56,  5.60it/s, lr=1e-5, step_loss=0.0904]07/20/2023 12:30:33 - INFO - __main__ - train loss is 6.322348322719336\n",
      "Steps:   2%|     | 230/15000 [02:01<43:51,  5.61it/s, lr=1e-5, step_loss=0.0938]07/20/2023 12:30:33 - INFO - __main__ - train loss is 6.814896311610937\n",
      "Steps:   2%|      | 231/15000 [02:01<43:51,  5.61it/s, lr=1e-5, step_loss=0.493]07/20/2023 12:30:33 - INFO - __main__ - train loss is 6.92490940913558\n",
      "Steps:   2%|       | 232/15000 [02:01<44:12,  5.57it/s, lr=1e-5, step_loss=0.11]07/20/2023 12:30:33 - INFO - __main__ - train loss is 7.041081752628088\n",
      "Steps:   2%|      | 233/15000 [02:01<44:48,  5.49it/s, lr=1e-5, step_loss=0.116]07/20/2023 12:30:33 - INFO - __main__ - train loss is 7.15962104126811\n",
      "Steps:   2%|      | 234/15000 [02:02<44:53,  5.48it/s, lr=1e-5, step_loss=0.119]07/20/2023 12:30:34 - INFO - __main__ - train loss is 7.551534753292799\n",
      "Steps:   2%|      | 235/15000 [02:02<44:57,  5.47it/s, lr=1e-5, step_loss=0.392]07/20/2023 12:30:34 - INFO - __main__ - train loss is 7.620395731180906\n",
      "Steps:   2%|     | 236/15000 [02:02<44:58,  5.47it/s, lr=1e-5, step_loss=0.0689]07/20/2023 12:30:34 - INFO - __main__ - train loss is 7.794673528522253\n",
      "Steps:   2%|      | 237/15000 [02:02<45:21,  5.42it/s, lr=1e-5, step_loss=0.174]07/20/2023 12:30:34 - INFO - __main__ - train loss is 8.145131941884756\n",
      "Steps:   2%|       | 238/15000 [02:02<44:53,  5.48it/s, lr=1e-5, step_loss=0.35]07/20/2023 12:30:34 - INFO - __main__ - train loss is 8.508518811315298\n",
      "Steps:   2%|      | 239/15000 [02:02<44:31,  5.53it/s, lr=1e-5, step_loss=0.363]07/20/2023 12:30:35 - INFO - __main__ - train loss is 8.673924174159765\n",
      "Steps:   2%|      | 240/15000 [02:03<44:18,  5.55it/s, lr=1e-5, step_loss=0.165]07/20/2023 12:30:35 - INFO - __main__ - train loss is 9.268452372401953\n",
      "Steps:   2%|      | 241/15000 [02:03<44:13,  5.56it/s, lr=1e-5, step_loss=0.595]07/20/2023 12:30:35 - INFO - __main__ - train loss is 9.294984985142946\n",
      "Steps:   2%|     | 242/15000 [02:03<44:25,  5.54it/s, lr=1e-5, step_loss=0.0265]07/20/2023 12:30:35 - INFO - __main__ - train loss is 9.462311554700136\n",
      "Steps:   2%|      | 243/15000 [02:03<44:29,  5.53it/s, lr=1e-5, step_loss=0.167]07/20/2023 12:30:35 - INFO - __main__ - train loss is 10.045496392995119\n",
      "Steps:   2%|      | 244/15000 [02:03<44:36,  5.51it/s, lr=1e-5, step_loss=0.583]07/20/2023 12:30:35 - INFO - __main__ - train loss is 10.082556627690792\n",
      "Steps:   2%|     | 245/15000 [02:04<44:28,  5.53it/s, lr=1e-5, step_loss=0.0371]07/20/2023 12:30:36 - INFO - __main__ - train loss is 10.277786619961262\n",
      "Steps:   2%|      | 246/15000 [02:04<44:30,  5.52it/s, lr=1e-5, step_loss=0.195]07/20/2023 12:30:36 - INFO - __main__ - train loss is 10.280282248277217\n",
      "Steps:   2%|     | 247/15000 [02:04<44:38,  5.51it/s, lr=1e-5, step_loss=0.0025]07/20/2023 12:30:36 - INFO - __main__ - train loss is 10.42447503330186\n",
      "Steps:   2%|      | 248/15000 [02:04<44:28,  5.53it/s, lr=1e-5, step_loss=0.144]07/20/2023 12:30:36 - INFO - __main__ - train loss is 10.56347279669717\n",
      "Steps:   2%|      | 249/15000 [02:04<44:12,  5.56it/s, lr=1e-5, step_loss=0.139]07/20/2023 12:30:36 - INFO - __main__ - train loss is 10.63386206747964\n",
      "Steps:   2%|     | 250/15000 [02:04<44:24,  5.53it/s, lr=1e-5, step_loss=0.0704]07/20/2023 12:30:36 - INFO - __main__ - train loss is 10.946991194505244\n",
      "Steps:   2%|      | 251/15000 [02:05<44:19,  5.55it/s, lr=1e-5, step_loss=0.313]07/20/2023 12:30:37 - INFO - __main__ - train loss is 11.072817270178348\n",
      "Steps:   2%|      | 252/15000 [02:05<44:10,  5.56it/s, lr=1e-5, step_loss=0.126]07/20/2023 12:30:37 - INFO - __main__ - train loss is 11.089347884524614\n",
      "Steps:   2%|     | 253/15000 [02:05<44:02,  5.58it/s, lr=1e-5, step_loss=0.0165]07/20/2023 12:30:37 - INFO - __main__ - train loss is 11.130245306063443\n",
      "Steps:   2%|     | 254/15000 [02:05<43:55,  5.59it/s, lr=1e-5, step_loss=0.0409]07/20/2023 12:30:37 - INFO - __main__ - train loss is 11.132166248629801\n",
      "Steps:   2%|    | 255/15000 [02:05<43:50,  5.61it/s, lr=1e-5, step_loss=0.00192]07/20/2023 12:30:37 - INFO - __main__ - train loss is 11.370830339263193\n",
      "Steps:   2%|      | 256/15000 [02:06<43:52,  5.60it/s, lr=1e-5, step_loss=0.239]07/20/2023 12:30:38 - INFO - __main__ - train loss is 11.831359487841837\n",
      "Steps:   2%|      | 257/15000 [02:06<44:12,  5.56it/s, lr=1e-5, step_loss=0.461]07/20/2023 12:30:38 - INFO - __main__ - train loss is 11.877109357039444\n",
      "Steps:   2%|     | 258/15000 [02:06<44:03,  5.58it/s, lr=1e-5, step_loss=0.0457]07/20/2023 12:30:38 - INFO - __main__ - train loss is 11.965123602072708\n",
      "Steps:   2%|      | 259/15000 [02:06<43:56,  5.59it/s, lr=1e-5, step_loss=0.088]07/20/2023 12:30:38 - INFO - __main__ - train loss is 12.200178646366112\n",
      "Steps:   2%|      | 260/15000 [02:06<43:56,  5.59it/s, lr=1e-5, step_loss=0.235]07/20/2023 12:30:38 - INFO - __main__ - train loss is 12.2743285902543\n",
      "Steps:   2%|     | 261/15000 [02:06<43:49,  5.60it/s, lr=1e-5, step_loss=0.0741]07/20/2023 12:30:38 - INFO - __main__ - train loss is 12.412312419037335\n",
      "Steps:   2%|      | 262/15000 [02:07<44:11,  5.56it/s, lr=1e-5, step_loss=0.138]07/20/2023 12:30:39 - INFO - __main__ - train loss is 12.427745192195289\n",
      "Steps:   2%|     | 263/15000 [02:07<44:03,  5.57it/s, lr=1e-5, step_loss=0.0154]07/20/2023 12:30:39 - INFO - __main__ - train loss is 12.810448526288383\n",
      "Steps:   2%|      | 264/15000 [02:07<44:22,  5.53it/s, lr=1e-5, step_loss=0.383]07/20/2023 12:30:39 - INFO - __main__ - train loss is 13.166468649054877\n",
      "Steps:   2%|      | 265/15000 [02:07<44:10,  5.56it/s, lr=1e-5, step_loss=0.356]07/20/2023 12:30:39 - INFO - __main__ - train loss is 13.234293742920272\n",
      "Steps:   2%|     | 266/15000 [02:07<44:04,  5.57it/s, lr=1e-5, step_loss=0.0678]07/20/2023 12:30:39 - INFO - __main__ - train loss is 13.23977017623838\n",
      "Steps:   2%|    | 267/15000 [02:08<43:59,  5.58it/s, lr=1e-5, step_loss=0.00548]07/20/2023 12:30:40 - INFO - __main__ - train loss is 13.404561119503342\n",
      "Steps:   2%|      | 268/15000 [02:08<43:56,  5.59it/s, lr=1e-5, step_loss=0.165]07/20/2023 12:30:40 - INFO - __main__ - train loss is 13.60445161384996\n",
      "Steps:   2%|‚ñè       | 269/15000 [02:08<43:56,  5.59it/s, lr=1e-5, step_loss=0.2]07/20/2023 12:30:40 - INFO - __main__ - train loss is 13.617638185969554\n",
      "Steps:   2%|     | 270/15000 [02:08<43:50,  5.60it/s, lr=1e-5, step_loss=0.0132]07/20/2023 12:30:40 - INFO - __main__ - train loss is 13.967343554249965\n",
      "Steps:   2%|‚ñè      | 271/15000 [02:08<43:48,  5.60it/s, lr=1e-5, step_loss=0.35]07/20/2023 12:30:40 - INFO - __main__ - train loss is 14.156162098399363\n",
      "Steps:   2%|      | 272/15000 [02:08<43:44,  5.61it/s, lr=1e-5, step_loss=0.189]07/20/2023 12:30:40 - INFO - __main__ - train loss is 14.192549832514487\n",
      "Steps:   2%|     | 273/15000 [02:09<43:41,  5.62it/s, lr=1e-5, step_loss=0.0364]07/20/2023 12:30:41 - INFO - __main__ - train loss is 14.372562446049415\n",
      "Steps:   2%|‚ñè      | 274/15000 [02:09<43:40,  5.62it/s, lr=1e-5, step_loss=0.18]07/20/2023 12:30:41 - INFO - __main__ - train loss is 14.37516548007261\n",
      "Steps:   2%|     | 275/15000 [02:09<43:40,  5.62it/s, lr=1e-5, step_loss=0.0026]07/20/2023 12:30:41 - INFO - __main__ - train loss is 14.452754559810273\n",
      "Steps:   2%|     | 276/15000 [02:09<43:36,  5.63it/s, lr=1e-5, step_loss=0.0776]07/20/2023 12:30:41 - INFO - __main__ - train loss is 14.996614399249665\n",
      "Steps:   2%|      | 277/15000 [02:09<43:37,  5.62it/s, lr=1e-5, step_loss=0.544]07/20/2023 12:30:41 - INFO - __main__ - train loss is 15.054543732549064\n",
      "Steps:   2%|     | 278/15000 [02:09<43:34,  5.63it/s, lr=1e-5, step_loss=0.0579]07/20/2023 12:30:41 - INFO - __main__ - train loss is 15.423689751769416\n",
      "Steps:   2%|      | 279/15000 [02:10<43:51,  5.59it/s, lr=1e-5, step_loss=0.369]07/20/2023 12:30:42 - INFO - __main__ - train loss is 15.471947251702659\n",
      "Steps:   2%|     | 280/15000 [02:10<43:52,  5.59it/s, lr=1e-5, step_loss=0.0483]07/20/2023 12:30:42 - INFO - __main__ - train loss is 15.618819757248275\n",
      "Steps:   2%|      | 281/15000 [02:10<43:45,  5.61it/s, lr=1e-5, step_loss=0.147]07/20/2023 12:30:42 - INFO - __main__ - train loss is 15.631174243870191\n",
      "Steps:   2%|     | 282/15000 [02:10<43:51,  5.59it/s, lr=1e-5, step_loss=0.0124]07/20/2023 12:30:42 - INFO - __main__ - train loss is 15.63821890798863\n",
      "Steps:   2%|    | 283/15000 [02:10<44:07,  5.56it/s, lr=1e-5, step_loss=0.00704]07/20/2023 12:30:42 - INFO - __main__ - train loss is 15.645227589528076\n",
      "Steps:   2%|    | 284/15000 [02:11<44:15,  5.54it/s, lr=1e-5, step_loss=0.00701]07/20/2023 12:30:43 - INFO - __main__ - train loss is 15.65226205100771\n",
      "Steps:   2%|    | 285/15000 [02:11<44:05,  5.56it/s, lr=1e-5, step_loss=0.00703]07/20/2023 12:30:43 - INFO - __main__ - train loss is 15.992055017850362\n",
      "Steps:   2%|‚ñè      | 286/15000 [02:11<43:53,  5.59it/s, lr=1e-5, step_loss=0.34]07/20/2023 12:30:43 - INFO - __main__ - train loss is 15.994577969308011\n",
      "Steps:   2%|    | 287/15000 [02:11<43:51,  5.59it/s, lr=1e-5, step_loss=0.00252]07/20/2023 12:30:43 - INFO - __main__ - train loss is 16.004677127930336\n",
      "Steps:   2%|     | 288/15000 [02:11<43:45,  5.60it/s, lr=1e-5, step_loss=0.0101]07/20/2023 12:30:43 - INFO - __main__ - train loss is 16.0229616536526\n",
      "Steps:   2%|     | 289/15000 [02:11<43:55,  5.58it/s, lr=1e-5, step_loss=0.0183]07/20/2023 12:30:43 - INFO - __main__ - train loss is 16.162962235393934\n",
      "Steps:   2%|‚ñè      | 290/15000 [02:12<43:51,  5.59it/s, lr=1e-5, step_loss=0.14]07/20/2023 12:30:44 - INFO - __main__ - train loss is 16.170513126882724\n",
      "Steps:   2%|    | 291/15000 [02:12<59:24,  4.13it/s, lr=1e-5, step_loss=0.00755]07/20/2023 12:30:44 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:44 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:44 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Per validation step average loss is 0.015274960547685623\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Cumulative validation average loss is 0.015274960547685623\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Per validation step average loss is 0.002026628702878952\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Cumulative validation average loss is 0.017301589250564575\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441043])\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Post-squeeze shape torch.Size([441043])\n",
      "07/20/2023 12:30:45 - INFO - __main__ - Post-avg shape torch.Size([441043])\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Per validation step average loss is 0.0815223753452301\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Cumulative validation average loss is 0.09882396459579468\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Per validation step average loss is 0.3172498941421509\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Cumulative validation average loss is 0.41607385873794556\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:46 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Per validation step average loss is 0.14667166769504547\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Cumulative validation average loss is 0.562745526432991\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Per validation step average loss is 0.0019078406039625406\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Cumulative validation average loss is 0.5646533670369536\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:47 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Per validation step average loss is 0.2128053605556488\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Cumulative validation average loss is 0.7774587275926024\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Per validation step average loss is 0.4680548906326294\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Cumulative validation average loss is 1.2455136182252318\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:48 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Per validation step average loss is 0.08867265284061432\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Cumulative validation average loss is 1.334186271065846\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Per validation step average loss is 0.007117206230759621\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Cumulative validation average loss is 1.3413034772966057\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Per validation step average loss is 0.06813761591911316\n",
      "07/20/2023 12:30:49 - INFO - __main__ - Cumulative validation average loss is 1.4094410932157189\n",
      "07/20/2023 12:30:50 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:30:50 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:30:50 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:30:50 - INFO - __main__ - Per validation step average loss is 0.003517637960612774\n",
      "07/20/2023 12:30:50 - INFO - __main__ - Cumulative validation average loss is 1.4129587311763316\n",
      "07/20/2023 12:30:50 - INFO - __main__ - Average validation loss for Epoch 2 is 0.11774656093136097\n",
      "07/20/2023 12:30:50 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "07/20/2023 12:31:03 - INFO - __main__ - Starting epoch 3\n",
      "07/20/2023 12:31:03 - INFO - __main__ - train loss is 0.2510793209075928\n",
      "Steps:   2%|   | 292/15000 [02:31<24:27:34,  5.99s/it, lr=1e-5, step_loss=0.251]07/20/2023 12:31:03 - INFO - __main__ - train loss is 0.29534081369638443\n",
      "Steps:   2%|  | 293/15000 [02:32<17:20:52,  4.25s/it, lr=1e-5, step_loss=0.0443]07/20/2023 12:31:04 - INFO - __main__ - train loss is 0.49948058277368546\n",
      "Steps:   2%|   | 294/15000 [02:32<12:22:45,  3.03s/it, lr=1e-5, step_loss=0.204]07/20/2023 12:31:04 - INFO - __main__ - train loss is 0.573175773024559\n",
      "Steps:   2%|   | 295/15000 [02:32<8:54:18,  2.18s/it, lr=1e-5, step_loss=0.0737]07/20/2023 12:31:04 - INFO - __main__ - train loss is 0.5753403659909964\n",
      "Steps:   2%|  | 296/15000 [02:32<6:27:06,  1.58s/it, lr=1e-5, step_loss=0.00216]07/20/2023 12:31:04 - INFO - __main__ - train loss is 0.5770887101534754\n",
      "Steps:   2%|  | 297/15000 [02:32<4:44:04,  1.16s/it, lr=1e-5, step_loss=0.00175]07/20/2023 12:31:04 - INFO - __main__ - train loss is 0.5795622523874044\n",
      "Steps:   2%|  | 298/15000 [02:33<3:32:23,  1.15it/s, lr=1e-5, step_loss=0.00247]07/20/2023 12:31:05 - INFO - __main__ - train loss is 0.8583693262189627\n",
      "Steps:   2%|    | 299/15000 [02:33<2:42:39,  1.51it/s, lr=1e-5, step_loss=0.279]07/20/2023 12:31:05 - INFO - __main__ - train loss is 0.8808784876018763\n",
      "Steps:   2%|   | 300/15000 [02:33<2:07:40,  1.92it/s, lr=1e-5, step_loss=0.0225]07/20/2023 12:31:05 - INFO - __main__ - train loss is 0.8893541265279055\n",
      "Steps:   2%|  | 301/15000 [02:33<1:42:26,  2.39it/s, lr=1e-5, step_loss=0.00848]07/20/2023 12:31:05 - INFO - __main__ - train loss is 0.9707907009869814\n",
      "Steps:   2%|   | 302/15000 [02:33<1:25:15,  2.87it/s, lr=1e-5, step_loss=0.0814]07/20/2023 12:31:05 - INFO - __main__ - train loss is 1.0700812507420778\n",
      "Steps:   2%|   | 303/15000 [02:33<1:14:03,  3.31it/s, lr=1e-5, step_loss=0.0993]07/20/2023 12:31:05 - INFO - __main__ - train loss is 1.1792413014918566\n",
      "Steps:   2%|    | 304/15000 [02:34<1:05:52,  3.72it/s, lr=1e-5, step_loss=0.109]07/20/2023 12:31:06 - INFO - __main__ - train loss is 1.3663786370307207\n",
      "Steps:   2%|      | 305/15000 [02:34<59:59,  4.08it/s, lr=1e-5, step_loss=0.187]07/20/2023 12:31:06 - INFO - __main__ - train loss is 1.3751554321497679\n",
      "Steps:   2%|    | 306/15000 [02:34<55:35,  4.40it/s, lr=1e-5, step_loss=0.00878]07/20/2023 12:31:06 - INFO - __main__ - train loss is 1.6048582028597593\n",
      "Steps:   2%|‚ñè      | 307/15000 [02:34<52:06,  4.70it/s, lr=1e-5, step_loss=0.23]07/20/2023 12:31:06 - INFO - __main__ - train loss is 2.026720179244876\n",
      "Steps:   2%|      | 308/15000 [02:34<49:31,  4.94it/s, lr=1e-5, step_loss=0.422]07/20/2023 12:31:06 - INFO - __main__ - train loss is 2.235017968341708\n",
      "Steps:   2%|      | 309/15000 [02:35<48:06,  5.09it/s, lr=1e-5, step_loss=0.208]07/20/2023 12:31:07 - INFO - __main__ - train loss is 2.2995511423796415\n",
      "Steps:   2%|     | 310/15000 [02:35<46:47,  5.23it/s, lr=1e-5, step_loss=0.0645]07/20/2023 12:31:07 - INFO - __main__ - train loss is 2.3248335141688585\n",
      "Steps:   2%|     | 311/15000 [02:35<46:13,  5.30it/s, lr=1e-5, step_loss=0.0253]07/20/2023 12:31:07 - INFO - __main__ - train loss is 2.405332075431943\n",
      "Steps:   2%|     | 312/15000 [02:35<46:14,  5.29it/s, lr=1e-5, step_loss=0.0805]07/20/2023 12:31:07 - INFO - __main__ - train loss is 2.5933832991868258\n",
      "Steps:   2%|‚ñè     | 313/15000 [02:35<46:00,  5.32it/s, lr=1e-5, step_loss=0.188]07/20/2023 12:31:07 - INFO - __main__ - train loss is 2.616698009893298\n",
      "Steps:   2%|     | 314/15000 [02:35<45:25,  5.39it/s, lr=1e-5, step_loss=0.0233]07/20/2023 12:31:08 - INFO - __main__ - train loss is 3.256991608068347\n",
      "Steps:   2%|‚ñè      | 315/15000 [02:36<45:03,  5.43it/s, lr=1e-5, step_loss=0.64]07/20/2023 12:31:08 - INFO - __main__ - train loss is 3.5287164580076933\n",
      "Steps:   2%|‚ñè     | 316/15000 [02:36<44:48,  5.46it/s, lr=1e-5, step_loss=0.272]07/20/2023 12:31:08 - INFO - __main__ - train loss is 3.5329202725552022\n",
      "Steps:   2%|     | 317/15000 [02:36<44:37,  5.48it/s, lr=1e-5, step_loss=0.0042]07/20/2023 12:31:08 - INFO - __main__ - train loss is 3.7189763500355184\n",
      "Steps:   2%|‚ñè     | 318/15000 [02:36<44:28,  5.50it/s, lr=1e-5, step_loss=0.186]07/20/2023 12:31:08 - INFO - __main__ - train loss is 3.758284905459732\n",
      "Steps:   2%|     | 319/15000 [02:36<44:27,  5.50it/s, lr=1e-5, step_loss=0.0393]07/20/2023 12:31:08 - INFO - __main__ - train loss is 3.9921695380471647\n",
      "Steps:   2%|‚ñè     | 320/15000 [02:37<44:23,  5.51it/s, lr=1e-5, step_loss=0.234]07/20/2023 12:31:09 - INFO - __main__ - train loss is 4.10163759579882\n",
      "Steps:   2%|‚ñè     | 321/15000 [02:37<44:19,  5.52it/s, lr=1e-5, step_loss=0.109]07/20/2023 12:31:09 - INFO - __main__ - train loss is 4.233107292558998\n",
      "Steps:   2%|‚ñè     | 322/15000 [02:37<44:19,  5.52it/s, lr=1e-5, step_loss=0.131]07/20/2023 12:31:09 - INFO - __main__ - train loss is 4.237822371535003\n",
      "Steps:   2%|    | 323/15000 [02:37<44:12,  5.53it/s, lr=1e-5, step_loss=0.00472]07/20/2023 12:31:09 - INFO - __main__ - train loss is 4.247030868194997\n",
      "Steps:   2%|    | 324/15000 [02:37<44:10,  5.54it/s, lr=1e-5, step_loss=0.00921]07/20/2023 12:31:09 - INFO - __main__ - train loss is 4.601132764481008\n",
      "Steps:   2%|‚ñè     | 325/15000 [02:37<44:01,  5.56it/s, lr=1e-5, step_loss=0.354]07/20/2023 12:31:09 - INFO - __main__ - train loss is 4.612555171363056\n",
      "Steps:   2%|     | 326/15000 [02:38<43:53,  5.57it/s, lr=1e-5, step_loss=0.0114]07/20/2023 12:31:10 - INFO - __main__ - train loss is 4.673346470110118\n",
      "Steps:   2%|     | 327/15000 [02:38<43:47,  5.58it/s, lr=1e-5, step_loss=0.0608]07/20/2023 12:31:10 - INFO - __main__ - train loss is 4.8017848981544375\n",
      "Steps:   2%|‚ñè     | 328/15000 [02:38<43:45,  5.59it/s, lr=1e-5, step_loss=0.128]07/20/2023 12:31:10 - INFO - __main__ - train loss is 4.959732542745769\n",
      "Steps:   2%|‚ñè     | 329/15000 [02:38<43:44,  5.59it/s, lr=1e-5, step_loss=0.158]07/20/2023 12:31:10 - INFO - __main__ - train loss is 5.0022733537480235\n",
      "Steps:   2%|     | 330/15000 [02:38<43:45,  5.59it/s, lr=1e-5, step_loss=0.0425]07/20/2023 12:31:10 - INFO - __main__ - train loss is 5.1124631417915225\n",
      "Steps:   2%|‚ñè      | 331/15000 [02:39<43:46,  5.59it/s, lr=1e-5, step_loss=0.11]07/20/2023 12:31:11 - INFO - __main__ - train loss is 5.216856638900936\n",
      "Steps:   2%|‚ñè     | 332/15000 [02:39<43:45,  5.59it/s, lr=1e-5, step_loss=0.104]07/20/2023 12:31:11 - INFO - __main__ - train loss is 5.220800393261015\n",
      "Steps:   2%|    | 333/15000 [02:39<43:45,  5.59it/s, lr=1e-5, step_loss=0.00394]07/20/2023 12:31:11 - INFO - __main__ - train loss is 5.233428157866001\n",
      "Steps:   2%|     | 334/15000 [02:39<43:42,  5.59it/s, lr=1e-5, step_loss=0.0126]07/20/2023 12:31:11 - INFO - __main__ - train loss is 5.3247304782271385\n",
      "Steps:   2%|     | 335/15000 [02:39<43:44,  5.59it/s, lr=1e-5, step_loss=0.0913]07/20/2023 12:31:11 - INFO - __main__ - train loss is 5.595585696399212\n",
      "Steps:   2%|‚ñè     | 336/15000 [02:39<44:07,  5.54it/s, lr=1e-5, step_loss=0.271]07/20/2023 12:31:11 - INFO - __main__ - train loss is 5.788313798606396\n",
      "Steps:   2%|‚ñè     | 337/15000 [02:40<44:08,  5.54it/s, lr=1e-5, step_loss=0.193]07/20/2023 12:31:12 - INFO - __main__ - train loss is 5.828224919736385\n",
      "Steps:   2%|     | 338/15000 [02:40<44:00,  5.55it/s, lr=1e-5, step_loss=0.0399]07/20/2023 12:31:12 - INFO - __main__ - train loss is 5.956696264445782\n",
      "Steps:   2%|‚ñè     | 339/15000 [02:40<43:52,  5.57it/s, lr=1e-5, step_loss=0.128]07/20/2023 12:31:12 - INFO - __main__ - train loss is 5.962132328655571\n",
      "Steps:   2%|    | 340/15000 [02:40<43:45,  5.58it/s, lr=1e-5, step_loss=0.00544]07/20/2023 12:31:12 - INFO - __main__ - train loss is 6.134076678659767\n",
      "Steps:   2%|‚ñè     | 341/15000 [02:40<43:41,  5.59it/s, lr=1e-5, step_loss=0.172]07/20/2023 12:31:12 - INFO - __main__ - train loss is 6.136051717214286\n",
      "Steps:   2%|    | 342/15000 [02:41<43:39,  5.60it/s, lr=1e-5, step_loss=0.00198]07/20/2023 12:31:13 - INFO - __main__ - train loss is 6.22915458958596\n",
      "Steps:   2%|     | 343/15000 [02:41<43:36,  5.60it/s, lr=1e-5, step_loss=0.0931]07/20/2023 12:31:13 - INFO - __main__ - train loss is 6.268798950128257\n",
      "Steps:   2%|     | 344/15000 [02:41<43:34,  5.60it/s, lr=1e-5, step_loss=0.0396]07/20/2023 12:31:13 - INFO - __main__ - train loss is 6.276874196715653\n",
      "Steps:   2%|    | 345/15000 [02:41<43:34,  5.60it/s, lr=1e-5, step_loss=0.00808]07/20/2023 12:31:13 - INFO - __main__ - train loss is 6.292656068690121\n",
      "Steps:   2%|     | 346/15000 [02:41<43:38,  5.60it/s, lr=1e-5, step_loss=0.0158]07/20/2023 12:31:13 - INFO - __main__ - train loss is 6.9056458519771695\n",
      "Steps:   2%|‚ñè     | 347/15000 [02:41<43:38,  5.60it/s, lr=1e-5, step_loss=0.613]07/20/2023 12:31:13 - INFO - __main__ - train loss is 6.965077736414969\n",
      "Steps:   2%|     | 348/15000 [02:42<43:37,  5.60it/s, lr=1e-5, step_loss=0.0594]07/20/2023 12:31:14 - INFO - __main__ - train loss is 6.968010030686855\n",
      "Steps:   2%|    | 349/15000 [02:42<43:34,  5.60it/s, lr=1e-5, step_loss=0.00293]07/20/2023 12:31:14 - INFO - __main__ - train loss is 7.132607273757458\n",
      "Steps:   2%|‚ñè     | 350/15000 [02:42<43:33,  5.61it/s, lr=1e-5, step_loss=0.165]07/20/2023 12:31:14 - INFO - __main__ - train loss is 7.135664751753211\n",
      "Steps:   2%|    | 351/15000 [02:42<43:35,  5.60it/s, lr=1e-5, step_loss=0.00306]07/20/2023 12:31:14 - INFO - __main__ - train loss is 7.151656422764063\n",
      "Steps:   2%|‚ñè     | 352/15000 [02:42<43:33,  5.60it/s, lr=1e-5, step_loss=0.016]07/20/2023 12:31:14 - INFO - __main__ - train loss is 7.208652522414923\n",
      "Steps:   2%|‚ñè     | 353/15000 [02:42<43:34,  5.60it/s, lr=1e-5, step_loss=0.057]07/20/2023 12:31:14 - INFO - __main__ - train loss is 7.285431418567896\n",
      "Steps:   2%|     | 354/15000 [02:43<43:36,  5.60it/s, lr=1e-5, step_loss=0.0768]07/20/2023 12:31:15 - INFO - __main__ - train loss is 7.393113199621439\n",
      "Steps:   2%|‚ñè     | 355/15000 [02:43<43:37,  5.60it/s, lr=1e-5, step_loss=0.108]07/20/2023 12:31:15 - INFO - __main__ - train loss is 7.453440081328154\n",
      "Steps:   2%|     | 356/15000 [02:43<43:47,  5.57it/s, lr=1e-5, step_loss=0.0603]07/20/2023 12:31:15 - INFO - __main__ - train loss is 7.542265471071005\n",
      "Steps:   2%|     | 357/15000 [02:43<43:44,  5.58it/s, lr=1e-5, step_loss=0.0888]07/20/2023 12:31:15 - INFO - __main__ - train loss is 7.806489434093237\n",
      "Steps:   2%|‚ñè     | 358/15000 [02:43<43:41,  5.59it/s, lr=1e-5, step_loss=0.264]07/20/2023 12:31:15 - INFO - __main__ - train loss is 7.867024838924408\n",
      "Steps:   2%|     | 359/15000 [02:44<43:50,  5.57it/s, lr=1e-5, step_loss=0.0605]07/20/2023 12:31:16 - INFO - __main__ - train loss is 8.263658106327057\n",
      "Steps:   2%|‚ñè     | 360/15000 [02:44<43:46,  5.57it/s, lr=1e-5, step_loss=0.397]07/20/2023 12:31:16 - INFO - __main__ - train loss is 8.267586782574654\n",
      "Steps:   2%|    | 361/15000 [02:44<43:41,  5.58it/s, lr=1e-5, step_loss=0.00393]07/20/2023 12:31:16 - INFO - __main__ - train loss is 8.545053824782372\n",
      "Steps:   2%|‚ñè     | 362/15000 [02:44<43:39,  5.59it/s, lr=1e-5, step_loss=0.277]07/20/2023 12:31:16 - INFO - __main__ - train loss is 8.547169242287055\n",
      "Steps:   2%|    | 363/15000 [02:44<44:24,  5.49it/s, lr=1e-5, step_loss=0.00212]07/20/2023 12:31:16 - INFO - __main__ - train loss is 8.773320976877585\n",
      "Steps:   2%|‚ñè     | 364/15000 [02:44<44:20,  5.50it/s, lr=1e-5, step_loss=0.226]07/20/2023 12:31:16 - INFO - __main__ - train loss is 8.899948690319434\n",
      "Steps:   2%|‚ñè     | 365/15000 [02:45<44:11,  5.52it/s, lr=1e-5, step_loss=0.127]07/20/2023 12:31:17 - INFO - __main__ - train loss is 9.283611241960898\n",
      "Steps:   2%|‚ñè     | 366/15000 [02:45<43:57,  5.55it/s, lr=1e-5, step_loss=0.384]07/20/2023 12:31:17 - INFO - __main__ - train loss is 9.464773107552901\n",
      "Steps:   2%|‚ñè     | 367/15000 [02:45<44:05,  5.53it/s, lr=1e-5, step_loss=0.181]07/20/2023 12:31:17 - INFO - __main__ - train loss is 9.739882815862074\n",
      "Steps:   2%|‚ñè     | 368/15000 [02:45<45:16,  5.39it/s, lr=1e-5, step_loss=0.275]07/20/2023 12:31:17 - INFO - __main__ - train loss is 9.744490830460563\n",
      "Steps:   2%|    | 369/15000 [02:45<45:24,  5.37it/s, lr=1e-5, step_loss=0.00461]07/20/2023 12:31:17 - INFO - __main__ - train loss is 9.756809637183324\n",
      "Steps:   2%|     | 370/15000 [02:46<45:04,  5.41it/s, lr=1e-5, step_loss=0.0123]07/20/2023 12:31:18 - INFO - __main__ - train loss is 10.02926941239275\n",
      "Steps:   2%|‚ñè     | 371/15000 [02:46<44:36,  5.47it/s, lr=1e-5, step_loss=0.272]07/20/2023 12:31:18 - INFO - __main__ - train loss is 10.23399753891863\n",
      "Steps:   2%|‚ñè     | 372/15000 [02:46<44:47,  5.44it/s, lr=1e-5, step_loss=0.205]07/20/2023 12:31:18 - INFO - __main__ - train loss is 10.251352843130007\n",
      "Steps:   2%|     | 373/15000 [02:46<44:24,  5.49it/s, lr=1e-5, step_loss=0.0174]07/20/2023 12:31:18 - INFO - __main__ - train loss is 10.47981395968236\n",
      "Steps:   2%|‚ñè     | 374/15000 [02:46<46:36,  5.23it/s, lr=1e-5, step_loss=0.228]07/20/2023 12:31:18 - INFO - __main__ - train loss is 10.833223905647174\n",
      "Steps:   2%|‚ñè     | 375/15000 [02:47<46:35,  5.23it/s, lr=1e-5, step_loss=0.353]07/20/2023 12:31:19 - INFO - __main__ - train loss is 10.929897245252505\n",
      "Steps:   3%|‚ñè    | 376/15000 [02:47<45:36,  5.34it/s, lr=1e-5, step_loss=0.0967]07/20/2023 12:31:19 - INFO - __main__ - train loss is 10.949622340733185\n",
      "Steps:   3%|‚ñè    | 377/15000 [02:47<44:55,  5.43it/s, lr=1e-5, step_loss=0.0197]07/20/2023 12:31:19 - INFO - __main__ - train loss is 11.426520712906495\n",
      "Steps:   3%|‚ñè     | 378/15000 [02:47<44:25,  5.49it/s, lr=1e-5, step_loss=0.477]07/20/2023 12:31:19 - INFO - __main__ - train loss is 11.490177065366879\n",
      "Steps:   3%|‚ñè    | 379/15000 [02:47<44:07,  5.52it/s, lr=1e-5, step_loss=0.0637]07/20/2023 12:31:19 - INFO - __main__ - train loss is 11.492260267492384\n",
      "Steps:   3%|    | 380/15000 [02:47<43:52,  5.55it/s, lr=1e-5, step_loss=0.00208]07/20/2023 12:31:19 - INFO - __main__ - train loss is 11.666502302046865\n",
      "Steps:   3%|‚ñè     | 381/15000 [02:48<43:38,  5.58it/s, lr=1e-5, step_loss=0.174]07/20/2023 12:31:20 - INFO - __main__ - train loss is 11.821309690829366\n",
      "Steps:   3%|‚ñè     | 382/15000 [02:48<43:30,  5.60it/s, lr=1e-5, step_loss=0.155]07/20/2023 12:31:20 - INFO - __main__ - train loss is 12.237432425376028\n",
      "Steps:   3%|‚ñè     | 383/15000 [02:48<43:27,  5.61it/s, lr=1e-5, step_loss=0.416]07/20/2023 12:31:20 - INFO - __main__ - train loss is 12.241965167224407\n",
      "Steps:   3%|    | 384/15000 [02:48<43:27,  5.60it/s, lr=1e-5, step_loss=0.00453]07/20/2023 12:31:20 - INFO - __main__ - train loss is 12.48402202874422\n",
      "Steps:   3%|‚ñè     | 385/15000 [02:48<43:24,  5.61it/s, lr=1e-5, step_loss=0.242]07/20/2023 12:31:20 - INFO - __main__ - train loss is 12.500870142132044\n",
      "Steps:   3%|‚ñè    | 386/15000 [02:48<43:21,  5.62it/s, lr=1e-5, step_loss=0.0168]07/20/2023 12:31:20 - INFO - __main__ - train loss is 12.93517017737031\n",
      "Steps:   3%|‚ñè     | 387/15000 [02:49<43:20,  5.62it/s, lr=1e-5, step_loss=0.434]07/20/2023 12:31:21 - INFO - __main__ - train loss is 12.984616059809923\n",
      "Steps:   3%|‚ñè    | 388/15000 [02:49<58:58,  4.13it/s, lr=1e-5, step_loss=0.0494]07/20/2023 12:31:22 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Per validation step average loss is 0.006496543530374765\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Cumulative validation average loss is 0.006496543530374765\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Per validation step average loss is 0.07273948192596436\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Cumulative validation average loss is 0.07923602545633912\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441043])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Post-squeeze shape torch.Size([441043])\n",
      "07/20/2023 12:31:22 - INFO - __main__ - Post-avg shape torch.Size([441043])\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Per validation step average loss is 0.004066602326929569\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Cumulative validation average loss is 0.08330262778326869\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Per validation step average loss is 0.17222675681114197\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Cumulative validation average loss is 0.25552938459441066\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:23 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Per validation step average loss is 0.19223284721374512\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Cumulative validation average loss is 0.4477622318081558\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Per validation step average loss is 0.002994519891217351\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Cumulative validation average loss is 0.4507567516993731\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:24 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Per validation step average loss is 0.18927618861198425\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Cumulative validation average loss is 0.6400329403113574\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Per validation step average loss is 0.6343203783035278\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Cumulative validation average loss is 1.2743533186148852\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:25 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Per validation step average loss is 0.17967522144317627\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Cumulative validation average loss is 1.4540285400580615\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Per validation step average loss is 0.015154673717916012\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Cumulative validation average loss is 1.4691832137759775\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:31:26 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Per validation step average loss is 0.003945118747651577\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Cumulative validation average loss is 1.473128332523629\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Per validation step average loss is 0.08351710438728333\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Cumulative validation average loss is 1.5566454369109124\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Average validation loss for Epoch 3 is 0.12972045307590938\n",
      "07/20/2023 12:31:27 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "07/20/2023 12:31:40 - INFO - __main__ - Starting epoch 4\n",
      "07/20/2023 12:31:40 - INFO - __main__ - train loss is 0.282459557056427\n",
      "Steps:   3%|   | 389/15000 [03:09<24:33:13,  6.05s/it, lr=1e-5, step_loss=0.282]07/20/2023 12:31:41 - INFO - __main__ - train loss is 0.3360542580485344\n",
      "Steps:   3%|  | 390/15000 [03:09<17:24:45,  4.29s/it, lr=1e-5, step_loss=0.0536]07/20/2023 12:31:41 - INFO - __main__ - train loss is 0.3400742029771209\n",
      "Steps:   3%| | 391/15000 [03:09<12:24:14,  3.06s/it, lr=1e-5, step_loss=0.00402]07/20/2023 12:31:41 - INFO - __main__ - train loss is 0.5502251600846648\n",
      "Steps:   3%|‚ñè    | 392/15000 [03:09<8:53:58,  2.19s/it, lr=1e-5, step_loss=0.21]07/20/2023 12:31:41 - INFO - __main__ - train loss is 0.6522611072286963\n",
      "Steps:   3%|    | 393/15000 [03:09<6:26:52,  1.59s/it, lr=1e-5, step_loss=0.102]07/20/2023 12:31:41 - INFO - __main__ - train loss is 0.8000401249155402\n",
      "Steps:   3%|    | 394/15000 [03:10<4:43:53,  1.17s/it, lr=1e-5, step_loss=0.148]07/20/2023 12:31:42 - INFO - __main__ - train loss is 0.8453548392280936\n",
      "Steps:   3%|   | 395/15000 [03:10<3:31:47,  1.15it/s, lr=1e-5, step_loss=0.0453]07/20/2023 12:31:42 - INFO - __main__ - train loss is 0.9938928922638297\n",
      "Steps:   3%|    | 396/15000 [03:10<2:41:10,  1.51it/s, lr=1e-5, step_loss=0.149]07/20/2023 12:31:42 - INFO - __main__ - train loss is 1.0072724148631096\n",
      "Steps:   3%|   | 397/15000 [03:10<2:05:43,  1.94it/s, lr=1e-5, step_loss=0.0134]07/20/2023 12:31:42 - INFO - __main__ - train loss is 1.174207128584385\n",
      "Steps:   3%|    | 398/15000 [03:10<1:40:56,  2.41it/s, lr=1e-5, step_loss=0.167]07/20/2023 12:31:42 - INFO - __main__ - train loss is 1.179253140464425\n",
      "Steps:   3%|  | 399/15000 [03:10<1:23:40,  2.91it/s, lr=1e-5, step_loss=0.00505]07/20/2023 12:31:42 - INFO - __main__ - train loss is 1.1932703303173184\n",
      "Steps:   3%|    | 400/15000 [03:11<1:11:29,  3.40it/s, lr=1e-5, step_loss=0.014]07/20/2023 12:31:43 - INFO - __main__ - train loss is 1.2070494731888175\n",
      "Steps:   3%|   | 401/15000 [03:11<1:02:59,  3.86it/s, lr=1e-5, step_loss=0.0138]07/20/2023 12:31:43 - INFO - __main__ - train loss is 1.2090991884469986\n",
      "Steps:   3%|    | 402/15000 [03:11<57:06,  4.26it/s, lr=1e-5, step_loss=0.00205]07/20/2023 12:31:43 - INFO - __main__ - train loss is 1.2736642435193062\n",
      "Steps:   3%|‚ñè    | 403/15000 [03:11<52:58,  4.59it/s, lr=1e-5, step_loss=0.0646]07/20/2023 12:31:43 - INFO - __main__ - train loss is 1.3011003527790308\n",
      "Steps:   3%|‚ñè    | 404/15000 [03:11<50:03,  4.86it/s, lr=1e-5, step_loss=0.0274]07/20/2023 12:31:43 - INFO - __main__ - train loss is 1.3756141308695078\n",
      "Steps:   3%|‚ñè    | 405/15000 [03:11<48:00,  5.07it/s, lr=1e-5, step_loss=0.0745]07/20/2023 12:31:44 - INFO - __main__ - train loss is 1.4681263361126184\n",
      "Steps:   3%|‚ñè    | 406/15000 [03:12<46:33,  5.22it/s, lr=1e-5, step_loss=0.0925]07/20/2023 12:31:44 - INFO - __main__ - train loss is 1.4729269105009735\n",
      "Steps:   3%|‚ñè    | 407/15000 [03:12<45:47,  5.31it/s, lr=1e-5, step_loss=0.0048]07/20/2023 12:31:44 - INFO - __main__ - train loss is 1.4933973415754735\n",
      "Steps:   3%|‚ñè    | 408/15000 [03:12<45:22,  5.36it/s, lr=1e-5, step_loss=0.0205]07/20/2023 12:31:44 - INFO - __main__ - train loss is 1.6469223364256322\n",
      "Steps:   3%|‚ñè     | 409/15000 [03:12<44:47,  5.43it/s, lr=1e-5, step_loss=0.154]07/20/2023 12:31:44 - INFO - __main__ - train loss is 1.6520052319392562\n",
      "Steps:   3%|    | 410/15000 [03:12<44:21,  5.48it/s, lr=1e-5, step_loss=0.00508]07/20/2023 12:31:44 - INFO - __main__ - train loss is 1.825467369519174\n",
      "Steps:   3%|‚ñè     | 411/15000 [03:13<44:02,  5.52it/s, lr=1e-5, step_loss=0.173]07/20/2023 12:31:45 - INFO - __main__ - train loss is 2.0985399102792144\n",
      "Steps:   3%|‚ñè     | 412/15000 [03:13<43:48,  5.55it/s, lr=1e-5, step_loss=0.273]07/20/2023 12:31:45 - INFO - __main__ - train loss is 2.358768663369119\n",
      "Steps:   3%|‚ñè      | 413/15000 [03:13<43:39,  5.57it/s, lr=1e-5, step_loss=0.26]07/20/2023 12:31:45 - INFO - __main__ - train loss is 2.386526624672115\n",
      "Steps:   3%|‚ñè    | 414/15000 [03:13<43:31,  5.59it/s, lr=1e-5, step_loss=0.0278]07/20/2023 12:31:45 - INFO - __main__ - train loss is 2.5023723049089313\n",
      "Steps:   3%|‚ñè     | 415/15000 [03:13<43:28,  5.59it/s, lr=1e-5, step_loss=0.116]07/20/2023 12:31:45 - INFO - __main__ - train loss is 2.621135259978473\n",
      "Steps:   3%|‚ñè     | 416/15000 [03:13<43:26,  5.59it/s, lr=1e-5, step_loss=0.119]07/20/2023 12:31:45 - INFO - __main__ - train loss is 2.693326319567859\n",
      "Steps:   3%|‚ñè    | 417/15000 [03:14<43:33,  5.58it/s, lr=1e-5, step_loss=0.0722]07/20/2023 12:31:46 - INFO - __main__ - train loss is 2.940587873570621\n",
      "Steps:   3%|‚ñè     | 418/15000 [03:14<43:31,  5.58it/s, lr=1e-5, step_loss=0.247]07/20/2023 12:31:46 - INFO - __main__ - train loss is 3.166398103348911\n",
      "Steps:   3%|‚ñè     | 419/15000 [03:14<43:28,  5.59it/s, lr=1e-5, step_loss=0.226]07/20/2023 12:31:46 - INFO - __main__ - train loss is 3.4150926573202014\n",
      "Steps:   3%|‚ñè     | 420/15000 [03:14<43:26,  5.59it/s, lr=1e-5, step_loss=0.249]07/20/2023 12:31:46 - INFO - __main__ - train loss is 3.4937621084973216\n",
      "Steps:   3%|‚ñè    | 421/15000 [03:14<43:26,  5.59it/s, lr=1e-5, step_loss=0.0787]07/20/2023 12:31:46 - INFO - __main__ - train loss is 3.9606476156041026\n",
      "Steps:   3%|‚ñè     | 422/15000 [03:15<43:26,  5.59it/s, lr=1e-5, step_loss=0.467]07/20/2023 12:31:47 - INFO - __main__ - train loss is 3.9795166393741965\n",
      "Steps:   3%|‚ñè    | 423/15000 [03:15<43:24,  5.60it/s, lr=1e-5, step_loss=0.0189]07/20/2023 12:31:47 - INFO - __main__ - train loss is 4.032039522193372\n",
      "Steps:   3%|‚ñè    | 424/15000 [03:15<43:21,  5.60it/s, lr=1e-5, step_loss=0.0525]07/20/2023 12:31:47 - INFO - __main__ - train loss is 4.458295642398298\n",
      "Steps:   3%|‚ñè     | 425/15000 [03:15<43:19,  5.61it/s, lr=1e-5, step_loss=0.426]07/20/2023 12:31:47 - INFO - __main__ - train loss is 4.4828158831223845\n",
      "Steps:   3%|‚ñè    | 426/15000 [03:15<43:17,  5.61it/s, lr=1e-5, step_loss=0.0245]07/20/2023 12:31:47 - INFO - __main__ - train loss is 4.545231907628477\n",
      "Steps:   3%|‚ñè    | 427/15000 [03:15<43:15,  5.61it/s, lr=1e-5, step_loss=0.0624]07/20/2023 12:31:47 - INFO - __main__ - train loss is 4.555300046689808\n",
      "Steps:   3%|‚ñè    | 428/15000 [03:16<43:25,  5.59it/s, lr=1e-5, step_loss=0.0101]07/20/2023 12:31:48 - INFO - __main__ - train loss is 4.557916766963899\n",
      "Steps:   3%|    | 429/15000 [03:16<43:21,  5.60it/s, lr=1e-5, step_loss=0.00262]07/20/2023 12:31:48 - INFO - __main__ - train loss is 4.645682274363935\n",
      "Steps:   3%|‚ñè    | 430/15000 [03:16<43:20,  5.60it/s, lr=1e-5, step_loss=0.0878]07/20/2023 12:31:48 - INFO - __main__ - train loss is 4.6653820322826505\n",
      "Steps:   3%|‚ñè    | 431/15000 [03:16<43:19,  5.60it/s, lr=1e-5, step_loss=0.0197]07/20/2023 12:31:48 - INFO - __main__ - train loss is 4.733795237727463\n",
      "Steps:   3%|‚ñè    | 432/15000 [03:16<43:42,  5.56it/s, lr=1e-5, step_loss=0.0684]07/20/2023 12:31:48 - INFO - __main__ - train loss is 4.961102184839547\n",
      "Steps:   3%|‚ñè     | 433/15000 [03:17<43:35,  5.57it/s, lr=1e-5, step_loss=0.227]07/20/2023 12:31:49 - INFO - __main__ - train loss is 4.967716049402952\n",
      "Steps:   3%|    | 434/15000 [03:17<43:28,  5.58it/s, lr=1e-5, step_loss=0.00661]07/20/2023 12:31:49 - INFO - __main__ - train loss is 4.988947194069624\n",
      "Steps:   3%|‚ñè    | 435/15000 [03:17<43:24,  5.59it/s, lr=1e-5, step_loss=0.0212]07/20/2023 12:31:49 - INFO - __main__ - train loss is 5.287867706269026\n",
      "Steps:   3%|‚ñè     | 436/15000 [03:17<43:23,  5.59it/s, lr=1e-5, step_loss=0.299]07/20/2023 12:31:49 - INFO - __main__ - train loss is 5.2944672727026045\n",
      "Steps:   3%|‚ñè    | 437/15000 [03:17<43:20,  5.60it/s, lr=1e-5, step_loss=0.0066]07/20/2023 12:31:49 - INFO - __main__ - train loss is 5.431492524687201\n",
      "Steps:   3%|‚ñè     | 438/15000 [03:17<43:20,  5.60it/s, lr=1e-5, step_loss=0.137]07/20/2023 12:31:49 - INFO - __main__ - train loss is 5.573853152338415\n",
      "Steps:   3%|‚ñè     | 439/15000 [03:18<43:17,  5.61it/s, lr=1e-5, step_loss=0.142]07/20/2023 12:31:50 - INFO - __main__ - train loss is 5.679812523070723\n",
      "Steps:   3%|‚ñè     | 440/15000 [03:18<43:19,  5.60it/s, lr=1e-5, step_loss=0.106]07/20/2023 12:31:50 - INFO - __main__ - train loss is 6.047990831080824\n",
      "Steps:   3%|‚ñè     | 441/15000 [03:18<43:18,  5.60it/s, lr=1e-5, step_loss=0.368]07/20/2023 12:31:50 - INFO - __main__ - train loss is 6.051100783981383\n",
      "Steps:   3%|    | 442/15000 [03:18<43:41,  5.55it/s, lr=1e-5, step_loss=0.00311]07/20/2023 12:31:50 - INFO - __main__ - train loss is 6.054485491244122\n",
      "Steps:   3%|    | 443/15000 [03:18<43:41,  5.55it/s, lr=1e-5, step_loss=0.00338]07/20/2023 12:31:50 - INFO - __main__ - train loss is 6.06770262750797\n",
      "Steps:   3%|‚ñè    | 444/15000 [03:18<43:32,  5.57it/s, lr=1e-5, step_loss=0.0132]07/20/2023 12:31:50 - INFO - __main__ - train loss is 6.312852359144017\n",
      "Steps:   3%|‚ñè     | 445/15000 [03:19<43:37,  5.56it/s, lr=1e-5, step_loss=0.245]07/20/2023 12:31:51 - INFO - __main__ - train loss is 6.4530007902067155\n",
      "Steps:   3%|‚ñè      | 446/15000 [03:19<43:30,  5.57it/s, lr=1e-5, step_loss=0.14]07/20/2023 12:31:51 - INFO - __main__ - train loss is 6.457597934408113\n",
      "Steps:   3%|‚ñè    | 447/15000 [03:19<43:23,  5.59it/s, lr=1e-5, step_loss=0.0046]07/20/2023 12:31:51 - INFO - __main__ - train loss is 6.468663441715762\n",
      "Steps:   3%|‚ñè    | 448/15000 [03:19<43:18,  5.60it/s, lr=1e-5, step_loss=0.0111]07/20/2023 12:31:51 - INFO - __main__ - train loss is 6.536490875063464\n",
      "Steps:   3%|‚ñè    | 449/15000 [03:19<43:16,  5.60it/s, lr=1e-5, step_loss=0.0678]07/20/2023 12:31:51 - INFO - __main__ - train loss is 6.538930125301704\n",
      "Steps:   3%|    | 450/15000 [03:20<43:13,  5.61it/s, lr=1e-5, step_loss=0.00244]07/20/2023 12:31:52 - INFO - __main__ - train loss is 6.543574905721471\n",
      "Steps:   3%|    | 451/15000 [03:20<43:11,  5.61it/s, lr=1e-5, step_loss=0.00464]07/20/2023 12:31:52 - INFO - __main__ - train loss is 6.716369098750874\n",
      "Steps:   3%|‚ñè     | 452/15000 [03:20<43:12,  5.61it/s, lr=1e-5, step_loss=0.173]07/20/2023 12:31:52 - INFO - __main__ - train loss is 6.980936682550237\n",
      "Steps:   3%|‚ñè     | 453/15000 [03:20<43:17,  5.60it/s, lr=1e-5, step_loss=0.265]07/20/2023 12:31:52 - INFO - __main__ - train loss is 7.387982940999791\n",
      "Steps:   3%|‚ñè     | 454/15000 [03:20<43:30,  5.57it/s, lr=1e-5, step_loss=0.407]07/20/2023 12:31:52 - INFO - __main__ - train loss is 7.5647637012880296\n",
      "Steps:   3%|‚ñè     | 455/15000 [03:20<43:58,  5.51it/s, lr=1e-5, step_loss=0.177]07/20/2023 12:31:52 - INFO - __main__ - train loss is 7.611982336966321\n",
      "Steps:   3%|‚ñè    | 456/15000 [03:21<43:47,  5.54it/s, lr=1e-5, step_loss=0.0472]07/20/2023 12:31:53 - INFO - __main__ - train loss is 7.617130217840895\n",
      "Steps:   3%|    | 457/15000 [03:21<43:41,  5.55it/s, lr=1e-5, step_loss=0.00515]07/20/2023 12:31:53 - INFO - __main__ - train loss is 7.620416250778362\n",
      "Steps:   3%|    | 458/15000 [03:21<43:32,  5.57it/s, lr=1e-5, step_loss=0.00329]07/20/2023 12:31:53 - INFO - __main__ - train loss is 7.932148066116497\n",
      "Steps:   3%|‚ñè     | 459/15000 [03:21<43:26,  5.58it/s, lr=1e-5, step_loss=0.312]07/20/2023 12:31:53 - INFO - __main__ - train loss is 8.074537303997204\n",
      "Steps:   3%|‚ñè     | 460/15000 [03:21<43:24,  5.58it/s, lr=1e-5, step_loss=0.142]07/20/2023 12:31:53 - INFO - __main__ - train loss is 8.185051907552406\n",
      "Steps:   3%|‚ñè     | 461/15000 [03:22<43:22,  5.59it/s, lr=1e-5, step_loss=0.111]07/20/2023 12:31:54 - INFO - __main__ - train loss is 8.429906611097977\n",
      "Steps:   3%|‚ñè     | 462/15000 [03:22<43:21,  5.59it/s, lr=1e-5, step_loss=0.245]07/20/2023 12:31:54 - INFO - __main__ - train loss is 8.441902614897117\n",
      "Steps:   3%|‚ñè     | 463/15000 [03:22<43:18,  5.60it/s, lr=1e-5, step_loss=0.012]07/20/2023 12:31:54 - INFO - __main__ - train loss is 8.540897942846641\n",
      "Steps:   3%|‚ñè     | 464/15000 [03:22<43:15,  5.60it/s, lr=1e-5, step_loss=0.099]07/20/2023 12:31:54 - INFO - __main__ - train loss is 8.929640926187858\n",
      "Steps:   3%|‚ñè     | 465/15000 [03:22<43:12,  5.61it/s, lr=1e-5, step_loss=0.389]07/20/2023 12:31:54 - INFO - __main__ - train loss is 8.94325372367166\n",
      "Steps:   3%|‚ñè    | 466/15000 [03:22<43:11,  5.61it/s, lr=1e-5, step_loss=0.0136]07/20/2023 12:31:54 - INFO - __main__ - train loss is 8.952303040539846\n",
      "Steps:   3%|    | 467/15000 [03:23<43:12,  5.61it/s, lr=1e-5, step_loss=0.00905]07/20/2023 12:31:55 - INFO - __main__ - train loss is 8.957838631002232\n",
      "Steps:   3%|    | 468/15000 [03:23<43:11,  5.61it/s, lr=1e-5, step_loss=0.00554]07/20/2023 12:31:55 - INFO - __main__ - train loss is 8.998669410822913\n",
      "Steps:   3%|‚ñè    | 469/15000 [03:23<43:08,  5.61it/s, lr=1e-5, step_loss=0.0408]07/20/2023 12:31:55 - INFO - __main__ - train loss is 9.003372562350705\n",
      "Steps:   3%|‚ñè    | 470/15000 [03:23<43:06,  5.62it/s, lr=1e-5, step_loss=0.0047]07/20/2023 12:31:55 - INFO - __main__ - train loss is 9.061687727691606\n",
      "Steps:   3%|‚ñè    | 471/15000 [03:23<43:10,  5.61it/s, lr=1e-5, step_loss=0.0583]07/20/2023 12:31:55 - INFO - __main__ - train loss is 9.096448050113395\n",
      "Steps:   3%|‚ñè    | 472/15000 [03:23<43:09,  5.61it/s, lr=1e-5, step_loss=0.0348]07/20/2023 12:31:55 - INFO - __main__ - train loss is 9.136558518977836\n",
      "Steps:   3%|‚ñè    | 473/15000 [03:24<43:33,  5.56it/s, lr=1e-5, step_loss=0.0401]07/20/2023 12:31:56 - INFO - __main__ - train loss is 9.736084149451926\n",
      "Steps:   3%|‚ñé       | 474/15000 [03:24<43:47,  5.53it/s, lr=1e-5, step_loss=0.6]07/20/2023 12:31:56 - INFO - __main__ - train loss is 10.527370617957786\n",
      "Steps:   3%|‚ñè     | 475/15000 [03:24<43:36,  5.55it/s, lr=1e-5, step_loss=0.791]07/20/2023 12:31:56 - INFO - __main__ - train loss is 10.530240307562053\n",
      "Steps:   3%|‚ñè   | 476/15000 [03:24<43:27,  5.57it/s, lr=1e-5, step_loss=0.00287]07/20/2023 12:31:56 - INFO - __main__ - train loss is 11.43382395338267\n",
      "Steps:   3%|‚ñè     | 477/15000 [03:24<43:20,  5.59it/s, lr=1e-5, step_loss=0.904]07/20/2023 12:31:56 - INFO - __main__ - train loss is 11.438748557120562\n",
      "Steps:   3%|‚ñè   | 478/15000 [03:25<43:16,  5.59it/s, lr=1e-5, step_loss=0.00492]07/20/2023 12:31:57 - INFO - __main__ - train loss is 11.460717160254717\n",
      "Steps:   3%|‚ñè     | 479/15000 [03:25<43:29,  5.56it/s, lr=1e-5, step_loss=0.022]07/20/2023 12:31:57 - INFO - __main__ - train loss is 11.745340336114168\n",
      "Steps:   3%|‚ñè     | 480/15000 [03:25<43:19,  5.59it/s, lr=1e-5, step_loss=0.285]07/20/2023 12:31:57 - INFO - __main__ - train loss is 11.74769158870913\n",
      "Steps:   3%|‚ñè   | 481/15000 [03:25<43:12,  5.60it/s, lr=1e-5, step_loss=0.00235]07/20/2023 12:31:57 - INFO - __main__ - train loss is 11.884853320429102\n",
      "Steps:   3%|‚ñè     | 482/15000 [03:25<43:07,  5.61it/s, lr=1e-5, step_loss=0.137]07/20/2023 12:31:57 - INFO - __main__ - train loss is 11.997379767009988\n",
      "Steps:   3%|‚ñè     | 483/15000 [03:25<43:00,  5.62it/s, lr=1e-5, step_loss=0.113]07/20/2023 12:31:57 - INFO - __main__ - train loss is 11.99984800745733\n",
      "Steps:   3%|‚ñè   | 484/15000 [03:26<43:05,  5.62it/s, lr=1e-5, step_loss=0.00247]07/20/2023 12:31:58 - INFO - __main__ - train loss is 12.045749704586342\n",
      "Steps:   3%|   | 485/15000 [03:26<1:00:08,  4.02it/s, lr=1e-5, step_loss=0.0459]07/20/2023 12:31:58 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:58 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:58 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Per validation step average loss is 0.25758635997772217\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Cumulative validation average loss is 0.25758635997772217\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Per validation step average loss is 0.018211670219898224\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Cumulative validation average loss is 0.2757980301976204\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441043])\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Post-squeeze shape torch.Size([441043])\n",
      "07/20/2023 12:31:59 - INFO - __main__ - Post-avg shape torch.Size([441043])\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Per validation step average loss is 0.01942206732928753\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Cumulative validation average loss is 0.2952200975269079\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Per validation step average loss is 0.3882914185523987\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Cumulative validation average loss is 0.6835115160793066\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:32:00 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Per validation step average loss is 0.040867943316698074\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Cumulative validation average loss is 0.7243794593960047\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Per validation step average loss is 0.11048945039510727\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Cumulative validation average loss is 0.834868909791112\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:32:01 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Per validation step average loss is 0.06115175783634186\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Cumulative validation average loss is 0.8960206676274538\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Per validation step average loss is 0.3731656074523926\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Cumulative validation average loss is 1.2691862750798464\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:32:02 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Per validation step average loss is 0.2192688286304474\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Cumulative validation average loss is 1.4884551037102938\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Per validation step average loss is 0.03850384056568146\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Cumulative validation average loss is 1.5269589442759752\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 1, 441000])\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Post-squeeze shape torch.Size([441000])\n",
      "07/20/2023 12:32:03 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Per validation step average loss is 0.12867826223373413\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Cumulative validation average loss is 1.6556372065097094\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Pre-squeeze shape torch.Size([1, 2, 441000])\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Post-squeeze shape torch.Size([2, 441000])\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Post-avg shape torch.Size([441000])\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Per validation step average loss is 0.36694538593292236\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Cumulative validation average loss is 2.0225825924426317\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Average validation loss for Epoch 4 is 0.16854854937021932\n",
      "07/20/2023 12:32:04 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of bird song.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --validation_epochs=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/19-07\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/13-07/2\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
