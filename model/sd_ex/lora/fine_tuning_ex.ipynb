{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19 12:32:19,537] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87822ed83f464169b722ef8107b923f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5782384a014eb4ad9eea06c1f6c6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789d2d98f3864f90810f1005daca42dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40a78d6f8664576bf83ab1c93d9cc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbeec814ab1473a928b797f8b14154c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-f96ff42a1aa9403f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/Bird vocalization-bird call-bird song/train\" , split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=501x512>,\n",
       " 'prompt': 'a spectrogram of bird song',\n",
       " 'audiofile': './data/Bird vocalization-bird call-bird song/train/-aC8TJIZrtE.wav'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-25 19:13:41,183] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-25 19:13:43,985] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-25 19:13:47,520] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-25 19:13:47,520] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-25 19:13:47,520] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/25/2023 19:13:47 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'clip_sample_range', 'prediction_type', 'sample_max_value', 'dynamic_thresholding_ratio', 'variance_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'class_embeddings_concat', 'projection_class_embeddings_input_dim', 'time_embedding_dim', 'mid_block_type', 'conv_out_kernel', 'dual_cross_attention', 'class_embed_type', 'mid_block_only_cross_attention', 'cross_attention_norm', 'resnet_time_scale_shift', 'resnet_out_scale_factor', 'time_cond_proj_dim', 'encoder_hid_dim', 'num_class_embeds', 'addition_embed_type', 'resnet_skip_time_act', 'encoder_hid_dim_type', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'time_embedding_type', 'use_linear_projection', 'conv_in_kernel', 'only_cross_attention', 'timestep_post_act', 'upcast_attention'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|███████████████| 607/607 [00:00<00:00, 402139.08it/s]\n",
      "Resolving data files: 100%|███████████████| 159/159 [00:00<00:00, 692517.48it/s]\n",
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-6db3f63079a2e832/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n",
      "Downloading data files: 100%|█████████████| 304/304 [00:00<00:00, 141031.79it/s]\n",
      "Downloading data files: 100%|█████████████| 303/303 [00:00<00:00, 154758.17it/s]\n",
      "Extracting data files: 100%|████████████████| 303/303 [00:00<00:00, 1487.36it/s]\n",
      "Downloading data files: 100%|███████████████| 80/80 [00:00<00:00, 152797.96it/s]\n",
      "Downloading data files: 100%|███████████████| 79/79 [00:00<00:00, 149324.03it/s]\n",
      "Extracting data files: 100%|██████████████████| 79/79 [00:00<00:00, 1486.97it/s]\n",
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-6db3f63079a2e832/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 356.58it/s]\n",
      "07/25/2023 19:13:59 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (1).\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.202056407928467 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-25 19:14:03,946] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/25/2023 19:14:03 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/25/2023 19:14:03 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-25 19:14:03,980] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-25 19:14:03,981] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-25 19:14:03,981] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-25 19:14:03,986] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-25 19:14:03,986] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-25 19:14:03,987] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-25 19:14:03,987] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-25 19:14:03,987] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-25 19:14:03,987] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-25 19:14:03,987] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07627058029174805 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-25 19:14:04,180] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-25 19:14:04,181] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-25 19:14:04,181] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 5.83 GB, percent = 37.5%\n",
      "[2023-07-25 19:14:04,285] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-25 19:14:04,286] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-25 19:14:04,286] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 5.84 GB, percent = 37.6%\n",
      "[2023-07-25 19:14:04,286] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-25 19:14:04,379] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-25 19:14:04,380] [INFO] [utils.py:786:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB \n",
      "[2023-07-25 19:14:04,380] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 5.84 GB, percent = 37.6%\n",
      "[2023-07-25 19:14:04,389] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-25 19:14:04,389] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-25 19:14:04,389] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-25 19:14:04,389] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
      "[2023-07-25 19:14:04,389] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-25 19:14:04,389] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-25 19:14:04,389] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-25 19:14:04,389] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-25 19:14:04,389] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f03209a8340>\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-25 19:14:04,390] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-25 19:14:04,391] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-25 19:14:04,391] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-25 19:14:04,391] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-25 19:14:04,391] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002009868621826172 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230725_191405-15wqn7qp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mradiant-wood-139\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/15wqn7qp\u001b[0m\n",
      "07/25/2023 19:14:10 - INFO - __main__ - ***** Running training *****\n",
      "07/25/2023 19:14:10 - INFO - __main__ -   Num examples = 303\n",
      "07/25/2023 19:14:10 - INFO - __main__ -   Num Epochs = 198\n",
      "07/25/2023 19:14:10 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/25/2023 19:14:10 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/25/2023 19:14:10 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/25/2023 19:14:10 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]07/25/2023 19:14:10 - INFO - __main__ - Starting epoch 0\n",
      "07/25/2023 19:14:13 - INFO - __main__ - train loss is 0.3472520709037781\n",
      "[2023-07-25 19:14:13,398] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|        | 1/15000 [00:02<11:24:50,  2.74s/it, lr=0, step_loss=0.347]07/25/2023 19:14:13 - INFO - __main__ - train loss is 0.4616546779870987\n",
      "[2023-07-25 19:14:13,894] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|         | 2/15000 [00:03<5:55:01,  1.42s/it, lr=0, step_loss=0.114]07/25/2023 19:14:14 - INFO - __main__ - train loss is 0.8806708604097366\n",
      "[2023-07-25 19:14:14,387] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|         | 3/15000 [00:03<4:09:10,  1.00it/s, lr=0, step_loss=0.419]07/25/2023 19:14:14 - INFO - __main__ - train loss is 0.9342177212238312\n",
      "[2023-07-25 19:14:14,878] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|        | 4/15000 [00:04<3:19:14,  1.25it/s, lr=0, step_loss=0.0535]07/25/2023 19:14:15 - INFO - __main__ - train loss is 1.0796399414539337\n",
      "[2023-07-25 19:14:15,368] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   0%|         | 5/15000 [00:04<2:51:29,  1.46it/s, lr=0, step_loss=0.145]07/25/2023 19:14:15 - INFO - __main__ - train loss is 1.2196008265018463\n",
      "[2023-07-25 19:14:15,863] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   0%|          | 6/15000 [00:05<2:35:12,  1.61it/s, lr=0, step_loss=0.14]07/25/2023 19:14:16 - INFO - __main__ - train loss is 1.4102746546268463\n",
      "[2023-07-25 19:14:16,354] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   0%|         | 7/15000 [00:05<2:24:34,  1.73it/s, lr=0, step_loss=0.191]07/25/2023 19:14:16 - INFO - __main__ - train loss is 1.647646278142929\n",
      "[2023-07-25 19:14:16,847] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   0%|         | 8/15000 [00:06<2:17:46,  1.81it/s, lr=0, step_loss=0.237]07/25/2023 19:14:17 - INFO - __main__ - train loss is 1.65213006362319\n",
      "Steps:   0%|  | 9/15000 [00:06<2:13:52,  1.87it/s, lr=2.5e-9, step_loss=0.00448]07/25/2023 19:14:17 - INFO - __main__ - train loss is 1.809285294264555\n",
      "[2023-07-25 19:14:17,838] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   0%|   | 10/15000 [00:07<2:10:19,  1.92it/s, lr=2.5e-9, step_loss=0.157]07/25/2023 19:14:18 - INFO - __main__ - train loss is 1.8304364755749702\n",
      "Steps:   0%|    | 11/15000 [00:07<2:07:54,  1.95it/s, lr=5e-9, step_loss=0.0212]07/25/2023 19:14:18 - INFO - __main__ - train loss is 1.9377861693501472\n",
      "Steps:   0%|   | 12/15000 [00:08<2:06:59,  1.97it/s, lr=7.5e-9, step_loss=0.107]07/25/2023 19:14:19 - INFO - __main__ - train loss is 1.9413428192492574\n",
      "Steps:   0%|   | 13/15000 [00:08<2:06:30,  1.97it/s, lr=1e-8, step_loss=0.00356]07/25/2023 19:14:19 - INFO - __main__ - train loss is 2.021493945037946\n",
      "Steps:   0%| | 14/15000 [00:09<2:05:43,  1.99it/s, lr=1.25e-8, step_loss=0.0802]07/25/2023 19:14:20 - INFO - __main__ - train loss is 2.0858366971369833\n",
      "Steps:   0%|  | 15/15000 [00:09<2:05:30,  1.99it/s, lr=1.5e-8, step_loss=0.0643]07/25/2023 19:14:20 - INFO - __main__ - train loss is 2.1337663342710584\n",
      "Steps:   0%| | 16/15000 [00:10<2:05:13,  1.99it/s, lr=1.75e-8, step_loss=0.0479]07/25/2023 19:14:21 - INFO - __main__ - train loss is 2.3831959476228803\n",
      "Steps:   0%|     | 17/15000 [00:10<2:04:47,  2.00it/s, lr=2e-8, step_loss=0.249]07/25/2023 19:14:21 - INFO - __main__ - train loss is 2.7848898281808943\n",
      "Steps:   0%|  | 18/15000 [00:11<2:04:34,  2.00it/s, lr=2.25e-8, step_loss=0.402]07/25/2023 19:14:22 - INFO - __main__ - train loss is 2.8266179969068617\n",
      "Steps:   0%|  | 19/15000 [00:11<2:03:59,  2.01it/s, lr=2.5e-8, step_loss=0.0417]07/25/2023 19:14:22 - INFO - __main__ - train loss is 2.867561969673261\n",
      "Steps:   0%| | 20/15000 [00:12<2:03:43,  2.02it/s, lr=2.75e-8, step_loss=0.0409]07/25/2023 19:14:23 - INFO - __main__ - train loss is 2.8789335421752185\n",
      "Steps:   0%|    | 21/15000 [00:12<2:03:56,  2.01it/s, lr=3e-8, step_loss=0.0114]07/25/2023 19:14:23 - INFO - __main__ - train loss is 2.900449639884755\n",
      "Steps:   0%| | 22/15000 [00:13<2:03:52,  2.02it/s, lr=3.25e-8, step_loss=0.0215]07/25/2023 19:14:24 - INFO - __main__ - train loss is 2.932458123890683\n",
      "Steps:   0%|   | 23/15000 [00:13<2:03:52,  2.02it/s, lr=3.5e-8, step_loss=0.032]07/25/2023 19:14:24 - INFO - __main__ - train loss is 3.1193646553438157\n",
      "Steps:   0%|  | 24/15000 [00:14<2:05:13,  1.99it/s, lr=3.75e-8, step_loss=0.187]07/25/2023 19:14:25 - INFO - __main__ - train loss is 3.147110677091405\n",
      "Steps:   0%|    | 25/15000 [00:14<2:05:11,  1.99it/s, lr=4e-8, step_loss=0.0277]07/25/2023 19:14:25 - INFO - __main__ - train loss is 3.187275632051751\n",
      "Steps:   0%| | 26/15000 [00:15<2:04:56,  2.00it/s, lr=4.25e-8, step_loss=0.0402]07/25/2023 19:14:26 - INFO - __main__ - train loss is 3.289387783734128\n",
      "Steps:   0%|   | 27/15000 [00:15<2:06:18,  1.98it/s, lr=4.5e-8, step_loss=0.102]07/25/2023 19:14:26 - INFO - __main__ - train loss is 3.356596416560933\n",
      "Steps:   0%| | 28/15000 [00:16<2:05:41,  1.99it/s, lr=4.75e-8, step_loss=0.0672]07/25/2023 19:14:27 - INFO - __main__ - train loss is 3.3601135830394924\n",
      "Steps:   0%|   | 29/15000 [00:16<2:03:37,  2.02it/s, lr=5e-8, step_loss=0.00352]07/25/2023 19:14:27 - INFO - __main__ - train loss is 3.373280461411923\n",
      "Steps:   0%| | 30/15000 [00:17<2:03:59,  2.01it/s, lr=5.25e-8, step_loss=0.0132]07/25/2023 19:14:28 - INFO - __main__ - train loss is 3.4449023413471878\n",
      "Steps:   0%|  | 31/15000 [00:17<2:03:55,  2.01it/s, lr=5.5e-8, step_loss=0.0716]07/25/2023 19:14:28 - INFO - __main__ - train loss is 3.450832632370293\n",
      "Steps:   0%| | 32/15000 [00:18<2:03:50,  2.01it/s, lr=5.75e-8, step_loss=0.0059307/25/2023 19:14:29 - INFO - __main__ - train loss is 3.4534763265401125\n",
      "Steps:   0%|   | 33/15000 [00:18<2:03:42,  2.02it/s, lr=6e-8, step_loss=0.00264]07/25/2023 19:14:29 - INFO - __main__ - train loss is 3.461034497246146\n",
      "Steps:   0%| | 34/15000 [00:19<2:03:24,  2.02it/s, lr=6.25e-8, step_loss=0.0075607/25/2023 19:14:30 - INFO - __main__ - train loss is 3.578804051503539\n",
      "Steps:   0%|   | 35/15000 [00:19<2:03:47,  2.01it/s, lr=6.5e-8, step_loss=0.118]07/25/2023 19:14:30 - INFO - __main__ - train loss is 4.020955627784133\n",
      "Steps:   0%|  | 36/15000 [00:20<2:04:53,  2.00it/s, lr=6.75e-8, step_loss=0.442]07/25/2023 19:14:31 - INFO - __main__ - train loss is 4.321807568892837\n",
      "Steps:   0%|     | 37/15000 [00:20<2:04:14,  2.01it/s, lr=7e-8, step_loss=0.301]07/25/2023 19:14:31 - INFO - __main__ - train loss is 4.3369308561086655\n",
      "Steps:   0%| | 38/15000 [00:21<2:04:02,  2.01it/s, lr=7.25e-8, step_loss=0.0151]07/25/2023 19:14:32 - INFO - __main__ - train loss is 4.5653384029865265\n",
      "Steps:   0%|   | 39/15000 [00:21<2:04:17,  2.01it/s, lr=7.5e-8, step_loss=0.228]07/25/2023 19:14:32 - INFO - __main__ - train loss is 4.769585624337196\n",
      "Steps:   0%|  | 40/15000 [00:22<2:04:17,  2.01it/s, lr=7.75e-8, step_loss=0.204]07/25/2023 19:14:33 - INFO - __main__ - train loss is 4.9495526403188705\n",
      "[2023-07-25 19:14:33,271] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   0%|   | 41/15000 [00:22<2:03:46,  2.01it/s, lr=7.75e-8, step_loss=0.18]07/25/2023 19:14:33 - INFO - __main__ - train loss is 4.953013127902523\n",
      "Steps:   0%|   | 42/15000 [00:23<2:04:10,  2.01it/s, lr=8e-8, step_loss=0.00346]07/25/2023 19:14:34 - INFO - __main__ - train loss is 4.983390281209722\n",
      "Steps:   0%| | 43/15000 [00:23<2:03:58,  2.01it/s, lr=8.25e-8, step_loss=0.0304]07/25/2023 19:14:34 - INFO - __main__ - train loss is 5.060751656303182\n",
      "Steps:   0%|  | 44/15000 [00:24<2:03:57,  2.01it/s, lr=8.5e-8, step_loss=0.0774]07/25/2023 19:14:35 - INFO - __main__ - train loss is 5.067048338474706\n",
      "Steps:   0%| | 45/15000 [00:24<2:03:52,  2.01it/s, lr=8.75e-8, step_loss=0.0063]07/25/2023 19:14:35 - INFO - __main__ - train loss is 5.221034643473104\n",
      "Steps:   0%|     | 46/15000 [00:25<2:03:58,  2.01it/s, lr=9e-8, step_loss=0.154]07/25/2023 19:14:36 - INFO - __main__ - train loss is 5.325908449711278\n",
      "Steps:   0%|  | 47/15000 [00:25<2:04:03,  2.01it/s, lr=9.25e-8, step_loss=0.105]07/25/2023 19:14:36 - INFO - __main__ - train loss is 5.465806273045018\n",
      "Steps:   0%|    | 48/15000 [00:26<2:05:24,  1.99it/s, lr=9.5e-8, step_loss=0.14]07/25/2023 19:14:37 - INFO - __main__ - train loss is 5.572141778888181\n",
      "Steps:   0%|  | 49/15000 [00:26<2:05:52,  1.98it/s, lr=9.75e-8, step_loss=0.106]07/25/2023 19:14:37 - INFO - __main__ - train loss is 5.731348988832906\n",
      "Steps:   0%|     | 50/15000 [00:27<2:05:21,  1.99it/s, lr=1e-7, step_loss=0.159]07/25/2023 19:14:38 - INFO - __main__ - train loss is 6.115742502035573\n",
      "Steps:   0%|  | 51/15000 [00:27<2:05:33,  1.98it/s, lr=1.03e-7, step_loss=0.384]07/25/2023 19:14:38 - INFO - __main__ - train loss is 6.126088598975912\n",
      "Steps:   0%| | 52/15000 [00:28<2:05:07,  1.99it/s, lr=1.05e-7, step_loss=0.0103]07/25/2023 19:14:39 - INFO - __main__ - train loss is 6.413025716552511\n",
      "Steps:   0%|  | 53/15000 [00:28<2:04:57,  1.99it/s, lr=1.08e-7, step_loss=0.287]07/25/2023 19:14:39 - INFO - __main__ - train loss is 6.41663296869956\n",
      "Steps:   0%| | 54/15000 [00:29<2:04:31,  2.00it/s, lr=1.1e-7, step_loss=0.00361]07/25/2023 19:14:40 - INFO - __main__ - train loss is 6.421531056752428\n",
      "Steps:   0%| | 55/15000 [00:29<2:04:33,  2.00it/s, lr=1.13e-7, step_loss=0.0049]07/25/2023 19:14:40 - INFO - __main__ - train loss is 6.926742290845141\n",
      "Steps:   0%|  | 56/15000 [00:30<2:04:09,  2.01it/s, lr=1.15e-7, step_loss=0.505]07/25/2023 19:14:41 - INFO - __main__ - train loss is 6.985881289234385\n",
      "Steps:   0%| | 57/15000 [00:30<2:03:41,  2.01it/s, lr=1.18e-7, step_loss=0.0591]07/25/2023 19:14:41 - INFO - __main__ - train loss is 7.061062073102221\n",
      "Steps:   0%|  | 58/15000 [00:31<2:03:42,  2.01it/s, lr=1.2e-7, step_loss=0.0752]07/25/2023 19:14:42 - INFO - __main__ - train loss is 7.773823534836993\n",
      "Steps:   0%|  | 59/15000 [00:31<2:04:41,  2.00it/s, lr=1.23e-7, step_loss=0.713]07/25/2023 19:14:42 - INFO - __main__ - train loss is 7.777299267239869\n",
      "Steps:   0%| | 60/15000 [00:32<2:04:10,  2.01it/s, lr=1.25e-7, step_loss=0.0034807/25/2023 19:14:43 - INFO - __main__ - train loss is 8.068135154433548\n",
      "Steps:   0%|  | 61/15000 [00:32<2:04:02,  2.01it/s, lr=1.27e-7, step_loss=0.291]07/25/2023 19:14:43 - INFO - __main__ - train loss is 8.082011389546096\n",
      "Steps:   0%|  | 62/15000 [00:33<2:04:04,  2.01it/s, lr=1.3e-7, step_loss=0.0139]07/25/2023 19:14:44 - INFO - __main__ - train loss is 8.386428612284362\n",
      "Steps:   0%|  | 63/15000 [00:33<2:04:16,  2.00it/s, lr=1.33e-7, step_loss=0.304]07/25/2023 19:14:44 - INFO - __main__ - train loss is 9.007678049616516\n",
      "Steps:   0%|  | 64/15000 [00:34<2:04:20,  2.00it/s, lr=1.35e-7, step_loss=0.621]07/25/2023 19:14:45 - INFO - __main__ - train loss is 9.015508844517171\n",
      "Steps:   0%| | 65/15000 [00:34<2:04:11,  2.00it/s, lr=1.38e-7, step_loss=0.0078307/25/2023 19:14:45 - INFO - __main__ - train loss is 9.74647159781307\n",
      "Steps:   0%|   | 66/15000 [00:35<2:04:15,  2.00it/s, lr=1.4e-7, step_loss=0.731]07/25/2023 19:14:46 - INFO - __main__ - train loss is 9.7570366198197\n",
      "Steps:   0%| | 67/15000 [00:35<2:04:42,  2.00it/s, lr=1.43e-7, step_loss=0.0106]07/25/2023 19:14:46 - INFO - __main__ - train loss is 9.782909109257162\n",
      "Steps:   0%| | 68/15000 [00:36<2:04:35,  2.00it/s, lr=1.45e-7, step_loss=0.0259]07/25/2023 19:14:47 - INFO - __main__ - train loss is 9.795419960282743\n",
      "Steps:   0%| | 69/15000 [00:36<2:04:51,  1.99it/s, lr=1.48e-7, step_loss=0.0125]07/25/2023 19:14:47 - INFO - __main__ - train loss is 10.092391519807279\n",
      "Steps:   0%|   | 70/15000 [00:37<2:04:34,  2.00it/s, lr=1.5e-7, step_loss=0.297]07/25/2023 19:14:48 - INFO - __main__ - train loss is 10.41614010836929\n",
      "Steps:   0%|  | 71/15000 [00:37<2:04:52,  1.99it/s, lr=1.53e-7, step_loss=0.324]07/25/2023 19:14:48 - INFO - __main__ - train loss is 10.424866913817823\n",
      "Steps:   0%| | 72/15000 [00:38<2:04:57,  1.99it/s, lr=1.55e-7, step_loss=0.0087307/25/2023 19:14:49 - INFO - __main__ - train loss is 10.433176886290312\n",
      "Steps:   0%| | 73/15000 [00:38<2:04:48,  1.99it/s, lr=1.58e-7, step_loss=0.0083107/25/2023 19:14:49 - INFO - __main__ - train loss is 10.438679730519652\n",
      "Steps:   0%|  | 74/15000 [00:39<2:04:45,  1.99it/s, lr=1.6e-7, step_loss=0.0055]07/25/2023 19:14:50 - INFO - __main__ - train loss is 10.478497324511409\n",
      "Steps:   0%| | 75/15000 [00:39<2:04:41,  1.99it/s, lr=1.63e-7, step_loss=0.0398]07/25/2023 19:14:50 - INFO - __main__ - train loss is 10.484946819022298\n",
      "Steps:   1%| | 76/15000 [00:40<2:04:29,  2.00it/s, lr=1.65e-7, step_loss=0.0064507/25/2023 19:14:51 - INFO - __main__ - train loss is 10.700766222551465\n",
      "Steps:   1%|  | 77/15000 [00:40<2:05:23,  1.98it/s, lr=1.68e-7, step_loss=0.216]07/25/2023 19:14:51 - INFO - __main__ - train loss is 11.00515209324658\n",
      "Steps:   1%|   | 78/15000 [00:41<2:05:38,  1.98it/s, lr=1.7e-7, step_loss=0.304]07/25/2023 19:14:52 - INFO - __main__ - train loss is 11.23828767426312\n",
      "Steps:   1%|  | 79/15000 [00:41<2:05:09,  1.99it/s, lr=1.73e-7, step_loss=0.233]07/25/2023 19:14:52 - INFO - __main__ - train loss is 11.290214566513896\n",
      "Steps:   1%| | 80/15000 [00:42<2:04:25,  2.00it/s, lr=1.75e-7, step_loss=0.0519]07/25/2023 19:14:53 - INFO - __main__ - train loss is 11.559527276083827\n",
      "[2023-07-25 19:14:53,289] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:   1%|  | 81/15000 [00:42<2:03:54,  2.01it/s, lr=1.75e-7, step_loss=0.269]07/25/2023 19:14:53 - INFO - __main__ - train loss is 11.660605637356639\n",
      "Steps:   1%|  | 82/15000 [00:43<2:04:06,  2.00it/s, lr=1.77e-7, step_loss=0.101]07/25/2023 19:14:54 - INFO - __main__ - train loss is 12.101070074364543\n",
      "Steps:   1%|    | 83/15000 [00:43<2:05:10,  1.99it/s, lr=1.8e-7, step_loss=0.44]07/25/2023 19:14:54 - INFO - __main__ - train loss is 12.112793670967221\n",
      "Steps:   1%| | 84/15000 [00:44<2:06:21,  1.97it/s, lr=1.82e-7, step_loss=0.0117]07/25/2023 19:14:55 - INFO - __main__ - train loss is 12.39916236884892\n",
      "Steps:   1%|  | 85/15000 [00:44<2:06:51,  1.96it/s, lr=1.85e-7, step_loss=0.286]07/25/2023 19:14:55 - INFO - __main__ - train loss is 12.437058946117759\n",
      "Steps:   1%| | 86/15000 [00:45<2:05:53,  1.97it/s, lr=1.88e-7, step_loss=0.0379]07/25/2023 19:14:56 - INFO - __main__ - train loss is 12.513950331136584\n",
      "Steps:   1%|  | 87/15000 [00:45<2:05:24,  1.98it/s, lr=1.9e-7, step_loss=0.0769]07/25/2023 19:14:56 - INFO - __main__ - train loss is 12.706680251285434\n",
      "Steps:   1%|  | 88/15000 [00:46<2:05:10,  1.99it/s, lr=1.93e-7, step_loss=0.193]07/25/2023 19:14:57 - INFO - __main__ - train loss is 12.896435527130961\n",
      "Steps:   1%|   | 89/15000 [00:46<2:07:52,  1.94it/s, lr=1.95e-7, step_loss=0.19]07/25/2023 19:14:57 - INFO - __main__ - train loss is 12.922601912170649\n",
      "Steps:   1%| | 90/15000 [00:47<2:07:37,  1.95it/s, lr=1.98e-7, step_loss=0.0262]07/25/2023 19:14:58 - INFO - __main__ - train loss is 13.12894431129098\n",
      "Steps:   1%|     | 91/15000 [00:47<2:06:59,  1.96it/s, lr=2e-7, step_loss=0.206]07/25/2023 19:14:58 - INFO - __main__ - train loss is 13.28705756738782\n",
      "Steps:   1%|  | 92/15000 [00:48<2:06:15,  1.97it/s, lr=2.03e-7, step_loss=0.158]07/25/2023 19:14:59 - INFO - __main__ - train loss is 13.360290620476007\n",
      "Steps:   1%| | 93/15000 [00:48<2:05:45,  1.98it/s, lr=2.05e-7, step_loss=0.0732]07/25/2023 19:14:59 - INFO - __main__ - train loss is 13.444113533943892\n",
      "Steps:   1%| | 94/15000 [00:49<2:05:11,  1.98it/s, lr=2.08e-7, step_loss=0.0838]07/25/2023 19:15:00 - INFO - __main__ - train loss is 13.895089846104383\n",
      "Steps:   1%|   | 95/15000 [00:49<2:06:05,  1.97it/s, lr=2.1e-7, step_loss=0.451]07/25/2023 19:15:00 - INFO - __main__ - train loss is 14.409859996289015\n",
      "Steps:   1%|  | 96/15000 [00:50<2:06:10,  1.97it/s, lr=2.13e-7, step_loss=0.515]07/25/2023 19:15:01 - INFO - __main__ - train loss is 14.798761527985334\n",
      "Steps:   1%|  | 97/15000 [00:50<2:05:33,  1.98it/s, lr=2.15e-7, step_loss=0.389]07/25/2023 19:15:01 - INFO - __main__ - train loss is 14.908068891614676\n",
      "Steps:   1%|  | 98/15000 [00:51<2:05:06,  1.99it/s, lr=2.18e-7, step_loss=0.109]07/25/2023 19:15:02 - INFO - __main__ - train loss is 15.14074882492423\n",
      "Steps:   1%|   | 99/15000 [00:51<2:05:55,  1.97it/s, lr=2.2e-7, step_loss=0.233]07/25/2023 19:15:02 - INFO - __main__ - train loss is 15.142584351473488\n",
      "Steps:   1%| | 100/15000 [00:52<2:05:26,  1.98it/s, lr=2.23e-7, step_loss=0.001807/25/2023 19:15:03 - INFO - __main__ - train loss is 15.211911534541287\n",
      "Steps:   1%| | 101/15000 [00:52<2:05:04,  1.99it/s, lr=2.25e-7, step_loss=0.069307/25/2023 19:15:03 - INFO - __main__ - train loss is 15.245099654071964\n",
      "Steps:   1%| | 102/15000 [00:53<2:05:06,  1.98it/s, lr=2.28e-7, step_loss=0.033207/25/2023 19:15:04 - INFO - __main__ - train loss is 15.425822218530811\n",
      "Steps:   1%|  | 103/15000 [00:53<2:04:54,  1.99it/s, lr=2.3e-7, step_loss=0.181]07/25/2023 19:15:04 - INFO - __main__ - train loss is 15.428955097100697\n",
      "Steps:   1%| | 104/15000 [00:54<2:04:25,  2.00it/s, lr=2.33e-7, step_loss=0.003107/25/2023 19:15:05 - INFO - __main__ - train loss is 15.847006101510487\n",
      "Steps:   1%| | 105/15000 [00:54<2:04:16,  2.00it/s, lr=2.35e-7, step_loss=0.418]07/25/2023 19:15:05 - INFO - __main__ - train loss is 15.855147572583519\n",
      "Steps:   1%| | 106/15000 [00:55<2:04:33,  1.99it/s, lr=2.38e-7, step_loss=0.008107/25/2023 19:15:06 - INFO - __main__ - train loss is 16.33177510125097\n",
      "Steps:   1%|  | 107/15000 [00:55<2:04:26,  1.99it/s, lr=2.4e-7, step_loss=0.477]07/25/2023 19:15:06 - INFO - __main__ - train loss is 16.3353094937047\n",
      "Steps:   1%| | 108/15000 [00:56<2:04:47,  1.99it/s, lr=2.43e-7, step_loss=0.003507/25/2023 19:15:07 - INFO - __main__ - train loss is 16.337875623372383\n",
      "Steps:   1%| | 109/15000 [00:56<2:04:36,  1.99it/s, lr=2.45e-7, step_loss=0.002507/25/2023 19:15:07 - INFO - __main__ - train loss is 17.15999527659733\n",
      "Steps:   1%| | 110/15000 [00:57<2:04:20,  2.00it/s, lr=2.48e-7, step_loss=0.822]07/25/2023 19:15:08 - INFO - __main__ - train loss is 17.16372388333548\n",
      "Steps:   1%| | 111/15000 [00:57<2:05:11,  1.98it/s, lr=2.5e-7, step_loss=0.0037307/25/2023 19:15:08 - INFO - __main__ - train loss is 17.18182585865725\n",
      "Steps:   1%| | 112/15000 [00:58<2:04:48,  1.99it/s, lr=2.53e-7, step_loss=0.018107/25/2023 19:15:09 - INFO - __main__ - train loss is 17.74821029335726\n",
      "Steps:   1%| | 113/15000 [00:58<2:04:34,  1.99it/s, lr=2.55e-7, step_loss=0.566]07/25/2023 19:15:09 - INFO - __main__ - train loss is 17.95684294134844\n",
      "Steps:   1%| | 114/15000 [00:59<2:04:53,  1.99it/s, lr=2.58e-7, step_loss=0.209]07/25/2023 19:15:10 - INFO - __main__ - train loss is 18.613804978434928\n",
      "Steps:   1%|  | 115/15000 [00:59<2:05:08,  1.98it/s, lr=2.6e-7, step_loss=0.657]07/25/2023 19:15:10 - INFO - __main__ - train loss is 18.77327675849665\n",
      "Steps:   1%| | 116/15000 [01:00<2:05:21,  1.98it/s, lr=2.63e-7, step_loss=0.159]07/25/2023 19:15:11 - INFO - __main__ - train loss is 19.127240133588202\n",
      "Steps:   1%| | 117/15000 [01:00<2:05:08,  1.98it/s, lr=2.65e-7, step_loss=0.354]07/25/2023 19:15:11 - INFO - __main__ - train loss is 19.449088645284064\n",
      "Steps:   1%| | 118/15000 [01:01<2:04:39,  1.99it/s, lr=2.68e-7, step_loss=0.322]07/25/2023 19:15:12 - INFO - __main__ - train loss is 19.673396316473372\n",
      "Steps:   1%|  | 119/15000 [01:01<2:04:26,  1.99it/s, lr=2.7e-7, step_loss=0.224]07/25/2023 19:15:12 - INFO - __main__ - train loss is 19.707563341711648\n",
      "Steps:   1%| | 120/15000 [01:02<2:04:48,  1.99it/s, lr=2.73e-7, step_loss=0.034207/25/2023 19:15:13 - INFO - __main__ - train loss is 19.743260846589692\n",
      "Steps:   1%| | 121/15000 [01:02<2:04:41,  1.99it/s, lr=2.75e-7, step_loss=0.035707/25/2023 19:15:13 - INFO - __main__ - train loss is 20.10068182752002\n",
      "Steps:   1%| | 122/15000 [01:03<2:05:57,  1.97it/s, lr=2.78e-7, step_loss=0.357]07/25/2023 19:15:14 - INFO - __main__ - train loss is 20.23038427636493\n",
      "Steps:   1%|   | 123/15000 [01:03<2:05:36,  1.97it/s, lr=2.8e-7, step_loss=0.13]07/25/2023 19:15:14 - INFO - __main__ - train loss is 20.852349148248322\n",
      "Steps:   1%| | 124/15000 [01:04<2:06:02,  1.97it/s, lr=2.83e-7, step_loss=0.622]07/25/2023 19:15:15 - INFO - __main__ - train loss is 20.95329453155864\n",
      "Steps:   1%| | 125/15000 [01:04<2:06:03,  1.97it/s, lr=2.85e-7, step_loss=0.101]07/25/2023 19:15:15 - INFO - __main__ - train loss is 20.95842223346699\n",
      "Steps:   1%| | 126/15000 [01:05<2:05:49,  1.97it/s, lr=2.88e-7, step_loss=0.005107/25/2023 19:15:16 - INFO - __main__ - train loss is 20.98359415784944\n",
      "Steps:   1%| | 127/15000 [01:05<2:05:12,  1.98it/s, lr=2.9e-7, step_loss=0.0252]07/25/2023 19:15:16 - INFO - __main__ - train loss is 21.60334179655183\n",
      "Steps:   1%|  | 128/15000 [01:06<2:05:05,  1.98it/s, lr=2.93e-7, step_loss=0.62]07/25/2023 19:15:17 - INFO - __main__ - train loss is 21.89138791814912\n",
      "Steps:   1%| | 129/15000 [01:06<2:04:59,  1.98it/s, lr=2.95e-7, step_loss=0.288]07/25/2023 19:15:17 - INFO - __main__ - train loss is 21.924351093475707\n",
      "Steps:   1%| | 130/15000 [01:07<2:05:28,  1.98it/s, lr=2.98e-7, step_loss=0.033]07/25/2023 19:15:18 - INFO - __main__ - train loss is 21.9373691707151\n",
      "Steps:   1%|    | 131/15000 [01:07<2:05:45,  1.97it/s, lr=3e-7, step_loss=0.013]07/25/2023 19:15:18 - INFO - __main__ - train loss is 22.324423733283766\n",
      "Steps:   1%| | 132/15000 [01:08<2:06:12,  1.96it/s, lr=3.03e-7, step_loss=0.387]07/25/2023 19:15:19 - INFO - __main__ - train loss is 22.54544982605148\n",
      "Steps:   1%| | 133/15000 [01:08<2:05:47,  1.97it/s, lr=3.05e-7, step_loss=0.221]07/25/2023 19:15:20 - INFO - __main__ - train loss is 22.55799474113155\n",
      "Steps:   1%| | 134/15000 [01:09<2:06:31,  1.96it/s, lr=3.08e-7, step_loss=0.012507/25/2023 19:15:20 - INFO - __main__ - train loss is 22.621362093021162\n",
      "Steps:   1%| | 135/15000 [01:09<2:06:08,  1.96it/s, lr=3.1e-7, step_loss=0.0634]07/25/2023 19:15:21 - INFO - __main__ - train loss is 22.672154731233604\n",
      "Steps:   1%| | 136/15000 [01:10<2:05:25,  1.98it/s, lr=3.13e-7, step_loss=0.050807/25/2023 19:15:21 - INFO - __main__ - train loss is 22.72273134358693\n",
      "Steps:   1%| | 137/15000 [01:10<2:04:42,  1.99it/s, lr=3.15e-7, step_loss=0.050607/25/2023 19:15:22 - INFO - __main__ - train loss is 22.762214011629112\n",
      "Steps:   1%| | 138/15000 [01:11<2:04:35,  1.99it/s, lr=3.18e-7, step_loss=0.039507/25/2023 19:15:22 - INFO - __main__ - train loss is 23.621728367288597\n",
      "Steps:   1%|   | 139/15000 [01:11<2:05:15,  1.98it/s, lr=3.2e-7, step_loss=0.86]07/25/2023 19:15:23 - INFO - __main__ - train loss is 23.793784788926132\n",
      "Steps:   1%| | 140/15000 [01:12<2:05:15,  1.98it/s, lr=3.23e-7, step_loss=0.172]07/25/2023 19:15:23 - INFO - __main__ - train loss is 23.92710114188958\n",
      "Steps:   1%| | 141/15000 [01:12<2:04:54,  1.98it/s, lr=3.25e-7, step_loss=0.133]07/25/2023 19:15:24 - INFO - __main__ - train loss is 23.958356208284386\n",
      "Steps:   1%| | 142/15000 [01:13<2:03:26,  2.01it/s, lr=3.28e-7, step_loss=0.031307/25/2023 19:15:24 - INFO - __main__ - train loss is 24.014910235186107\n",
      "Steps:   1%| | 143/15000 [01:13<2:04:30,  1.99it/s, lr=3.3e-7, step_loss=0.0566]07/25/2023 19:15:25 - INFO - __main__ - train loss is 24.021270673838444\n",
      "Steps:   1%| | 144/15000 [01:14<2:04:04,  2.00it/s, lr=3.33e-7, step_loss=0.006307/25/2023 19:15:25 - INFO - __main__ - train loss is 24.372025411692448\n",
      "Steps:   1%| | 145/15000 [01:14<2:04:13,  1.99it/s, lr=3.35e-7, step_loss=0.351]07/25/2023 19:15:26 - INFO - __main__ - train loss is 24.38795886200387\n",
      "Steps:   1%| | 146/15000 [01:15<2:06:39,  1.95it/s, lr=3.38e-7, step_loss=0.015907/25/2023 19:15:26 - INFO - __main__ - train loss is 24.484404958900996\n",
      "Steps:   1%| | 147/15000 [01:16<2:07:53,  1.94it/s, lr=3.4e-7, step_loss=0.0964]07/25/2023 19:15:27 - INFO - __main__ - train loss is 24.48650405893568\n",
      "Steps:   1%| | 148/15000 [01:16<2:06:30,  1.96it/s, lr=3.43e-7, step_loss=0.002107/25/2023 19:15:27 - INFO - __main__ - train loss is 24.80109761247877\n",
      "Steps:   1%| | 149/15000 [01:17<2:06:02,  1.96it/s, lr=3.45e-7, step_loss=0.315]07/25/2023 19:15:28 - INFO - __main__ - train loss is 25.0187566090608\n",
      "Steps:   1%| | 150/15000 [01:17<2:06:05,  1.96it/s, lr=3.48e-7, step_loss=0.218]07/25/2023 19:15:28 - INFO - __main__ - train loss is 25.041892746114172\n",
      "Steps:   1%| | 151/15000 [01:18<2:05:18,  1.97it/s, lr=3.5e-7, step_loss=0.0231]07/25/2023 19:15:29 - INFO - __main__ - train loss is 25.046267328434624\n",
      "Steps:   1%| | 152/15000 [01:18<2:05:24,  1.97it/s, lr=3.53e-7, step_loss=0.004307/25/2023 19:15:29 - INFO - __main__ - train loss is 25.17100731062237\n",
      "Steps:   1%| | 153/15000 [01:19<2:04:54,  1.98it/s, lr=3.55e-7, step_loss=0.125]07/25/2023 19:15:30 - INFO - __main__ - train loss is 25.174519060296007\n",
      "Steps:   1%| | 154/15000 [01:19<2:05:06,  1.98it/s, lr=3.58e-7, step_loss=0.003507/25/2023 19:15:30 - INFO - __main__ - train loss is 25.188641573418863\n",
      "Steps:   1%| | 155/15000 [01:20<2:05:30,  1.97it/s, lr=3.6e-7, step_loss=0.0141]07/25/2023 19:15:31 - INFO - __main__ - train loss is 25.190596764325164\n",
      "Steps:   1%| | 156/15000 [01:20<2:08:06,  1.93it/s, lr=3.63e-7, step_loss=0.001907/25/2023 19:15:31 - INFO - __main__ - train loss is 25.40147194766905\n",
      "Steps:   1%| | 157/15000 [01:21<2:08:48,  1.92it/s, lr=3.65e-7, step_loss=0.211]07/25/2023 19:15:32 - INFO - __main__ - train loss is 25.435921785770915\n",
      "Steps:   1%| | 158/15000 [01:21<2:07:22,  1.94it/s, lr=3.68e-7, step_loss=0.034407/25/2023 19:15:32 - INFO - __main__ - train loss is 25.438217424671166\n",
      "Steps:   1%| | 159/15000 [01:22<2:06:29,  1.96it/s, lr=3.7e-7, step_loss=0.0023]07/25/2023 19:15:33 - INFO - __main__ - train loss is 25.525418967823498\n",
      "Steps:   1%| | 160/15000 [01:22<2:05:31,  1.97it/s, lr=3.73e-7, step_loss=0.087207/25/2023 19:15:33 - INFO - __main__ - train loss is 25.53759377344977\n",
      "Steps:   1%| | 161/15000 [01:23<2:04:49,  1.98it/s, lr=3.75e-7, step_loss=0.012207/25/2023 19:15:34 - INFO - __main__ - train loss is 25.726681581581943\n",
      "Steps:   1%| | 162/15000 [01:23<2:04:17,  1.99it/s, lr=3.78e-7, step_loss=0.189]07/25/2023 19:15:34 - INFO - __main__ - train loss is 25.999015978421085\n",
      "Steps:   1%|  | 163/15000 [01:24<2:03:57,  1.99it/s, lr=3.8e-7, step_loss=0.272]07/25/2023 19:15:35 - INFO - __main__ - train loss is 26.266718557919376\n",
      "Steps:   1%| | 164/15000 [01:24<2:03:52,  2.00it/s, lr=3.83e-7, step_loss=0.268]07/25/2023 19:15:35 - INFO - __main__ - train loss is 26.271047170157544\n",
      "Steps:   1%| | 165/15000 [01:25<2:04:21,  1.99it/s, lr=3.85e-7, step_loss=0.004307/25/2023 19:15:36 - INFO - __main__ - train loss is 26.27698611735832\n",
      "Steps:   1%| | 166/15000 [01:25<2:14:19,  1.84it/s, lr=3.88e-7, step_loss=0.005907/25/2023 19:15:36 - INFO - __main__ - train loss is 26.295646856422536\n",
      "Steps:   1%| | 167/15000 [01:26<2:11:44,  1.88it/s, lr=3.9e-7, step_loss=0.0187]07/25/2023 19:15:37 - INFO - __main__ - train loss is 26.509895454044454\n",
      "Steps:   1%| | 168/15000 [01:26<2:09:09,  1.91it/s, lr=3.93e-7, step_loss=0.214]07/25/2023 19:15:37 - INFO - __main__ - train loss is 26.930637727375142\n",
      "Steps:   1%| | 169/15000 [01:27<2:07:20,  1.94it/s, lr=3.95e-7, step_loss=0.421]07/25/2023 19:15:38 - INFO - __main__ - train loss is 27.14785958349239\n",
      "Steps:   1%| | 170/15000 [01:27<2:06:09,  1.96it/s, lr=3.98e-7, step_loss=0.217]07/25/2023 19:15:38 - INFO - __main__ - train loss is 27.300326551194303\n",
      "Steps:   1%|    | 171/15000 [01:28<2:05:17,  1.97it/s, lr=4e-7, step_loss=0.152]07/25/2023 19:15:39 - INFO - __main__ - train loss is 27.586803520913236\n",
      "Steps:   1%| | 172/15000 [01:28<2:04:53,  1.98it/s, lr=4.03e-7, step_loss=0.286]07/25/2023 19:15:39 - INFO - __main__ - train loss is 27.757498363847844\n",
      "Steps:   1%| | 173/15000 [01:29<2:04:35,  1.98it/s, lr=4.05e-7, step_loss=0.171]07/25/2023 19:15:40 - INFO - __main__ - train loss is 28.094020794029348\n",
      "Steps:   1%| | 174/15000 [01:29<2:04:05,  1.99it/s, lr=4.08e-7, step_loss=0.337]07/25/2023 19:15:40 - INFO - __main__ - train loss is 28.309828947181813\n",
      "Steps:   1%|  | 175/15000 [01:30<2:05:12,  1.97it/s, lr=4.1e-7, step_loss=0.216]07/25/2023 19:15:41 - INFO - __main__ - train loss is 28.51620235561859\n",
      "Steps:   1%| | 176/15000 [01:30<2:06:46,  1.95it/s, lr=4.13e-7, step_loss=0.206]07/25/2023 19:15:41 - INFO - __main__ - train loss is 28.75605457543861\n",
      "Steps:   1%|  | 177/15000 [01:31<2:05:49,  1.96it/s, lr=4.15e-7, step_loss=0.24]07/25/2023 19:15:42 - INFO - __main__ - train loss is 28.92174814164173\n",
      "Steps:   1%| | 178/15000 [01:31<2:05:25,  1.97it/s, lr=4.18e-7, step_loss=0.166]07/25/2023 19:15:42 - INFO - __main__ - train loss is 28.939590559224598\n",
      "Steps:   1%| | 179/15000 [01:32<2:04:44,  1.98it/s, lr=4.2e-7, step_loss=0.0178]07/25/2023 19:15:43 - INFO - __main__ - train loss is 28.942101554130204\n",
      "Steps:   1%| | 180/15000 [01:32<2:04:18,  1.99it/s, lr=4.23e-7, step_loss=0.002507/25/2023 19:15:43 - INFO - __main__ - train loss is 28.94489678076934\n",
      "Steps:   1%| | 181/15000 [01:33<2:04:04,  1.99it/s, lr=4.25e-7, step_loss=0.002807/25/2023 19:15:44 - INFO - __main__ - train loss is 28.96326883218717\n",
      "Steps:   1%| | 182/15000 [01:33<2:03:45,  2.00it/s, lr=4.28e-7, step_loss=0.018407/25/2023 19:15:44 - INFO - __main__ - train loss is 29.040068850736134\n",
      "Steps:   1%| | 183/15000 [01:34<2:03:26,  2.00it/s, lr=4.3e-7, step_loss=0.0768]07/25/2023 19:15:45 - INFO - __main__ - train loss is 29.31873773119878\n",
      "Steps:   1%| | 184/15000 [01:34<2:03:22,  2.00it/s, lr=4.32e-7, step_loss=0.279]07/25/2023 19:15:45 - INFO - __main__ - train loss is 29.33548402681481\n",
      "Steps:   1%| | 185/15000 [01:35<2:03:28,  2.00it/s, lr=4.35e-7, step_loss=0.016707/25/2023 19:15:46 - INFO - __main__ - train loss is 29.51314476027619\n",
      "Steps:   1%| | 186/15000 [01:35<2:03:26,  2.00it/s, lr=4.37e-7, step_loss=0.178]07/25/2023 19:15:46 - INFO - __main__ - train loss is 29.92127647891175\n",
      "Steps:   1%|  | 187/15000 [01:36<2:03:46,  1.99it/s, lr=4.4e-7, step_loss=0.408]07/25/2023 19:15:47 - INFO - __main__ - train loss is 29.92627546924632\n",
      "Steps:   1%| | 188/15000 [01:36<2:06:38,  1.95it/s, lr=4.42e-7, step_loss=0.005]07/25/2023 19:15:47 - INFO - __main__ - train loss is 29.993164844694547\n",
      "Steps:   1%| | 189/15000 [01:37<2:06:34,  1.95it/s, lr=4.45e-7, step_loss=0.066907/25/2023 19:15:48 - INFO - __main__ - train loss is 30.09749019879382\n",
      "Steps:   1%| | 190/15000 [01:37<2:05:47,  1.96it/s, lr=4.48e-7, step_loss=0.104]07/25/2023 19:15:48 - INFO - __main__ - train loss is 30.144151531043462\n",
      "Steps:   1%| | 191/15000 [01:38<2:05:13,  1.97it/s, lr=4.5e-7, step_loss=0.0467]07/25/2023 19:15:49 - INFO - __main__ - train loss is 30.181668225559406\n",
      "Steps:   1%| | 192/15000 [01:38<2:04:42,  1.98it/s, lr=4.53e-7, step_loss=0.037507/25/2023 19:15:49 - INFO - __main__ - train loss is 30.436858598026447\n",
      "Steps:   1%| | 193/15000 [01:39<2:04:23,  1.98it/s, lr=4.55e-7, step_loss=0.255]07/25/2023 19:15:50 - INFO - __main__ - train loss is 30.461523065227084\n",
      "Steps:   1%| | 194/15000 [01:39<2:04:07,  1.99it/s, lr=4.58e-7, step_loss=0.024707/25/2023 19:15:50 - INFO - __main__ - train loss is 30.483337199199013\n",
      "Steps:   1%| | 195/15000 [01:40<2:03:52,  1.99it/s, lr=4.6e-7, step_loss=0.0218]07/25/2023 19:15:51 - INFO - __main__ - train loss is 30.796022361028008\n",
      "Steps:   1%| | 196/15000 [01:40<2:03:45,  1.99it/s, lr=4.63e-7, step_loss=0.313]07/25/2023 19:15:51 - INFO - __main__ - train loss is 30.838151564705186\n",
      "Steps:   1%| | 197/15000 [01:41<2:04:12,  1.99it/s, lr=4.65e-7, step_loss=0.042107/25/2023 19:15:52 - INFO - __main__ - train loss is 30.931211700546555\n",
      "Steps:   1%| | 198/15000 [01:41<2:04:03,  1.99it/s, lr=4.68e-7, step_loss=0.093107/25/2023 19:15:52 - INFO - __main__ - train loss is 30.991960121202283\n",
      "Steps:   1%| | 199/15000 [01:42<2:04:49,  1.98it/s, lr=4.7e-7, step_loss=0.0607]07/25/2023 19:15:53 - INFO - __main__ - train loss is 31.326873673009686\n",
      "Steps:   1%| | 200/15000 [01:42<2:06:38,  1.95it/s, lr=4.73e-7, step_loss=0.335]07/25/2023 19:15:54 - INFO - __main__ - train loss is 31.52667276363354\n",
      "Steps:   1%|   | 201/15000 [01:43<2:06:28,  1.95it/s, lr=4.75e-7, step_loss=0.2]07/25/2023 19:15:54 - INFO - __main__ - train loss is 31.56311296846252\n",
      "Steps:   1%| | 202/15000 [01:43<2:06:01,  1.96it/s, lr=4.78e-7, step_loss=0.036407/25/2023 19:15:55 - INFO - __main__ - train loss is 31.720502221840434\n",
      "Steps:   1%|  | 203/15000 [01:44<2:05:06,  1.97it/s, lr=4.8e-7, step_loss=0.157]07/25/2023 19:15:55 - INFO - __main__ - train loss is 32.08148005034309\n",
      "Steps:   1%| | 204/15000 [01:44<2:04:35,  1.98it/s, lr=4.83e-7, step_loss=0.361]07/25/2023 19:15:56 - INFO - __main__ - train loss is 32.81402983691078\n",
      "Steps:   1%| | 205/15000 [01:45<2:03:54,  1.99it/s, lr=4.85e-7, step_loss=0.733]07/25/2023 19:15:56 - INFO - __main__ - train loss is 33.04230194713455\n",
      "Steps:   1%| | 206/15000 [01:45<2:03:31,  2.00it/s, lr=4.88e-7, step_loss=0.228]07/25/2023 19:15:57 - INFO - __main__ - train loss is 33.05179919663351\n",
      "Steps:   1%| | 207/15000 [01:46<2:03:21,  2.00it/s, lr=4.9e-7, step_loss=0.0095]07/25/2023 19:15:57 - INFO - __main__ - train loss is 33.19806628290098\n",
      "Steps:   1%| | 208/15000 [01:46<2:03:00,  2.00it/s, lr=4.93e-7, step_loss=0.146]07/25/2023 19:15:58 - INFO - __main__ - train loss is 33.391614187392406\n",
      "Steps:   1%| | 209/15000 [01:47<2:02:56,  2.01it/s, lr=4.95e-7, step_loss=0.194]07/25/2023 19:15:58 - INFO - __main__ - train loss is 33.481824893387966\n",
      "Steps:   1%| | 210/15000 [01:47<2:02:41,  2.01it/s, lr=4.98e-7, step_loss=0.090207/25/2023 19:15:59 - INFO - __main__ - train loss is 33.485753714921884\n",
      "Steps:   1%|  | 211/15000 [01:48<2:04:22,  1.98it/s, lr=5e-7, step_loss=0.00393]07/25/2023 19:15:59 - INFO - __main__ - train loss is 34.25773644435685\n",
      "Steps:   1%| | 212/15000 [01:49<2:08:22,  1.92it/s, lr=5.03e-7, step_loss=0.772]07/25/2023 19:16:00 - INFO - __main__ - train loss is 34.66586089122575\n",
      "Steps:   1%| | 213/15000 [01:49<2:07:59,  1.93it/s, lr=5.05e-7, step_loss=0.408]07/25/2023 19:16:00 - INFO - __main__ - train loss is 34.66828722541686\n",
      "Steps:   1%| | 214/15000 [01:50<2:06:52,  1.94it/s, lr=5.08e-7, step_loss=0.002407/25/2023 19:16:01 - INFO - __main__ - train loss is 34.727188568911515\n",
      "Steps:   1%| | 215/15000 [01:50<2:06:07,  1.95it/s, lr=5.1e-7, step_loss=0.0589]07/25/2023 19:16:01 - INFO - __main__ - train loss is 34.8596524115419\n",
      "Steps:   1%| | 216/15000 [01:51<2:05:14,  1.97it/s, lr=5.12e-7, step_loss=0.132]07/25/2023 19:16:02 - INFO - __main__ - train loss is 34.99287463387009\n",
      "Steps:   1%| | 217/15000 [01:51<2:04:50,  1.97it/s, lr=5.15e-7, step_loss=0.133]07/25/2023 19:16:02 - INFO - __main__ - train loss is 35.05557234247681\n",
      "Steps:   1%| | 218/15000 [01:52<2:04:30,  1.98it/s, lr=5.18e-7, step_loss=0.062707/25/2023 19:16:03 - INFO - __main__ - train loss is 35.15376034786459\n",
      "Steps:   1%| | 219/15000 [01:52<2:04:40,  1.98it/s, lr=5.2e-7, step_loss=0.0982]07/25/2023 19:16:03 - INFO - __main__ - train loss is 35.169521719566546\n",
      "Steps:   1%| | 220/15000 [01:53<2:04:33,  1.98it/s, lr=5.22e-7, step_loss=0.015807/25/2023 19:16:04 - INFO - __main__ - train loss is 35.25650411879178\n",
      "Steps:   1%| | 221/15000 [01:53<2:03:51,  1.99it/s, lr=5.25e-7, step_loss=0.087]07/25/2023 19:16:04 - INFO - __main__ - train loss is 35.68888366257306\n",
      "Steps:   1%| | 222/15000 [01:54<2:03:57,  1.99it/s, lr=5.28e-7, step_loss=0.432]07/25/2023 19:16:05 - INFO - __main__ - train loss is 35.69153421081137\n",
      "Steps:   1%| | 223/15000 [01:54<2:03:36,  1.99it/s, lr=5.3e-7, step_loss=0.0026507/25/2023 19:16:05 - INFO - __main__ - train loss is 35.82623197592329\n",
      "Steps:   1%| | 224/15000 [01:55<2:04:06,  1.98it/s, lr=5.32e-7, step_loss=0.135]07/25/2023 19:16:06 - INFO - __main__ - train loss is 35.92586144513916\n",
      "Steps:   2%| | 225/15000 [01:55<2:05:42,  1.96it/s, lr=5.35e-7, step_loss=0.099607/25/2023 19:16:06 - INFO - __main__ - train loss is 35.95712724782061\n",
      "Steps:   2%| | 226/15000 [01:56<2:09:04,  1.91it/s, lr=5.38e-7, step_loss=0.031307/25/2023 19:16:07 - INFO - __main__ - train loss is 35.95920248690527\n",
      "Steps:   2%| | 227/15000 [01:56<2:07:19,  1.93it/s, lr=5.4e-7, step_loss=0.0020807/25/2023 19:16:07 - INFO - __main__ - train loss is 36.30785443249624\n",
      "Steps:   2%| | 228/15000 [01:57<2:06:17,  1.95it/s, lr=5.42e-7, step_loss=0.349]07/25/2023 19:16:08 - INFO - __main__ - train loss is 36.30984374752734\n",
      "Steps:   2%| | 229/15000 [01:57<2:05:29,  1.96it/s, lr=5.45e-7, step_loss=0.001907/25/2023 19:16:08 - INFO - __main__ - train loss is 36.904276578337885\n",
      "Steps:   2%| | 230/15000 [01:58<2:05:40,  1.96it/s, lr=5.48e-7, step_loss=0.594]07/25/2023 19:16:09 - INFO - __main__ - train loss is 37.290405301959254\n",
      "Steps:   2%|  | 231/15000 [01:58<2:04:52,  1.97it/s, lr=5.5e-7, step_loss=0.386]07/25/2023 19:16:09 - INFO - __main__ - train loss is 37.53697308769915\n",
      "Steps:   2%| | 232/15000 [01:59<2:04:16,  1.98it/s, lr=5.53e-7, step_loss=0.247]07/25/2023 19:16:10 - INFO - __main__ - train loss is 37.59291499352548\n",
      "Steps:   2%| | 233/15000 [01:59<2:03:57,  1.99it/s, lr=5.55e-7, step_loss=0.055907/25/2023 19:16:10 - INFO - __main__ - train loss is 37.59662142454181\n",
      "Steps:   2%| | 234/15000 [02:00<2:03:54,  1.99it/s, lr=5.58e-7, step_loss=0.003707/25/2023 19:16:11 - INFO - __main__ - train loss is 37.927685171947815\n",
      "Steps:   2%|  | 235/15000 [02:00<2:03:43,  1.99it/s, lr=5.6e-7, step_loss=0.331]07/25/2023 19:16:11 - INFO - __main__ - train loss is 37.94422739429865\n",
      "Steps:   2%| | 236/15000 [02:01<2:03:33,  1.99it/s, lr=5.63e-7, step_loss=0.016507/25/2023 19:16:12 - INFO - __main__ - train loss is 37.95960933493916\n",
      "Steps:   2%| | 237/15000 [02:01<2:03:19,  2.00it/s, lr=5.65e-7, step_loss=0.015407/25/2023 19:16:12 - INFO - __main__ - train loss is 38.07764941977803\n",
      "Steps:   2%| | 238/15000 [02:02<2:03:18,  2.00it/s, lr=5.68e-7, step_loss=0.118]07/25/2023 19:16:13 - INFO - __main__ - train loss is 38.08477464609314\n",
      "Steps:   2%| | 239/15000 [02:02<2:06:38,  1.94it/s, lr=5.7e-7, step_loss=0.0071307/25/2023 19:16:13 - INFO - __main__ - train loss is 38.40096685581375\n",
      "Steps:   2%| | 240/15000 [02:03<2:15:06,  1.82it/s, lr=5.73e-7, step_loss=0.316]07/25/2023 19:16:14 - INFO - __main__ - train loss is 38.56833261542488\n",
      "Steps:   2%| | 241/15000 [02:03<2:11:35,  1.87it/s, lr=5.75e-7, step_loss=0.167]07/25/2023 19:16:14 - INFO - __main__ - train loss is 38.901480796863325\n",
      "Steps:   2%| | 242/15000 [02:04<2:09:01,  1.91it/s, lr=5.78e-7, step_loss=0.333]07/25/2023 19:16:15 - INFO - __main__ - train loss is 38.92987405427266\n",
      "Steps:   2%| | 243/15000 [02:04<2:07:10,  1.93it/s, lr=5.8e-7, step_loss=0.0284]07/25/2023 19:16:15 - INFO - __main__ - train loss is 38.94207773648668\n",
      "Steps:   2%| | 244/15000 [02:05<2:06:35,  1.94it/s, lr=5.83e-7, step_loss=0.012207/25/2023 19:16:16 - INFO - __main__ - train loss is 38.94993115973193\n",
      "Steps:   2%| | 245/15000 [02:05<2:05:37,  1.96it/s, lr=5.85e-7, step_loss=0.007807/25/2023 19:16:16 - INFO - __main__ - train loss is 38.962496683117934\n",
      "Steps:   2%| | 246/15000 [02:06<2:04:50,  1.97it/s, lr=5.87e-7, step_loss=0.012607/25/2023 19:16:17 - INFO - __main__ - train loss is 39.07181485008914\n",
      "Steps:   2%|  | 247/15000 [02:06<2:04:11,  1.98it/s, lr=5.9e-7, step_loss=0.109]07/25/2023 19:16:17 - INFO - __main__ - train loss is 39.419660642859526\n",
      "Steps:   2%| | 248/15000 [02:07<2:04:00,  1.98it/s, lr=5.93e-7, step_loss=0.348]07/25/2023 19:16:18 - INFO - __main__ - train loss is 39.652152285096236\n",
      "Steps:   2%| | 249/15000 [02:07<2:04:07,  1.98it/s, lr=5.95e-7, step_loss=0.232]07/25/2023 19:16:18 - INFO - __main__ - train loss is 40.32588295650203\n",
      "Steps:   2%| | 250/15000 [02:08<2:03:34,  1.99it/s, lr=5.97e-7, step_loss=0.674]07/25/2023 19:16:19 - INFO - __main__ - train loss is 40.75574718427379\n",
      "Steps:   2%|     | 251/15000 [02:08<2:03:32,  1.99it/s, lr=6e-7, step_loss=0.43]07/25/2023 19:16:19 - INFO - __main__ - train loss is 40.84599399578292\n",
      "Steps:   2%| | 252/15000 [02:09<2:04:21,  1.98it/s, lr=6.03e-7, step_loss=0.090207/25/2023 19:16:20 - INFO - __main__ - train loss is 40.88315627735574\n",
      "Steps:   2%| | 253/15000 [02:09<2:07:34,  1.93it/s, lr=6.05e-7, step_loss=0.037207/25/2023 19:16:21 - INFO - __main__ - train loss is 41.13985685270745\n",
      "Steps:   2%| | 254/15000 [02:10<2:07:23,  1.93it/s, lr=6.08e-7, step_loss=0.257]07/25/2023 19:16:21 - INFO - __main__ - train loss is 41.19534154620487\n",
      "Steps:   2%| | 255/15000 [02:10<2:05:58,  1.95it/s, lr=6.1e-7, step_loss=0.0555]07/25/2023 19:16:22 - INFO - __main__ - train loss is 42.11507924285252\n",
      "Steps:   2%|  | 256/15000 [02:11<2:05:45,  1.95it/s, lr=6.13e-7, step_loss=0.92]07/25/2023 19:16:22 - INFO - __main__ - train loss is 42.44605787482578\n",
      "Steps:   2%| | 257/15000 [02:11<2:05:24,  1.96it/s, lr=6.15e-7, step_loss=0.331]07/25/2023 19:16:23 - INFO - __main__ - train loss is 42.47698108863551\n",
      "Steps:   2%| | 258/15000 [02:12<2:04:51,  1.97it/s, lr=6.18e-7, step_loss=0.030907/25/2023 19:16:23 - INFO - __main__ - train loss is 42.66637079429347\n",
      "Steps:   2%|  | 259/15000 [02:12<2:04:34,  1.97it/s, lr=6.2e-7, step_loss=0.189]07/25/2023 19:16:24 - INFO - __main__ - train loss is 42.80313974630553\n",
      "Steps:   2%| | 260/15000 [02:13<2:04:18,  1.98it/s, lr=6.23e-7, step_loss=0.137]07/25/2023 19:16:24 - INFO - __main__ - train loss is 43.00524967920501\n",
      "Steps:   2%| | 261/15000 [02:13<2:04:25,  1.97it/s, lr=6.25e-7, step_loss=0.202]07/25/2023 19:16:25 - INFO - __main__ - train loss is 43.023076646146365\n",
      "Steps:   2%| | 262/15000 [02:14<2:04:13,  1.98it/s, lr=6.28e-7, step_loss=0.017807/25/2023 19:16:25 - INFO - __main__ - train loss is 43.51472979050595\n",
      "Steps:   2%|  | 263/15000 [02:15<2:04:28,  1.97it/s, lr=6.3e-7, step_loss=0.492]07/25/2023 19:16:26 - INFO - __main__ - train loss is 43.661957718548365\n",
      "Steps:   2%| | 264/15000 [02:15<2:04:32,  1.97it/s, lr=6.33e-7, step_loss=0.147]07/25/2023 19:16:26 - INFO - __main__ - train loss is 43.66393648029771\n",
      "Steps:   2%| | 265/15000 [02:16<2:04:46,  1.97it/s, lr=6.35e-7, step_loss=0.001907/25/2023 19:16:27 - INFO - __main__ - train loss is 43.669976872741245\n",
      "Steps:   2%| | 266/15000 [02:16<2:04:22,  1.97it/s, lr=6.38e-7, step_loss=0.006007/25/2023 19:16:27 - INFO - __main__ - train loss is 43.76638689392712\n",
      "Steps:   2%| | 267/15000 [02:17<2:04:05,  1.98it/s, lr=6.4e-7, step_loss=0.0964]07/25/2023 19:16:28 - INFO - __main__ - train loss is 43.7782596902689\n",
      "Steps:   2%| | 268/15000 [02:17<2:05:17,  1.96it/s, lr=6.43e-7, step_loss=0.011907/25/2023 19:16:28 - INFO - __main__ - train loss is 43.835786245181225\n",
      "Steps:   2%| | 269/15000 [02:18<2:07:46,  1.92it/s, lr=6.45e-7, step_loss=0.057507/25/2023 19:16:29 - INFO - __main__ - train loss is 43.87398990930524\n",
      "Steps:   2%| | 270/15000 [02:18<2:07:10,  1.93it/s, lr=6.48e-7, step_loss=0.038207/25/2023 19:16:29 - INFO - __main__ - train loss is 43.89283280947711\n",
      "Steps:   2%| | 271/15000 [02:19<2:05:41,  1.95it/s, lr=6.5e-7, step_loss=0.0188]07/25/2023 19:16:30 - INFO - __main__ - train loss is 43.981990830390714\n",
      "Steps:   2%| | 272/15000 [02:19<2:04:35,  1.97it/s, lr=6.53e-7, step_loss=0.089207/25/2023 19:16:30 - INFO - __main__ - train loss is 44.0168740687659\n",
      "Steps:   2%| | 273/15000 [02:20<2:04:09,  1.98it/s, lr=6.55e-7, step_loss=0.034907/25/2023 19:16:31 - INFO - __main__ - train loss is 44.02235036797356\n",
      "Steps:   2%| | 274/15000 [02:20<2:03:48,  1.98it/s, lr=6.58e-7, step_loss=0.005407/25/2023 19:16:31 - INFO - __main__ - train loss is 44.040508222649805\n",
      "Steps:   2%| | 275/15000 [02:21<2:03:25,  1.99it/s, lr=6.6e-7, step_loss=0.0182]07/25/2023 19:16:32 - INFO - __main__ - train loss is 44.089413468609564\n",
      "Steps:   2%| | 276/15000 [02:21<2:03:08,  1.99it/s, lr=6.63e-7, step_loss=0.048907/25/2023 19:16:32 - INFO - __main__ - train loss is 44.10283882066142\n",
      "Steps:   2%| | 277/15000 [02:22<2:02:53,  2.00it/s, lr=6.65e-7, step_loss=0.013407/25/2023 19:16:33 - INFO - __main__ - train loss is 44.1989535902394\n",
      "Steps:   2%| | 278/15000 [02:22<2:03:07,  1.99it/s, lr=6.68e-7, step_loss=0.096107/25/2023 19:16:33 - INFO - __main__ - train loss is 44.29629898711573\n",
      "Steps:   2%| | 279/15000 [02:23<2:03:08,  1.99it/s, lr=6.7e-7, step_loss=0.0973]07/25/2023 19:16:34 - INFO - __main__ - train loss is 44.30476400151383\n",
      "Steps:   2%| | 280/15000 [02:23<2:03:13,  1.99it/s, lr=6.73e-7, step_loss=0.008407/25/2023 19:16:34 - INFO - __main__ - train loss is 44.37331756844651\n",
      "Steps:   2%| | 281/15000 [02:24<2:03:11,  1.99it/s, lr=6.75e-7, step_loss=0.068607/25/2023 19:16:35 - INFO - __main__ - train loss is 44.892791717196815\n",
      "Steps:   2%| | 282/15000 [02:24<2:02:56,  2.00it/s, lr=6.78e-7, step_loss=0.519]07/25/2023 19:16:35 - INFO - __main__ - train loss is 44.935529044712894\n",
      "Steps:   2%| | 283/15000 [02:25<2:03:03,  1.99it/s, lr=6.8e-7, step_loss=0.0427]07/25/2023 19:16:36 - INFO - __main__ - train loss is 45.432113221730106\n",
      "Steps:   2%| | 284/15000 [02:25<2:10:16,  1.88it/s, lr=6.83e-7, step_loss=0.497]07/25/2023 19:16:36 - INFO - __main__ - train loss is 45.70172493800055\n",
      "Steps:   2%|  | 285/15000 [02:26<2:08:58,  1.90it/s, lr=6.85e-7, step_loss=0.27]07/25/2023 19:16:37 - INFO - __main__ - train loss is 45.84540141269099\n",
      "Steps:   2%| | 286/15000 [02:26<2:07:35,  1.92it/s, lr=6.88e-7, step_loss=0.144]07/25/2023 19:16:37 - INFO - __main__ - train loss is 46.276274359668605\n",
      "Steps:   2%|  | 287/15000 [02:27<2:06:32,  1.94it/s, lr=6.9e-7, step_loss=0.431]07/25/2023 19:16:38 - INFO - __main__ - train loss is 46.6187147264136\n",
      "Steps:   2%| | 288/15000 [02:27<2:05:33,  1.95it/s, lr=6.93e-7, step_loss=0.342]07/25/2023 19:16:38 - INFO - __main__ - train loss is 46.67320168658625\n",
      "Steps:   2%| | 289/15000 [02:28<2:04:38,  1.97it/s, lr=6.95e-7, step_loss=0.054507/25/2023 19:16:39 - INFO - __main__ - train loss is 46.78997241600882\n",
      "Steps:   2%| | 290/15000 [02:28<2:03:48,  1.98it/s, lr=6.98e-7, step_loss=0.117]07/25/2023 19:16:39 - INFO - __main__ - train loss is 46.88870144530665\n",
      "Steps:   2%|   | 291/15000 [02:29<2:03:38,  1.98it/s, lr=7e-7, step_loss=0.0987]07/25/2023 19:16:40 - INFO - __main__ - train loss is 46.907454262371175\n",
      "Steps:   2%| | 292/15000 [02:29<2:03:27,  1.99it/s, lr=7.03e-7, step_loss=0.018807/25/2023 19:16:40 - INFO - __main__ - train loss is 47.12590817629825\n",
      "Steps:   2%| | 293/15000 [02:30<2:03:15,  1.99it/s, lr=7.05e-7, step_loss=0.218]07/25/2023 19:16:41 - INFO - __main__ - train loss is 47.15893897309434\n",
      "Steps:   2%| | 294/15000 [02:30<2:02:58,  1.99it/s, lr=7.08e-7, step_loss=0.033]07/25/2023 19:16:41 - INFO - __main__ - train loss is 47.19273191585671\n",
      "Steps:   2%| | 295/15000 [02:31<2:02:40,  2.00it/s, lr=7.1e-7, step_loss=0.0338]07/25/2023 19:16:42 - INFO - __main__ - train loss is 47.23757662519347\n",
      "Steps:   2%| | 296/15000 [02:31<2:02:45,  2.00it/s, lr=7.12e-7, step_loss=0.044807/25/2023 19:16:42 - INFO - __main__ - train loss is 47.2738848318113\n",
      "Steps:   2%| | 297/15000 [02:32<2:02:34,  2.00it/s, lr=7.15e-7, step_loss=0.036307/25/2023 19:16:43 - INFO - __main__ - train loss is 47.4424451579107\n",
      "Steps:   2%| | 298/15000 [02:32<2:01:41,  2.01it/s, lr=7.18e-7, step_loss=0.169]07/25/2023 19:16:43 - INFO - __main__ - train loss is 47.45773654326331\n",
      "Steps:   2%| | 299/15000 [02:33<2:02:05,  2.01it/s, lr=7.2e-7, step_loss=0.0153]07/25/2023 19:16:44 - INFO - __main__ - train loss is 48.1919382129563\n",
      "Steps:   2%| | 300/15000 [02:33<2:02:21,  2.00it/s, lr=7.22e-7, step_loss=0.734]07/25/2023 19:16:44 - INFO - __main__ - train loss is 48.20959472178947\n",
      "Steps:   2%| | 301/15000 [02:34<2:02:26,  2.00it/s, lr=7.25e-7, step_loss=0.017707/25/2023 19:16:45 - INFO - __main__ - train loss is 48.45765992521774\n",
      "Steps:   2%| | 302/15000 [02:34<2:10:50,  1.87it/s, lr=7.28e-7, step_loss=0.248]07/25/2023 19:16:46 - INFO - __main__ - train loss is 48.52897840260994\n",
      "Steps:   2%| | 303/15000 [02:35<2:18:23,  1.77it/s, lr=7.3e-7, step_loss=0.0713]07/25/2023 19:16:46 - INFO - __main__ - Per validation step average loss is 0.03449990227818489\n",
      "07/25/2023 19:16:46 - INFO - __main__ - Cumulative validation average loss is 0.03449990227818489\n",
      "07/25/2023 19:16:47 - INFO - __main__ - Per validation step average loss is 0.003273619804531336\n",
      "07/25/2023 19:16:47 - INFO - __main__ - Cumulative validation average loss is 0.03777352208271623\n",
      "07/25/2023 19:16:47 - INFO - __main__ - Per validation step average loss is 0.06674282252788544\n",
      "07/25/2023 19:16:47 - INFO - __main__ - Cumulative validation average loss is 0.10451634461060166\n",
      "07/25/2023 19:16:48 - INFO - __main__ - Per validation step average loss is 0.23814913630485535\n",
      "07/25/2023 19:16:48 - INFO - __main__ - Cumulative validation average loss is 0.342665480915457\n",
      "07/25/2023 19:16:48 - INFO - __main__ - Per validation step average loss is 0.005902987904846668\n",
      "07/25/2023 19:16:48 - INFO - __main__ - Cumulative validation average loss is 0.3485684688203037\n",
      "07/25/2023 19:16:48 - INFO - __main__ - Per validation step average loss is 0.20203951001167297\n",
      "07/25/2023 19:16:48 - INFO - __main__ - Cumulative validation average loss is 0.5506079788319767\n",
      "07/25/2023 19:16:49 - INFO - __main__ - Per validation step average loss is 0.1281607449054718\n",
      "07/25/2023 19:16:49 - INFO - __main__ - Cumulative validation average loss is 0.6787687237374485\n",
      "07/25/2023 19:16:49 - INFO - __main__ - Per validation step average loss is 0.1278509646654129\n",
      "07/25/2023 19:16:49 - INFO - __main__ - Cumulative validation average loss is 0.8066196884028614\n",
      "07/25/2023 19:16:50 - INFO - __main__ - Per validation step average loss is 0.047793127596378326\n",
      "07/25/2023 19:16:50 - INFO - __main__ - Cumulative validation average loss is 0.8544128159992397\n",
      "07/25/2023 19:16:50 - INFO - __main__ - Per validation step average loss is 0.5022726058959961\n",
      "07/25/2023 19:16:50 - INFO - __main__ - Cumulative validation average loss is 1.3566854218952358\n",
      "07/25/2023 19:16:50 - INFO - __main__ - Per validation step average loss is 0.039992693811655045\n",
      "07/25/2023 19:16:50 - INFO - __main__ - Cumulative validation average loss is 1.3966781157068908\n",
      "07/25/2023 19:16:51 - INFO - __main__ - Per validation step average loss is 0.16502675414085388\n",
      "07/25/2023 19:16:51 - INFO - __main__ - Cumulative validation average loss is 1.5617048698477447\n",
      "07/25/2023 19:16:51 - INFO - __main__ - Per validation step average loss is 0.007206378038972616\n",
      "07/25/2023 19:16:51 - INFO - __main__ - Cumulative validation average loss is 1.5689112478867173\n",
      "07/25/2023 19:16:52 - INFO - __main__ - Per validation step average loss is 0.0028439084999263287\n",
      "07/25/2023 19:16:52 - INFO - __main__ - Cumulative validation average loss is 1.5717551563866436\n",
      "07/25/2023 19:16:52 - INFO - __main__ - Per validation step average loss is 0.34369713068008423\n",
      "07/25/2023 19:16:52 - INFO - __main__ - Cumulative validation average loss is 1.9154522870667279\n",
      "07/25/2023 19:16:53 - INFO - __main__ - Per validation step average loss is 0.011082576587796211\n",
      "07/25/2023 19:16:53 - INFO - __main__ - Cumulative validation average loss is 1.926534863654524\n",
      "07/25/2023 19:16:53 - INFO - __main__ - Per validation step average loss is 0.7133477926254272\n",
      "07/25/2023 19:16:53 - INFO - __main__ - Cumulative validation average loss is 2.6398826562799513\n",
      "07/25/2023 19:16:53 - INFO - __main__ - Per validation step average loss is 0.015026044100522995\n",
      "07/25/2023 19:16:53 - INFO - __main__ - Cumulative validation average loss is 2.6549087003804743\n",
      "07/25/2023 19:16:54 - INFO - __main__ - Per validation step average loss is 0.15442407131195068\n",
      "07/25/2023 19:16:54 - INFO - __main__ - Cumulative validation average loss is 2.809332771692425\n",
      "07/25/2023 19:16:54 - INFO - __main__ - Per validation step average loss is 0.1098155677318573\n",
      "07/25/2023 19:16:54 - INFO - __main__ - Cumulative validation average loss is 2.9191483394242823\n",
      "07/25/2023 19:16:55 - INFO - __main__ - Per validation step average loss is 0.291103720664978\n",
      "07/25/2023 19:16:55 - INFO - __main__ - Cumulative validation average loss is 3.2102520600892603\n",
      "07/25/2023 19:16:55 - INFO - __main__ - Per validation step average loss is 0.0723288506269455\n",
      "07/25/2023 19:16:55 - INFO - __main__ - Cumulative validation average loss is 3.282580910716206\n",
      "07/25/2023 19:16:55 - INFO - __main__ - Per validation step average loss is 0.1833801567554474\n",
      "07/25/2023 19:16:55 - INFO - __main__ - Cumulative validation average loss is 3.4659610674716532\n",
      "07/25/2023 19:16:56 - INFO - __main__ - Per validation step average loss is 0.12775853276252747\n",
      "07/25/2023 19:16:56 - INFO - __main__ - Cumulative validation average loss is 3.5937196002341807\n",
      "07/25/2023 19:16:56 - INFO - __main__ - Per validation step average loss is 0.044090379029512405\n",
      "07/25/2023 19:16:56 - INFO - __main__ - Cumulative validation average loss is 3.637809979263693\n",
      "07/25/2023 19:16:57 - INFO - __main__ - Per validation step average loss is 0.006726912222802639\n",
      "07/25/2023 19:16:57 - INFO - __main__ - Cumulative validation average loss is 3.6445368914864957\n",
      "07/25/2023 19:16:57 - INFO - __main__ - Per validation step average loss is 0.010276595130562782\n",
      "07/25/2023 19:16:57 - INFO - __main__ - Cumulative validation average loss is 3.6548134866170585\n",
      "07/25/2023 19:16:57 - INFO - __main__ - Per validation step average loss is 0.0014412119053304195\n",
      "07/25/2023 19:16:57 - INFO - __main__ - Cumulative validation average loss is 3.656254698522389\n",
      "07/25/2023 19:16:58 - INFO - __main__ - Per validation step average loss is 0.010636488907039165\n",
      "07/25/2023 19:16:58 - INFO - __main__ - Cumulative validation average loss is 3.666891187429428\n",
      "07/25/2023 19:16:58 - INFO - __main__ - Per validation step average loss is 0.02249523624777794\n",
      "07/25/2023 19:16:58 - INFO - __main__ - Cumulative validation average loss is 3.689386423677206\n",
      "07/25/2023 19:16:59 - INFO - __main__ - Per validation step average loss is 0.2642754912376404\n",
      "07/25/2023 19:16:59 - INFO - __main__ - Cumulative validation average loss is 3.9536619149148464\n",
      "07/25/2023 19:16:59 - INFO - __main__ - Per validation step average loss is 0.004208431579172611\n",
      "07/25/2023 19:16:59 - INFO - __main__ - Cumulative validation average loss is 3.957870346494019\n",
      "07/25/2023 19:16:59 - INFO - __main__ - Per validation step average loss is 0.0031259828247129917\n",
      "07/25/2023 19:16:59 - INFO - __main__ - Cumulative validation average loss is 3.960996329318732\n",
      "07/25/2023 19:17:00 - INFO - __main__ - Per validation step average loss is 0.20772811770439148\n",
      "07/25/2023 19:17:00 - INFO - __main__ - Cumulative validation average loss is 4.1687244470231235\n",
      "07/25/2023 19:17:00 - INFO - __main__ - Per validation step average loss is 0.28478574752807617\n",
      "07/25/2023 19:17:00 - INFO - __main__ - Cumulative validation average loss is 4.4535101945512\n",
      "07/25/2023 19:17:01 - INFO - __main__ - Per validation step average loss is 0.36195236444473267\n",
      "07/25/2023 19:17:01 - INFO - __main__ - Cumulative validation average loss is 4.815462558995932\n",
      "07/25/2023 19:17:01 - INFO - __main__ - Per validation step average loss is 0.021298058331012726\n",
      "07/25/2023 19:17:01 - INFO - __main__ - Cumulative validation average loss is 4.836760617326945\n",
      "07/25/2023 19:17:01 - INFO - __main__ - Per validation step average loss is 0.026455044746398926\n",
      "07/25/2023 19:17:01 - INFO - __main__ - Cumulative validation average loss is 4.863215662073344\n",
      "07/25/2023 19:17:02 - INFO - __main__ - Per validation step average loss is 0.2236550897359848\n",
      "07/25/2023 19:17:02 - INFO - __main__ - Cumulative validation average loss is 5.086870751809329\n",
      "07/25/2023 19:17:02 - INFO - __main__ - Per validation step average loss is 0.21821972727775574\n",
      "07/25/2023 19:17:02 - INFO - __main__ - Cumulative validation average loss is 5.3050904790870845\n",
      "07/25/2023 19:17:03 - INFO - __main__ - Per validation step average loss is 0.02169569954276085\n",
      "07/25/2023 19:17:03 - INFO - __main__ - Cumulative validation average loss is 5.326786178629845\n",
      "07/25/2023 19:17:03 - INFO - __main__ - Per validation step average loss is 0.7041383981704712\n",
      "07/25/2023 19:17:03 - INFO - __main__ - Cumulative validation average loss is 6.030924576800317\n",
      "07/25/2023 19:17:04 - INFO - __main__ - Per validation step average loss is 0.029748253524303436\n",
      "07/25/2023 19:17:04 - INFO - __main__ - Cumulative validation average loss is 6.06067283032462\n",
      "07/25/2023 19:17:04 - INFO - __main__ - Per validation step average loss is 0.21841727197170258\n",
      "07/25/2023 19:17:04 - INFO - __main__ - Cumulative validation average loss is 6.279090102296323\n",
      "07/25/2023 19:17:04 - INFO - __main__ - Per validation step average loss is 0.4806380569934845\n",
      "07/25/2023 19:17:04 - INFO - __main__ - Cumulative validation average loss is 6.759728159289807\n",
      "07/25/2023 19:17:05 - INFO - __main__ - Per validation step average loss is 0.0023021965753287077\n",
      "07/25/2023 19:17:05 - INFO - __main__ - Cumulative validation average loss is 6.762030355865136\n",
      "07/25/2023 19:17:05 - INFO - __main__ - Per validation step average loss is 0.0766347125172615\n",
      "07/25/2023 19:17:05 - INFO - __main__ - Cumulative validation average loss is 6.838665068382397\n",
      "07/25/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.24931290745735168\n",
      "07/25/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 7.087977975839749\n",
      "07/25/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.038489386439323425\n",
      "07/25/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 7.126467362279072\n",
      "07/25/2023 19:17:06 - INFO - __main__ - Per validation step average loss is 0.011067185550928116\n",
      "07/25/2023 19:17:06 - INFO - __main__ - Cumulative validation average loss is 7.1375345478300005\n",
      "07/25/2023 19:17:07 - INFO - __main__ - Per validation step average loss is 0.005846285726875067\n",
      "07/25/2023 19:17:07 - INFO - __main__ - Cumulative validation average loss is 7.143380833556876\n",
      "07/25/2023 19:17:07 - INFO - __main__ - Per validation step average loss is 0.0053869388066232204\n",
      "07/25/2023 19:17:07 - INFO - __main__ - Cumulative validation average loss is 7.148767772363499\n",
      "07/25/2023 19:17:08 - INFO - __main__ - Per validation step average loss is 0.062015190720558167\n",
      "07/25/2023 19:17:08 - INFO - __main__ - Cumulative validation average loss is 7.210782963084057\n",
      "07/25/2023 19:17:08 - INFO - __main__ - Per validation step average loss is 0.21131625771522522\n",
      "07/25/2023 19:17:08 - INFO - __main__ - Cumulative validation average loss is 7.422099220799282\n",
      "07/25/2023 19:17:08 - INFO - __main__ - Per validation step average loss is 0.031160444021224976\n",
      "07/25/2023 19:17:08 - INFO - __main__ - Cumulative validation average loss is 7.453259664820507\n",
      "07/25/2023 19:17:09 - INFO - __main__ - Per validation step average loss is 0.0059382496401667595\n",
      "07/25/2023 19:17:09 - INFO - __main__ - Cumulative validation average loss is 7.459197914460674\n",
      "07/25/2023 19:17:09 - INFO - __main__ - Per validation step average loss is 0.0021032504737377167\n",
      "07/25/2023 19:17:09 - INFO - __main__ - Cumulative validation average loss is 7.461301164934412\n",
      "07/25/2023 19:17:10 - INFO - __main__ - Per validation step average loss is 0.02094794437289238\n",
      "07/25/2023 19:17:10 - INFO - __main__ - Cumulative validation average loss is 7.482249109307304\n",
      "07/25/2023 19:17:10 - INFO - __main__ - Per validation step average loss is 0.125512957572937\n",
      "07/25/2023 19:17:10 - INFO - __main__ - Cumulative validation average loss is 7.607762066880241\n",
      "07/25/2023 19:17:10 - INFO - __main__ - Per validation step average loss is 0.21229445934295654\n",
      "07/25/2023 19:17:10 - INFO - __main__ - Cumulative validation average loss is 7.820056526223198\n",
      "07/25/2023 19:17:11 - INFO - __main__ - Per validation step average loss is 0.11950081586837769\n",
      "07/25/2023 19:17:11 - INFO - __main__ - Cumulative validation average loss is 7.939557342091575\n",
      "07/25/2023 19:17:11 - INFO - __main__ - Per validation step average loss is 0.05057062208652496\n",
      "07/25/2023 19:17:11 - INFO - __main__ - Cumulative validation average loss is 7.9901279641781\n",
      "07/25/2023 19:17:12 - INFO - __main__ - Per validation step average loss is 0.20669050514698029\n",
      "07/25/2023 19:17:12 - INFO - __main__ - Cumulative validation average loss is 8.19681846932508\n",
      "07/25/2023 19:17:12 - INFO - __main__ - Per validation step average loss is 0.03507967293262482\n",
      "07/25/2023 19:17:12 - INFO - __main__ - Cumulative validation average loss is 8.231898142257705\n",
      "07/25/2023 19:17:13 - INFO - __main__ - Per validation step average loss is 0.15426310896873474\n",
      "07/25/2023 19:17:13 - INFO - __main__ - Cumulative validation average loss is 8.38616125122644\n",
      "07/25/2023 19:17:13 - INFO - __main__ - Per validation step average loss is 0.013392417691648006\n",
      "07/25/2023 19:17:13 - INFO - __main__ - Cumulative validation average loss is 8.399553668918088\n",
      "07/25/2023 19:17:13 - INFO - __main__ - Per validation step average loss is 0.007689840160310268\n",
      "07/25/2023 19:17:13 - INFO - __main__ - Cumulative validation average loss is 8.407243509078398\n",
      "07/25/2023 19:17:14 - INFO - __main__ - Per validation step average loss is 0.02629309892654419\n",
      "07/25/2023 19:17:14 - INFO - __main__ - Cumulative validation average loss is 8.433536608004943\n",
      "07/25/2023 19:17:14 - INFO - __main__ - Per validation step average loss is 0.10789158940315247\n",
      "07/25/2023 19:17:14 - INFO - __main__ - Cumulative validation average loss is 8.541428197408095\n",
      "07/25/2023 19:17:15 - INFO - __main__ - Per validation step average loss is 0.009203420951962471\n",
      "07/25/2023 19:17:15 - INFO - __main__ - Cumulative validation average loss is 8.550631618360057\n",
      "07/25/2023 19:17:15 - INFO - __main__ - Per validation step average loss is 0.2862958312034607\n",
      "07/25/2023 19:17:15 - INFO - __main__ - Cumulative validation average loss is 8.836927449563518\n",
      "07/25/2023 19:17:15 - INFO - __main__ - Per validation step average loss is 0.27059781551361084\n",
      "07/25/2023 19:17:15 - INFO - __main__ - Cumulative validation average loss is 9.107525265077129\n",
      "07/25/2023 19:17:16 - INFO - __main__ - Per validation step average loss is 0.2074960172176361\n",
      "07/25/2023 19:17:16 - INFO - __main__ - Cumulative validation average loss is 9.315021282294765\n",
      "07/25/2023 19:17:16 - INFO - __main__ - Per validation step average loss is 0.2707277834415436\n",
      "07/25/2023 19:17:16 - INFO - __main__ - Cumulative validation average loss is 9.585749065736309\n",
      "07/25/2023 19:17:17 - INFO - __main__ - Per validation step average loss is 0.0538896806538105\n",
      "07/25/2023 19:17:17 - INFO - __main__ - Cumulative validation average loss is 9.63963874639012\n",
      "07/25/2023 19:17:17 - INFO - __main__ - Per validation step average loss is 0.416317880153656\n",
      "07/25/2023 19:17:17 - INFO - __main__ - Cumulative validation average loss is 10.055956626543775\n",
      "07/25/2023 19:17:17 - INFO - __main__ - Per validation step average loss is 0.0778893530368805\n",
      "07/25/2023 19:17:17 - INFO - __main__ - Cumulative validation average loss is 10.133845979580656\n",
      "07/25/2023 19:17:18 - INFO - __main__ - Per validation step average loss is 0.0190280731767416\n",
      "07/25/2023 19:17:18 - INFO - __main__ - Cumulative validation average loss is 10.152874052757397\n",
      "07/25/2023 19:17:18 - INFO - __main__ - Per validation step average loss is 0.33202099800109863\n",
      "07/25/2023 19:17:18 - INFO - __main__ - Cumulative validation average loss is 10.484895050758496\n",
      "07/25/2023 19:17:18 - INFO - __main__ - Average validation loss for Epoch 0 is 0.13272019051593034\n",
      "07/25/2023 19:17:18 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A spectrogram of acoustic guitar.\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1219, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1116, in main\n",
      "    pipeline(prompt, num_inference_steps=30, generator=generator).images[0]\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 666, in __call__\n",
      "    self.check_inputs(\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 531, in check_inputs\n",
      "    raise ValueError(f\"`prompt` has to be of type `str` or `list` but is {type(prompt)}\")\n",
      "ValueError: `prompt` has to be of type `str` or `list` but is <class 'tuple'>\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1219\u001b[0m in \u001b[92m<module>\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1216 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1217 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1219 \u001b[2m│   \u001b[0mmain()                                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1220 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1116\u001b[0m in \u001b[92mmain\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1113 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mimages = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1114 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m _ \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(args.num_validation_images):       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1115 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mimages.append(                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1116 \u001b[2m│   │   │   │   │   │   │   \u001b[0mpipeline(prompt, num_inference_steps=\u001b[94m30\u001b[0m,  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1117 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m)                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1118 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1119 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mwandb.log(                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/p\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mipelines/stable_diffusion/\u001b[0m\u001b[1;33mpipeline_stable_diffusion.py\u001b[0m:\u001b[94m666\u001b[0m in \u001b[92m__call__\u001b[0m       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m663 \u001b[0m\u001b[2m│   │   \u001b[0mwidth = width \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.unet.config.sample_size * \u001b[96mself\u001b[0m.vae_scale \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m664 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m665 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 1. Check inputs. Raise error if not correct\u001b[0m                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m666 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.check_inputs(                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m667 \u001b[0m\u001b[2m│   │   │   \u001b[0mprompt, height, width, callback_steps, negative_prompt, pr \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m668 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m669 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/diffusers/p\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mipelines/stable_diffusion/\u001b[0m\u001b[1;33mpipeline_stable_diffusion.py\u001b[0m:\u001b[94m531\u001b[0m in \u001b[92mcheck_inputs\u001b[0m   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m528 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mProvide either `prompt` or `prompt_embeds`. Cannot le\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m529 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m530 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m prompt \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m (\u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(prompt, \u001b[96mstr\u001b[0m) \u001b[95mand\u001b[0m \u001b[95mn\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m531 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m`prompt` has to be of type `str` or `li\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m532 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m533 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m negative_prompt \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m negative_prompt_embeds \u001b[95mis\u001b[0m \u001b[95mn\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m534 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mValueError: \u001b[0m`prompt` has to be of type `str` or `list` but is \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'tuple'\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_train_loss_per_epoch ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_valid_loss_per_epoch ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       training_step_loss ▁▃▁▃▁▃▂▆▇▁▁▁▂▁▁▃▇▅▃▁▁▂▃▃▄▁▄▂▂▂▄▁▁▂▂▁▁▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_train_loss_per_epoch 0.16016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: avg_valid_loss_per_epoch 0.13272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       training_step_loss 0.07132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mradiant-wood-139\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/15wqn7qp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 912 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230725_191405-15wqn7qp/logs\u001b[0m\n",
      "\u001b[2;36m[19:17:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m4284\u001b[0m\u001b[1m)\u001b[0m of \u001b]8;id=985634;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=855583;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#672\u001b\\\u001b[2m672\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         binary:                                           \u001b[2m          \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[35m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[95mpython\u001b[0m    \u001b[2m          \u001b[0m\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m926\u001b[0m in \u001b[92mlaunch_command\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m923 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m924 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m925 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m926 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m927 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m928 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m929 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m671\u001b[0m in \u001b[92mdeepspeed_launcher\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m668 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m669 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m670 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m671 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m672 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m673 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m674 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m785\u001b[0m in \u001b[92mrun\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m782 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m783 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m784 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m785 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92m__call__\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mChildFailedError: \u001b[0m\n",
      "============================================================\n",
      "train_text_to_image_lora.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  \u001b[1m<\u001b[0m\u001b[1;95mNO_OTHER_FAILURES\u001b[0m\u001b[39m>\u001b[0m\n",
      "\u001b[39m------------------------------------------------------------\u001b[0m\n",
      "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m07\u001b[0m\u001b[39m-25_\u001b[0m\u001b[1;92m19:17:37\u001b[0m\n",
      "\u001b[39m  host      : honeybone.lan\u001b[0m\n",
      "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4284\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
      "  traceback : To enable traceback see: \n",
      "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/data/dataset/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --validation_epochs=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=1000 \\\n",
    "  --output_dir=$\"./out/25-07\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of acoustic guitar\" \\\n",
    "  --validation_prompt2=\"A spectrogram of cheering\" \\\n",
    "  --validation_prompt3=\"A spectrogram of dog bark\" \\\n",
    "  --validation_prompt4=\"A spectrogram of snare drum\" \\\n",
    "  --validation_prompt5=\"A spectrogram of train horn\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/13-07/2\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
