{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline from downloaded files, to complete huggingface dataset with metadata\n",
    "# Normalisation of sound to [-1, 1]\n",
    "# Construction of full dataset with metadata\n",
    "# Train/Test/Val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.spectrogram_image_converter import SpectrogramImageConverter\n",
    "from utils.spectrogram_params import SpectrogramParams\n",
    "import pydub\n",
    "import typing as T\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class WavPreprocessor:\n",
    "    \n",
    "    def __init__(self, spectrogram_params):\n",
    "        self._params = spectrogram_params\n",
    "        self._converter = SpectrogramImageConverter(params=spectrogram_params, device=\"cuda\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def resample(self, audio, target_sr):\n",
    "        y, sr = librosa.load(audio, sr=None)\n",
    "        \n",
    "        y_resampled = librosa.resample(y=y, orig_sr=sr, target_sr=target_sr)\n",
    "        \n",
    "        return y_resampled, target_sr\n",
    "\n",
    "    def resample_folder(self, input_path, target_sr):\n",
    "        for filename in os.listdir(input_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                path = os.path.join(input_path, filename)\n",
    "                y_resampled, sr = self.resample(path, target_sr)\n",
    "                \n",
    "                save_path = os.path.join(input_path, filename) # Overwrite the original file\n",
    "                sf.write(save_path, y_resampled, sr)\n",
    "\n",
    "    def min_max_normalise(self, audio):\n",
    "        y, sr = librosa.load(audio, sr=None)\n",
    "        \n",
    "        normalised_y = y / np.max(np.abs(y))\n",
    "        \n",
    "        return normalised_y, sr\n",
    "\n",
    "    def min_max_normalise_folder(self, input_path):\n",
    "        for filename in os.listdir(input_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                path = os.path.join(input_path, filename)\n",
    "                norm_wav, sr = self.min_max_normalise(path)\n",
    "                \n",
    "                save_path = os.path.join(input_path, filename) # Overwrite the original file\n",
    "                sf.write(save_path, norm_wav, sr)\n",
    "\n",
    "    def wav_to_spec(self, wav_path, output_path):\n",
    "        # Convert wav to audiosegment\n",
    "        segment = pydub.AudioSegment.from_wav(wav_path)\n",
    "\n",
    "        # Convert to mono\n",
    "        segment = segment.set_channels(1)\n",
    "\n",
    "        # Generate the spectrogram\n",
    "        image = self._converter.spectrogram_image_from_audio(segment)\n",
    "\n",
    "        # Save the image to disk\n",
    "        image_out = os.path.join(output_path, os.path.basename(wav_path)[:-4] + \".png\")\n",
    "        image.save(image_out, exif=image.getexif(), format=\"PNG\")\n",
    "        print(f\"Saved {image_out}\")\n",
    "\n",
    "\n",
    "    def wav_to_spec_folder(self, input_path):\n",
    "        for wav_file in os.listdir(input_path):\n",
    "            if wav_file.endswith('.wav'): # Ensure we're only working on wav files\n",
    "                wav_path = os.path.join(input_path, wav_file)\n",
    "                self.wav_to_spec(wav_path, input_path) # Output to the same folder\n",
    "\n",
    "    # def spec_to_wav(self, spec):\n",
    "    # def spec_to_wav_folder(self, input_path, output_path): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Select chosen classes and copy across into data folder\n",
    "class DatasetPipeline:    \n",
    "    \n",
    "    def __init__(self, dataset_path, class_path, preprocessor, *classes):\n",
    "        self._dataset_path = dataset_path # Where dataset will be constructed\n",
    "        self._class_path = class_path # Where raw data is saved\n",
    "        self._classes = [c for c in classes]\n",
    "        self._preprocessor = preprocessor\n",
    "    \n",
    "    \n",
    "    # Creates corresponding folders for chosen classes\n",
    "    def folder_setup(self):\n",
    "        for folder in self._classes:\n",
    "            dest_folder = os.path.join(self._dataset_path, folder)\n",
    "            if not os.path.exists(dest_folder):\n",
    "                print(f\"Creating directory: {dest_folder}\")\n",
    "                os.makedirs(dest_folder)\n",
    "            else:\n",
    "                print(f\"Directory already exists: {dest_folder}\")\n",
    "\n",
    "\n",
    "    # Copies files excluding those tagged with REMOVE\n",
    "    def copy_files(self):\n",
    "        for folder in os.listdir(self._class_path):  \n",
    "            if folder in self._classes and os.path.isdir(os.path.join(self._class_path, folder)):\n",
    "                for file in os.listdir(os.path.join(self._class_path, folder)):\n",
    "                    if 'REMOVE' in file:\n",
    "                        continue\n",
    "\n",
    "                    # Add the folder name (class name) as prefix to each file\n",
    "                    new_file_name = f\"{folder}_{file}\"\n",
    "                    \n",
    "                    src_file = os.path.join(self._class_path, folder, file)\n",
    "                    dest_file = os.path.join(self._dataset_path, folder, new_file_name)\n",
    "                    \n",
    "                    shutil.copy(src_file, dest_file)\n",
    "\n",
    "        \n",
    "    # Generates a metadata.csv with headings [image, prompt, audiofile]\n",
    "    def generate_metadata(self, prompt=None):\n",
    "        for folder in os.listdir(self._dataset_path):\n",
    "            # Define the output path for the CSV file\n",
    "            csv_path = os.path.join(self._dataset_path, folder, 'metadata.csv')\n",
    "            src_folder = self._dataset_path  # Please adjust this line based on where your data is\n",
    "\n",
    "            # Create the CSV file and write the header\n",
    "            with open(csv_path, 'w', newline='') as csv_file:\n",
    "                writer = csv.writer(csv_file)\n",
    "                writer.writerow(['file_name', 'text', 'audiofile'])\n",
    "\n",
    "                # Get the list of PNG files in the source folder\n",
    "                png_files = [f for f in os.listdir(src_folder) if f.endswith('.png')]\n",
    "\n",
    "                # Iterate over each PNG file\n",
    "                for png_file in png_files:\n",
    "                    # Extract the filename without the extension\n",
    "                    file_name = os.path.splitext(png_file)[0]\n",
    "\n",
    "                    # Construct the corresponding WAV file path\n",
    "                    audio_file = os.path.join(folder, file_name)\n",
    "\n",
    "                    # Get the absolute path of the audio file\n",
    "                    abs_audio_file = os.path.abspath(audio_file)\n",
    "\n",
    "                    # Write the row to the CSV file\n",
    "                    if prompt is None:\n",
    "                        prompt = f\"A spectrogram of {(folder.lower())}\"\n",
    "                        \n",
    "                    writer.writerow([png_file, prompt, abs_audio_file])\n",
    "        \n",
    "        \n",
    "    # Combines all classes into a single dataset folder, combining the metadata\n",
    "    def combine_data(self):\n",
    "        combined_folder = os.path.join(self._dataset_path, \"dataset\", \"unsplit\")\n",
    "        os.makedirs(combined_folder, exist_ok=True)\n",
    "\n",
    "        combined_metadata_path = os.path.join(combined_folder, 'metadata.csv')\n",
    "        with open(combined_metadata_path, 'w', newline='') as combined_metadata:\n",
    "            writer = csv.writer(combined_metadata)\n",
    "            writer.writerow(['file_name', 'text', 'audiofile'])  # Write header to the combined metadata\n",
    "\n",
    "            for folder in self._classes:\n",
    "                class_folder = os.path.join(self._dataset_path, folder)\n",
    "\n",
    "                # Copy files\n",
    "                for file in os.listdir(class_folder):\n",
    "                    if file.endswith(\".wav\") or file.endswith(\".png\"):\n",
    "                        src_file = os.path.join(class_folder, file)\n",
    "                        dest_file = os.path.join(combined_folder, file)\n",
    "                        shutil.copy(src_file, dest_file)\n",
    "\n",
    "                # Append metadata\n",
    "                metadata_path = os.path.join(class_folder, 'metadata.csv')\n",
    "                with open(metadata_path, 'r') as metadata:\n",
    "                    reader = csv.reader(metadata)\n",
    "                    next(reader)  # Skip header\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)  # Write each row to the combined metadata\n",
    "            \n",
    "            \n",
    "        # Splits data into train, test and var folders    \n",
    "    def split_data(self, train_ratio=0.8, val_ratio=0.1):\n",
    "        # Base directory of dataset\n",
    "        base_path = os.path.join(self._dataset_path)\n",
    "\n",
    "        # Create the new directories if they don't exist\n",
    "        train_folder = os.path.join(self._dataset_path, \"dataset\", \"train\")\n",
    "        val_folder = os.path.join(self._dataset_path, \"dataset\", \"val\")\n",
    "        test_folder = os.path.join(self._dataset_path, \"dataset\", \"test\")\n",
    "\n",
    "        os.makedirs(train_folder, exist_ok=True)\n",
    "        os.makedirs(val_folder, exist_ok=True)\n",
    "        os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "        # Iterate over each class directory\n",
    "        for class_dir in os.listdir(base_path):\n",
    "            class_path = os.path.join(base_path, class_dir)\n",
    "\n",
    "            # Collect all unique file prefixes in the class directory\n",
    "            file_prefixes = {filename.split('.')[0] for filename in os.listdir(class_path) if filename.endswith(('.wav', '.png'))}\n",
    "            file_prefixes = list(file_prefixes)\n",
    "\n",
    "            # Shuffle the list for randomness\n",
    "            random.shuffle(file_prefixes)\n",
    "\n",
    "            # Calculate the indices to split at\n",
    "            total_files = len(file_prefixes)\n",
    "            train_split = math.floor(total_files * train_ratio)\n",
    "            val_split = train_split + math.floor(total_files * val_ratio)\n",
    "\n",
    "            # Split the list\n",
    "            train_files = file_prefixes[:train_split]\n",
    "            val_files = file_prefixes[train_split:val_split]\n",
    "            test_files = file_prefixes[val_split:]\n",
    "\n",
    "            # Define a helper function to move files and update metadata\n",
    "            def move_files_and_update_metadata(files, destination_folder, metadata_writer):\n",
    "                for file_prefix in files:\n",
    "                    for extension in ['.wav', '.png']:\n",
    "                        file_name = file_prefix + extension\n",
    "                        src_path = os.path.join(class_path, file_name)\n",
    "                        dest_path = os.path.join(destination_folder, file_name)\n",
    "                        shutil.move(src_path, dest_path)\n",
    "\n",
    "                        # Update the metadata\n",
    "                        if extension == '.wav':  # We only need to do this once per pair, so let's do it for '.wav' files\n",
    "                            abs_audio_file = os.path.abspath(dest_path)\n",
    "                            prompt = f\"A spectrogram of {(file_prefix.lower())}\"\n",
    "                            metadata_writer.writerow([file_name, prompt, abs_audio_file])\n",
    "\n",
    "            # Move the files and update metadata\n",
    "            for folder, files in zip([train_folder, val_folder, test_folder], [train_files, val_files, test_files]):\n",
    "                metadata_path = os.path.join(folder, f\"{class_dir}_metadata.csv\")\n",
    "                with open(metadata_path, 'a', newline='') as metadata_file:  # We use 'a' mode to append to the existing file\n",
    "                    writer = csv.writer(metadata_file)\n",
    "                    if os.path.getsize(metadata_path) == 0:  # If the file is empty, write the header\n",
    "                        writer.writerow(['file_name', 'text', 'audiofile'])\n",
    "                    move_files_and_update_metadata(files, folder, writer)\n",
    "\n",
    "                \n",
    "    def preprocess(self, target_sr):\n",
    "        for folder in os.listdir(self._dataset_path):\n",
    "            if folder not in self._classes:\n",
    "                continue\n",
    "            folder_path = os.path.join(self._dataset_path, folder)  # Full path to the folder\n",
    "            self._preprocessor.resample_folder(folder_path, target_sr)\n",
    "            self._preprocessor.min_max_normalise_folder(folder_path)\n",
    "            self._preprocessor.wav_to_spec_folder(folder_path)\n",
    "\n",
    "\n",
    "    def create_dataset(self, target_sr, train_split, var_split):\n",
    "        assert train_split + var_split <= 1, \"Train and validation split must be less than 1\"\n",
    "        \n",
    "        # 1. Create folders for each class\n",
    "        self.folder_setup()\n",
    "\n",
    "        # 2. Copy files for each class\n",
    "        self.copy_files()\n",
    "        \n",
    "        # 3. Apply preprocessing (resampling and min_max_norm) for each class and create spectrograms\n",
    "        self.preprocess(target_sr)\n",
    "\n",
    "        # 4. Generate metadata for each class\n",
    "        self.generate_metadata()\n",
    "\n",
    "        # 5. Combine all classes into a single dataset folder\n",
    "        self.combine_data()\n",
    "\n",
    "        # 6. Split data into train, test and validation sets\n",
    "        self.split_data(train_ratio=train_split, val_ratio=var_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of target classes\n",
    "classes = [\"Acoustic guitar\", \"Cheering\", \"Dog bark\", \"Snare drum\", \"Train horn\"]\n",
    "\n",
    "# Specify paths\n",
    "class_path = \"./wav\"\n",
    "dataset_path = \"./data\"\n",
    "\n",
    "# Create objects\n",
    "spec_params = SpectrogramParams(\n",
    "        sample_rate=44100,\n",
    "        stereo=False,\n",
    "        step_size_ms=20,\n",
    "        min_frequency=20,\n",
    "        max_frequency=20000,\n",
    "        num_frequencies=512,\n",
    "    )\n",
    "preprocessor = WavPreprocessor(spec_params)\n",
    "pipeline = DatasetPipeline(dataset_path, class_path, preprocessor, *classes)\n",
    "\n",
    "\n",
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.create_dataset(44100, 0.8, 0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
