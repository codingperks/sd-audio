{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline from downloaded files, to complete huggingface dataset with metadata\n",
    "# Normalisation of sound to [-1, 1]\n",
    "# Construction of full dataset with metadata\n",
    "# Train/Test/Val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.spectrogram_image_converter import SpectrogramImageConverter\n",
    "from utils.spectrogram_params import SpectrogramParams\n",
    "import pydub\n",
    "import typing as T\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class WavPreprocessor:\n",
    "    \n",
    "    def __init__(self, spectrogram_params):\n",
    "        self._params = spectrogram_params\n",
    "        self._converter = SpectrogramImageConverter(params=spectrogram_params, device=\"cuda\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def resample(self, audio, target_sr):\n",
    "        y, sr = librosa.load(audio, sr=None)\n",
    "        \n",
    "        y_resampled = librosa.resample(y=y, orig_sr=sr, target_sr=target_sr)\n",
    "        \n",
    "        return y_resampled, target_sr\n",
    "\n",
    "    def resample_folder(self, input_path, target_sr):\n",
    "        for filename in os.listdir(input_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                path = os.path.join(input_path, filename)\n",
    "                y_resampled, sr = self.resample(path, target_sr)\n",
    "                \n",
    "                save_path = os.path.join(input_path, filename) # Overwrite the original file\n",
    "                sf.write(save_path, y_resampled, sr)\n",
    "\n",
    "    def min_max_normalise(self, audio):\n",
    "        y, sr = librosa.load(audio, sr=None)\n",
    "        \n",
    "        normalised_y = y / np.max(np.abs(y))\n",
    "        \n",
    "        return normalised_y, sr\n",
    "\n",
    "    def min_max_normalise_folder(self, input_path):\n",
    "        for filename in os.listdir(input_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                path = os.path.join(input_path, filename)\n",
    "                norm_wav, sr = self.min_max_normalise(path)\n",
    "                \n",
    "                save_path = os.path.join(input_path, filename) # Overwrite the original file\n",
    "                sf.write(save_path, norm_wav, sr)\n",
    "\n",
    "    def wav_to_spec(self, wav_path, output_path):\n",
    "        # Convert wav to audiosegment\n",
    "        segment = pydub.AudioSegment.from_wav(wav_path)\n",
    "\n",
    "        # Convert to mono\n",
    "        segment = segment.set_channels(1)\n",
    "\n",
    "        # Generate the spectrogram\n",
    "        image = self._converter.spectrogram_image_from_audio(segment)\n",
    "\n",
    "        # Save the image to disk\n",
    "        image_out = os.path.join(output_path, os.path.basename(wav_path)[:-4] + \".png\")\n",
    "        image.save(image_out, exif=image.getexif(), format=\"PNG\")\n",
    "        print(f\"Saved {image_out}\")\n",
    "\n",
    "\n",
    "    def wav_to_spec_folder(self, input_path):\n",
    "        for wav_file in os.listdir(input_path):\n",
    "            if wav_file.endswith('.wav'): # Ensure we're only working on wav files\n",
    "                wav_path = os.path.join(input_path, wav_file)\n",
    "                self.wav_to_spec(wav_path, input_path) # Output to the same folder\n",
    "\n",
    "    # def spec_to_wav(self, spec):\n",
    "    # def spec_to_wav_folder(self, input_path, output_path): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Select chosen classes and copy across into data folder\n",
    "class DatasetPipeline:    \n",
    "    \n",
    "    def __init__(self, dataset_path, class_path, preprocessor, *classes):\n",
    "        self._dataset_path = dataset_path # Where dataset will be constructed\n",
    "        self._class_path = class_path # Where raw data is saved\n",
    "        self._classes = [c for c in classes]\n",
    "        self._preprocessor = preprocessor\n",
    "    \n",
    "    \n",
    "    # Creates corresponding folders for chosen classes\n",
    "    def folder_setup(self):\n",
    "        for folder in self._classes:\n",
    "            dest_folder = os.path.join(self._dataset_path, folder)\n",
    "            if not os.path.exists(dest_folder):\n",
    "                print(f\"Creating directory: {dest_folder}\")\n",
    "                os.makedirs(dest_folder)\n",
    "            else:\n",
    "                print(f\"Directory already exists: {dest_folder}\")\n",
    "\n",
    "\n",
    "    # Copies files excluding those tagged with REMOVE\n",
    "    def copy_files(self):\n",
    "        for folder in os.listdir(self._class_path):  \n",
    "            if folder in self._classes and os.path.isdir(os.path.join(self._class_path, folder)):\n",
    "                for file in os.listdir(os.path.join(self._class_path, folder)):\n",
    "                    if 'REMOVE' in file:\n",
    "                        continue\n",
    "\n",
    "                    # Add the folder name (class name) as prefix to each file\n",
    "                    new_file_name = f\"{folder}_{file}\"\n",
    "                    \n",
    "                    src_file = os.path.join(self._class_path, folder, file)\n",
    "                    dest_file = os.path.join(self._dataset_path, folder, new_file_name)\n",
    "                    \n",
    "                    shutil.copy(src_file, dest_file)\n",
    "\n",
    "        \n",
    "    # Generates a metadata.csv with headings [image, prompt, audiofile]\n",
    "    def generate_metadata(self):\n",
    "        # Define the output path for the CSV file\n",
    "        csv_path = os.path.join(self._dataset_path, \"dataset\", \"unsplit\", 'metadata.csv')\n",
    "\n",
    "        # Create the CSV file and write the header\n",
    "        with open(csv_path, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow(['file_name', 'text', 'audiofile'])\n",
    "\n",
    "            # Get the list of PNG files in the source folder\n",
    "            png_files = [f for f in os.listdir(os.path.join(self._dataset_path, \"dataset\", \"unsplit\")) if f.endswith('.png')]\n",
    "\n",
    "            # Iterate over each PNG file\n",
    "            for png_file in png_files:\n",
    "                # Extract the filename without the extension\n",
    "                file_name = os.path.splitext(png_file)[0]\n",
    "\n",
    "                # Construct the corresponding WAV file path\n",
    "                audio_file = file_name + '.wav'\n",
    "\n",
    "                # Construct the prompt\n",
    "                prompt = f\"A spectrogram of {(file_name.split('_')[0])}\"\n",
    "\n",
    "                # Write the row to the CSV file\n",
    "                writer.writerow([png_file, prompt, audio_file])\n",
    "\n",
    "\n",
    "    # Combines all classes into a single dataset folder, combining the metadata\n",
    "    def combine_data(self):\n",
    "        combined_folder = os.path.join(self._dataset_path, \"dataset\", \"unsplit\")\n",
    "        os.makedirs(combined_folder, exist_ok=True)\n",
    "\n",
    "        combined_metadata_path = os.path.join(combined_folder, 'metadata.csv')\n",
    "        with open(combined_metadata_path, 'w', newline='') as combined_metadata:\n",
    "            writer = csv.writer(combined_metadata)\n",
    "            writer.writerow(['file_name', 'text', 'audiofile'])  # Write header to the combined metadata\n",
    "\n",
    "            for folder in self._classes:\n",
    "                class_folder = os.path.join(self._dataset_path, folder)\n",
    "\n",
    "                # Copy files\n",
    "                for file in os.listdir(class_folder):\n",
    "                    if file.endswith(\".wav\") or file.endswith(\".png\"):\n",
    "                        src_file = os.path.join(class_folder, file)\n",
    "                        dest_file = os.path.join(combined_folder, file)\n",
    "                        shutil.copy(src_file, dest_file)\n",
    "\n",
    "                # Append metadata\n",
    "                metadata_path = os.path.join(class_folder, 'metadata.csv')\n",
    "                with open(metadata_path, 'r') as metadata:\n",
    "                    reader = csv.reader(metadata)\n",
    "                    next(reader)  # Skip header\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)  # Write each row to the combined metadata\n",
    "            \n",
    "            \n",
    "    # Splits data into train, test and var folders    \n",
    "    def split_data(self, train_ratio=0.8, val_ratio=0.1):\n",
    "        # Base directory of dataset\n",
    "        base_path = os.path.join(self._dataset_path, \"dataset\", \"unsplit\")\n",
    "\n",
    "        # Create the new directories if they don't exist\n",
    "        train_folder = os.path.join(self._dataset_path, \"dataset\", \"train\")\n",
    "        val_folder = os.path.join(self._dataset_path, \"dataset\", \"val\")\n",
    "        test_folder = os.path.join(self._dataset_path, \"dataset\", \"test\")\n",
    "\n",
    "        os.makedirs(train_folder, exist_ok=True)\n",
    "        os.makedirs(val_folder, exist_ok=True)\n",
    "        os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "        # Create metadata files for each of train, test, and val\n",
    "        train_metadata_path = os.path.join(train_folder, \"metadata.csv\")\n",
    "        val_metadata_path = os.path.join(val_folder, \"metadata.csv\")\n",
    "        test_metadata_path = os.path.join(test_folder, \"metadata.csv\")\n",
    "\n",
    "        # Collect all unique file prefixes in the unsplit directory\n",
    "        file_prefixes = {filename.split('.')[0] for filename in os.listdir(base_path) if filename.endswith(('.wav', '.png'))}\n",
    "        file_prefixes = list(file_prefixes)\n",
    "\n",
    "        # Shuffle the list for randomness\n",
    "        random.shuffle(file_prefixes)\n",
    "\n",
    "        # Calculate the indices to split at\n",
    "        total_files = len(file_prefixes)\n",
    "        train_split = math.floor(total_files * train_ratio)\n",
    "        val_split = train_split + math.floor(total_files * val_ratio)\n",
    "\n",
    "        # Split the list\n",
    "        train_files = file_prefixes[:train_split]\n",
    "        val_files = file_prefixes[train_split:val_split]\n",
    "        test_files = file_prefixes[val_split:]\n",
    "\n",
    "        # Define a helper function to move files\n",
    "        def move_files(files, destination_folder):\n",
    "            for file_prefix in files:\n",
    "                for extension in ['.wav', '.png']:\n",
    "                    file_name = file_prefix + extension\n",
    "                    src_path = os.path.join(base_path, file_name)\n",
    "                    dest_path = os.path.join(destination_folder, file_name)\n",
    "                    shutil.move(src_path, dest_path)\n",
    "\n",
    "        # Move the files\n",
    "        move_files(train_files, train_folder)\n",
    "        move_files(val_files, val_folder)\n",
    "        move_files(test_files, test_folder)\n",
    "        \n",
    "        \n",
    "    # Generates a metadata.csv with headings [image, prompt, audiofile]\n",
    "    def generate_split_metadata(self, split_folder):\n",
    "        # Define the output path for the CSV file\n",
    "        csv_path = os.path.join(self._dataset_path, \"dataset\", split_folder, 'metadata.csv')\n",
    "\n",
    "        # Open the CSV file and write the header\n",
    "        with open(csv_path, 'w', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow(['file_name', 'text', 'audiofile'])\n",
    "\n",
    "            # Iterate over each PNG file in the split directory\n",
    "            for png_file in os.listdir(os.path.join(self._dataset_path, \"dataset\", split_folder)):\n",
    "                if png_file.endswith(\".png\"):\n",
    "                    # Extract the filename without the extension\n",
    "                    file_name = os.path.splitext(png_file)[0]\n",
    "\n",
    "                    # Construct the corresponding WAV file name\n",
    "                    audio_file = file_name + '.wav'\n",
    "\n",
    "                    # Get the absolute path of the audio file\n",
    "                    abs_audio_file = os.path.abspath(os.path.join(self._dataset_path, \"dataset\", split_folder, audio_file))\n",
    "\n",
    "                    # Construct the prompt\n",
    "                    prompt = f\"A spectrogram of {(file_name.split('_')[0])}\"\n",
    "\n",
    "                    # Write the row to the CSV file\n",
    "                    writer.writerow([png_file, prompt, abs_audio_file])\n",
    "\n",
    "\n",
    "    # Apply pre-processing steps to data\n",
    "    def preprocess(self, target_sr):\n",
    "        for folder in os.listdir(self._dataset_path):\n",
    "            if folder not in self._classes:\n",
    "                continue\n",
    "            folder_path = os.path.join(self._dataset_path, folder)  # Full path to the folder\n",
    "            self._preprocessor.resample_folder(folder_path, target_sr)\n",
    "            self._preprocessor.min_max_normalise_folder(folder_path)\n",
    "            self._preprocessor.wav_to_spec_folder(folder_path)\n",
    "\n",
    "\n",
    "    def create_dataset(self, target_sr, train_split, var_split):\n",
    "        assert train_split + var_split <= 1, \"Train and validation split must be less than 1\"\n",
    "        \n",
    "        # 1. Create folders for each class\n",
    "        self.folder_setup()\n",
    "\n",
    "        # 2. Copy files for each class\n",
    "        self.copy_files()\n",
    "        \n",
    "        # 3. Apply preprocessing (resampling and min_max_norm) for each class and create spectrograms\n",
    "        self.preprocess(target_sr)\n",
    "\n",
    "        # 4. Generate metadata for each class\n",
    "        self.generate_metadata()\n",
    "\n",
    "        # 5. Combine all classes into a single dataset folder\n",
    "        self.combine_data()\n",
    "\n",
    "        # 6. Split data into train, test and validation sets\n",
    "        self.split_data(train_ratio=train_split, val_ratio=var_split)\n",
    "        \n",
    "        # 7. Create new metadata\n",
    "        self.generate_split_metadata(\"train\")\n",
    "        self.generate_split_metadata(\"val\")\n",
    "        self.generate_split_metadata(\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of target classes\n",
    "classes = [\"Acoustic guitar\", \"Cheering\", \"Dog bark\", \"Snare drum\", \"Train horn\"]\n",
    "\n",
    "# Specify paths\n",
    "class_path = \"./wav\"\n",
    "dataset_path = \"./data\"\n",
    "\n",
    "# Create objects\n",
    "spec_params = SpectrogramParams(\n",
    "        sample_rate=44100,\n",
    "        stereo=False,\n",
    "        step_size_ms=20,\n",
    "        min_frequency=20,\n",
    "        max_frequency=20000,\n",
    "        num_frequencies=512,\n",
    "    )\n",
    "preprocessor = WavPreprocessor(spec_params)\n",
    "pipeline = DatasetPipeline(dataset_path, class_path, preprocessor, *classes)\n",
    "\n",
    "\n",
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ./data/Acoustic guitar\n",
      "Directory already exists: ./data/Cheering\n",
      "Directory already exists: ./data/Dog bark\n",
      "Directory already exists: ./data/Snare drum\n",
      "Directory already exists: ./data/Train horn\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_15z-gbPxdXg.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_9Qle4fgMbzk.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_ZVvX2-ldhvY.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_hbCaMcbT8to.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_F1uXNtotVsg.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_7ITwarmdyfI.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_AY_yCk4eTTI.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_XoTJkok3FlY.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_5pIdH6p3kuo.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_Mhvgz5AjV3U.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_cYSW6Y884dA.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_1JwoLPCIGhs.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_p1CtK4P7B-w.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_JCxzqy4QcKY.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_c5NGOcNyF4g.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_GW6pti04qIo.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_8UhdwnsckJ8.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_a_r8wKJ8ePw.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_26HLgXWF-Co.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_2K61zdPjAi8.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_ET7yQfaiF_8.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_1o7iTDLNTFk.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_7xD_Ib3VS_w.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_19Pp9QEw17U.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_j-TVVmVmygg.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_CzHZNJEV-3o.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_PkkhCW04O9k.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_axqtExFY5-s.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_HQ9HlWProm0.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_LJsYl38zPOQ.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_2x9735gU01s.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_n3EeS2mVU5w.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_EBpa2CADNJA.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_nsVBasT389w.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_0S5zWt91Bwo.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_-5xOcMJpTUk.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_Hn46VuvS88Y.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_XWVGQbfpA0k.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_yw6uqQQF5Ig.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_33LJ36nAozM.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_0ONdm4sW47c.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_5mut_FrB4As.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_kmZFn-CQ19A.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_-0SdAVK79lg.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_LTG-uVV_6q0.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_4H1nc2Xv2Hg.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_3OLeJZF4oI0.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_4M0njWKFsME.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_JDWPJ1AiDKc.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_S2yXmXUJ5xU.png\n",
      "Saved ./data/Acoustic guitar/Acoustic guitar_drJaSu3AWhQ.png\n",
      "Saved ./data/Train horn/Train horn_9NT6gEiqpWA.png\n",
      "Saved ./data/Train horn/Train horn_2pfjZSno0Bg.png\n",
      "Saved ./data/Train horn/Train horn_ry7WSjD4nOM.png\n",
      "Saved ./data/Train horn/Train horn_Oc9o_IKJqRw.png\n",
      "Saved ./data/Train horn/Train horn_UjlMSYSx49k.png\n",
      "Saved ./data/Train horn/Train horn_uZ9YMoUempU.png\n",
      "Saved ./data/Train horn/Train horn_eykvth4HdUw.png\n",
      "Saved ./data/Train horn/Train horn_x1LeLarmp3U.png\n",
      "Saved ./data/Train horn/Train horn_Va1z0FaJZ9g.png\n",
      "Saved ./data/Train horn/Train horn_Jd6QyMP6Mtk.png\n",
      "Saved ./data/Train horn/Train horn_sn9nx5PKbmA.png\n",
      "Saved ./data/Train horn/Train horn_fvXl_s2jCJ4.png\n",
      "Saved ./data/Train horn/Train horn_uuvp0tkzPbs.png\n",
      "Saved ./data/Train horn/Train horn_LK4b2eJpy24.png\n",
      "Saved ./data/Train horn/Train horn_G958vjLYBcI.png\n",
      "Saved ./data/Train horn/Train horn_g9JVq7wfDIo.png\n",
      "Saved ./data/Train horn/Train horn_hlwuLJ3JfHc.png\n",
      "Saved ./data/Train horn/Train horn_l5IEFoQ_BTQ.png\n",
      "Saved ./data/Train horn/Train horn_E33luTTDMPg.png\n",
      "Saved ./data/Train horn/Train horn_zP_NEorPQnE.png\n",
      "Saved ./data/Train horn/Train horn_mTUgsPfWiwM.png\n",
      "Saved ./data/Train horn/Train horn_cglysWXBmbI.png\n",
      "Saved ./data/Train horn/Train horn_GKc8PCTen8Q.png\n",
      "Saved ./data/Train horn/Train horn_smO6tid5Lsk.png\n",
      "Saved ./data/Train horn/Train horn_u0DxoED_3kA.png\n",
      "Saved ./data/Train horn/Train horn_IyspmEUfytc.png\n",
      "Saved ./data/Train horn/Train horn_if5kBcYKZ_I.png\n",
      "Saved ./data/Train horn/Train horn_UZx7OAgRMRY.png\n",
      "Saved ./data/Train horn/Train horn_ZbfEpDs45Ek.png\n",
      "Saved ./data/Train horn/Train horn_ikK57HnYyVA.png\n",
      "Saved ./data/Train horn/Train horn_bigChhh4a2Y.png\n",
      "Saved ./data/Train horn/Train horn_pGaUuVZe0mQ.png\n",
      "Saved ./data/Train horn/Train horn_d5sA37UOGgw.png\n",
      "Saved ./data/Train horn/Train horn_aXsUHAKbyLs.png\n",
      "Saved ./data/Train horn/Train horn_ahct5yzUtdE.png\n",
      "Saved ./data/Train horn/Train horn_imG4xZBppCc.png\n",
      "Saved ./data/Train horn/Train horn_yBVxtq9k8Sg.png\n",
      "Saved ./data/Train horn/Train horn_FOttjI3p1mM.png\n",
      "Saved ./data/Train horn/Train horn_DtdUYobU_EI.png\n",
      "Saved ./data/Train horn/Train horn_QDS6DNtVWSk.png\n",
      "Saved ./data/Train horn/Train horn_0omVgdC33FQ.png\n",
      "Saved ./data/Train horn/Train horn_ArtL_qXq5Rk.png\n",
      "Saved ./data/Train horn/Train horn_JBOMYsE8s3k.png\n",
      "Saved ./data/Train horn/Train horn__pUzVuWeLjM.png\n",
      "Saved ./data/Train horn/Train horn_XKvLkIM8dck.png\n",
      "Saved ./data/Train horn/Train horn_JNAnQklId4c.png\n",
      "Saved ./data/Train horn/Train horn_Gz6Fmcr7tXQ.png\n",
      "Saved ./data/Train horn/Train horn_wM9wNgY8d4g.png\n",
      "Saved ./data/Train horn/Train horn_pTRYm_peqGA.png\n",
      "Saved ./data/Train horn/Train horn_j2Kb0mdm7nE.png\n",
      "Saved ./data/Train horn/Train horn_8pAigLVDuns.png\n",
      "Saved ./data/Train horn/Train horn_kJCXjkQJ23A.png\n",
      "Saved ./data/Train horn/Train horn_acIL82JWyq4.png\n",
      "Saved ./data/Train horn/Train horn_PE0ddraVcdI.png\n",
      "Saved ./data/Train horn/Train horn_MNkQGlmeyK0.png\n",
      "Saved ./data/Train horn/Train horn_6QCcY4zycIg.png\n",
      "Saved ./data/Cheering/Cheering_RyPTSL-Zb3c.png\n",
      "Saved ./data/Cheering/Cheering_POZdRIMLlXc.png\n",
      "Saved ./data/Cheering/Cheering_3pv0kmrezHI.png\n",
      "Saved ./data/Cheering/Cheering_lGttYO2WqCk.png\n",
      "Saved ./data/Cheering/Cheering_E7cjHvnJLIk.png\n",
      "Saved ./data/Cheering/Cheering_2-RBVkZKJ54.png\n",
      "Saved ./data/Cheering/Cheering_u2iXtdqZIz8.png\n",
      "Saved ./data/Cheering/Cheering__j4Sv4TauOM.png\n",
      "Saved ./data/Cheering/Cheering_Bc6AIHASWxI.png\n",
      "Saved ./data/Cheering/Cheering_-mQR-O53mFE.png\n",
      "Saved ./data/Cheering/Cheering_7J7_OGwI2O4.png\n",
      "Saved ./data/Cheering/Cheering_WtV5ird3gPM.png\n",
      "Saved ./data/Cheering/Cheering_YMqY9e4ZXB4.png\n",
      "Saved ./data/Cheering/Cheering_hEQG_EdBTGI.png\n",
      "Saved ./data/Cheering/Cheering_r7Oq0c1GGqI.png\n",
      "Saved ./data/Cheering/Cheering_pvM9K8h7r1k.png\n",
      "Saved ./data/Cheering/Cheering_wSDBLBR5r4Y.png\n",
      "Saved ./data/Cheering/Cheering_s9IS_lGiKaA.png\n",
      "Saved ./data/Cheering/Cheering_7mGVgQhMQCE.png\n",
      "Saved ./data/Cheering/Cheering_gxv0RVCuw2o.png\n",
      "Saved ./data/Cheering/Cheering_GIFaOp1XGs8.png\n",
      "Saved ./data/Cheering/Cheering_1Z19W2GRX2s.png\n",
      "Saved ./data/Cheering/Cheering_lVCUaqXeBjY.png\n",
      "Saved ./data/Cheering/Cheering_x6T5ambPKwg.png\n",
      "Saved ./data/Cheering/Cheering_2MGsPzzb4yA.png\n",
      "Saved ./data/Cheering/Cheering_lhiQ_aHj7MI.png\n",
      "Saved ./data/Cheering/Cheering_0hrpu0UHkVw.png\n",
      "Saved ./data/Cheering/Cheering_UV90mG6wLBA.png\n",
      "Saved ./data/Cheering/Cheering_L5EscAyv4a4.png\n",
      "Saved ./data/Cheering/Cheering_4AZPDLhB--g.png\n",
      "Saved ./data/Cheering/Cheering_5exxJqJLrts.png\n",
      "Saved ./data/Cheering/Cheering_FwoJ69JvYjo.png\n",
      "Saved ./data/Cheering/Cheering_5upBlkwvHmg.png\n",
      "Saved ./data/Cheering/Cheering_pgaOSSAA_uE.png\n",
      "Saved ./data/Cheering/Cheering_LOLTshIl61E.png\n",
      "Saved ./data/Cheering/Cheering_O_3h32Hetwc.png\n",
      "Saved ./data/Cheering/Cheering_vvi1hCoFAgo.png\n",
      "Saved ./data/Cheering/Cheering_F3lXZDUz4kA.png\n",
      "Saved ./data/Cheering/Cheering_vwJU-4f2rOg.png\n",
      "Saved ./data/Cheering/Cheering_o-uOzHZRdYM.png\n",
      "Saved ./data/Cheering/Cheering_UZYDN3DBkAk.png\n",
      "Saved ./data/Cheering/Cheering_BtwvdgECX10.png\n",
      "Saved ./data/Cheering/Cheering_cnFjR8cfefk.png\n",
      "Saved ./data/Cheering/Cheering_OGPYXJyxQ24.png\n",
      "Saved ./data/Cheering/Cheering_zdPyYwzA1TE.png\n",
      "Saved ./data/Cheering/Cheering_7mp2S19k7as.png\n",
      "Saved ./data/Cheering/Cheering_NPDedSeMXTw.png\n",
      "Saved ./data/Cheering/Cheering_Zno9K9Rvlio.png\n",
      "Saved ./data/Cheering/Cheering_6f9hp7CJn64.png\n",
      "Saved ./data/Cheering/Cheering_EHbGdsiQ-nE.png\n",
      "Saved ./data/Cheering/Cheering_wFwQ6sQWdD8.png\n",
      "Saved ./data/Cheering/Cheering_iYrfMKz1xE8.png\n",
      "Saved ./data/Cheering/Cheering_WhqTqqzGRng.png\n",
      "Saved ./data/Cheering/Cheering_Wre8DkaPhyA.png\n",
      "Saved ./data/Cheering/Cheering_u2AaeUx5cMw.png\n",
      "Saved ./data/Cheering/Cheering_I9nCiUYreVc.png\n",
      "Saved ./data/Cheering/Cheering_cYdq2fjRhcg.png\n",
      "Saved ./data/Cheering/Cheering_8430QfEUpWo.png\n",
      "Saved ./data/Cheering/Cheering_ACm8QhYSQcQ.png\n",
      "Saved ./data/Snare drum/Snare drum_2gvyOxKuQPY.png\n",
      "Saved ./data/Snare drum/Snare drum_n_REM0fSVrA.png\n",
      "Saved ./data/Snare drum/Snare drum_GWcMqKYOJR4.png\n",
      "Saved ./data/Snare drum/Snare drum_CxgVq6eovRU.png\n",
      "Saved ./data/Snare drum/Snare drum_ow12iGt8z5Q.png\n",
      "Saved ./data/Snare drum/Snare drum_HbX1ZIuD0ac.png\n",
      "Saved ./data/Snare drum/Snare drum_tOb0M2k3deo.png\n",
      "Saved ./data/Snare drum/Snare drum_7lV4IvuW2lk.png\n",
      "Saved ./data/Snare drum/Snare drum_JpMHnsdsCiY.png\n",
      "Saved ./data/Snare drum/Snare drum_nu_Bl8Pz6PE.png\n",
      "Saved ./data/Snare drum/Snare drum_Zo9xROGuV3k.png\n",
      "Saved ./data/Snare drum/Snare drum_QrKJs6lBfmM.png\n",
      "Saved ./data/Snare drum/Snare drum_G13NEVAm6-o.png\n",
      "Saved ./data/Snare drum/Snare drum_-SD9DkKyOrY.png\n",
      "Saved ./data/Snare drum/Snare drum_tjQTZM-sqS0.png\n",
      "Saved ./data/Snare drum/Snare drum_wS4d-q9H4NE.png\n",
      "Saved ./data/Snare drum/Snare drum_djSu_1AUt-o.png\n",
      "Saved ./data/Snare drum/Snare drum_Akg1n9IWSrw.png\n",
      "Saved ./data/Snare drum/Snare drum_KqtlecvEOGw.png\n",
      "Saved ./data/Snare drum/Snare drum__DHMdtRRJzE.png\n",
      "Saved ./data/Snare drum/Snare drum_nrj2zTr7U0o.png\n",
      "Saved ./data/Snare drum/Snare drum_f8QGA4vN6HY.png\n",
      "Saved ./data/Snare drum/Snare drum_iBh37YAaHMU.png\n",
      "Saved ./data/Snare drum/Snare drum_KjJj5-HvSvQ.png\n",
      "Saved ./data/Snare drum/Snare drum_ik-fXNjxw58.png\n",
      "Saved ./data/Snare drum/Snare drum_WIuLaxWIAAI.png\n",
      "Saved ./data/Snare drum/Snare drum_jaJdPUAv6N0.png\n",
      "Saved ./data/Snare drum/Snare drum_3Yc7_n6mDsI.png\n",
      "Saved ./data/Snare drum/Snare drum_iMTHDuW_xKc.png\n",
      "Saved ./data/Snare drum/Snare drum_kp5OxEzxuSg.png\n",
      "Saved ./data/Snare drum/Snare drum_pdOskdFwRPg.png\n",
      "Saved ./data/Snare drum/Snare drum_-R0267o4lLk.png\n",
      "Saved ./data/Snare drum/Snare drum_KzzKguqINa8.png\n",
      "Saved ./data/Snare drum/Snare drum_xiN6XwZNEJo.png\n",
      "Saved ./data/Snare drum/Snare drum_5KvjUzQbMT4.png\n",
      "Saved ./data/Snare drum/Snare drum_c8gD6153aNI.png\n",
      "Saved ./data/Snare drum/Snare drum_6og50XOZeIk.png\n",
      "Saved ./data/Snare drum/Snare drum_8Z2GLhocH9A.png\n",
      "Saved ./data/Snare drum/Snare drum_-FFx68qSAuY.png\n",
      "Saved ./data/Snare drum/Snare drum_Qy77eJc72UQ.png\n",
      "Saved ./data/Snare drum/Snare drum_yj4xorgrbV4.png\n",
      "Saved ./data/Snare drum/Snare drum_EieK70X8lnw.png\n",
      "Saved ./data/Snare drum/Snare drum_Wu3LKQG1fwU.png\n",
      "Saved ./data/Snare drum/Snare drum_W_979HkE4EI.png\n",
      "Saved ./data/Snare drum/Snare drum_bJVogLOURmc.png\n",
      "Saved ./data/Snare drum/Snare drum_frqnZb8Ssjo.png\n",
      "Saved ./data/Snare drum/Snare drum_Fsv_syCvzsc.png\n",
      "Saved ./data/Snare drum/Snare drum_JwBJ2WaVp9M.png\n",
      "Saved ./data/Snare drum/Snare drum_A446kjocnCg.png\n",
      "Saved ./data/Snare drum/Snare drum_CYZZIkEw_jY.png\n",
      "Saved ./data/Snare drum/Snare drum_YSXrSxC68VM.png\n",
      "Saved ./data/Snare drum/Snare drum_pwX5SArqGKU.png\n",
      "Saved ./data/Snare drum/Snare drum_ui6ERk-AySw.png\n",
      "Saved ./data/Snare drum/Snare drum_gcdqffsCWI8.png\n",
      "Saved ./data/Snare drum/Snare drum_oFyhlXb7uCE.png\n",
      "Saved ./data/Snare drum/Snare drum_uegzZWp6Y4w.png\n",
      "Saved ./data/Snare drum/Snare drum_PpamaOkNqoI.png\n",
      "Saved ./data/Snare drum/Snare drum_ZCR7qJ2IgGI.png\n",
      "Saved ./data/Snare drum/Snare drum_8zGJ9N7c6pE.png\n",
      "Saved ./data/Snare drum/Snare drum_BcVapmCbULQ.png\n",
      "Saved ./data/Snare drum/Snare drum_pLqa0cqsICA.png\n",
      "Saved ./data/Snare drum/Snare drum_O8EMm4QJjeo.png\n",
      "Saved ./data/Snare drum/Snare drum_7_0g3tEcM0w.png\n",
      "Saved ./data/Snare drum/Snare drum__jhqvXtHcD8.png\n",
      "Saved ./data/Snare drum/Snare drum_zw5gs3uLvV0.png\n",
      "Saved ./data/Snare drum/Snare drum_AkHaDKuiE_s.png\n",
      "Saved ./data/Snare drum/Snare drum_h-3DrDQC62k.png\n",
      "Saved ./data/Snare drum/Snare drum_gjujPd1lP8E.png\n",
      "Saved ./data/Snare drum/Snare drum_xmaVWayBvaY.png\n",
      "Saved ./data/Snare drum/Snare drum_7NtM1MM76s0.png\n",
      "Saved ./data/Snare drum/Snare drum__miAGxDX5FM.png\n",
      "Saved ./data/Snare drum/Snare drum_OWbfAmrFdp8.png\n",
      "Saved ./data/Snare drum/Snare drum_RI71ebbU0PQ.png\n",
      "Saved ./data/Snare drum/Snare drum_VCrnnx9jTqs.png\n",
      "Saved ./data/Snare drum/Snare drum_t1ULMDpL35I.png\n",
      "Saved ./data/Snare drum/Snare drum_8fInAz_GICs.png\n",
      "Saved ./data/Snare drum/Snare drum_rKRI5UcIICI.png\n",
      "Saved ./data/Snare drum/Snare drum_b98BJ36K1wo.png\n",
      "Saved ./data/Snare drum/Snare drum_jR_wBfxgZwE.png\n",
      "Saved ./data/Snare drum/Snare drum_PG1nKnvHjYI.png\n",
      "Saved ./data/Snare drum/Snare drum_kkjNpwNcMWI.png\n",
      "Saved ./data/Snare drum/Snare drum_hbB4rvTgXeY.png\n",
      "Saved ./data/Snare drum/Snare drum_vf3n40mDLHw.png\n",
      "Saved ./data/Snare drum/Snare drum_FvdUm5j_oA0.png\n",
      "Saved ./data/Snare drum/Snare drum_FCvs17jk10A.png\n",
      "Saved ./data/Snare drum/Snare drum_xQX7RH4sgog.png\n",
      "Saved ./data/Dog bark/Dog bark_FuTiynEpLpE.png\n",
      "Saved ./data/Dog bark/Dog bark_Fw09tDLa-78.png\n",
      "Saved ./data/Dog bark/Dog bark_NuMp4zOZEbY.png\n",
      "Saved ./data/Dog bark/Dog bark_Mmke73EQZ08.png\n",
      "Saved ./data/Dog bark/Dog bark_n0P4klG9TFE.png\n",
      "Saved ./data/Dog bark/Dog bark_CTBFPn_S5u0.png\n",
      "Saved ./data/Dog bark/Dog bark_ZNUTbWD5ddE.png\n",
      "Saved ./data/Dog bark/Dog bark_grWa5wDZUVo.png\n",
      "Saved ./data/Dog bark/Dog bark_Glc6Ekc67OE.png\n",
      "Saved ./data/Dog bark/Dog bark_raww5tvi85A.png\n",
      "Saved ./data/Dog bark/Dog bark_5tOj-p8ANmM.png\n",
      "Saved ./data/Dog bark/Dog bark_DOtBB70Jgu4.png\n",
      "Saved ./data/Dog bark/Dog bark_yPkr1XQFNJA.png\n",
      "Saved ./data/Dog bark/Dog bark_9rwfy8B5EB8.png\n",
      "Saved ./data/Dog bark/Dog bark_GZUC9TF1kik.png\n",
      "Saved ./data/Dog bark/Dog bark_R-rS1jnK9Wc.png\n",
      "Saved ./data/Dog bark/Dog bark_3xCWI_22Z9A.png\n",
      "Saved ./data/Dog bark/Dog bark_FTYgwHJUkaY.png\n",
      "Saved ./data/Dog bark/Dog bark_KsT1OSUHFUY.png\n",
      "Saved ./data/Dog bark/Dog bark_yBukUnXhYnc.png\n",
      "Saved ./data/Dog bark/Dog bark_aSNvKefxs4c.png\n",
      "Saved ./data/Dog bark/Dog bark_hZ4d_dQm8jA.png\n",
      "Saved ./data/Dog bark/Dog bark_EakI8v4Ztt4.png\n",
      "Saved ./data/Dog bark/Dog bark_Zy2LsyinGcY.png\n",
      "Saved ./data/Dog bark/Dog bark_RB9xMnuB59A.png\n",
      "Saved ./data/Dog bark/Dog bark_VGpqLyx96Z8.png\n",
      "Saved ./data/Dog bark/Dog bark_k8qNBYDgHBA.png\n",
      "Saved ./data/Dog bark/Dog bark_WkU6zXSeKH8.png\n",
      "Saved ./data/Dog bark/Dog bark_HpWM0fc809Q.png\n",
      "Saved ./data/Dog bark/Dog bark_G7vXKtePlGM.png\n",
      "Saved ./data/Dog bark/Dog bark_GamZltmhYuc.png\n",
      "Saved ./data/Dog bark/Dog bark_QHWuQj95SYw.png\n",
      "Saved ./data/Dog bark/Dog bark_8cDXwosw9nA.png\n",
      "Saved ./data/Dog bark/Dog bark_m3kb8GFAvtI.png\n",
      "Saved ./data/Dog bark/Dog bark_nd78y2xIUuk.png\n",
      "Saved ./data/Dog bark/Dog bark_y6tnyCHq6xE.png\n",
      "Saved ./data/Dog bark/Dog bark_k-MqG-G_H0Y.png\n",
      "Saved ./data/Dog bark/Dog bark_s4wQi-0I2DE.png\n",
      "Saved ./data/Dog bark/Dog bark_id50FKUBH08.png\n",
      "Saved ./data/Dog bark/Dog bark_FeRaDiSPb2c.png\n",
      "Saved ./data/Dog bark/Dog bark_fEO0SbAuBQs.png\n",
      "Saved ./data/Dog bark/Dog bark_P_dXuddk3fE.png\n",
      "Saved ./data/Dog bark/Dog bark_TDBqWGhnoLM.png\n",
      "Saved ./data/Dog bark/Dog bark_64K4SlYR3BU.png\n",
      "Saved ./data/Dog bark/Dog bark_k7SgT11PwXo.png\n",
      "Saved ./data/Dog bark/Dog bark_WyqyK87HomE.png\n",
      "Saved ./data/Dog bark/Dog bark_tYA0D-S_30k.png\n",
      "Saved ./data/Dog bark/Dog bark_6l8elU3VEBE.png\n",
      "Saved ./data/Dog bark/Dog bark_5PbIH_kMyis.png\n",
      "Saved ./data/Dog bark/Dog bark_P_tkRYMJK_M.png\n",
      "Saved ./data/Dog bark/Dog bark_YCy_jDZJy3Y.png\n",
      "Saved ./data/Dog bark/Dog bark_2mJbGx5D-zA.png\n",
      "Saved ./data/Dog bark/Dog bark_h9OFJ5QSpAQ.png\n",
      "Saved ./data/Dog bark/Dog bark_mtjUgt-IUV8.png\n",
      "Saved ./data/Dog bark/Dog bark_Ga_0YqOBcew.png\n"
     ]
    }
   ],
   "source": [
    "pipeline.create_dataset(44100, 0.8, 0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
