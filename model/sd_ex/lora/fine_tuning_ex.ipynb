{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-17 13:01:02,077] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a788ba10105d48598f549caabeaea053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ryan/.cache/huggingface/datasets/imagefolder/default-da7eee62ee4928aa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e32c2452134146b6e56369e71d09c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b643eecb37ca4bde9811cd01dabc83b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3c5d7a59c7443d97127d889aeb4de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a61a44612a4b91a3e8984909b0b2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ryan/.cache/huggingface/datasets/imagefolder/default-da7eee62ee4928aa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-17 13:54:08,613] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-17 13:54:10,729] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-17 13:54:11,929] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-17 13:54:11,929] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-17 13:54:11,929] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/17/2023 13:54:11 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'variance_type', 'sample_max_value', 'thresholding', 'prediction_type', 'dynamic_thresholding_ratio', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'resnet_out_scale_factor', 'projection_class_embeddings_input_dim', 'upcast_attention', 'mid_block_only_cross_attention', 'time_embedding_type', 'time_embedding_act_fn', 'cross_attention_norm', 'time_embedding_dim', 'dual_cross_attention', 'conv_in_kernel', 'resnet_skip_time_act', 'timestep_post_act', 'mid_block_type', 'encoder_hid_dim', 'addition_embed_type', 'time_cond_proj_dim', 'class_embed_type', 'class_embeddings_concat', 'encoder_hid_dim_type', 'conv_out_kernel', 'addition_embed_type_num_heads', 'use_linear_projection', 'only_cross_attention', 'resnet_time_scale_shift', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|█████████████████| 98/98 [00:00<00:00, 638263.65it/s]\n",
      "07/17/2023 13:54:17 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-8cf943ace364c9c3/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1411.99it/s]\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.1974005699157715 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-17 13:54:23,461] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/17/2023 13:54:23 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/17/2023 13:54:23 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-17 13:54:23,500] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-17 13:54:23,501] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-17 13:54:23,501] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-17 13:54:23,507] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 13:54:23,507] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-17 13:54:23,507] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-17 13:54:23,507] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-17 13:54:23,507] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-17 13:54:23,507] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-17 13:54:23,507] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.08920669555664062 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-17 13:54:23,714] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-17 13:54:23,715] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 13:54:23,715] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 10.12 GB, percent = 65.1%\n",
      "[2023-07-17 13:54:23,819] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-17 13:54:23,819] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 13:54:23,820] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 10.13 GB, percent = 65.2%\n",
      "[2023-07-17 13:54:23,820] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-17 13:54:23,913] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-17 13:54:23,914] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 13:54:23,914] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 10.13 GB, percent = 65.2%\n",
      "[2023-07-17 13:54:23,918] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 13:54:23,918] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-17 13:54:23,918] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-17 13:54:23,919] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[(0.9, 0.999)]\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-17 13:54:23,919] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f90882aabc0>\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-17 13:54:23,920] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-17 13:54:23,921] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-17 13:54:23,921] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-17 13:54:23,921] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-17 13:54:23,921] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00021910667419433594 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230717_135424-3kpxpsu3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlaced-vortex-43\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/3kpxpsu3\u001b[0m\n",
      "07/17/2023 13:54:30 - INFO - __main__ - ***** Running training *****\n",
      "07/17/2023 13:54:30 - INFO - __main__ -   Num examples = 97\n",
      "07/17/2023 13:54:30 - INFO - __main__ -   Num Epochs = 600\n",
      "07/17/2023 13:54:30 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/17/2023 13:54:30 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/17/2023 13:54:30 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/17/2023 13:54:30 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1081, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 877, in main\n",
      "    accelerator.backward(loss)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1815, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/deepspeed.py\", line 167, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1862, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 1884, in backward\n",
      "    buf_0 = torch.empty(int(self.reduce_bucket_size),\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 954.00 MiB (GPU 0; 9.76 GiB total capacity; 4.15 GiB already allocated; 490.38 MiB free; 4.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1081\u001b[0m in \u001b[92m<module>\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1078 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1079 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1080 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1081 \u001b[2m│   \u001b[0mmain()                                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1082 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m877\u001b[0m in \u001b[92mmain\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 874 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtrain_loss += avg_loss.item() / args.gradient_accumul \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 875 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 876 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Backpropagate\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 877 \u001b[2m│   │   │   │   \u001b[0maccelerator.backward(loss)                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 878 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m accelerator.sync_gradients:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 879 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mparams_to_clip = lora_layers.parameters()         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 880 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0maccelerator.clip_grad_norm_(params_to_clip, args. \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1815\u001b[0m in \u001b[92mbackward\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# deepspeed handles loss scaling by gradient_accumulation\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1813 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = loss / \u001b[96mself\u001b[0m.gradient_accumulation_steps            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1814 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.distributed_type == DistributedType.DEEPSPEED:        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1815 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.deepspeed_engine_wrapped.backward(loss, **kwargs)    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1816 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.distributed_type == DistributedType.MEGATRON_LM:    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1817 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1818 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.scaler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mutils/\u001b[0m\u001b[1;33mdeepspeed.py\u001b[0m:\u001b[94m167\u001b[0m in \u001b[92mbackward\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbackward\u001b[0m(\u001b[96mself\u001b[0m, loss, **kwargs):                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# runs backpropagation and handles mixed precision\u001b[0m             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m167 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.engine.backward(loss, **kwargs)                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Deepspeed's `engine.step` performs the following operations:\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# - gradient accumulation check\u001b[0m                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/deepspeed/u\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtils/\u001b[0m\u001b[1;33mnvtx.py\u001b[0m:\u001b[94m15\u001b[0m in \u001b[92mwrapped_fn\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapped_fn\u001b[0m(*args, **kwargs):                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0mget_accelerator().range_push(func.\u001b[91m__qualname__\u001b[0m)                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m15 \u001b[2m│   │   \u001b[0mret_val = func(*args, **kwargs)                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0mget_accelerator().range_pop()                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m ret_val                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/deepspeed/r\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33muntime/\u001b[0m\u001b[1;33mengine.py\u001b[0m:\u001b[94m1862\u001b[0m in \u001b[92mbackward\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1859 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1860 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.zero_optimization():                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1861 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.optimizer.is_gradient_accumulation_boundary = \u001b[96mself\u001b[0m.i \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1862 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.optimizer.backward(loss, retain_graph=retain_graph)  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1863 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.amp_enabled():                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1864 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# AMP requires delaying unscale when inside gradient accu\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1865 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# https://nvidia.github.io/apex/advanced.html#gradient-ac\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/deepspeed/r\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33muntime/zero/\u001b[0m\u001b[1;33mstage_1_and_2.py\u001b[0m:\u001b[94m1884\u001b[0m in \u001b[92mbackward\u001b[0m                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1881 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1882 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.contiguous_gradients:                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1883 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.ipg_buffer = []                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1884 \u001b[2m│   │   │   \u001b[0mbuf_0 = torch.empty(\u001b[96mint\u001b[0m(\u001b[96mself\u001b[0m.reduce_bucket_size),         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1885 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0mdtype=\u001b[96mself\u001b[0m.dtype,                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1886 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0mdevice=get_accelerator().current_devi \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1887 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.ipg_buffer.append(buf_0)                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m954.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m9.76\u001b[0m \n",
      "GiB total capacity; \u001b[1;36m4.15\u001b[0m GiB already allocated; \u001b[1;36m490.38\u001b[0m MiB free; \u001b[1;36m4.36\u001b[0m GiB \n",
      "reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
      "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
      "Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlaced-vortex-43\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/3kpxpsu3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230717_135424-3kpxpsu3/logs\u001b[0m\n",
      "\u001b[2;36m[13:54:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m18399\u001b[0m\u001b[1m)\u001b[0m   \u001b]8;id=917197;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=396203;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#672\u001b\\\u001b[2m672\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         of binary:                                        \u001b[2m          \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[35m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[95mpython\u001b[0m    \u001b[2m          \u001b[0m\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m926\u001b[0m in \u001b[92mlaunch_command\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m923 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m924 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m925 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m926 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m927 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m928 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m929 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m671\u001b[0m in \u001b[92mdeepspeed_launcher\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m668 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m669 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m670 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m671 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m672 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m673 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m674 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m785\u001b[0m in \u001b[92mrun\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m782 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m783 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m784 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m785 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92m__call__\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mChildFailedError: \u001b[0m\n",
      "============================================================\n",
      "train_text_to_image_lora.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  \u001b[1m<\u001b[0m\u001b[1;95mNO_OTHER_FAILURES\u001b[0m\u001b[39m>\u001b[0m\n",
      "\u001b[39m------------------------------------------------------------\u001b[0m\n",
      "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m07\u001b[0m\u001b[39m-17_\u001b[0m\u001b[1;92m13:54:44\u001b[0m\n",
      "\u001b[39m  host      : honeybone.lan\u001b[0m\n",
      "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m18399\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
      "  traceback : To enable traceback see: \n",
      "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --val_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/val\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --val_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-04 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/17-07\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-17 10:27:34,906] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-17 10:27:37,001] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:589: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
      "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
      "[2023-07-17 10:27:38,196] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-17 10:27:38,196] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-17 10:27:38,196] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "07/17/2023 10:27:38 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'cpu', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "{'clip_sample_range', 'thresholding', 'sample_max_value', 'prediction_type', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'time_cond_proj_dim', 'conv_out_kernel', 'dual_cross_attention', 'resnet_time_scale_shift', 'use_linear_projection', 'time_embedding_dim', 'only_cross_attention', 'class_embeddings_concat', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'timestep_post_act', 'time_embedding_act_fn', 'addition_embed_type', 'encoder_hid_dim', 'num_class_embeds', 'time_embedding_type', 'class_embed_type', 'encoder_hid_dim_type', 'mid_block_type', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'resnet_out_scale_factor', 'cross_attention_norm', 'upcast_attention', 'mid_block_only_cross_attention'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|███████████████| 123/123 [00:00<00:00, 555327.66it/s]\n",
      "07/17/2023 10:27:41 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/ryan/.cache/huggingface/datasets/imagefolder/default-c5ce92831c385eb9/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1156.73it/s]\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.1926474571228027 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-07-17 10:27:46,312] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.4, git-hash=unknown, git-branch=unknown\n",
      "07/17/2023 10:27:46 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "07/17/2023 10:27:46 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-07-17 10:27:46,346] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-17 10:27:46,347] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-07-17 10:27:46,347] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-07-17 10:27:46,353] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 10:27:46,353] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-07-17 10:27:46,353] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-07-17 10:27:46,353] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ryan/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.07414817810058594 seconds\n",
      "Rank: 0 partition count [1] and sizes[(797184, False)] \n",
      "[2023-07-17 10:27:46,561] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-07-17 10:27:46,561] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 10:27:46,561] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 6.83 GB, percent = 43.9%\n",
      "[2023-07-17 10:27:46,665] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-07-17 10:27:46,666] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 10:27:46,666] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 6.83 GB, percent = 44.0%\n",
      "[2023-07-17 10:27:46,666] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-07-17 10:27:46,761] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-07-17 10:27:46,761] [INFO] [utils.py:786:see_memory_usage] MA 2.02 GB         Max_MA 2.02 GB         CA 2.03 GB         Max_CA 2 GB \n",
      "[2023-07-17 10:27:46,761] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 6.83 GB, percent = 44.0%\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-07-17 10:27:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-17 10:27:46,766] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f59f85e6080>\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   fp16_auto_cast ............... True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   train_batch_size ............. 1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-07-17 10:27:46,767] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": null\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/ryan/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00019621849060058594 seconds\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrap\u001b[0m (\u001b[33msteamclock\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/wandb/run-20230717_102747-5jbkskba\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvolcanic-dew-27\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/5jbkskba\u001b[0m\n",
      "07/17/2023 10:27:52 - INFO - __main__ - ***** Running training *****\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Num examples = 122\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Num Epochs = 484\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "07/17/2023 10:27:52 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 1000, in <module>\n",
      "    main()\n",
      "  File \"/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/train_text_to_image_lora.py\", line 779, in main\n",
      "    image_grid = make_grid(pixel_values)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torchvision/utils.py\", line 63, in make_grid\n",
      "    raise TypeError(f\"tensor or list of tensors expected, got {type(tensor)}\")\n",
      "TypeError: tensor or list of tensors expected, got <class 'numpy.ndarray'>\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1000\u001b[0m in \u001b[92m<module>\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 997 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 998 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 999 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1000 \u001b[2m│   \u001b[0mmain()                                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1001 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/diss/msc_diss/sdspeech/model/sd_ex/lora/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m779\u001b[0m in \u001b[92mmain\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 776 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids = input_ids.cpu().numpy()                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 777 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 778 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Create a grid of images\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 779 \u001b[2m│   │   │   \u001b[0mimage_grid = make_grid(pixel_values)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 780 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 781 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Log the batch of images\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 782 \u001b[0m\u001b[2m│   │   │   \u001b[0mwandb.log({\u001b[33m\"\u001b[0m\u001b[33mbatch_images\u001b[0m\u001b[33m\"\u001b[0m: [wandb.Image(image_grid, capti \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/utils\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torchvision\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m63\u001b[0m in \u001b[92mmake_grid\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m torch.is_tensor(t):                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mtensor or list of tensors expect\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 63 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mtensor or list of tensors expected, got \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# if list of tensors, convert to a 4D mini-batch Tensor\u001b[0m            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(tensor, \u001b[96mlist\u001b[0m):                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mTypeError: \u001b[0mtensor or list of tensors expected, got \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'numpy.ndarray'\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvolcanic-dew-27\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/steamclock/sd_speech/runs/5jbkskba\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230717_102747-5jbkskba/logs\u001b[0m\n",
      "\u001b[2;36m[10:28:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m10562\u001b[0m\u001b[1m)\u001b[0m   \u001b]8;id=417658;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=286919;file:///home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#672\u001b\\\u001b[2m672\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         of binary:                                        \u001b[2m          \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[35m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[95mpython\u001b[0m    \u001b[2m          \u001b[0m\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m926\u001b[0m in \u001b[92mlaunch_command\u001b[0m                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m923 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m924 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m925 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m926 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m927 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m928 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m929 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/accelerate/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mcommands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m671\u001b[0m in \u001b[92mdeepspeed_launcher\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m668 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m669 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m670 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m671 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m672 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m673 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m674 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m785\u001b[0m in \u001b[92mrun\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m782 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m783 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m784 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m785 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92m__call__\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ryan/miniconda3/envs/msc_diss/lib/python3.10/site-packages/torch/distr\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mibuted/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mChildFailedError: \u001b[0m\n",
      "============================================================\n",
      "train_text_to_image_lora.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  \u001b[1m<\u001b[0m\u001b[1;95mNO_OTHER_FAILURES\u001b[0m\u001b[39m>\u001b[0m\n",
      "\u001b[39m------------------------------------------------------------\u001b[0m\n",
      "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m07\u001b[0m\u001b[39m-17_\u001b[0m\u001b[1;92m10:28:00\u001b[0m\n",
      "\u001b[39m  host      : honeybone.lan\u001b[0m\n",
      "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m10562\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
      "  traceback : To enable traceback see: \n",
      "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run training script\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/home/ryan/diss/msc_diss/sdspeech/data/AudioSet/spec/Bird vocalization-bird call-bird song/train\" \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=$\"./out/13-07/2\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"A spectrogram of bird song\" \\\n",
    "  --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "# Load model\n",
    "model_base = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Set model to load fine-tuned weights\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.load_attn_procs(\"./out/26-06\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "inf_out = \"inference/out/11-07/no_aug\"\n",
    "\n",
    "seeds = [0, 1, 42, 49, 55, 1337, 26000, 50000, 50101]\n",
    "\n",
    "prompt = \"a spectrogram of bird song\"\n",
    "\n",
    "for seed in seeds:\n",
    "    gen = torch.manual_seed(seed)\n",
    "    \n",
    "    # use half the weights from the LoRA finetuned model and half the weights from the base model\n",
    "    image = pipe(\n",
    "        prompt, num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={\"scale\": 0}, generator=gen\n",
    "    ).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_base\" + \".png\")\n",
    "    # use the weights from the fully finetuned LoRA model\n",
    "\n",
    "    image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
    "    image.save(inf_out + prompt + \"_\" + str(seed) + \"_lora\" + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def display_images_in_grid(folder_path):\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    image_files.sort()  # Sort the image files in alphabetical order\n",
    "\n",
    "    # Set up the grid layout\n",
    "    num_images = len(image_files)\n",
    "    num_cols = 2  # Number of columns in the grid\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Number of rows based on the number of images\n",
    "\n",
    "    # Create a figure and axis objects\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "        # Adjust the spacing properties\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    # Iterate over the image files and display them in the grid\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Compute the row and column index of the current image\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Load the image using Matplotlib's imread\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Display the image\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "\n",
    "        # Set the filename as the title\n",
    "        \"\"\" filename = os.path.splitext(image_file)[0]\n",
    "        axs[row, col].set_title(filename, fontsize=8) \"\"\"\n",
    "\n",
    "    # Add column titles\n",
    "    axs[0, 0].set_title(\"Base\")\n",
    "    axs[0, 1].set_title(\"LoRA\")\n",
    "\n",
    "    # Adjust the spacing and layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the grid of images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference\n",
    "\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"./inference/05-06-spec-test/\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a72e5e1b89d6aca93f43995c0113c69f11f03ee989f354bc28ea86012bfefd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
